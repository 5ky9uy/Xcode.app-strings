We love Marisa.
N6marisa9ExceptionE
NSt3__117bad_function_callE
NSt3__110__function6__funcIPFvPvPN3nlp15_TrieCompletionEbPbENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEbPbEEE
PFvPvPN3nlp15_TrieCompletionEbPbE
FvPvPN3nlp15_TrieCompletionEbPbE
NSt3__110__function6__baseIFvPvPN3nlp15_TrieCompletionEPbEEE
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_16_RankedTrieLevelEPNS2_15_RankedListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
NSt3__110__function6__baseIFvPvPKhjjfPbEEE
ZN3nlpL12reverseBurstIPNS_16_RankedTrieLevelEPNS_15_RankedListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_16_RankedTrieLevelEPNS2_15_RankedListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE0_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_16_RankedTrieLevelEPNS_15_RankedListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE0_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_10_TrieLevelEPNS2_9_ListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_10_TrieLevelEPNS_9_ListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE_
NSt3__110__function6__funcIZN3nlpL12reverseBurstIPNS2_10_TrieLevelEPNS2_9_ListNodeEEEvPNS2_10_BurstTrieERKNS_6vectorIT_NS_9allocatorISB_EEEEPKhjEUlPvSI_jjfPbE0_NSC_ISL_EEFvSJ_SI_jjfSK_EEE
ZN3nlpL12reverseBurstIPNS_10_TrieLevelEPNS_9_ListNodeEEEvPNS_10_BurstTrieERKNSt3__16vectorIT_NS7_9allocatorIS9_EEEEPKhjEUlPvSG_jjfPbE0_
NSt3__110__function6__funcIZN3nlp15BurstTrieSearchEPKNS2_10_BurstTrieEPKhjPvNS_8functionIFvS8_PNS2_15_TrieCompletionEPbEEEiE3$_0NS_9allocatorISF_EEFvS8_S7_jjfSC_EEE
ZN3nlp15BurstTrieSearchEPKNS_10_BurstTrieEPKhjPvNSt3__18functionIFvS5_PNS_15_TrieCompletionEPbEEEiE3$_0
N11InputEngine15CandidateClonerI22ChineseStringCandidateEE
9CloneableIN11InputEngine20MecabraCandidateBaseEE
22ChineseStringCandidate
N5MeCab5MutexE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine13AsyncResourceINS1_13LanguageModelEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine13AsyncResourceINS1_13LanguageModelEEEEE
NSt3__110__function6__baseIFvPKvEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine19LanguageModelLoaderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine19LanguageModelLoaderEEE
N7Seaweed23SingleWordCandidateWordE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFStringEC1ES3_EUlPKvE_
N11InputEngine13MecabraStrokeE
N11InputEngine30MecabraSimplifiedChineseStrokeE
N11InputEngine31MecabraTraditionalChineseStrokeE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFStringE5resetES3_EUlPKvE_
N11InputEngine27MecabraCharacterInputEngineE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP7__CFSetEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP7__CFSetEC1ES2_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFStringE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFStringE7acquireES3_EUlPKvE_
N11InputEngine14MecabraCangjieE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__120__shared_ptr_pointerIPN11InputEngine12CharacterMapENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine12CharacterMapEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed36SeaweedFileMappedImmutableDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed36SeaweedFileMappedImmutableDictionaryEEE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9_LXCursorEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9_LXCursorEC1ES3_EUlPKvE_
22InspectorAccessContext
N11InputEngine19ConversionCandidateE
N11InputEngine15CandidateClonerI28SyntheticConversionCandidateEE
34ZhuyinSyntheticConversionCandidate
0EN11InputEngine15CandidateClonerINS_34MecabraJapaneseConversionCandidateEEE
N11InputEngine32MecabraJapaneseAcceptedCandidateE
25SyncMutableCFSpecificTypeIP14__CFDictionaryE
16SyncMutableCFRef
22IDXBuiltInAccessMethodI17TrieAccessContextE
15IDXAccessMethod
22IDXBuiltInAccessMethodI17HeapAccessContextE
22IDXBuiltInAccessMethodI22InspectorAccessContextE
N11InputEngine15CandidateClonerI18SyntheticCandidateEE
18SyntheticCandidate
22SyntheticCandidateWord
16IDXAccessContext
17HeapAccessContext
17TrieAccessContext
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
N5MeCab10scoped_ptrINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIcEEEE
N5MeCab4MmapIcEE
N5MeCab10DictionaryE
N5MeCab17MutableDictionaryE
N5MeCab6WriterE
N5MeCab13scoped_stringE
N5MeCab12scoped_arrayIcEE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10__CFLocaleEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10__CFLocaleEC1ES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP19__CFStringTokenizerEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP19__CFStringTokenizerEC1ES2_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP19__CFStringTokenizerE5resetES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP19__CFStringTokenizerE5resetES2_EUlPKvE_
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
21ChineseCompletionWord
N5MeCab5ParamE
N5MeCab12CharPropertyE
N)N+N.N@NGNHN
ZNiN
N,4.4
OdO7O>OTOXO
wOxOzO}O
P"Ph4BPFPNPSPWPcPfPjPpP
UR\RlRwR
S$S5S>SBS
gSlSzS
]5^5
SUT$T(Tn5CTbTfTlT
<UAU
5GUJU
5`UaUdU
V0V7V
5=V?V@VGV^V`VmV
EWFWLWMW
hWoWsWtWuW{W
 X'X2X9X
IXLXgX
[Y_Y
uYvY|Y
Z'Z-ZUZeZzZ
[4[-[L[R[h[o[|[
[l7k7
\)\0\
_\c\g\h\i\p\
] ]$]&]1]9]B]
7a]j]
^.^>^I^\8V^a8k^l^m^
_G_c_r_~_
`"`$`
a:ao9AaFa`a|a
b#b)bFbLbQbRbabdb{bmbsb
2c5c;c<cAcDcNc
d%d)d/dZd[d]dsd}d
e2eDeTekeze
f!f*fEfQfNf
[fcf
jfkflfmf{f
LgMgTg]g
tgvg
3h;h>hDhEhIhLhUhWhw;khnhzh|h
;Fiiilirizi
2j3j4j?jFjIjzjNjRjdj
k&</kJkXklkukzk
l5l6l:l
?lMl[lml
m$m&m'mgl/m<m[m^m`mpm
n"n'n
=2n<nHnInKnLnOnQnSnTnWncn
o%o6o<o
RoWoZo`oho
9p:p<pCpGpKp
=Tpepiplpnpvp~p
=/q1qPqJqSq^q
+r4r8r9r,NBrSrWrcr
nrorxr
rf>h>
>9s,s1s3s=sRs
>ksls
nsosqsws
t$t1t9tSt@tCtMtRt]tqt
 u$u*uW?
=u>u@uHuNuPuRuluruquzu}u~u
%v(v<v3v
IvUv
w-w5w
Xw`wjw
rw|w}w
x!x,xGxdxjx
y0y%y;yJyXy[y
Agyry
zcA-z
8zGzLzVzYz\z_z`zgzjzuzxz
={'{*{.{/{1{
AU{y{d{f{i{s{
|&|E|J|Q|W|^|a|i|n|o|p|
=}>}@}G}
BY}Z}j}p}
~ ~'~,~E~s~u~~~
~CC<
%ECE>
& % 
f"g"
"4"B&@&
2 3 
304050;0<0
"*")"
#'"("
"%"&"
"a"R"j"k"
"5"+","b"C"E"H"v"w"
!+!0 o&m&j&  ! 
n&k&l&i&
!4)5)
%=0F
%" !
!'!A
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
0K0M0O0Q0S0
d&`&b&f&a&e&g&c&
"S!T!U!
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%Q2R2S2T2U2V2W2X2Y2Z2[2\2]2^2_2
%< G H I 
v'w'x'y'z'{'|'}'~'
$p!q!r!s!t!u!v!w!x!y!z!{!
Q B 
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!j!I3
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3
4(N/N0N
O`OHOIOVO_OjOlO~O
P'P.P@P;PAP
Q5QJQ2
UQWQ
RIRWRaR
aScS}S
T'TMT
TkTtT
U+U5UPU^U
V;VIVvVfV8
oVqVrV
!W/W3W4WpWwW|W
aXdX9
XYA
]YmY
Z#ZgZmZwZ~Z
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
gbk{k
lEsIy
OPQW[
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0R
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
hsidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
A[V[}[
\#\+\
7b\;
F]G]S]J]m]
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8VkVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\
P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
ckcic
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpv
rvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~2~:~g~]~V~^~Y~Z~y~j~i~|~{~
^X^^^
_#_4_6_=_@_E_T_X_d_g_}_
`3`5`G`=
a+a0a7a>
"b>bCbVbZbob
c9cCcec|c
d"dydQd`dmd
d"e)eA
f:f"f$f+f0f1f3f
fHfLf
YfZfafefsfwfxf
3gfgGgHg{g
h,h1h[hrhuhD
5iBiWicidihi
;j>jEjPjVj[jkjsj
k,k5kFkVk`kekgkwk
l3lYl\l
ltlvl
m.m1m9m?mXmemE
4nDn\n^n
*o/o3oQoYo^oaobo~o
p(pJp]p^pNpdpup
q q.q0qFqGqQqH
Rq\q`qhq
rUrVr?>
's(s
Psfs|s
&t(t*t+t,t.t/t0tDtFtGtKtWtbtktmt
u/uouyu
v-v5vCvKvdvevmvovqv
w4w6wFwMwNw\w_wbwzw
CxNxOxQxhxnxK
y.y1y4yL
EyFyN
9z]zmzU
{-{;{G{N{`{m{o{r{
| |3|6|dB
Y|m|y|
}#}1}
A}H}S}\}z}
G~R~a~
SD[D`
& % 
f"g"
"4"B&@&
2 3 
"*")"
'"("
"a"R"j"k"
"5"+","
+!0 o&m&j&  ! 
A0B0C0D0E0F0G0H0I0J0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0c0d0e0f0g0h0i0j0k0l0m0n0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0~0
%,%$%4%<%
%#%3%+%;%K% %/%(%7%?%
%0%%%8%B%
`$a$b$c$d$e$f$g$h$i$j$k$l$m$n$o$p$q$r$s$`!a!b!c!d!e!f!g!h!i!
3"3M3
363Q3W3
3&3#3+3J3;3
2122292~3}3|3R"a"+"."
"5")"*"
pOupu
AQpS
U0[q_ f
l)m[t
vNz4
W0XDY
eZl%u
Q.YeY
e*j'k
vharYN
OxSi`)nOz
NUO=O
bYr;u
hwmppLu
d<h8h
\}iM
c {+j
_orR
*h\Q
[r^y^
h>kSkWl"o
8N+T
sLv<w
\^~^
_j0^
uHyc[
UThXjp
'xug
_%`Qe
=gBlrl
c nZ
QTS!S
\7_J_/`P`m`
cYeKj
fmi@\
e#k=k4t
]N6P
UzzvP
Q\H\
hp~Qhl
RDQSU-W
WQYb_
_u`vaga
c:dleofBh
nfu=z
}K~k
P kzlTotzP}@
N9P&PeP|Q8RcR
i)j}r
xoxy}w
S{^&_
sC}7
^'_8bEe
OHSIT>T/Z
PIQlQ
W}YT[][
_R`La
fmg!h
i_l*mim/n
vlx?z
KQ;RJT
V@zw
XZZh`
u:}n
[i_Mb
c=hsk
x&xmy
dR(WPgj
QBW*
\OJR
T>d(f
zV{"}/
dce_h
YP[M\
c/e\[
lEsIy
OPQW[
cBf!k
x:y
\hcf
enq>y
R:\Sg|p5rL
[Kb1g
s.zk
yB}M~
NOOEQAS
ncs&~
m]y.~
R SGS
TFU1U
ff-fvf~g
nXn<q&qgq
X"[8^
dagVgDm
rsucz
qT~w
;\8O
_Na/c
u=\N
]i]pe
ncIg
N,p]u/f
b?ete
wMzM|>~
NHQCS`S
]&bGb
g\oNq}q
U8o6qhQ
|LVQX
| }D}
XOY=r
OtPGRsSo`Ic_g,n
cX[k[
dQg\
Y*YplQ
_ `Ka4b
S'Y,{
n'pSSDU
SFOT
9NXS
_e`zf`l
Z@w-N
j&p*s
_5_k_
gnoRr:u:wt
iCO,o
?ipojW
X,[,}*r
NNO\PuPCR
HT$X
xQkX)YU\
T5XWX
e\g!n{v
%x:x
UTXXXWY
b-dqgCh
uwyI{T{R{
|q}0Rc
myrcw
z4iJ\
pxVo\
XpzcK
~wuWS`i
esNeQ
l>m6t4xFZu
cWeog
sidq
/OeRZS
Qu`ukQb
zVYX
4O$RJS
g>lNlHr
sTuA~,
=cifju
*SQS&T
`Ibyb
_buF{<
}~v,
thyh
W+YfZ
`vbwe
enfnm6r&{P
R;TtV
NuOuQ@Xc^s^
g&N=
WUcik+u
SFT1XIY
bgc>e
p2x+~
PVRJW
d4ggrfwFz
XL^TY,g
sT*gE
R"Y!q_r
xd!j
2Q(g
$\;b~|
Y:r6
/UQO*Q
m6s7s1uPy
ma}=
qNuSP]
Te\Ng
tYukx
`tAX
m/}^
a#oIq>|
N*N1N6N<N?NBNVNXN
OZO0O[O]OWOGOvO
O{OiOpO
P*P%P
O!P)P,P
PCPGP
gUPPPHPZPVPlPxP
Q!Q:Q7Q<Q;Q?Q@QRQLQTQbQ
ziQjQnQ
R'R*R.R3R9RORDRKRLR^RTRjRtRiRsR
S#S/S1S3S8S@SFSES
NISMS
Q^SiSnS
Y{SwS
T=T@T,T-T<T.T6T)T
T_TqTwTpT
T9U@UcULU.U\UEUVUWU8U3U]U
U{U~U
UNVPV
q4V6V2V8V
kVdV/VlVjV
W&W7W8WNW;W@WOWiW
XrX!XbXKXpX
kRX=XyX
h%Y,Y-Y2Y8Y>Y
zUYPYNYZYXYbY`YgYlYiY
Z@ZlZIZ5Z6ZbZjZ
Z*[6[>[C[E[@[Q[U[Z[[[e[i[p[s[u[x[
\ \"\(\8\9\A\F\N\S\P\O\q[l\n\bNv\y\
]L]R]N]K]l]s]v]
^6^7^D^C^@^N^W^T^_^b^d^G^u^v^z^
_]_\_
_)_-_8_A_H_L_N_/_Q_V_W_Y_a_m_s_w_
_!```
`+`&`
`:`Z`A`j`w`_`J`F`M`c`C`d`B`l`k`Y`
aGa>a(a'aJa?a<a,a4a=aBaDasawaXaYaZakataoaeaqa_a]aSaua
b!b*b.b0b2b3bAbNb^bcb[b`bhb|b
bPc>cMc
d&d6d
dgdodvdNd*e
e$e#e+e4e5e7e6e8eKuHeVeUeMeXe^e]erexe
esg5f6f4f
fOfDfIfAf^f]fdfgfhf_fbfpf
g&g'g8
.g?g6gAg8g7gFg^g`gYgcgdg
g|gjg
hFh)h@hMh2hNh
h+hYhchwh
h"i&i
h(i*i
i#i!i
hyiwi\ixikiTi~ini9iti=iYi0iai^i]i
jDjjrj6jxjGjbjYjfjHj8j"j
k8k7k
GkCkIkPkYkTk[k_kakxkyk
l$l#l^lUlbljl
l~lhlsl
6m+m=m8m
m5m3m
mmcm
mdmZmymYm
m-nnn.n
nrn_n>n#nkn+nvnMn
nCn:nNn$n
ozoxo
ooo[o
o|oXo
p0p>p2pQpcp
qeqUq
qfqbqLqVqlq
r(r-r,r0r2r;r<r?r@rFrKrXrtr~r
s4s/s)s%s>sNsOs
Wsjshspsxsus{szs
tot%t
s2t:tUt?t_tYtAt\titptctjtvt~t
u&u,u<uDuMuJuIu[uFuZuiudugukumuxuvu
v'v v!v"v$v4v0v;vGvHvFv\vXvavbvhvivjvgvlvpvrvvvxv|v
w)w$w
w%w&w
w7w8wGwZwhwkw[wew
w~wyw
x&y x*yEx
y,y+y@y`yWy_yZyUySyzy
y1z;z>z7zCzWzIzazbziz
pzyz}z
{5{({6{P{z{
{L{E{u{e{t{g{p{q{l{n{
{#|'|*|
|7|+|=|L|C|T|O|@|P|X|_|d|V|e|l|u|
}E}K}.}2}?}5}F}s}V}N}r}h}n}O}c}
~#~!~
~"~F~f~;~5~9~C~7~
2~:~g~]~V~^~Y~Z~y~j~i~|~{~
fE_(N
O9OVO
O@P"P
PFPpPBP
PJQdQ
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
p!q!r!s!t!u!v!w!x!y!
p!q!r!s!t!u!v!w!x!y!`!a!b!c!d!e!f!g!h!i!
!!!5"
fE_(N
O9OVO
O@P"P
PFPpPBP
S$SrS
UYWeW
YSY[Y]YcY
\']S]
B]m]
]!_4_g_
a7a0a
f$fefWfYf
i0jkjFjsj~j
k?l\l
m9n\n'n<n
q\qFqGq
s&t*t)t.tbt
R!xNxdxzx0y
H}\}
}R~G
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK7__CFURLEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK7__CFURLEC1ES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK14__CFDictionaryEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK14__CFDictionaryEC1ES3_EUlPKvE_
N5MeCab5IconvE
N11InputEngine24ChineseAdaptationContextE
B0D0F0H0J0
N5MeCab9ConnectorE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIsEEEE
N5MeCab4MmapIsEE
N5MeCab10MemoryPoolINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_4MmapIjEEEE
N5MeCab4MmapIjEE
N11InputEngine15CandidateClonerINS_17FacemarkCandidateEEE
N11InputEngine17FacemarkCandidateE
N5MeCab12StringBufferE
N5MeCab10TaggerImplE
N5MeCab6TaggerE
N5MeCab14NBestGeneratorE
N5MeCab8FreeListINS_14NBestGenerator12QueueElementEEE
N5MeCab10scoped_ptrINS_14NBestGeneratorEEE
N5MeCab13TokenizerImplI12mecab_node_t12mecab_path_tEE
N5MeCab8FreeListI12mecab_node_tEE
N5MeCab8FreeListI23mecab_dictionary_info_tEE
N5MeCab12scoped_arrayI25trie_search_result_type_tEE
N5MeCab34SpecialNodeCreationConcreteContextINS_13TokenizerImplI12mecab_node_t12mecab_path_tEEEE
N5MeCab26SpecialNodeCreationContextE
E@N5MeCab7ViterbiE
N5MeCab10scoped_ptrINS_8FreeListI12mecab_path_tEEEE
N5MeCab8FreeListI12mecab_path_tEE
N7Seaweed19PhraseCandidateWordE
333333
333333
N11InputEngine15MecabraJapaneseE
N11InputEngine8ObserverI30MobileAssetNotificationManagerEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP10__CFStringEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP10__CFStringEC1ES2_EUlPKvE_
NSt3__110__function6__funcIZN11InputEngine15MecabraJapanese31makeSingleEnglishWordCandidatesEPNS2_19MecabraCandidateSetERK11UTF16StringE3$_0NS_9allocatorIS9_EEFvPK10__CFStringSE_dRbEEE
NSt3__110__function6__baseIFvPK10__CFStringS4_dRbEEE
ZN11InputEngine15MecabraJapanese31makeSingleEnglishWordCandidatesEPNS_19MecabraCandidateSetERK11UTF16StringE3$_0
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9__CFArrayEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9__CFArrayEC1ES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK7__CFURLE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK7__CFURLE5resetES3_EUlPKvE_
32MecabSearchContextImplementationI13BridgeBuilderI23CommonDynamicWordBridgeES0_I36JapaneseRomajiToKanaConversionBridgeES0_I32CommonCharacterReplacementBridgeEE
18MecabSearchContext
/System/Library/LinguisticData/RequiredAssets_ja.bundle/AssetData
NSt3__118codecvt_utf8_utf16IDsLm1114111ELNS_12codecvt_modeE0EEE
14DynamicLexicon
N11InputEngine26MecabraConversionCandidateE
?ffffff
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP10__CFStringE5resetES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP10__CFStringE5resetES2_EUlPKvE_
NkQ]N
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraJapaneseENS_23NoopPredictionComponentEEE
N11InputEngine18MecabraInputEngineE
N11InputEngine28MecabraInputEngineDispatcherIN7Seaweed16ConversionEngineE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_30MecabraSimplifiedChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_31MecabraTraditionalChineseStrokeE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_14MecabraCangjieE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_15MecabraWubixingE23ChinesePredictionEngineEE
N11InputEngine28MecabraInputEngineDispatcherINS_18MecabraHandwritingE23ChinesePredictionEngineEE
N11InputEngine24ChinesePredictionContextE
N11InputEngine25DynamicDictionaryJapaneseE
N11InputEngine17DynamicDictionaryE
N11InputEngine20MecabraCandidateBaseE
32BTriePositionInterpreterInternal
23BTrieFatBaseInterpreter
27BTrieCompactBaseInterpreter
24BTrieFlatBaseInterpreter
20BTrieNoOpInterpreter
NSt3__120__shared_ptr_pointerIPN11InputEngine23MecabraChineseTokenizerENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine23MecabraChineseTokenizerEEE
17ChineseStringWord
N11InputEngine26MecabraCandidateSetAdaptorE
N11InputEngine34MecabraCandidateSetSkippingAdaptorE
N11InputEngine34MecabraCandidateSetOrderingAdaptorE
21EntryFieldStringValue
15EntryFieldValue
22EntryFieldIntegerValue
NSt3__120__shared_ptr_pointerIP21EntryFieldStringValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI21EntryFieldStringValueEE
NSt3__120__shared_ptr_pointerIP22EntryFieldIntegerValueNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI22EntryFieldIntegerValueEE
26AggregateDictionaryTracker
24MecabraStatisticsTracker
22NodeFeatureInterpreter
36JapaneseRomajiToKanaConversionBridge
37EngineRomajiToKanaConversionInterface
13FileException
NSt3__120__shared_ptr_pointerIP4FileIcENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteI4FileIcEEE
23CommonDynamicWordBridge
26EngineDynamicWordInterface
32CommonCharacterReplacementBridge
35EngineCharacterReplacementInterface
N11InputEngine15CandidateClonerI33CharacterInputConversionCandidateEE
33CharacterInputConversionCandidate
28SyntheticConversionCandidate
N11InputEngine34MecabraJapaneseConversionCandidateE
23SQLiteDatabaseException
N3nlp16BurstTrieAdapterIitEE
N3nlp11MutableTrieIitNS_22BurstTrieAdapterCursorEEE
N3nlp4TrieIitNS_22BurstTrieAdapterCursorEEE
NSt3__110__function6__funcIZNK3nlp16BurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNS_8functionIFvRKiS6_mRbEEEiEUlPvPNS2_15_TrieCompletionEPbE_NS_9allocatorISJ_EEFvSF_SH_SI_EEE
ZNK3nlp16BurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNSt3__18functionIFvRKiS3_mRbEEEiEUlPvPNS_15_TrieCompletionEPbE_
NSt3__110__function6__funcIZNK3nlp16BurstTrieAdapterIitE16enumerateEntriesERKNS2_22BurstTrieAdapterCursorERKNS_8functionIFvRKiPKcmRbEEEiEUlPvPKhjjfPbE_NS_9allocatorISM_EEFvSI_SK_jjfSL_EEE
ZNK3nlp16BurstTrieAdapterIitE16enumerateEntriesERKNS_22BurstTrieAdapterCursorERKNSt3__18functionIFvRKiPKcmRbEEEiEUlPvPKhjjfPbE_
N11InputEngine27MutableAmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEEE
N11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEEE
N11InputEngine13AmbiguousTrieIN3nlp16BurstTrieAdapterIitEEEE
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE15ambiguousSearchERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__baseIFvRKN3nlp22BurstTrieAdapterCursorEfPKcmmRbEEE
ZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE15ambiguousSearchERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_NS_9allocatorISR_EEFvSQ_fSI_mmSJ_EEE
NSt3__110__function6__funcIZZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKNS4_13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS4_22BurstTrieAdapterCursorEfSI_mmSJ_E_clESQ_fSI_mmSJ_EUlRKiSI_mSJ_E_NS_9allocatorISU_EEFvST_SI_mSJ_EEE
NSt3__110__function6__baseIFvRKiPKcmRbEEE
ZZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_clESO_fSG_mmSH_EUlRKiSG_mSH_E_
ZNK11InputEngine20AmbiguousTrieAdapterIN3nlp16BurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKNS1_13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS1_22BurstTrieAdapterCursorEfSG_mmSH_E_
NSt3__110__function6__funcIZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockERKNS_6vectorItNS_9allocatorItEEEEjU13block_pointerFviPbEE3$_1NS4_ISC_EEFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEE
NSt3__110__function6__baseIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEE
ZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockERKNSt3__16vectorItNS0_9allocatorItEEEEjU13block_pointerFviPbEE3$_1
NSt3__110__function6__funcIZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockERKNS_6vectorItNS_9allocatorItEEEEjU13block_pointerFviPbEE3$_2NS4_ISC_EEFvRKiPKcmRbEEE
ZNK22LearningDictionaryTrie28enumerateTrieValueUsingBlockERKNSt3__16vectorItNS0_9allocatorItEEEEjU13block_pointerFviPbEE3$_2
NSt3__110__function6__funcIZNK22LearningDictionaryTrie22enumeratePrefixEntriesERK12TriePositionmiPhU13block_pointerFvjmPbEE3$_3NS_9allocatorISA_EEFvRKiPKcmRbEEE
ZNK22LearningDictionaryTrie22enumeratePrefixEntriesERK12TriePositionmiPhU13block_pointerFvjmPbEE3$_3
27CharacterLatticeSessionData
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK14__CFDictionaryE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK14__CFDictionaryE7acquireES3_EUlPKvE_
333333
?34ChineseCompletionProducerException
NSt3__120__shared_ptr_pointerIP19ReadingMappedStringNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI19ReadingMappedStringEE
N11InputEngine15CandidateClonerIN7Seaweed25InlinePredictionCandidateEEE
N7Seaweed25InlinePredictionCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed20InlinePredictionWordENS_9allocatorIS2_EEEE
%@ffffff
?ffffff
?34ChinesePredictionProducerException
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP14__CFDictionaryE5resetES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP14__CFDictionaryE5resetES2_EUlPKvE_
N11InputEngine15MecabraWubixingE
17InstantLogPrinter
10LogPrinter
18BufferedLogPrinter
N7Seaweed31SeaweedDynamicMutableDictionaryE
22SyntheticCandidateBase
N11InputEngine13MecabraEngineE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9__CFArrayE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9__CFArrayE5resetES3_EUlPKvE_
N11InputEngine30ChineseRevertAdaptationContextE
ffffff
333333
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK8_LXEntryEC1ES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK8_LXEntryEC1ES3_EUlPKvE_
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController22enumerateSortedEntriesEPK10__CFStringdttRKNS_8functionIFvS6_S6_dRbEEEbE3$_0NS_9allocatorISD_EEFvPK9_LXCursorS8_EEE
NSt3__110__function6__baseIFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController22enumerateSortedEntriesEPK10__CFStringdttRKNSt3__18functionIFvS3_S3_dRbEEEbE3$_0
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController11shouldBlockEPK10__CFStringmE3$_1NS_9allocatorIS7_EEFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController11shouldBlockEPK10__CFStringmE3$_1
NSt3__110__function6__funcIZNK11InputEngine23EnglishLookupController39createLatinWordWithProperCapitalizationEPK10__CFStringS6_bE3$_2NS_9allocatorIS7_EEFvPK9_LXCursorRbEEE
ZNK11InputEngine23EnglishLookupController39createLatinWordWithProperCapitalizationEPK10__CFStringS3_bE3$_2
NSt3__120__shared_ptr_pointerIP7LexiconNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI7LexiconEE
N11InputEngine18MecabraContextImplE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK13__CFAllocatorE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK13__CFAllocatorE7acquireES3_EUlPKvE_
N11InputEngine19MecabraCandidateSetE
N11InputEngine26MecabraChineseCandidateSetE
N11InputEngine41MecabraChineseSingleCharacterCandidateSetE
N11InputEngine36MecabraChineseExactMatchCandidateSetE
N11InputEngine27MecabraJapaneseCandidateSetE
N11InputEngine14MecabraLearnerE
N11InputEngine27SeaweedChinesePinyinLearnerE
N11InputEngine21SeaweedChineseLearnerE
N11InputEngine37SeaweedSimplifiedChinesePinyinLearnerE
N11InputEngine38SeaweedTraditionalChinesePinyinLearnerE
N11InputEngine38SeaweedTraditionalChineseZhuyinLearnerE
19ChineseLearningInfo
12LearningInfo
N7Seaweed26ReverseDictionaryExceptionE
NSt3__120__shared_ptr_pointerIPN7Seaweed17ReverseDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed17ReverseDictionaryEEE
N11InputEngine22MecabraJapaneseLearnerE
27MecabraJapaneseLearningInfo
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP9__CFArrayEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP9__CFArrayEC1ES2_EUlPKvE_
default
allocation
conversion
context
correction
incremental
learning
languagemodel
live
mobileasset
prediction
pruning
reranking
MecabraSignposts
N11InputEngine15CandidateClonerI20HandwritingCandidateEE
20HandwritingCandidate
  0 
: `k
85*L
W&0CFq
 ? 2t{
,k!%
ab,Ac
^4-*L
Op"I
`'H*@
M!70
V\PI
 HC
k `p
$@R2
8! @
F3$xr0
$"0 
:0p(
<5*L
W&0c
g!Ip"
THhd
CQ d
d:9%
,k1%
cF(Aa
0&dH1
h+]A
H&@8J?
,iud>
&BaY
`"A0
R%!)
:J$4
+AL L+
te  8D
`B*@*
 !:"
I$3@
N7Seaweed23ConversionCandidateWordE
NSt3__120__shared_ptr_emplaceI19ReadingMappedStringNS_9allocatorIS1_EEEE
koyhdnihsnihukufnaemirtbtnoc   =
N11InputEngine15CandidateClonerIN7Seaweed19SingleWordCandidateEEE
N7Seaweed19SingleWordCandidateE
@ffffff
ffffff
333333
ffffff
?ffffff
?N7Seaweed16ConversionEngineE
19PreheatableResource
N11InputEngine8ObserverIN7Seaweed22AssetDictionaryManagerEEE
N11InputEngine15CandidateClonerI22ChineseHybridCandidateEE
22ChineseHybridCandidate
N7Mecabra16BurstTrieBuilderE
N7Mecabra11TrieBuilderE
N7Mecabra17MarisaTrieBuilderE
26CharacterLatticeController
N7Seaweed20InlinePredictionWordE
16CharacterLattice
N7Seaweed26SeaweedImmutableDictionaryE
N7Seaweed17SeaweedDictionaryE
29SingleIndexKeyTokenEnumerator
18KeyTokenEnumerator
31MultipleIndexKeyTokenEnumerator
N7Seaweed13CandidateWordE
333333
NSt3__120__shared_ptr_emplaceI15MecabraAssetSetNS_9allocatorIS1_EEEE
?ffffff
N7Seaweed13LatticeSearchE
N11InputEngine28MecabraCharacterInputLearnerE
N11InputEngine30MecabraSimplifiedStrokeLearnerE
N11InputEngine21MecabraSuchengLearnerE
N11InputEngine31MecabraTraditionalStrokeLearnerE
N11InputEngine22MecabraWubixingLearnerE
18StrokeLearningInfo
NSt3__120__shared_ptr_emplaceIN14SharedCFString7WrapperENS_9allocatorIS2_EEEE
N7Seaweed16LookupControllerE
N7Seaweed33MixedScriptSyllableSearchDelegateE
NSt3__120__shared_ptr_pointerIP29SingleWordCandidateSharedDataNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI29SingleWordCandidateSharedDataEE
NSt3__110__function6__funcIZN7Seaweed16LookupController28lookupTenKeyLatinSingleWordsEvE3$_0NS_9allocatorIS4_EEFvPK10__CFStringS9_dRbEEE
ZN7Seaweed16LookupController28lookupTenKeyLatinSingleWordsEvE3$_0
NSt3__110__function6__funcIZN7Seaweed16LookupController22lookupLatinSingleWordsEvE3$_1NS_9allocatorIS4_EEFvPK10__CFStringS9_dRbEEE
ZN7Seaweed16LookupController22lookupLatinSingleWordsEvE3$_1
N11InputEngine13LanguageModelE
N5MeCab25MecabraJapaneseDictionaryE
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary28enumerateReadingBigramTokensEPKcmbbS5_mjP18MecabSearchContextU13block_pointerFvRKNS2_11BigramTokenEfPbEE3$_0NS_9allocatorISE_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary28enumerateReadingBigramTokensEPKcmbbS2_mjP18MecabSearchContextU13block_pointerFvRKNS_11BigramTokenEfPbEE3$_0
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_1NS_9allocatorISA_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_1
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_2NS_9allocatorISA_EEFvRKN3nlp13ScoredPayloadIiEES5_mmRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_2
NSt3__110__function6__funcIZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_3NS_9allocatorISA_EEFvRKiS5_mRbEEE
ZN5MeCab25MecabraJapaneseDictionary6searchEjPKcmP18MecabSearchContextmP25trie_search_result_type_tmE3$_3
N7Mecabra22StaticBurstTrieAdapterIitEE
N3nlp4TrieIitN7Mecabra28StaticBurstTrieAdapterCursorEEE
NSt3__110__function6__funcIZN7Mecabra22StaticBurstTrieAdapterIitEC1ER7btrie_tEUlPS5_E_NS_9allocatorIS8_EEFvS7_EEE
NSt3__110__function6__baseIFvP7btrie_tEEE
ZN7Mecabra22StaticBurstTrieAdapterIitEC1ER7btrie_tEUlPS2_E_
NSt3__110__function6__funcIZNK7Mecabra22StaticBurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNS_8functionIFvRKiS6_mRbEEEiEUlS9_S6_mSA_E_NS_9allocatorISF_EESB_EE
ZNK7Mecabra22StaticBurstTrieAdapterIitE20enumerateCompletionsEPKcmRKNSt3__18functionIFvRKiS3_mRbEEEiEUlS7_S3_mS8_E_
N11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEEE
N11InputEngine13AmbiguousTrieIN7Mecabra22StaticBurstTrieAdapterIitEEEE
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE15ambiguousSearchERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS4_28StaticBurstTrieAdapterCursorEfSJ_mmSK_E_NS_9allocatorISS_EEFvSR_fSJ_mmSK_EEE
NSt3__110__function6__baseIFvRKN7Mecabra28StaticBurstTrieAdapterCursorEfPKcmmRbEEE
ZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE15ambiguousSearchERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEbEUlRKNS1_28StaticBurstTrieAdapterCursorEfSH_mmSI_E_
NSt3__110__function6__funcIZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS4_28StaticBurstTrieAdapterCursorEfSJ_mmSK_E_NS_9allocatorISS_EEFvSR_fSJ_mmSK_EEE
NSt3__110__function6__funcIZZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS2_26AmbiguousTrieSearchLatticeItEERKNS_8functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS4_28StaticBurstTrieAdapterCursorEfSJ_mmSK_E_clESR_fSJ_mmSK_EUlRKiSJ_mSK_E_NS_9allocatorISV_EEFvSU_SJ_mSK_EEE
ZZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiENKUlRKNS1_28StaticBurstTrieAdapterCursorEfSH_mmSI_E_clESP_fSH_mmSI_EUlRKiSH_mSI_E_
ZNK11InputEngine20AmbiguousTrieAdapterIN7Mecabra22StaticBurstTrieAdapterIitEEE20enumerateCompletionsERKNS_26AmbiguousTrieSearchLatticeItEERKNSt3__18functionIFvRKN3nlp13ScoredPayloadIiEEPKcmmRbEEEiEUlRKNS1_28StaticBurstTrieAdapterCursorEfSH_mmSI_E_
NSt3__110__function6__funcIZN7Mecabra22StaticBurstTrieAdapterIitEC1EPcmEUlP7btrie_tE_NS_9allocatorIS8_EEFvS7_EEE
ZN7Mecabra22StaticBurstTrieAdapterIitEC1EPcmEUlP7btrie_tE_
N7Seaweed26SeaweedConversionCandidateE
29SingleWordCandidateSharedData
19PredictionCandidate
N11InputEngine15CandidateClonerI26ChinesePredictionCandidateEE
26ChinesePredictionCandidate
N11InputEngine15CandidateClonerIN7Seaweed15PhraseCandidateEEE
N7Seaweed15PhraseCandidateE
NSt3__120__shared_ptr_emplaceIN7Seaweed19PhraseCandidateWordENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed19PhraseCandidateWordENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed19PhraseCandidateWordEEE
N11InputEngine19ChineseInputContextE
N7Seaweed8WordCoreE
N7Seaweed29StaticDictionaryEntryWordCoreE
N7Seaweed23DictionaryEntryWordCoreE
N7Seaweed16SentinelWordCoreE
N7Seaweed31LearningDictionaryEntryWordCoreE
N7Seaweed45StaticDictionaryEntryWithModifiedCostWordCoreE
N7Seaweed19MixedScriptWordCoreE
N7Seaweed17SyntheticWordCoreE
adgjmptw
N7Seaweed21SyllableLatticeColumnE
N7Seaweed15SyllableLatticeE
NSt3__120__shared_ptr_emplaceIN7Seaweed32SyntheticMixedScriptSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed25AutoCorrectedSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed28SyntheticEnglishSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed21SyntheticSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed21ShuangpinSyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed26IncompleteWithToneSyllableENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed17FuzzySyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN7Seaweed12SyllableNodeENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN7Seaweed25AutoCorrectedSyllableNodeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN7Seaweed25AutoCorrectedSyllableNodeEEE
N7Seaweed12SyllableNodeE
N7Seaweed16SyllableNodeBaseE
N7Seaweed17FuzzySyllableNodeE
N7Seaweed25AutoCorrectedSyllableNodeE
N7Seaweed26IncompleteWithToneSyllableE
N7Seaweed21ShuangpinSyllableNodeE
N7Seaweed21SyntheticSyllableNodeE
N7Seaweed28SyntheticEnglishSyllableNodeE
N7Seaweed32SyntheticMixedScriptSyllableNodeE
N7Seaweed35SimplifiedChineseFeatureInterpreterE
N7Seaweed18FeatureInterpreterE
N7Seaweed36TraditionalChineseFeatureInterpreterE
333333
?N11InputEngine15CandidateClonerI26ChineseCompletionCandidateEE
26ChineseCompletionCandidate
37ChineseCompletionFixedPhraseCandidate
NSt3__120__shared_ptr_pointerIPN11InputEngine26FacemarkLearningDictionaryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN11InputEngine26FacemarkLearningDictionaryEEE
N7Seaweed25WordLatticeControllerImplE
N7Seaweed21WordLatticeControllerE
N11InputEngine15CandidateClonerINS_25MecabraProactiveCandidateEEE
N11InputEngine25MecabraProactiveCandidateE
d0e0c0d0e0d0c0F0E0
0F0E0o0p0q0r0s0t0u0v0w0x0y0z0{0|0}0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0f0g0h0i0p0q0s0t0v0w0y0z0|0}0B0A0D0C0H0G0J0I0
0Z0e0X0b0
N11InputEngine27JapaneseSpecialtyDictionaryE
N11InputEngine19SpecialtyDictionaryE
21ChinesePredictionWord
N11InputEngine7SegmentE
N11InputEngine42MecabraCharacterPhraseInputAnalysisSessionE
N7Seaweed24SeaweedMutableDictionaryE
N7Seaweed36SeaweedFileMappedImmutableDictionaryE
N7Seaweed34SeaweedInMemoryImmutableDictionaryE
N7Seaweed28SeaweedAddressBookDictionaryE
N7Seaweed25SeaweedUserWordDictionaryE
NSt3__120__shared_ptr_pointerIPN11InputEngine13AsyncResourceINS1_14EnglishLexiconEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN11InputEngine13AsyncResourceINS1_14EnglishLexiconEEEEE
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIP14__CFDictionaryEC1ES5_EUlPKvE_NS_9allocatorIS9_EEFvS8_EEE
ZN3nlp11CFScopedPtrIP14__CFDictionaryEC1ES2_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK10_LXLexiconE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK10_LXLexiconE5resetES3_EUlPKvE_
NSt3__110__function6__funcIZN11InputEngine14EnglishLexicon23enumerateMatchedCursorsERKNS_8functionIFvPK9_LXCursorRbEEEbE3$_0NS_9allocatorISD_EEFvRKNS3_11CursorTupleEEEE
NSt3__110__function6__baseIFvRKN11InputEngine14EnglishLexicon11CursorTupleEEEE
ZN11InputEngine14EnglishLexicon23enumerateMatchedCursorsERKNSt3__18functionIFvPK9_LXCursorRbEEEbE3$_0
NSt3__110__function6__funcIZN11InputEngine14EnglishLexicon20enumerateCompletionsEPK10__CFStringRKNS_8functionIFvPK9_LXCursorRbEEEmtdE3$_1NS_9allocatorISG_EEFvRKNS3_11CursorTupleEEEE
ZN11InputEngine14EnglishLexicon20enumerateCompletionsEPK10__CFStringRKNSt3__18functionIFvPK9_LXCursorRbEEEmtdE3$_1
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9_LXCursorE7acquireES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9_LXCursorE7acquireES3_EUlPKvE_
NSt3__110__function6__funcIZN3nlp11CFScopedPtrIPK9_LXCursorE5resetES6_EUlPKvE_NS_9allocatorISA_EEFvS9_EEE
ZN3nlp11CFScopedPtrIPK9_LXCursorE5resetES3_EUlPKvE_
N11InputEngine39MecabraCharacterPhraseInputCandidateSetE
13CharacterNode
N11InputEngine21JapaneseLanguageModelE
32ReadingLookupDictionaryException
BOS/EOS
innsbruck
PosList.plist
posmap-migration.plist
posmap-current2univ.plist
posmap-univ2current.plist
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/agent.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/agent.cc:13: MARISA_NULL_ERROR: str == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/agent.cc:21: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/agent.cc:36: MARISA_STATE_ERROR: state_.get() != NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/agent.cc:38: MARISA_MEMORY_ERROR: state_.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/scoped-ptr.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:55: MARISA_NULL_ERROR: filename == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:63: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:71: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:72: MARISA_IO_ERROR: size > avail_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:99: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:100: MARISA_IO_ERROR: size > avail_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:141: MARISA_IO_ERROR: ::stat(filename, &st) != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:146: MARISA_IO_ERROR: fd_ == -1
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/mapper.cc:149: MARISA_IO_ERROR: origin_ == MAP_FAILED
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:27: MARISA_NULL_ERROR: filename == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:68: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:94: MARISA_IO_ERROR: file == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:113: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:129: MARISA_IO_ERROR: size_read <= 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:134: MARISA_IO_ERROR: ::fread(buf, 1, size, file_) != size
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:138: MARISA_IO_ERROR: !stream_->read(static_cast<char *>(buf), size)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/reader.cc:140: MARISA_IO_ERROR: std::ios_base::failure
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:68: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:113: MARISA_STATE_ERROR: !is_open()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:129: MARISA_IO_ERROR: size_written <= 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:134: MARISA_IO_ERROR: ::fwrite(data, 1, size, file_) != size
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:135: MARISA_IO_ERROR: ::fflush(file_) != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:139: MARISA_IO_ERROR: !stream_->write(static_cast<const char *>(data), size)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/io/writer.cc:141: MARISA_IO_ERROR: std::ios_base::failure
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:73: MARISA_BOUND_ERROR: agent.query().id() >= size()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:451: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:468: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:542: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:568: MARISA_MEMORY_ERROR: next_trie_.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/config.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/config.h:59: MARISA_CODE_ERROR: (config_flags & ~MARISA_CONFIG_MASK) != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/config.h:101: MARISA_CODE_ERROR: undefined cache level
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/config.h:121: MARISA_CODE_ERROR: undefined tail mode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/config.h:141: MARISA_CODE_ERROR: undefined node order
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/header.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/header.h:21: MARISA_FORMAT_ERROR: !test_header(ptr)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/mapper.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/mapper.h:28: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/mapper.h:30: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/header.h:26: MARISA_FORMAT_ERROR: !test_header(buf)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/reader.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/reader.h:31: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/reader.h:33: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/writer.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/writer.h:30: MARISA_NULL_ERROR: (objs == NULL) && (num_objs != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../io/writer.h:32: MARISA_SIZE_ERROR: num_objs > (MARISA_SIZE_MAX / sizeof(T))
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/bit-vector.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/bit-vector.h:52: MARISA_SIZE_ERROR: size_ == MARISA_UINT32_MAX
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/vector.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/bit-vector.h:135: MARISA_FORMAT_ERROR: temp_num_1s > size_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/vector.h:202: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/vector.h:107: MARISA_STATE_ERROR: fixed_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/flat-vector.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/flat-vector.h:134: MARISA_FORMAT_ERROR: temp_value_size > 32
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/bit-vector.h:153: MARISA_FORMAT_ERROR: temp_num_1s > size_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/vector.h:213: MARISA_FORMAT_ERROR: (total_size % sizeof(T)) != 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../vector/flat-vector.h:155: MARISA_FORMAT_ERROR: temp_value_size > 32
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/louds-trie.cc:428: MARISA_MEMORY_ERROR: std::bad_alloc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/../algorithm/../../scoped-ptr.h:19: MARISA_RESET_ERROR: (ptr != NULL) && (ptr == ptr_)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/tail.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/tail.cc:13: MARISA_NULL_ERROR: offsets == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/tail.cc:36: MARISA_CODE_ERROR: undefined tail mode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/tail.cc:170: MARISA_RANGE_ERROR: current.length() == 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/trie/tail.cc:192: MARISA_SIZE_ERROR: buf_.size() > MARISA_UINT32_MAX
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/vector/vector.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/grimoire/vector/vector.h:100: MARISA_STATE_ERROR: fixed_
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:61: MARISA_NULL_ERROR: (ptr == NULL) && (length != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:62: MARISA_SIZE_ERROR: length > MARISA_UINT32_MAX
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:129: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:138: MARISA_MEMORY_ERROR: new_block.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:151: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:159: MARISA_MEMORY_ERROR: new_block.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:169: MARISA_MEMORY_ERROR: new_blocks.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/keyset.cc:177: MARISA_MEMORY_ERROR: new_block.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:14: MARISA_MEMORY_ERROR: temp.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:21: MARISA_NULL_ERROR: filename == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:24: MARISA_MEMORY_ERROR: temp.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:33: MARISA_NULL_ERROR: (ptr == NULL) && (size != 0)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:36: MARISA_MEMORY_ERROR: temp.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:45: MARISA_NULL_ERROR: filename == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:48: MARISA_MEMORY_ERROR: temp.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:233: MARISA_NULL_ERROR: trie == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:200: MARISA_NULL_ERROR: trie == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:204: MARISA_MEMORY_ERROR: temp.get() == NULL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Marisa_Sim/Marisa-9.15.2/lib/marisa/trie.cc:213: MARISA_STATE_ERROR: trie.trie_.get() == NULL
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
^{LanguageModel=^^?^vq^{__CFString}}8@?0
en_US
Montreal-languagemodel
^{LanguageModelLoader=i^{__CFURL}^{__CFURL}{unique_ptr<InputEngine::LanguageModel, std::__1::default_delete<InputEngine::LanguageModel> >={__compressed_pair<InputEngine::LanguageModel *, std::__1::default_delete<InputEngine::LanguageModel> >=^{LanguageModel}}}}8@?0
^{AsyncResource<InputEngine::LanguageModel>=@?{unique_ptr<InputEngine::LanguageModel, std::__1::default_delete<InputEngine::LanguageModel> >={__compressed_pair<InputEngine::LanguageModel *, std::__1::default_delete<InputEngine::LanguageModel> >=^{LanguageModel}}}^{dispatch_group_s}^{dispatch_queue_s}{once_flag=Q}{atomic<InputEngine::AsyncResource<InputEngine::LanguageModel>::State>=Ai}{mutex={_opaque_pthread_mutex_t=q[56c]}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}8@?0
v8@?0
unique_lock::try_lock: references null mutex
unique_lock::try_lock: already locked
emoji.dat
no tone change
tone change
Base phrase: %s baseScore=%f candidateWord: %s homophoneForWord: %s homophoneScore=%f
bcdfghjklmprstvwxyz
qwrtpsdfghjklzxcvbnm
v24@?0r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}8^B16
v32@?0@"NSString"8i16B20^B24
v24@?0r^{CharacterNode=^^?^{__CFString}iBB}8^B16
v36@?0r^S8q16i24^B28
^{__CFString=}16@?0^{__CFString=}8
rank
extension
PRAutocorrectionContext
v20@?0^{__CFString=}8C16
v32@?0^{map<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}8i16i20^B24
.dic
/zip_code-ja.dat
%@*%@
CharacterMap
^{CharacterMap={map<unsigned short, unsigned short, std::__1::less<unsigned short>, std::__1::allocator<std::__1::pair<const unsigned short, unsigned short> > >={__tree<std::__1::__value_type<unsigned short, unsigned short>, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, unsigned short>, std::__1::less<unsigned short>, true>, std::__1::allocator<std::__1::__value_type<unsigned short, unsigned short> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<unsigned short, unsigned short>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, unsigned short>, std::__1::less<unsigned short>, true> >=Q}}}{map<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > >, std::__1::less<unsigned short>, std::__1::allocator<std::__1::pair<const unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > > > >={__tree<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::less<unsigned short>, true>, std::__1::allocator<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<unsigned short, std::__1::__value_type<unsigned short, std::__1::map<std::__1::basic_string<char>, unsigned short, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, unsigned short> > > >, std::__1::less<unsigned short>, true> >=Q}}}}8@?0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/CharacterMap.cpp
result.second
v32@?0{?=qq}8^B24
v24@?0r^S8Q16
J_Numeral.dict
Josu.data
^{SeaweedFileMappedImmutableDictionary=^^?CI^{BurstTrie}IIIi{shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}^{Token}*{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}^{FeatureInterpreter}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}{vector<BurstTrie, std::__1::allocator<BurstTrie> >=^{BurstTrie}^{BurstTrie}{__compressed_pair<BurstTrie *, std::__1::allocator<BurstTrie> >=^{BurstTrie}}}{vector<unsigned int *, std::__1::allocator<unsigned int *> >=^^I^^I{__compressed_pair<unsigned int **, std::__1::allocator<unsigned int *> >=^^I}}[256C]}8@?0
v24@?0^{_LXCursor=}8*16
NumberValue.index
openCount
initiallyOpenedCallCount
lastlyClosedCallCount
q24@?0@8@16
%s : %ld
Token count: %ld, UNK count = %ld
RevertLearning
PerformLearning
%s:%s
Contents
zip_code.dat
com.apple.TrieAccessMethod
com.apple.HeapAccessMethod
com.apple.TestAccessMethod-Inspector
IDXDefaultProperty
com.apple.DictionaryServices
plist
Resources
Contents/
Info.plist
IDXDictionaryVersion
IDXDictionaryIndexes
IDXIndexName
IDXIndexPath
IDXIndexAccessMethod
IDXIndexKeyMatchingMethods
IDXIndexDataSizeLength
IDXIndexWritable
IDXIndexSupportDataID
IDXIndexBigEndian
IDXIndexDataFields
IDXExternalDataFields
IDXFixedDataFields
IDXVariableDataFields
IDXDataFieldName
IDXDataSize
IDXDataSizeLength
IDXExactMatch
IDXPrefixMatch
IDXCommonPrefixMatch
IDXWildcardMatch
IDXAllMatch
IDXExactMatchVoicedAmbi
IDXExactMatchSmallAmbi
IDXExactMatchVoicedAndSmallAmbi
IDXPrefixMatchVoicedAmbi
IDXPrefixMatchSmallAmbi
IDXPrefixMatchVoicedAndSmallAmbi
IDXIndex
<%@>
<#invalid index>
<IDXIndexRef %p>{access method = %@, index = %@, open# = %d}
<IDXIndexRef %p>{access method = %@, #invalid index}
HeapDataCompressionType
HeapDataCompressionBlockSize
HeapDataCompressionMaxBlockCount
Failed to add a new data since record count exceeds limit (%lld) defined in the current compaction-type.
Record count exceeds limit (%lld).
TrieIndexCompressionType
TrieAuxiliaryDataOptions
TrieAuxiliaryDataFile
TrieSubIndexPath
%@_aux.data
Packed Homograph
dicdir
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/char_property.cpp
fsize == cmmap_->size()
invalid file size: 
DEFAULT 1 0 0
SPACE   0 1 0
0x0020 SPACE
 is not found. minimum setting is used
size >= 2
format error: 
r.low >= 0 && r.low < 0xffff && r.high >= 0 && r.high < 0xffff && r.low <= r.high
range error: low=
 high=
category.find(std::string(col[i])) != category.end()
category [
] is undefined
size >= 4
category.find(key) == category.end()
category 
 is already defined
category.size() < 18
too many categories(>= 18)
category.find("DEFAULT") != category.end()
category [DEFAULT] is undefined
category.find("SPACE") != category.end()
category [SPACE] is undefined
DEFAULT,0,0,0,*
SPACE,0,0,0,*
 is not found. minimum setting is used.
n >= 1
category.find(key) != category.end()
] is undefined in 
unk.find(it->first) != unk.end()
permission denied: 
std::strlen(s) >= 3 && s[0] == '0' && (s[1] == 'x' || s[1] == 'X')
no hex value: 
false
c.size()
category size is empty
it != category->end()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/mmap.h
unknown open mode: 
(fd = open_create__(filename, flag | O_BINARY, S_IRUSR | S_IWUSR)) >= 0
open failed: 
(fd = open__(filename, flag | O_BINARY)) >= 0
fstat(fd, &st) >= 0
failed to get file size: 
(p = reinterpret_cast<char *> (mmap(0, length, prot, MAP_SHARED, fd, 0))) != MAP_FAILED
mmap() failed: 
no such file or directory: 
enumerateEntriesWithPrefix
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/im/dictionary.cpp
!(option & MECAB_JAPANESE_ROMAJI)
dmmap_->size() >= 100
dictionary file is broken: 
(magic ^ DictionaryMagicID) == dmmap_->size()
ptr == dmmap_->end()
 count=
dicdir
matrix.def
matrix.bin
wakati
type
node-format
input-method-language
reading 
 ... 
com.apple.inMemoryImmutableDictionaryDispatcher.modify
com.apple.inMemoryImmutableDictionaryDispatcher.build
system
mixed
single_character
category
emoji
supplement
english
asset
asset_mixed
region
Wrong dictionary type string
Cannot load dictionary index property plist.
Cannot find properties for dictionary type 
feature_format
full
skip_syllable_lengths
Unrecognized feature format.
indexes
Cannot find index property array for dictionary type 
is_reversed
string
syllable_id
syllable_id based dictionary key must be in reversed direction
Syllable ID indexes must be before string indexes
Unrecognized dictionary key type.
has_sub_index_for_prefix
Analyses
DynamicDictionaries
SessionReset
MecabraAnalysisOption
CurrentAnalysisString
CandidateContext
InputContext
AppContext
GeometryData
Empty Input Context.
Empty App Context.
PosInfo.plist
properNounPosID
numeralPosID
commonNounPosID
sahenNounPosID
placeNamePosID
adjectivePosID
adverbPosID
suffixPosID
verbPosID
personNamePosID
personLastNamePosID
personFirstNamePosID
nounRegionBeginPosID
nounRegionEndPosID
verbRegionBeginPosID
verbRegionEndPosID
auxVerbRegionBeginPosID
auxVerbRegionEndPosID
depVerbRegionBeginPosID
depVerbRegionEndPosID
particleRegionBeginPosID
particleRegionEndPosID
sahenImperativePosID
sahenConjunctivePosID
suffixAdjectiveBasePosID
suffixAdjectiveAttributivePosID
shouldResetConstraint
phraseFlags
tokenize2(buf, "\t ", std::back_inserter(column), 2) == 2
UTF-8
EUC-JP
SHIFT-JIS
UTF-16
UTF-16BE
UTF-16LE
charset 
 is not defined, use EUC-JP
allocator<const T>::allocate(size_t n) 'n' exceeds maximum supported size
dicdir
open-mutable-dictionary
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/im/connector.cpp
matrix_
matrix is NULL
cmmap_->size() >= 2
file size is invalid: 
static_cast<size_t>(header_size * 2 + (lsize_+1) * 2 + data_num_ * 2) == cmmap_->size()
static_cast<size_t>(lsize_ * rsize_ + 2) == cmmap_->size()
0 0 0
tokenize2(buf, "\t ", column, 2) == 2
tokenize2(buf, "\t ", column, 3) == 3
l < lsize && r < rsize
index values are out of range
emitting matrix      
tokenize2(buf, "\t ", std::back_inserter(column), 3) == 3
first argment seems invalid
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/param.cpp
pos != std::string::npos
unknown
unrecognized option `
` requres an argument
` dosen't allow an argument
mecab
help
version
MeCab: Yet Another Part-of-Speech and Morphological Analyzer
Copyright(C) 2001-2008 Taku Kudo 
Copyright(C) 2004-2008 Nippon Telegraph and Telephone Corporation
Usage: 
 [options] files
 of 
0.97
, --
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/tagger.cpp
param_.open(arg, long_options)
help
version
load_dictionary_resource(param)
tokenizer_.open(*param)
connector_->open(*param)
viterbi_.open(*param, &tokenizer_, connector_)
writer_.open(*param)
output-format-type
dump
writer_.write(&ostrs_, str, n)
writer_.write(&os, str, n)
os.str()
output buffer overflow
writer_.writeNode(&ostrs_, static_cast<const char *>(begin_), node)
writer_.writeNode(&os, static_cast<const char *>(begin_), node)
NULL pointer is given
bosNode
(*viterbi_ptr_).lattice_level() >= 1
use -l option to obtain N-Best results. e.g., mecab -N10 -l1
writer_.write(&ostrs_, static_cast<const char *>(begin_), n)
writer_.write(&os, static_cast<const char *>(begin_), n)
output
nbest
lattice-level
dump-config
dictionary-info
input-buffer-size
partial
set input method language
rcfile
FILE
use FILE as resource file
set DIR  as a system dicdir
userdic
use FILE as a user dictionary
learndic
use FILE as a learn dictionary
word-completion-dic
use FILE as a word completion dictionary
lattice information level (default 0)
show dictionary information and exit
all-morphs
output all morphs(default false)
TYPE
set output format type (wakati,none,...)
partial parsing mode
%m\t%H\n
use STR as the user-defined node format
unk-format
use STR as the user-defined unk format
bos-format
use STR as the user-defined bos format
eos-format
EOS\n
use STR as the user-defined eos format
unk-feature
use STR as the feature for unknown word
set input buffer size (default 8192)
dump MeCab parameters
open-mutable-dictionary
open dictioanry with mutable mode (experimental)
allocate-sentence
allocate new memory for input sentence
output N best results (default 1)
theta
0.75
FLOAT
set temparature parameter theta (default 0.75)
set the output file name
show the version and exit.
show this help and exit.
v24@?0r^{?=SsQ}8^B16
v24@?0r^{?=SsQI}8^B16
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/tokenizer.cpp
property_.open(param)
unkdic_->open(create_filename (prefix, UNK_DIC_FILE).c_str(), mode) && setDictionaryID(unkdic_)
sys.dic
succeeded && setDictionaryID(sysdic)
sysdic->type() == 0
not a system dictionary: 
d->open(_dic[i], mode) && setDictionaryID(d)
d->type() == MECAB_USR_DIC
not a user dictionary: 
learndic_->open(learndicpath.c_str(), "r+") && setDictionaryID(learndic_)
n.value != 0
cannot find UNK category: 
bos-feature
*bos_feature_ != '\0'
bos-feature is undefined in dicrc
max-grouping-size
v24@?0r*8^B16
sjis
shift-jis
shift_jis
cp932
euc_jp
euc-jp
utf8
utf_8
utf-8
ascii
utf-16be
utf-16le
utf-16
%s: %3d%% |%.*s%*s| 
HOME
MECABRC
allocate-sentence
cost-factor
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/viterbi.cpp
cost_factor_ > 0
cost-factor is empty
theta
lattice-level
partial
all-morphs
0xffff != lsize
too long lines
*(uint16_t *)(column[1]) != '\0'
use \t as separator
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/viterbisub.h
bestNode
too long sentence.
none
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/writer.cpp
!tmp.empty()
unknown format type [
unkonwn meta char 
[iseSCwcnblLh] is required after %p
lr is required after %ph
node->lpath
no path information, use -l option
[icP] is required after %pp
node->feature[0] != '\0'
no feature information available
*++p =='['
cannot find '['
n < psize
given index is out of range
cannot find ']'
Seed
Hyoki
Yomi
__??info??__
Keyword_aux.data
@"NSMutableArray"16@?0@"NSString"8
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
1234512344***=
qwertyuiopasdfghjklcvbnmzxxz
qwertyuiopasdfghjklxcvbnm
12345
v24@?0Q8^B16
v24@?0@"MecabraCandidate"8^B16
q24@?0@"NSNumber"8@"NSNumber"16
[LexicalPreferenceLearner] Rewriting candidate from
[LexicalPreferenceLearner] Rewriting candidate to
## Lexical preference applied ##
## Before finalizing weights ##
## After finalizing weights ##
MECABRA_TEST
v32@?0r^S8q16^B24
Adding a single dynamic word candidate
v24@?0^{__CFString=}8i16B20
v24@?0r^{mecab_node_t=^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_path_t}^{mecab_path_t}**IIIssSSSSqSSCCCfC}8^B16
prefix
exact
[MJ::makeMecabSingleWordCandidates] Adding a single-word prefix candidate
[MJ::makeMecabSingleWordCandidates] Adding a single-word exact candidate
Adding a partial phrase candidate
Previous candidate
Last-bunsetsu
v24@?0r^{bigram_entry_t=ssSSS{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}f}8^B16
Added a phrase candidate
Replaced a phrase candidate
Failed to add a phrase candidate
Adding a phrase learning dictionary candidate (success)
Adding a phrase learning dictionary candidate (failure)
Added a single dynamic word candidate
Failed to add a single dynamic word candidates
stabilizeCandidates
Adding a bigram learning dictionary candidate
Adding a learned phrase bigram prefix candidate
## Final ##
v32@?0r^S8Q16^B24
[MJ:searchPhrasesByPosContext]
v28@?0@"MecabraCandidate"8s16^B20
Settings.plist
kanakb.dic
null
pos_prediction.dat
word_cache.dat
v24@?0^{__CFString=}8^B16
Creating accepted candidate from a synthetic candidate
Creating accepted candidate from a facemark candidate
Creating accepted candidate from a conversion candidate
## Before reranking ##
## After reranking ##
bcdfghjklmpqrstvwxyz
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
heteronyms.dat
-p -d %@ -l1
 -u %@
/Library/Dictionaries
 -g %@
 -i ja
 -i zh-Hans
 -i zh-Hant
Hans
Hant
zh-Hans
zh-Hant
zh-Hans-Pinyin10
zh-Hans-Pinyin
zh-Hans-Stroke
zh-Hans-Wubixing
zh-Hant-Cangjie
zh-Hant-Pinyin10
zh-Hant-Pinyin
zh-Hant-Stroke
zh-Hant-Zhuyin
ja-Romaji
ja-Kana
zh-Hans-HWR
zh-Hant-HWR
true
IPHONE_SIMULATOR_ROOT
createSystemRootPath
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/MecabraMiscUtilities.cpp
simulatorRoot
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
Library/Keyboard
wstring_convert: to_bytes error
Cannot initialize ICU transliterator.
Cannot initialize ICU number formatter.
v28@?0I8d12^B20
isInputReadingIncompleteForWordAtIndex
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/MecabraConversionCandidate.cpp
index < wordCount()
lastPrefixValue() <= wordCount()
inputMethodType
learningEnabled
dynamicLMEnabled
useSpecialSymbol
syncLearningData
liteMode
systemDictionaryDirectory
learningDictionaryDirectory
additionalDictionaryDirectories
staticLanguageModelBundle
dynamicLanguageModelBundle
isEndingWithPunctuation
MecabraLatticeNumberOfNodes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/Mecabra.mm
size <= std::numeric_limits<CFIndex>::max()
MecabraLatticeFanoutForNodeAtIndex
MecabraLatticeDestinationNodeForEdgeAtIndexFromSourceNodeAtIndex
destinationNodeIndex <= std::numeric_limits<CFIndex>::max()
%@%@
v36@?0{?=qq}8I24^B28
build
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/DynamicDictionary.cpp
(entriesBufferPos + 1 + keyLength + 1 + 1 + valueLength) <= entriesBufferLength
(entriesBufferPos + 1 + valueLength) <= entriesBufferLength
v28@?0I8Q12^B20
Tokenizer
^{MecabraChineseTokenizer=^v{mutex={_opaque_pthread_mutex_t=q[56c]}}}8@?0
emoji_adornment.plist
.%@.lock
v24@?0^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8^B16
Reading
Surface
Syllables
WordLengths
ReservedString
ReservedInteger
SurfaceSegments
ReadingSegments
PartOfSpeech
ExtraString1
PinyinReading
ZhuyinReading
PinyinSyllableLengths
ZhuyinSyllableLengths
completion-learning-dictionary-zh-Hans
completion-learning-dictionary-zh-Hant
completion-learning-zh-Hans.dictionary
completion-learning-zh-Hant.dictionary
ReadingMappedString
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/ReadingMappedString.cpp
unmappedString
phrase_candidate_accepted_count
system_dictionary_candidate_accepted_count
partial_candidate_accepted_count
abbreviated_pinyin_candidate_accepted_count
extension_candidate_accepted_count
user_dictionary_conversion_candidate_accepted_count
learning_dictionary_conversion_candidate_accepted_count
address_book_conversion_candidate_accepted_count
autocorrection_candidate_accepted_count
first_conversion_candidate_accepted_count
second_conversion_candidate_accepted_count
third_conversion_candidate_accepted_count
fourth_conversion_candidate_accepted_count
conversion_candidate_accepted_count
completion_candidates_appeared_count
fuzzy_pinyin_enabled
accepted_candidate_length
com.apple.keyboard.%s.%@
AdjacencyListLattice
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/AdjacencyListLattice.cpp
bosNode->stat == MECAB_BOS_NODE
<BOS>
<EOS>
<UNK>
<EXC>
^{File<char>=*Q{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}iB}8@?0
unknown open mode for file 
could not open file 
failed to get file size for 
mmap failed for 
failed to read from 
Wrong version from 
assetDataFilePaths
assetDataRegionIdentifier
.corrupt
v20@?0i8^B12
v32@?0r*8i16i20^B24
%@,%@
v16@?0r^{IDXUserDictionaryEntry=^Sq^Sq^SqI}8
v24@?0^{__CFString=}8^{__CFString=}16
Words
Words_tmp
DROP TABLE Assist
PRAGMA journal_mode = WAL;
:memory:
main
ROLLBACK
BEGIN IMMEDIATE
COMMIT
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
init
/BuildRoot/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator12.0.sdk/usr/local/include/nlp/BurstTrieAdapter.h
m_mutable
m_trie
addEntry
removeEntry
clear
ambiguousDfsTraverse
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/AmbiguousTrieAdapter.hpp
m_trie->isValid(curCursor)
operator()
m_trie->isValid(cursor)
 FROM Words
 AND 
 = ?
 (Seed
) VALUES (?
 FROM Words WHERE Identifier = ?
 (Identifier INTEGER PRIMARY KEY, Seed INTEGER
BLOB
INTEGER
CREATE TABLE Assist (Identifier INTEGER PRIMARY KEY, LastSeedValue INTEGER, LastUpdateTime REAL, Version INTEGER DEFAULT 0)
INSERT INTO Assist (LastSeedValue, LastUpdateTime, Version) VALUES (0, 0, 0)
ja_JP
EEEE
MMMM
analysisString
T@"NSString",C,N,V_analysisString
characterInformation
T@"NSArray",&,N,V_characterInformation
codeLookupInformation
T@"NSArray",&,N,V_codeLookupInformation
TB,N,GisEmoji,V_emoji
language
Ti,N,V_language
v32@?0^{?=^{Token}*}8Q16^B24
/System/Library/PrivateFrameworks/ProofReader.framework
Traditional - Simplified
Simplified - Traditional
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ
failed to set backup exclusion for item at URL: %s
[[:Hani:]]
zh-Hans
zh-Hant
B24@?0r^S8q16
Phrases-en_US
v44@?0I8r*12d20I28I32^B36
%@ %@
taiwan
tibet
/System/Library/PrivateFrameworks/EmojiFoundation.framework/EmojiFoundation
EMFEmojiLocaleData
Unable to find class %s
EMFEmojiToken
EMFEmojiPreferencesService
updateBestAnalysis
makeSegmentsExceptLast
best
top segment
best segment
makeLastSegments
createCandidateFromAnalysis
Adding top candidate
addCandidateAsTopCandidate
added
replaced
no update
top candidate
enabled
disabled
Last-bunsetsu candidate #
segments except last
last segments
logSegments
shouldChooseTopSegment
isTopSegmentSurfaceUnreliable
makeReliableKanaSegment
isBestSegmentReliable
makeLastSegmentFromTopSegment
yyyy-MM-dd@HHmm.ssSS
/tmp/GeometryModel
/tmp/GeometryModel/%@-%@.plist
getLoglikelihoodOfKeys:length:touch_index:totalCount:
keys
log likelihoods
stringFromGeometryData
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/GeometryModel.mm
numKeys > 0
%C:%f
{0:0}
com.apple.mecabra.
DEBUG_PRINT_NODES
DEBUG_PRINT_WORD_GROUPS
DEBUG_PRINT_SYLLABLE_LATTICE
DEBUG_PRINT_CONNECTED_NODES
DEBUG_PRINT_HYPOTHESES
DEBUG_PRINT_HYPOTHESIS_SETS
DEBUG_HOMOPHONE_PHRASES
DEBUG_NGRAM_SCORE
DEBUG_NGRAM_QUANTIZATION
DEBUG_INCREMENTAL_ANALYSIS
DEBUG_PINYIN_TEXT_CHECKING
MECABRA_LOG_TIMING
MECABRA_LOG_STATISTICS
DEBUG_PRINT_CHARACTER_LATTICE
LOG_GEOMETRY_MODEL_DATA
DEBUG_PRINT_BEST_BACKTRACE
DEBUG_RERANKING
DEBUG_LEARNING
DEBUG_DYNAMIC_CANDIDATES
DEBUG_ENGINE
DEBUG_PREDICTION
DEBUG_PRINT_ADAPTATION
DEBUG_PRUNING
DEBUG_LIVE_CONVERSION
MECABRA_LOG_DESTINATION
Cannot open specified log file %s.
All logging is turned off.
MECABRA_LOG_BUFFERED
MecabraLogLevel
Log message exceeded the 1024-byte length limit.
[%s] paused at (%lu, %lu), total time elapsed %.8f seconds
[%s] Total time elapsed %.8f seconds
total hypotheses created: %d
total hypothesis sets created: %d
%@ (AS:%@ CAS:%@ DR:%@), %ld, %f
%@ (AS:%@ CAS:%@ DR:%@), %ld
GARBAGE
(%@)
rawCandidate
T^{MecabraCandidateBase=^^?q},R,N
rawConversionCandidate
T^{ConversionCandidate=^^?q},R,N
isConversionCandidate
TB,R,N
isSyntheticCandidate
isExtensionCandidate
isEmojiCandidate
isPersonName
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
isRegionalCandidate
Ti,R,N
wordCount
TQ,R,N
surface
T@"NSString",R,N
convertedAnalysisString
dictionaryReading
attributes
T@"NSDictionary",R,N
kEmbedded
[ME::acceptLeftContext] #
[ME::acceptInlineContext] #
[ME:analyzeStringWithContext] Using a truncated context candidate
[ME::acceptCandidate] Accepted
v52@?0r^{UTF16String=^SQ}8r^{UTF16String=^SQ}16r^{UTF16String=^SQ}24r^{UTF16String=^SQ}32i40i44i48
{Word=SSiiiiSSSCBBBBc}48@?0r^{mecab_node_t=^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_node_t}^{mecab_path_t}^{mecab_path_t}**IIIssSSSSqSSCCCfC}8^S16Q24r^S32I40B44
[ME::addCandidateFromMecabNode] Adding a partial candidate
[ME::addCandidateFromMecabNode] Adding a non-partial candidate
wordListFile
candidates
incrementalAnalysisCount
totalAnalysisCount
Q24@?0^{trie_search_result_type_t=ccfIQ}8Q16
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/CharacterInfo/NSString+CharacterInformationAdditions.mm
<Unknown File>
Invalid parameter not satisfying: %@
toneNumber >= 1 && toneNumber <= 4
%K = %@
Delete
Partial Entry
Matching
Set Value
Duplicate entry
Restrict amount
Automatic Delete
Set Values
Uniquing
%@ [%@] 
[CoreData]
[%@] 
MecabraDatabaseDeletedAllElementsNotification
.bundle
%@_%@
database.db
Exception when trying to create new persistent store: %@
Could not create coordinator
CoreDataUbiquitySupport
B24@?0@"NSURL"8@"NSError"16
journal_mode
DELETE
Error in saving database; %@ %@
localURL
T@"NSURL",&,N,V_localURL
storedElementsForMerge
T@"NSArray",&,N,V_storedElementsForMerge
entityDescription
T@"NSEntityDescription",R,N,V_entityDescription
localStoreURL
T@"NSURL",R,N
localInfoPlistURL
managedObjectModel
T@"NSManagedObjectModel",&,N,V_managedObjectModel
managedObjectContext
T@"NSManagedObjectContext",&,N,V_managedObjectContext
persistentStoreCoordinator
T@"NSPersistentStoreCoordinator",&,N,V_persistentStoreCoordinator
storeURL
T@"NSURL",&,N,V_storeURL
T@"NSString",&,N,V_type
v24@?0^{_LXEntry=}8*16
Lexicon
^{Lexicon=^v^v}8@?0
.plist
EntityDescriptionURL
EntityModelName
EntityRequiredKeys
EntityUniquingKeys
SortDescriptors
SortDescriptorName
SortDescriptorAscending
com.apple.TextInput
Dictionaries/Storage.nosync/%@/database.db
Dictionaries
DatabaseSyncs
descriptionDictionary
T@"NSMutableDictionary",&,N,V_descriptionDictionary
T@"NSString",R,&,N,V_type
ubiquityContainerIdentifier
/usr/share/mecabra/common/descriptions/
%@:(%ld)
dictionary ID = %d
Error has occured when process word in %s ... 
Word ID = %d, token offset = %zu
Added %zu words
verify
Incorrect commandline arguments!
langugae
Too few arguments.
Language is not specified.
Language must be "zh-Hans" or "zh-Hant".
Failed to build reverse dictionary %s.
Failed to process %s.
locale
directory
s:i:d:
Locale is required.
Word-ID map is required.
Directory of source dictionaries is required.
Incorrect number of arguments.
Locale can must be zh-Hans or zh-Hant.
Cannot verify reverse dictionary %s!
Failed to load reverse dictionary %s
Didn't find word ID for %s(%d) in word to ID mapping file.
word to ID mapping file contains different word ID (%d) for %s(%d)
Usage:
%s <command> [args] [DictionaryFileName+] ReverseDictionaryFileName
build:
DictionaryFileName argument is required for build command.
-l|--language: "zh-Hans" or "zh-Hant".
verify:
-s|--locale: Locale.
-i|--id: Word to word ID mapping file.
-d|--directory: Directory containing source dictionaries.
com.apple.MobileAsset.LinguisticData.new-asset-installed
com.apple.mecabra.mobileassetnotificationmanager
v12@?0i8
Mecabra: Notification "%s" registration success (token=%d)
Mecabra: Notification "%s" registration FAILURE (status=%u)
q24@?0@"MecabraCandidate"8@"MecabraCandidate"16
MecabraLearningResetNotification
LearningDictionary
v32@?0^{__CFDictionary=}8^{map<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue>, std::__1::less<std::__1::basic_string<char> >, std::__1::allocator<std::__1::pair<const std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >={__tree<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> > > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<std::__1::basic_string<char>, std::__1::__value_type<std::__1::basic_string<char>, std::__1::shared_ptr<EntryFieldValue> >, std::__1::less<std::__1::basic_string<char> >, true> >=Q}}}16^B24
DynamicPhraseLexicon_zh_Hans.db
PhraseLearning_zh_Hans.db.bundle
PhraseLearning_zh_Hans.db
PhraseLearning_zh_Hans.dictionary
StructuralPinyinLearning_zh_Hans.db.bundle
StructuralPinyinLearning_zh_Hans.db
StructuralPinyinLearning_zh_Hans.dictionary
DynamicPhraseLexicon_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.db.bundle
PhraseLearning_zh_Hant_pinyin.db
PhraseLearning_zh_Hant_pinyin.dictionary
StructuralPinyinLearning_zh_Hant_pinyin.db.bundle
StructuralPinyinLearning_zh_Hant_pinyin.db
StructuralPinyinLearning_zh_Hant_pinyin.dictionary
DynamicPhraseLexicon_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.db.bundle
PhraseLearning_zh_Hant_zhuyin.db
PhraseLearning_zh_Hant_zhuyin.dictionary
StructuralZhuyinLearning_zh_Hant_zhuyin.db.bundle
StructuralZhuyinLearning_zh_Hant_zhuyin.db
StructuralZhuyinLearning_zh_Hant_zhuyin.dictionary
ReversedDictionary
^{ReverseDictionary={shared_ptr<File<char> >=^{File<char>}^{__shared_weak_count}}{vector<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>, std::__1::allocator<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> > >=^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}{__compressed_pair<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> *, std::__1::allocator<std::__1::shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary> > >=^{shared_ptr<Seaweed::SeaweedFileMappedImmutableDictionary>}}}i^{Header}^I{shared_ptr<InputEngine::CharacterMap>=^{CharacterMap}^{__shared_weak_count}}}8@?0
Failed to load character map for language 
 is unsupported language value.
supplement.dic
mixed.dic
 is not a recognized source dictionary name.
Token offset 
 is out of range. The max offset value is 0x1FFFFF.
Failed to open dictionary 
Failed to open dictionary : %s
LexicalLearning_ja_JP.db
NonLexicalLearning_ja_JP.db
FirstSurface
SecondReading
SecondSurface
SecondReadingSegments
SecondSurfaceSegments
SecondPartOfSpeech
Lexierra_ja_JP-dynamic-text.dat
LexicalLearning_ja_JP.dat
DynamicPhraseLexicon_ja_JP.db
PhraseLearning_ja_JP.db.bundle
PhraseLearning_ja_JP.dictionary
PhraseLearning_ja_JP.db
BigramLearning_ja_JP.dictionary
BigramLearning_ja_JP.db
DynamicBigramPhraseLexicon_ja_JP.db
BigramLearning_ja_JP.db.bundle
online
%@/%@ 
%@ (%d) 
LearningDictionaryJapanese
JapaneseBigram
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.mecabra
Building dictionary: %s
%s usage: <template file> <dictionary data file> <new dictionary path> 
can't read template from file %@
can't create URL for new dictionary %@
error building dictionary
Dictionary was built successfully.
reading dictionary data file %@ failed with error %@
bad dictionary data %@
POS:
LeftPOS1:
LeftPOS2:
RightPOS1:
RightPOS2:
LeftSurface1:
LeftSurface2:
RightSurface1:
RightSurface2:
LeftSurface1
LeftSurface2
RightSurface1
LeftPOS1
LeftPOS2
RightPOS1
IntValue
v48@?0r^I8q16d24q32^B40
[makeCandidateFromExpandedSequence]
[MJNP::expandPhrasesWithLanguageModel] Handling n-gram expansion from
[MJNP::expandPhrasesWithLanguageModel] Adding an n-gram expansion candidate
v24@?0^{DynamicDictionaryEntry=^Sq^Sq}8^B16
LearningSet_zh_Hans.plist
LearningSet_zh_Hant.plist
char.def
unk.def
char.bin
try '--help' for more information.
Not allow multiple dictionary to be built at the same time.
outdir
sysdic
phrase_bigram
reading_bigram
binary
matrix
set DIR as dicdi (default ".")
set DIR as output dir (default ".")
build user dictionary
build supplement dictionary
build parameters for unknown words
build system dictionary
phrase_bigram file
reading_bigram file
binary dictionary name
build connection matrix
show the version and exit
show this help and exit
Revert learning for candidate %s
v16@?0^{__CFString=}8
:/-_+@#
Best: 
AutoCorrection: 
Phrase without EOS: 
Alternative: 
B16@?0r^{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}8
UTF-8
UTF-16LE
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/Dictionary/MecabraJapaneseDictionaryCompiler.cpp
count == kTokenColumnCount
Wrong format with unigram string: 
 at line 
stringToUInt16(std::string(col[3]), cost)
wrong cost!
count == 3
wrong format.
m_iconvFromUTF8ToUTF16.convert(&bigramToken->previous)
error with iconv convert!
stringToUInt16(std::string(col[1]), &(bigramToken->prob))
wrong probability value!
bigramToken->prob <= 100
probability value is more than 100!
fields.size() == kTokenColumnCount - 1
Field count 
 is not expected! expected: 
stringToUInt16(fields[1], &lid)
error with stringToUInt16!
stringToUInt16(fields[2], &rid)
stringToUInt16(fields[3], &attribute)
stringToUInt32(fields[4], &tokenID)
m_iconvFromUTF8ToUTF16.convert(&token->reading)
m_iconvFromUTF8ToUTF16.convert(&token->surface)
m_trie.lookup(m_agent)
cannot find entry in trie.
Start to validate dictionary: 
DictionaryValidate done: 
Unigram testing
v24@?0r^{mecab_token_t=sSSSI}8^B16
found == true
cannot found the entry.
count == unigramReadingAndTokensPair.tokens.size()
count doesn't match.
Unigram testing done
Phrase bigram testing.
Reading bigram testing.
v28@?0r^{BigramToken=sII}8f16^B20
cannout found the bigram entry.
count >= firstStringAndTokensPair.tokens.size()
entry count is smaller than the number of token pair "
" entries:
 reading-token pairs:
Phrase bigram testing done.
Reading bigram testing done.
token->reading.size()
token reading is empty
token->surface.size()
token surface is empty
iterator == m_tokenIDToUnigramTokenIndexMap.end()
tokenID should be unique.
tokenCount == m_sortedUnigramTokenArray.size()
m_sortedUnigramTokenArray.size is not equal to the token count in m_unigramReadingAndTokensPairList.
token->previous.size()
iterator != m_tokenIDToUnigramTokenIndexMap.end()
wrong mapping from token ID to token index.
convertToKatakana(rawToken.reading, &unigramSurfaceString)
cannot convert to katakana.
homographCount <= 0xff
homographCount is greater than 0xff.
tokenIndex <= 0x00ffffff
tokenIndex is greater than 0x00ffffff.
------------Characters at pos 
 characters --------------- 
------------words at pos 
 cursors --------------- 
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/commercial.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/computer.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/industry.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/education.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/traffic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/law_poli.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/build.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/cmedic.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/medical.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/biology.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/military.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/phy_chem.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/sport.dic
/System/Library/LinguisticData/RequiredAssets_zh-Hant.bundle/AssetData/buddhism.dic
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/seaweed/Dictionary/SeaweedChineseDictionaryCompiler.cpp
m_converter.open("UTF-8", "UTF-16LE")
iconv_open() failed (from UTF-8 to UTF-16LE)
index_config
Cannot load dictionary index properties. Error: 
priority
input
pinyin_syllable
zhuyin_syllable
wrong language
columnCount == kOriginalFeatureStartColumn + 1
CSV format error: 
originalFeature.size()
feature empty error: 
featureColumnCount > data.syllableIDIndexCount()
feature format error: 
data.syllableIDIndexCount() <= data.indexCount()
feature format error (syllable ID index count is too big): 
readingColumnCount == data.indexCount()
reading format error: 
!readingString.empty()
readingString error: 
iconv.convert(&readingString)
convert reading error: 
iconv.convert(&convertedReading)
!convertedReading.empty()
empty converted reading error: 
set as input text file
set as output file
set as pinyin syllable data file
set as zhuyin syllable data file
dictionary type(system, supplement, single_character, category, emoji, english, asset (not implemented))
index configuration file
languge: zh-Hans or zh-Hant
compile_block_invoke
featureDataOffset < UINT32_MAX
v16@?0r^{RawDictionaryEntry=iii{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{vector<std::__1::basic_string<char>, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}{__compressed_pair<std::__1::basic_string<char> *, std::__1::allocator<std::__1::basic_string<char> > >=^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >}}}}8
(out.tellp() % kAlignmentNumber) == 0
header is not aligned: 
trie data header is not aligned: 
token buffer is not aligned: 
 compiled successfully.
m_data.indexCount() == dictionary->indexCount()
dictionary index count error. 
validate_block_invoke
featureOffset < UINT32_MAX
v24@?0^{?=^{Token}*}8^B16
[ERROR] validation failed on index 
 for line 
v40@?0^{?=^{Token}*}8r*16Q24^B32
keyTokenPairs.size() <= kMaxTrieEntryCount
trie can hold a maximum of 
 entries.
homographCount <= kMaxHomographEntryCount
number of homograph words is greater than 
. string =
allKeys.size()
no reading error. 
keyTokenOffsetPairs.size() <= kMaxTrieEntryCount
m_data.indexCount() > m_data.syllableIDIndexCount()
trie must hold at least one one non-syllable index
trie data is not aligned: 
token index buffer is not aligned: 
(reading[i] >= 'a' && reading[i] <= 'z') || reading[i] == '*'
not valid pinyin error: 
isZhuyinToneMark(zhuyin[i]) || isValidZhuyin(zhuyin[i])
not valid zhuyin error: 
syllableLengths[i]
syllable length is zero: 
total == reading.size()
syllable length doesn't match reading: 
syllableID != kInvalidIndex
cannot get syllable ID from syllable trie: 
v44@?0r^{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}8r^{Token=ISSI}16Q24B32^B36
v20@?0I8^{__CFDictionary=}12
single_character.dic
single_character2.dic
single_character3.dic
facemarks.plist
zh-Latn-CN-pinyin
zh-Hans-Latn-CN-pinyin
syllable.lm
Chinese.lm
charmap.dat
syllable.dat
emoji_dependency.dat
emoji_conversion.dat
emoji_adornment.dat
emoji_prediction.dat
reverse.dic
Cangjie.dictionary
CangjieCodes.dat
Stroke.dictionary
Wubixing.dictionary
homophones.plist
PinyinToZhuyin.plist
ZhuyinToPinyin.plist
SortedRadicals.plist
WordProperties_CharacterInformation.dictionary
WordProperties_KeyLookup.dictionary
rewrite.dat
LanguageModel
PhraseLearning_zh_Hans_Stroke.db.bundle
DynamicPhraseLexicon_zh_Hans_Stroke.db
PhraseLearning_zh_Hant_Sucheng.db.bundle
DynamicPhraseLexicon_zh_Hant_Sucheng.db
PhraseLearning_zh_Hant_Stroke.db.bundle
DynamicPhraseLexicon_zh_Hant_Stroke.db
DynamicPhraseLexicon_zh_Hans_Wubixing.db
PhraseLearning_zh_Hans_Wubixing.db.bundle
v24@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16
v24@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8^B16
B16@?0Q8
v52@?0^{LatticeSearchState=^{SyllableNodeBase}QQSSI{vector<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo>, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}{__compressed_pair<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> *, std::__1::allocator<std::__1::pair<unsigned char, Seaweed::DictionaryCursorInfo> > >=^{pair<unsigned char, Seaweed::DictionaryCursorInfo>}}}}8Q16r^{UTF16String=^SQ}24^{?=^{Token}*}32i40^B44
v56@?0Q8r^S16Q24r^S32Q40S48S52
NewWordPenalty
createHybridCandidateWithConversionCandidate
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/ChinesePrediction/ChinesePredictionCandidate.mm
v48@?0{?=qq}8r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}24r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}32r^{vector<unsigned short, std::__1::allocator<unsigned short> >=^S^S{__compressed_pair<unsigned short *, std::__1::allocator<unsigned short> >=^S}}40
%@(%d) 
 EOS
(%d)
iang
uang
iong
chon
jion
qion
xion
zhon
bang
beng
bian
biao
bing
cang
ceng
chai
chan
chang
chao
chen
cheng
chong
chou
chua
chuai
chuan
chuang
chui
chun
chuo
cong
cuan
dang
deng
dian
diao
ding
dong
duan
fang
feng
gang
geng
gong
guai
guan
guang
hang
heng
hong
huai
huan
huang
jian
jiang
jiao
jing
jiong
juan
kang
keng
kong
kuai
kuan
kuang
lang
leng
lian
liang
liao
ling
long
luan
lvan
mang
meng
mian
miao
ming
nang
neng
nian
niang
niao
ning
nong
nuan
pang
peng
pian
piao
ping
qian
qiang
qiao
qing
qiong
quan
rang
reng
rong
ruan
sang
seng
shai
shan
shang
shao
shei
shen
sheng
shou
shua
shuai
shuan
shuang
shui
shun
shuo
song
suan
tang
teng
tian
tiao
ting
tong
tuan
wang
weng
xian
xiang
xiao
xing
xiong
xuan
yang
ying
yong
yuan
zang
zeng
zhai
zhan
zhang
zhao
zhei
zhen
zheng
zhong
zhou
zhua
zhuai
zhuan
zhuang
zhui
zhun
zhuo
zong
zuan
biang
cuai
cuang
diang
duang
fong
fuai
fuan
fuang
juang
luang
miang
nuang
piang
quang
rian
riang
riao
ring
ruang
shong
suai
suang
tiang
tuang
xuang
yuang
zuai
zuang
v16@?0Q8
v16@?0^{?=Sf}8
%s: %s
Remove
-------------------- input = 
 ------------------
syllables ending with input char 
 at pos 
complete syllable: 
incomplete syllable: 
Autocorrected Complete syllable: 
prob = 
Previous syllable = 
 rawInputLength = 
Next syllable = 
Autocorrected Incomplete syllable: 
Synthetic syllable: mixed, length = 
Synthetic syllable: 
Start column indexes: 
First syllables: 
First syllable end column indexes: 
, separatorCount = 
, rawInputLength = 
 (fuzzy), original = 
bitset set argument out of range
bitset test argument out of range
Syllable trie file %s is incompatible (version %d, expected version %d)
Syllable trie open failed: %s
seed
Failed to delete legacy learning dictionary: %s
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8@?0
===RESET===
===cummulative stats since last reset===
hypotheses created = %ld
hypothesis sets created = %ld
words created = %ld
word groups created = %ld
%@ (%@)
T@"NSString",R,N,V_string
T@"NSString",R,N,V_category
synthetic word group:
type = 
syllable IDs: 
Syllable Lengths:
length = 
, trieValue = 
facemark.dat
^{FacemarkLearningDictionary={basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}{FacemarkLearningDictionaryHeader=IIId}{vector<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}^{FacemarkLearningEntry}{__compressed_pair<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry *, std::__1::allocator<InputEngine::FacemarkLearningDictionary::FacemarkLearningEntry> >=^{FacemarkLearningEntry}}}}8@?0
^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}32@?0r^{WordCore=^^?i^{WordGroupTraits}{vector<unsigned int, std::__1::allocator<unsigned int> >=^I^I{__compressed_pair<unsigned int *, std::__1::allocator<unsigned int> >=^I}}}8d16r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}24
adding word group endIndex=%d {
v24@?0r^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8Q16
^{WordGroup={WordGroupTraits=^{SyllableSequence}^{__CFString}QIIIi}{vector<Seaweed::LatticeWord *, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}^^{LatticeWord}{__compressed_pair<Seaweed::LatticeWord **, std::__1::allocator<Seaweed::LatticeWord *> >=^^{LatticeWord}}}B}8@?0
v24@?0r^{Hypothesis=[2I]Cd{BacktraceWaypoint=^{WordCore}^{BacktraceWaypoint}}}8^B16
NBest: 
 -> 
(%s, %d)
, prob: %f surface: %s
__insert_nodes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/src/trie_build.cpp
new_children
v40@?0r^{mecab_token_t=sSSSI}8r*16Q24^B32
This functionality has not been implemented for mutable dictionary!
Open file %s failed: %s
Dictionary file %s is empty
Dictionary file %s doesn't support the original format
Dictionary file %s has an empty header
Dictionary file %s is incompatible (version %d, expected version %d)
Dictionary file %s has the wrong content
Emoji file %s is empty
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/mecabra/EmojiDictionary.mm
columnCount >= 3
Wrong column count: 
emojiCount > 0 && emojiCount < kMaxFeatureCount
Wrong features: 
currentFeatureOffset < kMaxFeatureOffset
Exceed the feature offset limit: 
ofstream is empty: 
en_JP
EnglishLexicon_
^{EnglishLexicon={CFScopedPtr<const _LXLexicon *>={unique_ptr<const _LXLexicon, std::__1::function<void (const void *)> >={__compressed_pair<const _LXLexicon *, std::__1::function<void (const void *)> >=^{_LXLexicon}{function<void (const void *)>={type=[32C]}^{__base<void (const void *)>}}}}}{SearchState={CFScopedPtr<const __CFString *>={unique_ptr<const __CFString, std::__1::function<void (const void *)> >={__compressed_pair<const __CFString *, std::__1::function<void (const void *)> >=^{__CFString}{function<void (const void *)>={type=[32C]}^{__base<void (const void *)>}}}}}Qd{vector<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >, std::__1::allocator<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > > >=^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}{__compressed_pair<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > *, std::__1::allocator<std::__1::set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> > > >=^{set<InputEngine::EnglishLexicon::CursorTuple, std::__1::less<InputEngine::EnglishLexicon::CursorTuple>, std::__1::allocator<InputEngine::EnglishLexicon::CursorTuple> >}}}{vector<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> >, std::__1::allocator<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > > >=^{vector<unsigned short, std::__1::allocator<unsigned short> >}^{vector<unsigned short, std::__1::allocator<unsigned short> >}{__compressed_pair<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > *, std::__1::allocator<std::__1::vector<unsigned short, std::__1::allocator<unsigned short> > > >=^{vector<unsigned short, std::__1::allocator<unsigned short> >}}}}B}8@?0
EnglishPhraseLexicon_
/System/Library/LinguisticData/RequiredAssets_en.bundle/AssetData/
Phrases-
.dat
Delta-
^{AsyncResource<InputEngine::EnglishLexicon>=@?{unique_ptr<InputEngine::EnglishLexicon, std::__1::default_delete<InputEngine::EnglishLexicon> >={__compressed_pair<InputEngine::EnglishLexicon *, std::__1::default_delete<InputEngine::EnglishLexicon> >=^{EnglishLexicon}}}^{dispatch_group_s}^{dispatch_queue_s}{once_flag=Q}{atomic<InputEngine::AsyncResource<InputEngine::EnglishLexicon>::State>=Ai}{mutex={_opaque_pthread_mutex_t=q[56c]}}{basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >={__compressed_pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep, std::__1::allocator<char> >={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}8@?0
v40@?0^{_LXCursor=}8d16Q24*32
SuppressSensitiveWords
HistorySimulation
/System/Library/LinguisticData/RequiredAssets_zh.bundle/AssetData/reading-lookup.dat
Reading lookup index trie error.
Reading lookup version error.
reading %d: 
Cannot open %s
dumpDictionary
/BuildRoot/Library/Caches/com.apple.xbs/Sources/Mecabra_Sim/Mecabra-779.15.20/reading-lookup/BuildReadingLookupDictionary.mm
trie
%d words
reading-list
word-index
r:w:o:d:
ReadingLookupDictionaryBuild
[word length] > 0
[components count] == 4
offset <= 0xFFFFFF
CFBurstTrieAddUTF8String(trie, (UInt8*)utf16String, [word length] * sizeof(unichar), payload)
Cannot create %s
numByteWritten == sizeof(ReadingLookupDictionaryHeader)
numByteWritten == statBuffer.st_size - sizeof(ReadingHeader)
CFBurstTrieSerializeWithFileDescriptor(trie, outputFile, kCFBurstTrieReadOnly | kCFBurstTrieBitmapCompression | kCFBurstTrieSortByKey)
Created reading lookup dictioanry at %s
%s --reading-list PATH --word-index PATH --output PATH
%s --dump PATH
B0j0_0
D0d0
S0S0
S0a0
]0S0
i0S0
j0k0
0_0W0
[b_-
[b_-
*g6qb_-
B}bkb_-
SOb_-
SOb_-
(ub_-
B}bkb_-
SOb_-
*g6qb_-
(ub_-
(ub_-
(ub_-
B}bkb_-
(ub_-
(ub_-
B}bkb_-
(ub_-
SOb_-
]6qb_-
*g6qb_-
(ub_-
(ub_-
S0]0
K0W0
L0k0
U0H0
W0K0
W0M0
Z0d0
`0Q0
`0k0
c0f0
i0S0
j0h0
j0i0
0^0o0
p0K0
{0i0
~0g0
1\D0f0
U0K0D0
_0c0f0
d0d0
f0o0
h0f0
j0L0
p0c0f0
g0o0
k0f0
k0o0
K0D0
K0W0
O0U0
^0D0
n0F0
p0D0
y0D0
*g6qb_-
(ub_-
(ub_-
B}bkb_-
*g6qb_-
D}T~
B0h0
F0a0
S0h0
h0M0
h0S0
j0F0
o0Z0
{0F0
UOK0
,gS_
SOb_-
B}bkb_-
_0a0
Rpe^
Rpe^
zz}v
D0G0
F0C0
F0G0
M0C0
N0C0
M0G0
N0G0
O0A0
O0C0
P0C0
O0E0
P0E0
O0G0
P0G0
O0I0
P0I0
P0A0
W0C0
X0C0
W0G0
X0G0
Y0A0
Y0C0
Y0E0
Y0G0
Y0I0
a0C0
b0C0
a0G0
b0G0
d0A0
d0C0
d0G0
d0I0
f0C0
g0C0
f0G0
g0G0
k0C0
k0G0
r0C0
s0C0
t0C0
r0G0
s0G0
t0G0
u0A0
u0C0
u0G0
u0I0
F0I0
h0A0
i0A0
h0C0
i0C0
h0E0
i0E0
h0G0
i0G0
h0I0
i0I0
c0p0
c0s0
c0v0
c0y0
c0|0
c0s0
c0s0C0
c0s0
c0s0G0
c0s0
c0a0
c0a0
c0a0C0
c0a0
c0a0G0
c0a0
c0`0
c0b0
c0e0
c0g0
c0i0
c0g0
c0g0C0
c0g0
c0g0G0
c0g0
c0i0A0
c0i0C0
c0i0E0
c0i0G0
c0i0I0
c0b0
c0b0C0
c0b0
c0b0G0
c0b0
c0u0
c0u0
c0u0C0
c0u0
c0u0G0
c0u0
c0L0
c0N0
c0P0
c0R0
c0T0
c0P0A0
c0P0C0
c0P0E0
c0P0G0
c0P0I0
c0N0
c0N0C0
c0N0
c0N0G0
c0N0
c0o0
c0r0
c0x0
c0{0
c0u0A0
c0u0I0
c0r0
c0r0C0
c0r0
c0r0G0
c0r0
c0X0
c0X0
c0X0C0
c0X0
c0X0G0
c0X0
c0K0
c0M0
c0O0
c0Q0
c0S0
c0O0A0
c0O0C0
c0O0E0
c0O0G0
c0O0I0
c0M0
c0M0C0
c0M0
c0M0G0
c0M0
c0~0
c0q0
c0t0
c0w0
c0z0
c0}0
c0t0
c0t0C0
c0t0
c0t0G0
c0t0
c0O0
c0O0
c0O0
c0O0
c0U0
c0W0
c0Y0
c0[0
c0]0
c0W0
c0W0
c0W0G0
c0W0
c0W0C0
c0Y0A0
c0Y0C0
c0Y0E0
c0Y0G0
c0Y0I0
c0_0
c0d0
c0f0
c0h0
c0f0
c0f0C0
c0f0
c0f0G0
c0f0
c0d0A0
c0d0C0
c0d0G0
c0d0I0
c0h0A0
c0h0C0
c0h0E0
c0h0G0
c0h0I0
c0F0
c0F0C0
c0F0G0
c0F0I0
c0D0G0
c0V0
c0Z0
c0\0
c0^0
N(N?N6N[N
.(N,N6N7N?N@NANZN[N
["\n\
^P_Q_a_s_
_Lb4e5e5llp+r?r\r
uvv;y
(ub_
Kb0u4l
^\Sq\
e8\(gkp
zAS'Y-N
N(N?N6N
1OU*
z4lkpKN
](g'Y
SsYP[
NkQ]NAS]
NkQ]NAS]
NkQ]NAS
NkQ]NAS~vCS
0o0K0k0
0n0x0W0g0
1'1(1)1
1 1!1"1#1$1%1&1
4l!q
^y!q
P[t^
oSt^
HSt^
*gt^
3ut^
bt^
B0Y0
B0W0_0
B0U0c0f0
B0U0d0f0
W0B0U0c0f0
W0B0U0d0f0
0n0B0U0c0f0
0n0B0U0d0f0
0j0B0U0c0f0
0j0B0U0d0f0
T0B0U0c0f0
S0B0U0d0f0
M0n0F0
U0O0X0d0
U0O0W0d0
J0h0h0D0
D0c0U0O0X0d0
D0d0U0O0W0d0
0R0d0
0Q0d0
0D0R0d0
0D0Q0d0
0D0R0d0
0D0Q0d0
0R0d0
0Q0d0
0R0d0
0Q0d0
S0h0W0
0D0m0
0D0m0
U0O0m0
J0h0h0W0
D0c0U0O0m0
D0d0U0O0m0
U0M0J0h0h0W0
NkQ]NAS~vCS
j"k"
& & 
g0Y0
~0W0
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1%1
1'1 1
1'1!1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1"1
1'1%1
1(1"1
1(1#1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1"1
1(1#1
1(1%1
1 1
1!1
1"1
1$1
1%1
1'1
1'1
1'1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1(1
1(1
1(1"1
1(1#1
1(1%1
1)1
1)1
1)1"1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1'1 1
1'1!1
1'1"1
1'1#1
1'1$1
1'1%1
1)1"1
1)1#1
1)1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1%1
1(1"1
1(1#1
1(1$1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
1(1"1
1(1#1
1(1%1
'1 1
'1!1
'1"1
'1#1
'1$1
'1%1
(1"1
(1#1
(1$1
(1%1
)1"1
)1#1
)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1'1 1
1'1 1
1'1 1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1"1
1'1"1
1'1"1
1'1"1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1 1
1 1
1 1
1 1
1 1
1!1
1!1
1!1
1!1
1!1
1"1
1"1
1"1
1$1
1$1
1$1
1$1
1$1
1%1
1%1
1%1
1%1
1%1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1)1
1)1
1)1
1)1
1)1
1)1"1
1)1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1'1 1
1'1 1
1'1 1
1'1 1
1'1!1
1'1!1
1'1!1
1'1"1
1'1"1
1'1"1
1'1"1
1'1"1
1'1#1
1'1#1
1'1#1
1'1#1
1'1#1
1'1$1
1'1$1
1'1$1
1'1$1
1'1%1
1'1%1
1'1%1
1'1%1
1'1%1
1)1"1
1)1"1
1)1"1
1)1"1
1)1#1
1)1#1
1)1#1
1)1#1
1)1%1
1)1%1
1)1%1
1)1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1$1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1$1
1(1$1
1(1$1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1"1
1(1"1
1(1"1
1(1"1
1(1#1
1(1#1
1(1#1
1(1#1
1(1%1
1(1%1
1(1%1
1(1%1
1(1%1
'1 1
'1 1
'1 1
'1 1
'1 1
'1!1
'1!1
'1!1
'1!1
'1!1
'1"1
'1"1
'1"1
'1"1
'1"1
'1#1
'1#1
'1#1
'1#1
'1#1
'1$1
'1$1
'1$1
'1$1
'1$1
'1%1
'1%1
'1%1
'1%1
'1%1
(1"1
(1"1
(1"1
(1"1
(1#1
(1#1
(1#1
(1#1
(1#1
(1$1
(1$1
(1$1
(1$1
(1$1
(1%1
(1%1
(1%1
(1%1
)1"1
)1"1
)1"1
)1"1
)1#1
)1#1
)1#1
)1#1
)1#1
)1%1
)1%1
)1%1
)1%1
)1%1
rangeOfCharacterFromSet:options:
dictionaryWithContentsOfURL:
arrayWithObjects:count:
containsObject:
removeAllObjects
length
substringToIndex:
autorelease
stringByReplacingOccurrencesOfString:withString:
hasSuffix:
stringByAppendingString:
addObject:
alloc
initWithCandidate:
release
countByEnumeratingWithState:objects:count:
count
objectAtIndex:
rangeOfString:
rangeOfCharacterFromSet:
copy
characterAtIndex:
rawConversionCandidate
characterSetWithCharactersInString:
addCharactersInRange:
retain
initWithBytes:length:encoding:
init
classNamed:
autocorrectionContextOfType:
reset
addInputCharacter:geometryModel:geometryData:
prefixes
replacementString
stringWithCharacters:length:
type
surface
isEmojiCandidate
dictionaryReading
isConversionCandidate
rawCandidate
addObjectsFromArray:
substringFromIndex:
stringWithFormat:
hasPrefix:
rangeOfString:options:range:
stringByReplacingOccurrencesOfString:withString:options:range:
substringWithRange:
isEqualToString:
componentsSeparatedByCharactersInSet:
shortValue
objectForKey:
integerValue
numberWithInteger:
setObject:forKey:
keysSortedByValueUsingComparator:
UTF8String
stringWithCString:encoding:
dictionaryWithContentsOfFile:
boolValue
description
stringWithUTF8String:
componentsSeparatedByString:
intValue
dictionaryWithObject:forKey:
setValue:forKey:
array
enumerateSubstringsInRange:options:usingBlock:
initWithObjects:forKeys:
objectForKeyedSubscript:
appendString:
analysisString
indexSet
addIndex:
enumerateIndexesUsingBlock:
dictionary
matchedLengthType
numberWithUnsignedLong:
compare:
allKeys
sortedArrayUsingComparator:
unsignedLongValue
setYear:
setMonth:
setDay:
currentCalendar
dateFromComponents:
date
precomposedStringWithCompatibilityMapping
lowercaseString
uppercaseString
weight
firstObject
sortUsingFunction:context:
keyEnumerator
removeObjectsForKeys:
initWithCharacters:length:
kind
removeIndex:
initWithPattern:options:error:
matchesInString:options:range:
numberOfRanges
rangeAtIndex:
getCharacters:range:
setDisplayString:
attributes
convertedAnalysisString
isPersonName
isExtensionCandidate
isLearningDictionaryCandidate
isUserWordCandidate
isPredictionCandidate
isFuzzyMatchCandidate
isAutocorrectedCandidate
isOTAWordlistCandidate
isRegionalCandidate
phraseBoundaryAfterWordAtIndex:
wordCount
wordLengthAtIndex:
wordReadingLengthAtIndex:
wordDictionaryReadingLengthAtIndex:
wordIsFromSystemDictionaryAtIndex:
copySyllableLengthArrayForWordAtIndex:
lcAttrAtIndex:
rcAttrAtIndex:
trieValueAtIndex:
lastPrefixValue
matchType
copySyllableLengthArrayInAnalysisString
copySyllableLengthArrayInConvertedAnalysisString
copySyllableLengthArrayInDictionaryReading
wordRangeAtIndex:
initWithString:language:
valueForKey:
sortedRadicalList
arrayWithContentsOfFile:
punctuationCharacterSet
mutableCopy
whitespaceAndNewlineCharacterSet
formUnionWithCharacterSet:
symbolCharacterSet
initWithContentsOfFile:
allValues
objectAtIndexedSubscript:
arrayWithArray:
exchangeObjectAtIndex:withObjectAtIndex:
path
defaultManager
moveItemAtPath:toPath:error:
localeWithLocaleIdentifier:
calendarWithIdentifier:
setLocale:
setFormatterBehavior:
setTimeStyle:
dictionaryWithObjects:forKeys:count:
month
year
arrayWithCapacity:
dateByAddingComponents:toDate:options:
setCalendar:
setDateFormat:
stringFromDate:
setDateStyle:
component:fromDate:
informationDictionaryAtPath:
initWithContentsOfURL:
firstCharacter
characterInformationDictionary
searchResultsForString:dictionary:
codeLookupInformationDictionary
language
componentsByLanguage:
pinyinStringFromPinyinWithToneNumber
zhuyinSyllableFromPinyinSyllable
setWithCapacity:
rangeOfComposedCharacterSequenceAtIndex:
stringByStrippingDiacritics
allObjects
toneFromPinyinSyllableWithNumber
dealloc
codeLookupInformation
separatedInputCodesForString:
strokeStringFromNumberString
numberWithBool:
characterInformation
radicalInformationForString:
strokeInformationForString:
pinyinInformationForString:
zhuyinInformationForString:
initialsForStrings:
tonesForString:
wubixingCodes
bihuaCodes
cangjieCodes
isIncludedInCurrentLanguage
setAnalysisString:
setCharacterInformation:
setCodeLookupInformation:
isEmoji
setEmoji:
setLanguage:
_analysisString
_characterInformation
_codeLookupInformation
_emoji
_language
respondsToSelector:
standardUserDefaults
boolForKey:
stringForKey:
removeItemAtURL:error:
fileExistsAtPath:
integerForKey:
stringByStandardizingPath
bundleWithPath:
initWithObjects:
decimalDigitCharacterSet
rangeOfCharacterFromSet:options:range:
characterSetWithRange:
newlineCharacterSet
whitespaceCharacterSet
invertedSet
_fastCharacterContents
autoupdatingCurrentLocale
stringByTrimmingCharactersInSet:
emojiLocaleDataWithLocaleIdentifier:
emojiTokenWithString:localeData:
sharedServiceWithMachName:
dispatchQueue
preferences
didUseEmoji:
writeEmojiDefaults
supportsSkinToneVariants
lastUsedVariantEmojiForEmoji:
string
resetEmojiDefaults
recentEmojis
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
invoke
getReturnValue:
indexSetWithIndexesInRange:
insertObjects:atIndexes:
allocWithZone:
syllablesInAnalysisString
componentsJoinedByString:
syllablesInConvertedAnalysisString
syllablesInDictionaryReading
unsignedIntegerValue
syllablesInString:syllableLengths:
numberWithUnsignedInt:
syntheticCandidateFromWords:withLexicon:language:
copyWithZone:
isSyntheticCandidate
category
convertedAnalysisStringForFirstSyllable
isEqual:
syllabifiedAnalysisString
syllabifiedConvertedAnalysisString
syllabifiedDictionaryReading
words
wordReadings
wordIDs
setWeight:
_rawCandidate
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
numberWithUnsignedInteger:
initWithObjects:forKeys:count:
insertString:atIndex:
stringByReplacingCharactersInRange:withString:
callStackSymbols
compare:options:range:locale:
stringByApplyingPinyinToneMarkToFirstSyllableWithToneNumber:
appendFormat:
simplifiedChineseCompare:
traditionalChinesePinyinCompare:
traditionalChineseZhuyinCompare:
initWithLocaleIdentifier:
sharedInstanceForType:
requiredKeys
indexOfObject:
managedObjectContext
searchResultsWithValueDictionary:managedObjectContext:sortDescriptors:
entityDescriptionForContext:
setReturnsObjectsAsFaults:
setEntity:
setSortDescriptors:
class
isKindOfClass:
stringValue
predicateWithFormat:
andPredicateWithSubpredicates:
setPredicate:
executeFetchRequest:error:
dictionaryEntryHasAllRequiredKeys:
entityModelName
insertNewObjectForEntityForName:inManagedObjectContext:
isLogging
dictionaryValueFromManagedObject:
logEntry:operationType:extraInformation:
performBlockAndWait:
deleteAllMatchingEntries:
deleteObject:
localInfoPlistURL
prepareURLForDatabaseFile:
writeToURL:atomically:
entity
attributesByName
null
save
uniqueKeys
sortDescriptors
removeDuplicatesForEntry:uniquingKeys:sortDescriptors:restrictToNumberOfElements:identifierKey:
save:
logMessage:
searchResultsWithValueDictionary:
searchResultsWithValueDictionary:sortDescriptors:
addEntry:
deleteEntry:
deleteAllElements
setValue:forKey:entry:
setDatabaseProperty:forKey:
databasePropertyForKey:
dictionaryValuesFromManagedObjects:
setValuesForEntry:uniquingKeys:
initWithType:URL:
defaultCenter
postNotificationName:object:
removeObserver:
localURL
fileURLWithPathComponents:
databaseName
initWithManagedObjectModel:
addPersistentStoreWithType:configuration:URL:options:error:
databaseSyncs
entityDescriptionURL
URLByDeletingLastPathComponent
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
localStoreURL
ubiquityContainerIdentifier
managedObjectModel
newPersistentStoreWithURL:ubiquityContainerIdentifier:managedObjectModel:
sendRemoteNotification
persistentStoreCoordinator
initWithConcurrencyType:
setPersistentStoreCoordinator:
setMergePolicy:
entityForName:inManagedObjectContext:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
lastPathComponent
removePersistentStore:error:
storedElementsForMerge
setStoredElementsForMerge:
userInfo
resetDatabaseWithType:URL:
shouldSyncDatabase
locallyPresentUbiquitousFiles
stripUbiquitousInformationFromStore:
entriesFromStrippedStoreURL:
coreDataUbiquityFolderURLforStore:
entriesToMerge
clearStoredMergeEntries
entityDescription
setLocalURL:
setManagedObjectModel:
setManagedObjectContext:
storeURL
setStoreURL:
setType:
_entityDescription
_localURL
_localURLLastPartOfName
_managedObjectModel
_managedObjectContext
_persistentStoreCoordinator
_storeURL
_type
_storedElementsForMerge
initWithIdentifier:
descriptionDictionary
fileURLWithPath:
sortDescriptorWithKey:ascending:
URLForUbiquityContainerIdentifier:
ubiquitousURLWithSuffix:
setDefaultDescriptionPath:
defaultDescriptionPath
ubiquityContainerURL
ubiquitousStoreDirectoryURLForIdentifier:
ubiquitousTransactionURLForIdentifier:
forceNoSync
setDescriptionDictionary:
_descriptionDictionary
initWithContentsOfFile:encoding:error:
getCString:maxLength:encoding:
removeObjectAtIndex:
removeObjectsAtIndexes:
firstIndex
sortUsingComparator:
setObject:atIndexedSubscript:
insertObject:atIndex:
reverseObjectEnumerator
removeLastObject
fileURLWithPath:isDirectory:
stringWithContentsOfFile:usedEncoding:error:
getLineStart:end:contentsEnd:forRange:
dataUsingEncoding:
arrayWithObjects:
numberWithShort:
dictionaryWithObjects:forKeys:
removeObjectsInRange:
stringWithCapacity:
subarrayWithRange:
initWithArray:
removeObject:
writeToFile:atomically:
isEqualToArray:
indexSetWithIndex:
arrayWithObject:
containsIndex:
range
getCharacters:
setValidSequenceCorrectionThreshold:
completions
correction
guesses
removedModifications
addedModifications
modificationType
syllableRange
modificationScore
additionalSyllableRange
removeItemAtPath:error:
initWithString:category:
copyFacemarkCandidatesForLanguage:
candidateWithString:category:
copyFacemarkCandidatesForLocale:
_string
_category
characterIsMember:
stringWithContentsOfFile:encoding:error:
Creating Montreal model with identifier [%s]
getSharedMontrealLanguageModel
[getSharedMontrealLanguageModel] Actually creating Montreal model with identifier [%s]
Load resource with key: [%s]
SingletonResourceManagerLoad
Still waiting for resource [%s] to complete in background.
Async resource load with key: [%s]
AsyncResourceInit
[EmojiPredictor::setDictionary] Loading %@ (%s)
[JADM::setAdditionalConversionDictionaries] #dictionary:%ld
[JADM::setAdditionalConversionDictionaries] - %ld: %@
[JADM::setAdditionalConversionDictionaries] adding dictionary %@
[JADM::setAdditionalConversionDictionaries] setting zip code dictionary path to: %@
[TSC::generateReplacements] string:%@ converted:%@ correction:%d
[TaggerImpl::parseNBestInit] length:%lu (prefix:%d)
[TokenizerImpl::lookup] %s
[TokenizerImpl::lookupOneWord] Input:[%s]
[TI::set_additional_dictionaries] %s has been added with ID %d.
[TokenizerImpl::set_additional_dictionaries] Failed to open %s: %s
[TokenizerImpl::getMinimumCost]
[Viterbi::clear] clearning node_freelist and path_freelist
[Viterbi::reset_mempool] resetting path_freelist
MecabraJapanese engine init
MecabraJapaneseInit
Open MecabraJapanese engine
MecabraJapaneseOpen
Failed
Mecabra Japanese initialized.
Mecabra Japanese terminated.
Pruning %@ (n-gram expansion final)
[MJ::makeMecabSingleWordCandidates] Searching single-word %s candidates for [%@] with option: 0x%.6X
Partial phrase: %@ (weight: %ld)
[MJ::makeLastBunsetsuCandidatesFromCurrentLattice]
[MJ::makeMecabMultiWordCandidates] analysisString:%@ (prefix:%d)
[MJ::makeMecabPartialCandidate]
[%s] CandidateStabilizer didn't stabilize
[MJ::predict] prediction:%d acceptedCandidate:%p
[MJ:searchPhrasesByPosContext] Considering POS context (%d, %d) for %@ with additional cost %d
Failed to retrieve system dictionary path.
Failed to retrieve settings file path.
Failed to open Mecabra engine. (System dictionary directory: %@)
Failed to retrieve POS prediction dictionary path.
Failed to register an immutable dynamic dictionary.
Failed to register a mutable dynamic dictionary.
Failed to retrieve static LM path
No static LM found at %@
Failed to retrieve word cache file path.
[MJ::createCandidateFromContextString] string:%@|%@ isRightContext:%d allowSynthetic:%d
[MJ::createCandidateFromContextString] 
mergedString:%@
[MJ::createCandidateFromContextString] Reverse-analyzing %@
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning a synthetic candidate with an empty analysis string.
[MJ::createCandidateFromContextString] Reverse-analysis from %@ failed. Returning nil.
Pruning %@ (excessive learning candidates)
Pruning %@ (post-processing)
[MJ::assetDictionariesDidChange]
[MJ::assetDictionariesDidChange] setting additional dictionary %s
[MJ::updateAssetDictionaryManager]
[MecabraCreate]
Input method: %d
Failed for input method: %d
MecabraCreate
[MecabraAnalyzeString] mecabra:%p string:%@
[MecabraAnalyzeStringWithGeometryModel] mecabra:%p string:%@
[MecabraAnalyzeStringWithGeometryModelAndContext] mecabra:%p string:%@
[MecabraAnalyzeStringWithContext] mecabra:%p string:%@ options:0x%lx (L-context:%s I-context:%s)
MecabraAnalyzeStringWithContext
[MecabraDeclareEndOfSentence] mecabra:%p context:%p
[MecabraAcceptInlineCandidates] mecabra:%p context:%p candidates:%s
[MecabraRevertLearningForCandidate] mecabra:%p context:%p candidate:%@
[MecabraCancelAnalysis] mecabra:%p
[MecabraAcceptCandidate] mecabra:%p candidate.surface:%@ isPartial%d
[MecabraCancelLastAcceptedCandidate] mecabra:%p
[MecabraSetAdditionalConversionDictionaries] mecabra:%p
[MecabraSetAssetDataItemsForType] mecabra:%p type:%ld
[MecabraSaveLearningDictionaries] mecabra:%p
[MecabraClearLearningDictionaries] mecabra:%p
[MecabraResetLearningDictionaries] learningDictionaryDirectory:%@
[MecabraWaitForAsyncDataLoading] inputMethod: %u
[MecabraSetAddressBookNamePhoneticPairs] mecabra:%p size:%ld
Address book reset (%ld items).
SetAddressBook
[MecabraSetUserWordKeyPairs] mecabra:%p size:%ld
User word reset (%ld items).
SetUserWord
[MecabraPreheatResources] mecabra:%p
MecabraPreheatResources
[MecabraHandleMemoryPressure] mecabra:%p level:%uld, excessMemoryInBytes:%ld
level: %d, excessMemoryInBytes: %ld
MecabraHandleMemoryPressure
[MecabraRelease] mecabra:%p
MecabraPredictionAnalyzeWithContext
[MecabraCreateCandidateFromContextString] mecabra:%p string:[%@] isRightContext:%d
Reset (%ld) fuzzy pairs.
MecabraSetFuzzyPinyinPairs
[MecabraFlushDynamicData] mecabra:%p
[MecabraPerformMaintenance] mecabra:%p
[MecabraSpecialtyDictionaryCreateWithEntries] entries:%p
[MecabraSpecialtyDictionaryGetData] dictionary:%p
[MecabraSpecialtyDictionaryCreateWithData] dictionaryData:%p
[MecabraAddSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraRemoveSpecialtyDictionary] mecabra:%p dictionary:%p
[MecabraSpecialtyDictionaryEnumerateEntries] dictionary:%p
[MecabraSpecialtyDictionaryRelease] dictionary:%p
[MecabraAdaptToTokenizedText] mecabra:%p
[MecabraAdaptToTokenizedTextWithEffectiveTime] mecabra:%p
[MecabraAdaptToUntokenizedText] mecabra:%p
[MecabraSetDynamicLanguageModelAppContext] %@ (mecabra:%p)
Open file %s failed: %s
[Mecabra] Set region lexicon: %@
[Mecabra] Set Non-regional assets: %@
Corruption of learning dictionary detected. Database has been reset: %s
curSize: %d, rebuildThreshold: %d, newSize: %d
LearningDictionaryRebuild
Data in learning dictionary trie is corrupted.
[%s] reset best analysis for short input
[%s] update best analysis from previous best analysis (segment gap: %zu)
[%s] update best analysis based on truncated candidate
[%s] reset best analysis for unaligned truncated candidate
[%s] updating best analysis from history: %@
[%s] updating best analysis from converted analysis string
[%s] compound noun found, returning best segments
[%s] best-analysis:%d top-analysis:%d threshold:%d
[%s] using %@ segments as reference
[%s] segment[%zu]: from %@ segments
[%s] ignoring top segment
[%s] best analysis(%d) has a much lower weight than  top analysis(%d), using best segment
[%s] endingWithPunctuation:%d
[%s] %@
[%s] raw analysis string: %@
[%s] Temporary Roman mode
[%s] candidate has a punctuation, using best analysis
[%s] there is incomplete romaji and best analysis (weight:%d) can be trusted over top candidate(weight:%d) when truncated input is %s
[%s] %s: %s
[%s] topSegment:%d, bestSegment:%d, threshold:%d
[%s] top candidate: %@ (%ld) prefix katakana length: %zu
[%s] top candidate (updated): %@ (%ld) prefix katakana length: %zu
[%s] second top candidate: %@ (%ld) prefix katakana length: %zu
[%s] Katakana common prefix: %d, threshold: %ld
[%s] top segment is not reliable, but using the common katakana part
[%s] top segment is not reliable
[%s] ignoring best segment since it's a prefix segment
[%s] bestLBCandidate(weight:%d) %@, topLBCandidate(weight:%d) %@, threshold: %d
[%s] using exact top segment
[%s] using the katakana part (len:%zu) of top segment (prefix matched)
[%s] using best segment
[%s] using partial candidate
[%s] expanding the last segment to hiragana string
[MecabraEngine::analyzeString] analysisStr: [%@]
[ME::acceptCandidate] S:%@ isPartial:%d performLearning:%d
Open MecabraEngine with input method: %d
MecabraEngineOpen
[ME::convert] [%@]
[ME:removeTruncatedContextFromCandidates] Converting %@ (%@/%@) to %@ (%@/%@)
%s (%ld): [%@] (%@/%@), type: %c, length: %s, cost: %d, base-cost: %d, prob: %3.3lf, penalty: %d autocorrected: %d
Candidates: [Left: %@] [Inline: %@] [Right: %@]
App Context: %@
Text Content Type: %d
Shuangpin Type: %d
[MecabraLearner::acceptCandidate] %@ isPartial:%d performLearning:%d isOTAWordlist:%d
[MecabraLearner::resetInternalState]
[MecabraLearner::actuallyAcceptCandidate] S:[%@] isPartial:%d performLearning:%d
[MecabraLearner::actuallyAcceptCandidate] adding %@ to partial candidates (total count: %lu)
[MecabraLearner::flushAcceptedCandidate] S:%@ performLearning:%d shouldLearn:%d
[MecabraLearner::registerCandidate] AS:%@ DR:%@ S:%@ isPartial:%d
Begin init for learner type [%d] at [%@]
SeaweedChineseLearner
[MJL::registerToLearningDictionary] Learning phrase %@ (%@)
[MJL::registerToLearningDictionary] Learning dynamic word %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a phrase sequence: %@ (%@)
[MJL::combinePartialCandidatesAndRegister] Registering as a single phrase: %@ (%@)
[MJL::addBigramEntryIntoLearningDictionary] Registering phrase bigram %@ -> %@ %@
[MJL::incrementUsageCount] %@ (%@/%@) type:%@ contextWordCount:%ld
[MJL::incrementUsageCount] %@
[MJL::incrementUsageCount] Registering a dynamic token %@ %@ with ID %u
[MJL::incrementUsageCount] Incrementing usage counts for %@ (probability: %lf -> %lf)
[MJL::registerPhraseSequence] S:%@ AS:%@ DR:%@ phraseSize:%lu skipPhraseCount:%lu performLexicalLearning:%d->%d shouldLearnBigram:%d
Migrating %s %s %u %u (%u,%u,%u..).
Migrating %s => %s %s %u %u (%u,%u,%u..).
[JLPL::loadLexicalRules] Loading %@ (%s)
[registerNonLexicalEntry] Registering non-lexical preference %@ = %d
[LPL::registerLexicalEntry] Registering lexical rule: %@ => %@ (P0:%hu L2:[%@](%d) L1:[%@](%d) R1:[%@](%d) R2:[%@](%d))
[LPL::matchFeature] Comparing ( %s) with ( %s)
[LPL::applyLexicalRules] Rewriting %@ (%@) => %@
[LPL::applyLexicalPreferences] %@ (%@) => %@ (lc:%d rc:%d f-lc:%d f-rc:%d)
expandTokenSequence: %@ %@ is blacklisted.
[MJNP::getAndCheckContextSurfaceAndReadingFromCandidate] %@ %@ is an invalid context word.
getAndCheckContextSurfaceAndReadingFromHistory: %@ %@ (attr: %d) is an invalid context word.
Pruning %@ (n-gram expansion)
makeCandidateFromExpandedSequence: matching inputStr:%@ predictedReading:%@ matchResult:%d incompleteLength:%ld
LookupController init with input method [%d].
LookupControllerInit
[Mecabra] Reloading syllable LM
## Sorted ##
index: %lu, surface: %@, cost: %ld, dynamic-score: %lf, static-score: %lf
Pruning %@ (kind:%c) (after reranking)
[Mecabra] Fail to load syllable LM
[Mecabra] Load syllable LM successfully
Word history %ld: [%s] [%s] (lc:%d rc:%d)
Search depth is beyond limit. May not return all expected results.
Reload for LMLoader
LanguageModelLoaderReload
[Mecabra] Reset language model
Failed to find data path for locale %s
[MecabraContextCreateMutable]
[MecabraContextRelease] context:%p
[MecabraContextSetShuangpinType] context:%p type:%d
Dynamic LM word (%u, %@, %@) loaded.
MecabraWordProperties
MecabraCandidate
NSCopying
CharacterInformationAdditions
Access
MecabraCoreDataController
MecabraCoreDataProperties
MecabraFacemarkCandidate
^{__IDXIndex=}24@0:8^{__CFURL=}16
^{__IDXIndex=}16@0:8
@32@0:8@16^{__IDXIndex=}24
@16@0:8
@24@0:8@16
@28@0:8@16i24
v16@0:8
@20@0:8i16
v24@0:8@16
B16@0:8
v20@0:8B16
i16@0:8
v20@0:8i16
@"NSString"
@"NSArray"
@36@0:8@16^{Lexicon=^v^v}24i32
@24@0:8^{_NSZone=}16
^{MecabraCandidateBase=^^?q}16@0:8
B24@0:8^{__CFString=}16
Q16@0:8
S24@0:8Q16
{?=qq}24@0:8q16
q24@0:8q16
B24@0:8Q16
^{__CFArray=}24@0:8Q16
Q24@0:8Q16
S16@0:8
q16@0:8
^{__CFArray=}16@0:8
@24@0:8^{MecabraCandidateBase=^^?q}16
^{ConversionCandidate=^^?q}16@0:8
B24@0:8@16
@32@0:8@16@24
v24@0:8Q16
@24@0:8Q16
q24@0:8@16
@40@0:8@16@24@32
v40@0:8@16@24@32
v32@0:8@16@24
@56@0:8@16@24@32Q40@48
@"NSEntityDescription"
@"NSURL"
@"NSManagedObjectModel"
@"NSManagedObjectContext"
@"NSPersistentStoreCoordinator"
@"NSMutableDictionary"
###########################################
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
a000
e000 i000!o000"u000#v000$on00%io00&ion0've00(van0)vn00*
zh00
sh00
ch00
ing0
ai00
an00
ang0
ao00
ei00
en00
eng0
ia00ian0
iang
iao0
ie00
in00
iu00
ong0
ou00
ua00
uai0
uan0
ue00
un00
ui00
uo00
uang
er00
iong
van0
ve00 a000
e000"i000#o000$u000%v000&on00'io00(ion0)
