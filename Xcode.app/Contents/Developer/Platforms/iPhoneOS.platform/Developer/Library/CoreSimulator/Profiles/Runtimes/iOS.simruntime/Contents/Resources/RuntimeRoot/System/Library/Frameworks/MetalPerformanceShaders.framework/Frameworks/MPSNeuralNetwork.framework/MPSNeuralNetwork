initWithDevice:
class
primarySourceMatrixOrigin
secondarySourceMatrixOrigin
resultMatrixOrigin
dataType
matrices
columns
rows
vectors
copyWithZone:device:
initWithCoder:device:
release
decodeDoubleForKey:
decodeInt64ForKey:
encodeWithCoder:
encodeDouble:forKey:
encodeInt64:forKey:
libraryInfo
encodeGradientForDataToCommandBuffer:gradientMatrix:weightMatrix:resultGradientForDataMatrix:
encodeGradientForWeightsAndBiasToCommandBuffer:gradientMatrix:inputMatrix:resultGradientForWeightMatrix:resultGradientForBiasVector:
sourceNumberOfFeatureVectors
setSourceNumberOfFeatureVectors:
sourceInputFeatureChannels
setSourceInputFeatureChannels:
sourceOutputFeatureChannels
setSourceOutputFeatureChannels:
alpha
setAlpha:
_sourceNumberOfFeatureVectors
_sourceInputFeatureChannels
_sourceOutputFeatureChannels
_alpha
setConstantValue:type:atIndex:
newFunctionWithName:constantValues:completionHandler:
computeCommandEncoderWithDispatchType:
stringWithFormat:
stringByAppendingString:
setLabel:
rowBytes
maxTotalThreadsPerThreadgroup
setComputePipelineState:
data
setBuffer:offset:atIndex:
setBytes:length:atIndex:
dispatchThreadgroups:threadsPerThreadgroup:
endEncoding
debugDescription
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:
setWidth:
setHeight:
setFeatureChannels:
_reshapedWidth
_reshapedHeight
_reshapedFeatureChannels
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset:
objectAtIndexedSubscript:
width
height
featureChannels
initWithResource:
temporaryStateWithCommandBuffer:
dealloc
_fwdPadBefore
_fwdPadAfter
_srcImgFcCount
initWithDevice:paddingSizeBefore:paddingSizeAfter:fillValueArray:
length
newBufferWithLength:options:
contents
bytes
decodeFloatForKey:
encodeFloat:forKey:
destinationImageDescriptorForSourceImages:sourceStates:
offset
setOffset:
copyToGradientState:sourceImage:sourceStates:destinationImage:
initWithDevice:paddingSizeBefore:paddingSizeAfter:
isResultStateReusedAcrossBatch
resultStateForSourceImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:
paddingSizeBefore
setPaddingSizeBefore:
paddingSizeAfter
setPaddingSizeAfter:
fillValue
setFillValue:
_aBuf
_aBufFP32Len
_fillValue
_paddingSizeBefore
_paddingSizeAfter
isEqual:
arrayLength
setTexture:atIndex:
setSamplerState:atIndex:
setThreadgroupMemoryLength:atIndex:
retain
decodeBoolForKey:
newBufferWithBytes:length:options:
alloc
initWithFormat:
decodeBytesForKey:returnedLength:
encodeBool:forKey:
encodeBytes:length:forKey:
autorelease
sourceFeatureChannelMaxCount
numberOfImages
retainedReferences
addCompletedHandler:
maxThreadsPerThreadgroup
count
getObjects:range:
setTextures:withRange:
isKindOfClass:
primarySourceFeatureChannelMaxCount
initWithDevice:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
initWithDevice:kernelWidth:kernelHeight:
setKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
maxBatchSize
sourceSize
setSourceSize:
_sourceSize
zeroPadSizeX
setZeroPadSizeX:
zeroPadSizeY
setZeroPadSizeY:
_zeroPadSizeX
_zeroPadSizeY
initWithDevice:kernelWidth:kernelHeight:dilationRateX:dilationRateY:strideInPixelsX:strideInPixelsY:
newTextureViewWithPixelFormat:textureType:levels:slices:
threadExecutionWidth
resourceCount
init
_resourcePixelFormat
_resourceSize
textureType
setTextureType:
setPixelFormat:
setArrayLength:
initWithDevice:textureDescriptor:
temporaryStateWithCommandBuffer:textureDescriptor:
copyToBinaryGradientState:primaryImage:secondaryImage:sourceStates:destinationImage:
pixelFormat
privateResultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:commandBuffer:isTemporary:
primarySourceFeatureChannelOffset
secondarySourceFeatureChannelOffset
secondarySourceFeatureChannelMaxCount
encodeToCommandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
setPrimaryStrideInPixelsX:
setPrimaryStrideInPixelsY:
setPrimaryStrideInFeatureChannels:
setSecondaryStrideInPixelsX:
setSecondaryStrideInPixelsY:
setSecondaryStrideInFeatureChannels:
initWithDevice:arithmeticType:
resultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationImages:
primaryScale
setPrimaryScale:
secondaryScale
setSecondaryScale:
bias
setBias:
minimumValue
setMinimumValue:
maximumValue
setMaximumValue:
primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
_primaryScale
_secondaryScale
_bias
_minimumValue
_maximumValue
_primaryStrideInFeatureChannels
_secondaryStrideInFeatureChannels
_arithmeticType
comparisonType
setComparisonType:
threshold
setThreshold:
_threshold
_comparisonType
initWithDevice:arithmeticType:isSecondarySourceFilter:
isSecondarySourceFilter
_isSecondarySourceFilter
_reduceRows
_reduceColumns
_reduceFeatureChannels
initWithDevice:isSecondarySourceFilter:
primaryStrideInPixelsX
primaryStrideInPixelsY
secondaryStrideInPixelsX
secondaryStrideInPixelsY
initWithTexture:featureChannels:
texture
imageDescriptorWithChannelFormat:width:height:featureChannels:numberOfImages:usage:
pushDebugGroup:
popDebugGroup
temporaryImageWithCommandBuffer:imageDescriptor:
device
initWithDevice:imageDescriptor:
setReadCount:
getRecurrentOutputImageForLayerIndex:
getMemoryCellImageForLayerIndex:
initWithCommandBuffer:recurrentImageDescriptors:cellImageDescriptors:isTemporary:layerCount:
isTemporary
recurrentImages
cellImages
nLayers
_isTemporary
temporaryMatrixWithCommandBuffer:matrixDescriptor:
initWithBuffer:descriptor:
getRecurrentOutputMatrixForLayerIndex:
getMemoryCellMatrixForLayerIndex:
initWithCommandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
recurrentMatrices
cellMatrices
initForSingleGateWithCommandBuffer:matrixDescriptor:isTemporary:
singleGateZ
inputFeatureChannels
setInputFeatureChannels:
outputFeatureChannels
setOutputFeatureChannels:
inputTransform
setInputTransform:
outputTransform
setOutputTransform:
recurrentOutputTransform
setRecurrentOutputTransform:
useLayerInputUnitTransformMode
setUseLayerInputUnitTransformMode:
layerSequenceDirection
setLayerSequenceDirection:
useFloat32Weights
setUseFloat32Weights:
internalKernelSelector
setInternalKernelSelector:
_useLayerInputUnitTransformMode
_useFloat32Weights
_inputFeatureChannels
_outputFeatureChannels
_inputTransform
_outputTransform
_recurrentOutputTransform
_layerSequenceDirection
_internalKernelSelector
initWithInputFeatureChannels:outputFeatureChannels:
createRNNSingleGateDescriptorWithInputFeatureChannels:outputFeatureChannels:
inputWeights
setInputWeights:
recurrentWeights
setRecurrentWeights:
_inputWeights
_recurrentWeights
createLSTMDescriptorWithInputFeatureChannels:outputFeatureChannels:
memoryWeightsAreDiagonal
setMemoryWeightsAreDiagonal:
inputGateInputWeights
setInputGateInputWeights:
inputGateRecurrentWeights
setInputGateRecurrentWeights:
inputGateMemoryWeights
setInputGateMemoryWeights:
forgetGateInputWeights
setForgetGateInputWeights:
forgetGateRecurrentWeights
setForgetGateRecurrentWeights:
forgetGateMemoryWeights
setForgetGateMemoryWeights:
outputGateInputWeights
setOutputGateInputWeights:
outputGateRecurrentWeights
setOutputGateRecurrentWeights:
outputGateMemoryWeights
setOutputGateMemoryWeights:
cellGateInputWeights
setCellGateInputWeights:
cellGateRecurrentWeights
setCellGateRecurrentWeights:
cellGateMemoryWeights
setCellGateMemoryWeights:
cellToOutputNeuronType
setCellToOutputNeuronType:
cellToOutputNeuronParamA
setCellToOutputNeuronParamA:
cellToOutputNeuronParamB
setCellToOutputNeuronParamB:
cellToOutputNeuronParamC
setCellToOutputNeuronParamC:
cellClipThreshold
setCellClipThreshold:
coupleForgetGateToInputGate
setCoupleForgetGateToInputGate:
_memoryWeightsAreDiagonal
_coupleForgetGateToInputGate
_cellToOutputNeuronType
_cellToOutputNeuronParamA
_cellToOutputNeuronParamB
_cellToOutputNeuronParamC
_cellClipThreshold
_inputGateInputWeights
_inputGateRecurrentWeights
_inputGateMemoryWeights
_forgetGateInputWeights
_forgetGateRecurrentWeights
_forgetGateMemoryWeights
_outputGateInputWeights
_outputGateRecurrentWeights
_outputGateMemoryWeights
_cellGateInputWeights
_cellGateRecurrentWeights
_cellGateMemoryWeights
createGRUDescriptorWithInputFeatureChannels:outputFeatureChannels:
recurrentGateInputWeights
setRecurrentGateInputWeights:
recurrentGateRecurrentWeights
setRecurrentGateRecurrentWeights:
outputGateInputGateWeights
setOutputGateInputGateWeights:
gatePnormValue
setGatePnormValue:
flipOutputGates
setFlipOutputGates:
_flipOutputGates
_gatePnormValue
_recurrentGateInputWeights
_recurrentGateRecurrentWeights
_outputGateInputGateWeights
label
weights
biasTerms
copyWithZone:
initWithConvDescriptor:
allocWithZone:
initWithWeights:useBias:desc:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retainCount
zone
hash
superclass
description
descriptor
load
purge
rangesForUInt8Kernel
lookupTableForUInt8Kernel
weightsQuantizationType
updateWithCommandBuffer:gradientState:sourceState:
updateWithGradientState:sourceState:
_parentObj
_convDesc
_hasBias
setNeuronType:
setA:
setB:
setC:
clipRect
destinationFeatureChannelOffset
storeAllIntermediateStates
addObject:
initWithDevice:rnnDescriptor:
initWithDevice:rnnDescriptors:
encodeSequenceToCommandBuffer:sourceImages:destinationImages:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardImages:destinationBackwardImages:
numberOfLayers
recurrentOutputIsTemporary
setRecurrentOutputIsTemporary:
setStoreAllIntermediateStates:
bidirectionalCombineMode
setBidirectionalCombineMode:
layerTypes
layers
forwardLayers
forwardLayerTypes
nForwardLayers
backwardLayers
backwardLayerTypes
nBackwardLayers
_recurrentOutputIsTemporary
_storeAllIntermediateStates
_numberOfLayers
_bidirectionalCombineMode
initWithDevice:transposeLeft:transposeRight:resultRows:resultColumns:interiorColumns:alpha:beta:
encodeSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:recurrentInputState:recurrentOutputStates:
matrixDescriptorWithRows:columns:rowBytes:dataType:
encodeSequenceToCommandBuffer:sourceMatrices:destinationMatrices:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardMatrices:destinationBackwardMatrices:
gemmKernel
gemmKernelNonTranspose
encodeForwardSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:trainingStates:recurrentInputState:recurrentOutputStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:forwardSourceOffsets:sourceGradients:sourceGradientOffsets:destinationGradients:destinationOffsets:weightGradients:trainingStates:recurrentInputState:recurrentOutputStates:weights:
initWithDevice:rnnDescriptor:trainableWeights:
createWeightGradientMatrices:dataType:
createTemporaryWeightGradientMatrices:dataType:commandBuffer:
createWeightMatrices:
encodeCopyWeightsToCommandBuffer:weights:matrixId:matrix:copyFromWeightsToMatrix:matrixOffset:
encodeForwardSequenceToCommandBuffer:sourceMatrices:destinationMatrices:trainingStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:sourceGradients:destinationGradients:weightGradients:trainingStates:weights:
trainingStateIsTemporary
setTrainingStateIsTemporary:
accumulateWeightGradients
setAccumulateWeightGradients:
layerType
layer
gemmKernel_noAccumulate
gemmKernelNonTranspose_noAccumulate
gemmKernelTN
gemmKernelTN_accumulate
weightDescriptors
_trainingStateIsTemporary
_accumulateWeightGradients
imageDescriptorWithChannelFormat:width:height:featureChannels:
setNumberOfImages:
setChannelFormat:
setUsage:
setStorageMode:
setBuffers:offsets:withRange:
rowBytesForColumns:dataType:
setRows:
setK:
setN:
setM:
setResultMatrixOrigin:
encodeToCommandBuffer:encoder:leftMatrix:rightMatrix:resultMatrix:
setColumns:
setRowBytes:
setLeftMatrixOrigin:
setRightMatrixOrigin:
neuronInfo
lastObject
initWithDevice:weights:
decodeObjectForKey:
encodeObject:forKey:
arrayWithObjects:count:
initWithSourceImages:sourceStates:paddingPolicy:
initWithSource:transformProvider:outputSize:
nodeWithSource:transformProvider:outputSize:
nodeWithSource:outputSize:
privateInitWithSource:transformProvider:outputSize:
initWithSource:outputSize:
_transformProvider
_size
newFilterNode
initWithDevice:transformProvider:handle:outputSize:scaleClass:
setClipRect:
encodeInteger:forKey:
decodeIntegerForKey:
setOptions:
setEdgeMode:
transformForSourceImage:handle:
setScaleTransform:
_destSize
_filter
_handle
decodeObjectOfClass:forKey:
setDestinationFeatureChannelOffset:
setSourceFeatureChannelOffset:
setSourceFeatureChannelMaxCount:
padding
setDestinationImageAllocator:
setPadding:
encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
encodeToCommandBuffer:sourceImage:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImages:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:
cStringUsingEncoding:
sourceFeatureChannelOffset
imageForCommandBuffer:imageDescriptor:kernel:
arrayWithCapacity:
setObject:atIndexedSubscript:
imageBatchForCommandBuffer:imageDescriptor:kernel:count:
temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:
resultStateBatchForSourceImage:sourceStates:destinationImage:
encodeToCommandBuffer:sourceImages:destinationImage:
copyToGradientState:sourceImages:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImages:sourceStates:destinationImage:
initWithObjects:count:
resultStateForSourceImages:sourceStates:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImages:sourceStates:destinationImage:
resultStateBatchForSourceImages:sourceStates:destinationImage:
_sliceCount
_info
usage
initialize:convDesc:weights:dataType:fullyConnected:
initialize:weights:fullyConnected:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setGroups:
setStrideInPixelsX:
setStrideInPixelsY:
setDilationRateX:
setDilationRateY:
convolution
dataSource
PeakAtWeights:
initWithDevice:weights:fullyConnected:
reloadWeightsAndBiasesFromDataSource
reloadWeightsAndBiasesWithCommandBuffer:state:
biases
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
channelMultiplier
gradientOption
setGradientOption:
serializeWeightsAndBiases
setSerializeWeightsAndBiases:
_groups
_channelMultiplier
_gradientOption
_weights
_fullyConnected
_weightsDataType
_dataSource
_lock
_serializeWeightsAndBiases
initWithSource:
nodeWithSource:
gradientFilterWithSource:
clipRectSource
setClipRectSource:
_clipRectSource
gradientClass
initWithSourceGradient:sourceImage:gradientState:
initWithGradientImages:sourceImages:gradientState:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:
weight
setWeight:
_weight
encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationImages:
setPrimarySourceFeatureChannelOffset:
setPrimarySourceFeatureChannelMaxCount:
setSecondarySourceFeatureChannelOffset:
setSecondarySourceFeatureChannelMaxCount:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
destinationImageAllocator
temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
resultStateBatchForPrimaryImage:secondaryImage:sourceStates:destinationImage:
computeCommandEncoder
decodeInt32ForKey:
encodeInt32:forKey:
encodeToCommandBuffer:gradientMatrix:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultGradientForDataMatrix:resultGradientForGammaVector:resultGradientForBetaVector:
neuronType
neuronParameterA
neuronParameterB
neuronParameterC
setNeuronType:parameterA:parameterB:parameterC:
neuronA
setNeuronA:
neuronB
setNeuronB:
neuronC
setNeuronC:
epsilon
setEpsilon:
_neuronType
_neuronA
_neuronB
_neuronC
_epsilon
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
dataWithBytes:length:
maskData
_maskStrideInPixels
_keepProbability
setResourceOptions:
privateResultStateForSourceImage:sourceStates:destinationImage:commandBuffer:isTemporary:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
resetSeed:
initWithDevice:keepProbability:seed:maskStrideInPixels:
.cxx_destruct
.cxx_construct
keepProbability
seed
maskStrideInPixels
_seed
_engine
_engineMutex
_arithmetic
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
setPrimaryEdgeMode:
setSecondaryEdgeMode:
initWithCapacity:
replaceObjectAtIndex:withObject:
paddingWithMethod:
scaleFactorX
scaleFactorY
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:alignCorners:
alignCorners
_filterType
_scaleFactorX
_scaleFactorY
_alignCorners
initWithDevice:integerScaleFactorX:integerScaleFactorY:
initWithDevice:integerScaleFactorX:integerScaleFactorY:alignCorners:
maxTextureWidth2D
maxTextureHeight2D
paddingMethod
primaryOffset
secondaryOffset
setPrimaryOffset:
setSecondaryOffset:
destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:
resultStateForPrimaryImage:secondaryImage:sourceStates:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:
readGradientState:
readBinaryGradientState:isSecondarySourceFilter:
isStateModified
kernelOffsetX
setKernelOffsetX:
kernelOffsetY
setKernelOffsetY:
_kernelOffsetX
_kernelOffsetY
nodeWithSource:a:
nodeWithSource:a:b:
nodeWithSource:aData:
nodeWithSource:a:b:c:
cnnNeuronDescriptorWithType:a:b:c:
nodeWithSource:descriptor:
initWithSource:type:a:b:c:
_type
cnnNeuronPReLUDescriptorWithData:noCopy:
initWithDevice:neuronDescriptor:
initWithSource:a:
initWithSource:a:b:
initWithSource:aData:
_aData
initWithSource:a:b:c:
initWithSourceGradient:sourceImage:gradientState:descriptor:
initWithGradientImages:forwardFilter:
nodeWithSourceGradient:sourceImage:gradientState:descriptor:
_descriptor
initWithSource:resultWidth:resultHeight:resultFeatureChannels:
nodeWithSource:resultWidth:resultHeight:resultFeatureChannels:
_resultWidth
_resultHeight
_resultFeatureChannels
initWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
nodeWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
_edgeMode
newMatrixFullyConnected
batchStart
encodeToCommandBuffer:inputMatrix:weightMatrix:biasVector:resultMatrix:
setNeuronToPReLUWithParametersA:
_encode
neuronAParamBuf
_plugin
sourceMatrixOrigin
encodeToCommandBuffer:inputMatrix:biasVector:resultMatrix:
batchSize
minimumLinearTextureAlignmentForPixelFormat:
matrixBytes
vectorBytes
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
newTextureWithDescriptor:offset:bytesPerRow:
numberOfFeatureChannels
gamma
beta
mean
variance
copy
initWithDevice:dataSource:fusedNeuronDescriptor:
encodeToCommandBuffer:sourceImage:inState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:inStates:destinationImages:
encodeToCommandBuffer:sourceImage:inState:
initDeferredWithDevice:numberOfFeatureChannels:epsilon:batchNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:epsilon:batchNormalization:
reloadDataSourceDeprecated:doReloadWeights:doReloadStats:
reloadGammaAndBetaFromDataSource
reloadMeanAndVarianceFromDataSource
initWithBytes:length:
initWithDevice:dataSource:
encodeToCommandBuffer:sourceImage:batchNormalizationState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:destinationImages:
encodeToCommandBuffer:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:
reloadDataSource:
reloadGammaAndBetaWithCommandBuffer:gammaAndBetaState:
reloadMeanAndVarianceWithCommandBuffer:meanAndVarianceState:
_gamma
_beta
_meanDS
_varDS
_stateNeedsToLoad
_fusedNeuronDescriptor
_preluBuffer
_numberOfFeatureChannels
stringWithCString:encoding:
initWithCoder:
supportsSecureCoding
weightsBufferLength
accumulatorPrecisionOption
setAccumulatorPrecisionOption:
initialize:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initWithDevice:weights:fullyConnected:convolutionTranspose:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:convolutionTranspose:
neuronABuffer
quantizationType
quantizationBuffer
encodeBatchToCommandBuffer:sourceImages:inStates:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:
encodeToCommandBuffer:sourceImage:convolutionState:
encodeToCommandBuffer:sourceImage:convolutionGradientState:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationImages:
featureChannelsLayout
_featureChannelsLayout
_convolution
_neuronInfo
initWithSources:
initWithLeftSource:rightSource:
resultState
nodeWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
nodeWithSources:
nodeWithLeftSource:rightSource:
gradientFilterWithSources:
gradientFiltersWithSources:
_primaryStrideInPixelsX
_primaryStrideInPixelsY
_secondaryStrideInPixelsX
_secondaryStrideInPixelsY
initWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
initWithGradientImages:forwardFilter:isSecondarySourceFilter:
initWithDevice:fusedNeuronDescriptor:
accumulatesOverBatch
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:
initWithSource:integerScaleFactorX:integerScaleFactorY:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:
initWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
initWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
nodeWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
setLearningRate:
setGradientRescale:
setApplyGradientClipping:
setGradientClipMax:
setGradientClipMin:
setRegularizationType:
setRegularizationScale:
initWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
initWithLearningRate:gradientRescale:regularizationType:regularizationScale:
optimizerDescriptorWithLearningRate:gradientRescale:regularizationType:regularizationScale:
optimizerDescriptorWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
learningRate
gradientRescale
applyGradientClipping
gradientClipMax
gradientClipMin
regularizationType
regularizationScale
_learningRate
_gradientRescale
_applyGradientClipping
_gradientClipMax
_gradientClipMin
_regularizationType
_regularizationScale
initWithDevice:optimizerDescriptor:
initWithDevice:momentumScale:useNestrovMomentum:optimizerDescriptor:
kernelHeight
kernelWidth
vectorDescriptorWithLength:dataType:
gradientForWeights
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:resultValuesVector:
gradientForBiases
batchNormalization
gradientForGamma
gradientForBeta
initWithDevice:learningRate:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:resultState:
momentumScale
useNestrovMomentum
_momentumScale
_useNestrovMomentum
initWithDevice:decay:epsilon:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:resultValuesVector:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputSumOfSquaresVectors:resultState:
decay
_decay
initWithDevice:beta1:beta2:epsilon:timeStep:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:inputVelocityVector:resultValuesVector:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:inputVelocityVectors:resultState:
beta1
beta2
timeStep
setTimeStep:
_beta1
_beta2
_timeStep
_timeStepSemaphore
initWithDevice:resultImage:resultImageIsNeeded:
initWithDevice:resultImage:
defaultAllocator
initWithDevice:resultImages:resultsAreNeeded:
encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
encodeBatchToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
containsValueForKey:
commandBufferWithUnretainedReferences
encodeToCommandBuffer:sourceImages:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
storageMode
status
error
commit
graphWithDevice:resultImage:resultImageIsNeeded:
graphWithDevice:resultImage:
graphWithDevice:resultImages:resultsAreNeeded:
resultImageIsNeeded
sourceImageHandles
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
encodeBatchToCommandBuffer:sourceImages:sourceStates:
executeAsyncWithSourceImages:completionHandler:
reloadFromDataSources
readCountForSourceImageAtIndex:
readCountForSourceStateAtIndex:
outputStateIsTemporary
setOutputStateIsTemporary:
format
setFormat:
_graph
_destinationImageAllocator
_format
_resultIsNeeded
_outputStateIsTemporary
handle
sourceImages
sourceStates
objectForKey:
intValue
numberWithInt:
setObject:forKey:
allKeys
allValues
unsignedIntegerValue
paddingPolicy
readCount
prefetchStorageWithCommandBuffer:imageDescriptorList:
options
resultImage
imageAllocator
trainingStyle
setTrainingStyle:
resultStatesNoAllocate
wrapperWithFilterNode:
dataWithBytesNoCopy:length:freeWhenDone:
setWithObject:
unarchivedObjectOfClasses:fromData:device:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithFilterNode:
node
wrapperWithResource:
_node
null
isSubclassOfClass:
setWithArray:
decodeObjectOfClasses:forKey:
objectAtIndex:
initWithDevice:kernelSize:
kernelSize
setBeta:
delta
setDelta:
_kernelSize
_delta
setP0:
setPm:
setPs:
initWithSource:lossDescriptor:
initWithParent:
trainingGraphWithSourceGradient:nodeHandler:
nodeWithSource:lossDescriptor:
inputLabels
_labels
initWithDevice:lossDescriptor:
encodeToCommandBuffer:sourceImage:labels:destinationImage:
lossImage
synchronizeOnCommandBuffer:
encodeBatchToCommandBuffer:sourceImages:labels:destinationImages:
cnnLossDataDescriptorWithData:layout:size:
layout
size
bytesPerRow
setBytesPerRow:
bytesPerImage
setBytesPerImage:
_data
_layout
_bytesPerRow
_bytesPerImage
cnnLossDescriptorWithType:reductionType:
setLabelSmoothing:
setNumberOfClasses:
lossType
setLossType:
reductionType
setReductionType:
labelSmoothing
numberOfClasses
_lossType
_reductionType
_labelSmoothing
_numberOfClasses
initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:
appendTexture:
initWithDevice:resourceList:
writeBytes:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:
initWithDevice:labelsDescriptor:
labelsImage
weightsImage
_lossImageSize
_isScalarLoss
_numNonZeroWeights
_userData
_numFeatureChannels_labels
_numFeatureChannels_loss
initializeSupportFiltersWithDevice:
resultStateForSourceImage:sourceStates:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:
encodeToCommandBuffer:sourceImage:labels:
encodeBatchToCommandBuffer:sourceImages:labels:
_logSoftMax
depth
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:
primaryKernelWidth
primaryKernelHeight
primaryDilationRateX
primaryDilationRateY
strideInPixelsX
strideInPixelsY
dilationRateX
dilationRateY
subPixelScaleFactor
convolutionTranspose
setImageAllocator:
initWithHandle:
nodeWithHandle:
exportedNodeWithHandle:
debugQuickLookObject
setHandle:
exportFromGraph
setExportFromGraph:
synchronizeResource
setSynchronizeResource:
stopGradient
setStopGradient:
_parent
_imageAllocator
_clientCount
_exportFromGraph
_synchronize
_stopGradient
setPaddingPolicy:
setArray:
initWithObjects:
resultStates
gradientFiltersWithSource:
_sourceImages
_sourceStates
_resultImage
_resultStates
_paddingPolicy
_label
arrayByAddingObjectsFromArray:
initWithDevice:sourceIndex:
_sourceIndex
initWithDevice:numberOfFeatureChannels:instanceNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:instanceNormalization:
reloadDataSourceDeprecated:
resourceListWithBufferSizes:
arrayWithObjects:
initWithResources:
temporaryStateWithCommandBuffer:resourceList:
temporaryStateWithCommandBuffer:bufferSize:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:
initWithDevice:bufferSize:
initWithGamma:beta:
_initialized
instanceNormalization
_instanceNormalization
initWithDevice:resizeWidth:resizeHeight:numberOfRegions:regions:
resizeWidth
resizeHeight
numberOfRegions
regions
_resizeWidth
_resizeHeight
_numberOfRegions
_regions
_gpuRegions
encodeToCommandBuffer:sourceImage:
encodeBatchToCommandBuffer:sourceImages:
newPlugin
newCNNPoolingAverageWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
newCNNDilatedPoolingMaxWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
resourceListWithTextureDescriptors:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:destinationGradient:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:destinationGradients:
encodeToCommandBuffer:primaryImage:secondaryImage:inState:
batchRepresentation
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:
subarrayWithRange:
sourceWidth
sourceHeight
primarySourceRegionForDestinationSize:
secondarySourceRegionForDestinationSize:
encodeToCommandBuffer:primaryImage:secondaryImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
appendBatchBarrier
primaryEdgeMode
secondaryEdgeMode
secondaryKernelWidth
secondaryKernelHeight
secondaryDilationRateX
secondaryDilationRateY
isBackwards
_primaryOffset
_secondaryOffset
_clipRect
_destinationFeatureChannelOffset
_primarySourceFeatureChannelOffset
_secondarySourceFeatureChannelOffset
_primarySourceFeatureChannelMaxCount
_secondarySourceFeatureChannelMaxCount
_primaryKernelWidth
_primaryKernelHeight
_secondaryKernelWidth
_secondaryKernelHeight
_primaryDilationRateX
_primaryDilationRateY
_secondaryDilationRateX
_secondaryDilationRateY
_isBackwards
_supportsBroadcasting
_padding
_primaryEdgeMode
_secondaryEdgeMode
_checkFlags
_batchEncode
_encodeData
primaryStrideInPixels
secondaryStrideInPixels
initWithFilter:
temporaryImageWithCommandBuffer:textureDescriptor:featureChannels:
dispatchBarrier
subImageWithFeatureChannelRange:
reset
_batchNormalization
_accumulationCount
initWithMean:variance:
initWithDevice:resizeWidth:resizeHeight:alignCorners:
initWithSource:keepProbability:
initWithSource:keepProbability:seed:maskStrideInPixels:
nodeWithSource:keepProbability:
nodeWithSource:keepProbability:seed:maskStrideInPixels:
_maskStride
initWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
nodeWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
cnnNeuronDescriptorWithType:a:b:
cnnNeuronDescriptorWithType:a:
cnnNeuronDescriptorWithType:
setData:
_noCopy
_count
initializeWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
initializeWithNeuronType:neuronParameterA:count:
newCNNNeuronWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
newCNNNeuronWithNeuronType:neuronParameterAArray:count:
minBufferNoCopyAlignmentBytes
newBufferWithBytesNoCopy:length:options:deallocator:
initWithBytesNoCopy:length:deallocator:
privateInitWithDevice:a:b:c:type:
privateInitWithDevice:a:count:type:
initWithDevice:a:b:
initWithDevice:neuronDescriptor:aArray:
initWithDevice:a:
initWithDevice:a:count:
initWithDevice:a:b:c:
setWeightValue:
initWithDevice:reduceOperation:
_reduceOp
_weightValue
weight:
reduceOp
primarySourceClipRect
setPrimarySourceClipRect:
secondarySourceClipRect
setSecondarySourceClipRect:
_clipRectPrimarySource
_secondarySourceClipRect
_primarySourceClipRect
initWithDevice:doWeightedSumByNonZeroWeights:
doWeightedSumByNonZeroWeights
newTextureViewWithPixelFormat:
newDescriptorWithNeuronInfo:
setBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:
initWithSource:neuronInfo:batchNorm:
_source
sourceRegionForDestinationSize:
sourcePositionOfTopLeftCornerOfFilterWindow
edgeMode
_offset
_sourceFeatureChannelOffset
_sourceFeatureChannelMaxCount
_kernelWidth
_kernelHeight
_strideInPixelsX
_strideInPixelsY
_dilationRateX
_dilationRateY
_maxBatchSize
_pluginOptions
initWithPaddingMethod:
paddingForTensorflowAveragePooling
paddingForTensorflowAveragePoolingValidOnly
inverse
_method
_mpsOwned
initWithSource:filterSize:
initWithSource:filterSize:stride:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
nodeWithSource:filterSize:
nodeWithSource:filterSize:stride:
initWithSource:filterSize:stride:dilationRate:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSource:filterSize:stride:dilationRate:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
encodeToCommandBuffer:gradientMatrix:inputMatrix:biasVector:resultGradientForDataMatrix:resultGradientForBiasVector:
_reductionKernel
initWithSource:kernelSize:
nodeWithSource:kernelSize:
setKernelWidth:
setKernelHeight:
initWithSourceGradient:sourceImage:gradientState:kernelSize:
nodeWithSourceGradient:sourceImage:gradientState:kernelSize:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
kernelSizeInFeatureChannels
setKernelSizeInFeatureChannels:
_kernelSizeInFeatureChannels
initWithSource:dataSource:
nodeWithSource:dataSource:
_trainingStyle
updateGammaAndBetaWithCommandBuffer:instanceNormalizationStateBatch:
updateGammaAndBetaWithInstanceNormalizationStateBatch:
calculateStatistics
arrayByAddingObject:
flags
setFlags:
_flags
updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
updateMeanAndVarianceWithCommandBuffer:batchNormalizationState:
updateGammaAndBetaWithBatchNormalizationState:
updateMeanAndVarianceWithBatchNormalizationState:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initWithSource:weights:
initWithSource:weights:state:
convolutionGradientState
nodeWithSource:weights:
convolutionState
accumulatorPrecision
setAccumulatorPrecision:
_accumulatorPrecision
wrapperForDataSource:
appendNeuron:
appendBatchNorm:
fusedNeuronDescriptor
initWithSourceGradient:sourceImage:convolutionGradientState:weights:
nodeWithSourceGradient:sourceImage:convolutionGradientState:weights:
exportWeightsAndBiasesWithCommandBuffer:resultStateCanBeTemporary:
initWithSource:weights:scaleValue:type:flags:
initWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
nodeWithSource:weights:scaleValue:type:flags:
nodeWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
_scaleValue
_outputBiasTerms
_outputScaleTerms
_inputBiasTerms
_inputScaleTerms
initWithDevice:convolutionData:scaleValue:type:flags:
initWithDevice:convolutionData:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
initWithSource:convolutionGradientState:weights:
initWithSource:convolutionState:weights:
nodeWithSource:convolutionGradientState:weights:
nodeWithSource:convolutionState:weights:
initWithDataSource:
initialize
appendNeuronDescriptor:
setFusedNeuronDescriptor:
hasBatchNorm
_batchNorm
_neuron
_loadCount
isEqualToString:
setAnchorBoxes:
setNumberOfAnchorBoxes:
setScaleXY:
setScaleWH:
setScaleNoObject:
setScaleObject:
setScaleClass:
setMinIOUForObjectPresence:
setMaxIOUForObjectAbsence:
setRescore:
setXYLossDescriptor:
setWHLossDescriptor:
setConfidenceLossDescriptor:
setClassesLossDescriptor:
initWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
cnnLossDescriptorWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
XYLossDescriptor
WHLossDescriptor
confidenceLossDescriptor
classesLossDescriptor
rescore
scaleXY
scaleWH
scaleNoObject
scaleObject
scaleClass
minIOUForObjectPresence
maxIOUForObjectAbsence
anchorBoxes
numberOfAnchorBoxes
_XYLossDescriptor
_WHLossDescriptor
_confidenceLossDescriptor
_classesLossDescriptor
_rescore
_scaleXY
_scaleWH
_scaleNoObject
_scaleObject
_scaleClass
_minIOUForObjectPresence
_maxIOUForObjectAbsence
_anchorBoxes
_numberOfAnchorBoxes
initializeSupportFiltersWithDevice:lossDescriptor:
countPresetobjectsSourceImages:labels:
lossXY
lossWH
lossConfidence
lossClasses
_lossXY
_lossWH
_lossConfidence
_lossClasses
_sigmoid
_sigmoidGradient
_add
_slice
_countOfPresentObjects
_encodingSemaphore
readBytes:dataLayout:imageIndex:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setNeuron:
initWithBytesNoCopy:length:freeWhenDone:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:postFilters:
setNeuronParameterA:
setNeuronParameterB:
setNeuronParameterC:
setNeuronType:parameterA:parameterB:
hasBatchNormData
setFeatureChannelsLayout:
neuron
_batchNormalizationData
_deprecated_neuron
_subPixelScaleFactor
_depthWiseConvolution
_neuron_deprecated
setSubPixelScaleFactor:
initWithSourceWidth:sourceHeight:kernelWidth:kernelHeight:sourceOffset:
sourceOffset
_originalConvolutionSourceWidth
_originalConvolutionSourceHeight
_srcOffset
temporaryStateWithCommandBuffer:resourceList:convolution:
initWithDevice:weightsBufferSize:biasesBufferSize:convolution:
_tempWeights
_tempBiases
_dimSizeN
newCNNConvolutionWithDescriptor:dataSource:fullyConnected:
PrepareAndLoadData:dataType:weights:biases:quantizationType:ranges:lookUpTable:
initialize:convolutionDescriptor:kernelWeights:dataType:range:lookUpTable:qType:biasTerms:flags:fullyConnected:convolutionTranspose:
initializeWithDevice:weights:fullyConnected:convolutionTranspose:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
reloadWeightsAndBiases:
reloadWeightsAndBiasesWithCommandBuffer:encoder:state:
initWithDevice:cnnConvolutionDescriptor:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:
exportWeightsAndBiasesWithCommandBuffer:encoder:state:
encodeToCommandBuffer:sourceImage:destinationImage:state:
reloadWeightsAndBiasesWithDataSource:
_convolutionTranspose
_qWts
_qType
_scaleFactor
_biasOriginal
_neuronABuffer
_accumulatorPrecisionOption
initWithWeights:biases:
initWithDevice:count:rows:columns:transpose:
enumerateObjectsUsingBlock:
encodeToCommandBuffer:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
transpose
_transpose
_rows
_columns
newCNNSoftMax
encodeToCommandBuffer:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultMatrix:
computeStatistics
setComputeStatistics:
_computeStatistics
_destFeatureChannels
_srcSize
_sourceFeatureChannels
_initOnce
_provenance
_primarySrcSize
_primarySourceFeatureChannels
_secondarySrcSize
_secondarySourceFeatureChannels
initWithDeviceImpl:convolutionDescriptor:kernelWeights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
createBuffersFromkernelWeights:inputBiasTerms:inputScaleTerms:outputBiasTerms:outputScaleTerms:useHalfPrecision:
copyBuffer:device:
initWithDeviceImpl:convolutionDescriptor:kernelWeights:biasTerms:scaleValue:type:flags:
_filterStride
_outputbias
_outputScale
_inputbias
_inputScale
_convType
_poolingFilter
_outputScaleValue
initWithDeviceImpl:convolutionDescriptor:kernelWeights:scaleValue:type:flags:
doesNotRecognizeSelector:
encodeToCommandBuffer:computeCommandEncoder:options:pluginOptions:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
encodeWithFilter:encoder:commandBuffer:callInfo:
encodeToCommandBuffer:computeCommandEncoder:options:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:
[%@ apply...] commandBuffer may not be nil]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixFullyConnectedGradient.mm
[%@ apply...] input gradient matrix may not be nil
[%@ apply...] weight matrix may not be nil
[%@ apply...] result gradient for weight matrix may not be nil
[%@ apply...] input matrix origin z component must be 0
[%@ apply...] weight matrix origin z component must be 0
[%@ apply...] result matrix origin z component must be 0
Only MPSDataTypeFloat32 is supported.
Matrices contain batches, batching not supported.
secondarySourceMatrixOrigin.y not within domain of weight matrix.
secondarySourceMatrixOrigin.x not within domain of weight matrix.
primarySourceMatrixOrigin not within domain of input gradient matrix.
[%@ apply...] input data matrix may not be nil
[%@ apply...] result gradient for bias vector may not be nil
secondarySourceMatrixOrigin.y not within domain of input data matrix.
secondarySourceMatrixOrigin.x not within domain of input data matrix.
[%@ initWithCoder:device:] Failed: unsupported file version.
sourceNumberOfFeatureVectors
TQ,N,V_sourceNumberOfFeatureVectors
sourceOutputFeatureChannels
TQ,N,V_sourceOutputFeatureChannels
sourceInputFeatureChannels
TQ,N,V_sourceInputFeatureChannels
alpha
Td,N,V_alpha
MatrixFullyConnectedGradient
MPSMatrixFullyConnectedGradient._alpha;
MPSMatrixFullyConnectedGradient._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnectedGradient._sourceInputFeatureChannels;
MPSMatrixFullyConnectedGradient._sourceOutputFeatureChannels;
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNReshape.mm
ReshapeOperation
ReshapeGradientOperation
pad before (x,y,ch) = (%lu, %lu, %lu)
pad after  (x,y,ch) = (%lu, %lu, %lu)
secondary source fc count = %lu
[initWithCoder:] out of memory?: could not decode fillValueArray
padBefore: (%d, %d, %d), 
padAfter: (%d, %d, %d)            
fillValue: %f
fillValueBuf: %s
created by %@
paddingSizeBefore
T{MPSImageCoordinate=QQQ},N,V_paddingSizeBefore
paddingSizeAfter
T{MPSImageCoordinate=QQQ},N,V_paddingSizeAfter
fillValue
Tf,N,V_fillValue
reshape_array_2d
reshape_array_array
Source %p and destination %p shaapes are not the same sizes
Source feature channel offset for rehape must be 0 %lu
Destination feature channel offset for rehape must be 0 %lu
MPSNNReshape._reshapedWidth;
MPSNNReshape._reshapedHeight;
MPSNNReshape._reshapedFeatureChannels;
[... copyWithZone:device](copyBuffer) out of memory: could not allocate internal data
MPSNNPad_paddingSizeBefore.x
MPSNNPad_paddingSizeBefore.y
MPSNNPad_paddingSizeBefore.channel
MPSNNPad_paddingSizeAfter.x
MPSNNPad_paddingSizeAfter.y
MPSNNPad_paddingSizeAfter.channel
MPSNNPad_fillValue
MPSNNPad_aBufLenFP32
%@%@
.length
.data
MPSNNPad_aBuf
[MPSNNPad encode] Error: Number of feature channels in result (%d) not large enough (needed %lu).
cnnPadKernel
v16@?0@"<MTLCommandBuffer>"8
cnnPadGradientKernel
[%@ initWithDevice:] is not allowed. Please use initializers that are not marked NS_UNAVAILABLE.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNPoolingGradient.mm
sourceSize
T{?=QQQ},N,V_sourceSize
zero pad size X: %lu
zero pad size Y:%lu
zeroPadSizeX
TQ,N,V_zeroPadSizeX
zeroPadSizeY
TQ,N,V_zeroPadSizeY
MPSCNNPoolingGradient.sourceSize.width
MPSCNNPoolingGradient.sourceSize.height
MPSCNNPoolingGradient.sourceSize.depth
[%@ encode...] Destination feature channel offset too large!
[%@ encode...] Destination feature channel offset Not multiple of 4!
MPSCNNPoolingGradient_generic_max_2d_2d
MPSCNNPoolingGradient_generic_max_2dArray_2dArray
MPSCNNPoolingGradient_generic_average_2d_2d
MPSCNNPoolingGradient_generic_average_2dArray_2dArray
MPSCNNPoolingGradient_generic_dilatedmax_2d_2d
MPSCNNPoolingGradient_generic_dilatedmax_2dArray_2dArray
MPSCNNPoolingGradient_generic_L2norm_2d_2d
MPSCNNPoolingGradient_generic_L2norm_2dArray_2dArray
MPSCNNPoolingGradient_generic_batch
MPSCNNPoolingGradient_inStateTex_batch
MPSCNNPoolingGradient.padSizeX
MPSCNNPoolingGradient.padSizeY
Error: The only valid values for primaryStrideInPixelsX (%lu) are 0 or 1.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNArithmetic.mm
Error: The only valid values for primaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for primaryStrideInFeatureChannels (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsX (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInFeatureChannels (%lu) are 0 or 1.
Cannot directly initialize MPSCNNArithmetic. Use one of the sub-classes of MPSCNNArithmetic.
invalid arithmetic operator type (%u)
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
primaryStrideInFeatureChannels: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
arithmeticType: %lu
[%@ resultStatesForSourceImage...] sourceStates must be nil for this filter]
Error: [%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] called with less than two source images.
[%@ %@] Error: destination state may not be nil
[%@ %@] Error: destination state must be a MPSCNNArithmeticGradientState
primaryScale
Tf,N,V_primaryScale
secondaryScale
Tf,N,V_secondaryScale
bias
Tf,N,V_bias
primaryStrideInFeatureChannels
TQ,N,V_primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
TQ,N,V_secondaryStrideInFeatureChannels
minimumValue
Tf,N,V_minimumValue
maximumValue
Tf,N,V_maximumValue
comparisonType
TQ,N,V_comparisonType
threshold
Tf,N,V_threshold
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
isSecondarySourceFilter: %d
arithmeticType: %lu
isSecondarySourceFilter
TB,R,N,V_isSecondarySourceFilter
MPSArithmetic.primaryScale
MPSArithmetic.secondaryScale
MPSArithmetic.bias
MPSArithmetic.minimumValue
MPSArithmetic.maximumValue
MPSArithmetic.primaryStrideInFeatureChannels
MPSArithmetic.secondaryStrideInFeatureChannels
MPSArithmetic.arithmeticType
[%@ encode...] MPSImageFeatureChannelsInterleavedPerPixel is not supported
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + src.featureChannels > dest.featureChannels
[%@ encode...] invalid arithmetic operation
[%@ encode...] equality threshold is negative.
MPSCNNMath_Arithmetic
MPSCNNMath_Arithmetic_Special_SubtractGradient
MPSCNNMath_Arithmetic_4Pixel_StrideXY0
MPSArithmetic.isSecondarySourceFilter
[%@ encode...] partial computation failed
inputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputTransform
outputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputTransform
recurrentOutputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentOutputTransform
internalKernelSelector
TQ,N,V_internalKernelSelector
inputFeatureChannels
TQ,N,V_inputFeatureChannels
outputFeatureChannels
TQ,N,V_outputFeatureChannels
useLayerInputUnitTransformMode
TB,N,V_useLayerInputUnitTransformMode
useFloat32Weights
TB,N,V_useFloat32Weights
layerSequenceDirection
TQ,N,V_layerSequenceDirection
inputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputWeights
recurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentWeights
cellClipThreshold
Tf,N,V_cellClipThreshold
coupleForgetGateToInputGate
TB,N,V_coupleForgetGateToInputGate
memoryWeightsAreDiagonal
TB,N,V_memoryWeightsAreDiagonal
inputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateInputWeights
inputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateRecurrentWeights
inputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateMemoryWeights
forgetGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateInputWeights
forgetGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateRecurrentWeights
forgetGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateMemoryWeights
outputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputWeights
outputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateRecurrentWeights
outputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateMemoryWeights
cellGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateInputWeights
cellGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateRecurrentWeights
cellGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateMemoryWeights
cellToOutputNeuronType
Ti,N,V_cellToOutputNeuronType
cellToOutputNeuronParamA
Tf,N,V_cellToOutputNeuronParamA
cellToOutputNeuronParamB
Tf,N,V_cellToOutputNeuronParamB
cellToOutputNeuronParamC
Tf,N,V_cellToOutputNeuronParamC
recurrentGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateInputWeights
recurrentGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateRecurrentWeights
outputGateInputGateWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputGateWeights
gatePnormValue
Tf,N,V_gatePnormValue
flipOutputGates
TB,N,V_flipOutputGates
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSRNNLayer.mm
[%@ initWithDevice:rnnDescriptors:] device may not be nil
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor.inputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptor:] outputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu] may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].inputFeatureChannels must be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].outputFeatureChannels must be larger than zero
[%@ copyWithZone:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] Problem decoding layer stack
[%@ encodeWithCoder:] Problem allocating internal data
TQ,R,N,V_inputFeatureChannels
TQ,R,N,V_outputFeatureChannels
numberOfLayers
TQ,R,N,V_numberOfLayers
recurrentOutputIsTemporary
TB,N,V_recurrentOutputIsTemporary
storeAllIntermediateStates
TB,N,V_storeAllIntermediateStates
bidirectionalCombineMode
TQ,N,V_bidirectionalCombineMode
Out of memory in MPSRNNMatrixTrainingLayer:createWeightMatrices
[%@ encode...] Error: empty set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: matrix Id not found on this layer.
[%@ encode...] Error: Invalid matrix Id for single gate
[%@ encode...] Error: Datatype conversions in encodeCopyWeightsToCommandBuffer: not supported yet
[%@ encode...] Error: only MPSDataTypeFloat32 supported currently
[%@ encode...] Error: source size is (%lu, %lu) (rows, columns) - should be (%lu, %lu) 
[%@ encode...] Error: Invalid matrix Id for LSTM
[%@ encode...] Error: Invalid set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: Invalid matrix Id for GRU
[%@ encode...] Error: Number of weight matrices (%lu), does not match number of weightGradient matrices (%lu)
[%@ encode...] Error: Number of weight matrices (%lu), does not match number at init time (%lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match weightGradient matrix dimensions (rows = %lu, columns = %lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match init time weight matrix dimensions (rows = %lu, columns = %lu)
trainingStateIsTemporary
TB,N,V_trainingStateIsTemporary
accumulateWeightGradients
TB,N,V_accumulateWeightGradients
MPSRNNMatrixVecMulFloat4
MPSRNNMatrixVecMulFloat1
MPSRNNMatrixVecMulFloat1_nonMult4
MPSRNNCopyData
MPSRNNAddSequenceData
MPSRNNMultiInputKernelFloat1
MPSRNNMultiInputKernelFloat1_nonMult4
MPSRNNCombineInputVecs
RNNAddBiasToOutput
MPSRNNLSTMRecursionTex0
MPSRNNLSTMRecursionTex1
MPSRNNLSTMRecursionCombined0float
MPSRNNLSTMRecursionCombined1float
MPSRNNLSTMFullRecursion0float
MPSRNNLSTMFullRecursion1float
MPSRNNLSTMRecursionCombined0half
MPSRNNLSTMRecursionCombined1half
MPSRNNLSTMFullRecursion0half
MPSRNNLSTMFullRecursion1half
MPSRNNBreakUpToOutputVecs
MPSRNNReduceToBiasGradient
MPSRNNClearFloatBuffer
MPSRNNClearCharBuffer
kMPSRNNLayer._inputFeatureChannels
kMPSRNNLayer._outputFeatureChannels
kMPSRNNLayer._numberOfLayers
kMPSRNNLayer._recurrentOutputIsTemporary
kMPSRNNLayer._storeAllIntermediateStates
kMPSRNNLayer._bidirectionalCombineMode
kMPSRNNLayer.layerTypes
[%@ encode...] commandBuffer may not be nil]
[%@ encode...] source may not be nil
[%@ encode...] destination may not be nil
[%@ encode...] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
MPSRNNImageCombine_2d_2d_2d_float
MPSRNNImageCombine_2d_2dArray_2d_float
MPSRNNImageCombine_2dArray_2d_2d_float
MPSRNNImageCombine_2dArray_2dArray_2d_float
MPSRNNImageCombine_2d_2d_2dArray_float
MPSRNNImageCombine_2d_2dArray_2dArray_float
MPSRNNImageCombine_2dArray_2d_2dArray_float
MPSRNNImageCombine_2dArray_2dArray_2dArray_float
MPSRNNGateCombine_2d_2d_2d_float
MPSRNNGateCombine_2d_2dArray_2d_float
MPSRNNGateCombine_2dArray_2d_2d_float
MPSRNNGateCombine_2dArray_2dArray_2d_float
MPSRNNGateCombine_2d_2d_2dArray_float
MPSRNNGateCombine_2d_2dArray_2dArray_float
MPSRNNGateCombine_2dArray_2d_2dArray_float
MPSRNNGateCombine_2dArray_2dArray_2dArray_float
MPSRNNPNormCombine_2d_2d_2d_float
MPSRNNPNormCombine_2d_2dArray_2d_float
MPSRNNPNormCombine_2dArray_2d_2d_float
MPSRNNPNormCombine_2dArray_2dArray_2d_float
MPSRNNPNormCombine_2d_2d_2dArray_float
MPSRNNPNormCombine_2d_2dArray_2dArray_float
MPSRNNPNormCombine_2dArray_2d_2dArray_float
MPSRNNPNormCombine_2dArray_2dArray_2dArray_float
MPSLSTMMultiInputKernelFloat1
MPSLSTMMultiInputKernelFloat2
MPSLSTMMultiInputKernelFloat3
MPSLSTMMultiInputKernelFloat4
MPSLSTMMultiInputKernelFloat5
MPSLSTMMultiInputKernelFloat6
MPSLSTMMultiInputKernelFloat7
MPSLSTMMultiInputKernelFloat8
MPSLSTMMultiInputKernelFloat9
MPSLSTMMultiInputKernelFloat10
MPSLSTMMultiInputKernelFloat11
MPSLSTMMultiInputKernelFloat12
MPSLSTMMultiInputKernelFloat13
MPSLSTMMultiInputKernelFloat14
MPSLSTMMultiInputKernelFloat15
MPSLSTMMultiInputKernelFloat16
MPSRNNLSTMRecursionfloat00_11_1
MPSRNNLSTMRecursionhalf00_11_1
MPSRNNLSTMRecursionchar00_11_1
MPSRNNLSTMRecursionfloat00_11_2
MPSRNNLSTMRecursionhalf00_11_2
MPSRNNLSTMRecursionchar00_11_2
MPSRNNLSTMRecursionfloat00_11_4
MPSRNNLSTMRecursionhalf00_11_4
MPSRNNLSTMRecursionchar00_11_4
MPSRNNLSTMRecursionfloat00_11_8
MPSRNNLSTMRecursionhalf00_11_8
MPSRNNLSTMRecursionchar00_11_8
MPSRNNLSTMRecursionfloat00_41_1
MPSRNNLSTMRecursionhalf00_41_1
MPSRNNLSTMRecursionchar00_41_1
MPSRNNLSTMRecursionfloat00_42_1
MPSRNNLSTMRecursionhalf00_42_1
MPSRNNLSTMRecursionchar00_42_1
MPSRNNLSTMRecursionfloat00_44_1
MPSRNNLSTMRecursionhalf00_44_1
MPSRNNLSTMRecursionchar00_44_1
MPSRNNLSTMRecursionfloat00_81_1
MPSRNNLSTMRecursionhalf00_81_1
MPSRNNLSTMRecursionchar00_81_1
MPSRNNLSTMRecursionfloat00_82_1
MPSRNNLSTMRecursionhalf00_82_1
MPSRNNLSTMRecursionchar00_82_1
MPSRNNSingleGateGradientRecursion_float_14_1
MPSRNNSingleGateGradientRecursion_float_24_1
MPSRNNSingleGateGradientRecursion_float_44_1
MPSRNNSingleGateGradientRecursion_half_14_1
MPSRNNSingleGateGradientRecursion_half_24_1
MPSRNNSingleGateGradientRecursion_half_44_1
MPSRNNSingleGateGradientRecursion_char_14_1
MPSRNNSingleGateGradientRecursion_char_24_1
MPSRNNSingleGateGradientRecursion_char_44_1
MPSRNNLSTMGradientRecursion_float_14_1
MPSRNNLSTMGradientRecursion_float_24_1
MPSRNNLSTMGradientRecursion_float_44_1
MPSRNNLSTMGradientRecursion_half_14_1
MPSRNNLSTMGradientRecursion_half_24_1
MPSRNNLSTMGradientRecursion_half_44_1
MPSRNNLSTMGradientRecursion_char_14_1
MPSRNNLSTMGradientRecursion_char_24_1
MPSRNNLSTMGradientRecursion_char_44_1
MPSRNNGRUGradientRecursion1_float_14_1
MPSRNNGRUGradientRecursion1_float_24_1
MPSRNNGRUGradientRecursion1_float_44_1
MPSRNNGRUGradientRecursion1_half_14_1
MPSRNNGRUGradientRecursion1_half_24_1
MPSRNNGRUGradientRecursion1_half_44_1
MPSRNNGRUGradientRecursion1_char_14_1
MPSRNNGRUGradientRecursion1_char_24_1
MPSRNNGRUGradientRecursion1_char_44_1
MPSRNNGRUGradientRecursion2_float_14_1
MPSRNNGRUGradientRecursion2_float_24_1
MPSRNNGRUGradientRecursion2_float_44_1
MPSRNNGRUGradientRecursion2_half_14_1
MPSRNNGRUGradientRecursion2_half_24_1
MPSRNNGRUGradientRecursion2_half_44_1
MPSRNNGRUGradientRecursion2_char_14_1
MPSRNNGRUGradientRecursion2_char_24_1
MPSRNNGRUGradientRecursion2_char_44_1
MPSRNNSingleGateRec_float00_1_2
MPSRNNSingleGateRec_float00_1_4
MPSRNNSingleGateRec_float00_8_2
MPSRNNSingleGateRec_float00_8_4
MPSRNNSingleGateRec_half00_1_2
MPSRNNSingleGateRec_half00_1_4
MPSRNNSingleGateRec_half00_8_2
MPSRNNSingleGateRec_half00_8_4
MPSRNNSingleGateRec_char00_1_2
MPSRNNSingleGateRec_char00_1_4
MPSRNNSingleGateRec_char00_8_2
MPSRNNSingleGateRec_char00_8_4
MPSRNNGRURecursion1float00_11
MPSRNNGRURecursion1float00_44
MPSRNNGRURecursion1half00_11
MPSRNNGRURecursion1half00_44
MPSRNNGRURecursion1char00_11
MPSRNNGRURecursion1char00_44
MPSRNNGRURecursion2float00_11
MPSRNNGRURecursion2float00_44
MPSRNNGRURecursion2half00_11
MPSRNNGRURecursion2half00_44
MPSRNNGRURecursion2char00_11
MPSRNNGRURecursion2char00_44
Only MPSDataTypeFloat32 and MPSDataTypeFloat16 supported
[copySingleGateLayer copyWithZone:device] out of memory: could not allocate internal data
[copyLSTMLayer copyWithZone:device] out of memory: could not allocate internal data
[initWithCoder:] out of memory: could not allocate internal data
%@%d
kMPSRNNLayer.common.direction
kMPSRNNLayer.common.useUnitXForm
kMPSRNNLayer.common.nHiddenFeatures
kMPSRNNLayer.common.nInputFeatures
kMPSRNNLayer.common.nOutputFeatures
kMPSRNNLayer.common.nRecurrentOutputFeatures
kMPSRNNLayer.common.inputTransform
kMPSRNNLayer.common.outputTransform
kMPSRNNLayer.common.recurrentOutputTransform
kMPSRNNLayer.common.inputTransform.hasBias
kMPSRNNLayer.common.outputTransform.hasBias
kMPSRNNLayer.common.recurrentOutputTransform.hasBias
MPSRNNLayer.SingleGate.inputXForm
MPSRNNLayer.SingleGate.recurrentXForm
MPSRNNLayer.SingleGate.hasBias
MPSRNNLayer.SingleGate.biasData
.convolution
kMPSRNNLayer.neuron.neuronType
kMPSRNNLayer.neuron.neuronParamA
kMPSRNNLayer.neuron.neuronParamB
kMPSRNNLayer.neuron.neuronParamC
[initWithCoder:](decodeLSTMLayer) out of memory: could not allocate internal data
MPSRNNLayer.LSTM.inputGate
MPSRNNLayer.LSTM.forgetGate
MPSRNNLayer.LSTM.cellGate
MPSRNNLayer.LSTM.outputGate
MPSRNNLayer.LSTM.recursionXFormsCombined
MPSRNNLayer.LSTM.finalNeuron
MPSRNNLayer.LSTM.inputXFormsCombined
MPSRNNLayer.LSTM.coupleForgetGateToInputGate
MPSRNNLayer.LSTM.cellClipThreshold
.inputXForm
.recurrentXForm
.peepholeXForm
.hasBias
.biasVector
.peepholeVector
.nHiddenFeatures
[initWithCoder:](decodeGRULayer) out of memory: could not allocate internal data
MPSRNNLayer.GRU.inputGateInputXform
MPSRNNLayer.GRU.inputGateRecXform
MPSRNNLayer.GRU.inputGateBias
MPSRNNLayer.GRU.inputGateHasBias
MPSRNNLayer.GRU.inputNeuron
MPSRNNLayer.GRU.recGateInputXform
MPSRNNLayer.GRU.recGateRecXform
MPSRNNLayer.GRU.recGateBias
MPSRNNLayer.GRU.recGateHasBias
MPSRNNLayer.GRU.recurrentNeuron
MPSRNNLayer.GRU.outputGateInputXform
MPSRNNLayer.GRU.outputGateRecXform
MPSRNNLayer.GRU.outputGateMemoryform
MPSRNNLayer.GRU.outputGateBias
MPSRNNLayer.GRU.outputGateHasBias
MPSRNNLayer.GRU.outputNeuron
MPSRNNLayer.GRU.pNormGateValue
MPSRNNLayer.GRU.flipOutputGates
Out of memory initializing RNN training layer
[... initWithCoder:device](decodeTransform) out of memory: could not allocate internal data
.dataType
.biasLength
.biasData
.rows
.rowBytes
.columns
[... encodeWithCoder:](encodeTransform) Invalid transform buffer
[MPSNNScaleNode init] Error: Abstract class. 
Please use MPSNNBilinearScaleNode or MPSNNLanczosScaleNode instead.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNScale.mm
region provider: %@
size: {%lu, %lu, %lu}
use entire image
Internal error: [%@ initWithDevice:] unavailable
region provider: %@
Size: { %lu, %lu, %lu}
<copy entire image>
%@ error: Filter does not support result depth != 1
%@ %p error: the resampling filter does not support featureChannels > 4.
Error: class %@ does not conform to <MPSImageTransformProvider>
MPSNNScale.className
MPSNNScale.o
MPSNNScale.transformProviderName
MPSNNScale.handleName
MPSNNScale.handle.o
MPSNNScale.destSize.x
MPSNNScale.destSize.y
MPSNNScale.destSize.z
[MPSNNGraph encode...]: Error: MPSNNPadding method %p returned a nil formatting descriptor for an intermediate image.
The encode can not continue.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/FilterNode.h
Internal error: default encode for unary kernels doesn't take an input state
<missing label>
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
float16
float32
unorm8
unorm16
snorm8
snorm16
uint8
uint6
sint8
sint16
<unknown channel format>
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
*** Warning: kernel %s (%s) produces a result of size %lu x %lu. We will probably assert soon.
Perhaps the MPSNNGraph input image is too small for this network, or an upstream padding
policy was incorrect (full>same>valid), or a stride too large?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImage for destination.  Encode failed.
/BuildRoot/Library/Caches/com.apple.xbs/Binaries/MetalImage_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSImageInternal.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNConcatenation.mm
[%@ encode...] sourceImages may not be nil
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLPixelFormat is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLTextureUsage is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] sourceImages length is 0. Can not produce a result.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  The MPSImageFeatureChannelsLayout must match between source and destination MPSImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu and dest image must have the same feature channel layout
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  the sum of feature channels in the source images  must fit within the destination image
[%@ encodeToCommandBuffer:sourceImages:destinationImage] Error: source image %lu (%p) has invalid feature channel layout.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] internal error: unable to create MTLTextureType2DArray view of src texture %p
[%@ encodeBatchToCommandBuffer:sourceImages:destinationImage:] Error: there are not enough source images in batch %lu (%lu) to fill the destination batch %lu
[%@ encodeToCommandBuffer: sourceImages:] sourceImages.count may not be 0
[%@ %@] Error: command buffer may not be NULL
[%@ %@] Error: sourceImage batch may not be NULL
[%@ %@] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImages may not be NULL
[%@ resultStateBatchForSourceImages:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
%@, %lu
slice offsets:              {%@}
feature channels per slice: {%@}
ConcatenateInterleaved
ConcatenateInterleaved_array
ConcatenateArray
ConcatenateArray_array
Please initialize the %@ class with initWithDevice:weights
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNConvolutionGradientForData.mm
[%@ initWithDevice:convolutionDescriptor:weights:] device may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] convolutionDescriptor may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] 8-bit weights not supported in
kernel width must be > 0
kernel height must be > 0
number of input feature channels must be > 0
number of output feature channels must be > 0
strideX must be > 0
strideY must be > 0
dilationRateX must be > 0
dilationRateY must be > 0
number of groups must be > 0
Subpixel convolution does not currently supported gradient back propagation
Depthwise convoution gradient is only supported for channel multipler == 1
Lock creation failed
Failed to create weights buffer
weights.load should return YES
data source returned nil weights
weights to reload method cannot be nil
weights buffer should have %lu bytes of data
Internal error has occured
Number of source feature channels needed by convolution %lu are not available in image with %lu feature channels
Number of destination feature channels needed by convolution gradient w.r.t data %lu are not available in image with %lu feature channels at offset %lu
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
TQ,R,N,V_groups
channelMultiplier
TQ,R,N,V_channelMultiplier
dataSource
T@"<MPSCNNConvolutionDataSource>",R,&,N,V_dataSource
gradientOption
TQ,N,V_gradientOption
serializeWeightsAndBiases
TB,N,V_serializeWeightsAndBiases
MPSCNNConvolutionGradientIsFullyConnected
kMPSCNNConvolutionGradientSerializeWeightsAndBiases
MPSCNNConvolutionGradientInputFeatureChannels
MPSCNNConvolutionGradientOutputFeatureChannels
MPSCNNConvolutionGradientGroups
MPSCNNConvolutionChannelMultiplier
kMPSCNNConvolutionGradientWeightsDataType
Gradient filter not implemented for reduction kernels.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNReductionNodes.mm
clipRectSource
T{?={?=QQQ}{?=QQQ}},N,V_clipRectSource
weight
Tf,N,V_weight
Internal error: default encode for gradient kernels doesn't take an result state
Internal error: default encode for gradient kernels has an input state
Internal error: gradient kernels take an input state
Internal error: gradient kernels take multiple input images
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalizationGradient.mm
[%@ apply...] input matrix may not be nil
[%@ apply...] gradient matrix may not be nil
[%@ apply...] input mean vector may not be nil
[%@ apply...] input variance vector may not be nil
[%@ apply...] result gradient for data matrix may not be nil
Only outputs of MPSDataTypeFloat32 are supported.
Only beta vector value types of MPSDataTypeFloat32 are supported.
Only gamma vector value types of MPSDataTypeFloat32 are supported.
Only input matrix value types of MPSDataTypeFloat32 are supported.
PReLU not supported.
neuronType
Ti,N,V_neuronType
neuronA
Tf,N,V_neuronA
neuronB
Tf,N,V_neuronB
neuronC
Tf,N,V_neuronC
epsilon
Tf,N,V_epsilon
MatrixBatchNormalizationGradient
MPSMatrixBatchNormalizationGradient._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalizationGradient._sourceInputFeatureChannels;
MPSMatrixBatchNormalizationGradient._neuronType;
MPSMatrixBatchNormalizationGradient._neuronA;
MPSMatrixBatchNormalizationGradient._neuronB;
MPSMatrixBatchNormalizationGradient._neuronC;
MPSMatrixBatchNormalizationGradient._epsilon;
[%@ initWithDevice:keepProbability:seed:] Failed: the valid range of keepProbability (%lu) is (0.0f, 1.0f]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNDropout.mm
keepProbability: %f
seed: %lu
keepProbability
Tf,R,N,V_keepProbability
seed
TQ,R,N,V_seed
maskStrideInPixels
T{?=QQQ},R,N,V_maskStrideInPixels
MPSCNNDropoutKeepProbability
MPSCNNDropoutSeed
MPSCNNDropoutMaskStrideInPixelsWidth
MPSCNNDropoutMaskStrideInPixelsHeight
MPSCNNDropoutMaskStrideInPixelsDepth
EncodeDropoutCommon
YES == [filter isKindOfClass: MPSCNNDropoutGradient.class]
YES == [filter isKindOfClass: MPSCNNDropout.class]
[%@ encode...] valid values for maskStrideInPixels {%lu %lu %lu} are 0 and 1
[%@ encode...] operates only on a single image
[%@ encode...] the dropout state object cannot be nil
[%@ encode...] mask data in the state object must not be nil for this filter. Call resultStatesForSourceImage:sourceStates to initialize the state before calling encode.
[%@ encode...] not enough source images:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough labels data:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough destination images:  offset.z + clipRect.size.depth > destinationImage.numberOfImages
EncodeDropoutCommonBatch
[%@ encode...] the dropout states object cannot be nil
[%@ encode...] mask data in the state object must not be nil for this filter. Call resultStatesForSourceImages:sourceStates to initialize the state before calling encode.
MPSCNNDropoutGradientKeepProbability
MPSCNNDropoutGradientSeed
MPSCNNDropoutGradientMaskStrideInPixelsWidth
MPSCNNDropoutGradientMaskStrideInPixelsHeight
MPSCNNDropoutGradientMaskStrideInPixelsDepth
Cannot directly initialize MPSCNNUpsampling. Use one of the sub-classes of MPSCNNUpsampling.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNUpsampling.mm
scale factor in the x dimension (%lu) must be > 0
scale factor in the y dimension (%lu) must be > 0
invalid filter type (%lu)
scaleFactorX: %f
scaleFactorY: %f
scaleFactorX
Td,R,N,V_scaleFactorX
scaleFactorY
Td,R,N,V_scaleFactorY
alignCorners
TB,R,N,V_alignCorners
MPSCNNUpsampling_tex2d_tex2d_general
MPSCNNUpsampling_tex2darray_tex2darray_general
MPSCNNUpsampling_tex2d_tex2d_special_scaleFactor2
MPSCNNUpsampling_tex2darray_tex2darray_special_scaleFactor2
MPSCNNUpsampling_bilinear_tex2d_tex2d_general_float32
MPSCNNUpsampling_bilinear_tex2darray_tex2darray_general_float32
MPSCNNUpsampling_bilinear_tex2d_tex2d_special_scaleFactor2_float32
MPSCNNUpsampling_bilinear_tex2darray_tex2darray_special_scaleFactor2_float32
MPSCNNUpsampling.filterType
MPSCNNUpsampling.scaleFactorX
MPSCNNUpsampling.scaleFactorY
MPSCNNUpsampling.alignCorners
[%@ encode...] Specificed scaleFactorX would result in destination texture width that exceeds the maximum allowed texture width
[%@ encode...] Specificed scaleFactorY would result in destination texture height that exceeds the maximum allowed texture height
MPSCNNGradientKernel.kernelOffsetX
MPSCNNGradientKernel.kernelOffsetY
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] no padding method set. Can not compute result.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MetalPerformanceShaders/MPSCNNGradientKernel.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] the object padding method %p does not respond to the destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor: selector
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImage for destination.  Encode failed.
[%@ encode] Error: Gradient filters do not support gradient operations for Inference kernels that use the clipRect to operate on a subregion of the result
This would force the gradient kernel to have to do software edging at significant performance cost.
Use the slice operator to  trim away the unwanted parts of the gradient input.
[%@ encode] Error: Unknown state type.  Encode failed.
[%@ encodeToCommandBuffer:sourceGradients:...] Unable to create MPSImageDescriptor for destination.  Encode failed.
kernelOffsetX
Tq,N,V_kernelOffsetX
kernelOffsetY
Tq,N,V_kernelOffsetY
a: %f
b: %f
c: %f
Tf,R,N,V_a
Tf,R,N,V_b
Tf,R,N,V_c
Internal error: encountered unknown neuron type
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSCNNNeuronNodes.mm
descriptor
T@"MPSNNNeuronDescriptor",R,N,V_descriptor
Internal error: default encode for binary kernels doesn't take an input state
%@ (%s)
MPSCNNNeuron (%s)
MPSCNNNeuronGradient (%s)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixFullyConnected.mm
[%@ apply...] result matrix may not be nil
Only bias vector value types of MPSDataTypeFloat32 are supported.
Only weight matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
filter.batchStart not within domain of inputMatrix.
filter.batchStart not within domain of weightMatrix.
filter.batchStart not within domain of resultMatrix.
filter.batchStart not within domain of biasVector.
secondarySourceMatrixOrigin.y not within domain of weightMatrix.
secondarySourceMatrixOrigin.x not within domain of weightMatrix.
primarySourceMatrixOrigin not within domain of inputMatrix.
PReLU param-A array failed to set.
[%@ initWithCoder:device:] Failed: Unable to read array for MPSCNNNeuronTypePReLU.
For PReLU, use -setNeuronToPReLUWithParametersA:
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
sourceOutputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
Only outputs of MPSDataTypeFloat32 and MPSDataTypeFloat16 are supported.
Input matrix value type must match output matrix value type.
sourceMatrixOrigin not within domain of inputMatrix.
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixFullyConnected_AnyM
MatrixFullyConnectedTexture_M4
MatrixNeuron_float
MatrixNeuron_half
MPSMatrixFullyConnected._alpha;
MPSMatrixFullyConnected._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnected._sourceInputFeatureChannels;
MPSMatrixFullyConnected._sourceOutputFeatureChannels;
MPSMatrixFullyConnected._neuronType;
MPSMatrixFullyConnected._neuronA;
MPSMatrixFullyConnected._neuronB;
MPSMatrixFullyConnected._neuronC;
MPSMatrixFullyConnected._perChannelNeuronA;
[%@ initWithDevice:dataSource:] dataSource.load should return YES
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBatchNormalization.mm
[%@ initWithDevice:dataSource:fusedNeuronDescriptor] neuron is of type PReLU but data is nil.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported.  Batch normalization state requires a source state.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:] Attempting to use statistics from a temporary MPSCNNBatchNormalizationState with readCount of 0.
[%@ encodeBatchToCommandBuffer...] Error: convenience methods that return a image batch must have clipRect.origin.z = 0.  We can't return empty batch nodes in a NSArray.
Cannot create state for images with more feature channels than used to initialize batch normalization filter.
[%@ reloadDataSource:] dataSource.load should return YES
state does not have valid gamma and beta buffers.
reloadGammaAndBeta
state does not have valid mean and variance buffers.
reloadMeanAndVariance
[%@ %@] Error: Unable to decode data source.
[%@ %@] Error: dataSource does not support NSSecureCoding
feature channels: %lu
epsilon: %g
data source: %@
neuron:
numberOfFeatureChannels
TQ,R,N,V_numberOfFeatureChannels
T@"<MPSCNNBatchNormalizationDataSource>",R,&,N,V_dataSource
batchNormSimpleBufferCopy
encodeBatchToCommandBuffer: Neuron is of type PReLU but parameter buffer is nil.
imageBatchNormalization
Error: Can not decode. Unable to find class implementation for "%@".
/BuildRoot/Library/Caches/com.apple.xbs/Binaries/MetalImage_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSCoreInternal.h
kMPSCNNBatchNormalization.s
kMPSCNNBatchNormalization.o
kMPSCNNBatchNormalizationIsNeuronFusedKey
kMPSCNNBatchNormalizationFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLUData
kMPSCNNBatchNormalizationFusedNeuronA
kMPSCNNBatchNormalizationFusedNeuronB
kMPSCNNBatchNormalizationFusedNeuronC
supportsSecureCoding
TB,R
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNConvolutionTranspose.mm
Filter weights pointer should be non-null
Feature channel layout of source and MPSCNNConvolutionTranspose filter doesn't match
Feature channel layout of destination and MPSCNNConvolutionTranspose filter doesn't match
Number of source feature channels needed by convolution %lu are not available in image with %lu feacture channels
Number of destination feature channels needed by convolution %lu are not available in image with %lu feature channels at offset %lu
%@inputFeatureChannels: %lu
outputFeatureChannels: %lu
Feature channel layout: %lu
Groups: %lu 
kernelOffset: {%zd, %zd}
neuron type: %s
neuron A:  %10.14f
neuron B:  %10.14f
neuron C:  %10.14f
featureChannelsLayout
TQ,R,N,V_featureChannelsLayout
weightsBufferLength
TQ,R,N
accumulatorPrecisionOption
TQ,N
MPSCNNConvolutionTransposeVers
MPSCNNConvolutionTransposeWidth
MPSCNNConvolutionTransposeHeight
MPSCNNConvolutionTransposeInputFeatureChannels
MPSCNNConvolutionTransposeOutputFeatureChannels
MPSCNNConvolutionTransposeStrideInPixelsX
MPSCNNConvolutionTransposeStrideInPixelsY
MPSCNNConvolutionTransposeGroups
MPSCNNConvolutionTransposeFeatureChannelsLayout
MPSCNNConvolutionTransposeKernelOffsetX
MPSCNNConvolutionTransposeKernelOffsetY
MPSCNNConvolutionTransposeNeuron
dequantizeOSX
You must call -gradientFiltersWithSources:gradientImages: for this filter
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNArithmeticNodes.mm
[%@ gradientFiltersWithSources:] This method requires one gradient image as input
[%@ gradientFiltersWithSources:] gradientImages[0] must be valid and contain the source gradient
primaryStrideInPixelsX
TQ,N,V_primaryStrideInPixelsX
primaryStrideInPixelsY
TQ,N,V_primaryStrideInPixelsY
secondaryStrideInPixelsX
TQ,N,V_secondaryStrideInPixelsX
secondaryStrideInPixelsY
TQ,N,V_secondaryStrideInPixelsY
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNBinaryArithmeticNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalizationGradient.mm
imageInstanceNormalizationThreadgroupDot
imageInstanceNormalizationImageDot
imageInstanceNormalizationGradient
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationStatisticsGradient.mm
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientStates:destinationGradient:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
imageInitialDotBase
imageFinalSumBase
imageThreadgroupSumDotBase
kMPSCNNBatchNormalizationStatisticsGradientIsNeuronFusedKey
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLULength
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronA
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronB
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronC
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingNearestNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSCNNUpsamplingNodes.mm
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingBilinearNode
%s.dataType == MPSDataTypeFloat32 failed, Optimizers currently support only Float32 datatype vectors
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNOptimizers.mm
%s.vectors == 1 failed, Optimizers currently support only 1  vector per MPSVector
inputGradientVector.length == %s.length failed, number of elements must be same
learningRate
Tf,N,V_learningRate
gradientRescale
Tf,N,V_gradientRescale
applyGradientClipping
TB,N,V_applyGradientClipping
gradientClipMax
Tf,N,V_gradientClipMax
gradientClipMin
Tf,N,V_gradientClipMin
regularizationScale
Tf,N,V_regularizationScale
regularizationType
TQ,N,V_regularizationType
[%@ initWithCoder:device:] Unsupported file version. Could not init object.
            
learningRate:
            
gradientRescale:
            
applyGradientClipping:
            
gradientClipMax:
            
gradientClipMin:
            
regularizationType:
            
regularizationScale:
Tf,R,N,V_learningRate
Tf,R,N,V_gradientRescale
Tf,R,N,V_gradientClipMax
Tf,R,N,V_gradientClipMin
Tf,R,N,V_regularizationScale
TQ,R,N,V_regularizationType
            
momentumScale:
            
useNestrovMomentum:
inputGradientVector
inputValuesVector
resultValuesVector
inputMomentumVector
[resultState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionSourceState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionGradientState isKindOfClass: MPSCNNConvolutionGradientState] failed
[batchNormalizationSourceState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[batchNormalizationGradientState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[resultState isKindOfClass: MPSCNNNormalizationGammaAndBetaState.class] failed
inputGradientState.gradientForGamma returned nil
[batchNormalizationState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
momentumScale
Tf,R,N,V_momentumScale
useNestrovMomentum
TB,R,N,V_useNestrovMomentum
            
decay:
            
epsilon:
inputSumOfSquaresVector
decay
Td,R,N,V_decay
Tf,R,N,V_epsilon
            
beta1:
            
beta2:
            
epsilon:
%f            
timeStep:
inputVelocityVector
beta1
Td,R,N,V_beta1
beta2
Td,R,N,V_beta2
timeStep
TQ,N,V_timeStep
kMPSNNOptimizer.learningRate
kMPSNNOptimizer.gradientRescale
kMPSNNOptimizer.applyGradientClipping
kMPSNNOptimizer.gradientClipMax
kMPSNNOptimizer.gradientClipMin
kMPSNNOptimizer.regularizationType
kMPSNNOptimizer.regularizationScale
kMPSNNOptimizer.momentumScale
kMPSNNOptimizer.useNestrovMomentum
sgdUpdate
sgdUpdate4
sgdMomentumUpdate
sgdMomentumUpdate4
rmsPropUpdate
rmsPropUpdate4
adamUpdate
adamUpdate4
kMPSNNOptimizer.decay
kMPSNNOptimizer.epsilon
kMPSNNOptimizer.beta1
kMPSNNOptimizer.beta2
kMPSNNOptimizer.timeStep
[%@ initWithDevice:resultImage:resultStates:] error: resultImage may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNGraph.mm
[%@ initWithDevice:resultImage:resultStates:] error: resultImage must be a child class of MPSNNImageNode
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph consumes MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces intermediate image objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a MPSImage
[MPSNNGraph encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:] error: source images must currently be type compatible with half float texture loads.
Source image [%lu] has pixel format %s
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
Did you perhaps forget to provide the state objects for labels and weights for the loss layer?
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceStates[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: destination image allocator may not be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a array of MPSImage
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is not a MPSImage
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: %lu MPSStateBatches expected as input. nil was passed.
<nil>
<no description>
MPSImageFeatureChannelFormatNone
MPSImageFeatureChannelFormatUnorm8
MPSImageFeatureChannelFormatUnorm16
MPSImageFeatureChannelFormatFloat16
MPSImageFeatureChannelFormatFloat32
<Internal error: missing format name>
outputStateIsTemporary:              %s
destinatonImageAllocator:            %s
default intermediate storage foramt: %s
result is needed:                    %s
list of nodes:
(Note: missing nodes have been optimized away.)
[%@ initWithCoder:device:] Failed: unable to read class of MPSNNGraph destination image allocator.
[%@ initWithCoder:device:] Failed: unable to find class of MPSNNGraph destination image allocator %@ in application.
MPS Warning: failure to unpack graph default image allocator with unarchiver. MPSTemporaryImage defaultAllocator will be used.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: outputStateIsTemporary must be set to NO for this method
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the destinationImageAllocator is set to create a temporary image.
A temporary image only lives as long as the MTLCommandBuffer. Its contents would be invalid by the time you were able to use them.
MPSErrorDomain
Failed to allocate MPSImage
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModePrivate. Perhaps you made a MPSTemporaryImage instead by mistake? That can't work.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModeMemoryless
MPS Internal Error: Unexpected command buffer status encountered: %lu
sourceImageHandles
T@"NSArray",R,C,N
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
T@"<MPSHandle>",R,N
outputStateIsTemporary
TB,N,V_outputStateIsTemporary
destinationImageAllocator
T@"<MPSImageAllocator>",&,N,V_destinationImageAllocator
format
TQ,N,V_format
resultImageIsNeeded
TB,R,N
[%@ initWithDevice:resultImage:] internal error: could not create filter for node:
[%@ initWithDevice:resultImage:] internal error: source image is NULL
[%@ initWithDevice:resultImage:] internal error: state image is NULL
 result image id <-- filter <-- {filter source image id list}
 ============================================================
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{PrintStackFrame=}16
   * an image passed into the graph
   0 is the graph result image.
   () the result may be only partially overwritten.
Summary:
%4lu %s
Init MPSNNGraph %p
%lu nodes are specified.
Some may have been pruned because they were not needed to produce a result.
Initial graph:
v40@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQQ}16Q24^{EmptyStackFrame=}32
Final graph:
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{EmptyStackFrame=}16
Rejected contraction of %s:
it uses MPSNNPaddingMethodCustom without MPSNNPaddingMethodCustomWhitelistForNodeFusion
Rejected contraction of %s into %s:
the intermediate image is read by another filter (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu) or exported from the graph
  Attempting to contract consecutive filter passes into a single pass...
Removed %s because it does nothing
Can not contract %s: 
Contracted %s into %s
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{OptimizationStackFrame=}16
  Removed %lu passes
  No passes removed by contraction.
(This is common in training graphs because the intermediate tensors are needed for gradient passes.)
  Pruning unproductive filter nodes...
Pruned %s
  Pruned %lu nodes.
  Attempting to use feature channel offsets to eliminate concatenation and slice passes...
Optimized away %s
Optimized away %s
  Removed %lu passes
Verify Graph:
No filters in graph.
Error: node %p %@ "%@" has no result image. All MPS nodes are required to have a result.
Error: node %s has no result image. All MPS nodes are required to have a result.
Error: nothing reads the result from node %p %@ "%@".  All MPS nodes are required to have a result.
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES?
Error: nothing reads the result from node %s. 
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES.
Error: node %s has a missing result state? %lu
Error: nothing reads the result state from node %p %@ "%@".
Error: nothing reads the result state %lu from node %s. 
%lu issues reported.
Optimizing graph structure...
End graph optimization passes.
Error: using image with 0 read count
v40@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQQ}16Q24^{EncodeFrame=@@@@@QQQ^{Graph}}32
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{EncodeFrame=@@@@@QQQ^{Graph}}16
Legend:
FilterNodeType[filter.index] {src.width x src.height x src.featureChannels src.format}[src.index] ->
{dest.width x dest.height x dest.featureChannels dest.format}[dest.index] offset: destinationFeatureChannelOffset
=============================================================================================================
v40@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQQ}16Q24^{EncodeBatchFrame=@@@@^{NSArray}QQQ^{Graph}}32
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{EncodeBatchFrame=@@@@^{NSArray}QQQ^{Graph}}16
<none specified>
Internal Error: unhandled MPSImageFeatureChannelFormat %lu in [%@ debugDescription]
resultFormat:  %s
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}8^{AutoreleasePoolStackFrame=@}16
<no filters>
Warning: Some parts of the encoded graph appear to be missing. 
 %lu filters, %lu images and %lu states were found.
 Expected: %lu filters, %lu images, %lu states
Error: The indices of the returned graph image nodes are missing.
trainingStyle
, %lu
Filter: %@ {%lu}
Source Images: %lu {%s}
Source States: %lu
Result Images: %lu {%lu}
Result States: %lu
Filter:
  %@
Error: could not unpack resource node. File data segment too small
Error: could not unpack resource node. File version too new
Error: could not unpack resource node. unknown exception %u
MPSNNGraphc
MPSNNGraphA
MPSNNGraphFI
MPSNNGraphResultIsNeeded
MPSNNGraphOutputStateIsTemporary
(%lu)
%lu 
%5s <-- %s <-- 
%lu%s
{%lu%s
, %lu%s
[%lu] %@ %p "%@"
[%lu] %@ %p
%@ %p
%@ "%@"
MPSNNGraph.filterNodes
MPSNNGraph.imageNodes
MPSNNGraph.stateNodes
MPSNNGraph.resultIndexCount
MPSNNGraph.resultIndices
MPSNNGraph.filterCount
MPSNNGraph.imageCount
MPSNNGraph.stateCount
MPSNNGraph.exportedImages
Data
ResourceWrapper.d
ResourceWrapper.hc
ResourceWrapper.h
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu   "%s"
padding policy: %s
(%@ --> %@)
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
Out of memory:  Append node failed. This graph is unlikely to produce expected results.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/NodeList.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNNormalizationGradient.mm
Tf,N,V_alpha
beta
Tf,N,V_beta
delta
Tf,N,V_delta
kernelSize
TQ,R,N,V_kernelSize
alpha:          %f
beta:           %f
delta:          %f
p0:             %f
pm:             %f
ps:             %f
Tf,N,V_p0
Tf,N,V_pm
Tf,N,V_ps
cross_channel_normalization_gradient
cross_channel_normalization_gradient_array
local_contrast_normalization_gradient
local_contrast_normalization_gradient_array
spatial_normalization_gradient
spatial_normalization_gradient_array
MPSCNNCrossChannelNormalizationGradient.kernelSize
MPSCNNCrossChannelNormalizationGradient.alpha
MPSCNNCrossChannelNormalizationGradient.beta
MPSCNNCrossChannelNormalizationGradient.delta
[%@ encode...] info->primaryOffset.z != 0 not supported
[%@ encode...] info->primaryOffset.z == info->secondaryOffset.z failed
[%@ encode...] info->clipRect.origin.z != 0 not supported
MPSCNNSpatialNormalizationGradient.alpha
MPSCNNSpatialNormalizationGradient.beta
MPSCNNSpatialNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.alpha
MPSCNNLocalContrastNormalizationGradient.beta
MPSCNNLocalContrastNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.p0
MPSCNNLocalContrastNormalizationGradient.pm
MPSCNNLocalContrastNormalizationGradient.ps
[%@ initWithSource:labels:lossDescriptor:] descriptor may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MetalPerformanceShaders/MPSNNLossNode.mm
[%@ gradientFilterWithSources:] Error: the MPSNNLoss filter doesn't have a corresponding loss gradient filter.
It produces the gradient directly as its MPSImage destination and consequently acts as its own gradient filter.
Error: loss nodes do not have a separate gradient pass. The gradient image must either be nil or lossNode.resultImage.
inputLabels
T@"MPSNNLabelsNode",R,&,N,V_labels
Internal error: The Loss filter needs loss information. The loss labels are missing. 
[%@ cnnLossDataDescriptorWithData:layout:size:...] invalid data layout type (%lu)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNLoss.mm
layout: %s
size: {%lu, %lu, %lu}
bytesPerRow: %lu
bytesPerImage: %lu
layout
TQ,R,N,V_layout
size
T{?=QQQ},R,N,V_size
bytesPerRow
TQ,N,V_bytesPerRow
bytesPerImage
TQ,N,V_bytesPerImage
[%@ setLabelSmoothing...] labelSmoothing must be in the range [0.0f, 1.0f]
[%@ setLabelSmoothing...] labelSmoothing parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy, MPSCNNLossTypeSigmoidCrossEntropy
[%@ setNumberOfClasses...] number of classes must be greater than 0
[%@ setNumberOfClasses...] number of classes parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy
[%@ setEpsion...] epsilon parameter is valid only for the following loss type(s): MPSCNNLossTypeLog
[%@ setDelta...] delta parameter is valid only for the following loss type(s): MPSCNNLossTypeHuber
[%@ cnnLossDescriptorWithType:reductionType:...] invalid loss type (%lu)
[%@ cnnLossDescriptorWithType:reductionType:...] invalid reduction type (%lu)
lossType: %d
reductionType: %d
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
lossType
TI,N,V_lossType
reductionType
Ti,N,V_reductionType
labelSmoothing
Tf,N,V_labelSmoothing
numberOfClasses
TQ,N,V_numberOfClasses
Method unavailable. Use one of the available interfaces instead.
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] lossImageSize dimensions must be > 1
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels must be valid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= labels.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weightsDescriptor is specified, but the weights data is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) must match the size of labels data ({%lu, %lu, %lu})
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= weights.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
Cannot directly initialize MPSCNNLoss. Use initWithDevice:lossDescriptor: instead.
invalid loss type (%lu)
invalid reduction type (%lu)
TI,R,N,V_lossType
Ti,R,N,V_reductionType
Tf,R,N,V_weight
Tf,R,N,V_labelSmoothing
TQ,R,N,V_numberOfClasses
Tf,R,N,V_delta
MPSDataLayoutHeightxWidthxFeatureChannels
MPSDataLayoutFeatureChannelsxHeightxWidth
Invalid data layout type
MPSCNNLoss
Gradient
MPSCNNLossLossType
MPSCNNLossReductionType
MPSCNNLossWeight
MPSCNNLossLabelSmoothing
MPSCNNLossNumberOfClasses
MPSCNNLossEpsilon
MPSCNNLossDelta
[%@ encode...] state must be valid
[%@ encode...] label weights cannot be used together with a single weight parameter != 1.0f
[%@ encode...] The weights parameter is invalid for this operation; use a single weight value
[%@ encode...] result loss image size invalid; this filter returns a scalar loss value when reduction type is not MPSCNNReductionTypeNone
[%@ encode...] destinationImage size invalid; when reduction type is MPSCNNReductionTypeNone, the destinationImage should be at least as large as the specified clipRect parameter
[%@ encode...] not enough labels data:  offset.z + clipRect.size.depth > number of images in labels data
[%@ encode...] not enough weights data:  offset.z + clipRect.size.depth > number of images in weights data
[%@ encode...] number of non-zero weights cannot be 0 for reduction type MPSCNNReductionTypeSumByNonZeroWeights
[%@ encode...] weights cannot be used together with a single weight != 1.0f
[%@ encode...] weights parameter is invalid for this operation; use a single weight value
[%@ encode...] not enough labels / weights data:  clipRect.size.depth > number of images in labels data
[%@ encode...] internal error
nil != [stateLabels labelsImage], user must pass a labels image through state to calculate loss
nil != sourceImage[0]
nil != stateLabels, user must pass a labels state to calculate loss
nil != srcImage[bIdx]
nil != [stateLabels weightsImage], user must pass a weights image if first weights image is passed
gridWidth != [stateLabels labelsImage].width, the labels in state must be the same dimension as input image
gridHeight == [stateLabels labelsImage].height, the labels in state must be the same dimension as input image
((info->src.image.featureChannels) + 3) / 4) == (([stateLabels labelsImage].featureChannels + 3) / 4), the labels in state must be the same dimension as input image
LossBatch
LossFinalizeBatch
Cannot directly initialize MPSCNNUpsamplingGradient. Use one of the sub-classes of MPSCNNUpsamplingGradient.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNUpsamplingGradient.mm
MPSCNNUpsamplingGradient_tex2d_tex2d_general
MPSCNNUpsamplingGradient_tex2darray_tex2darray_general
MPSCNNUpsamplingGradient_tex2d_tex2d_special_scaleFactor2
MPSCNNUpsamplingGradient_tex2darray_tex2darray_special_scaleFactor2
MPSCNNUpsamplingGradient_bilinear_tex2d_tex2d_general_float32
MPSCNNUpsamplingGradient_bilinear_tex2darray_tex2darray_general_float32
MPSCNNUpsamplingGradient_bilinear_tex2d_tex2d_special_scaleFactor2_float32
MPSCNNUpsamplingGradient_bilinear_tex2darray_tex2darray_special_scaleFactor2_float32
MPSCNNUpsamplingGradient.filterType
MPSCNNUpsamplingGradient.scaleFactorX
MPSCNNUpsamplingGradient.scaleFactorY
Interleaved per pixel layout not supported on OSX
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNConvolutionOSX.mm
copyWeightsAndBiasesDepthwise
copyWeightsAndBiases
export
reloadForward
reloadBackward
cnnConv_Update_Depthwise
cnnConv_Update_reduction
cnnConvArray_winograd_2x2_3x3_32x32_256
cnnConvArray_winograd_2x2_3x3_32x4_128
cnnConvArray_winograd_2x2_3x3_16x32_256
cnnConvArray_32x32_64
cnnConvArray_32x32_128
cnnConvArray_32x64_64
cnnConvArray_32x64_128
cnnConvArray_64x32_64
cnnConvArray_64x32_128
cnnConvArray_64x64_64
cnnConvArray_64x64_128
cnnConvArray_64x64_256
cnnConvArray_16x128_128
cnnConvArray_32x32_1x1_4x4x8_128
depthwiseConvolution
cnnConv_Update_32x32
cnnConv_Update_32x64
cnnConv_Update_64x32
cnnConv_Update_64x64
cnnConv_Update_64x64_4x2x2
cnnConv_Update_64x64_1x1x16
parent filter: %p
format:          %d
handle:          <%p> %@
                 %@
allocator:       %p
exportFromGraph: %s
synchronize:     %s
stopGradient:    %s
handle
T@"<MPSHandle>",&,N,V_handle
imageAllocator
T@"<MPSImageAllocator>",&,N,V_imageAllocator
exportFromGraph
TB,N,V_exportFromGraph
synchronizeResource
TB,N,V_synchronize
stopGradient
TB,N,V_stopGradient
parent filter: %p
handle: <%p> %@
synchronize: %s
        %@
[%@ initWithSourceImages...] sourceImages may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNGraphNodes.mm
[%@ initWithSourceImages...] sourceImages.count may not be 0
[%@ initWithSourceImages...] sourceStates.count may not be 0
%@, %p
%@ "%@"
source images:  %@
source states:  %@
resultImage:    %p
result states:  %@
padding policy: 
<no label>
[%@ newFilterNode] Internal error: child class fails to override this method.
[%@ gradientFilterWithSources:] This is not a unary filter. Please use gradientFiltersWithSources: (extra 's') instead. 
[%@ gradientFilterWithSources:] Internal error: this isn't a unary filter and needs to override this method to return multiple filters
resultImage
T@"MPSNNImageNode",R,N,V_resultImage
resultState
T@"MPSNNStateNode",R,N
resultStates
T@"NSArray",R,N
paddingPolicy
T@"<MPSNNPadding>",&,N,V_paddingPolicy
label
T@"NSString",C,V_label
gradient for %p "%@"
gradient for %p
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNSlice.mm
Source Index: %lu
slice_along_feature_channels_array_array
slice_along_width_height_array_array
slice_along_width_height
slice_along_width_height_noarray_array
slice_along_width_height_array_noarray
Error: EncodeSlice() encountered caller of wrong class type
Insufficient number of feature channels in destination %p
MPSNNConcatenationGradient.sourceIndex
[%@ encode...] filter initialized with no feature channels.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalization.mm
Cannot create state for images containing multiple images.
data source: %p %@
epsilon: %g
T@"<MPSCNNInstanceNormalizationDataSource>",R,&,N,V_dataSource
gamma
T@"<MTLBuffer>",R,N
[%@ gradientForGamma] Gradient state does not contain a buffer for gamma gradient values.
[%@ gradientForBeta] Gradient state does not contain a buffer for beta gradient values.
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
instance normalization filter: %@
feature channels: %lu
epsilon: %g
instanceNormalization
T@"MPSCNNInstanceNormalization",R,&,N,V_instanceNormalization
gradientForGamma
gradientForBeta
imageInstanceNormalizationThreadgroupSum
imageInstanceNormalizationImageSum
imageInstanceNormalization
[%@ encode...] filter initialized with %lu feature channels but destination (after offset) contains only %lu feature channels.
[%@ encode...] filter initialized with %lu feature channels but source (after offset) contains only %lu feature channels.
kMPSCNNInstanceNormalization.s
kMPSCNNInstanceNormalization.o
resize width (%lu) must be > 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNCropAndResize.mm
resize height (%lu) must be > 0
Number of regions (%lu) must be > 0
regions argument cannot be a nil value
MPSRegion origin.z must be 0
MPSRegion size.depth must be 0
CropAndResizeBilinearOperation
resizeWidth
TQ,R,N,V_resizeWidth
resizeHeight
TQ,R,N,V_resizeHeight
numberOfRegions
TQ,R,N,V_numberOfRegions
regions
Tr^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}},R,N,V_regions
crop_and_resize_bilinear_tex2d_tex2d
crop_and_resize_bilinear_tex2d_tex2darray
crop_and_resize_bilinear_tex2d_tex2d_float32
crop_and_resize_bilinear_tex2d_tex2darray_float32
MPSNNCropAndResizeBilinear.resizeWidth
MPSNNCropAndResizeBilinear.resizeHeight
MPSNNCropAndResizeBilinear.numberOfRegions
MPSNNCropAndResizeBilinear.regions
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNPooling.mm
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
dilationRateX (%lu) must be > 0
dilationRateY (%lu) must be > 0
dilationRateX: %lu
dilationRateY: %lu
dilationRateX
dilationRateY
MPSCNNPooling.kernelWidth
MPSCNNPooling.kernelHeight
MPSCNNPooling.strideX
MPSCNNPooling.strideY
[%@ encode...] unsupported feature channels layout (MPSImageFeatureChannelsInterleavedPerPixel)
MPSCNNPooling_horizontal_tex2d_tex2d_max
MPSCNNPooling_horizontal_tex2darray_tex2darray_max
MPSCNNPooling_horizontal2_tex2d_tex2d_max
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max
MPSCNNPooling_vertical_tex2d_tex2d_max
MPSCNNPooling_vertical_tex2darray_tex2darray_max
MPSCNNPooling_2x2_tex2d_tex2d_max
MPSCNNPooling_2x2_tex2darray_tex2darray_max
MPSCNNPooling_3x3_tex2d_tex2d_max
MPSCNNPooling_3x3_tex2darray_tex2darray_max
MPSCNNPooling_new_tex2d_tex2d_max_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_vertical_tex2d_tex2d_max_swEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_2x2_tex2d_tex2d_max_swEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_3x3_tex2d_tex2d_max_swEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg
MPSCNNPooling_horizontal2_tex2d_tex2d_avg
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg
MPSCNNPooling_vertical_tex2d_tex2d_avg
MPSCNNPooling_vertical_tex2darray_tex2darray_avg
MPSCNNPooling_2x2_tex2d_tex2d_avg
MPSCNNPooling_2x2_tex2darray_tex2darray_avg
MPSCNNPooling_3x3_tex2d_tex2d_avg
MPSCNNPooling_3x3_tex2darray_tex2darray_avg
MPSCNNPooling_new_tex2d_tex2d_avg_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_vertical_tex2d_tex2d_avg_shEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_2x2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_3x3_tex2d_tex2d_avg_shEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_2
cnnPoolingGeneric
cnnPoolingGeneric_ppt2
MPSCNNPooling.padSizeX
MPSCNNPooling.padSizeY
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationGradient.mm
imageBatchNormalizationGradient
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBinaryKernel.mm
<NULL>
primaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld  len: %ld}
secondaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destChannelOffset{%ld} 
device:        %p
primary edge mode:     %s
secondary edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
2nd KernelSize: {%lu x %lu}
primary stride:      {%lu x %lu}
secondary stride:      {%lu x %lu}
dilation rate:        {%lu x %lu}
2nd dilation rate:    {%lu x %lu}
backwards?  %s
broadcasting?  %s
padding:       %@
MPSImageEdgeModeClamp
MPSImageEdgeModeZero
destinationFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelOffset must be multiple of 4
secondarySourceFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelMaxCount must be multiple of 4
secondarySourceFeatureChannelMaxCount must be multiple of 4
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encode...] primary source may not be nil
[%@ encode...] secondary source may not be nil
[%@ %@] Error: the primary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the primary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the secondary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the secondary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the destination image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  primary source image is a temporary image with readCount of 0.
Backing texture for primary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  secondary source image is a temporary image with readCount of 0.
Backing texture for secondary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  destination image is a temporary image with readCount of 0.
Backing texture for destination image is no longer valid. image=%p
Feature Channel Layout of primary source and destination does not match
Feature Channel Layout of secondary source and destination does not match
Primary source %p texture type (%lu) is unsupported
Secondary source %p texture type (%lu) is unsupported
Primary source %p texture format %lu must support filtering.
Secondary source %p texture format %lu must support filtering.
Primary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Secondary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Primary source MTLTextureType2D must have primaryOffset.z = 0
Primary source MTLTextureType2D must have clipRect.size.depth = 1
Primary source MTLTextureTypeArray2D must have 0 <= primaryOffset.z < primaryImage.numberOfImages
Primary source MTLTextureTypeArray2D must have clipRect.size.depth such that _primaryOffset.z + clipRect.depth < primaryImage.numberOfImages
Secondary source MTLTextureType2D must have secondaryOffset.z = 0
Secondary source MTLTextureType2D must have clipRect.size.depth = 1
Secondary source MTLTextureTypeArray2D must have 0 <= secondaryOffset.z < secondaryImage.numberOfImages
Secondary source MTLTextureTypeArray2D must have clipRect.size.depth such that _secondaryOffset.z + clipRect.depth < secondaryImage.numberOfImages
Destination %p texture type (%lu) is unsupported
Destination %p texture format %lu  must be writable.
Destination %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Destination MTLTextureType2D must have clipRect.origin.z = 0
Destination MTLTextureType2D must have clipRect.size.depth = 1
Destination MTLTextureTypeArray2D must have 0 <= clipRect.origin.z < dest.numberOfImages
Destination MTLTextureTypeArray2D must have clipRect.size.depth such that clipRect.origin.z + clipRect.depth < dest.numberOfImages
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of primary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of secondary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture.  Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of primary source
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of secondary source
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of destination
[%@ encode...] the primary offset.z may not be negative
[%@ encode...] the secondary offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > primaryImages.count(%lu)
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > secondaryImages.count(%lu)
[%@ encode...] each of the individual primary source images in a batch must have numberOfImages = 1
[%@ encode...] each of the individual secondary source images in a batch must have numberOfImages = 1
[%@ encode...] error: all primary source image sizes must match
[%@ encode...] error: all secondary source image sizes must match
[%@ encode...] error: all primary source number of feature channels must match
[%@ encode...] error: all secondary source number of feature channels must match
[%@ %@] Error: the primary source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ %@] Error: the secondaryImage source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ encode...] each of the individual destination images in a batch must have numberOfImages = 1
[%@ encode...] error: all destination image sizes must match
[%@ encode...] error: all destination number of feature channels must match
[%@ batchEncode...] out of memory: unable to allocate storage to hold encode arguments on device.
[%@ destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset] Error:
 This is a binary filter. sourceImages should be an array of at least length 2.
%@: Error for filters that support broadcasting the input source image widths must match (or be 1)
%@: Error for filters that support broadcasting the input source image heights must match (or be 1)
%@: Error for filters that support broadcasting the input source image count must match (or be 1)
%@: Error for filters that support broadcasting the number of input source image feature channels must match (or be 1)
sourceWidth
sourceHeight
[%@ destinationImageDescriptorForSouceImage:] probable internal error 8: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error H: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error 16: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error 32: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] unhandled pixel encoding: 0x%16.16llx
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch count is smaller than the primaryImage batch count
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
primaryOffset
T{?=qqq},N,V_primaryOffset
secondaryOffset
T{?=qqq},N,V_secondaryOffset
clipRect
T{?={?=QQQ}{?=QQQ}},N,V_clipRect
destinationFeatureChannelOffset
TQ,N,V_destinationFeatureChannelOffset
primarySourceFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelOffset
secondarySourceFeatureChannelOffset
TQ,N,V_secondarySourceFeatureChannelOffset
primarySourceFeatureChannelMaxCount
TQ,N,V_primarySourceFeatureChannelMaxCount
secondarySourceFeatureChannelMaxCount
TQ,N,V_secondarySourceFeatureChannelMaxCount
primaryEdgeMode
TQ,N,V_primaryEdgeMode
secondaryEdgeMode
TQ,N,V_secondaryEdgeMode
primaryKernelWidth
TQ,R,N,V_primaryKernelWidth
primaryKernelHeight
TQ,R,N,V_primaryKernelHeight
secondaryKernelWidth
TQ,R,N,V_secondaryKernelWidth
secondaryKernelHeight
TQ,R,N,V_secondaryKernelHeight
primaryDilationRateX
TQ,R,N,V_primaryDilationRateX
primaryDilationRateY
TQ,R,N,V_primaryDilationRateY
secondaryDilationRateX
TQ,R,N,V_secondaryDilationRateX
secondaryDilationRateY
TQ,R,N,V_secondaryDilationRateY
isBackwards
TB,R,N,V_isBackwards
isStateModified
padding
T@"<MPSNNPadding>",&,N,V_padding
Internal error: [%@ encodeWithCoder:] unavailable
MPSCNNBinaryKernel.primaryOffset.x
MPSCNNBinaryKernel.primaryOffset.y
MPSCNNBinaryKernel.primaryOffset.z
MPSCNNBinaryKernel.secondaryOffset.x
MPSCNNBinaryKernel.secondaryOffset.y
MPSCNNBinaryKernel.secondaryOffset.z
MPSCNNBinaryKernel.clipRect.origin.x
MPSCNNBinaryKernel.clipRect.origin.y
MPSCNNBinaryKernel.clipRect.origin.z
MPSCNNBinaryKernel.clipRect.size.width
MPSCNNBinaryKernel.clipRect.size.height
MPSCNNBinaryKernel.clipRect.size.depth
MPSCNNBinaryKernel.destinationFeatureChannelOffset
MPSCNNBinaryKernel.sourceFeatureChannelOffset1
MPSCNNBinaryKernel.sourceFeatureChannelOffset2
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount1
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount2
MPSCNNBinaryKernel.primaryEdgeMode
MPSCNNBinaryKernel.secondaryEdgeMode
MPSCNNBinaryKernel.checkFlags
MPSCNNBinaryKernel.kernelWidth
MPSCNNBinaryKernel.kernelHeight
MPSCNNBinaryKernel.secondaryKernelWidth
MPSCNNBinaryKernel.secondaryKernelHeight
MPSCNNBinaryKernel.primaryStride.x
MPSCNNBinaryKernel.primaryStride.y
MPSCNNBinaryKernel.secondaryStride.x
MPSCNNBinaryKernel.secondaryStride.y
MPSCNNBinaryKernel.dilationRate.x
MPSCNNBinaryKernel.dilationRate.y
MPSCNNBinaryKernel.secondaryDilationRate.x
MPSCNNBinaryKernel.secondaryDilationRate.y
MPSCNNBinaryKernel.isBackward
MPSCNNBinaryKernel.supportsBroadcasting
MPSCNNBinaryKernel.data
MPSCNNBinaryKernel.padding
MPSCNNBinaryKernel.data2
MPSCNNBinaryKernel.allocator
MPSCNNBinaryImageFilter.className
MPSCNNBinaryImageFilter.class
Error: attempted to extract gamma buffer from temporary MPSState with readCount of 0.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationState.mm
Error: attempted to extract beta buffer from temporary MPSState with readCount of 0.
Error: attempted to extract mean buffer from temporary MPSState with readCount of 0.
Error: attempted to extract variance buffer from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForGamma from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForBeta from temporary MPSState with readCount of 0.
batchNormalization
T@"MPSCNNBatchNormalization",R,&,N,V_batchNormalization
mean
variance
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNResize.mm
ResizeBilinearOperation
resize_bilinear_tex2d_tex2d
resize_bilinear_tex2darray_tex2darray
resize_bilinear_tex2d_tex2d_float32
resize_bilinear_tex2darray_tex2darray_float32
MPSNNResizeBilinear.resizeWidth
MPSNNResizeBilinear.resizeHeight
MPSNNResizeBilinear.alignCorners
T{?=QQQ},R,N,V_maskStride
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNDropoutNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNDropoutNodes.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid neuron type (%lu)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNNeuron.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid initialization method for the following neuron type(s): MPSCNNNeuronPReLU
[%@ cnnNeuronPReLUDescriptorWithData:...] data must be valid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid (not a multiple of sizeof(float))
neuronType: %s
a: %f 
b: %f 
c: %f 
data: %p
neuronType: %s
a: %f 
b: %f 
c: %f
Tf,N,V_a
Tf,N,V_b
Tf,N,V_c
data
T@"NSData",&,N,V_data
invalid neuron type (%lu)
[%@ initWithDevice:neuronDescriptor:...] data in neuron descriptor must be valid
[%@ initWithDevice:neuronDescriptor:...] data length (%lu) is invalid
Cannot directly initialize MPSCNNNeuron. Use initWithDevice:neuronDescriptor: or one of the sub-classes of MPSCNNNeuron
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation. See the requirements listed for the newBufferWithBytesNoCopy:length:options:deallocator Metal API.
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation
v24@?0^v8Q16
MPSCNNNeuronTypeNone  (f(x) = x)
MPSCNNNeuronTypeReLU  (f(x) = x >= 0 ? x : a * x)
MPSCNNNeuronTypeLinear  (f(x) = a * x + b)
MPSCNNNeuronTypeSigmoid  (f(x) = 1 / (1 + e^-x))
MPSCNNNeuronTypeHardSigmoid  (f(x) = clamp((x * a) + b, 0, 1))
MPSCNNNeuronTypeTanH    (f(x) = a * tanh(b * x))
MPSCNNNeuronTypeAbsolute  (f(x) = fabs(x))
MPSCNNNeuronTypeSoftPlus  (f(x) = a * log(1 + e^(b * x)))
MPSCNNNeuronTypeSoftSign  (f(x) = x / (1 + abs(x)))
MPSCNNNeuronTypeELU   (f(x) = x >= 0 ? x : a * (exp(x) - 1))
MPSCNNNeuronTypePReLU  (f(x[i]) = x[i] >= 0 ? x[i] : a[i] * x[i]), i in [0,featureChannels-1]
MPSCNNNeuronTypeReLUN  (f(x) = min((x >= 0 ? x : a * x), b))
MPSCNNNeuronTypePower  (f(x) = (a * x + b) ^ c)
MPSCNNNeuronTypeExponential  (f(x) = c ^ (a * x + b))
MPSCNNNeuronTypeLogarithm  (f(x) = log_c(a * x + b))
<invalid/missing type>
neuronType: %s
a: %f
b: %f
c: %f
data: %p
neuronType: %s
a: %f
b: %f
c: %f
Ti,R,N,V_neuronType
T@"NSData",R,&,N,V_data
Cannot call this initializer on this class.
MPSCNNNeuronTypeName
MPSCNNNeuronA
MPSCNNNeuronB
MPSCNNNeuronC
MPSCNNNeuronAArrayIsNil
MPSCNNNeuronAArrayLength
MPSCNNNeuronAArray
cnnNeuronGradient
cnnNeuron
MPSCNNNeuronGradientTypeName
MPSCNNNeuronGradientA
MPSCNNNeuronGradientB
MPSCNNNeuronGradientC
MPSCNNNeuronGradientAArrayIsNil
MPSCNNNeuronGradientAArrayLength
MPSCNNNeuronGradientAArray
Cannot directly initialize MPSNNReduceUnary. Use one of the sub-classes of MPSNNReduceUnary.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSNNReduce.mm
ReduceOperation: %lu
Cannot directly initialize MPSNNReduceBinary. Use one of the sub-classes of MPSNNReduce.
primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_primarySourceClipRect
secondarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_secondarySourceClipRect
doWeightedSumByNonZeroWeights
reduce_min_row_simd_rgba
reduce_min_column_simd_rgba
reduce_min_feature_channels_simd_rgba
reduce_argument_min_feature_channels_simd_rgba_uint
reduce_argument_min_feature_channels_simd_rgba_float
reduce_max_row_simd_rgba
reduce_max_column_simd_rgba
reduce_max_feature_channels_simd_rgba
reduce_argument_max_feature_channels_simd_rgba_uint
reduce_argument_max_feature_channels_simd_rgba_float
reduce_mean_row_simd_rgba
reduce_mean_column_simd_rgba
reduce_mean_feature_channels_simd_rgba
reduce_mean_feature_channels_and_weight_simd_rgba
reduce_array_min_row_simd_rgba
reduce_array_min_column_simd_rgba
reduce_array_min_feature_channels_simd_rgba
reduce_array_argument_min_feature_channels_simd_rgba_uint
reduce_array_argument_min_feature_channels_simd_rgba_float
reduce_array_max_row_simd_rgba
reduce_array_max_column_simd_rgba
reduce_array_max_feature_channels_simd_rgba
reduce_array_argument_max_feature_channels_simd_rgba_uint
reduce_array_argument_max_feature_channels_simd_rgba_float
reduce_array_mean_row_simd_rgba
reduce_array_mean_column_simd_rgba
reduce_array_mean_feature_channels_simd_rgba
reduce_array_mean_feature_channels_and_weight_simd_rgba
reduce_min_row_quadshuffle_rgba
reduce_min_column_quadshuffle_rgba
reduce_max_row_quadshuffle_rgba
reduce_max_column_quadshuffle_rgba
reduce_mean_row_quadshuffle_rgba
reduce_mean_column_quadshuffle_rgba
reduce_array_min_row_quadshuffle_rgba
reduce_array_min_column_quadshuffle_rgba
reduce_array_min_feature_channels_quadshuffle_rgba
reduce_array_argument_min_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_min_feature_channels_quadshuffle_rgba_float
reduce_array_max_row_quadshuffle_rgba
reduce_array_max_column_quadshuffle_rgba
reduce_array_max_feature_channels_quadshuffle_rgba
reduce_array_argument_max_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_max_feature_channels_quadshuffle_rgba_float
reduce_array_mean_row_quadshuffle_rgba
reduce_array_mean_column_quadshuffle_rgba
reduce_array_mean_feature_channels_quadshuffle_rgba
reduce_array_mean_feature_channels_and_weight_quadshuffle_rgba
MPSNNReduce.clipRectSource.origin.x
MPSNNReduce.clipRectSource.origin.y
MPSNNReduce.clipRectSource.origin.z
MPSNNReduce.clipRectSource.size.width
MPSNNReduce.clipRectSource.size.height
MPSNNReduce.clipRectSource.size.depth
MPSNNReduce.reduceOp
MPSNNReduce.weight
MPSNNReduce.primarySourceClipRect.origin.x
MPSNNReduce.primarySourceClipRect.origin.y
MPSNNReduce.primarySourceClipRect.origin.z
MPSNNReduce.primarySourceClipRect.size.width
MPSNNReduce.primarySourceClipRect.size.height
MPSNNReduce.primarySourceClipRect.size.depth
MPSNNReduce.secondarySourceClipRect.origin.x
MPSNNReduce.secondarySourceClipRect.origin.y
MPSNNReduce.secondarySourceClipRect.origin.z
MPSNNReduce.secondarySourceClipRect.size.width
MPSNNReduce.secondarySourceClipRect.size.height
MPSNNReduce.secondarySourceClipRect.size.depth
[<MPSCNNConvolutionDataSource> initWithSource:neuronInfo:batchNorm] Internal error: attempted to overwrite a convolution data source descriptor batch norm info with another set of batch norm info.
These should not be coalesced.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MetalPerformanceShaders/BackwardsCompatibility.mm
rangesForUInt8Kernel
rangesForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method 
lookupTableForUInt8Kernel
lookupTableForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method
MPSWeightsWrapper_SecureCoding.c0
MPSWeightsWrapper_SecureCoding.o0
MPSWeightsWrapper_SecureCoding.c1
MPSWeightsWrapper_SecureCoding.o1
MPSWeightsWrapper_SecureCoding.c2
MPSWeightsWrapper_SecureCoding.o2
MPSWeightsWrapper_SecureCoding.it
MPSWeightsWrapper_SecureCoding.ia
MPSWeightsWrapper_SecureCoding.ib
MPSWeightsWrapper_SecureCoding.ic
MPSWeightsWrapper_SecureCoding.id
Error: expected secure coding support from object: 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNKernel.mm
offset:        {%ld,%ld,%ld} sourceFeatureChannelRange{offset: %ld, len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destinationFeatureChannelOffset{%ld} 
device:        %p
edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
stride:        {%lu x %lu}
dilation factor {%lu x %lu}
backwards?  %s
destinationImageAllocator: %@
padding:       %@
sourceFeatureChannelOffset must be multiple of 4
setSourceFeatureChannelMaxCount must be multiple of 4
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: sourceImage batch may not be NULL
[%@ encode...] Error: commandBuffer may not be nil]
[%@ encode...] Error: source may not be nil
[%@ encode...] Error: destination may not be nil
[%@ encode...] Error: options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ encode...] Error: source feature channel offset (%lu) is too large to fit in the source image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) is too large to fit in the destination image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) must be divisible by 4.
Other values would require read-modify-write on individual texels which is not supported by some hardware and a problem for concurrent operation everywhere.
[%@ encode...]: Error: non-zero source feature channel offset unsupported for compound MPSImages. Use a MPSImageBatch instead.
[%@ %@] Error: the source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
Feature Channel Layout of source and destination does not match
Source %p texture type (%lu) is unsupported
Source %p texture format %lu  must support filtering.
Source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Source MTLTextureType2D must have offset.z = 0
Source MTLTextureType2D must have clipRect.size.depth = 1
Source MTLTextureTypeArray2D must have 0 <= offset.z < source.numberOfImages
Source MTLTextureTypeArray2D must have clipRect.size.depth such that _offset.z + clipRect.depth < source.numberOfImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: the filter edge mode must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: The number of source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for source image must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of source
[%@ encode...] Error: an error (%s) was encountered preventing this kernel from encoding.
[%@ encode...] the offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ encode...] Error invalid operation: offset.z(%d) < 0
[%@ encode...] each of the individual source images in a batch must have numberOfImages = 1
[%@ encode...] error: all source image sizes must match
[%@ encode...] error: all source number of feature channels must match
[%@ %@] Error: the source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
offset
T{?=qqq},N,V_offset
sourceFeatureChannelOffset
TQ,N,V_sourceFeatureChannelOffset
sourceFeatureChannelMaxCount
TQ,N,V_sourceFeatureChannelMaxCount
edgeMode
TQ,N,V_edgeMode
kernelWidth
TQ,R,N,V_kernelWidth
kernelHeight
TQ,R,N,V_kernelHeight
strideInPixelsX
TQ,R,N,V_strideInPixelsX
strideInPixelsY
TQ,R,N,V_strideInPixelsY
TQ,R,N,V_dilationRateX
TQ,R,N,V_dilationRateY
%s | %s | %s%s%s
%s, %s, %s%s%s
[MPSNNDefaultPadding paddingWithMethod:]: Can not create a new object with a custom sizing policy.
You must implement your own object using the MPSNNPadding Policy.
MPSCreatePaddingPolicy(): invalid / unknown bits in MPSNNPaddingMethod.
Error: overrelease of MPS owned MPSNNDefaultPadding object:
  %@
%@  variant: %@
MPSCNNKernel.offset.x
MPSCNNKernel.offset.y
MPSCNNKernel.offset.z
MPSCNNKernel.clipRect.origin.x
MPSCNNKernel.clipRect.origin.y
MPSCNNKernel.clipRect.origin.z
MPSCNNKernel.clipRect.size.width
MPSCNNKernel.clipRect.size.height
MPSCNNKernel.clipRect.size.depth
MPSCNNKernel.destinationFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelMaxCount
MPSCNNKernel.edgeMode
MPSCNNKernel.checkFlags
MPSCNNKernel.kernelWidth
MPSCNNKernel.kernelHeight
MPSCNNKernel.stride.x
MPSCNNKernel.stride.y
MPSCNNKernel.dilation.x
MPSCNNKernel.dilation.y
MPSCNNKernel.isBackward
MPSCNNKernel.data
MPSCNNKernel.padding
MPSCNNKernel.data2
MPSCNNKernel.allocator
[%@ resource] Internal error: unhandled resource type
/BuildRoot/Library/Caches/com.apple.xbs/Binaries/MetalImage_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSStateInternal.h
SizeValidOnly
SizeSame
SizeFull
Size_reserved
AlignCentered
AlignTopLeft
AlignBottomRight
Align_reserved
AddRemainderToTopLeft
AddRemainderToTopRight
AddRemainderToBottomLeft
AddRemainderToBottomRight
MPSNNPaddingMethod.CustomWhitelistForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.Custom (inhibits node fusion)
MPSNNPaddingMethod.Custom (whitelist for node fusion)
MPSNNPaddingMethod.ExcludeEdges
MPSNNPaddingMethod.ExcludeEdges | CustomWhitelistForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.ExcludeEdges | Custom (inhibits node fusion)MPSNNPaddingMethod.ExcludeEdges | Custom (whitelist for node fusion)
kMPSNNPaddingMethod_vers
kMPSNNPaddingMethod
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelWidth may not be 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSCNNPoolingNodes.mm
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelHeight may not be 0
MPS internal error: Need to override newFilterNodeForDevice for %@
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelWidth may not be 0
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelHeight may not be 0
[%@ initWithGradientImages:forwardFilter:] Error forwardFilter %p is not a MPSCNNPoolingNode
[%@ initWithGradientImages:forwardFilter:] Error: the filter <%p> is not a MPSCNNDilatedPoolingMaxNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixNeuronGradient.mm
[%@ apply...] source gradient matrix may not be nil
Matrices/vectors contain batches, batching not supported.
Only bias gradient vector value types of MPSDataTypeFloat32 are supported.
MatrixNeuronGradient
MPSMatrixNeuronGradient._alpha;
MPSMatrixNeuronGradient._sourceNumberOfFeatureVectors;
MPSMatrixNeuronGradient._sourceInputFeatureChannels;
MPSMatrixNeuronGradient._neuronType;
MPSMatrixNeuronGradient._neuronA;
MPSMatrixNeuronGradient._neuronB;
MPSMatrixNeuronGradient._neuronC;
MPSMatrixNeuronGradient._perChannelNeuronA;
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}32@?0@"MPSKernel"8r^^v16^Q24
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}32@?0^{_NSZone=}8r^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}16@"<MTLDevice>"24
Error: unable to read node data for %@ <%p>. File (or data chunk within file) too small.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/FilterNodeConstructors.mm
Error: unable to read node data for %@ <%p>. File version too new.
Error: unable to read node data for %@ <%p>. File version too old.
Error: unable to read node data for %@ <%p>. File could not be parsed.
Error: unable to read node data for %@ <%p>. Unhandled / unknown error %u.
MPSInternalError: Cant copy object with internal id out of bounds.
MPSInternalError: attempted to copy object type %lu but ended up with object type %lu
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNSoftMaxGradient.mm
softmax_gradient
softmax_gradient_array
softmax_gradient_multipass
softmax_gradient_multipass_array
log_softmax_gradient
log_softmax_gradient_array
log_softmax_gradient_multipass
log_softmax_gradient_multipass_array
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->secondarySrc.featureChannels - info->secondarySourceFeatureChannelOffset) failed
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->dest.featureChannels) failed
[%@ initWithSource:] Probable error: concatenate a image with nothing?
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSNNConcatenationNode.mm
{%lu x %lu x %lu}[%lu](offset:0)
"%@"
%s (%lu) [%s] -> {%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
%s (%lu) %lu*[%s] -> %lu*{%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the gradient state was not produced by a MPSNNConcatenationNode.
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the sourceImage provided was not among the input images to the MPSNNConcatenationNode
TQ,N,V_kernelWidth
TQ,N,V_kernelHeight
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNSpatialNormalizationNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSCNNNormalizationNodes.mm
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNLocalContrastNormalizationNode
kernelSizeInFeatureChannels
TQ,N,V_kernelSizeInFeatureChannels
[%@ initWithSource:dataSource:] dataSource may not be NULL
TQ,N,V_trainingStyle
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:instanceNormalizationState:
instance normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
flags
TQ,N,V_flags
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNBatchNormalizationNode
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
batch normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU batch normalization update pass because the data source doesn't implement -updateGammaAndBetaWithBatchNormalizationState:
Batch normalization node calculates statistics
Please initialize the %@ class with initWithDevice:weights:
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNInnerProduct.mm
Number of groups for inner product should be 1
strideX for inner product should be 1
strideY for inner product should be 1
Please initialize the %@ class with initWithDevice:convolutionDescriptor:kernelWeights:biasTerms
initializer unavailable
strideX should be 1 for fully connected kernel
strideY should be 1 for fully connected kernel
Number of groups should be 1 fully connected kernel
Kernel width and src width must match for fully connected kernel
Kernel height and src height must match for fully connected kernel
clipRect width must be 1 for fully connected kernel
clipRect height must be 1 for fully connected kernel
[%@ initWithSource:convolutionDescriptor:kernelWeights:biasTerms]: kernel weights may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/MPSCNNConvolutionGraphNodes.mm
convolutionState
T@"MPSCNNConvolutionStateNode",R,N
accumulatorPrecision
TQ,N,V_accumulatorPrecision
convolutionGradientState
T@"MPSCNNConvolutionGradientStateNode",R,N
MPSGraph internal error: cant append filter after filter creation.
MPSGraph internal error: convolution filter node missing data source?
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: gradient state may not be nil
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState doesn't have a parent convolution with a dataSource.
There are no weights to use here and MPS can not continue.
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState creator isn't a convolution node.
There are no weights to use here and MPS can not continue.
MPSNNTrainingStyleUpdateDeviceNone
MPSNNTrainingStyleUpdateDeviceCPU
MPSNNTrainingStyleUpdateDeviceGPU
MPSNNTrainingStyleUpdateDeviceAll
training style: %@
CNNConvolutionGradientFilterNode::InitFilter() Error: unexpectedly could not get a data source from the inference convolution node.
Can not continue...
Err: Unable to trigger -load on MPSCNNConvolutionDataSource: <%p>
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights must have a descriptor
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights.descriptor can not contain an integrated neuron.
A separate node must be built for neurons for training.
The graph will automatically integrate them later for inference.
Error while unpacking a convolution gradient node: a valid dataSource could not be found in either the gradient node or its partner convolution to initialize the convolution weights
Error: could not updates weights for convolution without a MPSCNNConvolutionDataSource to talk to.
Perhaps your data source doesn't conform to <NSSecureCoding> and couldn't be saved?
Perhaps you created the convolution gradient node with a nil data source and there is no matching convolution node that has a datasource?
Error: can not update data source "%@" on GPU, because it does not implement updateWeightasAndBiasesWithCommandBuffer:sourceState:gradientState:.
convolution gradient weight update pass: the gradients may not be in a temporary image for CPU update.
Find the state result from the forward convolution and set it to be .exportFromGraph = YES
Error: can not update data source "%@" on GPU, because it does not implement -updateWeightasAndBiasesWithCommandBuffer:sourceState:gradient:.
convolution gradient weight update pass: the weight gradients may not be in a temporary state for CPU update.
convolution gradient weight update pass: the weights may not be in a temporary state for CPU update.
%@.convolutionGradientState is an invalid operation.  The class doesn't support producing state.
%@.convolutionState is an invalid operation.  The class doesn't support producing state.
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionGradientState
fused: %s,  a = %g b = %g c = %g
imageInitialSumBase
imageThreadgroupSumBase
Error: [%@ load] returned NO.  MPS can wait no longer for data and can not proceed.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Graph/DataSourceWrappers.mm
Error: [%@ descriptor] returned nil.  MPS can wait no longer for data and can not proceed.
Error: [MPSCNNConvolutionDescriptor copyWithZone:] failed
Error: convolution data source over purged: 
aggregation container for %@ "%@"
aggregation container for %@ "%@"
convolution descriptor: %@batch norm data source: %@neuron descriptor:      %@
aggregation container for %@ "%@"
convolution descriptor: %@neuron descriptor:      %@
initWithCoder:
encodeWithCoder:
MPSConvolutionDataSourceWrapper.dataSource
MPSConvolutionDataSourceWrapper.c
MPSConvolutionDataSourceWrapper.batchNorm
MPSConvolutionDataSourceWrapper.b
MPSConvolutionDataSourceWrapper.neuron
MPSConvolutionDataSourceWrapper.n
Error: Can not encode convolution data source. It doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch norm descriptor doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch neuron doesn not conform to NSSSecureCoding.
lossXYDescriptor: 
lossWHDescriptor: 
lossConfidenceDescriptor: 
lossClassesDescriptor: 
reductionType = %d
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
%lu) (w, h) = (%f, %f)
XYLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_XYLossDescriptor
WHLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_WHLossDescriptor
confidenceLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_confidenceLossDescriptor
classesLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_classesLossDescriptor
rescore
TB,N,V_rescore
scaleXY
Tf,N,V_scaleXY
scaleWH
Tf,N,V_scaleWH
scaleNoObject
Tf,N,V_scaleNoObject
scaleObject
Tf,N,V_scaleObject
scaleClass
Tf,N,V_scaleClass
minIOUForObjectPresence
Tf,N,V_minIOUForObjectPresence
maxIOUForObjectAbsence
Tf,N,V_maxIOUForObjectAbsence
numberOfAnchorBoxes
TQ,N,V_numberOfAnchorBoxes
anchorBoxes
T@"NSData",&,N,V_anchorBoxes
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNYOLOLoss.mm
_reductionType == lossDescriptor.XYLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.WHLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.confidenceLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.classesLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
lossXY: 
lossWH: 
lossConfidence: 
lossClasses: 
reductionType = %d
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
lossXY
T@"MPSCNNLoss",R,&,N,V_lossXY
lossWH
T@"MPSCNNLoss",R,&,N,V_lossWH
lossConfidence
T@"MPSCNNLoss",R,&,N,V_lossConfidence
lossClasses
T@"MPSCNNLoss",R,&,N,V_lossClasses
Tf,R,N,V_scaleXY
Tf,R,N,V_scaleWH
Tf,R,N,V_scaleNoObject
Tf,R,N,V_scaleObject
Tf,R,N,V_scaleClass
Tf,R,N,V_minIOUForObjectPresence
Tf,R,N,V_maxIOUForObjectAbsence
TQ,R,N,V_numberOfAnchorBoxes
T@"NSData",R,&,N,V_anchorBoxes
concat_custom_2D_array
concat_custom_array_array
concat_custom_2D_array_hack
concat_custom_array_array_hack
zeroOutImage
zeroOutImageArray
MPSCNNYOLOLossReductionType
MPSCNNYOLOLossNumberOfAnchorBoxes
kMPSCNNYOLOLoss_scaleXY_Key
kMPSCNNYOLOLoss_scaleWH_Key
kMPSCNNYOLOLoss_scaleNoObject_Key
kMPSCNNYOLOLoss_scaleObject_Key
kMPSCNNYOLOLoss_scaleClass_Key
kMPSCNNYOLOLoss_minIOUForObjectPresence_Key
kMPSCNNYOLOLoss_maxIOUForObjectAbsence_Key
kMPSCNNYOLOLoss_rescore_Key
((info->src.image.featureChannels) / numAnchorBoxes) > 5, failed, input image does not have enough feature channels for the anchor boxes
((info->src.image.featureChannels) %% numAnchorBoxes) == 0, failed, input image feature channels must be a multiple of number of anchor boxes
gridWidth != [stateLabels weightsImage].width, the weightsImage in state must be the same dimension as input image
gridHeight == [stateLabels weightsImage].height, the weightsImage in state must be the same dimension as input image
(((info->src.image.featureChannels) + 3) / 4) == (([stateLabels weightsImage].featureChannels + 3) / 4), the weightsImage in state must be the same dimension as input image
YOLOLossBatch
YOLOFinalizeBatch
MPSNNNeuronDescriptor for fusing with convoution cannot be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNConvolution.mm
Use -setNeuronType:parameterA:parameterB instead
Number of groups should be 1 for depthwise convolution.
Number of input channels must be divisible by groups parameter
Number of output channels must be divisible by groups parameter
Number of input channels in each group must be multiple of 4
Number of output channels in each group must be multiple of 4
kernel width: %lu
kernel height: %lu
Input feature channels: %lu
Output feature channels: %lu
X stride (pixels): %lu
Y stride (pixels): %lu
Groups:    %lu
subPixelScaleFactor:    %lu
dilationRateX:    %lu
dilationRateY:    %lu
Batch norm data: %p
neuron:
Error: can not add neuron to descriptor that already has one.
neuron already set on the convolution descriptor next layer cannot be fused
TQ,N,V_featureChannelsLayout
TQ,N,V_strideInPixelsX
TQ,N,V_strideInPixelsY
TQ,N,V_groups
TQ,N,V_dilationRateX
TQ,N,V_dilationRateY
fusedNeuronDescriptor
T@"MPSNNNeuronDescriptor",&,N,V_fusedNeuronDescriptor
neuron
T@"MPSCNNNeuron",&,N,V_neuron_deprecated
outputFeatureChannels (%lu) in convolution descriptor must be multiple of scaleFactor*scaleFactor=%lu becuase these values are rearragned in scaleFactor x scaleFactor pixel block by sub pixel convolution with each pixel having outputFeatureChannels/(scaleFactor*scaleFactor) channels
When number of groups (%lu) is greater than 1, number of feature channel in upsampled output image (outputFeatureChannels/(scaleFactor*scaleFactor)) (%lu) must be multiple of 4
subPixelScaleFactor
outputFeatureChannels (%lu) in convolution descriptor must be multiple of _inputFeatureChannels (%lu)
channelMultiplier:    %lu
sourceOffset
T{?=qqq},R,N,V_srcOffset
TQ,R,N,V_originalConvolutionSourceWidth
TQ,R,N,V_originalConvolutionSourceHeight
convolution: %@ %p "%@"
gradientForWeights
gradientForBiases
convolution
T@"MPSCNNConvolution",R,&,N,V_convolution
v8@?0
vDSP_vsmul
vDSP_vma
8-bit weights are only allowed for interleaved per array slice layout
for depth wise convolution, number of output feature channels (%lu) must be multiple of input feature channels (%lu)
for depth wise convolution, currently only channel multiplier of 1 is supported.
for depth wise convolution, groups should be 1.
depth wise convolution currently only supported for FP weights.
parameterA of depreated neuron property doesnt match the value set for neuronParameterA of convolution descriptor.
parameterB of depreated neuron property doesnt match the value set for neuronParameterB of convolution descriptor.
Neuron type of depreated neuron property doesnt match the value set for neuronType of convolution descriptor.
[%@ initWithDevice:convolutionDescriptor:weights:] weights may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] weights.load should return YES
Only MPSDataTypeFloat32, MPSDataTypeFloat16 and MPSDataTypeUInt8 are supported by convolution.
Data source does not implement rangesForUInt8Kernel method
rangesForUInt8Kernel method returned nil
Data source does not implement lookupTableForUInt8Kernel method
lookupTableForUInt8Kernel method returned nil
Only linear or loopup table based dequantization available for UInt8 datatype
Weights data provider data type is UInt8 but no method implemented to dequantize the weights or methods returned nil LUT/ranges
[%@ initWithDevice:convolutionDescriptor:weights:] unsupported weights.dataType: 0x%16.16llx
Failed to load data source
data source does not repond to selector lookupTableForUInt8Kernel
data source does not repond to selector rangesForUInt8Kernel
Convolution object was not created with data source. Use initWithDevice:weights
data source load failed
MPSNNConvolutionAccumulatorPrecisionOptionHalf
MPSNNConvolutionAccumulatorPrecisionOptionFloat
inputFeatureChannels: %lu
outputFeatureChannels:   %lu
Feature channel layout:  %lu
Groups:                  %lu
scaleFactor:             %lu
Accumulator precision:   %s
Internal error: Plugin data is nil.
External plugin not supported currently for batch processing.
Feature channel layout of source and MPSCNNConvolution filter doesn't match
Feature channel layout of destination and MPSCNNConvolution filter doesn't match
Error: -[MPSCNNConvolution reloadWeightsAndBiasesWithDataSource:] does not support changing the data source.
It has been deprecated. Please use -reloadWeightsAndBiasesFromDataSource instead.
[%@ initWithDevice:convolutionDescriptor:weights:] dataSource.load should return YES
biases buffer should have %lu bytes of data
Convolution object was created without a data source. Use initWithDevice:weights:
TQ,R,N,V_scaleFactor
T@"MPSCNNNeuron",R,N,V_neuron_deprecated
Ti,R,N
neuronParameterA
Tf,R,N
neuronParameterB
neuronParameterC
T@"MPSNNNeuronDescriptor",R,N,V_fusedNeuronDescriptor
weights
biases
MPSCNNConvolutionDescriptorVers
MPSCNNConvolutionDescriptorWidth
MPSCNNConvolutionDescriptorHeight
MPSCNNConvolutionDescriptorInputFeatureChannels
MPSCNNConvolutionDescriptorOutputFeatureChannels
MPSCNNConvolutionDescriptorStrideInPixelsX
MPSCNNConvolutionDescriptorStrideInPixelsY
MPSCNNConvolutionDescriptorGroups
MPSCNNConvolutionDescriptorFeatureChannelsLayout
MPSCNNConvolutionDescriptorSubPixelScaleFactor
MPSCNNConvolutionDescriptorDilationRateX
MPSCNNConvolutionDescriptorDilationRateY
MPSCNNConvolutionDescriptorNeuronType
MPSCNNConvolutionDescriptorNeuronA
MPSCNNConvolutionDescriptorNeuronB
MPSCNNConvolutionDescriptorNeuronC
MPSCNNConvolutionDescriptorIsDepthWiseConvolution
MPSCNNConvolutionDescriptorBatchNormalization.isNull
MPSCNNConvolutionDescriptorBatchNormalization.data
MPSCNNConvolutionDescriptorNeuronParameterA.isNull
MPSCNNConvolutionDescriptorNeuronParameterA.data
MPSCNNConvolutionWeight.dataLayout
MPSCNNConvolutionWeight.dataType
MPSCNNConvolutionBias.isNull
MPSCNNConvolutionWeight.data
MPSCNNConvolutionBias.data
MPSCNNConvolutionQuantizationData.data
MPSCNNConvolutionFeatureChannelsLayout
MPSCNNConvolutionIsFullyConnected
MPSCNNConvolutionIsConvolutionTranspose
MPSCNNConvolutionFlags
MPSCNNConvolutionNeuronBufferA.isNull
MPSCNNConvolutionNeuronBufferA.data
MPSCNNConvolutionBatchNormalizationData.isNull
MPSCNNConvolutionBatchNormalizationData.data
MPSCNNConvolutionDataSourceClass
MPSCNNConvolutionDataSource
MPSCNNConvolutionInputFeatureChannels
MPSCNNConvolutionOutputFeatureChannels
MPSCNNConvolutionGroups
MPSCNNConvolutionNeuronInfo.type
MPSCNNConvolutionNeuronInfo.a
MPSCNNConvolutionNeuronInfo.b
MPSCNNConvolutionNeuronInfo.c
MPSCNNConvolutionScaleFactor
MPSCNNConvolutionQuantizationType
MPSCNNConvolutionChannelMultipler
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNNormalization.mm
MPSCNNNormalization_tex2d_tex2d_CHNorm
MPSCNNNormalization_tex2darray_tex2darray_CHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw2
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw3
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw4
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw5
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw6
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw7
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw8
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw9
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt2
MPSCNNNormalization_ArrayFC_GenCHNorm
MPSCNNNormalization_horizontal_tex2d_tex2d_XYNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_vertical_tex2d_tex2d_XYNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_horizontal_tex2d_tex2d_LCNNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_vertical_tex2d_tex2d_LCNNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNCrossChannelNormalization.kernelSize
MPSCNNCrossChannelNormalization.alpha
MPSCNNCrossChannelNormalization.beta
MPSCNNCrossChannelNormalization.delta
MPSCNNSpatialNormalization.alpha
MPSCNNSpatialNormalization.beta
MPSCNNSpatialNormalization.delta
MPSCNNLocalContrastNormalization.alpha
MPSCNNLocalContrastNormalization.beta
MPSCNNLocalContrastNormalization.delta
MPSCNNLocalContrastNormalization.p0
MPSCNNLocalContrastNormalization.pm
MPSCNNLocalContrastNormalization.ps
commandBuffer may not be nil.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixSum.mm
Requires at least two matrices to compute a sum.
Only matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
Offset vector must be of type MPSDataTypeUInt32.
v32@?0@"MPSMatrix"8Q16^B24
rows
TQ,R,N,V_rows
columns
TQ,R,N,V_columns
count
TQ,R,N,V_count
transpose
TB,R,N,V_transpose
MatrixSum_float
MatrixSum_half
MatrixSumRemainder_float
MatrixSumRemainder_half
MPSMatrixSum.rows
MPSMatrixSum.columns
MPSMatrixSum.count
MPSMatrixSum.transpose
MPSMatrixSum.neuronType
MPSMatrixSum.neuronA
MPSMatrixSum.neuronB
MPSMatrixSum.neuronC
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNSoftMax.mm
softmaxNleq4_RGBA
softmaxNgt4leq8_RGBA
softmaxNgt8leq12_RGBA
softmaxNdiv4_RGBA
softmaxN_RGBA
softmaxN_threadgroup
softmaxNleq4_array_RGBA
softmaxNgt4leq8_array_RGBA
softmaxNgt8leq12_array_RGBA
softmaxNdiv4_array_RGBA
softmaxN_array_RGBA
softmaxN_array_interleaved_pixel_threadgroup
softmaxN_array_interleaved_slice_threadgroup
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalization.mm
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
computeStatistics
TB,N,V_computeStatistics
MatrixBatchNormalization
MPSMatrixBatchNormalization._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalization._sourceInputFeatureChannels;
MPSMatrixBatchNormalization._neuronType;
MPSMatrixBatchNormalization._neuronA;
MPSMatrixBatchNormalization._neuronB;
MPSMatrixBatchNormalization._neuronC;
MPSMatrixBatchNormalization._epsilon;
MPSMatrixBatchNormalization._computeStatistics;
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNGradientKernel.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MetalPerformanceShaders/MPSNNGradientState.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least one source image are expected for a MPSCNNConvolutionTranspose.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
offset: {%ld, %ld, %ld}
clipRect:                          {origin:{%lu, %lu, %lu}, size:{%lu, %lu, %lu}}
dest size:                         {w:%lu, h:%lu, images:%lu}
destination feature channel offset: %lu
source feature channel offset:      %lu
kernel size:                        %lu x %lu
pixel stride:                       %lu x %lu
dilation rate:                      %lu x %lu
padding:                            
max batch size:                     %lu
is backwards:                       %@
edge mode:                          %lu
source size:                       {%lu, %lu, %lu} fc: %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNBinaryGradientKernel.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: primary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: secondary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Filters/MPSCNNBinaryConvolution.mm
number of groups must be 1
[%@ initWithCoder:device:] failed. %@
Problem decoding buffers
Problem creating pooling filter for internal use.
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
inputFeatureChannels: %lu
outputFeatureChannels: %lu
NeuronType: %d
outputBias: %d
outputScale: %d
inputBias: %d
inputScale: %d
PoolingFilter: %@
convType: %lu
flags: %lu
kMPSCNNBinaryConvolution._fullyConnected
kMPSCNNBinaryConvolution._kernelWidth
kMPSCNNBinaryConvolution._kernelHeight
kMPSCNNBinaryConvolution._inputFeatureChannels
kMPSCNNBinaryConvolution._outputFeatureChannels
kMPSCNNBinaryConvolution._strideInPixelsX
kMPSCNNBinaryConvolution._strideInPixelsY
kMPSCNNBinaryConvolution._flags
kMPSCNNBinaryConvolution._convType
kMPSCNNBinaryConvolution._outputScaleValue
kMPSCNNBinaryConvolution._weights
kMPSCNNBinaryConvolution._inputbias
kMPSCNNBinaryConvolution._inputScale
kMPSCNNBinaryConvolution._outputbias
kMPSCNNBinaryConvolution._outputScale
kMPSCNNBinaryConvolution._neuronType
kMPSCNNBinaryConvolution._neuronParamA
kMPSCNNBinaryConvolution._neuronParamB
kMPSCNNBinaryConvolution._neuronParamC
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + outputFeatureChannels > dest.featureChannels
MPSCNNBinarize_2d_2d_float
MPSCNNBinarize_2d_2dArray_float
MPSCNNBinarize_2dArray_2d_float
MPSCNNBinarize_2dArray_2dArray_float
MPSCNNBetaBinarize_2d_2d_float
MPSCNNBetaBinarize_2d_2dArray_float
MPSCNNBetaBinarize_2dArray_2d_float
MPSCNNBetaBinarize_2dArray_2dArray_float
MPSCNNBinarizePixelFC_2d_2d_float
MPSCNNBinarizePixelFC_2d_2dArray_float
MPSCNNBinarizePixelFC_2dArray_2d_float
MPSCNNBinarizePixelFC_2dArray_2dArray_float
MPSCNNBetaBinarizePixelFC_2d_2d_float
MPSCNNBetaBinarizePixelFC_2d_2dArray_float
MPSCNNBetaBinarizePixelFC_2dArray_2d_float
MPSCNNBetaBinarizePixelFC_2dArray_2dArray_float
MPSCNNBinaryConvolve_2d_2d_float
MPSCNNBinaryConvolve_2d_2dArray_float
MPSCNNBinaryConvolve_2dArray_2d_float
MPSCNNBinaryConvolve_2dArray_2dArray_float
MPSCNNBetaBinaryConvolve_2d_2d_float
MPSCNNBetaBinaryConvolve_2d_2dArray_float
MPSCNNBetaBinaryConvolve_2dArray_2d_float
MPSCNNBetaBinaryConvolve_2dArray_2dArray_float
MPSCNNBinaryConvolvePixelFC_2d_2d_float
MPSCNNBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNImageScale_2d_2d_float
MPSCNNImageScale_2d_2dArray_float
MPSCNNImageScale_2dArray_2d_float
MPSCNNImageScale_2dArray_2dArray_float
MPSCNNImageScalePixelFC_2d_2d_float
MPSCNNImageScalePixelFC_2d_2dArray_float
MPSCNNImageScalePixelFC_2dArray_2d_float
MPSCNNImageScalePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightConvolve_2d_2d_float
MPSCNNBinaryWeightConvolve_2d_2dArray_float
MPSCNNBinaryWeightConvolve_2dArray_2d_float
MPSCNNBinaryWeightConvolve_2dArray_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnected_2d_2d_float
MPSCNNBinaryWeightFullyConnected_2d_2dArray_float
MPSCNNBinaryWeightFullyConnected_2dArray_2d_float
MPSCNNBinaryWeightFullyConnected_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2dArray_float
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-121.4.3/MPSNeuralNetwork/Plugin/MPSCNNKernelPlugin.mm
[%@ encodeToCommandBuffer:computeCommandEncoder:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:]  Error: The device driver has failed to override this method
MPSMatrixFullyConnectedGradient
MPSNNReshape
MPSNNReshapeGradient
MPSNNPadGradientState
MPSNNPad
MPSNNPadGradient
MPSCNNPoolingGradient
MPSCNNPoolingMaxGradient
MPSCNNPoolingAverageGradient
MPSCNNPoolingL2NormGradient
MPSCNNDilatedPoolingMaxGradient
MPSCNNArithmeticGradientState
MPSCNNArithmetic
MPSCNNAdd
MPSCNNSubtract
MPSCNNMultiply
MPSCNNDivide
MPSNNCompare
MPSCNNArithmeticGradient
MPSCNNAddGradient
MPSCNNSubtractGradient
MPSCNNMultiplyGradient
MPSRNNRecurrentImageState
MPSRNNRecurrentMatrixState
MPSRNNMatrixTrainingState
MPSRNNDescriptor
MPSRNNSingleGateDescriptor
MPSLSTMDescriptor
MPSGRUDescriptor
TmpWeights
MPSCNNConvolutionDataSource
NSCopying
NSObject
TmpWeightsLUT
TmpWeightsLIN
MPSCNNConvolutionDescriptorNoNeuron
MPSRNNImageInferenceLayer
MPSRNNMatrixInferenceLayer
MPSRNNMatrixTrainingLayer
MPSNNScaleNode
MPSNNBilinearScaleNode
MPSNNLanczosScaleNode
MPSNNScale
MPSNNConcatenation
MPSNNConcatenationGradientState
MPSCNNConvolutionGradient
MPSNNUnaryReductionNode
MPSNNReductionRowMinNode
MPSNNReductionColumnMinNode
MPSNNReductionFeatureChannelsMinNode
MPSNNReductionFeatureChannelsArgumentMinNode
MPSNNReductionRowMaxNode
MPSNNReductionColumnMaxNode
MPSNNReductionFeatureChannelsMaxNode
MPSNNReductionFeatureChannelsArgumentMaxNode
MPSNNReductionRowMeanNode
MPSNNReductionColumnMeanNode
MPSNNReductionFeatureChannelsMeanNode
MPSNNReductionSpatialMeanNode
MPSNNReductionSpatialMeanGradientNode
MPSNNReductionRowSumNode
MPSNNReductionColumnSumNode
MPSNNReductionFeatureChannelsSumNode
MPSMatrixBatchNormalizationGradient
MPSCNNDropoutGradientState
MPSCNNDropout
MPSCNNDropoutGradient
MPSCNNUpsampling
MPSCNNUpsamplingNearest
MPSCNNUpsamplingBilinear
MPSCNNGradientKernel
MPSCNNNeuronNode
MPSCNNNeuronAbsoluteNode
MPSCNNNeuronELUNode
MPSCNNNeuronReLUNNode
MPSCNNNeuronLinearNode
MPSCNNNeuronReLUNode
MPSCNNNeuronSigmoidNode
MPSCNNNeuronHardSigmoidNode
MPSCNNNeuronSoftPlusNode
MPSCNNNeuronSoftSignNode
MPSCNNNeuronTanHNode
MPSCNNNeuronPReLUNode
MPSCNNNeuronPowerNode
MPSCNNNeuronExponentialNode
MPSCNNNeuronLogarithmNode
MPSCNNNeuronGradientNode
MPSNNReshapeNode
MPSNNReshapeGradientNode
MPSNNPadNode
MPSNNPadGradientNode
MPSMatrixFullyConnected
MPSMatrixNeuron
MPSCNNBatchNormalization
NSSecureCoding
NSCoding
MPSCNNConvolutionTranspose
MPSNNBinaryArithmeticNode
MPSNNAdditionNode
MPSNNSubtractionNode
MPSNNMultiplicationNode
MPSNNDivisionNode
MPSNNComparisonNode
MPSNNArithmeticGradientStateNode
MPSNNArithmeticGradientNode
MPSNNAdditionGradientNode
MPSNNSubtractionGradientNode
MPSNNMultiplicationGradientNode
MPSCNNInstanceNormalizationGradient
MPSCNNBatchNormalizationStatisticsGradient
MPSCNNUpsamplingNearestNode
MPSCNNUpsamplingBilinearNode
MPSCNNUpsamplingNearestGradientNode
MPSCNNUpsamplingBilinearGradientNode
MPSNNOptimizerDescriptor
MPSNNOptimizer
MPSNNOptimizerStochasticGradientDescent
MPSNNOptimizerRMSProp
MPSNNOptimizerAdam
MPSNNGraph
MPSNNTrainableNode
FilterNodeWrapper
ResourceWrapper
NodeWrapper
MPSCNNCrossChannelNormalizationGradient
MPSCNNSpatialNormalizationGradient
MPSCNNLocalContrastNormalizationGradient
MPSNNLabelsNode
MPSCNNLossNode
MPSCNNYOLOLossNode
MPSCNNLossDataDescriptor
MPSCNNLossDescriptor
MPSCNNLossLabels
MPSCNNLoss
MPSCNNUpsamplingGradient
MPSCNNUpsamplingNearestGradient
MPSCNNUpsamplingBilinearGradient
MPSNNImageNode
MPSNNStateNode
MPSNNFilterNode
MPSNNGradientFilterNode
MPSNNGradientStateNode
MPSNNBinaryGradientStateNode
MPSNNSlice
MPSNNConcatenationGradient
MPSCNNInstanceNormalization
MPSCNNNormalizationGammaAndBetaState
MPSCNNInstanceNormalizationGradientState
MPSNNCropAndResizeBilinear
MPSCNNPooling
MPSCNNPoolingMax
MPSCNNPoolingAverage
MPSCNNPoolingL2Norm
MPSCNNDilatedPoolingMax
MPSCNNBatchNormalizationGradient
MPSImageSizeEncodingState
MPSCNNBinaryKernel
MPSCNNBinaryImageFilter
MPSCNNBatchNormalizationState
MPSCNNNormalizationMeanAndVarianceState
MPSNNResizeBilinear
MPSCNNDropoutNode
MPSCNNDropoutGradientNode
MPSCNNSoftMaxNode
MPSCNNLogSoftMaxNode
MPSCNNSoftMaxGradientNode
MPSCNNLogSoftMaxGradientNode
MPSNNNeuronDescriptor
MPSCNNNeuron
MPSCNNNeuronGradient
MPSCNNNeuronLinear
MPSCNNNeuronReLU
MPSCNNNeuronPReLU
MPSCNNNeuronSigmoid
MPSCNNNeuronHardSigmoid
MPSCNNNeuronTanH
MPSCNNNeuronAbsolute
MPSCNNNeuronSoftPlus
MPSCNNNeuronSoftSign
MPSCNNNeuronELU
MPSCNNNeuronReLUN
MPSCNNNeuronPower
MPSCNNNeuronExponential
MPSCNNNeuronLogarithm
MPSNNReduceUnary
MPSNNReduceRowMin
MPSNNReduceColumnMin
MPSNNReduceFeatureChannelsMin
MPSNNReduceFeatureChannelsArgumentMin
MPSNNReduceRowMax
MPSNNReduceColumnMax
MPSNNReduceFeatureChannelsMax
MPSNNReduceFeatureChannelsArgumentMax
MPSNNReduceRowMean
MPSNNReduceColumnMean
MPSNNReduceFeatureChannelsMean
MPSNNReduceRowSum
MPSNNReduceColumnSum
MPSNNReduceFeatureChannelsSum
MPSNNReduceBinary
MPSNNReduceFeatureChannelsAndWeightsMean
MPSNNReduceFeatureChannelsAndWeightsSum
MPSWeightsWrapper
MPSWeightsWrapper_SecureCoding
MPSCNNKernel
MPSNNDefaultPadding
MPSNNPadding
MPSNNTensorFlowPoolingPadding
MPSNNTensorFlowPoolingPaddingValidOnly
MPSCNNPoolingNode
MPSCNNPoolingMaxNode
MPSCNNPoolingAverageNode
MPSCNNPoolingL2NormNode
MPSCNNDilatedPoolingMaxNode
MPSCNNPoolingGradientNode
MPSCNNPoolingMaxGradientNode
MPSCNNPoolingAverageGradientNode
MPSCNNPoolingL2NormGradientNode
MPSCNNDilatedPoolingMaxGradientNode
MPSMatrixNeuronGradient
MPSCNNSoftMaxGradient
MPSCNNLogSoftMaxGradient
MPSNNConcatenationNode
MPSNNConcatenationGradientNode
MPSCNNNormalizationNode
MPSCNNSpatialNormalizationNode
MPSCNNSpatialNormalizationGradientNode
MPSCNNLocalContrastNormalizationNode
MPSCNNLocalContrastNormalizationGradientNode
MPSCNNCrossChannelNormalizationNode
MPSCNNCrossChannelNormalizationGradientNode
MPSCNNInstanceNormalizationNode
MPSCNNInstanceNormalizationGradientNode
MPSCNNBatchNormalizationNode
MPSCNNBatchNormalizationGradientNode
MPSCNNFullyConnected
MPSCNNFullyConnectedGradient
MPSCNNConvolutionGradientStateNode
MPSCNNConvolutionStateNode
MPSCNNConvolutionNode
MPSCNNConvolutionGradientNode
MPSCNNFullyConnectedNode
MPSCNNBinaryConvolutionNode
MPSCNNBinaryFullyConnectedNode
MPSCNNConvolutionTransposeNode
MPSCNNBatchNormalizationStatistics
MPSCNNBatchNormalizationDataSource
MPSConvolutionDataSourceWrapper
MPSConvolutionDataSourceWrapper_SecureCoding
MPSCNNYOLOLossDescriptor
MPSCNNYOLOLoss
MPSCNNConvolutionDescriptor
MPSCNNSubPixelConvolutionDescriptor
MPSCNNDepthWiseConvolutionDescriptor
MPSCNNConvolutionState
MPSCNNConvolutionGradientState
MPSCNNConvolution
MPSCNNConvolutionWeightsAndBiasesState
MPSCNNCrossChannelNormalization
MPSCNNSpatialNormalization
MPSCNNLocalContrastNormalization
MPSMatrixSum
MPSCNNSoftMax
MPSCNNLogSoftMax
MPSMatrixBatchNormalization
MPSNNGradientState
MPSNNBinaryGradientState
MPSCNNBinaryConvolution
MPSCNNBinaryFullyConnected
MPSExternalCNNUnary
MPSExternalPluginBase
MPSExternalCNNBinary
MPSExternalCNNPoolingAverage
r^{MPSLibraryInfo=iI*{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}}16@0:8
@24@0:8@16
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@32@0:8^{_NSZone=}16@24
@32@0:8@16@24
v24@0:8@16
Q16@0:8
v24@0:8Q16
d16@0:8
v24@0:8d16
@16@0:8
@48@0:8@16@24Q32^{?=qqq}40
@64@0:8@16@24Q32^{?=qqq}40^{?=qqq}48^{?=qqq}56
v16@0:8
{MPSImageCoordinate="x"Q"y"Q"channel"Q}
@72@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48@72
B16@0:8
@40@0:8@16@24@32
@48@0:8@16@24@32@40
{MPSImageCoordinate=QQQ}16@0:8
v40@0:8{MPSImageCoordinate=QQQ}16
f16@0:8
v20@0:8f16
@"<MTLBuffer>"
@40@0:8@16Q24Q32
@56@0:8@16Q24Q32Q40Q48
v48@0:8Q16Q24Q32Q40
{?=QQQ}16@0:8
v40@0:8{?=QQQ}16
{?="width"Q"height"Q"depth"Q}
@72@0:8@16Q24Q32Q40Q48Q56Q64
@28@0:8@16i24
@60@0:8@16@24@32@40@48B56
@56@0:8@16@24@32@40@48
v56@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40^{NSArray=#}48
@32@0:8@16i24B28
@"MPSNNReduceUnary"
@28@0:8@16B24
@24@0:8Q16
@48@0:8@16^@24^@32B40i44
@36@0:8@16@24B32
@"MPSMatrix"
v20@0:8B16
@"<MPSCNNConvolutionDataSource>"
@32@0:8Q16Q24
i16@0:8
v20@0:8i16
@24@0:8^{_NSZone=}16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
I16@0:8
^v16@0:8
^f16@0:8
^16@0:8
B32@0:8@16@24
@"MPSCNNConvolutionDescriptor"16@0:8
@"MPSCNNConvolutionWeightsAndBiasesState"40@0:8@"<MTLCommandBuffer>"16@"MPSCNNConvolutionGradientState"24@"MPSCNNConvolutionWeightsAndBiasesState"32
B32@0:8@"MPSCNNConvolutionGradientState"16@"MPSCNNConvolutionWeightsAndBiasesState"24
@32@0:8^{_NSZone=}16@"<MTLDevice>"24
@36@0:8@16B24@28
@"MPSCNNConvolutionDescriptor"
v72@0:8@16@24^Q32@40^Q48@56@64
@"MPSMatrixMultiplication"
v28@0:8@16I24
v36@0:8@16I24@28
v76@0:8@16@24Q32@40B48{?=QQQ}52
v88@0:8@16@24^Q32@40^Q48@56@64@72@80
v112@0:8@16@24^Q32@40^Q48@56^Q64@72@80@88@96@104
v72@0:8@16@24@32@40@48@56@64
@"NSMutableArray"
@56@0:8@16@24{?=QQQ}32
@48@0:8@16{?=QQQ}24
@"<MPSImageTransformProvider>"
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}16@0:8
@72@0:8@16@24@32{?=QQQ}40#64
@"MPSImageScale"
@"<MPSHandle>"
v40@0:8@16@24@32
v40@0:8@16@24^{NSArray=#}32
^{NSArray=#}48@0:8@16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}48@0:8@16@24@32^{NSArray=#}40
^{NSArray=#}40@0:8^{NSArray=#}16@24^{NSArray=#}32
^{NSArray=#}40@0:8@16@24^{NSArray=#}32
^{MPSSliceInfo=QQ}
v48@0:8@16@24^v32I40B44
v36@0:8@16@24B32
v32@0:8@16@24
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{?={?=QQQ}{?=QQQ}}16@0:8
v64@0:8{?={?=QQQ}{?=QQQ}}16
{?="origin"{?="x"Q"y"Q"z"Q}"size"{?="width"Q"height"Q"depth"Q}}
v96@0:8@16@24@32@40@48@56@64@72@80@88
v32@0:8i16f20f24f28
@60@0:8@16f24Q28{?=QQQ}36
@52@0:8@16@24@32@40B48
@44@0:8@16@24^@32B40
^{NSArray=#}44@0:8@16^{NSArray=#}24^^{NSArray}32B40
{mersenne_twister_engine<unsigned int, 32, 624, 397, 31, 2567483615, 11, 4294967295, 7, 2636928640, 15, 4022730752, 18, 1812433253>="__x_"[624I]"__i_"Q}
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"MPSCNNMultiply"
@52@0:8@16Q24Q32Q40B48
@44@0:8@16Q24Q32B40
^{NSArray=#}48@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40
v28@0:8@16B24
q16@0:8
v24@0:8q16
@40@0:8@16i24f28f32f36
@28@0:8@16f24
@32@0:8@16f24f28
@"NSData"
@36@0:8@16f24f28f32
@"MPSNNNeuronDescriptor"
@48@0:8@16Q24Q32Q40
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48Q72
@"<MPSExternalMatrixFullyConnected>"
v48@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40
v48@0:8@16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}40@0:8@16^{NSArray=#}24@32
v32@0:8@16B24B28
^{MPSAutoBuffer={atomic<void *>=A^v}Q@@{?=QQ}}
@"<MPSCNNBatchNormalizationDataSource>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@56@0:8@16@24r^f32r^f40Q48
@60@0:8@16@24r^f32r^f40Q48B56
^{NSArray=#}40@0:8@16^{NSArray=#}24^{NSArray=#}32
@"MPSCNNConvolution"
{NeuronInfo="type"i"a"f"b"f"c"f"aData"@"NSData"}
@44@0:8@16@24@32B40
v48@0:8@16^{NSArray=#}24^{NSArray=#}32@40
@56@0:8@16@24@32d40d48
@36@0:8f16f20Q24f32
@48@0:8f16f20B24f28f32Q36f44
@40@0:8@16f24B28@32
@44@0:8@16d24f32@36
@60@0:8@16d24d32f40Q44@52
v64@0:8@16@24@32@40@48@56
@"NSObject<OS_dispatch_semaphore>"
@40@0:8@16@24^B32
^{NSArray=#}40@0:8@16@24@32
^{NSArray=#}56@0:8@16@24@32@40@48
@32@0:8@16@?24
Q24@0:8Q16
{Graph="_graphSourceImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphSourceStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphIntermediateImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graph"@"MPSNNGraph""_filters"{NodeList<FilterGraphNode *>="_items"^^{FilterGraphNode}"_count"Q"_storageSize"Q}"_images"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_states"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_cpuUpdateSem"@"NSObject<OS_dispatch_semaphore>""_graphNull"@"NSNull"}
@"<MPSImageAllocator>"
@24@0:8^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}16
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@)@QBBIQ}
@24@0:8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQQ}16
^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQQ}
@32@0:8@16Q24
@"MPSNNLabelsNode"
@"MPSCNNLossDescriptor"
@"MPSCNNYOLOLossDescriptor"
@56@0:8@16Q24{?=QQQ}32
@24@0:8I16i20
v20@0:8I16
@64@0:8@16{?=QQQ}24@48@56
@"MPSCNNLogSoftMax"
@"MPSCNNNeuron"
@"MPSNNFilterNode"
^{FilterGraphNode=}16@0:8
@"MPSNNImageNode"
@"<MPSNNPadding>"
@"NSString"
@"<MPSCNNInstanceNormalizationDataSource>"
@40@0:8@16Q24@32
@"MPSCNNInstanceNormalization"
@56@0:8@16Q24Q32Q40r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}48
r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}16@0:8
^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}
^{Region_params=}
v40@0:8@16^{NSArray=#}24^{NSArray=#}32
^{NSArray=#}32@0:8@16^{NSArray=#}24
v56@0:8@16^{NSArray=#}24^{NSArray=#}32@40^{NSArray=#}48
^{NSArray=#}48@0:8@16^{NSArray=#}24^{NSArray=#}32@40
{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}40@0:8{?=QQQ}16
@52@0:8@16@24@32^@40B48
^{NSArray=#}52@0:8@16^{NSArray=#}24^{NSArray=#}32^^{NSArray}40B48
^{NSArray=#}48@0:8^{NSArray=#}16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}56@0:8@16^{NSArray=#}24^{NSArray=#}32@40^{NSArray=#}48
{?=qqq}16@0:8
v40@0:8{?=qqq}16
{?="x"q"y"q"z"q}
@"MPSExternalCNNBinary"
@44@0:8@16Q24f32@36
@"MPSCNNBatchNormalization"
@76@0:8@16@24@32f40Q44{?=QQQ}52
@32@0:8i16f20f24f28
@28@0:8i16f20f24
@24@0:8i16f20
@20@0:8i16
{NeuronInfo=ifff@}16@0:8
@40@0:8@16f24f28f32i36
@44@0:8@16r^f24Q32i40
v36@0:8i16r^f20Q28
@40@0:8@16@24r^f32
@40@0:8@16r^f24Q32
@56@0:8@16{NeuronInfo=ifff@}24@48
16@0:8
@"MPSExternalCNNUnary"
@"MPSImageDescriptor"48@0:8@"NSArray"16@"NSArray"24@"MPSKernel"32@"MPSImageDescriptor"40
@80@0:8@16@24@32Q40Q48Q56Q64@72
@88@0:8@16@24@32Q40Q48Q56Q64Q72Q80
@"MPSNNReduceFeatureChannelsAndWeightsSum"
@"MPSNNReduceFeatureChannelsSum"
@48@0:8@16@24@32Q40
@56@0:8@16@24@32Q40Q48
@64@0:8@16@24r^f32r^f40Q48B56B60
@40@0:8@16@24B32B36
@52@0:8@16@24f32Q36Q44
@80@0:8@16@24r^f32r^f40r^f48r^f56Q64Q72
v40@0:8@16^{NSArray=#}24@32
@"MPSCNNNormalizationGammaAndBetaState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
@"MPSCNNNormalizationMeanAndVarianceState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
B24@0:8@"MPSCNNBatchNormalizationState"16
B24@0:8r^{NeuronInfo=ifff@}16
@"NSObject"
{atomic<long>="__a_"Aq}
@52@0:8I16I20I24I28i32@36Q44
f32@0:8^{NSArray=#}16^{NSArray=#}24
@"MPSCNNLoss"
@"MPSCNNNeuronGradient"
@"MPSCNNAdd"
@"MPSNNSlice"
@48@0:8Q16Q24Q32Q40
@56@0:8Q16Q24Q32Q40@48
v28@0:8i16f20f24
v52@0:8r^f16r^f24r^f32r^f40f48
@40@0:8{NeuronInfo=ifff@}16
@72@0:8Q16Q24Q32Q40{?=qqq}48
@48@0:8@16Q24Q32@40
B64@0:8@16I24r^v28r^f36i44r^48r^f56
B88@0:8@16@24r^v32I40r^44r^f52i60r^f64Q72B80B84
v48@0:8@16@24@32^@40
v72@0:8@16@24@32@40@48@56Q64
v60@0:8r^I16r^f24r^f32r^f40r^f48B56
@68@0:8@16@24r^I32r^f40f48Q52Q60
@88@0:8@16@24r^I32r^f40r^f48r^f56r^f64Q72Q80
@"MPSCNNPoolingAverage"
@60@0:8@16@24r^I32f40Q44Q52
@24@0:8@"<MTLDevice>"16
@"<MTLDevice>"16@0:8
Q72@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64
Q80@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}Q}56@64r^{?=QQQ{?={?=QQQ}{?=QQQ}}}72
Q72@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}Q}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64
Q80@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32Q40@"<MTLTexture>"48r^{?=QQ{?=qqq}Q}56@"<MTLTexture>"64r^{?=QQQ{?={?=QQQ}{?=QQQ}}}72
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}QQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQ{?=qqq}Q}64@72r^{?=QQQ{?={?=QQQ}{?=QQQ}}}80
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}QQQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64Q72Q80
Q88@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}Q}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64Q72Q80
L>19FilterNodeFileError
<empty>
21ResourceNodeFileError
@333?
@(#)PROGRAM:MPSNeuralNetwork  PROJECT:MPS-1
