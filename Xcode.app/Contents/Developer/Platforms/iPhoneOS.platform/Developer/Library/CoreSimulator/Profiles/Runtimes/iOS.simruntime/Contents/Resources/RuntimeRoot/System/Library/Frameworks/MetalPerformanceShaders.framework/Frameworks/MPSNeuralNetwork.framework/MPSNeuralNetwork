19FilterNodeFileError
<empty>
21ResourceNodeFileError
@(#)PROGRAM:MPSNeuralNetwork  PROJECT:MPS-1
[%@ initWithDevice:] is not allowed. Please use initializers that are not marked NS_UNAVAILABLE.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNPoolingGradient.mm
[%@ initWithCoder:device:] Failed: unsupported file version.
sourceSize
T{?=QQQ},N,V_sourceSize
zero pad size X: %lu
zero pad size Y:%lu
zeroPadSizeX
TQ,N,V_zeroPadSizeX
zeroPadSizeY
TQ,N,V_zeroPadSizeY
MPSCNNPoolingGradient.sourceSize.width
MPSCNNPoolingGradient.sourceSize.height
MPSCNNPoolingGradient.sourceSize.depth
MPSCNNPoolingGradient.padSizeX
MPSCNNPoolingGradient.padSizeY
[%@ encode...] unsupported feature channels layout (MPSImageFeatureChannelsInterleavedPerPixel)
[%@ encode...] Destination feature channel offset too large!
[%@ encode...] Destination feature channel offset Not multiple of 4!
v16@?0@"<MTLCommandBuffer>"8
MPSCNNPoolingGradient_generic_max_2d_2d
MPSCNNPoolingGradient_generic_max_2dArray_2dArray
MPSCNNPoolingGradient_generic_average_2d_2d
MPSCNNPoolingGradient_generic_average_2dArray_2dArray
MPSCNNPoolingGradient_generic_dilatedmax_2d_2d
MPSCNNPoolingGradient_generic_dilatedmax_2dArray_2dArray
MPSCNNPoolingGradient_generic_L2norm_2d_2d
MPSCNNPoolingGradient_generic_L2norm_2dArray_2dArray
Error: The only valid values for primaryStrideInPixelsX (%lu) are 0 or 1.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNArithmetic.mm
Error: The only valid values for primaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for primaryStrideInFeatureChannels (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsX (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInFeatureChannels (%lu) are 0 or 1.
Cannot directly initialize MPSCNNArithmetic. Use one of the sub-classes of MPSCNNArithmetic.
invalid arithmetic operator type (%u)
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
primaryStrideInFeatureChannels: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
arithmeticType: %lu
[%@ resultStatesForSourceImage...] sourceStates must be nil for this filter]
Error: [%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] called with less than two source images.
[%@ %@] Error: destination state may not be nil
[%@ %@] Error: destination state must be a MPSCNNArithmeticGradientState
primaryScale
Tf,N,V_primaryScale
secondaryScale
Tf,N,V_secondaryScale
bias
Tf,N,V_bias
primaryStrideInFeatureChannels
TQ,N,V_primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
TQ,N,V_secondaryStrideInFeatureChannels
minimumValue
Tf,N,V_minimumValue
maximumValue
Tf,N,V_maximumValue
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
isSecondarySourceFilter: %d
arithmeticType: %lu
isSecondarySourceFilter
TB,R,N,V_isSecondarySourceFilter
MPSCNNMath_Arithmetic
MPSCNNMath_Arithmetic_4Pixel_OneChannel_StrideXY0
MPSCNNMath_Arithmetic_4Pixel_StrideXY0
MPSCNNMath_Arithmetic_Special_SubtractGradient
MPSArithmetic.primaryScale
MPSArithmetic.secondaryScale
MPSArithmetic.bias
MPSArithmetic.minimumValue
MPSArithmetic.maximumValue
MPSArithmetic.primaryStrideInFeatureChannels
MPSArithmetic.secondaryStrideInFeatureChannels
MPSArithmetic.arithmeticType
[%@ encode...] MPSImageFeatureChannelsInterleavedPerPixel is not supported
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + src.featureChannels > dest.featureChannels
[%@ encode...] not enough source images:  primaryOffset.z + clipRect.size.depth > primarySource.numberOfImages
[%@ encode...] not enough source images:  secondaryOffset.z + clipRect.size.depth > secondarySource.numberOfImages
[%@ encode...] not enough destination images:  clipRect.origin.z + clipRect.size.depth > destinationImage.numberOfImages
MPSArithmetic.isSecondarySourceFilter
[%@ encode...] partial computation failed
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSNNReshape.mm
ReshapeOperation
reshape_array_2d
reshape_array_array
Source %p and destination %p shaapes are not the same sizes
Source feature channel offset for rehape must be 0 %lu
Destination feature channel offset for rehape must be 0 %lu
inputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputTransform
outputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputTransform
recurrentOutputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentOutputTransform
inputFeatureChannels
TQ,N,V_inputFeatureChannels
outputFeatureChannels
TQ,N,V_outputFeatureChannels
useLayerInputUnitTransformMode
TB,N,V_useLayerInputUnitTransformMode
useFloat32Weights
TB,N,V_useFloat32Weights
layerSequenceDirection
TQ,N,V_layerSequenceDirection
inputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputWeights
recurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentWeights
cellClipThreshold
Tf,N,V_cellClipThreshold
coupleForgetGateToInputGate
TB,N,V_coupleForgetGateToInputGate
memoryWeightsAreDiagonal
TB,N,V_memoryWeightsAreDiagonal
inputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateInputWeights
inputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateRecurrentWeights
inputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateMemoryWeights
forgetGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateInputWeights
forgetGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateRecurrentWeights
forgetGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateMemoryWeights
outputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputWeights
outputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateRecurrentWeights
outputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateMemoryWeights
cellGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateInputWeights
cellGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateRecurrentWeights
cellGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateMemoryWeights
cellToOutputNeuronType
Ti,N,V_cellToOutputNeuronType
cellToOutputNeuronParamA
Tf,N,V_cellToOutputNeuronParamA
cellToOutputNeuronParamB
Tf,N,V_cellToOutputNeuronParamB
cellToOutputNeuronParamC
Tf,N,V_cellToOutputNeuronParamC
recurrentGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateInputWeights
recurrentGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateRecurrentWeights
outputGateInputGateWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputGateWeights
gatePnormValue
Tf,N,V_gatePnormValue
flipOutputGates
TB,N,V_flipOutputGates
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSRNNLayer.mm
[%@ initWithDevice:rnnDescriptors:] device may not be nil
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor.inputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptor:] outputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu] may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].inputFeatureChannels must be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].outputFeatureChannels must be larger than zero
[%@ copyWithZone:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] Problem decoding layer stack
[%@ encodeWithCoder:] Problem allocating internal data
TQ,R,N,V_inputFeatureChannels
TQ,R,N,V_outputFeatureChannels
numberOfLayers
TQ,R,N,V_numberOfLayers
recurrentOutputIsTemporary
TB,N,V_recurrentOutputIsTemporary
storeAllIntermediateStates
TB,N,V_storeAllIntermediateStates
bidirectionalCombineMode
TQ,N,V_bidirectionalCombineMode
MPSRNNMatrixVecMulFloat4
MPSRNNMatrixVecMulFloat1
MPSRNNMatrixVecMulFloat1_nonMult4
MPSRNNSingleGateRec_float00
MPSRNNSingleGateRec_float01
MPSRNNSingleGateRec_float10
MPSRNNSingleGateRec_float11
MPSRNNSingleGateRec_half00
MPSRNNSingleGateRec_half01
MPSRNNSingleGateRec_half10
MPSRNNSingleGateRec_half11
MPSRNNSingleGateRec_char00
MPSRNNSingleGateRec_char01
MPSRNNSingleGateRec_char10
MPSRNNSingleGateRec_char11
MPSRNNLSTMRecursionfloat00
MPSRNNLSTMRecursionfloat01
MPSRNNLSTMRecursionfloat10
MPSRNNLSTMRecursionfloat11
MPSRNNLSTMRecursionhalf00
MPSRNNLSTMRecursionhalf01
MPSRNNLSTMRecursionhalf10
MPSRNNLSTMRecursionhalf11
MPSRNNLSTMRecursionchar00
MPSRNNLSTMRecursionchar01
MPSRNNLSTMRecursionchar10
MPSRNNLSTMRecursionchar11
MPSRNNGRURecursion1float00
MPSRNNGRURecursion1float01
MPSRNNGRURecursion1float10
MPSRNNGRURecursion1float11
MPSRNNGRURecursion2float00
MPSRNNGRURecursion2float01
MPSRNNGRURecursion2float10
MPSRNNGRURecursion2float11
MPSRNNGRURecursion1half00
MPSRNNGRURecursion1half01
MPSRNNGRURecursion1half10
MPSRNNGRURecursion1half11
MPSRNNGRURecursion2half00
MPSRNNGRURecursion2half01
MPSRNNGRURecursion2half10
MPSRNNGRURecursion2half11
MPSRNNGRURecursion1char00
MPSRNNGRURecursion1char01
MPSRNNGRURecursion1char10
MPSRNNGRURecursion1char11
MPSRNNGRURecursion2char00
MPSRNNGRURecursion2char01
MPSRNNGRURecursion2char10
MPSRNNGRURecursion2char11
MPSRNNCopyData
MPSRNNAddSequenceData
MPSRNNMultiInputKernelFloat1
MPSRNNMultiInputKernelFloat1_nonMult4
MPSRNNCombineInputVecs
RNNAddBiasToOutput
MPSRNNLSTMRecursionTex0
MPSRNNLSTMRecursionTex1
MPSRNNLSTMRecursionCombined0float
MPSRNNLSTMRecursionCombined1float
MPSRNNLSTMFullRecursion0float
MPSRNNLSTMFullRecursion1float
MPSRNNLSTMRecursionCombined0half
MPSRNNLSTMRecursionCombined1half
MPSRNNLSTMFullRecursion0half
MPSRNNLSTMFullRecursion1half
kMPSRNNLayer._inputFeatureChannels
kMPSRNNLayer._outputFeatureChannels
kMPSRNNLayer._numberOfLayers
kMPSRNNLayer._recurrentOutputIsTemporary
kMPSRNNLayer._storeAllIntermediateStates
kMPSRNNLayer._bidirectionalCombineMode
%@%@
.length
.data
kMPSRNNLayer.layerTypes
[%@ encode...] commandBuffer may not be nil]
[%@ encode...] source may not be nil
[%@ encode...] destination may not be nil
[%@ encode...] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
MPSRNNImageCombine_2d_2d_2d_float
MPSRNNImageCombine_2d_2dArray_2d_float
MPSRNNImageCombine_2dArray_2d_2d_float
MPSRNNImageCombine_2dArray_2dArray_2d_float
MPSRNNImageCombine_2d_2d_2dArray_float
MPSRNNImageCombine_2d_2dArray_2dArray_float
MPSRNNImageCombine_2dArray_2d_2dArray_float
MPSRNNImageCombine_2dArray_2dArray_2dArray_float
MPSRNNGateCombine_2d_2d_2d_float
MPSRNNGateCombine_2d_2dArray_2d_float
MPSRNNGateCombine_2dArray_2d_2d_float
MPSRNNGateCombine_2dArray_2dArray_2d_float
MPSRNNGateCombine_2d_2d_2dArray_float
MPSRNNGateCombine_2d_2dArray_2dArray_float
MPSRNNGateCombine_2dArray_2d_2dArray_float
MPSRNNGateCombine_2dArray_2dArray_2dArray_float
MPSRNNPNormCombine_2d_2d_2d_float
MPSRNNPNormCombine_2d_2dArray_2d_float
MPSRNNPNormCombine_2dArray_2d_2d_float
MPSRNNPNormCombine_2dArray_2dArray_2d_float
MPSRNNPNormCombine_2d_2d_2dArray_float
MPSRNNPNormCombine_2d_2dArray_2dArray_float
MPSRNNPNormCombine_2dArray_2d_2dArray_float
MPSRNNPNormCombine_2dArray_2dArray_2dArray_float
MPSLSTMMultiInputKernelFloat1
MPSLSTMMultiInputKernelFloat2
MPSLSTMMultiInputKernelFloat3
MPSLSTMMultiInputKernelFloat4
MPSLSTMMultiInputKernelFloat5
MPSLSTMMultiInputKernelFloat6
MPSLSTMMultiInputKernelFloat7
MPSLSTMMultiInputKernelFloat8
MPSLSTMMultiInputKernelFloat9
MPSLSTMMultiInputKernelFloat10
MPSLSTMMultiInputKernelFloat11
MPSLSTMMultiInputKernelFloat12
MPSLSTMMultiInputKernelFloat13
MPSLSTMMultiInputKernelFloat14
MPSLSTMMultiInputKernelFloat15
MPSLSTMMultiInputKernelFloat16
MPSLSTMMultiInputKernelHalf1
MPSLSTMMultiInputKernelHalf2
MPSLSTMMultiInputKernelHalf3
MPSLSTMMultiInputKernelHalf4
MPSLSTMMultiInputKernelHalf5
MPSLSTMMultiInputKernelHalf6
MPSLSTMMultiInputKernelHalf7
MPSLSTMMultiInputKernelHalf8
MPSLSTMMultiInputKernelHalf9
MPSLSTMMultiInputKernelHalf10
MPSLSTMMultiInputKernelHalf11
MPSLSTMMultiInputKernelHalf12
MPSLSTMMultiInputKernelHalf13
MPSLSTMMultiInputKernelHalf14
MPSLSTMMultiInputKernelHalf15
MPSLSTMMultiInputKernelHalf16
[copySingleGateLayer copyWithZone:device] out of memory: could not allocate internal data
[... copyWithZone:device](copyBuffer) out of memory: could not allocate internal data
[copyLSTMLayer copyWithZone:device] out of memory: could not allocate internal data
[initWithCoder:] out of memory: could not allocate internal data
%@%d
kMPSRNNLayer.common.direction
kMPSRNNLayer.common.useUnitXForm
kMPSRNNLayer.common.nHiddenFeatures
kMPSRNNLayer.common.nInputFeatures
kMPSRNNLayer.common.nOutputFeatures
kMPSRNNLayer.common.nRecurrentOutputFeatures
kMPSRNNLayer.common.inputTransform
kMPSRNNLayer.common.outputTransform
kMPSRNNLayer.common.recurrentOutputTransform
kMPSRNNLayer.common.inputTransform.hasBias
kMPSRNNLayer.common.outputTransform.hasBias
kMPSRNNLayer.common.recurrentOutputTransform.hasBias
MPSRNNLayer.SingleGate.inputXForm
MPSRNNLayer.SingleGate.recurrentXForm
MPSRNNLayer.SingleGate.hasBias
MPSRNNLayer.SingleGate.biasData
.convolution
kMPSRNNLayer.neuron.neuronType
kMPSRNNLayer.neuron.neuronParamA
kMPSRNNLayer.neuron.neuronParamB
kMPSRNNLayer.neuron.neuronParamC
[initWithCoder:](decodeLSTMLayer) out of memory: could not allocate internal data
MPSRNNLayer.LSTM.inputGate
MPSRNNLayer.LSTM.forgetGate
MPSRNNLayer.LSTM.cellGate
MPSRNNLayer.LSTM.outputGate
MPSRNNLayer.LSTM.recursionXFormsCombined
MPSRNNLayer.LSTM.finalNeuron
MPSRNNLayer.LSTM.inputXFormsCombined
MPSRNNLayer.LSTM.coupleForgetGateToInputGate
MPSRNNLayer.LSTM.cellClipThreshold
.inputXForm
.recurrentXForm
.peepholeXForm
.hasBias
.biasVector
.peepholeVector
.nHiddenFeatures
[initWithCoder:](decodeGRULayer) out of memory: could not allocate internal data
MPSRNNLayer.GRU.inputGateInputXform
MPSRNNLayer.GRU.inputGateRecXform
MPSRNNLayer.GRU.inputGateBias
MPSRNNLayer.GRU.inputGateHasBias
MPSRNNLayer.GRU.inputNeuron
MPSRNNLayer.GRU.recGateInputXform
MPSRNNLayer.GRU.recGateRecXform
MPSRNNLayer.GRU.recGateBias
MPSRNNLayer.GRU.recGateHasBias
MPSRNNLayer.GRU.recurrentNeuron
MPSRNNLayer.GRU.outputGateInputXform
MPSRNNLayer.GRU.outputGateRecXform
MPSRNNLayer.GRU.outputGateMemoryform
MPSRNNLayer.GRU.outputGateBias
MPSRNNLayer.GRU.outputGateHasBias
MPSRNNLayer.GRU.outputNeuron
MPSRNNLayer.GRU.pNormGateValue
MPSRNNLayer.GRU.flipOutputGates
[... initWithCoder:device](decodeTransform) out of memory: could not allocate internal data
.dataType
.biasLength
.biasData
.rows
.rowBytes
.columns
[... encodeWithCoder:](encodeTransform) Invalid transform buffer
[MPSNNScaleNode init] Error: Abstract class. 
Please use MPSNNBilinearScaleNode or MPSNNLanczosScaleNode instead.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNScale.mm
region provider: %@
size: {%lu, %lu, %lu}
use entire image
Internal error: [%@ initWithDevice:] unavailable
region provider: %@
Size: { %lu, %lu, %lu}
<copy entire image>
%@ error: Filter does not support result depth != 1
%@ %p error: the resampling filter does not support featureChannels > 4.
Error: class %@ does not conform to <MPSImageTransformProvider>
MPSNNScale.className
MPSNNScale.o
MPSNNScale.transformProviderName
MPSNNScale.handleName
MPSNNScale.handle.o
MPSNNScale.destSize.x
MPSNNScale.destSize.y
MPSNNScale.destSize.z
[MPSNNGraph encode...]: Error: MPSNNPadding method %p returned a nil formatting descriptor for an intermediate image.
The encode can not continue.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/FilterNode.h
Internal error: default encode for unary kernels doesn't take an input state
<missing label>
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
float16
float32
unorm8
unorm16
snorm8
snorm16
uint8
uint6
sint8
sint16
<unknown channel format>
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
*** Warning: kernel %s (%s) produces a result of size %lu x %lu. We will probably assert soon.
Perhaps the MPSNNGraph input image is too small for this network, or an upstream padding
policy was incorrect (full>same>valid), or a stride too large?
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSNNConcatenation.mm
[%@ encode...] sourceImages may not be nil
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLPixelFormat is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLTextureUsage is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] sourceImages length is 0. Can not produce a result.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  The MPSImageFeatureChannelsLayout must match between source and destination MPSImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu and dest image must have the same feature channel layout
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  the sum of feature channels in the source images  must fit within the destination image
[%@ encodeToCommandBuffer:sourceImages:destinationImage] Error: source image %lu (%p) has invalid feature channel layout.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] internal error: unable to create MTLTextureType2DArray view of src texture %p
[%@ encodeBatchToCommandBuffer:sourceImages:destinationImage:] Error: there are not enough source images in batch %lu (%lu) to fill the destination batch %lu
[%@ encodeToCommandBuffer: sourceImages:] sourceImages.count may not be 0
created by %@
[%@ %@] Error: command buffer may not be NULL
[%@ %@] Error: sourceImage batch may not be NULL
[%@ %@] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImages may not be NULL
[%@ resultStateBatchForSourceImages:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ destinationImageDescriptorForSourceImages:...] Error: The index of the slice %lu exceeds the number of slices in the preceeding concatenation operator. (%u)
%@, %lu
slice offsets:              {%@}
feature channels per slice: {%@}
ConcatenateInterleaved
ConcatenateInterleaved_array
ConcatenateArray
ConcatenateArray_array
Please initialize the %@ class with initWithDevice:weights
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNConvolutionGradientForData.mm
[%@ initWithDevice:convolutionDescriptor:weights:] weights may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] device may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] convolutionDescriptor may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] 8-bit weights not supported in
kernel width must be > 0
kernel height must be > 0
number of input feature channels must be > 0
number of output feature channels must be > 0
strideX must be > 0
strideY must be > 0
dilationRateX must be > 0
dilationRateY must be > 0
number of groups must be > 0
Depthwise convolution does not currently supported gradient back propagation
Subpixel convolution does not currently supported gradient back propagation
Failed to create weights buffer
weights.load should return YES
data source returned nil weights
kernelWidth of data source and convolution gradient doesn't match
kernelHeight of data source and convolution gradient doesn't match
feature channels of data source and convolution gradient doesn't match
sub pixel convolution reload is currently not supported
depthwise convolution reload is currently not supported
weights to reload method cannot be nil
weights buffer should have %lu bytes of data
Internal error has occured
supportsSecureCoding
TB,R
Data source must be NSSecureCoding conformant to serialize gradient object
Number of source feature channels needed by convolution %lu are not available in image with %lu feature channels
Number of destination feature channels needed by convolution gradient w.r.t data %lu are not available in image with %lu feature channels at offset %lu
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
TQ,R,N,V_groups
dataSource
T@"<MPSCNNConvolutionDataSource>",R,&,N,V_dataSource
gradientOption
TQ,N,V_gradientOption
serializeWeightsAndBiases
TB,N,V_serializeWeightsAndBiases
kMPSCNNConvolutionGradientSerializeWeightsAndBiases
MPSCNNConvolutionGradientIsFullyConnected
MPSCNNConvolutionDataSourceClass
MPSCNNConvolutionDataSource
MPSCNNConvolutionGradientInputFeatureChannels
MPSCNNConvolutionGradientOutputFeatureChannels
MPSCNNConvolutionGradientGroups
kMPSCNNConvolutionGradientWeightsDataType
kMPSCNNConvolutionGradientWeights
[%@ initWithDevice:keepProbability:seed:] Failed: the valid range of keepProbability (%lu) is (0.0f, 1.0f)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNDropout.mm
keepProbability: %f
seed: %lu
keepProbability
Tf,R,N,V_keepProbability
seed
TQ,R,N,V_seed
maskStrideInPixels
T{?=QQQ},R,N,V_maskStrideInPixels
MPSCNNDropoutKeepProbability
MPSCNNDropoutSeed
MPSCNNDropoutMaskStrideInPixelsWidth
MPSCNNDropoutMaskStrideInPixelsHeight
MPSCNNDropoutMaskStrideInPixelsDepth
EncodeDropoutCommon
YES == [filter isKindOfClass: MPSCNNDropoutGradient.class]
YES == [filter isKindOfClass: MPSCNNDropout.class]
[%@ encode...] valid values for maskStrideInPixels {%lu %lu %lu} are 0 and 1
[%@ encode...] operates only on a single image
[%@ encode...] the dropout state object cannot be nil
[%@ encode...] mask data in the state object must not be nil for this filter. Call resultStatesForSourceImage:sourceStates to initialize the state before calling encode.
[%@ encode...] not enough source images:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough labels data:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough destination images:  offset.z + clipRect.size.depth > destinationImage.numberOfImages
MPSCNNDropoutGradientKeepProbability
MPSCNNDropoutGradientSeed
MPSCNNDropoutGradientMaskStrideInPixelsWidth
MPSCNNDropoutGradientMaskStrideInPixelsHeight
MPSCNNDropoutGradientMaskStrideInPixelsDepth
Cannot directly initialize MPSCNNUpsampling. Use one of the sub-classes of MPSCNNUpsampling.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNUpsampling.mm
scale factor in the x dimension (%lu) must be > 0
scale factor in the y dimension (%lu) must be > 0
invalid filter type (%lu)
scaleFactorX: %f
scaleFactorY: %f
scaleFactorX
Td,R,N,V_scaleFactorX
scaleFactorY
Td,R,N,V_scaleFactorY
MPSCNNUpsampling_tex2d_tex2d_general
MPSCNNUpsampling_tex2darray_tex2darray_general
MPSCNNUpsampling_tex2d_tex2d_special_scaleFactor2
MPSCNNUpsampling_tex2darray_tex2darray_special_scaleFactor2
MPSCNNUpsampling_bilinear_tex2d_tex2d_general_float32
MPSCNNUpsampling_bilinear_tex2darray_tex2darray_general_float32
MPSCNNUpsampling_bilinear_tex2d_tex2d_special_scaleFactor2_float32
MPSCNNUpsampling_bilinear_tex2darray_tex2darray_special_scaleFactor2_float32
MPSCNNUpsampling.filterType
MPSCNNUpsampling.scaleFactorX
MPSCNNUpsampling.scaleFactorY
[%@ encode...] Specificed scaleFactorX would result in destination texture width that exceeds the maximum allowed texture width
[%@ encode...] Specificed scaleFactorY would result in destination texture height that exceeds the maximum allowed texture height
MPSCNNGradientKernel.kernelOffsetX
MPSCNNGradientKernel.kernelOffsetY
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] no padding method set. Can not compute result.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MetalPerformanceShaders/MPSCNNGradientKernel.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] the object padding method %p does not respond to the destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor: selector
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImage for destination.  Encode failed.
[%@ encode] Error: Gradient filters do not support gradient operations for Inference kernels that use the clipRect to operate on a subregion of the result
This would force the gradient kernel to have to do software edging at significant performance cost.
Use the slice operator to  trim away the unwanted parts of the gradient input.
[%@ encode] Error: Unknown state type.  Encode failed.
[%@ encodeToCommandBuffer:sourceGradients:...] Unable to create MPSImageDescriptor for destination.  Encode failed.
kernelOffsetX
Tq,N,V_kernelOffsetX
kernelOffsetY
Tq,N,V_kernelOffsetY
a: %f
b: %f
c: %f
Tf,R,N,V_a
Tf,R,N,V_b
Tf,R,N,V_c
descriptor
T@"MPSNNNeuronDescriptor",R,N,V_descriptor
Internal error: default encode for gradient kernels doesn't take an result state
Internal error: default encode for gradient kernels has an input state
Internal error: gradient kernels take an input state
Internal error: gradient kernels take multiple input images
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
[%@ apply...] commandBuffer may not be nil]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSMatrixFullyConnected.mm
[%@ apply...] input matrix may not be nil
[%@ apply...] weight matrix may not be nil
[%@ apply...] result matrix may not be nil
[%@ apply...] input matrix origin z component must be 0
[%@ apply...] weight matrix origin z component must be 0
[%@ apply...] result matrix origin z component must be 0
Only outputs of MPSDataTypeFloat32 are supported.
Only bias vector value types of MPSDataTypeFloat32 are supported.
Only input matrix value types of MPSDataTypeFloat32 are supported.
Only weight matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
filter.batchStart not within domain of inputMatrix.
filter.batchStart not within domain of weightMatrix.
filter.batchStart not within domain of resultMatrix.
filter.batchStart not within domain of biasVector.
secondarySourceMatrixOrigin.y not within domain of weightMatrix.
secondarySourceMatrixOrigin.x not within domain of weightMatrix.
primarySourceMatrixOrigin not within domain of inputMatrix.
PReLU param-A array failed to set.
[%@ initWithCoder:device:] Failed: Unable to read array for MPSCNNNeuronTypePReLU.
For PReLU, use -setNeuronToPReLUWithParametersA:
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
sourceOutputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
neuronType
Ti,N,V_neuronType
neuronA
Tf,N,V_neuronA
neuronB
Tf,N,V_neuronB
neuronC
Tf,N,V_neuronC
sourceNumberOfFeatureVectors
TQ,N,V_sourceNumberOfFeatureVectors
sourceInputFeatureChannels
TQ,N,V_sourceInputFeatureChannels
sourceOutputFeatureChannels
TQ,N,V_sourceOutputFeatureChannels
alpha
Td,N,V_alpha
Only outputs of MPSDataTypeFloat32 and MPSDataTypeFloat16 are supported.
Input matrix value type must match output matrix value type.
sourceMatrixOrigin not within domain of inputMatrix.
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixFullyConnected_AnyM
MatrixFullyConnectedTexture_M4
MatrixNeuron_float
MatrixNeuron_half
MPSMatrixFullyConnected._alpha;
MPSMatrixFullyConnected._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnected._sourceInputFeatureChannels;
MPSMatrixFullyConnected._sourceOutputFeatureChannels;
MPSMatrixFullyConnected._neuronType;
MPSMatrixFullyConnected._neuronA;
MPSMatrixFullyConnected._neuronB;
MPSMatrixFullyConnected._neuronC;
MPSMatrixFullyConnected._perChannelNeuronA;
[%@ initWithDevice:dataSource:] dataSource.load should return YES
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNBatchNormalization.mm
[%@ encodeBatchToCommandBuffer...] Error: convenience methods that return a image batch must have clipRect.origin.z = 0.  We can't return empty batch nodes in a NSArray.
Cannot create state for images with more feature channels than used to initialize batch normalization filter.
[%@ reloadDataSource:] dataSource.load should return YES
state does not have valid gamma and beta buffers.
[%@ %@] Error: dataSource does not support NSSecureCoding
feature channels: %lu
epsilon: %g
data source: %@
numberOfFeatureChannels
TQ,R,N,V_numberOfFeatureChannels
epsilon
Tf,N,V_epsilon
T@"<MPSCNNBatchNormalizationDataSource>",R,&,N,V_dataSource
imageBatchNormalization
imageBatchNormalizationArray
batchNormSimpleBufferCopy
kMPSCNNBatchNormalization.s
kMPSCNNBatchNormalization.o
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNConvolutionTranspose.mm
Filter weights pointer should be non-null
Feature channel layout of source and MPSCNNConvolutionTranspose filter doesn't match
Feature channel layout of destination and MPSCNNConvolutionTranspose filter doesn't match
Number of source feature channels needed by convolution %lu are not available in image with %lu feacture channels
Number of destination feature channels needed by convolution %lu are not available in image with %lu feature channels at offset %lu
%@inputFeatureChannels: %lu
outputFeatureChannels: %lu
Feature channel layout: %lu
Groups: %lu 
kernelOffset: {%zd, %zd}
neuron type: %s
neuron A:  %10.14f
neuron B:  %10.14f
neuron C:  %10.14f
featureChannelsLayout
TQ,R,N,V_featureChannelsLayout
accumulatorPrecisionOption
TQ,N
MPSCNNConvolutionTransposeVers
MPSCNNConvolutionTransposeWidth
MPSCNNConvolutionTransposeHeight
MPSCNNConvolutionTransposeInputFeatureChannels
MPSCNNConvolutionTransposeOutputFeatureChannels
MPSCNNConvolutionTransposeStrideInPixelsX
MPSCNNConvolutionTransposeStrideInPixelsY
MPSCNNConvolutionTransposeGroups
MPSCNNConvolutionTransposeFeatureChannelsLayout
MPSCNNConvolutionTransposeKernelOffsetX
MPSCNNConvolutionTransposeKernelOffsetY
MPSCNNConvolutionTransposeNeuron
add_zeroes
add_zeroes_array
add_zeroes_array_2d
You must call -gradientFiltersWithSources:gradientImages: for this filter
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNArithmeticNodes.mm
[%@ gradientFiltersWithSources:] This method requires one gradient image as input
[%@ gradientFiltersWithSources:] gradientImages[0] must be valid and contain the source gradient
primaryStrideInPixelsX
TQ,N,V_primaryStrideInPixelsX
primaryStrideInPixelsY
TQ,N,V_primaryStrideInPixelsY
secondaryStrideInPixelsX
TQ,N,V_secondaryStrideInPixelsX
secondaryStrideInPixelsY
TQ,N,V_secondaryStrideInPixelsY
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNBinaryArithmeticNode
Internal error: default encode for binary kernels doesn't take an input state
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalizationGradient.mm
imageInstanceNormalizationThreadgroupDot
imageInstanceNormalizationImageDot
imageInstanceNormalizationGradient
imageInitialDotBase
imageFinalSumBase
imageThreadgroupSumDotBase
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingNearestNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSCNNUpsamplingNodes.mm
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingBilinearNode
[%@ initWithDevice:resultImage:resultStates:] error: resultImage may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNGraph.mm
[%@ initWithDevice:resultImage:resultStates:] error: resultImage must be a child class of MPSNNImageNode
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph consumes MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces intermediate image objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a MPSImage
[MPSNNGraph encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:] error: source images must currently be type compatible with half float texture loads.
Source image [%lu] has pixel format %s
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
Did you perhaps forget to provide the state objects for labels and weights for the loss layer?
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceStates[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: destination image allocator may not be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a array of MPSImage
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is not a MPSImage
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
<nil>
<no description>
outputStateIsTemporary: %s
destinatonImageAllocator: %s
list of nodes:
(Note: missing nodes have been optimized away.)
[%@ initWithCoder:device:] Failed: unable to read class of MPSNNGraph destination image allocator.
[%@ initWithCoder:device:] Failed: unable to find class of MPSNNGraph destination image allocator %@ in application.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: outputStateIsTemporary must be set to NO for this method
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the destinationImageAllocator is set to create a temporary image.
A temporary image only lives as long as the MTLCommandBuffer. Its contents would be invalid by the time you were able to use them.
MPSErrorDomain
Failed to allocate MPSImage
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModePrivate. Perhaps you made a MPSTemporaryImage instead by mistake? That can't work.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModeMemoryless
MPS Internal Error: Unexpected command buffer status encountered: %lu
sourceImageHandles
T@"NSArray",R,C,N
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
T@"<MPSHandle>",R,N
outputStateIsTemporary
TB,N,V_outputStateIsTemporary
destinationImageAllocator
T@"<MPSImageAllocator>",&,N,V_destinationImageAllocator
format
TQ,N,V_format
resultImageIsNeeded
TB,R,N
[%@ initWithDevice:resultImage:] internal error: could not create filter for node:
[%@ initWithDevice:resultImage:] internal error: source image is NULL
[%@ initWithDevice:resultImage:] internal error: state image is NULL
v32@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQ}16^{EmptyStackFrame=}24
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{EmptyStackFrame=}16
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{OptimizationStackFrame=}16
v32@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQ}16^{EncodeFrame=@@@@@QQQ^{Graph}}24
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{EncodeFrame=@@@@@QQQ^{Graph}}16
Legend:
FilterNodeType[filter.index] {src.width x src.height x src.featureChannels src.format}[src.index] ->
{dest.width x dest.height x dest.featureChannels dest.format}[dest.index] offset: destinationFeatureChannelOffset
=============================================================================================================
v32@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQ}16^{EncodeBatchFrame=@@@@^{NSArray}QQQ^{Graph}}24
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{EncodeBatchFrame=@@@@^{NSArray}QQQ^{Graph}}16
<no filters>
<none specified>
Internal Error: unhandled MPSImageFeatureChannelFormat %lu in [%@ debugDescription]
resultFormat:  %s
v24@?0^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}8^{AutoreleasePoolStackFrame=@}16
Warning: Some parts of the encoded graph appear to be missing. 
 %lu filters, %lu images and %lu states were found.
 Expected: %lu filters, %lu images, %lu states
trainingStyle
, %lu
Filter: %@ {%lu}
Source Images: %lu {%s}
Source States: %lu
Result Images: %lu {%lu}
Result States: %lu
Filter:
  %@
Error: could not unpack resource node. File data segment too small
Error: could not unpack resource node. File version too new
Error: could not unpack resource node. unknown exception %u
MPSNNGraphOutputStateIsTemporary
MPSNNGraphc
MPSNNGraphA
MPSNNGraphResultIsNeeded
MPSNNGraph.filterNodes
MPSNNGraph.imageNodes
MPSNNGraph.stateNodes
MPSNNGraph.filterCount
MPSNNGraph.imageCount
MPSNNGraph.stateCount
MPSNNGraph.exportedImages
Data
ResourceWrapper.d
ResourceWrapper.hc
ResourceWrapper.h
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu   "%s"
padding policy: %s
(%@ --> %@)
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
Out of memory:  Append node failed. This graph is unlikely to produce expected results.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/NodeList.h
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNNormalizationGradient.mm
Tf,N,V_alpha
beta
Tf,N,V_beta
delta
Tf,N,V_delta
kernelSize
TQ,R,N,V_kernelSize
kernelWidth
TQ,R,N,V_kernelWidth
kernelHeight
TQ,R,N,V_kernelHeight
alpha:          %f
beta:           %f
delta:          %f
p0:             %f
pm:             %f
ps:             %f
Tf,N,V_p0
Tf,N,V_pm
Tf,N,V_ps
cross_channel_normalization_gradient
cross_channel_normalization_gradient_array
local_contrast_normalization_gradient
local_contrast_normalization_gradient_array
spatial_normalization_gradient
spatial_normalization_gradient_array
MPSCNNCrossChannelNormalizationGradient.kernelSize
MPSCNNCrossChannelNormalizationGradient.alpha
MPSCNNCrossChannelNormalizationGradient.beta
MPSCNNCrossChannelNormalizationGradient.delta
[%@ encode...] info->primaryOffset.z != 0 not supported
[%@ encode...] info->primaryOffset.z == info->secondaryOffset.z failed
[%@ encode...] info->clipRect.origin.z != 0 not supported
MPSCNNSpatialNormalizationGradient.kernelWidth
MPSCNNSpatialNormalizationGradient.kernelHeight
MPSCNNSpatialNormalizationGradient.alpha
MPSCNNSpatialNormalizationGradient.beta
MPSCNNSpatialNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.kernelWidth
MPSCNNLocalContrastNormalizationGradient.kernelHeight
MPSCNNLocalContrastNormalizationGradient.alpha
MPSCNNLocalContrastNormalizationGradient.beta
MPSCNNLocalContrastNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.p0
MPSCNNLocalContrastNormalizationGradient.pm
MPSCNNLocalContrastNormalizationGradient.ps
[%@ initWithSource:labels:lossDescriptor:] descriptor may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MetalPerformanceShaders/MPSNNLossNode.mm
[%@ gradientFilterWithSources:] Error: the MPSNNLoss filter doesn't have a corresponding loss gradient filter.
It produces the gradient directly as its MPSImage destination and consequently acts as its own gradient filter.
inputLabels
T@"MPSNNLabelsNode",R,&,N,V_labels
Internal error: The Loss filter needs loss information. The loss labels are missing. 
[%@ cnnLossDataDescriptorWithData:layout:size:...] invalid data layout type (%lu)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNLoss.mm
layout: %s
size: {%lu, %lu, %lu}
bytesPerRow: %lu
bytesPerImage: %lu
layout
TQ,R,N,V_layout
size
T{?=QQQ},R,N,V_size
bytesPerRow
TQ,N,V_bytesPerRow
bytesPerImage
TQ,N,V_bytesPerImage
[%@ setLabelSmoothing...] labelSmoothing must be in the range [0.0f, 1.0f]
[%@ setLabelSmoothing...] labelSmoothing parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy, MPSCNNLossTypeSigmoidCrossEntropy
[%@ setNumberOfClasses...] number of classes must be greater than 0
[%@ setNumberOfClasses...] number of classes parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy
[%@ setEpsion...] epsilon parameter is valid only for the following loss type(s): MPSCNNLossTypeLog
[%@ setDelta...] delta parameter is valid only for the following loss type(s): MPSCNNLossTypeHuber
[%@ cnnLossDescriptorWithType:reductionType:...] invalid loss type (%lu)
[%@ cnnLossDescriptorWithType:reductionType:...] invalid reduction type (%lu)
lossType: %d
reductionType: %d
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
lossType
TI,N,V_lossType
reductionType
Ti,N,V_reductionType
weight
Tf,N,V_weight
labelSmoothing
Tf,N,V_labelSmoothing
numberOfClasses
TQ,N,V_numberOfClasses
Method unavailable. Use one of the available interfaces instead.
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] lossImageSize dimensions must be > 1
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels must be valid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= labels.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weightsDescriptor is specified, but the weights data is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) must match the size of labels data ({%lu, %lu, %lu})
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= weights.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
Cannot directly initialize MPSCNNLoss. Use initWithDevice:lossDescriptor: instead.
invalid loss type (%lu)
invalid reduction type (%lu)
TI,R,N,V_lossType
Ti,R,N,V_reductionType
Tf,R,N,V_weight
Tf,R,N,V_labelSmoothing
TQ,R,N,V_numberOfClasses
Tf,R,N,V_epsilon
Tf,R,N,V_delta
MPSDataLayoutHeightxWidthxFeatureChannels
MPSDataLayoutFeatureChannelsxHeightxWidth
Invalid data layout type
MPSCNNLoss
Gradient
MPSCNNLossLossType
MPSCNNLossReductionType
MPSCNNLossWeight
MPSCNNLossLabelSmoothing
MPSCNNLossNumberOfClasses
MPSCNNLossEpsilon
MPSCNNLossDelta
[%@ encode...] state must be valid
[%@ encode] Error: This filter does not support clipRects that operate on a subregion of the result.
[%@ encode...] label weights cannot be used together with a single weight parameter != 1.0f
[%@ encode...] The weights parameter is invalid for this operation; use a single weight value
[%@ encode...] The only valid reduction type for the loss function of type MPSCNNLossTypeCosineDistance is MPSCNNReductionTypeSum
[%@ encode...] result loss image size invalid; this filter returns a scalar loss value when reduction type is not MPSCNNReductionTypeNone
[%@ encode...] destinationImage size invalid; when reduction type is MPSCNNReductionTypeNone, the destinationImage should be at least as large as the specified clipRect parameter
[%@ encode...] not enough labels data:  offset.z + clipRect.size.depth > number of images in labels data
[%@ encode...] not enough weights data:  offset.z + clipRect.size.depth > number of images in weights data
[%@ encode...] number of non-zero weights cannot be 0 for reduction type MPSCNNReductionTypeSumByNonZeroWeights
[%@ encode...] weights cannot be used together with a single weight != 1.0f
[%@ encode...] weights parameter is invalid for this operation; use a single weight value
[%@ encode...] The only reduction type for the loss function of type MPSCNNLossTypeCosineDistance is MPSCNNReductionTypeSum
[%@ encode...] not enough labels / weights data:  clipRect.size.depth > number of images in labels data
[%@ encode...] internal error
Cannot directly initialize MPSCNNUpsamplingGradient. Use one of the sub-classes of MPSCNNUpsamplingGradient.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNUpsamplingGradient.mm
MPSCNNUpsamplingGradient_tex2d_tex2d_general
MPSCNNUpsamplingGradient_tex2darray_tex2darray_general
MPSCNNUpsamplingGradient_tex2d_tex2d_special_scaleFactor2
MPSCNNUpsamplingGradient_tex2darray_tex2darray_special_scaleFactor2
MPSCNNUpsamplingGradient_bilinear_tex2d_tex2d_general_float32
MPSCNNUpsamplingGradient_bilinear_tex2darray_tex2darray_general_float32
MPSCNNUpsamplingGradient_bilinear_tex2d_tex2d_special_scaleFactor2_float32
MPSCNNUpsamplingGradient_bilinear_tex2darray_tex2darray_special_scaleFactor2_float32
MPSCNNUpsamplingGradient.filterType
MPSCNNUpsamplingGradient.scaleFactorX
MPSCNNUpsamplingGradient.scaleFactorY
depthwiseConvolution
cnnConvArray_winograd_2x2_3x3_32x32_sgemm
cnnConvArray_32x32_sgemm
Interleaved per pixel layout not supported on OSX
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNConvolutionOSX.mm
copyWeightsAndBiases
cnnConv_Update_32x32
parent filter: %p
format: %d
handle: <%p> %@
        %@
handle
T@"<MPSHandle>",&,N,V_handle
imageAllocator
T@"<MPSImageAllocator>",&,N,V_imageAllocator
exportFromGraph
TB,N,V_exportFromGraph
synchronizeResource
TB,N,V_synchronize
parent filter: %p
handle: <%p> %@
synchronize: %s
        %@
[%@ initWithSourceImages...] sourceImages may not be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNGraphNodes.mm
[%@ initWithSourceImages...] sourceImages.count may not be 0
[%@ initWithSourceImages...] sourceStates.count may not be 0
%@, %p
%@ "%@"
source images: %@
source states:  %@
resultImage:   %p
result states: %@
padding policy: %@
<no label>
[%@ newFilterNode] Internal error: child class fails to override this method.
[%@ gradientFilterWithSources:] This is not a unary filter. Please use gradientFiltersWithSources: (extra 's') instead. 
[%@ gradientFilterWithSources:] Internal error: this isn't a unary filter and needs to override this method to return multiple filters
resultImage
T@"MPSNNImageNode",R,N,V_resultImage
resultState
T@"MPSNNStateNode",R,N
resultStates
T@"NSArray",R,N
paddingPolicy
T@"<MPSNNPadding>",&,N,V_paddingPolicy
label
T@"NSString",C,V_label
gradient for %p "%@"
gradient for %p
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSNNSlice.mm
Slice
Source Index: %lu
slice_along_feature_channels_array_array
slice_along_width_height_array_array
slice_along_width_height
slice_along_width_height_noarray_array
slice_along_width_height_array_noarray
Error: EncodeSlice() encountered caller of wrong class type
Insufficient number of feature channels in destination %p
MPSNNConcatenationGradient.sourceIndex
[%@ encode...] filter initialized with no feature channels.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalization.mm
Cannot create state for images containing multiple images.
data source: %p %@
epsilon: %g
T@"<MPSCNNInstanceNormalizationDataSource>",R,&,N,V_dataSource
gamma
T@"<MTLBuffer>",R,N
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
instance normalization filter: %@
feature channels: %lu
epsilon: %g
instanceNormalization
T@"MPSCNNInstanceNormalization",R,&,N,V_instanceNormalization
gradientForGamma
gradientForBeta
imageInstanceNormalizationThreadgroupSum
imageInstanceNormalizationImageSum
imageInstanceNormalization
[%@ encode...] filter initialized with %lu feature channels but destination (after offset) contains only %lu feature channels.
[%@ encode...] filter initialized with %lu feature channels but source (after offset) contains only %lu feature channels.
kMPSCNNInstanceNormalization.s
kMPSCNNInstanceNormalization.o
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNPooling.mm
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
dilationRateX (%lu) must be > 0
dilationRateY (%lu) must be > 0
dilationRateX: %lu
dilationRateY: %lu
dilationRateX
TQ,R,N
dilationRateY
MPSCNNPooling.kernelWidth
MPSCNNPooling.kernelHeight
MPSCNNPooling.strideX
MPSCNNPooling.strideY
MPSCNNPooling_horizontal_tex2d_tex2d_max
MPSCNNPooling_horizontal_tex2darray_tex2darray_max
MPSCNNPooling_horizontal2_tex2d_tex2d_max
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max
MPSCNNPooling_vertical_tex2d_tex2d_max
MPSCNNPooling_vertical_tex2darray_tex2darray_max
MPSCNNPooling_2x2_tex2d_tex2d_max
MPSCNNPooling_2x2_tex2darray_tex2darray_max
MPSCNNPooling_3x3_tex2d_tex2d_max
MPSCNNPooling_3x3_tex2darray_tex2darray_max
MPSCNNPooling_new_tex2d_tex2d_max_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_vertical_tex2d_tex2d_max_swEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_2x2_tex2d_tex2d_max_swEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_3x3_tex2d_tex2d_max_swEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg
MPSCNNPooling_horizontal2_tex2d_tex2d_avg
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg
MPSCNNPooling_vertical_tex2d_tex2d_avg
MPSCNNPooling_vertical_tex2darray_tex2darray_avg
MPSCNNPooling_2x2_tex2d_tex2d_avg
MPSCNNPooling_2x2_tex2darray_tex2darray_avg
MPSCNNPooling_3x3_tex2d_tex2d_avg
MPSCNNPooling_3x3_tex2darray_tex2darray_avg
MPSCNNPooling_new_tex2d_tex2d_avg_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_vertical_tex2d_tex2d_avg_shEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_2x2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_3x3_tex2d_tex2d_avg_shEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_2
MPSCNNPooling.padSizeX
MPSCNNPooling.padSizeY
imageBatchNormalizationGradient
imageBatchNormalizationGradientArray
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNBinaryKernel.mm
<NULL>
primaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld  len: %ld}
secondaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destChannelOffset{%ld} 
device:        %p
primary edge mode:     %s
secondary edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
2nd KernelSize: {%lu x %lu}
primary stride:      {%lu x %lu}
secondary stride:      {%lu x %lu}
dilation rate:        {%lu x %lu}
2nd dilation rate:    {%lu x %lu}
backwards?  %s
broadcasting?  %s
padding:       %@
MPSImageEdgeModeClamp
MPSImageEdgeModeZero
destinationFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelOffset must be multiple of 4
secondarySourceFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelMaxCount must be multiple of 4
secondarySourceFeatureChannelMaxCount must be multiple of 4
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImage for destination.  Encode failed.
[%@ encode...] primary source may not be nil
[%@ encode...] secondary source may not be nil
[%@ %@] Error: the primary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the primary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the secondary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the secondary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the destination image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  primary source image is a temporary image with readCount of 0.
Backing texture for primary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  secondary source image is a temporary image with readCount of 0.
Backing texture for secondary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  destination image is a temporary image with readCount of 0.
Backing texture for destination image is no longer valid. image=%p
Feature Channel Layout of primary source and destination does not match
Feature Channel Layout of secondary source and destination does not match
Primary source %p texture type (%lu) is unsupported
Secondary source %p texture type (%lu) is unsupported
Primary source %p texture format %lu must support filtering.
Secondary source %p texture format %lu must support filtering.
Primary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Secondary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Primary source MTLTextureType2D must have primaryOffset.z = 0
Primary source MTLTextureType2D must have clipRect.size.depth = 1
Primary source MTLTextureTypeArray2D must have 0 <= primaryOffset.z < primaryImage.numberOfImages
Primary source MTLTextureTypeArray2D must have clipRect.size.depth such that _primaryOffset.z + clipRect.depth < primaryImage.numberOfImages
Secondary source MTLTextureType2D must have secondaryOffset.z = 0
Secondary source MTLTextureType2D must have clipRect.size.depth = 1
Secondary source MTLTextureTypeArray2D must have 0 <= secondaryOffset.z < secondaryImage.numberOfImages
Secondary source MTLTextureTypeArray2D must have clipRect.size.depth such that _secondaryOffset.z + clipRect.depth < secondaryImage.numberOfImages
Destination %p texture type (%lu) is unsupported
Destination %p texture format %lu  must be writable.
Destination %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Destination MTLTextureType2D must have clipRect.origin.z = 0
Destination MTLTextureType2D must have clipRect.size.depth = 1
Destination MTLTextureTypeArray2D must have 0 <= clipRect.origin.z < dest.numberOfImages
Destination MTLTextureTypeArray2D must have clipRect.size.depth such that clipRect.origin.z + clipRect.depth < dest.numberOfImages
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of primary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of secondary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture.  Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of primary source
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of secondary source
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of destination
[%@ encode...] the primary offset.z may not be negative
[%@ encode...] the secondary offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > primaryImages.count(%lu)
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > secondaryImages.count(%lu)
[%@ encode...] each of the individual primary source images in a batch must have numberOfImages = 1
[%@ encode...] each of the individual secondary source images in a batch must have numberOfImages = 1
[%@ encode...] error: all primary source image sizes must match
[%@ encode...] error: all secondary source image sizes must match
[%@ encode...] error: all primary source number of feature channels must match
[%@ encode...] error: all secondary source number of feature channels must match
[%@ %@] Error: the primary source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ %@] Error: the secondaryImage source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ encode...] each of the individual destination images in a batch must have numberOfImages = 1
[%@ encode...] error: all destination image sizes must match
[%@ encode...] error: all destination number of feature channels must match
[%@ batchEncode...] out of memory: unable to allocate storage to hold encode arguments on device.
[%@ destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset] Error:
 This is a binary filter. sourceImages should be an array of at least length 2.
%@: Error for filters that support broadcasting the input source image widths must match (or be 1)
%@: Error for filters that support broadcasting the input source image heights must match (or be 1)
%@: Error for filters that support broadcasting the input source image count must match (or be 1)
%@: Error for filters that support broadcasting the number of input source image feature channels must match (or be 1)
sourceWidth
sourceHeight
[%@ destinationImageDescriptorForSouceImage:] probable internal error 8: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error H: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error 16: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] probable internal error 32: invalid source image encoding. 0x%16.16llx
[%@ destinationImageDescriptorForSouceImage:] unhandled pixel encoding: 0x%16.16llx
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch count is smaller than the primaryImage batch count
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
primaryOffset
T{?=qqq},N,V_primaryOffset
secondaryOffset
T{?=qqq},N,V_secondaryOffset
clipRect
T{?={?=QQQ}{?=QQQ}},N,V_clipRect
destinationFeatureChannelOffset
TQ,N,V_destinationFeatureChannelOffset
primarySourceFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelOffset
secondarySourceFeatureChannelOffset
TQ,N,V_secondarySourceFeatureChannelOffset
primarySourceFeatureChannelMaxCount
TQ,N,V_primarySourceFeatureChannelMaxCount
secondarySourceFeatureChannelMaxCount
TQ,N,V_secondarySourceFeatureChannelMaxCount
primaryEdgeMode
TQ,N,V_primaryEdgeMode
secondaryEdgeMode
TQ,N,V_secondaryEdgeMode
primaryKernelWidth
TQ,R,N,V_primaryKernelWidth
primaryKernelHeight
TQ,R,N,V_primaryKernelHeight
secondaryKernelWidth
TQ,R,N,V_secondaryKernelWidth
secondaryKernelHeight
TQ,R,N,V_secondaryKernelHeight
primaryDilationRateX
TQ,R,N,V_primaryDilationRateX
primaryDilationRateY
TQ,R,N,V_primaryDilationRateY
secondaryDilationRateX
TQ,R,N,V_secondaryDilationRateX
secondaryDilationRateY
TQ,R,N,V_secondaryDilationRateY
isBackwards
TB,R,N,V_isBackwards
isStateModified
padding
T@"<MPSNNPadding>",&,N,V_padding
Internal error: [%@ encodeWithCoder:] unavailable
MPSCNNBinaryKernel.primaryOffset.x
MPSCNNBinaryKernel.primaryOffset.y
MPSCNNBinaryKernel.primaryOffset.z
MPSCNNBinaryKernel.secondaryOffset.x
MPSCNNBinaryKernel.secondaryOffset.y
MPSCNNBinaryKernel.secondaryOffset.z
MPSCNNBinaryKernel.clipRect.origin.x
MPSCNNBinaryKernel.clipRect.origin.y
MPSCNNBinaryKernel.clipRect.origin.z
MPSCNNBinaryKernel.clipRect.size.width
MPSCNNBinaryKernel.clipRect.size.height
MPSCNNBinaryKernel.clipRect.size.depth
MPSCNNBinaryKernel.destinationFeatureChannelOffset
MPSCNNBinaryKernel.sourceFeatureChannelOffset1
MPSCNNBinaryKernel.sourceFeatureChannelOffset2
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount1
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount2
MPSCNNBinaryKernel.primaryEdgeMode
MPSCNNBinaryKernel.secondaryEdgeMode
MPSCNNBinaryKernel.checkFlags
MPSCNNBinaryKernel.kernelWidth
MPSCNNBinaryKernel.kernelHeight
MPSCNNBinaryKernel.secondaryKernelWidth
MPSCNNBinaryKernel.secondaryKernelHeight
MPSCNNBinaryKernel.primaryStride.x
MPSCNNBinaryKernel.primaryStride.y
MPSCNNBinaryKernel.secondaryStride.x
MPSCNNBinaryKernel.secondaryStride.y
MPSCNNBinaryKernel.dilationRate.x
MPSCNNBinaryKernel.dilationRate.y
MPSCNNBinaryKernel.secondaryDilationRate.x
MPSCNNBinaryKernel.secondaryDilationRate.y
MPSCNNBinaryKernel.isBackward
MPSCNNBinaryKernel.supportsBroadcasting
MPSCNNBinaryKernel.data
MPSCNNBinaryKernel.padding
MPSCNNBinaryKernel.data2
MPSCNNBinaryKernel.allocator
[%@ resource] Internal error: unhandled resource type
/BuildRoot/Library/Caches/com.apple.xbs/Binaries/MetalImage_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSStateInternal.h
MPSCNNBinaryImageFilter.className
MPSCNNBinaryImageFilter.class
batchNormalization
T@"MPSCNNBatchNormalization",R,&,N,V_batchNormalization
T{?=QQQ},R,N,V_maskStride
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNDropoutNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNDropoutNodes.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid neuron type (%lu)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNNeuron.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid initialization method for the following neuron type(s): MPSCNNNeuronPReLU
[%@ cnnNeuronPReLUDescriptorWithData:...] data must be valid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid (not a multiple of sizeof(float))
neuronType: %s
a: %f
b: %f
c: %f
data: %p
neuronType: %s
a: %f
b: %f
c: %f
Tf,N,V_a
Tf,N,V_b
Tf,N,V_c
data
T@"NSData",&,N,V_data
invalid neuron type (%lu)
[%@ initWithDevice:neuronDescriptor:...] data in neuron descriptor must be valid
[%@ initWithDevice:neuronDescriptor:...] data length (%lu) is invalid
Cannot directly initialize MPSCNNNeuron. Use initWithDevice:neuronDescriptor: or one of the sub-classes of MPSCNNNeuron
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation. See the requirements listed for the newBufferWithBytesNoCopy:length:options:deallocator Metal API.
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation
v24@?0^v8Q16
MPSCNNNeuronTypeNone  (f(x) = x)
MPSCNNNeuronTypeReLU  (f(x) = x >= 0 ? x : a * x)
MPSCNNNeuronTypeLinear  (f(x) = a * x + b)
MPSCNNNeuronTypeSigmoid  (f(x) = 1 / (1 + e^-x))
MPSCNNNeuronTypeHardSigmoid  (f(x) = clamp((x * a) + b, 0, 1))
MPSCNNNeuronTypeTanH    (f(x) = a * tanh(b * x))
MPSCNNNeuronTypeAbsolute  (f(x) = fabs(x))
MPSCNNNeuronTypeSoftPlus  (f(x) = a * log(1 + e^(b * x)))
MPSCNNNeuronTypeSoftSign  (f(x) = x / (1 + abs(x)))
MPSCNNNeuronTypeELU   (f(x) = x >= 0 ? x : a * (exp(x) - 1))
MPSCNNNeuronTypePReLU  (f(x[i]) = x[i] >= 0 ? x[i] : a[i] * x[i]), i in [0,featureChannels-1]
MPSCNNNeuronTypeReLUN  (f(x) = min((x >= 0 ? x : a * x), b))
MPSCNNNeuronTypePower  (f(x) = (a * x + b) ^ c)
MPSCNNNeuronTypeExponential  (f(x) = c ^ (a * x + b))
MPSCNNNeuronTypeLogarithm  (f(x) = log_c(a * x + b))
<invalid/missing type>
Ti,R,N,V_neuronType
T@"NSData",R,&,N,V_data
Cannot call this initializer on this class.
MPSCNNNeuronTypeName
MPSCNNNeuronA
MPSCNNNeuronB
MPSCNNNeuronC
MPSCNNNeuronAArrayIsNil
MPSCNNNeuronAArrayLength
MPSCNNNeuronAArray
cnnNeuronGradient
cnnNeuron
MPSCNNNeuronGradientTypeName
MPSCNNNeuronGradientA
MPSCNNNeuronGradientB
MPSCNNNeuronGradientC
MPSCNNNeuronGradientAArrayIsNil
MPSCNNNeuronGradientAArrayLength
MPSCNNNeuronGradientAArray
Cannot directly initialize MPSNNReduceUnary. Use one of the sub-classes of MPSNNReduceUnary.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSNNReduce.mm
ReduceOperation: %lu
clipRectSource
T{?={?=QQQ}{?=QQQ}},N,V_clipRectSource
Cannot directly initialize MPSNNReduceBinary. Use one of the sub-classes of MPSNNReduce.
primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_primarySourceClipRect
secondarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_secondarySourceClipRect
doWeightedSumByNonZeroWeights
reduce_min_row_simd_rgba
reduce_min_column_simd_rgba
reduce_min_feature_channels_simd_rgba
reduce_max_row_simd_rgba
reduce_max_column_simd_rgba
reduce_max_feature_channels_simd_rgba
reduce_mean_row_simd_rgba
reduce_mean_column_simd_rgba
reduce_mean_feature_channels_simd_rgba
reduce_mean_feature_channels_and_weight_simd_rgba
reduce_array_min_row_simd_rgba
reduce_array_min_column_simd_rgba
reduce_array_min_feature_channels_simd_rgba
reduce_array_max_row_simd_rgba
reduce_array_max_column_simd_rgba
reduce_array_max_feature_channels_simd_rgba
reduce_array_mean_row_simd_rgba
reduce_array_mean_column_simd_rgba
reduce_array_mean_feature_channels_simd_rgba
reduce_array_mean_feature_channels_and_weight_simd_rgba
reduce_min_row_quadshuffle_rgba
reduce_min_column_quadshuffle_rgba
reduce_max_row_quadshuffle_rgba
reduce_max_column_quadshuffle_rgba
reduce_mean_row_quadshuffle_rgba
reduce_mean_column_quadshuffle_rgba
reduce_array_min_row_quadshuffle_rgba
reduce_array_min_column_quadshuffle_rgba
reduce_array_min_feature_channels_quadshuffle_rgba
reduce_array_max_row_quadshuffle_rgba
reduce_array_max_column_quadshuffle_rgba
reduce_array_max_feature_channels_quadshuffle_rgba
reduce_array_mean_row_quadshuffle_rgba
reduce_array_mean_column_quadshuffle_rgba
reduce_array_mean_feature_channels_quadshuffle_rgba
reduce_array_mean_feature_channels_and_weight_quadshuffle_rgba
MPSNNReduce.clipRectSource.origin.x
MPSNNReduce.clipRectSource.origin.y
MPSNNReduce.clipRectSource.origin.z
MPSNNReduce.clipRectSource.size.width
MPSNNReduce.clipRectSource.size.height
MPSNNReduce.clipRectSource.size.depth
MPSNNReduce.reduceOp
MPSNNReduce.weight
MPSNNReduce.primarySourceClipRect.origin.x
MPSNNReduce.primarySourceClipRect.origin.y
MPSNNReduce.primarySourceClipRect.origin.z
MPSNNReduce.primarySourceClipRect.size.width
MPSNNReduce.primarySourceClipRect.size.height
MPSNNReduce.primarySourceClipRect.size.depth
MPSNNReduce.secondarySourceClipRect.origin.x
MPSNNReduce.secondarySourceClipRect.origin.y
MPSNNReduce.secondarySourceClipRect.origin.z
MPSNNReduce.secondarySourceClipRect.size.width
MPSNNReduce.secondarySourceClipRect.size.height
MPSNNReduce.secondarySourceClipRect.size.depth
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNKernel.mm
offset:        {%ld,%ld,%ld} sourceFeatureChannelRange{offset: %ld, len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destinationFeatureChannelOffset{%ld} 
device:        %p
edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
stride:        {%lu x %lu}
dilation factor {%lu x %lu}
backwards?  %s
destinationImageAllocator: %@
padding:       %@
sourceFeatureChannelOffset must be multiple of 4
setSourceFeatureChannelMaxCount must be multiple of 4
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: sourceImage batch may not be NULL
[%@ encode...] Error: commandBuffer may not be nil]
[%@ encode...] Error: source may not be nil
[%@ encode...] Error: destination may not be nil
[%@ encode...] Error: options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ encode...] Error: source feature channel offset (%lu) is too large to fit in the source image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) is too large to fit in the destination image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) must be divisible by 4.
Other values would require read-modify-write on individual texels which is not supported by some hardware and a problem for concurrent operation everywhere.
[%@ encode...]: Error: non-zero source feature channel offset unsupported for compound MPSImages. Use a MPSImageBatch instead.
[%@ %@] Error: the source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
Feature Channel Layout of source and destination does not match
Source %p texture type (%lu) is unsupported
Source %p texture format %lu  must support filtering.
Source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Source MTLTextureType2D must have offset.z = 0
Source MTLTextureType2D must have clipRect.size.depth = 1
Source MTLTextureTypeArray2D must have 0 <= offset.z < source.numberOfImages
Source MTLTextureTypeArray2D must have clipRect.size.depth such that _offset.z + clipRect.depth < source.numberOfImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: the filter edge mode must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: The number of source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of source
[%@ encode...] Error: an error (%s) was encountered preventing this kernel from encoding.
[%@ encode...] the offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > sourceImages.count(%lu)
[%@ encode...] each of the individual source images in a batch must have numberOfImages = 1
[%@ encode...] error: all source image sizes must match
[%@ encode...] error: all source number of feature channels must match
[%@ %@] Error: the source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
offset
T{?=qqq},N,V_offset
sourceFeatureChannelOffset
TQ,N,V_sourceFeatureChannelOffset
sourceFeatureChannelMaxCount
TQ,N,V_sourceFeatureChannelMaxCount
edgeMode
TQ,N,V_edgeMode
strideInPixelsX
TQ,R,N,V_strideInPixelsX
strideInPixelsY
TQ,R,N,V_strideInPixelsY
TQ,R,N,V_dilationRateX
TQ,R,N,V_dilationRateY
%s | %s | %s%s%s
%s, %s, %s%s%s
[MPSNNDefaultPadding paddingWithMethod:]: Can not create a new object with a custom sizing policy.
You must implement your own object using the MPSNNPadding Policy.
MPSCreatePaddingPolicy(): invalid / unknown bits in MPSNNPaddingMethod.
Error: overrelease of MPS owned MPSNNDefaultPadding object:
  %@
%@  variant: %@
MPSCNNKernel.offset.x
MPSCNNKernel.offset.y
MPSCNNKernel.offset.z
MPSCNNKernel.clipRect.origin.x
MPSCNNKernel.clipRect.origin.y
MPSCNNKernel.clipRect.origin.z
MPSCNNKernel.clipRect.size.width
MPSCNNKernel.clipRect.size.height
MPSCNNKernel.clipRect.size.depth
MPSCNNKernel.destinationFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelMaxCount
MPSCNNKernel.edgeMode
MPSCNNKernel.checkFlags
MPSCNNKernel.kernelWidth
MPSCNNKernel.kernelHeight
MPSCNNKernel.stride.x
MPSCNNKernel.stride.y
MPSCNNKernel.dilation.x
MPSCNNKernel.dilation.y
MPSCNNKernel.isBackward
MPSCNNKernel.data
MPSCNNKernel.padding
MPSCNNKernel.data2
MPSCNNKernel.allocator
SizeValidOnly
SizeSame
SizeFull
Size_reserved
AlignCentered
AlignTopLeft
AlignBottomRight
Align_reserved
AddRemainderToTopLeft
AddRemainderToTopRight
AddRemainderToBottomLeft
AddRemainderToBottomRight
MPSNNPaddingMethodCustom
MPSNNPaddingMethodExcludeEdges
MPSNNPaddingMethodExcludeEdges | MPSNNPaddingMethodCustom
kMPSNNPaddingMethod_vers
kMPSNNPaddingMethod
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelWidth may not be 0
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSCNNPoolingNodes.mm
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelHeight may not be 0
MPS internal error: Need to override newFilterNodeForDevice for %@
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelWidth may not be 0
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelHeight may not be 0
[%@ initWithGradientImages:forwardFilter:] Error forwardFilter %p is not a MPSCNNPoolingNode
[%@ initWithGradientImages:forwardFilter:] Error: the filter <%p> is not a MPSCNNDilatedPoolingMaxNode
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}32@?0@"MPSKernel"8r^^v16^Q24
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}32@?0^{_NSZone=}8r^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}16@"<MTLDevice>"24
Error: unable to read node data for %@ <%p>. File (or data chunk within file) too small.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/FilterNodeConstructors.mm
Error: unable to read node data for %@ <%p>. File version too new.
Error: unable to read node data for %@ <%p>. File version too old.
Error: unable to read node data for %@ <%p>. Unhandled / unknown error %u.
MPSInternalError: Cant copy object with internal id out of bounds.
MPSInternalError: attempted to copy object type %lu but ended up with object type %lu
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNSoftMaxGradient.mm
softmax_gradient
softmax_gradient_array
softmax_gradient_multipass
softmax_gradient_multipass_array
log_softmax_gradient
log_softmax_gradient_array
log_softmax_gradient_multipass
log_softmax_gradient_multipass_array
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->secondarySrc.featureChannels - info->secondarySourceFeatureChannelOffset) failed
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->dest.featureChannels) failed
[%@ initWithSource:] Probable error: concatenate a image with nothing?
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNConcatenationNode.mm
{%lu x %lu x %lu}[%lu]
%s (%lu) [%s] -> {%lu x %lu x %lu}[%lu]
padding policy: n/a
%s (%lu) %lu*[%s] -> %lu*{%lu x %lu x %lu}[%lu]
padding policy: n/a
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the gradient state was not produced by a MPSNNConcatenationNode.
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the sourceImage provided was not among the input images to the MPSNNConcatenationNode
TQ,N,V_kernelWidth
TQ,N,V_kernelHeight
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNSpatialNormalizationNode
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSCNNNormalizationNodes.mm
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNLocalContrastNormalizationNode
kernelSizeInFeatureChannels
TQ,N,V_kernelSizeInFeatureChannels
[%@ initWithSource:dataSource:] dataSource may not be NULL
TQ,N,V_trainingStyle
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:instanceNormalizationState:
instance normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
flags
TQ,N,V_flags
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNBatchNormalizationNode
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
batch normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU batch normalization update pass because the data source doesn't implement -updateGammaAndBetaWithBatchNormalizationState:
Please initialize the %@ class with initWithDevice:convolutionDescriptor:kernelWeights:biasTerms
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNInnerProduct.mm
Number of groups for inner product should be 1
strideX for inner product should be 1
strideY for inner product should be 1
initializer unavailable
strideX should be 1 for fully connected kernel
strideY should be 1 for fully connected kernel
Number of groups should be 1 fully connected kernel
Kernel width and src width must match for fully connected kernel
Kernel height and src height must match for fully connected kernel
clipRect width must be 1 for fully connected kernel
clipRect height must be 1 for fully connected kernel
[<MPSCNNConvolutionDataSource> initWithSource:neuronInfo:batchNorm] Internal error: attempted to overwrite a convolution data source descriptor batch norm info with another set of batch norm info.
These should not be coalesced.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSCNNConvolutionGraphNodes.mm
rangesForUInt8Kernel
rangesForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method 
lookupTableForUInt8Kernel
lookupTableForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method
[%@ initWithSource:convolutionDescriptor:kernelWeights:biasTerms]: kernel weights may not be nil
convolutionState
T@"MPSCNNConvolutionStateNode",R,N
convolutionGradientState
T@"MPSCNNConvolutionGradientStateNode",R,N
Internal error: attempted to append neuron filter to convolution that already had a neuron filter
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: gradient state may not be nil
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState doesn't have a parent convolution with a dataSource.
There are no weights to use here and MPS can not continue.
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState creator isn't a convolution node.
There are no weights to use here and MPS can not continue.
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights must have a descriptor
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights.descriptor can not contain an integrated neuron.
A separate node must be built for neurons for training.
The graph will automatically integrate them later for inference.
MPSNNTrainingStyleUpdateDeviceNone
MPSNNTrainingStyleUpdateDeviceCPU
MPSNNTrainingStyleUpdateDeviceGPU
MPSNNTrainingStyleUpdateDeviceAll
training style: %@
CNNConvolutionGradientFilterNode::InitFilter() Error: unexpectedly could not get a data source from the inference convolution node.
Can not continue...
Error while unpacking a convolution gradient node: a valid dataSource could not be found in either the gradient node or its partner convolution to initialize the convolution weights
Error: could not updates weights for convolution without a MPSCNNConvolutionDataSource to talk to.
Perhaps your data source doesn't conform to <NSSecureCoding> and couldn't be saved?
Perhaps you created the convolution gradient node with a nil data source and there is no matching convolution node that has a datasource?
Error: can not update data source "%@" on GPU, because it does not implement updateWeightasAndBiasesWithCommandBuffer:sourceState:gradientState:.
convolution gradient weight update pass: the gradients may not be in a temporary image for CPU update.
Find the state result from the forward convolution and set it to be .exportFromGraph = YES
Error: can not update data source "%@" on GPU, because it does not implement -updateWeightasAndBiasesWithCommandBuffer:sourceState:gradient:.
convolution gradient weight update pass: the weight gradients may not be in a temporary state for CPU update.
convolution gradient weight update pass: the weights may not be in a temporary state for CPU update.
%@.convolutionGradientState is an invalid operation.  The class doesn't support producing state.
%@.convolutionState is an invalid operation.  The class doesn't support producing state.
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionGradientState
fused: %s,  a = %g b = %g c = %g
commandBuffer may not be nil.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationStatistics.mm
Each image in the batch must have the same number of feature channels.
Each image in the batch must have the same width.
Each image in the batch must have the same height.
v32@?0@"MPSImage"8Q16^B24
Not enough feature channels in each image to support the specified 'sourceFeatureChannelOffset'
TQ,N,V_numberOfFeatureChannels
imageInitialSumBase
imageThreadgroupSumBase
MPSNNNeuronDescriptor for fusing with convoution cannot be nil
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNConvolution.mm
Use -setNeuronType:parameterA:parameterB instead
Number of groups should be 1 for depthwise convolution.
Number of input channels must be divisible by groups parameter
Number of output channels must be divisible by groups parameter
Number of input channels in each group must be multiple of 4
Number of output channels in each group must be multiple of 4
kernel width: %lu
kernel height: %lu
Input feature channels: %lu
Output feature channels: %lu
X stride (pixels): %lu
Y stride (pixels): %lu
Groups:    %lu
subPixelScaleFactor:    %lu
dilationRateX:    %lu
dilationRateY:    %lu
neuronType:    %d
neuronA:     %f
neuronB:    %f
neuronC:    %f
Neuron (deprecated): %p
Error: can not add neuron to descriptor that already has one.
neuron already set on the convolution descriptor next layer cannot be fused
TQ,N,V_featureChannelsLayout
TQ,N,V_strideInPixelsX
TQ,N,V_strideInPixelsY
TQ,N,V_groups
TQ,N,V_dilationRateX
TQ,N,V_dilationRateY
fusedNeuronDescriptor
T@"MPSNNNeuronDescriptor",&,N,V_fusedNeuronDescriptor
neuron
T@"MPSCNNNeuron",&,N,V_neuron_deprecated
outputFeatureChannels (%lu) in convolution descriptor must be multiple of scaleFactor*scaleFactor=%lu becuase these values are rearragned in scaleFactor x scaleFactor pixel block by sub pixel convolution with each pixel having outputFeatureChannels/(scaleFactor*scaleFactor) channels
When number of groups (%lu) is greater than 1, number of feature channel in upsampled output image (outputFeatureChannels/(scaleFactor*scaleFactor)) (%lu) must be multiple of 4
subPixelScaleFactor
outputFeatureChannels (%lu) in convolution descriptor must be multiple of _inputFeatureChannels (%lu)
channelMultiplier:    %lu
channelMultiplier
sourceOffset
T{?=qqq},R,N,V_srcOffset
TQ,R,N,V_originalConvolutionSourceWidth
TQ,R,N,V_originalConvolutionSourceHeight
convolution: %@ %p "%@"
gradientForWeights
gradientForBiases
convolution
T@"MPSCNNConvolution",R,&,N,V_convolution
v8@?0
vDSP_vsmul
vDSP_vma
8-bit weights are only allowed for interleaved per array slice layout
for depth wise convolution, number of output feature channels (%lu) must be multiple of input feature channels (%lu)
for depth wise convolution, currently only channel multiplier of 1 is supported.
for depth wise convolution, groups should be 1.
depth wise convolution currently only supported for FP weights.
parameterA of depreated neuron property doesnt match the value set for neuronParameterA of convolution descriptor.
parameterB of depreated neuron property doesnt match the value set for neuronParameterB of convolution descriptor.
Neuron type of depreated neuron property doesnt match the value set for neuronType of convolution descriptor.
[%@ initWithDevice:convolutionDescriptor:weights:] weights.load should return YES
Only MPSDataTypeFloat32, MPSDataTypeFloat16 and MPSDataTypeUInt8 are supported by convolution.
Weights data provider data type is UInt8 but not method implemented to dequantize the weights
[%@ initWithDevice:convolutionDescriptor:weights:] unsupported weights.dataType: 0x%16.16llx
Failed to load data source
data source does not repond to selector lookupTableForUInt8Kernel
data source does not repond to selector rangesForUInt8Kernel
data source load failed
inputFeatureChannels: %lu
outputFeatureChannels: %lu
Feature channel layout: %lu
Groups: %lu scaleFactor: %lu
Internal error: Plugin data is nil.
External plugin not supported currently for batch processing.
Feature channel layout of source and MPSCNNConvolution filter doesn't match
Feature channel layout of destination and MPSCNNConvolution filter doesn't match
[%@ initWithDevice:convolutionDescriptor:weights:] dataSource.load should return YES
biases buffer should have %lu bytes of data
TQ,R,N,V_scaleFactor
T@"MPSCNNNeuron",R,N,V_neuron_deprecated
Ti,R,N
neuronParameterA
Tf,R,N
neuronParameterB
neuronParameterC
TQ,R,N,V_channelMultiplier
TQ,N,V_accumulatorPrecisionOption
weights
biases
MPSCNNConvolutionDescriptorVers
MPSCNNConvolutionDescriptorWidth
MPSCNNConvolutionDescriptorHeight
MPSCNNConvolutionDescriptorInputFeatureChannels
MPSCNNConvolutionDescriptorOutputFeatureChannels
MPSCNNConvolutionDescriptorStrideInPixelsX
MPSCNNConvolutionDescriptorStrideInPixelsY
MPSCNNConvolutionDescriptorGroups
MPSCNNConvolutionDescriptorFeatureChannelsLayout
MPSCNNConvolutionDescriptorSubPixelScaleFactor
MPSCNNConvolutionDescriptorDilationRateX
MPSCNNConvolutionDescriptorDilationRateY
MPSCNNConvolutionDescriptorNeuronType
MPSCNNConvolutionDescriptorNeuronA
MPSCNNConvolutionDescriptorNeuronB
MPSCNNConvolutionDescriptorNeuronC
MPSCNNConvolutionDescriptorIsDepthWiseConvolution
MPSCNNConvolutionDescriptorBatchNormalization.isNull
MPSCNNConvolutionDescriptorBatchNormalization.data
MPSCNNConvolutionDescriptorNeuronParameterA.isNull
MPSCNNConvolutionDescriptorNeuronParameterA.data
MPSCNNConvolutionWeight.dataLayout
MPSCNNConvolutionWeight.dataType
MPSCNNConvolutionBias.isNull
MPSCNNConvolutionWeight.data
MPSCNNConvolutionBias.data
MPSCNNConvolutionQuantizationData.data
dequantizeOSX
MPSCNNConvolutionFeatureChannelsLayout
MPSCNNConvolutionIsFullyConnected
MPSCNNConvolutionFlags
MPSCNNConvolutionNeuronBufferA.isNull
MPSCNNConvolutionNeuronBufferA.data
MPSCNNConvolutionBatchNormalizationData.isNull
MPSCNNConvolutionBatchNormalizationData.data
MPSCNNConvolutionInputFeatureChannels
MPSCNNConvolutionOutputFeatureChannels
MPSCNNConvolutionGroups
MPSCNNConvolutionNeuronInfo.type
MPSCNNConvolutionNeuronInfo.a
MPSCNNConvolutionNeuronInfo.b
MPSCNNConvolutionNeuronInfo.c
MPSCNNConvolutionScaleFactor
MPSCNNConvolutionQuantizationType
MPSCNNConvolutionChannelMultipler
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNNormalization.mm
MPSCNNNormalization_tex2d_tex2d_CHNorm
MPSCNNNormalization_tex2darray_tex2darray_CHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw2
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw3
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw4
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw5
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw6
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw7
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw8
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw9
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt2
MPSCNNNormalization_ArrayFC_GenCHNorm
MPSCNNNormalization_horizontal_tex2d_tex2d_XYNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_vertical_tex2d_tex2d_XYNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_horizontal_tex2d_tex2d_LCNNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_vertical_tex2d_tex2d_LCNNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNCrossChannelNormalization.kernelSize
MPSCNNCrossChannelNormalization.alpha
MPSCNNCrossChannelNormalization.beta
MPSCNNCrossChannelNormalization.delta
MPSCNNSpatialNormalization.kernelWidth
MPSCNNSpatialNormalization.kernelHeight
MPSCNNSpatialNormalization.alpha
MPSCNNSpatialNormalization.beta
MPSCNNSpatialNormalization.delta
MPSCNNLocalContrastNormalization.kernelWidth
MPSCNNLocalContrastNormalization.kernelHeight
MPSCNNLocalContrastNormalization.alpha
MPSCNNLocalContrastNormalization.beta
MPSCNNLocalContrastNormalization.delta
MPSCNNLocalContrastNormalization.p0
MPSCNNLocalContrastNormalization.pm
MPSCNNLocalContrastNormalization.ps
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSMatrixSum.mm
Requires at least two matrices to compute a sum.
Only matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
Offset vector must be of type MPSDataTypeUInt32.
v32@?0@"MPSMatrix"8Q16^B24
PReLU not supported.
rows
TQ,R,N,V_rows
columns
TQ,R,N,V_columns
count
TQ,R,N,V_count
transpose
TB,R,N,V_transpose
MatrixSum_float
MatrixSum_half
MatrixSumRemainder_float
MatrixSumRemainder_half
MPSMatrixSum.rows
MPSMatrixSum.columns
MPSMatrixSum.count
MPSMatrixSum.transpose
MPSMatrixSum.neuronType
MPSMatrixSum.neuronA
MPSMatrixSum.neuronB
MPSMatrixSum.neuronC
provider: %p
Error: unable to create a MPSNNCustomKernel with provider %p.
Can not continue.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Graph/MPSNNCustomFilterNode.mm
T{?=QQQ},N,V_kernelSize
stride
T{?=QQQ},N,V_stride
dilationRate
T{?=QQQ},N,V_dilationRate
TB,N,V_isBackward
Error: unable to create a MPSNNCustomKernel.Can not continue.
Provider:
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNSoftMax.mm
softmaxNleq4_RGBA
softmaxNgt4leq8_RGBA
softmaxNgt8leq12_RGBA
softmaxNdiv4_RGBA
softmaxN_RGBA
softmaxN_threadgroup
softmaxNleq4_array_RGBA
softmaxNgt4leq8_array_RGBA
softmaxNgt8leq12_array_RGBA
softmaxNdiv4_array_RGBA
softmaxN_array_RGBA
softmaxN_array_interleaved_pixel_threadgroup
softmaxN_array_interleaved_slice_threadgroup
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNGradientKernel.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MetalPerformanceShaders/MPSNNGradientState.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least one source image are expected for a MPSCNNConvolutionTranspose.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
offset: {%ld, %ld, %ld}
clipRect:                          {origin:{%lu, %lu, %lu}, size:{%lu, %lu, %lu}}
dest size:                         {w:%lu, h:%lu, images:%lu}
destination feature channel offset: %lu
source feature channel offset:      %lu
kernel size:                        %lu x %lu
pixel stride:                       %lu x %lu
dilation rate:                      %lu x %lu
padding:                            
max batch size:                     %lu
is backwards:                       %@
edge mode:                          %lu
source size:                       {%lu, %lu, %lu} fc: %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNBinaryGradientKernel.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: primary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: secondary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSCNNBinaryConvolution.mm
number of groups must be 1
[%@ initWithCoder:device:] failed. %@
Problem decoding buffers
Problem creating pooling filter for internal use.
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
inputFeatureChannels: %lu
outputFeatureChannels: %lu
NeuronType: %d
outputBias: %d
outputScale: %d
inputBias: %d
inputScale: %d
PoolingFilter: %@
convType: %lu
flags: %lu
kMPSCNNBinaryConvolution._fullyConnected
kMPSCNNBinaryConvolution._kernelWidth
kMPSCNNBinaryConvolution._kernelHeight
kMPSCNNBinaryConvolution._inputFeatureChannels
kMPSCNNBinaryConvolution._outputFeatureChannels
kMPSCNNBinaryConvolution._strideInPixelsX
kMPSCNNBinaryConvolution._strideInPixelsY
kMPSCNNBinaryConvolution._flags
kMPSCNNBinaryConvolution._convType
kMPSCNNBinaryConvolution._outputScaleValue
kMPSCNNBinaryConvolution._weights
kMPSCNNBinaryConvolution._inputbias
kMPSCNNBinaryConvolution._inputScale
kMPSCNNBinaryConvolution._outputbias
kMPSCNNBinaryConvolution._outputScale
kMPSCNNBinaryConvolution._neuronType
kMPSCNNBinaryConvolution._neuronParamA
kMPSCNNBinaryConvolution._neuronParamB
kMPSCNNBinaryConvolution._neuronParamC
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + outputFeatureChannels > dest.featureChannels
MPSCNNBinarize_2d_2d_float
MPSCNNBinarize_2d_2dArray_float
MPSCNNBinarize_2dArray_2d_float
MPSCNNBinarize_2dArray_2dArray_float
MPSCNNBetaBinarize_2d_2d_float
MPSCNNBetaBinarize_2d_2dArray_float
MPSCNNBetaBinarize_2dArray_2d_float
MPSCNNBetaBinarize_2dArray_2dArray_float
MPSCNNBinarizePixelFC_2d_2d_float
MPSCNNBinarizePixelFC_2d_2dArray_float
MPSCNNBinarizePixelFC_2dArray_2d_float
MPSCNNBinarizePixelFC_2dArray_2dArray_float
MPSCNNBetaBinarizePixelFC_2d_2d_float
MPSCNNBetaBinarizePixelFC_2d_2dArray_float
MPSCNNBetaBinarizePixelFC_2dArray_2d_float
MPSCNNBetaBinarizePixelFC_2dArray_2dArray_float
MPSCNNBinaryConvolve_2d_2d_float
MPSCNNBinaryConvolve_2d_2dArray_float
MPSCNNBinaryConvolve_2dArray_2d_float
MPSCNNBinaryConvolve_2dArray_2dArray_float
MPSCNNBetaBinaryConvolve_2d_2d_float
MPSCNNBetaBinaryConvolve_2d_2dArray_float
MPSCNNBetaBinaryConvolve_2dArray_2d_float
MPSCNNBetaBinaryConvolve_2dArray_2dArray_float
MPSCNNBinaryConvolvePixelFC_2d_2d_float
MPSCNNBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNImageScale_2d_2d_float
MPSCNNImageScale_2d_2dArray_float
MPSCNNImageScale_2dArray_2d_float
MPSCNNImageScale_2dArray_2dArray_float
MPSCNNImageScalePixelFC_2d_2d_float
MPSCNNImageScalePixelFC_2d_2dArray_float
MPSCNNImageScalePixelFC_2dArray_2d_float
MPSCNNImageScalePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightConvolve_2d_2d_float
MPSCNNBinaryWeightConvolve_2d_2dArray_float
MPSCNNBinaryWeightConvolve_2dArray_2d_float
MPSCNNBinaryWeightConvolve_2dArray_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnected_2d_2d_float
MPSCNNBinaryWeightFullyConnected_2d_2dArray_float
MPSCNNBinaryWeightFullyConnected_2dArray_2d_float
MPSCNNBinaryWeightFullyConnected_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2dArray_float
MTLComputePipelineState reflection failed
A compute pipeline state was returned but necessary reflection information about the nature of the kernel arguments is missing. Can not proceed.
Internal error: MPS encountered an unknown / unknown MTLArgument type when parsing the reflection for MPSNNCustomKernelParameters compute pipeline state creation
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Filters/MPSNNCustomKernel.mm
[%@ initForCustomKernel:inputImageNodeCount:pipelineDescriptor:completionHandler:] Error: kernel texture count is less than the inputImageNodeCount + 1 for the destination
[%@ initForCustomKernel:inputImageNodeCount:pipelineDescriptor:completionHandler:] Error: there must be at least two buffers in kernel 
%p %s
***Error building custom kernel (%s):
v32@?0@"<MTLComputePipelineState>"8@"MTLComputePipelineReflection"16@"NSError"24
kernel
T@"MPSNNCustomKernel",R,N,V_kernel
computePipelineState
T@"<MTLComputePipelineState>",R,N,V_pipelineState
inputImageNodeCount
TQ,R,N,V_inputImageNodeCount
maximumThreadgroupMemorySize
dispatchGridSize
T{?={?=QQQ}{?=QQQ}{?=QQQ}},N,V_gridSize
[%@ initWithDevice:kernelProvider] Illegal / unknown options: 0x%16.16llx provided by MPSNNCustomKernelProvider %p
[%@ initWithDevice:kernelProvider] provider may not be nil
[%@ initWithDevice:kernelProvider]: Error: kernelProvider doesn't conform to NSSecureCoding.
It must implement -encodeWithCoder: -initWithCoder: and -supportsSecureCoding
[%@ initWithDevice:kernelProvider]: Error: kernelProvider doesn't conform to NSCopying.
It must implement -copyWithZone:
[%@ initWithDevice:kernelProvider]: Error: kernelProvider must implement -isEqual:
[%@ initWithDevice:kernelProvider]: Error: kernelProvider must implement -maxSourceImageCount
[%@ initWithDevice:kernelProvider]: Error: kernelProvider must implement -parametersForKernel:sourceImages:sourceStates:destinationImage:prefetch:
[%@ initWithDevice:kernelProvider]: Error: kernelProvider must implement -isBackwards
[%@ offsetAtIndex:] index %lu exceeds maximum number of source images %lu
[%@ setOffset:AtIndex:] index %lu exceeds maximum number of source images %lu
[%@ edgeModeAtIndex:] index %lu exceeds maximum number of source images %lu
[%@ setEdgeMode:AtIndex:] index %lu exceeds maximum number of source images %lu
MPSNNCustomKernel.maxSourceCount
MPSNNCustomKernel.providerType
MPSNNCustomKernel.provider
MPSNNCustomKernel.paddingType
MPSNNCustomKernel.padding
MPSNNCustomKernel.destinationAllocatorType
MPSNNCustomKernel.destinationAllocator
MPSNNCustomKernel.clipRect.origin.x
MPSNNCustomKernel.clipRect.origin.y
MPSNNCustomKernel.clipRect.origin.z
MPSNNCustomKernel.clipRect.size.x
MPSNNCustomKernel.clipRect.size.y
MPSNNCustomKernel.clipRect.size.z
MPSNNCustomKernel.destinationFeatureChannelOffset
[%@ initWithCoder:device:] decoding of MPSNNCustomKernelProvider failed
[%@ destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:srcOffset:] error: too many source images provided
[%@ encode...] Error: too many source images
[%@ encodeToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage:] error:  source image is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage]: Error: MPSCustomKernelProvider returned nil MPSNNCustomKernelParameters
[%@ encode...] Custom kernel (%@) had nil pipeline state. Can not continue
T@"NSString",C
device
T@"<MTLDevice>",R
cpuCacheMode
storageMode
heap
T@"<MTLHeap>",R
allocatedSize
length
[%@ encode...] Error: myInfo buffer has invalid class %@
 id <MTLBuffer> or NSData*
kernelProvider
T@"<MPSNNCustomKernelProvider>",R,N,V_provider
[%@ init] This method is unavailable. Please call one of the other init methods.
[%@ initWithPipelineDescriptor:] Error: descriptor can not be nil.
MPSNNSimpleCustomKernelProvider.f1
MPSNNSimpleCustomKernelProvider.kernelSize.width
MPSNNSimpleCustomKernelProvider.kernelSize.height
MPSNNSimpleCustomKernelProvider.kernelSize.depth
MPSNNSimpleCustomKernelProvider.stride.width
MPSNNSimpleCustomKernelProvider.stride.height
MPSNNSimpleCustomKernelProvider.stride.depth
MPSNNSimpleCustomKernelProvider.dilationRate.depth
MPSNNSimpleCustomKernelProvider.dilationRate.width
MPSNNSimpleCustomKernelProvider.dilationRate.height
MPSNNSimpleCustomKernelProvider.isBackwards
MPSNNSimpleCustomKernelProvider.options
MPSNNSimpleCustomKernelProvider.ppc
MPSNNSimpleCustomKernelProvider.ppo
MPSNNSimpleCustomKernelProvider.uic
MPSNNSimpleCustomKernelProvider.uio
MPSNNSimpleCustomKernelProvider.label
MPSNNSimpleCustomKernelProvider.threadgroupMemorySize
kernelSize: {%lu, %lu, %lu}
stride:      {%lu, %lu, %lu}
dilationRate: {%lu, %lu, %lu}
isBackwards:    %d
functionName
T@"NSString",R,&,N,V_funcName
TB,N,V_isBackwards
options
TQ,N,V_options
T@"NSString",&,N,V_label
userInfo
T@"NSData",&,N,V_userInfo
threadgroupMemorySize
TQ,N,V_threadgroupMemorySize
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
/BuildRoot/Library/Caches/com.apple.xbs/Sources/MetalImage_Sim/MetalImage-100.6/MPSNeuralNetwork/Plugin/MPSCNNKernelPlugin.mm
[%@ encodeToCommandBuffer:computeCommandEncoder:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:]  Error: The device driver has failed to override this method
class
release
initWithDevice:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
initWithDevice:
initWithCoder:device:
decodeInt64ForKey:
encodeWithCoder:
encodeInt64:forKey:
copyWithZone:device:
libraryInfo
initWithDevice:kernelWidth:kernelHeight:
sourceSize
setSourceSize:
_sourceSize
debugDescription
stringWithFormat:
zeroPadSizeX
setZeroPadSizeX:
zeroPadSizeY
setZeroPadSizeY:
_zeroPadSizeX
_zeroPadSizeY
initWithDevice:kernelWidth:kernelHeight:dilationRateX:dilationRateY:strideInPixelsX:strideInPixelsY:
newTextureViewWithPixelFormat:textureType:levels:slices:
retainedReferences
retain
addCompletedHandler:
width
height
setComputePipelineState:
threadExecutionWidth
maxTotalThreadsPerThreadgroup
setTexture:atIndex:
setSamplerState:atIndex:
setBytes:length:atIndex:
dispatchThreadgroups:threadsPerThreadgroup:
isEqual:
setConstantValue:type:atIndex:
newFunctionWithName:constantValues:completionHandler:
initWithResource:
dealloc
init
_resourcePixelFormat
_resourceSize
decodeFloatForKey:
encodeFloat:forKey:
featureChannels
textureType
autorelease
setTextureType:
setPixelFormat:
setWidth:
setHeight:
setArrayLength:
alloc
initWithDevice:textureDescriptor:
temporaryStateWithCommandBuffer:textureDescriptor:
copyToBinaryGradientState:primaryImage:secondaryImage:sourceStates:destinationImage:
pixelFormat
privateResultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:commandBuffer:isTemporary:
count
objectAtIndexedSubscript:
primarySourceFeatureChannelOffset
primarySourceFeatureChannelMaxCount
secondarySourceFeatureChannelOffset
secondarySourceFeatureChannelMaxCount
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset:
isKindOfClass:
encodeToCommandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
setPrimaryStrideInPixelsX:
setPrimaryStrideInPixelsY:
setPrimaryStrideInFeatureChannels:
setSecondaryStrideInPixelsX:
setSecondaryStrideInPixelsY:
setSecondaryStrideInFeatureChannels:
initWithDevice:arithmeticType:
resultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationImages:
primaryScale
setPrimaryScale:
secondaryScale
setSecondaryScale:
bias
setBias:
minimumValue
setMinimumValue:
maximumValue
setMaximumValue:
primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
_primaryScale
_secondaryScale
_bias
_minimumValue
_maximumValue
_primaryStrideInFeatureChannels
_secondaryStrideInFeatureChannels
_arithmeticType
decodeBoolForKey:
encodeBool:forKey:
initWithDevice:arithmeticType:isSecondarySourceFilter:
isSecondarySourceFilter
_isSecondarySourceFilter
_reduceRows
_reduceColumns
_reduceFeatureChannels
initWithDevice:isSecondarySourceFilter:
primaryStrideInPixelsX
primaryStrideInPixelsY
secondaryStrideInPixelsX
secondaryStrideInPixelsY
numberOfImages
depth
texture
initWithTexture:featureChannels:
imageDescriptorWithChannelFormat:width:height:featureChannels:numberOfImages:usage:
pushDebugGroup:
popDebugGroup
arrayLength
setThreadgroupMemoryLength:atIndex:
temporaryImageWithCommandBuffer:imageDescriptor:
device
initWithDevice:imageDescriptor:
setReadCount:
getRecurrentOutputImageForLayerIndex:
getMemoryCellImageForLayerIndex:
initWithCommandBuffer:recurrentImageDescriptors:cellImageDescriptors:isTemporary:layerCount:
isTemporary
recurrentImages
cellImages
nLayers
_isTemporary
temporaryMatrixWithCommandBuffer:matrixDescriptor:
rows
rowBytes
newBufferWithLength:options:
initWithBuffer:descriptor:
getRecurrentOutputMatrixForLayerIndex:
getMemoryCellMatrixForLayerIndex:
initWithCommandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
recurrentMatrices
cellMatrices
inputFeatureChannels
setInputFeatureChannels:
outputFeatureChannels
setOutputFeatureChannels:
inputTransform
setInputTransform:
outputTransform
setOutputTransform:
recurrentOutputTransform
setRecurrentOutputTransform:
useLayerInputUnitTransformMode
setUseLayerInputUnitTransformMode:
layerSequenceDirection
setLayerSequenceDirection:
useFloat32Weights
setUseFloat32Weights:
_useLayerInputUnitTransformMode
_useFloat32Weights
_inputFeatureChannels
_outputFeatureChannels
_inputTransform
_outputTransform
_recurrentOutputTransform
_layerSequenceDirection
initWithInputFeatureChannels:outputFeatureChannels:
createRNNSingleGateDescriptorWithInputFeatureChannels:outputFeatureChannels:
inputWeights
setInputWeights:
recurrentWeights
setRecurrentWeights:
_inputWeights
_recurrentWeights
createLSTMDescriptorWithInputFeatureChannels:outputFeatureChannels:
memoryWeightsAreDiagonal
setMemoryWeightsAreDiagonal:
inputGateInputWeights
setInputGateInputWeights:
inputGateRecurrentWeights
setInputGateRecurrentWeights:
inputGateMemoryWeights
setInputGateMemoryWeights:
forgetGateInputWeights
setForgetGateInputWeights:
forgetGateRecurrentWeights
setForgetGateRecurrentWeights:
forgetGateMemoryWeights
setForgetGateMemoryWeights:
outputGateInputWeights
setOutputGateInputWeights:
outputGateRecurrentWeights
setOutputGateRecurrentWeights:
outputGateMemoryWeights
setOutputGateMemoryWeights:
cellGateInputWeights
setCellGateInputWeights:
cellGateRecurrentWeights
setCellGateRecurrentWeights:
cellGateMemoryWeights
setCellGateMemoryWeights:
cellToOutputNeuronType
setCellToOutputNeuronType:
cellToOutputNeuronParamA
setCellToOutputNeuronParamA:
cellToOutputNeuronParamB
setCellToOutputNeuronParamB:
cellToOutputNeuronParamC
setCellToOutputNeuronParamC:
cellClipThreshold
setCellClipThreshold:
coupleForgetGateToInputGate
setCoupleForgetGateToInputGate:
_memoryWeightsAreDiagonal
_coupleForgetGateToInputGate
_cellToOutputNeuronType
_cellToOutputNeuronParamA
_cellToOutputNeuronParamB
_cellToOutputNeuronParamC
_cellClipThreshold
_inputGateInputWeights
_inputGateRecurrentWeights
_inputGateMemoryWeights
_forgetGateInputWeights
_forgetGateRecurrentWeights
_forgetGateMemoryWeights
_outputGateInputWeights
_outputGateRecurrentWeights
_outputGateMemoryWeights
_cellGateInputWeights
_cellGateRecurrentWeights
_cellGateMemoryWeights
createGRUDescriptorWithInputFeatureChannels:outputFeatureChannels:
recurrentGateInputWeights
setRecurrentGateInputWeights:
recurrentGateRecurrentWeights
setRecurrentGateRecurrentWeights:
outputGateInputGateWeights
setOutputGateInputGateWeights:
gatePnormValue
setGatePnormValue:
flipOutputGates
setFlipOutputGates:
_flipOutputGates
_gatePnormValue
_recurrentGateInputWeights
_recurrentGateRecurrentWeights
_outputGateInputGateWeights
label
dataType
weights
biasTerms
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retainCount
zone
hash
superclass
description
descriptor
load
purge
rangesForUInt8Kernel
lookupTableForUInt8Kernel
updateWithCommandBuffer:gradientState:sourceState:
updateWithGradientState:sourceState:
initWithWeights:useBias:desc:
_parentObj
_convDesc
_hasBias
setNeuronType:
setA:
setB:
setC:
initWithConvDescriptor:
computeCommandEncoder
setLabel:
offset
clipRect
destinationFeatureChannelOffset
storeAllIntermediateStates
addObject:
endEncoding
initWithDevice:rnnDescriptor:
initWithDevice:rnnDescriptors:
encodeSequenceToCommandBuffer:sourceImages:destinationImages:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardImages:destinationBackwardImages:
numberOfLayers
recurrentOutputIsTemporary
setRecurrentOutputIsTemporary:
setStoreAllIntermediateStates:
bidirectionalCombineMode
setBidirectionalCombineMode:
layerTypes
layers
forwardLayers
forwardLayerTypes
nForwardLayers
backwardLayers
backwardLayerTypes
nBackwardLayers
_recurrentOutputIsTemporary
_storeAllIntermediateStates
_numberOfLayers
_bidirectionalCombineMode
initWithDevice:transposeLeft:transposeRight:resultRows:resultColumns:interiorColumns:alpha:beta:
matrixDescriptorWithRows:columns:rowBytes:dataType:
columns
encodeToCommandBuffer:sourceMatrix:destinationMatrix:recurrentInputState:recurrentOutputState:
encodeSequenceToCommandBuffer:sourceMatrices:destinationMatrices:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardMatrices:destinationBackwardMatrices:
gemmKernel
gemmKernelNonTranspose
initWithFormat:
decodeBytesForKey:returnedLength:
encodeBytes:length:forKey:
imageDescriptorWithChannelFormat:width:height:featureChannels:
setFeatureChannels:
setNumberOfImages:
setChannelFormat:
setUsage:
setStorageMode:
setTextures:withRange:
setBuffer:offset:atIndex:
setRows:
data
setBuffers:offsets:withRange:
setColumns:
setRowBytes:
setK:
setN:
setM:
setResultMatrixOrigin:
encodeToCommandBuffer:encoder:leftMatrix:rightMatrix:resultMatrix:
neuronInfo
initWithDevice:weights:
contents
length
decodeObjectForKey:
newBufferWithBytes:length:options:
encodeObject:forKey:
arrayWithObjects:count:
initWithSourceImages:sourceStates:paddingPolicy:
initWithSource:transformProvider:outputSize:
nodeWithSource:transformProvider:outputSize:
nodeWithSource:outputSize:
privateInitWithSource:transformProvider:outputSize:
initWithSource:outputSize:
_transformProvider
_size
newFilterNode
initWithDevice:transformProvider:handle:outputSize:scaleClass:
setOffset:
setClipRect:
encodeInteger:forKey:
decodeIntegerForKey:
setOptions:
setEdgeMode:
transformForSourceImage:handle:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:
setScaleTransform:
_destSize
_filter
_handle
decodeObjectOfClass:forKey:
setDestinationFeatureChannelOffset:
setSourceFeatureChannelOffset:
setSourceFeatureChannelMaxCount:
destinationImageDescriptorForSourceImages:sourceStates:
padding
setDestinationImageAllocator:
setPadding:
encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
encodeToCommandBuffer:sourceImage:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImages:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:
cStringUsingEncoding:
sourceFeatureChannelOffset
imageForCommandBuffer:imageDescriptor:kernel:
arrayWithCapacity:
setObject:atIndexedSubscript:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:
resultStateForSourceImage:sourceStates:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:
resultStateBatchForSourceImage:sourceStates:destinationImage:
encodeToCommandBuffer:sourceImages:destinationImage:
copyToGradientState:sourceImages:sourceStates:destinationImage:
temporaryStateWithCommandBuffer:
temporaryResultStateForCommandBuffer:sourceImages:sourceStates:destinationImage:
isResultStateReusedAcrossBatch
initWithObjects:count:
resultStateForSourceImages:sourceStates:destinationImage:
copyToGradientState:sourceImage:sourceStates:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImages:sourceStates:destinationImage:
resultStateBatchForSourceImages:sourceStates:destinationImage:
destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:
setPrimarySourceFeatureChannelOffset:
setPrimarySourceFeatureChannelMaxCount:
_sliceCount
_info
usage
initialize:convDesc:weights:dataType:serializeWeightsAndBiases:fullyConnected:
initialize:weights:fullyConnected:serializeWeightsAndBiases:
initWithCoder:
supportsSecureCoding
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setGroups:
setStrideInPixelsX:
setStrideInPixelsY:
setDilationRateX:
setDilationRateY:
initWithDevice:weights:fullyConnected:
reloadWeightsAndBiasesWithDataSource:
reloadWeightsAndBiasesWithCommandBuffer:state:
biases
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
gradientOption
setGradientOption:
serializeWeightsAndBiases
setSerializeWeightsAndBiases:
dataSource
_groups
_gradientOption
_weights
_fullyConnected
_weightsDataType
_serializeWeightsAndBiases
_dataSource
stringWithCString:encoding:
getBytes:bytesPerRow:bytesPerImage:fromRegion:mipmapLevel:slice:
dataWithBytes:length:
maskData
_maskStrideInPixels
_keepProbability
decodeInt32ForKey:
encodeInt32:forKey:
setResourceOptions:
privateResultStateForSourceImage:sourceStates:destinationImage:commandBuffer:isTemporary:
resetSeed:
initWithDevice:keepProbability:seed:maskStrideInPixels:
.cxx_destruct
.cxx_construct
keepProbability
seed
maskStrideInPixels
_seed
_engine
_engineMutex
_arithmetic
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
setPrimaryEdgeMode:
setSecondaryEdgeMode:
paddingWithMethod:
decodeDoubleForKey:
encodeDouble:forKey:
scaleFactorX
scaleFactorY
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:
_filterType
_scaleFactorX
_scaleFactorY
initWithDevice:integerScaleFactorX:integerScaleFactorY:
maxTextureWidth2D
maxTextureHeight2D
paddingMethod
primaryOffset
secondaryOffset
setPrimaryOffset:
setSecondaryOffset:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
setSecondarySourceFeatureChannelOffset:
resultStateForPrimaryImage:secondaryImage:sourceStates:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:
readGradientState:
readBinaryGradientState:isSecondarySourceFilter:
isStateModified
kernelOffsetX
setKernelOffsetX:
kernelOffsetY
setKernelOffsetY:
_kernelOffsetX
_kernelOffsetY
cnnNeuronDescriptorWithType:a:b:c:
initWithSource:type:a:b:c:
gradientClass
_type
initWithSource:
nodeWithSource:
initWithSource:a:
nodeWithSource:a:
initWithDevice:a:
initWithSource:a:b:
nodeWithSource:a:b:
initWithDevice:a:b:
initWithSource:aData:
cnnNeuronPReLUDescriptorWithData:noCopy:
nodeWithSource:aData:
_aData
bytes
initWithDevice:a:count:
initWithSource:a:b:c:
nodeWithSource:a:b:c:
initWithDevice:a:b:c:
initWithSourceGradient:sourceImage:gradientState:descriptor:
initWithGradientImages:sourceImages:gradientState:paddingPolicy:
initWithGradientImages:forwardFilter:
nodeWithSourceGradient:sourceImage:gradientState:descriptor:
_descriptor
initWithDevice:neuronDescriptor:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationImages:
setSecondarySourceFeatureChannelMaxCount:
destinationImageAllocator
temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
resultStateBatchForPrimaryImage:secondaryImage:sourceStates:destinationImage:
newMatrixFullyConnected
primarySourceMatrixOrigin
secondarySourceMatrixOrigin
resultMatrixOrigin
matrices
batchStart
vectors
encodeToCommandBuffer:inputMatrix:weightMatrix:biasVector:resultMatrix:
neuronType
neuronParameterA
neuronParameterB
neuronParameterC
setNeuronType:parameterA:parameterB:parameterC:
setNeuronToPReLUWithParametersA:
sourceNumberOfFeatureVectors
setSourceNumberOfFeatureVectors:
sourceInputFeatureChannels
setSourceInputFeatureChannels:
sourceOutputFeatureChannels
setSourceOutputFeatureChannels:
alpha
setAlpha:
neuronA
setNeuronA:
neuronB
setNeuronB:
neuronC
setNeuronC:
_encode
neuronAParamBuf
_plugin
_neuronType
_neuronA
_neuronB
_neuronC
_sourceNumberOfFeatureVectors
_sourceInputFeatureChannels
_sourceOutputFeatureChannels
_alpha
sourceMatrixOrigin
encodeToCommandBuffer:inputMatrix:biasVector:resultMatrix:
batchSize
minimumLinearTextureAlignmentForPixelFormat:
matrixBytes
vectorBytes
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
newTextureWithDescriptor:offset:bytesPerRow:
numberOfFeatureChannels
epsilon
gamma
beta
mean
variance
encodeToCommandBuffer:sourceImage:inState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:inStates:destinationImages:
encodeToCommandBuffer:sourceImage:inState:
sourceFeatureChannelMaxCount
initDeferredWithDevice:numberOfFeatureChannels:epsilon:batchNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:epsilon:batchNormalization:
reloadDataSource:
initWithDevice:dataSource:
encodeToCommandBuffer:sourceImage:batchNormalizationState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:destinationImages:
encodeToCommandBuffer:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:
reloadGammaAndBetaWithCommandBuffer:gammaAndBetaState:
setEpsilon:
_gamma
_beta
_meanDS
_varDS
_stateNeedsToLoad
_epsilon
_numberOfFeatureChannels
copyWithZone:
initWithDataSource:
accumulatorPrecisionOption
setAccumulatorPrecisionOption:
initialize:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initialize:weights:fullyConnected:
strideInPixelsX
strideInPixelsY
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:
encodeBatchToCommandBuffer:sourceImages:inStates:
encodeToCommandBuffer:sourceImage:convolutionState:
encodeToCommandBuffer:sourceImage:convolutionGradientState:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationImages:
featureChannelsLayout
_featureChannelsLayout
_convolution
_neuronInfo
initWithSources:
initWithLeftSource:rightSource:
resultState
nodeWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
nodeWithSources:
nodeWithLeftSource:rightSource:
gradientFilterWithSources:
gradientFiltersWithSources:
_primaryStrideInPixelsX
_primaryStrideInPixelsY
_secondaryStrideInPixelsX
_secondaryStrideInPixelsY
initWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
initWithGradientImages:forwardFilter:isSecondarySourceFilter:
accumulatesOverBatch
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:
staticThreadgroupMemoryLength
maxComputeThreadgroupMemory
initWithSource:integerScaleFactorX:integerScaleFactorY:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:
initWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
nodeWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
initWithDevice:resultImage:resultImageIsNeeded:
initWithDevice:resultImage:
defaultAllocator
encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
encodeBatchToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
containsValueForKey:
commandBufferWithUnretainedReferences
encodeToCommandBuffer:sourceImages:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
storageMode
status
error
commit
graphWithDevice:resultImage:resultImageIsNeeded:
graphWithDevice:resultImage:
resultImageIsNeeded
sourceImageHandles
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
encodeBatchToCommandBuffer:sourceImages:sourceStates:
executeAsyncWithSourceImages:completionHandler:
outputStateIsTemporary
setOutputStateIsTemporary:
format
setFormat:
_graph
_destinationImageAllocator
_format
_resultIsNeeded
_outputStateIsTemporary
handle
sourceImages
sourceStates
paddingPolicy
readCount
prefetchStorageWithCommandBuffer:imageDescriptorList:
options
resultImage
imageAllocator
trainingStyle
setTrainingStyle:
resultStatesNoAllocate
wrapperWithFilterNode:
dataWithBytesNoCopy:length:freeWhenDone:
unarchiveObjectWithData:device:
archivedDataWithRootObject:
initWithFilterNode:
node
wrapperWithResource:
_node
initWithCapacity:
null
isSubclassOfClass:
setWithArray:
decodeObjectOfClasses:forKey:
objectAtIndex:
initWithDevice:kernelSize:
kernelSize
setBeta:
delta
setDelta:
_kernelSize
_delta
kernelWidth
kernelHeight
_kernelWidth
_kernelHeight
setP0:
setPm:
setPs:
initWithSource:lossDescriptor:
initWithParent:
nodeWithSource:lossDescriptor:
inputLabels
_labels
initWithDevice:lossDescriptor:
encodeToCommandBuffer:sourceImage:labels:destinationImage:
encodeBatchToCommandBuffer:sourceImages:labels:destinationImages:
allocWithZone:
cnnLossDataDescriptorWithData:layout:size:
layout
size
bytesPerRow
setBytesPerRow:
bytesPerImage
setBytesPerImage:
_data
_layout
_bytesPerRow
_bytesPerImage
cnnLossDescriptorWithType:reductionType:
setLabelSmoothing:
setNumberOfClasses:
lossType
setLossType:
reductionType
setReductionType:
weight
setWeight:
labelSmoothing
numberOfClasses
_lossType
_reductionType
_weight
_labelSmoothing
_numberOfClasses
initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:
appendTexture:
initWithDevice:resourceList:
writeBytes:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:
initWithDevice:labelsDescriptor:
lossImage
_lossImageSize
_isScalarLoss
_numNonZeroWeights
initializeSupportFiltersWithDevice:
resultStateForSourceImage:sourceStates:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:
encodeToCommandBuffer:sourceImage:labels:
encodeBatchToCommandBuffer:sourceImages:labels:
_logSoftMax
stringByAppendingString:
resourceCount
primaryKernelWidth
primaryKernelHeight
primaryDilationRateX
primaryDilationRateY
dilationRateX
dilationRateY
subPixelScaleFactor
channelMultiplier
getObjects:range:
setImageAllocator:
initWithHandle:
nodeWithHandle:
exportedNodeWithHandle:
debugQuickLookObject
setHandle:
exportFromGraph
setExportFromGraph:
synchronizeResource
setSynchronizeResource:
_parent
_imageAllocator
_exportFromGraph
_synchronize
_clientCount
setPaddingPolicy:
setArray:
resultStates
gradientFilterWithSource:
gradientFiltersWithSource:
_sourceImages
_sourceStates
_resultImage
_resultStates
_paddingPolicy
_label
arrayByAddingObjectsFromArray:
initWithDevice:sourceIndex:
_sourceIndex
initWithDevice:numberOfFeatureChannels:instanceNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:instanceNormalization:
resourceListWithBufferSizes:
arrayWithObjects:
initWithResources:
temporaryStateWithCommandBuffer:resourceList:
temporaryStateWithCommandBuffer:bufferSize:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:
initWithDevice:bufferSize:
initWithGamma:beta:
_initialized
gradientForGamma
gradientForBeta
instanceNormalization
_instanceNormalization
encodeToCommandBuffer:sourceImage:
encodeBatchToCommandBuffer:sourceImages:
newPlugin
newCNNPoolingAverageWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
newCNNDilatedPoolingMaxWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:destinationGradient:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:destinationGradients:
encodeToCommandBuffer:primaryImage:secondaryImage:inState:
batchRepresentation
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:
subarrayWithRange:
sourceWidth
sourceHeight
primarySourceRegionForDestinationSize:
secondarySourceRegionForDestinationSize:
encodeToCommandBuffer:primaryImage:secondaryImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
appendBatchBarrier
primaryEdgeMode
secondaryEdgeMode
secondaryKernelWidth
secondaryKernelHeight
secondaryDilationRateX
secondaryDilationRateY
isBackwards
_primaryOffset
_secondaryOffset
_clipRect
_destinationFeatureChannelOffset
_primarySourceFeatureChannelOffset
_secondarySourceFeatureChannelOffset
_primarySourceFeatureChannelMaxCount
_secondarySourceFeatureChannelMaxCount
_primaryKernelWidth
_primaryKernelHeight
_secondaryKernelWidth
_secondaryKernelHeight
_primaryDilationRateX
_primaryDilationRateY
_secondaryDilationRateX
_secondaryDilationRateY
_isBackwards
_supportsBroadcasting
_padding
_primaryEdgeMode
_secondaryEdgeMode
_checkFlags
_batchEncode
_encodeData
primaryStrideInPixels
secondaryStrideInPixels
initWithFilter:
temporaryImageWithCommandBuffer:textureDescriptor:featureChannels:
dispatchBarrier
subImageWithFeatureChannelRange:
reset
batchNormalization
_batchNormalization
_accumulationCount
initWithSource:keepProbability:
initWithSource:keepProbability:seed:maskStrideInPixels:
nodeWithSource:keepProbability:
nodeWithSource:keepProbability:seed:maskStrideInPixels:
_maskStride
initWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
nodeWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
initWithSourceGradient:sourceImage:gradientState:
nodeWithSourceGradient:sourceImage:gradientState:
cnnNeuronDescriptorWithType:a:b:
cnnNeuronDescriptorWithType:a:
cnnNeuronDescriptorWithType:
setData:
_noCopy
_count
initializeWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
initializeWithNeuronType:neuronParameterA:count:
newCNNNeuronWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
newCNNNeuronWithNeuronType:neuronParameterAArray:count:
minBufferNoCopyAlignmentBytes
newBufferWithBytesNoCopy:length:options:deallocator:
initWithBytesNoCopy:length:deallocator:
privateInitWithDevice:a:b:c:type:
privateInitWithDevice:a:count:type:
_aBuf
initWithDevice:neuronDescriptor:aArray:
maxThreadsPerThreadgroup
setWeightValue:
initWithDevice:reduceOperation:
clipRectSource
setClipRectSource:
_clipRectSource
_reduceOp
_weightValue
weight:
reduceOp
primarySourceClipRect
setPrimarySourceClipRect:
secondarySourceClipRect
setSecondarySourceClipRect:
_clipRectPrimarySource
_secondarySourceClipRect
_primarySourceClipRect
initWithDevice:doWeightedSumByNonZeroWeights:
doWeightedSumByNonZeroWeights
sourceRegionForDestinationSize:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
sourcePositionOfTopLeftCornerOfFilterWindow
edgeMode
_offset
_sourceFeatureChannelOffset
_sourceFeatureChannelMaxCount
_strideInPixelsX
_strideInPixelsY
_dilationRateX
_dilationRateY
_maxBatchSize
_edgeMode
initWithPaddingMethod:
paddingForTensorflowAveragePooling
paddingForTensorflowAveragePoolingValidOnly
inverse
_method
_mpsOwned
initWithSource:filterSize:
initWithSource:filterSize:stride:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
nodeWithSource:filterSize:
nodeWithSource:filterSize:stride:
initWithSource:filterSize:stride:dilationRate:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSource:filterSize:stride:dilationRate:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
_reductionKernel
initWithSource:kernelSize:
nodeWithSource:kernelSize:
setKernelWidth:
setKernelHeight:
initWithSourceGradient:sourceImage:gradientState:kernelSize:
nodeWithSourceGradient:sourceImage:gradientState:kernelSize:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
kernelSizeInFeatureChannels
setKernelSizeInFeatureChannels:
_kernelSizeInFeatureChannels
initWithSource:dataSource:
nodeWithSource:dataSource:
_trainingStyle
updateGammaAndBetaWithCommandBuffer:instanceNormalizationStateBatch:
updateGammaAndBetaWithInstanceNormalizationStateBatch:
synchronizeOnCommandBuffer:
calculateStatistics
arrayByAddingObject:
flags
setFlags:
_flags
updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
updateGammaAndBetaWithBatchNormalizationState:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
newDescriptorWithNeuronInfo:
setBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:
initWithSource:neuronInfo:batchNorm:
_source
initWithSource:weights:
initWithSource:weights:state:
convolutionGradientState
nodeWithSource:weights:
convolutionState
fusedNeuronDescriptor
initWithBytesNoCopy:length:freeWhenDone:
initWithSourceGradient:sourceImage:convolutionGradientState:weights:
nodeWithSourceGradient:sourceImage:convolutionGradientState:weights:
convolution
exportWeightsAndBiasesWithCommandBuffer:resultStateCanBeTemporary:
initWithSource:weights:scaleValue:type:flags:
initWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
nodeWithSource:weights:scaleValue:type:flags:
nodeWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
_scaleValue
_outputBiasTerms
_outputScaleTerms
_inputBiasTerms
_inputScaleTerms
initWithDevice:convolutionData:scaleValue:type:flags:
initWithDevice:convolutionData:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
initWithSource:convolutionGradientState:weights:
initWithSource:convolutionState:weights:
nodeWithSource:convolutionGradientState:weights:
nodeWithSource:convolutionState:weights:
firstObject
enumerateObjectsUsingBlock:
setNumberOfFeatureChannels:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setNeuron:
initWithBytes:length:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:postFilters:
setFusedNeuronDescriptor:
setNeuronParameterA:
setNeuronParameterB:
setNeuronParameterC:
setNeuronType:parameterA:parameterB:
setFeatureChannelsLayout:
neuron
_batchNormalizationData
_deprecated_neuron
_subPixelScaleFactor
_depthWiseConvolution
_fusedNeuronDescriptor
_neuron_deprecated
setSubPixelScaleFactor:
initWithSourceWidth:sourceHeight:kernelWidth:kernelHeight:sourceOffset:
sourceOffset
_originalConvolutionSourceWidth
_originalConvolutionSourceHeight
_srcOffset
temporaryStateWithCommandBuffer:resourceList:convolution:
gradientForWeights
gradientForBiases
initWithDevice:weightsBufferSize:biasesBufferSize:convolution:
newCNNConvolutionWithDescriptor:dataSource:fullyConnected:
initialize:convolutionDescriptor:kernelWeights:dataType:range:lookUpTable:qType:biasTerms:flags:fullyConnected:
initializeWithDevice:weights:fullyConnected:
serializeData:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
initWithDevice:cnnConvolutionDescriptor:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:
encodeToCommandBuffer:sourceImage:destinationImage:state:
_qWts
_qType
_scaleFactor
_channelMultiplier
_biasOriginal
_neuronABuffer
_accumulatorPrecisionOption
initWithWeights:biases:
initWithDevice:count:rows:columns:transpose:
encodeToCommandBuffer:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
transpose
_transpose
_rows
_columns
initWithSources:sourceStates:provider:
nodeWithSources:sourceStates:provider:
nodeWithSources:provider:
nodeWithSource:provider:
initWithSources:provider:
initWithSource:provider:
_provider
initWithDevice:kernelProvider:
encodeToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage:
encodeBatchToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage:
hintWithCommandBuffer:sourceImages:sourceStates:destinationImage:
initWithSourceImage:descriptor:arrayDescriptor:
nodeWithSourceImage:descriptor:arrayDescriptor:
setKernelSize:
dilationRate
setDilationRate:
stride
setStride:
setIsBackwards:
_desc
_arrayDesc
_dilationRate
_stride
_isBackward
initWithPipelineDescriptor:arrayDescriptor:kernelSize:stride:dilationRate:isBackwards:
newCNNSoftMax
_destFeatureChannels
_srcSize
_sourceFeatureChannels
_initOnce
_provenance
_primarySrcSize
_primarySourceFeatureChannels
_secondarySrcSize
_secondarySourceFeatureChannels
initWithDeviceImpl:convolutionDescriptor:kernelWeights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
createBuffersFromkernelWeights:inputBiasTerms:inputScaleTerms:outputBiasTerms:outputScaleTerms:useHalfPrecision:
copyBuffer:device:
initWithDeviceImpl:convolutionDescriptor:kernelWeights:biasTerms:scaleValue:type:flags:
_filterStride
_outputbias
_outputScale
_inputbias
_inputScale
_convType
_poolingFilter
_outputScaleValue
initWithDeviceImpl:convolutionDescriptor:kernelWeights:scaleValue:type:flags:
arguments
type
index
localizedDescription
localizedFailureReason
newComputePipelineStateWithDescriptor:options:completionHandler:
initWithKernel:
compilePipelineDescriptor:completionHandler:
auxiliaryBufferOffsetAtIndex:
maximumThreadgroupMemorySize
threadgroupMemorySizeAtIndex:
completionBlock:
destinationStates
myInfo
myInfoOffset
computePipelineState
inputImageNodeCount
kernel
dispatchGridSize
setDispatchGridSize:
_kernel
_inputImageNodeCount
_gridSize
_group
_once
_pipelineState
_threadgroupBufferCount
_threadgroupIndices
maxSourceImageCount
parametersForKernel:sourceImages:sourceStates:destinationImage:prefetch:
kernelSizeAtIndex:
strideInPixelsAtIndex:
dilationRateAtIndex:
setKernelProvider:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:
destinationImageDescriptorForKernel:sourceImages:sourceStates:paddingMethod:suggestedDescriptor:
destinationImageDescriptorForSourceImages:sourceStates:updateOffset:
encodeToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage:prefetch:
encodeBatchToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationImage:prefetch:
setPurgeableState:
makeAliasable
isAliasable
cpuCacheMode
heap
allocatedSize
didModifyRange:
addDebugMarker:range:
removeAllDebugMarkers
offsetAtIndex:
setOffset:atIndex:
edgeModeAtIndex:
setEdgeMode:atIndex:
encodeToCommandBuffer:sourceImages:sourceStates:destinationStates:
hintBatchWithCommandBuffer:sourceImages:sourceStates:destinationImage:
resultStateBatchForSourceImages:sourceStates:destinationImages:
kernelProvider
_maxSrcCount
_srcProperties
initWithFunctionName:
newDefaultLibrary
parametersForBatchKernel:sourceImages:sourceStates:destinationImage:prefetch:
newLibraryForDevice:
newParametersForKernel:
functionName
userInfo
setUserInfo:
threadgroupMemorySize
setThreadgroupMemorySize:
_funcName
_options
_threadgroupMemorySize
_userInfo
doesNotRecognizeSelector:
encodeWithFilter:encoder:commandBuffer:callInfo:
encodeToCommandBuffer:computeCommandEncoder:options:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:
MPSCNNPoolingGradient
MPSCNNPoolingMaxGradient
MPSCNNPoolingAverageGradient
MPSCNNPoolingL2NormGradient
MPSCNNDilatedPoolingMaxGradient
MPSCNNArithmeticGradientState
MPSCNNArithmetic
MPSCNNAdd
MPSCNNSubtract
MPSCNNMultiply
MPSCNNDivide
MPSCNNArithmeticGradient
MPSCNNAddGradient
MPSCNNSubtractGradient
MPSCNNMultiplyGradient
MPSNNReshape
MPSRNNRecurrentImageState
MPSRNNRecurrentMatrixState
MPSRNNDescriptor
MPSRNNSingleGateDescriptor
MPSLSTMDescriptor
MPSGRUDescriptor
TmpWeights
MPSCNNConvolutionDataSource
NSObject
TmpWeightsLUT
TmpWeightsLIN
MPSCNNConvolutionDescriptorNoNeuron
MPSRNNImageInferenceLayer
MPSRNNMatrixInferenceLayer
MPSNNScaleNode
MPSNNBilinearScaleNode
MPSNNLanczosScaleNode
MPSNNScale
MPSNNConcatenation
MPSNNConcatenationGradientState
NSSecureCoding
NSCoding
MPSCNNConvolutionGradient
MPSCNNDropoutGradientState
MPSCNNDropout
MPSCNNDropoutGradient
MPSCNNUpsampling
MPSCNNUpsamplingNearest
MPSCNNUpsamplingBilinear
MPSCNNGradientKernel
MPSCNNNeuronNode
MPSCNNNeuronAbsoluteNode
MPSCNNNeuronELUNode
MPSCNNNeuronReLUNNode
MPSCNNNeuronLinearNode
MPSCNNNeuronReLUNode
MPSCNNNeuronSigmoidNode
MPSCNNNeuronHardSigmoidNode
MPSCNNNeuronSoftPlusNode
MPSCNNNeuronSoftSignNode
MPSCNNNeuronTanHNode
MPSCNNNeuronPReLUNode
MPSCNNNeuronPowerNode
MPSCNNNeuronExponentialNode
MPSCNNNeuronLogarithmNode
MPSCNNNeuronGradientNode
MPSMatrixFullyConnected
MPSMatrixNeuron
MPSCNNBatchNormalization
WrapperDataSourceWithStride1
WrapperDataSourceWithStride1WithRanges
WrapperDataSourceWithStride1WithLookup
WrapperDataSourceWithStride1WithRangesAndLookup
MPSCNNConvolutionTranspose
MPSNNBinaryArithmeticNode
MPSNNAdditionNode
MPSNNSubtractionNode
MPSNNMultiplicationNode
MPSNNDivisionNode
MPSNNArithmeticGradientStateNode
MPSNNArithmeticGradientNode
MPSNNAdditionGradientNode
MPSNNSubtractionGradientNode
MPSNNMultiplicationGradientNode
MPSCNNInstanceNormalizationGradient
MPSCNNBatchNormalizationStatisticsGradient
MPSCNNUpsamplingNearestNode
MPSCNNUpsamplingBilinearNode
MPSCNNUpsamplingNearestGradientNode
MPSCNNUpsamplingBilinearGradientNode
MPSNNGraph
NSCopying
MPSNNTrainableNode
FilterNodeWrapper
ResourceWrapper
NodeWrapper
MPSCNNCrossChannelNormalizationGradient
MPSCNNSpatialNormalizationGradient
MPSCNNLocalContrastNormalizationGradient
MPSNNLabelsNode
MPSCNNLossNode
MPSCNNLossDataDescriptor
MPSCNNLossDescriptor
MPSCNNLossLabels
MPSCNNLoss
MPSCNNUpsamplingGradient
MPSCNNUpsamplingNearestGradient
MPSCNNUpsamplingBilinearGradient
MPSNNImageNode
MPSNNStateNode
MPSNNFilterNode
MPSNNGradientFilterNode
MPSNNGradientStateNode
MPSNNBinaryGradientStateNode
MPSNNSlice
MPSNNConcatenationGradient
MPSCNNInstanceNormalization
MPSCNNNormalizationGammaAndBetaState
MPSCNNInstanceNormalizationGradientState
MPSCNNPooling
MPSCNNPoolingMax
MPSCNNPoolingAverage
MPSCNNPoolingL2Norm
MPSCNNDilatedPoolingMax
MPSCNNBatchNormalizationGradient
MPSImageSizeEncodingState
MPSCNNBinaryKernel
MPSCNNBinaryImageFilter
MPSCNNBatchNormalizationState
MPSCNNDropoutNode
MPSCNNDropoutGradientNode
MPSCNNSoftMaxNode
MPSCNNLogSoftMaxNode
MPSCNNSoftMaxGradientNode
MPSCNNLogSoftMaxGradientNode
MPSNNNeuronDescriptor
MPSCNNNeuron
MPSCNNNeuronGradient
MPSCNNNeuronLinear
MPSCNNNeuronReLU
MPSCNNNeuronPReLU
MPSCNNNeuronSigmoid
MPSCNNNeuronHardSigmoid
MPSCNNNeuronTanH
MPSCNNNeuronAbsolute
MPSCNNNeuronSoftPlus
MPSCNNNeuronSoftSign
MPSCNNNeuronELU
MPSCNNNeuronReLUN
MPSCNNNeuronPower
MPSCNNNeuronExponential
MPSCNNNeuronLogarithm
MPSNNReduceUnary
MPSNNReduceRowMin
MPSNNReduceColumnMin
MPSNNReduceFeatureChannelsMin
MPSNNReduceRowMax
MPSNNReduceColumnMax
MPSNNReduceFeatureChannelsMax
MPSNNReduceRowMean
MPSNNReduceColumnMean
MPSNNReduceFeatureChannelsMean
MPSNNReduceRowSum
MPSNNReduceColumnSum
MPSNNReduceFeatureChannelsSum
MPSNNReduceBinary
MPSNNReduceFeatureChannelsAndWeightsMean
MPSNNReduceFeatureChannelsAndWeightsSum
MPSCNNKernel
MPSNNDefaultPadding
MPSNNPadding
MPSNNTensorFlowPoolingPadding
MPSNNTensorFlowPoolingPaddingValidOnly
MPSCNNPoolingNode
MPSCNNPoolingMaxNode
MPSCNNPoolingAverageNode
MPSCNNPoolingL2NormNode
MPSCNNDilatedPoolingMaxNode
MPSCNNPoolingGradientNode
MPSCNNPoolingMaxGradientNode
MPSCNNPoolingAverageGradientNode
MPSCNNPoolingL2NormGradientNode
MPSCNNDilatedPoolingMaxGradientNode
MPSCNNSoftMaxGradient
MPSCNNLogSoftMaxGradient
MPSNNConcatenationNode
MPSNNConcatenationGradientNode
MPSCNNNormalizationNode
MPSCNNSpatialNormalizationNode
MPSCNNSpatialNormalizationGradientNode
MPSCNNLocalContrastNormalizationNode
MPSCNNLocalContrastNormalizationGradientNode
MPSCNNCrossChannelNormalizationNode
MPSCNNCrossChannelNormalizationGradientNode
MPSCNNInstanceNormalizationNode
MPSCNNInstanceNormalizationGradientNode
MPSCNNBatchNormalizationNode
MPSCNNBatchNormalizationGradientNode
MPSCNNFullyConnected
MPSCNNFullyConnectedGradient
MPSWeightsWrapper
MPSCNNConvolutionGradientStateNode
MPSCNNConvolutionStateNode
MPSCNNConvolutionNode
MPSCNNConvolutionGradientNode
MPSCNNFullyConnectedNode
MPSCNNBinaryConvolutionNode
MPSCNNBinaryFullyConnectedNode
MPSCNNConvolutionTransposeNode
MPSCNNBatchNormalizationStatistics
MPSCNNConvolutionDescriptor
MPSCNNSubPixelConvolutionDescriptor
MPSCNNDepthWiseConvolutionDescriptor
MPSCNNConvolutionState
MPSCNNConvolutionGradientState
MPSCNNConvolution
MPSCNNConvolutionWeightsAndBiasesState
MPSCNNCrossChannelNormalization
MPSCNNSpatialNormalization
MPSCNNLocalContrastNormalization
MPSMatrixSum
MPSNNCustomNode
MPSNNSimpleCustomNode
MPSCNNSoftMax
MPSCNNLogSoftMax
MPSNNGradientState
MPSNNBinaryGradientState
MPSCNNBinaryConvolution
MPSCNNBinaryFullyConnected
MPSNNCustomKernelParameters
MTLBuffer
MTLResource
MPSNNCustomKernel
MPSNNSimpleCustomKernelProvider
MPSNNCustomKernelProvider
MPSExternalCNNUnary
MPSExternalPluginBase
MPSExternalCNNBinary
MPSExternalCNNPoolingAverage
r^{MPSLibraryInfo=iI*{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}}16@0:8
@24@0:8@16
@40@0:8@16Q24Q32
@56@0:8@16Q24Q32Q40Q48
@32@0:8@16@24
v24@0:8@16
@32@0:8^{_NSZone=}16@24
{?=QQQ}16@0:8
v40@0:8{?=QQQ}16
{?="width"Q"height"Q"depth"Q}
@16@0:8
Q16@0:8
v24@0:8Q16
@72@0:8@16Q24Q32Q40Q48Q56Q64
v16@0:8
@28@0:8@16i24
@60@0:8@16@24@32@40@48B56
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
@64@0:8@16@24Q32^{?=qqq}40^{?=qqq}48^{?=qqq}56
v56@0:8@16@24@32@40@48
v56@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40^{NSArray=#}48
f16@0:8
v20@0:8f16
@32@0:8@16i24B28
B16@0:8
@"MPSNNReduceUnary"
@28@0:8@16B24
@24@0:8Q16
@48@0:8@16^@24^@32B40i44
v20@0:8B16
@"<MPSCNNConvolutionDataSource>"
@32@0:8Q16Q24
i16@0:8
v20@0:8i16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
I16@0:8
^v16@0:8
^f16@0:8
^16@0:8
@40@0:8@16@24@32
B32@0:8@16@24
@"MPSCNNConvolutionDescriptor"16@0:8
@"MPSCNNConvolutionWeightsAndBiasesState"40@0:8@"<MTLCommandBuffer>"16@"MPSCNNConvolutionGradientState"24@"MPSCNNConvolutionWeightsAndBiasesState"32
B32@0:8@"MPSCNNConvolutionGradientState"16@"MPSCNNConvolutionWeightsAndBiasesState"24
@36@0:8@16B24@28
@"MPSCNNConvolutionDescriptor"
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40^@48
@"MPSMatrixMultiplication"
@56@0:8@16@24{?=QQQ}32
@48@0:8@16{?=QQQ}24
@"<MPSImageTransformProvider>"
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}16@0:8
@72@0:8@16@24@32{?=QQQ}40#64
@48@0:8@16@24Q32^{?=qqq}40
@"MPSImageScale"
@"<MPSHandle>"
v40@0:8@16@24@32
v40@0:8@16@24^{NSArray=#}32
^{NSArray=#}48@0:8@16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}48@0:8@16@24@32^{NSArray=#}40
^{NSArray=#}40@0:8^{NSArray=#}16@24^{NSArray=#}32
^{NSArray=#}40@0:8@16@24^{NSArray=#}32
^{MPSSliceInfo=QQ}
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v52@0:8@16@24^v32I40B44B48
v40@0:8@16@24B32B36
@36@0:8@16@24B32
v32@0:8@16@24
@"<MTLBuffer>"
@60@0:8@16f24Q28{?=QQQ}36
@52@0:8@16@24@32@40B48
{mersenne_twister_engine<unsigned int, 32, 624, 397, 31, 2567483615, 11, 4294967295, 7, 2636928640, 15, 4022730752, 18, 1812433253>="__x_"[624I]"__i_"Q}
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"MPSCNNMultiply"
@48@0:8@16Q24Q32Q40
d16@0:8
^{NSArray=#}48@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40
v28@0:8@16B24
q16@0:8
v24@0:8q16
@40@0:8@16i24f28f32f36
@28@0:8@16f24
@32@0:8@16f24f28
@"NSData"
@36@0:8@16f24f28f32
@"MPSNNNeuronDescriptor"
v32@0:8i16f20f24f28
v24@0:8d16
@"<MPSExternalMatrixFullyConnected>"
v48@0:8@16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}40@0:8@16^{NSArray=#}24@32
^{MPSAutoBuffer={atomic<void *>=A^v}Q@@Q}
@"<MPSCNNBatchNormalizationDataSource>"
@56@0:8@16@24r^f32r^f40Q48
@60@0:8@16@24r^f32r^f40Q48B56
^{NSArray=#}40@0:8@16^{NSArray=#}24^{NSArray=#}32
v48@0:8@16^{NSArray=#}24^{NSArray=#}32^{NSArray=#}40
@"MPSCNNConvolution"
{NeuronInfo="type"i"a"f"b"f"c"f"aData"@"NSData"}
@44@0:8@16@24@32B40
v48@0:8@16^{NSArray=#}24^{NSArray=#}32@40
@56@0:8@16@24@32d40d48
@24@0:8^{_NSZone=}16
^{NSArray=#}40@0:8@16@24@32
^{NSArray=#}56@0:8@16@24@32@40@48
@32@0:8@16@?24
{Graph="_graphSourceImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphSourceStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultImage"^{ResourceGraphNode}"_graphIntermediateImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graph"@"MPSNNGraph""_filters"{NodeList<FilterGraphNode *>="_items"^^{FilterGraphNode}"_count"Q"_storageSize"Q}"_images"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_states"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_cpuUpdateSem"@"NSObject<OS_dispatch_semaphore>""_graphNull"@"NSNull"}
@"<MPSImageAllocator>"
@24@0:8^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}16
^{FilterGraphNode=^^?^{ResourceGraphNode}^{ResourceGraphNode}^{FilterGraphNode}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}{NodeList<ResourceGraphNode *>=^^{ResourceGraphNode}QQ}(?=@@@@@)@QBIQ}
@24@0:8^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQ}16
^{ResourceGraphNode=@{NodeList<FilterGraphNode *>=^^{FilterGraphNode}QQ}^{FilterGraphNode}^{ResourceGraphNode}@@QQBBBBQ}
@32@0:8@16Q24
@"MPSNNLabelsNode"
@"MPSCNNLossDescriptor"
@56@0:8@16Q24{?=QQQ}32
@24@0:8I16i20
v20@0:8I16
@64@0:8@16{?=QQQ}24@48@56
@"MPSCNNLogSoftMax"
@"MPSCNNNeuronLinear"
@"MPSNNFilterNode"
^{FilterGraphNode=}16@0:8
@"NSMutableArray"
@"MPSNNImageNode"
@"<MPSNNPadding>"
@"NSString"
@"<MPSCNNInstanceNormalizationDataSource>"
@40@0:8@16Q24@32
@"MPSCNNInstanceNormalization"
v40@0:8@16^{NSArray=#}24^{NSArray=#}32
^{NSArray=#}32@0:8@16^{NSArray=#}24
v56@0:8@16^{NSArray=#}24^{NSArray=#}32@40^{NSArray=#}48
^{NSArray=#}48@0:8@16^{NSArray=#}24^{NSArray=#}32@40
{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}40@0:8{?=QQQ}16
@52@0:8@16@24@32^@40B48
^{NSArray=#}52@0:8@16^{NSArray=#}24^{NSArray=#}32^^{NSArray}40B48
^{NSArray=#}48@0:8^{NSArray=#}16^{NSArray=#}24@32^{NSArray=#}40
^{NSArray=#}56@0:8@16^{NSArray=#}24^{NSArray=#}32@40^{NSArray=#}48
{?=qqq}16@0:8
v40@0:8{?=qqq}16
{?={?=QQQ}{?=QQQ}}16@0:8
v64@0:8{?={?=QQQ}{?=QQQ}}16
{?="x"q"y"q"z"q}
{?="origin"{?="x"Q"y"Q"z"Q}"size"{?="width"Q"height"Q"depth"Q}}
@"MPSExternalCNNBinary"
@44@0:8@16Q24f32@36
@"MPSCNNBatchNormalization"
@76@0:8@16@24@32f40Q44{?=QQQ}52
@32@0:8i16f20f24f28
@28@0:8i16f20f24
@24@0:8i16f20
@20@0:8i16
@40@0:8@16f24f28f32i36
@44@0:8@16r^f24Q32i40
v36@0:8i16r^f20Q28
@40@0:8@16@24r^f32
@40@0:8@16r^f24Q32
@44@0:8@16@24^@32B40
^{NSArray=#}44@0:8@16^{NSArray=#}24^^{NSArray}32B40
16@0:8
@"MPSExternalCNNUnary"
@"MPSImageDescriptor"48@0:8@"NSArray"16@"NSArray"24@"MPSKernel"32@"MPSImageDescriptor"40
@80@0:8@16@24@32Q40Q48Q56Q64@72
@88@0:8@16@24@32Q40Q48Q56Q64Q72Q80
@"MPSNNReduceFeatureChannelsAndWeightsSum"
@"MPSNNReduceFeatureChannelsSum"
@48@0:8@16@24@32Q40
@56@0:8@16@24@32Q40Q48
@56@0:8@16{NeuronInfo=ifff@}24@48
@52@0:8@16@24f32Q36Q44
@80@0:8@16@24r^f32r^f40r^f48r^f56Q64Q72
v40@0:8@16^{NSArray=#}24@32
@48@0:8Q16Q24Q32Q40
@56@0:8Q16Q24Q32Q40@48
v28@0:8i16f20f24
v52@0:8r^f16r^f24r^f32r^f40f48
{NeuronInfo=ifff@}16@0:8
@40@0:8{NeuronInfo=ifff@}16
@"MPSCNNNeuron"
@72@0:8Q16Q24Q32Q40{?=qqq}48
@48@0:8@16Q24Q32@40
B84@0:8@16@24r^v32I40r^44r^f52i60r^f64Q72B80
v48@0:8@16@24@32^@40
@52@0:8@16Q24Q32Q40B48
v72@0:8@16@24@32@40@48@56Q64
@"<MPSNNCustomKernelProvider>"
@"MTLComputePipelineDescriptor"
v60@0:8r^I16r^f24r^f32r^f40r^f48B56
@68@0:8@16@24r^I32r^f40f48Q52Q60
@88@0:8@16@24r^I32r^f40r^f48r^f56r^f64Q72Q80
@"MPSCNNPoolingAverage"
@60@0:8@16@24r^I32f40Q44Q52
v32@0:8@16@?24
Q24@0:8Q16
@?20@0:8B16
{?={?=QQQ}{?=QQQ}{?=QQQ}}16@0:8
v88@0:8{?={?=QQQ}{?=QQQ}{?=QQQ}}16
@"MPSNNCustomKernel"
{?="threadgroups"{?="width"Q"height"Q"depth"Q}"threadsPerThreadgroup"{?="width"Q"height"Q"depth"Q}"globalSize"{?="width"Q"height"Q"depth"Q}}
{atomic<NSObject<OS_dispatch_group> *>="__a_"A@}
{atomic<long>="__a_"Aq}
@"<MTLComputePipelineState>"
v24@0:8@"NSString"16
@"<MTLDevice>"16@0:8
@"<MTLHeap>"16@0:8
v32@0:8{_NSRange=QQ}16
v40@0:8@16{_NSRange=QQ}24
@"<MTLTexture>"40@0:8@"MTLTextureDescriptor"16Q24Q32
v40@0:8@"NSString"16{_NSRange=QQ}24
{?=qqq}24@0:8Q16
v48@0:8{?=qqq}16Q40
v32@0:8Q16Q24
@40@0:8@16@24Q32
v48@0:8@16@24@32^{NSArray=#}40
v60@0:8@16@24@32@40@48B56
v60@0:8@16@24@32@40^{NSArray=#}48B56
^{SrcProperties={?=qqq}{?=qqq}{?=QQQ}{?=QQQ}{?=QQQ}Q}
@52@0:8@16@24@32^{NSArray=#}40B48
{?=QQQ}24@0:8Q16
@56@0:8@16@24@32Q40@48
@"MPSNNCustomKernelParameters"52@0:8@"MPSNNCustomKernel"16@"NSArray"24@"NSArray"32@"MPSImage"40B48
@"MPSNNCustomKernelParameters"52@0:8@"MPSNNCustomKernel"16@"NSArray"24@"NSArray"32^{NSArray=#}40B48
@"MPSImageDescriptor"56@0:8@"MPSNNCustomKernel"16@"NSArray"24@"NSArray"32Q40@"MPSImageDescriptor"48
@24@0:8@"<MTLDevice>"16
Q72@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64
Q72@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}Q}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}QQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQ{?=qqq}Q}64@72r^{?=QQQ{?={?=QQQ}{?=QQQ}}}80
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}QQQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}Q}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64Q72Q80
Q88@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}Q}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}}64Q72Q80
