mcpl
error setting SRC quality: %d
%s: error %d %s level metering
Error AudioUnitSetProperty _floatConverter %d
Error AudioUnitSetProperty _integerConverter %d
Error AudioComponentInstanceNew _voiceBoostUnit %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_MaximumFramesPerSlice %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input %d
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output,  %d
Error AudioUnitInitialize _voiceBoostUnit %d
Error AudioUnitSetParameter %d
Error AudioConverterConvertComplexBuffer _floatConverter %d
Error AudioUnitProcess _voiceBoostUnit %d
Error AudioConverterConvertComplexBuffer _integerConverter %d
Failed ve_ttsGetLipSyncInfo 0x%x
Error ve_ttsInitialize: 0x%x
Error ve_ttsGetLanguageList: 0x%x
Error ve_ttsGetVoiceList: 0x%x
Error ve_ttsOpen 0x%x
Error ve_ttsSetParamList 0x%x
Error ve_ttsClose 0x%x
Error ve_ttsUnInitialize 0x%x
Error ve_ttsResourceLoad 0x%x, path: '%@', type: '%@'
Success ve_ttsResourceLoad, path: '%@', type: '%@'
Error ve_ttsSetOutDevice 0x%x
Error ve_ttsProcessText2Speech 0x%x
Error ve_ttsStop 0x%x
Error getting components in voice path, %@
Engine preheating latency: %.3f
Unable to open file '%s', error: %d
Unable to get size of file '%s', error: %d
Unable to mmap '%s', error: %d
madvise failed for '%s', error: %s
Unable to find broker file
%s: error converting disambiguation context
%s: allowing recognition start
%s: recognition requested when busy
%s: releasing active client to begin
%s: client requested cancellation of active recognition
%s: client requested cancellation of queued recognition
cancelling recognition
released from holding.. beginning now.
Running with background thread priority
couldn't create instance for client port - cancelling
couldn't open audio input file for reading
%s: sample rate change (now %d Hz); invalidating queue
%s: no valid models could be created
%s: client died - cancelling recognition
couldn't add listener for queue running state (%d)
couldn't create audio queue
setting recognition thread priority to %d
%s: sleeping for %g s
%s: finished starting queue in %g s
couldn't start audio queue for recognition (%d)
%s: starting recognition
%s: starting recognition from file
couldn't get file format description.
Recognition results:
--------------------
%s: error posting client completion notification
%s: error posting client error notification
%s: we're already terminating
%s: posted %s to client
caching model <%s> class <%s> ...
no valid cache found; recaching everything.
cache for model <%s> is valid; skipping recache request.
... finished caching model in %g s with error %d <%s> class <%s>
cache for model <%s> is valid; skipping recache.
recache for model <%s> done in %g s
error caching model <%s>
%s: couldn't write keyword index for cache
%s: couldn't create manifest for cache
%s: error setting info dict on temp cache
%s: couldn't move temp cache into place... deleting
%s: couldn't save cache; no base dir exists or couldn't create temp cache
error writing model configuration cache Info.plist:
beginning plugin registry rebuild...
finished.
%s: error examining plugins directory (%ld)
%s: error writing plugin registry cache:
data provider does not implement value method
%s: plugin class does not conform to appropriate protocol
%s: plugin class not found
%s: error loading plugin:
Using timestamp inside voiced
Prewarming: Invoked with request: '%@'
Prewarming: Started with request: '%@'
Can't prewarm engine with path '%@'
Engine is previously prewarmed with path '%@'
Prewarm latency: %.3f
Prewarming: Completed with request: '%@'
Start spinNextTask
Dispatch speaking task %p
Finish speaking task %p
%p wait another speaking task %p
%p wait similar synthesis task %p
%p interrupt synthesis %p
Dispatch synthesis task %p
Finish synthesis task %p
Finish spinNextTask
Starting synthesize task: %p
Starting speech task: %p
Cached synthesis %@ is found.
Can't create VSAudioPlaybackService
Enqueuing cached audio
Finished synthesizing utterance.
Stop task: %p
Speaking pre-synthesized audio: %@
Error decoding chunk: %@
Error playing decoded chunk: %@
Played %@ raw bytes in %@ chunks as %@ pcm bytes, decodeAndPlayDuration: %.3f, AudioQueueStart latency: %.3f
Pre-synthesized audio request stopped
Finished speaking pre-synthesized audio: %@
Task is cancelled by user: %@
Error converting audio during caching. %@
Can't add audio cache, error: %@
No voice available
Can't create engine with path '%@'
Task %p is cancelled by user. text: '%@'
Error in task %p, text: '%@', error: %@
Task %p: Finished %@ utterance: '%@', voice: %{public}@:%@:%{public}@:%@:%@:%@:%{public}@:%@, builtin resource: %{public}@:%{public}@, rate:%.2f, pitch: %.2f, volume: %.2f, cached: %@, warm_start: %@
Total latency: %.3f, Synthesis latency: %.3f, AudioQueueStart latency: %.3f
err %d copying manifest
Error %s, %@
Cache type name too long %@
Can't remove cache file '%@', error: %@
Time to cleaning cache: %f
#AudioSession session interrupted
#AudioSession mediaserverd died
#AudioSession : Setting up audio session
#AudioSession error setting HW sample rate: %ld
#AudioSession : category = %d
#AudioSession error %ld setting audio category
#AudioSession error %ld setting bluetooth allowability
#AudioSession : Bluetooth %sabled
#AudioSession active count went negative for input!
#AudioSession active count went negative for output!
#AudioSession active count went negative!
#AudioSession : activity %d --> %s
#AudioSession : Active --> FALSE
#AudioSession : Active --> TRUE
#AudioSession error %ld activating or deactivating session for activity %ld
#AudioSession could not stop queue (%d)
Error AudioQueueNewOutputWithAudioSession %d
VSAudioPlaybackService init latency: %.3f
Error AudioQueueDispose %d
mediaserverd reset
Error AudioQueueStart %d
Success AudioQueueStart
Error AudioQueueAllocateBuffer %d
Error AudioQueueEnqueueBuffer %d
Enqueued audio buffer at sample time: %.2f, size: %ld
Error AudioQueueFlush %d
Error AudioQueueStop %d
Error AudioQueuePause %d
Success AudioQueuePause
Error AudioQueueReset %d
Error AudioQueueAddPropertyListener %d
Error AudioQueueRemovePropertyListener %d
Error AudioQueueGetProperty isRunning %d
Played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Looking for data %s
Found data at path %s
-----------> Preheat: Preheating %u bytes of uselect starting at %u on same thread %s .....
-----------> done preheating %u bytes (%g seconds)
Reading cache %@ error: %@
Update with connection identifier: %{public}@
Created speech task: %p
Created presynthesized task: %p
Created synthesis task: %p
set auto download voice assets:%@
voiced starting up...
voiced shutting down
Receive notification %s
xpc_activity state must be RUN, got: %ld
running xpc_activity
Error cleanUnusedAssets in scheduled background task: %@
XPC connection invalidated, identifier: %{public}@
_VSAudioQueueSetLevelMeteringPropertyValue
enabling
disabling
com.apple.voiceservices.request
v8@?0
%@.%@.%@
loggingPrefix
T@"NSString",&,N,V_loggingPrefix
asbd
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
pcmBufferSize
TQ,N,V_pcmBufferSize
floatConverter
T^{OpaqueAudioConverter=},N,V_floatConverter
integerConverter
T^{OpaqueAudioConverter=},N,V_integerConverter
voiceBoostUnit
T^{OpaqueAudioComponentInstance=},N,V_voiceBoostUnit
audioTimeStamp
T{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II},N,V_audioTimeStamp
voiceBoostGainDecibels
Tf,N,V_voiceBoostGainDecibels
broker.hdr
broker.hdr.asset
VSVocalizerEngine
markerCount
TQ,N,V_markerCount
mutablePCMData
T@"NSMutableData",&,N,V_mutablePCMData
stopMark
Tq,N,V_stopMark
callback
T@?,C,N,V_callback
state
Tq,N,V_state
error
T@"NSError",&,N,V_error
engine
T@"VSSpeechEngine",&,N,V_engine
nil path or nil mimeType
path
mimeType
ve_ttsResourceLoad
ve_ttsSetOutDevice
ve_ttsProcessText2Speech
indx
mdnf
rnnf
clc_
<COMPONENT>monogryph/featextract</COMPONENT>
voicePath
T@"NSString",&,N,V_voicePath
vocalizerSpeech
T{_VE_HSAFE=^vI},N,V_vocalizerSpeech
vocalizerInstance
T{_VE_HSAFE=^vI},N,V_vocalizerInstance
vocalizerDataClass
T^v,N,V_vocalizerDataClass
language
T{_VE_LANGUAGE=[128c][4c][128c]S},N,V_language
voiceInfo
T{?=[128c][128c][128c][128c][128c]S},N,V_voiceInfo
currentCallbackResult
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
_default
server_VSRecognitionPrepareOrBegin
server_VSRecognitionBegin
server_VSRecognitionCancel
com.apple.voiceservices.recognition
Error %d at %s:%d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-384/Daemon/VSRecognitionServer.c
_CreateEngineIfNecessary
_InitializeEngine
_RecognitionClientInvalidationCallback
Error %d at %s:%d (%s)
couldn't start recognition
recording.wav
_BeginRecognition
_SendChoices
_VSThreadRegistryTerminate
VSThreadRegistryTerminating
VSClientPostNotification
VSLocaleIdentifier
VSVersion
VSPluginVersions
KeywordIndex.plist
%@%@
.vscache
Info.plist
temp.vscache.XXXXX
_SaveEngineToCache
VSEngineIdentifier
temp.vscache.
PluginPath
PluginRegistry.plist
_CreateRegistryAndSaveToCache
modelid-desc
pluginid-vers
pluginpath-moddate
/System/Library/VoiceServices/PlugIns
Library
Caches
VoiceServices
VSRecognitionVersion
VSRecognitionModels
VSRecognitionModelIdentifier
VSRecognitionModelFileName
VSRecognitionModelIsTopLevel
VSRecognitionModelWeight
VSRecognitionModelIsCancelModel
VSRecognitionModelRequiredCapabilities
VSRecognitionModelDataProvider
VSRecognitionResultValidator
VSRecognitionResultHandler
vsplugin
lang
VSRecognitionModelDefinition
.plist
VSPlugin
<VSPlugin %p: %@>
VSRecognitionClasses
VSRecognitionSequences
VSRecognitionKeywords
VSRecognitionClassIdentifier
VSRecognitionClassRequiredCapabilities
VSRecognitionClassElements
VSRecognitionClassElementValues
VSRecognitionClassSequences
VSRecognitionClassType
VSRecognitionClassWeight
VSRecognitionClassContainsKeywords
VSRecognitionClassTypeCommand
VSRecognitionClassTypePersonName
VSRecognitionClassTypeStreetName
VSRecognitionClassTypeCityName
VSRecognitionClassTypeSongTitle
VSRecognitionClassTypeArtistName
VSRecognitionClassTypeAlbumName
VSRecognitionSequenceElements
VSRecognitionSequenceDisambiguationTag
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
_InstantiatePluginClassWithRecognitionModelKeyedName
_LoadPluginIfNecessary
isvalid
VSRecognitionClassDataProvider
dflt%ld
VSRecognitionModel
VSRecognitionClass
VSRecognitionSequence
<%@>
com.apple.voiceservices.notification.voice-update
VoiceServicesErrorDomain
%@ %@ %@ %.2f %.2f %.2f %@
type
TQ,N,V_type
request
T@"VSSpeechRequest",&,N,V_request
voiceBooster
T@"VSVoiceBooster",&,N,V_voiceBooster
playbackService
T@"VSAudioPlaybackService",&,N,V_playbackService
voiceSelection
T@"VSVoiceAssetSelection",&,N,V_voiceSelection
voiceResource
T@"VSVoiceResourceAsset",&,N,V_voiceResource
instrumentMetrics
T@"VSInstrumentMetrics",&,N,V_instrumentMetrics
speechCache
T@"<VSSpeechCacheItem>",&,N,V_speechCache
phonemes
T@"NSArray",&,N,V_phonemes
audioData
T@"NSMutableData",&,N,V_audioData
utterance
T@"NSString",&,N,V_utterance
cancelled
TB,N,V_cancelled
playbackServiceError
T@"NSError",&,N,V_playbackServiceError
taskAuxiliaryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_taskAuxiliaryQueue
timingInfos
T@"NSArray",&,N,V_timingInfos
delegate
T@"<VSSpeechServiceDelegate>",W,N,V_delegate
eagerTTS
TB,N,V_eagerTTS
task: inprogress %@, request: %@
T@"VSPresynthesizedAudioRequest",R,N,V_request
inProgress
TB,N,V_inProgress
stop
TB,N,V_stop
com.apple.voiced.prewarmQueue
com.apple.voiced.speakingQueue
Prewarm textify emoji
@"NSError"16@?0@"VSSpeechSynthesisCallbackResult"8
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-384/Daemon/VSSpeechService.m
<Unknown File>
Invalid parameter not satisfying: %@
task.speechCache != nil
Unsupported cache format
[task.speechCache isKindOfClass:[VSSpeechCacheAudio class]]
Can't create VSAudioPlaybackService
task.voiceSelection != nil
Can't create VSSpeechEngine
@"NSError"16@?0@"NSData"8
Invalid chunk size: %@ at offset %@, bytes count = %@
@"AVAudioBuffer"20@?0I8^q12
client
%@.%@
voice
locale
gender
footprint
No voice available
Compact voice is explicited disabled.
Voice is deleted already.
VoiceServices/config
synthesizing
speaking
cachedEngine
T@"VSSpeechEngine",&,N,V_cachedEngine
prewarmQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_prewarmQueue
speechBooster
T@"VSVoiceBooster",&,N,V_speechBooster
speakingTasks
T@"NSMutableArray",&,N,V_speakingTasks
synthesisTasks
T@"NSMutableArray",&,N,V_synthesisTasks
currentTask
T@"<VSSpeechServiceTaskProtocol>",&,N,V_currentTask
threadMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_threadMutex
threadMutexAttr
T{_opaque_pthread_mutexattr_t=q[8c]},N,V_threadMutexAttr
speakingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_speakingQueue
Manifest.sqlitedb
SELECT model_id, validity FROM Model;
 WHERE model_id = ?;
INSERT OR REPLACE INTO ValueTranslation (model_id, class_id, original_value, translated_value) VALUES (?, ?, ?, ?);
SELECT original_value FROM ValueTranslation WHERE model_id = ? AND class_id = ? AND translated_value = ?;
DELETE FROM ValueTranslation
 model_id = ?
 class_id = ?
 WHERE
 AND
VSRecognitionConfigurationCacheManifest
Model
model_id
validity
last_update
SELECT %s FROM %s WHERE ROWID = ?
UPDATE %s SET %s = ? WHERE ROWID = ?
ValueTranslation
CREATE TABLE Model (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, validity TEXT, last_update INTEGER, UNIQUE(model_id));
CREATE INDEX ModelIdIndex on Model(model_id);
CREATE TABLE ValueTranslation (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, class_id TEXT, original_value TEXT, translated_value TEXT, UNIQUE(model_id, class_id, original_value));
CREATE INDEX ValueTranslationModelIdClassIdIndex on ValueTranslation(model_id, class_id, translated_value);
/var/mobile/Library/VoiceServices/SpeechCache
VSSpeechCacheErrorDomain
-[VSSpeechCache initWithStorePath:]
Cache type name too long
-[VSSpeechCache addCache:]
q24@?0@"NSURL"8@"NSURL"16
dirPath
T@"NSString",&,N,V_dirPath
VSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
Error AudioQueueStart
audioQueue
T^{OpaqueAudioQueue=},N,V_audioQueue
waitForStateChangeMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_waitForStateChangeMutex
stateChangeCondition
T{_opaque_pthread_cond_t=q[40c]},N,V_stateChangeCondition
sessionID
TI,N,V_sessionID
_VSVocalizerDataMappingImplMap
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-384/Daemon/VSVocalizerPlatform.c
info->mappedData == NULL
uselect
T@"NSString",&,N,V_key
T@"NSData",&,N,V_audioData
magicVersion
Tq,R,N,V_magicVersion
T@"NSArray",R,N,V_timingInfos
packetCount
Tq,R,N,V_packetCount
packetDescriptions
T@"NSData",R,N,V_packetDescriptions
connectionIdentifier
T@"NSString",&,N,V_connectionIdentifier
isSpeaking
TB,R,N
\audio=
\audio="%@"\
\mrk=%@=%@\
.wav
%02x
com.apple.notifyd.matching
com.apple.MobileAsset.VoiceServices.CustomVoice.cached-metadata-updated
com.apple.MobileAsset.VoiceServicesVocalizerVoice.cached-metadata-updated
com.apple.MobileAsset.VoiceServices.CustomVoice.new-asset-installed
com.apple.MobileAsset.VoiceServices.GryphonVoice.new-asset-installed
com.apple.MobileAsset.VoiceServicesVocalizerVoice.new-asset-installed
com.apple.MobileAsset.VoiceServices.VoiceResources.new-asset-installed
v16@?0@"NSObject<OS_xpc_object>"8
com.apple.voiced
KeepAliveManager
com.apple.voiceservices.keepalive
v16@?0@"NSError"8
connectionCount
TQ,N,V_connectionCount
runloopSourceRef
T^{__CFRunLoopSource=},N,V_runloopSourceRef
listener
T@"NSXPCListener",&,N,V_listener
init
alloc
initWithLoggingPrefix:
stringWithFormat:
defaultService
recordCategory:value:
.cxx_destruct
loggingPrefix
setLoggingPrefix:
_loggingPrefix
uninitialize
dealloc
initialize
voiceBoostGainDecibels
length
mutableBytes
dataWithLength:
errorWithDomain:code:userInfo:
initWithStreamDescription:pcmBufferSize:
setVoiceBoostGainDecibels:
processData:
asbd
setAsbd:
pcmBufferSize
setPcmBufferSize:
floatConverter
setFloatConverter:
integerConverter
setIntegerConverter:
voiceBoostUnit
setVoiceBoostUnit:
audioTimeStamp
setAudioTimeStamp:
_voiceBoostGainDecibels
_pcmBufferSize
_floatConverter
_integerConverter
_voiceBoostUnit
_asbd
_audioTimeStamp
setLength:
array
engine
setStartTime:
setTextRange:
addObject:
arrayWithCapacity:
vocalizerInstance
stringWithUTF8String:
initWithCallback:pcmBufferSize:
resetPCMBuffer
pcmData
markerBuffer
markerBufferSize
wordTimingInfos
phonemes
state
setState:
error
setError:
markerCount
setMarkerCount:
mutablePCMData
setMutablePCMData:
stopMark
setStopMark:
callback
setCallback:
setEngine:
_markerBuffer
_state
_error
_markerCount
_mutablePCMData
_stopMark
_callback
_engine
brokerInfoData
bytes
isGryphonVoice:
UTF8String
dictionaryWithObjects:forKeys:count:
dataWithContentsOfFile:
currentCallbackResult
lengthOfBytesUsingEncoding:
defaultManager
voicePath
contentsOfDirectoryAtPath:error:
countByEnumeratingWithState:objects:count:
shouldPreheatComponent:
stringByAppendingPathComponent:
mmapAndScanFile:
code
domain
isEqualToString:
arrayWithObjects:count:
setWithArray:
containsObject:
hasPrefix:
appendBytes:length:
initWithData:encoding:
containsString:
isUserCancelError:
initWithVoicePath:
setVolume:
setRate:
setPitch:
loadResourceAtPath:mimeType:
synthesizeText:callback:
stopAtMarker:
preheat
setVoicePath:
rate
pitch
volume
vocalizerSpeech
setVocalizerSpeech:
setVocalizerInstance:
vocalizerDataClass
setVocalizerDataClass:
language
setLanguage:
voiceInfo
setVoiceInfo:
setCurrentCallbackResult:
_rate
_pitch
_volume
_voicePath
_vocalizerDataClass
_currentCallbackResult
_vocalizerSpeech
_vocalizerInstance
_language
_voiceInfo
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
respondsToSelector:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
beginReportingChanges
stopReportingChanges
validRecognitionResultFromRecognitionResult:
validRecognitionResultFromRecognitionResult:knownDisambiguationValues:
requestCreatedTimestamp
setRequestCreatedTimestamp:
text
setUtterance:
request
voiceSelection
voiceResource
contextInfo
md5hash
isSpeakingTask
playbackService
delegate
initWithRequest:
taskAuxiliaryQueue
setRequest:
timingInfos
setTimingInfos:
setDelegate:
eagerTTS
setEagerTTS:
type
setType:
voiceBooster
setVoiceBooster:
setPlaybackService:
setVoiceSelection:
setVoiceResource:
instrumentMetrics
setInstrumentMetrics:
speechCache
setSpeechCache:
setPhonemes:
audioData
setAudioData:
utterance
cancelled
setCancelled:
playbackServiceError
setPlaybackServiceError:
setTaskAuxiliaryQueue:
_eagerTTS
_cancelled
_request
_timingInfos
_delegate
_type
_voiceBooster
_playbackService
_voiceSelection
_voiceResource
_instrumentMetrics
_speechCache
_phonemes
_audioData
_utterance
_playbackServiceError
_taskAuxiliaryQueue
numberWithBool:
inProgress
setInProgress:
stop
setStop:
_inProgress
_stop
selectVoiceForRequest:error:
cachedEngine
languageCode
engineForVoicePath:language:
setCachedEngine:
textifyEmojiWithLanguage:
setSpeechBooster:
spinNextTask
count
firstObject
removeObjectAtIndex:
speakTask:
presynthesizedAudioTask:
isSimilarTo:
stopCurrentTaskWithMark_nonlock:
synthesizeTask:
sharedManager
selectVoiceResourceAssetForLanguage:
defaultCacheStore
cacheDataForKey:
_synthesizeNonCachedTask:
setIsSynthesisCached:
durationOfSamples:withAudioDescription:
setAudioDuration:
setVoiceAssetKey:
setSpeechEndTimestamp:
speechEndTimestamp
setSpeechBeginTimestamp:
outputPath
shouldCache
standardInstance
disableCache
cacheTask:
logFinishTask:isSynthesizeTask:error:
synthesisRequestDidFinishWithInstrumentMetrics:error:
_initializeTask:
data
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
appendData:
_speakCachedTask:
_speakUncachedTask:
tallyTask:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
synthesisBeginTimestamp
_speakCachedAudio:
audioSessionID
initWithAudioSessionID:asbd:
start
setAudioStartTimestampDiffs:
speechRequestDidStart
speechRequestDidReceiveTimingInfo:
packetCount
packetDescriptions
enqueue:packetCount:packetDescriptions:
flushAndStop
voiceData
addObjectsFromArray:
speechBeginTimestamp
presynthesizedAudioRequestDidStopAtEnd:error:
pause
speechRequestDidPause
setIsWarmStart:
speechBooster
gainDecibelWithVolume:
insertContextInfo:
substituteAudioWithLocalPath
precomposedStringWithCanonicalMapping
playerStreamDescription
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
bytesOfDuration:withAudioDescription:
subdataWithRange:
presynthesizedAudioRequestDidStart
decoderStreamDescription
sharedInstance
beginChunkDecoderForStreamDescription:
numberWithInteger:
numberWithUnsignedInteger:
dataWithBytes:length:
decodeChunk:outError:
_clockFactor
audioQueueLatency
endChunkDecoding
setPcmDataSize:
initWithStreamDescription:
initFromFormat:toFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
convertToBuffer:error:withInputFromBlock:
audioBufferList
initWithKey:audioDescription:audioData:packetCount:packetDescriptions:wordTimingInfo:
addCache:
clientBundleIdentifier
masteredVersion
name
languages
gender
genderStringFromGender:
footprint
footprintStringFromFootprint:
voiceType
selectVoiceForLang:type:gender:footprint:
disableCompactVoiceFallback
fileExistsAtPath:
searchPathURL
path
resourceList
objectForKeyedSubscript:
stringByReplacingOccurrencesOfString:withString:
typeStringFromType:
contentVersion
isBuiltInVoice
numberWithInt:
isWarmStart
ttsTotalLatency
ttsSynthesisLatency
sharedService
prewarmWithRequest:
enqueueSpeakingTask:
enqueueSynthesisTask:
enqueuePresynthesizedAudioTask:
currentSpeakingTask
stopCurrentTaskWithMark:
pauseCurrentTask
unpauseCurrentTask
stopPresynthesizedAudioTask:
prewarmQueue
setPrewarmQueue:
speakingTasks
setSpeakingTasks:
synthesisTasks
setSynthesisTasks:
currentTask
setCurrentTask:
threadMutex
setThreadMutex:
threadMutexAttr
setThreadMutexAttr:
speakingQueue
setSpeakingQueue:
_cachedEngine
_prewarmQueue
_speechBooster
_speakingTasks
_synthesisTasks
_currentTask
_speakingQueue
_threadMutexAttr
_threadMutex
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithStorePath:
dataUsingEncoding:
serializedData
dataWithCapacity:
dirPath
writeToFile:options:error:
initWithKey:data:
fileURLWithPath:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
getResourceValue:forKey:error:
compare:
sortedArrayUsingComparator:
subarrayWithRange:
removeItemAtURL:error:
cleanCache
setDirPath:
_dirPath
defaultCenter
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
removeObserver:
userInfo
objectForKey:
integerValue
_setupAudioSession
setPreferredSampleRate:error:
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
doubleValue
currentRoute
inputs
objectAtIndex:
portType
opaqueSessionID
handleMediaServerReset
waitForAudioQueueStop
signalQueueRunningStateChange
isAudioQueueRunning
reset
audioQueue
setAudioQueue:
sessionID
setSessionID:
waitForStateChangeMutex
setWaitForStateChangeMutex:
stateChangeCondition
setStateChangeCondition:
_sessionID
_audioQueue
_stateChangeCondition
_waitForStateChangeMutex
archivedDataWithRootObject:
getBytes:range:
unarchiveObjectWithData:
magicVersion
setKey:
_magicVersion
_packetCount
_packetDescriptions
_key
invalidate
installedAssetsForType:voicename:language:gender:footprint:
remoteObjectProxy
speechRequestDidContinue
speechRequestMark:didStartForRange:
cleanOldVoiceResources
cleanUnusedVoiceAssets
installedVoiceResources
initWithDictionaryRepresentation:
dictionaryRepresentation
boolValue
sharedCurrentSpeakingTaskQueue
updateWithConnectionIdentifier:
prewarmIfNeededWithRequest:
startSpeechRequest:
startSynthesisRequest:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
startPresynthesizedAudioRequest:
stopPresynthesizedAudioRequest
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
cleanUnusedAssets:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getVoiceResourceForLanguage:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
setLogToFile:
getLogToFile:
initWithConnection:
isSpeaking
connectionIdentifier
setConnectionIdentifier:
_connection
_connectionIdentifier
stringWithString:
rangeOfString:options:range:
substringWithRange:
stringByAppendingString:
replaceCharactersInRange:withString:
stringWithCapacity:
appendFormat:
string
appendString:
resume
timeIntervalSinceNow
date
resetCache
initWithMachServiceName:
maintainWithAudioType:keepAudioSessionActive:
cancel
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInvalidationHandler:
listener:shouldAcceptNewConnection:
_keepAliveListener
_keepAliveManager
removeObject:
hasActiveKeepAlives
maintainKeepAlive:
cancelKeepAlive:
_activeKeepAlives
_shouldChangeAudioSession
setManager:
_manager
_isActive
_activity
_keepSessionActive
_transaction
_registryRunLoopSource
amendVoiceWithDefaultSettings:
downloadVoiceAsset:useBattery:completion:
cancelDownload:completion:
scheduleBackgroundTask
localizedDescription
setRemoteObjectInterface:
setClasses:forSelector:argumentIndex:ofReply:
connectionCount
setConnectionCount:
runloopSourceRef
setRunloopSourceRef:
listener
setListener:
_connectionCount
_runloopSourceRef
_listener
VSAggdService
VSVoiceBooster
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSRecognitionModelDataProvider
NSObject
VSRecognitionResultValidator
VSSpeechServiceSynthesisTask
VSSpeechServiceTaskProtocol
VSSpeechServicePresynthesizedAudioTask
VSSpeechService
VSSpeechCache
VSAudioSession
VSAudioPlaybackService
VSSpeechCacheAudio
VSSpeechCacheItem
VSSpeechXPCHandler
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSRemoteKeepAlive
VSKeepAliveServer
NSXPCListenerDelegate
VSServerKeepAliveManager
VSKeepAliveClient
VSSpeechServer
SpeechService
@16@0:8
@24@0:8@16
v32@0:8@16@24
v16@0:8
v24@0:8@16
@"NSString"
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16Q56
B16@0:8
v20@0:8f16
f16@0:8
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
Q16@0:8
v24@0:8Q16
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{OpaqueAudioComponentInstance=}16@0:8
v24@0:8^{OpaqueAudioComponentInstance=}16
{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16@0:8
v80@0:8{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16
^{OpaqueAudioConverter=}
^{OpaqueAudioComponentInstance=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
@32@0:8@?16Q24
^{?=IiIIIISII*}16@0:8
q16@0:8
v24@0:8q16
@?16@0:8
v24@0:8@?16
[64{?="ulMrkInfo"I"eMrkType"i"ulSrcPos"I"ulSrcTextLen"I"ulDestPos"I"ulDestLen"I"usPhoneme"S"ulMrkId"I"ulParam"I"szPromptID"*}]
@"NSError"
@"NSMutableData"
@"VSSpeechEngine"
B24@0:8@16
@32@0:8@16@24
@32@0:8@16@?24
{_VE_HSAFE=^vI}16@0:8
v32@0:8{_VE_HSAFE=^vI}16
^v16@0:8
v24@0:8^v16
{_VE_LANGUAGE=[128c][4c][128c]S}16@0:8
v278@0:8{_VE_LANGUAGE=[128c][4c][128c]S}16
{?=[128c][128c][128c][128c][128c]S}16@0:8
v658@0:8{?=[128c][128c][128c][128c][128c]S}16
@"VSSpeechSynthesisCallbackResult"
{_VE_HSAFE="pHandleData"^v"u32Check"I}
{_VE_LANGUAGE="szLanguage"[128c]"szLanguageTLW"[4c]"szVersion"[128c]"u16LangId"S}
{?="szVersion"[128c]"szLanguage"[128c]"szVoiceName"[128c]"szVoiceAge"[128c]"szVoiceType"[128c]"u16LangId"S}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
@"VSRecognitionResult"24@0:8@"VSRecognitionResult"16
@"VSRecognitionResult"32@0:8@"VSRecognitionResult"16@"NSDictionary"24
@"VSAudioPlaybackService"16@0:8
v20@0:8B16
@"VSSpeechRequest"
@"NSArray"
@"<VSSpeechServiceDelegate>"
@"VSVoiceBooster"
@"VSAudioPlaybackService"
@"VSVoiceAssetSelection"
@"VSVoiceResourceAsset"
@"VSInstrumentMetrics"
@"<VSSpeechCacheItem>"
@"NSObject<OS_dispatch_queue>"
@"VSPresynthesizedAudioRequest"
d16@0:8
@32@0:8@16^@24
v36@0:8@16B24@28
Q64@0:8d16{AudioStreamBasicDescription=dIIIIIIII}24
d64@0:8Q16{AudioStreamBasicDescription=dIIIIIIII}24
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
{_opaque_pthread_mutexattr_t=q[8c]}16@0:8
v32@0:8{_opaque_pthread_mutexattr_t=q[8c]}16
@"NSMutableArray"
@"<VSSpeechServiceTaskProtocol>"
{_opaque_pthread_mutexattr_t="__sig"q"__opaque"[8c]}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
q36@0:8B16q20q28
v28@0:8B16q20
{?="category"q"activity"q}
^{__CFBag=}
@60@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20
@40@0:8@16q24@32
^{OpaqueAudioQueue=}16@0:8
v24@0:8^{OpaqueAudioQueue=}16
I16@0:8
v20@0:8I16
{_opaque_pthread_cond_t=q[40c]}16@0:8
v64@0:8{_opaque_pthread_cond_t=q[40c]}16
^{OpaqueAudioQueue=}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
@"NSData"16@0:8
@32@0:8@"NSString"16@"NSData"24
@96@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24@64q72@80@88
@"NSData"
Vv24@0:8@16
Vv24@0:8q16
Vv32@0:8@16@?24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv56@0:8@16q24q32q40@?48
Vv20@0:8B16
Vv24@0:8@"NSString"16
Vv24@0:8@"VSSpeechRequest"16
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?@"NSError">16
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv24@0:8@"NSArray"16
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv56@0:8@"NSString"16q24q32q40@?<v@?@"VSVoiceAsset">48
Vv40@0:8q16{_NSRange=QQ}24
Vv36@0:8B16@20@28
Vv32@0:8@16@24
Vv28@0:8B16@20
Vv36@0:8B16@"NSString"20@"NSError"28
Vv24@0:8@"VSInstrumentMetrics"16
Vv32@0:8@"VSInstrumentMetrics"16@"NSError"24
Vv28@0:8B16@"NSError"20
@"NSXPCConnection"
Vv28@0:8q16B24
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"VSServerKeepAliveManager"
@"NSMutableSet"
@"NSObject<OS_os_transaction>"
^{__CFRunLoopSource=}
^{__CFRunLoopSource=}16@0:8
v24@0:8^{__CFRunLoopSource=}16
f24@0:8d16
bplist00
 !"#$%&'($)_
BuildMachineOSBuild_
CFBundleDevelopmentRegion_
CFBundleExecutable_
CFBundleIdentifier_
CFBundleInfoDictionaryVersion\CFBundleName_
CFBundlePackageType_
CFBundleShortVersionString_
CFBundleSignature_
CFBundleSupportedPlatforms_
CFBundleVersionZDTCompiler_
DTPlatformBuild^DTPlatformName_
DTPlatformVersionZDTSDKBuildYDTSDKNameWDTXcode\DTXcodeBuild_
MinimumOSVersion^UIDeviceFamilyW16B2657WEnglishVvoiced_
com.apple.voicedS6.0TFMWKU1.0.0T????
iPhoneSimulatorS1.0_
"com.apple.compilers.llvm.clang.1_0P_
iphonesimulatorT11.0V15A340_
iphonesimulator11.0T0900V9M189u
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.Contacts.database-allow</key>
<true/>
<key>com.apple.coreaudio.allow-opus-codec</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceServices.CustomVoice</string>
<string>com.apple.MobileAsset.VoiceServices.VoiceResources</string>
<string>com.apple.MobileAsset.VoiceServicesVocalizerVoice</string>
<string>com.apple.MobileAsset.VoiceServices.GryphonVoice</string>
</array>
<key>com.apple.private.assets.change-daemon-config</key>
<true/>
<key>com.apple.private.coreaudio.borrowaudiosession.allow</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceMediaLibrary</string>
</array>
</dict>
</plist>
