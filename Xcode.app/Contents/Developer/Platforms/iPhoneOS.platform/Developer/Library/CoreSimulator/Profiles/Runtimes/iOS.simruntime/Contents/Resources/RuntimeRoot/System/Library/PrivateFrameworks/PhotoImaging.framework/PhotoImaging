Fail: %{public}@
Trace: %{public}@
AL stabilization failure: not running fusion registration
Choosing gray world instead of gray edge
Brightness is %@, greenChannelPercentage is %f, Sushi: %@
aperture=%@, shutterSpeed=%@, iso=%@
Buffer size is %@, bytes per row is %ld, dark_thr=%f, sat_thr=%f, noise_thr=%f
all done summing, np_gw is %d, np_ge is %d
wp_ge {%f, %f, %f, %f} wp_gw {%f, %f, %f, %f}, Sushi? %@
RGB = %f, %f, %f
YIQ = %f, %f, %f from %f, %f, %f
Resolved source at: %@
Error resolving cache node: %@
Still image node:
Still image geometry:
Still image:
clap=%@, crop=%@, fullSize=%@, videoScale=%@ => guide rect: %@
Continue: %{public}@
Loading long-exposure fusion tuning parameters from file: %@
Failed to load fusion tuning parameters.
Using fusion tuning parameters: {kNCCBlurHalfSize=%d, kNCCEdge0=%f, kNCCEdge1=%f, kBlendMaskThreshold0=%f, kBlendMaskThreshold1=%f}
Missing inputImage
Missing inputMaskImage
Missing inputStillImage
Missing inputRenderScale
Missing inputVideoScale
Missing inputAlignmentExtent
Malformed inputAlignmentExtent vector
Missing inputAlignmentTransform
Malformed inputAlignmentTransform vector
Failed to apply red eye repair. error: %{public}@
Metadata dictionary missing fullSizeWith or fullSizeHeight:
Metadata dictionary missing exif aux dictionary:
Exif aux dictionary missing MWG region dictionary:
MWG region dictionary missing region list:
Region list does not contain a focus rect:
Malformed focus rect dictionary:
Invalid focus rect: {%g,%g,%g,%g}
Couldn't deserialize face observations from metadata: %@, assuming empty.
Invalid face indexes from metadata: %@, ignored. Error: %@
Couldn't deserialize face observations from metadata: %@
Initializer not available: -[%@ %@], use designated initializer instead.
-[PIAutoLoopExportRequest initWithRequest:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoopRequests.m
-[PIAutoLoopExportRequest initWithComposition:destinationURL:]
Invalid parameter not satisfying: %s
recipe != nil
-[PIAutoLoopExportRequest initWithComposition:autoLoopRecipe:flavor:destinationURL:maskDestinationURL:destinationUTI:]
PI_AUTOLOOP_AUDIO
B8@?0
metadata
T@"NSArray",C,V_metadata
recipe
T@"NSDictionary",R,V_recipe
flavor
Tq,R,V_flavor
addAudio
TB,V_addAudio
destinationUTI
T@"NSString",R,V_destinationUTI
destinationMaskURL
T@"NSURL",R,V_destinationMaskURL
Tq,N,V_flavor
T@"NSDictionary",C,N,V_recipe
v8@?0
completion != nil
-[PILongExposureFusionAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PILongExposureFusionAutoCalculator.m
PILongExposureFusionAutoCalculator requires a live-photo composition
autoLoop
enabled
PILongExposureFusionAutoCalculator requires a long-exposure adjustment
Malformed auto-loop recipe
transform
extent
v16@?0@"NUResponse"8
-[PIAutoLoopAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PIAutoLoopAutoCalculator.m
PIAutoLoopAutoCalculator requires a video
B32@?0@"AVMetadataItem"8Q16^B24
inputImage cannot be nil
-[PITempTintFilter outputImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PITempTintFilter.m
CIColorMatrix
inputImage
inputRVector
inputGVector
inputBVector
T@"CIImage",&,N,V_inputImage
temperature
Td,N,V_temperature
tint
Td,N,V_tint
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
statistics
T@"<NURenderStatistics>",R
T@"NSDictionary",R
T@"NSDictionary",&,V_recipe
error != nil
-[PIAutoLoopAnalysisJob prepare:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoopJobs+Analysis.m
unable to find video source node
-[PIAutoLoopAnalysisJob render:]
auto loop not supported
videoSource
T@"AVAsset",&,N,V_videoSource
T@"NSDictionary",&,N,V_recipe
neutralGray
faceBalance
tempTint
-[PIFaceBalanceAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PIWhiteBalanceAutoCalculators.m
CIFaceBalance
/Master/Source
{?={?=[4d]}{?=[4d]}d}
gu_grayColorResultValue
T{?={?=[4d]}{?=[4d]}d},R
{?=[4d]}
RGBResultValue
T{?=[4d]},R
colorType
grayColor
-[PIWhiteBalanceAutoCalculator calculate:]
faceI
OrigI
faceQ
OrigQ
faceWarmth
Warmth
faceStrength
Strength
v16@?0@"NUAutoCalculatorResponse"8
v16@?0^{NUResponse=#}8
PIWhiteBalanceAutoCalculator
v16@?0@"<NUMutableBuffer>"8
v24@?0@"<NUBufferTile>"8^B16
color
{Exif}
v16@?0@"<NUBuffer>"8
CIAreaAverage
return Filter('CIEdges', { 'inputImage' : input, 'inputIntensity' : 1.0 });
Expected non-NULL pixels passed in
void customRGBtoYIQ(const CGFloat *, double *, double, double, double)
CIBlendWithMask
inputMaskImage
T@"CIImage",&,N,V_inputMaskImage
inputOffset
T{CGPoint=dd},V_inputOffset
vec4 meaningBlur(vec4 im, vec4 b)
vec4 result = im;
float thresh = 0.1;
float g1 = max(max(im.r, im.g), im.b);
float g2 = dot(b.rgb, vec3(1.0/3.0));
float diff = max(g2-g1, -1.0);
diff = smoothstep(0.1-thresh, 0.1+thresh, diff);
result.rgb = mix(im.rgb, b.rgb, diff+0.5);
return result;
vec4 clarityNew(vec4 s, vec4 b, float intensity)
float sl = (s.r + s.g + s.b);
float bl = (b.r + b.g + b.b);
float dl = sl + (sl - bl) * intensity;
float mult = dl / max(sl, 0.0001);
mult = 1.571 * (mult - 1.0);
mult = mult / (1.0 + abs(mult));
mult += 1.0;
mult = clamp(mult, 1.0 - 0.5 * abs(intensity), 1.0 + 1.0 * abs(intensity));
s.rgb = s.rgb * mult;
return s;
kernel vec4 definition(sampler image, sampler blur, float intensity)
vec4 imgSample = sample(image, samplerCoord(image));
vec4 blurSample = sample(blur, samplerCoord(blur));
vec4 meaning = meaningBlur(imgSample, blurSample);
vec4 clarity = clarityNew(imgSample, meaning, intensity);
return clarity;
T@"CIImage",&,V_inputImage
inputBlurImage
T@"CIImage",&,V_inputBlurImage
inputIntensity
T@"NSNumber",&,V_inputIntensity
float luminanceWeight(vec4 pix, vec4 center, float slope)
return max(1.0 + (slope * length(pix.rgb - center.rgb)), 0.0);
vec4 bilateralRow_1(sampler src, float slope, vec2 offset1, float weight1)
float diff1;
vec2 coord;
vec4 pix1, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
diff1 = luminanceWeight(pix1, center, slope) * weight1;
return vec4(diff1 * pix1.rgb, diff1);
kernel vec4 bilateralAdd_1(sampler src, sampler sums, float slope, vec2 offset1, float weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_1(src, slope, offset1, weight1);
vec4 bilateralRow_2(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 weight1)
float diff1, diff2;
vec2 coord;
vec4 pix1, pix2, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb, diff1 + diff2);
kernel vec4 bilateralAdd_2(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_2(src, slope, offset1, offset2, weight1);
vec4 bilateralRow_3(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
float diff1, diff2, diff3;
vec2 coord;
vec4 pix1, pix2, pix3, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb, diff1 + diff2 + diff3);
kernel vec4 bilateralAdd_3(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_3(src, slope, offset1, offset2, offset3, weight1);
vec4 bilateralRow_4(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec4 weight1)
float diff1, diff2, diff3, diff4;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb,
diff1 + diff2 + diff3 + diff4);
kernel vec4 bilateralAdd_4(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3,
vec2 offset4, vec4 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_4(src, slope, offset1, offset2, offset3, offset4, weight1);
vec4 bilateralRow_5(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec4 weight1, float weight2)
float diff1, diff2, diff3, diff4, diff5;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb,
diff1 + diff2 + diff3 + diff4 + diff5);
kernel vec4 bilateralAdd_5(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec4 weight1, float weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_5(src, slope, offset1, offset2, offset3, offset4, offset5, weight1, weight2);
vec4 bilateralRow_6(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec4 weight1, vec2 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6);
kernel vec4 bilateralAdd_6(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec4 weight1, vec2 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_6(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, weight1, weight2);
vec4 bilateralRow_7(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7);
kernel vec4 bilateralAdd_7(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_7(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, weight1, weight2);
vec4 bilateralRow_8(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6,
vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8);
kernel vec4 bilateralAdd_8(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_8(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, weight1, weight2);
vec4 bilateralRow_9(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6, vec2 offset7,
vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, pix9, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
pix9 = sample(src, samplerTransform(src, coord + offset9));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
diff9 = luminanceWeight(pix9, center, slope) * weight3;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb + diff9 * pix9.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8 + diff9);
kernel vec4 bilateralAdd_9(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_9(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, offset9,
weight1, weight2, weight3);
kernel vec4 bilateralFinalize(sampler sums)
vec4 sum;
sum = sample(sums, samplerCoord(sums));
return vec4(sum.rgb / max(sum.a, 0.001), 1.0);
kernel vec4 bilateralLoop2(sampler src, float slope, vec2 weights12)
vec2 coord;
vec4 center = sample(src, samplerCoord(src));
vec4 sum;
vec4 pix0, pix1, pix2;
vec4 pix3,       pix5;
vec4 pix6, pix7, pix8;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-2.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -1.0));
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dy;
pix3 = sample(src, coord);
coord = coord + dx;
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dy;
pix6 = sample(src, coord);
coord = coord + dx;
pix7 = sample(src, coord);
coord = coord + dx;
pix8 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights12.y);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights12.x) + sum;
sum =                                        center                            + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix7 - center)))) * (pix7 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix8 - center)))) * (pix8 * weights12.y) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop5(sampler src, float slope, vec4 weights1245)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-4.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -2.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop11(sampler src, float slope, vec4 weights1245, vec4 weights89AD)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4, pix5, pix6;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-6.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-2.0, -3.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.y) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 convertFromRGBToLab(sampler src)
vec3 f;
vec4 pix, color;
pix = unpremultiply(sample(src, samplerCoord(src)));
color.xyz = pix.r * vec3(0.449695,  0.316251, 0.18452  )
+ pix.g * vec3(0.244634,  0.672034, 0.0833318)
+ pix.b * vec3(0.0251829, 0.141184, 0.922602 );
color.xyz *= vec3(1.052111, 1.0, 0.918417);
f = compare(color.xyz - 0.00885645, 7.787037 * color.xyz + 0.137931, pow(color.xyz, vec3(0.333333)));
color.r = 116.0 * f.y - 16.0;
color.g = 500.0 * (f.x - f.y);
color.b = 200.0 * (f.y - f.z);
color.rgb *= 0.005;
color.a = 1.0;
return color;
kernel vec4 convertFromLabToRGB(sampler src, sampler original)
vec3 f, cie;
vec4 color, pix, opix;
pix = sample(src, samplerCoord(src));
opix = sample(original, samplerCoord(original));
pix.rgb *= 200.0;
f.y = (pix.r + 16.0) / 116.0;
f.x = f.y + pix.g * 0.002;
f.z = f.y - pix.b * 0.005;
color.xyz = f * f * f;
cie = compare(color.xyz - 0.00885645, (f.xyz - 0.137931) / 7.787037, color.xyz);
cie *= vec3(0.95047, 1.0, 1.08883);
color.rgb = cie.x * vec3(2.95176,   -1.28951, -0.47388  )
+ cie.y * vec3(-1.0851,    1.99084,  0.0372023)
+ cie.z * vec3(0.0854804, -0.269456, 1.09113  );
color.a = opix.a;
return premultiply(color);
bilateralAdd_1
bilateralAdd_2
bilateralAdd_3
bilateralAdd_4
bilateralAdd_5
bilateralAdd_6
bilateralAdd_7
bilateralAdd_8
bilateralAdd_9
bilateralFinalize
convertFromRGBToLab
convertFromLabToRGB
points.count > 0
-[GUBilateralConvolution boundsForPointArray:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIBilateralFilter.m
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
inputPoints
T@"NSArray",&,V_inputPoints
inputWeights
T@"NSArray",&,V_inputWeights
inputEdgeDetail
T@"NSNumber",&,V_inputEdgeDetail
inputVersion
T@"NSNumber",&,V_inputVersion
bilateralLoop2
bilateralLoop5
bilateralLoop11
inputBorder
T@"NSNumber",&,V_inputBorder
ridiculously large radius for bilateral filter
-[PIBilateralFilter outputImage]
unable to allocate convolution table in bilateral filter
inputRadius
T@"NSNumber",&,V_inputRadius
Malformed AutoLoop recipe : flavor
AutoLoop
LongExposure
LongExposureMotion
Invalid recipe flavor
Long Exposure
error != NULL
-[PILongExposureCacheNode nodeByReplayingAgainstCache:pipelineState:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoopCacheNode.m
Cannot evaluate cache node
mask
originalRequest != nil
-[PILongExposureCacheNode newRenderRequestWithOriginalRequest:persistentURL:]
PIAutoLoopCacheNode
response != nil
-[PILongExposureCacheNode resolveSourceWithResponse:]
-[PILongExposureCacheNode _evaluateImageGeometry:]
Failed to get input geometry
Failed to get video properties
Malformed recipe
T@"NSDictionary",R,N,V_recipe
longExposureInput != nil
-[PILongExposureMotionCacheNode initWithLongExposureInput:]
-[PIAutoLoopCacheNode _evaluateImageGeometry:]
incorrect flavor type
Tq,R,N,V_flavor
-[PIAutoLoopVideoNode initWithSettings:inputs:]
-[PIAutoLoopVideoNode nodeByReplayingAgainstCache:pipelineState:error:]
loopFrameData_frameTransforms
loopRecipe_stabCropRect
primary
Missing primary video frame
video
frameTransform_rawTime
cleanAperture
secondary
Missing secondary video frame
Unexpected number of frame transforms
-[PIAutoLoopVideoNode _evaluateImageGeometry:]
-[PIAutoLoopVideoNode _evaluateVideoProperties:]
-[PIAutoLoopVideoNode _evaluateVideo:]
loopRecipe_frameInstructions
loopFrameData_presTime
loopFrameData_presDur
Failed to update video track
loopRecipe_loopParams
Malformed loop recipe, missing loop params
loopParams_duration
loopParams_fadeLen
loopParams_startTime
Failed to update audio track #1
Failed to update audio track #2
-[PIAutoLoopVideoNode _evaluateVideoComposition:]
Unsupported video configuration
-[PIAutoLoopVideoNode _evaluateAudioMix:]
-[PIAutoLoopMirrorNode _evaluateVideo:]
-[PIAutoLoopMirrorNode _evaluateVideoComposition:]
-[PIAutoLoopMirrorNode _evaluateAudioMix:]
Mirror does not require an AVAudioMix
-[PIAutoLoopFrameNode _evaluateImageGeometry:]
-[PIAutoLoopFrameNode _evaluateImage:]
origin_x
origin_y
width
height
missing primary input
missing secondary input
frameTransform_blend_alpha
Invalid frame instruction
frameTransform_homography
CIPerspectiveTransform
inputTopLeft
inputTopRight
inputBottomLeft
inputBottomRight
Flash
FNumber
ApertureValue
ShutterSpeedValue
ExposureTime
ISOSpeedRatings
kernel vec4 alphaCompositing(__sample src, __sample dst, float a)
return mix(dst, src, a);
kernel vec4 dynamismMap(sampler imageMax, sampler imageMin, float logisticGain, float logisticMid) __attribute__((outputFormat(kCIFormatRh)))
const float MAX_VAL = 1.74;
const float THRESHOLD = 0.05;
vec2 dc = destCoord();
vec2 sc;
sc = dc + vec2(-1,-1);
vec4 pMax00 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin00 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,0);
vec4 pMax01 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin01 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,1);
vec4 pMax02 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin02 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(0,-1);
vec4 pMax10 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin10 = sample(imageMin, samplerTransform(imageMin, sc));
vec4 pMax11 = sample(imageMax, samplerTransform(imageMax, dc));
vec4 pMin11 = sample(imageMin, samplerTransform(imageMin, dc));
sc = dc + vec2(0,1);
vec4 pMax12 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin12 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,-1);
vec4 pMax20 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin20 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,0);
vec4 pMax21 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin21 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,1);
vec4 pMax22 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin22 = sample(imageMin, samplerTransform(imageMin, sc));
float minDevCMaxNMin = distance(pMax11, pMin00);
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin01) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin02) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin10) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin11) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin12) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin20) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin21) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin22) );
float minDevCMinNMax = distance(pMin11, pMax00);
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax01) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax02) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax10) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax11) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax12) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax20) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax21) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax22) );
float outVal = min(minDevCMaxNMin , minDevCMinNMax) / MAX_VAL;
outVal = 1.0f / (1.0f + exp(-logisticGain*(outVal - logisticMid)));
vec4 outPixel = vec4(outVal, outVal, outVal, 1.0);
return outPixel;
kernel vec4 jointbilateralfilter(sampler mask, sampler guide, vec2 rad, vec3 sig) __attribute__((outputFormat(kCIFormatRh)))
vec2 coord = destCoord();
float rh = rad.x;
float rv = rad.y;
vec4 p0 = sample(mask, samplerTransform(mask, coord));
vec4 g0 = sample(guide, samplerTransform(guide, coord));
vec4 result = vec4(0.0f);
float w_sum = 0.0f;
for(float yo=-rad.y;  yo<=rad.y;  yo++) {
for(float xo=-rad.x;  xo<=rad.x;  xo++) {
vec2 dc = vec2(xo, yo);
vec4 p = sample(mask, samplerTransform(mask, coord + dc));
vec4 g = sample(guide, samplerTransform(guide, coord + dc));
float d = dot(dc, dc);
float pdif = dot(p-p0,p-p0);
float gdif = dot(g-g0,g-g0);
float w = exp(dot(sig, vec3(d,pdif,gdif)));
result += w*p;
w_sum += w;
result /= w_sum;
return vec4(result.rgb, 1.0);
kernel vec4 rgba_to_luma(__sample rgb)
const vec4 rgb2y = vec4(0.2999,0.5870,0.1140,0.0);
float luma = dot(rgb, rgb2y);
return vec4(luma, luma, luma, 1.0);
kernel vec2 warp_homography(vec3 h012, vec3 h345, vec3 h678)
vec3 coord = vec3(destCoord(), 1.f);
float norm = 1.f / dot(h678, coord);
float x = norm * dot(h012, coord);
float y = norm * dot(h345, coord);
return vec2(x,y);
kernel vec4 ncc_compute(sampler img1, sampler img2) __attribute__((outputFormat(kCIFormatR8)))
vec2 coord = destCoord();
float sum1   = float(0.0);
float sum2   = float(0.0);
float sumSq1 = float(0.0);
float sumSq2 = float(0.0);
float sumCrs = float(0.0);
float ncc;
float p1, p2;
const int halfKernel = 3;
const vec4 meanOp = vec4(1.0/3.0, 1.0/3.0, 1.0/3.0, 0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
p1 = dot(meanOp, sample(img1, samplerTransform(img1, coord + vec2(x, y))));
p2 = dot(meanOp, sample(img2, samplerTransform(img2, coord + vec2(x, y))));
sum1 += p1;
sum2 += p2;
sumSq1 += p1*p1;
sumSq2 += p2*p2;
sumCrs += p1*p2;
count += 1.0;
float denom = (sumSq1-sum1*sum1/count) * (sumSq2-sum2*sum2/count);
ncc = compare(denom, 0.0, ((sumCrs-(sum1*sum2/count)))/sqrt(denom));
ncc = max(ncc, 0.0);
return vec4(ncc, ncc, ncc, 1.0);
kernel vec4 ncc_coarse_compute(__sample ncc, vec2 edge) __attribute__((outputFormat(kCIFormatR8)))
float value = smoothstep(edge.x, edge.y, ncc.r);
return vec4(value, value, value, 1.0);
kernel vec4 blur_image_compute_5x5(sampler img)
const int halfKernel = 2;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_7x7(sampler img)
const int halfKernel = 3;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 fuse_image_compute(sampler refImg, sampler guideImg, sampler blurImg, sampler weightImg, sampler maskImg)
vec4 ref       = sample(refImg, samplerCoord(refImg));
vec4 refBlur   = ref;
vec4 guide     = sample(guideImg, samplerCoord(guideImg));
vec4 guideBlur = sample(blurImg, samplerCoord(blurImg));
float weight   = sample(weightImg, samplerCoord(weightImg)).r;
float mask     = sample(maskImg, samplerCoord(maskImg)).r;
vec3 CbCoef = vec3(-0.1726, -0.3391, 0.5117);
vec3 CrCoef = vec3(0.5115, -0.4282, -0.0830);
float CbRef   = dot(CbCoef, ref.rgb);
float CbGuide = dot(CbCoef, guideBlur.rgb);
float CrRef   = dot(CrCoef, ref.rgb);
float CrGuide = dot(CrCoef, guideBlur.rgb);
float crDiff = smoothstep(0.0, 0.2, abs(CbRef-CbGuide));
float cbDiff = smoothstep(0.0, 0.2, abs(CrRef-CrGuide));
float chDiff = smoothstep(0.0,0.3,crDiff+cbDiff);
float weight1 = (1.0-smoothstep(0.0,0.6,mask));
weight *= weight1 * (1.0-chDiff);
vec4 value = mix(ref, (0.9*(guide-guideBlur)+refBlur), weight);
return value;
jointbilateralfilter
rgba_to_luma
warp_homography
ncc_compute
ncc_coarse_compute
blur_image_compute_7x7
blur_image_compute_5x5
fuse_image_compute
CIPhotoEffectMono
Mono
CIPhotoEffectTonal
Tonal
CIPhotoEffectNoir
Noir
CIPhotoEffectFade
Fade
CIPhotoEffectChrome
Chrome
CIPhotoEffectProcess
Process
CIPhotoEffectTransfer
Transfer
CIPhotoEffectInstant
Instant
CIPhotoEffect3DVivid
3DVivid
CIPhotoEffect3DVividWarm
3DVividWarm
CIPhotoEffect3DVividCool
3DVividCool
CIPhotoEffect3DDramatic
3DDramatic
CIPhotoEffect3DDramaticWarm
3DDramaticWarm
CIPhotoEffect3DDramaticCool
3DDramaticCool
CIPhotoEffect3DSilverplate
3DSilverplate
CIPhotoEffect3DNoir
3DNoir
fileURL != nil
+[PIPhotoEditHelper imageSourceWithURL:type:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Util/PIPhotoEditHelper.m
+[PIPhotoEditHelper imageSourceWithURL:type:proxyImage:orientation:]
image != nil
NUOrientationIsValid(orientation)
+[PIPhotoEditHelper imageSourceWithCIImage:orientation:]
+[PIPhotoEditHelper videoSourceWithURL:]
photoSource != nil
+[PIPhotoEditHelper livePhotoSourceWithPhotoSource:videoSource:]
videoSource != nil
%@+%@
Expected multiple source definition instead of %@
name != nil
+[PIPhotoEditHelper newAdjustmentWithName:]
+[PIPhotoEditHelper newImageRenderClientWithName:]
+[PIPhotoEditHelper newImagePropertiesClientWithName:]
+[PIPhotoEditHelper newImageExportClientWithName:]
+[PIPhotoEditHelper newVideoPropertiesClientWithName:]
+[PIPhotoEditHelper newVideoExportClientWithName:]
targetSize.width > 0 && targetSize.height > 0
+[PIPhotoEditHelper imageRenderRequestWithComposition:fitInSize:wideGamut:]
+[PIPhotoEditHelper imageRenderRequestWithComposition:fillInSize:wideGamut:]
composition != nil
+[PIPhotoEditHelper _imageRenderRequestWithComposition:wideGamut:]
+[PIPhotoEditHelper videoRenderRequestWithComposition:fitInSize:wideGamut:]
LOOP
v32@?0@"NSString"8@"NSString"16^B24
/pre-Crop
kernel vec4 forwardBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k) - k;
vec3 neg = min(im.rgb, 0.0);
neg *= 2.8;
im.rgb = clamp(im.rgb, 0.0, k);
im.rgb = ((1.0+n)*im.rgb)/(1.0+(n*im.rgb)) + neg;
im.r = pos.r > 0.0 ? (.91803 + .470304*pos.r) : im.r;
im.g = pos.g > 0.0 ? (.91803 + .470304*pos.g) : im.g;
im.b = pos.b > 0.0 ? (.91803 + .470304*pos.b) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
kernel vec4 inverseBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k);
vec3 neg = min(im.rgb, 0.0);
im.rgb = clamp(im.rgb, 0.0, k);
neg *= .35714286;
im.rgb = im.rgb/(n+1.0-(im.rgb*n)) + neg;
im.r = pos.r > 0.8 ? k + 2.126286*(pos.r-.91803) : im.r;
im.g = pos.g > 0.8 ? k + 2.126286*(pos.g-.91803) : im.g;
im.b = pos.b > 0.8 ? k + 2.126286*(pos.b-.91803) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
boost kernel is nil
+[PIForwardFakeBoost kernel]_block_invoke
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIFakeBoost.m
-[PIForwardFakeBoost outputImage]
inputBoost
Td,V_inputBoost
inverse boost kernel is nil
+[PIInverseFakeBoost kernel]_block_invoke
-[PIInverseFakeBoost outputImage]
PI_LONG_EXPOSURE_DUMP_INTERMEDIATES
-[PILongExposureExportJob prepare:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoopJob+LongExposure.m
Malformed AutoLoop recipe : crop
-[PILongExposureExportJob render:]
auto loop variations not supported
-[PILongExposureExportJob _exportOutputImage:format:colorSpace:toURL:uti:error:]
destinationURL != nil
Failed to finalize image destination
Failed to create CGImageDestinationRef
Failed to create CGImageRef
videoAsset
T@"AVAsset",&,N,V_videoAsset
videoCleanAperture
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_videoCleanAperture
stabilizationCrop
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_stabilizationCrop
videoGeometry
T@"NUImageGeometry",&,N,V_videoGeometry
imageGeometry
T@"NUImageGeometry",&,N,V_imageGeometry
observation
T@"VNImageHomographicAlignmentObservation",R,C
T{?={?=qq}{?=qq}},R,N
T@"VNImageHomographicAlignmentObservation",C,N,V_observation
T{?={?=qq}{?=qq}},N,V_extent
/AutoLoop/LongExposure
-[PILongExposureRegistrationJob prepare:]
return Source(composition.source, {'skipOrientation':true});
-[PILongExposureRegistrationJob render:]
Failed to allocate intermediate pixel buffer
Failed to render luma
Image registration failure
Image registration failure (expected 1 observation)
guideExtent
T{?={?=qq}{?=qq}},N,V_guideExtent
stillImage
T@"CIImage",&,N,V_stillImage
T@"VNImageHomographicAlignmentObservation",&,N,V_observation
/RAW/SushiLevel1
CIRedEyeCorrections
inputCorrectionInfo
inputCameraModel
CIRedEyeCorrection
CILanczosScaleTransform
inputScale
inputDestinationImage
T@"CIImage",&,N,V_inputDestinationImage
T@"NSArray",&,N,V_inputCorrectionInfo
T@"NSString",&,N,V_inputCameraModel
Buffer must be RGBA16 type for red eye repairs
id<NUBuffer> computeRepairMask(__strong id<NUBuffer>, uint16_t *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIApertureRedEye.mm
reddestx out of bounds
void seedFill(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, const uint32_t, const NSInteger, const NSInteger)
reddesty out of bounds
maskBuffer != nil
void applyRepairMask(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, double, const uint32_t)
repairBuffer != nil
kernel vec4 curveRGB_uint16(sampler src, __table sampler curveData, float maxValue, float tableSize)
vec4 pixel = unpremultiply(sample(src, samplerCoord(src)));
vec3 rgbi, rgbf, rgb0, rgb1;
float scale = tableSize / maxValue;
pixel.rgb = pixel.rgb * scale;
rgbi = floor(clamp(pixel.rgb, 0.0, maxValue * scale - 2.0));
rgbf = pixel.rgb - rgbi;
rgbi += 0.5;
rgb0.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).r;
rgb0.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).g;
rgb0.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).b;
rgbi += 1.0;
rgb1.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).r;
rgb1.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).g;
rgb1.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).b;
rgb0.rgb = rgb0.rgb * 4.0 - 1.0;
rgb0.rgb = rgb0.rgb * abs(rgb0.rgb);
rgb1.rgb = rgb1.rgb * 4.0 - 1.0;
rgb1.rgb = rgb1.rgb * abs(rgb1.rgb);
pixel.rgb = mix(rgb0, rgb1, rgbf);
pixel.rgb = pixel.rgb * scale;
rgbi = floor(clamp(pixel.rgb, 0.0, maxValue * scale - 2.0));
rgbf = pixel.rgb - rgbi;
rgbi += 0.5;
rgb0.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).a;
rgb0.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).a;
rgb0.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).a;
rgbi += 1.0;
rgb1.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).a;
rgb1.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).a;
rgb1.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).a;
rgb0.rgb = rgb0.rgb * 4.0 - 1.0;
rgb0.rgb = rgb0.rgb * abs(rgb0.rgb);
rgb1.rgb = rgb1.rgb * 4.0 - 1.0;
rgb1.rgb = rgb1.rgb * abs(rgb1.rgb);
pixel.rgb = mix(rgb0, rgb1, rgbf);
return premultiply(pixel);
kernel vec4 curveLuminance_uint16(sampler src, __table sampler curveData, float maxValue, float tableSize) __attribute__ ((preserves_opacity))
vec4 pixel = unpremultiply(sample(src, samplerCoord(src)));
vec3 rgbi, rgbf, rgb0, rgb1;
float scale = tableSize / maxValue;
pixel.rgb = pixel.rgb * scale;
rgbi = floor(clamp(pixel.rgb, 0.0, maxValue * scale - 2.0));
rgbf = pixel.rgb - rgbi;
rgbi += 0.5;
rgb0.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).r;
rgb0.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).g;
rgb0.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).b;
rgbi += 1.0;
rgb1.r = sample(curveData, samplerTransform(curveData, vec2(rgbi.r, 0.5))).r;
rgb1.g = sample(curveData, samplerTransform(curveData, vec2(rgbi.g, 0.5))).g;
rgb1.b = sample(curveData, samplerTransform(curveData, vec2(rgbi.b, 0.5))).b;
rgb0.rgb = rgb0.rgb * 4.0 - 1.0;
rgb0.rgb = rgb0.rgb * abs(rgb0.rgb);
rgb1.rgb = rgb1.rgb * 4.0 - 1.0;
rgb1.rgb = rgb1.rgb * abs(rgb1.rgb);
pixel.rgb = mix(rgb0, rgb1, rgbf);
float lum = pixel.r * 0.3 + pixel.g * 0.59 + pixel.b * 0.11;
float val = lum * scale;
float vali = floor(clamp(val, 0.0, maxValue * scale - 2.0));
float valf = val - vali;
vali += 0.5;
float val0 = sample(curveData, samplerTransform(curveData, vec2(vali      , 0.5))).a;
float val1 = sample(curveData, samplerTransform(curveData, vec2(vali + 1.0, 0.5))).a;
val0 = val0 * 4.0 - 1.0;
val0 = val0 * abs(val0);
val1 = val1 * 4.0 - 1.0;
val1 = val1 * abs(val1);
float curveVal = mix(val0, val1, valf);
float ccval = clamp(curveVal, -8.0 * abs(lum), 8.0 * abs(lum));
float add = curveVal - ccval;
pixel.rgb = (lum == 0.0 ? vec3(0.0) : pixel.rgb * (ccval / lum)) + vec3(add);
return premultiply(pixel);
curveRGB_uint16
curveLuminance_uint16
com.apple.photo.PhotoImaging
Couldn't find bundle for class %@
+[NUJSRenderPipeline(PhotosPipeline) newPhotosPipeline:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIPhotosPipeline.m
PhotosPipeline
Couldn't find the specified Pipeline
PIAutoLoopExportJob
-[PIAutoLoopExportJob initWithExportRequest:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoopJob.m
-[PIAutoLoopExportJob evaluateOutputGeometry:]
-[PIAutoLoopExportJob prepare:]
-[PIAutoLoopExportJob render:]
-[PIAutoLoopExportJob complete:]
Failed to render autoloop in good time
Autoloop failure
data
T@"NSMutableData",&,Vdata
elementByteSize
TQ,R,VelementByteSize
rowElements
TQ,R,VrowElements
TQ,R,Vwidth
TQ,R,Vheight
format
Ti,R,Vformat
inputHue
inputStrength
inputNeutralGamma
inputTone
-[PISmartBlackAndWhiteAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PISmartBlackAndWhiteAutoCalculator.mm
Produced invalid BlackAndWhite settings, using defaults
void calculate_bw_auto_matrix_lum_contrast(__strong id<NUBuffer>, CGColorSpaceRef, MsgBlackAndWhiteSettings *)
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
xi < width && yi < height
const MsgPixel<ChannelType> MsgTypedBufferAccessor<float, 0, 1, 2, 3>::operator()(size_t, size_t) const [ChannelType = float, rOffset = 0, gOffset = 1, bOffset = 2, alphaOffset = 3]
num == w
void MsgMatrix<double>::AppendRow(const NumberType *, uint) [MatrixFloatType = double, NumberType = double]
xi < w && yi < h
MatrixFloatType &MsgMatrix<double>::operator()(size_t, size_t) [MatrixFloatType = double]
index < data.size()
-[PILevelsAutoAbstractCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PILevelsAutoCalculator.m
pre-Levels
This is an abstract method! Subclass '%@' should provide concrete implementation
-[PILevelsAutoAbstractCalculator calculateSettingsForImageHistogram:]
blackSrc
blackDst
shadowSrc
shadowDst
midSrc
midDst
hilightSrc
hilightDst
whiteSrc
whiteDst
Green
Blue
PI_LONG_EXPOSURE_FUSION_PARAMS
@"NSString"8@?0
kNCCBlurHalfSize
kNCCEdge0
kNCCEdge1
kBlendMaskThreshold0
kBlendMaskThreshold1
/tmp/long-exp-input-image.tiff
/tmp/long-exp-mask-image.tiff
/tmp/long-exp-still-image.tiff
/tmp/long-exp-guide-image.tiff
/tmp/long-exp-ncc-map-image.tiff
/tmp/long-exp-refined-mask-image.tiff
/tmp/long-exp-fusion-image.tiff
inputStillImage
T@"CIImage",&,N,V_inputStillImage
inputRenderScale
T@"NSNumber",&,N,V_inputRenderScale
inputVideoScale
T@"NSNumber",&,N,V_inputVideoScale
inputAlignmentExtent
T@"CIVector",&,N,V_inputAlignmentExtent
inputAlignmentTransform
T@"CIVector",&,N,V_inputAlignmentTransform
kernel vec4 levelsNewGammaForP3 (sampler src, sampler LUT)
vec4
p,r;
vec2
c1,c2;
float
p  = sample(src, samplerCoord(src));
vec3 neg = min(p.rgb, 0.0);
vec3 pos = max(p.rgb, 1.0)-1.0;
p.rgb = clamp(p.rgb, 0.0, 1.0);
f = p.r * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.r = r.r * 4.0 - 1.0;
f = p.g * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.g = r.g * 4.0 - 1.0;
f = p.b * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.b = r.b * 4.0 - 1.0;
p.rgb = max(p.rgb, 0.0);
p.rgb = p.rgb + pos + neg;
return p;
inputBlackSrc
inputBlackDst
inputShadowSrc
inputShadowDst
inputMidSrc
inputMidDst
inputHilightSrc
inputHilightDst
inputWhiteSrc
inputWhiteDst
inputBlackSrcRGB
inputBlackDstRGB
inputShadowSrcRGB
inputShadowDstRGB
inputMidSrcRGB
inputMidDstRGB
inputHilightSrcRGB
inputHilightDstRGB
inputWhiteSrcRGB
inputWhiteDstRGB
inputBlackSrcRed
inputBlackDstRed
inputShadowSrcRed
inputShadowDstRed
inputMidSrcRed
inputMidDstRed
inputHilightSrcRed
inputHilightDstRed
inputWhiteSrcRed
inputWhiteDstRed
inputBlackSrcGreen
inputBlackDstGreen
inputShadowSrcGreen
inputShadowDstGreen
inputMidSrcGreen
inputMidDstGreen
inputHilightSrcGreen
inputHilightDstGreen
inputWhiteSrcGreen
inputWhiteDstGreen
inputBlackSrcBlue
inputBlackDstBlue
inputShadowSrcBlue
inputShadowDstBlue
inputMidSrcBlue
inputMidDstBlue
inputHilightSrcBlue
inputHilightDstBlue
inputWhiteSrcBlue
inputWhiteDstBlue
Failed converting data to RGBAh: %ld
-[PILevelsFilter _LUTImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PILevelsFilter.m
T@"NSNumber",&,N,V_inputBlackSrcRGB
T@"NSNumber",&,N,V_inputBlackDstRGB
T@"NSNumber",&,N,V_inputShadowSrcRGB
T@"NSNumber",&,N,V_inputShadowDstRGB
T@"NSNumber",&,N,V_inputMidSrcRGB
T@"NSNumber",&,N,V_inputMidDstRGB
T@"NSNumber",&,N,V_inputHilightSrcRGB
T@"NSNumber",&,N,V_inputHilightDstRGB
T@"NSNumber",&,N,V_inputWhiteSrcRGB
T@"NSNumber",&,N,V_inputWhiteDstRGB
T@"NSNumber",&,N,V_inputBlackSrcRed
T@"NSNumber",&,N,V_inputBlackDstRed
T@"NSNumber",&,N,V_inputShadowSrcRed
T@"NSNumber",&,N,V_inputShadowDstRed
T@"NSNumber",&,N,V_inputMidSrcRed
T@"NSNumber",&,N,V_inputMidDstRed
T@"NSNumber",&,N,V_inputHilightSrcRed
T@"NSNumber",&,N,V_inputHilightDstRed
T@"NSNumber",&,N,V_inputWhiteSrcRed
T@"NSNumber",&,N,V_inputWhiteDstRed
T@"NSNumber",&,N,V_inputBlackSrcGreen
T@"NSNumber",&,N,V_inputBlackDstGreen
T@"NSNumber",&,N,V_inputShadowSrcGreen
T@"NSNumber",&,N,V_inputShadowDstGreen
T@"NSNumber",&,N,V_inputMidSrcGreen
T@"NSNumber",&,N,V_inputMidDstGreen
T@"NSNumber",&,N,V_inputHilightSrcGreen
T@"NSNumber",&,N,V_inputHilightDstGreen
T@"NSNumber",&,N,V_inputWhiteSrcGreen
T@"NSNumber",&,N,V_inputWhiteDstGreen
T@"NSNumber",&,N,V_inputBlackSrcBlue
T@"NSNumber",&,N,V_inputBlackDstBlue
T@"NSNumber",&,N,V_inputShadowSrcBlue
T@"NSNumber",&,N,V_inputShadowDstBlue
T@"NSNumber",&,N,V_inputMidSrcBlue
T@"NSNumber",&,N,V_inputMidDstBlue
T@"NSNumber",&,N,V_inputHilightSrcBlue
T@"NSNumber",&,N,V_inputHilightDstBlue
T@"NSNumber",&,N,V_inputWhiteSrcBlue
T@"NSNumber",&,N,V_inputWhiteDstBlue
inputColorSpace
T@"NSString",&,N,V_inputColorSpace
Mirror
Adjustment
identifier
RAW~1.0
settings
inputDecoderVersion
opaque
inputSushiLevel
required
Failed to register schema %@: %@
+[PISchema rawSchema]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PISchema.m
RawNoiseReduction~1.0
bool
luminance
number
minimum
maximum
detail
sharpness
contrast
+[PISchema rawNoiseReductionSchema]
SmartTone~1.0
inputLight
inputBlack
inputBrightness
inputContrast
inputExposure
inputHighlights
inputRawHighlights
inputShadows
offsetBlack
offsetBrightness
offsetContrast
offsetExposure
offsetHighlights
offsetLocalLight
offsetShadows
inputLocalLight
+[PISchema smartToneSchema]
SmartColor~1.0
inputColor
inputSaturation
offsetSaturation
inputCast
offsetCast
+[PISchema smartColorSchema]
SmartBlackAndWhite~1.0
strength
neutral
tone
grain
+[PISchema smartBlackAndWhiteSchema]
Sharpen~1.0
falloff
edges
intensity
+[PISchema sharpenSchema]
CropStraighten~1.0
xOrigin
yOrigin
constraintWidth
constraintHeight
angle
+[PISchema cropSchema]
Trim~1.0
start
scale
+[PISchema trimSchema]
LivePhotoKeyFrame~1.0
time
+[PISchema livePhotoKeyFrameSchema]
Mute~1.0
+[PISchema muteSchema]
AutoLoop~1.0
enum
values
+[PISchema autoLoopSchema]
HighResolutionFusion~1.0
alignment
+[PISchema highResFusionSchema]
DepthEffect~1.0
depthInfo
+[PISchema depthEffectSchema]
Effect3D~1.0
kind
version
+[PISchema effect3DSchema]
Effect
+[PISchema effectSchema]
RedEye
iPhone
+[PISchema redEyeSchema]
ApertureRedEye
array
content
compound
properties
pointX
pointY
radius
sensitivity
+[PISchema apertureRedEyeSchema]
Retouch
inputStrokes
mode
Repair
Clone
softness
opacity
repairEdges
default
sourceOffset
points
pressure
+[PISchema retouchSchema]
Vignette
+[PISchema vignetteSchema]
Orientation~1.0
value
+[PISchema orientationSchema]
Definition
+[PISchema definitionSchema]
NoiseReduction
edgeDetail
+[PISchema noiseReductionSchema]
WhiteBalance
grayStrength
grayWarmth
grayY
grayI
grayQ
+[PISchema whiteBalanceSchema]
Levels
colorSpace
Adobe RGB
sRGB
Display P3
blackSrcRGB
blackDstRGB
shadowSrcRGB
shadowDstRGB
midSrcRGB
midDstRGB
hilightSrcRGB
hilightDstRGB
whiteSrcRGB
whiteDstRGB
blackSrcRed
blackDstRed
shadowSrcRed
shadowDstRed
midSrcRed
midDstRed
hilightSrcRed
hilightDstRed
whiteSrcRed
whiteDstRed
blackSrcGreen
blackDstGreen
shadowSrcGreen
shadowDstGreen
midSrcGreen
midDstGreen
hilightSrcGreen
hilightDstGreen
whiteSrcGreen
whiteDstGreen
blackSrcBlue
blackDstBlue
shadowSrcBlue
shadowDstBlue
midSrcBlue
midDstBlue
hilightSrcBlue
hilightDstBlue
whiteSrcBlue
whiteDstBlue
+[PISchema levelsSchema]
Curves
inputRGBData
inputRedData
inputGreenData
inputBlueData
inputGrayChoice
+[PISchema curvesSchema]
SelectiveColor
corrections
green
blue
spread
hueShift
saturation
+[PISchema selectiveColorSchema]
Composition
PhotosComposition
contents
rawNoiseReduction
source
com.apple.photo:Source~1.0
reference
retouch
Retouch~1.0
whiteBalance
WhiteBalance~1.0
redEye
RedEye~1.0
apertureRedEye
ApertureRedEye~1.0
smartTone
smartColor
smartBlackAndWhite
sharpen
definition
Definition~1.0
effect
Effect~1.0
cropStraighten
trim
livePhotoKeyFrame
highResFusion
mute
vignette
Vignette~1.0
orientation
noiseReduction
NoiseReduction~1.0
levels
Levels~1.0
curves
Curves~1.0
selectiveColor
SelectiveColor~1.0
depthEffect
effect3D
+[PISchema photosCompositionSchema]
failed to register %@: %@
+[PISchema registerPhotosSchema]
failed to construct photos pipeline %@
T@"NUIdentifier",R
-[PICropAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PICropAutoCalculator.m
CIAutoStraighten
straightenAngleInDegreesCCW
autoCrop
kernel vec4 iptLumHueSatTable(sampler image, __table sampler hueSatLumTable)
vec4 im = sample(image, samplerCoord(image)) ;
vec4 result = im;
float hueIdx = 359.0 * 0.5 * (atan(im.b, im.g)/3.1416 + 1.0);
hueIdx = clamp(hueIdx, 0.0, 359.0) + 0.5;
float hueChange = (sample(hueSatLumTable, vec2(hueIdx,0.5)).r);
float satChange = (sample(hueSatLumTable, vec2(hueIdx,0.5)).g);
float lumChange = (sample(hueSatLumTable, vec2(hueIdx,0.5)).b);
float chroma = sqrt(im.g*im.g+im.b*im.b) ;
chroma *= satChange ;
float hue = atan(im.b, im.g) + hueChange ;
vec3 adjustIm = im.rgb;
float hueAngle = hue  ;
lumChange = mix(1.0, lumChange, chroma);
adjustIm.r *= lumChange;
adjustIm.g = chroma * cos(hueAngle) ;
adjustIm.b = chroma * sin(hueAngle) ;
result.rgb = mix(im.rgb, adjustIm.rgb, 1.0) ;
result.rgb = adjustIm.rgb;
result.a = im.a ;
return result ;
kernel vec4 srgbToIPT(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, ipt;
lms = im.r * vec3(0.3139902162, 0.155372406, 0.017752387) +
im.g * vec3(0.6395129383, 0.7578944616, 0.109442094) +
im.b * vec3(0.0464975462, 0.0867014186, 0.8725692246);
lms = sign(lms)*pow(abs(lms), vec3(0.43, 0.43, 0.43));
ipt = lms.r * vec3(0.4, 4.455, 0.8056) +
lms.g * vec3(0.4, -4.851, 0.3572) +
lms.b * vec3(0.2, 0.3960, -1.1628);
return vec4(ipt, im.a);
kernel vec4 iptToSRGB(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, rgb;
lms = im.rrr +
im.g * vec3(0.09756893,-0.11387649,0.03261511) +
im.b * vec3(0.20522644, 0.13321716,  -0.67688718);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
rgb = lms.r * vec3( 5.472212058380287,  -1.125241895533569,   0.029801651173470) +
lms.g * vec3(-4.641960098354470, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974,  -0.167895202223709, 1.163647892783812);
return vec4(rgb, im.a);
kernel vec4 add_gaussian(sampler srcTable, float tableSize, float hueAmplitude, float satAmplitude, float lumAmplitude, float gaussX, float gaussSigmaSquared) {
vec2 d = destCoord();
vec4 src = sample(srcTable, samplerCoord(srcTable));
float x = d.x / (tableSize - 1.0);
float dist = min(min(abs(x - gaussX), abs(x - 1.0 - gaussX)), abs(x + 1.0 - gaussX));
float p = -((dist * dist) / (2.0 * gaussSigmaSquared));
float ep = exp(p);
float hue = hueAmplitude * ep;
float sat = satAmplitude * ep;
float lum = lumAmplitude * ep;
float h = clamp(src.r + hue, -1.0, 1.0);
float s = clamp(src.g + sat, -1.0, 1.0);
float l = clamp(src.b + lum, -1.0, 1.0);
return vec4(h,s,l,1.0);
srgbToIPT
iptToSRGB
CIConstantColorGenerator
add_gaussian
CIAdditionCompositing
inputBackgroundImage
iptLumHueSatTable
inputCorrections
T@"NSArray",&,N,V_inputCorrections
kernel vec4 convertFromRGBToYIQ(sampler src, float gamma)
vec4 pix ;
vec3 pix2;
pix = sample(src, samplerCoord(src));
pix.rgb = sign(pix.rgb)*pow(abs(pix.rgb), vec3(1.0/gamma)) ;
pix2.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
return vec4(pix2, pix.a);
kernel vec4 convertFromYIQToRGB(sampler src, float gamma)
vec4 color, pix;
pix = sample(src, samplerCoord(src));
color.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
color.rgb = sign(color.rgb)*pow(abs(color.rgb), vec3(gamma, gamma, gamma) );
color.a = pix.a;
return color;
kernel vec4 whiteBalance(sampler image, float grayY, float grayI, float grayQ, float strength)
vec4 im = sample(image, samplerCoord(image)) ;
vec2 grayOffset = vec2(grayI, grayQ) ;
vec4 result ;
float newStrength = 1.0 + (strength-1.0)*(1.0-im.r) ;
result.r = im.r ;
result.gb = im.gb + newStrength*grayOffset ;
float damp = max(min(1.0, im.r/(grayY+0.00001)),0.0) ;
result.rgb = mix(im.rgb, result.rgb, damp) ;
result.a = im.a ;
return result ;
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
warmth
convertFromRGBToYIQ
convertFromYIQToRGB
gHDRtoPP
PPtogHDR
-[PINeutralGrayWhiteBalanceFilter outputImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PINeutralGrayWhiteBalanceFilter.m
T@"NSNumber",&,N,V_strength
T@"NSNumber",&,N,V_warmth
T@"NSNumber",&,N,V_y
T@"NSNumber",&,N,V_i
T@"NSNumber",&,N,V_q
-[PISmartToneAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PIAutoCalculators.mm
PISmartToneAutoCalculator
CISmartTone
pre-Adjustments
CILocalLight
-[PISmartColorAutoCalculator calculate:]
CISmartColor
-[PIRedEyeAutoCalculator calculate:]
CIAutoRedEye
locationX
locationY
touchDiameter
+[PIImageIO writeImage:fileURL:fileType:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Util/PIImageIO.m
cgImage != NULL
+[PIImageIO writeCGImage:fileURL:fileType:]
fileType != nil
Unhandled bit depth: %ld
+[PIImageIO writeCGImage:fileURL:fileType:options:]
Successfully wrote image to file %@
Failed to write image to file %@
%@-%d-%ld.tiff
tiff
GU %@ %@
Sensitivity
Bad float to fixed 16 conversion
+[PIApertureRedEyeProcessorKernel convertFloat:toFixed16:count:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIApertureRedEyeFilter.mm
Bad fixed 16 to float conversion
+[PIApertureRedEyeProcessorKernel convertFixed16:toFloat:count:]
inputSensitivity
CISourceOverCompositing
portraitInfo
Regions
-[PIPortraitAutoCalculator calculate:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Autocalculators/PIPortraitAutoCalculator.m
PIPortraitAutoCalculator face detection
PIPortraitAutoCalculator image properties
faceObservations != nil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromFaceObservations:metadata:orientation:]
metadata != nil
leftEyeX
leftEyeY
rightEyeX
rightEyeY
noseX
noseY
Insufficient number of landmark points
+[PIPortraitAutoCalculator depthEffectInfoDictionaryFromFaceObservations:focus:aperture:lumaNoiseScale:orientation:]
chinX
chinY
aperture
lumaNoiseScale
focusRect
faces
+[PIPortraitAutoCalculator portraitEffectInfoDictionaryFromFaceObservations:orientation:]
faceBoundingBox
faceJunkinessIndex
faceOrientationIndex
allPoints
faceContour
leftEye
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
faceLandmarks
+[PIPortraitAutoCalculator portraitInfoDictionaryFromCameraMetadata:]
var sourceSettings = {  }; 
var sourceSettings = { 'skipOrientation' : true }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
return Source(composition.source, sourceSettings); 
var source = GetTag('/ShowOriginalSource');ResetTagInput('/pre-Geometry', source);
return GetTag('/post-Geometry');
Could not construct stopAtTagPipeline from inline source
+[PIPipelineFilters originalWithGeometry]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/Adjustments/PIPipelineFilters.m
var source = GetTag('/pre-RedEye');ResetTagInput('/post-RedEye', source);
return GetTag('/post-RedEye');
Could not construct noRedEye filter from inline source
+[PIPipelineFilters noRedEyeFilter]
var preTrim = GetTag('pre-Trim');ResetTagInput('Trim', preTrim);
return GetTag('Image');
Could not construct noTrimFilter filter from inline source
+[PIPipelineFilters noTrimFilter]
var preMute = GetTag('pre-Mute');ResetTagInput('Mute', preMute);
return GetTag('Image');
Could not construct noMuteFilter filter from inline source
+[PIPipelineFilters noMuteFilter]
var preCrop = GetTag('/pre-Crop');ResetTagInput('/pre-Orientation', preCrop);
return GetTag('post-Geometry');
Could not construct noCropFilter filter from inline source
+[PIPipelineFilters noCropFilter]
/pre-Geometry
/post-Geometry
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Geometry', tagNode);
return GetTag('/post-Geometry');
+[PIPipelineFilters stopAtTagIncludeGeometryFilter:]
var output = input;
var orientation = composition.orientation;
if (orientation) {
    output = Orient(input, orientation.value);
return output;
Could not construct pipeline filter from source: %@
+[PIPipelineFilters applyOrientationFilter]
None
NSDictionary * _Nonnull PIAutoLoopRecipeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3202.4.209/PhotoImaging/AutoLoop/PIAutoLoop.m
CGRect PIAutoLoopRecipeGetCropRect(NSDictionary *__strong _Nonnull)
BOOL PIAutoLoopRecipeHasGoodStabilization(NSDictionary *__strong _Nonnull)
loopRecipe_stabilizeResult
frameTransform != nil
CMTime PIAutoLoopRecipeFrameTransformGetTime(NSDictionary *__strong)
matrix_float3x3 PIAutoLoopRecipeFrameTransformGetHomography(NSDictionary *__strong)
matrix_float3x3 PIAutoLoopRecipeGetHomographyAtTime(NSDictionary *__strong _Nonnull, CMTime, BOOL)
recipe != NULL
NUImageGeometry * _Nonnull PIAutoLoopRecipeComputeOutputGeometry(NSDictionary *__strong _Nonnull, NUOrientation, NUScale)
NUOrientationIsValid(videoOrientation)
NUScaleIsValid(videoScale)
NSDictionary * _Nonnull PIAutoLoopRecipeGetInstructionAtTime(NSDictionary *__strong _Nonnull, CMTime)
CMTIME_IS_VALID(time)
q24@?0@"NSDictionary"8@"NSDictionary"16
class
stringWithFormat:
callStackSymbols
componentsJoinedByString:
initWithComposition:destinationURL:
copy
globalSettings
boolSettingForKey:defaultValue:
flavor
alloc
initWithAutoLoopExportRequest:
copyWithZone:
submitGeneric:
initWithRequest:
initWithComposition:autoLoopRecipe:flavor:destinationURL:maskDestinationURL:destinationUTI:
newRenderJob
mediaComponentType
submit:
.cxx_destruct
metadata
setMetadata:
recipe
addAudio
setAddAudio:
destinationUTI
destinationMaskURL
_addAudio
_metadata
_recipe
_flavor
_destinationUTI
_destinationMaskURL
setGenericCompletionBlock:
submitGenericRequest:
setCompletionBlock:
submitRequest:
setFlavor:
setRecipe:
composition
mediaType
invalidError:object:
initWithError:
objectForKeyedSubscript:
boolValue
initWithResult:
result:
observation
warpTransform
initWithCapacity:
numberWithFloat:
addObject:
extent
numberWithInteger:
arrayWithObjects:count:
dictionaryWithObjects:forKeys:count:
calculate:
initWithComposition:
mutableCopy
init
setObject:forKeyedSubscript:
removeAssetIdentifierFromMetadataArray:
metadataItem
setIdentifier:
setValue:
identifier
isEqual:
indexOfObjectPassingTest:
removeObjectAtIndex:
addAssetIdentifier:toMetadataDictionary:
addAssetIdentifier:toMetadataArray:
filterWithName:
setValue:forKey:
setInputVectorsForFilter:
outputImage
vectorWithX:Y:Z:W:
inputImage
setInputImage:
temperature
setTemperature:
tint
setTint:
_inputImage
_temperature
_tint
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
statistics
oneToOneScalePolicy
request
prepare:
renderNode
missingError:object:
asset:
unsupportedError:object:
wantsOutputGeometry
wantsOutputVideo
wantsCompleteStage
scalePolicy
analysisRequest
render:
result
videoSource
setVideoSource:
_videoSource
initWithRequest:dataExtractor:options:
stopAtTagFilter:
setPipelineFilters:
initWithTargetPixelCount:
setScalePolicy:
setSampleMode:
data
count
initWithNoResult
valueWithBytes:objCType:
getValue:
gu_grayColorResultValue
gu_valueWithGrayColorResult:
RGBResultValue
valueWithRGBResult:
initWithName:
error
status
properties
rawProperties
initWithComposition:useSushi:
_chooseNeutralGrayForNonSushi:
calculateColorWithProperties:completion:
_chooseTempTintForSushi:RAWProperties:brightness:
submitPropertiesRequestForComposition:completion:
_correctedRGBResultFromResult:
_useTempTint:
numberWithDouble:
inputNeutralXYFromRGB:
objectAtIndexedSubscript:
doubleValue
_faceAutoCaculator
_imagePropertiesClient
_grayColor
_grayColorXY
_isRAW
initWithName:responseQueue:
validRegion
buffer
size
sharedFactory
bufferFactory
RGBAf
newStorageWithSize:format:
regionWithRect:
bytes
rowBytes
writeBufferInRegion:block:
returnStorage:
readBufferRegion:withBlock:
_brightnessMultiplierFromImageProperties:
begin
_computeGreenPercentage:
image
_submitGERenderRequest:
_submitGWRenderRequest:
rawCameraSpaceProperties
_whitePointColorFromGrayEdgesImage:grayWorldImage:greenChannelPercentage:RAWCameraSpaceProperties:
commitAndNotifyOnQueue:withBlock:
whiteValue
whiteFactor
_computeWhitePointColorWithGrayEdgesBuffer:grayWorldBuffer:greenChannelPercentage:RAWCameraSpaceProperties:
readBufferFromImage:withRGBAfBufferBlock:
RGBAh
setPixelFormat:
genericRGBLinearColorSpace
setColorSpace:
sourceFilterIncludingOrientation:
sushiLevel1Filter
initWithComposition:dataExtractor:options:
_configureRequest:
submitRequest:completion:
initWithSource:
initWithScript:
_composition
_bufferRenderClient
_imageDataClient
_useSushi
imageByCroppingToRect:
imageByApplyingTransform:
valueForKey:
inputMaskImage
setInputMaskImage:
inputOffset
setInputOffset:
_inputMaskImage
_inputOffset
kernelWithString:
imageByUnpremultiplyingAlpha
definitionKernel
applyWithExtent:arguments:
imageByPremultiplyingAlpha
inputBlurImage
setInputBlurImage:
inputIntensity
setInputIntensity:
_inputBlurImage
_inputIntensity
kernelsDictionaryWithString:
bilateralKernels
RGBToLabKernels
objectAtIndex:
boundsForPointArray:
enlargedBounds:withPoints:
shapeWithRect:
definition
unionWith:
bilateralAddROI:destRect:userInfo:
bilateralAdd1Kernel
applyWithExtent:roiCallback:arguments:
floatValue
vectorWithX:Y:
bilateralAdd2Kernel
vectorWithX:Y:Z:
bilateralAdd3Kernel
bilateralAdd4Kernel
bilateralAdd5Kernel
bilateralAdd6Kernel
bilateralAdd7Kernel
bilateralAdd8Kernel
bilateralAdd9Kernel
samplesPerPass
samplerWithImage:options:
RGBToLabKernel
subarrayWithRange:
doBilateralPass:points:weights:sums:slope:
bilateralFinalizeKernel
LabToRGBKernel
inputPoints
setInputPoints:
inputWeights
setInputWeights:
inputEdgeDetail
setInputEdgeDetail:
inputVersion
setInputVersion:
_inputPoints
_inputWeights
_inputEdgeDetail
_inputVersion
BWBilateralKernels
bilateralROI:destRect:userInfo:
bilateralLoop2Kernel
bilateralLoop5Kernel
bilateralLoop11Kernel
samplerWithImage:
doBilateralLoop:points:weights:slope:
inputBorder
setInputBorder:
_inputBorder
dictionaryWithObjectsAndKeys:
arrayWithCapacity:
customAttributes
inputRadius
setInputRadius:
_inputRadius
beginGroupWithName:error:
videoProperties:
orientation
outputImageGeometry:
initWithOrientation:input:
initWithInput:settings:
addTag:forNode:
initWithLongExposureInput:
endGroupWithName:error:
nodeWithInput:settings:pipelineState:error:
initWithInput:settings:subsampleFactor:
evaluationMode
setMediaComponentType:
setScale:
nodeByReplayingAgainstCache:pipelineState:error:
resolvedNodeWithCachedInputs:settings:pipelineState:error:
generatePersistentURLWithExtension:
URLByAppendingPathExtension:
initWithURL:UTI:
load:
resolveWithSourceNode:error:
persistentMaskURL
setResponseQueue:
resolveSourceWithResponse:
destinationURL
tryLoadPersistentURL:error:
inputNode
errorWithCode:reason:object:underlyingError:
renderScale
initWithExtent:renderScale:orientation:
descriptionSubClassHook
persistentURL
newRenderRequestWithOriginalRequest:persistentURL:
_evaluateImageGeometry:
longExposureNode
evaluateRenderDependenciesWithRequest:error:
isResolved
resolvedSourceNode:
errorWithCode:reason:object:
initWithSettings:inputs:
inputs
settings
time
videoFrames
setVideoFrames:
setTime:
pixelBuffer
nodeFromCache:cache:
setEvaluatedForMode:
_evaluateVideoProperties:
initWithProperties:
setLivePhotoKeyFrameTime:
outputVideo:
tracksWithMediaType:
firstObject
addMutableTrackWithMediaType:preferredTrackID:
countByEnumeratingWithState:objects:count:
insertTimeRange:ofTrack:atTime:error:
scaleTimeRange:toDuration:
timeRange
conformRange:inRange:
naturalTimeScale
setNaturalTimeScale:
outputVideoComposition:
instructions
setTimeRange:
trackID
numberWithInt:
setRequiredSourceTrackIDs:
setSourceIdentifier:forTrackID:
setFrameDuration:
setInstructions:
audioMix
audioMixInputParametersWithTrack:
setVolume:atTime:
setVolumeRampFromStartVolume:toEndVolume:timeRange:
setInputParameters:
shouldCacheNodeForPipelineState:
_evaluateVideo:
requiresVideoComposition
_evaluateVideoComposition:
requiresAudioMix
_evaluateAudioMix:
lastObject
outputImage:
_processImage:cleanRect:cropRect:transform:
alphaCompositingKernel
vectorWithCGPoint:
imageByApplyingFilter:withInputParameters:
_evaluateImage:
shortValue
longExposureFusionKernels
dynamismMapKernel
dynamismMapRefineKernel
rgbToLumaKernel
homographyKernel
nccKernel
nccCoarseKernel
blur7x7Kernel
blur5x5Kernel
fusionKernel
absoluteString
setAssetIdentifier:
initWithSourceDefinitions:
setResolvedSourceDefinition:
initWithCIImage:orientation:
UUID
UUIDString
assetIdentifier
resolvedSourceDefinition
initWithMultipleResolutionImageSourceDefinition:videoSourceDefinition:
registerPhotosSchema
initWithIdentifier:
_imageRenderRequestWithComposition:wideGamut:
initWithTargetSize:
setExtentPolicy:
setRegionPolicy:
displayP3ColorSpace
sRGBColorSpace
newCGImageFromBufferImage:
initWithLevel:
setOutputSettings:
setCompressionQuality:
initWithComposition:exportFormat:
setKey:
setKeySpace:
containsObject:
setDataType:
dataWithBytes:length:
allKeys
allValues
is3DEffect:
isEqualToString:
enumerateKeysAndObjectsUsingBlock:
initialize
imageSourceWithURL:type:
imageSourceWithURL:type:proxyImage:orientation:
imageSourceWithCIImage:orientation:
videoSourceWithURL:
livePhotoSourceWithPhotoSource:videoSource:
newComposition
newAdjustmentWithName:
newImageRenderClientWithName:
newImagePropertiesClientWithName:
newImageExportClientWithName:
newVideoPropertiesClientWithName:
newVideoExportClientWithName:
imageRenderRequestWithComposition:fitInSize:wideGamut:
imageRenderRequestWithComposition:fillInSize:wideGamut:
priorityWithLevel:
videoRenderRequestWithComposition:fitInSize:wideGamut:
videoExportRequestWithComposition:destinationURL:wideGamut:
newJPEGExportFormatWithCompressionQuality:
imageExportRequestWithComposition:format:wideGamut:
depthDataRenderRequestWithComposition:
addAutoLoopMetadataToMetadataArray:withKey:value:
effectNameForFilterName:
filterNameForEffectName:
pipelineFiltersForCropping
kernel
inputBoost
setInputBoost:
_inputBoost
kernelsWithString:
name
autoLoopExportRequest
sRGBLinearColorSpace
_debugDumpIntermediateImages
outputVideo
setVideoAsset:
videoAsset
cleanAperture
setVideoCleanAperture:
setVideoGeometry:
videoGeometry
setStabilizationCrop:
imageByClampingToExtent
renderer
context
createCGImage:fromRect:format:colorSpace:deferred:
failureError:object:
debugDumpIntermediateImages
workingColorSpace
outputColorSpace
_dynamismMapWithMinImage:maxImage:extent:
_exportOutputImage:format:colorSpace:toURL:uti:error:
videoCleanAperture
stabilizationCrop
imageGeometry
setImageGeometry:
_videoAsset
_videoGeometry
_imageGeometry
_videoCleanAperture
_stabilizationCrop
setObservation:
setExtent:
_observation
_extent
newRenderPipelineStateForEvaluationMode:
_shouldWaitForDependentJobs
prepareNodeWithPipelineState:error:
nodeByReplayingAgainstCache:error:
setStillImage:
stillImage
prepareNode
outputGeometry
registrationRequest
setGuideExtent:
guideExtent
CGColorSpace
imageByColorMatchingWorkingSpaceToColorSpace:
newPixelBufferOfSize:format:
CVPixelBuffer
initWithPixelBuffer:
renderImage:toDestination:bounds:error:
waitUntilCompletedAndReturnError:
initWithTargetedCVPixelBuffer:
initWithCVPixelBuffer:options:
performRequests:error:
results
wantsOutputImage
wantsRenderScaleClampedToNativeScale
_stillImage
_guideExtent
initWithComposition:tag:responseQueue:
initWithCGColorSpace:
initWithComposition:responseQueue:
_pipelineFilters
imageByCompositingOverImage:
inputDestinationImage
setInputDestinationImage:
inputCorrectionInfo
setInputCorrectionInfo:
inputCameraModel
setInputCameraModel:
_inputDestinationImage
_inputCorrectionInfo
_inputCameraModel
format
bytesPerPixel
initWithSize:format:
bytesAtPoint:
mutableBytesAtPoint:
RG16
dataWithBytesNoCopy:length:freeWhenDone:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
makeImageFromCurveData
curvesKernels
unsignedIntegerValue
objectForKey:
applyWithExtent:roiCallback:arguments:options:
inputRGBData
inputRedData
inputGreenData
inputBlueData
inputGrayChoice
bundleWithIdentifier:
URLForResource:withExtension:
initWithURL:
newPhotosPipeline:
initWithExportRequest:
evaluateOutputGeometry:
fail:
failed
complete:
_autoLoopProcessingQueue
_renderGroup
initWithData:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
setData:
dealloc
mutableBytes
initWithBytes:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
elementByteSize
rowElements
width
height
bufferColorspace
initWithTargetPixelSize:
_calculateBlackAndWhiteSettingsFromBufferImage:
CIFormat
stringWithUTF8String:
currentHandler
handleFailureInFunction:file:lineNumber:description:
stopAtTagIncludeGeometryFilter:
histogram
calculateSettingsForImageHistogram:
percentile:
stringByAppendingString:
calculateSettingsForSingleChannelHistogram:suffix:
luminance
addEntriesFromDictionary:
green
blue
loadFusionTuningParameters
stringSettingForKey:defaultValue:
dictionaryWithContentsOfFile:
intValue
inputStillImage
inputRenderScale
inputVideoScale
inputAlignmentExtent
CGRectValue
inputAlignmentTransform
valueAtIndex:
alignImage:transform:extent:
imageByApplyingTransform:highQualityDownsample:
_computeNCCMapFromImage:toImage:scale:
_refineMaskImage:guideImage:scale:
_fuseImage:withGuideImage:weightImage:maskImage:
writeToTIFF:
applyWithExtent:roiCallback:inputImage:arguments:
setInputStillImage:
setInputRenderScale:
setInputVideoScale:
setInputAlignmentExtent:
setInputAlignmentTransform:
_inputStillImage
_inputRenderScale
_inputVideoScale
_inputAlignmentExtent
_inputAlignmentTransform
containsString:
defaultValueForKey:
_customAttributesForKey:
floatValueForKey:defaultValue:clearIfNotDefault:
_LUTImage
samplerWithImage:keysAndValues:
P3Kernel
dictionary
displayP3LinearColorSpace
imageByColorMatchingColorSpaceToWorkingSpace:
setDefaults
inputBlackSrcRGB
setInputBlackSrcRGB:
inputBlackDstRGB
setInputBlackDstRGB:
inputShadowSrcRGB
setInputShadowSrcRGB:
inputShadowDstRGB
setInputShadowDstRGB:
inputMidSrcRGB
setInputMidSrcRGB:
inputMidDstRGB
setInputMidDstRGB:
inputHilightSrcRGB
setInputHilightSrcRGB:
inputHilightDstRGB
setInputHilightDstRGB:
inputWhiteSrcRGB
setInputWhiteSrcRGB:
inputWhiteDstRGB
setInputWhiteDstRGB:
inputBlackSrcRed
setInputBlackSrcRed:
inputBlackDstRed
setInputBlackDstRed:
inputShadowSrcRed
setInputShadowSrcRed:
inputShadowDstRed
setInputShadowDstRed:
inputMidSrcRed
setInputMidSrcRed:
inputMidDstRed
setInputMidDstRed:
inputHilightSrcRed
setInputHilightSrcRed:
inputHilightDstRed
setInputHilightDstRed:
inputWhiteSrcRed
setInputWhiteSrcRed:
inputWhiteDstRed
setInputWhiteDstRed:
inputBlackSrcGreen
setInputBlackSrcGreen:
inputBlackDstGreen
setInputBlackDstGreen:
inputShadowSrcGreen
setInputShadowSrcGreen:
inputShadowDstGreen
setInputShadowDstGreen:
inputMidSrcGreen
setInputMidSrcGreen:
inputMidDstGreen
setInputMidDstGreen:
inputHilightSrcGreen
setInputHilightSrcGreen:
inputHilightDstGreen
setInputHilightDstGreen:
inputWhiteSrcGreen
setInputWhiteSrcGreen:
inputWhiteDstGreen
setInputWhiteDstGreen:
inputBlackSrcBlue
setInputBlackSrcBlue:
inputBlackDstBlue
setInputBlackDstBlue:
inputShadowSrcBlue
setInputShadowSrcBlue:
inputShadowDstBlue
setInputShadowDstBlue:
inputMidSrcBlue
setInputMidSrcBlue:
inputMidDstBlue
setInputMidDstBlue:
inputHilightSrcBlue
setInputHilightSrcBlue:
inputHilightDstBlue
setInputHilightDstBlue:
inputWhiteSrcBlue
setInputWhiteSrcBlue:
inputWhiteDstBlue
setInputWhiteDstBlue:
inputColorSpace
setInputColorSpace:
_inputBlackSrcRGB
_inputBlackDstRGB
_inputShadowSrcRGB
_inputShadowDstRGB
_inputMidSrcRGB
_inputMidDstRGB
_inputHilightSrcRGB
_inputHilightDstRGB
_inputWhiteSrcRGB
_inputWhiteDstRGB
_inputBlackSrcRed
_inputBlackDstRed
_inputShadowSrcRed
_inputShadowDstRed
_inputMidSrcRed
_inputMidDstRed
_inputHilightSrcRed
_inputHilightDstRed
_inputWhiteSrcRed
_inputWhiteDstRed
_inputBlackSrcGreen
_inputBlackDstGreen
_inputShadowSrcGreen
_inputShadowDstGreen
_inputMidSrcGreen
_inputMidDstGreen
_inputHilightSrcGreen
_inputHilightDstGreen
_inputWhiteSrcGreen
_inputWhiteDstGreen
_inputBlackSrcBlue
_inputBlackDstBlue
_inputShadowSrcBlue
_inputShadowDstBlue
_inputMidSrcBlue
_inputMidDstBlue
_inputHilightSrcBlue
_inputHilightDstBlue
_inputWhiteSrcBlue
_inputWhiteDstBlue
_inputColorSpace
numberWithBool:
deserializeFromDictionary:error:
numberWithLong:
photosCompositionSchema
rawSchema
rawNoiseReductionSchema
retouchSchema
smartToneSchema
smartColorSchema
whiteBalanceSchema
cropSchema
trimSchema
livePhotoKeyFrameSchema
muteSchema
autoLoopSchema
orientationSchema
effectSchema
redEyeSchema
apertureRedEyeSchema
smartBlackAndWhiteSchema
sharpenSchema
definitionSchema
noiseReductionSchema
vignetteSchema
levelsSchema
curvesSchema
selectiveColorSchema
depthEffectSchema
effect3DSchema
highResFusionSchema
photosSchema
sharedRegistry
registerSchemas:error:
registry
registerClass:forCacheNodeType:
registerRenderPipeline:forIdentifier:
geometry
iptFromLinearInto:fromRed:green:blue:
hueAngleFrom:
selectiveColorKernels
colorWithRed:green:blue:alpha:colorSpace:
iptHueAngleFromRed:green:blue:
convertToIPT:
hueSatLumTable
convertFromIPT:
inputCorrections
setInputCorrections:
_inputCorrections
colorBalanceKernels
gHDRtoPPKernel
vectorWithX:
RGBToYIQKernel
YIQToRGBKernel
PPtogHDRKernel
applyInputConversion:
isDefaultWarmth:
whiteBalanceKernel
applyOutputConversion:
strength
setStrength:
warmth
setWarmth:
setY:
setI:
setQ:
_strength
_warmth
responseQueue
setDataExtractor:
_options
initWithComposition:location:touchDiameter:
_location
_touchDiameter
writeCGImage:fileURL:fileType:options:
BGRA8
path
stringByAppendingPathComponent:
fileURLWithPath:
writeImage:fileURL:fileType:
writeCGImage:fileURL:fileType:
writeImage:toTemporaryDirectoryWithBasename:
currentSoftwareVersion
platform
buildNumber
isEqualToPixelFormat:
ARGB8
bytesPerRow
region
baseAddress
dataWithLength:
convertFloat:toFixed16:count:
RGBA16
initWithSize:format:rowBytes:mutableBytes:
convertFixed16:toFloat:count:
initWithSize:format:rowBytes:bytes:
initWithBuffer:colorSpace:validRegion:
initWithMutableBuffer:colorSpace:validRegion:
copyPixelsFromImage:srcRect:destImage:destOrigin:
ROIForCenterPoint:radius:
processWithInputs:arguments:output:error:
roiForInput:arguments:outputRect:
formatForInputAtIndex:
outputFormat
pointValue
vectorWithCGRect:
applyWithExtent:inputs:arguments:error:
inputSpots
cancel
integerValue
focusRectDictionaryFromRect:
depthProperties
depthType
_calculateWithImageProperties:completion:
applyOrientationFilter
faces
portraitInfoDictionaryFromFaceObservations:metadata:orientation:
depthEffectInfoDictionaryFromFaceObservations:metadata:orientation:
portraitEffectInfoDictionaryFromFaceObservations:orientation:
focusRectDictionaryFromMetadata:
depthEffectInfoDictionaryFromFaceObservations:focus:aperture:lumaNoiseScale:orientation:
landmarks
boundingBox
leftEye
points
pointCount
averagePoints:pointCount:
convertFacePoint:toImagePointWithFaceRect:orientation:
rightEye
nose
allPoints
faceJunkinessIndex
faceOrientationIndex
faceObservationsData
unarchiveObjectWithData:
indexesOfShallowDepthOfFieldObservations
objectsAtIndexes:
faceOrientation
focusRectangle
apertureFocalRatio
luminanceNoiseAmplitude
portraitInfoDictionaryFromCameraMetadata:
_faceClient
originalWithGeometry
noRedEyeFilter
noTrimFilter
noMuteFilter
noCropFilter
preGeometryFilter
postGeometryFilter
uniqueInputNode
indexOfObject:inSortedRange:options:usingComparator:
PIAutoLoopExportRequest
PIAutoLoopExportClient
PIAutoLoopAnalysisRequest
PIAutoLoopAnalysisClient
PILongExposureRegistrationRequest
PILongExposureFusionAutoCalculator
PIAutoLoopAutoCalculator
PIMakerNoteUtilities
PITempTintFilter
_PIAutoLoopAnalysisResult
PIAutoLoopAnalysisResult
NURenderResult
NSObject
PIAutoLoopAnalysisJob
PIFaceBalanceAutoCalculator
GrayColorResult
RGBResult
PIWhiteBalanceAutoCalculator
_GUWhiteColorCalculator
PIClone
PIDefinitionFilter
GUBilateralConvolution
GUBWBilateralConvolution
PIBilateralFilter
PIAutoLoopFactoryNode
PILongExposureCacheNode
PILongExposureMotionCacheNode
PIAutoLoopCacheNode
PIAutoLoopVideoNode
PIAutoLoopMirrorNode
PIAutoLoopFrameNode
PIAutoLoopKernels
PIPhotoEditHelper
PIForwardFakeBoost
PIInverseFakeBoost
PICoreImageUtilities
PILongExposureExportJob
_PILongExposureRegistrationResult
PILongExposureRegistrationResult
PILongExposureRegistrationJob
PIRAWTempTintSampler
PIRedEye
PICurvesFilter
PhotosPipeline
PIAutoLoopExportJob
GUMsgImageBuffer
PISmartBlackAndWhiteAutoCalculator
PILevelsAutoAbstractCalculator
PILevelsLuminanceAutoCalculator
PILevelsRGBAutoCalculator
PILongExposureFusion
PILevelsFilter
PISchema
PICropAutoCalculator
PISelectiveColorFilter
PINeutralGrayWhiteBalanceFilter
PISmartToneAutoCalculator
PISmartColorAutoCalculator
PIRedEyeAutoCalculator
PIManualRedEyeAutoCalculator
PISourceSampler
PIImageIO
PIApertureRedEyeProcessorKernel
PIApertureRedEyeFilter
PIPortraitAutoCalculator
PIPipelineFilters
@24@0:8@16
@32@0:8@16@24
@64@0:8@16@24q32@40@48@56
@16@0:8
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8@?16
v16@0:8
v24@0:8@16
B16@0:8
v20@0:8B16
@"NSArray"
@"NSDictionary"
@"NSString"
@"NSURL"
v24@0:8q16
v32@0:8@16@24
d16@0:8
v24@0:8d16
@"CIImage"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"<NURenderStatistics>"16@0:8
@"NSDictionary"16@0:8
B24@0:8o^@16
@"AVAsset"
{?={?=[4d]}{?=[4d]}d}16@0:8
@88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=[4d]}16@0:8
@48@0:8{?=[4d]}16
B48@0:8{?=[4d]}16
{?=[4d]}48@0:8{?=[4d]}16
{?=[4d]}88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=dd}104@0:8{?={?=[4d]}{?=[4d]}d}16@88d96
@"PIFaceBalanceAutoCalculator"
@"NUImagePropertiesClient"
^{CGColor=}
@28@0:8@16B24
v32@0:8@16@?24
{?={?=[4d]}{?=[4d]}d}48@0:8@16@24d32@40
@"NUComposition"
@"NUBufferRenderClient"
@"NUImageDataClient"
@"NSObject<OS_dispatch_queue>"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"NSNumber"
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@56@0:8@16@24@32@40@48
@48@0:8@16@24@32@40
@48@0:8@16@24@32o^@40
@40@0:8@16@24q32
@40@0:8@16@24o^@32
@48@0:8^{NSDictionary=#}16@24@32o^@40
B32@0:8@16o^@24
v24@0:8^{NUResponse=#}16
@24@0:8o^@16
@32@0:8@16o^@24
@32@0:8@16^{NSDictionary=#}24
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88
@48@0:8@16@24@32q40
@32@0:8@16q24
@44@0:8@16{CGSize=dd}24B40
^{CGImage=}24@0:8@16
@24@0:8q16
@36@0:8@16@24B32
@24@0:8d16
v40@0:8@16@24@32
@64@0:8@16@24{?={?=qq}{?=qq}}32
B60@0:8@16i24^{CGColorSpace=}28@36@44o^@52
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"NUImageGeometry"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{?={?=qq}{?=qq}}16@0:8
@"VNImageHomographicAlignmentObservation"16@0:8
v48@0:8{?={?=qq}{?=qq}}16
@"VNImageHomographicAlignmentObservation"
{?="origin"{?="x"q"y"q}"size"{?="width"q"height"q}}
@"NSData"
@"NSObject<OS_dispatch_group>"
@68@0:8^v16Q24Q32q40Q48i56^{CGColorSpace=}60
@68@0:8@16Q24Q32q40Q48i56^{CGColorSpace=}60
^v16@0:8
i16@0:8
^{CGColorSpace=}
@"NSMutableData"
@104@0:8@16{?=[3]}24{CGRect={CGPoint=dd}{CGSize=dd}}72
@40@0:8@16@24d32
@"CIVector"
d40@0:8@16d24^B32
v36@0:8^f16f24f28f32
f24@0:8r^f16
d40@0:8d16d24d32
B24@0:8d16
@48@0:8@16{CGPoint=dd}24d40
B40@0:8@16@24@32
B40@0:8^{CGImage=}16@24@32
B48@0:8^{CGImage=}16@24@32@40
{?={?=qq}{?=qq}}40@0:8{CGPoint=dd}16d32
v40@0:8r^f16^S24Q32
v40@0:8r^S16^f24Q32
B48@0:8@16@24@32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
{CGPoint=dd}32@0:8r^16Q24
{CGPoint=dd}72@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32q64
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@48@0:8@16@24f32f36q40
@"NUFaceDetectionClient"
@20@0:8B16
?YAH
?ffffff
?YAH
?YAH
0Xr
?g|_\
pCh?
@<,_
=ffffff
0E33
UUUUUU
?UUUUUU
?ffffff
UUU?
?~0d>
#?6t>=
MbP?+
v@UUUUUU
#?6t>=
@(#)PROGRAM:PhotoImaging  PROJECT:Neutrino-3202.4.209
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
