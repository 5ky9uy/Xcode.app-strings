init
grabScreenWithRect:orientation:error:
getFaceLeftRightLocationInImage
getFaceTopBottomLocationInImage
computeFaceLocationUsingLeftRightLoc:andTopBottomLoc:
swap:with:
isLargeFace
getFaceCoordsInImage
getFaceLocationInImage
getFaceLocationOnScreen
imageWidth
setImageWidth:
imageHeight
setImageHeight:
size
setSize:
bounds
setBounds:
screenOrientation
setScreenOrientation:
imageMirrored
setImageMirrored:
smiling
setSmiling:
blinking
setBlinking:
_imageMirrored
_smiling
_blinking
_imageWidth
_imageHeight
_size
_screenOrientation
_bounds
nodeInitialize
initWithCoder:
encodeWithCoder:
evaluate:
visionImageRequestHandler
alloc
arrayWithObjects:count:
performRequests:error:
results
firstObject
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
requiresVisionKit
title
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
count
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
enumerateMainColors:
.cxx_destruct
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
countByEnumeratingWithState:objects:count:
featureWithVisionRequest:faceResult:canvasSize:
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
visionEngine:evaluateSource:context:options:result:
setXpcConnection:
_xpcConnectionQueue
_xpcConnection
initWithString:
speechItemSeparator
appendAttributedString:
bundleForClass:
URLForResource:withExtension:subdirectory:
addSoundItemWithURL:
numberWithInteger:
defaultManager
path
fileExistsAtPath:
array
addObject:
speechSequence
addSpeechItem:
soundFileURLs
addSoundItemWithID:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_speechSequence
_soundFileURLs
_interruptsAndClearsQueue
setShouldProcessRemotely:
objectForKeyedSubscript:
AXMRectValue
integerValue
screenGrabber
create:
defaultOptions
axmValueWithCGRect:
dictionaryWithObjects:forKeys:count:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
colorWithHue:saturation:brightness:
numberWithDouble:
featureWithColorInfo:canvasSize:
analyzeBuffer:
shouldEvaluateColorInformation
_evaluateColorInformation:
featureWithVisionRequest:brightnessResult:canvasSize:
featureWithVisionRequest:blurResult:canvasSize:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
_commonInit
setIdentifier:
initWithDelegate:targetQueue:
weakToWeakObjectsMapTable
setAxMediaUtilsService:
initWithIdentifier:delegate:
setTaskDispatcher:
isEqualToEngine:
identifier
isEqualToString:
sourceNodes
evaluationNodes
archivedDataWithRootObject:
unarchiveObjectWithData:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
setMaximumQueueSize:
decodeBoolForKey:
setDiagnosticsEnabled:
setPrioritySchedulingEnabled:
setThresholdPriority:
setFeatureTrackingEnabled:
maximumQueueSize
addSourceNode:
addEvaluationNode:
encodeInteger:forKey:
areDiagnosticsEnabled
encodeBool:forKey:
prioritySchedulingEnabled
isFeatureTrackingEnabled
thresholdPriority
isCachingEnabled
cacheKey
addResultHandlers:
resultHandlers
_queue_shouldContinueWithoutResultHandlers:
axMediaUtilsService
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectFaces
detectTraits
detectHumans
detectHorizon
detectRectangles
isEnabled
_queue_shouldEvaluateNode:withOptions:
boostEffectivePriority
effectivePriority
removeAllObjects
resetEffectivePriority
sourceProvidesResults
analysisOptions
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:
error
result
timeIntervalSinceReferenceDate
setProcessingEndTime:
diagnosticInfo
addPipelineTiming:
cache
setResult:forKey:
queue_processResult:
features
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
copy
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
stringWithFormat:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
setDiagnosticInfo:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
appendFormat:
axmAppendRecursiveDescription:withIndentation:
source
context
setProcessingStartTime:
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
_queue_addFeatureTrackingObbserver:targetQueue:
setObject:forKey:
_queue_removeFeatureTrackingObbserver:
removeObjectForKey:
_queue_removeAllFeatureTrackingObservers
queue_trackedFeatures
queue_trackedText
queue_trackedRectangles
keyEnumerator
objectForKey:
visionEngine:didBeginTrackingFeature:appliedOrientation:
visionEngine:didFinishTrackingFeature:appliedOrientation:
visionEngine:trackingFeatureLocationDidChange:appliedOrientation:
taskDispatcher
shouldCallCompletionHandlersForEngineBusyError
addObjectsFromArray:
itemWithSource:context:
scheduleTask:
didBeginProcessingCaptureSessionFrames
didEndProcessingCaptureSessionFrames
didProcessCaptureSessionFrame
didDropCaptureSessionFrame
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
trackingManager:didBeginTrackingFeature:appliedOrientation:
trackingManager:didFinishTrackingFeature:appliedOrientation:
trackingManager:trackingFeatureLocationDidChange:appliedOrientation:
dispatcher:handleTask:
copyWithZone:
initWithIdentifier:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
purgeResources:
addFeatureTrackingObbserver:targetQueue:
removeFeatureTrackingObbserver:
removeAllFeatureTrackingObservers
trackedFaces
trackedText
trackedRectangles
_queue
_queue_sourceNodes
_queue_evaluationNodes
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_queue_featureTrackingManager
_queue_featureTrackingObservers
_prioritySchedulingEnabled
_featureTrackingEnabled
_diagnosticsEnabled
_identifier
_maximumQueueSize
_thresholdPriority
_cache
_diagnosticInfo
_axMediaUtilsService
_taskDispatcher
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
sortedFeatures
objectAtIndex:
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
_updateDefaultLanguages
mainQueue
addObserverForName:object:queue:usingBlock:
autoupdatingCurrentLocale
initWithLocale:
preferredLanguages
length
initWithLanguageCode:
languageCode
isSupertypeOfLanguage:
lowercaseString
uppercaseString
stringByAppendingFormat:
localeIdentifier
primaryComponent
secondaryComponent
localizedStringForLanguageCode:
isSubtypeOfLanguage:
locale
isEqualToAXMLanguage:
setPrimaryComponent:
setSecondaryComponent:
setLanguageCode:
setLocale:
initialize
currentSystemLanguage
currentLocaleLanguage
languageCodesForLanguages:
languageInSet:isSupertypeOfLanguage:
languageDisplayName
_primaryComponent
_secondaryComponent
_languageCode
_locale
characterSetWithCharactersInString:
letterCharacterSet
invertedSet
componentsSeparatedByCharactersInSet:
rangeOfCharacterFromSet:
initWithLocaleIdentifier:
initWithSourceParameters:options:
setAnalysisOptions:
sourceParameters
setAppliedImageOrientation:
appliedImageOrientation
boolValue
inputImage
extent
initWithCIImage:options:
CGImage
errorOccurred:
setInputImage:
pixelBuffer
numberWithInt:
imageColorSpace
render:toCVPixelBuffer:bounds:colorSpace:
numberWithLong:
resultWithImage:features:orientation:
setError:
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
nativeFormatPixelBufferRenderIfNeeded:
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
creationTime
setCreationTime:
processingStartTime
processingEndTime
setSourceParameters:
setFeatures:
setResult:
setVisionImageRequestHandler:
_nativeFormatPixelBuffer
_resultHandlers
_extendedSRGBColorSpace
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_error
_analysisOptions
_inputImage
_appliedImageOrientation
_cacheKey
_creationTime
_processingStartTime
_processingEndTime
_sourceParameters
_features
_result
_visionImageRequestHandler
setMinimumCharacterHeight:
setDetectDiacritics:
setReturnSubFeatures:
decodeFloatForKey:
minimumCharacterHeight
encodeFloat:forKey:
detectDiacritics
returnSubFeatures
textDetectionLanguage
supportedDetectionLanguages
initWithDimensions:
setMinimizeFalseDetections:
setRecognitionLanguage:
detectFeaturesInBuffer:withRegionOfInterest:error:
featureWithFutharkFeature:canvasSize:context:
value
setWithArray:
_detectDiacritics
_returnSubFeatures
_minimumCharacterHeight
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
delegate
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
unscheduleAllTasks
setDelegate:
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
_delegate
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
decodeDoubleForKey:
axmDecodePointForKey:
cameraPixelFocalLength
encodeDouble:forKey:
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumberOfRects
dataWithBytes:length:
featureWithVisionRequest:rectangleResult:canvasSize:
_prepareRectangleRequestOptions
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_minimumConfidence
_maximumNumberOfRects
_cameraOpticalOrigin
_getHue:saturation:brightness:
_getRed:green:blue:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
setSynthesizer:
synthesizer
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:options:
handleRequest:options:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
raise:format:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
endAutoTriggerOfVideoFrameEvents
captureSessionNodeDelegate
setCaptureSessionNodeDelegate:
_avkit_queue
_captureSessionNodeDelegate
initWithFeature:
normalizedFrame
type
currentLocation
featureType
faceId
trackerWithFeature:
update:
_backingFeature
_currentLocation
setNotificationObserverTokens:
sharedInstance
setSession:
notificationObserverTokens
userInfo
unsignedIntegerValue
_handleSessionInterrupted:options:
_handleRouteChanged:previousRoute:
_handleMediaServicesLost
_handleMediaServicesReset
_handleSilenceSecondaryAudio:
removeObserver:
session
setCategory:withOptions:error:
setActive:error:
activateSessionWithError:
_notificationObserverTokens
_session
setComponentState:
transitionToState:completion:
componentState
_componentState
_init
setImage:
frame
compare:
sortedArrayUsingComparator:
detectedTextDescription
setDetectedTextDescription:
detectedFeatureDescription
setDetectedFeatureDescription:
detectionLanguage
isOCR
isFace
isClassification
isBlur
isBrightness
bundleWithIdentifier:
localizedStringForKey:value:table:
localizedStringWithFormat:
likelyExpression
allKeys
localizedStringFormatterForExpression:
blur
brightness
image
detectedTextLanguage
speakableDescription
colorInfoFeature
assetMetadataFeature
sanitizedResult
localizedDetectedTextHint
speakableDescriptionContainsDiscoveredText
_image
_detectedFeatureDescription
_detectedTextDescription
dictionary
orderedSet
enumerateKeysAndObjectsUsingBlock:
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
addOutput:
setTargetPlayerItem:
outputs
removeOutput:
numberWithBool:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
_targetPlayerItem
dictionaryWithDictionary:
setValue:forKey:
numberWithFloat:
currentDevice
userInterfaceIdiom
initWithOptions:
sharedFaceDetector
detectFacesInCGImage:options:error:
extractDetailsForFaces:inCGImage:options:error:
scale
convertFCRFacesArrayToFaceWrappersArray:sourceImageSize:activeCameraReturnsMirroredImage:scale:
face
faceSize
sharedApplication
interfaceOrientation
expressionFeatures
photoFaceWrappers:
photoDescription:withFaceCount:
value:withObjCType:
getValue:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
axmEncodeRect:forKey:
axmDecodeRectForKey:
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
initForReadingWithData:
setRequiresSecureCoding:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
isTrackable
_queue_trackerContainerForFeature:
initWithFeature:queue:
tracker
activeTimer
afterDelay:processBlock:cancelBlock:
queue_trackedFaces
processResult:
trackedFeatures
maximumSizeThreshold
setMaximumSizeThreshold:
maximumDistanceThreshold
setMaximumDistanceThreshold:
_queue_trackedFeatureContainers
_maximumSizeThreshold
_maximumDistanceThreshold
initWithQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setTracker:
setActiveTimer:
_tracker
_activeTimer
setAssetURL:
setName:
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
assetURL
name
creationDate
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
resourceValuesForKeys:error:
_name
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_assetURL
_initWithBackingType:
isMainDisplay
_updateDisplay:withConfiguration:
initWithInitializationCompletion:
setDisplayMonitor:
displayMonitor
addObserver:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
initWithCompletion:
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
setObject:forKeyedSubscript:
currentMode
preferredScale
setScale:
mobileGestaltOrientation
setOrientation:
orientation
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_scale
_orientation
_physicalOrientation
_backingType
_referenceBounds
_imageOrientationForInterfaceOrientation:displayOrientation:
imageByApplyingOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
saveToURL:withOrientation:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
URLByAppendingPathComponent:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:
setCachedLexicons:
mutableCopy
correctSpelling
filterForOCR
_filterTextForOCR:withOperation:useLexicons:useSpellCheck:
_correctSpellingOfText:withOperation:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
spellCheckingLanguages
setWithObject:
substringFromIndex:
allObjects
spellChecker
spellServer:findMisspelledWordInString:languages:wordCount:countOnly:correction:
replaceCharactersInRange:withString:
currentLocale
cachedLexicons
string
lexiconLocale
_lexiconForLocale:
decimalDigitCharacterSet
_shouldIncludeSingleLetterString:
_guessIfTextIsWord:locale:
_textIsWhitelistedWord:withLocale:
isWordValid:withLanguages:
setString:
hasPrefix:
removeCharactersInString:
pathForResource:ofType:
dictionaryWithContentsOfFile:
processText:withOperation:
setSpellChecker:
_vowelCharacters
_consonantCharacters
_globalWhitelistedWords
_localeWhitelistedWords
_spellChecker
_cachedLexicons
_opaqueLexiconForLocale:
anyObject
setCorrectSpelling:
setSpellCheckingLanguages:
setFilterForOCR:
_correctSpelling
_filterForOCR
_spellCheckingLanguages
intValue
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByAppendingString:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
indexOfObject:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
pathExtension
lastPathComponent
stringByDeletingPathExtension
rangeOfString:
processingDuration
setProcessingDuration:
totalDuration
setTotalDuration:
_processingDuration
_totalDuration
_queue_averageFramesProcessedPerSecond
_queue_averageFramesDroppedPerSecond
stringWithString:
appendString:
pipelineTimings
averageFramesProcessedPerSecond
averageFramesDroppedPerSecond
diagnosticReport
totalFramesProcessed
setTotalFramesProcessed:
totalFramesDropped
setTotalFramesDropped:
_isProcessingCaptureSessionFrames
_captureSessionProcessingBeginTime
_captureSessionProcessingEndTime
_queue_pipelineTimings
_totalFramesProcessed
_totalFramesDropped
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
axmValueWithCGAffineTransform:
filterWithName:withInputParameters:
outputImage
imageWithCVPixelBuffer:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
featureWithVisionRequest:humanResult:canvasSize:
setDispatchQueue:
initWithFormat:
_reallyCancel
setCancelled:
setPending:
setCancelBlock:
setProcessBlock:
dispatchQueue
isCancelled
dispatchTimer
automaticallyCancelPendingBlockUponSchedulingNewBlock
useWallTime
setActive:
setDispatchTimer:
cancelBlock
label
afterDelay:processBlock:
cancel
processBlock
setLabel:
setUseWallTime:
isActive
isPending
_cancelled
_automaticallyCancelPendingBlockUponSchedulingNewBlock
_useWallTime
_active
_pending
_processBlock
_cancelBlock
_label
_dispatchQueue
_dispatchTimer
captureOutput
setCaptureOutput:
_captureOutput
setPriority:
priority
defaultPriority
setEffectivePriority:
_priority
_effectivePriority
setIs3DLandmarks:
setResults:
is3DLandmarks
leftEye
pointsArrayForRegion:
numberWithUnsignedInteger:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
points
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
initWithVisionFaceLandmarks:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
_results
setClientID:
setDetectText:
setDetectScenes:
setDetectTraits:
setDetectFaces:
setDetectHumans:
setDetectHorizon:
setDetectRectangles:
setTextDetectionLanguage:
clientID
voiceOverOptions
_detectText
_detectFaces
_detectScenes
_detectTraits
_detectRectangles
_detectHumans
_detectHorizon
_clientID
_textDetectionLanguage
setRequest:
setOptions:
dispatchRequest:options:
request
options
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
_outputRequests
_audioSession
_state
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_request
_options
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
recognitionOptions
setRecognitionOptions:
_recognitionOptions
stringValue
_initWithType:value:confidence:canvasSize:frame:normalizedFrame:
setBarcodeType:
corners
text
boundingBox
setOcrFeatureType:
setDetectionLanguage:
confidence
landmarks
setFaceLandmarks:
landmarks3d
setFaceLandmarks3d:
expressionsAndConfidence
setFaceExpressionsAndConfidence:
pose
setFacePose:
setFaceId:
blurScore
setBlur:
exposureScore
setBrightness:
transform
setHorizonTransform:
angle
setHorizonAngle:
setColorInfo:
setAssetMetadata:
getBytes:length:
_serializeWithCoder:orDictionary:
canvasSize
debugNameForFeatureType:
barcodeType
ocrFeatureType
_nameForOCRFeatureType:
colorInfo
assetMetadata
horizonTransform
horizonAngle
facePose
faceExpressionsAndConfidence
faceLandmarks
faceLandmarks3d
stringForExpression:
confidenceForExpression:
isEqualToAXMVisionFeature:
expressionForString:
featureWithMetadata:canvasSize:
featureWithVisionRequest:classificationResult:canvasSize:
dictionaryRepresentation
isBarcode
isHuman
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
setFrame:
setNormalizedFrame:
setConfidence:
setLikelyExpression:
setCanvasSize:
_horizonAngle
_featureType
_confidence
_value
_barcodeType
_ocrFeatureType
_detectionLanguage
_colorInfo
_assetMetadata
_blur
_faceLandmarks
_faceLandmarks3d
_faceExpressionsAndConfidence
_faceId
_likelyExpression
_canvasSize
_frame
_normalizedFrame
_horizonTransform
_facePose
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:
unitTestingFeature
unitTestingFaceFeature
unitTestingHorizonFeature
setTimingTasks:
timingTasks
initWithFormat:arguments:
numberWithUnsignedLongLong:
unsignedLongLongValue
startTaskWithIdentifier:message:
endTaskWithIdentifier:message:
_timingTasks
processInfo
physicalMemory
knownSceneClassifications
possibleSceneClassifications
setSoundPlayer:
setConfigChangedObserverToken:
_buildEngine
_wireEngineConnections
_startEngineIfNeeded:
configChangedObserverToken
initForReading:error:
soundPlayer
scheduleFile:atTime:completionHandler:
play
setEngine:
engine
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
nextAvailableInputBus
connect:to:fromBus:toBus:format:
isRunning
startAndReturnError:
_logAudioFileInfo:
_engine
_soundPlayer
_configChangedObserverToken
setConnected:
setEnabled:
setNodeQueue:
_connected
_enabled
_nodeQueue
systemReport
privilegedSystemReport
triggerWithImage:options:cacheKey:resultHandler:
triggerWithImage:cacheKey:options:resultHandler:
triggerWithImage:cacheKey:options:clientID:resultHandler:
setCaptureNode:
setImageNode:
setTextDetector:
setSceneDetector:
setFaceDetector:
setTraitDetector:
setVisionRecognitionOptions:
captureNode
imageNode
textDetector
sceneDetector
faceDetector
traitDetector
_captureNode
_imageNode
_textDetector
_sceneDetector
_faceDetector
_traitDetector
axmAppendIndentation:
errorWithDomain:code:userInfo:
allocWithZone:
dateFormatFromTemplate:options:locale:
stringFromNumber:
valueWithBytes:objCType:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
Screen grab not supported on Simulator yet
imageWidth
Ti,N,V_imageWidth
imageHeight
Ti,N,V_imageHeight
size
Ti,N,V_size
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
screenOrientation
Tq,N,V_screenOrientation
imageMirrored
TB,N,V_imageMirrored
smiling
TB,N,V_smiling
blinking
TB,N,V_blinking
Horizon Detector
Could not evaluate. requestHandler was nil
Could not evaluate: %@
mainColors
mainColorWeights
input arrays must be same length
supportsSecureCoding
TB,R
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
remainingColorWeight
Td,N,V_remainingColorWeight
Face Detector
AXMServiceConnection
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
v8@?0
Connection to service invalidated. client: %@
Failed to get service proxy: %@
v16@?0@"NSError"8
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
ItemAppeared
aiff
sounds
ItemDisappeared
Could not produce URL for soundID: %@
sound file URL does not exist: %@
speechSequence
T@"NSAttributedString",R,N
interruptsAndClearsQueue
TB,N,V_interruptsAndClearsQueue
soundFileURLs
T@"NSArray",R,N
Model Detector
Model Detector not available on this platform
region
orientation
Screen Capture
@"CIImage"24@?0@"NSDictionary"8^@16
screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
Traits
v40@?0{vImage_Buffer=^vQQQ}8
Error evaluating color information: %@
sampleFrequency
Tq,N,V_sampleFrequency
shouldEvaluateColorInformation
TB,N,V_shouldEvaluateColorInformation
colorDistanceTheshold
Td,N,V_colorDistanceTheshold
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
diagnosticsEnabled
prioritySchedulingEnabled
thresholdPriority
featureTrackingEnabled
v24@?0@"AXMVisionResult"8@"NSError"16
With priority scheduling, there can be at most 1 evaluation node per cycle
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld tracking:%@ diagnostics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
A context must be provided
A source must be provided
Engine queue is at capacity
identifier
T@"NSString",C,V_identifier
axMediaUtilsService
T@"AXMService",&,N,V_axMediaUtilsService
cache
T@"AXMVisionEngineCache",&,N,V_cache
taskDispatcher
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
diagnosticInfo
T@"AXMVisionEngineDiagnosticInfo",&,N,V_diagnosticInfo
sourceNodes
evaluationNodes
maximumQueueSize
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TQ,V_thresholdPriority
isCachingEnabled
TB,R,N
cacheSize
Tq,R,N
TB,N,GisFeatureTrackingEnabled,V_featureTrackingEnabled
trackedFaces
trackedText
trackedRectangles
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
T@"NSUUID",&,N,V_identifier
context
T@"AXMVisionPipelineContext",&,N,V_context
source
T@"AXMSourceNode",&,N,V_source
AXMLanguage
v16@?0@"NSNotification"8
AXMLanguage<%p> languageID: '%@'. Locale: <%p> '%@'
primaryComponent
secondaryComponent
languageCode
locale
T@"NSString",&,N,V_primaryComponent
T@"NSString",&,N,V_secondaryComponent
T@"NSString",&,N,V_languageCode
T@"NSLocale",&,N,V_locale
languageDisplayName
T@"NSString",R,N
inputImage
appliedOrientation
sourceProvidesResults
sourceparams
features
analysisOptions
error
AXMVisionPipelineContext<%p>: source params: %@. error: %@
appliedImageOrientation
A creation node must return a valid image
pipeline context error. CVPixelBufferCreate returned NULL buffer for ocr pixel buffer. CVReturn: %@
error initializing vImageBuffer from CVPixelBuffer: %@
error initializing vImageBuffer from CGImageRef: %@
No inputImage or pixelBuffer found to initialize vImage_Buffer
sourceParameters
T@"NSDictionary",&,N,V_sourceParameters
T@"NSMutableArray",&,N,V_features
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
result
T@"AXMVisionResult",&,N,V_result
T@"CIImage",&,N,V_inputImage
T@"NSNumber",&,N,V_appliedImageOrientation
visionImageRequestHandler
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
shouldProcessRemotely
TB,N,V_shouldProcessRemotely
resultHandlers
T{CGSize=dd},R,N
visionImageRequestHandlerIsLoaded
cacheKey
T@"<NSCopying>",&,N,V_cacheKey
shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
creationTime
Td,N,V_creationTime
processingStartTime
Td,N,V_processingStartTime
processingEndTime
Td,N,V_processingEndTime
AXMMinimumCharacterHeight
AXMDetectDiacritics
AXMReturnSubFeatures
Text Detector
Could not evaluate with OCR. Input pixel buffer was nil
Could not OCR image. OCR detection error: %@
supportedDetectionLanguages
T@"NSSet",R,N
minimumCharacterHeight
Td,N,V_minimumCharacterHeight
detectDiacritics
TB,N,V_detectDiacritics
returnSubFeatures
TB,N,V_returnSubFeatures
task should not be in the completed state
taskIsBeingProcessed should be YES
v20@?0@"AXMTask"8B16
taskIsBeingProcessed should be NO
count
isEmpty
delegate
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
Task should not be complete if being marked as complete
complete
TB,N,GisComplete,V_complete
taskCompleteBlock
T@?,C,N,V_taskCompleteBlock
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
Td,N,V_minimumConfidence
maximumNumberOfRects
Tq,N,V_maximumNumberOfRects
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
redFloat
Td,R,N
greenFloat
blueFloat
hueFloat
saturationFloat
brightnessFloat
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
allColorMarkers
localizedName
T@"NSString",&,N,V_localizedName
handleRequest: expected nil completion block
didFinish: expected completion block, but found nil.
didCancel: expected completion block, but found nil.
synthesizer
T@"AVSpeechSynthesizer",&,N,V_synthesizer
currentRequestCompletionBlock
T@?,C,N,V_currentRequestCompletionBlock
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
AXMFeatureTracker<%p>: type:%ld loc:%@
type
TQ,R,N
currentLocation
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_currentLocation
value
faceId
Error updating audio session: %@
notificationObserverTokens
T@"NSMutableArray",&,N,V_notificationObserverTokens
session
T@"AVAudioSession",&,N,V_session
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
isSupported
componentState
Tq,N,V_componentState
AXMFeatures
AXMImage
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
Unknown
__AXMStringForVariablesSentinel
com.apple.accessibility.AXMediaUtilities
photo.description.faces
Accessibility
photo.description.blurriness.none
photo.description.blurriness.low
photo.description.blurriness.medium
photo.description.blurriness.high
photo.description.brightness.low
photo.description.brightness.high
detected.text.hint
detectedTextDescription
detectedFeatureDescription
detectedTextLanguage
AXMVisionResult<%p>: Image:%@ Results:%@ Speakable Description: %@
image
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSString",&,N,V_detectedFeatureDescription
T@"NSString",&,N,V_detectedTextDescription
colorInfoFeature
T@"AXMVisionFeature",R,N
assetMetadataFeature
localizedDetectedTextHint
T@"AXMLanguage",R,N
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
%@ playerItem:<%@>
legibility event: %@
targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
post
face.count
UIDevice
Unable to find class %s
/System/Library/Frameworks/UIKit.framework/UIKit
UIApplication
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
Asset Metadata
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
T@"<AXMFeatureTrackingManagerDelegate>",W,N,V_delegate
maximumSizeThreshold
Td,N,V_maximumSizeThreshold
maximumDistanceThreshold
Td,N,V_maximumDistanceThreshold
tracker
T@"AXMFeatureTracker",&,N,V_tracker
activeTimer
T@"AXMTimer",&,N,V_activeTimer
assetURL
name
creationDate
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
name:%@ created:%@ UTI:%@ typeDesc:%@
T@"NSURL",&,N,V_assetURL
T@"NSString",&,N,V_name
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
localizedTypeDescription
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
AXMDisplayManager
v24@?0@"FBSDisplayMonitor"8@"NSSet"16
AXMDisplayManager initialized: %@
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
Unable to look up screenInfo
main-screen-scale
Unable to look up screen scale
scale
main-screen-orientation
supportsDeepColor
Aixt/MEN2O2B7f+8m4TxUA
Unexpected physical screen orientaiton
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
displayMonitor
T@"FBSDisplayMonitor",&,N,V_displayMonitor
mobileGestaltOrientation
Td,N,V_mobileGestaltOrientation
frontBoardMainDisplay
T@"AXMDisplay",R,N
coreAnimationMainDisplay
isInitialized
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
backingType
Tq,N,V_backingType
T@"NSString",C,N,V_name
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
physicalOrientation
Tq,N,V_physicalOrientation
referenceBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
unknown
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
Unable to create lexicon: %@
No lexicon found for locale: %@
v24@?0^{_LXEntry=}8*16
aeiouyAEIOUY
whitelisted_words
plist
whitelisted_words_%@
spellChecker
T@"AppleSpell",&,N,V_spellChecker
cachedLexicons
T@"NSMutableDictionary",&,N,V_cachedLexicons
lexiconLocale
T@"NSLocale",R,N
correctSpelling
TB,N,V_correctSpelling
spellCheckingLanguages
T@"NSSet",&,N,V_spellCheckingLanguages
filterForOCR
TB,N,V_filterForOCR
-axout-tmp
AX: Export Session status: %ld %@
-axtmp
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
face detect error: %@
face.smiling
face.blinking
face.number.format
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/msword
filetype.word
application/postscript
filetype.postscript
application/rtf
filetype.rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
audio/mp4
filetype.audio
audio/x-wav
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.sunglasses
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
FCRPreciseDetectionParameters
/System/Library/PrivateFrameworks/FaceCore.framework/FaceCore
FCRSetupParamMinFaceSize
FCRSetupParamNumberOfAngles
FCRFaceDetector
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
FCRExtractionParamExtractSmile
FCRExtractionParamExtractBlink
FCRFaceExpressionSmile
FCRFaceExpressionLeftEyeClosed
FCRFaceExpressionRightEyeClosed
UIAccessibilityIsVoiceOverRunning
processingDuration
Td,N,V_processingDuration
totalDuration
Td,N,V_totalDuration
AXMVisionEngineDiagnosticInfo
Engine Diagnostic Report:
  Recent work items:
   Processing time: %.3f. end-to-end time: %.3f
  Capture Session frames
    processed :%lld. (%.2f frames / second)
    dropped   :%lld. (%.2f frames / second)
totalFramesProcessed
TQ,N,V_totalFramesProcessed
totalFramesDropped
TQ,N,V_totalFramesDropped
pipelineTimings
averageFramesProcessedPerSecond
averageFramesDroppedPerSecond
diagnosticReport
com.apple.AXMediaUtilitiesService
contextQueue
%.4s
Pixel buffer info: width:%ld height:%ld bytesPerRow:%ld dataSize:%ld isPlanar:%ld planeCount:%ld format:%@
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
CIAffineTransform
Human Detector
%@.%@.TimerQueue
%@: Ignoring block scheduled for execution %.2f seconds from now.
%@ - %@
active
TB,N,GisActive,V_active
pending
TB,N,GisPending,V_pending
cancelled
TB,N,GisCancelled,V_cancelled
dispatchQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_dispatchQueue
dispatchTimer
T@"NSObject<OS_dispatch_source>",&,N,V_dispatchTimer
processBlock
T@?,C,N,V_processBlock
cancelBlock
T@?,C,N,V_cancelBlock
label
T@"NSString",&,N,V_label
automaticallyCancelPendingBlockUponSchedulingNewBlock
TB,N,V_automaticallyCancelPendingBlockUponSchedulingNewBlock
useWallTime
TB,N,V_useWallTime
Barcode
captureOutput
T@"AVCaptureMetadataOutput",&,N,V_captureOutput
priority
effectivePriority
TQ,N,V_effectivePriority
TQ,N,V_priority
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
Error decoding face landmark dict: %@
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
is3DLandmarks
TB,N,V_is3DLandmarks
results
T@"NSDictionary",&,N,V_results
clientID
detectText
detectScenes
detectTraits
detectFaces
detectHumans
detectHorizon
detectRectangles
textDetectionLanguage
Tq,N,V_clientID
TB,N,V_detectText
TB,N,V_detectFaces
TB,N,V_detectScenes
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHumans
TB,N,V_detectHorizon
T@"AXMLanguage",&,N,V_textDetectionLanguage
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
Could not activate audio session: %@
request
T@"AXMOutputRequest",&,N,V_request
options
T@"AXMOutputRequestDispatchOptions",&,N,V_options
Source node not connected to any engine
Vision (Deprecated)
recognitionOptions
TQ,N,V_recognitionOptions
OCR (Deprecated)
Image Chr.. (Deprecated)
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceExpressions
AXMFeatureFacePose
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
Unknown AVMetadataObject
Error decoding face expression dict: %@
detectionLanguage
color info
asset metadata
Char
Diacrit
Brightness
Blur
Color
Face
Human
Classification
MediaLegibility
AssetMetadata
Horizon
Rectangle
AXMVisionFeature<%p> %@
ID:%lu [faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
value:'%@' type:%@ 
value:'%@' 
value:'%.2f' 
asset info [%@] 
horizon transform. angle: %f 
frame:%@ (normalized:%@) confidence:%.2f
dictionaryRepresentation
T@"NSDictionary",R,N
Td,N,V_creationDate
frame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_frame
normalizedFrame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_normalizedFrame
T@"NSString",&,N,V_value
barcodeType
T@"NSString",&,N,V_barcodeType
ocrFeatureType
Tq,N,V_ocrFeatureType
T@"AXMLanguage",&,N,V_detectionLanguage
colorInfo
T@"AXMVisionFeatureColorInfo",&,N,V_colorInfo
assetMetadata
T@"AXMVisionFeatureAssetMetadata",&,N,V_assetMetadata
blur
Td,N,V_blur
Td,N,V_brightness
confidence
Td,N,V_confidence
horizonTransform
T{CGAffineTransform=dddddd},N,V_horizonTransform
horizonAngle
Tf,N,V_horizonAngle
faceLandmarks
T@"AXMVisionFeatureFaceLandmarks",&,N,V_faceLandmarks
faceLandmarks3d
T@"AXMVisionFeatureFaceLandmarks",&,N,V_faceLandmarks3d
faceExpressionsAndConfidence
T@"NSDictionary",&,N,V_faceExpressionsAndConfidence
likelyExpression
Tq,N,V_likelyExpression
TQ,N,V_faceId
facePose
T{?=[4]},N,V_facePose
canvasSize
T{CGSize=dd},N,V_canvasSize
featureType
TQ,R,N,V_featureType
isBarcode
isFace
isHuman
isOCR
isClassification
isBrightness
isBlur
isHorizon
isColor
isMediaLegibility
isAssetMetadata
isRectangle
isTrackable
Time profiling error. task identifier already in progress: %@
TIME PROFILE: START '%@'
 - '%@'
Time profiling error. task identifier was not in progress: %@
TIME PROFILE: FINISHED '%@' 
- '%@' 
Elapsed: %@ s
timingTasks
T@"NSMutableDictionary",&,N,V_timingTasks
Scene Detector
possibleSceneClassifications
Could not handle audio request: %@. Error:%@
Could not start engine: %@
engine
T@"AVAudioEngine",&,N,V_engine
soundPlayer
T@"AVAudioPlayerNode",&,N,V_soundPlayer
configChangedObserverToken
T@,&,N,V_configChangedObserverToken
AXMNodeID
AXNodeEnabled
Subclass should override
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
title
requiresVisionKit
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
nodeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
enabled
TB,N,GisEnabled,V_enabled
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
VoiceOver
screenCapture
text
scene
face
trait
use init()
captureNode
T@"AXMScreenCaptureNode",W,N,V_captureNode
imageNode
T@"AXMImageNode",W,N,V_imageNode
textDetector
T@"AXMTextDetectorNode",W,N,V_textDetector
sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
faceDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
traitDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
com.apple.Accessibility
AXM-Service
AXM-Cache
AXM-Screen
AXM-Text
AXM-Results
AXM-Priority
AXM-Track
AXM-Output
AXM-Speech
AXM-Sound
AXM-Haptic
AXM-MediaDesc
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
, %@
AXDateFormatter
{CGVector=dd}
{CGAffineTransform=dddddd}
AXMPointValue
T{CGPoint=dd},R,N
AXMVectorValue
T{CGVector=dd},R,N
AXMSizeValue
AXMRectValue
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
AXMAffineTransformValue
T{CGAffineTransform=dddddd},R,N
AXMScreenGrabber
FaceWrapper
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMFaceDetectorNode
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMOutputRequest
AXMOutputRequestDispatchOptions
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMFeatureTrackingManagerDelegate
AXMTaskDispatcherDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMLanguage
AXMVisionPipelineContext
AXMTextDetectorNode
AXMTaskDispatcher
AXMTask
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAVCaptureSessionNode
AXMFeatureTracker
AXMAudioSession
AXMOutputComponent
AXMVisionResult
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXFaceDetection
AXMExtras
AXMAssetMetadataNode
AXMFeatureTrackingManager
_AXMFeatureTrackerContainer
AXMVisionFeatureAssetMetadata
FaceCoreLightWrapper
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMTextProcessor
UnitTesting
AXMTextProcessingOperation
AXMVisionEnginePipelineDiagnosticInfo
AXMVisionEngineDiagnosticInfo
AXMHumanDetectorNode
AXMTimer
AXMBarcodeNode
AXMEvaluationNode
AXMVisionFeatureFaceLandmarks
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMSourceNode
AXMVisionNode
AXMOCRNode
AXMImageCharacteristicsNode
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
AXMTimeProfiling
AXMSceneDetectorNode
AXMSoundComponent
AXMVisionEngineNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMGeomerty
@16@0:8
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48^@56
B16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
i16@0:8
q16@0:8
i32@0:8q16q24
v32@0:8^q16^q24
v20@0:8i16
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v24@0:8q16
v20@0:8B16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
v16@0:8
@24@0:8@16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v32@0:8@16@24
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
@"NSMutableAttributedString"
@"NSMutableArray"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v40@0:8@16@24@32
v40@0:8@"AXMFeatureTrackingManager"16@"AXMFeatureTracker"24@"NSNumber"32
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
@24@0:8^{_NSZone=}16
v32@0:8@16q24
v32@0:8@"NSMutableString"16q24
B32@0:8@16@24
@28@0:8@16B24
@24@0:8#16
v24@0:8Q16
@"_AXMVisionEngineAnalysisTask"
@"AXMFeatureTrackingManager"
@"NSMapTable"
@"NSString"
@"AXMVisionEngineCache"
@"AXMVisionEngineDiagnosticInfo"
@"AXMService"
@"AXMTaskDispatcher"
@32@0:8@16@24
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@"NSLocale"
{CGSize=dd}16@0:8
^{CGColorSpace=}16@0:8
^{__CVBuffer=}20@0:8B16
@24@0:8@?16
^{__CVBuffer=}
^{CGColorSpace=}
@"NSError"
@"AXMVisionAnalysisOptions"
@"CIImage"
@"NSNumber"
@"<NSCopying>"
@"NSDictionary"
@"AXMVisionResult"
@"VNImageRequestHandler"
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
@?16@0:8
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
d24@0:8@16
@48@0:8d16d24d32@40
@32@0:8@16d24
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v40@0:8@16@24@?32
@"AVSpeechSynthesizer"
@"<AXMAVCaptureSessionNodeDelegate>"
@"AXMVisionFeature"
B24@0:8^@16
v32@0:8Q16Q24
v32@0:8Q16@24
@"AVAudioSession"
v32@0:8q16@?24
@40@0:8@16@24@32
@24@0:8q16
@"NSMutableOrderedSet"
@"NSMutableDictionary"
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
@32@0:8@16q24
@48@0:8@16{CGSize=dd}24B40f44
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@48@0:8@16#24@32^@40
@"<AXMFeatureTrackingManagerDelegate>"
@"AXMFeatureTracker"
@"AXMTimer"
@"NSDate"
@"NSURL"
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8{CGSize=dd}16
{CGSize="width"d"height"d}
q32@0:8q16q24
q28@0:8q16B24
@40@0:8q16q24^q32
@36@0:8q16B24^q28
^{_LXLexicon=}24@0:8@16
v40@0:8@16@24B32B36
@"NSCharacterSet"
@"AppleSpell"
r^v24@0:8@16
@"NSSet"
v32@0:8d16@?24
v40@0:8d16@?24@?32
@"AVCaptureMetadataOutput"
@20@0:8B16
@24@0:8Q16
@"AXMLanguage"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputRequest"
@"AXMOutputRequestDispatchOptions"
@40@0:8@16{CGSize=dd}24
@48@0:8@16{CGSize=dd}24@40
@48@0:8@16@24{CGSize=dd}32
@"NSDictionary"16@0:8
@120@0:8Q16@24d32{CGSize=dd}40{CGRect={CGPoint=dd}{CGSize=dd}}56{CGRect={CGPoint=dd}{CGSize=dd}}88
q24@0:8@16
d24@0:8q16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
f16@0:8
v20@0:8f16
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
@"AXMVisionFeatureFaceLandmarks"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
{?="columns"[4]}
@96@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88
@"AVAudioEngine"
@"AVAudioPlayerNode"
@"<AXMVisionEngineNodeConnectionDelegate>"
v48@0:8@16@24@32@?40
v48@0:8@16@24Q32@?40
v56@0:8@16@24Q32q40@?48
@"AXMScreenCaptureNode"
@"AXMImageNode"
@"AXMTextDetectorNode"
@"AXMSceneDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
@ffffff
MbP?
@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
f024
