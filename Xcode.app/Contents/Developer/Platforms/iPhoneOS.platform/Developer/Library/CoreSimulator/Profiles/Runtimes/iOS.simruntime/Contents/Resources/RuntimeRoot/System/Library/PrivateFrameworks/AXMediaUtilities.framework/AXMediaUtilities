init
dictionary
_lexiconForLocale:
currentLocale
languageCode
localeIdentifier
objectForKey:
dictionaryWithObjects:forKeys:count:
setObject:forKey:
lexiconExistsForLocale:
textExistsInLexicon:withLocale:
.cxx_destruct
_cachedLexicons
_opaqueLexiconForLocale:
grabScreenWithRect:orientation:renderToPixelBufferNow:error:
getFaceLeftRightLocationInImage
getFaceTopBottomLocationInImage
computeFaceLocationUsingLeftRightLoc:andTopBottomLoc:
swap:with:
isLargeFace
getFaceCoordsInImage
getFaceLocationInImage
getFaceLocationOnScreen
imageWidth
setImageWidth:
imageHeight
setImageHeight:
size
setSize:
bounds
setBounds:
screenOrientation
setScreenOrientation:
imageMirrored
setImageMirrored:
smiling
setSmiling:
blinking
setBlinking:
_imageMirrored
_smiling
_blinking
_imageWidth
_imageHeight
_size
_screenOrientation
_bounds
nodeInitialize
initWithCoder:
encodeWithCoder:
evaluate:
visionImageRequestHandler
alloc
arrayWithObjects:count:
performRequests:error:
results
firstObject
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
title
requiresVisionFramework
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
count
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
countByEnumeratingWithState:objects:count:
featureWithVisionRequest:faceResult:canvasSize:
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
setXpcConnection:
_xpcConnectionQueue
_xpcConnection
initWithString:
speechItemSeparator
appendAttributedString:
bundleForClass:
URLForResource:withExtension:subdirectory:
addSoundItemWithURL:
numberWithInteger:
defaultManager
path
fileExistsAtPath:
array
addObject:
speechSequence
addSpeechItem:
soundFileURLs
addSoundItemWithID:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_speechSequence
_soundFileURLs
_interruptsAndClearsQueue
speechStringForObjectValue:
stringForObjectValue:
getObjectValue:forString:errorDescription:
copy
initWithFormattingBlock:
formattingBlock
setFormattingBlock:
_formattingBlock
decodeObjectForKey:
fileURLWithPath:
preloadModelIfNeeded:
modelURL
setModelURL:
_modelURL
setShouldProcessRemotely:
evaluationExclusivelyUsesVisionFramework
objectForKeyedSubscript:
AXMRectValue
integerValue
screenGrabber
produceImage:
defaultOptions
axmValueWithCGRect:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
colorWithHue:saturation:brightness:
numberWithDouble:
featureWithColorInfo:canvasSize:
analyzeBuffer:
shouldEvaluateColorInformation
_evaluateColorInformation:
featureWithVisionRequest:brightnessResult:canvasSize:
featureWithVisionRequest:blurResult:canvasSize:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
_commonInit
setIdentifier:
initWithDelegate:targetQueue:
weakToWeakObjectsMapTable
setAxMediaUtilsService:
initWithIdentifier:delegate:
setTaskDispatcher:
isEqualToEngine:
identifier
isEqualToString:
sourceNodes
evaluationNodes
archivedDataWithRootObject:
unarchiveObjectWithData:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
setMaximumQueueSize:
decodeBoolForKey:
setDiagnosticsEnabled:
setPrioritySchedulingEnabled:
setThresholdPriority:
setFeatureTrackingEnabled:
maximumQueueSize
addSourceNode:
addEvaluationNode:
encodeInteger:forKey:
areDiagnosticsEnabled
encodeBool:forKey:
prioritySchedulingEnabled
isFeatureTrackingEnabled
thresholdPriority
isCachingEnabled
cacheKey
addResultHandlers:
resultHandlers
_queue_shouldContinueWithoutResultHandlers:
axMediaUtilsService
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectModelClassifications
detectFaces
detectTraits
detectHumans
detectHorizon
detectRectangles
isEnabled
_queue_shouldEvaluateNode:withOptions:
boostEffectivePriority
effectivePriority
removeAllObjects
resetEffectivePriority
features
stringWithString:
appendFormat:
detectedFeatureDescription
detectedTextDescription
appendString:
sourceProvidesResults
analysisOptions
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
setEvaluationExclusivelyUsesVisionFramework:
settings
writeOutInputImages
generateImageRepresentation
generateFileNameForImageWithPrefix:extension:
URLByAppendingPathComponent:
error
result
_queue_logEvaluatedResult:
timeIntervalSinceReferenceDate
setProcessingEndTime:
diagnosticInfo
addPipelineTiming:
cache
setResult:forKey:
queue_processResult:
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
stringWithFormat:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
setDiagnosticInfo:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
axmAppendRecursiveDescription:withIndentation:
source
context
setProcessingStartTime:
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
_queue_addFeatureTrackingObbserver:targetQueue:
_queue_removeFeatureTrackingObbserver:
removeObjectForKey:
_queue_removeAllFeatureTrackingObservers
queue_trackedFeatures
queue_trackedText
queue_trackedRectangles
queue_trackedModelClassifiers
keyEnumerator
visionEngine:didBeginTrackingFeature:appliedOrientation:
visionEngine:didFinishTrackingFeature:appliedOrientation:
visionEngine:trackingFeatureLocationDidChange:appliedOrientation:
taskDispatcher
shouldCallCompletionHandlersForEngineBusyError
addObjectsFromArray:
itemWithSource:context:
scheduleTask:
didBeginProcessingCaptureSessionFrames
didEndProcessingCaptureSessionFrames
didProcessCaptureSessionFrame
didDropCaptureSessionFrame
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
trackingManager:didBeginTrackingFeature:appliedOrientation:
trackingManager:didFinishTrackingFeature:appliedOrientation:
trackingManager:trackingFeatureLocationDidChange:appliedOrientation:
dispatcher:handleTask:
copyWithZone:
initWithIdentifier:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
addFeatureTrackingObbserver:targetQueue:
removeFeatureTrackingObbserver:
removeAllFeatureTrackingObservers
trackedFaces
trackedText
trackedRectangles
trackedModelClassifiers
_queue
_queue_sourceNodes
_queue_evaluationNodes
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_queue_featureTrackingManager
_queue_featureTrackingObservers
_prioritySchedulingEnabled
_featureTrackingEnabled
_diagnosticsEnabled
_identifier
_maximumQueueSize
_thresholdPriority
_cache
_diagnosticInfo
_axMediaUtilsService
_taskDispatcher
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
sortedFeatures
objectAtIndex:
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
_updateDefaultLanguages
mainQueue
addObserverForName:object:queue:usingBlock:
autoupdatingCurrentLocale
initWithLocale:
preferredLanguages
length
initWithLanguageCode:
isSupertypeOfLanguage:
lowercaseString
uppercaseString
stringByAppendingFormat:
primaryComponent
secondaryComponent
localizedStringForLanguageCode:
isSubtypeOfLanguage:
locale
isEqualToAXMLanguage:
setPrimaryComponent:
setSecondaryComponent:
setLanguageCode:
setLocale:
initialize
currentSystemLanguage
currentLocaleLanguage
languageCodesForLanguages:
languageInSet:isSupertypeOfLanguage:
languageDisplayName
_primaryComponent
_secondaryComponent
_languageCode
_locale
characterSetWithCharactersInString:
letterCharacterSet
invertedSet
componentsSeparatedByCharactersInSet:
rangeOfCharacterFromSet:
initWithLocaleIdentifier:
whitespaceAndNewlineCharacterSet
addCharactersInString:
string
enumerateSubstringsInRange:options:usingBlock:
_groupSeperatorCharacterSet
initWithSourceParameters:options:
boolValue
setAnalysisOptions:
setAppliedImageOrientation:
appliedImageOrientation
extent
includeImageInResult
initWithCIImage:options:
_discardSourceImageIfPossible
nativeFormatPixelBufferRenderIfNeeded:
initWithCVPixelBuffer:options:
CGImage
errorOccurred:
pixelBuffer
numberWithInt:
imageColorSpace
render:toCVPixelBuffer:bounds:colorSpace:
numberWithLong:
resultWithImage:features:orientation:
resultWithFeatures:orientation:
setError:
imageWithCVPixelBuffer:
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
creationTime
setCreationTime:
processingStartTime
processingEndTime
sequenceID
setSequenceID:
setFeatures:
setResult:
setVisionImageRequestHandler:
_sourceImage
_sourceParameters
_sourceProvidesOwnResults
_nativeFormatPixelBuffer
_resultHandlers
_extendedSRGBColorSpace
_cachedSize
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_appliedImageOrientation
_cacheKey
_creationTime
_processingStartTime
_processingEndTime
_sequenceID
_features
_result
_visionImageRequestHandler
freeResources
decodeFloatForKey:
setMinimumCharacterHeight:
setDetectDiacritics:
setReturnSubFeatures:
setMinimizeFalsePositives:
minimumCharacterHeight
encodeFloat:forKey:
detectDiacritics
returnSubFeatures
minimizeFalsePositives
textDetectionLanguage
supportedDetectionLanguages
writeOutOCRInputImages
initWithDimensions:
setMinimizeFalseDetections:
setRecognitionLanguage:
minimizeFalseDetections
recognitionLanguage
detectFeaturesInBuffer:withRegionOfInterest:error:
text
textDocumentWithFutharkFeatures:canvasSize:context:error:
containsString:
setReportCharacterBoxes:
setMinimumCharacterPixelHeight:
_visionTextDetectionOptionForLangauge:
setTextRecognition:
minimumCharacterPixelHeight
reportCharacterBoxes
textRecognition
textDocumentWithVisionObservations:canvasSize:context:error:
_evaluateWithFutharkFlavor:
_evaluateWithVisionFlavor:
setWithArray:
detectionFlavor
setDetectionFlavor:
_textDetector
_textLayoutManager
_detectDiacritics
_returnSubFeatures
_minimizeFalsePositives
_detectionFlavor
_minimumCharacterHeight
setObject:forKeyedSubscript:
numberWithBool:
beginEditing
addAttribute:value:range:
endEditing
_evaluateIfNeeded
hasGlobalTag:
addGlobalTag:
removeGlobalTag:
_stringRange
attribute:atIndex:longestEffectiveRange:inRange:
speakableText
enumerateKeysAndObjectsUsingBlock:
enumerateAttributesInRange:options:usingBlock:
_isEvaluated
substringWithRange:
initWithFormat:
isSpeakable
_substringWithRange:
attributesAtIndex:effectiveRange:
_initWithAttributedString:
initWithString:attributes:
mutableCopy
mutableString
replaceCharactersInRange:withString:
setAttributes:range:
textWithString:locale:evaluationBlock:
addTag:withToken:range:
setSpeakable:
isRangeSpeakable:
_setNeedEvaluation
initWithAttributedString:
_attrString
_globalAttributes
_evaluationBlock
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
delegate
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
unscheduleAllTasks
setDelegate:
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
_delegate
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
decodeDoubleForKey:
axmDecodePointForKey:
cameraPixelFocalLength
encodeDouble:forKey:
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumberOfRects
dataWithBytes:length:
featureWithVisionRequest:rectangleResult:canvasSize:
_prepareRectangleRequestOptions
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
_getHue:saturation:brightness:
_getRed:green:blue:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
setSynthesizer:
synthesizer
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:options:
handleRequest:options:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
raise:format:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
endAutoTriggerOfVideoFrameEvents
captureSessionNodeDelegate
setCaptureSessionNodeDelegate:
_avkit_queue
_captureSessionNodeDelegate
initWithFeature:
normalizedFrame
type
currentLocation
featureType
value
faceId
trackerWithFeature:
update:
_backingFeature
_currentLocation
_init
_debugType
range
isPhoneNumber
isDate
isEmailAddress
phoneNumber
initWithNLToken:text:type:lexicalClass:language:script:namedEntity:derivedSubtoken:speechFormatter:
initWithdatatype:text:textCheckingResult:speechFormatter:
originalText
isPunctuation
isWhitespace
isSentenceTerminator
_originalText
_speechFormatter
_nlToken
_nlType
_nlLexicalClass
_nlLanguage
_nlScript
_nlNamedEntity
_nlDerivedSubtoken
_datatype
_textCheckingResult
setNotificationObserverTokens:
sharedInstance
setSession:
notificationObserverTokens
userInfo
unsignedIntegerValue
_handleSessionInterrupted:options:
_handleRouteChanged:previousRoute:
_handleMediaServicesLost
_handleMediaServicesReset
_handleSilenceSecondaryAudio:
removeObserver:
session
setCategory:withOptions:error:
setActive:error:
activateSessionWithError:
_notificationObserverTokens
_session
setComponentState:
transitionToState:completion:
componentState
_componentState
setImage:
frame
compare:
sortedArrayUsingComparator:
detectionLanguage
isOCR
isTextDocument
subfeatures
isValueSpeakable
isFace
isClassification
isBlur
isBrightness
bundleWithIdentifier:
localizedStringForKey:value:table:
localizedStringWithFormat:
likelyExpression
allKeys
localizedStringFormatterForExpression:
blur
brightness
setDetectedTextDescription:
setDetectedFeatureDescription:
image
detectedTextLanguage
speakableDescription
colorInfoFeature
assetMetadataFeature
localizedDetectedTextHint
speakableDescriptionContainsDiscoveredText
_image
_detectedFeatureDescription
_detectedTextDescription
orderedSet
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
addOutput:
setTargetPlayerItem:
outputs
removeOutput:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
_triggeringLegibilityEvents
_targetPlayerItem
_enumerateText:textCheckingType:datatype:withBlock:
emailAddressRegex
_enumerateText:regularExpression:datatype:withBlock:
speechFormatterForDatatype:
enumerateMatchesInString:options:range:usingBlock:
dataDetectorWithTypes:error:
regularExpressionWithPattern:options:error:
initWithSpeechFormatterCache:
enumerateText:searchingFordatatypes:withBlock:
_emailAddressRegex
_speechFormatterCache
dictionaryWithDictionary:
setValue:forKey:
numberWithFloat:
currentDevice
userInterfaceIdiom
initWithOptions:
sharedFaceDetector
detectFacesInCGImage:options:error:
extractDetailsForFaces:inCGImage:options:error:
scale
convertFCRFacesArrayToFaceWrappersArray:sourceImageSize:activeCameraReturnsMirroredImage:scale:
face
faceSize
sharedApplication
interfaceOrientation
expressionFeatures
photoFaceWrappers:
photoDescription:withFaceCount:
width
height
left
right
bottom
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
boundingFrameForItems:
normalizedBoundingFrameForItems:
metric:inProximityOfMetric:item:threshold:
sequence:
feature
_feature
arrayWithObject:
line:
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
featureWithFutharkFeature:canvasSize:context:
featureWithVisionRequest:textResult:canvasSize:context:
_axmVisionFeatureForFeature:canvasSize:context:
_assembleLayoutSequences:canvasSize:context:
_assembleLayoutLines:
_assembleLayoutRegions:
textLineWithBoundingBox:sequences:canvasSize:context:
textRegionWithBoundingBox:lines:canvasSize:context:
textDocumentWithBoundingBox:regions:canvasSize:context:
_textDocumentWithFeatures:canvasSize:context:error:
value:withObjCType:
getValue:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
axmEncodeRect:forKey:
axmDecodeRectForKey:
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
observer
callback
initWithSuiteName:
registerDefaults:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_queue_removeObserver:forSetting:
removeObjectsInArray:
boolForKey:
setBool:forKey:
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
removeObserverForAllSettings:
setWriteOutInputImages:
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
_defaults
_queue_settingObservers
initForReadingWithData:
setRequiresSecureCoding:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
isTrackable
_queue_trackerContainerForFeature:
initWithFeature:queue:
tracker
activeTimer
afterDelay:processBlock:cancelBlock:
queue_trackedFaces
processResult:
trackedFeatures
maximumSizeThreshold
setMaximumSizeThreshold:
maximumDistanceThreshold
setMaximumDistanceThreshold:
_queue_trackedFeatureContainers
_maximumSizeThreshold
_maximumDistanceThreshold
initWithQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setTracker:
setActiveTimer:
_tracker
_activeTimer
setAssetURL:
setName:
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
assetURL
name
creationDate
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
resourceValuesForKeys:error:
_name
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_assetURL
_initWithBackingType:
isMainDisplay
_updateDisplay:withConfiguration:
initWithInitializationCompletion:
setDisplayMonitor:
displayMonitor
addObserver:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
initWithCompletion:
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
currentMode
preferredScale
setScale:
mobileGestaltOrientation
setOrientation:
orientation
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_scale
_orientation
_physicalOrientation
_backingType
_referenceBounds
_imageOrientationForInterfaceOrientation:displayOrientation:
imageByApplyingOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
saveToURL:withOrientation:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:
_initWithLanguage:
operationWithLanguage:
operationWithSystemLanguage
lexiconLocale
language
_language
lexiconManager
tagger
dataDetector
numberWithUnsignedInteger:
enumerateText:locale:block:
_preprocessText:
punctuationCharacterSet
formUnionWithCharacterSet:
removeCharactersInString:
stringByTrimmingCharactersInSet:
symbolCharacterSet
componentsJoinedByString:
spellChecker
processText:withOperation:
_spellChecker
_lexiconManager
_tagger
_dataDetector
_globalWhitelistedWords
_localeWhitelistedWords
intValue
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByAppendingString:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
indexOfObject:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
pathExtension
hasPrefix:
lastPathComponent
stringByDeletingPathExtension
rangeOfString:
substringFromIndex:
processingDuration
setProcessingDuration:
totalDuration
setTotalDuration:
_processingDuration
_totalDuration
_queue_averageFramesProcessedPerSecond
_queue_averageFramesDroppedPerSecond
pipelineTimings
averageFramesProcessedPerSecond
averageFramesDroppedPerSecond
diagnosticReport
totalFramesProcessed
setTotalFramesProcessed:
totalFramesDropped
setTotalFramesDropped:
_isProcessingCaptureSessionFrames
_captureSessionProcessingBeginTime
_captureSessionProcessingEndTime
_queue_pipelineTimings
_totalFramesProcessed
_totalFramesDropped
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
axmValueWithCGAffineTransform:
filterWithName:withInputParameters:
outputImage
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
featureWithVisionRequest:humanResult:canvasSize:
setDispatchQueue:
_reallyCancel
setCancelled:
setPending:
setCancelBlock:
setProcessBlock:
dispatchQueue
isCancelled
dispatchTimer
automaticallyCancelPendingBlockUponSchedulingNewBlock
useWallTime
setActive:
setDispatchTimer:
cancelBlock
label
afterDelay:processBlock:
cancel
processBlock
setLabel:
setUseWallTime:
isActive
isPending
_cancelled
_automaticallyCancelPendingBlockUponSchedulingNewBlock
_useWallTime
_active
_pending
_processBlock
_cancelBlock
_label
_dispatchQueue
_dispatchTimer
captureOutput
setCaptureOutput:
_captureOutput
setPriority:
priority
defaultPriority
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
componentsSeparatedByString:
setIs3DLandmarks:
setResults:
is3DLandmarks
leftEye
pointsArrayForRegion:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
points
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
initWithVisionFaceLandmarks:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
_results
setClientID:
setIncludeImageInResult:
setDetectText:
setDetectScenes:
setDetectModelClassifications:
setDetectTraits:
setDetectFaces:
setDetectHumans:
setDetectHorizon:
setDetectRectangles:
setCorrectSpelling:
setTextDetectionLanguage:
setSpellCheckingLanguages:
clientID
correctSpelling
spellCheckingLanguages
voiceOverOptions
_detectText
_detectFaces
_detectScenes
_detectModelClassifications
_detectTraits
_detectRectangles
_detectHumans
_detectHorizon
_correctSpelling
_includeImageInResult
_clientID
_textDetectionLanguage
_spellCheckingLanguages
setRequest:
setOptions:
dispatchRequest:options:
request
options
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
_outputRequests
_audioSession
_state
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_request
_options
setWithObject:
allObjects
spellServer:findMisspelledWordInString:languages:wordCount:countOnly:correction:
correctSpellingInText:withLanguages:
textContainsMisspelling:withLanguages:
setSpellChecker:
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
recognitionOptions
setRecognitionOptions:
_recognitionOptions
stringValue
corners
boundingBox
confidence
landmarks
landmarks3d
expressionsAndConfidence
pose
blurScore
exposureScore
transform
angle
getBytes:length:
_serializeWithCoder:orDictionary:
debugNameForFeatureType:
_nameForOCRFeatureType:
faceExpressionsAndConfidence
_valueForTextFeature
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
_isTextFeatureValueSpeakable
_append:toList:
faceLandmarks
faceLandmarks3d
stringForExpression:
confidenceForExpression:
barcodeType
ocrFeatureType
assetMetadata
horizonAngle
isEqualToAXMVisionFeature:
expressionForString:
featureWithMetadata:canvasSize:
featureWithVisionRequest:classificationResult:canvasSize:
flattenedFeatureList:
dictionaryRepresentation
colorInfo
facePose
horizonTransform
isBarcode
isHuman
isModelClassification
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
_featureType
_subfeatures
_barcodeType
_ocrFeatureType
_detectionLanguage
_frame
_normalizedFrame
_value
_isValueSpeakable
_taggedText
_colorInfo
_assetMetadata
_blur
_confidence
_horizonTransform
_horizonAngle
_faceLandmarks
_faceLandmarks3d
_faceExpressionsAndConfidence
_likelyExpression
_faceId
_facePose
_canvasSize
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:
unitTestingFeature
unitTestingFaceFeature
unitTestingHorizonFeature
taggedText
initWithFormat:arguments:
numberWithUnsignedLongLong:
unsignedLongLongValue
_systemReport:
startTimingTaskWithIdentifier:message:
endTimingTaskWithIdentifier:message:
startMemoryTaskWithIdentifier:message:
endMemoryTaskWithIdentifier:message:
_queue_timingTasks
_queue_memoryTasks
processInfo
physicalMemory
knownSceneClassifications
possibleSceneClassifications
setSoundPlayer:
setConfigChangedObserverToken:
_buildEngine
_wireEngineConnections
_startEngineIfNeeded:
configChangedObserverToken
initForReading:error:
soundPlayer
scheduleFile:atTime:completionHandler:
play
setEngine:
engine
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
nextAvailableInputBus
connect:to:fromBus:toBus:format:
isRunning
startAndReturnError:
_logAudioFileInfo:
_engine
_soundPlayer
_configChangedObserverToken
setConnected:
setEnabled:
setNodeQueue:
_connected
_enabled
_nodeQueue
systemReport
privilegedSystemReport
triggerWithImage:options:cacheKey:resultHandler:
triggerWithImage:cacheKey:options:resultHandler:
triggerWithImage:cacheKey:options:clientID:resultHandler:
setCaptureNode:
setImageNode:
setTextDetector:
setSceneDetector:
setFaceDetector:
setTraitDetector:
setVisionRecognitionOptions:
captureNode
imageNode
textDetector
sceneDetector
faceDetector
traitDetector
_captureNode
_imageNode
_sceneDetector
_faceDetector
_traitDetector
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
axmAppendIndentation:
errorWithDomain:code:userInfo:
allocWithZone:
dateFormatFromTemplate:options:locale:
stringFromNumber:
valueWithBytes:objCType:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
checking token against lexicon
lex #%ld: '%@' flags:%lu prob:%.2f partialProb:%.2f usageCount:%u
v24@?0^{_LXEntry=}8*16
Using locale for lexicon: %@ (language: %@) (id: %@)
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Screen grab not supported on Simulator yet
imageWidth
Ti,N,V_imageWidth
imageHeight
Ti,N,V_imageHeight
size
Ti,N,V_size
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
screenOrientation
Tq,N,V_screenOrientation
imageMirrored
TB,N,V_imageMirrored
smiling
TB,N,V_smiling
blinking
TB,N,V_blinking
Horizon Detector
Could not evaluate. requestHandler was nil
Could not evaluate: %@
mainColors
mainColorWeights
input arrays must be same length
supportsSecureCoding
TB,R
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
remainingColorWeight
Td,N,V_remainingColorWeight
Face Detector
AXMServiceConnection
AXMService being deallocated: %@
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
Connection to service interrupted. client: %@
v8@?0
Connection to service invalidated. client: %@
Failed to get service proxy: %@
v16@?0@"NSError"8
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
ItemAppeared
aiff
sounds
ItemDisappeared
Could not produce URL for soundID: %@
sound file URL does not exist: %@
speechSequence
T@"NSAttributedString",R,N
interruptsAndClearsQueue
TB,N,V_interruptsAndClearsQueue
soundFileURLs
T@"NSArray",R,N
AXMSpeechFormatter does not implement getObjectValue:forString:errorDescription:
formattingBlock
T@?,C,N,V_formattingBlock
modelURL
Model Detector
Model loading not supported on this platform
Model Detector not available on this platform
T@"NSURL",&,N,V_modelURL
region
orientation
Screen Capture
@"CIImage"24@?0@"NSDictionary"8^@16
screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
Traits
v40@?0{vImage_Buffer=^vQQQ}8
Error evaluating color information: %@
sampleFrequency
Tq,N,V_sampleFrequency
shouldEvaluateColorInformation
TB,N,V_shouldEvaluateColorInformation
colorDistanceTheshold
Td,N,V_colorDistanceTheshold
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
diagnosticsEnabled
prioritySchedulingEnabled
thresholdPriority
featureTrackingEnabled
v24@?0@"AXMVisionResult"8@"NSError"16
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
------------------------------------------------------
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
With priority scheduling, there can be at most 1 evaluation node per cycle
'writeOutInputImages' is enabled. Writing input images to %@
InputImage
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld tracking:%@ diagnostics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
A context must be provided
A source must be provided
Engine queue is at capacity
identifier
T@"NSString",C,V_identifier
axMediaUtilsService
T@"AXMService",&,N,V_axMediaUtilsService
cache
T@"AXMVisionEngineCache",&,N,V_cache
taskDispatcher
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
diagnosticInfo
T@"AXMVisionEngineDiagnosticInfo",&,N,V_diagnosticInfo
sourceNodes
evaluationNodes
maximumQueueSize
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TQ,V_thresholdPriority
isCachingEnabled
TB,R,N
cacheSize
Tq,R,N
TB,N,GisFeatureTrackingEnabled,V_featureTrackingEnabled
trackedFaces
trackedText
trackedRectangles
trackedModelClassifiers
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
T@"NSUUID",&,N,V_identifier
context
T@"AXMVisionPipelineContext",&,N,V_context
source
T@"AXMSourceNode",&,N,V_source
AXMLanguage
v16@?0@"NSNotification"8
AXMLanguage<%p> languageID: '%@'. Locale: <%p> '%@'
primaryComponent
secondaryComponent
languageCode
locale
T@"NSString",&,N,V_primaryComponent
T@"NSString",&,N,V_secondaryComponent
T@"NSString",&,N,V_languageCode
T@"NSLocale",&,N,V_locale
languageDisplayName
T@"NSString",R,N
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
inputImage
appliedOrientation
sourceProvidesResults
sourceparams
features
analysisOptions
error
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
A creation node must return a valid image
pipeline context error. CVPixelBufferCreate returned NULL buffer for ocr pixel buffer. CVReturn: %@
error initializing vImageBuffer from CVPixelBuffer: %@
error initializing vImageBuffer from CGImageRef: %@
No inputImage or pixelBuffer found to initialize vImage_Buffer
%@-%ld-%ldx%ld.%@
T@"NSMutableArray",&,N,V_features
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
result
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
visionImageRequestHandler
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
shouldProcessRemotely
TB,N,V_shouldProcessRemotely
resultHandlers
T{CGSize=dd},R,N
visionImageRequestHandlerIsLoaded
cacheKey
T@"<NSCopying>",&,N,V_cacheKey
shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
evaluationExclusivelyUsesVisionFramework
TB,N,V_evaluationExclusivelyUsesVisionFramework
creationTime
Td,N,V_creationTime
processingStartTime
Td,N,V_processingStartTime
processingEndTime
Td,N,V_processingEndTime
TQ,N,V_sequenceID
AXMMinimumCharacterHeight
AXMDetectDiacritics
AXMReturnSubFeatures
AXMMinimizeFalsePositives
detectionFlavor
Text Detector
Will detect text with Futhark flavor
Could not evaluate with OCR. Input pixel buffer was nil
'writeOutOCRInputImages' is enabled. Writing OCR input images to %@
OCRInput
Will detect text with parameters: [minCharHeight:%d] [minimizeFalseDetections:%d] [returnSubfeatures:%d] [detectDiacritics:%d] [language:%@]
Could not OCR image. OCR detection error: %@
Did detect futhark features:
  %@ text:'%@'
Did not detect any text features
Could not create text document: %@
Will detect text with Vision flavor
Will detect text with parameters: [minCharHeight:%lu] [minimizeFalseDetections:%d] [returnSubfeatures:%d] [detectDiacritics:%d] [language:%@]
Did detect VNTextObservations
Did not detect any VNTextObservations
supportedDetectionLanguages
T@"NSSet",R,N
TQ,N,V_detectionFlavor
minimumCharacterHeight
Td,N,V_minimumCharacterHeight
detectDiacritics
TB,N,V_detectDiacritics
returnSubFeatures
TB,N,V_returnSubFeatures
minimizeFalsePositives
TB,N,V_minimizeFalsePositives
AXMGlobalTagLocale
AXMGlobalTagIsSpeakable
AXMGlobalTagIsEvaluated
IsSpeakable
IsNonspeakable
v32@?0@"NSString"8@16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
AXMTaggedText<%p> : '%@'
 Locale: %@
 Is evaluated? %@
 Is speakable? %@
 Speakable Text: '%@'
 Global Attributes:
  %@ : %@
 Tokens:
  '%@' [%ld %ld] : %@
T@"NSLocale",R,N
speakable
TB,N,GisSpeakable
speakableText
task should not be in the completed state
taskIsBeingProcessed should be YES
v20@?0@"AXMTask"8B16
taskIsBeingProcessed should be NO
count
isEmpty
delegate
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
Task should not be complete if being marked as complete
complete
TB,N,GisComplete,V_complete
taskCompleteBlock
T@?,C,N,V_taskCompleteBlock
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
maximumNumberOfRects
Tq,N,V_maximumNumberOfRects
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
redFloat
Td,R,N
greenFloat
blueFloat
hueFloat
saturationFloat
brightnessFloat
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
allColorMarkers
localizedName
T@"NSString",&,N,V_localizedName
handleRequest: expected nil completion block
didFinish: expected completion block, but found nil.
didCancel: expected completion block, but found nil.
synthesizer
T@"AVSpeechSynthesizer",&,N,V_synthesizer
currentRequestCompletionBlock
T@?,C,N,V_currentRequestCompletionBlock
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
AXMFeatureTracker<%p>: type:%ld loc:%@
type
TQ,R,N
currentLocation
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_currentLocation
value
faceId
AXMTag<%p>. [%@] [%lu %lu] '%@'
%@|%@|%@
Detected|Detector|PhoneNumber
Detected|Detector|Date
Detected|Regex|Email
Unknown
range
T{_NSRange=QQ},R,N
originalText
isPunctuation
isWhitespace
isSentenceTerminator
isPhoneNumber
isDate
isEmailAddress
Error updating audio session: %@
notificationObserverTokens
T@"NSMutableArray",&,N,V_notificationObserverTokens
session
T@"AVAudioSession",&,N,V_session
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
isSupported
componentState
Tq,N,V_componentState
AXMFeatures
AXMImage
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
There should be 0 or 1 OCR features
Top level text object should be the document
__AXMStringForVariablesSentinel
com.apple.accessibility.AXMediaUtilities
photo.description.faces
Accessibility
photo.description.blurriness.none
photo.description.blurriness.low
photo.description.blurriness.medium
photo.description.blurriness.high
photo.description.brightness.low
photo.description.brightness.high
detected.text.hint
detectedTextDescription
detectedFeatureDescription
detectedTextLanguage
AXMVisionResult<%p>: Image:%@ Results:%@ Speakable Description: %@
image
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSString",&,N,V_detectedFeatureDescription
T@"NSString",&,N,V_detectedTextDescription
colorInfoFeature
T@"AXMVisionFeature",R,N
assetMetadataFeature
localizedDetectedTextHint
T@"AXMLanguage",R,N
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
%@ playerItem:<%@>
legibility event: %@
targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
v32@?0@"NSTextCheckingResult"8Q16^B24
[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?
post
face.count
UIDevice
Unable to find class %s
/System/Library/Frameworks/UIKit.framework/UIKit
UIApplication
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
frame
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
height
bottom
width
left
right
normalizedFrame
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
no source features provided
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
Asset Metadata
AXMSetting
Did get KVO update for key: '%@'. change: %@
writeOutInputImages
TB,D,N
writeOutOCRInputImages
writeOutScreenCaptures
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
T@"<AXMFeatureTrackingManagerDelegate>",W,N,V_delegate
maximumSizeThreshold
Td,N,V_maximumSizeThreshold
maximumDistanceThreshold
Td,N,V_maximumDistanceThreshold
tracker
T@"AXMFeatureTracker",&,N,V_tracker
activeTimer
T@"AXMTimer",&,N,V_activeTimer
assetURL
name
creationDate
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
name:%@ created:%@ UTI:%@ typeDesc:%@
T@"NSURL",&,N,V_assetURL
T@"NSString",&,N,V_name
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
localizedTypeDescription
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
AXMDisplayManager
v24@?0@"FBSDisplayMonitor"8@"NSSet"16
AXMDisplayManager initialized: %@
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
Unable to look up screenInfo
main-screen-scale
Unable to look up screen scale
scale
main-screen-orientation
supportsDeepColor
Aixt/MEN2O2B7f+8m4TxUA
Unexpected physical screen orientaiton
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
displayMonitor
T@"FBSDisplayMonitor",&,N,V_displayMonitor
mobileGestaltOrientation
Td,N,V_mobileGestaltOrientation
frontBoardMainDisplay
T@"AXMDisplay",R,N
coreAnimationMainDisplay
isInitialized
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
backingType
Tq,N,V_backingType
T@"NSString",C,N,V_name
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
physicalOrientation
Tq,N,V_physicalOrientation
referenceBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
unknown
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
lexiconLocale
language
T@"AXMLanguage",R,N,V_language
Will process text: '%s'. language: %@
v16@?0@"AXMTag"8
v16@?0@"AXMTaggedText"8
Result text: '%s'
Will pre-process text: '%s'
.,!?
-axout-tmp
AX: Export Session status: %ld %@
-axtmp
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
face detect error: %@
face.smiling
face.blinking
face.number.format
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/msword
filetype.word
application/postscript
filetype.postscript
application/rtf
filetype.rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
video/
unknown file type: %@
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.sunglasses
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
FCRPreciseDetectionParameters
/System/Library/PrivateFrameworks/FaceCore.framework/FaceCore
FCRSetupParamMinFaceSize
FCRSetupParamNumberOfAngles
FCRFaceDetector
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
FCRExtractionParamExtractSmile
FCRExtractionParamExtractBlink
FCRFaceExpressionSmile
FCRFaceExpressionLeftEyeClosed
FCRFaceExpressionRightEyeClosed
UIAccessibilityIsVoiceOverRunning
processingDuration
Td,N,V_processingDuration
totalDuration
Td,N,V_totalDuration
AXMVisionEngineDiagnosticInfo
Engine Diagnostic Report:
  Recent work items:
   Processing time: %.3f. end-to-end time: %.3f
  Capture Session frames
    processed :%lld. (%.2f frames / second)
    dropped   :%lld. (%.2f frames / second)
totalFramesProcessed
TQ,N,V_totalFramesProcessed
totalFramesDropped
TQ,N,V_totalFramesDropped
pipelineTimings
averageFramesProcessedPerSecond
averageFramesDroppedPerSecond
diagnosticReport
com.apple.AXMediaUtilitiesService
contextQueue
%.4s
Pixel buffer info: width:%ld height:%ld bytesPerRow:%ld dataSize:%ld isPlanar:%ld planeCount:%ld format:%@
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
CIAffineTransform
Human Detector
%@.%@.TimerQueue
%@: Ignoring block scheduled for execution %.2f seconds from now.
%@ - %@
active
TB,N,GisActive,V_active
pending
TB,N,GisPending,V_pending
cancelled
TB,N,GisCancelled,V_cancelled
dispatchQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_dispatchQueue
dispatchTimer
T@"NSObject<OS_dispatch_source>",&,N,V_dispatchTimer
processBlock
T@?,C,N,V_processBlock
cancelBlock
T@?,C,N,V_cancelBlock
label
T@"NSString",&,N,V_label
automaticallyCancelPendingBlockUponSchedulingNewBlock
TB,N,V_automaticallyCancelPendingBlockUponSchedulingNewBlock
useWallTime
TB,N,V_useWallTime
Barcode
captureOutput
T@"AVCaptureMetadataOutput",&,N,V_captureOutput
Input text: '%@'
Input locale: '%@'
Token '%@' [%lu, %lu]
  Type: %@
  Lex Class: %@
  Language: %@
  Script: %@
  Named Entity: %@
  DerivedSubtoken: %@
v40@?0{?={?=qq}Q}8^B32
priority
effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
speech.formatter.email.address.standard.phonetic
 %@ 
speech.formatter.email.address.at.phonetic
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
Error decoding face landmark dict: %@
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
is3DLandmarks
TB,N,V_is3DLandmarks
results
T@"NSDictionary",&,N,V_results
clientID
includeImageInResult
detectText
detectScenes
detectModelClassifications
detectTraits
detectFaces
detectHumans
detectHorizon
detectRectangles
correctSpelling
spellCheckingLanguages
textDetectionLanguage
Tq,N,V_clientID
TB,N,V_detectText
TB,N,V_detectFaces
TB,N,V_detectScenes
TB,N,V_detectModelClassifications
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHumans
TB,N,V_detectHorizon
TB,N,V_correctSpelling
T@"AXMLanguage",&,N,V_textDetectionLanguage
T@"NSSet",&,N,V_spellCheckingLanguages
TB,N,V_includeImageInResult
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
Could not activate audio session: %@
request
T@"AXMOutputRequest",&,N,V_request
options
T@"AXMOutputRequestDispatchOptions",&,N,V_options
Using languages for spell checking: %s
spell-checking pass %ld of %ld
length of textToCheck is 0. break
Will look for misspelled word in text: '%s'. index: %ld
No misspelled words found. break
Misspelled word found at range [%ld, %ld], '%s'
replacing with correction: '%s' at range:[%ld %ld]
text after replacement: '%s'
No correction found
spellChecker
T@"AppleSpell",&,N,V_spellChecker
Source node not connected to any engine
Vision (Deprecated)
recognitionOptions
TQ,N,V_recognitionOptions
OCR (Deprecated)
Image Chr.. (Deprecated)
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceExpressions
AXMFeatureFacePose
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
Unknown AVMetadataObject
detectionLanguage
Error decoding face expression dict: %@
subfeatures
Error decoding subfeatures array: %@
color info
asset metadata
_valueForTextFeature is only valid for OCR features
subfeatures of a document should be regions
subfeatures of a region should be lines
subfeatures of a line should be sequences
textCharacter is not implemented
textDiacritic is not implemented
_isTextFeatureValueSpeakable is only valid for OCR features
Document
Region
Line
Char
Diacrit
Brightness
Blur
Color
Face
Human
Classification
ModelClassifier
MediaLegibility
AssetMetadata
Horizon
Rectangle
AXMVisionFeature<%p> %@
ID:%lu [faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
value:'%@' type:%@ 
value:'%@' 
value:'%.2f' 
asset info [%@] 
horizon transform. angle: %f 
frame:%@ (normalized:%@) confidence:%.2f
dictionaryRepresentation
T@"NSDictionary",R,N
featureType
isBarcode
isFace
isHuman
isClassification
isBrightness
isBlur
isHorizon
isColor
isMediaLegibility
isAssetMetadata
isRectangle
isModelClassification
isOCR
isTextDocument
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
confidence
isValueSpeakable
barcodeType
ocrFeatureType
colorInfo
T@"AXMVisionFeatureColorInfo",R,N
assetMetadata
T@"AXMVisionFeatureAssetMetadata",R,N
blur
faceLandmarks
T@"AXMVisionFeatureFaceLandmarks",R,N
faceLandmarks3d
faceExpressionsAndConfidence
likelyExpression
facePose
T{?=[4]},R,N
horizonTransform
T{CGAffineTransform=dddddd},R,N
horizonAngle
Tf,R,N
isTrackable
taggedText
T@"AXMTaggedText",R,N
TimeProfiling
TIME PROFILE: START '%@'
 - '%@'
Time profiling error. task identifier already in progress: %@
TIME PROFILE: FINISHED '%@' 
- '%@' 
Time profiling error. task identifier was not in progress: %@
Elapsed: %@ s
MEMORY PROFILE: START '%@'
Memory profiling error. task identifier already in progress: %@
MEMORY PROFILE: FINISHED '%@' 
Memory profiling error. task identifier was not in progress: %@
Could not look up MACH_TASK_BASIC_INFO. err:%@ (%s)
Could not look up TASK_VM_INFO. err:%@ (%s)
Physical Footprint: %@
%.2fMB
TaskInfo:{[res:%@] [resMax:%@] [virt:%@]} VMInfo:{[virt:%@] [res:%@] [resPk:%@] [dev:%@] [devPk:%@] [intrnl:%@] [intrnlPk:%@] [xtrnl:%@] [xtrnlPk:%@] [ftPrnt:%@]}
TaskInfo:
Resident Size:%@
Resident Size Maximum:%@
Virtual Size:%@
VM Info:
Virtual Size:%@
Resident Size:%@
Resident Size Peak:%@
Device:%@
Device Peak:%@
Internal:%@
Internal Peak:%@
External:%@
External Peak:%@
Physical Footprint:%@
com.apple.private.photoanalysisd.access
This process does not have the '%@' entitlement, and will not be able to connect to the photo analysis service. Scene classification will be limited
Scene Detector
possibleSceneClassifications
Could not handle audio request: %@. Error:%@
Could not start engine: %@
engine
T@"AVAudioEngine",&,N,V_engine
soundPlayer
T@"AVAudioPlayerNode",&,N,V_soundPlayer
configChangedObserverToken
T@,&,N,V_configChangedObserverToken
datatype-%lu
AXMNodeID
AXNodeEnabled
Subclass should override
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
title
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
nodeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
requiresVisionFramework
enabled
TB,N,GisEnabled,V_enabled
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
VoiceOver
screenCapture
text
scene
face
trait
use init()
captureNode
T@"AXMScreenCaptureNode",W,N,V_captureNode
imageNode
T@"AXMImageNode",W,N,V_imageNode
textDetector
T@"AXMTextDetectorNode",W,N,V_textDetector
sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
faceDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
traitDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
Library/Accessibility
Failed to create AXMediaUtilities working directory at path: %@. error: %@
com.apple.Accessibility
AXM-Prefs
AXM-Service
AXM-Cache
AXM-Screen
AXM-OCR
AXM-Text
AXM-TextLayout
AXM-Results
AXM-Priority
AXM-Track
AXM-Output
AXM-Speech
AXM-Sound
AXM-Haptic
AXM-MediaDesc
AXM-Time
AXM-Memory
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
, %@
AXDateFormatter
{CGVector=dd}
{CGAffineTransform=dddddd}
AXMPointValue
T{CGPoint=dd},R,N
AXMVectorValue
T{CGVector=dd},R,N
AXMSizeValue
AXMRectValue
AXMAffineTransformValue
AXMLexiconManager
UnitTesting
AXMScreenGrabber
FaceWrapper
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMFaceDetectorNode
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMOutputRequest
AXMOutputRequestDispatchOptions
AXMSpeechFormatter
AXMSpeechBlockFormatter
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMFeatureTrackingManagerDelegate
AXMTaskDispatcherDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMLanguage
AXMPhoneNumberSpeechFormatter
AXMVisionPipelineContext
AXMTextDetectorNode
AXMTaggedText
AXMTaskDispatcher
AXMTask
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAVCaptureSessionNode
AXMFeatureTracker
AXMTag
AXMAudioSession
AXMOutputComponent
AXMVisionResult
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMDataDetector
AXFaceDetection
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMTextLayoutManager
AXMExtras
AXMAssetMetadataNode
_AXMSettingObserver
AXMSettings
AXMFeatureTrackingManager
_AXMFeatureTrackerContainer
AXMVisionFeatureAssetMetadata
FaceCoreLightWrapper
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMTextProcessingOperation
AXMTextProcessor
AXMVisionEnginePipelineDiagnosticInfo
AXMVisionEngineDiagnosticInfo
AXMHumanDetectorNode
AXMTimer
AXMBarcodeNode
AXMTagger
AXMEvaluationNode
AXMEmailAddressSpeechFormatter
AXMVisionFeatureFaceLandmarks
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMSpellChecker
AXMSourceNode
AXMVisionNode
AXMOCRNode
AXMImageCharacteristicsNode
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
Private
AXMProfiling
AXMSceneDetectorNode
AXMSoundComponent
AXMSpeechFormatterCache
AXMVisionEngineNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMGeomerty
@16@0:8
B24@0:8@16
B32@0:8@16@24
^{_LXLexicon=}24@0:8@16
v16@0:8
@"NSMutableDictionary"
r^v24@0:8@16
@68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48B56^@60
B16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
i16@0:8
q16@0:8
i32@0:8q16q24
v32@0:8^q16^q24
v20@0:8i16
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v24@0:8q16
v20@0:8B16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@24@0:8@16
v24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v32@0:8@16@24
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
@"NSMutableAttributedString"
@"NSMutableArray"
B40@0:8o^@16@24o^@32
@24@0:8@?16
@?16@0:8
B24@0:8^@16
@"NSURL"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v40@0:8@16@24@32
v40@0:8@"AXMFeatureTrackingManager"16@"AXMFeatureTracker"24@"NSNumber"32
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
@24@0:8^{_NSZone=}16
v32@0:8@16q24
v32@0:8@"NSMutableString"16q24
@28@0:8@16B24
@24@0:8#16
v24@0:8Q16
@"_AXMVisionEngineAnalysisTask"
@"AXMFeatureTrackingManager"
@"NSMapTable"
@"NSString"
@"AXMVisionEngineCache"
@"AXMVisionEngineDiagnosticInfo"
@"AXMService"
@"AXMTaskDispatcher"
@32@0:8@16@24
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@"NSLocale"
@"NSMutableCharacterSet"
{CGSize=dd}16@0:8
^{CGColorSpace=}16@0:8
^{__CVBuffer=}20@0:8B16
@"CIImage"
@"NSDictionary"
^{__CVBuffer=}
^{CGColorSpace=}
{CGSize="width"d"height"d}
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSNumber"
@"<NSCopying>"
@"AXMVisionResult"
@"VNImageRequestHandler"
@"FKTextDetector"
@"AXMTextLayoutManager"
@40@0:8@16@24@?32
v48@0:8@16@24{_NSRange=QQ}32
B32@0:8{_NSRange=QQ}16
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
@32@0:8Q16^{_NSRange=QQ}24
v40@0:8{_NSRange=QQ}16@32
v40@0:8@16{_NSRange=QQ}24
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
d24@0:8@16
@48@0:8d16d24d32@40
@32@0:8@16d24
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v40@0:8@16@24@?32
@"AVSpeechSynthesizer"
@"<AXMAVCaptureSessionNodeDelegate>"
@"AXMVisionFeature"
@104@0:8{?={?=qq}Q}16@40@48@56@64@72@80@88@96
@48@0:8Q16@24@32@40
@"AXMSpeechFormatter"
{?="range"{?="location"q"length"q}"attributes"Q}
@"NSTextCheckingResult"
v32@0:8Q16Q24
v32@0:8Q16@24
@"AVAudioSession"
v32@0:8q16@?24
@40@0:8@16@24@32
@24@0:8q16
@"NSMutableOrderedSet"
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
v48@0:8@16@24Q32@?40
v48@0:8@16Q24Q32@?40
@"NSRegularExpression"
@"AXMSpeechFormatterCache"
@32@0:8@16q24
@48@0:8@16{CGSize=dd}24B40f44
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
d24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@48@0:8@16{CGSize=dd}24@40
@56@0:8@16{CGSize=dd}24@40^@48
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@48@0:8@16#24@32^@40
@"<AXMFeatureTrackingManagerDelegate>"
@"AXMFeatureTracker"
@"AXMTimer"
@"NSDate"
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8{CGSize=dd}16
q32@0:8q16q24
q28@0:8q16B24
@40@0:8q16q24^q32
@36@0:8q16B24^q28
@"AXMLanguage"
@"AXMSpellChecker"
@"AXMLexiconManager"
@"AXMTagger"
@"AXMDataDetector"
v32@0:8d16@?24
v40@0:8d16@?24@?32
@"AVCaptureMetadataOutput"
@20@0:8B16
@24@0:8Q16
@"NSSet"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputRequest"
@"AXMOutputRequestDispatchOptions"
@"AppleSpell"
@40@0:8@16{CGSize=dd}24
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48{CGSize=dd}56@72
@56@0:8@16@24{CGSize=dd}32@48
@48@0:8@16@24{CGSize=dd}32
@"NSDictionary"16@0:8
{?=[4]}16@0:8
{CGAffineTransform=dddddd}16@0:8
f16@0:8
q24@0:8@16
@"AXMTaggedText"
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceLandmarks"
{?="columns"[4]}
@96@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88
@"AVAudioEngine"
@"AVAudioPlayerNode"
@"<AXMVisionEngineNodeConnectionDelegate>"
v48@0:8@16@24@32@?40
v56@0:8@16@24Q32q40@?48
@"AXMScreenCaptureNode"
@"AXMImageNode"
@"AXMTextDetectorNode"
@"AXMSceneDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
333333
MbP?
@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
f024
