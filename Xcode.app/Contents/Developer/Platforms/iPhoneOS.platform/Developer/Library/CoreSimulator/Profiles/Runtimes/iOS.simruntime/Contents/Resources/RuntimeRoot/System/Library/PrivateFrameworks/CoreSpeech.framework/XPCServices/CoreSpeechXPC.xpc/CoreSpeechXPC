CoreSpeechXPCProtocol
ServiceDelegate
NSXPCListenerDelegate
NSObject
CoreSpeechXPC
ResourcePathHash
CSEventMonitor
CSAsset
CSAssetManagerEnablePolicyFactory
CSPreferences
CSVoiceTriggerRTModel
NSSecureCoding
NSCoding
CSAssetManagerEnablePolicy
LanguageCode
CSLanguageCodeUpdateMonitor
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
Utils
RTModel
NSXPC
CSUtils
CSFirstUnlockMonitor
CSAssetManagerEnablePolicyMac
CSPolicy
CSEventMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitor
CSSpringboardStartMonitor
CSConfig
CSVoiceTriggerAssetMetaUpdateMonitor
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
interfaceWithProtocol:
class
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
setExportedInterface:
xpcConnection:hasEntitlement:
invalidate
setExportedObject:
resume
isEqual:
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
listener:shouldAcceptNewConnection:
serviceListener
setDelegate:
init
dictionaryWithObjects:forKeys:count:
getAccessoryFallbackFamilyLocalTable
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
isEqualToString:
getAccessoryFallbackFamilyLocal:
modelLocale
selectFallbackModelForLocale:downloadedModels:preinstalledModels:
regularExpressionWithPattern:options:error:
localizedDescription
length
firstMatchInString:options:range:
numberOfRanges
rangeAtIndex:
substringWithRange:
assetHashInResourcePath:
weakObjectsHashTable
_stopMonitoring
dealloc
addObject:
count
_startMonitoringWithQueue:
removeObject:
enumerateObservers:
CSEventMonitorDidReceiveEvent:
addObserver:
removeObserver:
enumerateObserversInQueue:
notifyObserver:
.cxx_destruct
_observers
_queue
hybridEndpointerAssetFilename
alloc
initWithResourcePath:configFile:configVersion:
defaultManager
stringByAppendingPathComponent:
fileExistsAtPath:
_decodeJson:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
dictionary
numberWithBool:
getNumberForKey:category:default:
boolValue
resourcePath
stringWithFormat:
path
assetForAssetType:resourcePath:configVersion:
fallBackAssetResourcePath
defaultFallBackAssetForSmartSiriVolume
getBoolForKey:category:default:
getStringForKey:category:default:
hashFromResourcePath
isEqualAsset:
configVersion
_decodedInfo
_path
_resourcePath
_configVersion
assetManagerEnabledPolicy
_storeModeEnabled
numberWithInt:
setFileLoggingLevel:
fileLoggingLevel
intValue
baseDir
assistantLogDirectory
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
array
CSSATBasePath
URLWithString:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
getResourceValue:forKey:error:
lastPathComponent
getUserVoiceProfileUploadPathWithEnrolledLanguageList:
_CSSATUploadPath
removeItemAtPath:error:
_getEnrolledLanguageList
enumeratorAtPath:
_isDirectory:
pathExtension
copyItemAtPath:toPath:error:
fileExistsAtPath:isDirectory:
_CSSATUpdatePath
contentsOfDirectoryAtPath:error:
isCurrentDeviceCompatibleWithVoiceProfileAt:
_markSATEnrollmentSuccessForLanguageCode:
getSiriLanguageWithFallback:
_markSATEnrollmentMigratedForLanguageCode:
_markSATEnrollmentWithMarker:forLanguage:
createFileAtPath:contents:attributes:
deviceProductType
_deviceCategoryForDeviceProductType:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
predicateWithFormat:
filteredArrayUsingPredicate:
dataWithContentsOfURL:
deviceCategoryStringRepresentationForCategoryType:
setWithObjects:
containsObject:
containsString:
floatValue
interstitialRelativeDirForLevel:
enumerateObjectsUsingBlock:
integerValue
sharedPreferences
voiceTriggerEnabled
voiceTriggerInCoreSpeech
twoShotNotificationEnabled
setFileLoggingIsEnabled:
fileLoggingIsEnabled
voiceTriggerAudioLogDirectory
assistantAudioFileLogDirectory
getUserVoiceProfileFileList
getUserVoiceProfileUploadPath
notifyUserVoiceProfileUploadComplete
getUserVoiceProfileUpdateDirectory
notifyUserVoiceProfileUpdateReady
remoteVoiceTriggerDelayTime
remoteVoiceTriggerEndpointTimeoutWithDefault:
interstitialAbsoluteDirForLevel:
myriadFileLoggingEnabled
enableAudioInjection:
audioInjectionEnabled
setAudioInjectionFilePath:
audioInjectionFilePath
speakerIdEnabled
smartSiriVolumeSoftVolumeEnabled
audioSessionActivationDelay
maxNumLoggingFiles
containsValueForKey:
decodeObjectForKey:
encodeObject:forKey:
stringByAppendingString:
string
base64EncodedStringWithOptions:
substringToIndex:
appendFormat:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithData:hash:locale:digest:signature:certificate:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
_addAssetManagerEnabledConditions
_subscribeEventMonitors
sharedInstance
subscribeEventMonitor:
isSpringboardStarted
addConditions:
isFirstUnlocked
_notifyObserver:withLanguageCode:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
_didReceiveLanguageCodeUpdate
_notifyToken
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
numberWithUnsignedInteger:
isEnabled
_fetchRemoteMetaData
setCallback:
assetOfType:language:
assetOfType:language:completion:
installedAssetOfType:language:
installedAssetOfType:language:completion:
_isReadyToUse
predicateForAssetType:language:
installedAssetOfType:withPredicate:
_fetchRemoteAssetOfType:withPredicate:
errorWithDomain:code:userInfo:
installedAssetOfType:withPredicate:completion:
_installedAssetOfType:withPredicate:
getCSAssetOfType:
_installedAssetOfType:withPredicate:completion:
_assetQueryForAssetType:withPredicate:localOnly:
runQueryAndReturnError:
predicate
_findLatestInstalledAsset:
stopQuery
startQuery:
state
isLatestCompareTo:
initWithAssetType:
setPredicate:
setQueriesLocalAssetInformationOnly:
supportHybridEndpointer
unsignedIntegerValue
predicateForfetchRemoteMetadataForAssetType:
_runAssetQuery:completion:
_updateFromRemoteToLocalAssets:forAssetType:
isInstalled
isDownloading
cancelDownloadAndReturnError:
purgeAndReturnError:
CSAssetManagerDidDownloadNewAsset:
_downloadAsset:withComplete:
_startDownloadingAsset:progress:completion:
objectForKey:
doubleValue
setProgressHandler:
requiredDiskSpaceIsAvailable:error:
_defaultDownloadOptions
beginDownloadWithOptions:
resumeDownload:
adjustDownloadOptions:completion:
setObject:forKeyedSubscript:
sharedManager
assetForCurrentLanguageOfType:completion:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
assetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
currentLanguageCode
addObserver:forAssetType:
removeObserver:forAssetType:
_csAssetsDictionary
_enablePolicy
_currentLanguageCode
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
supportPremiumAssets
componentsJoinedByString:
predicateWithFormat:argumentArray:
stringByReplacingOccurrencesOfString:withString:
date
stringFromDate:
bytes
stringWithCapacity:
dataWithLength:
mutableBytes
RTModel
_sha1:
_sha256:
valueForEntitlement:
supportRaiseToSpeak
shouldRunVTOnCS
UTF8String
rootQueueWithFixedPriority:
csAudioProcessingQueuePriority
supportContinuousVoiceTrigger
supportKeywordDetector
supportOpportunisticZLL
supportSelfTriggerSuppression
supportCSTwoShotDecision
supportSmartVolume
supportImplictTraining
canLookupVoiceTriggerModelFromMobileAsset
supportSAT
hasRemoteCoreSpeech
supportPacketDecoding
shouldDeinterleaveAudioOnCS
supportCircularBuffer
getFixedPrioritySerialQueueWithLabel:fixedPriority:
getFixedHighPrioritySerialQueueWithLabel:
deviceProductVersion
systemUpTime
deviceUserAssignedName
deviceBuildVersion
_checkFirstUnlocked
_notifyObserver:withUnlocked:
CSFirstUnlockMonitor:didReceiveFirstUnlock:
_didReceiveFirstUnlockInQueue:
_didReceiveFirstUnlock:
_firstUnlocked
_checkAllConditionsEnabled
notifyCallback:
_monitors
_conditions
_callback
_didReceiveNewSpeechEndpointAssetMetaData
_notifyObserver:
localURL
_compatibilityVersion
stringValue
appendString:
_version
_footprint
attributes
isPremium
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
inputRecordingSampleByteDepth
inputRecordingFramesPerPacket
inputRecordingSampleRate
inputRecordingSampleRateNarrowBand
inputRecordingBytesPerFrame
inputRecordingBytesPerPacket
inputRecordingNumberOfChannels
inputRecordingDurationInSecs
inputRecordingSampleBitDepth
EncryptionAudioSampleByteDepth
inputRecordingEncoderAudioQuality
inputRecordingSampleRateConverterAlgorithm
inputRecordingBufferDuration
audioConverterBitrate
channelForOutputReference
channelForProcessedInput
zeroFilterWindowSizeInMs
zeroFilterApproxAbsSpeechThreshold
daysBeforeRemovingLogFiles
_asssetMetaUpdatedKey
_didReceiveNewVoiceTriggerAssetMetaData
v56@0:8Q16Q24@32@40@?48
v56@0:8Q16Q24@"NSArray"32@"NSArray"40@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">48
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@24@0:8@16
@40@0:8@16@24@32
v16@0:8
v24@0:8@16
v24@0:8@?16
@"NSHashTable"
@"NSObject<OS_dispatch_queue>"
@40@0:8Q16@24@32
B36@0:8@16@24B32
@"NSDictionary"
@"NSString"
@24@0:8Q16
Q24@0:8@16
v20@0:8B16
@24@0:8^@16
d16@0:8
d24@0:8d16
@24@0:8q16
B20@0:8B16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@64@0:8@16@24@32@40@48@56
@32@0:8@16@24
@"NSData"
v32@0:8@16@24
v28@0:8@16B24
v32@0:8@16@"NSString"24
v32@0:8Q16@?24
@32@0:8Q16@24
v40@0:8Q16@24@?32
@36@0:8Q16@24B32
v32@0:8@16@?24
v32@0:8Q16@24
v32@0:8@16Q24
v40@0:8@16@?24@?32
@"CSPolicy"
@"NSMutableDictionary"
@20@0:8i16
@28@0:8@16i24
@"NSMutableArray"
f16@0:8
I16@0:8
q16@0:8
S16@0:8
i16@0:8
r*16@0:8
corespeech.xpc
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
v8@?0
en-US
de-AT
de-DE
en-IE
en-IN
en-NZ
it-IT
ja-JP
zh-CN
zh-TW
nb-NO
nl-BE
nl-NL
sv-SE
tr-TR
fi-FI
he-IL
es-ES
es-US
es-CL
es-MX
fr-FR
fr-BE
fr-CA
fr-CH
ko-KR
zh-HK
yue-CN
da-DK
ms-MY
pt-BR
ru-RU
th-TH
ar-AE
ar-SA
nohash
((?:[a-z]|[0-9])*)\.asset
+[CSUtils(ResourcePathHash) assetHashInResourcePath:]
Serial CSEventMonitor queue
corespeech.json
hybridendpointer.json
hybridendpointer_marsh.json
/System/Library/PrivateFrameworks/CoreSpeech.framework
+[CSAsset fallBackAssetResourcePath]
-[CSAsset initWithResourcePath:configFile:configVersion:]
-[CSAsset _decodeJson:]
-[CSAsset getNumberForKey:category:default:]
-[CSAsset getStringForKey:category:default:]
configVersion:%@ resourcePath:%@ path:%@
path
T@"NSString",R,N,V_path
resourcePath
T@"NSString",R,N,V_resourcePath
dictionary
T@"NSDictionary",R,N
hashFromResourcePath
T@"NSString",R,N
configVersion
T@"NSString",R,N,V_configVersion
com.apple.voicetrigger
com.apple.voicetrigger.notbackedup
productType
VoiceTrigger Enabled
VoiceTrigger CoreSpeech Enabled
Enable Two Shot Notification
com.apple.demo-settings
StoreDemoMode
File Logging Level
Library
Logs/CrashReporter/VoiceTrigger/audio/
/Logs/CrashReporter/Assistant/
SpeechLogs
-[CSPreferences assistantAudioFileLogDirectory]
VoiceTrigger/SAT
Caches/VoiceTrigger/SATUpdate
Caches/VoiceTrigger/SATUpload
-[CSPreferences getUserVoiceProfileUploadPathWithEnrolledLanguageList:]
json
-[CSPreferences notifyUserVoiceProfileUploadComplete]
-[CSPreferences getUserVoiceProfileUpdateDirectory]
-[CSPreferences notifyUserVoiceProfileUpdateReady]
Enable VoiceTrigger Upon VoiceProfile Sync For Language
enrollment_completed
enrollment_migrated
audio
-[CSPreferences _markSATEnrollmentWithMarker:forLanguage:]
+[CSPreferences isCurrentDeviceCompatibleWithVoiceProfileAt:]
pathExtension='json'
kCSDeviceCategory_Unknown
kCSDeviceCategory_iOS_NonAop
kCSDeviceCategory_iOS_Aop
kCSDeviceCategory_macOS
iPad3,4
iPad3,5
iPad3,6
iPad4,1
iPad4,2
iPad4,3
iPad4,4
iPad4,5
iPad4,6
iPad4,7
iPad4,8
iPad4,9
iPad5,1
iPad5,2
iPad5,3
iPad5,4
iPad6,7
iPad6,8
iPad6,11
iPad6,12
iPhone5,1
iPhone5,2
iPhone5,3
iPhone5,4
iPhone6,1
iPhone6,2
iPhone7,1
iPhone7,2
macOS
iPad
iPhone
+[CSPreferences _deviceCategoryForDeviceProductType:]
Remote VoiceTrigger Delay
Remote VoiceTrigger Endpoint Timeout
VoiceTrigger/interstitial
Myriad File Logging Enabled
-[CSPreferences enableAudioInjection:]
Audio Injection Enabled
-[CSPreferences setAudioInjectionFilePath:]
Audio Injection File Path
-[CSPreferences audioInjectionFilePath]
-[CSPreferences audioInjectionFilePath]_block_invoke
v32@?0@8Q16^B24
SpeakerId Enabled
SmartSiriVolume SoftVolume Enabled
Audio Session Activation Delay
Max Number Logging Files
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
supportsSecureCoding
TB,R
modelData
T@"NSData",R,N,V_modelData
modelLocale
T@"NSString",R,N,V_modelLocale
modelHash
T@"NSString",R,N,V_modelHash
digest
T@"NSData",R,N,V_digest
signature
T@"NSData",R,N,V_signature
certificate
T@"NSData",R,N,V_certificate
B8@?0
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor _didReceiveLanguageCodeUpdate]
v16@?0@8
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsMac
com.apple.MobileAsset.SpeechEndpointAssets
-[CSAssetManager init]
Serial CSAssetManager queue
v12@?0B8
-[CSAssetManager assetOfType:language:]
-[CSAssetManager assetOfType:language:completion:]
-[CSAssetManager installedAssetOfType:language:]
-[CSAssetManager installedAssetOfType:language:completion:]
v24@?0@"ASAsset"8@"NSError"16
-[CSAssetManager _installedAssetOfType:withPredicate:]
-[CSAssetManager _installedAssetOfType:withPredicate:completion:]_block_invoke
v24@?0@"NSArray"8@"NSError"16
-[CSAssetManager _assetQueryForAssetType:withPredicate:localOnly:]
-[CSAssetManager _runAssetQuery:completion:]
-[CSAssetManager _runAssetQuery:completion:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _fetchRemoteAssetOfType:withPredicate:]
-[CSAssetManager _updateFromRemoteToLocalAssets:forAssetType:]
-[CSAssetManager _defaultDownloadOptions]
-[CSAssetManager _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetManager _downloadAsset:withComplete:]_block_invoke
v16@?0@"NSError"8
-[CSAssetManager _startDownloadingAsset:progress:completion:]
v24@?0@"NSDictionary"8@"NSError"16
-[CSAssetManager _startDownloadingAsset:progress:completion:]_block_invoke
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
currentLanguageCode
+[CSAssetManager(Utils) predicateForAssetType:language:]
(%@ == %K)
(%@ IN %K)
((%K == nil) OR (%K != %@))
 && 
com.apple.corespeech
-[CSAsset(RTModel) RTModel]
%02x
com.apple.
com.apple.private.
InternalBuild
-[CSFirstUnlockMonitor _stopMonitoring]
Serial CSPolicy queue
v12@?0i8
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssets.cached-metadata-updated
Languages
Footprint
Premium
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.cached-metadata-updated
%s Received a request for VoiceTriggerRTModel for Firmware Version : %{public}d.%{public}d
%s Failed to create regular expression : %{public}@
%s Fallback asset resource path : %{public}@
%s %{public}@
%s Cannot find corespeech asset from resourcePath : %{public}@
%s Configuration file is not exists : %{public}@
%s Cannot read configuration file : %{public}@
%s Cannot decode configuration json file : %{public}@
%s Configuration json file is not expected format
%s Cannot access to %{public}@ %{public}@ using default value
%s Couldn't create speech log directory at path %{public}@ %{public}@
%s Cannot delete existing SATUpload Diretory : %{public}@
%s Cannot create SAT Upload Directory : %{public}@
%s Cannot create directory(%{public}@)
%s Cannot copy file from %{public}@ to %{public}@ : %{public}@
%s PHS update directory already exists, remove before we move forward
%s Failed to delete PHS update directory
%s Failed to create PHS update directory
%s We need SAT directory, deleting the file with same name first
%s Failed to get device hash list %{public}@
%s Processing sync data from device hash: %{public}@
%s Error to copy profile from %{public}@ to %{public}@, error: %{public}@
%s language: %{public}@, enableVTAfterSyncLanguage: %{public}@, currSiriLanguage: %{public}@
%s Enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@ and enrolled language: %{public}@
%s VoiceTrigger does not exist for this platform, not setting VoiceTriggerEnabled
%s Not enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@
%s Sucessfully migrated language %{public}@
%s Migrated language %{public}@ but failed to mark SAT enrollment
%s Sucessfully marked as migrated for language : %{public}@
%s Failed to mark migrated for language : %{public}@
%s Failed to remove update path [%{public}@] upon migration completion, error: %{public}@
%s Coudn't mark SAT enrollment %{public}@ at path %{public}@
%s Marked SAT enrollment %{public}@ at path %{public}@
%s We can't mark SAT {public}%@ when there is no audio directory
%s ERR: Unknown device. returning false: %{public}@
%s Malformed audio-dir URL for string <%{public}@>:url
%s ERR: reading contents of audioDir: %{public}@
%s No jsonFiles found in %{public}@: jsonFiles.count=%{public}lu
%s Unexpected: empty JSON data for file: %{public}@
%s Error reading metaDict at path: %{public}@
%s metaProductType: %{public}@
%s vtprofile: currDevice=[%{public}@:%{public}@] ; vpDirDevice=[%{public}@:%{public}@]
%s VoiceProfile MATCH
%s VoiceProfile MIS-MATCH
%s Could not find productType in VT-Meta file, trying next one
%s No compatible VT profile found for CurrDevice: %{public}@
%s Unknown Device category for deviceProduceType: %@
%s enableAudioInection: is only available on internal builds
%s setAudioInjectionFilePath: is only available on internal builds
%s kCSAudioInjectionFilePathKey is not array type
%s kCSAudioInjectionFilePathKey array size = %d
%s kCSAudioInjectionFilePathKey doesn't have NSString as an array entry
%s AssetManager cannot be turned on since springBoard is not started
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s Siri language is nil, falling back to %@
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s init-_currentLanguageCode: %{public}@
%s Not able to fetch remote meta now, registering for callback
%s CSAssetManager cannot query for nil language
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, predicate: %{public}@, error: %{public}@
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s ::: %{public}s
%s ::: predicate: %{public}@
%s ::: %{public}s; query: %{public}@
%s Error running asset query: error %{public}@
%s ::: Request Fetching RemoteMetaData
%s ::: Request fetching remote asset
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading; %{public}@
%s ::: download completed successfully.
%s Attempting to download asset %{public}@
%s Failure resuming paused voice asset %{public}@
%s Asset doesn't need downloading, invoking completion
%s _currentLanguageCode changed: %{public}@
%s ERR: Unknown AssetType: %{public}lu
%s CS doesn't have ndblobbuilder!
%s Stop monitoring : First unlock
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceTriggerAssets</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsWatch</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMarsh</string>
<string>com.apple.MobileAsset.VoiceTriggerAssetsMac</string>
</array>
</dict>
</plist>
