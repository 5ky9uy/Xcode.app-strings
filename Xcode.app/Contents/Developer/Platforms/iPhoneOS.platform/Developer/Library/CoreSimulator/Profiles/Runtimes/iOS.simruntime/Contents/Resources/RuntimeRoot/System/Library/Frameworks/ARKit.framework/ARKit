333333$@
MbP?
MbP?
N3acv15CovariantVectorINS_8tracking9detection15IAlignedSurfaceIfEENS_24CovariantVectorInterfaceIS4_NS5_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS8_EEEEEEEE
N3acv24CovariantVectorInterfaceINS_8tracking9detection15IAlignedSurfaceIfEENS0_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS7_EEEEEE
N3acv24CovariantVectorInterfaceINS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS3_EEEE
N3acv16ICovariantVectorINS_8geometry8ISurfaceIfEEEE
N3acv20ICovariantVectorBaseE
N3acv9SingletonINS_7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection15IAlignedSurfaceIfEENS2_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS9_EEEEEEEENS_22SingletonNoInitFunctorISE_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8tracking9detection15IAlignedSurfaceIfEENS3_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISA_EEEEEEEENS_14default_deleteISF_EENS_9allocatorISF_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8tracking9detection15IAlignedSurfaceIfEENS3_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISA_EEEEEEEEEE
N3acv7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection15IAlignedSurfaceIfEENS1_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS8_EEEEEEEE
N3acv15UncopyableClassINS_7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection15IAlignedSurfaceIfEENS2_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS9_EEEEEEEEEE
N3acv9SingletonINS_7ClassIdINS_24CovariantVectorInterfaceINS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS5_EEEEEENS_22SingletonNoInitFunctorIS9_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorIS6_EEEEEENS_14default_deleteISA_EENS_9allocatorISA_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorIS6_EEEEEEEE
N3acv7ClassIdINS_24CovariantVectorInterfaceINS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS4_EEEEEE
N3acv15UncopyableClassINS_7ClassIdINS_24CovariantVectorInterfaceINS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS5_EEEEEEEE
NSt3__120__shared_ptr_pointerIPN3acv8geometry10PointCloudIfEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv8geometry10PointCloudIfEEEE
NSt3__120__shared_ptr_pointerIPNS_6vectorINS_10shared_ptrIN3acv8tracking9detection15IAlignedSurfaceIfEEEENS_9allocatorIS8_EEEENS_14default_deleteISB_EENS9_ISB_EEEE
NSt3__114default_deleteINS_6vectorINS_10shared_ptrIN3acv8tracking9detection15IAlignedSurfaceIfEEEENS_9allocatorIS8_EEEEEE
NSt3__120__shared_ptr_pointerIPN3acv15CovariantVectorINS1_8tracking9detection15IAlignedSurfaceIfEENS1_24CovariantVectorInterfaceIS6_NS7_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISA_EEEEEEEENS_14default_deleteISF_EENS_9allocatorISF_EEEE
NSt3__114default_deleteIN3acv15CovariantVectorINS1_8tracking9detection15IAlignedSurfaceIfEENS1_24CovariantVectorInterfaceIS6_NS7_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISA_EEEEEEEEEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
16ARKitLogAppender
N4tlog9IAppenderE
N4tlog13PatternLayoutE
N4tlog7ILayoutE
N4tlog18IAppenderParameterE
%Y-%m-%d %H:%M:%S
NSt3__120__shared_ptr_pointerIPN4tlog8LogLevelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN4tlog8LogLevelEEE
NSt3__120__shared_ptr_pointerIP16ARKitLogAppenderNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
NSt3__114default_deleteI16ARKitLogAppenderEE
@(#)PROGRAM:ARKit  PROJECT:ARKit-33
????????????????
N4tlog15ConsoleAppenderE
NSt3__120__shared_ptr_pointerIPN4tlog15ConsoleAppenderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN4tlog15ConsoleAppenderEEE
N3acv18ComputationStorageE
NSt3__120__shared_ptr_pointerIPN3acv18ComputationStorageENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3acv18ComputationStorageEEE
NSt3__120__shared_ptr_pointerIPN3acv18ComputationHistoryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3acv18ComputationHistoryEEE
N3acv23IWeakComputationHistoryE
N3acv19IComputationHistoryE
N3acv18ComputationHistoryE
N3acv22WeakComputationHistoryE
N3acv23IComputationHistoryImplE
N4tlog6LoggerE
N3acv20IHashableComputationE
N3acv11IdGeneratorE
N3acv4math12ICameraModelE
N3acv4math7ICameraE
N3acv4math13PinholeCameraE
N3acv4math18PinholeCameraModelE
NSt3__120__shared_ptr_pointerIPNS_18basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_14default_deleteIS6_EENS4_IS6_EEEE
NSt3__114default_deleteINS_18basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEEEE
N3acv4math10CameraTypeE
N3acv9NamedEnumINS_4math10CameraTypeEEE
N3acv4EnumINS_4math10CameraTypeEEE
N3acv10INamedEnumE
N3acv9SingletonINS_9NamedEnumINS_4math10CameraTypeEE7NameMapENS4_11InitNameMapEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv9NamedEnumINS1_4math10CameraTypeEE7NameMapENS_14default_deleteIS6_EENS_9allocatorIS6_EEEE
NSt3__114default_deleteIN3acv9NamedEnumINS1_4math10CameraTypeEE7NameMapEEE
N3acv9NamedEnumINS_4math10CameraTypeEE7NameMapE
NSt3__120__shared_ptr_pointerIPNS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS5_IS7_EEEENS_14default_deleteIS9_EENS5_IS9_EEEE
NSt3__114default_deleteINS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS5_IS7_EEEEEE
N3acv9NamedEnumINS_4math10CameraTypeEE18NamedEnumExceptionE
NSt3__120__shared_ptr_pointerIPN3acv4math18PinholeCameraModelENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN3acv4math18PinholeCameraModelEEE
NSt3__120__shared_ptr_pointerIPN3acv4math13PinholeCameraENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN3acv4math13PinholeCameraEEE
N3acv4time10TimerAppleE
GB42ARGBf00Lf0C2
800L
f024
ABGR
g61b
svuy024f
?N3acv8graphics6BufferIhEE
N3acv8graphics6BufferItEE
N3acv8graphics6BufferIfEE
N3acv8graphics11ColorFormatE
N3acv9NamedEnumINS_8graphics11ColorFormatEEE
N3acv4EnumINS_8graphics11ColorFormatEEE
N3acv5IEnumE
N3acv9SingletonINS_9NamedEnumINS_8graphics11ColorFormatEE7NameMapENS4_11InitNameMapEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv9NamedEnumINS1_8graphics11ColorFormatEE7NameMapENS_14default_deleteIS6_EENS_9allocatorIS6_EEEE
NSt3__114default_deleteIN3acv9NamedEnumINS1_8graphics11ColorFormatEE7NameMapEEE
N3acv9NamedEnumINS_8graphics11ColorFormatEE7NameMapE
N3acv9NamedEnumINS_8graphics11ColorFormatEE18NamedEnumExceptionE
N3acv8graphics14ImageValueTypeE
N3acv9NamedEnumINS_8graphics14ImageValueTypeEEE
N3acv4EnumINS_8graphics14ImageValueTypeEEE
N3acv9SingletonINS_9NamedEnumINS_8graphics14ImageValueTypeEE7NameMapENS4_11InitNameMapEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv9NamedEnumINS1_8graphics14ImageValueTypeEE7NameMapENS_14default_deleteIS6_EENS_9allocatorIS6_EEEE
NSt3__114default_deleteIN3acv9NamedEnumINS1_8graphics14ImageValueTypeEE7NameMapEEE
N3acv9NamedEnumINS_8graphics14ImageValueTypeEE7NameMapE
N3acv9NamedEnumINS_8graphics14ImageValueTypeEE18NamedEnumExceptionE
NSt3__120__shared_ptr_pointerIPhN3acv8graphics10FreeBufferENS_9allocatorIhEEEE
N3acv8graphics10FreeBufferE
NSt3__120__shared_ptr_pointerIPhN3acv8graphics6BufferIhE12noop_deleterENS_9allocatorIhEEEE
N3acv8graphics6BufferIhE12noop_deleterE
NSt3__120__shared_ptr_pointerIPtN3acv8graphics10FreeBufferENS_9allocatorItEEEE
NSt3__120__shared_ptr_pointerIPtN3acv8graphics6BufferItE12noop_deleterENS_9allocatorItEEEE
N3acv8graphics6BufferItE12noop_deleterE
NSt3__120__shared_ptr_pointerIPfN3acv8graphics10FreeBufferENS_9allocatorIfEEEE
NSt3__120__shared_ptr_pointerIPfN3acv8graphics6BufferIfE12noop_deleterENS_9allocatorIfEEEE
N3acv8graphics6BufferIfE12noop_deleterE
N3acv12TypeToStringIhEE
N3acv16TypeToStringBaseIhNS_12TypeToStringIhEEEE
N3acv10UncopyableE
N3acv12TypeToStringItEE
N3acv16TypeToStringBaseItNS_12TypeToStringItEEEE
N3acv12TypeToStringIfEE
N3acv16TypeToStringBaseIfNS_12TypeToStringIfEEEE
N3acv12TypeToStringIKhEE
N3acv16TypeToStringBaseIKhNS_12TypeToStringIS1_EEEE
N3acv12TypeToStringIKtEE
N3acv16TypeToStringBaseIKtNS_12TypeToStringIS1_EEEE
N3acv12TypeToStringIKfEE
N3acv16TypeToStringBaseIKfNS_12TypeToStringIS1_EEEE
NSt3__120__shared_ptr_pointerIPN3acv8graphics11ImageBufferIhEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv8graphics11ImageBufferIhEEEE
NSt3__120__shared_ptr_pointerIPN3acv8graphics11ImageBufferItEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv8graphics11ImageBufferItEEEE
NSt3__120__shared_ptr_pointerIPN3acv8graphics11ImageBufferIfEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv8graphics11ImageBufferIfEEEE
N3acv8graphics12ConvertImageE
N3acv19HashableComputationINS_8graphics12ConvertImageEEE
NSt3__120__shared_ptr_pointerIPN3acv8graphics12ConvertImageENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN3acv8graphics12ConvertImageEEE
N3acv9SingletonINS_7ClassIdINS_19HashableComputationINS_8graphics12ConvertImageEEEEENS_22SingletonNoInitFunctorIS6_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_19HashableComputationINS1_8graphics12ConvertImageEEEEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_19HashableComputationINS1_8graphics12ConvertImageEEEEEEE
N3acv7ClassIdINS_19HashableComputationINS_8graphics12ConvertImageEEEEE
N3acv15UncopyableClassINS_7ClassIdINS_19HashableComputationINS_8graphics12ConvertImageEEEEEEE
N3acv9SingletonINS_7ClassIdINS_20IHashableComputationEEENS_22SingletonNoInitFunctorIS3_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_20IHashableComputationEEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_20IHashableComputationEEEEE
N3acv7ClassIdINS_20IHashableComputationEEE
N3acv15UncopyableClassINS_7ClassIdINS_20IHashableComputationEEEEE
N3acv9SingletonINS_7ClassIdINS_8graphics12ConvertImageEEENS_22SingletonNoInitFunctorIS4_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_8graphics12ConvertImageEEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_8graphics12ConvertImageEEEEE
N3acv7ClassIdINS_8graphics12ConvertImageEEE
N3acv15UncopyableClassINS_7ClassIdINS_8graphics12ConvertImageEEEEE
 C333=
NSt3__120__shared_ptr_pointerIPN3acv6vision10algorithms23HorizontalPlaneDetectorENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv6vision10algorithms23HorizontalPlaneDetectorEEE
N3acv8geometry3RayIN3cva6MatrixIfLj2ELj1EEEEE
NSt3__120__shared_ptr_emplaceIN3acv8geometry17IndexedPointCloudIfEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorIfNS_9allocatorIfEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN3acv6vision10algorithms19TemporalPlanarModelENS_9allocatorIS4_EEEE
N5boost6detail18sp_counted_impl_pdIPNS_18default_color_typeENS_21checked_array_deleterIS2_EEEE
N5boost6detail15sp_counted_baseE
N5boost21checked_array_deleterINS_18default_color_typeEEE
NSt3__120__shared_ptr_pointerIPNS_6vectorImNS_9allocatorImEEEENS_14default_deleteIS4_EENS2_IS4_EEEE
NSt3__114default_deleteINS_6vectorImNS_9allocatorImEEEEEE
NSt3__120__shared_ptr_pointerIPN3acv8geometry17IndexedPointCloudIfEENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv8geometry17IndexedPointCloudIfEEEE
NSt3__120__shared_ptr_pointerIPN3acv6vision10algorithms21TemporalPlaneDetectorENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv6vision10algorithms21TemporalPlaneDetectorEEE
.AN3acv4time5TimerINSt3__16chrono8durationIxNS2_5ratioILl1ELl1000EEEEEEE
N3acv4time6ITimerE
N3acv6vision10estimation26LeastSquaresPlaneEstimatorIfEE
N3acv6vision10estimation15IPlaneEstimatorIfEE
NSt3__120__shared_ptr_pointerIPN3acv6vision10estimation26LeastSquaresPlaneEstimatorIfEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN3acv6vision10estimation26LeastSquaresPlaneEstimatorIfEEEE
NSt3__120__shared_ptr_pointerIPN3acv6vision10algorithms34VerticalAndHorizontalPlaneDetectorENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv6vision10algorithms34VerticalAndHorizontalPlaneDetectorEEE
NSt3__120__shared_ptr_pointerIPN3acv6vision10algorithms21VerticalPlaneDetectorENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv6vision10algorithms21VerticalPlaneDetectorEEE
NSt3__120__shared_ptr_emplaceINS_6vectorImNS_9allocatorImEEEENS2_IS4_EEEE
N3acv6vision10estimation19LinearPoseEstimatorE
AN3acv6vision10estimation26LeastSquaresPlaneEstimatorIdEE
N3acv6vision10estimation15IPlaneEstimatorIdEE
N3acv6vision10estimation20RansacPlaneEstimatorIfEE
N3acv6vision10estimation20RansacPlaneEstimatorIdEE
N3acv6vision6marker8BCHCoderE
NSt3__120__shared_ptr_pointerIPNS_5arrayIN3acv6vision7feature5PixelIfEELm4EEENS_14default_deleteIS7_EENS_9allocatorIS7_EEEE
NSt3__114default_deleteINS_5arrayIN3acv6vision7feature5PixelIfEELm4EEEEE
N3acv6vision6marker18MarkerDetectorImplE
NSt3__120__shared_ptr_pointerIPN3acv6vision6marker18MarkerDetectorImplENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN3acv6vision6marker18MarkerDetectorImplEEE
N3acv8tracking9detection27VerticalOrHorizontalSurfaceIfEE
N3acv8tracking9detection15IAlignedSurfaceIfEE
N3acv8geometry8ISurfaceIfEE
N3acv8tracking9detection36VerticalAndHorizontalSurfaceDetectorIfEE
N3acv8tracking9detection23IAlignedSurfaceDetectorIfEE
NSt3__120__shared_ptr_pointerIPN3acv8tracking9detection36VerticalAndHorizontalSurfaceDetectorIfEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN3acv8tracking9detection36VerticalAndHorizontalSurfaceDetectorIfEEEE
N3acv8tracking9detection35VerticalAndHorizontalSurfaceTrackerIfEE
N3acv4math4PoseIfLNS0_16CoordinateSystemE0ELS2_0EEE
NSt3__117bad_function_callE
NSt3__110__function6__funcIZN3acv8geometry13sampleUniformIfNS_11__wrap_iterIPKN3cva6MatrixIfLj3ELj1EEEEENS_20back_insert_iteratorINS_6vectorIS8_NS_9allocatorIS8_EEEEEENS_8functionIFRS9_SB_EEEEEvT0_SM_T1_RKNS7_IT_Lj3ELj1EEET2_E3$_0NSE_IST_EESK_EE
NSt3__110__function6__baseIFRKN3cva6MatrixIfLj3ELj1EEENS_11__wrap_iterIPS5_EEEEE
ZN3acv8geometry13sampleUniformIfNSt3__111__wrap_iterIPKN3cva6MatrixIfLj3ELj1EEEEENS2_20back_insert_iteratorINS2_6vectorIS6_NS2_9allocatorIS6_EEEEEENS2_8functionIFRS7_S9_EEEEEvT0_SK_T1_RKNS5_IT_Lj3ELj1EEET2_E3$_0
N3acv8geometry12BoundingBox2IfLNS0_16BoundingBoxFlagsE1EEE
NSt3__120__shared_ptr_emplaceIN3acv8tracking9detection13SurfaceExtentIfEENS_9allocatorIS5_EEEE
NSt3__120__shared_ptr_pointerIPN3acv8tracking9detection27VerticalOrHorizontalSurfaceIfEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN3acv8tracking9detection27VerticalOrHorizontalSurfaceIfEEEE
N3acv15CovariantVectorINS_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS_24CovariantVectorInterfaceIS4_NS5_INS2_15IAlignedSurfaceIfEENS5_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorISA_EEEEEEEEEE
N3acv24CovariantVectorInterfaceINS_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS0_INS2_15IAlignedSurfaceIfEENS0_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorIS9_EEEEEEEE
NSt3__120__shared_ptr_pointerIPNS_6vectorINS_10shared_ptrIN3acv8tracking9detection27VerticalOrHorizontalSurfaceIfEEEENS_9allocatorIS8_EEEENS_14default_deleteISB_EENS9_ISB_EEEE
NSt3__114default_deleteINS_6vectorINS_10shared_ptrIN3acv8tracking9detection27VerticalOrHorizontalSurfaceIfEEEENS_9allocatorIS8_EEEEEE
NSt3__120__shared_ptr_pointerIPN3acv15CovariantVectorINS1_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS1_24CovariantVectorInterfaceIS6_NS7_INS4_15IAlignedSurfaceIfEENS7_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISC_EEEEEEEEEENS_14default_deleteISI_EENS_9allocatorISI_EEEE
NSt3__114default_deleteIN3acv15CovariantVectorINS1_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS1_24CovariantVectorInterfaceIS6_NS7_INS4_15IAlignedSurfaceIfEENS7_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISC_EEEEEEEEEEEE
N3acv9SingletonINS_7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS2_INS4_15IAlignedSurfaceIfEENS2_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorISB_EEEEEEEEEENS_22SingletonNoInitFunctorISH_EEE11InitializerE
NSt3__120__shared_ptr_pointerIPN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS3_INS5_15IAlignedSurfaceIfEENS3_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISC_EEEEEEEEEENS_14default_deleteISI_EENS_9allocatorISI_EEEE
NSt3__114default_deleteIN3acv7ClassIdINS1_24CovariantVectorInterfaceINS1_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS3_INS5_15IAlignedSurfaceIfEENS3_INS1_8geometry8ISurfaceIfEENS1_16ICovariantVectorISC_EEEEEEEEEEEE
N3acv7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS1_INS3_15IAlignedSurfaceIfEENS1_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorISA_EEEEEEEEEE
N3acv15UncopyableClassINS_7ClassIdINS_24CovariantVectorInterfaceINS_8tracking9detection27VerticalOrHorizontalSurfaceIfEENS2_INS4_15IAlignedSurfaceIfEENS2_INS_8geometry8ISurfaceIfEENS_16ICovariantVectorISB_EEEEEEEEEEEE
NSt3__120__shared_ptr_pointerIPN3acv8tracking9detection35VerticalAndHorizontalSurfaceTrackerIfEENS_14default_deleteIS5_EENS_9allocatorIS5_EEEE
NSt3__114default_deleteIN3acv8tracking9detection35VerticalAndHorizontalSurfaceTrackerIfEEEE
NSt3__120__shared_ptr_emplaceIN3acv8geometry10PointCloudIfEENS_9allocatorIS4_EEEE
init
class
captureDateFromPresentationTimestamp:session:
exposureTargetOffset
exposureDuration
position
activeVideoMinFrameDuration
_intrinsicsFromSampleBuffer:focalLengthFallback:principalPointFallback:didUseFallbackIntrinsics:
dealloc
objectForKeyedSubscript:
floatValue
masterClock
dateWithTimeIntervalSinceNow:
decodeDoubleForKey:
setTimestamp:
decodeFloatForKey:
setExposureTargetOffset:
setExposureDuration:
setISO:
self
decodeObjectOfClass:forKey:
focalLength
principalPoint
setCameraIntrinsics:
decodeDataObject
decodeIntegerForKey:
setCameraPosition:
decodeBoolForKey:
setPixelBufferIsMirrored:
setTargetFramesPerSecond:
setCaptureDate:
setPixelBuffer:
encodeDouble:forKey:
encodeFloat:forKey:
dataWithBytes:length:
encodeDataObject:
encodeInteger:forKey:
encodeBool:forKey:
encodeObject:forKey:
supportsSecureCoding
isEqual:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
timestamp
encodeWithCoder:
initWithCoder:
initWithSampleBuffer:captureDevice:captureSession:
imageResolution
.cxx_destruct
captureDate
cameraIntrinsics
pixelBuffer
pixelBufferIsMirrored
cameraPosition
targetFramesPerSecond
shouldRestrictFrameRate
setShouldRestrictFrameRate:
_pixelBufferIsMirrored
_shouldRestrictFrameRate
_exposureTargetOffset
_ISO
_timestamp
_captureDate
_pixelBuffer
_exposureDuration
_cameraPosition
_targetFramesPerSecond
_cameraIntrinsics
allocWithZone:
initWithFocalLength:imageResolution:principalPoint:
copyWithZone:
_imageResolution
_focalLength
_principalPoint
stop
providedDataTypes
start
delegate
setDelegate:
powerUsage
setPowerUsage:
initWithMotionManager:
preferredInterval
setInterval:
_delegate
UUID
initWithIdentifier:transform:
copy
identifier
isEqualToAnchor:
transform
stringWithFormat:
_description:
referenceTransform
initWithTransform:
debugQuickLookObject
setTransform:
setReferenceTransform:
_identifier
_transform
_referenceTransform
isTracked
initWithIdentifier:transform:isTracked:
setIsTracked:
_isTracked
arrayWithObjects:count:
initWithIDMarkers:
countByEnumeratingWithState:objects:count:
markerID
markerSize
count
setUid:
numberWithUnsignedInteger:
addObject:
containsObject:
technique:didOutputResultData:timestamp:context:
isEqualToArray:
initWithIDMarker:
requiredSensorDataTypes
processData:
requestResultDataAtTimestamp:context:
.cxx_construct
_markers
_detector
_camera
_semaphore
_detectedMarkers
alloc
initWithMarkerID:transform:isTracked:
cameraTransform
trackingState
worldOriginTransform
lightEstimate
featurePoints
anchorsForCameraWithTransform:referenceOriginTransform:existingAnchors:anchorsToRemove:
_uid
setLightIntensity:
lightIntensity
_lightIntensity
points
initWithType:
setDistance:
setWorldTransform:
setLocalTransform:
initWithPointsVector:
_hitTestFromOrigin:withDirection:
pointCloudByApplyingTransform:
_pointsVector
setAcceleration:
acceleration
_acceleration
sessionStopped
date
camera
trackingStateReason
timeIntervalSinceNow
_baseKey
stringByAppendingString:
_recordBadFramePercentageFinal:
_recordBadFramePercentageWithBucket:
stringByAppendingFormat:
sessionStartedWithConfiguration:
sessionDidUpdateFrame:
_queue
_configClass
_startDate
_frameStartDate
_sessionTimeForLastBadFrameRecording
_initializingVIO
_frameCount
_badFrameCount
_positionInitialized
_minPos
_maxPos
initWithCameraPosition:
lightEstimation
setLightEstimation:
customSensors
deviceModel
latencyFrameCount
recordingConfigurationWithConfiguration:recordingTechnique:fileURL:
techniques
mutableCopy
initWithFileURL:sensorDataTypes:
indexOfObjectPassingTest:
removeObjectAtIndex:
insertObject:atIndex:
setTechniques:
cameraDeviceType
setCaptureDeviceType:
customCaptureSession
setCustomCaptureSession:
worldAlignment
setWorldAlignment:
audioDataOutput
setAudioDataOutput:
appendFormat:
_descriptionWithoutBrackets
appendString:
initWithAlignment:
isSupported
recordingConfigurationWithConfiguration:recordingTechnique:
isLightEstimationEnabled
setLightEstimationEnabled:
latencyFrameCountAdjustedForReplay
setCustomSensors:
setLatencyFrameCount:
_worldAlignment
_customSensors
_lightEstimation
_customCaptureSession
_audioDataOutput
_latencyFrameCount
markers
initWithDownscaleFactor:
addObjectsFromArray:
setMarkers:
initWithDeviceModel:latencyFrameCount:
relocalizationEnabled
setRelocalizationEnabled:
planeDetection
setPlaneDetection:
initWithPlaneDetection:
_relocalizationEnabled
_planeDetection
ensureTechniqueAndCustomSensorCompatibility
enumerateObjectsUsingBlock:
objectAtIndex:
replaceObjectAtIndex:withObject:
captureDeviceType
_captureDeviceType
_techniques
stringWithString:
length
captureDevice
captureSession
preferredFrameRateForPowerUsage:devicePosition:
lockForConfiguration:
activeFormat
videoSupportedFrameRateRanges
closestFrameRateIn:target:preferHigher:
setActiveVideoMaxFrameDuration:
setActiveVideoMinFrameDuration:
unlockForConfiguration
activeVideoMaxFrameDuration
localizedRecoverySuggestion
standardUserDefaults
valueForKey:
floatForKey:
objectAtIndexedSubscript:
maxFrameRate
minFrameRate
_adjustForPowerUsage
removeObserver:forKeyPath:
stringByAppendingPathComponent:
fileURLWithPath:
defaultCenter
finishRecording
addObserver:selector:name:object:
writeImageData:
writeOutCachedMotionDataIfPresent
writeAccelerometerMetadata:
writeGyroscopeMetadata:
writeDeviceOrientationMetadata:
markAsFinished
status
copyVideoToPhotoLibrary
dictionary
mainBundle
localizedStringForKey:value:table:
setObject:forKeyedSubscript:
technique:didFinishWithResult:
requestAuthorization:
error
finishWritingWithCompletionHandler:
sharedPhotoLibrary
creationRequestForAssetFromVideoAtFileURL:
performChanges:completionHandler:
defaultManager
checkResourceIsReachableAndReturnError:
removeItemAtURL:error:
localizedDescription
removeTemporaryVideoFile
assetWriterWithURL:fileType:error:
numberWithInt:
dictionaryWithObjects:forKeys:count:
numberWithFloat:
assetWriterInputWithMediaType:outputSettings:
setExpectsMediaDataInRealTime:
computeVideoTransformForDeviceOrientationWithCameraPosition:
assetWriterInputPixelBufferAdaptorWithAssetWriterInput:sourcePixelBufferAttributes:
addInput:
assetWriterInputWithMediaType:outputSettings:sourceFormatHint:
assetWriterInputMetadataAdaptorWithAssetWriterInput:
addTrackAssociationWithTrackOfInput:type:
addObserver:forKeyPath:options:context:
createFileMetadata
setMetadata:
startWriting
isFileURL
URLByDeletingLastPathComponent
resourceValuesForKeys:error:
boolValue
technique:didFailWithError:
isEqualToString:
currentDevice
orientation
setupAssetWriterWithImageData:
cmTimestampFromNSTimeInterval:
startSessionAtSourceTime:
removeAllObjects
initAssetWriterIfRequiredWithImageData:
writePixelBuffer:withTimestamp:
writeImageMetadata:withTimestamp:
isReadyForMoreMediaData
appendPixelBuffer:withPresentationTime:
writeData:toInputAdaptor:withIdentifier:
setIdentifier:
setDataType:
archivedDataWithRootObject:
setValue:
initWithItems:timeRange:
assetWriterInput
appendTimedMetadataGroup:
observeValueForKeyPath:ofObject:change:context:
outputFileURL
shouldSaveVideoInPhotosLibrary
setShouldSaveVideoInPhotosLibrary:
recordingTechniqueDelegate
setRecordingTechniqueDelegate:
_processingQueue
_assetWriter
_videoInput
_videoMetadataInput
_accelInput
_gyroInput
_deviceOrientationInput
_videoInputAdaptor
_accelInputAdaptor
_gyroInputAdaptor
_videoMetadataInputAdaptor
_deviceOrientationInputAdaptor
_inputIsReadySemaphore
_isWaitingUntilInputIsReady
_sensorDataTypes
_motionDataCache
_sessionSourceTime
_sessionStarted
_stopRecordingRequested
_shouldSaveVideoInPhotosLibrary
_outputFileURL
_recordingTechniqueDelegate
array
initWithParentContext:
firstObject
indexOfObject:
arrayWithCapacity:
gatheredData
parentContext
processResultData:timestamp:context:
componentsJoinedByString:
initWithTechniques:
setParentContext:
setGatheredData:
_parentContext
_gatheredData
initWithResultLatency:timeoutInterval:
_useFixedIntrinsics
_vioState
_vioStateSemaphore
_latestVisionFeaturePointDatas
_cachedFeaturePointCloud
_errorData
_cachedTrackingData
_lastPointCloudTrackingData
_resultSemaphore
_lastErrorLogTimestamp
_deviceModel
errorCode
setErrorCode:
_errorCode
setFeaturePoints:
_featurePoints
initWithTimestamp:
setVisionCameraTransform:
setVisionFeaturePoints:
setFeaturePointsForRendering:
visionFeaturePoints
visionCameraTransform
setTrackingState:
setCameraTransform:
_visionFeaturePoints
_trackingState
_visionCameraTransform
_cameraTransform
initWithCoefficients:
setLightEstimate:
_sphericalHarmonics
_lastLightIntensity
initWithPatchesVector:pivotAngle:
size
patches
pivot
_patchesVector
_angle
decodeCGSizeForKey:
encodeCGSize:forKey:
initWithIntrinsics:imageResolution:
eulerAngles
projectionMatrix
projectionMatrixWithViewportSize:orientation:zNear:zFar:
setTrackingStateReason:
intrinsics
setIntrinsics:
setImageResolution:
_trackingStateReason
_intrinsics
setMarkerID:
setMarkerSize:
markerWithID:andSize:
_markerID
_markerSize
commonInit
initWithFrame:
sharedApplication
statusBarOrientation
bounds
setAllowsTransparency:
setIgnoresSiblingOrder:
mainQueue
userInfo
objectForKey:
integerValue
addObserverForName:object:queue:usingBlock:
removeObserver:
layoutSubviews
_addObserver:
_removeObserver:
currentFrame
hitTest:types:
_anchorForNode:inFrame:
allValues
setWithArray:
scene
parent
allKeysForObject:
anchors
minusSet:
removeFromParent
removeObjectForKey:
view:didRemoveNode:forAnchor:
view:nodeForAnchor:
node
addChild:
view:didAddNode:forAnchor:
view:willUpdateNode:forAnchor:
_updateNode:forAnchor:projectionMatrix:camera:orientation:
view:didUpdateNode:forAnchor:
convertPoint:toScene:
setHidden:
setPosition:
setXScale:
setYScale:
setZPosition:
setZRotation:
capturedImage
_setBackgroundContentsWithBuffer:
_updateAnchors:camera:
session
session:didFailWithError:
session:cameraDidChangeTrackingState:
sessionWasInterrupted:
sessionInterruptionEnded:
session:didUpdateFrame:
session:didAddAnchors:
session:didUpdateAnchors:
session:didRemoveAnchors:
session:didChangeState:
setSession:
anchorForNode:
nodeForAnchor:
_session
_nodesByAnchorIdentifier
_lastFrameAnchors
_interfaceOrientation
_interfaceOrientationObserver
_viewportSize
_hitTestFromOrigin:withDirection:types:
_hitTestFromOrigin:withDirection:usingExtent:
hitTestFromOrigin:withDirection:
detectPlanes:withFrame:
sortDescriptorWithKey:ascending:
sortUsingDescriptors:
initWithCamera:timestamp:
setCapturedImage:
displayTransformWithViewportSize:orientation:
rawFeaturePoints
setAnchors:
referenceFeaturePoints
setReferenceFeaturePoints:
worldOrigin
setWorldOrigin:
trackingErrorData
setTrackingErrorData:
_cachedHorizontalPlaneData
_cachedVerticalPlaneData
_capturedImage
_anchors
_lightEstimate
_referenceFeaturePoints
_worldOrigin
_trackingErrorData
discoverySessionWithDeviceTypes:mediaType:position:
devices
initWithDevicePosition:deviceType:captureSession:
_validateCameraAuthorization
isRunning
setSessionPreset:
beginConfiguration
configureCaptureSession
commitConfiguration
sensor:didFailWithError:
configureCaptureDevice
startRunning
setRunning:
captureSessionStateChanged:
sensorDidStart:
isInterrupted
setInterrupted:
sensorDidPause:
removeObserver:name:object:
stopRunning
setSampleBufferDelegate:queue:
inputs
device
hasMediaType:
formatDescription
initWithDevice:error:
localizedFailureReason
outputs
_createAudioInput:
sampleBufferDelegate
sampleBufferCallbackQueue
addOutput:
setAlwaysDiscardsLateVideoFrames:
connectionWithMediaType:
isCameraIntrinsicMatrixDeliverySupported
setCameraIntrinsicMatrixDeliveryEnabled:
bestFormatForDevice:withResolution:pixelFormatType:frameRate:
setActiveFormat:
setProvidesStortorgetMetadata:
_configureCameraExposureForDevice:
_configureCameraFocusForDevice:
minExposureDuration
maxExposureDuration
authorizationStatusForMediaType:
running
requestAccessForMediaType:completionHandler:
defaultDeviceWithMediaType:
deviceInputWithDevice:error:
doubleValue
setExposureModeCustomWithDuration:ISO:completionHandler:
reason
isExposureModeSupported:
isExposurePointOfInterestSupported
setExposurePointOfInterest:
exposurePointOfInterest
setExposureMode:
isWhiteBalanceModeSupported:
setWhiteBalanceMode:
autoFocusSystem
isAutoFocusEnabled
isFocusPointOfInterestSupported
setFocusPointOfInterest:
focusPointOfInterest
isFocusModeSupported:
setFocusMode:
isSmoothAutoFocusSupported
setSmoothAutoFocusEnabled:
isLockingFocusWithCustomLensPositionSupported
hasPrefix:
lensPosition
setFocusModeLockedWithLensPosition:completionHandler:
formats
isVideoBinned
sensor:didOutputSensorData:
name
interrupted
sensorDidRestart:
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:didDropSampleBuffer:fromConnection:
initWithDevicePosition:deviceType:
videoOutput
setAutoFocusEnabled:
_previouslyRunning
_previousOutputDelegate
_previousOutputCallbackQueue
_captureQueue
_autoFocusEnabled
_running
_interrupted
_captureDevice
_captureSession
_videoOutput
_powerUsage
addEntriesFromDictionary:
errorWithDomain:code:userInfo:
center
extent
setAnchor:
alignment
gridExtent
visionTransform
activePlaneID
initWithIdentifier:transform:alignment:
setCenter:
setExtent:
setGridExtent:
setVisionTransform:
setActivePlaneID:
_alignment
_gridExtent
_activePlaneID
_center
_extent
_visionTransform
rotationMatrix
setRotationMatrix:
setWorldOriginTransform:
_deviceOrientationData
_trackingData
_deviceOrientationAlignment
_deviceOrientationReferenced
_trackingReferenced
_dataSemaphore
_worldOriginTransform
weakObjectsHashTable
setUnderlyingQueue:
object
_updateThermalState:
_updatePowerUsage
processInfo
runWithConfiguration:options:
_sessionDidFailWithError:
technique
_updateSessionWithConfiguration:options:
_updateSessionStateWithConfiguration:options:
state
pausedSensors
setState:
_stopAllSensors
_setTechnique:
removeObject:
_getObservers
configuration
thermalState
availableSensors
allObjects
_updateSensorsWithConfiguration:
runningSensors
_stopSensorsWithDataTypes:keepingDataTypes:
setConfiguration:
_startSensorsWithDataTypes:
_updateAnchorsForFrame:resultDatas:addedAnchors:updatedAnchors:removedAnchors:worldOriginUpdated:reinitializeExistingAnchors:
_sessionDidRemoveAnchors:
_sessionDidAddAnchors:
_sessionDidUpdateAnchors:
_sessionCameraDidChangeTrackingState:
_sessionDidUpdateFrame:
setObject:atIndexedSubscript:
indexOfObjectIdenticalTo:
setRunningSensors:
setAvailableSensors:
_imageSensorForConfiguration:existingSensor:
initWithMotionManager:alignment:
_replaceOrAddSensor:
removeOutput:
canAddOutput:
deviceType
setPausedSensors:
delegateQueue
_interruptSession
_endInterruption
code
pause
runWithConfiguration:
addAnchor:
removeAnchor:
setSessionOriginTransform:
_stateQueue
setDelegateQueue:
sessionOriginTransform
_technique
_worldTrackingTechnique
_lastProcessedFrame
_lastProcessedFrameSemaphore
_anchorsToAdd
_anchorsToRemove
_sessionOriginUpdated
_worldOriginInitialized
_observers
_observersSemaphore
_thermalStateObserver
_thermalState
_motionManger
_metrics
_delegateQueue
_state
_configuration
_availableSensors
_runningSensors
_pausedSensors
_sessionOriginTransform
initWithUUIDBytes:
getUUIDBytes:
ar_integerValue
ar_UUIDWithIntegerValue:
_commonInit
initWithFrame:options:
setCamera:
setZNear:
setZFar:
setScene:
clearColor
setBackgroundColor:
deviceOrientationDidChange:
_forceUpdateCamera
frame
sceneTime
pointOfView
removeFromParentNode
_hitTest:frame:types:
rootNode
addChildNode:
setPointOfView:
setDrawsCameraImage:
drawsCameraImage
background
contents
setContents:
setDebugOptions:
captureDeviceOutputConsumer
setCaptureDevice:
_renderCapturedPixelBuffer:
_updateCamera:
automaticallyUpdatesLighting
_updateLighting:
frameToRemoveRotationSnapshotOn
removeFromSuperview
setFrameToRemoveRotationSnapshotOn:
_removeAnchors
_addAnchors
_updateAnchors
_updateDebugVisualization:
_updateFramesPerSecondWithTarget:shouldRestrictFrameRate:
set_wantsSceneRendererDelegationMessages:
setPlaying:
removeObjectsInArray:
parentNode
zNear
zFar
setProjectionTransform:
setSimdTransform:
light
setLight:
setType:
sphericalHarmonicsCoefficients
set_sphericalHarmonics:
renderer:nodeForAnchor:
renderer:didAddNode:forAnchor:
renderer:willUpdateNode:forAnchor:
_updateNode:forAnchor:
renderer:didUpdateNode:forAnchor:
renderer:didRemoveNode:forAnchor:
createAxesNode:
createGeometryForPointCloud:
setGeometry:
setDeveloperPreferredFramesPerSecond:
_updatePreferredFramesPerSecond
developerPreferredFramesPerSecond
preferredFramesPerSecond
setPreferredFramesPerSecond:
window
windowWillRotateNotification:
windowWillAnimateRotateNotification:
windowDidRotateNotification:
cleanupLingeringRotationState
drawViewHierarchyInRect:afterScreenUpdates:
initWithImage:
setAutoresizingMask:
setFrame:
addSubview:
performWithoutAnimation:
windowRotationDuration
animateWithDuration:animations:
_renderer:updateAtTime:
_renderer:didApplyAnimationsAtTime:
_renderer:didSimulatePhysicsAtTime:
_renderer:didApplyConstraintsAtTime:
_renderer:willRenderScene:atTime:
_renderer:didRenderScene:atTime:
setAutomaticallyUpdatesLighting:
didMoveToWindow
_lastFrameTimestamp
_captureDeviceOutputConsumer
_lightNode
_cameraNode
_addedAnchors
_updatedAnchors
_removedAnchors
_worldOriginNode
_featurePointNode
_currentlyVisibleDebugPointerCloud
_anchorsSemaphore
_originalBackgroundContents
_arDebugOptions
_rotationSnapshot
_automaticallyUpdatesLighting
_drawsCameraImage
_developerPreferredFramesPerSecond
_frameToRemoveRotationSnapshotOn
material
diffuse
ambient
blackColor
setLightingModelName:
setLocksAmbientWithDiffuse:
redColor
createMaterialWithTexture:
boxWithWidth:height:length:chamferRadius:
setMaterials:
nodeWithGeometry:
greenColor
blueColor
geometrySourceWithData:semantic:vectorCount:floatComponents:componentsPerVector:bytesPerComponent:dataOffset:dataStride:
geometryElementWithData:primitiveType:primitiveCount:bytesPerIndex:
setPointSize:
setMinimumPointScreenSpaceRadius:
setMaximumPointScreenSpaceRadius:
geometryWithSources:elements:
colorWithRed:green:blue:alpha:
setFirstMaterial:
assetWithURL:
initializeAssetReaderWithAsset:
readFileMetadataFromAsset:
startReading
readMetadataIntoArrays
replayData
cancelReading
assetReaderWithAsset:error:
failWithError:
tracksWithMediaType:
dictionaryWithObject:forKey:
initWithTrack:outputSettings:
track:hasMetadataIdentifier:
createAndAddMetadataAdaptorForTrack:
formatDescriptions
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
unpackItemsOfClass:withIdentifier:inOutputAdaptor:
initForReadingWithData:
setRequiresSecureCoding:
setWithObjects:
decodeObjectOfClasses:forKey:
enumerateDataWithIdentifier:inOutputAdaptor:usingBlock:
compare:
sortUsingComparator:
replaySensorDelegate
replaySensorDidFinishLoadingFrames:
preloadNextPixelBuffers:
timeIntervalSince1970
tick
hasMoreData
replaySensorDidFinishReplayingData
hasImageDataForTime:
getNextImageData
hasAccelerometerDataForTime:
getNextAccelerometerData
hasGyroDataForTime:
getNextGyroData
hasDeviceOrientationDataForTime:
getNextDeviceOrientationData
requestNextPixelBufferForTimestamp:
nextTimedMetadataGroup
items
dataType
timeRange
value
copyNextSampleBuffer
metadata
numberValue
unsignedIntegerValue
stringValue
initWithDataFromFile:
setReplaySensorDelegate:
_arImageData
_arAccelerometerData
_arGyroData
_arDeviceOrientationData
_replayQueue
_timer
_startTime
_imageIndexForPreloading
_imageIndex
_accelDataIndex
_gyroDataIndex
_deviceOrientationDataIndex
_replayInProgress
_dataLoadedFromAsset
_nextSampleBuffer
_assetReader
_imageOutput
_oldMotionOutputMetadataAdaptor
_accelOutputMetadataAdaptor
_gyroOutputMetadataAdaptor
_imageOutputMetadataAdaptor
_deviceOrientationOutputMetadataAdaptor
_replaySensorDelegate
bytes
isEqualToData:
ambientIntensity
confidenceRating
setConfidenceRating:
_ambientIntensity
_confidenceRating
_sphericalHarmonicsCoefficients
appendBytes:length:
characterAtIndex:
substringToIndex:
numberWithUnsignedLong:
numberWithUnsignedInt:
intValue
_detectPlanesWithDetector:types:camera:featurePoints:inVisionCoordinates:
initWithDetectedSurfaces:detectionTypeMask:techniqueIdentifier:
_detectionTypeMask
_semaphoreResult
_surfaceDetector
_planeResultData
_detectionQueue
_detectionSemaphore
predicateWithBlock:
filteredArrayUsingPredicate:
techniqueIdentifier
_updatedAnchor:forSurface:identifier:referenceOriginTransform:
_anchorForSurface:identifier:referenceOriginTransform:
_planeToWorldTransformForSurface:
distance
worldTransform
localTransform
_alignmentRotationForAnchorTransform:planeAlignment:
_boundsFromSurfaceExtent:planeToAnchorTransform:alignmentRotation:
detectionTypeMask
_gridExtentFromSurfaceExtent:planeToAnchorTransform:alignmentRotation:
detectedSurfaces
_techniqueIdentifier
_detectedSurfaces
indexOfObjectWithOptions:passingTest:
removeObjectsInRange:
latencyResultCount
_resultsAvailableSemaphore
_resultsAvailableSemaphoreWaitResult
_results
_resultTimeoutInterval
_resultsSemaphore
_requestsQueue
_latencyResultsNeeded
_latencyResultCount
_rotationMatrix
setRotationRate:
rotationRate
_rotationRate
downscaleFactor
_vtPixelTransferSession
_scaledPixelBufferPool
_downscaleFactor
type
anchor
_type
_distance
_anchor
_localTransform
_worldTransform
getBytes:length:
_motionManager
_updateQueueDeviceMotion
_currentOrientationData
systemUptime
Using fallback intrinsics
ARMotionSensor dealloc
It took %f seconds to initialize vio
ARSession duration: %f
%@ = %f
Power usage changed, video frame duration adjusted to %f-%f
Unable to configure capture device. %@
Saved video to file at %@.
Saved video to file at %@ and to the photo library.
%@ %@
Error: Could not remove temporary file at %@: %@
CMMetadataDataTypeRegistryRegisterDataType failed: %d
Starting recording at timestamp %f
Skipping ARImageData as session has not started.
appendPixelBuffer for timestamp %f failed
Pixel buffer with timestamp %f was dropped because video input was not ready
Tried to call %@ with %@ before session has started
%@ for %@ metadata with timestamp %f failed
%@ metadata with timestamp %f was dropped because input was not ready
[ARSKView] Interface orientation changed to %lu
[ARSKView] Layout changed to %f, %f, %lu
No capture device found
ARImageSensor dealloc
ARImageSensor already running
ARImageSensor start
ARImageSensor stop
Power usage changed from %li to %li
Unsupported capture device: %@
Unsupported pixel format: %d
Error creating capture input: %@
Error creating audio input: %@
Intrinsic matrix delivery is supported by the connection
Exposure duration supported: %f - %f
Active format selected: %@
Video frame duration: %f - %f
Exposure duration set at %f, ISO %f
Unable to set custom exposure and ISO: %@
Exposure point of interest set at %f, %f
Exposure mode set to AVCaptureExposureModeContinuousAutoExposure
Continuous white balance enabled
Auto focus system: %li
Focus point of interest at at %f, %f
Continuous auto focus enabled
Smooth auto focus enabled
Lens position set at %f
Unable to set fixed lens position: %@
Device Orientation Referenced at (%0.2f
 %0.2f
 %0.2f
World Tracking Referenced at (%0.2f
 %0.2f
 %0.2f
) Camera = (%0.2f
 %0.2f
 %0.2f
World Tracking Reference Cleared
Unable to run the session, configuration is not supported on this device: %@
Deferring run due to paused sensors
Pausing techniques due to paused sensor type(s) %ld
Resuming techniques
Restoring normal power utilization
Decreasing power utilization [%li]
Increasing power utilization [%li]
Removed Existing Anchors
Reset Session Origin
Updated Session Heading (%0.2f
Updated Session Origin (%f, %f, %f)
World origin initialized.
Replacing image sensor because camera position has changed
Replacing orientation sensor because alignment has changed
Error: Audio output could not be added to capture session
Starting sensors with data type(s): %lu ...
Started sensors with data type(s): %lu
Currently running sensors with data type(s): %lu
Unable to start required sensor(s) [%lu]
startedSensorDataTypes: %@  VS.  dataTypes: %@
Stopped sensors with data type(s): %lu
Stopped all sensors
Tracking state changed: %li reason: %li
[ARSCNView] Layout changed to %f, %f, %lu
[ARSCNView] Setting playing state to %s
ARReplaySensor dealloc
Error creating asset reader: %@
Created asset reader
Error: Asset reader could not add video output
Error: no video track found in asset
Asset reader could not add output
This is an old style, DEPRECATED recording where gyro and accel data are on the same motion track
Replay sensor could not unpack motion data
Loading complete, image data count: %lu
Replay sensor could not unpack %@
Unable to create plane detector.
Invalid camera parameters
Time out waiting for result: %f
Unable to create pixel transfer session for image downscaling
Unable to create pixel buffer pool for downscaling
Unable to create pixel buffer for downscaling
ARDeviceOrientationSensor dealloc
timestamp
exposureTargetOffset
exposureDuration
cameraParameters
cameraPosition
pixelBufferIsMirrored
targetFramesPerSecond
captureDate
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
Td,N
supportsSecureCoding
TB,R
Td,N,V_timestamp
T@"NSDate",&,N,V_captureDate
cameraIntrinsics
T{?=[3]},N,V_cameraIntrinsics
pixelBuffer
T^{__CVBuffer=},N,V_pixelBuffer
TB,N,V_pixelBufferIsMirrored
imageResolution
T{CGSize=dd},R,N
Tf,N,V_exposureTargetOffset
Td,N,V_exposureDuration
Tf,N,V_ISO
Tq,N,V_cameraPosition
Tq,N,V_targetFramesPerSecond
shouldRestrictFrameRate
TB,N,V_shouldRestrictFrameRate
resolutionHeight
resolutionWidth
focalLengthX
focalLengthY
principalPointX
principalPointY
T{CGSize=dd},R,N,V_imageResolution
focalLength
T{CGPoint=dd},R,N,V_focalLength
principalPoint
T{CGPoint=dd},R,N,V_principalPoint
com.apple.ARKit
delegate
T@"<ARSensorDelegate>",W,N
powerUsage
TQ,N
T@"<ARSensorDelegate>",W,N,V_delegate
Sensor
<%@: %p identifier="%@" transform=%@>
transform
T{?=[4]},N,V_transform
referenceTransform
T{?=[4]},N,V_referenceTransform
identifier
T@"NSUUID",R,N,V_identifier
isTracked
TB,N,V_isTracked
TQ,N,V_uid
lightIntensity
Tf,N,V_lightIntensity
<%@: %p count=%lu>
count
TQ,R,N
points
Tr^,R,N
accelerationX
accelerationY
accelerationZ
acceleration
T{?=ddd},N,V_acceleration
com.apple.arkit.session.run
com.apple.arkit.session.pause
com.apple.arkit.sessionInstantiations
vioInitializationTime
sessionDuration
area
heightDelta
com.apple.arkit.%@.
moreThan%is
badFramePercentage.%@
Session
B32@?0@8Q16^B24
 worldAlignment=%@
 lightEstimation=%@
Enabled
Disabled
<%@: %p
isSupported
TB,R,N
customSensors
T@"NSArray",&,N,V_customSensors
lightEstimation
TQ,N,V_lightEstimation
customCaptureSession
T@"AVCaptureSession",&,N,V_customCaptureSession
audioDataOutput
T@"AVCaptureAudioDataOutput",&,N,V_audioDataOutput
latencyFrameCount
Tq,N,V_latencyFrameCount
worldAlignment
Tq,N,V_worldAlignment
lightEstimationEnabled
TB,N,GisLightEstimationEnabled
markers
T@"NSArray",C,N,V_markers
 planeDetection=%@
relocalizationEnabled
TB,N,V_relocalizationEnabled
planeDetection
TQ,N,V_planeDetection
v32@?0@"ARTechnique"8Q16^B24
captureDeviceType
T@"NSString",&,N,V_captureDeviceType
techniques
T@"NSArray",C,N,V_techniques
Gravity
GravityAndHeading
Camera
<Unknown>
None
Horizontal
Vertical
ARKitDefaults_FrontImageSensorFrameRate
mdta/com.apple.arkit.arimagedata
mdta/com.apple.arkit.ardeviceorientationdata
mdta/com.apple.arkit.araccelerometerdata
mdta/com.apple.arkit.argyroscopedata
mdta/com.apple.arkit.arsensordatatypeinformation
mdta/com.apple.arkit.devicestring
readyForMoreMediaData
movie.mov
com.apple.arkit.arrecordingtechnique.processingqueue
Saved video to file at %@, but not in the photo library because the permission has not been granted.
v16@?0q8
Error saving video to file for an unknown reason.
Saved video to file at %@, but not in the photo library because of an error.
v20@?0B8@"NSError"12
Custom raw data type to store serialized ARImageData objects
Recording outputFileURL is not writable
outputFileURL
T@"NSURL",R,N,V_outputFileURL
shouldSaveVideoInPhotosLibrary
TB,N,V_shouldSaveVideoInPhotosLibrary
recordingTechniqueDelegate
T@"<ARRecordingTechniqueDelegate>",W,N,V_recordingTechniqueDelegate
Technique
<%@(%p) techniques=[%@]>
<%@(%p)>
T@"NSArray",&,N,V_techniques
T@"<ARTechniqueDelegate>",W,N,V_delegate
parentContext
T@,&,N,V_parentContext
gatheredData
T@"NSMutableArray",&,N,V_gatheredData
com.apple.arkit.worldtracking.fixedIntrinsics
com.apple.arkit.worldtracking.calibrationParameters
deviceModel
T@"NSString",R,N,V_deviceModel
Tq,R,N,V_latencyFrameCount
errorCode
Tq,N,V_errorCode
featurePoints
T@"ARPointCloud",&,N,V_featurePoints
cameraTransform
T{?=[4]},N,V_cameraTransform
Td,R,N,V_timestamp
visionFeaturePoints
T@"ARPointCloud",&,N,V_visionFeaturePoints
visionCameraTransform
T{?=[4]},N,V_visionCameraTransform
trackingState
T{?=qqB},N,V_trackingState
size
patches
Tr^{?=},R,N
pivot
Tf,R,N
intrinsics
trackingStateReason
<%@: %p image-resolution=(%.f, %.f) focal-length=(%.03f, %.03f) principal-point=(%.03f, %.03f) transform=%@>
T{CGSize=dd},N,V_imageResolution
T{?=[3]},N,V_intrinsics
Tq,N,V_trackingState
Tq,N,V_trackingStateReason
eulerAngles
T,R,N
projectionMatrix
T{?=[4]},R,N
ARSensorDataTypeColorImage
ARSensorDataTypeAccelerometer
ARSensorDataTypeGyroscope
ARSensorDataTypeDeviceOrientation
markerID
Ti,N,V_markerID
markerSize
Tf,N,V_markerSize
v16@?0@"NSNotification"8
B32@?0@"ARAnchor"8Q16^B24
T@"NSObject<ARSKViewDelegate>",W,D,N
session
T@"ARSession",&,N
distance
 timestamp=%f
 capturedImage=%p
 camera=%p
 lightEstimate=%p
 | no anchors
 | 1 anchor
 | %d anchors
, %d features
capturedImage
T^{__CVBuffer=},N,V_capturedImage
anchors
T@"NSArray",C,N,V_anchors
lightEstimate
T@"ARLightEstimate",C,N,V_lightEstimate
referenceFeaturePoints
T@"ARPointCloud",&,N,V_referenceFeaturePoints
worldOrigin
T@"ARAnchor",&,N,V_worldOrigin
trackingErrorData
T@"ARTrackingErrorData",&,N,V_trackingErrorData
camera
T@"ARCamera",R,C,N,V_camera
rawFeaturePoints
T@"ARPointCloud",R,N
com.apple.arkit.imagesensor.back.exposureDuration
com.apple.arkit.imagesensor.back.iso
com.apple.arkit.imagesensor.back.lensPosition
com.apple.arkit.capture
AVCapture failed to deliver the right image format
Camera use is restricted on this device
v12@?0B8
v32@?0{?=qiIq}8
J207
J208
J120
J121
Tq,V_targetFramesPerSecond
running
TB,V_running
interrupted
TB,V_interrupted
captureDevice
T@"AVCaptureDevice",R,N,V_captureDevice
captureSession
T@"AVCaptureSession",R,N,V_captureSession
videoOutput
T@"AVCaptureVideoDataOutput",R,N,V_videoOutput
autoFocusEnabled
TB,N,GisAutoFocusEnabled,V_autoFocusEnabled
TQ,N,V_powerUsage
com.apple.arkit.error
Unsupported session configuration.
The provided session configuration is not supported on this device.
Please provide a supported session configuration.
Required sensor unavailable.
A required sensor is not available on this device.
Please check that this device is supported.
Required sensor failed.
A sensor failed to deliver the required input.
Make sure that the application has the required privacy settings.
Camera access not authorized.
The app does not have permission to use the camera.
Unsupported capture session configuration.
Input device and/or format of the provided capture session are not supported for the given configuration.
Make sure that the correct device and format are being used for capture.
World tracking failed.
World tracking cannot determine the device's position.
Unauthorized to write to the photo library.
A permission is missing to access the photo library.
Failed saving the recording.
Failed saving the recording for an unknown reason.
horizontal
vertical
<%@: %p identifier="%@" transform=%@ alignment=%@ center=%@ extent=%@>
center
T,N,V_center
extent
T,N,V_extent
gridExtent
T@"ARPatchGrid",&,N,V_gridExtent
visionTransform
T{?=[4]},N,V_visionTransform
activePlaneID
Tq,N,V_activePlaneID
alignment
Tq,R,N,V_alignment
T@"ARLightEstimate",&,N,V_lightEstimate
worldOriginTransform
T{?=[4]},N,V_worldOriginTransform
com.apple.arkit.stateSerialQueue
 currentFrame=%p
 configuration=%@
v32@?0@"<ARSensor>"8Q16^B24
state
TQ,N,V_state
configuration
T@"ARSessionConfiguration",C,N,V_configuration
availableSensors
T@"NSArray",&,N,V_availableSensors
runningSensors
TQ,N,V_runningSensors
pausedSensors
TQ,N,V_pausedSensors
sessionOriginTransform
T{?=[4]},N,V_sessionOriginTransform
T@"<ARSessionDelegate>",W,N,V_delegate
delegateQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateQueue
currentFrame
T@"ARFrame",R,C,N
automaticallyUpdatesLighting
<%@: %p | session=%p scene=%@ sceneTime=%f frame=%@ pointOfView=%@>
TB,V_shouldRestrictFrameRate
developerPreferredFramesPerSecond
Tq,V_developerPreferredFramesPerSecond
drawsCameraImage
TB,V_drawsCameraImage
frameToRemoveRotationSnapshotOn
Tq,V_frameToRemoveRotationSnapshotOn
T@"<ARSCNViewDelegate>",W,D,N
scene
T@"SCNScene",&,D,N
TB,N,V_automaticallyUpdatesLighting
com.apple.arkit.arreplaysensor.timerQueue
Asset reader could not add output
v24@?0d8@"NSData"16
q24@?0@"ARImageData"8@"ARImageData"16
q24@?0@"ARAccelerometerData"8@"ARAccelerometerData"16
q24@?0@"ARGyroscopeData"8@"ARGyroscopeData"16
q24@?0@"ARDeviceOrientationData"8@"ARDeviceOrientationData"16
replaySensorDelegate
T@"<ARReplaySensorDelegate>",W,N,V_replaySensorDelegate
 ambientIntensity=%f
confidenceRating
Td,N,V_confidenceRating
sphericalHarmonicsCoefficients
T@"NSData",R,C,N,V_sphericalHarmonicsCoefficients
ambientIntensity
Td,R,N,V_ambientIntensity
IDMarker
TQ,R,N,V_markerID
HWModelStr
arkit
ARPixelBufferData
ARPixelBufferWidth
ARPixelBufferHeight
ARPixelBufferBytesPerRow
ARPixelBufferFormat
com.apple.arkit.planeEstimation.minDetectionCount
com.apple.arkit.planeEstimation.maxFeatureVariance
com.apple.arkit.planeEstimation
B24@?0@"ARAnchor"8@"NSDictionary"16
detectedSurfaces
T{CovariantVector<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^^?{shared_ptr<std::__1::vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > > >=^{vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > >}^{__shared_weak_count}}{shared_ptr<acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^{CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > >}^{__shared_weak_count}}},R,N,V_detectedSurfaces
detectionTypeMask
TQ,R,N,V_detectionTypeMask
techniqueIdentifier
TQ,R,N,V_techniqueIdentifier
com.apple.arkit.technique.requests
B32@?0@"<ARTimestampedResultData>"8Q16^B24
latencyResultCount
Tq,R,N,V_latencyResultCount
rotationMatrix
T{?=ddddddddd},N,V_rotationMatrix
rotationX
rotationY
rotationZ
rotationRate
T{?=ddd},N,V_rotationRate
downscaleFactor
TC,R,N,V_downscaleFactor
featurePoint
estimatedHorizontalPlane
existingPlane
existingPlaneUsingExtent
<%@: %p type=%@ distance=%f localTransform=%@ worldTransform=%@
 anchor=%@
anchor
T@"ARAnchor",&,N,V_anchor
Td,N,V_distance
localTransform
T{?=[4]},N,V_localTransform
worldTransform
T{?=[4]},N,V_worldTransform
type
TQ,R,N,V_type
 matrix=
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f %f %f)
v8@?0
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
DEBUG
FATAL
%p %c %f (%F:%L): %m%n
yyyy.mm.dd.HH-MM.SS.fff
Internal
General
Tq,R,N,V_worldAlignment
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/Conversions.cpp
Unsupported ColorImage format conversion.
Scale is less or equal to zero
Source and destination widths do not match
Source and destination heights do not match
Source and destination formats do not match
Unsupported format
Image dimensions are too big. Maximum are 8388607 pixels which is sufficient for Ultra HD (3840 x 2160)
Source ColorImage is not in the expected format
Destination ColorImage is not in the expected format
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/include/VisionLib/Types.h
assertion of (pI) failed!
src stride is not 16 byte aligned
dst stride is not 16 byte aligned
assertion of (pSourceImage->width % 2 == 0) failed!
Unexpected error
%s:%d: %s
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/Debug.cpp
assertion of (strlen(buffer)<sizeof(buffer)) failed!
%sMISMATCH
0x%8p : 
%02x 
REFERENCE
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/Filters.cpp
Source width has to be at least 3 pixels
Source height has to be at least 3 pixels
y=%d not in [0,(pSrc)->height-1]=[%d,%d]
0=%d not in [0,(pSrc)->width-1]=[%d,%d]
y > 0 ? y - 1 : y + 1=%d not in [0,(pSrc)->height-1]=[%d,%d]
y < h - 1 ? y + 1 : y - 1=%d not in [0,(pSrc)->height-1]=[%d,%d]
y < h - 2 ? y + 2 : y=%d not in [0,(pSrc)->height-1]=[%d,%d]
y=%d not in [0,(pDst)->height-1]=[%d,%d]
0=%d not in [0,(pDst)->width-1]=[%d,%d]
y + 1=%d not in [0,(pDst)->height-1]=[%d,%d]
h - 1=%d not in [0,(pDst)->height-1]=[%d,%d]
%s is null
pScratch
Scratch size is too small (use getScratchSizeFilter3x3(pSrcImage))
y-1=%d not in [0,(pSrc)->height-1]=[%d,%d]
y+1=%d not in [0,(pSrc)->height-1]=[%d,%d]
0=%d not in [0,(pDst)->height-1]=[%d,%d]
1=%d not in [0,(pDst)->height-1]=[%d,%d]
pDst->height-1=%d not in [0,(pDst)->height-1]=[%d,%d]
pDst->height-2=%d not in [0,(pDst)->height-1]=[%d,%d]
y-2=%d not in [0,(pSrc)->height-1]=[%d,%d]
y+2=%d not in [0,(pSrc)->height-1]=[%d,%d]
2=%d not in [0,(pDst)->height-1]=[%d,%d]
pDst->height-3=%d not in [0,(pDst)->height-1]=[%d,%d]
Source width too small for block size
Source height too small for block size
Half block size must be greater than 0
Delta needs to be between -255 and 255
blockSizeHalf=%d not in [0,(pDst)->height-1]=[%d,%d]
blockSize-1=%d not in [0,(pSrc)->height-1]=[%d,%d]
y - blockSizeHalf - 1=%d not in [0,(pSrc)->height-1]=[%d,%d]
y + blockSizeHalf=%d not in [0,(pSrc)->height-1]=[%d,%d]
pDst->height-1-y=%d not in [0,(pDst)->height-1]=[%d,%d]
pDst->height-1-blockSizeHalf=%d not in [0,(pDst)->height-1]=[%d,%d]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/ImageChecks.cpp
Unexpected null pointer pImage->pBuffer.
Width or height less or equal to zero.
Image stride is not a multiple of 8.
Unknown image format.
Image height must be a multiple of 2.
Image stride must be a multiple of 2.
Stride is smaller than width.
Stride is smaller than width * bytes per pixel.
assertion of ((align==4) || (align==8) || (align==16) || (align==32)) failed!
Image is not %d-Byte aligned and might slow down performance
Stride is less than width.
Image has not been created with createImage() (Head Canary Value corrupted)
Image has not been created with createImage()
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/Memory.cpp
0!=((size_t)pBufferAligned&0xF): 0=%d (0x%x), ((size_t)pBufferAligned&0xF)=%d ($%x)
%s:%d: 
Unexpected null pointer pImage.
terminating
Unexpected null pointer pImagePyramid
Error in function called with VAC_SAFE_CALL
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/dependencies/visionlib/Code/src/VisionLib/Scaling.cpp
Width resolution of destination image (is %d) has to be half resolution of source width (is %d)
Height resolution of destination image (is %d) has to be half resolution of source height (is %d)
y*2=%d not in [0,(pSrc)->height-1]=[%d,%d]
y*2+1=%d not in [0,(pSrc)->height-1]=[%d,%d]
Width Resolution of Destination image has to be 1.5 times Resolution of Source Width. pDst->width %d pSrc->width %d
Height Resolution of destination image has to be 1.5 times Resolution of Source Height. pDst->height %d pSrc->height %d
0=%d not in [0,(pSrc)->height-1]=[%d,%d]
1=%d not in [0,(pSrc)->height-1]=[%d,%d]
2=%d not in [0,(pSrc)->height-1]=[%d,%d]
Resolution of destination image too small for given scale.
Unexpected null pointer pImagePyramid.
Resolution of image for level %i is too low (level %i: %ix%i, level %i: %ix%i).
Image pyramid has less than one levels.
Invalid scale for given filter
Image pyramid has too many levels for the given scale and resolution.
Sizes of input image and pyramid do not match.
Scratch buffer size too small for pre-filtering. (use getMinimumScratchBufferSize() for correct size)
No scratch buffer allocated while using MEAN_3X3
TRACE
ERROR
%d [%t] %p %c: %m%n
PatternLayout
ILayout
 NONE
 INFO
 WARN
Computation.self() did not return self pointer
Illegal IComputationHistoryImpl self pointer
acv.ComputationHistory
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_.
IHashableComputation: given self pointer is not this
checkAndUseResult called with computation of illgal class. Types must be covariant.
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVCommon/src/CVCommon/math/PinholeCamera.cpp
create
Parameters f(%f,%f) p(%f,%f) are invalid.
setParameters
{unknown name}
{unnamed}
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVCommon/include/CVCommon/Types/Enum.h
makeValid
Constructing Enum '%s' with illegal value '%i'. Allowed values are in range [%i, %i], valid values following:
%sSetting to default value %s (%i) instead.
Constructing Enum '%s' with illegal value '%i'. Allowed values are in range [%i, %i]. Setting to default value %s (%i) instead.
{unnamed enum}
CameraType
Invalid
Pinhole
Scaramuzza
Zhang
Invalid enum name map given. Must not be 0-ptr.
Invalid enum name map given. Must not be empty.
Invalid enum value inserted to enum name map. Values need to be between NO_VALUE and MAX_VALUE.
NamedEnumException: 
acv.common
acv::common::ECF_RGB8
acv::common::ECF_R8G8B8
acv::common::ECF_BGR8
acv::common::ECF_B8G8R8
acv::common::ECF_RGBA8
acv::common::ECF_A8R8G8B8
acv::common::ECF_BGRA8
acv::common::ECF_A8B8G8R8
acv::common::ECF_HSV8
acv::common::ECF_YUY2
acv::common::ECF_YV12
acv::common::ECF_IYUV
acv::common::ECF_GRAY8
acv::common::ECF_GRAY
acv::common::ECF_NV21
acv::common::ECF_YUV420SP
acv::common::ECF_NV12
acv::common::ECF_D16
acv::common::ECF_S16
acv::common::ECF_UV32
acv::common::ECF_U32V32
acv::common::ECF_FF32
acv::common::ECF_FFF32
acv::common::ECF_RGB32F
acv::common::ECF_F32
acv::common::ECF_FLIR8
Image<
 [stride 
], values = {
(cannot be printed)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVGraphics/src/CVGraphics/Image.cpp
checkConsistency
Image dimensions and format are inconsistent
Image stride and format are inconsistent
Image value type and format are inconsistent
computeBufferSize
planePaddingOffset is non-zero;it must only be given in planar YUV formats (NV12, NV21, YV12)
ColorFormat
BGRA8
FLIR8
GRAY8
RGBA8
RGBX8
FFF32
RGB32F
Unknown
acv.graphics
ImageValueType
UINT8
UINT16
FLOAT32
uint8
uint16
float32
const 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVGraphics/src/CVGraphics/ImageTransforms.cpp
crop
region for cropping outside image
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/algorithms/HorizontalPlaneDetector.cpp
Horizontal parameters invalid
unordered_map::at: key not found
weightAtHeight
Requested height not in range... %d %d %d
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/algorithms/TemporalPlanarModel.cpp
getExtent
Nothing requested
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/algorithms/TemporalPlaneDetector.cpp
createTemporalPlaneDetector
TemporalPlaneDetector parameters
---- maxSideLength:
---- onOffPixelSize:
---- minimumPlaneAreaMeasured:
---- minimumModelledPlaneArea:
---- minDetections:
---- minimumEvidenceForExtentUnit: 
---- distanceToleranceMerge:
acv.vision.algorithms
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/algorithms/VerticalAndHorizontalPlaneDetector.cpp
Horizontal parameters are invalid
Vertical parameters are invalid
Extent parameters are invalid
ARINTERNALPLANEDETECTION
ARINTERNALPLANEHORIZONTAL
detectPlanesPrivate
HPD: [%6.2fms] Horizontal planes detected %ld uncertainty? %d
ARINTERNALPLANEVERTICAL
VPD: [%6.2fms] Vertical planes detected %ld
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/include/CVVision/algorithms/HorizontalPlaneDetector.h
---- Horizontal parameters ----
histogramBucketResolution :
minimumSupport :
isValid :
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/include/CVVision/algorithms/VerticalPlaneDetector.h
---- Vertical parameters ----
supportingPointsForLinesH :
angularResolution :
accumResolution :
angleThreshold :
distThreshold :
memPoolMaxSize :
memPoolVecLength :
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/include/CVVision/algorithms/VerticalAndHorizontalPlaneDetector.h
---- Plane detection Extent parameters ----
minCameraAngleFromPlane :
acv.trace
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/algorithms/VerticalPlaneDetector.cpp
Vertical parameters invalid
ARINTERNALPLANEVERTICALHOUGH
ARINTERNALPLANEVERTICALESTIMATOR
ARINTERNALPLANEVERTICALCVP
ARINTERNALPLANEVERTICALPOSTCVP
No planes found with the given configuration
PointCloud does not span a plane
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/estimation/PlaneEstimation.cpp
checkIsPlaneAndSaveEigen
Eigen vectors computation failed with error!
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVCommon/include/CVCommon/geometry/GeometryUtils.h
computeEigenVectors
computeEigenVectors failed in computing SVD
acv.geometry
acv.vision.estimation
Minimum of three points required to span a plane
delta[
]  : 
params+update[
  0     
[last error]->[new error][lambda][delta]  : [
 -> 
bitset flip argument out of range
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVVision/src/CVVision/marker/MarkerDetector.cpp
detectMarkers
Invalid parameters. Image and camera need to be of same dimensions
detectMarkerAndSaveCorners
Multiple different markers with same ID '
' in image. Skipping subsequent detection. Undefined results.
100010101101100011010010010000111011
acv.vision.marker
map::at:  key not found
bitset string pos out of range
bitset string ctor has invalid argument
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVTracking/src/CVTracking/detection/AlignedSurfaceDetection.cpp
Failed to create TemporalPlaneDetector
createPlaneDetector
Invalid SurfaceDetection parameter: distanceToSurface must be greater than 0
Invalid SurfaceDetection parameter: minimumSupportMultiplier must be at least 1
Invalid SurfaceDetection parameter: alignmentSupportBalance must be at least 1
Invalid SurfaceDetection parameter: planeSeparationDistance must be greater than 0
Invalid SurfaceDetection parameter: surfaceClosingDistance must be greater than 0
Failed to create VerticalAndHorizontalPlaneDetector
detectAlignedSurfaces
Requested surfaces of orientation NONE (no surfaces returned).
Requested unsupported orientation. Can only return XY or Z aligned surfaces. Other flags are ignored.
Requested unsupported surface support points. Can only returnBOUNDS, GRID_MS or BOUNDS_AND_GRID_MS.
Given point list is 0
Camera must be a Pinhole Camera
extrinsicTransform must have determinant 1.
extrinsicTransform must be orthogonal.
samplePointCloud
Sampling: Gridsize:<%.4f>, Before vs After: <%ld vs %ld>, difference: <%ld>
alignedSurfaceExtent
Requested surface support not available
Requested unsupported surface support points. Can only return BOUNDS.
Received surface IDs to forget but one-shot detection is stateless. 
Ignoring the hint.
Input world to camera space transform is inaccurate. Results of surface detection may be unreliable. Error: 
Input world to camera space transform is very inaccurate. Ignoring call since results of surface detection would be unreliable. Error: 
/BuildRoot/Library/Caches/com.apple.xbs/Sources/ARKit_Sim/ARKit-33/components/CVTracking/src/CVTracking/detection/SurfaceDetection.cpp
createAlignedSurfaceDetector
Desired orientation combination for type 
 not supported.
createAlignedSurfaceTracker
acv.tracking.detection
ARImageData
ARSensorData
ARData
NSObject
NSSecureCoding
NSCoding
ARCameraParameters
ARMotionSensor
ARSensor
ARAnchor
NSCopying
ARTrackedAnchor
ARMarkerTrackingTechnique
ARMarkerData
ARResultData
ARAmbientLightData
ARPointCloud
ARAccelerometerData
ARMutableSensorData
ARSessionMetrics
ARSessionConfiguration
ARMarkerTrackingSessionConfiguration
ARWorldTrackingSessionConfiguration
ARCustomTechniquesSessionConfiguration
PowerUsage
ARRecordingTechnique
ARTechnique
ARTechniqueDelegate
ARTechniqueGatherContext
ARWorldTrackingTechnique
ARTrackingErrorData
ARWorldTrackingFeaturePointData
ARWorldTrackingData
ARExposureLightEstimationTechnique
ARPatchGrid
ARCamera
ARIDMarker
ARSKView
ARInternalSessionObserver
ARSessionDelegate
ARSessionObserver
ARFrame
ARImageSensor
AVCaptureVideoDataOutputSampleBufferDelegate
ARPlaneAnchor
ARLightEstimationData
ARWorldAlignmentTechnique
ARCameraAlignmentData
ARWorldAlignmentData
ARSession
ARSensorDelegate
ARAdditions
ARSCNView
_SCNSceneRendererDelegate
ARSCNVisualizationHelper
ARReplaySensor
ARLightEstimate
ARMarkerAnchor
ARPlaneEstimationTechnique
ARPlaneData
ARBuiltInLatency
ARDeviceOrientationData
ARGyroscopeData
ARImageScalingTechnique
ARHitTestResult
ARDeviceOrientationSensor
{?=[3]}56@0:8^{opaqueCMSampleBuffer=}16d24{CGPoint=dd}32^B48
@48@0:8{?=qiIq}16@40
B16@0:8
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
d16@0:8
v24@0:8d16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@40@0:8^{opaqueCMSampleBuffer=}16@24@32
v16@0:8
v24@0:8^{__CVBuffer=}16
{CGSize=dd}16@0:8
{?=[3]}16@0:8
v64@0:8{?=[3]}16
^{__CVBuffer=}16@0:8
v20@0:8B16
f16@0:8
v20@0:8f16
q16@0:8
v24@0:8q16
@"NSDate"
^{__CVBuffer=}
{?="columns"[3]}
@64@0:8{CGPoint=dd}16{CGSize=dd}32{CGPoint=dd}48
@24@0:8^{_NSZone=}16
{CGPoint=dd}16@0:8
{CGSize="width"d"height"d}
{CGPoint="x"d"y"d}
v24@0:8Q16
@"<ARSensorDelegate>"16@0:8
v24@0:8@"<ARSensorDelegate>"16
@"<ARSensorDelegate>"
@80@0:8{?=[4]}16
@88@0:8@16{?=[4]}24
@20@0:8B16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
@"NSUUID"
{?="columns"[4]}
@92@0:8@16{?=[4]}24B88
v32@0:8d16@24
@"NSArray"
^{MarkerDetector={shared_ptr<acv::vision::marker::MarkerDetectorImpl>=^{MarkerDetectorImpl}^{__shared_weak_count}}{Settings=iCiiBi}{map<int, acv::vision::marker::ReferenceMarker, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, acv::vision::marker::ReferenceMarker> > >={__tree<std::__1::__value_type<int, acv::vision::marker::ReferenceMarker>, std::__1::__map_value_compare<int, std::__1::__value_type<int, acv::vision::marker::ReferenceMarker>, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, acv::vision::marker::ReferenceMarker> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, acv::vision::marker::ReferenceMarker>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, acv::vision::marker::ReferenceMarker>, std::__1::less<int>, true> >=Q}}}{ImageT<unsigned char>={shared_ptr<acv::graphics::ImageBuffer<unsigned char> >=^{ImageBuffer<unsigned char>}^{__shared_weak_count}}}{ImageT<unsigned char>={shared_ptr<acv::graphics::ImageBuffer<unsigned char> >=^{ImageBuffer<unsigned char>}^{__shared_weak_count}}}{ImageT<unsigned char>={shared_ptr<acv::graphics::ImageBuffer<unsigned char> >=^{ImageBuffer<unsigned char>}^{__shared_weak_count}}}{ImageT<unsigned char>={shared_ptr<acv::graphics::ImageBuffer<unsigned char> >=^{ImageBuffer<unsigned char>}^{__shared_weak_count}}}{ImageT<unsigned char>={shared_ptr<acv::graphics::ImageBuffer<unsigned char> >=^{ImageBuffer<unsigned char>}^{__shared_weak_count}}}{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}{vector<unsigned char, std::__1::allocator<unsigned char> >=**{__compressed_pair<unsigned char *, std::__1::allocator<unsigned char> >=*}}{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}{vector<unsigned char, std::__1::allocator<unsigned char> >=**{__compressed_pair<unsigned char *, std::__1::allocator<unsigned char> >=*}}}
{shared_ptr<acv::math::PinholeCamera>="__ptr_"^{PinholeCamera}"__cntrl_"^{__shared_weak_count}}
@"NSObject<OS_dispatch_semaphore>"
{map<int, acv::vision::marker::DetectedMarker, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, acv::vision::marker::DetectedMarker> > >="__tree_"{__tree<std::__1::__value_type<int, acv::vision::marker::DetectedMarker>, std::__1::__map_value_compare<int, std::__1::__value_type<int, acv::vision::marker::DetectedMarker>, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, acv::vision::marker::DetectedMarker> > >="__begin_node_"^{__tree_end_node<std::__1::__tree_node_base<void *> *>}"__pair1_"{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, acv::vision::marker::DetectedMarker>, void *> > >="__first_"{__tree_end_node<std::__1::__tree_node_base<void *> *>="__left_"^{__tree_node_base<void *>}}}"__pair3_"{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, acv::vision::marker::DetectedMarker>, std::__1::less<int>, true> >="__first_"Q}}}
{?=qqB}16@0:8
@160@0:8{?=[4]}16{?=[4]}80@144@152
@"ARLightEstimate"16@0:8
@"ARPointCloud"16@0:8
@"NSArray"160@0:8{?=[4]}16{?=[4]}80@"NSArray"144@"NSMutableArray"152
@40@0:8{vector<float __attribute__((ext_vector_type(3))), std::__1::allocator<float __attribute__((ext_vector_type(3)))> >=^^{__compressed_pair<float * __attribute__((ext_vector_type(3))), std::__1::allocator<float __attribute__((ext_vector_type(3)))> >=^}}16
r^16@0:8
@48@0:81632
{vector<float __attribute__((ext_vector_type(3))), std::__1::allocator<float __attribute__((ext_vector_type(3)))> >="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(3))), std::__1::allocator<float __attribute__((ext_vector_type(3)))> >="__first_"^}}
{?=ddd}16@0:8
v40@0:8{?=ddd}16
{?="x"d"y"d"z"d}
@"NSObject<OS_dispatch_queue>"
@32@0:8@16^@24
@40@0:8@16^@24@32
@24@0:8q16
@"AVCaptureSession"
@"AVCaptureAudioDataOutput"
@"NSString"
d32@0:8Q16q24
d36@0:8@16d24B32
@32@0:8@16Q24
v48@0:8@16@24@32^v40
{CGAffineTransform=dddddd}24@0:8q16
v48@0:8^{__CVBuffer=}16{?=qiIq}24
v48@0:8@16{?=qiIq}24
v40@0:8@16@24@32
{?=qiIq}24@0:8d16
@"AVAssetWriter"
@"AVAssetWriterInput"
@"AVAssetWriterInputPixelBufferAdaptor"
@"AVAssetWriterInputMetadataAdaptor"
@"NSMutableArray"
@"NSURL"
@"<ARRecordingTechniqueDelegate>"
v48@0:8@16@24d32@40
v32@0:8@16@24
v48@0:8@"ARTechnique"16@"NSArray"24d32@40
v32@0:8@"ARTechnique"16@"NSError"24
@40@0:8@16d24@32
@"<ARTechniqueDelegate>"
@32@0:8@16q24
@"ARPointCloud"
@"ARTrackingErrorData"
@"ARWorldTrackingData"
@24@0:8d16
v40@0:8{?=qqB}16
{?="state"q"reason"q"relocalized"B}
[27f]
@44@0:8{vector<ARPatch, std::__1::allocator<ARPatch> >=^{?}^{?}{__compressed_pair<ARPatch *, std::__1::allocator<ARPatch> >=^{?}}}16f40
r^{?=}16@0:8
{vector<ARPatch, std::__1::allocator<ARPatch> >="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<ARPatch *, std::__1::allocator<ARPatch> >="__first_"^{?}}}
@80@0:8{?=[3]}16{CGSize=dd}64
16@0:8
{?=[4]}56@0:8{CGSize=dd}16q32d40d48
v32@0:8{CGSize=dd}16
@24@0:8i16f20
i16@0:8
v20@0:8i16
v32@0:8@"ARSession"16@"NSError"24
v32@0:8@"ARSession"16@"ARCamera"24
v24@0:8@"ARSession"16
v32@0:8@"ARSession"16@"ARFrame"24
v32@0:8@"ARSession"16@"NSArray"24
v32@0:8@16Q24
v32@0:8@"ARSession"16Q24
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@40@0:8{CGPoint=dd}16Q32
@32@0:8@16@24
v112@0:8@16@24{?=[4]}32@96q104
@"ARSession"
@"NSMutableDictionary"
@"NSSet"
@"<NSObject>"
@32@0:8@16d24
{CGAffineTransform=dddddd}40@0:8{CGSize=dd}16q32
@56@0:81632Q48
@"ARPlaneData"
@"ARCamera"
@"ARLightEstimate"
@"ARAnchor"
@44@0:8@16{?=ii}24I32d36
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
@40@0:8q16@24@32
@32@0:8q16@24
@24@0:8^@16
@"<AVCaptureVideoDataOutputSampleBufferDelegate>"
@"AVCaptureDevice"
@"AVCaptureVideoDataOutput"
@96@0:8@16{?=[4]}24q88
@52@0:81632B48
v32@0:816
@"ARPatchGrid"
@"ARDeviceOrientationData"
v32@0:8@"<ARSensor>"16@"<ARSensorData>"24
v32@0:8@"<ARSensor>"16@"NSError"24
v24@0:8@"<ARSensor>"16
v64@0:8@16@24@32@40@48B56B60
v32@0:8Q16Q24
@"ARTechnique"
@"ARWorldTrackingTechnique"
@"ARFrame"
@"NSMutableSet"
@"NSHashTable"
@"CMMotionManager"
@"ARSessionMetrics"
@"<ARSessionDelegate>"
@"ARSessionConfiguration"
@24@0:8Q16
v32@0:8@16d24
v40@0:8@16@24d32
v32@0:8@"<SCNSceneRenderer>"16d24
v40@0:8@"<SCNSceneRenderer>"16@"SCNScene"24d32
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@48@0:8{CGPoint=dd}16@32Q40
v28@0:8q16B24
@"<SCNCaptureDeviceOutputConsumer>"
@"SCNNode"
@"UIView"
B32@0:8@16@24
B24@0:8d16
@40@0:8#16@24@32
v40@0:8@16@24@?32
^{__CVBuffer=}24@0:8d16
@"NSObject<OS_dispatch_source>"
^{opaqueCMSampleBuffer=}
@"AVAssetReader"
@"AVAssetReaderTrackOutput"
@"AVAssetReaderOutputMetadataAdaptor"
@"<ARReplaySensorDelegate>"
@"NSData"
@92@0:8Q16{?=[4]}24B88
@32@0:8Q16@24
@60@0:8{shared_ptr<acv::tracking::detection::IAlignedSurfaceDetector<float> >=^{IAlignedSurfaceDetector<float>}^{__shared_weak_count}}16Q32@40@48B56
{shared_ptr<acv::tracking::detection::IAlignedSurfaceDetector<float> >="__ptr_"^{IAlignedSurfaceDetector<float>}"__cntrl_"^{__shared_weak_count}}
@72@0:8{CovariantVector<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^^?{shared_ptr<std::__1::vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > > >=^{vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > >}^{__shared_weak_count}}{shared_ptr<acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^{CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > >}^{__shared_weak_count}}}16Q56Q64
@96@0:8r^{IAlignedSurface<float>=^^?}16@24{?=[4]}32
@104@0:8@16r^{IAlignedSurface<float>=^^?}24@32{?=[4]}40
i88@0:8{?=[4]}16q80
{?=[4]}24@0:8r^{IAlignedSurface<float>=^^?}16
{?=}92@0:8r^{SurfaceExtent<float>={Matrix<float, 3, 3>=[9f]}{vector<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>, std::__1::allocator<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> > >=^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}{__compressed_pair<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> *, std::__1::allocator<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> > >=^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}}}{SE3GroupStorage<float, cva::Matrix<float, 4, 4> >=[16f]}f}16{?=[4]}24i88
@92@0:8r^{SurfaceExtent<float>={Matrix<float, 3, 3>=[9f]}{vector<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>, std::__1::allocator<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> > >=^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}{__compressed_pair<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> *, std::__1::allocator<acv::geometry::BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe> > >=^{BoundingBox2<float, acv::geometry::BoundingBoxFlags::Safe>}}}{SE3GroupStorage<float, cva::Matrix<float, 4, 4> >=[16f]}f}16{?=[4]}24i88
{CovariantVector<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^^?{shared_ptr<std::__1::vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > > >=^{vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > >}^{__shared_weak_count}}{shared_ptr<acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >=^{CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > >}^{__shared_weak_count}}}16@0:8
{CovariantVector<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >="_vptr$ICovariantVectorBase"^^?"m_vector"{shared_ptr<std::__1::vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > > >="__ptr_"^{vector<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> >, std::__1::allocator<std::__1::shared_ptr<acv::tracking::detection::IAlignedSurface<float> > > >}"__cntrl_"^{__shared_weak_count}}"m_originalInterface"{shared_ptr<acv::CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > > >="__ptr_"^{CovariantVectorInterface<acv::tracking::detection::IAlignedSurface<float>, acv::CovariantVectorInterface<acv::geometry::ISurface<float>, acv::ICovariantVector<acv::geometry::ISurface<float> > > >}"__cntrl_"^{__shared_weak_count}}}
@32@0:8q16d24
{?=ddddddddd}16@0:8
v88@0:8{?=ddddddddd}16
{?="m11"d"m12"d"m13"d"m21"d"m22"d"m23"d"m31"d"m32"d"m33"d}
@20@0:8C16
C16@0:8
^{OpaqueVTPixelTransferSession=}
^{__CVPixelBufferPool=}
@"NSOperationQueue"
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
