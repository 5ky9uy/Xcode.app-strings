@(#)PROGRAM:ARKit  PROJECT:ARKit-381.28
MbP?
<%@: %p
 identifier="%@"
 name="%@"
 transform=%@
 referenceImage=%@
 tracked=%@
 estimatedScale=%f
referenceImage
referenceImageUUID
detectionOnly
tracked
estimatedScaleFactor
translation
rotation
scale
perspective
 matrix=
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
<matrix=
(%f, %f, %f)
(%f, %f, %f)
(%f, %f, %f)
<matrix=
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f %f %f)
(%f %f %f %f)
%@ = [%f,%f,%f]
%@ = [%f,%f,%f,%f]
%@ = [%f,%f,%f;
%f,%f,%f;
%f,%f,%f]
%@ = [%f,%f,%f,%f;
%f,%f,%f,%f;
%f,%f,%f,%f;
%f,%f,%f,%f]
v8@?0
arkitd
arkitctl
ARExamples
ARKit_iOS_tests_app
com.apple.ARKit
General
<%@: %p instanceID=%@ url="%@" identifier="%@" transform=%@>
instanceID
confidence
radius
urlDecodingStateInternal
isTracked
isScaleReliable
urlEncodingVersion
@"(.*)"
BuildVersion
CFBundleVersion
rear-facing-camera
front-facing-camera
FrontCameraOffsetFromDisplayCenter
FrontCameraRotationFromDisplayNormal
RearCameraOffsetFromDisplayCenter
+N9mZUAHooNvMiQnjeTJ8g
AirplaneMode
566JrJVMlDfnslGpwUzNlQ
@16@?0@"ARVideoFormat"8
hnXJ1OpiiIL0+p3jUG/XxQ
Failed to create an in-memory output stream.
Writing a string to an output stream failed with an unknown error.
An anchor geometrie's vertex count does not match normal count.
A face index is out of range.
There is no mesh to save.
# ARKit mesh exported from ARExamples %@, ARKit %@, AppleCV3D %@
com.apple.AppleCV3D
# Vertex count: %d
# Face count: %d
# Real world scale is 1 unit = 1 m
# Each vertex is followed by four RGBA color values in range [0.0 - 1.0] (not in spec)
o mesh_anchor_%@
v %.06f %.06f %.06f %.03f %.03f %.03f %.03f
vn %f %f %f
f %d//%d %d//%d %d//%d
# EOF
pid=%d <Unknown>
kern.boottime
Back
Front
Unspecified
ARKit
Frameworks/ARKit.framework
com.apple.ARKitUI
PrivateFrameworks/ARKitUI.framework
com.apple.ARKitCore
PrivateFrameworks/ARKitCore.framework
Apple Global Domain
B24@?0@"NSString"8@"NSDictionary"16
com.apple.arkit.
com_apple_arkit_
QVwCp3Lu9RLnxw7LO9DBfQ
System Default
test
width
height
com.apple.arkit.useCacheForUserDefaults
com.apple.arkit.bufferPopulationMonitor
com.apple.arkit.session.cameraPosition
com.apple.arkit.session.qatracing
com.apple.arkit.session.qatracing.screenRecording
com.apple.arkit.session.qatracing.forceQuitApp
com.apple.arkit.session.qatracing.framesLabelOffset
com.apple.arkit.session.qatracing.dumpSemanticSegmantationData
com.apple.arkit.session.qatracing.filepath
com.apple.arkit.session.record.filepath
com.apple.arkit.session.forceRecording
com.apple.arkit.session.replay.filepath
com.apple.arkit.session.replay.filepath.manual
com.apple.arkit.session.defaultRelocalizationTimeout
com.apple.arkit.session.useIOKit
com.apple.arkit.session.disableSessionMetricsReporting
com.apple.arkit.daemonMetrics.disableReporting
com.apple.arkit.session.mirroredFrameOutput
com.apple.arkit.session.featurePointAccumulationCount
com.apple.arkit.motionSensor.sampleRate
com.apple.arkit.motionSensor.magnetometerEnabled
com.apple.arkit.imagesensor.attemptfailurerecovery
com.apple.arkit.imagesensor.attemptfailurerecoveryafterbackground
com.apple.arkit.imagesensor.back.wide.resolution
com.apple.arkit.imagesensor.back.wide.frameRate
com.apple.arkit.imagesensor.back.wide.videoBinned
com.apple.arkit.imagesensor.back.wide.exposureDuration
com.apple.arkit.imagesensor.back.wide.iso
com.apple.arkit.imagesensor.back.wide.whiteBalance
com.apple.arkit.imagesensor.back.wide.lensPosition
com.apple.arkit.imagesensor.back.wide.autoFocus
com.apple.arkit.imagesensor.back.wide.smoothAutoFocus
com.apple.arkit.imagesensor.back.wide.autoFocusRange
com.apple.arkit.imagesensor.back.wide.photoQualityPrioritization
com.apple.arkit.imagesensor.front.resolution
com.apple.arkit.imagesensor.front.frameRate
com.apple.arkit.imagesensor.front.videoBinned
com.apple.arkit.imagesensor.front.exposureDuration
com.apple.arkit.imagesensor.front.iso
com.apple.arkit.imagesensor.front.whiteBalance
com.apple.arkit.imagesensor.back.ultrawide.resolution
com.apple.arkit.imagesensor.back.ultrawide.frameRate
com.apple.arkit.imagesensor.back.ultrawide.videoBinned
com.apple.arkit.imagesensor.back.ultrawide.exposureDuration
com.apple.arkit.imagesensor.back.ultrawide.iso
com.apple.arkit.imagesensor.back.ultrawide.whiteBalance
com.apple.arkit.imagesensor.back.ultrawide.geometricDistortionCorrection
com.apple.arkit.imagesensor.initialFrameDrop.enabled
com.apple.arkit.imagesensor.initialFrameDrop.negativeExposureTargetOffsetThreshold
com.apple.arkit.imagesensor.initialFrameDrop.positiveExposureTargetOffsetThreshold
com.apple.arkit.imagesensor.initialFrameDrop.maxDroppedFramesCount
com.apple.arkit.imagesensor.videoHDR.allowed
com.apple.arkit.imagesensor.calibrationData.alwaysDiscardsLateData
com.apple.arkit.imagesensor.face.frameRateNormal
com.apple.arkit.imagesensor.face.frameRateLow
com.apple.arkit.imagesensor.face.frameRateLowest
com.apple.arkit.imagesensor.face.previousImageDataOnDrop
com.apple.arkit.imagesensor.face.mirror
com.apple.arkit.imageSensor.face.depthDataFiltering
com.apple.arkit.faceTracking.rgbOnly.enabled
com.apple.arkit.faceTracking.backCamera.allowed
com.apple.arkit.faceTracking.lowPowerMode.enabled
com.apple.arkit.planeEstimation.minDetectionCount
com.apple.arkit.planeEstimation.minVergenceAngle
com.apple.arkit.planeEstimation.lineFeaturesAlwaysOn
com.apple.arkit.planeEstimation.mlOnANEDevices
com.apple.arkit.planeEstimation.normalsKernelSize
com.apple.arkit.planeEstimation.enableLowQosScheduling
com.apple.arkit.planeEstimation.detectionMethod
com.apple.arkit.planeEstimation.enableInverseDepthDetector
com.apple.arkit.planeEstimation.anchorRotation
com.apple.arkit.worldtracking.calibrationParameters.imu
com.apple.arkit.worldtracking.calibrationParameters.back.wide
com.apple.arkit.worldtracking.calibrationParameters.back.ultrawide
com.apple.arkit.worldtracking.slamConfiguration
com.apple.arkit.worldtracking.lineFeatures
com.apple.arkit.worldtracking.lineFeaturesAlwaysOn
com.apple.arkit.worldtracking.minVergenceAngle
com.apple.arkit.worldtracking.poseGraphUpdates
com.apple.arkit.worldTracking.resultLatency
com.apple.arkit.worldtracking.fixedIntrinsics
com.apple.arkit.worldtracking.deviceModel
com.apple.arkit.worldTracking.visionData
com.apple.arkit.worldTracking.simulateHWFeatureDetection
com.apple.arkit.worldTracking.useLACCIfAvailable
com.apple.arkit.worldTracking.collaborativeMappingStatistics
com.apple.arkit.worldTracking.useUltraWide
com.apple.arkit.worldTracking.forceDisableFrontCamera
com.apple.arkit.worldTracking.participantAnchors
com.apple.arkit.worldTracking.warningSounds
com.apple.arkit.worldTracking.mlRelocalizationMode
com.apple.arkit.worldTracking.accuratePlaneExtentCheck
com.apple.arkit.worldTracking.newCV3DApis
com.apple.arkit.worldTracking.enableMLCMRelocalization
com.apple.arkit.worldtracking.transformToExternalSubmap
com.apple.arkit.worldtracking.enableTempMappingDirectory
com.apple.arkit.geotracking.useclfusion
com.apple.arkit.geotracking.usecmfusion
com.apple.arkit.geotracking.usegradualcorrection
com.apple.arkit.geotracking.gradualcorrectioninterval
com.apple.arkit.geotracking.useVLTraceRecorder
com.apple.arkit.geotracking.bypassChecksForANE
com.apple.arkit.geotracking.bypassChecksForGPS
com.apple.arkit.geotracking.visualLocalizationCallInterval
com.apple.arkit.geotracking.posteriorVisualLocalizationCallInterval
com.apple.arkit.geotracking.visualLocalizationCallIntervalTimeThreshold
com.apple.arkit.imagedetection.assetcatalog
com.apple.arkit.imageDetection.fixedPriorityProcessingQueue
com.apple.arkit.imagedetection.percentageThresholdPixels
com.apple.arkit.objctdetection.fixedPriorityProcessingQueue
com.apple.arkit.objctdetection.regionProposalModel
com.apple.arkit.environmentTexturing.minimumProbeUpdateInterval
com.apple.arkit.environmentTexturing.wantsHDR
com.apple.arkit.environmentTexturing.maxHDR
com.apple.arkit.personDetectionTechnique.renderBoundingBoxesIntoCapturedImage
com.apple.arkit.personDetectionTechnique.mergeLargelyOverlappingBoundingBoxes
com.apple.arkit.personocclusion.skipFrameWhenBusy
com.apple.arkit.scaling.useOptimalMSRCoeficients
com.apple.arkit.matting.erosionRadius
com.apple.arkit.matting.uncertaintyRadius
com.apple.arkit.matting.epsilon
com.apple.arkit.matting.disableSoftEdges
com.apple.arkit.matting.depthScale
com.apple.arkit.matting.dilationRadius
com.apple.arkit.matting.useTemporalSmoothing
com.apple.arkit.matting.doubleMLResolutionForIPad
com.apple.arkit.matting.useTemporalHandsSegmentation
com.apple.arkit.bodytracking.multipleBodyAnchors
com.apple.arkit.bodytracking.extrapolationTimeLimitSeconds
com.apple.arkit.bodytracking.pushProjected3DSkeleton
com.apple.arkit.bodyTracking.useSupport3DSkeleton
com.apple.arkit.view.rendersCameraGrain
com.apple.arkit.view.rendersMotionBlur
com.apple.arkit.view.attemptRenderSynchronizationARFrame
com.apple.arkit.view.renderRawSceneUnderstandingImage
com.apple.arkit.multicam_mode.enabled
com.apple.arkit.sceneReconstruction.voxelSize
com.apple.arkit.sceneReconstruction.waitTillVIOIsStable
com.apple.arkit.sceneReconstruction.enableLowQosScheduling
com.apple.arkit.sceneReconstruction.enableOccupancyMapping
com.apple.arkit.sceneReconstruction.enableKeyVolPipeline
com.apple.arkit.sceneReconstruction.bucketsCount
com.apple.arkit.sceneReconstruction.enableMeshPlaneHarmony
com.apple.arkit.semanticSegmentation.uncertaintyThreshold
com.apple.arkit.recordingTechnique.recordPearlDepthData
com.apple.arkit.replaySensor.deterministicMode
com.apple.arkit.replaySensor.deterministicMode.useMovieFPS
com_apple_arkit_replay_filepath_advanceToFrame
com_apple_arkit_replay_filepath_advanceFramesPerSecondMultiplier
com_apple_arkit_replay_filepath_nextFrameIndex
com.apple.arkit.replay.display.synchronization.marker
com.apple.arkit.replay.display.synchronization.marker.frameCount
com.apple.arkit.replaySensor.cropFrames
com.apple.arkit.replaySensor.replayVisionData
com.apple.arkit.replaySensor.replayPearlDepthData
com.apple.arkit.test.default
com.apple.arkit.session.configuration.saveDotGraph
com.apple.arkit.appleDepth.useExpFilter
com.apple.arkit.appleDepth.averageDepthBoundingBox
com.apple.arkit.appleDepth.temporalSmoothingMethod
com.apple.arkit.appleDepth.temporalFilteringStoredFrames
com.apple.arkit.appleDepth.computeNormals
com.apple.arkit.appleDepthSPI.bundleID.approvedList
com.apple.arkit.jasper.enabled
com.apple.arkit.jasper.timeOfFlightProjectorMode
com.apple.arkit.jasper.framerate
com.apple.arkit.jasper.replayFramerate
com.apple.arkit.jasper.aggregationBankCount
com.apple.arkit.personOcclusion.optimizationStrategy
com.apple.arkit.forceLinkedOnOrAfterAzul
com.apple.arkit.appClipCodeTracking.performanceTestMode
com.apple.arkit.skipCrashOnARCrash
<%@: %p identifier="%@" transform=%@ referenceObject=%@>
referenceObject
root
head_joint
left_hand_joint
right_hand_joint
left_foot_joint
right_foot_joint
left_shoulder_1_joint
right_shoulder_1_joint
identifier
transform
referenceTransform
lastUpdateTimestamp
isHiddenFromPublicDelegate
name
 sessionIdentifier="%@"
B24@?0@"ARAnchor"8@"NSDictionary"16
geometry
timestamp
extent
maxExtentError
visionTransform
corner
 geometry="%@"
 timestamp=%f
trackingData
anchorIdentifier
vertexData
vertexData2D
normalsData
blendShapeCoefficientsData
leftEyeTransform
rightEyeTransform
gaze
tongueOut
trackedFaces
None
Manual
Automatic
Unknown
Horizontal
Vertical
Gravity
GravityAndHeading
Camera
Person Segmentation with Depth
Person Segmentation
Body Detection
Scene Depth
Smoothed Scene Depth
ColorImage
Accelerometer
Gyroscope
DeviceOrientation
FaceMetaData
Depth
Location
Magnetometer
ARTimeOfFlightProjectorModeNone
ARTimeOfFlightProjectorModeNormal
ARTimeOfFlightProjectorModeShortRange
ARTimeOfFlightProjectorModeNormalShortHybrid
ARTimeOfFlightProjectorModeHighQualityMacro
Coarse
Precise
User Defined
 coordinate=(%f,%f,%f) altitudeSource=%@ isAltitudeAvailable=%d undulation=%f>
latitude
longitude
altitude
altitudeSource
isAltitudeAvailable
undulation
Unable to create archive.
Unable to read archive from memory.
NULL
Underlying NSData was nil
com.apple.arkit.error
ARErrorItems
ARServiceName
Unsupported configuration.
The provided configuration is not supported on this device.
Required sensor unavailable.
A required sensor is not available on this device.
Required sensor failed.
A sensor failed to deliver the required input.
Make sure that the application has the required privacy settings.
Camera access not authorized.
The app does not have permission to use the camera.
Make sure that the application has the required camera privacy settings.
Microphone access not authorized.
The app does not have permission to use the microphone.
Make sure that the application has the required microphone privacy settings.
Unsupported capture session configuration.
Input device and/or format of the provided capture session are not supported for the given configuration.
Make sure that the correct device and format are being used for capture.
World tracking failed.
Geo tracking is not available at this location.
Geo tracking failed because of a runtime error.
Location access not authorized.
The app does not have permission to use the location of the device.
Location access and precise accuracy must be enabled in the app's privacy settings.
Invalid reference image.
Invalid reference object.
The reference object data is not in a format supported by this version of ARReferenceObject.
Invalid world map.
The world map data is not in a format supported by this version of ARWorldMap.
Invalid configuration.
Invalid collaboration data.
The encoded data is not in a format supported by this version of ARCollaborationData.
Unsupported sensor data.
Insufficient features.
Object merge failed.
Not enough matching features were found for the reference objects to be merged.
File IO failed.
Unable to read from or write to URL: %@.
Request failed.
Unauthorized to write to the photo library.
A permission is missing to access the photo library.
Failed saving the recording.
Failed saving the recording for an unknown reason.
Failed to load espresso model.
File path '%@' is invalid or does not exist
File path is invalid or does not exist
Tracking is currently limited.
Lack of visible features.
Excessive motion of the device.
Low lighting conditions.
Another high-resolution frame is currently being captured.
Please wait for the completion handler call.
Capturing a high resolution frame failed.
angle
patchesVector
Seat
Wall
Floor
Table
Ceiling
Window
Door
Unavailable
Undetermined
Known
There is no plane geometry mesh to save.
# ARKit plane geometry mesh exported from ARExamples %@, ARKit %@, AppleCV3D %@
o plane_anchor_%@
v %.03f %.03f %.03f %.03f %.03f %.03f %.03f
f %d %d %d
rotationOnYAxis
alignment
center
planeExtent
worldAlignmentRotation
classificationStatus
classification
uncertaintyAlongNormal
classificationLabel
gridExtent
<%@: %p identifier="%@" name="%@" transform=%@ texture=%p extent=%@>
<%@: %p identifier="%@" transform=%@ texture=%p extent=%@>
trackedPlaneIdentifier
ARQLCanonicalWebPageURL
allowObjectScaling
ARQLWantsStatusPillHiddenKey
ARQLForceIgnoreMuteSwitchKey
Not Available
Initializing
Localizing
Localized
Medium
High
Not Available At Location
Need Location Permissions
World Tracking Unstable
Waiting For Location
Waiting for Availability Check
Geo Data Not Loaded
Device Pointed Too Low
Visual Localization Failed
VL Unsupported
VL Map Data Not Loaded
VL Map Data Pending
VL Pose Estimation Failed
VL Rejected Pose
VL Bad Input
Invalid VIO Pose
Phone Angle
VL Bad Image
VL Unavailable At Location
VL Unrecognized Error
Waiting For Availability Check
ARGeoTrackingStatus_state
ARGeoTrackingStatus_accuracy
ARGeoTrackingStatus_stateReason
ARGeoTrackingStatus_failureReasons
skeletonData
arobject
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
v32@?0@"NSString"8@"NSNumber"16^B24
blendShapeCoefficientsDictionary
trackingError
Error reading matrix from dictionary
Error: Error reading matrix from dictionary
Couldn't find bundle for name %@
Error: Couldn't find bundle for name %@
Using front camera offset values (%f, %f, %f).
No front camera offset value found for device: %@
No front camera rotation value found in MobileGetStalt for device: %@
Using rear camera offset values (%f, %f, %f).
No rear camera offset value found for device: %@
Error: No rear camera offset value found for device: %@
Creating the OBJ failed.
Error: Creating the OBJ failed.
Writing a string to the output stream failed with error: %@
Error: Writing a string to the output stream failed with error: %@
Writing an OBJ file for %lu mesh anchors to a stream.
Vertex count %ld does not match normal count %ld.
Error: Vertex count %ld does not match normal count %ld.
Face index %d is out of range [0, %ld].
Error: Face index %d is out of range [0, %ld].
No mesh to save.
Error: No mesh to save.
Failed to get kern.boottime MIB with error: %{private}s
Error: Failed to get kern.boottime MIB with error: %{private}s
Failed to lookup kern.boottime with error: %{private}s
Error: Failed to lookup kern.boottime with error: %{private}s
%{public}@ <%p>: Received location
%@ <%p>: Location request handler failed: %@
%@ <%p> Error: Location request handler failed: %@
%{public}@ <%p>: User has set location authorization status: %d
%{public}@ <%p>: Waiting for location authorization from user
%{public}@ <%p>: Waiting for location for availability check
%{public}@ <%p>: Unable to create archive at path: %{public}@.
%{public}@ <%p>: Unable to write to archive at path: %{public}@.
%{public}@ <%p>: Unable to create archive.
%{public}@ <%p>: Unable to write archive to memory
%{public}@ <%p>: Cannot read archive from memory
%{public}@ <%p>: Cannot read archive from nil URL
%{public}@ <%p>: Unable to read archive at path: %{public}@.
%@ <%p>: Unable to construct path
%@ <%p> Error: Unable to construct path
%@ <%p>: Could not read data to buffer.
%@ <%p> Error: Could not read data to buffer.
ARImageAnchor
ARTrackable
NSObject
ARWorldMap
NSCopying
NSSecureCoding
NSCoding
ARAppClipCodeAnchor
ARSession
ARPositionalTrackingConfiguration
ARFaceTrackingConfiguration
ARPointCloud
ARObjectScanningConfiguration
ARDepthData
ARResultData
ARData
ARTrackedRaycast
ARIOMotionSensor
ARSensor
ARAppleGlobalDomain
ARKitUserDefaults
ARObjectAnchor
ARSkeletonDefinition
ARImageTrackingConfiguration
ARAnchor
ARDaemonSecureCoding
ARAnchorCopying
ARAccelerometerData
ARDictionaryCoding
ARMetadataWrapperCoding
ARMutableSensorData
ARSensorData
ARMeshAnchor
ARGeoTrackingLocationRequestHandler
CLLocationManagerDelegate
ARFaceGeometry
ARSCNFaceGeometry
ARFaceTrackingData
ARFaceTrackingDataProtocol
ARFaceTrackingResults
ARMotionSensor
ARSKView
ARSessionProviding
ARConfiguration
ARRaycastResult
ARPlaneGeometry
ARSCNPlaneGeometry
ARBody2D
ARGeoAnchor
ARArchive
ARRaycastQuery
ARCamera
AROrientationTrackingConfiguration
ARLightEstimate
ARDirectionalLightEstimate
ARReferenceImage
ARCoachingOverlayView
ARPatchGrid
ARGeoTrackingConfiguration
ARSkeleton
ARSkeleton3D
ARSkeleton2D
ARPlaneExtent
ARPlaneAnchor
AREnvironmentProbeAnchor
ARMatteGenerator
ARCollaborationData
ARQuickLookPreviewItem
QLPreviewItem
ARGeoTrackingStatus
ARBodyTrackingConfiguration
ARGeometrySource
ARGeometryElement
ARMeshGeometry
ARBodyAnchor
ARSCNView
ARSCNVisualizationHelper
ARReferenceObject
ARFrame
ARParticipantAnchor
ARHitTestResult
ARFaceAnchor
ARWorldTrackingConfiguration
ARVideoFormat
identifier
initWithIdentifier:transform:
referenceImage
name
stringWithFormat:
appendFormat:
transform
description
estimatedScaleFactor
appendString:
copy
isTracked
setIsTracked:
initWithAnchor:
isDetectionOnly
encodeWithCoder:
encodeObject:forKey:
encodeBool:forKey:
encodeDouble:forKey:
initWithCoder:
decodeObjectOfClass:forKey:
decodeBoolForKey:
decodeDoubleForKey:
supportsSecureCoding
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
TB,R,N
initWithReferenceImage:transform:detectionOnly:tracked:
copyWithTrackedState:
setEstimatedScaleFactor:
setDetectionOnly:
.cxx_destruct
_referenceImageUUID
_detectionOnly
_isTracked
_referenceImage
_estimatedScaleFactor
detectionOnly
TB,N,GisDetectionOnly,V_detectionOnly
TB,N,V_isTracked
T@"ARReferenceImage",R,N,V_referenceImage
Td,R,N,V_estimatedScaleFactor
allocWithZone:
init
copyWithZone:
TB,R
center
extent
anchors
setAnchors:
rawFeaturePoints
_anchors
_rawFeaturePoints
_center
_extent
T,R,N,V_center
T,R,N,V_extent
T@"NSArray",C,N,V_anchors
T@"ARPointCloud",R,N,V_rawFeaturePoints
formatDescription
videoFieldOfView
objectAtIndexedSubscript:
subarrayWithRange:
numberWithFloat:
arrayWithObjects:count:
floatValue
doubleValue
numberWithDouble:
getBytes:length:
objectForKeyedSubscript:
setObject:forKeyedSubscript:
rotationMatrix
processInfo
processName
containsObject:
initWithTransform:
size
confidence
urlDecodingStateInternal
isScaleReliable
urlEncodingVersion
instanceID
absoluteString
radius
encodeFloat:forKey:
encodeInteger:forKey:
decodeFloatForKey:
decodeIntegerForKey:
setRadius:
setConfidence:
setUrl:
setUrlDecodingStateInternal:
setIsScaleReliable:
setUrlEncodingVersion:
initWithAppClipCodeResult:instanceID:
urlDecodingState
copyWithAppClipCodeResult:isTracked:
setInstanceID:
_isScaleReliable
_radius
_confidence
_url
_instanceID
_urlDecodingStateInternal
_urlEncodingVersion
T@"NSURL",C,N,V_url
T@"NSNumber",&,N,V_instanceID
Tf,N,V_confidence
Tf,N,V_radius
Tq,N,V_urlDecodingStateInternal
TB,N,V_isScaleReliable
TQ,N,V_urlEncodingVersion
Tq,R,N
UUID
runWithConfiguration:options:
delegate
session:didFailWithError:
delegateQueue
runWithConfiguration:
pause
addAnchor:
removeAnchor:
setWorldOrigin:
getCurrentWorldMapWithCompletionHandler:
createReferenceObjectWithTransform:center:extent:completionHandler:
raycast:
trackedRaycast:updateHandler:
updateWithCollaborationData:
getGeoLocationForPoint:completionHandler:
captureHighResolutionFrameWithCompletion:
setDelegate:
setDelegateQueue:
currentFrame
configuration
_identifier
_delegate
_delegateQueue
_currentFrame
_configuration
T@"NSUUID",R,V_identifier
T@"<ARSessionDelegate>",W,N,V_delegate
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateQueue
T@"ARFrame",R,C,N,V_currentFrame
T@"ARConfiguration",R,C,N,V_configuration
initPrivate
planeDetection
setPlaneDetection:
initialWorldMap
setInitialWorldMap:
_planeDetection
_initialWorldMap
TQ,N,V_planeDetection
T@"ARWorldMap",&,N,V_initialWorldMap
supportedNumberOfTrackedFaces
supportsWorldTracking
maximumNumberOfTrackedFaces
setMaximumNumberOfTrackedFaces:
isWorldTrackingEnabled
setWorldTrackingEnabled:
_worldTrackingEnabled
_maximumNumberOfTrackedFaces
Tq,N,V_maximumNumberOfTrackedFaces
worldTrackingEnabled
TB,N,GisWorldTrackingEnabled,V_worldTrackingEnabled
count
points
identifiers
.cxx_construct
_pointsVector
_identifiersVector
_count
_points
_identifiers
TQ,R,N,V_count
Tr^,R,N,V_points
Tr^Q,R,N,V_identifiers
isAutoFocusEnabled
setAutoFocusEnabled:
_autoFocusEnabled
autoFocusEnabled
TB,N,GisAutoFocusEnabled,V_autoFocusEnabled
initWithCapacity:
stringWithUTF8String:
addObject:
UTF8String
hasPrefix:
regularExpressionWithPattern:options:error:
length
matchesInString:options:range:
firstObject
numberOfRanges
rangeAtIndex:
substringWithRange:
methodForSelector:
timestamp
cameraTransform
worldTrackingState
worldAlignmentTransform
worldAlignmentModifiers
lightEstimate
featurePoints
segmentationBuffer
anchorsForCameraWithTransform:referenceOriginTransform:existingAnchors:anchorsToRemove:
externalAnchorsWithReferenceOriginTransform:existingAnchors:
initWithDepthMap:confidenceMap:
depthMap
setDepthMap:
confidenceMap
setConfidenceMap:
normalsBuffer
setNormalsBuffer:
confidenceBuffer
setConfidenceBuffer:
setTimestamp:
cameraIntrinsics
setCameraIntrinsics:
extrinsicsToAppNode
setExtrinsicsToAppNode:
deviceTransform
setDeviceTransform:
isValid
setIsValid:
_isValid
_depthMap
_confidenceMap
_normalsBuffer
_confidenceBuffer
_timestamp
_cameraIntrinsics
_extrinsicsToAppNode
_deviceTransform
T^{__CVBuffer=},N,V_depthMap
T^{__CVBuffer=},N,V_confidenceMap
T^{__CVBuffer=},N,V_normalsBuffer
T^{__CVBuffer=},N,V_confidenceBuffer
Td,N,V_timestamp
T{?=[3]},N,V_cameraIntrinsics
T{?=[4]},N,V_extrinsicsToAppNode
T{?=[4]},N,V_deviceTransform
TB,N,V_isValid
stopTracking
bundleWithIdentifier:
infoDictionary
lowercaseString
isEqualToString:
boolForKey:
objectForKey:
boolValue
integerValue
isMultiCamSupported
captureDeviceType
ar_map:
setWithArray:
allObjects
discoverySessionWithDeviceTypes:mediaType:position:
supportedMultiCamDeviceSets
countByEnumeratingWithState:objects:count:
position
captureDevicePosition
deviceType
initWithImageResolution:captureDevicePosition:captureDeviceType:
initToMemory
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
open
close
propertyForKey:
initWithData:encoding:
dataUsingEncoding:
bytes
write:maxLength:
streamError
string
geometry
vertices
normals
faces
buffer
contents
mainBundle
UUIDString
classification
array
isSubclassOfClass:
lastObject
stringByAppendingPathComponent:
stringByAppendingString:
defaultManager
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
bundleWithPath:
objectAtIndex:
providedDataTypes
start
stop
forceUpdatePowerUsage:
waitForOutstandingCallbacks
powerUsage
setPowerUsage:
T@"<ARSensorDelegate>",W,N
TQ,N
T@"<ARSensorDelegate>",W,N,V_delegate
initWithSuiteName:
appleGlobalDomain
dictionaryRepresentation
allKeys
predicateWithBlock:
filteredArrayUsingPredicate:
appleGlobalDomainARKitKeys
dictionary
setObject:forKey:
appleGlobalDomainARKitDefaults
numberWithBool:
objectForKeySlow:
userDefaultsCache
removeObjectForKey:
null
removeAllObjects
removeCachedObjectForKey:
keysApprovedForProcessEnvironmentOverride
environment
defaultValues
shouldUseCache
cachedObjectForKey:
cacheObject:forKey:
stringValue
decimalDigitCharacterSet
addCharactersInString:
invertedSet
componentsSeparatedByCharactersInSet:
setDecimalSeparator:
setNumberStyle:
numberFromString:
numberForKey:
componentsSeparatedByString:
synchronize
clearUserDefaultsCache
removeAllKeys
objectForKey:useCache:
valueForKey:
setValue:forKey:
setBool:forKey:
stringForKey:
integerForKey:
floatForKey:
doubleForKey:
listForKey:
resolutionDictionaryForKey:
referenceObject
initWithReferenceObject:transform:
_referenceObject
T@"ARReferenceObject",R,N,V_referenceObject
initDefault2DSkeletonDefinition
initDefault3DSkeletonDefinition
defaultBody2DSkeletonDefinition
defaultBody3DSkeletonDefinition
T@"ARSkeletonDefinition",R,N
indexForJointName:
jointCount
jointNames
parentIndices
neutralBodySkeleton3D
_jointCount
_jointNames
_parentIndices
_neutralBodySkeleton3D
TQ,R,N,V_jointCount
T@"NSArray",R,N,V_jointNames
T@"NSArray",R,N,V_parentIndices
T@"ARSkeleton3D",R,N,V_neutralBodySkeleton3D
trackingImages
setTrackingImages:
maximumNumberOfTrackedImages
setMaximumNumberOfTrackedImages:
_trackingImages
_maximumNumberOfTrackedImages
T@"NSSet",C,N,V_trackingImages
Tq,N,V_maximumNumberOfTrackedImages
_commonInit:transform:name:
ar_encodeMatrix4x4:forKey:
ar_decodeMatrix4x4ForKey:
sessionIdentifier
referenceTransform
lastUpdateTimestamp
isHiddenFromPublicDelegate
isEqualToAnchor:
_description:
dictionaryWithCapacity:
initWithIdentifier:transform:name:
initWithIdentifier:transform:name:hiddenFromPublicDelegate:
initWithName:transform:
debugQuickLookObject
setSessionIdentifier:
setTransform:
setReferenceTransform:
setLastUpdateTimestamp:
_isHiddenFromPublicDelegate
_name
_sessionIdentifier
_lastUpdateTimestamp
_transform
_referenceTransform
T@"NSUUID",&,N,V_sessionIdentifier
T{?=[4]},N,V_transform
T{?=[4]},N,V_referenceTransform
Td,N,V_lastUpdateTimestamp
TB,R,N,V_isHiddenFromPublicDelegate
T@"NSUUID",R,N,V_identifier
T@"NSString",R,N,V_name
encodeToDictionary
initWithDictionary:
encodeToMetadataWrapper
initWithMetadataWrapper:
Td,N
acceleration
setAcceleration:
temperature
setTemperature:
_temperature
_acceleration
T{?=ddd},N,V_acceleration
Td,N,V_temperature
initWithGeometry:atTimestamp:identifier:visionTransform:referenceOriginTransform:
initWithGeometry:atTimestamp:identifier:transform:
maxExtentError
visionTransform
corner
ar_encodeVector3:forKey:
ar_decodeVector3ForKey:
initWithGeometry:atTimestamp:identifier:referenceOriginTransform:
initWithGeometry:atTimestamp:identifier:
initWithGeometry:atTimestamp:identifier:transform:voxelSize:
setMaxExtentError:
_geometry
_maxExtentError
_corner
_visionTransform
T,R,N,V_corner
Td,R,N,V_timestamp
Td,N,V_maxExtentError
T{?=[4]},R,N,V_visionTransform
T@"ARMeshGeometry",R,N,V_geometry
stopUpdatingLocation
code
lock
authorizationStatus
broadcast
unlock
wait
setLocationCompletionHandler:
startUpdatingLocation
locationManager:didUpdateToLocation:fromLocation:
locationManager:didUpdateLocations:
locationManager:didUpdateHeading:
locationManagerShouldDisplayHeadingCalibration:
locationManager:didDetermineState:forRegion:
locationManager:didRangeBeacons:inRegion:
locationManager:rangingBeaconsDidFailForRegion:withError:
locationManager:didRangeBeacons:satisfyingConstraint:
locationManager:didFailRangingBeaconsForConstraint:error:
locationManager:didEnterRegion:
locationManager:didExitRegion:
locationManager:didFailWithError:
locationManager:monitoringDidFailForRegion:withError:
locationManager:didChangeAuthorizationStatus:
locationManagerDidChangeAuthorization:
locationManager:didStartMonitoringForRegion:
locationManagerDidPauseLocationUpdates:
locationManagerDidResumeLocationUpdates:
locationManager:didFinishDeferredUpdatesWithError:
locationManager:didVisit:
setLocationManager:
waitForAuthorizationStatus
requestLocationWithCompletionHandler:
locationCompletionHandler
_locationManager
_authorizationCondition
_authorizationStatus
_locationCompletionHandler
T@?,C,N,V_locationCompletionHandler
initWithBlendShapes:
vertexCount
textureCoordinateCount
textureCoordinates
triangleCount
triangleIndices
_vertexCount
_vertices
_textureCoordinateCount
_textureCoordinates
_triangleCount
_triangleIndices
TQ,R,N,V_vertexCount
Tr^,R,N,V_vertices
TQ,R,N,V_textureCoordinateCount
Tr^,R,N,V_textureCoordinates
TQ,R,N,V_triangleCount
Tr^s,R,N,V_triangleIndices
faceGeometryWithDevice:
faceGeometryWithDevice:fillMesh:
updateFromFaceGeometry:
initWithTrackingData:transformToMirrored:anchorIdentifier:
_extractMetaDataAndTransformToMirrored:
sharedNeutralGeometry
containsValueForKey:
setWithObjects:
decodeObjectOfClasses:forKey:
initWithTrackingData:anchorIdentifier:
isEqualToDictionary:
leftEyeTransform
rightEyeTransform
gazePoint
imageVertices
normalCount
blendShapeCoefficientsCount
blendShapeCoefficients
trackingData
T@"NSUUID",R,N
T{?=[4]},R,N
T,R,N
TQ,R,N
Tr^,R,N
Tr^f,R,N
T@"NSDictionary",R,N
trackingError
tongueOut
setLeftEyeTransform:
setRightEyeTransform:
setGazePoint:
setTrackingData:
_meshVertices
_verticesImageSpace
_normals
_blendShapeCoefficients
_normalsSemaphore
_imageVerticesSemaphore
_anchorIdentifier
_tongueOut
_trackingError
_trackingData
_gazePoint
_leftEyeTransform
_rightEyeTransform
T{?=[4]},N,V_leftEyeTransform
T{?=[4]},N,V_rightEyeTransform
T,N,V_gazePoint
T@"NSDictionary",&,N,V_trackingData
T@"NSError",R,N,V_trackingError
Tf,R,N,V_tongueOut
trackedFaces
initWithIdentifier:trackingData:
allValues
initWithExistingFaceAnchor:tracked:trackingError:
setTrackedFaces:
_trackedFaces
T@"NSArray",C,N,V_trackedFaces
initWithMotionManager:
initWithFrame:
session
T@"ARSession",R
hitTest:types:
anchorForNode:
nodeForAnchor:
setSession:
_session
T@"NSObject<ARSKViewDelegate>",W,D,N
T@"ARSession",&,N,V_session
stringWithString:
componentsJoinedByString:
isSupported
supportedVideoFormats
supportsFrameSemantics:
recommendedVideoFormatFor4KResolution
recommendedVideoFormatForHighResolutionFrameCapturing
configurableCaptureDeviceForPrimaryCamera
supportsTimeOfFlightProjectorMode
shouldUse30FPSJasperFormats
setShouldUse30FPSJasperFormats:
setShouldProvideX420VideoFormat:
shouldProvideX420VideoFormat
setShouldProvideNonBinnedVideoFormats:
shouldProvideNonBinnedVideoFormats
TB,N
T@"NSArray",R,N
T@"AVCaptureDevice",R,N
T@"ARVideoFormat",R,N
descriptionWithoutBrackets
techniques
isKindOfConfiguration:
getAsKindOfConfiguration:
videoFormat
setVideoFormat:
worldAlignment
setWorldAlignment:
isLightEstimationEnabled
setLightEstimationEnabled:
providesAudioData
setProvidesAudioData:
frameSemantics
setFrameSemantics:
videoHDRAllowed
setVideoHDRAllowed:
deviceModel
parentImageSensorSettings
imageSensorSettings
customSensors
setCustomSensors:
lightEstimation
setLightEstimation:
frameDebugOptions
setFrameDebugOptions:
isPersonMetadataEnabled
setPersonMetadataEnabled:
jasperFrameRate
setJasperFrameRate:
cameraPosition
setCameraPosition:
allowCameraInMultipleForegroundAppLayout
setAllowCameraInMultipleForegroundAppLayout:
disableOcclusionForPersonSegmentation
setDisableOcclusionForPersonSegmentation:
disableMLRelocalization
setDisableMLRelocalization:
mirroredFrameOutput
setMirroredFrameOutput:
replaySensor
timeOfFlightProjectorMode
setTimeOfFlightProjectorMode:
maxUltrawideImageForwardingFrameRate
setMaxUltrawideImageForwardingFrameRate:
_cameraPosition
_videoFormat
_lightEstimationEnabled
_providesAudioData
_videoHDRAllowed
_personMetadataEnabled
_allowCameraInMultipleForegroundAppLayout
_disableOcclusionForPersonSegmentation
_disableMLRelocalization
_mirroredFrameOutput
_worldAlignment
_frameSemantics
_deviceModel
_parentImageSensorSettings
_imageSensorSettings
_customSensors
_lightEstimation
_frameDebugOptions
_jasperFrameRate
_replaySensor
_timeOfFlightProjectorMode
_maxUltrawideImageForwardingFrameRate
T@"NSString",R,N,V_deviceModel
T@"ARParentImageSensorSettings",R,N,V_parentImageSensorSettings
T@"ARImageSensorSettings",R,N,V_imageSensorSettings
T@"NSArray",&,N,V_customSensors
TQ,N,V_lightEstimation
TQ,N,V_frameDebugOptions
personMetadataEnabled
TB,N,GisPersonMetadataEnabled,V_personMetadataEnabled
Tq,N,V_jasperFrameRate
Tq,N,V_cameraPosition
TB,N,V_allowCameraInMultipleForegroundAppLayout
TB,N,V_disableOcclusionForPersonSegmentation
TB,N,V_disableMLRelocalization
TB,N,V_mirroredFrameOutput
T@"<ARReplaySensorProtocol>",R,N,V_replaySensor
T@"NSString",&,N,V_timeOfFlightProjectorMode
Tq,N,V_maxUltrawideImageForwardingFrameRate
T@"ARVideoFormat",&,N,V_videoFormat
Tq,N,V_worldAlignment
lightEstimationEnabled
TB,N,GisLightEstimationEnabled,V_lightEstimationEnabled
TB,N,V_providesAudioData
TQ,N,V_frameSemantics
TB,N,V_videoHDRAllowed
worldTransform
target
targetAlignment
anchor
_target
_targetAlignment
_anchor
_worldTransform
T{?=[4]},R,N,V_worldTransform
Tq,R,N,V_target
Tq,R,N,V_targetAlignment
T@"ARAnchor",R,N,V_anchor
boundaryVertexCount
boundaryVertices
_boundaryVertexCount
_boundaryVertices
TQ,R,N,V_boundaryVertexCount
Tr^,R,N,V_boundaryVertices
planeGeometryWithDevice:
updateFromPlaneGeometry:
skeleton
_skeleton
T@"ARSkeleton2D",R,N,V_skeleton
initWithCoordinate:altitude:altitudeSource:isAltitudeAvailable:undulation:
altitude
altitudeSource
isAltitudeAvailable
undulation
stringByReplacingCharactersInRange:withString:
coordinate
initWithCoordinate:
initWithCoordinate:altitude:
initWithName:coordinate:
initWithName:coordinate:altitude:
isAltitudeLookupInProgress
setIsAltitudeLookupInProgress:
locationLLA
locationECEF
ecefFromAnchor
_isAltitudeAvailable
_isAltitudeLookupInProgress
_altitudeSource
_undulation
_coordinate
_locationLLA
_locationECEF
_ecefFromAnchor
TB,R,N,V_isAltitudeAvailable
TB,N,V_isAltitudeLookupInProgress
Td,R,N,V_undulation
T,R,N,V_locationLLA
T,R,N,V_locationECEF
T{?=[4]},R,N,V_ecefFromAnchor
T{CLLocationCoordinate2D=dd},R,N,V_coordinate
Td,R,N
Tq,R,N,V_altitudeSource
_loadArchiveFromURL:error:
_loadArchiveFromMemory:error:
stringByAppendingPathExtension:
addData:withPath:
dataForResourceAtPath:
path
localizedStringForKey:value:table:
fileSystemRepresentation
_writeToArchive:
_createArchiveForReading
_readDataFromArchive:
_readDataForEntry:archive:
appendBytes:length:
initWithContentsOfURL:error:
initWithData:error:
filePaths
addData:withFilename:extension:
dataForResource:withExtension:
writeToURL:error:
dataRepresentation
_dataByPath
T@"NSArray",R,C,N
initWithOrigin:direction:allowingTarget:alignment:
origin
direction
_origin
_direction
T,R,N,V_origin
T,R,N,V_direction
_bundleWithIdentifier:andLibraryName:
projectionMatrixForOrientation:viewportSize:zNear:zFar:
projectPoint:orientation:viewportSize:
unprojectPoint:ontoPlaneWithTransform:orientation:viewportSize:
viewMatrixForOrientation:
eulerAngles
trackingState
trackingStateReason
intrinsics
imageResolution
exposureDuration
exposureOffset
projectionMatrix
_exposureOffset
_trackingState
_trackingStateReason
_exposureDuration
_eulerAngles
_imageResolution
_intrinsics
_projectionMatrix
T{?=[4]},R,N,V_transform
T,R,N,V_eulerAngles
Tq,R,N,V_trackingState
Tq,R,N,V_trackingStateReason
T{?=[3]},R,N,V_intrinsics
T{CGSize=dd},R,N,V_imageResolution
Td,R,N,V_exposureDuration
Tf,R,N,V_exposureOffset
T{?=[4]},R,N,V_projectionMatrix
addEntriesFromDictionary:
ambientIntensity
ambientColorTemperature
_ambientIntensity
_ambientColorTemperature
Td,R,N,V_ambientIntensity
Td,R,N,V_ambientColorTemperature
sphericalHarmonicsCoefficients
primaryLightDirection
primaryLightIntensity
_sphericalHarmonicsCoefficients
_primaryLightIntensity
_primaryLightDirection
T@"NSData",R,C,N,V_sphericalHarmonicsCoefficients
T,R,N,V_primaryLightDirection
Td,R,N,V_primaryLightIntensity
referenceImagesInGroupNamed:bundle:
validateWithCompletionHandler:
initWithCGImage:orientation:physicalWidth:
initWithPixelBuffer:orientation:physicalWidth:
setName:
physicalSize
resourceGroupName
_resourceGroupName
_physicalSize
T@"NSString",C,N,V_name
T{CGSize=dd},R,N,V_physicalSize
T@"NSString",R,N,V_resourceGroupName
setSessionProvider:
setGoal:
isActive
setActive:animated:
intrinsicContentSize
sessionProvider
goal
activatesAutomatically
setActivatesAutomatically:
_activatesAutomatically
_sessionProvider
_goal
T@"<ARCoachingOverlayViewDelegate>",W,N,V_delegate
T@"NSObject<ARSessionProviding>",W,N,V_sessionProvider
Tq,N,V_goal
TB,N,V_activatesAutomatically
initWithPatchesVector:pivotAngle:
encodeBytes:length:forKey:
decodeBytesForKey:returnedLength:
patches
pivot
_patchesVector
_angle
Tr^{?=},R,N
Tf,R,N
checkAvailabilityWithCompletionHandler:
checkAvailabilityAtCoordinate:completionHandler:
supportsAppClipCodeTracking
setDetectionImages:
environmentTexturing
setEnvironmentTexturing:
wantsHDREnvironmentTextures
setWantsHDREnvironmentTextures:
detectionImages
automaticImageScaleEstimationEnabled
setAutomaticImageScaleEstimationEnabled:
detectionObjects
setDetectionObjects:
appClipCodeTrackingEnabled
setAppClipCodeTrackingEnabled:
_wantsHDREnvironmentTextures
_automaticImageScaleEstimationEnabled
_appClipCodeTrackingEnabled
_environmentTexturing
_detectionImages
_detectionObjects
Tq,D,N
Tq,N,V_environmentTexturing
TB,N,V_wantsHDREnvironmentTextures
T@"NSSet",C,N,V_detectionImages
TB,N,V_automaticImageScaleEstimationEnabled
T@"NSSet",C,N,V_detectionObjects
TB,N,V_appClipCodeTrackingEnabled
isJointTracked:
definition
_definition
T@"ARSkeletonDefinition",R,N,V_definition
modelTransformForJointName:
localTransformForJointName:
jointModelTransforms
jointLocalTransforms
_jointModelTransforms
_jointLocalTransforms
Tr^{?=[4]},R,N,V_jointModelTransforms
Tr^{?=[4]},R,N,V_jointLocalTransforms
landmarkForJointNamed:
jointLandmarks
_jointLandmarks
Tr^,R,N,V_jointLandmarks
bundleIdentifier
rotationOnYAxis
width
height
setRotationOnYAxis:
setWidth:
setHeight:
_rotationOnYAxis
_width
_height
Tf,N,V_rotationOnYAxis
Tf,N,V_width
Tf,N,V_height
isClassificationSupported
classificationSupported
TB,R,N,GisClassificationSupported
alignment
setCenter:
setExtent:
planeExtent
setPlaneExtent:
setGeometry:
classificationStatus
setClassificationStatus:
setClassification:
gridExtent
setGridExtent:
uncertaintyAlongNormal
setUncertaintyAlongNormal:
worldAlignmentRotation
setWorldAlignmentRotation:
possibleClassifications
setPossibleClassifications:
classificationLabel
setClassificationLabel:
_uncertaintyAlongNormal
_alignment
_planeExtent
_classificationStatus
_classification
_gridExtent
_worldAlignmentRotation
_possibleClassifications
_classificationLabel
T,N,V_center
T,N,V_extent
T@"ARPlaneExtent",&,N,V_planeExtent
T@"ARPlaneGeometry",&,V_geometry
T@"ARPatchGrid",&,N,V_gridExtent
Tf,N,V_uncertaintyAlongNormal
Tq,N,V_worldAlignmentRotation
Tq,N,V_classificationStatus
Tq,N,V_classification
T@"NSDictionary",C,N,V_possibleClassifications
T@"NSString",&,N,V_classificationLabel
Tq,R,N,V_alignment
environmentTexture
clippingPointLux
parametricLights
sourceKeyframeUUIDs
trackedPlaneIdentifier
colorHistogram
opaquePixelPercentage
initWithTransform:extent:
initWithName:transform:extent:
initWithIdentifier:transform:extent:
initWithIdentifier:onPlane:
setEnvironmentTexture:
setClippingPointLux:
setParametricLights:
setSourceKeyframeUUIDs:
setColorHistogram:
setOpaquePixelPercentage:
setTrackedPlaneIdentifier:
_clippingPointLux
_opaquePixelPercentage
_environmentTexture
_parametricLights
_sourceKeyframeUUIDs
_colorHistogram
_trackedPlaneIdentifier
T@"<MTLTexture>",&,N,V_environmentTexture
Tf,N,V_clippingPointLux
T@"ARParametricLights",&,N,V_parametricLights
T@"NSSet",&,N,V_sourceKeyframeUUIDs
T@"NSData",&,N,V_colorHistogram
Tf,N,V_opaquePixelPercentage
T@"NSUUID",&,N,V_trackedPlaneIdentifier
initWithDevice:matteResolution:
generateMatteFromFrame:commandBuffer:
generateDilatedDepthFromFrame:commandBuffer:
priority
_priority
Tq,R,N,V_priority
fileURL
previewItemURL
previewItemTitle
T@"NSURL",R,N
T@"NSString",R,N
initWithFileAtURL:
canonicalWebPageURL
setCanonicalWebPageURL:
allowsContentScaling
setAllowsContentScaling:
setFileURL:
_allowsContentScaling
_canonicalWebPageURL
_fileURL
T@"NSURL",&,N,V_fileURL
T@"NSURL",&,N,V_canonicalWebPageURL
TB,N,V_allowsContentScaling
initWithGeoTrackingState:accuracy:stateReason:failureReasons:
failureReasons
state
accuracy
stateReason
decodeIntForKey:
initialStatus
isEqualPrivate:
setState:
setStateReason:
_state
_accuracy
_stateReason
_failureReasons
Tq,R,N,V_failureReasons
Tq,N,V_state
Tq,N,V_stateReason
Tq,R,N,V_accuracy
automaticSkeletonScaleEstimationEnabled
setAutomaticSkeletonScaleEstimationEnabled:
_automaticSkeletonScaleEstimationEnabled
TB,N,V_automaticSkeletonScaleEstimationEnabled
format
componentsPerVector
offset
stride
_buffer
_format
_componentsPerVector
_offset
_stride
T@"<MTLBuffer>",R,N,V_buffer
Tq,R,N,V_count
TQ,R,N,V_format
Tq,R,N,V_componentsPerVector
Tq,R,N,V_offset
Tq,R,N,V_stride
bytesPerIndex
indexCountPerPrimitive
primitiveType
_bytesPerIndex
_indexCountPerPrimitive
_primitiveType
Tq,R,N,V_bytesPerIndex
Tq,R,N,V_indexCountPerPrimitive
Tq,R,N,V_primitiveType
_faces
T@"ARGeometrySource",R,N,V_vertices
T@"ARGeometrySource",R,N,V_normals
T@"ARGeometryElement",R,N,V_faces
T@"ARGeometrySource",R,N,V_classification
initWithCoreRESkeletonResult:
liftedSkeletonData
skeletonDetectionResult2D
initWithDetectedSkeleton:
initWithSkeleton2D:
initWithIdentifier:transform:tracked:skeletonData:
decodeObjectForKey:
isEqualToARBodyAnchor:
referenceBody
_tracked
_skeletonData
_referenceBody
T@"ARBody2D",R,N
T@"ARSkeleton3D",R,N,V_skeleton
initWithFrame:options:
unprojectPoint:ontoPlaneWithTransform:
raycastQueryFromPoint:allowingTarget:alignment:
automaticallyUpdatesLighting
setAutomaticallyUpdatesLighting:
rendersCameraGrain
setRendersCameraGrain:
rendersMotionBlur
setRendersMotionBlur:
_automaticallyUpdatesLighting
_rendersCameraGrain
_rendersMotionBlur
T@"<ARSCNViewDelegate>",W,D,N
scene
T@"SCNScene",&,D,N
TB,N,V_automaticallyUpdatesLighting
TB,N,V_rendersCameraGrain
TB,N,V_rendersMotionBlur
material
diffuse
setContents:
blackColor
ambient
setLightingModelName:
setLocksAmbientWithDiffuse:
redColor
createMaterialWithTexture:
boxWithWidth:height:length:chamferRadius:
setMaterials:
nodeWithGeometry:
setPosition:
greenColor
blueColor
node
addChildNode:
dataWithBytes:length:
geometrySourceWithData:semantic:vectorCount:floatComponents:componentsPerVector:bytesPerComponent:dataOffset:dataStride:
geometryElementWithData:primitiveType:primitiveCount:bytesPerIndex:
setPointSize:
setMinimumPointScreenSpaceRadius:
setMaximumPointScreenSpaceRadius:
geometryWithSources:elements:
colorWithRed:green:blue:alpha:
setFirstMaterial:
createAxesNode:
createGeometryForPointCloud:
referenceObjectsInGroupNamed:bundle:
referenceObjectsInGroupNamed:catalogURL:
referenceObjectsInGroupNamed:catalogName:bundle:
writeToArchiveWithPreviewImage:error:
initWithArchiveURL:error:
initWithArchiveData:error:
initWithArchiveData:name:error:
initWithTrackingData:referenceOriginTransform:
exportObjectToURL:previewImage:error:
exportObjectToMemoryWithPreviewImage:error:
referenceObjectByApplyingTransform:
referenceObjectByMergingObject:error:
scale
version
referenceOriginTransform
keyframes
_version
_keyframes
_scale
_referenceOriginTransform
Tq,R,N,V_version
T@"NSData",R,N,V_trackingData
T{?=[4]},R,N,V_referenceOriginTransform
T@"NSSet",R,N,V_keyframes
T,R,N,V_scale
displayTransformForOrientation:viewportSize:
detectedBody
capturedImage
exifData
cameraGrainTexture
cameraGrainIntensity
capturedDepthData
capturedDepthDataTimestamp
camera
worldMappingStatus
estimatedDepthData
geoTrackingStatus
sceneDepth
smoothedSceneDepth
_cameraGrainIntensity
_capturedImage
_exifData
_cameraGrainTexture
_capturedDepthData
_capturedDepthDataTimestamp
_camera
_lightEstimate
_worldMappingStatus
_segmentationBuffer
_estimatedDepthData
_geoTrackingStatus
_sceneDepth
_smoothedSceneDepth
T^{__CVBuffer=},R,N,V_capturedImage
T@"NSDictionary",R,N,V_exifData
T@"<MTLTexture>",R,N,V_cameraGrainTexture
Tf,R,N,V_cameraGrainIntensity
T@"AVDepthData",R,N,V_capturedDepthData
Td,R,N,V_capturedDepthDataTimestamp
T@"ARCamera",R,C,N,V_camera
T@"NSArray",R,C,N,V_anchors
T@"ARLightEstimate",R,N,V_lightEstimate
T@"ARPointCloud",R,N
Tq,R,N,V_worldMappingStatus
T^{__CVBuffer=},R,N,V_segmentationBuffer
T^{__CVBuffer=},R,N,V_estimatedDepthData
T@"ARGeoTrackingStatus",R,N,V_geoTrackingStatus
T@"ARDepthData",R,N,V_sceneDepth
T@"ARDepthData",R,N,V_smoothedSceneDepth
initWithType:
type
distance
localTransform
_type
_distance
_localTransform
TQ,R,N,V_type
Td,R,N,V_distance
T{?=[4]},R,N,V_localTransform
initWithIdentifier:faceTrackingData:
initWithFaceTrackingDataProtocol:
numberWithInt:
blendShapeMapping
mirroredBlendShapeMapping
enumerateKeysAndObjectsUsingBlock:
blendShapeToMirroredBlendShapeMapping
faceTrackingData
blendShapes
lookAtPoint
isEqualToFaceAnchor:
setTrackingError:
_blendShapeCoefficientsDictionary
T@"<ARFaceTrackingDataProtocol>",&,N,V_trackingData
T@"NSError",&,N,V_trackingError
T@"ARFaceGeometry",R,N,V_geometry
supportsUserFaceTracking
supportsSceneReconstruction:
isCollaborationEnabled
setCollaborationEnabled:
userFaceTrackingEnabled
setUserFaceTrackingEnabled:
sceneReconstruction
setSceneReconstruction:
_collaborationEnabled
_userFaceTrackingEnabled
_sceneReconstruction
collaborationEnabled
TB,N,GisCollaborationEnabled,V_collaborationEnabled
TB,N,GuserFaceTrackingEnabled,V_userFaceTrackingEnabled
TQ,N,V_sceneReconstruction
framesPerSecond
isRecommendedForHighResolutionFrameCapturing
isVideoHDRSupported
_isRecommendedForHighResolutionFrameCapturing
_videoHDRSupported
_captureDevicePosition
_captureDeviceType
_framesPerSecond
Tq,R,N,V_captureDevicePosition
T@"NSString",R,N,V_captureDeviceType
Tq,R,N,V_framesPerSecond
TB,R,N,V_isRecommendedForHighResolutionFrameCapturing
videoHDRSupported
TB,R,N,GisVideoHDRSupported,V_videoHDRSupported
B16@0:8
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@96@0:8@16{?=[4]}24B88B92
@20@0:8B16
@24@0:8@16
v24@0:8@16
v24@0:8d16
d16@0:8
v20@0:8B16
v16@0:8
@"NSUUID"
@"ARReferenceImage"
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
16@0:8
@"NSArray"
@"ARPointCloud"
@32@0:8@16@24
q16@0:8
@28@0:8@16B24
f16@0:8
v20@0:8f16
v24@0:8q16
v24@0:8Q16
@"NSURL"
@"NSNumber"
v32@0:8@16Q24
v80@0:8{?=[4]}16
v24@0:8@?16
v120@0:8{?=[4]}168096@?112
@32@0:8@16@?24
v40@0:816@?32
@"<ARSessionDelegate>"
@"NSObject<OS_dispatch_queue>"
@"ARFrame"
@"ARConfiguration"
@"ARWorldMap"
r^16@0:8
r^Q16@0:8
{vector<float __attribute__((ext_vector_type(3))), std::allocator<float __attribute__((ext_vector_type(3)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(3))), std::allocator<float __attribute__((ext_vector_type(3)))>>="__value_"^}}
{vector<unsigned long long, std::allocator<unsigned long long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>="__value_"^Q}}
{?=[4]}16@0:8
^{__CVBuffer=}16@0:8
@160@0:8{?=[4]}16{?=[4]}80@144@152
@88@0:8{?=[4]}16@80
@"ARWorldTrackingState"16@0:8
@"ARLightEstimate"16@0:8
@"ARPointCloud"16@0:8
@"NSArray"160@0:8{?=[4]}16{?=[4]}80@"NSArray"144@"NSMutableArray"152
@"NSArray"88@0:8{?=[4]}16@"NSArray"80
@32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
v24@0:8^{__CVBuffer=}16
{?=[3]}16@0:8
v64@0:8{?=[3]}16
^{__CVBuffer=}
{?="columns"[3]}
{?="columns"[4]}
@"<ARSensorDelegate>"16@0:8
v24@0:8@"<ARSensorDelegate>"16
@"<ARSensorDelegate>"
v32@0:8@16@24
v28@0:8B16@20
q24@0:8@16
f24@0:8@16
d24@0:8@16
@88@0:8@16{?=[4]}24
@"ARReferenceObject"
Q24@0:8@16
@"ARSkeleton3D"
@"NSSet"
@24@0:8@"ARAnchor"16
@80@0:8{?=[4]}16
@96@0:8@16{?=[4]}24@88
@100@0:8@16{?=[4]}24@88B96
v96@0:8@16{?=[4]}24@88
@"NSString"
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
@"NSData"16@0:8
@24@0:8@"NSData"16
{?=ddd}16@0:8
v40@0:8{?=ddd}16
{?="x"d"y"d"z"d}
@104@0:8@16d24@32{?=[4]}40
@168@0:8@16d24@32{?=[4]}40{?=[4]}104
@40@0:8@16d24@32
@112@0:8@16d24@32{?=[4]}40d104
@"ARMeshGeometry"
v40@0:8@16@24@32
v40@0:8@16q24@32
v28@0:8@16i24
v40@0:8@"CLLocationManager"16@"CLLocation"24@"CLLocation"32
v32@0:8@"CLLocationManager"16@"NSArray"24
v32@0:8@"CLLocationManager"16@"CLHeading"24
B24@0:8@"CLLocationManager"16
v40@0:8@"CLLocationManager"16q24@"CLRegion"32
v40@0:8@"CLLocationManager"16@"NSArray"24@"CLBeaconRegion"32
v40@0:8@"CLLocationManager"16@"CLBeaconRegion"24@"NSError"32
v40@0:8@"CLLocationManager"16@"NSArray"24@"CLBeaconIdentityConstraint"32
v40@0:8@"CLLocationManager"16@"CLBeaconIdentityConstraint"24@"NSError"32
v32@0:8@"CLLocationManager"16@"CLRegion"24
v32@0:8@"CLLocationManager"16@"NSError"24
v40@0:8@"CLLocationManager"16@"CLRegion"24@"NSError"32
v28@0:8@"CLLocationManager"16i24
v24@0:8@"CLLocationManager"16
v32@0:8@"CLLocationManager"16@"CLVisit"24
i16@0:8
@?16@0:8
@"CLLocationManager"
@"NSCondition"
r^s16@0:8
r^f16@0:8
@"NSUUID"16@0:8
@36@0:8@16B24@28
v32@0:816
{vector<float __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__value_"^}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@"NSDictionary"
@"ARSession"16@0:8
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@40@0:8{CGPoint=dd}16Q32
@"ARSession"
B24@0:8Q16
@24@0:8#16
@"ARVideoFormat"
@"ARParentImageSensorSettings"
@"ARImageSensorSettings"
@"<ARReplaySensorProtocol>"
@"ARAnchor"
@"ARSkeleton2D"
@32@0:8{CLLocationCoordinate2D=dd}16
@40@0:8{CLLocationCoordinate2D=dd}16d32
@40@0:8@16{CLLocationCoordinate2D=dd}24
@48@0:8@16{CLLocationCoordinate2D=dd}24d40
v60@0:8{CLLocationCoordinate2D=dd}16d32q40B48d52
{CLLocationCoordinate2D=dd}16@0:8
{CLLocationCoordinate2D="latitude"d"longitude"d}
@32@0:8@16^@24
B32@0:8@16^@24
B24@0:8^{archive=}16
^{archive=}16@0:8
B32@0:8^{archive_entry=}16^{archive=}24
@"NSMutableDictionary"
@64@0:81632q48q56
{?=[4]}56@0:8q16{CGSize=dd}24d40d48
{CGPoint=dd}56@0:816q32{CGSize=dd}40
120@0:8{CGPoint=dd}16{?=[4]}32q96{CGSize=dd}104
{?=[4]}24@0:8q16
{CGSize=dd}16@0:8
{CGSize="width"d"height"d}
@"NSData"
@36@0:8^{CGImage=}16I24d28
@36@0:8^{__CVBuffer=}16I24d28
v24@0:8B16B20
@"<ARCoachingOverlayViewDelegate>"
@"NSObject<ARSessionProviding>"
@44@0:8{vector<ARPatch, std::allocator<ARPatch>>=^{?}^{?}{__compressed_pair<ARPatch *, std::allocator<ARPatch>>=^{?}}}16f40
r^{?=}16@0:8
{vector<ARPatch, std::allocator<ARPatch>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<ARPatch *, std::allocator<ARPatch>>="__value_"^{?}}}
v40@0:8{CLLocationCoordinate2D=dd}16@?32
B24@0:8q16
@"ARSkeletonDefinition"
{?=[4]}24@0:8@16
r^{?=[4]}16@0:8
r^{?=[4]}
24@0:8@16
@"ARPlaneExtent"
@"ARPlaneGeometry"
@"ARPatchGrid"
@96@0:8{?=[4]}1680
@104@0:8@16{?=[4]}2488
@248@0:8@16{ARTexturedPlane={array<unsigned char, 16UL>=[16C]}Q{?=[4]}{array<float __attribute__((ext_vector_type(3))), 4UL>=[4]}{set<std::array<unsigned char, 16>, std::less<std::array<unsigned char, 16>>, std::allocator<std::array<unsigned char, 16>>>={__tree<std::array<unsigned char, 16>, std::less<std::array<unsigned char, 16>>, std::allocator<std::array<unsigned char, 16>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::array<unsigned char, 16>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::array<unsigned char, 16>>>=Q}}}@}24
@"<MTLTexture>"
@"ARParametricLights"
@32@0:8@16q24
@"NSURL"16@0:8
@48@0:8q16q24q32q40
@"<MTLBuffer>"
@"ARGeometrySource"
@"ARGeometryElement"
@100@0:8@16{?=[4]}24B88@92
@"ARCoreRESkeletonResult"
@"ARBody2D"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
96@0:8{CGPoint=dd}16{?=[4]}32
@48@0:8{CGPoint=dd}16q32q40
@24@0:8d16
@40@0:8@16@24@32
@40@0:8@16@24^@32
B40@0:8@16@24^@32
{CGAffineTransform=dddddd}40@0:8q16{CGSize=dd}24
@"AVDepthData"
@"ARCamera"
@"ARLightEstimate"
@"ARGeoTrackingStatus"
@"ARDepthData"
@24@0:8Q16
@"ARFaceGeometry"
@"<ARFaceTrackingDataProtocol>"
@(#)PROGRAM:ARKit  PROJECT:ARKit-381.28
MbP?
%.(...+
<%@: %p
 identifier="%@"
 name="%@"
 transform=%@
 referenceImage=%@
 tracked=%@
 estimatedScale=%f
referenceImage
referenceImageUUID
detectionOnly
tracked
estimatedScaleFactor
translation
rotation
scale
perspective
 matrix=
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
<matrix=
(%f, %f, %f)
(%f, %f, %f)
(%f, %f, %f)
<matrix=
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f, %f, %f, %f)
(%f %f %f)
(%f %f %f %f)
%@ = [%f,%f,%f]
%@ = [%f,%f,%f,%f]
%@ = [%f,%f,%f;
%f,%f,%f;
%f,%f,%f]
%@ = [%f,%f,%f,%f;
%f,%f,%f,%f;
%f,%f,%f,%f;
%f,%f,%f,%f]
v8@?0
arkitd
arkitctl
ARExamples
ARKit_iOS_tests_app
com.apple.ARKit
General
<%@: %p instanceID=%@ url="%@" identifier="%@" transform=%@>
instanceID
confidence
radius
urlDecodingStateInternal
isTracked
isScaleReliable
urlEncodingVersion
@"(.*)"
BuildVersion
CFBundleVersion
rear-facing-camera
front-facing-camera
FrontCameraOffsetFromDisplayCenter
FrontCameraRotationFromDisplayNormal
RearCameraOffsetFromDisplayCenter
+N9mZUAHooNvMiQnjeTJ8g
AirplaneMode
566JrJVMlDfnslGpwUzNlQ
@16@?0@"ARVideoFormat"8
hnXJ1OpiiIL0+p3jUG/XxQ
Failed to create an in-memory output stream.
Writing a string to an output stream failed with an unknown error.
An anchor geometrie's vertex count does not match normal count.
A face index is out of range.
There is no mesh to save.
# ARKit mesh exported from ARExamples %@, ARKit %@, AppleCV3D %@
com.apple.AppleCV3D
# Vertex count: %d
# Face count: %d
# Real world scale is 1 unit = 1 m
# Each vertex is followed by four RGBA color values in range [0.0 - 1.0] (not in spec)
o mesh_anchor_%@
v %.06f %.06f %.06f %.03f %.03f %.03f %.03f
vn %f %f %f
f %d//%d %d//%d %d//%d
# EOF
pid=%d <Unknown>
kern.boottime
Back
Front
Unspecified
ARKit
Frameworks/ARKit.framework
com.apple.ARKitUI
PrivateFrameworks/ARKitUI.framework
com.apple.ARKitCore
PrivateFrameworks/ARKitCore.framework
Apple Global Domain
B24@?0@"NSString"8@"NSDictionary"16
com.apple.arkit.
com_apple_arkit_
QVwCp3Lu9RLnxw7LO9DBfQ
System Default
test
width
height
com.apple.arkit.useCacheForUserDefaults
com.apple.arkit.bufferPopulationMonitor
com.apple.arkit.session.cameraPosition
com.apple.arkit.session.qatracing
com.apple.arkit.session.qatracing.screenRecording
com.apple.arkit.session.qatracing.forceQuitApp
com.apple.arkit.session.qatracing.framesLabelOffset
com.apple.arkit.session.qatracing.dumpSemanticSegmantationData
com.apple.arkit.session.qatracing.filepath
com.apple.arkit.session.record.filepath
com.apple.arkit.session.forceRecording
com.apple.arkit.session.replay.filepath
com.apple.arkit.session.replay.filepath.manual
com.apple.arkit.session.defaultRelocalizationTimeout
com.apple.arkit.session.useIOKit
com.apple.arkit.session.disableSessionMetricsReporting
com.apple.arkit.daemonMetrics.disableReporting
com.apple.arkit.session.mirroredFrameOutput
com.apple.arkit.session.featurePointAccumulationCount
com.apple.arkit.motionSensor.sampleRate
com.apple.arkit.motionSensor.magnetometerEnabled
com.apple.arkit.imagesensor.attemptfailurerecovery
com.apple.arkit.imagesensor.attemptfailurerecoveryafterbackground
com.apple.arkit.imagesensor.back.wide.resolution
com.apple.arkit.imagesensor.back.wide.frameRate
com.apple.arkit.imagesensor.back.wide.videoBinned
com.apple.arkit.imagesensor.back.wide.exposureDuration
com.apple.arkit.imagesensor.back.wide.iso
com.apple.arkit.imagesensor.back.wide.whiteBalance
com.apple.arkit.imagesensor.back.wide.lensPosition
com.apple.arkit.imagesensor.back.wide.autoFocus
com.apple.arkit.imagesensor.back.wide.smoothAutoFocus
com.apple.arkit.imagesensor.back.wide.autoFocusRange
com.apple.arkit.imagesensor.back.wide.photoQualityPrioritization
com.apple.arkit.imagesensor.front.resolution
com.apple.arkit.imagesensor.front.frameRate
com.apple.arkit.imagesensor.front.videoBinned
com.apple.arkit.imagesensor.front.exposureDuration
com.apple.arkit.imagesensor.front.iso
com.apple.arkit.imagesensor.front.whiteBalance
com.apple.arkit.imagesensor.back.ultrawide.resolution
com.apple.arkit.imagesensor.back.ultrawide.frameRate
com.apple.arkit.imagesensor.back.ultrawide.videoBinned
com.apple.arkit.imagesensor.back.ultrawide.exposureDuration
com.apple.arkit.imagesensor.back.ultrawide.iso
com.apple.arkit.imagesensor.back.ultrawide.whiteBalance
com.apple.arkit.imagesensor.back.ultrawide.geometricDistortionCorrection
com.apple.arkit.imagesensor.initialFrameDrop.enabled
com.apple.arkit.imagesensor.initialFrameDrop.negativeExposureTargetOffsetThreshold
com.apple.arkit.imagesensor.initialFrameDrop.positiveExposureTargetOffsetThreshold
com.apple.arkit.imagesensor.initialFrameDrop.maxDroppedFramesCount
com.apple.arkit.imagesensor.videoHDR.allowed
com.apple.arkit.imagesensor.calibrationData.alwaysDiscardsLateData
com.apple.arkit.imagesensor.face.frameRateNormal
com.apple.arkit.imagesensor.face.frameRateLow
com.apple.arkit.imagesensor.face.frameRateLowest
com.apple.arkit.imagesensor.face.previousImageDataOnDrop
com.apple.arkit.imagesensor.face.mirror
com.apple.arkit.imageSensor.face.depthDataFiltering
com.apple.arkit.faceTracking.rgbOnly.enabled
com.apple.arkit.faceTracking.backCamera.allowed
com.apple.arkit.faceTracking.lowPowerMode.enabled
com.apple.arkit.planeEstimation.minDetectionCount
com.apple.arkit.planeEstimation.minVergenceAngle
com.apple.arkit.planeEstimation.lineFeaturesAlwaysOn
com.apple.arkit.planeEstimation.mlOnANEDevices
com.apple.arkit.planeEstimation.normalsKernelSize
com.apple.arkit.planeEstimation.enableLowQosScheduling
com.apple.arkit.planeEstimation.detectionMethod
com.apple.arkit.planeEstimation.enableInverseDepthDetector
com.apple.arkit.planeEstimation.anchorRotation
com.apple.arkit.worldtracking.calibrationParameters.imu
com.apple.arkit.worldtracking.calibrationParameters.back.wide
com.apple.arkit.worldtracking.calibrationParameters.back.ultrawide
com.apple.arkit.worldtracking.slamConfiguration
com.apple.arkit.worldtracking.lineFeatures
com.apple.arkit.worldtracking.lineFeaturesAlwaysOn
com.apple.arkit.worldtracking.minVergenceAngle
com.apple.arkit.worldtracking.poseGraphUpdates
com.apple.arkit.worldTracking.resultLatency
com.apple.arkit.worldtracking.fixedIntrinsics
com.apple.arkit.worldtracking.deviceModel
com.apple.arkit.worldTracking.visionData
com.apple.arkit.worldTracking.simulateHWFeatureDetection
com.apple.arkit.worldTracking.useLACCIfAvailable
com.apple.arkit.worldTracking.collaborativeMappingStatistics
com.apple.arkit.worldTracking.useUltraWide
com.apple.arkit.worldTracking.forceDisableFrontCamera
com.apple.arkit.worldTracking.participantAnchors
com.apple.arkit.worldTracking.warningSounds
com.apple.arkit.worldTracking.mlRelocalizationMode
com.apple.arkit.worldTracking.accuratePlaneExtentCheck
com.apple.arkit.worldTracking.newCV3DApis
com.apple.arkit.worldTracking.enableMLCMRelocalization
com.apple.arkit.worldtracking.transformToExternalSubmap
com.apple.arkit.worldtracking.enableTempMappingDirectory
com.apple.arkit.geotracking.useclfusion
com.apple.arkit.geotracking.usecmfusion
com.apple.arkit.geotracking.usegradualcorrection
com.apple.arkit.geotracking.gradualcorrectioninterval
com.apple.arkit.geotracking.useVLTraceRecorder
com.apple.arkit.geotracking.bypassChecksForANE
com.apple.arkit.geotracking.bypassChecksForGPS
com.apple.arkit.geotracking.visualLocalizationCallInterval
com.apple.arkit.geotracking.posteriorVisualLocalizationCallInterval
com.apple.arkit.geotracking.visualLocalizationCallIntervalTimeThreshold
com.apple.arkit.imagedetection.assetcatalog
com.apple.arkit.imageDetection.fixedPriorityProcessingQueue
com.apple.arkit.imagedetection.percentageThresholdPixels
com.apple.arkit.objctdetection.fixedPriorityProcessingQueue
com.apple.arkit.objctdetection.regionProposalModel
com.apple.arkit.environmentTexturing.minimumProbeUpdateInterval
com.apple.arkit.environmentTexturing.wantsHDR
com.apple.arkit.environmentTexturing.maxHDR
com.apple.arkit.personDetectionTechnique.renderBoundingBoxesIntoCapturedImage
com.apple.arkit.personDetectionTechnique.mergeLargelyOverlappingBoundingBoxes
com.apple.arkit.personocclusion.skipFrameWhenBusy
com.apple.arkit.scaling.useOptimalMSRCoeficients
com.apple.arkit.matting.erosionRadius
com.apple.arkit.matting.uncertaintyRadius
com.apple.arkit.matting.epsilon
com.apple.arkit.matting.disableSoftEdges
com.apple.arkit.matting.depthScale
com.apple.arkit.matting.dilationRadius
com.apple.arkit.matting.useTemporalSmoothing
com.apple.arkit.matting.doubleMLResolutionForIPad
com.apple.arkit.matting.useTemporalHandsSegmentation
com.apple.arkit.bodytracking.multipleBodyAnchors
com.apple.arkit.bodytracking.extrapolationTimeLimitSeconds
com.apple.arkit.bodytracking.pushProjected3DSkeleton
com.apple.arkit.bodyTracking.useSupport3DSkeleton
com.apple.arkit.view.rendersCameraGrain
com.apple.arkit.view.rendersMotionBlur
com.apple.arkit.view.attemptRenderSynchronizationARFrame
com.apple.arkit.view.renderRawSceneUnderstandingImage
com.apple.arkit.multicam_mode.enabled
com.apple.arkit.sceneReconstruction.voxelSize
com.apple.arkit.sceneReconstruction.waitTillVIOIsStable
com.apple.arkit.sceneReconstruction.enableLowQosScheduling
com.apple.arkit.sceneReconstruction.enableOccupancyMapping
com.apple.arkit.sceneReconstruction.enableKeyVolPipeline
com.apple.arkit.sceneReconstruction.bucketsCount
com.apple.arkit.sceneReconstruction.enableMeshPlaneHarmony
com.apple.arkit.semanticSegmentation.uncertaintyThreshold
com.apple.arkit.recordingTechnique.recordPearlDepthData
com.apple.arkit.replaySensor.deterministicMode
com.apple.arkit.replaySensor.deterministicMode.useMovieFPS
com_apple_arkit_replay_filepath_advanceToFrame
com_apple_arkit_replay_filepath_advanceFramesPerSecondMultiplier
com_apple_arkit_replay_filepath_nextFrameIndex
com.apple.arkit.replay.display.synchronization.marker
com.apple.arkit.replay.display.synchronization.marker.frameCount
com.apple.arkit.replaySensor.cropFrames
com.apple.arkit.replaySensor.replayVisionData
com.apple.arkit.replaySensor.replayPearlDepthData
com.apple.arkit.test.default
com.apple.arkit.session.configuration.saveDotGraph
com.apple.arkit.appleDepth.useExpFilter
com.apple.arkit.appleDepth.averageDepthBoundingBox
com.apple.arkit.appleDepth.temporalSmoothingMethod
com.apple.arkit.appleDepth.temporalFilteringStoredFrames
com.apple.arkit.appleDepth.computeNormals
com.apple.arkit.appleDepthSPI.bundleID.approvedList
com.apple.arkit.jasper.enabled
com.apple.arkit.jasper.timeOfFlightProjectorMode
com.apple.arkit.jasper.framerate
com.apple.arkit.jasper.replayFramerate
com.apple.arkit.jasper.aggregationBankCount
com.apple.arkit.personOcclusion.optimizationStrategy
com.apple.arkit.forceLinkedOnOrAfterAzul
com.apple.arkit.appClipCodeTracking.performanceTestMode
com.apple.arkit.skipCrashOnARCrash
<%@: %p identifier="%@" transform=%@ referenceObject=%@>
referenceObject
root
head_joint
left_hand_joint
right_hand_joint
left_foot_joint
right_foot_joint
left_shoulder_1_joint
right_shoulder_1_joint
identifier
transform
referenceTransform
lastUpdateTimestamp
isHiddenFromPublicDelegate
name
 sessionIdentifier="%@"
B24@?0@"ARAnchor"8@"NSDictionary"16
geometry
timestamp
extent
maxExtentError
visionTransform
corner
 geometry="%@"
 timestamp=%f
trackingData
anchorIdentifier
vertexData
vertexData2D
normalsData
blendShapeCoefficientsData
leftEyeTransform
rightEyeTransform
gaze
tongueOut
trackedFaces
None
Manual
Automatic
Unknown
Horizontal
Vertical
Gravity
GravityAndHeading
Camera
Person Segmentation with Depth
Person Segmentation
Body Detection
Scene Depth
Smoothed Scene Depth
ColorImage
Accelerometer
Gyroscope
DeviceOrientation
FaceMetaData
Depth
Location
Magnetometer
ARTimeOfFlightProjectorModeNone
ARTimeOfFlightProjectorModeNormal
ARTimeOfFlightProjectorModeShortRange
ARTimeOfFlightProjectorModeNormalShortHybrid
ARTimeOfFlightProjectorModeHighQualityMacro
Coarse
Precise
User Defined
 coordinate=(%f,%f,%f) altitudeSource=%@ isAltitudeAvailable=%d undulation=%f>
latitude
longitude
altitude
altitudeSource
isAltitudeAvailable
undulation
Unable to create archive.
Unable to read archive from memory.
NULL
Underlying NSData was nil
com.apple.arkit.error
ARErrorItems
ARServiceName
Unsupported configuration.
The provided configuration is not supported on this device.
Required sensor unavailable.
A required sensor is not available on this device.
Required sensor failed.
A sensor failed to deliver the required input.
Make sure that the application has the required privacy settings.
Camera access not authorized.
The app does not have permission to use the camera.
Make sure that the application has the required camera privacy settings.
Microphone access not authorized.
The app does not have permission to use the microphone.
Make sure that the application has the required microphone privacy settings.
Unsupported capture session configuration.
Input device and/or format of the provided capture session are not supported for the given configuration.
Make sure that the correct device and format are being used for capture.
World tracking failed.
Geo tracking is not available at this location.
Geo tracking failed because of a runtime error.
Location access not authorized.
The app does not have permission to use the location of the device.
Location access and precise accuracy must be enabled in the app's privacy settings.
Invalid reference image.
Invalid reference object.
The reference object data is not in a format supported by this version of ARReferenceObject.
Invalid world map.
The world map data is not in a format supported by this version of ARWorldMap.
Invalid configuration.
Invalid collaboration data.
The encoded data is not in a format supported by this version of ARCollaborationData.
Unsupported sensor data.
Insufficient features.
Object merge failed.
Not enough matching features were found for the reference objects to be merged.
File IO failed.
Unable to read from or write to URL: %@.
Request failed.
Unauthorized to write to the photo library.
A permission is missing to access the photo library.
Failed saving the recording.
Failed saving the recording for an unknown reason.
Failed to load espresso model.
File path '%@' is invalid or does not exist
File path is invalid or does not exist
Tracking is currently limited.
Lack of visible features.
Excessive motion of the device.
Low lighting conditions.
Another high-resolution frame is currently being captured.
Please wait for the completion handler call.
Capturing a high resolution frame failed.
angle
patchesVector
Seat
Wall
Floor
Table
Ceiling
Window
Door
Unavailable
Undetermined
Known
There is no plane geometry mesh to save.
# ARKit plane geometry mesh exported from ARExamples %@, ARKit %@, AppleCV3D %@
o plane_anchor_%@
v %.03f %.03f %.03f %.03f %.03f %.03f %.03f
f %d %d %d
rotationOnYAxis
alignment
center
planeExtent
worldAlignmentRotation
classificationStatus
classification
uncertaintyAlongNormal
classificationLabel
gridExtent
<%@: %p identifier="%@" name="%@" transform=%@ texture=%p extent=%@>
<%@: %p identifier="%@" transform=%@ texture=%p extent=%@>
trackedPlaneIdentifier
ARQLCanonicalWebPageURL
allowObjectScaling
ARQLWantsStatusPillHiddenKey
ARQLForceIgnoreMuteSwitchKey
Not Available
Initializing
Localizing
Localized
Medium
High
Not Available At Location
Need Location Permissions
World Tracking Unstable
Waiting For Location
Waiting for Availability Check
Geo Data Not Loaded
Device Pointed Too Low
Visual Localization Failed
VL Unsupported
VL Map Data Not Loaded
VL Map Data Pending
VL Pose Estimation Failed
VL Rejected Pose
VL Bad Input
Invalid VIO Pose
Phone Angle
VL Bad Image
VL Unavailable At Location
VL Unrecognized Error
Waiting For Availability Check
ARGeoTrackingStatus_state
ARGeoTrackingStatus_accuracy
ARGeoTrackingStatus_stateReason
ARGeoTrackingStatus_failureReasons
skeletonData
arobject
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
v32@?0@"NSString"8@"NSNumber"16^B24
blendShapeCoefficientsDictionary
trackingError
Error reading matrix from dictionary
Error: Error reading matrix from dictionary
Couldn't find bundle for name %@
Error: Couldn't find bundle for name %@
Using front camera offset values (%f, %f, %f).
No front camera offset value found for device: %@
No front camera rotation value found in MobileGetStalt for device: %@
Using rear camera offset values (%f, %f, %f).
No rear camera offset value found for device: %@
Error: No rear camera offset value found for device: %@
Creating the OBJ failed.
Error: Creating the OBJ failed.
Writing a string to the output stream failed with error: %@
Error: Writing a string to the output stream failed with error: %@
Writing an OBJ file for %lu mesh anchors to a stream.
Vertex count %ld does not match normal count %ld.
Error: Vertex count %ld does not match normal count %ld.
Face index %d is out of range [0, %ld].
Error: Face index %d is out of range [0, %ld].
No mesh to save.
Error: No mesh to save.
Failed to get kern.boottime MIB with error: %{private}s
Error: Failed to get kern.boottime MIB with error: %{private}s
Failed to lookup kern.boottime with error: %{private}s
Error: Failed to lookup kern.boottime with error: %{private}s
%{public}@ <%p>: Received location
%@ <%p>: Location request handler failed: %@
%@ <%p> Error: Location request handler failed: %@
%{public}@ <%p>: User has set location authorization status: %d
%{public}@ <%p>: Waiting for location authorization from user
%{public}@ <%p>: Waiting for location for availability check
%{public}@ <%p>: Unable to create archive at path: %{public}@.
%{public}@ <%p>: Unable to write to archive at path: %{public}@.
%{public}@ <%p>: Unable to create archive.
%{public}@ <%p>: Unable to write archive to memory
%{public}@ <%p>: Cannot read archive from memory
%{public}@ <%p>: Cannot read archive from nil URL
%{public}@ <%p>: Unable to read archive at path: %{public}@.
%@ <%p>: Unable to construct path
%@ <%p> Error: Unable to construct path
%@ <%p>: Could not read data to buffer.
%@ <%p> Error: Could not read data to buffer.
ARImageAnchor
ARTrackable
NSObject
ARWorldMap
NSCopying
NSSecureCoding
NSCoding
ARAppClipCodeAnchor
ARSession
ARPositionalTrackingConfiguration
ARFaceTrackingConfiguration
ARPointCloud
ARObjectScanningConfiguration
ARDepthData
ARResultData
ARData
ARTrackedRaycast
ARIOMotionSensor
ARSensor
ARAppleGlobalDomain
ARKitUserDefaults
ARObjectAnchor
ARSkeletonDefinition
ARImageTrackingConfiguration
ARAnchor
ARDaemonSecureCoding
ARAnchorCopying
ARAccelerometerData
ARDictionaryCoding
ARMetadataWrapperCoding
ARMutableSensorData
ARSensorData
ARMeshAnchor
ARGeoTrackingLocationRequestHandler
CLLocationManagerDelegate
ARFaceGeometry
ARSCNFaceGeometry
ARFaceTrackingData
ARFaceTrackingDataProtocol
ARFaceTrackingResults
ARMotionSensor
ARSKView
ARSessionProviding
ARConfiguration
ARRaycastResult
ARPlaneGeometry
ARSCNPlaneGeometry
ARBody2D
ARGeoAnchor
ARArchive
ARRaycastQuery
ARCamera
AROrientationTrackingConfiguration
ARLightEstimate
ARDirectionalLightEstimate
ARReferenceImage
ARCoachingOverlayView
ARPatchGrid
ARGeoTrackingConfiguration
ARSkeleton
ARSkeleton3D
ARSkeleton2D
ARPlaneExtent
ARPlaneAnchor
AREnvironmentProbeAnchor
ARMatteGenerator
ARCollaborationData
ARQuickLookPreviewItem
QLPreviewItem
ARGeoTrackingStatus
ARBodyTrackingConfiguration
ARGeometrySource
ARGeometryElement
ARMeshGeometry
ARBodyAnchor
ARSCNView
ARSCNVisualizationHelper
ARReferenceObject
ARFrame
ARParticipantAnchor
ARHitTestResult
ARFaceAnchor
ARWorldTrackingConfiguration
ARVideoFormat
decodeIntegerForKey:
dictionaryRepresentation
componentsSeparatedByString:
ar_encodeMatrix4x4:forKey:
blueColor
absoluteString
encodeObject:forKey:
numberWithDouble:
isEqualToString:
stringWithFormat:
filteredArrayUsingPredicate:
greenColor
initToMemory
path
hasPrefix:
startUpdatingLocation
decodeObjectForKey:
dictionaryWithCapacity:
setLocksAmbientWithDiffuse:
ar_encodeVector3:forKey:
numberWithFloat:
_bundleWithIdentifier:andLibraryName:
decodeObjectOfClass:forKey:
firstObject
length
stringWithString:
ar_map:
containsObject:
setMaterials:
enumerateKeysAndObjectsUsingBlock:
dictionaryWithObjects:forKeys:count:
dataUsingEncoding:
environment
addCharactersInString:
floatValue
stringWithUTF8String:
position
decodeObjectOfClasses:forKey:
liftedSkeletonData
integerValue
boxWithWidth:height:length:chamferRadius:
ambient
UUID
regularExpressionWithPattern:options:error:
setMaximumPointScreenSpaceRadius:
numberWithInt:
array
videoFieldOfView
initWithCapacity:
isMultiCamSupported
containsValueForKey:
objectAtIndex:
stopUpdatingLocation
broadcast
formatDescription
subarrayWithRange:
UUIDString
defaultManager
predicateWithBlock:
setContents:
diffuse
arrayWithObjects:count:
addChildNode:
localizedStringForKey:value:table:
discoverySessionWithDeviceTypes:mediaType:position:
node
setWithArray:
appendBytes:length:
dataWithBytes:length:
contents
decimalDigitCharacterSet
objectAtIndexedSubscript:
removeAllObjects
errorWithDomain:code:userInfo:
invertedSet
setMinimumPointScreenSpaceRadius:
setNumberStyle:
lock
streamError
substringWithRange:
processInfo
setDecimalSeparator:
nodeWithGeometry:
appendFormat:
authorizationStatus
doubleValue
close
decodeBoolForKey:
setWithObjects:
string
isSubclassOfClass:
wait
appendString:
supportedMultiCamDeviceSets
processName
addEntriesFromDictionary:
lowercaseString
bundleIdentifier
copy
encodeBool:forKey:
initWithCoreRESkeletonResult:
infoDictionary
code
setFirstMaterial:
null
addObject:
bundleWithIdentifier:
initWithData:encoding:
stringByAppendingPathComponent:
setObject:forKeyedSubscript:
initWithImageResolution:captureDevicePosition:captureDeviceType:
propertyForKey:
mainBundle
blackColor
decodeBytesForKey:returnedLength:
unlock
objectForKeyedSubscript:
decodeDoubleForKey:
geometryElementWithData:primitiveType:primitiveCount:bytesPerIndex:
write:maxLength:
encodeBytes:length:forKey:
bundleWithPath:
matchesInString:options:range:
allKeys
encodeDouble:forKey:
rotationMatrix
stringByAppendingPathExtension:
colorWithRed:green:blue:alpha:
setPointSize:
initWithDetectedSkeleton:
numberFromString:
decodeFloatForKey:
allObjects
bytes
geometrySourceWithData:semantic:vectorCount:floatComponents:componentsPerVector:bytesPerComponent:dataOffset:dataStride:
stringByAppendingString:
rangeAtIndex:
deviceType
ar_decodeMatrix4x4ForKey:
componentsJoinedByString:
initWithSkeleton2D:
material
encodeFloat:forKey:
numberOfRanges
setPosition:
countByEnumeratingWithState:objects:count:
geometryWithSources:elements:
UTF8String
open
lastObject
allValues
stringByReplacingCharactersInRange:withString:
componentsSeparatedByCharactersInSet:
ar_decodeVector3ForKey:
skeletonDetectionResult2D
fileSystemRepresentation
getBytes:length:
decodeIntForKey:
initWithSuiteName:
numberWithBool:
encodeInteger:forKey:
setLightingModelName:
dictionary
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithFaceTrackingDataProtocol:
allocWithZone:
redColor
isEqualToDictionary:
methodForSelector:
initWithIdentifier:transform:
initWithAnchor:
encodeWithCoder:
initWithCoder:
supportsSecureCoding
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
isTracked
TB,R,N
initWithReferenceImage:transform:detectionOnly:tracked:
name
copyWithTrackedState:
setEstimatedScaleFactor:
referenceImage
estimatedScaleFactor
isDetectionOnly
setDetectionOnly:
setIsTracked:
.cxx_destruct
_referenceImageUUID
_detectionOnly
_isTracked
_referenceImage
_estimatedScaleFactor
detectionOnly
TB,N,GisDetectionOnly,V_detectionOnly
TB,N,V_isTracked
T@"ARReferenceImage",R,N,V_referenceImage
Td,R,N,V_estimatedScaleFactor
copyWithZone:
TB,R
center
extent
anchors
setAnchors:
rawFeaturePoints
_anchors
_rawFeaturePoints
_center
_extent
T,R,N,V_center
T,R,N,V_extent
T@"NSArray",C,N,V_anchors
T@"ARPointCloud",R,N,V_rawFeaturePoints
initWithTransform:
initWithAppClipCodeResult:instanceID:
urlDecodingState
copyWithAppClipCodeResult:isTracked:
setUrl:
radius
setRadius:
instanceID
setInstanceID:
confidence
setConfidence:
urlDecodingStateInternal
setUrlDecodingStateInternal:
isScaleReliable
setIsScaleReliable:
urlEncodingVersion
setUrlEncodingVersion:
_isScaleReliable
_radius
_confidence
_url
_instanceID
_urlDecodingStateInternal
_urlEncodingVersion
T@"NSURL",C,N,V_url
T@"NSNumber",&,N,V_instanceID
Tf,N,V_confidence
Tf,N,V_radius
Tq,N,V_urlDecodingStateInternal
TB,N,V_isScaleReliable
TQ,N,V_urlEncodingVersion
Tq,R,N
init
session:didFailWithError:
runWithConfiguration:
runWithConfiguration:options:
pause
addAnchor:
removeAnchor:
setWorldOrigin:
getCurrentWorldMapWithCompletionHandler:
createReferenceObjectWithTransform:center:extent:completionHandler:
raycast:
trackedRaycast:updateHandler:
updateWithCollaborationData:
getGeoLocationForPoint:completionHandler:
captureHighResolutionFrameWithCompletion:
identifier
delegate
setDelegate:
delegateQueue
setDelegateQueue:
currentFrame
configuration
_identifier
_delegate
_delegateQueue
_currentFrame
_configuration
T@"NSUUID",R,V_identifier
T@"<ARSessionDelegate>",W,N,V_delegate
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateQueue
T@"ARFrame",R,C,N,V_currentFrame
T@"ARConfiguration",R,C,N,V_configuration
initPrivate
planeDetection
setPlaneDetection:
initialWorldMap
setInitialWorldMap:
_planeDetection
_initialWorldMap
TQ,N,V_planeDetection
T@"ARWorldMap",&,N,V_initialWorldMap
supportedNumberOfTrackedFaces
supportsWorldTracking
maximumNumberOfTrackedFaces
setMaximumNumberOfTrackedFaces:
isWorldTrackingEnabled
setWorldTrackingEnabled:
_worldTrackingEnabled
_maximumNumberOfTrackedFaces
Tq,N,V_maximumNumberOfTrackedFaces
worldTrackingEnabled
TB,N,GisWorldTrackingEnabled,V_worldTrackingEnabled
count
points
identifiers
.cxx_construct
_pointsVector
_identifiersVector
_count
_points
_identifiers
TQ,R,N,V_count
Tr^,R,N,V_points
Tr^Q,R,N,V_identifiers
isAutoFocusEnabled
setAutoFocusEnabled:
_autoFocusEnabled
autoFocusEnabled
TB,N,GisAutoFocusEnabled,V_autoFocusEnabled
timestamp
cameraTransform
worldTrackingState
worldAlignmentTransform
worldAlignmentModifiers
lightEstimate
featurePoints
segmentationBuffer
anchorsForCameraWithTransform:referenceOriginTransform:existingAnchors:anchorsToRemove:
externalAnchorsWithReferenceOriginTransform:existingAnchors:
initWithDepthMap:confidenceMap:
depthMap
setDepthMap:
confidenceMap
setConfidenceMap:
normalsBuffer
setNormalsBuffer:
confidenceBuffer
setConfidenceBuffer:
setTimestamp:
cameraIntrinsics
setCameraIntrinsics:
extrinsicsToAppNode
setExtrinsicsToAppNode:
deviceTransform
setDeviceTransform:
isValid
setIsValid:
_isValid
_depthMap
_confidenceMap
_normalsBuffer
_confidenceBuffer
_timestamp
_cameraIntrinsics
_extrinsicsToAppNode
_deviceTransform
T^{__CVBuffer=},N,V_depthMap
T^{__CVBuffer=},N,V_confidenceMap
T^{__CVBuffer=},N,V_normalsBuffer
T^{__CVBuffer=},N,V_confidenceBuffer
Td,N,V_timestamp
T{?=[3]},N,V_cameraIntrinsics
T{?=[4]},N,V_extrinsicsToAppNode
T{?=[4]},N,V_deviceTransform
TB,N,V_isValid
stopTracking
providedDataTypes
start
stop
forceUpdatePowerUsage:
waitForOutstandingCallbacks
powerUsage
setPowerUsage:
T@"<ARSensorDelegate>",W,N
TQ,N
T@"<ARSensorDelegate>",W,N,V_delegate
appleGlobalDomain
appleGlobalDomainARKitKeys
appleGlobalDomainARKitDefaults
boolValue
stringValue
defaultValues
userDefaultsCache
shouldUseCache
cachedObjectForKey:
removeCachedObjectForKey:
cacheObject:forKey:
clearUserDefaultsCache
keysApprovedForProcessEnvironmentOverride
removeAllKeys
removeObjectForKey:
objectForKeySlow:
objectForKey:
objectForKey:useCache:
valueForKey:
setObject:forKey:
setValue:forKey:
boolForKey:
setBool:forKey:
stringForKey:
numberForKey:
integerForKey:
floatForKey:
doubleForKey:
listForKey:
resolutionDictionaryForKey:
synchronize
initWithReferenceObject:transform:
referenceObject
_referenceObject
T@"ARReferenceObject",R,N,V_referenceObject
defaultBody2DSkeletonDefinition
defaultBody3DSkeletonDefinition
T@"ARSkeletonDefinition",R,N
initDefault2DSkeletonDefinition
initDefault3DSkeletonDefinition
indexForJointName:
jointCount
jointNames
parentIndices
neutralBodySkeleton3D
_jointCount
_jointNames
_parentIndices
_neutralBodySkeleton3D
TQ,R,N,V_jointCount
T@"NSArray",R,N,V_jointNames
T@"NSArray",R,N,V_parentIndices
T@"ARSkeleton3D",R,N,V_neutralBodySkeleton3D
trackingImages
setTrackingImages:
maximumNumberOfTrackedImages
setMaximumNumberOfTrackedImages:
_trackingImages
_maximumNumberOfTrackedImages
T@"NSSet",C,N,V_trackingImages
Tq,N,V_maximumNumberOfTrackedImages
initWithIdentifier:transform:name:
initWithIdentifier:transform:name:hiddenFromPublicDelegate:
initWithName:transform:
_commonInit:transform:name:
isEqualToAnchor:
_description:
debugQuickLookObject
sessionIdentifier
setSessionIdentifier:
transform
setTransform:
referenceTransform
setReferenceTransform:
lastUpdateTimestamp
setLastUpdateTimestamp:
isHiddenFromPublicDelegate
_isHiddenFromPublicDelegate
_name
_sessionIdentifier
_lastUpdateTimestamp
_transform
_referenceTransform
T@"NSUUID",&,N,V_sessionIdentifier
T{?=[4]},N,V_transform
T{?=[4]},N,V_referenceTransform
Td,N,V_lastUpdateTimestamp
TB,R,N,V_isHiddenFromPublicDelegate
T@"NSUUID",R,N,V_identifier
T@"NSString",R,N,V_name
encodeToDictionary
initWithDictionary:
encodeToMetadataWrapper
initWithMetadataWrapper:
Td,N
acceleration
setAcceleration:
temperature
setTemperature:
_temperature
_acceleration
T{?=ddd},N,V_acceleration
Td,N,V_temperature
initWithGeometry:atTimestamp:identifier:referenceOriginTransform:
initWithGeometry:atTimestamp:identifier:visionTransform:referenceOriginTransform:
initWithGeometry:atTimestamp:identifier:
initWithGeometry:atTimestamp:identifier:transform:
initWithGeometry:atTimestamp:identifier:transform:voxelSize:
geometry
corner
maxExtentError
setMaxExtentError:
visionTransform
_geometry
_maxExtentError
_corner
_visionTransform
T,R,N,V_corner
Td,R,N,V_timestamp
Td,N,V_maxExtentError
T{?=[4]},R,N,V_visionTransform
T@"ARMeshGeometry",R,N,V_geometry
locationManager:didUpdateToLocation:fromLocation:
locationManager:didUpdateLocations:
locationManager:didUpdateHeading:
locationManagerShouldDisplayHeadingCalibration:
locationManager:didDetermineState:forRegion:
locationManager:didRangeBeacons:inRegion:
locationManager:rangingBeaconsDidFailForRegion:withError:
locationManager:didRangeBeacons:satisfyingConstraint:
locationManager:didFailRangingBeaconsForConstraint:error:
locationManager:didEnterRegion:
locationManager:didExitRegion:
locationManager:didFailWithError:
locationManager:monitoringDidFailForRegion:withError:
locationManager:didChangeAuthorizationStatus:
locationManagerDidChangeAuthorization:
locationManager:didStartMonitoringForRegion:
locationManagerDidPauseLocationUpdates:
locationManagerDidResumeLocationUpdates:
locationManager:didFinishDeferredUpdatesWithError:
locationManager:didVisit:
setLocationManager:
waitForAuthorizationStatus
requestLocationWithCompletionHandler:
locationCompletionHandler
setLocationCompletionHandler:
_locationManager
_authorizationCondition
_authorizationStatus
_locationCompletionHandler
T@?,C,N,V_locationCompletionHandler
initWithBlendShapes:
vertexCount
vertices
textureCoordinateCount
textureCoordinates
triangleCount
triangleIndices
_vertexCount
_vertices
_textureCoordinateCount
_textureCoordinates
_triangleCount
_triangleIndices
TQ,R,N,V_vertexCount
Tr^,R,N,V_vertices
TQ,R,N,V_textureCoordinateCount
Tr^,R,N,V_textureCoordinates
TQ,R,N,V_triangleCount
Tr^s,R,N,V_triangleIndices
faceGeometryWithDevice:
faceGeometryWithDevice:fillMesh:
updateFromFaceGeometry:
sharedNeutralGeometry
leftEyeTransform
rightEyeTransform
gazePoint
imageVertices
normalCount
normals
blendShapeCoefficientsCount
blendShapeCoefficients
trackingData
T@"NSUUID",R,N
T{?=[4]},R,N
T,R,N
TQ,R,N
Tr^,R,N
Tr^f,R,N
T@"NSDictionary",R,N
initWithTrackingData:anchorIdentifier:
initWithTrackingData:transformToMirrored:anchorIdentifier:
_extractMetaDataAndTransformToMirrored:
trackingError
tongueOut
setLeftEyeTransform:
setRightEyeTransform:
setGazePoint:
setTrackingData:
_meshVertices
_verticesImageSpace
_normals
_blendShapeCoefficients
_normalsSemaphore
_imageVerticesSemaphore
_anchorIdentifier
_tongueOut
_trackingError
_trackingData
_gazePoint
_leftEyeTransform
_rightEyeTransform
T{?=[4]},N,V_leftEyeTransform
T{?=[4]},N,V_rightEyeTransform
T,N,V_gazePoint
T@"NSDictionary",&,N,V_trackingData
T@"NSError",R,N,V_trackingError
Tf,R,N,V_tongueOut
trackedFaces
setTrackedFaces:
_trackedFaces
T@"NSArray",C,N,V_trackedFaces
initWithMotionManager:
initWithFrame:
session
T@"ARSession",R
hitTest:types:
anchorForNode:
nodeForAnchor:
setSession:
_session
T@"NSObject<ARSKViewDelegate>",W,D,N
T@"ARSession",&,N,V_session
isSupported
supportedVideoFormats
supportsFrameSemantics:
recommendedVideoFormatFor4KResolution
recommendedVideoFormatForHighResolutionFrameCapturing
configurableCaptureDeviceForPrimaryCamera
supportsTimeOfFlightProjectorMode
shouldUse30FPSJasperFormats
setShouldUse30FPSJasperFormats:
setShouldProvideX420VideoFormat:
shouldProvideX420VideoFormat
setShouldProvideNonBinnedVideoFormats:
shouldProvideNonBinnedVideoFormats
TB,N
T@"NSArray",R,N
T@"AVCaptureDevice",R,N
T@"ARVideoFormat",R,N
descriptionWithoutBrackets
techniques
isKindOfConfiguration:
getAsKindOfConfiguration:
videoFormat
setVideoFormat:
worldAlignment
setWorldAlignment:
isLightEstimationEnabled
setLightEstimationEnabled:
providesAudioData
setProvidesAudioData:
frameSemantics
setFrameSemantics:
videoHDRAllowed
setVideoHDRAllowed:
deviceModel
parentImageSensorSettings
imageSensorSettings
customSensors
setCustomSensors:
lightEstimation
setLightEstimation:
frameDebugOptions
setFrameDebugOptions:
isPersonMetadataEnabled
setPersonMetadataEnabled:
jasperFrameRate
setJasperFrameRate:
cameraPosition
setCameraPosition:
allowCameraInMultipleForegroundAppLayout
setAllowCameraInMultipleForegroundAppLayout:
disableOcclusionForPersonSegmentation
setDisableOcclusionForPersonSegmentation:
disableMLRelocalization
setDisableMLRelocalization:
mirroredFrameOutput
setMirroredFrameOutput:
replaySensor
timeOfFlightProjectorMode
setTimeOfFlightProjectorMode:
maxUltrawideImageForwardingFrameRate
setMaxUltrawideImageForwardingFrameRate:
_cameraPosition
_videoFormat
_lightEstimationEnabled
_providesAudioData
_videoHDRAllowed
_personMetadataEnabled
_allowCameraInMultipleForegroundAppLayout
_disableOcclusionForPersonSegmentation
_disableMLRelocalization
_mirroredFrameOutput
_worldAlignment
_frameSemantics
_deviceModel
_parentImageSensorSettings
_imageSensorSettings
_customSensors
_lightEstimation
_frameDebugOptions
_jasperFrameRate
_replaySensor
_timeOfFlightProjectorMode
_maxUltrawideImageForwardingFrameRate
T@"NSString",R,N,V_deviceModel
T@"ARParentImageSensorSettings",R,N,V_parentImageSensorSettings
T@"ARImageSensorSettings",R,N,V_imageSensorSettings
T@"NSArray",&,N,V_customSensors
TQ,N,V_lightEstimation
TQ,N,V_frameDebugOptions
personMetadataEnabled
TB,N,GisPersonMetadataEnabled,V_personMetadataEnabled
Tq,N,V_jasperFrameRate
Tq,N,V_cameraPosition
TB,N,V_allowCameraInMultipleForegroundAppLayout
TB,N,V_disableOcclusionForPersonSegmentation
TB,N,V_disableMLRelocalization
TB,N,V_mirroredFrameOutput
T@"<ARReplaySensorProtocol>",R,N,V_replaySensor
T@"NSString",&,N,V_timeOfFlightProjectorMode
Tq,N,V_maxUltrawideImageForwardingFrameRate
T@"ARVideoFormat",&,N,V_videoFormat
Tq,N,V_worldAlignment
lightEstimationEnabled
TB,N,GisLightEstimationEnabled,V_lightEstimationEnabled
TB,N,V_providesAudioData
TQ,N,V_frameSemantics
TB,N,V_videoHDRAllowed
worldTransform
target
targetAlignment
anchor
_target
_targetAlignment
_anchor
_worldTransform
T{?=[4]},R,N,V_worldTransform
Tq,R,N,V_target
Tq,R,N,V_targetAlignment
T@"ARAnchor",R,N,V_anchor
boundaryVertexCount
boundaryVertices
_boundaryVertexCount
_boundaryVertices
TQ,R,N,V_boundaryVertexCount
Tr^,R,N,V_boundaryVertices
planeGeometryWithDevice:
updateFromPlaneGeometry:
skeleton
_skeleton
T@"ARSkeleton2D",R,N,V_skeleton
initWithCoordinate:
initWithCoordinate:altitude:
initWithName:coordinate:
initWithName:coordinate:altitude:
initWithCoordinate:altitude:altitudeSource:isAltitudeAvailable:undulation:
altitude
coordinate
altitudeSource
isAltitudeAvailable
isAltitudeLookupInProgress
setIsAltitudeLookupInProgress:
undulation
locationLLA
locationECEF
ecefFromAnchor
_isAltitudeAvailable
_isAltitudeLookupInProgress
_altitudeSource
_undulation
_coordinate
_locationLLA
_locationECEF
_ecefFromAnchor
TB,R,N,V_isAltitudeAvailable
TB,N,V_isAltitudeLookupInProgress
Td,R,N,V_undulation
T,R,N,V_locationLLA
T,R,N,V_locationECEF
T{?=[4]},R,N,V_ecefFromAnchor
T{CLLocationCoordinate2D=dd},R,N,V_coordinate
Td,R,N
Tq,R,N,V_altitudeSource
initWithContentsOfURL:error:
initWithData:error:
filePaths
addData:withFilename:extension:
addData:withPath:
dataForResource:withExtension:
dataForResourceAtPath:
writeToURL:error:
dataRepresentation
_loadArchiveFromMemory:error:
_loadArchiveFromURL:error:
_writeToArchive:
_createArchiveForReading
_readDataFromArchive:
_readDataForEntry:archive:
_dataByPath
T@"NSArray",R,C,N
initWithOrigin:direction:allowingTarget:alignment:
origin
direction
_origin
_direction
T,R,N,V_origin
T,R,N,V_direction
projectionMatrixForOrientation:viewportSize:zNear:zFar:
projectPoint:orientation:viewportSize:
unprojectPoint:ontoPlaneWithTransform:orientation:viewportSize:
viewMatrixForOrientation:
eulerAngles
trackingState
trackingStateReason
intrinsics
imageResolution
exposureDuration
exposureOffset
projectionMatrix
_exposureOffset
_trackingState
_trackingStateReason
_exposureDuration
_eulerAngles
_imageResolution
_intrinsics
_projectionMatrix
T{?=[4]},R,N,V_transform
T,R,N,V_eulerAngles
Tq,R,N,V_trackingState
Tq,R,N,V_trackingStateReason
T{?=[3]},R,N,V_intrinsics
T{CGSize=dd},R,N,V_imageResolution
Td,R,N,V_exposureDuration
Tf,R,N,V_exposureOffset
T{?=[4]},R,N,V_projectionMatrix
ambientIntensity
ambientColorTemperature
_ambientIntensity
_ambientColorTemperature
Td,R,N,V_ambientIntensity
Td,R,N,V_ambientColorTemperature
sphericalHarmonicsCoefficients
primaryLightDirection
primaryLightIntensity
_sphericalHarmonicsCoefficients
_primaryLightIntensity
_primaryLightDirection
T@"NSData",R,C,N,V_sphericalHarmonicsCoefficients
T,R,N,V_primaryLightDirection
Td,R,N,V_primaryLightIntensity
referenceImagesInGroupNamed:bundle:
validateWithCompletionHandler:
initWithCGImage:orientation:physicalWidth:
initWithPixelBuffer:orientation:physicalWidth:
setName:
physicalSize
resourceGroupName
_resourceGroupName
_physicalSize
T@"NSString",C,N,V_name
T{CGSize=dd},R,N,V_physicalSize
T@"NSString",R,N,V_resourceGroupName
setSessionProvider:
setGoal:
isActive
setActive:animated:
intrinsicContentSize
sessionProvider
goal
activatesAutomatically
setActivatesAutomatically:
_activatesAutomatically
_sessionProvider
_goal
T@"<ARCoachingOverlayViewDelegate>",W,N,V_delegate
T@"NSObject<ARSessionProviding>",W,N,V_sessionProvider
Tq,N,V_goal
TB,N,V_activatesAutomatically
initWithPatchesVector:pivotAngle:
size
patches
pivot
_patchesVector
_angle
Tr^{?=},R,N
Tf,R,N
checkAvailabilityWithCompletionHandler:
checkAvailabilityAtCoordinate:completionHandler:
supportsAppClipCodeTracking
setDetectionImages:
environmentTexturing
setEnvironmentTexturing:
wantsHDREnvironmentTextures
setWantsHDREnvironmentTextures:
detectionImages
automaticImageScaleEstimationEnabled
setAutomaticImageScaleEstimationEnabled:
detectionObjects
setDetectionObjects:
appClipCodeTrackingEnabled
setAppClipCodeTrackingEnabled:
_wantsHDREnvironmentTextures
_automaticImageScaleEstimationEnabled
_appClipCodeTrackingEnabled
_environmentTexturing
_detectionImages
_detectionObjects
Tq,D,N
Tq,N,V_environmentTexturing
TB,N,V_wantsHDREnvironmentTextures
T@"NSSet",C,N,V_detectionImages
TB,N,V_automaticImageScaleEstimationEnabled
T@"NSSet",C,N,V_detectionObjects
TB,N,V_appClipCodeTrackingEnabled
isJointTracked:
definition
_definition
T@"ARSkeletonDefinition",R,N,V_definition
modelTransformForJointName:
localTransformForJointName:
jointModelTransforms
jointLocalTransforms
_jointModelTransforms
_jointLocalTransforms
Tr^{?=[4]},R,N,V_jointModelTransforms
Tr^{?=[4]},R,N,V_jointLocalTransforms
landmarkForJointNamed:
jointLandmarks
_jointLandmarks
Tr^,R,N,V_jointLandmarks
rotationOnYAxis
setRotationOnYAxis:
width
setWidth:
height
setHeight:
_rotationOnYAxis
_width
_height
Tf,N,V_rotationOnYAxis
Tf,N,V_width
Tf,N,V_height
isClassificationSupported
classificationSupported
TB,R,N,GisClassificationSupported
alignment
setCenter:
setExtent:
planeExtent
setPlaneExtent:
setGeometry:
classificationStatus
setClassificationStatus:
classification
setClassification:
gridExtent
setGridExtent:
uncertaintyAlongNormal
setUncertaintyAlongNormal:
worldAlignmentRotation
setWorldAlignmentRotation:
possibleClassifications
setPossibleClassifications:
classificationLabel
setClassificationLabel:
_uncertaintyAlongNormal
_alignment
_planeExtent
_classificationStatus
_classification
_gridExtent
_worldAlignmentRotation
_possibleClassifications
_classificationLabel
T,N,V_center
T,N,V_extent
T@"ARPlaneExtent",&,N,V_planeExtent
T@"ARPlaneGeometry",&,V_geometry
T@"ARPatchGrid",&,N,V_gridExtent
Tf,N,V_uncertaintyAlongNormal
Tq,N,V_worldAlignmentRotation
Tq,N,V_classificationStatus
Tq,N,V_classification
T@"NSDictionary",C,N,V_possibleClassifications
T@"NSString",&,N,V_classificationLabel
Tq,R,N,V_alignment
initWithTransform:extent:
initWithName:transform:extent:
initWithIdentifier:transform:extent:
initWithIdentifier:onPlane:
environmentTexture
setEnvironmentTexture:
clippingPointLux
setClippingPointLux:
parametricLights
setParametricLights:
sourceKeyframeUUIDs
setSourceKeyframeUUIDs:
colorHistogram
setColorHistogram:
opaquePixelPercentage
setOpaquePixelPercentage:
trackedPlaneIdentifier
setTrackedPlaneIdentifier:
_clippingPointLux
_opaquePixelPercentage
_environmentTexture
_parametricLights
_sourceKeyframeUUIDs
_colorHistogram
_trackedPlaneIdentifier
T@"<MTLTexture>",&,N,V_environmentTexture
Tf,N,V_clippingPointLux
T@"ARParametricLights",&,N,V_parametricLights
T@"NSSet",&,N,V_sourceKeyframeUUIDs
T@"NSData",&,N,V_colorHistogram
Tf,N,V_opaquePixelPercentage
T@"NSUUID",&,N,V_trackedPlaneIdentifier
initWithDevice:matteResolution:
generateMatteFromFrame:commandBuffer:
generateDilatedDepthFromFrame:commandBuffer:
priority
_priority
Tq,R,N,V_priority
previewItemURL
previewItemTitle
T@"NSURL",R,N
T@"NSString",R,N
initWithFileAtURL:
canonicalWebPageURL
setCanonicalWebPageURL:
allowsContentScaling
setAllowsContentScaling:
fileURL
setFileURL:
_allowsContentScaling
_canonicalWebPageURL
_fileURL
T@"NSURL",&,N,V_fileURL
T@"NSURL",&,N,V_canonicalWebPageURL
TB,N,V_allowsContentScaling
initialStatus
initWithGeoTrackingState:accuracy:stateReason:failureReasons:
isEqualPrivate:
state
setState:
accuracy
stateReason
setStateReason:
failureReasons
_state
_accuracy
_stateReason
_failureReasons
Tq,R,N,V_failureReasons
Tq,N,V_state
Tq,N,V_stateReason
Tq,R,N,V_accuracy
automaticSkeletonScaleEstimationEnabled
setAutomaticSkeletonScaleEstimationEnabled:
_automaticSkeletonScaleEstimationEnabled
TB,N,V_automaticSkeletonScaleEstimationEnabled
buffer
format
componentsPerVector
offset
stride
_buffer
_format
_componentsPerVector
_offset
_stride
T@"<MTLBuffer>",R,N,V_buffer
Tq,R,N,V_count
TQ,R,N,V_format
Tq,R,N,V_componentsPerVector
Tq,R,N,V_offset
Tq,R,N,V_stride
bytesPerIndex
indexCountPerPrimitive
primitiveType
_bytesPerIndex
_indexCountPerPrimitive
_primitiveType
Tq,R,N,V_bytesPerIndex
Tq,R,N,V_indexCountPerPrimitive
Tq,R,N,V_primitiveType
faces
_faces
T@"ARGeometrySource",R,N,V_vertices
T@"ARGeometrySource",R,N,V_normals
T@"ARGeometryElement",R,N,V_faces
T@"ARGeometrySource",R,N,V_classification
initWithIdentifier:transform:tracked:skeletonData:
referenceBody
isEqualToARBodyAnchor:
_tracked
_skeletonData
_referenceBody
T@"ARBody2D",R,N
T@"ARSkeleton3D",R,N,V_skeleton
initWithFrame:options:
unprojectPoint:ontoPlaneWithTransform:
raycastQueryFromPoint:allowingTarget:alignment:
automaticallyUpdatesLighting
setAutomaticallyUpdatesLighting:
rendersCameraGrain
setRendersCameraGrain:
rendersMotionBlur
setRendersMotionBlur:
_automaticallyUpdatesLighting
_rendersCameraGrain
_rendersMotionBlur
T@"<ARSCNViewDelegate>",W,D,N
scene
T@"SCNScene",&,D,N
TB,N,V_automaticallyUpdatesLighting
TB,N,V_rendersCameraGrain
TB,N,V_rendersMotionBlur
createMaterialWithTexture:
createAxesNode:
createGeometryForPointCloud:
referenceObjectsInGroupNamed:bundle:
referenceObjectsInGroupNamed:catalogURL:
referenceObjectsInGroupNamed:catalogName:bundle:
writeToArchiveWithPreviewImage:error:
initWithArchiveURL:error:
initWithArchiveData:error:
initWithArchiveData:name:error:
initWithTrackingData:referenceOriginTransform:
exportObjectToURL:previewImage:error:
exportObjectToMemoryWithPreviewImage:error:
referenceObjectByApplyingTransform:
referenceObjectByMergingObject:error:
scale
version
referenceOriginTransform
keyframes
_version
_keyframes
_scale
_referenceOriginTransform
Tq,R,N,V_version
T@"NSData",R,N,V_trackingData
T{?=[4]},R,N,V_referenceOriginTransform
T@"NSSet",R,N,V_keyframes
T,R,N,V_scale
displayTransformForOrientation:viewportSize:
detectedBody
capturedImage
exifData
cameraGrainTexture
cameraGrainIntensity
capturedDepthData
capturedDepthDataTimestamp
camera
worldMappingStatus
estimatedDepthData
geoTrackingStatus
sceneDepth
smoothedSceneDepth
_cameraGrainIntensity
_capturedImage
_exifData
_cameraGrainTexture
_capturedDepthData
_capturedDepthDataTimestamp
_camera
_lightEstimate
_worldMappingStatus
_segmentationBuffer
_estimatedDepthData
_geoTrackingStatus
_sceneDepth
_smoothedSceneDepth
T^{__CVBuffer=},R,N,V_capturedImage
T@"NSDictionary",R,N,V_exifData
T@"<MTLTexture>",R,N,V_cameraGrainTexture
Tf,R,N,V_cameraGrainIntensity
T@"AVDepthData",R,N,V_capturedDepthData
Td,R,N,V_capturedDepthDataTimestamp
T@"ARCamera",R,C,N,V_camera
T@"NSArray",R,C,N,V_anchors
T@"ARLightEstimate",R,N,V_lightEstimate
T@"ARPointCloud",R,N
Tq,R,N,V_worldMappingStatus
T^{__CVBuffer=},R,N,V_segmentationBuffer
T^{__CVBuffer=},R,N,V_estimatedDepthData
T@"ARGeoTrackingStatus",R,N,V_geoTrackingStatus
T@"ARDepthData",R,N,V_sceneDepth
T@"ARDepthData",R,N,V_smoothedSceneDepth
initWithType:
type
distance
localTransform
_type
_distance
_localTransform
TQ,R,N,V_type
Td,R,N,V_distance
T{?=[4]},R,N,V_localTransform
blendShapeMapping
mirroredBlendShapeMapping
blendShapeToMirroredBlendShapeMapping
initWithIdentifier:trackingData:
initWithIdentifier:faceTrackingData:
initWithExistingFaceAnchor:tracked:trackingError:
faceTrackingData
blendShapes
lookAtPoint
isEqualToFaceAnchor:
setTrackingError:
_blendShapeCoefficientsDictionary
T@"<ARFaceTrackingDataProtocol>",&,N,V_trackingData
T@"NSError",&,N,V_trackingError
T@"ARFaceGeometry",R,N,V_geometry
supportsUserFaceTracking
supportsSceneReconstruction:
isCollaborationEnabled
setCollaborationEnabled:
userFaceTrackingEnabled
setUserFaceTrackingEnabled:
sceneReconstruction
setSceneReconstruction:
_collaborationEnabled
_userFaceTrackingEnabled
_sceneReconstruction
collaborationEnabled
TB,N,GisCollaborationEnabled,V_collaborationEnabled
TB,N,GuserFaceTrackingEnabled,V_userFaceTrackingEnabled
TQ,N,V_sceneReconstruction
captureDevicePosition
captureDeviceType
framesPerSecond
isRecommendedForHighResolutionFrameCapturing
isVideoHDRSupported
_isRecommendedForHighResolutionFrameCapturing
_videoHDRSupported
_captureDevicePosition
_captureDeviceType
_framesPerSecond
Tq,R,N,V_captureDevicePosition
T@"NSString",R,N,V_captureDeviceType
Tq,R,N,V_framesPerSecond
TB,R,N,V_isRecommendedForHighResolutionFrameCapturing
videoHDRSupported
TB,R,N,GisVideoHDRSupported,V_videoHDRSupported
B16@0:8
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@96@0:8@16{?=[4]}24B88B92
@20@0:8B16
@24@0:8@16
v24@0:8@16
v24@0:8d16
d16@0:8
v20@0:8B16
v16@0:8
@"NSUUID"
@"ARReferenceImage"
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
16@0:8
@"NSArray"
@"ARPointCloud"
@32@0:8@16@24
q16@0:8
@28@0:8@16B24
f16@0:8
v20@0:8f16
v24@0:8q16
v24@0:8Q16
@"NSURL"
@"NSNumber"
v32@0:8@16Q24
v80@0:8{?=[4]}16
v24@0:8@?16
v120@0:8{?=[4]}168096@?112
@32@0:8@16@?24
v40@0:816@?32
@"<ARSessionDelegate>"
@"NSObject<OS_dispatch_queue>"
@"ARFrame"
@"ARConfiguration"
@"ARWorldMap"
r^16@0:8
r^Q16@0:8
{vector<float __attribute__((ext_vector_type(3))), std::allocator<float __attribute__((ext_vector_type(3)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(3))), std::allocator<float __attribute__((ext_vector_type(3)))>>="__value_"^}}
{vector<unsigned long long, std::allocator<unsigned long long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>="__value_"^Q}}
{?=[4]}16@0:8
^{__CVBuffer=}16@0:8
@160@0:8{?=[4]}16{?=[4]}80@144@152
@88@0:8{?=[4]}16@80
@"ARWorldTrackingState"16@0:8
@"ARLightEstimate"16@0:8
@"ARPointCloud"16@0:8
@"NSArray"160@0:8{?=[4]}16{?=[4]}80@"NSArray"144@"NSMutableArray"152
@"NSArray"88@0:8{?=[4]}16@"NSArray"80
@32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
v24@0:8^{__CVBuffer=}16
{?=[3]}16@0:8
v64@0:8{?=[3]}16
^{__CVBuffer=}
{?="columns"[3]}
{?="columns"[4]}
@"<ARSensorDelegate>"16@0:8
v24@0:8@"<ARSensorDelegate>"16
@"<ARSensorDelegate>"
v32@0:8@16@24
v28@0:8B16@20
q24@0:8@16
f24@0:8@16
d24@0:8@16
@88@0:8@16{?=[4]}24
@"ARReferenceObject"
Q24@0:8@16
@"ARSkeleton3D"
@"NSSet"
@24@0:8@"ARAnchor"16
@80@0:8{?=[4]}16
@96@0:8@16{?=[4]}24@88
@100@0:8@16{?=[4]}24@88B96
v96@0:8@16{?=[4]}24@88
@"NSString"
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
@"NSData"16@0:8
@24@0:8@"NSData"16
{?=ddd}16@0:8
v40@0:8{?=ddd}16
{?="x"d"y"d"z"d}
@104@0:8@16d24@32{?=[4]}40
@168@0:8@16d24@32{?=[4]}40{?=[4]}104
@40@0:8@16d24@32
@112@0:8@16d24@32{?=[4]}40d104
@"ARMeshGeometry"
v40@0:8@16@24@32
v40@0:8@16q24@32
v28@0:8@16i24
v40@0:8@"CLLocationManager"16@"CLLocation"24@"CLLocation"32
v32@0:8@"CLLocationManager"16@"NSArray"24
v32@0:8@"CLLocationManager"16@"CLHeading"24
B24@0:8@"CLLocationManager"16
v40@0:8@"CLLocationManager"16q24@"CLRegion"32
v40@0:8@"CLLocationManager"16@"NSArray"24@"CLBeaconRegion"32
v40@0:8@"CLLocationManager"16@"CLBeaconRegion"24@"NSError"32
v40@0:8@"CLLocationManager"16@"NSArray"24@"CLBeaconIdentityConstraint"32
v40@0:8@"CLLocationManager"16@"CLBeaconIdentityConstraint"24@"NSError"32
v32@0:8@"CLLocationManager"16@"CLRegion"24
v32@0:8@"CLLocationManager"16@"NSError"24
v40@0:8@"CLLocationManager"16@"CLRegion"24@"NSError"32
v28@0:8@"CLLocationManager"16i24
v24@0:8@"CLLocationManager"16
v32@0:8@"CLLocationManager"16@"CLVisit"24
i16@0:8
@?16@0:8
@"CLLocationManager"
@"NSCondition"
r^s16@0:8
r^f16@0:8
@"NSUUID"16@0:8
@36@0:8@16B24@28
v32@0:816
{vector<float __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__begin_"^"__end_"^"__end_cap_"{__compressed_pair<float * __attribute__((ext_vector_type(2))), std::allocator<float __attribute__((ext_vector_type(2)))>>="__value_"^}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSObject<OS_dispatch_semaphore>"
@"NSError"
@"NSDictionary"
@"ARSession"16@0:8
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@40@0:8{CGPoint=dd}16Q32
@"ARSession"
B24@0:8Q16
@24@0:8#16
@"ARVideoFormat"
@"ARParentImageSensorSettings"
@"ARImageSensorSettings"
@"<ARReplaySensorProtocol>"
@"ARAnchor"
@"ARSkeleton2D"
@32@0:8{CLLocationCoordinate2D=dd}16
@40@0:8{CLLocationCoordinate2D=dd}16d32
@40@0:8@16{CLLocationCoordinate2D=dd}24
@48@0:8@16{CLLocationCoordinate2D=dd}24d40
v60@0:8{CLLocationCoordinate2D=dd}16d32q40B48d52
{CLLocationCoordinate2D=dd}16@0:8
{CLLocationCoordinate2D="latitude"d"longitude"d}
@32@0:8@16^@24
B32@0:8@16^@24
B24@0:8^{archive=}16
^{archive=}16@0:8
B32@0:8^{archive_entry=}16^{archive=}24
@"NSMutableDictionary"
@64@0:81632q48q56
{?=[4]}56@0:8q16{CGSize=dd}24d40d48
{CGPoint=dd}56@0:816q32{CGSize=dd}40
120@0:8{CGPoint=dd}16{?=[4]}32q96{CGSize=dd}104
{?=[4]}24@0:8q16
{CGSize=dd}16@0:8
{CGSize="width"d"height"d}
@"NSData"
@36@0:8^{CGImage=}16I24d28
@36@0:8^{__CVBuffer=}16I24d28
v24@0:8B16B20
@"<ARCoachingOverlayViewDelegate>"
@"NSObject<ARSessionProviding>"
@44@0:8{vector<ARPatch, std::allocator<ARPatch>>=^{?}^{?}{__compressed_pair<ARPatch *, std::allocator<ARPatch>>=^{?}}}16f40
r^{?=}16@0:8
{vector<ARPatch, std::allocator<ARPatch>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<ARPatch *, std::allocator<ARPatch>>="__value_"^{?}}}
v40@0:8{CLLocationCoordinate2D=dd}16@?32
B24@0:8q16
@"ARSkeletonDefinition"
{?=[4]}24@0:8@16
r^{?=[4]}16@0:8
r^{?=[4]}
24@0:8@16
@"ARPlaneExtent"
@"ARPlaneGeometry"
@"ARPatchGrid"
@96@0:8{?=[4]}1680
@104@0:8@16{?=[4]}2488
@248@0:8@16{ARTexturedPlane={array<unsigned char, 16UL>=[16C]}Q{?=[4]}{array<float __attribute__((ext_vector_type(3))), 4UL>=[4]}{set<std::array<unsigned char, 16>, std::less<std::array<unsigned char, 16>>, std::allocator<std::array<unsigned char, 16>>>={__tree<std::array<unsigned char, 16>, std::less<std::array<unsigned char, 16>>, std::allocator<std::array<unsigned char, 16>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::array<unsigned char, 16>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::less<std::array<unsigned char, 16>>>=Q}}}@}24
@"<MTLTexture>"
@"ARParametricLights"
@32@0:8@16q24
@"NSURL"16@0:8
@48@0:8q16q24q32q40
@"<MTLBuffer>"
@"ARGeometrySource"
@"ARGeometryElement"
@100@0:8@16{?=[4]}24B88@92
@"ARCoreRESkeletonResult"
@"ARBody2D"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
96@0:8{CGPoint=dd}16{?=[4]}32
@48@0:8{CGPoint=dd}16q32q40
@24@0:8d16
@40@0:8@16@24@32
@40@0:8@16@24^@32
B40@0:8@16@24^@32
{CGAffineTransform=dddddd}40@0:8q16{CGSize=dd}24
@"AVDepthData"
@"ARCamera"
@"ARLightEstimate"
@"ARGeoTrackingStatus"
@"ARDepthData"
@24@0:8Q16
@"ARFaceGeometry"
@"<ARFaceTrackingDataProtocol>"
