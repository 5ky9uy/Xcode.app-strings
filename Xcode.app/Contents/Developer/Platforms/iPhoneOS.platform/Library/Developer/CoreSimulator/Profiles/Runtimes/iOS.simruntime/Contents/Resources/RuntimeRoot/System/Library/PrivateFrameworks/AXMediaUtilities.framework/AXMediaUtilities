@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
333333
l@q=
uouacoirlppa
?333333
@ffffff
y@NSt3__120__shared_ptr_pointerIP13vImage_BufferZ46+[AXShotflowHelpers getCGImageAsVImageBuffer:]E3$_0NS_9allocatorIS1_EEEE
Z46+[AXShotflowHelpers getCGImageAsVImageBuffer:]E3$_0
NSt3__120__shared_ptr_pointerIP7CGImagePFvS2_ENS_9allocatorIS1_EEEE
PFvP7CGImageE
@UUUUUU
@o@{
?UUUUUU
?UUUUUU
?UUUUUU
?433333
?UUUUUU
?UUUUUU
?UUUUUU
?UUUUUU
/B33
B33CCgf
?fff?
BNSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
v24@?0^{_LXEntry=}8*16
Create Lexicon %@
@16@?0@"AXMetric"8
UIType
wordCount
charCount
featureNames
T@"NSSet",R,N
T@"NSString",&,N,V_UIType
Td,N,V_x
Td,N,V_y
Td,N,V_w
Td,N,V_h
Td,N,V_wordCount
Td,N,V_charCount
labelWithUIType
labelWithUITypeProbability
T@"NSString",&,N,V_labelWithUIType
T@"NSDictionary",&,N,V_labelWithUITypeProbability
Clickability
mlmodelc
model
T@"MLModel",R,N,V_model
IgnoredLayerContextIDs
IncludedLayerContextIDs
UsePreferredModelInputSizeForDetectors
Screen Grab
Screen grab not supported on this platform
v8@?0
Library/Accessibility/PhotoCaptionAssets
CompiledModels
UncompiledModels
mlmodel
Horizon Detector
_detectHorizonRequest
T@"VNDetectHorizonRequest",&,N,S_setDetectHorizonRequest:,V__detectHorizonRequest
VNDetectHorizonRequest
Unable to find class %s
/System/Library/Frameworks/Vision.framework/Vision
mainColors
mainColorWeights
supportsSecureCoding
TB,R
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
remainingColorWeight
Td,N,V_remainingColorWeight
gender
eyes
smiling
faceHair
hairColor
bald
glasses
com.apple.accessibility.AXMediaUtilities
faceattributes.eyes.closed
Accessibility
faceattributes.eyes.open
faceattributes.smiling
faceattributes.facehair.beard
faceattributes.facehair.goatee
faceattributes.facehair.moustache
faceattributes.facehair.stubble
faceattributes.haircolor.black
faceattributes.haircolor.blonde
faceattributes.haircolor.brown
faceattributes.haircolor.gray
faceattributes.haircolor.red
faceattributes.haircolor.white
faceattributes.bald
faceattributes.glasses.prescription
faceattributes.glasses.sunglasses
faceattributes.age.baby
faceattributes.age.child
faceattributes.age.youngadult
faceattributes.age.senior
wearing.glasses
with.face.attributes
three.attributes.described
two.attributes.described
results
T@"NSDictionary",&,N,V_results
ageCategory
Tq,R,N,V_ageCategory
genderCategory
Tq,R,N,V_genderCategory
eyesCategory
Tq,R,N,V_eyesCategory
smilingCategory
Tq,R,N,V_smilingCategory
faceHairCategory
Tq,R,N,V_faceHairCategory
hairColorCategory
Tq,R,N,V_hairColorCategory
baldCategory
Tq,R,N,V_baldCategory
glassesCategory
Tq,R,N,V_glassesCategory
VNFaceAttributeAgeBaby
VNFaceAttributeAgeChild
VNFaceAttributeAgeYoungAdult
VNFaceAttributeAgeSenior
VN1yPD9G185LIMKFd9RgandG6vUu4B3DZk
VN6cM1E1jfvMnUZoEeDjinPOtJKpacqIpr
VNFaceAttributeEyesClosed
VNFaceAttributeEyesOpen
VNFaceAttributeNotSmiling
VNFaceAttributeSmiling
VNFaceAttributeFaceHairBeard
VNFaceAttributeFaceHairGoatee
VNFaceAttributeFaceHairMoustache
VNFaceAttributeFaceHairStubble
VNFaceAttributeFaceHairUnsure
VNFaceAttributeHairColorBlack
VNFaceAttributeHairColorBlonde
VNFaceAttributeHairColorBrown
VNFaceAttributeHairColorGray
VNFaceAttributeHairColorRed
VNFaceAttributeHairColorWhite
VNFaceAttributeNotBald
VNFaceAttributeBald
VNFaceAttributeGlassesPrescription
VNFaceAttributeGlassesSunglasses
VNFaceAttributeGlassesNone
objectType
Tq,V_objectType
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
center
T{CGPoint=dd},R
confidence
Tf,V_confidence
Face Detector
v32@?0@8Q16^B24
v32@?0@"NSString"8@"AXMVisionFeatureFaceDetectionResult"16^B24
_faceRectanglesRequest
T@"VNDetectFaceRectanglesRequest",&,N,V__faceRectanglesRequest
_faceprintRequest
T@"VNCreateFaceprintRequest",&,N,V__faceprintRequest
_faceAttributesRequest
T@"VNClassifyFaceAttributesRequest",&,N,V__faceAttributesRequest
_faceExpressionsRequest
T@"VNDetectFaceExpressionsRequest",&,N,V__faceExpressionsRequest
_faceLandmarksRequest
T@"VNDetectFaceLandmarksRequest",&,N,V__faceLandmarksRequest
_facePoseRequest
T@"VNDetectFacePoseRequest",&,N,V__facePoseRequest
VNDetectFaceExpressionsRequest
VNClassifyFaceAttributesRequest
VNDetectFaceLandmarksRequest
VNDetectFacePoseRequest
VNDetectFaceRectanglesRequest
Aesthetics
_imageAestheticsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V__imageAestheticsRequest
VNClassifyImageAestheticsRequest
AXMServiceConnection
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
v16@?0@"NSError"8
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
delegate
T@"<AXMServiceDelegate>",W,N,V_delegate
AXMOutputRequest
B24@?0@"AXMOutputAction"8@"NSDictionary"16
handle
T@"AXMOutputRequestHandle",R,N,V_handle
actions
T@"NSArray",R,N
speechActions
oneShotSoundActions
activeSoundActions
completionBlock
T@?,C,N,V_completionBlock
interruptsAndClearsQueue
TB,N,V_interruptsAndClearsQueue
actionHandles
chart.model.exponential
d32@?0^d8Q16d24
y = %@ * e^(%@x)
AXMSpeechFormatter does not implement getObjectValue:forString:errorDescription:
formattingBlock
T@?,C,N,V_formattingBlock
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
defaultBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
Tf,N,V_confidence
scale
Ti,N,V_scale
mergesCount
Ti,N,V_mergesCount
rotationAngle
Tf,N,V_rotationAngle
yawAngle
Tf,N,V_yawAngle
hasPose
TB,N,V_hasPose
hasLabel
TB,N,V_hasLabel
label
Ti,N,V_label
labelName
T@"NSString",&,N,V_labelName
boxCenter
T{CGPoint=dd},R,N
distanceToDefaultBox
Tf,R,N
smartDistance
modelURL
Model Detector
Model loading not supported on this platform
T@"NSURL",&,N,V_modelURL
modelIdentifier
T@"NSString",R,N,V_modelIdentifier
region
orientation
Screen Capture
@"AXMPipelineContextInput"24@?0@"NSDictionary"8^@16
screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
Traits
sampleFrequency
Tq,N,V_sampleFrequency
shouldEvaluateColorInformation
TB,N,V_shouldEvaluateColorInformation
colorDistanceTheshold
Td,N,V_colorDistanceTheshold
VNImageScoreObservation
VNImageBrightnessObservation
VNImageBlurObservation
VNImageBlurScoreRequest
FormatVersion
B32@?0@"MAAsset"8Q16^B24
q24@?0@"MAAsset"8@"MAAsset"16
_ContentVersion
v16@?0q8
mlModels
T@"NSArray",R,N,V_mlModels
mobileAssetBaseURL
T@"NSURL",R,N,V_mobileAssetBaseURL
v16@?0@"NSString"8
com.apple.accessibility.vot.caption.fallbacktemplates
fallbacktemplate
@"NSDictionary"8@?0
caption-low-confidence
caption-nsfw
photo.description.brightness.level.1
photo.description.brightness.level.2
photo.description.brightness.level.3
photo.description.brightness.level.4
photo.description.brightness.level.5
photo.description.blurriness.level.1
photo.description.blurriness.level.2
photo.description.blurriness.level.3
photo.description.blurriness.level.4
photo.description.blurriness.level.5
photo.description.blurriness.level.6
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.faces
face.number
blood
 that might contain blood
demonstration
 that might be a demonstration
 that might be a scene of destruction
fire
 that might include fire
flood
 that might be a flood
funeral
 that might be a funeral
hospital
 that might be a hospital
religious
 that might be a religious setting
crash
 that might be a vehicle crash
AXCaptionTemplateRules
plist
subsume
baby
ignored
Possible adult content
priority
q24@?0@"NSString"8@"NSString"16
B32@?0@"NSString"8Q16^B24
No description available
aeiouAEIOU
speech
nonCountNounOrPlural
A photo containing %@ %@
A photo of %@
 and 
%@ %@
v32@?0@"NSString"8@"NSString"16^B24
v32@?0@"NSString"8Q16^B24
blurFeature
T@"AXMVisionFeature",&,N,V_blurFeature
brightnessFeature
T@"AXMVisionFeature",&,N,V_brightnessFeature
isNSFW
TB,N,V_isNSFW
shouldModifyCaptionForSensitiveContent
TB,N,V_shouldModifyCaptionForSensitiveContent
primarySensitiveContentFeature
T@"AXMVisionFeature",&,N,V_primarySensitiveContentFeature
/System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics
AnalyticsSendEventLazy
Caption Confidence Insufficient
Blacklist Rule
Taboo Filter
NSFW Filter
MinimumConfidence
BlacklistRule
ClassifierLabel
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
AXMImgRegistration
diagnosticsEnabled
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
v24@?0@"AXMVisionResult"8@"NSError"16
v32@?0@"AXMEvaluationNode"8Q16^B24
v24@?0@"AXMVisionPipelineContext"8@"AXMEvaluationNode"16
Evaluate %@
v16@?0@"AXMetric"8
Create Image
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld metrics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
Engine queue is at capacity
identifier
T@"NSString",C,V_identifier
axMediaUtilsService
T@"AXMService",&,N,V_axMediaUtilsService
cache
T@"AXMVisionEngineCache",&,N,V_cache
taskDispatcher
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
sequenceRequestManager
T@"AXMSequenceRequestManager",&,N,V_sequenceRequestManager
sourceNodes
evaluationNodes
maximumQueueSize
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TB,V_prioritySchedulingAllowMultipleNodeExecution
TQ,V_thresholdPriority
imageRegistrationFilteringEnabled
TB,N,V_imageRegistrationFilteringEnabled
minimumImageRegistrationSignalLevel
Tq,N,V_minimumImageRegistrationSignalLevel
isCachingEnabled
TB,R,N
cacheSize
Tq,R,N
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
disableResultLogging
TB,N,V_disableResultLogging
T@"NSUUID",&,N,V_identifier
context
T@"AXMVisionPipelineContext",&,N,V_context
source
T@"AXMSourceNode",&,N,V_source
VNRequestHandlerCleanupOption_AllPipelines
VNCleanupLevel_Complete
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNImageRequestHandler
AXMLanguage
v16@?0@"NSNotification"8
AXMLanguage<%p> languageID: '%@'. Locale: <%p> '%@'
primaryComponent
secondaryComponent
languageCode
locale
T@"NSString",&,N,V_primaryComponent
T@"NSString",&,N,V_secondaryComponent
T@"NSString",&,N,V_languageCode
T@"NSLocale",&,N,V_locale
languageDisplayName
T@"NSString",R,N
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
deviceAttitude
Tf,R,N,V_videoFieldOfView
Tf,R,N,V_videoZoomFactor
Tq,R,N,V_videoSourceWidth
Tq,R,N,V_videoSourceHeight
Td,R,N,V_presentationTimestamp
T@"CMAttitude",R,N,V_deviceAttitude
function
T@?,R,N,V_function
xAxisDescriptor
T{?=^dddddd},R,N,V_xAxisDescriptor
yAxisDescriptor
T{?=^dddddd},R,N,V_yAxisDescriptor
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
input
sourceProvidesResults
sourceparams
features
evaluatedFeatureTypes
analysisOptions
userContext
error
EffectiveTextDetectionLocales
Pipeline-%ld
AXM_VISION_ENGINE_METRICS
com.apple.accessibility.sceneobservation
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
A creation node must return a valid image
%@-%ld-%ldx%ld.%@
Pipeline
T@"NSMutableArray",&,N,V_features
T@"NSMutableSet",&,N,V_evaluatedFeatureTypes
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
result
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
metricSession
T@"AXMetricSession",&,N,V_metricSession
visionImageRequestHandler
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
imageRegistrationState
Tq,N,V_imageRegistrationState
T@"NSObject<NSSecureCoding>",&,N,V_userContext
effectiveTextDetectionLocales
T@"NSArray",&,N,V_effectiveTextDetectionLocales
shouldProcessRemotely
TB,N,V_shouldProcessRemotely
resultHandlers
size
T{CGSize=dd},R,N
visionImageRequestHandlerIsLoaded
cacheKey
T@"<NSCopying>",&,N,V_cacheKey
shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
evaluationExclusivelyUsesVisionFramework
TB,N,V_evaluationExclusivelyUsesVisionFramework
TQ,N,V_sequenceID
sourceInput
T@"AXMPipelineContextInput",R,N
pipelineMetric
T@"<AXMetricContainer>",R,N
Text Detector
@16@?0@"NSString"8
@16@?0@"VNRecognizedTextObservation"8
en-US
semanticTextFactory
T@"AXMSemanticTextFactory",&,N,V_semanticTextFactory
textLayoutManager
T@"AXMTextLayoutManager",&,N,V_textLayoutManager
VNRecognizeTextRequest
AXMGlobalTagLocale
AXMGlobalTagIsSpeakable
AXMGlobalTagIsEvaluated
IsSpeakable
IsNonspeakable
v32@?0@"NSString"8@16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
AXMTaggedText<%p> Speakable:%d. Text: '%@'
AXMTaggedText<%p> : '%@'
 Locale: %@
 Is evaluated? %@
 Is speakable? %@
 Speakable Text: '%@'
 Global Attributes:
  %@ : %@
 Tokens:
  '%@' [%ld %ld] : %@
T@"NSLocale",R,N
speakable
TB,N,GisSpeakable
speakableText
image
iconClass
SharedIconVision
imageNode
T@"AXMImageNode",W,N,V_imageNode
iconClassDetector
T@"AXMIconClassDetectorNode",W,N,V_iconClassDetector
v20@?0@"AXMTask"8B16
count
isEmpty
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
complete
TB,N,GisComplete,V_complete
taskCompleteBlock
T@?,C,N,V_taskCompleteBlock
iouThreshold
confidenceThreshold
T^{__CVBuffer=},N,V_image
Td,N,V_iouThreshold
Td,N,V_confidenceThreshold
coordinates
T@"MLMultiArray",&,N,V_confidence
T@"MLMultiArray",&,N,V_coordinates
AXElementVision
attackMS
Td,N,V_attackMS
attackLevel
Td,N,V_attackLevel
decayMS
Td,N,V_decayMS
sustainMS
Td,N,V_sustainMS
sustainLevel
Td,N,V_sustainLevel
releaseMS
Td,N,V_releaseMS
lengthMS
Td,R,N
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
maximumNumberOfRects
Tq,N,V_maximumNumberOfRects
VNDetectRectanglesRequest
VNImageOptionCameraIntrinsics
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
redFloat
greenFloat
blueFloat
hueFloat
saturationFloat
brightnessFloat
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
allColorMarkers
localizedName
T@"NSString",&,N,V_localizedName
synthesizer
T@"AVSpeechSynthesizer",&,N,V_synthesizer
currentRequestCompletionBlock
T@?,C,N,V_currentRequestCompletionBlock
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu sources=
name
T@"NSString",C,N,V_name
panning
Td,N,V_panning
dataSources
T@"NSSet",&,N,V_dataSources
isMonoOutput
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
B32@?0@8Q16^B24
captureSession
T@"AVCaptureSession",W,N,V_captureSession
captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
frameDelegate
T@"<AXMAVCaptureSessionNodeFrameDelegate>",W,N,V_frameDelegate
axVideoDataOutput
T@"AXMCaptureVideoDataOutput",&,N,V_axVideoDataOutput
AXMTag<%p>. [%@] [%lu %lu] '%@'
%@|%@|%@
Detected|Detector|PhoneNumber
Detected|Detector|Date
Detected|Regex|Email
Unknown
range
T{_NSRange=QQ},R,N
originalText
isPunctuation
isWhitespace
isSentenceTerminator
isOpenQuote
isCloseQuote
isPhoneNumber
isDate
isEmailAddress
Began
Ended
New Device Available
Old Device Unavailable
Category Change
Override
Wake From Sleep
No Suitable Route for Category
Route Congifuration Change
notificationObserverTokens
T@"NSMutableArray",&,N,V_notificationObserverTokens
session
T@"AVAudioSession",&,N,V_session
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
isSupported
componentState
Tq,N,V_componentState
AXMFeatures
AXMImage
B32@?0@"AXMVisionFeature"8Q16^B24
detected.text.hint
Locale
en_US
ModifyForSensitiveContent
caption.contains.senstive.content.warning
detected.icon.hint
detectedTextDescription
equivalenceToken
metrics
AXMVisionResult<%p>: Image:%@ Results:%@ Feature Description: '%@'. Text Description: '%@'.
T@"NSString",&,N,V_detectedTextDescription
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSSet",&,N,V_evaluatedFeatureTypes
colorInfoFeature
T@"AXMVisionFeature",R,N
assetMetadataFeature
localizedDetectedTextHint
localizedDetectedIconHint
featureGates
T@"NSDictionary",R,N
T@"NSData",&,N,V_equivalenceToken
detectedTextLanguage
T@"AXMLanguage",R,N
localizedSensitiveContentWarning
detectedFeatureDescription
faceFeatures
sceneClassificationFeatures
objectClassificationFeatures
modelClassificationFeatures
captionFeatures
ocrFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
includesNSFWFeatures
sensitiveContentForCaptionFeatures
captionMayContainSensitiveContent
axm_featuresSortedByConfidence
axm_featureWithHighestConfidence
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
%@ playerItem:<%@>
targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
model_info.json
Stable
T@"NSURL",C,N,V_modelURL
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceLandmarksConfidence
AXMFeatureFaceExpressions
AXMFeatureFacePose
AXMVisionFeatureCodingKeyFacePoseConfidence
AXMFeatureFaceName
AXMFeatureFaceNameConfidence 
AXMFeatureFaceAttributes
AXMFeatureFaceAttributesConfidence
AXMFeatureFaceRectangles
AXMFeatureFaceRectanglesConfidence
AXMFeatureFaceUUID
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
uuid
T@"NSUUID",&,N,V_uuid
faceId
TQ,N,V_faceId
frame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_frame
rectanglesConfidence
Td,N,V_rectanglesConfidence
T@"NSString",&,N,V_name
nameConfidence
Td,N,V_nameConfidence
attributes
T@"AXMVisionFeatureFaceAttributes",&,N,V_attributes
attributesConfidence
Td,N,V_attributesConfidence
expressionsAndConfidence
T@"NSDictionary",&,N,V_expressionsAndConfidence
likelyExpression
landmarks
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks
landmarks3d
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks3d
landmarksConfidence
Td,N,V_landmarksConfidence
pose
T{?=[4]},N,V_pose
poseConfidence
Td,N,V_poseConfidence
B24@?0@"AXShotflowFaceDetection"8@"NSDictionary"16
overlap_threshold
Tf,N,V_overlap_threshold
threshold
Tf,N
filterThreshold
T@"NSArray",&,N,V_filterThreshold
nmsThreshold
Tf,N,V_nmsThreshold
mergeHeadsThreshold
Tf,N,V_mergeHeadsThreshold
osfsThreshold
Tf,N,V_osfsThreshold
osfsSizeRatio
Tf,N,V_osfsSizeRatio
olmcsThreshold
Tf,N,V_olmcsThreshold
olmcsMergeCountDelta
Ti,N,V_olmcsMergeCountDelta
smartThreshold
Tf,N,V_smartThreshold
smartDistanceFactor
Tf,N,V_smartDistanceFactor
v32@?0@"NSTextCheckingResult"8Q16^B24
[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?
T@"NSString",&,N,V_label
Td,N,V_confidence
NSFW Detector
VNVYvzEtX1JlUdu8xx5qhDI
VN81aedeb999c79d74e79af7f1c922cf97
CaptureSettings:device unexpectedly nil
CaptureSettings:format unexpectedly nil
Cannot add input '%@' to session '%@'
AXMCaptureManagerFrameReceive
Cannot add output '%@' to session '%@'
@"NSError"16@?0@"AVCaptureSession"8
<unavilable>
T@"AVCaptureSession",R,N
activeScenario
Tq,R,N,V_activeScenario
deviceOrientation
Tq,N,V_deviceOrientation
captureDevice
T@"AVCaptureDevice",&,N,V_captureDevice
captureFormat
T@"AVCaptureDeviceFormat",&,N,V_captureFormat
B24@?0@"AVFrameRateRange"8@"NSDictionary"16
B24@?0@"AVCaptureDeviceFormat"8@"NSDictionary"16
device
formats
AXMCaptureManager
InputImage
SceneDetector
FaceDetector
sequenceRequestHandler
T@"VNSequenceRequestHandler",&,N,V_sequenceRequestHandler
VNSequenceRequestHandler
 - [%@]
uiClass
TQ,N,V_uiClass
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
AXElement Detector
com.apple.MobileAsset.AXElementVision
CIConstantColorGenerator
CICrop
inputImage
inputRectangle
CIColorControls
{CGAffineTransform=dddddd}
CIAffineTransform
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
AXElementVision_ANOD.espresso.net
AXElementVision_ANOD_NonSquare.espresso.net
q24@?0@"AXShotflowFaceDetection"8@"AXShotflowFaceDetection"16
ERROR: zero image dimension
esp error
boxes
Text
Text_True
mlModel
T@"AXElementVision__generated__",&,D,N
shotflowDetector
T@"AXShotflowDetector",R,N,V_shotflowDetector
ANODModelVersion
Ti,N,V_ANODModelVersion
VNCoreMLModel
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
height
bottom
width
left
right
normalizedFrame
no source texts provided
@16@?0@"AXMVisionFeature"8
Image Registration
registrationState
VNTranslationalImageRegistrationRequest
VNImageTranslationAlignmentObservation
Camera Metadata
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
ratio
Td,N,V_ratio
gainReduction
Td,N,V_gainReduction
engagement
Td,N,V_engagement
emaSamples
TQ,N,V_emaSamples
Td,N,V_ema
compressionRatio
Td,N,V_compressionRatio
gain
Td,N,V_gain
Td,N,V_threshold
sampleRate
Td,N,V_sampleRate
bubbleUp
bubbleDown
pluck1
pluck2
scratch1
scratch2
success1
T@"AXMOutputActionHandle",R,N
text
aiff
sounds
soundFileURL
T@"NSURL",R,N
soundID
T@"AXMActiveSoundOutputActionHandle",R,D,N
handleProvider
T@"<AXMActiveSoundOutputActionHandleProvider>",&,N,V_handleProvider
pitch
rate
inputType
ciImage
use wrapperWithPixelBuffer:
PixelWidth
PixelHeight
CIImage
Pixel Buffer
%@ (%@)
Convert to CGImage
T@"CIImage",R,N
pixelBuffer
T@"AXMPixelBufferWrapper",R,N
imageColorSpace
T^{CGColorSpace=},R,N
wrappedPixelBuffer
T^{__CVBuffer=},R,N
Icon Class Detector
com.apple.MobileAsset.AXIconVision
iconclassification.mlmodelc
CILanczosScaleTransform
inputScale
inputAspectRatio
unknown
icon.type.
T@"iconclassification__generated__",R,D,N
NLPToken
IsInLexicon
NumericToken
DataDetector
CustomPattern
SemanticError
NLP:OtherWord
NLP:PersonalName
NLP:OrganizationName
NLP:PlaceName
NLP:Whitespace
NLP:Dash
NLP:Punctuation
NLP:SentenceTerminator
NLP:Unknown
DD:Date
DD:Address
DD:Link
DD:PhoneNumber
DD:TransitInfo
US_Currency
v40@?0@8{_NSRange=QQ}16^B32
transformedSpeechText
T@"NSString",&,N,V_transformedSpeechText
preprocessedText
isSemanticallyComplete
SemanticTextPatterns
Patterns
Pattern
v40@?0@"NSString"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"NSRegularExpression"16^B24
Failed to match current cursor position. remaining:[%ld %ld]
tagger
T@"NLTagger",&,N,V_tagger
cachedLexicons
T@"NSMutableDictionary",&,N,V_cachedLexicons
numberFormatter
T@"NSNumberFormatter",&,N,V_numberFormatter
compiledPatterns
T@"NSMutableDictionary",&,N,V_compiledPatterns
dataDetector
T@"NSDataDetector",&,N,V_dataDetector
Failed to advance cursor. No value for attribute: %@. remaining:[%ld %ld]
isFinished
currentAttributes
remainingRange
isOtherWord
isProperNoun
isInLexicon
isCustomPattern
TI,R,N
unorientedSize
orientedSize
Sceneprint Creator
@"VNSceneObservation"8@?0
VNCreateSceneprintRequest
Asset Metadata
PlaybackMixer
PlaybackChartData
PlaybackTrendline
ScrubbingMixer
ScrubbingDiscreteData
ScrubbingContinuousData
ScrubbingTrendline
LiveToneMixer
LiveContinuousData
v16@?0@"NSTimer"8
Error playing audio buffer
Error stopping audio playback
Error initalizing audio unit
Error initializing audio component
Error setting audio format
Error setting output callback
playbackObserverUpdateTimer
T@"NSTimer",&,N,V_playbackObserverUpdateTimer
playbackMixerDataSource
T@"AXMAudioDataSourceMixer",&,N,V_playbackMixerDataSource
playbackChartDataAudioDataSource
T@"AXMAudioDataSource",&,N,V_playbackChartDataAudioDataSource
playbackTrendlineAudioDataSource
T@"AXMAudioDataSource",&,N,V_playbackTrendlineAudioDataSource
scrubbingMixerDataSource
T@"AXMAudioDataSourceMixer",&,N,V_scrubbingMixerDataSource
scrubbingDiscreteAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingDiscreteAudioDataSource
scrubbingContinuousAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingContinuousAudioDataSource
scrubbingTrendlineAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingTrendlineAudioDataSource
liveContinuousMixerDataSource
T@"AXMAudioDataSourceMixer",&,N,V_liveContinuousMixerDataSource
liveContinuousAudioDataSource
T@"AXMAudioDataSource",&,N,V_liveContinuousAudioDataSource
playbackObservers
T@"NSPointerArray",&,N,V_playbackObservers
interpolationMode
Ti,R,N,V_interpolationMode
continuousScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_continuousScrubbingTone
trendlineScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_trendlineScrubbingTone
liveContinuousDataTone
T@"AXMLiveContinuousTone",R,N,V_liveContinuousDataTone
trendlineFunction
T@?,C,N,V_trendlineFunction
isEndingScrubbing
TB,R,N,V_isEndingScrubbing
scrubbingDiscreteDataRenderingContext
T^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}},R,N,V_scrubbingDiscreteDataRenderingContext
scrubbingPlaybackCallbackRenderingContext
T^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}},R,N,V_scrubbingPlaybackCallbackRenderingContext
liveTonePlaybackCallbackRenderingContext
T^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}},R,N,V_liveTonePlaybackCallbackRenderingContext
playbackSampleCount
TQ,R,N,V_playbackSampleCount
isPlaying
TB,R,N,V_playing
isPaused
TB,R,N,V_paused
isScrubbing
TB,R,N,V_scrubbing
isInLiveContinuousToneSession
TB,R,N,V_isInLiveContinuousToneSession
currentPlaybackPosition
minimumPlaybackFrequency
Td,N,V_minimumPlaybackFrequency
maximumPlaybackFrequency
Td,N,V_maximumPlaybackFrequency
playbackDuration
Td,N,V_playbackDuration
ampEnvelope
T@"AXMADSREnvelope",&,N,V_ampEnvelope
toneWaveform
TQ,N,V_toneWaveform
usesBinauralPanning
TB,N,V_usesBinauralPanning
dataMode
Ti,R,N,V_dataMode
Error: IO audio unit is running but we aren't in a scrubbing or playback session -- investigate.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
input_1
T@"MLMultiArray",&,N,V_input_1
output1
classLabel
T@"NSDictionary",&,N,V_output1
T@"NSString",&,N,V_classLabel
iconclassification
AXMSetting
writeOutInputImages
TB,D,N
writeOutOCRInputImages
writeOutScreenCaptures
useANODModelForAXElementVision
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
assetURL
creationDate
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
name:%@ created:%@ UTI:%@ typeDesc:%@
T@"NSURL",&,N,V_assetURL
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
localizedTypeDescription
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
Aesthetics: aesthetic=%.2f wellFramedSubject=%.2f wellChosenBackground=%.2f noise=%.2f failure=%.2f pleasantComposition=%.2f
Tf,R,N,V_aestheticScore
Tf,R,N,V_wellFramedSubjectScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_noiseScore
Tf,R,N,V_failureScore
AXMDisplayManager
DeviceClassNumber
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
main-screen-scale
main-screen-orientation
Aixt/MEN2O2B7f+8m4TxUA
supportsDeepColor
displayMonitor
T@"FBSDisplayMonitor",&,N,V_displayMonitor
mobileGestaltOrientation
Td,N,V_mobileGestaltOrientation
frontBoardMainDisplay
T@"AXMDisplay",R,N
coreAnimationMainDisplay
isInitialized
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
backingType
Tq,N,V_backingType
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
physicalOrientation
Tq,N,V_physicalOrientation
referenceBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
chart.model.power
y = %@ * x^%@
__AXMDataSummaryStringForVariablesSentinel
Must have two series names and an equal number of xValues, and yValues.
chart.series.trend.increasing
chart.series.trend.decreasing
chart.series.trend.verystrong
chart.series.trend.strong
chart.series.trend.moderate
chart.series.trend.weak
chart.series.trend.none
chart.series.minvalue.format
chart.series.maxvalue.format
chart.series.meanvalue.format
chart.series.outlier.format
chart.series.outliers.none
<%@ %p x:[%.1f, %.1f] y:[%.1f, %.1f] model=%@ xbar=%.1f ybar=%.1f r=%.4f rSq=%.4f y=%.4fx+%.4f
desc=%@
 outliers=%@>
self
axisTitles
T@"NSArray",R,N,V_axisTitles
xValues
T@"NSArray",R,N,V_xValues
yValues
T@"NSArray",R,N,V_yValues
regressionModel
T@"AXMDataRegressionModel",R,N,V_regressionModel
TQ,R,N,V_n
Td,R,N,V_r
rSquared
Td,R,N,V_rSquared
minX
Td,R,N,V_minX
maxX
Td,R,N,V_maxX
meanX
Td,R,N,V_meanX
varianceX
Td,R,N,V_varianceX
minY
Td,R,N,V_minY
maxY
Td,R,N,V_maxY
meanY
Td,R,N,V_meanY
varianceY
Td,R,N,V_varianceY
covariance
Td,R,N,V_covariance
slope
Td,R,N,V_slope
intercept
Td,R,N,V_intercept
residuals
T@"NSArray",R,N,V_residuals
outliers
T@"NSArray",R,N,V_outliers
categoryNameDelegate
T@"NSObject<AXMDataSummaryCategoryNameProvider>",W,N,V_categoryNameDelegate
modelDescription
slopeDescription
confidenceDescription
minValueDescription
maxValueDescription
meanValueDescription
medianValueDescription
outliersDescription
bestFitCurveEquation
fullDescription
simpleDescription
numericalDescription
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
Text Processing
v16@?0@"AXMTag"8
v16@?0@"AXMTaggedText"8
Text Pre-Processing
.,!?
axout-tmp
-axtmp
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
__AXMStringForVariablesSentinel
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
image/gif
filetype.gif
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/rtf
filetype.rtf.document
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/vnd.openxmlformats-officedocument.presentationml.presentation
application/msword
filetype.word
application/vnd.openxmlformats-officedocument.wordprocessingml.document
application/postscript
filetype.postscript
application/rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
application/epub+zip
filetype.epub
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
com.apple.coreaudio-format
video/
usdz
filetype.3D.model
numbers
filetype.number
pages
filetype.pages
filetype.keynote
rtfd
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.sunglasses
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
/System/Library/Frameworks/UIKit.framework/UIKit
UIAccessibilityIsVoiceOverRunning
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
AXMCoreMotionNode_samplesPerSecond
AXMCoreMotionNode_lastSampleTime
Core Motion
lastSampleTime
Td,N,V_lastSampleTime
samplesPerSecond
TQ,N,V_samplesPerSecond
com.apple.AXMediaUtilitiesService
com.apple.AXMediaUtilitiesService-access
contextQueue
Create CIContext
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
phase
Td,R,N,V_phase
framesRendered
TQ,N,V_framesRendered
releasing
TB,N,V_releasing
releaseFrame
TQ,N,V_releaseFrame
muted
TB,N,V_muted
chart.model.sinusoidal
y = %@ * sin(%@x + %@) + %@
Prominent Object Detector
v32@?0@"VNRectangleObservation"8Q16^B24
_imageSaliencyRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V__imageSaliencyRequest
VNGenerateAttentionBasedSaliencyImageRequest
Barcode
captureOutput
T@"AVCaptureMetadataOutput",&,N,V_captureOutput
v40@?0{?={?=qq}Q}8^B32
v32@?0@"VNRequest"8Q16^B24
@"NSError"16@?0@"AXMetric"8
VN PerformRequests
Vision:
preferredModelInputSize
ANEDeviceAvailable
TB,R,N,GisANEDeviceAvailable
effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
VNProcessingDevice
screenCapture
axElement
captureNode
T@"AXMScreenCaptureNode",W,N,V_captureNode
textDetector
T@"AXMTextDetectorNode",W,N,V_textDetector
axElementDetector
T@"AXMAXElementDetectorNode",W,N,V_axElementDetector
inputSource
T@"AXMAudioDataSource",W,N,V_inputSource
Tf,V_rotationAngle
Tf,V_yawAngle
labelKey
Ti,V_labelKey
speech.formatter.email.address.standard.phonetic
 %@ 
speech.formatter.email.address.at.phonetic
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
is3DLandmarks
TB,N,V_is3DLandmarks
VNFaceLandmarks2D
recognitionLevel
normalizedMinimumTextHeightRatio
usesLanguageCorrection
correctSpelling
spellCheckingLanguages
textDetectionLanguage
AXMTextDetectionOptions<%p>
  Options: 
    Recognition Level: %@
Fast
Accurate
    Minimum Text Height Ratio: %.3f
    Use Language Correction: %ld
    Detection Languages: %@
    Correct Spelling: %ld
TQ,N,V_recognitionLevel
Td,N,V_normalizedMinimumTextHeightRatio
TB,N,V_usesLanguageCorrection
textDetectionLocales
T@"NSArray",&,N,V_textDetectionLocales
TB,N,V_correctSpelling
T@"NSSet",&,N,V_spellCheckingLanguages
T@"AXMLanguage",&,N,V_textDetectionLanguage
clientID
includeImageInResult
detectText
textDetectionOptions
detectScenes
detectNSFW
detectSignificantEvents
detectModelClassifications
detectCaptions
detectTraits
detectFaceRectangles
detectFaceNames
detectFaceAttributes
detectFaceExpressions
detectFaceLandmarks
detectFacePose
detectHorizon
detectRectangles
detectProminentObjects
detectAesthetics
detectIconClass
detectAXElements
ignoredLayerContextIDs
includedLayerContextIDs
preserveInputImageSize
AXMVisionAnalysisOptions<%p>. Client: %ld
  Detectors:
    Traits: %ld
    Faces: %ld
    Text: %ld
    Scenes: %ld
    NSFW: %ld
    Significant Events: %ld
    Model Classifications: %ld
    Captions: %ld
    Prominent Objects: %ld
    Aesthetics: %ld
    Icon Classifications: %ld
    AXElement Detection: %ld
    Preserve Input Image Size: %ld
Tq,N,V_clientID
hasDetectionsEnabled
detectFaces
TB,N,V_detectFaceRectangles
TB,N,V_detectFaceNames
TB,N,V_detectFaceAttributes
TB,N,V_detectFaceExpressions
TB,N,V_detectFaceLandmarks
TB,N,V_detectFacePose
TB,N,V_detectScenes
TB,N,V_detectNSFW
TB,N,V_detectSignificantEvents
TB,N,V_detectModelClassifications
TB,N,V_detectCaptions
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHorizon
TB,N,V_detectProminentObjects
TB,N,V_detectAesthetics
TB,N,V_detectIconClass
TB,N,V_detectAXElements
TB,N,V_detectText
T@"AXMTextDetectionOptions",&,N,V_textDetectionOptions
TB,N,V_includeImageInResult
T@"NSArray",&,N,V_ignoredLayerContextIDs
T@"NSArray",&,N,V_includedLayerContextIDs
TB,N,V_preserveInputImageSize
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
request
T@"AXMOutputRequest",&,N,V_request
spellChecker
T@"AppleSpell",&,N,V_spellChecker
TQ,N,V_sampleRate
frequency
Td,R,N,V_frequency
envelope
T@"AXMADSREnvelope",R,N,V_envelope
waveform
TQ,N,V_waveform
aWeighting
Td,R,N,V_aWeighting
chart.model.linear
y = %@x + %@
labelProbability
T@"NSDictionary",&,N,V_labelProbability
SelectedCheckboxFromIcon
NSFW Explicit
Blood
Demonstration
Destruction
Fire Devastation
Flood Devastation
Funeral
Hospital
Religious Setting
Vehicle Crash
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureIsLowConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceDetectionResult
AXMFeatureFaceID
AXMDeviceMotion
AXMFeatureDeviceOrientation
AXMFeatureCameraType
AXMFeatureModelID
AXMFeatureAesthetics
AXMFeatureUserContext
AXMFeatureCodingKeyUIClass
AXMFeatureGates
AXMCaptionMayContainSensitiveContent
AVMetadataVideoPreviewHistogramObject
classificationLocalizedValue
classificationLabel
caption
subfeatures
color info
asset metadata
Top left
Top right
Right
Center
Left
Bottom left
Bottom
Bottom right
Outside top left
Outside top
Outside top right
Outside right
Outside left
Outside bottom left
Outside bottom
Outside bottom right
centered
near.left.edge
near.top-left.edge
near.top.edge
near.top-right.edge
near.right.edge
near.bottom-right.edge
near.bottom.edge
near.bottom-left.edge
outside.left
outside.top-left
outside.top
outside.top-right
outside.right
outside.bottom-right
outside.bottom
outside.bottom-left
.implicit-subject
Document
Region
Line
Char
Diacrit
Picture
Picture:Button
Icon
Icon:Button
Container
TextField
PageControl
Checkbox:NotSelected
Checkbox:Selected
Slider
SegmentedControl
Switch:On
Switch:Off
Text:Button
TabBar:Button
Dialog
Brightness
Blur
Color
Face
RealtimeFace
Person
SceneClassification
NSFW
SignificantEventClassification
ObjectClassification
ModelClassifier
Caption
MediaLegibility
AssetMetadata
Horizon
Rectangle
AXElement
Motion
CameraMetadata
ProminentObject
IconClass
Sequence
Character
Diacritic
AXMVisionFeature<%p> %@
uiClass:%@ 
value:%@ 
face id: %lu 
Name: %@ 
[faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
Face Attributes : %@
Face location: %@
value:'%@' type:%@ 
classificationLabel:'%@' localizedName:'%@' 
classificationLabel:'%@' 
ModelID: '%@' classificationLabel:'%@' 
caption:'%@' 
value:'%.2f' 
value:'%@' 
asset info [%@] 
horizon transform. angle: %f 
deviceMotion: %@
front-facing
back-facing
camera: %@
location : %@
frame:%@ (normalized:%@) 
confidence:%.2f lowConfidence:%ld 
dictionaryRepresentation
debugRectangles
T@"NSDictionary",&,N,V_debugRectangles
overrideLabel
T@"NSString",&,N,V_overrideLabel
featureType
TQ,R,N
isBarcode
isFace
isRealtimeFace
isPerson
isSceneClassification
isObjectClassification
isNSFWClassification
isSignificantEventClassification
isBrightness
isBlur
isHorizon
isColor
isMediaLegibility
isAssetMetadata
isRectangle
isModelClassification
isCaption
isMotion
isCameraMetadata
isProminentObject
isIconClass
isImageAesthetics
isOCR
isTextDocument
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
canvasSize
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
isLowConfidence
value
isValueSpeakable
Tq,R,N,V_uiClass
barcodeType
ocrFeatureType
colorInfo
T@"AXMVisionFeatureColorInfo",R,N
assetMetadata
T@"AXMVisionFeatureAssetMetadata",R,N
blur
faceDetectionResult
T@"AXMVisionFeatureFaceDetectionResult",R,N
unpaddedDetectedFaceRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unpaddedDetectedFaceRect
horizonTransform
T{CGAffineTransform=dddddd},R,N
horizonAngle
aestheticsResult
T@"AXMVisionFeatureAestheticsResult",R,N,V_aestheticsResult
deviceMotion
T@"CMDeviceMotion",R,N,V_deviceMotion
Tq,R,N,V_deviceOrientation
cameraType
Tq,R,N,V_cameraType
TB,N,V_captionMayContainSensitiveContent
Alex
%d x %d
%.6f
Subclasses must override %@
q24@?0@"AXMDataPoint"8@"AXMDataPoint"16
dataSatisfiesInitialConditions
Td,R,N,V_error
score
Td,R,N,V_score
isDisqualified
TB,N,V_isDisqualified
bestFitParameters
T^d,R,N,V_bestFitParameters
modelParameterCount
Ti,R,N
modelFunction
T@?,R,N
partialDerivatives
iterations
Ti,R,N,V_iterations
T^d,R,N,V_x
T^d,R,N,V_y
Ti,R,N,V_n
overrideModelURL
overrideScaleMethod
genderStrategy
sceneDetector
Caption Detector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
T@"NSURL",&,N
TQ,N
effectiveModelURL
effectiveCaptionModelInfo
T@"AXImageCaptionModel",R,N
taxonomyOptions
Scene Detector
possibleSceneClassifications
_sceneClassificationRequest
T@"VNSceneClassificationRequest",&,N,S_setSceneClassificationRequest:,V__sceneClassificationRequest
TI,N,V_taxonomyOptions
VNSceneClassificationRequest
player
T@"AVAudioPlayerNode",&,N,V_player
timePitch
T@"AVAudioUnitTimePitch",&,N,V_timePitch
configChangedObserverToken
T@,&,N,V_configChangedObserverToken
activeSound
T@"AXMActiveSound",W,N,V_activeSound
soundComponent
T@"AXMSoundComponent",W,N,V_soundComponent
Tf,N,V_rate
Tf,N,V_pitch
chart.model.logarithmic
y = %@ * ln(x) + %@
datatype-%lu
AXMNodeID
AXNodeEnabled
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
title
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
nodeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
areDiagnosticsEnabled
requiresVisionFramework
enabled
TB,N,GisEnabled,V_enabled
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu>
Td,R,N,V_sampleRate
sampleBuffer
T^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}},R,N,V_sampleBuffer
length
TQ,N,V_length
currentSampleIndex
TQ,N,V_currentSampleIndex
circular
TB,N,GisCircular,V_circular
level
Td,N,V_level
effectsChain
T@"NSArray",R,N,V_effectsChain
Significant Events Detector
VN6Mb1ME89lyW3HpahkEygIG
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
Input file URL does not exist: %@
VoiceOver
scene
face
trait
prominentObjects
SignificantEvent
captions
use init()
faceDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
traitDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
prominentObjectsDetector
T@"AXMProminentObjectsDetectorNode",W,N,V_prominentObjectsDetector
captionDetector
T@"AXMCaptionDetectorNode",W,N,V_captionDetector
nsfwDetector
T@"AXMNSFWDetectorNode",W,N,V_nsfwDetector
significantEventDetector
T@"AXMSignificantEventDetectorNode",W,N,V_significantEventDetector
Trying ANE backend: %@
ANE unavailable/did not compile, falling back to MPS backend
human_body
head
aeroplane
bicycle
bird
boat
bottle
chair
dining_table
horse
motorbike
person
potted_plant
sheep
sofa
train
tv_monitor
food
drink
ERROR: Espresso returned a null context
ERROR: Espresso returned a null plan
ERROR: Espresso returned an error:
logits_pos_%ld
logits_neg_%ld
logits_%ld
offsets_%ld
logits_roll_%ld
logits_yaw_%ld
Ill-supported input size: (%d, %d) ; only (448x597) input are guaranteed correct.
ERROR: threshold cannot be 1.0
timing
Invalid input
Intermediate buffer allocation failed
ERROR: maximum image dimensions exceeded
preferredSmallSide
Tf,N,V_threshold
version
Ti,N,V_version
T@"NSString",&,N,V_text
Library/Accessibility
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
, %@
AXDateFormatter
{CGVector=dd}
AXMPointValue
AXMVectorValue
T{CGVector=dd},R,N
AXMSizeValue
AXMRectValue
AXMAffineTransformValue
<%@ %p frequency=%.2f timeOffsetMS=%.2f
Td,N,V_frequency
timeOffsetMS
Td,N,V_timeOffsetMS
Init fail -- use designated initializer
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Could not fetch uncompiled photo caption models: %@
Could not evaluate. VNDetectHorizonRequestSoft was nil
input arrays must be same length
Unhandled mapping for AXMVisionFeatureAgeCategory
Unhandled mapping for AXMVisionFeatureGenderCategory
Unhandled mapping for AXMVisionFeatureEyesCategory
Unhandled mapping for AXMVisionFeatureSmilingCategory
Unhandled mapping for AXMVisionFeatureFaceHairCategory
Unhandled mapping for AXMVisionFeatureHairColorCategory
Unhandled mapping for AXMVisionFeatureBaldCategory
Unhandled mapping for AXMVisionFeatureGlassesCategory
Could not evaluate. VNDetectFaceExpressionsRequestSoft was nil
Could not evaluate. VNClassifyFaceAttributesRequestSoft was nil
Could not evaluate. VNDetectFaceLandmarksRequestSoft was nil
Could not evaluate. VNDetectFacePoseRequestSoft was nil
Could not evaluate. VNDetectFaceRectanglesRequestSoft was nil
AXMFaceDetectorNode: no requests to evaluate
Could not evaluate. VNClassifyImageAestheticsRequestSoft was nil
AXMService being deallocated: %@
Connection to service interrupted. client: %@
Connection to service invalidated. client: %@
Failed to get service proxy: %@
Could not produce URL for soundID: %@
Could not make soundAction url does not exist: %@
Could not make sound. Action url does not exist: %@
Model Detector not available on this platform
Could not evaluate. VNImageScoreObservationSoft was nil
Could not evaluate. VNImageBrightnessObservationSoft was nil
Could not evaluate. VNImageBlurObservationSoft was nil
Could not evaluate. requestHandler was nil
Could not evaluate: %@
Need to define mlModelClasses for subclass of AXMMobileAssetEvaluationNode
Need to define an mobileAssetType for subclass of AXMMobileAssetEvaluationNode
Need to define modelResourceNames for subclass of AXMMobileAssetEvaluationNode
Need to define an minSupportedFormatVersion for subclass of AXMMobileAssetEvaluationNode
Mismatched number of model classes and resource names
Cannot modify caption for sensitive content. unexpected category: %@
Queueing remote evaluation of %@
Received remote evaluation for %@
Recived error for remote evaluation: %@
Source: %@
engine threshold priority: %ld
   node <%p> :'%@'. boosted priority:%ld
highest priority node(s): %@
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
Will not run detector '%@' due to previous error set in context: %@
With priority scheduling, there can be at most 1 evaluation node per cycle
Invoking remote result handler for error: %@
Invoking remote result handler for result
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
Current task is not nil but we're resetting it
AXMVisionEngine: event occurred: %d
AXMVisionEngine: service indicated it went invalid. clearing client-side tasks
A context must be provided
A source must be provided
AXMVisionEngine: canceling queued task to replace with newer incoming task
AXMVisionEngine: ignoring task since queue is full (maximumQueueSize = %ld)
AXMCameraFrameContext motionCorrectedNormalizedFrame received invalid input
userContext class %@ not in AXMSecureCodingClasses()
pipelineMetric accessed before being created. This will certainly lead to unexpected behavior
Could not evaluate. VNRecognizeTextRequestSoft was nil
Will not perform text detection. No effective languages resolved
Text detection error occurred: %@
Unable to convert detected text into document: %@
Will detect text with options: %@
textDetectionLocales unexpectedly empty! falling back to en-US
Could not get supported text detection languages: %@
task should not be in the completed state
Task is marked complete: %@ -> %d
taskIsBeingProcessed should be YES
taskIsBeingProcessed should be NO
Task should not be complete if being marked as complete
Could not evaluate. VNDetectRectanglesRequestSoft was nil
handleRequest: expected nil completion block
speech started: '%@'
speech finished: '%@'
didFinish: expected completion block, but found nil.
speech canceled: '%@'
didCancel: expected completion block, but found nil.
speech paused: '%@'
speech resumed: '%@'
Cannot add output '%@' to session '%@'
AXMAVCaptureSessionNode already has a AVCaptureSession attached
Capture session '%@' already has output '%@'
Error updating audio session: %@
Session interruption (%@). Resume? %d
Route Changed. Reason: %@
Media services lost
Media services reset
Should silence secondary audio (%@)
Result found for key: %p. moving to newest position
set nil result. removing key: %p. %ld items remain
set new result. adding key: %p. %ld items remain
cache size too big. evicted key: %p. %ld items remain
purge cache of all keys
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
legibility event: %@
Did time out waiting for image caption asset refresh. timeWaited:%.2f timeout:%.2f
Could not load AXImageCaptionModel at %@. error: %@
ImageCaptionAssetManager. didFinishRefreshingAssets: (%@). error: %@
ImageCaptionAssetManager. No compatible installed asset found
Failed to archive expressionsAndConfidence data: %@
Error decoding face expression dict: %@
Could not evaluate. VNClassifyNSFWImageRequestSoft was nil
AXMGeometryUtilities motionCorrectedNormalizedFrame received invalid input
failed to obtain pixel buffer from sample buffer
No matching capture devices found for scenario: %ld
AXElementDetectorNode models unavailable [%ld/%ld]
AXMLElementDetectorNode
AXMLElementDetectorNode-ScreenEquivalence
Same equivalence token - no work to do
Effective text detect languages: %@
Performing OCR: %d, %@
OCR Results: %@
OCR: %@
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
Could not evaluate. VNTranslationalImageRegistrationRequestSoft was nil
Could not evaluate. VNImageTranslationAlignmentObservationSoft was nil
Could not create CGDataProviderRef for URL: %@
Error compiling pattern '%@' : %@
Error creating data detector: %@
input text: %@
will enumerate tags for scheme: %@. options: all
  %@ -> %@
  WARNING: Unhandled NLToken: %@ -> %@
  WARNING: Unhandled Data Detector: %@ -> %@
remaining:[%ld %ld] word:%ld lexicon:%ld whitespace:%ld
semanticallyComplete:%ld speechText: '%@'
lex #%ld: '%@' flags:%lu prob:%.2f partialProb:%.2f usageCount:%u
Could not evaluate. VNCreateSceneprintRequestSoft was nil
Did get KVO update for key: '%@'. change: %@
AXMDisplayManager initialized: %@
Unable to look up screenInfo
Unable to look up screen scale
Unexpected physical screen orientation
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
Will process text: '%s'. locales: %@
Text being marked as unspeakable becuase of tag: '%@'
Text being marked as unspeakable becuase no lexicon exists for locale: %@
Result text: '%s
Will pre-process text: '%s'
Pre-processed text: '%s'
AX: Export Session status: %ld %@
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
Error retrieving caption: %@
Error setting caption: %@
unknown file type: UTI: %@, extension: %@
Could not evaluate. VNGenerateAttentionBasedSaliencyImageRequestSoft was nil
Input text: '%@'
Input locale: '%@'
Token: '%@' [%lu, %lu] Type: '%@' Class: '%@' Lang: '%@' Script: '%@' Entity: '%@' Subtoken: '%@'
Could not evaluate. VNProcessingDeviceSoft was nil
Error decoding face landmark dict: %@
Failed to archive face landmark results: %@
Could not de-activate audio session: %@
Could not activate audio session: %@
Ignoring dispatch request. Output manager not ready
Using languages for spell checking: %s
spell-checking pass %ld of %ld
length of textToCheck is 0. break
Will look for misspelled word in text: '%s'. index: %ld
No misspelled words found. break
Misspelled word found at range [%ld, %ld], '%s'
replacing with correction: '%s' at range:[%ld %ld]
text after replacement: '%s'
No correction found
Source node not connected to any engine
Error: unhandled AVMetadataObject %@
Error decoding subfeatures array: %@
Failed to archive subfeature data: %@
Error: %@
Caption Detection not available
Could not evaluate. VNSceneClassificationRequestSoft was nil
Error starting audio engine: %@
Unexpected state change. from %@. to %@
Could not handle audio request: %@. Error:%@
Could not begin active sound playback: %@
One-shot sound player did finish playing sound
Could not start engine: %@
Subclass should override
Could not evaluate. VNClassifySignificantEventRequestSoft was nil
Failed to create AXMediaUtilities working directory at path: %@. error: %@
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/UIKit.framework/UIKit
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
AXMLexiconManager
UnitTesting
Clickability__generated__Input
MLFeatureProvider
Clickability__generated__Output
Clickability__generated__
AXMScreenGrabber
AXMAssetManager
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMVisionFeatureFaceAttributes
AXVNEspressoDetectedObject
AXMSinglePitchTone
AXMFaceDetectorNode
AXMImageAestheticsNode
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMOutputRequest
AXMOutputRequestHandle
AXMDataRegressionModelExponential
AXMSpeechFormatter
AXMSpeechBlockFormatter
AXShotflowFaceDetection
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMMobileAssetEvaluationNode
AXMDescriptionBuilder
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMTaskDispatcherDelegate
AXMServiceDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMLanguage
AXMCameraFrameContext
AXMFunctionTone
AXMPhoneNumberSpeechFormatter
AXMVisionPipelineContext
AXMTextDetectorNode
AXMTaggedText
AXMIconVisionEngine
AXMTaskDispatcher
AXMTask
AXElementVision__generated__Input
AXElementVision__generated__Output
AXElementVision__generated__
AXMADSREnvelope
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAudioDataSourceMixer
AXMAVCaptureSessionNode
AVCaptureVideoDataOutputSampleBufferDelegate
AXMAVCaptureSessionNodeFrameDelegate
AXMTag
AXMReplacementTag
AXMAudioSession
AXMOutputComponent
AXMVisionResult
AXMVisionEngineLookupConvenience
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMImageCaptionModelAssetManager
AXAssetControllerObserver
AXMVisionFeatureFaceDetectionResult
AXShotflowDetector
AXMDataDetector
AXMTaxonomyNode
AXMPhotoVisionSupport
AXMNSFWDetectorNode
AXMGeometryUtilities
AXMAVUtilities
AXMCaptureManager
AXMExtras
AXMCaptureSettings
DeviceDiscovery
VisionEngine
_AXMCaptureManagerDetectionEngine
AXMCaptureManagerVideoFrameObserver
AXMSequenceRequestManager
Prediction
AXMAXElementDetectorNode
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMTextLayoutManager
AXMImageRegistrationNode
AXMCameraMetadataNode
AXMCaptureVideoDataOutput
AXMCompressor
AXMOutputAction
AXMSpeechOutputAction
AXMSoundOutputAction
AXMOneShotSoundOutputAction
AXMActiveSoundOutputAction
AXMOutputActionHandle
AXMActiveSoundOutputActionHandle
AXMPipelineContextInput
AXMIconClassDetectorNode
AXMSemanticText
AXMSemanticTextFactory
_AXMSemanticTextCursor
AXMPixelBufferWrapper
AXMSceneprintBasedNode
AXMAssetMetadataNode
AXMDataSonifier
iconclassification__generated__Input
iconclassification__generated__Output
iconclassification__generated__
_AXMSettingObserver
AXMSettings
AXMVisionFeatureAssetMetadata
AXMVisionFeatureAestheticsResult
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMDataRegressionModelPower
AXMDataSummary
AXMTextProcessor
AXMCoreMotionNode
AXMLiveContinuousTone
AXShotflowHelpers
AXMDataRegressionModelSine
AXMProminentObjectsDetectorNode
AXMBarcodeNode
AXMTagger
AXMEvaluationNode
AXMAXElementVisionEngine
AXMAudioEffect
AXANFDDetectedObject
AXMEmailAddressSpeechFormatter
AXMVisionFeatureFaceLandmarks
AXMTextDetectionOptions
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMSpellChecker
AXMTone
AXMDataRegressionModelLinear
AXMSourceNode
SelectedCheckboxFromIcon__generated__Input
SelectedCheckboxFromIcon__generated__Output
SelectedCheckboxFromIcon__generated__
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
AXMDataPoint
AXMDataRegressionModel
AXMCaptionDetectorNode
AXMSceneDetectorNode
AXMActiveSound
AXMSoundComponent
AXMActiveSoundOutputActionHandleImpl
AXMActiveSoundOutputActionHandleProvider
AXMDataRegressionModelLogarithmic
AXMSpeechFormatterCache
AXMVisionEngineNode
AXMAudioDataSource
AXMSignificantEventDetectorNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXShotflowNetwork
AXMText
AXMGeomerty
KeyPitch
AXMVariablePitchTone
init
dictionary
_lexiconForLocale:metrics:
currentLocale
objectForKey:
languageCode
localeIdentifier
dictionaryWithObjects:forKeys:count:
stringWithFormat:
measure:tryExecute:
setObject:forKey:
lexiconExistsForLocale:metrics:
textExistsInLexicon:withLocale:metrics:
.cxx_destruct
_cachedLexicons
_opaqueLexiconForLocale:metrics:
setWithArray:
isEqualToString:
featureValueWithString:
featureValueWithDouble:
featureValueForName:
featureNames
initWithUIType:x:y:w:h:wordCount:charCount:
UIType
setUIType:
setX:
setY:
setW:
setH:
wordCount
setWordCount:
charCount
setCharCount:
_UIType
_wordCount
_charCount
featureValueWithDictionary:error:
initWithLabelWithUIType:labelWithUITypeProbability:
labelWithUIType
setLabelWithUIType:
labelWithUITypeProbability
setLabelWithUITypeProbability:
_labelWithUIType
_labelWithUITypeProbability
bundleForClass:
pathForResource:ofType:
fileURLWithPath:
urlOfModelInThisBundle
initWithContentsOfURL:error:
modelWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
modelWithContentsOfURL:configuration:error:
predictionFromFeatures:options:error:
stringValue
dictionaryValue
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
count
arrayWithCapacity:
featuresAtIndex:
addObject:
initWithConfiguration:error:
predictionFromUIType:x:y:w:h:wordCount:charCount:error:
predictionsFromInputs:options:error:
model
_model
startMeasure:
endMeasurement
grabScreenWithRect:orientation:options:metrics:error:
URLByAppendingPathComponent:
_modelsDirectoryForType:compiled:
_photoCaptionAssetsDirectory
_modelAssetURLsOfType:sources:compiled:
array
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
countByEnumeratingWithState:objects:count:
pathExtension
URLByDeletingPathExtension
lastPathComponent
_modelAssetNamesOfType:sources:compiled:
_modelAssetURLForModelNamed:ofType:sources:compiled:
_uncompiledModelsDirectoryForType:
_compiledModelsDirectoryForType:
compiledModelAssetURLsOfType:sources:
uncompiledModelAssetURLsOfType:sources:
compiledModelAssetNamesOfType:sources:
uncompiledModelAssetNamesOfType:sources:
compiledModelAssetURLForModelNamed:ofType:sources:
uncompiledModelAssetURLForModelNamed:ofType:sources:
modelWithName:ofType:sources:compileIfNeeded:persistCompiledModel:error:
nodeInitialize
initWithCoder:
encodeWithCoder:
validateVisionKitSoftLinkSymbols
evaluate:metrics:
_detectHorizonRequest
_setDetectHorizonRequest:
arrayWithObjects:count:
evaluateRequests:withContext:requestHandlerOptions:metrics:error:
results
firstObject
size
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
title
requiresVisionFramework
__detectHorizonRequest
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
ageCategory
label
identifier
_AXMAgeCategoryForVisionCategoryIdentifier:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
_AXMGenderCategoryForVisionCategoryIdentifier:
eyesCategory
_AXMEyesCategoryForVisionCategoryIdentifier:
smilingCategory
_AXMSmilingCategoryForVisionCategoryIdentifier:
faceHairCategory
_AXMFaceHairCategoryForVisionCategoryIdentifier:
hairColorCategory
_AXMHairColorCategoryForVisionCategoryIdentifier:
baldCategory
_AXMBaldCategoryForVisionCategoryIdentifier:
glassesCategory
_AXMGlassesCategoryForVisionCategoryIdentifier:
encodeInteger:forKey:
genderCategory
decodeIntegerForKey:
objectForKeyedSubscript:
integerValue
bundleWithIdentifier:
localizedStringForKey:value:table:
_accessibilityLabelForAgeCategory
_accessibilityLabelForSmilingCategory
_accessibilityLabelForFaceHairCategory
_accessibilityLabelForHairColorCategory
_accessibilityLabelForBaldCategory
_accessibilityLabelForGlassesCategory
string
appendString:
unitTestingFaceAttributes
initWithVisionFaceAttributes:
initWithAVMetadataFaceObject:
_accessibilityLabelForEyesCategory
accessibilityLabelForAttributes
setResults:
_ageCategory
_genderCategory
_eyesCategory
_smilingCategory
_faceHairCategory
_hairColorCategory
_baldCategory
_glassesCategory
_results
bounds
initWithObjectType:boundingBox:confidence:
center
objectType
setObjectType:
setBounds:
confidence
setConfidence:
_bounds
_confidence
_objectType
initWithFrequency:sampleRate:envelope:
initWithSampleRate:envelope:
_setFrequency:
envelope
lengthMS
sampleRate
_rawValueForTonePhase:
levelForTime:
gain
frequency
renderInBuffer:atFrame:
analysisOptions
detectFaceAttributes
_faceAttributesRequest
set_faceAttributesRequest:
detectFaceExpressions
_faceExpressionsRequest
set_faceExpressionsRequest:
detectFaceLandmarks
_faceLandmarksRequest
set_faceLandmarksRequest:
detectFacePose
_facePoseRequest
set_facePoseRequest:
detectFaceRectangles
_faceRectanglesRequest
set_faceRectanglesRequest:
uuid
_faceResultForUUID:inFaceDictionary:
faceId
setFaceId:
setUuid:
boundingBox
setFrame:
setRectanglesConfidence:
faceAttributes
setAttributes:
setAttributesConfidence:
expressionsAndConfidence
setExpressionsAndConfidence:
landmarks
initWithVisionFaceLandmarks:
setLandmarks:
landmarks3d
setLandmarks3d:
setLandmarksConfidence:
pose
setPose:
setPoseConfidence:
enumerateObjectsUsingBlock:
_createRequestsForContext:
_faceDetectionResultsForVisionRequests:canvasSize:
featureWithFaceDetectionResult:canvasSize:
enumerateKeysAndObjectsUsingBlock:
addEvaluatedFeatureType:
UUIDString
setObject:forKeyedSubscript:
_faceprintRequest
set_faceprintRequest:
__faceRectanglesRequest
__faceprintRequest
__faceAttributesRequest
__faceExpressionsRequest
__faceLandmarksRequest
__facePoseRequest
_imageAestheticsRequest
set_imageAestheticsRequest:
configureForRunningOnANEIfPossibleWithRequest:
featureWithImageAestheticsObservation:
__imageAestheticsRequest
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
delegate
axMediaUtilitiesService:eventOccurred:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
setDelegate:
setXpcConnection:
_xpcConnectionQueue
_delegate
_xpcConnection
initWithString:
copy
actions
predicateWithBlock:
filteredArrayUsingPredicate:
handle
addActionHandle:
initWithText:
_addAction:
initWithSoundID:
initWithURL:
speechItemSeparator
speechActions
oneShotSoundActions
activeSoundActions
addSpeechItem:
addSoundItemWithID:
addSoundItemWithURL:
addActiveSoundItemWithID:
addActiveSoundItemWithURL:
completionBlock
setCompletionBlock:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_handle
_queue
_queue_actions
_interruptsAndClearsQueue
_completionBlock
actionHandles
_actionHandles
setUsesSignificantDigits:
setMaximumSignificantDigits:
numberWithDouble:
stringFromNumber:
modelDescription
modelFunction
modelParameterCount
getInitialParams:
partialDerivatives
modelFunctionStringForParameters:significantFigures:
dataSatisfiesInitialConditions
speechStringForObjectValue:
stringForObjectValue:
getObjectValue:forString:errorDescription:
initWithFormattingBlock:
formattingBlock
setFormattingBlock:
_formattingBlock
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasPose:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasPose:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:mergesCount:hasPose:hasLabel:label:labelName:
boxCenter
defaultBox
distanceToDefaultBox
mergesCount
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasPose:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasPose:hasLabel:label:
initWithBox:defaultBox:confidence:scale:rotationAngle:yawAngle:hasPose:hasLabel:label:labelName:
smartDistance
overlap:
iOa:
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
setBox:
setDefaultBox:
setMergesCount:
scale
setScale:
rotationAngle
setRotationAngle:
yawAngle
setYawAngle:
hasPose
setHasPose:
hasLabel
setHasLabel:
setLabel:
labelName
setLabelName:
_area
_hasPose
_hasLabel
_mergesCount
_scale
_rotationAngle
_yawAngle
_label
_labelName
_box
_defaultBox
decodeObjectForKey:
path
preloadModelIfNeeded:
modelURL
setModelURL:
modelIdentifier
_modelURL
_modelIdentifier
setShouldProcessRemotely:
AXMRectValue
ignoredLayerContextIDs
includedLayerContextIDs
preserveInputImageSize
screenGrabber
pipelineMetric
inputWithCIImage:
produceImage:
defaultOptions
axmValueWithCGRect:
numberWithInteger:
areDiagnosticsEnabled
numberWithBool:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
shouldEvaluateColorInformation
_evaluateColorInformation:
visionImageRequestHandler
performRequests:error:
_blurValueForVisionObservation:
featureWithVisionRequest:blurValue:canvasSize:
brightness
numberWithFloat:
exposureScore
blurMeasure
blurScore
_brightnessValueForVisionObservation:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
initWithIdentifier:
_downloadAssetsIfNecessary
modelURLs
removeAllObjects
addObjectsFromArray:
modelResourceNames
mlModelClasses
mobileAssetType
initWithType:
returnTypes:
setDoNotBlockBeforeFirstUnlock:
attributes
unsignedIntegerValue
minSupportedFormatVersion
maxSupportedFormatVersion
ax_filteredArrayUsingBlock:
compare:
sortedArrayUsingComparator:
lastObject
logAsset
state
startDownload:
getLocalFileUrl
setModelURLs:
subarrayWithRange:
purge:
startCatalogDownload:then:
queryMetaData:
mlModels
mobileAssetBaseURL
_mlModels
_mobileAssetBaseURL
_initWithOptions:
classificationLocalizedValue
classificationLabel
addDetectedClassificationLocalizedValue:forLabel:
length
isLowConfidence
isNSFW
_shouldReplaceCaptionWithGenericTemplate
_addGenericTemplateForCaptionInformationToDescription:
_addCaptionInformationToDescription:
_addBrightnessInformationToDescription:
_addBlurInformationToDescription:
_addFaceInformationToDescription:
_addClassificationInformationToDescription:
_addIconClassInformationToDescription:
buildSpeakableDescription
hasSuffix:
_stringForPauseType:
appendFormat:
_appendPauseType:toDescriptionIfNeeded:
_appendToDescription:afterPauseType:withContents:
blur
faceDetectionResult
name
sortUsingComparator:
localizedStringWithFormat:
likelyExpression
numberWithLong:
allKeys
localizedStringFormatterForExpression:
caption
shouldModifyCaptionForSensitiveContent
primarySensitiveContentFeature
containsString:
stringByAppendingString:
dictionaryWithContentsOfFile:
_templateRulesForTag:
boolValue
doubleValue
_subsumedTagsForTags:
_ignoredTagsForTags:
containsObject:
characterSetWithCharactersInString:
objectAtIndex:
lowercaseString
rangeOfCharacterFromSet:
allObjects
axm_featureWithHighestConfidence
value
builderWithOptions:
addDetectedFaces:
addDetectedClassificationFeatures:
setDetectedCaption:
addDetectedIconClasses:
buildVisualDescription
blurFeature
setBlurFeature:
brightnessFeature
setBrightnessFeature:
setIsNSFW:
setShouldModifyCaptionForSensitiveContent:
setPrimarySensitiveContentFeature:
_builderOptions
_speakableDescription
_visualDescription
_faceFeatures
_classificationLabelsToLocValuesMap
_iconClassFeatures
_captionFeature
_isNSFW
_shouldModifyCaptionForSensitiveContent
_blurFeature
_brightnessFeature
_primarySensitiveContentFeature
_commonInit
setIdentifier:
setAxMediaUtilsService:
axMediaUtilsService
initWithIdentifier:delegate:
setTaskDispatcher:
setSequenceRequestManager:
isEqualToEngine:
sourceNodes
evaluationNodes
archivedDataWithRootObject:requiringSecureCoding:error:
unarchivedObjectOfClass:fromData:error:
decodeObjectOfClass:forKey:
setMaximumQueueSize:
decodeBoolForKey:
setDiagnosticsEnabled:
setPrioritySchedulingEnabled:
setPrioritySchedulingAllowMultipleNodeExecution:
setThresholdPriority:
addSourceNode:
addEvaluationNode:
maximumQueueSize
encodeBool:forKey:
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
isCachingEnabled
cacheKey
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectNSFW
detectSignificantEvents
detectModelClassifications
detectCaptions
detectFaces
detectTraits
detectHorizon
detectRectangles
detectProminentObjects
detectIconClass
detectAXElements
detectAesthetics
isEnabled
_queue_shouldEvaluateNode:withOptions:
boostEffectivePriority
effectivePriority
resetEffectivePriority
features
detectedFeatureDescription
detectedTextDescription
error
measure:execute:
sourceProvidesResults
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:prioritySchedulingAllowMultipleNodeExecution:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
setEvaluationExclusivelyUsesVisionFramework:
imageRegistrationFilteringEnabled
imageRegistrationState
minimumImageRegistrationSignalLevel
auxiliaryDetectors
removeAllAuxiliaryDetectors
result
disableResultLogging
_queue_logEvaluatedResult:
didFinishProcessingContext
cache
setResult:forKey:
resultHandlers
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
axmAppendRecursiveDescription:withIndentation:
source
context
sequenceRequestManager
addResultHandlers:
_queue_shouldContinueWithoutResultHandlers:
willBeginProcessingContext
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
taskDispatcher
unscheduleAllTasks
scheduleTask:
_invokeFullQueueResultHandlersForContext:
itemWithSource:context:
shouldCallCompletionHandlersForEngineBusyError
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
diagnosticsEnabled:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
dispatcher:handleTask:
copyWithZone:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
addSourceNodes:evaluationNodes:
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
setImageRegistrationFilteringEnabled:
setMinimumImageRegistrationSignalLevel:
setDisableResultLogging:
_queue_sourceNodes
_queue_evaluationNodes
_queue_imageRegistrationNode
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_prioritySchedulingEnabled
_prioritySchedulingAllowMultipleNodeExecution
_imageRegistrationFilteringEnabled
_diagnosticsEnabled
_disableResultLogging
_identifier
_maximumQueueSize
_thresholdPriority
_minimumImageRegistrationSignalLevel
_cache
_axMediaUtilsService
_taskDispatcher
_sequenceRequestManager
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
sortedFeatures
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
_updateDefaultLanguages
mainQueue
addObserverForName:object:queue:usingBlock:
autoupdatingCurrentLocale
initWithLocale:
preferredLanguages
initWithLanguageCode:
isSupertypeOfLanguage:
isSubtypeOfLanguage:
uppercaseString
stringByAppendingFormat:
primaryComponent
secondaryComponent
localizedStringForLanguageCode:
locale
isEqualToAXMLanguage:
setPrimaryComponent:
setSecondaryComponent:
setLanguageCode:
setLocale:
initialize
currentSystemLanguage
currentLocaleLanguage
languageCodesForLanguages:
languageInSet:isSupertypeOfLanguage:
languageInSet:isSubtypeOfLanguage:
languageDisplayName
_primaryComponent
_secondaryComponent
_languageCode
_locale
letterCharacterSet
invertedSet
componentsSeparatedByCharactersInSet:
initWithLocaleIdentifier:
decodeFloatForKey:
decodeDoubleForKey:
videoFieldOfView
encodeFloat:forKey:
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
encodeDouble:forKey:
deviceAttitude
motionCorrectedNormalizedFrame:fromAttitude:fromFieldOfViewX:fromFieldOfViewY:toAttitude:toFieldOfViewX:toFieldOfViewY:interfaceOrientation:mirrored:
initWithVideoFieldOfView:zoomFactor:sourceWidth:sourceHeight:presentationTimestamp:attitude:
motionCorrectedNormalizedFrame:targetAttitude:targetZoomFactor:interfaceOrientation:mirrored:
_videoFieldOfView
_videoZoomFactor
_videoSourceWidth
_videoSourceHeight
_presentationTimestamp
_deviceAttitude
_xAxisValueForNormalizedPosition:
initWithUnivariateFunction:sampleRate:envelope:xAxisDescriptor:yAxisDescriptor:
function
xAxisDescriptor
yAxisDescriptor
_function
_xAxisDescriptor
_yAxisDescriptor
whitespaceAndNewlineCharacterSet
addCharactersInString:
enumerateSubstringsInRange:options:usingBlock:
_groupSeperatorCharacterSet
initWithSourceParameters:options:
setAnalysisOptions:
_commonInitWithDiagnosticsEnabled:
timeIntervalSinceReferenceDate
initWithName:measurementsEnabled:orEnabledByEnvironmentVariables:
setAppliedImageOrientation:
metricSession
measurementsEnabled
evaluatedFeatureTypes
appliedImageOrientation
userContext
effectiveTextDetectionLocales
inputType
ciImage
initWithCIImage:options:
pixelBuffer
orientation
initWithCVPixelBuffer:orientation:options:
initWithURL:options:
_makeRequestHandlerForInput:options:
errorOccurred:
setUserContext:
featureType
numberWithUnsignedInteger:
addFeatureGate:userInfo:
setEquivalenceToken:
_init
setFeatures:
setEffectiveTextDetectionLocales:
setEvaluatedFeatureTypes:
setMetricSession:
setImageRegistrationState:
includeImageInResult
generateImageRepresentation
setImage:
setError:
numberWithUnsignedInt:
imageWithCVPixelBuffer:options:
imageWithContentsOfURL:
orderedSet
generateReport
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
createSceneObservationIfNilWithBlock:
sceneObservation
_addSignificantEventFeatureGateIfNeededToFeature:category:minimumConfidence:
generateFileNameForImageWithPrefix:extension:
sourceInput
addAuxiliaryDetector:
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
evaluationExclusivelyUsesVisionFramework
sequenceID
setSequenceID:
setResult:
setVisionImageRequestHandler:
_sourceInput
_sourceParameters
_sourceProvidesOwnResults
_resultHandlers
_piplelineMetric
_sceneObservation
_sceneObservationQueue
_auxiliaryDetectors
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_effectiveTextDetectionLocales
_imageRegistrationState
_userContext
_cacheKey
_sequenceID
_metricSession
_features
_evaluatedFeatureTypes
_result
_appliedImageOrientation
_visionImageRequestHandler
recognitionLevelFromOptions:
textDetectionLanguagesFromOptions:
supportedDetectionLanguagesForLevel:
filterPreferredDetectionLanguages:withSupportedDetectionLanguages:
_textDetectionOptions:
effectiveLanguagesFromOptions:
setRecognitionLanguages:
setRecognitionLevel:
usesLanguageCorrection
setUsesLanguageCorrection:
normalizedMinimumTextHeightRatio
setMinimumTextHeight:
ax_mappedArrayUsingBlock:
textLayoutManager
_textsForObservations:
documentWithTextItems:canvasSize:preferredLocales:applySemanticAnalysis:error:
semanticTextFactory
initWithSemanticTextFactory:
topCandidates:
setText:
setBoundingBox:
textDetectionOptions
recognitionLevel
textDetectionLocales
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
baseLanguageFromLanguage:
setSemanticTextFactory:
setTextLayoutManager:
_semanticTextFactory
_textLayoutManager
beginEditing
addAttribute:value:range:
originalText
replaceCharactersInRange:withString:
endEditing
_evaluateIfNeeded
hasGlobalTag:
addGlobalTag:
removeGlobalTag:
_stringRange
attribute:atIndex:longestEffectiveRange:inRange:
speakableText
enumerateAttributesInRange:options:usingBlock:
_isEvaluated
substringWithRange:
isSpeakable
initWithFormat:
_substringWithRange:
attributesAtIndex:effectiveRange:
_initWithAttributedString:
initWithString:attributes:
mutableCopy
mutableString
setAttributes:range:
textWithString:locale:evaluationBlock:
addReplacementTag:withToken:range:
addTag:withToken:range:
setSpeakable:
isRangeSpeakable:
_setNeedEvaluation
initWithAttributedString:
_attrString
_globalAttributes
_evaluationBlock
setImageNode:
setIconClassDetector:
imageWithData:
setDetectIconClass:
imageNode
triggerWithImage:options:cacheKey:resultHandler:
sharedInstance
classifyImages:withTimeout:
iconClassDetector
_imageNode
_iconClassDetector
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
featureValueWithPixelBuffer:
initWithImage:iouThreshold:confidenceThreshold:
image
iouThreshold
setIouThreshold:
confidenceThreshold
setConfidenceThreshold:
_image
_iouThreshold
_confidenceThreshold
featureValueWithMultiArray:
initWithConfidence:coordinates:
coordinates
setCoordinates:
_coordinates
multiArrayValue
predictionFromImage:iouThreshold:confidenceThreshold:error:
initWithAttackDuration:attackLevel:decayDuration:sustainDuration:sustainLevel:releaseDuration:
attackMS
decayMS
sustainMS
releaseMS
attackLevel
sustainLevel
defaultEnvelope
setAttackMS:
setAttackLevel:
setDecayMS:
setSustainMS:
setSustainLevel:
setReleaseMS:
_attackMS
_attackLevel
_decayMS
_sustainMS
_sustainLevel
_releaseMS
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
axmDecodePointForKey:
cameraPixelFocalLength
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
maximumNumberOfRects
dataWithBytes:length:
minimumConfidence
setMaximumObservations:
featureWithVisionRequest:rectangleResult:canvasSize:
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
_getHue:saturation:brightness:
_getRed:green:blue:
colorWithHue:saturation:brightness:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
setSynthesizer:
synthesizer
text
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
attributedSpeechString
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:
handleRequest:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
initWithName:sampleRate:circular:
currentSampleIndex
isCircular
setCurrentSampleIndex:
dataSources
setWithSet:
processEffects:
sampleBuffer
level
isMonoOutput
panning
addDataSource:
removeDataSource:
removeAllDataSources
prepareNextSamples:
setName:
setPanning:
setDataSources:
_name
_panning
_dataSources
raise:format:
setCaptureSessionNodeDelegate:
beginFrameEventsWithAVCaptureSession:delegate:queue:
setAutomaticallyConfiguresOutputBufferDimensions:
setDeliversPreviewSizedOutputBuffers:
axVideoDataOutput
setSampleBufferDelegate:queue:
canAddOutput:
addOutput:
setCaptureSession:
captureSession
setFrameDelegate:
outputs
addVideoDataOutputWithAVCaptureSession:queue:
endVideoFrameEvents
removeOutput:
frameDelegate
captureSessionNode:didOutputSampleBuffer:fromConnection:
wrapperWithPixelBuffer:orientation:
inputWithPixelBuffer:
captureSessionNodeDelegate
interfaceOrientationForCaptureSessionNode:
videoDeviceFromConnection:
isMirroredVideoDevice:
triggerWithSampleBuffer:interfaceOrientation:mirrored:options:userContext:
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:didDropSampleBuffer:fromConnection:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
endAutoTriggerOfVideoFrameEvents
setAxVideoDataOutput:
_autotrigger_queue
_axVideoDataOutput
_captureSessionNodeDelegate
_frameDelegate
_captureSession
_debugType
range
isPhoneNumber
isDate
isEmailAddress
phoneNumber
initWithNLToken:text:type:lexicalClass:language:script:namedEntity:derivedSubtoken:speechFormatter:
initWithdatatype:text:textCheckingResult:speechFormatter:
isPunctuation
isWhitespace
isSentenceTerminator
isOpenQuote
isCloseQuote
_originalText
_speechFormatter
_nlToken
_nlType
_nlLexicalClass
_nlLanguage
_nlScript
_nlNamedEntity
_nlDerivedSubtoken
_datatype
_textCheckingResult
replacementTagWithSpeakableText:range:
_overrideSpeakableText
_overrideRange
setNotificationObserverTokens:
auxiliarySession
setSession:
notificationObserverTokens
userInfo
_handleSessionInterrupted:options:
_handleRouteChanged:previousRoute:
_handleMediaServicesLost
_handleMediaServicesReset
_handleSilenceSecondaryAudio:
removeObserver:
session
setActive:error:
setCategory:withOptions:error:
_stringForRouteChangeReason:
deactivateSessionWithError:
activateSessionWithError:
_notificationObserverTokens
_session
setComponentState:
transitionToState:completion:
componentState
_componentState
resultWithImage:features:orientation:metricSession:userContext:
isEqualToAXMVisionResult:
normalizedFrame
ocrFeatures
isTextDocument
isValueSpeakable
localeWithLocaleIdentifier:
detectedFeatureDescriptionWithOptions:
faceFeatures
sceneClassificationFeatures
objectClassificationFeatures
captionFeatures
includesNSFWFeatures
sensitiveContentForCaptionFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
setDetectedTextDescription:
equivalenceToken
featureGates
addEntriesFromDictionary:
resultWithImage:features:orientation:metricSession:
colorInfoFeature
assetMetadataFeature
detectedTextLanguage
localizedDetectedTextHint
localizedSensitiveContentWarning
localizedDetectedIconHint
_equivalenceToken
_detectedTextDescription
isFace
isSceneClassification
isObjectClassification
isCaption
isNSFWClassification
isModelClassification
isOCR
isBlur
isBrightness
isIconClass
captionMayContainSensitiveContent
modelClassificationFeatures
sensitiveContentFeatures
axm_featuresSortedByConfidence
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
removeObjectForKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
setTargetPlayerItem:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
_avkit_queue
_triggeringLegibilityEvents
_targetPlayerItem
policy
assetControllerWithPolicy:
addObserver:
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:
_performWithLock:
dataWithContentsOfURL:options:error:
JSONObjectWithData:options:error:
initWithModelProperties:
newsestCompatibleImageCaptionModelAssetFromAssets:withStage:language:isInstalled:isDownloadable:
localURL
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
modelURLWithTimeout:
infoForModelAtURL:
_lock
_didTryWaitingForAssetLookup
_assetController
frame
axmEncodeRect:forKey:
rectanglesConfidence
nameConfidence
attributesConfidence
landmarksConfidence
poseConfidence
axmDecodeRectForKey:
setNameConfidence:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
getBytes:length:
descriptionForExpression:
_expressionForString:
nameForFaceExpression:
confidenceForExpression:
_likelyExpression
_uuid
_faceId
_rectanglesConfidence
_nameConfidence
_attributes
_attributesConfidence
_expressionsAndConfidence
_landmarks
_landmarks3d
_landmarksConfidence
_poseConfidence
_frame
_pose
cpuNetworkWithModelPath:threshold:version:
initWithNetwork:filterThreshold:
gpuNetworkWithModelPath:threshold:preferredMetalDeviceID:version:
threshold
setThreshold:
nmsThreshold
sortDescriptorWithKey:ascending:
sortedArrayUsingDescriptors:
osfsThreshold
osfsSizeRatio
mergeHeadsThreshold
olmcsThreshold
olmcsMergeCountDelta
smartThreshold
smartDistanceFactor
version
processCIImage:
nmsBoxes:
filterBoxes:
enforceSquareFaces:withHeight:andWidth:
mergeHeadsBoxes:
cpuDetectorWithModelPath:networkThreshold:filterThreshold:version:
gpuDetectorWithModelPath:networkThreshold:filterThreshold:preferredMetalDeviceID:version:
overlappingSmallFacesSuppression:
overlappingLowMergeCountSuppression:
mergeBoxes:
smartMergeBoxes:
detect:
processBoxes:withHeight:andWidth:
overlap_threshold
setOverlap_threshold:
filterThreshold
setFilterThreshold:
setNmsThreshold:
setMergeHeadsThreshold:
setOsfsThreshold:
setOsfsSizeRatio:
setOlmcsThreshold:
setOlmcsMergeCountDelta:
setSmartThreshold:
setSmartDistanceFactor:
_network
_overlap_threshold
_nmsThreshold
_mergeHeadsThreshold
_osfsThreshold
_osfsSizeRatio
_olmcsThreshold
_olmcsMergeCountDelta
_smartThreshold
_smartDistanceFactor
_filterThreshold
_enumerateText:textCheckingType:datatype:withBlock:
emailAddressRegex
_enumerateText:regularExpression:datatype:withBlock:
speechFormatterForDatatype:
enumerateMatchesInString:options:range:usingBlock:
dataDetectorWithTypes:error:
regularExpressionWithPattern:options:error:
initWithSpeechFormatterCache:
enumerateText:searchingFordatatypes:withBlock:
_emailAddressRegex
_speechFormatterCache
buildTaxonomyDescription
buildParentChainDescriptionForAllNodes
buildGraphStatisticsDescription
leafNodeLabels
nonLeafNodeLabels
processSceneClassifications:withOptions:
localizedLabelForClassificationObservation:
processInfo
physicalMemory
addNSFWResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
nsfwClassificationWithCategory:confidence:canvasSize:
setCaptionMayContainSensitiveContent:
_request
multiplyByInverseOfAttitude:
quaternion
inputPorts
input
device
position
formatDescription
videoDimensionsForDeviceFormat:
initWithCaptureSession:
beginConfiguration
commitConfiguration
isRunning
startRunning
stopRunning
idealCaptureSettingsForScenario:
captureDevice
captureFormat
deviceInputWithDevice:error:
canAddInput:
connectionWithMediaType:
setEnabled:
setSessionPreset:
removeInput:
addInput:
lockForConfiguration:
setActiveFormat:
unlockForConfiguration
_configureSessionWithBlock:error:
weakObjectsHashTable
captureManager:didOutputPixelBuffer:
captureSessionReport:
startSessionIfNeeded
stopSession
configureForScenario:error:
addVideoFrameObserver:
removeVideoFrameObserver:
addFeatureDetectionObserver:
removeFeatureDetectionObserver:
activeScenario
deviceOrientation
setDeviceOrientation:
_captureDevice
_captureDeviceInput
_videoDataOutput
_videoFrameReceiveQueue
_activeScenario
_videoFrameObservers
_detectionEngine
_featureDetectionObservers
_observerLock
_deviceOrientation
axm_totalResolutionPixels
setCaptureDevice:
setCaptureFormat:
_captureFormat
_minimumAcceptableFramerateForScenario:
_maximumAcceptableFramerateForScenario:
_minimumAcceptableResolutionForScenario:
_maximumAcceptableResolutionForScenario:
_pixelFormatForScenario:
discoverySessionWithDeviceTypes:mediaType:position:
devices
formats
videoSupportedFrameRateRanges
maxFrameRate
_filteredDevicesAndFormatsForScenario:
_preferredFormatForFormats:
deviceType
printAllVideoDevices
initWithCaptureManager:options:
beginLiveDetectionWithOptions:
endLiveDetection
setTaxonomyOptions:
captureManager:didOutputDetection:
triggerWithPixelBuffer:exifOrientation:options:cacheKey:resultHandler:
_captureManager
_visionEngine
_sceneDetector
_faceDetector
sequenceRequestHandler
setSequenceRequestHandler:
_sequenceRequestHandler
uiClass
setUiClass:
_uiClass
_boundingBox
modelForMLModel:error:
_evaluateANOD:
emptyImage
rectValue
imageByCroppingToRect:
extent
dataWithLength:
mutableBytes
render:toBitmap:rowBytes:bounds:format:colorSpace:
bytes
numberWithLongLong:
numberWithUnsignedLong:
colorWithRed:green:blue:alpha:colorSpace:
filterWithName:
setValue:forKey:
outputImage
vectorWithX:Y:Z:W:
imageByCompositingOverImage:
filterWithName:withInputParameters:
valueWithBytes:objCType:
contextWithOptions:
createCGImage:fromRect:
labels
nameForUIClass:
IoUForbb1:bb2:
fileExistsAtPath:
_initializeShotflowDetector
_screenEquivalenceToken:
isEqualToData:
_performCrossClassNMSForDetections:iouThreshold:
removeObjectsInArray:
featureWithVisionRequest:axElementRect:confidence:uiClass:label:canvasSize:
componentsSeparatedByString:
clickabilityModel
axElementVisionModel
_imageByWipingTextFromRects:image:colorSpace:ciContext:
_nonMaxSupression:iouThreshold:
shotflowDetector
ANODModelVersion
setANODModelVersion:
_ANODModelVersion
_shotflowDetector
width
height
left
right
bottom
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
boundingFrameForItems:
normalizedBoundingFrameForItems:
metric:inProximityOfMetric:item:threshold:
sequence:
feature
_feature
arrayWithObject:
line:
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
textSequence:canvasSize:
_assembleLayoutSequences:canvasSize:
_assembleLayoutLines:
_assembleLayoutRegions:
componentsJoinedByString:
textLineWithText:boundingBox:sequences:canvasSize:
semanticTextForText:withLocale:
isSemanticallyComplete
transformedSpeechText
textRegionWithText:isSpeakable:boundingBox:lines:canvasSize:
textDocumentWithText:isSpeakable:boundingBox:regions:canvasSize:
_resetTranspositionHistory
initWithTargetedCIImage:options:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedImageURL:options:
_translationalImageRegistrationRequestForInput:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCIImage:error:
alignmentTransform
_recordTransposition:
_resetImageRegistration
registrationState
_previousInput
_currentInput
_transpositionHistoryCircularBuffer
_transpositionHistoryLastRecordedIndex
_fillingHistoryBuffer
_registrationState
featureWithCameraType:
triggerWithCameraType:cacheKey:resultHandler:
value:withObjCType:
getValue:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
initWithAttack:release:compressionRatio:threshold:sampleRate:
inputSource
emaSamples
setEma:
ratio
engagement
setEngagement:
compressor
limiter
processSamples:
compressionRatio
setCompressionRatio:
setGain:
setSampleRate:
setRatio:
gainReduction
setGainReduction:
setEmaSamples:
_compressionRatio
_gain
_threshold
_sampleRate
_ratio
_gainReduction
_engagement
_emaSamples
_ema
_initWithHandle:
_text
URLForResource:withExtension:subdirectory:
_soundFileURLForSoundID:
_initWithURL:handle:
_initWithSoundID:handle:
soundFileURL
soundID
_soundID
_soundFileURL
handleProvider
stop
pitch
setPitch:
rate
setRate:
setQuantizedRate:
setHandleProvider:
_handleProvider
_initWithCIImage:
_initWithPixelBuffer:
_initWithURL:
orientedSize
CGImage
imageWithCVPixelBuffer:
inputWithURL:
imageColorSpace
createCGImageWithMetrics:
wrappedPixelBuffer
_inputType
_ciImage
_pixelBuffer
_extendedSRGBColorSpace
_URL
_cachedImageURLSize
render:toCVPixelBuffer:
initWithShape:dataType:error:
dataPointer
initWithInput_1:
classLabel
output1
_localizedClassForClass:
featureWithIconClass:confidence:
textRange
enumerateAttribute:inRange:options:usingBlock:
initWithText:semanticText:
initWithText:locale:
preprocessedText
enumerateNLPTokens:
enumerateLexiconMarkers:
enumerateNumericTokens:
enumerateDataDetectors:
enumerateCustomPatterns:
enumerateSemanticErrors:
addNLPToken:withRange:
addDataDetector:withRange:
addCustomPattern:withRange:
addIsInLexionMarker:withRange:
addSemanticErrorWithRange:
addNumericToken:withRange:
makeCursor
setTransformedSpeechText:
_transformedSpeechText
initWithTagSchemes:
URLForResource:withExtension:
dictionaryWithContentsOfURL:
initWithTypes:error:
_preprocessedText:
_applyNaturalLanguageTokens:
_applyDataDetectors:
_applyCustomPatterns:
_performSemanticAnalysis:
substringFromIndex:
alphanumericCharacterSet
stringByTrimmingCharactersInSet:
tagger
setString:
_textExistsInLexicon:withLocale:
numberFormatter
numberFromString:
enumerateTagsInRange:unit:scheme:options:usingBlock:
dataDetector
resultType
compiledPatterns
isFinished
remainingRange
isOtherWord
isInLexicon
isCustomPattern
processAttribute:getSubstring:advanceCursor:markAsSemanticError:error:
isProperNoun
errorWithDomain:code:userInfo:
markCurrentIndexAsSemanticErrorAndAdvanceCursor
_lexiconForLocale:
cachedLexicons
_string:containsOnlyCharactersFrom:
_lexiconExistsForLocale:
setTagger:
setCachedLexicons:
setNumberFormatter:
setCompiledPatterns:
setDataDetector:
_tagger
_numberFormatter
_compiledPatterns
_dataDetector
advance
currentAttributes
_semanticText
_length
_currentIndex
_initWithPixelBuffer:orientation:
unorientedSize
_orientation
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
weakObjectsPointerArray
_initializeAudioUnit
stopPlaying
playbackDuration
playbackMixerDataSource
playbackSampleCount
setLength:
playbackChartDataAudioDataSource
playbackTrendlineAudioDataSource
scrubbingMixerDataSource
scrubbingDiscreteAudioDataSource
scrubbingContinuousAudioDataSource
scrubbingTrendlineAudioDataSource
scrubbingDiscreteDataRenderingContext
liveContinuousMixerDataSource
liveContinuousAudioDataSource
isPaused
playbackObservers
dataSonifierPlaybackDidBeginAtPosition:
currentPlaybackPosition
dataSonifierPlaybackDidResumeAtPosition:
dataSonifierPlaybackProgressDidChange:
scheduledTimerWithTimeInterval:repeats:block:
setPlaybackObserverUpdateTimer:
playbackObserverUpdateTimer
dataSonifierPlaybackDidPauseAtPosition:
dataSonifierPlaybackDidEndAtPosition:
_uninitializeAudioUnit
addPointer:
indexOfObject:
removePointerAtIndex:
isScrubbing
scrubToPlaybackFrame:
trendlineFunction
interpolationMode
setLevel:
_newContinuousToneEnvelope
isPlaying
pause
isEndingScrubbing
stopScrubbing
dataSonifierScrubbingDidBeginAtPosition:
continuousScrubbingTone
startRelease
trendlineScrubbingTone
dataSonifierScrubbingDidEndAtPosition:
intValue
frequencyForYAxisValue:
ampEnvelope
toneWaveform
setWaveform:
_peakNormalizeBuffer:length:level:
hasContinuousDataForXPosition:
setMuted:
interpolatedYAxisValueForNormalizedPosition:
setFrequency:
xAxisValueForPosition:
dataSonifierScrubbingPositionDidChange:
setTrendlineFunction:
_initializeAXMAudioDataSources
_renderDiscreteAudio
_renderContinuousAudio
_renderUnivariateFunctionAudio
sampleIndexForXAxisValue:
normalizeAudio
timeOffsetForXAxisValue:
initWithFrequency:timeOffset:
timeOffsetMS
initWithKeyPitches:sampleRate:envelope:
_initializeAudioComponent
_setAudioFormat
_setOutputCallback
normalizedXAxisValueForValue:
minimumPlaybackFrequency
maximumPlaybackFrequency
normalizedYAxisValueForValue:
_initializeLiveToneDataSource
liveContinuousDataTone
play
addPlaybackObserver:
removePlaybackObserver:
setPlaybackPosition:
beginScrubbing
endScrubbing
loadDataAndRenderAudioForXAxis:yAxis:numValues:axisMinimumX:axisMaximumX:axisMinimumY:axisMaximumY:interpolationMode:trendline:
sampleIndexForTimeOffset:
beginLiveContinuousToneSession
endLiveContinuousToneSession
setLiveContinuousToneNormalizedFrequency:
setMinimumPlaybackFrequency:
setMaximumPlaybackFrequency:
setPlaybackDuration:
setAmpEnvelope:
setToneWaveform:
usesBinauralPanning
setUsesBinauralPanning:
dataMode
isInLiveContinuousToneSession
setPlaybackMixerDataSource:
setPlaybackChartDataAudioDataSource:
setPlaybackTrendlineAudioDataSource:
setScrubbingMixerDataSource:
setScrubbingDiscreteAudioDataSource:
setScrubbingContinuousAudioDataSource:
setScrubbingTrendlineAudioDataSource:
setLiveContinuousMixerDataSource:
setLiveContinuousAudioDataSource:
setPlaybackObservers:
scrubbingPlaybackCallbackRenderingContext
liveTonePlaybackCallbackRenderingContext
_audioUnit
_xData
_yData
_usesBinauralPanning
_playing
_paused
_scrubbing
_isEndingScrubbing
_isInLiveContinuousToneSession
_dataMode
_interpolationMode
_minimumPlaybackFrequency
_maximumPlaybackFrequency
_playbackDuration
_ampEnvelope
_toneWaveform
_continuousScrubbingTone
_playbackObserverUpdateTimer
_playbackMixerDataSource
_playbackChartDataAudioDataSource
_playbackTrendlineAudioDataSource
_scrubbingMixerDataSource
_scrubbingDiscreteAudioDataSource
_scrubbingContinuousAudioDataSource
_scrubbingTrendlineAudioDataSource
_liveContinuousMixerDataSource
_liveContinuousAudioDataSource
_playbackObservers
_trendlineScrubbingTone
_liveContinuousDataTone
_trendlineFunction
_scrubbingDiscreteDataRenderingContext
_scrubbingPlaybackCallbackRenderingContext
_liveTonePlaybackCallbackRenderingContext
_playbackSampleCount
renderInBuffer:atFrame:numSamples:
input_1
setInput_1:
_input_1
initWithOutput1:classLabel:
setOutput1:
setClassLabel:
_output1
_classLabel
predictionFromInput_1:error:
observer
callback
initWithSuiteName:
registerDefaults:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_queue_removeObserver:forSetting:
boolForKey:
setBool:forKey:
settings
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
removeObserverForAllSettings:
writeOutInputImages
setWriteOutInputImages:
writeOutOCRInputImages
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
useANODModelForAXElementVision
setUseANODModelForAXElementVision:
_defaults
_queue_settingObservers
initForReadingFromData:error:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
setAssetURL:
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
assetURL
creationDate
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
resourceValuesForKeys:error:
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_assetURL
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
initWithVisionAestheticsObservation:
_aestheticScore
_wellFramedSubjectScore
_pleasantCompositionScore
_wellChosenBackgroundScore
_noiseScore
_failureScore
_initWithBackingType:
setDisplayMonitor:
displayMonitor
connectedIdentities
configurationForIdentity:
isMainDisplay
_updateDisplay:withConfiguration:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
initWithCompletion:
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
currentMode
preferredScale
mobileGestaltOrientation
setOrientation:
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
setSize:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_physicalOrientation
_backingType
_size
_referenceBounds
compute
xValues
getValues:fromNSNumberArray:
yValues
getModelForX:y:n:
setRegressionModel:
regressionModel
descriptionForXValue:
bestFitParameters
slopeDescription
confidenceDescription
outliersDescription
meanValueDescription
minValueDescription
maxValueDescription
stringForComponents:
computeRanges
computeMeans
computeCovariance
computeVariances
computeR
computeLinearRegression
computeResiduals
computeOutliers
getMean:
getVariance:
fullDescription
stringWithString:
maxX
minX
maxY
minY
positionForXAxisValue:
categoryNameDelegate
categoryNameForXAxisPosition:
initWithAxisTitles:xValues:yValues:
computeRegressionModel:
medianValueDescription
bestFitCurveEquation
simpleDescription
numericalDescription
getMedian:
positionForYAxisValue:
axisTitles
rSquared
meanX
varianceX
meanY
varianceY
covariance
slope
intercept
residuals
outliers
setCategoryNameDelegate:
_axisTitles
_xValues
_yValues
_regressionModel
_rSquared
_minX
_maxX
_meanX
_varianceX
_minY
_maxY
_meanY
_varianceY
_covariance
_slope
_intercept
_residuals
_outliers
_categoryNameDelegate
_imageOrientationForInterfaceOrientation:displayOrientation:
imageByApplyingOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
saveToURL:withOrientation:metrics:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:metrics:
lexiconManager
enumerateText:locale:block:
_preprocessText:metrics:
punctuationCharacterSet
formUnionWithCharacterSet:
removeCharactersInString:
symbolCharacterSet
_text:containsOnlyCharactersFromSet:
spellChecker
processText:withLocales:metrics:
_spellChecker
_lexiconManager
_globalWhitelistedWords
_localeWhitelistedWords
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByDeletingPathExtension
stringByAppendingPathExtension:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
stringByAppendingPathComponent:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
hasPrefix:
rangeOfString:
samplesPerSecond
lastSampleTime
isDeviceMotionAvailable
deviceMotion
featureWithDeviceMotion:orientation:
setLastSampleTime:
triggerWithCoreMotionManager:deviceOrientation:cacheKey:resultHandler:
setSamplesPerSecond:
_samplesPerSecond
_lastSampleTime
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
numberWithInt:
axmValueWithCGAffineTransform:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
setReleasing:
setReleaseFrame:
muted
framesRendered
resetRelease
phase
releasing
releaseFrame
setFramesRendered:
_muted
_releasing
_phase
_framesRendered
_releaseFrame
setCIContext
imageByApplyingTransform:
resizeImage:byX:andY:
resizeImage:to:
getCGImageAsVImageBuffer:
setCIContext:
getCGImageFromCIImage:
resizeImage:toWidth:andHeight:
setIsDisqualified:
estimatedRadianFrequency
sortDataPoints
getSMA:lookback:
disqualifyModelIfNecessary
_imageSaliencyRequest
set_imageSaliencyRequest:
salientObjects
narrowedBoundingBox
prominentObjectWithBoundingBox:canvasSize:confidence:
__imageSaliencyRequest
captureOutput
setCaptureOutput:
_captureOutput
setPriority:
priority
defaultPriority
defaultANEDevice
setProcessingDevice:
setModelFileBackingStore:
_diagnosticNameForRequests:metrics:
preferredModelInputSize
isANEDeviceAvailable
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
setCaptureNode:
setTextDetector:
setAxElementDetector:
captureNode
textDetector
axElementDetector
_captureNode
_textDetector
_axElementDetector
setInputSource:
_inputSource
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:labelKey:
labelKey
setLabelKey:
_labelKey
setIs3DLandmarks:
is3DLandmarks
leftEye
pointsArrayForRegion:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
normalizedPoints
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
setNormalizedMinimumTextHeightRatio:
setCorrectSpelling:
setSpellCheckingLanguages:
setTextDetectionLanguage:
correctSpelling
spellCheckingLanguages
textDetectionLanguage
arrayWithArray:
setTextDetectionLocales:
_usesLanguageCorrection
_correctSpelling
_recognitionLevel
_normalizedMinimumTextHeightRatio
_textDetectionLocales
_spellCheckingLanguages
_textDetectionLanguage
setClientID:
setIncludeImageInResult:
setDetectText:
setTextDetectionOptions:
setDetectScenes:
setDetectNSFW:
setDetectSignificantEvents:
setDetectModelClassifications:
setDetectCaptions:
setDetectTraits:
setDetectFaceRectangles:
setDetectFaceNames:
setDetectFaceAttributes:
setDetectFaceExpressions:
setDetectFaceLandmarks:
setDetectFacePose:
setDetectProminentObjects:
setDetectHorizon:
setDetectRectangles:
setDetectAXElements:
detectFaceNames
setDetectAesthetics:
setPreserveInputImageSize:
setIgnoredLayerContextIDs:
setIncludedLayerContextIDs:
clientID
voiceOverOptions
hasDetectionsEnabled
disableAllDetectors
_detectFaceRectangles
_detectFaceNames
_detectFaceAttributes
_detectFaceExpressions
_detectFaceLandmarks
_detectFacePose
_detectScenes
_detectNSFW
_detectSignificantEvents
_detectModelClassifications
_detectCaptions
_detectTraits
_detectRectangles
_detectHorizon
_detectProminentObjects
_detectAesthetics
_detectIconClass
_detectAXElements
_detectText
_includeImageInResult
_preserveInputImageSize
_clientID
_textDetectionOptions
_ignoredLayerContextIDs
_includedLayerContextIDs
setRequest:
dispatchRequest:
request
initWithComponents:options:
disable
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
playActiveSound:
_outputRequests
_usesPrivateAudioSession
_audioSession
_state
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
setWithObject:
spellServer:findMisspelledWordInString:languages:wordCount:countOnly:correction:
correctSpellingInText:withLanguages:
textContainsMisspelling:withLanguages:
setSpellChecker:
waveform
aWeighting
_frequency
_envelope
_waveform
_aWeighting
getResidualsVector:result:
computeScore
fitDataWithModelParams:finalParams:
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
initWithImage:
initWithLabelProbability:label:
labelProbability
setLabelProbability:
_labelProbability
predictionFromImage:error:
_aspectFaceRectFromSquareFaceRect:sizeInPixels:
faceID
type
transform
angle
_serializeWithCoder:orDictionary:
nameForFeatureType:
_nameForOCRFeatureType:
locationForNormalizedFrame:previousLocation:usingThirds:
subfeatures
_append:toList:
locationUsingThirds:
nameForLocation:
barcodeType
ocrFeatureType
assetMetadata
horizonAngle
cameraType
isEqualToAXMVisionFeature:
featureWithMetadata:interfaceOrientation:isMirrored:canvasSize:
personWithBoundingBox:confidence:canvasSize:
featureWithVisionRequest:brightnessValue:canvasSize:
objectClassificationWithLabel:localizedValue:boundingBox:confidence:canvasSize:
sceneClassificationWithLabel:localizedValue:confidence:canvasSize:
significantEventClassificationWithCategory:confidence:canvasSize:
featureWithTaxonomyNode:canvasSize:
groupedFeatureWithElementRect:uiClass:confidence:label:canvasSize:subElements:
featureWithColorInfo:canvasSize:
localizedStringForLocation:isSubjectImplicit:
uiClassForName:
nameForOCRType:
flattenedFeatureList:
dictionaryRepresentation
canvasSize
colorInfo
facePose
horizonTransform
isBarcode
isRealtimeFace
isPerson
isSignificantEventClassification
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
isTextRegion
isTextLine
isTextSequence
isTextCharacter
isTextDiacritic
isMotion
isCameraMetadata
isProminentObject
isImageAesthetics
unpaddedDetectedFaceRect
aestheticsResult
debugRectangles
setDebugRectangles:
overrideLabel
setOverrideLabel:
_featureType
_subfeatures
_barcodeType
_ocrFeatureType
_normalizedFrame
_value
_isValueSpeakable
_colorInfo
_assetMetadata
_blur
_isLowConfidence
_horizonTransform
_horizonAngle
_faceDetectionResult
_facePose
_canvasSize
_modelID
_classificationLabel
_classificationLocalizedValue
_caption
_featureGates
_captionMayContainSensitiveContent
_aestheticsResult
_deviceMotion
_cameraType
_debugRectangles
_overrideLabel
_unpaddedDetectedFaceRect
unitTestingFeatureWithType:canvasSize:frame:value:valueIsSpeakable:barcodeType:ocrFeatureType:subFeatures:
unitTestingFaceFeatureWithSize:faceFrame:
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:subFeatures:
unitTestingTeatureWithType:axElementRect:confidence:uiClass:label:canvasSize:
unitTestingFeature
unitTestingFaceFeature
unitTestingProminentObjectFeature
unitTestingHorizonFeature
initWithXValues:yValues:count:
isDisqualified
score
getJacobianForParameters:gradient:result:
getDiagonal:size:result:
getMatrixInverse:size:pivot:tmp:result:
magnitude:size:
getGradientForX:parameterValues:result:
printMatrix:rows:cols:
getIdentityMatrixWithSize:scalar:result:
roundNumber:withSignificantFigures:
iterations
_score
_bestFitParameters
_isDisqualified
_iterations
setOverrideModelURL:
setOverrideScaleMethod:
setGenderStrategy:
setSceneDetector:
overrideModelURL
overrideScaleMethod
genderStrategy
sceneDetector
effectiveModelURL
effectiveCaptionModelInfo
decodeInt32ForKey:
encodeInt32:forKey:
knownSceneClassifications
_sceneClassificationRequest
_setSceneClassificationRequest:
taxonomyOptions
possibleSceneClassifications
_taxonomyOptions
__sceneClassificationRequest
setPlayer:
setTimePitch:
player
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
timePitch
connect:to:fromBus:toBus:format:
nextAvailableInputBus
detachNode:
processingFormat
initWithPCMFormat:frameCapacity:
readIntoBuffer:error:
scheduleBuffer:atTime:options:completionHandler:
connectToEngine:
disconnectFromEngine:
beginPlayback:withError:
_player
_timePitch
_startEngineIfNeeded:
initForReading:error:
_scheduleOneShotSound:completion:
_scheduleActiveSound:
setActiveSound:
setSoundComponent:
scheduleFile:atTime:completionHandler:
startAndReturnError:
_stopActiveSound:
_logAudioFileInfo:
configChangedObserverToken
setConfigChangedObserverToken:
_engine
_oneShotSoundPlayer
_activeSounds
_configChangedObserverToken
activeSound
soundComponent
_rate
_pitch
_activeSound
_soundComponent
setConnected:
freeResources
setNodeQueue:
_connected
_enabled
_nodeQueue
effectsChain
addEffectToChain:
removeEffectFromChain:
setCircular:
_circular
_sampleBuffer
_currentSampleIndex
_level
_effectsChain
addSignificantEventResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
systemReport
privilegedSystemReport
triggerWithImageURL:options:cacheKey:resultHandler:
setFaceDetector:
setTraitDetector:
setProminentObjectsDetector:
setNsfwDetector:
setSignificantEventDetector:
setCaptionDetector:
captionDetector
configuredOptionsDisableAllDetectors:elementOptions:textRecognitionLevel:textDetectionLanguage:preferringFullCaptions:
faceDetector
traitDetector
prominentObjectsDetector
nsfwDetector
significantEventDetector
_traitDetector
_prominentObjectsDetector
_captionDetector
_nsfwDetector
_significantEventDetector
initWithModelPath:espressoEngineID:espressoDeviceID:threshold:version:
setInputShape:height:
runNetwork:inputIsBGR:
timeIntervalSinceDate:
processVImage:inputIsBGR:
resizeAndProcessVImage:inputIsBGR:
preferredSmallSide
setVersion:
.cxx_construct
_espressoPlan
_espressoContext
_espressoNetwork
_logitsPosOutputs
_logitsNegOutputs
_offsetsOutputs
_rollOutputs
_yawOutputs
_currentNetworkWidth
_currentNetworkHeight
_version
_maxout_layers
_bins_neg_maxout
_has_pose
_pose_square
_extra_default_boxes
_num_pos_classes
_important_classes
_model_labels
_num_ratios
_ratios
_defaultBoxSizes
_cell_starts_x
_cell_starts_y
_input_aspect_ratio
_keep_aspect_ratio
_can_rotate
_input_height
fileExistsAtPath:isDirectory:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
axmAppendIndentation:
initWithFormat:arguments:
dateFormatFromTemplate:options:locale:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
setTimeOffsetMS:
_timeOffsetMS
_bufferFrameForKeyPitch:
_keyPitches
@16@0:8
B32@0:8@16@24
B40@0:8@16@24@32
^{_LXLexicon=}32@0:8@16@24
v16@0:8
@"NSMutableDictionary"
^v32@0:8@16@24
@24@0:8@16
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@72@0:8@16d24d32d40d48d56d64
v24@0:8@16
d16@0:8
v24@0:8d16
@"NSString"
@32@0:8@16@24
@"NSDictionary"
@32@0:8@16^@24
@40@0:8@16@24^@32
@80@0:8@16d24d32d40d48d56d64^@72
@"MLModel"
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64^@72
@24@0:8Q16
@28@0:8Q16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@40@0:8@16Q24Q32
@44@0:8@16Q24Q32B40
@56@0:8@16Q24Q32B40B44^@48
B16@0:8
v32@0:8@16@24
@"VNDetectHorizonRequest"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v24@0:8@?16
@"NSArray"
q24@0:8@16
q16@0:8
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
{CGPoint=dd}16@0:8
v24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
f16@0:8
v20@0:8f16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@32@0:8d16@24
@40@0:8d16d24@32
v32@0:8^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}}16Q24
@40@0:8@16{CGSize=dd}24
@"VNDetectFaceRectanglesRequest"
@"VNCreateFaceprintRequest"
@"VNClassifyFaceAttributesRequest"
@"VNDetectFaceExpressionsRequest"
@"VNDetectFaceLandmarksRequest"
@"VNDetectFacePoseRequest"
@"VNClassifyImageAestheticsRequest"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"<AXMServiceDelegate>"
@"NSXPCConnection"
@?16@0:8
v20@0:8B16
@"AXMOutputRequestHandle"
@"NSMutableArray"
i16@0:8
v24@0:8^d16
@28@0:8^d16i24
B40@0:8o^@16@24o^@32
@24@0:8@?16
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96B100i104
@116@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92B96B100i104@108
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100B104i108
@120@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84f88f92i96B100B104i108@112
f24@0:8@16
B32@0:8@16f24f28
B32@0:8@16f24i28
v20@0:8i16
B24@0:8^@16
@"NSURL"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
@24@0:8q16
v32@0:8q16@24
v40@0:8@16q24@32
@"NSMutableString"
@"AXMVisionFeature"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
B24@0:8@"AXMVisionEngineNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
v32@0:8@16q24
v32@0:8@"AXMService"16q24
@24@0:8^{_NSZone=}16
v32@0:8@"NSMutableString"16q24
@32@0:8@16B24B28
v40@0:8@16@24@32
@24@0:8#16
v24@0:8Q16
@"AXMImageRegistrationNode"
@"_AXMVisionEngineAnalysisTask"
@"AXMVisionEngineCache"
@"AXMService"
@"AXMTaskDispatcher"
@"AXMSequenceRequestManager"
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@"NSLocale"
@56@0:8f16f20q24q32d40@48
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56q60B68
@"CMAttitude"
@136@0:8@?16d24@32{?=^dddddd}40{?=^dddddd}88
d24@0:8d16
{?=^dddddd}16@0:8
{?="values"^d"scaleMinimum"d"scaleMaximum"d"valueMinimum"d"valueMaximum"d"count"d}
@"NSMutableCharacterSet"
{CGSize=dd}16@0:8
B40@0:8@16@24d32
@"AXMPipelineContextInput"
@"AXBookendMetric"
@"VNSceneObservation"
@"NSMutableOrderedSet"
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSObject<NSSecureCoding>"
@"<NSCopying>"
@"AXMetricSession"
@"NSMutableSet"
@"AXMVisionResult"
@"NSNumber"
@"VNImageRequestHandler"
@"AXMSemanticTextFactory"
@"AXMTextLayoutManager"
@40@0:8@16@24@?32
v48@0:8@16@24{_NSRange=QQ}32
B32@0:8{_NSRange=QQ}16
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
@32@0:8Q16^{_NSRange=QQ}24
v40@0:8{_NSRange=QQ}16@32
v40@0:8@16{_NSRange=QQ}24
@"NSMutableAttributedString"
@32@0:8@16d24
@"AXMImageNode"
@"AXMIconClassDetectorNode"
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
@40@0:8^{__CVBuffer=}16d24d32
^{__CVBuffer=}16@0:8
v24@0:8^{__CVBuffer=}16
^{__CVBuffer=}
@"MLMultiArray"
@48@0:8^{__CVBuffer=}16d24d32^@40
@64@0:8d16d24d32d40d48d56
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
d24@0:8@16
@48@0:8d16d24d32@40
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v32@0:8@16@?24
@"AVSpeechSynthesizer"
@36@0:8@16d24B32
@"NSSet"
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v40@0:8@"AXMAVCaptureSessionNode"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v52@0:8^{opaqueCMSampleBuffer=}16q24B32@36@44
@"AXMCaptureVideoDataOutput"
@"<AXMAVCaptureSessionNodeDelegate>"
@"<AXMAVCaptureSessionNodeFrameDelegate>"
@"AVCaptureSession"
@104@0:8{?={?=qq}Q}16@40@48@56@64@72@80@88@96
@48@0:8Q16@24@32@40
@"AXMSpeechFormatter"
{?="range"{?="location"q"length"q}"attributes"Q}
@"NSTextCheckingResult"
@40@0:8@16{_NSRange=QQ}24
{_NSRange="location"Q"length"Q}
v32@0:8Q16Q24
v32@0:8Q16@24
@"AVAudioSession"
v32@0:8q16@?24
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
@"CIImage"
@"NSData"
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
v44@0:8@16@24B32@36
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
@24@0:8d16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"AXAssetController"
d24@0:8q16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
@"AXMVisionFeatureFaceAttributes"
@"AXMVisionFeatureFaceLandmarks"
{?="columns"[4]}
@40@0:8@16f24@28i36
@44@0:8@16f24@28i36i40
@32@0:8@16f24f28
@"AXShotflowNetwork"
v40@0:8@16@24@?32
v48@0:8@16@24Q32@?40
v48@0:8@16Q24Q32@?40
@"NSRegularExpression"
@"AXMSpeechFormatterCache"
@28@0:8@16I24
B44@0:8@16@24d32B40
@"VNVYvzEtX1JlUdu8xx5qhDI"
{CGRect={CGPoint=dd}{CGSize=dd}}92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56f60@64f72f76q80B88
{?=ii}24@0:8@16
B32@0:8@?16^@24
B32@0:8q16^@24
@"AVCaptureDevice"
@"AVCaptureDeviceInput"
@"AVCaptureVideoDataOutput"
@"NSHashTable"
@"_AXMCaptureManagerDetectionEngine"
@"AVCaptureDeviceFormat"
i24@0:8q16
I24@0:8q16
v32@0:8@16^{__CVBuffer=}24
v32@0:8@"AXMCaptureManager"16^{__CVBuffer=}24
@"AXMCaptureManager"
@"AXMVisionEngine"
@"AXMSceneDetectorNode"
@"AXMFaceDetectorNode"
@"VNSequenceRequestHandler"
@48@0:8@16@24^{CGColorSpace=}32@40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@"AXShotflowDetector"
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@60@0:8@16{CGSize=dd}24@40B48^@52
[10{CGPoint="x"d"y"d}]
v40@0:8q16@24@?32
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@56@0:8d16d24d32d40d48
@"AXMOutputActionHandle"
@"<AXMActiveSoundOutputActionHandleProvider>"
^{CGColorSpace=}16@0:8
^{CGImage=}24@0:8@16
@"AXMPixelBufferWrapper"
^{CGColorSpace=}
{CGSize="width"d"height"d}
v36@0:8B16{_NSRange=QQ}20
v32@0:8{_NSRange=QQ}16
^{_LXLexicon=}24@0:8@16
@"NLTagger"
@"NSNumberFormatter"
@"NSDataDetector"
B48@0:8@16^@24B32B36^@40
@"NSAttributedString"
@"AXMSemanticText"
@28@0:8^{__CVBuffer=}16I24
I16@0:8
v84@0:8^d16^d24Q32d40d48d56d64i72@?76
Q24@0:8d16
B24@0:8d16
v40@0:8^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}}16Q24d32
^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}}16@0:8
^{OpaqueAudioComponentInstance=}
@"AXMADSREnvelope"
@"AXMLiveContinuousTone"
@"NSTimer"
@"AXMAudioDataSourceMixer"
@"AXMAudioDataSource"
@"NSPointerArray"
^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}}
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@48@0:8@16#24@32^@40
@"NSDate"
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8{CGSize=dd}16
@40@0:8@16@24@32
v32@0:8^d16@24
@"AXMDataRegressionModel"
@"NSObject<AXMDataSummaryCategoryNameProvider>"
I32@0:8q16q24
I28@0:8q16B24
@40@0:8q16q24^I32
@36@0:8q16B24^I28
v36@0:8@16I24@28
@"AXMSpellChecker"
@"AXMLexiconManager"
@"AXMTagger"
@"AXMDataDetector"
v48@0:8@16q24@32@?40
v40@0:8^{vector<int, std::__1::allocator<int> >=^i^i{__compressed_pair<int *, std::__1::allocator<int> >=^i}}16Q24Q32
{shared_ptr<vImage_Buffer>=^{vImage_Buffer}^{__shared_weak_count}}24@0:8^{CGImage=}16
{shared_ptr<CGImage>=^{CGImage}^{__shared_weak_count}}24@0:8@16
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"AVCaptureMetadataOutput"
B56@0:8@16@24@32@40^@48
@"AXMScreenCaptureNode"
@"AXMTextDetectorNode"
@"AXMAXElementDetectorNode"
@72@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64i68
@20@0:8B16
@"AXMLanguage"
@"AXMTextDetectionOptions"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputRequest"
@"AppleSpell"
v32@0:8^{vector<int, std::__1::allocator<int> >=}16Q24
d32@0:8^d16^d24
@24@0:8^{__CVBuffer=}16
@32@0:8^{__CVBuffer=}16^@24
@52@0:8@16q24B32{CGSize=dd}36
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGSize=dd}56
@44@0:8@16f24{CGSize=dd}28
@48@0:8@16@24{CGSize=dd}32
@84@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64{CGSize=dd}68
@52@0:8@16@24f32{CGSize=dd}36
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48d56@64{CGSize=dd}72@88
@84@0:8@16B24{CGRect={CGPoint=dd}{CGSize=dd}}28@60{CGSize=dd}68
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56{CGSize=dd}64
@32@0:8@16q24
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
@28@0:8q16B24
q60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48B56
@"NSDictionary"16@0:8
{CGAffineTransform=dddddd}16@0:8
q20@0:8B16
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceDetectionResult"
@"AXMVisionFeatureAestheticsResult"
@"CMDeviceMotion"
@104@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88@96
@96@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@108@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72B80@84q92@100
@64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
@36@0:8^d16^d24i32
v32@0:8^d16i24i28
d28@0:8^d16i24
v36@0:8i16d20^d28
v32@0:8^d16^d24
v40@0:8d16^d24^d32
v40@0:8^d16^d24^d32
i52@0:8^d16i24^i28^d36^d44
v36@0:8^d16i24^d28
v28@0:8^d16i24
d32@0:8d16Q24
^d16@0:8
v20@0:8I16
@"VNSceneClassificationRequest"
B32@0:8@16^@24
@"AVAudioPlayerNode"
@"AVAudioUnitTimePitch"
@"AVAudioEngine"
@"AXMActiveSound"
@"<AXMVisionEngineNodeConnectionDelegate>"
@"VN6Mb1ME89lyW3HpahkEygIG"
v48@0:8@16@24@32@?40
v52@0:8^{__CVBuffer=}16I24@28@36@?44
@48@0:8@?16I24@?28@?36B44
@"AXMTraitDetectorNode"
@"AXMProminentObjectsDetectorNode"
@"AXMCaptionDetectorNode"
@"AXMNSFWDetectorNode"
@"AXMSignificantEventDetectorNode"
@32@0:8@16f24i28
@36@0:8@16f24i28i32
@40@0:8@16i24i28f32i36
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{?="plan"^v"network_index"i}
{vector<std::__1::shared_ptr<espresso_buffer_t>, std::__1::allocator<std::__1::shared_ptr<espresso_buffer_t> > >="__begin_"^{shared_ptr<espresso_buffer_t>}"__end_"^{shared_ptr<espresso_buffer_t>}"__end_cap_"{__compressed_pair<std::__1::shared_ptr<espresso_buffer_t> *, std::__1::allocator<std::__1::shared_ptr<espresso_buffer_t> > >="__value_"^{shared_ptr<espresso_buffer_t>}}}
{vector<int, std::__1::allocator<int> >="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::__1::allocator<int> >="__value_"^i}}
{vector<NSString *, std::__1::allocator<NSString *> >="__begin_"^@"__end_"^@"__end_cap_"{__compressed_pair<NSString *__strong *, std::__1::allocator<NSString *> >="__value_"^@}}
{vector<float, std::__1::allocator<float> >="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float> >="__value_"^f}}
[6[20[2f]]]
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@32@0:8d16d24
@40@0:8@16d24@32
Q24@0:8@16
ARGB
ffffff
