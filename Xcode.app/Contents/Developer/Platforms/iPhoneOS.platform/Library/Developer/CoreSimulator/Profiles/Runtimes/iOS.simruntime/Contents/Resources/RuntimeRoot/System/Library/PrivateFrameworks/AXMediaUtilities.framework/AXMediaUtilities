@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
@NSt3__120__shared_ptr_pointerIP7CGImagePFvS2_ENS_9allocatorIS1_EEEE
PFvP7CGImageE
?333333
zt?{
p@ffffff
333333
?ffffff
?ffffff
?ffffff
4@333333
?uouacoirlppa
mcpl
UUUUUU
/B33
B33CCgf
?fff?
BNSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
@o@{
?UUUUUU
?UUUUUU
?UUUUUU
?433333
?UUUUUU
?UUUUUU
?UUUUUU
?UUUUUU
|@ffffff
MbP?
AXMediaUtilities
AXBoundingBox
UIType
UITypeClickability
AXMElementDetectorResult
AXMClickabilityDetectorResult
AXModelType
CodingKeys
CGRect
CGSize
CGPoint
IgnoredLayerContextIDs
IncludedLayerContextIDs
UsePreferredModelInputSizeForDetectors
Screen Grab
Screen grab not supported on this platform
Screen recording is not supported
v8@?0
Library/Accessibility/PhotoCaptionAssets
CompiledModels
UncompiledModels
mlmodelc
mlmodel
Horizon Detector
VNDetectHorizonRequest
Unable to find class %s
mainColors
mainColorWeights
ageConfidence
gender
genderConfidence
eyes
eyesConfidence
smiling
faceHair
hairColor
hairColorConfidence
bald
glasses
glassesConfidence
makeupEyes
makeupEyesConfidence
makeupLips
makeupLipsConfidence
facemask
facemaskConfidence
ethnicity
ethnicityConfidence
expression
expressionConfidence
faceHairV2
faceHairV2Confidence
hairType
hairTypeConfidence
headgear
headgearConfidence
pose
poseConfidence
skintone
skintoneConfidence
Pose_Front
Pose_LeftProfile
Pose_RightProfile
Pose_LeftThreeQuarters
Pose_RightThreeQuarters
Skintone_I
Skintone_II
Skintone_III
Skintone_IV
Skintone_V
Skintone_VI
Ethnicity_African
Ethnicity_Caucasian
Ethnicity_LatinAmerican
Ethnicity_EastAsian
Ethnicity_SouthAsian
Gender_Male
Gender_Female
Age_Baby
Age_Child
Age_YoungAdult
Age_Adult
Age_Senior
HairColor_Black
HairColor_Blonde
HairColor_Brown
HairColor_Gray
HairColor_Red
HairColor_White
Hairtype_Wavy
Hairtype_Curly
Hairtype_Straight
Hairtype_African
Hairtype_BuzzCut
Hairtype_SparseBald
Hairtype_Frizzy
FaceHairV2_BeardOnly
FaceHairV2_GoateeOnly
aceHairV2_MoustacheOnly
FaceHairV2_MoustacheAndBeard
FaceHairV2_MoustacheAndGoatee
FaceHairV2_Stubble
Glasses_Prescription
Glasses_Sunglasses
Facemask_Available
Headgear_Cap
Headgear_Hat
Headgear_Beanie
Headgear_Headscarf
MakeupEyes_Available
MakeupLips_Available
Expression_Laugh
Expression_Smile
Expression_Sad
Expression_Angry
Expression_Neutral
Eyes_Closed
Eyes_Open
.pose.left
.pose.right
.pose.left3_4
.pose.right3_4
.age.baby
.age.person
.haircolor.black
.haircolor.blonde
.haircolor.brown
.haircolor.gray
.haircolor.red
.haircolor.white
.hairtype.wavy
.hairtype.curly
.hairtype.straight
.facehair.included
.facehair.present
.prescription
.sunglasses
.facemask
.laughing
.smiling
faceattributes
com.apple.accessibility.AXMediaUtilities
Accessibility
.accessories
.expression
VNFaceAttributeAgeBaby
VNFaceAttributeAgeChild
VNFaceAttributeAgeYoungAdult
VNFaceAttributeAgeAdult
VNFaceAttributeAgeSenior
VN1yPD9G185LIMKFd9RgandG6vUu4B3DZk
VN6cM1E1jfvMnUZoEeDjinPOtJKpacqIpr
VNFaceAttributeEyesClosed
VNFaceAttributeEyesOpen
VNFaceAttributeHairColorBlack
VNFaceAttributeHairColorBlonde
VNFaceAttributeHairColorBrown
VNFaceAttributeHairColorGray
VNFaceAttributeHairColorRed
VNFaceAttributeHairColorWhite
VNFaceAttributeGlassesPrescription
VNFaceAttributeGlassesSunglasses
VNFaceAttributeGlassesNone
VNFaceAttributeMakeupEyesUnsure
VNFaceAttributeMakeupEyesNone
VNFaceAttributeMakeupEyes
VNFaceAttributeMakeupLipsUnsure
VNFaceAttributeMakeupLipsNone
VNFaceAttributeMakeupLips
VNFaceAttributeFacemaskNone
VNFaceAttributeFacemask
VN7yMsLB9ggBYLDbJYIMGMSW6YBgi5uH2p
VN2eECeAuLQ8wnXvvNNkc5XEtpjqyiYvIp
VN2AhEqI0IOCJAaCX6zovlg85aFZ80JfES
VN6a4sQBuQ5pSiUEd6p9iQflpz8xkWOnD2
VN6pbJdmseepvIGYzcDyryle1xGdZEWhHN
VN607hNga4JKRc1ljftiy9QfPCqbXQmLP4
VN2TVJG6FfNTt72vwVKOv1Jf5dWtEHvQIS
VN7ja3fTi9TZDyKN8NdYJaWqla1NRFdcRX
VN4lC1NTVMt6oWugtej0fqgS3z5p60aMup
VN1VQUXOcXrfZPXtaGgfZBhujM6uH6hvmI
VN6i04vrZluouTItkCUMtS916cLgTyvODX
VN42tJSMaSWdsAnZKXv8XcZg2j2AIS7gjm
VN7vELTVTtPH26ptfCYi9dUHH8NxJ7O3cF
VN5ijZTfHVHp6ubCHBh4oIZR1SW4xbvQ00
VN3WbFaDRN3PTBiMaMEq5ttCx7hmmfySmR
VN4lCLwxDV30rFLSeoihd8yM1zdbka3cVu
VN4qKg9nfl3p0M4juXFIsbUb7tpfCv9epx
VN31UxDngUK44hDexm8CSuZnlLxECLb0yU
VN5JBEfctS0JUWeTVUxBAKOSXCUuMqPxTg
VN7CY11MLEimaE8WoiQ4opgi5HOi84j0UH
VN5SpoOVxahuTheCrHGepAYKTVB1baFLhQ
VN6YAJH4UBXYDBoH6cemKhJR7fPi2dt5Qd
VN21VM8NbCJMJjpepNo1kZkxteFybpDwlB
VN6lDi9hTBjr2vdjAJ5rwdun4YEH09u5F5
VN2X5h7waRTqk71pInqK4dnT6sZ6dRElxe
VNPdH78Lr962vQvRIq2JApX2QJZtbR3fvi
VN2nEhtfck4KB7KsvJeCeSEPcGLfKzeUKi
VN465E5iEqlR2tknJ0qZkyAn3yIDrmUpJw
VN4oD9MSPBdmmSq6KG3k7nYqdSMT5aNp6p
VN34LMYSFC7onytwsvH0y6uz2QaYvqY9qi
VN5iEOkR2NrIkLsZRvJTn61k1ovk3hvuxY
VN7ICFqxCpgr8BTWkFrFGYTQ3INUhxhYXR
VN3rKrpi4DELvo8AgM5Y3C68ryFlgB1grk
VN7ar6bR0PqRvM9BZ0nqEdwh61tXzue1Ut
VN1I7oR8JHxER2i7d6nQxNtHhGXxkJuH7c
VNDGCsUiwnQwGz0qSSQPGGd177EyoSaoGN
VN6LhAjooMZpZkrkhS48XbQt7602EpEAxv
VN1HsiXmKrxTsH8TYOuN5s7G3uHSP75iYS
VN1kD4zwSpSn6esc2wHjyAeZ2IRmwqjgtt
VN1PwKd46IDZj2ErCN9d1fTn3FuN3h4d9p
VN4bzonkXHYlzBnJNXcyyPd8WLw1wAI1Pv
Face Detector
v32@?0@8Q16^B24
v32@?0@"NSString"8@"AXMVisionFeatureFaceDetectionResult"16^B24
VNDetectFaceExpressionsRequest
VNDetectFaceRectanglesRequest
VNClassifyFaceAttributesRequest
VNDetectFaceLandmarksRequest
VNDetectFacePoseRequest
Aesthetics
VNClassifyImageAestheticsRequest
B24@?0@"AXElementDetection"8@"NSDictionary"16
confidence
mergesCount
smartDistance
AXMServiceConnection
v16@?0@"NSError"8
AXMOutputRequest
B24@?0@"AXMOutputAction"8@"NSDictionary"16
chart.model.exponential
d32@?0^d8Q16d24
y = %@ * e^(%@x)
modelURL
Model Detector
Model loading not supported on this platform
region
orientation
Screen Capture
@"AXMPipelineContextInput"24@?0@"NSDictionary"8^@16
Traits
VNImageScoreObservation
VNImageBrightnessObservation
VNImageBlurObservation
VNImageBlurScoreRequest
_ContentVersion
FormatVersion
B32@?0@"MAAsset"8Q16^B24
q24@?0@"MAAsset"8@"MAAsset"16
v16@?0q8
v16@?0@"NSString"8
com.apple.accessibility.vot.caption.fallbacktemplates
fallbacktemplate
@"NSDictionary"8@?0
caption-low-confidence
caption-nsfw
photo.description.brightness.level.1
photo.description.brightness.level.2
photo.description.brightness.level.3
photo.description.brightness.level.4
photo.description.brightness.level.5
photo.description.blurriness.level.1
photo.description.blurriness.level.2
photo.description.blurriness.level.3
photo.description.blurriness.level.4
photo.description.blurriness.level.5
photo.description.blurriness.level.6
people.summary.one.person
people.summary.multiple.people
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.faces
face.number
^(?!.*?\b(person|people|child|children|baby|babies)\b.*?\ba\s+person\b)(?!.*?\ba\s+person\b.*?\b(person|people|child|children|baby|babies)\b)(?<prefix>.*?)\ba\s+person(\s+that\s+is\b)?\b(?<suffix>.*)$
prefix
suffix
%@%@%@
blood
 that might contain blood
demonstration
 that might be a demonstration
 that might be a scene of destruction
fire
 that might include fire
flood
 that might be a flood
funeral
 that might be a funeral
hospital
 that might be a hospital
religious
 that might be a religious setting
crash
 that might be a vehicle crash
AXCaptionTemplateRules
plist
subsume
baby
ignored
Possible adult content
priority
q24@?0@"NSString"8@"NSString"16
B32@?0@"NSString"8Q16^B24
No_Description
aeiouAEIOU
speech
nonCountNounOrPlural
A photo containing %@ %@
A photo of %@
 and 
%@ %@
v32@?0@"NSString"8@"NSString"16^B24
v32@?0@"NSString"8Q16^B24
AnalyticsSendEventLazy
Caption Confidence Insufficient
Denylist Rule
Taboo Filter
NSFW Filter
MinimumConfidence
DenylistRule
ClassifierLabel
10.15
inputHeight
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
kernel vec4 _morphmin (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = min(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
kernel vec4 _morphmax (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = max(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
AXMImgRegistration
diagnosticsEnabled
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
v24@?0@"AXMVisionResult"8@"NSError"16
v32@?0@"AXMEvaluationNode"8Q16^B24
v24@?0@"AXMVisionPipelineContext"8@"AXMEvaluationNode"16
Evaluate %@
v16@?0@"AXMetric"8
Create Image
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld metrics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
Engine queue is at capacity
VNRequestHandlerCleanupOption_AllPipelines
VNCleanupLevel_Complete
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNImageRequestHandler
NutritionLabel
image.text.nutrition
image.text.calories
image.text.fat
image.text.carbohydrate
image.text.protein
image.text.sodium
image.text.potassium
image.text.calcium
image.text.fiber
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
deviceAttitude
kAXMHarmonicValue
kAXMHarmonicAmplitude
input
sourceProvidesResults
sourceparams
features
evaluatedFeatureTypes
analysisOptions
userContext
error
EffectiveTextDetectionLocales
Pipeline-%ld
AXM_VISION_ENGINE_METRICS
com.apple.accessibility.sceneobservation
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
A creation node must return a valid image
%@-%ld-%ldx%ld.%@
Pipeline
Text Detector
@16@?0@"NSString"8
scene
@16@?0@"AXMVisionFeature"8
en-US
VNRecognizeTextRequest
image
iconClass
brailleEdges
SharedIconVision
v20@?0@"AXMTask"8B16
iouThreshold
confidenceThreshold
coordinates
AXElementVision
assetURL
creationDate
localIdentifier
imageData
allowNetworkAccess
photoLibraryURL
User has not yet made a choice to authorize access to photo data with regards to this application
User has explicitly denied this application access to photos data.
<%@ %p URL=%@ creationDate=%@ localIdentifier=%@ data=%@ UTI=%@ orientation=%u>
v36@?0@"NSData"8@"NSString"16I24@"NSDictionary"28
PHPhotoLibrary
PHAsset
PHImageManager
PHImageRequestOptions
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
VNDetectRectanglesRequest
VNImageOptionCameraIntrinsics
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu sources=
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
B32@?0@8Q16^B24
v16@?0@"NSNotification"8
Began
Ended
Unknown
New Device Available
Old Device Unavailable
Category Change
Override
Wake From Sleep
No Suitable Route for Category
Route Congifuration Change
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
BitsPerComponent
CGBitmapInfo
BitsPerBlock
AXMFeatures
AXMImage
B32@?0@"AXMVisionFeature"8Q16^B24
detected.text.type.hint
detected.text.summary.hint
detected.text.hint
SELF != ''
description.face
description.prominent.object
description.person
B24@?0@8@"NSDictionary"16
Locale
ModifyForSensitiveContent
detected.icon.hint
detectedTextDescription
detectedTextType
detectedTextSummary
imageRegistrationState
equivalenceToken
effectiveTextDetectionLocales
metrics
en_US
AXMVisionResult<%p>: Image:%@ Results:%@ Feature Description: '%@'. Text Description: '%@'.
v32@?0@"AXMVisionFeature"8Q16^B24
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
%@ playerItem:<%@>
model_info.json
ImageCaptionModel
VideoCaptionModel
Stable
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceLandmarksConfidence
AXMFeatureFaceExpressions
AXMFeatureFacePose
AXMVisionFeatureCodingKeyFacePoseConfidence
AXMFeatureFaceName
AXMFeatureFaceNameConfidence 
AXMFeatureFaceAttributes
AXMFeatureFaceAttributesConfidence
AXMFeatureFaceRectangles
AXMFeatureFaceRectanglesConfidence
AXMFeatureFaceUUID
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
image/Placeholder
leaf/leaf/predictions/probabilities
iconclassification
v24@?0@"MLModel"8@"NSError"16
AXMChildren
AXMType
AXMTypeContainer
AXMContent
AXMBounds
AXMRowType
NSFW Detector
VNVYvzEtX1JlUdu8xx5qhDI
VN81aedeb999c79d74e79af7f1c922cf97
VNSequenceRequestHandler
Object Detector
VNRecognizeObjectsRequest
 - [%@]
AXElement Detector
_ContentVersion_v2
CIConstantColorGenerator
CICrop
inputImage
inputRectangle
CIColorControls
{CGAffineTransform=dddddd}
CIAffineTransform
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
q24@?0@"AXElementDetection"8@"AXElementDetection"16
ScreenRecognitionIconDetector
esp error
B32@?0@"VNRecognizedTextObservation"8Q16^B24
inputTransform
outputImage
%@-image.png
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
image.value.one
image.value.half
image.value.third
image.value.fourth
image.value.fifth
image.value.sixth
image.value.seventh
image.value.eighth
image.value.nineth
image.value.tenth
image.value.halves
image.value.thirds
image.value.fourths
image.value.sixths
image.value.sevenths
image.value.eighths
image.value.nineths
image.value.tenths
[\d]+ ?g(\s|\)|$|,)
[\d]+ ?mg(\s|\)|$|,)
[\d]+ ?mcg(\s|\)|$|,)
[\d]+ ?ml(\s|\)|$|,)
kcal
[\d]+ ?kcal(\s|\)|$|,)
[\d]+ ?kg(\s|\)|$|,)
no source texts provided
envelope.address.formatter
%@, %@
en-CA
math.table.row.format
math.table.column.format
table.incomplete
nutrition.label.row.format
q24@?0@"VNRecognizedTextObservation"8@"VNRecognizedTextObservation"16
CIPhotoEffectNoir
CIColorInvert
CIColorThresholdOtsu
AXMCIMorphologyRectangleMinimum
inputWidth
AXMCIMorphologyRectangleMaximum
q24@?0@"VNContour"8@"VNContour"16
B32@?0@"VNContour"8Q16^B24
image.text.name
image.text.address
, %@
receipt.product.unitprice.total.formatter
receipt.product.qty.unitprice.total.formatter
(.)\1{%lu}
\d{%lu}
q24@?0@8@16
\d+%
[0-9]/[0-9]
VNDetectContoursRequest
Image Registration
VNTranslationalImageRegistrationRequest
VNImageTranslationAlignmentObservation
Camera Metadata
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
bubbleUp
bubbleDown
pluck1
pluck2
scratch1
scratch2
success1
aiff
sounds
inputType
ciImage
use wrapperWithPixelBuffer:
PixelWidth
PixelHeight
CIImage
Pixel Buffer
%@ (%@)
Convert to CGImage
Icon Class Detector
iconclassification.mlmodelc
apple
back
bluetooth
bookmark
calendar
camera
cart
chat
checkmark
clipboard
clock
close
compass
compose
copy
currency
delete
down
download
expand
facebook
fastForward
flag
flight
folder
font
gift
globe
heart
help
home
info
keyboard
launch
layers
lightning
list
location
locationCrosshair
locked
mail
menu
microphone
minus
more
music
notification
pause
people
person
phone
play
refresh
repeat
rewind
rightArrow
rightCurved
search
send
settings
share
sliders
smile
speaker
star
stop
thumbsDown
thumbsUp
trophy
twitter
unknown
videoRecorder
iconTypes.plist
iconTypes
CILanczosScaleTransform
inputScale
inputAspectRatio
icon.type.
__AXMStringForVariablesSentinel
@"AXMVisionFeature"16@?0@"AXMMLElementGroup"8
AXMLElementProperties
clickable_text_keywords
[^[a-z]]
B32@?0@"AXMMLElementGroup"8Q16^B24
@16@?0@"AXMMLElementGroup"8
v32@?0@"NSNumber"8@"NSMutableArray"16^B24
q24@?0@"AXMMLElementGroup"8@"AXMMLElementGroup"16
q24@?0@"NSNumber"8@"NSNumber"16
NLPToken
IsInLexicon
NumericToken
DataDetector
CustomPattern
SemanticError
NLP:OtherWord
NLP:PersonalName
NLP:OrganizationName
NLP:PlaceName
NLP:Whitespace
NLP:Dash
NLP:Punctuation
NLP:SentenceTerminator
NLP:Unknown
DD:Date
DD:Address
DD:Link
DD:PhoneNumber
DD:TransitInfo
US_Currency
v40@?0{_NSRange=QQ}8Q24^B32
v40@?0@8{_NSRange=QQ}16^B32
SemanticTextPatterns
Patterns
Pattern
v40@?0@"NSString"8{_NSRange=QQ}16^B32
v32@?0@"NSTextCheckingResult"8Q16^B24
v32@?0@"NSString"8@"NSRegularExpression"16^B24
Failed to match current cursor position. remaining:[%@ %@]
v24@?0^{_LXEntry=}8*16
en_CA
Failed to advance cursor. No value for attribute: %@. remaining:[%@ %@]
Sceneprint Creator
@"VNSceneObservation"8@?0
VNCreateSceneprintRequest
Asset Metadata
PlaybackMixer
PlaybackChartData
PlaybackTrendline
ScrubbingMixer
ScrubbingDiscreteData
ScrubbingContinuousData
ScrubbingTrendline
LiveToneMixer
LiveContinuousData
v16@?0@"NSTimer"8
Error playing audio buffer
Error stopping audio playback
Error: IO audio unit is running but we aren't in a scrubbing or playback session -- investigate.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
AXMSetting
writeOutInputImages
writeOutOCRInputImages
writeOutScreenCaptures
useANODModelForAXElementVision
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
Braille Edge Detector
CIEdges
CIBloom
name
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
isAssetLocallyAvailable
name:%@ created:%@ UTI:%@ typeDesc:%@ assetLocalIdentifier:%@ isAssetLocallyAvailable:%d photoLibraryURL:%@
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
Aesthetics: aesthetic=%.2f wellFramedSubject=%.2f wellChosenBackground=%.2f noise=%.2f failure=%.2f pleasantComposition=%.2f
AXMDisplayManager
DeviceClassNumber
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
main-screen-scale
scale
main-screen-orientation
Aixt/MEN2O2B7f+8m4TxUA
supportsDeepColor
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
chart.model.power
y = %@ * x^%@
__AXMDataSummaryStringForVariablesSentinel
chart.series.trend.increasing
chart.series.trend.decreasing
chart.series.trend.verystrong
chart.series.trend.strong
chart.series.trend.moderate
chart.series.trend.weak
chart.series.trend.none
chart.series.minvalue.format
chart.series.maxvalue.format
chart.series.meanvalue.format
chart.series.outlier.format
chart.series.outliers.none
<%@ %p x:[%.1f, %.1f] y:[%.1f, %.1f] model=%@ xbar=%.1f ybar=%.1f r=%.4f rSq=%.4f y=%.4fx+%.4f
outliers=%@>
self
filterThresholds
nmsThreshold
B16@?0@8
filterThresholds: %@
nmsThreshold: %@
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
axout-tmp
-axtmp
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
image/gif
filetype.gif
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/rtf
filetype.rtf.document
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/vnd.openxmlformats-officedocument.presentationml.presentation
application/msword
filetype.word
application/vnd.openxmlformats-officedocument.wordprocessingml.document
application/postscript
filetype.postscript
application/rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
application/epub+zip
filetype.epub
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
com.apple.coreaudio-format
video/
usdz
filetype.3D.model
numbers
filetype.number
pages
filetype.pages
filetype.keynote
rtfd
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
UIAccessibilityIsVoiceOverRunning
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
AXMCoreMotionNode_samplesPerSecond
AXMCoreMotionNode_lastSampleTime
Core Motion
 North 
 N. 
 South 
 S. 
 East 
 E. 
 West 
 W. 
 NE 
 North East 
 NE. 
 NW 
 North West 
 NW. 
 SE 
 South East 
 SE. 
 SW 
 South West 
 SW. 
North
South
East
West
North East
 NE.
North West
 NW.
South East
 SE.
South West
 SW.
Street
 AVE
Avenue
Road
Lane
 ST 
 Street 
 AVE 
 Avenue 
 RD 
 Road 
 LN 
 Lane 
 STE 
 Suite 
 APT 
 Apartment 
 UNT 
 Unit 
com.apple.accessibility.vot.DataSonifierAccess
audiograph.series.number
audiograph.datapoint
audiograph.datapoints.count
com.apple.AXMediaUtilitiesService
com.apple.AXMediaUtilitiesService-access
contextQueue
Create CIContext
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
networkThreshold
defaultBoxesSidesNormalized
ratios
filterThresholds: %@
networkThreshold: %@
nmsThreshold: %@
defaultBoxesSidesNormalized: %@
ratios: %@
tiff
Could not allocate color space
Could not allocate bitmap memory
Could not allocate context
ERROR: Could not create image from URL %@
Orientation
could not create image from data
Failed to load raw buffer
ERROR: data is nil
Format not supported (input image must be 32 or 8 bits per pixels)
Ignoring lumaOnly flag when operating on RAW buffers
Failed to create the context
Failed to allocate the image buffer
Could not extract first image from bundle
Could not create image from data
Failed to create the CVPixelBuffer
Format not supported (input image must be 32 bits per pixels)
%s error %lld:%s in %s @ %s:%d
+[ImageTools loadCVPixelBuffer420YpCbCr8FromURL:error:]
/Library/Caches/com.apple.xbs/Sources/AccessibilityMediaUtilities_Sim/AXMediaUtilities/source/ImageTools.m
unexpected number of bytes per pixels
ERROR: Could not load 420YpCbCr8 buffer
+[ImageTools saveCVPixelBuffer420YpCbCr8:withName:inFolder:error:]
ERROR: Could not save 420YpCbCr8 buffer
Could not create data provider.
Could not create image.
Could not create image destination.
Could not finalize image.
+[ImageTools extractLumaFromBGRA8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toBuffer:withBytesPerRow:]
+[ImageTools create420YCbCr8BufferFromPlanar8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:]
+[ImageTools create420YCbCr8BufferFromRGB8Buffer:withWidth:andWithHeight:andWithBytesPerRow:andAlphaFirst:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:]
+[ImageTools createRGB8BufferFrom420Y8PlanarBuffer:withBytesPerRowY:andFrom420Cb8Buffer:withBytesPerRowCb:andFrom420Cr8Buffer:withBytesPerRowCr:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:]
+[ImageTools createRGB8BufferFrom420Y8BiPlanarBuffer:withBytesPerRowLuma:andFrom420CbCr8Buffer:withBytesPerRowChroma:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:]
chart.model.sinusoidal
y = %@ * sin(%@x + %@) + %@
%@: %@
Prominent Object Detector
v32@?0@"VNRectangleObservation"8Q16^B24
VNGenerateAttentionBasedSaliencyImageRequest
kAXMChartSeriesKey
kAXMChartXAxisKey
kAXMChartYAxisKey
kAXMChartAdditionalAxesKey
kAXMChartTitleKey
kAXMChartSummaryKey
kAXMChartContentDirectionKey
kAXMChartContentFrameKey
kAXMChartSeriesNameKey
kAXMChartSeriesContinuousKey
kAXMChartSeriesXDataKey
kAXMChartSeriesYDataKey
kAXMChartSeriesZNumericDataKey
kAXMChartSeriesZCategoricalDataKey
kAXMChartSeriesLabelDataKey
kAXMChartSeriesValueDescriptionsKey
kAXMChartSeriesMeanValueDescriptionKey
kAXMChartAxisTitleKey
kAXMChartAxisType
categorical
numeric
kAXMChartNumericAxisScaleTypeKey
kAXMChartNumericAxisLowerBoundKey
kAXMChartNumericAxisUpperBoundKey
kAXMChartNumericAxisGridlinePositionsKey
kAXMChartCategoryAxisCategoriesKey
@"NSString"16@?0d8
<%@ %p title=%@ bounds=[%@, %@], gridlines=%@>
<%@ %p title=%@ order=%@>
%@%@
label=%@
desc=%@)
@16@?0@"AXMDataPoint"8
@"NSNumber"16@?0@"AXMDataPointValue"8
<%@ %p name=%@ continuous=%@ points=%@>
<%@ %p
title=%@
summary=%@
Axes:
%@Series:
v16@?0@"AXMDataRegressionModel"8
d16@?0d8
Trying ANE backend: %@
ANE unavailable/did not compile, falling back to MPS backend
face
human_body
head
aeroplane
bicycle
bird
boat
bottle
chair
dining_table
horse
motorbike
potted_plant
sheep
sofa
train
tv_monitor
food
drink
logits_pos_%ld
logits_neg_%ld
logits_%ld
offsets_%ld
logits_roll_%ld
logits_yaw_%ld
boxes
timing
Invalid input
Intermediate buffer allocation failed
Barcode
v32@?0@"VNRequest"8Q16^B24
@"NSError"16@?0@"AXMetric"8
VN PerformRequests
Vision:
VNProcessingDevice
screenCapture
text
axElement
AXMFeatureTextRecognition
AXMFeatureRange
VNRecognizedText
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
VNFaceLandmarks2D
recognitionLevel
normalizedMinimumTextHeightRatio
usesLanguageCorrection
textDetectionLocales
postProcessingOptions
AXMTextDetectionOptions<%p>
  Options: 
    Recognition Level: %@
Fast
Accurate
    Minimum Text Height Ratio: %.3f
    Use Language Correction: %ld
    Detection Languages: %@
    Apply Semantic Text Filtering: %ld
height
width
numberOfDiscretePinHeights
hasConsistentHorizontalPinSpacing
hasConsistentVerticalPinSpacing
verticalPinSpacing
horizontalPinSpacing
interCellHorizontalSpacing
interCellVerticalSpacing
verticalPinSpacing and horizontalPinSpacing are required if cell spacing is not uniform.
AXMBrailleCanvasDescription<%p>
    Size(%ld, %ld)
    numberOfDiscretePinHeights: %ld
        verticalPinSpacing: %.2f
        horizontalPinSpacing: %.2f
        interCellHorizontalSpacing: %.2f
        interCellVerticalSpacing: %.2f
canvasDescription
zoomLevel
origin
edgeStrength
invert
AXMBrailleEdgeDetectorOptions<%p>
    CanvasDescription: %@
    zoomLevel: %.2f
    origin: %@
    edgeStrength: %.2f
clientID
includeImageInResult
detectText
textDetectionOptions
detectScenes
detectObjects
detectNSFW
detectSignificantEvents
detectModelClassifications
detectCaptions
detectTraits
detectFaceRectangles
detectFaceNames
detectFaceAttributes
detectFaceExpressions
detectFaceLandmarks
detectFacePose
detectHorizon
detectRectangles
detectProminentObjects
detectAesthetics
detectIconClass
detectBrailleEdges
brailleEdgeOptions
detectAXElements
ignoredLayerContextIDs
includedLayerContextIDs
preserveInputImageSize
preferredOutputLocale
AXMVisionAnalysisOptions<%p>. Client: %ld
  Detectors:
    Traits: %ld
    Faces: %ld
    Text: %ld
    Scenes: %ld
    Objects: %ld
    NSFW: %ld
    Significant Events: %ld
    Model Classifications: %ld
    Captions: %ld
    Prominent Objects: %ld
    Aesthetics: %ld
    Face names: %ld
    Face rectangles : %ld
    Face attributes : %ld
    Icon Classifications: %ld
    Braille Edges: %ld
    AXElement Detection: %ld
  Preserve Input Image Size: %ld
  Preferred Output Locale: %@
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
Speech
Sounds
Haptics
[%@] usesPrivateAudioSession=%ld hapticEngineUsesAutoShutdown=%ld hapticEngineAutoShutdownTimeout=%.2f hapticEngineUsesHapticsOnly=%ld
chart.model.linear
y = %@x + %@
labelProbability
label
SelectedCheckboxFromIcon
NSFW Explicit
Blood
Demonstration
Destruction
Fire Devastation
Flood Devastation
Funeral
Hospital
Religious Setting
Vehicle Crash
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureRecognizedText
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureIsLowConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceDetectionResult
AXMFeatureFaceID
AXMDeviceMotion
AXMFeatureDeviceOrientation
AXMFeatureCameraType
AXMFeatureModelID
AXMFeatureAesthetics
AXMFeatureUserContext
AXMFeatureCodingKeyUIClass
AXMFeatureGates
AXMCaptionMayContainSensitiveContent
AXMVisionFeatureCodingKeyDetectorSceneClassIds
AXMVisionFeatureCodingKeySceneClassId
AVMetadataVideoPreviewHistogramObject
classificationLocalizedValue
classificationLabel
caption
translatedCaption
subfeatures
color info
asset metadata
Top left
Top right
Right
Center
Left
Bottom left
Bottom
Bottom right
Outside top left
Outside top
Outside top right
Outside right
Outside left
Outside bottom left
Outside bottom
Outside bottom right
centered
near.left.edge
near.top-left.edge
near.top.edge
near.top-right.edge
near.right.edge
near.bottom-right.edge
near.bottom.edge
near.bottom-left.edge
outside.left
outside.top-left
outside.top
outside.top-right
outside.right
outside.bottom-right
outside.bottom
outside.bottom-left
.implicit-subject
Document
Region
Line
Char
Diacrit
Table
Incomplete Table
Column
Cell
Nutrition Label
Envelope
Envelope Region
Receipt
Cell Header
Picture
Picture:Button
Icon
Icon:Button
Container
TextField
PageControl
Checkbox:NotSelected
Checkbox:Selected
Slider
TabBar
SegmentedControl
Switch:On
Switch:Off
Text
Text:Button
TabBar:Button
Dialog
Brightness
Blur
Color
Face
RealtimeFace
Person
SceneClassification
NSFW
SignificantEventClassification
ObjectClassification
ModelClassifier
Caption
MediaLegibility
AssetMetadata
Horizon
Rectangle
AXElement
Motion
CameraMetadata
ProminentObject
IconClass
Sequence
Character
Diacritic
AXMVisionFeature<%p> %@
uiClass:%@ 
value:%@ 
face id: %lu 
Name: %@ 
[faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
Face Attributes : %@
Face location: %@
value:'%@' type:%@ 
classificationLabel:'%@' localizedName:'%@' sceneClassID:'%@' detectorSceneClassIds:'%@' 
classificationLabel:'%@' 
ModelID: '%@' classificationLabel: '%@' 
caption: '%@' translated: '%@' 
value:'%.2f' 
value:'%@' 
asset info [%@] 
horizon transform. angle: %f 
deviceMotion: %@
front-facing
back-facing
camera: %@
location : %@
frame:%@ (normalized:%@) 
confidence:%.2f lowConfidence:%ld 
Alex
%d x %d
%.6f
Subclasses must override %@
q24@?0@"AXMPoint"8@"AXMPoint"16
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
com.apple.cvml.%@
CVML module = %@
overrideModelURL
overrideScaleMethod
genderStrategy
sceneDetector
Caption Detector
taxonomyOptions
Scene Detector
VNSceneClassificationRequest
chart.model.logarithmic
y = %@ * ln(x) + %@
AXMNodeID
AXNodeEnabled
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu>
Significant Events Detector
VN6Mb1ME89lyW3HpahkEygIG
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
Input file URL does not exist: %@
VoiceOver
object
trait
prominentObjects
SignificantEvent
captions
use init()
targetLocale
lowConfidence
diagram
envelope
receipt
Library/Accessibility
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
last.string.to.append.in.a.sentence
AXDateFormatter
{CGVector=dd}
<%@ %p frequency=%.2f timeOffsetMS=%.2f
Init fail -- use designated initializer
AXMediaUtilities.AXBoundingBox
init()
AXMediaUtilities.AXMElementDetectorResult
AXMediaUtilities.AXMClickabilityDetectorResult
_TtC16AXMediaUtilities13AXBoundingBox
@36@0:8@16f24@28
@16@0:8
v16@0:8
heat
angle
rect
classIndex
heatByClass
firstSeen
lastSeen
depth
centroid3d
knownFeaturePoints
physicalSize
description
T@"NSString",N,R
_TtC16AXMediaUtilities24AXMElementDetectorResult
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
q16@0:8
d16@0:8
labelName
_TtC16AXMediaUtilities29AXMClickabilityDetectorResult
Swift/Dictionary.swift
Swift/NativeDictionary.swift
Fatal error
Duplicate values for key: '
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
offset element 
Could not fetch uncompiled photo caption models: %@
Could not evaluate. VNDetectHorizonRequestSoft was nil
input arrays must be same length
Unhandled mapping for AXMVisionFeatureAgeCategory
Unhandled mapping for AXMVisionFeatureGenderCategory
Unhandled mapping for AXMVisionFeatureEyesCategory
Unhandled mapping for AXMVisionFeatureHairColorCategory
Unhandled mapping for AXMVisionFeatureGlassesCategory
Unhandled mapping for AXMVisionFeatureMakeupEyesCategory
Unhandled mapping for AXMVisionFeatureMakeupLipsCategory
Unhandled mapping for AXMVisionFeatureFacemaskCategory
Unhandled mapping for AXMVisionFeatureEthnicityCategory
Unhandled mapping for AXMVisionFeatureExpressionCategory
Unhandled mapping for AXMVisionFeatureFaceHairV2Category
Unhandled mapping for AXMVisionFeatureHairtypeCategory
Unhandled mapping for AXMVisionFeatureHeadgearCategory
Unhandled mapping for AXMVisionFeaturePoseCategory
Unhandled mapping for AXMVisionFeatureSkintoneCategory
Could not evaluate. VNDetectFaceExpressionsRequestSoft was nil
AXMFaceDetectorNode: no requests to evaluate
Could not evaluate. VNClassifyImageAestheticsRequestSoft was nil
AXMService being deallocated: %@
Connection to service interrupted. client: %@
Connection to service invalidated. client: %@
Failed to get service proxy: %@
Could not produce URL for soundID: %@
Could not make soundAction url does not exist: %@
Could not make sound. Action url does not exist: %@
Model Detector not available on this platform
Could not evaluate. VNImageScoreObservationSoft was nil
Could not evaluate. VNImageBrightnessObservationSoft was nil
Could not evaluate. VNImageBlurObservationSoft was nil
Could not evaluate. requestHandler was nil
Could not evaluate: %@
Need to define mlModelClasses for subclass of AXMMobileAssetEvaluationNode
Need to define an mobileAssetType for subclass of AXMMobileAssetEvaluationNode
Need to define modelResourceNames for subclass of AXMMobileAssetEvaluationNode
Need to define an minSupportedFormatVersion for subclass of AXMMobileAssetEvaluationNode
Retrieved assets: %@
Supported assets: %@ %@ %@
Found download node asset: %@
Adding model URLS: %@
Adding base URLS: %@ -> %@
No base URL, resetting model URLs
Can't load model: %@
Made model: %@ %@
Failed to create caption personalization regex: %@
Cannot modify caption for sensitive content. unexpected category: %@
Queueing remote evaluation of %@
Received remote evaluation for %@
Recived error for remote evaluation: %@
Source: %@
engine threshold priority: %ld
   node <%p> :'%@'. boosted priority:%ld
highest priority node(s): %@
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
Will run detector: %@
Will not run detector '%@' due to previous error set in context: %@
With priority scheduling, there can be at most 1 evaluation node per cycle
Will begin image evaluation. %@
Invoking remote result handler for error: %@
Invoking remote result handler for result
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
Current task is not nil but we're resetting it
AXMVisionEngine: event occurred: %d
AXMVisionEngine: service indicated it went invalid. clearing client-side tasks
A context must be provided
A source must be provided
AXMVisionEngine: canceling queued task to replace with newer incoming task
AXMVisionEngine: ignoring task since queue is full (maximumQueueSize = %ld)
AXMCameraFrameContext motionCorrectedNormalizedFrame received invalid input
userContext class %@ not in AXMSecureCodingClasses()
pipelineMetric accessed before being created. This will certainly lead to unexpected behavior
Could not evaluate. VNRecognizeTextRequestSoft was nil
Will not perform text detection. No effective languages resolved
Text detection error occurred: %@
Unable to convert detected text into document. Input image unexpectedly nil
Unable to convert detected text into document: %@
Will detect text with options: %@
textDetectionLocales unexpectedly empty! falling back to en-US
Could not get supported text detection languages: %@
task should not be in the completed state
Task is marked complete: %@ -> %d
taskIsBeingProcessed should be YES
taskIsBeingProcessed should be NO
Task should not be complete if being marked as complete
AXMPhotoAssetData: Could not fetch Photo Library using the photo library URL : %@ error: %@
AXMPhotoAssetData: PhotoLibrary Authorization Failure - Image resource load will not be available : %@
AXMPhotoAssetData: Unable to load image data
Could not evaluate. VNDetectRectanglesRequestSoft was nil
handleRequest: expected nil completion block
speech started: '%@'
speech finished: '%@'
didFinish: expected completion block, but found nil.
speech canceled: '%@'
didCancel: expected completion block, but found nil.
speech paused: '%@'
speech resumed: '%@'
Cannot add output '%@' to session '%@'
AXMAVCaptureSessionNode already has a AVCaptureSession attached
Capture session '%@' already has output '%@'
Error updating audio session: %@
Session interruption (%@). Resume? %d
Route Changed. Reason: %@
Media services lost
Media services reset
Should silence secondary audio (%@)
Pixel create: %d
Could not creat pixel buffer: %d
Result found for key: %p. moving to newest position
set nil result. removing key: %p. %ld items remain
set new result. adding key: %p. %ld items remain
cache size too big. evicted key: %p. %ld items remain
purge cache of all keys
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
legibility event: %@
Did time out waiting for image caption asset refresh. timeWaited:%.2f timeout:%.2f
Could not load AXImageCaptionModel at %@. error: %@
ImageCaptionAssetManager. didFinishRefreshingAssets: (%@). error: %@
ImageCaptionAssetManager. No compatible installed asset found
ImageCaptionAssetManager. asset controller setting model baseURL after asset refresh: %@
Failed to archive expressionsAndConfidence data: %@
Error decoding face expression dict: %@
Could not load iconclassification.mlmodelc in the bundle resource
Could not evaluate. VNClassifyNSFWImageRequestSoft was nil
AXMGeometryUtilities motionCorrectedNormalizedFrame received invalid input
Could not look up supported identifiers for VNRecognizeObjectsRequest
Could not evaluate. VNRecognizeObjectsRequestSoft was nil
Object Detector not supported on this platform
AXMLElementDetectorNode
AXMLElementDetectorNode-ScreenEquivalence
Same equivalence token - no work to do
Beginning element detection:
ERROR: zero image dimension
Effective text detect languages: %@
Performing OCR: %d, %@
Time to OCR: %f
OCR error: %@
OCR Results: %@
Icon detected: %@ for bounds %@ in image: %@ -> %@
OCR: %@
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
  Next cell: %@
  Adding cell to row
  Adding cell to headeer
  Adding cell to column
Will assemble table...
  Next row: %@
  Adding row to table
  Creating new table with header
  Next column: %@
  Adding column to table
Will assemble label...
  Adding row to label
  Creating new label with header
Will assemble receipt...
  Adding row to receipt
  Creating new receipt
Could not evaluate. VNTranslationalImageRegistrationRequestSoft was nil
Could not evaluate. VNImageTranslationAlignmentObservationSoft was nil
Equivalence tokens %@ %@
Equivalence token is the same
Feature results: %@
Time to Coagulate: %f
Sorted results
Sorted results: %@
No sorted features
Rect: %@, orientation: %@, generation: %@
ML Gen: %d Receieved remote handler reply %@/%@
Handling results for ML detection for gen: %d
ML Elements same screen capture - ignoring results
Could not create CGDataProviderRef for URL: %@
Could not find ml model classes, returning default: %@
Icon Class detector had no base URL
Error icon vision prediction: %@
Determined label class for icon: %@ (%@)
Error compiling pattern '%@' : %@
Error creating data detector: %@
input text: %@
will enumerate tags for scheme: %@. options: all
  %@ -> %@
  WARNING: Unhandled NLToken: %@ -> %@
  WARNING: Unhandled Data Detector: %@ -> %@
remaining:[%ld %ld] word:%ld lexicon:%ld whitespace:%ld
semanticallyComplete:%ld speechText: '%@'
lex #%ld: '%@' flags:%lu prob:%.2f partialProb:%.2f usageCount:%u
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Could not evaluate. VNCreateSceneprintRequestSoft was nil
Chart descriptor has no series, can't render sonification
Error initalizing audio unit
Error initializing audio component
Error setting audio format
Error setting output callback
error starting audio output: %@
Did get KVO update for key: '%@'. change: %@
%@ %@ -- %@ %@
AXMDisplayManager initialized: %@
Unable to look up screenInfo
Unable to look up screen scale
Display settings after update from CADisplay.mainDisplay: %@
Unexpected physical screen orientation
Display settings after update from FB configuration: %@
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
AX: Export Session status: %ld %@
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
Error retrieving caption: %@
Error setting caption: %@
unknown file type: UTI: %@, extension: %@
Could not evaluate. VNGenerateAttentionBasedSaliencyImageRequestSoft was nil
Could not evaluate. VNProcessingDeviceSoft was nil
Error decoding face landmark dict: %@
Failed to archive face landmark results: %@
Initializing output manager with config: %@
Could not de-activate audio session: %@
Could not activate audio session: %@
Ignoring dispatch request. Output manager not ready
Source node not connected to any engine
Error: unhandled AVMetadataObject %@
Error decoding subfeatures array: %@
Error decoding recognizedTextFeatures array: %@
Failed to archive subfeature data: %@
Failed to archive text recognition data: %@
Error: %@
Failed to find bounding box for text: %@ and range: %@
Caption Detection not available
Could not evaluate. VNSceneClassificationRequestSoft was nil
Scene Detector not supported on this platform
Error starting audio engine: %@
Unexpected state change. from %@. to %@
Could not handle audio request: %@. Error:%@
Could not begin active sound playback: %@
One-shot sound player did finish playing sound
Could not start engine: %@
Subclass should override
Could not evaluate. VNClassifySignificantEventRequestSoft was nil
Failed to create AXMediaUtilities working directory at path: %@. error: %@
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Photos.framework/Photos
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/UIKit.framework/UIKit
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
SaySfG
ySfG
ySfGG
ySfG
$ss12IdentifiableP
$ss12CaseIterableP
$sSY
So8NSObjectC
SfSg
ySfGSg
ySfGGSg
ySfGSg
ySfG
ySfG
ySiG
SnySiG
ySfGG
ySfGG
yyXlG
ySfG
ySnySiGG
ySiG
ySo8NSNumberCG
AllCases
RawValue
heat
angle
rect
classIndex
heatByClass
firstSeen
lastSeen
depth
centroid3d
knownFeaturePoints
physicalSize
checkboxNotSelected
checkboxSelected
container
dialog
icon
pageControl
picture
segmentedControl
slider
tabBar
text
textfield
toggleNotSelected
toggleSelected
containerClickable
containerNotClickable
iconClickable
iconNotClickable
pictureClickable
pictureNotClickable
textClickable
textNotClickable
label
labelName
confidence
origin
size
width
height
AXMScreenGrabber
AXMAssetManager
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMVisionFeatureFaceAttributes
AXMSinglePitchTone
AXMFaceDetectorNode
AXMImageAestheticsNode
AXShotflowDetector
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMOutputRequest
AXMOutputRequestHandle
AXMDataRegressionModelExponential
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMMobileAssetEvaluationNode
AXMDescriptionBuilder
AXMCIMorphologyRectangle
AXMCIMorphologyRectangleMaximum
AXMCIMorphologyRectangleMinimum
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMTaskDispatcherDelegate
AXMServiceDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMTextSpecialCase
AXMCameraFrameContext
AXMSynthPatch
AXMFunctionTone
AXMVisionPipelineContext
AXMTextDetectorNode
AXMIconVisionEngine
AXMTaskDispatcher
AXMTask
AXElementVision__generated__Input
MLFeatureProvider
AXElementVision__generated__Output
AXElementVision__generated__
AXMPhotoAssetData
AXMADSREnvelope
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAudioDataSourceMixer
AXMAVCaptureSessionNode
AVCaptureVideoDataOutputSampleBufferDelegate
AXMAVCaptureSessionNodeFrameDelegate
AXMAudioSession
AXMOutputComponent
AXShotflowHelpers
AXMVisionResult
AXMVisionEngineLookupConvenience
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMImageCaptionModelAssetManager
AXAssetControllerObserver
AXMVisionFeatureFaceDetectionResult
iconclassificationInput
iconclassificationOutput
iconclassification
AXMTaxonomyNode
AXMNSFWDetectorNode
AXMGeometryUtilities
AXMAVUtilities
AXMSequenceRequestManager
AXMObjectDetectorNode
Prediction
AXMAXElementDetectorNode
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMLayoutCell
AXMLayoutRow
AXMLayoutHeader
AXMLayoutColumn
AXMLayoutTable
AXMLayoutNutritionLabel
AXMLayoutReceipt
AXMTextLayoutManager
AXMImageRegistrationNode
AXMCameraMetadataNode
AXMCaptureVideoDataOutput
AXMLocSupport
AXMExtras
AXMCompressor
AXMScreenRecognitionVisionProcessingResult
AXMVisionScreenRecognitionOptions
AXMScreenRecognitionCenter
AXMOutputAction
AXMSpeechOutputAction
AXMSoundOutputAction
AXMOneShotSoundOutputAction
AXMActiveSoundOutputAction
AXMOutputActionHandle
AXMActiveSoundOutputActionHandle
AXMPipelineContextInput
AXMIconClassDetectorNode
AXMMLElementGroup
AXMLTabButtonGroup
AXMLElementCoagulation
AXMindNetHelpers
AXMSemanticText
AXMSemanticTextFactory
_AXMSemanticTextCursor
AXMPixelBufferWrapper
AXMSceneprintBasedNode
AXMAssetMetadataNode
AXMDataSonifier
_AXMSettingObserver
AXMSettings
AXANFDDetectedObject
AXMBrailleEdgesDetectorNode
AXMVisionFeatureAssetMetadata
AXMVisionFeatureAestheticsResult
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMDataRegressionModelPower
AXMDataSummary
AXMindNetConfiguration
AXMCoreMotionNode
AXMAddressFormatter
AXMDataSonificationManager
AXMDataSonifierPlaybackObserver
AXMDataSummaryCategoryNameProvider
AXShotflowConfiguration
AXMLiveContinuousTone
ImageTools
AXMDataRegressionModelSine
AXElementDetection
AXVNEspressoDetectedObject
AXMProminentObjectsDetectorNode
AXMNumericDataAxisDescriptor
AXMChartDictionaryRepresentable
AXMDataAxisDescriptor
AXMCategoricalDataAxisDescriptor
AXMDataPointValue
AXMDataPoint
AXMDataSeriesDescriptor
AXMChartDescriptor
AXMScale
AXMNumericScale
AXMCategoricalScale
AXMDataAnnotation
AXShotflowNetwork
AXMBarcodeNode
AXMEvaluationNode
AXMAXElementVisionEngine
AXMAudioEffect
AXMVisionFeatureRecognizedText
AXMVisionFeatureFaceLandmarks
AXMTextDetectionOptions
AXMBrailleCanvasDescription
AXMBrailleEdgeDetectorOptions
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMOutputManagerConfiguration
AXMTone
AXMDataRegressionModelLinear
AXMSourceNode
SelectedCheckboxFromIcon__generated__Input
SelectedCheckboxFromIcon__generated__Output
SelectedCheckboxFromIcon__generated__
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
AXMPoint
AXMDataRegressionModel
AX_CVML_Error
AXMCaptionDetectorNode
AXMSceneDetectorNode
AXMActiveSound
AXMSoundComponent
AXMActiveSoundOutputActionHandleImpl
AXMActiveSoundOutputActionHandleProvider
AXMDataRegressionModelLogarithmic
AXMVisionEngineNode
AXMAudioDataSource
AXMSignificantEventDetectorNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMTranslatedText
AXMGeomerty
KeyPitch
AXMVariablePitchTone
startMeasure:
endMeasurement
grabScreenWithRect:orientation:options:metrics:error:
recordScreenForDuration:completion:
fileURLWithPath:
URLByAppendingPathComponent:
_modelsDirectoryForType:compiled:
_photoCaptionAssetsDirectory
_modelAssetURLsOfType:sources:compiled:
array
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
countByEnumeratingWithState:objects:count:
pathExtension
isEqualToString:
addObject:
URLByDeletingPathExtension
lastPathComponent
_modelAssetNamesOfType:sources:compiled:
_modelAssetURLForModelNamed:ofType:sources:compiled:
_uncompiledModelsDirectoryForType:
_compiledModelsDirectoryForType:
compiledModelAssetURLsOfType:sources:
uncompiledModelAssetURLsOfType:sources:
compiledModelAssetNamesOfType:sources:
uncompiledModelAssetNamesOfType:sources:
compiledModelAssetURLForModelNamed:ofType:sources:
uncompiledModelAssetURLForModelNamed:ofType:sources:
modelWithName:ofType:sources:compileIfNeeded:persistCompiledModel:error:
nodeInitialize
initWithCoder:
encodeWithCoder:
validateVisionKitSoftLinkSymbols
evaluate:metrics:
_detectHorizonRequest
_setDetectHorizonRequest:
arrayWithObjects:count:
evaluateRequests:withContext:requestHandlerOptions:metrics:error:
results
firstObject
size
featureWithVisionRequest:horizonResult:canvasSize:
appendFeature:
supportsSecureCoding
isSupported
title
requiresVisionFramework
.cxx_destruct
__detectHorizonRequest
T@"VNDetectHorizonRequest",&,N,S_setDetectHorizonRequest:,V__detectHorizonRequest
init
decodeObjectOfClasses:forKey:
setMainColors:weights:
mainColors
encodeObject:forKey:
mainColorWeights
count
setMainColors:
setMainColorWeights:
objectAtIndexedSubscript:
floatValue
TB,R
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
_remainingColorWeight
_mainColors
_mainColorWeights
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
Td,N,V_remainingColorWeight
ageCategory
label
identifier
_AXMAgeCategoryForVisionCategoryIdentifier:
confidence
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
_AXMGenderCategoryForVisionCategoryIdentifier:
eyesCategory
_AXMEyesCategoryForVisionCategoryIdentifier:
hairColorCategory
_AXMHairColorCategoryForVisionCategoryIdentifier:
glassesCategory
_AXMGlassesCategoryForVisionCategoryIdentifier:
makeupEyesCategory
_AXMMakeupEyesCategoryForVisionCategoryIdentifier:
makeupLipsCategory
_AXMMakeupLipsCategoryForVisionCategoryIdentifier:
facemaskCategory
_AXMFacemaskCategoryForVisionCategoryIdentifier:
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
_AXMEthnicityCategoryForVisionCategoryIdentifier:
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
_AXMExpressionCategoryForVisionCategoryIdentifier:
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
_AXMFaceHairV2CategoryForVisionCategoryIdentifier:
VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
_AXMHairtypeCategoryForVisionCategoryIdentifier:
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
_AXMHeadgearCategoryForVisionCategoryIdentifier:
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
_AXMPoseCategoryForVisionCategoryIdentifier:
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
_AXMSkintoneCategoryForVisionCategoryIdentifier:
axAgeCategory
encodeInteger:forKey:
axAgeCategoryConfidence
encodeFloat:forKey:
axGenderCategory
axGenderCategoryConfidence
axEyesCategory
axEyesCategoryConfidence
axSmilingCategory
axFaceHairCategory
axHairColorCategory
axHairColorCategoryConfidence
axBaldCategory
axGlassesCategory
axGlassesCategoryConfidence
axMakeupEyesCategory
axMakeupEyesCategoryConfidence
axMakeupLipsCategory
axMakeupLipsCategoryConfidence
axFacemaskCategory
axFacemaskCategoryConfidence
axEthnicityCategory
axEthnicityCategoryConfidence
axExpressionCategory
axExpressionCategoryConfidence
axFaceHairV2Category
axFaceHairV2CategoryConfidence
axHairTypeCategory
axHairTypeCategoryConfidence
axHeadgearCategory
axHeadgearCategoryConfidence
axPoseCategory
axPoseCategoryConfidence
axSkintoneCategory
axSkintoneCategoryConfidence
decodeIntegerForKey:
decodeFloatForKey:
dictionaryWithObjects:forKeys:count:
objectForKeyedSubscript:
integerValue
excludeOptions
_accessibilityLabelFormatterForHairColorCategory
_accessibilityLabelFormatterForHairTypeCategory
_accessibilityLabelFormatterBeginning
stringWithString:
_accessibilityLabelFormatterForPoseCategory
appendString:
_accessibilityLabelFormatterForAgeCategory
bundleWithIdentifier:
localizedStringForKey:value:table:
_accessibilityLabelFormatterForFaceHairV2Category
_accessibilityLabelFormatterForGlassesCategory
_accessibilityLabelFormatterForFaceMaskCategory
_accessibilityLabelFormatterForExpressionCategory
_accessibilityLabelForDemographics
_accessibilityLabelForHairDetails
_accessibilityLabelForFacialHairDetails
_accessibilityLabelForAccessoryDetails
_accessibilityLabelForExpressionDetails
axmArrayByIgnoringNilElementsWithCount:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
dictionary
_accessibilityIdentifierForPoseCategory
numberWithDouble:
setObject:forKeyedSubscript:
_accessibilityIdentifierForAgeCategory
_accessibilityIdentifierForGenderCategory
_accessibilityIdentifierForGlassesCategory
_accessibilityIdentifierForHairColorCategory
_accessibilityIdentifierForHairTypeCategory
_accessibilityIdentifierForFaceHairV2Category
_accessibilityIdentifierForHeadgearCategory
_accessibilityIdentifierForFacemaskCategory
_accessibilityIdentifierForExpressionCategory
_accessibilityIdentifierForEthnicityCategory
_accessibilityIdentifierForEyesCategory
_accessibilityIdentifierForMakeupEyesCategory
_accessibilityIdentifierForMakeupLipsCategory
_accessibilityIdentifierForSkintoneCategory
setExcludeOptions:
defaultExcludeOptions
unitTestingFaceAttributesForAge:gender:eyes:smiling:facialHair:hairColor:baldness:glasses:eyeMakeup:lipMakeup:faceMask:ethnicity:expression:facialHairV2:hairType:headGear:pose:skinTone:excludeOptions:
unitTestingFaceAttributes
initWithVisionFaceAttributes:
initWithAVMetadataFaceObject:
accessibilityLabelForAttributes
accessibilityLabelAndConfidenceMappingForAttributes
setAxAgeCategoryConfidence:
setAxGenderCategoryConfidence:
setAxEyesCategoryConfidence:
setAxHairColorCategoryConfidence:
setAxGlassesCategoryConfidence:
setAxMakeupEyesCategoryConfidence:
setAxMakeupLipsCategoryConfidence:
setAxFacemaskCategoryConfidence:
setAxEthnicityCategoryConfidence:
setAxExpressionCategoryConfidence:
setAxFaceHairV2CategoryConfidence:
setAxHairTypeCategoryConfidence:
setAxHeadgearCategoryConfidence:
setAxPoseCategoryConfidence:
setAxSkintoneCategoryConfidence:
setResults:
_axAgeCategory
_axAgeCategoryConfidence
_axGenderCategory
_axGenderCategoryConfidence
_axEyesCategory
_axEyesCategoryConfidence
_axSmilingCategory
_axFaceHairCategory
_axHairColorCategory
_axHairColorCategoryConfidence
_axBaldCategory
_axGlassesCategory
_axGlassesCategoryConfidence
_axMakeupEyesCategory
_axMakeupEyesCategoryConfidence
_axMakeupLipsCategory
_axMakeupLipsCategoryConfidence
_axFacemaskCategory
_axFacemaskCategoryConfidence
_axEthnicityCategory
_axEthnicityCategoryConfidence
_axExpressionCategory
_axExpressionCategoryConfidence
_axFaceHairV2Category
_axFaceHairV2CategoryConfidence
_axHairTypeCategory
_axHairTypeCategoryConfidence
_axHeadgearCategory
_axHeadgearCategoryConfidence
_axPoseCategory
_axPoseCategoryConfidence
_axSkintoneCategory
_axSkintoneCategoryConfidence
_excludeOptions
_results
T@"NSDictionary",&,N,V_results
Tq,R,N,V_axAgeCategory
Td,N,V_axAgeCategoryConfidence
Tq,R,N,V_axGenderCategory
Td,N,V_axGenderCategoryConfidence
Tq,R,N,V_axEyesCategory
Td,N,V_axEyesCategoryConfidence
Tq,R,N,V_axSmilingCategory
Tq,R,N,V_axFaceHairCategory
Tq,R,N,V_axHairColorCategory
Td,N,V_axHairColorCategoryConfidence
Tq,R,N,V_axBaldCategory
Tq,R,N,V_axGlassesCategory
Td,N,V_axGlassesCategoryConfidence
Tq,R,N,V_axMakeupEyesCategory
Td,N,V_axMakeupEyesCategoryConfidence
Tq,R,N,V_axMakeupLipsCategory
Td,N,V_axMakeupLipsCategoryConfidence
Tq,R,N,V_axFacemaskCategory
Td,N,V_axFacemaskCategoryConfidence
Tq,R,N,V_axEthnicityCategory
Td,N,V_axEthnicityCategoryConfidence
Tq,R,N,V_axExpressionCategory
Td,N,V_axExpressionCategoryConfidence
Tq,R,N,V_axFaceHairV2Category
Td,N,V_axFaceHairV2CategoryConfidence
Tq,R,N,V_axHairTypeCategory
Td,N,V_axHairTypeCategoryConfidence
Tq,R,N,V_axHeadgearCategory
Td,N,V_axHeadgearCategoryConfidence
Tq,R,N,V_axPoseCategory
Td,N,V_axPoseCategoryConfidence
Tq,R,N,V_axSkintoneCategory
Td,N,V_axSkintoneCategoryConfidence
Tq,N,V_excludeOptions
initWithFrequency:sampleRate:envelope:
initWithSampleRate:envelope:
_setFrequency:
envelope
lengthMS
sampleRate
_rawValueForTonePhase:
levelForTime:
gain
frequency
renderInBuffer:atFrame:
uuid
_faceResultForUUID:inFaceDictionary:
faceId
setFaceId:
setUuid:
boundingBox
setFrame:
setRectanglesConfidence:
faceAttributes
setAttributes:
attributes
setAttributesConfidence:
expressionsAndConfidence
setExpressionsAndConfidence:
landmarks
initWithVisionFaceLandmarks:
setLandmarks:
landmarks3d
setLandmarks3d:
setLandmarksConfidence:
pose
setPose:
setPoseConfidence:
enumerateObjectsUsingBlock:
_createRequestsForContext:
_faceDetectionResultsForVisionRequests:canvasSize:
featureWithFaceDetectionResult:canvasSize:
enumerateKeysAndObjectsUsingBlock:
addEvaluatedFeatureType:
UUIDString
_faceRectanglesRequest
set_faceRectanglesRequest:
_faceprintRequest
set_faceprintRequest:
_faceAttributesRequest
set_faceAttributesRequest:
_faceExpressionsRequest
set_faceExpressionsRequest:
_faceLandmarksRequest
set_faceLandmarksRequest:
_facePoseRequest
set_facePoseRequest:
__faceRectanglesRequest
__faceprintRequest
__faceAttributesRequest
__faceExpressionsRequest
__faceLandmarksRequest
__facePoseRequest
T@"VNDetectFaceRectanglesRequest",&,N,V__faceRectanglesRequest
T@"VNCreateFaceprintRequest",&,N,V__faceprintRequest
T@"VNClassifyFaceAttributesRequest",&,N,V__faceAttributesRequest
T@"VNDetectFaceExpressionsRequest",&,N,V__faceExpressionsRequest
T@"VNDetectFaceLandmarksRequest",&,N,V__faceLandmarksRequest
T@"VNDetectFacePoseRequest",&,N,V__facePoseRequest
_imageAestheticsRequest
set_imageAestheticsRequest:
configureForRunningOnANEIfPossibleWithRequest:
featureWithImageAestheticsObservation:
__imageAestheticsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V__imageAestheticsRequest
cpuNetworkWithModelPath:configuration:version:modelType:
nmsThreshold
filterThresholds
initWithNetwork:nmsThreshold:filterThreshold:
gpuNetworkWithModelPath:configuration:preferredMetalDeviceID:version:modelType:
threshold
setThreshold:
predicateWithBlock:
filteredArrayUsingPredicate:
sortDescriptorWithKey:ascending:
sortedArrayUsingDescriptors:
overlap:
osfsThreshold
osfsSizeRatio
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
mergeHeadsThreshold
iOa:
olmcsThreshold
olmcsMergeCountDelta
mergesCount
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
defaultBox
scale
hasLabel
labelName
initWithBox:defaultBox:confidence:scale:mergesCount:hasLabel:label:labelName:
smartThreshold
smartDistanceFactor
boxCenter
modelType
version
processCIImage:
nmsBoxes:
filterBoxes:
enforceSquareFaces:withHeight:andWidth:
mergeHeadsBoxes:
cpuDetectorWithModelPath:configuration:version:
gpuDetectorWithModelPath:configuration:preferredMetalDeviceID:version:modelType:
overlappingSmallFacesSuppression:
overlappingLowMergeCountSuppression:
mergeBoxes:
smartMergeBoxes:
detect:
processBoxes:withHeight:andWidth:
overlap_threshold
setOverlap_threshold:
filterThreshold
setFilterThreshold:
setNmsThreshold:
setMergeHeadsThreshold:
setOsfsThreshold:
setOsfsSizeRatio:
setOlmcsThreshold:
setOlmcsMergeCountDelta:
setSmartThreshold:
setSmartDistanceFactor:
_network
_overlap_threshold
_nmsThreshold
_mergeHeadsThreshold
_osfsThreshold
_osfsSizeRatio
_olmcsThreshold
_olmcsMergeCountDelta
_smartThreshold
_smartDistanceFactor
_filterThreshold
Tf,N,V_overlap_threshold
Tf,N
T@"NSArray",&,N,V_filterThreshold
Tf,N,V_nmsThreshold
Tf,N,V_mergeHeadsThreshold
Tf,N,V_osfsThreshold
Tf,N,V_osfsSizeRatio
Tf,N,V_olmcsThreshold
Ti,N,V_olmcsMergeCountDelta
Tf,N,V_smartThreshold
Tf,N,V_smartDistanceFactor
invalidate
_destroyXPCConnection
dealloc
initWithServiceName:
setRemoteObjectInterface:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
delegate
axMediaUtilitiesService:eventOccurred:
setInterruptionHandler:
setInvalidationHandler:
resume
xpcConnection
remoteObjectProxyWithErrorHandler:
_serviceProxy
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
setDelegate:
setXpcConnection:
_xpcConnectionQueue
_delegate
_xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
T@"<AXMServiceDelegate>",W,N,V_delegate
initWithString:
copy
actions
handle
addActionHandle:
initWithText:
_addAction:
initWithSoundID:
initWithURL:
speechItemSeparator
speechActions
oneShotSoundActions
activeSoundActions
addSpeechItem:
addSoundItemWithID:
addSoundItemWithURL:
addActiveSoundItemWithID:
addActiveSoundItemWithURL:
completionBlock
setCompletionBlock:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
_handle
_queue
_queue_actions
_interruptsAndClearsQueue
_completionBlock
T@"AXMOutputRequestHandle",R,N,V_handle
T@"NSArray",R,N
T@?,C,N,V_completionBlock
TB,N,V_interruptsAndClearsQueue
actionHandles
_actionHandles
setUsesSignificantDigits:
setMaximumSignificantDigits:
stringFromNumber:
stringWithFormat:
modelDescription
modelFunction
modelParameterCount
getInitialParams:
partialDerivatives
modelFunctionStringForParameters:significantFigures:
dataSatisfiesInitialConditions
decodeObjectForKey:
path
preloadModelIfNeeded:
modelURL
setModelURL:
modelIdentifier
_modelURL
_modelIdentifier
T@"NSURL",&,N,V_modelURL
T@"NSString",R,N,V_modelIdentifier
setShouldProcessRemotely:
AXMRectValue
analysisOptions
ignoredLayerContextIDs
includedLayerContextIDs
preserveInputImageSize
screenGrabber
pipelineMetric
inputWithCIImage:
produceImage:
defaultOptions
axmValueWithCGRect:
numberWithInteger:
areDiagnosticsEnabled
numberWithBool:
contextWithSourceParameters:options:
triggerWithContext:cacheKey:resultHandler:
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
shouldEvaluateColorInformation
_evaluateColorInformation:
visionImageRequestHandler
performRequests:error:
_blurValueForVisionObservation:
featureWithVisionRequest:blurValue:canvasSize:
brightness
numberWithFloat:
exposureScore
blurMeasure
blurScore
_brightnessValueForVisionObservation:
sampleFrequency
setSampleFrequency:
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
Tq,N,V_sampleFrequency
TB,N,V_shouldEvaluateColorInformation
Td,N,V_colorDistanceTheshold
initWithIdentifier:
_downloadAssetsIfNecessary
modelURLs
removeAllObjects
addObjectsFromArray:
mobileAssetType
initWithType:
returnTypes:
setDoNotBlockBeforeFirstUnlock:
unsignedIntegerValue
minSupportedFormatVersion
maxSupportedFormatVersion
ax_filteredArrayUsingBlock:
numberWithUnsignedInteger:
contentVersionKey
compare:
sortedArrayUsingComparator:
lastObject
logAsset
state
startDownload:
modelResourceNames
getLocalFileUrl
setModelURLs:
subarrayWithRange:
purge:
startCatalogDownload:then:
queryMetaData:
mlModelClasses
initWithContentsOfURL:error:
formatVersion
mlModels
mobileAssetBaseURL
_formatVersion
_mlModels
_mobileAssetBaseURL
T@"NSArray",R,N,V_mlModels
T@"NSURL",R,N,V_mobileAssetBaseURL
_initWithOptions:
classificationLocalizedValue
classificationLabel
addDetectedClassificationLocalizedValue:forLabel:
length
_usesTemplateForLowConfidenceAndExplicitFeatures
isLowConfidence
isNSFW
string
_shouldReplaceCaptionWithGenericTemplate
_addGenericTemplateForCaptionInformationToDescription:
_addCaptionInformationToDescription:didConsumeDetectedFaceInfo:
_addBrightnessInformationToDescription:
_addBlurInformationToDescription:
_addFaceInformationToDescription:
_addClassificationInformationToDescription:
_addIconClassInformationToDescription:
buildSpeakableDescription
hasSuffix:
_stringForPauseType:
appendFormat:
_appendPauseType:toDescriptionIfNeeded:
_appendToDescription:afterPauseType:withContents:
blur
faceDetectionResult
name
allObjects
_knownPersonNames
localizedStringWithFormat:
localizedStringByJoiningStrings:
localizedStringFromNumber:numberStyle:
sortUsingComparator:
likelyExpression
objectForKey:
numberWithLong:
setObject:forKey:
allKeys
localizedStringFormatterForExpression:
_shouldSummarizeDetectedPeople
_addPersonSummaryToDescription:
_addDetailedFaceInformationToDescription:
translatedCaption
sharedInstance
targetLocale
localeBaseLanguageIsEnglish:
text
_shouldPersonalizeCaptionWithKnownPeople
initWithPattern:options:error:
matchesInString:options:range:
rangeWithName:
substringWithRange:
shouldModifyCaptionForSensitiveContent
primarySensitiveContentFeature
containsString:
stringByAppendingString:
bundleForClass:
pathForResource:ofType:
dictionaryWithContentsOfFile:
_templateRulesForTag:
boolValue
doubleValue
_subsumedTagsForTags:
_ignoredTagsForTags:
containsObject:
characterSetWithCharactersInString:
objectAtIndex:
lowercaseString
rangeOfCharacterFromSet:
axm_featureWithHighestConfidence
value
builderWithOptions:
addDetectedFaces:
addDetectedClassificationFeatures:
setDetectedCaption:
addDetectedIconClasses:
buildVisualDescription
blurFeature
setBlurFeature:
brightnessFeature
setBrightnessFeature:
setIsNSFW:
setShouldModifyCaptionForSensitiveContent:
setPrimarySensitiveContentFeature:
_builderOptions
_speakableDescription
_visualDescription
_faceFeatures
_classificationLabelsToLocValuesMap
_iconClassFeatures
_captionFeature
_isNSFW
_shouldModifyCaptionForSensitiveContent
_blurFeature
_brightnessFeature
_primarySensitiveContentFeature
T@"AXMVisionFeature",&,N,V_blurFeature
T@"AXMVisionFeature",&,N,V_brightnessFeature
TB,N,V_isNSFW
TB,N,V_shouldModifyCaptionForSensitiveContent
T@"AXMVisionFeature",&,N,V_primarySensitiveContentFeature
intValue
_isIdentity
_doMinimum
extent
emptyImage
numberWithInt:
vectorWithX:Y:
applyWithExtent:roiCallback:arguments:
customAttributes
outputImage
inputImage
setInputImage:
inputWidth
setInputWidth:
inputHeight
setInputHeight:
T@"CIImage",&,N,VinputImage
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputHeight
kernelWithString:
setCanReduceOutputChannels:
_commonInit
setIdentifier:
setAxMediaUtilsService:
axMediaUtilsService
initWithIdentifier:delegate:
setTaskDispatcher:
setSequenceRequestManager:
isEqualToEngine:
sourceNodes
evaluationNodes
archivedDataWithRootObject:requiringSecureCoding:error:
unarchivedObjectOfClass:fromData:error:
decodeObjectOfClass:forKey:
setMaximumQueueSize:
decodeBoolForKey:
setDiagnosticsEnabled:
setPrioritySchedulingEnabled:
setPrioritySchedulingAllowMultipleNodeExecution:
setThresholdPriority:
addSourceNode:
addEvaluationNode:
maximumQueueSize
encodeBool:forKey:
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
isCachingEnabled
cacheKey
_queue_handleEvaluatedContext:result:error:
shouldEvaluate:
detectText
detectScenes
detectObjects
detectNSFW
detectSignificantEvents
detectModelClassifications
detectCaptions
detectFaces
detectTraits
detectHorizon
detectRectangles
detectProminentObjects
detectIconClass
detectBrailleEdges
detectAXElements
detectAesthetics
isEnabled
_queue_shouldEvaluateNode:withOptions:
arrayWithCapacity:
boostEffectivePriority
effectivePriority
resetEffectivePriority
features
detectedFeatureDescriptionWithOptions:
detectedTextDescription
error
measure:execute:
sourceProvidesResults
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:prioritySchedulingAllowMultipleNodeExecution:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
setEvaluationExclusivelyUsesVisionFramework:
imageRegistrationFilteringEnabled
imageRegistrationState
minimumImageRegistrationSignalLevel
auxiliaryDetectors
removeAllAuxiliaryDetectors
result
disableResultLogging
_queue_logEvaluatedResult:
didFinishProcessingContext
cache
setResult:forKey:
resultHandlers
_invokeResultHandlers:withError:
shouldCallCompletionHandlersForEmptyResultSet
_invokeResultHandlers:withResult:
markAsComplete:
canAddSourceNode:
isConnected
connect:
insertObject:atIndex:
disconnect
removeObject:
canAddEvaluationNode:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
_queue_makeUniqueIdentifierForNode:
stringByReplacingOccurrencesOfString:withString:
_queue_nodeIdentifierExists:
_queue_addResultHandler:
_queue_removeResultHandler:
_queue_removeAllResultHandlers
cacheSize
initWithCacheSize:
setCache:
defaultCenter
postNotificationName:object:
requestForcedCleanupWithOptions:completion:
axmIndentationString:
axmDescription
axmAppendRecursiveDescription:withIndentation:
source
context
sequenceRequestManager
addResultHandlers:
_queue_shouldContinueWithoutResultHandlers:
willBeginProcessingContext
shouldProcessRemotely
_queue_remotelyEvaluateWithSource:context:
_queue_evaluateWithSource:context:
taskDispatcher
unscheduleAllTasks
scheduleTask:
_invokeFullQueueResultHandlersForContext:
itemWithSource:context:
shouldCallCompletionHandlersForEngineBusyError
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
diagnosticsEnabled:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
dispatcher:handleTask:
copyWithZone:
canAddSourceNodeClass:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
canAddEvaluationNodeClass:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
addSourceNodes:evaluationNodes:
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
nodeIdentifierExists:
addResultHandler:
removeResultHandler:
removeAllResultHandlers
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
setImageRegistrationFilteringEnabled:
setMinimumImageRegistrationSignalLevel:
setDisableResultLogging:
_queue_sourceNodes
_queue_evaluationNodes
_queue_imageRegistrationNode
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_prioritySchedulingEnabled
_prioritySchedulingAllowMultipleNodeExecution
_imageRegistrationFilteringEnabled
_diagnosticsEnabled
_disableResultLogging
_identifier
_maximumQueueSize
_thresholdPriority
_minimumImageRegistrationSignalLevel
_cache
_axMediaUtilsService
_taskDispatcher
_sequenceRequestManager
T@"NSString",C,V_identifier
T@"AXMService",&,N,V_axMediaUtilsService
T@"AXMVisionEngineCache",&,N,V_cache
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
T@"AXMSequenceRequestManager",&,N,V_sequenceRequestManager
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TB,V_prioritySchedulingAllowMultipleNodeExecution
TQ,V_thresholdPriority
TB,N,V_imageRegistrationFilteringEnabled
Tq,N,V_minimumImageRegistrationSignalLevel
TB,R,N
Tq,R,N
diagnosticsEnabled
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
TB,N,V_disableResultLogging
initWithSource:context:
setSource:
setContext:
UUID
_context
_source
T@"NSUUID",&,N,V_identifier
T@"AXMVisionPipelineContext",&,N,V_context
T@"AXMSourceNode",&,N,V_source
sortedFeatures
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
arrayWithObjects:
detectNutritionLabel:
componentsJoinedByString:
nutritionLabelKeywords
nutritionLabelKeywordCountMinimum
detectSpecialCase:preferredLocales:
decodeDoubleForKey:
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
encodeDouble:forKey:
deviceAttitude
motionCorrectedNormalizedFrame:fromAttitude:fromFieldOfViewX:fromFieldOfViewY:toAttitude:toFieldOfViewX:toFieldOfViewY:interfaceOrientation:mirrored:
initWithVideoFieldOfView:zoomFactor:sourceWidth:sourceHeight:presentationTimestamp:attitude:
motionCorrectedNormalizedFrame:targetAttitude:targetZoomFactor:interfaceOrientation:mirrored:
_videoFieldOfView
_videoZoomFactor
_videoSourceWidth
_videoSourceHeight
_presentationTimestamp
_deviceAttitude
Tf,R,N,V_videoFieldOfView
Tf,R,N,V_videoZoomFactor
Tq,R,N,V_videoSourceWidth
Tq,R,N,V_videoSourceHeight
Td,R,N,V_presentationTimestamp
T@"CMAttitude",R,N,V_deviceAttitude
setHarmonicInfos:
sinePatch
initWithHarmonics:
defaultPatch
squarePatch
trianglePatch
sawPatch
violinPatch
trapeziumPatch
waveformValueForPhase:frequency:amplitude:
harmonicInfos
_baseFrequency
_baseAmplitude
_harmonics
_amplitudes
_harmonicInfos
T@"NSArray",C,N,V_harmonicInfos
_xAxisValueForNormalizedPosition:
initWithUnivariateFunction:sampleRate:envelope:xAxisDescriptor:yAxisDescriptor:
function
xAxisDescriptor
yAxisDescriptor
_function
_xAxisDescriptor
_yAxisDescriptor
T@?,R,N,V_function
T{?=^dddddd},R,N,V_xAxisDescriptor
T{?=^dddddd},R,N,V_yAxisDescriptor
initWithSourceParameters:options:
setAnalysisOptions:
_commonInitWithDiagnosticsEnabled:
timeIntervalSinceReferenceDate
initWithName:measurementsEnabled:orEnabledByEnvironmentVariables:
setAppliedImageOrientation:
metricSession
measurementsEnabled
evaluatedFeatureTypes
appliedImageOrientation
userContext
effectiveTextDetectionLocales
inputType
ciImage
initWithCIImage:options:
pixelBuffer
orientation
initWithCVPixelBuffer:orientation:options:
initWithURL:options:
_makeRequestHandlerForInput:options:
errorOccurred:
setUserContext:
featureType
addFeatureGate:userInfo:
setEquivalenceToken:
_init
setFeatures:
setEffectiveTextDetectionLocales:
setEvaluatedFeatureTypes:
setMetricSession:
setImageRegistrationState:
includeImageInResult
generateImageRepresentation
setImage:
setError:
numberWithUnsignedInt:
imageWithCVPixelBuffer:options:
imageWithContentsOfURL:
orderedSet
generateReport
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
createSceneObservationIfNilWithBlock:
sceneObservation
sceneLabelsForOCRDocumentTypeDetection
addSceneLabelForOCRDocumentTypeDetection:
_addSignificantEventFeatureGateIfNeededToFeature:category:minimumConfidence:
generateFileNameForImageWithPrefix:extension:
sourceInput
addAuxiliaryDetector:
setCacheKey:
setShouldCallCompletionHandlersForEngineBusyError:
setShouldCallCompletionHandlersForEmptyResultSet:
evaluationExclusivelyUsesVisionFramework
sequenceID
setSequenceID:
setResult:
setVisionImageRequestHandler:
_sourceInput
_sourceParameters
_sourceProvidesOwnResults
_resultHandlers
_piplelineMetric
_sceneObservation
_sceneObservationQueue
_detectedSceneClassifications
_auxiliaryDetectors
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_effectiveTextDetectionLocales
_imageRegistrationState
_userContext
_cacheKey
_sequenceID
_metricSession
_features
_evaluatedFeatureTypes
_result
_appliedImageOrientation
_visionImageRequestHandler
T@"NSMutableArray",&,N,V_features
T@"NSMutableSet",&,N,V_evaluatedFeatureTypes
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
T@"AXMetricSession",&,N,V_metricSession
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
Tq,N,V_imageRegistrationState
T@"NSObject<NSSecureCoding>",&,N,V_userContext
T@"NSArray",&,N,V_effectiveTextDetectionLocales
TB,N,V_shouldProcessRemotely
T{CGSize=dd},R,N
T@"<NSCopying>",&,N,V_cacheKey
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_evaluationExclusivelyUsesVisionFramework
TQ,N,V_sequenceID
T@"AXMPipelineContextInput",R,N
T@"<AXMetricContainer>",R,N
recognitionLevelFromOptions:
textDetectionLanguagesFromOptions:
supportedDetectionLanguagesForLevel:
filterPreferredDetectionLanguages:withSupportedDetectionLanguages:
_textDetectionOptions:
effectiveLanguagesFromOptions:
initWithLocaleIdentifier:
ax_mappedArrayUsingBlock:
setRecognitionLanguages:
setRecognitionLevel:
usesLanguageCorrection
setUsesLanguageCorrection:
normalizedMinimumTextHeightRatio
setMinimumTextHeight:
setTaxonomyOptions:
_sequencesForObservations:canvasSize:
ax_flatMappedArrayUsingBlock:
specialCaseManager
textLayoutManager
documentWithNutritionLabel:canvasSize:requestHandler:metrics:error:
detectTextSkew:
documentWithReceipt:withTextSkew:canvasSize:preferredLocales:requestHandler:metrics:error:
shouldApplySemanticTextFiltering
envelopeWithTextFeatures:canvasSize:preferredLocales:applySemanticAnalysis:error:
documentWithTable:canvasSize:preferredLocales:requestHandler:metrics:error:
documentWithTextFeatures:canvasSize:preferredLocales:applySemanticAnalysis:error:
semanticTextFactory
initWithSemanticTextFactory:
topCandidates:
rangeOfComposedCharacterSequenceAtIndex:
characterAtIndex:
initWithRecognizedText:range:
textSequence:boundingBox:recognizedTextFeatures:confidence:canvasSize:
textDetectionOptions
recognitionLevel
textDetectionLocales
languageCode
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
baseLanguageFromLanguage:
boundingBoxForRange:error:
bottomLeft
bottomRight
setSemanticTextFactory:
setTextLayoutManager:
setSpecialCaseManager:
setSceneLabelsForOCRDocumentTypeDetection:
_semanticTextFactory
_textLayoutManager
_specialCaseManager
_sceneLabelsForOCRDocumentTypeDetection
T@"AXMSemanticTextFactory",&,N,V_semanticTextFactory
T@"AXMTextLayoutManager",&,N,V_textLayoutManager
T@"AXMTextSpecialCase",&,N,V_specialCaseManager
T@"NSArray",&,N,V_sceneLabelsForOCRDocumentTypeDetection
setImageNode:
setIconClassDetector:
setBrailleEdgeDetector:
imageWithData:
setDetectIconClass:
imageNode
triggerWithImage:options:cacheKey:resultHandler:
classifyImages:withTimeout:
iconClassDetector
brailleEdgeDetector
_imageNode
_iconClassDetector
_brailleEdgeDetector
T@"AXMImageNode",W,N,V_imageNode
T@"AXMIconClassDetectorNode",W,N,V_iconClassDetector
T@"AXMBrailleEdgesDetectorNode",W,N,V_brailleEdgeDetector
UTF8String
_queue_processNextTask
_queue_count
_queue_dequeueTask
isComplete
setTaskCompleteBlock:
_queue_scheduleTask:
_queue_unscheduleAllTasks
removeObjectAtIndex:
isEmpty
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
taskCompleteBlock
setComplete:
_complete
_taskCompleteBlock
complete
TB,N,GisComplete,V_complete
T@?,C,N,V_taskCompleteBlock
setWithArray:
featureValueWithPixelBuffer:
featureValueWithDouble:
featureValueForName:
featureNames
T@"NSSet",R,N
initWithImage:iouThreshold:confidenceThreshold:
image
iouThreshold
setIouThreshold:
confidenceThreshold
setConfidenceThreshold:
_image
_iouThreshold
_confidenceThreshold
T^{__CVBuffer=},N,V_image
Td,N,V_iouThreshold
Td,N,V_confidenceThreshold
featureValueWithMultiArray:
initWithConfidence:coordinates:
setConfidence:
coordinates
setCoordinates:
_confidence
_coordinates
T@"MLMultiArray",&,N,V_confidence
T@"MLMultiArray",&,N,V_coordinates
urlOfModelInThisBundle
modelWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
modelWithContentsOfURL:configuration:error:
predictionFromFeatures:options:error:
multiArrayValue
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
initWithConfiguration:error:
predictionFromImage:iouThreshold:confidenceThreshold:error:
predictionsFromInputs:options:error:
model
_model
T@"MLModel",R,N,V_model
setAssetURL:
setAssetCreationDate:
setAssetUTI:
setAssetLocalIdentifier:
setAssetImageData:
decodeInt32ForKey:
setAssetOrientation:
setAllowNetworkAccess:
setPhotoLibraryURL:
assetURL
assetCreationDate
assetUTI
assetLocalIdentifier
assetImageData
assetOrientation
encodeInt32:forKey:
allowNetworkAccess
photoLibraryURL
updateAssetDetails
initWithPhotoLibraryURL:
openAndWaitWithUpgrade:error:
librarySpecificFetchOptions
setIncludeGuestAssets:
authorizationStatus
_photoAuthorizationMessage:
fetchAssetsWithLocalIdentifiers:options:
creationDate
mainFileURL
setResizeMode:
setDeliveryMode:
setSynchronous:
setNetworkAccessAllowed:
requestImageDataAndOrientationForAsset:options:resultHandler:
initWithImageAssetLocalIdentifier:photoLibraryURL:allowsNetworkAccess:
localIdentifier
imageData
_allowNetworkAccess
_assetOrientation
_assetLocalIdentifier
_assetImageData
_assetUTI
_assetCreationDate
_assetURL
_photoLibraryURL
T@"NSString",&,N,V_assetLocalIdentifier
T@"NSData",&,N,V_assetImageData
T@"NSString",&,N,V_assetUTI
T@"NSDate",&,N,V_assetCreationDate
T@"NSURL",&,N,V_assetURL
TI,N,V_assetOrientation
TB,N,V_allowNetworkAccess
T@"NSURL",&,N,V_photoLibraryURL
T@"NSString",R,N
T@"NSData",R,N
T@"NSDate",R,N
T@"NSURL",R,N
TI,R,N
initWithAttackDuration:attackLevel:decayDuration:sustainDuration:sustainLevel:releaseDuration:
attackMS
decayMS
sustainMS
releaseMS
attackLevel
sustainLevel
defaultEnvelope
setAttackMS:
setAttackLevel:
setDecayMS:
setSustainMS:
setSustainLevel:
setReleaseMS:
_attackMS
_attackLevel
_decayMS
_sustainMS
_sustainLevel
_releaseMS
Td,N,V_attackMS
Td,N,V_attackLevel
Td,N,V_decayMS
Td,N,V_sustainMS
Td,N,V_sustainLevel
Td,N,V_releaseMS
Td,R,N
setCameraPixelFocalLength:
setCameraOpticalOrigin:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMinimumConfidence:
setMaximumNumberOfRects:
axmDecodePointForKey:
cameraPixelFocalLength
cameraOpticalOrigin
axmEncodePoint:forKey:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
maximumNumberOfRects
dataWithBytes:length:
minimumConfidence
setMaximumObservations:
featureWithVisionRequest:rectangleResult:canvasSize:
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
Tq,N,V_maximumNumberOfRects
_getHue:saturation:brightness:
_getRed:green:blue:
colorWithHue:saturation:brightness:
isEqualToAXMVisionColor:
unsignedCharValue
numberWithUnsignedChar:
saturationFloat
hueRadians
brightnessFloat
hueFloat
colorWithRed:green:blue:
colorWithHueDegrees:saturation:brightness:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
_red
_green
_blue
_hue
_saturation
_brightness
setLocalizedName:
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
localizedName
closestMarkerToColor:withMaximumThreshold:
_localizedName
T@"NSString",&,N,V_localizedName
setSynthesizer:
synthesizer
initWithString:attributes:
currentRequestCompletionBlock
speechUtteranceWithAttributedString:
setCurrentRequestCompletionBlock:
speakUtterance:
stopSpeakingAtBoundary:
attributedSpeechString
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:
handleRequest:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
_synthesizer
_currentRequestCompletionBlock
T@"AVSpeechSynthesizer",&,N,V_synthesizer
T@?,C,N,V_currentRequestCompletionBlock
initWithName:sampleRate:circular:
currentSampleIndex
isCircular
setCurrentSampleIndex:
dataSources
setWithSet:
processEffects:
sampleBuffer
level
isMonoOutput
panning
addDataSource:
removeDataSource:
removeAllDataSources
prepareNextSamples:
setName:
setPanning:
setDataSources:
_name
_panning
_dataSources
T@"NSString",C,N,V_name
Td,N,V_panning
T@"NSSet",&,N,V_dataSources
raise:format:
setCaptureSessionNodeDelegate:
beginFrameEventsWithAVCaptureSession:delegate:queue:
setAutomaticallyConfiguresOutputBufferDimensions:
setDeliversPreviewSizedOutputBuffers:
axVideoDataOutput
setSampleBufferDelegate:queue:
canAddOutput:
addOutput:
setCaptureSession:
captureSession
setFrameDelegate:
outputs
addVideoDataOutputWithAVCaptureSession:queue:
endVideoFrameEvents
removeOutput:
frameDelegate
captureSessionNode:didOutputSampleBuffer:fromConnection:
wrapperWithPixelBuffer:orientation:
inputWithPixelBuffer:
captureSessionNodeDelegate
interfaceOrientationForCaptureSessionNode:
videoDeviceFromConnection:
isMirroredVideoDevice:
triggerWithSampleBuffer:interfaceOrientation:mirrored:options:userContext:
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:didDropSampleBuffer:fromConnection:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
endAutoTriggerOfVideoFrameEvents
setAxVideoDataOutput:
_autotrigger_queue
_axVideoDataOutput
_captureSessionNodeDelegate
_frameDelegate
_captureSession
T@"AVCaptureSession",W,N,V_captureSession
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeFrameDelegate>",W,N,V_frameDelegate
T@"AXMCaptureVideoDataOutput",&,N,V_axVideoDataOutput
setNotificationObserverTokens:
auxiliarySession
setSession:
notificationObserverTokens
userInfo
_handleSessionInterrupted:options:
addObserverForName:object:queue:usingBlock:
_handleRouteChanged:previousRoute:
_handleMediaServicesLost
_handleMediaServicesReset
_handleSilenceSecondaryAudio:
removeObserver:
session
setActive:error:
setCategory:withOptions:error:
_stringForRouteChangeReason:
deactivateSessionWithError:
activateSessionWithError:
_notificationObserverTokens
_session
T@"NSMutableArray",&,N,V_notificationObserverTokens
T@"AVAudioSession",&,N,V_session
setComponentState:
transitionToState:completion:
componentState
_componentState
Tq,N,V_componentState
render:toCVPixelBuffer:
colorSpace
setCIContext
createCGImage:fromRect:
imageByApplyingTransform:
resizeImage:byX:andY:
resizeImage:to:
createVImageBuffer:
setCIContext:
getCGImageFromCIImage:
resizeImage:toWidth:andHeight:
resultWithImage:features:orientation:metricSession:userContext:
isEqualToAXMVisionResult:
normalizedFrame
ocrFeatures
isOCR
isValueSpeakable
ocrFeatureType
nameForOCRType:
whitespaceCharacterSet
isTable
isNutritionLabel
isEnvelope
values
null
isReceipt
isTextDocument
parentOCRFeatureTypes
semanticTextForText:withLocale:
isSemanticallyComplete
subfeatures
_processFeatureChild:
smallestChildOCRFeatureTypes
componentsSeparatedByCharactersInSet:
predicateWithFormat:
_textExistsInLexicon:withLocale:
nameForFeatureType:
nameForFaceExpression:
_processFeatureTree:
faceFeatures
captionFeatures
includesNSFWFeatures
sceneClassificationFeatures
sensitiveContentForCaptionFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
setDetectedTextDescription:
setDetectedTextType:
setDetectedTextSummary:
setBrailleEdges:
detectedTextType
detectedTextSummary
equivalenceToken
brailleEdges
featureGates
addEntriesFromDictionary:
localeWithLocaleIdentifier:
resultWithImage:features:orientation:metricSession:
colorInfoFeature
assetMetadataFeature
localizedDetectedTextTypeHint
localizedDetectedTextSummaryHint
localizedDetectedTextHint
detectedFeatureDictionary
detectedCaptionFeatureDescriptionWithOptions:
detectedSceneClassificationFeatureDescriptionWithOptions:
captionTranslationLocale
localizedDetectedIconHint
_equivalenceToken
_brailleEdges
_detectedTextType
_detectedTextDescription
_detectedTextSummary
T@"NSString",&,N,V_detectedTextType
T@"NSString",&,N,V_detectedTextDescription
T@"NSString",&,N,V_detectedTextSummary
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSSet",&,N,V_evaluatedFeatureTypes
T@"AXMVisionFeature",R,N
T@"NSDictionary",R,N
T@"NSData",&,N,V_equivalenceToken
T@"NSData",&,N,V_brailleEdges
isFace
isSceneClassification
isObjectClassification
isCaption
isNSFWClassification
isModelClassification
isBlur
isBrightness
isIconClass
captionMayContainSensitiveContent
assetMetadata
objectClassificationFeatures
modelClassificationFeatures
sensitiveContentFeatures
includesFeaturesForImageExploration
axm_featuresSortedByConfidence
_cacheQueue_cacheSize
_cacheQueue_resultForKey:
_cacheQueue_setResult:forKey:
removeObjectForKey:
resultForKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
targetPlayerItem
_mainQueue_endAutoTriggerOfLegibilityEvents
setDelegate:queue:
setTargetPlayerItem:
featureWithMediaLegibility:
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
_avkit_queue
_triggeringLegibilityEvents
_targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
policy
assetControllerWithPolicy:
addObserver:
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
_performWithLock:
_modelURLForType:baseURL:
dataWithContentsOfURL:options:error:
JSONObjectWithData:options:error:
initWithModelProperties:
fileExistsAtPath:isDirectory:
newsestCompatibleImageCaptionModelAssetFromAssets:withStage:language:isInstalled:isDownloadable:
store
recordLastAssetAccess:
localURL
setBaseURL:
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
modelURLForType:timeout:
infoForModelAtURL:
baseURL
_lock
_didTryWaitingForAssetLookup
_assetController
_baseURL
T@"NSURL",C,N,V_baseURL
frame
axmEncodeRect:forKey:
rectanglesConfidence
nameConfidence
attributesConfidence
landmarksConfidence
poseConfidence
axmDecodeRectForKey:
setNameConfidence:
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
getBytes:length:
descriptionForExpression:
_expressionForString:
confidenceForExpression:
_likelyExpression
_uuid
_faceId
_rectanglesConfidence
_nameConfidence
_attributes
_attributesConfidence
_expressionsAndConfidence
_landmarks
_landmarks3d
_landmarksConfidence
_poseConfidence
_frame
_pose
T@"NSUUID",&,N,V_uuid
TQ,N,V_faceId
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_frame
Td,N,V_rectanglesConfidence
T@"NSString",&,N,V_name
Td,N,V_nameConfidence
T@"AXMVisionFeatureFaceAttributes",&,N,V_attributes
Td,N,V_attributesConfidence
T@"NSDictionary",&,N,V_expressionsAndConfidence
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks3d
Td,N,V_landmarksConfidence
T{?=[4]},N,V_pose
Td,N,V_poseConfidence
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
imageBufferValue
initWithImage_Placeholder:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
initWithImage_PlaceholderFromCGImage:error:
initWithImage_PlaceholderAtURL:error:
setImage_PlaceholderWithCGImage:error:
setImage_PlaceholderWithURL:error:
image_Placeholder
setImage_Placeholder:
_image_Placeholder
T^{__CVBuffer=},N,V_image_Placeholder
initWithLeaf_leaf_predictions_probabilities:
leaf_leaf_predictions_probabilities
setLeaf_leaf_predictions_probabilities:
_leaf_leaf_predictions_probabilities
T@"MLMultiArray",&,N,V_leaf_leaf_predictions_probabilities
URLOfModelInThisBundle
initWithMLModel:
loadContentsOfURL:configuration:completionHandler:
loadWithConfiguration:completionHandler:
predictionFromImage_Placeholder:error:
setLabel:
sceneClassId
setSceneClassId:
detectorSceneClassIds
setDetectorSceneClassIds:
_sceneClassId
_label
_detectorSceneClassIds
T@"NSString",&,N,V_label
Td,N,V_confidence
TI,N,V_sceneClassId
T@"NSMutableSet",&,N,V_detectorSceneClassIds
processInfo
physicalMemory
addNSFWResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
nsfwClassificationWithCategory:confidence:canvasSize:
setCaptionMayContainSensitiveContent:
_request
multiplyByInverseOfAttitude:
quaternion
inputPorts
input
device
position
formatDescription
videoDimensionsForDeviceFormat:
sequenceRequestHandler
setSequenceRequestHandler:
_sequenceRequestHandler
T@"VNSequenceRequestHandler",&,N,V_sequenceRequestHandler
supportedIdentifiersAndReturnError:
possibleObjectClassifications
_recognizeObjectsRequest
uiClass
setUiClass:
setBoundingBox:
_uiClass
_boundingBox
TQ,N,V_uiClass
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
assetType
_evaluateANOD:metrics:
rectValue
imageByCroppingToRect:
dataWithLength:
mutableBytes
render:toBitmap:rowBytes:bounds:format:colorSpace:
bytes
numberWithLongLong:
numberWithUnsignedLong:
colorWithRed:green:blue:alpha:colorSpace:
filterWithName:
setValue:forKey:
vectorWithX:Y:Z:W:
imageByCompositingOverImage:
filterWithName:withInputParameters:
valueWithBytes:objCType:
contextWithOptions:
labels
nameForUIClass:
IoUForbb1:bb2:
setWriteDebugImage:
_initializeIconDetector
_screenEquivalenceToken:
isEqualToData:
_performCrossClassNMSForDetections:iouThreshold:
indexesOfObjectsPassingTest:
objectsAtIndexes:
mutableCopy
removeObjectsInArray:
featureWithVisionRequest:axElementRect:confidence:uiClass:label:canvasSize:
transform
translateXBy:yBy:
valueForKey:
setLoggingName:
_imageByWipingTextFromRects:image:colorSpace:ciContext:
_nonMaxSupression:iouThreshold:
remapUIClassForClickability:andClass:
_iconDetector
width
height
left
right
bottom
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
boundingFrameForItems:
normalizedBoundingFrameForItems:
normalizedBoundingFrameForItem:
metric:inProximityOfMetric:item:threshold:
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
sequence:
feature
_feature
arrayWithObject:
recognizedTextFeatures
line:
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
row:
addCell:
cells
_cells
header:
column:
region:row:
addRow:
header
addColumn:
firstColumn
rows
columns
_header
_rows
_columns
setNumberStyle:
setUnitStyle:
measurementFormatter
grams
stringFromUnit:
milligrams
micrograms
milliliters
kilocalories
kilograms
reverseObjectEnumerator
_assembleLayoutSequences:
_assembleLayoutLines:
_assembleLayoutRegions:
textLineWithText:boundingBox:recognizedTextFeatures:canvasSize:
transformedSpeechText
textRegionWithText:isSpeakable:boundingBox:lines:canvasSize:
textDocumentWithText:isSpeakable:boundingBox:regions:canvasSize:
extractDataFromEnvelopeWithFeatures:preferredLocales:canvasSize:
envelopeWithText:isSpeakable:boundingBox:regions:canvasSize:
dataDetectorWithTypes:error:
numberOfMatchesInString:options:range:
indexOfObject:
localeIdentifier
replaceDirectionalAbbreviations:
envelopeRegion:boundingBox:confidence:canvasSize:
preprocessTable:width:height:metrics:
sortContourRowResults:maxWidth:maxHeight:minWidth:minHeight:
getTableRows:
sortContourColumnResults:maxWidth:maxHeight:
getTableColumns:
verifyTable:sortedColumns:
textRowsForTable:sourceImage:requestHandler:canvasSize:
_assembleLayoutCellsWithFeatures:
_assembleLayoutHeader:
_assembleLayoutRow:
textColumnsForTable:sourceImage:requestHandler:canvasSize:
_assembleLayoutColumn:
_assembleLayoutTable:header:columnItems:
tableRowWithText:boundingBox:cells:canvasSize:
tableColumnWithText:boundingBox:cells:canvasSize:
tableWithText:isSpeakable:boundingBox:rows:columns:canvasSize:isIncomplete:
properties
imageByApplyingOrientation:
preprocessNutritionLabel:finalFrame:
nutritionLabelRowsForContourResults:normalizedNutritionLabelFrame:fullImageFrame:processedImageFrame:
featureCellsForNutritionLabelRows:withRequestHandler:withCanvasSize:
_assembleLayoutRowFromCell:
_assembleNutritionLabelLayoutWithRows:
nutritionLabelWithText:isSpeakable:boundingBox:rows:canvasSize:
preprocessReceipt:withTextSkew:width:height:metrics:requestHandler:finalFrame:
preferredLanguages
getReceiptRows:preferredLocales:canvasSize:
_assembleReceipt:
receiptWithText:isSpeakable:boundingBox:regions:canvasSize:
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
imageByClampingToExtent
mergeWithImage:withSize:withMetrics:
largestDetectedContoursForImage:
detectCenterContourFromContours:withImageExtent:
imageRectForNormalizedRect:imageWidth:imageHeight:
addBorderWithBorderSize:
contourCount
contourAtIndex:error:
normalizedPath
isBoundary:withinNormalizedDistance:ofBoundary:
filterReceiptForGarbageText:
stringByAppendingFormat:
symbolCharacterSet
formUnionWithCharacterSet:
punctuationCharacterSet
removeCharactersInString:
stringWithCapacity:
receiptRegularExpressions
firstMatchInString:options:range:
range
rangeAtIndex:
hasConsecutiveCharacters:withLength:
hasConsecutiveDigits:withLength:
getValue:
valueWithRect:
processReceiptText:foundMerchantName:preferredLocales:
tableCellWithText:boundingBox:confidence:recognizedTextFeatures:canvasSize:isHeader:
isBoundary:withinBoundary:withNormalizedThreshold:
processNutritionLabelText:
processFraction:
processMeasurement:
componentsSeparatedByString:
numberFormatter
fractionDenominatorValuesWithOneAsNumerator
fractionDenominatorValues
measurementAbbreviationsToVerboseString
setNumberFormatter:
setMeasurementFormatter:
_numberFormatter
_measurementFormatter
T@"NSNumberFormatter",&,N,V_numberFormatter
T@"NSMeasurementFormatter",&,N,V_measurementFormatter
_resetTranspositionHistory
initWithTargetedCIImage:options:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedImageURL:options:
_translationalImageRegistrationRequestForInput:
performRequests:onCVPixelBuffer:orientation:error:
performRequests:onCIImage:error:
alignmentTransform
_recordTransposition:
_resetImageRegistration
registrationState
_previousInput
_currentInput
_transpositionHistoryCircularBuffer
_transpositionHistoryLastRecordedIndex
_fillingHistoryBuffer
_registrationState
featureWithCameraType:
triggerWithCameraType:cacheKey:resultHandler:
en_USLocale
localeForLanguageCode:
baseLanguageForLocale:
localeMatchingBaseLanguageOfLocale:fromLocales:
setEn_USLocale:
_en_USLocale
T@"NSLocale",&,N,V_en_USLocale
value:withObjCType:
axmEncodeSize:forKey:
axmDecodeSizeForKey:
initWithAttack:release:compressionRatio:threshold:sampleRate:
inputSource
emaSamples
setEma:
ratio
engagement
setEngagement:
compressor
limiter
processSamples:
compressionRatio
setCompressionRatio:
setGain:
setSampleRate:
setRatio:
gainReduction
setGainReduction:
setEmaSamples:
_compressionRatio
_gain
_threshold
_sampleRate
_ratio
_gainReduction
_engagement
_emaSamples
_ema
Td,N,V_ratio
Td,N,V_gainReduction
Td,N,V_engagement
TQ,N,V_emaSamples
Td,N,V_ema
Td,N,V_compressionRatio
Td,N,V_gain
Td,N,V_threshold
Td,N,V_sampleRate
sameScreenCapResult
setSameScreenCapResult:
screenEquivalenceToken
setScreenEquivalenceToken:
setSortedFeatures:
_sameScreenCapResult
_screenEquivalenceToken
_sortedFeatures
TB,N,V_sameScreenCapResult
T@"NSData",&,N,V_screenEquivalenceToken
T@"NSArray",&,N,V_sortedFeatures
testingImage
setTestingImage:
disableCoagulator
setDisableCoagulator:
fullRect
setFullRect:
setOrientation:
isRTL
setIsRTL:
_disableCoagulator
_isRTL
_testingImage
_orientation
_fullRect
T@"CIImage",&,N,V_testingImage
TB,N,V_disableCoagulator
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_fullRect
Tq,N,V_orientation
TB,N,V_isRTL
coagulateElements:
initWithCompletion:
coreAnimationMainDisplay
setAppFrame:
setAppOrientation:
setScreenScale:
numberWithUnsignedLongLong:
_processVisionResult:options:coagulator:
data
captureNode
processFeatures:
_initWithHandle:
T@"AXMOutputActionHandle",R,N
_text
URLForResource:withExtension:subdirectory:
fileExistsAtPath:
_soundFileURLForSoundID:
_initWithURL:handle:
_initWithSoundID:handle:
soundFileURL
soundID
_soundID
_soundFileURL
T@"AXMActiveSoundOutputActionHandle",R,D,N
handleProvider
stop
pitch
setPitch:
rate
setRate:
setQuantizedRate:
setHandleProvider:
_handleProvider
T@"<AXMActiveSoundOutputActionHandleProvider>",&,N,V_handleProvider
_initWithCIImage:
_initWithCIImage:photoLibraryURL:
_initWithPixelBuffer:
_initWithURL:
_initWithURL:photoLibraryURL:
orientedSize
CGImage
containsValueForKey:
imageWithCVPixelBuffer:
inputWithCIImage:photoLibraryURL:
inputWithURL:
inputWithURL:photoLibraryURL:
imageColorSpace
createCGImageWithMetrics:
wrappedPixelBuffer
_inputType
_ciImage
_pixelBuffer
_extendedSRGBColorSpace
_URL
_cachedImageURLSize
T@"CIImage",R,N
T@"AXMPixelBufferWrapper",R,N
T^{CGColorSpace=},R,N
T^{__CVBuffer=},R,N
dictionaryWithContentsOfURL:
_initializeClassLabels
classLabelForIdx:
_localizedClassForClass:
featureWithIconClass:confidence:
writeDebugImage
loggingName
iconClassLabels
_writeDebugImage
_loggingName
_iconClassLabels
mlModel
T@"iconclassification",R,D,N
T@"NSArray",R,N,V_iconClassLabels
TB,N,V_writeDebugImage
T@"NSString",&,N,V_loggingName
setTopLevel:
setIncludeChildren:
setSubfeatures:
textLabel
featureLabel
rangeOfString:options:
childFeatures
setFeature:
topLevel
includeChildren
_topLevel
_includeChildren
_subfeatures
T@"AXMVisionFeature",&,N,V_feature
T@"NSMutableArray",&,N,V_subfeatures
TB,N,V_topLevel
TB,N,V_includeChildren
topmost
regularExpressionWithPattern:options:error:
screenScale
appFrame
setCanvasSize:
appOrientation
canvasSize
_applyCrossUITypeNMS:
_getCandidateTabBarFeatures:screenSize:
_repairTextInTabItems:
_getAXMLElementGroupsForFeatures:
_sortFeaturesReadingOrder:
_getGroupedTabBarFeatures:
_groupFeatures:
_flattenFeatures:
_improveFeatureFrames:
arrayByAddingObjectsFromArray:
_isInTopBar:
nonAlphaCharactersRegex
stringByReplacingMatchesInString:options:range:withTemplate:
clickableTextKeywords
groupedFeatureWithElementRect:uiClass:confidence:label:canvasSize:subElements:
_getFlattenedChildFeatures:
_getClickableTextButtons:
_getGroupedSegmentedControlFeatures:
_getGroupedTextFields:
_mergeTopLeftButton:
_getGroupedToggleCheckboxWithText:
_getGroupedTextFeatures:
_getGroupedPictureAndSubtitleFeature:
_groupFeaturesByContainment:
_getTopLevelFeatureGroups:
_getGroupedTextButtonFeatures:
_applyHorizontalMirrorToFeatures:
_reorderByYCut:
_compareForY:
_hasXOverlap:obj2:
_getXOverlap:obj2:
_hasYOverlap:obj2:
_mergeFeatureIntoGroup:feature:
setActivationPoint:
_compareArea:
substringFromIndex:
_removeExtraOCRAndIconFromTextField:
_compareForX:
_getYOverlap:obj2:
_removeTextContainingOnlyToggles:toggleCheckboxTypes:
_createToggleGroup:toGroup:
_getClosestDetectionBelow:target:maxDistance:
_reorderByXCut:
_removeFeatureFromGroup:feature:
_groupSingleContainerAsButton:featureToGroup:
_getTabGroupSubfeatureUIClassTypes:
anyObject
longValue
activationPoint
isiPad
_getHorizontalSegmentationPointDict:
_getFeaturesForAXMLTabButtonGroups:
_compareY:frame2:
_compareX:frame2:
rangeOfString:
_featuresByReorderingTwoRows:minY:maxY:
setObject:atIndexedSubscript:
_allTabGroupsHaveSingleSubfeature:
_shouldBeTabBar:groupedTabButtons:
_reorderedTabsForSortedFeatures:screenSize:
_reorderSimilarTopNeighbors:
setClickableTextKeywords:
setNonAlphaCharactersRegex:
setIsiPad:
_isiPad
_screenScale
_appOrientation
_clickableTextKeywords
_nonAlphaCharactersRegex
_canvasSize
_appFrame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_appFrame
Td,N,V_screenScale
T{CGSize=dd},N,V_canvasSize
Tq,N,V_appOrientation
T@"NSArray",&,N,V_clickableTextKeywords
T@"NSRegularExpression",&,N,V_nonAlphaCharactersRegex
TB,N,V_isiPad
initWithUnit:
setString:
enumerateTokensInRange:usingBlock:
textRange
enumerateAttribute:inRange:options:usingBlock:
addAttribute:value:range:
initWithText:semanticText:
initWithText:locale:
tokenizedLength
preprocessedText
enumerateNLPTokens:
enumerateLexiconMarkers:
enumerateNumericTokens:
enumerateDataDetectors:
enumerateCustomPatterns:
enumerateSemanticErrors:
addNLPToken:withRange:
addDataDetector:withRange:
addCustomPattern:withRange:
addIsInLexionMarker:withRange:
addSemanticErrorWithRange:
addNumericToken:withRange:
makeCursor
setTransformedSpeechText:
locale
setLocale:
setTokenizedLength:
_transformedSpeechText
_locale
_tokenizedLength
T@"NSLocale",&,N,V_locale
T@"NSString",&,N,V_transformedSpeechText
Tq,N,V_tokenizedLength
initWithTagSchemes:
URLForResource:withExtension:
initWithTypes:error:
currentLocale
_preprocessedText:
_applyNaturalLanguageTokens:
_applyDataDetectors:
_applyCustomPatterns:
_performSemanticAnalysis:
alphanumericCharacterSet
invertedSet
tagger
numberFromString:
enumerateTagsInRange:unit:scheme:options:usingBlock:
dataDetector
resultType
enumerateMatchesInString:options:range:usingBlock:
compiledPatterns
isFinished
remainingRange
isOtherWord
isInLexicon
isWhitespace
isCustomPattern
processAttribute:getSubstring:advanceCursor:markAsSemanticError:error:
isDataDetector
isSentenceTerminator
isPunctuation
isProperNoun
errorWithDomain:code:userInfo:
markCurrentIndexAsSemanticErrorAndAdvanceCursor
_lexiconForLocale:
cachedLexicons
_string:containsOnlyCharactersFrom:
_lexiconExistsForLocale:
setDataDetector:
setTagger:
setCachedLexicons:
setCompiledPatterns:
_dataDetector
_tagger
_cachedLexicons
_compiledPatterns
T@"NLTagger",&,N,V_tagger
T@"NSMutableDictionary",&,N,V_cachedLexicons
T@"NSMutableDictionary",&,N,V_compiledPatterns
T@"NSDataDetector",&,N,V_dataDetector
attribute:atIndex:longestEffectiveRange:inRange:
advance
attributesAtIndex:effectiveRange:
currentAttributes
_semanticText
_length
_currentIndex
T{_NSRange=QQ},R,N
_initWithPixelBuffer:orientation:
unorientedSize
assetMetadataFromURL:
featureWithAssetMetadata:
triggerWithAssetURL:cacheKey:resultHandler:
weakObjectsPointerArray
_initializeAudioUnit
stopPlaying
playbackDuration
playbackMixerDataSource
playbackSampleCount
setLength:
playbackChartDataAudioDataSource
playbackTrendlineAudioDataSource
scrubbingMixerDataSource
scrubbingDiscreteAudioDataSource
scrubbingContinuousAudioDataSource
scrubbingTrendlineAudioDataSource
scrubbingDiscreteDataRenderingContext
liveContinuousMixerDataSource
liveContinuousAudioDataSource
setLevel:
masterVolume
setMasterVolume:
scheduledTimerWithTimeInterval:repeats:block:
isPlaying
isPaused
playbackObservers
dataSonifierPlaybackDidBeginAtPosition:
currentPlaybackPosition
dataSonifierPlaybackDidResumeAtPosition:
dataSonifierPlaybackProgressDidChange:
setPlaybackObserverUpdateTimer:
playbackObserverUpdateTimer
dataSonifierPlaybackDidPauseAtPosition:
dataSonifierPlaybackDidEndAtPosition:
_uninitializeAudioUnit
_regenerateTimeEncodingValuesForDataPoints
currentChartDescriptor
xAxis
currentSeries
isCategoricalAxis
dataPoints
addPointer:
removePointerAtIndex:
isScrubbing
scrubToPlaybackFrame:
trendlineFunction
_newContinuousToneEnvelope
setPatch:
pause
isEndingScrubbing
stopScrubbing
dataSonifierScrubbingDidBeginAtPosition:
continuousScrubbingTone
startRelease
trendlineScrubbingTone
dataSonifierScrubbingDidEndAtPosition:
currentSeriesIndex
series
isContinuous
timeEncodingValue
normalizedTimeEncodingValueForValue:
pitchEncodingValue
frequencyForPitchEncodingValue:
durationEncodingValue
durationForDurationEncodingValue:
volumeEncodingValue
volumeForVolumeEncodingValue:
timbreAxisDescriptor
zCategoryAxisValue
categoryOrder
category
_peakNormalizeBuffer:length:level:
series:hasContinuousPitchDataForTimePosition:
setMuted:
interpolatedPitchValueForNormalizedTimePosition:inSeries:
setFrequency:
timeAxisDescriptor
lowerBound
upperBound
valueFromNormalizedValue:min:max:
dataSonifierScrubbingPositionDidChange:
dataCategories
renderSonification
_initializeAXMAudioDataSources
_renderSeries:
normalizeAudio
_renderContinuousAudioForSeries:
_renderDiscreteAudioForSeries:
playbackTimeOffsetMS
sampleIndexForTimeOffset:
timbreEncodingValue
initWithFrequency:volume:timeOffset:
timeOffsetMS
initWithKeyPitches:sampleRate:envelope:
_initializeAudioComponent
_setAudioFormat
_setOutputCallback
timeNumericAxisDescriptor
number
normalizedValueForValue:min:max:
timeCategoricalAxisDescriptor
minimumPlaybackFrequency
maximumPlaybackFrequency
pitchAxisDescriptor
volumeAxisDescriptor
maximumToneVolume
minimumToneVolume
durationAxisDescriptor
maximumDiscreteToneLength
minimumDiscreteToneLength
minimumDataValueOnTimeAxis
maximumDataValueOnTimeAxis
_initializeLiveToneDataSource
patch
liveContinuousDataTone
setPlaybackTimeOffsetMS:
setMasterVolume:fadeDuration:
play
setPlaybackDuration:
addPlaybackObserver:
removePlaybackObserver:
setPlaybackPosition:
beginScrubbing
endScrubbing
setCurrentChartDescriptor:
setCurrentSeriesIndex:
_renderUnivariateFunctionAudio
timeOffsetForTimeEncodingValue:
beginLiveContinuousToneSession
endLiveContinuousToneSession
setLiveContinuousToneNormalizedFrequency:
setMinimumPlaybackFrequency:
setMaximumPlaybackFrequency:
usesBinauralPanning
setUsesBinauralPanning:
dataMode
interpolationMode
isInLiveContinuousToneSession
setPlaybackMixerDataSource:
setPlaybackChartDataAudioDataSource:
setPlaybackTrendlineAudioDataSource:
setScrubbingMixerDataSource:
setScrubbingDiscreteAudioDataSource:
setScrubbingContinuousAudioDataSource:
setScrubbingTrendlineAudioDataSource:
setLiveContinuousMixerDataSource:
setLiveContinuousAudioDataSource:
setPlaybackObservers:
setTrendlineFunction:
scrubbingPlaybackCallbackRenderingContext
liveTonePlaybackCallbackRenderingContext
setMinimumDiscreteToneLength:
setMaximumDiscreteToneLength:
setMinimumToneVolume:
setMaximumToneVolume:
_audioUnit
_userDefinedPlaybackDuration
_usesBinauralPanning
_playing
_paused
_scrubbing
_isEndingScrubbing
_isInLiveContinuousToneSession
_dataMode
_interpolationMode
_minimumPlaybackFrequency
_maximumPlaybackFrequency
_continuousScrubbingTone
_patch
_currentChartDescriptor
_currentSeriesIndex
_playbackObserverUpdateTimer
_playbackMixerDataSource
_playbackChartDataAudioDataSource
_playbackTrendlineAudioDataSource
_scrubbingMixerDataSource
_scrubbingDiscreteAudioDataSource
_scrubbingContinuousAudioDataSource
_scrubbingTrendlineAudioDataSource
_liveContinuousMixerDataSource
_liveContinuousAudioDataSource
_playbackObservers
_trendlineScrubbingTone
_liveContinuousDataTone
_trendlineFunction
_scrubbingDiscreteDataRenderingContext
_scrubbingPlaybackCallbackRenderingContext
_liveTonePlaybackCallbackRenderingContext
_playbackSampleCount
_dataCategories
_minimumDiscreteToneLength
_maximumDiscreteToneLength
_minimumToneVolume
_maximumToneVolume
T@"NSTimer",&,N,V_playbackObserverUpdateTimer
T@"AXMAudioDataSourceMixer",&,N,V_playbackMixerDataSource
T@"AXMAudioDataSource",&,N,V_playbackChartDataAudioDataSource
T@"AXMAudioDataSource",&,N,V_playbackTrendlineAudioDataSource
T@"AXMAudioDataSourceMixer",&,N,V_scrubbingMixerDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingDiscreteAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingContinuousAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingTrendlineAudioDataSource
T@"AXMAudioDataSourceMixer",&,N,V_liveContinuousMixerDataSource
T@"AXMAudioDataSource",&,N,V_liveContinuousAudioDataSource
T@"NSPointerArray",&,N,V_playbackObservers
Ti,R,N,V_interpolationMode
T@"AXMLiveContinuousTone",R,N,V_continuousScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_trendlineScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_liveContinuousDataTone
T@?,C,N,V_trendlineFunction
T^v,R,N,V_scrubbingDiscreteDataRenderingContext
T^v,R,N,V_scrubbingPlaybackCallbackRenderingContext
T^v,R,N,V_liveTonePlaybackCallbackRenderingContext
TQ,R,N,V_playbackSampleCount
T@"NSMutableOrderedSet",R,N,V_dataCategories
Td,N,V_minimumDiscreteToneLength
Td,N,V_maximumDiscreteToneLength
Td,N,V_minimumToneVolume
Td,N,V_maximumToneVolume
Td,N
TB,R,N,V_playing
TB,R,N,V_paused
TB,R,N,V_scrubbing
TB,R,N,V_isEndingScrubbing
TB,R,N,V_isInLiveContinuousToneSession
Td,N,V_minimumPlaybackFrequency
Td,N,V_maximumPlaybackFrequency
Td,N,V_userDefinedPlaybackDuration
TB,N,V_usesBinauralPanning
Ti,R,N,V_dataMode
T@"AXMSynthPatch",&,N,V_patch
T@"AXMChartDescriptor",&,N,V_currentChartDescriptor
Tq,N,V_currentSeriesIndex
T@"AXMDataSeriesDescriptor",R,N
renderInBuffer:atFrame:numSamples:
observer
callback
initWithSuiteName:
registerDefaults:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_queue_removeObserver:forSetting:
boolForKey:
setBool:forKey:
settings
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
removeObserverForAllSettings:
writeOutInputImages
setWriteOutInputImages:
writeOutOCRInputImages
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
useANODModelForAXElementVision
setUseANODModelForAXElementVision:
_defaults
_queue_settingObservers
TB,D,N
initWithObjectType:boundingBox:confidence:
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:labelKey:
rotationAngle
setRotationAngle:
yawAngle
setYawAngle:
labelKey
setLabelKey:
_rotationAngle
_yawAngle
_labelKey
Tf,V_rotationAngle
Tf,V_yawAngle
Ti,V_labelKey
initForReadingFromData:error:
setWithObjects:
setByAddingObjectsFromSet:
decodeTopLevelObjectOfClasses:forKey:error:
numberOfDiscretePinHeights
_mapLuminance:toDiscreteNumber:invert:
appendBytes:length:
_processImage:analaysisOptions:
brailleEdgeOptions
canvasDescription
invert
_generateResultFromImage:canvasDescription:invert:
imageByApplyingTransform:highQualityDownsample:
edgeStrength
zoomLevel
origin
setCreationDate:
setUti:
setLocalizedTypeDescription:
setTIFFImageDescription:
setIPTCCaptionAbstract:
setEXIFUserComment:
setPNGImageDescription:
setImageAssetLocalIdentifier:
setImageAssetLocallyAvailable:
setImageAssetPhotoLibraryURL:
localizedTypeDescription
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
imageAssetLocalIdentifier
imageAssetLocallyAvailable
imageAssetPhotoLibraryURL
assetLocallyAvailable
resourceValuesForKeys:error:
assetMetadataFromURL:localIdentifier:photoLibraryURL:
assetMetadataWithLocalIdentifier:photoLibraryURL:creationDate:UTI:
_imageAssetLocallyAvailable
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_imageAssetLocalIdentifier
_imageAssetPhotoLibraryURL
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
T@"NSString",&,N,V_imageAssetLocalIdentifier
TB,N,V_imageAssetLocallyAvailable
T@"NSURL",&,N,V_imageAssetPhotoLibraryURL
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
initWithVisionAestheticsObservation:
_aestheticScore
_wellFramedSubjectScore
_pleasantCompositionScore
_wellChosenBackgroundScore
_noiseScore
_failureScore
Tf,R,N,V_aestheticScore
Tf,R,N,V_wellFramedSubjectScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_noiseScore
Tf,R,N,V_failureScore
_initWithBackingType:
setDisplayMonitor:
displayMonitor
connectedIdentities
configurationForIdentity:
isMainDisplay
_updateDisplay:withConfiguration:
isMainThread
mainDisplay
_updateDisplay:withCADisplay:
frontBoardMainDisplay
_displayPropertiesFromMobileGestalt
currentMode
preferredScale
setScale:
mobileGestaltOrientation
bounds
_discreteOrientationForOrientation:
setPhysicalOrientation:
setReferenceBounds:
setSize:
pixelSize
setSupportsDeepColor:
_updateDisplayPropertiesWithConfiguration:
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initAndWaitForMainDisplayConfiguration
isInitialized
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
T@"FBSDisplayMonitor",&,N,V_displayMonitor
Td,N,V_mobileGestaltOrientation
T@"AXMDisplay",R,N
referenceBounds
supportsDeepColor
convertPointToDisplay:
convertRectToDisplay:
physicalOrientation
backingType
setBackingType:
_supportsDeepColor
_scale
_physicalOrientation
_backingType
_size
_referenceBounds
Tq,N,V_backingType
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
Tq,N,V_physicalOrientation
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
xValues
numericalValuesFromDataPointValues:
yValues
yAxis
zNumericAxisDescriptor
zCategoricalAxisDescriptor
compute
numValues
getValues:fromNSNumberArray:
getModelForX:y:n:
setRegressionModel:
regressionModel
slopeDescription
confidenceDescription
outliersDescription
minValueDescription
maxValueDescription
meanValueDescription
medianValueDescription
valueDescription
bestFitParameters
computeRanges
computeMeans
computeCovariance
computeVariances
computeR
computeLinearRegression
computeResiduals
computeOutliers
getMean:
getVariance:
maxX
minX
maxY
minY
initWithSeries:chartDescriptor:
computeRegressionModel:
dataFeatureDescriptions
statsDescriptions
bestFitCurveEquation
stringForComponents:
getMedian:
positionForXAxisValue:
positionForYAxisValue:
setSeries:
chartDescriptor
setChartDescriptor:
setDataFeatureDescriptions:
setStatsDescriptions:
setNumValues:
rSquared
meanX
varianceX
meanY
varianceY
covariance
slope
intercept
residuals
outliers
categoryNameDelegate
setCategoryNameDelegate:
setXValues:
setYValues:
axisTitles
setAxisTitles:
_series
_chartDescriptor
_dataFeatureDescriptions
_statsDescriptions
_regressionModel
_numValues
_rSquared
_minX
_maxX
_meanX
_varianceX
_minY
_maxY
_meanY
_varianceY
_covariance
_slope
_intercept
_residuals
_outliers
_categoryNameDelegate
_xValues
_yValues
_axisTitles
T@"NSArray",&,N,V_xValues
T@"NSArray",&,N,V_yValues
T@"NSArray",&,N,V_axisTitles
TQ,N,V_numValues
T@"AXMDataSeriesDescriptor",W,N,V_series
T@"AXMChartDescriptor",W,N,V_chartDescriptor
T@"NSArray",&,N,V_dataFeatureDescriptions
T@"NSArray",&,N,V_statsDescriptions
T@"AXMDataRegressionModel",R,N,V_regressionModel
Td,R,N,V_r
Td,R,N,V_rSquared
Td,R,N,V_minX
Td,R,N,V_maxX
Td,R,N,V_meanX
Td,R,N,V_varianceX
Td,R,N,V_minY
Td,R,N,V_maxY
Td,R,N,V_meanY
Td,R,N,V_varianceY
Td,R,N,V_covariance
Td,R,N,V_slope
Td,R,N,V_intercept
T@"NSArray",R,N,V_residuals
T@"NSArray",R,N,V_outliers
T@"NSObject<AXMDataSummaryCategoryNameProvider>",W,N,V_categoryNameDelegate
_filterThresholds
T@"NSArray",R,N,V_filterThresholds
T@"NSNumber",R,N,V_nmsThreshold
_imageOrientationForInterfaceOrientation:displayOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
initWithOptions:
imageWithCGImage:
saveToURL:withOrientation:metrics:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
writeImageInAllOrientationsToDirectoryAtURL:metrics:
mainScreen
assetWithURL:
commonMetadata
metadataItemsFromArray:withKey:keySpace:
exportSessionWithAsset:presetName:
supportedFileTypes
setOutputFileType:
absoluteString
stringByDeletingPathExtension
stringByAppendingPathExtension:
URLWithString:
setOutputURL:
metadata
metadataItem
setKeySpace:
setKey:
setValue:
setMetadata:
status
exportAsynchronouslyWithCompletionHandler:
moveItemAtURL:toURL:error:
removeItemAtURL:error:
dateFromString:
currentCalendar
components:fromDate:
year
month
dictionaryWithObjectsAndKeys:
stringByAppendingPathComponent:
bundleWithPath:
load
evaluateImage:forCriteria:inRect:
blurResult
luminanceResult
humanReadableResult
hasPrefix:
samplesPerSecond
lastSampleTime
isDeviceMotionAvailable
deviceMotion
featureWithDeviceMotion:orientation:
setLastSampleTime:
triggerWithCoreMotionManager:deviceOrientation:cacheKey:resultHandler:
setSamplesPerSecond:
_samplesPerSecond
_lastSampleTime
Td,N,V_lastSampleTime
TQ,N,V_samplesPerSecond
stringByReplacingCharactersInRange:withString:
setLastScrubbingValueAnnouncementPosition:
lastScrubbingValueAnnouncementPosition
stopSpeaking
scrubbingValueAnnouncementTimer
announceValueForPlayheadPosition
setScrubbingValueAnnouncementTimer:
setLastPlayheadPosition:
xValue
sharedManager
categoryNameForXAxisPosition:
beginLiveModeSession
endLiveModeSession
setLiveModeValue:
beginScrubbingSession
scrubToPosition:
endScrubbingSession
playbackStatus
valueDescriptionForPlayheadPosition
hapticsEnabled
setHapticsEnabled:
lastPlayheadPosition
xGridlinePositions
xCategoryLabels
dataSeriesSummary
setDataSeriesSummary:
isDataSeriesRegressionModelLoaded
_dataSonifierAccessQueue
_hapticsEnabled
_isDataSeriesRegressionModelLoaded
_lastPlayheadPosition
_xGridlinePositions
_xCategoryLabels
_dataSeriesSummary
_lastScrubbingValueAnnouncementPosition
_scrubbingValueAnnouncementTimer
Td,N,V_lastScrubbingValueAnnouncementPosition
T@"NSTimer",&,N,V_scrubbingValueAnnouncementTimer
Tq,N
TB,N,V_hapticsEnabled
Td,N,V_lastPlayheadPosition
T@"NSArray",R,N,V_xGridlinePositions
T@"NSArray",R,N,V_xCategoryLabels
T@"AXMDataSummary",&,N,V_dataSeriesSummary
TB,R,N,V_isDataSeriesRegressionModelLoaded
TQ,R,N
setClasses:forSelector:argumentIndex:ofReply:
mainBundle
bundleIdentifier
axmValueWithCGAffineTransform:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
networkThreshold
defaultBoxesSidesNormalized
ratios
_networkThreshold
_defaultBoxesSidesNormalized
_ratios
T@"NSNumber",R,N,V_networkThreshold
T@"NSArray",R,N,V_defaultBoxesSidesNormalized
T@"NSArray",R,N,V_ratios
setReleasing:
setReleaseFrame:
muted
framesRendered
resetRelease
phase
releasing
releaseFrame
setFramesRendered:
_muted
_releasing
_phase
_framesRendered
_releaseFrame
Td,R,N,V_phase
TQ,N,V_framesRendered
TB,N,V_releasing
TQ,N,V_releaseFrame
TB,N,V_muted
getValueForTag:inObject:depth:parent:
rotateImage:withAngle:andXFlip:andYFlip:
exceptionWithName:reason:userInfo:
createNSErrorWithStatus:andMessage:
getValueForTag:inObject:
rotateImage:accordingToEXIFOrientation:
loadCGImageEXIFRotatedFromSource:error:
getBytes:range:
dataWithContentsOfFile:
loadRawBufferFromData:width:height:rowBytes:error:
extractLumaFromBGRA8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toBuffer:withBytesPerRow:
stringWithUTF8String:
guessType:
dataWithContentsOfURL:
loadVImageBufferFromData:isRaw:lumaOnly:error:
loadCGImageEXIFRotatedFromURL:error:
getVImageBufferFromCGImage:error:
loadCGImageEXIFRotatedFromData:error:
create420YCbCr8BufferFromPlanar8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:
create420YCbCr8BufferFromRGB8Buffer:withWidth:andWithHeight:andWithBytesPerRow:andAlphaFirst:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:
createRGB8BufferFrom420Y8PlanarBuffer:withBytesPerRowY:andFrom420Cb8Buffer:withBytesPerRowCb:andFrom420Cr8Buffer:withBytesPerRowCr:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:
createRGB8BufferFrom420Y8BiPlanarBuffer:withBytesPerRowLuma:andFrom420CbCr8Buffer:withBytesPerRowChroma:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:
saveCVPixelBufferRGBA8:withName:inFolder:error:
newCGImageFromPlanar8VImageBuffer:error:
writeImageToData:type:error:
writeImage:toFile:error:
newCGImageFromRGBA8VImageBuffer:error:
replaceBytesInRange:withBytes:
writeToFile:atomically:
createARGBBitmapContextWithImage:
loadCGImageFromURL:error:
loadRawBufferFromURL:width:height:rowBytes:error:
numberOfChannelsInImageData:error:
loadVImageBufferFromURL:lumaOnly:error:
loadVImageBufferEXIFRotatedFromURL:error:
loadVImageBufferEXIFRotatedFromData:error:
loadCVPixelBufferARGB8FromURL:error:
loadCVPixelBuffer420YpCbCr8FromURL:error:
saveCVPixelBufferPlane8:from:withName:inFolder:error:
saveCVPixelBuffer420YpCbCr8:withName:inFolder:error:
saveVImageBufferPlanar8ToJPEGData:withCompressionQuality:error:
saveVImageBufferPlanar8ToData:deriveTypeFromFileName:error:
saveVImageBufferPlanar8:withName:inFolder:error:
saveVImageBufferRGBA8ToJPEGData:withCompressionQuality:error:
saveVImageBufferRGBA8ToData:deriveTypeFromFileName:error:
saveVImageBufferRGBA8:withName:inFolder:error:
saveCGImage:withName:inFolder:error:
saveRawBuffer:withWidth:andHeight:andRowBytes:withName:inFolder:error:
getVImageBufferFromCVPixelBuffer:channel:error:
getVImageBufferFromCGImageLuma:error:
setIsDisqualified:
estimatedRadianFrequency
sortDataPoints
getSMA:lookback:
disqualifyModelIfNecessary
initWithBox:defaultBox:confidence:scale:mergesCount:
initWithBox:defaultBox:confidence:scale:mergesCount:hasLabel:label:
distanceToDefaultBox
initWithBox:defaultBox:confidence:scale:
initWithBox:defaultBox:confidence:scale:hasLabel:label:
initWithBox:defaultBox:confidence:scale:hasLabel:label:labelName:
smartDistance
setBox:
setDefaultBox:
setMergesCount:
setHasLabel:
setLabelName:
_area
_hasLabel
_mergesCount
_labelName
_box
_defaultBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
Tf,N,V_confidence
Ti,N,V_scale
Ti,N,V_mergesCount
TB,N,V_hasLabel
Ti,N,V_label
T@"NSString",&,N,V_labelName
T{CGPoint=dd},R,N
Tf,R,N
center
objectType
setObjectType:
setBounds:
_bounds
_objectType
Tq,V_objectType
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGPoint=dd},R
Tf,V_confidence
_imageSaliencyRequest
set_imageSaliencyRequest:
salientObjects
narrowedBoundingBox
prominentObjectWithBoundingBox:canvasSize:confidence:
__imageSaliencyRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V__imageSaliencyRequest
setTitle:
_commonInitWithLowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
initWithAttributedTitle:lowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
setScaleType:
gridlinePositions
valueDescriptionProvider
initWithTitle:lowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
attributedTitle
setAttributedTitle:
scaleType
dictionaryRepresentation
initWithDictionary:
T@"NSString",C,N
T@"NSAttributedString",C,N
normalizedAxisValueForValue:
setLowerBound:
setUpperBound:
setValueDescriptionProvider:
setGridlinePositions:
_title
_attributedTitle
_scaleType
_lowerBound
_upperBound
_valueDescriptionProvider
_gridlinePositions
T@"AXMScale",&,N,V_scale
Tq,N,V_scaleType
Td,N,V_lowerBound
Td,N,V_upperBound
T@?,C,N,V_valueDescriptionProvider
T@"NSArray",C,N,V_gridlinePositions
T@"NSString",C,N,V_title
T@"NSAttributedString",C,N,V_attributedTitle
initWithAttributedTitle:categoryOrder:
allocWithZone:
initWithTitle:categoryOrder:
setCategoryOrder:
_categoryOrder
T@"NSArray",C,N,V_categoryOrder
setNumber:
setCategory:
setIsEmptyValue:
isEmptyValue
valueWithNumber:
valueWithCategory:
emptyValue
_isEmptyValue
_number
_category
Td,N,V_number
T@"NSString",C,N,V_category
TB,R,N,V_isEmptyValue
initWithX:y:additionalValues:label:
yValue
additionalValues
attributedLabel
zNumericAxisValue
initWithX:y:
initWithX:y:additionalValues:
setXValue:
setYValue:
setAdditionalValues:
setAttributedLabel:
setValueDescription:
setTimeEncodingValue:
setPitchEncodingValue:
setVolumeEncodingValue:
setDurationEncodingValue:
setTimbreEncodingValue:
_xValue
_yValue
_additionalValues
_attributedLabel
_valueDescription
_timeEncodingValue
_pitchEncodingValue
_volumeEncodingValue
_durationEncodingValue
_timbreEncodingValue
_playbackTimeOffsetMS
T@"AXMDataPointValue",C,N,V_timeEncodingValue
T@"NSNumber",C,N,V_pitchEncodingValue
T@"NSNumber",C,N,V_volumeEncodingValue
T@"NSNumber",C,N,V_durationEncodingValue
T@"NSString",C,N,V_timbreEncodingValue
Td,N,V_playbackTimeOffsetMS
T@"AXMDataPointValue",C,N,V_xValue
T@"AXMDataPointValue",C,N,V_yValue
T@"NSArray",C,N,V_additionalValues
T@"NSAttributedString",C,N,V_attributedLabel
T@"NSString",C,N,V_valueDescription
T@"AXMDataPointValue",R,N
_commonInitWithContinuous:dataPoints:
initWithAttributedName:isContinuous:dataPoints:
attributedName
_mutableArrayOfNSNullWithCount:
initWithName:isContinuous:dataPoints:
additionalNumericalValues
additionalCategoricalValues
setDataSummary:
setAttributedName:
setIsContinuous:
setDataPoints:
dataSummary
_isContinuous
_attributedName
_dataPoints
_dataSummary
_meanValueDescription
T@"NSAttributedString",C,N,V_attributedName
TB,N,V_isContinuous
T@"NSArray",C,N,V_dataPoints
T@"AXMDataSummary",R,N,V_dataSummary
T@"NSString",R,N,V_meanValueDescription
initWithTitle:summary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
initWithAttributedTitle:summary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
_commonInitWithSummary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
setContentDirection:
setContentFrame:
summary
additionalAxes
contentDirection
initWithTitle:summary:xAxisDescriptor:yAxisDescriptor:series:
initWithAttributedTitle:summary:xAxisDescriptor:yAxisDescriptor:series:
generateDataSummariesWithCompletion:
setSummary:
contentFrame
setXAxis:
setYAxis:
setAdditionalAxes:
annotations
setAnnotations:
_timeNumericAxisDescriptor
_timeCategoricalAxisDescriptor
_pitchAxisDescriptor
_durationAxisDescriptor
_volumeAxisDescriptor
_timbreAxisDescriptor
_summary
_contentDirection
_xAxis
_yAxis
_additionalAxes
_annotations
_contentFrame
T@"NSArray",C,N,V_annotations
T@"NSString",C,N,V_summary
Tq,N,V_contentDirection
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_contentFrame
T@"NSArray",C,N,V_series
T@"<AXMDataAxisDescriptor>",&,N,V_xAxis
T@"AXMNumericDataAxisDescriptor",&,N,V_yAxis
T@"NSArray",C,N,V_additionalAxes
T@"<AXMDataAxisDescriptor>",R,N
T@"AXMNumericDataAxisDescriptor",R,N,V_timeNumericAxisDescriptor
T@"AXMCategoricalDataAxisDescriptor",R,N,V_timeCategoricalAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_pitchAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_durationAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_volumeAxisDescriptor
T@"AXMCategoricalDataAxisDescriptor",R,N,V_timbreAxisDescriptor
domain
setDomain:
_domain
T@"NSArray",C,N,V_domain
initWithLowerBound:upperBound:apply:invert:
linearScaleWithLowerBound:upperBound:
log10ScaleWithLowerBound:upperBound:
lnScaleWithLowerBound:upperBound:
apply
setApply:
setInvert:
_apply
_invert
T@?,C,N,V_apply
T@?,C,N,V_invert
initWithDomain:
initWithLocation:label:
initWithLocation:
location
setLocation:
playsHaptic
setPlaysHaptic:
speakDuringPlayback
setSpeakDuringPlayback:
_playsHaptic
_speakDuringPlayback
_location
T@"AXMDataPoint",&,N,V_location
T@"NSString",C,N,V_label
TB,N,V_playsHaptic
TB,N,V_speakDuringPlayback
initWithModelPath:espressoEngineID:espressoDeviceID:configuration:version:modelType:
setInputShape:height:
runNetwork:inputIsBGR:
timeIntervalSinceDate:
processVImage:inputIsBGR:
resizeAndProcessVImage:inputIsBGR:
preferredSmallSide
setVersion:
setModelType:
.cxx_construct
_modelType
_espressoPlan
_espressoContext
_espressoNetwork
_logitsPosOutputs
_logitsNegOutputs
_offsetsOutputs
_rollOutputs
_yawOutputs
_currentNetworkWidth
_currentNetworkHeight
_version
_maxout_layers
_bins_neg_maxout
_has_pose
_pose_square
_extra_default_boxes
_num_pos_classes
_important_classes
_model_labels
_num_ratios
_default_boxes_sides
_default_boxes_sides_normalized
_defaultBoxSizes
_cell_starts_x
_cell_starts_y
_input_aspect_ratio
_keep_aspect_ratio
_can_rotate
_input_height
Tf,N,V_threshold
Ti,N,V_version
Tq,N,V_modelType
captureOutput
setCaptureOutput:
_captureOutput
T@"AVCaptureMetadataOutput",&,N,V_captureOutput
setPriority:
priority
defaultPriority
defaultANEDevice
setProcessingDevice:
setModelFileBackingStore:
_diagnosticNameForRequests:metrics:
measure:tryExecute:
preferredModelInputSize
isANEDeviceAvailable
ANEDeviceAvailable
TB,R,N,GisANEDeviceAvailable
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
setCaptureNode:
setTextDetector:
setAxElementDetector:
textDetector
axElementDetector
_captureNode
_textDetector
_axElementDetector
T@"AXMScreenCaptureNode",W,N,V_captureNode
T@"AXMTextDetectorNode",W,N,V_textDetector
T@"AXMAXElementDetectorNode",W,N,V_axElementDetector
setInputSource:
_inputSource
T@"AXMAudioDataSource",W,N,V_inputSource
valueWithRange:
rangeValue
_textRange
T@"VNRecognizedText",R,N,V_text
T{_NSRange=QQ},R,N,V_textRange
setIs3DLandmarks:
is3DLandmarks
leftEye
pointsArrayForRegion:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
pointCount
normalizedPoints
axmValueWithCGPoint:
unitTestingFaceLandmarksIs3D:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
_is3DLandmarks
TB,N,V_is3DLandmarks
setNormalizedMinimumTextHeightRatio:
setTextDetectionLocales:
setPostProcessingOptions:
postProcessingOptions
arrayWithArray:
_usesLanguageCorrection
_recognitionLevel
_normalizedMinimumTextHeightRatio
_textDetectionLocales
_postProcessingOptions
TQ,N,V_recognitionLevel
Td,N,V_normalizedMinimumTextHeightRatio
TB,N,V_usesLanguageCorrection
T@"NSArray",&,N,V_textDetectionLocales
TQ,N,V_postProcessingOptions
initWithHeight:width:numberOfDiscretePinHeights:
hasConsistentHorizontalPinSpacing
setHasConsistentHorizontalPinSpacing:
hasConsistentVerticalPinSpacing
setHasConsistentVerticalPinSpacing:
verticalPinSpacing
setVerticalPinSpacing:
horizontalPinSpacing
setHorizontalPinSpacing:
interCellHorizontalSpacing
setInterCellHorizontalSpacing:
interCellVerticalSpacing
setInterCellVerticalSpacing:
_hasConsistentHorizontalPinSpacing
_hasConsistentVerticalPinSpacing
_width
_height
_numberOfDiscretePinHeights
_verticalPinSpacing
_horizontalPinSpacing
_interCellHorizontalSpacing
_interCellVerticalSpacing
TQ,R,V_width
TQ,R,V_height
TQ,R,V_numberOfDiscretePinHeights
TB,N,V_hasConsistentHorizontalPinSpacing
TB,N,V_hasConsistentVerticalPinSpacing
Td,N,V_verticalPinSpacing
Td,N,V_horizontalPinSpacing
Td,N,V_interCellHorizontalSpacing
Td,N,V_interCellVerticalSpacing
initWithCanvasDescription:
setZoomLevel:
setOrigin:
setEdgeStrength:
setCanvasDescription:
_zoomLevel
_edgeStrength
_canvasDescription
_origin
T@"AXMBrailleCanvasDescription",&,N,V_canvasDescription
Td,N,V_zoomLevel
T{CGPoint=dd},N,V_origin
Td,N,V_edgeStrength
TB,N,V_invert
setClientID:
setIncludeImageInResult:
setDetectText:
setTextDetectionOptions:
setDetectScenes:
setDetectObjects:
setDetectNSFW:
setDetectSignificantEvents:
setDetectModelClassifications:
setDetectCaptions:
setDetectTraits:
setDetectFaceRectangles:
setDetectFaceNames:
setDetectFaceAttributes:
setDetectFaceExpressions:
setDetectFaceLandmarks:
setDetectFacePose:
setDetectProminentObjects:
setDetectHorizon:
setDetectRectangles:
setDetectAXElements:
detectFaceRectangles
detectFaceNames
detectFaceAttributes
detectFaceExpressions
detectFaceLandmarks
detectFacePose
setDetectAesthetics:
setDetectBrailleEdges:
setPreserveInputImageSize:
setBrailleEdgeOptions:
setIgnoredLayerContextIDs:
setIncludedLayerContextIDs:
setPreferredOutputLocale:
clientID
preferredOutputLocale
voiceOverOptions
hasDetectionsEnabled
disableAllDetectors
_detectFaceRectangles
_detectFaceNames
_detectFaceAttributes
_detectFaceExpressions
_detectFaceLandmarks
_detectFacePose
_detectScenes
_detectObjects
_detectNSFW
_detectSignificantEvents
_detectModelClassifications
_detectCaptions
_detectTraits
_detectRectangles
_detectHorizon
_detectProminentObjects
_detectAesthetics
_detectIconClass
_detectBrailleEdges
_detectAXElements
_detectText
_includeImageInResult
_preserveInputImageSize
_clientID
_brailleEdgeOptions
_textDetectionOptions
_preferredOutputLocale
_ignoredLayerContextIDs
_includedLayerContextIDs
Tq,N,V_clientID
TB,N,V_detectFaceRectangles
TB,N,V_detectFaceNames
TB,N,V_detectFaceAttributes
TB,N,V_detectFaceExpressions
TB,N,V_detectFaceLandmarks
TB,N,V_detectFacePose
TB,N,V_detectScenes
TB,N,V_detectObjects
TB,N,V_detectNSFW
TB,N,V_detectSignificantEvents
TB,N,V_detectModelClassifications
TB,N,V_detectCaptions
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHorizon
TB,N,V_detectProminentObjects
TB,N,V_detectAesthetics
TB,N,V_detectIconClass
TB,N,V_detectBrailleEdges
T@"AXMBrailleEdgeDetectorOptions",&,N,V_brailleEdgeOptions
TB,N,V_detectAXElements
TB,N,V_detectText
T@"AXMTextDetectionOptions",&,N,V_textDetectionOptions
TB,N,V_includeImageInResult
T@"NSLocale",&,N,V_preferredOutputLocale
T@"NSArray",&,N,V_ignoredLayerContextIDs
T@"NSArray",&,N,V_includedLayerContextIDs
TB,N,V_preserveInputImageSize
setComponents:
setUsesPrivateAudioSession:
setHapticEngineUsesAutoShutdown:
setHapticEngineAutoShutdownTimeout:
initWithConfiguration:
setConfiguration:
usesPrivateAudioSession
components
setRequest:
dispatchRequest:
request
initWithComponents:options:
disable
enableWithCompletion:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
playActiveSound:
configuration
_outputRequests
_usesPrivateAudioSession
_audioSession
_state
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_configuration
T@"AXMOutputManagerConfiguration",&,N,V_configuration
T@"AXMOutputRequest",&,N,V_request
hapticEngineUsesAutoShutdown
hapticEngineAutoShutdownTimeout
hapticEngineUsesHapticsOnly
setHapticEngineUsesHapticsOnly:
_hapticEngineUsesAutoShutdown
_hapticEngineUsesHapticsOnly
_components
_hapticEngineAutoShutdownTimeout
TQ,N,V_components
TB,N,V_usesPrivateAudioSession
TB,N,V_hapticEngineUsesAutoShutdown
Td,N,V_hapticEngineAutoShutdownTimeout
TB,N,V_hapticEngineUsesHapticsOnly
aWeighting
_frequency
_envelope
_aWeighting
TQ,N,V_sampleRate
Td,R,N,V_frequency
T@"AXMADSREnvelope",R,N,V_envelope
Td,R,N,V_aWeighting
getResidualsVector:result:
computeScore
fitDataWithModelParams:finalParams:
nodeQueue
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
initWithImage:
featureValueWithDictionary:error:
featureValueWithString:
initWithLabelProbability:label:
labelProbability
setLabelProbability:
_labelProbability
T@"NSDictionary",&,N,V_labelProbability
dictionaryValue
stringValue
predictionFromImage:error:
_aspectFaceRectFromSquareFaceRect:sizeInPixels:
faceID
type
angle
_serializeWithCoder:orDictionary:
_nameForOCRFeatureType:
locationForNormalizedFrame:previousLocation:usingThirds:
_append:toList:
locationUsingThirds:withFlippedYAxis:
nameForLocation:
barcodeType
caption
horizonAngle
cameraType
isEqualToAXMVisionFeature:
featureWithMetadata:interfaceOrientation:isMirrored:canvasSize:
personWithBoundingBox:confidence:canvasSize:
featureWithVisionRequest:brightnessValue:canvasSize:
objectClassificationWithLabel:localizedValue:boundingBox:confidence:canvasSize:sceneClassId:
sceneClassificationWithLabel:localizedValue:confidence:canvasSize:
significantEventClassificationWithCategory:confidence:canvasSize:
featureWithTaxonomyNode:canvasSize:
featureWithColorInfo:canvasSize:
localizedStringForLocation:isSubjectImplicit:
uiClassForName:
flattenedFeatureList:
filterFeatureList:basedOnSceneClassIdsForFeature:
colorInfo
facePose
horizonTransform
isBarcode
isRealtimeFace
isPerson
isSignificantEventClassification
isColor
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
isTextRegion
isTextLine
isTextSequence
isTableRow
isTableColumn
isTableCell
isEnvelopeRegion
isTextCharacter
isTextDiacritic
isMotion
isCameraMetadata
isProminentObject
isImageAesthetics
boundingBoxForRange:
unpaddedDetectedFaceRect
aestheticsResult
deviceOrientation
debugRectangles
setDebugRectangles:
overrideLabel
setOverrideLabel:
_featureType
_barcodeType
_ocrFeatureType
_normalizedFrame
_value
_values
_isValueSpeakable
_recognizedTextFeatures
_colorInfo
_assetMetadata
_blur
_isLowConfidence
_horizonTransform
_horizonAngle
_faceDetectionResult
_facePose
_modelID
_classificationLabel
_classificationLocalizedValue
_caption
_translatedCaption
_featureGates
_captionMayContainSensitiveContent
_aestheticsResult
_deviceMotion
_deviceOrientation
_cameraType
_debugRectangles
_overrideLabel
_activationPoint
_unpaddedDetectedFaceRect
T@"NSDictionary",&,N,V_debugRectangles
T@"NSString",&,N,V_overrideLabel
T@"NSArray",R,N,V_recognizedTextFeatures
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T@"NSArray",R,N,V_values
Tq,N,V_uiClass
T@"AXMTranslatedText",R,N
T@"AXMVisionFeatureColorInfo",R,N
T@"AXMVisionFeatureAssetMetadata",R,N
T@"AXMVisionFeatureFaceDetectionResult",R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unpaddedDetectedFaceRect
T{CGAffineTransform=dddddd},R,N
T@"AXMVisionFeatureAestheticsResult",R,N,V_aestheticsResult
T@"CMDeviceMotion",R,N,V_deviceMotion
Tq,R,N,V_deviceOrientation
Tq,R,N,V_cameraType
TB,N,V_captionMayContainSensitiveContent
T{CGPoint=dd},N,V_activationPoint
unitTestingFeatureWithType:canvasSize:frame:value:valueIsSpeakable:barcodeType:ocrFeatureType:subFeatures:
unitTestingFaceFeatureWithSize:faceFrame:
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:subFeatures:
unitTestingTeatureWithType:axElementRect:confidence:uiClass:label:canvasSize:
unitTestingFeature
unitTestingFaceFeature
unitTestingProminentObjectFeature
unitTestingHorizonFeature
setX:
setY:
Td,N,V_x
Td,N,V_y
initWithXValues:yValues:count:
isDisqualified
score
getJacobianForParameters:gradient:result:
getDiagonal:size:result:
getMatrixInverse:size:pivot:tmp:result:
magnitude:size:
getGradientForX:parameterValues:result:
printMatrix:rows:cols:
getIdentityMatrixWithSize:scalar:result:
roundNumber:withSignificantFigures:
iterations
_score
_bestFitParameters
_isDisqualified
_iterations
Td,R,N,V_error
Td,R,N,V_score
TB,N,V_isDisqualified
T^d,R,N,V_bestFitParameters
Ti,R,N
T@?,R,N
Ti,R,N,V_iterations
T^d,R,N,V_x
T^d,R,N,V_y
Ti,R,N,V_n
createNSExceptionWithStatus:andMessage:
setOverrideModelURL:
setOverrideScaleMethod:
setGenderStrategy:
setSceneDetector:
overrideModelURL
overrideScaleMethod
genderStrategy
sceneDetector
effectiveModelURL
effectiveCaptionModelInfo
_sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
T@"NSURL",&,N
TQ,N
T@"AXImageCaptionModel",R,N
knownSceneClassifications
possibleSceneClassifications
_shouldIncludeSceneLabelForOCRDocumenTypeDetection:
taxonomyOptions
_sceneClassificationRequest
_setSceneClassificationRequest:
_taxonomyOptions
__sceneClassificationRequest
T@"VNSceneClassificationRequest",&,N,S_setSceneClassificationRequest:,V__sceneClassificationRequest
TI,N,V_taxonomyOptions
setPlayer:
setTimePitch:
player
attachNode:
mainMixerNode
initStandardFormatWithSampleRate:channels:
timePitch
connect:to:fromBus:toBus:format:
nextAvailableInputBus
detachNode:
processingFormat
initWithPCMFormat:frameCapacity:
readIntoBuffer:error:
scheduleBuffer:atTime:options:completionHandler:
connectToEngine:
disconnectFromEngine:
beginPlayback:withError:
_player
_timePitch
T@"AVAudioPlayerNode",&,N,V_player
T@"AVAudioUnitTimePitch",&,N,V_timePitch
_startEngineIfNeeded:
initForReading:error:
_scheduleOneShotSound:completion:
_scheduleActiveSound:
setActiveSound:
setSoundComponent:
scheduleFile:atTime:completionHandler:
isRunning
startAndReturnError:
_stopActiveSound:
_logAudioFileInfo:
configChangedObserverToken
setConfigChangedObserverToken:
_engine
_oneShotSoundPlayer
_activeSounds
_configChangedObserverToken
T@,&,N,V_configChangedObserverToken
activeSound
soundComponent
_rate
_pitch
_activeSound
_soundComponent
T@"AXMActiveSound",W,N,V_activeSound
T@"AXMSoundComponent",W,N,V_soundComponent
Tf,N,V_rate
Tf,N,V_pitch
setConnected:
freeResources
setEnabled:
setNodeQueue:
_connected
_enabled
_nodeQueue
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
enabled
TB,N,GisEnabled,V_enabled
effectsChain
addEffectToChain:
removeEffectFromChain:
setCircular:
_circular
_sampleBuffer
_currentSampleIndex
_level
_effectsChain
Td,R,N,V_sampleRate
T^v,R,N,V_sampleBuffer
TQ,N,V_length
TQ,N,V_currentSampleIndex
circular
TB,N,GisCircular,V_circular
Td,N,V_level
T@"NSArray",R,N,V_effectsChain
addSignificantEventResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
systemReport
privilegedSystemReport
initWithData:
triggerWithImageURL:assetLocalIdentifier:photoLibraryURL:options:cacheKey:resultHandler:
triggerWithImageURL:options:cacheKey:resultHandler:
triggerWithPixelBuffer:exifOrientation:options:cacheKey:resultHandler:
triggerWithImageAssetLocalIdentifier:photoLibraryURL:options:cacheKey:resultHandler:
setObjectDetector:
setFaceDetector:
setTraitDetector:
setProminentObjectsDetector:
setNsfwDetector:
setSignificantEventDetector:
setCaptionDetector:
captionDetector
configuredOptionsDisableAllDetectors:elementOptions:textRecognitionLevel:textDetectionLocales:preferringFullCaptions:
objectDetector
faceDetector
traitDetector
prominentObjectsDetector
nsfwDetector
significantEventDetector
_objectDetector
_faceDetector
_traitDetector
_prominentObjectsDetector
_captionDetector
_nsfwDetector
_significantEventDetector
T@"AXMObjectDetectorNode",W,N,V_objectDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
T@"AXMProminentObjectsDetectorNode",W,N,V_prominentObjectsDetector
T@"AXMCaptionDetectorNode",W,N,V_captionDetector
T@"AXMNSFWDetectorNode",W,N,V_nsfwDetector
T@"AXMSignificantEventDetectorNode",W,N,V_significantEventDetector
setText:
setTargetLocale:
setLowConfidence:
text:confidence:isLowConfidence:targetLocale:
_lowConfidence
_targetLocale
T@"NSString",&,N,V_text
lowConfidence
TB,N,GisLowConfidence,V_lowConfidence
T@"NSLocale",&,N,V_targetLocale
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
axmAppendIndentation:
initWithFormat:arguments:
autoupdatingCurrentLocale
dateFormatFromTemplate:options:locale:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMAffineTransformValue
axmValueWithCGVector:
axmValueWithCGSize:
T{CGVector=dd},R,N
setTimeOffsetMS:
volume
setVolume:
_timeOffsetMS
_volume
Td,N,V_frequency
Td,N,V_volume
Td,N,V_timeOffsetMS
_bufferFrameForKeyPitch:
_keyPitches
initWithInteger:
postComputeWithDecoded:nmsThreshold:filterThresholds:
postComputeClickabilityWithDecoded:nmsThreshold:filterThresholds:
resultBox
resultLabel
resultLabelName
resultConfidence
shape
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64^@72
v32@0:8d16@?24
@16@0:8
@24@0:8Q16
@28@0:8Q16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@40@0:8@16Q24Q32
@44@0:8@16Q24Q32B40
@56@0:8@16Q24Q32B40B44^@48
B16@0:8
v16@0:8
@24@0:8@16
v24@0:8@16
v32@0:8@16@24
@"VNDetectHorizonRequest"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
q16@0:8
@168@0:8q16q24q32q40q48q56q64q72q80q88q96q104q112q120q128q136q144q152q160
q24@0:8@16
v24@0:8q16
@"NSDictionary"
@32@0:8d16@24
@40@0:8d16d24@32
v32@0:8^v16Q24
@40@0:8@16{CGSize=dd}24
@32@0:8@16@24
@"VNDetectFaceRectanglesRequest"
@"VNCreateFaceprintRequest"
@"VNClassifyFaceAttributesRequest"
@"VNDetectFaceExpressionsRequest"
@"VNDetectFaceLandmarksRequest"
@"VNDetectFacePoseRequest"
@"VNClassifyImageAestheticsRequest"
@36@0:8@16@24i32
@48@0:8@16@24i32i36q40
@36@0:8@16f24@28
f16@0:8
v20@0:8f16
@32@0:8@16f24f28
i16@0:8
v20@0:8i16
@"AXShotflowNetwork"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"<AXMServiceDelegate>"
@"NSXPCConnection"
@?16@0:8
v20@0:8B16
@"AXMOutputRequestHandle"
@"NSMutableArray"
v24@0:8^d16
@28@0:8^d16i24
B24@0:8^@16
@"NSURL"
@"NSString"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
@24@0:8q16
v32@0:8q16@24
v40@0:8@16q24@32
v32@0:8@16^B24
@"NSMutableString"
@"NSMutableDictionary"
@"AXMVisionFeature"
@"CIImage"
@"NSNumber"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
B24@0:8@"AXMVisionEngineNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
v32@0:8@16q24
v32@0:8@"AXMService"16q24
@24@0:8^{_NSZone=}16
v32@0:8@"NSMutableString"16q24
B32@0:8@16@24
@32@0:8@16B24B28
v40@0:8@16@24@32
@24@0:8#16
v24@0:8Q16
@"AXMImageRegistrationNode"
@"_AXMVisionEngineAnalysisTask"
@"AXMVisionEngineCache"
@"AXMService"
@"AXMTaskDispatcher"
@"AXMSequenceRequestManager"
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@56@0:8f16f20q24q32d40@48
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56q60B68
@"CMAttitude"
d40@0:8d16d24d32
@136@0:8@?16d24@32{?=^dddddd}40{?=^dddddd}88
d24@0:8d16
{?=^dddddd}16@0:8
{?="values"^d"scaleMinimum"d"scaleMaximum"d"valueMinimum"d"valueMaximum"d"count"d}
{CGSize=dd}16@0:8
B40@0:8@16@24d32
@"AXMPipelineContextInput"
@"AXBookendMetric"
@"VNSceneObservation"
@"NSMutableOrderedSet"
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSObject<NSSecureCoding>"
@"<NSCopying>"
@"AXMetricSession"
@"NSMutableSet"
@"AXMVisionResult"
@"VNImageRequestHandler"
d24@0:8@16
@"AXMSemanticTextFactory"
@"AXMTextLayoutManager"
@"AXMTextSpecialCase"
@32@0:8@16d24
@"AXMImageNode"
@"AXMIconClassDetectorNode"
@"AXMBrailleEdgesDetectorNode"
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8^{__CVBuffer=}16d24d32
^{__CVBuffer=}16@0:8
v24@0:8^{__CVBuffer=}16
^{__CVBuffer=}
@"MLMultiArray"
@32@0:8@16^@24
@40@0:8@16@24^@32
@48@0:8^{__CVBuffer=}16d24d32^@40
@"MLModel"
@36@0:8@16@24B32
I16@0:8
v20@0:8I16
@"NSData"
@"NSDate"
@64@0:8d16d24d32d40d48d56
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
@48@0:8d16d24d32@40
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v32@0:8@16@?24
@"AVSpeechSynthesizer"
@36@0:8@16d24B32
@"NSSet"
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v40@0:8@"AXMAVCaptureSessionNode"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v52@0:8^{opaqueCMSampleBuffer=}16q24B32@36@44
@"AXMCaptureVideoDataOutput"
@"<AXMAVCaptureSessionNodeDelegate>"
@"<AXMAVCaptureSessionNodeFrameDelegate>"
@"AVCaptureSession"
v32@0:8Q16Q24
v32@0:8Q16@24
@"AVAudioSession"
v32@0:8q16@?24
^{vImage_Buffer=^vQQQ}24@0:8@16
{shared_ptr<CGImage>=^{CGImage}^{__shared_weak_count}}24@0:8@16
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
v44@0:8@16@24B32@36
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
@32@0:8Q16d24
@32@0:8Q16@24
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"AXAssetController"
d24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
@"AXMVisionFeatureFaceAttributes"
@"AXMVisionFeatureFaceLandmarks"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{?="columns"[4]}
@24@0:8^{__CVBuffer=}16
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
B32@0:8@16^@24
v40@0:8@16@24@?32
@32@0:8^{__CVBuffer=}16^@24
B44@0:8@16@24d32B40
@"VNVYvzEtX1JlUdu8xx5qhDI"
{CGRect={CGPoint=dd}{CGSize=dd}}92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56f60@64f72f76q80B88
{?=ii}24@0:8@16
@"VNSequenceRequestHandler"
@"VNRecognizeObjectsRequest"
@48@0:8@16@24^{CGColorSpace=}32@40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
q28@0:8i16q20
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@"AXMLayoutHeader"
@40@0:8@16@24@32
@60@0:8@16{CGSize=dd}24@40B48^@52
@48@0:8@16@24{CGSize=dd}32
@72@0:8@16{CGSize=dd}24@40@48@56^@64
@64@0:8@16{CGSize=dd}24@40@48^@56
@80@0:8@16d24{CGSize=dd}32@48@56@64^@72
@48@0:8@16Q24Q32@40
@32@0:8@16^{CGRect={CGPoint=dd}{CGSize=dd}}24
@72@0:8@16d24Q32Q40@48@56^{CGRect={CGPoint=dd}{CGSize=dd}}64
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGRect={CGPoint=dd}{CGSize=dd}}56
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48d80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16Q48Q56
@40@0:8@16^B24@32
B32@0:8@16Q24
@56@0:8@16d24d32d40d48
@40@0:8@16d24d32
@120@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{CGRect={CGPoint=dd}{CGSize=dd}}88
@56@0:8@16@24@32{CGSize=dd}40
@"NSNumberFormatter"
@"NSMeasurementFormatter"
[10{CGPoint="x"d"y"d}]
v40@0:8q16@24@?32
@"NSLocale"
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@56@0:8d16d24d32d40d48
{?=@@Q}24@0:8@16
@"AXMOutputActionHandle"
@"<AXMActiveSoundOutputActionHandleProvider>"
^{CGColorSpace=}16@0:8
^{CGImage=}24@0:8@16
@"AXMPixelBufferWrapper"
^{CGColorSpace=}
{CGSize="width"d"height"d}
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@40@0:8@16@24q32
B28@0:8B16@20
q80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v32@0:8{CGSize=dd}16
@"NSRegularExpression"
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
v40@0:8@16{_NSRange=QQ}24
v36@0:8B16{_NSRange=QQ}20
v32@0:8{_NSRange=QQ}16
@"NSMutableAttributedString"
^{_LXLexicon=}24@0:8@16
@"NSDataDetector"
@"NLTagger"
B48@0:8@16^@24B32B36^@40
@"NSAttributedString"
@"AXMSemanticText"
@28@0:8^{__CVBuffer=}16I24
v32@0:8d16d24
d32@0:8d16@24
Q24@0:8d16
B32@0:8@16d24
v40@0:8^v16Q24d32
^v16@0:8
^{OpaqueAudioComponentInstance=}
@"AXMLiveContinuousTone"
@"AXMSynthPatch"
@"AXMChartDescriptor"
@"NSTimer"
@"AXMAudioDataSourceMixer"
@"AXMAudioDataSource"
@"NSPointerArray"
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@72@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64i68
@48@0:8@16#24@32^@40
C36@0:8d16Q24B32
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
@24@0:8@?16
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8^d16@24
@"AXMDataSeriesDescriptor"
@"AXMDataRegressionModel"
@"NSObject<AXMDataSummaryCategoryNameProvider>"
I32@0:8q16q24
I28@0:8q16B24
@40@0:8q16q24^I32
@36@0:8q16B24^I28
@48@0:8@16{CGSize=dd}24@40
@24@0:8d16
v36@0:8@16I24@28
v48@0:8@16q24@32@?40
v24@0:8^@16
@"NSString"24@0:8d16
@"AXMDataSummary"
v40@0:8^v16Q24Q32
^{__CFString=}24@0:8@16
@44@0:8@16@24i32@36
^{CGImage=}36@0:8^{CGImage=}16f24B28B32
^{CGImage=}28@0:8^{CGImage=}16i24
^{CGContext=}24@0:8^{CGImage=}16
^{CGImage=}32@0:8@16^@24
^{CGImage=}32@0:8^{CGImageSource=}16^@24
^v56@0:8@16^I24^I32^I40^@48
^{vImage_Buffer=^vQQQ}40@0:8@16B24B28^@32
^{vImage_Buffer=^vQQQ}36@0:8@16B24^@28
^{vImage_Buffer=^vQQQ}32@0:8@16^@24
^{__CVBuffer=}32@0:8@16^@24
@52@0:8i16^{__CVBuffer=}20@28@36^@44
@48@0:8^{__CVBuffer=}16@24@32^@40
^{CGImage=}32@0:8r^{vImage_Buffer=^vQQQ}16^@24
@36@0:8r^{vImage_Buffer=^vQQQ}16f24^@28
@40@0:8r^{vImage_Buffer=^vQQQ}16@24^@32
@48@0:8r^{vImage_Buffer=^vQQQ}16@24@32^@40
@40@0:8^{CGImage=}16^{__CFString=}24^@32
B40@0:8^{CGImage=}16@24^@32
@48@0:8r^{CGImage=}16@24@32^@40
@60@0:8^v16I24I28I32@36@44^@52
{vImage_Buffer=^vQQQ}36@0:8^{__CVBuffer=}16i24^@28
{vImage_Buffer=^vQQQ}32@0:8^{CGImage=}16^@24
q56@0:8^v16i24i28Q32^v40Q48
q72@0:8^v16i24i28Q32^v40Q48^v56Q64
q76@0:8^v16i24i28Q32B40^v44Q52^v60Q68
q92@0:8^v16Q24^v32Q40^v48Q56i64i68B72^v76Q84
q76@0:8^v16Q24^v32Q40i48i52B56^v60Q68
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84
@92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84B88i92
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84B88i92@96
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88B92i96
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88B92i96@100
f24@0:8@16
B32@0:8@16f24f28
B32@0:8@16f24i28
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSAttributedString"16@0:8
v24@0:8@"NSAttributedString"16
@56@0:8@16d24d32@40@?48
v48@0:8d16d24@32@?40
@"AXMScale"
@"AXMDataPointValue"
@36@0:8@16B24@28
v28@0:8B16@20
@64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32@40@48
@"AXMNumericDataAxisDescriptor"
@"AXMCategoricalDataAxisDescriptor"
@"<AXMDataAxisDescriptor>"
@32@0:8d16d24
@48@0:8d16d24@?32@?40
@"AXMDataPoint"
@44@0:8@16@24i32q36
@52@0:8@16i24i28@32i40q44
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{?="plan"^v"network_index"i}
{vector<std::shared_ptr<espresso_buffer_t>, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::shared_ptr<espresso_buffer_t> *, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__value_"^v}}
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
{vector<NSString *, std::allocator<NSString *>>="__begin_"^@"__end_"^@"__end_cap_"{__compressed_pair<NSString *__strong *, std::allocator<NSString *>>="__value_"^@}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
[6[20[2f]]]
@"AVCaptureMetadataOutput"
B56@0:8@16@24@32@40^@48
@"AXMScreenCaptureNode"
@"AXMTextDetectorNode"
@"AXMAXElementDetectorNode"
@40@0:8@16{_NSRange=QQ}24
@"VNRecognizedText"
{_NSRange="location"Q"length"Q}
@20@0:8B16
@40@0:8Q16Q24Q32
@"AXMBrailleCanvasDescription"
@"AXMBrailleEdgeDetectorOptions"
@"AXMTextDetectionOptions"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputManagerConfiguration"
@"AXMOutputRequest"
@"AXMADSREnvelope"
d32@0:8^d16^d24
@52@0:8@16q24B32{CGSize=dd}36
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGSize=dd}56
@44@0:8@16f24{CGSize=dd}28
@92@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64{CGSize=dd}68@84
@52@0:8@16@24f32{CGSize=dd}36
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48d56@64{CGSize=dd}72@88
@84@0:8@16B24{CGRect={CGPoint=dd}{CGSize=dd}}28@60{CGSize=dd}68
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56{CGSize=dd}64
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56d64{CGSize=dd}72
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56{CGSize=dd}64
@96@0:8@16B24{CGRect={CGPoint=dd}{CGSize=dd}}28@60@68{CGSize=dd}76B92
@92@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56@64{CGSize=dd}72B88
@32@0:8@16q24
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
@28@0:8q16B24
q60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48B56
{CGAffineTransform=dddddd}16@0:8
q24@0:8B16B20
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8{_NSRange=QQ}16
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceDetectionResult"
@"AXMTranslatedText"
@"AXMVisionFeatureAestheticsResult"
@"CMDeviceMotion"
@104@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88@96
@96@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@108@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72B80@84q92@100
@64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
@36@0:8^d16^d24i32
v32@0:8^d16i24i28
d28@0:8^d16i24
v36@0:8i16d20^d28
v32@0:8^d16^d24
v40@0:8d16^d24^d32
v40@0:8^d16^d24^d32
i52@0:8^d16i24^i28^d36^d44
v36@0:8^d16i24^d28
v28@0:8^d16i24
d32@0:8d16Q24
^d16@0:8
@32@0:8q16@24
@"AXMSceneDetectorNode"
@"VNSceneClassificationRequest"
@"AVAudioPlayerNode"
@"AVAudioUnitTimePitch"
@"AVAudioEngine"
@"AXMActiveSound"
@"<AXMVisionEngineNodeConnectionDelegate>"
@"VN6Mb1ME89lyW3HpahkEygIG"
v48@0:8@16@24@32@?40
v64@0:8@16@24@32@40@48@?56
v52@0:8^{__CVBuffer=}16I24@28@36@?44
v56@0:8@16@24@32@40@?48
@48@0:8@?16I24@?28@?36B44
@"AXMObjectDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
@"AXMProminentObjectsDetectorNode"
@"AXMCaptionDetectorNode"
@"AXMNSFWDetectorNode"
@"AXMSignificantEventDetectorNode"
@44@0:8@16d24B32@36
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@40@0:8@16d24@32
Q24@0:8@16
333333
MbP?#
333333
333333
UUUUUU
ffffff
ARGB
@(#)PROGRAM:AXMediaUtilities  PROJECT:AXMediaUtilities-1
@333333
A@q=
B@)\
?ffffff
e@q=
k@333333
@NSt3__120__shared_ptr_pointerIP7CGImagePFvS2_ENS_9allocatorIS1_EEEE
PFvP7CGImageE
FvP7CGImageE
N@333333
zt?{
ffffff
333333
?ffffff
?ffffff
?ffffff
4@333333
?uouacoirlppa
mcpl
*.(,
OKMI
UUUUUU
/B33
B33CCgf
?fff?
BNSt3__120__shared_ptr_emplaceI17espresso_buffer_tNS_9allocatorIS1_EEEE
(2<FPZdn
?UUUUUU
#*28>FKS
UUUUUU
?UUUUUU
?UUUUUU
?433333
!$'*-0369<?BEHKNQTWZ]`cfilorux{~
 #&),/258;>ADGJMPSVY\_behknqtwz}
ffffff
MbP?
#).5<
AXMediaUtilities
AXBoundingBox
UIType
UITypeClickability
AXMElementDetectorResult
AXMClickabilityDetectorResult
AXModelType
CodingKeys
CGRect
CGSize
CGPoint
IgnoredLayerContextIDs
IncludedLayerContextIDs
UsePreferredModelInputSizeForDetectors
Screen Grab
Screen grab not supported on this platform
Screen recording is not supported
v8@?0
Library/Accessibility/PhotoCaptionAssets
CompiledModels
UncompiledModels
mlmodelc
mlmodel
Horizon Detector
VNDetectHorizonRequest
Unable to find class %s
mainColors
mainColorWeights
ageConfidence
gender
genderConfidence
eyes
eyesConfidence
smiling
faceHair
hairColor
hairColorConfidence
bald
glasses
glassesConfidence
makeupEyes
makeupEyesConfidence
makeupLips
makeupLipsConfidence
facemask
facemaskConfidence
ethnicity
ethnicityConfidence
expression
expressionConfidence
faceHairV2
faceHairV2Confidence
hairType
hairTypeConfidence
headgear
headgearConfidence
pose
poseConfidence
skintone
skintoneConfidence
Pose_Front
Pose_LeftProfile
Pose_RightProfile
Pose_LeftThreeQuarters
Pose_RightThreeQuarters
Skintone_I
Skintone_II
Skintone_III
Skintone_IV
Skintone_V
Skintone_VI
Ethnicity_African
Ethnicity_Caucasian
Ethnicity_LatinAmerican
Ethnicity_EastAsian
Ethnicity_SouthAsian
Gender_Male
Gender_Female
Age_Baby
Age_Child
Age_YoungAdult
Age_Adult
Age_Senior
HairColor_Black
HairColor_Blonde
HairColor_Brown
HairColor_Gray
HairColor_Red
HairColor_White
Hairtype_Wavy
Hairtype_Curly
Hairtype_Straight
Hairtype_African
Hairtype_BuzzCut
Hairtype_SparseBald
Hairtype_Frizzy
FaceHairV2_BeardOnly
FaceHairV2_GoateeOnly
aceHairV2_MoustacheOnly
FaceHairV2_MoustacheAndBeard
FaceHairV2_MoustacheAndGoatee
FaceHairV2_Stubble
Glasses_Prescription
Glasses_Sunglasses
Facemask_Available
Headgear_Cap
Headgear_Hat
Headgear_Beanie
Headgear_Headscarf
MakeupEyes_Available
MakeupLips_Available
Expression_Laugh
Expression_Smile
Expression_Sad
Expression_Angry
Expression_Neutral
Eyes_Closed
Eyes_Open
.pose.left
.pose.right
.pose.left3_4
.pose.right3_4
.age.baby
.age.person
.haircolor.black
.haircolor.blonde
.haircolor.brown
.haircolor.gray
.haircolor.red
.haircolor.white
.hairtype.wavy
.hairtype.curly
.hairtype.straight
.facehair.included
.facehair.present
.prescription
.sunglasses
.facemask
.laughing
.smiling
faceattributes
com.apple.accessibility.AXMediaUtilities
Accessibility
.accessories
.expression
VNFaceAttributeAgeBaby
VNFaceAttributeAgeChild
VNFaceAttributeAgeYoungAdult
VNFaceAttributeAgeAdult
VNFaceAttributeAgeSenior
VN1yPD9G185LIMKFd9RgandG6vUu4B3DZk
VN6cM1E1jfvMnUZoEeDjinPOtJKpacqIpr
VNFaceAttributeEyesClosed
VNFaceAttributeEyesOpen
VNFaceAttributeHairColorBlack
VNFaceAttributeHairColorBlonde
VNFaceAttributeHairColorBrown
VNFaceAttributeHairColorGray
VNFaceAttributeHairColorRed
VNFaceAttributeHairColorWhite
VNFaceAttributeGlassesPrescription
VNFaceAttributeGlassesSunglasses
VNFaceAttributeGlassesNone
VNFaceAttributeMakeupEyesUnsure
VNFaceAttributeMakeupEyesNone
VNFaceAttributeMakeupEyes
VNFaceAttributeMakeupLipsUnsure
VNFaceAttributeMakeupLipsNone
VNFaceAttributeMakeupLips
VNFaceAttributeFacemaskNone
VNFaceAttributeFacemask
VN7yMsLB9ggBYLDbJYIMGMSW6YBgi5uH2p
VN2eECeAuLQ8wnXvvNNkc5XEtpjqyiYvIp
VN2AhEqI0IOCJAaCX6zovlg85aFZ80JfES
VN6a4sQBuQ5pSiUEd6p9iQflpz8xkWOnD2
VN6pbJdmseepvIGYzcDyryle1xGdZEWhHN
VN607hNga4JKRc1ljftiy9QfPCqbXQmLP4
VN2TVJG6FfNTt72vwVKOv1Jf5dWtEHvQIS
VN7ja3fTi9TZDyKN8NdYJaWqla1NRFdcRX
VN4lC1NTVMt6oWugtej0fqgS3z5p60aMup
VN1VQUXOcXrfZPXtaGgfZBhujM6uH6hvmI
VN6i04vrZluouTItkCUMtS916cLgTyvODX
VN42tJSMaSWdsAnZKXv8XcZg2j2AIS7gjm
VN7vELTVTtPH26ptfCYi9dUHH8NxJ7O3cF
VN5ijZTfHVHp6ubCHBh4oIZR1SW4xbvQ00
VN3WbFaDRN3PTBiMaMEq5ttCx7hmmfySmR
VN4lCLwxDV30rFLSeoihd8yM1zdbka3cVu
VN4qKg9nfl3p0M4juXFIsbUb7tpfCv9epx
VN31UxDngUK44hDexm8CSuZnlLxECLb0yU
VN5JBEfctS0JUWeTVUxBAKOSXCUuMqPxTg
VN7CY11MLEimaE8WoiQ4opgi5HOi84j0UH
VN5SpoOVxahuTheCrHGepAYKTVB1baFLhQ
VN6YAJH4UBXYDBoH6cemKhJR7fPi2dt5Qd
VN21VM8NbCJMJjpepNo1kZkxteFybpDwlB
VN6lDi9hTBjr2vdjAJ5rwdun4YEH09u5F5
VN2X5h7waRTqk71pInqK4dnT6sZ6dRElxe
VNPdH78Lr962vQvRIq2JApX2QJZtbR3fvi
VN2nEhtfck4KB7KsvJeCeSEPcGLfKzeUKi
VN465E5iEqlR2tknJ0qZkyAn3yIDrmUpJw
VN4oD9MSPBdmmSq6KG3k7nYqdSMT5aNp6p
VN34LMYSFC7onytwsvH0y6uz2QaYvqY9qi
VN5iEOkR2NrIkLsZRvJTn61k1ovk3hvuxY
VN7ICFqxCpgr8BTWkFrFGYTQ3INUhxhYXR
VN3rKrpi4DELvo8AgM5Y3C68ryFlgB1grk
VN7ar6bR0PqRvM9BZ0nqEdwh61tXzue1Ut
VN1I7oR8JHxER2i7d6nQxNtHhGXxkJuH7c
VNDGCsUiwnQwGz0qSSQPGGd177EyoSaoGN
VN6LhAjooMZpZkrkhS48XbQt7602EpEAxv
VN1HsiXmKrxTsH8TYOuN5s7G3uHSP75iYS
VN1kD4zwSpSn6esc2wHjyAeZ2IRmwqjgtt
VN1PwKd46IDZj2ErCN9d1fTn3FuN3h4d9p
VN4bzonkXHYlzBnJNXcyyPd8WLw1wAI1Pv
Face Detector
v32@?0@8Q16^B24
v32@?0@"NSString"8@"AXMVisionFeatureFaceDetectionResult"16^B24
VNDetectFaceExpressionsRequest
VNDetectFaceRectanglesRequest
VNClassifyFaceAttributesRequest
VNDetectFaceLandmarksRequest
VNDetectFacePoseRequest
Aesthetics
VNClassifyImageAestheticsRequest
B24@?0@"AXElementDetection"8@"NSDictionary"16
confidence
mergesCount
smartDistance
AXMServiceConnection
v16@?0@"NSError"8
AXMOutputRequest
B24@?0@"AXMOutputAction"8@"NSDictionary"16
chart.model.exponential
d32@?0^d8Q16d24
y = %@ * e^(%@x)
modelURL
Model Detector
Model loading not supported on this platform
region
orientation
Screen Capture
@"AXMPipelineContextInput"24@?0@"NSDictionary"8^@16
Traits
VNImageScoreObservation
VNImageBrightnessObservation
VNImageBlurObservation
VNImageBlurScoreRequest
_ContentVersion
FormatVersion
B32@?0@"MAAsset"8Q16^B24
q24@?0@"MAAsset"8@"MAAsset"16
v16@?0q8
v16@?0@"NSString"8
com.apple.accessibility.vot.caption.fallbacktemplates
fallbacktemplate
@"NSDictionary"8@?0
caption-low-confidence
caption-nsfw
photo.description.brightness.level.1
photo.description.brightness.level.2
photo.description.brightness.level.3
photo.description.brightness.level.4
photo.description.brightness.level.5
photo.description.blurriness.level.1
photo.description.blurriness.level.2
photo.description.blurriness.level.3
photo.description.blurriness.level.4
photo.description.blurriness.level.5
photo.description.blurriness.level.6
people.summary.one.person
people.summary.multiple.people
q24@?0@"AXMVisionFeature"8@"AXMVisionFeature"16
photo.description.faces
face.number
^(?!.*?\b(person|people|child|children|baby|babies)\b.*?\ba\s+person\b)(?!.*?\ba\s+person\b.*?\b(person|people|child|children|baby|babies)\b)(?<prefix>.*?)\ba\s+person(\s+that\s+is\b)?\b(?<suffix>.*)$
prefix
suffix
%@%@%@
blood
 that might contain blood
demonstration
 that might be a demonstration
 that might be a scene of destruction
fire
 that might include fire
flood
 that might be a flood
funeral
 that might be a funeral
hospital
 that might be a hospital
religious
 that might be a religious setting
crash
 that might be a vehicle crash
AXCaptionTemplateRules
plist
subsume
baby
ignored
Possible adult content
priority
q24@?0@"NSString"8@"NSString"16
B32@?0@"NSString"8Q16^B24
No_Description
aeiouAEIOU
speech
nonCountNounOrPlural
A photo containing %@ %@
A photo of %@
 and 
%@ %@
v32@?0@"NSString"8@"NSString"16^B24
v32@?0@"NSString"8Q16^B24
AnalyticsSendEventLazy
Caption Confidence Insufficient
Denylist Rule
Taboo Filter
NSFW Filter
MinimumConfidence
DenylistRule
ClassifierLabel
10.15
inputHeight
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
kernel vec4 _morphmin (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = min(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
kernel vec4 _morphmax (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = max(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
Identifier
QueueSize
SourceNodes
EvaluationNodes
VisionEngineConfigurationDidChange
AXMVisionEngine
AXMImgRegistration
diagnosticsEnabled
prioritySchedulingEnabled
prioritySchedulingAllowMultipleNodeExecution
thresholdPriority
v24@?0@"AXMVisionResult"8@"NSError"16
v32@?0@"AXMEvaluationNode"8Q16^B24
v24@?0@"AXMVisionPipelineContext"8@"AXMEvaluationNode"16
Evaluate %@
v16@?0@"AXMetric"8
Create Image
Node
%@-%ld
%@<%p>: ID:'%@' [PriorSched:%@ threshhold:%lu] maxQueueSize:%ld cacheSize:%ld metrics:%@
%@%@
%@Source Nodes:
%@Evaluation Nodes:
Engine queue is at capacity
VNRequestHandlerCleanupOption_AllPipelines
VNCleanupLevel_Complete
VNRequestHandlerCleanupOption_ImageBuffers
VNCleanupPurgeAll
VNImageRequestHandler
NutritionLabel
image.text.nutrition
image.text.calories
image.text.fat
image.text.carbohydrate
image.text.protein
image.text.sodium
image.text.potassium
image.text.calcium
image.text.fiber
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
deviceAttitude
kAXMHarmonicValue
kAXMHarmonicAmplitude
input
sourceProvidesResults
sourceparams
features
evaluatedFeatureTypes
analysisOptions
userContext
error
EffectiveTextDetectionLocales
Pipeline-%ld
AXM_VISION_ENGINE_METRICS
com.apple.accessibility.sceneobservation
AXMVisionPipelineContext<%p>: seqID:%lu source params: %@. error: %@
appliedImageOrientation
sequenceID
A creation node must return a valid image
%@-%ld-%ldx%ld.%@
Pipeline
Text Detector
@16@?0@"NSString"8
scene
@16@?0@"AXMVisionFeature"8
en-US
VNRecognizeTextRequest
image
iconClass
brailleEdges
SharedIconVision
v20@?0@"AXMTask"8B16
iouThreshold
confidenceThreshold
coordinates
AXElementVision
assetURL
creationDate
localIdentifier
imageData
allowNetworkAccess
photoLibraryURL
User has not yet made a choice to authorize access to photo data with regards to this application
User has explicitly denied this application access to photos data.
<%@ %p URL=%@ creationDate=%@ localIdentifier=%@ data=%@ UTI=%@ orientation=%u>
v36@?0@"NSData"8@"NSString"16I24@"NSDictionary"28
PHPhotoLibrary
PHAsset
PHImageManager
PHImageRequestOptions
cameraPixelFocalLength
cameraOpticalOrigin
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
minimumConfidence
maximumNumber
Rectangle Detector
VNDetectRectanglesRequest
VNImageOptionCameraIntrinsics
green
blue
saturation
brightness
%@<%p> [r:%u g:%u b:%u] [h:%u s:%u b:%u]
Black
Gray
Silver
White
Salmon
Rose
Brown
Coral
Orange
Chestnut
Gold
Olive
Ivory
Beige
Yellow
Lime Green
Light Green
Sea Foam Green
Forest Green
Green
Turquoise
Teal
Cyan
Aqua
Sky Blue
Royal Blue
Navy Blue
Indigo
Lavender
Purple
Fuchsia
Dark Purple
Light Pink
Violet
Pink
Maroon
Crimson
%@ name:%@
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu sources=
Capture Session
AXMAVCaptureSessionNode does not support remote triggering
AXMAVCaptureSessionNode-avkit-queue
B32@?0@8Q16^B24
v16@?0@"NSNotification"8
Began
Ended
Unknown
New Device Available
Old Device Unavailable
Category Change
Override
Wake From Sleep
No Suitable Route for Category
Route Congifuration Change
Ready
Unitialized
Initialize Failure
%@<%p>: state:'%@'
BitsPerComponent
CGBitmapInfo
BitsPerBlock
AXMFeatures
AXMImage
B32@?0@"AXMVisionFeature"8Q16^B24
detected.text.type.hint
detected.text.summary.hint
detected.text.hint
SELF != ''
description.face
description.prominent.object
description.person
B24@?0@8@"NSDictionary"16
Locale
ModifyForSensitiveContent
detected.icon.hint
detectedTextDescription
detectedTextType
detectedTextSummary
imageRegistrationState
equivalenceToken
effectiveTextDetectionLocales
metrics
en_US
AXMVisionResult<%p>: Image:%@ Results:%@ Feature Description: '%@'. Text Description: '%@'.
v32@?0@"AXMVisionFeature"8Q16^B24
cacheQueue
AXMVisionEngineCache<%p>: %ld items
AXMVisionEngineCache<%p>: %ld items
  Key:%@
  Result:%@
v32@?0@"<NSCopying>"8@"AXMVisionResult"16^B24
AVPlayerItem
AXMAVPlayerItemNode does not support remote triggering
AXMAVPlayerItemNode-avkit-queue
%@ playerItem:<%@>
model_info.json
ImageCaptionModel
VideoCaptionModel
Stable
Disgust
Neutral
Scream
Smile
Surprise
Suspicious
AXMFeatureFaceLandmarks
AXMFeatureFaceLandmarks3d
AXMFeatureFaceLandmarksConfidence
AXMFeatureFaceExpressions
AXMFeatureFacePose
AXMVisionFeatureCodingKeyFacePoseConfidence
AXMFeatureFaceName
AXMFeatureFaceNameConfidence 
AXMFeatureFaceAttributes
AXMFeatureFaceAttributesConfidence
AXMFeatureFaceRectangles
AXMFeatureFaceRectanglesConfidence
AXMFeatureFaceUUID
photo.description.expression.smile
photo.description.expression.scream
photo.description.expression.disgust
photo.description.expression.surprise
photo.description.expression.suspicious
image/Placeholder
leaf/leaf/predictions/probabilities
iconclassification
v24@?0@"MLModel"8@"NSError"16
AXMChildren
AXMType
AXMTypeContainer
AXMContent
AXMBounds
AXMRowType
NSFW Detector
VNVYvzEtX1JlUdu8xx5qhDI
VN81aedeb999c79d74e79af7f1c922cf97
VNSequenceRequestHandler
Object Detector
VNRecognizeObjectsRequest
 - [%@]
AXElement Detector
_ContentVersion_v2
CIConstantColorGenerator
CICrop
inputImage
inputRectangle
CIColorControls
{CGAffineTransform=dddddd}
CIAffineTransform
q24@?0@"VNRecognizedObjectObservation"8@"VNRecognizedObjectObservation"16
q24@?0@"AXElementDetection"8@"AXElementDetection"16
ScreenRecognitionIconDetector
esp error
B32@?0@"VNRecognizedTextObservation"8Q16^B24
inputTransform
outputImage
%@-image.png
%@ [W:%.2f H:%.2f] [L:%.2f T:%.2f R:%.2f B:%.2f]
image.value.one
image.value.half
image.value.third
image.value.fourth
image.value.fifth
image.value.sixth
image.value.seventh
image.value.eighth
image.value.nineth
image.value.tenth
image.value.halves
image.value.thirds
image.value.fourths
image.value.sixths
image.value.sevenths
image.value.eighths
image.value.nineths
image.value.tenths
[\d]+ ?g(\s|\)|$|,)
[\d]+ ?mg(\s|\)|$|,)
[\d]+ ?mcg(\s|\)|$|,)
[\d]+ ?ml(\s|\)|$|,)
kcal
[\d]+ ?kcal(\s|\)|$|,)
[\d]+ ?kg(\s|\)|$|,)
no source texts provided
envelope.address.formatter
%@, %@
en-CA
math.table.row.format
math.table.column.format
table.incomplete
nutrition.label.row.format
q24@?0@"VNRecognizedTextObservation"8@"VNRecognizedTextObservation"16
CIPhotoEffectNoir
CIColorInvert
CIColorThresholdOtsu
AXMCIMorphologyRectangleMinimum
inputWidth
AXMCIMorphologyRectangleMaximum
q24@?0@"VNContour"8@"VNContour"16
B32@?0@"VNContour"8Q16^B24
image.text.name
image.text.address
, %@
receipt.product.unitprice.total.formatter
receipt.product.qty.unitprice.total.formatter
(.)\1{%lu}
\d{%lu}
q24@?0@8@16
\d+%
[0-9]/[0-9]
VNDetectContoursRequest
Image Registration
VNTranslationalImageRegistrationRequest
VNImageTranslationAlignmentObservation
Camera Metadata
{CGSize=dd}
{CGPoint=dd}
{CGRect={CGPoint=dd}{CGSize=dd}}
bubbleUp
bubbleDown
pluck1
pluck2
scratch1
scratch2
success1
aiff
sounds
inputType
ciImage
use wrapperWithPixelBuffer:
PixelWidth
PixelHeight
CIImage
Pixel Buffer
%@ (%@)
Convert to CGImage
Icon Class Detector
iconclassification.mlmodelc
apple
back
bluetooth
bookmark
calendar
camera
cart
chat
checkmark
clipboard
clock
close
compass
compose
copy
currency
delete
down
download
expand
facebook
fastForward
flag
flight
folder
font
gift
globe
heart
help
home
info
keyboard
launch
layers
lightning
list
location
locationCrosshair
locked
mail
menu
microphone
minus
more
music
notification
pause
people
person
phone
play
refresh
repeat
rewind
rightArrow
rightCurved
search
send
settings
share
sliders
smile
speaker
star
stop
thumbsDown
thumbsUp
trophy
twitter
unknown
videoRecorder
iconTypes.plist
iconTypes
CILanczosScaleTransform
inputScale
inputAspectRatio
icon.type.
__AXMStringForVariablesSentinel
@"AXMVisionFeature"16@?0@"AXMMLElementGroup"8
AXMLElementProperties
clickable_text_keywords
[^[a-z]]
B32@?0@"AXMMLElementGroup"8Q16^B24
@16@?0@"AXMMLElementGroup"8
v32@?0@"NSNumber"8@"NSMutableArray"16^B24
q24@?0@"AXMMLElementGroup"8@"AXMMLElementGroup"16
q24@?0@"NSNumber"8@"NSNumber"16
NLPToken
IsInLexicon
NumericToken
DataDetector
CustomPattern
SemanticError
NLP:OtherWord
NLP:PersonalName
NLP:OrganizationName
NLP:PlaceName
NLP:Whitespace
NLP:Dash
NLP:Punctuation
NLP:SentenceTerminator
NLP:Unknown
DD:Date
DD:Address
DD:Link
DD:PhoneNumber
DD:TransitInfo
US_Currency
v40@?0{_NSRange=QQ}8Q24^B32
v40@?0@8{_NSRange=QQ}16^B32
SemanticTextPatterns
Patterns
Pattern
v40@?0@"NSString"8{_NSRange=QQ}16^B32
v32@?0@"NSTextCheckingResult"8Q16^B24
v32@?0@"NSString"8@"NSRegularExpression"16^B24
Failed to match current cursor position. remaining:[%@ %@]
v24@?0^{_LXEntry=}8*16
en_CA
Failed to advance cursor. No value for attribute: %@. remaining:[%@ %@]
Sceneprint Creator
@"VNSceneObservation"8@?0
VNCreateSceneprintRequest
Asset Metadata
PlaybackMixer
PlaybackChartData
PlaybackTrendline
ScrubbingMixer
ScrubbingDiscreteData
ScrubbingContinuousData
ScrubbingTrendline
LiveToneMixer
LiveContinuousData
v16@?0@"NSTimer"8
Error playing audio buffer
Error stopping audio playback
Error: IO audio unit is running but we aren't in a scrubbing or playback session -- investigate.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
AXMSetting
writeOutInputImages
writeOutOCRInputImages
writeOutScreenCaptures
useANODModelForAXElementVision
'data' was not of required type NSData
'unarchivedResult' was not of type 'expectedClass'
Braille Edge Detector
CIEdges
CIBloom
name
localizedTypeDesc
TIFFImageDescription
IPTCCaptionAbstract
EXIFUserComment
PNGImageDescription
isAssetLocallyAvailable
name:%@ created:%@ UTI:%@ typeDesc:%@ assetLocalIdentifier:%@ isAssetLocallyAvailable:%d photoLibraryURL:%@
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
noiseScore
failureScore
pleasantCompositionScore
Aesthetics: aesthetic=%.2f wellFramedSubject=%.2f wellChosenBackground=%.2f noise=%.2f failure=%.2f pleasantComposition=%.2f
AXMDisplayManager
DeviceClassNumber
AXMDisplayManager:<%p> Initialized %ld
Frontbaord Main:%@
CADisplay Main:%@
Static (gestalt) props: %@
screen-dimensions
main-screen-scale
scale
main-screen-orientation
Aixt/MEN2O2B7f+8m4TxUA
supportsDeepColor
Default
None
CoreAnimation
FrontBoardServices (dynamic)
AXMDisplay<%p>: Backing:%@ Name:%@ scale:%@ size:[%.2f %.2f] orientation:%@ (%s) refBounds:[%.2f %.2f %.2f %.2f] deepColor:%d
AXMDisplayManagerMainDisplayWasUpdatedNotification
AXMPhysicalDisplayOrientationUnknown
AXMPhysicalDisplayOrientationPortrait
AXMPhysicalDisplayOrientationPortraitUpsideDown
AXMPhysicalDisplayOrientationLandscapeLeft
AXMPhysicalDisplayOrientationLandscapeRight
chart.model.power
y = %@ * x^%@
__AXMDataSummaryStringForVariablesSentinel
chart.series.trend.increasing
chart.series.trend.decreasing
chart.series.trend.verystrong
chart.series.trend.strong
chart.series.trend.moderate
chart.series.trend.weak
chart.series.trend.none
chart.series.minvalue.format
chart.series.maxvalue.format
chart.series.meanvalue.format
chart.series.outlier.format
chart.series.outliers.none
<%@ %p x:[%.1f, %.1f] y:[%.1f, %.1f] model=%@ xbar=%.1f ybar=%.1f r=%.4f rSq=%.4f y=%.4fx+%.4f
outliers=%@>
self
filterThresholds
nmsThreshold
B16@?0@8
filterThresholds: %@
nmsThreshold: %@
MM-dd-HH-mm-ss
image_%dx%d_%ld_%@.jpg
axout-tmp
-axtmp
yyyy:MM:dd HH:mm:ss
MMMMddyyyyjjmm
MMMMddjjmm
jjmm
/System/Library/PrivateFrameworks/ScreenReaderCore.framework
SCRCPhotoEvaluator
image/png
filetype.image
image/bmp
image/jpeg
image/vnd.adobe.photoshop
filetype.psd
image/tiff
filetype.tiff
image/svg+xml
filetype.svg
image/gif
filetype.gif
text/css
filetype.css.file
text/csv
filetype.csv.file
text/html
filetype.html.file
text/calendar
filetype.calendar.event
text/plain
filetype.text.file
text/rtf
filetype.rtf.document
text/directory
filetype.contact.card
application/pdf
filetype.pdf
application/x-latex
filetype.latex
application/json
filetype.json
application/vnd.ms-excel
filetype.excel
application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
application/onenote
filetype.onenote
application/vnd.ms-powerpoint
filetype.powerpoint
application/vnd.openxmlformats-officedocument.presentationml.presentation
application/msword
filetype.word
application/vnd.openxmlformats-officedocument.wordprocessingml.document
application/postscript
filetype.postscript
application/rtf
application/xml
filetype.xml
application/rss+xml
filetype.rss
application/zip
filetype.zip
application/x-rar-compressed
filetype.rar
application/x-tar
filetype.tar
application/epub+zip
filetype.epub
audio/mp4
filetype.audio
audio/x-wav
audio/x-m4a
video/quicktime
filetype.video
video/mp4
video/mpeg
video/x-m4v
audio/
com.apple.coreaudio-format
video/
usdz
filetype.3D.model
numbers
filetype.number
pages
filetype.pages
filetype.keynote
rtfd
filetype.unknown
.dizzy
.thinking.heart
.sparkling
.arrow
.wings
.broken
.shattering
.exploding
.beating
.fist
.peace
.thumbs.up.back.of.hand
.thumbs.down
.ok.symbol
.pointing.left
.pointing.right
.crossing.fingers.back.of.hand
.crossing.fingers.palm.of.hand
.raised.hand
.hang.loose
.waving
.waving.royal
.face.eyes.open
.face.eyes.one.eye.closed
.face.eyes.hearts
.eyes.hearts
.eyes.one.eye.closed
.aviator.sunglasses
.cat.eye.sunglasses
.eyes.furled
.eyes.crying
.eyes.open
.eyes.wide.open
.eyes.closed
.eyes.black.hearts
.eyes.crosses
.eyes.bandages
.eyes.half.closed
.eyes.half.closed.one
.eyes.tearing.up
.mouth.smiling
.mouth.smiling.half.open
.mouth.smiling.wide
.mouth.tongue
.mouth.blowing.kiss
.mouth.smirking
.mouth.half.frowning
.mouth.frowning
.mouth.gasping
.mouth.screaming
.mouth.thermometer
.mouth.surgical.mask
.mouth.smiling.teeth
heart-blue-loop-
emoji.heart.blue
heart-red-loop-
emoji.heart.red
heart-purple-loop-
emoji.heart.purple
hand-loop-
emoji.hand
face-red-loop-
emoji.face.sad
emoji.face.sleeping
emoji.face.confused.and.dismayed
emoji.face
emoji.red.face
face-yellow-loop-
emoji.yellow.face
UIScreen
UIAccessibilityIsVoiceOverRunning
UIGraphicsBeginImageContextWithOptions
UIGraphicsGetCurrentContext
UIGraphicsEndImageContext
AXMCoreMotionNode_samplesPerSecond
AXMCoreMotionNode_lastSampleTime
Core Motion
 North 
 N. 
 South 
 S. 
 East 
 E. 
 West 
 W. 
 NE 
 North East 
 NE. 
 NW 
 North West 
 NW. 
 SE 
 South East 
 SE. 
 SW 
 South West 
 SW. 
North
South
East
West
North East
 NE.
North West
 NW.
South East
 SE.
South West
 SW.
Street
 AVE
Avenue
Road
Lane
 ST 
 Street 
 AVE 
 Avenue 
 RD 
 Road 
 LN 
 Lane 
 STE 
 Suite 
 APT 
 Apartment 
 UNT 
 Unit 
com.apple.accessibility.vot.DataSonifierAccess
audiograph.series.number
audiograph.datapoint
audiograph.datapoints.count
com.apple.AXMediaUtilitiesService
com.apple.AXMediaUtilitiesService-access
contextQueue
Create CIContext
Could not rotate buffer with orientation: %@
could not allocate pixel buffer: %@
Could not rotate buffer: %@
networkThreshold
defaultBoxesSidesNormalized
ratios
filterThresholds: %@
networkThreshold: %@
nmsThreshold: %@
defaultBoxesSidesNormalized: %@
ratios: %@
tiff
Could not allocate color space
Could not allocate bitmap memory
Could not allocate context
ERROR: Could not create image from URL %@
Orientation
could not create image from data
Failed to load raw buffer
ERROR: data is nil
Format not supported (input image must be 32 or 8 bits per pixels)
Ignoring lumaOnly flag when operating on RAW buffers
Failed to create the context
Failed to allocate the image buffer
Could not extract first image from bundle
Could not create image from data
Failed to create the CVPixelBuffer
Format not supported (input image must be 32 bits per pixels)
%s error %lld:%s in %s @ %s:%d
+[ImageTools loadCVPixelBuffer420YpCbCr8FromURL:error:]
/Library/Caches/com.apple.xbs/Sources/AccessibilityMediaUtilities_Sim/AXMediaUtilities/source/ImageTools.m
unexpected number of bytes per pixels
ERROR: Could not load 420YpCbCr8 buffer
+[ImageTools saveCVPixelBuffer420YpCbCr8:withName:inFolder:error:]
ERROR: Could not save 420YpCbCr8 buffer
Could not create data provider.
Could not create image.
Could not create image destination.
Could not finalize image.
+[ImageTools extractLumaFromBGRA8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toBuffer:withBytesPerRow:]
+[ImageTools create420YCbCr8BufferFromPlanar8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:]
+[ImageTools create420YCbCr8BufferFromRGB8Buffer:withWidth:andWithHeight:andWithBytesPerRow:andAlphaFirst:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:]
+[ImageTools createRGB8BufferFrom420Y8PlanarBuffer:withBytesPerRowY:andFrom420Cb8Buffer:withBytesPerRowCb:andFrom420Cr8Buffer:withBytesPerRowCr:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:]
+[ImageTools createRGB8BufferFrom420Y8BiPlanarBuffer:withBytesPerRowLuma:andFrom420CbCr8Buffer:withBytesPerRowChroma:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:]
chart.model.sinusoidal
y = %@ * sin(%@x + %@) + %@
%@: %@
Prominent Object Detector
v32@?0@"VNRectangleObservation"8Q16^B24
VNGenerateAttentionBasedSaliencyImageRequest
kAXMChartSeriesKey
kAXMChartXAxisKey
kAXMChartYAxisKey
kAXMChartAdditionalAxesKey
kAXMChartTitleKey
kAXMChartSummaryKey
kAXMChartContentDirectionKey
kAXMChartContentFrameKey
kAXMChartSeriesNameKey
kAXMChartSeriesContinuousKey
kAXMChartSeriesXDataKey
kAXMChartSeriesYDataKey
kAXMChartSeriesZNumericDataKey
kAXMChartSeriesZCategoricalDataKey
kAXMChartSeriesLabelDataKey
kAXMChartSeriesValueDescriptionsKey
kAXMChartSeriesMeanValueDescriptionKey
kAXMChartAxisTitleKey
kAXMChartAxisType
categorical
numeric
kAXMChartNumericAxisScaleTypeKey
kAXMChartNumericAxisLowerBoundKey
kAXMChartNumericAxisUpperBoundKey
kAXMChartNumericAxisGridlinePositionsKey
kAXMChartCategoryAxisCategoriesKey
@"NSString"16@?0d8
<%@ %p title=%@ bounds=[%@, %@], gridlines=%@>
<%@ %p title=%@ order=%@>
%@%@
label=%@
desc=%@)
@16@?0@"AXMDataPoint"8
@"NSNumber"16@?0@"AXMDataPointValue"8
<%@ %p name=%@ continuous=%@ points=%@>
<%@ %p
title=%@
summary=%@
Axes:
%@Series:
v16@?0@"AXMDataRegressionModel"8
d16@?0d8
Trying ANE backend: %@
ANE unavailable/did not compile, falling back to MPS backend
face
human_body
head
aeroplane
bicycle
bird
boat
bottle
chair
dining_table
horse
motorbike
potted_plant
sheep
sofa
train
tv_monitor
food
drink
logits_pos_%ld
logits_neg_%ld
logits_%ld
offsets_%ld
logits_roll_%ld
logits_yaw_%ld
boxes
timing
Invalid input
Intermediate buffer allocation failed
Barcode
v32@?0@"VNRequest"8Q16^B24
@"NSError"16@?0@"AXMetric"8
VN PerformRequests
Vision:
VNProcessingDevice
screenCapture
text
axElement
AXMFeatureTextRecognition
AXMFeatureRange
VNRecognizedText
AXMVisionFeatureFaceLandmarksIs3DLandmarks
AXMVisionFeatureFaceLandmarksResults
photo.landmarks.nose
photo.landmarks.face
photo.landmarks.lefteye
photo.landmarks.righteye
photo.landmarks.innerlips
photo.landmarks.leftpupil
photo.landmarks.nosecrest
photo.landmarks.mouth
photo.landmarks.medianline
photo.landmarks.rightpupil
photo.landmarks.lefteyebrow
photo.landmarks.righteyebrow
VNFaceLandmarks2D
recognitionLevel
normalizedMinimumTextHeightRatio
usesLanguageCorrection
textDetectionLocales
postProcessingOptions
AXMTextDetectionOptions<%p>
  Options: 
    Recognition Level: %@
Fast
Accurate
    Minimum Text Height Ratio: %.3f
    Use Language Correction: %ld
    Detection Languages: %@
    Apply Semantic Text Filtering: %ld
height
width
numberOfDiscretePinHeights
hasConsistentHorizontalPinSpacing
hasConsistentVerticalPinSpacing
verticalPinSpacing
horizontalPinSpacing
interCellHorizontalSpacing
interCellVerticalSpacing
verticalPinSpacing and horizontalPinSpacing are required if cell spacing is not uniform.
AXMBrailleCanvasDescription<%p>
    Size(%ld, %ld)
    numberOfDiscretePinHeights: %ld
        verticalPinSpacing: %.2f
        horizontalPinSpacing: %.2f
        interCellHorizontalSpacing: %.2f
        interCellVerticalSpacing: %.2f
canvasDescription
zoomLevel
origin
edgeStrength
invert
AXMBrailleEdgeDetectorOptions<%p>
    CanvasDescription: %@
    zoomLevel: %.2f
    origin: %@
    edgeStrength: %.2f
clientID
includeImageInResult
detectText
textDetectionOptions
detectScenes
detectObjects
detectNSFW
detectSignificantEvents
detectModelClassifications
detectCaptions
detectTraits
detectFaceRectangles
detectFaceNames
detectFaceAttributes
detectFaceExpressions
detectFaceLandmarks
detectFacePose
detectHorizon
detectRectangles
detectProminentObjects
detectAesthetics
detectIconClass
detectBrailleEdges
brailleEdgeOptions
detectAXElements
ignoredLayerContextIDs
includedLayerContextIDs
preserveInputImageSize
preferredOutputLocale
AXMVisionAnalysisOptions<%p>. Client: %ld
  Detectors:
    Traits: %ld
    Faces: %ld
    Text: %ld
    Scenes: %ld
    Objects: %ld
    NSFW: %ld
    Significant Events: %ld
    Model Classifications: %ld
    Captions: %ld
    Prominent Objects: %ld
    Aesthetics: %ld
    Face names: %ld
    Face rectangles : %ld
    Face attributes : %ld
    Icon Classifications: %ld
    Braille Edges: %ld
    AXElement Detection: %ld
  Preserve Input Image Size: %ld
  Preferred Output Locale: %@
OutputManager
AXMOutputManager<%p>: state:'%@'. Speech? %@. Sound? %@.
Speech
Sounds
Haptics
[%@] usesPrivateAudioSession=%ld hapticEngineUsesAutoShutdown=%ld hapticEngineAutoShutdownTimeout=%.2f hapticEngineUsesHapticsOnly=%ld
chart.model.linear
y = %@x + %@
labelProbability
label
SelectedCheckboxFromIcon
NSFW Explicit
Blood
Demonstration
Destruction
Fire Devastation
Flood Devastation
Funeral
Hospital
Religious Setting
Vehicle Crash
AXMFeatureType
AXMFeatureCanvasSize
AXMFeatureFrame
AXMFeatureNormalizedFrame
AXMFeatureValue
AXMFeatureRecognizedText
AXMFeatureBarcodeType
AXMOCRFeatureType
AXMFeatureColorInfo
AXMFeatureAssetMetadata
AXMFeatureBlur
AXMFeatureBrightness
AXMFeatureConfidence
AXMFeatureIsLowConfidence
AXMFeatureHorizonTransform
AXMFeatureHorizonAngle
AXMFeatureFaceDetectionResult
AXMFeatureFaceID
AXMDeviceMotion
AXMFeatureDeviceOrientation
AXMFeatureCameraType
AXMFeatureModelID
AXMFeatureAesthetics
AXMFeatureUserContext
AXMFeatureCodingKeyUIClass
AXMFeatureGates
AXMCaptionMayContainSensitiveContent
AXMVisionFeatureCodingKeyDetectorSceneClassIds
AXMVisionFeatureCodingKeySceneClassId
AVMetadataVideoPreviewHistogramObject
classificationLocalizedValue
classificationLabel
caption
translatedCaption
subfeatures
color info
asset metadata
Top left
Top right
Right
Center
Left
Bottom left
Bottom
Bottom right
Outside top left
Outside top
Outside top right
Outside right
Outside left
Outside bottom left
Outside bottom
Outside bottom right
centered
near.left.edge
near.top-left.edge
near.top.edge
near.top-right.edge
near.right.edge
near.bottom-right.edge
near.bottom.edge
near.bottom-left.edge
outside.left
outside.top-left
outside.top
outside.top-right
outside.right
outside.bottom-right
outside.bottom
outside.bottom-left
.implicit-subject
Document
Region
Line
Char
Diacrit
Table
Incomplete Table
Column
Cell
Nutrition Label
Envelope
Envelope Region
Receipt
Cell Header
Picture
Picture:Button
Icon
Icon:Button
Container
TextField
PageControl
Checkbox:NotSelected
Checkbox:Selected
Slider
TabBar
SegmentedControl
Switch:On
Switch:Off
Text
Text:Button
TabBar:Button
Dialog
Brightness
Blur
Color
Face
RealtimeFace
Person
SceneClassification
NSFW
SignificantEventClassification
ObjectClassification
ModelClassifier
Caption
MediaLegibility
AssetMetadata
Horizon
Rectangle
AXElement
Motion
CameraMetadata
ProminentObject
IconClass
Sequence
Character
Diacritic
AXMVisionFeature<%p> %@
uiClass:%@ 
value:%@ 
face id: %lu 
Name: %@ 
[faceLandmarks: %@ faceLandmarks3d: %@ faceExpressions: %@ likelyExpression: %@ likelyConfidence: %f] 
Face Attributes : %@
Face location: %@
value:'%@' type:%@ 
classificationLabel:'%@' localizedName:'%@' sceneClassID:'%@' detectorSceneClassIds:'%@' 
classificationLabel:'%@' 
ModelID: '%@' classificationLabel: '%@' 
caption: '%@' translated: '%@' 
value:'%.2f' 
value:'%@' 
asset info [%@] 
horizon transform. angle: %f 
deviceMotion: %@
front-facing
back-facing
camera: %@
location : %@
frame:%@ (normalized:%@) 
confidence:%.2f lowConfidence:%ld 
Alex
%d x %d
%.6f
Subclasses must override %@
q24@?0@"AXMPoint"8@"AXMPoint"16
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
com.apple.cvml.%@
CVML module = %@
overrideModelURL
overrideScaleMethod
genderStrategy
sceneDetector
Caption Detector
taxonomyOptions
Scene Detector
VNSceneClassificationRequest
chart.model.logarithmic
y = %@ * ln(x) + %@
AXMNodeID
AXNodeEnabled
NodeQueue
%@<%p>: ID:'%@' title:'%@' supported:%@ needsVisionKit:%@ enabled:%@ connected:%@
<%@ %p name=%@ circular=%d currentSample=%lu length=%lu>
Significant Events Detector
VN6Mb1ME89lyW3HpahkEygIG
VN3FNQUJVIs2puI1uPc9mxh7
VNSY8t4EoTztuqIL02g8uVA0
VN6XNMvaRunPpzWjGa9uUHD6
VN4QuphG8kE4qDaDycivBkX5
VN7gQUejje8mmnE9GSTsVBVV
VNa9xpOJNvRoaW9plFGZ9Eo0
VN2vIWnsZbk4Su55oeWfKDq1
VNmNJnu0xlW8CZXt6hJ7Rpb0
VN35FOB1QhtSfYGRIJvTgtTq
VN6ZsEIQ9ri2eF1vhsxw5COm
AXMedia Utilities System Report: <Unavailable on this platform>
AXMedia Utilities System Report (privileged): <Unavailable on this platform>
Image
Input file URL does not exist: %@
VoiceOver
object
trait
prominentObjects
SignificantEvent
captions
use init()
targetLocale
lowConfidence
diagram
envelope
receipt
Library/Accessibility
AXMediaUtilities
%.1f,%.1f,%.1f,%.1f
%.2f,%.2f,%.2f,%.2f
%.1f,%.1f
last.string.to.append.in.a.sentence
AXDateFormatter
{CGVector=dd}
<%@ %p frequency=%.2f timeOffsetMS=%.2f
Init fail -- use designated initializer
AXMediaUtilities.AXBoundingBox
init()
AXMediaUtilities.AXMElementDetectorResult
AXMediaUtilities.AXMClickabilityDetectorResult
_TtC16AXMediaUtilities13AXBoundingBox
@36@0:8@16f24@28
@16@0:8
v16@0:8
heat
angle
rect
classIndex
heatByClass
firstSeen
lastSeen
depth
centroid3d
knownFeaturePoints
physicalSize
description
T@"NSString",N,R
_TtC16AXMediaUtilities24AXMElementDetectorResult
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
q16@0:8
d16@0:8
labelName
_TtC16AXMediaUtilities29AXMClickabilityDetectorResult
Swift/Dictionary.swift
Swift/NativeDictionary.swift
Fatal error
Duplicate values for key: '
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
offset element 
Could not fetch uncompiled photo caption models: %@
Could not evaluate. VNDetectHorizonRequestSoft was nil
input arrays must be same length
Unhandled mapping for AXMVisionFeatureAgeCategory
Unhandled mapping for AXMVisionFeatureGenderCategory
Unhandled mapping for AXMVisionFeatureEyesCategory
Unhandled mapping for AXMVisionFeatureHairColorCategory
Unhandled mapping for AXMVisionFeatureGlassesCategory
Unhandled mapping for AXMVisionFeatureMakeupEyesCategory
Unhandled mapping for AXMVisionFeatureMakeupLipsCategory
Unhandled mapping for AXMVisionFeatureFacemaskCategory
Unhandled mapping for AXMVisionFeatureEthnicityCategory
Unhandled mapping for AXMVisionFeatureExpressionCategory
Unhandled mapping for AXMVisionFeatureFaceHairV2Category
Unhandled mapping for AXMVisionFeatureHairtypeCategory
Unhandled mapping for AXMVisionFeatureHeadgearCategory
Unhandled mapping for AXMVisionFeaturePoseCategory
Unhandled mapping for AXMVisionFeatureSkintoneCategory
Could not evaluate. VNDetectFaceExpressionsRequestSoft was nil
AXMFaceDetectorNode: no requests to evaluate
Could not evaluate. VNClassifyImageAestheticsRequestSoft was nil
AXMService being deallocated: %@
Connection to service interrupted. client: %@
Connection to service invalidated. client: %@
Failed to get service proxy: %@
Could not produce URL for soundID: %@
Could not make soundAction url does not exist: %@
Could not make sound. Action url does not exist: %@
Model Detector not available on this platform
Could not evaluate. VNImageScoreObservationSoft was nil
Could not evaluate. VNImageBrightnessObservationSoft was nil
Could not evaluate. VNImageBlurObservationSoft was nil
Could not evaluate. requestHandler was nil
Could not evaluate: %@
Need to define mlModelClasses for subclass of AXMMobileAssetEvaluationNode
Need to define an mobileAssetType for subclass of AXMMobileAssetEvaluationNode
Need to define modelResourceNames for subclass of AXMMobileAssetEvaluationNode
Need to define an minSupportedFormatVersion for subclass of AXMMobileAssetEvaluationNode
Retrieved assets: %@
Supported assets: %@ %@ %@
Found download node asset: %@
Adding model URLS: %@
Adding base URLS: %@ -> %@
No base URL, resetting model URLs
Can't load model: %@
Made model: %@ %@
Failed to create caption personalization regex: %@
Cannot modify caption for sensitive content. unexpected category: %@
Queueing remote evaluation of %@
Received remote evaluation for %@
Recived error for remote evaluation: %@
Source: %@
engine threshold priority: %ld
   node <%p> :'%@'. boosted priority:%ld
highest priority node(s): %@
Did not produce result features. Result was nil
Did not produce result features. Features was nil
Did not produce result features. Feature list was empty
Did produce result with %lu features:
  %@
Resulting speakable description. [features:'%@'] [text:'%@']
------------------------------------------------------
Will run detector: %@
Will not run detector '%@' due to previous error set in context: %@
With priority scheduling, there can be at most 1 evaluation node per cycle
Will begin image evaluation. %@
Invoking remote result handler for error: %@
Invoking remote result handler for result
Cannot add source node. %@
Cannot add a node that is already connected
Cannot add evaluation node. %@
Current task is not nil but we're resetting it
AXMVisionEngine: event occurred: %d
AXMVisionEngine: service indicated it went invalid. clearing client-side tasks
A context must be provided
A source must be provided
AXMVisionEngine: canceling queued task to replace with newer incoming task
AXMVisionEngine: ignoring task since queue is full (maximumQueueSize = %ld)
AXMCameraFrameContext motionCorrectedNormalizedFrame received invalid input
userContext class %@ not in AXMSecureCodingClasses()
pipelineMetric accessed before being created. This will certainly lead to unexpected behavior
Could not evaluate. VNRecognizeTextRequestSoft was nil
Will not perform text detection. No effective languages resolved
Text detection error occurred: %@
Unable to convert detected text into document. Input image unexpectedly nil
Unable to convert detected text into document: %@
Will detect text with options: %@
textDetectionLocales unexpectedly empty! falling back to en-US
Could not get supported text detection languages: %@
task should not be in the completed state
Task is marked complete: %@ -> %d
taskIsBeingProcessed should be YES
taskIsBeingProcessed should be NO
Task should not be complete if being marked as complete
AXMPhotoAssetData: Could not fetch Photo Library using the photo library URL : %@ error: %@
AXMPhotoAssetData: PhotoLibrary Authorization Failure - Image resource load will not be available : %@
AXMPhotoAssetData: Unable to load image data
Could not evaluate. VNDetectRectanglesRequestSoft was nil
handleRequest: expected nil completion block
speech started: '%@'
speech finished: '%@'
didFinish: expected completion block, but found nil.
speech canceled: '%@'
didCancel: expected completion block, but found nil.
speech paused: '%@'
speech resumed: '%@'
Cannot add output '%@' to session '%@'
AXMAVCaptureSessionNode already has a AVCaptureSession attached
Capture session '%@' already has output '%@'
Error updating audio session: %@
Session interruption (%@). Resume? %d
Route Changed. Reason: %@
Media services lost
Media services reset
Should silence secondary audio (%@)
Pixel create: %d
Could not creat pixel buffer: %d
Result found for key: %p. moving to newest position
set nil result. removing key: %p. %ld items remain
set new result. adding key: %p. %ld items remain
cache size too big. evicted key: %p. %ld items remain
purge cache of all keys
Will begin processing legibility events with player item: %@
Asked to auto-trigger events with item: '%@', but same targetPalyerItem was already set!
Asked to auto-trigger events with item: '%@', but targetPalyerItem already exists: '%@'. Unregistering current targetPalyerItem first. 
Will stop processing legibility events for player item: %@
legibility event: %@
Did time out waiting for image caption asset refresh. timeWaited:%.2f timeout:%.2f
Could not load AXImageCaptionModel at %@. error: %@
ImageCaptionAssetManager. didFinishRefreshingAssets: (%@). error: %@
ImageCaptionAssetManager. No compatible installed asset found
ImageCaptionAssetManager. asset controller setting model baseURL after asset refresh: %@
Failed to archive expressionsAndConfidence data: %@
Error decoding face expression dict: %@
Could not load iconclassification.mlmodelc in the bundle resource
Could not evaluate. VNClassifyNSFWImageRequestSoft was nil
AXMGeometryUtilities motionCorrectedNormalizedFrame received invalid input
Could not look up supported identifiers for VNRecognizeObjectsRequest
Could not evaluate. VNRecognizeObjectsRequestSoft was nil
Object Detector not supported on this platform
AXMLElementDetectorNode
AXMLElementDetectorNode-ScreenEquivalence
Same equivalence token - no work to do
Beginning element detection:
ERROR: zero image dimension
Effective text detect languages: %@
Performing OCR: %d, %@
Time to OCR: %f
OCR error: %@
OCR Results: %@
Icon detected: %@ for bounds %@ in image: %@ -> %@
OCR: %@
Metric types are not compatible '%ld' and '%ld'
metric does not support float values: '%ld'
metric does not support frame values: '%ld'
Will assemble lines...
  Next sequence: %@
   Compare w/ line %@
   threshold (%.0f%% of lineItem.height): %.2f
   sequence and line differ. height:%ld top:%ld
  Adding sqeuence to line
  Creating new line with sequence
Will assemble regions...
  Next line: %@
   Compare w/ region %@
   threshold (%.0f%% of regionItem.firstLine.height): %.2f
   line and region differ. height:%ld left:%ld
  Adding line to region
  Creating new region with line
  Next cell: %@
  Adding cell to row
  Adding cell to headeer
  Adding cell to column
Will assemble table...
  Next row: %@
  Adding row to table
  Creating new table with header
  Next column: %@
  Adding column to table
Will assemble label...
  Adding row to label
  Creating new label with header
Will assemble receipt...
  Adding row to receipt
  Creating new receipt
Could not evaluate. VNTranslationalImageRegistrationRequestSoft was nil
Could not evaluate. VNImageTranslationAlignmentObservationSoft was nil
Equivalence tokens %@ %@
Equivalence token is the same
Feature results: %@
Time to Coagulate: %f
Sorted results
Sorted results: %@
No sorted features
Rect: %@, orientation: %@, generation: %@
ML Gen: %d Receieved remote handler reply %@/%@
Handling results for ML detection for gen: %d
ML Elements same screen capture - ignoring results
Could not create CGDataProviderRef for URL: %@
Could not find ml model classes, returning default: %@
Icon Class detector had no base URL
Error icon vision prediction: %@
Determined label class for icon: %@ (%@)
Error compiling pattern '%@' : %@
Error creating data detector: %@
input text: %@
will enumerate tags for scheme: %@. options: all
  %@ -> %@
  WARNING: Unhandled NLToken: %@ -> %@
  WARNING: Unhandled Data Detector: %@ -> %@
remaining:[%ld %ld] word:%ld lexicon:%ld whitespace:%ld
semanticallyComplete:%ld speechText: '%@'
lex #%ld: '%@' flags:%lu prob:%.2f partialProb:%.2f usageCount:%u
Creating new lexicon for locale (an expensive operation): %@ (language: %@) (id: %@)
Unable to create lexicon: %@
No lexicon found for locale: %@
Could not evaluate. VNCreateSceneprintRequestSoft was nil
Chart descriptor has no series, can't render sonification
Error initalizing audio unit
Error initializing audio component
Error setting audio format
Error setting output callback
error starting audio output: %@
Did get KVO update for key: '%@'. change: %@
%@ %@ -- %@ %@
AXMDisplayManager initialized: %@
Unable to look up screenInfo
Unable to look up screen scale
Display settings after update from CADisplay.mainDisplay: %@
Unexpected physical screen orientation
Display settings after update from FB configuration: %@
connected new display. Updating AXMDisplay properties
display config changed. Updating AXMDisplay properties
disconnected new display
unknown interface orienation
Orientation unexpected: AXMPhysicalDisplayOrientationPortraitUpsideDown. If you see this assert, please file a bug with PEP Accessibility and your device type. 
unhandled display orientation. AXMPhysicalDisplayOrientationUnknown / default
Unknown interface orientation. assuming portrait
AX: Export Session status: %ld %@
AX: EXPORT: 1 Error: %@
AX: EXPORT: 2 Error: %@
AX: EXPORT: 3 Error: %@
Error retrieving caption: %@
Error setting caption: %@
unknown file type: UTI: %@, extension: %@
Could not evaluate. VNGenerateAttentionBasedSaliencyImageRequestSoft was nil
Could not evaluate. VNProcessingDeviceSoft was nil
Error decoding face landmark dict: %@
Failed to archive face landmark results: %@
Initializing output manager with config: %@
Could not de-activate audio session: %@
Could not activate audio session: %@
Ignoring dispatch request. Output manager not ready
Source node not connected to any engine
Error: unhandled AVMetadataObject %@
Error decoding subfeatures array: %@
Error decoding recognizedTextFeatures array: %@
Failed to archive subfeature data: %@
Failed to archive text recognition data: %@
Error: %@
Failed to find bounding box for text: %@ and range: %@
Caption Detection not available
Could not evaluate. VNSceneClassificationRequestSoft was nil
Scene Detector not supported on this platform
Error starting audio engine: %@
Unexpected state change. from %@. to %@
Could not handle audio request: %@. Error:%@
Could not begin active sound playback: %@
One-shot sound player did finish playing sound
Could not start engine: %@
Subclass should override
Could not evaluate. VNClassifySignificantEventRequestSoft was nil
Failed to create AXMediaUtilities working directory at path: %@. error: %@
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Photos.framework/Photos
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/UIKit.framework/UIKit
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:o:path:/System/Library/Frameworks/Vision.framework/Vision
SaySfG
ySfG
ySfGG
ySfG
$ss12IdentifiableP
$ss12CaseIterableP
$sSY
So8NSObjectC
SfSg
ySfGSg
ySfGGSg
ySfGSg
ySfG
ySfG
ySiG
SnySiG
ySfGG
ySfGG
yyXlG
ySfG
ySnySiGG
ySiG
ySo8NSNumberCG
AllCases
RawValue
heat
angle
rect
classIndex
heatByClass
firstSeen
lastSeen
depth
centroid3d
knownFeaturePoints
physicalSize
checkboxNotSelected
checkboxSelected
container
dialog
icon
pageControl
picture
segmentedControl
slider
tabBar
text
textfield
toggleNotSelected
toggleSelected
containerClickable
containerNotClickable
iconClickable
iconNotClickable
pictureClickable
pictureNotClickable
textClickable
textNotClickable
label
labelName
confidence
origin
size
width
height
AXMScreenGrabber
AXMAssetManager
AXMHorizonDetectorNode
AXMVisionFeatureColorInfo
NSSecureCoding
NSCoding
AXMVisionFeatureFaceAttributes
AXMSinglePitchTone
AXMFaceDetectorNode
AXMImageAestheticsNode
AXShotflowDetector
AXMServiceClientInterface
NSObject
AXMService
AXMServiceInterface
AXMOutputRequest
AXMOutputRequestHandle
AXMDataRegressionModelExponential
AXMModelDetectorNode
AXMScreenCaptureNode
AXMTraitDetectorNode
AXMMobileAssetEvaluationNode
AXMDescriptionBuilder
AXMCIMorphologyRectangle
AXMCIMorphologyRectangleMaximum
AXMCIMorphologyRectangleMinimum
AXMVisionEngine
AXMVisionEngineNodeConnectionDelegate
AXMTaskDispatcherDelegate
AXMServiceDelegate
NSCopying
AXMDescribing
_AXMVisionEngineAnalysisTask
AXMVisionFeatureComparator
AXMTextSpecialCase
AXMCameraFrameContext
AXMSynthPatch
AXMFunctionTone
AXMVisionPipelineContext
AXMTextDetectorNode
AXMIconVisionEngine
AXMTaskDispatcher
AXMTask
AXElementVision__generated__Input
MLFeatureProvider
AXElementVision__generated__Output
AXElementVision__generated__
AXMPhotoAssetData
AXMADSREnvelope
AXMRectangleDetectorNode
AXMVisionColor
AXMVisionColorMarker
AXMSpeechComponent
AVSpeechSynthesizerDelegate
AXMAudioDataSourceMixer
AXMAVCaptureSessionNode
AVCaptureVideoDataOutputSampleBufferDelegate
AXMAVCaptureSessionNodeFrameDelegate
AXMAudioSession
AXMOutputComponent
AXShotflowHelpers
AXMVisionResult
AXMVisionEngineLookupConvenience
AXMVisionEngineCache
_AXMPlayerItemLegibleOutput
AXMAVPlayerItemNode
AVPlayerItemLegibleOutputPushDelegate
AVPlayerItemOutputPushDelegate
AXMImageCaptionModelAssetManager
AXAssetControllerObserver
AXMVisionFeatureFaceDetectionResult
iconclassificationInput
iconclassificationOutput
iconclassification
AXMTaxonomyNode
AXMNSFWDetectorNode
AXMGeometryUtilities
AXMAVUtilities
AXMSequenceRequestManager
AXMObjectDetectorNode
Prediction
AXMAXElementDetectorNode
AXMLayoutItem
AXMLayoutSequence
AXMLayoutLine
AXMLayoutRegion
AXMLayoutCell
AXMLayoutRow
AXMLayoutHeader
AXMLayoutColumn
AXMLayoutTable
AXMLayoutNutritionLabel
AXMLayoutReceipt
AXMTextLayoutManager
AXMImageRegistrationNode
AXMCameraMetadataNode
AXMCaptureVideoDataOutput
AXMLocSupport
AXMExtras
AXMCompressor
AXMScreenRecognitionVisionProcessingResult
AXMVisionScreenRecognitionOptions
AXMScreenRecognitionCenter
AXMOutputAction
AXMSpeechOutputAction
AXMSoundOutputAction
AXMOneShotSoundOutputAction
AXMActiveSoundOutputAction
AXMOutputActionHandle
AXMActiveSoundOutputActionHandle
AXMPipelineContextInput
AXMIconClassDetectorNode
AXMMLElementGroup
AXMLTabButtonGroup
AXMLElementCoagulation
AXMindNetHelpers
AXMSemanticText
AXMSemanticTextFactory
_AXMSemanticTextCursor
AXMPixelBufferWrapper
AXMSceneprintBasedNode
AXMAssetMetadataNode
AXMDataSonifier
_AXMSettingObserver
AXMSettings
AXANFDDetectedObject
AXMBrailleEdgesDetectorNode
AXMVisionFeatureAssetMetadata
AXMVisionFeatureAestheticsResult
AXMDisplayManager
FBSDisplayObserving
AXMDisplay
AXMDataRegressionModelPower
AXMDataSummary
AXMindNetConfiguration
AXMCoreMotionNode
AXMAddressFormatter
AXMDataSonificationManager
AXMDataSonifierPlaybackObserver
AXMDataSummaryCategoryNameProvider
AXShotflowConfiguration
AXMLiveContinuousTone
ImageTools
AXMDataRegressionModelSine
AXElementDetection
AXVNEspressoDetectedObject
AXMProminentObjectsDetectorNode
AXMNumericDataAxisDescriptor
AXMChartDictionaryRepresentable
AXMDataAxisDescriptor
AXMCategoricalDataAxisDescriptor
AXMDataPointValue
AXMDataPoint
AXMDataSeriesDescriptor
AXMChartDescriptor
AXMScale
AXMNumericScale
AXMCategoricalScale
AXMDataAnnotation
AXShotflowNetwork
AXMBarcodeNode
AXMEvaluationNode
AXMAXElementVisionEngine
AXMAudioEffect
AXMVisionFeatureRecognizedText
AXMVisionFeatureFaceLandmarks
AXMTextDetectionOptions
AXMBrailleCanvasDescription
AXMBrailleEdgeDetectorOptions
AXMVisionAnalysisOptions
AXMOutputManager
_AXMOutputRequestTask
AXMOutputManagerConfiguration
AXMTone
AXMDataRegressionModelLinear
AXMSourceNode
SelectedCheckboxFromIcon__generated__Input
SelectedCheckboxFromIcon__generated__Output
SelectedCheckboxFromIcon__generated__
AXMVisionFeature
AXMJSONSerializable
AXUnitTesting
AXMPoint
AXMDataRegressionModel
AX_CVML_Error
AXMCaptionDetectorNode
AXMSceneDetectorNode
AXMActiveSound
AXMSoundComponent
AXMActiveSoundOutputActionHandleImpl
AXMActiveSoundOutputActionHandleProvider
AXMDataRegressionModelLogarithmic
AXMVisionEngineNode
AXMAudioDataSource
AXMSignificantEventDetectorNode
AXMDeviceInfo
AXMImageNode
AXMVoiceOverVisionEngine
AXMTranslatedText
AXMGeomerty
KeyPitch
AXMVariablePitchTone
year
URLByAppendingPathComponent:
URLForResource:withExtension:
URLForResource:withExtension:subdirectory:
URLWithString:
UTF8String
JSONObjectWithData:options:error:
CGImage
UUID
UUIDString
VN1uMyFtnYEWjbrdx3yAuDndKkPeyzNJhB
VN2riiZbQrloRhCzYW56f0rk4N3ROe151S
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
VN4UfLbvVUqMvYV8bbGFQcxg5yRLm8ekI1
VN7CbCeAogPS2iHE6VQwu6H96xanljtMqk
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
VN7fiLHgGnvqPqG63cfDUCK4Xm8obUuWoP
VNpLorzxnyAlLcPFNcKhgoNCmy9b5BRWyk
absoluteString
addAttribute:value:range:
addEntriesFromDictionary:
addObject:
addObjectsFromArray:
addObserver:
addObserver:forKeyPath:options:context:
addObserverForName:object:queue:usingBlock:
addOutput:
addPointer:
ageCategory
alignmentTransform
allKeys
allObjects
allocWithZone:
alphanumericCharacterSet
angle
anyObject
appendBytes:length:
appendFormat:
appendString:
applyWithExtent:roiCallback:arguments:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObjectsFromArray:
arrayWithArray:
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
assetControllerWithPolicy:
assetType
assetWithURL:
attachNode:
attribute:atIndex:longestEffectiveRange:inRange:
attributedSpeechString
attributesAtIndex:effectiveRange:
authorizationStatus
autoupdatingCurrentLocale
auxiliarySession
ax_filteredArrayUsingBlock:
ax_flatMappedArrayUsingBlock:
ax_mappedArrayUsingBlock:
baseLanguageFromLanguage:
blurMeasure
blurResult
blurScore
boolForKey:
boolValue
bottomLeft
bottomRight
boundingBoxForRange:error:
bundleForClass:
bundleIdentifier
bundleWithIdentifier:
bundleWithPath:
bytes
canAddOutput:
characterAtIndex:
characterSetWithCharactersInString:
colorSpace
colorWithRed:green:blue:alpha:colorSpace:
commonMetadata
compare:
components:fromDate:
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
configurationForIdentity:
connect:to:fromBus:toBus:format:
connectedIdentities
containsObject:
containsString:
containsValueForKey:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextWithOptions:
contourAtIndex:error:
contourCount
countByEnumeratingWithState:objects:count:
createCGImage:fromRect:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
currentCalendar
currentLocale
currentMode
data
dataDetectorWithTypes:error:
dataWithBytes:length:
dataWithContentsOfFile:
dataWithContentsOfURL:
dataWithContentsOfURL:options:error:
dataWithLength:
date
dateFormatFromTemplate:options:locale:
dateFromString:
decodeBoolForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeIntegerForKey:
decodeObjectForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodeTopLevelObjectOfClasses:forKey:error:
defaultANEDevice
defaultCenter
detachNode:
device
dictionary
dictionaryValue
dictionaryWithContentsOfFile:
dictionaryWithContentsOfURL:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
doubleValue
emptyImage
encodeBool:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInt32:forKey:
encodeInteger:forKey:
encodeObject:forKey:
endMeasurement
enumerateAttribute:inRange:options:usingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateMatchesInString:options:range:usingBlock:
enumerateObjectsUsingBlock:
enumerateTagsInRange:unit:scheme:options:usingBlock:
enumerateTokensInRange:usingBlock:
errorWithDomain:code:userInfo:
evaluateImage:forCriteria:inRect:
exceptionWithName:reason:userInfo:
exportAsynchronouslyWithCompletionHandler:
exportSessionWithAsset:presetName:
exposureScore
extent
eyesCategory
faceAttributes
faceID
facemaskCategory
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithDictionary:error:
featureValueWithDouble:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
featureValueWithString:
featuresAtIndex:
fetchAssetsWithLocalIdentifiers:options:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileURLWithPath:
filterWithName:
filterWithName:withInputParameters:
filteredArrayUsingPredicate:
firstMatchInString:options:range:
firstObject
formUnionWithCharacterSet:
formatDescription
generateReport
getBytes:length:
getBytes:range:
getLocalFileUrl
getValue:
glassesCategory
grams
hairColorCategory
hasPrefix:
hasSuffix:
humanReadableResult
imageBufferValue
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
imageByApplyingOrientation:
imageByApplyingTransform:
imageByApplyingTransform:highQualityDownsample:
imageByClampingToExtent
imageByCompositingOverImage:
imageByCroppingToRect:
imageWithCGImage:
imageWithCVPixelBuffer:
imageWithCVPixelBuffer:options:
imageWithContentsOfURL:
imageWithData:
indexOfObject:
indexesOfObjectsPassingTest:
initForReading:error:
initForReadingFromData:error:
initStandardFormatWithSampleRate:channels:
initWithCIImage:options:
initWithCVPixelBuffer:orientation:options:
initWithData:
initWithFeatureProviderArray:
initWithFormat:arguments:
initWithLocaleIdentifier:
initWithModelProperties:
initWithName:measurementsEnabled:orEnabledByEnvironmentVariables:
initWithOptions:
initWithPCMFormat:frameCapacity:
initWithPattern:options:error:
initWithPhotoLibraryURL:
initWithServiceName:
initWithString:
initWithString:attributes:
initWithSuiteName:
initWithTagSchemes:
initWithTargetedCIImage:options:
initWithTargetedCVPixelBuffer:orientation:options:
initWithTargetedImageURL:options:
initWithType:
initWithTypes:error:
initWithURL:options:
initWithUnit:
innerLips
input
inputPorts
insertObject:atIndex:
intValue
interfaceOrientationForCaptureSessionNode:
interfaceWithProtocol:
invalidate
invertedSet
isDeviceMotionAvailable
isEqualToData:
isEqualToString:
isMainDisplay
isMainThread
isRunning
kernelWithString:
kilocalories
kilograms
knownSceneClassifications
labels
languageCode
lastObject
lastPathComponent
leftEye
leftEyebrow
leftPupil
librarySpecificFetchOptions
load
localURL
localeIdentifier
localeWithLocaleIdentifier:
localizedStringByJoiningStrings:
localizedStringForKey:value:table:
localizedStringFromNumber:numberStyle:
localizedStringWithFormat:
logAsset
longValue
lowercaseString
luminanceResult
mainBundle
mainDisplay
mainFileURL
mainMixerNode
mainScreen
makeupEyesCategory
makeupLipsCategory
matchesInString:options:range:
measure:execute:
measure:tryExecute:
measurementsEnabled
medianLine
metadata
metadataItem
metadataItemsFromArray:withKey:keySpace:
micrograms
milligrams
milliliters
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
month
moveItemAtURL:toURL:error:
multiArrayValue
multiplyByInverseOfAttitude:
mutableBytes
mutableCopy
narrowedBoundingBox
newsestCompatibleImageCaptionModelAssetFromAssets:withStage:language:isInstalled:isDownloadable:
nextAvailableInputBus
normalizedPath
normalizedPoints
nose
noseCrest
null
numberFromString:
numberOfMatchesInString:options:range:
numberWithBool:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLong:
numberWithLongLong:
numberWithUnsignedChar:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectsAtIndexes:
openAndWaitWithUpgrade:error:
orderedSet
outerLips
outputs
path
pathExtension
pathForResource:ofType:
performRequests:error:
performRequests:onCIImage:error:
performRequests:onCVPixelBuffer:orientation:error:
physicalMemory
pixelSize
pointCount
policy
position
postNotificationName:object:
predicateWithBlock:
predicateWithFormat:
predictionsFromBatch:options:error:
preferredLanguages
preferredScale
processInfo
processingFormat
properties
punctuationCharacterSet
purge:
quaternion
queryMetaData:
raise:format:
range
rangeAtIndex:
rangeOfCharacterFromSet:
rangeOfComposedCharacterSequenceAtIndex:
rangeOfString:
rangeOfString:options:
rangeValue
rangeWithName:
readIntoBuffer:error:
recordLastAssetAccess:
rectValue
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
registerDefaults:
regularExpressionWithPattern:options:error:
remoteObjectProxyWithErrorHandler:
removeAllObjects
removeCharactersInString:
removeObject:
removeItemAtURL:error:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsInArray:
removeObserver:
removeOutput:
removePointerAtIndex:
render:toBitmap:rowBytes:bounds:format:colorSpace:
render:toCVPixelBuffer:
replaceBytesInRange:withBytes:
requestForcedCleanupWithOptions:completion:
requestImageDataAndOrientationForAsset:options:resultHandler:
resourceValuesForKeys:error:
resultType
resume
returnTypes:
reverseObjectEnumerator
rightEye
rightEyebrow
rightPupil
salientObjects
scheduleBuffer:atTime:options:completionHandler:
scheduleFile:atTime:completionHandler:
scheduledTimerWithTimeInterval:repeats:block:
setActive:error:
setAutomaticallyConfiguresOutputBufferDimensions:
setBool:forKey:
setByAddingObjectsFromSet:
setCanReduceOutputChannels:
setCategory:withOptions:error:
setClasses:forSelector:argumentIndex:ofReply:
setDateFormat:
setDelegate:queue:
setDeliversPreviewSizedOutputBuffers:
setDeliveryMode:
setDoNotBlockBeforeFirstUnlock:
setExportedInterface:
setExportedObject:
setIncludeGuestAssets:
setInterruptionHandler:
setInvalidationHandler:
setKey:
setKeySpace:
setMaximumObservations:
setMaximumSignificantDigits:
setMetadata:
setMinimumTextHeight:
setModelFileBackingStore:
setNetworkAccessAllowed:
setNumberStyle:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setOutputFileType:
setOutputURL:
setProcessingDevice:
setRecognitionLanguages:
setRemoteObjectInterface:
setResizeMode:
setSampleBufferDelegate:queue:
setString:
setSynchronous:
setUnitStyle:
setUsesSignificantDigits:
setValue:
setValue:forKey:
setWithArray:
setWithObjects:
setWithSet:
sortDescriptorWithKey:ascending:
sortUsingComparator:
sortedArrayUsingComparator:
sortedArrayUsingDescriptors:
speakUtterance:
speechUtteranceWithAttributedString:
startAndReturnError:
startCatalogDownload:then:
startDownload:
startMeasure:
state
status
stopSpeakingAtBoundary:
store
string
stringByAppendingFormat:
stringByAppendingPathComponent:
stringByAppendingPathExtension:
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingCharactersInRange:withString:
stringByReplacingMatchesInString:options:range:withTemplate:
stringByReplacingOccurrencesOfString:withString:
stringByTrimmingCharactersInSet:
stringFromDate:
stringFromNumber:
stringFromUnit:
stringValue
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
subarrayWithRange:
substringFromIndex:
supportedFileTypes
supportedIdentifiersAndReturnError:
supportedRecognitionLanguagesForTextRecognitionLevel:revision:error:
symbolCharacterSet
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
topCandidates:
transform
translateXBy:yBy:
type
unarchivedObjectOfClass:fromData:error:
unsignedCharValue
unsignedIntegerValue
userInfo
value:withObjCType:
valueForKey:
valueWithBytes:objCType:
valueWithRange:
valueWithRect:
vectorWithX:Y:
vectorWithX:Y:Z:W:
weakObjectsPointerArray
whitespaceAndNewlineCharacterSet
whitespaceCharacterSet
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
writeToFile:atomically:
URLByDeletingPathExtension
grabScreenWithRect:orientation:options:metrics:error:
recordScreenForDuration:completion:
defaultManager
_photoCaptionAssetsDirectory
_uncompiledModelsDirectoryForType:
_compiledModelsDirectoryForType:
_modelsDirectoryForType:compiled:
compiledModelAssetURLsOfType:sources:
uncompiledModelAssetURLsOfType:sources:
_modelAssetURLsOfType:sources:compiled:
_modelAssetNamesOfType:sources:compiled:
compiledModelAssetNamesOfType:sources:
uncompiledModelAssetNamesOfType:sources:
compiledModelAssetURLForModelNamed:ofType:sources:
uncompiledModelAssetURLForModelNamed:ofType:sources:
_modelAssetURLForModelNamed:ofType:sources:compiled:
modelWithName:ofType:sources:compileIfNeeded:persistCompiledModel:error:
nodeInitialize
initWithCoder:
encodeWithCoder:
validateVisionKitSoftLinkSymbols
evaluate:metrics:
supportsSecureCoding
isSupported
title
requiresVisionFramework
_detectHorizonRequest
_setDetectHorizonRequest:
.cxx_destruct
__detectHorizonRequest
T@"VNDetectHorizonRequest",&,N,S_setDetectHorizonRequest:,V__detectHorizonRequest
init
TB,R
setMainColors:weights:
enumerateMainColors:
remainingColorWeight
setRemainingColorWeight:
mainColors
setMainColors:
mainColorWeights
setMainColorWeights:
_remainingColorWeight
_mainColors
_mainColorWeights
T@"NSArray",&,N,V_mainColors
T@"NSArray",&,N,V_mainColorWeights
Td,N,V_remainingColorWeight
defaultExcludeOptions
unitTestingFaceAttributesForAge:gender:eyes:smiling:facialHair:hairColor:baldness:glasses:eyeMakeup:lipMakeup:faceMask:ethnicity:expression:facialHairV2:hairType:headGear:pose:skinTone:excludeOptions:
unitTestingFaceAttributes
initWithVisionFaceAttributes:
initWithAVMetadataFaceObject:
_AXMAgeCategoryForVisionCategoryIdentifier:
_AXMGenderCategoryForVisionCategoryIdentifier:
_AXMEyesCategoryForVisionCategoryIdentifier:
_AXMHairColorCategoryForVisionCategoryIdentifier:
_AXMGlassesCategoryForVisionCategoryIdentifier:
_AXMMakeupEyesCategoryForVisionCategoryIdentifier:
_AXMMakeupLipsCategoryForVisionCategoryIdentifier:
_AXMFacemaskCategoryForVisionCategoryIdentifier:
_AXMEthnicityCategoryForVisionCategoryIdentifier:
_AXMExpressionCategoryForVisionCategoryIdentifier:
_AXMFaceHairV2CategoryForVisionCategoryIdentifier:
_AXMHairtypeCategoryForVisionCategoryIdentifier:
_AXMHeadgearCategoryForVisionCategoryIdentifier:
_AXMPoseCategoryForVisionCategoryIdentifier:
_AXMSkintoneCategoryForVisionCategoryIdentifier:
_accessibilityIdentifierForPoseCategory
_accessibilityIdentifierForSkintoneCategory
_accessibilityIdentifierForEthnicityCategory
_accessibilityIdentifierForGenderCategory
_accessibilityIdentifierForAgeCategory
_accessibilityIdentifierForHairColorCategory
_accessibilityIdentifierForHairTypeCategory
_accessibilityIdentifierForFaceHairV2Category
_accessibilityIdentifierForGlassesCategory
_accessibilityIdentifierForFacemaskCategory
_accessibilityIdentifierForHeadgearCategory
_accessibilityIdentifierForMakeupEyesCategory
_accessibilityIdentifierForMakeupLipsCategory
_accessibilityIdentifierForExpressionCategory
_accessibilityIdentifierForEyesCategory
_accessibilityLabelFormatterForPoseCategory
_accessibilityLabelFormatterForAgeCategory
_accessibilityLabelFormatterForHairColorCategory
_accessibilityLabelFormatterForHairTypeCategory
_accessibilityLabelFormatterForFaceHairV2Category
_accessibilityLabelFormatterForGlassesCategory
_accessibilityLabelFormatterForFaceMaskCategory
_accessibilityLabelFormatterForExpressionCategory
_accessibilityLabelFormatterBeginning
_accessibilityLabelForDemographics
_accessibilityLabelForHairDetails
_accessibilityLabelForFacialHairDetails
_accessibilityLabelForAccessoryDetails
_accessibilityLabelForExpressionDetails
accessibilityLabelForAttributes
accessibilityLabelAndConfidenceMappingForAttributes
axAgeCategory
axAgeCategoryConfidence
setAxAgeCategoryConfidence:
axGenderCategory
axGenderCategoryConfidence
setAxGenderCategoryConfidence:
axEyesCategory
axEyesCategoryConfidence
setAxEyesCategoryConfidence:
axSmilingCategory
axFaceHairCategory
axHairColorCategory
axHairColorCategoryConfidence
setAxHairColorCategoryConfidence:
axBaldCategory
axGlassesCategory
axGlassesCategoryConfidence
setAxGlassesCategoryConfidence:
axMakeupEyesCategory
axMakeupEyesCategoryConfidence
setAxMakeupEyesCategoryConfidence:
axMakeupLipsCategory
axMakeupLipsCategoryConfidence
setAxMakeupLipsCategoryConfidence:
axFacemaskCategory
axFacemaskCategoryConfidence
setAxFacemaskCategoryConfidence:
axEthnicityCategory
axEthnicityCategoryConfidence
setAxEthnicityCategoryConfidence:
axExpressionCategory
axExpressionCategoryConfidence
setAxExpressionCategoryConfidence:
axFaceHairV2Category
axFaceHairV2CategoryConfidence
setAxFaceHairV2CategoryConfidence:
axHairTypeCategory
axHairTypeCategoryConfidence
setAxHairTypeCategoryConfidence:
axHeadgearCategory
axHeadgearCategoryConfidence
setAxHeadgearCategoryConfidence:
axPoseCategory
axPoseCategoryConfidence
setAxPoseCategoryConfidence:
axSkintoneCategory
axSkintoneCategoryConfidence
setAxSkintoneCategoryConfidence:
excludeOptions
setExcludeOptions:
results
setResults:
_axAgeCategory
_axAgeCategoryConfidence
_axGenderCategory
_axGenderCategoryConfidence
_axEyesCategory
_axEyesCategoryConfidence
_axSmilingCategory
_axFaceHairCategory
_axHairColorCategory
_axHairColorCategoryConfidence
_axBaldCategory
_axGlassesCategory
_axGlassesCategoryConfidence
_axMakeupEyesCategory
_axMakeupEyesCategoryConfidence
_axMakeupLipsCategory
_axMakeupLipsCategoryConfidence
_axFacemaskCategory
_axFacemaskCategoryConfidence
_axEthnicityCategory
_axEthnicityCategoryConfidence
_axExpressionCategory
_axExpressionCategoryConfidence
_axFaceHairV2Category
_axFaceHairV2CategoryConfidence
_axHairTypeCategory
_axHairTypeCategoryConfidence
_axHeadgearCategory
_axHeadgearCategoryConfidence
_axPoseCategory
_axPoseCategoryConfidence
_axSkintoneCategory
_axSkintoneCategoryConfidence
_excludeOptions
_results
T@"NSDictionary",&,N,V_results
Tq,R,N,V_axAgeCategory
Td,N,V_axAgeCategoryConfidence
Tq,R,N,V_axGenderCategory
Td,N,V_axGenderCategoryConfidence
Tq,R,N,V_axEyesCategory
Td,N,V_axEyesCategoryConfidence
Tq,R,N,V_axSmilingCategory
Tq,R,N,V_axFaceHairCategory
Tq,R,N,V_axHairColorCategory
Td,N,V_axHairColorCategoryConfidence
Tq,R,N,V_axBaldCategory
Tq,R,N,V_axGlassesCategory
Td,N,V_axGlassesCategoryConfidence
Tq,R,N,V_axMakeupEyesCategory
Td,N,V_axMakeupEyesCategoryConfidence
Tq,R,N,V_axMakeupLipsCategory
Td,N,V_axMakeupLipsCategoryConfidence
Tq,R,N,V_axFacemaskCategory
Td,N,V_axFacemaskCategoryConfidence
Tq,R,N,V_axEthnicityCategory
Td,N,V_axEthnicityCategoryConfidence
Tq,R,N,V_axExpressionCategory
Td,N,V_axExpressionCategoryConfidence
Tq,R,N,V_axFaceHairV2Category
Td,N,V_axFaceHairV2CategoryConfidence
Tq,R,N,V_axHairTypeCategory
Td,N,V_axHairTypeCategoryConfidence
Tq,R,N,V_axHeadgearCategory
Td,N,V_axHeadgearCategoryConfidence
Tq,R,N,V_axPoseCategory
Td,N,V_axPoseCategoryConfidence
Tq,R,N,V_axSkintoneCategory
Td,N,V_axSkintoneCategoryConfidence
Tq,N,V_excludeOptions
initWithSampleRate:envelope:
initWithFrequency:sampleRate:envelope:
renderInBuffer:atFrame:
_createRequestsForContext:
_faceDetectionResultsForVisionRequests:canvasSize:
_faceResultForUUID:inFaceDictionary:
_faceRectanglesRequest
set_faceRectanglesRequest:
_faceprintRequest
set_faceprintRequest:
_faceAttributesRequest
set_faceAttributesRequest:
_faceExpressionsRequest
set_faceExpressionsRequest:
_faceLandmarksRequest
set_faceLandmarksRequest:
_facePoseRequest
set_facePoseRequest:
__faceRectanglesRequest
__faceprintRequest
__faceAttributesRequest
__faceExpressionsRequest
__faceLandmarksRequest
__facePoseRequest
T@"VNDetectFaceRectanglesRequest",&,N,V__faceRectanglesRequest
T@"VNCreateFaceprintRequest",&,N,V__faceprintRequest
T@"VNClassifyFaceAttributesRequest",&,N,V__faceAttributesRequest
T@"VNDetectFaceExpressionsRequest",&,N,V__faceExpressionsRequest
T@"VNDetectFaceLandmarksRequest",&,N,V__faceLandmarksRequest
T@"VNDetectFacePoseRequest",&,N,V__facePoseRequest
_imageAestheticsRequest
set_imageAestheticsRequest:
__imageAestheticsRequest
T@"VNClassifyImageAestheticsRequest",&,N,V__imageAestheticsRequest
cpuDetectorWithModelPath:configuration:version:
gpuDetectorWithModelPath:configuration:preferredMetalDeviceID:version:modelType:
initWithNetwork:nmsThreshold:filterThreshold:
threshold
setThreshold:
nmsBoxes:
overlappingSmallFacesSuppression:
mergeHeadsBoxes:
overlappingLowMergeCountSuppression:
mergeBoxes:
smartMergeBoxes:
filterBoxes:
enforceSquareFaces:withHeight:andWidth:
detect:
processBoxes:withHeight:andWidth:
overlap_threshold
setOverlap_threshold:
filterThreshold
setFilterThreshold:
nmsThreshold
setNmsThreshold:
mergeHeadsThreshold
setMergeHeadsThreshold:
osfsThreshold
setOsfsThreshold:
osfsSizeRatio
setOsfsSizeRatio:
olmcsThreshold
setOlmcsThreshold:
olmcsMergeCountDelta
setOlmcsMergeCountDelta:
smartThreshold
setSmartThreshold:
smartDistanceFactor
setSmartDistanceFactor:
_network
_overlap_threshold
_nmsThreshold
_mergeHeadsThreshold
_osfsThreshold
_osfsSizeRatio
_olmcsThreshold
_olmcsMergeCountDelta
_smartThreshold
_smartDistanceFactor
_filterThreshold
Tf,N,V_overlap_threshold
Tf,N
T@"NSArray",&,N,V_filterThreshold
Tf,N,V_nmsThreshold
Tf,N,V_mergeHeadsThreshold
Tf,N,V_osfsThreshold
Tf,N,V_osfsSizeRatio
Tf,N,V_olmcsThreshold
Ti,N,V_olmcsMergeCountDelta
Tf,N,V_smartThreshold
Tf,N,V_smartDistanceFactor
dealloc
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
prewarmVisionEngineService
visionEngine:evaluateSource:context:options:result:
_destroyXPCConnection
xpcConnection
_serviceProxy
delegate
setDelegate:
setXpcConnection:
_xpcConnectionQueue
_delegate
_xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
T@"<AXMServiceDelegate>",W,N,V_delegate
speechItemSeparator
actions
speechActions
oneShotSoundActions
activeSoundActions
_addAction:
addSpeechItem:
addSoundItemWithID:
addSoundItemWithURL:
addActiveSoundItemWithID:
addActiveSoundItemWithURL:
completionBlock
setCompletionBlock:
interruptsAndClearsQueue
setInterruptsAndClearsQueue:
handle
_handle
_queue
_queue_actions
_interruptsAndClearsQueue
_completionBlock
T@"AXMOutputRequestHandle",R,N,V_handle
T@"NSArray",R,N
T@?,C,N,V_completionBlock
TB,N,V_interruptsAndClearsQueue
addActionHandle:
actionHandles
_actionHandles
modelDescription
modelFunction
modelParameterCount
getInitialParams:
partialDerivatives
modelFunctionStringForParameters:significantFigures:
dataSatisfiesInitialConditions
preloadModelIfNeeded:
modelURL
setModelURL:
modelIdentifier
_modelURL
_modelIdentifier
T@"NSURL",&,N,V_modelURL
T@"NSString",R,N,V_modelIdentifier
triggerWithContext:cacheKey:resultHandler:
produceImage:
screenGrabber
triggerWithScreenCaptureRegion:interfaceOrientation:options:cacheKey:resultHandler:
setScreenGrabber:
_screenGrabber
T@"AXMScreenGrabber",&,N,V_screenGrabber
_brightnessValueForVisionObservation:
_blurValueForVisionObservation:
_evaluateColorInformation:
sampleFrequency
setSampleFrequency:
shouldEvaluateColorInformation
setShouldEvaluateColorInformation:
colorDistanceTheshold
setColorDistanceTheshold:
_shouldEvaluateColorInformation
_sampleFrequency
_colorDistanceTheshold
Tq,N,V_sampleFrequency
TB,N,V_shouldEvaluateColorInformation
Td,N,V_colorDistanceTheshold
initWithIdentifier:
mlModelClasses
mobileAssetType
modelResourceNames
minSupportedFormatVersion
maxSupportedFormatVersion
formatVersion
modelURLs
setModelURLs:
contentVersionKey
_downloadAssetsIfNecessary
mlModels
mobileAssetBaseURL
_formatVersion
_mlModels
_mobileAssetBaseURL
T@"NSArray",R,N,V_mlModels
T@"NSURL",R,N,V_mobileAssetBaseURL
builderWithOptions:
_initWithOptions:
addDetectedFaces:
addDetectedClassificationFeatures:
addDetectedClassificationLocalizedValue:forLabel:
setDetectedCaption:
addDetectedIconClasses:
_usesTemplateForLowConfidenceAndExplicitFeatures
_shouldSummarizeDetectedPeople
_shouldPersonalizeCaptionWithKnownPeople
_shouldReplaceCaptionWithGenericTemplate
buildSpeakableDescription
buildVisualDescription
_stringForPauseType:
_appendPauseType:toDescriptionIfNeeded:
_appendToDescription:afterPauseType:withContents:
_addBrightnessInformationToDescription:
_addBlurInformationToDescription:
_knownPersonNames
_addPersonSummaryToDescription:
_addDetailedFaceInformationToDescription:
_addFaceInformationToDescription:
_addCaptionInformationToDescription:didConsumeDetectedFaceInfo:
_templateRulesForTag:
_subsumedTagsForTags:
_ignoredTagsForTags:
_addGenericTemplateForCaptionInformationToDescription:
_addClassificationInformationToDescription:
_addIconClassInformationToDescription:
blurFeature
setBlurFeature:
brightnessFeature
setBrightnessFeature:
isNSFW
setIsNSFW:
shouldModifyCaptionForSensitiveContent
setShouldModifyCaptionForSensitiveContent:
primarySensitiveContentFeature
setPrimarySensitiveContentFeature:
_builderOptions
_speakableDescription
_visualDescription
_faceFeatures
_classificationLabelsToLocValuesMap
_iconClassFeatures
_captionFeature
_isNSFW
_shouldModifyCaptionForSensitiveContent
_blurFeature
_brightnessFeature
_primarySensitiveContentFeature
T@"AXMVisionFeature",&,N,V_blurFeature
T@"AXMVisionFeature",&,N,V_brightnessFeature
TB,N,V_isNSFW
TB,N,V_shouldModifyCaptionForSensitiveContent
T@"AXMVisionFeature",&,N,V_primarySensitiveContentFeature
customAttributes
_isIdentity
_doMinimum
outputImage
inputImage
setInputImage:
inputWidth
setInputWidth:
inputHeight
setInputHeight:
T@"CIImage",&,N,VinputImage
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputHeight
triggerWithSource:context:
engineWillAcceptTiggerWithSource:
diagnosticsEnabled:
captureSessionNodeDidBeginProcessingFrames:
captureSessionNodeDidEndProcessingFrames:
captureSessionNodeWillProcessFrame:
captureSessionNodeDidDropFrame:
dispatcher:handleTask:
axMediaUtilitiesService:eventOccurred:
copyWithZone:
axmDescription
axmAppendRecursiveDescription:withIndentation:
_commonInit
isEqualToEngine:
_queue_shouldContinueWithoutResultHandlers:
_queue_remotelyEvaluateWithSource:context:
_queue_shouldEvaluateNode:withOptions:
_queue_activeEvaluationNodesForOptions:applyPriorityScheduling:prioritySchedulingAllowMultipleNodeExecution:
_queue_logEvaluatedResult:
_queue_activeEvaluationNodesExclusivelyUseVisionFramework:
_queue_evaluateWithSource:context:
_queue_handleEvaluatedContext:result:error:
sourceNodes
canAddSourceNode:
canAddSourceNodeClass:
addSourceNode:
insertSourceNode:atIndex:
removeSourceNode:
removeAllSourceNodes
evaluationNodes
canAddEvaluationNode:
canAddEvaluationNodeClass:
addEvaluationNode:
insertEvaluationNode:atIndex:
removeEvaluationNode:
removeAllEvaluationNodes
addSourceNodes:evaluationNodes:
sourceNodeWithIdentifier:
evaluationNodeWithIdentifier:
_queue_sourceNodeWithIdentifier:
_queue_evaluationNodeWithIdentifier:
makeUniqueIdentifierForNode:
_queue_makeUniqueIdentifierForNode:
nodeIdentifierExists:
_queue_nodeIdentifierExists:
resultHandlers
addResultHandler:
_queue_addResultHandler:
removeResultHandler:
_queue_removeResultHandler:
removeAllResultHandlers
_queue_removeAllResultHandlers
_invokeResultHandlers:withError:
_invokeResultHandlers:withResult:
isCachingEnabled
cacheSize
enableResultCachingWithCacheSize:
disableResultCaching
updateEngineConfiguration:
prewarmEngine
purgeResources:
_invokeFullQueueResultHandlersForContext:
identifier
setIdentifier:
maximumQueueSize
setMaximumQueueSize:
prioritySchedulingEnabled
setPrioritySchedulingEnabled:
prioritySchedulingAllowMultipleNodeExecution
setPrioritySchedulingAllowMultipleNodeExecution:
thresholdPriority
setThresholdPriority:
imageRegistrationFilteringEnabled
setImageRegistrationFilteringEnabled:
minimumImageRegistrationSignalLevel
setMinimumImageRegistrationSignalLevel:
cache
setCache:
areDiagnosticsEnabled
setDiagnosticsEnabled:
disableResultLogging
setDisableResultLogging:
axMediaUtilsService
setAxMediaUtilsService:
taskDispatcher
setTaskDispatcher:
sequenceRequestManager
setSequenceRequestManager:
_queue_sourceNodes
_queue_evaluationNodes
_queue_imageRegistrationNode
_queue_resultHandlers
_queue_shouldNotifyServiceOfEngineConfigChange
_queue_currentTask
_prioritySchedulingEnabled
_prioritySchedulingAllowMultipleNodeExecution
_imageRegistrationFilteringEnabled
_diagnosticsEnabled
_disableResultLogging
_identifier
_maximumQueueSize
_thresholdPriority
_minimumImageRegistrationSignalLevel
_cache
_axMediaUtilsService
_taskDispatcher
_sequenceRequestManager
T@"NSString",C,V_identifier
T@"AXMService",&,N,V_axMediaUtilsService
T@"AXMVisionEngineCache",&,N,V_cache
T@"AXMTaskDispatcher",&,N,V_taskDispatcher
T@"AXMSequenceRequestManager",&,N,V_sequenceRequestManager
Tq,V_maximumQueueSize
TB,V_prioritySchedulingEnabled
TB,V_prioritySchedulingAllowMultipleNodeExecution
TQ,V_thresholdPriority
TB,N,V_imageRegistrationFilteringEnabled
Tq,N,V_minimumImageRegistrationSignalLevel
TB,R,N
Tq,R,N
diagnosticsEnabled
TB,N,GareDiagnosticsEnabled,V_diagnosticsEnabled
TB,N,V_disableResultLogging
itemWithSource:context:
initWithSource:context:
context
setContext:
source
setSource:
_context
_source
T@"NSUUID",&,N,V_identifier
T@"AXMVisionPipelineContext",&,N,V_context
T@"AXMSourceNode",&,N,V_source
compareInitialResult:withFinalResult:indexOfUnequalItem:sortInitialResult:sortFinalResult:
nutritionLabelKeywords
nutritionLabelKeywordCountMinimum
detectSpecialCase:preferredLocales:
detectNutritionLabel:
initWithVideoFieldOfView:zoomFactor:sourceWidth:sourceHeight:presentationTimestamp:attitude:
motionCorrectedNormalizedFrame:targetAttitude:targetZoomFactor:interfaceOrientation:mirrored:
videoFieldOfView
videoZoomFactor
videoSourceWidth
videoSourceHeight
presentationTimestamp
deviceAttitude
_videoFieldOfView
_videoZoomFactor
_videoSourceWidth
_videoSourceHeight
_presentationTimestamp
_deviceAttitude
Tf,R,N,V_videoFieldOfView
Tf,R,N,V_videoZoomFactor
Tq,R,N,V_videoSourceWidth
Tq,R,N,V_videoSourceHeight
Td,R,N,V_presentationTimestamp
T@"CMAttitude",R,N,V_deviceAttitude
defaultPatch
sinePatch
squarePatch
trianglePatch
sawPatch
violinPatch
trapeziumPatch
initWithHarmonics:
setHarmonicInfos:
waveformValueForPhase:frequency:amplitude:
harmonicInfos
_baseFrequency
_baseAmplitude
_harmonics
_amplitudes
_harmonicInfos
T@"NSArray",C,N,V_harmonicInfos
initWithUnivariateFunction:sampleRate:envelope:xAxisDescriptor:yAxisDescriptor:
_xAxisValueForNormalizedPosition:
function
xAxisDescriptor
yAxisDescriptor
_function
_xAxisDescriptor
_yAxisDescriptor
T@?,R,N,V_function
T{?=^dddddd},R,N,V_xAxisDescriptor
T{?=^dddddd},R,N,V_yAxisDescriptor
contextWithSourceParameters:options:
initWithSourceParameters:options:
_commonInitWithDiagnosticsEnabled:
sourceProvidesResults
size
_makeRequestHandlerForInput:options:
visionImageRequestHandler
visionImageRequestHandlerWithOptions:
visionImageRequestHandlerIsLoaded
createSceneObservationIfNilWithBlock:
sceneObservation
setUserContext:
addResultHandlers:
sceneLabelsForOCRDocumentTypeDetection
addSceneLabelForOCRDocumentTypeDetection:
appendFeature:
addEvaluatedFeatureType:
_addSignificantEventFeatureGateIfNeededToFeature:category:minimumConfidence:
setEquivalenceToken:
result
errorOccurred:
generateFileNameForImageWithPrefix:extension:
generateImageRepresentation
sourceInput
addAuxiliaryDetector:
auxiliaryDetectors
removeAllAuxiliaryDetectors
pipelineMetric
willBeginProcessingContext
didFinishProcessingContext
shouldProcessRemotely
setShouldProcessRemotely:
error
setError:
analysisOptions
setAnalysisOptions:
effectiveTextDetectionLocales
setEffectiveTextDetectionLocales:
imageRegistrationState
setImageRegistrationState:
userContext
cacheKey
setCacheKey:
shouldCallCompletionHandlersForEngineBusyError
setShouldCallCompletionHandlersForEngineBusyError:
shouldCallCompletionHandlersForEmptyResultSet
setShouldCallCompletionHandlersForEmptyResultSet:
evaluationExclusivelyUsesVisionFramework
setEvaluationExclusivelyUsesVisionFramework:
sequenceID
setSequenceID:
metricSession
setMetricSession:
features
setFeatures:
evaluatedFeatureTypes
setEvaluatedFeatureTypes:
setResult:
appliedImageOrientation
setAppliedImageOrientation:
setVisionImageRequestHandler:
_sourceInput
_sourceParameters
_sourceProvidesOwnResults
_resultHandlers
_piplelineMetric
_sceneObservation
_sceneObservationQueue
_detectedSceneClassifications
_auxiliaryDetectors
_shouldProcessRemotely
_shouldCallCompletionHandlersForEngineBusyError
_shouldCallCompletionHandlersForEmptyResultSet
_evaluationExclusivelyUsesVisionFramework
_error
_analysisOptions
_effectiveTextDetectionLocales
_imageRegistrationState
_userContext
_cacheKey
_sequenceID
_metricSession
_features
_evaluatedFeatureTypes
_result
_appliedImageOrientation
_visionImageRequestHandler
T@"NSMutableArray",&,N,V_features
T@"NSMutableSet",&,N,V_evaluatedFeatureTypes
T@"NSError",&,N,V_error
T@"AXMVisionAnalysisOptions",&,N,V_analysisOptions
T@"AXMVisionResult",&,N,V_result
T@"NSNumber",&,N,V_appliedImageOrientation
T@"AXMetricSession",&,N,V_metricSession
T@"VNImageRequestHandler",&,N,V_visionImageRequestHandler
Tq,N,V_imageRegistrationState
T@"NSObject<NSSecureCoding>",&,N,V_userContext
T@"NSArray",&,N,V_effectiveTextDetectionLocales
TB,N,V_shouldProcessRemotely
T{CGSize=dd},R,N
T@"<NSCopying>",&,N,V_cacheKey
TB,N,V_shouldCallCompletionHandlersForEngineBusyError
TB,N,V_shouldCallCompletionHandlersForEmptyResultSet
TB,N,V_evaluationExclusivelyUsesVisionFramework
TQ,N,V_sequenceID
T@"AXMPipelineContextInput",R,N
T@"<AXMetricContainer>",R,N
effectiveLanguagesFromOptions:
recognitionLevelFromOptions:
textDetectionLanguagesFromOptions:
supportedDetectionLanguagesForLevel:
filterPreferredDetectionLanguages:withSupportedDetectionLanguages:
shouldEvaluate:
semanticTextFactory
textLayoutManager
specialCaseManager
_sequencesForObservations:canvasSize:
_textDetectionOptions:
detectTextSkew:
setSemanticTextFactory:
setTextLayoutManager:
setSpecialCaseManager:
setSceneLabelsForOCRDocumentTypeDetection:
_semanticTextFactory
_textLayoutManager
_specialCaseManager
_sceneLabelsForOCRDocumentTypeDetection
T@"AXMSemanticTextFactory",&,N,V_semanticTextFactory
T@"AXMTextLayoutManager",&,N,V_textLayoutManager
T@"AXMTextSpecialCase",&,N,V_specialCaseManager
T@"NSArray",&,N,V_sceneLabelsForOCRDocumentTypeDetection
sharedInstance
classifyImages:withTimeout:
imageNode
setImageNode:
iconClassDetector
setIconClassDetector:
brailleEdgeDetector
setBrailleEdgeDetector:
_imageNode
_iconClassDetector
_brailleEdgeDetector
T@"AXMImageNode",W,N,V_imageNode
T@"AXMIconClassDetectorNode",W,N,V_iconClassDetector
T@"AXMBrailleEdgesDetectorNode",W,N,V_brailleEdgeDetector
initWithIdentifier:delegate:
count
_queue_count
isEmpty
_queue_processNextTask
scheduleTask:
_queue_scheduleTask:
unscheduleAllTasks
_queue_unscheduleAllTasks
_queue_dequeueTask
_processQueueSource
_queue_taskList
_queue_taskIsBeingProcessed
T@"<AXMTaskDispatcherDelegate>",W,N,V_delegate
markAsComplete:
isComplete
setComplete:
taskCompleteBlock
setTaskCompleteBlock:
_complete
_taskCompleteBlock
complete
TB,N,GisComplete,V_complete
T@?,C,N,V_taskCompleteBlock
featureValueForName:
featureNames
T@"NSSet",R,N
initWithImage:iouThreshold:confidenceThreshold:
image
setImage:
iouThreshold
setIouThreshold:
confidenceThreshold
setConfidenceThreshold:
_image
_iouThreshold
_confidenceThreshold
T^{__CVBuffer=},N,V_image
Td,N,V_iouThreshold
Td,N,V_confidenceThreshold
initWithConfidence:coordinates:
confidence
setConfidence:
coordinates
setCoordinates:
_confidence
_coordinates
T@"MLMultiArray",&,N,V_confidence
T@"MLMultiArray",&,N,V_coordinates
urlOfModelInThisBundle
initWithContentsOfURL:error:
initWithConfiguration:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionFromImage:iouThreshold:confidenceThreshold:error:
predictionsFromInputs:options:error:
model
_model
T@"MLModel",R,N,V_model
_photoAuthorizationMessage:
initWithImageAssetLocalIdentifier:photoLibraryURL:allowsNetworkAccess:
updateAssetDetails
localIdentifier
creationDate
imageData
orientation
assetLocalIdentifier
setAssetLocalIdentifier:
assetImageData
setAssetImageData:
assetUTI
setAssetUTI:
assetCreationDate
setAssetCreationDate:
assetURL
setAssetURL:
assetOrientation
setAssetOrientation:
allowNetworkAccess
setAllowNetworkAccess:
photoLibraryURL
setPhotoLibraryURL:
_allowNetworkAccess
_assetOrientation
_assetLocalIdentifier
_assetImageData
_assetUTI
_assetCreationDate
_assetURL
_photoLibraryURL
T@"NSString",&,N,V_assetLocalIdentifier
T@"NSData",&,N,V_assetImageData
T@"NSString",&,N,V_assetUTI
T@"NSDate",&,N,V_assetCreationDate
T@"NSURL",&,N,V_assetURL
TI,N,V_assetOrientation
TB,N,V_allowNetworkAccess
T@"NSURL",&,N,V_photoLibraryURL
T@"NSString",R,N
T@"NSData",R,N
T@"NSDate",R,N
T@"NSURL",R,N
TI,R,N
defaultEnvelope
initWithAttackDuration:attackLevel:decayDuration:sustainDuration:sustainLevel:releaseDuration:
copy
lengthMS
levelForTime:
attackMS
setAttackMS:
attackLevel
setAttackLevel:
decayMS
setDecayMS:
sustainMS
setSustainMS:
sustainLevel
setSustainLevel:
releaseMS
setReleaseMS:
_attackMS
_attackLevel
_decayMS
_sustainMS
_sustainLevel
_releaseMS
Td,N,V_attackMS
Td,N,V_attackLevel
Td,N,V_decayMS
Td,N,V_sustainMS
Td,N,V_sustainLevel
Td,N,V_releaseMS
Td,R,N
setCameraPixelFocalLength:
setMinimumAspectRatio:
setMaximumAspectRatio:
setQuadratureTolerance:
setMinimumSize:
setMaximumNumberOfRects:
cameraPixelFocalLength
cameraOpticalOrigin
setCameraOpticalOrigin:
minimumAspectRatio
maximumAspectRatio
quadratureTolerance
minimumSize
maximumNumberOfRects
_cameraPixelFocalLength
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_maximumNumberOfRects
_cameraOpticalOrigin
Td,N,V_cameraPixelFocalLength
T{CGPoint=dd},N,V_cameraOpticalOrigin
Td,N,V_minimumAspectRatio
Td,N,V_maximumAspectRatio
Td,N,V_quadratureTolerance
Td,N,V_minimumSize
Tq,N,V_maximumNumberOfRects
colorWithRed:green:blue:
colorWithHue:saturation:brightness:
colorWithHueDegrees:saturation:brightness:
isEqualToAXMVisionColor:
_getHue:saturation:brightness:
_getRed:green:blue:
euclidianDistanceHSV:
euclidianDistanceHS:
redFloat
greenFloat
blueFloat
hueFloat
hueRadians
saturationFloat
brightnessFloat
_red
_green
_blue
_hue
_saturation
_brightness
colorWithHueDegrees:saturation:brightness:localizedName:
allColorMarkers
closestMarkerToColor:withMaximumThreshold:
localizedName
setLocalizedName:
_localizedName
T@"NSString",&,N,V_localizedName
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
canHandleRequest:
handleRequest:completion:
stopSpeakingImmediately
stopSpeakingAtNextWord
synthesizer
setSynthesizer:
currentRequestCompletionBlock
setCurrentRequestCompletionBlock:
_synthesizer
_currentRequestCompletionBlock
T@"AVSpeechSynthesizer",&,N,V_synthesizer
T@?,C,N,V_currentRequestCompletionBlock
initWithName:sampleRate:circular:
setCurrentSampleIndex:
addDataSource:
removeDataSource:
removeAllDataSources
prepareNextSamples:
isMonoOutput
name
setName:
panning
setPanning:
dataSources
setDataSources:
_name
_panning
_dataSources
T@"NSString",C,N,V_name
Td,N,V_panning
T@"NSSet",&,N,V_dataSources
captureOutput:didOutputSampleBuffer:fromConnection:
captureOutput:didDropSampleBuffer:fromConnection:
captureSessionNode:didOutputSampleBuffer:fromConnection:
autoTriggerVideoFrameEventsWithAVCaptureSession:options:delegate:
axVideoDataOutput
addVideoDataOutputWithAVCaptureSession:queue:
beginFrameEventsWithAVCaptureSession:delegate:queue:
endAutoTriggerOfVideoFrameEvents
endVideoFrameEvents
triggerWithSampleBuffer:interfaceOrientation:mirrored:options:userContext:
setAxVideoDataOutput:
captureSessionNodeDelegate
setCaptureSessionNodeDelegate:
frameDelegate
setFrameDelegate:
captureSession
setCaptureSession:
_autotrigger_queue
_axVideoDataOutput
_captureSessionNodeDelegate
_frameDelegate
_captureSession
T@"AVCaptureSession",W,N,V_captureSession
T@"<AXMAVCaptureSessionNodeDelegate>",W,N,V_captureSessionNodeDelegate
T@"<AXMAVCaptureSessionNodeFrameDelegate>",W,N,V_frameDelegate
T@"AXMCaptureVideoDataOutput",&,N,V_axVideoDataOutput
deactivateSessionWithError:
activateSessionWithError:
_handleSessionInterrupted:options:
_stringForRouteChangeReason:
_handleRouteChanged:previousRoute:
_handleMediaServicesLost
_handleMediaServicesReset
_handleSilenceSecondaryAudio:
notificationObserverTokens
setNotificationObserverTokens:
session
setSession:
_notificationObserverTokens
_session
T@"NSMutableArray",&,N,V_notificationObserverTokens
T@"AVAudioSession",&,N,V_session
transitionToState:completion:
componentState
setComponentState:
_componentState
Tq,N,V_componentState
createVImageBuffer:
setCIContext
setCIContext:
getCGImageFromCIImage:
resizeImage:byX:andY:
resizeImage:to:
resizeImage:toWidth:andHeight:
resultWithImage:features:orientation:metricSession:
resultWithImage:features:orientation:metricSession:userContext:
_init
isEqualToAXMVisionResult:
sortedFeatures
colorInfoFeature
assetMetadataFeature
parentOCRFeatureTypes
smallestChildOCRFeatureTypes
detectedTextType
detectedTextSummary
detectedTextDescription
localizedDetectedTextTypeHint
localizedDetectedTextSummaryHint
localizedDetectedTextHint
_processFeatureChild:
_processFeatureTree:
detectedFeatureDictionary
detectedFeatureDescriptionWithOptions:
detectedCaptionFeatureDescriptionWithOptions:
detectedSceneClassificationFeatureDescriptionWithOptions:
captionTranslationLocale
localizedDetectedIconHint
featureGates
equivalenceToken
brailleEdges
setBrailleEdges:
setDetectedTextType:
setDetectedTextDescription:
setDetectedTextSummary:
_equivalenceToken
_brailleEdges
_detectedTextType
_detectedTextDescription
_detectedTextSummary
T@"NSString",&,N,V_detectedTextType
T@"NSString",&,N,V_detectedTextDescription
T@"NSString",&,N,V_detectedTextSummary
T@"CIImage",&,N,V_image
T@"NSArray",&,N,V_features
T@"NSSet",&,N,V_evaluatedFeatureTypes
T@"AXMVisionFeature",R,N
T@"NSDictionary",R,N
T@"NSData",&,N,V_equivalenceToken
T@"NSData",&,N,V_brailleEdges
faceFeatures
sceneClassificationFeatures
objectClassificationFeatures
captionFeatures
includesNSFWFeatures
modelClassificationFeatures
ocrFeatures
blurFeatures
brightnessFeatures
iconClassFeatures
sensitiveContentFeatures
sensitiveContentForCaptionFeatures
captionMayContainSensitiveContent
includesFeaturesForImageExploration
axm_featuresSortedByConfidence
axm_featureWithHighestConfidence
initWithCacheSize:
_cacheQueue_cacheSize
resultForKey:
_cacheQueue_resultForKey:
setResult:forKey:
_cacheQueue_setResult:forKey:
purgeCache
_cacheQueue
_cacheQueue_maxItems
_cacheQueue_orderedKeys
_cacheQueue_results
outputSequenceWasFlushed:
legibleOutput:didOutputAttributedStrings:nativeSampleBuffers:forItemTime:
autoTriggerLegibilityEventsWithAVPlayerItem:
_mainQueue_endAutoTriggerOfLegibilityEvents
endAutoTriggerOfLegibilityEvents
isTriggeringLegibilityEvents
targetPlayerItem
setTargetPlayerItem:
_avkit_queue
_triggeringLegibilityEvents
_targetPlayerItem
T@"AVPlayerItem",W,N,V_targetPlayerItem
triggeringLegibilityEvents
TB,R,N,GisTriggeringLegibilityEvents,V_triggeringLegibilityEvents
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
modelURLForType:timeout:
infoForModelAtURL:
_modelURLForType:baseURL:
_performWithLock:
baseURL
setBaseURL:
_lock
_didTryWaitingForAssetLookup
_assetController
_baseURL
T@"NSURL",C,N,V_baseURL
nameForFaceExpression:
localizedStringFormatterForExpression:
confidenceForExpression:
likelyExpression
descriptionForExpression:
_expressionForString:
uuid
setUuid:
faceId
setFaceId:
frame
setFrame:
rectanglesConfidence
setRectanglesConfidence:
nameConfidence
setNameConfidence:
attributes
setAttributes:
attributesConfidence
setAttributesConfidence:
expressionsAndConfidence
setExpressionsAndConfidence:
landmarks
setLandmarks:
landmarks3d
setLandmarks3d:
landmarksConfidence
setLandmarksConfidence:
pose
setPose:
poseConfidence
setPoseConfidence:
_likelyExpression
_uuid
_faceId
_rectanglesConfidence
_nameConfidence
_attributes
_attributesConfidence
_expressionsAndConfidence
_landmarks
_landmarks3d
_landmarksConfidence
_poseConfidence
_frame
_pose
T@"NSUUID",&,N,V_uuid
TQ,N,V_faceId
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_frame
Td,N,V_rectanglesConfidence
T@"NSString",&,N,V_name
Td,N,V_nameConfidence
T@"AXMVisionFeatureFaceAttributes",&,N,V_attributes
Td,N,V_attributesConfidence
T@"NSDictionary",&,N,V_expressionsAndConfidence
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks
T@"AXMVisionFeatureFaceLandmarks",&,N,V_landmarks3d
Td,N,V_landmarksConfidence
T{?=[4]},N,V_pose
Td,N,V_poseConfidence
initWithImage_Placeholder:
initWithImage_PlaceholderFromCGImage:error:
initWithImage_PlaceholderAtURL:error:
setImage_PlaceholderWithCGImage:error:
setImage_PlaceholderWithURL:error:
image_Placeholder
setImage_Placeholder:
_image_Placeholder
T^{__CVBuffer=},N,V_image_Placeholder
initWithLeaf_leaf_predictions_probabilities:
leaf_leaf_predictions_probabilities
setLeaf_leaf_predictions_probabilities:
_leaf_leaf_predictions_probabilities
T@"MLMultiArray",&,N,V_leaf_leaf_predictions_probabilities
URLOfModelInThisBundle
loadWithConfiguration:completionHandler:
loadContentsOfURL:configuration:completionHandler:
initWithMLModel:
predictionFromImage_Placeholder:error:
label
setLabel:
sceneClassId
setSceneClassId:
detectorSceneClassIds
setDetectorSceneClassIds:
_sceneClassId
_label
_detectorSceneClassIds
T@"NSString",&,N,V_label
Td,N,V_confidence
TI,N,V_sceneClassId
T@"NSMutableSet",&,N,V_detectorSceneClassIds
addNSFWResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
_request
motionCorrectedNormalizedFrame:fromAttitude:fromFieldOfViewX:fromFieldOfViewY:toAttitude:toFieldOfViewX:toFieldOfViewY:interfaceOrientation:mirrored:
videoDeviceFromConnection:
isMirroredVideoDevice:
videoDimensionsForDeviceFormat:
sequenceRequestHandler
setSequenceRequestHandler:
_sequenceRequestHandler
T@"VNSequenceRequestHandler",&,N,V_sequenceRequestHandler
possibleObjectClassifications
_recognizeObjectsRequest
uiClass
setUiClass:
boundingBox
setBoundingBox:
_uiClass
_boundingBox
TQ,N,V_uiClass
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_boundingBox
_imageByWipingTextFromRects:image:colorSpace:ciContext:
_screenEquivalenceToken:
_nonMaxSupression:iouThreshold:
IoUForbb1:bb2:
_performCrossClassNMSForDetections:iouThreshold:
_initializeIconDetector
_evaluateANOD:metrics:
remapUIClassForClickability:andClass:
_iconDetector
boundingFrameForItems:
normalizedBoundingFrameForItems:
normalizedBoundingFrameForItem:
height
bottom
width
left
right
metric:inProximityOfMetric:item:threshold:
_metricTypeForMetric:
_floatValueForMetric:
_rectValueForMetric:
T{CGRect={CGPoint=dd}{CGSize=dd}},R,D,N
normalizedFrame
sequence:
feature
_feature
line:
recognizedTextFeatures
addSequence:
sequences
_sequences
region:
addLine:
firstLine
lines
_lines
row:
addCell:
cells
_cells
header:
column:
region:row:
addRow:
header
addColumn:
firstColumn
rows
columns
_header
_rows
_columns
initWithSemanticTextFactory:
numberFormatter
measurementFormatter
fractionDenominatorValuesWithOneAsNumerator
fractionDenominatorValues
measurementAbbreviationsToVerboseString
receiptRegularExpressions
_assembleLayoutSequences:
_assembleLayoutLines:
_assembleLayoutRegions:
_assembleLayoutCellsWithFeatures:
_assembleLayoutRow:
_assembleLayoutHeader:
_assembleLayoutColumn:
_assembleLayoutRowFromCell:
_assembleLayoutTable:header:columnItems:
_assembleNutritionLabelLayoutWithRows:
_assembleReceipt:
documentWithTextFeatures:canvasSize:preferredLocales:applySemanticAnalysis:error:
envelopeWithTextFeatures:canvasSize:preferredLocales:applySemanticAnalysis:error:
extractDataFromEnvelopeWithFeatures:preferredLocales:canvasSize:
documentWithTable:canvasSize:preferredLocales:requestHandler:metrics:error:
documentWithNutritionLabel:canvasSize:requestHandler:metrics:error:
documentWithReceipt:withTextSkew:canvasSize:preferredLocales:requestHandler:metrics:error:
preprocessTable:width:height:metrics:
preprocessNutritionLabel:finalFrame:
preprocessReceipt:withTextSkew:width:height:metrics:requestHandler:finalFrame:
largestDetectedContoursForImage:
detectCenterContourFromContours:withImageExtent:
isBoundary:withinNormalizedDistance:ofBoundary:
isBoundary:withinBoundary:withNormalizedThreshold:
imageRectForNormalizedRect:imageWidth:imageHeight:
processReceiptText:foundMerchantName:preferredLocales:
filterReceiptForGarbageText:
hasConsecutiveCharacters:withLength:
hasConsecutiveDigits:withLength:
sortContourRowResults:maxWidth:maxHeight:minWidth:minHeight:
sortContourColumnResults:maxWidth:maxHeight:
getTableRows:
getTableColumns:
verifyTable:sortedColumns:
nutritionLabelRowsForContourResults:normalizedNutritionLabelFrame:fullImageFrame:processedImageFrame:
getReceiptRows:preferredLocales:canvasSize:
textRowsForTable:sourceImage:requestHandler:canvasSize:
textColumnsForTable:sourceImage:requestHandler:canvasSize:
featureCellsForNutritionLabelRows:withRequestHandler:withCanvasSize:
processNutritionLabelText:
processFraction:
processMeasurement:
setNumberFormatter:
setMeasurementFormatter:
_numberFormatter
_measurementFormatter
T@"NSNumberFormatter",&,N,V_numberFormatter
T@"NSMeasurementFormatter",&,N,V_measurementFormatter
_translationalImageRegistrationRequestForInput:
_resetTranspositionHistory
_resetImageRegistration
_recordTransposition:
registrationState
_previousInput
_currentInput
_transpositionHistoryCircularBuffer
_transpositionHistoryLastRecordedIndex
_fillingHistoryBuffer
_registrationState
triggerWithCameraType:cacheKey:resultHandler:
en_USLocale
localeForLanguageCode:
baseLanguageForLocale:
localeBaseLanguageIsEnglish:
localeMatchingBaseLanguageOfLocale:fromLocales:
setEn_USLocale:
_en_USLocale
T@"NSLocale",&,N,V_en_USLocale
axmEncodeSize:forKey:
axmDecodeSizeForKey:
axmEncodePoint:forKey:
axmDecodePointForKey:
axmEncodeRect:forKey:
axmDecodeRectForKey:
compressor
limiter
initWithAttack:release:compressionRatio:threshold:sampleRate:
processSamples:
compressionRatio
setCompressionRatio:
gain
setGain:
sampleRate
setSampleRate:
ratio
setRatio:
gainReduction
setGainReduction:
engagement
setEngagement:
emaSamples
setEmaSamples:
setEma:
_compressionRatio
_gain
_threshold
_sampleRate
_ratio
_gainReduction
_engagement
_emaSamples
_ema
Td,N,V_ratio
Td,N,V_gainReduction
Td,N,V_engagement
TQ,N,V_emaSamples
Td,N,V_ema
Td,N,V_compressionRatio
Td,N,V_gain
Td,N,V_threshold
Td,N,V_sampleRate
sameScreenCapResult
setSameScreenCapResult:
screenEquivalenceToken
setScreenEquivalenceToken:
setSortedFeatures:
_sameScreenCapResult
_screenEquivalenceToken
_sortedFeatures
TB,N,V_sameScreenCapResult
T@"NSData",&,N,V_screenEquivalenceToken
T@"NSArray",&,N,V_sortedFeatures
testingImage
setTestingImage:
disableCoagulator
setDisableCoagulator:
fullRect
setFullRect:
setOrientation:
isRTL
setIsRTL:
_disableCoagulator
_isRTL
_testingImage
_orientation
_fullRect
T@"CIImage",&,N,V_testingImage
TB,N,V_disableCoagulator
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_fullRect
Tq,N,V_orientation
TB,N,V_isRTL
_processVisionResult:options:coagulator:
processFeatures:
_initWithHandle:
T@"AXMOutputActionHandle",R,N
initWithText:
text
_text
_soundFileURLForSoundID:
_initWithURL:handle:
_initWithSoundID:handle:
initWithURL:
initWithSoundID:
soundFileURL
soundID
_soundID
_soundFileURL
T@"AXMActiveSoundOutputActionHandle",R,D,N
stop
pitch
setPitch:
rate
setRate:
setQuantizedRate:
handleProvider
setHandleProvider:
_handleProvider
T@"<AXMActiveSoundOutputActionHandleProvider>",&,N,V_handleProvider
inputWithCIImage:
inputWithCIImage:photoLibraryURL:
inputWithPixelBuffer:
inputWithURL:
inputWithURL:photoLibraryURL:
_initWithCIImage:
_initWithCIImage:photoLibraryURL:
_initWithPixelBuffer:
_initWithURL:
_initWithURL:photoLibraryURL:
inputType
pixelBuffer
ciImage
imageColorSpace
createCGImageWithMetrics:
wrappedPixelBuffer
_inputType
_ciImage
_pixelBuffer
_extendedSRGBColorSpace
_URL
_cachedImageURLSize
T@"CIImage",R,N
T@"AXMPixelBufferWrapper",R,N
T^{CGColorSpace=},R,N
T^{__CVBuffer=},R,N
classLabelForIdx:
_initializeClassLabels
_localizedClassForClass:
writeDebugImage
setWriteDebugImage:
loggingName
setLoggingName:
iconClassLabels
_writeDebugImage
_loggingName
_iconClassLabels
mlModel
T@"iconclassification",R,D,N
T@"NSArray",R,N,V_iconClassLabels
TB,N,V_writeDebugImage
T@"NSString",&,N,V_loggingName
featureLabel
textLabel
childFeatures
setFeature:
subfeatures
setSubfeatures:
topLevel
setTopLevel:
includeChildren
setIncludeChildren:
_topLevel
_includeChildren
_subfeatures
T@"AXMVisionFeature",&,N,V_feature
T@"NSMutableArray",&,N,V_subfeatures
TB,N,V_topLevel
TB,N,V_includeChildren
topmost
_hasXOverlap:obj2:
_getXOverlap:obj2:
_hasYOverlap:obj2:
_getYOverlap:obj2:
coagulateElements:
_getAXMLElementGroupsForFeatures:
_applyCrossUITypeNMS:
_isInTopBar:
_getClickableTextButtons:
_flattenFeatures:
_getFlattenedChildFeatures:
_groupFeatures:
_applyHorizontalMirrorToFeatures:
_getGroupedTextFeatures:
_mergeTopLeftButton:
_removeExtraOCRAndIconFromTextField:
_getGroupedTextFields:
_getGroupedSegmentedControlFeatures:
_createToggleGroup:toGroup:
_removeTextContainingOnlyToggles:toggleCheckboxTypes:
_getGroupedToggleCheckboxWithText:
_groupFeaturesByContainment:
_getClosestDetectionBelow:target:maxDistance:
_getGroupedPictureAndSubtitleFeature:
_getTopLevelFeatureGroups:
_groupSingleContainerAsButton:featureToGroup:
_getGroupedTextButtonFeatures:
_mergeFeatureIntoGroup:feature:
_removeFeatureFromGroup:feature:
_allTabGroupsHaveSingleSubfeature:
_getTabGroupSubfeatureUIClassTypes:
_shouldBeTabBar:groupedTabButtons:
_improveFeatureFrames:
_getFeaturesForAXMLTabButtonGroups:
_getGroupedTabBarFeatures:
_compareForY:
_compareForX:
_compareArea:
_sortFeaturesReadingOrder:
_getCandidateTabBarFeatures:screenSize:
_repairTextInTabItems:
_reorderedTabsForSortedFeatures:screenSize:
_featuresByReorderingTwoRows:minY:maxY:
_reorderSimilarTopNeighbors:
_reorderByYCut:
_compareY:frame2:
_compareX:frame2:
_getHorizontalSegmentationPointDict:
_reorderByXCut:
appFrame
setAppFrame:
screenScale
setScreenScale:
canvasSize
setCanvasSize:
appOrientation
setAppOrientation:
clickableTextKeywords
setClickableTextKeywords:
nonAlphaCharactersRegex
setNonAlphaCharactersRegex:
isiPad
setIsiPad:
_isiPad
_screenScale
_appOrientation
_clickableTextKeywords
_nonAlphaCharactersRegex
_canvasSize
_appFrame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_appFrame
Td,N,V_screenScale
T{CGSize=dd},N,V_canvasSize
Tq,N,V_appOrientation
T@"NSArray",&,N,V_clickableTextKeywords
T@"NSRegularExpression",&,N,V_nonAlphaCharactersRegex
TB,N,V_isiPad
initWithText:locale:
tokenizedLength
preprocessedText
enumerateNLPTokens:
enumerateLexiconMarkers:
enumerateNumericTokens:
enumerateDataDetectors:
enumerateCustomPatterns:
enumerateSemanticErrors:
isSemanticallyComplete
textRange
substringWithRange:
addNLPToken:withRange:
addDataDetector:withRange:
addCustomPattern:withRange:
addIsInLexionMarker:withRange:
addSemanticErrorWithRange:
addNumericToken:withRange:
makeCursor
transformedSpeechText
setTransformedSpeechText:
locale
setLocale:
setTokenizedLength:
_transformedSpeechText
_locale
_tokenizedLength
T@"NSLocale",&,N,V_locale
T@"NSString",&,N,V_transformedSpeechText
Tq,N,V_tokenizedLength
tagger
cachedLexicons
compiledPatterns
dataDetector
semanticTextForText:withLocale:
_preprocessedText:
_string:containsOnlyCharactersFrom:
_applyNaturalLanguageTokens:
_applyDataDetectors:
_applyCustomPatterns:
_performSemanticAnalysis:
_lexiconExistsForLocale:
_textExistsInLexicon:withLocale:
_lexiconForLocale:
setDataDetector:
setTagger:
setCachedLexicons:
setCompiledPatterns:
_dataDetector
_tagger
_cachedLexicons
_compiledPatterns
T@"NLTagger",&,N,V_tagger
T@"NSMutableDictionary",&,N,V_cachedLexicons
T@"NSMutableDictionary",&,N,V_compiledPatterns
T@"NSDataDetector",&,N,V_dataDetector
initWithText:semanticText:
remainingRange
isFinished
advance
processAttribute:getSubstring:advanceCursor:markAsSemanticError:error:
markCurrentIndexAsSemanticErrorAndAdvanceCursor
currentAttributes
isOtherWord
isProperNoun
isWhitespace
isPunctuation
isSentenceTerminator
isInLexicon
isCustomPattern
isDataDetector
_semanticText
_length
_currentIndex
T{_NSRange=QQ},R,N
wrapperWithPixelBuffer:orientation:
_initWithPixelBuffer:orientation:
unorientedSize
orientedSize
triggerWithAssetURL:cacheKey:resultHandler:
dataSonifierPlaybackDidBeginAtPosition:
dataSonifierPlaybackDidResumeAtPosition:
dataSonifierPlaybackProgressDidChange:
dataSonifierPlaybackDidPauseAtPosition:
dataSonifierPlaybackDidEndAtPosition:
dataSonifierScrubbingDidBeginAtPosition:
dataSonifierScrubbingDidEndAtPosition:
dataSonifierScrubbingPositionDidChange:
_initializeAXMAudioDataSources
_initializeLiveToneDataSource
currentPlaybackPosition
setMasterVolume:
masterVolume
setMasterVolume:fadeDuration:
play
pause
stopPlaying
setPlaybackDuration:
playbackDuration
addPlaybackObserver:
removePlaybackObserver:
setPlaybackPosition:
beginScrubbing
endScrubbing
stopScrubbing
scrubToPlaybackFrame:
setCurrentChartDescriptor:
setCurrentSeriesIndex:
renderSonification
_renderSeries:
_renderDiscreteAudioForSeries:
_renderContinuousAudioForSeries:
_renderUnivariateFunctionAudio
_initializeAudioUnit
_uninitializeAudioUnit
_initializeAudioComponent
_setAudioFormat
_setOutputCallback
normalizedTimeEncodingValueForValue:
normalizedValueForValue:min:max:
valueFromNormalizedValue:min:max:
interpolatedPitchValueForNormalizedTimePosition:inSeries:
timeOffsetForTimeEncodingValue:
sampleIndexForTimeOffset:
frequencyForPitchEncodingValue:
volumeForVolumeEncodingValue:
durationForDurationEncodingValue:
series:hasContinuousPitchDataForTimePosition:
beginLiveContinuousToneSession
endLiveContinuousToneSession
setLiveContinuousToneNormalizedFrequency:
_peakNormalizeBuffer:length:level:
_newContinuousToneEnvelope
_regenerateTimeEncodingValuesForDataPoints
currentSeries
minimumPlaybackFrequency
setMinimumPlaybackFrequency:
maximumPlaybackFrequency
setMaximumPlaybackFrequency:
usesBinauralPanning
setUsesBinauralPanning:
dataMode
isPlaying
isPaused
isScrubbing
isEndingScrubbing
interpolationMode
continuousScrubbingTone
isInLiveContinuousToneSession
patch
setPatch:
currentChartDescriptor
currentSeriesIndex
playbackObserverUpdateTimer
setPlaybackObserverUpdateTimer:
playbackMixerDataSource
setPlaybackMixerDataSource:
playbackChartDataAudioDataSource
setPlaybackChartDataAudioDataSource:
playbackTrendlineAudioDataSource
setPlaybackTrendlineAudioDataSource:
scrubbingMixerDataSource
setScrubbingMixerDataSource:
scrubbingDiscreteAudioDataSource
setScrubbingDiscreteAudioDataSource:
scrubbingContinuousAudioDataSource
setScrubbingContinuousAudioDataSource:
scrubbingTrendlineAudioDataSource
setScrubbingTrendlineAudioDataSource:
liveContinuousMixerDataSource
setLiveContinuousMixerDataSource:
liveContinuousAudioDataSource
setLiveContinuousAudioDataSource:
playbackObservers
setPlaybackObservers:
trendlineScrubbingTone
liveContinuousDataTone
trendlineFunction
setTrendlineFunction:
scrubbingDiscreteDataRenderingContext
scrubbingPlaybackCallbackRenderingContext
liveTonePlaybackCallbackRenderingContext
playbackSampleCount
dataCategories
minimumDiscreteToneLength
setMinimumDiscreteToneLength:
maximumDiscreteToneLength
setMaximumDiscreteToneLength:
minimumToneVolume
setMinimumToneVolume:
maximumToneVolume
setMaximumToneVolume:
_audioUnit
_userDefinedPlaybackDuration
_usesBinauralPanning
_playing
_paused
_scrubbing
_isEndingScrubbing
_isInLiveContinuousToneSession
_dataMode
_interpolationMode
_minimumPlaybackFrequency
_maximumPlaybackFrequency
_continuousScrubbingTone
_patch
_currentChartDescriptor
_currentSeriesIndex
_playbackObserverUpdateTimer
_playbackMixerDataSource
_playbackChartDataAudioDataSource
_playbackTrendlineAudioDataSource
_scrubbingMixerDataSource
_scrubbingDiscreteAudioDataSource
_scrubbingContinuousAudioDataSource
_scrubbingTrendlineAudioDataSource
_liveContinuousMixerDataSource
_liveContinuousAudioDataSource
_playbackObservers
_trendlineScrubbingTone
_liveContinuousDataTone
_trendlineFunction
_scrubbingDiscreteDataRenderingContext
_scrubbingPlaybackCallbackRenderingContext
_liveTonePlaybackCallbackRenderingContext
_playbackSampleCount
_dataCategories
_minimumDiscreteToneLength
_maximumDiscreteToneLength
_minimumToneVolume
_maximumToneVolume
T@"NSTimer",&,N,V_playbackObserverUpdateTimer
T@"AXMAudioDataSourceMixer",&,N,V_playbackMixerDataSource
T@"AXMAudioDataSource",&,N,V_playbackChartDataAudioDataSource
T@"AXMAudioDataSource",&,N,V_playbackTrendlineAudioDataSource
T@"AXMAudioDataSourceMixer",&,N,V_scrubbingMixerDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingDiscreteAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingContinuousAudioDataSource
T@"AXMAudioDataSource",&,N,V_scrubbingTrendlineAudioDataSource
T@"AXMAudioDataSourceMixer",&,N,V_liveContinuousMixerDataSource
T@"AXMAudioDataSource",&,N,V_liveContinuousAudioDataSource
T@"NSPointerArray",&,N,V_playbackObservers
Ti,R,N,V_interpolationMode
T@"AXMLiveContinuousTone",R,N,V_continuousScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_trendlineScrubbingTone
T@"AXMLiveContinuousTone",R,N,V_liveContinuousDataTone
T@?,C,N,V_trendlineFunction
T^v,R,N,V_scrubbingDiscreteDataRenderingContext
T^v,R,N,V_scrubbingPlaybackCallbackRenderingContext
T^v,R,N,V_liveTonePlaybackCallbackRenderingContext
TQ,R,N,V_playbackSampleCount
T@"NSMutableOrderedSet",R,N,V_dataCategories
Td,N,V_minimumDiscreteToneLength
Td,N,V_maximumDiscreteToneLength
Td,N,V_minimumToneVolume
Td,N,V_maximumToneVolume
Td,N
TB,R,N,V_playing
TB,R,N,V_paused
TB,R,N,V_scrubbing
TB,R,N,V_isEndingScrubbing
TB,R,N,V_isInLiveContinuousToneSession
Td,N,V_minimumPlaybackFrequency
Td,N,V_maximumPlaybackFrequency
Td,N,V_userDefinedPlaybackDuration
TB,N,V_usesBinauralPanning
Ti,R,N,V_dataMode
T@"AXMSynthPatch",&,N,V_patch
T@"AXMChartDescriptor",&,N,V_currentChartDescriptor
Tq,N,V_currentSeriesIndex
T@"AXMDataSeriesDescriptor",R,N
observer
callback
observeValueForKeyPath:ofObject:change:context:
settings
addObserver:forSeetting:withBlock:
removeObserver:forSetting:
_queue_removeObserver:forSetting:
removeObserverForAllSettings:
writeOutInputImages
setWriteOutInputImages:
writeOutOCRInputImages
setWriteOutOCRInputImages:
writeOutScreenCaptures
setWriteOutScreenCaptures:
useANODModelForAXElementVision
setUseANODModelForAXElementVision:
_defaults
_queue_settingObservers
TB,D,N
initWithObjectType:boundingBox:confidence:
initWithObjectType:boundingBox:confidence:rotationAngle:yawAngle:labelKey:
rotationAngle
setRotationAngle:
yawAngle
setYawAngle:
labelKey
setLabelKey:
_rotationAngle
_yawAngle
_labelKey
Tf,V_rotationAngle
Tf,V_yawAngle
Ti,V_labelKey
axmSecurelyUnarchiveData:withExpectedClass:otherAllowedClasses:error:
_generateResultFromImage:canvasDescription:invert:
_mapLuminance:toDiscreteNumber:invert:
_processImage:analaysisOptions:
assetMetadataFromURL:
assetMetadataFromURL:localIdentifier:photoLibraryURL:
assetMetadataWithLocalIdentifier:photoLibraryURL:creationDate:UTI:
assetLocallyAvailable
setCreationDate:
setUti:
localizedTypeDescription
setLocalizedTypeDescription:
TIFFImageDescription
setTIFFImageDescription:
IPTCCaptionAbstract
setIPTCCaptionAbstract:
EXIFUserComment
setEXIFUserComment:
PNGImageDescription
setPNGImageDescription:
imageAssetLocalIdentifier
setImageAssetLocalIdentifier:
imageAssetLocallyAvailable
setImageAssetLocallyAvailable:
imageAssetPhotoLibraryURL
setImageAssetPhotoLibraryURL:
_imageAssetLocallyAvailable
_creationDate
_uti
_localizedTypeDescription
_TIFFImageDescription
_IPTCCaptionAbstract
_EXIFUserComment
_PNGImageDescription
_imageAssetLocalIdentifier
_imageAssetPhotoLibraryURL
T@"NSDate",&,N,V_creationDate
T@"NSString",&,N,V_uti
T@"NSString",&,N,V_localizedTypeDescription
T@"NSString",&,N,V_TIFFImageDescription
T@"NSString",&,N,V_IPTCCaptionAbstract
T@"NSString",&,N,V_EXIFUserComment
T@"NSString",&,N,V_PNGImageDescription
T@"NSString",&,N,V_imageAssetLocalIdentifier
TB,N,V_imageAssetLocallyAvailable
T@"NSURL",&,N,V_imageAssetPhotoLibraryURL
initWithVisionAestheticsObservation:
aestheticScore
wellFramedSubjectScore
pleasantCompositionScore
wellChosenBackgroundScore
noiseScore
failureScore
_aestheticScore
_wellFramedSubjectScore
_pleasantCompositionScore
_wellChosenBackgroundScore
_noiseScore
_failureScore
Tf,R,N,V_aestheticScore
Tf,R,N,V_wellFramedSubjectScore
Tf,R,N,V_pleasantCompositionScore
Tf,R,N,V_wellChosenBackgroundScore
Tf,R,N,V_noiseScore
Tf,R,N,V_failureScore
displayMonitor:didConnectIdentity:withConfiguration:
displayMonitor:didUpdateIdentity:withConfiguration:
displayMonitor:willDisconnectIdentity:
initWithCompletion:
initAndWaitForMainDisplayConfiguration
isInitialized
mobileGestaltOrientation
frontBoardMainDisplay
coreAnimationMainDisplay
_displayPropertiesFromMobileGestalt
_updateDisplay:withCADisplay:
_discreteOrientationForOrientation:
_updateDisplay:withConfiguration:
_updateDisplayPropertiesWithConfiguration:
displayMonitor
setDisplayMonitor:
setMobileGestaltOrientation:
_queue_CoreAnimationMainDisplay
_queue_FrontBoardMainDisplay
_initialized
_displayMonitor
_mobileGestaltOrientation
T@"FBSDisplayMonitor",&,N,V_displayMonitor
Td,N,V_mobileGestaltOrientation
T@"AXMDisplay",R,N
_initWithBackingType:
convertPointToDisplay:
convertRectToDisplay:
scale
setScale:
setSize:
physicalOrientation
setPhysicalOrientation:
referenceBounds
setReferenceBounds:
supportsDeepColor
setSupportsDeepColor:
backingType
setBackingType:
_supportsDeepColor
_scale
_physicalOrientation
_backingType
_size
_referenceBounds
Tq,N,V_backingType
Td,N,V_scale
T{CGSize=dd},N,V_size
Td,N,V_orientation
Tq,N,V_physicalOrientation
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_referenceBounds
TB,N,V_supportsDeepColor
initWithSeries:chartDescriptor:
computeRegressionModel:
setRegressionModel:
dataFeatureDescriptions
statsDescriptions
slopeDescription
confidenceDescription
minValueDescription
maxValueDescription
meanValueDescription
medianValueDescription
outliersDescription
bestFitCurveEquation
compute
computeRanges
computeMeans
computeCovariance
computeVariances
computeR
computeLinearRegression
computeResiduals
computeOutliers
stringForComponents:
getMean:
getMedian:
getVariance:
getValues:fromNSNumberArray:
positionForXAxisValue:
positionForYAxisValue:
series
setSeries:
chartDescriptor
setChartDescriptor:
setDataFeatureDescriptions:
setStatsDescriptions:
regressionModel
numValues
setNumValues:
rSquared
minX
maxX
meanX
varianceX
minY
maxY
meanY
varianceY
covariance
slope
intercept
residuals
outliers
categoryNameDelegate
setCategoryNameDelegate:
xValues
setXValues:
yValues
setYValues:
axisTitles
setAxisTitles:
_series
_chartDescriptor
_dataFeatureDescriptions
_statsDescriptions
_regressionModel
_numValues
_rSquared
_minX
_maxX
_meanX
_varianceX
_minY
_maxY
_meanY
_varianceY
_covariance
_slope
_intercept
_residuals
_outliers
_categoryNameDelegate
_xValues
_yValues
_axisTitles
T@"NSArray",&,N,V_xValues
T@"NSArray",&,N,V_yValues
T@"NSArray",&,N,V_axisTitles
TQ,N,V_numValues
T@"AXMDataSeriesDescriptor",W,N,V_series
T@"AXMChartDescriptor",W,N,V_chartDescriptor
T@"NSArray",&,N,V_dataFeatureDescriptions
T@"NSArray",&,N,V_statsDescriptions
T@"AXMDataRegressionModel",R,N,V_regressionModel
Td,R,N,V_r
Td,R,N,V_rSquared
Td,R,N,V_minX
Td,R,N,V_maxX
Td,R,N,V_meanX
Td,R,N,V_varianceX
Td,R,N,V_minY
Td,R,N,V_maxY
Td,R,N,V_meanY
Td,R,N,V_varianceY
Td,R,N,V_covariance
Td,R,N,V_slope
Td,R,N,V_intercept
T@"NSArray",R,N,V_residuals
T@"NSArray",R,N,V_outliers
T@"NSObject<AXMDataSummaryCategoryNameProvider>",W,N,V_categoryNameDelegate
filterThresholds
_filterThresholds
T@"NSArray",R,N,V_filterThresholds
T@"NSNumber",R,N,V_nmsThreshold
_imageOrientationForInterfaceOrientation:displayOrientation:
_imageOrientationForInterfaceOrientation:isMirrored:
rotatedImageWithInterfaceOrientation:displayOrientation:appliedImageOrientation:
rotatedImageWithInterfaceOrientation:isMirrored:appliedImageOrientation:
mergeWithImage:withSize:withMetrics:
addBorderWithBorderSize:
writeImageInAllOrientationsToDirectoryAtURL:metrics:
saveToURL:withOrientation:metrics:
triggerWithCoreMotionManager:deviceOrientation:cacheKey:resultHandler:
samplesPerSecond
setSamplesPerSecond:
lastSampleTime
setLastSampleTime:
_samplesPerSecond
_lastSampleTime
Td,N,V_lastSampleTime
TQ,N,V_samplesPerSecond
replaceDirectionalAbbreviations:
sharedManager
categoryNameForXAxisPosition:
beginLiveModeSession
endLiveModeSession
setLiveModeValue:
beginScrubbingSession
scrubToPosition:
endScrubbingSession
stopSpeaking
playbackStatus
valueDescriptionForPlayheadPosition
announceValueForPlayheadPosition
hapticsEnabled
setHapticsEnabled:
lastPlayheadPosition
setLastPlayheadPosition:
xGridlinePositions
xCategoryLabels
dataSeriesSummary
setDataSeriesSummary:
isDataSeriesRegressionModelLoaded
lastScrubbingValueAnnouncementPosition
setLastScrubbingValueAnnouncementPosition:
scrubbingValueAnnouncementTimer
setScrubbingValueAnnouncementTimer:
_dataSonifierAccessQueue
_hapticsEnabled
_isDataSeriesRegressionModelLoaded
_lastPlayheadPosition
_xGridlinePositions
_xCategoryLabels
_dataSeriesSummary
_lastScrubbingValueAnnouncementPosition
_scrubbingValueAnnouncementTimer
Td,N,V_lastScrubbingValueAnnouncementPosition
T@"NSTimer",&,N,V_scrubbingValueAnnouncementTimer
Tq,N
TB,N,V_hapticsEnabled
Td,N,V_lastPlayheadPosition
T@"NSArray",R,N,V_xGridlinePositions
T@"NSArray",R,N,V_xCategoryLabels
T@"AXMDataSummary",&,N,V_dataSeriesSummary
TB,R,N,V_isDataSeriesRegressionModelLoaded
TQ,R,N
networkThreshold
defaultBoxesSidesNormalized
ratios
_networkThreshold
_defaultBoxesSidesNormalized
_ratios
T@"NSNumber",R,N,V_networkThreshold
T@"NSArray",R,N,V_defaultBoxesSidesNormalized
T@"NSArray",R,N,V_ratios
setFrequency:
resetRelease
startRelease
setMuted:
renderInBuffer:atFrame:numSamples:
phase
muted
framesRendered
setFramesRendered:
releasing
setReleasing:
releaseFrame
setReleaseFrame:
_muted
_releasing
_phase
_framesRendered
_releaseFrame
Td,R,N,V_phase
TQ,N,V_framesRendered
TB,N,V_releasing
TQ,N,V_releaseFrame
TB,N,V_muted
guessType:
getValueForTag:inObject:
getValueForTag:inObject:depth:parent:
rotateImage:withAngle:andXFlip:andYFlip:
rotateImage:accordingToEXIFOrientation:
createARGBBitmapContextWithImage:
loadCGImageFromURL:error:
loadCGImageEXIFRotatedFromSource:error:
loadCGImageEXIFRotatedFromURL:error:
loadCGImageEXIFRotatedFromData:error:
loadRawBufferFromData:width:height:rowBytes:error:
loadRawBufferFromURL:width:height:rowBytes:error:
numberOfChannelsInImageData:error:
loadVImageBufferFromData:isRaw:lumaOnly:error:
loadVImageBufferFromURL:lumaOnly:error:
loadVImageBufferEXIFRotatedFromURL:error:
loadVImageBufferEXIFRotatedFromData:error:
loadCVPixelBufferARGB8FromURL:error:
loadCVPixelBuffer420YpCbCr8FromURL:error:
saveCVPixelBufferPlane8:from:withName:inFolder:error:
saveCVPixelBufferRGBA8:withName:inFolder:error:
saveCVPixelBuffer420YpCbCr8:withName:inFolder:error:
newCGImageFromPlanar8VImageBuffer:error:
saveVImageBufferPlanar8ToJPEGData:withCompressionQuality:error:
saveVImageBufferPlanar8ToData:deriveTypeFromFileName:error:
saveVImageBufferPlanar8:withName:inFolder:error:
newCGImageFromRGBA8VImageBuffer:error:
writeImageToData:type:error:
saveVImageBufferRGBA8ToJPEGData:withCompressionQuality:error:
saveVImageBufferRGBA8ToData:deriveTypeFromFileName:error:
writeImage:toFile:error:
saveVImageBufferRGBA8:withName:inFolder:error:
saveCGImage:withName:inFolder:error:
saveRawBuffer:withWidth:andHeight:andRowBytes:withName:inFolder:error:
getVImageBufferFromCVPixelBuffer:channel:error:
getVImageBufferFromCGImageLuma:error:
getVImageBufferFromCGImage:error:
extractLumaFromBGRA8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toBuffer:withBytesPerRow:
create420YCbCr8BufferFromPlanar8Buffer:withWidth:andWithHeight:andWithBytesPerRow:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:
create420YCbCr8BufferFromRGB8Buffer:withWidth:andWithHeight:andWithBytesPerRow:andAlphaFirst:toLumaBuffer:withBytesPerRowLuma:andToChromaBuffer:withBytesPerRowChroma:
createRGB8BufferFrom420Y8PlanarBuffer:withBytesPerRowY:andFrom420Cb8Buffer:withBytesPerRowCb:andFrom420Cr8Buffer:withBytesPerRowCr:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:
createRGB8BufferFrom420Y8BiPlanarBuffer:withBytesPerRowLuma:andFrom420CbCr8Buffer:withBytesPerRowChroma:andWithWidth:andWithHeight:andAlphaFirst:toRGB8Buffer:withBytesPerRowDst:
disqualifyModelIfNecessary
estimatedRadianFrequency
initWithBox:defaultBox:confidence:scale:
initWithBox:defaultBox:confidence:scale:mergesCount:
initWithBox:defaultBox:confidence:scale:hasLabel:label:
initWithBox:defaultBox:confidence:scale:hasLabel:label:labelName:
initWithBox:defaultBox:confidence:scale:mergesCount:hasLabel:label:
initWithBox:defaultBox:confidence:scale:mergesCount:hasLabel:label:labelName:
boxCenter
distanceToDefaultBox
smartDistance
overlap:
iOa:
isOverlappingSmallFace:withOverlapThreshold:withSizeRatio:
isOverlappingLowMergeDet:withOverlapThreshold:withMergeCountDelta:
setBox:
defaultBox
setDefaultBox:
mergesCount
setMergesCount:
hasLabel
setHasLabel:
labelName
setLabelName:
_area
_hasLabel
_mergesCount
_labelName
_box
_defaultBox
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_defaultBox
Tf,N,V_confidence
Ti,N,V_scale
Ti,N,V_mergesCount
TB,N,V_hasLabel
Ti,N,V_label
T@"NSString",&,N,V_labelName
T{CGPoint=dd},R,N
Tf,R,N
center
objectType
setObjectType:
bounds
setBounds:
_bounds
_objectType
Tq,V_objectType
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
T{CGPoint=dd},R
Tf,V_confidence
_imageSaliencyRequest
set_imageSaliencyRequest:
__imageSaliencyRequest
T@"VNGenerateAttentionBasedSaliencyImageRequest",&,N,V__imageSaliencyRequest
dictionaryRepresentation
initWithDictionary:
lowerBound
upperBound
setTitle:
attributedTitle
setAttributedTitle:
isCategoricalAxis
T@"NSString",C,N
T@"NSAttributedString",C,N
initWithTitle:lowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
initWithAttributedTitle:lowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
_commonInitWithLowerBound:upperBound:gridlinePositions:valueDescriptionProvider:
normalizedAxisValueForValue:
scaleType
setScaleType:
setLowerBound:
setUpperBound:
valueDescriptionProvider
setValueDescriptionProvider:
gridlinePositions
setGridlinePositions:
_title
_attributedTitle
_scaleType
_lowerBound
_upperBound
_valueDescriptionProvider
_gridlinePositions
T@"AXMScale",&,N,V_scale
Tq,N,V_scaleType
Td,N,V_lowerBound
Td,N,V_upperBound
T@?,C,N,V_valueDescriptionProvider
T@"NSArray",C,N,V_gridlinePositions
T@"NSString",C,N,V_title
T@"NSAttributedString",C,N,V_attributedTitle
initWithTitle:categoryOrder:
initWithAttributedTitle:categoryOrder:
categoryOrder
setCategoryOrder:
_categoryOrder
T@"NSArray",C,N,V_categoryOrder
valueWithNumber:
valueWithCategory:
emptyValue
setIsEmptyValue:
number
setNumber:
category
setCategory:
isEmptyValue
_isEmptyValue
_number
_category
Td,N,V_number
T@"NSString",C,N,V_category
TB,R,N,V_isEmptyValue
initWithX:y:
initWithX:y:additionalValues:
initWithX:y:additionalValues:label:
zCategoryAxisValue
zNumericAxisValue
timeEncodingValue
pitchEncodingValue
durationEncodingValue
volumeEncodingValue
timbreEncodingValue
xValue
setXValue:
yValue
setYValue:
additionalValues
setAdditionalValues:
attributedLabel
setAttributedLabel:
valueDescription
setValueDescription:
setTimeEncodingValue:
setPitchEncodingValue:
setVolumeEncodingValue:
setDurationEncodingValue:
setTimbreEncodingValue:
playbackTimeOffsetMS
setPlaybackTimeOffsetMS:
_xValue
_yValue
_additionalValues
_attributedLabel
_valueDescription
_timeEncodingValue
_pitchEncodingValue
_volumeEncodingValue
_durationEncodingValue
_timbreEncodingValue
_playbackTimeOffsetMS
T@"AXMDataPointValue",C,N,V_timeEncodingValue
T@"NSNumber",C,N,V_pitchEncodingValue
T@"NSNumber",C,N,V_volumeEncodingValue
T@"NSNumber",C,N,V_durationEncodingValue
T@"NSString",C,N,V_timbreEncodingValue
Td,N,V_playbackTimeOffsetMS
T@"AXMDataPointValue",C,N,V_xValue
T@"AXMDataPointValue",C,N,V_yValue
T@"NSArray",C,N,V_additionalValues
T@"NSAttributedString",C,N,V_attributedLabel
T@"NSString",C,N,V_valueDescription
T@"AXMDataPointValue",R,N
initWithName:isContinuous:dataPoints:
initWithAttributedName:isContinuous:dataPoints:
_commonInitWithContinuous:dataPoints:
minimumDataValueOnTimeAxis
maximumDataValueOnTimeAxis
_mutableArrayOfNSNullWithCount:
additionalNumericalValues
additionalCategoricalValues
numericalValuesFromDataPointValues:
setDataSummary:
attributedName
setAttributedName:
isContinuous
setIsContinuous:
dataPoints
setDataPoints:
dataSummary
_isContinuous
_attributedName
_dataPoints
_dataSummary
_meanValueDescription
T@"NSAttributedString",C,N,V_attributedName
TB,N,V_isContinuous
T@"NSArray",C,N,V_dataPoints
T@"AXMDataSummary",R,N,V_dataSummary
T@"NSString",R,N,V_meanValueDescription
initWithTitle:summary:xAxisDescriptor:yAxisDescriptor:series:
initWithAttributedTitle:summary:xAxisDescriptor:yAxisDescriptor:series:
initWithTitle:summary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
initWithAttributedTitle:summary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
_commonInitWithSummary:xAxisDescriptor:yAxisDescriptor:additionalAxes:series:
generateDataSummariesWithCompletion:
timeAxisDescriptor
timeNumericAxisDescriptor
timeCategoricalAxisDescriptor
pitchAxisDescriptor
durationAxisDescriptor
volumeAxisDescriptor
timbreAxisDescriptor
zNumericAxisDescriptor
zCategoricalAxisDescriptor
summary
setSummary:
contentDirection
setContentDirection:
contentFrame
setContentFrame:
xAxis
setXAxis:
yAxis
setYAxis:
additionalAxes
setAdditionalAxes:
annotations
setAnnotations:
_timeNumericAxisDescriptor
_timeCategoricalAxisDescriptor
_pitchAxisDescriptor
_durationAxisDescriptor
_volumeAxisDescriptor
_timbreAxisDescriptor
_summary
_contentDirection
_xAxis
_yAxis
_additionalAxes
_annotations
_contentFrame
T@"NSArray",C,N,V_annotations
T@"NSString",C,N,V_summary
Tq,N,V_contentDirection
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_contentFrame
T@"NSArray",C,N,V_series
T@"<AXMDataAxisDescriptor>",&,N,V_xAxis
T@"AXMNumericDataAxisDescriptor",&,N,V_yAxis
T@"NSArray",C,N,V_additionalAxes
T@"<AXMDataAxisDescriptor>",R,N
T@"AXMNumericDataAxisDescriptor",R,N,V_timeNumericAxisDescriptor
T@"AXMCategoricalDataAxisDescriptor",R,N,V_timeCategoricalAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_pitchAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_durationAxisDescriptor
T@"AXMNumericDataAxisDescriptor",R,N,V_volumeAxisDescriptor
T@"AXMCategoricalDataAxisDescriptor",R,N,V_timbreAxisDescriptor
domain
setDomain:
_domain
T@"NSArray",C,N,V_domain
linearScaleWithLowerBound:upperBound:
log10ScaleWithLowerBound:upperBound:
lnScaleWithLowerBound:upperBound:
initWithLowerBound:upperBound:apply:invert:
apply
setApply:
invert
setInvert:
_apply
_invert
T@?,C,N,V_apply
T@?,C,N,V_invert
initWithDomain:
initWithLocation:label:
initWithLocation:
location
setLocation:
playsHaptic
setPlaysHaptic:
speakDuringPlayback
setSpeakDuringPlayback:
_playsHaptic
_speakDuringPlayback
_location
T@"AXMDataPoint",&,N,V_location
T@"NSString",C,N,V_label
TB,N,V_playsHaptic
TB,N,V_speakDuringPlayback
cpuNetworkWithModelPath:configuration:version:modelType:
gpuNetworkWithModelPath:configuration:preferredMetalDeviceID:version:modelType:
preferredSmallSide
initWithModelPath:espressoEngineID:espressoDeviceID:configuration:version:modelType:
setInputShape:height:
runNetwork:inputIsBGR:
processVImage:inputIsBGR:
resizeAndProcessVImage:inputIsBGR:
processCIImage:
version
setVersion:
modelType
setModelType:
.cxx_construct
_modelType
_espressoPlan
_espressoContext
_espressoNetwork
_logitsPosOutputs
_logitsNegOutputs
_offsetsOutputs
_rollOutputs
_yawOutputs
_currentNetworkWidth
_currentNetworkHeight
_version
_maxout_layers
_bins_neg_maxout
_has_pose
_pose_square
_extra_default_boxes
_num_pos_classes
_important_classes
_model_labels
_num_ratios
_default_boxes_sides
_default_boxes_sides_normalized
_defaultBoxSizes
_cell_starts_x
_cell_starts_y
_input_aspect_ratio
_keep_aspect_ratio
_can_rotate
_input_height
Tf,N,V_threshold
Ti,N,V_version
Tq,N,V_modelType
captureOutput
setCaptureOutput:
_captureOutput
T@"AVCaptureMetadataOutput",&,N,V_captureOutput
preferredModelInputSize
isANEDeviceAvailable
configureForRunningOnANEIfPossibleWithRequest:
defaultPriority
ANEDeviceAvailable
TB,R,N,GisANEDeviceAvailable
boostEffectivePriority
resetEffectivePriority
setMinimumConfidence:
evaluateRequests:withContext:requestHandlerOptions:metrics:error:
_diagnosticNameForRequests:metrics:
minimumConfidence
priority
setPriority:
effectivePriority
setEffectivePriority:
_minimumConfidence
_priority
_effectivePriority
TQ,N,V_effectivePriority
Td,N,V_minimumConfidence
TQ,N,V_priority
captureNode
setCaptureNode:
textDetector
setTextDetector:
axElementDetector
setAxElementDetector:
_captureNode
_textDetector
_axElementDetector
T@"AXMScreenCaptureNode",W,N,V_captureNode
T@"AXMTextDetectorNode",W,N,V_textDetector
T@"AXMAXElementDetectorNode",W,N,V_axElementDetector
inputSource
setInputSource:
_inputSource
T@"AXMAudioDataSource",W,N,V_inputSource
initWithRecognizedText:range:
_textRange
T@"VNRecognizedText",R,N,V_text
T{_NSRange=QQ},R,N,V_textRange
unitTestingFaceLandmarksIs3D:
initWithVisionFaceLandmarks:
pointsArrayForRegion:
pointValuesForFaceLandmarkType:
localizedStringForLandmarkType:
is3DLandmarks
setIs3DLandmarks:
_is3DLandmarks
TB,N,V_is3DLandmarks
defaultOptions
shouldApplySemanticTextFiltering
setNormalizedMinimumTextHeightRatio:
textDetectionLocales
recognitionLevel
setRecognitionLevel:
normalizedMinimumTextHeightRatio
usesLanguageCorrection
setUsesLanguageCorrection:
setTextDetectionLocales:
postProcessingOptions
setPostProcessingOptions:
_usesLanguageCorrection
_recognitionLevel
_normalizedMinimumTextHeightRatio
_textDetectionLocales
_postProcessingOptions
TQ,N,V_recognitionLevel
Td,N,V_normalizedMinimumTextHeightRatio
TB,N,V_usesLanguageCorrection
T@"NSArray",&,N,V_textDetectionLocales
TQ,N,V_postProcessingOptions
initWithHeight:width:numberOfDiscretePinHeights:
numberOfDiscretePinHeights
hasConsistentHorizontalPinSpacing
setHasConsistentHorizontalPinSpacing:
hasConsistentVerticalPinSpacing
setHasConsistentVerticalPinSpacing:
verticalPinSpacing
setVerticalPinSpacing:
horizontalPinSpacing
setHorizontalPinSpacing:
interCellHorizontalSpacing
setInterCellHorizontalSpacing:
interCellVerticalSpacing
setInterCellVerticalSpacing:
_hasConsistentHorizontalPinSpacing
_hasConsistentVerticalPinSpacing
_width
_height
_numberOfDiscretePinHeights
_verticalPinSpacing
_horizontalPinSpacing
_interCellHorizontalSpacing
_interCellVerticalSpacing
TQ,R,V_width
TQ,R,V_height
TQ,R,V_numberOfDiscretePinHeights
TB,N,V_hasConsistentHorizontalPinSpacing
TB,N,V_hasConsistentVerticalPinSpacing
Td,N,V_verticalPinSpacing
Td,N,V_horizontalPinSpacing
Td,N,V_interCellHorizontalSpacing
Td,N,V_interCellVerticalSpacing
initWithCanvasDescription:
zoomLevel
setZoomLevel:
origin
setOrigin:
edgeStrength
setEdgeStrength:
canvasDescription
setCanvasDescription:
_zoomLevel
_edgeStrength
_canvasDescription
_origin
T@"AXMBrailleCanvasDescription",&,N,V_canvasDescription
Td,N,V_zoomLevel
T{CGPoint=dd},N,V_origin
Td,N,V_edgeStrength
TB,N,V_invert
voiceOverOptions
detectFaces
hasDetectionsEnabled
disableAllDetectors
clientID
setClientID:
detectFaceRectangles
setDetectFaceRectangles:
detectFaceNames
setDetectFaceNames:
detectFaceAttributes
setDetectFaceAttributes:
detectFaceExpressions
setDetectFaceExpressions:
detectFaceLandmarks
setDetectFaceLandmarks:
detectFacePose
setDetectFacePose:
detectScenes
setDetectScenes:
detectObjects
setDetectObjects:
detectNSFW
setDetectNSFW:
detectSignificantEvents
setDetectSignificantEvents:
detectModelClassifications
setDetectModelClassifications:
detectCaptions
setDetectCaptions:
detectTraits
setDetectTraits:
detectRectangles
setDetectRectangles:
detectHorizon
setDetectHorizon:
detectProminentObjects
setDetectProminentObjects:
detectAesthetics
setDetectAesthetics:
detectIconClass
setDetectIconClass:
detectBrailleEdges
setDetectBrailleEdges:
brailleEdgeOptions
setBrailleEdgeOptions:
detectAXElements
setDetectAXElements:
detectText
setDetectText:
textDetectionOptions
setTextDetectionOptions:
includeImageInResult
setIncludeImageInResult:
preferredOutputLocale
setPreferredOutputLocale:
ignoredLayerContextIDs
setIgnoredLayerContextIDs:
includedLayerContextIDs
setIncludedLayerContextIDs:
preserveInputImageSize
setPreserveInputImageSize:
_detectFaceRectangles
_detectFaceNames
_detectFaceAttributes
_detectFaceExpressions
_detectFaceLandmarks
_detectFacePose
_detectScenes
_detectObjects
_detectNSFW
_detectSignificantEvents
_detectModelClassifications
_detectCaptions
_detectTraits
_detectRectangles
_detectHorizon
_detectProminentObjects
_detectAesthetics
_detectIconClass
_detectBrailleEdges
_detectAXElements
_detectText
_includeImageInResult
_preserveInputImageSize
_clientID
_brailleEdgeOptions
_textDetectionOptions
_preferredOutputLocale
_ignoredLayerContextIDs
_includedLayerContextIDs
Tq,N,V_clientID
TB,N,V_detectFaceRectangles
TB,N,V_detectFaceNames
TB,N,V_detectFaceAttributes
TB,N,V_detectFaceExpressions
TB,N,V_detectFaceLandmarks
TB,N,V_detectFacePose
TB,N,V_detectScenes
TB,N,V_detectObjects
TB,N,V_detectNSFW
TB,N,V_detectSignificantEvents
TB,N,V_detectModelClassifications
TB,N,V_detectCaptions
TB,N,V_detectTraits
TB,N,V_detectRectangles
TB,N,V_detectHorizon
TB,N,V_detectProminentObjects
TB,N,V_detectAesthetics
TB,N,V_detectIconClass
TB,N,V_detectBrailleEdges
T@"AXMBrailleEdgeDetectorOptions",&,N,V_brailleEdgeOptions
TB,N,V_detectAXElements
TB,N,V_detectText
T@"AXMTextDetectionOptions",&,N,V_textDetectionOptions
TB,N,V_includeImageInResult
T@"NSLocale",&,N,V_preferredOutputLocale
T@"NSArray",&,N,V_ignoredLayerContextIDs
T@"NSArray",&,N,V_includedLayerContextIDs
TB,N,V_preserveInputImageSize
initWithComponents:options:
initWithConfiguration:
disable
enableWithCompletion:
dispatchRequest:
speak:
interrupt:
interruptImmediately
interruptPolitely
playSound:
playActiveSound:
configuration
setConfiguration:
_outputRequests
_usesPrivateAudioSession
_audioSession
_state
_queue_soundComponent
_queue_speechComponent
_queue_activeComponents
_configuration
T@"AXMOutputManagerConfiguration",&,N,V_configuration
request
setRequest:
T@"AXMOutputRequest",&,N,V_request
components
setComponents:
usesPrivateAudioSession
setUsesPrivateAudioSession:
hapticEngineUsesAutoShutdown
setHapticEngineUsesAutoShutdown:
hapticEngineAutoShutdownTimeout
setHapticEngineAutoShutdownTimeout:
hapticEngineUsesHapticsOnly
setHapticEngineUsesHapticsOnly:
_hapticEngineUsesAutoShutdown
_hapticEngineUsesHapticsOnly
_components
_hapticEngineAutoShutdownTimeout
TQ,N,V_components
TB,N,V_usesPrivateAudioSession
TB,N,V_hapticEngineUsesAutoShutdown
Td,N,V_hapticEngineAutoShutdownTimeout
TB,N,V_hapticEngineUsesHapticsOnly
_setFrequency:
_rawValueForTonePhase:
frequency
envelope
aWeighting
_frequency
_envelope
_aWeighting
TQ,N,V_sampleRate
Td,R,N,V_frequency
T@"AXMADSREnvelope",R,N,V_envelope
Td,R,N,V_aWeighting
fitDataWithModelParams:finalParams:
_nodeQueue_addResultHandler:
_nodeQueue_removeResultHandler:
_nodeQueue_removeAllResultHandlers
_nodeQueue_resultHandlers
initWithImage:
initWithLabelProbability:label:
labelProbability
setLabelProbability:
_labelProbability
T@"NSDictionary",&,N,V_labelProbability
predictionFromImage:error:
featureWithMetadata:interfaceOrientation:isMirrored:canvasSize:
featureWithFaceDetectionResult:canvasSize:
prominentObjectWithBoundingBox:canvasSize:confidence:
personWithBoundingBox:confidence:canvasSize:
featureWithVisionRequest:blurValue:canvasSize:
featureWithVisionRequest:brightnessValue:canvasSize:
featureWithVisionRequest:horizonResult:canvasSize:
objectClassificationWithLabel:localizedValue:boundingBox:confidence:canvasSize:sceneClassId:
sceneClassificationWithLabel:localizedValue:confidence:canvasSize:
nsfwClassificationWithCategory:confidence:canvasSize:
significantEventClassificationWithCategory:confidence:canvasSize:
featureWithTaxonomyNode:canvasSize:
featureWithImageAestheticsObservation:
featureWithVisionRequest:rectangleResult:canvasSize:
featureWithVisionRequest:axElementRect:confidence:uiClass:label:canvasSize:
groupedFeatureWithElementRect:uiClass:confidence:label:canvasSize:subElements:
textDocumentWithText:isSpeakable:boundingBox:regions:canvasSize:
textRegionWithText:isSpeakable:boundingBox:lines:canvasSize:
textLineWithText:boundingBox:recognizedTextFeatures:canvasSize:
textSequence:boundingBox:recognizedTextFeatures:confidence:canvasSize:
nutritionLabelWithText:isSpeakable:boundingBox:rows:canvasSize:
envelopeWithText:isSpeakable:boundingBox:regions:canvasSize:
envelopeRegion:boundingBox:confidence:canvasSize:
receiptWithText:isSpeakable:boundingBox:regions:canvasSize:
tableWithText:isSpeakable:boundingBox:rows:columns:canvasSize:isIncomplete:
tableRowWithText:boundingBox:cells:canvasSize:
tableColumnWithText:boundingBox:cells:canvasSize:
tableCellWithText:boundingBox:confidence:recognizedTextFeatures:canvasSize:isHeader:
featureWithIconClass:confidence:
featureWithMediaLegibility:
featureWithColorInfo:canvasSize:
featureWithAssetMetadata:
featureWithDeviceMotion:orientation:
featureWithCameraType:
_aspectFaceRectFromSquareFaceRect:sizeInPixels:
nameForLocation:
localizedStringForLocation:isSubjectImplicit:
locationForNormalizedFrame:previousLocation:usingThirds:
nameForUIClass:
uiClassForName:
nameForFeatureType:
nameForOCRType:
_append:toList:
flattenedFeatureList:
filterFeatureList:basedOnSceneClassIdsForFeature:
_serializeWithCoder:orDictionary:
featureType
isLowConfidence
barcodeType
ocrFeatureType
colorInfo
assetMetadata
blur
brightness
faceDetectionResult
facePose
horizonTransform
horizonAngle
classificationLabel
classificationLocalizedValue
caption
translatedCaption
locationUsingThirds:withFlippedYAxis:
value
isValueSpeakable
isBarcode
isFace
isRealtimeFace
isPerson
isSceneClassification
isObjectClassification
isNSFWClassification
isSignificantEventClassification
isModelClassification
isCaption
isColor
isBrightness
isBlur
isHorizon
isMediaLegibility
isAssetMetadata
isRectangle
isOCR
isTextDocument
isTextRegion
isTextLine
isTextSequence
isTable
isTableRow
isTableColumn
isTableCell
isNutritionLabel
isEnvelope
isEnvelopeRegion
isReceipt
isTextCharacter
isTextDiacritic
isMotion
isCameraMetadata
isProminentObject
isIconClass
isImageAesthetics
_nameForOCRFeatureType:
boundingBoxForRange:
addFeatureGate:userInfo:
isEqualToAXMVisionFeature:
values
unpaddedDetectedFaceRect
aestheticsResult
deviceMotion
deviceOrientation
cameraType
setCaptionMayContainSensitiveContent:
activationPoint
setActivationPoint:
debugRectangles
setDebugRectangles:
overrideLabel
setOverrideLabel:
_featureType
_barcodeType
_ocrFeatureType
_normalizedFrame
_value
_values
_isValueSpeakable
_recognizedTextFeatures
_colorInfo
_assetMetadata
_blur
_isLowConfidence
_horizonTransform
_horizonAngle
_faceDetectionResult
_facePose
_modelID
_classificationLabel
_classificationLocalizedValue
_caption
_translatedCaption
_featureGates
_captionMayContainSensitiveContent
_aestheticsResult
_deviceMotion
_deviceOrientation
_cameraType
_debugRectangles
_overrideLabel
_activationPoint
_unpaddedDetectedFaceRect
T@"NSDictionary",&,N,V_debugRectangles
T@"NSString",&,N,V_overrideLabel
T@"NSArray",R,N,V_recognizedTextFeatures
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T@"NSArray",R,N,V_values
Tq,N,V_uiClass
T@"AXMTranslatedText",R,N
T@"AXMVisionFeatureColorInfo",R,N
T@"AXMVisionFeatureAssetMetadata",R,N
T@"AXMVisionFeatureFaceDetectionResult",R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_unpaddedDetectedFaceRect
T{CGAffineTransform=dddddd},R,N
T@"AXMVisionFeatureAestheticsResult",R,N,V_aestheticsResult
T@"CMDeviceMotion",R,N,V_deviceMotion
Tq,R,N,V_deviceOrientation
Tq,R,N,V_cameraType
TB,N,V_captionMayContainSensitiveContent
T{CGPoint=dd},N,V_activationPoint
unitTestingFeatureWithType:canvasSize:frame:value:barcodeType:ocrFeatureType:subFeatures:
unitTestingTeatureWithType:axElementRect:confidence:uiClass:label:canvasSize:
unitTestingFeatureWithType:canvasSize:frame:value:valueIsSpeakable:barcodeType:ocrFeatureType:subFeatures:
unitTestingFeature
unitTestingFaceFeature
unitTestingProminentObjectFeature
unitTestingFaceFeatureWithSize:faceFrame:
unitTestingHorizonFeature
setX:
setY:
Td,N,V_x
Td,N,V_y
getModelForX:y:n:
initWithXValues:yValues:count:
printMatrix:rows:cols:
magnitude:size:
getIdentityMatrixWithSize:scalar:result:
getResidualsVector:result:
getGradientForX:parameterValues:result:
getJacobianForParameters:gradient:result:
getMatrixInverse:size:pivot:tmp:result:
getDiagonal:size:result:
computeScore
sortDataPoints
getSMA:lookback:
roundNumber:withSignificantFigures:
bestFitParameters
score
isDisqualified
setIsDisqualified:
iterations
_score
_bestFitParameters
_isDisqualified
_iterations
Td,R,N,V_error
Td,R,N,V_score
TB,N,V_isDisqualified
T^d,R,N,V_bestFitParameters
Ti,R,N
T@?,R,N
Ti,R,N,V_iterations
T^d,R,N,V_x
T^d,R,N,V_y
Ti,R,N,V_n
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
overrideModelURL
setOverrideModelURL:
overrideScaleMethod
setOverrideScaleMethod:
genderStrategy
setGenderStrategy:
effectiveModelURL
effectiveCaptionModelInfo
sceneDetector
setSceneDetector:
_sceneDetector
T@"AXMSceneDetectorNode",W,N,V_sceneDetector
T@"NSURL",&,N
TQ,N
T@"AXImageCaptionModel",R,N
possibleSceneClassifications
_shouldIncludeSceneLabelForOCRDocumenTypeDetection:
taxonomyOptions
setTaxonomyOptions:
_sceneClassificationRequest
_setSceneClassificationRequest:
_taxonomyOptions
__sceneClassificationRequest
T@"VNSceneClassificationRequest",&,N,S_setSceneClassificationRequest:,V__sceneClassificationRequest
TI,N,V_taxonomyOptions
connectToEngine:
disconnectFromEngine:
beginPlayback:withError:
player
setPlayer:
timePitch
setTimePitch:
_player
_timePitch
T@"AVAudioPlayerNode",&,N,V_player
T@"AVAudioUnitTimePitch",&,N,V_timePitch
_scheduleActiveSound:
_scheduleOneShotSound:completion:
_startEngineIfNeeded:
_stopActiveSound:
_logAudioFileInfo:
configChangedObserverToken
setConfigChangedObserverToken:
_engine
_oneShotSoundPlayer
_activeSounds
_configChangedObserverToken
T@,&,N,V_configChangedObserverToken
activeSound
setActiveSound:
soundComponent
setSoundComponent:
_rate
_pitch
_activeSound
_soundComponent
T@"AXMActiveSound",W,N,V_activeSound
T@"AXMSoundComponent",W,N,V_soundComponent
Tf,N,V_rate
Tf,N,V_pitch
freeResources
connect:
disconnect
isConnected
setConnected:
isEnabled
setEnabled:
nodeQueue
setNodeQueue:
_connected
_enabled
_nodeQueue
connected
TB,N,GisConnected,V_connected
T@"<AXMVisionEngineNodeConnectionDelegate>",W,N,V_delegate
T@"NSString",C,N,V_identifier
T@"NSObject<OS_dispatch_queue>",&,N,V_nodeQueue
enabled
TB,N,GisEnabled,V_enabled
setLength:
setLevel:
addEffectToChain:
removeEffectFromChain:
processEffects:
normalizeAudio
sampleBuffer
length
currentSampleIndex
isCircular
setCircular:
level
effectsChain
_circular
_sampleBuffer
_currentSampleIndex
_level
_effectsChain
Td,R,N,V_sampleRate
T^v,R,N,V_sampleBuffer
TQ,N,V_length
TQ,N,V_currentSampleIndex
circular
TB,N,GisCircular,V_circular
Td,N,V_level
T@"NSArray",R,N,V_effectsChain
addSignificantEventResultToContext:forIdentifier:confidence:markAsSensitiveCaptionContent:
systemReport
privilegedSystemReport
triggerWithImage:options:cacheKey:resultHandler:
triggerWithImageURL:assetLocalIdentifier:photoLibraryURL:options:cacheKey:resultHandler:
triggerWithImageURL:options:cacheKey:resultHandler:
triggerWithPixelBuffer:exifOrientation:options:cacheKey:resultHandler:
triggerWithImageAssetLocalIdentifier:photoLibraryURL:options:cacheKey:resultHandler:
configuredOptionsDisableAllDetectors:elementOptions:textRecognitionLevel:textDetectionLocales:preferringFullCaptions:
objectDetector
setObjectDetector:
faceDetector
setFaceDetector:
traitDetector
setTraitDetector:
prominentObjectsDetector
setProminentObjectsDetector:
captionDetector
setCaptionDetector:
nsfwDetector
setNsfwDetector:
significantEventDetector
setSignificantEventDetector:
_objectDetector
_faceDetector
_traitDetector
_prominentObjectsDetector
_captionDetector
_nsfwDetector
_significantEventDetector
T@"AXMObjectDetectorNode",W,N,V_objectDetector
T@"AXMFaceDetectorNode",W,N,V_faceDetector
T@"AXMTraitDetectorNode",W,N,V_traitDetector
T@"AXMProminentObjectsDetectorNode",W,N,V_prominentObjectsDetector
T@"AXMCaptionDetectorNode",W,N,V_captionDetector
T@"AXMNSFWDetectorNode",W,N,V_nsfwDetector
T@"AXMSignificantEventDetectorNode",W,N,V_significantEventDetector
text:confidence:isLowConfidence:targetLocale:
setText:
setLowConfidence:
targetLocale
setTargetLocale:
_lowConfidence
_targetLocale
T@"NSString",&,N,V_text
lowConfidence
TB,N,GisLowConfidence,V_lowConfidence
T@"NSLocale",&,N,V_targetLocale
axmAppendIndentation:
axmIndentationString:
axmArrayByIgnoringNilElementsWithCount:
AXMPointValue
AXMVectorValue
AXMSizeValue
AXMRectValue
AXMAffineTransformValue
axmValueWithCGPoint:
axmValueWithCGVector:
axmValueWithCGSize:
axmValueWithCGRect:
axmValueWithCGAffineTransform:
T{CGVector=dd},R,N
initWithFrequency:volume:timeOffset:
timeOffsetMS
setTimeOffsetMS:
volume
setVolume:
_timeOffsetMS
_volume
Td,N,V_frequency
Td,N,V_volume
Td,N,V_timeOffsetMS
initWithKeyPitches:sampleRate:envelope:
_bufferFrameForKeyPitch:
_keyPitches
initWithInteger:
objectForKeyedSubscript:
floatValue
postComputeWithDecoded:nmsThreshold:filterThresholds:
postComputeClickabilityWithDecoded:nmsThreshold:filterThresholds:
resultBox
resultLabel
resultLabelName
resultConfidence
shape
integerValue
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64^@72
v32@0:8d16@?24
@16@0:8
@24@0:8Q16
@28@0:8Q16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@40@0:8@16Q24Q32
@44@0:8@16Q24Q32B40
@56@0:8@16Q24Q32B40B44^@48
B16@0:8
v16@0:8
@24@0:8@16
v24@0:8@16
v32@0:8@16@24
@"VNDetectHorizonRequest"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSArray"
q16@0:8
@168@0:8q16q24q32q40q48q56q64q72q80q88q96q104q112q120q128q136q144q152q160
q24@0:8@16
v24@0:8q16
@"NSDictionary"
@32@0:8d16@24
@40@0:8d16d24@32
v32@0:8^v16Q24
@40@0:8@16{CGSize=dd}24
@32@0:8@16@24
@"VNDetectFaceRectanglesRequest"
@"VNCreateFaceprintRequest"
@"VNClassifyFaceAttributesRequest"
@"VNDetectFaceExpressionsRequest"
@"VNDetectFaceLandmarksRequest"
@"VNDetectFacePoseRequest"
@"VNClassifyImageAestheticsRequest"
@36@0:8@16@24i32
@48@0:8@16@24i32i36q40
@36@0:8@16f24@28
f16@0:8
v20@0:8f16
@32@0:8@16f24f28
i16@0:8
v20@0:8i16
@"AXShotflowNetwork"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v56@0:8@16@24@32q40@?48
v56@0:8@"AXMVisionEngine"16@"AXMSourceNode"24@"AXMVisionPipelineContext"32q40@?<v@?@"AXMVisionResult"@"NSError">48
@"NSObject<OS_dispatch_queue>"
@"<AXMServiceDelegate>"
@"NSXPCConnection"
@?16@0:8
v20@0:8B16
@"AXMOutputRequestHandle"
@"NSMutableArray"
v24@0:8^d16
@28@0:8^d16i24
B24@0:8^@16
@"NSURL"
@"NSString"
v80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48@56@64@?72
@"AXMScreenGrabber"
@24@0:8q16
v32@0:8q16@24
v40@0:8@16q24@32
v32@0:8@16^B24
@"NSMutableString"
@"NSMutableDictionary"
@"AXMVisionFeature"
@"CIImage"
@"NSNumber"
v32@0:8@"AXMSourceNode"16@"AXMVisionPipelineContext"24
B24@0:8@"AXMSourceNode"16
B24@0:8@"AXMVisionEngineNode"16
v24@0:8@"AXMAVCaptureSessionNode"16
v32@0:8@"AXMTaskDispatcher"16@"AXMTask"24
v32@0:8@16q24
v32@0:8@"AXMService"16q24
@24@0:8^{_NSZone=}16
v32@0:8@"NSMutableString"16q24
B32@0:8@16@24
@32@0:8@16B24B28
v40@0:8@16@24@32
@24@0:8#16
v24@0:8Q16
@"AXMImageRegistrationNode"
@"_AXMVisionEngineAnalysisTask"
@"AXMVisionEngineCache"
@"AXMService"
@"AXMTaskDispatcher"
@"AXMSequenceRequestManager"
@"NSUUID"
@"AXMVisionPipelineContext"
@"AXMSourceNode"
q48@0:8@16@24^q32B40B44
@56@0:8f16f20q24q32d40@48
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56q60B68
@"CMAttitude"
d40@0:8d16d24d32
@136@0:8@?16d24@32{?=^dddddd}40{?=^dddddd}88
d24@0:8d16
{?=^dddddd}16@0:8
{?="values"^d"scaleMinimum"d"scaleMaximum"d"valueMinimum"d"valueMaximum"d"count"d}
{CGSize=dd}16@0:8
B40@0:8@16@24d32
@"AXMPipelineContextInput"
@"AXBookendMetric"
@"VNSceneObservation"
@"NSMutableOrderedSet"
@"NSError"
@"AXMVisionAnalysisOptions"
@"NSObject<NSSecureCoding>"
@"<NSCopying>"
@"AXMetricSession"
@"NSMutableSet"
@"AXMVisionResult"
@"VNImageRequestHandler"
d24@0:8@16
@"AXMSemanticTextFactory"
@"AXMTextLayoutManager"
@"AXMTextSpecialCase"
@32@0:8@16d24
@"AXMImageNode"
@"AXMIconClassDetectorNode"
@"AXMBrailleEdgesDetectorNode"
@"NSObject<OS_dispatch_source>"
@"<AXMTaskDispatcherDelegate>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@40@0:8^{__CVBuffer=}16d24d32
^{__CVBuffer=}16@0:8
v24@0:8^{__CVBuffer=}16
^{__CVBuffer=}
@"MLMultiArray"
@32@0:8@16^@24
@40@0:8@16@24^@32
@48@0:8^{__CVBuffer=}16d24d32^@40
@"MLModel"
@36@0:8@16@24B32
I16@0:8
v20@0:8I16
@"NSData"
@"NSDate"
@64@0:8d16d24d32d40d48d56
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@28@0:8C16C20C24
@40@0:8d16d24d32
v40@0:8*16*24*32
@48@0:8d16d24d32@40
v48@0:8@16{_NSRange=QQ}24@40
v32@0:8@"AVSpeechSynthesizer"16@"AVSpeechUtterance"24
v48@0:8@"AVSpeechSynthesizer"16{_NSRange=QQ}24@"AVSpeechUtterance"40
v32@0:8@16@?24
@"AVSpeechSynthesizer"
@36@0:8@16d24B32
@"NSSet"
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
v40@0:8@"AVCaptureOutput"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v40@0:8@"AXMAVCaptureSessionNode"16^{opaqueCMSampleBuffer=}24@"AVCaptureConnection"32
v52@0:8^{opaqueCMSampleBuffer=}16q24B32@36@44
@"AXMCaptureVideoDataOutput"
@"<AXMAVCaptureSessionNodeDelegate>"
@"<AXMAVCaptureSessionNodeFrameDelegate>"
@"AVCaptureSession"
v32@0:8Q16Q24
v32@0:8Q16@24
@"AVAudioSession"
v32@0:8q16@?24
^{vImage_Buffer=^vQQQ}24@0:8@16
{shared_ptr<CGImage>=^{CGImage}^{__shared_weak_count}}24@0:8@16
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
v24@0:8@"AVPlayerItemOutput"16
v64@0:8@16@24@32{?=qiIq}40
v64@0:8@"AVPlayerItemLegibleOutput"16@"NSArray"24@"NSArray"32{?=qiIq}40
@"AVPlayerItem"
v44@0:8@16@24B32@36
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
@32@0:8Q16d24
@32@0:8Q16@24
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"AXAssetController"
d24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
@"AXMVisionFeatureFaceAttributes"
@"AXMVisionFeatureFaceLandmarks"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{?="columns"[4]}
@24@0:8^{__CVBuffer=}16
@32@0:8^{CGImage=}16^@24
B32@0:8^{CGImage=}16^@24
B32@0:8@16^@24
v40@0:8@16@24@?32
@32@0:8^{__CVBuffer=}16^@24
B44@0:8@16@24d32B40
@"VNVYvzEtX1JlUdu8xx5qhDI"
{CGRect={CGPoint=dd}{CGSize=dd}}92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48f56f60@64f72f76q80B88
{?=ii}24@0:8@16
@"VNSequenceRequestHandler"
@"VNRecognizeObjectsRequest"
@48@0:8@16@24^{CGColorSpace=}32@40
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
q28@0:8i16q20
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B48@0:8q16q24@32d40
q24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8q16
@"AXMLayoutHeader"
@40@0:8@16@24@32
@60@0:8@16{CGSize=dd}24@40B48^@52
@48@0:8@16@24{CGSize=dd}32
@72@0:8@16{CGSize=dd}24@40@48@56^@64
@64@0:8@16{CGSize=dd}24@40@48^@56
@80@0:8@16d24{CGSize=dd}32@48@56@64^@72
@48@0:8@16Q24Q32@40
@32@0:8@16^{CGRect={CGPoint=dd}{CGSize=dd}}24
@72@0:8@16d24Q32Q40@48@56^{CGRect={CGPoint=dd}{CGSize=dd}}64
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGRect={CGPoint=dd}{CGSize=dd}}56
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48d80
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16Q48Q56
@40@0:8@16^B24@32
B32@0:8@16Q24
@56@0:8@16d24d32d40d48
@40@0:8@16d24d32
@120@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{CGRect={CGPoint=dd}{CGSize=dd}}88
@56@0:8@16@24@32{CGSize=dd}40
@"NSNumberFormatter"
@"NSMeasurementFormatter"
[10{CGPoint="x"d"y"d}]
v40@0:8q16@24@?32
@"NSLocale"
v40@0:8{CGSize=dd}16@32
{CGSize=dd}24@0:8@16
v40@0:8{CGPoint=dd}16@32
{CGPoint=dd}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@56@0:8d16d24d32d40d48
{?=@@Q}24@0:8@16
@"AXMOutputActionHandle"
@"<AXMActiveSoundOutputActionHandleProvider>"
^{CGColorSpace=}16@0:8
^{CGImage=}24@0:8@16
@"AXMPixelBufferWrapper"
^{CGColorSpace=}
{CGSize="width"d"height"d}
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@40@0:8@16@24q32
B28@0:8B16@20
q80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v32@0:8{CGSize=dd}16
@"NSRegularExpression"
{_NSRange=QQ}16@0:8
@32@0:8{_NSRange=QQ}16
v40@0:8@16{_NSRange=QQ}24
v36@0:8B16{_NSRange=QQ}20
v32@0:8{_NSRange=QQ}16
@"NSMutableAttributedString"
^{_LXLexicon=}24@0:8@16
@"NSDataDetector"
@"NLTagger"
B48@0:8@16^@24B32B36^@40
@"NSAttributedString"
@"AXMSemanticText"
@28@0:8^{__CVBuffer=}16I24
v32@0:8d16d24
d32@0:8d16@24
Q24@0:8d16
B32@0:8@16d24
v40@0:8^v16Q24d32
^v16@0:8
^{OpaqueAudioComponentInstance=}
@"AXMLiveContinuousTone"
@"AXMSynthPatch"
@"AXMChartDescriptor"
@"NSTimer"
@"AXMAudioDataSourceMixer"
@"AXMAudioDataSource"
@"NSPointerArray"
v48@0:8@16@24@32^v40
@"NSUserDefaults"
@72@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56f60f64i68
@48@0:8@16#24@32^@40
C36@0:8d16Q24B32
v40@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24@"FBSDisplayConfiguration"32
v32@0:8@"FBSDisplayMonitor"16@"FBSDisplayIdentity"24
@24@0:8@?16
q24@0:8d16
@"AXMDisplay"
@"FBSDisplayMonitor"
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v32@0:8^d16@24
@"AXMDataSeriesDescriptor"
@"AXMDataRegressionModel"
@"NSObject<AXMDataSummaryCategoryNameProvider>"
I32@0:8q16q24
I28@0:8q16B24
@40@0:8q16q24^I32
@36@0:8q16B24^I28
@48@0:8@16{CGSize=dd}24@40
@24@0:8d16
v36@0:8@16I24@28
v48@0:8@16q24@32@?40
v24@0:8^@16
@"NSString"24@0:8d16
@"AXMDataSummary"
v40@0:8^v16Q24Q32
^{__CFString=}24@0:8@16
@44@0:8@16@24i32@36
^{CGImage=}36@0:8^{CGImage=}16f24B28B32
^{CGImage=}28@0:8^{CGImage=}16i24
^{CGContext=}24@0:8^{CGImage=}16
^{CGImage=}32@0:8@16^@24
^{CGImage=}32@0:8^{CGImageSource=}16^@24
^v56@0:8@16^I24^I32^I40^@48
^{vImage_Buffer=^vQQQ}40@0:8@16B24B28^@32
^{vImage_Buffer=^vQQQ}36@0:8@16B24^@28
^{vImage_Buffer=^vQQQ}32@0:8@16^@24
^{__CVBuffer=}32@0:8@16^@24
@52@0:8i16^{__CVBuffer=}20@28@36^@44
@48@0:8^{__CVBuffer=}16@24@32^@40
^{CGImage=}32@0:8r^{vImage_Buffer=^vQQQ}16^@24
@36@0:8r^{vImage_Buffer=^vQQQ}16f24^@28
@40@0:8r^{vImage_Buffer=^vQQQ}16@24^@32
@48@0:8r^{vImage_Buffer=^vQQQ}16@24@32^@40
@40@0:8^{CGImage=}16^{__CFString=}24^@32
B40@0:8^{CGImage=}16@24^@32
@48@0:8r^{CGImage=}16@24@32^@40
@60@0:8^v16I24I28I32@36@44^@52
{vImage_Buffer=^vQQQ}36@0:8^{__CVBuffer=}16i24^@28
{vImage_Buffer=^vQQQ}32@0:8^{CGImage=}16^@24
q56@0:8^v16i24i28Q32^v40Q48
q72@0:8^v16i24i28Q32^v40Q48^v56Q64
q76@0:8^v16i24i28Q32B40^v44Q52^v60Q68
q92@0:8^v16Q24^v32Q40^v48Q56i64i68B72^v76Q84
q76@0:8^v16Q24^v32Q40i48i52B56^v60Q68
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84
@92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84B88i92
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84B88i92@96
@100@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88B92i96
@108@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48f80i84i88B92i96@100
f24@0:8@16
B32@0:8@16f24f28
B32@0:8@16f24i28
@60@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
@"VNGenerateAttentionBasedSaliencyImageRequest"
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
v24@0:8@"NSString"16
@"NSAttributedString"16@0:8
v24@0:8@"NSAttributedString"16
@56@0:8@16d24d32@40@?48
v48@0:8d16d24@32@?40
@"AXMScale"
@"AXMDataPointValue"
@36@0:8@16B24@28
v28@0:8B16@20
@64@0:8@16@24@32@40@48@56
v56@0:8@16@24@32@40@48
@"AXMNumericDataAxisDescriptor"
@"AXMCategoricalDataAxisDescriptor"
@"<AXMDataAxisDescriptor>"
@32@0:8d16d24
@48@0:8d16d24@?32@?40
@"AXMDataPoint"
@44@0:8@16@24i32q36
@52@0:8@16i24i28@32i40q44
i32@0:8Q16Q24
v52@0:8{vImage_Buffer=^vQQQ}16B48
@52@0:8{vImage_Buffer=^vQQQ}16B48
{?="plan"^v"network_index"i}
{vector<std::shared_ptr<espresso_buffer_t>, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::shared_ptr<espresso_buffer_t> *, std::allocator<std::shared_ptr<espresso_buffer_t>>>="__value_"^v}}
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
{vector<NSString *, std::allocator<NSString *>>="__begin_"^@"__end_"^@"__end_cap_"{__compressed_pair<NSString *__strong *, std::allocator<NSString *>>="__value_"^@}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
[6[20[2f]]]
@"AVCaptureMetadataOutput"
B56@0:8@16@24@32@40^@48
@"AXMScreenCaptureNode"
@"AXMTextDetectorNode"
@"AXMAXElementDetectorNode"
@40@0:8@16{_NSRange=QQ}24
@"VNRecognizedText"
{_NSRange="location"Q"length"Q}
@20@0:8B16
@40@0:8Q16Q24Q32
@"AXMBrailleCanvasDescription"
@"AXMBrailleEdgeDetectorOptions"
@"AXMTextDetectionOptions"
@"AXMAudioSession"
@"AXMSoundComponent"
@"AXMSpeechComponent"
@"AXMOutputManagerConfiguration"
@"AXMOutputRequest"
@"AXMADSREnvelope"
d32@0:8^d16^d24
@52@0:8@16q24B32{CGSize=dd}36
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGSize=dd}56
@44@0:8@16f24{CGSize=dd}28
@92@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64{CGSize=dd}68@84
@52@0:8@16@24f32{CGSize=dd}36
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48d56@64{CGSize=dd}72@88
@84@0:8@16B24{CGRect={CGPoint=dd}{CGSize=dd}}28@60{CGSize=dd}68
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56{CGSize=dd}64
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56d64{CGSize=dd}72
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56{CGSize=dd}64
@96@0:8@16B24{CGRect={CGPoint=dd}{CGSize=dd}}28@60@68{CGSize=dd}76B92
@92@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24d56@64{CGSize=dd}72B88
@32@0:8@16q24
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48
@28@0:8q16B24
q60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16q48B56
{CGAffineTransform=dddddd}16@0:8
q24@0:8B16B20
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8{_NSRange=QQ}16
@"AXMVisionFeatureColorInfo"
@"AXMVisionFeatureAssetMetadata"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@"AXMVisionFeatureFaceDetectionResult"
@"AXMTranslatedText"
@"AXMVisionFeatureAestheticsResult"
@"CMDeviceMotion"
@104@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80q88@96
@96@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24d56q64@72{CGSize=dd}80
@108@0:8Q16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40@72B80@84q92@100
@64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
@36@0:8^d16^d24i32
v32@0:8^d16i24i28
d28@0:8^d16i24
v36@0:8i16d20^d28
v32@0:8^d16^d24
v40@0:8d16^d24^d32
v40@0:8^d16^d24^d32
i52@0:8^d16i24^i28^d36^d44
v36@0:8^d16i24^d28
v28@0:8^d16i24
d32@0:8d16Q24
^d16@0:8
@32@0:8q16@24
@"AXMSceneDetectorNode"
@"VNSceneClassificationRequest"
@"AVAudioPlayerNode"
@"AVAudioUnitTimePitch"
@"AVAudioEngine"
@"AXMActiveSound"
@"<AXMVisionEngineNodeConnectionDelegate>"
@"VN6Mb1ME89lyW3HpahkEygIG"
v48@0:8@16@24@32@?40
v64@0:8@16@24@32@40@48@?56
v52@0:8^{__CVBuffer=}16I24@28@36@?44
v56@0:8@16@24@32@40@?48
@48@0:8@?16I24@?28@?36B44
@"AXMObjectDetectorNode"
@"AXMFaceDetectorNode"
@"AXMTraitDetectorNode"
@"AXMProminentObjectsDetectorNode"
@"AXMCaptionDetectorNode"
@"AXMNSFWDetectorNode"
@"AXMSignificantEventDetectorNode"
@44@0:8@16d24B32@36
{CGVector=dd}16@0:8
@32@0:8{CGPoint=dd}16
@32@0:8{CGVector=dd}16
@32@0:8{CGSize=dd}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{CGAffineTransform=dddddd}16
@40@0:8@16d24@32
Q24@0:8@16
333333
MbP?F
333333
333333
UUUUUU
ffffff
ARGB
