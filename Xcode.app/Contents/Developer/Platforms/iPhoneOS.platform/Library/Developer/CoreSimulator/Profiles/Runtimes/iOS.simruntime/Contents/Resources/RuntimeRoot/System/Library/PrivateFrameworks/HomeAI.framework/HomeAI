Motion
Person
Vehicle
@(#)PROGRAM:HomeAI  PROJECT:HomeAI-63
featureNames
T@"NSSet",R,N
pixelBuffer
T^{__CVBuffer=},R,V_pixelBuffer
inputName
T@"NSString",R,V_inputName
SignificantActivity
mlmodelc
image__Placeholder__0
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
CoreML output nil or not of type MLFeatureTypeMultiArray
significant.activity.detector
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
mlModel
T@"MLModel",R,V_mlModel
inputFeatureValueName
T@"NSString",R,V_inputFeatureValueName
offsetsFeatureValueNames
T@"NSArray",R,V_offsetsFeatureValueNames
scoresFeatureValueNames
T@"NSArray",R,V_scoresFeatureValueNames
nmsThreshold
Td,R,V_nmsThreshold
useSoftmax
TB,R,V_useSoftmax
predictionOptions
T@"MLPredictionOptions",R,V_predictionOptions
inputDimensions
T{CGSize=dd},R,V_inputDimensions
camera.video.encoder.session
com.apple.videotoolbox.videoencoder.h264.rtvc
HMICameraVideoEncoderSession
Asset writer can't keep up with compression session output, skipping frame
v24@?0i8I12^{opaqueCMSampleBuffer=}16
v8@?0
session
T^{OpaqueVTCompressionSession=},R,V_session
assetWriter
T@"AVAssetWriter",R,V_assetWriter
assetWriterInput
T@"AVAssetWriterInput",R,V_assetWriterInput
encodedAssetData
T@"NSMutableData",R,V_encodedAssetData
activity
T@"HMFActivity",R,V_activity
bitRate
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
systemResourceUsageLevel
Tq,N,V_systemResourceUsageLevel
delegate
T@"<HMISystemResourceUsageMonitorDelegate>",W
systemResourceUsageMonitorImpl
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
workQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
Frame@%llu
camera.video.frame
regionOfInterestPixelBuffer
T^{__CVBuffer=},R,V_regionOfInterestPixelBuffer
jpegData
T@"NSData",R,V_jpegData
motionResult
T@"HMICameraVideoFrameMotionAnalysisResult",&,V_motionResult
presentationTime
T{?=qiIq},R,V_presentationTime
size
T{CGSize=dd},R,V_size
frameId
TQ,R,V_frameId
fragmentSequenceNumber
TQ,R,V_fragmentSequenceNumber
cropAndResizePixelBuffer
Invalid crop rect {x:%f y:%f width:%f height:%f} for source image {width:%f height:%f}
VTPixelTransferSessionCreate failed. Error %d
VTSessionSetProperty failed. Error %d
VTPixelTransferSessionTransferImage failed. Error %d
vision.utilities
Invalid parameter for windowSize: %lu, windowSize must be > 0
lock
T@"HMFUnfairLock",R,N,V_lock
currentIndex
TQ,V_currentIndex
queue
T@"NSMutableArray",&,N,V_queue
windowSize
TQ,R,N,V_windowSize
movingAverage
Tf,V_movingAverage
Invalid parameter not satisfying: %@
HKD://
analyzed-video-frames
%#{flags}
Success
SystemResourceUsageHigh
InsufficentTime
AnyMotion
SkippedAnalysis
duration
T{?=qiIq},V_duration
creationDate
T@"NSDate",&,V_creationDate
lastSequenceNumber
TQ,R,V_lastSequenceNumber
events
Tq,R,V_events
annotationScores
T@"NSDictionary",R,V_annotationScores
posterFrames
T@"NSArray",R,V_posterFrames
frameResults
T@"NSArray",R,V_frameResults
resultCode
Tq,V_resultCode
timeToAnalyzeFragment
Td,V_timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
Td,V_timeSinceFragmentWasSubmitted
videoFragment
T@"HMICameraVideoFragment",&,V_videoFragment
local
remote-fragment
serviceType
TQ,V_serviceType
startingMediaIntegritySequenceNumber
TQ,V_startingMediaIntegritySequenceNumber
transcodeFragment
TB,V_transcodeFragment
useScheduler
TB,V_useScheduler
inMediaAnalysis
TB,V_inMediaAnalysis
posterFrameGenerationInterval
TQ,R,V_posterFrameGenerationInterval
posterFrameHeight
TQ,R,V_posterFrameHeight
maxFragmentAnalysisDuration
Td,R,V_maxFragmentAnalysisDuration
maxFragmentDuration
Td,R,V_maxFragmentDuration
videoFrame
T@"HMICameraVideoFrame",R,V_videoFrame
detections
T@"NSArray",R,V_detections
frameWidth
TQ,R,V_frameWidth
frameHeight
TQ,R,V_frameHeight
fragment/%lu
fragmentData
T@"NSMutableData",R
T@"NSURL",&,N,V_url
sequenceNumber
TQ,R,V_sequenceNumber
data
T@"NSData",R,V_data
moovFragment
T@"NSData",R,N,V_moovFragment
eventTypes
Tq,R,V_eventTypes
[%@] [Fragment:%lu] %@
camera.video.analyzer.request
request
T@"HMICameraVideoAnalyzerRequest",R,W,V_request
Start analysis, elapsed time since submission: %fs
v24@?0@"NSData"8@"NSError"16
T@"HMICameraVideoAnalyzerRequestLog",R,V_log
phase
Tq,V_phase
analysisSubmissionTime
T@"NSDate",R,V_analysisSubmissionTime
timeSinceAnalysisSubmission
Td,R
analysisStartTime
T@"NSDate",R,V_analysisStartTime
timeSinceAnalysisStart
maxAnalysisFPS
Td,R,V_maxAnalysisFPS
fragment
T@"HMICameraVideoFragment",R,V_fragment
attributes
T@"HMICameraVideoResourceAttributes",R,V_attributes
encoderSession
T@"HMICameraVideoEncoderSession",R,V_encoderSession
posterFrameGenerator
T@"HMICameraVideoPosterFrameGenerator",R,V_posterFrameGenerator
frameSelector
T@"HMICameraVideoFrameSelector",R,V_frameSelector
assetReader
T@"HMICameraVideoAssetReader",R,V_assetReader
analyzer
T@"HMICameraVideoAnalyzer",R,V_analyzer
Tq,V_events
videoFrameResults
T@"NSMutableArray",&,V_videoFrameResults
skipAnalysis
TB,GshouldSkipAnalysis,V_skipAnalysis
failAnalysis
TB,GshouldFailAnalysis,V_failAnalysis
HMICameraVideoAnalyzerScheduler
HIGH
averageAnalysisTime: %.2f (total: %.2f), level: %@, analysisFPS: %.2f
v16@?0@"HMICameraVideoAnalyzerRequest"8
[%@] [A:%d]
 [%lu,%lu,%lu,%lu,%lu]
camera.video.analyzer.scheduler
tick
T@"HMFTimer",R,V_tick
internalAnalyzers
T@"NSPointerArray",R,V_internalAnalyzers
systemResourceUsageMonitor
T@"HMISystemResourceUsageMonitor",R,V_systemResourceUsageMonitor
systemResourceUsageMonitorUsageLevel
Tq,V_systemResourceUsageMonitorUsageLevel
averageAnalysisTime
averageAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageAnalysisTimeMovingAverage
averageTotalAnalysisTime
averageTotalAnalysisTimeMovingAverage
T@"MovingAverage",R,V_averageTotalAnalysisTimeMovingAverage
fpsSelector
T@"HMICameraVideoFPSSelector",R,V_fpsSelector
analysisFPSPreference
analysisFPS
Td,R,V_analysisFPS
maxConcurrentAnalyzers
TQ,R,V_maxConcurrentAnalyzers
Tq,R
paused
TB,GisPaused,V_paused
analyzers
T@"NSArray",R
HMICameraVideoAnalyzer
Video fragment duration: %fs is greater than expected value: %fs
Video fragment sequence number: %lu is not eqaul to expected value: %lu
Video fragment has no frames
XPC connection was interrupted, retrying.
Unknown delegate name: %@
v24@?0@"NSDictionary"8@"NSError"16
Failed to start reading of the asset: %@
v24@?0@"HMICameraVideoResourceAttributes"8@"NSError"16
End analysis: didAnalyze, significant events detected: %@
Transcoded, bytes: %lu (%f)
End analysis, time spent: %fs, elapsed time since submission: %fs
Stopping analysis due to high system resource usage
Stopping analysis due to cancelling
Stopping analysis due to analysis time past the maximum fragment analysis time: %fs
Frame selector produced 0 frames
Finished executing analysis for frame number: %lu
%@-%06d.%@
%@/%@/%@
[Fragment:%lu] Failed to save the video frame %lu error: %@
[Fragment:%lu] Saving video frame %lu
result
foundSignificantEvent
framesAnalyzedFragment
personDetected
petDetected
vehicleDetected
personScore
petScore
vehicleScore
sessionId
Uploading analytics event %@
com.apple.HomeKit.VideoAnalyzerStats
@"NSDictionary"8@?0
com.apple.HomeAI
homeai: %@
camera.video.analyzer
internalPendingRequests
T@"NSMutableArray",R,V_internalPendingRequests
didAnalyzeCount
TQ,V_didAnalyzeCount
didNotAnalyzeCount
TQ,V_didNotAnalyzeCount
didFailCount
TQ,V_didFailCount
scheduler
T@"HMICameraVideoAnalyzerScheduler",R,V_scheduler
mediaIntegritySequenceNumber
TQ,V_mediaIntegritySequenceNumber
skipSequentialMediaIntegrityCheck
TB,R,V_skipSequentialMediaIntegrityCheck
analysisInProgress
TB,V_analysisInProgress
inErrorState
TB,V_inErrorState
inBypassMode
TB,V_inBypassMode
configuration
T@"HMICameraVideoAnalyzerConfiguration",&,V_configuration
remoteAnalysisService
T@"HMIAnalysisService",&,N,V_remoteAnalysisService
sessionEnded
TB,V_sessionEnded
uploadVideoAnalysisEvent
TB,R,GshouldUploadVideoAnalysisEvent,V_uploadVideoAnalysisEvent
saveVideoFramesToDisk
TB,GshouldSaveVideoFramesToDisk,V_saveVideoFramesToDisk
pendingRequests
T@"<HMICameraVideoAnalyzerDelegate>",W,V_delegate
identifier
T@"NSUUID",R,C,V_identifier
Initializing HMICameraVideoFrameAnalyzerFactory
Resetting VideoFrameAnalyzer
Failed to load video frame analyzer
Warm starting model...
warm_start_model
Failed to create pixel buffer when warm starting model
Failed to warm start model: %@
Warm start of model took: %f
Analyze Frame
camera.video.frame.analyzer.factory
sharedInstance
T@"HMICameraVideoFrameAnalyzerFactory",R
videoFrameAnalyzer
T@"<HMICameraVideoFrameAnalyzer>",&,N,V_videoFrameAnalyzer
watchdogTimer
T@"HMFTimer",R,V_watchdogTimer
Label:%d Confidence:%f X:%f Y:%f Width:%f Height:%f}
labelIndex
Ti,R,V_labelIndex
confidence
Td,R,V_confidence
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
timeOffset
T{?=qiIq},R,V_timeOffset
width
TQ,R,V_width
height
TQ,R,V_height
generationFrequency
T{?=qiIq},R,V_generationFrequency
[Fragment:%lu] Failed to generate poster frame for: %lu
camera.video.poster.frame.generator
posterFramesInternal
T@"NSMutableArray",&,V_posterFramesInternal
input
T@"HMICameraVideoPosterFrameGeneratorInput",R,V_input
nextGenerationTime
T{?=qiIq},V_nextGenerationTime
Current system resource usage level is: %@
Analysis time + time since submission: %f
New FPS multiplier is %f and analysisFPS is %f
camera.video.fps.selector
multiplier
Td,V_multiplier
TQ,R,V_maxAnalysisFPS
[Fragment:%lu] frames initial width:%lu frames initial height:%lu number of frames to select:%lu
[Fragment:%lu] resized width:%lu resized height:%lu 
[Fragment:%lu] fragmentAnalysisFPS: %f fragmentNominalFrameRate: %f fragmentDuration: %f totalNumFramesInFragment: %lu numberFramesToSelect: %lu enable_optical_flow: %d
Optical Flow
@min.self
camera.video.frame.selector
framesInternal
T@"NSMutableArray",&,V_framesInternal
totalNumberOfFramesInFragment
TQ,V_totalNumberOfFramesInFragment
numberFramesToAdvance
Tf,V_numberFramesToAdvance
nextFrameToSelectForAnalysis
Tf,V_nextFrameToSelectForAnalysis
currentFrameNumber
TQ,V_currentFrameNumber
numberFramesToSelect
TQ,V_numberFramesToSelect
enableOpticalFlow
TB,V_enableOpticalFlow
minRows
T@"NSMutableDictionary",&,V_minRows
maxRows
T@"NSMutableDictionary",&,V_maxRows
minCols
T@"NSMutableDictionary",&,V_minCols
maxCols
T@"NSMutableDictionary",&,V_maxCols
flowArray
T^f,V_flowArray
quantizedFrames
T@"NSMutableArray",&,V_quantizedFrames
connectedComponentsMap
T@"NSMutableArray",&,V_connectedComponentsMap
framesScore
T@"NSMutableArray",&,V_framesScore
TQ,V_frameWidth
TQ,V_frameHeight
opticalFlowReferenceImage
T^{__CVBuffer=},V_opticalFlowReferenceImage
frames
T@"NSArray",R,V_frames
logIdentifier
T@"NSString",R,V_logIdentifier
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to read fragment
Failed to generate poster frame
Failed to transcode fragment
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToReadFragment
HMIErrorCodeFailedToGeneratePosterFrame
HMIErrorcodeFailedToTranscodeFragment
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodePosterFrameGenerationFailed
HMIPrivateErrorCodeCodecNotAvailable
HMIPrivateErrorCodeEncodingFailed
HMIPrivateErrorCodeInvalidVideoFrameFormatToSave
HMIPrivateErrorCodeInvalidCropRect
HMIPrivateErrorCodeScalerError
ERROR_%ld
%@: %@
HMISyntheticErrorDomain
resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
camera.video.frame.motion.analysis.result
movingObjectCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_movingObjectCropRect
motionScore
Tf,R,V_motionScore
pixelBufferUV
T^{__CVBuffer=},V_pixelBufferUV
video/mp4
Failed to initialize HMICameraVideoResourceAttributes from fragment data, err: %d
camera.video.resource.attributes
assetDuration
T{?=qiIq},R,V_assetDuration
T@"NSDate",R,V_creationDate
firstSequenceNumber
TQ,R,V_firstSequenceNumber
nominalFrameRate
Td,R,V_nominalFrameRate
naturalSize
T{CGSize=dd},R,V_naturalSize
tracks
firstFragmentSequenceNumber
fragmentCount
timeRange
formatDescriptions
[Fragment:%lu] Creating asset with url: %@
[Fragment:%lu] Failed to initialize AVAssetReader
[Fragment:%lu] Start %0.2f, Duration %0.2f, FPS %0.2f
[Fragment:%lu] No fragment URL found on loading request %@
[Fragment:%lu] No fragment data found for URL %@
[Fragment:%lu] Finished handling load request
camera.video.asset.reader
currentFrameId
TQ,V_currentFrameId
T@"AVAssetReader",&,N,V_assetReader
resourceLoaderWorkQueue
T@"NSObject<OS_dispatch_queue>",R,V_resourceLoaderWorkQueue
T@"HMICameraVideoFragment",R,V_videoFragment
HMICVFR.fi
HMICVFR.e
HMICVFR.as
HMICVFR.d
HMICVFR.fw
HMICVFR.fh
HMICVAR.e
HMICVAR.rc
HMICVAR.fr
HMICVAR.as
HMICVAR.cd
HMICVAR.d
HMICVAR.pf
HMICVAR.ttaf
HMICVAR.tsfws
HMICVAR.lsn
HMICVAR.vf
HMICVAC.pfgi
HMICVAC.pfh
HMICVAC.mfad
HMICVAC.mfd
HMICVAC.st
HMICVAC.smisn
HMICVAC.tf
HMICVASE.e
HMICVASE.vf
HMICVF.et
HMICVF.sn
HMICVF.mf
HMICVF.d
HMICVPF.d
HMICVPF.to
HMICVPF.w
HMICVPF.h
HMICVFMAR.ms
HMICVFMAR.mocrx
HMICVFMAR.mocry
HMICVFMAR.mocrw
HMICVFMAR.mocrh
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
supportsSecureCoding
TB,R
HMICameraVideoFrame does not support NSSecureCoding in the simulator
preferenceOverrides
videoAnalyzerIdentifier
didAnalyzeFragment
didNotAnalyzeFragment
didFindSignificantEvent
significantEvents
HMIAnalysisServiceTypeUnknown
HMIAnalysisServiceTypeLocal
HMIAnalysisServiceTypeRemoteFragment
HMIAnalysisServiceTypeUndefined
v24@?0@"HMICameraVideoFragment"8@"HMICameraVideoAnalyzerResult"16
v24@?0@"HMICameraVideoFragment"8@"NSError"16
T@?,C,N,V_didAnalyzeFragment
didFailAnalysisForFragment
T@?,C,N,V_didFailAnalysisForFragment
T@?,C,N,V_didFindSignificantEvent
T@?,C,N,V_didNotAnalyzeFragment
HMIAnalysisService
Remote analysis not supported in the simulator
Asset data is ignored if the video fragment is passed through the properties dictionary
Analyzer configuration property key (%@) is missing
v24@?0@"HMICameraVideoAnalyzerSignificantEvent"8@"HMICameraVideoFragment"16
camera.video.analysis.service
nextRequestID
Ti,V_nextRequestID
requests
T@"NSMapTable",R,V_requests
runRemotely
TB,V_runRemotely
com.apple.homed
analysisQOS
analysisServiceType
enableFPSSelector
analysisEnableOpticalFlow
processingDevice
confidenceThresholdPerson
confidenceThresholdPet
confidenceThresholdVehicle
modelTimeout
assetReaderMaximizePowerEfficiency
assetReaderForceBGRA
shouldLoadBaseDecodeTimestampAssetProperty
analysisEnableTranscodeFragment
realTimeEncoding
maxConcurrentAnalysisRequests
espressoLowPriority
syntheticRemoteAnalysisError
syntheticAssetReaderStartReadingError
syntheticAssetReaderReadNextFrameError
analyzeFrameSleep
user-interactive
user-initiated
unspecified
default
utility
background
Preference %@ is now %@, previously was %@
Only NSNumber and NSString properties are supported.
HMIPreference
T@"HMIPreference",R
qosMap
T@"NSDictionary",R
isProductTypeJ105A
preferenceLoggedValues
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
preferenceOverridesInternal
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
usesCPUOnly
Already started listening for the notification
v12@?0i8
HMINotifydObserver
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
callback
T@?,R,N,V_callback
token
Ti,N,V_token
notificationName
Tr*,R,N,V_notificationName
com.apple.HomeAI.%@%@%@.%tu
v32@?0@"NSNumber"8@"NSNumber"16^B24
HMICameraVideoFrameAnalyzerSignificantActivity
camera.video.frame.analyzer.significant.activity
classHierarchyMap
significantActivityDetector
T@"HMISignificantActivityDetector",R,V_significantActivityDetector
T@"NSMutableDictionary",&,V_annotationScores
T@"NSMutableArray",&,V_detections
transaction
T@"HMFOSTransaction",&,N,V_transaction
T^{__CVBuffer=},N,V_image__Placeholder__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
T@"MLMultiArray",&,N,V_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
model
T@"MLModel",R,N,V_model
%{public}@%{public}@
HMIInputFeatureProvider
MLFeatureProvider
HMISignificantActivityDetector
HMFLogging
NSObject
HMICameraVideoEncoderSession
AVAssetWriterDelegate
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMICameraVideoFrame
HMIVisionUtilities
MovingAverage
HMICameraVideoAnalyzerResult
HMICameraVideoAnalyzerConfiguration
NSCopying
HMICameraVideoAnalyzerSignificantEvent
HMICameraVideoFrameResult
HMICameraVideoFragment
HMICameraVideoAnalyzerRequestLog
HMICameraVideoAnalyzerRequest
HMICameraVideoAnalyzerScheduler
HMFTimerDelegate
HMISystemResourceUsageMonitorDelegate
HMICameraVideoAnalyzer
HMICameraVideoFrameAnalyzerFactory
HMIObjectDetection
HMIObjectDetectionUtils
HMICameraVideoPosterFrame
HMICameraVideoPosterFrameGeneratorInput
HMICameraVideoPosterFrameGenerator
HMICameraVideoFPSSelector
HMICameraVideoFrameSelector
HMIError
HMISystemResourceUsageMonitorImpl
HMICameraVideoFrameMotionAnalysisResult
HMICameraVideoResourceAttributes
HMICameraVideoAssetReader
AVAssetResourceLoaderDelegate
NSCoding
NSSecureCoding
HMICameraVideoAnalyzerDelegateAdapter
HMICameraVideoAnalyzerDelegate
HMIAnalysisService
HMIPreference
HMINotifydObserver
HMICameraVideoFrameAnalyzerSignificantActivity
HMICameraVideoFrameAnalyzer
SignificantActivityInput
SignificantActivityOutput
SignificantActivity
init
inputName
arrayWithObjects:count:
setWithArray:
isEqualToString:
pixelBuffer
featureValueWithPixelBuffer:
featureValueForName:
featureNames
initWithPixelBuffer:inputName:
.cxx_destruct
_pixelBuffer
_inputName
count
objectAtIndexedSubscript:
doubleValue
sharedInstance
usesCPUOnly
setUsesCPUOnly:
boolPreferenceForKey:defaultValue:
setAllowBackgroundGPUCompute:
bundleForClass:
pathForResource:ofType:
fileURLWithPath:
modelWithContentsOfURL:configuration:error:
hmiPrivateErrorWithCode:underlyingError:
arrayWithCapacity:
_runNeuralNetworkOnPixelBuffer:offsets:scores:error:
_postProcessOffsets:scores:outputPredictions:
inputFeatureValueName
mlModel
predictionOptions
predictionFromFeatures:options:error:
offsetsFeatureValueNames
type
hmiPrivateErrorWithCode:description:
multiArrayValue
addObject:
scoresFeatureValueNames
array
shape
unsignedLongValue
dataPointer
strides
useSoftmax
init:confidence:boundingBox:
nmsThreshold
nmsMultiClass:output:withThreshold:
countByEnumeratingWithState:objects:count:
labelIndex
confidence
boundingBox
categoryWithName:
logCategory
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
logIdentifier
initWithConfidenceThresholds:nmsThreshold:error:
predict:detectedObjects:error:
inputDimensions
_confidenceThresholds
_anchorSizes
_numberOfAnchors
_useSoftmax
_mlModel
_inputFeatureValueName
_offsetsFeatureValueNames
_scoresFeatureValueNames
_nmsThreshold
_predictionOptions
_inputDimensions
numberWithBool:
numberWithUnsignedInt:
dictionaryWithObjects:forKeys:count:
mutableCopy
numberWithInt:
setObject:forKey:
hmiPrivateErrorWithCode:
setBitRate:
initWithFileType:error:
assetWriterInputWithMediaType:outputSettings:
setExpectsMediaDataInRealTime:
addInput:
setDelegate:
data
initWithName:
encodedAssetData
appendData:
session
assetWriterInput
isReadyForMoreMediaData
setLength:
assetWriter
startWriting
startSessionAtSourceTime:
internal
stringWithFormat:
appendSampleBuffer:
invalidate
activity
markAsFinished
flush
finishWritingWithCompletionHandler:
status
error
copy
dealloc
assetWriter:didProduceFragmentedHeaderData:
assetWriter:didProduceFragmentedMediaData:fragmentedMediaDataReport:
initWithWidth:height:codecType:realTime:error:
bitRate
startEncoding
encodePixelBuffer:presentationTime:
finishEncodingWithCompletionHandler:
_session
_assetWriter
_assetWriterInput
_encodedAssetData
_activity
systemResourceUsageLevel
setSystemResourceUsageLevel:
_systemResourceUsageLevel
UTF8String
productInfo
productClass
initWithProductClass:workQueue:
workQueue
systemResourceUsageMonitorImpl
delegate
getCurrentSystemResourceUsage
start
_systemResourceUsageMonitorImpl
_workQueue
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
imageWithCVPixelBuffer:
jpegData
imageWithData:
imageByApplyingTransform:
JPEGRepresentationOfImage:colorSpace:options:
extent
JPEGRepresentationWithDownscaleFactor:outSize:
motionResult
movingObjectCropRect
cropAndResizePixelBuffer:rect:size:error:
regionOfInterestPixelBuffer
presentationTime
initWithPixelBuffer:
initWithJPEGData:presentationTime:frameId:fragmentSequenceNumber:size:
convertToJPEGAndGenerateRegionOfInterestWithSize:error:
size
frameId
fragmentSequenceNumber
setMotionResult:
_frameId
_fragmentSequenceNumber
_regionOfInterestPixelBuffer
_jpegData
_motionResult
_size
_presentationTime
createIOSurfaceBackedPixelBufferWithWidth:height:pixelBuffer:
cropPixelBuffer:cropRect:error:
resizePixelBuffer:resultSize:error:
exceptionWithName:reason:userInfo:
windowSize
floatValue
queue
movingAverage
setMovingAverage:
currentIndex
setObject:atIndexedSubscript:
setCurrentIndex:
initWithWindowSize:
addNumber:
lock
setQueue:
_movingAverage
_lock
_currentIndex
_queue
_windowSize
performBlock:
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:resultCode:lastSequenceNumber:
events
resultCode
lastSequenceNumber
duration
creationDate
frameResults
isEqualToArray:
annotationScores
isEqualToDictionary:
posterFrames
videoFragment
timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:
initWithEvents:posterFrames:frameResults:duration:creationDate:
isEqual:excludeTime:
setDuration:
setCreationDate:
setResultCode:
setTimeToAnalyzeFragment:
setTimeSinceFragmentWasSubmitted:
setVideoFragment:
_events
_annotationScores
_posterFrames
_frameResults
_creationDate
_resultCode
_timeToAnalyzeFragment
_timeSinceFragmentWasSubmitted
_videoFragment
_lastSequenceNumber
_duration
getAnalysisServiceTypePreference
numberWithUnsignedInteger:
numberPreferenceForKey:defaultValue:withMap:
integerValue
allocWithZone:
initWithPosterFrameGenerationInterval:posterFrameHeight:maxFragmentAnalysisDuration:maxFragmentDuration:
copyWithZone:
posterFrameGenerationInterval
posterFrameHeight
maxFragmentAnalysisDuration
maxFragmentDuration
serviceType
setServiceType:
startingMediaIntegritySequenceNumber
setStartingMediaIntegritySequenceNumber:
transcodeFragment
setTranscodeFragment:
useScheduler
setUseScheduler:
inMediaAnalysis
setInMediaAnalysis:
_transcodeFragment
_useScheduler
_inMediaAnalysis
_posterFrameGenerationInterval
_posterFrameHeight
_maxFragmentAnalysisDuration
_maxFragmentDuration
_serviceType
_startingMediaIntegritySequenceNumber
initWithEvents:videoFrame:
videoFrame
_videoFrame
initWithFrameId:events:annotationScores:detections:frameWidth:frameHeight:
detections
frameWidth
frameHeight
_detections
_frameWidth
_frameHeight
initWithSequenceNumber:data:moovFragment:eventTypes:
setUrl:
moovFragment
length
initWithData:
sequenceNumber
stringByAppendingFormat:
URLWithString:
absoluteString
initWithSequenceNumber:data:moovFragment:
initWithSequenceNumber:fragmentData:eventTypes:
initWithSequenceNumber:fragmentData:eventTypes:url:
fragmentData
eventTypes
_sequenceNumber
_data
_moovFragment
_eventTypes
_url
request
analyzer
identifier
UUIDString
fragment
initWithFormat:arguments:
initWithRequest:
info:
debug:
_request
date
initWithAssetData:error:
loadAttributesFromVideoFragment:
analysisSubmissionTime
timeIntervalSinceDate:
attributes
naturalSize
encoderSession
initWithGenerationFrequency:andPosterFrameHeight:
initWithInput:
startHandlingFrames
readerForVideoFragment:workQueue:logIdentifier:
maxAnalysisFPS
scheduler
analysisFPS
initWithAnalysisFPS:logIdentifier:
startHandlingFramesFromVideoResource:fragmentSequenceNumber:frameWidth:frameHeight:
objectForKeyedSubscript:
videoFrameResults
videoAnnotationScoresForFrameResult:
posterFrameGenerator
assetDuration
timeSinceAnalysisStart
timeSinceAnalysisSubmission
analysisStartTime
setSkipAnalysis:
initWithVideoFragment:analyzer:maxAnalysisFPS:
loadAttributes
startAnalysis
startEncodingSessionWithError:
startPosterFrameGeneratorWithInterval:frameHeight:
startAssetReaderWithWorkQueue:logIdentifier:
startFrameSelector
finishEncoderSession
makeDidAnalyzeResult
makeDidNotAnalyzeResultWithResultCode:
cancel
frameSelector
assetReader
setEvents:
setVideoFrameResults:
shouldSkipAnalysis
shouldFailAnalysis
setFailAnalysis:
phase
setPhase:
_skipAnalysis
_failAnalysis
_analysisSubmissionTime
_analysisStartTime
_maxAnalysisFPS
_fragment
_attributes
_encoderSession
_posterFrameGenerator
_frameSelector
_assetReader
_analyzer
_videoFrameResults
_log
_phase
alloc
initWithTimeInterval:options:
weakObjectsPointerArray
analysisFPSPreference
initWithAnalysisFPS:
setSystemResourceUsageMonitorUsageLevel:
systemResourceUsageMonitorUsageLevel
numberWithInteger:
numberPreferenceForKey:defaultValue:
unsignedIntegerValue
isProductTypeJ105A
intValue
averageAnalysisTimeMovingAverage
averageTotalAnalysisTimeMovingAverage
fpsSelector
averageAnalysisTime
updateAnalysisFPSForAverageAnalysisTime:timeSinceFragmentWasSubmitted:duration:currentSystemResourceUsageLevel:
numberWithDouble:
updateAnalysisFPS:
internalAnalyzers
hmf_addObject:
tick
resume
assertOwner
addPointer:
compact
setCount:
_compactInternalAnalyzers
suspend
isPaused
logState
analyzers
maxConcurrentAnalyzers
setInBypassMode:
_skipPendingRequests
processPendingRequests
averageTotalAnalysisTime
pendingRequests
na_each:
setZeroPadsFractionDigits:
setAllowedUnits:
setCountStyle:
stringFromByteCount:
stringByPaddingToLength:withString:startingAtIndex:
appendFormat:
didAnalyzeCount
didNotAnalyzeCount
didFailCount
mediaIntegritySequenceNumber
inBypassMode
inErrorState
analysisInProgress
appendString:
allObjects
timerDidFire:
systemResourceUsageDidChangeTo:
requestDidEnd:
registerAnalyzer:
removeAllAnalyzers
setPaused:
systemResourceUsageMonitor
_paused
_analysisFPS
_maxConcurrentAnalyzers
_tick
_internalAnalyzers
_systemResourceUsageMonitor
_systemResourceUsageMonitorUsageLevel
_averageAnalysisTimeMovingAverage
_averageTotalAnalysisTimeMovingAverage
_fpsSelector
qosMap
_scheduleRequest:
sessionEnded
configuration
_handleError:request:
internalPendingRequests
hmf_enqueue:
setSessionEnded:
setRunRemotely:
_handleError:request:description:
skipSequentialMediaIntegrityCheck
firstSequenceNumber
nominalFrameRate
_handleDidNotAnalyzeRequest:resultCode:
_shouldContinueAnalyzingRequest:resultCode:
hmf_maybeDequeue
_analyzeRequest:
setAnalysisInProgress:
_checkRequest:
_analyzeRequestRemotely:retryOnConnectionInterruption:
_analyzeRequestLocally:
setMediaIntegritySequenceNumber:
remoteAnalysisService
preferenceOverrides
hmiSyntheticErrorFromPreference:
analyzer:didFindSignificantEvent:inFragment:
code
_handleError:request:underlyingError:
_handleDidAnalyzeRequest:withResult:
_handleDidNotAnalyzeRequest:withResult:
requestAnalysisForAssetData:withProperties:andCompletionHandler:
warmStartModel
_willAnalyzeRequest:
_handleError:request:description:underlyingError:
_analyzeRequestFramesLocally:
startReading:
_didAnalyzeRequest:withResult:
setDidAnalyzeCount:
_sendAnalyticsEventForRequest:result:
_requestDidEnd:
analyzer:willAnalyzeRequest:
analyzer:didAnalyzeFragment:withResult:
analyzer:didAnalyzeRequest:withResult:
analyzer:didNotAnalyzeFragment:withResult:
analyzer:didNotAnalyzeRequest:withResult:
analyzer:didFailAnalysisForFragment:withError:
analyzer:didFailAnalysisForRequest:withError:
_handleDidNotAnalyzeRequest:resultCode:description:
_didNotAnalyzeRequest:withResult:
setDidNotAnalyzeCount:
hmiErrorWithCode:description:
callStackSymbols
_enterErrorState
_didFailAnalysisForRequest:withError:
setDidFailCount:
_sendAnalyticsEventForRequest:error:
setInErrorState:
_failPendingRequests
readNextFrame:error:
willHandleFramesFromVideoResource:
handleVideoFrame:error:
willHandleFrames
_analyzeRequestFrames:
_handleDidAnalyzeRequest:
frames
_analyzeVideoFrame:request:error:events:
sleepForTimeInterval:
analyze:error:
shouldSaveVideoFramesToDisk
_saveVideoFrame:videoFragment:error:
_analyzeFrame:error:
_resetFrameEvents:
hasPrefix:
lastPathComponent
stringByDeletingPathExtension
hasPreferenceForKey:
shouldUploadVideoAnalysisEvent
numberWithFloat:
string
bundleWithIdentifier:
infoDictionary
objectForKey:
queryVersionInformation
initWithConfiguration:identifier:
analyzeFragment:
clearPendingFragments
pendingRequestsCount
setConfiguration:
setRemoteAnalysisService:
setSaveVideoFramesToDisk:
_skipSequentialMediaIntegrityCheck
_analysisInProgress
_inErrorState
_inBypassMode
_sessionEnded
_uploadVideoAnalysisEvent
_saveVideoFramesToDisk
_delegate
_identifier
_internalPendingRequests
_didAnalyzeCount
_didNotAnalyzeCount
_didFailCount
_scheduler
_mediaIntegritySequenceNumber
_configuration
_remoteAnalysisService
setVideoFrameAnalyzer:
watchdogTimer
kick
getConfidenceThresholdPreferenceForKey:defaultConfidenceThreshold:
modelTimeoutPreference
videoFrameAnalyzer
classify:error:
_videoFrameAnalyzer
_watchdogTimer
_labelIndex
_confidence
_boundingBox
sortedArrayUsingComparator:
setObject:forKeyedSubscript:
nonMaximumSuppression:output:withThreshold:
addObjectsFromArray:
intersectionOverUnion:b:
convertObjectDetections:cropRect:originalImageSize:output:
initWithData:timeOffset:width:height:
timeOffset
width
height
_width
_height
_timeOffset
generationFrequency
_generationFrequency
posterFramesInternal
input
nextGenerationTime
removeAllObjects
setNextGenerationTime:
saveAsPosterFrame:error:
setPosterFramesInternal:
_posterFramesInternal
_input
_nextGenerationTime
multiplier
setMultiplier:
_multiplier
framesInternal
opticalFlowReferenceImage
flowArray
setTotalNumberOfFramesInFragment:
setFrameWidth:
setFrameHeight:
setNumberFramesToSelect:
setNumberFramesToAdvance:
setCurrentFrameNumber:
setNextFrameToSelectForAnalysis:
getEnableOpticalFlowPreference
setEnableOpticalFlow:
numberFramesToSelect
enableOpticalFlow
getScaledFrameWidth
getScaledFrameHeight
minRows
minCols
maxRows
maxCols
connectedComponentsMap
quantizedFrames
framesScore
initWithCapacity:
setFlowArray:
totalNumberOfFramesInFragment
currentFrameNumber
setOpticalFlowReferenceImage:
initWithCVPixelBuffer:options:
initWithTargetedCVPixelBuffer:options:
setEnableFiltering:
performRequests:error:
results
computeFlowMagnitudeMatrixFromOriginal:error:
initWithMotionScore:pixelBufferUV:cropRect:
quantizedAndBinarizeFrame:frame_height:error:
connectedComponents
unionTheRegoins
allKeys
applyPaddingIndex:
valueForKeyPath:
indexOfObject:
nextFrameToSelectForAnalysis
numberFramesToAdvance
getScaleFactorWidth
getScaleFactorHeight
removeObjectForKey:
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
containsObject:
setFramesInternal:
setMinRows:
setMaxRows:
setMinCols:
setMaxCols:
setQuantizedFrames:
setConnectedComponentsMap:
setFramesScore:
_enableOpticalFlow
_numberFramesToAdvance
_nextFrameToSelectForAnalysis
_frames
_logIdentifier
_framesInternal
_totalNumberOfFramesInFragment
_currentFrameNumber
_numberFramesToSelect
_minRows
_maxRows
_minCols
_maxCols
_flowArray
_quantizedFrames
_connectedComponentsMap
_framesScore
_opticalFlowReferenceImage
dictionary
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
initWithDomain:code:userInfo:
hmiErrorWithCode:underlyingError:
hmiErrorWithCode:
hmiErrorWithCode:description:underlyingError:
hmiPrivateErrorWithCode:description:underlyingError:
resourceUsageMonitor
_resourceUsageMonitor
pixelBufferUV
_motionScoreForObjectRect:
initWithCropRect:motionScore:
initWithMotionScore:
isDetectedObjectStatic:
motionScore
setPixelBufferUV:
_motionScore
_pixelBufferUV
_movingObjectCropRect
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:
bytes
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:nominalFrameRate:naturalSize:
initWithAssetDuration:creationDate:
_firstSequenceNumber
_nominalFrameRate
_naturalSize
_assetDuration
initWithVideoFragment:workQueue:logIdentifier:
assetWithURL:
resourceLoader
resourceLoaderWorkQueue
setDelegate:queue:
initWithAsset:error:
setAssetReader:
assetKeys
_propertiesLoadedForAsset:resultCallback:
loadValuesAsynchronouslyForKeys:completionHandler:
fragments
lastObject
firstObject
statusOfValueForKey:error:
_didKeyValueLoadFailed:
tracksWithMediaType:
trackKeys
_propertiesLoadedForTrack:fromAsset:resultCallback:
timeRange
initWithTrack:outputSettings:
setAlwaysCopiesSampleData:
setMaximizePowerEfficiency:
addOutput:
startReading
_validateSequentialIntegrityOfFragmentsInAsset:
_sequenceNumberOfLastFragmentInAsset:
_sequenceNumberOfFirstFragmentInAsset:
dateValue
outputs
objectAtIndex:
copyNextSampleBuffer
currentFrameId
setCurrentFrameId:
finishLoadingWithError:
contentInformationRequest
setContentLength:
setContentType:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestsAllDataToEndOfResource
requestedLength
subdataWithRange:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
_currentFrameId
_resourceLoaderWorkQueue
decodeIntegerForKey:
decodeObjectOfClasses:forKey:
decodeObjectOfClass:forKey:
decodeCMTimeForKey:
decodeDoubleForKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeCMTime:forKey:
encodeDouble:forKey:
initWithCoder:
encodeWithCoder:
supportsSecureCoding
decodeBoolForKey:
encodeBool:forKey:
isEqualToData:
decodeIntForKey:
encodeInt:forKey:
decodeFloatForKey:
encodeFloat:forKey:
_finish
didAnalyzeFragment
didFailAnalysisForFragment
didFindSignificantEvent
didNotAnalyzeFragment
setDidAnalyzeFragment:
setDidFailAnalysisForFragment:
setDidNotAnalyzeFragment:
setDidFindSignificantEvent:
_didAnalyzeFragment
_didFailAnalysisForFragment
_didFindSignificantEvent
_didNotAnalyzeFragment
mapTableWithStrongToWeakObjects
nextRequestID
setNextRequestID:
runRemotely
removeAllPreferenceOverrides
addPreferenceOverrideFromDictionary:
UUID
getNextRequestID
requests
expectedClasses
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
cancelRequest:
_runRemotely
_nextRequestID
_requests
boolValue
preferenceOverridesInternal
addEntriesFromDictionary:
preferenceLoggedValues
initWithKey:options:domain:defaultValue:
value
systemPreferenceValueForKey:
logPreferenceForKey:value:
caseInsensitiveCompare:
numberPreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withMap:
stringPreferenceForKey:defaultValue:
_preferenceLoggedValues
_preferenceOverridesInternal
setNumberStyle:
numberFromString:
token
notificationName
publishValueForToken:
publishInitialValue
setToken:
callback
initWithNotificationName:andQueue:andCallback:
_token
_notificationName
_callback
stringByDeletingLastPathComponent
defaultManager
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
imageWithCVImageBuffer:
contextWithOptions:
pathExtension
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
classHierarchyMap
enumerateKeysAndObjectsUsingBlock:
setAnnotationScores:
setDetections:
significantActivityDetector
arrayWithArray:
transaction
setTransaction:
_significantActivityDetector
_transaction
initWithImage__Placeholder__0:
image__Placeholder__0
setImage__Placeholder__0:
_image__Placeholder__0
featureValueWithMultiArray:
initWithShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0:
ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
setShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0:
ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
setShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0:
_ShotNet__ShotNet__ssd_predictions__block8_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block8_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block7_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block7_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block6_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block6_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block9_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block9_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block10_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block10_box__box_offset__0
_ShotNet__ShotNet__ssd_predictions__block11_box__class_prob__0
_ShotNet__ShotNet__ssd_predictions__block11_box__box_offset__0
urlOfModelInThisBundle
initWithContentsOfURL:error:
modelWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
initWithConfiguration:error:
predictionFromImage__Placeholder__0:error:
predictionsFromInputs:options:error:
model
_model
@24@0:8@16
@16@0:8
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@32@0:8^{__CVBuffer=}16@24
v16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"NSString"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"HMFLogCategory"16@0:8
@40@0:8@16d24^@32
B40@0:8^{__CVBuffer=}16@24^@32
B48@0:8^{__CVBuffer=}16@24@32^@40
v40@0:8@16@24@32
{CGSize=dd}16@0:8
d16@0:8
[91d]
[6[6{CGSize="width"d"height"d}]]
[6Q]
@"MLModel"
@"NSArray"
@"MLPredictionOptions"
{CGSize="width"d"height"d}
v32@0:8@16@24
v32@0:8@"AVAssetWriter"16@"NSData"24
v40@0:8@"AVAssetWriter"16@"NSData"24@"AVFragmentedMediaDataReport"32
@40@0:8i16i20I24B28^@32
i16@0:8
v20@0:8i16
B48@0:8^{__CVBuffer=}16{?=qiIq}24
v24@0:8@?16
^{OpaqueVTCompressionSession=}16@0:8
^{OpaqueVTCompressionSession=}
@"AVAssetWriter"
@"AVAssetWriterInput"
@"NSMutableData"
@"HMFActivity"
q16@0:8
v24@0:8q16
v24@0:8@16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@80@0:8@16{?=qiIq}24Q48Q56{CGSize=dd}64
@28@0:8f16^{CGSize=dd}20
B40@0:8{CGSize=dd}16^@32
{?=qiIq}16@0:8
@"NSData"
@"HMICameraVideoFrameMotionAnalysisResult"
{?="value"q"timescale"i"flags"I"epoch"q}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56^@72
i40@0:8Q16Q24^^{__CVBuffer}32
@24@0:8Q16
f16@0:8
v20@0:8f16
v24@0:8Q16
@"HMFUnfairLock"
@"NSMutableArray"
@96@0:8q16@24@32@40{?=qiIq}48@72q80Q88
@80@0:8q16@24@32@40{?=qiIq}48@72
@72@0:8q16@24@32{?=qiIq}40@64
B28@0:8@16B24
v40@0:8{?=qiIq}16
v24@0:8d16
@"NSDictionary"
@"NSDate"
@"HMICameraVideoFragment"
@24@0:8^{_NSZone=}16
@48@0:8Q16Q24d32d40
v20@0:8B16
@32@0:8q16@24
@"HMICameraVideoFrame"
@64@0:8Q16q24@32@40Q48Q56
@40@0:8Q16@24@32
@48@0:8Q16@24@32q40
@40@0:8Q16@24q32
@48@0:8Q16@24q32@40
@"NSURL"
@"HMICameraVideoAnalyzerRequest"
@40@0:8@16@24d32
B24@0:8^@16
B32@0:8Q16Q24
B32@0:8@16@24
@24@0:8q16
@"HMICameraVideoResourceAttributes"
@"HMICameraVideoEncoderSession"
@"HMICameraVideoPosterFrameGenerator"
@"HMICameraVideoFrameSelector"
@"HMICameraVideoAssetReader"
@"HMICameraVideoAnalyzer"
@"HMICameraVideoAnalyzerRequestLog"
v24@0:8@"HMFTimer"16
@"HMFTimer"
@"NSPointerArray"
@"HMISystemResourceUsageMonitor"
@"MovingAverage"
@"HMICameraVideoFPSSelector"
@32@0:8@16@24
v28@0:8@16B24
v32@0:8@16q24
v40@0:8@16q24@32
v32@0:8q16@24
v40@0:8q16@24@32
v48@0:8q16@24@32@40
B32@0:8@16^q24
@32@0:8@16^@24
B48@0:8@16@24^@32^q40
B40@0:8@16@24^@32
q24@0:8q16
@"<HMICameraVideoAnalyzerDelegate>"
@"NSUUID"
@"HMICameraVideoAnalyzerScheduler"
@"HMICameraVideoAnalyzerConfiguration"
@"HMIAnalysisService"
@32@0:8@16d24
@"<HMICameraVideoFrameAnalyzer>"
@60@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v40@0:8@16@24d32
v80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56@72
@64@0:8@16{?=qiIq}24Q48Q56
@48@0:8{?=qiIq}16Q40
B32@0:8@16^@24
@"HMICameraVideoPosterFrameGeneratorInput"
d64@0:8d16d24{?=qiIq}32q56
@32@0:8d16@24
v48@0:8@16Q24Q32Q40
f32@0:8^{__CVBuffer=}16^@24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8Q16Q24^@32
^f16@0:8
v24@0:8^f16
v24@0:8^{__CVBuffer=}16
@"NSMutableDictionary"
@56@0:8Q16@24@32@40@48
@40@0:8q16@24@32
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
@20@0:8f16
@60@0:8f16^{__CVBuffer=}20{CGRect={CGPoint=dd}{CGSize=dd}}28
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@64@0:8{?=qiIq}16@40Q48Q56
@48@0:8{?=qiIq}16@40
@88@0:8{?=qiIq}16@40Q48Q56d64{CGSize=dd}72
@40@0:8@16@24@32
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
Q24@0:8@16
v32@0:8@16@?24
v40@0:8@16@24@?32
B32@0:8^@16^@24
@"AVAssetReader"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"HMICameraVideoAnalyzerResult"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoAnalyzerSignificantEvent"24@"HMICameraVideoFragment"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"NSError"32
@?16@0:8
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
B20@0:8i16
@"NSMapTable"
@40@0:8@16@24@?32
@40@0:8r*16@24@?32
r*16@0:8
@40@0:8^{NSDictionary=#}16d24^@32
B32@0:8@"HMICameraVideoFrame"16^@24
@"NSDictionary"16@0:8
@"NSArray"16@0:8
@"HMISignificantActivityDetector"
@"HMFOSTransaction"
@112@0:8@16@24@32@40@48@56@64@72@80@88@96@104
@"MLMultiArray"
@40@0:8@16@24^@32
@32@0:8^{__CVBuffer=}16^@24
