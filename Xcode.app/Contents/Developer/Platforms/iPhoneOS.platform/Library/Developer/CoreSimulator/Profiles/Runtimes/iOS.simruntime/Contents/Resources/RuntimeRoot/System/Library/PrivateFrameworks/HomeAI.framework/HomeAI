@(#)PROGRAM:HomeAI  PROJECT:HomeAI-284
q@#B
Mb@?
UsesIOSurface
HardwareAcceleratedTransfer
HighSpeedTransfer
HMIPixelBufferTransferMultiStageResize
?a0cTa1cTa2cTa3cTa0hTa1hTa2hTa3hT
r@ffffff
N6homeai3mod28ImageDescriptorBufferFloat32E
N6homeai10clustering15GreedyClustererE
NSt3__120__shared_ptr_emplaceINS_6vectorIxNS_9allocatorIxEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6homeai10clustering15GreedyClusterer9cluster_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_5tupleIJxxfEEENS_9allocatorIS3_EEEENS4_IS6_EEEE
N6homeai3mod29ImageDescriptorBufferAbstractE
?ffffff
ffffff
>NSt3__120__shared_ptr_emplaceIN6homeai10clustering15GreedyClustererENS_9allocatorIS3_EEEE
MbP?
W>333?
Motion
Person
Vehicle
Package
?fff?
N2cv13BaseRowFilterE
N2cv16BaseColumnFilterE
N2cv10BaseFilterE
N2cv12FilterEngineE
N2cv18SymmRowSmallFilterIhiNS_21SymmRowSmallVec_8u32sEEE
N2cv9RowFilterIhiNS_21SymmRowSmallVec_8u32sEEE
N2cv18SymmRowSmallFilterIffNS_19SymmRowSmallVec_32fEEE
N2cv9RowFilterIffNS_19SymmRowSmallVec_32fEEE
N2cv9RowFilterIhiNS_12RowVec_8u32sEEE
N2cv9RowFilterIhfNS_8RowNoVecEEE
N2cv9RowFilterIhdNS_8RowNoVecEEE
N2cv9RowFilterItfNS_8RowNoVecEEE
N2cv9RowFilterItdNS_8RowNoVecEEE
N2cv9RowFilterIsfNS_13RowVec_16s32fEEE
N2cv9RowFilterIsdNS_8RowNoVecEEE
N2cv9RowFilterIffNS_10RowVec_32fEEE
N2cv9RowFilterIfdNS_8RowNoVecEEE
N2cv9RowFilterIddNS_8RowNoVecEEE
N2cv12ColumnFilterINS_13FixedPtCastExIihEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIffEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
N2cv21SymmColumnSmallFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv16SymmColumnFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv12ColumnFilterINS_13FixedPtCastExIihEENS_19SymmColumnVec_32s8uEEE
N2cv21SymmColumnSmallFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv12ColumnFilterINS_4CastIisEENS_25SymmColumnSmallVec_32s16sEEE
N2cv21SymmColumnSmallFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv12ColumnFilterINS_4CastIffEENS_22SymmColumnSmallVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIfsEENS_20SymmColumnVec_32f16sEEE
N2cv12ColumnFilterINS_4CastIfsEENS_20SymmColumnVec_32f16sEEE
N2cv16SymmColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_17SymmColumnVec_32fEEE
N2cv12ColumnFilterINS_4CastIffEENS_17SymmColumnVec_32fEEE
N2cv16SymmColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
N2cv8Filter2DIhNS_4CastIfhEENS_12FilterVec_8uEEE
N2cv8Filter2DIhNS_4CastIftEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIfsEENS_15FilterVec_8u16sEEE
N2cv8Filter2DIhNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIftEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIfsEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DIfNS_4CastIffEENS_13FilterVec_32fEEE
N2cv8Filter2DIdNS_4CastIddEENS_11FilterNoVecEEE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
ucwsifdr
?qxs?qxs
9D)5:
@`|-A
PF SdF
 [@W:[
D]eV
"x@
z4I5z
?~my
!Y?4
!I?u
!)?gX
?g^FT
?$"LT
?$"LT
N2cv15ThresholdRunnerE
4N2cv6detail16LKTrackerInvokerE
N2cv9ColumnSumIihEE
N2cv9ColumnSumIitEE
N2cv9ColumnSumIisEE
N2cv6RowSumIhiEE
N2cv6RowSumIhdEE
N2cv6RowSumItiEE
N2cv6RowSumItdEE
N2cv6RowSumIsiEE
N2cv6RowSumIiiEE
N2cv6RowSumIsdEE
N2cv6RowSumIfdEE
N2cv6RowSumIddEE
N2cv9ColumnSumIdhEE
N2cv9ColumnSumIdtEE
N2cv9ColumnSumIdsEE
N2cv9ColumnSumIiiEE
N2cv9ColumnSumIifEE
N2cv9ColumnSumIdfEE
N2cv9ColumnSumIidEE
N2cv9ColumnSumIddEE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
N2cv11_InputArrayE
N2cv12_OutputArrayE
N2cv9ExceptionE
14EmptyFuncTable
12GpuFuncTable
N2cv16ParallelLoopBodyE
@N2cv16MorphologyRunnerE
N2cv14MorphRowFilterINS_5MinOpIhEENS_12MorphRowIVecINS_6VMin8uEEEEE
N2cv14MorphRowFilterINS_5MinOpItEENS_12MorphRowIVecINS_7VMin16uEEEEE
N2cv14MorphRowFilterINS_5MinOpIsEENS_12MorphRowIVecINS_7VMin16sEEEEE
N2cv14MorphRowFilterINS_5MinOpIfEENS_12MorphRowFVecINS_7VMin32fEEEEE
N2cv14MorphRowFilterINS_5MinOpIdEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIhEENS_12MorphRowIVecINS_6VMax8uEEEEE
N2cv14MorphRowFilterINS_5MaxOpItEENS_12MorphRowIVecINS_7VMax16uEEEEE
N2cv14MorphRowFilterINS_5MaxOpIsEENS_12MorphRowIVecINS_7VMax16sEEEEE
N2cv14MorphRowFilterINS_5MaxOpIfEENS_12MorphRowFVecINS_7VMax32fEEEEE
N2cv14MorphRowFilterINS_5MaxOpIdEENS_13MorphRowNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIhEENS_15MorphColumnIVecINS_6VMin8uEEEEE
N2cv17MorphColumnFilterINS_5MinOpItEENS_15MorphColumnIVecINS_7VMin16uEEEEE
N2cv17MorphColumnFilterINS_5MinOpIsEENS_15MorphColumnIVecINS_7VMin16sEEEEE
N2cv17MorphColumnFilterINS_5MinOpIfEENS_15MorphColumnFVecINS_7VMin32fEEEEE
N2cv17MorphColumnFilterINS_5MinOpIdEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIhEENS_15MorphColumnIVecINS_6VMax8uEEEEE
N2cv17MorphColumnFilterINS_5MaxOpItEENS_15MorphColumnIVecINS_7VMax16uEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIsEENS_15MorphColumnIVecINS_7VMax16sEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIfEENS_15MorphColumnFVecINS_7VMax32fEEEEE
N2cv17MorphColumnFilterINS_5MaxOpIdEENS_16MorphColumnNoVecEEE
N2cv11MorphFilterINS_5MinOpIhEENS_9MorphIVecINS_6VMin8uEEEEE
N2cv11MorphFilterINS_5MinOpItEENS_9MorphIVecINS_7VMin16uEEEEE
N2cv11MorphFilterINS_5MinOpIsEENS_9MorphIVecINS_7VMin16sEEEEE
N2cv11MorphFilterINS_5MinOpIfEENS_9MorphFVecINS_7VMin32fEEEEE
N2cv11MorphFilterINS_5MinOpIdEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIhEENS_9MorphIVecINS_6VMax8uEEEEE
N2cv11MorphFilterINS_5MaxOpItEENS_9MorphIVecINS_7VMax16uEEEEE
N2cv11MorphFilterINS_5MaxOpIsEENS_9MorphIVecINS_7VMax16sEEEEE
N2cv11MorphFilterINS_5MaxOpIfEENS_9MorphFVecINS_7VMax32fEEEEE
N2cv11MorphFilterINS_5MaxOpIdEENS_10MorphNoVecEEE
?N2cv5MatOpE
N2cv14MatOp_IdentityE
N2cv11MatOp_AddExE
N2cv9MatOp_BinE
N2cv9MatOp_CmpE
N2cv10MatOp_GEMME
N2cv12MatOp_InvertE
N2cv7MatOp_TE
N2cv11MatOp_SolveE
N2cv17MatOp_InitializerE
Error creating directory for person:%@
version
UUID
displayName
person.json
Error saving metadata to disk for person:%@
v8@?0
Error creating directory for person face crop:%@
faceBoundingBox
dateCreated
facecrop.json
Error saving metadata to disk for person face crop:%@
facecrop.jpeg
Error saving face crop image to disk for person face crop:%@
#ffffff
#000000
</body>
</html>
Visualizer saved (%@)
HMIHTMLReport
<html>
<head><title>%@</title></head>
<style>
</style>
<body text='%@' bgcolor='%@'>
<script>
</script>
%@<br>
border:%dpx;
border:%dpx solid %@;
outline:%dpx;
outline:%dpx solid %@;
<div class='image'>
<img width='%d' height='%d' src='data:image/jpeg;base64,%@' style='%@'/>
<div class='rect' style='top:%dpx; left:%dpx; width:%dpx; height:%dpx; border-color:%@; opacity:%.1f' threshold='%.3f'>%@</div>
v32@?0@"HMIHTMLReportBox"8Q16^B24
<div class="text">%@</div>
</div>
%.3fs
v16@?0@"HMIVideoAnalyzerFrameResult"8
@"NSValue"16@?0@"HMIVideoAnalyzerFrameResult"8
[%lu/%lu] %@ (%.2fs)
v32@?0@"HMIVideoFrame"8Q16^B24
v16@?0@"NSArray"8
v24@?0@"HMIVideoAnalyzerEvent"8^B16
confidence.value
v16@?0@"HMIVideoAnalyzerEvent"8
%.3f %@
%.3f
%.3f %@ %.2f %@
#ffff00
B16@?0@"HMITorsoprint"8
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
FaceFilteredState
HMIVAEF.fr
HMIVAEF.ta
HMIVAEF.ya
HMIVAEF.ro
None
QualitySVMKnown
QualitySVMUnknown
QualityANFRScore
NoPredictions
HasFaceMask
Face Recognition
Torso Annotation
Face Yaw
Face Roll
%@@(%@,%@)
v16@?0@"NSError"8
%c%c%c%c
Type: %@, DTS: %@, PTS: %@, DUR: %@, NUM: %ld [%@]
Sync
%c%02d:%02d:%02d.%03d
%*lld/%-6d %@
%*lld %@
POSITIVE INFINITY
NEGATIVE INFINITY
   INDEFINITE    
  INVALID TIME   
%@ DTS %@ PTS %@ dur %@%@
PTS: %.2f
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss
%.3f x %.3f
%.3f, %.3f %@
%.2f
%02x
q24@?0@"<HMIVideoEvent>"8@"<HMIVideoEvent>"16
B32@?0@"<HMIVideoEvent>"8Q16^B24
@16@?0@"<HMIVideoEvent>"8
Time: %@, Date: %@
HMIVAEM.ms
Motion score
%@@(%@)
Failed to set request revision
failed to perform image request
Expected 1 torsoprint, but got %lu torsoprints
torsoprint is nil
HMICoreAnalyticsVIPModelReportTime
v24@?0@"HMIHomePersonManagerSettings"8@"NSError"16
v24@?0@"NSDictionary"8@"NSError"16
B16@?0@"HMIFaceClassification"8
UUID:%@ HomeUUID:%@
Frame %lu @ %@
Logi Circle 2
%#{flags}
transferPixelBuffer
VTPixelTransferSessionCreate failed. Error %d
VTSessionSetProperty failed. Error %d
VTPixelTransferSessionTransferImage failed. Error %d
JPEGDataFromPixelBuffer
Invalid crop for affine transform
Error in pixelbuffer format for affine transform
Error generating pixelbuffer for affine transform
Error applying affine transform
q24@?0@"HMIPairwiseMatch"8@"HMIPairwiseMatch"16
v12@?0i8
/private/var
OutOfMemory
Reached high water mark.
HMIThermalPressureLevelNominal
HMIThermalPressureLevelLight
HMIThermalPressureLevelModerate
HMIThermalPressureLevelHeavy
HMIThermalPressureLevelTrapping
HMIThermalPressureLevelSleeping
HMIThermalPressureLevelUnknown
HMIThermalPressureLevelDidChangeNotification
PrimaryUsagePage
PrimaryUsage
LocationID
image_Placeholder
HomeSSD_box0_offset0
HomeSSD_box0_offset1
HomeSSD_box0_offset2
HomeSSD_box0_offset3
HomeSSD_box0_offset4
HomeSSD_box1_offset0
HomeSSD_box1_offset1
HomeSSD_box1_offset2
HomeSSD_box1_offset3
HomeSSD_box1_offset4
HomeSSD_class_prob0
HomeSSD_class_prob1
HomeSSD_class_prob2
HomeSSD_class_prob3
HomeSSD_class_prob4
HomeSSD_object_yaw0
HomeSSD_object_yaw1
HomeSSD_object_yaw2
HomeSSD_object_yaw3
HomeSSD_object_yaw4
HomeSSD_object_roll0
HomeSSD_object_roll1
HomeSSD_object_roll2
HomeSSD_object_roll3
HomeSSD_object_roll4
SignificantActivityFcosDetector
CoreML output nil or not of type MLFeatureTypeMultiArray
SignificantActivityFcos
mlmodelc
name
VeryLongTrackDuration
discussion
Track %@ has an unexpectedly long track duration %@.
v16@?0@"AVAssetTrack"8
WidelyDifferingTrackDurations
Track durations vary widely, this is usually caused by a corrupt video / audio sample duration.
v16@?0@"NSDictionary"8
Sanitized Data
Asset Check
HMIHomeKitClient HomeKit Delegate Queue
B16@?0@"HMHome"8
B16@?0@"HMResidentDevice"8
B16@?0@"HMCameraProfile"8
v16@?0@"HMHomeManager"8
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
%@ (%@)
input
transformed_features
classProbability
FaceRecognizabilityFilterSVM
FaceRecognizabilityFilterSVMDataScaler
FaceAestheticQualityFilterSVM
FaceAestheticQualityFilterSVMDataScaler
You must override %@ in a subclass
@16@?0@"HMPerson"8
v24@?0@"NSSet"8@"NSError"16
@16@?0@"HMPersonFaceCrop"8
@16@?0@"HMFaceprint"8
@16@?0@"HMIFaceprint"8
com.apple.cvml.%@
CVML module = %@
HMIFC.ck.pu
HMIFC.ck.so
Unknown
PhotoLibrary
User
ImpureClusteringCleanup
Unknown source: %ld
dataRepresentation
personUUID
Person UUID
Source
frame
Frame
Events
Region of Interest
B16@?0@"HMIVideoAnalyzerEvent"8
@16@?0#8
q24@?0@"HMIVideoAnalyzerFrameResult"8@"HMIVideoAnalyzerFrameResult"16
CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange || CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange
v16@?0@"HMIVideoAnalyzerTrack"8
{CGRect={CGPoint=dd}{CGSize=dd}}
v16@?0@"HMIMotionVector"8
B16@?0@"HMIVideoAnalyzerBlob"8
v32@?0@"HMIVideoAnalyzerBlob"8Q16^B24
v32@?0@"HMIVideoAnalyzerTrack"8Q16^B24
v16@?0@"HMIPairwiseMatch"8
v24@?0Q8^B16
B16@?0@"HMIVideoAnalyzerTrack"8
B16@?0@"NSValue"8
CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange
hmi://in-memory
HMIMemoryAVAsset
tracks
Invalid parameter for windowSize: %lu, windowSize must be > 0
v16@?0@"MovingAverageEntry"8
@16@?0@"HMIVideoAnalyzerEvent"8
class
timestamp
uuid
v32@?0@"NSArray"8Q16^B24
@16@?0@"NSDictionary"8
v16@?0@"HMIVideoAnnotationParserTrack"8
{CGRect={CGPoint=dd}{CGSize=dd}}80@?0{CGRect={CGPoint=dd}{CGSize=dd}}8{CGRect={CGPoint=dd}{CGSize=dd}}40f72f76
@16@?0@"HMIVideoAnnotationParserTrack"8
@16@?0@"HMIPersonsModelPrediction"8
detections
bounds
label
confidence
filters
v16@?0@8
com.apple.HomeAIDESPlugin
v24@?0@"NSUUID"8@"NSError"16
bias_b
bias_g
bias_r
is_network_bgr
scale
Label:%d Confidence:%f X:%f Y:%f Width:%f Height:%f Yaw:%@}
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
@16@?0@"HMIObjectDetection"8
PersonBlob(PTS:%.2f): %@ (%@%@%@%@)
@"HMIPersonBlob"16@?0@"HMIVideoAnalyzerEventPerson"8
@16@?0@"HMIVideoAnalyzerEventPerson"8
@16@?0@"HMIPersonBlob"8
v32@?0@"HMIPersonBlob"8Q16^B24
v24@?0@"NSNumber"8@"NSNumber"16
<%@: %p> timeStamp: %@, detections: [%@], regionOfInterest: %@
<%@: %p> %@
self.dynamicConfiguration
@16@?0@"HMIVideoAnalyzerTrack"8
@max.floatValue
@16@?0@"HMIVideoAnalyzerReportRecord"8
@sum.count
Precision
Recall
True Positive
False Negative
False Positive
Fragments
v16@?0@"HMIVideoAnalyzerFragmentResult"8
v24@?0@"NSString"8@"HMIVideoAnalyzerMutableReportSession"16
v16@?0#8
@"HMIVideoAnalyzerMutableReportComparison"20@?0#8f16
precision
recall
threshold
annotation
opacity
/System/Library/CoreServices/SystemVersion.plist
com.apple.HomeAI
HomeAIBundleVersion
Debug
Truth
image_id
B16@?0@"NSDictionary"8
classification_classes
@16@?0@"NSString"8
@24@?0@"NSString"8@"HMIVideoAnalyzerMutableReportSession"16
f56@?0@"HMIVideoAnalyzerEvent"8@"HMIVideoAnalyzerEvent"16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"NSArray"16@?0@"HMIVideoAnalyzerEvent"8
@24@?0@"NSNumber"8@"NSNumber"16
@16@?0@"NSNumber"8
v32@?0@"HMIVideoAnalyzerFrameResult"8Q16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
v16@?0@"NSNumber"8
score
%@%@
Object detection (%@)
Visualize%@.html
%lu %@s (Precision: %.3f, Recall: %.3f)
v16@?0@"HMIVideoAnalyzerReportRecord"8
@"NSValue"16@?0@"HMIVideoFrame"8
@16@?0@"HMIVideoFrame"8
q24@?0@"NSString"8@"NSString"16
Fragment%@%@.txt
v24@?0@"NSString"8@"NSArray"16
PRArray.json
domain
range
@24@?0@"NSString"8@"NSString"16
'%@': '%@'
{%@}[datum.label]
labelExpr
$schema
https://vega.github.io/schema/vega-lite/v4.json
description
PR Curves
width
container
height
config
style
align
center
baseline
layer
mark
type
line
clip
true
point
encoding
field
quantitative
nominal
legend
text
left
%@_%.0f_%@_%lu.png
v32@?0@"HMIVideoAnalyzerEvent"8Q16^B24
v16@?0@"HMIVideoAnalyzerReportMatch"8
v32@?0@"NSUUID"8@"HMIVideoAnalyzerEventPerson"16^B24
HMIFC.ck.u
HMIFC.ck.dr
HMIFC.ck.dc
HMIFC.ck.fbb
Data Representation
Date Created
Face Bounding Box
mediaType == kCMMediaType_Video
Descriptor count = 
Descriptor length = 
 bytes
 = [
identifier
Identifier
Name
Manufacturer
Model
Firmware Version
Descriptor vectors nil
Success
Canceled
Error
UpdatePersonsModelTask
RemovePersonsModelTask
HomePersonClusteringTask
FaceMisclassificationTask
PersonsModelsSummaryTask
UpdateTorsoModelTask
FeedbackTask
EmptyTask
resultCode
taskType
faceCrop
sourceUUID
homeUUID
isExternal
doImpurePersonCleanup
cameraProfileUUID
clipUUID
torsoAnnotations
duration
Unknown task type: %@
v16@?0d8
v32@?0@"HMITask"8Q16^B24
HMITaskHomeUUIDKey is nil
HMIUpdatePersonsModelTaskIsExternal is nil
HMIPersonsModelTaskSourceUUID is nil
Failed to get HMPhotosPersonManager
Failed to get HMHomePersonManager
Failed to initialize data source
Disk-based Home Person Data Source not supported
HomeUUID is nil
cleanup key is missing
HMIUpdateTorsoModelTaskAnnotationsKey is nil
HMIEmptyTaskDurationKey is nil
HMITaskService not available on this platform.
HMITR.c
HMITR.tp
HMITR.sea
HMITR.seu
v16@?0@"HMIFaceprint"8
warm_start_faceprint_model
CreateFaceprint
B16@?0@"HMIFaceprint"8
HMIFP.ck.u
HMIFP.ck.d
HMIFP.ck.mu
HMIFP.ck.fcu
modelUUID
faceCropUUID
Data
Model UUID
Face Crop UUID
cameraName
cameraUUID
roomName
nightVision
currentHorizontalTilt
currentVerticalTilt
opticalZoom
digitalZoom
imageRotation
imageMirroring
model
manufacturer
firmwareVersion
@16@?0@"HMCameraClipSignificantEvent"8
timeOffsetWithinClip
dateOfOccurrence
confidenceLevel
reason
startDate
quality
significantEvents
<%0.3f %0.3f>
HMPMS.fce
Face Classification Enabled
faceCrops
authTag
internal
wrappedKey
1.2.840.113635.100.6.27.38
HMIFeedback Queue
hkcvml.apple.com
hkcvml-dev.apple.com
HFFeedbackService
camera.recording.feedback
Cannot find camera profile.
Cannot find home for camera profile.
Cannot download clip asset.
Check network connectivity.
v24@?0@"HMCameraClipVideoAssetContext"8@"NSError"16
v16@?0Q8
v16@?0@"HMCameraClip"8
Cannot download clip for camera profile.
Ensure the clip belongs to the camera profile.
v24@?0@"HMCameraClip"8@"NSError"16
Unable to blur faces.
Unable to read the asset from disk.
Clip doesn't have a video track.
https://%@/v2/clip-uuid/
feedback
%@.%@
json
application/json
Content-Type
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
Invalid key size.
Cannot generate initialization vector.
Failed to encrypt data.
Failed to encrypt face crop data.
v24@?0@"NSURL"8@"NSError"16
Status Code:400, Error: Resource not found on server error
Status Code:500, Error: Internal server error
Unkown server error
v16@?0@"NSURL"8
HMIFC.pu
HMIFC.su
HMIFC.seu
HMIFC.fc
HMIFC.fp
HMIFC.c
HMIFC.ftc
HMIFC.f
Known
Uncertain
Source UUID
Session Entity UUID
Confidence
Familiarity
FaceCrop UUID
Faceprint UUID
FromTorsoClassification
@"NSUUID"16@?0@"HMIPerson"8
@"NSUUID"16@?0@"HMIPersonFaceCrop"8
v16@?0@"NSSet"8
@"NSUUID"16@?0@"HMIFaceCrop"8
Invalid person UUIDs
v32@?0@"HMIPerson"8@"NSSet"16^B24
B16@?0@"HMIPerson"8
Not implemented
Invalid persons, person already exists
v16@?0@"HMIPerson"8
Invalid faceCropUUIDs
B16@?0@"HMIPersonFaceCrop"8
Invalid persons, person UUID doesn't exists
Invalid personUUID
@"HMIPersonFaceCrop"16@?0@"HMIFaceCrop"8
B16@?0@"HMIFaceCrop"8
@"HMIPersonFaceCrop"16@?0@"HMIPersonFaceCrop"8
NOT IMPLEMENTED
@16@?0@"HMIPersonFaceCrop"8
SourceUUID:%@ HomeUUID:%@
v24@?0@"HMIVideoDecoder"8^{opaqueCMSampleBuffer=}16
Medium
High
%.4f
%.2f[%c]
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to read fragment
Failed to verify fragment
Failed to transcode fragment
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToReadFragment
HMIErrorCodeFailedToVerifyFragment
HMIErrorcodeFailedToTranscodeFragment
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodeCodecNotAvailable
HMIPrivateErrorCodeEncodingFailed
HMIPrivateErrorCodeInvalidVideoFrameFormatToSave
HMIPrivateErrorCodeScalerError
HMIPrivateErrorCodeFaceprintingFailed
HMIPrivateErrorCodeUpdatePersonsModelTaskFailed
HMIPrivateErrorCodeExternalPersonSourceDiskError
HMIPrivateErrorCodeLoadPersonsModelsFailed
HMIPrivateErrorCodeUpdatePersonsModelFailed
HMIPrivateErrorCodeRemovePersonsModelFailed
HMIPrivateErrorCodePersonsModelPredictionFailed
HMIPrivateErrorCodeNilDataSource
HMIPrivateErrorCodeUnknownTask
HMIPrivateErrorCodeHomePersonClusteringTaskFailed
HMIPrivateErrorCodeRemovePersonsModelTaskFailed
HMIPrivateErrorCodeFaceMisclassificationTaskFailed
HMIPrivateErrorCodePersonsModelsSummaryTaskFailed
HMIPrivateErrorCodeCleanupImpureHomePersonsOperationFailed
HMIPrivateErrorCodeFeedbackServiceInternalServerError
HMIPrivateErrorCodeFeedbackServiceResourceNotFoundError
ERROR_%ld
fragments.count >= 1
[first isCombinableWithFragment:fragment]
v16@?0@"HMIVideoFragment"8
B28@?0I8@"NSData"12@"NSData"20
v12@?0I8
video/mp4
first
second
[%@]
Initialization Segment Data
Separable Segment Data
Sequence Numbers
Time Range
First Video Sample Byte Range
v16@?0@"HMIVideoAnalyzerEventPerson"8
v32@?0@"HMIVideoAnalyzerEventPerson"8Q16^B24
v24@?0@"NSUUID"8@"HMIMutableCluster"16
(faceRecognition != nil) || (torsoRecognition != nil)
v16@?0@"NSUUID"8
v16@?0@"HMITorsoprint"8
@16@?0@"HMIFaceClassification"8
HMIASU.ck.ta
Torso Annotations
B16@?0@"HMITorsoAnnotation"8
@"HMITorsoAnnotation"16@?0@"HMIVideoAnalyzerEventFace"8
v16@?0@"HMIPoint"8
HMIPSUP.ck.p
HMIPSUP.ck.s
HMIP.ck.u
HMIP.ck.n
HMIP.ck.pl
personLinks
@"HMIPersonSourceUUIDPair"16@?0@"HMPersonLink"8
v16@?0@"<NSObject><NSCopying><NSSecureCoding>"8
data:;base64,%@
@16@?0@8
@24@?0@8@16
%.6f
data:;base64,
Invalid JSONObject class name: %@
Invalid JSONObject: %@
Cannot parse JSON data: %@
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
could not create image ref
Error creating directory:%@ to save face classifications
faceprintUUID
%@-%03lu-%03u-%@-%@-%@
known
unknown
Error saving metadata to disk for face classification:%@
Error saving face crop image to disk for face classification:%@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
faceCropDimensionsFromFaceCrop failed:%@
Could not create image source
No meta data exists on image
HMITP.ck.u
HMITP.ck.d
HMITP.ck.lq
HMITP.ck.ur
Bad Torso
ROI Boundary
HMITA.ck.fr
HMITA.ck.tps
HMITA.ck.tmv
faceRecognition
torsoprints
Torsoprints
TorsoModelVersion
HMIVideoEncoderWorkQueue
self.session == NULL
VTCompressionSessionCreate failed, err: %d
VTCompressionSessionPrepareToEncodeFrames failed, err: %d
Video encoding failed, err: %d
self.session
v24@?0i8I12^{opaqueCMSampleBuffer=}16
VTCompressionSessionEncodeFrameWithOutputHandler failed, err: %d
%@ is unavailable
@16@?0@"HMIFaceCrop"8
@16@?0@"HMIPerson"8
@16@?0@"HMFaceCrop"8
source != HMIPersonFaceCropSourceUnknown
HMPMS.ifple
HMPMS.sfce
Importing From Photo Library Enabled
Sharing Face Classifications Enabled
cameraManufacturer
cameraModel
recognitionType
face
torso
com.apple.HomeAI.PersonRecognitionEvent
@"NSMutableDictionary"8@?0
detectionScore
faceFilteredState
homeFamiliarity
v16@?0@"HMIFaceClassification"8
q24@?0@"NSNumber"8@"NSNumber"16
externalFamiliarity
sessionEntityAssignment
com.apple.HomeAI.FaceEvent
faceprintsClustered
clusters
personsCreated
faceprintsAssociated
faceprintingDuration
clusteringDuration
totalDuration
errorCode
errorDescription
com.apple.HomeAI.FaceClustering
v24@?0@"NSString"8@"NSNumber"16
v16@?0@"HMIPersonsModelSummary"8
@avg.self
externalLibraries
homeIdentities
averageExternalIdentities
averageHomeFaceCrops
averageExternalFaceCrops
homeToExternal
externalToExternal
com.apple.HomeAI.PersonsModels
@"NSDictionary"8@?0
B16@?0@"NSNumber"8
inclusion
exclusion
com.apple.HomeAI.MotionScore
zoneType
motionScore
com.apple.HomeAI.VideoAnalyzer.DidTerminate_v0
Fail
error
underlyingError
timeSinceAnalyzerStarted
com.apple.HomeAI.VideoAnalyzer.DidCreateTimelapseFragment_v0
bitrate
com.apple.HomeAI.VideoAnalyzer.DidAnalyzeFragment_v3
recognizeFaces
%@Trigger
%@Found
v32@?0@"NSString"8q16#24
motion
person
vehicle
package
transcode
analysisQuality
sequenceNumber
com.apple.HomeAI.VideoPackageAnalyzer.DidClassify_v0
com.apple.HomeAI.VideoPackageAnalyzer.DidReset_v0
interval
personsmodels
home
external
torso.bin
torso_to_facecrop.bin
torsoprinter_version.bin
user_defined_person_links.bin
v32@?0@"NSUUID"8@"HMIPersonsModel"16^B24
Error adding faceprints to model for personUUID: %@
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8@"NSArray"16^B24
Failed to remove stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to remove stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@
Failed to persist VNPersonsModel for homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to persist VNPersonsModel for homeUUID: %@ sourceUUID: %@, path: %@
Failed to remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, path: %@
Home persons model not found for homeUUID: %@
Failed to predict using VNPersonsModel for home persons model
Unable to get person model for homeUUID: %@ (self.personsModelsByHome is %@ nil)
Failed to predict using VNPersonsModel for homeUUID: %@ sourceUUID: %@
 not
v24@?0@"HMIPersonSourceUUIDPair"8^B16
v32@?0@"NSSet"8@"HMIPersonsModelPrediction"16^B24
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
v24@?0@"HMIFaceClassification"8^B16
@"VNFaceObservation"16@?0@"HMITorsoprint"8
v16@?0@"HMITorsoAnnotation"8
v16@?0@"HMIFaceCrop"8
Failed to predict using torso model for homeUUID: %@
@16@?0@"HMIPersonSourceUUIDPair"8
%@.bin
Directory to load/store persons models (%@) does not exist
Failed to enumerate persons models at path (%@)
\A[A-F0-9]{8}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{12}\.bin\Z
B16@?0@"NSURL"8
Failed to enumerate homes at path: %@
Directory to load/store home persons model (%@) contains multiples files: %@ there can only be one
Invalid file path in load model attempt: %@
Refusing to load %@ VNPersonsModel at path: %@
Failed to load VNPersonsModel at path: %@
@24@?0@"NSUUID"8@"HMIPersonsModel"16
v32@?0@"HMIPersonSourceUUIDPair"8@"NSSet"16^B24
v16@?0@"HMIDESLayerParameters"8
is_training
checkpoint
Loss/total_loss
B32@?0Q8@"<ETDataProvider>"16@"<ETTaskContext>"24
/tmp/train.espresso.net
Unknown reason.
Skipped
{code: %@, analysisFPS: %f, message: "%@"}
{code: %@, analysisFPS: %f}
v24@?0@"HMIExternalPersonManagerSettings"8@"NSError"16
@16@?0@"HMIVideoAnalyzer"8
@16@?0@"HMIVideoAnalyzerState"8
v16@?0@"HMIVideoAnalyzerConfiguration"8
v32@?0@"HMIVideoAnalyzer"8Q16^B24
Undefined
mediaserverd
homed
v16@?0@"HMIVideoAnalyzer"8
Scheduler state: 
usage: %@
, idle: %@
, %@: (%llu MB | %llu MB)
, mediaserverd: (%llu MB | %llu MB)
, homed: (%llu MB | %llu MB)
, thermalLevel: %lu
, peakPowerPressureLevel: %lu
, build: %@
Release
, maxConcurrentAnalyzers: %lu
v32@?0@"NSString"8Q16^B24
usage
idle
footprint
maxFootprint
thermalLevel
peakPowerPressureLevel
build
analyzers
Failed to read json file
homePersonsAndFaceCrops
photosPersonsAndFaceCrops
@"HMIPerson"16@?0@"NSDictionary"8
descriptorA.length == descriptorB.length
cluster.objects.count > 0
faceObservations.count > 0
faceObservations.firstObject.faceprint != nil
faceprintLength == faceObservation.faceprint.lengthInBytes / sizeof(float)
Sample buffer has an invalid PTS.
randomUniform
value
{CGAffineTransform=dddddd}
probability
attributes
B16@?0@"HMICIFilterAttribute"8
HMIRotate
CIAffineTransform
inputAngle
inputTransform
v16@?0@"HMICIFilterAttribute"8
camera_recording
camera_recording_analyzer
camera_recording_analyzer_media
camera_recording_analyzer_scheduler
camera_recording_analyzer_scheduler_json
camera_recording_maintenance
Failed to load model at path: %@
HMIMLModel
@"HMIVideoAnalyzerFrameResult"16@?0@"HMIVideoAnalyzerFrameResult"8
@"HMIVideoFrame"16@?0@"HMIVideoFrame"8
@"NSArray"16@?0@"HMIVideoAnalyzerFrameResult"8
Max Confidence Events
Frame Results
Thumbnails
Fragment
Configuration
HMICVFR.f
HMICVFR.roi
HMICVFR.ae
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
HMIOD.y.a
HMIOD.r.o
HMIP.x
HMIP.y
HMIAZ.p
HMIAZ.i
HMICameraVideoFrame does not support NSSecureCoding in the simulator
HKD://
analyzed-video-frames
 isInclusion:%d 
class-label
coordinates
overlap
activityZone
%@-%@-%@-%@.json
%@/%@
%@/activityzone-%@
B16@?0@"HMICameraActivityZone"8
filteringLevel
numDetectedObjects
com.apple.HomeAI.ActivityZone
noFiltering
resize_0
resize_10
resize_20
resize_26
resize_36
IFrameOnly
Full
Detector
Thumbnail Interval
Thumbnail Height
Timelapse Interval
Timelapse Preferred Fragment Duration
Max Fragment Duration
Max Fragment Analysis Duration
Decode Mode
Transcode
Transcode Codec
Passthrough Audio
Redact frames
Min Frame Quality
Min Frame Scale
Camera
Home UUID
Package Classifier Mode
Analysis FPS
minFrameQuality > 0 && minFrameQuality <= 1
minFrameScale > 0 && minFrameScale <= 1
analysisFPS > 0
Event Triggers
Recognize Faces
Activity Zone Count
q24@?0@"HMIVideoAnalyzerEvent"8@"HMIVideoAnalyzerEvent"16
B16@?0@"HMIStationaryObject"8
HMIVAEP.f
HMIVAEP.t
HMIVAEP.ibbe
Is Bounding Box & Confidence Estimated
Face
Torso
%@ %@ %@
com.apple.homed
syntheticEvents
personDetected
petDetected
vehicleDetected
packageDetected
analysisQOS
systemResourceUsageLevel
motionDetector
frameSelectorSampleRateMultiplier
frameSelectorTargetInterval
processingDevice
confidenceThresholdPersonHigh
confidenceThresholdPetHigh
confidenceThresholdVehicleHigh
confidenceThresholdFaceHigh
confidenceThresholdTorsoHigh
confidenceThresholdPackageHigh
confidenceThresholdPersonMedium
confidenceThresholdPetMedium
confidenceThresholdVehicleMedium
confidenceThresholdFaceMedium
confidenceThresholdTorsoMedium
confidenceThresholdPackageMedium
confidenceThresholdPackageClassifierMedium
confidenceThresholdPackageClassifierHigh
modelTimeout
uploadVideoAnalysisEvent
saveVideoFragmentResultHTML
assetReaderMaximizePowerEfficiency
assetReaderForceBGRA
analysisEnableTranscodeFragment
realTimeEncoding
espressoLowPriority
maxConcurrentAnalyzers
maxAnalysisFPS
opticalFlowLowPriority
opticalFlowBackgroundProcessing
saveDESRecords
skipMinDESRecordCount
DESSkipTraining
saveTrainedModel
DESSkipTrainingScalar
DESSkipPrivatize
enableDASTestConfiguration
personsModelStoragePath
personDataSourceDiskStoragePath
personsModelClassificationThresholdKnown
torsoPersonsModelClassificationThresholdKnown
faceVIPThresholdForTorsoAnnotation
personsModelClassificationThresholdUnknown
saveFaceCropsToDisk
showROI
useDevelopmentFeedbackService
eventTriggers
logHumanFriendlySchedulerState
schedulerStateLogFrequency
enableTorsoRecognition
enableSignposts
fragmentDiskBufferSize
logOtherProcessMemorySchedulerState
videoFrameTrackerMaxCandidates
useHEVC
taskServiceRunLocally
restartDecoderIfFormatChanges
user-interactive
user-initiated
unspecified
default
utility
background
Only NSNumber and NSString properties are supported.
Track:%.2f-%.2f @ %@ (%@)
%@ - %f
/tmp/TrackerReport-%@-%@.html
Tracker
%.2f %@
v64@?0Q8@"NSSet"16{CGRect={CGPoint=dd}{CGSize=dd}}24@"NSString"56
Target
Mean
Motion
Assign
v24@?0@"HMIVideoAssetWriter"8@"NSData"16
v32@?0@"HMIVideoAssetWriter"8@"NSData"16@"AVAssetSegmentReport"24
Encoder Queue
v24@?0@"HMIVideoEncoder"8^{opaqueCMSampleBuffer=}16
v24@?0@"HMIVideoFrameSampler"8^{opaqueCMSampleBuffer=}16
v32@?0@"HMIVideoFrameSampler"8@"HMIVideoEncoder"16^{opaqueCMSampleBuffer=}24
@"NSNumber"24@?0@"HMIVideoAnalyzerEvent"8@"NSNumber"16
FFArchive
yyyy-MM-dd
2021-05-15
q24@?0@"VNCluster"8@"VNCluster"16
v16@?0@"VNCluster"8
@"VNFaceObservation"16@?0@"NSNumber"8
B16@?0@"VNCluster"8
q24@?0@"HMIPersonFaceCrop"8@"HMIPersonFaceCrop"16
yyyy-MM-dd'T'HH-mm-ss
%@_%@.plist
@"NSUUID"16@?0@"HMIFaceprint"8
Fetch persons failed
CleanImpureHomePersonsOperation encountered failures
com.apple.HomeAI.%@%@%@.%tu
yyyy-MM-dd'T'HH:mm:ss.SSS'Z'
homeai: %@
Vision
Faceprints
Clusters
Persons
Associated
Faceprinting Duration
Clustering Duration
Total Duration
B16@?0@"HMIPersonSourceUUIDPair"8
v32@?0@"VNCluster"8@"NSUUID"16^B24
Error on dispatch_group_wait (associateFaceCrops)
Error associating face crops for %lu person%@: (
 ...
v16@?0@"HMIPersonFaceCrop"8
@"NSUUID"16@?0@"VNFaceObservation"8
@"NSUUID"16@?0@"NSUUID"8
v32@?0@"NSNumber"8@16^B24
HMICameraVideoFrameAnalyzerSignificantActivity
@"HMIFaceClassification"16@?0@"HMIPersonsModelPrediction"8
@"HMIVideoAnalyzerEvent"16@?0@"HMIVideoAnalyzerEvent"8
none
@"NSString"16@?0@"NSObject"8
high
medium
ClassifyFaceEvent
ClassifyTorsoEvent
HMIDESBT.u
HMIDESBackgroundTask
scale > 0 && scale <= 1
quality > 0 && quality <= 1
HMIVideoFrame failed to create compressed representation.
]1337;File=inline=1;preserveAspectRatio=1:%@
Data (JPEG)
CVPixelBuffer
Presentation Time Stamp
Size
Store
HMIVideoFrame does not support NSSecureCoding in the simulator.
#EXTM3U
#EXT-X-VERSION:7
#EXT-X-TARGETDURATION:%.6f
#EXT-X-PLAYLIST-TYPE:VOD
#EXT-X-INDEPENDENT-SEGMENTS
#EXT-X-I-FRAMES-ONLY
#EXT-X-KEY:METHOD=AES-256-GCM,URI="%@"
#EXT-X-MAP:URI="%@"
#EXTINF:%.5f
#EXT-X-BYTERANGE:%lu@%lu
#EXT-X-ENDLIST
Bounding Box
P(%@|[%@])=%@
Package
Person
Vehicle
Event
event
#D62728
#2CA02C
#1F77B4
#9467BD
#FF7F0E
#8C564B
#7F7F7F
@24@?0#8@"NSString"16
HMITC.su
HMITC.pu
HMITC.conf
%.4lf
HMIVideoDecoderWorkQueue
Format description is missing.
Cannot accept format description.
Cannot create reorder buffer, err: %d.
Cannot create decoder.
Cannot decode frame, err: %d.
Cannot reorder frames.
Decoded sample has an invalid PTS.
HMIVideoAssetWriter
HMIVideoAssetWriterOutput
UTType class is not available.
HMICMSampleBufferIsAudio(sbuf)
Underlying asset writer has failed.
Couldn't append sample buffer because, exception %@
Failed to flush segment.
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8Q16^B24
@"NSDictionary"24@?0@"NSUUID"8@"HMIPersonsModel"16
v16@?0@"HMIPersonSourceUUIDPair"8
v32@?0@"NSUUID"8@"NSSet"16^B24
v32@?0@"NSUUID"8@"NSDictionary"16^B24
v24@?0@"VNFaceObservation"8^B16
B16@?0@"HMIMotionDetection"8
Sparse Optical Flow
monitored
analysisFPS
timeSinceLastFragmentWasReceived
bufferFillRatio
bufferSize
delay
numDecodedSamples
numDidAnalyzeFrames
numDidAnalyzePackages
numDidCreateTimelapseFragments
averageAnalysisTime
decodeMode
transcodeCodecType
encode
encoder
activityZones
Name           
AFPS
Time
Last
Buffer               
Delay
     Decode:PTS
FR, FRAG
FR Time
Enc, Lapse:FRAG
Faces
Zones
Triggers
] %5ld KB
%.1f
%4ld:%.1f
%ld, %ld
%@%@%@ %@, %@:%ld
camera
Session has not received any new data for over 60 seconds.
Session Check
HMIFR.c
HMIFR.fc
HMIFR.fp
HMIFR.fqs
HMIFR.sea
HMIFR.seu
HMIFR.leus
TransitionMatrix
Joint
Face Classifications
Face Quality Score
selector
arguments
configuration
HMIVideoAnalyzer does not support remote analysis.
@"HMIVideoAnalyzer"16@?0@"HMIVideoAnalyzerConfiguration"8
VideoAnalyzerReport %@ %@
/tmp/%@.plist
fragmentResult
v16@?0@"HMIVideoAnalyzerEventFace"8
HMIVideoAnalyzerServer
HMIVideoAnalyzerServer - Input
HMIVideoAnalyzerServer - Encoder
dynamicConfiguration
Video fragment duration: %fs is greater than the max fragment duration value: %fs
Fragment had no video samples, fragment is likely corrupted.
%@_%@_%@
UnknownManufacturer
UnknownModel
UnknownFirmware
v20@?0@"NSString"8B16
YYYY-MM-dd-HH-mm-ss
sanitized.mp4
self.assetWriter == nil
self.timelapseOutputVideoFormat
 Timelapse
_encode
!self.encoder
self.inputVideoFormat
!self.timelapseEncoder
self.assetWriter
self.timelapseAssetWriter
v16@?0@"HMIVideoAnalyzerResultFilter"8
Filtered
B16@?0@"AVAssetSegmentTrackReport"8
Analyzer is in full bypass mode.
Analyzer is in partial bypass mode, only IFrames are decoded.
Analyzer has not received fragments from client in a long time.
/tmp/com.apple.HomeAI/familiar-face-data
Error initializing with home UUID: %@ source UUID:%@
Error enumerating persons
Error loading person from JSON
Error enumerating face crops for person UUID:%@
Error loading face crop from JSON
Error loading face crop image
HMIVAET.ro
HMIVAET.tr
Torso Roll
Torso Recognition
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/datastructs.cpp
cvReleaseMemStorage
cvRestoreMemStoragePos
NULL storage pointer
cvMemStorageAlloc
Too large memory block is requested
datastructs.cpp
storage->free_space % CV_STRUCT_ALIGN == 0
requested size is negative or too big
(size_t)ptr % CV_STRUCT_ALIGN == 0
cvCreateSeq
Specified element size doesn't match to the size of the specified element type (try to use 0 for element type)
cvSetSeqBlockSize
Storage block size is too small to fit the sequence elements
cvCvtSeqToArray
cvStartReadSeq
cvChangeSeqBlock
cvGetSeqReaderPos
cvSetSeqReaderPos
cvSeqPush
ptr + elem_size <= seq->block_max
block->start_index > 0
NULL sequence pointer
cvSeqPushMulti
number of removed elements is negative
cvSeqPopMulti
delta > 0
cvClearSeq
Invalid sequence header
cvSeqSlice
Bad sequence slice
Bad input sequence
cvSeqSort
Null compare function
cvCreateSet
cvSetAdd
count <= CV_SET_ELEM_IDX_MASK+1
cvCreateGraph
cvGraphAddVtx
cvFindGraphEdgeByPtr
ofs == 1 || start_vtx == edge->vtx[0]
graph pointer is NULL
cvGraphAddEdgeByPtr
vertex pointers coinside (or set to NULL)
edge->flags >= 0
Invalid graph pointer
cvCloneGraph
cvInitTreeNodeIterator
cvNextTreeNode
icvInitMemStorage
icvDestroyMemStorage
icvGoNextMemBlock
parent->bottom == block
icvGrowSeq
The sequence has NULL storage pointer
storage->free_space >= delta
block->count % seq->elem_size == 0 && block->count > 0
seq->first->start_index == 0
icvFreeSeqBlock
(in_front_of ? block : block->prev)->count == 0
seq->ptr == block->data
block->count > 0 && block->count % seq->elem_size == 0
Unknown/unsupported border type
borderInterpolate
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/filter.cpp
columnBorderType != BORDER_WRAP
!rowFilter.empty() && !columnFilter.empty()
bufType == srcType
0 <= anchor.x && anchor.x < ksize.width && 0 <= anchor.y && anchor.y < ksize.height
roi.x >= 0 && roi.y >= 0 && roi.width >= 0 && roi.height >= 0 && roi.x + roi.width <= wholeSize.width && roi.y + roi.height <= wholeSize.height
start
srcRoi.x >= 0 && srcRoi.y >= 0 && srcRoi.width >= 0 && srcRoi.height >= 0 && srcRoi.x + srcRoi.width <= src.cols && srcRoi.y + srcRoi.height <= src.rows
wholeSize.width > 0 && wholeSize.height > 0
proceed
src && dst && count > 0
srcY >= startY
dstY <= roi.height
src.type() == srcType && dst.type() == dstType
apply
dstOfs.x >= 0 && dstOfs.y >= 0 && dstOfs.x + srcRoi.width <= dst.cols && dstOfs.y + srcRoi.height <= dst.rows
_kernel.channels() == 1
getKernelType
cn == CV_MAT_CN(bufType) && ddepth >= std::max(sdepth, CV_32S) && kernel.type() == ddepth
getLinearRowFilter
Unsupported combination of source format (=%d), and buffer format (=%d)
cn == CV_MAT_CN(bufType) && sdepth >= std::max(ddepth, CV_32S) && kernel.type() == sdepth
getLinearColumnFilter
Unsupported combination of buffer format (=%d), and destination format (=%d)
cn == CV_MAT_CN(_dstType)
createSeparableLinearFilter
ktype == CV_8U || ktype == CV_32S || ktype == CV_32F || ktype == CV_64F
preprocess2DKernel
cn == CV_MAT_CN(dstType) && ddepth >= sdepth
getLinearFilter
Unsupported combination of source format (=%d), and destination format (=%d)
createLinearFilter
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0
SymmColumnVec_32s8u
SymmColumnSmallVec_32s16s
SymmColumnSmallVec_32f
SymmColumnVec_32f16s
SymmColumnVec_32f
anchor.inside(Rect(0, 0, ksize.width, ksize.height))
normalizeAnchor
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/precomp.hpp
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0 && this->ksize <= 5
SymmRowSmallFilter
kernel.type() == DataType<DT>::type && (kernel.rows == 1 || kernel.cols == 1)
RowFilter
kernel.type() == DataType<ST>::type && (kernel.rows == 1 || kernel.cols == 1)
ColumnFilter
this->ksize == 3
SymmColumnSmallFilter
SymmColumnFilter
_kernel.type() == DataType<KT>::type
Filter2D
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/alloc.cpp
Failed to allocate %lu bytes
OutOfMemoryError
borderType != BORDER_CONSTANT
pyrDown
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/pyramids.cpp
!_src.empty()
pyrDown_
std::abs(dsize.width*2 - ssize.width) <= 2 && std::abs(dsize.height*2 - ssize.height) <= 2
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/opengl_interop_deprecated.cpp
GlBuffer
GlTexture
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/persistence.cpp
Invalid pointer to file storage
The node is neither a map nor an empty collection
cvGetFileNodeByName
Null element name
cvStartWriteStruct
The file storage is opened for reading
cvEndWriteStruct
cvWriteInt
cvWriteString
cvWriteRawData
Negative number of elements
Null data pointer
persistence.cpp
cvStartReadRawData
Null pointer to source file node or reader
The file node should be a numerical scalar or a sequence
cvReadRawDataSlice
Null pointer to reader or destination array
The readed sequence is a scalar, thus len must be 1
The sequence element is not a numerical scalar
The sequence slice does not fit an integer number of records
Null pointers to source file node or destination array
cvReadRawData
opencv-sequence
opencv-sequence-tree
opencv-graph
opencv-sparse-matrix
opencv-image
opencv-matrix
opencv-nd-matrix
Invalid type info
cvRegisterType
Some of required function pointers (is_instance, release, read or write) are NULL
Type name should start with a letter or _
Type name should contain only letters, digits, - and _
NULL double pointer
cvRead
The node does not represent a user object (unknown type?)
Unknown array type
The storage is not opened
icvPuts
An attempt to add element without a key to a map, or add element with key to sequence
icvXMLWriteTag
A single _ is a reserved tag name
Closing tag should not include any attributes
Key should start with a letter or _
Key name may only contain alphanumeric characters [a-zA-Z0-9], '-' and '_'
icvDecodeFormat
fmt_pairs != 0 && max_len > 0
Invalid data type specification
Too long data type specification
(align & (align-1)) == 0 && size < INT_MAX
%.8e
-.Inf
.Inf
%.16e
elements with keys can not be written to sequence
icvXMLWriteScalar
icvYMLWrite
The key is an empty
The key is too long
Key must start with a letter or _
Key names may only contain alphanumeric characters [a-zA-Z0-9], '-', '_' and ' '
icvReleaseSeq
flags
count
Some of essential sequence attributes are absent
icvReadSeq
The sequence flags are invalid
curve
closed
hole
untyped
header_dt
header_user_data
One of "header_dt" and "header_user_data" is there, while the other is not
rect
origin
Only one of "header_user_data", "rect" and "origin" tags may occur
color
data
The image data is not found in file storage
The number of stored elements does not match to "count"
Too complex format for the matrix
icvDecodeSimpleFormat
recursive
false
False
FALSE
icvWriteSeqTree
CV_IS_SEQ( seq )
sequences
icvWriteSeq
level
The size of element calculated from "dt" and the elem_size do not match
icvGetFormat
Size of sequence element (elem_size) is inconsistent with seq->flags
%d%c
The size of header calculated from "header_dt" is greater than header_size
icvWriteHeaderData
opencv-sequence-tree instance should contain a field "sequences" that should be a sequence
icvReadSeqTree
All the sequence tree nodes should contain "level" field
level == prev_level + 1
icvReleaseGraph
vertex_dt
edge_dt
vertex_count
edge_count
Some of essential graph attributes are absent
icvReadGraph
oriented
Graph edges should start with 2 integers and a float
%df%s
vertices
edges
No edges data
No vertices data
Some of stored vertex indices are out of range
Duplicated edge has occured
cvAlignPtr
(align & (align-1)) == 0
icvWriteGraph
CV_IS_GRAPH(graph)
2if%s
sizes
Some of essential matrix attributes are absent
icvReadSparseMat
Could not determine sparse matrix dimensionality
The matrix data is not found in file storage
Sparse matrix data is corrupted
icvWriteSparseMat
CV_IS_SPARSE_MAT(mat)
(reader).seq->elem_size == sizeof(idx)
k < dims
Some of essential image attributes are absent
icvReadImage
layout
interleaved
Only interleaved images can be read
The matrix size does not match to the number of stored elements
icvWriteImage
CV_IS_IMAGE(image)
Images with planar data layout are not supported
top-left
bottom-left
planar
rows
cols
icvReadMat
icvWriteMat
CV_IS_MAT_HDR_Z(mat)
icvReadMatND
Could not determine the matrix dimensionality
icvWriteMatND
CV_IS_MATND_HDR(mat)
type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/dxt.cpp
This mode (using nonzero_rows with a single-column matrix) breaks the function's logic, so it is prohibited.
For fast convolution/correlation use 2-column matrix or single-row matrix instead
dxt.cpp
!inv
type == srcB.type() && srcA.size() == srcB.size()
mulSpectrums
(flags & DFT_NO_PERMUTE) == 0
(unsigned)k0 < (unsigned)n && (unsigned)k1 < (unsigned)n
factors[0] == factors[nf-1]
(unsigned)j < (unsigned)n2
(unsigned)j < (unsigned)n
RealDFT
tab_size == n
CCSIDFT
src != dst
DFTInit
nf < 34
elem_size == sizeof(Complex<float>)
channels() == CV_MAT_CN(dtype)
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/copy.cpp
mask.depth() == CV_8U && (mcn == 1 || mcn == cn)
size() == mask.size()
checkScalar(value, type(), _value.kind(), _InputArray::MAT )
setTo
mask.empty() || mask.type() == CV_8U
repeat
ny > 0 && nx > 0
maskarr == 0
cvCopy
src.depth() == dst.depth() && src.size == dst.size
(coi1 != 0 || src.channels() == 1) && (coi2 != 0 || dst.channels() == 1)
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/opengl_interop.cpp
The library is compiled without OpenGL support
throw_nogl
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/thresh.cpp
Unknown threshold type
thresh_8u
thresh_16s
thresh_32f
img.depth() == CV_8U && winSize.width > 2 && winSize.height > 2
buildOpticalFlowPyramid
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/video/lkpyramid.cpp
maxLevel >= 0 && winSize.width > 2 && winSize.height > 2
calcOpticalFlowPyrLK
(npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0
nextPtsMat.checkVector(2, CV_32F, true) == npoints
statusMat.isContinuous()
errMat.isContinuous()
levels1 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + prevPyr[lvlStep1].cols + winSize.width <= fullSize.width && ofs.y + prevPyr[lvlStep1].rows + winSize.height <= fullSize.height
levels2 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + nextPyr[lvlStep2].cols + winSize.width <= fullSize.width && ofs.y + nextPyr[lvlStep2].rows + winSize.height <= fullSize.height
prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size()
prevPyr[level * lvlStep1].type() == nextPyr[level * lvlStep2].type()
depth == CV_8U
calcSharrDeriv
cvAlign
internal.hpp
scn == 1
convertAndUnrollScalar
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/arithm.cpp
op == CMP_LT || op == CMP_LE || op == CMP_EQ || op == CMP_NE || op == CMP_GE || op == CMP_GT
compare
The operation is neither 'array op array' (where arrays have the same size and the same type), nor 'array op scalar', nor 'scalar op array'
The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array'
binary_op
(mask.type() == CV_8UC1 || mask.type() == CV_8SC1)
mask.size == src1.size
The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
arithm_op
src2.type() == CV_64F && (src2.rows == 4 || src2.rows == 1)
When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified
img.dims <= 2 && templ.dims <= 2 && corr.dims <= 2
crossCorr
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/templmatch.cpp
depth == tdepth || tdepth == CV_32F
corrsize.height <= img.rows + templ.rows - 1 && corrsize.width <= img.cols + templ.cols - 1
ccn == 1 || delta == 0
the input arrays are too big
CV_MAT_CN(sumType) == CV_MAT_CN(srcType)
getRowSumFilter
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/smooth.cpp
CV_MAT_CN(sumType) == CV_MAT_CN(dstType)
getColumnSumFilter
Unsupported combination of sum format (=%d), and destination format (=%d)
sumCount == ksize-1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/utils.cpp
top >= 0 && bottom >= 0 && left >= 0 && right >= 0
copyMakeBorder
value[0] == value[1] && value[0] == value[2] && value[0] == value[3]
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/deriv.cpp
ktype == CV_32F || ktype == CV_64F
getScharrKernels
dx >= 0 && dy >= 0 && dx+dy == 1
getSobelKernels
The kernel size must be odd and not larger than 31
dx >= 0 && dy >= 0 && dx+dy > 0
ksize > order
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/convert.cpp
src && nsrcs > 0 && dst && ndsts > 0 && fromTo && npairs > 0
mixChannels
j < nsrcs && src[j].depth() == depth
i1 >= 0 && j < ndsts && dst[j].depth() == depth
type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == CV_32FC2 || type == CV_64FC2)
gemm
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matmul.cpp
a_size.width == len
a_size.height == len
C.type() == type && (((flags&GEMM_3_T) == 0 && C.rows == d_size.height && C.cols == d_size.width) || ((flags&GEMM_3_T) != 0 && C.rows == d_size.width && C.cols == d_size.height))
type == CV_64FC2
src1.type() == src2.type()
scaleAdd
src.channels() == 1
mulTransposed
delta.channels() == 1 && (delta.rows == src.rows || delta.rows == 1) && (delta.cols == src.cols || delta.cols == 1)
operator()
GEMM_TransposeBlock
matmul.cpp
MulTransposedR
delta_cols == 1
cn <= 4 && func != 0
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/stat.cpp
src.channels() == 1 && func != 0
countNonZero
mean
(cn == 1 && (mask.empty() || mask.type() == CV_8U)) || (cn >= 1 && mask.empty() && !minIdx && !maxIdx)
minMaxIdx
img.dims <= 2
src.type() == CV_8UC1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/lapack.cpp
type == CV_32F || type == CV_64F
invert
m == n
method == DECOMP_LU || method == DECOMP_CHOLESKY
lapack.cpp
n == 1
type == _src2.type() && (type == CV_32F || type == CV_64F)
solve
(method != DECOMP_LU && method != DECOMP_CHOLESKY) || is_normal || src.rows == src.cols
src.rows == 1
The function can not solve under-determined linear systems
src.rows == src.cols
eigen
w.type() == u.type() && u.type() == vt.type() && u.data && vt.data && w.data
backSubst
u.cols >= nm && vt.rows >= nm && (w.size() == Size(nm, 1) || w.size() == Size(1, nm) || w.size() == Size(vt.rows, u.cols))
rhs.data == 0 || (rhs.type() == type && rhs.rows == m)
_SVDcompute
0 <= d && d <= CV_MAX_DIM && _sizes
create
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matrix.cpp
step[dims-1] == (size_t)CV_ELEM_SIZE(flags)
m.dims >= 2
0 <= _rowRange.start && _rowRange.start <= _rowRange.end && _rowRange.end <= m.rows
0 <= _colRange.start && _colRange.start <= _colRange.end && _colRange.end <= m.cols
m.dims <= 2
0 <= roi.x && 0 <= roi.width && roi.x + roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height <= m.rows
ranges
r == Range::all() || (0 <= r.start && r.start < r.end && r.end <= m.size[i])
dims <= 2
diag
img->dataOrder == IPL_DATA_ORDER_PIXEL
img->dataOrder == IPL_DATA_ORDER_PIXEL || img->roi->coi != 0
(int)nelems >= 0
reserve
resize
COI is not supported by the function
cvarrToMat
seq->total > 0 && CV_ELEM_SIZE(seq->flags) == seq->elem_size
dims <= 2 && step[0] > 0
locateROI
adjustROI
reshape
The matrix is not continuous, thus its number of rows can not be changed
Bad new number of rows
The total number of matrix elements is not divisible by the new number of rows
The total width is not divisible by the new number of channels
cn <= 4
scalarToRawData
i < 0
getMat
0 <= i && i < (int)vv.size()
This method is not implemented for oclMat yet
k == STD_VECTOR_MAT
0 <= i && i < (int)v.size()
getMatVector
This function in deprecated, do not use it
getGlBuffer
getGlTexture
k == GPU_MAT
getGpuMat
size
i < (int)vv.size()
total
empty
!fixedSize() || ((Mat*)obj)->size.operator()() == _sz
!fixedType() || ((Mat*)obj)->type() == mtype
!fixedSize() || ((gpu::GpuMat*)obj)->size() == _sz
!fixedType() || ((gpu::GpuMat*)obj)->type() == mtype
!fixedSize() || ((ogl::Buffer*)obj)->size() == _sz
!fixedType() || ((ogl::Buffer*)obj)->type() == mtype
!fixedSize() || ((Mat*)obj)->size.operator()() == Size(cols, rows)
!fixedSize() || ((gpu::GpuMat*)obj)->size() == Size(cols, rows)
!fixedSize() || ((ogl::Buffer*)obj)->size() == Size(cols, rows)
!fixedType() && !fixedSize()
CV_MAT_TYPE(mtype) == m.type()
m.dims == dims
m.size[j] == sizes[j]
mtype == type0 || (CV_MAT_CN(mtype) == 1 && ((1 << type0) & fixedDepthMask) != 0)
dims == 2 && ((sizes[0] == sz.height && sizes[1] == sz.width) || (allowTransposed && sizes[0] == sz.width && sizes[1] == sz.height))
dims == 2 && (sizes[0] == 1 || sizes[1] == 1 || sizes[0]*sizes[1] == 0)
!fixedSize() || len == vv.size()
mtype == type0 || (CV_MAT_CN(mtype) == CV_MAT_CN(type0) && ((1 << type0) & fixedDepthMask) != 0)
!fixedSize() || len == ((vector<uchar>*)v)->size() / esz
Vectors with element size %d are not supported. Please, modify OutputArray::create()
create() called for the missing output array
!fixedSize() || len == len0
v[j].empty()
i < (int)v.size()
!fixedType() || (CV_MAT_CN(mtype) == m.channels() && ((1 << CV_MAT_TYPE(flags)) & fixedDepthMask) != 0)
!fixedSize()
release
clear
k == MAT
getMatRef
setIdentity
src.dims <= 2 && esz <= (size_t)32
transpose
src.size() == dst.size() && (src.cols == 1 || src.rows == 1)
func != 0
m.dims <= 2 && m.rows == m.cols
completeSymm
src.dims <= 2
src.channels() == dst.channels()
_arrays && (_ptrs || _planes)
init
narrays <= 1000
arrays[i] != 0
A.size == arrays[i0]->size
A.step[d-1] == A.elemSize()
copyTo
convertTo
minMaxLoc
0 <= _dims && _dims <= CV_MAX_DIM
setSize
s >= 0
OpenCV Error: %s (%s) in %s, file %s, line %d
No Error
Backtrace
Unspecified error
Internal error
Insufficient memory
Bad argument
Iterations do not converge
Autotrace call
Incorrect size of input array
Null pointer
Division by zero occured
Image step is wrong
Inplace operation is not supported
Requested object was not found
Input image depth is not supported by function
Formats of input arguments do not match
Sizes of input arguments do not match
One of arguments' values is out of range
Unsupported format or combination of formats
Input COI is not supported
Bad number of channels
Bad flag (parameter or structure field)
Bad parameter of type CvPoint
Bad type of mask argument
Parsing error
The function/feature is not implemented
Memory block has been corrupted
Assertion failed
No GPU support
Gpu API call
No OpenGL support
OpenGL API call
Unknown %s code %d
status
module != 0 && module->name != 0 && module->version != 0
cvRegisterModule
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/system.cpp
cxcore
2.4.13.6
vector
basic_string
unknown function
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/include/opencv2/dynamicuda/dynamicuda.hpp
copy
copyWithMask
convert
mallocPitch
The library is compiled without CUDA support
qualityLevel > 0 && minDistance >= 0 && maxCorners >= 0
goodFeaturesToTrack
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/featureselect.cpp
mask.empty() || (mask.type() == CV_8UC1 && mask.size() == image.size())
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/array.cpp
Non-positive width or height
cvCreateMatHeader
Invalid matrix type
cvInitMatHeader
Non-positive cols or rows
cvReleaseMat
Bad CvMat header
cvCloneMat
NULL matrix header pointer
cvInitMatNDHeader
invalid array data type
NULL <sizes> pointer
non-positive or too large number of dimensions
one of dimesion sizes is non-positive
The array is too big
cvCreateMatNDHeader
Bad CvMatND header
cvCloneMatND
src->dims <= CV_MAX_DIM
_dst.data == data0
Incorrect number of arrays
cvInitNArrayIterator
Some of required array pointers is NULL
Iterator pointer is NULL
COI set is not allowed here
Number of dimensions is the same for all arrays
Data type is not the same for all arrays
Number of channels is not the same for all arrays
Depth is not the same for all arrays
Mask should have 8uC1 or 8sC1 data type
Dimension sizes are the same for all arrays
cvNextNArraySlice
array.cpp
iterator != 0
cvCreateSparseMat
bad number of dimensions
cvReleaseSparseMat
Invalid sparse array header
cvCloneSparseMat
Invalid sparse matrix header
cvInitSparseMatIterator
NULL iterator pointer
Data is already allocated
cvCreateData
unrecognized or unsupported array type
cvReleaseData
Only continuous nD arrays are supported here
cvGetElemType
cvGetDims
Array should be CvMat or IplImage
cvGetSize
index is out of range
cvPtr2D
COI must be non-null in case of planar images
NULL pointer to indices
cvPtrND
NULL array pointer is passed
cvGetMat
The matrix has NULL data pointer
The image has NULL data pointer
Images with planar data layout should be used with COI selected
The image is interleaved and has over CV_CN_MAX channels
Pixel order should be used with coi == 0
Input array has NULL data pointer
Unrecognized or unsupported array type
cvCreateImage
null pointer to header
cvInitImageHeader
Bad input roi
Unsupported format
Bad input origin
Bad input align
cvReleaseImageHeader
cvReleaseImage
cvSetImageROI
rect.width >= 0 && rect.height >= 0 && rect.x < image->width && rect.y < image->height && rect.x + rect.width >= (int)(rect.width > 0) && rect.y + rect.height >= (int)(rect.height > 0)
cvSetImageCOI
cvGetImageCOI
Bad image header
cvCloneImage
cvGetMatND
icvGetNodePtr
CV_IS_SPARSE_MAT( mat )
One of indices is out of range
(newsize & (newsize - 1)) == 0
GRAY
BGRA
op == MORPH_ERODE || op == MORPH_DILATE
getMorphologyRowFilter
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/morph.cpp
Unsupported data type (=%d)
getMorphologyColumnFilter
getMorphologyFilter
depth == CV_8U || depth == CV_16U || depth == CV_16S || depth == CV_32F || depth == CV_64F
createMorphologyFilter
shape == MORPH_RECT || shape == MORPH_CROSS || shape == MORPH_ELLIPSE
getStructuringElement
morphOp
((size_t)src[i] & 15) == 0
((size_t)_src[i] & 15) == 0
_kernel.type() == CV_8U
MorphFilter
src.type() == CV_8UC1 || src.type() == CV_32FC1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/corner.cpp
cornerEigenValsVecs
CV_MAT_CN(_type) == e.a.channels()
assign
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matop.cpp
Unknown operation
Invalid matrix initializer type
%{public}@Storing faceprints:%@ failed with error:%@
%{public}@Storing faceprints:%@ completed successfully
%{public}@Sample has a very large duration, the source video is corrupt.
%{public}@Original Sample Buffer: %@
%{public}@Bogus atomSize %llu, recovering by adjusting size.
%{public}@Simulated crash reporting is not available on this system.
%{public}@Not generating a memory exception report for %@ since another report was generated within last %f seconds.
%{public}@Memory exception reporting is not available on this system.
%{public}@Torsoprint Version: %ld.%ld
%{public}@Found low quality torso conf: %.4f
%{public}@Found low quality torso entropyOfSaturation: %.4f entropyOfLaplacian: %.4f
%{public}@Removing faceCrops:%@ failed with error:%@
%{public}@Removing faceCrops:%@ completed successfully
%{public}@Received nil data source
%{public}@Fetching settings using data source: %@
%{public}@Error fetching settings: %@
%{public}@handleUpdatedPerson: %@
%{public}@handleUpdatedUnassociatedFaceCrop: %@
%{public}@handleUpdatedPersonFaceCrop: %@
%{public}@handleUpdatedFaceprint: %@
%{public}@handleUpdatedSettings: %@
%{public}@handleRemovedPersonWithUUID: %@
%{public}@handleRemovedFaceCropWithUUID: %@
%{public}@handleRemovedFaceprintWithUUID: %@
%{public}@Successfully handled face misclassification
%{public}@Error in handling face misclassification, error:%@
%{public}@Submitted face misclassification task, taskID:%u
%{public}@Not storing face crop and faceprint for HMIHomePersonManager.UUID:%@ from face event:%@
%{public}@Storing unknown to Home face crop:%@ and faceprint:%@
%{public}@Error storing unassociated face crop:%@, error:%@
%{public}@Stored unassociated face crop:%@
%{public}@Error storing faceprint:%@, error:%@
%{public}@Stored faceprint:%@
%{public}@Reached face crop limit for sessionEntityUUID:%@ for HMIHomePersonManager.UUID:%@; not storing
%{public}@Timer fired, but person data is not yet available, waiting...
%{public}@Timer fired, updating home persons model
%{public}@Not triggering daily VIP Model Core Analytics event, last event was sent less than 1 day ago
%{public}@Triggering daily VIP Model Core Analytics event
%{public}@Successfully ran persons model summary task
%{public}@Failed to run persons model summary task, error:%@
%{public}@Submitted persons model summary task, taskID:%u
%{public}@Unrecognized timer: %@
%{public}@Updating with settings: %@
%{public}@Settings have disabled face classification, removing home persons model
%{public}@Settings have enabled face classification, updating home persons model
%{public}@Storing face crop:%@ failed with error:%@
%{public}@Storing face crop:%@ completed successfully
%{public}@Storing faceprint:%@ failed with error:%@
%{public}@Storing faceprint:%@ completed successfully
%{public}@Registering for Thermal Level Notifications
%{public}@Thermal Level is now: %lu
%{public}@Cannot get available space, error: %@
%{public}@Footprint: %@, Average: %@, Peak: %@
%{public}@Registering for Thermal Pressure Notifications
%{public}@Thermal Pressure Level is now: %@
%{public}@Initializing shared model
%{public}@Model is not bundled into framework. Default model is stored in Git LFS. Make sure Git LFS is installed in your local system.
%{public}@Failed to load model!
%{public}@Failed to read sample buffer, error: %@
%{public}@Asset reader failed, ignoring
%{public}@Track %@, %@
%{public}@Warnings: %@
%{public}@personManager is nil for homeUUID: %@
%{public}@Error refreshing home data: %@
%{public}@No homes were located
%{public}@Found home: name: %@, primary: %s, UUID: %@
Identifier = %@, Name = %@
HMISignpost
%{public}@Ignoring %@
%{public}@fetchAllPersonsWithCompletion
%{public}@fetchPersonsWithUUIDs:%@
%{public}@fetchAllPersonFaceCropsWithCompletion
%{public}@Received invalid HMPersonFaceCropSource: %ld
%{public}@fetchFaceCropsForPersonsWithUUIDs:%@
%{public}@fetchAllFaceprintsWithCompletion
%{public}@fetchFaceprintsForFaceCropsWithUUIDs:%@
%{public}@fetchSettingsWithCompletion
%{public}@performCloudPullWithCompletion
%{public}@addFaceprints:%@
%{public}@removeFaceprintsWithUUIDs:%@
%{public}@Could not initialize from decoded personUUID: %@
%{public}@BackgroundEstimator(PTS:%.2f) Unable to update background model (%lu/%lu)
%{public}@Background model assignment is NULL %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to past timestamp %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset outdated background model %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to image size change
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to very large foreground object
%{public}@BackgroundEstimator(PTS:%.2f) Unable to alloc buffer
%{public}@BackgroundEstimator(PTS:%.2f) No background model
%{public}@Fullfilled content request: %@
%{public}@Fullfilled data request: %@
%{public}@Failed to loadValuesAsynchronouslyForKeys, due to timeout.
%{public}@Face below face quality thresholds: SVM recognizability = %lf, Yaw = %lf, discarding
%{public}@Face below ANFR face quality threshold: ANFR confidence = %lf, discarding
%{public}@personsModelPredictions is empty
%{public}@Positively classified face with facemask: (sourceUUID: %@, personUUID: %@)
%{public}@Face removed from unknown & uncertain bucket: has facemask
%{public}@Face removed from unknown and uncertian bucket, SSD confidence = %f, entropy of laplacian = %f, Face yaw = %f, box size: %f
%{public}@Added to unknown bucket yaw: %@
%{public}@Added to uncertain bucket yaw: %@
%{public}@Face recognition set is empty
%{public}@Positive face classifications: %@ 
%{public}@DES record saving is not permitted.
%{public}@There isn't enough available disk space (%ld MB) to save DES records.
%{public}@Couldn't determine the amount of available space disk space, continuing.
%{public}@Saving des record for video frame (PTS:%0.2fs) to disk
%{public}@Saving DES Record, recordInfo: %@, data: %@
%{public}@Saved DES Record: %@, error: %@
%{public}@Unable to create input image tensor with error %@
%{public}@Track(PTS:%.2f-%.2f), dF:%.2f(%.2f), dT:%.2f(%.2f), GIOU:%.2f(%.2f), %@(%@) vs %@(%@)
%{public}@HMIPersonTracker: unable to get %@ at index %lu / %lu
%{public}@Error creating frame analyzer: %@
%{public}@Face Classification is enabled, but homeUUID is nil, skipping face recognition
%{public}@Cannot find ground truth for %@
%{public}@Error, couldn't get face box from photos data, ignoring face crop
%{public}@Error while detecting face in Photos face crop, error: %@, or no box detected, falling back to photos bounding box
%{public}@No detected box overlaps with photos bounding box, falling back to photos bounding box
%{public}@Could not initialize from decoded UUID: %@ dataRepresentation: %@ dateCreated: %@
%{public}@Dropping frame, lastSamplePTS > nextSamplePTS.
%{public}@TaskID: %u running for %f seconds ...
%{public}@TaskID: %u step %d of %d
%{public}@options is empty/nil, defaulting to Home persons clustering task with impure person cleanup
%{public}@Creating HMPhotosPersonManager for homeUUID:%@ sourceUUID:%@
%{public}@Creating HMHomePersonManager for homeUUID:%@
%{public}@Current device is not primary resident, skipping clustering
%{public}@Initializing HMITaskServiceServer
%{public}@Error fetching persons:%@
%{public}@Skipping sentinel faceprint in existingAtCurrentVersion
%{public}@Skipping sentinel faceprint in createdAtCurrentVersion
%{public}@Faceprint Version: %ld.%ld
%{public}@Warm starting faceprint model...
%{public}@Failed to create pixel buffer when warm starting faceprint model
%{public}@Failed to warm start faceprint model: %@
%{public}@Warm start of faceprint model took: %f
%{public}@Cropping face %@ from pixel buffer with dimensions: %.1f x %.1f roll: %.02f degrees
%{public}@Error pixel buffer type conversion %@.
%{public}@Error in rotating the face %@.
%{public}@Face was rotated by:%.02f degrees
%{public}@HMIPrivateErrorCodeCropAndResizeFailed %@
%{public}@Cropping face %@ from face crop with dimensions %.1f x %.1f
%{public}@%lu faceprint(s) exist for face crop:%@ but are not the current version
%{public}@Using existing faceprint for face crop:%@
%{public}@Faceprinting face crop:%@
%{public}@Skipping crop, encountered error faceprinting: %@
%{public}@Face crop has a facemask, creating sentinel faceprint
%{public}@Vision run-time version: %d.%02d.%02d (%d)
%{public}@releaseCachedResources is deprecated and is now a no-op.
%{public}@Could not initialize from decoded UUID: %@ data: %@ modelUUID: %@ faceCropUUID: %@
%{public}@Error during update torso model task: %@
%{public}@Trusting host: %@ by default, not enforcing certificate pinning since user is donating videos to a dev server
%{public}@Trusting host: %@
%{public}@Force Certificate Pinning
%{public}@Error setting trust policies: %lu
%{public}@Invalid certificate: %@
%{public}@Downloading Clip
%{public}@Fetched Clip videoAssetContext: %@, error: %@
%{public}@Fetching Clip, progress %lu%%
%{public}@Face crops are not available.
%{public}@Fetching Face Crops
%{public}@Fetched Person UUIDs: %@
%{public}@Fetched Face Crops: %@, error: %@
%{public}@Fetching Clip
%{public}@Use the face-blurred video for upload
%{public}@Use the original video without audio track for upload
%{public}@Uploading payload data: %@, to URL %@
%{public}@Submitting clipUUID: %@, cameraProfileUUID: %@
%{public}@Stripped Audio %@, error: %@
%{public}@Downloaded %@, error: %@
%{public}@Failed to fetch pre-signed URL, error: %@
%{public}@Requesting a pre-signed url from server endpoint:%@, for clipUUID:%@
%{public}@Failed to request service result from server, error: %@
%{public}@Failed to decode server response, error: %@
%{public}@Service result: %@
%{public}@Failed to request service result, resource is not found, serverResponse: %@
%{public}@Failed to request service result due to internal server error, serverResponse: %@
%{public}@Failed to request service result due to server error, serverResponse: %@
%{public}@Deleting Temporary File %@
%{public}@Deleted Temporary File %@, error: %@
%{public}@Failed to generate persons model summary, error:%@
%{public}@Failed to fetch face crops with error: %@
%{public}@Failed to fetch faceprints with error: %@
%{public}@Error faceprinting face crops:%@
%{public}@Person (%@) has no faceprints -- nothing to remove
%{public}@Nearest face crop to be removed: %@
%{public}@Failed to remove face crop with error: %@
%{public}@Successfully removed face crop (%@) via user indicated misclassification
%{public}@Failed to remove persons model, error:%@
%{public}@Successfully removed persons model
%{public}@%@: %@
%{public}@Provided sequenceNumbers: %@, don't match fragment's sequenceNumbers: %@
%{public}@Failed to read fragment data, err: %d
%{public}@No torso annotations -- skipping torso model update
%{public}@Adding torso to existing sessionEntityUUID: %@ (face)
%{public}@Adding face to existing sessionEntityUUID: %@ (torso)
%{public}@Session entity %@ already has a face recognition, skipping subsequent match
%{public}@Existing face classification: %@
%{public}@New face classification: %@
%{public}@Assigning session entity %@ the face classification: %@
%{public}@updateTorsoModelAndGetTorsoAnnotationsForHome: %@
%{public}@Creating torso annotation with %lu torsoprints
%{public}@Adding face to existing sessionEntityUUID: %@ (VIP)
%{public}@Adding torso to existing sessionEntityUUID: %@ (VIP)
%{public}@Adding face to existing sessionEntityUUID: %@ (NN)
%{public}@Adding torso to existing sessionEntityUUID: %@ (NN)
%{public}@Adding face to existing sessionEntityUUID: %@ (track)
%{public}@Adding torso to existing sessionEntityUUID: %@ (track)
%{public}@Adding new face sessionEntityUUID: %@
%{public}@Adding new torso sessionEntityUUID: %@
%{public}@Error removing persons with UUIDs:%@, error:%@
%{public}@Succesfully removed persons %@
%{public}@Removing faceprints:%@ failed with error:%@
%{public}@Removing faceprints:%@ completed successfully
%{public}@Could not decode torsoAnnotations
%{public}@Publishing local state
%{public}@Dropping remote analysis torso update since torso rec is not enabled on this device
%{public}@Dropped %lu incompatible torsoprint annotations out of %lu total
%{public}@Successfully update torso model
%{public}@Error in update torso model, error:%@
%{public}@Submitted torso model update task, taskID:%u
%{public}@Could not initialize from decoded sourceUUID: %@
%{public}@Could not initialize from decoded UUID: %@
%{public}@Saved face classification:%@ to disk
%{public}@Invalid photos face crop data
%{public}@Face Box dict is null in photos metadata
%{public}@Couldn't convert face box dict to rect
%{public}@Error: %@
%{public}@imageData is nil
%{public}@Metadata string is nil in photos face crop data
%{public}@Couldn't retrieve metadata from photos crop:%@
%{public}@Could not initialize from decoded UUID: %@ data: %@ hasLowQualityKey: %@, hasUnrecognizableKey: %@
%{public}@Could not initialize from decoded faceRecognition: %@ torsoprints: %@ torsoModelVersion: %@
%{public}@Invalidated with err: %d
%{public}@Encoder is in a failed state, ignoring sample.
%{public}@VTCompressionSessionEncodeFrameWithOutputHandler (Handler) failed, err: %d
%{public}@VTCompressionSessionEncodeFrameWithOutputHandler, frame dropped.
%{public}@VTCompressionSessionCompleteFrames failed, err: %d
%{public}@VTCompressionSessionPrepareToEncodeFrames failed, err: %d
%{public}@Cannot set property: %@, error: %d
%{public}@Cannot copy property: %@, error: %d
%{public}@addFaceCrops:%@
%{public}@addPersonFaceCrops:%@
%{public}@Received invalid HMIPersonFaceCropSource: %ld
%{public}@addPersons:%@
%{public}@fetchAllUnassociatedFaceCropsWithCompletion
%{public}@removeFaceCropsWithUUIDs:%@
%{public}@removePersonsWithUUIDs:%@
%{public}@associateFaceCropsWithUUIDs:%@ toPersonWithUUID:%@
%{public}@Writing updated userDefinedPersonLinksByHome[%@] to disk
%{public}@Stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@ detected, attempting to remove...
%{public}@Stale model path no longer on disk, proceeding with building persons model...
%{public}@Persisted VNPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@Did not remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, no model found
%{public}@Error removing user defined person links file: %@
%{public}@Removed userDefinedPersonLinksByHome for homeUUID: %@
%{public}@Removed VNPersonsModel for homeUUID: %@ sourceUUID:%@
%{public}@Unable to build equivalency map for homeUUID: %@, error: %@
%{public}@Failure to lookup equivalency cell for %@ (equivalencyCellForHome is%@ nil)
%{public}@Found nil torsoToFaceCrop for home %@ with non-nil model!
%{public}@Unable to retrieve torsoprints for person: %@, %@
%{public}@Person %@ has %lu torsoprints
%{public}@Received torso annotation with no identifier: %@
%{public}@Received torso annotation with no classification corresponding to the linkedEntityUUID: %@
%{public}@Created new torso model with %lu persons and %d total torsoprints for home: %@
%{public}@Successfully updated torso model and face crop map for home: %@
%{public}@Resetting torso model and wiping data
%{public}@Successfully deleted torso data at path: %@
%{public}@Failed to delete torso directory at path: %@, error: %@
%{public}@Torso model version on disk doesn't match current version
%{public}@Found stale torso_to_facecrop file
%{public}@There is no current torso model for home: %@
%{public}@Torso model predicted person %@ with confidence %f
%{public}@Persons Model Storage Path:%@
%{public}@Failed to parse Home UUID from path: %@
%{public}@Failed to load External HMIPersonsModel at path: %@, error: %@
%{public}@Loaded External HMIPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@No home model found for homeUUID: %@
%{public}@Failed to load Home HMIPersonsModel at path: %@, error: %@
%{public}@Loaded Home HMIPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@Loaded %lu user defined equivalencies found for home: %@
%{public}@No user defined equivalencies found for home: %@ (reason: %@)
%{public}@Got nil for torso model file path, error: %@
%{public}@No torso model found for home %@ at path: %@
%{public}@Failed to load torsoToFaceCrop map, error: %@
%{public}@Failed to load torso model at path: %@, error: %@
%{public}@Successfully loaded torso model and face crop map for home: %@
%{public}@Resetting HMIPersonsModelManager
%{public}@Recipe doesn't have a custom learningRate value, learning rate in model definition is used for training: %e
%{public}@Recipe has a custom learningRate value, learning rate in recipe is used for training: %e
%{public}@Calculating pre-training loss value
%{public}@trainingCallback %lu, loss: %f
%{public}@Training was skipped because %@ is YES.
%{public}@Training Started
%{public}@Training Finished
%{public}@Saving trained model to %@
%{public}@Successfully saved trained model at %@
%{public}@Timer fired, updating external persons model
%{public}@Settings have disabled face classification, removing external persons model
%{public}@Settings have enabled face classification, updating external persons model
%{public}@Failed to remove persons model, error:%@, retrying...
%{public}@Submitted persons model remove task, taskID:%u, retryOnError:%@
%{public}@Cannot decode additional streams using H.264, %lu H.264 decoders are already being used.
%{public}@Cannot transcode additional streams using H.265, %lu H.265 encoders are already being used, trying with H.264.
%{public}@Cannot transcode additional streams, %lu H.264 encoders are already being used.
%{public}@Cannot generate timelapse, %lu H.264 encoders are already being used.
%{public}@%@
%{public}@Clustering successful
%{public}@Clustering error
%{public}@Initializing HMIVisionSession
%{public}@Releasing vision session after period of inactivity
%{public}@Unloading model at path %@ after period of inactivity
%{public}@Error creating activity zone result directory: %@
%{public}@Activity zone file path:%@
%{public}@Error converting activity zone results to JSON: %@
%{public}@Error writing activity zone results JSON to file: %@
%{public}@motionScore %f
%{public}@Inclusion zone:%@ intersecting with:(%@) Object coordinate %@ insetThreshold %f
%{public}@Exclusion zone:%@ intersecting with:(%@) Object coordinate %@ insetThreshold %f
%{public}@Events after activity zone filtering:(%@) Object coordinate %@ insetPercentage %f
%{public}@Add motion-vector stationary event %@
%{public}@Replace matched stationary event %@ for %@
%{public}@Add edge-distance stationary event %@
%{public}@Encrypted Training Result
%{public}@Preference %@ is now %@, previously was %@
%{public}@Error fetching face crops for person:%@, error:%@
%{public}@Already started listening for the notification
%{public}@Unsupported aspect ratio: (%d, %d)
%{public}@Adding Candidate: %@
%{public}@Selected: %@
%{public}@Synthesizing Motion Detections, Target: %@
%{public}@Unable to read the asset %@
%{public}@Finish re-encoding %.3f > %.3f
%{public}@Unable to get fragment %@ from AssetWriter
%{public}@Unable to init face detector %@
%{public}@Skip the frame @ %.3fs due to analyzer failure
%{public}@Skip the frame @ %.3fs due to blurring failure
%{public}@Failed to convert YCbCr to RGBA (%@)
%{public}@Failed to clone RGBA source image
%{public}@Failed to blur entire image (vImage_Error = %zd)
%{public}@Failed to copy blurred patch (vImage_Error = %zd)
%{public}@Failed to convert RGBA to YCbCr (%@)
%{public}@Fetching persons for HMICleanupImpureHomePersonsOperation
%{public}@Error fetching persons, error:%@
%{public}@Fetched %lu persons
%{public}@Fetching face crops for person: %@
%{public}@Error fetching facecrops for person:%@, error:%@
%{public}@Fetched %lu face crops for person: %@
%{public}@Ignoring error fetching faceprints for person:%@, error:%@
%{public}@Error faceprinting face crops for person:%@, error:%@
%{public}@Number of faceprints to cluster: %lu
%{public}@Clustering error:%@ treating identity: %@ as impure
%{public}@0 or 1 cluster exists, treating identity: %@ as pure
%{public}@Unnamed person %@ has %lu clusters, treating as impure
%{public}@Named person %@ with atleast 1 personLink has %lu clusters, treating as impure
%{public}@%lu clusters exists, for person %@ trying to club clusters using vip model
%{public}@Cluster size: %lu
%{public}@Error while creating vnpersonsmodel: %@, treating identity as impure
%{public}@Failed to predict using VNPersonsModel, error: %@, treating identity as impure
%{public}@Error while removing facecrops %@
%{public}@Reassociating %lu face crops to person UUID: %@
%{public}@Error while reassociating facecrops %@
%{public}@Error creating directory %@
%{public}@Error fetching attributes of the file: %@ at: %@. Attempting to delete it
%{public}@Deleted %@ to free up some space, error: %@
%{public}@Error while deleting %@ to free up some space, error: %@
%{public}@Disk buffer size of %@: %ld KB
%{public}@Archive familiar face data for home: %@ person: %@
%{public}@Cannot archive familiar face data for person %@, error: %@
%{public}@Couldn't get URL for home archives, error: %@
%{public}@Saving archived familiar face data for home: %@ person: %@ to: %@
%{public}@Couldn't save FF archive
%{public}@Saved FF archive
%{public}@Skipping person %@ due to nil or 0 face crops
%{public}@Person %@ has crops with unknown source, reassociating them
%{public}@Skipping person %@ as all crops are either old or have a non-unknown source
%{public}@Removing %lu sentinel facecrops for person %@
%{public}@0 faceprints for person: %@, skipping
%{public}@Found pure identity, skipping person %@
%{public}@Removing person %@ and associated crops
%{public}@HMICleanupImpureHomePersonsOperation exiting early because operation was canceled.
%{public}@Completed CleanImpureHomePersonsOperation
%{public}@CleanImpureHomePersonsOperation encountered %d failures
%{public}@Error while removing persons %@
%{public}@Spawning CleanupImpureHomePersonsOperation for %@ before home person clustering
%{public}@CleanupImpureHomePersonOperation finished with error:%@
%{public}@CleanupImpureHomePersonOperation finished successfully
%{public}@Error performing cloud pull:%@
%{public}@Fetching persons
%{public}@Fetched %lu persons (%lu unnamed)
%{public}@Exiting early because task was canceled.
%{public}@Skipping named person
%{public}@Deleting unnamed person %@ (0 face crops)
%{public}@Deleting unnamed person %@ (age = %f seconds)
%{public}@Error fetching face crops:%@
%{public}@Error fetching faceprints:%@
%{public}@Storing %lu newly created faceprints
%{public}@Error saving new faceprints:%@
%{public}@Removing %lu faceprints from old versions
%{public}@Error removing faceprints from old versions:%@
%{public}@Clustering error:%@
%{public}@Number of clusters: %lu
%{public}@Cluster of size %lu beneath threshold of %d
%{public}@Face prediction error:%@
%{public}@Assigning cluster to existing person with UUID: %@
%{public}@Error adding new persons:%@
%{public}@Error associating face crops with person (%@): %@
%{public}@Finished calls to associateFaceCropsWithUUIDs
%{public}@Error removing person with UUID:%@, error:%@
%{public}@Succesfully removed person %@
%{public}@Error fetching faceprints for face crop UUIDs:%@, error:%@
%{public}@Storing newly created faceprints: %@
%{public}@Removing existing faceprints at other versions: %@
%{public}@Failed to generate persons model, error:%@
%{public}@Invalid configuration: isExternalLibrary is NO but self.dataSource does not conform to HMIHomePersonManagerDataSource protocol!
%{public}@Successfully updated persons model
%{public}@WARNING: Model has %lu named persons -- limit supported is %d
%{public}@Error fetching faces to subsample for %@: %@
%{public}@Fetched 0 training faces for %@, this would remove all face crops! Skipping face crop removal.
%{public}@Expected subsampling to leave no more than %d, but got %lu faces selected. Enforcing limit.
%{public}@Subsampling will retain %lu from a total of %lu faces for %@
%{public}@Deleting a total of %lu face crops after subsampling
%{public}@Selected %lu persons for subsampling faces but did not choose any face crops to delete!
%{public}@Reading and injecting synthesized events from path %@
%{public}@Creating analysis state update with %lu torso annotations
%{public}@Error while retrieving facecrop from torsomodel for personUUID: %@ homeUUID: %@
%{public}@Couldn't retrieve linked predictions from torsomodel for personUUID: %@ homeUUID: %@ error: %@
%{public}@Dropping Face event: %@ due to torso recognition
%{public}@Creating face recognition event: %@ from torso recognition event: %@
%{public}@Faceprinting failed for face: %@, error: %@
%{public}@Face: %@ didn't produce any classifications
%{public}@Torsoprinting failed for torso: %@, error: %@
%{public}@Unable to archive task %@: %@
%{public}@There is no task to schedule
%{public}@Error fetching unassociated face crops:%@
%{public}@Error associating face crops (num UUIDs:%lu), to personUUID: %@ with source: %@ error:%@
%{public}@Succesfully associated face crops (num UUIDs %lu) to person UUID: %@ for source: %@
%{public}@Events file "%@" does not exist.
%{public}@Cannot read events from file "%@", error: %@
%{public}@Cannot load events file, exception: %@
%{public}@Video decoder is not running, ignoring %@
%{public}@Sample buffer has no samples, skipping.
%{public}@Invalid DTS, expected > %@, got %@, skipping.
%{public}@Restarting decoder because format description changed.
%{public}@Decoded sample is out of PTS order, sample: %@
%{public}@Decoded sample has an invalid PTS, sample: %@
%{public}@Decoder is already in a failed state.
%{public}@Decompression session decoded frames after decoder was deallocated, ignoring frames.
%{public}@Frame decode error %d
%{public}@Cannot add video input.
%{public}@Cannot add audio input.
%{public}@Failed to start writing, assetWriter.status: %ld, assetWriter:.error: %@
%{public}@Started writing at %@
%{public}@didOutputSegmentData segmentType: %ld
%{public}@Trying to recover by adjusting trim duration from %@ to the minimum trim duration: %@
%{public}@Asset writer has failed fatally, ignoring %@
%{public}@Failed to write to asset writer, error %@
%{public}@Dropped   %@ because an input for the media type was not found.
%{public}@Dropped    %@ because asset writer is waiting for a sync sample.
%{public}@Dropped    %@ because of input error %@
%{public}@Video / Audio Drift (video is ahead by) %+4.3f
%{public}@Dropped    %@ because an input %@ is not ready for more media data.
%{public}@Asset writer has failed fatally, ignoring flush.
%{public}@We don't have anything to flush, ignoring flush.
%{public}@Finished waiting for flushSegment, assetWriter.status: %ld, assetWriter.error: %@
%{public}@Number of all face observations: %ld
%{public}@Invalid entry in userDefinedPersonLinks: %@
%{public}@All links for %@ in userDefinedPersonLinks are invalid
%{public}@Skipping person who belongs to user defined equivalency cell: %@
%{public}@Comparing persons (%@, %@)
%{public}@Equivalency determined between pair: (%@, %@)!
%{public}@Cannot add to matching equivalency cell because it already has entry from this source: %@
%{public}@Failed to update persons model, error:%@, retrying...
%{public}@Failed to update persons model, error:%@
%{public}@Submitted persons model update task, taskID:%u, retryOnError:%@
%{public}@Skip torsoEvent with extreme roll (%.0f deg)
%{public}@Skip torsoEvent with extreme aspect ratio (w/h) (%.2f) pixelDim:(%f, %f) bbox:(%f, %f)
%{public}@Skip torsoEvent with torsoBox close to roi boundary. Dist: (%.4f)
%{public}@Failed to predict using torso vip model
%{public}@Creating analyzer with identifier: %@, configuration: %@
%{public}@VideoAnalyzerReport saved (%@)
%{public}@Dynamic configuration is missing for time: %@, using the first instead.
%{public}@Received Message: %@
%{public}@Unknown %@
%{public}@Sent Message Reply: %@
%{public}@Camera, Manufacturer: %@, Model: %@, Fragment: %@, Sanitized Fragment Data: %@
%{public}@Finish Analyzer
%{public}@Analyzer has failed, ignoring finish.
%{public}@Video file %@ size is too large, maximum allowed is (%ld MB), no longer appending fragments.
%{public}@Disk buffer size remaining in %@, %ld MB
%{public}@Appending fragment to %@
%{public}@Saving fragment to %@
%{public}@Video format should not change.
%{public}@Audio format should not change.
%{public}@-[HMIVideoAnalyzerServer dealloc]
%{public}@Analyzer has failed or was cancelled, ignoring sample buffer.
%{public}@Analyzer has failed or was cancelled, ignoring flush.
%{public}@AnalyzerEvents(PTS:%.2f/%.2f): %@ %@
%{public}@Bundling Fragment Result, timeRange: %@, frames: [%@], thumbnails [%@]
%{public}@Analyzer frame result buffer should be empty. %@
%{public}@Thumbnail buffer should be empty. %@
%{public}@Timelapse encoder failed, ignoring: error: %@
%{public}@Generated Fragment: %@ Outcome: %@ Max Confidence Events: %@
%{public}@Analyzer Failed: %@
%{public}@Analyzer is already in a failed state.
%{public}@Sending Result: %@
%{public}@analysisFPS changing from: %f to: %f
HMIExternalPersonDataSourceDisk
HMIExternalPersonManagerDataSource
HMIPersonManagerDataSource
NSObject
HMITorsoQuality
HMFLogging
HMIHTMLReportBox
HMIHTMLReport
HMIMutableCluster
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMIVideoAnalyzerEventFace
HMIStoreFaceprintsOperation
HMIDataReader
HMIVideoEventEntry
HMIVideoEvent
HMIVideoEventBuffer
HMIVideoTimelineEntry
HMIVideoTimeline
HMIVideoTimelineProfiler
HMITimeIntervalAverage
HMIVideoAnalyzerEventMotion
HMITorsoprinter
HMIRemoveFaceCropsOperation
HMIHomePersonManager
HMFTimerDelegate
HMIStoreFaceCropOperation
HMIStoreFaceprintOperation
HMICameraVideoFrame
HMIVisionUtilities
HMIPairwiseMatch
HMIThermalMonitorService
HMIThermalMonitor
HMIMemorySampler
HMIThermalPressureMonitor
HMISignificantActivityFcosDetector
HMIVideoAssetReader
HMIHomeKitClient
HMHomeManagerDelegateAdapter
HMHomeManagerDelegate
HMISignpost
HMIFaceQualityFilterModelInput
MLFeatureProvider
HMIFaceQualityFilterSVM
HMIVideoNode
HMIVideoProcessingNode
HMIVideoAnalyzerProcessingNode
PFLBackgroundRunner
HMIExternalPersonDataSourceHomeKit
HMI_CVML_Error
HMIPersonFaceCrop
NSCopying
NSSecureCoding
NSCoding
HMIVideoAnalyzerFrameResult
HMIBackgroundEstimator
HMIMemoryAVAsset
AVAssetResourceLoaderDelegate
MovingAverageEntry
MovingAverage
HMICameraVideoFrameResult
HMIVideoAnnotationParserRecord
HMIVideoAnnotationParserTrack
HMIVideoAnnotationParser
HMIDESMutableFloatArray
HMIFaceClassifierVIP
HMIFaceClassifier
HMIDESDetection
HMIDESDatasetSample
HMIDESDataset
HMIInputFeatureProvider
HMINMSConfiguration
HMIObjectDetection
HMIObjectDetectionUtils
HMIPersonBlob
HMIPersonTracker
HMIVideoFrameAnalyzerResult
HMIVideoFrameAnalyzer
HMIVideoFrameSamplerDelegate
HMIVideoFrameAnalyzerDelegateAdapter
HMIVideoFrameAnalyzerDelegate
HMIVideoAnalyzerReportMatch
HMIVideoAnalyzerReportRecord
HMIVideoAnalyzerMutableReportComparison
HMIVideoAnalyzerMutableReportSession
HMIVideoAnalyzerMutableReport
HMIFaceCrop
HMIVideoRetimer
HMIVideoRetimerDelegateAdapter
HMIVideoRetimerDelegate
HMICamera
HMITask
HMIHomeTask
HMIEmptyTask
HMITaskServiceServer
HMITaskService
HMIFetchPersonsOperation
HMFObject
HMITorsoRecognition
HMIUpdatedFaceprintsResult
HMIFaceprinter
HMIFaceDetectorVision
HMIFaceDetector
HMIFaceprint
HMIFeedbackClipMetadata
HMIFeedbackClipMetadataGenerator
HMIPoint
HMIHomePersonManagerSettings
NSMutableCopying
HMIMutableHomePersonManagerSettings
HMIUpdateTorsoModelTask
HMIFeedbackSession
NSURLSessionDelegate
HMIFeedbackSubmitClipOperation
HMIFeedbackTask
HMIFeedback
HMIFaceClassification
HMIHomePersonDataSourceInMemory
HMIHomePersonManagerDataSource
HMIPersonsModelsSummaryTask
HMIFaceMisclassificationTask
HMIRemovePersonsModelTask
HMIVideoFrameGenerator
HMIPersonManager
HMIConfidence
HMIError
HMIVideoFragment
HMISessionEntityManager
HMIRemovePersonsOperation
HMIRemoveFaceprintsOperation
HMIAnalysisStateUpdate
HMIAnalysisStateManager
HMIVideoAnnotator
HMISystemResourceUsageMonitorImpl
HMIVideoAnalyzerResultFilter
HMIVideoAnalyzerResultActivityZoneFilter
HMIPersonSourceUUIDPair
HMIPerson
HMIPersonsModelSummary
HMIPersonsModel
HMIJSONArchiver
HMIJSONUnarchiver
HMIFaceUtilities
HMITorsoprint
HMITorsoAnnotation
HMIVideoEncoder
HMIVideoEncoderDelegateAdapter
HMIVideoEncoderDelegate
HMIHomePersonDataSourceHomeKit
HMIExternalPersonManagerSettings
HMIMutableExternalPersonManagerSettings
HMIAnalytics
HMIPersonsModelsSummary
HMIPersonsModelPrediction
HMIPersonsModelManager
HMIDESLayerParameters
HMIDESTrainingResult
HMIDESTrainer
HMIVideoAnalyzerResultOutcome
HMIExternalPersonManager
HMIRemovePersonsModelOperation
HMIVideoAnalyzerSchedulerJSONLogger
HMIVideoAnalyzerScheduler
HMISystemResourceUsageMonitorDelegate
HMIFFArchive
HMIGreedyClustering
HMIVideoFrameSampler
HMIVideoFrameIntervalSampler
HMIVideoFrameSamplerDelegateAdapter
HMICIFilterAttributeValue
HMICIFilterAttribute
HMICIFilter
HMIVisionSession
HMIMLModel
HMIFaceQualityEntropyOfLaplacian
HMIVideoAnalyzerFragmentResult
HMICameraActivityZone
HMIVideoAnalyzerConfiguration
HMIVideoAnalyzerDynamicConfiguration
HMIStationaryObject
HMIVideoTemporalEventFilter
HMIAnalysisService
HMIVideoAnalyzerEventPerson
HMIDESPackageResult
HMIDESResultPackager
HMIPreference
HMIHomePersonDataSourceDisk
HMIFetchPersonFaceCropsOperation
HMIVideoAnalyzerBlob
HMIVideoAnalyzerTrack
HMINotifydObserver
HMIVideoFrameTrackerFrameCandidate
HMIVideoFrameTracker
HMIVideoFrameTrackerDelegateAdapter
HMIVideoFrameTrackerDelegate
HMIVideoAnalyzerEventVehicle
HMIFeedbackVisionProcessor
HMICleanupImpureHomePersonsOperation
HMIClusteringTaskSummary
HMIHomePersonClusteringTask
HMIFetchFaceprintsForFaceCropsOperation
HMIUpdatePersonsModelTask
HMICameraVideoFrameAnalyzerSignificantActivity
HMICameraVideoFrameAnalyzer
HMIDESBackgroundTask
HMIVideoFrame
HMIVideoCommandBuffer
HMIVideoCommandBufferDelegateAdapter
HMIVideoCommandBufferDelegate
HMIVideoAnalyzerEventPet
HMIHLSPlaylist
HMIFetchUnassociatedFaceCropsOperation
HMIAssociateFaceCropsOperation
HMIVideoAnalyzerEvent
HMITorsoClassification
HMIVideoAnalyzerEventPackage
HMIVideoDecoder
HMIVideoDecoderDelegateAdapter
HMIVideoDecoderDelegate
HMIVideoAssetWriter
AVAssetWriterDelegate
HMIVideoAssetWriterDelegateAdapter
HMIVideoAssetWriterDelegate
HMIPersonsModelEquivalencyTable
HMIUpdatePersonsModelOperation
HMIMotionVector
HMIMotionDetection
HMIMotionDetector
HMITorsoClassifier
HMIVideoFrameSelector
HMIVideoFrameSelectorDelegateAdapter
HMIVideoFrameSelectorDelegate
HMIVideoAnalyzerState
HMIFaceRecognition
HMIVideoAnalyzer
HMIVideoAnalyzerDelegatePrivate
HMIVideoAnalyzerDelegate
HMIVideoAnalyzerServer
HMIVideoAnalyzerDelegateAdapter
HMIPersonDataSourceDisk
HMIVideoAnalyzerEventTorso
T@"HMFTimer",R,V_analyticsTimer
.cxx_destruct
T@"HMIVideoEncoder",&,V_encoder
CMTimeValue
T@"NSArray",R,V_levelThresholds
JSONObjectStringWithObject:
T@"NSData",R,V_separableSegment
JSONObjectWithData:options:error:
T@"VNSession",R
T#,&,V_eventClass
T@?,C,V_encoderDidFailWithError
T#,R,V_eventClass
TB,V_supportsFaceClassification
T@"<HMICameraVideoFrameAnalyzer>",R,V_cameraVideoFrameAnalyzer
T^f,R,N
T@"<HMIHomePersonManagerDataSource>",R,V_dataSource
Td,R,V_duration
T@"<HMIPersonManagerDataSource>",R,V_dataSource
Tf,R,V_blobArea
T@"<HMISystemResourceUsageMonitorDelegate>",W
Tq,N,V_systemResourceUsageLevel
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T{?=qiIq},V_backgroundTimeStamp
T@"<HMIVideoAssetWriterDelegate>",W,V_delegate
T{?=qiIq},V_lastSampleBufferDTS
T@"<HMIVideoDecoderDelegate>",W,V_delegate
T{?=qiIq},V_maxFragmentDuration
T@"<HMIVideoFrameAnalyzerDelegate>",W,V_delegate
T{HMIVideoEncoderDataRate=qq},N
T@"<HMIVideoFrameSelectorDelegate>",W,V_delegate
_analyzerEvents
T@"<HMIVideoRetimerDelegate>",W,V_delegate
_blobID
T@"AVAssetWriterInput",R,V_audioInput
_blurRadiusForEvents:imageSize:
T@"HMFOSTransaction",&,N,V_transaction
_camera
T@"HMFTimer",R,V_preferenceCacheFlushTimer
_classification
T@"HMFTimer",R,V_watchdogTimer
_client
T@"HMHomeManager",&,V_homeManager
_encode
T@"HMIAnalysisStateManager",&,V_analysisStateManager
_faceClassifier
T@"HMICIFilterAttributeValue",R,V_value
_ffData
T@"HMICameraVideoFrame",R,V_frame
_inactiveTracks
T@"HMIConfidence",R,V_confidence
_lastAudioPresentationTimeStamp
T@"HMIDESMutableFloatArray",R
_losses
T@"HMIDESMutableFloatArray",R,V_faceCentroid
_modelSummaries
T@"HMIDESMutableFloatArray",R,V_weights
_motionDetector
T@"HMIFaceClassifierVIP",R,V_faceClassifier
_operationQueue
T@"HMIFaceQualityFilterSVM",R,V_faceAestheticQualityFilter
_person
T@"HMIFaceRecognition",&,V_faceRecognition
_preferredOutputSegmentInterval
T@"HMIFaceprint",R,V_faceprint
_recall
T@"HMIFeedbackSession",R,V_feedbackSession
_report
T@"HMIHTMLReport",R,V_report
_source
T@"HMIHomePersonManager",&,V_homePersonManager
_status
T@"HMIMLModel",R
_systemResourceUsageMonitorImpl
T@"HMINMSConfiguration",R,V_nmsConfiguration
_taskID
T@"HMIPersonFaceCrop",R,V_faceCrop
_tracks
T@"HMIPersonsModelManager",R,V_personsModelManager
_updateRunningStd:withAuxBuffer:runningMean:runningSquaredMean:
T@"HMIPreference",R
addTorsoprints:
T@"HMISignificantActivityFcosDetector",R,V_significantActivityFcosDetector
appendFragmentResult:assetPath:
T@"HMITimeIntervalAverage",R,V_sampleBufferDelay
average
T@"HMITorsoClassification",R,V_classification
bufferFillRatio
T@"HMITorsoRecognition",R,V_torsoRecognition
bundleForClass:
T@"HMITorsoprinter",R,V_torsoprinter
classifications
T@"HMIVideoAnalyzerConfiguration",R,C,V_configuration
compact
T@"HMIVideoAnalyzerConfiguration",R,V_configuration
confidenceLevel
T@"HMIVideoAnalyzerDynamicConfiguration",R,V_configuration
currentCalendar
T@"HMIVideoAnalyzerEvent",R,V_event
dateFromString:
T@"HMIVideoAnalyzerEventTorso",R,V_torso
decoder
T@"HMIVideoAnalyzerMutableReport",R,V_report
defaultRecognizabilityModelPath
T@"HMIVideoAnalyzerResultOutcome",R,V_outcome
detectFacesInPixelBuffer:error:
T@"HMIVideoAssetReader",R,V_reader
enabled
T@"HMIVideoAssetWriter",&,V_timelapseAssetWriter
encryptedDataWithPublicKey:inPlaceDataFloatNumbers:count:error:
T@"HMIVideoEncoder",&,V_timelapseEncoder
eventConfidenceThresholdsMedium
T@"HMIVideoEventBuffer",R,V_frameAnalyzerFrameResultBuffer
expectedClasses
T@"HMIVideoFragment",R,V_fragment
externalToExternalEquivalencies
T@"HMIVideoFrameAnalyzer",R,V_frameAnalyzer
faceRecognition
T@"HMIVideoFrameSampler",R,V_frameThumbnailSampler
firmwareVersion
T@"HMIVideoFrameSelector",R,V_frameSelector
forceKeyFrameOnNextEncodedFrame
T@"HMIVideoFrameTrackerFrameCandidate",&,V_candidate
getBytes:range:
T@"HMIVideoTimeline",R,V_timeline
handleRemovedFaceprintWithUUID:
T@"HMPhotosPersonManager",&,V_photosPersonManager
hmiPrivateErrorWithCode:description:suggestion:underlyingError:
T@"MLModel",R
initWithDataSource:personUUIDs:
T@"MLModel",R,V_scalerModel
initWithLength:
T@"MovingAverage",R,V_average
initWithProductClass:workQueue:
T@"NSArray",&,V_motionDetections
initWithTaskID:
T@"NSArray",R,C,N
inputDimensions
T@"NSArray",R,V_activityZones
isCurrentDevice
T@"NSArray",R,V_attributes
isEqualToArray:
T@"NSArray",R,V_falseNegativeKeys
isProxy
T@"NSArray",R,V_frameResultIndices
T@"NSArray",R,V_homePersonsAndFaceCrops
levelThresholds
T@"NSArray",R,V_losses
lowercaseString
T@"NSArray",R,V_motionVectors
message
T@"NSArray",R,V_offsetsZeroFeatureValueNames
minFrameQuality
T@"NSArray",R,V_records
multiArrayValue
T@"NSArray",R,V_samples
na_any:
T@"NSArray",R,V_thumbnails
na_setByRemovingObjectsFromSet:
T@"NSArray",R,V_tracks
numberWithBool:
T@"NSArray",R,V_yawsFeatureValueNames
opacity
T@"NSData",&,V_assetData
outcome
T@"NSData",&,V_timelapseInitializationSegment
personCreatedDateFromFaceCrops:
T@"NSData",R,&,N
persons
T@"NSData",R,C,V_data
preTrainingLoss
T@"NSData",R,V_data
preferenceCache
T@"NSData",R,V_initializationSegment
prevFrameResult
T@"NSData",R,V_result
printWithScale:
T@"NSDate",R,C,V_dateCreated
quality
T@"NSDate",R,V_date
regionOfInterestForMotionDetections:foregroundEvents:frameSize:
T@"NSDate",R,V_startTime
requestWithURL:
T@"NSDictionary",&,V_classMap
requestedOffset
T@"NSDictionary",R
residentDevices
T@"NSDictionary",R,V_annotationScores
samples
T@"NSDictionary",R,V_clipMetadata
sequenceNumbers
T@"NSDictionary",R,V_equivalencyTablesByHome
sessionEntities
T@"NSDictionary",R,V_ffData
setAnalysisFPS:
T@"NSDictionary",R,V_homeMetadata
setAssetWriterDidFailWithError:
T@"NSDictionary",R,V_metricWithLabels
setContentType:
T@"NSDictionary",R,V_personsModelsByHome
setFrameSelectorDidSelectFrame:
T@"NSDictionary",R,V_thresholdWithLabels
setMaxConcurrentOperationCount:
T@"NSDictionary",R,V_torsoToFaceCropByHome
setMaxKeyFrameIntervalDuration:
T@"NSDictionary",R,V_userInfo
setNumberOfFaceprintsClustered:
T@"NSError",R
setPretendProductTypeIsUnknown:
T@"NSMutableArray",&,N,V_queue
setRunningMean:
T@"NSMutableArray",&,V_torsoprints
setTensorNamed:withValue:error:
T@"NSMutableArray",R,V_backgroundEvents
setTransaction:
T@"NSMutableArray",R,V_fragments
setWeakDecoder:
T@"NSMutableArray",R,V_motionDetections
significantActivityFcosDetector
T@"NSMutableArray",R,V_previousPersons
strides
T@"NSMutableArray",R,V_stationaryObjects
stringByAppendingPathExtension:
T@"NSMutableDictionary",R,N,V_preferenceCache
submitFeedbackWithCameraProfileUUID:clipUUID:completionHandler:
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
summary
T@"NSMutableDictionary",R,V_personToFaceCrops
systemResourceUsageDidChangeTo:
T@"NSMutableDictionary",R,V_sessionEntities
thumbnailBuffer
T@"NSMutableDictionary",R,V_tracks
torsoAnnotation
T@"NSMutableIndexSet",&,V_personIndices
torsoprintUUIDs
T@"NSMutableSet",R,V_eventClasses
T@"NSNumber",R,V_confidence
weights
T@"NSNumber",R,V_metricDefault
T@"NSNumber",R,V_roll
.cxx_construct
T@"HMIVideoDecoder",R,V_decoder
CGAffineTransformValue
T@"NSArray",R,V_layerParameters
JSONObject
T@"NSArray",R,V_sequenceNumbers
JSONObjectStringWithObject:pretty:options:
T@"NSUUID",R,V_linkedEntityUUID
JSONObjectWithObject:options:
T@?,C,V_decoderDidFailWithError
T#,R
TB,R,V_external
T@"<HMIAnalysisStateManagerDelegate>",W,V_delegate
TQ,R,V_capacity
T@"<HMIExternalPersonManagerDataSource>",W,N,V_dataSource
T^{__CVBuffer=},R,V_pixelBuffer
T@"<HMIHomePersonManagerDataSource>",W,N,V_dataSource
Td,R,V_timeSinceAnalyzerStarted
T@"<HMIPersonManagerDataSource>",W,N,V_dataSource
Ti,V_nextTaskID
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
Tq,V_decodeMode
T@"<HMIVideoAnalyzerDelegate>",W,V_delegate
T{?=qiIq},V_foregroundTimeStamp
T@"<HMIVideoCommandBufferDelegate>",W,V_delegate
T{?=qiIq},V_lastSampleBufferPTS
T@"<HMIVideoEncoderDelegate>",W,V_delegate
T{CGPoint=dd},R
T@"<HMIVideoFrameSamplerDelegate>",W,V_delegate
_analyticsTimer
T@"<HMIVideoFrameTrackerDelegate>",W,V_delegate
_biases
T@"AVAssetWriter",&,V_assetWriter
_blobsFromAssignment:timeStamp:
T@"AVAssetWriterInput",R,V_videoInput
_buffer
T@"HMFOSTransaction",&,V_transaction
_cameraMetadata
T@"HMFTimer",R,V_tick
_classificationThresholdUnknown
T@"HMFWeakObject",&,V_weakDecoder
_didUpdateHomes
T@"HMHomePersonManager",&,V_homePersonManager
_events
T@"HMIBackgroundEstimator",&,V_backgroundEstimator
_faceprintUUIDs
T@"HMICamera",&,V_camera
_frameAnalyzerFrameResultBuffer
T@"HMIClusteringTaskSummary",R,V_summary
_l2Norm
T@"HMIDESDataset",R,V_data
_lastVideoPresentationTimeStamp
T@"HMIDESMutableFloatArray",R,V_biases
_minorVersionFromVisionVersion:
T@"HMIDESMutableFloatArray",R,V_torsoCentroid
_motion
T@"HMIExternalPersonManagerSettings",R,V_settings
_numDidCreateTimelapseFragments
T@"HMIFaceCrop",R,V_faceCrop
_origin
T@"HMIFaceQualityFilterSVM",R,V_faceRecognizabilityFilter
_points
T@"HMIFaceRecognition",R,V_faceRecognition
_reader
T@"HMIFaceprinter",R,V_faceprinter
_recognizeFaces
T@"HMIGreedyClustering",R,V_clusterer
_result
T@"HMIHomeKitClient",R,V_homeKitClient
_stageZero_expireUnnamedPersons
T@"HMIHomePersonManagerSettings",R,V_settings
_stream
T@"HMIMotionDetector",R,V_motionDetector
_targetInterval
T@"HMIPerson",R,V_person
_timelapseInitializationSegment
T@"HMIPersonsModelManager",R
_unrecognizable
T@"HMIPersonsModelSummary",R
addDate:atTime:
T@"HMISessionEntityManager",R,V_sessionEntityManager
allKeys
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
arrayWithArray:
T@"HMITorsoAnnotation",R,V_torsoAnnotation
base64EncodedStringWithOptions:
T@"HMITorsoClassifier",R,V_torsoClassifier
bufferWillFlush
T@"HMITorsoprint",R,V_torsoprint
classPaddingMap
T@"HMIVideoAnalyzerBlob",R
classifyTorsoEvent:regionOfInterest:pixelBuffer:homeUUID:error:
T@"HMIVideoAnalyzerConfiguration",R,V_analyzerConfiguration
computeJunkScoreForPixelBuffer:
T@"HMIVideoAnalyzerDynamicConfiguration",&,V_dynamicConfiguration
containsObject:
T@"HMIVideoAnalyzerDynamicConfiguration",R,V_dynamicConfiguration
dataWithLength:
T@"HMIVideoAnalyzerEventFace",R,V_face
dealloc
T@"HMIVideoAnalyzerFrameResult",&,V_prevFrameResult
defaultConfidenceThresholdsHigh
T@"HMIVideoAnalyzerResultOutcome",R
defaultRevision
T@"HMIVideoAnalyzerState",R,V_state
dictionaryValue
T@"HMIVideoAssetWriter",&,V_assetWriter
encoder
T@"HMIVideoCommandBuffer",R,V_commandBuffer
T@"HMIVideoEventBuffer",R,V_dynamicConfigurationBuffer
eventForClass:boundingBox:UUID:
T@"HMIVideoEventBuffer",R,V_thumbnailBuffer
externalLibrary
T@"HMIVideoFrame",R,V_frame
faceBoundingBox
T@"HMIVideoFrameSampler",R,V_frameSampler
feedbackSession
T@"HMIVideoFrameSampler",R,V_frameTimelapseSampler
flushAndGetAnalysisStateUpdateForHome:enableFaceClassification:
T@"HMIVideoFrameTracker",R,V_frameTracker
frameId
T@"HMIVideoTemporalEventFilter",R,V_temporalEventFilter
getTensorNamed:
T@"HMIVisionSession",R
handleSampleBuffer:outputFrame:
T@"MLModel",&,V_model
initWithConfidence:boundingBox:
T@"MLModel",R,V_mlModel
initWithInitializationSegment:separableSegment:sequenceNumbers:
T@"MLMultiArray",&,N,V_input
initWithPoints:
T@"NSArray",&,V_activityZones
initWithSource:
T@"NSArray",R
initWithTruth:prediction:score:
T@"NSArray",R,C,V_points
isAffectedDate:
T@"NSArray",R,V_allPersonsAndFaceCrops
isEmpty
T@"NSArray",R,V_detections
isPersonDataAvailableViaHomeKit
T@"NSArray",R,V_falsePositiveKeys
isSetup
T@"NSArray",R,V_frameResults
layerParameters
T@"NSArray",R,V_homes
limitEnforcedSubsetFromPersons:
T@"NSArray",R,V_motionDetections
maxNorm
T@"NSArray",R,V_offsetsOneFeatureValueNames
metricForLabel:
T@"NSArray",R,V_photosPersonsAndFaceCrops
mlModel
T@"NSArray",R,V_rollsFeatureValueNames
na_all:
T@"NSArray",R,V_scoresFeatureValueNames
na_map:
T@"NSArray",R,V_torsoprints
T@"NSArray",R,V_truePositiveKeys
objects
T@"NSCondition",R,V_condition
options
T@"NSData",&,V_initializationSegment
performCloudPullWithCompletion:
T@"NSData",R
personFaceCrops
T@"NSData",R,C
placeholderCopy
T@"NSData",R,C,V_dataRepresentation
predictedPersonUniqueIdentifier
T@"NSData",R,V_imageData
prepare
T@"NSData",R,V_jpegData
previousPersons
T@"NSDate",&,V_lastFragmentReceivedDate
protectionSpace
T@"NSDate",R,V_beginDate
records
T@"NSDate",R,V_startDate
release
T@"NSDate",R,V_targetDate
requestedLength
T@"NSDictionary",&,V_serviceResult
resetReferences
T@"NSDictionary",R,C,V_options
results
T@"NSDictionary",R,V_cameraMetadata
seekToEndOfFile
T@"NSDictionary",R,V_deviceInformation
session
T@"NSDictionary",R,V_faceCountsByPerson
T@"NSDictionary",R,V_highConfidenceThresholds
setAssetWriter:
T@"NSDictionary",R,V_mediumConfidenceThresholds
setCachePolicy:
T@"NSDictionary",R,V_personToEquivalencyCell
setDropTrimDurationAttachments:
T@"NSDictionary",R,V_targetEventClassRanks
setHomeManager:
T@"NSDictionary",R,V_torsoModelsByHome
setMaxFragmentAnalysisDuration:
T@"NSDictionary",R,V_userDefinedPersonLinksByHome
setNumFailures:
T@"NSError",&,V_error
setNumberStyle:
T@"NSMutableArray",&,N,V_faceprintUUIDs
setProducesCombinableFragments:
T@"NSMutableArray",&,N,V_torsoprintUUIDs
setShouldOptimizeForNetworkUse:
T@"NSMutableArray",R,V_analysisTimeStamps
setTorsoprints:
T@"NSMutableArray",R,V_blobs
setUsesCPUOnly:
T@"NSMutableArray",R,V_lines
settingsControl
T@"NSMutableArray",R,V_motionTimeStamps
skipped
T@"NSMutableArray",R,V_reportBuffer
stringByAppendingPathComponent:
T@"NSMutableArray",R,V_temporaryFileURLs
stringFromDate:
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
success
T@"NSMutableDictionary",R,V_inactiveTracks
suspend
T@"NSMutableDictionary",R,V_services
taskRunnerClass
T@"NSMutableDictionary",R,V_sessions
thumbnailHeight
T@"NSMutableDictionary",R,V_unknownFacesSavedCounts
torsoClassifier
T@"NSMutableSet",&,N,V_linkedEntityUUIDs
underlyingModel
T@"NSMutableSet",R,V_unassociatedFaceCrops
version
T@"NSNumber",R,V_label
T@"NSNumber",R,V_prediction
T@"NSNumber",R,V_thresholdDefault
T@"NSNumber",R,V_truth
T@"NSNumber",R,V_value
T@"NSNumber",R,V_yaw
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
T@"NSObject<OS_dispatch_queue>",R,V_delegateQueue
T@"NSObject<OS_dispatch_queue>",R,V_encoderQueue
T@"NSObject<OS_dispatch_queue>",R,V_inputQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
T@"NSOperationQueue",R,V_homeKitOperationQueue
T@"NSOperationQueue",R,V_operationQueue
T@"NSOutputStream",R,V_stream
T@"NSPointerArray",R,V_internalAnalyzers
T@"NSSet",&,V_externalPersonManagers
T@"NSSet",&,V_faceCrops
T@"NSSet",R
T@"NSSet",R,C,V_faceCropUUIDs
T@"NSSet",R,C,V_personLinks
T@"NSSet",R,N
T@"NSSet",R,V_analyzerEvents
T@"NSSet",R,V_backgroundEvents
T@"NSSet",R,V_classifications
T@"NSSet",R,V_createdAtCurrentVersion
T@"NSSet",R,V_events
T@"NSSet",R,V_existingAtCurrentVersion
T@"NSSet",R,V_existingAtOtherVersions
T@"NSSet",R,V_faceClassifications
T@"NSSet",R,V_faceCropUUIDs
T@"NSSet",R,V_faceprintUUIDs
T@"NSSet",R,V_faceprints
T@"NSSet",R,V_modelSummaries
T@"NSSet",R,V_personFaceCrops
T@"NSSet",R,V_personUUIDs
T@"NSSet",R,V_persons
T@"NSSet",R,V_predictedLinkedEntityUUIDs
T@"NSSet",R,V_removedPersonFaceCrops
T@"NSSet",R,V_torsoAnnotations
T@"NSSet",R,V_tracks
T@"NSSet",R,V_unassociatedFaceCrops
T@"NSString",&,V_logIdentifier
T@"NSString",C,V_source
T@"NSString",R
T@"NSString",R,C
T@"NSString",R,C,V_name
T@"NSString",R,V_boxesName
T@"NSString",R,V_classesName
T@"NSString",R,V_color
T@"NSString",R,V_feedbackServiceHost
T@"NSString",R,V_firmwareVersion
T@"NSString",R,V_identifier
T@"NSString",R,V_imageName
T@"NSString",R,V_inputFeatureValueName
T@"NSString",R,V_inputName
T@"NSString",R,V_key
T@"NSString",R,V_manufacturer
T@"NSString",R,V_message
T@"NSString",R,V_model
T@"NSString",R,V_name
T@"NSString",R,V_outputPath
T@"NSString",R,V_personsModelIdentifier
T@"NSString",R,V_text
T@"NSString",R,V_type
T@"NSString",R,V_weightsName
T@"NSURL",R,V_modelURL
T@"NSURL",R,V_networkPath
T@"NSURL",R,V_sourceURL
T@"NSURL",R,V_url
T@"NSURLSession",R,V_session
T@"NSUUID",&,V_blobID
T@"NSUUID",&,V_homeUUID
T@"NSUUID",R
T@"NSUUID",R,C,V_UUID
T@"NSUUID",R,C,V_faceCropUUID
T@"NSUUID",R,C,V_homeUUID
T@"NSUUID",R,C,V_identifier
T@"NSUUID",R,C,V_modelUUID
T@"NSUUID",R,C,V_personUUID
T@"NSUUID",R,C,V_sourceUUID
T@"NSUUID",R,V_UUID
T@"NSUUID",R,V_cameraProfileUUID
T@"NSUUID",R,V_clipUUID
T@"NSUUID",R,V_homeUUID
T@"NSUUID",R,V_identifier
T@"NSUUID",R,V_personUUID
T@"NSUUID",R,V_sessionEntityUUID
T@"NSUUID",R,V_sourceUUID
T@"NSUUID",R,V_torsoModelVersion
T@"VNPersonsModel",R,V_visionPersonsModel
T@,R,V_container
T@,R,V_value
T@?,C,V_analyzerDidAnalyzeFragmentWithResult
T@?,C,V_analyzerDidAnalyzeFrameWithResult
T@?,C,V_analyzerDidCreateTimelapseFragment
T@?,C,V_analyzerDidFailWithError
T@?,C,V_analyzerDidProduceAnalysisStateUpdate
T@?,C,V_assetWriterDidFailWithError
T@?,C,V_assetWriterDidOutputInitializationSegment
T@?,C,V_assetWriterDidOutputSeparableSegment
T@?,C,V_bufferWillFlush
T@?,C,V_bufferWillHandleSampleBuffer
T@?,C,V_decoderDidDecodeSampleBuffer
T@?,C,V_didUpdateHomes
T@?,C,V_encoderDidEncodeSampleBuffer
T@?,C,V_frameAnalyzerDidAnalyzeFrame
T@?,C,V_frameAnalyzerDidProduceAnalysisStateUpdate
T@?,C,V_frameSamplerDidDropFrame
T@?,C,V_frameSamplerDidSampleFrame
T@?,C,V_frameSelectorDidSelectFrame
T@?,C,V_frameSelectorDidSkipFrame
T@?,C,V_frameSelectorPrepareFrame
T@?,C,V_frameTrackerDidTrackFrame
T@?,C,V_progressBlock
T@?,C,V_retimerDidRetimeSampleBuffer
T@?,R,N,V_callback
TB,D,GisFaceClassificationEnabled
TB,D,GisImportingFromPhotoLibraryEnabled
TB,D,GisSharingFaceClassificationsEnabled
TB,GisCancelled,V_cancelled
TB,GisFaceClassificationEnabled,V_faceClassificationEnabled
TB,GisImportingFromPhotoLibraryEnabled,V_importingFromPhotoLibraryEnabled
TB,GisPersonDataAvailableViaHomeKit,V_personDataAvailableViaHomeKit
TB,GisSharingFaceClassificationsEnabled,V_sharingFaceClassificationsEnabled
TB,N
TB,R
TB,R,GhasEstimatedBoundingBox,V_isBoundingBoxEstimated
TB,R,GisExternalLibrary,V_externalLibrary
TB,R,GisInclusion,V_inclusion
TB,R,GisSentinelFaceprint
TB,R,GisSetup,V_setup
TB,R,GshouldRemoveExcessFaceCrops,V_removeExcessFaceCrops
TB,R,V_allowRecoveryFromInsufficientAudioTrim
TB,R,V_didEncryptPackageResult
TB,R,V_didPrivatizePackageResult
TB,R,V_doImpurePersonCleanup
TB,R,V_encode
TB,R,V_encoder
TB,R,V_frameReorderingRequired
TB,R,V_fromTorsoClassification
TB,R,V_lowQuality
TB,R,V_monitored
TB,R,V_unrecognizable
TB,V_adjustBrightness
TB,V_allowReducedConfiguration
TB,V_dropSamplesUntilSync
TB,V_dropTrimDurationAttachments
TB,V_enableTemporalEventFiltering
TB,V_enabled
TB,V_forceKeyFrameOnNextEncodedFrame
TB,V_hasFailed
TB,V_ignoreThermalAndSystemResourceUsageLevel
TB,V_passthroughAudio
TB,V_recognizeFaces
TB,V_redactFrames
TB,V_resetReferences
TB,V_saveAnalyzerResultsToDisk
TB,V_transcode
TI,R
TI,V_transcodeCodecType
TQ,R
TQ,R,N
TQ,R,N,V_windowSize
TQ,R,V_bufferSize
TQ,R,V_cachePolicy
TQ,R,V_code
TQ,R,V_count
TQ,R,V_externalToExternalEquivalencies
TQ,R,V_firstIndex
TQ,R,V_fragmentSequenceNumber
TQ,R,V_frameId
TQ,R,V_homeToExternalEquivalencies
TQ,R,V_maxCandidates
TQ,R,V_minSampleSize
TQ,R,V_motionMode
TQ,R,V_numDecodedSamples
TQ,R,V_numDidAnalyzeFragments
TQ,R,V_numDidAnalyzeFrames
TQ,R,V_numDidAnalyzePackages
TQ,R,V_numDidCreateTimelapseFragments
TQ,R,V_numberOfDroppedFrames
TQ,R,V_reorderBufferSize
TQ,R,V_secondIndex
TQ,R,V_signpostIdentifier
TQ,R,V_status
TQ,R,V_thermalLevel
TQ,R,V_trackIndex
TQ,V_maxH264VideoDecoders
TQ,V_maxH264VideoEncoders
TQ,V_maxH265VideoEncoders
TQ,V_maxReferences
TQ,V_numCandidates
TQ,V_numImages
TQ,V_numTracks
TQ,V_size
TQ,V_stationaryBlobIndex
TQ,V_thumbnailHeight
TS,R,V_blobID
T^S,V_assignment
T^f,V_runningMean
T^f,V_runningStd
T^{OpaqueVTCompressionSession=},V_session
T^{OpaqueVTDecompressionSession=},V_session
T^{__CFArray=},R,V_references
T^{__CFArray=},R,V_resizedSampleBuffers
T^{opaqueCMBufferQueue=},V_buffer
T^{opaqueCMSampleBuffer=},R,V_sbuf
T^{opaqueCMSampleBuffer=},V_background
Td,N
Td,R
Td,R,V_analysisFPS
Td,R,V_averageAnalysisTime
Td,R,V_bufferFillRatio
Td,R,V_classificationThresholdKnown
Td,R,V_classificationThresholdUnknown
Td,R,V_confidence
Td,R,V_delay
Td,R,V_faceQualityScore
Td,R,V_faceVIPThresholdForTorsoAnnotation
Td,R,V_maxNorm
Td,R,V_probability
Td,R,V_timeSinceLastFragmentWasReceived
Td,R,V_timeStamp
Td,R,V_value
Td,V_analysisFPS
Td,V_clusteringDuration
Td,V_faceprintingDuration
Td,V_maxFragmentAnalysisDuration
Td,V_minFrameQuality
Td,V_minFrameScale
Td,V_movingAverage
Td,V_totalDuration
Tf,R
Tf,R,V_l2Norm
Tf,R,V_motionScore
Tf,R,V_opacity
Tf,R,V_postTrainingLoss
Tf,R,V_preTrainingLoss
Tf,R,V_precision
Tf,R,V_recall
Tf,R,V_score
Tf,R,V_value
Ti,N,V_token
Ti,R,V_labelIndex
Ti,R,V_taskID
Ti,V_numFailures
Tq,N
Tq,R
Tq,R,V_events
Tq,R,V_falseNegative
Tq,R,V_falsePositive
Tq,R,V_familiarity
Tq,R,V_sessionEntityAssignment
Tq,R,V_source
Tq,R,V_thermalPressureLevel
Tq,R,V_truePositive
Tq,R,V_version
Tq,V_eventTriggers
Tq,V_highWaterMark
Tq,V_logStateCount
Tq,V_numberOfClusters
Tq,V_numberOfFaceprintsClustered
Tq,V_numberOfPersonsCreated
Tq,V_numberOfUnknownFaceprintsAssociated
Tq,V_options
Tq,V_packageClassifierMode
Tr*,R,N,V_notificationName
Tr^f,R,N
Tr^{opaqueCMFormatDescription=},R,V_audioFormat
Tr^{opaqueCMFormatDescription=},R,V_audioFormatDescription
Tr^{opaqueCMFormatDescription=},R,V_videoFormat
Tr^{opaqueCMFormatDescription=},R,V_videoFormatDescription
Tr^{opaqueCMFormatDescription=},V_inputAudioFormat
Tr^{opaqueCMFormatDescription=},V_inputVideoFormat
Tr^{opaqueCMFormatDescription=},V_timelapseOutputVideoFormat
T{?=qiIq},R
T{?=qiIq},R,V_approximationInterval
T{?=qiIq},R,V_backgroundChangeInterval
T{?=qiIq},R,V_backgroundChangeResetInterval
T{?=qiIq},R,V_backgroundExpireInterval
T{?=qiIq},R,V_backgroundTimeStamp
T{?=qiIq},R,V_baseDecodeTimeStamp
T{?=qiIq},R,V_currentPTS
T{?=qiIq},R,V_expirationInterval
T{?=qiIq},R,V_motionValidInterval
T{?=qiIq},R,V_presentationTime
T{?=qiIq},R,V_presentationTimeStamp
T{?=qiIq},R,V_targetInterval
T{?=qiIq},R,V_time
T{?=qiIq},R,V_timeInterval
T{?=qiIq},R,V_timeStamp
T{?=qiIq},R,V_trackInterval
T{?=qiIq},R,V_videoDuration
T{?=qiIq},V_backgroundChangeTimeStamp
T{?=qiIq},V_currentDTS
T{?=qiIq},V_currentFragmentStartTime
T{?=qiIq},V_currentPTS
T{?=qiIq},V_lastAudioPresentationTimeStamp
T{?=qiIq},V_lastVideoPresentationTimeStamp
T{?=qiIq},V_preferredOutputSegmentInterval
T{?=qiIq},V_referenceInterval
T{?=qiIq},V_thumbnailInterval
T{?=qiIq},V_timelapseInterval
T{?=qiIq},V_timelapsePreferredFragmentDuration
T{?=qiIq},V_trackAnalysisPTS
T{?={?=qiIq}{?=qiIq}},R,V_audioTrackTimeRange
T{?={?=qiIq}{?=qiIq}},R,V_timeRange
T{?={?=qiIq}{?=qiIq}},R,V_videoTrackTimeRange
T{CGPoint=dd},R,V_origin
T{CGPoint=dd},R,V_point
T{CGRect={CGPoint=dd}{CGSize=dd}},R
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_regionOfInterest
T{CGSize=dd},R
T{CGSize=dd},R,V_inputDimensions
T{CGSize=dd},R,V_size
T{CGSize=dd},V_imageSize
T{CGSize=dd},V_modelSize
T{CGVector=dd},R,V_motion
T{_NSRange=QQ},R,V_firstVideoSampleByteRange
T{os_unfair_lock_s=I},R,N,V_lock
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLByDeletingPathExtension
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLSession:didBecomeInvalidWithError:
URLSession:didReceiveChallenge:completionHandler:
URLSessionDidFinishEventsForBackgroundURLSession:
URLWithString:
UTF8String
UUID
UUIDPairString
UUIDString
_JSONObjectWithObject:options:
_UUID
_activityZones
_addCandidateForTarget:motionScore:motionDetections:tracks:
_addClassToContainer:
_addEventsToEventQueue:events:
_addValueToContainer:forKey:
_adjustBackgroundAtAttribute:backgroundChanged:timeStamp:
_adjustBrightness
_allPersonsAndFaceCrops
_allowRecoveryFromInsufficientAudioTrim
_allowReducedConfiguration
_analysisFPS
_analysisStateManager
_analysisTime
_analysisTimeStamps
_analyzerConfiguration
_analyzerDidAnalyzeFragmentWithResult
_analyzerDidAnalyzeFrameWithResult
_analyzerDidCreateTimelapseFragment
_analyzerDidFailWithError
_analyzerDidProduceAnalysisStateUpdate
_analyzerEventsFromObjectDetections:
_anchorStrides
_annotationScores
_annotationScoresFromAnalyzerEvents:
_appendSampleBuffer:
_appendTarget:timeStamp:motionDetections:
_approximationInterval
_asset
_assetData
_assetReader
_assetWriter
_assetWriterDidFailWithError
_assetWriterDidOutputInitializationSegment
_assetWriterDidOutputSeparableSegment
_assignment
_attachEncryptedDataUsingKey:toPayload:error:
_attachFaceCrops:toPayload:error:
_attributes
_attributesLoaded
_audioFormat
_audioFormatDescription
_audioInput
_audioTrackTimeRange
_average
_averageAnalysisTime
_background
_backgroundAtTimeStamp:
_backgroundChangeInterval
_backgroundChangeResetInterval
_backgroundChangeTimeStamp
_backgroundEstimator
_backgroundEvents
_backgroundExpireInterval
_backgroundTimeStamp
_base64StringFromData:
_baseDecodeTimeStamp
_beginDate
_binWidth
_blobArea
_blobs
_blurSampleBufferWithEncoder:sampleBuffer:events:
_boundingBox
_boxesName
_boxesTensorData
_bufferFillRatio
_bufferSize
_bufferWillFlush
_bufferWillHandleSampleBuffer
_cachePolicy
_callback
_cameraProfileUUID
_cameraVideoFrameAnalyzer
_cancelled
_candidate
_capacity
_classMap
_classesName
_classesTensorData
_classificationThresholdKnown
_classifications
_clipMetadata
_clipUUID
_clusterer
_clusteringDuration
_code
_color
_colorSpace
_commandBuffer
_compactInternalAnalyzers
_computeOpticalFlow:with:globalMotionScore:activityZones:operationMode:
_condition
_confidence
_confidenceThresholds
_configuration
_configureAssetWriter
_configureEncoder
_configureTimelapseAssetWriter
_configureTimelapseEncoder
_container
_containerIsArray
_context
_copyFromOutputBuffer:toPixelBuffer:
_copyFromPixelBuffer:toInputBuffer:translateCol:translateRow:
_copyNextSampleBufferFromTrackOutput:
_correctRunningMeanBrightnessAtAttribute:
_count
_createBlurredPixelBuffer:events:
_createFontWithSize:
_createOutputsForAsset:readVideo:readAudio:
_createPayloadWithServiceResult:error:
_createSessionWithFormatDescription:
_createdAtCurrentVersion
_currentDTS
_currentFragmentStartTime
_currentPTS
_data
_dataRepresentation
_dataSource
_date
_dateCreated
_decodeMode
_decoder
_decoderDidDecodeSampleBuffer
_decoderDidFailWithError
_delay
_delegate
_delegateQueue
_detections
_detectionsFromAnalyzerEvents:
_deviceInformation
_didDecodeSampleBuffer:
_didEncryptPackageResult
_didPrivatizePackageResult
_doImpurePersonCleanup
_downloadClipWithCameraProfileUUID:clipUUID:completionHandler:
_drainCandidateThatExpiredBefore:
_drainResizedBuffersThatExpiredBefore:
_dropSamplesUntilSync
_dropTrimDurationAttachments
_duration
_dynamicConfiguration
_dynamicConfigurationBuffer
_enableTemporalEventFiltering
_enabled
_encoder
_encoderDidEncodeSampleBuffer
_encoderDidFailWithError
_encoderQueue
_ensureAttributes
_ensureDecoderForFragment:
_ensureEncoder
_ensureFirstAudioSampleBufferHasSufficientPrimingTrim:
_ensureInternalBuffersForPixelBuffer:
_ensureModelWithError:
_ensureTimelapseEncoder
_equivalencyTablesByHome
_error
_event
_eventClass
_eventClasses
_eventTriggers
_eventsFromAnalyzerEvents:
_eventsWithClassificationsFromEvents:videoFrame:regionOfInterest:homeUUID:
_eventsWithSessionEntitiesFromEvents:regionOfInterest:timeStamp:homeUUID:
_evictSampleBuffer:
_existingAtCurrentVersion
_existingAtOtherVersions
_expirationInterval
_expireMotionDetectionsAtTimeStamp:
_exportInternalStateForPixelBuffer:exportMode:
_external
_externalLibrary
_externalPersonManagers
_externalToExternalEquivalencies
_face
_faceAestheticQualityFilter
_faceBoundingBox
_faceCentroid
_faceClassificationEnabled
_faceClassifications
_faceClassificationsFromAnalyzerEvents:
_faceCountsByPerson
_faceCrop
_faceCropUUID
_faceCropUUIDs
_faceCrops
_faceQualityScore
_faceRecognition
_faceRecognizabilityFilter
_faceVIPThresholdForTorsoAnnotation
_faceprint
_faceprinter
_faceprintingDuration
_faceprints
_failWithDescription:
_falseNegative
_falseNegativeKeys
_falsePositive
_falsePositiveKeys
_familiarity
_feedbackServiceHost
_feedbackSession
_filterEvents:stationaryEvents:motionDetection:
_filterEvents:stationaryEvents:motionDetection:prevFrameResult:regionOfInterest:
_filterEvents:stationaryEvents:stationaryObjects:expirationPTS:imageSize:
_filterFrameResult:dynamicConfiguration:motionDetections:
_filterPackageEvents:backgroundEvents:
_firmwareVersion
_firstIndex
_firstPTS
_firstVideoSampleByteRange
_flushAutomatically:
_font
_forceKeyFrameOnNextEncodedFrame
_foregroundBlobsFromBlobs:backgroundChanged:
_foregroundDifferencesFromPixelBuffer:differences:
_foregroundPixelsFromPixelBuffer:attribute:assignment:useChromaOnly:
_foregroundTimeStamp
_fragment
_fragmentSequenceNumber
_fragments
_frame
_frameAnalyzer
_frameAnalyzerDidAnalyzeFrame
_frameAnalyzerDidProduceAnalysisStateUpdate
_frameId
_frameReorderingRequired
_frameResultIndices
_frameResults
_frameSampler
_frameSamplerDidDropFrame
_frameSamplerDidSampleFrame
_frameSelector
_frameSelectorDidSelectFrame
_frameSelectorDidSkipFrame
_frameSelectorPrepareFrame
_frameThumbnailSampler
_frameTimelapseSampler
_frameTracker
_frameTrackerDidTrackFrame
_fromTorsoClassification
_getFloat64Property:propertyValueOut:
_getPeakPowerPressureLevel
_getProperty:propertyValue:
_getSInt32Property:propertyValueOut:
_greedyClusterer
_handleDecodedSampleBuffer:
_hasFailed
_hasTorsoprinterVersionChangedForHome:
_highConfidenceThresholds
_highWaterMark
_histogram
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
_homeKitClient
_homeKitOperationQueue
_homeManager
_homeMetadata
_homePersonManager
_homePersonsAndFaceCrops
_homeToExternalEquivalencies
_homeUUID
_homes
_identifier
_ignoreThermalAndSystemResourceUsageLevel
_imageData
_imageName
_imageSize
_importingFromPhotoLibraryEnabled
_inclusion
_initSessionWithDimensions:codecType:useHardwareAcceleration:error:
_initializationSegment
_input
_inputAudioFormat
_inputDimensions
_inputFeatureValueName
_inputName
_inputQueue
_inputVideoFormat
_internalAnalyzers
_intersectionOverUnionFromBlob:boundingBox:assignment:
_interval
_invalidate
_invalidateBackgroundForPixelBuffer:timeStamp:
_invalidateWithErr:
_isBoundingBoxEstimated
_isTorsoFaceCropMapStale:
_jpegData
_key
_label
_labelIndex
_lastFragmentReceivedDate
_lastIndex
_lastSample
_lastSampleBufferDTS
_lastSampleBufferPTS
_layerParameters
_levelThresholds
_lines
_linkedEntityUUID
_linkedEntityUUIDs
_loadResource:withExtension:
_loadTorsoDataForHomeUUID:intoTorsoModelsByHome:torsoToFaceCropByHome:
_lock
_logIdentifier
_logState
_logStateCount
_lowQuality
_manufacturer
_maxCandidates
_maxCapacity
_maxFragmentAnalysisDuration
_maxFragmentDuration
_maxH264VideoDecoders
_maxH264VideoEncoders
_maxH265VideoEncoders
_maxLaplacianScore
_maxNorm
_maxReferences
_maxScore
_mediumConfidenceThresholds
_message
_metricDefault
_metricWithLabels
_minFrameQuality
_minFrameScale
_minLaplacianScore
_minSampleSize
_mlModel
_model
_modelSize
_modelURL
_modelUUID
_monitored
_motionDetections
_motionDetectionsFromTarget:reference:dynamicConfiguration:motionScore:
_motionMode
_motionScore
_motionTimeStamps
_motionValidInterval
_motionVectors
_movingAverage
_name
_networkPath
_nextTaskID
_nmsConfiguration
_notificationName
_notificationQueue
_notifyDelegateDidAnalyzeFragmentWithResult:
_notifyDelegateDidAnalyzeFrameWithResult:
_notifyDelegateDidCreateTimelapseFragment:
_notifyDelegateDidFailWithError:
_notifyDelegateDidProduceAnalysisStateUpdate:
_numBins
_numCandidates
_numDecodedSamples
_numDidAnalyzeFragments
_numDidAnalyzeFrames
_numDidAnalyzePackages
_numFailures
_numImages
_numTracks
_numberOfClusters
_numberOfDroppedFrames
_numberOfFaceprintsClustered
_numberOfPersonsCreated
_numberOfUnknownFaceprintsAssociated
_objectWithJSONObject:allowedClasses:
_offsetsOneFeatureValueNames
_offsetsZeroFeatureValueNames
_opacity
_operation
_options
_osThermalPressureLevelNotificationToken
_outcome
_outputPath
_packageClassifierMode
_passthroughAudio
_personDataAvailableViaHomeKit
_personFaceCrops
_personIndices
_personLinks
_personToEquivalencyCell
_personToFaceCrops
_personTracker
_personUUID
_personUUIDs
_persons
_personsModelIdentifier
_personsModelManager
_personsModelsByHome
_photosPersonManager
_photosPersonsAndFaceCrops
_pixelBuffer
_point
_position
_postProcessOffsetsZero:offsetsOne:scores:yaws:rolls:outputPredictions:
_postTrainingLoss
_preTrainingLoss
_precision
_predictEventsFromCropPixelBuffer:cropRect:imageSize:error:
_predictForegroundFromPixelBuffer:timeStamp:
_predictedLinkedEntityUUIDs
_prediction
_preferenceCache
_preferenceCacheFlushTimer
_preferenceLoggedValues
_preferenceOverridesInternal
_prepareForInputVideoFormat:audioFormat:
_prepareForTimelapseOutputVideoFormat:
_presentationTime
_presentationTimeStamp
_prevFrameResult
_previousPersons
_probability
_produceResult:withArguments:
_progressBlock
_queue
_records
_redactFrames
_referenceInterval
_references
_refreshBeforeDate:completionHandler:
_regionOfInterest
_registerLock
_removeExcessFaceCrops
_removeTemporaryFiles
_removeTrimDurationAttachmentsFromAudioSampleBuffer:
_removedPersonFaceCrops
_reorderBufferSize
_reportBuffer
_requestPreSignedURLWithClipUUID:completionHandler:
_reset
_resetPreviousFrameResult:expirationPTS:regionOfInterest:
_resetReferences
_resetStaleTorsoStateForHome:torsoToFaceCropMap:
_resizedSampleBuffers
_resourceUsageMonitor
_retimerDidRetimeSampleBuffer
_roll
_rollsFeatureValueNames
_runNeuralNetworkOnPixelBuffer:offsetsZero:offsetsOne:scores:yaws:rolls:error:
_runningMean
_runningStd
_sampleBufferDelay
_samples
_saveAnalyzerResultsToDisk
_saveFragmentDataToDisk:diskBufferSize:
_sbuf
_scalerModel
_score
_scoresFeatureValueNames
_secondIndex
_separableSegment
_sequenceNumbers
_service
_serviceResult
_services
_session
_sessionEntities
_sessionEntityAssignment
_sessionEntityManager
_sessionEntityUUID
_sessionUUIDToPreviousFaceprints
_sessionUUIDToPreviousTorsoprints
_sessions
_setAssignment:greaterThanType:value:boundingBox:scale:
_setFloat64Property:propertyValue:
_setProperty:propertyValue:
_setSInt32Property:propertyValue:
_settings
_setup
_sharingFaceClassificationsEnabled
_shouldSkipLogState
_significantActivityFcosDetector
_signpostIdentifier
_simulatedEventForEventClass:
_size
_sourceURL
_sourceUUID
_stageFive_addPersons:clusterMapping:faceprints:
_stageFour_clusterFaceprints:
_stageOne_fetchFaceCrops
_stageSix_associateFaceCropsWithClusterMapping:faceprints:
_stageThree_generateFaceprintsForFaceCrops:existingFaceprints:
_stageTwo_fetchFaceprints:
_startDate
_startTime
_startWritingAtStartTime:
_state
_stationaryBlobIndex
_stationaryObjects
_stationaryTracks:timeStamp:
_store
_stripAudioTrackAndFacesFromAsset:completionHandler:
_submitClipWithCameraProfileUUID:clipUUID:completionHandler:
_summary
_supportsFaceClassification
_synthesizeMotionDetectionWithTarget:
_systemResourceUsageLevel
_targetDate
_targetEventClassRanks
_targetEventsSetFromEventTriggers:enableFaceClassification:enableTorsoRecognition:
_temporalEventFilter
_temporaryFileURLWithUUID:extension:error:
_temporaryFileURLs
_text
_thermalLevel
_thermalLevelNotificationToken
_thermalPressureLevel
_thresholdDefault
_thresholdWithLabels
_thumbnailBuffer
_thumbnailHeight
_thumbnailInterval
_thumbnails
_tick
_time
_timeInterval
_timeRange
_timeSinceAnalyzerStarted
_timeSinceLastFragmentWasReceived
_timeStamp
_timelapseAssetWriter
_timelapseEncoder
_timelapseInterval
_timelapseOutputVideoFormat
_timelapsePreferredFragmentDuration
_timeline
_token
_torso
_torsoAnnotation
_torsoAnnotations
_torsoCentroid
_torsoClassifier
_torsoModelVersion
_torsoModelsByHome
_torsoRecognition
_torsoToFaceCropByHome
_torsoprint
_torsoprintUUIDs
_torsoprinter
_torsoprints
_totalDuration
_trackAnalysisPTS
_trackIndex
_trackInterval
_trackOutputs
_trackSamples
_tracksFromTarget:reference:background:dynamicConfiguration:motionDetections:
_transaction
_transcode
_transcodeCodecType
_truePositive
_truePositiveKeys
_truth
_type
_unassociatedFaceCrops
_unknownFacesSavedCounts
_updateAnalyzer:withIndex:
_updateBackgroundFromPixelBuffer:timeStamp:
_updateCurrentTracks:inactiveTracks:blobs:timeStamp:
_updateRunningMean:runningSquaredMean:fromInputBuffer:decay:
_updateSettings:
_updateThermalLevel
_updateThermalPressureLevel
_uploadPayloadData:uploadURL:completionHandler:
_url
_usageLevel
_usageMonitor
_userDefinedPersonLinksByHome
_userInfo
_value
_valueForNumber:
_version
_videoDuration
_videoFormat
_videoFormatDescription
_videoInput
_videoTrackTimeRange
_visionPersonsModel
_visualizeFrames:targetEvents:backgroundEvents:regionOfInterest:
_visualizeTargetEvents:backgroundEvents:regionOfInterest:targetTimeStamp:
_visualizeTargetsThatExpiredBefore:
_watchdogTimer
_weakDecoder
_weights
_weightsName
_weightsTensorData
_windowSize
_workQueue
_yaw
_yawsFeatureValueNames
absoluteFaceBoxFromPhotosFaceCropImageData:
absoluteString
absoluteURL
accessories
accessory
activityForScheduling
activityZoneType
activityZones
activityZonesFromString:isInclusion:
add:
addEntriesFromDictionary:
addExecutionBlock:
addFaceCrops:completion:
addFaceObservations:toFaceDescriptorBuffer:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceprints:
addFaceprints:completion:
addIndex:
addInput:
addLinkedEntityUUIDs:
addMutableTrackWithMediaType:preferredTrackID:
addNumber:
addObject:
addObjectsFromArray:
addOperation:
addOrUpdateFaceCrops:completion:
addOrUpdateFaceprints:completion:
addOrUpdatePersons:completion:
addOutput:
addPerson:completion:
addPersonFaceCrops:completion:
addPersons:completion:
addPointer:
addPreferenceOverrideFromDictionary:
addValue:
adjustBrightness
allAtCurrentVersion
allEvents
allObjects
allPersons
allPersonsAndFaceCrops
allValues
allocWithZone:
allowRecoveryFromInsufficientAudioTrim
allowReducedConfiguration
allowedClasses
allowsKeyedCoding
analysisFPS
analysisQOS
analysisStateManager
analysisTimeStamps
analyticsTimer
analyzeBackgroundFrame:packageEvents:newBackgroundEvents:regionOfInterest:
analyzeFragment:configuration:
analyzeFrame:regionOfInterest:
analyzePixelBuffer:regionOfInterest:error:
analyzePixelBuffer:timeStamp:
analyzer:didAnalyzeFragmentWithResult:
analyzer:didAnalyzeFrameWithResult:
analyzer:didCreateTimelapseFragment:
analyzer:didFailWithError:
analyzer:didProduceAnalysisStateUpdate:
analyzer:didProduceResult:
analyzerConfiguration
analyzerConfigurations
analyzerDidAnalyzeFragmentWithResult
analyzerDidAnalyzeFrameWithResult
analyzerDidCreateTimelapseFragment
analyzerDidFailWithError
analyzerDidProduceAnalysisStateUpdate
analyzerEvents
analyzerStates
analyzerWithConfiguration:block:
analyzerWithConfiguration:identifier:error:
analyzerWithConfiguration:identifier:remote:error:
analyzerWithOptions:error:
analyzers
annotationScores
anyObject
appendArray:
appendBlob:
appendBytes:length:
appendData:
appendEncryptionModeWithPath:
appendFaceCrop:imageBorder:imageColor:outlineBorder:outlineColor:
appendFloats:count:
appendFormat:
appendFragmentResult:
appendFragmentResult:forKey:source:redactFrames:
appendFragmentResult:redactFrames:
appendFragmentResultsFromReport:
appendFrame:text:
appendFrame:text:boxes:imageBorder:imageColor:outlineBorder:outlineColor:
appendFrameResult:frameTruth:description:
appendHeaderWithTitle:textColor:backgroundColor:
appendIFrameOnly
appendInitializationSegmentWithPath:
appendJPEG:imageBorder:imageColor:outlineBorder:outlineColor:
appendSampleBuffer:
appendSeparableSegmentWithPath:duration:
appendSeparableSegmentWithPath:duration:byteRange:
appendString:
appendText:
applyActivityZoneFilteringOnSourcePoint:destinationPoint:frameSize:activityZones:
applyEventTypeAndCheckIfSubBoundingIsStatic:eventClass:confidence:
applyFilterWithFrameResult:motionDetection:
applyPadding:withOriginalSize:padding:
applyToImage:withProbability:
applyWithFrameResult:
approximationInterval
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
assetData
assetReaderTrackOutputWithTrack:outputSettings:
assetReaderWithAsset:error:
assetWithURL:
assetWriter
assetWriter:didFailWithError:
assetWriter:didOutputInitializationSegment:
assetWriter:didOutputSegmentData:segmentType:
assetWriter:didOutputSegmentData:segmentType:segmentReport:
assetWriter:didOutputSeparableSegment:segmentReport:
assetWriterDidFailWithError
assetWriterDidOutputInitializationSegment
assetWriterDidOutputSeparableSegment
assetWriterInputWithMediaType:outputSettings:sourceFormatHint:
assignBackgroundEvents:timeStamp:
assignForegroundEvents:timeStamp:
assignSessionEntitiesToPersonEvents:regionOfInterest:timeStamp:homeUUID:
assignSessionEntityToFaceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:availableSessionEntityUUIDs:sessionEntityAssignment:
assignment
associateFaceCropsWithUUIDs:toPersonWithUUID:forSource:completion:
attributeDescriptions
attributeForKey:
attributes
attributesOfItemAtPath:error:
audioFormat
audioFormatDescription
audioInput
audioTrackTimeRange
augmentWithOptions:
authenticationMethod
autorelease
averageAnalysisTime
averageBitRate
averagePrecisionForMinPrecision:comparator:
averagePrecisionWithClassificationTruth:minPrecision:
averagePrecisionWithDetectionTruth:minPrecision:iouThreshold:videoMetric:
averageTime
background
backgroundChangeInterval
backgroundChangeResetInterval
backgroundChangeTimeStamp
backgroundEstimator
backgroundEvents
backgroundExpireInterval
backgroundTimeStamp
base64Encoded
base64EncodedDataWithOptions:
baseDecodeTimeStamp
begin
beginDate
biases
blobArea
blobAtTimeStamp:
blobID
blobs
blurFacesFromAssetURL:outputURL:duration:analysisFPS:windowSize:faceDetected:
boolPreferenceForKey:defaultValue:
boolValue
boundingBox
boundingBoxForTracker
boxForRegionOfInterest:
boxesForEvent:isTruth:
boxesName
bucketForValue:usingBuckets:
buffer
buffer:willHandleSampleBuffer:
bufferSize
bufferWillFlush:
bufferWillHandleSampleBuffer
buildEmptyTaskFromOptions:error:
buildEquivalencyMapForPersonsModels:userDefinedPersonLinks:error:
buildFaceMisclassificationTaskFromOptions:error:
buildHomePersonClusteringTaskFromOptions:error:
buildPersonsModelForHomeUUID:sourceUUID:externalLibrary:faceObservationsByPerson:error:
buildPersonsModelsSummaryTaskFromOptions:error:
buildRemovePersonsModelTaskFromOptions:error:
buildSubmitFeedbackTaskFromOptions:error:
buildUpdatePersonsModelTaskFromOptions:error:
buildUpdateTorsoModelTaskFromOptions:error:
bundleWithIdentifier:
bytes
cachePolicy
calculateMotionDetection:score:srcFeatureCVPoints:dstFeatreCVPoints:activityZones:operationMode:srcPyramid:frameSize:brightnessChange:
callback
camera
cameraMetadata
cameraProfileUUID
cameraProfileWithUUID:
cameraProfiles
cameraVideoFrameAnalyzer
canAddInput:
canAddOutput:
canFragmentData:
cancel
cancelReading
cancelRequest:
cancelTask:
cancelWithError:
cancelled
candidate
capacity
caseInsensitiveCompare:
centermostFaceprintInCluster:faceObservations:
characterAtIndex:
characterSetWithCharactersInString:
chartDataWithBaseline:comparator:
chartDataWithClassificationTruth:isBaseline:
chartDataWithDetectionTruth:isBaseline:iouThreshold:videoMetric:
chartSpecWithRange:colors:labels:
check
checkAndSaveCrashReportWithData:
checkIfObjectIsStaticWithBoundingBox:motionDetection:eventClass:
class
classHierarchyMap
classMap
classMotionScoreMap
classesName
classification
classificationThresholdKnown
classificationThresholdUnknown
classifyFaceEvent:pixelBuffer:fastMode:homeUUID:error:
clipManager
clipMetadata
clipUUID
close
closeFile
clusterSessionEntityToFaceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:availableSessionEntityUUIDs:sessionEntityAssignment:
clusterer
clusteringDuration
code
color
colorSpace
combineFrameResults:withResults:
commandBuffer
compare:
compareWithClassificationTruth:eventClass:confidenceThreshold:
compareWithDetectionTruth:eventClass:confidenceThreshold:iouThreshold:videoMetric:
compareWithTrackingTruth:eventClass:confidenceThreshold:ioaThreshold:
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
composition
compressedFrameWithScale:quality:error:
condition
confidence
configuration
conformsToProtocol:
container
containsEvent:withInsetPercentage:
containsIndex:
containsValueForKey:
containsVectorWithSource:destination:
contentInformationRequest
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextWithOptions:
convertObjectDetections:cropRect:originalImageSize:
convertToClusters:
copy
copyNextSampleBuffer
copyNextSampleBufferWithTrackIndexOutput:
copyWithFaceEvent:torso:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createBoxesTensorWithError:
createClassesTensorWithError:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createFacePixelBufferForFaceDetection:pixelBuffer:roll:error:
createFacePixelBufferForFaceEvent:pixelBuffer:roll:error:
createFacePixelBufferFromFaceCrop:error:
createFaceprintForFacePixelBuffer:fastMode:error:
createImageTensorWithError:
createJPEGDataFromPixelBuffer:scale:encodeQuality:error:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
createPackageEventAtTimeStamp:
createPixelBufferFromImageData:error:
createPixelBufferFromJPEGData:error:
createPixelBufferFromJPEGDataProvider:error:
createPixelBufferFromJPEGPath:error:
createPixelBufferWithSize:pixelFormat:useIOSurface:
createRegionOfInterestPixelBufferWithError:
createSessionEntityWithUUID:faceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:sessionEntityAssignment:
createTorsoPixelBufferForTorsoEvent:pixelBuffer:error:
createWeightsTensorWithError:
createdAtCurrentVersion
credentialForTrust:
cropPixelBuffer:crop:error:
croppedJpegDataFromFaceCrop:
currentDTS
currentFragmentStartTime
currentHorizontalTilt
currentModelUUID
currentPTS
currentTorsoRequestRevision
currentVerticalTilt
data
dataPointAtIndex:error:
dataPointer
dataRateLimit
dataRepresentation
dataRequest
dataScalerInputName
dataScalerOutputName
dataSource
dataTaskWithURL:completionHandler:
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
dataWithContentsOfFile:options:error:
dataWithContentsOfURL:
dataWithContentsOfURL:options:error:
dataWithData:
dataWithJSONObject:options:error:
date
dateAtTime:
dateCreated
dateOfOccurrence
dateWithTimeIntervalSinceNow:
debugDescription
decimalNumberByRoundingAccordingToBehavior:
decimalNumberHandlerWithRoundingMode:scale:raiseOnExactness:raiseOnOverflow:raiseOnUnderflow:raiseOnDivideByZero:
decimalNumberWithDecimal:
decimalNumberWithString:
decimalValue
decodeBoolForKey:
decodeCMTimeForKey:
decodeCMTimeRangeForKey:
decodeDoubleForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeMode
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodeRectForKey:
decoder:didDecodeSampleBuffer:
decoder:didFailWithError:
decoderDidDecodeSampleBuffer
decoderDidFailWithError
defaultAestheticQualityDataScalerPath
defaultAestheticQualityModelPath
defaultAssetPath
defaultCenter
defaultConfidenceThreshold:confidenceLevel:
defaultConfidenceThresholdsFeedback
defaultConfidenceThresholdsMedium
defaultFormatter
defaultManager
defaultNMSConfiguration
defaultPrivateConfiguration
defaultRecognizabilityDataScalerPath
defaultSessionConfiguration
delay
delegate
delegateQueue
desLabelIndexForEventClass:
description
descriptorData
detectFacesInImageData:error:
detectWithGlobalMotionScore:referencePixelBuffer:targetPixelBuffer:activityZones:detectorMode:
detections
deviceInformation
dictionary
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
didEncryptPackageResult
didPrivatizePackageResult
didUpdateHomes
digitalZoom
distance
distantPast
doImpurePersonCleanup
doInferenceOnData:error:
doTrainingOnData:forNumberOfEpochs:withCallback:error:
doubleForKey:
doubleValue
draw:
drawBoundingBox:lineWidth:text:color:
drawPolygonWithNormalizedPoints:
drawRect:width:color:
drawText:at:color:
drawTextHeaderBar:
dropSamplesUntilSync
dropTrimDurationAttachments
dumpFFDataToCacheForPerson:personFaceCrops:
duration
dynamicConfiguration
dynamicConfigurationBuffer
dynamicConfigurationForTime:
earlierDate:
enableTemporalEventFiltering
encode
encodeBool:forKey:
encodeCMTime:forKey:
encodeCMTimeRange:forKey:
encodeDouble:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInt:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeRect:forKey:
encodeWithCoder:
encoder:didEncodeSampleBuffer:
encoder:didFailWithError:
encoderDidEncodeSampleBuffer
encoderDidFailWithError
encoderQueue
endedAtTime:
entropy:numPixels:
entropyOfLaplacianForBGRAPixelBuffer:
entropyOfSaturationForBGRAPixelBuffer:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
enumeratorAtPath:
equivalencyCellForPerson:
equivalencyCellForPerson:homeUUID:error:
equivalencyTablesByHome
error
errorWithDomain:code:userInfo:
event
eventClass
eventClassForShortName:
eventClasses
eventClassesArray
eventConfidenceThresholdsHigh
eventTriggers
events
eventsForFragment
eventsForTimeStamp:
eventsWithContentsOfFile:
eventsWithFaceEventsFromTorsoEventsFromEvents:homeUUID:
exceptionWithName:reason:userInfo:
exchangeObjectAtIndex:withObjectAtIndex:
existingAtCurrentVersion
existingAtOtherVersions
existingFaceCropUUIDs
existingPersonFaceCropUUIDs
existingPersonUUIDs
expectedAttributeForKey:
expectedDuration
expectedFrameRate
expirationInterval
exportAsynchronouslyWithCompletionHandler:
extent
external
externalPersonManagers
extractObjectsInTimeRange:
face
faceAestheticQualityFilter
faceAttributes
faceBoundingBoxFromPhotosFaceCropData:
faceCentroid
faceClassification
faceClassificationEnabled
faceClassifications
faceClassifier
faceCount
faceCountForPersonWithUniqueIdentifier:
faceCountsByPerson
faceCrop
faceCropDimensionsFromFaceCrop:error:
faceCropFromPhotosFaceCropImageData:
faceCropFromTorsoModelForHomeUUID:personUUID:sourceUUID:
faceCropUUID
faceCropUUIDs
faceCrops
faceCropsForPerson:
faceDistanceFromDescriptor:toDescriptor:
faceId
faceObservationFromFaceprint:
faceObservationFromTorsoprint:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceObservationWithRequestRevision:unalignedBoundingBox:alignedBoundingBox:
faceObservationsForPersonWithUniqueIdentifier:error:
faceObservationsFromFaceprintsForClustering:
faceQualityScore
faceRecognizabilityFilter
faceVIPThresholdForTorsoAnnotation
facemaskCategory
faceprint
faceprintDefaultRevision
faceprintUUIDs
faceprinter
faceprintingDuration
faceprints
facesAreSamePersonFromSet:andSet:
facesAreSamePersonFromSet:andSet:distanceThreshold:percentMatchingThreshold:
falseNegative
falseNegativeKeys
falsePositive
falsePositiveKeys
familiarity
featureNames
featureValueForName:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
feedbackRequestURLForClipWithUUID:
feedbackServiceHost
feedbackServiceURL
fetchAllFaceprintsWithCompletion:
fetchAllPersonFaceCropsWithCompletion:
fetchAllPersonsWithCompletion:
fetchAllUnassociatedFaceCropsWithCompletion:
fetchClipWithUUID:completion:
fetchFaceCropsForPerson:
fetchFaceCropsForPersonsWithUUIDs:completion:
fetchFaceprintsForFaceCropsWithUUIDs:completion:
fetchOrCreateFaceprintsForCrops:person:
fetchPersons
fetchPersonsWithUUIDs:completion:
fetchSettingsWithCompletion:
ffArchiveRootURLWithError:
ffData
fileExistsAtPath:
fileHandleForReadingFromURL:error:
fileHandleForWritingAtPath:
fileSize
fileURLWithPath:
fileURLWithPath:relativeToURL:
fileURLWithPathComponents:
fillRatio
fillWithFloat:
filterEvents:withActivityZones:motionDetection:insetPercentageInclusion:insetPercentageExclusion:
filterWithName:withInputParameters:
finalizeFragmentResult:homePersonManager:analysisStateManager:
finish
finishLoading
finishWithCompletionHandler:
firstIndex
firstMotionDetectionInArray:withMode:
firstObject
firstVideoSampleByteRange
firstVideoSampleInformation
flattedTrainingResult
floatArrayByAdding:
floatArrayByScaling:
floatArrayBySubtracting:
floatValue
floats
flush
flushAsync
flushSegment
flushTorsoprints
flushWithCompletionHandler:
flushWithNextSamplePTS:
foregroundTimeStamp
fragment
fragmentData:handler:
fragmentSequenceNumber
fragments
frame
frameAnalyzer
frameAnalyzer:didAnalyzeFrame:
frameAnalyzer:didProduceAnalysisStateUpdate:
frameAnalyzerDidAnalyzeFrame
frameAnalyzerDidProduceAnalysisStateUpdate
frameAnalyzerFrameResultBuffer
frameReorderingRequired
frameResultIndices
frameResults
frameSampler
frameSampler:didDropFrame:
frameSampler:didSampleFrame:
frameSamplerDidDropFrame
frameSamplerDidSampleFrame
frameSelector
frameSelector:didSelectFrame:reference:
frameSelector:didSkipFrame:
frameSelector:prepareFrame:
frameSelectorDidSelectFrame
frameSelectorDidSkipFrame
frameSelectorPrepareFrame
frameThumbnailSampler
frameTimelapseSampler
frameTracker
frameTracker:didTrackFrame:background:motionDetections:tracks:
frameTrackerDidTrackFrame
fromTorsoClassification
generateAndSubmitStats:filteredEvents:motionDetection:activityZones:
generateFaceprintForFaceCrop:error:
generateVideoFramesForTimes:completionHandler:
getAnalyzerEvents:eventTriggers:enableFaceClassification:enableTorsoRecognition:
getBlobIDAtIndex:
getClustersWithFaces:error:
getCurrentSystemResourceUsage
getModelStoragePathForHome:error:
getModelStoragePathForModel:error:
getNextTaskID
getPackageEvents:foregroundEvents:newBackgroundEvents:backgroundTimeStamp:
getParameterOfType:forLayerNamed:error:
getParametersFromLayers:fromTask:error:
getResourceValue:forKey:error:
getRootModelStoragePathWithError:
getStoragePath
getTorsoModelStoragePathForHomeUUID:error:
getTorsoSubdirectoryPathForHomeUUID:error:
getTorsoToFaceCropStoragePathForHomeUUID:error:
getTorsoprinterVersionStoragePathForHomeUUID:error:
getUUIDBytes:
getUserDefinedPersonLinksStoragePathForHomeUUID:error:
globalSession
greedyMatchBetweenPredictionEvents:truthEvents:falsePositiveIndices:falseNegativeIndices:eventClass:regionOfInterest:confidenceThreshold:scoreThreshold:scoreFunction:
handleAssetData:withOptions:completionHandler:
handleAudioSampleBuffer:
handleBlock:
handleCleanupForPerson:
handleFrameAnalyzerResult:
handleMessageWithOptions:completionHandler:
handleMisclassifiedPersonForFaceCrop:
handleMotionDetection:inFrame:
handleNewFaceEvents:
handleRemoteStateUpdate:
handleRemoteStateUpdate:completionHandler:
handleRemovedFaceCropWithUUID:
handleRemovedPersonWithUUID:
handleSampleBuffer:
handleSampleBuffer:background:motionDetections:tracks:
handleSampleBuffer:errorHandler:
handleSampleBuffer:reference:
handleUpdatedFaceprint:
handleUpdatedPerson:
handleUpdatedPersonFaceCrop:
handleUpdatedSettings:
handleUpdatedUnassociatedFaceCrop:
handleVideoSampleBuffer:
hasBegun
hasEstimatedBoundingBox
hasFailed
hasNewBackground
hasPreferenceForKey:
hasPrefix:
hasSuffix:
hash
highConfidenceThresholds
highWaterMark
hmfErrorWithCode:
hmf_UUIDWithNamespace:data:
hmf_addObject:
hmf_firstObjectWithUUID:
hmf_isEmpty
hmf_isEqualToUUID:
hmf_objectsPassingTest:
hmf_removeFirstObject
hmf_zeroUUID
hmiErrorWithCode:
hmiErrorWithCode:description:
hmiErrorWithCode:description:underlyingError:
hmiErrorWithCode:underlyingError:
hmiPrivateErrorWithCode:
hmiPrivateErrorWithCode:description:
hmiPrivateErrorWithCode:description:underlyingError:
hmiPrivateErrorWithCode:underlyingError:
homeForHMPersonManagerUUID:
homeKitClient
homeKitOperationQueue
homeManager
homeManager:didAddHome:
homeManager:didReceiveAddAccessoryRequest:
homeManager:didRemoveHome:
homeManager:didUpdateAuthorizationStatus:
homeManagerDidUpdateHomes:
homeManagerDidUpdatePrimaryHome:
homeMetadata
homePersonManager
homePersonManagerForHomeUUID:
homePersonManagersForCurrentDevice
homePersons
homePersonsAndFaceCrops
homePersonsModelForHomeWithUUID:
homeToExternalEquivalencies
homeUUID
homeWithCameraProfileUUID:
homes
host
identifier
ignoreThermalAndSystemResourceUsageLevel
imageCreationOptions
imageData
imageMirroring
imageName
imageRotation
imageSize
imageWithData:
importingFromPhotoLibraryEnabled
imposeMinSizeFor:withOriginalSize:minCrop:
inactiveTracks
inclusion
indexOfObject:inSortedRange:options:usingComparator:
indexSet
indexSetWithIndexesInRange:
indexesOfObjectsPassingTest:
inferenceInputs:inferenceOutputs:trainingInputs:trainingOutputs:learningRate:error:
infoDictionary
init
initPrivate
initToFileAtPath:append:
initWith
initWithActivityZones:motionDetections:
initWithArray
initWithArray:
initWithAsset:
initWithAsset:presetName:
initWithAsset:readVideoTrack:readAudioTrack:
initWithBlob:trackIndex:
initWithBoundingBox:size:motionVectors:motionScore:motionMode:
initWithBoundingBox:text:color:opacity:value:
initWithBoundingBox:timeStamp:
initWithBoundingBox:timeStamp:blobArea:blobID:
initWithBundleIdentifier:
initWithCVPixelBuffer:
initWithCVPixelBuffer:imageParameters:error:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCachePolicy:
initWithClipManager:clip:
initWithClipMetadata:cameraMetadata:homeMetadata:
initWithCode:analysisFPS:message:
initWithCoder:
initWithConfidence:boundingBox:face:
initWithConfidence:boundingBox:face:torso:
initWithConfidence:boundingBox:faceRecognition:
initWithConfidence:boundingBox:motionScore:
initWithConfidence:boundingBox:roll:torsoRecognition:
initWithConfidence:boundingBox:userInfo:
initWithConfidence:boundingBox:yaw:roll:faceRecognition:torsoAnnotation:userInfo:
initWithConfidence:boundingBox:yaw:roll:faceRecognition:userInfo:
initWithConfidenceThresholds:nmsConfiguration:error:
initWithConfiguration:
initWithConfiguration:dynamicConfiguration:identifier:monitored:analysisFPS:timeSinceAnalyzerStarted:timeSinceLastFragmentWasReceived:bufferFillRatio:bufferSize:delay:currentPTS:numDecodedSamples:numDidAnalyzeFrames:numDidAnalyzeFragments:numDidAnalyzePackages:numDidCreateTimelapseFragments:averageAnalysisTime:encode:encoder:
initWithConfiguration:identifier:
initWithContentType:
initWithContentsOfFile:
initWithData:
initWithData:elementCount:elementType:lengthInBytes:confidence:requestRevision:
initWithData:encoding:
initWithData:error:
initWithData:options:session:
initWithData:timeRange:
initWithData:type:shape:strides:
initWithDataSource:
initWithDataSource:faceCrop:
initWithDataSource:faceCropUUIDs:
initWithDataSource:faceCropUUIDs:personUUID:source:
initWithDataSource:faceprint:
initWithDataSource:faceprintUUIDs:
initWithDataSource:faceprints:
initWithDataSource:person:
initWithDataTensor:
initWithDictionary
initWithDictionary:
initWithDictionary:forType:
initWithDictionary:regionOfInterest:
initWithDimensions:codecType:useHardwareAcceleration:error:
initWithError:
initWithEvent:time:
initWithEventClass:records:UUID:
initWithExistingAtCurrentVersion:createdAtCurrentVersion:existingAtOtherVersions:
initWithFaceCrop:faceprint:classifications:
initWithFaceCrop:faceprint:classifications:predictedLinkedEntityUUIDs:
initWithFaceCrop:faceprint:classifications:predictedLinkedEntityUUIDs:faceQualityScore:sessionEntityAssignment:sessionEntityUUID:
initWithFaceEvent:
initWithFaceEvent:torso:
initWithFaceRecognition:torsoprints:
initWithFaceRecognition:torsoprints:torsoModelVersion:
initWithFaceThreshold:singleLinkThreshold:percentConnectionsThreshold:error:
initWithFaceprint:
initWithFeedbackSession:cameraProfileUUID:clipUUID:
initWithFirstIndex:secondIndex:score:
initWithFloats:count:
initWithFragment:events:frameResults:thumbnails:configuration:outcome:
initWithFragments:
initWithFrame:events:
initWithFrame:events:annotationScores:detections:regionOfInterest:faceClassifications:
initWithFrame:events:backgroundEvents:backgroundTimeStamp:regionOfInterest:motionDetections:
initWithFrame:events:regionOfInterest:
initWithFrame:regionOfInterest:analyzerEvents:
initWithFrameRate:
initWithFrameReordering:
initWithHMHomePersonManager:
initWithHMPhotosPersonManager:
initWithHomeMangerConfiguration:
initWithHomeUUID:
initWithHomeUUID:dataSource:
initWithHomeUUID:sourceUUID:error:
initWithIdentifier:name:manufacturer:model:
initWithIdentifier:name:manufacturer:model:firmwareVersion:
initWithImageData:regionOfInterest:detections:
initWithInitializationSegment:separableSegment:
initWithInitializationSegment:separableSegment:timeRange:
initWithInitializationSegment:separableSegment:timeRange:firstVideoSampleByteRange:
initWithInitializationSegment:separableSegment:timeRange:sequenceNumbers:
initWithInitializationSegment:separableSegment:timeRange:sequenceNumbers:firstVideoSampleByteRange:
initWithInput:inputName:
initWithInterval:
initWithJPEGData:presentationTime:frameId:fragmentSequenceNumber:size:
initWithJPEGData:size:presentationTimeStamp:
initWithJSONObject:
initWithJSONPath:error:
initWithKey:ascending:
initWithKey:classificationScore:
initWithKey:detectionScores:frameResultIndex:
initWithKey:options:domain:defaultValue:
initWithKey:trackingScores:frameResultIndices:
initWithLabelIndex:confidence:boundingBox:yaw:roll:
initWithLabelIndex:confidence:unclampedBoundingBox:yaw:roll:
initWithLayerParameters:losses:preTrainingLoss:postTrainingLoss:
initWithLocaleIdentifier:
initWithMaxCapacity:
initWithMediaType:outputSettings:sourceFormatHint:
initWithMediumConfidenceThresholds:highConfidenceThresholds:analyzerConfiguration:error:
initWithModelPath:dataScalerPath:error:
initWithModelSummaries:homeToExternalEquivalencies:externalToExternalEquivalencies:
initWithModelURL:
initWithName:
initWithName:deferred:
initWithName:reason:userInfo:
initWithName:value:
initWithName:value:options:formatter:
initWithName:weights:biases:
initWithNewPersonEvent:timeStamp:
initWithNoCaching
initWithNotificationName:andQueue:andCallback:
initWithOrigin:motion:
initWithPackageResult:didPrivatizePackageResult:didEncryptPackageResult:maxNorm:l2Norm:
initWithPersonUUID:sourceUUID:
initWithPersonUUID:sourceUUID:confidence:
initWithPersonUUID:sourceUUID:confidence:fromTorsoClassification:familiarity:
initWithPersonUUID:sourceUUID:sessionEntityUUID:confidence:familiarity:
initWithPersonsModel:homeUUID:sourceUUID:externalLibrary:
initWithPersonsModels:userDefinedPersonLinks:error:
initWithPixelBuffer:
initWithPixelBuffer:fontSize:
initWithPixelBuffer:inputName:
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
initWithPixelBuffer:presentationTimeStamp:
initWithPlaylistString:
initWithPoint:
initWithPoints:isInclusion:
initWithSampleBuffer:
initWithSampleBuffer:score:motionDetections:tracks:
initWithSamples:imageName:boxesName:weightsName:classesName:
initWithService:
initWithShape:dataType:error:
initWithSourceUUID:externalLibrary:faceCountsByPerson:
initWithSourceUUID:homeUUID:external:
initWithSourceUUID:personUUID:confidence:linkedEntityUUID:
initWithString:attributes:
initWithTargetDuration:
initWithTaskID:cameraProfileUUID:clipUUID:
initWithTaskID:dataSource:faceCrop:
initWithTaskID:duration:
initWithTaskID:homeUUID:
initWithTaskID:homeUUID:dataSource:sourceUUID:personsModelManager:doImpurePersonCleanup:error:
initWithTaskID:homeUUID:sourceUUID:
initWithTaskID:homeUUID:sourceUUID:dataSource:externalLibrary:removeExcessFaceCrops:
initWithTaskID:homeUUID:timeout:
initWithTaskID:homeUUID:torsoAnnotations:
initWithTaskID:timeout:
initWithThresholdWithLabels:metricWithLabels:thresholdDefault:metricDefault:
initWithTime:date:
initWithTimeInterval:options:
initWithTimeout:
initWithTitle:outputPath:
initWithTorsoAnnotations:
initWithTorsoAnnotationsArray:
initWithTorsoEvent:
initWithTorsoprint:
initWithTorsoprint:classification:predictedLinkedEntityUUIDs:sessionEntityAssignment:sessionEntityUUID:
initWithTrainingModelDefinition:forPlatform:error:
initWithTrainingNetworkPath:data:error:
initWithTrainingNetworkPath:inferenceInputs:inferenceOutputs:trainingInputs:trainingOutputs:trainingControlVariableName:withInitializer:error:
initWithTruePositiveKeys:falseNegativeKeys:falsePositiveKeys:groupByKey:
initWithURL:
initWithURL:options:
initWithUUID:
initWithUUID:data:
initWithUUID:data:lowQuality:unrecognizable:
initWithUUID:data:modelUUID:faceCropUUID:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:personUUID:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:personUUID:source:
initWithUUID:homeUUID:
initWithUUID:name:
initWithUUID:name:personLinks:
initWithUUID:name:personsModelIdentifier:faceBoundingBox:
initWithUUID:sourceUUID:faceBoundingBox:
initWithUUID:sourceUUID:sessionEntityUUID:faceBoundingBox:facecrop:faceprint:confidence:
initWithUUID:sourceUUID:sessionEntityUUID:faceCrop:faceprint:confidence:familiarity:
initWithUUID:sourceUUID:sessionEntityUUID:faceCrop:faceprint:confidence:fromTorsoClassification:familiarity:
initWithUUIDPairString:
initWithUUIDString:
initWithValue:
initWithValue:count:
initWithValue:levelThresholds:
initWithValue:time:
initWithVideoFormat:audioFormat:
initWithVideoFormat:audioFormat:initialFragmentSequenceNumber:preferredOutputSegmentInterval:
initWithVideoFragment:
initWithWeakObject:
initWithWindowSize:
initializationSegment
input
inputAudioFormat
inputFeatureValueName
inputName
inputQueue
inputVideoFormat
insertObject:atIndex:
insertTimeRange:ofTrack:atTime:error:
intValue
integerValue
internalAnalyzers
intersectsSet:
isAudioAccessory
isBoundingBoxEstimated
isCancelled
isClassified
isCombinableWithFragment:
isCurrentDevicePrimaryResident
isDate:inSameDayAsDate:
isEqual:
isEqualToData:
isEqualToDate:
isEqualToDictionary:
isEqualToNumber:
isEqualToSet:
isEqualToString:
isExpiredAtTimeStamp:
isExternalLibrary
isFaceClassificationEnabled
isFull
isIdentityPureWithFaceprints:person:
isIdle
isImportingFromPhotoLibraryEnabled
isInclusion
isInitializationSegment:combinableWithInitializationSegment:
isInternalInstall
isKindOfClass:
isLostAtTimeStamp:
isMemberOfClass:
isPermitted
isPrimary
isProductTypeB238
isProductTypeB520
isProductTypeB620
isProductTypeJ105
isProductTypeJ255
isProductTypeJ305
isProductTypeJ42
isReadable
isReadyForMoreMediaData
isSentinelFaceprint
isSharingFaceClassificationsEnabled
isSkipped
isStationaryAtTimeStamp:
isSubsetOfSet:
isSuccess
isValidFaceCrop:
jpegData
jsonReperesentaionOfDetectedObject:motionDetection:eventClass:
kick
l2Norm
label
labelIndex
labelIndexForEventClass:
lastAudioPresentationTimeStamp
lastBlob
lastFragmentReceivedDate
lastKnownTimeStamp
lastObject
lastPathComponent
lastSampleBufferDTS
lastSampleBufferPTS
lastVideoPresentationTimeStamp
lazyPayloads
length
lengthInBytes
level
lines
linkedEntityUUID
linkedEntityUUIDs
linkedPredictionsForPrediction:homeUUID:error:
loadModelAtPath:error:
loadModelsWithError:
loadPersonsModelFromURL:externalLibrary:homeUUID:error:
loadTorsoToFaceCrop:error:
loadTorsoprinterVersion:error:
loadUserDefinedPersonLinksForHomeUUID:error:
loadValuesAsynchronouslyForKeys:completionHandler:
loadValuesSynchronously
localeWithLocaleIdentifier:
localizedStandardCompare:
localizedStringForKey:value:table:
lock
logCategory
logIdentifier
logPreferenceForKey:value:
logStateCount
losses
lowQuality
main
mainBundle
mainInsideAutoreleasePool
maintainAspectRatio:originalSize:ratioThreshold:
manufacturer
maxAnalysisFPSForCurrentPeakPowerPressureLevel
maxAnalysisFPSForCurrentThermalLevel
maxAnalysisFPSForSystemResourceUsageLevel:
maxCandidates
maxConcurrentAnalyzersForCurrentPeakPowerPressureLevel
maxConcurrentAnalyzersForCurrentThermalLevel
maxConcurrentAnalyzersForSystemResourceUsageLevel:
maxConfidenceEventForEventClass:
maxConfidenceEvents
maxFragmentAnalysisDuration
maxFragmentDuration
maxFrameDelayCount
maxH264VideoDecoders
maxH264VideoEncoders
maxH265VideoEncoders
maxKeyFrameIntervalDuration
maxReferences
mediaType
mediumConfidenceThresholds
mergedPersonEventsFromEvents:
metadataForCameraProfile:
metadataForClip:
metadataForClip:withCameraProfile:inHome:
metadataForHome:
metricDefault
metricWithLabels
midpoint
minFrameScale
minSampleSize
minimumUUIDInEquivalencyCell:
model
modelFromURL:options:error:
modelPathForResource:
modelSize
modelSummaries
modelURL
modelURLsFromPath:error:
modelUUID
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
monitored
motion
motionDetections
motionDetector
motionMode
motionScore
motionTimeStamps
motionValidInterval
motionVectors
movingAverage
movingAverageForInterval:defaultValue:
mutableBytes
mutableCopy
mutableCopyWithZone:
mutableFloats
na_arrayByFlattening
na_dictionaryByMappingValues:
na_each:
na_filter:
na_firstObjectPassingTest:
na_flatMap:
na_reduceWithInitialValue:reducer:
name
neighborsOfObject:
networkPath
newDictionaryPopulatedWithFaceCropDataFromImageData:
nextObject
nextTaskID
nightVision
nmsConfiguration
nmsMultiClass:output:nmsConfiguration:
nonMaximumSuppression:output:withThreshold:withMetric:
notificationName
null
numCandidates
numDecodedSamples
numDidAnalyzeFragments
numDidAnalyzeFrames
numDidAnalyzePackages
numDidCreateTimelapseFragments
numFailures
numImages
numTracks
numberFromString:
numberOfClusters
numberOfDataPoints
numberOfDroppedFrames
numberOfFaceprintsClustered
numberOfMatchesInString:options:range:
numberOfPersonsCreated
numberOfUnknownFaceprintsAssociated
numberPreferenceForKey:
numberPreferenceForKey:defaultValue:
numberPreferenceForKey:defaultValue:withMap:
numberPreferenceForKey:defaultValue:withParser:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
objectJSON
objectPrettyJSON
objectWithJSONData:classMap:
objectWithJSONObject:classMap:
objectWithJSONObjectString:classMap:
objectsAtIndexes:
objectsInTimeRange:includeEnd:
observationWithRequestRevision:boundingBox:
offset
offsetsOneFeatureValueNames
offsetsZeroFeatureValueNames
open
operationQueue
operations
opticalZoom
origin
outputImage
outputPath
overlapsWithElipseInsideRect:
overlapsWithElipseInsideRect:withInsetPercentage:
packageClassifierMode
packageTrainingResult:privatize:maxNorm:normBinCount:encryptionKey:error:
passthroughAudio
path
pathExtension
pathForResource:ofType:
pathWithComponents:
payloadWithCamera:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
persistModel:toPath:error:
persistTorsoToFaceCrop:forHomeUUID:error:
persistTorsoprinterVersionForHomeUUID:error:
persistUserDefinedPersonLinks:forHomeUUID:error:
person
personDataAvailableViaHomeKit
personFromHomePerson:
personIndices
personLinks
personManager
personManagerUUID
personSourceUUIDPairFromPersonLink:
personToEquivalencyCell
personToFaceCrops
personUUID
personUUIDs
personUniqueIdentifiers
personsModelIdentifier
personsModelManager
personsModelWithFaceObservations:error:
personsModelWithFaceObservationsByID:error:
personsModelsByHome
photosPersonManager
photosPersonManagerForHomeUUID:sourceUUID:
photosPersonManagerWithUUID:
photosPersons
photosPersonsAndFaceCrops
pixelBuffer
pixelBufferFrameWithError:
playlistString
point
points
position
postNotificationName:object:
postTrainingLoss
preTrainingInferenceOutputDictionary:preTrainingtrainingLossKeyName:error:
precision
predict:detectedObjects:error:
predict:output:error:
predictHomePersonFromFaceObservation:homeUUID:error:
predictPersonFromFaceObservation:homeUUID:error:
predictPersonFromFaceObservation:limit:canceller:error:
predictPersonFromTorsoObservation:homeUUID:error:
predictedLinkedEntityUUIDs
prediction
predictionFromFeatures:error:
preferenceCacheFlushTimer
preferenceLoggedValues
preferenceOverrides
preferenceOverridesInternal
preferredOutputSegmentInterval
prepareSampleBuffer:
presentationTime
presentationTimeStamp
pretendProductTypeIsUnknown
printWithHeight:
privateDescription
probability
processInfo
processName
productClass
productInfo
progressBlock
propertyDescription
publishInitialValue
publishLocalState:
publishValueForToken:
purgeURLIfNeeded:
qosMap
qualityPredictionFromSVMUsingFaceQualityFilterSVM:detectorConfidence:laplacian:yaw:boxSize:error:
queue
readData:
readDataToEndOfFile
readMaxValue:
readUInt32
readUInt64
readValue
readValueFromSensor:value:
reader
reason
reassociateFaceCropsWithUnknownSource:toPersonUUID:
recall
recognizeEvents:frame:regionOfInterest:homeUUID:
recognizeFaces
rectValue
redactFrames
redactedCopy
redactedCopyWithFrameResults:fragment:
redactedCopyWithMetadata
reducedConfiguration:
reducedConfiguration:configurations:
reducedConfiguration:states:
reencodeAssetURL:outputURL:bitRate:duration:analysisFPS:sampleFrameHandler:dropFrameHandler:
referenceInterval
references
regionOfInterest
registerAnalyzer:
regularExpressionWithPattern:options:error:
releaseCachedResources
releaseCachedVisionResources
removeAllIndexes
removeAllObjects
removeAllPreferenceOverrides
removeExcessFaceCrops
removeFaceCropsWithUUIDs:
removeFaceCropsWithUUIDs:completion:
removeFaceprintsWithUUIDs:completion:
removeIndex:
removeIndexes:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeNearestFaceprint:withFaceCrops:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsAtIndexes:
removeObjectsInRange:
removePerson:
removePersonsModelForHomeUUID:sourceUUID:error:
removePersonsModelWithRetryOnError:
removePersonsWithUUIDs:completion:
removedPersonFaceCrops
render:toCVPixelBuffer:
reorderBufferSize
replaceObjectAtIndex:withObject:
report
reportBuffer
requestAnalysisForAssetData:withProperties:andCompletionHandler:
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
reset
resizePixelBuffer:
resizePixelBuffer:size:error:
resizePixelBuffer:size:pixelFormat:options:error:
resizedSampleBuffers
resourceLoader
resourceLoader:didCancelAuthenticationChallenge:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceUsageMonitor
respondWithData:
respondsToSelector:
result
resume
retain
retainCount
retimer:didRetimeSampleBuffer:
retimerDidRetimeSampleBuffer
rgbColorCodeForEventClass:
roll
rollsFeatureValueNames
room
runningMean
runningStd
sampleBufferDelay
sanitizedData
sanitizedSeperableSegment
saveAnalyzerResultsToDisk
saveDESRecordWithVideoFrame:recordInfo:
saveFaceClassifications:videoId:fragmentId:frameId:baseURL:error:
saveRecordWithData:recordInfo:completion:
saveToJsonActivityZones:motionDetection:videoFragmentUrl:frameId:UUID:detectionID:zoneID:
saveTrainingNetwork:checkpoint:error:
sbuf
scale:
scalerModel
scheduleTask:
score
scoreForSubBoundingBox:eventClass:confidence:
scoresFeatureValueNames
secondIndex
seek:
selectBestObservation:faceBoundingBoxFromPhotos:
selectFramesWithRecord:truth:frameResults:
self
sendEventForClusteringTask:
sendEventForFaceEvent:homePersonManagerUUID:camera:
sendEventForPersonRecognitionType:camera:
sendEventForPersonsModels:
sendEventWithName:payloadBuilder:
sendEventsForFragmentResult:
sentinelFaceprint
sentinelFaceprintWithUUID:modelUUID:faceCropUUID:
separableSegment
sequenceNumber
serializeJSONObject:url:error:
serverTrust
serviceResult
services
sessionEntityAssignment
sessionEntityManager
sessionEntityUUID
sessionWithConfiguration:delegate:delegateQueue:
sessions
setActivityZones:
setAdjustBrightness:
setAllowBackgroundGPUCompute:
setAllowReducedConfiguration:
setAllowedUnits:
setAllowsNonnumericFormatting:
setAlwaysCopiesSampleData:
setAnalysisStateManager:
setAnalyzerDidAnalyzeFragmentWithResult:
setAnalyzerDidAnalyzeFrameWithResult:
setAnalyzerDidCreateTimelapseFragment:
setAnalyzerDidFailWithError:
setAnalyzerDidProduceAnalysisStateUpdate:
setArray:
setAssetData:
setAssetWriterDidOutputInitializationSegment:
setAssetWriterDidOutputSeparableSegment:
setAssignment:
setAverageBitRate:
setBackground:
setBackgroundChangeTimeStamp:
setBackgroundEstimator:
setBackgroundTimeStamp:
setBlobID:
setBuffer:
setBufferWillFlush:
setBufferWillHandleSampleBuffer:
setByAddingObject:
setByAddingObjectsFromArray:
setByAddingObjectsFromSet:
setByteRangeAccessSupported:
setCamera:
setCancelled:
setCandidate:
setClassMap:
setClipDestinationFileURL:
setClusterId:
setClusteringDuration:
setCompletionBlock:
setComputeUnits:
setContentLength:
setCountStyle:
setCurrentDTS:
setCurrentFragmentStartTime:
setCurrentPTS:
setDataRateLimit:
setDataSource:
setDateFormat:
setDecodeMode:
setDecoderDidDecodeSampleBuffer:
setDecoderDidFailWithError:
setDelegate:
setDelegate:queue:
setDelegateQueue:
setDetectionLevel:
setDidUpdateHomes:
setDiscretionary:
setDouble:forKey:
setDownloadProgressHandler:
setDropSamplesUntilSync:
setDynamicConfiguration:
setEnableTemporalEventFiltering:
setEnabled:
setEncode:
setEncoder:
setEncoderDidEncodeSampleBuffer:
setEncoderDidFailWithError:
setError:
setEventClass:
setEventTriggers:
setExpectedDuration:
setExpectedFrameRate:
setExpectsMediaDataInRealTime:
setExternalPersonManagers:
setFaceClassificationEnabled:
setFaceCrops:
setFaceId:
setFaceRecognition:
setFaceprint:
setFaceprintUUIDs:
setFaceprintingDuration:
setFetchVideoAssetContextCompletionBlock:
setForceKeyFrameOnNextEncodedFrame:
setForegroundTimeStamp:
setFrameAnalyzerDidAnalyzeFrame:
setFrameAnalyzerDidProduceAnalysisStateUpdate:
setFrameSamplerDidDropFrame:
setFrameSamplerDidSampleFrame:
setFrameSelectorDidSkipFrame:
setFrameSelectorPrepareFrame:
setFrameTrackerDidTrackFrame:
setHTTPMethod:
setHasFailed:
setHighWaterMark:
setHomePersonManager:
setHomeUUID:
setIgnoreThermalAndSystemResourceUsageLevel:
setImageSize:
setImportingFromPhotoLibraryEnabled:
setInitialMovieFragmentSequenceNumber:
setInitialSegmentStartTime:
setInitializationSegment:
setInput:
setInputAudioFormat:
setInputDetectedObjectObservations:
setInputFaceObservations:
setInputVideoFormat:
setLastAudioPresentationTimeStamp:
setLastFragmentReceivedDate:
setLastSampleBufferDTS:
setLastSampleBufferPTS:
setLastVideoPresentationTimeStamp:
setLinkedEntityUUIDs:
setLocale:
setLogIdentifier:
setLogStateCount:
setMaxFragmentDuration:
setMaxFrameDelayCount:
setMaxH264VideoDecoders:
setMaxH264VideoEncoders:
setMaxH265VideoEncoders:
setMaxNumberOfElements:
setMaxReferences:
setMaximumFractionDigits:
setMaximumIdentities:
setMaximumTrainingFaceprintsPerIdentity:
setMediaTimeScale:
setMinFrameQuality:
setMinFrameScale:
setModel:
setModelSize:
setMonitored:
setMotionDetections:
setMovingAverage:
setName:
setNextTaskID:
setNumCandidates:
setNumImages:
setNumTracks:
setNumberOfClusters:
setNumberOfPersonsCreated:
setNumberOfUnknownFaceprintsAssociated:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjects:
setOptions:
setOutputFileType:
setOutputFileTypeProfile:
setOutputURL:
setPackageClassifierMode:
setPassthroughAudio:
setPersonDataAvailableViaHomeKit:
setPersonIndices:
setPhotosPersonManager:
setPreferenceOverrideFromDictionary:
setPreferredOutputSegmentInterval:
setPrevFrameResult:
setProgressBlock:
setQuality:
setQualityOfService:
setQueue:
setReadOnly:
setRecognizeFaces:
setRedactFrames:
setReferenceInterval:
setResetReferences:
setRetimerDidRetimeSampleBuffer:
setRevision:
setRevision:error:
setRunningStd:
setSampleRate:
setSaveAnalyzerResultsToDisk:
setServiceResult:
setSession:
setSharingFaceClassificationsEnabled:
setShouldUpdateRepresentative:
setSize:
setSource:
setStationaryBlobIndex:
setSupportsFaceClassification:
setSystemResourceUsageLevel:
setThumbnailHeight:
setThumbnailInterval:
setTimeRange:
setTimeZone:
setTimelapseAssetWriter:
setTimelapseEncoder:
setTimelapseInitializationSegment:
setTimelapseInterval:
setTimelapseOutputVideoFormat:
setTimelapsePreferredFragmentDuration:
setTimelapseVideo:
setTimelapseVideoPreferredFragmentDuration:
setToken:
setTorsoprintUUIDs:
setTotalDuration:
setTotalObjectCount:
setTrackAnalysisPTS:
setTranscode:
setTranscodeCodecType:
setValue:forHTTPHeaderField:
setValue:forKey:
setWithArray:
setWithObject:
setWithSet:
setZeroPadsFractionDigits:
settings
setup
shape
sharedInstance
sharedModel
sharingFaceClassificationsEnabled
shortDescription
shortNameForEventClass:
shouldEnableTorsoRecognition
shouldGenerateThumbnailForAnalysisFPS:
shouldRemoveExcessFaceCrops
shouldSignpost
shouldUseCPUOnlyForVisionFaceDetection
signal
significantEvents
signpostIdentifier
signpostLog
sihouetteScoreForMatches:previousMatches:truePositiveScores:falsePositiveScores:falseNegativeScores:
similarityToBlob:
similarityToPersonBlob:
size
sleepForTimeInterval:
sortUsingComparator:
sortedArrayUsingComparator:
sortedArrayUsingDescriptors:
sortedArrayUsingSelector:
source
sourceURL
sourceUUID
sourceUUIDForPerson:
standardUserDefaults
start
startDate
startReading
startSessionAtSourceTime:
startTime
startWriting
startedAtTime:
state
stateManager:didReceiveLocalUpdate:
stateUpdateByMergingStateUpdate:
stateUpdateFromFaceEvents:
stationaryBlobIndex
stationaryIndexToBoundingBox:
stationaryObjects
status
statusCode
statusOfValueForKey:error:
stop
storeFaceprint:completion:
storeUnassociatedFaceCrop:completion:
stream
string
stringByAppendingString:
stringByDeletingPathExtension
stringByPaddingToLength:withString:startingAtIndex:
stringByReplacingOccurrencesOfString:withString:
stringByTrimmingCharactersInSet:
stringFromByteCount:
stringFromNumber:
stringPreferenceForKey:defaultValue:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
subarrayWithRange:
subdataWithRange:
submitCoreAnalyticsEvent:filteringLevel:numberOfDetectedObjects:
submitCoreAnalyticsEventForActivityZones:motionScore:
submitFeedbackWithCameraProfileUUID:clipUUID:runRemotely:completionHandler:
submitTask:progressHandler:completionHander:
submitTaskWithOptions:completionHandler:
submitTaskWithOptions:progressHandler:completionHandler:
submitTorsoprintsToModelManagerForHome:withTorsoAnnotations:
subsampleFacesForPersons:withFaceObservationsMap:dataSource:vnUUIDToFaceCropUUIDMap:
substringToIndex:
subtract:
summaryForHomeUUID:error:
superclass
supportsFaceClassification
supportsSecureCoding
svmInputName
svmOutputName
systemDeviceInformation
systemPreferenceValueForKey:
systemResourceUsageLevel
systemResourceUsageMonitorImpl
tableColumns
tableValues
target
targetDate
targetEventClassRanks
targetInterval
taskID
taskIdentifier
taskService
taskServiceClient
temporalEventFilter
temporaryFileURLs
text
thermalLevel
thermalPressureLevel
thresholdDefault
thresholdForLabel:
thresholdWithLabels
thumbnailInterval
thumbnails
tick
time
timeInterval
timeIntervalSinceDate:
timeIntervalSinceDateAtTime:
timeIntervalSinceNow
timeIntervalSinceReferenceDate
timeOffsetWithinClip
timeRange
timeSinceAnalyzerStarted
timeSinceLastFragmentWasReceived
timeStamp
timeZoneForSecondsFromGMT:
timelapseAssetWriter
timelapseEncoder
timelapseInitializationSegment
timelapseInterval
timelapseOutputVideoFormat
timelapsePreferredFragmentDuration
timelapseVideo
timelapseVideoPreferredFragmentDuration
timeline
timerDidFire:
token
torso
torsoAnnotations
torsoCentroid
torsoCount
torsoModelVersion
torsoModelsByHome
torsoRecognition
torsoToFaceCropByHome
torsoprint
torsoprintForTorsoPixelBuffer:unrecognizable:error:
torsoprinter
torsoprints
totalDuration
trackAnalysisPTS
trackIndex
trackInterval
trackNewPersons:knownPersons:regionOfInterest:timeStamp:
trackPersonBlob:
trackReports
tracks
tracksWithMediaType:
trainLayers:epochs:fromTask:shouldCalculatePreTrainingLoss:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
transaction
transcode
transcodeCodecType
transferPixelBuffer:crop:size:pixelFormat:options:error:
transferPixelBuffer:pixelFormat:options:error:
transferPixelBuffer:rotationAngle:crop:size:precision:error:
truePositive
truePositiveKeys
truth
truthReportFromLegacyClassificationFormat:
truthReportFromLegacyDetectionFormat:
type
typeWithIdentifier:
unalignedBoundingBox
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unassociatedFaceCrops
unionSet:
uniqueIdentifier
unknownFacesSavedCounts
unlock
unrecognizable
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
updatePersonEventWithPersonEvent:sessionEntityUUID:predictedLinkedEntityUUIDs:sessionEntityAssignment:
updatePersonsModelWithRetryOnError:
updatePreviousPrintsForSessionEntityUUID:faceRecognition:torsoRecognition:
updateTorsoModelAndGetTorsoAnnotationsForHome:
updateTorsoModelForHome:torsoAnnotations:error:
updatedFaceprintsForFaceCrops:withExistingFaceprints:error:
upload
uploadTaskWithRequest:fromFile:completionHandler:
userDefinedPersonLinksByHome
userInfo
usesCPUOnly
uuid
value
valueAtIndex:
valueForInterval:defaultValue:
valueForKeyPath:
valuePreferenceForKey:defaultValue:withMap:
valuePreferenceForKey:defaultValue:withParser:
valueWithBytes:objCType:
valueWithCMTime:
vectorWithString:
videoAnalyzerDidAnalyzeFragmentWithResult:state:
videoAnalyzerDidCreateTimelapseFragment:state:
videoAnalyzerDidFindFaceEvent:homePersonManagerUUID:camera:
videoAnalyzerDidTerminateWithError:state:
videoDuration
videoFormat
videoFormatDescription
videoInput
videoPackageAnalyzerDidClassifyCandidateAsPackage:camera:
videoPackageAnalyzerDidResetReferenceImageWithInterval:camera:
videoTrackTimeRange
visionPersonsModel
visualizeBackgroundMean
visualizeBackgroundStd
visualizeForegroundAssignment
visualizeForegroundDiffForPixelBuffer:
visualizeMotionDetections:frameSize:timeStamp:
vnSession
wait
waitUntilFinished
warmStart
watchdogTimer
weakDecoder
weakObjectsPointerArray
weightsName
whitespaceCharacterSet
windowSize
workQueue
write:maxLength:
writeData:
writeFragmentFileComparison:eventClass:outputPath:
writeHTMLReportComparison:truth:eventClass:comparisonType:assetPath:outputPath:limit:shuffle:
writeImageCropForEventClass:outputPath:assetPath:
writeImageCropFromFrame:events:outputPath:source:
writeJSONChartData:outputPath:
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
writeToFile:atomically:
writeToFile:atomically:encoding:error:
writeToURL:atomically:
writeToURL:atomically:encoding:error:
writeToURL:options:error:
yawsFeatureValueNames
zone
@16@0:8
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8@?16
v32@0:8@16@?24
v24@0:8@?<v@?@"NSSet"@"NSError">16
v32@0:8@"NSSet"16@?<v@?@"NSSet"@"NSError">24
v24@0:8@?<v@?@"NSError">16
v32@0:8@"NSSet"16@?<v@?@"NSError">24
v24@0:8@?<v@?@"HMIExternalPersonManagerSettings"@"NSError">16
f28@0:8r^v16i24
f24@0:8^{__CVBuffer=}16
@"NSObject"16@0:8
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56f64f68
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
f16@0:8
v16@0:8
@"NSString"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@28@0:8@16B24
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@32@0:8@16@24
v40@0:8@16@24@32
v24@0:8@16
v32@0:8@16@24
v64@0:8@16@24@32i40@44i52@56
v48@0:8@16i24@28i36@40
@"NSOutputStream"
@24@0:8@16
@"HMIDESMutableFloatArray"
@"NSMutableArray"
@"NSMutableSet"
@"HMIFaceRecognition"
q16@0:8
v24@0:8q16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72@80
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72@80@88
@"NSNumber"
@"HMITorsoAnnotation"
@"<HMIPersonManagerDataSource>"
@"NSSet"
I16@0:8
v24@0:8Q16
@24@0:8Q16
@"NSData"
{?=qiIq}16@0:8
@48@0:8@16{?=qiIq}24
{?="value"q"timescale"i"flags"I"epoch"q}
@24@0:8q16
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
@64@0:8{?={?=qiIq}{?=qiIq}}16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@48@0:8{?=qiIq}16@40
@"NSDate"
v48@0:8@16{?=qiIq}24
@40@0:8{?=qiIq}16
d40@0:8{?=qiIq}16
@"HMIVideoEventBuffer"
v40@0:8{?=qiIq}16
d16@0:8
@"HMIVideoTimeline"
@"HMITimeIntervalAverage"
v24@0:8d16
d32@0:8d16d24
@"MovingAverage"
@60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
^{__CVBuffer=}40@0:8@16^{__CVBuffer=}24^@32
@36@0:8^{__CVBuffer=}16B24^@28
@"<HMIHomePersonManagerDataSource>"
v24@0:8@"HMFTimer"16
@"HMIHomePersonManagerSettings"
@"NSOperationQueue"
@"HMFTimer"
@"NSMutableDictionary"
@"HMIFaceCrop"
@"HMIFaceprint"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@80@0:8@16{?=qiIq}24Q48Q56{CGSize=dd}64
{CGSize=dd}16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"NSArray"
{CGSize="width"d"height"d}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}60@0:8^{__CVBuffer=}16{CGSize=dd}24I40q44^@52
^{__CVBuffer=}44@0:8^{__CVBuffer=}16I24q28^@36
^{__CVBuffer=}92@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56I72q76^@84
@40@0:8^{__CVBuffer=}16f24f28^@32
^{__CVBuffer=}32@0:8^{CGDataProvider=}16^@24
^{__CVBuffer=}32@0:8@16^@24
^{__CVBuffer=}40@0:8{CGSize=dd}16I32B36
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48{CGSize=dd}64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48f64
^{__CVBuffer=}92@0:8^{__CVBuffer=}16f24{CGRect={CGPoint=dd}{CGSize=dd}}28{CGSize=dd}60Q76^@84
@36@0:8Q16Q24f32
@24@0:8^{__IOHIDServiceClient=}16
^{__IOHIDServiceClient=}
B28@0:8i16^d20
B24@0:8^d16
^{__IOHIDEventSystemClient=}
@40@0:8@16@24^@32
B40@0:8^{__CVBuffer=}16@24^@32
B72@0:8^{__CVBuffer=}16@24@32@40@48@56^@64
v64@0:8@16@24@32@40@48@56
[7f]
[5{CGSize="width"d"height"d}]
@"HMINMSConfiguration"
@32@0:8@16B24B28
B32@0:8@16B24B28
^{opaqueCMSampleBuffer=}24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
^{opaqueCMSampleBuffer=}24@0:8^Q16
@"AVAsset"
@"AVAssetReader"
^{__CFArray=}
@"HMHomeManager"
v32@0:8@16Q24
v32@0:8@"HMHomeManager"16Q24
v24@0:8@"HMHomeManager"16
v32@0:8@"HMHomeManager"16@"HMHome"24
v32@0:8@"HMHomeManager"16@"HMAddAccessoryRequest"24
@?16@0:8
@"NSUUID"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLMultiArray"
B40@0:8@16^d24^@32
@"MLModel"
@"NSError"
v24@0:8^{opaqueCMSampleBuffer=}16
@"HMIVideoAnalyzerConfiguration"
@"HMIVideoAnalyzerDynamicConfiguration"
@"HMPhotosPersonManager"
@32@0:8q16@24
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@80@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72
@88@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72q80
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
@24@0:8#16
@"HMIVideoFrame"
@48@0:8^{__CVBuffer=}16{?=qiIq}24
v32@0:8@16^{opaqueCMSampleBuffer=}24
B48@0:8^{__CVBuffer=}16{?=qiIq}24
B52@0:8r*16B24{?=qiIq}28
@32@0:8@16^B24
v64@0:8@16@24@32{?=qiIq}40
v24@0:8^{__CVBuffer=}16
v40@0:8^{__CVBuffer=}16^f24i32i36
v32@0:8r^f16^{__CVBuffer=}24
f64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^S56
v68@0:8^S16S24S28{CGRect={CGPoint=dd}{CGSize=dd}}32f64
v44@0:8^f16^f24r^f32f40
v48@0:8^f16^f24r^f32r^f40
v24@0:8r*16
v44@0:8^{__CVBuffer=}16*24^S32B40
v32@0:8^{__CVBuffer=}16^f24
@48@0:8^S16{?=qiIq}24
@32@0:8^{__CVBuffer=}16Q24
^S16@0:8
v24@0:8^S16
^f16@0:8
v24@0:8^f16
v32@0:8{CGSize=dd}16
v20@0:8B16
B32@0:8@16@24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
q24@0:8@16
@88@0:8@16q24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@"HMICameraVideoFrame"
@"NSDictionary"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48
@40@0:8#16@24@32
@64@0:8#16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@28@0:8f16Q20
@32@0:8r^f16Q24
v20@0:8f16
v32@0:8r^f16Q24
r^f16@0:8
@20@0:8f16
@"NSMutableData"
@52@0:8@16^{__CVBuffer=}24B32@36^@44
@"HMIVideoAnalyzerEventFace"52@0:8@"HMIVideoAnalyzerEventFace"16^{__CVBuffer=}24B32@"NSUUID"36^@44
@24@0:8^@16
@64@0:8@16d24d32d40d48^@56
@"HMIFaceprinter"
@"HMIFaceQualityFilterSVM"
^{__CVBuffer=}24@0:8^@16
@56@0:8@16@24@32@40@48
@32@0:8Q16^@24
@32@0:8^{__CVBuffer=}16@24
@48@0:8@16@24@32@40
@76@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28@60@68
i16@0:8
v48@0:8@16@24d32q40
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56
f24@0:8@16
B40@0:8{?=qiIq}16
@"HMITorsoprint"
@"NSMutableIndexSet"
v88@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64
@104@0:8@16@24@32{?=qiIq}40{CGRect={CGPoint=dd}{CGSize=dd}}64@96
v32@0:8@"HMIVideoFrameSampler"16^{opaqueCMSampleBuffer=}24
B48@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24@32@40
@"<HMIVideoFrameAnalyzerDelegate>"
@"<HMICameraVideoFrameAnalyzer>"
@"HMIVideoFrameSampler"
v32@0:8@"HMIVideoFrameAnalyzer"16@"HMIVideoFrameAnalyzerResult"24
v32@0:8@"HMIVideoFrameAnalyzer"16@"HMIAnalysisStateUpdate"24
@36@0:8@16@24f32
@40@0:8@16@24Q32
@40@0:8@16@24@32
@44@0:8@16@24@32B40
v28@0:8@16B24
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
v48@0:8@16@24@32@40
@104@0:8@16@24@32@40#48{CGRect={CGPoint=dd}{CGSize=dd}}56f88f92@?96
v56@0:8@16@24@32@40@48
@32@0:8@16^@24
v44@0:8@16@24@32B40
@28@0:8f16@?20
@28@0:8@16f24
@36@0:8@16f24f28B32
@28@0:8B16@?20
@36@0:8@16B24f28B32
@36@0:8@16#24f32
@44@0:8@16#24f32f36B40
@40@0:8@16#24f32f36
v76@0:8@16@24#32@40@48@56Q64B72
v40@0:8#16@24@32
v40@0:8@16#24@32
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
^{opaqueCMSampleBuffer=}
@"<HMIVideoRetimerDelegate>"
v32@0:8@"HMIVideoRetimer"16^{opaqueCMSampleBuffer=}24
@20@0:8i16
@28@0:8i16d20
@36@0:8i16@20d28
i40@0:8@16@?24@?32
B20@0:8i16
v20@0:8i16
i32@0:8@16@?24
@"NSArray"16@0:8
@56@0:8@16@24@32q40@48
@"HMITorsoClassification"
^{__CVBuffer=}48@0:8@16^{__CVBuffer=}24@32^@40
q20@0:8i16
@32@0:8^{__CVBuffer=}16^@24
@"NSArray"32@0:8^{__CVBuffer=}16^@24
@"NSArray"32@0:8@"NSData"16^@24
@32@0:8{CGPoint=dd}16
{CGPoint=dd}16@0:8
{CGPoint="x"d"y"d}
@36@0:8i16@20@28
v40@0:8@16@24@?32
v32@0:8@"NSURLSession"16@"NSError"24
v40@0:8@"NSURLSession"16@"NSURLAuthenticationChallenge"24@?<v@?q@"NSURLCredential">32
v24@0:8@"NSURLSession"16
@"HMIHomeKitClient"
@"NSURLSession"
B40@0:8@16@24^@32
@"HMIFeedbackSession"
@"HMFOperation"
v44@0:8@16@24B32@?36
@52@0:8@16@24d32B40q44
@56@0:8@16@24@32d40q48
@72@0:8@16@24@32@40@48d56q64
@76@0:8@16@24@32@40@48d56B64q68
@96@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80d88
v48@0:8@16@24q32@?40
v24@0:8@?<v@?@"HMIHomePersonManagerSettings"@"NSError">16
v48@0:8@"NSSet"16@"NSUUID"24q32@?<v@?@"NSError">40
@28@0:8i16@20
@"HMIPersonFaceCrop"
@"HMIVideoAssetReader"
@32@0:8d16@24
@56@0:8Q16@24@32@40@48
@40@0:8q16@24@32
@48@0:8q16@24@32@40
@72@0:8@16{?={?=qiIq}{?=qiIq}}24
@80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
@96@0:8@16@24{?={?=qiIq}{?=qiIq}}32{_NSRange=QQ}80
@88@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80
@104@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80{_NSRange=QQ}88
{?={?=qiIq}{?=qiIq}}16@0:8
r^{opaqueCMFormatDescription=}16@0:8
{_NSRange=QQ}16@0:8
r^{opaqueCMFormatDescription=}
{_NSRange="location"Q"length"Q}
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@48@0:8@16@24@32q40
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56@80
@56@0:8@16@24@32@40^q48
v56@0:8@16@24@32@40^q48
@"HMIPersonTracker"
@"<HMIAnalysisStateManagerDelegate>"
@32@0:8^{__CVBuffer=}16d24
r^{__CTFont=}24@0:8d16
v48@0:8@16{CGPoint=dd}24r^d40
v64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48r^d56
v72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48@56r^d64
^{CGContext=}
^{CGColorSpace=}
^{__CTFont=}
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@36@0:8@16B24@28
@"VNPersonsModel"
@32@0:8@16q24
@36@0:8@16B24q28
v24@0:8#16
v28@0:8i16@20
v32@0:8q16@24
v32@0:8d16@24
v28@0:8B16@20
i24@0:8@16
d24@0:8@16
@32@0:8#16@24
B64@0:8@16@24Q32@40@48^@56
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGSize=dd}32@0:8@16^@24
@40@0:8@16@24B32B36
@40@0:8{?=ii}16I24B28^@32
B40@0:8{?=ii}16I24B28^@32
i32@0:8r^{__CFString=}16r^v24
i32@0:8r^{__CFString=}16r^^v24
i28@0:8r^{__CFString=}16i24
i32@0:8r^{__CFString=}16^i24
i32@0:8r^{__CFString=}16d24
i32@0:8r^{__CFString=}16^d24
v32@0:8{HMIVideoEncoderDataRate=qq}16
{HMIVideoEncoderDataRate=qq}16@0:8
^{OpaqueVTCompressionSession=}16@0:8
v24@0:8^{OpaqueVTCompressionSession=}16
^{OpaqueVTCompressionSession=}
@"<HMIVideoEncoderDelegate>"
v32@0:8@"HMIVideoEncoder"16^{opaqueCMSampleBuffer=}24
v32@0:8@"HMIVideoEncoder"16@"NSError"24
@"HMHomePersonManager"
B32@0:8@16@?24
q32@0:8q16@24
@40@0:8@16Q24Q32
B32@0:8@16^@24
B52@0:8@16@24B32@36^@44
B24@0:8^@16
@44@0:8@16B24@28^@36
@40@0:8@16@24f32f36
@64@0:8@16@24@32@40@48^@56
f40@0:8@16@24^@32
@52@0:8@16Q24@32B40^@44
@"HMIDESDataset"
@"NSURL"
@40@0:8Q16d24@32
@"<HMIExternalPersonManagerDataSource>"
@"HMIExternalPersonManagerSettings"
@36@0:8@16@24B32
@32@0:8@16@?24
@"HMISystemResourceUsageMonitor"
@"NSPointerArray"
B40@0:8@16^v24^@32
f32@0:8@16@24
@48@0:8@16@24@32^@40
@24@0:8^v16
{shared_ptr<homeai::clustering::GreedyClusterer>="__ptr_"^{GreedyClusterer}"__cntrl_"^{__shared_weak_count}}
@"<HMIVideoFrameSamplerDelegate>"
@"HMICIFilterAttributeValue"
@32@0:8@16d24
@"VNSession"
@"HMFOSTransaction"
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@64@0:8@16@24@32@40@48@56
@24@0:8B16B20
@"HMIVideoFragment"
@"HMIVideoAnalyzerResultOutcome"
@48@0:8@16@24@32f40f44
v28@0:8@16f24
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
B28@0:8@16f24
B72@0:8@16@24@32@40@48@56@64
B64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48#56
B48@0:8{CGPoint=dd}16{CGPoint=dd}32
v20@0:8I16
@"HMICamera"
@"HMIVideoAnalyzerEvent"
@80@0:8@16@24@32{?=qiIq}40{CGSize=dd}64
@80@0:8@16@24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48
B80@0:8@16{?=qiIq}24{CGRect={CGPoint=dd}{CGSize=dd}}48
@"HMIVideoAnalyzerFrameResult"
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64
@"HMIVideoAnalyzerEventFace"
@"HMIVideoAnalyzerEventTorso"
@44@0:8@16B24B28d32f40
@60@0:8@16B24d28Q36@44^@52
Q24@0:8q16
d24@0:8q16
B24@0:8d16
@40@0:8@16@24@?32
B28@0:8@16B24
@"HMIPerson"
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?=qiIq}48f72S76
S16@0:8
@32@0:8@16Q24
Q48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@40@0:8r*16@24@?32
r*16@0:8
@44@0:8^{opaqueCMSampleBuffer=}16f24@28@36
^{__CVBuffer=}24@0:8^{__CVBuffer=}16
v32@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24
^{opaqueCMSampleBuffer=}24@0:8^{opaqueCMSampleBuffer=}16
v44@0:8^{opaqueCMSampleBuffer=}16f24@28@36
@48@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24@32^f40
@56@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48
^{opaqueCMSampleBuffer=}40@0:8{?=qiIq}16
v56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24@48
v72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
^{__CFArray=}16@0:8
@"<HMIVideoFrameTrackerDelegate>"
@"HMIMotionDetector"
@"HMIVideoFrameTrackerFrameCandidate"
@"HMIBackgroundEstimator"
@"HMIHTMLReport"
v56@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48
v56@0:8@"HMIVideoFrameTracker"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"NSArray"40@"NSSet"48
B84@0:8@16@24q32{?=qiIq}40f64@?68@?76
B76@0:8@16@24{?=qiIq}32f56Q60^B68
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
^{__CVBuffer=}32@0:8^{__CVBuffer=}16@24
I40@0:8@16{CGSize=dd}24
@"HMIGreedyClustering"
@64@0:8i16@20@28@36@44B52^@56
@"<HMIFaceClassifier>"
@"HMIPersonsModelManager"
@"HMIClusteringTaskSummary"
@52@0:8i16@20@28@36B44B48
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8@16@24{CGSize=dd}32
@40@0:8@16q24B32B36
@64@0:8@16@24@32{?=qiIq}40
@72@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64
@64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@48@0:8@"NSDictionary"16@"NSDictionary"24@"HMIVideoAnalyzerConfiguration"32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8@"NSArray"16@"NSSet"24{CGSize=dd}32
@"NSSet"56@0:8@"HMIVideoFrame"16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"NSSet"40@0:8@"NSSet"16q24B32B36
@"NSSet"64@0:8@"NSSet"16@"NSSet"24@"NSMutableSet"32{?=qiIq}40
@"NSSet"72@0:8@"HMIVideoFrame"16@"NSSet"24@"NSMutableSet"32{CGRect={CGPoint=dd}{CGSize=dd}}40
@"NSSet"72@0:8@"NSSet"16@"HMIVideoFrame"24{CGRect={CGPoint=dd}{CGSize=dd}}32@"NSUUID"64
@"NSSet"64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@"HMIAnalysisStateUpdate"28@0:8@"NSUUID"16B24
@"NSDictionary"16@0:8
@80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56^@72
@32@0:8q16B24B28
@"HMISignificantActivityFcosDetector"
@"HMIFaceClassifierVIP"
@"HMITorsoClassifier"
@"HMISessionEntityManager"
@64@0:8@16{CGSize=dd}24{?=qiIq}40
@24@0:8^{opaqueCMSampleBuffer=}16
@40@0:8d16d24^@32
@"NSCondition"
@"<HMIVideoCommandBufferDelegate>"
v32@0:8@"HMIVideoCommandBuffer"16^{opaqueCMSampleBuffer=}24
v24@0:8@"HMIVideoCommandBuffer"16
@24@0:8d16
v32@0:8@16d24
v48@0:8@16d24{_NSRange=QQ}32
#24@0:8@16
@32@0:8#16q24
@"HMIConfidence"
@40@0:8@16@24d32
@20@0:8B16
B28@0:8^{opaqueCMSampleBuffer=}16B24
B24@0:8r^{opaqueCMFormatDescription=}16
^{opaqueCMBufferQueue=}16@0:8
v24@0:8^{opaqueCMBufferQueue=}16
^{OpaqueVTDecompressionSession=}16@0:8
v24@0:8^{OpaqueVTDecompressionSession=}16
@"<HMIVideoDecoderDelegate>"
^{opaqueCMBufferQueue=}
^{OpaqueVTDecompressionSession=}
@"HMFWeakObject"
v32@0:8@"HMIVideoDecoder"16^{opaqueCMSampleBuffer=}24
v32@0:8@"HMIVideoDecoder"16@"NSError"24
v48@0:8@16@24q32@40
v40@0:8@16@24q32
v48@0:8@"AVAssetWriter"16@"NSData"24q32@"AVAssetSegmentReport"40
v40@0:8@"AVAssetWriter"16@"NSData"24q32
@32@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24
@64@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24Q32{?=qiIq}40
@"<HMIVideoAssetWriterDelegate>"
@"AVAssetWriter"
@"AVAssetWriterInput"
v32@0:8@"HMIVideoAssetWriter"16@"NSData"24
v40@0:8@"HMIVideoAssetWriter"16@"NSData"24@"AVAssetSegmentReport"32
v32@0:8@"HMIVideoAssetWriter"16@"NSError"24
B48@0:8@16@24d32d40
@48@0:8{CGPoint=dd}16{CGVector=dd}32
{CGVector=dd}16@0:8
{CGVector="dx"d"dy"d}
@84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64f72Q76
f60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16#48f56
B60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16#48f56
@56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^f32@40Q48
@172@0:8{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}40{vector<cv::Point_<float>, std::allocator<cv::Point_<float>>>=^v^v{__compressed_pair<cv::Point_<float> *, std::allocator<cv::Point_<float>>>=^v}}64{vector<cv::Point_<float>, std::allocator<cv::Point_<float>>>=^v^v{__compressed_pair<cv::Point_<float> *, std::allocator<cv::Point_<float>>>=^v}}88@112Q120{vector<cv::Mat, std::allocator<cv::Mat>>=^{Mat}^{Mat}{__compressed_pair<cv::Mat *, std::allocator<cv::Mat>>=^{Mat}}}128{CGSize=dd}152f168
B72@0:8{CGPoint=dd}16{CGPoint=dd}32{CGSize=dd}48@64
@56@0:8^f16^{__CVBuffer=}24^{__CVBuffer=}32@40Q48
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{__CVBuffer=}56@64^@72
@"HMITorsoprinter"
{os_unfair_lock_s=I}16@0:8
@"<HMIVideoFrameSelectorDelegate>"
v40@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32
^{opaqueCMSampleBuffer=}32@0:8@16^{opaqueCMSampleBuffer=}24
v40@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32
v32@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24
^{opaqueCMSampleBuffer=}32@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24
@172@0:8@16@24@32B40d44d52d60d68Q76d84{?=qiIq}92Q116Q124Q132Q140Q148d156B164B168
@72@0:8@16@24@32@40d48q56@64
@44@0:8@16@24B32^@36
@"<HMIVideoAnalyzerDelegate>"
@"HMIHomePersonManager"
@"HMIAnalysisStateManager"
@"HMIVideoAnalyzerState"
@"HMIVideoAnalyzerMutableReport"
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoAnalyzerFragmentResult"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoAnalyzerFrameResult"24
v32@0:8@"HMIVideoAnalyzer"16@"NSError"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoFragment"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIAnalysisStateUpdate"24
v32@0:8@"HMIVideoAnalyzer"16@"NSDictionary"24
v32@0:8^{opaqueCMSampleBuffer=}16@?24
v32@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24
v24@0:8r^{opaqueCMFormatDescription=}16
v32@0:8:16@24
@"HMIVideoCommandBuffer"
@"HMIVideoDecoder"
@"HMIVideoEncoder"
@"HMIVideoFrameSelector"
@"HMIVideoFrameTracker"
@"HMIVideoFrameAnalyzer"
@"HMIVideoAssetWriter"
@"HMIVideoTemporalEventFilter"
@"HMITorsoRecognition"
gepj
v024
ffffff
333333
333333
333333
333333
333333
333333
@(#)PROGRAM:HomeAI  PROJECT:HomeAI-284
Mb@?
UsesIOSurface
HardwareAcceleratedTransfer
HighSpeedTransfer
HMIPixelBufferTransferMultiStageResize
a0cTa1cTa2cTa3cTa0hTa1hTa2hTa3hT
!$'*-0369<?BEHKNQTWZ]`cfilorux{~
 #&),/258;>ADGJMPSVY\_behknqtwz}
r@ffffff
N6homeai3mod28ImageDescriptorBufferFloat32E
&2uu
@LEN6homeai10clustering15GreedyClustererE
NSt3__120__shared_ptr_emplaceINS_6vectorIxNS_9allocatorIxEEEENS2_IS4_EEEE
NSt3__120__shared_ptr_emplaceIN6homeai10clustering15GreedyClusterer9cluster_tENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceINS_6vectorINS_5tupleIJxxfEEENS_9allocatorIS3_EEEENS4_IS6_EEEE
3tFN6homeai3mod29ImageDescriptorBufferAbstractE
?ffffff
 #&),/2
8;>ADGJMPSVY\_behknq
ffffff
>NSt3__120__shared_ptr_emplaceIN6homeai10clustering15GreedyClustererENS_9allocatorIS3_EEEE
MbP?
W>333?
Motion
Person
Vehicle
Package
?fff?
N2cv13BaseRowFilterE
N2cv16BaseColumnFilterE
N2cv10BaseFilterE
N2cv12FilterEngineE
N2cv18SymmRowSmallFilterIhiNS_17SymmRowSmallNoVecEEE
N2cv9RowFilterIhiNS_17SymmRowSmallNoVecEEE
N2cv18SymmRowSmallFilterIffNS_17SymmRowSmallNoVecEEE
N2cv9RowFilterIffNS_17SymmRowSmallNoVecEEE
N2cv9RowFilterIhiNS_8RowNoVecEEE
N2cv9RowFilterIhfNS_8RowNoVecEEE
N2cv9RowFilterIhdNS_8RowNoVecEEE
N2cv9RowFilterItfNS_8RowNoVecEEE
N2cv9RowFilterItdNS_8RowNoVecEEE
N2cv9RowFilterIsfNS_8RowNoVecEEE
N2cv9RowFilterIsdNS_8RowNoVecEEE
N2cv9RowFilterIffNS_8RowNoVecEEE
N2cv9RowFilterIfdNS_8RowNoVecEEE
N2cv9RowFilterIddNS_8RowNoVecEEE
N2cv12ColumnFilterINS_13FixedPtCastExIihEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIfsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIffEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
N2cv21SymmColumnSmallFilterINS_13FixedPtCastExIihEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_13FixedPtCastExIihEENS_11ColumnNoVecEEE
N2cv21SymmColumnSmallFilterINS_4CastIisEENS_20SymmColumnSmallNoVecEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_20SymmColumnSmallNoVecEEE
N2cv12ColumnFilterINS_4CastIisEENS_20SymmColumnSmallNoVecEEE
N2cv21SymmColumnSmallFilterINS_4CastIffEENS_20SymmColumnSmallNoVecEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_20SymmColumnSmallNoVecEEE
N2cv12ColumnFilterINS_4CastIffEENS_20SymmColumnSmallNoVecEEE
N2cv16SymmColumnFilterINS_4CastIfhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdhEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIftEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdtEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv12ColumnFilterINS_4CastIisEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIfsEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIdsEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIffEENS_11ColumnNoVecEEE
N2cv16SymmColumnFilterINS_4CastIddEENS_11ColumnNoVecEEE
N2cv8Filter2DIhNS_4CastIfhEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIftEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIfsEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DIhNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIftEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DItNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIfsEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DIsNS_4CastIddEENS_11FilterNoVecEEE
N2cv8Filter2DIfNS_4CastIffEENS_11FilterNoVecEEE
N2cv8Filter2DIdNS_4CastIddEENS_11FilterNoVecEEE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
(Zm
,6<FJ*M
9CIS
4Zucwsifdr
?qxs?qxs
9D)5:
@`|-A
PF SdF
 [@W:[
D]eV
"x@
z4I5z
?~my
!Y?4
!I?u
!)?gX
?g^FT
?$"LT
?$"LT
N2cv15ThresholdRunnerE
N2cv6detail16LKTrackerInvokerE
5ii5
9qq9
6kk6
7mm7
9qq9
N2cv9ColumnSumIihEE
N2cv9ColumnSumIitEE
N2cv9ColumnSumIisEE
N2cv6RowSumIhiEE
N2cv6RowSumIhdEE
N2cv6RowSumItiEE
N2cv6RowSumItdEE
N2cv6RowSumIsiEE
N2cv6RowSumIiiEE
N2cv6RowSumIsdEE
N2cv6RowSumIfdEE
N2cv6RowSumIddEE
N2cv9ColumnSumIdhEE
N2cv9ColumnSumIdtEE
N2cv9ColumnSumIdsEE
N2cv9ColumnSumIiiEE
N2cv9ColumnSumIifEE
N2cv9ColumnSumIdfEE
N2cv9ColumnSumIidEE
N2cv9ColumnSumIddEE
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
5:=`
26:V*V>VVV.VVVB
$yV'*-0N2cv11_InputArrayE
N2cv12_OutputArrayE
 #&),/258;>AD
ZZ9ZZZZZZ<Z?ZBZZZZEHZKNQTWgN2cv9ExceptionE
14EmptyFuncTable
12GpuFuncTable
N2cv16ParallelLoopBodyE
bnz
N2cv16MorphologyRunnerE
N2cv14MorphRowFilterINS_5MinOpIhEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MinOpItEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MinOpIsEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MinOpIfEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MinOpIdEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIhEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpItEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIsEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIfEENS_13MorphRowNoVecEEE
N2cv14MorphRowFilterINS_5MaxOpIdEENS_13MorphRowNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIhEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpItEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIsEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIfEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MinOpIdEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIhEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpItEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIsEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIfEENS_16MorphColumnNoVecEEE
N2cv17MorphColumnFilterINS_5MaxOpIdEENS_16MorphColumnNoVecEEE
N2cv11MorphFilterINS_5MinOpIhEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MinOpItEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MinOpIsEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MinOpIfEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MinOpIdEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIhEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpItEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIsEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIfEENS_10MorphNoVecEEE
N2cv11MorphFilterINS_5MaxOpIdEENS_10MorphNoVecEEE
N2cv5MatOpE
N2cv14MatOp_IdentityE
N2cv11MatOp_AddExE
N2cv9MatOp_BinE
N2cv9MatOp_CmpE
N2cv10MatOp_GEMME
N2cv12MatOp_InvertE
N2cv7MatOp_TE
N2cv11MatOp_SolveE
N2cv17MatOp_InitializerE
Error creating directory for person:%@
version
UUID
displayName
person.json
Error saving metadata to disk for person:%@
v8@?0
Error creating directory for person face crop:%@
faceBoundingBox
dateCreated
facecrop.json
Error saving metadata to disk for person face crop:%@
facecrop.jpeg
Error saving face crop image to disk for person face crop:%@
#ffffff
#000000
</body>
</html>
Visualizer saved (%@)
HMIHTMLReport
<html>
<head><title>%@</title></head>
<style>
</style>
<body text='%@' bgcolor='%@'>
<script>
</script>
%@<br>
border:%dpx;
border:%dpx solid %@;
outline:%dpx;
outline:%dpx solid %@;
<div class='image'>
<img width='%d' height='%d' src='data:image/jpeg;base64,%@' style='%@'/>
<div class='rect' style='top:%dpx; left:%dpx; width:%dpx; height:%dpx; border-color:%@; opacity:%.1f' threshold='%.3f'>%@</div>
v32@?0@"HMIHTMLReportBox"8Q16^B24
<div class="text">%@</div>
</div>
%.3fs
v16@?0@"HMIVideoAnalyzerFrameResult"8
@"NSValue"16@?0@"HMIVideoAnalyzerFrameResult"8
[%lu/%lu] %@ (%.2fs)
v32@?0@"HMIVideoFrame"8Q16^B24
v16@?0@"NSArray"8
v24@?0@"HMIVideoAnalyzerEvent"8^B16
confidence.value
v16@?0@"HMIVideoAnalyzerEvent"8
%.3f %@
%.3f
%.3f %@ %.2f %@
#ffff00
B16@?0@"HMITorsoprint"8
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
FaceFilteredState
HMIVAEF.fr
HMIVAEF.ta
HMIVAEF.ya
HMIVAEF.ro
None
QualitySVMKnown
QualitySVMUnknown
QualityANFRScore
NoPredictions
HasFaceMask
Face Recognition
Torso Annotation
Face Yaw
Face Roll
%@@(%@,%@)
v16@?0@"NSError"8
%c%c%c%c
Type: %@, DTS: %@, PTS: %@, DUR: %@, NUM: %ld [%@]
Sync
%c%02d:%02d:%02d.%03d
%*lld/%-6d %@
%*lld %@
POSITIVE INFINITY
NEGATIVE INFINITY
   INDEFINITE    
  INVALID TIME   
%@ DTS %@ PTS %@ dur %@%@
PTS: %.2f
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss
%.3f x %.3f
%.3f, %.3f %@
%.2f
%02x
q24@?0@"<HMIVideoEvent>"8@"<HMIVideoEvent>"16
B32@?0@"<HMIVideoEvent>"8Q16^B24
@16@?0@"<HMIVideoEvent>"8
Time: %@, Date: %@
HMIVAEM.ms
Motion score
%@@(%@)
Failed to set request revision
failed to perform image request
Expected 1 torsoprint, but got %lu torsoprints
torsoprint is nil
HMICoreAnalyticsVIPModelReportTime
v24@?0@"HMIHomePersonManagerSettings"8@"NSError"16
v24@?0@"NSDictionary"8@"NSError"16
B16@?0@"HMIFaceClassification"8
UUID:%@ HomeUUID:%@
Frame %lu @ %@
Logi Circle 2
%#{flags}
transferPixelBuffer
VTPixelTransferSessionCreate failed. Error %d
VTSessionSetProperty failed. Error %d
VTPixelTransferSessionTransferImage failed. Error %d
JPEGDataFromPixelBuffer
Invalid crop for affine transform
Error in pixelbuffer format for affine transform
Error generating pixelbuffer for affine transform
Error applying affine transform
q24@?0@"HMIPairwiseMatch"8@"HMIPairwiseMatch"16
v12@?0i8
/private/var
OutOfMemory
Reached high water mark.
HMIThermalPressureLevelNominal
HMIThermalPressureLevelLight
HMIThermalPressureLevelModerate
HMIThermalPressureLevelHeavy
HMIThermalPressureLevelTrapping
HMIThermalPressureLevelSleeping
HMIThermalPressureLevelUnknown
HMIThermalPressureLevelDidChangeNotification
PrimaryUsagePage
PrimaryUsage
LocationID
image_Placeholder
HomeSSD_box0_offset0
HomeSSD_box0_offset1
HomeSSD_box0_offset2
HomeSSD_box0_offset3
HomeSSD_box0_offset4
HomeSSD_box1_offset0
HomeSSD_box1_offset1
HomeSSD_box1_offset2
HomeSSD_box1_offset3
HomeSSD_box1_offset4
HomeSSD_class_prob0
HomeSSD_class_prob1
HomeSSD_class_prob2
HomeSSD_class_prob3
HomeSSD_class_prob4
HomeSSD_object_yaw0
HomeSSD_object_yaw1
HomeSSD_object_yaw2
HomeSSD_object_yaw3
HomeSSD_object_yaw4
HomeSSD_object_roll0
HomeSSD_object_roll1
HomeSSD_object_roll2
HomeSSD_object_roll3
HomeSSD_object_roll4
SignificantActivityFcosDetector
CoreML output nil or not of type MLFeatureTypeMultiArray
SignificantActivityFcos
mlmodelc
name
VeryLongTrackDuration
discussion
Track %@ has an unexpectedly long track duration %@.
v16@?0@"AVAssetTrack"8
WidelyDifferingTrackDurations
Track durations vary widely, this is usually caused by a corrupt video / audio sample duration.
v16@?0@"NSDictionary"8
Sanitized Data
Asset Check
HMIHomeKitClient HomeKit Delegate Queue
B16@?0@"HMHome"8
B16@?0@"HMResidentDevice"8
B16@?0@"HMCameraProfile"8
v16@?0@"HMHomeManager"8
Not supported error
General error
Espresso error
incorrect binserializer key
small sparsity error
feature extraction error
initialization error
no saved state to revert
nominal distance not changed
batch size violation
computation kill request was issued
too few IDs to build VIP model
video error
error with projection computation
missing positional parameter
inconsistent state error
warping error
OpenGL error
invalid format
out of bounds
singular point configuration error
division by zero
LAPACK error
platform endianess not supported
hash already in use
invalid ID
invalid data type
data inconsistency error
I/O error
unknown option
invalid option
missing option
delegate error
vImage related error
memory allocation error
invalid parameter
unexpected null pointer
internal error
not implemented error
CVML_status module %d error %lld
BinSerializer
Face3D
FaceDescriptor
FaceFrontalizer
FaceWarper
Geometry2D
Geometry3D
ImageGrouping
ImageQuality
LandmarkDetector
MomentProcessor
FaceboxAligner
ImageDescriptor
ImageClassifier
ImageProcessing
VIPIdentification
ImageRegistration
SimilarityMatrix
Clustering
HumanDetector
FaceRegionMap
ObjectDetector
ObjectTracker
SRCClassifier
Kmeans
SparseCoding
FaceID
BoostedClassifier
FaceSegmenter
ImageAnalyzer
FaceAttributes
FaceprintAndAttributes
FaceQuality
Generic
ImageTools
VideoTools
ImageWarper
ThirdParty
BinSerializerProcessor
AppleNetParser
FaceProcessorCLI
ImageClassifierCLI
MPCmdlineClientCLI
ClusteringCLI
ImageProcessorCLI
PhotosProcessorCLI
CVMLEngine
CVML Module %lld
%@ (%@)
input
transformed_features
classProbability
FaceRecognizabilityFilterSVM
FaceRecognizabilityFilterSVMDataScaler
FaceAestheticQualityFilterSVM
FaceAestheticQualityFilterSVMDataScaler
You must override %@ in a subclass
@16@?0@"HMPerson"8
v24@?0@"NSSet"8@"NSError"16
@16@?0@"HMPersonFaceCrop"8
@16@?0@"HMFaceprint"8
@16@?0@"HMIFaceprint"8
com.apple.cvml.%@
CVML module = %@
HMIFC.ck.pu
HMIFC.ck.so
Unknown
PhotoLibrary
User
ImpureClusteringCleanup
Unknown source: %ld
dataRepresentation
personUUID
Person UUID
Source
frame
Frame
Events
Region of Interest
B16@?0@"HMIVideoAnalyzerEvent"8
@16@?0#8
q24@?0@"HMIVideoAnalyzerFrameResult"8@"HMIVideoAnalyzerFrameResult"16
CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange || CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange
v16@?0@"HMIVideoAnalyzerTrack"8
{CGRect={CGPoint=dd}{CGSize=dd}}
v16@?0@"HMIMotionVector"8
B16@?0@"HMIVideoAnalyzerBlob"8
v32@?0@"HMIVideoAnalyzerBlob"8Q16^B24
v32@?0@"HMIVideoAnalyzerTrack"8Q16^B24
v16@?0@"HMIPairwiseMatch"8
v24@?0Q8^B16
B16@?0@"HMIVideoAnalyzerTrack"8
B16@?0@"NSValue"8
CVPixelBufferGetPixelFormatType(pixelBuffer) == kCVPixelFormatType_420YpCbCr8BiPlanarFullRange
vector
hmi://in-memory
HMIMemoryAVAsset
tracks
Invalid parameter for windowSize: %lu, windowSize must be > 0
v16@?0@"MovingAverageEntry"8
@16@?0@"HMIVideoAnalyzerEvent"8
class
timestamp
uuid
v32@?0@"NSArray"8Q16^B24
@16@?0@"NSDictionary"8
v16@?0@"HMIVideoAnnotationParserTrack"8
{CGRect={CGPoint=dd}{CGSize=dd}}80@?0{CGRect={CGPoint=dd}{CGSize=dd}}8{CGRect={CGPoint=dd}{CGSize=dd}}40f72f76
@16@?0@"HMIVideoAnnotationParserTrack"8
@16@?0@"HMIPersonsModelPrediction"8
detections
bounds
label
confidence
filters
v16@?0@8
com.apple.HomeAIDESPlugin
v24@?0@"NSUUID"8@"NSError"16
bias_b
bias_g
bias_r
is_network_bgr
scale
Label:%d Confidence:%f X:%f Y:%f Width:%f Height:%f Yaw:%@}
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
@16@?0@"HMIObjectDetection"8
PersonBlob(PTS:%.2f): %@ (%@%@%@%@)
@"HMIPersonBlob"16@?0@"HMIVideoAnalyzerEventPerson"8
@16@?0@"HMIVideoAnalyzerEventPerson"8
@16@?0@"HMIPersonBlob"8
v32@?0@"HMIPersonBlob"8Q16^B24
v24@?0@"NSNumber"8@"NSNumber"16
<%@: %p> timeStamp: %@, detections: [%@], regionOfInterest: %@
<%@: %p> %@
self.dynamicConfiguration
@16@?0@"HMIVideoAnalyzerTrack"8
@max.floatValue
@16@?0@"HMIVideoAnalyzerReportRecord"8
@sum.count
Precision
Recall
True Positive
False Negative
False Positive
Fragments
v16@?0@"HMIVideoAnalyzerFragmentResult"8
v24@?0@"NSString"8@"HMIVideoAnalyzerMutableReportSession"16
v16@?0#8
@"HMIVideoAnalyzerMutableReportComparison"20@?0#8f16
precision
recall
threshold
annotation
opacity
/System/Library/CoreServices/SystemVersion.plist
com.apple.HomeAI
HomeAIBundleVersion
Debug
Truth
image_id
B16@?0@"NSDictionary"8
classification_classes
@16@?0@"NSString"8
@24@?0@"NSString"8@"HMIVideoAnalyzerMutableReportSession"16
f56@?0@"HMIVideoAnalyzerEvent"8@"HMIVideoAnalyzerEvent"16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"NSArray"16@?0@"HMIVideoAnalyzerEvent"8
@24@?0@"NSNumber"8@"NSNumber"16
@16@?0@"NSNumber"8
v32@?0@"HMIVideoAnalyzerFrameResult"8Q16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
v16@?0@"NSNumber"8
score
%@%@
Object detection (%@)
Visualize%@.html
%lu %@s (Precision: %.3f, Recall: %.3f)
v16@?0@"HMIVideoAnalyzerReportRecord"8
@"NSValue"16@?0@"HMIVideoFrame"8
@16@?0@"HMIVideoFrame"8
q24@?0@"NSString"8@"NSString"16
Fragment%@%@.txt
v24@?0@"NSString"8@"NSArray"16
PRArray.json
domain
range
@24@?0@"NSString"8@"NSString"16
'%@': '%@'
{%@}[datum.label]
labelExpr
$schema
https://vega.github.io/schema/vega-lite/v4.json
description
PR Curves
width
container
height
data
config
style
align
center
baseline
layer
mark
type
line
clip
true
point
encoding
field
quantitative
color
nominal
legend
text
left
%@_%.0f_%@_%lu.png
v32@?0@"HMIVideoAnalyzerEvent"8Q16^B24
v16@?0@"HMIVideoAnalyzerReportMatch"8
v32@?0@"NSUUID"8@"HMIVideoAnalyzerEventPerson"16^B24
HMIFC.ck.u
HMIFC.ck.dr
HMIFC.ck.dc
HMIFC.ck.fbb
Data Representation
Date Created
Face Bounding Box
mediaType == kCMMediaType_Video
Descriptor count = 
Descriptor length = 
 bytes
 = [
basic_string
identifier
Identifier
Name
Manufacturer
Model
Firmware Version
Descriptor vectors nil
Success
Canceled
Error
UpdatePersonsModelTask
RemovePersonsModelTask
HomePersonClusteringTask
FaceMisclassificationTask
PersonsModelsSummaryTask
UpdateTorsoModelTask
FeedbackTask
EmptyTask
resultCode
taskType
faceCrop
sourceUUID
homeUUID
isExternal
doImpurePersonCleanup
cameraProfileUUID
clipUUID
torsoAnnotations
duration
Unknown task type: %@
v16@?0d8
v32@?0@"HMITask"8Q16^B24
HMITaskHomeUUIDKey is nil
HMIUpdatePersonsModelTaskIsExternal is nil
HMIPersonsModelTaskSourceUUID is nil
Failed to get HMPhotosPersonManager
Failed to get HMHomePersonManager
Failed to initialize data source
Disk-based Home Person Data Source not supported
HomeUUID is nil
cleanup key is missing
HMIUpdateTorsoModelTaskAnnotationsKey is nil
HMIEmptyTaskDurationKey is nil
HMITaskService not available on this platform.
HMITR.c
HMITR.tp
HMITR.sea
HMITR.seu
v16@?0@"HMIFaceprint"8
warm_start_faceprint_model
CreateFaceprint
B16@?0@"HMIFaceprint"8
HMIFP.ck.u
HMIFP.ck.d
HMIFP.ck.mu
HMIFP.ck.fcu
modelUUID
faceCropUUID
Data
Model UUID
Face Crop UUID
cameraName
cameraUUID
roomName
nightVision
currentHorizontalTilt
currentVerticalTilt
opticalZoom
digitalZoom
imageRotation
imageMirroring
model
manufacturer
firmwareVersion
@16@?0@"HMCameraClipSignificantEvent"8
timeOffsetWithinClip
dateOfOccurrence
confidenceLevel
reason
startDate
quality
significantEvents
<%0.3f %0.3f>
HMPMS.fce
Face Classification Enabled
faceCrops
authTag
internal
wrappedKey
1.2.840.113635.100.6.27.38
HMIFeedback Queue
hkcvml.apple.com
hkcvml-dev.apple.com
HFFeedbackService
camera.recording.feedback
Cannot find camera profile.
Cannot find home for camera profile.
Cannot download clip asset.
Check network connectivity.
v24@?0@"HMCameraClipVideoAssetContext"8@"NSError"16
v16@?0Q8
v16@?0@"HMCameraClip"8
Cannot download clip for camera profile.
Ensure the clip belongs to the camera profile.
v24@?0@"HMCameraClip"8@"NSError"16
Unable to blur faces.
Unable to read the asset from disk.
Clip doesn't have a video track.
https://%@/v2/clip-uuid/
feedback
%@.%@
json
application/json
Content-Type
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
Invalid key size.
Cannot generate initialization vector.
Failed to encrypt data.
Failed to encrypt face crop data.
v24@?0@"NSURL"8@"NSError"16
Status Code:400, Error: Resource not found on server error
Status Code:500, Error: Internal server error
Unkown server error
v16@?0@"NSURL"8
HMIFC.pu
HMIFC.su
HMIFC.seu
HMIFC.fc
HMIFC.fp
HMIFC.c
HMIFC.ftc
HMIFC.f
Known
Uncertain
Source UUID
Session Entity UUID
Confidence
Familiarity
FaceCrop UUID
Faceprint UUID
FromTorsoClassification
@"NSUUID"16@?0@"HMIPerson"8
@"NSUUID"16@?0@"HMIPersonFaceCrop"8
v16@?0@"NSSet"8
@"NSUUID"16@?0@"HMIFaceCrop"8
Invalid person UUIDs
v32@?0@"HMIPerson"8@"NSSet"16^B24
B16@?0@"HMIPerson"8
Not implemented
Invalid persons, person already exists
v16@?0@"HMIPerson"8
Invalid faceCropUUIDs
B16@?0@"HMIPersonFaceCrop"8
Invalid persons, person UUID doesn't exists
Invalid personUUID
@"HMIPersonFaceCrop"16@?0@"HMIFaceCrop"8
B16@?0@"HMIFaceCrop"8
@"HMIPersonFaceCrop"16@?0@"HMIPersonFaceCrop"8
NOT IMPLEMENTED
@16@?0@"HMIPersonFaceCrop"8
SourceUUID:%@ HomeUUID:%@
v24@?0@"HMIVideoDecoder"8^{opaqueCMSampleBuffer=}16
Medium
High
%.4f
%.2f[%c]
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to read fragment
Failed to verify fragment
Failed to transcode fragment
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToReadFragment
HMIErrorCodeFailedToVerifyFragment
HMIErrorcodeFailedToTranscodeFragment
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodeCodecNotAvailable
HMIPrivateErrorCodeEncodingFailed
HMIPrivateErrorCodeInvalidVideoFrameFormatToSave
HMIPrivateErrorCodeScalerError
HMIPrivateErrorCodeFaceprintingFailed
HMIPrivateErrorCodeUpdatePersonsModelTaskFailed
HMIPrivateErrorCodeExternalPersonSourceDiskError
HMIPrivateErrorCodeLoadPersonsModelsFailed
HMIPrivateErrorCodeUpdatePersonsModelFailed
HMIPrivateErrorCodeRemovePersonsModelFailed
HMIPrivateErrorCodePersonsModelPredictionFailed
HMIPrivateErrorCodeNilDataSource
HMIPrivateErrorCodeUnknownTask
HMIPrivateErrorCodeHomePersonClusteringTaskFailed
HMIPrivateErrorCodeRemovePersonsModelTaskFailed
HMIPrivateErrorCodeFaceMisclassificationTaskFailed
HMIPrivateErrorCodePersonsModelsSummaryTaskFailed
HMIPrivateErrorCodeCleanupImpureHomePersonsOperationFailed
HMIPrivateErrorCodeFeedbackServiceInternalServerError
HMIPrivateErrorCodeFeedbackServiceResourceNotFoundError
ERROR_%ld
fragments.count >= 1
[first isCombinableWithFragment:fragment]
v16@?0@"HMIVideoFragment"8
B28@?0I8@"NSData"12@"NSData"20
v12@?0I8
video/mp4
first
second
[%@]
Initialization Segment Data
Separable Segment Data
Sequence Numbers
Time Range
First Video Sample Byte Range
v16@?0@"HMIVideoAnalyzerEventPerson"8
v32@?0@"HMIVideoAnalyzerEventPerson"8Q16^B24
v24@?0@"NSUUID"8@"HMIMutableCluster"16
(faceRecognition != nil) || (torsoRecognition != nil)
v16@?0@"NSUUID"8
v16@?0@"HMITorsoprint"8
@16@?0@"HMIFaceClassification"8
HMIASU.ck.ta
Torso Annotations
B16@?0@"HMITorsoAnnotation"8
@"HMITorsoAnnotation"16@?0@"HMIVideoAnalyzerEventFace"8
v16@?0@"HMIPoint"8
HMIPSUP.ck.p
HMIPSUP.ck.s
HMIP.ck.u
HMIP.ck.n
HMIP.ck.pl
personLinks
@"HMIPersonSourceUUIDPair"16@?0@"HMPersonLink"8
v16@?0@"<NSObject><NSCopying><NSSecureCoding>"8
data:;base64,%@
@16@?0@8
@24@?0@8@16
%.6f
data:;base64,
Invalid JSONObject class name: %@
Invalid JSONObject: %@
Cannot parse JSON data: %@
PVFC:PVFC
PVFC_VER
PVFC_FB
PVFC_CB
could not create image ref
Error creating directory:%@ to save face classifications
faceprintUUID
%@-%03lu-%03u-%@-%@-%@
known
unknown
Error saving metadata to disk for face classification:%@
Error saving face crop image to disk for face classification:%@
the supplied data is not a facecrop
could not create an image source
Could not retrieve image properties
faceCropDimensionsFromFaceCrop failed:%@
Could not create image source
No meta data exists on image
HMITP.ck.u
HMITP.ck.d
HMITP.ck.lq
HMITP.ck.ur
Bad Torso
ROI Boundary
HMITA.ck.fr
HMITA.ck.tps
HMITA.ck.tmv
faceRecognition
torsoprints
Torsoprints
TorsoModelVersion
HMIVideoEncoderWorkQueue
self.session == NULL
VTCompressionSessionCreate failed, err: %d
VTCompressionSessionPrepareToEncodeFrames failed, err: %d
Video encoding failed, err: %d
self.session
v24@?0i8I12^{opaqueCMSampleBuffer=}16
VTCompressionSessionEncodeFrameWithOutputHandler failed, err: %d
%@ is unavailable
@16@?0@"HMIFaceCrop"8
@16@?0@"HMIPerson"8
@16@?0@"HMFaceCrop"8
source != HMIPersonFaceCropSourceUnknown
HMPMS.ifple
HMPMS.sfce
Importing From Photo Library Enabled
Sharing Face Classifications Enabled
cameraManufacturer
cameraModel
recognitionType
face
torso
com.apple.HomeAI.PersonRecognitionEvent
@"NSMutableDictionary"8@?0
detectionScore
faceFilteredState
homeFamiliarity
v16@?0@"HMIFaceClassification"8
q24@?0@"NSNumber"8@"NSNumber"16
externalFamiliarity
sessionEntityAssignment
com.apple.HomeAI.FaceEvent
faceprintsClustered
clusters
personsCreated
faceprintsAssociated
faceprintingDuration
clusteringDuration
totalDuration
errorCode
errorDescription
com.apple.HomeAI.FaceClustering
v24@?0@"NSString"8@"NSNumber"16
v16@?0@"HMIPersonsModelSummary"8
@avg.self
externalLibraries
homeIdentities
averageExternalIdentities
averageHomeFaceCrops
averageExternalFaceCrops
homeToExternal
externalToExternal
com.apple.HomeAI.PersonsModels
@"NSDictionary"8@?0
B16@?0@"NSNumber"8
inclusion
exclusion
com.apple.HomeAI.MotionScore
zoneType
motionScore
com.apple.HomeAI.VideoAnalyzer.DidTerminate_v0
Fail
status
error
underlyingError
timeSinceAnalyzerStarted
com.apple.HomeAI.VideoAnalyzer.DidCreateTimelapseFragment_v0
bitrate
com.apple.HomeAI.VideoAnalyzer.DidAnalyzeFragment_v3
recognizeFaces
%@Trigger
%@Found
v32@?0@"NSString"8q16#24
motion
person
vehicle
package
transcode
analysisQuality
sequenceNumber
com.apple.HomeAI.VideoPackageAnalyzer.DidClassify_v0
com.apple.HomeAI.VideoPackageAnalyzer.DidReset_v0
interval
personsmodels
home
external
torso.bin
torso_to_facecrop.bin
torsoprinter_version.bin
user_defined_person_links.bin
v32@?0@"NSUUID"8@"HMIPersonsModel"16^B24
Error adding faceprints to model for personUUID: %@
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8@"NSArray"16^B24
Failed to remove stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to remove stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@
Failed to persist VNPersonsModel for homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to persist VNPersonsModel for homeUUID: %@ sourceUUID: %@, path: %@
Failed to remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, error getting model storage path
Failed to remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, path: %@
Home persons model not found for homeUUID: %@
Failed to predict using VNPersonsModel for home persons model
Unable to get person model for homeUUID: %@ (self.personsModelsByHome is %@ nil)
Failed to predict using VNPersonsModel for homeUUID: %@ sourceUUID: %@
 not
v24@?0@"HMIPersonSourceUUIDPair"8^B16
v32@?0@"NSSet"8@"HMIPersonsModelPrediction"16^B24
q24@?0@"VNFaceObservation"8@"VNFaceObservation"16
v24@?0@"HMIFaceClassification"8^B16
@"VNFaceObservation"16@?0@"HMITorsoprint"8
v16@?0@"HMITorsoAnnotation"8
v16@?0@"HMIFaceCrop"8
Failed to predict using torso model for homeUUID: %@
@16@?0@"HMIPersonSourceUUIDPair"8
%@.bin
Directory to load/store persons models (%@) does not exist
Failed to enumerate persons models at path (%@)
\A[A-F0-9]{8}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{12}\.bin\Z
B16@?0@"NSURL"8
Failed to enumerate homes at path: %@
Directory to load/store home persons model (%@) contains multiples files: %@ there can only be one
Invalid file path in load model attempt: %@
Refusing to load %@ VNPersonsModel at path: %@
Failed to load VNPersonsModel at path: %@
@24@?0@"NSUUID"8@"HMIPersonsModel"16
v32@?0@"HMIPersonSourceUUIDPair"8@"NSSet"16^B24
v16@?0@"HMIDESLayerParameters"8
is_training
checkpoint
Loss/total_loss
B32@?0Q8@"<ETDataProvider>"16@"<ETTaskContext>"24
/tmp/train.espresso.net
Unknown reason.
Skipped
{code: %@, analysisFPS: %f, message: "%@"}
{code: %@, analysisFPS: %f}
v24@?0@"HMIExternalPersonManagerSettings"8@"NSError"16
@16@?0@"HMIVideoAnalyzer"8
@16@?0@"HMIVideoAnalyzerState"8
v16@?0@"HMIVideoAnalyzerConfiguration"8
v32@?0@"HMIVideoAnalyzer"8Q16^B24
Undefined
mediaserverd
homed
v16@?0@"HMIVideoAnalyzer"8
Scheduler state: 
usage: %@
, idle: %@
, %@: (%llu MB | %llu MB)
, mediaserverd: (%llu MB | %llu MB)
, homed: (%llu MB | %llu MB)
, thermalLevel: %lu
, peakPowerPressureLevel: %lu
, build: %@
Release
, maxConcurrentAnalyzers: %lu
v32@?0@"NSString"8Q16^B24
usage
idle
footprint
maxFootprint
thermalLevel
peakPowerPressureLevel
build
analyzers
Failed to read json file
homePersonsAndFaceCrops
photosPersonsAndFaceCrops
@"HMIPerson"16@?0@"NSDictionary"8
descriptorA.length == descriptorB.length
cluster.objects.count > 0
faceObservations.count > 0
faceObservations.firstObject.faceprint != nil
faceprintLength == faceObservation.faceprint.lengthInBytes / sizeof(float)
Sample buffer has an invalid PTS.
randomUniform
value
{CGAffineTransform=dddddd}
probability
attributes
B16@?0@"HMICIFilterAttribute"8
HMIRotate
CIAffineTransform
inputAngle
inputTransform
v16@?0@"HMICIFilterAttribute"8
camera_recording
camera_recording_analyzer
camera_recording_analyzer_media
camera_recording_analyzer_scheduler
camera_recording_analyzer_scheduler_json
camera_recording_maintenance
Failed to load model at path: %@
HMIMLModel
@"HMIVideoAnalyzerFrameResult"16@?0@"HMIVideoAnalyzerFrameResult"8
@"HMIVideoFrame"16@?0@"HMIVideoFrame"8
@"NSArray"16@?0@"HMIVideoAnalyzerFrameResult"8
Max Confidence Events
Frame Results
Thumbnails
Fragment
Configuration
HMICVFR.f
HMICVFR.roi
HMICVFR.ae
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
HMIOD.y.a
HMIOD.r.o
HMIP.x
HMIP.y
HMIAZ.p
HMIAZ.i
HMICameraVideoFrame does not support NSSecureCoding in the simulator
HKD://
analyzed-video-frames
 isInclusion:%d 
class-label
coordinates
overlap
activityZone
%@-%@-%@-%@.json
%@/%@
%@/activityzone-%@
B16@?0@"HMICameraActivityZone"8
filteringLevel
numDetectedObjects
com.apple.HomeAI.ActivityZone
noFiltering
resize_0
resize_10
resize_20
resize_26
resize_36
IFrameOnly
Full
Detector
Thumbnail Interval
Thumbnail Height
Timelapse Interval
Timelapse Preferred Fragment Duration
Max Fragment Duration
Max Fragment Analysis Duration
Decode Mode
Transcode
Transcode Codec
Passthrough Audio
Redact frames
Min Frame Quality
Min Frame Scale
Camera
Home UUID
Package Classifier Mode
Analysis FPS
minFrameQuality > 0 && minFrameQuality <= 1
minFrameScale > 0 && minFrameScale <= 1
analysisFPS > 0
Event Triggers
Recognize Faces
Activity Zone Count
q24@?0@"HMIVideoAnalyzerEvent"8@"HMIVideoAnalyzerEvent"16
B16@?0@"HMIStationaryObject"8
HMIVAEP.f
HMIVAEP.t
HMIVAEP.ibbe
Is Bounding Box & Confidence Estimated
Face
Torso
%@ %@ %@
com.apple.homed
syntheticEvents
personDetected
petDetected
vehicleDetected
packageDetected
analysisQOS
systemResourceUsageLevel
motionDetector
frameSelectorSampleRateMultiplier
frameSelectorTargetInterval
processingDevice
confidenceThresholdPersonHigh
confidenceThresholdPetHigh
confidenceThresholdVehicleHigh
confidenceThresholdFaceHigh
confidenceThresholdTorsoHigh
confidenceThresholdPackageHigh
confidenceThresholdPersonMedium
confidenceThresholdPetMedium
confidenceThresholdVehicleMedium
confidenceThresholdFaceMedium
confidenceThresholdTorsoMedium
confidenceThresholdPackageMedium
confidenceThresholdPackageClassifierMedium
confidenceThresholdPackageClassifierHigh
modelTimeout
uploadVideoAnalysisEvent
saveVideoFragmentResultHTML
assetReaderMaximizePowerEfficiency
assetReaderForceBGRA
analysisEnableTranscodeFragment
realTimeEncoding
espressoLowPriority
maxConcurrentAnalyzers
maxAnalysisFPS
opticalFlowLowPriority
opticalFlowBackgroundProcessing
saveDESRecords
skipMinDESRecordCount
DESSkipTraining
saveTrainedModel
DESSkipTrainingScalar
DESSkipPrivatize
enableDASTestConfiguration
personsModelStoragePath
personDataSourceDiskStoragePath
personsModelClassificationThresholdKnown
torsoPersonsModelClassificationThresholdKnown
faceVIPThresholdForTorsoAnnotation
personsModelClassificationThresholdUnknown
saveFaceCropsToDisk
showROI
useDevelopmentFeedbackService
eventTriggers
logHumanFriendlySchedulerState
schedulerStateLogFrequency
enableTorsoRecognition
enableSignposts
fragmentDiskBufferSize
logOtherProcessMemorySchedulerState
videoFrameTrackerMaxCandidates
useHEVC
taskServiceRunLocally
restartDecoderIfFormatChanges
user-interactive
user-initiated
unspecified
default
utility
background
Only NSNumber and NSString properties are supported.
Track:%.2f-%.2f @ %@ (%@)
%@ - %f
/tmp/TrackerReport-%@-%@.html
Tracker
%.2f %@
v64@?0Q8@"NSSet"16{CGRect={CGPoint=dd}{CGSize=dd}}24@"NSString"56
Target
Mean
Motion
Assign
v24@?0@"HMIVideoAssetWriter"8@"NSData"16
v32@?0@"HMIVideoAssetWriter"8@"NSData"16@"AVAssetSegmentReport"24
Encoder Queue
v24@?0@"HMIVideoEncoder"8^{opaqueCMSampleBuffer=}16
v24@?0@"HMIVideoFrameSampler"8^{opaqueCMSampleBuffer=}16
v32@?0@"HMIVideoFrameSampler"8@"HMIVideoEncoder"16^{opaqueCMSampleBuffer=}24
@"NSNumber"24@?0@"HMIVideoAnalyzerEvent"8@"NSNumber"16
FFArchive
yyyy-MM-dd
2021-05-15
q24@?0@"VNCluster"8@"VNCluster"16
v16@?0@"VNCluster"8
@"VNFaceObservation"16@?0@"NSNumber"8
B16@?0@"VNCluster"8
q24@?0@"HMIPersonFaceCrop"8@"HMIPersonFaceCrop"16
yyyy-MM-dd'T'HH-mm-ss
%@_%@.plist
@"NSUUID"16@?0@"HMIFaceprint"8
Fetch persons failed
CleanImpureHomePersonsOperation encountered failures
com.apple.HomeAI.%@%@%@.%tu
yyyy-MM-dd'T'HH:mm:ss.SSS'Z'
homeai: %@
Vision
Faceprints
Clusters
Persons
Associated
Faceprinting Duration
Clustering Duration
Total Duration
B16@?0@"HMIPersonSourceUUIDPair"8
v32@?0@"VNCluster"8@"NSUUID"16^B24
Error on dispatch_group_wait (associateFaceCrops)
Error associating face crops for %lu person%@: (
 ...
v16@?0@"HMIPersonFaceCrop"8
@"NSUUID"16@?0@"VNFaceObservation"8
@"NSUUID"16@?0@"NSUUID"8
v32@?0@"NSNumber"8@16^B24
HMICameraVideoFrameAnalyzerSignificantActivity
@"HMIFaceClassification"16@?0@"HMIPersonsModelPrediction"8
@"HMIVideoAnalyzerEvent"16@?0@"HMIVideoAnalyzerEvent"8
none
@"NSString"16@?0@"NSObject"8
high
medium
ClassifyFaceEvent
ClassifyTorsoEvent
HMIDESBT.u
HMIDESBackgroundTask
scale > 0 && scale <= 1
quality > 0 && quality <= 1
HMIVideoFrame failed to create compressed representation.
]1337;File=inline=1;preserveAspectRatio=1:%@
Data (JPEG)
CVPixelBuffer
Presentation Time Stamp
Size
Store
HMIVideoFrame does not support NSSecureCoding in the simulator.
#EXTM3U
#EXT-X-VERSION:7
#EXT-X-TARGETDURATION:%.6f
#EXT-X-PLAYLIST-TYPE:VOD
#EXT-X-INDEPENDENT-SEGMENTS
#EXT-X-I-FRAMES-ONLY
#EXT-X-KEY:METHOD=AES-256-GCM,URI="%@"
#EXT-X-MAP:URI="%@"
#EXTINF:%.5f
#EXT-X-BYTERANGE:%lu@%lu
#EXT-X-ENDLIST
Bounding Box
P(%@|[%@])=%@
Package
Person
Vehicle
Event
event
#D62728
#2CA02C
#1F77B4
#9467BD
#FF7F0E
#8C564B
#7F7F7F
@24@?0#8@"NSString"16
HMITC.su
HMITC.pu
HMITC.conf
%.4lf
HMIVideoDecoderWorkQueue
Format description is missing.
Cannot accept format description.
Cannot create reorder buffer, err: %d.
Cannot create decoder.
Cannot decode frame, err: %d.
Cannot reorder frames.
Decoded sample has an invalid PTS.
HMIVideoAssetWriter
HMIVideoAssetWriterOutput
UTType class is not available.
HMICMSampleBufferIsAudio(sbuf)
Underlying asset writer has failed.
Couldn't append sample buffer because, exception %@
Failed to flush segment.
v32@?0@"<NSObject><NSCopying><NSSecureCoding>"8Q16^B24
@"NSDictionary"24@?0@"NSUUID"8@"HMIPersonsModel"16
v16@?0@"HMIPersonSourceUUIDPair"8
v32@?0@"NSUUID"8@"NSSet"16^B24
v32@?0@"NSUUID"8@"NSDictionary"16^B24
v24@?0@"VNFaceObservation"8^B16
B16@?0@"HMIMotionDetection"8
Sparse Optical Flow
monitored
analysisFPS
timeSinceLastFragmentWasReceived
bufferFillRatio
bufferSize
delay
numDecodedSamples
numDidAnalyzeFrames
numDidAnalyzePackages
numDidCreateTimelapseFragments
averageAnalysisTime
decodeMode
transcodeCodecType
encode
encoder
activityZones
Name           
AFPS
Time
Last
Buffer               
Delay
     Decode:PTS
FR, FRAG
FR Time
Enc, Lapse:FRAG
Faces
Zones
Triggers
] %5ld KB
%.1f
%4ld:%.1f
%ld, %ld
%@%@%@ %@, %@:%ld
camera
Session has not received any new data for over 60 seconds.
Session Check
HMIFR.c
HMIFR.fc
HMIFR.fp
HMIFR.fqs
HMIFR.sea
HMIFR.seu
HMIFR.leus
TransitionMatrix
Joint
Face Classifications
Face Quality Score
selector
arguments
configuration
HMIVideoAnalyzer does not support remote analysis.
@"HMIVideoAnalyzer"16@?0@"HMIVideoAnalyzerConfiguration"8
VideoAnalyzerReport %@ %@
/tmp/%@.plist
fragmentResult
v16@?0@"HMIVideoAnalyzerEventFace"8
HMIVideoAnalyzerServer
HMIVideoAnalyzerServer - Input
HMIVideoAnalyzerServer - Encoder
dynamicConfiguration
Video fragment duration: %fs is greater than the max fragment duration value: %fs
Fragment had no video samples, fragment is likely corrupted.
%@_%@_%@
UnknownManufacturer
UnknownModel
UnknownFirmware
v20@?0@"NSString"8B16
YYYY-MM-dd-HH-mm-ss
sanitized.mp4
self.assetWriter == nil
self.timelapseOutputVideoFormat
 Timelapse
_encode
!self.encoder
self.inputVideoFormat
!self.timelapseEncoder
self.assetWriter
self.timelapseAssetWriter
v16@?0@"HMIVideoAnalyzerResultFilter"8
Filtered
B16@?0@"AVAssetSegmentTrackReport"8
Analyzer is in full bypass mode.
Analyzer is in partial bypass mode, only IFrames are decoded.
Analyzer has not received fragments from client in a long time.
/tmp/com.apple.HomeAI/familiar-face-data
Error initializing with home UUID: %@ source UUID:%@
Error enumerating persons
Error loading person from JSON
Error enumerating face crops for person UUID:%@
Error loading face crop from JSON
Error loading face crop image
HMIVAET.ro
HMIVAET.tr
Torso Roll
Torso Recognition
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/datastructs.cpp
cvReleaseMemStorage
cvRestoreMemStoragePos
NULL storage pointer
cvMemStorageAlloc
Too large memory block is requested
datastructs.cpp
storage->free_space % CV_STRUCT_ALIGN == 0
requested size is negative or too big
(size_t)ptr % CV_STRUCT_ALIGN == 0
cvCreateSeq
Specified element size doesn't match to the size of the specified element type (try to use 0 for element type)
cvSetSeqBlockSize
Storage block size is too small to fit the sequence elements
cvCvtSeqToArray
cvStartReadSeq
cvChangeSeqBlock
cvGetSeqReaderPos
cvSetSeqReaderPos
cvSeqPush
ptr + elem_size <= seq->block_max
block->start_index > 0
NULL sequence pointer
cvSeqPushMulti
number of removed elements is negative
cvSeqPopMulti
delta > 0
cvClearSeq
Invalid sequence header
cvSeqSlice
Bad sequence slice
Bad input sequence
cvSeqSort
Null compare function
cvCreateSet
cvSetAdd
count <= CV_SET_ELEM_IDX_MASK+1
cvCreateGraph
cvGraphAddVtx
cvFindGraphEdgeByPtr
ofs == 1 || start_vtx == edge->vtx[0]
graph pointer is NULL
cvGraphAddEdgeByPtr
vertex pointers coinside (or set to NULL)
edge->flags >= 0
Invalid graph pointer
cvCloneGraph
cvInitTreeNodeIterator
cvNextTreeNode
icvInitMemStorage
icvDestroyMemStorage
icvGoNextMemBlock
parent->bottom == block
icvGrowSeq
The sequence has NULL storage pointer
storage->free_space >= delta
block->count % seq->elem_size == 0 && block->count > 0
seq->first->start_index == 0
icvFreeSeqBlock
(in_front_of ? block : block->prev)->count == 0
seq->ptr == block->data
block->count > 0 && block->count % seq->elem_size == 0
Unknown/unsupported border type
borderInterpolate
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/filter.cpp
columnBorderType != BORDER_WRAP
!rowFilter.empty() && !columnFilter.empty()
bufType == srcType
0 <= anchor.x && anchor.x < ksize.width && 0 <= anchor.y && anchor.y < ksize.height
roi.x >= 0 && roi.y >= 0 && roi.width >= 0 && roi.height >= 0 && roi.x + roi.width <= wholeSize.width && roi.y + roi.height <= wholeSize.height
start
srcRoi.x >= 0 && srcRoi.y >= 0 && srcRoi.width >= 0 && srcRoi.height >= 0 && srcRoi.x + srcRoi.width <= src.cols && srcRoi.y + srcRoi.height <= src.rows
wholeSize.width > 0 && wholeSize.height > 0
proceed
src && dst && count > 0
srcY >= startY
dstY <= roi.height
src.type() == srcType && dst.type() == dstType
apply
dstOfs.x >= 0 && dstOfs.y >= 0 && dstOfs.x + srcRoi.width <= dst.cols && dstOfs.y + srcRoi.height <= dst.rows
_kernel.channels() == 1
getKernelType
cn == CV_MAT_CN(bufType) && ddepth >= std::max(sdepth, CV_32S) && kernel.type() == ddepth
getLinearRowFilter
Unsupported combination of source format (=%d), and buffer format (=%d)
cn == CV_MAT_CN(bufType) && sdepth >= std::max(ddepth, CV_32S) && kernel.type() == sdepth
getLinearColumnFilter
Unsupported combination of buffer format (=%d), and destination format (=%d)
cn == CV_MAT_CN(_dstType)
createSeparableLinearFilter
ktype == CV_8U || ktype == CV_32S || ktype == CV_32F || ktype == CV_64F
preprocess2DKernel
cn == CV_MAT_CN(dstType) && ddepth >= sdepth
getLinearFilter
Unsupported combination of source format (=%d), and destination format (=%d)
createLinearFilter
anchor.inside(Rect(0, 0, ksize.width, ksize.height))
normalizeAnchor
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/precomp.hpp
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0 && this->ksize <= 5
SymmRowSmallFilter
kernel.type() == DataType<DT>::type && (kernel.rows == 1 || kernel.cols == 1)
RowFilter
kernel.type() == DataType<ST>::type && (kernel.rows == 1 || kernel.cols == 1)
ColumnFilter
this->ksize == 3
SymmColumnSmallFilter
(symmetryType & (KERNEL_SYMMETRICAL | KERNEL_ASYMMETRICAL)) != 0
SymmColumnFilter
_kernel.type() == DataType<KT>::type
Filter2D
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/alloc.cpp
Failed to allocate %lu bytes
OutOfMemoryError
borderType != BORDER_CONSTANT
pyrDown
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/pyramids.cpp
!_src.empty()
pyrDown_
std::abs(dsize.width*2 - ssize.width) <= 2 && std::abs(dsize.height*2 - ssize.height) <= 2
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/opengl_interop_deprecated.cpp
GlBuffer
GlTexture
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/persistence.cpp
Invalid pointer to file storage
The node is neither a map nor an empty collection
cvGetFileNodeByName
Null element name
cvStartWriteStruct
The file storage is opened for reading
cvEndWriteStruct
cvWriteInt
cvWriteString
cvWriteRawData
Negative number of elements
Null data pointer
persistence.cpp
cvStartReadRawData
Null pointer to source file node or reader
The file node should be a numerical scalar or a sequence
cvReadRawDataSlice
Null pointer to reader or destination array
The readed sequence is a scalar, thus len must be 1
The sequence element is not a numerical scalar
The sequence slice does not fit an integer number of records
Null pointers to source file node or destination array
cvReadRawData
opencv-sequence
opencv-sequence-tree
opencv-graph
opencv-sparse-matrix
opencv-image
opencv-matrix
opencv-nd-matrix
Invalid type info
cvRegisterType
Some of required function pointers (is_instance, release, read or write) are NULL
Type name should start with a letter or _
Type name should contain only letters, digits, - and _
NULL double pointer
cvRead
The node does not represent a user object (unknown type?)
The storage is not opened
icvPuts
An attempt to add element without a key to a map, or add element with key to sequence
icvXMLWriteTag
A single _ is a reserved tag name
Closing tag should not include any attributes
Key should start with a letter or _
Key name may only contain alphanumeric characters [a-zA-Z0-9], '-' and '_'
icvDecodeFormat
fmt_pairs != 0 && max_len > 0
Invalid data type specification
Too long data type specification
%.8e
-.Inf
.Inf
%.16e
elements with keys can not be written to sequence
icvXMLWriteScalar
icvYMLWrite
The key is an empty
The key is too long
Key must start with a letter or _
Key names may only contain alphanumeric characters [a-zA-Z0-9], '-', '_' and ' '
icvReleaseSeq
flags
count
Some of essential sequence attributes are absent
icvReadSeq
The sequence flags are invalid
curve
closed
hole
untyped
header_dt
header_user_data
One of "header_dt" and "header_user_data" is there, while the other is not
rect
origin
Only one of "header_user_data", "rect" and "origin" tags may occur
The image data is not found in file storage
The number of stored elements does not match to "count"
Too complex format for the matrix
icvDecodeSimpleFormat
recursive
false
False
FALSE
icvWriteSeqTree
CV_IS_SEQ( seq )
sequences
icvWriteSeq
level
 untyped
The size of element calculated from "dt" and the elem_size do not match
icvGetFormat
Size of sequence element (elem_size) is inconsistent with seq->flags
%d%c
The size of header calculated from "header_dt" is greater than header_size
icvWriteHeaderData
opencv-sequence-tree instance should contain a field "sequences" that should be a sequence
icvReadSeqTree
All the sequence tree nodes should contain "level" field
level == prev_level + 1
icvReleaseGraph
vertex_dt
edge_dt
vertex_count
edge_count
Some of essential graph attributes are absent
icvReadGraph
oriented
Graph edges should start with 2 integers and a float
%df%s
vertices
edges
No edges data
No vertices data
Some of stored vertex indices are out of range
Duplicated edge has occured
cvAlignPtr
(align & (align-1)) == 0
icvWriteGraph
CV_IS_GRAPH(graph)
2if%s
sizes
Some of essential matrix attributes are absent
icvReadSparseMat
Could not determine sparse matrix dimensionality
The matrix data is not found in file storage
Sparse matrix data is corrupted
icvWriteSparseMat
CV_IS_SPARSE_MAT(mat)
(reader).seq->elem_size == sizeof(idx)
k < dims
Some of essential image attributes are absent
icvReadImage
layout
interleaved
Only interleaved images can be read
The matrix size does not match to the number of stored elements
icvWriteImage
CV_IS_IMAGE(image)
Images with planar data layout are not supported
top-left
bottom-left
planar
rows
cols
icvReadMat
icvWriteMat
CV_IS_MAT_HDR_Z(mat)
icvReadMatND
Could not determine the matrix dimensionality
icvWriteMatND
CV_IS_MATND_HDR(mat)
type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/dxt.cpp
This mode (using nonzero_rows with a single-column matrix) breaks the function's logic, so it is prohibited.
For fast convolution/correlation use 2-column matrix or single-row matrix instead
dxt.cpp
!inv
type == srcB.type() && srcA.size() == srcB.size()
mulSpectrums
(flags & DFT_NO_PERMUTE) == 0
(unsigned)k0 < (unsigned)n && (unsigned)k1 < (unsigned)n
factors[0] == factors[nf-1]
(unsigned)j < (unsigned)n2
(unsigned)j < (unsigned)n
RealDFT
tab_size == n
CCSIDFT
src != dst
DFTInit
nf < 34
elem_size == sizeof(Complex<float>)
channels() == CV_MAT_CN(dtype)
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/copy.cpp
mask.depth() == CV_8U && (mcn == 1 || mcn == cn)
size() == mask.size()
checkScalar(value, type(), _value.kind(), _InputArray::MAT )
setTo
mask.empty() || mask.type() == CV_8U
repeat
ny > 0 && nx > 0
maskarr == 0
cvCopy
src.depth() == dst.depth() && src.size == dst.size
(coi1 != 0 || src.channels() == 1) && (coi2 != 0 || dst.channels() == 1)
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/opengl_interop.cpp
The library is compiled without OpenGL support
throw_nogl
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/thresh.cpp
Unknown threshold type
thresh_8u
thresh_16s
thresh_32f
img.depth() == CV_8U && winSize.width > 2 && winSize.height > 2
buildOpticalFlowPyramid
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/video/lkpyramid.cpp
maxLevel >= 0 && winSize.width > 2 && winSize.height > 2
calcOpticalFlowPyrLK
(npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0
nextPtsMat.checkVector(2, CV_32F, true) == npoints
statusMat.isContinuous()
errMat.isContinuous()
levels1 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + prevPyr[lvlStep1].cols + winSize.width <= fullSize.width && ofs.y + prevPyr[lvlStep1].rows + winSize.height <= fullSize.height
levels2 >= 0
ofs.x >= winSize.width && ofs.y >= winSize.height && ofs.x + nextPyr[lvlStep2].cols + winSize.width <= fullSize.width && ofs.y + nextPyr[lvlStep2].rows + winSize.height <= fullSize.height
prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size()
prevPyr[level * lvlStep1].type() == nextPyr[level * lvlStep2].type()
depth == CV_8U
calcSharrDeriv
cvAlign
internal.hpp
(align & (align-1)) == 0 && size < INT_MAX
scn == 1
convertAndUnrollScalar
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/arithm.cpp
op == CMP_LT || op == CMP_LE || op == CMP_EQ || op == CMP_NE || op == CMP_GE || op == CMP_GT
compare
The operation is neither 'array op array' (where arrays have the same size and the same type), nor 'array op scalar', nor 'scalar op array'
The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array'
binary_op
(mask.type() == CV_8UC1 || mask.type() == CV_8SC1)
mask.size == src1.size
The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array'
arithm_op
src2.type() == CV_64F && (src2.rows == 4 || src2.rows == 1)
When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified
img.dims <= 2 && templ.dims <= 2 && corr.dims <= 2
crossCorr
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/templmatch.cpp
depth == tdepth || tdepth == CV_32F
corrsize.height <= img.rows + templ.rows - 1 && corrsize.width <= img.cols + templ.cols - 1
ccn == 1 || delta == 0
the input arrays are too big
CV_MAT_CN(sumType) == CV_MAT_CN(srcType)
getRowSumFilter
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/smooth.cpp
CV_MAT_CN(sumType) == CV_MAT_CN(dstType)
getColumnSumFilter
Unsupported combination of sum format (=%d), and destination format (=%d)
sumCount == ksize-1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/utils.cpp
top >= 0 && bottom >= 0 && left >= 0 && right >= 0
copyMakeBorder
value[0] == value[1] && value[0] == value[2] && value[0] == value[3]
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/deriv.cpp
ktype == CV_32F || ktype == CV_64F
getScharrKernels
dx >= 0 && dy >= 0 && dx+dy == 1
getSobelKernels
The kernel size must be odd and not larger than 31
dx >= 0 && dy >= 0 && dx+dy > 0
ksize > order
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/convert.cpp
src && nsrcs > 0 && dst && ndsts > 0 && fromTo && npairs > 0
mixChannels
j < nsrcs && src[j].depth() == depth
i1 >= 0 && j < ndsts && dst[j].depth() == depth
type == B.type() && (type == CV_32FC1 || type == CV_64FC1 || type == CV_32FC2 || type == CV_64FC2)
gemm
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matmul.cpp
a_size.width == len
a_size.height == len
C.type() == type && (((flags&GEMM_3_T) == 0 && C.rows == d_size.height && C.cols == d_size.width) || ((flags&GEMM_3_T) != 0 && C.rows == d_size.width && C.cols == d_size.height))
type == CV_64FC2
src1.type() == src2.type()
scaleAdd
src.channels() == 1
mulTransposed
delta.channels() == 1 && (delta.rows == src.rows || delta.rows == 1) && (delta.cols == src.cols || delta.cols == 1)
operator()
GEMM_TransposeBlock
matmul.cpp
MulTransposedR
delta_cols == 1
cn <= 4 && func != 0
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/stat.cpp
src.channels() == 1 && func != 0
countNonZero
mean
(cn == 1 && (mask.empty() || mask.type() == CV_8U)) || (cn >= 1 && mask.empty() && !minIdx && !maxIdx)
minMaxIdx
img.dims <= 2
src.type() == CV_8UC1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/lapack.cpp
type == CV_32F || type == CV_64F
invert
m == n
method == DECOMP_LU || method == DECOMP_CHOLESKY
lapack.cpp
n == 1
type == _src2.type() && (type == CV_32F || type == CV_64F)
solve
(method != DECOMP_LU && method != DECOMP_CHOLESKY) || is_normal || src.rows == src.cols
src.rows == 1
The function can not solve under-determined linear systems
src.rows == src.cols
eigen
w.type() == u.type() && u.type() == vt.type() && u.data && vt.data && w.data
backSubst
u.cols >= nm && vt.rows >= nm && (w.size() == Size(nm, 1) || w.size() == Size(1, nm) || w.size() == Size(vt.rows, u.cols))
rhs.data == 0 || (rhs.type() == type && rhs.rows == m)
_SVDcompute
0 <= d && d <= CV_MAX_DIM && _sizes
create
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matrix.cpp
step[dims-1] == (size_t)CV_ELEM_SIZE(flags)
m.dims >= 2
0 <= _rowRange.start && _rowRange.start <= _rowRange.end && _rowRange.end <= m.rows
0 <= _colRange.start && _colRange.start <= _colRange.end && _colRange.end <= m.cols
m.dims <= 2
0 <= roi.x && 0 <= roi.width && roi.x + roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height <= m.rows
ranges
r == Range::all() || (0 <= r.start && r.start < r.end && r.end <= m.size[i])
dims <= 2
diag
img->dataOrder == IPL_DATA_ORDER_PIXEL
img->dataOrder == IPL_DATA_ORDER_PIXEL || img->roi->coi != 0
(int)nelems >= 0
reserve
resize
COI is not supported by the function
cvarrToMat
seq->total > 0 && CV_ELEM_SIZE(seq->flags) == seq->elem_size
Unknown array type
dims <= 2 && step[0] > 0
locateROI
adjustROI
reshape
The matrix is not continuous, thus its number of rows can not be changed
Bad new number of rows
The total number of matrix elements is not divisible by the new number of rows
The total width is not divisible by the new number of channels
cn <= 4
scalarToRawData
i < 0
getMat
0 <= i && i < (int)vv.size()
This method is not implemented for oclMat yet
k == STD_VECTOR_MAT
0 <= i && i < (int)v.size()
getMatVector
This function in deprecated, do not use it
getGlBuffer
getGlTexture
k == GPU_MAT
getGpuMat
size
i < (int)vv.size()
total
empty
!fixedSize() || ((Mat*)obj)->size.operator()() == _sz
!fixedType() || ((Mat*)obj)->type() == mtype
!fixedSize() || ((gpu::GpuMat*)obj)->size() == _sz
!fixedType() || ((gpu::GpuMat*)obj)->type() == mtype
!fixedSize() || ((ogl::Buffer*)obj)->size() == _sz
!fixedType() || ((ogl::Buffer*)obj)->type() == mtype
!fixedSize() || ((Mat*)obj)->size.operator()() == Size(cols, rows)
!fixedSize() || ((gpu::GpuMat*)obj)->size() == Size(cols, rows)
!fixedSize() || ((ogl::Buffer*)obj)->size() == Size(cols, rows)
!fixedType() && !fixedSize()
CV_MAT_TYPE(mtype) == m.type()
m.dims == dims
m.size[j] == sizes[j]
mtype == type0 || (CV_MAT_CN(mtype) == 1 && ((1 << type0) & fixedDepthMask) != 0)
dims == 2 && ((sizes[0] == sz.height && sizes[1] == sz.width) || (allowTransposed && sizes[0] == sz.width && sizes[1] == sz.height))
dims == 2 && (sizes[0] == 1 || sizes[1] == 1 || sizes[0]*sizes[1] == 0)
!fixedSize() || len == vv.size()
mtype == type0 || (CV_MAT_CN(mtype) == CV_MAT_CN(type0) && ((1 << type0) & fixedDepthMask) != 0)
!fixedSize() || len == ((vector<uchar>*)v)->size() / esz
Vectors with element size %d are not supported. Please, modify OutputArray::create()
create() called for the missing output array
!fixedSize() || len == len0
v[j].empty()
i < (int)v.size()
!fixedType() || (CV_MAT_CN(mtype) == m.channels() && ((1 << CV_MAT_TYPE(flags)) & fixedDepthMask) != 0)
!fixedSize()
release
clear
k == MAT
getMatRef
setIdentity
src.dims <= 2 && esz <= (size_t)32
transpose
src.size() == dst.size() && (src.cols == 1 || src.rows == 1)
func != 0
m.dims <= 2 && m.rows == m.cols
completeSymm
src.dims <= 2
src.channels() == dst.channels()
_arrays && (_ptrs || _planes)
init
narrays <= 1000
arrays[i] != 0
A.size == arrays[i0]->size
A.step[d-1] == A.elemSize()
copyTo
convertTo
minMaxLoc
0 <= _dims && _dims <= CV_MAX_DIM
setSize
s >= 0
OpenCV Error: %s (%s) in %s, file %s, line %d
No Error
Backtrace
Unspecified error
Internal error
Insufficient memory
Bad argument
Iterations do not converge
Autotrace call
Incorrect size of input array
Null pointer
Division by zero occured
Image step is wrong
Inplace operation is not supported
Requested object was not found
Input image depth is not supported by function
Formats of input arguments do not match
Sizes of input arguments do not match
One of arguments' values is out of range
Unsupported format or combination of formats
Input COI is not supported
Bad number of channels
Bad flag (parameter or structure field)
Bad parameter of type CvPoint
Bad type of mask argument
Parsing error
The function/feature is not implemented
Memory block has been corrupted
Assertion failed
No GPU support
Gpu API call
No OpenGL support
OpenGL API call
Unknown %s code %d
module != 0 && module->name != 0 && module->version != 0
cvRegisterModule
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/system.cpp
cxcore
2.4.13.6
unknown function
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/include/opencv2/dynamicuda/dynamicuda.hpp
copy
copyWithMask
convert
mallocPitch
The library is compiled without CUDA support
qualityLevel > 0 && minDistance >= 0 && maxCorners >= 0
goodFeaturesToTrack
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/featureselect.cpp
mask.empty() || (mask.type() == CV_8UC1 && mask.size() == image.size())
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/array.cpp
Non-positive width or height
cvCreateMatHeader
Invalid matrix type
cvInitMatHeader
Non-positive cols or rows
cvReleaseMat
Bad CvMat header
cvCloneMat
NULL matrix header pointer
cvInitMatNDHeader
invalid array data type
NULL <sizes> pointer
non-positive or too large number of dimensions
one of dimesion sizes is non-positive
The array is too big
cvCreateMatNDHeader
Bad CvMatND header
cvCloneMatND
src->dims <= CV_MAX_DIM
_dst.data == data0
Incorrect number of arrays
cvInitNArrayIterator
Some of required array pointers is NULL
Iterator pointer is NULL
COI set is not allowed here
Number of dimensions is the same for all arrays
Data type is not the same for all arrays
Number of channels is not the same for all arrays
Depth is not the same for all arrays
Mask should have 8uC1 or 8sC1 data type
Dimension sizes are the same for all arrays
cvNextNArraySlice
array.cpp
iterator != 0
cvCreateSparseMat
bad number of dimensions
cvReleaseSparseMat
Invalid sparse array header
cvCloneSparseMat
Invalid sparse matrix header
cvInitSparseMatIterator
NULL iterator pointer
Data is already allocated
cvCreateData
unrecognized or unsupported array type
cvReleaseData
Only continuous nD arrays are supported here
cvGetElemType
cvGetDims
Array should be CvMat or IplImage
cvGetSize
index is out of range
cvPtr2D
COI must be non-null in case of planar images
NULL pointer to indices
cvPtrND
NULL array pointer is passed
cvGetMat
The matrix has NULL data pointer
The image has NULL data pointer
Images with planar data layout should be used with COI selected
The image is interleaved and has over CV_CN_MAX channels
Pixel order should be used with coi == 0
Input array has NULL data pointer
Unrecognized or unsupported array type
cvCreateImage
null pointer to header
cvInitImageHeader
Bad input roi
Unsupported format
Bad input origin
Bad input align
cvReleaseImageHeader
cvReleaseImage
cvSetImageROI
rect.width >= 0 && rect.height >= 0 && rect.x < image->width && rect.y < image->height && rect.x + rect.width >= (int)(rect.width > 0) && rect.y + rect.height >= (int)(rect.height > 0)
cvSetImageCOI
cvGetImageCOI
Bad image header
cvCloneImage
cvGetMatND
icvGetNodePtr
CV_IS_SPARSE_MAT( mat )
One of indices is out of range
(newsize & (newsize - 1)) == 0
GRAY
BGRA
op == MORPH_ERODE || op == MORPH_DILATE
getMorphologyRowFilter
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/morph.cpp
Unsupported data type (=%d)
getMorphologyColumnFilter
getMorphologyFilter
depth == CV_8U || depth == CV_16U || depth == CV_16S || depth == CV_32F || depth == CV_64F
createMorphologyFilter
shape == MORPH_RECT || shape == MORPH_CROSS || shape == MORPH_ELLIPSE
getStructuringElement
morphOp
_kernel.type() == CV_8U
MorphFilter
src.type() == CV_8UC1 || src.type() == CV_32FC1
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/imgproc/corner.cpp
cornerEigenValsVecs
CV_MAT_CN(_type) == e.a.channels()
assign
/Library/Caches/com.apple.xbs/Sources/HomeAI_Sim/OpenCV/src/core/matop.cpp
Unknown operation
Invalid matrix initializer type
%{public}@Storing faceprints:%@ failed with error:%@
%{public}@Storing faceprints:%@ completed successfully
%{public}@Sample has a very large duration, the source video is corrupt.
%{public}@Original Sample Buffer: %@
%{public}@Bogus atomSize %llu, recovering by adjusting size.
%{public}@Simulated crash reporting is not available on this system.
%{public}@Not generating a memory exception report for %@ since another report was generated within last %f seconds.
%{public}@Memory exception reporting is not available on this system.
%{public}@Torsoprint Version: %ld.%ld
%{public}@Found low quality torso conf: %.4f
%{public}@Found low quality torso entropyOfSaturation: %.4f entropyOfLaplacian: %.4f
%{public}@Removing faceCrops:%@ failed with error:%@
%{public}@Removing faceCrops:%@ completed successfully
%{public}@Received nil data source
%{public}@Fetching settings using data source: %@
%{public}@Error fetching settings: %@
%{public}@handleUpdatedPerson: %@
%{public}@handleUpdatedUnassociatedFaceCrop: %@
%{public}@handleUpdatedPersonFaceCrop: %@
%{public}@handleUpdatedFaceprint: %@
%{public}@handleUpdatedSettings: %@
%{public}@handleRemovedPersonWithUUID: %@
%{public}@handleRemovedFaceCropWithUUID: %@
%{public}@handleRemovedFaceprintWithUUID: %@
%{public}@Successfully handled face misclassification
%{public}@Error in handling face misclassification, error:%@
%{public}@Submitted face misclassification task, taskID:%u
%{public}@Not storing face crop and faceprint for HMIHomePersonManager.UUID:%@ from face event:%@
%{public}@Storing unknown to Home face crop:%@ and faceprint:%@
%{public}@Error storing unassociated face crop:%@, error:%@
%{public}@Stored unassociated face crop:%@
%{public}@Error storing faceprint:%@, error:%@
%{public}@Stored faceprint:%@
%{public}@Reached face crop limit for sessionEntityUUID:%@ for HMIHomePersonManager.UUID:%@; not storing
%{public}@Timer fired, but person data is not yet available, waiting...
%{public}@Timer fired, updating home persons model
%{public}@Not triggering daily VIP Model Core Analytics event, last event was sent less than 1 day ago
%{public}@Triggering daily VIP Model Core Analytics event
%{public}@Successfully ran persons model summary task
%{public}@Failed to run persons model summary task, error:%@
%{public}@Submitted persons model summary task, taskID:%u
%{public}@Unrecognized timer: %@
%{public}@Updating with settings: %@
%{public}@Settings have disabled face classification, removing home persons model
%{public}@Settings have enabled face classification, updating home persons model
%{public}@Storing face crop:%@ failed with error:%@
%{public}@Storing face crop:%@ completed successfully
%{public}@Storing faceprint:%@ failed with error:%@
%{public}@Storing faceprint:%@ completed successfully
%{public}@Registering for Thermal Level Notifications
%{public}@Thermal Level is now: %lu
%{public}@Cannot get available space, error: %@
%{public}@Footprint: %@, Average: %@, Peak: %@
%{public}@Registering for Thermal Pressure Notifications
%{public}@Thermal Pressure Level is now: %@
%{public}@Initializing shared model
%{public}@Model is not bundled into framework. Default model is stored in Git LFS. Make sure Git LFS is installed in your local system.
%{public}@Failed to load model!
%{public}@Failed to read sample buffer, error: %@
%{public}@Asset reader failed, ignoring
%{public}@Track %@, %@
%{public}@Warnings: %@
%{public}@personManager is nil for homeUUID: %@
%{public}@Error refreshing home data: %@
%{public}@No homes were located
%{public}@Found home: name: %@, primary: %s, UUID: %@
Identifier = %@, Name = %@
HMISignpost
%{public}@Ignoring %@
%{public}@fetchAllPersonsWithCompletion
%{public}@fetchPersonsWithUUIDs:%@
%{public}@fetchAllPersonFaceCropsWithCompletion
%{public}@Received invalid HMPersonFaceCropSource: %ld
%{public}@fetchFaceCropsForPersonsWithUUIDs:%@
%{public}@fetchAllFaceprintsWithCompletion
%{public}@fetchFaceprintsForFaceCropsWithUUIDs:%@
%{public}@fetchSettingsWithCompletion
%{public}@performCloudPullWithCompletion
%{public}@addFaceprints:%@
%{public}@removeFaceprintsWithUUIDs:%@
%{public}@Could not initialize from decoded personUUID: %@
%{public}@BackgroundEstimator(PTS:%.2f) Unable to update background model (%lu/%lu)
%{public}@Background model assignment is NULL %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to past timestamp %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset outdated background model %.2f
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to image size change
%{public}@BackgroundEstimator(PTS:%.2f) Reset background model due to very large foreground object
%{public}@BackgroundEstimator(PTS:%.2f) Unable to alloc buffer
%{public}@BackgroundEstimator(PTS:%.2f) No background model
%{public}@Fullfilled content request: %@
%{public}@Fullfilled data request: %@
%{public}@Failed to loadValuesAsynchronouslyForKeys, due to timeout.
%{public}@Face below face quality thresholds: SVM recognizability = %lf, Yaw = %lf, discarding
%{public}@Face below ANFR face quality threshold: ANFR confidence = %lf, discarding
%{public}@personsModelPredictions is empty
%{public}@Positively classified face with facemask: (sourceUUID: %@, personUUID: %@)
%{public}@Face removed from unknown & uncertain bucket: has facemask
%{public}@Face removed from unknown and uncertian bucket, SSD confidence = %f, entropy of laplacian = %f, Face yaw = %f, box size: %f
%{public}@Added to unknown bucket yaw: %@
%{public}@Added to uncertain bucket yaw: %@
%{public}@Face recognition set is empty
%{public}@Positive face classifications: %@ 
%{public}@DES record saving is not permitted.
%{public}@There isn't enough available disk space (%ld MB) to save DES records.
%{public}@Couldn't determine the amount of available space disk space, continuing.
%{public}@Saving des record for video frame (PTS:%0.2fs) to disk
%{public}@Saving DES Record, recordInfo: %@, data: %@
%{public}@Saved DES Record: %@, error: %@
%{public}@Unable to create input image tensor with error %@
%{public}@Track(PTS:%.2f-%.2f), dF:%.2f(%.2f), dT:%.2f(%.2f), GIOU:%.2f(%.2f), %@(%@) vs %@(%@)
%{public}@HMIPersonTracker: unable to get %@ at index %lu / %lu
%{public}@Error creating frame analyzer: %@
%{public}@Face Classification is enabled, but homeUUID is nil, skipping face recognition
%{public}@Cannot find ground truth for %@
%{public}@Error, couldn't get face box from photos data, ignoring face crop
%{public}@Error while detecting face in Photos face crop, error: %@, or no box detected, falling back to photos bounding box
%{public}@No detected box overlaps with photos bounding box, falling back to photos bounding box
%{public}@Could not initialize from decoded UUID: %@ dataRepresentation: %@ dateCreated: %@
%{public}@Dropping frame, lastSamplePTS > nextSamplePTS.
%{public}@TaskID: %u running for %f seconds ...
%{public}@TaskID: %u step %d of %d
%{public}@options is empty/nil, defaulting to Home persons clustering task with impure person cleanup
%{public}@Creating HMPhotosPersonManager for homeUUID:%@ sourceUUID:%@
%{public}@Creating HMHomePersonManager for homeUUID:%@
%{public}@Current device is not primary resident, skipping clustering
%{public}@Initializing HMITaskServiceServer
%{public}@Error fetching persons:%@
%{public}@Skipping sentinel faceprint in existingAtCurrentVersion
%{public}@Skipping sentinel faceprint in createdAtCurrentVersion
%{public}@Faceprint Version: %ld.%ld
%{public}@Warm starting faceprint model...
%{public}@Failed to create pixel buffer when warm starting faceprint model
%{public}@Failed to warm start faceprint model: %@
%{public}@Warm start of faceprint model took: %f
%{public}@Cropping face %@ from pixel buffer with dimensions: %.1f x %.1f roll: %.02f degrees
%{public}@Error pixel buffer type conversion %@.
%{public}@Error in rotating the face %@.
%{public}@Face was rotated by:%.02f degrees
%{public}@HMIPrivateErrorCodeCropAndResizeFailed %@
%{public}@Cropping face %@ from face crop with dimensions %.1f x %.1f
%{public}@%lu faceprint(s) exist for face crop:%@ but are not the current version
%{public}@Using existing faceprint for face crop:%@
%{public}@Faceprinting face crop:%@
%{public}@Skipping crop, encountered error faceprinting: %@
%{public}@Face crop has a facemask, creating sentinel faceprint
%{public}@Vision run-time version: %d.%02d.%02d (%d)
%{public}@releaseCachedResources is deprecated and is now a no-op.
%{public}@Could not initialize from decoded UUID: %@ data: %@ modelUUID: %@ faceCropUUID: %@
%{public}@Error during update torso model task: %@
%{public}@Trusting host: %@ by default, not enforcing certificate pinning since user is donating videos to a dev server
%{public}@Trusting host: %@
%{public}@Force Certificate Pinning
%{public}@Error setting trust policies: %lu
%{public}@Invalid certificate: %@
%{public}@Downloading Clip
%{public}@Fetched Clip videoAssetContext: %@, error: %@
%{public}@Fetching Clip, progress %lu%%
%{public}@Face crops are not available.
%{public}@Fetching Face Crops
%{public}@Fetched Person UUIDs: %@
%{public}@Fetched Face Crops: %@, error: %@
%{public}@Fetching Clip
%{public}@Use the face-blurred video for upload
%{public}@Use the original video without audio track for upload
%{public}@Uploading payload data: %@, to URL %@
%{public}@Submitting clipUUID: %@, cameraProfileUUID: %@
%{public}@Stripped Audio %@, error: %@
%{public}@Downloaded %@, error: %@
%{public}@Failed to fetch pre-signed URL, error: %@
%{public}@Requesting a pre-signed url from server endpoint:%@, for clipUUID:%@
%{public}@Failed to request service result from server, error: %@
%{public}@Failed to decode server response, error: %@
%{public}@Service result: %@
%{public}@Failed to request service result, resource is not found, serverResponse: %@
%{public}@Failed to request service result due to internal server error, serverResponse: %@
%{public}@Failed to request service result due to server error, serverResponse: %@
%{public}@Deleting Temporary File %@
%{public}@Deleted Temporary File %@, error: %@
%{public}@Failed to generate persons model summary, error:%@
%{public}@Failed to fetch face crops with error: %@
%{public}@Failed to fetch faceprints with error: %@
%{public}@Error faceprinting face crops:%@
%{public}@Person (%@) has no faceprints -- nothing to remove
%{public}@Nearest face crop to be removed: %@
%{public}@Failed to remove face crop with error: %@
%{public}@Successfully removed face crop (%@) via user indicated misclassification
%{public}@Failed to remove persons model, error:%@
%{public}@Successfully removed persons model
%{public}@%@: %@
%{public}@Provided sequenceNumbers: %@, don't match fragment's sequenceNumbers: %@
%{public}@Failed to read fragment data, err: %d
%{public}@No torso annotations -- skipping torso model update
%{public}@Adding torso to existing sessionEntityUUID: %@ (face)
%{public}@Adding face to existing sessionEntityUUID: %@ (torso)
%{public}@Session entity %@ already has a face recognition, skipping subsequent match
%{public}@Existing face classification: %@
%{public}@New face classification: %@
%{public}@Assigning session entity %@ the face classification: %@
%{public}@updateTorsoModelAndGetTorsoAnnotationsForHome: %@
%{public}@Creating torso annotation with %lu torsoprints
%{public}@Adding face to existing sessionEntityUUID: %@ (VIP)
%{public}@Adding torso to existing sessionEntityUUID: %@ (VIP)
%{public}@Adding face to existing sessionEntityUUID: %@ (NN)
%{public}@Adding torso to existing sessionEntityUUID: %@ (NN)
%{public}@Adding face to existing sessionEntityUUID: %@ (track)
%{public}@Adding torso to existing sessionEntityUUID: %@ (track)
%{public}@Adding new face sessionEntityUUID: %@
%{public}@Adding new torso sessionEntityUUID: %@
%{public}@%@
%{public}@Error removing persons with UUIDs:%@, error:%@
%{public}@Succesfully removed persons %@
%{public}@Removing faceprints:%@ failed with error:%@
%{public}@Removing faceprints:%@ completed successfully
%{public}@Could not decode torsoAnnotations
%{public}@Publishing local state
%{public}@Dropping remote analysis torso update since torso rec is not enabled on this device
%{public}@Dropped %lu incompatible torsoprint annotations out of %lu total
%{public}@Successfully update torso model
%{public}@Error in update torso model, error:%@
%{public}@Submitted torso model update task, taskID:%u
%{public}@Could not initialize from decoded sourceUUID: %@
%{public}@Could not initialize from decoded UUID: %@
%{public}@Saved face classification:%@ to disk
%{public}@Invalid photos face crop data
%{public}@Face Box dict is null in photos metadata
%{public}@Couldn't convert face box dict to rect
%{public}@Error: %@
%{public}@imageData is nil
%{public}@Metadata string is nil in photos face crop data
%{public}@Couldn't retrieve metadata from photos crop:%@
%{public}@Could not initialize from decoded UUID: %@ data: %@ hasLowQualityKey: %@, hasUnrecognizableKey: %@
%{public}@Could not initialize from decoded faceRecognition: %@ torsoprints: %@ torsoModelVersion: %@
%{public}@Invalidated with err: %d
%{public}@Encoder is in a failed state, ignoring sample.
%{public}@VTCompressionSessionEncodeFrameWithOutputHandler (Handler) failed, err: %d
%{public}@VTCompressionSessionEncodeFrameWithOutputHandler, frame dropped.
%{public}@VTCompressionSessionCompleteFrames failed, err: %d
%{public}@VTCompressionSessionPrepareToEncodeFrames failed, err: %d
%{public}@Cannot set property: %@, error: %d
%{public}@Cannot copy property: %@, error: %d
%{public}@addFaceCrops:%@
%{public}@addPersonFaceCrops:%@
%{public}@Received invalid HMIPersonFaceCropSource: %ld
%{public}@addPersons:%@
%{public}@fetchAllUnassociatedFaceCropsWithCompletion
%{public}@removeFaceCropsWithUUIDs:%@
%{public}@removePersonsWithUUIDs:%@
%{public}@associateFaceCropsWithUUIDs:%@ toPersonWithUUID:%@
%{public}@Writing updated userDefinedPersonLinksByHome[%@] to disk
%{public}@Stale Home VNPersonsModel with homeUUID: %@ sourceUUID: %@ detected, attempting to remove...
%{public}@Stale model path no longer on disk, proceeding with building persons model...
%{public}@Persisted VNPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@Did not remove VNPersonsModel for homeUUID: %@ sourceUUID: %@, no model found
%{public}@Error removing user defined person links file: %@
%{public}@Removed userDefinedPersonLinksByHome for homeUUID: %@
%{public}@Removed VNPersonsModel for homeUUID: %@ sourceUUID:%@
%{public}@Unable to build equivalency map for homeUUID: %@, error: %@
%{public}@Failure to lookup equivalency cell for %@ (equivalencyCellForHome is%@ nil)
%{public}@Found nil torsoToFaceCrop for home %@ with non-nil model!
%{public}@Unable to retrieve torsoprints for person: %@, %@
%{public}@Person %@ has %lu torsoprints
%{public}@Received torso annotation with no identifier: %@
%{public}@Received torso annotation with no classification corresponding to the linkedEntityUUID: %@
%{public}@Created new torso model with %lu persons and %d total torsoprints for home: %@
%{public}@Successfully updated torso model and face crop map for home: %@
%{public}@Resetting torso model and wiping data
%{public}@Successfully deleted torso data at path: %@
%{public}@Failed to delete torso directory at path: %@, error: %@
%{public}@Torso model version on disk doesn't match current version
%{public}@Found stale torso_to_facecrop file
%{public}@There is no current torso model for home: %@
%{public}@Torso model predicted person %@ with confidence %f
%{public}@Persons Model Storage Path:%@
%{public}@Failed to parse Home UUID from path: %@
%{public}@Failed to load External HMIPersonsModel at path: %@, error: %@
%{public}@Loaded External HMIPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@No home model found for homeUUID: %@
%{public}@Failed to load Home HMIPersonsModel at path: %@, error: %@
%{public}@Loaded Home HMIPersonsModel for homeUUID: %@ sourceUUID: %@
%{public}@Loaded %lu user defined equivalencies found for home: %@
%{public}@No user defined equivalencies found for home: %@ (reason: %@)
%{public}@Got nil for torso model file path, error: %@
%{public}@No torso model found for home %@ at path: %@
%{public}@Failed to load torsoToFaceCrop map, error: %@
%{public}@Failed to load torso model at path: %@, error: %@
%{public}@Successfully loaded torso model and face crop map for home: %@
%{public}@Resetting HMIPersonsModelManager
%{public}@Recipe doesn't have a custom learningRate value, learning rate in model definition is used for training: %e
%{public}@Recipe has a custom learningRate value, learning rate in recipe is used for training: %e
%{public}@Calculating pre-training loss value
%{public}@trainingCallback %lu, loss: %f
%{public}@Training was skipped because %@ is YES.
%{public}@Training Started
%{public}@Training Finished
%{public}@Saving trained model to %@
%{public}@Successfully saved trained model at %@
%{public}@Timer fired, updating external persons model
%{public}@Settings have disabled face classification, removing external persons model
%{public}@Settings have enabled face classification, updating external persons model
%{public}@Failed to remove persons model, error:%@, retrying...
%{public}@Submitted persons model remove task, taskID:%u, retryOnError:%@
%{public}@Cannot decode additional streams using H.264, %lu H.264 decoders are already being used.
%{public}@Cannot transcode additional streams using H.265, %lu H.265 encoders are already being used, trying with H.264.
%{public}@Cannot transcode additional streams, %lu H.264 encoders are already being used.
%{public}@Cannot generate timelapse, %lu H.264 encoders are already being used.
%{public}@Clustering successful
%{public}@Clustering error
%{public}@Initializing HMIVisionSession
%{public}@Releasing vision session after period of inactivity
%{public}@Unloading model at path %@ after period of inactivity
%{public}@Error creating activity zone result directory: %@
%{public}@Activity zone file path:%@
%{public}@Error converting activity zone results to JSON: %@
%{public}@Error writing activity zone results JSON to file: %@
%{public}@motionScore %f
%{public}@Inclusion zone:%@ intersecting with:(%@) Object coordinate %@ insetThreshold %f
%{public}@Exclusion zone:%@ intersecting with:(%@) Object coordinate %@ insetThreshold %f
%{public}@Events after activity zone filtering:(%@) Object coordinate %@ insetPercentage %f
%{public}@Add motion-vector stationary event %@
%{public}@Replace matched stationary event %@ for %@
%{public}@Add edge-distance stationary event %@
%{public}@Encrypted Training Result
%{public}@Preference %@ is now %@, previously was %@
%{public}@Error fetching face crops for person:%@, error:%@
%{public}@Already started listening for the notification
%{public}@Unsupported aspect ratio: (%d, %d)
%{public}@Adding Candidate: %@
%{public}@Selected: %@
%{public}@Synthesizing Motion Detections, Target: %@
%{public}@Unable to read the asset %@
%{public}@Finish re-encoding %.3f > %.3f
%{public}@Unable to get fragment %@ from AssetWriter
%{public}@Unable to init face detector %@
%{public}@Skip the frame @ %.3fs due to analyzer failure
%{public}@Skip the frame @ %.3fs due to blurring failure
%{public}@Failed to convert YCbCr to RGBA (%@)
%{public}@Failed to clone RGBA source image
%{public}@Failed to blur entire image (vImage_Error = %zd)
%{public}@Failed to copy blurred patch (vImage_Error = %zd)
%{public}@Failed to convert RGBA to YCbCr (%@)
%{public}@Fetching persons for HMICleanupImpureHomePersonsOperation
%{public}@Error fetching persons, error:%@
%{public}@Fetched %lu persons
%{public}@Fetching face crops for person: %@
%{public}@Error fetching facecrops for person:%@, error:%@
%{public}@Fetched %lu face crops for person: %@
%{public}@Ignoring error fetching faceprints for person:%@, error:%@
%{public}@Error faceprinting face crops for person:%@, error:%@
%{public}@Number of faceprints to cluster: %lu
%{public}@Clustering error:%@ treating identity: %@ as impure
%{public}@0 or 1 cluster exists, treating identity: %@ as pure
%{public}@Unnamed person %@ has %lu clusters, treating as impure
%{public}@Named person %@ with atleast 1 personLink has %lu clusters, treating as impure
%{public}@%lu clusters exists, for person %@ trying to club clusters using vip model
%{public}@Cluster size: %lu
%{public}@Error while creating vnpersonsmodel: %@, treating identity as impure
%{public}@Failed to predict using VNPersonsModel, error: %@, treating identity as impure
%{public}@Error while removing facecrops %@
%{public}@Reassociating %lu face crops to person UUID: %@
%{public}@Error while reassociating facecrops %@
%{public}@Error creating directory %@
%{public}@Error fetching attributes of the file: %@ at: %@. Attempting to delete it
%{public}@Deleted %@ to free up some space, error: %@
%{public}@Error while deleting %@ to free up some space, error: %@
%{public}@Disk buffer size of %@: %ld KB
%{public}@Archive familiar face data for home: %@ person: %@
%{public}@Cannot archive familiar face data for person %@, error: %@
%{public}@Couldn't get URL for home archives, error: %@
%{public}@Saving archived familiar face data for home: %@ person: %@ to: %@
%{public}@Couldn't save FF archive
%{public}@Saved FF archive
%{public}@Skipping person %@ due to nil or 0 face crops
%{public}@Person %@ has crops with unknown source, reassociating them
%{public}@Skipping person %@ as all crops are either old or have a non-unknown source
%{public}@Removing %lu sentinel facecrops for person %@
%{public}@0 faceprints for person: %@, skipping
%{public}@Found pure identity, skipping person %@
%{public}@Removing person %@ and associated crops
%{public}@HMICleanupImpureHomePersonsOperation exiting early because operation was canceled.
%{public}@Completed CleanImpureHomePersonsOperation
%{public}@CleanImpureHomePersonsOperation encountered %d failures
%{public}@Error while removing persons %@
%{public}@Spawning CleanupImpureHomePersonsOperation for %@ before home person clustering
%{public}@CleanupImpureHomePersonOperation finished with error:%@
%{public}@CleanupImpureHomePersonOperation finished successfully
%{public}@Error performing cloud pull:%@
%{public}@Fetching persons
%{public}@Fetched %lu persons (%lu unnamed)
%{public}@Exiting early because task was canceled.
%{public}@Skipping named person
%{public}@Deleting unnamed person %@ (0 face crops)
%{public}@Deleting unnamed person %@ (age = %f seconds)
%{public}@Error fetching face crops:%@
%{public}@Error fetching faceprints:%@
%{public}@Storing %lu newly created faceprints
%{public}@Error saving new faceprints:%@
%{public}@Removing %lu faceprints from old versions
%{public}@Error removing faceprints from old versions:%@
%{public}@Clustering error:%@
%{public}@Number of clusters: %lu
%{public}@Cluster of size %lu beneath threshold of %d
%{public}@Face prediction error:%@
%{public}@Assigning cluster to existing person with UUID: %@
%{public}@Error adding new persons:%@
%{public}@Error associating face crops with person (%@): %@
%{public}@Finished calls to associateFaceCropsWithUUIDs
%{public}@Error removing person with UUID:%@, error:%@
%{public}@Succesfully removed person %@
%{public}@Error fetching faceprints for face crop UUIDs:%@, error:%@
%{public}@Storing newly created faceprints: %@
%{public}@Removing existing faceprints at other versions: %@
%{public}@Failed to generate persons model, error:%@
%{public}@Invalid configuration: isExternalLibrary is NO but self.dataSource does not conform to HMIHomePersonManagerDataSource protocol!
%{public}@Successfully updated persons model
%{public}@WARNING: Model has %lu named persons -- limit supported is %d
%{public}@Error fetching faces to subsample for %@: %@
%{public}@Fetched 0 training faces for %@, this would remove all face crops! Skipping face crop removal.
%{public}@Expected subsampling to leave no more than %d, but got %lu faces selected. Enforcing limit.
%{public}@Subsampling will retain %lu from a total of %lu faces for %@
%{public}@Deleting a total of %lu face crops after subsampling
%{public}@Selected %lu persons for subsampling faces but did not choose any face crops to delete!
%{public}@Reading and injecting synthesized events from path %@
%{public}@Creating analysis state update with %lu torso annotations
%{public}@Error while retrieving facecrop from torsomodel for personUUID: %@ homeUUID: %@
%{public}@Couldn't retrieve linked predictions from torsomodel for personUUID: %@ homeUUID: %@ error: %@
%{public}@Dropping Face event: %@ due to torso recognition
%{public}@Creating face recognition event: %@ from torso recognition event: %@
%{public}@Faceprinting failed for face: %@, error: %@
%{public}@Face: %@ didn't produce any classifications
%{public}@Torsoprinting failed for torso: %@, error: %@
%{public}@Unable to archive task %@: %@
%{public}@There is no task to schedule
%{public}@Error fetching unassociated face crops:%@
%{public}@Error associating face crops (num UUIDs:%lu), to personUUID: %@ with source: %@ error:%@
%{public}@Succesfully associated face crops (num UUIDs %lu) to person UUID: %@ for source: %@
%{public}@Events file "%@" does not exist.
%{public}@Cannot read events from file "%@", error: %@
%{public}@Cannot load events file, exception: %@
%{public}@Video decoder is not running, ignoring %@
%{public}@Sample buffer has no samples, skipping.
%{public}@Invalid DTS, expected > %@, got %@, skipping.
%{public}@Restarting decoder because format description changed.
%{public}@Decoded sample is out of PTS order, sample: %@
%{public}@Decoded sample has an invalid PTS, sample: %@
%{public}@Decoder is already in a failed state.
%{public}@Decompression session decoded frames after decoder was deallocated, ignoring frames.
%{public}@Frame decode error %d
%{public}@Cannot add video input.
%{public}@Cannot add audio input.
%{public}@Failed to start writing, assetWriter.status: %ld, assetWriter:.error: %@
%{public}@Started writing at %@
%{public}@didOutputSegmentData segmentType: %ld
%{public}@Trying to recover by adjusting trim duration from %@ to the minimum trim duration: %@
%{public}@Asset writer has failed fatally, ignoring %@
%{public}@Failed to write to asset writer, error %@
%{public}@Dropped   %@ because an input for the media type was not found.
%{public}@Dropped    %@ because asset writer is waiting for a sync sample.
%{public}@Dropped    %@ because of input error %@
%{public}@Video / Audio Drift (video is ahead by) %+4.3f
%{public}@Dropped    %@ because an input %@ is not ready for more media data.
%{public}@Asset writer has failed fatally, ignoring flush.
%{public}@We don't have anything to flush, ignoring flush.
%{public}@Finished waiting for flushSegment, assetWriter.status: %ld, assetWriter.error: %@
%{public}@Number of all face observations: %ld
%{public}@Invalid entry in userDefinedPersonLinks: %@
%{public}@All links for %@ in userDefinedPersonLinks are invalid
%{public}@Skipping person who belongs to user defined equivalency cell: %@
%{public}@Comparing persons (%@, %@)
%{public}@Equivalency determined between pair: (%@, %@)!
%{public}@Cannot add to matching equivalency cell because it already has entry from this source: %@
%{public}@Failed to update persons model, error:%@, retrying...
%{public}@Failed to update persons model, error:%@
%{public}@Submitted persons model update task, taskID:%u, retryOnError:%@
%{public}@Skip torsoEvent with extreme roll (%.0f deg)
%{public}@Skip torsoEvent with extreme aspect ratio (w/h) (%.2f) pixelDim:(%f, %f) bbox:(%f, %f)
%{public}@Skip torsoEvent with torsoBox close to roi boundary. Dist: (%.4f)
%{public}@Failed to predict using torso vip model
%{public}@Creating analyzer with identifier: %@, configuration: %@
%{public}@VideoAnalyzerReport saved (%@)
%{public}@Dynamic configuration is missing for time: %@, using the first instead.
%{public}@Received Message: %@
%{public}@Unknown %@
%{public}@Sent Message Reply: %@
%{public}@Camera, Manufacturer: %@, Model: %@, Fragment: %@, Sanitized Fragment Data: %@
%{public}@Finish Analyzer
%{public}@Analyzer has failed, ignoring finish.
%{public}@Video file %@ size is too large, maximum allowed is (%ld MB), no longer appending fragments.
%{public}@Disk buffer size remaining in %@, %ld MB
%{public}@Appending fragment to %@
%{public}@Saving fragment to %@
%{public}@Video format should not change.
%{public}@Audio format should not change.
%{public}@-[HMIVideoAnalyzerServer dealloc]
%{public}@Analyzer has failed or was cancelled, ignoring sample buffer.
%{public}@Analyzer has failed or was cancelled, ignoring flush.
%{public}@AnalyzerEvents(PTS:%.2f/%.2f): %@ %@
%{public}@Bundling Fragment Result, timeRange: %@, frames: [%@], thumbnails [%@]
%{public}@Analyzer frame result buffer should be empty. %@
%{public}@Thumbnail buffer should be empty. %@
%{public}@Timelapse encoder failed, ignoring: error: %@
%{public}@Generated Fragment: %@ Outcome: %@ Max Confidence Events: %@
%{public}@Analyzer Failed: %@
%{public}@Analyzer is already in a failed state.
%{public}@Sending Result: %@
%{public}@analysisFPS changing from: %f to: %f
HMIExternalPersonDataSourceDisk
HMIExternalPersonManagerDataSource
HMIPersonManagerDataSource
NSObject
HMITorsoQuality
HMFLogging
HMIHTMLReportBox
HMIHTMLReport
HMIMutableCluster
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMIVideoAnalyzerEventFace
HMIStoreFaceprintsOperation
HMIDataReader
HMIVideoEventEntry
HMIVideoEvent
HMIVideoEventBuffer
HMIVideoTimelineEntry
HMIVideoTimeline
HMIVideoTimelineProfiler
HMITimeIntervalAverage
HMIVideoAnalyzerEventMotion
HMITorsoprinter
HMIRemoveFaceCropsOperation
HMIHomePersonManager
HMFTimerDelegate
HMIStoreFaceCropOperation
HMIStoreFaceprintOperation
HMICameraVideoFrame
HMIVisionUtilities
HMIPairwiseMatch
HMIThermalMonitorService
HMIThermalMonitor
HMIMemorySampler
HMIThermalPressureMonitor
HMISignificantActivityFcosDetector
HMIVideoAssetReader
HMIHomeKitClient
HMHomeManagerDelegateAdapter
HMHomeManagerDelegate
HMISignpost
HMIFaceQualityFilterModelInput
MLFeatureProvider
HMIFaceQualityFilterSVM
HMIVideoNode
HMIVideoProcessingNode
HMIVideoAnalyzerProcessingNode
PFLBackgroundRunner
HMIExternalPersonDataSourceHomeKit
HMI_CVML_Error
HMIPersonFaceCrop
NSCopying
NSSecureCoding
NSCoding
HMIVideoAnalyzerFrameResult
HMIBackgroundEstimator
HMIMemoryAVAsset
AVAssetResourceLoaderDelegate
MovingAverageEntry
MovingAverage
HMICameraVideoFrameResult
HMIVideoAnnotationParserRecord
HMIVideoAnnotationParserTrack
HMIVideoAnnotationParser
HMIDESMutableFloatArray
HMIFaceClassifierVIP
HMIFaceClassifier
HMIDESDetection
HMIDESDatasetSample
HMIDESDataset
HMIInputFeatureProvider
HMINMSConfiguration
HMIObjectDetection
HMIObjectDetectionUtils
HMIPersonBlob
HMIPersonTracker
HMIVideoFrameAnalyzerResult
HMIVideoFrameAnalyzer
HMIVideoFrameSamplerDelegate
HMIVideoFrameAnalyzerDelegateAdapter
HMIVideoFrameAnalyzerDelegate
HMIVideoAnalyzerReportMatch
HMIVideoAnalyzerReportRecord
HMIVideoAnalyzerMutableReportComparison
HMIVideoAnalyzerMutableReportSession
HMIVideoAnalyzerMutableReport
HMIFaceCrop
HMIVideoRetimer
HMIVideoRetimerDelegateAdapter
HMIVideoRetimerDelegate
HMICamera
HMITask
HMIHomeTask
HMIEmptyTask
HMITaskServiceServer
HMITaskService
HMIFetchPersonsOperation
HMFObject
HMITorsoRecognition
HMIUpdatedFaceprintsResult
HMIFaceprinter
HMIFaceDetectorVision
HMIFaceDetector
HMIFaceprint
HMIFeedbackClipMetadata
HMIFeedbackClipMetadataGenerator
HMIPoint
HMIHomePersonManagerSettings
NSMutableCopying
HMIMutableHomePersonManagerSettings
HMIUpdateTorsoModelTask
HMIFeedbackSession
NSURLSessionDelegate
HMIFeedbackSubmitClipOperation
HMIFeedbackTask
HMIFeedback
HMIFaceClassification
HMIHomePersonDataSourceInMemory
HMIHomePersonManagerDataSource
HMIPersonsModelsSummaryTask
HMIFaceMisclassificationTask
HMIRemovePersonsModelTask
HMIVideoFrameGenerator
HMIPersonManager
HMIConfidence
HMIError
HMIVideoFragment
HMISessionEntityManager
HMIRemovePersonsOperation
HMIRemoveFaceprintsOperation
HMIAnalysisStateUpdate
HMIAnalysisStateManager
HMIVideoAnnotator
HMISystemResourceUsageMonitorImpl
HMIVideoAnalyzerResultFilter
HMIVideoAnalyzerResultActivityZoneFilter
HMIPersonSourceUUIDPair
HMIPerson
HMIPersonsModelSummary
HMIPersonsModel
HMIJSONArchiver
HMIJSONUnarchiver
HMIFaceUtilities
HMITorsoprint
HMITorsoAnnotation
HMIVideoEncoder
HMIVideoEncoderDelegateAdapter
HMIVideoEncoderDelegate
HMIHomePersonDataSourceHomeKit
HMIExternalPersonManagerSettings
HMIMutableExternalPersonManagerSettings
HMIAnalytics
HMIPersonsModelsSummary
HMIPersonsModelPrediction
HMIPersonsModelManager
HMIDESLayerParameters
HMIDESTrainingResult
HMIDESTrainer
HMIVideoAnalyzerResultOutcome
HMIExternalPersonManager
HMIRemovePersonsModelOperation
HMIVideoAnalyzerSchedulerJSONLogger
HMIVideoAnalyzerScheduler
HMISystemResourceUsageMonitorDelegate
HMIFFArchive
HMIGreedyClustering
HMIVideoFrameSampler
HMIVideoFrameIntervalSampler
HMIVideoFrameSamplerDelegateAdapter
HMICIFilterAttributeValue
HMICIFilterAttribute
HMICIFilter
HMIVisionSession
HMIMLModel
HMIFaceQualityEntropyOfLaplacian
HMIVideoAnalyzerFragmentResult
HMICameraActivityZone
HMIVideoAnalyzerConfiguration
HMIVideoAnalyzerDynamicConfiguration
HMIStationaryObject
HMIVideoTemporalEventFilter
HMIAnalysisService
HMIVideoAnalyzerEventPerson
HMIDESPackageResult
HMIDESResultPackager
HMIPreference
HMIHomePersonDataSourceDisk
HMIFetchPersonFaceCropsOperation
HMIVideoAnalyzerBlob
HMIVideoAnalyzerTrack
HMINotifydObserver
HMIVideoFrameTrackerFrameCandidate
HMIVideoFrameTracker
HMIVideoFrameTrackerDelegateAdapter
HMIVideoFrameTrackerDelegate
HMIVideoAnalyzerEventVehicle
HMIFeedbackVisionProcessor
HMICleanupImpureHomePersonsOperation
HMIClusteringTaskSummary
HMIHomePersonClusteringTask
HMIFetchFaceprintsForFaceCropsOperation
HMIUpdatePersonsModelTask
HMICameraVideoFrameAnalyzerSignificantActivity
HMICameraVideoFrameAnalyzer
HMIDESBackgroundTask
HMIVideoFrame
HMIVideoCommandBuffer
HMIVideoCommandBufferDelegateAdapter
HMIVideoCommandBufferDelegate
HMIVideoAnalyzerEventPet
HMIHLSPlaylist
HMIFetchUnassociatedFaceCropsOperation
HMIAssociateFaceCropsOperation
HMIVideoAnalyzerEvent
HMITorsoClassification
HMIVideoAnalyzerEventPackage
HMIVideoDecoder
HMIVideoDecoderDelegateAdapter
HMIVideoDecoderDelegate
HMIVideoAssetWriter
AVAssetWriterDelegate
HMIVideoAssetWriterDelegateAdapter
HMIVideoAssetWriterDelegate
HMIPersonsModelEquivalencyTable
HMIUpdatePersonsModelOperation
HMIMotionVector
HMIMotionDetection
HMIMotionDetector
HMITorsoClassifier
HMIVideoFrameSelector
HMIVideoFrameSelectorDelegateAdapter
HMIVideoFrameSelectorDelegate
HMIVideoAnalyzerState
HMIFaceRecognition
HMIVideoAnalyzer
HMIVideoAnalyzerDelegatePrivate
HMIVideoAnalyzerDelegate
HMIVideoAnalyzerServer
HMIVideoAnalyzerDelegateAdapter
HMIPersonDataSourceDisk
HMIVideoAnalyzerEventTorso
T@"HMFTimer",R,V_analyticsTimer
.cxx_destruct
T@"HMIVideoEncoder",&,V_encoder
CMTimeValue
T@"NSArray",R,V_levelThresholds
JSONObjectStringWithObject:
T@"NSData",R,V_separableSegment
JSONObjectWithData:options:error:
T@"VNSession",R
T#,&,V_eventClass
T@?,C,V_encoderDidFailWithError
T#,R,V_eventClass
TB,V_supportsFaceClassification
T@"<HMICameraVideoFrameAnalyzer>",R,V_cameraVideoFrameAnalyzer
T^f,R,N
T@"<HMIHomePersonManagerDataSource>",R,V_dataSource
Td,R,V_duration
T@"<HMIPersonManagerDataSource>",R,V_dataSource
Tf,R,V_blobArea
T@"<HMISystemResourceUsageMonitorDelegate>",W
Tq,N,V_systemResourceUsageLevel
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T{?=qiIq},V_backgroundTimeStamp
T@"<HMIVideoAssetWriterDelegate>",W,V_delegate
T{?=qiIq},V_lastSampleBufferDTS
T@"<HMIVideoDecoderDelegate>",W,V_delegate
T{?=qiIq},V_maxFragmentDuration
T@"<HMIVideoFrameAnalyzerDelegate>",W,V_delegate
T{HMIVideoEncoderDataRate=qq},N
T@"<HMIVideoFrameSelectorDelegate>",W,V_delegate
_analyzerEvents
T@"<HMIVideoRetimerDelegate>",W,V_delegate
_blobID
T@"AVAssetWriterInput",R,V_audioInput
_blurRadiusForEvents:imageSize:
T@"HMFOSTransaction",&,N,V_transaction
_camera
T@"HMFTimer",R,V_preferenceCacheFlushTimer
_classification
T@"HMFTimer",R,V_watchdogTimer
_client
T@"HMHomeManager",&,V_homeManager
_encode
T@"HMIAnalysisStateManager",&,V_analysisStateManager
_faceClassifier
T@"HMICIFilterAttributeValue",R,V_value
_ffData
T@"HMICameraVideoFrame",R,V_frame
_inactiveTracks
T@"HMIConfidence",R,V_confidence
_lastAudioPresentationTimeStamp
T@"HMIDESMutableFloatArray",R
_losses
T@"HMIDESMutableFloatArray",R,V_faceCentroid
_modelSummaries
T@"HMIDESMutableFloatArray",R,V_weights
_motionDetector
T@"HMIFaceClassifierVIP",R,V_faceClassifier
_operationQueue
T@"HMIFaceQualityFilterSVM",R,V_faceAestheticQualityFilter
_person
T@"HMIFaceRecognition",&,V_faceRecognition
_preferredOutputSegmentInterval
T@"HMIFaceprint",R,V_faceprint
_recall
T@"HMIFeedbackSession",R,V_feedbackSession
_report
T@"HMIHTMLReport",R,V_report
_source
T@"HMIHomePersonManager",&,V_homePersonManager
_status
T@"HMIMLModel",R
_systemResourceUsageMonitorImpl
T@"HMINMSConfiguration",R,V_nmsConfiguration
_taskID
T@"HMIPersonFaceCrop",R,V_faceCrop
_tracks
T@"HMIPersonsModelManager",R,V_personsModelManager
_updateRunningStd:withAuxBuffer:runningMean:runningSquaredMean:
T@"HMIPreference",R
addTorsoprints:
T@"HMISignificantActivityFcosDetector",R,V_significantActivityFcosDetector
appendFragmentResult:assetPath:
T@"HMITimeIntervalAverage",R,V_sampleBufferDelay
average
T@"HMITorsoClassification",R,V_classification
bufferFillRatio
T@"HMITorsoRecognition",R,V_torsoRecognition
bundleForClass:
T@"HMITorsoprinter",R,V_torsoprinter
classifications
T@"HMIVideoAnalyzerConfiguration",R,C,V_configuration
compact
T@"HMIVideoAnalyzerConfiguration",R,V_configuration
confidenceLevel
T@"HMIVideoAnalyzerDynamicConfiguration",R,V_configuration
currentCalendar
T@"HMIVideoAnalyzerEvent",R,V_event
dateFromString:
T@"HMIVideoAnalyzerEventTorso",R,V_torso
decoder
T@"HMIVideoAnalyzerMutableReport",R,V_report
defaultRecognizabilityModelPath
T@"HMIVideoAnalyzerResultOutcome",R,V_outcome
detectFacesInPixelBuffer:error:
T@"HMIVideoAssetReader",R,V_reader
enabled
T@"HMIVideoAssetWriter",&,V_timelapseAssetWriter
encryptedDataWithPublicKey:inPlaceDataFloatNumbers:count:error:
T@"HMIVideoEncoder",&,V_timelapseEncoder
eventConfidenceThresholdsMedium
T@"HMIVideoEventBuffer",R,V_frameAnalyzerFrameResultBuffer
expectedClasses
T@"HMIVideoFragment",R,V_fragment
externalToExternalEquivalencies
T@"HMIVideoFrameAnalyzer",R,V_frameAnalyzer
faceRecognition
T@"HMIVideoFrameSampler",R,V_frameThumbnailSampler
firmwareVersion
T@"HMIVideoFrameSelector",R,V_frameSelector
forceKeyFrameOnNextEncodedFrame
T@"HMIVideoFrameTrackerFrameCandidate",&,V_candidate
getBytes:range:
T@"HMIVideoTimeline",R,V_timeline
handleRemovedFaceprintWithUUID:
T@"HMPhotosPersonManager",&,V_photosPersonManager
hmiPrivateErrorWithCode:description:suggestion:underlyingError:
T@"MLModel",R
initWithDataSource:personUUIDs:
T@"MLModel",R,V_scalerModel
initWithLength:
T@"MovingAverage",R,V_average
initWithProductClass:workQueue:
T@"NSArray",&,V_motionDetections
initWithTaskID:
T@"NSArray",R,C,N
inputDimensions
T@"NSArray",R,V_activityZones
isCurrentDevice
T@"NSArray",R,V_attributes
isEqualToArray:
T@"NSArray",R,V_falseNegativeKeys
isProxy
T@"NSArray",R,V_frameResultIndices
T@"NSArray",R,V_homePersonsAndFaceCrops
levelThresholds
T@"NSArray",R,V_losses
lowercaseString
T@"NSArray",R,V_motionVectors
message
T@"NSArray",R,V_offsetsZeroFeatureValueNames
minFrameQuality
T@"NSArray",R,V_records
multiArrayValue
T@"NSArray",R,V_samples
na_any:
T@"NSArray",R,V_thumbnails
na_setByRemovingObjectsFromSet:
T@"NSArray",R,V_tracks
numberWithBool:
T@"NSArray",R,V_yawsFeatureValueNames
opacity
T@"NSData",&,V_assetData
outcome
T@"NSData",&,V_timelapseInitializationSegment
personCreatedDateFromFaceCrops:
T@"NSData",R,&,N
persons
T@"NSData",R,C,V_data
preTrainingLoss
T@"NSData",R,V_data
preferenceCache
T@"NSData",R,V_initializationSegment
prevFrameResult
T@"NSData",R,V_result
printWithScale:
T@"NSDate",R,C,V_dateCreated
quality
T@"NSDate",R,V_date
regionOfInterestForMotionDetections:foregroundEvents:frameSize:
T@"NSDate",R,V_startTime
requestWithURL:
T@"NSDictionary",&,V_classMap
requestedOffset
T@"NSDictionary",R
residentDevices
T@"NSDictionary",R,V_annotationScores
samples
T@"NSDictionary",R,V_clipMetadata
sequenceNumbers
T@"NSDictionary",R,V_equivalencyTablesByHome
sessionEntities
T@"NSDictionary",R,V_ffData
setAnalysisFPS:
T@"NSDictionary",R,V_homeMetadata
setAssetWriterDidFailWithError:
T@"NSDictionary",R,V_metricWithLabels
setContentType:
T@"NSDictionary",R,V_personsModelsByHome
setFrameSelectorDidSelectFrame:
T@"NSDictionary",R,V_thresholdWithLabels
setMaxConcurrentOperationCount:
T@"NSDictionary",R,V_torsoToFaceCropByHome
setMaxKeyFrameIntervalDuration:
T@"NSDictionary",R,V_userInfo
setNumberOfFaceprintsClustered:
T@"NSError",R
setPretendProductTypeIsUnknown:
T@"NSMutableArray",&,N,V_queue
setRunningMean:
T@"NSMutableArray",&,V_torsoprints
setTensorNamed:withValue:error:
T@"NSMutableArray",R,V_backgroundEvents
setTransaction:
T@"NSMutableArray",R,V_fragments
setWeakDecoder:
T@"NSMutableArray",R,V_motionDetections
significantActivityFcosDetector
T@"NSMutableArray",R,V_previousPersons
strides
T@"NSMutableArray",R,V_stationaryObjects
stringByAppendingPathExtension:
T@"NSMutableDictionary",R,N,V_preferenceCache
submitFeedbackWithCameraProfileUUID:clipUUID:completionHandler:
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
summary
T@"NSMutableDictionary",R,V_personToFaceCrops
systemResourceUsageDidChangeTo:
T@"NSMutableDictionary",R,V_sessionEntities
thumbnailBuffer
T@"NSMutableDictionary",R,V_tracks
torsoAnnotation
T@"NSMutableIndexSet",&,V_personIndices
torsoprintUUIDs
T@"NSMutableSet",R,V_eventClasses
T@"NSNumber",R,V_confidence
weights
T@"NSNumber",R,V_metricDefault
T@"NSNumber",R,V_roll
.cxx_construct
T@"HMIVideoDecoder",R,V_decoder
CGAffineTransformValue
T@"NSArray",R,V_layerParameters
JSONObject
T@"NSArray",R,V_sequenceNumbers
JSONObjectStringWithObject:pretty:options:
T@"NSUUID",R,V_linkedEntityUUID
JSONObjectWithObject:options:
T@?,C,V_decoderDidFailWithError
T#,R
TB,R,V_external
T@"<HMIAnalysisStateManagerDelegate>",W,V_delegate
TQ,R,V_capacity
T@"<HMIExternalPersonManagerDataSource>",W,N,V_dataSource
T^{__CVBuffer=},R,V_pixelBuffer
T@"<HMIHomePersonManagerDataSource>",W,N,V_dataSource
Td,R,V_timeSinceAnalyzerStarted
T@"<HMIPersonManagerDataSource>",W,N,V_dataSource
Ti,V_nextTaskID
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
Tq,V_decodeMode
T@"<HMIVideoAnalyzerDelegate>",W,V_delegate
T{?=qiIq},V_foregroundTimeStamp
T@"<HMIVideoCommandBufferDelegate>",W,V_delegate
T{?=qiIq},V_lastSampleBufferPTS
T@"<HMIVideoEncoderDelegate>",W,V_delegate
T{CGPoint=dd},R
T@"<HMIVideoFrameSamplerDelegate>",W,V_delegate
_analyticsTimer
T@"<HMIVideoFrameTrackerDelegate>",W,V_delegate
_biases
T@"AVAssetWriter",&,V_assetWriter
_blobsFromAssignment:timeStamp:
T@"AVAssetWriterInput",R,V_videoInput
_buffer
T@"HMFOSTransaction",&,V_transaction
_cameraMetadata
T@"HMFTimer",R,V_tick
_classificationThresholdUnknown
T@"HMFWeakObject",&,V_weakDecoder
_didUpdateHomes
T@"HMHomePersonManager",&,V_homePersonManager
_events
T@"HMIBackgroundEstimator",&,V_backgroundEstimator
_faceprintUUIDs
T@"HMICamera",&,V_camera
_frameAnalyzerFrameResultBuffer
T@"HMIClusteringTaskSummary",R,V_summary
_l2Norm
T@"HMIDESDataset",R,V_data
_lastVideoPresentationTimeStamp
T@"HMIDESMutableFloatArray",R,V_biases
_minorVersionFromVisionVersion:
T@"HMIDESMutableFloatArray",R,V_torsoCentroid
_motion
T@"HMIExternalPersonManagerSettings",R,V_settings
_numDidCreateTimelapseFragments
T@"HMIFaceCrop",R,V_faceCrop
_origin
T@"HMIFaceQualityFilterSVM",R,V_faceRecognizabilityFilter
_points
T@"HMIFaceRecognition",R,V_faceRecognition
_reader
T@"HMIFaceprinter",R,V_faceprinter
_recognizeFaces
T@"HMIGreedyClustering",R,V_clusterer
_result
T@"HMIHomeKitClient",R,V_homeKitClient
_stageZero_expireUnnamedPersons
T@"HMIHomePersonManagerSettings",R,V_settings
_stream
T@"HMIMotionDetector",R,V_motionDetector
_targetInterval
T@"HMIPerson",R,V_person
_timelapseInitializationSegment
T@"HMIPersonsModelManager",R
_unrecognizable
T@"HMIPersonsModelSummary",R
addDate:atTime:
T@"HMISessionEntityManager",R,V_sessionEntityManager
allKeys
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
arrayWithArray:
T@"HMITorsoAnnotation",R,V_torsoAnnotation
base64EncodedStringWithOptions:
T@"HMITorsoClassifier",R,V_torsoClassifier
bufferWillFlush
T@"HMITorsoprint",R,V_torsoprint
classPaddingMap
T@"HMIVideoAnalyzerBlob",R
classifyTorsoEvent:regionOfInterest:pixelBuffer:homeUUID:error:
T@"HMIVideoAnalyzerConfiguration",R,V_analyzerConfiguration
computeJunkScoreForPixelBuffer:
T@"HMIVideoAnalyzerDynamicConfiguration",&,V_dynamicConfiguration
containsObject:
T@"HMIVideoAnalyzerDynamicConfiguration",R,V_dynamicConfiguration
dataWithLength:
T@"HMIVideoAnalyzerEventFace",R,V_face
dealloc
T@"HMIVideoAnalyzerFrameResult",&,V_prevFrameResult
defaultConfidenceThresholdsHigh
T@"HMIVideoAnalyzerResultOutcome",R
defaultRevision
T@"HMIVideoAnalyzerState",R,V_state
dictionaryValue
T@"HMIVideoAssetWriter",&,V_assetWriter
encoder
T@"HMIVideoCommandBuffer",R,V_commandBuffer
T@"HMIVideoEventBuffer",R,V_dynamicConfigurationBuffer
eventForClass:boundingBox:UUID:
T@"HMIVideoEventBuffer",R,V_thumbnailBuffer
externalLibrary
T@"HMIVideoFrame",R,V_frame
faceBoundingBox
T@"HMIVideoFrameSampler",R,V_frameSampler
feedbackSession
T@"HMIVideoFrameSampler",R,V_frameTimelapseSampler
flushAndGetAnalysisStateUpdateForHome:enableFaceClassification:
T@"HMIVideoFrameTracker",R,V_frameTracker
frameId
T@"HMIVideoTemporalEventFilter",R,V_temporalEventFilter
getTensorNamed:
T@"HMIVisionSession",R
handleSampleBuffer:outputFrame:
T@"MLModel",&,V_model
initWithConfidence:boundingBox:
T@"MLModel",R,V_mlModel
initWithInitializationSegment:separableSegment:sequenceNumbers:
T@"MLMultiArray",&,N,V_input
initWithPoints:
T@"NSArray",&,V_activityZones
initWithSource:
T@"NSArray",R
initWithTruth:prediction:score:
T@"NSArray",R,C,V_points
isAffectedDate:
T@"NSArray",R,V_allPersonsAndFaceCrops
isEmpty
T@"NSArray",R,V_detections
isPersonDataAvailableViaHomeKit
T@"NSArray",R,V_falsePositiveKeys
isSetup
T@"NSArray",R,V_frameResults
layerParameters
T@"NSArray",R,V_homes
limitEnforcedSubsetFromPersons:
T@"NSArray",R,V_motionDetections
maxNorm
T@"NSArray",R,V_offsetsOneFeatureValueNames
metricForLabel:
T@"NSArray",R,V_photosPersonsAndFaceCrops
mlModel
T@"NSArray",R,V_rollsFeatureValueNames
na_all:
T@"NSArray",R,V_scoresFeatureValueNames
na_map:
T@"NSArray",R,V_torsoprints
T@"NSArray",R,V_truePositiveKeys
objects
T@"NSCondition",R,V_condition
options
T@"NSData",&,V_initializationSegment
performCloudPullWithCompletion:
T@"NSData",R
personFaceCrops
T@"NSData",R,C
placeholderCopy
T@"NSData",R,C,V_dataRepresentation
predictedPersonUniqueIdentifier
T@"NSData",R,V_imageData
prepare
T@"NSData",R,V_jpegData
previousPersons
T@"NSDate",&,V_lastFragmentReceivedDate
protectionSpace
T@"NSDate",R,V_beginDate
records
T@"NSDate",R,V_startDate
release
T@"NSDate",R,V_targetDate
requestedLength
T@"NSDictionary",&,V_serviceResult
resetReferences
T@"NSDictionary",R,C,V_options
results
T@"NSDictionary",R,V_cameraMetadata
seekToEndOfFile
T@"NSDictionary",R,V_deviceInformation
session
T@"NSDictionary",R,V_faceCountsByPerson
T@"NSDictionary",R,V_highConfidenceThresholds
setAssetWriter:
T@"NSDictionary",R,V_mediumConfidenceThresholds
setCachePolicy:
T@"NSDictionary",R,V_personToEquivalencyCell
setDropTrimDurationAttachments:
T@"NSDictionary",R,V_targetEventClassRanks
setHomeManager:
T@"NSDictionary",R,V_torsoModelsByHome
setMaxFragmentAnalysisDuration:
T@"NSDictionary",R,V_userDefinedPersonLinksByHome
setNumFailures:
T@"NSError",&,V_error
setNumberStyle:
T@"NSMutableArray",&,N,V_faceprintUUIDs
setProducesCombinableFragments:
T@"NSMutableArray",&,N,V_torsoprintUUIDs
setShouldOptimizeForNetworkUse:
T@"NSMutableArray",R,V_analysisTimeStamps
setTorsoprints:
T@"NSMutableArray",R,V_blobs
setUsesCPUOnly:
T@"NSMutableArray",R,V_lines
settingsControl
T@"NSMutableArray",R,V_motionTimeStamps
skipped
T@"NSMutableArray",R,V_reportBuffer
stringByAppendingPathComponent:
T@"NSMutableArray",R,V_temporaryFileURLs
stringFromDate:
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
success
T@"NSMutableDictionary",R,V_inactiveTracks
suspend
T@"NSMutableDictionary",R,V_services
taskRunnerClass
T@"NSMutableDictionary",R,V_sessions
thumbnailHeight
T@"NSMutableDictionary",R,V_unknownFacesSavedCounts
torsoClassifier
T@"NSMutableSet",&,N,V_linkedEntityUUIDs
underlyingModel
T@"NSMutableSet",R,V_unassociatedFaceCrops
version
T@"NSNumber",R,V_label
T@"NSNumber",R,V_prediction
T@"NSNumber",R,V_thresholdDefault
T@"NSNumber",R,V_truth
T@"NSNumber",R,V_value
T@"NSNumber",R,V_yaw
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
T@"NSObject<OS_dispatch_queue>",R,V_delegateQueue
T@"NSObject<OS_dispatch_queue>",R,V_encoderQueue
T@"NSObject<OS_dispatch_queue>",R,V_inputQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
T@"NSOperationQueue",R,V_homeKitOperationQueue
T@"NSOperationQueue",R,V_operationQueue
T@"NSOutputStream",R,V_stream
T@"NSPointerArray",R,V_internalAnalyzers
T@"NSSet",&,V_externalPersonManagers
T@"NSSet",&,V_faceCrops
T@"NSSet",R
T@"NSSet",R,C,V_faceCropUUIDs
T@"NSSet",R,C,V_personLinks
T@"NSSet",R,N
T@"NSSet",R,V_analyzerEvents
T@"NSSet",R,V_backgroundEvents
T@"NSSet",R,V_classifications
T@"NSSet",R,V_createdAtCurrentVersion
T@"NSSet",R,V_events
T@"NSSet",R,V_existingAtCurrentVersion
T@"NSSet",R,V_existingAtOtherVersions
T@"NSSet",R,V_faceClassifications
T@"NSSet",R,V_faceCropUUIDs
T@"NSSet",R,V_faceprintUUIDs
T@"NSSet",R,V_faceprints
T@"NSSet",R,V_modelSummaries
T@"NSSet",R,V_personFaceCrops
T@"NSSet",R,V_personUUIDs
T@"NSSet",R,V_persons
T@"NSSet",R,V_predictedLinkedEntityUUIDs
T@"NSSet",R,V_removedPersonFaceCrops
T@"NSSet",R,V_torsoAnnotations
T@"NSSet",R,V_tracks
T@"NSSet",R,V_unassociatedFaceCrops
T@"NSString",&,V_logIdentifier
T@"NSString",C,V_source
T@"NSString",R
T@"NSString",R,C
T@"NSString",R,C,V_name
T@"NSString",R,V_boxesName
T@"NSString",R,V_classesName
T@"NSString",R,V_color
T@"NSString",R,V_feedbackServiceHost
T@"NSString",R,V_firmwareVersion
T@"NSString",R,V_identifier
T@"NSString",R,V_imageName
T@"NSString",R,V_inputFeatureValueName
T@"NSString",R,V_inputName
T@"NSString",R,V_key
T@"NSString",R,V_manufacturer
T@"NSString",R,V_message
T@"NSString",R,V_model
T@"NSString",R,V_name
T@"NSString",R,V_outputPath
T@"NSString",R,V_personsModelIdentifier
T@"NSString",R,V_text
T@"NSString",R,V_type
T@"NSString",R,V_weightsName
T@"NSURL",R,V_modelURL
T@"NSURL",R,V_networkPath
T@"NSURL",R,V_sourceURL
T@"NSURL",R,V_url
T@"NSURLSession",R,V_session
T@"NSUUID",&,V_blobID
T@"NSUUID",&,V_homeUUID
T@"NSUUID",R
T@"NSUUID",R,C,V_UUID
T@"NSUUID",R,C,V_faceCropUUID
T@"NSUUID",R,C,V_homeUUID
T@"NSUUID",R,C,V_identifier
T@"NSUUID",R,C,V_modelUUID
T@"NSUUID",R,C,V_personUUID
T@"NSUUID",R,C,V_sourceUUID
T@"NSUUID",R,V_UUID
T@"NSUUID",R,V_cameraProfileUUID
T@"NSUUID",R,V_clipUUID
T@"NSUUID",R,V_homeUUID
T@"NSUUID",R,V_identifier
T@"NSUUID",R,V_personUUID
T@"NSUUID",R,V_sessionEntityUUID
T@"NSUUID",R,V_sourceUUID
T@"NSUUID",R,V_torsoModelVersion
T@"VNPersonsModel",R,V_visionPersonsModel
T@,R,V_container
T@,R,V_value
T@?,C,V_analyzerDidAnalyzeFragmentWithResult
T@?,C,V_analyzerDidAnalyzeFrameWithResult
T@?,C,V_analyzerDidCreateTimelapseFragment
T@?,C,V_analyzerDidFailWithError
T@?,C,V_analyzerDidProduceAnalysisStateUpdate
T@?,C,V_assetWriterDidFailWithError
T@?,C,V_assetWriterDidOutputInitializationSegment
T@?,C,V_assetWriterDidOutputSeparableSegment
T@?,C,V_bufferWillFlush
T@?,C,V_bufferWillHandleSampleBuffer
T@?,C,V_decoderDidDecodeSampleBuffer
T@?,C,V_didUpdateHomes
T@?,C,V_encoderDidEncodeSampleBuffer
T@?,C,V_frameAnalyzerDidAnalyzeFrame
T@?,C,V_frameAnalyzerDidProduceAnalysisStateUpdate
T@?,C,V_frameSamplerDidDropFrame
T@?,C,V_frameSamplerDidSampleFrame
T@?,C,V_frameSelectorDidSelectFrame
T@?,C,V_frameSelectorDidSkipFrame
T@?,C,V_frameSelectorPrepareFrame
T@?,C,V_frameTrackerDidTrackFrame
T@?,C,V_progressBlock
T@?,C,V_retimerDidRetimeSampleBuffer
T@?,R,N,V_callback
TB,D,GisFaceClassificationEnabled
TB,D,GisImportingFromPhotoLibraryEnabled
TB,D,GisSharingFaceClassificationsEnabled
TB,GisCancelled,V_cancelled
TB,GisFaceClassificationEnabled,V_faceClassificationEnabled
TB,GisImportingFromPhotoLibraryEnabled,V_importingFromPhotoLibraryEnabled
TB,GisPersonDataAvailableViaHomeKit,V_personDataAvailableViaHomeKit
TB,GisSharingFaceClassificationsEnabled,V_sharingFaceClassificationsEnabled
TB,N
TB,R
TB,R,GhasEstimatedBoundingBox,V_isBoundingBoxEstimated
TB,R,GisExternalLibrary,V_externalLibrary
TB,R,GisInclusion,V_inclusion
TB,R,GisSentinelFaceprint
TB,R,GisSetup,V_setup
TB,R,GshouldRemoveExcessFaceCrops,V_removeExcessFaceCrops
TB,R,V_allowRecoveryFromInsufficientAudioTrim
TB,R,V_didEncryptPackageResult
TB,R,V_didPrivatizePackageResult
TB,R,V_doImpurePersonCleanup
TB,R,V_encode
TB,R,V_encoder
TB,R,V_frameReorderingRequired
TB,R,V_fromTorsoClassification
TB,R,V_lowQuality
TB,R,V_monitored
TB,R,V_unrecognizable
TB,V_adjustBrightness
TB,V_allowReducedConfiguration
TB,V_dropSamplesUntilSync
TB,V_dropTrimDurationAttachments
TB,V_enableTemporalEventFiltering
TB,V_enabled
TB,V_forceKeyFrameOnNextEncodedFrame
TB,V_hasFailed
TB,V_ignoreThermalAndSystemResourceUsageLevel
TB,V_passthroughAudio
TB,V_recognizeFaces
TB,V_redactFrames
TB,V_resetReferences
TB,V_saveAnalyzerResultsToDisk
TB,V_transcode
TI,R
TI,V_transcodeCodecType
TQ,R
TQ,R,N
TQ,R,N,V_windowSize
TQ,R,V_bufferSize
TQ,R,V_cachePolicy
TQ,R,V_code
TQ,R,V_count
TQ,R,V_externalToExternalEquivalencies
TQ,R,V_firstIndex
TQ,R,V_fragmentSequenceNumber
TQ,R,V_frameId
TQ,R,V_homeToExternalEquivalencies
TQ,R,V_maxCandidates
TQ,R,V_minSampleSize
TQ,R,V_motionMode
TQ,R,V_numDecodedSamples
TQ,R,V_numDidAnalyzeFragments
TQ,R,V_numDidAnalyzeFrames
TQ,R,V_numDidAnalyzePackages
TQ,R,V_numDidCreateTimelapseFragments
TQ,R,V_numberOfDroppedFrames
TQ,R,V_reorderBufferSize
TQ,R,V_secondIndex
TQ,R,V_signpostIdentifier
TQ,R,V_status
TQ,R,V_thermalLevel
TQ,R,V_trackIndex
TQ,V_maxH264VideoDecoders
TQ,V_maxH264VideoEncoders
TQ,V_maxH265VideoEncoders
TQ,V_maxReferences
TQ,V_numCandidates
TQ,V_numImages
TQ,V_numTracks
TQ,V_size
TQ,V_stationaryBlobIndex
TQ,V_thumbnailHeight
TS,R,V_blobID
T^S,V_assignment
T^f,V_runningMean
T^f,V_runningStd
T^{OpaqueVTCompressionSession=},V_session
T^{OpaqueVTDecompressionSession=},V_session
T^{__CFArray=},R,V_references
T^{__CFArray=},R,V_resizedSampleBuffers
T^{opaqueCMBufferQueue=},V_buffer
T^{opaqueCMSampleBuffer=},R,V_sbuf
T^{opaqueCMSampleBuffer=},V_background
Td,N
Td,R
Td,R,V_analysisFPS
Td,R,V_averageAnalysisTime
Td,R,V_bufferFillRatio
Td,R,V_classificationThresholdKnown
Td,R,V_classificationThresholdUnknown
Td,R,V_confidence
Td,R,V_delay
Td,R,V_faceQualityScore
Td,R,V_faceVIPThresholdForTorsoAnnotation
Td,R,V_maxNorm
Td,R,V_probability
Td,R,V_timeSinceLastFragmentWasReceived
Td,R,V_timeStamp
Td,R,V_value
Td,V_analysisFPS
Td,V_clusteringDuration
Td,V_faceprintingDuration
Td,V_maxFragmentAnalysisDuration
Td,V_minFrameQuality
Td,V_minFrameScale
Td,V_movingAverage
Td,V_totalDuration
Tf,R
Tf,R,V_l2Norm
Tf,R,V_motionScore
Tf,R,V_opacity
Tf,R,V_postTrainingLoss
Tf,R,V_preTrainingLoss
Tf,R,V_precision
Tf,R,V_recall
Tf,R,V_score
Tf,R,V_value
Ti,N,V_token
Ti,R,V_labelIndex
Ti,R,V_taskID
Ti,V_numFailures
Tq,N
Tq,R
Tq,R,V_events
Tq,R,V_falseNegative
Tq,R,V_falsePositive
Tq,R,V_familiarity
Tq,R,V_sessionEntityAssignment
Tq,R,V_source
Tq,R,V_thermalPressureLevel
Tq,R,V_truePositive
Tq,R,V_version
Tq,V_eventTriggers
Tq,V_highWaterMark
Tq,V_logStateCount
Tq,V_numberOfClusters
Tq,V_numberOfFaceprintsClustered
Tq,V_numberOfPersonsCreated
Tq,V_numberOfUnknownFaceprintsAssociated
Tq,V_options
Tq,V_packageClassifierMode
Tr*,R,N,V_notificationName
Tr^f,R,N
Tr^{opaqueCMFormatDescription=},R,V_audioFormat
Tr^{opaqueCMFormatDescription=},R,V_audioFormatDescription
Tr^{opaqueCMFormatDescription=},R,V_videoFormat
Tr^{opaqueCMFormatDescription=},R,V_videoFormatDescription
Tr^{opaqueCMFormatDescription=},V_inputAudioFormat
Tr^{opaqueCMFormatDescription=},V_inputVideoFormat
Tr^{opaqueCMFormatDescription=},V_timelapseOutputVideoFormat
T{?=qiIq},R
T{?=qiIq},R,V_approximationInterval
T{?=qiIq},R,V_backgroundChangeInterval
T{?=qiIq},R,V_backgroundChangeResetInterval
T{?=qiIq},R,V_backgroundExpireInterval
T{?=qiIq},R,V_backgroundTimeStamp
T{?=qiIq},R,V_baseDecodeTimeStamp
T{?=qiIq},R,V_currentPTS
T{?=qiIq},R,V_expirationInterval
T{?=qiIq},R,V_motionValidInterval
T{?=qiIq},R,V_presentationTime
T{?=qiIq},R,V_presentationTimeStamp
T{?=qiIq},R,V_targetInterval
T{?=qiIq},R,V_time
T{?=qiIq},R,V_timeInterval
T{?=qiIq},R,V_timeStamp
T{?=qiIq},R,V_trackInterval
T{?=qiIq},R,V_videoDuration
T{?=qiIq},V_backgroundChangeTimeStamp
T{?=qiIq},V_currentDTS
T{?=qiIq},V_currentFragmentStartTime
T{?=qiIq},V_currentPTS
T{?=qiIq},V_lastAudioPresentationTimeStamp
T{?=qiIq},V_lastVideoPresentationTimeStamp
T{?=qiIq},V_preferredOutputSegmentInterval
T{?=qiIq},V_referenceInterval
T{?=qiIq},V_thumbnailInterval
T{?=qiIq},V_timelapseInterval
T{?=qiIq},V_timelapsePreferredFragmentDuration
T{?=qiIq},V_trackAnalysisPTS
T{?={?=qiIq}{?=qiIq}},R,V_audioTrackTimeRange
T{?={?=qiIq}{?=qiIq}},R,V_timeRange
T{?={?=qiIq}{?=qiIq}},R,V_videoTrackTimeRange
T{CGPoint=dd},R,V_origin
T{CGPoint=dd},R,V_point
T{CGRect={CGPoint=dd}{CGSize=dd}},R
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_faceBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_regionOfInterest
T{CGSize=dd},R
T{CGSize=dd},R,V_inputDimensions
T{CGSize=dd},R,V_size
T{CGSize=dd},V_imageSize
T{CGSize=dd},V_modelSize
T{CGVector=dd},R,V_motion
T{_NSRange=QQ},R,V_firstVideoSampleByteRange
T{os_unfair_lock_s=I},R,N,V_lock
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLByDeletingPathExtension
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLSession:didBecomeInvalidWithError:
URLSession:didReceiveChallenge:completionHandler:
URLSessionDidFinishEventsForBackgroundURLSession:
URLWithString:
UTF8String
UUID
UUIDPairString
UUIDString
_JSONObjectWithObject:options:
_UUID
_activityZones
_addCandidateForTarget:motionScore:motionDetections:tracks:
_addClassToContainer:
_addEventsToEventQueue:events:
_addValueToContainer:forKey:
_adjustBackgroundAtAttribute:backgroundChanged:timeStamp:
_adjustBrightness
_allPersonsAndFaceCrops
_allowRecoveryFromInsufficientAudioTrim
_allowReducedConfiguration
_analysisFPS
_analysisStateManager
_analysisTime
_analysisTimeStamps
_analyzerConfiguration
_analyzerDidAnalyzeFragmentWithResult
_analyzerDidAnalyzeFrameWithResult
_analyzerDidCreateTimelapseFragment
_analyzerDidFailWithError
_analyzerDidProduceAnalysisStateUpdate
_analyzerEventsFromObjectDetections:
_anchorStrides
_annotationScores
_annotationScoresFromAnalyzerEvents:
_appendSampleBuffer:
_appendTarget:timeStamp:motionDetections:
_approximationInterval
_asset
_assetData
_assetReader
_assetWriter
_assetWriterDidFailWithError
_assetWriterDidOutputInitializationSegment
_assetWriterDidOutputSeparableSegment
_assignment
_attachEncryptedDataUsingKey:toPayload:error:
_attachFaceCrops:toPayload:error:
_attributes
_attributesLoaded
_audioFormat
_audioFormatDescription
_audioInput
_audioTrackTimeRange
_average
_averageAnalysisTime
_background
_backgroundAtTimeStamp:
_backgroundChangeInterval
_backgroundChangeResetInterval
_backgroundChangeTimeStamp
_backgroundEstimator
_backgroundEvents
_backgroundExpireInterval
_backgroundTimeStamp
_base64StringFromData:
_baseDecodeTimeStamp
_beginDate
_binWidth
_blobArea
_blobs
_blurSampleBufferWithEncoder:sampleBuffer:events:
_boundingBox
_boxesName
_boxesTensorData
_bufferFillRatio
_bufferSize
_bufferWillFlush
_bufferWillHandleSampleBuffer
_cachePolicy
_callback
_cameraProfileUUID
_cameraVideoFrameAnalyzer
_cancelled
_candidate
_capacity
_classMap
_classesName
_classesTensorData
_classificationThresholdKnown
_classifications
_clipMetadata
_clipUUID
_clusterer
_clusteringDuration
_code
_color
_colorSpace
_commandBuffer
_compactInternalAnalyzers
_computeOpticalFlow:with:globalMotionScore:activityZones:operationMode:
_condition
_confidence
_confidenceThresholds
_configuration
_configureAssetWriter
_configureEncoder
_configureTimelapseAssetWriter
_configureTimelapseEncoder
_container
_containerIsArray
_context
_copyFromOutputBuffer:toPixelBuffer:
_copyFromPixelBuffer:toInputBuffer:translateCol:translateRow:
_copyNextSampleBufferFromTrackOutput:
_correctRunningMeanBrightnessAtAttribute:
_count
_createBlurredPixelBuffer:events:
_createFontWithSize:
_createOutputsForAsset:readVideo:readAudio:
_createPayloadWithServiceResult:error:
_createSessionWithFormatDescription:
_createdAtCurrentVersion
_currentDTS
_currentFragmentStartTime
_currentPTS
_data
_dataRepresentation
_dataSource
_date
_dateCreated
_decodeMode
_decoder
_decoderDidDecodeSampleBuffer
_decoderDidFailWithError
_delay
_delegate
_delegateQueue
_detections
_detectionsFromAnalyzerEvents:
_deviceInformation
_didDecodeSampleBuffer:
_didEncryptPackageResult
_didPrivatizePackageResult
_doImpurePersonCleanup
_downloadClipWithCameraProfileUUID:clipUUID:completionHandler:
_drainCandidateThatExpiredBefore:
_drainResizedBuffersThatExpiredBefore:
_dropSamplesUntilSync
_dropTrimDurationAttachments
_duration
_dynamicConfiguration
_dynamicConfigurationBuffer
_enableTemporalEventFiltering
_enabled
_encoder
_encoderDidEncodeSampleBuffer
_encoderDidFailWithError
_encoderQueue
_ensureAttributes
_ensureDecoderForFragment:
_ensureEncoder
_ensureFirstAudioSampleBufferHasSufficientPrimingTrim:
_ensureInternalBuffersForPixelBuffer:
_ensureModelWithError:
_ensureTimelapseEncoder
_equivalencyTablesByHome
_error
_event
_eventClass
_eventClasses
_eventTriggers
_eventsFromAnalyzerEvents:
_eventsWithClassificationsFromEvents:videoFrame:regionOfInterest:homeUUID:
_eventsWithSessionEntitiesFromEvents:regionOfInterest:timeStamp:homeUUID:
_evictSampleBuffer:
_existingAtCurrentVersion
_existingAtOtherVersions
_expirationInterval
_expireMotionDetectionsAtTimeStamp:
_exportInternalStateForPixelBuffer:exportMode:
_external
_externalLibrary
_externalPersonManagers
_externalToExternalEquivalencies
_face
_faceAestheticQualityFilter
_faceBoundingBox
_faceCentroid
_faceClassificationEnabled
_faceClassifications
_faceClassificationsFromAnalyzerEvents:
_faceCountsByPerson
_faceCrop
_faceCropUUID
_faceCropUUIDs
_faceCrops
_faceQualityScore
_faceRecognition
_faceRecognizabilityFilter
_faceVIPThresholdForTorsoAnnotation
_faceprint
_faceprinter
_faceprintingDuration
_faceprints
_failWithDescription:
_falseNegative
_falseNegativeKeys
_falsePositive
_falsePositiveKeys
_familiarity
_feedbackServiceHost
_feedbackSession
_filterEvents:stationaryEvents:motionDetection:
_filterEvents:stationaryEvents:motionDetection:prevFrameResult:regionOfInterest:
_filterEvents:stationaryEvents:stationaryObjects:expirationPTS:imageSize:
_filterFrameResult:dynamicConfiguration:motionDetections:
_filterPackageEvents:backgroundEvents:
_firmwareVersion
_firstIndex
_firstPTS
_firstVideoSampleByteRange
_flushAutomatically:
_font
_forceKeyFrameOnNextEncodedFrame
_foregroundBlobsFromBlobs:backgroundChanged:
_foregroundDifferencesFromPixelBuffer:differences:
_foregroundPixelsFromPixelBuffer:attribute:assignment:useChromaOnly:
_foregroundTimeStamp
_fragment
_fragmentSequenceNumber
_fragments
_frame
_frameAnalyzer
_frameAnalyzerDidAnalyzeFrame
_frameAnalyzerDidProduceAnalysisStateUpdate
_frameId
_frameReorderingRequired
_frameResultIndices
_frameResults
_frameSampler
_frameSamplerDidDropFrame
_frameSamplerDidSampleFrame
_frameSelector
_frameSelectorDidSelectFrame
_frameSelectorDidSkipFrame
_frameSelectorPrepareFrame
_frameThumbnailSampler
_frameTimelapseSampler
_frameTracker
_frameTrackerDidTrackFrame
_fromTorsoClassification
_getFloat64Property:propertyValueOut:
_getPeakPowerPressureLevel
_getProperty:propertyValue:
_getSInt32Property:propertyValueOut:
_greedyClusterer
_handleDecodedSampleBuffer:
_hasFailed
_hasTorsoprinterVersionChangedForHome:
_highConfidenceThresholds
_highWaterMark
_histogram
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
_homeKitClient
_homeKitOperationQueue
_homeManager
_homeMetadata
_homePersonManager
_homePersonsAndFaceCrops
_homeToExternalEquivalencies
_homeUUID
_homes
_identifier
_ignoreThermalAndSystemResourceUsageLevel
_imageData
_imageName
_imageSize
_importingFromPhotoLibraryEnabled
_inclusion
_initSessionWithDimensions:codecType:useHardwareAcceleration:error:
_initializationSegment
_input
_inputAudioFormat
_inputDimensions
_inputFeatureValueName
_inputName
_inputQueue
_inputVideoFormat
_internalAnalyzers
_intersectionOverUnionFromBlob:boundingBox:assignment:
_interval
_invalidate
_invalidateBackgroundForPixelBuffer:timeStamp:
_invalidateWithErr:
_isBoundingBoxEstimated
_isTorsoFaceCropMapStale:
_jpegData
_key
_label
_labelIndex
_lastFragmentReceivedDate
_lastIndex
_lastSample
_lastSampleBufferDTS
_lastSampleBufferPTS
_layerParameters
_levelThresholds
_lines
_linkedEntityUUID
_linkedEntityUUIDs
_loadResource:withExtension:
_loadTorsoDataForHomeUUID:intoTorsoModelsByHome:torsoToFaceCropByHome:
_lock
_logIdentifier
_logState
_logStateCount
_lowQuality
_manufacturer
_maxCandidates
_maxCapacity
_maxFragmentAnalysisDuration
_maxFragmentDuration
_maxH264VideoDecoders
_maxH264VideoEncoders
_maxH265VideoEncoders
_maxLaplacianScore
_maxNorm
_maxReferences
_maxScore
_mediumConfidenceThresholds
_message
_metricDefault
_metricWithLabels
_minFrameQuality
_minFrameScale
_minLaplacianScore
_minSampleSize
_mlModel
_model
_modelSize
_modelURL
_modelUUID
_monitored
_motionDetections
_motionDetectionsFromTarget:reference:dynamicConfiguration:motionScore:
_motionMode
_motionScore
_motionTimeStamps
_motionValidInterval
_motionVectors
_movingAverage
_name
_networkPath
_nextTaskID
_nmsConfiguration
_notificationName
_notificationQueue
_notifyDelegateDidAnalyzeFragmentWithResult:
_notifyDelegateDidAnalyzeFrameWithResult:
_notifyDelegateDidCreateTimelapseFragment:
_notifyDelegateDidFailWithError:
_notifyDelegateDidProduceAnalysisStateUpdate:
_numBins
_numCandidates
_numDecodedSamples
_numDidAnalyzeFragments
_numDidAnalyzeFrames
_numDidAnalyzePackages
_numFailures
_numImages
_numTracks
_numberOfClusters
_numberOfDroppedFrames
_numberOfFaceprintsClustered
_numberOfPersonsCreated
_numberOfUnknownFaceprintsAssociated
_objectWithJSONObject:allowedClasses:
_offsetsOneFeatureValueNames
_offsetsZeroFeatureValueNames
_opacity
_operation
_options
_osThermalPressureLevelNotificationToken
_outcome
_outputPath
_packageClassifierMode
_passthroughAudio
_personDataAvailableViaHomeKit
_personFaceCrops
_personIndices
_personLinks
_personToEquivalencyCell
_personToFaceCrops
_personTracker
_personUUID
_personUUIDs
_persons
_personsModelIdentifier
_personsModelManager
_personsModelsByHome
_photosPersonManager
_photosPersonsAndFaceCrops
_pixelBuffer
_point
_position
_postProcessOffsetsZero:offsetsOne:scores:yaws:rolls:outputPredictions:
_postTrainingLoss
_preTrainingLoss
_precision
_predictEventsFromCropPixelBuffer:cropRect:imageSize:error:
_predictForegroundFromPixelBuffer:timeStamp:
_predictedLinkedEntityUUIDs
_prediction
_preferenceCache
_preferenceCacheFlushTimer
_preferenceLoggedValues
_preferenceOverridesInternal
_prepareForInputVideoFormat:audioFormat:
_prepareForTimelapseOutputVideoFormat:
_presentationTime
_presentationTimeStamp
_prevFrameResult
_previousPersons
_probability
_produceResult:withArguments:
_progressBlock
_queue
_records
_redactFrames
_referenceInterval
_references
_refreshBeforeDate:completionHandler:
_regionOfInterest
_registerLock
_removeExcessFaceCrops
_removeTemporaryFiles
_removeTrimDurationAttachmentsFromAudioSampleBuffer:
_removedPersonFaceCrops
_reorderBufferSize
_reportBuffer
_requestPreSignedURLWithClipUUID:completionHandler:
_reset
_resetPreviousFrameResult:expirationPTS:regionOfInterest:
_resetReferences
_resetStaleTorsoStateForHome:torsoToFaceCropMap:
_resizedSampleBuffers
_resourceUsageMonitor
_retimerDidRetimeSampleBuffer
_roll
_rollsFeatureValueNames
_runNeuralNetworkOnPixelBuffer:offsetsZero:offsetsOne:scores:yaws:rolls:error:
_runningMean
_runningStd
_sampleBufferDelay
_samples
_saveAnalyzerResultsToDisk
_saveFragmentDataToDisk:diskBufferSize:
_sbuf
_scalerModel
_score
_scoresFeatureValueNames
_secondIndex
_separableSegment
_sequenceNumbers
_service
_serviceResult
_services
_session
_sessionEntities
_sessionEntityAssignment
_sessionEntityManager
_sessionEntityUUID
_sessionUUIDToPreviousFaceprints
_sessionUUIDToPreviousTorsoprints
_sessions
_setAssignment:greaterThanType:value:boundingBox:scale:
_setFloat64Property:propertyValue:
_setProperty:propertyValue:
_setSInt32Property:propertyValue:
_settings
_setup
_sharingFaceClassificationsEnabled
_shouldSkipLogState
_significantActivityFcosDetector
_signpostIdentifier
_simulatedEventForEventClass:
_size
_sourceURL
_sourceUUID
_stageFive_addPersons:clusterMapping:faceprints:
_stageFour_clusterFaceprints:
_stageOne_fetchFaceCrops
_stageSix_associateFaceCropsWithClusterMapping:faceprints:
_stageThree_generateFaceprintsForFaceCrops:existingFaceprints:
_stageTwo_fetchFaceprints:
_startDate
_startTime
_startWritingAtStartTime:
_state
_stationaryBlobIndex
_stationaryObjects
_stationaryTracks:timeStamp:
_store
_stripAudioTrackAndFacesFromAsset:completionHandler:
_submitClipWithCameraProfileUUID:clipUUID:completionHandler:
_summary
_supportsFaceClassification
_synthesizeMotionDetectionWithTarget:
_systemResourceUsageLevel
_targetDate
_targetEventClassRanks
_targetEventsSetFromEventTriggers:enableFaceClassification:enableTorsoRecognition:
_temporalEventFilter
_temporaryFileURLWithUUID:extension:error:
_temporaryFileURLs
_text
_thermalLevel
_thermalLevelNotificationToken
_thermalPressureLevel
_thresholdDefault
_thresholdWithLabels
_thumbnailBuffer
_thumbnailHeight
_thumbnailInterval
_thumbnails
_tick
_time
_timeInterval
_timeRange
_timeSinceAnalyzerStarted
_timeSinceLastFragmentWasReceived
_timeStamp
_timelapseAssetWriter
_timelapseEncoder
_timelapseInterval
_timelapseOutputVideoFormat
_timelapsePreferredFragmentDuration
_timeline
_token
_torso
_torsoAnnotation
_torsoAnnotations
_torsoCentroid
_torsoClassifier
_torsoModelVersion
_torsoModelsByHome
_torsoRecognition
_torsoToFaceCropByHome
_torsoprint
_torsoprintUUIDs
_torsoprinter
_torsoprints
_totalDuration
_trackAnalysisPTS
_trackIndex
_trackInterval
_trackOutputs
_trackSamples
_tracksFromTarget:reference:background:dynamicConfiguration:motionDetections:
_transaction
_transcode
_transcodeCodecType
_truePositive
_truePositiveKeys
_truth
_type
_unassociatedFaceCrops
_unknownFacesSavedCounts
_updateAnalyzer:withIndex:
_updateBackgroundFromPixelBuffer:timeStamp:
_updateCurrentTracks:inactiveTracks:blobs:timeStamp:
_updateRunningMean:runningSquaredMean:fromInputBuffer:decay:
_updateSettings:
_updateThermalLevel
_updateThermalPressureLevel
_uploadPayloadData:uploadURL:completionHandler:
_url
_usageLevel
_usageMonitor
_userDefinedPersonLinksByHome
_userInfo
_value
_valueForNumber:
_version
_videoDuration
_videoFormat
_videoFormatDescription
_videoInput
_videoTrackTimeRange
_visionPersonsModel
_visualizeFrames:targetEvents:backgroundEvents:regionOfInterest:
_visualizeTargetEvents:backgroundEvents:regionOfInterest:targetTimeStamp:
_visualizeTargetsThatExpiredBefore:
_watchdogTimer
_weakDecoder
_weights
_weightsName
_weightsTensorData
_windowSize
_workQueue
_yaw
_yawsFeatureValueNames
absoluteFaceBoxFromPhotosFaceCropImageData:
absoluteString
absoluteURL
accessories
accessory
activityForScheduling
activityZoneType
activityZones
activityZonesFromString:isInclusion:
add:
addEntriesFromDictionary:
addExecutionBlock:
addFaceCrops:completion:
addFaceObservations:toFaceDescriptorBuffer:error:
addFaceObservations:toPersonWithUniqueIdentifier:error:
addFaceprints:
addFaceprints:completion:
addIndex:
addInput:
addLinkedEntityUUIDs:
addMutableTrackWithMediaType:preferredTrackID:
addNumber:
addObject:
addObjectsFromArray:
addOperation:
addOrUpdateFaceCrops:completion:
addOrUpdateFaceprints:completion:
addOrUpdatePersons:completion:
addOutput:
addPerson:completion:
addPersonFaceCrops:completion:
addPersons:completion:
addPointer:
addPreferenceOverrideFromDictionary:
addValue:
adjustBrightness
allAtCurrentVersion
allEvents
allObjects
allPersons
allPersonsAndFaceCrops
allValues
allocWithZone:
allowRecoveryFromInsufficientAudioTrim
allowReducedConfiguration
allowedClasses
allowsKeyedCoding
analysisFPS
analysisQOS
analysisStateManager
analysisTimeStamps
analyticsTimer
analyzeBackgroundFrame:packageEvents:newBackgroundEvents:regionOfInterest:
analyzeFragment:configuration:
analyzeFrame:regionOfInterest:
analyzePixelBuffer:regionOfInterest:error:
analyzePixelBuffer:timeStamp:
analyzer:didAnalyzeFragmentWithResult:
analyzer:didAnalyzeFrameWithResult:
analyzer:didCreateTimelapseFragment:
analyzer:didFailWithError:
analyzer:didProduceAnalysisStateUpdate:
analyzer:didProduceResult:
analyzerConfiguration
analyzerConfigurations
analyzerDidAnalyzeFragmentWithResult
analyzerDidAnalyzeFrameWithResult
analyzerDidCreateTimelapseFragment
analyzerDidFailWithError
analyzerDidProduceAnalysisStateUpdate
analyzerEvents
analyzerStates
analyzerWithConfiguration:block:
analyzerWithConfiguration:identifier:error:
analyzerWithConfiguration:identifier:remote:error:
analyzerWithOptions:error:
analyzers
annotationScores
anyObject
appendArray:
appendBlob:
appendBytes:length:
appendData:
appendEncryptionModeWithPath:
appendFaceCrop:imageBorder:imageColor:outlineBorder:outlineColor:
appendFloats:count:
appendFormat:
appendFragmentResult:
appendFragmentResult:forKey:source:redactFrames:
appendFragmentResult:redactFrames:
appendFragmentResultsFromReport:
appendFrame:text:
appendFrame:text:boxes:imageBorder:imageColor:outlineBorder:outlineColor:
appendFrameResult:frameTruth:description:
appendHeaderWithTitle:textColor:backgroundColor:
appendIFrameOnly
appendInitializationSegmentWithPath:
appendJPEG:imageBorder:imageColor:outlineBorder:outlineColor:
appendSampleBuffer:
appendSeparableSegmentWithPath:duration:
appendSeparableSegmentWithPath:duration:byteRange:
appendString:
appendText:
applyActivityZoneFilteringOnSourcePoint:destinationPoint:frameSize:activityZones:
applyEventTypeAndCheckIfSubBoundingIsStatic:eventClass:confidence:
applyFilterWithFrameResult:motionDetection:
applyPadding:withOriginalSize:padding:
applyToImage:withProbability:
applyWithFrameResult:
approximationInterval
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObject:
arrayWithObjects:count:
assetData
assetReaderTrackOutputWithTrack:outputSettings:
assetReaderWithAsset:error:
assetWithURL:
assetWriter
assetWriter:didFailWithError:
assetWriter:didOutputInitializationSegment:
assetWriter:didOutputSegmentData:segmentType:
assetWriter:didOutputSegmentData:segmentType:segmentReport:
assetWriter:didOutputSeparableSegment:segmentReport:
assetWriterDidFailWithError
assetWriterDidOutputInitializationSegment
assetWriterDidOutputSeparableSegment
assetWriterInputWithMediaType:outputSettings:sourceFormatHint:
assignBackgroundEvents:timeStamp:
assignForegroundEvents:timeStamp:
assignSessionEntitiesToPersonEvents:regionOfInterest:timeStamp:homeUUID:
assignSessionEntityToFaceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:availableSessionEntityUUIDs:sessionEntityAssignment:
assignment
associateFaceCropsWithUUIDs:toPersonWithUUID:forSource:completion:
attributeDescriptions
attributeForKey:
attributes
attributesOfItemAtPath:error:
audioFormat
audioFormatDescription
audioInput
audioTrackTimeRange
augmentWithOptions:
authenticationMethod
autorelease
averageAnalysisTime
averageBitRate
averagePrecisionForMinPrecision:comparator:
averagePrecisionWithClassificationTruth:minPrecision:
averagePrecisionWithDetectionTruth:minPrecision:iouThreshold:videoMetric:
averageTime
background
backgroundChangeInterval
backgroundChangeResetInterval
backgroundChangeTimeStamp
backgroundEstimator
backgroundEvents
backgroundExpireInterval
backgroundTimeStamp
base64Encoded
base64EncodedDataWithOptions:
baseDecodeTimeStamp
begin
beginDate
biases
blobArea
blobAtTimeStamp:
blobID
blobs
blurFacesFromAssetURL:outputURL:duration:analysisFPS:windowSize:faceDetected:
boolPreferenceForKey:defaultValue:
boolValue
boundingBox
boundingBoxForTracker
boxForRegionOfInterest:
boxesForEvent:isTruth:
boxesName
bucketForValue:usingBuckets:
buffer
buffer:willHandleSampleBuffer:
bufferSize
bufferWillFlush:
bufferWillHandleSampleBuffer
buildEmptyTaskFromOptions:error:
buildEquivalencyMapForPersonsModels:userDefinedPersonLinks:error:
buildFaceMisclassificationTaskFromOptions:error:
buildHomePersonClusteringTaskFromOptions:error:
buildPersonsModelForHomeUUID:sourceUUID:externalLibrary:faceObservationsByPerson:error:
buildPersonsModelsSummaryTaskFromOptions:error:
buildRemovePersonsModelTaskFromOptions:error:
buildSubmitFeedbackTaskFromOptions:error:
buildUpdatePersonsModelTaskFromOptions:error:
buildUpdateTorsoModelTaskFromOptions:error:
bundleWithIdentifier:
bytes
cachePolicy
calculateMotionDetection:score:srcFeatureCVPoints:dstFeatreCVPoints:activityZones:operationMode:srcPyramid:frameSize:brightnessChange:
callback
camera
cameraMetadata
cameraProfileUUID
cameraProfileWithUUID:
cameraProfiles
cameraVideoFrameAnalyzer
canAddInput:
canAddOutput:
canFragmentData:
cancel
cancelReading
cancelRequest:
cancelTask:
cancelWithError:
cancelled
candidate
capacity
caseInsensitiveCompare:
centermostFaceprintInCluster:faceObservations:
characterAtIndex:
characterSetWithCharactersInString:
chartDataWithBaseline:comparator:
chartDataWithClassificationTruth:isBaseline:
chartDataWithDetectionTruth:isBaseline:iouThreshold:videoMetric:
chartSpecWithRange:colors:labels:
check
checkAndSaveCrashReportWithData:
checkIfObjectIsStaticWithBoundingBox:motionDetection:eventClass:
class
classHierarchyMap
classMap
classMotionScoreMap
classesName
classification
classificationThresholdKnown
classificationThresholdUnknown
classifyFaceEvent:pixelBuffer:fastMode:homeUUID:error:
clipManager
clipMetadata
clipUUID
close
closeFile
clusterSessionEntityToFaceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:availableSessionEntityUUIDs:sessionEntityAssignment:
clusterer
clusteringDuration
code
color
colorSpace
combineFrameResults:withResults:
commandBuffer
compare:
compareWithClassificationTruth:eventClass:confidenceThreshold:
compareWithDetectionTruth:eventClass:confidenceThreshold:iouThreshold:videoMetric:
compareWithTrackingTruth:eventClass:confidenceThreshold:ioaThreshold:
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
composition
compressedFrameWithScale:quality:error:
condition
confidence
configuration
conformsToProtocol:
container
containsEvent:withInsetPercentage:
containsIndex:
containsValueForKey:
containsVectorWithSource:destination:
contentInformationRequest
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextWithOptions:
convertObjectDetections:cropRect:originalImageSize:
convertToClusters:
copy
copyNextSampleBuffer
copyNextSampleBufferWithTrackIndexOutput:
copyWithFaceEvent:torso:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createBoxesTensorWithError:
createClassesTensorWithError:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createFacePixelBufferForFaceDetection:pixelBuffer:roll:error:
createFacePixelBufferForFaceEvent:pixelBuffer:roll:error:
createFacePixelBufferFromFaceCrop:error:
createFaceprintForFacePixelBuffer:fastMode:error:
createImageTensorWithError:
createJPEGDataFromPixelBuffer:scale:encodeQuality:error:
createNSErrorWithStatus:andMessage:
createNSExceptionWithStatus:andMessage:
createPackageEventAtTimeStamp:
createPixelBufferFromImageData:error:
createPixelBufferFromJPEGData:error:
createPixelBufferFromJPEGDataProvider:error:
createPixelBufferFromJPEGPath:error:
createPixelBufferWithSize:pixelFormat:useIOSurface:
createRegionOfInterestPixelBufferWithError:
createSessionEntityWithUUID:faceRecognition:torsoRecognition:predictedLinkedEntityUUIDs:sessionEntityAssignment:
createTorsoPixelBufferForTorsoEvent:pixelBuffer:error:
createWeightsTensorWithError:
createdAtCurrentVersion
credentialForTrust:
cropPixelBuffer:crop:error:
croppedJpegDataFromFaceCrop:
currentDTS
currentFragmentStartTime
currentHorizontalTilt
currentModelUUID
currentPTS
currentTorsoRequestRevision
currentVerticalTilt
data
dataPointAtIndex:error:
dataPointer
dataRateLimit
dataRepresentation
dataRequest
dataScalerInputName
dataScalerOutputName
dataSource
dataTaskWithURL:completionHandler:
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
dataWithContentsOfFile:options:error:
dataWithContentsOfURL:
dataWithContentsOfURL:options:error:
dataWithData:
dataWithJSONObject:options:error:
date
dateAtTime:
dateCreated
dateOfOccurrence
dateWithTimeIntervalSinceNow:
debugDescription
decimalNumberByRoundingAccordingToBehavior:
decimalNumberHandlerWithRoundingMode:scale:raiseOnExactness:raiseOnOverflow:raiseOnUnderflow:raiseOnDivideByZero:
decimalNumberWithDecimal:
decimalNumberWithString:
decimalValue
decodeBoolForKey:
decodeCMTimeForKey:
decodeCMTimeRangeForKey:
decodeDoubleForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeMode
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodeRectForKey:
decoder:didDecodeSampleBuffer:
decoder:didFailWithError:
decoderDidDecodeSampleBuffer
decoderDidFailWithError
defaultAestheticQualityDataScalerPath
defaultAestheticQualityModelPath
defaultAssetPath
defaultCenter
defaultConfidenceThreshold:confidenceLevel:
defaultConfidenceThresholdsFeedback
defaultConfidenceThresholdsMedium
defaultFormatter
defaultManager
defaultNMSConfiguration
defaultPrivateConfiguration
defaultRecognizabilityDataScalerPath
defaultSessionConfiguration
delay
delegate
delegateQueue
desLabelIndexForEventClass:
description
descriptorData
detectFacesInImageData:error:
detectWithGlobalMotionScore:referencePixelBuffer:targetPixelBuffer:activityZones:detectorMode:
detections
deviceInformation
dictionary
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
didEncryptPackageResult
didPrivatizePackageResult
didUpdateHomes
digitalZoom
distance
distantPast
doImpurePersonCleanup
doInferenceOnData:error:
doTrainingOnData:forNumberOfEpochs:withCallback:error:
doubleForKey:
doubleValue
draw:
drawBoundingBox:lineWidth:text:color:
drawPolygonWithNormalizedPoints:
drawRect:width:color:
drawText:at:color:
drawTextHeaderBar:
dropSamplesUntilSync
dropTrimDurationAttachments
dumpFFDataToCacheForPerson:personFaceCrops:
duration
dynamicConfiguration
dynamicConfigurationBuffer
dynamicConfigurationForTime:
earlierDate:
enableTemporalEventFiltering
encode
encodeBool:forKey:
encodeCMTime:forKey:
encodeCMTimeRange:forKey:
encodeDouble:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInt:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeRect:forKey:
encodeWithCoder:
encoder:didEncodeSampleBuffer:
encoder:didFailWithError:
encoderDidEncodeSampleBuffer
encoderDidFailWithError
encoderQueue
endedAtTime:
entropy:numPixels:
entropyOfLaplacianForBGRAPixelBuffer:
entropyOfSaturationForBGRAPixelBuffer:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
enumeratorAtPath:
equivalencyCellForPerson:
equivalencyCellForPerson:homeUUID:error:
equivalencyTablesByHome
error
errorWithDomain:code:userInfo:
event
eventClass
eventClassForShortName:
eventClasses
eventClassesArray
eventConfidenceThresholdsHigh
eventTriggers
events
eventsForFragment
eventsForTimeStamp:
eventsWithContentsOfFile:
eventsWithFaceEventsFromTorsoEventsFromEvents:homeUUID:
exceptionWithName:reason:userInfo:
exchangeObjectAtIndex:withObjectAtIndex:
existingAtCurrentVersion
existingAtOtherVersions
existingFaceCropUUIDs
existingPersonFaceCropUUIDs
existingPersonUUIDs
expectedAttributeForKey:
expectedDuration
expectedFrameRate
expirationInterval
exportAsynchronouslyWithCompletionHandler:
extent
external
externalPersonManagers
extractObjectsInTimeRange:
face
faceAestheticQualityFilter
faceAttributes
faceBoundingBoxFromPhotosFaceCropData:
faceCentroid
faceClassification
faceClassificationEnabled
faceClassifications
faceClassifier
faceCount
faceCountForPersonWithUniqueIdentifier:
faceCountsByPerson
faceCrop
faceCropDimensionsFromFaceCrop:error:
faceCropFromPhotosFaceCropImageData:
faceCropFromTorsoModelForHomeUUID:personUUID:sourceUUID:
faceCropUUID
faceCropUUIDs
faceCrops
faceCropsForPerson:
faceDistanceFromDescriptor:toDescriptor:
faceId
faceObservationFromFaceprint:
faceObservationFromTorsoprint:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
faceObservationWithRequestRevision:unalignedBoundingBox:alignedBoundingBox:
faceObservationsForPersonWithUniqueIdentifier:error:
faceObservationsFromFaceprintsForClustering:
faceQualityScore
faceRecognizabilityFilter
faceVIPThresholdForTorsoAnnotation
facemaskCategory
faceprint
faceprintDefaultRevision
faceprintUUIDs
faceprinter
faceprintingDuration
faceprints
facesAreSamePersonFromSet:andSet:
facesAreSamePersonFromSet:andSet:distanceThreshold:percentMatchingThreshold:
falseNegative
falseNegativeKeys
falsePositive
falsePositiveKeys
familiarity
featureNames
featureValueForName:
featureValueWithMultiArray:
featureValueWithPixelBuffer:
feedbackRequestURLForClipWithUUID:
feedbackServiceHost
feedbackServiceURL
fetchAllFaceprintsWithCompletion:
fetchAllPersonFaceCropsWithCompletion:
fetchAllPersonsWithCompletion:
fetchAllUnassociatedFaceCropsWithCompletion:
fetchClipWithUUID:completion:
fetchFaceCropsForPerson:
fetchFaceCropsForPersonsWithUUIDs:completion:
fetchFaceprintsForFaceCropsWithUUIDs:completion:
fetchOrCreateFaceprintsForCrops:person:
fetchPersons
fetchPersonsWithUUIDs:completion:
fetchSettingsWithCompletion:
ffArchiveRootURLWithError:
ffData
fileExistsAtPath:
fileHandleForReadingFromURL:error:
fileHandleForWritingAtPath:
fileSize
fileURLWithPath:
fileURLWithPath:relativeToURL:
fileURLWithPathComponents:
fillRatio
fillWithFloat:
filterEvents:withActivityZones:motionDetection:insetPercentageInclusion:insetPercentageExclusion:
filterWithName:withInputParameters:
finalizeFragmentResult:homePersonManager:analysisStateManager:
finish
finishLoading
finishWithCompletionHandler:
firstIndex
firstMotionDetectionInArray:withMode:
firstObject
firstVideoSampleByteRange
firstVideoSampleInformation
flattedTrainingResult
floatArrayByAdding:
floatArrayByScaling:
floatArrayBySubtracting:
floatValue
floats
flush
flushAsync
flushSegment
flushTorsoprints
flushWithCompletionHandler:
flushWithNextSamplePTS:
foregroundTimeStamp
fragment
fragmentData:handler:
fragmentSequenceNumber
fragments
frame
frameAnalyzer
frameAnalyzer:didAnalyzeFrame:
frameAnalyzer:didProduceAnalysisStateUpdate:
frameAnalyzerDidAnalyzeFrame
frameAnalyzerDidProduceAnalysisStateUpdate
frameAnalyzerFrameResultBuffer
frameReorderingRequired
frameResultIndices
frameResults
frameSampler
frameSampler:didDropFrame:
frameSampler:didSampleFrame:
frameSamplerDidDropFrame
frameSamplerDidSampleFrame
frameSelector
frameSelector:didSelectFrame:reference:
frameSelector:didSkipFrame:
frameSelector:prepareFrame:
frameSelectorDidSelectFrame
frameSelectorDidSkipFrame
frameSelectorPrepareFrame
frameThumbnailSampler
frameTimelapseSampler
frameTracker
frameTracker:didTrackFrame:background:motionDetections:tracks:
frameTrackerDidTrackFrame
fromTorsoClassification
generateAndSubmitStats:filteredEvents:motionDetection:activityZones:
generateFaceprintForFaceCrop:error:
generateVideoFramesForTimes:completionHandler:
getAnalyzerEvents:eventTriggers:enableFaceClassification:enableTorsoRecognition:
getBlobIDAtIndex:
getClustersWithFaces:error:
getCurrentSystemResourceUsage
getModelStoragePathForHome:error:
getModelStoragePathForModel:error:
getNextTaskID
getPackageEvents:foregroundEvents:newBackgroundEvents:backgroundTimeStamp:
getParameterOfType:forLayerNamed:error:
getParametersFromLayers:fromTask:error:
getResourceValue:forKey:error:
getRootModelStoragePathWithError:
getStoragePath
getTorsoModelStoragePathForHomeUUID:error:
getTorsoSubdirectoryPathForHomeUUID:error:
getTorsoToFaceCropStoragePathForHomeUUID:error:
getTorsoprinterVersionStoragePathForHomeUUID:error:
getUUIDBytes:
getUserDefinedPersonLinksStoragePathForHomeUUID:error:
globalSession
greedyMatchBetweenPredictionEvents:truthEvents:falsePositiveIndices:falseNegativeIndices:eventClass:regionOfInterest:confidenceThreshold:scoreThreshold:scoreFunction:
handleAssetData:withOptions:completionHandler:
handleAudioSampleBuffer:
handleBlock:
handleCleanupForPerson:
handleFrameAnalyzerResult:
handleMessageWithOptions:completionHandler:
handleMisclassifiedPersonForFaceCrop:
handleMotionDetection:inFrame:
handleNewFaceEvents:
handleRemoteStateUpdate:
handleRemoteStateUpdate:completionHandler:
handleRemovedFaceCropWithUUID:
handleRemovedPersonWithUUID:
handleSampleBuffer:
handleSampleBuffer:background:motionDetections:tracks:
handleSampleBuffer:errorHandler:
handleSampleBuffer:reference:
handleUpdatedFaceprint:
handleUpdatedPerson:
handleUpdatedPersonFaceCrop:
handleUpdatedSettings:
handleUpdatedUnassociatedFaceCrop:
handleVideoSampleBuffer:
hasBegun
hasEstimatedBoundingBox
hasFailed
hasNewBackground
hasPreferenceForKey:
hasPrefix:
hasSuffix:
hash
highConfidenceThresholds
highWaterMark
hmfErrorWithCode:
hmf_UUIDWithNamespace:data:
hmf_addObject:
hmf_firstObjectWithUUID:
hmf_isEmpty
hmf_isEqualToUUID:
hmf_objectsPassingTest:
hmf_removeFirstObject
hmf_zeroUUID
hmiErrorWithCode:
hmiErrorWithCode:description:
hmiErrorWithCode:description:underlyingError:
hmiErrorWithCode:underlyingError:
hmiPrivateErrorWithCode:
hmiPrivateErrorWithCode:description:
hmiPrivateErrorWithCode:description:underlyingError:
hmiPrivateErrorWithCode:underlyingError:
homeForHMPersonManagerUUID:
homeKitClient
homeKitOperationQueue
homeManager
homeManager:didAddHome:
homeManager:didReceiveAddAccessoryRequest:
homeManager:didRemoveHome:
homeManager:didUpdateAuthorizationStatus:
homeManagerDidUpdateHomes:
homeManagerDidUpdatePrimaryHome:
homeMetadata
homePersonManager
homePersonManagerForHomeUUID:
homePersonManagersForCurrentDevice
homePersons
homePersonsAndFaceCrops
homePersonsModelForHomeWithUUID:
homeToExternalEquivalencies
homeUUID
homeWithCameraProfileUUID:
homes
host
identifier
ignoreThermalAndSystemResourceUsageLevel
imageCreationOptions
imageData
imageMirroring
imageName
imageRotation
imageSize
imageWithData:
importingFromPhotoLibraryEnabled
imposeMinSizeFor:withOriginalSize:minCrop:
inactiveTracks
inclusion
indexOfObject:inSortedRange:options:usingComparator:
indexSet
indexSetWithIndexesInRange:
indexesOfObjectsPassingTest:
inferenceInputs:inferenceOutputs:trainingInputs:trainingOutputs:learningRate:error:
infoDictionary
init
initPrivate
initToFileAtPath:append:
initWith
initWithActivityZones:motionDetections:
initWithArray
initWithArray:
initWithAsset:
initWithAsset:presetName:
initWithAsset:readVideoTrack:readAudioTrack:
initWithBlob:trackIndex:
initWithBoundingBox:size:motionVectors:motionScore:motionMode:
initWithBoundingBox:text:color:opacity:value:
initWithBoundingBox:timeStamp:
initWithBoundingBox:timeStamp:blobArea:blobID:
initWithBundleIdentifier:
initWithCVPixelBuffer:
initWithCVPixelBuffer:imageParameters:error:
initWithCVPixelBuffer:options:
initWithCVPixelBuffer:options:session:
initWithCachePolicy:
initWithClipManager:clip:
initWithClipMetadata:cameraMetadata:homeMetadata:
initWithCode:analysisFPS:message:
initWithCoder:
initWithConfidence:boundingBox:face:
initWithConfidence:boundingBox:face:torso:
initWithConfidence:boundingBox:faceRecognition:
initWithConfidence:boundingBox:motionScore:
initWithConfidence:boundingBox:roll:torsoRecognition:
initWithConfidence:boundingBox:userInfo:
initWithConfidence:boundingBox:yaw:roll:faceRecognition:torsoAnnotation:userInfo:
initWithConfidence:boundingBox:yaw:roll:faceRecognition:userInfo:
initWithConfidenceThresholds:nmsConfiguration:error:
initWithConfiguration:
initWithConfiguration:dynamicConfiguration:identifier:monitored:analysisFPS:timeSinceAnalyzerStarted:timeSinceLastFragmentWasReceived:bufferFillRatio:bufferSize:delay:currentPTS:numDecodedSamples:numDidAnalyzeFrames:numDidAnalyzeFragments:numDidAnalyzePackages:numDidCreateTimelapseFragments:averageAnalysisTime:encode:encoder:
initWithConfiguration:identifier:
initWithContentType:
initWithContentsOfFile:
initWithData:
initWithData:elementCount:elementType:lengthInBytes:confidence:requestRevision:
initWithData:encoding:
initWithData:error:
initWithData:options:session:
initWithData:timeRange:
initWithData:type:shape:strides:
initWithDataSource:
initWithDataSource:faceCrop:
initWithDataSource:faceCropUUIDs:
initWithDataSource:faceCropUUIDs:personUUID:source:
initWithDataSource:faceprint:
initWithDataSource:faceprintUUIDs:
initWithDataSource:faceprints:
initWithDataSource:person:
initWithDataTensor:
initWithDictionary
initWithDictionary:
initWithDictionary:forType:
initWithDictionary:regionOfInterest:
initWithDimensions:codecType:useHardwareAcceleration:error:
initWithError:
initWithEvent:time:
initWithEventClass:records:UUID:
initWithExistingAtCurrentVersion:createdAtCurrentVersion:existingAtOtherVersions:
initWithFaceCrop:faceprint:classifications:
initWithFaceCrop:faceprint:classifications:predictedLinkedEntityUUIDs:
initWithFaceCrop:faceprint:classifications:predictedLinkedEntityUUIDs:faceQualityScore:sessionEntityAssignment:sessionEntityUUID:
initWithFaceEvent:
initWithFaceEvent:torso:
initWithFaceRecognition:torsoprints:
initWithFaceRecognition:torsoprints:torsoModelVersion:
initWithFaceThreshold:singleLinkThreshold:percentConnectionsThreshold:error:
initWithFaceprint:
initWithFeedbackSession:cameraProfileUUID:clipUUID:
initWithFirstIndex:secondIndex:score:
initWithFloats:count:
initWithFragment:events:frameResults:thumbnails:configuration:outcome:
initWithFragments:
initWithFrame:events:
initWithFrame:events:annotationScores:detections:regionOfInterest:faceClassifications:
initWithFrame:events:backgroundEvents:backgroundTimeStamp:regionOfInterest:motionDetections:
initWithFrame:events:regionOfInterest:
initWithFrame:regionOfInterest:analyzerEvents:
initWithFrameRate:
initWithFrameReordering:
initWithHMHomePersonManager:
initWithHMPhotosPersonManager:
initWithHomeMangerConfiguration:
initWithHomeUUID:
initWithHomeUUID:dataSource:
initWithHomeUUID:sourceUUID:error:
initWithIdentifier:name:manufacturer:model:
initWithIdentifier:name:manufacturer:model:firmwareVersion:
initWithImageData:regionOfInterest:detections:
initWithInitializationSegment:separableSegment:
initWithInitializationSegment:separableSegment:timeRange:
initWithInitializationSegment:separableSegment:timeRange:firstVideoSampleByteRange:
initWithInitializationSegment:separableSegment:timeRange:sequenceNumbers:
initWithInitializationSegment:separableSegment:timeRange:sequenceNumbers:firstVideoSampleByteRange:
initWithInput:inputName:
initWithInterval:
initWithJPEGData:presentationTime:frameId:fragmentSequenceNumber:size:
initWithJPEGData:size:presentationTimeStamp:
initWithJSONObject:
initWithJSONPath:error:
initWithKey:ascending:
initWithKey:classificationScore:
initWithKey:detectionScores:frameResultIndex:
initWithKey:options:domain:defaultValue:
initWithKey:trackingScores:frameResultIndices:
initWithLabelIndex:confidence:boundingBox:yaw:roll:
initWithLabelIndex:confidence:unclampedBoundingBox:yaw:roll:
initWithLayerParameters:losses:preTrainingLoss:postTrainingLoss:
initWithLocaleIdentifier:
initWithMaxCapacity:
initWithMediaType:outputSettings:sourceFormatHint:
initWithMediumConfidenceThresholds:highConfidenceThresholds:analyzerConfiguration:error:
initWithModelPath:dataScalerPath:error:
initWithModelSummaries:homeToExternalEquivalencies:externalToExternalEquivalencies:
initWithModelURL:
initWithName:
initWithName:deferred:
initWithName:reason:userInfo:
initWithName:value:
initWithName:value:options:formatter:
initWithName:weights:biases:
initWithNewPersonEvent:timeStamp:
initWithNoCaching
initWithNotificationName:andQueue:andCallback:
initWithOrigin:motion:
initWithPackageResult:didPrivatizePackageResult:didEncryptPackageResult:maxNorm:l2Norm:
initWithPersonUUID:sourceUUID:
initWithPersonUUID:sourceUUID:confidence:
initWithPersonUUID:sourceUUID:confidence:fromTorsoClassification:familiarity:
initWithPersonUUID:sourceUUID:sessionEntityUUID:confidence:familiarity:
initWithPersonsModel:homeUUID:sourceUUID:externalLibrary:
initWithPersonsModels:userDefinedPersonLinks:error:
initWithPixelBuffer:
initWithPixelBuffer:fontSize:
initWithPixelBuffer:inputName:
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
initWithPixelBuffer:presentationTimeStamp:
initWithPlaylistString:
initWithPoint:
initWithPoints:isInclusion:
initWithSampleBuffer:
initWithSampleBuffer:score:motionDetections:tracks:
initWithSamples:imageName:boxesName:weightsName:classesName:
initWithService:
initWithShape:dataType:error:
initWithSourceUUID:externalLibrary:faceCountsByPerson:
initWithSourceUUID:homeUUID:external:
initWithSourceUUID:personUUID:confidence:linkedEntityUUID:
initWithString:attributes:
initWithTargetDuration:
initWithTaskID:cameraProfileUUID:clipUUID:
initWithTaskID:dataSource:faceCrop:
initWithTaskID:duration:
initWithTaskID:homeUUID:
initWithTaskID:homeUUID:dataSource:sourceUUID:personsModelManager:doImpurePersonCleanup:error:
initWithTaskID:homeUUID:sourceUUID:
initWithTaskID:homeUUID:sourceUUID:dataSource:externalLibrary:removeExcessFaceCrops:
initWithTaskID:homeUUID:timeout:
initWithTaskID:homeUUID:torsoAnnotations:
initWithTaskID:timeout:
initWithThresholdWithLabels:metricWithLabels:thresholdDefault:metricDefault:
initWithTime:date:
initWithTimeInterval:options:
initWithTimeout:
initWithTitle:outputPath:
initWithTorsoAnnotations:
initWithTorsoAnnotationsArray:
initWithTorsoEvent:
initWithTorsoprint:
initWithTorsoprint:classification:predictedLinkedEntityUUIDs:sessionEntityAssignment:sessionEntityUUID:
initWithTrainingModelDefinition:forPlatform:error:
initWithTrainingNetworkPath:data:error:
initWithTrainingNetworkPath:inferenceInputs:inferenceOutputs:trainingInputs:trainingOutputs:trainingControlVariableName:withInitializer:error:
initWithTruePositiveKeys:falseNegativeKeys:falsePositiveKeys:groupByKey:
initWithURL:
initWithURL:options:
initWithUUID:
initWithUUID:data:
initWithUUID:data:lowQuality:unrecognizable:
initWithUUID:data:modelUUID:faceCropUUID:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:personUUID:
initWithUUID:dataRepresentation:dateCreated:faceBoundingBox:personUUID:source:
initWithUUID:homeUUID:
initWithUUID:name:
initWithUUID:name:personLinks:
initWithUUID:name:personsModelIdentifier:faceBoundingBox:
initWithUUID:sourceUUID:faceBoundingBox:
initWithUUID:sourceUUID:sessionEntityUUID:faceBoundingBox:facecrop:faceprint:confidence:
initWithUUID:sourceUUID:sessionEntityUUID:faceCrop:faceprint:confidence:familiarity:
initWithUUID:sourceUUID:sessionEntityUUID:faceCrop:faceprint:confidence:fromTorsoClassification:familiarity:
initWithUUIDPairString:
initWithUUIDString:
initWithValue:
initWithValue:count:
initWithValue:levelThresholds:
initWithValue:time:
initWithVideoFormat:audioFormat:
initWithVideoFormat:audioFormat:initialFragmentSequenceNumber:preferredOutputSegmentInterval:
initWithVideoFragment:
initWithWeakObject:
initWithWindowSize:
initializationSegment
input
inputAudioFormat
inputFeatureValueName
inputName
inputQueue
inputVideoFormat
insertObject:atIndex:
insertTimeRange:ofTrack:atTime:error:
intValue
integerValue
internalAnalyzers
intersectsSet:
isAudioAccessory
isBoundingBoxEstimated
isCancelled
isClassified
isCombinableWithFragment:
isCurrentDevicePrimaryResident
isDate:inSameDayAsDate:
isEqual:
isEqualToData:
isEqualToDate:
isEqualToDictionary:
isEqualToNumber:
isEqualToSet:
isEqualToString:
isExpiredAtTimeStamp:
isExternalLibrary
isFaceClassificationEnabled
isFull
isIdentityPureWithFaceprints:person:
isIdle
isImportingFromPhotoLibraryEnabled
isInclusion
isInitializationSegment:combinableWithInitializationSegment:
isInternalInstall
isKindOfClass:
isLostAtTimeStamp:
isMemberOfClass:
isPermitted
isPrimary
isProductTypeB238
isProductTypeB520
isProductTypeB620
isProductTypeJ105
isProductTypeJ255
isProductTypeJ305
isProductTypeJ42
isReadable
isReadyForMoreMediaData
isSentinelFaceprint
isSharingFaceClassificationsEnabled
isSkipped
isStationaryAtTimeStamp:
isSubsetOfSet:
isSuccess
isValidFaceCrop:
jpegData
jsonReperesentaionOfDetectedObject:motionDetection:eventClass:
kick
l2Norm
label
labelIndex
labelIndexForEventClass:
lastAudioPresentationTimeStamp
lastBlob
lastFragmentReceivedDate
lastKnownTimeStamp
lastObject
lastPathComponent
lastSampleBufferDTS
lastSampleBufferPTS
lastVideoPresentationTimeStamp
lazyPayloads
length
lengthInBytes
level
lines
linkedEntityUUID
linkedEntityUUIDs
linkedPredictionsForPrediction:homeUUID:error:
loadModelAtPath:error:
loadModelsWithError:
loadPersonsModelFromURL:externalLibrary:homeUUID:error:
loadTorsoToFaceCrop:error:
loadTorsoprinterVersion:error:
loadUserDefinedPersonLinksForHomeUUID:error:
loadValuesAsynchronouslyForKeys:completionHandler:
loadValuesSynchronously
localeWithLocaleIdentifier:
localizedStandardCompare:
localizedStringForKey:value:table:
lock
logCategory
logIdentifier
logPreferenceForKey:value:
logStateCount
losses
lowQuality
main
mainBundle
mainInsideAutoreleasePool
maintainAspectRatio:originalSize:ratioThreshold:
manufacturer
maxAnalysisFPSForCurrentPeakPowerPressureLevel
maxAnalysisFPSForCurrentThermalLevel
maxAnalysisFPSForSystemResourceUsageLevel:
maxCandidates
maxConcurrentAnalyzersForCurrentPeakPowerPressureLevel
maxConcurrentAnalyzersForCurrentThermalLevel
maxConcurrentAnalyzersForSystemResourceUsageLevel:
maxConfidenceEventForEventClass:
maxConfidenceEvents
maxFragmentAnalysisDuration
maxFragmentDuration
maxFrameDelayCount
maxH264VideoDecoders
maxH264VideoEncoders
maxH265VideoEncoders
maxKeyFrameIntervalDuration
maxReferences
mediaType
mediumConfidenceThresholds
mergedPersonEventsFromEvents:
metadataForCameraProfile:
metadataForClip:
metadataForClip:withCameraProfile:inHome:
metadataForHome:
metricDefault
metricWithLabels
midpoint
minFrameScale
minSampleSize
minimumUUIDInEquivalencyCell:
model
modelFromURL:options:error:
modelPathForResource:
modelSize
modelSummaries
modelURL
modelURLsFromPath:error:
modelUUID
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
monitored
motion
motionDetections
motionDetector
motionMode
motionScore
motionTimeStamps
motionValidInterval
motionVectors
movingAverage
movingAverageForInterval:defaultValue:
mutableBytes
mutableCopy
mutableCopyWithZone:
mutableFloats
na_arrayByFlattening
na_dictionaryByMappingValues:
na_each:
na_filter:
na_firstObjectPassingTest:
na_flatMap:
na_reduceWithInitialValue:reducer:
name
neighborsOfObject:
networkPath
newDictionaryPopulatedWithFaceCropDataFromImageData:
nextObject
nextTaskID
nightVision
nmsConfiguration
nmsMultiClass:output:nmsConfiguration:
nonMaximumSuppression:output:withThreshold:withMetric:
notificationName
null
numCandidates
numDecodedSamples
numDidAnalyzeFragments
numDidAnalyzeFrames
numDidAnalyzePackages
numDidCreateTimelapseFragments
numFailures
numImages
numTracks
numberFromString:
numberOfClusters
numberOfDataPoints
numberOfDroppedFrames
numberOfFaceprintsClustered
numberOfMatchesInString:options:range:
numberOfPersonsCreated
numberOfUnknownFaceprintsAssociated
numberPreferenceForKey:
numberPreferenceForKey:defaultValue:
numberPreferenceForKey:defaultValue:withMap:
numberPreferenceForKey:defaultValue:withParser:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
object
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
objectJSON
objectPrettyJSON
objectWithJSONData:classMap:
objectWithJSONObject:classMap:
objectWithJSONObjectString:classMap:
objectsAtIndexes:
objectsInTimeRange:includeEnd:
observationWithRequestRevision:boundingBox:
offset
offsetsOneFeatureValueNames
offsetsZeroFeatureValueNames
open
operationQueue
operations
opticalZoom
origin
outputImage
outputPath
overlapsWithElipseInsideRect:
overlapsWithElipseInsideRect:withInsetPercentage:
packageClassifierMode
packageTrainingResult:privatize:maxNorm:normBinCount:encryptionKey:error:
passthroughAudio
path
pathExtension
pathForResource:ofType:
pathWithComponents:
payloadWithCamera:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
persistModel:toPath:error:
persistTorsoToFaceCrop:forHomeUUID:error:
persistTorsoprinterVersionForHomeUUID:error:
persistUserDefinedPersonLinks:forHomeUUID:error:
person
personDataAvailableViaHomeKit
personFromHomePerson:
personIndices
personLinks
personManager
personManagerUUID
personSourceUUIDPairFromPersonLink:
personToEquivalencyCell
personToFaceCrops
personUUID
personUUIDs
personUniqueIdentifiers
personsModelIdentifier
personsModelManager
personsModelWithFaceObservations:error:
personsModelWithFaceObservationsByID:error:
personsModelsByHome
photosPersonManager
photosPersonManagerForHomeUUID:sourceUUID:
photosPersonManagerWithUUID:
photosPersons
photosPersonsAndFaceCrops
pixelBuffer
pixelBufferFrameWithError:
playlistString
point
points
position
postNotificationName:object:
postTrainingLoss
preTrainingInferenceOutputDictionary:preTrainingtrainingLossKeyName:error:
precision
predict:detectedObjects:error:
predict:output:error:
predictHomePersonFromFaceObservation:homeUUID:error:
predictPersonFromFaceObservation:homeUUID:error:
predictPersonFromFaceObservation:limit:canceller:error:
predictPersonFromTorsoObservation:homeUUID:error:
predictedLinkedEntityUUIDs
prediction
predictionFromFeatures:error:
preferenceCacheFlushTimer
preferenceLoggedValues
preferenceOverrides
preferenceOverridesInternal
preferredOutputSegmentInterval
prepareSampleBuffer:
presentationTime
presentationTimeStamp
pretendProductTypeIsUnknown
printWithHeight:
privateDescription
probability
processInfo
processName
productClass
productInfo
progressBlock
propertyDescription
publishInitialValue
publishLocalState:
publishValueForToken:
purgeURLIfNeeded:
qosMap
qualityPredictionFromSVMUsingFaceQualityFilterSVM:detectorConfidence:laplacian:yaw:boxSize:error:
queue
readData:
readDataToEndOfFile
readMaxValue:
readUInt32
readUInt64
readValue
readValueFromSensor:value:
reader
reason
reassociateFaceCropsWithUnknownSource:toPersonUUID:
recall
recognizeEvents:frame:regionOfInterest:homeUUID:
recognizeFaces
rectValue
redactFrames
redactedCopy
redactedCopyWithFrameResults:fragment:
redactedCopyWithMetadata
reducedConfiguration:
reducedConfiguration:configurations:
reducedConfiguration:states:
reencodeAssetURL:outputURL:bitRate:duration:analysisFPS:sampleFrameHandler:dropFrameHandler:
referenceInterval
references
regionOfInterest
registerAnalyzer:
regularExpressionWithPattern:options:error:
releaseCachedResources
releaseCachedVisionResources
removeAllIndexes
removeAllObjects
removeAllPreferenceOverrides
removeExcessFaceCrops
removeFaceCropsWithUUIDs:
removeFaceCropsWithUUIDs:completion:
removeFaceprintsWithUUIDs:completion:
removeIndex:
removeIndexes:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeNearestFaceprint:withFaceCrops:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsAtIndexes:
removeObjectsInRange:
removePerson:
removePersonsModelForHomeUUID:sourceUUID:error:
removePersonsModelWithRetryOnError:
removePersonsWithUUIDs:completion:
removedPersonFaceCrops
render:toCVPixelBuffer:
reorderBufferSize
replaceObjectAtIndex:withObject:
report
reportBuffer
requestAnalysisForAssetData:withProperties:andCompletionHandler:
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
reset
resizePixelBuffer:
resizePixelBuffer:size:error:
resizePixelBuffer:size:pixelFormat:options:error:
resizedSampleBuffers
resourceLoader
resourceLoader:didCancelAuthenticationChallenge:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceUsageMonitor
respondWithData:
respondsToSelector:
result
resume
retain
retainCount
retimer:didRetimeSampleBuffer:
retimerDidRetimeSampleBuffer
rgbColorCodeForEventClass:
roll
rollsFeatureValueNames
room
runningMean
runningStd
sampleBufferDelay
sanitizedData
sanitizedSeperableSegment
saveAnalyzerResultsToDisk
saveDESRecordWithVideoFrame:recordInfo:
saveFaceClassifications:videoId:fragmentId:frameId:baseURL:error:
saveRecordWithData:recordInfo:completion:
saveToJsonActivityZones:motionDetection:videoFragmentUrl:frameId:UUID:detectionID:zoneID:
saveTrainingNetwork:checkpoint:error:
sbuf
scale:
scalerModel
scheduleTask:
score
scoreForSubBoundingBox:eventClass:confidence:
scoresFeatureValueNames
secondIndex
seek:
selectBestObservation:faceBoundingBoxFromPhotos:
selectFramesWithRecord:truth:frameResults:
self
sendEventForClusteringTask:
sendEventForFaceEvent:homePersonManagerUUID:camera:
sendEventForPersonRecognitionType:camera:
sendEventForPersonsModels:
sendEventWithName:payloadBuilder:
sendEventsForFragmentResult:
sentinelFaceprint
sentinelFaceprintWithUUID:modelUUID:faceCropUUID:
separableSegment
sequenceNumber
serializeJSONObject:url:error:
serverTrust
serviceResult
services
sessionEntityAssignment
sessionEntityManager
sessionEntityUUID
sessionWithConfiguration:delegate:delegateQueue:
sessions
setActivityZones:
setAdjustBrightness:
setAllowBackgroundGPUCompute:
setAllowReducedConfiguration:
setAllowedUnits:
setAllowsNonnumericFormatting:
setAlwaysCopiesSampleData:
setAnalysisStateManager:
setAnalyzerDidAnalyzeFragmentWithResult:
setAnalyzerDidAnalyzeFrameWithResult:
setAnalyzerDidCreateTimelapseFragment:
setAnalyzerDidFailWithError:
setAnalyzerDidProduceAnalysisStateUpdate:
setArray:
setAssetData:
setAssetWriterDidOutputInitializationSegment:
setAssetWriterDidOutputSeparableSegment:
setAssignment:
setAverageBitRate:
setBackground:
setBackgroundChangeTimeStamp:
setBackgroundEstimator:
setBackgroundTimeStamp:
setBlobID:
setBuffer:
setBufferWillFlush:
setBufferWillHandleSampleBuffer:
setByAddingObject:
setByAddingObjectsFromArray:
setByAddingObjectsFromSet:
setByteRangeAccessSupported:
setCamera:
setCancelled:
setCandidate:
setClassMap:
setClipDestinationFileURL:
setClusterId:
setClusteringDuration:
setCompletionBlock:
setComputeUnits:
setContentLength:
setCountStyle:
setCurrentDTS:
setCurrentFragmentStartTime:
setCurrentPTS:
setDataRateLimit:
setDataSource:
setDateFormat:
setDecodeMode:
setDecoderDidDecodeSampleBuffer:
setDecoderDidFailWithError:
setDelegate:
setDelegate:queue:
setDelegateQueue:
setDetectionLevel:
setDidUpdateHomes:
setDiscretionary:
setDouble:forKey:
setDownloadProgressHandler:
setDropSamplesUntilSync:
setDynamicConfiguration:
setEnableTemporalEventFiltering:
setEnabled:
setEncode:
setEncoder:
setEncoderDidEncodeSampleBuffer:
setEncoderDidFailWithError:
setError:
setEventClass:
setEventTriggers:
setExpectedDuration:
setExpectedFrameRate:
setExpectsMediaDataInRealTime:
setExternalPersonManagers:
setFaceClassificationEnabled:
setFaceCrops:
setFaceId:
setFaceRecognition:
setFaceprint:
setFaceprintUUIDs:
setFaceprintingDuration:
setFetchVideoAssetContextCompletionBlock:
setForceKeyFrameOnNextEncodedFrame:
setForegroundTimeStamp:
setFrameAnalyzerDidAnalyzeFrame:
setFrameAnalyzerDidProduceAnalysisStateUpdate:
setFrameSamplerDidDropFrame:
setFrameSamplerDidSampleFrame:
setFrameSelectorDidSkipFrame:
setFrameSelectorPrepareFrame:
setFrameTrackerDidTrackFrame:
setHTTPMethod:
setHasFailed:
setHighWaterMark:
setHomePersonManager:
setHomeUUID:
setIgnoreThermalAndSystemResourceUsageLevel:
setImageSize:
setImportingFromPhotoLibraryEnabled:
setInitialMovieFragmentSequenceNumber:
setInitialSegmentStartTime:
setInitializationSegment:
setInput:
setInputAudioFormat:
setInputDetectedObjectObservations:
setInputFaceObservations:
setInputVideoFormat:
setLastAudioPresentationTimeStamp:
setLastFragmentReceivedDate:
setLastSampleBufferDTS:
setLastSampleBufferPTS:
setLastVideoPresentationTimeStamp:
setLinkedEntityUUIDs:
setLocale:
setLogIdentifier:
setLogStateCount:
setMaxFragmentDuration:
setMaxFrameDelayCount:
setMaxH264VideoDecoders:
setMaxH264VideoEncoders:
setMaxH265VideoEncoders:
setMaxNumberOfElements:
setMaxReferences:
setMaximumFractionDigits:
setMaximumIdentities:
setMaximumTrainingFaceprintsPerIdentity:
setMediaTimeScale:
setMinFrameQuality:
setMinFrameScale:
setModel:
setModelSize:
setMonitored:
setMotionDetections:
setMovingAverage:
setName:
setNextTaskID:
setNumCandidates:
setNumImages:
setNumTracks:
setNumberOfClusters:
setNumberOfPersonsCreated:
setNumberOfUnknownFaceprintsAssociated:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setObjects:
setOptions:
setOutputFileType:
setOutputFileTypeProfile:
setOutputURL:
setPackageClassifierMode:
setPassthroughAudio:
setPersonDataAvailableViaHomeKit:
setPersonIndices:
setPhotosPersonManager:
setPreferenceOverrideFromDictionary:
setPreferredOutputSegmentInterval:
setPrevFrameResult:
setProgressBlock:
setQuality:
setQualityOfService:
setQueue:
setReadOnly:
setRecognizeFaces:
setRedactFrames:
setReferenceInterval:
setResetReferences:
setRetimerDidRetimeSampleBuffer:
setRevision:
setRevision:error:
setRunningStd:
setSampleRate:
setSaveAnalyzerResultsToDisk:
setServiceResult:
setSession:
setSharingFaceClassificationsEnabled:
setShouldUpdateRepresentative:
setSize:
setSource:
setStationaryBlobIndex:
setSupportsFaceClassification:
setSystemResourceUsageLevel:
setThumbnailHeight:
setThumbnailInterval:
setTimeRange:
setTimeZone:
setTimelapseAssetWriter:
setTimelapseEncoder:
setTimelapseInitializationSegment:
setTimelapseInterval:
setTimelapseOutputVideoFormat:
setTimelapsePreferredFragmentDuration:
setTimelapseVideo:
setTimelapseVideoPreferredFragmentDuration:
setToken:
setTorsoprintUUIDs:
setTotalDuration:
setTotalObjectCount:
setTrackAnalysisPTS:
setTranscode:
setTranscodeCodecType:
setValue:forHTTPHeaderField:
setValue:forKey:
setWithArray:
setWithObject:
setWithSet:
setZeroPadsFractionDigits:
settings
setup
shape
sharedInstance
sharedModel
sharingFaceClassificationsEnabled
shortDescription
shortNameForEventClass:
shouldEnableTorsoRecognition
shouldGenerateThumbnailForAnalysisFPS:
shouldRemoveExcessFaceCrops
shouldSignpost
shouldUseCPUOnlyForVisionFaceDetection
signal
significantEvents
signpostIdentifier
signpostLog
sihouetteScoreForMatches:previousMatches:truePositiveScores:falsePositiveScores:falseNegativeScores:
similarityToBlob:
similarityToPersonBlob:
size
sleepForTimeInterval:
sortUsingComparator:
sortedArrayUsingComparator:
sortedArrayUsingDescriptors:
sortedArrayUsingSelector:
source
sourceURL
sourceUUID
sourceUUIDForPerson:
standardUserDefaults
start
startDate
startReading
startSessionAtSourceTime:
startTime
startWriting
startedAtTime:
state
stateManager:didReceiveLocalUpdate:
stateUpdateByMergingStateUpdate:
stateUpdateFromFaceEvents:
stationaryBlobIndex
stationaryIndexToBoundingBox:
stationaryObjects
status
statusCode
statusOfValueForKey:error:
stop
storeFaceprint:completion:
storeUnassociatedFaceCrop:completion:
stream
string
stringByAppendingString:
stringByDeletingPathExtension
stringByPaddingToLength:withString:startingAtIndex:
stringByReplacingOccurrencesOfString:withString:
stringByTrimmingCharactersInSet:
stringFromByteCount:
stringFromNumber:
stringPreferenceForKey:defaultValue:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
subarrayWithRange:
subdataWithRange:
submitCoreAnalyticsEvent:filteringLevel:numberOfDetectedObjects:
submitCoreAnalyticsEventForActivityZones:motionScore:
submitFeedbackWithCameraProfileUUID:clipUUID:runRemotely:completionHandler:
submitTask:progressHandler:completionHander:
submitTaskWithOptions:completionHandler:
submitTaskWithOptions:progressHandler:completionHandler:
submitTorsoprintsToModelManagerForHome:withTorsoAnnotations:
subsampleFacesForPersons:withFaceObservationsMap:dataSource:vnUUIDToFaceCropUUIDMap:
substringToIndex:
subtract:
summaryForHomeUUID:error:
superclass
supportsFaceClassification
supportsSecureCoding
svmInputName
svmOutputName
systemDeviceInformation
systemPreferenceValueForKey:
systemResourceUsageLevel
systemResourceUsageMonitorImpl
tableColumns
tableValues
target
targetDate
targetEventClassRanks
targetInterval
taskID
taskIdentifier
taskService
taskServiceClient
temporalEventFilter
temporaryFileURLs
text
thermalLevel
thermalPressureLevel
thresholdDefault
thresholdForLabel:
thresholdWithLabels
thumbnailInterval
thumbnails
tick
time
timeInterval
timeIntervalSinceDate:
timeIntervalSinceDateAtTime:
timeIntervalSinceNow
timeIntervalSinceReferenceDate
timeOffsetWithinClip
timeRange
timeSinceAnalyzerStarted
timeSinceLastFragmentWasReceived
timeStamp
timeZoneForSecondsFromGMT:
timelapseAssetWriter
timelapseEncoder
timelapseInitializationSegment
timelapseInterval
timelapseOutputVideoFormat
timelapsePreferredFragmentDuration
timelapseVideo
timelapseVideoPreferredFragmentDuration
timeline
timerDidFire:
token
torso
torsoAnnotations
torsoCentroid
torsoCount
torsoModelVersion
torsoModelsByHome
torsoRecognition
torsoToFaceCropByHome
torsoprint
torsoprintForTorsoPixelBuffer:unrecognizable:error:
torsoprinter
torsoprints
totalDuration
trackAnalysisPTS
trackIndex
trackInterval
trackNewPersons:knownPersons:regionOfInterest:timeStamp:
trackPersonBlob:
trackReports
tracks
tracksWithMediaType:
trainLayers:epochs:fromTask:shouldCalculatePreTrainingLoss:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
transaction
transcode
transcodeCodecType
transferPixelBuffer:crop:size:pixelFormat:options:error:
transferPixelBuffer:pixelFormat:options:error:
transferPixelBuffer:rotationAngle:crop:size:precision:error:
truePositive
truePositiveKeys
truth
truthReportFromLegacyClassificationFormat:
truthReportFromLegacyDetectionFormat:
type
typeWithIdentifier:
unalignedBoundingBox
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
unassociatedFaceCrops
unionSet:
uniqueIdentifier
unknownFacesSavedCounts
unlock
unrecognizable
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
updatePersonEventWithPersonEvent:sessionEntityUUID:predictedLinkedEntityUUIDs:sessionEntityAssignment:
updatePersonsModelWithRetryOnError:
updatePreviousPrintsForSessionEntityUUID:faceRecognition:torsoRecognition:
updateTorsoModelAndGetTorsoAnnotationsForHome:
updateTorsoModelForHome:torsoAnnotations:error:
updatedFaceprintsForFaceCrops:withExistingFaceprints:error:
upload
uploadTaskWithRequest:fromFile:completionHandler:
userDefinedPersonLinksByHome
userInfo
usesCPUOnly
uuid
value
valueAtIndex:
valueForInterval:defaultValue:
valueForKeyPath:
valuePreferenceForKey:defaultValue:withMap:
valuePreferenceForKey:defaultValue:withParser:
valueWithBytes:objCType:
valueWithCMTime:
vectorWithString:
videoAnalyzerDidAnalyzeFragmentWithResult:state:
videoAnalyzerDidCreateTimelapseFragment:state:
videoAnalyzerDidFindFaceEvent:homePersonManagerUUID:camera:
videoAnalyzerDidTerminateWithError:state:
videoDuration
videoFormat
videoFormatDescription
videoInput
videoPackageAnalyzerDidClassifyCandidateAsPackage:camera:
videoPackageAnalyzerDidResetReferenceImageWithInterval:camera:
videoTrackTimeRange
visionPersonsModel
visualizeBackgroundMean
visualizeBackgroundStd
visualizeForegroundAssignment
visualizeForegroundDiffForPixelBuffer:
visualizeMotionDetections:frameSize:timeStamp:
vnSession
wait
waitUntilFinished
warmStart
watchdogTimer
weakDecoder
weakObjectsPointerArray
weightsName
whitespaceCharacterSet
windowSize
workQueue
write:maxLength:
writeData:
writeFragmentFileComparison:eventClass:outputPath:
writeHTMLReportComparison:truth:eventClass:comparisonType:assetPath:outputPath:limit:shuffle:
writeImageCropForEventClass:outputPath:assetPath:
writeImageCropFromFrame:events:outputPath:source:
writeJSONChartData:outputPath:
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
writeToFile:atomically:
writeToFile:atomically:encoding:error:
writeToURL:atomically:
writeToURL:atomically:encoding:error:
writeToURL:options:error:
yawsFeatureValueNames
zone
@16@0:8
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8@?16
v32@0:8@16@?24
v24@0:8@?<v@?@"NSSet"@"NSError">16
v32@0:8@"NSSet"16@?<v@?@"NSSet"@"NSError">24
v24@0:8@?<v@?@"NSError">16
v32@0:8@"NSSet"16@?<v@?@"NSError">24
v24@0:8@?<v@?@"HMIExternalPersonManagerSettings"@"NSError">16
f28@0:8r^v16i24
f24@0:8^{__CVBuffer=}16
@"NSObject"16@0:8
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56f64f68
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
f16@0:8
v16@0:8
@"NSString"
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@28@0:8@16B24
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@32@0:8@16@24
v40@0:8@16@24@32
v24@0:8@16
v32@0:8@16@24
v64@0:8@16@24@32i40@44i52@56
v48@0:8@16i24@28i36@40
@"NSOutputStream"
@24@0:8@16
@"HMIDESMutableFloatArray"
@"NSMutableArray"
@"NSMutableSet"
@"HMIFaceRecognition"
q16@0:8
v24@0:8q16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72@80
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64@72@80@88
@"NSNumber"
@"HMITorsoAnnotation"
@"<HMIPersonManagerDataSource>"
@"NSSet"
I16@0:8
v24@0:8Q16
@24@0:8Q16
@"NSData"
{?=qiIq}16@0:8
@48@0:8@16{?=qiIq}24
{?="value"q"timescale"i"flags"I"epoch"q}
@24@0:8q16
@68@0:8{?={?=qiIq}{?=qiIq}}16B64
@64@0:8{?={?=qiIq}{?=qiIq}}16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@48@0:8{?=qiIq}16@40
@"NSDate"
v48@0:8@16{?=qiIq}24
@40@0:8{?=qiIq}16
d40@0:8{?=qiIq}16
@"HMIVideoEventBuffer"
v40@0:8{?=qiIq}16
d16@0:8
@"HMIVideoTimeline"
@"HMITimeIntervalAverage"
v24@0:8d16
d32@0:8d16d24
@"MovingAverage"
@60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
^{__CVBuffer=}40@0:8@16^{__CVBuffer=}24^@32
@36@0:8^{__CVBuffer=}16B24^@28
@"<HMIHomePersonManagerDataSource>"
v24@0:8@"HMFTimer"16
@"HMIHomePersonManagerSettings"
@"NSOperationQueue"
@"HMFTimer"
@"NSMutableDictionary"
@"HMIFaceCrop"
@"HMIFaceprint"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@80@0:8@16{?=qiIq}24Q48Q56{CGSize=dd}64
{CGSize=dd}16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"NSArray"
{CGSize="width"d"height"d}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}60@0:8^{__CVBuffer=}16{CGSize=dd}24I40q44^@52
^{__CVBuffer=}44@0:8^{__CVBuffer=}16I24q28^@36
^{__CVBuffer=}92@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56I72q76^@84
@40@0:8^{__CVBuffer=}16f24f28^@32
^{__CVBuffer=}32@0:8^{CGDataProvider=}16^@24
^{__CVBuffer=}32@0:8@16^@24
^{__CVBuffer=}40@0:8{CGSize=dd}16I32B36
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48{CGSize=dd}64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48f64
^{__CVBuffer=}92@0:8^{__CVBuffer=}16f24{CGRect={CGPoint=dd}{CGSize=dd}}28{CGSize=dd}60Q76^@84
@36@0:8Q16Q24f32
@24@0:8^{__IOHIDServiceClient=}16
^{__IOHIDServiceClient=}
B28@0:8i16^d20
B24@0:8^d16
^{__IOHIDEventSystemClient=}
@40@0:8@16@24^@32
B40@0:8^{__CVBuffer=}16@24^@32
B72@0:8^{__CVBuffer=}16@24@32@40@48@56^@64
v64@0:8@16@24@32@40@48@56
[7f]
[5{CGSize="width"d"height"d}]
@"HMINMSConfiguration"
@32@0:8@16B24B28
B32@0:8@16B24B28
^{opaqueCMSampleBuffer=}24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
^{opaqueCMSampleBuffer=}24@0:8^Q16
@"AVAsset"
@"AVAssetReader"
^{__CFArray=}
@"HMHomeManager"
v32@0:8@16Q24
v32@0:8@"HMHomeManager"16Q24
v24@0:8@"HMHomeManager"16
v32@0:8@"HMHomeManager"16@"HMHome"24
v32@0:8@"HMHomeManager"16@"HMAddAccessoryRequest"24
@?16@0:8
@"NSUUID"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLMultiArray"
B40@0:8@16^d24^@32
@"MLModel"
@"NSError"
v24@0:8^{opaqueCMSampleBuffer=}16
@"HMIVideoAnalyzerConfiguration"
@"HMIVideoAnalyzerDynamicConfiguration"
@"HMPhotosPersonManager"
@32@0:8q16@24
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@80@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72
@88@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72q80
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
@24@0:8#16
@"HMIVideoFrame"
@48@0:8^{__CVBuffer=}16{?=qiIq}24
v32@0:8@16^{opaqueCMSampleBuffer=}24
B48@0:8^{__CVBuffer=}16{?=qiIq}24
B52@0:8r*16B24{?=qiIq}28
@32@0:8@16^B24
v64@0:8@16@24@32{?=qiIq}40
v24@0:8^{__CVBuffer=}16
v40@0:8^{__CVBuffer=}16^f24i32i36
v32@0:8r^f16^{__CVBuffer=}24
f64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^S56
v68@0:8^S16S24S28{CGRect={CGPoint=dd}{CGSize=dd}}32f64
v44@0:8^f16^f24r^f32f40
v48@0:8^f16^f24r^f32r^f40
v24@0:8r*16
v44@0:8^{__CVBuffer=}16*24^S32B40
v32@0:8^{__CVBuffer=}16^f24
@48@0:8^S16{?=qiIq}24
@32@0:8^{__CVBuffer=}16Q24
^S16@0:8
v24@0:8^S16
^f16@0:8
v24@0:8^f16
v32@0:8{CGSize=dd}16
v20@0:8B16
B32@0:8@16@24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
q24@0:8@16
@88@0:8@16q24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48@80
@"HMICameraVideoFrame"
@"NSDictionary"
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48
@40@0:8#16@24@32
@64@0:8#16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@28@0:8f16Q20
@32@0:8r^f16Q24
v20@0:8f16
v32@0:8r^f16Q24
r^f16@0:8
@20@0:8f16
@"NSMutableData"
@52@0:8@16^{__CVBuffer=}24B32@36^@44
@"HMIVideoAnalyzerEventFace"52@0:8@"HMIVideoAnalyzerEventFace"16^{__CVBuffer=}24B32@"NSUUID"36^@44
@24@0:8^@16
@64@0:8@16d24d32d40d48^@56
@"HMIFaceprinter"
@"HMIFaceQualityFilterSVM"
^{__CVBuffer=}24@0:8^@16
@56@0:8@16@24@32@40@48
@32@0:8Q16^@24
@32@0:8^{__CVBuffer=}16@24
@48@0:8@16@24@32@40
@76@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28@60@68
i16@0:8
v48@0:8@16@24d32q40
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56
f24@0:8@16
B40@0:8{?=qiIq}16
@"HMITorsoprint"
@"NSMutableIndexSet"
v88@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{?=qiIq}64
@104@0:8@16@24@32{?=qiIq}40{CGRect={CGPoint=dd}{CGSize=dd}}64@96
v32@0:8@"HMIVideoFrameSampler"16^{opaqueCMSampleBuffer=}24
B48@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24@32@40
@"<HMIVideoFrameAnalyzerDelegate>"
@"<HMICameraVideoFrameAnalyzer>"
@"HMIVideoFrameSampler"
v32@0:8@"HMIVideoFrameAnalyzer"16@"HMIVideoFrameAnalyzerResult"24
v32@0:8@"HMIVideoFrameAnalyzer"16@"HMIAnalysisStateUpdate"24
@36@0:8@16@24f32
@40@0:8@16@24Q32
@40@0:8@16@24@32
@44@0:8@16@24@32B40
v28@0:8@16B24
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
v48@0:8@16@24@32@40
@104@0:8@16@24@32@40#48{CGRect={CGPoint=dd}{CGSize=dd}}56f88f92@?96
v56@0:8@16@24@32@40@48
@32@0:8@16^@24
v44@0:8@16@24@32B40
@28@0:8f16@?20
@28@0:8@16f24
@36@0:8@16f24f28B32
@28@0:8B16@?20
@36@0:8@16B24f28B32
@36@0:8@16#24f32
@44@0:8@16#24f32f36B40
@40@0:8@16#24f32f36
v76@0:8@16@24#32@40@48@56Q64B72
v40@0:8#16@24@32
v40@0:8@16#24@32
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
^{opaqueCMSampleBuffer=}
@"<HMIVideoRetimerDelegate>"
v32@0:8@"HMIVideoRetimer"16^{opaqueCMSampleBuffer=}24
@20@0:8i16
@28@0:8i16d20
@36@0:8i16@20d28
i40@0:8@16@?24@?32
B20@0:8i16
v20@0:8i16
i32@0:8@16@?24
@"NSArray"16@0:8
@56@0:8@16@24@32q40@48
@"HMITorsoClassification"
^{__CVBuffer=}48@0:8@16^{__CVBuffer=}24@32^@40
q20@0:8i16
@32@0:8^{__CVBuffer=}16^@24
@"NSArray"32@0:8^{__CVBuffer=}16^@24
@"NSArray"32@0:8@"NSData"16^@24
@32@0:8{CGPoint=dd}16
{CGPoint=dd}16@0:8
{CGPoint="x"d"y"d}
@36@0:8i16@20@28
v40@0:8@16@24@?32
v32@0:8@"NSURLSession"16@"NSError"24
v40@0:8@"NSURLSession"16@"NSURLAuthenticationChallenge"24@?<v@?q@"NSURLCredential">32
v24@0:8@"NSURLSession"16
@"HMIHomeKitClient"
@"NSURLSession"
B40@0:8@16@24^@32
@"HMIFeedbackSession"
@"HMFOperation"
v44@0:8@16@24B32@?36
@52@0:8@16@24d32B40q44
@56@0:8@16@24@32d40q48
@72@0:8@16@24@32@40@48d56q64
@76@0:8@16@24@32@40@48d56B64q68
@96@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40@72@80d88
v48@0:8@16@24q32@?40
v24@0:8@?<v@?@"HMIHomePersonManagerSettings"@"NSError">16
v48@0:8@"NSSet"16@"NSUUID"24q32@?<v@?@"NSError">40
@28@0:8i16@20
@"HMIPersonFaceCrop"
@"HMIVideoAssetReader"
@32@0:8d16@24
@56@0:8Q16@24@32@40@48
@40@0:8q16@24@32
@48@0:8q16@24@32@40
@72@0:8@16{?={?=qiIq}{?=qiIq}}24
@80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
@96@0:8@16@24{?={?=qiIq}{?=qiIq}}32{_NSRange=QQ}80
@88@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80
@104@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80{_NSRange=QQ}88
{?={?=qiIq}{?=qiIq}}16@0:8
r^{opaqueCMFormatDescription=}16@0:8
{_NSRange=QQ}16@0:8
r^{opaqueCMFormatDescription=}
{_NSRange="location"Q"length"Q}
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@48@0:8@16@24@32q40
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56@80
@56@0:8@16@24@32@40^q48
v56@0:8@16@24@32@40^q48
@"HMIPersonTracker"
@"<HMIAnalysisStateManagerDelegate>"
@32@0:8^{__CVBuffer=}16d24
r^{__CTFont=}24@0:8d16
v48@0:8@16{CGPoint=dd}24r^d40
v64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48r^d56
v72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48@56r^d64
^{CGContext=}
^{CGColorSpace=}
^{__CTFont=}
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@36@0:8@16B24@28
@"VNPersonsModel"
@32@0:8@16q24
@36@0:8@16B24q28
v24@0:8#16
v28@0:8i16@20
v32@0:8q16@24
v32@0:8d16@24
v28@0:8B16@20
i24@0:8@16
d24@0:8@16
@32@0:8#16@24
B64@0:8@16@24Q32@40@48^@56
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGSize=dd}32@0:8@16^@24
@40@0:8@16@24B32B36
@40@0:8{?=ii}16I24B28^@32
B40@0:8{?=ii}16I24B28^@32
i32@0:8r^{__CFString=}16r^v24
i32@0:8r^{__CFString=}16r^^v24
i28@0:8r^{__CFString=}16i24
i32@0:8r^{__CFString=}16^i24
i32@0:8r^{__CFString=}16d24
i32@0:8r^{__CFString=}16^d24
v32@0:8{HMIVideoEncoderDataRate=qq}16
{HMIVideoEncoderDataRate=qq}16@0:8
^{OpaqueVTCompressionSession=}16@0:8
v24@0:8^{OpaqueVTCompressionSession=}16
^{OpaqueVTCompressionSession=}
@"<HMIVideoEncoderDelegate>"
v32@0:8@"HMIVideoEncoder"16^{opaqueCMSampleBuffer=}24
v32@0:8@"HMIVideoEncoder"16@"NSError"24
@"HMHomePersonManager"
B32@0:8@16@?24
q32@0:8q16@24
@40@0:8@16Q24Q32
B32@0:8@16^@24
B52@0:8@16@24B32@36^@44
B24@0:8^@16
@44@0:8@16B24@28^@36
@40@0:8@16@24f32f36
@64@0:8@16@24@32@40@48^@56
f40@0:8@16@24^@32
@52@0:8@16Q24@32B40^@44
@"HMIDESDataset"
@"NSURL"
@40@0:8Q16d24@32
@"<HMIExternalPersonManagerDataSource>"
@"HMIExternalPersonManagerSettings"
@36@0:8@16@24B32
@32@0:8@16@?24
@"HMISystemResourceUsageMonitor"
@"NSPointerArray"
B40@0:8@16^v24^@32
f32@0:8@16@24
@48@0:8@16@24@32^@40
@24@0:8^v16
{shared_ptr<homeai::clustering::GreedyClusterer>="__ptr_"^{GreedyClusterer}"__cntrl_"^{__shared_weak_count}}
@"<HMIVideoFrameSamplerDelegate>"
@"HMICIFilterAttributeValue"
@32@0:8@16d24
@"VNSession"
@"HMFOSTransaction"
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@64@0:8@16@24@32@40@48@56
@24@0:8B16B20
@"HMIVideoFragment"
@"HMIVideoAnalyzerResultOutcome"
@48@0:8@16@24@32f40f44
v28@0:8@16f24
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
B28@0:8@16f24
B72@0:8@16@24@32@40@48@56@64
B64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48#56
B48@0:8{CGPoint=dd}16{CGPoint=dd}32
v20@0:8I16
@"HMICamera"
@"HMIVideoAnalyzerEvent"
@80@0:8@16@24@32{?=qiIq}40{CGSize=dd}64
@80@0:8@16@24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48
B80@0:8@16{?=qiIq}24{CGRect={CGPoint=dd}{CGSize=dd}}48
@"HMIVideoAnalyzerFrameResult"
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64
@"HMIVideoAnalyzerEventFace"
@"HMIVideoAnalyzerEventTorso"
@44@0:8@16B24B28d32f40
@60@0:8@16B24d28Q36@44^@52
Q24@0:8q16
d24@0:8q16
B24@0:8d16
@40@0:8@16@24@?32
B28@0:8@16B24
@"HMIPerson"
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?=qiIq}48f72S76
S16@0:8
@32@0:8@16Q24
Q48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@40@0:8r*16@24@?32
r*16@0:8
@44@0:8^{opaqueCMSampleBuffer=}16f24@28@36
^{__CVBuffer=}24@0:8^{__CVBuffer=}16
v32@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24
^{opaqueCMSampleBuffer=}24@0:8^{opaqueCMSampleBuffer=}16
v44@0:8^{opaqueCMSampleBuffer=}16f24@28@36
@48@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24@32^f40
@56@0:8^{opaqueCMSampleBuffer=}16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48
^{opaqueCMSampleBuffer=}40@0:8{?=qiIq}16
v56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24@48
v72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
^{__CFArray=}16@0:8
@"<HMIVideoFrameTrackerDelegate>"
@"HMIMotionDetector"
@"HMIVideoFrameTrackerFrameCandidate"
@"HMIBackgroundEstimator"
@"HMIHTMLReport"
v56@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@40@48
v56@0:8@"HMIVideoFrameTracker"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32@"NSArray"40@"NSSet"48
B84@0:8@16@24q32{?=qiIq}40f64@?68@?76
B76@0:8@16@24{?=qiIq}32f56Q60^B68
v40@0:8@16^{opaqueCMSampleBuffer=}24@32
^{__CVBuffer=}32@0:8^{__CVBuffer=}16@24
I40@0:8@16{CGSize=dd}24
@"HMIGreedyClustering"
@64@0:8i16@20@28@36@44B52^@56
@"<HMIFaceClassifier>"
@"HMIPersonsModelManager"
@"HMIClusteringTaskSummary"
@52@0:8i16@20@28@36B44B48
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8@16@24{CGSize=dd}32
@40@0:8@16q24B32B36
@64@0:8@16@24@32{?=qiIq}40
@72@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64
@64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@48@0:8@"NSDictionary"16@"NSDictionary"24@"HMIVideoAnalyzerConfiguration"32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8@"NSArray"16@"NSSet"24{CGSize=dd}32
@"NSSet"56@0:8@"HMIVideoFrame"16{CGRect={CGPoint=dd}{CGSize=dd}}24
@"NSSet"40@0:8@"NSSet"16q24B32B36
@"NSSet"64@0:8@"NSSet"16@"NSSet"24@"NSMutableSet"32{?=qiIq}40
@"NSSet"72@0:8@"HMIVideoFrame"16@"NSSet"24@"NSMutableSet"32{CGRect={CGPoint=dd}{CGSize=dd}}40
@"NSSet"72@0:8@"NSSet"16@"HMIVideoFrame"24{CGRect={CGPoint=dd}{CGSize=dd}}32@"NSUUID"64
@"NSSet"64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@"HMIAnalysisStateUpdate"28@0:8@"NSUUID"16B24
@"NSDictionary"16@0:8
@80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56^@72
@32@0:8q16B24B28
@"HMISignificantActivityFcosDetector"
@"HMIFaceClassifierVIP"
@"HMITorsoClassifier"
@"HMISessionEntityManager"
@64@0:8@16{CGSize=dd}24{?=qiIq}40
@24@0:8^{opaqueCMSampleBuffer=}16
@40@0:8d16d24^@32
@"NSCondition"
@"<HMIVideoCommandBufferDelegate>"
v32@0:8@"HMIVideoCommandBuffer"16^{opaqueCMSampleBuffer=}24
v24@0:8@"HMIVideoCommandBuffer"16
@24@0:8d16
v32@0:8@16d24
v48@0:8@16d24{_NSRange=QQ}32
#24@0:8@16
@32@0:8#16q24
@"HMIConfidence"
@40@0:8@16@24d32
@20@0:8B16
B28@0:8^{opaqueCMSampleBuffer=}16B24
B24@0:8r^{opaqueCMFormatDescription=}16
^{opaqueCMBufferQueue=}16@0:8
v24@0:8^{opaqueCMBufferQueue=}16
^{OpaqueVTDecompressionSession=}16@0:8
v24@0:8^{OpaqueVTDecompressionSession=}16
@"<HMIVideoDecoderDelegate>"
^{opaqueCMBufferQueue=}
^{OpaqueVTDecompressionSession=}
@"HMFWeakObject"
v32@0:8@"HMIVideoDecoder"16^{opaqueCMSampleBuffer=}24
v32@0:8@"HMIVideoDecoder"16@"NSError"24
v48@0:8@16@24q32@40
v40@0:8@16@24q32
v48@0:8@"AVAssetWriter"16@"NSData"24q32@"AVAssetSegmentReport"40
v40@0:8@"AVAssetWriter"16@"NSData"24q32
@32@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24
@64@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24Q32{?=qiIq}40
@"<HMIVideoAssetWriterDelegate>"
@"AVAssetWriter"
@"AVAssetWriterInput"
v32@0:8@"HMIVideoAssetWriter"16@"NSData"24
v40@0:8@"HMIVideoAssetWriter"16@"NSData"24@"AVAssetSegmentReport"32
v32@0:8@"HMIVideoAssetWriter"16@"NSError"24
B48@0:8@16@24d32d40
@48@0:8{CGPoint=dd}16{CGVector=dd}32
{CGVector=dd}16@0:8
{CGVector="dx"d"dy"d}
@84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64f72Q76
f60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16#48f56
B60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16#48f56
@56@0:8^{__CVBuffer=}16^{__CVBuffer=}24^f32@40Q48
@172@0:8{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}40{vector<cv::Point_<float>, std::allocator<cv::Point_<float>>>=^v^v{__compressed_pair<cv::Point_<float> *, std::allocator<cv::Point_<float>>>=^v}}64{vector<cv::Point_<float>, std::allocator<cv::Point_<float>>>=^v^v{__compressed_pair<cv::Point_<float> *, std::allocator<cv::Point_<float>>>=^v}}88@112Q120{vector<cv::Mat, std::allocator<cv::Mat>>=^{Mat}^{Mat}{__compressed_pair<cv::Mat *, std::allocator<cv::Mat>>=^{Mat}}}128{CGSize=dd}152f168
B72@0:8{CGPoint=dd}16{CGPoint=dd}32{CGSize=dd}48@64
@56@0:8^f16^{__CVBuffer=}24^{__CVBuffer=}32@40Q48
@80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^{__CVBuffer=}56@64^@72
@"HMITorsoprinter"
{os_unfair_lock_s=I}16@0:8
@"<HMIVideoFrameSelectorDelegate>"
v40@0:8@16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32
^{opaqueCMSampleBuffer=}32@0:8@16^{opaqueCMSampleBuffer=}24
v40@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24^{opaqueCMSampleBuffer=}32
v32@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24
^{opaqueCMSampleBuffer=}32@0:8@"HMIVideoFrameSelector"16^{opaqueCMSampleBuffer=}24
@172@0:8@16@24@32B40d44d52d60d68Q76d84{?=qiIq}92Q116Q124Q132Q140Q148d156B164B168
@72@0:8@16@24@32@40d48q56@64
@44@0:8@16@24B32^@36
@"<HMIVideoAnalyzerDelegate>"
@"HMIHomePersonManager"
@"HMIAnalysisStateManager"
@"HMIVideoAnalyzerState"
@"HMIVideoAnalyzerMutableReport"
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoAnalyzerFragmentResult"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoAnalyzerFrameResult"24
v32@0:8@"HMIVideoAnalyzer"16@"NSError"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIVideoFragment"24
v32@0:8@"HMIVideoAnalyzer"16@"HMIAnalysisStateUpdate"24
v32@0:8@"HMIVideoAnalyzer"16@"NSDictionary"24
v32@0:8^{opaqueCMSampleBuffer=}16@?24
v32@0:8r^{opaqueCMFormatDescription=}16r^{opaqueCMFormatDescription=}24
v24@0:8r^{opaqueCMFormatDescription=}16
v32@0:8:16@24
@"HMIVideoCommandBuffer"
@"HMIVideoDecoder"
@"HMIVideoEncoder"
@"HMIVideoFrameSelector"
@"HMIVideoFrameTracker"
@"HMIVideoFrameAnalyzer"
@"HMIVideoAssetWriter"
@"HMIVideoTemporalEventFilter"
@"HMITorsoRecognition"
gepj
v024
ffffff
333333
333333
333333
333333
333333
333333
