Motion
Person
Vehicle
?333333
+Cfff?
@UUUUUU
@(#)PROGRAM:HomeAI  PROJECT:HomeAI-44.1
width
Td,R,V_width
height
Td,R,V_height
layerNumber
TQ,R,V_layerNumber
offsetsFeatureValueName
T@"NSString",R,V_offsetsFeatureValueName
scoresFeatureValueName
T@"NSString",R,V_scoresFeatureValueName
stride
TQ,R,V_stride
defaultBoxCount
TQ,R,V_defaultBoxCount
cellStartX
Tf,R,V_cellStartX
cellStartY
Tf,R,V_cellStartY
scale
Tf,R,V_scale
defaultBoxesSizes
T@"NSArray",R,V_defaultBoxesSizes
ratios
T@"NSArray",R,V_ratios
layerConfigs
T@"NSArray",R,V_layerConfigs
numberOfClasses
Ti,R,V_numberOfClasses
inputDimensions
T{CGSize=dd},R,V_inputDimensions
confidenceThresholds
T^d,R,V_confidenceThresholds
nmsThreshold
Td,R,V_nmsThreshold
inputFeatureValueName
T@"NSString",R,V_inputFeatureValueName
Invalid parameter for config.numberOfClasses: %i, numberOfClasses must be <= %i
CoreML output nil or not of type MLFeatureTypeMultiArray
shotflow
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
mlModel
T@"MLModel",R,V_mlModel
config
T@"HMIShotFlowConfig",R,V_config
com.apple.videotoolbox.videoencoder.h264.rtvc
encoderQueue
v8@?0
v24@?0i8I12^{opaqueCMSampleBuffer=}16
v24@?0@"HMICameraVideoResourceAttributes"8@"NSError"16
camera.video.encoder
encodedAssetData
T@"NSMutableData",&,V_encodedAssetData
bitRate
Ti,V_bitRate
codecType
TI,V_codecType
realTime
TB,V_realTime
HMISystemResourceUsageLevelLow
HMISystemResourceUsageLevelMed
HMISystemResourceUsageLevelHigh
HMISystemResourceUsageLevelUnknown
HMISystemResourceUsageLevelUndefined
systemResourceUsageLevel
Tq,N,V_systemResourceUsageLevel
delegate
T@"<HMISystemResourceUsageMonitorDelegate>",W
systemResourceUsageMonitorImpl
T@"HMISystemResourceUsageMonitorImpl",R,V_systemResourceUsageMonitorImpl
workQueue
T@"NSObject<OS_dispatch_queue>",R,V_workQueue
Frame@%llu
pixelBuffer
T^{__CVBuffer=},R,V_pixelBuffer
motionResult
T@"HMICameraVideoFrameMotionAnalysisResult",&,V_motionResult
presentationTime
T{?=qiIq},R,V_presentationTime
frameId
TQ,R,V_frameId
fragmentSequenceNumber
TQ,R,V_fragmentSequenceNumber
Invalid parameter for windowSize: %lu, windowSize must be > 0
lock
T@"HMFUnfairLock",R,N,V_lock
currentIndex
TQ,V_currentIndex
queue
T@"NSMutableArray",&,N,V_queue
windowSize
TQ,R,N,V_windowSize
movingAverage
Tf,V_movingAverage
Invalid parameter not satisfying: %@
Success
SystemResourceUsageHigh
InsufficentTime
AnyMotion
HKD://
%#{flags}
0x%x <%@>
duration
T{?=qiIq},V_duration
creationDate
T@"NSDate",&,V_creationDate
lastSequenceNumber
TQ,R,V_lastSequenceNumber
events
Tq,R,V_events
annotationScores
T@"NSDictionary",R,V_annotationScores
posterFrames
T@"NSArray",R,V_posterFrames
frameResults
T@"NSArray",R,V_frameResults
resultCode
Tq,V_resultCode
timeToAnalyzeFragment
Td,V_timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
Td,V_timeSinceFragmentWasSubmitted
videoFragment
T@"HMICameraVideoFragment",&,V_videoFragment
local
remote-frame
remote-fragment
serviceType
TQ,V_serviceType
startingMediaIntegritySequenceNumber
TQ,V_startingMediaIntegritySequenceNumber
transcodeFragment
TB,V_transcodeFragment
posterFrameGenerationInterval
TQ,R,V_posterFrameGenerationInterval
posterFrameHeight
TQ,R,V_posterFrameHeight
maxFragmentAnalysisDuration
Td,R,V_maxFragmentAnalysisDuration
maxFragmentDuration
Td,R,V_maxFragmentDuration
videoFrame
T@"HMICameraVideoFrame",R,V_videoFrame
detections
T@"NSArray",R,V_detections
frameWidth
TQ,R,V_frameWidth
frameHeight
TQ,R,V_frameHeight
fragment/%lu
fragmentData
T@"NSMutableData",R
T@"NSURL",R,V_url
analysisSubmissionTime
T@"NSDate",&,V_analysisSubmissionTime
sequenceNumber
TQ,R,V_sequenceNumber
data
T@"NSData",R,V_data
moovFragment
T@"NSData",R,N,V_moovFragment
eventTypes
Tq,R,V_eventTypes
[Fragment:%lu] analyzeFragment called
[Fragment:%lu] Session already ended, ignoring analysis
[Fragment:%lu] analysis failed because the XPC connection was interrupted, retrying.
Unknown delegate name: %@
v24@?0@"NSDictionary"8@"NSError"16
[Fragment:%lu] Transcoded fragment, original size: %lu, new size: %lu, compression ratio: %.2f
v24@?0@"NSData"8@"NSError"16
[Fragment:%lu] Start analysis, elapsed time since submission: %fs
[Fragment:%lu] Failed to start reading of the asset: %@
[Fragment:%lu] Video fragment duration : %fs is greater than expected value: %fs
[Fragment:%lu] Sequential media integrity of the media fragments violated expected seq num: %lu received seq num: %lu
[Fragment:%lu] End analysis: didNotAnalyze due to %@, elapsed time since submission: %fs
[Fragment:%lu] End analysis: didAnalyze, time spent: %fs, elapsed time since submission: %fs, significant events detected: %@
[Fragment:%lu] End analysis: didNotAnalyze due to %@, time spent: %fs, elapsed time since submission: %fs
Session already ended, clearing pending fragments
HMICameraVideoAnalyzer
[Fragment:%lu] Video fragment failed to read initial frame
[Fragment:%lu] assetReader readNextFrame: %lu took: %fs
[Fragment:%lu] Video fragment has no frames
[Fragment:%lu] Video frame buffer is nil
[Fragment:%lu] Failed to generate poster frame on %@
[Fragment:%lu] Failed to run frame selection on %@
[Fragment:%lu] Failed to read video frame
[Fragment:%lu] Frame selection & poster frame generation took: %fs
[Fragment:%lu] Remaining time available for analyzing frames: %fs
[Fragment:%lu] Motion Only, will not analyze any frames
[Fragment:%lu] Remaining time available after analyzing frames: %fs
[Fragment:%lu] Frame selector produced 0 frames for videoFragment:%@
[Fragment:%lu] About to analyze: %lu frames
[Fragment:%lu] Failed to run analysis on %@
[Fragment:%lu] Finished executing analysis for frame number: %lu, in time: %f
[Fragment:%lu] Stopping video fragment analysis due to high system resource usage
[Fragment:%lu] Stopping video fragment analysis due to analysis time past the maximum fragment analysis time: %fs
[Fragment:%lu] Stopping video fragment analysis due to remaining analysis time: %fs less than averageFrameAnalysisTime: %fs
[Fragment:%lu] Failed to run analysis on %lu
********** Resetting %@ to %d, frameEvents: %ld
HIGH
result
foundSignificantEvent
framesAnalyzedFragment
personDetected
petDetected
vehicleDetected
personScore
petScore
vehicleScore
sessionId
[Fragment:%lu] Uploading analytics event %@
com.apple.HomeKit.VideoAnalyzerStats
@"NSDictionary"8@?0
com.apple.HomeAI
homeai: %@
camera.video.analyzer
fpsSelector
T@"HMICameraVideoFPSSelector",R
averageTimeToAnalyzeFragment
T@"MovingAverage",R
systemResourceUsageMonitor
T@"HMISystemResourceUsageMonitor",&,V_systemResourceUsageMonitor
currentSystemResourceUsageLevel
Tq,V_currentSystemResourceUsageLevel
T@"NSLock",R,V_lock
mediaIntegritySequenceNumber
TQ,V_mediaIntegritySequenceNumber
skipSequentialMediaIntegrityCheck
TB,R,V_skipSequentialMediaIntegrityCheck
analysisInProgress
TB,GisAnalysisInProgress,V_analysisInProgress
inErrorState
TB,GisInErrorState,V_inErrorState
pendingRequests
T@"NSMutableArray",&,V_pendingRequests
posterFrameGenerator
T@"HMICameraVideoPosterFrameGenerator",&,V_posterFrameGenerator
videoAnalyzerConfiguration
T@"HMICameraVideoAnalyzerConfiguration",&,V_videoAnalyzerConfiguration
Tq,V_events
videoFrameResults
T@"NSMutableArray",&,V_videoFrameResults
fragmentAnalysisResultCode
Tq,V_fragmentAnalysisResultCode
remoteAnalysisService
T@"HMIAnalysisService",&,N,V_remoteAnalysisService
sessionEnded
TB,GisSessionEnded,V_sessionEnded
uploadVideoAnalysisEvent
TB,R,GshouldUploadVideoAnalysisEvent,V_uploadVideoAnalysisEvent
T@"<HMICameraVideoAnalyzerDelegate>",W,V_delegate
identifier
T@"NSUUID",R,C,V_identifier
SSDMobileNetV1
Initializing HMICameraVideoFrameAnalyzerFactory
Resetting VideoFrameAnalyzer
ShotFlow
Unsupported model %@
Failed to load video frame analyzer
Warm starting model...
warm_start_model
Failed to create pixel buffer when warm starting model
Failed to warm start model: %@
Warm start of model took: %f
camera.video.frame.analyzer.factory
sharedInstance
T@"HMICameraVideoFrameAnalyzerFactory",R
videoFrameAnalyzer
T@"<HMICameraVideoFrameAnalyzer>",&,N,V_videoFrameAnalyzer
watchdogTimer
T@"HMFTimer",R,V_watchdogTimer
Index: %d Confidence: %f rect: {x: %f, y: %f, width: %f, height: %f}
labelIndex
Ti,R,V_labelIndex
confidence
Td,R,V_confidence
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
q24@?0@"HMIObjectDetection"8@"HMIObjectDetection"16
featureNames
T@"NSSet",R,N
inputName
T@"NSString",R,V_inputName
timeOffset
T{?=qiIq},R,V_timeOffset
TQ,R,V_width
TQ,R,V_height
generationFrequency
T{?=qiIq},R,V_generationFrequency
[Fragment:%lu] Failed to generate poster frame for: %lu
camera.video.poster.frame.generator
posterFramesInternal
T@"NSMutableArray",&,V_posterFramesInternal
input
T@"HMICameraVideoPosterFrameGeneratorInput",R,V_input
nextGenerationTime
T{?=qiIq},V_nextGenerationTime
Current system resource usage level is: %@
Analysis time + time since submission: %f
New FPS multiplier is %f and analysisFPS is %f
camera.video.fps.selector
multiplier
Td,V_multiplier
maxAnalysisFPS
TQ,R,V_maxAnalysisFPS
Td,R,V_x
Td,R,V_y
anchors
T@"MLMultiArray",R,V_anchors
scaleFactors
T@"HMISSDScaleFactors",R,V_scaleFactors
coordinatesAxis
Ti,R,V_coordinatesAxis
coordinatesFeatureValueName
T@"NSString",R,V_coordinatesFeatureValueName
confidencesFeatureValueName
T@"NSString",R,V_confidencesFeatureValueName
T@"HMISSDConfig",R,V_config
[Fragment:%lu] frames initial width:%lu frames initial height:%lu number of frames to select:%lu
[Fragment:%lu] resized width:%lu resized height:%lu 
[Fragment:%lu] fragmentAnalysisFPS: %f fragmentNominalFrameRate: %f fragmentDuration: %f totalNumFramesInFragment: %lu numberFramesToSelect: %lu enable_optical_flow: %d
@min.self
camera.video.frame.selector
framesInternal
T@"NSMutableArray",&,V_framesInternal
totalNumberOfFramesInFragment
TQ,V_totalNumberOfFramesInFragment
numberFramesToAdvance
Tf,V_numberFramesToAdvance
nextFrameToSelectForAnalysis
Tf,V_nextFrameToSelectForAnalysis
currentFrameNumber
TQ,V_currentFrameNumber
numberFramesToSelect
TQ,V_numberFramesToSelect
enableOpticalFlow
TB,V_enableOpticalFlow
imageRequestHandler
T@"VNImageRequestHandler",&,V_imageRequestHandler
opticalFlowRequest
T@"VNGenerateOpticalFlowRequest",&,V_opticalFlowRequest
minRows
T@"NSMutableDictionary",&,V_minRows
maxRows
T@"NSMutableDictionary",&,V_maxRows
minCols
T@"NSMutableDictionary",&,V_minCols
maxCols
T@"NSMutableDictionary",&,V_maxCols
flowArray
T^f,V_flowArray
quantizedFrames
T@"NSMutableArray",&,V_quantizedFrames
connectedComponentsMap
T@"NSMutableArray",&,V_connectedComponentsMap
framesScore
T@"NSMutableArray",&,V_framesScore
TQ,V_frameWidth
TQ,V_frameHeight
frames
T@"NSArray",R,V_frames
analysisFPS
Td,R,V_analysisFPS
logIdentifier
T@"NSString",R,V_logIdentifier
HMIErrorDomain
Unexpected error
Failed to analyze
Failed to parse
Video analyzer in error state
Model failed to load
Fragment is invalid
No pixel buffer
Unknown error code %ld
HMIErrorCodeUnexpectedError
HMIErrorCodeFailedToAnalyze
HMIErrorCodeFailedToParse
HMIErrorCodeAnalyzerInErrorState
HMIErrorCodeModelFailedToLoad
HMIErrorCodeFragmentIsInvalid
HMIPrivateErrorCodeNilPixelBuffer
HMIPrivateErrorCodeEmptyURL
HMIPrivateErrorCodeAVAssetReaderInitializationFailed
HMIPrivateErrorCodeFailedToLoadProperty
HMIPrivateErrorCodeAssetLoadCancelled
HMIPrivateErrorCodeReadingStartFailed
HMIPrivateErrorCodeNoTrackOutput
HMIPrivateErrorCodeSampleBufferUnavailable
HMIPrivateErrorCodeNoVideoTrackFound
HMIPrivateErrorCodeMultipleVideoTracksFound
HMIPrivateErrorInvalidPresentationTime
HMIPrivateErrorAVAssetReaderNotStarted
HMIPrivateErrorCodeSequentialIntegrityViolated
HMIPrivateErrorCodeAnalysisServiceNoConfiguration
HMIPrivateErrorCodeLoadingCoreMLModelFailed
HMIPrivateErrorCodeCoreMLPredictionFailed
HMIPrivateErrorCodeCoreMLOutputIncorrect
HMIPrivateErrorCodeCropAndResizeFailed
HMIPrivateErrorCodePosterFrameGenerationFailed
HMIPrivateErrorCodeCodecNotAvailable
ERROR_%ld
%@: %@
resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorProtocol>",R,V_resourceUsageMonitor
T@"<HMISystemResourceUsageMonitorDelegate>",W,Vdelegate
movingObjectCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,V_movingObjectCropRect
motionScore
Tf,R,V_motionScore
mlmodelc
ssd_predictions_block8_offset
ssd_predictions_block8_class_prob
ssd_predictions_block7_offset
ssd_predictions_block7_class_prob
ssd_predictions_block6_offset
ssd_predictions_block6_class_prob
ssd_predictions_block9_offset
ssd_predictions_block9_class_prob
ssd_predictions_block10_offset
ssd_predictions_block10_class_prob
ssd_predictions_block11_offset
ssd_predictions_block11_class_prob
inputImage
HMICameraVideoFrameAnalyzerShotFlow
camera.video.frame.analyzer.shotflow
T@"NSDictionary",R
Tq,R
T@"NSArray",R
classHierarchyMap
shotFlow
T@"HMIShotFlow",R,V_shotFlow
classLabelsToEvents
T@"NSDictionary",R,V_classLabelsToEvents
T@"NSDictionary",&,V_annotationScores
T@"NSArray",&,V_detections
transaction
T@"HMFOSTransaction",&,N,V_transaction
assetDuration
T{?=qiIq},R,V_assetDuration
T@"NSDate",R,V_creationDate
firstSequenceNumber
TQ,R,V_firstSequenceNumber
nominalFrameRate
Td,R,V_nominalFrameRate
tracks
firstFragmentSequenceNumber
fragmentCount
timeRange
formatDescriptions
[Fragment:%lu] Creating asset with url: %@
[Fragment:%lu] Failed to initialize AVAssetReader
[Fragment:%lu] Start %0.2f, Duration %0.2f, FPS %0.2f
[Fragment:%lu] No fragment URL found on loading request %@
[Fragment:%lu] No fragment data found for URL %@
[Fragment:%lu] Finished handling load request
camera.video.asset.reader
currentFrameId
TQ,V_currentFrameId
assetReader
T@"AVAssetReader",&,N,V_assetReader
resourceLoaderWorkQueue
T@"NSObject<OS_dispatch_queue>",R,V_resourceLoaderWorkQueue
T@"HMICameraVideoFragment",R,V_videoFragment
HMICVFR.fi
HMICVFR.e
HMICVFR.as
HMICVFR.d
HMICVFR.fw
HMICVFR.fh
HMICVAR.e
HMICVAR.rc
HMICVAR.fr
HMICVAR.as
HMICVAR.cd
HMICVAR.d
HMICVAR.pf
HMICVAR.ttaf
HMICVAR.tsfws
HMICVAR.lsn
HMICVAR.vf
HMICVAC.pfgi
HMICVAC.pfh
HMICVAC.mfad
HMICVAC.mfd
HMICVAC.st
HMICVAC.smisn
HMICVAC.tf
HMICVASE.e
HMICVASE.vf
HMICVF.et
HMICVF.sn
HMICVF.mf
HMICVF.d
HMICVF.ast
HMICVPF.d
HMICVPF.to
HMICVPF.w
HMICVPF.h
HMICVFMAR.ms
HMICVFMAR.mocrx
HMICVFMAR.mocry
HMICVFMAR.mocrw
HMICVFMAR.mocrh
HMIOD.l
HMIOD.c
HMIOD.b.x
HMIOD.b.y
HMIOD.b.w
HMIOD.b.h
supportsSecureCoding
TB,R
HMICameraVideoFrame does not support NSSecureCoding in the simulator
configuration
preferenceOverrides
videoAnalyzerIdentifier
didAnalyzeFragment
didNotAnalyzeFragment
didFindSignificantEvent
significantEvents
HMIAnalysisServiceTypeUnknown
HMIAnalysisServiceTypeLocal
HMIAnalysisServiceTypeRemoteFrame
HMIAnalysisServiceTypeRemoteFragment
HMIAnalysisServiceTypeUndefined
v24@?0@"HMICameraVideoFragment"8@"HMICameraVideoAnalyzerResult"16
v24@?0@"HMICameraVideoFragment"8@"NSError"16
T@?,C,N,V_didAnalyzeFragment
didFailAnalysisForFragment
T@?,C,N,V_didFailAnalysisForFragment
T@?,C,N,V_didFindSignificantEvent
T@?,C,N,V_didNotAnalyzeFragment
HMIAnalysisService
Remote analysis not supported in the simulator
Pixel buffer is ignored if the video frame is passed through the properties dictionary
Asset data is ignored if the video fragment is passed through the properties dictionary
Analyzer configuration property key (%@) is missing
v24@?0@"HMICameraVideoAnalyzerSignificantEvent"8@"HMICameraVideoFragment"16
camera.video.analysis.service
runRemotely
TB,V_runRemotely
com.apple.homed
analysisServiceType
enableFPSSelector
analysisEnableOpticalFlow
processingDevice
model
confidenceThresholdPerson
confidenceThresholdPet
confidenceThresholdVehicle
modelTimeout
assetReaderForceBGRA
shouldLoadBaseDecodeTimestampAssetProperty
analysisEnableTranscodeFragment
syntheticRemoteAnalysisError
Preference %@ is now %@, previously was %@
Only NSNumber and NSString properties are supported.
HMIPreference
T@"HMIPreference",R
preferenceLoggedValues
T@"NSMutableDictionary",R,N,V_preferenceLoggedValues
preferenceOverridesInternal
T@"NSMutableDictionary",R,N,V_preferenceOverridesInternal
Already started listening for the notification
v12@?0i8
HMINotifydObserver
T@"NSObject<OS_dispatch_queue>",R,N,V_queue
callback
T@?,R,N,V_callback
token
Ti,N,V_token
notificationName
Tr*,R,N,V_notificationName
com.apple.HomeAI.%@%@%@.%tu
ssd_mobilenet_v1
Preprocessor__sub__0
concat__0
concat_1__0
HMICameraVideoFrameAnalyzerSSDMobileNetV1
camera.video.frame.analyzer.ssd
T@"HMISSD",R,V_ssd
T@"NSMutableDictionary",&,V_annotationScores
T@"NSMutableArray",&,V_detections
T^{__CVBuffer=},N,V_Preprocessor__sub__0
T@"MLMultiArray",&,N,V_concat__0
T@"MLMultiArray",&,N,V_concat_1__0
T@"MLModel",R,N,V_model
%{public}@%{public}@
HMIShotFlowBoxSize
HMIShotFlowLayerConfig
HMIShotFlowConfig
HMIShotFlow
HMFLogging
NSObject
HMICameraVideoEncoder
AVAssetWriterDelegate
HMISystemResourceUsage
HMISystemResourceUsageMonitor
HMISystemResourceUsageMonitorProtocol
HMICameraVideoFrame
HMIVisionUtilities
MovingAverage
HMICameraVideoAnalyzerResult
HMICameraVideoAnalyzerConfiguration
NSCopying
HMICameraVideoAnalyzerSignificantEvent
HMICameraVideoFrameResult
HMICameraVideoFragment
HMICameraVideoAnalyzer
HMISystemResourceUsageMonitorDelegate
HMICameraVideoFrameAnalyzerFactory
HMFTimerDelegate
HMIObjectDetection
HMIObjectDetectionUtils
HMIInputFeatureProvider
MLFeatureProvider
HMICameraVideoPosterFrame
HMICameraVideoPosterFrameGeneratorInput
HMICameraVideoPosterFrameGenerator
HMICameraVideoFPSSelector
HMISSDScaleFactors
HMISSDConfig
HMIConfidenceLabelPair
HMISSD
HMICameraVideoFrameSelector
HMIError
HMISystemResourceUsageMonitorImpl
HMICameraVideoFrameMotionAnalysisResult
HMICameraVideoFrameAnalyzerShotFlow
HMICameraVideoFrameAnalyzer
HMICameraVideoResourceAttributes
HMICameraVideoAssetReader
AVAssetResourceLoaderDelegate
NSCoding
NSSecureCoding
HMICameraVideoAnalyzerDelegateAdapter
HMICameraVideoAnalyzerDelegate
HMIAnalysisService
HMIPreference
HMINotifydObserver
HMICameraVideoFrameAnalyzerSSDMobileNetV1
ssd_mobilenet_v1Input
ssd_mobilenet_v1Output
ssd_mobilenet_v1
init
initWithWidth:height:
width
height
_width
_height
initWithLayerNumber:offsetsFeatureValueName:scoresFeatureValueName:stride:defaultBoxCount:cellStartX:cellStartY:scale:
.cxx_destruct
layerNumber
offsetsFeatureValueName
scoresFeatureValueName
stride
defaultBoxCount
cellStartX
cellStartY
scale
_cellStartX
_cellStartY
_scale
_layerNumber
_offsetsFeatureValueName
_scoresFeatureValueName
_stride
_defaultBoxCount
_generateDefaultBoxesSizesFromLayerConfigs:ratios:
count
arrayWithCapacity:
objectAtIndexedSubscript:
array
numberWithDouble:
arrayWithObject:
_generateSubscalesForBaseScale:nextScale:count:
addObjectsFromArray:
arrayWithArray:
countByEnumeratingWithState:objects:count:
doubleValue
addObject:
copy
initWithLayerConfigs:ratios:numberOfClasses:inputDimensions:confidenceThresholds:nmsThreshold:inputFeatureValueName:
ratios
layerConfigs
numberOfClasses
inputDimensions
confidenceThresholds
nmsThreshold
inputFeatureValueName
defaultBoxesSizes
_numberOfClasses
_ratios
_layerConfigs
_confidenceThresholds
_nmsThreshold
_inputFeatureValueName
_defaultBoxesSizes
_inputDimensions
stringWithFormat:
exceptionWithName:reason:userInfo:
config
cropAndResizePixelBuffer:rect:size:error:
hmiPrivateErrorWithCode:underlyingError:
initWithPixelBuffer:inputName:
sharedInstance
numberWithBool:
dictionaryWithObjects:forKeys:count:
numberPreferenceForKey:defaultValue:withMap:
boolValue
setUsesCPUOnly:
mlModel
predictionFromFeatures:options:error:
featureValueForName:
type
hmiPrivateErrorWithCode:description:
multiArrayValue
_decodeOffsets:withScores:toPredictions:config:
nmsMultiClass:output:withThreshold:
convertObjectDetections:cropRect:originalImageSize:output:
shape
unsignedIntegerValue
dataPointer
strides
init:confidence:boundingBox:
categoryWithName:
logCategory
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
logIdentifier
initWithMLModel:config:
predict:cropRect:detectedObjects:error:
_mlModel
_config
encodedAssetData
appendData:
numberWithUnsignedInt:
mutableCopy
codecType
realTime
numberWithInt:
setObject:forKey:
bitRate
data
setEncodedAssetData:
initWithFileType:error:
setDelegate:
assetWriterInputWithMediaType:outputSettings:
addInput:
startWriting
startSessionAtSourceTime:
initWithSequenceNumber:fragmentData:eventTypes:
readerForVideoFragment:workQueue:logIdentifier:
isReadyForMoreMediaData
readNextFrame:error:
markAsFinished
status
error
finishWritingWithCompletionHandler:
pixelBuffer
createCompressionSessionWithWidth:height:
hmiPrivateErrorWithCode:
presentationTime
appendSampleBuffer:
requestMediaDataWhenReadyOnQueue:usingBlock:
startReading:
assetWriter:didProduceFragmentedHeaderData:
assetWriter:didProduceFragmentedMediaData:fragmentedMediaDataReport:
encodeWithAssetData:completionHandler:
setBitRate:
setCodecType:
setRealTime:
_realTime
_bitRate
_codecType
_encodedAssetData
systemResourceUsageLevel
setSystemResourceUsageLevel:
_systemResourceUsageLevel
UTF8String
productInfo
productClass
initWithProductClass:workQueue:
workQueue
systemResourceUsageMonitorImpl
delegate
getCurrentSystemResourceUsage
start
_systemResourceUsageMonitorImpl
_workQueue
initWithPixelBuffer:presentationTime:frameId:fragmentSequenceNumber:
imageWithCVPixelBuffer:
imageByApplyingTransform:
JPEGRepresentationOfImage:colorSpace:options:
extent
motionResult
movingObjectCropRect
cropPixelBuffer:cropRect:error:
dealloc
initWithPixelBuffer:
JPEGRepresentationWithDownscaleFactor:outSize:
getCroppedPixelBuffer:
frameId
fragmentSequenceNumber
setMotionResult:
_frameId
_fragmentSequenceNumber
_pixelBuffer
_motionResult
_presentationTime
createIOSurfaceBackedPixelBufferWithWidth:height:pixelBuffer:
imageWithCVImageBuffer:
imageByCroppingToRect:
contextWithOptions:
render:toCVPixelBuffer:
null
dictionaryWithObjectsAndKeys:
imageWithCVImageBuffer:options:
resizePixelBuffer:resultSize:error:
windowSize
floatValue
queue
movingAverage
setMovingAverage:
currentIndex
setObject:atIndexedSubscript:
setCurrentIndex:
initWithWindowSize:
addNumber:
lock
setQueue:
_movingAverage
_lock
_currentIndex
_queue
_windowSize
performBlock:
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:resultCode:lastSequenceNumber:
events
resultCode
lastSequenceNumber
duration
creationDate
frameResults
isEqualToArray:
annotationScores
isEqualToDictionary:
posterFrames
videoFragment
timeToAnalyzeFragment
timeSinceFragmentWasSubmitted
initWithEvents:posterFrames:frameResults:annotationScores:duration:creationDate:
initWithEvents:posterFrames:frameResults:duration:creationDate:
isEqual:excludeTime:
setDuration:
setCreationDate:
setResultCode:
setTimeToAnalyzeFragment:
setTimeSinceFragmentWasSubmitted:
setVideoFragment:
_events
_annotationScores
_posterFrames
_frameResults
_creationDate
_resultCode
_timeToAnalyzeFragment
_timeSinceFragmentWasSubmitted
_videoFragment
_lastSequenceNumber
_duration
getAnalysisServiceTypePreference
boolPreferenceForKey:defaultValue:
numberWithUnsignedInteger:
integerValue
allocWithZone:
initWithPosterFrameGenerationInterval:posterFrameHeight:maxFragmentAnalysisDuration:maxFragmentDuration:
copyWithZone:
posterFrameGenerationInterval
posterFrameHeight
maxFragmentAnalysisDuration
maxFragmentDuration
serviceType
setServiceType:
startingMediaIntegritySequenceNumber
setStartingMediaIntegritySequenceNumber:
transcodeFragment
setTranscodeFragment:
_transcodeFragment
_posterFrameGenerationInterval
_posterFrameHeight
_maxFragmentAnalysisDuration
_maxFragmentDuration
_serviceType
_startingMediaIntegritySequenceNumber
initWithEvents:videoFrame:
videoFrame
_videoFrame
initWithFrameId:events:annotationScores:detections:frameWidth:frameHeight:
detections
frameWidth
frameHeight
_detections
_frameWidth
_frameHeight
initWithSequenceNumber:data:moovFragment:eventTypes:
date
moovFragment
length
initWithData:
sequenceNumber
stringByAppendingFormat:
URLWithString:
absoluteString
initWithSequenceNumber:data:moovFragment:
fragmentData
eventTypes
analysisSubmissionTime
setAnalysisSubmissionTime:
_url
_sequenceNumber
_data
_moovFragment
_eventTypes
_analysisSubmissionTime
getAnalysisFPSPreference
initWithAnalysisFPS:
unlock
initWithGenerationFrequency:andPosterFrameHeight:
initWithInput:
uploadVideoAnalysisEventPreference
setSystemResourceUsageMonitor:
systemResourceUsageMonitor
setCurrentSystemResourceUsageLevel:
internal
_analyzeIfPossible:
isSessionEnded
isInErrorState
hmiErrorWithCode:
_handleError:videoFragment:
videoAnalyzerConfiguration
isAnalysisInProgress
pendingRequests
_analyze:
setSessionEnded:
setRunRemotely:
mediaIntegritySequenceNumber
remoteAnalysisService
identifier
preferenceOverrides
numberPreferenceForKey:defaultValue:
intValue
initWithDomain:code:userInfo:
objectForKeyedSubscript:
analyzer:didFindSignificantEvent:inFragment:
code
_analyzeFragmentRemotely:retryOnConnectionInterruption:
isEqualToString:
analyzer:didAnalyzeFragment:withResult:
setMediaIntegritySequenceNumber:
analyzer:didNotAnalyzeFragment:withResult:
_handlePendingRequestsIfNeeded
requestAnalysisForAssetData:withProperties:andCompletionHandler:
setAnalysisInProgress:
warmStartModel
timeIntervalSinceDate:
_createSystemResourceUsageMonitor
setFragmentAnalysisResultCode:
hmiErrorWithCode:description:underlyingError:
assetDuration
hmiErrorWithCode:description:
skipSequentialMediaIntegrityCheck
firstSequenceNumber
computeRemainingAnalysisTimeFromStartTime:
fragmentAnalysisResultCode
_handleDidNotAnalyzeVideoFragment:attributes:timeToAnalyzeFragment:
_analyzeVideoHavingAttributes:usingReader:error:
videoFrameResults
videoAnnotationScoresForFrameResult:
averageTimeToAnalyzeFragment
posterFrameGenerator
transcodeFragment:
_sendAnalyticsEventForFragment:result:
setInErrorState:
analyzer:didFailAnalysisForFragment:withError:
_sendAnalyticsEventForFragment:error:
_failPendingRequests
removeAllObjects
firstObject
removeObject:
initWithName:
setVideoFrameResults:
setEvents:
fpsSelector
getSystemResourceUsageLevel
getAnalysisFPSForAverageAnalysisTime:timeSinceFragmentWasSubmitted:duration:currentSystemResourceUsageLevel:
initWithAnalysisFPS:logIdentifier:
startHandlingFramesFromVideoResource:fragmentSequenceNumber:frameWidth:frameHeight:
startHandlingFrames
nominalFrameRate
shouldContinueAnalysis:analysisStartTime:fragmentSequenceNumber:
willHandleFrames
willHandleFramesFromVideoResource:
handleVideoFrame:error:
_analyzeFramesFromFragment:frameSelector:error:
hmiErrorWithCode:underlyingError:
frames
analyzeVideoFrame:videoFragment:error:events:
analyze:runRemotely:error:
resetFrameEvents:
numberWithInteger:
initWithKey:options:domain:defaultValue:
value
objectForKey:
getSystemResourceUsageLevelPreference
currentSystemResourceUsageLevel
UUIDString
shouldUploadVideoAnalysisEvent
numberWithFloat:
string
bundleWithIdentifier:
infoDictionary
appendFormat:
queryVersionInformation
systemResourceUsageDidChangeTo:
initWithConfiguration:identifier:
analyzeFragment:
clearPendingFragments
setPendingRequests:
setPosterFrameGenerator:
setVideoAnalyzerConfiguration:
setRemoteAnalysisService:
_skipSequentialMediaIntegrityCheck
_analysisInProgress
_inErrorState
_sessionEnded
_uploadVideoAnalysisEvent
_currentSystemResourceUsageLevel
_delegate
_identifier
_systemResourceUsageMonitor
_mediaIntegritySequenceNumber
_pendingRequests
_posterFrameGenerator
_videoAnalyzerConfiguration
_videoFrameResults
_fragmentAnalysisResultCode
_remoteAnalysisService
alloc
setVideoFrameAnalyzer:
watchdogTimer
suspend
assertOwner
kick
getMLModelPreference
getConfidenceThresholdPreferenceForKey:defaultConfidenceThreshold:
caseInsensitiveCompare:
initWithConfidenceThresholds:nmsThreshold:error:
resume
modelTimeoutPreference
initWithTimeInterval:options:
requestAnalysisForPixelBuffer:withProperties:andCompletionHandler:
videoFrameAnalyzer
classify:error:
stringPreferenceForKey:defaultValue:
timerDidFire:
_videoFrameAnalyzer
_watchdogTimer
labelIndex
confidence
boundingBox
_labelIndex
_confidence
_boundingBox
sortedArrayUsingComparator:
setObject:forKeyedSubscript:
nonMaximumSuppression:output:withThreshold:
intersectionOverUnion:b:
inputName
arrayWithObjects:count:
setWithArray:
featureValueWithPixelBuffer:
featureNames
_inputName
initWithData:timeOffset:width:height:
timeOffset
_timeOffset
generationFrequency
_generationFrequency
posterFramesInternal
input
nextGenerationTime
setNextGenerationTime:
saveAsPosterFrame:error:
setPosterFramesInternal:
_posterFramesInternal
_input
_nextGenerationTime
multiplier
maxAnalysisFPS
setMultiplier:
_multiplier
_maxAnalysisFPS
initWithX:y:width:height:
initWithAnchors:scaleFactors:inputDimensions:confidenceThresholds:nmsThreshold:coordinatesAxis:inputFeatureValueName:offsetsFeatureValueName:scoresFeatureValueName:
anchors
scaleFactors
coordinatesAxis
coordinatesFeatureValueName
confidencesFeatureValueName
_coordinatesAxis
_anchors
_scaleFactors
_coordinatesFeatureValueName
_confidencesFeatureValueName
initWithConfidence:forLabelIndex:
_decodeCoordinates:withConfidences:toPredictions:config:
_decodeBox:withAnchor:scales:
_clampBox:
framesInternal
flowArray
setTotalNumberOfFramesInFragment:
setFrameWidth:
setFrameHeight:
analysisFPS
setNumberFramesToSelect:
setNumberFramesToAdvance:
setCurrentFrameNumber:
setNextFrameToSelectForAnalysis:
getEnableOpticalFlowPreference
setEnableOpticalFlow:
enableOpticalFlow
getScaledFrameWidth
getScaledFrameHeight
minRows
minCols
maxRows
maxCols
connectedComponentsMap
quantizedFrames
framesScore
numberFramesToSelect
initWithCapacity:
setFlowArray:
totalNumberOfFramesInFragment
currentFrameNumber
initWithCVPixelBuffer:options:
setImageRequestHandler:
imageResize:to:
initWithTargetedCVPixelBuffer:options:
setOpticalFlowRequest:
imageRequestHandler
opticalFlowRequest
performRequests:error:
results
computeFlowMagnitudeMatrixFromOriginal:error:
quantizedAndBinarizeFrame:frame_height:error:
connectedComponents
unionTheRegoins
allKeys
applyPaddingIndex:
initWithCropRect:motionScore:
valueForKeyPath:
indexOfObject:
nextFrameToSelectForAnalysis
numberFramesToAdvance
getScaleFactorWidth
getScaleFactorHeight
removeObjectForKey:
imageWithCVPixelBuffer:options:
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
allObjects
containsObject:
setFramesInternal:
setMinRows:
setMaxRows:
setMinCols:
setMaxCols:
setQuantizedFrames:
setConnectedComponentsMap:
setFramesScore:
_enableOpticalFlow
_numberFramesToAdvance
_nextFrameToSelectForAnalysis
_frames
_logIdentifier
_analysisFPS
_framesInternal
_totalNumberOfFramesInFragment
_currentFrameNumber
_numberFramesToSelect
_imageRequestHandler
_opticalFlowRequest
_minRows
_maxRows
_minCols
_maxCols
_flowArray
_quantizedFrames
_connectedComponentsMap
_framesScore
dictionary
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
_hmiErrorWithCode:description:reason:suggestion:underlyingError:
hmiPrivateErrorWithCode:description:underlyingError:
resourceUsageMonitor
_resourceUsageMonitor
motionScore
_motionScore
_movingObjectCropRect
bundleForClass:
pathForResource:ofType:
fileURLWithPath:
modelWithContentsOfURL:error:
shotFlow
classHierarchyMap
setAnnotationScores:
setDetections:
classLabelsToEvents
transaction
setTransaction:
_shotFlow
_classLabelsToEvents
_transaction
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:
initWithAssetDuration:creationDate:
initWithAssetDuration:creationDate:firstSequenceNumber:lastSequenceNumber:nominalFrameRate:
_firstSequenceNumber
_nominalFrameRate
_assetDuration
initWithVideoFragment:workQueue:logIdentifier:
assetWithURL:
resourceLoader
resourceLoaderWorkQueue
setDelegate:queue:
initWithAsset:error:
setAssetReader:
assetReader
assetKeys
_propertiesLoadedForAsset:resultCallback:
loadValuesAsynchronouslyForKeys:completionHandler:
fragments
lastObject
statusOfValueForKey:error:
_didKeyValueLoadFailed:
tracksWithMediaType:
trackKeys
_propertiesLoadedForTrack:fromAsset:resultCallback:
timeRange
initWithTrack:outputSettings:
setAlwaysCopiesSampleData:
addOutput:
startReading
_validateSequentialIntegrityOfFragmentsInAsset:
_sequenceNumberOfLastFragmentInAsset:
_sequenceNumberOfFirstFragmentInAsset:
dateValue
outputs
objectAtIndex:
copyNextSampleBuffer
currentFrameId
setCurrentFrameId:
request
finishLoadingWithError:
contentInformationRequest
setContentLength:
setContentType:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestsAllDataToEndOfResource
requestedLength
subdataWithRange:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
_currentFrameId
_assetReader
_resourceLoaderWorkQueue
decodeIntegerForKey:
decodeObjectOfClasses:forKey:
decodeObjectOfClass:forKey:
decodeCMTimeForKey:
decodeDoubleForKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeCMTime:forKey:
encodeDouble:forKey:
initWithCoder:
encodeWithCoder:
supportsSecureCoding
decodeBoolForKey:
encodeBool:forKey:
isEqualToDate:
isEqualToData:
decodeIntForKey:
encodeInt:forKey:
decodeFloatForKey:
encodeFloat:forKey:
_finish
didAnalyzeFragment
didFailAnalysisForFragment
didFindSignificantEvent
didNotAnalyzeFragment
setDidAnalyzeFragment:
setDidFailAnalysisForFragment:
setDidNotAnalyzeFragment:
setDidFindSignificantEvent:
_didAnalyzeFragment
_didFailAnalysisForFragment
_didFindSignificantEvent
_didNotAnalyzeFragment
runRemotely
removeAllPreferenceOverrides
addPreferenceOverrideFromDictionary:
UUID
expectedClasses
cancelRequest:
_runRemotely
preferenceOverridesInternal
addEntriesFromDictionary:
preferenceLoggedValues
systemPreferenceValueForKey:
logPreferenceForKey:value:
numberPreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withParser:
valuePreferenceForKey:defaultValue:withMap:
_preferenceLoggedValues
_preferenceOverridesInternal
setNumberStyle:
numberFromString:
token
notificationName
publishValueForToken:
publishInitialValue
setToken:
callback
initWithNotificationName:andQueue:andCallback:
_token
_notificationName
_callback
modelDescription
metadata
dataUsingEncoding:
JSONObjectWithData:options:error:
initWithShape:dataType:error:
_ssd
initWithPreprocessor__sub__0:
Preprocessor__sub__0
setPreprocessor__sub__0:
_Preprocessor__sub__0
featureValueWithMultiArray:
initWithConcat__0:concat_1__0:
concat__0
setConcat__0:
concat_1__0
setConcat_1__0:
_concat__0
_concat_1__0
urlOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
modelWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
initWithFeatureProviderArray:
predictionsFromBatch:options:error:
featuresAtIndex:
initWithConfiguration:error:
predictionFromPreprocessor__sub__0:error:
predictionsFromInputs:options:error:
model
_model
@32@0:8d16d24
d16@0:8
@68@0:8Q16@24@32Q40Q48f56f60f64
v16@0:8
Q16@0:8
@16@0:8
f16@0:8
@"NSString"
@76@0:8@16@24i32{CGSize=dd}36^d52d60@68
@32@0:8@16@24
@40@0:8d16d24Q32
i16@0:8
{CGSize=dd}16@0:8
^d16@0:8
@"NSArray"
{CGSize="width"d"height"d}
v48@0:8@16@24@32@40
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"HMFLogCategory"16@0:8
B72@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^@64
@"MLModel"
@"HMIShotFlowConfig"
v32@0:8@16@24
v40@0:8@16@24@32
v32@0:8@"AVAssetWriter"16@"NSData"24
v40@0:8@"AVAssetWriter"16@"NSData"24@"AVFragmentedMediaDataReport"32
^{OpaqueVTCompressionSession=}24@0:8i16i20
v32@0:8@16@?24
v20@0:8i16
I16@0:8
v20@0:8I16
v20@0:8B16
v24@0:8@16
@"NSMutableData"
q16@0:8
v24@0:8q16
@"HMISystemResourceUsage"16@0:8
@"<HMISystemResourceUsageMonitorDelegate>"16@0:8
v24@0:8@"<HMISystemResourceUsageMonitorDelegate>"16
@"HMISystemResourceUsageMonitorImpl"
@"NSObject<OS_dispatch_queue>"
@24@0:8^{__CVBuffer=}16
@64@0:8^{__CVBuffer=}16{?=qiIq}24Q48Q56
@28@0:8f16^{CGSize=dd}20
^{__CVBuffer=}24@0:8^@16
{?=qiIq}16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
@"HMICameraVideoFrameMotionAnalysisResult"
{?="value"q"timescale"i"flags"I"epoch"q}
^{__CVBuffer=}64@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
^{__CVBuffer=}48@0:8^{__CVBuffer=}16{CGSize=dd}24^@40
^{__CVBuffer=}80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56^@72
i40@0:8Q16Q24^^{__CVBuffer}32
@24@0:8Q16
v20@0:8f16
v24@0:8Q16
@"HMFUnfairLock"
@"NSMutableArray"
@96@0:8q16@24@32@40{?=qiIq}48@72q80Q88
@80@0:8q16@24@32@40{?=qiIq}48@72
@72@0:8q16@24@32{?=qiIq}40@64
B28@0:8@16B24
v40@0:8{?=qiIq}16
v24@0:8d16
@"NSDictionary"
@"NSDate"
@"HMICameraVideoFragment"
@24@0:8^{_NSZone=}16
@48@0:8Q16Q24d32d40
@32@0:8q16@24
@"HMICameraVideoFrame"
@64@0:8Q16q24@32@40Q48Q56
@40@0:8Q16@24@32
@48@0:8Q16@24@32q40
@40@0:8Q16@24q32
@"NSURL"
@"NSData"
v28@0:8@16B24
@24@0:8@16
v40@0:8@16@24d32
B40@0:8@16@24^@32
d24@0:8@16
B36@0:8f16@20Q28
B48@0:8@16@24^@32^q40
q24@0:8q16
@"<HMICameraVideoAnalyzerDelegate>"
@"NSUUID"
@"HMISystemResourceUsageMonitor"
@"NSLock"
@"HMICameraVideoPosterFrameGenerator"
@"HMICameraVideoAnalyzerConfiguration"
@"HMIAnalysisService"
v24@0:8@"HMFTimer"16
@36@0:8@16B24^@28
@32@0:8@16d24
@"<HMICameraVideoFrameAnalyzer>"
@"HMFTimer"
@60@0:8i16d20{CGRect={CGPoint=dd}{CGSize=dd}}28
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
v80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56@72
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@32@0:8^{__CVBuffer=}16@24
@64@0:8@16{?=qiIq}24Q48Q56
@48@0:8{?=qiIq}16Q40
B32@0:8@16^@24
@"HMICameraVideoPosterFrameGeneratorInput"
d64@0:8d16d24{?=qiIq}32q56
@48@0:8d16d24d32d40
@92@0:8@16@24{CGSize=dd}32^d48d56i64@68@76@84
@"MLMultiArray"
@"HMISSDScaleFactors"
@28@0:8d16i24
{CGRect={CGPoint=dd}{CGSize=dd}}88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"HMISSDConfig"
@32@0:8d16@24
v48@0:8@16Q24Q32Q40
f32@0:8^{__CVBuffer=}16^@24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
B40@0:8Q16Q24^@32
^f16@0:8
v24@0:8^f16
@"VNImageRequestHandler"
@"VNGenerateOpticalFlowRequest"
@"NSMutableDictionary"
@56@0:8Q16@24@32@40@48
@24@0:8q16
@40@0:8q16@24@32
@"<HMISystemResourceUsageMonitorDelegate>"
@"<HMISystemResourceUsageMonitorProtocol>"
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
@40@0:8^{NSDictionary=#}16d24^@32
B32@0:8@"HMICameraVideoFrame"16^@24
@"NSDictionary"16@0:8
@"NSArray"16@0:8
@40@0:8@16d24^@32
[20d]
@"HMIShotFlow"
@"HMFOSTransaction"
@64@0:8{?=qiIq}16@40Q48Q56
@48@0:8{?=qiIq}16@40
@72@0:8{?=qiIq}16@40Q48Q56d64
@40@0:8@16@24@32
B32@0:8@16@24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v24@0:8@?16
Q24@0:8@16
v40@0:8@16@24@?32
B32@0:8^@16^@24
@"AVAssetReader"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"HMICameraVideoAnalyzerResult"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoAnalyzerSignificantEvent"24@"HMICameraVideoFragment"32
v40@0:8@"HMICameraVideoAnalyzer"16@"HMICameraVideoFragment"24@"NSError"32
@?16@0:8
i40@0:8^{__CVBuffer=}16@24@?32
i40@0:8@16@24@?32
B20@0:8i16
@40@0:8@16@24@?32
@40@0:8r*16@24@?32
r*16@0:8
[91d]
@"HMISSD"
v24@0:8^{__CVBuffer=}16
@32@0:8@16^@24
@40@0:8@16@24^@32
@32@0:8^{__CVBuffer=}16^@24
