giP9giP9giP9giP9
giP9
BNNS SoftMax: sum result shouldn't be 0, something is wrong
BNNS BroadcastMatMul: Only supports Float32 data types
BNNS BroadcastMatMul: Unsupported layout inputA->layout=%x
BNNS BroadcastMatMul: Unsupported layout inputB->layout=%x
BNNS BroadcastMatMul: Unsupported layout output->layout=%x
BNNS BroadcastMatMul: Inconsistent tensor dimensions. A has dimension %u, B has dimension %u, C has dimension %u
BNNS BroadcastMatMul: inputA->stride[0] = %zu, but must be >= 1.
BNNS BroadcastMatMul: inputA->stride[%u] = %zu, but must be >= inputA->size[%u] * inputA->stride[%u] = %zu * %zu = %zu.
BNNS BroadcastMatMul: inputB->stride[0] = %zu, but must be >= 1.
BNNS BroadcastMatMul: inputB->stride[%u] = %zu, but must be >= inputB->size[%u] * inputB->stride[%u] = %zu * %zu = %zu.
BNNS BroadcastMatMul:output->stride[0] = %zu, but must be >= 1.
BNNS BroadcastMatMul:output->stride[%u] = %zu, but must be >= output->size[%u] * output->stride[%u] = %zu * %zu = %zu.
BNNS BroadcastMatMul: Require one matrix multiplication dimension in inputA to have stride 1. inputA->stride[%u]=%zu, inputA->stride[%u]=%zu
BNNS BroadcastMatMul: Require one matrix multiplication dimension in inputB to have stride 1. inputB->stride[%u]=%zu, inputB->stride[%u]=%zu
BNNS BroadcastMatMul: Require one matrix result dimension in output to have stride 1. output->stride[%u]=%zu, output->stride[%u]=%zu
BNNS BroadcastMatMul: inconsistent final dimensions A%s is %zux%zu, B%s is %zux%zu, C is %zux%zu
BNNS BroadcastMatMul: broadcasting dimensions do not match.inputA->size[%d]=%zu, inputB->size[%d]=%zu, output->size[%d]=%zu.
BNNS BroadcastMatMul: Requires workspace of size %ld, exceeds limit of size %d.
v16@?0Q8
%s: 
BNNS Convolution version2 error: minimum float w_pack weight packing value is 32
BNNS Dequantize: input and output can't be null
BNNS Dequantize: in place conversion not supported
BNNS Dequantize: only __fp16 output is supported
BNNS Dequantize: lut is null and needed for Indexed input type
BNNS Dequantize: input type not supported
BNNS Fully Connected Apply: allocation of work buffer failed
BNNS Fully Connected: Unexpected result, should be at least 1
BNNS Fully Connected: Unexpected result, at least 1 batch should remain
BNNS Fully Connected: Unexpected result, at least 1 output should remain
BNNS Fully Connected: Failed to fit in memory limit, using generic code
BNNS FUlly: allocation failed
BNNS Fully Connected: weights conversion buffer isn't allocated.
BNNS Fully Connected: inputs conversion buffer isn't allocated.
BNNS Fully Connected Backward: only float32 delta are supported
BNNS Fully Connected Backward: invalid argument
BNNS Fully Connected Backward: Fusion of compute with activation is unsupported for given activation function
BNNS Fully Connected Backward: failed to allocate memory
BNNS Fully Connected Backward: failed to apply activation backward
BNNS Fully Connected Backward: user requested weights delta but didn't supply original inputs
BNNS Fully Connected Backward: only fp32 inputs/weights/outputs are supported for backward
BNNS Fully Connected Backward: weights sizes doesn't match weights delta sizes
BNNS Fully Connected Backward: no bias, bias delta is set to 0
BNNS Fully Connected Backward: only float32 bias are supported
BNNS Fully Connected Create: failed to allocated memory (%zu bytes))
Shouldn't call get_data_size with Indexded2 or Indexed4, switch to get_data_bits
BNNS Fully Connected: compute data type not supported
BNNS_FULLY: input doesn't support Indexed data type
BNNS_FULLY: output only support fp32 data type
BNNS Fully Connected: using generic code to convert data 1 element each time
BNNS Fully Connected: output data type not supported for conversion
BNNS Fully Connected: input must be a 1D array
BNNS Fully Connected: input descriptor is illegal
BNNS Fully Connected: output must be a 1D array
BNNS Fully Connected: output descriptor is illegal
BNNS Fully Connected: weights row size should match input vector size
BNNS Fully Connected: weights number of rows should match output vector size
BNNS Fully Connected: weights must be a 2D array
BNNS Fully Connected: weights descriptor is ilegal
BNNS Fully Connected: Pointer to weight data must be non-NULL
BNNS Fully Connected: Output data types supported in this version: Float32, Float16
BNNS Fully Connected: Bias data types supported in this version: Float32
BNNS Fully Connected: Float16 output isn't supported with bias or activation function
BNNS Fully Connected: Input/Weight data types supported in this version: Float32, Int8, Int16
BNNS Fully Connected: Data type of weights and input should match
BNNS Fully Connected: size computation wraparound -I %zu -O %zu
BNNS Fully Connected: bias size computation wraparound -O %zu bias data type %x
BNNS Fully Connected: Weight type not supported
malloc
BNNS Optimizer Error: layer_params is NULL
BNNS Optimizer Error: unsupported optimizer function
BNNS Optimizer Error: memory allocation failed
BNNS Optimizer: Failed to init filter
BNNS Loss Error: filter is NULL
BNNS Optimizer: parameter array pointer is NULL
BNNS Optimizer: gradient array pointer is NULL
BNNS Optimizer: accumulator array pointer is NULL
BNNS Optimizer: parameter pointer number %zu is NULL
BNNS Optimizer: gradient pointer number %zu is NULL
BNNS Optimizer: accumulator pointer number %zu is NULL
BNNS Optimizer Error in parameter %zu: Parameter and Gradient descriptors must have the same sizes and strides
BNNS Optimizer Error in parameter %zu: Parameter and Accumulator descriptors must have the same sizes and strides
BNNS Optimizer Error in parameter %zu: Parameter data type is not BNNSDataTypeFloat32
BNNS Optimizer Error in gradient %zu: Gradient data type is not BNNSDataTypeFloat32
BNNS Optimizer Error in accumulator %zu: Accumulator data type is not BNNSDataTypeFloat32
BNNS Optimizer Error in parameter %zu: parameter descriptor must be dense such that stride[0]=1 and for every N>0 stride[N]=stride[N-1]*size[N-1]
BNNS Optimizer: unsupported optimizer function
BNNS Optimizer Error: OptimizerAlgFields is NULL
BNNS unsupported sgd variant
BNNS Sparse Fully Connected: input must be a 1D array
BNNS Sparse Fully Connected: input descriptor is illegal
BNNS Sparse Fully Connected: output must be a 1D array
BNNS Sparse Fully Connected: output descriptor is illegal
BNNS Sparse Fully Connected: invalid matrix layout
BNNS Sparse Fully Connected: invalid block row count: %u
BNNS Sparse Fully Connected: invalid block col count: %u
BNNS Sparse Fully Connected: input data types supported in this version: Float16
BNNS Sparse Fully Connected: output data types supported in this version: Float32, Float16
BNNS Sparse Fully Connected: weights data types supported in this version: Float16
BNNS Sparse Fully Connected: unsupported matrix block size %u x %u
BNNS Sparse Fully Connected: Allocation of the setup structure failed
BNNS Loss Error: unsupported loss function
BNNS Loss Error: Input width is 0
BNNS Loss Error: Input must be BNNSDataTypeFloat32 type
BNNS Loss Error: Input must be of BNNSDataLayoutVector layout
BNNS Loss Error: Input must be dense. stride0 must be 1 or 0
BNNS Loss Error: unknown reduction function
BNNS Loss Error: output data type must be BNNSDataTypeFloat32
BNNS Loss Error: output size>1 is only allow with reduction BNNSLossReductionNone.
BNNS Loss: memory allocation failed
BNNS Loss Error: batch_size is 0
BNNS Loss Error: in is NULL
BNNS Loss Error: in_stride is smaller than i_desc.size[0]
BNNS Loss Error: labels is NULL
BNNS Loss Error: labels_stride is smaller than i_desc.size[0]
BNNS Loss Error: weights_size>0 but weights pointer is NULL
BNNS Loss Error: weight_size value must be 0,1 or batch_size
BNNS Loss Warning: weight_size==0 but weight pointer is not NULL. Weight pointer is ignored.
BNNS Loss Error: out is NULL
BNNS Loss Error: in_delta descriptor is ilegal
BNNS Loss Error: in_delta must be dense, such that stride[0] is 0 or 1
BNNS Loss: unsupported loss function
BNNS softmax cross entropy loss error: in pointer is NULL
BNNS softmax cross entropy loss error: in stride cannot be smaller than input width
BNNS softmax cross entropy loss error: out pointer is NULL
BNNS softmax cross entropy loss error: batch_size is 0
BNNS softmax cross entropy loss: malloc failed
BNNS softmax cross entropy loss error: weight size must be equal 0,1 or batch size
BNNS Loss Warning: reduction BNNSLossReductionWeightedMean sum of weights is zero
BNNS Loss Error: reduction BNNSLossReductionNonZeroWeightMean all weights are zero
BNNS LOW MEM CONVOLUTION: Client needs to support weights ptr with low_mem
BNNS LOW MEM CONVOLUTION: malloc
BNNS LOW MEM CONVOLUTION: failed to create convolution context
BNNS LOW MEM CONVOLUTION: failed to divide work between convolution contexts to fit in memory
BNNS LOW MEM CONVOLUTION: failed to create single generic convolution
BNNS LOW MEM CONVOLUTION: invalid argument
BNNS LOW MEM CONVOLUTION: malloc
BNNS LOW MEM CONVOLUTION: Winograd weights memory doesn't fit in memory
BNNS LOW MEM CONVOLUTION: unable to create Winograd that fit in memory
BNNS LOW MEM CONVOLUTION: malloc failed
BNNS LOW MEM CONVOLUTION: failed to create winograd convolution
BNNS LOW MEM CONVOLUTION: incompatible BNNS_low_memory_context id
BNNS LOW MEM CONVOLUTION: convolution failed
BNNS LOW MEM CONVOLUTION: input aux buffer wasn't allocated
BNNS LOW MEM CONVOLUTION:: context type not supported
BNNS LOW MEM CONVOLUTION: apply convolution failed
failed to upconvert or copy weights
failed to allocate none generic format
BNNS CONVOLUTIONS VERSION2: only dense memory laout is supported
BNNS CONVOLUTIONS VERSION2: output bias or scale is not supported
BNNS CONVOLUTIONS VERSION2: integer engine does not support weight bias and scale
BNNS CONVOLUTIONS VERSION2: malloc failed
BNNS CONVOLUTIONS VERSION2: malloc failed
invalid argument
BNNS CONV: input batch stride doesn't make sense (%zu < %zu x %zu)
BNNS CONV: output batch stride doesn't make sense (%zu < %zu x %zu)
BNNS CONVOLUTIONS: malloc failed
BNNS Convolution: malloc failed
BNNS malloc failed
Tranposed Convolution currently does not support BNNSInternalFlagsUseLowMemConvolutions
Tranposed Convolution currently does not support dilation
Tranposed Convolution currently does not support weight packing
malloc failed
Invalid filter
BNNSDirectApplyConvolutionBatch not supported 
BNNSDirectApplyTransposedConvolutionBatch not supported 
BNNSDirectApplyFullyConnectedBatch not supported 
BNNSDirectApplyPoolingBatch not supported 
BNNSDirectApplyActivationBatch not supported 
BNNSDirectApplyLossBatch not supported 
Loss filter apply must be called with BNNSLossFilterApplyBatch
Optimizer filter apply must be called with BNNSOptimizerFilterApply
invalid filter
BNNS DESTROY: invalid filter
input type %s not supported!!!
compute type %s not supported!!!
int8
int16
int32
uint8
uint16
uint32
indexed8
indexed4
indexed2
BNNS GRU Fused Gates: only arm64 version is supported
BNNS Activation: number of memory descriptor is lower than expected
BNNS Activation: claiming pre allocated memory failed
BNNS Activation: memory allocation failed
BNNS Activation: Failed to init filter
BNNS SoftMax: sum result shouldn't be 0
BNNSActivationFunctionIntegerLinearSaturate isn't supported in apply_activation_backward
BNNSActivationFunctionIntegerLinearSaturatePerChannel isn't supported in apply_activation_backward
unsupported activation backward
BNNS Activation Backward: cannot compute backward if both forward pass output and forward pass input are NULL
BNNS Activation Backward: invalid argument
BNNS Activation Backward: output delta data type isn't fp32
BNNS Activation Backward: preallocated memory isn't supported
BNNS Activation Backward: Weights Delta not supported
BNNS Activation Backward: Bias Delta not supported
BNNS Activation Backward: Input Delta type isn't fp32
BNNS Activation: in-place activation layer is allowed only for output types with the same or smaller storage size
BNNS Activation backward: softmax backward does not support stride0!=1
BNNS Activation: invalid argument
BNNS Activation: unsupported types for conversion
BNNS Activation: Apply failed
BNNS Activation INIT: input descriptor is ilegal
BNNS Activation INIT: output descriptor is ilegal
BNNS Activation INIT: layout doesn't match
BNNS Activation Sofmax: only 1D input is supported
BNNS Activation INIT: only 3D conversoins are supported
BNNS Activation INIT: dim %zu input size %zu != %zu output size
BNNS Activation INIT: invalid activation function
BNNS Activation INIT: supported input data types: float32
BNNS Activation INIT: supported output data types: float32
BNNS Activation INIT: unsupported types for conversion
BNNS Activation error: NULL input/output pointer
BNNS Activation error: number of input channels must be equal to number of output channels
BNNS Activation error: input/output/activation pointers cannot be NULL
BNNS Activation error: SoftMax activation require input and output images to be dense such that stride0=1, stride1=width, stride2=width*height
BNNS POOLING: input batch stride doesn't make sense (%zu < %zu x %zu)
Pooling layer filter running slow path: stride=%zu,%zu kernel=%zu,%zu
case not implemented
BNNS Pooling Apply: allocation of work buffer failed
BNNS Pooling Backward: cannot run backward without output delta
BNNS Pooling Backward: only float32 output delta are supported
BNNS Pooling Backward: only float32 input delta are supported
BNNS Pooling Backward: only float32 bias delta are supported
BNNS Pooling Backward: unsupported pooling function
BNNS Pooling Backward: invalid argument
BNNS Pooling Backward: Fusion of compute with activation is unsupported for given activation function
BNNS Pooling Backward: failed to allocate memory
BNNS Pooling Backward: failed to apply activation backward
BNNS POOLING: input must be a 3D array
BNNS POOLING: input descriptor is ilegal
BNNS POOLING: output must be a 3D array
BNNS POOLING: output descriptor is ilegal
BNNS POOLING: input/output channel counts do not match
BNNS POOLING: input/output types do not match
BNNS POOLING: invalid kernel dimensions, should be greater than 0
BNNS POOLING: optimized code supports kernel width/height up to 16
BNNS_POOLING: input size computation wraparound input (%zu x %zu), output (%zu x %zu), stride (%zu x %zu), padding (%zu x %zu)
BNNS_POOLING: output(%zu x %zu) is larger than input(%zu x %zu) with padding(%zu x %zu).
 stride (%zu x %zu)
BNNS_POOLING: invalid pooling function
BNNS_POOLING: supported input/output data types: float32 float16
BNNS_POOLING: slow path: stride not in {1,2}
BNNS_POOLING: slow path: kernel size not in {2,3,4}
BNNS POOLING: Internal Memory size %zu doesn't match expected %d
BNNS Pooling: claiming pre allocated memory failed
memory allocation
BNNS Pooling Backward: only float32 delta are supported
BNNS Pooling Backward: wrong pooling function called
BNNS CONV: bias is not 0, activation function is not identity
BNNS CONV: convolution kernel is too large
BNNS CONV: invalid stride/padding
BNNS CONV: float32 only
v8@?0
hw.physicalcpu
BNNSActivationFunctionIntegerLinearSaturate isn't supported in apply_bias_and_activation
BNNSActivationFunctionIntegerLinearSaturatePerChannel isn't supported in apply_bias_and_activation
allocation failed, size=%zu
allocation failed, size=%zu, align=%zu
BNNS Fully Connected: unexpected data type, failing
BNNS Fully Connected: Data type not supprted, fail
invalid layer data type: %u
BNNS: layout not supported
BNNS: active dimension must be greater than 0
BNNS: dimension %zu stride %zu is lower then previous dimension actual size %zu * %zu (size*stride)
BNNS POOLING: memory usage exceeded capacity
BNNS PreAllocated Memory: memory usage exceeded capacity
BNNS PreAllocated Memory: failed to claim scratch memory
BNNS Create Convolution Winograd: malloc failed
memory allocation failed
weight packing must be at least 32 and a power of 2
BNNS Convolution version2 error: minimum int32_t w_pack weight packing value is 32
BNNS Dequantize: shouldn't have reached fp16 convert path
Transposed convolution currently only supports BNNSDataTypeFloat32 data type
BNNS_TRANSPOSE_CONV: forward pass check (swapping input and output)  - input size computation wraparound input (%zu x %zu), output (%zu x %zu), stride (%zu x %zu), padding (%zu x %zu)
BNNS_TRANSPOSE_CONV: forward pass check (swapping input and output) - output(%zu x %zu x %zu) is larger than input(%zu x %zu x %zu) with padding(%zu x %zu).
 kernel (%zu x %zu) and stride (%zu x %zu)
Filter is NULL
transposed convolution apply failed
failed to allocate weights in apply
NULL weight object
dst weight size too small
NULL weight array
BNNS Convolution Backward: cannot run backward without output delta
BNNS Convolution Backward: only float32 delta are supported
BNNS Convolution dilation is not supported backward
BNNS Convolution weight packing is not supported backward
BNNS Convolution Backward: BNNSFlagsUseClientPtr must be enabled during training
BNNS Convolution Backward: invalid argument
BNNS Convolution Backward: Fusion of compute with activation is unsupported for given activation function
BNNS Convolution Backward: failed to apply activation backward
BNNS Conv: Unsupported weight format for Input delta compute
BNNS Convolution Backward: could not create transposed convolution filter
BNNS Convolution Backward: could not create convolution filter
transposed convolution input delta backward failed
transposed convolution parameter error
transposed convolution backward failed
BNNS CONV: incompatible numbers of channels between images and convolution parameters
BNNS CONV: unsupported weight format
BNNS Conv: input must be a 3D array
BNNS Conv: input descriptor is ilegal
BNNS Conv: output must be a 3D array
BNNS Conv: output descriptor is ilegal
BNNS Conv: weights descriptor is ilegal
BNNS CONV: not allowed to delay allocation to apply if weights ptr isn't maintained by Client
BNNS_CONV: input size computation wraparound input (%zu x %zu), output (%zu x %zu), stride (%zu x %zu), padding (%zu x %zu)
BNNS_CONV: output(%zu x %zu x %zu) is larger than input(%zu x %zu x %zu) with padding(%zu x %zu).
 kernel (%zu x %zu) and stride (%zu x %zu)
BNNS CONV: failled to allocate weights buffer
BNNS CONV: input stack data type is not Float32 or Float16 or int8 or uint8
BNNS CONV: output stack data type is not Float32 or Float16 or int8 or uint8
BNNS CONV: int8 input stack only supported with int8 output stack and int8 weights
BNNS CONV: uint8 input stack only supported with uint8 output stack and int8 weights
int8 convolution can't have bias or activation other than BNNSActivationFunctionIntegerLinearSaturate
BNNS CONV: convolution doesn't support indexed weights
BNNS Convolution Create: failed to allocate memory
failed to allocate weights descriptor
convert weights
BNNS Convolution Create: failed to prepare blocks
create blocks
transposed convolution input manipulation failed
transposed convolution input manipulation failed - nothing to do, should not have allocated dst_input buffer
transposed convolution backward dy padding failed
