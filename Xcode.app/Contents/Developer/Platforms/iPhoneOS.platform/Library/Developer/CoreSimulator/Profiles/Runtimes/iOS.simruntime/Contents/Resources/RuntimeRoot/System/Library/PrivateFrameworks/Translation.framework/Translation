@(#)PROGRAM:Translation  PROJECT:Translation-216.8
@mcpl
@mcpl
@mcpl
com.apple.translation.DailyActive
com.apple.translation.WeeklyActive
com.apple.translation.MonthlyActive
LastActivityDate
feature
%0*ld_%ld
week_name
month_name
system
siri
app_review
aggregate
%@_%@
daily
weekly
monthly
identifier
<no value>
text
targetRange
start
length
sourceRange
shouldTranslate
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
Error
com.apple.translation
selector
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
@"NSDictionary"8@?0
com.apple.translation.analytics-event
v8@?0
errorDomain
errorCode
errorDescription
duration
sourceLocale
targetLocale
%@.%@
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
application-identifier
sentence
singleParagraph
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
v16@?0@"NSError"8
paragraphs
com.apple.TranslationUIServices.TranslationUIService
text-to-speech
speech
preheat
text-LID
processName
unknown
type
v24@?0@"_LTAudioData"8@"NSError"16
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v24@?0@"_LTTranslationResult"8@"NSError"16
com.apple.private.translation
com.apple.Translation
Daemon
com.apple.translation.daemon.listener
DisambiguationEnabled
DataCollectionEnabled
TextLIDUseLSTM
com.apple.translationd
com.apple.translation.text
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
UNKNOWN_ERROR_DESCRIPTION
REMOTE_SERVICE_FAILURE_DESCRIPTION
ONLINE_TRANSLATION_NOT_IMPLEMENTED_ERROR_DESCRIPTION
INVALID_ONLINE_OFFLINE_REQUEST_ERROR_DESCRIPTION
LID_MODEL_LOAD_ERROR_DESCRIPTION
ONGOING_SPEECH_TRANSLATION_ERROR_DESCRIPTION
SPEECH_DURATION_EXCEEDED_ERROR_DESCRIPTION
SERVER_TIMEOUT_ERROR_DESCRIPTION
OFFLINE_TTS_FAILURE_ERROR_DESCRIPTION
UNSUPPORTED_LOCALE_PAIR_ERROR_DESCRIPTION_FORMATTED_STRING
%@ %@ %@
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
com.apple.translation.HotfixError
file
HotfixManager
Translation
Hotfix
com.apple.Translator.HotfixManager
Mapping
FormatVersion
Cannot find any compatible hotfix
v24@?0@"NSDictionary"8@"NSError"16
com.apple.Translate
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
mapping-info-plist
v24@?0@"NSData"8@"NSError"16
HotfixAssetVersion
%@-%@
mt-quasar-config.json
HotfixAssetName
Failed to specify compression algorithm
Failed to specify format
Failed to open archive for reading
Unable to extract file
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
Languages
Footprint
Premium
hybridendpointer.json
InstallRequest
com.apple.siri.translation.speechrequest
locales
useCellular
zh-Hant
zh_TW
zh-Hans
zh_CN
en_US
dominantLanguage
confidences
isConfident
isFinal
com.apple.translation.lid.result
com.apple.translation.lid.finalResult
final
intermediate
, partial ASR confidences
, final ASR results
CSLanguageDetector
Unable to find class %s
CSLanguageDetectorOption
features
compiledModelFile
modelInput
modelInputIsMatrix
modelOutput
missingFeatureValueDefault
missingLanguageDetectionDefault
LanguageLocaleToIdentifier
min_source
max_source
avg_source
min_target
max_target
avg_target
most_recent_partial_source
max_partial_source
avg_partial_source
most_recent_partial_target
max_partial_target
avg_partial_target
acoustic_lid
acoustic_lid_count
acoustic_lid0
acoustic_lid1
acoustic_lid2
identifier_source
identifier_target
identifier_asr
v32@?0@"NSString"8Q16^B24
@max.doubleValue
@avg.doubleValue
v32@?0@"NSNumber"8Q16^B24
1.0-
%lld
progress
offlineState
localeIdentifier
totalExpected
totalWritten
isStalled
expectedTimeRemaining
Missing
Installed
Downloading
NeedsDownload
ErrorInstalling
%@ %@ %@ %@
LanguageManager
com.apple.siri.translation.LanguageManager
mt_app.offline
LanguagePairs
ASR-%@
TTS-%@
asset_list
AssetName
v16@?0@"MAProgressNotification"8
asr_languages
_all
TTS-
Translation voice not found for %@:%@
Translation voice downloaded for %@:%@
Downloading Translation voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
ASR-
v16@?0q8
Not Present
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
<%@: source:%@ target:%@>
Translator
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
conversationID
requestID
localePair
selectedLocale
lidResult
senses
userInteractedSenses
firstResponse
firstParagraphComplete
progressComplete
pageComplete
timeToFirstResponse
timeToFirstParagraphComplete
timeToProgressComplete
timeToPageComplete
v16@?0@"OspreyMutableRequest"8
com.apple.translation.ParagraphTranslationDone
hw.machine
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechTranslationAssets2
com.apple.MobileAsset.SpeechTranslationAssets3
com.apple.MobileAsset.SpeechTranslationAssets4
com.apple.MobileAsset.SpeechEndpointAssets
AssetsV3
Assets
AssetsV2
AssetManager
com.apple.Translator.EMTAssetManager
v12@?0B8
plist
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
MADownLoadResult
MOBILE_ASSET_DOWNLOAD_FAILURE_ERROR_DESCRIPTION
v16@?0@"NSArray"8
assets.json
Type
AssetVersion
RequiredCapabilityIdentifier
CONFIGURATION_ASSET_MISSING_ERROR_DESCRIPTION
CONFIGURATION_ASSET_MISSING_ERROR_DESCRIPTION_REASON
Missing asset entitlement
LanguageDetectorDefaultAsset
featureCombinationLID.plist
_UnarchivedSize
TranslationAssetQueryDomain
OfflineSpeechSynthesizer
com.apple.assistant.backedup
Output Voice
Gender
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
GENERIC_FAILURE_ERROR_DESCRIPTION
INPUT_EMPTY_ERROR_DESCRIPTION
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
asrBestConfidence
asrBestText
request_id
hasFinalServerResponse
completionHandlerCalled
MISSING_BATCH_RESPONSE_ERROR_DESCRIPTION
com.apple.siri
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.mobilesafari
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
x-sequoia-client
sentenceCount
v32@?0@"_LTTranslationParagraph"8Q16^B24
com.apple.translation.OnlineSpeechTranslation
sentAudio
sentEndAudio
endpointedSpeech
didReceiveAudioLimitExceededResponse
didReceivePartialRecognitionResponse
didReceiveFinalRecognitionResponse
didReceiveTranslationResponse
didReceiveTTSResponse
didReceiveFinalBlazarResponse
didTimeout
<%@: sentAudio:%@ sentEndAudio:%@ endpointedSpeech:%@ didReceiveAudioLimitExceededResponse:%@ didReceivePartialRecognitionResponse:%@ didReceiveFinalRecognitionResponse:%@ didReceiveTranslationResponse:%@  didReceiveTTSResponse:%@ didReceiveFinalBlazarResponse:%@ didTimeout:%@ error %@>
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
paragraph
INVALID_REQUEST_NO_RANGES_OR_TEXT_ERROR_DESCRIPTION
v32@?0@"_LTTranslationRange"8Q16^B24
Error AudioQueueStart
com.apple.translation.powerlog
default
InstalledLocales
LastOfflineAssetCatalogUpdate
LastCDNUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
RequestID
HotfixEndpointURL
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
FinalAcousticLanguageDetectionResultsWaitTimeInMs
FinalThresholdsAcousticLanguageDetectionResultsWaitTimeInMs
MinimumAcousticLanguageDetectionResults
MaximumAcousticLanguageDetectionResults
VADAudioCacheMaxDuration
LanguageDetectorFeatureCombinationModelSupported
LanguageDetectorFeatureCombinationModelVersionID
LanguageDetectorFeatureCombinationModelThreshold
LanguageDetectorFeatureCombinationModelConfidenceThreshold
ASRDataPackToLIDThresholdVersion
ASRDataPackToASRTypeIdentifier
TextLIDScorerConfidenceThreshold
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
CharacterBasedLocales
TranslationEngineCacheSize
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
RateLimitingMaximumPageLoadRequests
RateLimitingMaximumDynamicContentRequests
Configuration
v220621
-finalASR
mt_app.online
web.online
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
https://sequoia.apple.com
https://seed-sequoia.siri.apple.com
https://carry-sequoia.siri.apple.com
https://sequoia.cdn-apple.com/sequoia-prod
https://sequoia-test.cdn-apple.com/sequoia-livability/carry
EDC04020
com.apple.translationd.playback
com.apple.translation.session
v16@?0@"NSData"8
v24@?0@"NSURL"8@"NSError"16
com.apple.translation.AnalysisQueue
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
stable
locale
transcriptions
sausage
Sausage
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
confidence
(%@)
bins
alternatives
bestIndex
lowConfidence
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
SpeechRecognizer
com.apple.translation.speech
mini.json
dispatch.voc
lexicon.enh
itn_s.enh
MtApp
EMPTY_RECOGNITION_ERROR_DESCRIPTION
SPEECH_NOT_RECOGNIZED_ERROR_DESCRIPTION
sanitizedFormattedString
formattedString
minConfidence
maxConfidence
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
v32@?0@"NSLocale"8@"_LTSpeechRecognitionResult"16^B24
sessionID
taskHint
deviceOS
deviceType
appIdentifier
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
com.apple.translation.TextLID
language
isSupported
Detection result locale count: %ld, unsupported count: %ld, dominant: %@
weighted
TextLIDAggregateEvaluation
[ %@ ]
com.apple.translation.tts-cache
MISS
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
com.apple.Translate.globalprefschanged
com.apple.onboarding.translate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
tokens
genders
statistics
romanization
status
phrasebook_exact
gender_alternatives
com.apple.
translate
<redacted>
 (%@)
; %@
 | OCR
uniqueID
autodetectLanguage
autoEndpoint
censorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
ttsPlaybackRate
enableVAD
sourceOrigin
untrustedClientIdentifier
logIdentifier
sourceContentAsJSON
targetContentAsJSON
errorsAsJSON
safariVersion
webpageURL
group
defaultGender
spans
projection
default_gender
@"_LTTranslationGenderAlternative"16@?0@"NSObject"8
v32@?0@"_LTTranslationSpan"8Q16^B24
-[_LTTranslationParagraph splitIntoSentences]_block_invoke_2
LTTranslationParagraph.m
previousSpan.range.location + previousSpan.range.length == textRange.location
v32@?0@"NSString"8@"_LTTranslationSpan"16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
undefined
%@/%@
batch
TranslationRequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
textToSpeech
CFBundleIdentifier
CMBlockBufferCopyDataBytes could not copy data: %d
Translate
genderDisambiguation
sentencepiece encoder input
es_ES
The nurse went to the bank
El enfermero fue al banco
La enfermera fue al banco
El enfermero fue a la banca
La enfermera fue a la banca
El enfermero fue a la orilla
La enfermera fue a la orilla
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
@16@?0@"FTBatchTranslationResponse_TranslatedSentence"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
NO_IDENTIFIER
translations
sourceString
sanitizedSourceString
alignments
sourceMatch
targetMatch
pbMatch
sense ID
definition
source match
target match
input
output
labels
gender
formality
@"_LTTranslationSense"16@?0@"NSObject"8
group.com.apple.private.translation
com.apple.translationd.server
OFFLINE_MODELS_UNAVAILABLE_ERROR_DESCRIPTION
FirstUseConsent
v24@?0q8@"NSError"16
v16@?0@"NSDictionary"8
v24@?0@"<_LTTextTranslationService>"8@?<v@?>16
RATE_LIMIT_EXCEEDED_ERROR_DESCRIPTION
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
range
metaInfoData
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
firstleg sentencepiece decoder output
sentencepiece decoder output
mt_app
camera
image
v24@?0@"<_LTTranslationService>"8@?<v@?>16
v16@?0@"<_LTTranslationService>"8
v16@?0@"_LTLanguageDetectionResult"8
whitelist
entitlement
v16@?0@"_LTTextLanguageDetectionResult"8
CLIENT_REQUIRES_TEXT_SERVICE_ERROR_DESCRIPTION
InternalBuild
ar_SA
male
female
id_ID
pl_PL
vi_VN
th_TH
@16@?0@"FTWordTimingInfo"8
word
sampleIndex
offset
timestamp
Language
Config
MT-bi-
v24@?0^v8Q16
session_message
error_message
disable_session_log
container_message
error_code
reason
session_message_type
container_message_type
v20@?0r*8I16
tok_phrases
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
bool_stats
int32_stats
double_stats
acoustic_feature_per_frame
speech_recognition_features
acoustic_features
value
recognition_result
audio_analytics
latnn_mitigator_result
start_speech_request
user_parameters
pron_hints
contextual_text
context_with_pron_hints
user_language_profile
user_acoustic_profile
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
attributes
category_data
user_data
voc_token
tts_pronunciations
human_readable_prons
apg_ids
recovery_return_codes
voc_tokens
words_list
formatted_words_list
normalized_tokens
nbest_variants
sanitized_sequences
prons
normalized_prons
sanitized_tokens
phonemes
aot_token_prons
jit_token_prons
index
span
raw_sausage
raw_nbest_choices
post_itn_tokens
itn_alignments
translation_phrase
pre_sausage_payload
siri_translation_info
speech_translation_info
siri_payload_translation_info
web_translation_info
n_best_translated_phrases
engine_output
mt_alignment
translated_tokens
meta_info_data
audio_packets
keywords
corrected_sausage
n_best_list
pause_counts
corrections
voice
resource
server_info
context_info
word_phonemes
prompts
normalized_text
phoneme_sequence
replacement
neural_phoneme_sequence
resources
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
wave_data
user_voice_profile
decoder_description
playback_description
word_timing_info
dev_data
cache_meta_info
cache_object
cached_request
cached_response
cached_begin_response
cached_partial_response
cached_final_response
words
phonemeseq
model_id
lexicon
zk_node
audio_frames
translation_locale_pairs
translation_request
text_to_speech_requests
translation_locale_pair
detected_locale
user_interacted_senses
text_to_speech_response
server_endpoint_features
utterance
shortcuts
shortcut_score_pairs
language_parameters_by_id
predictions
translated_sentences
repeated_spans
source_span
target_span
n_best_choices
language_pairs
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
profile_blob
profile_blob_version
profile_checksum
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
add_space_after
phone_seq
ipa_phone_seq
has_unsuggested_alternatives
speech_id
request_locale
name
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
frame_duration
session_id
return_code
return_str
lang_profile_recreate_codes
watermark_detection
watermark_peak_average
has_result
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
primary_speech_id
product_id
vendor_id
left_context
right_context
audio_bytes
packet_count
total_audio_recorded_seconds
orthography
pronunciations
frequency
category_name
error_str
incomplete_profile
recreate_apg_prons
blob
apg_id
num_of_requested
num_of_processed
num_of_succeeded
post_itn_string
nbest_variants_max
original_token
pron_sequence
log_weight
token
pron_source
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
start_index
end_index
do_not_translate
post_itn_recognition
pre_itn_payload
post_itn_payload
task
source_language
target_language
sequence_id
disable_log
opt_in_status
app_id
use_case
translation_text
final_message
return_string
engine_input
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
calibration_scale
calibration_offset
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
keyword_orthography
posterior
enable_sanitization
num_of_words
trailing_silence_duration
eos_likelihood
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
fe_feature
fe_feature_only
disable_prompts
cache_only
phoneset_type
quality
channel_type
is_synthesis
dialog_identifier
experiment_identifier
prompts_v2
original
force_use_tts_service
disable_cache
data
return_log
voice_asset_path
resource_asset_path
return_server_info
has_click
worker_process_type
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
user_voice_profile_url
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
sample_idx
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
pcm_data
phone_name
begin_time
end_time
pitch
energy
support_homograph
endpoint_threshold
endpoint_extra_delay
zk_path
source_locale
target_locale
conversation_id
restricted_mode
streaming_mode
user_selected_locale
user_selected_sense
is_final
interaction_id
raw_string
shortcut
similarity_score
is_low_confidence
paragraph_id
source_content
translated_content
errors
safari_version
os_version
time_to_first_response
time_to_viewport_complete
time_to_page_complete
translated_text
sentence_count
qss_version_server
qss_version_brane
qss_version_serverkit
qss_version_siritts
content
content_type
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Blazar/ServiceDiscovery
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Mt/StreamingTranslation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Tts/TextToSpeechSpeechFeature
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Sls/LanguageDetection
Client attempted to register unspecified event; clients should always specify which event is being logged
Log %{public}@ activity for %{public}@
Updating last logged date for %{public}@ to: %{public}@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Trusted client connection
Untrusted client connection
XPC connection was interrupted, likely because the process was killed
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
XPC languages for text call
Failed to deserialize logging request: %@
XPC on-device mode call
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Failed to set user dir suffix: %{public}s
Memory pressure warning level %lu.
Failed to get cache directory: %{public}s
Rejected Translation client with PID %d lacking the appropriate entitlement (%@).
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
rm -rf %@
Could not delete: %@
Downloading: %@
Failed to download %@ with error: %@
Select hotfix: %@
Found existing hotfix
Remove folder failed: %@
Create folder failed: %@
Decompression failed: %@
Failed to specify compression algorithm: %s
Failed to specify format: %s
Start extracting archive
Failed to open archive for reading: %s
Entry extraction path: %@
Unable to extract file: %s
Finished extracting archive to: %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Updating source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Updating target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Start installation request with service
Failed to obtain LID asset
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
Sending out new %@ LID result, detected %@
Computing new LID result, with %ld acoustic results%@%@
Already sent final LID result, ignoring additional speech result
Change in model-version triggers deletion of cached %@ partial-confidences
Calling endAudio from addSpeechRecognitionResult
Initiate use of final thresholds to reduce dialog rates, as timer ended after 1st final ASR
Try to force final LID, as timer ended after 1st final ASR
Added %@ partial-confidence: %f; new array length: %ld
Already sent final LID result, ignoring additional audio data
NumSamples: %ld
LID Audio Data
Trying to send final LID result from endAudio
Forcing current language detection result to be final
Forcing language detection result to be %@
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
Acoustic LID detected %@ (confident: %@): %@
Trying to send final LID result from acousticLID CoreSpeech delegate
Setting default value for input is matrix to NO
Missing necessary configuration values
Setting default value for missing feature value to %f
Setting default value for missing language detector result to %f
Unknown feature in model file: %@
Unable to load CoreML model from: %@
CoreML model loaded: %@
Min confidence source: %f
Max confidence source: %f
Average confidence source: %f
Min confidence target: %f
Max confidence target: %f
Average confidence target: %f
Acoustic LID: %f
Acoustic LID count: %ld
Acoustic LID0: %f
Acoustic LID1: %f
Acoustic LID2: %f
Most recent partial confidence source: %f
Max partial confidence source: %f
Average partial confidence source: %f
Most recent partial confidence target: %f
Max partial confidence target: %f
Average partial confidence target: %f
Language %@ locale identifier source: %f
ASR-type identifier for model version=%@ -> feature: %f
Discarded CoreML features, as all values were defaults
Created CoreML features: %@
Unable to compile CoreML input features
Unable to construct CoreML feature provider
Unable to perform inference on CoreML model
Was unable to extract CoreML prediction
Was unable to extract posterior values from prediction results
Queried LID threshold version "%@" useFinalThresholds: %@ isFinalASR: %@, detected %@, with score %f using discriminator threshold %@%f and confidence offset %f (confident: %@)
missing mt_app.offline.plist
asset names for %@: %@
downloadAsset %@ totalExpected %@
progressCallback update assetIdentifier %@ %@
Finished downloading all assets
Required Assets: %@
setAutoDownloadedVoiceAssets %@
Unreferenced assets: %@
purged %@ result %ld
Nothing to install.
Installing:
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start speech senses logging request
Speech senses logging request finished with error: %@
Speech senses logging request finished
Start Safari latency logging request
Start Safari feedback request
Safari feedback request finished with error: %@
Safari feedback request finished
Received speech logging request response: [%d] %@
Speech logging request received unexpected response: %@
Speech logging request received error: %@
Received safari feedback request response: [%d] %@
Safari feedback request received unexpected response: %@
Safari feedback request received error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Received new language detection result
Trying to cancel recognition for %@
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
MADownloadNotEntitled
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
error querying obsolete catalog assets
Deleting Obsolete Assets %@
error querying catalog assets
error querying installed assets
Config asset not installed!
Reading configuration plist %@
Failed to read plist %@
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Start downloading asset %@ userInitiated: %@, useCellular: %@
Asset progress: %@
update: %@ %@
Asset download finished %@
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
Failed to remove old asset directory %@
Failed to create asset directory %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
update asset %@ %@ %@ %@
error downloading asset %@
error deleting asset %@
----------------------------- determine installed pairs ------------------------------------ 
----------------------------- check config asset for update ------------------------------------ 
----------------------------- Determine pairs to update ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
error downloading assets %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Starting download for asset with attributes: %@
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Failed to fetch asset metadata. Result: %ld
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Failed to create recognizer: %@
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Failed to create translator: %@
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Already got final LID result, forwarding...
Waiting for LID result
Received final LID result, continue with wait block
Starting translation
Initialize translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
Starting partial translation
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
streamDidReceiveBatchTranslationStreamingResponse request_id %{public}@
found BatchTranslationResponse request_id %{public}@
FIXME: NULL FTBatchTranslationResponse!
Succeeded request %{public}@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %{public}@
NULL FTFinalBlazarResponse!
GRPC error %d: %@
Translation error on %{public}@: %@
found FTFinalBlazarResponse request_id %{public}@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FBFLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
startServerTimeoutTimer 
updateServerTimeout %.2fs 
cancelServerTimeout: %@
batch timeout triggered
 serverTimeoutFired Sending batch request after %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ after %.2fs
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %{public}@, task: %{public}@, sessionID: %{public}@, URL: %@
Batch request created (sessionID: %{public}@)
Batch SELF log created
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Starting speech translation with request ID: %{public}@ session ID: %{public}@, opt in status: %ld
Streaming connection finished with error: %@
Initializing LTOspreySpeechTranslationSession with no text to translate.  This may not be what you want.
Starting text to speech translation with request ID: %{public}@, session ID: %{public}@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
sendAudioData: Final ASR response received, not sending audio.
sendAudioData: Already sent end audio, not sending audio.
sendAudioData: Already endpointed, do not need to send additional audio.
sendAudioData: Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring non-final LID result
LID result received. Primary language recognized: %@
Sending MT responses if needed
Detected translation locale: %{public}@
Result locale: %{public}@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Create SELF Batch request log with request sessionID: %{public}@, appID: %{public}@, mtID: %{public}@
Start SELF Batch request log with %lu paragraphs
End SELF Batch request log
End SELF Batch request log with error %{public}@
Cancel SELF Batch request log with reason %{public}@
SELF Batch request log sent %@
SELF One or more locales did not have a SISchemaLocale %{public}@, %{public}@
SELF Invocation event initialized
SELF Invocation start sent %@
SELF Invocation end sent %@
SELF Invocation log: Empty language pair
SELF Invocation event log start context %@
Log ended successfully but with unknown QSS Session ID
SELF Invocation event log end context %@
Log cancelled (reason: %{public}@) with unknown QSS Session ID
SELF Invocation event log cancel context %@
Log failed with unknown QSS Session ID; error: %@
SELF Invocation event log error context %@
SELF ASR event initialized %{public}@
SELF ASR event log sent %@
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
Sending end of audio
Asked to cancel speech session
SNAudioStreamAnalyzer failure: %@
Sausage conf %ld for locale %@
Sausage confidences: %@
Initializing recognition with config based formatter
Initializing recognition with old ncs formatter, as new config based formatter was not found
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Detection result via detected locales: %@
Detection result via detection counts: %@
Detection result via weighted locale: %@
Using LSTM text lid engine
Using CFRO text lid engine
Detection for string value
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Detection for %ld string array using strategy: %@
Text lid evaluation strategy: aggregate
Text lid evaluation strategy: count-based
nil locale encountered in scorable item init; will ignore this item
new scoring item locale:%{public}@ confidence:%f words:%ld
supported locales for scoring: %{public}@
no scorable dominant language for text length: %ld
weightedLocale for %lu items
weightedLocale confidence threshold from preferences: %f
weightedLocale item confidence %f < confidence threshold %f, skipping
weightedLocale is %{public}@ with score %f on %lu words from %lu locales
TTS cache request: %@
Purging %ld items from TTS cache
Setting romanization from meta_info_data: %@
Phrase has no meta_info_data romanization
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Setting romanization from meta JSON string: %@
Using trusted client identifier: %{private}@
Failed to get trusted client identifier, falling back to untrusted value: %{private}@
Trying to set new text on a request that already had text (and a session) set; this could lead to unexpected behavior
Created _LTTranslationSession for use in a _LTTextTranslationRequest. SessionID: %{public}@
_LTTranslationRequest had text set, creating sub-request with suggested uniqueID: %{public}@
Text Translation: start with service
Using paragraph translation
Received parapraph translation result
Fallback to text to speech translation
Translation failed with error: %@
Skipping alignment information in translation when 1:1 with translation
Alignment '%@' ID: %@
No alignment information in translation
Received translated paragraph for ID: %@
New outstanding count: %ld
Received text to speech result
Using `-[_LTTranslator translate:]` is not supported on batch translation. Please take a look at `_LTTranslationSession`.
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TextToSpeechTranslation did receive translation result
Got (untrusted) client identifier from Info.plist: %{private}@
Unable to read (untrusted) client identifier from Info.plist; falling back to process name: %{private}@
No asset info found for pair %@
Reusing cached offline engine for locales: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %{public}@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %{public}@, current ongoing is: %{public}@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
XPC languages for text result: %@
XPC on-device mode result: %@
Error ensuring service connection %@
Translation XPC connection failure, ignoring %lu requests
Translation rate limit reached, ignoring %lu requests
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Translation XPC connection failure, abort sending session feedback
Session sending feedback
Received translation result for %@
Connection to translationd was interrupted, the process exited or crashed
Failed to complete onDeviceModeEnabled check, using dedicated mach port %i: %@
Failed to clear caches: %@
Failed to complete get offline language status: %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete purging all assets: %@
Failed to complete updating all assets: %@
Failed to complete updating hotfix: %@
Failed to complete deleting hotfix: %@
Failed to complete installedLocales %@
Failed to complete getting asset size: %@
Failed to install offline locales: %@
Failed to complete availableLocalePairsForTask, using dedicated mach port: %i: %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Not showing first-use consent because it's running in the Translate app
Failed to complete checking whether to present system first time use consent: %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Failed to complete text-LID %{public}@-based request %@
Creating service proxy
Connection error: %@
Connection done
Creating text-only service proxy
Text translation connection error: %@
Text translation connection done
Creating SYNC service proxy
Failed to complete sync preheat request: %@
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Starting translation for request (using dedicated text mach port = %d)
Refusing to translate text since request isn't allowed to use dedicated mach port
Failed to complete getting text service for translation with dedicated mach port: %@
Failed to complete getting text service for translation without dedicated mach port: %@
Failed to serialize logging request: %@
Failed to complete logging request: %@
Voice type overridden for locale %{public}@ from %{public}@ to %{public}@
softlink:r:path:/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
Q@c!
ABSD
_LTActivityLogger
_LTActivityLoggerDelegate
NSObject
JSONRepresentation
_LTAlignment
NSSecureCoding
NSCoding
_LTAnalyticsEvent
_LTAsyncMap
_LTAudioData
_LTClientConnection
_LTTranslationService
_LTTextTranslationService
_LTCombinedEngine
_LTSpeechTranslationDelegate
_LTTranslationEngine
_LTCombinedRouteParagraphTranslationRequest
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
LTTranslationError
_LTMatch
_LTEtiquetteSanitizer
_LTHotfixManager
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTHybridEndpointerAssetInfo
_LTInstallRequest
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
_LTLanguageDetectorAssetInfo
_LTLanguageDetectorFeatureCombinationModel
_LTLanguageInstallationStatus
_LTLanguageAssetStatus
_LTLanguageManager
_LTLanguagePairOfflineAvailability
_LTLocalePair
NSCopying
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTTranslationSensesLoggingRequest
_LTSafariLatencyLoggingRequest
_LTLoggingRequestHandler
FTSpeechTranslationResponseDelegate
FTBatchTranslationResponseDelegate
_LTMultilingualSpeechRecognizer
_LTOfflineAssetManager
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
_LTOfflineTranslationEngine
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
_LTOnlineTranslationEngine
_LTOspreySpeechTranslationSession
_LTSpeechCompressorDelegate
_LTParagraphTranslationRequest
_LTPlaybackService
_LTPowerLogger
_LTRateLimiter
_LTBatchEventLog
SISchemaAdditions
EmptyPair
_LTInvocationEventLog
_LTInvocationEventContext
_LTASRStateEventLog
_LTServerSpeakSession
_LTServerSpeechSession
_LTSpeakRequest
_LTSpeechActivityDetector
SNResultsObserving
_LTSpeechCompressor
_LTSpeechDataQueueNode
_LTSpeechDataQueue
Osprey
_LTSpeechRecognitionResult
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTSpeechTranscription
_LTSpeechTranslationAssetInfo
_LTSpeechTranslationResultsBuffer
_LTTaskContext
_LTTextLanguageDetectionResult
_LTTextLanguageDetector
_LTTextLanguageDetectorScorerItem
_LTTextLanguageDetectorScorer
_LTTextToSpeechCache
_LTTokenizer
_LTTranslateSettingsController
_LTTranslationCandidate
OspreyRequest
_LTTranslationContext
_LTTranslationFeedback
_LTTranslationGenderAlternative
_LTTranslationParagraph
_LTTranslationRange
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTranslationResult
_LTTranslationSense
_LTTranslationServer
_LTTranslationSession
_LTTranslationSpan
LTStatistics
_LTTranslationStatistics
_LTTranslationToken
_LTTranslator
_LTWordTimingInfo
TranslationAssetUtil
LTArrayExtensions
LTParagraphs
LTLocaleIdentifier
LTPathUtil
FTErrorMessage
FLTBFBufferAccessor
FTDisableSessionLog
FTApgPronGuessMessage
FTApgBatchRecoverMessage
FTAsrRecognitionMessage
FTAsrErrorBlamerMessage
FTAsrItnMessage
FTAsrTextNormalizationMessage
FTAsrPostItnHammerMessage
FTAsrKeywordFinderMessage
FTAsrCorrectionsValidatorMessage
FTAsrGraphemeToPhonemeMessage
FTBlazarMultiUserMessage
FTBlazarMultilingualMessage
FTBlazarSpeechTranslationMessage
FTBlazarBatchTranslationMessage
FTBlazarTextToSpeechRouterMessage
FTBlazarTextToSpeechRouterStreamingMessage
FTBlazarServiceDiscoveryMessage
FTLmtLmScorerMessage
FTNapgCreateLanguageProfileMessage
FTMtTranslationMessage
FTMtStreamingTranslationMessage
FTTtsTextToSpeechMessage
FTTtsTextToSpeechStreamingMessage
FTTtsTextToSpeechSpeechFeatureMessage
FTNlShortcutFuzzyMatchMessage
FTSlsLanguageDetectionMessage
FTQssMessage
FTMutableErrorMessage
FTMutableDisableSessionLog
FTMutableApgPronGuessMessage
FTMutableApgBatchRecoverMessage
FTMutableAsrRecognitionMessage
FTMutableAsrErrorBlamerMessage
FTMutableAsrItnMessage
FTMutableAsrTextNormalizationMessage
FTMutableAsrPostItnHammerMessage
FTMutableAsrKeywordFinderMessage
FTMutableAsrCorrectionsValidatorMessage
FTMutableAsrGraphemeToPhonemeMessage
FTMutableBlazarMultiUserMessage
FTMutableBlazarMultilingualMessage
FTMutableBlazarSpeechTranslationMessage
FTMutableBlazarBatchTranslationMessage
FTMutableBlazarTextToSpeechRouterMessage
FTMutableBlazarTextToSpeechRouterStreamingMessage
FTMutableBlazarServiceDiscoveryMessage
FTMutableLmtLmScorerMessage
FTMutableNapgCreateLanguageProfileMessage
FTMutableMtTranslationMessage
FTMutableMtStreamingTranslationMessage
FTMutableTtsTextToSpeechMessage
FTMutableTtsTextToSpeechStreamingMessage
FTMutableTtsTextToSpeechSpeechFeatureMessage
FTMutableNlShortcutFuzzyMatchMessage
FTMutableSlsLanguageDetectionMessage
FTMutableQssMessage
FTUserLanguageProfile
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTStreamingTranslationRequest
FTTranslationPhraseMetaInfo
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTTTSWordPhonemes
FTTTSPhonemeSequence
FTTTSNeuralPhonemeSequence
FTTTSPrompts
FTTTSReplacement
FTTTSNormalizedText
FTTextToSpeechFeature
FTTextToSpeechRequestDebug
FTTextToSpeechVoiceResource
FTTextToSpeechUserProfile
FTTextToSpeechRequestDevConfig
FTTextToSpeechResponseDevData
FTTextToSpeechRequestProsodyControlConfig
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTTextToSpeechUserVoiceProfile
FTTextToSpeechRequestProsodyTransferConfig
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTTextToSpeechCacheContainerRpcV2
FTTextToSpeechCacheContainerStreamingV2
FTQssAckResponse
FTTextToSpeechSpeechFeatureModelIdentifier
FTTextToSpeechSpeechFeatureInputWord
FTTextToSpeechSpeechFeatureInputText
FTTextToSpeechSpeechFeatureInputWave
FTTextToSpeechSpeechFeatureOutputFeature
FTTextToSpeechSpeechFeatureInputPhoneme
FTTextToSpeechSpeechFeatureInputPhonemeSequence
FTTextToSpeechSpeechFeatureRequest
FTTextToSpeechSpeechFeatureRequest_LexiconEntry
FTTextToSpeechSpeechFeatureResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTServiceDiscoveryRequest
FTServiceDiscoveryResponse
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationFeedbackRequest
FTBatchTranslationLoggingRequest
FTBatchTranslationResponse
FTBatchTranslationResponse_TranslationPhrase
FTBatchTranslationResponse_TranslatedSentence
FTBatchTranslationCacheContainer
FTTranslationSupportedLanguagesRequest
FTTranslationSupportedLanguagesResponse
FTTranslationSupportedLanguagesResponse_LanguagePair
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTQSSVersionInfo
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableStreamingTranslationRequest
FTMutableTranslationPhraseMetaInfo
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableTTSWordPhonemes
FTMutableTTSPhonemeSequence
FTMutableTTSNeuralPhonemeSequence
FTMutableTTSPrompts
FTMutableTTSReplacement
FTMutableTTSNormalizedText
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequestDebug
FTMutableTextToSpeechVoiceResource
FTMutableTextToSpeechUserProfile
FTMutableTextToSpeechRequestDevConfig
FTMutableTextToSpeechResponseDevData
FTMutableTextToSpeechRequestProsodyControlConfig
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableTextToSpeechUserVoiceProfile
FTMutableTextToSpeechRequestProsodyTransferConfig
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableTextToSpeechCacheContainerRpcV2
FTMutableTextToSpeechCacheContainerStreamingV2
FTMutableQssAckResponse
FTMutableTextToSpeechSpeechFeatureModelIdentifier
FTMutableTextToSpeechSpeechFeatureInputWord
FTMutableTextToSpeechSpeechFeatureInputText
FTMutableTextToSpeechSpeechFeatureInputWave
FTMutableTextToSpeechSpeechFeatureOutputFeature
FTMutableTextToSpeechSpeechFeatureInputPhoneme
FTMutableTextToSpeechSpeechFeatureInputPhonemeSequence
FTMutableTextToSpeechSpeechFeatureRequest
FTMutableTextToSpeechSpeechFeatureRequest_LexiconEntry
FTMutableTextToSpeechSpeechFeatureResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableServiceDiscoveryRequest
FTMutableServiceDiscoveryResponse
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationFeedbackRequest
FTMutableBatchTranslationLoggingRequest
FTMutableBatchTranslationResponse
FTMutableBatchTranslationResponse_TranslationPhrase
FTMutableBatchTranslationResponse_TranslatedSentence
FTMutableBatchTranslationCacheContainer
FTMutableTranslationSupportedLanguagesRequest
FTMutableTranslationSupportedLanguagesResponse
FTMutableTranslationSupportedLanguagesResponse_LanguagePair
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutableQSSVersionInfo
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTStreamingTranslationStreamingRequest
FTStreamingTranslationStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableStreamingTranslationStreamingRequest
FTMutableStreamingTranslationStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTStreamingTranslationStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
format_id
sample_rate
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
audioStreamBasicDescription
init
calendarWithIdentifier:
date
_registerActivity:onDate:
lastAggregateLogDateForActivityLogger:
activityLogger:lastLoggedDateForTask:
_logAllIntervalsForTask:date:
_updateLastLoggedDate:forTask:
isDate:inSameDayAsDate:
_logActivityForTask:interval:date:
isDate:equalToDate:toUnitGranularity:
_featureNameForTask:
activityLogger:logAggregateUsageForInterval:date:
activityLogger:logUsageForTask:interval:date:
activityLogger:updateLastAggregateLogDate:
activityLogger:updateLastLoggedDate:forTask:
_sendDailyUsageForTask:date:
_sendWeeklyUsageForTask:date:
_sendMonthlyUsageForTask:date:
_activityDatePreferenceKeyForTask:
standardUserDefaults
objectForKey:
setObject:forKey:
dictionaryWithObjects:forKeys:count:
components:fromDate:
weekOfYear
year
stringWithFormat:
month
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
registerActivity:
delegate
setDelegate:
.cxx_destruct
_calendar
_delegate
T@"<_LTActivityLoggerDelegate>",W,N,V_delegate
identifier
text
targetRange
numberWithUnsignedInteger:
jsonRepresentation
encodeObject:forKey:
valueWithRange:
encodeBool:forKey:
decodeObjectOfClass:forKey:
rangeValue
decodeBoolForKey:
isEqualToString:
sourceRange
shouldTranslate
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
setIdentifier:
setSourceRange:
setTargetRange:
setText:
setShouldTranslate:
_shouldTranslate
_identifier
_text
_sourceRange
_targetRange
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_identifier
T@"NSString",C,N,V_text
TB,N,V_shouldTranslate
code
numberWithInteger:
domain
dictionaryWithDictionary:
userInfo
objectForKeyedSubscript:
setObject:forKeyedSubscript:
dictionary
initWithName:
markStart
processInfo
systemUptime
numberWithDouble:
addFieldsFromDictionary:internalOnly:
addEntriesFromDictionary:
localizedDescription
addFieldsFromDictionary:
markEnd
sourceLocale
_ltLocaleIdentifier
targetLocale
timedEventWithName:
timestampWithName:
addFieldsWithError:
sendLazy
setSourceLocale:
setTargetLocale:
_eventName
_startTime
_endTime
_queue
_fields
_sourceLocale
_targetLocale
T@"NSLocale",C,N,V_sourceLocale
T@"NSLocale",C,N,V_targetLocale
_ltAsyncMap:queue:completion:
array
count
null
addObject:
setObject:atIndexedSubscript:
enumerateObjectsUsingBlock:
objectEnumerator
nextObject
_ltAsyncMap:completion:
_ltSequentialMap:completion:
_populateWithOpusData:
data
length
bytes
appendBytes:length:
defaultManager
URLByDeletingLastPathComponent
path
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToURL:options:error:
initWithASBD:rawData:wordTimingInfo:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
wordTimingInfo
_asbd
_data
_packetCount
_packetDescriptions
_rawData
_wordTimingInfo
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T@"NSData",R,N,V_rawData
Tq,R,N,V_packetCount
T@"NSData",R,N,V_packetDescriptions
T@"NSArray",R,N,V_wordTimingInfo
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
cleanupOnDisconnect
setInterruptionHandler:
setInvalidationHandler:
valueForEntitlement:
remoteObjectProxy
cancelSpeechSessionWithID:
clientConnectionClosed:
clearCaches
logRequestOfType:context:
setTrustedClientIdentifier:
translateSentence:withContext:completion:
sanitizedCopyForUntrustedTextTranslation
arrayWithObjects:count:
translateParagraphs:withContext:paragraphResult:completion:
_clientDelegate
paragraphTranslation:result:error:
speak:withContext:delegate:completion:
setTaskHint:
startTextToSpeechTranslationWithContext:text:delegate:
startSpeechTranslationWithContext:delegate:
addSpeechAudioData:
endAudio
preheatWithContext:completion:
shouldPresentSystemFirstUseConsent:
languageForText:completion:
languagesForText:usingModel:strategy:completion:
cleanup
clientIdentifier
route
sharedInstance
logTranslateRequestEvent:requestType:routeType:
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
installedLocales:
startInstallRequest:delegate:
_getAssetSize:
availableLocalePairsForTask:completion:
task:isSupportedInCountry:completion:
additionalLikelyPreferredLocalesForLocale:completion:
configInfoForLocale:otherLocale:completion:
unarchivedObjectOfClasses:fromData:error:
setProcessName:
setClientBundleID:
startLoggingRequest:
_updateHotfix:
_deleteHotfix:
onDeviceModeEnabled:
translate:withContext:completion:
translateParagraphs:withContext:completion:
provideFeedback:withContext:
startTextToSpeechTranslationWithContext:text:
startSpeechTranslationWithContext:
languagesForText:completion:
speak:withContext:completion:
startInstallRequest:
logWithRequestData:
initWithConnection:server:trusted:
languagesForText:usingModel:completion:
_connection
_server
_trusted
_trustedClientIdentifier
_speechSessionID
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
offlineEngine
translatesPair:
onlineEngine
preheatAsynchronously:withContext:
setLanguagesRecognized:
cancelSpeechTranslation
_ltCompactMap:
mutableCopy
removeObject:
translate:withContext:paragraphResult:completion:
countByEnumeratingWithState:objects:count:
endpoint
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
speechRecognitionResult:
translatorDidTranslate:
hasFailed
stopBuffering
translationDidFinishWithError:
speechActivityDetected
languageDetectionResult:
languageDetectionCompleted
cancel
languageInstallProgressed:error:
ttsProgressed:
setOfflineEngine:
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
requestContext
setRoute:
forcedOfflineTranslation
_forcedOnlineTranslation
registerDefaults:
_enterSandbox
_setupMemoryWarningListener
initWithMachServiceName:
_setQueue:
resume
currentRunLoop
notifyOfMemoryPressure
stringWithUTF8String:
boolValue
processIdentifier
initialize
listener:shouldAcceptNewConnection:
_cacheDirectoryPath
_translationListener
_textTranslationListener
_listenerQueue
_connections
stringByAppendingString:
mainBundle
localizedStringForKey:value:table:
errorWithDomain:code:userInfo:
lt_errorWithCode:description:userInfo:
lt_internalErrorWithCode:description:userInfo:
currentLocale
localizedStringForLocaleIdentifier:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
initWithNode:range:
node
setNode:
range
setRange:
token
setToken:
_node
_token
_range
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
dataWithContentsOfURL:
JSONObjectWithData:options:error:
enumerateKeysAndObjectsUsingBlock:
treeForReplacementTokens:
URLByAppendingPathComponent:
initWithReplacementTokenDictionary:language:
lowercaseString
enumerateSubstringsInRange:options:usingBlock:
removeObjectsInArray:
removeAllObjects
replaceCharactersInRange:withString:
substringWithRange:
replacementStringForString:forToken:
copy
matchesForString:
stringByReplacingMatches:inString:
localeIdentifier
initWithModelURL:language:
sanitizedStringForString:
_replacementTree
_locale
URLForDirectory:inDomain:appropriateForURL:create:error:
contentsOfDirectoryAtPath:error:
firstObject
minimumSupportedConfigurationVersion
intValue
maximumSupportedConfigurationVersion
_downloadHotfix:completion:
_downloadMappingPlist:
removeItemAtURL:error:
defaultSessionConfiguration
set_sourceApplicationBundleIdentifier:
setAllowsCellularAccess:
sessionWithConfiguration:
dataTaskWithURL:completionHandler:
_CDNURL:
stringValue
propertyListWithData:options:format:error:
_downloadWithURL:completion:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
_decompressArchive:to:error:
stringByAppendingPathComponent:
UTF8String
hotfixURL
updateHotfix:
deleteHotfix:
_hotfixURL
T@"NSURL",R,N,V_hotfixURL
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
processed_audio_duration_ms
decodeInt64ForKey:
decodeDoubleForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
defaultServerEndpointFeatures
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEosLikelihood:
setPauseCounts:
silencePosterior
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
eosLikelihood
pauseCounts
processedAudioDurationInMilliseconds
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
autoEndpoint
endpointAssetInfoWithContext:error:
caesuraModelURL
initWithConfigFile:samplingRate:
localePair
endpointerModelURL:
initWithConfiguration:
requestSupportedWithSamplingRate:
floatValue
updateEndpointerThresholdWithValue:
autodetectLanguage
addAudio:numSamples:
processedAudioMs
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
componentsJoinedByString:
didEndpointWithFeatures:silenceFeatures:endpointer:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
endpointerThreshold
setEndpointerThreshold:
samplingRate
audioBitDepth
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_context
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_samplingRate
_audioBitDepth
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
Tq,R,N,V_audioBitDepth
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
endpointerIsAvailableWithContext:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
attributes
valueForKey:
_ltCsLocaleIdentifier
containsObject:
integerValue
isPremium:
state
getLocalUrl
initWithAvailableAssets:context:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
T@"NSString",R,N,V_hybridepAssetFile
T@"NSString",R,N,V_spgAssetFile
initWithLocales:useCellular:
initWithLocales:useCellular:progressHandler:
initWithLocales:useCellular:delegate:
_startInstallationWithService:done:
locales
setLocales:
useCellular
setUseCellular:
progressHandler
setProgressHandler:
completionHandler
setCompletionHandler:
_service
_done
_useCellular
_locales
_progressHandler
_completionHandler
T@?,C,N,V_completionHandler
T@"NSArray",C,N,V_locales
TB,N,V_useCellular
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
T@?,C,N,V_progressHandler
localeWithLocaleIdentifier:
languageCode
allKeys
doubleValue
setDominantLanguage:
setConfidences:
dominantLanguage
confidences
isConfident
isFinal
initWithConfidences:isConfident:dominantLanguage:isFinal:
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
languageDetectorAssetWithError:
languageDetectorModelURL
initWithModelURL:
featureCombinationConfigUrl
initWithConfig:
lidThreshold
reversedPair
setSamplingRate:
setWithObjects:
setDictationLanguages:
resetForNewRequest:
haveFinalASRResults
haveAtLeastOneFinalASRResult
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:useFinalThresholds:
sendLIDResult:
locale
modelVersion
sendFinalLanguageDetectionResult:
bestTranscription
confidence
sessionID
initWithUUIDString:
logFirstPacketSent:
addSamples:numSamples:
cancelCurrentRequest
logFirstPacketReceived:
lastObject
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
startLanguageDetectionWithContext:delegate:
addSpeechRecognitionResult:
cancelLanguageDetection
forceLanguageDetectionResult
acousticResults
setAcousticResults:
lastResult
setLastResult:
featureCombinationModelSupported
setFeatureCombinationModelSupported:
featureCombinationModel
setFeatureCombinationModel:
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_minimumAcousticLanguageDetectorResults
_maximumAcousticLanguageDetectorResults
_endAudioCalled
_useFinalThresholds
_finalLIDResultSent
_firstPacketSent
_receivedPartialSpeechResult
_havePartialASRConfidences
_partialSpeechResultConfidences
_finalSpeechResults
_modelVersions
_lidSignpostID
_resultQueue
_finalResultWaitQueue
_featureCombinationModelSupported
_acousticResults
_lastResult
_featureCombinationModel
T@"NSMutableArray",&,N,V_acousticResults
T@"_LTLanguageDetectionResult",&,N,V_lastResult
TB,N,V_featureCombinationModelSupported
T@"_LTLanguageDetectorFeatureCombinationModel",&,N,V_featureCombinationModel
Td,R,N,V_samplingRate
initWithAssetUrl:featureCombinationAssetUrl:
_assetUrl
_featureCombinationConfigUrl
initWithContentsOfURL:
numberWithUnsignedInt:
modelWithContentsOfURL:error:
modelDescription
initWithShape:dataType:error:
minConfidence
maxConfidence
getAcousticLidConfidenceFromResult:locale:
objectAtIndex:
valueForKeyPath:
canonicalLocalePair
getModelFeatures:canonicalPair:partialSpeechResultConfidences:finalSpeechResults:modelVersion:
initWithDictionary:error:
predictionFromFeatures:options:error:
featureValueForName:
multiArrayValue
objectAtIndexedSubscript:
oppositeToLocale:
initWithSourceLocale:targetLocale:
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:
_mlModel
_modelInput
_modelInputIsMatrix
_modelOutput
_features
_missingFeatureValueDefault
_missingLanguageDetectorDefault
_languageLocaleToIdentifier
progress
setProgress:
setLocaleIdentifier:
offlineState
setOfflineState:
totalExpected
setTotalExpected:
totalWritten
setTotalWritten:
isStalled
setIsStalled:
expectedTimeRemaining
setExpectedTimeRemaining:
_isStalled
_progress
_localeIdentifier
_offlineState
_totalExpected
_totalWritten
_expectedTimeRemaining
Tq,N,V_progress
T@"NSString",C,N,V_localeIdentifier
TQ,N,V_offlineState
Tq,N,V_totalExpected
Tq,N,V_totalWritten
TB,N,V_isStalled
Td,N,V_expectedTimeRemaining
_LTAssetStateString
finished
setFinished:
status
setStatus:
localIdentifiers
setLocalIdentifiers:
update
setUpdate:
_finished
_status
_localIdentifiers
_update
TB,N,V_finished
TQ,N,V_status
T@"NSArray",&,N,V_localIdentifiers
T@"MAProgressNotification",&,N,V_update
removeObsoleteAssets
compare:
sortedArrayUsingSelector:
componentsSeparatedByString:
identifiersInIdentifiers:forLanguageName:
arrayByAddingObjectsFromArray:
subarrayWithRange:
_configPlistWithFileName:
addObjectsFromArray:
allObjects
pairWithIdentifiers:
hasPrefix:
hasSuffix:
languageToStatusDictionary
installationStatusArray
downloadSize
numberWithLongLong:
updateProgress
allValues
downloadAsset:userInitiated:useCellular:progressCallback:completion:
_setInstalledLocales:
configurationPropertyListWithName:
catalogAssets
installedAssets
setDiscretionary:
setRequiresPowerPluggedIn:
pairNamesForLocales:
assetNamesForPairNames:
substringFromIndex:
_vsLocaleIdentifier
_voiceAssetForLocaleIdentifier:
isInstalled
isBuiltInVoice
sharedManager
languages
gender
genderStringFromGender:
downloadVoiceAsset:options:progressUpdateHandler:
setAutoDownloadedVoiceAssets:
matchingASRAssetForLocale:inAssets:
assetWithName:inAssets:
identifiersInIdentifiers:forAssetName:
downloadAsset:withStatus:
isConfig
purge:
assetsNamesForLocale:
setInstalledLocales:useCellular:completion:
_assetManager
_assetStatusDictionary
_localeIdentifierList
pair
decodeIntegerForKey:
decodeObjectForKey:
encodeInteger:forKey:
initWithLocales:
pairState
setPairState:
setPair:
sourceASRState
setSourceASRState:
targetASRState
setTargetASRState:
mtState
setMtState:
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
needsUpdate
setNeedsUpdate:
_needsUpdate
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
canonicalIdentifier
_ltEqual:
isPassthrough
copyWithZone:
combinedLocaleIdentifier
isBidirectionalEqual:
isVariantPair
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
conversationID
setConversationID:
requestID
setRequestID:
setLocalePair:
selectedLocale
setSelectedLocale:
lidResult
setLidResult:
_conversationID
_requestID
_localePair
_selectedLocale
_lidResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"_LTLocalePair",C,N,V_localePair
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_lidResult
senses
setSenses:
userInteractedSenses
setUserInteractedSenses:
_senses
_userInteractedSenses
T@"NSArray",C,N,V_senses
T@"NSArray",C,N,V_userInteractedSenses
markResponse
markFirstParagraphComplete
markProgressDone
markPageComplete
dict
start
firstResponse
firstParagraphComplete
progressComplete
pageComplete
processName
_start
_firstResponse
_firstParagraphComplete
_progressComplete
_pageComplete
_processName
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_firstParagraphComplete
Td,R,N,V_progressComplete
Td,R,N,V_pageComplete
T@"NSString",C,N,V_processName
T@"NSDictionary",R,N
blazarServiceWithBundleID:
startSpeechLIDRequest:
startSpeechSensesLoggingRequest:
startSafariLatencyLoggingRequest:
startSafariFeedbackRequest:
mtAppService
performSpeechTranslationWithDelegate:requestBuilder:completion:
setTarget_locale:
setSource_locale:
setDetected_locale:
setLocale:
setConfidence:
setIs_low_confidence:
setPredictions:
setConversation_id:
setRequest_id:
setUser_selected_locale:
setTranslation_locale_pair:
setContentAsFTStartSpeechTranslationLoggingRequest:
sendSpeechTranslationStreamingRequest:
closeStream
setUser_selected_sense:
setUser_interacted_senses:
performBatchTranslationWithDelegate:requestBuilder:completion:
sourceContentAsJSON
setSource_content:
targetContentAsJSON
setTranslated_content:
webpageURL
absoluteString
setUrl:
errorsAsJSON
setErrors:
setSession_id:
setSource_language:
setTarget_language:
safariVersion
setSafari_version:
clientBundleID
setApp_id:
operatingSystemVersionString
setOs_version:
setDevice_type:
setContentAsFTBatchTranslationFeedbackRequest:
sendBatchTranslationStreamingRequest:
content_type
contentAsFTFinalBlazarResponse
return_code
return_str
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
_mtAppService
T@"FTBlazarService",R,N,V_mtAppService
initWithModelURL:language:modelVersion:
language
formattedString
triggerServerSideEndPointer
startRecognitionWithAutoStop:resultHandler:
cancelRecognition
initWithModelURLs:modelVersions:
startRecognitionForLocale:autoEndpoint:resultHandler:
_recognizers
_removeOldAssetDirectory
configAsset
getLocalFileUrl
timeIntervalSinceDate:
startCatalogDownload:options:then:
compareAssetVersionReversed:
isDownloading
configAssetInAssets:
_clearCaches
updateAllAssets:
_refreshAllAssets:
_refreshCatalogIfNeededWithCompletion:
results
deleteAsset:completion:
assetsSortedByVersion:
isASRModel
transcribesLocale:
isANEModel
URLByAppendingPathExtension:
bundleForClass:
URLForResource:withExtension:
dataWithContentsOfURL:options:error:
sortUsingComparator:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
availabilityInfo
downloadAsset:downloadOptions:progressCallback:completion:
longLongValue
progressWithTotalUnitCount:
setTotalUnitCount:
setCompletedUnitCount:
attachProgressCallBack:
totalUnitCount
startDownload:then:
_queryLanguagePairStatus:
preferredVoiceGender
arrayWithObject:
setLanguages:
setGender:
_downloadVoiceAsset:
getAutoDownloadedVoiceAssets:
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
assetDirectory
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
_assetIdentifiersForLanguagePairDirectory:
numberWithLong:
_speechTranslationAssetInfoForLocalePair:error:
purgeAssetUserInitiated:queue:completion:
matchesAsset:
isNewerCompatibleVersionThan:
_updateAsset:catalogAssets:downloadGroup:completion:
debugDumpAssets:
downloadAssetsUserInitiated:queue:completion:
updateSpeechTranslationAssetSymLinks:
createSymlinkDirectoryForMTAssets
downloadVoiceAssetsForLanguagePair:
downloadAsset:userInitiated:progressCallback:completion:
refreshAllIfNeededWithCompletion:
_downloadPassthroughAssetForLocale:userInitiated:completion:
assetIdentifierReferenceCountDictionary
isCompletePassthroughModel
isCompleteBidirectionalModel
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
getEndpointerAssetWithType:error:
resourceURL
fallBackAssetResourcePath
checkResourceIsReachableAndReturnError:
configurationPropertyListWithURL:
configAssetURL
offlineLanguageStatus:
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
modelURLsForLanguagePair:
speechTranslationAssetInfoForLocalePair:error:
assetSize:
_hotfixMgr
initWithType:
returnTypes:
queryMetaDataSync
initWithSuiteName:
substringToIndex:
setLanguageCode:
outputFileURL
setOutputPath:
audioSessionID
setAudioSessionID:
ttsPlaybackRate
setRate:
setCanUseServerTTS:
startSpeakingRequest:
stopSpeakingAtNextBoundary:synchronously:error:
dictionaryMetrics
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didStartPlayingPreviewRequest:
initWithCompletion:
speak:withContext:
_completion
asrModelURLs
speechModelURLForLocale:
speechModelVersionForLocale:
reason
mtModelURL
translationModelURLs
initWithModelURLs:task:skipNonFinalToCatchup:translatorCacheSize:
loadTranslatorFrom:to:
stringWithCString:encoding:
_loadRecognizers
taskHint
_loadTranslatorForTask:
censorSpeech
_loadEtiquetteSanitizers
tokens
initWithText:confidence:
lowConfidence
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:romanization:tokens:preToPostITN:
metaInfo
updateWithEngineMeta:locale:
resultWithLocale:translations:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithIdentifier:range:doNotTranslate:
_handleTranslationResults:withContext:
setSourceString:
setSanitizedSourceString:
translations
translateTokens:from:to:spans:completion:
romanization
sanitizedFormattedString
splitIntoSentences
spans
_translateString:withContext:toLocale:withSpans:completion:
_paragraphResultFromSentences:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
_translatePrepare:
passthroughResultWithString:sanitizedString:locale:
uniqueID
translateTokens:isFinal:completion:
prepareFor:to:
UUID
UUIDString
numberWithBool:
_translate:withContext:isFinal:completion:
transcriptions
asrConfidenceThreshold
setLowConfidence:
isLowConfidence
setSanitizedFormattedString:
isStable
_getBestRecognitionResult:context:
_waitForLIDWithContext:completion:
initWithLocalePair:assetInfo:
setAsrModelURLs:
setMtModelURL:
ttsCache
setTtsCache:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_didEndpointSpeech
_earError
_asrModelURLs
_mtModelURL
_ttsCache
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
T@"_LTTextToSpeechCache",&,N,V_ttsCache
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_paragraph
_requestParagraph
T@?,C,N,V_completion
T@"_LTTranslationParagraph",&,N,V_paragraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
request_id
contentAsFTBatchTranslationResponse
paragraph_id
return_string
span
translated_text
initWithOspreyBatchResponse:
updateAlignmentWithSourceSpan:targetSpan:
removeObjectForKey:
setHasFinalServerResponse:
endSuccessfully
endWithError:failedParagraphs:
callCompletionHandlersWithError:
request
setRequest:
toLocale
setToLocale:
batchLog
setBatchLog:
batchedParagraphs
setBatchedParagraphs:
bufferSize
setBufferSize:
setSessionID:
clientHeader
setClientHeader:
setClientIdentifier:
sourceURL
setSourceURL:
hasFinalServerResponse
completionHandlerCalled
setCompletionHandlerCalled:
logIdentifier
setLogIdentifier:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_batchLog
_batchedParagraphs
_taskHint
_bufferSize
_sessionID
_clientHeader
_clientIdentifier
_sourceURL
_logIdentifier
T@"FTMutableBatchTranslationRequest",&,N,V_request
T@"NSLocale",&,N,V_toLocale
T@"_LTBatchEventLog",&,N,V_batchLog
T@"NSMutableDictionary",&,N,V_batchedParagraphs
Tq,N,V_taskHint
TQ,N,V_bufferSize
T@"NSLocale",&,N,V_sourceLocale
T@"NSLocale",&,N,V_targetLocale
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
T@"NSString",C,N,V_clientHeader
T@"NSString",&,N,V_clientIdentifier
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
T@"NSString",C,N,V_logIdentifier
setMaxConcurrentOperationCount:
getSiriDataSharingOptInStatusWithCompletion:
initWithURL:configuration:
setUseCompression:
_webTaskService
_siriService
_systemService
_blazarService
updateServerTimeout
serverTimeoutFired
sendBatchTranslationRequestWithDelegate:
tokenize:forLocale:
audioDataForKey:
_ospreyTTSRequestWithText:
_serviceForTask:
speech_id
setClientTraceIdentifier:
error_code
error_str
decoder_description
word_timing_info
wordTimingInfoFromArray:
audio
cacheAudioData:forKey:
performTextToSpeechRouter:requestBuilder:completion:
setTranslations:
sequoiaClientHeaderValue
startServerTimeoutTimer
setParagraph_id:
setStart_index:
setEnd_index:
setDo_not_translate:
metaInfoData
initWithData:encoding:
setMeta_info:
setSpan:
cancelServerTimeout
setTask:
setParagraphs:
task
setContentAsFTBatchTranslationRequest:
setContent_type:
session_id
initWithRequest:logID:
paragraphs
startWithParagraphCount:
setValue:forHTTPHeaderField:
initWithIdentifier:text:spans:
_translateParagraph:index:context:completion:
_hasOngoingSpeechSession
setDataSharingOptInStatus:
initWithService:context:text:delegate:
_speechSessionCompletedWithError:
setCompletionBlock:
sendAudioData:
sendEndAudio
initWithService:context:delegate:
_tokenizeString:inLocale:
serverQueue
setServerQueue:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_dataSharingOptInStatus
_serverQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverQueue
initWithDelegate:
startCompressionNarrowband:
dataSharingOptInStatus
sendAnalyticsEvent
completionBlock
_ospreySpeechTranslationRequestWithHybridEndpointer:
initCommon
_ospreyTextToSpeechTranslationRequestWithText:
updateServerTimeout:
addAudioSampleData:
setPacket_count:
setContentAsFTFinishAudio:
_primaryLanguageRecognized
confirmDataIfNeeded
setContentAsFTLanguageDetected:
setAudio_bytes:
setAudio_frames:
setContentAsFTSpeechTranslationAudioPacket:
source_locale
initWithOspreyPartialRecognitionResponse:isSanitized:
initWithLocaleIdentifier:
initWithOspreyResponse:confidenceThreshold:isSanitized:
server_endpoint_features
initWithOspreySpeechTranslationMTResponse:
is_final
target_locale
text_to_speech_response
audio_type
_translationForLocale:
contentAsFTSpeechTranslationPartialRecognitionResponse
_handlePartialRecognitionResponse:
contentAsFTSpeechTranslationFinalRecognitionResponse
_handleFinalRecognitionResponse:
contentAsFTAudioLimitExceeded
_handleAudioLimitExceededResponse:
contentAsFTSpeechTranslationMtResponse
_handleTranslationResponse:
contentAsFTSpeechTranslationTextToSpeechResponse
_handleTTSResponse:
_handleFinalBlazarResponse:
contentAsFTSpeechTranslationServerEndpointFeatures
_handleServerEndpointFeatures:
didCompressPackets:totalPacketCount:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
_streamContext
_sentAudio
_sentEndAudio
_endpointedSpeech
_didReceiveAudioLimitExceededResponse
_didReceivePartialRecognitionResponse
_didReceiveFinalRecognitionResponse
_didReceiveTranslationResponse
_didReceiveTTSResponse
_didReceiveFinalBlazarResponse
_didTimeout
_error
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
Td,N,V_initialOnlineTimeout
Td,N,V_onlineTimeout
Td,N,V_endpointTimeout
T@?,C,N,V_completionBlock
_startTranslationWithTextService:done:
_translationFailedWithError:
string
appendString:
translationParagraph
initWithIdentifier:range:
isValidJSONObject:
dataWithJSONObject:options:error:
setMetaInfoData:
loggingType
_canUseTextService
_startTranslationWithService:done:
ranges
setRanges:
_ranges
T@"NSArray",C,N,V_ranges
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
dealloc
stop
isAudioQueueRunning
waitForAudioQueueStop
initWithContext:ASBD:
enqueue:packetCount:packetDescriptions:
signalQueueRunningStateChanged
flushAndStop
reset
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
Tq,R,N,V_state
orderedSetWithObjects:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
T@"NSOrderedSet",&,V_requestTypeSet
boolForKey:
arrayForKey:
dictionaryForKey:
URLWithString:
stringByReplacingCharactersInRange:withString:
initWithMaximumPageLoadRequest:maximumDynamicContentRequests:
allowedForRequests:
markPageLoaded
maximumPageLoadRequests
setMaximumPageLoadRequests:
maximumDynamicContentRequests
setMaximumDynamicContentRequests:
_count
_pageLoaded
_maximumPageLoadRequests
_maximumDynamicContentRequests
TQ,N,V_maximumPageLoadRequests
TQ,N,V_maximumDynamicContentRequests
app_id
initWithNSUUID:
setSessionId:
setMtId:
setNumParagraphs:
setSequenceNumber:
makeContext
setStartedOrChanged:
sendWithContext:
setExists:
setEnded:
setErrorDomain:
setErrorCode:
setError:
setNumParagraphFailures:
setFailed:
setCancelled:
setContextId:
setEventMetadata:
setBatchRequestContext:
sharedAnalytics
defaultMessageStream
sessionId
toNSUUID
emitMessage:isolatedStreamUUID:
dictionaryRepresentation
cancelWithReason:
convertLanguageCodeToSchemaLocale:
schemaPair
unknown
logStartedOrChanged
setInvocationContext:
mtId
logEndedWithQSSSessionID:
logFailedWithError:qssSessionID:
logCancelledWithReason:qssSessionID:
setLanguagePair:
setInputMode:
setIsOnDevice:
endSuccessfullyWithQSSSessionID:
endWithError:qssSessionID:
cancelWithReason:qssSessionID:
mtID
setMode:
setOnDevice:
context
T@"_LTInvocationEventContext",R,N,V_context
setIsExplicitLanguageFilterEnabled:
setIsLanguageIdentificationEnabled:
setIsOnDeviceTranslation:
setInputSource:
setDisplayMode:
setQssSessionId:
isOnDevice
explicitLanguageFilterEnabled
setExplicitLanguageFilterEnabled:
languageIDEnabled
setLanguageIDEnabled:
configVersion
setConfigVersion:
inputMode
uiMode
setUiMode:
languagePair
_isOnDevice
_explicitLanguageFilterEnabled
_languageIDEnabled
_configVersion
_task
_inputMode
_uiMode
_languagePair
TB,N,V_isOnDevice
TB,N,V_explicitLanguageFilterEnabled
TB,N,V_languageIDEnabled
T@"NSString",&,N,V_configVersion
Tq,N,V_task
Tq,N,V_inputMode
Tq,N,V_uiMode
T@"_LTLocalePair",&,N,V_languagePair
emitWithState:uuid:
mtSELFLog
setAsrStateUpdated:
setAsrState:
logFirstPacketDisplayed:
logFinalPacketSent:
logFinalPacketReceived:
Tq,R,V_state
fileURLWithPath:isDirectory:
lastPathComponent
fileURLWithPath:relativeToURL:
_createTemporaryOutputFileWithURL:
_playback:context:completion:audioStartHandler:
initWithEngine:
speak:context:completion:audioStartHandler:
_engine
_player
enableVAD
initForSeconds:
_startSpeechTranslationWithContext:
_translateSpeechAudioData:
consumeAll:
delegateTranslationDidFinishWithError:
initWithEngine:delegate:
engine
setEngine:
languageDetector
endpointer
_expectFinalLidResult
_sentFinalLidResult
_translationFinished
_speechActivityDetected
_translationError
_cache
_speechDetector
_languageDetector
_endpointer
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
T@"_LTLanguageDetector",R,N,V_languageDetector
T@"_LTHybridEndpointer",R,N,V_endpointer
initWithLocalePair:
setTtsPlaybackRate:
setOutputFileURL:
ttsProgressHandler
setTtsProgressHandler:
_ttsPlaybackRate
_ttsProgressHandler
T@"NSString",&,N,V_text
Td,N,V_ttsPlaybackRate
T@?,C,N,V_ttsProgressHandler
nativeAudioFormat
initWithFormat:
initWithSoundIdentifier:
addRequest:withObserver:error:
initWithStreamDescription:
initWithPCMFormat:frameCapacity:
setFrameLength:
int16ChannelData
analyzeAudioBuffer:atAudioFramePosition:
detected
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
_streamAnalyzer
_position
appendData:
mutableBytes
dataWithBytes:length:
replaceBytesInRange:withBytes:length:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
setData:
next
setNext:
_next
T@"NSData",&,N,V_data
T@"_LTSpeechDataQueueNode",&,N,V_next
_maxFrames
_currentFrames
_head
_tail
setFinal:
setStable:
setModelVersion:
recognition_result
post_itn
recognition_text
containsString:
post_itn_nbest_choices
initWithRecognitionChoice:inSausage:
setTranscriptions:
initWithOspreySausage:choices:locale:
setBestRecognitionAlternatives:
is_stable_result
setFormattedString:
setMinConfidence:
setMaxConfidence:
nBestResults
_transcriptionWithResult:locale:
recognition
initWithRecognition:wordConfidenceThreshold:
initWithFormattedString:locale:confidence:minConfidence:maxConfidence:
initWithPackage:locale:modelVersion:isFinal:
initWithResult:locale:modelVersion:isFinal:
initEmptyResultWithLocale:isFinal:
tokenName
hasSpaceAfter
whitespaceCharacterSet
resultWithPackage:locale:modelVersion:isFinal:
resultWithResult:locale:modelVersion:isFinal:
emptyResultWithLocale:isFinal:
bestRecognitionAlternatives
_final
_stable
_transcriptions
_bestRecognitionAlternatives
_modelVersion
final
TB,N,GisFinal,V_final
stable
TB,N,GisStable,V_stable
T@"NSString",&,N,V_modelVersion
T@"NSLocale",C,N,V_locale
T@"NSArray",&,N,V_transcriptions
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
alternative_index
positional_tok_phrase_alt
tok_phrases
token_text
add_space_after
setHasSpaceAfter:
unsignedIntegerValue
setBestAlternativeIndex:
setAlternatives:
alternatives
setBins:
interpretationIndices
tokenSausage
hasSpaceBefore
bins
_bins
T@"NSArray",&,N,V_bins
bestAlternativeIndex
_alternatives
_bestAlternativeIndex
T@"NSArray",&,N,V_alternatives
TQ,N,V_bestAlternativeIndex
_lowConfidence
_hasSpaceAfter
_confidence
Tq,N,V_confidence
TB,N,GisLowConfidence,V_lowConfidence
TB,N,V_hasSpaceAfter
supportedByQuasarConfig:
initWithConfiguration:useQuasarFormatter:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
setDetectUtterances:
setConcatenateUtterances:
runRecognitionWithResultStream:language:task:samplingRate:
recognitionHandler
_recognizedResult:error:
detectUtterances
stringWithString:
hatToQsrString:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
speechRecognizer:didRecognizeFinalResultCandidatePackage:
modelURL
setRecognitionHandler:
_buffer
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelURL
_language
_recognitionHandler
T@?,C,N,V_recognitionHandler
T@"NSURL",R,N,V_modelURL
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
_formattedString
_sanitizedFormattedString
_minConfidence
_maxConfidence
Td,N,V_confidence
Td,N,V_minConfidence
Td,N,V_maxConfidence
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
_getTranslationConfig
referenceAssets:catalogAssets:
updateAvailableInAssets:
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
isMTModel
isPhrasebook
isCurrentlyAvailable
_mtModelOfflineState
_languagePairDirectory
assetId
createSymbolicLinkAtPath:withDestinationPath:error:
writeToURL:atomically:
moveItemAtURL:toURL:error:
currentProgress
initWithParent:userInfo:
becomeCurrentWithPendingUnitCount:
resignCurrent
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_modelURLs
refreshState
hasResults
_isBuffering
_lastASRResults
_translationResult
_didFinish
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
countForObject:
sendAnalytics:isSupported:
weightedLocale
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
initWithScorer:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
initWithModel:
processString:
languageHypothesesWithMaximum:
availableLocales
detectionForStrings:strategy:
initWithSupportedLocales:
append:recognizer:
detectionForString:
detectionForStrings:
setAvailableLocales:
_availableLocales
T@"NSArray",C,N,V_availableLocales
initWithLocale:confidence:wordCount:
score
T@"NSLocale",R,C,N,V_locale
Td,R,N,V_confidence
Tq,R,N,V_wordCount
_wordCount:inLocale:
hasWeightedLocale
_items
_supportedLocales
TB,R,N
T@"NSLocale",R,C,N
clear
_cacheQueue
getCharacters:range:
componentsSeparatedByCharactersInSet:
predicateWithFormat:
filteredArrayUsingPredicate:
initWithUnit:
setLanguage:
setString:
enumerateTokensInRange:usingBlock:
tokensForRange:
stringWithCharacters:length:
sharedConnection
isOnDeviceOnlyTranslationForced
initWithBundleIdentifier:
specifiersForPolicyOptions:force:
groupSpecifierWithID:
rangeOfString:
valueWithNonretainedObject:
setPreferenceValue:specifier:
readPreferenceValue:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
presenterForPrivacySplashWithIdentifier:
setPresentingViewController:
present
specifiers
showTranslatePrivacy
translated_tokens
initWithOspreyToken:
setTokens:
meta_info_data
setRomanization:
translation_phrase
low_confidence
meta_info
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:locale:
initWithOspreyMtResponsePhrase:locale:injectingGenderTranslation:genderInjectedMetaInfo:
dataUsingEncoding:
statisticsWithEngineMeta:locale:
setStatistics:
sensesFromArray:
senseWithPhrasebookMatchMeta:
genderAlternativesFromDictionary:
setGenderAlternatives:
preToPostITN
genderAlternatives
statistics
proToPostITN
setProToPostITN:
_preToPostITN
_tokens
_genderAlternatives
_statistics
_romanization
_proToPostITN
T@"NSArray",C,N,V_tokens
T@"NSArray",C,N,V_proToPostITN
T@"NSArray",C,N,V_genderAlternatives
T@"_LTTranslationStatistics",C,N,V_statistics
T@"NSString",C,N,V_romanization
T@"NSArray",R,N,V_preToPostITN
setRestricted_mode:
_ospreyDataSharingStatus
setOpt_in_status:
setStreaming_mode:
setTranslation_locale_pairs:
setSpeech_id:
setTask_name:
setCodec:
setStream_results:
setStore_audio:
setEnd_point_mode:
setEnable_server_side_endpoint:
setClient_endpointer_model_version:
setEnable_hybrid_endpoint:
setKeyboard_identifier:
setInput_origin:
setInitial_recognition_candidate_id:
setDisable_auto_punctuation:
setStart_speech_request:
setTranslation_request:
_ttsVoiceStringWithLocale:
setAudio_type:
setChannel_type:
setText_to_speech_requests:
setContentAsFTStartSpeechTranslationRequest:
setTranslation_phrase:
setEnable_word_timing_info:
redactIfNeeded:
appendFormat:
sourceOrigin
decodeInt32ForKey:
encodeInt32:forKey:
setUniqueID:
setAutodetectLanguage:
setCensorSpeech:
setAutoEndpoint:
setLidThreshold:
setAppIdentifier:
setSourceOrigin:
setAsrConfidenceThreshold:
setEnableVAD:
untrustedClientIdentifier
setUntrustedClientIdentifier:
trustedClientIdentifier
_autodetectLanguage
_censorSpeech
_autoEndpoint
_enableVAD
_audioSessionID
_uniqueID
_outputFileURL
_lidThreshold
_route
_asrConfidenceThreshold
_sourceOrigin
_untrustedClientIdentifier
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
TB,N,V_autodetectLanguage
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
TB,N,V_enableVAD
T@"NSString",C,N,V_appIdentifier
Tq,N,V_sourceOrigin
T@"NSString",C,N,V_untrustedClientIdentifier
T@"NSString",R,C,N
T@"NSString",C,N,V_trustedClientIdentifier
Tq,N,V_dataSharingOptInStatus
setSourceContentAsJSON:
setTargetContentAsJSON:
setErrorsAsJSON:
setSafariVersion:
setWebpageURL:
_sourceContentAsJSON
_targetContentAsJSON
_errorsAsJSON
_safariVersion
_webpageURL
_clientBundleID
T@"NSString",C,N,V_clientBundleID
T@"NSString",C,N,V_sourceContentAsJSON
T@"NSString",C,N,V_targetContentAsJSON
T@"NSString",C,N,V_errorsAsJSON
T@"NSString",C,N,V_safariVersion
T@"NSURL",C,N,V_webpageURL
genderAlternativeFromDictionary:withGroup:
setGroup:
setDefaultGender:
group
defaultGender
_group
_defaultGender
T@"NSNumber",C,N,V_group
T@"NSString",&,N,V_defaultGender
initWithString:
addAttribute:value:range:
sentences
initWithIdentifier:range:shouldTranslate:metaInfoData:
enumerateAttributesInRange:options:usingBlock:
_spans
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
T@"NSArray",R,C,N,V_spans
initWithIdentifier:text:shouldTranslate:
setMetaInfo:
_metaInfo
TB,R,N,V_shouldTranslate
T@"NSDictionary",C,N,V_metaInfo
initWithLocalePair:suggestedUniqueID:
opaqueSessionID
initWithSourceLocale:targetLocale:suggestedUniqueID:
batchSessionUUID
_offlineMTModelURL
qssSessionID
serviceDelegate
setForcedOfflineTranslation:
set_forcedOnlineTranslation:
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
setBatchSessionUUID:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
_batchSessionUUID
T@"NSUUID",C,N,V_batchSessionUUID
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
TB,N,V_forcedOfflineTranslation
TB,N,V__forcedOnlineTranslation
T@"NSURL",&,N,V__offlineMTModelURL
Tq,N,V__mtConfidenceThreshold
ignoringAttributes
initForFutureServiceWithSessionID:
prepareWithService:
_paragraphRequestForText:
_handleParagraphResponse:error:
translate:
textTranslationHandler
alignments
appendAttributedString:
initWithString:attributes:
_realign:identifier:
_constructFinalParagraphResult
sentence
setSentence:
setIgnoringAttributes:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
setTextTranslationHandler:
_session
_savedAttributes
_paragraphOrder
_outstandingCount
_receivedParagraphs
_sentence
_ignoringAttributes
_textHandler
_translationHandler
_textTranslationHandler
T@"NSString",C,N,V_sentence
T@"NSAttributedString",C,N,V_text
T@"NSArray",C,N,V_ignoringAttributes
T@?,C,N,V_textHandler
T@?,C,N,V_translationHandler
T@?,C,N,V_textTranslationHandler
_paragraphs
T@"NSArray",C,N,V_paragraphs
_offlineASRModelURLs
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:simulateRealtime:
format
frameLength
_convertAndFeedPCMBuffer:
sleepForTimeInterval:
subdataWithRange:
_drainAndClearAudioConverter
_simulateRealtimeBehavior:
mutableAudioBufferList
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
appendAudioPCMBuffer:
append:simulateRealtime:
_lidModelURL
set_lidModelURL:
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
T@"NSURL",&,N,V__lidModelURL
T@"NSArray",&,N,V__offlineASRModelURLs
Tq,N,V__asrConfidenceThreshold
Tq,N,V__lidThreshold
objectForInfoDictionaryKey:
initWithLength:
translation_locale_pair
n_best_translated_phrases
translated_sentences
n_best_choices
start_index
end_index
do_not_translate
setAlignments:
initWithOspreyResponse:
sourceString
sanitizedSourceString
_translations
_sourceString
_sanitizedSourceString
_alignments
T@"NSArray",C,N,V_translations
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
senseID
definition
sourceMatch
targetMatch
senseFromDictionary:
setSenseID:
setDefinition:
setPhrasebookMatch:
isPhrasebookMatch
setSourceMatch:
setTargetMatch:
setLabels:
labels
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
_labels
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
T@"NSArray",C,N,V_labels
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
_speechSessionCompleted
containerURLForSecurityApplicationGroupIdentifier:
_initWithSuiteName:container:
cancelSpeechSession
cleanupOfflineEngine
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
_activityLogger
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
_commonInitWithSuggestedSessionID:
service
setService:
unsignedIntValue
setRateLimiter:
translationQueue
_getTextServiceProxyWithDelegate:useDedicatedTextMachPort:errorHandler:block:
translate:useDedicatedTextMachPort:
_ensureServiceConnection:useDedicatedTextMachPort:
log:
initWithTranslator:
provideFeedback:
setURL:
translator
setTranslator:
rateLimiter
setTranslationQueue:
_outstandingRequests
_logging
_waitingForService
_URL
_rateLimiter
T@"_LTTranslator",&,N,V_translator
T@"<_LTTextTranslationService>",&,N,V_service
T@"_LTRateLimiter",&,N,V_rateLimiter
T@"NSObject<OS_dispatch_queue>",&,N,V_translationQueue
T@"NSURL",C,N,V_URL
_metaInfoData
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
T@"NSData",C,N,V_metaInfoData
stringByReplacingOccurrencesOfString:withString:options:range:
_ltRemoveAllWhitespaces
_ltTrimWhitespaces
_countWithTokenString:countCharacters:
setInputTokenCount:
setInputSubtokenCount:
allocWithZone:
inputTokenCount
inputSubtokenCount
_inputTokenCount
_inputSubtokenCount
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
onDeviceModeEnabledWithDedicatedMachPort:completion:
_getSyncServiceProxyWithDelegate:errorHandler:block:
_getServiceProxyWithDelegate:errorHandler:block:
availableLocalePairsForTask:useDedicatedMachPort:completion:
infoDictionary
languagesForText:usingModel:strategy:useDedicatedTextMachPort:completion:
initWithMachServiceName:options:
invalidate
remoteObjectProxyWithErrorHandler:
initWithServiceName:options:
synchronousRemoteObjectProxyWithErrorHandler:
archivedDataWithRootObject:requiringSecureCoding:error:
interruptionHandler
installOfflineLocales:completion:
shouldPresentSystemFirstUseConsentWithDedicatedMachPort:completion:
taskIsSupportedInCurrentRegion:completion:
languagesForText:usingModel:useDedicatedTextMachPort:completion:
T@?,C,N
preheatForRequestSync:
preheatForRequest:completion:
startTranslationSession
word
sample_idx
offset
timestamp
initWithFTWordTimingInfo:
sampleIndex
_sampleIndex
_offset
_length
_word
_timestamp
T@"NSString",R,N,V_word
TI,R,N,V_sampleIndex
TI,R,N,V_offset
TI,R,N,V_length
Td,R,N,V_timestamp
requiredCapabilityIdentifier
assetVersion
isCompatibleWithThisDevice
isNewerVersionThan:
localeIdentifiers
canBePurged
translatesLanguagePair:
formatVersion
arrayWithCapacity:
arrayWithArray:
initWithAttributedString:
rangeOfCharacterFromSet:
rangeOfCharacterFromSet:options:
attributedSubstringFromRange:
_ltAttributedStringByTrimmingCharactersInSet:
T@"NSArray",R,N
stringByReplacingOccurrencesOfString:withString:
lt_realPath:
initWithFlatbuffData:root:verify:
initWithBytes:length:encoding:
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
_storage
_root
TI,R,N
session_message_type
session_messageAsFTStartPronGuessRequest
session_messageAsFTAudioPacket
session_messageAsFTFinishAudio
session_messageAsFTCancelRequest
session_messageAsFTPronGuessResponse
session_message_immutableClassForType:
session_message_typeForImmutableObject:
session_message
Tq,R,N
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
T@"FTPronGuessResponse",R,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
session_messageAsFTStartBatchRecoverRequest
session_messageAsFTBatchRecoverFinalResponse
T@"FTStartBatchRecoverRequest",R,N
T@"FTBatchRecoverFinalResponse",R,N
session_messageAsFTStartSpeechRequest
session_messageAsFTUpdateAudioInfo
session_messageAsFTSetRequestOrigin
session_messageAsFTSetSpeechContext
session_messageAsFTSetSpeechProfile
session_messageAsFTSetEndpointerState
session_messageAsFTResetServerEndpointer
session_messageAsFTCheckForSpeechRequest
session_messageAsFTSetAlternateRecognitionSausage
session_messageAsFTFinalSpeechRecognitionResponse
session_messageAsFTPartialSpeechRecognitionResponse
session_messageAsFTUpdatedAcousticProfile
session_messageAsFTEndPointLikelihood
session_messageAsFTEndPointCandidate
session_messageAsFTRecognitionProgress
session_messageAsFTCheckForSpeechResponse
session_messageAsFTRecognitionCandidate
session_messageAsFTRequestStatsResponse
session_messageAsFTServerEndpointFeatures
session_messageAsFTClientSetupInfo
session_messageAsFTAudioLimitExceeded
T@"FTStartSpeechRequest",R,N
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTServerEndpointFeatures",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
session_messageAsFTErrorBlamerRequest
session_messageAsFTErrorBlamerResponse
T@"FTErrorBlamerRequest",R,N
T@"FTErrorBlamerResponse",R,N
session_messageAsFTItnRequest
session_messageAsFTItnResponse
T@"FTItnRequest",R,N
T@"FTItnResponse",R,N
session_messageAsFTTextNormalizationRequest
session_messageAsFTTextNormalizationResponse
T@"FTTextNormalizationRequest",R,N
T@"FTTextNormalizationResponse",R,N
session_messageAsFTPostItnHammerRequest
session_messageAsFTPostItnHammerResponse
T@"FTPostItnHammerRequest",R,N
T@"FTPostItnHammerResponse",R,N
session_messageAsFTKeywordFinderRequest
session_messageAsFTKeywordFinderResponse
T@"FTKeywordFinderRequest",R,N
T@"FTKeywordFinderResponse",R,N
session_messageAsFTCorrectionsValidatorRequest
session_messageAsFTCorrectionsValidatorResponse
T@"FTCorrectionsValidatorRequest",R,N
T@"FTCorrectionsValidatorResponse",R,N
session_messageAsFTGraphemeToPhonemeRequest
session_messageAsFTGraphemeToPhonemeResponse
T@"FTGraphemeToPhonemeRequest",R,N
T@"FTGraphemeToPhonemeResponse",R,N
session_messageAsFTMultiUserStartSpeechRequest
session_messageAsFTFinalBlazarResponse
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
session_messageAsFTStartMultilingualSpeechRequest
session_messageAsFTLanguageDetected
T@"FTStartMultilingualSpeechRequest",R,N
T@"FTLanguageDetected",R,N
session_messageAsFTStartSpeechTranslationRequest
session_messageAsFTSpeechTranslationAudioPacket
session_messageAsFTStartSpeechTranslationLoggingRequest
session_messageAsFTSpeechTranslationPartialRecognitionResponse
session_messageAsFTSpeechTranslationFinalRecognitionResponse
session_messageAsFTSpeechTranslationMtResponse
session_messageAsFTSpeechTranslationTextToSpeechResponse
session_messageAsFTSpeechTranslationServerEndpointFeatures
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
session_messageAsFTBatchTranslationRequest
session_messageAsFTBatchTranslationFeedbackRequest
session_messageAsFTBatchTranslationLoggingRequest
session_messageAsFTTranslationSupportedLanguagesRequest
session_messageAsFTBatchTranslationResponse
session_messageAsFTTranslationSupportedLanguagesResponse
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationFeedbackRequest",R,N
T@"FTBatchTranslationLoggingRequest",R,N
T@"FTTranslationSupportedLanguagesRequest",R,N
T@"FTBatchTranslationResponse",R,N
T@"FTTranslationSupportedLanguagesResponse",R,N
session_messageAsFTTextToSpeechRequest
session_messageAsFTTextToSpeechResponse
T@"FTTextToSpeechRequest",R,N
T@"FTTextToSpeechResponse",R,N
session_messageAsFTStartTextToSpeechStreamingRequest
session_messageAsFTBeginTextToSpeechStreamingResponse
session_messageAsFTPartialTextToSpeechStreamingResponse
session_messageAsFTFinalTextToSpeechStreamingResponse
T@"FTStartTextToSpeechStreamingRequest",R,N
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
session_messageAsFTServiceDiscoveryRequest
session_messageAsFTServiceDiscoveryResponse
T@"FTServiceDiscoveryRequest",R,N
T@"FTServiceDiscoveryResponse",R,N
session_messageAsFTLmScorerRequest
session_messageAsFTLmScorerResponse
T@"FTLmScorerRequest",R,N
T@"FTLmScorerResponse",R,N
session_messageAsFTCreateLanguageProfileRequest
session_messageAsFTCreateLanguageProfileResponse
T@"FTCreateLanguageProfileRequest",R,N
T@"FTCreateLanguageProfileResponse",R,N
session_messageAsFTTranslationRequest
session_messageAsFTTranslationResponse
T@"FTTranslationRequest",R,N
T@"FTTranslationResponse",R,N
session_messageAsFTStreamingTranslationRequest
T@"FTStreamingTranslationRequest",R,N
session_messageAsFTQssAckResponse
T@"FTQssAckResponse",R,N
session_messageAsFTTextToSpeechSpeechFeatureRequest
session_messageAsFTTextToSpeechSpeechFeatureResponse
T@"FTTextToSpeechSpeechFeatureRequest",R,N
T@"FTTextToSpeechSpeechFeatureResponse",R,N
session_messageAsFTShortcutFuzzyMatchRequest
session_messageAsFTShortcutFuzzyMatchResponse
T@"FTShortcutFuzzyMatchRequest",R,N
T@"FTShortcutFuzzyMatchResponse",R,N
session_messageAsFTStartLanguageDetectionRequest
session_messageAsFTLanguageDetectionResponse
T@"FTStartLanguageDetectionRequest",R,N
T@"FTLanguageDetectionResponse",R,N
container_message_type
container_messageAsFTApgPronGuessMessage
container_messageAsFTApgBatchRecoverMessage
container_messageAsFTAsrRecognitionMessage
container_messageAsFTAsrErrorBlamerMessage
container_messageAsFTAsrItnMessage
container_messageAsFTAsrTextNormalizationMessage
container_messageAsFTAsrPostItnHammerMessage
container_messageAsFTAsrKeywordFinderMessage
container_messageAsFTAsrCorrectionsValidatorMessage
container_messageAsFTAsrGraphemeToPhonemeMessage
container_messageAsFTBlazarMultiUserMessage
container_messageAsFTBlazarMultilingualMessage
container_messageAsFTBlazarSpeechTranslationMessage
container_messageAsFTBlazarBatchTranslationMessage
container_messageAsFTBlazarTextToSpeechRouterMessage
container_messageAsFTBlazarTextToSpeechRouterStreamingMessage
container_messageAsFTBlazarServiceDiscoveryMessage
container_messageAsFTLmtLmScorerMessage
container_messageAsFTNapgCreateLanguageProfileMessage
container_messageAsFTMtTranslationMessage
container_messageAsFTMtStreamingTranslationMessage
container_messageAsFTTtsTextToSpeechMessage
container_messageAsFTTtsTextToSpeechStreamingMessage
container_messageAsFTTtsTextToSpeechSpeechFeatureMessage
container_messageAsFTNlShortcutFuzzyMatchMessage
container_messageAsFTSlsLanguageDetectionMessage
error_message
disable_session_log
container_message_immutableClassForType:
container_message_typeForImmutableObject:
container_message
T@"FTErrorMessage",R,N
T@"FTDisableSessionLog",R,N
T@"FTApgPronGuessMessage",R,N
T@"FTApgBatchRecoverMessage",R,N
T@"FTAsrRecognitionMessage",R,N
T@"FTAsrErrorBlamerMessage",R,N
T@"FTAsrItnMessage",R,N
T@"FTAsrTextNormalizationMessage",R,N
T@"FTAsrPostItnHammerMessage",R,N
T@"FTAsrKeywordFinderMessage",R,N
T@"FTAsrCorrectionsValidatorMessage",R,N
T@"FTAsrGraphemeToPhonemeMessage",R,N
T@"FTBlazarMultiUserMessage",R,N
T@"FTBlazarMultilingualMessage",R,N
T@"FTBlazarSpeechTranslationMessage",R,N
T@"FTBlazarBatchTranslationMessage",R,N
T@"FTBlazarTextToSpeechRouterMessage",R,N
T@"FTBlazarTextToSpeechRouterStreamingMessage",R,N
T@"FTBlazarServiceDiscoveryMessage",R,N
T@"FTLmtLmScorerMessage",R,N
T@"FTNapgCreateLanguageProfileMessage",R,N
T@"FTMtTranslationMessage",R,N
T@"FTMtStreamingTranslationMessage",R,N
T@"FTTtsTextToSpeechMessage",R,N
T@"FTTtsTextToSpeechStreamingMessage",R,N
T@"FTTtsTextToSpeechSpeechFeatureMessage",R,N
T@"FTNlShortcutFuzzyMatchMessage",R,N
T@"FTSlsLanguageDetectionMessage",R,N
initWithUnsignedInteger:
setError_code:
setReason:
TI,N
T@"NSString",C,N
initWithInteger:
setSession_message_type:
session_message_typeForObject:
session_message_mutableClassForType:
session_message_typeForMutableObject:
setSession_messageAsFTStartPronGuessRequest:
setSession_messageAsFTAudioPacket:
setSession_messageAsFTFinishAudio:
setSession_messageAsFTCancelRequest:
setSession_messageAsFTPronGuessResponse:
setSession_message:
Tq,N
T@"FTStartPronGuessRequest",C,N
T@"FTAudioPacket",C,N
T@"FTFinishAudio",C,N
T@"FTCancelRequest",C,N
T@"FTPronGuessResponse",C,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
setSession_messageAsFTStartBatchRecoverRequest:
setSession_messageAsFTBatchRecoverFinalResponse:
T@"FTStartBatchRecoverRequest",C,N
T@"FTBatchRecoverFinalResponse",C,N
setSession_messageAsFTStartSpeechRequest:
setSession_messageAsFTUpdateAudioInfo:
setSession_messageAsFTSetRequestOrigin:
setSession_messageAsFTSetSpeechContext:
setSession_messageAsFTSetSpeechProfile:
setSession_messageAsFTSetEndpointerState:
setSession_messageAsFTResetServerEndpointer:
setSession_messageAsFTCheckForSpeechRequest:
setSession_messageAsFTSetAlternateRecognitionSausage:
setSession_messageAsFTFinalSpeechRecognitionResponse:
setSession_messageAsFTPartialSpeechRecognitionResponse:
setSession_messageAsFTUpdatedAcousticProfile:
setSession_messageAsFTEndPointLikelihood:
setSession_messageAsFTEndPointCandidate:
setSession_messageAsFTRecognitionProgress:
setSession_messageAsFTCheckForSpeechResponse:
setSession_messageAsFTRecognitionCandidate:
setSession_messageAsFTRequestStatsResponse:
setSession_messageAsFTServerEndpointFeatures:
setSession_messageAsFTClientSetupInfo:
setSession_messageAsFTAudioLimitExceeded:
T@"FTStartSpeechRequest",C,N
T@"FTUpdateAudioInfo",C,N
T@"FTSetRequestOrigin",C,N
T@"FTSetSpeechContext",C,N
T@"FTSetSpeechProfile",C,N
T@"FTSetEndpointerState",C,N
T@"FTResetServerEndpointer",C,N
T@"FTCheckForSpeechRequest",C,N
T@"FTSetAlternateRecognitionSausage",C,N
T@"FTFinalSpeechRecognitionResponse",C,N
T@"FTPartialSpeechRecognitionResponse",C,N
T@"FTUpdatedAcousticProfile",C,N
T@"FTEndPointLikelihood",C,N
T@"FTEndPointCandidate",C,N
T@"FTRecognitionProgress",C,N
T@"FTCheckForSpeechResponse",C,N
T@"FTRecognitionCandidate",C,N
T@"FTRequestStatsResponse",C,N
T@"FTServerEndpointFeatures",C,N
T@"FTClientSetupInfo",C,N
T@"FTAudioLimitExceeded",C,N
setSession_messageAsFTErrorBlamerRequest:
setSession_messageAsFTErrorBlamerResponse:
T@"FTErrorBlamerRequest",C,N
T@"FTErrorBlamerResponse",C,N
setSession_messageAsFTItnRequest:
setSession_messageAsFTItnResponse:
T@"FTItnRequest",C,N
T@"FTItnResponse",C,N
setSession_messageAsFTTextNormalizationRequest:
setSession_messageAsFTTextNormalizationResponse:
T@"FTTextNormalizationRequest",C,N
T@"FTTextNormalizationResponse",C,N
setSession_messageAsFTPostItnHammerRequest:
setSession_messageAsFTPostItnHammerResponse:
T@"FTPostItnHammerRequest",C,N
T@"FTPostItnHammerResponse",C,N
setSession_messageAsFTKeywordFinderRequest:
setSession_messageAsFTKeywordFinderResponse:
T@"FTKeywordFinderRequest",C,N
T@"FTKeywordFinderResponse",C,N
setSession_messageAsFTCorrectionsValidatorRequest:
setSession_messageAsFTCorrectionsValidatorResponse:
T@"FTCorrectionsValidatorRequest",C,N
T@"FTCorrectionsValidatorResponse",C,N
setSession_messageAsFTGraphemeToPhonemeRequest:
setSession_messageAsFTGraphemeToPhonemeResponse:
T@"FTGraphemeToPhonemeRequest",C,N
T@"FTGraphemeToPhonemeResponse",C,N
setSession_messageAsFTMultiUserStartSpeechRequest:
setSession_messageAsFTFinalBlazarResponse:
T@"FTMultiUserStartSpeechRequest",C,N
T@"FTFinalBlazarResponse",C,N
setSession_messageAsFTStartMultilingualSpeechRequest:
setSession_messageAsFTLanguageDetected:
T@"FTStartMultilingualSpeechRequest",C,N
T@"FTLanguageDetected",C,N
setSession_messageAsFTStartSpeechTranslationRequest:
setSession_messageAsFTSpeechTranslationAudioPacket:
setSession_messageAsFTStartSpeechTranslationLoggingRequest:
setSession_messageAsFTSpeechTranslationPartialRecognitionResponse:
setSession_messageAsFTSpeechTranslationFinalRecognitionResponse:
setSession_messageAsFTSpeechTranslationMtResponse:
setSession_messageAsFTSpeechTranslationTextToSpeechResponse:
setSession_messageAsFTSpeechTranslationServerEndpointFeatures:
T@"FTStartSpeechTranslationRequest",C,N
T@"FTSpeechTranslationAudioPacket",C,N
T@"FTStartSpeechTranslationLoggingRequest",C,N
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
T@"FTSpeechTranslationMtResponse",C,N
T@"FTSpeechTranslationTextToSpeechResponse",C,N
T@"FTSpeechTranslationServerEndpointFeatures",C,N
setSession_messageAsFTBatchTranslationRequest:
setSession_messageAsFTBatchTranslationFeedbackRequest:
setSession_messageAsFTBatchTranslationLoggingRequest:
setSession_messageAsFTTranslationSupportedLanguagesRequest:
setSession_messageAsFTBatchTranslationResponse:
setSession_messageAsFTTranslationSupportedLanguagesResponse:
T@"FTBatchTranslationRequest",C,N
T@"FTBatchTranslationFeedbackRequest",C,N
T@"FTBatchTranslationLoggingRequest",C,N
T@"FTTranslationSupportedLanguagesRequest",C,N
T@"FTBatchTranslationResponse",C,N
T@"FTTranslationSupportedLanguagesResponse",C,N
setSession_messageAsFTTextToSpeechRequest:
setSession_messageAsFTTextToSpeechResponse:
T@"FTTextToSpeechRequest",C,N
T@"FTTextToSpeechResponse",C,N
setSession_messageAsFTStartTextToSpeechStreamingRequest:
setSession_messageAsFTBeginTextToSpeechStreamingResponse:
setSession_messageAsFTPartialTextToSpeechStreamingResponse:
setSession_messageAsFTFinalTextToSpeechStreamingResponse:
T@"FTStartTextToSpeechStreamingRequest",C,N
T@"FTBeginTextToSpeechStreamingResponse",C,N
T@"FTPartialTextToSpeechStreamingResponse",C,N
T@"FTFinalTextToSpeechStreamingResponse",C,N
setSession_messageAsFTServiceDiscoveryRequest:
setSession_messageAsFTServiceDiscoveryResponse:
T@"FTServiceDiscoveryRequest",C,N
T@"FTServiceDiscoveryResponse",C,N
setSession_messageAsFTLmScorerRequest:
setSession_messageAsFTLmScorerResponse:
T@"FTLmScorerRequest",C,N
T@"FTLmScorerResponse",C,N
setSession_messageAsFTCreateLanguageProfileRequest:
setSession_messageAsFTCreateLanguageProfileResponse:
T@"FTCreateLanguageProfileRequest",C,N
T@"FTCreateLanguageProfileResponse",C,N
setSession_messageAsFTTranslationRequest:
setSession_messageAsFTTranslationResponse:
T@"FTTranslationRequest",C,N
T@"FTTranslationResponse",C,N
setSession_messageAsFTStreamingTranslationRequest:
T@"FTStreamingTranslationRequest",C,N
setSession_messageAsFTQssAckResponse:
T@"FTQssAckResponse",C,N
setSession_messageAsFTTextToSpeechSpeechFeatureRequest:
setSession_messageAsFTTextToSpeechSpeechFeatureResponse:
T@"FTTextToSpeechSpeechFeatureRequest",C,N
T@"FTTextToSpeechSpeechFeatureResponse",C,N
setSession_messageAsFTShortcutFuzzyMatchRequest:
setSession_messageAsFTShortcutFuzzyMatchResponse:
T@"FTShortcutFuzzyMatchRequest",C,N
T@"FTShortcutFuzzyMatchResponse",C,N
setSession_messageAsFTStartLanguageDetectionRequest:
setSession_messageAsFTLanguageDetectionResponse:
T@"FTStartLanguageDetectionRequest",C,N
T@"FTLanguageDetectionResponse",C,N
setContainer_message_type:
container_message_typeForObject:
container_message_mutableClassForType:
container_message_typeForMutableObject:
setError_message:
setDisable_session_log:
setContainer_messageAsFTApgPronGuessMessage:
setContainer_messageAsFTApgBatchRecoverMessage:
setContainer_messageAsFTAsrRecognitionMessage:
setContainer_messageAsFTAsrErrorBlamerMessage:
setContainer_messageAsFTAsrItnMessage:
setContainer_messageAsFTAsrTextNormalizationMessage:
setContainer_messageAsFTAsrPostItnHammerMessage:
setContainer_messageAsFTAsrKeywordFinderMessage:
setContainer_messageAsFTAsrCorrectionsValidatorMessage:
setContainer_messageAsFTAsrGraphemeToPhonemeMessage:
setContainer_messageAsFTBlazarMultiUserMessage:
setContainer_messageAsFTBlazarMultilingualMessage:
setContainer_messageAsFTBlazarSpeechTranslationMessage:
setContainer_messageAsFTBlazarBatchTranslationMessage:
setContainer_messageAsFTBlazarTextToSpeechRouterMessage:
setContainer_messageAsFTBlazarTextToSpeechRouterStreamingMessage:
setContainer_messageAsFTBlazarServiceDiscoveryMessage:
setContainer_messageAsFTLmtLmScorerMessage:
setContainer_messageAsFTNapgCreateLanguageProfileMessage:
setContainer_messageAsFTMtTranslationMessage:
setContainer_messageAsFTMtStreamingTranslationMessage:
setContainer_messageAsFTTtsTextToSpeechMessage:
setContainer_messageAsFTTtsTextToSpeechStreamingMessage:
setContainer_messageAsFTTtsTextToSpeechSpeechFeatureMessage:
setContainer_messageAsFTNlShortcutFuzzyMatchMessage:
setContainer_messageAsFTSlsLanguageDetectionMessage:
setContainer_message:
T@"FTErrorMessage",C,N
T@"FTDisableSessionLog",C,N
T@"FTApgPronGuessMessage",C,N
T@"FTApgBatchRecoverMessage",C,N
T@"FTAsrRecognitionMessage",C,N
T@"FTAsrErrorBlamerMessage",C,N
T@"FTAsrItnMessage",C,N
T@"FTAsrTextNormalizationMessage",C,N
T@"FTAsrPostItnHammerMessage",C,N
T@"FTAsrKeywordFinderMessage",C,N
T@"FTAsrCorrectionsValidatorMessage",C,N
T@"FTAsrGraphemeToPhonemeMessage",C,N
T@"FTBlazarMultiUserMessage",C,N
T@"FTBlazarMultilingualMessage",C,N
T@"FTBlazarSpeechTranslationMessage",C,N
T@"FTBlazarBatchTranslationMessage",C,N
T@"FTBlazarTextToSpeechRouterMessage",C,N
T@"FTBlazarTextToSpeechRouterStreamingMessage",C,N
T@"FTBlazarServiceDiscoveryMessage",C,N
T@"FTLmtLmScorerMessage",C,N
T@"FTNapgCreateLanguageProfileMessage",C,N
T@"FTMtTranslationMessage",C,N
T@"FTMtStreamingTranslationMessage",C,N
T@"FTTtsTextToSpeechMessage",C,N
T@"FTTtsTextToSpeechStreamingMessage",C,N
T@"FTTtsTextToSpeechSpeechFeatureMessage",C,N
T@"FTNlShortcutFuzzyMatchMessage",C,N
T@"FTSlsLanguageDetectionMessage",C,N
profile_blob:
profile_blob_version
profile_checksum
profile_blob
T@"NSData",R,N
acoustic_profile_version
acoustic_profile_blob:
acoustic_profile_blob
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
phone_seq
ipa_phone_seq
Ti,R,N
tokens_enumerateObjectsUsingBlock:
tokens_objectAtIndex:
tokens_count
tok_phrases_enumerateObjectsUsingBlock:
has_unsuggested_alternatives
tok_phrases_objectAtIndex:
tok_phrases_count
positional_tok_phrase_alt_enumerateObjectsUsingBlock:
positional_tok_phrase_alt_objectAtIndex:
positional_tok_phrase_alt_count
alternative_index_enumerateObjectsUsingBlock:
numberWithInt:
alternative_index_objectAtIndex:
alternative_index_count
itn_alignment_enumerateObjectsUsingBlock:
itn_alignment
itn_alignment_objectAtIndex:
itn_alignment_count
post_itn_choice_indices_enumerateObjectsUsingBlock:
pre_itn_token_to_post_itn_char_alignments_enumerateObjectsUsingBlock:
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
post_itn_choice_indices_objectAtIndex:
post_itn_choice_indices_count
pre_itn_token_to_post_itn_char_alignments_objectAtIndex:
pre_itn_token_to_post_itn_char_alignments_count
pre_itn_nbest_choices_enumerateObjectsUsingBlock:
post_itn_nbest_choices_enumerateObjectsUsingBlock:
pre_itn_token_to_post_itn_char_alignment_enumerateObjectsUsingBlock:
choice_alignments_enumerateObjectsUsingBlock:
pre_itn
pre_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
pre_itn_nbest_choices_objectAtIndex:
pre_itn_nbest_choices_count
post_itn_nbest_choices_objectAtIndex:
post_itn_nbest_choices_count
pre_itn_token_to_post_itn_char_alignment_objectAtIndex:
pre_itn_token_to_post_itn_char_alignment_count
choice_alignments_objectAtIndex:
choice_alignments_count
T@"FTRecognitionSausage",R,N
bool_stats_enumerateObjectsUsingBlock:
int32_stats_enumerateObjectsUsingBlock:
double_stats_enumerateObjectsUsingBlock:
bool_stats
int32_stats
double_stats
request_locale
bool_stats_objectAtIndex:
bool_stats_count
int32_stats_objectAtIndex:
int32_stats_count
double_stats_objectAtIndex:
double_stats_count
name
value
Td,R,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
acoustic_feature_per_frame_enumerateObjectsUsingBlock:
numberWithFloat:
acoustic_feature_per_frame
frame_duration
acoustic_feature_per_frame_objectAtIndex:
acoustic_feature_per_frame_count
Tf,R,N
speech_recognition_features_enumerateObjectsUsingBlock:
acoustic_features_enumerateObjectsUsingBlock:
speech_recognition_features
acoustic_features
speech_recognition_features_objectAtIndex:
speech_recognition_features_count
acoustic_features_objectAtIndex:
acoustic_features_count
T@"FTAcousticFeature",R,N
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,R,N
user_parameters_enumerateObjectsUsingBlock:
start_speech_request
user_parameters
primary_speech_id
user_parameters_objectAtIndex:
user_parameters_count
product_id
vendor_id
pron_hints_enumerateObjectsUsingBlock:
contextual_text
pron_hints
pron_hints_objectAtIndex:
pron_hints_count
contextual_text_enumerateObjectsUsingBlock:
context_with_pron_hints_enumerateObjectsUsingBlock:
left_context
right_context
context_with_pron_hints
contextual_text_objectAtIndex:
contextual_text_count
context_with_pron_hints_objectAtIndex:
context_with_pron_hints_count
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
audio_bytes:
audio_bytes
features_at_endpoint_enumerateObjectsUsingBlock:
server_feature_latency_distribution_enumerateObjectsUsingBlock:
packet_count
total_audio_recorded_seconds
features_at_endpoint
server_feature_latency_distribution
features_at_endpoint_objectAtIndex:
features_at_endpoint_count
server_feature_latency_distribution_objectAtIndex:
server_feature_latency_distribution_count
updated_acoustic_profile
orthography
pronunciations:
frequency
pronunciations
attributes_enumerateObjectsUsingBlock:
attributes_objectAtIndex:
attributes_count
category_data_enumerateObjectsUsingBlock:
category_name
category_data
category_data_objectAtIndex:
category_data_count
user_data_enumerateObjectsUsingBlock:
user_data
user_data_objectAtIndex:
user_data_count
incomplete_profile
recreate_apg_prons
phonemes
blob:
blob
tts_pronunciations_enumerateObjectsUsingBlock:
human_readable_prons_enumerateObjectsUsingBlock:
apg_id
voc_token
tts_pronunciations
human_readable_prons
tts_pronunciations_objectAtIndex:
tts_pronunciations_count
human_readable_prons_objectAtIndex:
human_readable_prons_count
T@"FTVocToken",R,N
apg_ids_enumerateObjectsUsingBlock:
apg_ids
apg_ids_objectAtIndex:
apg_ids_count
recovery_return_codes_enumerateObjectsUsingBlock:
voc_tokens_enumerateObjectsUsingBlock:
recovery_return_codes
voc_tokens
recovery_return_codes_objectAtIndex:
recovery_return_codes_count
voc_tokens_objectAtIndex:
voc_tokens_count
num_of_requested
num_of_processed
num_of_succeeded
words_list_enumerateObjectsUsingBlock:
words_list
words_list_objectAtIndex:
words_list_count
formatted_words_list_enumerateObjectsUsingBlock:
formatted_words_list
formatted_words_list_objectAtIndex:
formatted_words_list_count
post_itn_string
nbest_variants_max
normalized_tokens_enumerateObjectsUsingBlock:
normalized_tokens
normalized_tokens_objectAtIndex:
normalized_tokens_count
nbest_variants_enumerateObjectsUsingBlock:
original_token
nbest_variants
nbest_variants_objectAtIndex:
nbest_variants_count
pron_sequence
log_weight
pron_source
sanitized_sequences_enumerateObjectsUsingBlock:
prons_enumerateObjectsUsingBlock:
normalized_prons_enumerateObjectsUsingBlock:
sanitized_sequences
prons
normalized_prons
sanitized_sequences_objectAtIndex:
sanitized_sequences_count
prons_objectAtIndex:
prons_count
normalized_prons_objectAtIndex:
normalized_prons_count
sanitized_tokens_enumerateObjectsUsingBlock:
sanitized_tokens
sanitized_tokens_objectAtIndex:
sanitized_tokens_count
T@"FTContextWithPronHints",R,N
phonemes_enumerateObjectsUsingBlock:
aot_token_prons_enumerateObjectsUsingBlock:
jit_token_prons_enumerateObjectsUsingBlock:
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
jit_token_prons
phonemes_objectAtIndex:
phonemes_count
aot_token_prons_objectAtIndex:
aot_token_prons_count
jit_token_prons_objectAtIndex:
jit_token_prons_count
index_enumerateObjectsUsingBlock:
index
index_objectAtIndex:
index_count
span_enumerateObjectsUsingBlock:
span_objectAtIndex:
span_count
raw_nbest_choices_enumerateObjectsUsingBlock:
raw_sausage
raw_nbest_choices
raw_nbest_choices_objectAtIndex:
raw_nbest_choices_count
post_itn_tokens_enumerateObjectsUsingBlock:
itn_alignments_enumerateObjectsUsingBlock:
translation_phrase_enumerateObjectsUsingBlock:
post_itn_tokens
post_itn_recognition
itn_alignments
post_itn_tokens_objectAtIndex:
post_itn_tokens_count
itn_alignments_objectAtIndex:
itn_alignments_count
translation_phrase_objectAtIndex:
translation_phrase_count
pre_itn_payload
post_itn_payload
pre_sausage_payload
spans_enumerateObjectsUsingBlock:
spans_objectAtIndex:
spans_count
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
use_case
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
translation_text
final_message
n_best_translated_phrases_enumerateObjectsUsingBlock:
engine_output_enumerateObjectsUsingBlock:
engine_input
engine_output
n_best_translated_phrases_objectAtIndex:
n_best_translated_phrases_count
engine_output_objectAtIndex:
engine_output_count
mt_alignment
T@"FTAlignment",R,N
translated_tokens_enumerateObjectsUsingBlock:
translated_tokens_objectAtIndex:
translated_tokens_count
T@"FTTranslationPhraseMetaInfo",R,N
end_point_likelihood
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
calibration_scale
calibration_offset
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets_enumerateObjectsUsingBlock:
audio_packets
ref_transcript
audio_packets_objectAtIndex:
audio_packets_count
blamer_report
token_str
log10_score
ngram_used
transcript
keyword_orthography
posterior
keywords_enumerateObjectsUsingBlock:
keywords
enable_sanitization
keywords_objectAtIndex:
keywords_count
n_best_list_enumerateObjectsUsingBlock:
corrected_sausage
n_best_list
n_best_list_objectAtIndex:
n_best_list_count
pause_counts_enumerateObjectsUsingBlock:
pause_counts_objectAtIndex:
pause_counts_count
original_utterance
corrected_utterance
original_words
corrected_words
corrections_enumerateObjectsUsingBlock:
corrections
corrections_objectAtIndex:
corrections_count
fe_feature
fe_feature_only
disable_prompts
cache_only
phoneset_type
quality
type
voice
resource
server_info
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
T@"FTQSSVersionInfo",R,N
channel_type
is_synthesis
context_info_enumerateObjectsUsingBlock:
context_info
dialog_identifier
context_info_objectAtIndex:
context_info_count
experiment_identifier
word_phonemes_enumerateObjectsUsingBlock:
word_phonemes
word_phonemes_objectAtIndex:
word_phonemes_count
prompts_enumerateObjectsUsingBlock:
prompts
prompts_v2:
prompts_objectAtIndex:
prompts_count
prompts_v2
original
replacement
normalized_text_enumerateObjectsUsingBlock:
phoneme_sequence_enumerateObjectsUsingBlock:
replacement_enumerateObjectsUsingBlock:
neural_phoneme_sequence_enumerateObjectsUsingBlock:
normalized_text
phoneme_sequence
neural_phoneme_sequence
normalized_text_objectAtIndex:
normalized_text_count
phoneme_sequence_objectAtIndex:
phoneme_sequence_count
replacement_objectAtIndex:
replacement_count
neural_phoneme_sequence_objectAtIndex:
neural_phoneme_sequence_count
force_use_tts_service
disable_cache
data:
resources_enumerateObjectsUsingBlock:
resources
resources_objectAtIndex:
resources_count
return_log
voice_asset_path
resource_asset_path
return_server_info
has_click
worker_process_type
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
enable_word_timing_info
voice_name
preferred_voice_type
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTTextToSpeechRequestDebug",R,N
T@"FTTextToSpeechUserProfile",R,N
T@"FTTextToSpeechRequestDevConfig",R,N
T@"FTTextToSpeechRequestProsodyTransferConfig",R,N
T@"FTTextToSpeechRequestProsodyControlConfig",R,N
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
T@"FTTextToSpeechSpeechFeatureInputWave",R,N
T@"FTTextToSpeechUserVoiceProfile",R,N
word_timing_info_enumerateObjectsUsingBlock:
audio:
playback_description
feature
dev_data
word_timing_info_objectAtIndex:
word_timing_info_count
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
T@"FTTextToSpeechResponseDevData",R,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_object_enumerateObjectsUsingBlock:
cache_meta_info
cache_object
cache_object_objectAtIndex:
cache_object_count
T@"FTTextToSpeechCacheMetaInfo",R,N
cached_request
cached_response
cached_partial_response_enumerateObjectsUsingBlock:
cached_begin_response
cached_partial_response
cached_final_response
cached_partial_response_objectAtIndex:
cached_partial_response_count
words_enumerateObjectsUsingBlock:
words
words_objectAtIndex:
words_count
pcm_data:
pcm_data
phone_name
begin_time
end_time
duration
pitch
energy
phonemeseq_enumerateObjectsUsingBlock:
phonemeseq
phonemeseq_objectAtIndex:
phonemeseq_count
lexicon_enumerateObjectsUsingBlock:
model_id
lexicon
support_homograph
lexicon_objectAtIndex:
lexicon_count
T@"FTTextToSpeechSpeechFeatureModelIdentifier",R,N
T@"FTTextToSpeechSpeechFeatureInputText",R,N
T@"FTTextToSpeechSpeechFeatureInputPhonemeSequence",R,N
features_enumerateObjectsUsingBlock:
features
features_objectAtIndex:
features_count
endpoint_threshold
endpoint_extra_delay
zk_path
zk_node_enumerateObjectsUsingBlock:
zk_node
zk_node_objectAtIndex:
zk_node_count
audio_frames_enumerateObjectsUsingBlock:
audio_frames
audio_frames_objectAtIndex:
audio_frames_count
translation_locale_pairs_enumerateObjectsUsingBlock:
text_to_speech_requests_enumerateObjectsUsingBlock:
conversation_id
translation_locale_pairs
translation_request
text_to_speech_requests
restricted_mode
streaming_mode
translation_locale_pairs_objectAtIndex:
translation_locale_pairs_count
text_to_speech_requests_objectAtIndex:
text_to_speech_requests_count
senses_enumerateObjectsUsingBlock:
user_interacted_senses_enumerateObjectsUsingBlock:
detected_locale
user_selected_locale
user_selected_sense
user_interacted_senses
senses_objectAtIndex:
senses_count
user_interacted_senses_objectAtIndex:
user_interacted_senses_count
T@"FTTranslationLocalePair",R,N
shortcuts_enumerateObjectsUsingBlock:
utterance
shortcuts
interaction_id
shortcuts_objectAtIndex:
shortcuts_count
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
raw_string
shortcut_score_pairs_enumerateObjectsUsingBlock:
shortcut_score_pairs
shortcut_score_pairs_objectAtIndex:
shortcut_score_pairs_count
shortcut
similarity_score
language_parameters_by_id_enumerateObjectsUsingBlock:
language_parameters_by_id
language_parameters_by_id_objectAtIndex:
language_parameters_by_id_count
is_low_confidence
predictions_enumerateObjectsUsingBlock:
predictions
predictions_objectAtIndex:
predictions_count
paragraphs_enumerateObjectsUsingBlock:
paragraphs_objectAtIndex:
paragraphs_count
source_content
translated_content
errors
safari_version
os_version
time_to_first_response
time_to_viewport_complete
time_to_page_complete
translated_sentences_enumerateObjectsUsingBlock:
translated_sentences_objectAtIndex:
translated_sentences_count
repeated_spans_enumerateObjectsUsingBlock:
repeated_spans
repeated_spans_objectAtIndex:
repeated_spans_count
n_best_choices_enumerateObjectsUsingBlock:
source_span
target_span
n_best_choices_objectAtIndex:
n_best_choices_count
T@"FTSpan",R,N
sentence_count
language_pairs_enumerateObjectsUsingBlock:
language_pairs
language_pairs_objectAtIndex:
language_pairs_count
locales_enumerateObjectsUsingBlock:
locales_objectAtIndex:
locales_count
qss_version_server
qss_version_brane
qss_version_serverkit
qss_version_siritts
setProfile_blob:
setProfile_blob_version:
setProfile_checksum:
T@"NSData",C,N
setAcoustic_profile_version:
setAcoustic_profile_blob:
initWithInt:
initWithBool:
setToken_text:
setStart_milli_seconds:
setEnd_milli_seconds:
setSilence_start_milli_seconds:
setAdd_space_after:
setPhone_seq:
setIpa_phone_seq:
Ti,N
TB,N
T@"NSArray",C,N
setTok_phrases:
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
setItn_alignment:
setPost_itn_choice_indices:
setPre_itn_token_to_post_itn_char_alignments:
setPre_itn:
setPost_itn:
setPre_itn_nbest_choices:
setPost_itn_nbest_choices:
setPre_itn_token_to_post_itn_char_alignment:
setChoice_alignments:
T@"FTRecognitionSausage",C,N
setBool_stats:
setInt32_stats:
setDouble_stats:
setRequest_locale:
setName:
setValue:
initWithDouble:
Td,N
setFirst_pre_itn_token_index:
setLast_pre_itn_token_index:
setFirst_post_itn_char_pos:
setLast_post_itn_char_pos:
initWithFloat:
setAcoustic_feature_per_frame:
setFrame_duration:
Tf,N
setSpeech_recognition_features:
setAcoustic_features:
setKey:
T@"FTAcousticFeature",C,N
setReturn_code:
setReturn_str:
setRecognition_result:
setLang_profile_recreate_codes:
setAudio_analytics:
setWatermark_detection:
setWatermark_peak_average:
setLatnn_mitigator_result:
setHas_result:
T@"FTRecognitionResult",C,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
setRecognition_text:
setIs_stable_result:
setAudio_duration_ms:
unsignedLongValue
initWithUnsignedLong:
setDevice_os:
setMic_type:
setUdm_host:
setUdm_port:
setTandem_mode:
setStream_unstable_results:
setStart_audio_bookmark:
setIs_far_field:
setEnable_utterance_detection:
setEnable_endpoint_candidate:
setStart_recognition_at:
setStart_endpointing_at:
setKeyboard_dictation:
setExperiment_id:
setSpeech_request_source:
setFork_id:
setApplication_name:
setMetadata:
TQ,N
setUser_parameters:
setPrimary_speech_id:
setProduct_id:
setVendor_id:
setContextual_text:
setPron_hints:
setLeft_context:
setRight_context:
setContext_with_pron_hints:
setUser_language_profile:
setUser_acoustic_profile:
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
setTotal_audio_recorded_seconds:
setFeatures_at_endpoint:
setServer_feature_latency_distribution:
setUpdated_acoustic_profile:
setOrthography:
setPronunciations:
setFrequency:
setTag:
setAttributes:
setCategory_name:
setCategory_data:
setUser_data:
setError_str:
setIncomplete_profile:
setRecreate_apg_prons:
setPhonemes:
setBlob:
setApg_id:
setVoc_token:
setTts_pronunciations:
setHuman_readable_prons:
T@"FTVocToken",C,N
setApg_ids:
setRecovery_return_codes:
setVoc_tokens:
setNum_of_requested:
setNum_of_processed:
setNum_of_succeeded:
setWords_list:
setFormatted_words_list:
setPost_itn_string:
setNbest_variants_max:
setNormalized_tokens:
setOriginal_token:
setNbest_variants:
setPron_sequence:
setLog_weight:
setPron_source:
setSanitized_sequences:
setProns:
setNormalized_prons:
setSanitized_tokens:
T@"FTContextWithPronHints",C,N
setIs_pron_guessed:
setG2p_version:
setG2p_model_version:
setPhoneset_version:
setAot_token_prons:
setJit_token_prons:
setIndex:
setRaw_sausage:
setRaw_nbest_choices:
setPost_itn_tokens:
setPost_itn_recognition:
setItn_alignments:
setPre_itn_payload:
setPost_itn_payload:
setPre_sausage_payload:
setSpans:
setSiri_translation_info:
setSpeech_translation_info:
setSiri_payload_translation_info:
setSequence_id:
setWeb_translation_info:
setDisable_log:
setUse_case:
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
setTranslation_text:
setFinal_message:
setReturn_string:
setN_best_translated_phrases:
setEngine_input:
setEngine_output:
setMt_alignment:
T@"FTAlignment",C,N
setTranslated_tokens:
setLow_confidence:
setMeta_info_data:
T@"FTTranslationPhraseMetaInfo",C,N
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
setLatitude:
setLongitude:
setEnable_geo_location_features:
longValue
initWithLong:
setSpeech_packet_count:
setProcessed:
setVersion:
setThreshold:
setScore:
setCalibration_scale:
setCalibration_offset:
setResult_id:
setSnr:
setFingerprint_detection:
setStart_speech_time:
setEnd_speech_time:
setSpeech_detected:
setAudio_packets:
setRef_transcript:
setBlamer_report:
setToken_str:
setLog10_score:
setNgram_used:
setTranscript:
setPpl:
setKeyword_orthography:
setPosterior:
setKeywords:
setEnable_sanitization:
setCorrected_sausage:
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
setOriginal_utterance:
setCorrected_utterance:
setOriginal_words:
setCorrected_words:
setCorrections:
setFe_feature:
setFe_feature_only:
setDisable_prompts:
setCache_only:
setPhoneset_type:
setQuality:
setType:
setVoice:
setResource:
setServer_info:
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
T@"FTQSSVersionInfo",C,N
setIs_synthesis:
setContext_info:
setDialog_identifier:
setExperiment_identifier:
setWord_phonemes:
setPrompts:
setPrompts_v2:
setOriginal:
setReplacement:
setNormalized_text:
setPhoneme_sequence:
setNeural_phoneme_sequence:
setForce_use_tts_service:
setDisable_cache:
setResources:
setReturn_log:
setVoice_asset_path:
setResource_asset_path:
setReturn_server_info:
setLog:
setHas_click:
setWorker_process_type:
setGlobal_rate:
setGlobal_pitch:
setGlobal_energy:
setGlobal_sent_pitch:
setGlobal_sent_pitchrange:
setGlobal_sent_duration:
setGlobal_sent_energy:
setGlobal_sent_tilt:
setVoice_name:
setPreferred_voice_type:
setContext:
setExperiment:
setFeature_flags:
setDebug:
setProfile:
setDev_config:
setProsody_config:
setProsody_control_config:
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
T@"FTTextToSpeechRequestDebug",C,N
T@"FTTextToSpeechUserProfile",C,N
T@"FTTextToSpeechRequestDevConfig",C,N
T@"FTTextToSpeechRequestProsodyTransferConfig",C,N
T@"FTTextToSpeechRequestProsodyControlConfig",C,N
setPitch_mean:
setPitch_std:
setEnergy_mean:
setEnergy_std:
setDuration_mean:
setDuration_std:
setWave_data:
setUser_voice_profile:
setUser_voice_profile_url:
T@"FTTextToSpeechSpeechFeatureInputWave",C,N
T@"FTTextToSpeechUserVoiceProfile",C,N
setSample_rate:
setFormat_id:
setFormat_flags:
setBytes_per_packet:
setFrames_per_packet:
setBytes_per_frame:
setChannels_per_frame:
setBits_per_channel:
setReserved:
setWord:
setSample_idx:
setOffset:
setLength:
setTimestamp:
setAudio:
setDecoder_description:
setPlayback_description:
setWord_timing_info:
setFeature:
setDev_data:
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
T@"FTTextToSpeechResponseDevData",C,N
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setCurrent_pkt_number:
setTotal_pkt_number:
setAudio_length:
setOriginal_session_id:
setCache_meta_info:
setCache_object:
T@"FTTextToSpeechCacheMetaInfo",C,N
setCached_request:
setCached_response:
setCached_begin_response:
setCached_partial_response:
setCached_final_response:
setWords:
setPcm_data:
setPhone_name:
setBegin_time:
setEnd_time:
setDuration:
setPitch:
setEnergy:
setPhonemeseq:
setModel_id:
setLexicon:
setSupport_homograph:
T@"FTTextToSpeechSpeechFeatureModelIdentifier",C,N
T@"FTTextToSpeechSpeechFeatureInputText",C,N
T@"FTTextToSpeechSpeechFeatureInputPhonemeSequence",C,N
setFeatures:
setEndpoint_threshold:
setEndpoint_extra_delay:
setZk_path:
setZk_node:
T@"FTTranslationLocalePair",C,N
setIs_final:
setText_to_speech_response:
setServer_endpoint_features:
setUtterance:
setShortcuts:
setInteraction_id:
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
setRaw_string:
setShortcut_score_pairs:
setShortcut:
setSimilarity_score:
setLanguage_parameters_by_id:
setTime_to_first_response:
setTime_to_viewport_complete:
setTime_to_page_complete:
setTranslated_text:
setTranslated_sentences:
setRepeated_spans:
setSource_span:
setTarget_span:
setN_best_choices:
T@"FTSpan",C,N
setSentence_count:
setLanguage_pairs:
setQss_version_server:
setQss_version_brane:
setQss_version_serverkit:
setQss_version_siritts:
contentAsFTStartPronGuessRequest
contentAsFTAudioPacket
contentAsFTFinishAudio
contentAsFTCancelRequest
content_immutableClassForType:
content_typeForImmutableObject:
content
contentAsFTPronGuessResponse
contentAsFTStartBatchRecoverRequest
contentAsFTBatchRecoverFinalResponse
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
contentAsFTSetRequestOrigin
contentAsFTSetSpeechContext
contentAsFTSetSpeechProfile
contentAsFTSetEndpointerState
contentAsFTResetServerEndpointer
contentAsFTCheckForSpeechRequest
contentAsFTSetAlternateRecognitionSausage
contentAsFTFinalSpeechRecognitionResponse
contentAsFTPartialSpeechRecognitionResponse
contentAsFTUpdatedAcousticProfile
contentAsFTEndPointLikelihood
contentAsFTEndPointCandidate
contentAsFTRecognitionProgress
contentAsFTCheckForSpeechResponse
contentAsFTRecognitionCandidate
contentAsFTRequestStatsResponse
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
contentAsFTMultiUserStartSpeechRequest
contentAsFTStartMultilingualSpeechRequest
contentAsFTLanguageDetected
contentAsFTStartSpeechTranslationRequest
contentAsFTSpeechTranslationAudioPacket
contentAsFTStartSpeechTranslationLoggingRequest
contentAsFTBatchTranslationRequest
contentAsFTBatchTranslationFeedbackRequest
contentAsFTBatchTranslationLoggingRequest
contentAsFTTranslationSupportedLanguagesRequest
contentAsFTTranslationSupportedLanguagesResponse
contentAsFTStartTextToSpeechStreamingRequest
contentAsFTBeginTextToSpeechStreamingResponse
contentAsFTPartialTextToSpeechStreamingResponse
contentAsFTFinalTextToSpeechStreamingResponse
contentAsFTStreamingTranslationRequest
contentAsFTTranslationResponse
contentAsFTQssAckResponse
contentAsFTStartLanguageDetectionRequest
contentAsFTLanguageDetectionResponse
content_typeForObject:
content_mutableClassForType:
content_typeForMutableObject:
setContentAsFTStartPronGuessRequest:
setContentAsFTAudioPacket:
setContentAsFTCancelRequest:
setContent:
setContentAsFTPronGuessResponse:
setContentAsFTStartBatchRecoverRequest:
setContentAsFTBatchRecoverFinalResponse:
setContentAsFTStartSpeechRequest:
setContentAsFTUpdateAudioInfo:
setContentAsFTSetRequestOrigin:
setContentAsFTSetSpeechContext:
setContentAsFTSetSpeechProfile:
setContentAsFTSetEndpointerState:
setContentAsFTResetServerEndpointer:
setContentAsFTCheckForSpeechRequest:
setContentAsFTSetAlternateRecognitionSausage:
setContentAsFTFinalSpeechRecognitionResponse:
setContentAsFTPartialSpeechRecognitionResponse:
setContentAsFTUpdatedAcousticProfile:
setContentAsFTEndPointLikelihood:
setContentAsFTEndPointCandidate:
setContentAsFTRecognitionProgress:
setContentAsFTCheckForSpeechResponse:
setContentAsFTRecognitionCandidate:
setContentAsFTRequestStatsResponse:
setContentAsFTServerEndpointFeatures:
setContentAsFTClientSetupInfo:
setContentAsFTAudioLimitExceeded:
setContentAsFTMultiUserStartSpeechRequest:
setContentAsFTFinalBlazarResponse:
setContentAsFTStartMultilingualSpeechRequest:
setContentAsFTSpeechTranslationPartialRecognitionResponse:
setContentAsFTSpeechTranslationFinalRecognitionResponse:
setContentAsFTSpeechTranslationMtResponse:
setContentAsFTSpeechTranslationTextToSpeechResponse:
setContentAsFTSpeechTranslationServerEndpointFeatures:
setContentAsFTBatchTranslationLoggingRequest:
setContentAsFTTranslationSupportedLanguagesRequest:
setContentAsFTBatchTranslationResponse:
setContentAsFTTranslationSupportedLanguagesResponse:
setContentAsFTStartTextToSpeechStreamingRequest:
setContentAsFTBeginTextToSpeechStreamingResponse:
setContentAsFTPartialTextToSpeechStreamingResponse:
setContentAsFTFinalTextToSpeechStreamingResponse:
setContentAsFTStreamingTranslationRequest:
setContentAsFTTranslationResponse:
setContentAsFTQssAckResponse:
setContentAsFTStartLanguageDetectionRequest:
setContentAsFTLanguageDetectionResponse:
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithGRPCStreamingCallContext:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performServiceDiscovery:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
streamFailVerifyStreamingTranslationStreamingResponse:
streamDidReceiveStreamingTranslationStreamingResponse:
performTranslation:requestBuilder:completion:
performStreamingTranslationWithDelegate:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performTextToSpeechSpeechFeature:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
writeFrame:
finishWriting
sendPronGuessStreamingRequest:
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendStreamingTranslationStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16q24Q32@40
v40@0:8@16Q24@32
@32@0:8@16q24
v40@0:8@16@24q32
@24@0:8@16
v32@0:8@16@24
v48@0:8@"_LTActivityLogger"16q24Q32@"NSDate"40
v40@0:8@"_LTActivityLogger"16Q24@"NSDate"32
@"NSDate"32@0:8@"_LTActivityLogger"16q24
v40@0:8@"_LTActivityLogger"16@"NSDate"24q32
@"NSDate"24@0:8@"_LTActivityLogger"16
v32@0:8@"_LTActivityLogger"16@"NSDate"24
v24@0:8q16
v32@0:8q16@24
v40@0:8q16Q24@32
v32@0:8@16q24
@24@0:8q16
v24@0:8@16
v16@0:8
@"NSCalendar"
@"<_LTActivityLoggerDelegate>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v20@0:8B16
@"NSString"
{_NSRange="location"Q"length"Q}
v28@0:8@16B24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSLocale"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
@72@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56@64
q16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
@"NSArray"
v24@0:8@?16
v32@0:8q16@?24
v48@0:8@16Q24Q32@?40
v40@0:8@16@24@?32
v24@0:8@?<v@?B>16
v32@0:8q16@?<v@?@"NSArray">24
v48@0:8@"NSArray"16Q24Q32@?<v@?@"_LTTextLanguageDetectionResult">40
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
v32@0:8@16@?24
v36@0:8@16B24@?28
v40@0:8q16@24@?32
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v24@0:8@"NSData"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSURL"@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?q@"NSError">16
v24@0:8@"_LTInstallRequest"16
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
@36@0:8@16@24B32
v40@0:8@16Q24@?32
@"NSXPCConnection"
@"_LTTranslationServer"
@"NSUUID"
@"<_LTClientConnectionDelegate>"
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
v32@0:8@"NSArray"16@"NSError"24
v24@0:8@"_LTWordTimingInfo"16
v28@0:8B16@20
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@"<_LTSpeechTranslationDelegate>"
@"<_LTTranslationEngine>"
@"_LTSpeechTranslationResultsBuffer"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"NSMutableArray"
@40@0:8q16@24@32
@40@0:8@16{_NSRange=QQ}24
@"NSDictionary"
@32@0:8@16@24
v40@0:8@16@24^@32
@"NSURL"
d16@0:8
v24@0:8d16
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTTranslationContext"
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"NSNumber"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
@40@0:8@16@24@32
@"MAAsset"
@28@0:8@16B24
@36@0:8@16B24@?28
@36@0:8@16B24@28
@?16@0:8
@"<_LTTranslationService>"
@40@0:8@16B24@28B36
v36@0:8@16@24B32
v24@0:8Q16
v36@0:8@"NSString"16@"NSDictionary"24B32
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@"_LTLanguageDetectorFeatureCombinationModel"
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@"MLModel"
@"MAProgressNotification"
@"_LTOfflineAssetManager"
@"_LTLocalePair"
@24@0:8^{_NSZone=}16
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v24@0:8@"FTBatchTranslationStreamingResponse"16
@"FTBlazarService"
v44@0:8@16B24@?28@?36
v48@0:8@16B24B28@?32@?40
v28@0:8B16@?20
v48@0:8@16@24@32@?40
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
@24@0:8^@16
@"_LTHotfixManager"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v32@0:8@"VSSpeechSynthesizer"16@"VSPreviewRequest"24
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v56@0:8@16@24@32@?40@?48
v44@0:8@16@24B32@?36
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
@"NSError"
@"_LTTextToSpeechCache"
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
@"FTMutableBatchTranslationRequest"
@"_LTBatchEventLog"
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"NSDate"
@"AFSettingsConnection"
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@48@0:8@16@24@32@40
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
@"NSOrderedSet"
@32@0:8Q16q24
B24@0:8Q16
@"_LTInvocationEventContext"
@"_LTPlaybackService"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"_LTSpeechDataQueue"
@"_LTSpeechActivityDetector"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@"SNAudioStreamAnalyzer"
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@"_LTSpeechDataQueueNode"
@24@0:8d16
@36@0:8@16q24B32
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARSpeechRecognitionResultPackage"
@56@0:8@16@24d32d40d48
v36@0:8B16@20@?28
@"_LTTranslationResult"
@64@0:8@16q24@32@40@48@56
@"NSCountedSet"
@24@0:8Q16
@32@0:8@16Q24
@"NLLanguageRecognizer"
@40@0:8@16d24q32
Q32@0:8@16@24
@68@0:8@16@24d32B40@44@52@60
@"_LTTranslationStatistics"
@20@0:8B16
I16@0:8
v20@0:8I16
@"_LTTranslationSession"
@"_LTTextToSpeechTranslationRequest"
@"NSAttributedString"
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"_LTActivityLogger"
v28@0:8@?16B24
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
@"<_LTTextTranslationService>"
@"_LTRateLimiter"
@52@0:8@16{_NSRange=QQ}24B40@44
q28@0:8@16B24
@32@0:8@16d24
v36@0:8q16B24@?28
v44@0:8@16Q24B32@?36
v52@0:8@16Q24Q32B40@?44
v40@0:8@16@?24@?32
q24@0:8@16
@"NSData"16@0:8
@32@0:8@16r^{ErrorMessage=[1C]}24
@36@0:8@16r^{ErrorMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ErrorMessage>=I}24@0:8^v16
r^{ErrorMessage=[1C]}
@32@0:8@16r^{DisableSessionLog=[1C]}24
@36@0:8@16r^{DisableSessionLog=[1C]}24B32
{Offset<siri::speech::qss_fb::DisableSessionLog>=I}24@0:8^v16
r^{DisableSessionLog=[1C]}
#24@0:8q16
@32@0:8@16r^{ApgPronGuessMessage=[1C]}24
@36@0:8@16r^{ApgPronGuessMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ApgPronGuessMessage>=I}24@0:8^v16
r^{ApgPronGuessMessage=[1C]}
@32@0:8@16r^{ApgBatchRecoverMessage=[1C]}24
@36@0:8@16r^{ApgBatchRecoverMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ApgBatchRecoverMessage>=I}24@0:8^v16
r^{ApgBatchRecoverMessage=[1C]}
@32@0:8@16r^{AsrRecognitionMessage=[1C]}24
@36@0:8@16r^{AsrRecognitionMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrRecognitionMessage>=I}24@0:8^v16
r^{AsrRecognitionMessage=[1C]}
@32@0:8@16r^{AsrErrorBlamerMessage=[1C]}24
@36@0:8@16r^{AsrErrorBlamerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrErrorBlamerMessage>=I}24@0:8^v16
r^{AsrErrorBlamerMessage=[1C]}
@32@0:8@16r^{AsrItnMessage=[1C]}24
@36@0:8@16r^{AsrItnMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrItnMessage>=I}24@0:8^v16
r^{AsrItnMessage=[1C]}
@32@0:8@16r^{AsrTextNormalizationMessage=[1C]}24
@36@0:8@16r^{AsrTextNormalizationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrTextNormalizationMessage>=I}24@0:8^v16
r^{AsrTextNormalizationMessage=[1C]}
@32@0:8@16r^{AsrPostItnHammerMessage=[1C]}24
@36@0:8@16r^{AsrPostItnHammerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrPostItnHammerMessage>=I}24@0:8^v16
r^{AsrPostItnHammerMessage=[1C]}
@32@0:8@16r^{AsrKeywordFinderMessage=[1C]}24
@36@0:8@16r^{AsrKeywordFinderMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrKeywordFinderMessage>=I}24@0:8^v16
r^{AsrKeywordFinderMessage=[1C]}
@32@0:8@16r^{AsrCorrectionsValidatorMessage=[1C]}24
@36@0:8@16r^{AsrCorrectionsValidatorMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrCorrectionsValidatorMessage>=I}24@0:8^v16
r^{AsrCorrectionsValidatorMessage=[1C]}
@32@0:8@16r^{AsrGraphemeToPhonemeMessage=[1C]}24
@36@0:8@16r^{AsrGraphemeToPhonemeMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrGraphemeToPhonemeMessage>=I}24@0:8^v16
r^{AsrGraphemeToPhonemeMessage=[1C]}
@32@0:8@16r^{BlazarMultiUserMessage=[1C]}24
@36@0:8@16r^{BlazarMultiUserMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarMultiUserMessage>=I}24@0:8^v16
r^{BlazarMultiUserMessage=[1C]}
@32@0:8@16r^{BlazarMultilingualMessage=[1C]}24
@36@0:8@16r^{BlazarMultilingualMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarMultilingualMessage>=I}24@0:8^v16
r^{BlazarMultilingualMessage=[1C]}
@32@0:8@16r^{BlazarSpeechTranslationMessage=[1C]}24
@36@0:8@16r^{BlazarSpeechTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarSpeechTranslationMessage>=I}24@0:8^v16
r^{BlazarSpeechTranslationMessage=[1C]}
@32@0:8@16r^{BlazarBatchTranslationMessage=[1C]}24
@36@0:8@16r^{BlazarBatchTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarBatchTranslationMessage>=I}24@0:8^v16
r^{BlazarBatchTranslationMessage=[1C]}
@32@0:8@16r^{BlazarTextToSpeechRouterMessage=[1C]}24
@36@0:8@16r^{BlazarTextToSpeechRouterMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarTextToSpeechRouterMessage>=I}24@0:8^v16
r^{BlazarTextToSpeechRouterMessage=[1C]}
@32@0:8@16r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}24
@36@0:8@16r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarTextToSpeechRouterStreamingMessage>=I}24@0:8^v16
r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}
@32@0:8@16r^{BlazarServiceDiscoveryMessage=[1C]}24
@36@0:8@16r^{BlazarServiceDiscoveryMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarServiceDiscoveryMessage>=I}24@0:8^v16
r^{BlazarServiceDiscoveryMessage=[1C]}
@32@0:8@16r^{LmtLmScorerMessage=[1C]}24
@36@0:8@16r^{LmtLmScorerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::LmtLmScorerMessage>=I}24@0:8^v16
r^{LmtLmScorerMessage=[1C]}
@32@0:8@16r^{NapgCreateLanguageProfileMessage=[1C]}24
@36@0:8@16r^{NapgCreateLanguageProfileMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::NapgCreateLanguageProfileMessage>=I}24@0:8^v16
r^{NapgCreateLanguageProfileMessage=[1C]}
@32@0:8@16r^{MtTranslationMessage=[1C]}24
@36@0:8@16r^{MtTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::MtTranslationMessage>=I}24@0:8^v16
r^{MtTranslationMessage=[1C]}
@32@0:8@16r^{MtStreamingTranslationMessage=[1C]}24
@36@0:8@16r^{MtStreamingTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::MtStreamingTranslationMessage>=I}24@0:8^v16
r^{MtStreamingTranslationMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechMessage>=I}24@0:8^v16
r^{TtsTextToSpeechMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechStreamingMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechStreamingMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechStreamingMessage>=I}24@0:8^v16
r^{TtsTextToSpeechStreamingMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechSpeechFeatureMessage>=I}24@0:8^v16
r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}
@32@0:8@16r^{NlShortcutFuzzyMatchMessage=[1C]}24
@36@0:8@16r^{NlShortcutFuzzyMatchMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::NlShortcutFuzzyMatchMessage>=I}24@0:8^v16
r^{NlShortcutFuzzyMatchMessage=[1C]}
@32@0:8@16r^{SlsLanguageDetectionMessage=[1C]}24
@36@0:8@16r^{SlsLanguageDetectionMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::SlsLanguageDetectionMessage>=I}24@0:8^v16
r^{SlsLanguageDetectionMessage=[1C]}
@32@0:8@16r^{QssMessage=[1C]}24
@36@0:8@16r^{QssMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::QssMessage>=I}24@0:8^v16
r^{QssMessage=[1C]}
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^v16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^v16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
i16@0:8
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^v16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^v16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^v16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^v16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^v16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^v16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^v16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^v16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^v16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^v16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^v16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^v16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^v16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^v16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
f16@0:8
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^v16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^v16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^v16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^v16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^v16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^v16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^v16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^v16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^v16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^v16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^v16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^v16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^v16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^v16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^v16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^v16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^v16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^v16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^v16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^v16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^v16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^v16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^v16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^v16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^v16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^v16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^v16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^v16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^v16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^v16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^v16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^v16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^v16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^v16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^v16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^v16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^v16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^v16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^v16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^v16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^v16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^v16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^v16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^v16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^v16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^v16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^v16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^v16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^v16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^v16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^v16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^v16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^v16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^v16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{StreamingTranslationRequest=[1C]}24
@36@0:8@16r^{StreamingTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StreamingTranslationRequest>=I}24@0:8^v16
r^{StreamingTranslationRequest=[1C]}
@32@0:8@16r^{TranslationPhraseMetaInfo=[1C]}24
@36@0:8@16r^{TranslationPhraseMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationPhraseMetaInfo>=I}24@0:8^v16
r^{TranslationPhraseMetaInfo=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^v16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^v16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^v16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^v16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^v16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^v16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^v16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^v16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^v16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^v16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^v16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^v16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^v16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^v16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^v16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^v16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^v16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^v16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^v16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^v16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^v16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^v16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^v16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^v16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechResponseDevData=[1C]}24
@36@0:8@16r^{TextToSpeechResponseDevData=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponseDevData>=I}24@0:8^v16
r^{TextToSpeechResponseDevData=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^v16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^v16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^v16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainerRpcV2=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainerRpcV2=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainerRpcV2>=I}24@0:8^v16
r^{TextToSpeechCacheContainerRpcV2=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainerStreamingV2=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainerStreamingV2=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainerStreamingV2>=I}24@0:8^v16
r^{TextToSpeechCacheContainerStreamingV2=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^v16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureModelIdentifier>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWord=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWord=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWord>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWord=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputText=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputText=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputText>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputText=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureOutputFeature>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputPhoneme>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputPhonemeSequence>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureRequest=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureRequest>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureRequest=[1C]}
@32@0:8@16r^{LexiconEntry=[1C]}24
@36@0:8@16r^{LexiconEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureRequest_::LexiconEntry>=I}24@0:8^v16
r^{LexiconEntry=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureResponse=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureResponse>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^v16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^v16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{ServiceDiscoveryRequest=[1C]}24
@36@0:8@16r^{ServiceDiscoveryRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ServiceDiscoveryRequest>=I}24@0:8^v16
r^{ServiceDiscoveryRequest=[1C]}
@32@0:8@16r^{ServiceDiscoveryResponse=[1C]}24
@36@0:8@16r^{ServiceDiscoveryResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ServiceDiscoveryResponse>=I}24@0:8^v16
r^{ServiceDiscoveryResponse=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^v16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^v16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^v16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^v16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^v16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^v16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^v16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^v16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^v16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^v16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^v16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^v16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^v16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^v16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^v16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^v16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^v16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^v16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^v16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24
@36@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationFeedbackRequest>=I}24@0:8^v16
r^{BatchTranslationFeedbackRequest=[1C]}
@32@0:8@16r^{BatchTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationLoggingRequest>=I}24@0:8^v16
r^{BatchTranslationLoggingRequest=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^v16
r^{BatchTranslationResponse=[1C]}
{Offset<siri::speech::schema_fb::BatchTranslationResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{TranslatedSentence=[1C]}24
@36@0:8@16r^{TranslatedSentence=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse_::TranslatedSentence>=I}24@0:8^v16
r^{TranslatedSentence=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^v16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{TranslationSupportedLanguagesRequest=[1C]}24
@36@0:8@16r^{TranslationSupportedLanguagesRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesRequest>=I}24@0:8^v16
r^{TranslationSupportedLanguagesRequest=[1C]}
@32@0:8@16r^{TranslationSupportedLanguagesResponse=[1C]}24
@36@0:8@16r^{TranslationSupportedLanguagesResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesResponse>=I}24@0:8^v16
r^{TranslationSupportedLanguagesResponse=[1C]}
@32@0:8@16r^{LanguagePair=[1C]}24
@36@0:8@16r^{LanguagePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesResponse_::LanguagePair>=I}24@0:8^v16
r^{LanguagePair=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^v16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^v16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{QSSVersionInfo=[1C]}24
@36@0:8@16r^{QSSVersionInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::QSSVersionInfo>=I}24@0:8^v16
r^{QSSVersionInfo=[1C]}
v20@0:8i16
v20@0:8f16
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^v16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^v16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^v16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^v16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^v16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^v16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^v16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^v16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^v16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^v16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^v16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^v16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^v16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^v16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{StreamingTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{StreamingTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::StreamingTranslationStreamingRequest>=I}24@0:8^v16
r^{StreamingTranslationStreamingRequest=[1C]}
@32@0:8@16r^{StreamingTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{StreamingTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::StreamingTranslationStreamingResponse>=I}24@0:8^v16
r^{StreamingTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^v16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^v16
r^{LanguageDetectionStreamingResponse=[1C]}
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
@(#)PROGRAM:Translation  PROJECT:Translation-216.8
#+;;;;;3
@mcpl
@supo
mcpl
@mcpl
"&*.26:>BFJNRVZ
"&*.26:>BFJ
"&*.26
"&*.26:>BFJN
"&*.26:>BFJNRVZ^bf
$*06<BHNTZ`flrx~
$*06<BHNTZ`fn
$*06<BHP
$*06<DJPV\bhnt
 $(,048<@DHLPTX\`d
 $(,
 $(,
$*06<B
 &,28>D
com.apple.translation.DailyActive
com.apple.translation.WeeklyActive
com.apple.translation.MonthlyActive
LastActivityDate
feature
%0*ld_%ld
week_name
month_name
system
siri
app_review
aggregate
%@_%@
daily
weekly
monthly
identifier
<no value>
text
targetRange
start
length
sourceRange
shouldTranslate
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
Error
com.apple.translation
selector
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
@"NSDictionary"8@?0
com.apple.translation.analytics-event
v8@?0
errorDomain
errorCode
errorDescription
duration
sourceLocale
targetLocale
%@.%@
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
application-identifier
sentence
singleParagraph
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
v16@?0@"NSError"8
paragraphs
com.apple.TranslationUIServices.TranslationUIService
text-to-speech
speech
preheat
text-LID
processName
unknown
type
v24@?0@"_LTAudioData"8@"NSError"16
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v24@?0@"_LTTranslationResult"8@"NSError"16
com.apple.private.translation
com.apple.Translation
Daemon
com.apple.translation.daemon.listener
DisambiguationEnabled
DataCollectionEnabled
TextLIDUseLSTM
com.apple.translationd
com.apple.translation.text
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
UNKNOWN_ERROR_DESCRIPTION
REMOTE_SERVICE_FAILURE_DESCRIPTION
ONLINE_TRANSLATION_NOT_IMPLEMENTED_ERROR_DESCRIPTION
INVALID_ONLINE_OFFLINE_REQUEST_ERROR_DESCRIPTION
LID_MODEL_LOAD_ERROR_DESCRIPTION
ONGOING_SPEECH_TRANSLATION_ERROR_DESCRIPTION
SPEECH_DURATION_EXCEEDED_ERROR_DESCRIPTION
SERVER_TIMEOUT_ERROR_DESCRIPTION
OFFLINE_TTS_FAILURE_ERROR_DESCRIPTION
UNSUPPORTED_LOCALE_PAIR_ERROR_DESCRIPTION_FORMATTED_STRING
%@ %@ %@
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
com.apple.translation.HotfixError
file
HotfixManager
Translation
Hotfix
com.apple.Translator.HotfixManager
Mapping
FormatVersion
Cannot find any compatible hotfix
v24@?0@"NSDictionary"8@"NSError"16
com.apple.Translate
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
mapping-info-plist
v24@?0@"NSData"8@"NSError"16
HotfixAssetVersion
%@-%@
mt-quasar-config.json
HotfixAssetName
Failed to specify compression algorithm
Failed to specify format
Failed to open archive for reading
Unable to extract file
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
Languages
Footprint
Premium
hybridendpointer.json
InstallRequest
com.apple.siri.translation.speechrequest
locales
useCellular
zh-Hant
zh_TW
zh-Hans
zh_CN
en_US
dominantLanguage
confidences
isConfident
isFinal
com.apple.translation.lid.result
com.apple.translation.lid.finalResult
final
intermediate
, partial ASR confidences
, final ASR results
CSLanguageDetector
Unable to find class %s
CSLanguageDetectorOption
features
compiledModelFile
modelInput
modelInputIsMatrix
modelOutput
missingFeatureValueDefault
missingLanguageDetectionDefault
LanguageLocaleToIdentifier
min_source
max_source
avg_source
min_target
max_target
avg_target
most_recent_partial_source
max_partial_source
avg_partial_source
most_recent_partial_target
max_partial_target
avg_partial_target
acoustic_lid
acoustic_lid_count
acoustic_lid0
acoustic_lid1
acoustic_lid2
identifier_source
identifier_target
identifier_asr
v32@?0@"NSString"8Q16^B24
@max.doubleValue
@avg.doubleValue
v32@?0@"NSNumber"8Q16^B24
1.0-
%lld
progress
offlineState
localeIdentifier
totalExpected
totalWritten
isStalled
expectedTimeRemaining
Missing
Installed
Downloading
NeedsDownload
ErrorInstalling
%@ %@ %@ %@
LanguageManager
com.apple.siri.translation.LanguageManager
mt_app.offline
LanguagePairs
ASR-%@
TTS-%@
asset_list
AssetName
v16@?0@"MAProgressNotification"8
asr_languages
_all
TTS-
Translation voice not found for %@:%@
Translation voice downloaded for %@:%@
Downloading Translation voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
ASR-
v16@?0q8
Not Present
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
<%@: source:%@ target:%@>
Translator
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
conversationID
requestID
localePair
selectedLocale
lidResult
senses
userInteractedSenses
firstResponse
firstParagraphComplete
progressComplete
pageComplete
timeToFirstResponse
timeToFirstParagraphComplete
timeToProgressComplete
timeToPageComplete
v16@?0@"OspreyMutableRequest"8
com.apple.translation.ParagraphTranslationDone
hw.machine
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechTranslationAssets2
com.apple.MobileAsset.SpeechTranslationAssets3
com.apple.MobileAsset.SpeechTranslationAssets4
com.apple.MobileAsset.SpeechEndpointAssets
AssetsV3
Assets
AssetsV2
AssetManager
com.apple.Translator.EMTAssetManager
v12@?0B8
plist
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
MADownLoadResult
MOBILE_ASSET_DOWNLOAD_FAILURE_ERROR_DESCRIPTION
v16@?0@"NSArray"8
assets.json
Type
AssetVersion
RequiredCapabilityIdentifier
CONFIGURATION_ASSET_MISSING_ERROR_DESCRIPTION
CONFIGURATION_ASSET_MISSING_ERROR_DESCRIPTION_REASON
Missing asset entitlement
LanguageDetectorDefaultAsset
featureCombinationLID.plist
_UnarchivedSize
TranslationAssetQueryDomain
OfflineSpeechSynthesizer
com.apple.assistant.backedup
Output Voice
Gender
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
GENERIC_FAILURE_ERROR_DESCRIPTION
INPUT_EMPTY_ERROR_DESCRIPTION
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
asrBestConfidence
asrBestText
request_id
hasFinalServerResponse
completionHandlerCalled
MISSING_BATCH_RESPONSE_ERROR_DESCRIPTION
com.apple.siri
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.mobilesafari
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
x-sequoia-client
sentenceCount
v32@?0@"_LTTranslationParagraph"8Q16^B24
com.apple.translation.OnlineSpeechTranslation
sentAudio
sentEndAudio
endpointedSpeech
didReceiveAudioLimitExceededResponse
didReceivePartialRecognitionResponse
didReceiveFinalRecognitionResponse
didReceiveTranslationResponse
didReceiveTTSResponse
didReceiveFinalBlazarResponse
didTimeout
<%@: sentAudio:%@ sentEndAudio:%@ endpointedSpeech:%@ didReceiveAudioLimitExceededResponse:%@ didReceivePartialRecognitionResponse:%@ didReceiveFinalRecognitionResponse:%@ didReceiveTranslationResponse:%@  didReceiveTTSResponse:%@ didReceiveFinalBlazarResponse:%@ didTimeout:%@ error %@>
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
paragraph
INVALID_REQUEST_NO_RANGES_OR_TEXT_ERROR_DESCRIPTION
v32@?0@"_LTTranslationRange"8Q16^B24
Error AudioQueueStart
com.apple.translation.powerlog
default
InstalledLocales
LastOfflineAssetCatalogUpdate
LastCDNUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
RequestID
HotfixEndpointURL
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
FinalAcousticLanguageDetectionResultsWaitTimeInMs
FinalThresholdsAcousticLanguageDetectionResultsWaitTimeInMs
MinimumAcousticLanguageDetectionResults
MaximumAcousticLanguageDetectionResults
VADAudioCacheMaxDuration
LanguageDetectorFeatureCombinationModelSupported
LanguageDetectorFeatureCombinationModelVersionID
LanguageDetectorFeatureCombinationModelThreshold
LanguageDetectorFeatureCombinationModelConfidenceThreshold
ASRDataPackToLIDThresholdVersion
ASRDataPackToASRTypeIdentifier
TextLIDScorerConfidenceThreshold
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
CharacterBasedLocales
TranslationEngineCacheSize
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
RateLimitingMaximumPageLoadRequests
RateLimitingMaximumDynamicContentRequests
Configuration
v220621
-finalASR
mt_app.online
web.online
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
https://sequoia.apple.com
https://seed-sequoia.siri.apple.com
https://carry-sequoia.siri.apple.com
https://sequoia.cdn-apple.com/sequoia-prod
https://sequoia-test.cdn-apple.com/sequoia-livability/carry
EDC04020
com.apple.translationd.playback
com.apple.translation.session
v16@?0@"NSData"8
v24@?0@"NSURL"8@"NSError"16
com.apple.translation.AnalysisQueue
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
stable
locale
transcriptions
sausage
Sausage
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
confidence
(%@)
bins
alternatives
bestIndex
lowConfidence
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
SpeechRecognizer
com.apple.translation.speech
mini.json
dispatch.voc
lexicon.enh
itn_s.enh
MtApp
EMPTY_RECOGNITION_ERROR_DESCRIPTION
SPEECH_NOT_RECOGNIZED_ERROR_DESCRIPTION
sanitizedFormattedString
formattedString
minConfidence
maxConfidence
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
v32@?0@"NSLocale"8@"_LTSpeechRecognitionResult"16^B24
sessionID
taskHint
deviceOS
deviceType
appIdentifier
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
com.apple.translation.TextLID
language
isSupported
Detection result locale count: %ld, unsupported count: %ld, dominant: %@
weighted
TextLIDAggregateEvaluation
[ %@ ]
com.apple.translation.tts-cache
MISS
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
com.apple.Translate.globalprefschanged
com.apple.onboarding.translate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
tokens
genders
statistics
romanization
status
phrasebook_exact
gender_alternatives
com.apple.
translate
<redacted>
 (%@)
; %@
 | OCR
uniqueID
autodetectLanguage
autoEndpoint
censorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
ttsPlaybackRate
enableVAD
sourceOrigin
untrustedClientIdentifier
logIdentifier
sourceContentAsJSON
targetContentAsJSON
errorsAsJSON
safariVersion
webpageURL
group
defaultGender
spans
projection
default_gender
@"_LTTranslationGenderAlternative"16@?0@"NSObject"8
v32@?0@"_LTTranslationSpan"8Q16^B24
-[_LTTranslationParagraph splitIntoSentences]_block_invoke_3
LTTranslationParagraph.m
previousSpan.range.location + previousSpan.range.length == textRange.location
v32@?0@"NSString"8@"_LTTranslationSpan"16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
undefined
%@/%@
batch
TranslationRequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
textToSpeech
CFBundleIdentifier
CMBlockBufferCopyDataBytes could not copy data: %d
Translate
genderDisambiguation
sentencepiece encoder input
es_ES
The nurse went to the bank
El enfermero fue al banco
La enfermera fue al banco
El enfermero fue a la banca
La enfermera fue a la banca
El enfermero fue a la orilla
La enfermera fue a la orilla
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
@16@?0@"FTBatchTranslationResponse_TranslatedSentence"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
NO_IDENTIFIER
translations
sourceString
sanitizedSourceString
alignments
sourceMatch
targetMatch
pbMatch
sense ID
definition
source match
target match
input
output
labels
gender
formality
@"_LTTranslationSense"16@?0@"NSObject"8
group.com.apple.private.translation
com.apple.translationd.server
OFFLINE_MODELS_UNAVAILABLE_ERROR_DESCRIPTION
FirstUseConsent
v24@?0q8@"NSError"16
v16@?0@"NSDictionary"8
v24@?0@"<_LTTextTranslationService>"8@?<v@?>16
RATE_LIMIT_EXCEEDED_ERROR_DESCRIPTION
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
range
metaInfoData
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
firstleg sentencepiece decoder output
sentencepiece decoder output
mt_app
camera
image
v24@?0@"<_LTTranslationService>"8@?<v@?>16
v16@?0@"<_LTTranslationService>"8
v16@?0@"_LTLanguageDetectionResult"8
whitelist
entitlement
v16@?0@"_LTTextLanguageDetectionResult"8
CLIENT_REQUIRES_TEXT_SERVICE_ERROR_DESCRIPTION
InternalBuild
ar_SA
male
female
id_ID
pl_PL
vi_VN
th_TH
@16@?0@"FTWordTimingInfo"8
word
sampleIndex
offset
timestamp
Language
Config
MT-bi-
v24@?0^v8Q16
session_message
error_message
disable_session_log
container_message
error_code
reason
session_message_type
container_message_type
v20@?0r*8I16
tok_phrases
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
bool_stats
int32_stats
double_stats
acoustic_feature_per_frame
speech_recognition_features
acoustic_features
value
recognition_result
audio_analytics
latnn_mitigator_result
start_speech_request
user_parameters
pron_hints
contextual_text
context_with_pron_hints
user_language_profile
user_acoustic_profile
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
attributes
category_data
user_data
voc_token
tts_pronunciations
human_readable_prons
apg_ids
recovery_return_codes
voc_tokens
words_list
formatted_words_list
normalized_tokens
nbest_variants
sanitized_sequences
prons
normalized_prons
sanitized_tokens
phonemes
aot_token_prons
jit_token_prons
index
span
raw_sausage
raw_nbest_choices
post_itn_tokens
itn_alignments
translation_phrase
pre_sausage_payload
siri_translation_info
speech_translation_info
siri_payload_translation_info
web_translation_info
n_best_translated_phrases
engine_output
mt_alignment
translated_tokens
meta_info_data
audio_packets
keywords
corrected_sausage
n_best_list
pause_counts
corrections
voice
resource
server_info
context_info
word_phonemes
prompts
normalized_text
phoneme_sequence
replacement
neural_phoneme_sequence
resources
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
wave_data
user_voice_profile
decoder_description
playback_description
word_timing_info
dev_data
cache_meta_info
cache_object
cached_request
cached_response
cached_begin_response
cached_partial_response
cached_final_response
words
phonemeseq
model_id
lexicon
zk_node
audio_frames
translation_locale_pairs
translation_request
text_to_speech_requests
translation_locale_pair
detected_locale
user_interacted_senses
text_to_speech_response
server_endpoint_features
utterance
shortcuts
shortcut_score_pairs
language_parameters_by_id
predictions
translated_sentences
repeated_spans
source_span
target_span
n_best_choices
language_pairs
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
profile_blob
profile_blob_version
profile_checksum
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
add_space_after
phone_seq
ipa_phone_seq
has_unsuggested_alternatives
speech_id
request_locale
name
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
frame_duration
session_id
return_code
return_str
lang_profile_recreate_codes
watermark_detection
watermark_peak_average
has_result
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
primary_speech_id
product_id
vendor_id
left_context
right_context
audio_bytes
packet_count
total_audio_recorded_seconds
orthography
pronunciations
frequency
category_name
error_str
incomplete_profile
recreate_apg_prons
blob
apg_id
num_of_requested
num_of_processed
num_of_succeeded
post_itn_string
nbest_variants_max
original_token
pron_sequence
log_weight
token
pron_source
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
start_index
end_index
do_not_translate
post_itn_recognition
pre_itn_payload
post_itn_payload
task
source_language
target_language
sequence_id
disable_log
opt_in_status
app_id
use_case
translation_text
final_message
return_string
engine_input
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
calibration_scale
calibration_offset
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
keyword_orthography
posterior
enable_sanitization
num_of_words
trailing_silence_duration
eos_likelihood
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
fe_feature
fe_feature_only
disable_prompts
cache_only
phoneset_type
quality
channel_type
is_synthesis
dialog_identifier
experiment_identifier
prompts_v2
original
force_use_tts_service
disable_cache
data
return_log
voice_asset_path
resource_asset_path
return_server_info
has_click
worker_process_type
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
user_voice_profile_url
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
sample_idx
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
pcm_data
phone_name
begin_time
end_time
pitch
energy
support_homograph
endpoint_threshold
endpoint_extra_delay
zk_path
source_locale
target_locale
conversation_id
restricted_mode
streaming_mode
user_selected_locale
user_selected_sense
is_final
interaction_id
raw_string
shortcut
similarity_score
is_low_confidence
paragraph_id
source_content
translated_content
errors
safari_version
os_version
time_to_first_response
time_to_viewport_complete
time_to_page_complete
translated_text
sentence_count
qss_version_server
qss_version_brane
qss_version_serverkit
qss_version_siritts
content
content_type
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Blazar/ServiceDiscovery
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Mt/StreamingTranslation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Tts/TextToSpeechSpeechFeature
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Sls/LanguageDetection
Client attempted to register unspecified event; clients should always specify which event is being logged
Log %{public}@ activity for %{public}@
Updating last logged date for %{public}@ to: %{public}@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Trusted client connection
Untrusted client connection
XPC connection was interrupted, likely because the process was killed
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
XPC languages for text call
Failed to deserialize logging request: %@
XPC on-device mode call
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Failed to set user dir suffix: %{public}s
Memory pressure warning level %lu.
Failed to get cache directory: %{public}s
Rejected Translation client with PID %d lacking the appropriate entitlement (%@).
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
rm -rf %@
Could not delete: %@
Downloading: %@
Failed to download %@ with error: %@
Select hotfix: %@
Found existing hotfix
Remove folder failed: %@
Create folder failed: %@
Decompression failed: %@
Failed to specify compression algorithm: %s
Failed to specify format: %s
Start extracting archive
Failed to open archive for reading: %s
Entry extraction path: %@
Unable to extract file: %s
Finished extracting archive to: %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Updating source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Updating target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Start installation request with service
Failed to obtain LID asset
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
Sending out new %@ LID result, detected %@
Computing new LID result, with %ld acoustic results%@%@
Already sent final LID result, ignoring additional speech result
Change in model-version triggers deletion of cached %@ partial-confidences
Calling endAudio from addSpeechRecognitionResult
Initiate use of final thresholds to reduce dialog rates, as timer ended after 1st final ASR
Try to force final LID, as timer ended after 1st final ASR
Added %@ partial-confidence: %f; new array length: %ld
Already sent final LID result, ignoring additional audio data
NumSamples: %ld
LID Audio Data
Trying to send final LID result from endAudio
Forcing current language detection result to be final
Forcing language detection result to be %@
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
Acoustic LID detected %@ (confident: %@): %@
Trying to send final LID result from acousticLID CoreSpeech delegate
Setting default value for input is matrix to NO
Missing necessary configuration values
Setting default value for missing feature value to %f
Setting default value for missing language detector result to %f
Unknown feature in model file: %@
Unable to load CoreML model from: %@
CoreML model loaded: %@
Min confidence source: %f
Max confidence source: %f
Average confidence source: %f
Min confidence target: %f
Max confidence target: %f
Average confidence target: %f
Acoustic LID: %f
Acoustic LID count: %ld
Acoustic LID0: %f
Acoustic LID1: %f
Acoustic LID2: %f
Most recent partial confidence source: %f
Max partial confidence source: %f
Average partial confidence source: %f
Most recent partial confidence target: %f
Max partial confidence target: %f
Average partial confidence target: %f
Language %@ locale identifier source: %f
ASR-type identifier for model version=%@ -> feature: %f
Discarded CoreML features, as all values were defaults
Created CoreML features: %@
Unable to compile CoreML input features
Unable to construct CoreML feature provider
Unable to perform inference on CoreML model
Was unable to extract CoreML prediction
Was unable to extract posterior values from prediction results
Queried LID threshold version "%@" useFinalThresholds: %@ isFinalASR: %@, detected %@, with score %f using discriminator threshold %@%f and confidence offset %f (confident: %@)
missing mt_app.offline.plist
asset names for %@: %@
downloadAsset %@ totalExpected %@
progressCallback update assetIdentifier %@ %@
Finished downloading all assets
Required Assets: %@
setAutoDownloadedVoiceAssets %@
Unreferenced assets: %@
purged %@ result %ld
Nothing to install.
Installing:
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start speech senses logging request
Speech senses logging request finished with error: %@
Speech senses logging request finished
Start Safari latency logging request
Start Safari feedback request
Safari feedback request finished with error: %@
Safari feedback request finished
Received speech logging request response: [%d] %@
Speech logging request received unexpected response: %@
Speech logging request received error: %@
Received safari feedback request response: [%d] %@
Safari feedback request received unexpected response: %@
Safari feedback request received error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Received new language detection result
Trying to cancel recognition for %@
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
MADownloadNotEntitled
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
error querying obsolete catalog assets
Deleting Obsolete Assets %@
error querying catalog assets
error querying installed assets
Config asset not installed!
Reading configuration plist %@
Failed to read plist %@
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Start downloading asset %@ userInitiated: %@, useCellular: %@
Asset progress: %@
update: %@ %@
Asset download finished %@
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
Failed to remove old asset directory %@
Failed to create asset directory %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
update asset %@ %@ %@ %@
error downloading asset %@
error deleting asset %@
----------------------------- determine installed pairs ------------------------------------ 
----------------------------- check config asset for update ------------------------------------ 
----------------------------- Determine pairs to update ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
error downloading assets %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Starting download for asset with attributes: %@
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Failed to fetch asset metadata. Result: %ld
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Failed to create recognizer: %@
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Failed to create translator: %@
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Already got final LID result, forwarding...
Waiting for LID result
Received final LID result, continue with wait block
Starting translation
Initialize translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
Starting partial translation
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
streamDidReceiveBatchTranslationStreamingResponse request_id %{public}@
found BatchTranslationResponse request_id %{public}@
FIXME: NULL FTBatchTranslationResponse!
Succeeded request %{public}@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %{public}@
NULL FTFinalBlazarResponse!
GRPC error %d: %@
Translation error on %{public}@: %@
found FTFinalBlazarResponse request_id %{public}@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FBFLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
startServerTimeoutTimer 
updateServerTimeout %.2fs 
cancelServerTimeout: %@
batch timeout triggered
 serverTimeoutFired Sending batch request after %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ after %.2fs
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %{public}@, task: %{public}@, sessionID: %{public}@, URL: %@
Batch request created (sessionID: %{public}@)
Batch SELF log created
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Starting speech translation with request ID: %{public}@ session ID: %{public}@, opt in status: %ld
Streaming connection finished with error: %@
Initializing LTOspreySpeechTranslationSession with no text to translate.  This may not be what you want.
Starting text to speech translation with request ID: %{public}@, session ID: %{public}@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
sendAudioData: Final ASR response received, not sending audio.
sendAudioData: Already sent end audio, not sending audio.
sendAudioData: Already endpointed, do not need to send additional audio.
sendAudioData: Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring non-final LID result
LID result received. Primary language recognized: %@
Sending MT responses if needed
Detected translation locale: %{public}@
Result locale: %{public}@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Create SELF Batch request log with request sessionID: %{public}@, appID: %{public}@, mtID: %{public}@
Start SELF Batch request log with %lu paragraphs
End SELF Batch request log
End SELF Batch request log with error %{public}@
Cancel SELF Batch request log with reason %{public}@
SELF Batch request log sent %@
SELF One or more locales did not have a SISchemaLocale %{public}@, %{public}@
SELF Invocation event initialized
SELF Invocation start sent %@
SELF Invocation end sent %@
SELF Invocation log: Empty language pair
SELF Invocation event log start context %@
Log ended successfully but with unknown QSS Session ID
SELF Invocation event log end context %@
Log cancelled (reason: %{public}@) with unknown QSS Session ID
SELF Invocation event log cancel context %@
Log failed with unknown QSS Session ID; error: %@
SELF Invocation event log error context %@
SELF ASR event initialized %{public}@
SELF ASR event log sent %@
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
Sending end of audio
Asked to cancel speech session
SNAudioStreamAnalyzer failure: %@
Sausage conf %ld for locale %@
Sausage confidences: %@
Initializing recognition with config based formatter
Initializing recognition with old ncs formatter, as new config based formatter was not found
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Detection result via detected locales: %@
Detection result via detection counts: %@
Detection result via weighted locale: %@
Using LSTM text lid engine
Using CFRO text lid engine
Detection for string value
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Detection for %ld string array using strategy: %@
Text lid evaluation strategy: aggregate
Text lid evaluation strategy: count-based
nil locale encountered in scorable item init; will ignore this item
new scoring item locale:%{public}@ confidence:%f words:%ld
supported locales for scoring: %{public}@
no scorable dominant language for text length: %ld
weightedLocale for %lu items
weightedLocale confidence threshold from preferences: %f
weightedLocale item confidence %f < confidence threshold %f, skipping
weightedLocale is %{public}@ with score %f on %lu words from %lu locales
TTS cache request: %@
Purging %ld items from TTS cache
Setting romanization from meta_info_data: %@
Phrase has no meta_info_data romanization
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Setting romanization from meta JSON string: %@
Using trusted client identifier: %{private}@
Failed to get trusted client identifier, falling back to untrusted value: %{private}@
Trying to set new text on a request that already had text (and a session) set; this could lead to unexpected behavior
Created _LTTranslationSession for use in a _LTTextTranslationRequest. SessionID: %{public}@
_LTTranslationRequest had text set, creating sub-request with suggested uniqueID: %{public}@
Text Translation: start with service
Using paragraph translation
Received parapraph translation result
Fallback to text to speech translation
Translation failed with error: %@
Skipping alignment information in translation when 1:1 with translation
Alignment '%@' ID: %@
No alignment information in translation
Received translated paragraph for ID: %@
New outstanding count: %ld
Received text to speech result
Using `-[_LTTranslator translate:]` is not supported on batch translation. Please take a look at `_LTTranslationSession`.
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TextToSpeechTranslation did receive translation result
Got (untrusted) client identifier from Info.plist: %{private}@
Unable to read (untrusted) client identifier from Info.plist; falling back to process name: %{private}@
No asset info found for pair %@
Reusing cached offline engine for locales: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %{public}@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %{public}@, current ongoing is: %{public}@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
XPC languages for text result: %@
XPC on-device mode result: %@
Error ensuring service connection %@
Translation XPC connection failure, ignoring %lu requests
Translation rate limit reached, ignoring %lu requests
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Translation XPC connection failure, abort sending session feedback
Session sending feedback
Received translation result for %@
Connection to translationd was interrupted, the process exited or crashed
Failed to complete onDeviceModeEnabled check, using dedicated mach port %i: %@
Failed to clear caches: %@
Failed to complete get offline language status: %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete purging all assets: %@
Failed to complete updating all assets: %@
Failed to complete updating hotfix: %@
Failed to complete deleting hotfix: %@
Failed to complete installedLocales %@
Failed to complete getting asset size: %@
Failed to install offline locales: %@
Failed to complete availableLocalePairsForTask, using dedicated mach port: %i: %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Not showing first-use consent because it's running in the Translate app
Failed to complete checking whether to present system first time use consent: %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Failed to complete text-LID %{public}@-based request %@
Creating service proxy
Connection error: %@
Connection done
Creating text-only service proxy
Text translation connection error: %@
Text translation connection done
Creating SYNC service proxy
Failed to complete sync preheat request: %@
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Starting translation for request (using dedicated text mach port = %d)
Refusing to translate text since request isn't allowed to use dedicated mach port
Failed to complete getting text service for translation with dedicated mach port: %@
Failed to complete getting text service for translation without dedicated mach port: %@
Failed to serialize logging request: %@
Failed to complete logging request: %@
Voice type overridden for locale %{public}@ from %{public}@ to %{public}@
softlink:r:path:/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
ABSD
_LTActivityLogger
_LTActivityLoggerDelegate
NSObject
JSONRepresentation
_LTAlignment
NSSecureCoding
NSCoding
_LTAnalyticsEvent
_LTAsyncMap
_LTAudioData
_LTClientConnection
_LTTranslationService
_LTTextTranslationService
_LTCombinedEngine
_LTSpeechTranslationDelegate
_LTTranslationEngine
_LTCombinedRouteParagraphTranslationRequest
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
LTTranslationError
_LTMatch
_LTEtiquetteSanitizer
_LTHotfixManager
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTHybridEndpointerAssetInfo
_LTInstallRequest
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
_LTLanguageDetectorAssetInfo
_LTLanguageDetectorFeatureCombinationModel
_LTLanguageInstallationStatus
_LTLanguageAssetStatus
_LTLanguageManager
_LTLanguagePairOfflineAvailability
_LTLocalePair
NSCopying
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTTranslationSensesLoggingRequest
_LTSafariLatencyLoggingRequest
_LTLoggingRequestHandler
FTSpeechTranslationResponseDelegate
FTBatchTranslationResponseDelegate
_LTMultilingualSpeechRecognizer
_LTOfflineAssetManager
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
_LTOfflineTranslationEngine
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
_LTOnlineTranslationEngine
_LTOspreySpeechTranslationSession
_LTSpeechCompressorDelegate
_LTParagraphTranslationRequest
_LTPlaybackService
_LTPowerLogger
_LTRateLimiter
_LTBatchEventLog
SISchemaAdditions
EmptyPair
_LTInvocationEventLog
_LTInvocationEventContext
_LTASRStateEventLog
_LTServerSpeakSession
_LTServerSpeechSession
_LTSpeakRequest
_LTSpeechActivityDetector
SNResultsObserving
_LTSpeechCompressor
_LTSpeechDataQueueNode
_LTSpeechDataQueue
Osprey
_LTSpeechRecognitionResult
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTSpeechTranscription
_LTSpeechTranslationAssetInfo
_LTSpeechTranslationResultsBuffer
_LTTaskContext
_LTTextLanguageDetectionResult
_LTTextLanguageDetector
_LTTextLanguageDetectorScorerItem
_LTTextLanguageDetectorScorer
_LTTextToSpeechCache
_LTTokenizer
_LTTranslateSettingsController
_LTTranslationCandidate
OspreyRequest
_LTTranslationContext
_LTTranslationFeedback
_LTTranslationGenderAlternative
_LTTranslationParagraph
_LTTranslationRange
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTranslationResult
_LTTranslationSense
_LTTranslationServer
_LTTranslationSession
_LTTranslationSpan
LTStatistics
_LTTranslationStatistics
_LTTranslationToken
_LTTranslator
_LTWordTimingInfo
TranslationAssetUtil
LTArrayExtensions
LTParagraphs
LTLocaleIdentifier
LTPathUtil
FTErrorMessage
FLTBFBufferAccessor
FTDisableSessionLog
FTApgPronGuessMessage
FTApgBatchRecoverMessage
FTAsrRecognitionMessage
FTAsrErrorBlamerMessage
FTAsrItnMessage
FTAsrTextNormalizationMessage
FTAsrPostItnHammerMessage
FTAsrKeywordFinderMessage
FTAsrCorrectionsValidatorMessage
FTAsrGraphemeToPhonemeMessage
FTBlazarMultiUserMessage
FTBlazarMultilingualMessage
FTBlazarSpeechTranslationMessage
FTBlazarBatchTranslationMessage
FTBlazarTextToSpeechRouterMessage
FTBlazarTextToSpeechRouterStreamingMessage
FTBlazarServiceDiscoveryMessage
FTLmtLmScorerMessage
FTNapgCreateLanguageProfileMessage
FTMtTranslationMessage
FTMtStreamingTranslationMessage
FTTtsTextToSpeechMessage
FTTtsTextToSpeechStreamingMessage
FTTtsTextToSpeechSpeechFeatureMessage
FTNlShortcutFuzzyMatchMessage
FTSlsLanguageDetectionMessage
FTQssMessage
FTMutableErrorMessage
FTMutableDisableSessionLog
FTMutableApgPronGuessMessage
FTMutableApgBatchRecoverMessage
FTMutableAsrRecognitionMessage
FTMutableAsrErrorBlamerMessage
FTMutableAsrItnMessage
FTMutableAsrTextNormalizationMessage
FTMutableAsrPostItnHammerMessage
FTMutableAsrKeywordFinderMessage
FTMutableAsrCorrectionsValidatorMessage
FTMutableAsrGraphemeToPhonemeMessage
FTMutableBlazarMultiUserMessage
FTMutableBlazarMultilingualMessage
FTMutableBlazarSpeechTranslationMessage
FTMutableBlazarBatchTranslationMessage
FTMutableBlazarTextToSpeechRouterMessage
FTMutableBlazarTextToSpeechRouterStreamingMessage
FTMutableBlazarServiceDiscoveryMessage
FTMutableLmtLmScorerMessage
FTMutableNapgCreateLanguageProfileMessage
FTMutableMtTranslationMessage
FTMutableMtStreamingTranslationMessage
FTMutableTtsTextToSpeechMessage
FTMutableTtsTextToSpeechStreamingMessage
FTMutableTtsTextToSpeechSpeechFeatureMessage
FTMutableNlShortcutFuzzyMatchMessage
FTMutableSlsLanguageDetectionMessage
FTMutableQssMessage
FTUserLanguageProfile
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTStreamingTranslationRequest
FTTranslationPhraseMetaInfo
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTTTSWordPhonemes
FTTTSPhonemeSequence
FTTTSNeuralPhonemeSequence
FTTTSPrompts
FTTTSReplacement
FTTTSNormalizedText
FTTextToSpeechFeature
FTTextToSpeechRequestDebug
FTTextToSpeechVoiceResource
FTTextToSpeechUserProfile
FTTextToSpeechRequestDevConfig
FTTextToSpeechResponseDevData
FTTextToSpeechRequestProsodyControlConfig
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTTextToSpeechUserVoiceProfile
FTTextToSpeechRequestProsodyTransferConfig
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTTextToSpeechCacheContainerRpcV2
FTTextToSpeechCacheContainerStreamingV2
FTQssAckResponse
FTTextToSpeechSpeechFeatureModelIdentifier
FTTextToSpeechSpeechFeatureInputWord
FTTextToSpeechSpeechFeatureInputText
FTTextToSpeechSpeechFeatureInputWave
FTTextToSpeechSpeechFeatureOutputFeature
FTTextToSpeechSpeechFeatureInputPhoneme
FTTextToSpeechSpeechFeatureInputPhonemeSequence
FTTextToSpeechSpeechFeatureRequest
FTTextToSpeechSpeechFeatureRequest_LexiconEntry
FTTextToSpeechSpeechFeatureResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTServiceDiscoveryRequest
FTServiceDiscoveryResponse
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationFeedbackRequest
FTBatchTranslationLoggingRequest
FTBatchTranslationResponse
FTBatchTranslationResponse_TranslationPhrase
FTBatchTranslationResponse_TranslatedSentence
FTBatchTranslationCacheContainer
FTTranslationSupportedLanguagesRequest
FTTranslationSupportedLanguagesResponse
FTTranslationSupportedLanguagesResponse_LanguagePair
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTQSSVersionInfo
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableStreamingTranslationRequest
FTMutableTranslationPhraseMetaInfo
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableTTSWordPhonemes
FTMutableTTSPhonemeSequence
FTMutableTTSNeuralPhonemeSequence
FTMutableTTSPrompts
FTMutableTTSReplacement
FTMutableTTSNormalizedText
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequestDebug
FTMutableTextToSpeechVoiceResource
FTMutableTextToSpeechUserProfile
FTMutableTextToSpeechRequestDevConfig
FTMutableTextToSpeechResponseDevData
FTMutableTextToSpeechRequestProsodyControlConfig
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableTextToSpeechUserVoiceProfile
FTMutableTextToSpeechRequestProsodyTransferConfig
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableTextToSpeechCacheContainerRpcV2
FTMutableTextToSpeechCacheContainerStreamingV2
FTMutableQssAckResponse
FTMutableTextToSpeechSpeechFeatureModelIdentifier
FTMutableTextToSpeechSpeechFeatureInputWord
FTMutableTextToSpeechSpeechFeatureInputText
FTMutableTextToSpeechSpeechFeatureInputWave
FTMutableTextToSpeechSpeechFeatureOutputFeature
FTMutableTextToSpeechSpeechFeatureInputPhoneme
FTMutableTextToSpeechSpeechFeatureInputPhonemeSequence
FTMutableTextToSpeechSpeechFeatureRequest
FTMutableTextToSpeechSpeechFeatureRequest_LexiconEntry
FTMutableTextToSpeechSpeechFeatureResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableServiceDiscoveryRequest
FTMutableServiceDiscoveryResponse
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationFeedbackRequest
FTMutableBatchTranslationLoggingRequest
FTMutableBatchTranslationResponse
FTMutableBatchTranslationResponse_TranslationPhrase
FTMutableBatchTranslationResponse_TranslatedSentence
FTMutableBatchTranslationCacheContainer
FTMutableTranslationSupportedLanguagesRequest
FTMutableTranslationSupportedLanguagesResponse
FTMutableTranslationSupportedLanguagesResponse_LanguagePair
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutableQSSVersionInfo
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTStreamingTranslationStreamingRequest
FTStreamingTranslationStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableStreamingTranslationStreamingRequest
FTMutableStreamingTranslationStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTStreamingTranslationStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
UUID
sessionWithConfiguration:
componentsSeparatedByString:
prepareFor:to:
UUIDString
initWithPCMFormat:frameCapacity:
setExportedObject:
set_sourceApplicationBundleIdentifier:
toNSUUID
setFailed:
setAllowsCellularAccess:
sharedAnalytics
present
dictionary
initWithParent:userInfo:
opaqueSessionID
sharedConnection
presenterForPrivacySplashWithIdentifier:
operatingSystemVersionString
setRequiresPowerPluggedIn:
dictionaryMetrics
requestSupportedWithSamplingRate:
processIdentifier
sharedManager
dictionaryRepresentation
tokenName
processInfo
dictionaryWithDictionary:
orderedSetWithObjects:
tokenSausage
setFrameLength:
dictionaryWithObjects:forKeys:count:
infoDictionary
setAsrState:
processString:
stopSpeakingAtNextBoundary:synchronously:error:
setAsrStateUpdated:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
becomeCurrentWithPendingUnitCount:
setSampleRateConverterQuality:
_setQueue:
setSamplingRate:
maximumSupportedConfigurationVersion
resetForNewRequest:
processedAudioMs
featureValueForName:
containerURLForSecurityApplicationGroupIdentifier:
tokensForRange:
resignCurrent
initWithServiceName:options:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithShape:dataType:error:
contentsOfDirectoryAtPath:error:
resourceURL
silenceDurationMs
languageCode
setAutoDownloadedVoiceAssets:
totalUnitCount
initWithSoundIdentifier:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
initFromFormat:toFormat:
valueForEntitlement:
silenceFramesCountMs
outputs
setSequenceNumber:
setInputSource:
valueForKey:
fileExistsAtPath:
silenceProbability
valueForKeyPath:
domain
initWithStreamDescription:
initWithAttributedString:
fileExistsAtPath:isDirectory:
valueWithNonretainedObject:
boolForKey:
initWithString:
minimumSupportedConfigurationVersion
valueWithRange:
progressWithTotalUnitCount:
setBatchRequestContext:
fileURLWithPath:isDirectory:
doubleValue
boolValue
modelDescription
initWithString:attributes:
initWithBool:
fileURLWithPath:relativeToURL:
languageHypothesesWithMaximum:
initWithSuiteName:
setSessionId:
initWithBundleIdentifier:
filteredArrayUsingPredicate:
setInvalidationHandler:
initWithBytes:length:encoding:
modelWithContentsOfURL:error:
results
setInvocationContext:
initWithBytesNoCopy:length:deallocator:
sleepForTimeInterval:
bundleForClass:
resume
setIsExplicitLanguageFilterEnabled:
bytes
initWithType:
finishWriting
month
absoluteString
retrieveSessionWithID:
convertLanguageCodeToSchemaLocale:
sortUsingComparator:
initWithURL:configuration:
returnTypes:
setIsLanguageIdentificationEnabled:
moveItemAtURL:toURL:error:
convertToBuffer:error:withInputFromBlock:
firstObject
sortedArrayUsingSelector:
setCanUseServerTTS:
initWithUUIDString:
copy
initWithConfigFile:samplingRate:
languages
setCancelled:
initWithUnit:
initWithConfiguration:
mtId
setIsOnDeviceTranslation:
initWithConfiguration:overrideConfigFiles:generalVoc:lexiconEnh:itnEnh:
initWithUnsignedInteger:
path
downloadVoiceAsset:options:progressUpdateHandler:
initWithConfiguration:useQuasarFormatter:
initWithUnsignedLong:
floatValue
setClasses:forSelector:argumentIndex:ofReply:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
translateTokens:from:to:spans:completion:
translateTokens:isFinal:completion:
initWithContentsOfURL:
multiArrayValue
propertyListWithData:options:format:error:
lastObject
inputFormat
count
setLanguageCode:
mutableAudioBufferList
lastPathComponent
countByEnumeratingWithState:objects:count:
initWithData:encoding:
mutableBytes
weekOfYear
setClientTraceIdentifier:
emitMessage:isolatedStreamUUID:
mutableCopy
setLanguages:
countForObject:
purge:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
nBestResults
whitespaceAndNewlineCharacterSet
format
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
initWithDictionary:error:
runRecognitionWithResultStream:language:task:samplingRate:
setCompletedUnitCount:
whitespaceCharacterSet
string
createSymbolicLinkAtPath:withDestinationPath:error:
addAttribute:value:range:
initWithDouble:
stringByAppendingPathComponent:
addAudio:numSamples:
calendarWithIdentifier:
int16ChannelData
stringByAppendingString:
currentLocale
containsObject:
setStartedOrChanged:
addEntriesFromDictionary:
stringByReplacingCharactersInRange:withString:
currentProgress
containsString:
appendAttributedString:
setConcatenateUtterances:
frameLength
currentRoute
addObject:
intValue
appendBytes:length:
currentRunLoop
stringByReplacingOccurrencesOfString:withString:
initWithFloat:
integerValue
setMaxConcurrentOperationCount:
initWithFormat:
appendData:
stringByReplacingOccurrencesOfString:withString:options:range:
queryMetaDataSync
loadTranslatorFrom:to:
cancelCurrentRequest
addObjectsFromArray:
stringByTrimmingCharactersInSet:
appendFormat:
specifiersForPolicyOptions:force:
encodeBool:forKey:
addObserver:selector:name:object:
interfaceWithProtocol:
stringValue
appendString:
rangeOfCharacterFromSet:
encodeDouble:forKey:
addRequest:withObserver:error:
interpretationIndices
setString:
stringWithCString:encoding:
rangeOfCharacterFromSet:options:
addSamples:numSamples:
encodeInt32:forKey:
invalidate
dataTaskWithURL:completionHandler:
stringWithCharacters:length:
archivedDataWithRootObject:requiringSecureCoding:error:
rangeOfString:
encodeInt64:forKey:
stringWithFormat:
array
initWithIdentifier:range:doNotTranslate:
dataUsingEncoding:
rangeValue
localeWithLocaleIdentifier:
encodeInteger:forKey:
_initWithSuiteName:container:
arrayByAddingObjectsFromArray:
setMtId:
dataWithBytes:length:
stringWithString:
encodeObject:forKey:
writeFrame:
stringWithUTF8String:
dataWithContentsOfURL:
genderStringFromGender:
nextObject
subarrayWithRange:
dataWithContentsOfURL:options:error:
localizedDescription
arrayWithArray:
writeToURL:atomically:
endOfSentenceLikelihood
isBuiltInVoice
dataWithJSONObject:options:error:
portType
subdataWithRange:
arrayWithCapacity:
writeToURL:options:error:
localizedStringForKey:value:table:
getAutoDownloadedVoiceAssets:
allKeys
date
substringFromIndex:
arrayWithObject:
year
localizedStringForLocaleIdentifier:
setContextId:
initWithInt:
getCharacters:range:
allObjects
arrayWithObjects:count:
substringToIndex:
initWithInteger:
allValues
substringWithRange:
setNumParagraphFailures:
initWithLength:
getLocalFileUrl
recognition
allocWithZone:
decodeBoolForKey:
setNumParagraphs:
getLocalUrl
setObject:atIndexedSubscript:
decodeDoubleForKey:
initWithLocaleIdentifier:
supportedByQuasarConfig:
setObject:forKey:
decodeInt32ForKey:
synchronousRemoteObjectProxyWithErrorHandler:
standardUserDefaults
isDate:equalToDate:toUnitGranularity:
setObject:forKeyedSubscript:
systemUptime
decodeInt64ForKey:
assetId
getSiriDataSharingOptInStatusWithCompletion:
isDate:inSameDayAsDate:
checkResourceIsReachableAndReturnError:
decodeIntegerForKey:
startCatalogDownload:options:then:
setDetectUtterances:
setTotalUnitCount:
analyzeAudioBuffer:atAudioFramePosition:
null
decodeObjectForKey:
unarchivedObjectOfClasses:fromData:error:
decodeObjectOfClass:forKey:
startDownload:then:
isEqualToString:
decodeObjectOfClasses:forKey:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
setDictationLanguages:
initWithLong:
initWithMachServiceName:
defaultCenter
setDiscretionary:
initWithMachServiceName:options:
unsignedIntValue
defaultManager
attachProgressCallBack:
setOutputPath:
numberWithBool:
setDisplayMode:
refreshState
unsignedIntegerValue
numberWithDouble:
defaultMessageStream
attributedSubstringFromRange:
defaultServerEndpointFeatures
initWithModelURL:
numberWithFloat:
unsignedLongValue
registerDefaults:
longLongValue
groupSpecifierWithID:
defaultSessionConfiguration
numberWithInt:
remoteObjectProxy
longValue
numberWithInteger:
hasPrefix:
remoteObjectProxyWithErrorHandler:
clientSilenceFramesCountMs
numberWithLong:
removeAllObjects
clientSilenceProbability
numberWithLongLong:
initWithModelURLs:task:skipNonFinalToCatchup:translatorCacheSize:
removeItemAtPath:error:
hasSpaceBefore
updateEndpointerThresholdWithValue:
enumerateAttributesInRange:options:usingBlock:
numberWithUnsignedInt:
initWithNSUUID:
lowercaseString
removeItemAtURL:error:
hasSuffix:
startSpeakingRequest:
enumerateKeysAndObjectsUsingBlock:
numberWithUnsignedInteger:
serverFeaturesLatency
removeObject:
code
enumerateObjectsUsingBlock:
objectAtIndex:
setPresentingViewController:
removeObjectForKey:
setEnded:
enumerateSubstringsInRange:options:usingBlock:
predicateWithFormat:
JSONObjectWithData:options:error:
objectAtIndexedSubscript:
detectUtterances
removeObjectsInArray:
predictionFromFeatures:options:error:
objectEnumerator
URLByAppendingPathComponent:
enumerateTokensInRange:usingBlock:
detected
removeObserver:
setError:
setUseCompression:
isValidJSONObject:
URLByAppendingPathExtension:
objectForInfoDictionaryKey:
setErrorCode:
hatToQsrString:
objectForKey:
URLByDeletingLastPathComponent
timeIntervalSinceDate:
setErrorDomain:
errorWithDomain:code:userInfo:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
objectForKeyedSubscript:
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
setEventMetadata:
replaceBytesInRange:withBytes:length:
components:fromDate:
setValue:forHTTPHeaderField:
setRate:
URLWithString:
mainBundle
replaceCharactersInRange:withString:
setExists:
componentsJoinedByString:
setWithArray:
UTF8String
sessionId
componentsSeparatedByCharactersInSet:
userInfo
setWithObjects:
setRemoteObjectInterface:
setExportedInterface:
audioStreamBasicDescription
init
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
activityLogger:logUsageForTask:interval:date:
activityLogger:logAggregateUsageForInterval:date:
activityLogger:lastLoggedDateForTask:
activityLogger:updateLastLoggedDate:forTask:
lastAggregateLogDateForActivityLogger:
activityLogger:updateLastAggregateLogDate:
registerActivity:
_registerActivity:onDate:
_logAllIntervalsForTask:date:
_logActivityForTask:interval:date:
_updateLastLoggedDate:forTask:
_sendDailyUsageForTask:date:
_sendWeeklyUsageForTask:date:
_sendMonthlyUsageForTask:date:
_featureNameForTask:
_activityDatePreferenceKeyForTask:
delegate
setDelegate:
.cxx_destruct
_calendar
_delegate
T@"<_LTActivityLoggerDelegate>",W,N,V_delegate
jsonRepresentation
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
identifier
setIdentifier:
sourceRange
setSourceRange:
targetRange
setTargetRange:
text
setText:
shouldTranslate
setShouldTranslate:
_shouldTranslate
_identifier
_text
_sourceRange
_targetRange
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_identifier
T@"NSString",C,N,V_text
TB,N,V_shouldTranslate
timedEventWithName:
initWithName:
markStart
markEnd
timestampWithName:
addFieldsFromDictionary:
addFieldsFromDictionary:internalOnly:
addFieldsWithError:
sendLazy
sourceLocale
setSourceLocale:
targetLocale
setTargetLocale:
_eventName
_startTime
_endTime
_queue
_fields
_sourceLocale
_targetLocale
T@"NSLocale",C,N,V_sourceLocale
T@"NSLocale",C,N,V_targetLocale
_ltAsyncMap:completion:
_ltAsyncMap:queue:completion:
_ltSequentialMap:completion:
initWithASBD:rawData:wordTimingInfo:
_populateWithOpusData:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
wordTimingInfo
_asbd
_data
_packetCount
_packetDescriptions
_rawData
_wordTimingInfo
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T@"NSData",R,N,V_rawData
Tq,R,N,V_packetCount
T@"NSData",R,N,V_packetDescriptions
T@"NSArray",R,N,V_wordTimingInfo
onDeviceModeEnabled:
shouldPresentSystemFirstUseConsent:
availableLocalePairsForTask:completion:
languagesForText:usingModel:strategy:completion:
translate:withContext:completion:
translateParagraphs:withContext:completion:
configInfoForLocale:otherLocale:completion:
preheatWithContext:completion:
translateSentence:withContext:completion:
provideFeedback:withContext:
startTextToSpeechTranslationWithContext:text:
startSpeechTranslationWithContext:
addSpeechAudioData:
endAudio
clearCaches
languageForText:completion:
languagesForText:completion:
speak:withContext:completion:
cleanup
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
_getAssetSize:
_updateHotfix:
_deleteHotfix:
installedLocales:
startInstallRequest:
task:isSupportedInCountry:completion:
additionalLikelyPreferredLocalesForLocale:completion:
logWithRequestData:
initWithConnection:server:trusted:
_clientDelegate
cleanupOnDisconnect
languagesForText:usingModel:completion:
logRequestOfType:context:
_connection
_server
_trusted
_trustedClientIdentifier
_speechSessionID
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
setLanguagesRecognized:
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
speechRecognitionResult:
translatorDidTranslate:
translationDidFinishWithError:
speechActivityDetected
languageDetectionResult:
languageDetectionCompleted
cancel
paragraphTranslation:result:error:
languageInstallProgressed:error:
ttsProgressed:
translatesPair:
preheatAsynchronously:withContext:
translate:withContext:paragraphResult:completion:
startSpeechTranslationWithContext:delegate:
endpoint
cancelSpeechTranslation
startTextToSpeechTranslationWithContext:text:delegate:
offlineEngine
setOfflineEngine:
onlineEngine
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
requestContext
initialize
listener:shouldAcceptNewConnection:
clientConnectionClosed:
_setupMemoryWarningListener
_cacheDirectoryPath
_enterSandbox
_translationListener
_textTranslationListener
_listenerQueue
_connections
lt_internalErrorWithCode:description:userInfo:
lt_errorWithCode:description:userInfo:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
initWithNode:range:
node
setNode:
range
setRange:
token
setToken:
_node
_token
_range
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
initWithReplacementTokenDictionary:language:
initWithModelURL:language:
treeForReplacementTokens:
matchesForString:
replacementStringForString:forToken:
stringByReplacingMatches:inString:
sanitizedStringForString:
_replacementTree
_locale
hotfixURL
updateHotfix:
deleteHotfix:
_downloadWithURL:completion:
_CDNURL:
_downloadMappingPlist:
_downloadHotfix:completion:
_decompressArchive:to:error:
_hotfixURL
T@"NSURL",R,N,V_hotfixURL
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
didEndpointWithFeatures:silenceFeatures:endpointer:
endpointerThreshold
setEndpointerThreshold:
samplingRate
audioBitDepth
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_context
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_samplingRate
_audioBitDepth
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
Tq,R,N,V_audioBitDepth
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
initWithAvailableAssets:context:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
isPremium:
caesuraModelURL
endpointerModelURL:
endpointerIsAvailableWithContext:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
T@"NSString",R,N,V_hybridepAssetFile
T@"NSString",R,N,V_spgAssetFile
initWithLocales:useCellular:
initWithLocales:useCellular:progressHandler:
initWithLocales:useCellular:delegate:
_startInstallationWithService:done:
locales
setLocales:
useCellular
setUseCellular:
progressHandler
setProgressHandler:
completionHandler
setCompletionHandler:
_service
_done
_useCellular
_locales
_progressHandler
_completionHandler
T@?,C,N,V_completionHandler
T@"NSArray",C,N,V_locales
TB,N,V_useCellular
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
T@?,C,N,V_progressHandler
initWithConfidences:isConfident:dominantLanguage:isFinal:
dominantLanguage
setDominantLanguage:
confidences
setConfidences:
isConfident
isFinal
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
startLanguageDetectionWithContext:delegate:
sendLIDResult:
haveFinalASRResults
haveAtLeastOneFinalASRResult
sendFinalLanguageDetectionResult:
addSpeechRecognitionResult:
cancelLanguageDetection
forceLanguageDetectionResult
acousticResults
setAcousticResults:
lastResult
setLastResult:
featureCombinationModelSupported
setFeatureCombinationModelSupported:
featureCombinationModel
setFeatureCombinationModel:
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_minimumAcousticLanguageDetectorResults
_maximumAcousticLanguageDetectorResults
_endAudioCalled
_useFinalThresholds
_finalLIDResultSent
_firstPacketSent
_receivedPartialSpeechResult
_havePartialASRConfidences
_partialSpeechResultConfidences
_finalSpeechResults
_modelVersions
_lidSignpostID
_resultQueue
_finalResultWaitQueue
_featureCombinationModelSupported
_acousticResults
_lastResult
_featureCombinationModel
T@"NSMutableArray",&,N,V_acousticResults
T@"_LTLanguageDetectionResult",&,N,V_lastResult
TB,N,V_featureCombinationModelSupported
T@"_LTLanguageDetectorFeatureCombinationModel",&,N,V_featureCombinationModel
Td,R,N,V_samplingRate
initWithAssetUrl:featureCombinationAssetUrl:
languageDetectorModelURL
featureCombinationConfigUrl
_assetUrl
_featureCombinationConfigUrl
initWithConfig:
getAcousticLidConfidenceFromResult:locale:
getModelFeatures:canonicalPair:partialSpeechResultConfidences:finalSpeechResults:modelVersion:
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:useFinalThresholds:
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:
_mlModel
_modelInput
_modelInputIsMatrix
_modelOutput
_features
_missingFeatureValueDefault
_missingLanguageDetectorDefault
_languageLocaleToIdentifier
progress
setProgress:
localeIdentifier
setLocaleIdentifier:
offlineState
setOfflineState:
totalExpected
setTotalExpected:
totalWritten
setTotalWritten:
isStalled
setIsStalled:
expectedTimeRemaining
setExpectedTimeRemaining:
_isStalled
_progress
_localeIdentifier
_offlineState
_totalExpected
_totalWritten
_expectedTimeRemaining
Tq,N,V_progress
T@"NSString",C,N,V_localeIdentifier
TQ,N,V_offlineState
Tq,N,V_totalExpected
Tq,N,V_totalWritten
TB,N,V_isStalled
Td,N,V_expectedTimeRemaining
_LTAssetStateString
finished
setFinished:
status
setStatus:
localIdentifiers
setLocalIdentifiers:
update
setUpdate:
_finished
_status
_localIdentifiers
_update
TB,N,V_finished
TQ,N,V_status
T@"NSArray",&,N,V_localIdentifiers
T@"MAProgressNotification",&,N,V_update
compare:
sharedInstance
identifiersInIdentifiers:forLanguageName:
identifiersInIdentifiers:forAssetName:
pairNamesForLocales:
assetNamesForPairNames:
assetsNamesForLocale:
assetWithName:inAssets:
installationStatusArray
languageToStatusDictionary
updateProgress
downloadAsset:withStatus:
setInstalledLocales:useCellular:completion:
_setInstalledLocales:
_assetManager
_assetStatusDictionary
_localeIdentifierList
initWithLocales:
pairState
setPairState:
pair
setPair:
sourceASRState
setSourceASRState:
targetASRState
setTargetASRState:
mtState
setMtState:
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
needsUpdate
setNeedsUpdate:
_needsUpdate
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
pairWithIdentifiers:
copyWithZone:
initWithSourceLocale:targetLocale:
combinedLocaleIdentifier
reversedPair
isBidirectionalEqual:
oppositeToLocale:
canonicalIdentifier
canonicalLocalePair
isPassthrough
isVariantPair
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
conversationID
setConversationID:
requestID
setRequestID:
localePair
setLocalePair:
selectedLocale
setSelectedLocale:
lidResult
setLidResult:
_conversationID
_requestID
_localePair
_selectedLocale
_lidResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"_LTLocalePair",C,N,V_localePair
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_lidResult
senses
setSenses:
userInteractedSenses
setUserInteractedSenses:
_senses
_userInteractedSenses
T@"NSArray",C,N,V_senses
T@"NSArray",C,N,V_userInteractedSenses
markResponse
markFirstParagraphComplete
markProgressDone
markPageComplete
dict
start
firstResponse
firstParagraphComplete
progressComplete
pageComplete
processName
setProcessName:
_start
_firstResponse
_firstParagraphComplete
_progressComplete
_pageComplete
_processName
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_firstParagraphComplete
Td,R,N,V_progressComplete
Td,R,N,V_pageComplete
T@"NSString",C,N,V_processName
T@"NSDictionary",R,N
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
mtAppService
startLoggingRequest:
startSpeechLIDRequest:
startSpeechSensesLoggingRequest:
startSafariLatencyLoggingRequest:
startSafariFeedbackRequest:
_mtAppService
T@"FTBlazarService",R,N,V_mtAppService
initWithModelURLs:modelVersions:
startRecognitionForLocale:autoEndpoint:resultHandler:
cancelRecognition
_recognizers
compareAssetVersionReversed:
fallBackAssetResourcePath
_clearCaches
configAssetURL
_refreshCatalogIfNeededWithCompletion:
assetsSortedByVersion:
_refreshAllAssets:
refreshAllIfNeededWithCompletion:
removeObsoleteAssets
catalogAssets
installedAssets
configAssetInAssets:
configAsset
matchingASRAssetForLocale:inAssets:
_configPlistWithFileName:
_queryLanguagePairStatus:
deleteAsset:completion:
downloadAsset:userInitiated:progressCallback:completion:
downloadAsset:userInitiated:useCellular:progressCallback:completion:
downloadAsset:downloadOptions:progressCallback:completion:
offlineLanguageStatus:
_downloadVoiceAsset:
_voiceAssetForLocaleIdentifier:
downloadVoiceAssetsForLanguagePair:
_removeOldAssetDirectory
assetDirectory
_assetIdentifiersForLanguagePairDirectory:
assetIdentifierReferenceCountDictionary
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
debugDumpAssets:
_updateAsset:catalogAssets:downloadGroup:completion:
updateAllAssets:
updateSpeechTranslationAssetSymLinks:
_downloadPassthroughAssetForLocale:userInitiated:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
modelURLsForLanguagePair:
speechTranslationAssetInfoForLocalePair:error:
_speechTranslationAssetInfoForLocalePair:error:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
getEndpointerAssetWithType:error:
endpointAssetInfoWithContext:error:
languageDetectorAssetWithError:
configurationPropertyListWithURL:
configurationPropertyListWithName:
assetSize:
_hotfixMgr
preferredVoiceGender
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didStartPlayingPreviewRequest:
initWithCompletion:
speak:withContext:
_completion
initWithLocalePair:assetInfo:
_loadRecognizers
_loadEtiquetteSanitizers
_loadTranslatorForTask:
_handleTranslationResults:withContext:
_translateString:withContext:toLocale:withSpans:completion:
_paragraphResultFromSentences:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
_getBestRecognitionResult:context:
_waitForLIDWithContext:completion:
_translate:withContext:isFinal:completion:
_translatePrepare:
asrModelURLs
setAsrModelURLs:
mtModelURL
setMtModelURL:
ttsCache
setTtsCache:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_didEndpointSpeech
_earError
_asrModelURLs
_mtModelURL
_ttsCache
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
T@"_LTTextToSpeechCache",&,N,V_ttsCache
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_paragraph
_requestParagraph
T@?,C,N,V_completion
T@"_LTTranslationParagraph",&,N,V_paragraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
callCompletionHandlersWithError:
request
setRequest:
toLocale
setToLocale:
batchLog
setBatchLog:
batchedParagraphs
setBatchedParagraphs:
taskHint
setTaskHint:
bufferSize
setBufferSize:
sessionID
setSessionID:
clientHeader
setClientHeader:
clientIdentifier
setClientIdentifier:
sourceURL
setSourceURL:
hasFinalServerResponse
setHasFinalServerResponse:
completionHandlerCalled
setCompletionHandlerCalled:
logIdentifier
setLogIdentifier:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_batchLog
_batchedParagraphs
_taskHint
_bufferSize
_sessionID
_clientHeader
_clientIdentifier
_sourceURL
_logIdentifier
T@"FTMutableBatchTranslationRequest",&,N,V_request
T@"NSLocale",&,N,V_toLocale
T@"_LTBatchEventLog",&,N,V_batchLog
T@"NSMutableDictionary",&,N,V_batchedParagraphs
Tq,N,V_taskHint
TQ,N,V_bufferSize
T@"NSLocale",&,N,V_sourceLocale
T@"NSLocale",&,N,V_targetLocale
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
T@"NSString",C,N,V_clientHeader
T@"NSString",&,N,V_clientIdentifier
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
T@"NSString",C,N,V_logIdentifier
blazarServiceWithBundleID:
_blazarService
_siriService
_systemService
_webTaskService
_serviceForTask:
startServerTimeoutTimer
updateServerTimeout
cancelServerTimeout
serverTimeoutFired
_tokenizeString:inLocale:
_translateParagraph:index:context:completion:
sendBatchTranslationRequestWithDelegate:
_hasOngoingSpeechSession
_speechSessionCompletedWithError:
serverQueue
setServerQueue:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_dataSharingOptInStatus
_serverQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverQueue
didCompressPackets:totalPacketCount:
sendAnalyticsEvent
initWithService:context:delegate:
initWithService:context:text:delegate:
initCommon
updateServerTimeout:
sendAudioData:
sendEndAudio
_primaryLanguageRecognized
_translationForLocale:
confirmDataIfNeeded
_handleAudioLimitExceededResponse:
_handlePartialRecognitionResponse:
_handleFinalRecognitionResponse:
_handleServerEndpointFeatures:
_handleTranslationResponse:
_handleTTSResponse:
_handleFinalBlazarResponse:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
completionBlock
setCompletionBlock:
_streamContext
_sentAudio
_sentEndAudio
_endpointedSpeech
_didReceiveAudioLimitExceededResponse
_didReceivePartialRecognitionResponse
_didReceiveFinalRecognitionResponse
_didReceiveTranslationResponse
_didReceiveTTSResponse
_didReceiveFinalBlazarResponse
_didTimeout
_error
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
Td,N,V_initialOnlineTimeout
Td,N,V_onlineTimeout
Td,N,V_endpointTimeout
T@?,C,N,V_completionBlock
loggingType
_canUseTextService
_startTranslationWithService:done:
_startTranslationWithTextService:done:
_translationFailedWithError:
translationParagraph
ranges
setRanges:
_ranges
T@"NSArray",C,N,V_ranges
handleMediaServerReset
dealloc
initWithContext:ASBD:
enqueue:packetCount:packetDescriptions:
signalQueueRunningStateChanged
waitForAudioQueueStop
flushAndStop
stop
reset
isAudioQueueRunning
state
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
Tq,R,N,V_state
logTranslateRequestEvent:requestType:routeType:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
T@"NSOrderedSet",&,V_requestTypeSet
initWithMaximumPageLoadRequest:maximumDynamicContentRequests:
allowedForRequests:
markPageLoaded
maximumPageLoadRequests
setMaximumPageLoadRequests:
maximumDynamicContentRequests
setMaximumDynamicContentRequests:
_count
_pageLoaded
_maximumPageLoadRequests
_maximumDynamicContentRequests
TQ,N,V_maximumPageLoadRequests
TQ,N,V_maximumDynamicContentRequests
initWithRequest:logID:
startWithParagraphCount:
endSuccessfully
endWithError:failedParagraphs:
cancelWithReason:
makeContext
sendWithContext:
schemaPair
unknown
endSuccessfullyWithQSSSessionID:
endWithError:qssSessionID:
cancelWithReason:qssSessionID:
mtID
setTask:
setMode:
setOnDevice:
context
T@"_LTInvocationEventContext",R,N,V_context
setQssSessionId:
logStartedOrChanged
logEndedWithQSSSessionID:
logCancelledWithReason:qssSessionID:
logFailedWithError:qssSessionID:
isOnDevice
setIsOnDevice:
explicitLanguageFilterEnabled
setExplicitLanguageFilterEnabled:
languageIDEnabled
setLanguageIDEnabled:
configVersion
setConfigVersion:
task
inputMode
setInputMode:
uiMode
setUiMode:
languagePair
setLanguagePair:
_isOnDevice
_explicitLanguageFilterEnabled
_languageIDEnabled
_configVersion
_task
_inputMode
_uiMode
_languagePair
TB,N,V_isOnDevice
TB,N,V_explicitLanguageFilterEnabled
TB,N,V_languageIDEnabled
T@"NSString",&,N,V_configVersion
Tq,N,V_task
Tq,N,V_inputMode
Tq,N,V_uiMode
T@"_LTLocalePair",&,N,V_languagePair
logFirstPacketSent:
logFirstPacketReceived:
logFirstPacketDisplayed:
logFinalPacketSent:
logFinalPacketReceived:
emitWithState:uuid:
mtSELFLog
Tq,R,V_state
initWithEngine:
_createTemporaryOutputFileWithURL:
_playback:context:completion:audioStartHandler:
speak:context:completion:audioStartHandler:
_engine
_player
initWithEngine:delegate:
_startSpeechTranslationWithContext:
_translateSpeechAudioData:
delegateTranslationDidFinishWithError:
engine
setEngine:
languageDetector
endpointer
_expectFinalLidResult
_sentFinalLidResult
_translationFinished
_speechActivityDetected
_translationError
_cache
_speechDetector
_languageDetector
_endpointer
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
T@"_LTLanguageDetector",R,N,V_languageDetector
T@"_LTHybridEndpointer",R,N,V_endpointer
initWithLocalePair:
ttsPlaybackRate
setTtsPlaybackRate:
ttsProgressHandler
setTtsProgressHandler:
_ttsPlaybackRate
_ttsProgressHandler
T@"NSString",&,N,V_text
Td,N,V_ttsPlaybackRate
T@?,C,N,V_ttsProgressHandler
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithDelegate:
nativeAudioFormat
_streamAnalyzer
_position
startCompressionNarrowband:
addAudioSampleData:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
data
setData:
next
setNext:
_next
T@"NSData",&,N,V_data
T@"_LTSpeechDataQueueNode",&,N,V_next
initForSeconds:
consumeAll:
_maxFrames
_currentFrames
_head
_tail
initWithOspreyResponse:confidenceThreshold:isSanitized:
initWithOspreyPartialRecognitionResponse:isSanitized:
resultWithPackage:locale:modelVersion:isFinal:
resultWithResult:locale:modelVersion:isFinal:
emptyResultWithLocale:isFinal:
initWithPackage:locale:modelVersion:isFinal:
initWithResult:locale:modelVersion:isFinal:
initEmptyResultWithLocale:isFinal:
_transcriptionWithResult:locale:
bestTranscription
setFinal:
isStable
setStable:
locale
setLocale:
transcriptions
setTranscriptions:
bestRecognitionAlternatives
setBestRecognitionAlternatives:
modelVersion
setModelVersion:
_final
_stable
_transcriptions
_bestRecognitionAlternatives
_modelVersion
final
TB,N,GisFinal,V_final
stable
TB,N,GisStable,V_stable
T@"NSString",&,N,V_modelVersion
T@"NSLocale",C,N,V_locale
T@"NSArray",&,N,V_transcriptions
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
initWithOspreySausage:choices:locale:
initWithRecognition:wordConfidenceThreshold:
bins
setBins:
_bins
T@"NSArray",&,N,V_bins
alternatives
setAlternatives:
bestAlternativeIndex
setBestAlternativeIndex:
_alternatives
_bestAlternativeIndex
T@"NSArray",&,N,V_alternatives
TQ,N,V_bestAlternativeIndex
confidence
setConfidence:
isLowConfidence
setLowConfidence:
hasSpaceAfter
setHasSpaceAfter:
_lowConfidence
_hasSpaceAfter
_confidence
Tq,N,V_confidence
lowConfidence
TB,N,GisLowConfidence,V_lowConfidence
TB,N,V_hasSpaceAfter
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
speechRecognizer:didRecognizeFinalResultCandidatePackage:
initWithModelURL:language:modelVersion:
startRecognitionWithAutoStop:resultHandler:
triggerServerSideEndPointer
_recognizedResult:error:
modelURL
language
recognitionHandler
setRecognitionHandler:
_buffer
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelURL
_language
_recognitionHandler
T@?,C,N,V_recognitionHandler
T@"NSURL",R,N,V_modelURL
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
initWithRecognitionChoice:inSausage:
initWithFormattedString:locale:confidence:minConfidence:maxConfidence:
formattedString
setFormattedString:
sanitizedFormattedString
setSanitizedFormattedString:
minConfidence
setMinConfidence:
maxConfidence
setMaxConfidence:
_formattedString
_sanitizedFormattedString
_minConfidence
_maxConfidence
Td,N,V_confidence
Td,N,V_minConfidence
Td,N,V_maxConfidence
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
_getTranslationConfig
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
createSymlinkDirectoryForMTAssets
referenceAssets:catalogAssets:
updateAvailableInAssets:
speechModelURLForLocale:
speechModelVersionForLocale:
translationModelURLs
isCompletePassthroughModel
isCompleteBidirectionalModel
_mtModelOfflineState
availabilityInfo
_languagePairDirectory
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
downloadAssetsUserInitiated:queue:completion:
purgeAssetUserInitiated:queue:completion:
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_modelURLs
stopBuffering
hasFailed
hasResults
_isBuffering
_lastASRResults
_translationResult
_didFinish
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
sendAnalytics:isSupported:
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
initWithScorer:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
initWithModel:
detectionForString:
detectionForStrings:
detectionForStrings:strategy:
availableLocales
setAvailableLocales:
_availableLocales
T@"NSArray",C,N,V_availableLocales
initWithLocale:confidence:wordCount:
score
T@"NSLocale",R,C,N,V_locale
Td,R,N,V_confidence
Tq,R,N,V_wordCount
initWithSupportedLocales:
append:recognizer:
hasWeightedLocale
weightedLocale
_items
_supportedLocales
TB,R,N
T@"NSLocale",R,C,N
cacheAudioData:forKey:
audioDataForKey:
clear
_cacheQueue
_wordCount:inLocale:
tokenize:forLocale:
setPreferenceValue:specifier:
readPreferenceValue:
isOnDeviceOnlyTranslationForced
specifiers
showTranslatePrivacy
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:locale:
initWithOspreyMtResponsePhrase:locale:injectingGenderTranslation:genderInjectedMetaInfo:
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:romanization:tokens:preToPostITN:
updateWithEngineMeta:locale:
preToPostITN
tokens
setTokens:
genderAlternatives
setGenderAlternatives:
statistics
setStatistics:
romanization
setRomanization:
proToPostITN
setProToPostITN:
_preToPostITN
_tokens
_genderAlternatives
_statistics
_romanization
_proToPostITN
T@"NSArray",C,N,V_tokens
T@"NSArray",C,N,V_proToPostITN
T@"NSArray",C,N,V_genderAlternatives
T@"_LTTranslationStatistics",C,N,V_statistics
T@"NSString",C,N,V_romanization
T@"NSArray",R,N,V_preToPostITN
_ospreyDataSharingStatus
_ttsVoiceStringWithLocale:
_ospreySpeechTranslationRequestWithHybridEndpointer:
_ospreyTextToSpeechTranslationRequestWithText:
_ospreyTTSRequestWithText:
redactIfNeeded:
sequoiaClientHeaderValue
sanitizedCopyForUntrustedTextTranslation
uniqueID
setUniqueID:
autodetectLanguage
setAutodetectLanguage:
censorSpeech
setCensorSpeech:
outputFileURL
setOutputFileURL:
autoEndpoint
setAutoEndpoint:
lidThreshold
setLidThreshold:
route
setRoute:
audioSessionID
setAudioSessionID:
asrConfidenceThreshold
setAsrConfidenceThreshold:
enableVAD
setEnableVAD:
setAppIdentifier:
sourceOrigin
setSourceOrigin:
untrustedClientIdentifier
setUntrustedClientIdentifier:
trustedClientIdentifier
setTrustedClientIdentifier:
dataSharingOptInStatus
setDataSharingOptInStatus:
_autodetectLanguage
_censorSpeech
_autoEndpoint
_enableVAD
_audioSessionID
_uniqueID
_outputFileURL
_lidThreshold
_route
_asrConfidenceThreshold
_sourceOrigin
_untrustedClientIdentifier
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
TB,N,V_autodetectLanguage
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
TB,N,V_enableVAD
T@"NSString",C,N,V_appIdentifier
Tq,N,V_sourceOrigin
T@"NSString",C,N,V_untrustedClientIdentifier
T@"NSString",R,C,N
T@"NSString",C,N,V_trustedClientIdentifier
Tq,N,V_dataSharingOptInStatus
sourceContentAsJSON
setSourceContentAsJSON:
targetContentAsJSON
setTargetContentAsJSON:
errorsAsJSON
setErrorsAsJSON:
safariVersion
setSafariVersion:
webpageURL
setWebpageURL:
clientBundleID
setClientBundleID:
_sourceContentAsJSON
_targetContentAsJSON
_errorsAsJSON
_safariVersion
_webpageURL
_clientBundleID
T@"NSString",C,N,V_clientBundleID
T@"NSString",C,N,V_sourceContentAsJSON
T@"NSString",C,N,V_targetContentAsJSON
T@"NSString",C,N,V_errorsAsJSON
T@"NSString",C,N,V_safariVersion
T@"NSURL",C,N,V_webpageURL
genderAlternativesFromDictionary:
genderAlternativeFromDictionary:withGroup:
group
setGroup:
defaultGender
setDefaultGender:
_group
_defaultGender
T@"NSNumber",C,N,V_group
T@"NSString",&,N,V_defaultGender
initWithIdentifier:text:spans:
splitIntoSentences
spans
_spans
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
T@"NSArray",R,C,N,V_spans
initWithIdentifier:text:shouldTranslate:
metaInfo
setMetaInfo:
_metaInfo
TB,R,N,V_shouldTranslate
T@"NSDictionary",C,N,V_metaInfo
initWithLocalePair:suggestedUniqueID:
initWithSourceLocale:targetLocale:suggestedUniqueID:
qssSessionID
serviceDelegate
forcedOfflineTranslation
setForcedOfflineTranslation:
_forcedOnlineTranslation
set_forcedOnlineTranslation:
_offlineMTModelURL
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
batchSessionUUID
setBatchSessionUUID:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
_batchSessionUUID
T@"NSUUID",C,N,V_batchSessionUUID
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
TB,N,V_forcedOfflineTranslation
TB,N,V__forcedOnlineTranslation
T@"NSURL",&,N,V__offlineMTModelURL
Tq,N,V__mtConfidenceThreshold
_paragraphRequestForText:
_realign:identifier:
_constructFinalParagraphResult
_handleParagraphResponse:error:
sentence
setSentence:
ignoringAttributes
setIgnoringAttributes:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
textTranslationHandler
setTextTranslationHandler:
_session
_savedAttributes
_paragraphOrder
_outstandingCount
_receivedParagraphs
_sentence
_ignoringAttributes
_textHandler
_translationHandler
_textTranslationHandler
T@"NSString",C,N,V_sentence
T@"NSAttributedString",C,N,V_text
T@"NSArray",C,N,V_ignoringAttributes
T@?,C,N,V_textHandler
T@?,C,N,V_translationHandler
T@?,C,N,V_textTranslationHandler
paragraphs
setParagraphs:
_paragraphs
T@"NSArray",C,N,V_paragraphs
_appendAudioPCMBuffer:
appendAudioPCMBuffer:
_simulateRealtimeBehavior:
_appendAudioSampleBuffer:simulateRealtime:
append:simulateRealtime:
_drainAndClearAudioConverter
_convertAndFeedPCMBuffer:
_lidModelURL
set_lidModelURL:
_offlineASRModelURLs
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
T@"NSURL",&,N,V__lidModelURL
T@"NSArray",&,N,V__offlineASRModelURLs
Tq,N,V__asrConfidenceThreshold
Tq,N,V__lidThreshold
initWithOspreySpeechTranslationMTResponse:
initWithOspreyResponse:
initWithOspreyBatchResponse:
updateAlignmentWithSourceSpan:targetSpan:
passthroughResultWithString:sanitizedString:locale:
resultWithLocale:translations:
translations
setTranslations:
sourceString
setSourceString:
sanitizedSourceString
setSanitizedSourceString:
alignments
setAlignments:
_translations
_sourceString
_sanitizedSourceString
_alignments
T@"NSArray",C,N,V_translations
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
sensesFromArray:
senseWithPhrasebookMatchMeta:
senseFromDictionary:
isPhrasebookMatch
setPhrasebookMatch:
senseID
setSenseID:
definition
setDefinition:
sourceMatch
setSourceMatch:
targetMatch
setTargetMatch:
labels
setLabels:
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
_labels
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
T@"NSArray",C,N,V_labels
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
translateParagraphs:withContext:paragraphResult:completion:
speak:withContext:delegate:completion:
cancelSpeechSession
cancelSpeechSessionWithID:
_speechSessionCompleted
notifyOfMemoryPressure
cleanupOfflineEngine
startInstallRequest:delegate:
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
_activityLogger
initWithTranslator:
initForFutureServiceWithSessionID:
_commonInitWithSuggestedSessionID:
prepareWithService:
_ensureServiceConnection:useDedicatedTextMachPort:
translate:
translate:useDedicatedTextMachPort:
provideFeedback:
setURL:
translator
setTranslator:
service
setService:
rateLimiter
setRateLimiter:
translationQueue
setTranslationQueue:
_outstandingRequests
_logging
_waitingForService
_URL
_rateLimiter
T@"_LTTranslator",&,N,V_translator
T@"<_LTTextTranslationService>",&,N,V_service
T@"_LTRateLimiter",&,N,V_rateLimiter
T@"NSObject<OS_dispatch_queue>",&,N,V_translationQueue
T@"NSURL",C,N,V_URL
initWithIdentifier:range:
initWithIdentifier:range:shouldTranslate:metaInfoData:
metaInfoData
setMetaInfoData:
_metaInfoData
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
T@"NSData",C,N,V_metaInfoData
_ltRemoveAllWhitespaces
_ltTrimWhitespaces
_countWithTokenString:countCharacters:
statisticsWithEngineMeta:locale:
inputTokenCount
setInputTokenCount:
inputSubtokenCount
setInputSubtokenCount:
_inputTokenCount
_inputSubtokenCount
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
initWithOspreyToken:
initWithText:confidence:
interruptionHandler
setInterruptionHandler:
onDeviceModeEnabledWithDedicatedMachPort:completion:
installOfflineLocales:completion:
availableLocalePairsForTask:useDedicatedMachPort:completion:
shouldPresentSystemFirstUseConsentWithDedicatedMachPort:completion:
taskIsSupportedInCurrentRegion:completion:
languagesForText:usingModel:useDedicatedTextMachPort:completion:
languagesForText:usingModel:strategy:useDedicatedTextMachPort:completion:
_getServiceProxyWithDelegate:errorHandler:block:
_getTextServiceProxyWithDelegate:useDedicatedTextMachPort:errorHandler:block:
_getSyncServiceProxyWithDelegate:errorHandler:block:
T@?,C,N
preheatForRequestSync:
preheatForRequest:completion:
log:
startTranslationSession
wordTimingInfoFromArray:
initWithFTWordTimingInfo:
word
sampleIndex
offset
length
timestamp
_sampleIndex
_offset
_length
_word
_timestamp
T@"NSString",R,N,V_word
TI,R,N,V_sampleIndex
TI,R,N,V_offset
TI,R,N,V_length
Td,R,N,V_timestamp
transcribesLocale:
isASRModel
isMTModel
isPhrasebook
isConfig
localeIdentifiers
isDownloading
isInstalled
canBePurged
translatesLanguagePair:
isCurrentlyAvailable
isCompatibleWithThisDevice
assetVersion
formatVersion
isNewerVersionThan:
isNewerCompatibleVersionThan:
requiredCapabilityIdentifier
isANEModel
matchesAsset:
downloadSize
_ltCompactMap:
_ltAttributedStringByTrimmingCharactersInSet:
sentences
T@"NSArray",R,N
_ltLocaleIdentifier
_ltCsLocaleIdentifier
_vsLocaleIdentifier
_ltEqual:
lt_realPath:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
error_code
reason
addObjectToBuffer:
_storage
_root
TI,R,N
session_message_immutableClassForType:
session_message_typeForImmutableObject:
session_message_type
session_messageAsFTStartPronGuessRequest
session_messageAsFTAudioPacket
session_messageAsFTFinishAudio
session_messageAsFTCancelRequest
session_messageAsFTPronGuessResponse
session_message
Tq,R,N
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
T@"FTPronGuessResponse",R,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
session_messageAsFTStartBatchRecoverRequest
session_messageAsFTBatchRecoverFinalResponse
T@"FTStartBatchRecoverRequest",R,N
T@"FTBatchRecoverFinalResponse",R,N
session_messageAsFTStartSpeechRequest
session_messageAsFTUpdateAudioInfo
session_messageAsFTSetRequestOrigin
session_messageAsFTSetSpeechContext
session_messageAsFTSetSpeechProfile
session_messageAsFTSetEndpointerState
session_messageAsFTResetServerEndpointer
session_messageAsFTCheckForSpeechRequest
session_messageAsFTSetAlternateRecognitionSausage
session_messageAsFTFinalSpeechRecognitionResponse
session_messageAsFTPartialSpeechRecognitionResponse
session_messageAsFTUpdatedAcousticProfile
session_messageAsFTEndPointLikelihood
session_messageAsFTEndPointCandidate
session_messageAsFTRecognitionProgress
session_messageAsFTCheckForSpeechResponse
session_messageAsFTRecognitionCandidate
session_messageAsFTRequestStatsResponse
session_messageAsFTServerEndpointFeatures
session_messageAsFTClientSetupInfo
session_messageAsFTAudioLimitExceeded
T@"FTStartSpeechRequest",R,N
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTServerEndpointFeatures",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
session_messageAsFTErrorBlamerRequest
session_messageAsFTErrorBlamerResponse
T@"FTErrorBlamerRequest",R,N
T@"FTErrorBlamerResponse",R,N
session_messageAsFTItnRequest
session_messageAsFTItnResponse
T@"FTItnRequest",R,N
T@"FTItnResponse",R,N
session_messageAsFTTextNormalizationRequest
session_messageAsFTTextNormalizationResponse
T@"FTTextNormalizationRequest",R,N
T@"FTTextNormalizationResponse",R,N
session_messageAsFTPostItnHammerRequest
session_messageAsFTPostItnHammerResponse
T@"FTPostItnHammerRequest",R,N
T@"FTPostItnHammerResponse",R,N
session_messageAsFTKeywordFinderRequest
session_messageAsFTKeywordFinderResponse
T@"FTKeywordFinderRequest",R,N
T@"FTKeywordFinderResponse",R,N
session_messageAsFTCorrectionsValidatorRequest
session_messageAsFTCorrectionsValidatorResponse
T@"FTCorrectionsValidatorRequest",R,N
T@"FTCorrectionsValidatorResponse",R,N
session_messageAsFTGraphemeToPhonemeRequest
session_messageAsFTGraphemeToPhonemeResponse
T@"FTGraphemeToPhonemeRequest",R,N
T@"FTGraphemeToPhonemeResponse",R,N
session_messageAsFTMultiUserStartSpeechRequest
session_messageAsFTFinalBlazarResponse
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
session_messageAsFTStartMultilingualSpeechRequest
session_messageAsFTLanguageDetected
T@"FTStartMultilingualSpeechRequest",R,N
T@"FTLanguageDetected",R,N
session_messageAsFTStartSpeechTranslationRequest
session_messageAsFTSpeechTranslationAudioPacket
session_messageAsFTStartSpeechTranslationLoggingRequest
session_messageAsFTSpeechTranslationPartialRecognitionResponse
session_messageAsFTSpeechTranslationFinalRecognitionResponse
session_messageAsFTSpeechTranslationMtResponse
session_messageAsFTSpeechTranslationTextToSpeechResponse
session_messageAsFTSpeechTranslationServerEndpointFeatures
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
session_messageAsFTBatchTranslationRequest
session_messageAsFTBatchTranslationFeedbackRequest
session_messageAsFTBatchTranslationLoggingRequest
session_messageAsFTTranslationSupportedLanguagesRequest
session_messageAsFTBatchTranslationResponse
session_messageAsFTTranslationSupportedLanguagesResponse
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationFeedbackRequest",R,N
T@"FTBatchTranslationLoggingRequest",R,N
T@"FTTranslationSupportedLanguagesRequest",R,N
T@"FTBatchTranslationResponse",R,N
T@"FTTranslationSupportedLanguagesResponse",R,N
session_messageAsFTTextToSpeechRequest
session_messageAsFTTextToSpeechResponse
T@"FTTextToSpeechRequest",R,N
T@"FTTextToSpeechResponse",R,N
session_messageAsFTStartTextToSpeechStreamingRequest
session_messageAsFTBeginTextToSpeechStreamingResponse
session_messageAsFTPartialTextToSpeechStreamingResponse
session_messageAsFTFinalTextToSpeechStreamingResponse
T@"FTStartTextToSpeechStreamingRequest",R,N
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
session_messageAsFTServiceDiscoveryRequest
session_messageAsFTServiceDiscoveryResponse
T@"FTServiceDiscoveryRequest",R,N
T@"FTServiceDiscoveryResponse",R,N
session_messageAsFTLmScorerRequest
session_messageAsFTLmScorerResponse
T@"FTLmScorerRequest",R,N
T@"FTLmScorerResponse",R,N
session_messageAsFTCreateLanguageProfileRequest
session_messageAsFTCreateLanguageProfileResponse
T@"FTCreateLanguageProfileRequest",R,N
T@"FTCreateLanguageProfileResponse",R,N
session_messageAsFTTranslationRequest
session_messageAsFTTranslationResponse
T@"FTTranslationRequest",R,N
T@"FTTranslationResponse",R,N
session_messageAsFTStreamingTranslationRequest
T@"FTStreamingTranslationRequest",R,N
session_messageAsFTQssAckResponse
T@"FTQssAckResponse",R,N
session_messageAsFTTextToSpeechSpeechFeatureRequest
session_messageAsFTTextToSpeechSpeechFeatureResponse
T@"FTTextToSpeechSpeechFeatureRequest",R,N
T@"FTTextToSpeechSpeechFeatureResponse",R,N
session_messageAsFTShortcutFuzzyMatchRequest
session_messageAsFTShortcutFuzzyMatchResponse
T@"FTShortcutFuzzyMatchRequest",R,N
T@"FTShortcutFuzzyMatchResponse",R,N
session_messageAsFTStartLanguageDetectionRequest
session_messageAsFTLanguageDetectionResponse
T@"FTStartLanguageDetectionRequest",R,N
T@"FTLanguageDetectionResponse",R,N
container_message_immutableClassForType:
container_message_typeForImmutableObject:
error_message
disable_session_log
container_message_type
container_messageAsFTApgPronGuessMessage
container_messageAsFTApgBatchRecoverMessage
container_messageAsFTAsrRecognitionMessage
container_messageAsFTAsrErrorBlamerMessage
container_messageAsFTAsrItnMessage
container_messageAsFTAsrTextNormalizationMessage
container_messageAsFTAsrPostItnHammerMessage
container_messageAsFTAsrKeywordFinderMessage
container_messageAsFTAsrCorrectionsValidatorMessage
container_messageAsFTAsrGraphemeToPhonemeMessage
container_messageAsFTBlazarMultiUserMessage
container_messageAsFTBlazarMultilingualMessage
container_messageAsFTBlazarSpeechTranslationMessage
container_messageAsFTBlazarBatchTranslationMessage
container_messageAsFTBlazarTextToSpeechRouterMessage
container_messageAsFTBlazarTextToSpeechRouterStreamingMessage
container_messageAsFTBlazarServiceDiscoveryMessage
container_messageAsFTLmtLmScorerMessage
container_messageAsFTNapgCreateLanguageProfileMessage
container_messageAsFTMtTranslationMessage
container_messageAsFTMtStreamingTranslationMessage
container_messageAsFTTtsTextToSpeechMessage
container_messageAsFTTtsTextToSpeechStreamingMessage
container_messageAsFTTtsTextToSpeechSpeechFeatureMessage
container_messageAsFTNlShortcutFuzzyMatchMessage
container_messageAsFTSlsLanguageDetectionMessage
container_message
T@"FTErrorMessage",R,N
T@"FTDisableSessionLog",R,N
T@"FTApgPronGuessMessage",R,N
T@"FTApgBatchRecoverMessage",R,N
T@"FTAsrRecognitionMessage",R,N
T@"FTAsrErrorBlamerMessage",R,N
T@"FTAsrItnMessage",R,N
T@"FTAsrTextNormalizationMessage",R,N
T@"FTAsrPostItnHammerMessage",R,N
T@"FTAsrKeywordFinderMessage",R,N
T@"FTAsrCorrectionsValidatorMessage",R,N
T@"FTAsrGraphemeToPhonemeMessage",R,N
T@"FTBlazarMultiUserMessage",R,N
T@"FTBlazarMultilingualMessage",R,N
T@"FTBlazarSpeechTranslationMessage",R,N
T@"FTBlazarBatchTranslationMessage",R,N
T@"FTBlazarTextToSpeechRouterMessage",R,N
T@"FTBlazarTextToSpeechRouterStreamingMessage",R,N
T@"FTBlazarServiceDiscoveryMessage",R,N
T@"FTLmtLmScorerMessage",R,N
T@"FTNapgCreateLanguageProfileMessage",R,N
T@"FTMtTranslationMessage",R,N
T@"FTMtStreamingTranslationMessage",R,N
T@"FTTtsTextToSpeechMessage",R,N
T@"FTTtsTextToSpeechStreamingMessage",R,N
T@"FTTtsTextToSpeechSpeechFeatureMessage",R,N
T@"FTNlShortcutFuzzyMatchMessage",R,N
T@"FTSlsLanguageDetectionMessage",R,N
setError_code:
setReason:
TI,N
T@"NSString",C,N
session_message_mutableClassForType:
session_message_typeForMutableObject:
session_message_typeForObject:
setSession_message_type:
setSession_messageAsFTStartPronGuessRequest:
setSession_messageAsFTAudioPacket:
setSession_messageAsFTFinishAudio:
setSession_messageAsFTCancelRequest:
setSession_messageAsFTPronGuessResponse:
setSession_message:
Tq,N
T@"FTStartPronGuessRequest",C,N
T@"FTAudioPacket",C,N
T@"FTFinishAudio",C,N
T@"FTCancelRequest",C,N
T@"FTPronGuessResponse",C,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
setSession_messageAsFTStartBatchRecoverRequest:
setSession_messageAsFTBatchRecoverFinalResponse:
T@"FTStartBatchRecoverRequest",C,N
T@"FTBatchRecoverFinalResponse",C,N
setSession_messageAsFTStartSpeechRequest:
setSession_messageAsFTUpdateAudioInfo:
setSession_messageAsFTSetRequestOrigin:
setSession_messageAsFTSetSpeechContext:
setSession_messageAsFTSetSpeechProfile:
setSession_messageAsFTSetEndpointerState:
setSession_messageAsFTResetServerEndpointer:
setSession_messageAsFTCheckForSpeechRequest:
setSession_messageAsFTSetAlternateRecognitionSausage:
setSession_messageAsFTFinalSpeechRecognitionResponse:
setSession_messageAsFTPartialSpeechRecognitionResponse:
setSession_messageAsFTUpdatedAcousticProfile:
setSession_messageAsFTEndPointLikelihood:
setSession_messageAsFTEndPointCandidate:
setSession_messageAsFTRecognitionProgress:
setSession_messageAsFTCheckForSpeechResponse:
setSession_messageAsFTRecognitionCandidate:
setSession_messageAsFTRequestStatsResponse:
setSession_messageAsFTServerEndpointFeatures:
setSession_messageAsFTClientSetupInfo:
setSession_messageAsFTAudioLimitExceeded:
T@"FTStartSpeechRequest",C,N
T@"FTUpdateAudioInfo",C,N
T@"FTSetRequestOrigin",C,N
T@"FTSetSpeechContext",C,N
T@"FTSetSpeechProfile",C,N
T@"FTSetEndpointerState",C,N
T@"FTResetServerEndpointer",C,N
T@"FTCheckForSpeechRequest",C,N
T@"FTSetAlternateRecognitionSausage",C,N
T@"FTFinalSpeechRecognitionResponse",C,N
T@"FTPartialSpeechRecognitionResponse",C,N
T@"FTUpdatedAcousticProfile",C,N
T@"FTEndPointLikelihood",C,N
T@"FTEndPointCandidate",C,N
T@"FTRecognitionProgress",C,N
T@"FTCheckForSpeechResponse",C,N
T@"FTRecognitionCandidate",C,N
T@"FTRequestStatsResponse",C,N
T@"FTServerEndpointFeatures",C,N
T@"FTClientSetupInfo",C,N
T@"FTAudioLimitExceeded",C,N
setSession_messageAsFTErrorBlamerRequest:
setSession_messageAsFTErrorBlamerResponse:
T@"FTErrorBlamerRequest",C,N
T@"FTErrorBlamerResponse",C,N
setSession_messageAsFTItnRequest:
setSession_messageAsFTItnResponse:
T@"FTItnRequest",C,N
T@"FTItnResponse",C,N
setSession_messageAsFTTextNormalizationRequest:
setSession_messageAsFTTextNormalizationResponse:
T@"FTTextNormalizationRequest",C,N
T@"FTTextNormalizationResponse",C,N
setSession_messageAsFTPostItnHammerRequest:
setSession_messageAsFTPostItnHammerResponse:
T@"FTPostItnHammerRequest",C,N
T@"FTPostItnHammerResponse",C,N
setSession_messageAsFTKeywordFinderRequest:
setSession_messageAsFTKeywordFinderResponse:
T@"FTKeywordFinderRequest",C,N
T@"FTKeywordFinderResponse",C,N
setSession_messageAsFTCorrectionsValidatorRequest:
setSession_messageAsFTCorrectionsValidatorResponse:
T@"FTCorrectionsValidatorRequest",C,N
T@"FTCorrectionsValidatorResponse",C,N
setSession_messageAsFTGraphemeToPhonemeRequest:
setSession_messageAsFTGraphemeToPhonemeResponse:
T@"FTGraphemeToPhonemeRequest",C,N
T@"FTGraphemeToPhonemeResponse",C,N
setSession_messageAsFTMultiUserStartSpeechRequest:
setSession_messageAsFTFinalBlazarResponse:
T@"FTMultiUserStartSpeechRequest",C,N
T@"FTFinalBlazarResponse",C,N
setSession_messageAsFTStartMultilingualSpeechRequest:
setSession_messageAsFTLanguageDetected:
T@"FTStartMultilingualSpeechRequest",C,N
T@"FTLanguageDetected",C,N
setSession_messageAsFTStartSpeechTranslationRequest:
setSession_messageAsFTSpeechTranslationAudioPacket:
setSession_messageAsFTStartSpeechTranslationLoggingRequest:
setSession_messageAsFTSpeechTranslationPartialRecognitionResponse:
setSession_messageAsFTSpeechTranslationFinalRecognitionResponse:
setSession_messageAsFTSpeechTranslationMtResponse:
setSession_messageAsFTSpeechTranslationTextToSpeechResponse:
setSession_messageAsFTSpeechTranslationServerEndpointFeatures:
T@"FTStartSpeechTranslationRequest",C,N
T@"FTSpeechTranslationAudioPacket",C,N
T@"FTStartSpeechTranslationLoggingRequest",C,N
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
T@"FTSpeechTranslationMtResponse",C,N
T@"FTSpeechTranslationTextToSpeechResponse",C,N
T@"FTSpeechTranslationServerEndpointFeatures",C,N
setSession_messageAsFTBatchTranslationRequest:
setSession_messageAsFTBatchTranslationFeedbackRequest:
setSession_messageAsFTBatchTranslationLoggingRequest:
setSession_messageAsFTTranslationSupportedLanguagesRequest:
setSession_messageAsFTBatchTranslationResponse:
setSession_messageAsFTTranslationSupportedLanguagesResponse:
T@"FTBatchTranslationRequest",C,N
T@"FTBatchTranslationFeedbackRequest",C,N
T@"FTBatchTranslationLoggingRequest",C,N
T@"FTTranslationSupportedLanguagesRequest",C,N
T@"FTBatchTranslationResponse",C,N
T@"FTTranslationSupportedLanguagesResponse",C,N
setSession_messageAsFTTextToSpeechRequest:
setSession_messageAsFTTextToSpeechResponse:
T@"FTTextToSpeechRequest",C,N
T@"FTTextToSpeechResponse",C,N
setSession_messageAsFTStartTextToSpeechStreamingRequest:
setSession_messageAsFTBeginTextToSpeechStreamingResponse:
setSession_messageAsFTPartialTextToSpeechStreamingResponse:
setSession_messageAsFTFinalTextToSpeechStreamingResponse:
T@"FTStartTextToSpeechStreamingRequest",C,N
T@"FTBeginTextToSpeechStreamingResponse",C,N
T@"FTPartialTextToSpeechStreamingResponse",C,N
T@"FTFinalTextToSpeechStreamingResponse",C,N
setSession_messageAsFTServiceDiscoveryRequest:
setSession_messageAsFTServiceDiscoveryResponse:
T@"FTServiceDiscoveryRequest",C,N
T@"FTServiceDiscoveryResponse",C,N
setSession_messageAsFTLmScorerRequest:
setSession_messageAsFTLmScorerResponse:
T@"FTLmScorerRequest",C,N
T@"FTLmScorerResponse",C,N
setSession_messageAsFTCreateLanguageProfileRequest:
setSession_messageAsFTCreateLanguageProfileResponse:
T@"FTCreateLanguageProfileRequest",C,N
T@"FTCreateLanguageProfileResponse",C,N
setSession_messageAsFTTranslationRequest:
setSession_messageAsFTTranslationResponse:
T@"FTTranslationRequest",C,N
T@"FTTranslationResponse",C,N
setSession_messageAsFTStreamingTranslationRequest:
T@"FTStreamingTranslationRequest",C,N
setSession_messageAsFTQssAckResponse:
T@"FTQssAckResponse",C,N
setSession_messageAsFTTextToSpeechSpeechFeatureRequest:
setSession_messageAsFTTextToSpeechSpeechFeatureResponse:
T@"FTTextToSpeechSpeechFeatureRequest",C,N
T@"FTTextToSpeechSpeechFeatureResponse",C,N
setSession_messageAsFTShortcutFuzzyMatchRequest:
setSession_messageAsFTShortcutFuzzyMatchResponse:
T@"FTShortcutFuzzyMatchRequest",C,N
T@"FTShortcutFuzzyMatchResponse",C,N
setSession_messageAsFTStartLanguageDetectionRequest:
setSession_messageAsFTLanguageDetectionResponse:
T@"FTStartLanguageDetectionRequest",C,N
T@"FTLanguageDetectionResponse",C,N
container_message_mutableClassForType:
container_message_typeForMutableObject:
container_message_typeForObject:
setError_message:
setDisable_session_log:
setContainer_message_type:
setContainer_messageAsFTApgPronGuessMessage:
setContainer_messageAsFTApgBatchRecoverMessage:
setContainer_messageAsFTAsrRecognitionMessage:
setContainer_messageAsFTAsrErrorBlamerMessage:
setContainer_messageAsFTAsrItnMessage:
setContainer_messageAsFTAsrTextNormalizationMessage:
setContainer_messageAsFTAsrPostItnHammerMessage:
setContainer_messageAsFTAsrKeywordFinderMessage:
setContainer_messageAsFTAsrCorrectionsValidatorMessage:
setContainer_messageAsFTAsrGraphemeToPhonemeMessage:
setContainer_messageAsFTBlazarMultiUserMessage:
setContainer_messageAsFTBlazarMultilingualMessage:
setContainer_messageAsFTBlazarSpeechTranslationMessage:
setContainer_messageAsFTBlazarBatchTranslationMessage:
setContainer_messageAsFTBlazarTextToSpeechRouterMessage:
setContainer_messageAsFTBlazarTextToSpeechRouterStreamingMessage:
setContainer_messageAsFTBlazarServiceDiscoveryMessage:
setContainer_messageAsFTLmtLmScorerMessage:
setContainer_messageAsFTNapgCreateLanguageProfileMessage:
setContainer_messageAsFTMtTranslationMessage:
setContainer_messageAsFTMtStreamingTranslationMessage:
setContainer_messageAsFTTtsTextToSpeechMessage:
setContainer_messageAsFTTtsTextToSpeechStreamingMessage:
setContainer_messageAsFTTtsTextToSpeechSpeechFeatureMessage:
setContainer_messageAsFTNlShortcutFuzzyMatchMessage:
setContainer_messageAsFTSlsLanguageDetectionMessage:
setContainer_message:
T@"FTErrorMessage",C,N
T@"FTDisableSessionLog",C,N
T@"FTApgPronGuessMessage",C,N
T@"FTApgBatchRecoverMessage",C,N
T@"FTAsrRecognitionMessage",C,N
T@"FTAsrErrorBlamerMessage",C,N
T@"FTAsrItnMessage",C,N
T@"FTAsrTextNormalizationMessage",C,N
T@"FTAsrPostItnHammerMessage",C,N
T@"FTAsrKeywordFinderMessage",C,N
T@"FTAsrCorrectionsValidatorMessage",C,N
T@"FTAsrGraphemeToPhonemeMessage",C,N
T@"FTBlazarMultiUserMessage",C,N
T@"FTBlazarMultilingualMessage",C,N
T@"FTBlazarSpeechTranslationMessage",C,N
T@"FTBlazarBatchTranslationMessage",C,N
T@"FTBlazarTextToSpeechRouterMessage",C,N
T@"FTBlazarTextToSpeechRouterStreamingMessage",C,N
T@"FTBlazarServiceDiscoveryMessage",C,N
T@"FTLmtLmScorerMessage",C,N
T@"FTNapgCreateLanguageProfileMessage",C,N
T@"FTMtTranslationMessage",C,N
T@"FTMtStreamingTranslationMessage",C,N
T@"FTTtsTextToSpeechMessage",C,N
T@"FTTtsTextToSpeechStreamingMessage",C,N
T@"FTTtsTextToSpeechSpeechFeatureMessage",C,N
T@"FTNlShortcutFuzzyMatchMessage",C,N
T@"FTSlsLanguageDetectionMessage",C,N
profile_blob
profile_blob:
profile_blob_version
profile_checksum
T@"NSData",R,N
acoustic_profile_version
acoustic_profile_blob
acoustic_profile_blob:
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
add_space_after
phone_seq
ipa_phone_seq
Ti,R,N
tokens_objectAtIndex:
tokens_count
tokens_enumerateObjectsUsingBlock:
tok_phrases
tok_phrases_objectAtIndex:
tok_phrases_count
tok_phrases_enumerateObjectsUsingBlock:
has_unsuggested_alternatives
positional_tok_phrase_alt
positional_tok_phrase_alt_objectAtIndex:
positional_tok_phrase_alt_count
positional_tok_phrase_alt_enumerateObjectsUsingBlock:
alternative_index
alternative_index_objectAtIndex:
alternative_index_count
alternative_index_enumerateObjectsUsingBlock:
itn_alignment
itn_alignment_objectAtIndex:
itn_alignment_count
itn_alignment_enumerateObjectsUsingBlock:
post_itn_choice_indices
post_itn_choice_indices_objectAtIndex:
post_itn_choice_indices_count
post_itn_choice_indices_enumerateObjectsUsingBlock:
pre_itn_token_to_post_itn_char_alignments
pre_itn_token_to_post_itn_char_alignments_objectAtIndex:
pre_itn_token_to_post_itn_char_alignments_count
pre_itn_token_to_post_itn_char_alignments_enumerateObjectsUsingBlock:
pre_itn
post_itn
pre_itn_nbest_choices
pre_itn_nbest_choices_objectAtIndex:
pre_itn_nbest_choices_count
pre_itn_nbest_choices_enumerateObjectsUsingBlock:
post_itn_nbest_choices
post_itn_nbest_choices_objectAtIndex:
post_itn_nbest_choices_count
post_itn_nbest_choices_enumerateObjectsUsingBlock:
pre_itn_token_to_post_itn_char_alignment
pre_itn_token_to_post_itn_char_alignment_objectAtIndex:
pre_itn_token_to_post_itn_char_alignment_count
pre_itn_token_to_post_itn_char_alignment_enumerateObjectsUsingBlock:
choice_alignments
choice_alignments_objectAtIndex:
choice_alignments_count
choice_alignments_enumerateObjectsUsingBlock:
T@"FTRecognitionSausage",R,N
bool_stats
bool_stats_objectAtIndex:
bool_stats_count
bool_stats_enumerateObjectsUsingBlock:
int32_stats
int32_stats_objectAtIndex:
int32_stats_count
int32_stats_enumerateObjectsUsingBlock:
double_stats
double_stats_objectAtIndex:
double_stats_count
double_stats_enumerateObjectsUsingBlock:
speech_id
request_locale
name
value
Td,R,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
acoustic_feature_per_frame
acoustic_feature_per_frame_objectAtIndex:
acoustic_feature_per_frame_count
acoustic_feature_per_frame_enumerateObjectsUsingBlock:
frame_duration
Tf,R,N
speech_recognition_features
speech_recognition_features_objectAtIndex:
speech_recognition_features_count
speech_recognition_features_enumerateObjectsUsingBlock:
acoustic_features
acoustic_features_objectAtIndex:
acoustic_features_count
acoustic_features_enumerateObjectsUsingBlock:
T@"FTAcousticFeature",R,N
session_id
return_code
return_str
recognition_result
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,R,N
start_speech_request
user_parameters
user_parameters_objectAtIndex:
user_parameters_count
user_parameters_enumerateObjectsUsingBlock:
primary_speech_id
product_id
vendor_id
contextual_text
pron_hints
pron_hints_objectAtIndex:
pron_hints_count
pron_hints_enumerateObjectsUsingBlock:
contextual_text_objectAtIndex:
contextual_text_count
contextual_text_enumerateObjectsUsingBlock:
left_context
right_context
context_with_pron_hints
context_with_pron_hints_objectAtIndex:
context_with_pron_hints_count
context_with_pron_hints_enumerateObjectsUsingBlock:
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
audio_bytes
audio_bytes:
packet_count
total_audio_recorded_seconds
features_at_endpoint
features_at_endpoint_objectAtIndex:
features_at_endpoint_count
features_at_endpoint_enumerateObjectsUsingBlock:
server_feature_latency_distribution
server_feature_latency_distribution_objectAtIndex:
server_feature_latency_distribution_count
server_feature_latency_distribution_enumerateObjectsUsingBlock:
updated_acoustic_profile
orthography
pronunciations
pronunciations:
frequency
attributes
attributes_objectAtIndex:
attributes_count
attributes_enumerateObjectsUsingBlock:
category_name
category_data
category_data_objectAtIndex:
category_data_count
category_data_enumerateObjectsUsingBlock:
user_data
user_data_objectAtIndex:
user_data_count
user_data_enumerateObjectsUsingBlock:
error_str
incomplete_profile
recreate_apg_prons
phonemes
blob
blob:
apg_id
voc_token
tts_pronunciations
tts_pronunciations_objectAtIndex:
tts_pronunciations_count
tts_pronunciations_enumerateObjectsUsingBlock:
human_readable_prons
human_readable_prons_objectAtIndex:
human_readable_prons_count
human_readable_prons_enumerateObjectsUsingBlock:
T@"FTVocToken",R,N
apg_ids
apg_ids_objectAtIndex:
apg_ids_count
apg_ids_enumerateObjectsUsingBlock:
recovery_return_codes
recovery_return_codes_objectAtIndex:
recovery_return_codes_count
recovery_return_codes_enumerateObjectsUsingBlock:
voc_tokens
voc_tokens_objectAtIndex:
voc_tokens_count
voc_tokens_enumerateObjectsUsingBlock:
num_of_requested
num_of_processed
num_of_succeeded
words_list
words_list_objectAtIndex:
words_list_count
words_list_enumerateObjectsUsingBlock:
formatted_words_list
formatted_words_list_objectAtIndex:
formatted_words_list_count
formatted_words_list_enumerateObjectsUsingBlock:
post_itn_string
nbest_variants_max
normalized_tokens
normalized_tokens_objectAtIndex:
normalized_tokens_count
normalized_tokens_enumerateObjectsUsingBlock:
original_token
nbest_variants
nbest_variants_objectAtIndex:
nbest_variants_count
nbest_variants_enumerateObjectsUsingBlock:
pron_sequence
log_weight
pron_source
sanitized_sequences
sanitized_sequences_objectAtIndex:
sanitized_sequences_count
sanitized_sequences_enumerateObjectsUsingBlock:
prons
prons_objectAtIndex:
prons_count
prons_enumerateObjectsUsingBlock:
normalized_prons
normalized_prons_objectAtIndex:
normalized_prons_count
normalized_prons_enumerateObjectsUsingBlock:
sanitized_tokens
sanitized_tokens_objectAtIndex:
sanitized_tokens_count
sanitized_tokens_enumerateObjectsUsingBlock:
T@"FTContextWithPronHints",R,N
phonemes_objectAtIndex:
phonemes_count
phonemes_enumerateObjectsUsingBlock:
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
aot_token_prons_objectAtIndex:
aot_token_prons_count
aot_token_prons_enumerateObjectsUsingBlock:
jit_token_prons
jit_token_prons_objectAtIndex:
jit_token_prons_count
jit_token_prons_enumerateObjectsUsingBlock:
index
index_objectAtIndex:
index_count
index_enumerateObjectsUsingBlock:
start_index
end_index
do_not_translate
meta_info
span
span_objectAtIndex:
span_count
span_enumerateObjectsUsingBlock:
raw_sausage
raw_nbest_choices
raw_nbest_choices_objectAtIndex:
raw_nbest_choices_count
raw_nbest_choices_enumerateObjectsUsingBlock:
post_itn_tokens
post_itn_tokens_objectAtIndex:
post_itn_tokens_count
post_itn_tokens_enumerateObjectsUsingBlock:
post_itn_recognition
itn_alignments
itn_alignments_objectAtIndex:
itn_alignments_count
itn_alignments_enumerateObjectsUsingBlock:
translation_phrase
translation_phrase_objectAtIndex:
translation_phrase_count
translation_phrase_enumerateObjectsUsingBlock:
pre_itn_payload
post_itn_payload
pre_sausage_payload
spans_objectAtIndex:
spans_count
spans_enumerateObjectsUsingBlock:
request_id
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
app_id
use_case
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
translation_text
final_message
return_string
n_best_translated_phrases
n_best_translated_phrases_objectAtIndex:
n_best_translated_phrases_count
n_best_translated_phrases_enumerateObjectsUsingBlock:
engine_input
engine_output
engine_output_objectAtIndex:
engine_output_count
engine_output_enumerateObjectsUsingBlock:
mt_alignment
T@"FTAlignment",R,N
translated_tokens
translated_tokens_objectAtIndex:
translated_tokens_count
translated_tokens_enumerateObjectsUsingBlock:
low_confidence
meta_info_data
T@"FTTranslationPhraseMetaInfo",R,N
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
calibration_scale
calibration_offset
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets
audio_packets_objectAtIndex:
audio_packets_count
audio_packets_enumerateObjectsUsingBlock:
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
keyword_orthography
posterior
keywords
keywords_objectAtIndex:
keywords_count
keywords_enumerateObjectsUsingBlock:
enable_sanitization
corrected_sausage
n_best_list
n_best_list_objectAtIndex:
n_best_list_count
n_best_list_enumerateObjectsUsingBlock:
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
pause_counts_objectAtIndex:
pause_counts_count
pause_counts_enumerateObjectsUsingBlock:
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
corrections
corrections_objectAtIndex:
corrections_count
corrections_enumerateObjectsUsingBlock:
fe_feature
fe_feature_only
disable_prompts
cache_only
phoneset_type
gender
quality
type
voice
resource
server_info
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
T@"FTQSSVersionInfo",R,N
channel_type
is_synthesis
context_info
context_info_objectAtIndex:
context_info_count
context_info_enumerateObjectsUsingBlock:
dialog_identifier
experiment_identifier
word_phonemes
word_phonemes_objectAtIndex:
word_phonemes_count
word_phonemes_enumerateObjectsUsingBlock:
prompts
prompts_objectAtIndex:
prompts_count
prompts_enumerateObjectsUsingBlock:
prompts_v2
prompts_v2:
original
replacement
normalized_text
normalized_text_objectAtIndex:
normalized_text_count
normalized_text_enumerateObjectsUsingBlock:
phoneme_sequence
phoneme_sequence_objectAtIndex:
phoneme_sequence_count
phoneme_sequence_enumerateObjectsUsingBlock:
replacement_objectAtIndex:
replacement_count
replacement_enumerateObjectsUsingBlock:
neural_phoneme_sequence
neural_phoneme_sequence_objectAtIndex:
neural_phoneme_sequence_count
neural_phoneme_sequence_enumerateObjectsUsingBlock:
force_use_tts_service
disable_cache
data:
resources
resources_objectAtIndex:
resources_count
resources_enumerateObjectsUsingBlock:
return_log
voice_asset_path
resource_asset_path
return_server_info
has_click
worker_process_type
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTTextToSpeechRequestDebug",R,N
T@"FTTextToSpeechUserProfile",R,N
T@"FTTextToSpeechRequestDevConfig",R,N
T@"FTTextToSpeechRequestProsodyTransferConfig",R,N
T@"FTTextToSpeechRequestProsodyControlConfig",R,N
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
T@"FTTextToSpeechSpeechFeatureInputWave",R,N
T@"FTTextToSpeechUserVoiceProfile",R,N
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
sample_idx
audio
audio:
decoder_description
playback_description
word_timing_info
word_timing_info_objectAtIndex:
word_timing_info_count
word_timing_info_enumerateObjectsUsingBlock:
feature
dev_data
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
T@"FTTextToSpeechResponseDevData",R,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_meta_info
cache_object
cache_object_objectAtIndex:
cache_object_count
cache_object_enumerateObjectsUsingBlock:
T@"FTTextToSpeechCacheMetaInfo",R,N
cached_request
cached_response
cached_begin_response
cached_partial_response
cached_partial_response_objectAtIndex:
cached_partial_response_count
cached_partial_response_enumerateObjectsUsingBlock:
cached_final_response
words
words_objectAtIndex:
words_count
words_enumerateObjectsUsingBlock:
pcm_data
pcm_data:
phone_name
begin_time
end_time
duration
pitch
energy
phonemeseq
phonemeseq_objectAtIndex:
phonemeseq_count
phonemeseq_enumerateObjectsUsingBlock:
model_id
lexicon
lexicon_objectAtIndex:
lexicon_count
lexicon_enumerateObjectsUsingBlock:
support_homograph
T@"FTTextToSpeechSpeechFeatureModelIdentifier",R,N
T@"FTTextToSpeechSpeechFeatureInputText",R,N
T@"FTTextToSpeechSpeechFeatureInputPhonemeSequence",R,N
features
features_objectAtIndex:
features_count
features_enumerateObjectsUsingBlock:
endpoint_threshold
endpoint_extra_delay
zk_path
zk_node
zk_node_objectAtIndex:
zk_node_count
zk_node_enumerateObjectsUsingBlock:
audio_frames
audio_frames_objectAtIndex:
audio_frames_count
audio_frames_enumerateObjectsUsingBlock:
source_locale
target_locale
conversation_id
translation_locale_pairs
translation_locale_pairs_objectAtIndex:
translation_locale_pairs_count
translation_locale_pairs_enumerateObjectsUsingBlock:
translation_request
text_to_speech_requests
text_to_speech_requests_objectAtIndex:
text_to_speech_requests_count
text_to_speech_requests_enumerateObjectsUsingBlock:
restricted_mode
streaming_mode
translation_locale_pair
detected_locale
user_selected_locale
senses_objectAtIndex:
senses_count
senses_enumerateObjectsUsingBlock:
user_selected_sense
user_interacted_senses
user_interacted_senses_objectAtIndex:
user_interacted_senses_count
user_interacted_senses_enumerateObjectsUsingBlock:
T@"FTTranslationLocalePair",R,N
is_final
text_to_speech_response
server_endpoint_features
utterance
shortcuts
shortcuts_objectAtIndex:
shortcuts_count
shortcuts_enumerateObjectsUsingBlock:
interaction_id
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
raw_string
shortcut_score_pairs
shortcut_score_pairs_objectAtIndex:
shortcut_score_pairs_count
shortcut_score_pairs_enumerateObjectsUsingBlock:
shortcut
similarity_score
language_parameters_by_id
language_parameters_by_id_objectAtIndex:
language_parameters_by_id_count
language_parameters_by_id_enumerateObjectsUsingBlock:
is_low_confidence
predictions
predictions_objectAtIndex:
predictions_count
predictions_enumerateObjectsUsingBlock:
paragraphs_objectAtIndex:
paragraphs_count
paragraphs_enumerateObjectsUsingBlock:
paragraph_id
source_content
translated_content
errors
safari_version
os_version
time_to_first_response
time_to_viewport_complete
time_to_page_complete
translated_text
translated_sentences
translated_sentences_objectAtIndex:
translated_sentences_count
translated_sentences_enumerateObjectsUsingBlock:
repeated_spans
repeated_spans_objectAtIndex:
repeated_spans_count
repeated_spans_enumerateObjectsUsingBlock:
source_span
target_span
n_best_choices
n_best_choices_objectAtIndex:
n_best_choices_count
n_best_choices_enumerateObjectsUsingBlock:
T@"FTSpan",R,N
sentence_count
language_pairs
language_pairs_objectAtIndex:
language_pairs_count
language_pairs_enumerateObjectsUsingBlock:
locales_objectAtIndex:
locales_count
locales_enumerateObjectsUsingBlock:
qss_version_server
qss_version_brane
qss_version_serverkit
qss_version_siritts
setProfile_blob:
setProfile_blob_version:
setProfile_checksum:
T@"NSData",C,N
setAcoustic_profile_version:
setAcoustic_profile_blob:
setToken_text:
setStart_milli_seconds:
setEnd_milli_seconds:
setSilence_start_milli_seconds:
setAdd_space_after:
setPhone_seq:
setIpa_phone_seq:
Ti,N
TB,N
T@"NSArray",C,N
setTok_phrases:
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
setItn_alignment:
setPost_itn_choice_indices:
setPre_itn_token_to_post_itn_char_alignments:
setPre_itn:
setPost_itn:
setPre_itn_nbest_choices:
setPost_itn_nbest_choices:
setPre_itn_token_to_post_itn_char_alignment:
setChoice_alignments:
T@"FTRecognitionSausage",C,N
setBool_stats:
setInt32_stats:
setDouble_stats:
setLanguage:
setSpeech_id:
setRequest_locale:
setName:
setValue:
Td,N
setFirst_pre_itn_token_index:
setLast_pre_itn_token_index:
setFirst_post_itn_char_pos:
setLast_post_itn_char_pos:
setAcoustic_feature_per_frame:
setFrame_duration:
Tf,N
setSpeech_recognition_features:
setAcoustic_features:
setKey:
T@"FTAcousticFeature",C,N
setSession_id:
setReturn_code:
setReturn_str:
setRecognition_result:
setLang_profile_recreate_codes:
setAudio_analytics:
setWatermark_detection:
setWatermark_peak_average:
setLatnn_mitigator_result:
setHas_result:
T@"FTRecognitionResult",C,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
setRecognition_text:
setIs_stable_result:
setAudio_duration_ms:
setTask_name:
setCodec:
setStream_results:
setEnable_server_side_endpoint:
setDevice_type:
setDevice_os:
setMic_type:
setUdm_host:
setUdm_port:
setTandem_mode:
setStore_audio:
setStream_unstable_results:
setEnd_point_mode:
setStart_audio_bookmark:
setIs_far_field:
setEnable_utterance_detection:
setEnable_endpoint_candidate:
setStart_recognition_at:
setStart_endpointing_at:
setEnable_hybrid_endpoint:
setClient_endpointer_model_version:
setKeyboard_identifier:
setInput_origin:
setInitial_recognition_candidate_id:
setDisable_auto_punctuation:
setKeyboard_dictation:
setExperiment_id:
setSpeech_request_source:
setFork_id:
setApplication_name:
setMetadata:
TQ,N
setStart_speech_request:
setUser_parameters:
setPrimary_speech_id:
setProduct_id:
setVendor_id:
setContextual_text:
setPron_hints:
setLeft_context:
setRight_context:
setContext_with_pron_hints:
setUser_language_profile:
setUser_acoustic_profile:
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
setAudio_bytes:
setPacket_count:
setTotal_audio_recorded_seconds:
setFeatures_at_endpoint:
setServer_feature_latency_distribution:
setUpdated_acoustic_profile:
setOrthography:
setPronunciations:
setFrequency:
setTag:
setAttributes:
setCategory_name:
setCategory_data:
setUser_data:
setError_str:
setIncomplete_profile:
setRecreate_apg_prons:
setPhonemes:
setBlob:
setApg_id:
setVoc_token:
setTts_pronunciations:
setHuman_readable_prons:
T@"FTVocToken",C,N
setApg_ids:
setRecovery_return_codes:
setVoc_tokens:
setNum_of_requested:
setNum_of_processed:
setNum_of_succeeded:
setWords_list:
setFormatted_words_list:
setPost_itn_string:
setNbest_variants_max:
setNormalized_tokens:
setOriginal_token:
setNbest_variants:
setPron_sequence:
setLog_weight:
setPron_source:
setSanitized_sequences:
setProns:
setNormalized_prons:
setSanitized_tokens:
T@"FTContextWithPronHints",C,N
setIs_pron_guessed:
setG2p_version:
setG2p_model_version:
setPhoneset_version:
setAot_token_prons:
setJit_token_prons:
setIndex:
setStart_index:
setEnd_index:
setDo_not_translate:
setMeta_info:
setSpan:
setRaw_sausage:
setRaw_nbest_choices:
setPost_itn_tokens:
setPost_itn_recognition:
setItn_alignments:
setTranslation_phrase:
setPre_itn_payload:
setPost_itn_payload:
setPre_sausage_payload:
setSpans:
setRequest_id:
setSource_language:
setTarget_language:
setSiri_translation_info:
setSpeech_translation_info:
setSiri_payload_translation_info:
setSequence_id:
setWeb_translation_info:
setDisable_log:
setOpt_in_status:
setApp_id:
setUse_case:
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
setTranslation_text:
setFinal_message:
setReturn_string:
setN_best_translated_phrases:
setEngine_input:
setEngine_output:
setMt_alignment:
T@"FTAlignment",C,N
setTranslated_tokens:
setLow_confidence:
setMeta_info_data:
T@"FTTranslationPhraseMetaInfo",C,N
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
setLatitude:
setLongitude:
setEnable_geo_location_features:
setSpeech_packet_count:
setProcessed:
setVersion:
setThreshold:
setScore:
setCalibration_scale:
setCalibration_offset:
setResult_id:
setSnr:
setFingerprint_detection:
setStart_speech_time:
setEnd_speech_time:
setSpeech_detected:
setAudio_packets:
setRef_transcript:
setBlamer_report:
setToken_str:
setLog10_score:
setNgram_used:
setTranscript:
setPpl:
setKeyword_orthography:
setPosterior:
setKeywords:
setEnable_sanitization:
setCorrected_sausage:
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
setOriginal_utterance:
setCorrected_utterance:
setOriginal_words:
setCorrected_words:
setCorrections:
setFe_feature:
setFe_feature_only:
setDisable_prompts:
setCache_only:
setPhoneset_type:
setGender:
setQuality:
setType:
setVoice:
setResource:
setServer_info:
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
T@"FTQSSVersionInfo",C,N
setChannel_type:
setIs_synthesis:
setContext_info:
setDialog_identifier:
setExperiment_identifier:
setWord_phonemes:
setPrompts:
setPrompts_v2:
setOriginal:
setReplacement:
setNormalized_text:
setPhoneme_sequence:
setNeural_phoneme_sequence:
setForce_use_tts_service:
setDisable_cache:
setResources:
setReturn_log:
setVoice_asset_path:
setResource_asset_path:
setReturn_server_info:
setLog:
setHas_click:
setWorker_process_type:
setGlobal_rate:
setGlobal_pitch:
setGlobal_energy:
setGlobal_sent_pitch:
setGlobal_sent_pitchrange:
setGlobal_sent_duration:
setGlobal_sent_energy:
setGlobal_sent_tilt:
setAudio_type:
setEnable_word_timing_info:
setVoice_name:
setPreferred_voice_type:
setContext:
setExperiment:
setFeature_flags:
setDebug:
setProfile:
setDev_config:
setProsody_config:
setProsody_control_config:
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
T@"FTTextToSpeechRequestDebug",C,N
T@"FTTextToSpeechUserProfile",C,N
T@"FTTextToSpeechRequestDevConfig",C,N
T@"FTTextToSpeechRequestProsodyTransferConfig",C,N
T@"FTTextToSpeechRequestProsodyControlConfig",C,N
setPitch_mean:
setPitch_std:
setEnergy_mean:
setEnergy_std:
setDuration_mean:
setDuration_std:
setWave_data:
setUser_voice_profile:
setUser_voice_profile_url:
T@"FTTextToSpeechSpeechFeatureInputWave",C,N
T@"FTTextToSpeechUserVoiceProfile",C,N
setSample_rate:
setFormat_id:
setFormat_flags:
setBytes_per_packet:
setFrames_per_packet:
setBytes_per_frame:
setChannels_per_frame:
setBits_per_channel:
setReserved:
setWord:
setSample_idx:
setOffset:
setLength:
setTimestamp:
setAudio:
setDecoder_description:
setPlayback_description:
setWord_timing_info:
setFeature:
setDev_data:
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
T@"FTTextToSpeechResponseDevData",C,N
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setCurrent_pkt_number:
setTotal_pkt_number:
setAudio_length:
setOriginal_session_id:
setCache_meta_info:
setCache_object:
T@"FTTextToSpeechCacheMetaInfo",C,N
setCached_request:
setCached_response:
setCached_begin_response:
setCached_partial_response:
setCached_final_response:
setWords:
setPcm_data:
setPhone_name:
setBegin_time:
setEnd_time:
setDuration:
setPitch:
setEnergy:
setPhonemeseq:
setModel_id:
setLexicon:
setSupport_homograph:
T@"FTTextToSpeechSpeechFeatureModelIdentifier",C,N
T@"FTTextToSpeechSpeechFeatureInputText",C,N
T@"FTTextToSpeechSpeechFeatureInputPhonemeSequence",C,N
setFeatures:
setEndpoint_threshold:
setEndpoint_extra_delay:
setZk_path:
setZk_node:
setAudio_frames:
setSource_locale:
setTarget_locale:
setConversation_id:
setTranslation_locale_pairs:
setTranslation_request:
setText_to_speech_requests:
setRestricted_mode:
setStreaming_mode:
setTranslation_locale_pair:
setDetected_locale:
setUser_selected_locale:
setUser_selected_sense:
setUser_interacted_senses:
T@"FTTranslationLocalePair",C,N
setIs_final:
setText_to_speech_response:
setServer_endpoint_features:
setUtterance:
setShortcuts:
setInteraction_id:
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
setRaw_string:
setShortcut_score_pairs:
setShortcut:
setSimilarity_score:
setLanguage_parameters_by_id:
setIs_low_confidence:
setPredictions:
setUrl:
setParagraph_id:
setSource_content:
setTranslated_content:
setErrors:
setSafari_version:
setOs_version:
setTime_to_first_response:
setTime_to_viewport_complete:
setTime_to_page_complete:
setTranslated_text:
setTranslated_sentences:
setRepeated_spans:
setSource_span:
setTarget_span:
setN_best_choices:
T@"FTSpan",C,N
setSentence_count:
setLanguage_pairs:
setQss_version_server:
setQss_version_brane:
setQss_version_serverkit:
setQss_version_siritts:
content_immutableClassForType:
content_typeForImmutableObject:
content_type
contentAsFTStartPronGuessRequest
contentAsFTAudioPacket
contentAsFTFinishAudio
contentAsFTCancelRequest
content
contentAsFTPronGuessResponse
contentAsFTStartBatchRecoverRequest
contentAsFTBatchRecoverFinalResponse
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
contentAsFTSetRequestOrigin
contentAsFTSetSpeechContext
contentAsFTSetSpeechProfile
contentAsFTSetEndpointerState
contentAsFTResetServerEndpointer
contentAsFTCheckForSpeechRequest
contentAsFTSetAlternateRecognitionSausage
contentAsFTFinalSpeechRecognitionResponse
contentAsFTPartialSpeechRecognitionResponse
contentAsFTUpdatedAcousticProfile
contentAsFTEndPointLikelihood
contentAsFTEndPointCandidate
contentAsFTRecognitionProgress
contentAsFTCheckForSpeechResponse
contentAsFTRecognitionCandidate
contentAsFTRequestStatsResponse
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
contentAsFTAudioLimitExceeded
contentAsFTMultiUserStartSpeechRequest
contentAsFTFinalBlazarResponse
contentAsFTStartMultilingualSpeechRequest
contentAsFTLanguageDetected
contentAsFTStartSpeechTranslationRequest
contentAsFTSpeechTranslationAudioPacket
contentAsFTStartSpeechTranslationLoggingRequest
contentAsFTSpeechTranslationPartialRecognitionResponse
contentAsFTSpeechTranslationFinalRecognitionResponse
contentAsFTSpeechTranslationMtResponse
contentAsFTSpeechTranslationTextToSpeechResponse
contentAsFTSpeechTranslationServerEndpointFeatures
contentAsFTBatchTranslationRequest
contentAsFTBatchTranslationFeedbackRequest
contentAsFTBatchTranslationLoggingRequest
contentAsFTTranslationSupportedLanguagesRequest
contentAsFTBatchTranslationResponse
contentAsFTTranslationSupportedLanguagesResponse
contentAsFTStartTextToSpeechStreamingRequest
contentAsFTBeginTextToSpeechStreamingResponse
contentAsFTPartialTextToSpeechStreamingResponse
contentAsFTFinalTextToSpeechStreamingResponse
contentAsFTStreamingTranslationRequest
contentAsFTTranslationResponse
contentAsFTQssAckResponse
contentAsFTStartLanguageDetectionRequest
contentAsFTLanguageDetectionResponse
content_mutableClassForType:
content_typeForMutableObject:
content_typeForObject:
setContent_type:
setContentAsFTStartPronGuessRequest:
setContentAsFTAudioPacket:
setContentAsFTFinishAudio:
setContentAsFTCancelRequest:
setContent:
setContentAsFTPronGuessResponse:
setContentAsFTStartBatchRecoverRequest:
setContentAsFTBatchRecoverFinalResponse:
setContentAsFTStartSpeechRequest:
setContentAsFTUpdateAudioInfo:
setContentAsFTSetRequestOrigin:
setContentAsFTSetSpeechContext:
setContentAsFTSetSpeechProfile:
setContentAsFTSetEndpointerState:
setContentAsFTResetServerEndpointer:
setContentAsFTCheckForSpeechRequest:
setContentAsFTSetAlternateRecognitionSausage:
setContentAsFTFinalSpeechRecognitionResponse:
setContentAsFTPartialSpeechRecognitionResponse:
setContentAsFTUpdatedAcousticProfile:
setContentAsFTEndPointLikelihood:
setContentAsFTEndPointCandidate:
setContentAsFTRecognitionProgress:
setContentAsFTCheckForSpeechResponse:
setContentAsFTRecognitionCandidate:
setContentAsFTRequestStatsResponse:
setContentAsFTServerEndpointFeatures:
setContentAsFTClientSetupInfo:
setContentAsFTAudioLimitExceeded:
setContentAsFTMultiUserStartSpeechRequest:
setContentAsFTFinalBlazarResponse:
setContentAsFTStartMultilingualSpeechRequest:
setContentAsFTLanguageDetected:
setContentAsFTStartSpeechTranslationRequest:
setContentAsFTSpeechTranslationAudioPacket:
setContentAsFTStartSpeechTranslationLoggingRequest:
setContentAsFTSpeechTranslationPartialRecognitionResponse:
setContentAsFTSpeechTranslationFinalRecognitionResponse:
setContentAsFTSpeechTranslationMtResponse:
setContentAsFTSpeechTranslationTextToSpeechResponse:
setContentAsFTSpeechTranslationServerEndpointFeatures:
setContentAsFTBatchTranslationRequest:
setContentAsFTBatchTranslationFeedbackRequest:
setContentAsFTBatchTranslationLoggingRequest:
setContentAsFTTranslationSupportedLanguagesRequest:
setContentAsFTBatchTranslationResponse:
setContentAsFTTranslationSupportedLanguagesResponse:
setContentAsFTStartTextToSpeechStreamingRequest:
setContentAsFTBeginTextToSpeechStreamingResponse:
setContentAsFTPartialTextToSpeechStreamingResponse:
setContentAsFTFinalTextToSpeechStreamingResponse:
setContentAsFTStreamingTranslationRequest:
setContentAsFTTranslationResponse:
setContentAsFTQssAckResponse:
setContentAsFTStartLanguageDetectionRequest:
setContentAsFTLanguageDetectionResponse:
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performSpeechTranslationWithDelegate:requestBuilder:completion:
performBatchTranslationWithDelegate:requestBuilder:completion:
performTextToSpeechRouter:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performServiceDiscovery:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
streamFailVerifyStreamingTranslationStreamingResponse:
streamDidReceiveStreamingTranslationStreamingResponse:
performTranslation:requestBuilder:completion:
performStreamingTranslationWithDelegate:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performTextToSpeechSpeechFeature:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
initWithGRPCStreamingCallContext:
sendPronGuessStreamingRequest:
closeStream
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendSpeechTranslationStreamingRequest:
sendBatchTranslationStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendStreamingTranslationStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8@16q24Q32@40
v40@0:8@16Q24@32
@32@0:8@16q24
v40@0:8@16@24q32
@24@0:8@16
v32@0:8@16@24
v48@0:8@"_LTActivityLogger"16q24Q32@"NSDate"40
v40@0:8@"_LTActivityLogger"16Q24@"NSDate"32
@"NSDate"32@0:8@"_LTActivityLogger"16q24
v40@0:8@"_LTActivityLogger"16@"NSDate"24q32
@"NSDate"24@0:8@"_LTActivityLogger"16
v32@0:8@"_LTActivityLogger"16@"NSDate"24
v24@0:8q16
v32@0:8q16@24
v40@0:8q16Q24@32
v32@0:8@16q24
@24@0:8q16
v24@0:8@16
v16@0:8
@"NSCalendar"
@"<_LTActivityLoggerDelegate>"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v20@0:8B16
@"NSString"
{_NSRange="location"Q"length"Q}
v28@0:8@16B24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSLocale"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
@72@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56@64
q16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
@"NSArray"
v24@0:8@?16
v32@0:8q16@?24
v48@0:8@16Q24Q32@?40
v40@0:8@16@24@?32
v24@0:8@?<v@?B>16
v32@0:8q16@?<v@?@"NSArray">24
v48@0:8@"NSArray"16Q24Q32@?<v@?@"_LTTextLanguageDetectionResult">40
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
v32@0:8@16@?24
v36@0:8@16B24@?28
v40@0:8q16@24@?32
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v24@0:8@"NSData"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSURL"@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?q@"NSError">16
v24@0:8@"_LTInstallRequest"16
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
@36@0:8@16@24B32
v40@0:8@16Q24@?32
@"NSXPCConnection"
@"_LTTranslationServer"
@"NSUUID"
@"<_LTClientConnectionDelegate>"
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
v32@0:8@"NSArray"16@"NSError"24
v24@0:8@"_LTWordTimingInfo"16
v28@0:8B16@20
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@"<_LTSpeechTranslationDelegate>"
@"<_LTTranslationEngine>"
@"_LTSpeechTranslationResultsBuffer"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"NSMutableArray"
@40@0:8q16@24@32
@40@0:8@16{_NSRange=QQ}24
@"NSDictionary"
@32@0:8@16@24
v40@0:8@16@24^@32
@"NSURL"
d16@0:8
v24@0:8d16
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTTranslationContext"
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"NSNumber"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
@40@0:8@16@24@32
@"MAAsset"
@28@0:8@16B24
@36@0:8@16B24@?28
@36@0:8@16B24@28
@?16@0:8
@"<_LTTranslationService>"
@40@0:8@16B24@28B36
v36@0:8@16@24B32
v24@0:8Q16
v36@0:8@"NSString"16@"NSDictionary"24B32
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@"_LTLanguageDetectorFeatureCombinationModel"
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@"MLModel"
@"MAProgressNotification"
@"_LTOfflineAssetManager"
@"_LTLocalePair"
@24@0:8^{_NSZone=}16
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v24@0:8@"FTBatchTranslationStreamingResponse"16
@"FTBlazarService"
v44@0:8@16B24@?28@?36
v48@0:8@16B24B28@?32@?40
v28@0:8B16@?20
v48@0:8@16@24@32@?40
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
@24@0:8^@16
@"_LTHotfixManager"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v32@0:8@"VSSpeechSynthesizer"16@"VSPreviewRequest"24
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v56@0:8@16@24@32@?40@?48
v44@0:8@16@24B32@?36
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
@"NSError"
@"_LTTextToSpeechCache"
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
@"FTMutableBatchTranslationRequest"
@"_LTBatchEventLog"
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"NSDate"
@"AFSettingsConnection"
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@48@0:8@16@24@32@40
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
@"NSOrderedSet"
@32@0:8Q16q24
B24@0:8Q16
@"_LTInvocationEventContext"
@"_LTPlaybackService"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"_LTSpeechDataQueue"
@"_LTSpeechActivityDetector"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@"SNAudioStreamAnalyzer"
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@"_LTSpeechDataQueueNode"
@24@0:8d16
@36@0:8@16q24B32
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARSpeechRecognitionResultPackage"
@56@0:8@16@24d32d40d48
v36@0:8B16@20@?28
@"_LTTranslationResult"
@64@0:8@16q24@32@40@48@56
@"NSCountedSet"
@24@0:8Q16
@32@0:8@16Q24
@"NLLanguageRecognizer"
@40@0:8@16d24q32
Q32@0:8@16@24
@68@0:8@16@24d32B40@44@52@60
@"_LTTranslationStatistics"
@20@0:8B16
I16@0:8
v20@0:8I16
@"_LTTranslationSession"
@"_LTTextToSpeechTranslationRequest"
@"NSAttributedString"
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"_LTActivityLogger"
v28@0:8@?16B24
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
@"<_LTTextTranslationService>"
@"_LTRateLimiter"
@52@0:8@16{_NSRange=QQ}24B40@44
q28@0:8@16B24
@32@0:8@16d24
v36@0:8q16B24@?28
v44@0:8@16Q24B32@?36
v52@0:8@16Q24Q32B40@?44
v40@0:8@16@?24@?32
q24@0:8@16
@"NSData"16@0:8
@32@0:8@16r^{ErrorMessage=[1C]}24
@36@0:8@16r^{ErrorMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ErrorMessage>=I}24@0:8^v16
r^{ErrorMessage=[1C]}
@32@0:8@16r^{DisableSessionLog=[1C]}24
@36@0:8@16r^{DisableSessionLog=[1C]}24B32
{Offset<siri::speech::qss_fb::DisableSessionLog>=I}24@0:8^v16
r^{DisableSessionLog=[1C]}
#24@0:8q16
@32@0:8@16r^{ApgPronGuessMessage=[1C]}24
@36@0:8@16r^{ApgPronGuessMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ApgPronGuessMessage>=I}24@0:8^v16
r^{ApgPronGuessMessage=[1C]}
@32@0:8@16r^{ApgBatchRecoverMessage=[1C]}24
@36@0:8@16r^{ApgBatchRecoverMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::ApgBatchRecoverMessage>=I}24@0:8^v16
r^{ApgBatchRecoverMessage=[1C]}
@32@0:8@16r^{AsrRecognitionMessage=[1C]}24
@36@0:8@16r^{AsrRecognitionMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrRecognitionMessage>=I}24@0:8^v16
r^{AsrRecognitionMessage=[1C]}
@32@0:8@16r^{AsrErrorBlamerMessage=[1C]}24
@36@0:8@16r^{AsrErrorBlamerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrErrorBlamerMessage>=I}24@0:8^v16
r^{AsrErrorBlamerMessage=[1C]}
@32@0:8@16r^{AsrItnMessage=[1C]}24
@36@0:8@16r^{AsrItnMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrItnMessage>=I}24@0:8^v16
r^{AsrItnMessage=[1C]}
@32@0:8@16r^{AsrTextNormalizationMessage=[1C]}24
@36@0:8@16r^{AsrTextNormalizationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrTextNormalizationMessage>=I}24@0:8^v16
r^{AsrTextNormalizationMessage=[1C]}
@32@0:8@16r^{AsrPostItnHammerMessage=[1C]}24
@36@0:8@16r^{AsrPostItnHammerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrPostItnHammerMessage>=I}24@0:8^v16
r^{AsrPostItnHammerMessage=[1C]}
@32@0:8@16r^{AsrKeywordFinderMessage=[1C]}24
@36@0:8@16r^{AsrKeywordFinderMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrKeywordFinderMessage>=I}24@0:8^v16
r^{AsrKeywordFinderMessage=[1C]}
@32@0:8@16r^{AsrCorrectionsValidatorMessage=[1C]}24
@36@0:8@16r^{AsrCorrectionsValidatorMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrCorrectionsValidatorMessage>=I}24@0:8^v16
r^{AsrCorrectionsValidatorMessage=[1C]}
@32@0:8@16r^{AsrGraphemeToPhonemeMessage=[1C]}24
@36@0:8@16r^{AsrGraphemeToPhonemeMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::AsrGraphemeToPhonemeMessage>=I}24@0:8^v16
r^{AsrGraphemeToPhonemeMessage=[1C]}
@32@0:8@16r^{BlazarMultiUserMessage=[1C]}24
@36@0:8@16r^{BlazarMultiUserMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarMultiUserMessage>=I}24@0:8^v16
r^{BlazarMultiUserMessage=[1C]}
@32@0:8@16r^{BlazarMultilingualMessage=[1C]}24
@36@0:8@16r^{BlazarMultilingualMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarMultilingualMessage>=I}24@0:8^v16
r^{BlazarMultilingualMessage=[1C]}
@32@0:8@16r^{BlazarSpeechTranslationMessage=[1C]}24
@36@0:8@16r^{BlazarSpeechTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarSpeechTranslationMessage>=I}24@0:8^v16
r^{BlazarSpeechTranslationMessage=[1C]}
@32@0:8@16r^{BlazarBatchTranslationMessage=[1C]}24
@36@0:8@16r^{BlazarBatchTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarBatchTranslationMessage>=I}24@0:8^v16
r^{BlazarBatchTranslationMessage=[1C]}
@32@0:8@16r^{BlazarTextToSpeechRouterMessage=[1C]}24
@36@0:8@16r^{BlazarTextToSpeechRouterMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarTextToSpeechRouterMessage>=I}24@0:8^v16
r^{BlazarTextToSpeechRouterMessage=[1C]}
@32@0:8@16r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}24
@36@0:8@16r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarTextToSpeechRouterStreamingMessage>=I}24@0:8^v16
r^{BlazarTextToSpeechRouterStreamingMessage=[1C]}
@32@0:8@16r^{BlazarServiceDiscoveryMessage=[1C]}24
@36@0:8@16r^{BlazarServiceDiscoveryMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::BlazarServiceDiscoveryMessage>=I}24@0:8^v16
r^{BlazarServiceDiscoveryMessage=[1C]}
@32@0:8@16r^{LmtLmScorerMessage=[1C]}24
@36@0:8@16r^{LmtLmScorerMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::LmtLmScorerMessage>=I}24@0:8^v16
r^{LmtLmScorerMessage=[1C]}
@32@0:8@16r^{NapgCreateLanguageProfileMessage=[1C]}24
@36@0:8@16r^{NapgCreateLanguageProfileMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::NapgCreateLanguageProfileMessage>=I}24@0:8^v16
r^{NapgCreateLanguageProfileMessage=[1C]}
@32@0:8@16r^{MtTranslationMessage=[1C]}24
@36@0:8@16r^{MtTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::MtTranslationMessage>=I}24@0:8^v16
r^{MtTranslationMessage=[1C]}
@32@0:8@16r^{MtStreamingTranslationMessage=[1C]}24
@36@0:8@16r^{MtStreamingTranslationMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::MtStreamingTranslationMessage>=I}24@0:8^v16
r^{MtStreamingTranslationMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechMessage>=I}24@0:8^v16
r^{TtsTextToSpeechMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechStreamingMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechStreamingMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechStreamingMessage>=I}24@0:8^v16
r^{TtsTextToSpeechStreamingMessage=[1C]}
@32@0:8@16r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}24
@36@0:8@16r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::TtsTextToSpeechSpeechFeatureMessage>=I}24@0:8^v16
r^{TtsTextToSpeechSpeechFeatureMessage=[1C]}
@32@0:8@16r^{NlShortcutFuzzyMatchMessage=[1C]}24
@36@0:8@16r^{NlShortcutFuzzyMatchMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::NlShortcutFuzzyMatchMessage>=I}24@0:8^v16
r^{NlShortcutFuzzyMatchMessage=[1C]}
@32@0:8@16r^{SlsLanguageDetectionMessage=[1C]}24
@36@0:8@16r^{SlsLanguageDetectionMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::SlsLanguageDetectionMessage>=I}24@0:8^v16
r^{SlsLanguageDetectionMessage=[1C]}
@32@0:8@16r^{QssMessage=[1C]}24
@36@0:8@16r^{QssMessage=[1C]}24B32
{Offset<siri::speech::qss_fb::QssMessage>=I}24@0:8^v16
r^{QssMessage=[1C]}
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^v16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^v16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
i16@0:8
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^v16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^v16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^v16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^v16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^v16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^v16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^v16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^v16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^v16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^v16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^v16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^v16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^v16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^v16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
f16@0:8
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^v16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^v16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^v16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^v16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^v16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^v16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^v16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^v16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^v16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^v16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^v16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^v16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^v16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^v16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^v16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^v16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^v16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^v16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^v16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^v16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^v16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^v16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^v16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^v16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^v16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^v16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^v16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^v16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^v16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^v16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^v16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^v16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^v16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^v16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^v16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^v16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^v16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^v16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^v16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^v16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^v16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^v16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^v16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^v16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^v16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^v16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^v16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^v16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^v16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^v16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^v16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^v16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^v16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^v16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{StreamingTranslationRequest=[1C]}24
@36@0:8@16r^{StreamingTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StreamingTranslationRequest>=I}24@0:8^v16
r^{StreamingTranslationRequest=[1C]}
@32@0:8@16r^{TranslationPhraseMetaInfo=[1C]}24
@36@0:8@16r^{TranslationPhraseMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationPhraseMetaInfo>=I}24@0:8^v16
r^{TranslationPhraseMetaInfo=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^v16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^v16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^v16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^v16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^v16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^v16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^v16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^v16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^v16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^v16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^v16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^v16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^v16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^v16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^v16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^v16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^v16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^v16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^v16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^v16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^v16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^v16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^v16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^v16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechResponseDevData=[1C]}24
@36@0:8@16r^{TextToSpeechResponseDevData=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponseDevData>=I}24@0:8^v16
r^{TextToSpeechResponseDevData=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^v16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^v16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^v16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainerRpcV2=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainerRpcV2=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainerRpcV2>=I}24@0:8^v16
r^{TextToSpeechCacheContainerRpcV2=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainerStreamingV2=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainerStreamingV2=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainerStreamingV2>=I}24@0:8^v16
r^{TextToSpeechCacheContainerStreamingV2=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^v16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureModelIdentifier>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureModelIdentifier=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWord=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWord=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWord>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWord=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputText=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputText=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputText>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputText=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureOutputFeature>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureOutputFeature=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputPhoneme>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputPhoneme=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputPhonemeSequence>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputPhonemeSequence=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureRequest=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureRequest>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureRequest=[1C]}
@32@0:8@16r^{LexiconEntry=[1C]}24
@36@0:8@16r^{LexiconEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureRequest_::LexiconEntry>=I}24@0:8^v16
r^{LexiconEntry=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureResponse=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureResponse>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^v16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^v16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{ServiceDiscoveryRequest=[1C]}24
@36@0:8@16r^{ServiceDiscoveryRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ServiceDiscoveryRequest>=I}24@0:8^v16
r^{ServiceDiscoveryRequest=[1C]}
@32@0:8@16r^{ServiceDiscoveryResponse=[1C]}24
@36@0:8@16r^{ServiceDiscoveryResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ServiceDiscoveryResponse>=I}24@0:8^v16
r^{ServiceDiscoveryResponse=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^v16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^v16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^v16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^v16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^v16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^v16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^v16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^v16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^v16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^v16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^v16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^v16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^v16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^v16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^v16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^v16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^v16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^v16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^v16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24
@36@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationFeedbackRequest>=I}24@0:8^v16
r^{BatchTranslationFeedbackRequest=[1C]}
@32@0:8@16r^{BatchTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationLoggingRequest>=I}24@0:8^v16
r^{BatchTranslationLoggingRequest=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^v16
r^{BatchTranslationResponse=[1C]}
{Offset<siri::speech::schema_fb::BatchTranslationResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{TranslatedSentence=[1C]}24
@36@0:8@16r^{TranslatedSentence=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse_::TranslatedSentence>=I}24@0:8^v16
r^{TranslatedSentence=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^v16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{TranslationSupportedLanguagesRequest=[1C]}24
@36@0:8@16r^{TranslationSupportedLanguagesRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesRequest>=I}24@0:8^v16
r^{TranslationSupportedLanguagesRequest=[1C]}
@32@0:8@16r^{TranslationSupportedLanguagesResponse=[1C]}24
@36@0:8@16r^{TranslationSupportedLanguagesResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesResponse>=I}24@0:8^v16
r^{TranslationSupportedLanguagesResponse=[1C]}
@32@0:8@16r^{LanguagePair=[1C]}24
@36@0:8@16r^{LanguagePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationSupportedLanguagesResponse_::LanguagePair>=I}24@0:8^v16
r^{LanguagePair=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^v16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^v16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{QSSVersionInfo=[1C]}24
@36@0:8@16r^{QSSVersionInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::QSSVersionInfo>=I}24@0:8^v16
r^{QSSVersionInfo=[1C]}
v20@0:8i16
v20@0:8f16
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^v16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^v16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^v16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^v16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^v16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^v16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^v16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^v16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^v16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^v16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^v16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^v16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^v16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^v16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{StreamingTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{StreamingTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::StreamingTranslationStreamingRequest>=I}24@0:8^v16
r^{StreamingTranslationStreamingRequest=[1C]}
@32@0:8@16r^{StreamingTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{StreamingTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::StreamingTranslationStreamingResponse>=I}24@0:8^v16
r^{StreamingTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^v16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^v16
r^{LanguageDetectionStreamingResponse=[1C]}
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
