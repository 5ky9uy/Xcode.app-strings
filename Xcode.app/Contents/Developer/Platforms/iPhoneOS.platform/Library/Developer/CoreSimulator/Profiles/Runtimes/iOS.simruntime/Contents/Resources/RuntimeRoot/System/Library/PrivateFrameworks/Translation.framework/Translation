@(#)PROGRAM:Translation  PROJECT:Translation-173.11.4
@mcpl
@mcpl
@mcpl
LastActivityDate
%@_%@
com.apple.translation.DailyActive
feature
%0*ld_%ld
com.apple.translation.WeeklyActive
week_name
com.apple.translation.MonthlyActive
month_name
system
undefined
identifier
<no value>
text
targetRange
start
length
sourceRange
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
Error
com.apple.translation
selector
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
@"NSDictionary"8@?0
com.apple.translation.analytics-event
v8@?0
errorDomain
errorCode
errorDescription
duration
sourceLocale
targetLocale
%@.%@
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
application-identifier
sentence
singleParagraph
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
v16@?0@"NSError"8
paragraphs
com.apple.TranslationUIServices.TranslationUIService
text-to-speech
speech
preheat
text-LID
processName
unknown
type
v24@?0@"_LTAudioData"8@"NSError"16
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v24@?0@"_LTTranslationResult"8@"NSError"16
com.apple.private.translation
com.apple.Translation
Daemon
com.apple.translation.daemon.listener
DisambiguationEnabled
DataCollectionEnabled
com.apple.translationd
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
unknown error
Remote service failure
Online translation not implemented
Cannot force both online and offline
Failed to load LID model
Translation ongoing already
Speech translation already ongoing
Speech duration limit exceeded
Translation server did not respond in time.
Offline TTS failed
Translation from %@ to %@ is not supported.
%@ %@ %@
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
LTEtiquetteSanitizer.m
missing replacement tokens
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
HotfixManager
Translation
Hotfix
com.apple.Translator.HotfixManager
Mapping
FormatVersion
Cannot find any compatible hotfix
v24@?0@"NSDictionary"8@"NSError"16
com.apple.Translate
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
mapping-info-plist
v24@?0@"NSData"8@"NSError"16
HotfixAssetVersion
%@-%@
mt-quasar-config.json
HotfixAssetName
Failed to specify compression algorithm
Failed to specify format
Failed to open archive for reading
Unable to extract file
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
Languages
Footprint
Premium
hybridendpointer.json
InstallRequest
com.apple.siri.translation.speechrequest
locales
useCellular
zh-Hant
zh_TW
zh-Hans
zh_CN
dominantLanguage
confidences
isConfident
isFinal
com.apple.translation.lid.result
com.apple.translation.lid.finalResult
final
intermediate
, partial ASR confidences
, final ASR results
CSLanguageDetector
Class getCSLanguageDetectorClass(void)_block_invoke
LTLanguageDetector.m
Unable to find class %s
void *CoreSpeechLibrary(void)
/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
/System/Library/PrivateFrameworks/CoreSpeech.framework/Contents/MacOS/CoreSpeech
CSLanguageDetectorOption
Class getCSLanguageDetectorOptionClass(void)_block_invoke
features
compiledModelFile
modelInput
modelInputIsMatrix
modelOutput
missingFeatureValueDefault
missingLanguageDetectionDefault
LanguageLocaleToIdentifier
min_source
max_source
avg_source
min_target
max_target
avg_target
most_recent_partial_source
max_partial_source
avg_partial_source
most_recent_partial_target
max_partial_target
avg_partial_target
acoustic_lid
acoustic_lid_count
acoustic_lid0
acoustic_lid1
acoustic_lid2
identifier_source
identifier_target
identifier_asr
v32@?0@"NSString"8Q16^B24
@max.doubleValue
@avg.doubleValue
v32@?0@"NSNumber"8Q16^B24
1.0-
%lld
progress
offlineState
localeIdentifier
totalExpected
totalWritten
isStalled
expectedTimeRemaining
Missing
Installed
Downloading
NeedsDownload
ErrorInstalling
%@ %@ %@ %@
LanguageManager
com.apple.siri.translation.LanguageManager
mt_app.offline
LanguagePairs
ASR-%@
TTS-%@
asset_list
AssetName
v16@?0@"MAProgressNotification"8
asr_languages
_all
TTS-
Translation voice not found for %@:%@
Translation voice downloaded for %@:%@
Downloading Translation voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
ASR-
v16@?0q8
Not Present
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
<%@: source:%@ target:%@>
Translator
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
conversationID
requestID
localePair
selectedLocale
lidResult
senses
userInteractedSenses
firstResponse
firstParagraphComplete
progressComplete
pageComplete
timeToFirstResponse
timeToFirstParagraphComplete
timeToProgressComplete
timeToPageComplete
v16@?0@"OspreyMutableRequest"8
com.apple.translation.ParagraphTranslationDone
hw.machine
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechTranslationAssets2
com.apple.MobileAsset.SpeechEndpointAssets
AssetManager
com.apple.Translator.EMTAssetManager
v12@?0B8
plist
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
MADownLoadResult
Mobile asset failed to download.
v16@?0@"NSArray"8
Assets
AssetsV2
assets.json
Type
AssetVersion
RequiredCapabilityIdentifier
Configuration asset is missing.
The Configuration asset has not yet been downloaded.
Missing asset entitlement
LanguageDetectorDefaultAsset
featureCombinationLID.plist
_UnarchivedSize
TranslationAssetQueryDomain
OfflineSpeechSynthesizer
com.apple.assistant.backedup
Output Voice
Gender
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
LTOfflineTranslationEngine.mm
Missing result locale
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
Translation failed
Translation input was empty
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
asrBestConfidence
asrBestText
request_id
hasFinalServerResponse
completionHandlerCalled
Missing Batch Translation Responses
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.mobilesafari
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
x-sequoia-client
sentenceCount
v32@?0@"_LTTranslationParagraph"8Q16^B24
com.apple.translation.OnlineSpeechTranslation
sentAudio
sentEndAudio
endpointedSpeech
didReceiveAudioLimitExceededResponse
didReceivePartialRecognitionResponse
didReceiveFinalRecognitionResponse
didReceiveTranslationResponse
didReceiveTTSResponse
didReceiveFinalBlazarResponse
didTimeout
<%@: sentAudio:%@ sentEndAudio:%@ endpointedSpeech:%@ didReceiveAudioLimitExceededResponse:%@ didReceivePartialRecognitionResponse:%@ didReceiveFinalRecognitionResponse:%@ didReceiveTranslationResponse:%@  didReceiveTTSResponse:%@ didReceiveFinalBlazarResponse:%@ didTimeout:%@ error %@>
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
paragraph
Text or ranges need to be specified
v32@?0@"_LTTranslationRange"8Q16^B24
Error AudioQueueStart
com.apple.translation.powerlog
default
InstalledLocales
LastOfflineAssetCatalogUpdate
LastCDNUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
RequestID
HotfixEndpointURL
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
FinalAcousticLanguageDetectionResultsWaitTimeInMs
FinalThresholdsAcousticLanguageDetectionResultsWaitTimeInMs
MinimumAcousticLanguageDetectionResults
MaximumAcousticLanguageDetectionResults
VADAudioCacheMaxDuration
LanguageDetectorFeatureCombinationModelSupported
LanguageDetectorFeatureCombinationModelThreshold
LanguageDetectorFeatureCombinationModelConfidenceThreshold
ASRDataPackToLIDThresholdVersion
ASRDataPackToASRTypeIdentifier
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
CharacterBasedLocales
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
RateLimitingMaximumPageLoadRequests
RateLimitingMaximumDynamicContentRequests
VisualParagraphSegmenterLocalesEnabled
Configuration
-finalASR
mt_app.online
web.online
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
https://sequoia.apple.com
https://seed-sequoia.siri.apple.com
https://carry-sequoia.siri.apple.com
https://sequoia.cdn-apple.com/sequoia-prod
https://sequoia-test.cdn-apple.com/sequoia-livability/carry
EDC04020
com.apple.translationd.playback
com.apple.translation.session
v16@?0@"NSData"8
com.apple.translation.AnalysisQueue
LTSpeechCompressor.m
Already started compressor
AudioConverterNew failed: %x
AudioConverterSetProperty/kAudioConverterEncodeBitRate failed: %x
Too many buffers
Cannot produce ASPD for PCM
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
stable
locale
transcriptions
sausage
Sausage
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
confidence
(%@)
bins
alternatives
bestIndex
lowConfidence
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
com.apple.translation.speech
mini.json
MtApp
Empty recognition
No speech recognized
sanitizedFormattedString
formattedString
minConfidence
maxConfidence
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
v32@?0@"NSLocale"8@"_LTSpeechRecognitionResult"16^B24
sessionID
taskHint
deviceOS
deviceType
appIdentifier
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
LTTextLanguageDetectionResult.m
Invalid parameter not satisfying: %@
languages
com.apple.translation.TextLID
language
isSupported
TextLIDAggregateEvaluation
TextLIDUseLSTM
com.apple.translation.tts-cache
LTTextToSpeechCache.m
MISS
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
com.apple.Translate.globalprefschanged
com.apple.onboarding.translate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
tokens
statistics
status
phrasebook_exact
com.apple
translate
<redacted>
 (%@)
; %@
 | OCR
uniqueID
autodetectLanguage
autoEndpoint
censorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
ttsPlaybackRate
enableVAD
sourceOrigin
sourceContentAsJSON
targetContentAsJSON
errorsAsJSON
safariVersion
webpageURL
spans
v32@?0@"_LTTranslationSpan"8Q16^B24
-[_LTTranslationParagraph splitIntoSentences]_block_invoke_2
LTTranslationParagraph.m
previousSpan.range.location + previousSpan.range.length == textRange.location
v32@?0@"NSString"8@"_LTTranslationSpan"16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
LTTranslationRange.m
Invalid paramter: identifier is nil
%@/%@
batch
LTTranslationRequest.m
This is deprecated
TranslationRequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
textToSpeech
CMBlockBufferCopyDataBytes could not copy data: %d
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
NO_IDENTIFIER
translations
sourceString
sanitizedSourceString
alignments
sourceMatch
targetMatch
pbMatch
sense ID
definition
source match
target match
input
output
labels
gender
formality
@"_LTTranslationSense"16@?0@"NSObject"8
com.apple.translationd.server
Offline models not available for language pair
v24@?0q8@"NSError"16
com.apple.translation.text
LTTranslationSession.m
completion
v16@?0@"NSDictionary"8
v24@?0@"<_LTTranslationService>"8@?<v@?>16
requests
Service should be set before calling translate
Translation rate limit reached
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
feedback
range
shouldTranslate
metaInfoData
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
sentencepiece encoder input
firstleg sentencepiece decoder output
sentencepiece decoder output
siri
app_review
mt_app
v16@?0@"<_LTTranslationService>"8
v16@?0@"_LTLanguageDetectionResult"8
v16@?0@"_LTTextLanguageDetectionResult"8
InternalBuild
ar_SA
male
female
Language
Config
MT-bi-
senseId
reason
cancelled
ended
failed
started
alternateLocale
error
userSelectedLocale
exists
inputSourceAppBundleId
contextId
startedOrChanged
numParagraphFailures
numberOfParagraphs
com.apple.aiml.mi.mt.MTClientEvent
appDisambiguationInteracted
appLIDContext
appLIDInteracted
appTextPasted
batchRequestContext
eventMetadata
invocationContext
sessionContext
speechRecognitionSignal
userFacingSessionSignal
clientAppBundleId
mtId
sessionId
inputMode
isExplicitLanguageFilterEnabled
isLanguageIdentificationEnabled
isOnDeviceTranslationEnabled
mobileAssetConfigVersion
mtLanguagePair
task
uiMode
sourceLanguage
targetLanguage
speechRequestStatus
userFacingSessionStatus
LOCALE_UNKNOWN_LOCALE
LOCALE_AR_AE
LOCALE_AR_SA
LOCALE_CA_ES
LOCALE_CS_CZ
LOCALE_DA_DK
LOCALE_DE_AT
LOCALE_DE_CH
LOCALE_DE_DE
LOCALE_EL_GR
LOCALE_EN_AE
LOCALE_EN_AU
LOCALE_EN_CA
LOCALE_EN_GB
LOCALE_EN_ID
LOCALE_EN_IE
LOCALE_EN_IN
LOCALE_EN_MY
LOCALE_EN_NZ
LOCALE_EN_PH
LOCALE_EN_SG
LOCALE_EN_SA
LOCALE_EN_US
LOCALE_EN_ZA
LOCALE_ES_CL
LOCALE_ES_CO
LOCALE_ES_ES
LOCALE_ES_MX
LOCALE_ES_US
LOCALE_FI_FI
LOCALE_FR_BE
LOCALE_FR_CA
LOCALE_FR_CH
LOCALE_FR_FR
LOCALE_HE_IL
LOCALE_HI_IN
LOCALE_HR_HR
LOCALE_HU_HU
LOCALE_ID_ID
LOCALE_IT_CH
LOCALE_IT_IT
LOCALE_JA_JP
LOCALE_KO_KR
LOCALE_MS_MY
LOCALE_NB_NO
LOCALE_NL_BE
LOCALE_NL_NL
LOCALE_PL_PL
LOCALE_PT_BR
LOCALE_PT_PT
LOCALE_RO_RO
LOCALE_RU_RU
LOCALE_SK_SK
LOCALE_SV_SE
LOCALE_TH_TH
LOCALE_TR_TR
LOCALE_UK_UA
LOCALE_VI_VN
LOCALE_WUU_CN
LOCALE_YUE_CN
LOCALE_ZH_CN
LOCALE_ZH_HK
LOCALE_ZH_TW
(unknown: %i)
QssRpc_immutable_generated.mm
Output Buffer is null
v20@?0r*8I16
v24@?0^v8Q16
tok_phrases
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
bool_stats
int32_stats
double_stats
acoustic_feature_per_frame
speech_recognition_features
acoustic_features
value
recognition_result
audio_analytics
latnn_mitigator_result
start_speech_request
user_parameters
pron_hints
contextual_text
context_with_pron_hints
user_language_profile
user_acoustic_profile
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
attributes
category_data
user_data
voc_token
tts_pronunciations
human_readable_prons
apg_ids
recovery_return_codes
voc_tokens
words_list
formatted_words_list
normalized_tokens
nbest_variants
sanitized_sequences
prons
normalized_prons
sanitized_tokens
phonemes
aot_token_prons
jit_token_prons
index
span
raw_sausage
raw_nbest_choices
post_itn_tokens
itn_alignments
translation_phrase
pre_sausage_payload
siri_translation_info
speech_translation_info
siri_payload_translation_info
web_translation_info
n_best_translated_phrases
engine_output
mt_alignment
translated_tokens
audio_packets
match_ids
results
keywords
corrected_sausage
n_best_list
pause_counts
corrections
voice
resource
context_info
word_phonemes
prompts
normalized_text
phoneme_sequence
replacement
neural_phoneme_sequence
resources
meta_info
context
experiment
feature_flags
debug
profile
decoder_description
playback_description
word_timing_info
cache_meta_info
cache_object
audio_frames
translation_locale_pairs
translation_request
text_to_speech_requests
translation_locale_pair
detected_locale
user_interacted_senses
text_to_speech_response
server_endpoint_features
utterance
shortcuts
shortcut_score_pairs
language_parameters_by_id
predictions
content
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
profile_blob
profile_blob_version
profile_checksum
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
add_space_after
phone_seq
ipa_phone_seq
has_unsuggested_alternatives
speech_id
request_locale
name
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
frame_duration
session_id
return_code
return_str
lang_profile_recreate_codes
watermark_detection
watermark_peak_average
has_result
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
primary_speech_id
product_id
vendor_id
left_context
right_context
audio_bytes
packet_count
total_audio_recorded_seconds
orthography
pronunciations
frequency
category_name
error_code
error_str
incomplete_profile
recreate_apg_prons
blob
apg_id
num_of_requested
num_of_processed
num_of_succeeded
post_itn_string
nbest_variants_max
original_token
pron_sequence
log_weight
token
pron_source
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
start_index
end_index
do_not_translate
post_itn_recognition
pre_itn_payload
post_itn_payload
source_language
target_language
sequence_id
disable_log
opt_in_status
app_id
return_string
engine_input
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
debug_information
matcher_id
query
target
latency
expanded_path
keyword_orthography
posterior
enable_sanitization
num_of_words
trailing_silence_duration
eos_likelihood
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
fe_feature
fe_feature_only
disable_prompts
cache_only
quality
channel_type
is_synthesis
dialog_identifier
experiment_identifier
prompts_v2
original
force_use_tts_service
disable_cache
data
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
timestamp
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
endpoint_threshold
endpoint_extra_delay
source_locale
target_locale
conversation_id
restricted_mode
streaming_mode
user_selected_locale
user_selected_sense
is_final_result
interaction_id
raw_string
shortcut
similarity_score
is_low_confidence
paragraph_id
source_content
translated_content
errors
safari_version
os_version
translated_text
sentence_count
content_type
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Afm/AStarFuzzyMatching
/siri.speech.qss_fb.Sls/LanguageDetection
Log daily activity for %@
Log weekly activity
Log monthly activity for %@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
Failed to deserialize logging request: %@ 
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Memory pressure warning level %lu.
Rejected Translation client with PID %d lacking the appropriate entitlement (%@).
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
rm -rf %@
Could not delete: %@
Downloading: %@
Failed to download %@ with error: %@
Select hotfix: %@
Found existing hotfix
Remove folder failed: %@
Create folder failed: %@
Decompression failed: %@
Failed to specify compression algorithm: %s
Failed to specify format: %s
Start extracting archive
Failed to open archive for reading: %s
Entry extraction path: %@
Unable to extract file: %s
Finished extracting archive to: %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Updating source endpointer threshold to %f
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Updating target endpointer threshold to %f
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Start installation request with service
Failed to obtain LID asset
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
Sending out new %@ LID result, detected %@
Computing new LID result, with %ld acoustic results%@%@
Already sent final LID result, ignoring additional speech result
Change in model-version triggers deletion of cached %@ partial-confidences
Calling endAudio from addSpeechRecognitionResult
Initiate use of final thresholds to reduce dialog rates, as timer ended after 1st final ASR
Try to force final LID, as timer ended after 1st final ASR
Added %@ partial-confidence: %f; new array length: %ld
Already sent final LID result, ignoring additional audio data
NumSamples: %ld
LID Audio Data
Trying to send final LID result from endAudio
Forcing current language detection result to be final
Forcing language detection result to be %@
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
Acoustic LID detected %@ (confident: %@): %@
Trying to send final LID result from acousticLID CoreSpeech delegate
Setting default value for input is matrix to NO
Missing necessary configuration values
Setting default value for missing feature value to %f
Setting default value for missing language detector result to %f
Unknown feature in model file: %@
Unable to load CoreML model from: %@
CoreML model loaded: %@
Min confidence source: %f
Max confidence source: %f
Average confidence source: %f
Min confidence target: %f
Max confidence target: %f
Average confidence target: %f
Acoustic LID: %f
Acoustic LID count: %ld
Acoustic LID0: %f
Acoustic LID1: %f
Acoustic LID2: %f
Most recent partial confidence source: %f
Max partial confidence source: %f
Average partial confidence source: %f
Most recent partial confidence target: %f
Max partial confidence target: %f
Average partial confidence target: %f
Language %@ locale identifier source: %f
ASR-type identifier for model version=%@ -> feature: %f
Discarded CoreML features, as all values were defaults
Created CoreML features: %@
Unable to compile CoreML input features
Unable to construct CoreML feature provider
Unable to perform inference on CoreML model
Was unable to extract CoreML prediction
Was unable to extract posterior values from prediction results
Queried LID threshold version "%@" useFinalThresholds: %@ isFinalASR: %@, detected %@, with score %f using discriminator threshold %@%f and confidence offset %f (confident: %@)
missing mt_app.offline.plist
asset names for %@: %@
downloadAsset %@ totalExpected %@
progressCallback update assetIdentifier %@ %@
Finished downloading all assets
Required Assets: %@
setAutoDownloadedVoiceAssets %@
Unreferenced assets: %@
purged %@ result %ld
Nothing to install.
Installing:
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start speech senses logging request
Speech senses logging request finished with error: %@
Speech senses logging request finished
Start Safari latency logging request
Start Safari feedback request
Safari feedback request finished with error: %@
Safari feedback request finished
Received speech logging request response: [%d] %@
Speech logging request received unexpected response: %@
Speech logging request received error: %@
Received safari feedback request response: [%d] %@
Safari feedback request received unexpected response: %@
Safari feedback request received error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Received new language detection result
Trying to cancel recognition for %@
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
MADownloadNotEntitled
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
error querying obsolete catalog assets
Deleting Obsolete Assets %@
error querying catalog assets
error querying installed assets
Config asset not installed!
Reading configuration plist %@
Failed to read plist %@
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Start downloading asset %@ userInitiated: %@, useCellular: %@
Asset progress: %@
update: %@ %@
Asset download finished %@
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
Failed to remove old asset directory %@
Failed to create asset directory %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
----------------------------- sortedCatalogAssets ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
%@ %@ %@ %@
error downloading asset %@
error deleting asset %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Starting download for asset with attributes: %@
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Failed to fetch asset metadata. Result: %ld
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Failed to create recognizer: %@
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Failed to create translator: %@
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Already got final LID result, forwarding...
Waiting for LID result
Received final LID result, continue with wait block
Starting translation
Initialize translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
Starting partial translation
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
streamDidReceiveBatchTranslationStreamingResponse request_id %{public}@
found BatchTranslationResponse request_id %{public}@
FIXME: NULL FTBatchTranslationResponse!
Succeeded request %{public}@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %{public}@
NULL FTFinalBlazarResponse!
GRPC error %d: %@
Translation error on %{public}@: %@
found FTFinalBlazarResponse request_id %{public}@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FBFLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
startServerTimeoutTimer 
updateServerTimeout %.2fs 
cancelServerTimeout: %@
batch timeout triggered
 serverTimeoutFired Sending batch request after %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ after %.2fs
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %{public}@, task: %{public}@, sessionID: %{public}@, URL: %@
Batch SELF log created
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Starting speech translation with request ID: %{public}@ session ID: %{public}@, opt in status: %ld
Streaming connection finished with error: %@
Starting text to speech translation with request ID: %{public}@, session ID: %{public}@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
sendAudioData: Final ASR response received, not sending audio.
sendAudioData: Already sent end audio, not sending audio.
sendAudioData: Already endpointed, do not need to send additional audio.
sendAudioData: Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring non-final LID result
LID result received. Primary language recognized: %@
Sending MT responses if needed
Detected translation locale: %@
Result locale: %@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Create SELF Batch request log with request sessionID: %@, requestID: %@, appID: %@
Unable to create the SELF Batch request log.
Start SELF Batch request log with %lu paragraphs
End SELF Batch request log
End SELF Batch request log with error %@
Cancel SELF Batch request log with reason %@
SELF Batch request log sent %@
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
Sending end of audio
Asked to cancel speech session
SNAudioStreamAnalyzer failure: %@
Sausage conf %ld for locale %@
Sausage confidences: %@
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Using LSTM text lid engine
Using CFRO text lid engine
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Using aggregate text lid evaluation
TTS cache request: %@
Purging %ld items from TTS cache
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Text Translation: start with service
Using paragraph translation
Received parapraph translation result
Fallback to text to speech translation
Translation failed with error: %@
Alignment '%@' ID: %@
No alignment information in translation
Received translated paragraph for ID: %@
New outstanding count: %ld
Received text to speech result
Using `-[_LTTranslator translate:]` is not supported on batch translation. Please take a look at `_LTTranslationSession`.
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TextToSpeechTranslation did receive translation result
No asset info found for pair %@
Reusing cached offline engine for locales: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %{public}@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %{public}@, current ongoing is: %{public}@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
Translation rate limit reached, ignoring %lu requests
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Session sending feedback
Received translation result for %@
Failed to clear caches: %@
Failed to complete _offlineLanguageStatus %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete installedLocales %@
Failed to complete availableLocalePairsForTask %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Creating service proxy
Connection error: %@
Connection done
Creating SYNC service proxy
Failed sync preheat request
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Starting translation for request
Failed to serialize logging request: %@
Failed to complete logging request: %@
softlink:r:path:/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
ABSD
_LTActivityLogging
JSONRepresentation
_LTAlignment
NSSecureCoding
NSCoding
_LTAnalyticsEvent
_LTAsyncMap
_LTAudioData
_LTClientConnection
_LTTranslationService
_LTCombinedEngine
_LTSpeechTranslationDelegate
NSObject
_LTTranslationEngine
_LTCombinedRouteParagraphTranslationRequest
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
LTTranslationError
_LTMatch
_LTEtiquetteSanitizer
_LTHotfixManager
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTHybridEndpointerAssetInfo
_LTInstallRequest
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
_LTLanguageDetectorAssetInfo
_LTLanguageDetectorFeatureCombinationModel
_LTLanguageInstallationStatus
_LTLanguageAssetStatus
_LTLanguageManager
_LTLanguagePairOfflineAvailability
_LTLocalePair
NSCopying
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTTranslationSensesLoggingRequest
_LTSafariLatencyLoggingRequest
_LTLoggingRequestHandler
FTSpeechTranslationResponseDelegate
FTBatchTranslationResponseDelegate
_LTMultilingualSpeechRecognizer
_LTOfflineAssetManager
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
_LTOfflineTranslationEngine
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
_LTOnlineTranslationEngine
_LTOspreySpeechTranslationSession
_LTSpeechCompressorDelegate
_LTParagraphTranslationRequest
_LTPlaybackService
_LTPowerLogger
_LTRateLimiter
LTBatchEventLog
_LTServerSpeakSession
_LTServerSpeechSession
_LTSpeakRequest
_LTSpeechActivityDetector
SNResultsObserving
_LTSpeechCompressor
_LTSpeechDataQueueNode
_LTSpeechDataQueue
Osprey
_LTSpeechRecognitionResult
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTSpeechTranscription
_LTSpeechTranslationAssetInfo
_LTSpeechTranslationResultsBuffer
_LTTaskContext
_LTTextLanguageDetectionResult
_LTTextLanguageDetector
_LTTextToSpeechCache
_LTTokenizer
_LTTranslateSettingsController
_LTTranslationCandidate
OspreyRequest
_LTTranslationContext
_LTTranslationFeedback
_LTTranslationParagraph
_LTTranslationRange
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTranslationResult
_LTTranslationSense
_LTTranslationServer
_LTTranslationSession
_LTTranslationSpan
LTStatistics
_LTTranslationStatistics
_LTTranslationToken
_LTTranslator
TranslationAssetUtil
MTSchemaProvisionalLanguageIdentificationLocaleConfidence
MTSchemaProvisionalMTAppDisambiguationInteracted
MTSchemaProvisionalMTAppLanguageIdentificationCancelled
MTSchemaProvisionalMTAppLanguageIdentificationContext
MTSchemaProvisionalMTAppLanguageIdentificationEnded
MTSchemaProvisionalMTAppLanguageIdentificationFailed
MTSchemaProvisionalMTAppLanguageIdentificationInteracted
MTSchemaProvisionalMTAppLanguageIdentificationStarted
MTSchemaProvisionalMTAppTextPasted
MTSchemaProvisionalMTBatchRequestCancelled
MTSchemaProvisionalMTBatchRequestContext
MTSchemaProvisionalMTBatchRequestEnded
MTSchemaProvisionalMTBatchRequestFailed
MTSchemaProvisionalMTBatchRequestStarted
InstrumentationAdditions
MTSchemaProvisionalMTClientEvent
MTSchemaProvisionalMTClientEventMetadata
MTSchemaProvisionalMTError
MTSchemaProvisionalMTInvocationCancelled
MTSchemaProvisionalMTInvocationContext
MTSchemaProvisionalMTInvocationEnded
MTSchemaProvisionalMTInvocationFailed
MTSchemaProvisionalMTInvocationStarted
MTSchemaProvisionalMTLanguagePair
MTSchemaProvisionalMTSessionCancelled
MTSchemaProvisionalMTSessionContext
MTSchemaProvisionalMTSessionEnded
MTSchemaProvisionalMTSessionFailed
MTSchemaProvisionalMTSessionStarted
MTSchemaProvisionalMTSpeechTranslationSignal
MTSchemaProvisionalMTUserFacingSessionSignal
LTArrayExtensions
LTParagraphs
LTLocaleIdentifier
FTUserLanguageProfile
FLTBFBufferAccessor
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTAStarFuzzyMatchingConfig
FTAStarFuzzyMatchingResult
FTAStarFuzzyMatchingRequest
FTAStarFuzzyMatchingResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTTTSWordPhonemes
FTTTSPhonemeSequence
FTTTSNeuralPhonemeSequence
FTTTSPrompts
FTTTSReplacement
FTTTSNormalizedText
FTTextToSpeechFeature
FTTextToSpeechRequestDebug
FTTextToSpeechVoiceResource
FTTextToSpeechUserProfile
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTQssAckResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationFeedbackRequest
FTBatchTranslationResponse
FTBatchTranslationCacheContainer
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableAStarFuzzyMatchingConfig
FTMutableAStarFuzzyMatchingResult
FTMutableAStarFuzzyMatchingRequest
FTMutableAStarFuzzyMatchingResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableTTSWordPhonemes
FTMutableTTSPhonemeSequence
FTMutableTTSNeuralPhonemeSequence
FTMutableTTSPrompts
FTMutableTTSReplacement
FTMutableTTSNormalizedText
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequestDebug
FTMutableTextToSpeechVoiceResource
FTMutableTextToSpeechUserProfile
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableQssAckResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationFeedbackRequest
FTMutableBatchTranslationResponse
FTMutableBatchTranslationCacheContainer
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTAfmService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
format_id
sample_rate
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
audioStreamBasicDescription
init
calendarWithIdentifier:
_featureNameForTask:
stringWithFormat:
date
standardUserDefaults
objectForKey:
_logAllActivityFeature:date:
setObject:forKey:
isDate:inSameDayAsDate:
_logDailyActivityFeature:date:
isDate:equalToDate:toUnitGranularity:
_logWeeklyActivityFeature:date:
_logMonthlyActivityFeature:date:
dictionaryWithObjects:forKeys:count:
components:fromDate:
weekOfYear
year
month
registerActivity:
.cxx_destruct
_calendar
identifier
text
targetRange
numberWithUnsignedInteger:
jsonRepresentation
encodeObject:forKey:
valueWithRange:
decodeObjectOfClass:forKey:
rangeValue
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
setIdentifier:
sourceRange
setSourceRange:
setTargetRange:
setText:
shouldTranslate
setShouldTranslate:
_shouldTranslate
_identifier
_text
_sourceRange
_targetRange
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_identifier
T@"NSString",C,N,V_text
TB,N,V_shouldTranslate
code
numberWithInteger:
domain
dictionaryWithDictionary:
userInfo
objectForKeyedSubscript:
setObject:forKeyedSubscript:
dictionary
initWithName:
markStart
processInfo
systemUptime
numberWithDouble:
addFieldsFromDictionary:internalOnly:
addEntriesFromDictionary:
localizedDescription
addFieldsFromDictionary:
markEnd
sourceLocale
_ltLocaleIdentifier
targetLocale
timedEventWithName:
timestampWithName:
addFieldsWithError:
sendLazy
setSourceLocale:
setTargetLocale:
_eventName
_startTime
_endTime
_queue
_fields
_sourceLocale
_targetLocale
T@"NSLocale",C,N,V_sourceLocale
T@"NSLocale",C,N,V_targetLocale
_ltAsyncMap:queue:completion:
array
count
null
addObject:
setObject:atIndexedSubscript:
enumerateObjectsUsingBlock:
objectEnumerator
nextObject
_ltAsyncMap:completion:
_ltSequentialMap:completion:
_populateWithOpusData:
data
length
bytes
appendBytes:length:
defaultManager
URLByDeletingLastPathComponent
path
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToURL:options:error:
initWithASBD:rawData:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
_asbd
_data
_packetCount
_packetDescriptions
_rawData
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T@"NSData",R,N,V_rawData
Tq,R,N,V_packetCount
T@"NSData",R,N,V_packetDescriptions
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
cleanupOnDisconnect
setInterruptionHandler:
setInvalidationHandler:
valueForEntitlement:
processIdentifier
stringWithUTF8String:
remoteObjectProxy
cancelSpeechSessionWithID:
delegate
clientConnectionClosed:
clearCaches
logRequestOfType:context:
setClientIdentifier:
translateSentence:withContext:completion:
arrayWithObjects:count:
translateParagraphs:withContext:paragraphResult:completion:
_clientDelegate
paragraphTranslation:result:error:
speak:withContext:completion:
isEqual:
setTaskHint:
startTextToSpeechTranslationWithContext:text:delegate:
startSpeechTranslationWithContext:delegate:
addSpeechAudioData:
endAudio
preheatWithContext:completion:
languageForText:completion:
languagesForText:usingModel:completion:
cleanup
route
sharedInstance
logTranslateRequestEvent:requestType:routeType:
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
installedLocales:
startInstallRequest:delegate:
_getAssetSize:
availableLocalePairsForTask:completion:
task:isSupportedInCountry:completion:
additionalLikelyPreferredLocalesForLocale:completion:
configInfoForLocale:otherLocale:completion:
unarchivedObjectOfClasses:fromData:error:
setProcessName:
setClientBundleID:
startLoggingRequest:
_updateHotfix:
_deleteHotfix:
translate:withContext:completion:
translateParagraphs:withContext:completion:
provideFeedback:withContext:
startTextToSpeechTranslationWithContext:text:
startSpeechTranslationWithContext:
languagesForText:completion:
startInstallRequest:
logWithRequestData:
initWithConnection:server:
setDelegate:
_connection
_server
_clientIdentifier
_speechSessionID
_delegate
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
offlineEngine
translatesPair:
onlineEngine
preheatAsynchronously:withContext:
setLanguagesRecognized:
cancelSpeechTranslation
_ltCompactMap:
mutableCopy
removeObject:
translate:withContext:paragraphResult:completion:
countByEnumeratingWithState:objects:count:
endpoint
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
speechRecognitionResult:
translatorDidTranslate:
hasFailed
stopBuffering
translationDidFinishWithError:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechActivityDetected
languageDetectionResult:
languageDetectionCompleted
cancel
languageInstallProgressed:error:
setOfflineEngine:
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
requestContext
setRoute:
forcedOfflineTranslation
_forcedOnlineTranslation
registerDefaults:
_setupMemoryWarningListener
initWithMachServiceName:
_setQueue:
resume
currentRunLoop
notifyOfMemoryPressure
boolValue
initialize
listener:shouldAcceptNewConnection:
_translationListener
_listenerQueue
_connections
stringByAppendingString:
errorWithDomain:code:userInfo:
mainBundle
localizedStringForKey:value:table:
lt_errorWithCode:description:userInfo:
currentLocale
localizedStringForLocaleIdentifier:
lt_internalErrorWithCode:description:userInfo:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_speechTranslationOngoingError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
initWithNode:range:
node
setNode:
range
setRange:
token
setToken:
_node
_token
_range
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
dataWithContentsOfURL:
JSONObjectWithData:options:error:
enumerateKeysAndObjectsUsingBlock:
treeForReplacementTokens:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
URLByAppendingPathComponent:
initWithReplacementTokenDictionary:language:
lowercaseString
enumerateSubstringsInRange:options:usingBlock:
removeObjectsInArray:
removeAllObjects
isEqualToString:
replaceCharactersInRange:withString:
substringWithRange:
replacementStringForString:forToken:
copy
matchesForString:
stringByReplacingMatches:inString:
localeIdentifier
initWithModelURL:language:
sanitizedStringForString:
_replacementTree
_locale
URLForDirectory:inDomain:appropriateForURL:create:error:
contentsOfDirectoryAtPath:error:
firstObject
minimumSupportedConfigurationVersion
intValue
maximumSupportedConfigurationVersion
_downloadHotfix:completion:
_downloadMappingPlist:
removeItemAtURL:error:
defaultSessionConfiguration
set_sourceApplicationBundleIdentifier:
setAllowsCellularAccess:
sessionWithConfiguration:
dataTaskWithURL:completionHandler:
_CDNURL:
propertyListWithData:options:format:error:
_downloadWithURL:completion:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
_decompressArchive:to:error:
stringByAppendingPathComponent:
UTF8String
hotfixURL
updateHotfix:
deleteHotfix:
_hotfixURL
T@"NSURL",R,N,V_hotfixURL
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
processed_audio_duration_ms
decodeInt64ForKey:
decodeDoubleForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
defaultServerEndpointFeatures
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEosLikelihood:
setPauseCounts:
silencePosterior
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
eosLikelihood
pauseCounts
processedAudioDurationInMilliseconds
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
autoEndpoint
endpointAssetInfoWithContext:error:
caesuraModelURL
initWithConfigFile:samplingRate:
localePair
endpointerModelURL:
initWithConfiguration:
requestSupportedWithSamplingRate:
floatValue
updateEndpointerThresholdWithValue:
autodetectLanguage
addAudio:numSamples:
processedAudioMs
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
componentsJoinedByString:
didEndpointWithFeatures:silenceFeatures:endpointer:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
endpointerThreshold
setEndpointerThreshold:
samplingRate
audioBitDepth
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_context
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_samplingRate
_audioBitDepth
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
Tq,R,N,V_audioBitDepth
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
endpointerIsAvailableWithContext:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
attributes
valueForKey:
_ltCsLocaleIdentifier
containsObject:
integerValue
isPremium:
state
getLocalUrl
initWithAvailableAssets:context:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
T@"NSString",R,N,V_hybridepAssetFile
T@"NSString",R,N,V_spgAssetFile
initWithLocales:useCellular:
decodeBoolForKey:
encodeBool:forKey:
initWithLocales:useCellular:progressHandler:
initWithLocales:useCellular:delegate:
_startInstallationWithService:done:
locales
setLocales:
useCellular
setUseCellular:
progressHandler
setProgressHandler:
completionHandler
setCompletionHandler:
_service
_done
_useCellular
_locales
_progressHandler
_completionHandler
T@?,C,N,V_completionHandler
T@"NSArray",C,N,V_locales
TB,N,V_useCellular
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
T@?,C,N,V_progressHandler
localeWithLocaleIdentifier:
languageCode
allKeys
doubleValue
setDominantLanguage:
setConfidences:
dominantLanguage
confidences
isConfident
isFinal
initWithConfidences:isConfident:dominantLanguage:isFinal:
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
languageDetectorAssetWithError:
languageDetectorModelURL
initWithModelURL:
featureCombinationConfigUrl
initWithConfig:
lidThreshold
reversedPair
setSamplingRate:
setWithObjects:
setDictationLanguages:
resetForNewRequest:
haveFinalASRResults
haveAtLeastOneFinalASRResult
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:useFinalThresholds:
sendLIDResult:
locale
modelVersion
sendFinalLanguageDetectionResult:
bestTranscription
confidence
addSamples:numSamples:
cancelCurrentRequest
lastObject
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
startLanguageDetectionWithContext:delegate:
addSpeechRecognitionResult:
cancelLanguageDetection
forceLanguageDetectionResult
acousticResults
setAcousticResults:
lastResult
setLastResult:
featureCombinationModelSupported
setFeatureCombinationModelSupported:
featureCombinationModel
setFeatureCombinationModel:
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_minimumAcousticLanguageDetectorResults
_maximumAcousticLanguageDetectorResults
_endAudioCalled
_useFinalThresholds
_finalLIDResultSent
_receivedPartialSpeechResult
_havePartialASRConfidences
_partialSpeechResultConfidences
_finalSpeechResults
_modelVersions
_lidSignpostID
_resultQueue
_finalResultWaitQueue
_featureCombinationModelSupported
_acousticResults
_lastResult
_featureCombinationModel
T@"NSMutableArray",&,N,V_acousticResults
T@"_LTLanguageDetectionResult",&,N,V_lastResult
TB,N,V_featureCombinationModelSupported
T@"_LTLanguageDetectorFeatureCombinationModel",&,N,V_featureCombinationModel
Td,R,N,V_samplingRate
handleFailureInFunction:file:lineNumber:description:
initWithAssetUrl:featureCombinationAssetUrl:
_assetUrl
_featureCombinationConfigUrl
initWithContentsOfURL:
numberWithUnsignedInt:
modelWithContentsOfURL:error:
modelDescription
initWithShape:dataType:error:
minConfidence
maxConfidence
getAcousticLidConfidenceFromResult:locale:
objectAtIndex:
valueForKeyPath:
cannonicalLocalePair
getModelFeatures:canonicalPair:partialSpeechResultConfidences:finalSpeechResults:modelVersion:
initWithDictionary:error:
predictionFromFeatures:options:error:
featureValueForName:
multiArrayValue
objectAtIndexedSubscript:
oppositeToLocale:
initWithSourceLocale:targetLocale:
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:
_mlModel
_modelInput
_modelInputIsMatrix
_modelOutput
_features
_missingFeatureValueDefault
_missingLanguageDetectorDefault
_languageLocaleToIdentifier
progress
setProgress:
setLocaleIdentifier:
offlineState
setOfflineState:
totalExpected
setTotalExpected:
totalWritten
setTotalWritten:
isStalled
setIsStalled:
expectedTimeRemaining
setExpectedTimeRemaining:
_isStalled
_progress
_localeIdentifier
_offlineState
_totalExpected
_totalWritten
_expectedTimeRemaining
Tq,N,V_progress
T@"NSString",C,N,V_localeIdentifier
TQ,N,V_offlineState
Tq,N,V_totalExpected
Tq,N,V_totalWritten
TB,N,V_isStalled
Td,N,V_expectedTimeRemaining
_LTAssetStateString
finished
setFinished:
status
setStatus:
localIdentifiers
setLocalIdentifiers:
update
setUpdate:
_finished
_status
_localIdentifiers
_update
TB,N,V_finished
TQ,N,V_status
T@"NSArray",&,N,V_localIdentifiers
T@"MAProgressNotification",&,N,V_update
removeObsoleteAssets
compare:
sortedArrayUsingSelector:
componentsSeparatedByString:
identifiersInIdentifiers:forLanguageName:
arrayByAddingObjectsFromArray:
subarrayWithRange:
_configPlistWithFileName:
addObjectsFromArray:
allObjects
pairWithIdentifiers:
hasPrefix:
hasSuffix:
languageToStatusDictionary
installationStatusArray
downloadSize
numberWithLongLong:
updateProgress
allValues
downloadAsset:userInitiated:useCellular:progressCallback:completion:
_setInstalledLocales:
configurationPropertyListWithName:
catalogAssets
installedAssets
setDiscretionary:
setRequiresPowerPluggedIn:
pairNamesForLocales:
assetNamesForPairNames:
substringFromIndex:
_vsLocaleIdentifier
_voiceAssetForLocaleIdentifier:
isInstalled
isBuiltInVoice
sharedManager
languages
gender
genderStringFromGender:
downloadVoiceAsset:options:progressUpdateHandler:
setAutoDownloadedVoiceAssets:
matchingASRAssetForLocale:inAssets:
assetWithName:inAssets:
identifiersInIdentifiers:forAssetName:
downloadAsset:withStatus:
isConfig
purge:
assetsNamesForLocale:
setInstalledLocales:useCellular:completion:
_assetManager
_assetStatusDictionary
_localeIdentifierList
pair
decodeIntegerForKey:
decodeObjectForKey:
encodeInteger:forKey:
initWithLocales:
pairState
setPairState:
setPair:
sourceASRState
setSourceASRState:
targetASRState
setTargetASRState:
mtState
setMtState:
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
needsUpdate
setNeedsUpdate:
_needsUpdate
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
cannonicalIdentifier
_ltEqual:
isPassthrough
copyWithZone:
combinedLocaleIdentifier
isVariantPair
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
conversationID
setConversationID:
requestID
setRequestID:
setLocalePair:
selectedLocale
setSelectedLocale:
lidResult
setLidResult:
_conversationID
_requestID
_localePair
_selectedLocale
_lidResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"_LTLocalePair",C,N,V_localePair
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_lidResult
senses
setSenses:
userInteractedSenses
setUserInteractedSenses:
_senses
_userInteractedSenses
T@"NSArray",C,N,V_senses
T@"NSArray",C,N,V_userInteractedSenses
markResponse
markFirstParagraphComplete
markProgressDone
markPageComplete
dict
start
firstResponse
firstParagraphComplete
progressComplete
pageComplete
processName
_start
_firstResponse
_firstParagraphComplete
_progressComplete
_pageComplete
_processName
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_firstParagraphComplete
Td,R,N,V_progressComplete
Td,R,N,V_pageComplete
T@"NSString",C,N,V_processName
T@"NSDictionary",R,N
blazarServiceWithBundleID:
startSpeechLIDRequest:
startSpeechSensesLoggingRequest:
startSafariLatencyLoggingRequest:
startSafariFeedbackRequest:
mtAppService
performSpeechTranslationWithDelegate:requestBuilder:completion:
setTarget_locale:
setSource_locale:
setDetected_locale:
setLocale:
setConfidence:
setIs_low_confidence:
setPredictions:
setConversation_id:
setRequest_id:
setUser_selected_locale:
setTranslation_locale_pair:
setContentAsFTStartSpeechTranslationLoggingRequest:
sendSpeechTranslationStreamingRequest:
closeStream
setUser_selected_sense:
setUser_interacted_senses:
performBatchTranslationWithDelegate:requestBuilder:completion:
sourceContentAsJSON
setSource_content:
targetContentAsJSON
setTranslated_content:
webpageURL
absoluteString
setUrl:
errorsAsJSON
setErrors:
sessionID
setSession_id:
setSource_language:
setTarget_language:
safariVersion
setSafari_version:
clientBundleID
setApp_id:
operatingSystemVersionString
setOs_version:
setDevice_type:
setContentAsFTBatchTranslationFeedbackRequest:
sendBatchTranslationStreamingRequest:
content_type
contentAsFTFinalBlazarResponse
return_code
return_str
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
_mtAppService
T@"FTBlazarService",R,N,V_mtAppService
initWithModelURL:language:modelVersion:
language
formattedString
triggerServerSideEndPointer
startRecognitionWithAutoStop:resultHandler:
cancelRecognition
initWithModelURLs:modelVersions:
startRecognitionForLocale:autoEndpoint:resultHandler:
_recognizers
_removeOldAssetDirectory
configAsset
getLocalFileUrl
timeIntervalSinceDate:
startCatalogDownload:options:then:
compareAssetVersionReversed:
isDownloading
configAssetInAssets:
_clearCaches
updateAllAssets:
_refreshAllAssets:
_refreshCatalogIfNeededWithCompletion:
results
deleteAsset:completion:
assetsSortedByVersion:
isASRModel
transcribesLocale:
isANEModel
URLByAppendingPathExtension:
bundleForClass:
URLForResource:withExtension:
dataWithContentsOfURL:options:error:
sortUsingComparator:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
availabilityInfo
downloadAsset:downloadOptions:progressCallback:completion:
longLongValue
progressWithTotalUnitCount:
setTotalUnitCount:
setCompletedUnitCount:
attachProgressCallBack:
totalUnitCount
startDownload:then:
_queryLanguagePairStatus:
preferredVoiceGender
arrayWithObject:
setLanguages:
setGender:
_downloadVoiceAsset:
getAutoDownloadedVoiceAssets:
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
assetDirectory
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
_assetIdentifiersForLanguagePairDirectory:
numberWithLong:
_speechTranslationAssetInfoForLocalePair:error:
purgeAssetUserInitiated:queue:completion:
debugDumpAssets:
matchesAsset:
isNewerCompatibleVersionThan:
updateSpeechTranslationAssetSymLinks:
createSymlinkDirectoryForMTAssets
downloadVoiceAssetsForLanguagePair:
downloadAsset:userInitiated:progressCallback:completion:
refreshAllIfNeededWithCompletion:
_downloadPassthroughAssetForLocale:userInitiated:completion:
assetIdentifierReferenceCountDictionary
downloadAssetsUserInitiated:queue:completion:
isCompletePassthroughModel
isCompleteBidirectionalModel
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
getEndpointerAssetWithType:error:
resourceURL
fallBackAssetResourcePath
checkResourceIsReachableAndReturnError:
configurationPropertyListWithURL:
configAssetURL
offlineLanguageStatus:
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
modelURLsForLanguagePair:
speechTranslationAssetInfoForLocalePair:error:
assetSize:
_hotfixMgr
initWithType:
returnTypes:
queryMetaDataSync
initWithSuiteName:
substringToIndex:
setLanguageCode:
outputFileURL
setOutputPath:
audioSessionID
setAudioSessionID:
ttsPlaybackRate
setRate:
setCanUseServerTTS:
startSpeakingRequest:
stopSpeakingAtNextBoundary:synchronously:error:
dictionaryMetrics
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizerDidPauseSpeaking:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:
initWithCompletion:
speak:withContext:
_completion
asrModelURLs
speechModelURLForLocale:
speechModelVersionForLocale:
reason
mtModelURL
translationModelURLs
initWithModelURLs:task:skipNonFinalToCatchup:
loadTranslatorFrom:to:
stringWithCString:encoding:
_loadRecognizers
taskHint
_loadTranslatorForTask:
censorSpeech
_loadEtiquetteSanitizers
tokens
initWithText:confidence:
lowConfidence
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:tokens:preToPostITN:
metaInfo
updateWithEngineMeta:locale:
resultWithLocale:translations:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithIdentifier:range:doNotTranslate:
_handleTranslationResults:withContext:
setSourceString:
setSanitizedSourceString:
translations
translateTokens:from:to:spans:completion:
sanitizedFormattedString
splitIntoSentences
spans
_translateString:withContext:toLocale:withSpans:completion:
_paragraphResultFromSentences:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
_translatePrepare:
passthroughResultWithString:sanitizedString:locale:
uniqueID
translateTokens:isFinal:completion:
prepareFor:to:
UUID
UUIDString
numberWithBool:
_translate:withContext:isFinal:completion:
transcriptions
asrConfidenceThreshold
setLowConfidence:
isLowConfidence
setSanitizedFormattedString:
isStable
_getBestRecognitionResult:context:
_waitForLIDWithContext:completion:
initWithLocalePair:assetInfo:
setAsrModelURLs:
setMtModelURL:
ttsCache
setTtsCache:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_didEndpointSpeech
_earError
_asrModelURLs
_mtModelURL
_ttsCache
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
T@"_LTTextToSpeechCache",&,N,V_ttsCache
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_paragraph
_requestParagraph
T@?,C,N,V_completion
T@"_LTTranslationParagraph",&,N,V_paragraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
request_id
contentAsFTBatchTranslationResponse
paragraph_id
return_string
span
translated_text
initWithOspreyBatchResponse:
updateAlignmentWithSourceSpan:targetSpan:
removeObjectForKey:
setHasFinalServerResponse:
endSuccessfully
endWithError:failedParagraphs:
callCompletionHandlersWithError:
request
setRequest:
toLocale
setToLocale:
batchLog
setBatchLog:
batchedParagraphs
setBatchedParagraphs:
bufferSize
setBufferSize:
setSessionID:
clientHeader
setClientHeader:
clientIdentifier
sourceURL
setSourceURL:
hasFinalServerResponse
completionHandlerCalled
setCompletionHandlerCalled:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_batchLog
_batchedParagraphs
_taskHint
_bufferSize
_sessionID
_clientHeader
_sourceURL
T@"FTMutableBatchTranslationRequest",&,N,V_request
T@"NSLocale",&,N,V_toLocale
T@"LTBatchEventLog",&,N,V_batchLog
T@"NSMutableDictionary",&,N,V_batchedParagraphs
Tq,N,V_taskHint
TQ,N,V_bufferSize
T@"NSLocale",&,N,V_sourceLocale
T@"NSLocale",&,N,V_targetLocale
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
T@"NSString",C,N,V_clientHeader
T@"NSString",&,N,V_clientIdentifier
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
setMaxConcurrentOperationCount:
getSiriDataSharingOptInStatusWithCompletion:
initWithURL:configuration:
setUseCompression:
_webTaskService
_systemService
_blazarService
updateServerTimeout
serverTimeoutFired
sendBatchTranslationRequestWithDelegate:
tokenize:forLocale:
audioDataForKey:
_ospreyTTSRequestWithText:
_serviceForTask:
speech_id
setClientTraceIdentifier:
error_code
error_str
decoder_description
audio
cacheAudioData:forKey:
performTextToSpeechRouter:requestBuilder:completion:
setTranslations:
sequoiaClientHeaderValue
startServerTimeoutTimer
setParagraph_id:
setStart_index:
setEnd_index:
setDo_not_translate:
metaInfoData
initWithData:encoding:
setMeta_info:
setSpan:
cancelServerTimeout
setTask:
setParagraphs:
task
setContentAsFTBatchTranslationRequest:
setContent_type:
setTranslationTask:
setSourceLanguage:
setTargetLanguage:
setDeviceOS:
setDeviceType:
setOsVersion:
setBundleIdentifier:
initWithRequest:
paragraphs
startWithParagraphCount:
setValue:forHTTPHeaderField:
initWithIdentifier:text:spans:
_translateParagraph:index:context:completion:
_hasOngoingSpeechSession
setDataSharingOptInStatus:
initWithService:context:text:delegate:
_speechSessionCompletedWithError:
setCompletionBlock:
sendAudioData:
sendEndAudio
initWithService:context:delegate:
_tokenizeString:inLocale:
serverQueue
setServerQueue:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_dataSharingOptInStatus
_serverQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverQueue
initWithDelegate:
startCompressionNarrowband:
dataSharingOptInStatus
sendAnalyticsEvent
completionBlock
_ospreySpeechTranslationRequestWithHybridEndpointer:
initCommon
_ospreyTextToSpeechTranslationRequestWithText:
updateServerTimeout:
addAudioSampleData:
setPacket_count:
setContentAsFTFinishAudio:
_primaryLanguageRecognized
confirmDataIfNeeded
setContentAsFTLanguageDetected:
setAudio_bytes:
setAudio_frames:
setContentAsFTSpeechTranslationAudioPacket:
source_locale
initWithOspreyPartialRecognitionResponse:isSanitized:
initWithLocaleIdentifier:
initWithOspreyResponse:confidenceThreshold:isSanitized:
server_endpoint_features
initWithOspreySpeechTranslationMTResponse:
is_final_result
target_locale
text_to_speech_response
audio_type
_translationForLocale:
contentAsFTSpeechTranslationPartialRecognitionResponse
_handlePartialRecognitionResponse:
contentAsFTSpeechTranslationFinalRecognitionResponse
_handleFinalRecognitionResponse:
contentAsFTAudioLimitExceeded
_handleAudioLimitExceededResponse:
contentAsFTSpeechTranslationMtResponse
_handleTranslationResponse:
contentAsFTSpeechTranslationTextToSpeechResponse
_handleTTSResponse:
_handleFinalBlazarResponse:
contentAsFTSpeechTranslationServerEndpointFeatures
_handleServerEndpointFeatures:
didCompressPackets:totalPacketCount:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
_streamContext
_sentAudio
_sentEndAudio
_endpointedSpeech
_didReceiveAudioLimitExceededResponse
_didReceivePartialRecognitionResponse
_didReceiveFinalRecognitionResponse
_didReceiveTranslationResponse
_didReceiveTTSResponse
_didReceiveFinalBlazarResponse
_didTimeout
_error
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
Td,N,V_initialOnlineTimeout
Td,N,V_onlineTimeout
Td,N,V_endpointTimeout
T@?,C,N,V_completionBlock
_translationFailedWithError:
string
appendString:
translationParagraph
initWithIdentifier:range:
isValidJSONObject:
dataWithJSONObject:options:error:
setMetaInfoData:
loggingType
_startTranslationWithService:done:
ranges
setRanges:
_ranges
T@"NSArray",C,N,V_ranges
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
dealloc
stop
isAudioQueueRunning
waitForAudioQueueStop
initWithContext:ASBD:
enqueue:packetCount:packetDescriptions:
signalQueueRunningStateChanged
flushAndStop
reset
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
Tq,R,N,V_state
orderedSetWithObjects:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
T@"NSOrderedSet",&,V_requestTypeSet
boolForKey:
arrayForKey:
dictionaryForKey:
URLWithString:
stringByReplacingCharactersInRange:withString:
initWithMaximumPageLoadRequest:maximumDynamicContentRequests:
allowedForRequests:
markPageLoaded
maximumPageLoadRequests
setMaximumPageLoadRequests:
maximumDynamicContentRequests
setMaximumDynamicContentRequests:
_count
_pageLoaded
_maximumPageLoadRequests
_maximumDynamicContentRequests
TQ,N,V_maximumPageLoadRequests
TQ,N,V_maximumDynamicContentRequests
session_id
initWithUUIDString:
app_id
initWithNSUUID:
setSessionId:
setMtId:
setClientAppBundleId:
setNumberOfParagraphs:
makeContext
setStartedOrChanged:
sendWithContext:
setExists:
setEnded:
setDomain:
setErrorCode:
setError:
setNumParagraphFailures:
setFailed:
setReason:
setCancelled:
setContextId:
setEventMetadata:
setBatchRequestContext:
sharedStream
emitMessage:
cancelWithReason:
_playback:context:completion:
initWithEngine:
speak:context:completion:
_engine
_player
enableVAD
initForSeconds:
_startSpeechTranslationWithContext:
_translateSpeechAudioData:
consumeAll:
delegateTranslationDidFinishWithError:
initWithEngine:delegate:
engine
setEngine:
languageDetector
endpointer
_expectFinalLidResult
_sentFinalLidResult
_translationFinished
_speechActivityDetected
_translationError
_cache
_speechDetector
_languageDetector
_endpointer
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
T@"_LTLanguageDetector",R,N,V_languageDetector
T@"_LTHybridEndpointer",R,N,V_endpointer
initWithLocalePair:
setTtsPlaybackRate:
_ttsPlaybackRate
T@"NSString",&,N,V_text
Td,N,V_ttsPlaybackRate
nativeAudioFormat
initWithFormat:
initWithSoundIdentifier:
addRequest:withObserver:error:
initWithStreamDescription:
initWithPCMFormat:frameCapacity:
setFrameLength:
int16ChannelData
analyzeAudioBuffer:atAudioFramePosition:
detected
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
_streamAnalyzer
_position
appendData:
mutableBytes
dataWithBytes:length:
replaceBytesInRange:withBytes:length:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
setData:
next
setNext:
_next
T@"NSData",&,N,V_data
T@"_LTSpeechDataQueueNode",&,N,V_next
_maxFrames
_currentFrames
_head
_tail
setFinal:
setStable:
setModelVersion:
recognition_result
post_itn
recognition_text
containsString:
post_itn_nbest_choices
initWithRecognitionChoice:inSausage:
setTranscriptions:
initWithOspreySausage:choices:locale:
setBestRecognitionAlternatives:
is_stable_result
setFormattedString:
setMinConfidence:
setMaxConfidence:
nBestResults
_transcriptionWithResult:locale:
recognition
initWithRecognition:wordConfidenceThreshold:
initWithFormattedString:locale:confidence:minConfidence:maxConfidence:
initWithPackage:locale:modelVersion:isFinal:
initWithResult:locale:modelVersion:isFinal:
initEmptyResultWithLocale:isFinal:
tokenName
hasSpaceAfter
whitespaceCharacterSet
resultWithPackage:locale:modelVersion:isFinal:
resultWithResult:locale:modelVersion:isFinal:
emptyResultWithLocale:isFinal:
bestRecognitionAlternatives
_final
_stable
_transcriptions
_bestRecognitionAlternatives
_modelVersion
final
TB,N,GisFinal,V_final
stable
TB,N,GisStable,V_stable
T@"NSString",&,N,V_modelVersion
T@"NSLocale",C,N,V_locale
T@"NSArray",&,N,V_transcriptions
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
alternative_index
positional_tok_phrase_alt
tok_phrases
token_text
add_space_after
setHasSpaceAfter:
unsignedIntegerValue
setBestAlternativeIndex:
setAlternatives:
alternatives
setBins:
interpretationIndices
tokenSausage
hasSpaceBefore
bins
_bins
T@"NSArray",&,N,V_bins
bestAlternativeIndex
_alternatives
_bestAlternativeIndex
T@"NSArray",&,N,V_alternatives
TQ,N,V_bestAlternativeIndex
_lowConfidence
_hasSpaceAfter
_confidence
Tq,N,V_confidence
TB,N,GisLowConfidence,V_lowConfidence
TB,N,V_hasSpaceAfter
initWithConfiguration:useQuasarFormatter:
setDetectUtterances:
setConcatenateUtterances:
runRecognitionWithResultStream:language:task:samplingRate:
recognitionHandler
_recognizedResult:error:
detectUtterances
stringWithString:
hatToQsrString:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
modelURL
setRecognitionHandler:
_buffer
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelURL
_language
_recognitionHandler
T@?,C,N,V_recognitionHandler
T@"NSURL",R,N,V_modelURL
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
_formattedString
_sanitizedFormattedString
_minConfidence
_maxConfidence
Td,N,V_confidence
Td,N,V_minConfidence
Td,N,V_maxConfidence
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
_getTranslationConfig
referenceAssets:catalogAssets:
updateAvailableInAssets:
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
isMTModel
isPhrasebook
isCurrentlyAvailable
_mtModelOfflineState
_languagePairDirectory
assetId
createSymbolicLinkAtPath:withDestinationPath:error:
writeToURL:atomically:
moveItemAtURL:toURL:error:
currentProgress
initWithParent:userInfo:
becomeCurrentWithPendingUnitCount:
resignCurrent
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_modelURLs
refreshState
hasResults
_isBuffering
_lastASRResults
_translationResult
_didFinish
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
countForObject:
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
initWithModel:
processString:
languageHypothesesWithMaximum:
availableLocales
detectionForString:
detectionForStrings:
setAvailableLocales:
_availableLocales
T@"NSArray",C,N,V_availableLocales
clear
_cacheQueue
getCharacters:range:
componentsSeparatedByCharactersInSet:
predicateWithFormat:
filteredArrayUsingPredicate:
initWithUnit:
setLanguage:
setString:
enumerateTokensInRange:usingBlock:
stringWithCharacters:length:
sharedConnection
isOnDeviceOnlyTranslationForced
initWithBundleIdentifier:
specifiersForPolicyOptions:force:
groupSpecifierWithID:
rangeOfString:
valueWithNonretainedObject:
setPreferenceValue:specifier:
readPreferenceValue:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
presenterForPrivacySplashWithIdentifier:
setPresentingViewController:
present
specifiers
showTranslatePrivacy
translated_tokens
initWithOspreyToken:
setTokens:
translation_phrase
low_confidence
meta_info
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:locale:
dataUsingEncoding:
statisticsWithEngineMeta:locale:
setStatistics:
sensesFromArray:
senseWithPhrasebookMatchMeta:
preToPostITN
statistics
proToPostITN
setProToPostITN:
_preToPostITN
_tokens
_statistics
_proToPostITN
T@"NSArray",C,N,V_tokens
T@"NSArray",C,N,V_proToPostITN
T@"_LTTranslationStatistics",C,N,V_statistics
T@"NSArray",R,N,V_preToPostITN
setRestricted_mode:
_ospreyDataSharingStatus
setOpt_in_status:
setStreaming_mode:
setTranslation_locale_pairs:
setSpeech_id:
setTask_name:
setCodec:
setStream_results:
setStore_audio:
setEnd_point_mode:
setEnable_server_side_endpoint:
setClient_endpointer_model_version:
setEnable_hybrid_endpoint:
setKeyboard_identifier:
setInput_origin:
setInitial_recognition_candidate_id:
setDisable_auto_punctuation:
setStart_speech_request:
setTranslation_request:
_ttsVoiceStringWithLocale:
setAudio_type:
setChannel_type:
setText_to_speech_requests:
setContentAsFTStartSpeechTranslationRequest:
setTranslation_phrase:
redactIfNeeded:
appendFormat:
sourceOrigin
decodeInt32ForKey:
encodeInt32:forKey:
setUniqueID:
setAutodetectLanguage:
setCensorSpeech:
setOutputFileURL:
setAutoEndpoint:
setLidThreshold:
setAsrConfidenceThreshold:
setEnableVAD:
setAppIdentifier:
setSourceOrigin:
_autodetectLanguage
_censorSpeech
_autoEndpoint
_enableVAD
_audioSessionID
_uniqueID
_outputFileURL
_lidThreshold
_route
_asrConfidenceThreshold
_sourceOrigin
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
TB,N,V_autodetectLanguage
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
TB,N,V_enableVAD
T@"NSString",C,N,V_appIdentifier
Tq,N,V_sourceOrigin
Tq,N,V_dataSharingOptInStatus
setSourceContentAsJSON:
setTargetContentAsJSON:
setErrorsAsJSON:
setSafariVersion:
setWebpageURL:
_sourceContentAsJSON
_targetContentAsJSON
_errorsAsJSON
_safariVersion
_webpageURL
_clientBundleID
T@"NSString",C,N,V_clientBundleID
T@"NSString",C,N,V_sourceContentAsJSON
T@"NSString",C,N,V_targetContentAsJSON
T@"NSString",C,N,V_errorsAsJSON
T@"NSString",C,N,V_safariVersion
T@"NSURL",C,N,V_webpageURL
initWithString:
addAttribute:value:range:
sentences
initWithIdentifier:range:shouldTranslate:metaInfoData:
enumerateAttributesInRange:options:usingBlock:
_spans
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
T@"NSArray",R,C,N,V_spans
initWithIdentifier:text:shouldTranslate:
setMetaInfo:
_metaInfo
TB,R,N,V_shouldTranslate
T@"NSDictionary",C,N,V_metaInfo
_offlineMTModelURL
opaqueSessionID
serviceDelegate
setForcedOfflineTranslation:
set_forcedOnlineTranslation:
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
TB,N,V_forcedOfflineTranslation
TB,N,V__forcedOnlineTranslation
T@"NSURL",&,N,V__offlineMTModelURL
Tq,N,V__mtConfidenceThreshold
ignoringAttributes
initForFutureService
prepareWithService:
_paragraphRequestForText:
_handleParagraphResponse:error:
translate:
textTranslationHandler
alignments
initWithString:attributes:
appendAttributedString:
_realign:identifier:
_constructFinalParagraphResult
sentence
setSentence:
setIgnoringAttributes:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
setTextTranslationHandler:
_session
_savedAttributes
_paragraphOrder
_outstandingCount
_receivedParagraphs
_sentence
_ignoringAttributes
_textHandler
_translationHandler
_textTranslationHandler
T@"NSString",C,N,V_sentence
T@"NSAttributedString",C,N,V_text
T@"NSArray",C,N,V_ignoringAttributes
T@?,C,N,V_textHandler
T@?,C,N,V_translationHandler
T@?,C,N,V_textTranslationHandler
_paragraphs
T@"NSArray",C,N,V_paragraphs
_offlineASRModelURLs
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:simulateRealtime:
format
frameLength
_convertAndFeedPCMBuffer:
sleepForTimeInterval:
subdataWithRange:
_drainAndClearAudioConverter
_simulateRealtimeBehavior:
mutableAudioBufferList
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
appendAudioPCMBuffer:
append:simulateRealtime:
_lidModelURL
set_lidModelURL:
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
T@"NSURL",&,N,V__lidModelURL
T@"NSArray",&,N,V__offlineASRModelURLs
Tq,N,V__asrConfidenceThreshold
Tq,N,V__lidThreshold
initWithLength:
translation_locale_pair
n_best_translated_phrases
start_index
end_index
do_not_translate
setAlignments:
initWithOspreyResponse:
sourceString
sanitizedSourceString
_translations
_sourceString
_sanitizedSourceString
_alignments
T@"NSArray",C,N,V_translations
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
senseID
definition
sourceMatch
targetMatch
senseFromDictionary:
setSenseID:
setDefinition:
setPhrasebookMatch:
isPhrasebookMatch
setSourceMatch:
setTargetMatch:
setLabels:
labels
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
_labels
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
T@"NSArray",C,N,V_labels
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
_speechSessionCompleted
cancelSpeechSession
cleanupOfflineEngine
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
_activityLogger
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
_commonInit
service
setService:
unsignedIntValue
setRateLimiter:
translationQueue
_getServiceProxyWithDelegate:errorHandler:block:
_ensureServiceConnection:
log:
initWithTranslator:
provideFeedback:
setURL:
translator
setTranslator:
rateLimiter
setTranslationQueue:
_outstandingRequests
_logging
_waitingForService
_URL
_rateLimiter
T@"_LTTranslator",&,N,V_translator
T@"<_LTTranslationService>",&,N,V_service
T@"_LTRateLimiter",&,N,V_rateLimiter
T@"NSObject<OS_dispatch_queue>",&,N,V_translationQueue
T@"NSURL",C,N,V_URL
_metaInfoData
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
T@"NSData",C,N,V_metaInfoData
stringByReplacingOccurrencesOfString:withString:options:range:
_ltRemoveAllWhitespaces
_ltTrimWhitespaces
_countWithTokenString:countCharacters:
setInputTokenCount:
setInputSubtokenCount:
allocWithZone:
inputTokenCount
inputSubtokenCount
_inputTokenCount
_inputSubtokenCount
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
_getSyncServiceProxyWithDelegate:errorHandler:block:
initWithMachServiceName:options:
invalidate
remoteObjectProxyWithErrorHandler:
initWithServiceName:options:
synchronousRemoteObjectProxyWithErrorHandler:
archivedDataWithRootObject:requiringSecureCoding:error:
interruptionHandler
installOfflineLocales:completion:
taskIsSupportedInCurrentRegion:completion:
T@?,C,N
preheatForRequestSync:
preheatForRequest:completion:
startTranslationSession
requiredCapabilityIdentifier
assetVersion
isCompatibleWithThisDevice
isNewerVersionThan:
localeIdentifiers
canBePurged
translatesLanguagePair:
formatVersion
dictionaryRepresentation
initWithDictionary:
hasLocale
setHasLocale:
hasConfidence
setHasConfidence:
readFrom:
writeTo:
jsonData
initWithJSON:
_has
Ti,N,V_locale
TB,N
TI,N,V_confidence
T@"NSData",R,N
setSenseId:
senseId
hasSenseId
setHasSenseId:
_senseId
_hasSenseId
T@"NSString",C,N,V_senseId
TB,N,V_hasSenseId
hasReason
setHasReason:
_reason
_hasReason
T@"NSString",C,N,V_reason
TB,N,V_hasReason
setStarted:
started
ended
failed
cancelled
whichContextevent
hasStarted
setHasStarted:
hasEnded
setHasEnded:
setHasFailed:
hasCancelled
setHasCancelled:
_started
_ended
_failed
_cancelled
_hasStarted
_hasEnded
_hasFailed
_hasCancelled
_whichContextevent
T@"MTSchemaProvisionalMTAppLanguageIdentificationStarted",&,N,V_started
TB,N,V_hasStarted
T@"MTSchemaProvisionalMTAppLanguageIdentificationEnded",&,N,V_ended
TB,N,V_hasEnded
T@"MTSchemaProvisionalMTAppLanguageIdentificationFailed",&,N,V_failed
TB,N,V_hasFailed
T@"MTSchemaProvisionalMTAppLanguageIdentificationCancelled",&,N,V_cancelled
TB,N,V_hasCancelled
TQ,R,N,V_whichContextevent
setAlternateLocale:
alternateLocale
hasSelectedLocale
hasAlternateLocale
setHasSelectedLocale:
setHasAlternateLocale:
_alternateLocale
_hasSelectedLocale
_hasAlternateLocale
T@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence",&,N,V_selectedLocale
TB,N,V_hasSelectedLocale
T@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence",&,N,V_alternateLocale
TB,N,V_hasAlternateLocale
error
hasError
setHasError:
_hasError
T@"MTSchemaProvisionalMTError",&,N,V_error
TB,N,V_hasError
setUserSelectedLocale:
userSelectedLocale
hasUserSelectedLocale
setHasUserSelectedLocale:
_userSelectedLocale
_hasUserSelectedLocale
T@"NSString",C,N,V_userSelectedLocale
TB,N,V_hasUserSelectedLocale
exists
hasExists
setHasExists:
_exists
TB,N,V_exists
setInputSourceAppBundleId:
inputSourceAppBundleId
hasInputSourceAppBundleId
setHasInputSourceAppBundleId:
_inputSourceAppBundleId
_hasInputSourceAppBundleId
T@"NSString",C,N,V_inputSourceAppBundleId
TB,N,V_hasInputSourceAppBundleId
contextId
startedOrChanged
hasContextId
setHasContextId:
hasStartedOrChanged
setHasStartedOrChanged:
_contextId
_startedOrChanged
_hasContextId
_hasStartedOrChanged
T@"SISchemaUUID",&,N,V_contextId
TB,N,V_hasContextId
T@"MTSchemaProvisionalMTBatchRequestStarted",&,N,V_startedOrChanged
TB,N,V_hasStartedOrChanged
T@"MTSchemaProvisionalMTBatchRequestEnded",&,N,V_ended
T@"MTSchemaProvisionalMTBatchRequestFailed",&,N,V_failed
T@"MTSchemaProvisionalMTBatchRequestCancelled",&,N,V_cancelled
numParagraphFailures
hasNumParagraphFailures
setHasNumParagraphFailures:
_numParagraphFailures
TI,N,V_numParagraphFailures
numberOfParagraphs
hasNumberOfParagraphs
setHasNumberOfParagraphs:
_numberOfParagraphs
TI,N,V_numberOfParagraphs
getAnyEventType
isProvisional
getTypeId
getVersion
setInvocationContext:
setSessionContext:
setAppTextPasted:
setAppLIDContext:
setAppLIDInteracted:
setAppDisambiguationInteracted:
setSpeechRecognitionSignal:
setUserFacingSessionSignal:
eventMetadata
batchRequestContext
invocationContext
sessionContext
appTextPasted
appLIDContext
appLIDInteracted
appDisambiguationInteracted
speechRecognitionSignal
userFacingSessionSignal
whichEvent_Type
hasEventMetadata
setHasEventMetadata:
hasBatchRequestContext
setHasBatchRequestContext:
hasInvocationContext
setHasInvocationContext:
hasSessionContext
setHasSessionContext:
hasAppTextPasted
setHasAppTextPasted:
hasAppLIDContext
setHasAppLIDContext:
hasAppLIDInteracted
setHasAppLIDInteracted:
hasAppDisambiguationInteracted
setHasAppDisambiguationInteracted:
hasSpeechRecognitionSignal
setHasSpeechRecognitionSignal:
hasUserFacingSessionSignal
setHasUserFacingSessionSignal:
_eventMetadata
_batchRequestContext
_invocationContext
_sessionContext
_appTextPasted
_appLIDContext
_appLIDInteracted
_appDisambiguationInteracted
_speechRecognitionSignal
_userFacingSessionSignal
_hasEventMetadata
_hasBatchRequestContext
_hasInvocationContext
_hasSessionContext
_hasAppTextPasted
_hasAppLIDContext
_hasAppLIDInteracted
_hasAppDisambiguationInteracted
_hasSpeechRecognitionSignal
_hasUserFacingSessionSignal
_whichEvent_Type
T@"MTSchemaProvisionalMTClientEventMetadata",&,N,V_eventMetadata
TB,N,V_hasEventMetadata
T@"MTSchemaProvisionalMTBatchRequestContext",&,N,V_batchRequestContext
TB,N,V_hasBatchRequestContext
T@"MTSchemaProvisionalMTInvocationContext",&,N,V_invocationContext
TB,N,V_hasInvocationContext
T@"MTSchemaProvisionalMTSessionContext",&,N,V_sessionContext
TB,N,V_hasSessionContext
T@"MTSchemaProvisionalMTAppTextPasted",&,N,V_appTextPasted
TB,N,V_hasAppTextPasted
T@"MTSchemaProvisionalMTAppLanguageIdentificationContext",&,N,V_appLIDContext
TB,N,V_hasAppLIDContext
T@"MTSchemaProvisionalMTAppLanguageIdentificationInteracted",&,N,V_appLIDInteracted
TB,N,V_hasAppLIDInteracted
T@"MTSchemaProvisionalMTAppDisambiguationInteracted",&,N,V_appDisambiguationInteracted
TB,N,V_hasAppDisambiguationInteracted
T@"MTSchemaProvisionalMTSpeechTranslationSignal",&,N,V_speechRecognitionSignal
TB,N,V_hasSpeechRecognitionSignal
T@"MTSchemaProvisionalMTUserFacingSessionSignal",&,N,V_userFacingSessionSignal
TB,N,V_hasUserFacingSessionSignal
TQ,R,N,V_whichEvent_Type
mtId
sessionId
clientAppBundleId
hasMtId
hasSessionId
hasClientAppBundleId
setHasMtId:
setHasSessionId:
setHasClientAppBundleId:
_mtId
_sessionId
_clientAppBundleId
_hasMtId
_hasSessionId
_hasClientAppBundleId
T@"SISchemaUUID",&,N,V_mtId
TB,N,V_hasMtId
T@"SISchemaUUID",&,N,V_sessionId
TB,N,V_hasSessionId
T@"NSString",C,N,V_clientAppBundleId
TB,N,V_hasClientAppBundleId
errorCode
hasDomain
hasErrorCode
setHasErrorCode:
setHasDomain:
_domain
_errorCode
_hasDomain
T@"NSString",C,N,V_domain
TB,N,V_hasDomain
TI,N,V_errorCode
T@"MTSchemaProvisionalMTInvocationStarted",&,N,V_startedOrChanged
T@"MTSchemaProvisionalMTInvocationEnded",&,N,V_ended
T@"MTSchemaProvisionalMTInvocationFailed",&,N,V_failed
T@"MTSchemaProvisionalMTInvocationCancelled",&,N,V_cancelled
setIsOnDeviceTranslationEnabled:
setMobileAssetConfigVersion:
setMtLanguagePair:
setInputMode:
setIsExplicitLanguageFilterEnabled:
setIsLanguageIdentificationEnabled:
setUiMode:
mobileAssetConfigVersion
mtLanguagePair
isOnDeviceTranslationEnabled
inputMode
isExplicitLanguageFilterEnabled
isLanguageIdentificationEnabled
uiMode
hasIsOnDeviceTranslationEnabled
setHasIsOnDeviceTranslationEnabled:
hasMobileAssetConfigVersion
hasTask
setHasTask:
hasMtLanguagePair
hasInputMode
setHasInputMode:
hasIsExplicitLanguageFilterEnabled
setHasIsExplicitLanguageFilterEnabled:
hasIsLanguageIdentificationEnabled
setHasIsLanguageIdentificationEnabled:
hasUiMode
setHasUiMode:
setHasMobileAssetConfigVersion:
setHasMtLanguagePair:
_isOnDeviceTranslationEnabled
_mobileAssetConfigVersion
_task
_mtLanguagePair
_inputMode
_isExplicitLanguageFilterEnabled
_isLanguageIdentificationEnabled
_uiMode
_hasMobileAssetConfigVersion
_hasMtLanguagePair
TB,N,V_isOnDeviceTranslationEnabled
T@"NSString",C,N,V_mobileAssetConfigVersion
TB,N,V_hasMobileAssetConfigVersion
Ti,N,V_task
T@"MTSchemaProvisionalMTLanguagePair",&,N,V_mtLanguagePair
TB,N,V_hasMtLanguagePair
Ti,N,V_inputMode
TB,N,V_isExplicitLanguageFilterEnabled
TB,N,V_isLanguageIdentificationEnabled
Ti,N,V_uiMode
sourceLanguage
targetLanguage
hasSourceLanguage
setHasSourceLanguage:
hasTargetLanguage
setHasTargetLanguage:
_sourceLanguage
_targetLanguage
Ti,N,V_sourceLanguage
Ti,N,V_targetLanguage
T@"MTSchemaProvisionalMTSessionStarted",&,N,V_started
T@"MTSchemaProvisionalMTSessionEnded",&,N,V_ended
T@"MTSchemaProvisionalMTSessionFailed",&,N,V_failed
T@"MTSchemaProvisionalMTSessionCancelled",&,N,V_cancelled
setSpeechRequestStatus:
speechRequestStatus
hasSpeechRequestStatus
setHasSpeechRequestStatus:
_speechRequestStatus
Ti,N,V_speechRequestStatus
setUserFacingSessionStatus:
userFacingSessionStatus
hasUserFacingSessionStatus
setHasUserFacingSessionStatus:
_userFacingSessionStatus
Ti,N,V_userFacingSessionStatus
arrayWithCapacity:
arrayWithArray:
initWithAttributedString:
rangeOfCharacterFromSet:
rangeOfCharacterFromSet:options:
tokensForRange:
attributedSubstringFromRange:
_ltAttributedStringByTrimmingCharactersInSet:
T@"NSArray",R,N
stringByReplacingOccurrencesOfString:withString:
initWithFlatbuffData:root:verify:
initWithBytes:length:encoding:
profile_blob:
profile_blob_version
profile_checksum
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
profile_blob
_storage
_root
acoustic_profile_version
acoustic_profile_blob:
acoustic_profile_blob
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
phone_seq
ipa_phone_seq
Ti,R,N
TB,R,N
has_unsuggested_alternatives
numberWithInt:
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
pre_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
T@"FTRecognitionSausage",R,N
bool_stats
int32_stats
double_stats
request_locale
name
value
Td,R,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
numberWithFloat:
acoustic_feature_per_frame
frame_duration
Tf,R,N
speech_recognition_features
acoustic_features
T@"FTAcousticFeature",R,N
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",R,N
Tq,R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,R,N
TI,R,N
start_speech_request
user_parameters
primary_speech_id
T@"FTStartSpeechRequest",R,N
product_id
vendor_id
contextual_text
pron_hints
left_context
right_context
context_with_pron_hints
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
audio_bytes:
audio_bytes
packet_count
total_audio_recorded_seconds
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
orthography
pronunciations:
frequency
pronunciations
category_name
category_data
user_data
incomplete_profile
recreate_apg_prons
phonemes
blob:
blob
apg_id
voc_token
tts_pronunciations
human_readable_prons
T@"FTVocToken",R,N
apg_ids
recovery_return_codes
voc_tokens
num_of_requested
num_of_processed
num_of_succeeded
words_list
formatted_words_list
post_itn_string
nbest_variants_max
normalized_tokens
original_token
nbest_variants
pron_sequence
log_weight
pron_source
sanitized_sequences
prons
normalized_prons
sanitized_tokens
T@"FTContextWithPronHints",R,N
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
jit_token_prons
index
raw_sausage
raw_nbest_choices
post_itn_tokens
post_itn_recognition
itn_alignments
pre_itn_payload
post_itn_payload
pre_sausage_payload
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
engine_input
engine_output
mt_alignment
T@"FTAlignment",R,N
end_point_likelihood
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
match_ids
debug_information
matcher_id
query
target
config
T@"FTAStarFuzzyMatchingConfig",R,N
latency
expanded_path
keyword_orthography
posterior
keywords
enable_sanitization
corrected_sausage
n_best_list
original_utterance
corrected_utterance
original_words
corrected_words
corrections
fe_feature
fe_feature_only
disable_prompts
cache_only
quality
type
voice
resource
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
channel_type
is_synthesis
context_info
dialog_identifier
experiment_identifier
word_phonemes
prompts
prompts_v2:
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data:
resources
enable_word_timing_info
voice_name
preferred_voice_type
context
experiment
feature_flags
debug
profile
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTTextToSpeechRequestDebug",R,N
T@"FTTextToSpeechUserProfile",R,N
word
sample_idx
offset
timestamp
audio:
playback_description
word_timing_info
feature
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_meta_info
cache_object
T@"FTTextToSpeechCacheMetaInfo",R,N
endpoint_threshold
endpoint_extra_delay
audio_frames
conversation_id
translation_locale_pairs
translation_request
text_to_speech_requests
restricted_mode
streaming_mode
T@"FTTranslationRequest",R,N
detected_locale
user_selected_locale
user_selected_sense
user_interacted_senses
T@"FTTranslationLocalePair",R,N
T@"FTLanguageDetected",R,N
T@"FTTextToSpeechResponse",R,N
T@"FTServerEndpointFeatures",R,N
utterance
shortcuts
interaction_id
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
raw_string
shortcut_score_pairs
shortcut
similarity_score
language_parameters_by_id
is_low_confidence
predictions
source_content
translated_content
errors
safari_version
os_version
sentence_count
contentAsFTStartPronGuessRequest
contentAsFTAudioPacket
contentAsFTFinishAudio
contentAsFTCancelRequest
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
contentAsFTPronGuessResponse
T@"FTPronGuessResponse",R,N
contentAsFTStartBatchRecoverRequest
T@"FTStartBatchRecoverRequest",R,N
contentAsFTBatchRecoverFinalResponse
T@"FTBatchRecoverFinalResponse",R,N
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
contentAsFTSetRequestOrigin
contentAsFTSetSpeechContext
contentAsFTSetSpeechProfile
contentAsFTSetEndpointerState
contentAsFTResetServerEndpointer
contentAsFTCheckForSpeechRequest
contentAsFTSetAlternateRecognitionSausage
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
contentAsFTFinalSpeechRecognitionResponse
contentAsFTPartialSpeechRecognitionResponse
contentAsFTUpdatedAcousticProfile
contentAsFTEndPointLikelihood
contentAsFTEndPointCandidate
contentAsFTRecognitionProgress
contentAsFTCheckForSpeechResponse
contentAsFTRecognitionCandidate
contentAsFTRequestStatsResponse
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
contentAsFTMultiUserStartSpeechRequest
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
contentAsFTStartMultilingualSpeechRequest
contentAsFTLanguageDetected
T@"FTStartMultilingualSpeechRequest",R,N
contentAsFTStartSpeechTranslationRequest
contentAsFTSpeechTranslationAudioPacket
contentAsFTStartSpeechTranslationLoggingRequest
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
contentAsFTBatchTranslationRequest
contentAsFTBatchTranslationFeedbackRequest
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationFeedbackRequest",R,N
T@"FTBatchTranslationResponse",R,N
contentAsFTStartTextToSpeechStreamingRequest
T@"FTStartTextToSpeechStreamingRequest",R,N
contentAsFTBeginTextToSpeechStreamingResponse
contentAsFTPartialTextToSpeechStreamingResponse
contentAsFTFinalTextToSpeechStreamingResponse
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
contentAsFTQssAckResponse
T@"FTQssAckResponse",R,N
contentAsFTStartLanguageDetectionRequest
T@"FTStartLanguageDetectionRequest",R,N
contentAsFTLanguageDetectionResponse
T@"FTLanguageDetectionResponse",R,N
setProfile_blob:
setProfile_blob_version:
setProfile_checksum:
T@"NSData",C,N
T@"NSString",C,N
setAcoustic_profile_version:
setAcoustic_profile_blob:
initWithInt:
initWithBool:
setToken_text:
setStart_milli_seconds:
setEnd_milli_seconds:
setSilence_start_milli_seconds:
setAdd_space_after:
setPhone_seq:
setIpa_phone_seq:
Ti,N
T@"NSArray",C,N
setTok_phrases:
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
setItn_alignment:
setPost_itn_choice_indices:
setPre_itn_token_to_post_itn_char_alignments:
setPre_itn:
setPost_itn:
setPre_itn_nbest_choices:
setPost_itn_nbest_choices:
setPre_itn_token_to_post_itn_char_alignment:
setChoice_alignments:
T@"FTRecognitionSausage",C,N
setBool_stats:
setInt32_stats:
setDouble_stats:
setRequest_locale:
setName:
setValue:
initWithDouble:
Td,N
setFirst_pre_itn_token_index:
setLast_pre_itn_token_index:
setFirst_post_itn_char_pos:
setLast_post_itn_char_pos:
initWithFloat:
setAcoustic_feature_per_frame:
setFrame_duration:
Tf,N
setSpeech_recognition_features:
setAcoustic_features:
setKey:
T@"FTAcousticFeature",C,N
initWithInteger:
setReturn_code:
setReturn_str:
setRecognition_result:
setLang_profile_recreate_codes:
setAudio_analytics:
setWatermark_detection:
setWatermark_peak_average:
setLatnn_mitigator_result:
setHas_result:
T@"FTRecognitionResult",C,N
Tq,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
setRecognition_text:
setIs_stable_result:
setAudio_duration_ms:
unsignedLongValue
initWithUnsignedLong:
initWithUnsignedInteger:
setDevice_os:
setMic_type:
setUdm_host:
setUdm_port:
setTandem_mode:
setStream_unstable_results:
setStart_audio_bookmark:
setIs_far_field:
setEnable_utterance_detection:
setEnable_endpoint_candidate:
setStart_recognition_at:
setStart_endpointing_at:
setKeyboard_dictation:
setExperiment_id:
setSpeech_request_source:
setFork_id:
setApplication_name:
setMetadata:
TQ,N
TI,N
setUser_parameters:
setPrimary_speech_id:
T@"FTStartSpeechRequest",C,N
setProduct_id:
setVendor_id:
setContextual_text:
setPron_hints:
setLeft_context:
setRight_context:
setContext_with_pron_hints:
setUser_language_profile:
setUser_acoustic_profile:
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
setTotal_audio_recorded_seconds:
setFeatures_at_endpoint:
setServer_feature_latency_distribution:
setUpdated_acoustic_profile:
setOrthography:
setPronunciations:
setFrequency:
setTag:
setAttributes:
setCategory_name:
setCategory_data:
setUser_data:
setError_code:
setError_str:
setIncomplete_profile:
setRecreate_apg_prons:
setPhonemes:
setBlob:
setApg_id:
setVoc_token:
setTts_pronunciations:
setHuman_readable_prons:
T@"FTVocToken",C,N
setApg_ids:
setRecovery_return_codes:
setVoc_tokens:
setNum_of_requested:
setNum_of_processed:
setNum_of_succeeded:
setWords_list:
setFormatted_words_list:
setPost_itn_string:
setNbest_variants_max:
setNormalized_tokens:
setOriginal_token:
setNbest_variants:
setPron_sequence:
setLog_weight:
setPron_source:
setSanitized_sequences:
setProns:
setNormalized_prons:
setSanitized_tokens:
T@"FTContextWithPronHints",C,N
setIs_pron_guessed:
setG2p_version:
setG2p_model_version:
setPhoneset_version:
setAot_token_prons:
setJit_token_prons:
setIndex:
setRaw_sausage:
setRaw_nbest_choices:
setPost_itn_tokens:
setPost_itn_recognition:
setItn_alignments:
setPre_itn_payload:
setPost_itn_payload:
setPre_sausage_payload:
setSpans:
setSiri_translation_info:
setSpeech_translation_info:
setSiri_payload_translation_info:
setSequence_id:
setWeb_translation_info:
setDisable_log:
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
setReturn_string:
setN_best_translated_phrases:
setEngine_input:
setEngine_output:
setMt_alignment:
T@"FTAlignment",C,N
setTranslated_tokens:
setLow_confidence:
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
setLatitude:
setLongitude:
setEnable_geo_location_features:
longValue
initWithLong:
setSpeech_packet_count:
setProcessed:
setVersion:
setThreshold:
setScore:
setResult_id:
setSnr:
setFingerprint_detection:
setStart_speech_time:
setEnd_speech_time:
setSpeech_detected:
setAudio_packets:
setRef_transcript:
setBlamer_report:
setToken_str:
setLog10_score:
setNgram_used:
setTranscript:
setPpl:
setEnable_completion:
setMax_results:
setMax_expand_paths:
setMax_tm_score:
setAbs_pruning_threshold:
setRel_pruning_threshold:
setEnable_word_boundary:
setMax_path_num_at_boundary:
setParabolic_error_wide:
setParabolic_error_center:
setParabolic_error_bias:
setParabolic_error_min:
setMax_latency:
setWord_penalty:
setDelimiter:
setMatched_result:
setTotal_score:
setTm_score:
setMatch_ids:
setDebug_information:
setMatcher_id:
setQuery:
setTarget:
setConfig:
T@"FTAStarFuzzyMatchingConfig",C,N
setLatency:
setExpanded_path:
setResults:
setKeyword_orthography:
setPosterior:
setKeywords:
setEnable_sanitization:
setCorrected_sausage:
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
setOriginal_utterance:
setCorrected_utterance:
setOriginal_words:
setCorrected_words:
setCorrections:
setFe_feature:
setFe_feature_only:
setDisable_prompts:
setCache_only:
setQuality:
setType:
setVoice:
setResource:
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
setIs_synthesis:
setContext_info:
setDialog_identifier:
setExperiment_identifier:
setWord_phonemes:
setPrompts:
setPrompts_v2:
setOriginal:
setReplacement:
setNormalized_text:
setPhoneme_sequence:
setNeural_phoneme_sequence:
setForce_use_tts_service:
setDisable_cache:
setResources:
setEnable_word_timing_info:
setVoice_name:
setPreferred_voice_type:
setContext:
setExperiment:
setFeature_flags:
setDebug:
setProfile:
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
T@"FTTextToSpeechRequestDebug",C,N
T@"FTTextToSpeechUserProfile",C,N
setSample_rate:
setFormat_id:
setFormat_flags:
setBytes_per_packet:
setFrames_per_packet:
setBytes_per_frame:
setChannels_per_frame:
setBits_per_channel:
setReserved:
setWord:
setSample_idx:
setOffset:
setLength:
setTimestamp:
setAudio:
setDecoder_description:
setPlayback_description:
setWord_timing_info:
setFeature:
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setCurrent_pkt_number:
setTotal_pkt_number:
setAudio_length:
setOriginal_session_id:
setCache_meta_info:
setCache_object:
T@"FTTextToSpeechCacheMetaInfo",C,N
setEndpoint_threshold:
setEndpoint_extra_delay:
T@"FTTranslationRequest",C,N
T@"FTTranslationLocalePair",C,N
T@"FTLanguageDetected",C,N
setIs_final_result:
setText_to_speech_response:
T@"FTTextToSpeechResponse",C,N
setServer_endpoint_features:
T@"FTServerEndpointFeatures",C,N
setUtterance:
setShortcuts:
setInteraction_id:
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
setRaw_string:
setShortcut_score_pairs:
setShortcut:
setSimilarity_score:
setLanguage_parameters_by_id:
setTranslated_text:
setSentence_count:
setContentAsFTStartPronGuessRequest:
setContentAsFTAudioPacket:
setContentAsFTCancelRequest:
T@"FTStartPronGuessRequest",C,N
T@"FTAudioPacket",C,N
T@"FTFinishAudio",C,N
T@"FTCancelRequest",C,N
setContentAsFTPronGuessResponse:
T@"FTPronGuessResponse",C,N
setContentAsFTStartBatchRecoverRequest:
T@"FTStartBatchRecoverRequest",C,N
setContentAsFTBatchRecoverFinalResponse:
T@"FTBatchRecoverFinalResponse",C,N
setContentAsFTStartSpeechRequest:
setContentAsFTUpdateAudioInfo:
setContentAsFTSetRequestOrigin:
setContentAsFTSetSpeechContext:
setContentAsFTSetSpeechProfile:
setContentAsFTSetEndpointerState:
setContentAsFTResetServerEndpointer:
setContentAsFTCheckForSpeechRequest:
setContentAsFTSetAlternateRecognitionSausage:
T@"FTUpdateAudioInfo",C,N
T@"FTSetRequestOrigin",C,N
T@"FTSetSpeechContext",C,N
T@"FTSetSpeechProfile",C,N
T@"FTSetEndpointerState",C,N
T@"FTResetServerEndpointer",C,N
T@"FTCheckForSpeechRequest",C,N
T@"FTSetAlternateRecognitionSausage",C,N
setContentAsFTFinalSpeechRecognitionResponse:
setContentAsFTPartialSpeechRecognitionResponse:
setContentAsFTUpdatedAcousticProfile:
setContentAsFTEndPointLikelihood:
setContentAsFTEndPointCandidate:
setContentAsFTRecognitionProgress:
setContentAsFTCheckForSpeechResponse:
setContentAsFTRecognitionCandidate:
setContentAsFTRequestStatsResponse:
setContentAsFTServerEndpointFeatures:
setContentAsFTClientSetupInfo:
setContentAsFTAudioLimitExceeded:
T@"FTFinalSpeechRecognitionResponse",C,N
T@"FTPartialSpeechRecognitionResponse",C,N
T@"FTUpdatedAcousticProfile",C,N
T@"FTEndPointLikelihood",C,N
T@"FTEndPointCandidate",C,N
T@"FTRecognitionProgress",C,N
T@"FTCheckForSpeechResponse",C,N
T@"FTRecognitionCandidate",C,N
T@"FTRequestStatsResponse",C,N
T@"FTClientSetupInfo",C,N
T@"FTAudioLimitExceeded",C,N
setContentAsFTMultiUserStartSpeechRequest:
T@"FTMultiUserStartSpeechRequest",C,N
setContentAsFTFinalBlazarResponse:
T@"FTFinalBlazarResponse",C,N
setContentAsFTStartMultilingualSpeechRequest:
T@"FTStartMultilingualSpeechRequest",C,N
T@"FTStartSpeechTranslationRequest",C,N
T@"FTSpeechTranslationAudioPacket",C,N
T@"FTStartSpeechTranslationLoggingRequest",C,N
setContentAsFTSpeechTranslationPartialRecognitionResponse:
setContentAsFTSpeechTranslationFinalRecognitionResponse:
setContentAsFTSpeechTranslationMtResponse:
setContentAsFTSpeechTranslationTextToSpeechResponse:
setContentAsFTSpeechTranslationServerEndpointFeatures:
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
T@"FTSpeechTranslationMtResponse",C,N
T@"FTSpeechTranslationTextToSpeechResponse",C,N
T@"FTSpeechTranslationServerEndpointFeatures",C,N
T@"FTBatchTranslationRequest",C,N
T@"FTBatchTranslationFeedbackRequest",C,N
setContentAsFTBatchTranslationResponse:
T@"FTBatchTranslationResponse",C,N
setContentAsFTStartTextToSpeechStreamingRequest:
T@"FTStartTextToSpeechStreamingRequest",C,N
setContentAsFTBeginTextToSpeechStreamingResponse:
setContentAsFTPartialTextToSpeechStreamingResponse:
setContentAsFTFinalTextToSpeechStreamingResponse:
T@"FTBeginTextToSpeechStreamingResponse",C,N
T@"FTPartialTextToSpeechStreamingResponse",C,N
T@"FTFinalTextToSpeechStreamingResponse",C,N
setContentAsFTQssAckResponse:
T@"FTQssAckResponse",C,N
setContentAsFTStartLanguageDetectionRequest:
T@"FTStartLanguageDetectionRequest",C,N
setContentAsFTLanguageDetectionResponse:
T@"FTLanguageDetectionResponse",C,N
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithGRPCStreamingCallContext:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
performTranslation:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
performAStarFuzzyMatching:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
writeFrame:
finishWriting
sendPronGuessStreamingRequest:
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
@16@0:8
v24@0:8q16
v32@0:8q16@24
@24@0:8q16
v16@0:8
@"NSCalendar"
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v20@0:8B16
@"NSString"
{_NSRange="location"Q"length"Q}
v28@0:8@16B24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSLocale"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
B24@0:8@16
q16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
v32@0:8@16@?24
v40@0:8@16@24@?32
v32@0:8@16@24
v40@0:8@16Q24@?32
v24@0:8@?16
v36@0:8@16B24@?28
v32@0:8q16@?24
v40@0:8q16@24@?32
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v24@0:8@"NSData"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSArray"16Q24@?<v@?@"_LTTextLanguageDetectionResult">32
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?q@"NSError">16
v24@0:8@"_LTInstallRequest"16
v32@0:8q16@?<v@?@"NSArray">24
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
@32@0:8@16@24
@"NSXPCConnection"
@"_LTTranslationServer"
@"NSUUID"
@"<_LTClientConnectionDelegate>"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
v32@0:8@"NSArray"16@"NSError"24
v28@0:8B16@20
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@"<_LTSpeechTranslationDelegate>"
@"<_LTTranslationEngine>"
@"_LTSpeechTranslationResultsBuffer"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"NSMutableArray"
@40@0:8q16@24@32
@40@0:8@16{_NSRange=QQ}24
@"NSDictionary"
v40@0:8@16@24^@32
@"NSURL"
d16@0:8
v24@0:8d16
@"NSArray"
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTTranslationContext"
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"NSNumber"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
@40@0:8@16@24@32
@"MAAsset"
@28@0:8@16B24
@36@0:8@16B24@?28
@36@0:8@16B24@28
@?16@0:8
@"<_LTTranslationService>"
@40@0:8@16B24@28B36
v36@0:8@16@24B32
v24@0:8Q16
v36@0:8@"NSString"16@"NSDictionary"24B32
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@"_LTLanguageDetectorFeatureCombinationModel"
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@"MLModel"
@"MAProgressNotification"
@"_LTOfflineAssetManager"
@"_LTLocalePair"
@24@0:8^{_NSZone=}16
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v24@0:8@"FTBatchTranslationStreamingResponse"16
@"FTBlazarService"
v44@0:8@16B24@?28@?36
v48@0:8@16B24B28@?32@?40
v28@0:8B16@?20
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
@24@0:8^@16
@"_LTHotfixManager"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v44@0:8@16B24@28@36
v36@0:8@16B24@28
v40@0:8@16{_NSRange=QQ}24
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v24@0:8@"VSSpeechSynthesizer"16
v44@0:8@"VSSpeechSynthesizer"16B24@"NSString"28@"NSError"36
v36@0:8@"VSSpeechSynthesizer"16B24@"NSError"28
v44@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSError"36
v40@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@?40@?48
v44@0:8@16@24B32@?36
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
@"NSError"
@"_LTTextToSpeechCache"
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
@"FTMutableBatchTranslationRequest"
@"LTBatchEventLog"
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"NSDate"
@"AFSettingsConnection"
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@48@0:8@16@24@32@40
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
v40@0:8@16@24q32
@"NSOrderedSet"
@32@0:8Q16q24
B24@0:8Q16
@"_LTPlaybackService"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"_LTSpeechDataQueue"
@"_LTSpeechActivityDetector"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@"SNAudioStreamAnalyzer"
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@"_LTSpeechDataQueueNode"
@24@0:8d16
@36@0:8@16q24B32
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
@32@0:8@16q24
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARSpeechRecognitionResultPackage"
@56@0:8@16@24d32d40d48
v36@0:8B16@20@?28
@"_LTTranslationResult"
@64@0:8@16q24@32@40@48@56
@"NSCountedSet"
@24@0:8Q16
@"NLLanguageRecognizer"
@60@0:8@16@24d32B40@44@52
@"_LTTranslationStatistics"
@20@0:8B16
I16@0:8
v20@0:8I16
@36@0:8@16@24B32
@"_LTTranslationSession"
@"_LTTextToSpeechTranslationRequest"
@"NSAttributedString"
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"_LTActivityLogging"
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
@"_LTRateLimiter"
@52@0:8@16{_NSRange=QQ}24B40@44
q28@0:8@16B24
@32@0:8@16d24
v40@0:8@16@?24@?32
q24@0:8@16
v20@0:8i16
i16@0:8
{?="locale"b1"confidence"b1}
@"MTSchemaProvisionalMTAppLanguageIdentificationStarted"
@"MTSchemaProvisionalMTAppLanguageIdentificationEnded"
@"MTSchemaProvisionalMTAppLanguageIdentificationFailed"
@"MTSchemaProvisionalMTAppLanguageIdentificationCancelled"
@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence"
@"MTSchemaProvisionalMTError"
{?="exists"b1}
@"SISchemaUUID"
@"MTSchemaProvisionalMTBatchRequestStarted"
@"MTSchemaProvisionalMTBatchRequestEnded"
@"MTSchemaProvisionalMTBatchRequestFailed"
@"MTSchemaProvisionalMTBatchRequestCancelled"
{?="numParagraphFailures"b1}
{?="numberOfParagraphs"b1}
@"MTSchemaProvisionalMTClientEventMetadata"
@"MTSchemaProvisionalMTBatchRequestContext"
@"MTSchemaProvisionalMTInvocationContext"
@"MTSchemaProvisionalMTSessionContext"
@"MTSchemaProvisionalMTAppTextPasted"
@"MTSchemaProvisionalMTAppLanguageIdentificationContext"
@"MTSchemaProvisionalMTAppLanguageIdentificationInteracted"
@"MTSchemaProvisionalMTAppDisambiguationInteracted"
@"MTSchemaProvisionalMTSpeechTranslationSignal"
@"MTSchemaProvisionalMTUserFacingSessionSignal"
{?="errorCode"b1}
@"MTSchemaProvisionalMTInvocationStarted"
@"MTSchemaProvisionalMTInvocationEnded"
@"MTSchemaProvisionalMTInvocationFailed"
@"MTSchemaProvisionalMTInvocationCancelled"
@"MTSchemaProvisionalMTLanguagePair"
{?="isOnDeviceTranslationEnabled"b1"task"b1"inputMode"b1"isExplicitLanguageFilterEnabled"b1"isLanguageIdentificationEnabled"b1"uiMode"b1}
{?="sourceLanguage"b1"targetLanguage"b1}
@"MTSchemaProvisionalMTSessionStarted"
@"MTSchemaProvisionalMTSessionEnded"
@"MTSchemaProvisionalMTSessionFailed"
@"MTSchemaProvisionalMTSessionCancelled"
{?="speechRequestStatus"b1}
{?="userFacingSessionStatus"b1}
@"NSData"16@0:8
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^v16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^v16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^v16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^v16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^v16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^v16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^v16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^v16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^v16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^v16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^v16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^v16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^v16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^v16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^v16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^v16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
f16@0:8
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^v16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^v16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^v16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^v16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^v16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^v16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^v16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^v16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^v16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^v16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^v16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^v16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^v16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^v16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^v16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^v16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^v16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^v16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^v16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^v16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^v16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^v16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^v16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^v16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^v16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^v16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^v16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^v16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^v16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^v16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^v16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^v16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^v16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^v16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^v16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^v16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^v16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^v16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^v16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^v16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^v16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^v16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^v16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^v16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^v16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^v16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^v16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^v16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^v16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^v16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^v16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^v16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^v16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^v16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^v16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^v16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^v16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^v16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^v16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^v16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^v16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^v16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^v16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^v16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^v16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^v16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^v16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^v16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^v16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^v16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^v16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingConfig>=I}24@0:8^v16
r^{AStarFuzzyMatchingConfig=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResult>=I}24@0:8^v16
r^{AStarFuzzyMatchingResult=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingRequest>=I}24@0:8^v16
r^{AStarFuzzyMatchingRequest=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResponse>=I}24@0:8^v16
r^{AStarFuzzyMatchingResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^v16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^v16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^v16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^v16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^v16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^v16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^v16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^v16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^v16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^v16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^v16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^v16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^v16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^v16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^v16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^v16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^v16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^v16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^v16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^v16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^v16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^v16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^v16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^v16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^v16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^v16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^v16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^v16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^v16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^v16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^v16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^v16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24
@36@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationFeedbackRequest>=I}24@0:8^v16
r^{BatchTranslationFeedbackRequest=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^v16
r^{BatchTranslationResponse=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^v16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^v16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^v16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^v16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^v16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^v16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^v16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^v16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^v16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^v16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^v16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^v16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^v16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^v16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^v16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^v16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^v16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^v16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^v16
r^{LanguageDetectionStreamingResponse=[1C]}
v20@0:8f16
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
@(#)PROGRAM:Translation  PROJECT:Translation-173.11.4
@mcpl
@supo
mcpl
@mcpl
&8J\n
"&*L
 &,28>D
 &,4
"(.4:@F
LastActivityDate
%@_%@
com.apple.translation.DailyActive
feature
%0*ld_%ld
com.apple.translation.WeeklyActive
week_name
com.apple.translation.MonthlyActive
month_name
system
undefined
identifier
<no value>
text
targetRange
start
length
sourceRange
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
Error
com.apple.translation
selector
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
@"NSDictionary"8@?0
com.apple.translation.analytics-event
v8@?0
errorDomain
errorCode
errorDescription
duration
sourceLocale
targetLocale
%@.%@
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
application-identifier
sentence
singleParagraph
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
v16@?0@"NSError"8
paragraphs
com.apple.TranslationUIServices.TranslationUIService
text-to-speech
speech
preheat
text-LID
processName
unknown
type
v24@?0@"_LTAudioData"8@"NSError"16
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v24@?0@"_LTTranslationResult"8@"NSError"16
com.apple.private.translation
com.apple.Translation
Daemon
com.apple.translation.daemon.listener
DisambiguationEnabled
DataCollectionEnabled
com.apple.translationd
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
unknown error
Remote service failure
Online translation not implemented
Cannot force both online and offline
Failed to load LID model
Translation ongoing already
Speech translation already ongoing
Speech duration limit exceeded
Translation server did not respond in time.
Offline TTS failed
Translation from %@ to %@ is not supported.
%@ %@ %@
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
LTEtiquetteSanitizer.m
missing replacement tokens
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
HotfixManager
Translation
Hotfix
com.apple.Translator.HotfixManager
Mapping
FormatVersion
Cannot find any compatible hotfix
v24@?0@"NSDictionary"8@"NSError"16
com.apple.Translate
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
mapping-info-plist
v24@?0@"NSData"8@"NSError"16
HotfixAssetVersion
%@-%@
mt-quasar-config.json
HotfixAssetName
Failed to specify compression algorithm
Failed to specify format
Failed to open archive for reading
Unable to extract file
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
Languages
Footprint
Premium
hybridendpointer.json
InstallRequest
com.apple.siri.translation.speechrequest
locales
useCellular
zh-Hant
zh_TW
zh-Hans
zh_CN
dominantLanguage
confidences
isConfident
isFinal
com.apple.translation.lid.result
com.apple.translation.lid.finalResult
final
intermediate
, partial ASR confidences
, final ASR results
CSLanguageDetector
Class getCSLanguageDetectorClass(void)_block_invoke
LTLanguageDetector.m
Unable to find class %s
void *CoreSpeechLibrary(void)
/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
/System/Library/PrivateFrameworks/CoreSpeech.framework/Contents/MacOS/CoreSpeech
CSLanguageDetectorOption
Class getCSLanguageDetectorOptionClass(void)_block_invoke
features
compiledModelFile
modelInput
modelInputIsMatrix
modelOutput
missingFeatureValueDefault
missingLanguageDetectionDefault
LanguageLocaleToIdentifier
min_source
max_source
avg_source
min_target
max_target
avg_target
most_recent_partial_source
max_partial_source
avg_partial_source
most_recent_partial_target
max_partial_target
avg_partial_target
acoustic_lid
acoustic_lid_count
acoustic_lid0
acoustic_lid1
acoustic_lid2
identifier_source
identifier_target
identifier_asr
v32@?0@"NSString"8Q16^B24
@max.doubleValue
@avg.doubleValue
v32@?0@"NSNumber"8Q16^B24
1.0-
%lld
progress
offlineState
localeIdentifier
totalExpected
totalWritten
isStalled
expectedTimeRemaining
Missing
Installed
Downloading
NeedsDownload
ErrorInstalling
%@ %@ %@ %@
LanguageManager
com.apple.siri.translation.LanguageManager
mt_app.offline
LanguagePairs
ASR-%@
TTS-%@
asset_list
AssetName
v16@?0@"MAProgressNotification"8
asr_languages
_all
TTS-
Translation voice not found for %@:%@
Translation voice downloaded for %@:%@
Downloading Translation voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
ASR-
v16@?0q8
Not Present
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
<%@: source:%@ target:%@>
Translator
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
conversationID
requestID
localePair
selectedLocale
lidResult
senses
userInteractedSenses
firstResponse
firstParagraphComplete
progressComplete
pageComplete
timeToFirstResponse
timeToFirstParagraphComplete
timeToProgressComplete
timeToPageComplete
v16@?0@"OspreyMutableRequest"8
com.apple.translation.ParagraphTranslationDone
hw.machine
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechTranslationAssets2
com.apple.MobileAsset.SpeechEndpointAssets
AssetManager
com.apple.Translator.EMTAssetManager
v12@?0B8
plist
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
MADownLoadResult
Mobile asset failed to download.
v16@?0@"NSArray"8
Assets
AssetsV2
assets.json
Type
AssetVersion
RequiredCapabilityIdentifier
Configuration asset is missing.
The Configuration asset has not yet been downloaded.
Missing asset entitlement
LanguageDetectorDefaultAsset
featureCombinationLID.plist
_UnarchivedSize
TranslationAssetQueryDomain
OfflineSpeechSynthesizer
com.apple.assistant.backedup
Output Voice
Gender
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
LTOfflineTranslationEngine.mm
Missing result locale
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
Translation failed
Translation input was empty
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
asrBestConfidence
asrBestText
request_id
hasFinalServerResponse
completionHandlerCalled
Missing Batch Translation Responses
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.mobilesafari
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
x-sequoia-client
sentenceCount
v32@?0@"_LTTranslationParagraph"8Q16^B24
com.apple.translation.OnlineSpeechTranslation
sentAudio
sentEndAudio
endpointedSpeech
didReceiveAudioLimitExceededResponse
didReceivePartialRecognitionResponse
didReceiveFinalRecognitionResponse
didReceiveTranslationResponse
didReceiveTTSResponse
didReceiveFinalBlazarResponse
didTimeout
<%@: sentAudio:%@ sentEndAudio:%@ endpointedSpeech:%@ didReceiveAudioLimitExceededResponse:%@ didReceivePartialRecognitionResponse:%@ didReceiveFinalRecognitionResponse:%@ didReceiveTranslationResponse:%@  didReceiveTTSResponse:%@ didReceiveFinalBlazarResponse:%@ didTimeout:%@ error %@>
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
paragraph
Text or ranges need to be specified
v32@?0@"_LTTranslationRange"8Q16^B24
Error AudioQueueStart
com.apple.translation.powerlog
default
InstalledLocales
LastOfflineAssetCatalogUpdate
LastCDNUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
RequestID
HotfixEndpointURL
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
FinalAcousticLanguageDetectionResultsWaitTimeInMs
FinalThresholdsAcousticLanguageDetectionResultsWaitTimeInMs
MinimumAcousticLanguageDetectionResults
MaximumAcousticLanguageDetectionResults
VADAudioCacheMaxDuration
LanguageDetectorFeatureCombinationModelSupported
LanguageDetectorFeatureCombinationModelThreshold
LanguageDetectorFeatureCombinationModelConfidenceThreshold
ASRDataPackToLIDThresholdVersion
ASRDataPackToASRTypeIdentifier
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
CharacterBasedLocales
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
RateLimitingMaximumPageLoadRequests
RateLimitingMaximumDynamicContentRequests
VisualParagraphSegmenterLocalesEnabled
Configuration
-finalASR
mt_app.online
web.online
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
https://sequoia.apple.com
https://seed-sequoia.siri.apple.com
https://carry-sequoia.siri.apple.com
https://sequoia.cdn-apple.com/sequoia-prod
https://sequoia-test.cdn-apple.com/sequoia-livability/carry
EDC04020
com.apple.translationd.playback
com.apple.translation.session
v16@?0@"NSData"8
com.apple.translation.AnalysisQueue
LTSpeechCompressor.m
Already started compressor
AudioConverterNew failed: %x
AudioConverterSetProperty/kAudioConverterEncodeBitRate failed: %x
Too many buffers
Cannot produce ASPD for PCM
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
stable
locale
transcriptions
sausage
Sausage
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
confidence
(%@)
bins
alternatives
bestIndex
lowConfidence
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
com.apple.translation.speech
mini.json
MtApp
Empty recognition
No speech recognized
sanitizedFormattedString
formattedString
minConfidence
maxConfidence
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
v32@?0@"NSLocale"8@"_LTSpeechRecognitionResult"16^B24
sessionID
taskHint
deviceOS
deviceType
appIdentifier
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
LTTextLanguageDetectionResult.m
Invalid parameter not satisfying: %@
languages
com.apple.translation.TextLID
language
isSupported
TextLIDAggregateEvaluation
TextLIDUseLSTM
com.apple.translation.tts-cache
LTTextToSpeechCache.m
MISS
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
com.apple.Translate.globalprefschanged
com.apple.onboarding.translate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
tokens
statistics
status
phrasebook_exact
com.apple
translate
<redacted>
 (%@)
; %@
 | OCR
uniqueID
autodetectLanguage
autoEndpoint
censorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
ttsPlaybackRate
enableVAD
sourceOrigin
sourceContentAsJSON
targetContentAsJSON
errorsAsJSON
safariVersion
webpageURL
spans
v32@?0@"_LTTranslationSpan"8Q16^B24
-[_LTTranslationParagraph splitIntoSentences]_block_invoke_2
LTTranslationParagraph.m
previousSpan.range.location + previousSpan.range.length == textRange.location
v32@?0@"NSString"8@"_LTTranslationSpan"16^B24
v40@?0@"NSDictionary"8{_NSRange=QQ}16^B32
LTTranslationRange.m
Invalid paramter: identifier is nil
%@/%@
batch
LTTranslationRequest.m
This is deprecated
TranslationRequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
textToSpeech
CMBlockBufferCopyDataBytes could not copy data: %d
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
NO_IDENTIFIER
translations
sourceString
sanitizedSourceString
alignments
sourceMatch
targetMatch
pbMatch
sense ID
definition
source match
target match
input
output
labels
gender
formality
@"_LTTranslationSense"16@?0@"NSObject"8
com.apple.translationd.server
Offline models not available for language pair
v24@?0q8@"NSError"16
com.apple.translation.text
LTTranslationSession.m
completion
v16@?0@"NSDictionary"8
v24@?0@"<_LTTranslationService>"8@?<v@?>16
requests
Service should be set before calling translate
Translation rate limit reached
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
feedback
range
shouldTranslate
metaInfoData
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
sentencepiece encoder input
firstleg sentencepiece decoder output
sentencepiece decoder output
siri
app_review
mt_app
v16@?0@"<_LTTranslationService>"8
v16@?0@"_LTLanguageDetectionResult"8
v16@?0@"_LTTextLanguageDetectionResult"8
InternalBuild
ar_SA
male
female
Language
Config
MT-bi-
senseId
reason
cancelled
ended
failed
started
alternateLocale
error
userSelectedLocale
exists
inputSourceAppBundleId
contextId
startedOrChanged
numParagraphFailures
numberOfParagraphs
com.apple.aiml.mi.mt.MTClientEvent
appDisambiguationInteracted
appLIDContext
appLIDInteracted
appTextPasted
batchRequestContext
eventMetadata
invocationContext
sessionContext
speechRecognitionSignal
userFacingSessionSignal
clientAppBundleId
mtId
sessionId
inputMode
isExplicitLanguageFilterEnabled
isLanguageIdentificationEnabled
isOnDeviceTranslationEnabled
mobileAssetConfigVersion
mtLanguagePair
task
uiMode
sourceLanguage
targetLanguage
speechRequestStatus
userFacingSessionStatus
LOCALE_UNKNOWN_LOCALE
LOCALE_AR_AE
LOCALE_AR_SA
LOCALE_CA_ES
LOCALE_CS_CZ
LOCALE_DA_DK
LOCALE_DE_AT
LOCALE_DE_CH
LOCALE_DE_DE
LOCALE_EL_GR
LOCALE_EN_AE
LOCALE_EN_AU
LOCALE_EN_CA
LOCALE_EN_GB
LOCALE_EN_ID
LOCALE_EN_IE
LOCALE_EN_IN
LOCALE_EN_MY
LOCALE_EN_NZ
LOCALE_EN_PH
LOCALE_EN_SG
LOCALE_EN_SA
LOCALE_EN_US
LOCALE_EN_ZA
LOCALE_ES_CL
LOCALE_ES_CO
LOCALE_ES_ES
LOCALE_ES_MX
LOCALE_ES_US
LOCALE_FI_FI
LOCALE_FR_BE
LOCALE_FR_CA
LOCALE_FR_CH
LOCALE_FR_FR
LOCALE_HE_IL
LOCALE_HI_IN
LOCALE_HR_HR
LOCALE_HU_HU
LOCALE_ID_ID
LOCALE_IT_CH
LOCALE_IT_IT
LOCALE_JA_JP
LOCALE_KO_KR
LOCALE_MS_MY
LOCALE_NB_NO
LOCALE_NL_BE
LOCALE_NL_NL
LOCALE_PL_PL
LOCALE_PT_BR
LOCALE_PT_PT
LOCALE_RO_RO
LOCALE_RU_RU
LOCALE_SK_SK
LOCALE_SV_SE
LOCALE_TH_TH
LOCALE_TR_TR
LOCALE_UK_UA
LOCALE_VI_VN
LOCALE_WUU_CN
LOCALE_YUE_CN
LOCALE_ZH_CN
LOCALE_ZH_HK
LOCALE_ZH_TW
(unknown: %i)
QssRpc_immutable_generated.mm
Output Buffer is null
v20@?0r*8I16
v24@?0^v8Q16
tok_phrases
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
bool_stats
int32_stats
double_stats
acoustic_feature_per_frame
speech_recognition_features
acoustic_features
value
recognition_result
audio_analytics
latnn_mitigator_result
start_speech_request
user_parameters
pron_hints
contextual_text
context_with_pron_hints
user_language_profile
user_acoustic_profile
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
attributes
category_data
user_data
voc_token
tts_pronunciations
human_readable_prons
apg_ids
recovery_return_codes
voc_tokens
words_list
formatted_words_list
normalized_tokens
nbest_variants
sanitized_sequences
prons
normalized_prons
sanitized_tokens
phonemes
aot_token_prons
jit_token_prons
index
span
raw_sausage
raw_nbest_choices
post_itn_tokens
itn_alignments
translation_phrase
pre_sausage_payload
siri_translation_info
speech_translation_info
siri_payload_translation_info
web_translation_info
n_best_translated_phrases
engine_output
mt_alignment
translated_tokens
audio_packets
match_ids
results
keywords
corrected_sausage
n_best_list
pause_counts
corrections
voice
resource
context_info
word_phonemes
prompts
normalized_text
phoneme_sequence
replacement
neural_phoneme_sequence
resources
meta_info
context
experiment
feature_flags
debug
profile
decoder_description
playback_description
word_timing_info
cache_meta_info
cache_object
audio_frames
translation_locale_pairs
translation_request
text_to_speech_requests
translation_locale_pair
detected_locale
user_interacted_senses
text_to_speech_response
server_endpoint_features
utterance
shortcuts
shortcut_score_pairs
language_parameters_by_id
predictions
content
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
profile_blob
profile_blob_version
profile_checksum
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
add_space_after
phone_seq
ipa_phone_seq
has_unsuggested_alternatives
speech_id
request_locale
name
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
frame_duration
session_id
return_code
return_str
lang_profile_recreate_codes
watermark_detection
watermark_peak_average
has_result
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
primary_speech_id
product_id
vendor_id
left_context
right_context
audio_bytes
packet_count
total_audio_recorded_seconds
orthography
pronunciations
frequency
category_name
error_code
error_str
incomplete_profile
recreate_apg_prons
blob
apg_id
num_of_requested
num_of_processed
num_of_succeeded
post_itn_string
nbest_variants_max
original_token
pron_sequence
log_weight
token
pron_source
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
start_index
end_index
do_not_translate
post_itn_recognition
pre_itn_payload
post_itn_payload
source_language
target_language
sequence_id
disable_log
opt_in_status
app_id
return_string
engine_input
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
debug_information
matcher_id
query
target
latency
expanded_path
keyword_orthography
posterior
enable_sanitization
num_of_words
trailing_silence_duration
eos_likelihood
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
fe_feature
fe_feature_only
disable_prompts
cache_only
quality
channel_type
is_synthesis
dialog_identifier
experiment_identifier
prompts_v2
original
force_use_tts_service
disable_cache
data
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
timestamp
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
endpoint_threshold
endpoint_extra_delay
source_locale
target_locale
conversation_id
restricted_mode
streaming_mode
user_selected_locale
user_selected_sense
is_final_result
interaction_id
raw_string
shortcut
similarity_score
is_low_confidence
paragraph_id
source_content
translated_content
errors
safari_version
os_version
translated_text
sentence_count
content_type
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Afm/AStarFuzzyMatching
/siri.speech.qss_fb.Sls/LanguageDetection
Log daily activity for %@
Log weekly activity
Log monthly activity for %@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
Failed to deserialize logging request: %@ 
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Memory pressure warning level %lu.
Rejected Translation client with PID %d lacking the appropriate entitlement (%@).
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
rm -rf %@
Could not delete: %@
Downloading: %@
Failed to download %@ with error: %@
Select hotfix: %@
Found existing hotfix
Remove folder failed: %@
Create folder failed: %@
Decompression failed: %@
Failed to specify compression algorithm: %s
Failed to specify format: %s
Start extracting archive
Failed to open archive for reading: %s
Entry extraction path: %@
Unable to extract file: %s
Finished extracting archive to: %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Updating source endpointer threshold to %f
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Updating target endpointer threshold to %f
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Start installation request with service
Failed to obtain LID asset
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
Sending out new %@ LID result, detected %@
Computing new LID result, with %ld acoustic results%@%@
Already sent final LID result, ignoring additional speech result
Change in model-version triggers deletion of cached %@ partial-confidences
Calling endAudio from addSpeechRecognitionResult
Initiate use of final thresholds to reduce dialog rates, as timer ended after 1st final ASR
Try to force final LID, as timer ended after 1st final ASR
Added %@ partial-confidence: %f; new array length: %ld
Already sent final LID result, ignoring additional audio data
NumSamples: %ld
LID Audio Data
Trying to send final LID result from endAudio
Forcing current language detection result to be final
Forcing language detection result to be %@
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
Acoustic LID detected %@ (confident: %@): %@
Trying to send final LID result from acousticLID CoreSpeech delegate
Setting default value for input is matrix to NO
Missing necessary configuration values
Setting default value for missing feature value to %f
Setting default value for missing language detector result to %f
Unknown feature in model file: %@
Unable to load CoreML model from: %@
CoreML model loaded: %@
Min confidence source: %f
Max confidence source: %f
Average confidence source: %f
Min confidence target: %f
Max confidence target: %f
Average confidence target: %f
Acoustic LID: %f
Acoustic LID count: %ld
Acoustic LID0: %f
Acoustic LID1: %f
Acoustic LID2: %f
Most recent partial confidence source: %f
Max partial confidence source: %f
Average partial confidence source: %f
Most recent partial confidence target: %f
Max partial confidence target: %f
Average partial confidence target: %f
Language %@ locale identifier source: %f
ASR-type identifier for model version=%@ -> feature: %f
Discarded CoreML features, as all values were defaults
Created CoreML features: %@
Unable to compile CoreML input features
Unable to construct CoreML feature provider
Unable to perform inference on CoreML model
Was unable to extract CoreML prediction
Was unable to extract posterior values from prediction results
Queried LID threshold version "%@" useFinalThresholds: %@ isFinalASR: %@, detected %@, with score %f using discriminator threshold %@%f and confidence offset %f (confident: %@)
missing mt_app.offline.plist
asset names for %@: %@
downloadAsset %@ totalExpected %@
progressCallback update assetIdentifier %@ %@
Finished downloading all assets
Required Assets: %@
setAutoDownloadedVoiceAssets %@
Unreferenced assets: %@
purged %@ result %ld
Nothing to install.
Installing:
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start speech senses logging request
Speech senses logging request finished with error: %@
Speech senses logging request finished
Start Safari latency logging request
Start Safari feedback request
Safari feedback request finished with error: %@
Safari feedback request finished
Received speech logging request response: [%d] %@
Speech logging request received unexpected response: %@
Speech logging request received error: %@
Received safari feedback request response: [%d] %@
Safari feedback request received unexpected response: %@
Safari feedback request received error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Received new language detection result
Trying to cancel recognition for %@
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
MADownloadNotEntitled
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
error querying obsolete catalog assets
Deleting Obsolete Assets %@
error querying catalog assets
error querying installed assets
Config asset not installed!
Reading configuration plist %@
Failed to read plist %@
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Start downloading asset %@ userInitiated: %@, useCellular: %@
Asset progress: %@
update: %@ %@
Asset download finished %@
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
Failed to remove old asset directory %@
Failed to create asset directory %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
----------------------------- sortedCatalogAssets ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
%@ %@ %@ %@
error downloading asset %@
error deleting asset %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Starting download for asset with attributes: %@
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Failed to fetch asset metadata. Result: %ld
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Failed to create recognizer: %@
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Failed to create translator: %@
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Already got final LID result, forwarding...
Waiting for LID result
Received final LID result, continue with wait block
Starting translation
Initialize translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
Starting partial translation
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
streamDidReceiveBatchTranslationStreamingResponse request_id %{public}@
found BatchTranslationResponse request_id %{public}@
FIXME: NULL FTBatchTranslationResponse!
Succeeded request %{public}@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %{public}@
NULL FTFinalBlazarResponse!
GRPC error %d: %@
Translation error on %{public}@: %@
found FTFinalBlazarResponse request_id %{public}@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FBFLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
startServerTimeoutTimer 
updateServerTimeout %.2fs 
cancelServerTimeout: %@
batch timeout triggered
 serverTimeoutFired Sending batch request after %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ after %.2fs
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %{public}@, task: %{public}@, sessionID: %{public}@, URL: %@
Batch SELF log created
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Starting speech translation with request ID: %{public}@ session ID: %{public}@, opt in status: %ld
Streaming connection finished with error: %@
Starting text to speech translation with request ID: %{public}@, session ID: %{public}@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
sendAudioData: Final ASR response received, not sending audio.
sendAudioData: Already sent end audio, not sending audio.
sendAudioData: Already endpointed, do not need to send additional audio.
sendAudioData: Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring non-final LID result
LID result received. Primary language recognized: %@
Sending MT responses if needed
Detected translation locale: %@
Result locale: %@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Create SELF Batch request log with request sessionID: %@, requestID: %@, appID: %@
Unable to create the SELF Batch request log.
Start SELF Batch request log with %lu paragraphs
End SELF Batch request log
End SELF Batch request log with error %@
Cancel SELF Batch request log with reason %@
SELF Batch request log sent %@
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
Sending end of audio
Asked to cancel speech session
SNAudioStreamAnalyzer failure: %@
Sausage conf %ld for locale %@
Sausage confidences: %@
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Using LSTM text lid engine
Using CFRO text lid engine
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Using aggregate text lid evaluation
TTS cache request: %@
Purging %ld items from TTS cache
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Text Translation: start with service
Using paragraph translation
Received parapraph translation result
Fallback to text to speech translation
Translation failed with error: %@
Alignment '%@' ID: %@
No alignment information in translation
Received translated paragraph for ID: %@
New outstanding count: %ld
Received text to speech result
Using `-[_LTTranslator translate:]` is not supported on batch translation. Please take a look at `_LTTranslationSession`.
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TextToSpeechTranslation did receive translation result
No asset info found for pair %@
Reusing cached offline engine for locales: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %{public}@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %{public}@, current ongoing is: %{public}@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
Translation rate limit reached, ignoring %lu requests
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Session sending feedback
Received translation result for %@
Failed to clear caches: %@
Failed to complete _offlineLanguageStatus %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete installedLocales %@
Failed to complete availableLocalePairsForTask %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Creating service proxy
Connection error: %@
Connection done
Creating SYNC service proxy
Failed sync preheat request
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Starting translation for request
Failed to serialize logging request: %@
Failed to complete logging request: %@
softlink:r:path:/System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
ABSD
_LTActivityLogging
JSONRepresentation
_LTAlignment
NSSecureCoding
NSCoding
_LTAnalyticsEvent
_LTAsyncMap
_LTAudioData
_LTClientConnection
_LTTranslationService
_LTCombinedEngine
_LTSpeechTranslationDelegate
NSObject
_LTTranslationEngine
_LTCombinedRouteParagraphTranslationRequest
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
LTTranslationError
_LTMatch
_LTEtiquetteSanitizer
_LTHotfixManager
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTHybridEndpointerAssetInfo
_LTInstallRequest
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
_LTLanguageDetectorAssetInfo
_LTLanguageDetectorFeatureCombinationModel
_LTLanguageInstallationStatus
_LTLanguageAssetStatus
_LTLanguageManager
_LTLanguagePairOfflineAvailability
_LTLocalePair
NSCopying
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTTranslationSensesLoggingRequest
_LTSafariLatencyLoggingRequest
_LTLoggingRequestHandler
FTSpeechTranslationResponseDelegate
FTBatchTranslationResponseDelegate
_LTMultilingualSpeechRecognizer
_LTOfflineAssetManager
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
_LTOfflineTranslationEngine
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
_LTOnlineTranslationEngine
_LTOspreySpeechTranslationSession
_LTSpeechCompressorDelegate
_LTParagraphTranslationRequest
_LTPlaybackService
_LTPowerLogger
_LTRateLimiter
LTBatchEventLog
_LTServerSpeakSession
_LTServerSpeechSession
_LTSpeakRequest
_LTSpeechActivityDetector
SNResultsObserving
_LTSpeechCompressor
_LTSpeechDataQueueNode
_LTSpeechDataQueue
Osprey
_LTSpeechRecognitionResult
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTSpeechTranscription
_LTSpeechTranslationAssetInfo
_LTSpeechTranslationResultsBuffer
_LTTaskContext
_LTTextLanguageDetectionResult
_LTTextLanguageDetector
_LTTextToSpeechCache
_LTTokenizer
_LTTranslateSettingsController
_LTTranslationCandidate
OspreyRequest
_LTTranslationContext
_LTTranslationFeedback
_LTTranslationParagraph
_LTTranslationRange
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTranslationResult
_LTTranslationSense
_LTTranslationServer
_LTTranslationSession
_LTTranslationSpan
LTStatistics
_LTTranslationStatistics
_LTTranslationToken
_LTTranslator
TranslationAssetUtil
MTSchemaProvisionalLanguageIdentificationLocaleConfidence
MTSchemaProvisionalMTAppDisambiguationInteracted
MTSchemaProvisionalMTAppLanguageIdentificationCancelled
MTSchemaProvisionalMTAppLanguageIdentificationContext
MTSchemaProvisionalMTAppLanguageIdentificationEnded
MTSchemaProvisionalMTAppLanguageIdentificationFailed
MTSchemaProvisionalMTAppLanguageIdentificationInteracted
MTSchemaProvisionalMTAppLanguageIdentificationStarted
MTSchemaProvisionalMTAppTextPasted
MTSchemaProvisionalMTBatchRequestCancelled
MTSchemaProvisionalMTBatchRequestContext
MTSchemaProvisionalMTBatchRequestEnded
MTSchemaProvisionalMTBatchRequestFailed
MTSchemaProvisionalMTBatchRequestStarted
InstrumentationAdditions
MTSchemaProvisionalMTClientEvent
MTSchemaProvisionalMTClientEventMetadata
MTSchemaProvisionalMTError
MTSchemaProvisionalMTInvocationCancelled
MTSchemaProvisionalMTInvocationContext
MTSchemaProvisionalMTInvocationEnded
MTSchemaProvisionalMTInvocationFailed
MTSchemaProvisionalMTInvocationStarted
MTSchemaProvisionalMTLanguagePair
MTSchemaProvisionalMTSessionCancelled
MTSchemaProvisionalMTSessionContext
MTSchemaProvisionalMTSessionEnded
MTSchemaProvisionalMTSessionFailed
MTSchemaProvisionalMTSessionStarted
MTSchemaProvisionalMTSpeechTranslationSignal
MTSchemaProvisionalMTUserFacingSessionSignal
LTArrayExtensions
LTParagraphs
LTLocaleIdentifier
FTUserLanguageProfile
FLTBFBufferAccessor
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTAStarFuzzyMatchingConfig
FTAStarFuzzyMatchingResult
FTAStarFuzzyMatchingRequest
FTAStarFuzzyMatchingResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTTTSWordPhonemes
FTTTSPhonemeSequence
FTTTSNeuralPhonemeSequence
FTTTSPrompts
FTTTSReplacement
FTTTSNormalizedText
FTTextToSpeechFeature
FTTextToSpeechRequestDebug
FTTextToSpeechVoiceResource
FTTextToSpeechUserProfile
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTQssAckResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationFeedbackRequest
FTBatchTranslationResponse
FTBatchTranslationCacheContainer
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableAStarFuzzyMatchingConfig
FTMutableAStarFuzzyMatchingResult
FTMutableAStarFuzzyMatchingRequest
FTMutableAStarFuzzyMatchingResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableTTSWordPhonemes
FTMutableTTSPhonemeSequence
FTMutableTTSNeuralPhonemeSequence
FTMutableTTSPrompts
FTMutableTTSReplacement
FTMutableTTSNormalizedText
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequestDebug
FTMutableTextToSpeechVoiceResource
FTMutableTextToSpeechUserProfile
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableQssAckResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationFeedbackRequest
FTMutableBatchTranslationResponse
FTMutableBatchTranslationCacheContainer
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTAfmService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
format_id
sample_rate
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
audioStreamBasicDescription
init
calendarWithIdentifier:
_featureNameForTask:
stringWithFormat:
date
standardUserDefaults
objectForKey:
_logAllActivityFeature:date:
setObject:forKey:
isDate:inSameDayAsDate:
_logDailyActivityFeature:date:
isDate:equalToDate:toUnitGranularity:
_logWeeklyActivityFeature:date:
_logMonthlyActivityFeature:date:
dictionaryWithObjects:forKeys:count:
components:fromDate:
weekOfYear
year
month
registerActivity:
.cxx_destruct
_calendar
identifier
text
targetRange
numberWithUnsignedInteger:
jsonRepresentation
encodeObject:forKey:
valueWithRange:
decodeObjectOfClass:forKey:
rangeValue
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
setIdentifier:
sourceRange
setSourceRange:
setTargetRange:
setText:
shouldTranslate
setShouldTranslate:
_shouldTranslate
_identifier
_text
_sourceRange
_targetRange
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_identifier
T@"NSString",C,N,V_text
TB,N,V_shouldTranslate
code
numberWithInteger:
domain
dictionaryWithDictionary:
userInfo
objectForKeyedSubscript:
setObject:forKeyedSubscript:
dictionary
initWithName:
markStart
processInfo
systemUptime
numberWithDouble:
addFieldsFromDictionary:internalOnly:
addEntriesFromDictionary:
localizedDescription
addFieldsFromDictionary:
markEnd
sourceLocale
_ltLocaleIdentifier
targetLocale
timedEventWithName:
timestampWithName:
addFieldsWithError:
sendLazy
setSourceLocale:
setTargetLocale:
_eventName
_startTime
_endTime
_queue
_fields
_sourceLocale
_targetLocale
T@"NSLocale",C,N,V_sourceLocale
T@"NSLocale",C,N,V_targetLocale
_ltAsyncMap:queue:completion:
array
count
null
addObject:
setObject:atIndexedSubscript:
enumerateObjectsUsingBlock:
objectEnumerator
nextObject
_ltAsyncMap:completion:
_ltSequentialMap:completion:
_populateWithOpusData:
data
length
bytes
appendBytes:length:
defaultManager
URLByDeletingLastPathComponent
path
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToURL:options:error:
initWithASBD:rawData:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
_asbd
_data
_packetCount
_packetDescriptions
_rawData
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T@"NSData",R,N,V_rawData
Tq,R,N,V_packetCount
T@"NSData",R,N,V_packetDescriptions
setExportedInterface:
setExportedObject:
setRemoteObjectInterface:
cleanupOnDisconnect
setInterruptionHandler:
setInvalidationHandler:
valueForEntitlement:
processIdentifier
stringWithUTF8String:
remoteObjectProxy
cancelSpeechSessionWithID:
delegate
clientConnectionClosed:
clearCaches
logRequestOfType:context:
setClientIdentifier:
translateSentence:withContext:completion:
arrayWithObjects:count:
translateParagraphs:withContext:paragraphResult:completion:
_clientDelegate
paragraphTranslation:result:error:
speak:withContext:completion:
isEqual:
setTaskHint:
startTextToSpeechTranslationWithContext:text:delegate:
startSpeechTranslationWithContext:delegate:
addSpeechAudioData:
endAudio
preheatWithContext:completion:
languageForText:completion:
languagesForText:usingModel:completion:
cleanup
route
sharedInstance
logTranslateRequestEvent:requestType:routeType:
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
installedLocales:
startInstallRequest:delegate:
_getAssetSize:
availableLocalePairsForTask:completion:
task:isSupportedInCountry:completion:
additionalLikelyPreferredLocalesForLocale:completion:
configInfoForLocale:otherLocale:completion:
unarchivedObjectOfClasses:fromData:error:
setProcessName:
setClientBundleID:
startLoggingRequest:
_updateHotfix:
_deleteHotfix:
translate:withContext:completion:
translateParagraphs:withContext:completion:
provideFeedback:withContext:
startTextToSpeechTranslationWithContext:text:
startSpeechTranslationWithContext:
languagesForText:completion:
startInstallRequest:
logWithRequestData:
initWithConnection:server:
setDelegate:
_connection
_server
_clientIdentifier
_speechSessionID
_delegate
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
offlineEngine
translatesPair:
onlineEngine
preheatAsynchronously:withContext:
setLanguagesRecognized:
cancelSpeechTranslation
_ltCompactMap:
mutableCopy
removeObject:
translate:withContext:paragraphResult:completion:
countByEnumeratingWithState:objects:count:
endpoint
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
speechRecognitionResult:
translatorDidTranslate:
hasFailed
stopBuffering
translationDidFinishWithError:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
speechActivityDetected
languageDetectionResult:
languageDetectionCompleted
cancel
languageInstallProgressed:error:
setOfflineEngine:
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
requestContext
setRoute:
forcedOfflineTranslation
_forcedOnlineTranslation
registerDefaults:
_setupMemoryWarningListener
initWithMachServiceName:
_setQueue:
resume
currentRunLoop
notifyOfMemoryPressure
boolValue
initialize
listener:shouldAcceptNewConnection:
_translationListener
_listenerQueue
_connections
stringByAppendingString:
errorWithDomain:code:userInfo:
mainBundle
localizedStringForKey:value:table:
lt_errorWithCode:description:userInfo:
currentLocale
localizedStringForLocaleIdentifier:
lt_internalErrorWithCode:description:userInfo:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_speechTranslationOngoingError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
initWithNode:range:
node
setNode:
range
setRange:
token
setToken:
_node
_token
_range
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
dataWithContentsOfURL:
JSONObjectWithData:options:error:
enumerateKeysAndObjectsUsingBlock:
treeForReplacementTokens:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
URLByAppendingPathComponent:
initWithReplacementTokenDictionary:language:
lowercaseString
enumerateSubstringsInRange:options:usingBlock:
removeObjectsInArray:
removeAllObjects
isEqualToString:
replaceCharactersInRange:withString:
substringWithRange:
replacementStringForString:forToken:
copy
matchesForString:
stringByReplacingMatches:inString:
localeIdentifier
initWithModelURL:language:
sanitizedStringForString:
_replacementTree
_locale
URLForDirectory:inDomain:appropriateForURL:create:error:
contentsOfDirectoryAtPath:error:
firstObject
minimumSupportedConfigurationVersion
intValue
maximumSupportedConfigurationVersion
_downloadHotfix:completion:
_downloadMappingPlist:
removeItemAtURL:error:
defaultSessionConfiguration
set_sourceApplicationBundleIdentifier:
setAllowsCellularAccess:
sessionWithConfiguration:
dataTaskWithURL:completionHandler:
_CDNURL:
propertyListWithData:options:format:error:
_downloadWithURL:completion:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
_decompressArchive:to:error:
stringByAppendingPathComponent:
UTF8String
hotfixURL
updateHotfix:
deleteHotfix:
_hotfixURL
T@"NSURL",R,N,V_hotfixURL
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
processed_audio_duration_ms
decodeInt64ForKey:
decodeDoubleForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
defaultServerEndpointFeatures
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEosLikelihood:
setPauseCounts:
silencePosterior
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
eosLikelihood
pauseCounts
processedAudioDurationInMilliseconds
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
autoEndpoint
endpointAssetInfoWithContext:error:
caesuraModelURL
initWithConfigFile:samplingRate:
localePair
endpointerModelURL:
initWithConfiguration:
requestSupportedWithSamplingRate:
floatValue
updateEndpointerThresholdWithValue:
autodetectLanguage
addAudio:numSamples:
processedAudioMs
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
componentsJoinedByString:
didEndpointWithFeatures:silenceFeatures:endpointer:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
endpointerThreshold
setEndpointerThreshold:
samplingRate
audioBitDepth
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_context
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_samplingRate
_audioBitDepth
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
Tq,R,N,V_audioBitDepth
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
endpointerIsAvailableWithContext:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
attributes
valueForKey:
_ltCsLocaleIdentifier
containsObject:
integerValue
isPremium:
state
getLocalUrl
initWithAvailableAssets:context:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
T@"NSString",R,N,V_hybridepAssetFile
T@"NSString",R,N,V_spgAssetFile
initWithLocales:useCellular:
decodeBoolForKey:
encodeBool:forKey:
initWithLocales:useCellular:progressHandler:
initWithLocales:useCellular:delegate:
_startInstallationWithService:done:
locales
setLocales:
useCellular
setUseCellular:
progressHandler
setProgressHandler:
completionHandler
setCompletionHandler:
_service
_done
_useCellular
_locales
_progressHandler
_completionHandler
T@?,C,N,V_completionHandler
T@"NSArray",C,N,V_locales
TB,N,V_useCellular
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
T@?,C,N,V_progressHandler
localeWithLocaleIdentifier:
languageCode
allKeys
doubleValue
setDominantLanguage:
setConfidences:
dominantLanguage
confidences
isConfident
isFinal
initWithConfidences:isConfident:dominantLanguage:isFinal:
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
languageDetectorAssetWithError:
languageDetectorModelURL
initWithModelURL:
featureCombinationConfigUrl
initWithConfig:
lidThreshold
reversedPair
setSamplingRate:
setWithObjects:
setDictationLanguages:
resetForNewRequest:
haveFinalASRResults
haveAtLeastOneFinalASRResult
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:useFinalThresholds:
sendLIDResult:
locale
modelVersion
sendFinalLanguageDetectionResult:
bestTranscription
confidence
addSamples:numSamples:
cancelCurrentRequest
lastObject
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
startLanguageDetectionWithContext:delegate:
addSpeechRecognitionResult:
cancelLanguageDetection
forceLanguageDetectionResult
acousticResults
setAcousticResults:
lastResult
setLastResult:
featureCombinationModelSupported
setFeatureCombinationModelSupported:
featureCombinationModel
setFeatureCombinationModel:
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_minimumAcousticLanguageDetectorResults
_maximumAcousticLanguageDetectorResults
_endAudioCalled
_useFinalThresholds
_finalLIDResultSent
_receivedPartialSpeechResult
_havePartialASRConfidences
_partialSpeechResultConfidences
_finalSpeechResults
_modelVersions
_lidSignpostID
_resultQueue
_finalResultWaitQueue
_featureCombinationModelSupported
_acousticResults
_lastResult
_featureCombinationModel
T@"NSMutableArray",&,N,V_acousticResults
T@"_LTLanguageDetectionResult",&,N,V_lastResult
TB,N,V_featureCombinationModelSupported
T@"_LTLanguageDetectorFeatureCombinationModel",&,N,V_featureCombinationModel
Td,R,N,V_samplingRate
handleFailureInFunction:file:lineNumber:description:
initWithAssetUrl:featureCombinationAssetUrl:
_assetUrl
_featureCombinationConfigUrl
initWithContentsOfURL:
numberWithUnsignedInt:
modelWithContentsOfURL:error:
modelDescription
initWithShape:dataType:error:
minConfidence
maxConfidence
getAcousticLidConfidenceFromResult:locale:
objectAtIndex:
valueForKeyPath:
cannonicalLocalePair
getModelFeatures:canonicalPair:partialSpeechResultConfidences:finalSpeechResults:modelVersion:
initWithDictionary:error:
predictionFromFeatures:options:error:
featureValueForName:
multiArrayValue
objectAtIndexedSubscript:
oppositeToLocale:
initWithSourceLocale:targetLocale:
estimateLanguage:languageDetectionResults:partialSpeechResultConfidences:finalSpeechResults:modelVersions:
_mlModel
_modelInput
_modelInputIsMatrix
_modelOutput
_features
_missingFeatureValueDefault
_missingLanguageDetectorDefault
_languageLocaleToIdentifier
progress
setProgress:
setLocaleIdentifier:
offlineState
setOfflineState:
totalExpected
setTotalExpected:
totalWritten
setTotalWritten:
isStalled
setIsStalled:
expectedTimeRemaining
setExpectedTimeRemaining:
_isStalled
_progress
_localeIdentifier
_offlineState
_totalExpected
_totalWritten
_expectedTimeRemaining
Tq,N,V_progress
T@"NSString",C,N,V_localeIdentifier
TQ,N,V_offlineState
Tq,N,V_totalExpected
Tq,N,V_totalWritten
TB,N,V_isStalled
Td,N,V_expectedTimeRemaining
_LTAssetStateString
finished
setFinished:
status
setStatus:
localIdentifiers
setLocalIdentifiers:
update
setUpdate:
_finished
_status
_localIdentifiers
_update
TB,N,V_finished
TQ,N,V_status
T@"NSArray",&,N,V_localIdentifiers
T@"MAProgressNotification",&,N,V_update
removeObsoleteAssets
compare:
sortedArrayUsingSelector:
componentsSeparatedByString:
identifiersInIdentifiers:forLanguageName:
arrayByAddingObjectsFromArray:
subarrayWithRange:
_configPlistWithFileName:
addObjectsFromArray:
allObjects
pairWithIdentifiers:
hasPrefix:
hasSuffix:
languageToStatusDictionary
installationStatusArray
downloadSize
numberWithLongLong:
updateProgress
allValues
downloadAsset:userInitiated:useCellular:progressCallback:completion:
_setInstalledLocales:
configurationPropertyListWithName:
catalogAssets
installedAssets
setDiscretionary:
setRequiresPowerPluggedIn:
pairNamesForLocales:
assetNamesForPairNames:
substringFromIndex:
_vsLocaleIdentifier
_voiceAssetForLocaleIdentifier:
isInstalled
isBuiltInVoice
sharedManager
languages
gender
genderStringFromGender:
downloadVoiceAsset:options:progressUpdateHandler:
setAutoDownloadedVoiceAssets:
matchingASRAssetForLocale:inAssets:
assetWithName:inAssets:
identifiersInIdentifiers:forAssetName:
downloadAsset:withStatus:
isConfig
purge:
assetsNamesForLocale:
setInstalledLocales:useCellular:completion:
_assetManager
_assetStatusDictionary
_localeIdentifierList
pair
decodeIntegerForKey:
decodeObjectForKey:
encodeInteger:forKey:
initWithLocales:
pairState
setPairState:
setPair:
sourceASRState
setSourceASRState:
targetASRState
setTargetASRState:
mtState
setMtState:
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
needsUpdate
setNeedsUpdate:
_needsUpdate
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
cannonicalIdentifier
_ltEqual:
isPassthrough
copyWithZone:
combinedLocaleIdentifier
isVariantPair
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
conversationID
setConversationID:
requestID
setRequestID:
setLocalePair:
selectedLocale
setSelectedLocale:
lidResult
setLidResult:
_conversationID
_requestID
_localePair
_selectedLocale
_lidResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"_LTLocalePair",C,N,V_localePair
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_lidResult
senses
setSenses:
userInteractedSenses
setUserInteractedSenses:
_senses
_userInteractedSenses
T@"NSArray",C,N,V_senses
T@"NSArray",C,N,V_userInteractedSenses
markResponse
markFirstParagraphComplete
markProgressDone
markPageComplete
dict
start
firstResponse
firstParagraphComplete
progressComplete
pageComplete
processName
_start
_firstResponse
_firstParagraphComplete
_progressComplete
_pageComplete
_processName
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_firstParagraphComplete
Td,R,N,V_progressComplete
Td,R,N,V_pageComplete
T@"NSString",C,N,V_processName
T@"NSDictionary",R,N
blazarServiceWithBundleID:
startSpeechLIDRequest:
startSpeechSensesLoggingRequest:
startSafariLatencyLoggingRequest:
startSafariFeedbackRequest:
mtAppService
performSpeechTranslationWithDelegate:requestBuilder:completion:
setTarget_locale:
setSource_locale:
setDetected_locale:
setLocale:
setConfidence:
setIs_low_confidence:
setPredictions:
setConversation_id:
setRequest_id:
setUser_selected_locale:
setTranslation_locale_pair:
setContentAsFTStartSpeechTranslationLoggingRequest:
sendSpeechTranslationStreamingRequest:
closeStream
setUser_selected_sense:
setUser_interacted_senses:
performBatchTranslationWithDelegate:requestBuilder:completion:
sourceContentAsJSON
setSource_content:
targetContentAsJSON
setTranslated_content:
webpageURL
absoluteString
setUrl:
errorsAsJSON
setErrors:
sessionID
setSession_id:
setSource_language:
setTarget_language:
safariVersion
setSafari_version:
clientBundleID
setApp_id:
operatingSystemVersionString
setOs_version:
setDevice_type:
setContentAsFTBatchTranslationFeedbackRequest:
sendBatchTranslationStreamingRequest:
content_type
contentAsFTFinalBlazarResponse
return_code
return_str
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
_mtAppService
T@"FTBlazarService",R,N,V_mtAppService
initWithModelURL:language:modelVersion:
language
formattedString
triggerServerSideEndPointer
startRecognitionWithAutoStop:resultHandler:
cancelRecognition
initWithModelURLs:modelVersions:
startRecognitionForLocale:autoEndpoint:resultHandler:
_recognizers
_removeOldAssetDirectory
configAsset
getLocalFileUrl
timeIntervalSinceDate:
startCatalogDownload:options:then:
compareAssetVersionReversed:
isDownloading
configAssetInAssets:
_clearCaches
updateAllAssets:
_refreshAllAssets:
_refreshCatalogIfNeededWithCompletion:
results
deleteAsset:completion:
assetsSortedByVersion:
isASRModel
transcribesLocale:
isANEModel
URLByAppendingPathExtension:
bundleForClass:
URLForResource:withExtension:
dataWithContentsOfURL:options:error:
sortUsingComparator:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
availabilityInfo
downloadAsset:downloadOptions:progressCallback:completion:
longLongValue
progressWithTotalUnitCount:
setTotalUnitCount:
setCompletedUnitCount:
attachProgressCallBack:
totalUnitCount
startDownload:then:
_queryLanguagePairStatus:
preferredVoiceGender
arrayWithObject:
setLanguages:
setGender:
_downloadVoiceAsset:
getAutoDownloadedVoiceAssets:
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
assetDirectory
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
_assetIdentifiersForLanguagePairDirectory:
numberWithLong:
_speechTranslationAssetInfoForLocalePair:error:
purgeAssetUserInitiated:queue:completion:
debugDumpAssets:
matchesAsset:
isNewerCompatibleVersionThan:
updateSpeechTranslationAssetSymLinks:
createSymlinkDirectoryForMTAssets
downloadVoiceAssetsForLanguagePair:
downloadAsset:userInitiated:progressCallback:completion:
refreshAllIfNeededWithCompletion:
_downloadPassthroughAssetForLocale:userInitiated:completion:
assetIdentifierReferenceCountDictionary
downloadAssetsUserInitiated:queue:completion:
isCompletePassthroughModel
isCompleteBidirectionalModel
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
getEndpointerAssetWithType:error:
resourceURL
fallBackAssetResourcePath
checkResourceIsReachableAndReturnError:
configurationPropertyListWithURL:
configAssetURL
offlineLanguageStatus:
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
modelURLsForLanguagePair:
speechTranslationAssetInfoForLocalePair:error:
assetSize:
_hotfixMgr
initWithType:
returnTypes:
queryMetaDataSync
initWithSuiteName:
substringToIndex:
setLanguageCode:
outputFileURL
setOutputPath:
audioSessionID
setAudioSessionID:
ttsPlaybackRate
setRate:
setCanUseServerTTS:
startSpeakingRequest:
stopSpeakingAtNextBoundary:synchronously:error:
dictionaryMetrics
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizerDidPauseSpeaking:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:
initWithCompletion:
speak:withContext:
_completion
asrModelURLs
speechModelURLForLocale:
speechModelVersionForLocale:
reason
mtModelURL
translationModelURLs
initWithModelURLs:task:skipNonFinalToCatchup:
loadTranslatorFrom:to:
stringWithCString:encoding:
_loadRecognizers
taskHint
_loadTranslatorForTask:
censorSpeech
_loadEtiquetteSanitizers
tokens
initWithText:confidence:
lowConfidence
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:tokens:preToPostITN:
metaInfo
updateWithEngineMeta:locale:
resultWithLocale:translations:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
initWithIdentifier:range:doNotTranslate:
_handleTranslationResults:withContext:
setSourceString:
setSanitizedSourceString:
translations
translateTokens:from:to:spans:completion:
sanitizedFormattedString
splitIntoSentences
spans
_translateString:withContext:toLocale:withSpans:completion:
_paragraphResultFromSentences:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
_translatePrepare:
passthroughResultWithString:sanitizedString:locale:
uniqueID
translateTokens:isFinal:completion:
prepareFor:to:
UUID
UUIDString
numberWithBool:
_translate:withContext:isFinal:completion:
transcriptions
asrConfidenceThreshold
setLowConfidence:
isLowConfidence
setSanitizedFormattedString:
isStable
_getBestRecognitionResult:context:
_waitForLIDWithContext:completion:
initWithLocalePair:assetInfo:
setAsrModelURLs:
setMtModelURL:
ttsCache
setTtsCache:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_didEndpointSpeech
_earError
_asrModelURLs
_mtModelURL
_ttsCache
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
T@"_LTTextToSpeechCache",&,N,V_ttsCache
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_paragraph
_requestParagraph
T@?,C,N,V_completion
T@"_LTTranslationParagraph",&,N,V_paragraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
request_id
contentAsFTBatchTranslationResponse
paragraph_id
return_string
span
translated_text
initWithOspreyBatchResponse:
updateAlignmentWithSourceSpan:targetSpan:
removeObjectForKey:
setHasFinalServerResponse:
endSuccessfully
endWithError:failedParagraphs:
callCompletionHandlersWithError:
request
setRequest:
toLocale
setToLocale:
batchLog
setBatchLog:
batchedParagraphs
setBatchedParagraphs:
bufferSize
setBufferSize:
setSessionID:
clientHeader
setClientHeader:
clientIdentifier
sourceURL
setSourceURL:
hasFinalServerResponse
completionHandlerCalled
setCompletionHandlerCalled:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_batchLog
_batchedParagraphs
_taskHint
_bufferSize
_sessionID
_clientHeader
_sourceURL
T@"FTMutableBatchTranslationRequest",&,N,V_request
T@"NSLocale",&,N,V_toLocale
T@"LTBatchEventLog",&,N,V_batchLog
T@"NSMutableDictionary",&,N,V_batchedParagraphs
Tq,N,V_taskHint
TQ,N,V_bufferSize
T@"NSLocale",&,N,V_sourceLocale
T@"NSLocale",&,N,V_targetLocale
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
T@"NSString",C,N,V_clientHeader
T@"NSString",&,N,V_clientIdentifier
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
setMaxConcurrentOperationCount:
getSiriDataSharingOptInStatusWithCompletion:
initWithURL:configuration:
setUseCompression:
_webTaskService
_systemService
_blazarService
updateServerTimeout
serverTimeoutFired
sendBatchTranslationRequestWithDelegate:
tokenize:forLocale:
audioDataForKey:
_ospreyTTSRequestWithText:
_serviceForTask:
speech_id
setClientTraceIdentifier:
error_code
error_str
decoder_description
audio
cacheAudioData:forKey:
performTextToSpeechRouter:requestBuilder:completion:
setTranslations:
sequoiaClientHeaderValue
startServerTimeoutTimer
setParagraph_id:
setStart_index:
setEnd_index:
setDo_not_translate:
metaInfoData
initWithData:encoding:
setMeta_info:
setSpan:
cancelServerTimeout
setTask:
setParagraphs:
task
setContentAsFTBatchTranslationRequest:
setContent_type:
setTranslationTask:
setSourceLanguage:
setTargetLanguage:
setDeviceOS:
setDeviceType:
setOsVersion:
setBundleIdentifier:
initWithRequest:
paragraphs
startWithParagraphCount:
setValue:forHTTPHeaderField:
initWithIdentifier:text:spans:
_translateParagraph:index:context:completion:
_hasOngoingSpeechSession
setDataSharingOptInStatus:
initWithService:context:text:delegate:
_speechSessionCompletedWithError:
setCompletionBlock:
sendAudioData:
sendEndAudio
initWithService:context:delegate:
_tokenizeString:inLocale:
serverQueue
setServerQueue:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_dataSharingOptInStatus
_serverQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverQueue
initWithDelegate:
startCompressionNarrowband:
dataSharingOptInStatus
sendAnalyticsEvent
completionBlock
_ospreySpeechTranslationRequestWithHybridEndpointer:
initCommon
_ospreyTextToSpeechTranslationRequestWithText:
updateServerTimeout:
addAudioSampleData:
setPacket_count:
setContentAsFTFinishAudio:
_primaryLanguageRecognized
confirmDataIfNeeded
setContentAsFTLanguageDetected:
setAudio_bytes:
setAudio_frames:
setContentAsFTSpeechTranslationAudioPacket:
source_locale
initWithOspreyPartialRecognitionResponse:isSanitized:
initWithLocaleIdentifier:
initWithOspreyResponse:confidenceThreshold:isSanitized:
server_endpoint_features
initWithOspreySpeechTranslationMTResponse:
is_final_result
target_locale
text_to_speech_response
audio_type
_translationForLocale:
contentAsFTSpeechTranslationPartialRecognitionResponse
_handlePartialRecognitionResponse:
contentAsFTSpeechTranslationFinalRecognitionResponse
_handleFinalRecognitionResponse:
contentAsFTAudioLimitExceeded
_handleAudioLimitExceededResponse:
contentAsFTSpeechTranslationMtResponse
_handleTranslationResponse:
contentAsFTSpeechTranslationTextToSpeechResponse
_handleTTSResponse:
_handleFinalBlazarResponse:
contentAsFTSpeechTranslationServerEndpointFeatures
_handleServerEndpointFeatures:
didCompressPackets:totalPacketCount:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
_streamContext
_sentAudio
_sentEndAudio
_endpointedSpeech
_didReceiveAudioLimitExceededResponse
_didReceivePartialRecognitionResponse
_didReceiveFinalRecognitionResponse
_didReceiveTranslationResponse
_didReceiveTTSResponse
_didReceiveFinalBlazarResponse
_didTimeout
_error
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
Td,N,V_initialOnlineTimeout
Td,N,V_onlineTimeout
Td,N,V_endpointTimeout
T@?,C,N,V_completionBlock
_translationFailedWithError:
string
appendString:
translationParagraph
initWithIdentifier:range:
isValidJSONObject:
dataWithJSONObject:options:error:
setMetaInfoData:
loggingType
_startTranslationWithService:done:
ranges
setRanges:
_ranges
T@"NSArray",C,N,V_ranges
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
dealloc
stop
isAudioQueueRunning
waitForAudioQueueStop
initWithContext:ASBD:
enqueue:packetCount:packetDescriptions:
signalQueueRunningStateChanged
flushAndStop
reset
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
Tq,R,N,V_state
orderedSetWithObjects:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
T@"NSOrderedSet",&,V_requestTypeSet
boolForKey:
arrayForKey:
dictionaryForKey:
URLWithString:
stringByReplacingCharactersInRange:withString:
initWithMaximumPageLoadRequest:maximumDynamicContentRequests:
allowedForRequests:
markPageLoaded
maximumPageLoadRequests
setMaximumPageLoadRequests:
maximumDynamicContentRequests
setMaximumDynamicContentRequests:
_count
_pageLoaded
_maximumPageLoadRequests
_maximumDynamicContentRequests
TQ,N,V_maximumPageLoadRequests
TQ,N,V_maximumDynamicContentRequests
session_id
initWithUUIDString:
app_id
initWithNSUUID:
setSessionId:
setMtId:
setClientAppBundleId:
setNumberOfParagraphs:
makeContext
setStartedOrChanged:
sendWithContext:
setExists:
setEnded:
setDomain:
setErrorCode:
setError:
setNumParagraphFailures:
setFailed:
setReason:
setCancelled:
setContextId:
setEventMetadata:
setBatchRequestContext:
sharedStream
emitMessage:
cancelWithReason:
_playback:context:completion:
initWithEngine:
speak:context:completion:
_engine
_player
enableVAD
initForSeconds:
_startSpeechTranslationWithContext:
_translateSpeechAudioData:
consumeAll:
delegateTranslationDidFinishWithError:
initWithEngine:delegate:
engine
setEngine:
languageDetector
endpointer
_expectFinalLidResult
_sentFinalLidResult
_translationFinished
_speechActivityDetected
_translationError
_cache
_speechDetector
_languageDetector
_endpointer
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
T@"_LTLanguageDetector",R,N,V_languageDetector
T@"_LTHybridEndpointer",R,N,V_endpointer
initWithLocalePair:
setTtsPlaybackRate:
_ttsPlaybackRate
T@"NSString",&,N,V_text
Td,N,V_ttsPlaybackRate
nativeAudioFormat
initWithFormat:
initWithSoundIdentifier:
addRequest:withObserver:error:
initWithStreamDescription:
initWithPCMFormat:frameCapacity:
setFrameLength:
int16ChannelData
analyzeAudioBuffer:atAudioFramePosition:
detected
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
_streamAnalyzer
_position
appendData:
mutableBytes
dataWithBytes:length:
replaceBytesInRange:withBytes:length:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
setData:
next
setNext:
_next
T@"NSData",&,N,V_data
T@"_LTSpeechDataQueueNode",&,N,V_next
_maxFrames
_currentFrames
_head
_tail
setFinal:
setStable:
setModelVersion:
recognition_result
post_itn
recognition_text
containsString:
post_itn_nbest_choices
initWithRecognitionChoice:inSausage:
setTranscriptions:
initWithOspreySausage:choices:locale:
setBestRecognitionAlternatives:
is_stable_result
setFormattedString:
setMinConfidence:
setMaxConfidence:
nBestResults
_transcriptionWithResult:locale:
recognition
initWithRecognition:wordConfidenceThreshold:
initWithFormattedString:locale:confidence:minConfidence:maxConfidence:
initWithPackage:locale:modelVersion:isFinal:
initWithResult:locale:modelVersion:isFinal:
initEmptyResultWithLocale:isFinal:
tokenName
hasSpaceAfter
whitespaceCharacterSet
resultWithPackage:locale:modelVersion:isFinal:
resultWithResult:locale:modelVersion:isFinal:
emptyResultWithLocale:isFinal:
bestRecognitionAlternatives
_final
_stable
_transcriptions
_bestRecognitionAlternatives
_modelVersion
final
TB,N,GisFinal,V_final
stable
TB,N,GisStable,V_stable
T@"NSString",&,N,V_modelVersion
T@"NSLocale",C,N,V_locale
T@"NSArray",&,N,V_transcriptions
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
alternative_index
positional_tok_phrase_alt
tok_phrases
token_text
add_space_after
setHasSpaceAfter:
unsignedIntegerValue
setBestAlternativeIndex:
setAlternatives:
alternatives
setBins:
interpretationIndices
tokenSausage
hasSpaceBefore
bins
_bins
T@"NSArray",&,N,V_bins
bestAlternativeIndex
_alternatives
_bestAlternativeIndex
T@"NSArray",&,N,V_alternatives
TQ,N,V_bestAlternativeIndex
_lowConfidence
_hasSpaceAfter
_confidence
Tq,N,V_confidence
TB,N,GisLowConfidence,V_lowConfidence
TB,N,V_hasSpaceAfter
initWithConfiguration:useQuasarFormatter:
setDetectUtterances:
setConcatenateUtterances:
runRecognitionWithResultStream:language:task:samplingRate:
recognitionHandler
_recognizedResult:error:
detectUtterances
stringWithString:
hatToQsrString:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
speechRecognizer:didProduceLoggablePackage:
modelURL
setRecognitionHandler:
_buffer
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelURL
_language
_recognitionHandler
T@?,C,N,V_recognitionHandler
T@"NSURL",R,N,V_modelURL
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
_formattedString
_sanitizedFormattedString
_minConfidence
_maxConfidence
Td,N,V_confidence
Td,N,V_minConfidence
Td,N,V_maxConfidence
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
_getTranslationConfig
referenceAssets:catalogAssets:
updateAvailableInAssets:
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
isMTModel
isPhrasebook
isCurrentlyAvailable
_mtModelOfflineState
_languagePairDirectory
assetId
createSymbolicLinkAtPath:withDestinationPath:error:
writeToURL:atomically:
moveItemAtURL:toURL:error:
currentProgress
initWithParent:userInfo:
becomeCurrentWithPendingUnitCount:
resignCurrent
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_modelURLs
refreshState
hasResults
_isBuffering
_lastASRResults
_translationResult
_didFinish
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
countForObject:
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
initWithModel:
processString:
languageHypothesesWithMaximum:
availableLocales
detectionForString:
detectionForStrings:
setAvailableLocales:
_availableLocales
T@"NSArray",C,N,V_availableLocales
clear
_cacheQueue
getCharacters:range:
componentsSeparatedByCharactersInSet:
predicateWithFormat:
filteredArrayUsingPredicate:
initWithUnit:
setLanguage:
setString:
enumerateTokensInRange:usingBlock:
stringWithCharacters:length:
sharedConnection
isOnDeviceOnlyTranslationForced
initWithBundleIdentifier:
specifiersForPolicyOptions:force:
groupSpecifierWithID:
rangeOfString:
valueWithNonretainedObject:
setPreferenceValue:specifier:
readPreferenceValue:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
presenterForPrivacySplashWithIdentifier:
setPresentingViewController:
present
specifiers
showTranslatePrivacy
translated_tokens
initWithOspreyToken:
setTokens:
translation_phrase
low_confidence
meta_info
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:locale:
dataUsingEncoding:
statisticsWithEngineMeta:locale:
setStatistics:
sensesFromArray:
senseWithPhrasebookMatchMeta:
preToPostITN
statistics
proToPostITN
setProToPostITN:
_preToPostITN
_tokens
_statistics
_proToPostITN
T@"NSArray",C,N,V_tokens
T@"NSArray",C,N,V_proToPostITN
T@"_LTTranslationStatistics",C,N,V_statistics
T@"NSArray",R,N,V_preToPostITN
setRestricted_mode:
_ospreyDataSharingStatus
setOpt_in_status:
setStreaming_mode:
setTranslation_locale_pairs:
setSpeech_id:
setTask_name:
setCodec:
setStream_results:
setStore_audio:
setEnd_point_mode:
setEnable_server_side_endpoint:
setClient_endpointer_model_version:
setEnable_hybrid_endpoint:
setKeyboard_identifier:
setInput_origin:
setInitial_recognition_candidate_id:
setDisable_auto_punctuation:
setStart_speech_request:
setTranslation_request:
_ttsVoiceStringWithLocale:
setAudio_type:
setChannel_type:
setText_to_speech_requests:
setContentAsFTStartSpeechTranslationRequest:
setTranslation_phrase:
redactIfNeeded:
appendFormat:
sourceOrigin
decodeInt32ForKey:
encodeInt32:forKey:
setUniqueID:
setAutodetectLanguage:
setCensorSpeech:
setOutputFileURL:
setAutoEndpoint:
setLidThreshold:
setAsrConfidenceThreshold:
setEnableVAD:
setAppIdentifier:
setSourceOrigin:
_autodetectLanguage
_censorSpeech
_autoEndpoint
_enableVAD
_audioSessionID
_uniqueID
_outputFileURL
_lidThreshold
_route
_asrConfidenceThreshold
_sourceOrigin
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
TB,N,V_autodetectLanguage
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
TB,N,V_enableVAD
T@"NSString",C,N,V_appIdentifier
Tq,N,V_sourceOrigin
Tq,N,V_dataSharingOptInStatus
setSourceContentAsJSON:
setTargetContentAsJSON:
setErrorsAsJSON:
setSafariVersion:
setWebpageURL:
_sourceContentAsJSON
_targetContentAsJSON
_errorsAsJSON
_safariVersion
_webpageURL
_clientBundleID
T@"NSString",C,N,V_clientBundleID
T@"NSString",C,N,V_sourceContentAsJSON
T@"NSString",C,N,V_targetContentAsJSON
T@"NSString",C,N,V_errorsAsJSON
T@"NSString",C,N,V_safariVersion
T@"NSURL",C,N,V_webpageURL
initWithString:
addAttribute:value:range:
sentences
initWithIdentifier:range:shouldTranslate:metaInfoData:
enumerateAttributesInRange:options:usingBlock:
_spans
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
T@"NSArray",R,C,N,V_spans
initWithIdentifier:text:shouldTranslate:
setMetaInfo:
_metaInfo
TB,R,N,V_shouldTranslate
T@"NSDictionary",C,N,V_metaInfo
_offlineMTModelURL
opaqueSessionID
serviceDelegate
setForcedOfflineTranslation:
set_forcedOnlineTranslation:
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
TB,N,V_forcedOfflineTranslation
TB,N,V__forcedOnlineTranslation
T@"NSURL",&,N,V__offlineMTModelURL
Tq,N,V__mtConfidenceThreshold
ignoringAttributes
initForFutureService
prepareWithService:
_paragraphRequestForText:
_handleParagraphResponse:error:
translate:
textTranslationHandler
alignments
initWithString:attributes:
appendAttributedString:
_realign:identifier:
_constructFinalParagraphResult
sentence
setSentence:
setIgnoringAttributes:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
setTextTranslationHandler:
_session
_savedAttributes
_paragraphOrder
_outstandingCount
_receivedParagraphs
_sentence
_ignoringAttributes
_textHandler
_translationHandler
_textTranslationHandler
T@"NSString",C,N,V_sentence
T@"NSAttributedString",C,N,V_text
T@"NSArray",C,N,V_ignoringAttributes
T@?,C,N,V_textHandler
T@?,C,N,V_translationHandler
T@?,C,N,V_textTranslationHandler
_paragraphs
T@"NSArray",C,N,V_paragraphs
_offlineASRModelURLs
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:simulateRealtime:
format
frameLength
_convertAndFeedPCMBuffer:
sleepForTimeInterval:
subdataWithRange:
_drainAndClearAudioConverter
_simulateRealtimeBehavior:
mutableAudioBufferList
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
appendAudioPCMBuffer:
append:simulateRealtime:
_lidModelURL
set_lidModelURL:
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
T@"NSURL",&,N,V__lidModelURL
T@"NSArray",&,N,V__offlineASRModelURLs
Tq,N,V__asrConfidenceThreshold
Tq,N,V__lidThreshold
initWithLength:
translation_locale_pair
n_best_translated_phrases
start_index
end_index
do_not_translate
setAlignments:
initWithOspreyResponse:
sourceString
sanitizedSourceString
_translations
_sourceString
_sanitizedSourceString
_alignments
T@"NSArray",C,N,V_translations
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
senseID
definition
sourceMatch
targetMatch
senseFromDictionary:
setSenseID:
setDefinition:
setPhrasebookMatch:
isPhrasebookMatch
setSourceMatch:
setTargetMatch:
setLabels:
labels
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
_labels
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
T@"NSArray",C,N,V_labels
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
_speechSessionCompleted
cancelSpeechSession
cleanupOfflineEngine
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
_activityLogger
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
_commonInit
service
setService:
unsignedIntValue
setRateLimiter:
translationQueue
_getServiceProxyWithDelegate:errorHandler:block:
_ensureServiceConnection:
log:
initWithTranslator:
provideFeedback:
setURL:
translator
setTranslator:
rateLimiter
setTranslationQueue:
_outstandingRequests
_logging
_waitingForService
_URL
_rateLimiter
T@"_LTTranslator",&,N,V_translator
T@"<_LTTranslationService>",&,N,V_service
T@"_LTRateLimiter",&,N,V_rateLimiter
T@"NSObject<OS_dispatch_queue>",&,N,V_translationQueue
T@"NSURL",C,N,V_URL
_metaInfoData
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
T@"NSData",C,N,V_metaInfoData
stringByReplacingOccurrencesOfString:withString:options:range:
_ltRemoveAllWhitespaces
_ltTrimWhitespaces
_countWithTokenString:countCharacters:
setInputTokenCount:
setInputSubtokenCount:
allocWithZone:
inputTokenCount
inputSubtokenCount
_inputTokenCount
_inputSubtokenCount
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
_getSyncServiceProxyWithDelegate:errorHandler:block:
initWithMachServiceName:options:
invalidate
remoteObjectProxyWithErrorHandler:
initWithServiceName:options:
synchronousRemoteObjectProxyWithErrorHandler:
archivedDataWithRootObject:requiringSecureCoding:error:
interruptionHandler
installOfflineLocales:completion:
taskIsSupportedInCurrentRegion:completion:
T@?,C,N
preheatForRequestSync:
preheatForRequest:completion:
startTranslationSession
requiredCapabilityIdentifier
assetVersion
isCompatibleWithThisDevice
isNewerVersionThan:
localeIdentifiers
canBePurged
translatesLanguagePair:
formatVersion
dictionaryRepresentation
initWithDictionary:
hasLocale
setHasLocale:
hasConfidence
setHasConfidence:
readFrom:
writeTo:
jsonData
initWithJSON:
_has
Ti,N,V_locale
TB,N
TI,N,V_confidence
T@"NSData",R,N
setSenseId:
senseId
hasSenseId
setHasSenseId:
_senseId
_hasSenseId
T@"NSString",C,N,V_senseId
TB,N,V_hasSenseId
hasReason
setHasReason:
_reason
_hasReason
T@"NSString",C,N,V_reason
TB,N,V_hasReason
setStarted:
started
ended
failed
cancelled
whichContextevent
hasStarted
setHasStarted:
hasEnded
setHasEnded:
setHasFailed:
hasCancelled
setHasCancelled:
_started
_ended
_failed
_cancelled
_hasStarted
_hasEnded
_hasFailed
_hasCancelled
_whichContextevent
T@"MTSchemaProvisionalMTAppLanguageIdentificationStarted",&,N,V_started
TB,N,V_hasStarted
T@"MTSchemaProvisionalMTAppLanguageIdentificationEnded",&,N,V_ended
TB,N,V_hasEnded
T@"MTSchemaProvisionalMTAppLanguageIdentificationFailed",&,N,V_failed
TB,N,V_hasFailed
T@"MTSchemaProvisionalMTAppLanguageIdentificationCancelled",&,N,V_cancelled
TB,N,V_hasCancelled
TQ,R,N,V_whichContextevent
setAlternateLocale:
alternateLocale
hasSelectedLocale
hasAlternateLocale
setHasSelectedLocale:
setHasAlternateLocale:
_alternateLocale
_hasSelectedLocale
_hasAlternateLocale
T@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence",&,N,V_selectedLocale
TB,N,V_hasSelectedLocale
T@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence",&,N,V_alternateLocale
TB,N,V_hasAlternateLocale
error
hasError
setHasError:
_hasError
T@"MTSchemaProvisionalMTError",&,N,V_error
TB,N,V_hasError
setUserSelectedLocale:
userSelectedLocale
hasUserSelectedLocale
setHasUserSelectedLocale:
_userSelectedLocale
_hasUserSelectedLocale
T@"NSString",C,N,V_userSelectedLocale
TB,N,V_hasUserSelectedLocale
exists
hasExists
setHasExists:
_exists
TB,N,V_exists
setInputSourceAppBundleId:
inputSourceAppBundleId
hasInputSourceAppBundleId
setHasInputSourceAppBundleId:
_inputSourceAppBundleId
_hasInputSourceAppBundleId
T@"NSString",C,N,V_inputSourceAppBundleId
TB,N,V_hasInputSourceAppBundleId
contextId
startedOrChanged
hasContextId
setHasContextId:
hasStartedOrChanged
setHasStartedOrChanged:
_contextId
_startedOrChanged
_hasContextId
_hasStartedOrChanged
T@"SISchemaUUID",&,N,V_contextId
TB,N,V_hasContextId
T@"MTSchemaProvisionalMTBatchRequestStarted",&,N,V_startedOrChanged
TB,N,V_hasStartedOrChanged
T@"MTSchemaProvisionalMTBatchRequestEnded",&,N,V_ended
T@"MTSchemaProvisionalMTBatchRequestFailed",&,N,V_failed
T@"MTSchemaProvisionalMTBatchRequestCancelled",&,N,V_cancelled
numParagraphFailures
hasNumParagraphFailures
setHasNumParagraphFailures:
_numParagraphFailures
TI,N,V_numParagraphFailures
numberOfParagraphs
hasNumberOfParagraphs
setHasNumberOfParagraphs:
_numberOfParagraphs
TI,N,V_numberOfParagraphs
getAnyEventType
isProvisional
getTypeId
getVersion
setInvocationContext:
setSessionContext:
setAppTextPasted:
setAppLIDContext:
setAppLIDInteracted:
setAppDisambiguationInteracted:
setSpeechRecognitionSignal:
setUserFacingSessionSignal:
eventMetadata
batchRequestContext
invocationContext
sessionContext
appTextPasted
appLIDContext
appLIDInteracted
appDisambiguationInteracted
speechRecognitionSignal
userFacingSessionSignal
whichEvent_Type
hasEventMetadata
setHasEventMetadata:
hasBatchRequestContext
setHasBatchRequestContext:
hasInvocationContext
setHasInvocationContext:
hasSessionContext
setHasSessionContext:
hasAppTextPasted
setHasAppTextPasted:
hasAppLIDContext
setHasAppLIDContext:
hasAppLIDInteracted
setHasAppLIDInteracted:
hasAppDisambiguationInteracted
setHasAppDisambiguationInteracted:
hasSpeechRecognitionSignal
setHasSpeechRecognitionSignal:
hasUserFacingSessionSignal
setHasUserFacingSessionSignal:
_eventMetadata
_batchRequestContext
_invocationContext
_sessionContext
_appTextPasted
_appLIDContext
_appLIDInteracted
_appDisambiguationInteracted
_speechRecognitionSignal
_userFacingSessionSignal
_hasEventMetadata
_hasBatchRequestContext
_hasInvocationContext
_hasSessionContext
_hasAppTextPasted
_hasAppLIDContext
_hasAppLIDInteracted
_hasAppDisambiguationInteracted
_hasSpeechRecognitionSignal
_hasUserFacingSessionSignal
_whichEvent_Type
T@"MTSchemaProvisionalMTClientEventMetadata",&,N,V_eventMetadata
TB,N,V_hasEventMetadata
T@"MTSchemaProvisionalMTBatchRequestContext",&,N,V_batchRequestContext
TB,N,V_hasBatchRequestContext
T@"MTSchemaProvisionalMTInvocationContext",&,N,V_invocationContext
TB,N,V_hasInvocationContext
T@"MTSchemaProvisionalMTSessionContext",&,N,V_sessionContext
TB,N,V_hasSessionContext
T@"MTSchemaProvisionalMTAppTextPasted",&,N,V_appTextPasted
TB,N,V_hasAppTextPasted
T@"MTSchemaProvisionalMTAppLanguageIdentificationContext",&,N,V_appLIDContext
TB,N,V_hasAppLIDContext
T@"MTSchemaProvisionalMTAppLanguageIdentificationInteracted",&,N,V_appLIDInteracted
TB,N,V_hasAppLIDInteracted
T@"MTSchemaProvisionalMTAppDisambiguationInteracted",&,N,V_appDisambiguationInteracted
TB,N,V_hasAppDisambiguationInteracted
T@"MTSchemaProvisionalMTSpeechTranslationSignal",&,N,V_speechRecognitionSignal
TB,N,V_hasSpeechRecognitionSignal
T@"MTSchemaProvisionalMTUserFacingSessionSignal",&,N,V_userFacingSessionSignal
TB,N,V_hasUserFacingSessionSignal
TQ,R,N,V_whichEvent_Type
mtId
sessionId
clientAppBundleId
hasMtId
hasSessionId
hasClientAppBundleId
setHasMtId:
setHasSessionId:
setHasClientAppBundleId:
_mtId
_sessionId
_clientAppBundleId
_hasMtId
_hasSessionId
_hasClientAppBundleId
T@"SISchemaUUID",&,N,V_mtId
TB,N,V_hasMtId
T@"SISchemaUUID",&,N,V_sessionId
TB,N,V_hasSessionId
T@"NSString",C,N,V_clientAppBundleId
TB,N,V_hasClientAppBundleId
errorCode
hasDomain
hasErrorCode
setHasErrorCode:
setHasDomain:
_domain
_errorCode
_hasDomain
T@"NSString",C,N,V_domain
TB,N,V_hasDomain
TI,N,V_errorCode
T@"MTSchemaProvisionalMTInvocationStarted",&,N,V_startedOrChanged
T@"MTSchemaProvisionalMTInvocationEnded",&,N,V_ended
T@"MTSchemaProvisionalMTInvocationFailed",&,N,V_failed
T@"MTSchemaProvisionalMTInvocationCancelled",&,N,V_cancelled
setIsOnDeviceTranslationEnabled:
setMobileAssetConfigVersion:
setMtLanguagePair:
setInputMode:
setIsExplicitLanguageFilterEnabled:
setIsLanguageIdentificationEnabled:
setUiMode:
mobileAssetConfigVersion
mtLanguagePair
isOnDeviceTranslationEnabled
inputMode
isExplicitLanguageFilterEnabled
isLanguageIdentificationEnabled
uiMode
hasIsOnDeviceTranslationEnabled
setHasIsOnDeviceTranslationEnabled:
hasMobileAssetConfigVersion
hasTask
setHasTask:
hasMtLanguagePair
hasInputMode
setHasInputMode:
hasIsExplicitLanguageFilterEnabled
setHasIsExplicitLanguageFilterEnabled:
hasIsLanguageIdentificationEnabled
setHasIsLanguageIdentificationEnabled:
hasUiMode
setHasUiMode:
setHasMobileAssetConfigVersion:
setHasMtLanguagePair:
_isOnDeviceTranslationEnabled
_mobileAssetConfigVersion
_task
_mtLanguagePair
_inputMode
_isExplicitLanguageFilterEnabled
_isLanguageIdentificationEnabled
_uiMode
_hasMobileAssetConfigVersion
_hasMtLanguagePair
TB,N,V_isOnDeviceTranslationEnabled
T@"NSString",C,N,V_mobileAssetConfigVersion
TB,N,V_hasMobileAssetConfigVersion
Ti,N,V_task
T@"MTSchemaProvisionalMTLanguagePair",&,N,V_mtLanguagePair
TB,N,V_hasMtLanguagePair
Ti,N,V_inputMode
TB,N,V_isExplicitLanguageFilterEnabled
TB,N,V_isLanguageIdentificationEnabled
Ti,N,V_uiMode
sourceLanguage
targetLanguage
hasSourceLanguage
setHasSourceLanguage:
hasTargetLanguage
setHasTargetLanguage:
_sourceLanguage
_targetLanguage
Ti,N,V_sourceLanguage
Ti,N,V_targetLanguage
T@"MTSchemaProvisionalMTSessionStarted",&,N,V_started
T@"MTSchemaProvisionalMTSessionEnded",&,N,V_ended
T@"MTSchemaProvisionalMTSessionFailed",&,N,V_failed
T@"MTSchemaProvisionalMTSessionCancelled",&,N,V_cancelled
setSpeechRequestStatus:
speechRequestStatus
hasSpeechRequestStatus
setHasSpeechRequestStatus:
_speechRequestStatus
Ti,N,V_speechRequestStatus
setUserFacingSessionStatus:
userFacingSessionStatus
hasUserFacingSessionStatus
setHasUserFacingSessionStatus:
_userFacingSessionStatus
Ti,N,V_userFacingSessionStatus
arrayWithCapacity:
arrayWithArray:
initWithAttributedString:
rangeOfCharacterFromSet:
rangeOfCharacterFromSet:options:
tokensForRange:
attributedSubstringFromRange:
_ltAttributedStringByTrimmingCharactersInSet:
T@"NSArray",R,N
stringByReplacingOccurrencesOfString:withString:
initWithFlatbuffData:root:verify:
initWithBytes:length:encoding:
profile_blob:
profile_blob_version
profile_checksum
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
profile_blob
_storage
_root
acoustic_profile_version
acoustic_profile_blob:
acoustic_profile_blob
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
phone_seq
ipa_phone_seq
Ti,R,N
TB,R,N
has_unsuggested_alternatives
numberWithInt:
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
pre_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
T@"FTRecognitionSausage",R,N
bool_stats
int32_stats
double_stats
request_locale
name
value
Td,R,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
numberWithFloat:
acoustic_feature_per_frame
frame_duration
Tf,R,N
speech_recognition_features
acoustic_features
T@"FTAcousticFeature",R,N
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",R,N
Tq,R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,R,N
TI,R,N
start_speech_request
user_parameters
primary_speech_id
T@"FTStartSpeechRequest",R,N
product_id
vendor_id
contextual_text
pron_hints
left_context
right_context
context_with_pron_hints
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
audio_bytes:
audio_bytes
packet_count
total_audio_recorded_seconds
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
orthography
pronunciations:
frequency
pronunciations
category_name
category_data
user_data
incomplete_profile
recreate_apg_prons
phonemes
blob:
blob
apg_id
voc_token
tts_pronunciations
human_readable_prons
T@"FTVocToken",R,N
apg_ids
recovery_return_codes
voc_tokens
num_of_requested
num_of_processed
num_of_succeeded
words_list
formatted_words_list
post_itn_string
nbest_variants_max
normalized_tokens
original_token
nbest_variants
pron_sequence
log_weight
pron_source
sanitized_sequences
prons
normalized_prons
sanitized_tokens
T@"FTContextWithPronHints",R,N
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
jit_token_prons
index
raw_sausage
raw_nbest_choices
post_itn_tokens
post_itn_recognition
itn_alignments
pre_itn_payload
post_itn_payload
pre_sausage_payload
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
engine_input
engine_output
mt_alignment
T@"FTAlignment",R,N
end_point_likelihood
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
match_ids
debug_information
matcher_id
query
target
config
T@"FTAStarFuzzyMatchingConfig",R,N
latency
expanded_path
keyword_orthography
posterior
keywords
enable_sanitization
corrected_sausage
n_best_list
original_utterance
corrected_utterance
original_words
corrected_words
corrections
fe_feature
fe_feature_only
disable_prompts
cache_only
quality
type
voice
resource
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
channel_type
is_synthesis
context_info
dialog_identifier
experiment_identifier
word_phonemes
prompts
prompts_v2:
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data:
resources
enable_word_timing_info
voice_name
preferred_voice_type
context
experiment
feature_flags
debug
profile
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTTextToSpeechRequestDebug",R,N
T@"FTTextToSpeechUserProfile",R,N
word
sample_idx
offset
timestamp
audio:
playback_description
word_timing_info
feature
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_meta_info
cache_object
T@"FTTextToSpeechCacheMetaInfo",R,N
endpoint_threshold
endpoint_extra_delay
audio_frames
conversation_id
translation_locale_pairs
translation_request
text_to_speech_requests
restricted_mode
streaming_mode
T@"FTTranslationRequest",R,N
detected_locale
user_selected_locale
user_selected_sense
user_interacted_senses
T@"FTTranslationLocalePair",R,N
T@"FTLanguageDetected",R,N
T@"FTTextToSpeechResponse",R,N
T@"FTServerEndpointFeatures",R,N
utterance
shortcuts
interaction_id
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
raw_string
shortcut_score_pairs
shortcut
similarity_score
language_parameters_by_id
is_low_confidence
predictions
source_content
translated_content
errors
safari_version
os_version
sentence_count
contentAsFTStartPronGuessRequest
contentAsFTAudioPacket
contentAsFTFinishAudio
contentAsFTCancelRequest
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
contentAsFTPronGuessResponse
T@"FTPronGuessResponse",R,N
contentAsFTStartBatchRecoverRequest
T@"FTStartBatchRecoverRequest",R,N
contentAsFTBatchRecoverFinalResponse
T@"FTBatchRecoverFinalResponse",R,N
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
contentAsFTSetRequestOrigin
contentAsFTSetSpeechContext
contentAsFTSetSpeechProfile
contentAsFTSetEndpointerState
contentAsFTResetServerEndpointer
contentAsFTCheckForSpeechRequest
contentAsFTSetAlternateRecognitionSausage
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
contentAsFTFinalSpeechRecognitionResponse
contentAsFTPartialSpeechRecognitionResponse
contentAsFTUpdatedAcousticProfile
contentAsFTEndPointLikelihood
contentAsFTEndPointCandidate
contentAsFTRecognitionProgress
contentAsFTCheckForSpeechResponse
contentAsFTRecognitionCandidate
contentAsFTRequestStatsResponse
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
contentAsFTMultiUserStartSpeechRequest
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
contentAsFTStartMultilingualSpeechRequest
contentAsFTLanguageDetected
T@"FTStartMultilingualSpeechRequest",R,N
contentAsFTStartSpeechTranslationRequest
contentAsFTSpeechTranslationAudioPacket
contentAsFTStartSpeechTranslationLoggingRequest
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
contentAsFTBatchTranslationRequest
contentAsFTBatchTranslationFeedbackRequest
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationFeedbackRequest",R,N
T@"FTBatchTranslationResponse",R,N
contentAsFTStartTextToSpeechStreamingRequest
T@"FTStartTextToSpeechStreamingRequest",R,N
contentAsFTBeginTextToSpeechStreamingResponse
contentAsFTPartialTextToSpeechStreamingResponse
contentAsFTFinalTextToSpeechStreamingResponse
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
contentAsFTQssAckResponse
T@"FTQssAckResponse",R,N
contentAsFTStartLanguageDetectionRequest
T@"FTStartLanguageDetectionRequest",R,N
contentAsFTLanguageDetectionResponse
T@"FTLanguageDetectionResponse",R,N
setProfile_blob:
setProfile_blob_version:
setProfile_checksum:
T@"NSData",C,N
T@"NSString",C,N
setAcoustic_profile_version:
setAcoustic_profile_blob:
initWithInt:
initWithBool:
setToken_text:
setStart_milli_seconds:
setEnd_milli_seconds:
setSilence_start_milli_seconds:
setAdd_space_after:
setPhone_seq:
setIpa_phone_seq:
Ti,N
T@"NSArray",C,N
setTok_phrases:
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
setItn_alignment:
setPost_itn_choice_indices:
setPre_itn_token_to_post_itn_char_alignments:
setPre_itn:
setPost_itn:
setPre_itn_nbest_choices:
setPost_itn_nbest_choices:
setPre_itn_token_to_post_itn_char_alignment:
setChoice_alignments:
T@"FTRecognitionSausage",C,N
setBool_stats:
setInt32_stats:
setDouble_stats:
setRequest_locale:
setName:
setValue:
initWithDouble:
Td,N
setFirst_pre_itn_token_index:
setLast_pre_itn_token_index:
setFirst_post_itn_char_pos:
setLast_post_itn_char_pos:
initWithFloat:
setAcoustic_feature_per_frame:
setFrame_duration:
Tf,N
setSpeech_recognition_features:
setAcoustic_features:
setKey:
T@"FTAcousticFeature",C,N
initWithInteger:
setReturn_code:
setReturn_str:
setRecognition_result:
setLang_profile_recreate_codes:
setAudio_analytics:
setWatermark_detection:
setWatermark_peak_average:
setLatnn_mitigator_result:
setHas_result:
T@"FTRecognitionResult",C,N
Tq,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
setRecognition_text:
setIs_stable_result:
setAudio_duration_ms:
unsignedLongValue
initWithUnsignedLong:
initWithUnsignedInteger:
setDevice_os:
setMic_type:
setUdm_host:
setUdm_port:
setTandem_mode:
setStream_unstable_results:
setStart_audio_bookmark:
setIs_far_field:
setEnable_utterance_detection:
setEnable_endpoint_candidate:
setStart_recognition_at:
setStart_endpointing_at:
setKeyboard_dictation:
setExperiment_id:
setSpeech_request_source:
setFork_id:
setApplication_name:
setMetadata:
TQ,N
TI,N
setUser_parameters:
setPrimary_speech_id:
T@"FTStartSpeechRequest",C,N
setProduct_id:
setVendor_id:
setContextual_text:
setPron_hints:
setLeft_context:
setRight_context:
setContext_with_pron_hints:
setUser_language_profile:
setUser_acoustic_profile:
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
setTotal_audio_recorded_seconds:
setFeatures_at_endpoint:
setServer_feature_latency_distribution:
setUpdated_acoustic_profile:
setOrthography:
setPronunciations:
setFrequency:
setTag:
setAttributes:
setCategory_name:
setCategory_data:
setUser_data:
setError_code:
setError_str:
setIncomplete_profile:
setRecreate_apg_prons:
setPhonemes:
setBlob:
setApg_id:
setVoc_token:
setTts_pronunciations:
setHuman_readable_prons:
T@"FTVocToken",C,N
setApg_ids:
setRecovery_return_codes:
setVoc_tokens:
setNum_of_requested:
setNum_of_processed:
setNum_of_succeeded:
setWords_list:
setFormatted_words_list:
setPost_itn_string:
setNbest_variants_max:
setNormalized_tokens:
setOriginal_token:
setNbest_variants:
setPron_sequence:
setLog_weight:
setPron_source:
setSanitized_sequences:
setProns:
setNormalized_prons:
setSanitized_tokens:
T@"FTContextWithPronHints",C,N
setIs_pron_guessed:
setG2p_version:
setG2p_model_version:
setPhoneset_version:
setAot_token_prons:
setJit_token_prons:
setIndex:
setRaw_sausage:
setRaw_nbest_choices:
setPost_itn_tokens:
setPost_itn_recognition:
setItn_alignments:
setPre_itn_payload:
setPost_itn_payload:
setPre_sausage_payload:
setSpans:
setSiri_translation_info:
setSpeech_translation_info:
setSiri_payload_translation_info:
setSequence_id:
setWeb_translation_info:
setDisable_log:
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
setReturn_string:
setN_best_translated_phrases:
setEngine_input:
setEngine_output:
setMt_alignment:
T@"FTAlignment",C,N
setTranslated_tokens:
setLow_confidence:
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
setLatitude:
setLongitude:
setEnable_geo_location_features:
longValue
initWithLong:
setSpeech_packet_count:
setProcessed:
setVersion:
setThreshold:
setScore:
setResult_id:
setSnr:
setFingerprint_detection:
setStart_speech_time:
setEnd_speech_time:
setSpeech_detected:
setAudio_packets:
setRef_transcript:
setBlamer_report:
setToken_str:
setLog10_score:
setNgram_used:
setTranscript:
setPpl:
setEnable_completion:
setMax_results:
setMax_expand_paths:
setMax_tm_score:
setAbs_pruning_threshold:
setRel_pruning_threshold:
setEnable_word_boundary:
setMax_path_num_at_boundary:
setParabolic_error_wide:
setParabolic_error_center:
setParabolic_error_bias:
setParabolic_error_min:
setMax_latency:
setWord_penalty:
setDelimiter:
setMatched_result:
setTotal_score:
setTm_score:
setMatch_ids:
setDebug_information:
setMatcher_id:
setQuery:
setTarget:
setConfig:
T@"FTAStarFuzzyMatchingConfig",C,N
setLatency:
setExpanded_path:
setResults:
setKeyword_orthography:
setPosterior:
setKeywords:
setEnable_sanitization:
setCorrected_sausage:
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
setOriginal_utterance:
setCorrected_utterance:
setOriginal_words:
setCorrected_words:
setCorrections:
setFe_feature:
setFe_feature_only:
setDisable_prompts:
setCache_only:
setQuality:
setType:
setVoice:
setResource:
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
setIs_synthesis:
setContext_info:
setDialog_identifier:
setExperiment_identifier:
setWord_phonemes:
setPrompts:
setPrompts_v2:
setOriginal:
setReplacement:
setNormalized_text:
setPhoneme_sequence:
setNeural_phoneme_sequence:
setForce_use_tts_service:
setDisable_cache:
setResources:
setEnable_word_timing_info:
setVoice_name:
setPreferred_voice_type:
setContext:
setExperiment:
setFeature_flags:
setDebug:
setProfile:
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
T@"FTTextToSpeechRequestDebug",C,N
T@"FTTextToSpeechUserProfile",C,N
setSample_rate:
setFormat_id:
setFormat_flags:
setBytes_per_packet:
setFrames_per_packet:
setBytes_per_frame:
setChannels_per_frame:
setBits_per_channel:
setReserved:
setWord:
setSample_idx:
setOffset:
setLength:
setTimestamp:
setAudio:
setDecoder_description:
setPlayback_description:
setWord_timing_info:
setFeature:
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setCurrent_pkt_number:
setTotal_pkt_number:
setAudio_length:
setOriginal_session_id:
setCache_meta_info:
setCache_object:
T@"FTTextToSpeechCacheMetaInfo",C,N
setEndpoint_threshold:
setEndpoint_extra_delay:
T@"FTTranslationRequest",C,N
T@"FTTranslationLocalePair",C,N
T@"FTLanguageDetected",C,N
setIs_final_result:
setText_to_speech_response:
T@"FTTextToSpeechResponse",C,N
setServer_endpoint_features:
T@"FTServerEndpointFeatures",C,N
setUtterance:
setShortcuts:
setInteraction_id:
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
setRaw_string:
setShortcut_score_pairs:
setShortcut:
setSimilarity_score:
setLanguage_parameters_by_id:
setTranslated_text:
setSentence_count:
setContentAsFTStartPronGuessRequest:
setContentAsFTAudioPacket:
setContentAsFTCancelRequest:
T@"FTStartPronGuessRequest",C,N
T@"FTAudioPacket",C,N
T@"FTFinishAudio",C,N
T@"FTCancelRequest",C,N
setContentAsFTPronGuessResponse:
T@"FTPronGuessResponse",C,N
setContentAsFTStartBatchRecoverRequest:
T@"FTStartBatchRecoverRequest",C,N
setContentAsFTBatchRecoverFinalResponse:
T@"FTBatchRecoverFinalResponse",C,N
setContentAsFTStartSpeechRequest:
setContentAsFTUpdateAudioInfo:
setContentAsFTSetRequestOrigin:
setContentAsFTSetSpeechContext:
setContentAsFTSetSpeechProfile:
setContentAsFTSetEndpointerState:
setContentAsFTResetServerEndpointer:
setContentAsFTCheckForSpeechRequest:
setContentAsFTSetAlternateRecognitionSausage:
T@"FTUpdateAudioInfo",C,N
T@"FTSetRequestOrigin",C,N
T@"FTSetSpeechContext",C,N
T@"FTSetSpeechProfile",C,N
T@"FTSetEndpointerState",C,N
T@"FTResetServerEndpointer",C,N
T@"FTCheckForSpeechRequest",C,N
T@"FTSetAlternateRecognitionSausage",C,N
setContentAsFTFinalSpeechRecognitionResponse:
setContentAsFTPartialSpeechRecognitionResponse:
setContentAsFTUpdatedAcousticProfile:
setContentAsFTEndPointLikelihood:
setContentAsFTEndPointCandidate:
setContentAsFTRecognitionProgress:
setContentAsFTCheckForSpeechResponse:
setContentAsFTRecognitionCandidate:
setContentAsFTRequestStatsResponse:
setContentAsFTServerEndpointFeatures:
setContentAsFTClientSetupInfo:
setContentAsFTAudioLimitExceeded:
T@"FTFinalSpeechRecognitionResponse",C,N
T@"FTPartialSpeechRecognitionResponse",C,N
T@"FTUpdatedAcousticProfile",C,N
T@"FTEndPointLikelihood",C,N
T@"FTEndPointCandidate",C,N
T@"FTRecognitionProgress",C,N
T@"FTCheckForSpeechResponse",C,N
T@"FTRecognitionCandidate",C,N
T@"FTRequestStatsResponse",C,N
T@"FTClientSetupInfo",C,N
T@"FTAudioLimitExceeded",C,N
setContentAsFTMultiUserStartSpeechRequest:
T@"FTMultiUserStartSpeechRequest",C,N
setContentAsFTFinalBlazarResponse:
T@"FTFinalBlazarResponse",C,N
setContentAsFTStartMultilingualSpeechRequest:
T@"FTStartMultilingualSpeechRequest",C,N
T@"FTStartSpeechTranslationRequest",C,N
T@"FTSpeechTranslationAudioPacket",C,N
T@"FTStartSpeechTranslationLoggingRequest",C,N
setContentAsFTSpeechTranslationPartialRecognitionResponse:
setContentAsFTSpeechTranslationFinalRecognitionResponse:
setContentAsFTSpeechTranslationMtResponse:
setContentAsFTSpeechTranslationTextToSpeechResponse:
setContentAsFTSpeechTranslationServerEndpointFeatures:
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
T@"FTSpeechTranslationMtResponse",C,N
T@"FTSpeechTranslationTextToSpeechResponse",C,N
T@"FTSpeechTranslationServerEndpointFeatures",C,N
T@"FTBatchTranslationRequest",C,N
T@"FTBatchTranslationFeedbackRequest",C,N
setContentAsFTBatchTranslationResponse:
T@"FTBatchTranslationResponse",C,N
setContentAsFTStartTextToSpeechStreamingRequest:
T@"FTStartTextToSpeechStreamingRequest",C,N
setContentAsFTBeginTextToSpeechStreamingResponse:
setContentAsFTPartialTextToSpeechStreamingResponse:
setContentAsFTFinalTextToSpeechStreamingResponse:
T@"FTBeginTextToSpeechStreamingResponse",C,N
T@"FTPartialTextToSpeechStreamingResponse",C,N
T@"FTFinalTextToSpeechStreamingResponse",C,N
setContentAsFTQssAckResponse:
T@"FTQssAckResponse",C,N
setContentAsFTStartLanguageDetectionRequest:
T@"FTStartLanguageDetectionRequest",C,N
setContentAsFTLanguageDetectionResponse:
T@"FTLanguageDetectionResponse",C,N
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithGRPCStreamingCallContext:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
performTranslation:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
performAStarFuzzyMatching:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
writeFrame:
finishWriting
sendPronGuessStreamingRequest:
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
@16@0:8
v24@0:8q16
v32@0:8q16@24
@24@0:8q16
v16@0:8
@"NSCalendar"
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v20@0:8B16
@"NSString"
{_NSRange="location"Q"length"Q}
v28@0:8@16B24
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSLocale"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
B24@0:8@16
q16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
v32@0:8@16@?24
v40@0:8@16@24@?32
v32@0:8@16@24
v40@0:8@16Q24@?32
v24@0:8@?16
v36@0:8@16B24@?28
v32@0:8q16@?24
v40@0:8q16@24@?32
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v24@0:8@"NSData"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSArray"16Q24@?<v@?@"_LTTextLanguageDetectionResult">32
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?q@"NSError">16
v24@0:8@"_LTInstallRequest"16
v32@0:8q16@?<v@?@"NSArray">24
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
@32@0:8@16@24
@"NSXPCConnection"
@"_LTTranslationServer"
@"NSUUID"
@"<_LTClientConnectionDelegate>"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
v32@0:8@"NSArray"16@"NSError"24
v28@0:8B16@20
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@"<_LTSpeechTranslationDelegate>"
@"<_LTTranslationEngine>"
@"_LTSpeechTranslationResultsBuffer"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"NSMutableArray"
@40@0:8q16@24@32
@40@0:8@16{_NSRange=QQ}24
@"NSDictionary"
v40@0:8@16@24^@32
@"NSURL"
d16@0:8
v24@0:8d16
@"NSArray"
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTTranslationContext"
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"NSNumber"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
@40@0:8@16@24@32
@"MAAsset"
@28@0:8@16B24
@36@0:8@16B24@?28
@36@0:8@16B24@28
@?16@0:8
@"<_LTTranslationService>"
@40@0:8@16B24@28B36
v36@0:8@16@24B32
v24@0:8Q16
v36@0:8@"NSString"16@"NSDictionary"24B32
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@"_LTLanguageDetectorFeatureCombinationModel"
@56@0:8@16@24@32@40@48
@60@0:8@16@24@32@40@48B56
@"MLModel"
@"MAProgressNotification"
@"_LTOfflineAssetManager"
@"_LTLocalePair"
@24@0:8^{_NSZone=}16
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v24@0:8@"FTBatchTranslationStreamingResponse"16
@"FTBlazarService"
v44@0:8@16B24@?28@?36
v48@0:8@16B24B28@?32@?40
v28@0:8B16@?20
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
@24@0:8^@16
@"_LTHotfixManager"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v44@0:8@16B24@28@36
v36@0:8@16B24@28
v40@0:8@16{_NSRange=QQ}24
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v24@0:8@"VSSpeechSynthesizer"16
v44@0:8@"VSSpeechSynthesizer"16B24@"NSString"28@"NSError"36
v36@0:8@"VSSpeechSynthesizer"16B24@"NSError"28
v44@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSError"36
v40@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@?40@?48
v44@0:8@16@24B32@?36
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
@"NSError"
@"_LTTextToSpeechCache"
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
@"FTMutableBatchTranslationRequest"
@"LTBatchEventLog"
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"NSDate"
@"AFSettingsConnection"
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@48@0:8@16@24@32@40
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
v40@0:8@16@24q32
@"NSOrderedSet"
@32@0:8Q16q24
B24@0:8Q16
@"_LTPlaybackService"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"_LTSpeechDataQueue"
@"_LTSpeechActivityDetector"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@"SNAudioStreamAnalyzer"
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@"_LTSpeechDataQueueNode"
@24@0:8d16
@36@0:8@16q24B32
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
@32@0:8@16q24
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARSpeechRecognitionResultPackage"
@56@0:8@16@24d32d40d48
v36@0:8B16@20@?28
@"_LTTranslationResult"
@64@0:8@16q24@32@40@48@56
@"NSCountedSet"
@24@0:8Q16
@"NLLanguageRecognizer"
@60@0:8@16@24d32B40@44@52
@"_LTTranslationStatistics"
@20@0:8B16
I16@0:8
v20@0:8I16
@36@0:8@16@24B32
@"_LTTranslationSession"
@"_LTTextToSpeechTranslationRequest"
@"NSAttributedString"
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"_LTActivityLogging"
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
@"_LTRateLimiter"
@52@0:8@16{_NSRange=QQ}24B40@44
q28@0:8@16B24
@32@0:8@16d24
v40@0:8@16@?24@?32
q24@0:8@16
v20@0:8i16
i16@0:8
{?="locale"b1"confidence"b1}
@"MTSchemaProvisionalMTAppLanguageIdentificationStarted"
@"MTSchemaProvisionalMTAppLanguageIdentificationEnded"
@"MTSchemaProvisionalMTAppLanguageIdentificationFailed"
@"MTSchemaProvisionalMTAppLanguageIdentificationCancelled"
@"MTSchemaProvisionalLanguageIdentificationLocaleConfidence"
@"MTSchemaProvisionalMTError"
{?="exists"b1}
@"SISchemaUUID"
@"MTSchemaProvisionalMTBatchRequestStarted"
@"MTSchemaProvisionalMTBatchRequestEnded"
@"MTSchemaProvisionalMTBatchRequestFailed"
@"MTSchemaProvisionalMTBatchRequestCancelled"
{?="numParagraphFailures"b1}
{?="numberOfParagraphs"b1}
@"MTSchemaProvisionalMTClientEventMetadata"
@"MTSchemaProvisionalMTBatchRequestContext"
@"MTSchemaProvisionalMTInvocationContext"
@"MTSchemaProvisionalMTSessionContext"
@"MTSchemaProvisionalMTAppTextPasted"
@"MTSchemaProvisionalMTAppLanguageIdentificationContext"
@"MTSchemaProvisionalMTAppLanguageIdentificationInteracted"
@"MTSchemaProvisionalMTAppDisambiguationInteracted"
@"MTSchemaProvisionalMTSpeechTranslationSignal"
@"MTSchemaProvisionalMTUserFacingSessionSignal"
{?="errorCode"b1}
@"MTSchemaProvisionalMTInvocationStarted"
@"MTSchemaProvisionalMTInvocationEnded"
@"MTSchemaProvisionalMTInvocationFailed"
@"MTSchemaProvisionalMTInvocationCancelled"
@"MTSchemaProvisionalMTLanguagePair"
{?="isOnDeviceTranslationEnabled"b1"task"b1"inputMode"b1"isExplicitLanguageFilterEnabled"b1"isLanguageIdentificationEnabled"b1"uiMode"b1}
{?="sourceLanguage"b1"targetLanguage"b1}
@"MTSchemaProvisionalMTSessionStarted"
@"MTSchemaProvisionalMTSessionEnded"
@"MTSchemaProvisionalMTSessionFailed"
@"MTSchemaProvisionalMTSessionCancelled"
{?="speechRequestStatus"b1}
{?="userFacingSessionStatus"b1}
@"NSData"16@0:8
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^v16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^v16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^v16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^v16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^v16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^v16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^v16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^v16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^v16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^v16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^v16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^v16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^v16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^v16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^v16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^v16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
f16@0:8
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^v16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^v16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^v16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^v16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^v16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^v16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^v16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^v16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^v16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^v16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^v16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^v16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^v16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^v16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^v16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^v16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^v16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^v16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^v16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^v16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^v16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^v16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^v16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^v16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^v16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^v16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^v16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^v16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^v16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^v16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^v16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^v16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^v16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^v16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^v16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^v16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^v16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^v16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^v16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^v16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^v16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^v16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^v16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^v16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^v16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^v16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^v16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^v16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^v16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^v16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^v16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^v16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^v16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^v16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^v16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^v16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^v16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^v16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^v16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^v16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^v16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^v16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^v16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^v16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^v16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^v16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^v16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^v16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^v16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^v16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^v16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingConfig>=I}24@0:8^v16
r^{AStarFuzzyMatchingConfig=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResult>=I}24@0:8^v16
r^{AStarFuzzyMatchingResult=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingRequest>=I}24@0:8^v16
r^{AStarFuzzyMatchingRequest=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResponse>=I}24@0:8^v16
r^{AStarFuzzyMatchingResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^v16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^v16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^v16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^v16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^v16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^v16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^v16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^v16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^v16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^v16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^v16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^v16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^v16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^v16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^v16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^v16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^v16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^v16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^v16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^v16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^v16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^v16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^v16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^v16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^v16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^v16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^v16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^v16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^v16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^v16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^v16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^v16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^v16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^v16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24
@36@0:8@16r^{BatchTranslationFeedbackRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationFeedbackRequest>=I}24@0:8^v16
r^{BatchTranslationFeedbackRequest=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^v16
r^{BatchTranslationResponse=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^v16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^v16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^v16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^v16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^v16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^v16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^v16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^v16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^v16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^v16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^v16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^v16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^v16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^v16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^v16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^v16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^v16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^v16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^v16
r^{LanguageDetectionStreamingResponse=[1C]}
v20@0:8f16
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
