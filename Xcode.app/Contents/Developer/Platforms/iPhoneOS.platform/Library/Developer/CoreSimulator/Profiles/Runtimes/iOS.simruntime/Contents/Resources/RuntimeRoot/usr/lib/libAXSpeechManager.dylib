com.apple.speech.voice.Alex
com.apple.ttsbundle.gryphon_male
com.apple.ttsbundle.gryphon_female
(pause\=(\d{1,4})\\)
content is nil, language detection not possible
%s:%d %@
-[AXSpeechAction _detectLanguageFromContent]
v8@?0
com.apple.Accessibility
SpeechManager
Not enough characters (%lu) to accurately detect language
could not determine content language, returning default
<AXSpeechAction: %p> %@ :Pitch %f : Language: %@, voiceId: %@
processedString
T@"NSString",&,N,V_processedString
emojiRangeReplacements
T@"NSMutableArray",&,N,V_emojiRangeReplacements
shouldQueue
TB,N,V_shouldQueue
cannotInterrupt
TB,N,V_cannotInterrupt
shouldDetectLanguage
TB,N,V_shouldDetectLanguage
shouldProcessEmoji
TB,N,V_shouldProcessEmoji
shouldProcessEmoticons
TB,N,V_shouldProcessEmoticons
shouldPrecomposeString
TB,N,V_shouldPrecomposeString
ignoreCustomSubstitutions
TB,N,V_ignoreCustomSubstitutions
synthesizeSilently
TB,N,V_synthesizeSilently
language
T@"NSString",&,N,V_language
voiceIdentifier
T@"NSString",&,N,V_voiceIdentifier
state
Tq,N,V_state
audioBufferCallback
T@?,C,N,V_audioBufferCallback
string
T@"NSString",C,N,V_string
attributedString
T@"NSAttributedString",C,N,V_attributedString
completionCallback
T@?,C,N,V_completionCallback
onPauseCallback
T@?,C,N,V_onPauseCallback
onResumeCallback
T@?,C,N,V_onResumeCallback
onWillSpeakRangeCallback
T@?,C,N,V_onWillSpeakRangeCallback
onSpeechStartCallback
T@?,C,N,V_onSpeechStartCallback
speakingRate
Td,N,V_speakingRate
useMonarchStyleSpeechRate
TB,N,V_useMonarchStyleSpeechRate
pitch
Td,N,V_pitch
volume
Td,N,V_volume
wordCallbackPostProcessedOffset
Tq,N,V_wordCallbackPostProcessedOffset
finalSpokenString
T@"NSString",&,N,V_finalSpokenString
speech-manager-properties
audioSessionCategory
audioSessionCategoryOptions
Speech interrupted, pausing
-[AXSpeechManager _didBeginInterruption]
AVSpeechSynthesizer Audio interruption notification: %@
-[AXSpeechManager _handleAudioInterruption:]
AXSettings
Synthesizer created: %@
-[AXSpeechManager _initialize]
**** AX Error: Could not load AccessibilityUtilities.framework bundle. bundleWithPath came back nil
+[AXSpeechManager availableVoices:]_block_invoke
Could not load bundle: %@
com.apple.accessibility.AccessibilityUIServer
com.apple.springboard
reset_tts_voices_queue
Failure: %@
+[AXSpeechManager _resetAvailableVoices:]
Removing from queue: %@
-[AXSpeechManager _speechJobFinished:action:]
Remaining queue: %@
Start next job
Error setting audio session to inactive: %@
-[AXSpeechManager _speechJobFinished:action:]_block_invoke
v40@?0@8{_NSRange=QQ}16^B32
Existing speech job already in flight
-[AXSpeechManager _startNextSpeechJob]
Is in audio interruption, not starting speech
%@ Will speak: %@ %f
Stopping existing job
Error setting active: %@
Speech Error:%@
%@ Should queue: %@ -> %d
-[AXSpeechManager _dispatchSpeechAction:]
Telling synthesizer to stop because this job doesn't want to queue
isSpeaking: %d
Speech queue items: %@
Starting next job
-[AXSpeechManager clearSpeechQueue]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/AccessibilityFrameworks-2725/Source/AXSpeechManager/AXSpeechManager.m
![_runThread isFinished]
-[AXSpeechManager dispatchSpeechAction:]
-[AXSpeechManager pauseSpeaking:]
-[AXSpeechManager continueSpeaking]
-[AXSpeechManager isSpeaking]
%@ Speech finished: %d %@
-[AXSpeechManager speechSynthesizer:didFinishSpeakingRequest:successfully:withError:]
No action for request: %@
processedRange
notified
originalRange
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
originalSpeechRateForJobOverride
T@"NSNumber",&,N,V_originalSpeechRateForJobOverride
isPaused
TB,N,V_isPaused
audioDeactivatorTimer
T@"AXDispatchTimer",&,N,V_audioDeactivatorTimer
wasSpeakingBeforeAudioInterruption
TB,N,V_wasSpeakingBeforeAudioInterruption
didRequestStartSpeakingDuringAudioInterruption
TB,N,V_didRequestStartSpeakingDuringAudioInterruption
didRequestPauseSpeakingDuringAudioInterruption
TB,N,V_didRequestPauseSpeakingDuringAudioInterruption
didRequestResumeSpeakingDuringAudioInterruption
TB,N,V_didRequestResumeSpeakingDuringAudioInterruption
audioInterruptionStartedTime
Td,N,V_audioInterruptionStartedTime
audioSession
T@"AVAudioSession",&,N,V_audioSession
isInAudioInterruption
TB,N,V_isInAudioInterruption
requestedActionDuringAudioInterruption
T@"AXSpeechAction",&,N,V_requestedActionDuringAudioInterruption
shouldHandleAudioInterruptions
TB,N,V_shouldHandleAudioInterruptions
speechEnabled
TB,N,V_speechEnabled
showControlCenterControls
TB,R,N,V_showControlCenterControls
isSpeaking
TB,R,D,N
audioQueueFlags
TI,N,V_audioQueueFlags
setActiveOptions
TQ,N,V_setActiveOptions
T@"NSString",&,N,V_audioSessionCategory
TQ,N,V_audioSessionCategoryOptions
outputChannels
T@"NSArray",&,N
requestWillStart
T@?,C,N,V_requestWillStart
supportsAccurateWordCallbacks
TB,N,V_supportsAccurateWordCallbacks
VOTEmoticons
plist
VOTLocalizedStrings
v32@?0@8@16^B24
\pause=350\ 
Unable to create AVSpeechSynthesisVoice from TTSVoice: %@
AVSpeechSynthesisVoice *AXAVSpeechSynthesisVoiceFromTTSSpeechVoice(TTSSpeechVoice *__strong)
nb-no
no-NO
ru-RU
IPHONE_SIMULATOR_ROOT
/System/Library/CoreServices/VoiceOverTouch.app
NSBundle *VOTBundle()
<Unknown Function>
/BuildRoot/Library/Caches/com.apple.xbs/Sources/AccessibilityFrameworks_Sim/AccessibilityFrameworks-2725/Source/AXSpeechManager/AXEmojiUtilities.m
<Unknown File>
Unable to create VOT bundle from path: %@
v40@?0^{__EmojiTokenWrapper=}8{?=qq}16^B32
internal-emoji-locale-cache
 %@ 
emoji.suffix
AXSpeech
%@ Don't call -cancel to stop an AXSpeechThread, call -stop instead.
%{public}s
AXSpeechAction
AXSpeechManager
TTSSpeechSynthesizerDelegate
NSObject
AXEmojiUtilities
AXSpeechThread
init
setString:
setShouldQueue:
setAttributedString:
string
precomposedStringWithCanonicalMapping
language
_detectLanguageFromContent
setLanguage:
setProcessedString:
isEqualToString:
regularExpressionWithPattern:options:error:
processedString
length
stringByReplacingMatchesInString:options:range:withTemplate:
stringWithFormat:
UTF8String
rangeOfString:
actionWithString:shouldQueue:
actionWithAttributedString:shouldQueue:
test_setUseMaxSpeechRate:
preprocessAction
description
.cxx_destruct
shouldQueue
cannotInterrupt
setCannotInterrupt:
shouldDetectLanguage
setShouldDetectLanguage:
shouldProcessEmoji
setShouldProcessEmoji:
shouldProcessEmoticons
setShouldProcessEmoticons:
shouldPrecomposeString
setShouldPrecomposeString:
ignoreCustomSubstitutions
setIgnoreCustomSubstitutions:
synthesizeSilently
setSynthesizeSilently:
voiceIdentifier
setVoiceIdentifier:
state
setState:
audioBufferCallback
setAudioBufferCallback:
attributedString
completionCallback
setCompletionCallback:
onPauseCallback
setOnPauseCallback:
onResumeCallback
setOnResumeCallback:
onWillSpeakRangeCallback
setOnWillSpeakRangeCallback:
onSpeechStartCallback
setOnSpeechStartCallback:
speakingRate
setSpeakingRate:
useMonarchStyleSpeechRate
setUseMonarchStyleSpeechRate:
pitch
setPitch:
volume
setVolume:
wordCallbackPostProcessedOffset
setWordCallbackPostProcessedOffset:
finalSpokenString
setFinalSpokenString:
emojiRangeReplacements
setEmojiRangeReplacements:
_string
_pitch
_volume
_speakingRate
_language
_shouldQueue
_cannotInterrupt
_shouldDetectLanguage
_shouldProcessEmoji
_shouldProcessEmoticons
_shouldPrecomposeString
_completionCallback
_onPauseCallback
_onResumeCallback
_onWillSpeakRangeCallback
_onSpeechStartCallback
_ignoreCustomSubstitutions
_synthesizeSilently
_useMonarchStyleSpeechRate
_voiceIdentifier
_state
_audioBufferCallback
_attributedString
_wordCallbackPostProcessedOffset
_finalSpokenString
_processedString
_emojiRangeReplacements
setShouldHandleAudioInterruptions:
auxiliarySession
setAudioSession:
initWithTargetSerialQueue:
setAutomaticallyCancelPendingBlockUponSchedulingNewBlock:
setAudioSessionCategoryOptions:
setAudioSessionCategory:
addObserver:forKeyPath:options:context:
defaultCenter
_handleAudioInterruption:
audioSession
addObserver:selector:name:object:
_handleMediaServicesWereLost:
_handleMediaServicesWereReset:
start
_initialize
performSelector:onThread:withObject:waitUntilDone:
removeObserver:forKeyPath:context:
removeObserver:
dealloc
_tearDown
removeObserver:name:object:
stop
shouldHandleAudioInterruptions
_didBeginInterruption
_updateAudioSessionProperties
_didEndInterruption
setAudioInterruptionStartedTime:
setWasSpeakingBeforeAudioInterruption:
setDidRequestStartSpeakingDuringAudioInterruption:
setDidRequestPauseSpeakingDuringAudioInterruption:
setDidRequestResumeSpeakingDuringAudioInterruption:
setRequestedActionDuringAudioInterruption:
setIsInAudioInterruption:
didRequestStartSpeakingDuringAudioInterruption
requestedActionDuringAudioInterruption
dispatchSpeechAction:
wasSpeakingBeforeAudioInterruption
didRequestPauseSpeakingDuringAudioInterruption
didRequestResumeSpeakingDuringAudioInterruption
continueSpeaking
_resetInterruptionTracking
isSpeaking
pauseSpeaking:
userInfo
objectForKey:
integerValue
audioSessionCategory
audioSessionCategoryOptions
setCategory:withOptions:error:
observeValueForKeyPath:ofObject:change:context:
opaqueSessionID
useSpecificAudioSession:
setDelegate:
mainBundle
bundleIdentifier
setBundleIdentifier:
sharedInstance
_updateUserSubstitutions
customPronunciationSubstitutions
registerUpdateBlock:forRetrieveSelector:withListener:
setUserSubstitutions:
speechMarkupStringForType:forIdentifier:string:
availableLanguageCodes
availableVoices:
bundleWithPath:
isLoaded
loadAndReturnError:
currentVoices
_resetAvailableVoices:
allAvailableVoices
processInfo
processName
refreshAllAvailableVoices:
count
initWithCapacity:
countByEnumeratingWithState:objects:count:
addObject:
copy
setCurrentVoices:
getCharacters:range:
getCharacters:
array
valueWithRange:
audioFileSettingsForVoice:
setIsPaused:
firstObject
removeObjectIdenticalTo:
_startNextSpeechJob
audioDeactivatorTimer
setActiveOptions
setActive:withOptions:error:
afterDelay:processBlock:
_speechVoiceForIdentifier:language:footprint:useFallbackDefault:
identifier
substringWithRange:
setOriginalString:
setPhonemes:
setReplacementRange:
enumerateAttribute:inRange:options:usingBlock:
objectAtIndex:
isInAudioInterruption
audioInterruptionStartedTime
currentThread
name
stopSpeakingAtNextBoundary:synchronously:error:
setRate:
setUseMonarchStyleRate:
audioQueueFlags
setAudioQueueFlags:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
_phonemeSubstitutionsForAction:
setPhonemeSubstitutions:
setSpeakingRequestClientContext:
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
requestWillStart
cancel
startSpeakingString:withLanguageCode:request:error:
localizedDescription
clearSpeechQueue
removeAllObjects
isFinished
_clearSpeechQueue
speechEnabled
_dispatchSpeechAction:
intValue
pauseSpeakingAtNextBoundary:error:
_pauseSpeaking:
numberWithUnsignedInt:
continueSpeakingWithError:
_continueSpeaking
_stopSpeaking:
stopSpeaking:
_isSpeaking:
boolValue
outputChannels
convertChannels:
setOutputChannels:
channelWithChannel:
clientContext
objectAtIndexedSubscript:
_speechJobFinished:action:
__speechJobFinished:
text
numberWithInt:
arrayWithObjects:count:
rangeValue
indexOfObject:
mutableCopy
numberWithBool:
setObject:forKeyedSubscript:
replaceObjectAtIndex:withObject:
currentLanguageCode
spellOutMarkupString:string:
pauseMarkupString:
availableVoices
_resetAvailableVoices
createRegularExpressionFromString:
matchedRangesForString:withRegularExpression:
remapLanguageCode:
test_actionStartTap:
test_setUnitTestMode:
test_setAvailableVoices:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didSynthesizeSilentlyToURL:forRequest:
tearDown
setSetActiveOptions:
isPaused
externalVoiceIdentifierUsedForLanguage:
voiceIdentifierUsedForLanguage:
setSpeechEnabled:
stopSpeaking
showControlCenterControls
setRequestWillStart:
originalSpeechRateForJobOverride
setOriginalSpeechRateForJobOverride:
setAudioDeactivatorTimer:
_speechQueue
_synthesizer
_runThread
_propertyQueue
_isSpeaking
_speechEnabled
_isPaused
_isInAudioInterruption
_supportsAccurateWordCallbacks
_showControlCenterControls
_wasSpeakingBeforeAudioInterruption
_didRequestStartSpeakingDuringAudioInterruption
_didRequestPauseSpeakingDuringAudioInterruption
_didRequestResumeSpeakingDuringAudioInterruption
_shouldHandleAudioInterruptions
_audioQueueFlags
_requestedActionDuringAudioInterruption
_audioSessionCategoryOptions
_audioSessionCategory
_setActiveOptions
_audioSession
_requestWillStart
_originalSpeechRateForJobOverride
_audioDeactivatorTimer
_audioInterruptionStartedTime
pathForResource:ofType:
dictionaryWithContentsOfFile:
whitespaceAndNewlineCharacterSet
rangeOfString:options:range:
characterAtIndex:
characterIsMember:
substringToIndex:
replaceCharactersInRange:withString:
dictionaryWithObjects:forKeys:count:
enumerateKeysAndObjectsUsingBlock:
stringByReplacingEmojiCharactersWithEmojiDescriptions:stringForPauses:language:rangeReplacements:appendEmojiSuffix:
lowercaseString
setIdentifier:
setName:
footprint
setQuality:
setIsInstalled:
canBeDownloaded
setCanBeDownloaded:
setAssetSize:
isCombinedFootprint
setIsCombinedVoice:
isDefault
setIsDefault:
isFallbackDefault
setIsFallbackDefault:
nonCombinedVoiceId
setNonCombinedVoiceId:
gender
setGender:
hasPrefix:
stringWithUTF8String:
stringByAppendingString:
currentHandler
handleFailureInFunction:file:lineNumber:description:
currentLocale
languageCode
_initializeEmojiStructures:
emojiRangeFromString:withSearchRange:
stringByRemovingEmojiCharacters:
currentRunLoop
port
addPort:forMode:
isCancelled
distantFuture
runMode:beforeDate:
getCFRunLoop
main
_machPort
_threadRunLoop
@28@0:8@16B24
v20@0:8B16
@16@0:8
v16@0:8
B16@0:8
v24@0:8@16
q16@0:8
v24@0:8q16
@?16@0:8
v24@0:8@?16
d16@0:8
v24@0:8d16
@"NSString"
@"NSAttributedString"
@"NSMutableArray"
@32@0:8@16@24
@24@0:8@16
@20@0:8B16
^{URegularExpression=}24@0:8@16
@32@0:8@16^{URegularExpression=}24
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v44@0:8@16@24B32@36
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v40@0:8@16@24@32
v32@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24
v44@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSError"36
v52@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v48@0:8@"TTSSpeechSynthesizer"16{_NSRange=QQ}24@"TTSSpeechRequest"40
v40@0:8@"TTSSpeechSynthesizer"16@"NSURL"24@"TTSSpeechRequest"32
v48@0:8@16@24@32^v40
v24@0:8Q16
v28@0:8B16@20
v20@0:8i16
I16@0:8
v20@0:8I16
@"TTSSpeechSynthesizer"
@"AXSpeechThread"
@"NSObject<OS_dispatch_queue>"
@"AXSpeechAction"
@"AVAudioSession"
@"NSNumber"
@"AXDispatchTimer"
{_NSRange=QQ}40@0:8@16{_NSRange=QQ}24
@52@0:8@16@24@32@40B48
@"NSPort"
@"NSRunLoop"
