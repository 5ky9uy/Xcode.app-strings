@(#)PROGRAM:Portrait  PROJECT:Portrait-1
25;>
<sSb<^R
<sSb<nb
T09$
>333?
sctd
L?33
33s?
 A33
>333@
<Sk?
?fff?
?fff?
?U0*
?U0*
rdhvdnerbatsgtnc
hx_in
cx_in
mask
hx_out
cx_out
pred
version
_step_i
_network_detections
_last_focus_detection
models/%@
model.espresso
model.parameters
json
_x_in
_hx_in
_cx_in
_mask_in
_hx_out
_cx_out
_pred_out
-[PTCinematographyNetwork _getLeastRecentNetworkDetectionIndex]
PTCinematographyNetwork.m
self.networkDetections.count >= 2
-[PTCinematographyNetwork _setMissingDetectionAtIndex:time:]
i < _x_in.height
i < self.networkDetections.count
-[PTCinematographyNetwork _setNetworkDetection:atIndex:time:]
i <= self.networkDetections.count
_DebugLogEspressoBufferRow
index < bp->height
_DebugLogEspressoBufferColumn
index < bp->width
('%@')
atom%@: { offset: %lu, size: %lu }, data: { offset: %lu, size: %lu }%@
 (%@)
attempt to read past end %lu (offset %lu; size %lu)
PTEffectIrrUpdateCoefficientDisparity
PTEffectIrrUpdateCoefficientNormal
PTEffectSDOFixedFocusDepth
PTEffectSDOFMaxFocusDepth
PTEffectSDOFFocusOffsetDepth
PTEffectFocusDisparityExponentialMovingAverage
PTEffectLKTQuality
commandBuffer
v32@?0@"<MTLComputeCommandEncoder>"8@"PTRenderRequest"16@"<MTLTexture>"24
DetectedObjectsInfo
HumanFaces
ObjectsArray
Rect
Width
Height
PTEffectDebug
status
-[PTEffectRendererStudioLight render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:]
PTEffectRendererStudioLight.m
status == noErr && "Error executing render pipeline"
PixelFormatDescription
EquivalentUncompressedPixelFormat
+[PTPixelBufferUtil pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:]
PTPixelBufferUtil.m
MTLPixelFormatInvalid != lumaAndChromaFormats[0]
MTLPixelFormatInvalid != lumaAndChromaFormats[1]
dstTexLumaDesc
dstTexChromaDesc
user_created
track_type
track_id
group_id
detection_type
detections
-[PTEffectRendererSDOF initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:prevTemporalState:sharedResources:]
PTEffectRendererSDOF.m
effectType == PTEffectTypeSDOF
-[PTEffectRendererSDOF render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:]
estimateNormalsFromDisparity
com.apple.Portrait.AssetReader
Did not receive videoBuffer from async request
v32@?0@8@16^B24
Couldn't find video track in asset: %@
Couldn't find metadata track in asset: %@
Couldn't find disparity track in asset: %@
Cannot add videoCompositionOutput to assetReader
com.apple.quicktime.mdta
WARNING: Metadata items did not all have the same timestamp!
WARNING: Metadata sample with invalid time added!
mdta/
_alpha
_maxv
_resistance
v8@?0
version %lu is too big to fit
data size %lu is too big to fit
excludeAsCinematicChoice
isFixedPlaneFocus
isHardFocus
isFixedFocus
CinematographyParameters
detectionModel
focusBlurMapMode
_network_state
_frame_index
_previous_frame_serialized
FTCinematicTrackingResult
FocusRegion
FocusBlurMap
SensorRawValidBufferRect
RawSensorWidth
RawSensorHeight
MLSignals
anod_pose
AngleInfoRoll
AngleInfoPitch
AngleInfoYaw
GroupID
__BaseFocusTrackNumberOverride
FTTrackingResult
CinematographySnapshotEveryFrame
frame
stream detection
Raw Cinematography
CinematographyFocus
network
fixed
closest
largest
FocusMode
CinematographyDebugLogMLSignals
CinematographyDisparityWeighting
reading disparity buffer
 from %@
 (strong)
detection
FTCinematicTrackingResult (%ld) [DDR:%d]: %@
G%ld
(excluded)
T%ld%@(%zd)%@: (%g,%g,%g,%g)
attempt to write bytes at offset %lu size %lu to data of length %lu
flatten
com.apple.portrait
core
kColorSize
kRaycount
kRadiusLocal
kRadiusLocalFraction
kRayMarch
kDiameterCoverageLimit
kFocusBlendCoefficients
kCoverageOverscan
kRayMarchDisparityRadiusTolorance
kSkipFullSizeLayer
raytracingV2002
DDiff
RGBWeightUpscaled
RaytracingDependencies
computeEncoder
v16@?0@"<MTLCommandBuffer>"8
PortTypeBack
PortTypeFrontInfrared
PortTypeFront
PortTypeBackTelephoto
kIIRUpdateCoefficients
kMotionThresholdMinMax
kDirection
kMotionCorrectionFunction
temporalFilterDEMA_LKT
temporalFilterDEMA_LKT_VisualizeMotion
resampleDisparity
-[PTCinematographyFocusFrames startIndexForLinearRackFocusPullToFrameAtIndex:]
PTCinematographyFocusFrames.m
startIndex >= 0
-[PTCinematographyFocusFrames _framesIndex:earlierBy:]
index < _frames.count
com.apple.quicktime.cinematography-dictionary
com.apple.quicktime.camera-dictionary
com.apple.quicktime.cinematic-video
com.apple.quicktime.cinematic-video.cinematography
com.apple.quicktime.cinematic-video.rendering
com.apple.quicktime.cinematic-video.stabilization
_version
focus_puller
user_aperture
ptime
aperture
alphaLowLight
disparity
focus_blend
trackers
user_track_id
base_track_id
user_focus_strong
user_focus_group
detector_did_run
focus_track_id
transition_coefficient
transition_elapsed_time
transition_duration
attributes
focus_id
rect
label
detected_object_id
user_track
coefficients
detected_rect
Invalid parameter
Odd image dimensions are not supported
Unknown preset
LKT::KeypointsFromFlow
The number of scales specified is too large
+[LKTFlowGPU _computeScalingFactor:dst_tex:scale_xy_inv:coeff:]
LKTFlowGPU.m
(dst_tex.width == src_tex.width) && (dst_tex.height == src_tex.height)
Unidentified Metal format
lkt_bgra2yuva
lkt_zero_flow
lkt_downscale_2x
lkt_features
lkt_features_derivatives
lkt_solver_prepare_matrices
lkt_solver_box_y
lkt_solver_box_x_and_Axb
lkt_flow_consistency
lkt_keypoints_from_flow
lkt_nlreg_hegbf
lkt_copy
params
timer_seconds_divisor
Unknown
kWeights2DRow0
kWeights2DRow1
temporalFilterExponentialMovingAverageLKTMotion
temporalFilterExponentialMovingAverageLKTMotionNormal
copyDisparityWithBias
PortraitDump
PTDisparityFilterLKTQuality
PTImageBufferTransferFunction_Linear_1_6
width_height
geomean
warpTexture
v24@?0Q8^B16
flow
focusPos
regions
enabled
sizeX
sizeY
startX
startY
tileSizeX
tileSizeY
tileCountX
tileCountY
tiles
defocus
conf
flags
valid
flat
level
guidedFilterAverageUpsamplingCoefficients
_averageUpsamplingCoefficients
guidedFilterApplyUpsamplingCoefficients
_applyUpsamplingCoefficients
guidedFilterComputeUpsamplingCoefficients
_computeUpsamplingCoefficients
computeWeightedUpsamplingCoefficients
_computeWeightedUpsamplingCoefficients
GuidedFilter
temporalFilterExponentialMovingAverageColorSimilarities
+N9mZUAHooNvMiQnjeTJ8g
com.apple.portrait.effect_init
-[PTEffect initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:prewarmOnly:effectQuality:]
PTEffect.m
(activeEffectType == PTEffectTypeNone ) || (activeEffectType == PTEffectTypeSDOF) || (activeEffectType == PTEffectTypeStudioLight) || (activeEffectType == (PTEffectTypeSDOF | PTEffectTypeStudioLight) )
PortTypeBackSuperWide
Invalid size of inRGBA
Invalid size of outDisplacement
Invalid size of inDisparity
Invalid size of inDisplacement
Invalid size of inDisparityPrev
Invalid size of outDisparity
Invalid size of outDisparityFiltered
zero_label
remap
DictionaryFromRemapParam
PTCinematographyNetworkLabelSignal.m
[element isKindOfClass:[NSNumber class]]
descr
_guidedFilter
guidedupscale
Raymarch all
Raymarch adaptive
1-step
%@. Circles: %i. upscale-disp:%f %@
FirstLevelGaussianDownsample
PTEffectShowFaceRects
-[PTTensorSwapPair initWithIOSurfaces:names:]
PTEspressoGenericExecutor.m
status == noErr
unInterleaveTexture
monocular-depth-sync
-[PTEspressoGenericExecutor initWithUrl:inputNames:outputNames:tensorSwapNames:device:library:pipelineLibrary:commandQueue:reshape:configuration:]
_ctx
eStatus == ESPRESSO_STATUS_SUCCESS
-[PTEspressoGenericExecutor bindBuffers:toMap:withMode:]
v16@?0^{?=ii*}8
com.apple.portrait.serialization
PTSerializationVersionKey
-[PTMSRResize initWithDevice:commandQueue:inputSize:target:rotateTargetPixelBuffer:sharedResources:]
PTMSRResize.m
_allocatedIOSurfaces < MAX_DOWNSAMPLING_STEPS
lightEstimation
com.apple.portrait.srl_async_queue
-[FloatArray floatAtIndex:]
FloatArray.m
index < _count
-[FloatArray subtracting:]
_count == array->_count
-[MutableFloatArray floatAtIndex:]
-[MutableFloatArray setFloat:atIndex:]
-[MutableFloatArray setFloat:inRange:]
NSMaxRange(range) <= _count
-[MutableFloatArray setFloats:inRange:]
-[MutableFloatArray appendFloat:]
!"out of memory allocating FloatArray buffer"
parallelReductionTextureSimd
error == nil
parallelReductionTextureMinMaxSimd
GlobalReductionSimd
parallelReductionAverage
parallelReductionMax
parallelReductionMin
GlobalReduction
MaskThreshold
MinFaceSize
MaxCurveBoost
MinCurveBoost
MaxTargetRatioDarkening
MaxTargetRatioLimit
BiasFactorSRLv2
ToneSimilaritySigma
FaceExpDifThreshold
TargetMedian_I
TargetMedian_II
TargetMedian_III
TargetMedian_IV
TargetMedian_V
TargetMedian_VI
MaxBoost_I
MaxBoost_II
MaxBoost_III
MaxBoost_IV
MaxBoost_V
MaxBoost_VI
srlV2GlobalSparseHistogramLivePhotos
srlV2FaceSparseHistogramLivePhotos
srlV2CalcCoefficientsLivePhotos
BackWide-IQTuning
plist
DeepFusionParameters
ToneMapping
DefaultParameters
SRLv2
UNKNOWN_17_unknown0
%@ (DDR:%@, pts:%@)
renderRequest.sourceColor.width == (int)_desc.colorInputSize.width && renderRequest.sourceColor.height == (int)_desc.colorInputSize.height
renderRequest.destinationColor.width == (int)_desc.colorOutputSize.width && renderRequest.destinationColor.height == (int)_desc.colorOutputSize.height
[renderRequest.sourceColor.transferFunction isEqual:renderRequest.destinationColor.transferFunction] || (renderRequest.sourceColor.transferFunction == nil && renderRequest.destinationColor.transferFunction == nil)
%02X 
%c%c%c%c
kRaytracingRaycount
kDisableForegroundBlur
raytracingV14
RGBRadiusUpscaled
%@, Rays: %i
Refined Cinematography
linear rack focus
CaptureMTLDevice
-[PTMTLDropHints setDropHintsFor:]
PTMTLDropHints.m
_count == 0
-[PTMTLDropHints dropHintsFor:]
_count == 1
centerDisparityOnFocus
_centerDisparityOnFocus
sobelEdgeDetector
_sobelEdgeDetector
edgeDilation
_edgeDilation
focusEdgeMask
_focusEdgeMask
kColorTransferFunctionToLinear
interpolateRGBRadiusToDestYUV
_interpolateRGBRadiusToDestYUV[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestYUVFromSource
_interpolateRGBRadiusToDestYUVFromSource[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestRGB
_interpolateRGBRadiusToDestRGBA[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestRGBFromSource
_interpolateRGBRadiusToDestRGBAFromSource[colorTransferFunctionToLinear]
convertRGBPyramid
_convertRGBPyramid[colorTransferFunctionToLinear]
convertRGBPyramidFromYUV
_convertRGBPyramidFromYUV[colorTransferFunctionToLinear]
updateFocusObject
effectSampleFaceRects
convertToDisparity
fixedFocusDistanceAndCenterDisparity
copySingleChannel
copyRGBAToBGRA
clear
_effectSampleFaceRects
__rect
__uncertainty
__label_onehot
name
count
PTCinematographyDetectionTypeHuman
person
PTCinematographyDetectionTypePet
PTCinematographyDetectionTypeSportsBall
sports ball
PTCinematographyDetectionTypeDefault
object
com.apple.coremedia
_snapshot
_snapshot_policy
_raw_disparity
-[PTCinematographyFrame focusTrackIdentifier]
PTCinematographyFrame.m
self.focusDetection.trackIdentifier == result
Frame: %@ [%@] (%@, %@)
; userFocusTrackNumber: %@ %@%@
raytracingV2001
centerDisparityOnFocusV2
sobelEdgeDetectorV2
edgeDilationV2
focusEdgeMaskV2
expected_fps
forget_after_seconds
sync_with_detector
supported_detection_types
input_schemas
_timeForObject: error: object %@ is neither a time value nor an object that responds to %@
q24@?0@8@16
temporalFilterExponentialMovingAverageLKT
kDisparityFilterStepWidth
kDisparityFilterType
studioLight
createLightMask
relightFullsizeInput
studioLightDebug
lightMaskForDebug
fgBgForDebug
lightMaskOutline
filterLightGainApplyToRGB
_filterLightGainApplyToRGB
PTEffectRelighting
user_decisions
user_tracks
track_allocator
com.apple.Portrait.CinematographyScript
com.apple.Portrait.CinematographyScript.serialQueue
Failed to read AVAsset: %@
Value for %@ key is of unexpected type: %@ for frame index %lu
CinematographyDictionary
No %@ key in metadata for frame index %lu
Failed to parse cinematography metadata for frame %lu. Dictionary: %@
v20@?0B8@"NSError"12
 within %@
%@%@%@-%lu
%@: %@: %@ focus: %g
%@, rect: %@, focusDistance: %@, trackID: %@
texDesc
LeftEyeRect
RightEyeRect
FaceID
ConfidenceLevel
stabilizationHomography is optional metadata and hasn't been found.
estimatedMotionBlur is optional metadata and hasn't been found.
primary
secondary
coefficient
FocusBlend(%@: %@; %@: %@)
attempt to read bytes at offset %lu size %lu from data of length %lu
options
is_user
min_duration
max_duration
Base
User
%@: [%@] T%@ G%@ %@%@
convertRGB
_convertRGB[i]
convertRGBToYUV
_convertRGBToYUV[i]
convertYUVToRGB
_convertYUVToRGB[i]
Cannot load bundle from %@
assignAndWatchKernel
renderDisparity
_renderDisparity
copy
_kernelCopy
multiplyTex
_multiplyTex
addConstant
_addConstant
fillWithColor
_fillWithColor
reciprocal
_reciprocal
sobelFilter
gaussianNoise
_gaussianNoise
renderRect
_renderRect
visualizeCircleUsingRect
_visualizeCircleUsingRect
drawTurboLegend
_drawTurboLegend
drawTurboLegendYUV
_drawTurboLegendYUV
gaussianFilter3x3
_gaussianFilter3x3
dd-MM-yyyy_HHmmss
originalVideoDimensions is optional metadata and hasn't been found.
%ld.%d
%ld.%d.%d
descriptor != nil
i-disp: %lux%lu u-disp: %lux%lu colorInput: %lux%lu colorOutput: %lux%lu
downscaleGaussian3x3
updateLevel0Box2x2FromRGBA
updateLevel0Box2x2FromYUV
updateLevel0Gaussian3x3FromRGBA
updateLevel0Gaussian3x3FromYUV
updateLevel0and1Gaussian3x3FromRGBA
updateLevel0and1Gaussian3x3FromYUV
PTPyramidRGB
com.apple.Portrait.RenderingMetadata
interpolateRGBWeightSourceYUVDestRGBA
_interpolateRGBWeightSourceYUVDestRGBA[colorTransferFunctionToLinear]
interpolateRGBWeightSourceYUVDestYUV
_interpolateRGBWeightSourceYUVDestYUV[colorTransferFunctionToLinear]
interpolateRGBWeightSourceRGBADestRGBA
_interpolateRGBWeightSourceRGBADestRGBA[colorTransferFunctionToLinear]
studioLightInterpolateRGBWeightSourceYUVDestYUV
_studioLightInterpolateRGBWeightSourceYUVDestYUV[colorTransferFunctionToLinear]
unable to find espresso model for version in %@
cannot find espresso model for version %@
no model parameters json file for version %@
malformed model.parameters.json for version %@
network version %@
espresso error loading network %@
network repeating last decision
network repeating last decision, but there is none, so autofocus
network inputs:
network outputs:
ignoring network decision to focus on stale track: %@
network forgetting stale detection: %@
espresso error unable to create context for engine %d on default system device
espresso error unable to create plan for engine %d on default system device
espresso error %d loading network %@
espresso error %d building plan for %@
espresso error %d binding %@ to %s
espresso error binding network (_x_in.height == %zd)
raw prediction: %zd
error: network predicts disabled index %@
_setMissingDetection[%ld]
_setNetworkDetection[%ld]: %@
espresso array count %@ 
 buffer count %@
%zu: %@
r[%zd]: %@
Format description does not have kCMFormatDescriptionExtension_TransferFunction. Using value kCMFormatDescriptionTransferFunction_ITU_R_709_2
Format description does not have kCMFormatDescriptionExtension_YCbCrMatrix. Using value kCMFormatDescriptionYCbCrMatrix_ITU_R_601_4
defaults write com.apple.coremedia PTEffectIrrUpdateCoefficientDisparity %f
defaults write com.apple.coremedia PTEffectIrrUpdateCoefficientNormal %f
defaults write com.apple.coremedia PTEffectSDOFixedFocusDepth %f
defaults write com.apple.coremedia PTEffectSDOFMaxFocusDepth %f
defaults write com.apple.coremedia PTEffectSDOFFocusOffsetDepth %f
defaults write com.apple.coremedia PTEffectFocusDisparityExponentialMovingAverage %f
PTRenderEffectNetwork is nil
defaults write com.apple.coremedia PTEffectLKTQuality %i
PTMSRResize init failed
Assertion failed %s
PTEffectRendererSL init failed
Assertion failed %s %i
Unable to determine appropriate metal pixel format for CVPixelBuffer of pixel format type = %x %@
Issue with pixelformat %@ %i for pixelbuffer %p
Cannot allocate textures for pixel format %@ %i for pixelbuffer %p
Unknown pixel format %x %c%c%c%c
Not found %i
Not found %lu
attempt to get detections in time range for continuous track %@
PTEffectRendererSDOF init failed
WARNING: meta timeRange (%@) not equal to vide timeRange (%@)
WARNING: auxv timeRange (%@) not equal to vide timeRange (%@)
ERROR: couldn't calculate frame count
Failed to deserialize global rendering metadata: %@
Failed to deserialize global stabilization metadata: %@
Failed to deserialize global cinematography metadata: %@
Failed to deserialize global video header metadata: %@
ERROR: Failed to find global metadata.
ERROR: Failed to decode metadata dictionary for %@. Value is not NSData.
ERROR: Failed to decode metadata dictionary for %@. Decoder failed: %@
Failed to deserialize timed rendering metadata: %@
Failed to deserialize timed stabilization metadata: %@
Failed to deserialize cinematography metadata: %@
Failed to get composed frame %lu from custom compositor
Failed to decode auxv buffer for frame %lu. Format was not 'kCVPixelFormatType_DisparityFloat16'
Failed to set parameter %d to non-numeric CMTime value %@
Failed to set parameter %d to CMTime value %@ using scale %d
Failed to get parameter %d of type %d. Unknown type.
Couldn't find parameter %d in parameter pair list.
focus puller: EMA (alpha: %g, sampleCount: %lu)
focus puller: EMA (sampleCount: %lu, alpha: %g)
focus puller: weighted dial (maxv: %g, resistance: %g)
w[+]: %@
w[%zd]: %@
stream options requested unsupported version %@
init with detection model %@
init with focus blur map mode %@
change from detection model %@ to %@
change from focus blur map mode %@ to %@
Frame: %@
end of cinematography stream
unexpected global metadata class %@
user focus: no longer detected
user focus: base focus changed after user focus lock expired
user focus: fixed focus depth changed after lock expired
error: user focus on unknown group %@
error: user focus on unknown track %@
unable to restore internal state of class %@
attempt to restore internal state to unsupported version %@
stream state missing network state
stream state has invalid network
Cinematography network version %@ (restored)
CinematographyAperture: %g
Cinematography network version %@
focus puller: %@
defaults: CinematographyFocus %@
user tap %@ ends due to depth change of %.1f%% (from disparity %.3f to %.3f)
fixed focus user tap at point %@ (rect %@; disparity %@)
user tap response missing request
user tap response/request unknown (ignored)
user tap %@ abandoned since detection %@ is marked as excluded as cinematic choice
error: FusionTracker information not provided in metadata
Synthetic DDR:%d
Setting DDR:1 for the first frame seen by cinematography
FusionTracker: %@
*** error: FT track %ld(%zd) with empty box (%g,%g,%g,%g) - skipping
auto focus mode: %@
auto focus rect: %@
no ISP detections; copying from prior frame (once)
error: FusionTracker: track with negative identifier (%@)
%@ named signals: %@
defaults: CinematographyDisparityWeighting: %@
raw focus %zd: %g
auto focus %zd: %g
cinematography focus change%@ to %@
user tap at (%g,%g) focus distance %g
user tap on track %@%@
unusual %@ disparity %@ (%@)
not enough room to write signal for network payload
Expected %ld values for named signal %@, got %ld values
unimplemented transition kind %ld
Commandbuffer Error %@
PTDisparityFilterDEMA_LKT init failed
Invalid filtered prev size
Bias is no longer supported
CinematographyMinPullTime: %@
CinematographyMaxPullTime: %@
CinematographyMaxDisparityPerSecond: %@
focus frames does not support global cinematography metadata version %d
LKTFlowGPU Init failed
newBufferWithLength failed
_G0_tex[%i] is nil
_G1_tex[%i] is nil
_C0_tex[%i] is nil
_C1_tex[%i] is nil
_w_tex[%i] is nil
_uv_fwd_tex[%i][%i] is nil
_uv_bwd_tex[%i][%i] is nil
Unsupported
Kernel uses bicubic sampler (Apple Silicon only)
Should be overwritted
lktflowgpuContext estimateFlowFromTexReference returned %i
Changing displacement textures is only valid when allocateDisplacementFWD is false
ignoring blur map with tile count %@ - too big
Not supported
effectType %i
updateEffectDelegate failed %i
Schedule set effect type: %i async: %i forceImmediatePassthrough: %i
Completed set effect type: %i
PTEffectRendererSDOF is nil
Unexpected effectType. Was %lu expected %lu
Should never happen
Releasing reference to %@
Failed to prewarm PTEffect SDOF (%d)
Failed to prewarm PTEffect SL (%d)
Error updateEffectDelegate
No detections found
Change quality from %lu to %lu
Disparity size must equal color size
Failed to prewarm PTDisparityPostProcessing (%d)
PTDisparityUpscale Cannot allocate texture
Error espresso plan add network: %s for %@
Error espresso set priority: %s for %@
network version: %s
unknown version of espresso model loaded
Error espresso_network_select_configuration: %s for %@
Espresso error building plan: %s for %@
Espresso cannot bind input buffer %s for %@
Expresso cannot bind output buffer %s for %@
espresso_network_bind_buffer %@ failed
Name %@ not found
espresso_network_bind_cvpixelbuffer: espresso error %s for %@
espresso_plan_execute_sync: espresso error %s for %@
espresso_plan_submit callback. %s %i %i for %@
espresso_plan_submit: espresso error %s for %@
AppleDepth not available
attempt to register class %@ for serialization that does not support PTSerialization protocol
registering atom type %@
error reading detection from container
CVPixelBufferCreate failed %i
IOSurface not found
IOSurface not found. Rotation
No MSR support
MSR only
Failed allocating PTSegmentationNetwork
PTGlobalReduction init failed
Cannot load plist
excluding %@ as best detection for group %@
Disable drop hints
Changing renderingVersion after initialization not supported
warning: snapshot missing from refined frame %@
Cinematography refinement <%p> start recording
Cinematography refinement <%p> stop recording
error: frames in smoother after recording stopped
Cinematography %@ from frame %ld (%@) to frame %ld (%@)
PTMTLDropHintsInFlight setEnabled: %i
FocusDistance will be clipped during rendering. Was %f
warning: no detection found from legacy coefficients dictionary %@
%@ Frame %@: focus %@ (%@), disparity %@, aperture %@%@ rect { %.3f, %.3f, %.3f, %.3f }
error: focusing on nothing
stack trace: %@
prepareForPerformingRequests failed %@
Private variant unsupported. Using default behavior. Error: %@
request nil
error %@ reading network parameters %@
expected a dictionary, got a %@ from network parameters %@
lightGainMapScale: %f
Must be equal size
WARNING: frameCount estimate was off. %lu frames expected, but only %lu were read
Effective decisions: %@
Track decisions: %@
unsupported globals version %@
internalizing user decision %@ end at %@
internalizing user focus end without prior user decision
internalizing user decision %@
userFocusTrackNumber %@ has no corresponding detection on frame %@. No user decision was added.
attempt to set user aperture to non-positive value ignored
finished updating frames for decisions in index range %@
track doesn't change across adjacent decisions (%@; %@)
did shorten transition from track %lu to track %lu
error: no frames in transition from %@ to %@ time range %@ to %@
error: cannot find current or prior detection for decision %@
error: endingDecision at %@ (%@) past end of frames at %@ (%@)
cannot find detections of track %@ at or before index %@%@
cannot find detections of group %@ at or before index %@%@
updating frames %lu to %lu to focus on track %lu
updating frames %lu thru %lu to rack focus from track %lu to track %lu
updating frames %lu thru %lu to fill in gap in track %lu
frame %lu: normalizedTime: %@
internalizing base decision %@
baseFocusTrackNumber %@ has no corresponding detection on frame %@. No base decision was added.
warning: unable to add detections from non-custom track %@
error: detection missing both trackIdentifier & focusIdentifier: %@
error: detection missing trackIdentifier: %@
focusOnTrackIdentifier:atTime: time %@ is not numeric
focusOnTrackIdentifier:atTime: No such %li trackIdentifier
focusOnGroupIdentifier:atTime: time %@ is not numeric
adding user decision %@
Adding group user decision with no corresponding detection: %@
removing all user decisions %@
removing all user decisions
removing user decision %@
attempt to remove non-user decision %@
attempt to remove decision not found: %@
track %@ already added
error: track %@ already belongs to another script
track %@ already removed
error: attempt to remove track %@ from a different script
Adding track %@ (%@)
Removing track %@ (%@)
attempt to add track with invalid group identifier %@ (%@)
Adding group track %@ (%@) with group identifier %@
error: addTrack: track detection at time not present in script: %@
Primary decision %@ is user decision, but previous user decision %@ has maximum duration %@ that ends before trim starts %@
trackIdentifier missing from original detection %@
error: detection missing track identifier (%@)
SingleColorCubeCorrectionStage: cannot load 3d LUT from data!
GroupID / FaceID not found
hanging focus track id %ld (%@?) with mismatching last known detection: %@
error: attempt to read from nonexistent focus smoother for track %@
error: focus detection smoothers remain when none expected
detection type: %ld rect: { %.3f, %.3f, %.3f, %.3f } disparity: %.3f
error: histogram - unexpected pixel format type '%@' (%zdx%zd) - must be DisparityFloat16 or DisparityFloat32
error: attempt to create user tap with nil detection track number
Tracing enabled
PTRenderPipeline only supports transferFunctions: kCMFormatDescriptionTransferFunction_ITU_R_709_2, kCVImageBufferTransferFunction_ITU_R_2100_HLG, kCVImageBufferTransferFunction_Linear
PTRenderPipeline only supports transferFunctions: kCMFormatDescriptionTransferFunction_ITU_R_709_2, kCVImageBufferTransferFunction_ITU_R_2100_HLG
Unsupported bit depth: %d
Unsupported matrix type: %d
Cannot load bundle from %@
Error creating library %@ from %@
Error creating pipeline library %@ from className %@. Falling back to MTLLibrary
Unable to create function (%s): %s
Metal shader compilation warnings: %s
PortraitRuntimeAPIVersion %i
PTRenderPipeline requires Metal support for Non Uniform Threadgroup Size
prepareForRendering failed
Failed to prewarm PTRenderPipeline (%d)
minimumResourceHeapSize currently unsupported
setResourceHeap currently unsupported
PTPyramidRGB init failed
r[+]: %@
PTCinematographyNetwork
PTAtomStream
PTEffectRendererStudioLight
PTEffectImpl
NSObject
PTPixelBufferUtil
PTCinematographyTrack
PTCinematographyFixedFocusTrack
PTCinematographyExistingTrack
PTCinematographyExistingGroupTrack
PTCinematographyCustomTrack
PTEffectRendererSDOF
PTNormalEstimation
PTAssetReaderComposedFrame
PTAssetReaderCompositionInstruction
AVVideoCompositionInstruction
PTAssetReaderCustomCompositor
AVVideoCompositing
PTAssetReaderFrame
PTAssetReader
PTParameterPairSerialization
PTCinematographyFocusPuller
PTAtomWriter
PTCinematographyStreamOptions
NSCopying
NSMutableCopying
PTCinematographyStream
PTDataByteWriter
PTByteWriter
PTCinematographyFocusSmoother
PTCinematographyNetworkNamedSignal
PTCinematographyTransition
PTRaytracingV2002
RenderingIntegration
PTDisparityFilterDEMA_LKT
PTAbstractDisparityFilter
PTCinematographyFocusFramesOptions
PTCinematographyFocusFrames
CinematographyDictionary
LKTFlowGPU
PTCinematographyTrackAllocator
PTCinematographyNetworkUncertaintySignal
PTTuningParameters
PTDisparityFilterPassThrough
PTDisparityFilterExponentialMovingAverageLKTMotion
PTRenderRequest
PTTexture
PTCinematographyNetworkRectSignal
PTOpticalFlow
PTGlobalCinematographyMetadata
PTSerializable
PTGlobalCinematographyMetadataVersion1
ExtendedIndexSet
PTFocusBlurMap
PTGuidedFilter
PTDisparityFilterColorSimilarity
PTEffect
PTDisparityPostProcessingDescriptor
PTDisparityPostProcessing
PTTextureRGBA
PTTextureYUV420
PTCinematographyNetworkLabelSignal
PTDisparityUpscale
PTQualitySettings
PTEffectDebugLayer
PTTensorSwapPair
PTEspressoGenericExecutor
PTRenderEffectNetwork
PTSerializationTypeInfo
PTSerialization
PTTimedRenderingMetadata
PTTimedRenderingMetadataVersion1
Serialization
PTArraySerialization
PTMSRResize
PTSyntheticLight
FloatArray
MutableFloatArray
PTGlobalReduction
SRLv2Plist
PTSubjectRelighting
PTCinematographyFrameDetections
PTRenderPipelineState
PTRenderState
PTRaytracingV14RenderState
PTRaytracingV14
PTCinematographyRefinementOptions
PTCinematographyRefinement
PTMTLDropHintsInFlight
PTMTLDropHints
PTScanlineMask
PTScanlineMask_FocusBlurMap
PTScanlineIter_FocusBlurMap
PTScanlineIter
PTRaytracingUtils
PTRenderDebugLayer
PTTapToTrackPrediction
PTTapToTrack
PTEffectUtil
PTCinematographyNetworkPayload
PTCinematographyNetworkFloatOutputStream
PTCinematographyNetworkSignal
PTCinematographyFrame
Private
PTFaceAttributesNetwork
PTRaytracingV2001
PTRaytracingUtilsV2
PTCinematographyNetworkInputSchema
PTCinematographyNetworkParameters
Cinematography
PTDisparityFilterExponentialMovingAverageLKT
PTEffectRelighting
PTCinematographyScript
PTCinematographyDetection
PrivateCinematographyDictionary
SingleColorCubeCorrectionStage
PTHumanDetections
PTMTLDeviceProxy
MTLDeviceSPI
MTLDevice
PTCinematographyFrameDetectionSmoother
PTGlobalVideoHeaderMetadata
PTGlobalVideoHeaderMetadataVersion1
PTTimedStabilizationMetadata
PTTimedStabilizationMetadataVersion1
PTCinematographyUserTap
PTCinematographyFocusBlend
PTDataByteStream
PTByteStream
PTEffectTemporalState
PTCinematographyDecision
PTColor
PTUtil
PTEffectResources
PTGlobalStabilizationMetadata
PTGlobalStabilizationMetadataVersion1
PTRenderPipelineDescriptor
PTRenderPipeline
PTPyramidRGB
PTGlobalVideoMetadata
PTGlobalRenderingMetadata
PTGlobalRenderingMetadataVersion1
PTRaytracingInterpolateResult
PTEffectFilter
PTSegmentationNetwork
firstExistingVersion:
objectAtIndexedSubscript:
defaultVersionString
countByEnumeratingWithState:objects:count:
existsVersionString:
bundleForClass:
stringWithFormat:
URLForResource:withExtension:subdirectory:
initWithVersionString:
initWithURL:
_initWithNetwork:parameters:
init
_loadEspressoNetwork:
initWithTime:rect:focusDistance:
setDetectionType:
setTrackIdentifier:
arrayWithCapacity:
indexSet
array
params
inputSchemas
initWithModelDictionary:
addObject:
copy
dealloc
expectedFPS
_setNetworkDetectionsFromFrameDetections:
runOnlyWhenDetectorDidRun
detectorDidRun
boolValue
lastFocusDetection
trackIdentifier
detectionForTrackIdentifier:
autoFocusDetection
setLastFocusDetection:
presentationTime
_setNetworkInputsFromNetworkDetections
_debugLogNetworkInputs
_networkPredictionIndex
_debugLogNetworkOutputs
_shouldIgnoreNetworkPredictionIndex:time:
networkDetections
_detectionAtNetworkIndex:frameDetections:
_updateLastNetworkPredictionIndex:time:
lastNetworkPredictionIndex
lastNetworkPredictionTrackID
unusedIndexes
containsIndex:
time
_forgetNetworkDetectionAtIndex:
setLastNetworkPredictionIndex:
setLastNetworkPredictionTrackID:
supportedDetectionTypes
numberWithUnsignedInteger:
containsObject:
path
UTF8String
_allNetworkDetectionsAreStaleAtTime:
count
allTrackIdentifiersForCinematicChoice
setWithArray:
zeroDisparityDetection
_setNetworkDetection:atIndex:time:
_setMissingDetectionAtIndex:time:
forgetDetectionsAfterSeconds
_forgetNetworkDetectionsOlderThan:
numberWithInteger:
removeObject:
detectionType
_isNetworkCompatibleDetectionType:
_allocateNetworkDetectionIndex
numberWithUnsignedLong:
initWithTime:detection:missing:
initWithDestination:count:
inputSignals
writePayload:toStream:
objectForKeyedSubscript:
integerValue
_initWithCinematographyDictionary:
_isInvalid
addIndex:
setObject:forKeyedSubscript:
_asCinematographyDictionary
_setInvalid:
firstIndex
_getLeastRecentNetworkDetectionIndex
_setDetection:asInputRow:time:missing:
_shouldResetDetectionFromType:toType:
removeIndex:
setObject:atIndexedSubscript:
firstObject
reverseObjectEnumerator
allObjects
lastObject
defaultVersionStringForDetectionModel:
earliestVersionString
latestVersionString
T@"NSString",R
stepWithFrameDetections:
_debugLogAllNetworkInputs
versionString
.cxx_destruct
_step_i
_context
_plan
_network
_x_in
_hx_in
_cx_in
_mask_in
_hx_out
_cx_out
_pred_out
_versionString
_params
_inputSignals
_zeroDisparityDetection
_networkDetections
_unusedIndexes
_lastFocusDetection
_lastNetworkPredictionIndex
_lastNetworkPredictionTrackID
T@"PTCinematographyNetworkParameters",R,V_params
T@"NSArray",R,V_inputSignals
T@"PTCinematographyDetection",R,V_zeroDisparityDetection
T@"NSMutableArray",R,V_networkDetections
T@"NSMutableIndexSet",R,V_unusedIndexes
T@"PTCinematographyDetection",&,V_lastFocusDetection
TQ,V_lastNetworkPredictionIndex
Tq,V_lastNetworkPredictionTrackID
T@"NSString",R,V_versionString
Tf,R
floatValue
numberWithFloat:
appendString:
appendFormat:
initWithByteStream:offset:
size
_readAtomHeader
initWithParent:offset:
byteStream
globalAtomDataOffset
globalAtomOffset
atomSize
error
isAtEndOfStream
readCurrentAtomDataBytes:size:offset:
_debugLogAtomReaderState
_setErrorForByteStreamIfNeeded
_readBytes:size:offset:
_setEndOfStream
setError:
atomDataOffset
atomDataSize
_errorForReadPastLimit:size:offset:
readBytes:size:offset:
_debugLogBytes:size:offset:
_errorForByteStreamError:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
debugDescription
initWithByteStream:
initWithParent:
hasAtom
readCurrentAtomVersionAndFlags
advanceToNextAtom
parentStream
atomType
atomVersion
atomFlags
globalEndOffset
didReadAtomVersionAndFlags
_atEndOfStream
_didReadAtomVersionAndFlags
_atomType
_byteStream
_parentStream
_atomVersion
_atomFlags
_error
_atomSize
_atomDataOffset
_globalAtomOffset
_globalEndOffset
TQ,R,V_atomSize
TQ,R,V_atomDataOffset
TQ,R,V_globalAtomOffset
TQ,R,V_globalEndOffset
atEndOfStream
TB,R,GisAtEndOfStream,V_atEndOfStream
TB,R,V_didReadAtomVersionAndFlags
T@"<PTByteStream>",R,V_byteStream
T@"PTAtomStream",R,V_parentStream
TB,R
TI,R,V_atomType
TQ,R
TQ,R,V_atomVersion
TQ,R,V_atomFlags
T@"NSError",R,V_error
getColorMatrix:
device
newBufferWithLength:options:
initWithDevice:library:pipelineLibrary:
initPipelineState:library:pipelineLibrary:
initWithDevice:library:pipelineLibrary:commandQueue:colorSize:effectUtil:util:useHighResNetwork:sharedResources:
outDisparity
width
height
initDisparityNormalFilterWithDevice:disparitySize:updateCoefficientDisparity:updateCoefficientNormal:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setUsage:
supportsFamily:
setResourceOptions:
intValue
initWithDevice:colorSize:lktPreset:allocateDisplacementFWD:needConversionBGRA2YUVA:inverseFlow:
inRGBA
rotated
initWithDevice:commandQueue:inputSize:target:rotateTargetPixelBuffer:sharedResources:
targetRGBAPixelBuffer
bindColorInputPixelBuffer:
pyramidRGBA
findMipmapLevel:largerThan:
newTextureWithDescriptor:
initWithDevice:library:pipelineLibrary:colorSize:pixelFormat:skipFullSizeLayer:doFirstLevelGaussianDownsample:mipmapLevelCount:
commandBuffer
restoreState:network:disparityFilter:faceRects:numberOfFaceRects:
commit
latestVersion
initWithDevice:version:colorSize:disparitySize:
createWithQuality:config:
setDoCenterDisparity:
setDisableForegroundBlur:
setDisparityUpsampleFactor:
setIntermediatePixelFormat:
initWithDevice:library:pipelineLibrary:useExportQualityNoise:
initWithDevice:library:pipelineLibrary:imageSize:scale:epsilon:
newBufferWithBytes:length:options:
setFrameId:
initWithDevice:library:pipelineLibrary:commandQueue:faceAttributesNetwork:effectUtil:util:prewarmOnly:colorSize:msrColorPyramid:sharedResources:
gainMap
colorCube
interpolateRGBWeightUsingSourceToDest:renderRequest:inRGBWeight:inGainMap:inColorCube:
setOptions:
initWithDescriptor:
quality
createRenderStateWithQuality:
setSourceColorBitDepth:
initWithDevice:library:pipelineLibrary:commandQueue:effectRelighting:disparityNormalFilter:opticalFlow:renderState:util:portraitColor:msrColorPyramid:network:disparityFixedFocus:focusDepthFixed:focusObject:
initWithDevice:util:
saveState:network:msrColorPyramid:faceRects:numberOfFaceRects:
reset
setFrameIndex:
executeNetwork
parseFaceRects:
pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:
createYUV420:chroma:
setSourceColor:
sourceColor
setColorSpaceInformation:pixelBuffer:
downsampleToQuarterSize:
downsampleQuarterSizeToTargetSize:
instance:
setActiveResourceGroups:
prepareFilter:rgbaPyramid:network:
depthEstimation
applyFilter:disparity:
filteredDisparity
sampleFaceRects:maxFaceRects:faceRects:numberOfFaceRects:inDisparity:outFocusDistanceArray:
updateFocusObject:faceRectCount:focusDepthOffset:exponentialMovingAverage:isFirstFrame:lastFocus:inFocusDistanceArray:outFocusObject:outFocusFaceIndex:
fixedFocusDistanceAndCenterDisparity:inDisparity:outDisparity:focusDepthFixed:focusDepthMax:inFocusObject:
guidedFilter:image:guideRGBACoefficients:guideRGBAUpscale:sourceColorBitDepth:
setDestinationColor:
destinationColor
estimateLightIntensity:inChroma:inFaceRects:numberOfFaceRects:focusFaceIndex:humanDetections:transform:
filteredNormal
getColorTransferFunction:linearToEncoded:
studioLight:inLuma:inChroma:inNormal:inDisparity:inFocusObject:outPTTexture:outRgbaPyramid:colorTransferFunction:colorYCbCrMatrix:
updatePyramid:offset:
setAperture:
setFocusDistance:
upscaledTexture
setSourceDisparity:
setRenderState:
encodeRenderTo:withRenderRequest:
addCompletedHandler:
waitUntilCompleted
waitUntilScheduled
isPixelBuffer10Bit:
setYCbCrColorDepth:
isPixelBufferVideoRange:
setYCbCrFullRange:
setYCbCrMatrix:
setTransferFunction:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
T#,R
T@"NSString",R,C
render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:
copyTemporalState:
setDebug:
effectQuality
setEffectQuality:
initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:faceAttributesNetwork:prevTemporalState:sharedResources:
_device
_library
_pipelineLibrary
_commandQueue
_renderPipeline
_renderState
_raytracingInterpolation
_disparityFixedFocus
_focusDisparityArray
_focusObject
_lastFocus
_msrColorPyramid
_transferFunction
_YCbCrMatrix
_colorPrimaries
_colorYCbCrMatrix
_guidedFilter
_guideRGBAUpscale
_guideRGBACoefficients
_effectRelighting
_rgbaPyramid
_portraitColor
_sdofRenderRequest
_debugLayer
_colorWidth
_colorHeight
_fNumber
_asynchronous
_disparityOpticalFlow
_frameIndex
_networkIndex
_faceRects
_numberOfFaceRects
_focusDepthFixed
_focusDepthMax
_focusDepthOffset
_iirUpdateCoefficientDisparity
_iirUpdateCoefficientNormal
_temporalDisparityTempDropHints
_util
_effectUtil
_focusDisparityUpdateCoefficient
_effectType
_disparityNormalFilter
_focusFaceIndex
_debugType
Tq,VeffectQuality
_getPixelFormatsForType:luma:chroma:
unsignedIntValue
isCompressed:
getNoConcurrentAccessHint:
getMetalLumaAndChromaFormats:luma:chroma:
newTextureWithDescriptor:iosurface:plane:
getMTLTextureDescriptor:device:
getMTLTextureFromPixelBuffer:device:
getCVPixelBufferGetPixelFormatType:
initWithDetectionType:
timeRangeForTime:
timeRangeCount
timeRangeAtIndex:
timeRanges
_calculateTimeRanges
CMTimeRangeValue
script
timeRange
framesInTimeRange:
detectionInFrame:
_addStartTime:endTime:toTimeRanges:
valueWithCMTimeRange:
debugTrackIdentifierString
cachedTrackIdentifierString
isUserCreated
numberWithBool:
trackType
groupIdentifier
_asMutableCinematographyDictionary
unsignedIntegerValue
isDiscrete
timeRangeEndForTime:
detectionNearestTime:
detectionAtOrBeforeTime:
detectionsInTimeRange:
setGroupIdentifier:
setScript:
_trackByTrimmingToTimeRange:subtracting:
setUserCreated:
_userCreated
_trackIdentifier
_groupIdentifier
_detectionType
_script
_timeRanges
_cachedTrackIdentifierString
T@"PTCinematographyScript",W,N,V_script
T@"NSArray",R,N,V_timeRanges
userCreated
TB,N,GisUserCreated,V_userCreated
T@"NSString",R,N,V_cachedTrackIdentifierString
TQ,R,N
Tq,R,N,V_trackIdentifier
Tq,R,N,V_groupIdentifier
TQ,R,N,V_detectionType
discrete
TB,R,N,GisDiscrete
initWithDetection:
focusDistance
detection
_detectionByChangingTime:
_fixedFocusDetectionAtTime:
arrayWithObjects:count:
initWithFocusDistance:
_detection
Tf,R,N
T@"PTCinematographyDetection",R,N,V_detection
_detectionWithTrackIdentifier:atOrBeforeTime:
initWithDetectionType:trackIdentifier:groupIdentifier:
bestDetectionForGroupIdentifier:
_detectionWithGroupIdentifier:atOrBeforeTime:
trackDecisions
_calculateTrackDecisions
_indexRangeOfTimeRange:
subarrayWithRange:
initWithTime:trackIdentifier:options:
initWithDetectionType:groupIdentifier:
trackDecisionsInTimeRange:
_trackDecisions
T@"NSArray",R,N,V_trackDecisions
allDetections
addSample:
endSamples
nextSmoothedSample
detections
_firstIndexAtOrAfterTime:
_indexNearestTime:
mutableCopy
initWithDetections:
_cinematographyArrayFromDetections:
_detectionsFromCinematographyArray:
applyDetectionSmoothing
setDetections:
_detections
T@"NSArray",&,N,V_detections
T@"NSArray",R,N
initDisparityFilterWithDevice:disparitySize:updateCoefficientDisparity:
setDisparityGuidedFilterEpsilon:
dropHints
setDropHintsFor:
updatePyramidFromPTTexture:inPTTexture:
renderDebugInformation:renderRequest:humanDetections:transform:
initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:prevTemporalState:sharedResources:
_renderStates
_disparityFilter
computeCommandEncoder
setComputePipelineState:
setTexture:atIndex:
setBytes:length:atIndex:
dispatchThreads:threadsPerThreadgroup:
endEncoding
initWithDevice:
estimateNormalsFromDisparity:inDiparity:outNormal:sensorWidth:focalLength:
_estimateNormalsFromDisparity
initWithTime:colorBuffer:auxBuffer:
colorBuffer
auxBuffer
_colorBuffer
_auxBuffer
_time
T{?=qiIq},R,N,V_time
T^{__CVBuffer=},R,N,V_colorBuffer
T^{__CVBuffer=},R,N,V_auxBuffer
videTrackID
numberWithInt:
auxvTrackID
enablePostProcessing
containsTweening
requiredSourceTrackIDs
passthroughTrackID
requiredSourceSampleDataTrackIDs
T{?={?=qiIq}{?=qiIq}},R,N
TB,R,N
Ti,R,N
setTimeRange:
setVideTrackID:
setAuxvTrackID:
assetReader
setAssetReader:
_videTrackID
_auxvTrackID
_assetReader
_timeRange
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
Ti,N,V_videTrackID
Ti,N,V_auxvTrackID
T@"PTAssetReader",W,N,V_assetReader
videoCompositionInstruction
sourceFrameByTrackID:
compositionTime
pushComposedFrame:
finishWithComposedVideoFrame:
finishWithError:
renderContextChanged:
startVideoCompositionRequest:
sourcePixelBufferAttributes
requiredPixelBufferAttributesForRenderContext
cancelAllPendingVideoCompositionRequests
anticipateRenderingUsingHint:
prerollForRenderingUsingHint:
supportsWideColorSourceFrames
supportsHDRSourceFrames
canConformColorOfSourceFrames
T@"NSDictionary",R,N
disparityBuffer
isValidJSONObject:
_jsonFriendlyObject:
setObject:forKey:
enumerateKeysAndObjectsUsingBlock:
metadata
jsonFriendlyMetadata
setTime:
index
setIndex:
setMetadata:
setJsonFriendlyMetadata:
metadataTime
setMetadataTime:
setColorBuffer:
colorBufferTime
setColorBufferTime:
colorBufferPreferredTransform
setColorBufferPreferredTransform:
setDisparityBuffer:
disparityBufferTime
setDisparityBufferTime:
disparityBufferPreferredTransform
setDisparityBufferPreferredTransform:
_index
_metadata
_jsonFriendlyMetadata
_disparityBuffer
_metadataTime
_colorBufferTime
_disparityBufferTime
_colorBufferPreferredTransform
_disparityBufferPreferredTransform
T{?=qiIq},N,V_time
TQ,N,V_index
T@"NSDictionary",&,N,V_metadata
T@"NSDictionary",&,N,V_jsonFriendlyMetadata
T{?=qiIq},N,V_metadataTime
T^{__CVBuffer=},N,V_colorBuffer
T{?=qiIq},N,V_colorBufferTime
T{CGAffineTransform=dddddd},N,V_colorBufferPreferredTransform
T^{__CVBuffer=},N,V_disparityBuffer
T{?=qiIq},N,V_disparityBufferTime
T{CGAffineTransform=dddddd},N,V_disparityBufferPreferredTransform
registerSerializationClass:
removeObjectAtIndex:
tracksWithMediaType:
estimatedDataRate
nominalFrameRate
formatDescriptions
updateFormatPropertiesFromAsset:
stopReadingFrames
startReadingFrames:error:
startReadingFrames:atTime:error:
asset
assetReaderWithAsset:error:
initWithTrack:outputSettings:
initWithAssetReaderTrackOutput:
addOutput:
trackID
videoComposition
setCustomVideoCompositorClass:
setSourceTrackIDForFrameTiming:
naturalSize
setRenderSize:
setFrameDuration:
setInstructions:
initWithVideoTracks:videoSettings:
setVideoComposition:
setAlwaysCopiesSampleData:
canAddOutput:
startReading
cancelReading
duration
startReadingFrames:
nextFrame
_decodeGlobalMetadata
metadataForFormat:
isEqualToString:
value
deserializeMetadataWithType:fromGlobalMetadata:error:
unarchivedObjectOfClasses:fromData:error:
globalRenderingMetadata
majorVersion
minorVersion
objectFromData:withMajorVersion:minorVersion:
globalStabilizationMetadata
objectFromData:error:
nextTimedMetadataGroup
dictionary
items
_decodeMetadata:
copyNextSampleBuffer
popComposedFrame
videoTracks
preferredTransform
initialize
isReadyForReading
initWithAsset:
estimatedFrameCount
frameCount
globalCinematographyMetadata
globalVideoHeaderMetadata
formatDescription
frameDuration
colorPrimaries
setColorPrimaries:
transferFunction
YCbCrMatrix
is420YUV10Bit
setIs420YUV10Bit:
metadataAdaptor
videoCompositionOutput
composedFrames
lastDecodedFrameIndex
_cachedAccurateFrameCount
_globalCinematographyMetadata
_globalRenderingMetadata
_globalStabilizationMetadata
_globalVideoHeaderMetadata
_is420YUV10Bit
_asset
_estimatedDataRate
_formatDescription
_frameDuration
T@"AVAsset",R,N,V_asset
TQ,R,N,V_estimatedDataRate
Tr^{opaqueCMFormatDescription=},R,N,V_formatDescription
T{?=qiIq},R,N,V_frameDuration
T@"PTGlobalCinematographyMetadata",R,N
T@"PTGlobalRenderingMetadata",R,N
T@"PTGlobalStabilizationMetadata",R,N
T@"PTGlobalVideoHeaderMetadata",R,N
T@"NSString",&,N,V_colorPrimaries
T@"NSString",&,N,V_transferFunction
T@"NSString",&,N,V_YCbCrMatrix
TB,N,V_is420YUV10Bit
isEnabled
stringByAppendingString:
appendUIntParameter:value:toOutput:
getFloatParameter:fromPairs:numPairs:didFindValue:
getUIntParameter:fromPairs:numPairs:withDefault:didFindValue:
getUIntParameter:fromPairs:numPairs:didFindValue:
appendFloatParameter:value:toOutput:
appendCMTimeParameter:value:scale:toOutput:
getFloatParameter:fromPairs:numPairs:
getFloatParameter:fromPairs:numPairs:withDefault:
getUIntParameter:fromPairs:numPairs:
getCMTimeParameter:scale:fromPairs:numPairs:withDefault:
defaultStrategy
defaultEMASampleCount
initWithExponentialMovingAverageSampleCount:
defaultMaximumVelocity
defaultResistance
initWithMaximumVelocity:resistance:
setAlpha:
setSampleCount:
maximumVelocity
maximumAcceleration
_minimumTimestepsToMoveBy:maxddx:
velocity
setFocusDistance:time:
strategy
_emaDelta:
_weightedDialDelta:timeDelta:
pullTowardFocusDistance:time:
initWithExponentialMovingAverageAlpha:
alpha
resistance
sampleCount
pullTowardFocusDistance:time:missing:
setVelocity:
targetDistance
setTargetDistance:
_alpha
_maximumVelocity
_resistance
_focusDistance
_velocity
_maximumAcceleration
_targetDistance
_sampleCount
_strategy
Tf,R,V_maximumAcceleration
Tf,V_alpha
TQ,V_sampleCount
Tf,V_targetDistance
TQ,R,V_strategy
Tf,R,V_maximumVelocity
Tf,R,V_resistance
T{?=qiIq},V_time
Tf,V_focusDistance
Tf,V_velocity
byteWriter
_appendBytes:size:
_debugLogAtomWriterState
_setErrorForByteWriterIfNeeded
_errorForVersion:
_errorForSize:
_writeBytes:size:offset:
_debugLogBytes:size:
appendBytes:size:
writeBytes:size:offset:
_errorForByteWriterError:
initWithByteWriter:
beginAtomOfType:
appendVersion:flags:
endAtom
parentWriter
didBeginAtom
_didBeginAtom
_byteWriter
_parentWriter
TB,R,V_didBeginAtom
T@"<PTByteWriter>",R,V_byteWriter
T@"PTAtomWriter",R,V_parentWriter
version
fixedFocusNormalizedRectSize
cinematographyParameters
_snapshotPolicy
_overrideFrameSnapshotPolicy
initWithOptions:
copyWithZone:
mutableCopyWithZone:
_setSnapshotPolicy:
_setOverrideFrameSnapshotPolicy:
setVersion:
setFixedFocusNormalizedRectSize:
setCinematographyParameters:
_version
_cinematographyParameters
_fixedFocusNormalizedRectSize
TQ,N,S_setSnapshotPolicy:,V_snapshotPolicy
TB,N,S_setOverrideFrameSnapshotPolicy:,V_overrideFrameSnapshotPolicy
TQ,V_version
T{CGSize=dd},V_fixedFocusNormalizedRectSize
T@"NSDictionary",C,V_cinematographyParameters
isSupportedVersion:
_reset
_updateDetectionModelFromMetadata:
_updateFocusBlurMapModeFromMetadata:
_frameDetectionsFromMetadata:time:disparityBuffer:
_userTapFromMetadata:frameDetections:disparityBuffer:
setActiveUserTap:
_logUserTap:
userAperture
options
_frameFromDetections:userAperture:snapshotPolicy:disparityPixelBuffer:
_logFocusChangeForFrame:
_logUnusualDisparity:kind:info:
setPreviousFrame:
setPreviousRecordingState:
network
setFocusPullerAlpha:
setFocusPullerMaxV:
setFocusPullerResistance:
writeToGlobalMetadata:
_nextSnapshotForPolicy:
_chooseFocusDetection:
activeUserTap
isFixedFocusDetection
_isUserTap:inFrameDetections:
isStrong
_userTapLockEndsAtTime:
_userTapEndsForBaseFocusDetection:
_userTapEndsForChangedFocusWithDisparityBuffer:
addDetection:
_copyUserFocusDetectionFromDetections:
setAllDetections:
setFocusDetection:
setRawFocusDistance:
trackNumber
setFocusTrackNumber:
setBaseFocusTrackNumber:
setUserFocusTrackNumber:
_setDetectorDidRun:
setUserFocusStrong:
isGroupTap
setUserFocusGroup:
setUserFocusEnd:
frameIndex
_setFrameNumber:
_setSnapshot:
_debugLogFrames:label:
bestDetectionForGroupIdentifier:options:
activeVersion
previewFocusPuller
previousFrame
removeObjectForKey:
setUserAperture:
setPreviewFocusPuller:
previousRecordingState
_copyInternalState
_defaultAperture
initWithTrackIdentifier:
_userDefaultNetworkVersion
rect
trackAllocator
nextTrackIdentifier
componentsSeparatedByString:
didReadFocusStrategyDefault
setDidReadFocusStrategyDefault:
hasPrefix:
setInternalDefaultFocusStrategy:
_stringValueForAssignmentString:
setInternalDefaultNetworkVersion:
_floatValueForAssignmentString:
setInternalDefaultFixedFocusDisparity:
_getFocusStrategyIfNeeded
internalDefaultFocusStrategy
internalDefaultNetworkVersion
internalDefaultFixedFocusDisparity
_userDefaultFocusStrategy
_userDefaultFixedFocusDisparity
_detectionForFixedFocusDistance:rect:
_chooseClosestObjectDetection:
_chooseLargestAreaDetection:
baseFocusTrackNumberOverride
_minimumUserTapSeconds
baseFocusTrackNumber
detectionForTrackNumber:
isEqualToNumber:
_hasFusionTrackerMetadata:
_trackingResultFromFusionTrackerMetadata:
tapResponse
_userTapFromFTTapResponse:frameDetections:disparityBuffer:
_isFixedFocusFTTapRequestMetadata:
tapPoint
_isValidNormalizedPoint:
wasSuccessful
request
_isTapToTrackFTTapRequest:
_defaultFixedFocusRectForPoint:disparityBuffer:
_fixedFocusRectForPoint:disparityBuffer:
trackId
_isSuccessfulTapToTrackFTTapResponse:
customDetection
_isFixedFocusFTTapRequest:
_isFailedTapToTrackFTTapResponse:
_detectionForFixedFocusAtNormalizedPoint:disparityBuffer:
initWithTime:tappedDetection:strong:group:
_isExcludedAsCinematicChoice
_frameDetectionsFromFusionTrackerMetadata:time:disparityBuffer:
setBaseFocusTrackNumberOverride:
_useSyntheticDDR
setDetectorDidRunNextExpectedTime:
detectorDidRunNextExpectedTime
_autoFocusRectFromMetadata:
_autoFocusBlurMapFromMetadata:
setAutoFocusRect:
_detectionsFromFTTrackingResult:autoFocusRect:focusBlurMap:namedSignalsPerTrack:time:disparityBuffer:
_detectorDidRunFromFTTrackingResult:time:
frameDetections:detectorDidRun:presentationTime:
identifier
objectKind
doubleValue
_sensorSizeFromMetadata:
_validSensorRectFromMetadata:
initWithFocusBlurMapData:sensorSize:validSensorRect:
valueWithRect:
setCanCopyISPDetectionsIfMissing:
canCopyISPDetectionsIfMissing
_copyPreviousISPDetections:toDetections:time:
_mutableDetectionsFromFTTrackingResult:namedSignalsPerTrack:time:
_autoFocusDetectionWithTime:rect:
_setDisparityOfDetections:disparityBuffer:focusBlurMap:
_updateDetections:ifMissingISPDetectionsFromTrackingResult:time:
_ANODPoseFromFTTrackMetadata:
tracks
_isInvalidFTTrack:
_detectionTypeForFTObjectKind:
_setExcludedAsCinematicChoice:
numberWithLongLong:
objectForKey:
_namedSignals:addingANODPoseFromFTTrackMetadata:
set_namedSignals:
_namedSignals
focusIdentifier
inFocusRegion
largestFocusRegion
_inFocusRegionForFocusBlurMap:
inputValidNormalizedRect
scanlineMaskWithFocusBlurMap:region:
validNormalizedRectFromRegion:
setRect:
isAutoFocusDetection
_focusDistanceForAutoFocusDetection:lockedDisparityBufferAddress:width:height:bytesPerRow:formatType:focusBlurMap:
_focusDistanceForDetection:lockedDisparityBufferAddress:width:height:bytesPerRow:formatType:
_logUnusualDetection:info:
focusDetection
processColorBuffer:disparityBuffer:metadataDictionary:presentationTime:
endOfStream
adviseDidStartRecording
adviseDidStopRecording
modelVersionString
getGlobalMetadata:
_restoreInternalState:
_disparityWeightingValue
smoothFocusDistance:trackIdentifier:sampleCount:
delegate
setDelegate:
setTrackAllocator:
setNetwork:
detectionModel
setDetectionModel:
focusBlurMapMode
setFocusBlurMapMode:
autoFocusUseBlurMap
setAutoFocusUseBlurMap:
autoFocusUseMask
setAutoFocusUseMask:
autoFocusInFocusRegionSelect
setAutoFocusInFocusRegionSelect:
_autoFocusUseBlurMap
_autoFocusUseMask
_canCopyISPDetectionsIfMissing
_didReadFocusStrategyDefault
_userAperture
_internalDefaultFixedFocusDisparity
_delegate
_activeVersion
_options
_trackAllocator
_previewFocusPuller
_detectionModel
_focusBlurMapMode
_autoFocusInFocusRegionSelect
_previousRecordingState
_previousFrame
_activeUserTap
_internalDefaultFocusStrategy
_internalDefaultNetworkVersion
_detectorDidRunNextExpectedTime
T@"PTCinematographyStreamOptions",&,N,V_options
T@"PTCinematographyTrackAllocator",&,N,V_trackAllocator
T@"PTCinematographyNetwork",&,N,V_network
T@"PTCinematographyFocusPuller",&,N,V_previewFocusPuller
TQ,N,V_detectionModel
TQ,N,V_focusBlurMapMode
TB,N,V_autoFocusUseBlurMap
TB,N,V_autoFocusUseMask
TQ,N,V_autoFocusInFocusRegionSelect
TQ,N,V_frameIndex
TQ,N,V_previousRecordingState
T@"PTCinematographyFrame",&,N,V_previousFrame
TB,N,V_canCopyISPDetectionsIfMissing
T@"PTCinematographyUserTap",&,N,V_activeUserTap
T{?=qiIq},N,V_detectorDidRunNextExpectedTime
TB,V_didReadFocusStrategyDefault
TQ,V_internalDefaultFocusStrategy
Tf,V_internalDefaultFixedFocusDisparity
T@"NSString",&,V_internalDefaultNetworkVersion
T@"<PTCinematographyStreamDelegate>",W,N,V_delegate
Tf,N,V_userAperture
TQ,R,V_activeVersion
userFocusTrackNumber
isUserFocusStrong
isFocusStrong
focusStrong
TB,R,N,GisFocusStrong
sourceFrameTimestamp
length
appendBytes:length:
_errorForSize:offset:
replaceBytesInRange:withBytes:length:
initWithMutableData:
data
setData:
_data
T@"NSError",&,V_error
T@"NSMutableData",&,V_data
initWithCount:capacity:
setFloat:inRange:
appendFloat:
_padToFill
isSmoothedSampleAvailable
_getSmoothedSample
_advanceToNextSmoothedSample
nextFocusSmoother
floatAtIndex:
floats
removeFromStart:
_padByCount:
_lastAddedSample
isEndOfSmoothedSamples
lastFocusSmoother
minSamplesNeeded
didEndSamples
setNextFocusSmoother:
cachedSamples
setCachedSamples:
unprocessedSampleCount
setUnprocessedSampleCount:
_didEndSamples
_minSamplesNeeded
_nextFocusSmoother
_cachedSamples
_unprocessedSampleCount
T@"MutableFloatArray",&,V_cachedSamples
TQ,V_unprocessedSampleCount
TQ,R,V_minSamplesNeeded
TB,R,V_didEndSamples
T@"PTCinematographyFocusSmoother",&,V_nextFocusSmoother
T@"PTCinematographyFocusSmoother",R
checkSignalForStream:
name
flatten
_flattenArray:
isMissingDetection
writeZerosWithCount:
writeFloat:
_flattenArray:toMutableArray:
objectAtIndex:
_flatten
TB,R,V_flatten
kind
linearCoefficientForNormalizedTime:
initWithKind:
coefficientForNormalizedTime:
setKind:
_kind
TQ,N,V_kind
createFocusEdge
doFirstLevelGaussianDownsample
useExportQualityNoise
numberOfPatternCircles
initEquidistPoints:samplePatternCircles:
createRandomUChars:rayCount:
rayMarchAll
rayMarch
renderDownscale
setConstantValue:type:withName:
initWithDevice:library:pipelineLibrary:textureSize:
doDisparityUpsampling
disparityUpsampleFactor
disparityGuidedFilterEpsilon
rgbaPyramidArray
doCenterDisparity
arrayWithObjects:
initWithDevice:resources:name:
doFocusEdgeMask
intermediatePixelFormat
doIntermediate2XUpscale
renderState
aperture
alphaLowLight
doMacroApertureLimit
createFocusObject:coverageOverscan:anamorphicFactor:rayCount:colorSize:doMacroApertureLimit:
scissorRect
sourceDisparity
foregroundBlurLimitingFactor
centerDisparityOnFocus:inDisparity:outDisparity:focusObject:foregroundBlurLimitingFactor:
parallelReductionMinMax:inTexture:globalMinMaxBuffer:
detectDilatedEdges:inDisparity:tempEdges:outEdges:focusObject:disparityDiffMinMax:edgeTolerance:
sourceColorBitDepth
dropHintsFor:
focusEdgeMask:inDisparityDiff:focusObject:focusEdge:outFocusEdgeMask:
rgbaPyramid
setBuffer:offset:atIndex:
copyTex:inTex:outTex:
interpolateRGBWeightUsingSourceToDest:renderRequest:inRGBWeight:
commandQueue
checkForUnreleasedDrophints
status
initWithDevice:library:pipelineLibrary:colorSize:disparitySize:debugRendering:verbose:gpuProfiling:config:quality:
renderContinuousWithSource:renderRequest:
prewarm
minimumResourceHeapSize
setResourceHeap:
_config
_debugRendering
_disparitySize
_colorSize
_injectedRGBAPyramid
_focusEdge
_qualitySettings
_raytracingUtils
_raytracingInterpolateResult
_globalReduction
_aperturePointsXY
_randomUChars
_disparityDiffGlobalMinMax
_disparityEdges
_disparityEdgesTemp
_disparityDiff
_focusEdgeMask
_raytracedRGBWeight
_raytracedRGBWeightUpscaled
_disparityDiffDropHints
_dropHintsRaytracing
_dropHintsRGBWeightUpscaled
_doVisualization
_kRayCount
_kColorSize
_kCoverageOverscan
_anamorphicFactor
_edgeTolerance
_raytracingSDOF
interpolateRGBWeightCustomFn
initFilter:sensorPort:
setNormalizedCoordinates:
setMinFilter:
setMagFilter:
newSamplerStateWithDescriptor:
initWithDevice:library:pipelineLibrary:textureSize:pixelFormat:
estimateDisplacementStream:destRGBA:outDisplacement:
copyDisparity:inDisparity:outDisparity:
exponentialMovingAverageFilter:inDisplacement:inDemaPrev:inDisparity:outDisparity:outDEMA:
temporalDisparityFilter:inDisplacement:inStatePrev:inDisparity:outDisparity:outState:
parallelReductionAverage:inTexture:outGlobalAverage:
setSamplerState:atIndex:
prepareFilter:inRGBA:outDisplacement:
temporalDisparityFilter:inDisplacement:inDisparityPrev:inDisparity:outDisparity:disparityBias:
initFilter:
initWithCommandQueue:disparitySize:disparityFilteredSize:disparityPixelFormat:colorSize:colorPixelFormat:sensorPort:
_temporalFilterDEMA_LKT
_temporalFilterDEMA_LKT_VisualizeMotion
_resampleDisparity
_frameCount
_opticalFlow
_avgDisplacement
_dumpInputOutputFolder
_disparityFilteredSize
_direction
_motionVisualization
_demaStates
_samplerState
_defaultMinimumRackFocusPullTime
_defaultMaximumRackFocusPullTime
_defaultMaximumDisparityPerSecond
minimumRackFocusPullTime
maximumRackFocusPullTime
maximumDisparityPerSecond
setMinimumRackFocusPullTime:
setMaximumRackFocusPullTime:
setMaximumDisparityPerSecond:
initWithGlobalMetadata:
_maximumDisparityPerSecond
_minimumRackFocusPullTime
_maximumRackFocusPullTime
T{?=qiIq},N,V_minimumRackFocusPullTime
T{?=qiIq},N,V_maximumRackFocusPullTime
Tf,N,V_maximumDisparityPerSecond
_framesIndex:earlierBy:
initWithFrames:options:
startIndexForLinearRackFocusPullToFrameAtIndex:
frames
setFrames:
_frames
T@"NSArray",&,N,V_frames
T@"PTCinematographyFocusFramesOptions",C,N,V_options
numberWithDouble:
asCinematographyDictionary
exceptionWithName:reason:userInfo:
_setDefaultParameters
_initMemory:height:nscales:
_setupPipelines
_setupBuffer
setOutputTexUVForward:backward:
_zeroFlowWithCommandBuffer:uv_tex:
isBidirectional
_createImagePyramidWithCommandBuffer:in_tex:I_idx:
_computeOpticalFlowBidirectional:
_computeOpticalFlow:computeFeatureI0:computeFeatureI1:
setLabel:
_enqueueKeypointsFromFlowWithCommandBuffer:in_uv_fwd_tex:in_uv_bwd_tex:out_kpt_buf:block_size:bidirectional_error:out_num_keypoints:
initWithUTF8String:
newFunctionWithName:
setPipelineLibrary:
setComputeFunction:
newComputePipelineStateWithDescriptor:error:
threadExecutionWidth
setWidth:
setHeight:
setPixelFormat:
newTextureViewWithPixelFormat:
newBufferWithPixelFormat:width:data:
_computeFeaturesWithCommandBuffer:in_tex:out_tex:
_computeFeaturesDerivativesWithCommandBuffer:in_tex:out_tex:
_doSolverWithCommandBuffer:scale:in_uv_tex:in_G0_tex:in_G1_tex:in_C0_tex:in_C1_tex:out_uv_tex:out_w_tex:
_doNLRegularizationWithCommandBuffer:in_uv_tex:join_tex:w_tex:out_uv_tex:
_enqueueFlowConsistencyWithCommandBuffer:in_uv0_tex:in_uv1_tex:out_uv_tex:
_downscale2XWithCommandBuffer:in_tex:out_tex:
_computeScalingFactor:dst_tex:scale_xy_inv:coeff:
initWithDevice:width:height:nscales:
keypoints
setPreset:
setOutputTexUV:
estimateFlowFromTexReference:target:commandBuffer:
estimateFlowStreamTex:index:doOpticalFlow:commandBuffer:
estimateFlowStreamTex:commandBuffer:
computeKeypointsFromTexForwardFlow:backwardFlow:bidirectionalError:blockSize:outNumKeypoints:commandBuffer:
isValid
needConversionBGRA2YUVA
setNeedConversionBGRA2YUVA:
ref_size
aux_size
nscales
streamFrameCount
nwarpings
setNwarpings:
useNonLocalRegularization
setUseNonLocalRegularization:
nlreg_radius
setNlreg_radius:
nlreg_padding
setNlreg_padding:
nlreg_sigma_l
setNlreg_sigma_l:
nlreg_sigma_c
setNlreg_sigma_c:
nlreg_sigma_w
setNlreg_sigma_w:
setIsBidirectional:
isInverse
setIsInverse:
_computePipelines
_maxThreadExecutionWidth
_ref_pyr_size
_aux_pyr_size
_I_tex
_I_u32_alias_tex
_G0_tex
_G1_tex
_C0_tex
_C1_tex
_Adiagb_buf
_Ixy_buf
_idt_buf
_w_tex
_uv_fwd_tex
_uv_bwd_tex
_uv_fwd_u32_alias_tex
_uv_bwd_u32_alias_tex
_current_frame_index
_streamFrameCount
_indexUpdated
_uv_fwd_tex_user_ref
_uv_bwd_tex_user_ref
_kpt_buf
_dropHints
_isValid
_needConversionBGRA2YUVA
_useNonLocalRegularization
_isBidirectional
_isInverse
_nscales
_nwarpings
_nlreg_radius
_nlreg_padding
_nlreg_sigma_l
_nlreg_sigma_c
_nlreg_sigma_w
_ref_size
_aux_size
TB,R,N,V_isValid
TB,N,V_needConversionBGRA2YUVA
T{CGSize=dd},R,N,V_ref_size
T{CGSize=dd},R,N,V_aux_size
Ti,R,N,V_nscales
Ti,R,N,V_streamFrameCount
Ti,N,V_nwarpings
TB,N,V_useNonLocalRegularization
Ti,N,V_nlreg_radius
Ti,N,V_nlreg_padding
Tf,N,V_nlreg_sigma_l
Tf,N,V_nlreg_sigma_c
Tf,N,V_nlreg_sigma_w
TB,N,V_isBidirectional
TB,N,V_isInverse
T@"<MTLBuffer>",R,N
Tq,N,V_trackIdentifier
_timerUncertaintyForPayload:
timerSecondsDivisor
_timerSecondsDivisor
Tf,R,V_timerSecondsDivisor
noiseScaleFactorForHwModelID:sensorID:
hwModelIDFromFigModelSpecificName:
hwModelIDToString:
initWithCommandQueue:
debugTextures:
debugTexturesNames
temporaryDirectory:
copyDisparityWithBias:inDisparity:outDisparity:disparityBias:
exponentialMovingAverageFilter:inDisplacement:inDisparityPrev:inDisparity:outDisparity:updateCoefficient:disparityBias:
exponentialMovingAverageFilterNormal:inDisplacement:inNormalPrev:inNormal:outNormal:updateCoefficient:
_temporalFilterExponentialMovingAverageLKTMotion
_temporalFilterExponentialMovingAverageLKTMotionNormal
_copyDisparityWithBias
_iirUpdateCoefficient
setAlphaLowLight:
setAGC:
highlightBoostFactor
setHighlightBoostFactor:
highlightChromaFactor
setHighlightChromaFactor:
frameId
disparityMin
setDisparityMin:
disparityMax
setDisparityMax:
setScissorRect:
_aperture
_alphaLowLight
_AGC
_highlightBoostFactor
_highlightChromaFactor
_frameId
_disparityMin
_disparityMax
_sourceColor
_sourceDisparity
_destinationColor
_scissorRect
T@"<PTRenderState>",&,N,V_renderState
T@"PTTexture",&,N,V_sourceColor
T@"<MTLTexture>",&,N,V_sourceDisparity
T@"PTTexture",&,N,V_destinationColor
Tf,N,V_aperture
Tf,N,V_focusDistance
Tf,N,V_alphaLowLight
Ti,N,V_AGC
Tf,N,V_highlightBoostFactor
Tf,N,V_highlightChromaFactor
TI,N,V_frameId
Tf,N,V_disparityMin
Tf,N,V_disparityMax
T{?=QQQQ},N,V_scissorRect
T@"NSDictionary",&,N,V_options
setTexRGBA:
setTexLuma:
setTexChroma:
createRGBA:
YCbCrColorDepth
YCbCrFullRange
_YCbCrFullRange
_YCbCrColorDepth
Tq,N,V_YCbCrColorDepth
TB,N,V_YCbCrFullRange
useSqrtForArea
setUseSqrtForArea:
_useSqrtForArea
TB,V_useSqrtForArea
setDisplacementFWD:
textureType
pixelFormat
newTextureViewWithPixelFormat:textureType:levels:slices:
initWithDevice:colorSize:lktPreset:
estimateDisplacementStream:index:doOpticalFlow:destRGBA:
estimateDisplacementFWD:sourceRGBA:destRGBA:
toTextureArray:
warp:inTexture:inDisplacement:outTextureWarped:
displacementFWD
_warpTexture
_lktflowgpuContext
_displacementFWD
_allocateDisplacementFWD
_inverseFlow
bytes
initWithData:
objectFromData:
sizeOfSerializedObjectWithOptions:
writeToData:withOptions:
initWithMajorVersion:minorVersion:
_majorVersion
_minorVersion
TI,R,N,V_majorVersion
TI,R,N,V_minorVersion
mutableBytes
initWithMinorVersion:
focusPullerAlpha
focusPullerMaxV
focusPullerResistance
_focusPullerAlpha
_focusPullerMaxV
_focusPullerResistance
Tf,N,V_focusPullerAlpha
Tf,N,V_focusPullerMaxV
Tf,N,V_focusPullerResistance
enumerateIndexesUsingBlock:
compare:
sortUsingSelector:
allNumbers
T@"NSArray",R
getBytes:length:
_initValidRectFromSensorWidth:height:
_nodesForNormalizedRect:
_blurExtendedNodes:options:
_connectedComponents:
_largestOfComponents:
_sensorPixelRectFromTileRect:
_validNormalizedRectFromSensorPixelRect:
_sensorPixelRectFromRegion:
_pixelRectFromNormalRect:
_tileRectFromSensorPixelRect:
_nodesFromTileRect:
_blurExtendedNodes:blurMin:blurMax:
indexGreaterThanIndex:
_getBlurRangeOfNodes:blurMin:blurMax:
indexSetWithIndex:
_connectedComponentWithNode:unvisited:
_tileRectFromNodes:
_normalRectFromPixelRect:
initWithFocusBlurMapDictionary:
_inputSensorPixelRect
focusValidNormalizedRect
inputX
inputY
inputWidth
inputHeight
tileWidth
tileHeight
tileCountX
tileCountY
tileXForTile:
tileYForTile:
_nodesBetweenBlurMin:blurMax:
_inFocusNodes
_boxFromComponent:
autoFocusRect
sensorWidth
sensorHeight
validX
validY
validWidth
validHeight
_map
_sensorWidth
_sensorHeight
_validX
_validY
_validWidth
_validHeight
_autoFocusRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_autoFocusRect
TQ,R,V_sensorWidth
TQ,R,V_sensorHeight
TQ,R,V_validX
TQ,R,V_validY
TQ,R,V_validWidth
TQ,R,V_validHeight
T@"NSIndexSet",R
T{CGRect={CGPoint=dd}{CGSize=dd}},R
setConstantValue:type:atIndex:
initWithObjects:
sobelEdgeDetection:inImage:outEdges:edgeTolerance:
computeUpsamplingCoefficients:guideTexture:imageTexture:coeffTexture:weights:guideMultiplier:
averageUpsamplingCoefficients:coeffTexture:coeffAveragedTexture:
applyUpsamplingCoefficients:guideTexture:coeffTexture:upsampledTexture:guideMultiplier:
edges
_computeWeightedUpsamplingCoefficients
_computeUpsamplingCoefficients
_averageUpsamplingCoefficients
_applyUpsamplingCoefficients
_coeffTexture
_edges
_coeffAveragedTexture
_upscaledTexture
_textureDropHints
_utils
_useWeightedSampling
_useHighresGuideForComputingCoefficients
_skipBoxFilter
_temporalFilterExponentialMovingAverageColorSimilarities
_inputRGB
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:effectQuality:
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:prewarmOnly:effectQuality:
newCommandQueue
setGPUPriority:
updateEffectDelegate:
keepOldDelegateAlive:
prewarmWithFormat:metalCommandQueue:effectType:
render:disparity:detectedObjects:transform:toColorBuffer:
unpactDetections:
initFilterDetections
filterDetections
disableAsynchronousWork
prewarmForMediaserverd
initWithFormat:metalCommandQueue:effectType:
setEffectType:
waitForAsyncInitialization
initWithFormat:metalCommandQueue:effectType:effectQuality:
render:detectedObjects:toColorBuffer:
render:detectedObjects:transform:toColorBuffer:
_metalCommandQueue
_asyncInitQueue
_effectTypeNew
_pixelTransferSession
_faceAttributesNetwork
_resources
_asyncInitialization
_prewarmOnly
_effectQuality
_effectQualityNew
_humanDetections
_lastFrameTime
_delegateLock
initWithCommandQueue:disparitySize:filteredDisparitySize:disparityPixelFormat:colorSize:colorPixelFormat:sensorPort:
disparitySize
filteredDisparitySize
disparityPixelFormat
colorSize
colorPixelFormat
sensorPort
_disparityPixelFormat
_colorPixelFormat
_sensorPort
_filteredDisparitySize
T@"<MTLCommandQueue>",R,&,V_commandQueue
T{?=QQQ},R,V_disparitySize
T{?=QQQ},R,V_filteredDisparitySize
TQ,R,V_disparityPixelFormat
T{?=QQQ},R,V_colorSize
TQ,R,V_colorPixelFormat
T@"NSString",R,V_sensorPort
prewarmWithDescriptor:
computeOpticalFlow:outDisplacement:
temporalDisparityFilter:inDisplacement:inDisparityFilteredPrev:outDisparityFiltered:disparityBias:
temporalDisparityFilter:inStatePrev:inDisparity:outDisparityFiltered:outState:
texRGBA
_texRGBA
T@"<MTLTexture>",&,V_texRGBA
texLuma
texChroma
_texLuma
_texChroma
T@"<MTLTexture>",&,V_texLuma
T@"<MTLTexture>",&,V_texChroma
_networkLabelForDetection:
writeOneHot:count:
labelOffset
labelZero
remap
_labelOffset
_labelZero
_remap
Tq,R,V_labelOffset
TQ,R,V_labelZero
T@"NSDictionary",R,V_remap
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
initWithDevice:filterDescriptor:
setTextureType:
allocatedTextures
multiplyTex:inTex:outTex:multiplier:
encodeRegressionToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationCoefficientsTextureArray:
encodeReconstructionToCommandBuffer:guidanceTexture:coefficientsTextureArray:destinationTextureArray:
initWithDevice:library:pipelineLibrary:colorSize:disparitySize:config:
guidedUpsampling:inDisparity:inRGBA:colorDepth:
_upscaleFactor
_disparityUpscaled
_width
_height
_portraitUtil
_guideConversionTexture
_coefficientsTextureArray
_dropHintsTextures
_isShaderHarvesting
setQuality:
setDoFirstLevelGaussianDownsample:
setUsePrecomputedGaussianNoise:
setUseExportQualityNoise:
setRenderDownscale:
setDoMacroApertureLimit:
setForegroundBlurLimitingFactor:
setNumberOfPatternCircles:
setRayMarch:
setDoFocusEdgeMask:
setRayMarchAll:
setDoIntermediate2XUpscale:
updateDescription
disableForegroundBlur
usePrecomputedGaussianNoise
_description
_rayMarchAll
_rayMarch
_disableForegroundBlur
_doCenterDisparity
_doFocusEdgeMask
_doFirstLevelGaussianDownsample
_usePrecomputedGaussianNoise
_doMacroApertureLimit
_doIntermediate2XUpscale
_useExportQualityNoise
_quality
_numberOfPatternCircles
_disparityUpsampleFactor
_disparityGuidedFilterEpsilon
_foregroundBlurLimitingFactor
_renderDownscale
_intermediatePixelFormat
Ti,V_quality
Ti,V_numberOfPatternCircles
TB,V_rayMarchAll
TB,V_rayMarch
Tf,V_disparityUpsampleFactor
Tf,V_disparityGuidedFilterEpsilon
TB,V_disableForegroundBlur
TB,V_doCenterDisparity
Tf,V_foregroundBlurLimitingFactor
TB,V_doFocusEdgeMask
TB,V_doFirstLevelGaussianDownsample
TB,V_usePrecomputedGaussianNoise
TB,V_doMacroApertureLimit
Tf,V_renderDownscale
TB,V_doIntermediate2XUpscale
TQ,V_intermediatePixelFormat
TB,V_useExportQualityNoise
renderThumbnails:defaults:renderRequest:
detectionsRaw
renderRect:rect:color:fill:outTexture:
detectionsFiltered
smoothFaceRects
renderDisparity:inDisparity:outLuma:outChroma:region:drawLegend:
addConstant:inTex:outTex:value:
renderDebugSubjectRelighting:humanDetections:renderRequest:transform:
initWithIOSurfaces:names:
tensorWithIndex:
tensorNameWithIndex:
_names
_tensorPair
stringWithUTF8String:
bindTensorSwaps:
bindBuffers:toMap:withMode:
registryID
getResourceWithName:fromMap:
unInterleaveTexture:input:output:
convertBindInput
executeAsync:
getEspressoMetalDeviceId:
initWithUrl:inputNames:outputNames:tensorSwapNames:device:library:pipelineLibrary:commandQueue:reshape:configuration:
texture2DArrayToTexture2D:
bindInputResourceWithName:to:
getInputResourceWithName:
getOutputResourceWithName:
execute
executeAsync
tensorSwap:
networkVersion
_ctx
_net
_inputsMap
_outputsMap
_inputConversion
_tensorSwap
_espressoCallbackQueue
_unInterleaveTexture
_url
_networkVersion
lastNetworkVersion
inPrevDisparity
highResNetwork
Tq,V_frameIndex
initWithType:providerClass:
type
setType:
providerClass
setProviderClass:
isAtomContainerType
setIsAtomContainerType:
isProviderArrayType
setIsProviderArrayType:
_isAtomContainerType
_isProviderArrayType
_type
_providerClass
TI,V_type
T#,&,V_providerClass
TB,V_isAtomContainerType
TB,V_isProviderArrayType
supportsVersion:
writeToAtomWriter:options:
registerForSerialization
objectFromAtomStream:
isValidObject:
classForType:
_errorFromAtomStream:
_errorNotSerializable
writeObject:toData:options:error:
_supportedOptions:forObject:
_errorUnsupportedVersion
_errorFromAtomWriter:
numberWithUnsignedInt:
infoForType:
registerTypeInfo:
_errorWithCode:
_errorFromAtomError:
code
sizeOfSerializedObject:options:
dataFromObject:options:error:
registerType:providerClass:
initWithData:minorVersion:
applyToRenderRequest:
setAgc:
_agc
TI,N,V_agc
_copyToDetectionData_0:
_initWithDetectionData_0:
_detectionsFromInnerAtomStream:
objectsFromAtomStream:
sizeOfSerializedArray:options:
writeArray:toAtomWriter:options:
_rotate:toDest:synchronous:
rotate:crop:rotationDegree:toDest:synchronous:
_downsample:toDest:useCustomFilter:centerAlignment:synchronous:
targetRGBA
_outputPixelbuffer
_outputIOSurface
_pyramidRGBA
_allocatedIOSurfaces
_runOptions
_csRGBLinear
_csSRGB
_colorUtil
_hasMSR
_rotateTargetPixelBuffer
initWithDevice:library:pipelineLibrary:commandQueue:effectUtil:util:sharedResources:
initWithDevice:library:pipelineLibrary:commandQueue:effectUtil:util:prewarmOnly:
contents
orientationFromTransform:
faceRectsForVision:numberOfFaceRects:transform:
faceLandmarksInPixelBuffer:faceRects:orientation:
outSkinMask
outPersonMask
runSRLForLivePhotosWithInputBuffer:lumaTexture:chromaTexture:skinMaskTexture:personMaskTexture:instanceMaskConfidences:skinToneClassification:validROI:expBias:faceExpRatio:exifOrientation:
srlV2CoeffsBuffer
updateSubjectRelighting:inLuma:inChroma:inFaceRects:runOnAsyncCommandQueue:focusFaceIndex:transform:
estimateLightIntensity:
initWithDevice:library:pipelineLibrary:commandQueue:faceAttributesNetwork:effectUtil:util:msrColorPyramid:colorSize:prewarmOnly:sharedResources:
estimateLightIntensityWithFaceRects:inLuma:inChroma:focusFaceIndex:numberOfFaceRects:transform:humanDetections:
interpolateLightIntensity:
debugTextures
lightEstimation
faceObservations
_lightEstimation
_mainCommandQueue
_asyncCommandQueue
_segmentationNetwork
_skinMaskRGBA
_subjectRelighting
_faceObservations
_subjectRelightingRunning
srlAsyncQueue
_rgbaPixelBufferCopy
_rgbaTextureCopy
_quarterSizeLumaCopy
_quarterSizeChromaCopy
_lightEstimationBuffer
initWithCount:
initWithFloats:count:
isEqualToFloatArray:tolerance:
maximumDifferenceWithFloatArray:
mutableFloats
dataWithBytes:length:
initWithFloatArray:
initWithZeros:
initWithFloat:repeatCount:
isEqualToFloatArray:
mean
argMinimum
addingConstant:
subtracting:
initWithArray:
asArray
asData
_buffer
_count
TQ,R,N,V_count
Tr^f,R,N
initWithZeros:capacity:
initWithFloat:repeatCount:capacity:
setFloat:atIndex:
setFloats:inRange:
addConstant:
_start
_capacity
T^f,R,N
parallelReduction:inTexture:globalBuffer:offset:pipelineState:reductionType:factor:
parallelReductionTextureMinMaxSimd:inTexture:globalBuffer:
parallelReductionTextureSimd:inTexture:globalBuffer:offset:reductionType:factor:
parallelReductionMax:inTexture:globalMaxBuffer:
parallelReductionMin:inTexture:globalMinBuffer:
_texPing
_texPong
_simdTextures
_simdMinMaxTextures
_parallelReductionTextureSimd
_parallelReductionTextureMinMaxSimd
_parallelReductionAverage
_parallelReductionMax
_parallelReductionMin
simdReductionThreadsPerGroup
simdReductionThreadGroups
_supportGpuSIMD
readPlist:
maskThreshold
minFaceSize
maxCurveBoost
minCurveBoost
maxTargetRatioDarkening
maxTargetRatioLimit
biasFactorSRLv2
toneSimilaritySigma
faceExpDifThreshold
relightOnlyPersonMask
targetMedian_I
targetMedian_II
targetMedian_III
targetMedian_IV
targetMedian_V
targetMedian_VI
maxBoost_I
maxBoost_II
maxBoost_III
maxBoost_IV
maxBoost_V
maxBoost_VI
valueForKey:
pathForResource:ofType:inDirectory:
fileURLWithPath:
dictionaryWithContentsOfURL:error:
replaceRegion:mipmapLevel:withBytes:bytesPerRow:
faceAttributes
boundingBox
facemaskCategory
label
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
allLabelsWithConfidences
confidence
maxTotalThreadsPerThreadgroup
dispatchThreadgroups:threadsPerThreadgroup:
_srlV2GlobalHistogramLivePhotos
_srlV2FaceHistogramLivePhotos
_srlV2CalcCoefficientsLivePhotos
_srlV2GlobalStatsBuffer
_srlV2FaceStatsBuffer
_srlV2CoeffsBuffer
_srlV2Plist
_plistSRL
_black
initWithDetections:detectorDidRun:presentationTime:
_detectionsByTrackIdentifier
_detectionsByFocusIdentifier
allKeys
allTrackIdentifiers
_detectionsByTrackIdentifierFromArray:
_detectionsByFocusIdentifierFromArray:
didCacheAutoFocusDetection
setCachedAutoFocusDetection:
setDidCacheAutoFocusDetection:
cachedAutoFocusDetection
didCacheCustomDetection
isCustomDetection
setCachedCustomDetection:
setDidCacheCustomDetection:
cachedCustomDetection
flushCachedDetectionsDictionaries
detectionForFocusIdentifier:
allFocusIdentifiers
setPresentationTime:
cachedDetectionsByFocusIdentifier
cachedDetectionsByTrackIdentifier
_didCacheAutoFocusDetection
_didCacheCustomDetection
_detectorDidRun
_cachedDetectionsByFocusIdentifier
_cachedDetectionsByTrackIdentifier
_cachedAutoFocusDetection
_cachedCustomDetection
_baseFocusTrackNumberOverride
_presentationTime
T@"NSDictionary",R,V_cachedDetectionsByFocusIdentifier
T@"NSDictionary",R,V_cachedDetectionsByTrackIdentifier
TB,V_didCacheAutoFocusDetection
T@"PTCinematographyDetection",&,V_cachedAutoFocusDetection
TB,V_didCacheCustomDetection
T@"PTCinematographyDetection",&,V_cachedCustomDetection
T@"NSNumber",&,V_baseFocusTrackNumberOverride
T@"NSArray",R,V_detections
T@"NSNumber",R,V_detectorDidRun
T{?=qiIq},V_presentationTime
T@"PTCinematographyDetection",R
setEnabled:device:
focalLength
renderingVersion
classForVersion:
colorOutputSize
debugRendering
verbose
gpuProfiling
prepareForRendering:
adjustScissorRect:
colorInputSize
prepareForRendering
focalLenIn35mmFilm
setFocalLenIn35mmFilm:
conversionGain
setConversionGain:
readNoise_1x
setReadNoise_1x:
readNoise_8x
setReadNoise_8x:
noiseScaleFactor
setNoiseScaleFactor:
rawSensorHeight
setRawSensorHeight:
rawSensorWidth
setRawSensorWidth:
visCropFactor
setVisCropFactor:
sensorID
setSensorID:
totalSensorCrop
setTotalSensorCrop:
setRenderingVersion:
networkBias
setNetworkBias:
hwModelID
setHwModelID:
Ti,R
Tf,N
Ti,N
T{CGRect={CGPoint=dd}{CGSize=dd}},N
TQ,N
initWithPipelineDescriptor:quality:
_desc
_renderIntegration
_colorOutputSizeCropped
_renderingVersion
Ti,R,Vquality
Tf,N,VfocalLenIn35mmFilm
Ti,N,VconversionGain
Ti,N,VreadNoise_1x
Ti,N,VreadNoise_8x
Tf,N,VnoiseScaleFactor
Ti,N,VrawSensorHeight
Ti,N,VrawSensorWidth
T,N,VvisCropFactor
Ti,N,VsensorID
T{CGRect={CGPoint=dd}{CGSize=dd}},N,VtotalSensorCrop
Ti,N,VsourceColorBitDepth
Tf,N,VnetworkBias
Ti,N,VhwModelID
T@"NSString",R,C,Vdescription
deleteCharactersInRange:
precomputeNoise:seed:device:
gaussianNoise:inNoise:outTex:
initWithDevice:library:pipelineLibrary:util:quality:colorSize:disparitySize:pyramidPixelFormat:config:debugTextures:
dependentFrames
randomUChars
setRandomUChars:
randomGaussNoise
setRandomGaussNoise:
focusEdgeMask
setFocusEdgeMask:
doVisualization
setDoVisualization:
setColorSize:
coverageOverscan
setCoverageOverscan:
edgeTolerance
setEdgeTolerance:
rayCount
setRayCount:
raytracingSDOF
setRaytracingSDOF:
aperturePointsXY
setAperturePointsXY:
raytracedRGBRadius
setRaytracedRGBRadius:
raytracedRGBRadiusUpscaled
setRaytracedRGBRadiusUpscaled:
disparityEdges
setDisparityEdges:
disparityEdgesTemp
setDisparityEdgesTemp:
disparityUpscale
setDisparityUpscale:
globalReduction
setGlobalReduction:
disparityDiffGlobalMinMax
setDisparityDiffGlobalMinMax:
anamorphicFactor
setAnamorphicFactor:
raytracingRadiusLocal
setRaytracingRadiusLocal:
qualitySettings
setQualitySettings:
disparityDiff
setDisparityDiff:
disparityDiffDropHints
setDisparityDiffDropHints:
dropHintsRaytracing
setDropHintsRaytracing:
dropHintsRGBRadiusUpscaled
setDropHintsRGBRadiusUpscaled:
_disparityUpscale
_disparityDiffGlobalMax
_randomizedGauss
_rayCount
_raytracingRadiusLocal
_randomGaussNoise
_raytracedRGBRadius
_raytracedRGBRadiusUpscaled
_dropHintsRGBRadiusUpscaled
Ti,V_rayCount
T@"<MTLComputePipelineState>",&,N,V_raytracingSDOF
T@"<MTLBuffer>",&,N,V_randomUChars
T@"<MTLBuffer>",&,N,V_aperturePointsXY
T@"<MTLTexture>",&,N,V_randomGaussNoise
T@"<MTLTexture>",&,N,V_focusEdgeMask
T@"<MTLTexture>",&,N,V_raytracedRGBRadius
T@"<MTLTexture>",&,N,V_raytracedRGBRadiusUpscaled
T@"<MTLTexture>",&,N,V_disparityEdges
T@"<MTLTexture>",&,N,V_disparityEdgesTemp
T@"PTDisparityUpscale",&,N,V_disparityUpscale
T@"PTGlobalReduction",&,N,V_globalReduction
T@"<MTLBuffer>",&,N,V_disparityDiffGlobalMinMax
TB,V_doVisualization
T,V_kColorSize
Tf,V_kCoverageOverscan
Tf,V_anamorphicFactor
Tf,V_raytracingRadiusLocal
Tf,V_edgeTolerance
T@"PTQualitySettings",&,N,V_qualitySettings
T@"<MTLTexture>",&,N,V_disparityDiff
T@"PTMTLDropHints",&,N,V_disparityDiffDropHints
T@"PTMTLDropHints",&,N,V_dropHintsRaytracing
T@"PTMTLDropHints",&,N,V_dropHintsRGBRadiusUpscaled
createFocusObject:coverageOverscan:anamorphicFactor:raytracingRadiusLocal:rayCount:colorSize:doMacroApertureLimit:
convertRGBLinearFromPTTexture:inPTTexture:outRGBA:
convertRGBPyramidFromSource:renderRequest:rgbaPyramidArray:skipLevel0:
centerDisparityOnFocus:inDisparity:outDisparity:focusObject:
findMipmapLevel:largerThan:fromLevel:
interpolateRGBRadiusToDest:renderRequest:inRGBA:inRGBRadius:inRandomGauss:bicubicSampling:
interpolateRGBRadiusUsingSourceToDest:renderRequest:inRGBRadius:inRandomGauss:bicubicSampling:
_bicubicUpscale
focusFramesOptions
setFocusFramesOptions:
globalMetadata
setGlobalMetadata:
disableDetectionSmoothing
setDisableDetectionSmoothing:
rackFocusPullTime
setRackFocusPullTime:
_globalMetadata
_disableDetectionSmoothing
_focusFramesOptions
T@"PTCinematographyFocusFramesOptions",&,V_focusFramesOptions
T@"PTGlobalCinematographyMetadata",C,N
TB,N,V_disableDetectionSmoothing
T{?=qiIq},N
refinedFrameNumber
numberWithLong:
setRefinedFrameNumber:
_needSnapshotForPolicy:
_snapshot
_updateRecordingStateForSnapshot:
_frameNumber
addFrame:
_moveAlongSmoothedFrames
setRecordingState:
_endSmoothedFrames
stopRecording
_performRackFocusPullsStartingAtIndex:
_extractFramesReturningAll:
globals
isNextFrameAvailable
endFrames
isNextFrameAtEnd
focusTrackIdentifier
_performRackFocusPullToFrameAtIndex:
_logRackFocusPullToFrameAtIndex:fromIndex:label:
_performLinearRackFocusPullToFrameAtIndex:fromIndex:
longValue
setTransitionCoefficient:
setTransitionElapsedTime:
setTransitionDuration:
_framesIndexForTime:
_extractFramesToIndex:
removeObjectsInRange:
recordingState
_updateGlobalsWithSnapshot:
addEntriesFromDictionary:
addFrames:
startRecording
endOfFrames
refinedFrames
globalCinematographyDictionary
timeDelayForRefinement
setGlobals:
smoother
setSmoother:
firstIndexToLookForTransitions
setFirstIndexToLookForTransitions:
shouldReturnAllCachedFrames
setShouldReturnAllCachedFrames:
_shouldReturnAllCachedFrames
_globals
_smoother
_refinedFrameNumber
_firstIndexToLookForTransitions
_recordingState
_timeDelayForRefinement
T@"PTCinematographyRefinementOptions",C,N,V_options
T@"NSMutableDictionary",&,N,V_globals
T@"PTCinematographyFrameDetectionSmoother",&,N,V_smoother
T@"NSMutableArray",&,N,V_frames
T@"NSNumber",&,N,V_refinedFrameNumber
TQ,N,V_firstIndexToLookForTransitions
TQ,N,V_recordingState
TB,N,V_shouldReturnAllCachedFrames
T{?=qiIq},R,N,V_timeDelayForRefinement
getObjects:range:
setResourceGroups:count:
dropResourceGroups:count:
_addResourceGroup:toCommandBuffer:
_dropResourceGroup:fromCommandBuffer:
_activeGroups
newResourceGroupFromResources:count:
enabled
setEnabled:
_resourceGroup
_name
_enabled
TB,V_enabled
initWithFocusBlurMap:region:
scanlineIter
placement
setPlacement:
_placement
T{CGRect={CGPoint=dd}{CGSize=dd}},V_placement
initWithMask:
_recalculatePlacementTileSize
pixelRangeForTileRangeX:
pixelRangeForTileRangeY:
region
normalizedTileSize
setNormalizedTileSize:
placementTileSize
setPlacementTileSize:
_region
_normalizedTileSize
_placementTileSize
T{CGSize=dd},V_normalizedTileSize
T{CGSize=dd},V_placementTileSize
T@"PTFocusBlurMap",R,V_map
T@"NSIndexSet",R,V_region
_advanceToNextTileRow
_advanceToNextTile
resetX
nextRangeY
nextRangeX
mask
currentTileRow
setCurrentTileRow:
currentTile
setCurrentTile:
_mask
_currentTileRow
_currentTile
TQ,V_currentTileRow
TQ,V_currentTile
T@"PTScanlineMask_FocusBlurMap",R,V_mask
calculateVarReadNoise:
colorMatrixAndBiasFor:toRGB:fullRange:colorYCbCrDepth:
frameWidth
dataWithLength:
sNBE
sNLE
_interpolateRGBRadiusToDestYUV
_interpolateRGBRadiusToDestRGBA
_interpolateRGBRadiusToDestYUVFromSource
_interpolateRGBRadiusToDestRGBAFromSource
_convertRGBPyramid
_convertRGBPyramidFromYUV
_centerDisparityOnFocus
_sobelEdgeDetector
_edgeDilation
_sNBE
_sNLE
initWithDevice:library:
renderDebugLayer:renderRequest:inDisparity:disparityOffset:focusObject:quality:edgeTolerance:debugTextures:debugRendering:
renderTurbo:inTex:outRGBA:valueOffset:valueMinMax:valueAbs:colorRangeMax:channelMultiplier:region:
renderTurboMix:inTex:inRGBA:outRGBA:valueOffset:valueMinMax:valueAbs:colorRangeMax:channelMultiplier:mixFraction:region:
getBiasedDisparityVisualizationRange:
dumpDebug:renderRequest:debugTextures:
setConfidence:
initWithRect:confidence:
_confidence
_rect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_rect
Tf,V_confidence
isSupported
trackerWithCommandQueue:
resetTrack
predictRectForPoint:inColorBuffer:
startTrackingRect:colorBuffer:
addDetectionAtTime:rect:disparityBuffer:
stepTrackingWithFrame:
getRectForPoint:colorBuffer:
addDetectionAndStartTrackingRect:time:colorBuffer:disparityBuffer:
addDetectionForNextFrameAt:colorBuffer:disparityBuffer:
finalizeTrack
_tmpCurrentRect
_tracker
T@"NSMutableArray",&,N,V_detections
normalizedPoints
pointCount
observationWithBoundingBox:
rotateTexture:inTex:outTex:rotationDegrees:
copySingleChannel:inTex:outTex:
clear:outTex:
copyRGBAToBGRA:inTex:outTex:
orientationForTransform:size:
getBoundingBox:
_updateFocusObject
_effectSampleFaceRects
_convertToDisparity
_fixedFocusDistanceAndCenterDisparity
_copySingleChannel
_copyRGBAToBGRA
_clear
_isMissingDetection
T{?=qiIq},R,V_time
T@"PTCinematographyDetection",R,V_detection
TB,R,V_isMissingDetection
remainingCount
writeFloats:count:
T^f,R,V_fp
TQ,R,V_count
TQ,V_index
subclassForName:
networkSignalWithModelDictionary:
T@"NSString",R,V_name
localizedStringForKey:value:table:
initWithSuiteName:
dictionaryRepresentation
_updateDetectionTimes
focusTrackNumber
transitionCoefficient
allValues
initFocusedOnDetection:
isUserFocusGroup
transitionElapsedTime
transitionDuration
_detectionTrackNumberSet
focusGroupIdentifier
isInTransition
primaryFocusDetection
focusBlend
detectionForTrack:
detectionAtPoint:
rawFocusDistance
isUserFocusEnd
setFocusBlend:
_userFocusStrong
_userFocusGroup
_userFocusEnd
_rawFocusDistance
_transitionCoefficient
_transitionElapsedTime
_transitionDuration
_focusDetection
_allDetections
_focusTrackNumber
_baseFocusTrackNumber
_userFocusTrackNumber
_focusBlend
Tf,N,V_rawFocusDistance
T@"PTCinematographyDetection",&,N,V_focusDetection
T@"NSArray",&,N,V_allDetections
T@"NSNumber",&,N,V_focusTrackNumber
T@"NSNumber",&,N,V_baseFocusTrackNumber
T@"NSNumber",&,N,V_userFocusTrackNumber
userFocusStrong
TB,N,GisUserFocusStrong,V_userFocusStrong
userFocusGroup
TB,N,GisUserFocusGroup,V_userFocusGroup
userFocusEnd
TB,N,GisUserFocusEnd,V_userFocusEnd
T@"NSNumber",&,N,S_setDetectorDidRun:,V_detectorDidRun
Tf,N,V_transitionCoefficient
Tf,N,V_transitionElapsedTime
Tf,N,V_transitionDuration
T@"NSNumber",&,N,S_setFrameNumber:,V_frameNumber
T@,&,N,S_setSnapshot:,V_snapshot
T@"NSDictionary",R,N,V_cachedDetectionsByFocusIdentifier
T@"NSDictionary",R,N,V_cachedDetectionsByTrackIdentifier
T@"PTCinematographyFocusBlend",&,N,V_focusBlend
Tq,R,N
_flushCachedDetectionsDictionaries
_removeDetection:
_focusDetectionFromCoefficientsDictionary:coefficient:
_restoreOriginal
_debugLogFrame:label:
callStackSymbols
focusOnNothing
focusOnDetection:focusPuller:
_addDetection:
_removeDetectionWithTrackIdentifier:
_initWithCinematographyDictionary:time:
focusOnDetection:
_focusFromDetection:toDetection:rawFocusDistance:focusDistance:transitionCoefficient:elapsedTime:duration:
_framesWithCinematographyDictionaries:
T@"PTCinematographyDetection",&,N
T@"NSArray",&,N
T@"NSSet",R,N
T@"NSNumber",&,N
TB,N,GisUserFocusStrong
TB,N,GisUserFocusGroup
TB,N,GisUserFocusEnd
T@"NSNumber",&,N,S_setDetectorDidRun:
T@"NSNumber",&,N,S_setFrameNumber:
TQ,N,S_setSnapshotPolicy:
T@,&,N,S_setSnapshot:
createRequest
prepareForPerformingRequests:error:
initWithSession:
setRevision:error:
defaultANEDevice
setProcessingDevice:
setInputFaceObservations:
performRequests:onCVPixelBuffer:orientation:error:
results
_handler
_session
_writeHeaderToAtomWriter:options:
_copyToFrameHeaderData_0:
_frameFromInnerAtomStream:
_frameHeaderFromAtomStream:
_initWithFrameHeaderData_0:
T@"NSDictionary",R,V_params
inputStreamWithURL:
open
JSONObjectWithStream:options:error:
_defaultSupportedDetectionTypes
_processInputSchemaDicts:
setExpectedFPS:
setForgetDetectionsAfterSeconds:
setRunOnlyWhenDetectorDidRun:
setSupportedDetectionTypes:
setInputSchemas:
totalInputFloatCount
_runOnlyWhenDetectorDidRun
_expectedFPS
_forgetDetectionsAfterSeconds
_supportedDetectionTypes
_inputSchemas
_totalInputFloatCount
Tf,V_expectedFPS
Tf,V_forgetDetectionsAfterSeconds
TB,V_runOnlyWhenDetectorDidRun
T@"NSSet",&,V_supportedDetectionTypes
T@"NSArray",&,V_inputSchemas
TQ,R,V_totalInputFloatCount
_indexNearestTime:timeSelector:
_indexAtOrBeforeTime:timeSelector:
_firstIndexAtOrAfterTime:timeSelector:
_indexRangeOfTimeRange:timeSelector:
_timeRangeOfIndexRange:timeSelector:
_firstIndexAtOrAfterTime:startIndex:lastIfEqual:timeSelector:
_timeForObject:timeSelector:
_firstIndexAfterTime:startIndex:timeSelector:
CMTimeValue
methodForSelector:
valueWithCMTime:
indexOfObject:inSortedRange:options:usingComparator:
_indexAtOrBeforeTime:
_timeRangeOfIndexRange:
_temporalFilterExponentialMovingAverageLKT
updateColorCube
initRelightingParam
init:cubeSize:data:
cubeTexture
updateParamters
computeSmoothFaceRect:transform:
gaussianFilter3x3:inRGB:outRGB:
filterLightGainApplyToRGB:inRGB:outRGB:filterLightGainMapLowres:
commaSeparatedString:toFloatArray:maxCount:
fgBgForDebug:inDisparity:inNormal:inFocusObject:outMask:debugType:
lightMaskDebug:msrColorPyramid:outFaceMask:
syntheticLight
_studioLight
_createLightMask
_fgBgForDebug
_lightMaskForDebug
_relightFullsizeInput
_studioLightDebug
_lightMaskOutline
_filterLightGainApplyToRGB
_syntheticLight
_parameters
_smoothFaceRects
_weightHeadEye
_eyeRadiusFactor
_lightMasks
_lightGainMapScale
_lightGainMapLowRes
_lightGainMapLowResFiltered
_lightGainMapFiltered
_colorCube
_quarterSizeRGBA
_relightSizeRGBA
_colorCubeType
_addZeroDisparityTrack
progressWithTotalUnitCount:
initWithCapacity:
isCancelled
setLoadedUserAperture:
setCompletedUnitCount:
_internalizeLoadedFrames:changesDictionary:reloading:
loadWithAsset:changesDictionary:completion:
changesDelegate
setChangesDelegate:
removeAllUserDecisions
_removeAllUserTracksForReloading
loadedUserAperture
_notifyDelegateOfChangesToDecisionsInTimeRange:
_notifyDelegateOfChangesToFramesInTimeRange:
_internalizeUserApertureFromChangesDictionary:
_internalizeFocusPullerFromFrames:
_reloadTrackAllocator
_internalizeTracksFromFrames:
_internalizeTracksFromChangesDictionary:
_internalizeBaseDecisionsFromFrames:
_internalizeUserDecisionsFromChangesDictionary:
_internalizeUserDecisionsFromFrames:
_updateEffectiveDecisionsInTimeRange:
effectiveDecisions
_updateFramesForDecisions:timeRange:
_mutableDecisionsWithCinematographyDictionaries:
setMaximumDuration:
_userDecisionToFocusOnDetection:time:strong:group:
defaultMinimumUserFocusDuration
setMinimumDuration:
setUserDecisions:
frameNearestTime:
_latestDetectionOfTrackIdentifier:atOrBeforeFrameIndex:timeLimit:
_latestDetectionOfGroupIdentifier:atOrBeforeFrameIndex:timeLimit:
_updateFramesForDecisions:indexRange:
_updateFramesForTransitionFromDecision:toDecision:
_updateFramesFromDecision:toDecision:
_updateFramesForFinalDecision:
_updateFramesForDecision:upToTime:
_timeRangeOfTransitionfromDecision:toDecision:didShortenTransition:
_updateFramesForTransitionFromDecision:toDecision:timeRange:
_updateFramesInTimeRange:toFocusOnTrackIdentifier:
_timeRangeOfTransitionfromDecision:toDecision:
transition
_updateFramesInTimeRange:forTransition:fromDetection:toDetection:
_updateFramesInIndexRange:toFocusOnTrackIdentifier:
_updateFramesInIndexRange:forTransition:fromDetection:toDetection:overTimeRange:
focusPuller
_updateFramesInIndexRange:forTransition:fromDetection:toDetection:
_updateFramesInIndexRange:toFocusOnDetection:
isGroupDecision
_addDecision:toTrackDecisions:
_addGroupDecision:toTrackDecisions:nextDecision:
_existingGroupTrackForGroupIdentifier:
_decisionByRemovingOptions:
_addDecisions:toTrackDecisions:
_shouldAddTrackDecision:afterDecision:
addObjectsFromArray:
trackForGroupIdentifier:
decisionAtOrBeforeTime:
decisionAfterTime:
timeRangeOfTransitionBeforeDecision:
decisionBeforeTime:
_useFixedTransition
_startTimeOfFixedTransitionToDecision:
userDecisions
baseDecisions
initWithTime:trackIdentifier:
setBaseDecisions:
mutableTracks
trackForIdentifier:
_internalizeTrackForDetection:
_internalizeGroupTrackForDetection:
_addTrack:identifier:
_internalizeDetectionsFromTrack:
_addDetectionsFromCustomTrack:
_addDetectionsFromFixedFocusTrack:
_internalizeTrackNumberForFocusIdentifier:
setTrackNumber:
_internalizeTrackWithNumberFromDetection:
_internalizeTrackWithGroupNumberFromDetection:
_addGroupTrack:
trackAllocatorForFocusIdentifier
setFramesAreMutable:
setBaseDecisionsAreMutable:
addUserDecision:
initWithTime:groupIdentifier:options:
focusOnTrackIdentifier:atTime:strong:
_resolveIfGroupDecision:
_removeUserDecision:
insertObject:atIndex:
_updateDecisionsAndFramesInTimeRange:
removeAllObjects
isUserDecision
_bestDetectionForGroupIdentifier:time:
_effectiveDecisionsFromBaseDecisionsRange:userDecisionsRange:endTime:
replaceObjectsInRange:withObjectsFromArray:
_invalidateTrackDecisions
_zipBaseDecisionsRange:userDecisionsRange:
_effectiveDecisionsFromZippedDecisions:endTime:
_decisionByChangingTime:
trackForDecision:
hasMinimumDuration
minimumDuration
hasMaximumDuration
maximumDuration
isStrongDecision
_removeDetectionsWithTrackIdentifier:
_removeTrack:
_isEditCreatedTrack:
removeTrack:
mutableGroupTracks
frameAtTime:tolerance:
decisionsDidChangeInScript:timeRange:
framesDidChangeInScript:timeRange:
_userDecisionDictionaries
_userTrackDictionaries
_userDecisionDictionariesTrimmedByTimeRange:
_userTrackDictionariesTrimmedByTimeRange:
primaryDecisionAtTime:
_loadWithAsset:changesDictionary:error:
reloadWithChangesDictionary:
_trackDecisionsInTimeRange:
decisionNearestTime:
decisionsInTimeRange:
secondaryDecisionAtTime:
timeRangeOfTransitionAfterDecision:
userDecisionsInTimeRange:
baseDecisionsInTimeRange:
_trackAllocatorState
_userCreatedTracks
addBaseDecision:
focusOnGroupIdentifier:atTime:strong:
focusOnDetection:strong:
focusOnTrack:atTime:strong:
removeUserDecision:
addTrack:
changesDictionary
changesDictionaryTrimmedByTimeRange:
setAsset:
setEffectiveDecisions:
setTrackDecisions:
setMutableTracks:
trackForNumber
setTrackForNumber:
zeroDisparityTrack
setZeroDisparityTrack:
setMutableGroupTracks:
trackForGroupNumber
setTrackForGroupNumber:
trackNumberForFocusIdentifier
setTrackNumberForFocusIdentifier:
setTrackAllocatorForFocusIdentifier:
didInternalizeTracks
setDidInternalizeTracks:
setFocusPuller:
loadedTrackAllocatorState
setLoadedTrackAllocatorState:
_framesAreMutable
_baseDecisionsAreMutable
_serialQueue
_didInternalizeTracks
_loadedUserAperture
_changesDelegate
_baseDecisions
_userDecisions
_effectiveDecisions
_mutableTracks
_trackForNumber
_zeroDisparityTrack
_mutableGroupTracks
_trackForGroupNumber
_trackNumberForFocusIdentifier
_trackAllocatorForFocusIdentifier
_focusPuller
_loadedTrackAllocatorState
T@"AVAsset",&,N,V_asset
T@"PTGlobalCinematographyMetadata",&,N,V_globals
T@"PTCinematographyFocusFramesOptions",&,N,V_focusFramesOptions
T@"NSArray",&,N,V_baseDecisions
T@"NSMutableArray",&,N,V_userDecisions
T@"NSMutableArray",&,N,V_effectiveDecisions
T@"NSArray",&,N,V_trackDecisions
T@"NSMutableArray",&,N,V_mutableTracks
T@"NSMutableDictionary",&,N,V_trackForNumber
T@"PTCinematographyTrack",&,N,V_zeroDisparityTrack
T@"NSMutableArray",&,N,V_mutableGroupTracks
T@"NSMutableDictionary",&,N,V_trackForGroupNumber
T@"NSMutableDictionary",&,N,V_trackNumberForFocusIdentifier
T@"PTCinematographyTrackAllocator",&,N,V_trackAllocatorForFocusIdentifier
TB,N,V_didInternalizeTracks
T@"PTCinematographyFocusPuller",&,N,V_focusPuller
Tf,N,V_loadedUserAperture
Tq,N,V_loadedTrackAllocatorState
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
T@"<PTCinematographyScriptChanges>",W,N,V_changesDelegate
_prefixForDetectionType:
cachedFocusIdentifierWasSetByClient
setCachedFocusIdentifierWasSetByClient:
cachedFocusIdentifier
setCachedFocusIdentifier:
_clearCachedFocusIdentifier
accessibilityLabelForDetectionType:
accessibilityLabel
setFocusIdentifier:
_cachedFocusIdentifierWasSetByClient
__excludedAsCinematicChoice
_trackNumber
_cachedFocusIdentifier
__namedSignals
T@"NSNumber",&,N,V_trackNumber
T@"NSString",&,N,V_cachedFocusIdentifier
TB,N,V_cachedFocusIdentifierWasSetByClient
_excludedAsCinematicChoice
TB,N,G_isExcludedAsCinematicChoice,S_setExcludedAsCinematicChoice:,V__excludedAsCinematicChoice
T@"NSDictionary",&,N,V__namedSignals
TQ,N,V_detectionType
Tq,N
Tq,N,V_groupIdentifier
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_rect
T@"NSString",R,N
dictionaryWithCapacity:
_fixMissingTrackIdentifier:
unsignedLongValue
_isEqual:
_detectionTypeForPrefix:
_invalid
TB,N,G_isInvalid,S_setInvalid:
TB,N,G_isExcludedAsCinematicChoice,S_setExcludedAsCinematicChoice:
T@"NSDictionary",&,N
setDepth:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
load3DTextureFromData:cubeSize:metal:outTexture:
_defaultCubeTexture
_detectionsRaw
_detectionsFiltered
Ti,R,V_count
T^{PTHumanDetection=if[2B][2]f},R
selector
invokeWithTarget:
getReturnValue:
forwardInvocation:
methodSignatureForSelector:
newCommandQueueWithMaxCommandBufferCount:
heapTextureSizeAndAlignWithDescriptor:
heapBufferSizeAndAlignWithLength:options:
newHeapWithDescriptor:
newBufferWithBytesNoCopy:length:options:deallocator:
newDepthStencilStateWithDescriptor:
newDefaultLibrary
newDefaultLibraryWithBundle:error:
newLibraryWithFile:error:
newLibraryWithURL:error:
newLibraryWithData:error:
newLibraryWithSource:options:error:
newLibraryWithSource:options:completionHandler:
newLibraryWithStitchedDescriptor:error:
newLibraryWithStitchedDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:error:
newRenderPipelineStateWithDescriptor:options:reflection:error:
newRenderPipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:options:completionHandler:
newComputePipelineStateWithFunction:error:
newComputePipelineStateWithFunction:options:reflection:error:
newComputePipelineStateWithFunction:completionHandler:
newComputePipelineStateWithFunction:options:completionHandler:
newComputePipelineStateWithDescriptor:options:reflection:error:
newComputePipelineStateWithDescriptor:options:completionHandler:
newFence
supportsFeatureSet:
supportsTextureSampleCount:
minimumLinearTextureAlignmentForPixelFormat:
minimumTextureBufferAlignmentForPixelFormat:
newRenderPipelineStateWithTileDescriptor:options:reflection:error:
newRenderPipelineStateWithTileDescriptor:options:completionHandler:
newRenderPipelineStateWithMeshDescriptor:options:reflection:error:
newRenderPipelineStateWithMeshDescriptor:options:completionHandler:
getDefaultSamplePositions:count:
newArgumentEncoderWithArguments:
supportsRasterizationRateMapWithLayerCount:
newRasterizationRateMapWithDescriptor:
newIndirectCommandBufferWithDescriptor:maxCommandCount:options:
newEvent
newSharedEvent
newSharedEventWithHandle:
newIOHandleWithURL:error:
newIOCommandQueueWithDescriptor:error:
newIOHandleWithURL:compressionMethod:error:
sparseTileSizeWithTextureType:pixelFormat:sampleCount:
sparseTileSizeInBytesForSparsePageSize:
sparseTileSizeWithTextureType:pixelFormat:sampleCount:sparsePageSize:
newCounterSampleBufferWithDescriptor:error:
sampleTimestamps:gpuTimestamp:
newArgumentEncoderWithBufferBinding:
supportsCounterSampling:
supportsVertexAmplificationCount:
newDynamicLibrary:error:
newDynamicLibraryWithURL:error:
newBinaryArchiveWithDescriptor:error:
accelerationStructureSizesWithDescriptor:
newAccelerationStructureWithSize:
newAccelerationStructureWithDescriptor:
heapAccelerationStructureSizeAndAlignWithSize:
heapAccelerationStructureSizeAndAlignWithDescriptor:
maxThreadsPerThreadgroup
isLowPower
isHeadless
isRemovable
hasUnifiedMemory
recommendedMaxWorkingSetSize
isDepth24Stencil8PixelFormatSupported
readWriteTextureSupport
argumentBuffersSupport
areRasterOrderGroupsSupported
supports32BitFloatFiltering
supports32BitMSAA
supportsQueryTextureLOD
supportsBCTextureCompression
supportsPullModelInterpolation
areBarycentricCoordsSupported
supportsShaderBarycentricCoordinates
currentAllocatedSize
maxThreadgroupMemoryLength
maxArgumentBufferSamplerCount
areProgrammableSamplePositionsSupported
sparseTileSizeInBytes
maxBufferLength
counterSets
supportsDynamicLibraries
supportsRenderDynamicLibraries
supportsRaytracing
supportsFunctionPointers
supportsFunctionPointersFromRender
supportsRaytracingFromRender
supportsPrimitiveMotionBlur
convertSparsePixelRegions:toTileRegions:withTileSize:alignmentMode:numRegions:
convertSparseTileRegions:toPixelRegions:withTileSize:numRegions:
T{?=QQQ},R
lowPower
TB,R,GisLowPower
headless
TB,R,GisHeadless
removable
TB,R,GisRemovable
depth24Stencil8PixelFormatSupported
TB,R,GisDepth24Stencil8PixelFormatSupported
rasterOrderGroupsSupported
TB,R,GareRasterOrderGroupsSupported
barycentricCoordsSupported
TB,R,GareBarycentricCoordsSupported
programmableSamplePositionsSupported
TB,R,GareProgrammableSamplePositionsSupported
reportLeaks
allowLibrariesFromOtherPlatforms
vendorName
familyName
productName
getMostCompatibleArchitecture:
compilerPropagatesThreadPriority:
_setDeviceWrapper:
_deviceWrapper
deviceSupportsFeatureSet:
deviceOrFeatureProfileSupportsFeatureSet:
minLinearTextureAlignmentForPixelFormat:
newBufferWithIOSurface:
unloadShaderCaches
libraryCacheStats
pipelineCacheStats
copyShaderCacheToPath:
supportsSampleCount:
newCommandQueueWithDescriptor:
newIndirectArgumentBufferLayoutWithStructType:
newArgumentEncoderWithLayout:
supportsTextureWriteRoundingMode:
newIndirectCommandBufferWithDescriptor:maxCount:options:
newIndirectRenderCommandEncoderWithBuffer:
newIndirectComputeCommandEncoderWithBuffer:
newSharedEventWithMachPort:
setResourcesPurgeableState:newState:oldState:count:
newAccelerationStructureWithSize:resourceIndex:
isCompatibleWithAccelerationStructure:
newAccelerationStructureWithBuffer:offset:
newAccelerationStructureWithBuffer:offset:resourceIndex:
deserializePrimitiveAccelerationStructureFromBytes:withDescriptor:
deserializeInstanceAccelerationStructureFromBytes:primitiveAccelerationStructures:withDescriptor:
newAccelerationStructureWithSize:withDescriptor:
deserializePrimitiveAccelerationStructure:fromBytes:withDescriptor:
deserializeInstanceAccelerationStructure:fromBytes:primitiveAccelerationStructures:withDescriptor:
newDynamicLibrary:computeDescriptor:error:
validateDynamicLibraryDescriptor:error:
newDynamicLibraryWithDescriptor:error:
newDynamicLibraryWithURL:options:error:
newDynamicLibraryFromURL:error:
loadDynamicLibrariesForComputeDescriptor:error:
loadDynamicLibrariesForComputeDescriptor:options:error:
loadDynamicLibrariesForFunction:insertLibraries:error:
loadDynamicLibrariesForFunction:insertLibraries:options:error:
validateDynamicLibrary:state:error:
validateDynamicLibraryURL:error:
newBinaryLibraryWithOptions:url:error:
newVisibleFunctionTableWithDescriptor:
newIntersectionFunctionTableWithDescriptor:
newRenderPipelineStateWithMeshDescriptor:error:
newRenderPipelineStateWithMeshDescriptor:completionHandler:
newProfileWithExecutionSize:
supportsBufferlessClientStorageTexture
supportsComputeMemoryBarrier
supportsRenderMemoryBarrier
supportsArgumentBuffersTier2
supportsReadWriteTextureArgumentsTier2
supportsStreamingCodecSignaling
supportsProgrammableSamplePositions
supportsLargeFramebufferConfigs
supportsCustomBorderColor
supportsSamplerAddressModeClampToHalfBorder
supports3DBCTextures
supportsRGBA10A2Gamma
supportsBGR10A2
supportsPrimitiveRestartOverride
supportsGlobalVariableRelocation
supportsGlobalVariableRelocationRender
supportsGlobalVariableRelocationCompute
supportsTLS
supports32bpcMSAATextures
supportsVertexAmplification
supportsPlacementHeaps
supportsOpenCLTextureWriteSwizzles
supportsInt64
supportsFixedLinePointFillDepthGradient
supportsLateEvalEvent
supportsNonZeroTextureWriteLOD
supportsSharedTextureHandles
supportsBufferPrefetchStatistics
supportsLimitedYUVFormats
supportsNonPrivateDepthStencilTextures
supportsNonPrivateMSAATextures
supportsSharedStorageHeapResources
supportsSharedStorageTextures
supportsLinearTextureFromSharedBuffer
supportsPipelineLibraries
supportsFragmentOnlyEncoders
supportsBufferWithIOSurface
supportsProgrammableBlending
supportsRenderToLinearTextures
supportsMemorylessRenderTargets
supportsFastMathInfNaNPropagation
supportsInvariantVertexPosition
supportsShaderLODAverage
supportsRelaxedTextureViewRequirements
supportsSeparateDepthStencil
supportsGPUStatistics
supportsCompressedTextureViewSPI
supportsRenderTargetTextureRotation
supportsDynamicControlPointCount
supportsIABHashForTools
supportsBinaryArchives
supportsBinaryLibraries
supportsDeadlineProfile
supportsFillTexture
supportsSetThreadgroupPackingDisabled
supportsASTCTextureCompression
supportsExtendedYUVFormats
supportsPublicXR10Formats
supportsSRGBwrites
supportsDepthClipMode
supportsPacked32TextureBufferWrites
supports3DASTCTextures
supportsExtendedXR10Formats
supportsFragmentBufferWrites
supportsCountingOcclusionQuery
supportsBaseVertexInstanceDrawing
supportsIndirectDrawAndDispatch
supportsTessellation
supportsReadWriteBufferArguments
supportsArrayOfTextures
supportsArrayOfSamplers
supportsCombinedMSAAStoreAndResolveAction
supportsMutableTier1ArgumentBuffers
supportsSamplerCompareFunction
supportsMSAADepthResolve
supportsMSAAStencilResolve
supportsMSAADepthResolveFilter
supportsGFXIndirectCommandBuffers
supportsCMPIndirectCommandBuffers
supportsIndirectStageInRegion
supportsIndirectTextures
supportsNorm16BCubicFiltering
supportsTextureOutOfBoundsReads
supportsTextureSwizzle
supportsAlphaYUVFormats
supportsMemoryOrderAtomics
supportsQuadGroup
supportsRenderTextureWrites
supportsImageBlocks
supportsTileShaders
supportsImageBlockSampleCoverageControl
supportsNativeHardwareFP16
supportsPostDepthCoverage
supportsMipLevelsSmallerThanBlockSize
supportsNonUniformThreadgroupSize
supportsReadWriteTextureArguments
supportsReadWriteTextureCubeArguments
supportsTextureCubeArray
supportsQuadShufflesAndBroadcast
supportsConcurrentComputeDispatch
supportsRenderPassWithoutRenderTarget
supportsRasterOrderGroups
supportsRasterOrderGroupsColorAttachment
supportsLinearTexture2DArray
supportsNonSquareTileShaders
supportsSeparateVisibilityAndShadingRate
supports2DLinearTexArraySPI
supportsLayeredRendering
supportsViewportAndScissorArray
supportsIndirectTessellation
supportsMSAAStencilResolveFilter
supportsStencilFeedback
supportsFP32TessFactors
supportsUnalignedVertexFetch
supportsSIMDGroup
supportsShaderMinLODClamp
supportsSIMDShufflesAndBroadcast
supportsWritableArrayOfTextures
supportsVariableRateRasterization
supportsYCBCRFormats
supportsYCBCRFormatsPQ
supportsYCBCRFormats12
supportsYCBCRFormatsXR
supportsASTCHDRTextureCompression
supportsSparseTextures
supportsSparseHeaps
supportsIndirectWritableTextures
supportsStatefulDynamicLibraries
supportsSharedFunctionTables
supportsRayTracingExtendedVertexFormats
supportsHeapAccelerationStructureAllocation
supportsRayTracingPerPrimitiveData
supportsRayTracingBuffersFromTables
supportsRayTracingAccelerationStructureCPUDeserialization
supportsBlackOrWhiteSamplerBorderColors
supportsMirrorClampToEdgeSamplerMode
supportsSIMDReduction
supportsDepthClipModeClampExtended
supportsTexture2DMultisampleArray
supportsForceSeamsOnCubemaps
supportsFloat16BCubicFiltering
supportsFloat16InfNanFiltering
supportsRTZRounding
supportsAnisoSampleFix
supportsYCBCRPackedFormatsPQ
supportsYCBCRPackedFormats12
supportsYCBCRPackedFormatsXR
supportsBufferBoundsChecking
supportsForkJoin
supportsDevicePartitioning
supportsComputeCompressedTextureWrite
supportsSIMDGroupMatrix
supportsInterchangeTiled
supportsQuadReduction
supportsSIMDShuffleAndFill
supportsBfloat16Format
supportsSparseDepthAttachments
supportsLossyCompression
supportsMeshShaders
supportsFunctionPointersFromMesh
supportsMeshShadersInICB
supportsCommandBufferJump
supportsStackOverflowErrorCode
supportsRayTracingICBs
supportsExplicitVisibilityGroups
bufferRobustnessSupport
deviceCreationFlags
areGPUAssertionsEnabled
setGPUAssertionsEnabled:
commandBufferErrorOptions
setCommandBufferErrorOptions:
isBCTextureCompressionSupported
targetDeviceInfo
targetDeviceArchitecture
architecture
halfFPConfig
singleFPConfig
doubleFPConfig
metalAssertionsEnabled
setMetalAssertionsEnabled:
featureProfile
simulatorHostFeatureProfile
limits
maxFramebufferStorageBits
linearTextureArrayAlignmentBytes
linearTextureArrayAlignmentSlice
maxTileBuffers
maxTileTextures
maxTileSamplers
maxTileInlineDataSize
minTilePixels
maxColorAttachments
maxVertexAttributes
maxVertexBuffers
maxVertexTextures
maxVertexSamplers
maxVertexInlineDataSize
maxInterpolants
maxFragmentBuffers
maxFragmentTextures
maxFragmentSamplers
maxFragmentInlineDataSize
maxComputeBuffers
maxComputeTextures
maxComputeSamplers
maxComputeInlineDataSize
maxComputeLocalMemorySizes
maxTotalComputeThreadsPerThreadgroup
maxComputeThreadgroupMemory
maxLineWidth
maxPointSize
maxVisibilityQueryOffset
minConstantBufferAlignmentBytes
minBufferNoCopyAlignmentBytes
maxTextureWidth1D
maxTextureWidth2D
maxTextureHeight2D
maxTextureWidth3D
maxTextureHeight3D
maxTextureDepth3D
maxTextureDimensionCube
maxTextureLayers
linearTextureAlignmentBytes
iosurfaceTextureAlignmentBytes
iosurfaceReadOnlyTextureAlignmentBytes
deviceLinearTextureAlignmentBytes
deviceLinearReadOnlyTextureAlignmentBytes
maxFunctionConstantIndices
maxComputeThreadgroupMemoryAlignmentBytes
maxInterpolatedComponents
maxTessellationFactor
maxIndirectBuffers
maxIndirectTextures
maxIndirectSamplers
maxIndirectSamplersPerDevice
maxFenceInstances
maxViewportCount
maxCustomSamplePositions
maxVertexAmplificationFactor
maxVertexAmplificationCount
maxTextureBufferWidth
maxComputeAttributes
maxIOCommandsInFlight
maxPredicatedNestingDepth
maxConstantBufferArguments
supportPriorityBand
sharedMemorySize
dedicatedMemorySize
indirectArgumentBufferCapabilities
isFloat32FilteringSupported
isMsaa32bSupported
isRTZRoundingSupported
defaultTextureWriteRoundingMode
isAnisoSampleFixSupported
isFixedLinePointFillDepthGradientSupported
isLargeMRTSupported
maxRasterizationRateLayerCount
isPlacementHeapSupported
GPUBVHBuilder
requiresRaytracingEmulation
pluginData
setPluginData:
registerDevices
supportsPrimitiveType:
indirectArgumentBufferDecodingData
setIndirectArgumentBufferDecodingData:
setupMPSFunctionTable:
resourcePatchingTypeForResourceType:
reserveResourceIndicesForResourceType:indices:indexCount:
reserveGPUAddressRange:
newBufferWithLength:options:gpuAddress:
newBufferWithBytes:length:options:gpuAddress:
newBufferWithBytesNoCopy:length:options:gpuAddress:deallocator:
newBufferWithDescriptor:
newLateEvalEvent
mapShaderSampleBufferWithBuffer:capacity:size:
unmapShaderSampleBuffer
newComputePipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithTileDescriptor:error:
newRenderPipelineStateWithTileDescriptor:completionHandler:
newFunctionWithGLCoreIR:functionType:
newFunctionWithGLCoreIR:inputsDescription:functionType:
newFunctionWithGLESIR:functionType:
newFunctionWithGLESIR:inputsDescription:functionType:
newFunctionWithGLIR:functionType:
newFunctionWithGLIR:inputsDescription:functionType:
getShaderCacheKeys
getBVHBuilderLock
getRawBVHBuilderPtr
setRawBVHBuilderPtr:
newIndirectArgumentEncoderWithArguments:
newComputePipelineStateWithImageFilterFunctionsSPI:imageFilterFunctionInfo:error:
newLibraryWithDAG:functions:error:
newLibraryWithGraphs:functions:error:
newLibraryWithGraphsSPI:functions:error:
newLibraryWithStitchedDescriptorSPI:error:
newLibraryWithDescriptor:error:
newLibraryWithDescriptor:completionHandler:
newLibraryWithDescriptorSPI:error:
newDagStringWithGraphs:
newLibraryWithImageFilterFunctionsSPI:imageFilterFunctionInfo:error:
newLibraryWithCIFilters:imageFilterFunctionInfo:error:
newLibraryWithCIFiltersForComputePipeline:imageFilterFunctionInfo:error:
newPipelineLibraryWithFilePath:error:
startCollectingPipelineDescriptors
startCollectingPipelineDescriptorsUsingPrefixForNames:
endCollectingPipelineDescriptors
serializeRenderPipelineDescriptor:
serializeComputePipelineDescriptor:
newRenderPipelineDescriptorWithSerializedData:deserializationContext:
newComputePipelineDescriptorWithSerializedData:deserializationContext:
serializeStructType:
serializeStructType:version:
newStructTypeWithSerializedData:
newTextureWithBytesNoCopy:length:descriptor:deallocator:
newTextureLayoutWithDescriptor:isHeapOrBufferBacked:
newIndirectArgumentEncoderWithLayout:
tileSizeWithSparsePageSize:textureType:pixelFormat:sampleCount:
compileVisibleFunction:withDescriptor:destinationBinaryArchive:error:
compileVisibleFunction:withDescriptor:error:
compileVisibleFunction:withDescriptor:completionHandler:
deserializeCompileTimeStats:addToDictionary:
shaderDebugInfoCaching
setShaderDebugInfoCaching:
isQuadDataSharingSupported
sparseTexturesSupport
isRGB10A2GammaSupported
isCustomBorderColorSupported
isClampToHalfBorderSupported
gpuAssertionsEnabled
TB,GareGPUAssertionsEnabled,SsetGPUAssertionsEnabled:
BCTextureCompressionSupported
TB,R,GisBCTextureCompressionSupported
Tr^{MTLTargetDeviceArch=QI*},R
T@"MTLTargetDeviceArchitecture",R
T@"MTLArchitecture",R
TB,N
Tr^{?=IIIIIIIIIIIIIIIIIIIIIIIIIIffIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIQ},R
T{IndirectArgumentBufferCapabilities=b1b1b1b29},R
quadDataSharingSupported
TB,R,GisQuadDataSharingSupported
float32FilteringSupported
TB,R,GisFloat32FilteringSupported
msaa32bSupported
TB,R,GisMsaa32bSupported
RTZRoundingSupported
TB,R,GisRTZRoundingSupported
Tq,R
AnisoSampleFixSupported
TB,R,GisAnisoSampleFixSupported
FixedLinePointFillDepthGradientSupported
TB,R,GisFixedLinePointFillDepthGradientSupported
largeMRTSupported
TB,R,GisLargeMRTSupported
RGB10A2GammaSupported
TB,R,GisRGB10A2GammaSupported
CustomBorderColorSupported
TB,R,GisCustomBorderColorSupported
ClampToHalfBorderSupported
TB,R,GisClampToHalfBorderSupported
placementHeapSupported
TB,R,GisPlacementHeapSupported
T@"MTLGPUBVHBuilder",R
T@"NSDictionary",C,N
setAllocatedTextures:
_allocatedTextures
T@"<MTLDeviceSPI>",&,V_delegate
T@"NSMutableArray",&,V_allocatedTextures
_reinit
_activeTrackNumbers
_focusSmootherForAppendingWithTrackIdentifier:
_endFocusSmoothersForTrackNumbers:
_invalidateIsNextFrameAvailableCache
_computeIsNextFrameAvailable
setLastKnownFocusDetection:
lastKnownFocusDetection
_focusSmootherForReadingWithTrackIdentifier:
_skipToNextFocusSmootherWithTrackIdentifier:
_updateFocusDetectionForFrame:
_dropAllFocusSmoothersIfLeaked
firstFocusSmootherByTrackNumber
_newFocusSmoother
setFirstFocusSmootherByTrackNumber:
didEndFrames
setDidEndFrames:
didCacheIsNextFrameAvailable
setDidCacheIsNextFrameAvailable:
isNextFrameAvailableCache
setIsNextFrameAvailableCache:
_didEndFrames
_didCacheIsNextFrameAvailable
_isNextFrameAvailableCache
_lastKnownFocusDetection
_firstFocusSmootherByTrackNumber
T@"NSMutableArray",&,V_frames
T@"PTCinematographyDetection",&,V_lastKnownFocusDetection
T@"NSMutableDictionary",&,V_firstFocusSmootherByTrackNumber
TB,V_didEndFrames
TB,V_didCacheIsNextFrameAvailable
TB,V_isNextFrameAvailableCache
stringWithCharacters:length:
stabilizationHomography
setStabilizationHomography:
estimatedMotionBlur
setEstimatedMotionBlur:
hasStabilizationHomography
hasEstimatedMotionBlur
_stabilizationHomography
_hasStabilizationHomography
_estimatedMotionBlur
_hasEstimatedMotionBlur
T{?=[3]},N
TB,R,V_hasStabilizationHomography
TB,R,V_hasEstimatedMotionBlur
initWithTime:tappedDetection:strong:
_strong
_groupTap
strong
TB,R,GisStrong,V_strong
T@"NSNumber",R
groupTap
TB,R,GisGroupTap,V_groupTap
_setFocusOnDetection:
_setFocusBetweenDetection:detection:coefficient:
_setFocusOnPrimaryDetection:secondaryDetection:primaryCoefficient:
secondaryFocusDetection
primaryFocusCoefficient
secondaryFocusCoefficient
initWithPrimaryDetection:secondaryDetection:primaryCoefficient:
_initWithDetections:coefficients:
initFocusedBetweenDetection:detection:coefficient:
_initWithDetections:cinematographyDictionary:
_initWithDetections:coefficientsDictionary:
_asCoefficientsDictionary
_primaryFocusCoefficient
_secondaryFocusCoefficient
_primaryFocusDetection
_secondaryFocusDetection
T@"PTCinematographyDetection",R,N,V_primaryFocusDetection
T@"PTCinematographyDetection",R,N,V_secondaryFocusDetection
Tf,R,N,V_primaryFocusCoefficient
Tf,R,N,V_secondaryFocusCoefficient
getBytes:range:
T@"NSData",&,V_data
_disparityNetworkTemporalState
_lastQuatersizeRGBA
_initWithTime:trackIdentifier:groupIdentifier:transition:options:
defaultTransition
T@"PTCinematographyTransition",R,N
_transition
_minimumDuration
_maximumDuration
TQ,R,N,V_options
Tq,N,V_type
T{?=qiIq},N,V_minimumDuration
T{?=qiIq},N,V_maximumDuration
T@"PTCinematographyTransition",R,N,V_transition
userDecision
TB,R,N,GisUserDecision
strongDecision
TB,R,N,GisStrongDecision
groupDecision
TB,R,N,GisGroupDecision
_decisionsWithCinematographyDictionaries:
float4x4ToHalf3x4:
getChromaFactor2BooleanFromPTTexture:
convertRGB:inRGBA:outRGBA:colorTransferFunction:rotateCCW:
convertRGB:inRGBA:outRGBA:colorTransferFunction:
convertYUVtoRGB:inLuma:inChroma:outRGBA:colorTransferFunction:colorYCbCrMatrix:colorYCbCrFullRange:colorYCbCrDepthIn:
convertRGBtoYUV:inRGBA:outLuma:outChroma:colorTransferFunction:colorYCbCrMatrix:colorYCbCrFullRange:colorYCbCrDepthOut:
getChromaOffsetFromPTTexture:
convertRGBLinearToPTTexture:inRGBA:outPTTexture:
_convertRGB
_convertRGBToYUV
_convertYUVToRGB
resourcePath
setThreadGroupSizeIsMultipleOfThreadExecutionWidth:
setMipmapLevelCount:
mipmapLevelCount
initWithLength:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
writeToFile:atomically:
hasSuffix:
defaultManager
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
setDateFormat:
date
stringFromDate:
stringByAppendingFormat:
_drawTurboLegendTick:outTexture:rect:maxValue:
drawTurboLegend:outLuma:outChroma:rect:maxValue:
reciprocalTex:inTex:outTex:epsilon:
fillWithColor:color:outTex:
drawTurboLegend:outRGBA:rect:maxValue:
sobelFilterSingleChannelColor:input:output:scale:
visualizeCircleUsingRect:center:radius:outTexture:
_defaultLibrary
_renderDisparity
_kernelCopy
_multiplyTex
_addConstant
_reciprocal
_fillWithColor
_drawTurboLegend
_drawTurboLegendYUV
_gaussianNoise
_sobelFilter
_renderRect
_visualizeCircleUsingRect
_gaussianFilter3x3
newFunctionWithName:constantValues:error:
newFunctionWithName:constantValues:pipelineLibrary:error:
effectNetworkPath
setEffectNetworkPath:
effectNetworkConfig
setEffectNetworkConfig:
effectNetwork
setEffectNetwork:
segmentationNetwork
setSegmentationNetwork:
_effectNetworkPath
_effectNetworkConfig
_effectNetwork
T@"NSString",&,N,V_effectNetworkPath
T@"NSString",&,N,V_effectNetworkConfig
T@"PTEspressoGenericExecutor",&,N,V_effectNetwork
T@"PTEspressoGenericExecutor",&,N,V_segmentationNetwork
_originalVideoDimensions
originalVideoDimensions
setOriginalVideoDimensions:
hasOriginalVideoDimensions
_hasOriginalVideoDimensions
T{?=ii},N
TB,R,V_hasOriginalVideoDimensions
initWithDevice:version:colorInputSize:colorOutputSize:disparitySize:
setDebugRendering:
setVerbose:
setGpuProfiling:
setUseRGBA:
useRGBA
_verbose
_gpuProfiling
_useRGBA
_colorInputSize
_colorOutputSize
T@"<MTLDevice>",R,&,V_device
TQ,R,V_version
T{CGSize=dd},R,V_colorInputSize
T{CGSize=dd},R,V_colorOutputSize
T{CGSize=dd},R,V_disparitySize
Tq,V_debugRendering
TB,V_verbose
TB,V_gpuProfiling
TB,V_useRGBA
isMetalDeviceSupported:
isRenderVersionSupported:
setActiveVersion:
_descriptor
updateLevel0FromPTTextureRGBA:inPTTextureRGBA:doFirstLevelGaussianDownsample:
updateLevel0FromPTTextureYUV:inPTTextureYUV:doFirstLevelGaussianDownsample:
updateLevel0and1FromPTTextureRGBA:inPTTextureRGBA:
updateLevel0and1FromPTTextureYUV:inPTTextureYUV:
setRgbaPyramid:
setRgbaPyramidArray:
bicubic
setBicubic:
setDropHints:
_downscaleGaussian3x3
_updateLevel0Gaussian3x3FromRGBA
_updateLevel0Gaussian3x3FromYUV
_updateLevel0and1Gaussian3x3FromRGBA
_updateLevel0and1Gaussian3x3FromYUV
_updateLevel0Box2x2FromRGBA
_updateLevel0Box2x2FromYUV
_rgbaPyramidArray
_skipFullSizeLayer
_bicubic
T@"<MTLTexture>",&,N,V_rgbaPyramid
T@"NSArray",&,N,V_rgbaPyramidArray
TB,N,V_bicubic
T@"PTMTLDropHints",&,N,V_dropHints
_sizeOfAtomOfType:withOptions:
dataWithBytesNoCopy:length:freeWhenDone:
setMetadata:ofType:
_atoms
matchesRenderState:
applyToRenderState:
applyToRenderState:error:
TI,N,V_renderingVersion
nanAwareEqual:with:
defaultAperture
setDefaultAperture:
minAperture
setMinAperture:
maxAperture
setMaxAperture:
sensorCropRect
setSensorCropRect:
rawSensorSize
setRawSensorSize:
focalLength35mm
setFocalLength35mm:
extrinsicsMatrix
setExtrinsicsMatrix:
readNoise1x
setReadNoise1x:
readNoise8x
setReadNoise8x:
_minAperture
_maxAperture
_focalLength35mm
_conversionGain
_readNoise1x
_readNoise8x
_rawSensorSize
_sensorCropRect
_extrinsicsMatrix
_visCropFactor
_sensorID
_sourceColorBitDepth
_networkBias
_noiseScaleFactor
_hwModelID
Tf,N,V_defaultAperture
Tf,N,V_minAperture
Tf,N,V_maxAperture
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_sensorCropRect
T{?=ii},N,V_rawSensorSize
Tf,N,V_focalLength35mm
T{?=[4]},N,V_extrinsicsMatrix
TI,N,V_conversionGain
TI,N,V_readNoise1x
TI,N,V_readNoise8x
T,N,V_visCropFactor
TI,N,V_sensorID
TI,N,V_sourceColorBitDepth
Tf,N,V_networkBias
Tf,N,V_noiseScaleFactor
TI,N,V_hwModelID
precomputeGaussianFromNumberOfSamples:seed:
_interpolateRGBWeightSourceYUVDestYUV
_interpolateRGBWeightSourceYUVDestRGBA
_interpolateRGBWeightSourceRGBADestRGBA
_studioLightInterpolateRGBWeightSourceYUVDestYUV
_precomputedGaussian
_sizePrecomputedGaussian
debugTexture
normal
_updateCoefficientDisparity
_updateCoefficientNormal
_filteredDisparity
_temporalDisparity
_temporalNormal
_normal
_normalEstimation
@16@0:8
@24@0:8Q16
@24@0:8@16
B24@0:8@16
@32@0:8@16@24
v16@0:8
f16@0:8
v48@0:8Q16{?=qiIq}24
B24@0:8Q16
B48@0:8Q16{?=qiIq}24
B40@0:8{?=qiIq}16
v24@0:8@16
Q16@0:8
@32@0:8Q16@24
v60@0:8@16Q24{?=qiIq}32B56
v24@0:8Q16
v40@0:8{?=qiIq}16
B32@0:8Q16Q24
v56@0:8@16Q24{?=qiIq}32
q16@0:8
v24@0:8q16
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSString"
@"PTCinematographyNetworkParameters"
@"NSArray"
@"PTCinematographyDetection"
@"NSMutableArray"
@"NSMutableIndexSet"
@32@0:8@16Q24
B16@0:8
v40@0:8^v16Q24Q32
@40@0:8Q16Q24Q32
v40@0:8r^v16Q24Q32
I16@0:8
@"<PTByteStream>"
@"PTAtomStream"
@"NSError"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
i116@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32@40{CGAffineTransform=dddddd}48^{__CVBuffer=}96B104@?108
i116@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32@"PTHumanDetections"40{CGAffineTransform=dddddd}48^{__CVBuffer=}96B104@?<v@?@"<MTLCommandBuffer>">108
@"PTEffectTemporalState"24@0:8@"<MTLCommandBuffer>"16
@112@0:8@16@24@32{?=QQQ}40@64Q72B80B84@88@96@104
v24@0:8r^{__CFDictionary=}16
v32@0:8@16^{__CVBuffer=}24
@"<MTLDevice>"
@"<MTLLibrary>"
@"<MTLPipelineLibrary>"
@"<MTLCommandQueueSPI>"
@"PTRenderPipeline"
@"<PTRenderState>"
@"PTRaytracingInterpolateResult"
@"<MTLTexture>"
@"<MTLBuffer>"
@"PTMSRResize"
@"PTGuidedFilter"
@"PTRenderEffectNetwork"
@"PTEffectRelighting"
@"PTPyramidRGB"
@"PTColor"
@"PTRenderRequest"
@"PTEffectDebugLayer"
@"PTOpticalFlow"
@"PTMTLDropHints"
@"PTUtil"
@"PTEffectUtil"
@"PTEffectFilter"
B36@0:8I16^Q20^Q28
B40@0:8^{__CVBuffer=}16^Q24^Q32
B24@0:8^{__CVBuffer=}16
Q24@0:8^{__CVBuffer=}16
I56@0:8@16^{__CVBuffer=}24^@32^@40B48B52
@32@0:8^{__CVBuffer=}16@24
I24@0:8Q16
{?=qiIq}40@0:8{?=qiIq}16
{?={?=qiIq}{?=qiIq}}40@0:8{?=qiIq}16
{?={?=qiIq}{?=qiIq}}16@0:8
{?={?=qiIq}{?=qiIq}}24@0:8Q16
@40@0:8{?=qiIq}16
@64@0:8{?={?=qiIq}{?=qiIq}}16
@88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
v72@0:8{?=qiIq}16{?=qiIq}40@64
v20@0:8B16
@"PTCinematographyScript"
@20@0:8f16
@40@0:8Q16q24q32
@32@0:8Q16q24
@104@0:8@16@24@32{?=QQQ}40@64Q72B80B84@88@96
[3@"PTRenderPipeline"]
[3@"<PTRenderState>"]
v48@0:8@16@24@32f40f44
@"<MTLComputePipelineState>"
@56@0:8{?=qiIq}16^{__CVBuffer=}40^{__CVBuffer=}48
{?=qiIq}16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
{?="value"q"timescale"i"flags"I"epoch"q}
i16@0:8
@"NSArray"16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8i16
@"PTAssetReader"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v24@0:8@"AVVideoCompositionRenderContext"16
v24@0:8@"AVAsynchronousVideoCompositionRequest"16
@"NSDictionary"16@0:8
v24@0:8@"AVVideoCompositionRenderHint"16
v24@0:8^{__CVBuffer=}16
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
@"NSDictionary"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
B32@0:8Q16^@24
B56@0:8Q16{?=qiIq}24^@48
r^{opaqueCMFormatDescription=}16@0:8
@"AVAssetReader"
@"AVAssetReaderOutputMetadataAdaptor"
@"AVMutableVideoComposition"
@"AVAssetReaderVideoCompositionOutput"
@"PTGlobalCinematographyMetadata"
@"PTGlobalRenderingMetadata"
@"PTGlobalStabilizationMetadata"
@"PTGlobalVideoHeaderMetadata"
@"AVAsset"
r^{opaqueCMFormatDescription=}
v32@0:8S16f20^^{?}24
v32@0:8S16I20^^{?}24
f40@0:8S16r^{?=SS(?=fiI)}20I28^B32
v56@0:8S16{?=qiIq}20i44^^{?}48
f32@0:8S16r^{?=SS(?=fiI)}20I28
f36@0:8S16r^{?=SS(?=fiI)}20I28f32
I40@0:8S16r^{?=SS(?=fiI)}20I28^B32
I32@0:8S16r^{?=SS(?=fiI)}20I28
I44@0:8S16r^{?=SS(?=fiI)}20I28I32^B36
{?=qiIq}60@0:8S16i20r^{?=SS(?=fiI)}24I32{?=qiIq}36
v20@0:8f16
@24@0:8f16f20
v44@0:8f16{?=qiIq}20
f20@0:8f16
f24@0:8f16f20
f44@0:8f16{?=qiIq}20
f48@0:8f16{?=qiIq}20B44
v20@0:8I16
v32@0:8Q16Q24
v32@0:8r^v16Q24
@"<PTByteWriter>"
@"PTAtomWriter"
@24@0:8^{_NSZone=}16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
{CGSize="width"d"height"d}
@64@0:8^{__CVBuffer=}16^{__CVBuffer=}24@32{?=qiIq}40
@44@0:8@16f24Q28^{__CVBuffer=}36
@52@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20
f24@0:8@16
@40@0:8@16@24^{__CVBuffer=}32
B32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
@40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B32@0:8@16@24
@56@0:8@16{?=qiIq}24^{__CVBuffer=}48
B48@0:8@16{?=qiIq}24
{CGSize=dd}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@72@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40
v56@0:8@16@24{?=qiIq}32
@104@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64{?=qiIq}72^{__CVBuffer=}96
Q24@0:8Q16
@56@0:8@16@24{?=qiIq}32
f60@0:8@16^v24Q32Q40Q48I56
f68@0:8@16^v24Q32Q40Q48I56@60
v40@0:8@16^{__CVBuffer=}24@32
f36@0:8f16q20Q28
B36@0:8f16@20@28
@"<PTCinematographyStreamDelegate>"
@"PTCinematographyStreamOptions"
@"PTCinematographyTrackAllocator"
@"PTCinematographyNetwork"
@"PTCinematographyFocusPuller"
@"PTCinematographyFrame"
@"PTCinematographyUserTap"
B32@0:8r^v16Q24
B40@0:8r^v16Q24Q32
@"NSError"16@0:8
@32@0:8Q16Q24
@"NSMutableData"
@"PTCinematographyFocusSmoother"
@"MutableFloatArray"
v32@0:8@16@24
@100@0:8@16@24@32{CGSize=dd}40{CGSize=dd}56q72B80B84@88i96
i32@0:8@16@24
@100@0:8@"<MTLDeviceSPI>"16@"<MTLLibrary>"24@"<MTLPipelineLibrary>"32{CGSize=dd}40{CGSize=dd}56q72B80B84@"NSDictionary"88i96
i32@0:8@"<MTLCommandBuffer>"16@"PTRenderRequest"24
v24@0:8@"<MTLHeap>"16
@"PTRenderDebugLayer"
@"<MTLDeviceSPI>"
{PTFocusEdge="width"f"gradientThreshold"f"gradientWeight"f"minMaxThreshold"f}
@"PTQualitySettings"
@"PTRaytracingUtilsV2"
@"PTGlobalReduction"
i40@0:8@16@24@32
i64@0:8@16@24@32@40@48@56
i60@0:8@16@24@32@40@48f56
i40@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32
i64@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32@"<MTLTexture>"40@"<MTLTexture>"48@"<MTLTexture>"56
i60@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32@"<MTLTexture>"40@"<MTLTexture>"48f56
@120@0:8@16{?=QQQ}24{?=QQQ}48Q72{?=QQQ}80Q104@112
{?="width"Q"height"Q"depth"Q}
@"<MTLSamplerState>"
q24@0:8Q16
q48@0:8Q16{?=qiIq}24
@"PTCinematographyFocusFramesOptions"
v48@0:8@16@24^32^f40
@36@0:8@16i24i28i32
@36@0:8Q16i24r^v28
i24@0:8@16
i40@0:8@16i24B28@32
i56@0:8@16@24f32i36^S40@48
v28@0:8i16i20i24
i32@0:8@16B24B28
i36@0:8@16@24i32
i84@0:8@16i24@28@36@44@52@60@68@76
i48@0:8@16@24@32@40
i64@0:8@16@24@32@40i48f52^S56
i56@0:8@16@24@32@40@48
[12@"<MTLComputePipelineState>"]
[10{CGSize="width"d"height"d}]
[2[10@"<MTLTexture>"]]
[10@"<MTLTexture>"]
[2@"<MTLBuffer>"]
[2B]
@24@0:8q16
f24@0:8i16i20
@20@0:8i16
@"<MTLCommandQueue>"
i62@0:8@16@24@32@40@48 56f58
i58@0:8@16@24@32@40@48 56
i44@0:8@16@24@32f40
{?=QQQQ}16@0:8
v48@0:8{?=QQQQ}16
@"PTTexture"
{?="x"Q"y"Q"width"Q"height"Q}
@56@0:8@16{?=QQQ}24q48
@68@0:8@16{?=QQQ}24q48B56B60B64
s40@0:8@16i24B28@32
s40@0:8@16@24@32
s48@0:8@16@24@32@40
s24@0:8@16
@"LKTFlowGPU"
I24@0:8@16
I24@0:8@"NSDictionary"16
B32@0:8@"NSMutableData"16@"NSDictionary"24
@24@0:8@"NSData"16
@24@0:8I16I20
@20@0:8I16
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@24@0:8i16i20
@32@0:8@16i24i28
v40@0:8@16^i24^i32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{PTFigCaptureStreamFocusBlurMap=C{PTFigCaptureStreamFocusBlurMapHeader=SSSSSSSSSSSCCCCCCff}[512{PTFigCaptureStreamFocusBlurMapTile=sCCCCCC}]}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@72@0:8@16@24@32{?=QQQ}40f64f68
i52@0:8@16@24@32@40i48
v60@0:8@16@24@32@40@48f56
v40@0:8@16@24@32
v52@0:8@16@24@32@40f48
i40@0:8^{opaqueCMFormatDescription=}16@24Q32
@40@0:8^{opaqueCMFormatDescription=}16@24Q32
@48@0:8^{opaqueCMFormatDescription=}16@24Q32Q40
@56@0:8^{opaqueCMFormatDescription=}16@24Q32Q40q48
@60@0:8^{opaqueCMFormatDescription=}16@24Q32Q40B48q52
i24@0:8Q16
i20@0:8B16
@48@0:8^{opaqueCMFormatDescription=}16@24Q32q40
i40@0:8^{__CVBuffer=}16r^{__CFDictionary=}24^{__CVBuffer=}32
i88@0:8^{__CVBuffer=}16r^{__CFDictionary=}24{CGAffineTransform=dddddd}32^{__CVBuffer=}80
i96@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32{CGAffineTransform=dddddd}40^{__CVBuffer=}88
@"<PTEffectImpl>"
@"NSObject<OS_dispatch_queue>"
^{OpaqueVTPixelTransferSession=}
@"PTFaceAttributesNetwork"
@"PTEffectResources"
@"PTHumanDetections"
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
{?=QQQ}16@0:8
i52@0:8@16@24@32@40f48
@"<PTAbstractDisparityFilter>"
Q24@0:8@16
@80@0:8@16@24@32{CGSize=dd}40{CGSize=dd}56@72
@48@0:8@16@24@32q40
@"MPSImageSpatioTemporalGuidedFilter"
@28@0:8i16@20
@132@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112f120@124
v88@0:8@16@24@32{CGAffineTransform=dddddd}40
v88@0:8q16@24@32{CGAffineTransform=dddddd}40
@32@0:8^^{__IOSurface}16@24
^{__CVBuffer=}20@0:8i16
[2@"NSString"]
[2^{__CVBuffer}]
@40@0:8@16@24@32
@96@0:8@16@24@32@40@48@56@64@72^{?=QQQ}80@88
s36@0:8@16@24i32
I32@0:8@16^{__CVBuffer=}24
I24@0:8@?16
I20@0:8i16
@"NSMutableDictionary"
@"NSURL"
@100@0:8@16@24@32@40{?=QQQ}48@72@80B88@92
@28@0:8I16#20
v24@0:8#16
Q24@0:8@"NSDictionary"16
B32@0:8@"PTAtomWriter"16@"NSDictionary"24
@24@0:8@"PTAtomStream"16
Q32@0:8@16@24
@32@0:8@16^@24
@40@0:8@16@24^@32
B48@0:8@16@24@32^@40
#20@0:8I16
v28@0:8I16#20
@32@0:8@16I24I28
@28@0:8@16I24
@24@0:8^{DetectionData_0=QQIf[4f]}16
B24@0:8^{DetectionData_0=QQIf[4f]}16
B40@0:8@16@24@32
@"NSArray"24@0:8@"PTAtomStream"16
Q32@0:8@"NSArray"16@"NSDictionary"24
B40@0:8@"NSArray"16@"PTAtomWriter"24@"NSDictionary"32
@76@0:8@16@24{?=QQQ}32@56B64@68
I24@0:8^{__CVBuffer=}16
i36@0:8^{__IOSurface=}16^{__IOSurface=}24B32
I56@0:8^{__IOSurface=}1624i40^{__IOSurface=}44B52
i44@0:8^{__IOSurface=}16^{__IOSurface=}24B32B36B40
[10^{__CVBuffer}]
[10^{__IOSurface}]
^{__CFDictionary=}
^{CGColorSpace=}
@116@0:8@16@24@32@40@48@56@64@72{?=QQQ}80B104@108
v180@0:8^{__CVBuffer=}16@24@32{FaceRectsWrapper=[4]i}40B120@124{CGAffineTransform=dddddd}132
v108@0:8^16@24@32@40i48{CGAffineTransform=dddddd}52@100
@"PTSegmentationNetwork"
{PTSyntheticLightConfig="firstFrame"B"framesSinceLightEstimate"i"lightEstimateFrequency"i"emaCoefficient"f"fgDiffuseMinLightIntensity"f"fgDiffuseMaxLightIntensity"f}
@"PTSubjectRelighting"
@28@0:8f16Q20
@32@0:8r^f16Q24
f24@0:8Q16
r^f16@0:8
B28@0:8@16f24
@36@0:8f16Q20Q28
^f16@0:8
v28@0:8f16Q20
v36@0:8f16{_NSRange=QQ}20
v40@0:8r^f16{_NSRange=QQ}24
@56@0:8@16@24@32{CGSize=dd}40
@64@0:8@16@24@32{CGSize=dd}40Q56
v60@0:8@16@24@32i40@44i52f56
v52@0:8@16@24@32i40i44f48
[2s]
@68@0:8@16@24@32@40@48@56B64
i116@0:8@16@24@32@40@48@56@64{CGRect={CGPoint=dd}{CGSize=dd}}72f104f108i112
@"SRLv2Plist"
@32@0:8q16Q24
@"NSNumber"
#24@0:8Q16
B20@0:8B16
16@0:8
v24@0:816
@28@0:8@16i24
@"PTRenderPipelineDescriptor"
@"<RenderingIntegration>"
@108@0:8@16@24@32@40i48{CGSize=dd}52{CGSize=dd}68Q84@92@100
@"PTDisparityUpscale"
@"PTRaytracingV14RenderState"
@"PTRaytracingUtils"
v40@0:8Q16Q24@32
v32@0:8Q16q24
@20@0:8B16
Q40@0:8{?=qiIq}16
@"PTCinematographyRefinementOptions"
@"PTCinematographyFrameDetectionSmoother"
v28@0:8B16@20
@"<MTLResourceGroupSPI>"
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
@"PTFocusBlurMap"
@"NSIndexSet"
{_NSRange=QQ}16@0:8
@"PTScanlineMask_FocusBlurMap"
v28@0:8^{PTRandomDisk=[94{Half2=  }]i }16i24
{PTFocus=ffffff}52@0:8@16f24f28f32i3640B48
{PTFocusEdge=ffff}16@0:8
@56@0:8{?=QQQ}16q40@48
{PTNoiseValues=ff}24@0:8@16
v52@0:8@16@24@32@40B48
v60@0:8@16@24@32@40@48B56
i44@0:8@16@24@32B40
v96@0:8@16@24{PTFocus=ffffff}32{PTFocusEdge=ffff}72@88
v80@0:8@16@24@32{PTFocus=ffffff}40
i100@0:8@16@24@32@40{PTFocus=ffffff}48@88f96
[9@"<MTLComputePipelineState>"]
v108@0:8@16@24@32f40{PTFocus=ffffff}44i84f88@92q100
v124@0:8@16@24@32f4044B52f5660{?={?=QQQ}{?=QQQ}}76
v136@0:8@16@24@32@40f4852B60f6468f84{?={?=QQQ}{?=QQQ}}88
24@0:8@16
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?=qiIq}48^{__CVBuffer=}72^{__CVBuffer=}80
v80@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40^{__CVBuffer=}72
@"FTCinematicTapToTrack"
I64@0:8{CGAffineTransform=dddddd}16
@76@0:8^16i24{CGAffineTransform=dddddd}28
v72@0:8@16i24f28f32B36@40@48@56@64
v56@0:8@16i24^28i36@40@48
v44@0:8@16@24@32i40
v56@0:8@16@24@32f40f44@48
i88@0:8{CGAffineTransform=dddddd}16{?=QQQ}64
@52@0:8{?=qiIq}16@40B48
@32@0:8^f16Q24
v32@0:8^f16Q24
#24@0:8@16
@32@0:8{CGPoint=dd}16
@"PTCinematographyFocusBlend"
@32@0:8@16^f24
@48@0:8@16{?=qiIq}24
v52@0:8@16@24f32f36f40f44f48
@36@0:8^{__CVBuffer=}16@24I32
@"VNSequenceRequestHandler"
@"VNSession"
{PTFocus=ffffff}48@0:8@16f24f28i3236B44
v84@0:8@16@24@32{PTFocus=ffffff}40f80
@24@0:8^{FrameHeaderData_0=QQQffffffI}16
B24@0:8^{FrameHeaderData_0=QQQffffffI}16
@"NSSet"
q40@0:8{?=qiIq}16
{_NSRange=QQ}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}32@0:8{_NSRange=QQ}16
q48@0:8{?=qiIq}16:40
Q48@0:8{?=qiIq}16:40
{_NSRange=QQ}72@0:8{?={?=qiIq}{?=qiIq}}16:64
{?={?=qiIq}{?=qiIq}}40@0:8{_NSRange=QQ}16:32
{?=qiIq}32@0:8@16:24
q60@0:8{?=qiIq}16q40B48:52
q56@0:8{?=qiIq}16q40:48
@116@0:8@16@24@32@40@48@56@64B72{?=QQQ}76@100@108
^{SmoothFaceRectData=fffff{?=[2]}[4{SmoothFaceRect=fffff}]}16@0:8
i36@0:8@16^f24i32
v72@0:8@16{CGAffineTransform=dddddd}24
v64@0:8@16@24@32@40@48q56
v108@0:8@16@24^32i40@44@52{CGAffineTransform=dddddd}60
v88@0:8@16@24@32@40@48@56@64@72i80i84
@"PTSyntheticLight"
{RelightingParam="bgLightIntensity"[3f]"bgVignetteLightIntensity"[3f]"bgVignetteFalloff"f"fgOffsetFactorNear"f"fgOffsetFactorFar"f"bgThresholdDisparity"f"bgEffectThresholdDisparity"f"fgLightDesaturation"f"fgLightColor"[3f]"bgToneCurveReciprocal"[3f]}
{SmoothFaceRectData="aspect"f"lightMaskExponent"f"preumbraBendFactor"f"lightMaskWidth"f"lightMaskFaceOffsetY"f"faceEyeWeight""rotation"{?="columns"[2]}"faces"[4{SmoothFaceRect="faceCenter""faceRadius"f"bodyPos""bodySize""leftEyeCenter""leftEyeRadius"f"rightEyeCenter""rightEyeRadius"f"preumbra"f"weight"f}]}
[2f]
@"SingleColorCubeCorrectionStage"
@40@0:8@16@24@?32
B40@0:8@16@24^@32
v36@0:8@16@24B32
@56@0:8@16{?=qiIq}24B48B52
@64@0:8{?=qiIq}16{?=qiIq}40
@48@0:8q16{?=qiIq}24
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
v40@0:8@16{_NSRange=QQ}24
v48@0:8@16{?=qiIq}24
v80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
@56@0:8q16Q24{?=qiIq}32
v72@0:8{?={?=qiIq}{?=qiIq}}16Q64
v56@0:8{_NSRange=QQ}16@32@40@48
v88@0:8{?={?=qiIq}{?=qiIq}}16@64@72@80
v40@0:8{_NSRange=QQ}16q32
v40@0:8{_NSRange=QQ}16@32
v104@0:8{_NSRange=QQ}16@32@40@48{?={?=qiIq}{?=qiIq}}56
{?={?=qiIq}{?=qiIq}}24@0:8@16
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{?={?=qiIq}{?=qiIq}}40@0:8@16@24^B32
{?=qiIq}24@0:8@16
B52@0:8q16{?=qiIq}24B48
B28@0:8@16B24
B52@0:8@16{?=qiIq}24B48
@72@0:8{_NSRange=QQ}16{_NSRange=QQ}32{?=qiIq}48
@48@0:8{_NSRange=QQ}16{_NSRange=QQ}32
v32@0:8@16q24
@"<PTCinematographyScriptChanges>"
@"PTCinematographyTrack"
@76@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40f72
B24@0:8q16
i44@0:8r*16I24@28^@36
@36@0:8@16I24r*28
^{PTHumanDetection=if[2B][2]f}16@0:8
[4{PTHumanDetection="groupId"i"faceRect""faceRectCenteredEma""faceRectCenteredEmaEma""headRotation""faceConfidenceLevel"f"eyeConfidenceLevel"[2B]"eyeRect"[2]"confidence"f}]
{?=QQ}24@0:8@16
{?=QQ}32@0:8Q16Q24
@40@0:8r^v16Q24Q32
@48@0:8^v16Q24Q32@?40
@40@0:8@16^{__IOSurface=}24Q32
v40@0:8@16@24@?32
v32@0:8@16@?24
@48@0:8@16Q24^@32^@40
v40@0:8@16Q24@?32
v32@0:8^{?=ff}16Q24
@40@0:8@16Q24Q32
@40@0:8@16q24^@32
{?=QQQ}40@0:8Q16Q24Q32
Q24@0:8q16
{?=QQQ}48@0:8Q16Q24Q32q40
v32@0:8^Q16^Q24
{?=QQQ}24@0:8@16
{?=QQ}24@0:8Q16
v72@0:8r^{?={?=QQQ}{?=QQQ}}16^{?={?=QQQ}{?=QQQ}}24{?=QQQ}32Q56Q64
v64@0:8r^{?={?=QQQ}{?=QQQ}}16^{?={?=QQQ}{?=QQQ}}24{?=QQQ}32Q56
@"<MTLCommandQueue>"16@0:8
@"<MTLCommandQueue>"24@0:8Q16
{?=QQ}24@0:8@"MTLTextureDescriptor"16
@"<MTLHeap>"24@0:8@"MTLHeapDescriptor"16
@"<MTLBuffer>"32@0:8Q16Q24
@"<MTLBuffer>"40@0:8r^v16Q24Q32
@"<MTLBuffer>"48@0:8^v16Q24Q32@?<v@?^vQ>40
@"<MTLDepthStencilState>"24@0:8@"MTLDepthStencilDescriptor"16
@"<MTLTexture>"24@0:8@"MTLTextureDescriptor"16
@"<MTLTexture>"40@0:8@"MTLTextureDescriptor"16^{__IOSurface=}24Q32
@"<MTLSamplerState>"24@0:8@"MTLSamplerDescriptor"16
@"<MTLLibrary>"16@0:8
@"<MTLLibrary>"32@0:8@"NSBundle"16^@24
@"<MTLLibrary>"32@0:8@"NSString"16^@24
@"<MTLLibrary>"32@0:8@"NSURL"16^@24
@"<MTLLibrary>"32@0:8@"NSObject<OS_dispatch_data>"16^@24
@"<MTLLibrary>"40@0:8@"NSString"16@"MTLCompileOptions"24^@32
v40@0:8@"NSString"16@"MTLCompileOptions"24@?<v@?@"<MTLLibrary>"@"NSError">32
@"<MTLLibrary>"32@0:8@"MTLStitchedLibraryDescriptor"16^@24
v32@0:8@"MTLStitchedLibraryDescriptor"16@?<v@?@"<MTLLibrary>"@"NSError">24
@"<MTLRenderPipelineState>"32@0:8@"MTLRenderPipelineDescriptor"16^@24
@"<MTLRenderPipelineState>"48@0:8@"MTLRenderPipelineDescriptor"16Q24^@32^@40
v32@0:8@"MTLRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
v40@0:8@"MTLRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"32@0:8@"<MTLFunction>"16^@24
@"<MTLComputePipelineState>"48@0:8@"<MTLFunction>"16Q24^@32^@40
v32@0:8@"<MTLFunction>"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
v40@0:8@"<MTLFunction>"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"48@0:8@"MTLComputePipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLComputePipelineDescriptor"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLFence>"16@0:8
@"<MTLRenderPipelineState>"48@0:8@"MTLTileRenderPipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLTileRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLRenderPipelineState>"48@0:8@"MTLMeshRenderPipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLMeshRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLRasterizationRateMap>"24@0:8@"MTLRasterizationRateMapDescriptor"16
@"<MTLIndirectCommandBuffer>"40@0:8@"MTLIndirectCommandBufferDescriptor"16Q24Q32
@"<MTLEvent>"16@0:8
@"<MTLSharedEvent>"16@0:8
@"<MTLSharedEvent>"24@0:8@"MTLSharedEventHandle"16
@"<MTLIOFileHandle>"32@0:8@"NSURL"16^@24
@"<MTLIOCommandQueue>"32@0:8@"MTLIOCommandQueueDescriptor"16^@24
@"<MTLIOFileHandle>"40@0:8@"NSURL"16q24^@32
@"<MTLCounterSampleBuffer>"32@0:8@"MTLCounterSampleBufferDescriptor"16^@24
@"<MTLArgumentEncoder>"24@0:8@"<MTLBufferBinding>"16
@"<MTLDynamicLibrary>"32@0:8@"<MTLLibrary>"16^@24
@"<MTLDynamicLibrary>"32@0:8@"NSURL"16^@24
@"<MTLBinaryArchive>"32@0:8@"MTLBinaryArchiveDescriptor"16^@24
{?=QQQ}24@0:8@"MTLAccelerationStructureDescriptor"16
@"<MTLAccelerationStructure>"24@0:8Q16
@"<MTLAccelerationStructure>"24@0:8@"MTLAccelerationStructureDescriptor"16
{?=QQ}24@0:8@"MTLAccelerationStructureDescriptor"16
@24@0:8^{__IOSurface=}16
{?=II}16@0:8
B44@0:8^@16Q24^Q32i40
B24@0:8{?=II}16
@32@0:8^v16@24
@40@0:8^v16@24@32
v40@0:8@16r^v24@32
v48@0:8@16r^v24@32@40
B32@0:8@16^@24
@40@0:8@16Q24^@32
@48@0:8@16@24Q32^@40
B36@0:8@16B24^@28
@40@0:8Q16@24^@32
r^{MTLTargetDeviceArch=QI*}16@0:8
r^{?=IIIIIIIIIIIIIIIIIIIIIIIIIIffIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIQ}16@0:8
{IndirectArgumentBufferCapabilities=b1b1b1b29}16@0:8
v24@0:8^{MPSFunctionTable=}16
v40@0:8Q16^Q24Q32
B32@0:8{_NSRange=QQ}16
@48@0:8r^v16Q24Q32Q40
@56@0:8^v16Q24Q32Q40@?48
B40@0:8^{?=III}16Q24Q32
@32@0:8^v16Q24
@40@0:8^v16@24Q32
^v16@0:8
^{os_unfair_lock_s=I}16@0:8
@40@0:8@16r^{?=BQ^{?}}24^@32
@48@0:8^v16Q24@32@?40
@28@0:8@16B24
{?=QQQ}48@0:8q16Q24Q32Q40
v48@0:8@16@24@32^@40
v40@0:8@16@24^@32
@32@0:8r^@16Q24
@"MTLArchitecture"24@0:8@"NSArray"16
v24@0:8@"<MTLDeviceSPI>"16
@"<MTLDevice>"16@0:8
@"<MTLBuffer>"24@0:8^{__IOSurface=}16
B24@0:8@"NSString"16
@"<MTLCommandQueue>"24@0:8@"MTLCommandQueueDescriptor"16
@"_MTLIndirectArgumentBufferLayout"24@0:8@"MTLStructType"16
@"<MTLArgumentEncoder>"24@0:8@"_MTLIndirectArgumentBufferLayout"16
@"<MTLBuffer>"40@0:8@"MTLIndirectCommandBufferDescriptor"16Q24Q32
@"<MTLIndirectRenderCommandEncoder>"24@0:8@"<MTLBuffer>"16
@"<MTLIndirectComputeCommandEncoder>"24@0:8@"<MTLBuffer>"16
@"<MTLSharedEvent>"20@0:8I16
@"<MTLAccelerationStructure>"32@0:8Q16Q24
@"<MTLAccelerationStructure>"32@0:8@"<MTLBuffer>"16Q24
@"<MTLAccelerationStructure>"40@0:8@"<MTLBuffer>"16Q24Q32
@"<MTLAccelerationStructure>"32@0:8^v16@"MTLAccelerationStructureDescriptor"24
@"<MTLAccelerationStructure>"40@0:8^v16@"NSArray"24@"MTLAccelerationStructureDescriptor"32
@"<MTLAccelerationStructure>"32@0:8Q16@"MTLAccelerationStructureAllocationDescriptor"24
v40@0:8@"<MTLAccelerationStructure>"16r^v24@"MTLAccelerationStructureDescriptor"32
v48@0:8@"<MTLAccelerationStructure>"16r^v24@"NSArray"32@"MTLAccelerationStructureDescriptor"40
@"<MTLDynamicLibrary>"40@0:8@"<MTLLibrary>"16@"MTLComputePipelineDescriptor"24^@32
B32@0:8@"MTLDynamicLibraryDescriptorSPI"16^@24
@"<MTLDynamicLibrary>"32@0:8@"MTLDynamicLibraryDescriptorSPI"16^@24
@"<MTLDynamicLibrary>"40@0:8@"NSURL"16Q24^@32
@"NSArray"32@0:8@"MTLComputePipelineDescriptor"16^@24
@"NSArray"40@0:8@"MTLComputePipelineDescriptor"16Q24^@32
@"NSArray"40@0:8@"MTLFunction"16@"NSArray"24^@32
@"NSArray"48@0:8@"MTLFunction"16@"NSArray"24Q32^@40
B36@0:8@"<MTLLibrary>"16B24^@28
B32@0:8@"NSURL"16^@24
@"<MTLBinaryArchive>"40@0:8Q16@"NSURL"24^@32
@"<MTLVisibleFunctionTable>"24@0:8@"MTLVisibleFunctionTableDescriptor"16
@"<MTLIntersectionFunctionTable>"24@0:8@"MTLIntersectionFunctionTableDescriptor"16
@"<MTLRenderPipelineState>"32@0:8@"MTLMeshRenderPipelineDescriptor"16^@24
v32@0:8@"MTLMeshRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
@"<MTLDeadlineProfile>"24@0:8Q16
@"MTLTargetDeviceArchitecture"16@0:8
@"MTLArchitecture"16@0:8
@"MTLGPUBVHBuilder"16@0:8
v24@0:8@"NSDictionary"16
@"NSObject<OS_dispatch_data>"16@0:8
v24@0:8@"NSObject<OS_dispatch_data>"16
@"<MTLBuffer>"40@0:8Q16Q24Q32
@"<MTLBuffer>"48@0:8r^v16Q24Q32Q40
@"<MTLBuffer>"56@0:8^v16Q24Q32Q40@?<v@?^vQ>48
@"<MTLBuffer>"24@0:8@"MTLBufferDescriptor"16
@"<MTLLateEvalEvent>"16@0:8
@"<MTLComputePipelineState>"32@0:8@"MTLComputePipelineDescriptor"16^@24
v32@0:8@"MTLComputePipelineDescriptor"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
@"<MTLRenderPipelineState>"32@0:8@"MTLTileRenderPipelineDescriptor"16^@24
v32@0:8@"MTLTileRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
@"<MTLFunction>"32@0:8^v16Q24
@"<MTLFunction>"40@0:8^v16@"NSObject<OS_dispatch_data>"24Q32
v24@0:8@"MTLGPUBVHBuilder"16
@"<MTLIndirectArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLComputePipelineState>"40@0:8@"NSArray"16r^{?=BQ^{?}}24^@32
@"<MTLLibrary>"40@0:8@"NSString"16@"NSArray"24^@32
@"<MTLLibrary>"40@0:8@"NSArray"16@"NSArray"24^@32
@"<MTLLibrary>"32@0:8@"MTLStitchedLibraryDescriptorSPI"16^@24
@"NSString"24@0:8@"NSArray"16
@"<MTLLibrary>"40@0:8@"NSArray"16r^{?=BQ^{?}}24^@32
@"<MTLPipelineLibrarySPI>"32@0:8@"NSString"16^@24
v24@0:8@"NSString"16
@"NSData"16@0:8
@"NSObject<OS_dispatch_data>"24@0:8@"MTLRenderPipelineDescriptor"16
@"NSObject<OS_dispatch_data>"24@0:8@"MTLComputePipelineDescriptor"16
@"MTLRenderPipelineDescriptor"32@0:8@"NSObject<OS_dispatch_data>"16@"<MTLDeserializationContext>"24
@"MTLComputePipelineDescriptor"32@0:8@"NSObject<OS_dispatch_data>"16@"<MTLDeserializationContext>"24
@"NSObject<OS_dispatch_data>"24@0:8@"MTLStructType"16
@"NSObject<OS_dispatch_data>"28@0:8@"MTLStructType"16I24
@"MTLStructType"24@0:8@"NSObject<OS_dispatch_data>"16
@"<MTLTexture>"48@0:8^v16Q24@"MTLTextureDescriptor"32@?<v@?^vQ>40
@"<MTLTextureLayout>"28@0:8@"MTLTextureDescriptor"16B24
@"<MTLIndirectArgumentEncoder>"24@0:8@"_MTLIndirectArgumentBufferLayout"16
v48@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24@"<MTLBinaryArchive>"32^@40
v40@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24^@32
v40@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24@?<v@?@"NSError">32
@"<MTLResourceGroupSPI>"32@0:8r^@16Q24
v32@0:8@"NSObject<OS_dispatch_data>"16@"NSMutableDictionary"24
{?=[3]}16@0:8
v64@0:8{?=[3]}16
{?="columns"[3]}
@56@0:8{?=qiIq}16@40B48B52
@36@0:8@16@24f32
v36@0:8@16@24f32
Q40@0:8^v16Q24Q32
@"NSData"
v52@0:8@16@24@32^40i48
v56@0:8@16@24@32^40^i48
@48@0:8{?=qiIq}16q40
@56@0:8{?=qiIq}16q40Q48
@72@0:8{?=qiIq}16q40q48@56Q64
@"PTCinematographyTransition"
{half3x4=[3{half4=[4 ]}]}80@0:8{?=[4]}16
{half3x4=[3{half4=[4 ]}]}32@0:8i16B20B24i28
i28@0:8@16B24
{bool2=BB}24@0:8@16
i48@0:8@16@24@32i40B44
i44@0:8@16@24@32i40
i64@0:8@16@24@32@40i48i52B56i60
@48@0:8@16{?=QQQ}24
@52@0:8@16{?=QQQ}24i48
i48@0:8@1624@40
i84@0:8@16@24{?={?=QQQ}{?=QQQ}}32f80
i92@0:8@16@24@32{?={?=QQQ}{?=QQQ}}40f88
i100@0:8@16@24@32@40{?={?=QQQ}{?=QQQ}}48B96
i44@0:8@1624f32@36
i68@0:8@162440B56@60
@"PTEspressoGenericExecutor"
{?="width"i"height"i}
{?=ii}16@0:8
v24@0:8{?=ii}16
@64@0:8@16Q24{CGSize=dd}32{CGSize=dd}48
@80@0:8@16Q24{CGSize=dd}32{CGSize=dd}48{CGSize=dd}64
@76@0:8@16@24@32{CGSize=dd}40Q56B64B68i72
i36@0:8@16@24B32
i28@0:8@16i24
@36@0:8I16@20^@28
v28@0:8@16I24
I28@0:8I16@20
[5@"NSObject<PTSerializable>"]
B24@0:8f16f20
{?=[4]}16@0:8
v80@0:8{?=[4]}16
{?="columns"[4]}
@44@0:8@16@24@32B40
v24@0:8i16I20
v56@0:8@16@24@32@40@48
@52@0:8@16{?=QQQ}24f48
@56@0:8@16{?=QQQ}24f48f52
I40@0:8@16@24@32
I32@0:8@16@24
[2@"<MTLTexture>"]
@"PTDisparityFilterExponentialMovingAverageLKTMotion"
@"PTNormalEstimation"
@72@0:8@16@24@32@40@48@56@64
f024
v024
f224
v224
02fx
024x
22fx
224x
800L
sidh
@(#)PROGRAM:Portrait  PROJECT:Portrait-1
L>\3
L=\3
25;>
<sSb<^R
<sSb<nb
T09$
>333?
)))))
))))
))))))))
)))))))))
))))
))))
)))))
@@iW
*>f2
sctd
L?33
?33s?
>333@
?fff?
?fff?
<Sk?
?U0*
?U0*
@rdhvdnerbatsgtnc
hx_in
cx_in
mask
hx_out
cx_out
pred
version
_step_i
_network_detections
_last_focus_detection
models/%@
model.espresso
model.parameters
json
_x_in
_hx_in
_cx_in
_mask_in
_hx_out
_cx_out
_pred_out
-[PTCinematographyNetwork _getLeastRecentNetworkDetectionIndex]
PTCinematographyNetwork.m
self.networkDetections.count >= 2
-[PTCinematographyNetwork _setMissingDetectionAtIndex:time:]
i < _x_in.height
i < self.networkDetections.count
-[PTCinematographyNetwork _setNetworkDetection:atIndex:time:]
i <= self.networkDetections.count
_DebugLogEspressoBufferRow
index < bp->height
_DebugLogEspressoBufferColumn
index < bp->width
('%@')
atom%@: { offset: %lu, size: %lu }, data: { offset: %lu, size: %lu }%@
 (%@)
attempt to read past end %lu (offset %lu; size %lu)
PTEffectIrrUpdateCoefficientDisparity
PTEffectIrrUpdateCoefficientNormal
PTEffectSDOFixedFocusDepth
PTEffectSDOFMaxFocusDepth
PTEffectSDOFFocusOffsetDepth
PTEffectFocusDisparityExponentialMovingAverage
PTEffectLKTQuality
commandBuffer
v32@?0@"<MTLComputeCommandEncoder>"8@"PTRenderRequest"16@"<MTLTexture>"24
DetectedObjectsInfo
HumanFaces
ObjectsArray
Rect
Width
Height
PTEffectDebug
status
-[PTEffectRendererStudioLight render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:]
PTEffectRendererStudioLight.m
status == noErr && "Error executing render pipeline"
PixelFormatDescription
EquivalentUncompressedPixelFormat
+[PTPixelBufferUtil pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:]
PTPixelBufferUtil.m
MTLPixelFormatInvalid != lumaAndChromaFormats[0]
MTLPixelFormatInvalid != lumaAndChromaFormats[1]
dstTexLumaDesc
dstTexChromaDesc
user_created
track_type
track_id
group_id
detection_type
detections
-[PTEffectRendererSDOF initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:prevTemporalState:sharedResources:]
PTEffectRendererSDOF.m
effectType == PTEffectTypeSDOF
-[PTEffectRendererSDOF render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:]
estimateNormalsFromDisparity
com.apple.Portrait.AssetReader
Did not receive videoBuffer from async request
v32@?0@8@16^B24
Couldn't find video track in asset: %@
Couldn't find metadata track in asset: %@
Couldn't find disparity track in asset: %@
Cannot add videoCompositionOutput to assetReader
com.apple.quicktime.mdta
WARNING: Metadata items did not all have the same timestamp!
WARNING: Metadata sample with invalid time added!
mdta/
_alpha
_maxv
_resistance
v8@?0
version %lu is too big to fit
data size %lu is too big to fit
excludeAsCinematicChoice
isFixedPlaneFocus
isHardFocus
isFixedFocus
CinematographyParameters
detectionModel
focusBlurMapMode
_network_state
_frame_index
_previous_frame_serialized
FTCinematicTrackingResult
FocusRegion
FocusBlurMap
SensorRawValidBufferRect
RawSensorWidth
RawSensorHeight
MLSignals
anod_pose
AngleInfoRoll
AngleInfoPitch
AngleInfoYaw
GroupID
__BaseFocusTrackNumberOverride
FTTrackingResult
CinematographySnapshotEveryFrame
frame
stream detection
Raw Cinematography
CinematographyFocus
network
fixed
closest
largest
FocusMode
CinematographyDebugLogMLSignals
CinematographyDisparityWeighting
reading disparity buffer
 from %@
 (strong)
detection
FTCinematicTrackingResult (%ld) [DDR:%d]: %@
G%ld
(excluded)
T%ld%@(%zd)%@: (%g,%g,%g,%g)
attempt to write bytes at offset %lu size %lu to data of length %lu
flatten
com.apple.portrait
core
kColorSize
kRaycount
kRadiusLocal
kRadiusLocalFraction
kRayMarch
kDiameterCoverageLimit
kFocusBlendCoefficients
kCoverageOverscan
kRayMarchDisparityRadiusTolorance
kSkipFullSizeLayer
raytracingV2002
DDiff
RGBWeightUpscaled
RaytracingDependencies
computeEncoder
v16@?0@"<MTLCommandBuffer>"8
PortTypeBack
PortTypeFrontInfrared
PortTypeFront
PortTypeBackTelephoto
kIIRUpdateCoefficients
kMotionThresholdMinMax
kDirection
kMotionCorrectionFunction
temporalFilterDEMA_LKT
temporalFilterDEMA_LKT_VisualizeMotion
resampleDisparity
-[PTCinematographyFocusFrames startIndexForLinearRackFocusPullToFrameAtIndex:]
PTCinematographyFocusFrames.m
startIndex >= 0
-[PTCinematographyFocusFrames _framesIndex:earlierBy:]
index < _frames.count
com.apple.quicktime.cinematography-dictionary
com.apple.quicktime.camera-dictionary
com.apple.quicktime.cinematic-video
com.apple.quicktime.cinematic-video.cinematography
com.apple.quicktime.cinematic-video.rendering
com.apple.quicktime.cinematic-video.stabilization
_version
focus_puller
user_aperture
ptime
aperture
alphaLowLight
disparity
focus_blend
trackers
user_track_id
base_track_id
user_focus_strong
user_focus_group
detector_did_run
focus_track_id
transition_coefficient
transition_elapsed_time
transition_duration
attributes
focus_id
rect
label
detected_object_id
user_track
coefficients
detected_rect
Invalid parameter
Odd image dimensions are not supported
Unknown preset
LKT::KeypointsFromFlow
The number of scales specified is too large
+[LKTFlowGPU _computeScalingFactor:dst_tex:scale_xy_inv:coeff:]
LKTFlowGPU.m
(dst_tex.width == src_tex.width) && (dst_tex.height == src_tex.height)
Unidentified Metal format
lkt_bgra2yuva
lkt_zero_flow
lkt_downscale_2x
lkt_features
lkt_features_derivatives
lkt_solver_prepare_matrices
lkt_solver_box_y
lkt_solver_box_x_and_Axb
lkt_flow_consistency
lkt_keypoints_from_flow
lkt_nlreg_hegbf
lkt_copy
params
timer_seconds_divisor
Unknown
kWeights2DRow0
kWeights2DRow1
temporalFilterExponentialMovingAverageLKTMotion
temporalFilterExponentialMovingAverageLKTMotionNormal
copyDisparityWithBias
PortraitDump
PTDisparityFilterLKTQuality
PTImageBufferTransferFunction_Linear_1_6
width_height
geomean
warpTexture
v24@?0Q8^B16
flow
focusPos
regions
enabled
sizeX
sizeY
startX
startY
tileSizeX
tileSizeY
tileCountX
tileCountY
tiles
defocus
conf
flags
valid
flat
level
guidedFilterAverageUpsamplingCoefficients
_averageUpsamplingCoefficients
guidedFilterApplyUpsamplingCoefficients
_applyUpsamplingCoefficients
guidedFilterComputeUpsamplingCoefficients
_computeUpsamplingCoefficients
computeWeightedUpsamplingCoefficients
_computeWeightedUpsamplingCoefficients
GuidedFilter
temporalFilterExponentialMovingAverageColorSimilarities
+N9mZUAHooNvMiQnjeTJ8g
com.apple.portrait.effect_init
-[PTEffect initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:prewarmOnly:effectQuality:]
PTEffect.m
(activeEffectType == PTEffectTypeNone ) || (activeEffectType == PTEffectTypeSDOF) || (activeEffectType == PTEffectTypeStudioLight) || (activeEffectType == (PTEffectTypeSDOF | PTEffectTypeStudioLight) )
PortTypeBackSuperWide
Invalid size of inRGBA
Invalid size of outDisplacement
Invalid size of inDisparity
Invalid size of inDisplacement
Invalid size of inDisparityPrev
Invalid size of outDisparity
Invalid size of outDisparityFiltered
zero_label
remap
DictionaryFromRemapParam
PTCinematographyNetworkLabelSignal.m
[element isKindOfClass:[NSNumber class]]
descr
_guidedFilter
guidedupscale
Raymarch all
Raymarch adaptive
1-step
%@. Circles: %i. upscale-disp:%f %@
FirstLevelGaussianDownsample
PTEffectShowFaceRects
-[PTTensorSwapPair initWithIOSurfaces:names:]
PTEspressoGenericExecutor.m
status == noErr
unInterleaveTexture
monocular-depth-sync
-[PTEspressoGenericExecutor initWithUrl:inputNames:outputNames:tensorSwapNames:device:library:pipelineLibrary:commandQueue:reshape:configuration:]
_ctx
eStatus == ESPRESSO_STATUS_SUCCESS
-[PTEspressoGenericExecutor bindBuffers:toMap:withMode:]
v16@?0^{?=ii*}8
com.apple.portrait.serialization
PTSerializationVersionKey
-[PTMSRResize initWithDevice:commandQueue:inputSize:target:rotateTargetPixelBuffer:sharedResources:]
PTMSRResize.m
_allocatedIOSurfaces < MAX_DOWNSAMPLING_STEPS
lightEstimation
com.apple.portrait.srl_async_queue
-[FloatArray floatAtIndex:]
FloatArray.m
index < _count
-[FloatArray subtracting:]
_count == array->_count
-[MutableFloatArray floatAtIndex:]
-[MutableFloatArray setFloat:atIndex:]
-[MutableFloatArray setFloat:inRange:]
NSMaxRange(range) <= _count
-[MutableFloatArray setFloats:inRange:]
-[MutableFloatArray appendFloat:]
!"out of memory allocating FloatArray buffer"
parallelReductionTextureSimd
error == nil
parallelReductionTextureMinMaxSimd
GlobalReductionSimd
parallelReductionAverage
parallelReductionMax
parallelReductionMin
GlobalReduction
MaskThreshold
MinFaceSize
MaxCurveBoost
MinCurveBoost
MaxTargetRatioDarkening
MaxTargetRatioLimit
BiasFactorSRLv2
ToneSimilaritySigma
FaceExpDifThreshold
TargetMedian_I
TargetMedian_II
TargetMedian_III
TargetMedian_IV
TargetMedian_V
TargetMedian_VI
MaxBoost_I
MaxBoost_II
MaxBoost_III
MaxBoost_IV
MaxBoost_V
MaxBoost_VI
srlV2GlobalSparseHistogramLivePhotos
srlV2FaceSparseHistogramLivePhotos
srlV2CalcCoefficientsLivePhotos
BackWide-IQTuning
plist
DeepFusionParameters
ToneMapping
DefaultParameters
SRLv2
UNKNOWN_17_unknown0
%@ (DDR:%@, pts:%@)
renderRequest.sourceColor.width == (int)_desc.colorInputSize.width && renderRequest.sourceColor.height == (int)_desc.colorInputSize.height
renderRequest.destinationColor.width == (int)_desc.colorOutputSize.width && renderRequest.destinationColor.height == (int)_desc.colorOutputSize.height
[renderRequest.sourceColor.transferFunction isEqual:renderRequest.destinationColor.transferFunction] || (renderRequest.sourceColor.transferFunction == nil && renderRequest.destinationColor.transferFunction == nil)
%02X 
%c%c%c%c
kRaytracingRaycount
kDisableForegroundBlur
raytracingV14
RGBRadiusUpscaled
%@, Rays: %i
Refined Cinematography
linear rack focus
CaptureMTLDevice
-[PTMTLDropHints setDropHintsFor:]
PTMTLDropHints.m
_count == 0
-[PTMTLDropHints dropHintsFor:]
_count == 1
centerDisparityOnFocus
_centerDisparityOnFocus
sobelEdgeDetector
_sobelEdgeDetector
edgeDilation
_edgeDilation
focusEdgeMask
_focusEdgeMask
kColorTransferFunctionToLinear
interpolateRGBRadiusToDestYUV
_interpolateRGBRadiusToDestYUV[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestYUVFromSource
_interpolateRGBRadiusToDestYUVFromSource[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestRGB
_interpolateRGBRadiusToDestRGBA[colorTransferFunctionToLinear]
interpolateRGBRadiusToDestRGBFromSource
_interpolateRGBRadiusToDestRGBAFromSource[colorTransferFunctionToLinear]
convertRGBPyramid
_convertRGBPyramid[colorTransferFunctionToLinear]
convertRGBPyramidFromYUV
_convertRGBPyramidFromYUV[colorTransferFunctionToLinear]
updateFocusObject
effectSampleFaceRects
convertToDisparity
fixedFocusDistanceAndCenterDisparity
copySingleChannel
copyRGBAToBGRA
clear
_effectSampleFaceRects
__rect
__uncertainty
__label_onehot
name
count
PTCinematographyDetectionTypeHuman
person
PTCinematographyDetectionTypePet
PTCinematographyDetectionTypeSportsBall
sports ball
PTCinematographyDetectionTypeDefault
object
com.apple.coremedia
_snapshot
_snapshot_policy
_raw_disparity
-[PTCinematographyFrame focusTrackIdentifier]
PTCinematographyFrame.m
self.focusDetection.trackIdentifier == result
Frame: %@ [%@] (%@, %@)
; userFocusTrackNumber: %@ %@%@
raytracingV2001
centerDisparityOnFocusV2
sobelEdgeDetectorV2
edgeDilationV2
focusEdgeMaskV2
expected_fps
forget_after_seconds
sync_with_detector
supported_detection_types
input_schemas
_timeForObject: error: object %@ is neither a time value nor an object that responds to %@
q24@?0@8@16
temporalFilterExponentialMovingAverageLKT
kDisparityFilterStepWidth
kDisparityFilterType
studioLight
createLightMask
relightFullsizeInput
studioLightDebug
lightMaskForDebug
fgBgForDebug
lightMaskOutline
filterLightGainApplyToRGB
_filterLightGainApplyToRGB
PTEffectRelighting
user_decisions
user_tracks
track_allocator
com.apple.Portrait.CinematographyScript
com.apple.Portrait.CinematographyScript.serialQueue
Failed to read AVAsset: %@
Value for %@ key is of unexpected type: %@ for frame index %lu
CinematographyDictionary
No %@ key in metadata for frame index %lu
Failed to parse cinematography metadata for frame %lu. Dictionary: %@
v20@?0B8@"NSError"12
 within %@
%@%@%@-%lu
%@: %@: %@ focus: %g
%@, rect: %@, focusDistance: %@, trackID: %@
texDesc
LeftEyeRect
RightEyeRect
FaceID
ConfidenceLevel
stabilizationHomography is optional metadata and hasn't been found.
estimatedMotionBlur is optional metadata and hasn't been found.
primary
secondary
coefficient
FocusBlend(%@: %@; %@: %@)
attempt to read bytes at offset %lu size %lu from data of length %lu
options
is_user
min_duration
max_duration
Base
User
%@: [%@] T%@ G%@ %@%@
convertRGB
_convertRGB[i]
convertRGBToYUV
_convertRGBToYUV[i]
convertYUVToRGB
_convertYUVToRGB[i]
Cannot load bundle from %@
assignAndWatchKernel
renderDisparity
_renderDisparity
copy
_kernelCopy
multiplyTex
_multiplyTex
addConstant
_addConstant
fillWithColor
_fillWithColor
reciprocal
_reciprocal
sobelFilter
gaussianNoise
_gaussianNoise
renderRect
_renderRect
visualizeCircleUsingRect
_visualizeCircleUsingRect
drawTurboLegend
_drawTurboLegend
drawTurboLegendYUV
_drawTurboLegendYUV
gaussianFilter3x3
_gaussianFilter3x3
dd-MM-yyyy_HHmmss
originalVideoDimensions is optional metadata and hasn't been found.
%ld.%d
%ld.%d.%d
descriptor != nil
i-disp: %lux%lu u-disp: %lux%lu colorInput: %lux%lu colorOutput: %lux%lu
downscaleGaussian3x3
updateLevel0Box2x2FromRGBA
updateLevel0Box2x2FromYUV
updateLevel0Gaussian3x3FromRGBA
updateLevel0Gaussian3x3FromYUV
updateLevel0and1Gaussian3x3FromRGBA
updateLevel0and1Gaussian3x3FromYUV
PTPyramidRGB
com.apple.Portrait.RenderingMetadata
interpolateRGBWeightSourceYUVDestRGBA
_interpolateRGBWeightSourceYUVDestRGBA[colorTransferFunctionToLinear]
interpolateRGBWeightSourceYUVDestYUV
_interpolateRGBWeightSourceYUVDestYUV[colorTransferFunctionToLinear]
interpolateRGBWeightSourceRGBADestRGBA
_interpolateRGBWeightSourceRGBADestRGBA[colorTransferFunctionToLinear]
studioLightInterpolateRGBWeightSourceYUVDestYUV
_studioLightInterpolateRGBWeightSourceYUVDestYUV[colorTransferFunctionToLinear]
unable to find espresso model for version in %@
cannot find espresso model for version %@
no model parameters json file for version %@
malformed model.parameters.json for version %@
network version %@
espresso error loading network %@
network repeating last decision
network repeating last decision, but there is none, so autofocus
network inputs:
network outputs:
ignoring network decision to focus on stale track: %@
network forgetting stale detection: %@
espresso error unable to create context for engine %d on default system device
espresso error unable to create plan for engine %d on default system device
espresso error %d loading network %@
espresso error %d building plan for %@
espresso error %d binding %@ to %s
espresso error binding network (_x_in.height == %zd)
raw prediction: %zd
error: network predicts disabled index %@
_setMissingDetection[%ld]
_setNetworkDetection[%ld]: %@
espresso array count %@ 
 buffer count %@
%zu: %@
r[%zd]: %@
Format description does not have kCMFormatDescriptionExtension_TransferFunction. Using value kCMFormatDescriptionTransferFunction_ITU_R_709_2
Format description does not have kCMFormatDescriptionExtension_YCbCrMatrix. Using value kCMFormatDescriptionYCbCrMatrix_ITU_R_601_4
defaults write com.apple.coremedia PTEffectIrrUpdateCoefficientDisparity %f
defaults write com.apple.coremedia PTEffectIrrUpdateCoefficientNormal %f
defaults write com.apple.coremedia PTEffectSDOFixedFocusDepth %f
defaults write com.apple.coremedia PTEffectSDOFMaxFocusDepth %f
defaults write com.apple.coremedia PTEffectSDOFFocusOffsetDepth %f
defaults write com.apple.coremedia PTEffectFocusDisparityExponentialMovingAverage %f
PTRenderEffectNetwork is nil
defaults write com.apple.coremedia PTEffectLKTQuality %i
PTMSRResize init failed
Assertion failed %s
PTEffectRendererSL init failed
Assertion failed %s %i
Unable to determine appropriate metal pixel format for CVPixelBuffer of pixel format type = %x %@
Issue with pixelformat %@ %i for pixelbuffer %p
Cannot allocate textures for pixel format %@ %i for pixelbuffer %p
Unknown pixel format %x %c%c%c%c
Not found %i
Not found %lu
attempt to get detections in time range for continuous track %@
PTEffectRendererSDOF init failed
WARNING: meta timeRange (%@) not equal to vide timeRange (%@)
WARNING: auxv timeRange (%@) not equal to vide timeRange (%@)
ERROR: couldn't calculate frame count
Failed to deserialize global rendering metadata: %@
Failed to deserialize global stabilization metadata: %@
Failed to deserialize global cinematography metadata: %@
Failed to deserialize global video header metadata: %@
ERROR: Failed to find global metadata.
ERROR: Failed to decode metadata dictionary for %@. Value is not NSData.
ERROR: Failed to decode metadata dictionary for %@. Decoder failed: %@
Failed to deserialize timed rendering metadata: %@
Failed to deserialize timed stabilization metadata: %@
Failed to deserialize cinematography metadata: %@
Failed to get composed frame %lu from custom compositor
Failed to decode auxv buffer for frame %lu. Format was not 'kCVPixelFormatType_DisparityFloat16'
Failed to set parameter %d to non-numeric CMTime value %@
Failed to set parameter %d to CMTime value %@ using scale %d
Failed to get parameter %d of type %d. Unknown type.
Couldn't find parameter %d in parameter pair list.
focus puller: EMA (alpha: %g, sampleCount: %lu)
focus puller: EMA (sampleCount: %lu, alpha: %g)
focus puller: weighted dial (maxv: %g, resistance: %g)
w[+]: %@
w[%zd]: %@
stream options requested unsupported version %@
init with detection model %@
init with focus blur map mode %@
change from detection model %@ to %@
change from focus blur map mode %@ to %@
Frame: %@
end of cinematography stream
unexpected global metadata class %@
user focus: no longer detected
user focus: base focus changed after user focus lock expired
user focus: fixed focus depth changed after lock expired
error: user focus on unknown group %@
error: user focus on unknown track %@
unable to restore internal state of class %@
attempt to restore internal state to unsupported version %@
stream state missing network state
stream state has invalid network
Cinematography network version %@ (restored)
CinematographyAperture: %g
Cinematography network version %@
focus puller: %@
defaults: CinematographyFocus %@
user tap %@ ends due to depth change of %.1f%% (from disparity %.3f to %.3f)
fixed focus user tap at point %@ (rect %@; disparity %@)
user tap response missing request
user tap response/request unknown (ignored)
user tap %@ abandoned since detection %@ is marked as excluded as cinematic choice
error: FusionTracker information not provided in metadata
Synthetic DDR:%d
Setting DDR:1 for the first frame seen by cinematography
FusionTracker: %@
*** error: FT track %ld(%zd) with empty box (%g,%g,%g,%g) - skipping
auto focus mode: %@
auto focus rect: %@
no ISP detections; copying from prior frame (once)
error: FusionTracker: track with negative identifier (%@)
%@ named signals: %@
defaults: CinematographyDisparityWeighting: %@
raw focus %zd: %g
auto focus %zd: %g
cinematography focus change%@ to %@
user tap at (%g,%g) focus distance %g
user tap on track %@%@
unusual %@ disparity %@ (%@)
not enough room to write signal for network payload
Expected %ld values for named signal %@, got %ld values
unimplemented transition kind %ld
Commandbuffer Error %@
PTDisparityFilterDEMA_LKT init failed
Invalid filtered prev size
Bias is no longer supported
CinematographyMinPullTime: %@
CinematographyMaxPullTime: %@
CinematographyMaxDisparityPerSecond: %@
focus frames does not support global cinematography metadata version %d
LKTFlowGPU Init failed
newBufferWithLength failed
_G0_tex[%i] is nil
_G1_tex[%i] is nil
_C0_tex[%i] is nil
_C1_tex[%i] is nil
_w_tex[%i] is nil
_uv_fwd_tex[%i][%i] is nil
_uv_bwd_tex[%i][%i] is nil
Unsupported
Should be overwritted
lktflowgpuContext estimateFlowFromTexReference returned %i
Changing displacement textures is only valid when allocateDisplacementFWD is false
ignoring blur map with tile count %@ - too big
Not supported
effectType %i
updateEffectDelegate failed %i
Schedule set effect type: %i async: %i forceImmediatePassthrough: %i
Completed set effect type: %i
PTEffectRendererSDOF is nil
Unexpected effectType. Was %lu expected %lu
Should never happen
Releasing reference to %@
Failed to prewarm PTEffect SDOF (%d)
Failed to prewarm PTEffect SL (%d)
Error updateEffectDelegate
No detections found
Change quality from %lu to %lu
Disparity size must equal color size
Failed to prewarm PTDisparityPostProcessing (%d)
PTDisparityUpscale Cannot allocate texture
Error espresso plan add network: %s for %@
Error espresso set priority: %s for %@
network version: %s
unknown version of espresso model loaded
Error espresso_network_select_configuration: %s for %@
Espresso error building plan: %s for %@
Espresso cannot bind input buffer %s for %@
Expresso cannot bind output buffer %s for %@
espresso_network_bind_buffer %@ failed
Name %@ not found
espresso_network_bind_cvpixelbuffer: espresso error %s for %@
espresso_plan_execute_sync: espresso error %s for %@
espresso_plan_submit callback. %s %i %i for %@
espresso_plan_submit: espresso error %s for %@
AppleDepth not available
attempt to register class %@ for serialization that does not support PTSerialization protocol
registering atom type %@
error reading detection from container
CVPixelBufferCreate failed %i
IOSurface not found
IOSurface not found. Rotation
No MSR support
MSR only
Failed allocating PTSegmentationNetwork
PTGlobalReduction init failed
Cannot load plist
excluding %@ as best detection for group %@
Disable drop hints
Changing renderingVersion after initialization not supported
warning: snapshot missing from refined frame %@
Cinematography refinement <%p> start recording
Cinematography refinement <%p> stop recording
error: frames in smoother after recording stopped
Cinematography %@ from frame %ld (%@) to frame %ld (%@)
PTMTLDropHintsInFlight setEnabled: %i
FocusDistance will be clipped during rendering. Was %f
warning: no detection found from legacy coefficients dictionary %@
%@ Frame %@: focus %@ (%@), disparity %@, aperture %@%@ rect { %.3f, %.3f, %.3f, %.3f }
error: focusing on nothing
stack trace: %@
prepareForPerformingRequests failed %@
Private variant unsupported. Using default behavior. Error: %@
request nil
error %@ reading network parameters %@
expected a dictionary, got a %@ from network parameters %@
lightGainMapScale: %f
Must be equal size
WARNING: frameCount estimate was off. %lu frames expected, but only %lu were read
Effective decisions: %@
Track decisions: %@
unsupported globals version %@
internalizing user decision %@ end at %@
internalizing user focus end without prior user decision
internalizing user decision %@
userFocusTrackNumber %@ has no corresponding detection on frame %@. No user decision was added.
attempt to set user aperture to non-positive value ignored
finished updating frames for decisions in index range %@
track doesn't change across adjacent decisions (%@; %@)
did shorten transition from track %lu to track %lu
error: no frames in transition from %@ to %@ time range %@ to %@
error: cannot find current or prior detection for decision %@
error: endingDecision at %@ (%@) past end of frames at %@ (%@)
cannot find detections of track %@ at or before index %@%@
cannot find detections of group %@ at or before index %@%@
updating frames %lu to %lu to focus on track %lu
updating frames %lu thru %lu to rack focus from track %lu to track %lu
updating frames %lu thru %lu to fill in gap in track %lu
frame %lu: normalizedTime: %@
internalizing base decision %@
baseFocusTrackNumber %@ has no corresponding detection on frame %@. No base decision was added.
warning: unable to add detections from non-custom track %@
error: detection missing both trackIdentifier & focusIdentifier: %@
error: detection missing trackIdentifier: %@
focusOnTrackIdentifier:atTime: time %@ is not numeric
focusOnTrackIdentifier:atTime: No such %li trackIdentifier
focusOnGroupIdentifier:atTime: time %@ is not numeric
adding user decision %@
Adding group user decision with no corresponding detection: %@
removing all user decisions %@
removing all user decisions
removing user decision %@
attempt to remove non-user decision %@
attempt to remove decision not found: %@
track %@ already added
error: track %@ already belongs to another script
track %@ already removed
error: attempt to remove track %@ from a different script
Adding track %@ (%@)
Removing track %@ (%@)
attempt to add track with invalid group identifier %@ (%@)
Adding group track %@ (%@) with group identifier %@
error: addTrack: track detection at time not present in script: %@
Primary decision %@ is user decision, but previous user decision %@ has maximum duration %@ that ends before trim starts %@
trackIdentifier missing from original detection %@
error: detection missing track identifier (%@)
SingleColorCubeCorrectionStage: cannot load 3d LUT from data!
GroupID / FaceID not found
hanging focus track id %ld (%@?) with mismatching last known detection: %@
error: attempt to read from nonexistent focus smoother for track %@
error: focus detection smoothers remain when none expected
detection type: %ld rect: { %.3f, %.3f, %.3f, %.3f } disparity: %.3f
error: histogram - unexpected pixel format type '%@' (%zdx%zd) - must be DisparityFloat16 or DisparityFloat32
error: attempt to create user tap with nil detection track number
Tracing enabled
PTRenderPipeline only supports transferFunctions: kCMFormatDescriptionTransferFunction_ITU_R_709_2, kCVImageBufferTransferFunction_ITU_R_2100_HLG, kCVImageBufferTransferFunction_Linear
PTRenderPipeline only supports transferFunctions: kCMFormatDescriptionTransferFunction_ITU_R_709_2, kCVImageBufferTransferFunction_ITU_R_2100_HLG
Unsupported bit depth: %d
Unsupported matrix type: %d
Cannot load bundle from %@
Error creating library %@ from %@
Error creating pipeline library %@ from className %@. Falling back to MTLLibrary
Unable to create function (%s): %s
Metal shader compilation warnings: %s
PortraitRuntimeAPIVersion %i
PTRenderPipeline requires Metal support for Non Uniform Threadgroup Size
prepareForRendering failed
Failed to prewarm PTRenderPipeline (%d)
minimumResourceHeapSize currently unsupported
setResourceHeap currently unsupported
PTPyramidRGB init failed
r[+]: %@
PTCinematographyNetwork
PTAtomStream
PTEffectRendererStudioLight
PTEffectImpl
NSObject
PTPixelBufferUtil
PTCinematographyTrack
PTCinematographyFixedFocusTrack
PTCinematographyExistingTrack
PTCinematographyExistingGroupTrack
PTCinematographyCustomTrack
PTEffectRendererSDOF
PTNormalEstimation
PTAssetReaderComposedFrame
PTAssetReaderCompositionInstruction
AVVideoCompositionInstruction
PTAssetReaderCustomCompositor
AVVideoCompositing
PTAssetReaderFrame
PTAssetReader
PTParameterPairSerialization
PTCinematographyFocusPuller
PTAtomWriter
PTCinematographyStreamOptions
NSCopying
NSMutableCopying
PTCinematographyStream
PTDataByteWriter
PTByteWriter
PTCinematographyFocusSmoother
PTCinematographyNetworkNamedSignal
PTCinematographyTransition
PTRaytracingV2002
RenderingIntegration
PTDisparityFilterDEMA_LKT
PTAbstractDisparityFilter
PTCinematographyFocusFramesOptions
PTCinematographyFocusFrames
CinematographyDictionary
LKTFlowGPU
PTCinematographyTrackAllocator
PTCinematographyNetworkUncertaintySignal
PTTuningParameters
PTDisparityFilterPassThrough
PTDisparityFilterExponentialMovingAverageLKTMotion
PTRenderRequest
PTTexture
PTCinematographyNetworkRectSignal
PTOpticalFlow
PTGlobalCinematographyMetadata
PTSerializable
PTGlobalCinematographyMetadataVersion1
ExtendedIndexSet
PTFocusBlurMap
PTGuidedFilter
PTDisparityFilterColorSimilarity
PTEffect
PTDisparityPostProcessingDescriptor
PTDisparityPostProcessing
PTTextureRGBA
PTTextureYUV420
PTCinematographyNetworkLabelSignal
PTDisparityUpscale
PTQualitySettings
PTEffectDebugLayer
PTTensorSwapPair
PTEspressoGenericExecutor
PTRenderEffectNetwork
PTSerializationTypeInfo
PTSerialization
PTTimedRenderingMetadata
PTTimedRenderingMetadataVersion1
Serialization
PTArraySerialization
PTMSRResize
PTSyntheticLight
FloatArray
MutableFloatArray
PTGlobalReduction
SRLv2Plist
PTSubjectRelighting
PTCinematographyFrameDetections
PTRenderPipelineState
PTRenderState
PTRaytracingV14RenderState
PTRaytracingV14
PTCinematographyRefinementOptions
PTCinematographyRefinement
PTMTLDropHintsInFlight
PTMTLDropHints
PTScanlineMask
PTScanlineMask_FocusBlurMap
PTScanlineIter_FocusBlurMap
PTScanlineIter
PTRaytracingUtils
PTRenderDebugLayer
PTTapToTrackPrediction
PTTapToTrack
PTEffectUtil
PTCinematographyNetworkPayload
PTCinematographyNetworkFloatOutputStream
PTCinematographyNetworkSignal
PTCinematographyFrame
Private
PTFaceAttributesNetwork
PTRaytracingV2001
PTRaytracingUtilsV2
PTCinematographyNetworkInputSchema
PTCinematographyNetworkParameters
Cinematography
PTDisparityFilterExponentialMovingAverageLKT
PTEffectRelighting
PTCinematographyScript
PTCinematographyDetection
PrivateCinematographyDictionary
SingleColorCubeCorrectionStage
PTHumanDetections
PTMTLDeviceProxy
MTLDeviceSPI
MTLDevice
PTCinematographyFrameDetectionSmoother
PTGlobalVideoHeaderMetadata
PTGlobalVideoHeaderMetadataVersion1
PTTimedStabilizationMetadata
PTTimedStabilizationMetadataVersion1
PTCinematographyUserTap
PTCinematographyFocusBlend
PTDataByteStream
PTByteStream
PTEffectTemporalState
PTCinematographyDecision
PTColor
PTUtil
PTEffectResources
PTGlobalStabilizationMetadata
PTGlobalStabilizationMetadataVersion1
PTRenderPipelineDescriptor
PTRenderPipeline
PTPyramidRGB
PTGlobalVideoMetadata
PTGlobalRenderingMetadata
PTGlobalRenderingMetadataVersion1
PTRaytracingInterpolateResult
PTEffectFilter
PTSegmentationNetwork
containsObject:
indexSetWithIndex:
removeObjectAtIndex:
isCancelled
errorWithDomain:code:userInfo:
boundingBox
lastObject
containsIndex:
setHeight:
indexSet
indexOfObject:inSortedRange:options:usingComparator:
defaultANEDevice
setPixelFormat:
writeToFile:atomically:
startReading
removeObject:
setDepth:
setPipelineLibrary:
selector
removeIndex:
boolValue
indexGreaterThanIndex:
getBytes:range:
enumerateKeysAndObjectsUsingBlock:
objectForKeyedSubscript:
enumerateIndexesUsingBlock:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
setThreadGroupSizeIsMultipleOfThreadExecutionWidth:
removeAllObjects
invokeWithTarget:
getBytes:length:
sourceFrameTimestamp
allValues
firstObject
setGPUPriority:
initWithDevice:filterDescriptor:
objectAtIndexedSubscript:
setTextureType:
naturalSize
sourceFrameByTrackID:
setDateFormat:
threadExecutionWidth
JSONObjectWithStream:options:error:
firstIndex
textureType
computeCommandEncoder
setObject:forKeyedSubscript:
setTexture:atIndex:
setObject:forKey:
compositionTime
endEncoding
numberWithUnsignedLong:
initWithObjects:
label
setCustomVideoCompositorClass:
allObjects
identifier
unsignedLongValue
componentsSeparatedByString:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setObject:atIndexedSubscript:
numberWithUnsignedInteger:
prepareForPerformingRequests:error:
allLabelsWithConfidences
sortUsingSelector:
finishWithError:
date
numberWithUnsignedInt:
commit
allKeys
CMTimeRangeValue
dictionaryWithObjects:forKeys:count:
setConstantValue:type:withName:
encodeRegressionToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationCoefficientsTextureArray:
dictionaryWithContentsOfURL:error:
finishWithComposedVideoFrame:
unsignedIntegerValue
setNormalizedCoordinates:
dataWithLength:
numberWithLongLong:
dictionaryWithCapacity:
setFrameDuration:
setConstantValue:type:atIndex:
dataWithBytesNoCopy:length:freeWhenDone:
unsignedIntValue
setSourceTrackIDForFrameTiming:
numberWithLong:
encodeReconstructionToCommandBuffer:guidanceTexture:coefficientsTextureArray:destinationTextureArray:
commandBuffer
dictionaryRepresentation
items
preferredTransform
numberWithInteger:
UTF8String
predictRectForPoint:inColorBuffer:
initWithLength:
wasSuccessful
dataWithBytes:length:
mutableCopy
unarchivedObjectOfClasses:fromData:error:
setComputePipelineState:
mutableBytes
hasSuffix:
numberWithInt:
dictionary
waitUntilScheduled
setComputeFunction:
isValidJSONObject:
setMipmapLevelCount:
mipmapLevelCount
numberWithFloat:
setCompletedUnitCount:
waitUntilCompleted
numberWithDouble:
hasPrefix:
duration
integerValue
dropResourceGroups:count:
pointCount
numberWithBool:
intValue
videoTracks
addOutput:
addObjectsFromArray:
insertObject:atIndex:
reverseObjectEnumerator
videoCompositionInstruction
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
results
setSamplerState:atIndex:
normalizedPoints
setMinFilter:
formatDescriptions
fileURLWithPath:
fileExistsAtPath:
addObject:
setRevision:error:
resourcePath
tapResponse
nominalFrameRate
setWithArray:
methodForSelector:
addIndex:
code
VN3iT1YRjjnIuELobV1olJiO1vvItN6Kdq
tapPoint
setWidth:
facemaskCategory
pixelFormat
setResourceGroups:count:
inputStreamWithURL:
tracksWithMediaType:
setResourceOptions:
addEntriesFromDictionary:
assetReaderWithAsset:error:
performRequests:onCVPixelBuffer:orientation:error:
metadataForFormat:
trackerWithCommandQueue:
setVideoComposition:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
nextTimedMetadataGroup
faceAttributes
pathForResource:ofType:inDirectory:
setMagFilter:
doubleValue
initWithCapacity:
valueWithRect:
arrayWithObjects:count:
setRenderSize:
path
arrayWithObjects:
request
valueWithCMTimeRange:
replaceRegion:mipmapLevel:withBytes:bytesPerRow:
valueWithCMTime:
addCompletedHandler:
countByEnumeratingWithState:objects:count:
replaceRegion:mipmapLevel:slice:withBytes:bytesPerRow:bytesPerImage:
initWithVideoTracks:videoSettings:
subarrayWithRange:
trackId
arrayWithCapacity:
setBytes:length:atIndex:
valueForKey:
replaceObjectsInRange:withObjectsFromArray:
setBuffer:offset:atIndex:
array
trackID
stringWithUTF8String:
initWithUTF8String:
value
replaceBytesInRange:withBytes:length:
cancelReading
initWithAssetReaderTrackOutput:
stringWithCharacters:length:
stringWithFormat:
maxTotalThreadsPerThreadgroup
copyNextSampleBuffer
setLabel:
stringFromDate:
URLForResource:withExtension:subdirectory:
newTextureViewWithPixelFormat:textureType:levels:slices:
canAddOutput:
callStackSymbols
exceptionWithName:reason:userInfo:
newTextureViewWithPixelFormat:
stringByAppendingFormat:
stringByAppendingString:
dispatchThreads:threadsPerThreadgroup:
getReturnValue:
dispatchThreadgroups:threadsPerThreadgroup:
deleteCharactersInRange:
longValue
initWithTrack:outputSettings:
appendString:
localizedStringForKey:value:table:
getObjects:range:
newFunctionWithName:constantValues:pipelineLibrary:error:
appendFormat:
isEqualToString:
newFunctionWithName:constantValues:error:
setUsage:
isEqualToNumber:
setAlwaysCopiesSampleData:
stepTrackingWithFrame:
open
setProcessingDevice:
newFunctionWithName:
observationWithBoundingBox:
setInstructions:
setInputFaceObservations:
bytes
status
startTrackingRect:colorBuffer:
progressWithTotalUnitCount:
CMTimeValue
removeObjectsInRange:
objectKind
appendBytes:length:
isEnabled
initWithSuiteName:
contents
length
defaultManager
removeObjectForKey:
bundleForClass:
initWithSession:
init
dealloc
defaultVersionString
defaultVersionStringForDetectionModel:
firstExistingVersion:
existsVersionString:
earliestVersionString
latestVersionString
T@"NSString",R
initWithVersionString:
_initWithNetwork:parameters:
expectedFPS
stepWithFrameDetections:
_updateLastNetworkPredictionIndex:time:
_isNetworkCompatibleDetectionType:
_loadEspressoNetwork:
_shouldIgnoreNetworkPredictionIndex:time:
_allNetworkDetectionsAreStaleAtTime:
_setNetworkDetectionsFromFrameDetections:
_setNetworkInputsFromNetworkDetections
_networkPredictionIndex
_detectionAtNetworkIndex:frameDetections:
_setDetection:asInputRow:time:missing:
_initWithCinematographyDictionary:
_asCinematographyDictionary
_getLeastRecentNetworkDetectionIndex
_forgetNetworkDetectionAtIndex:
_forgetNetworkDetectionsOlderThan:
_allocateNetworkDetectionIndex
_setMissingDetectionAtIndex:time:
_shouldResetDetectionFromType:toType:
_setNetworkDetection:atIndex:time:
_debugLogNetworkInputs
_debugLogNetworkOutputs
_debugLogAllNetworkInputs
versionString
params
inputSignals
zeroDisparityDetection
networkDetections
unusedIndexes
lastFocusDetection
setLastFocusDetection:
lastNetworkPredictionIndex
setLastNetworkPredictionIndex:
lastNetworkPredictionTrackID
setLastNetworkPredictionTrackID:
.cxx_destruct
_step_i
_context
_plan
_network
_x_in
_hx_in
_cx_in
_mask_in
_hx_out
_cx_out
_pred_out
_versionString
_params
_inputSignals
_zeroDisparityDetection
_networkDetections
_unusedIndexes
_lastFocusDetection
_lastNetworkPredictionIndex
_lastNetworkPredictionTrackID
T@"PTCinematographyNetworkParameters",R,V_params
T@"NSArray",R,V_inputSignals
T@"PTCinematographyDetection",R,V_zeroDisparityDetection
T@"NSMutableArray",R,V_networkDetections
T@"NSMutableIndexSet",R,V_unusedIndexes
T@"PTCinematographyDetection",&,V_lastFocusDetection
TQ,V_lastNetworkPredictionIndex
Tq,V_lastNetworkPredictionTrackID
T@"NSString",R,V_versionString
Tf,R
initWithByteStream:
initWithByteStream:offset:
initWithParent:
initWithParent:offset:
hasAtom
atomDataSize
globalAtomDataOffset
readCurrentAtomVersionAndFlags
readCurrentAtomDataBytes:size:offset:
advanceToNextAtom
setError:
debugDescription
_setEndOfStream
_readAtomHeader
_readBytes:size:offset:
_setErrorForByteStreamIfNeeded
_errorForByteStreamError:
_errorForReadPastLimit:size:offset:
_debugLogBytes:size:offset:
_debugLogAtomReaderState
byteStream
parentStream
atomType
atomVersion
atomFlags
error
atomSize
atomDataOffset
globalAtomOffset
globalEndOffset
isAtEndOfStream
didReadAtomVersionAndFlags
_atEndOfStream
_didReadAtomVersionAndFlags
_atomType
_byteStream
_parentStream
_atomVersion
_atomFlags
_error
_atomSize
_atomDataOffset
_globalAtomOffset
_globalEndOffset
TQ,R,V_atomSize
TQ,R,V_atomDataOffset
TQ,R,V_globalAtomOffset
TQ,R,V_globalEndOffset
atEndOfStream
TB,R,GisAtEndOfStream,V_atEndOfStream
TB,R,V_didReadAtomVersionAndFlags
T@"<PTByteStream>",R,V_byteStream
T@"PTAtomStream",R,V_parentStream
TB,R
TI,R,V_atomType
TQ,R
TQ,R,V_atomVersion
TQ,R,V_atomFlags
T@"NSError",R,V_error
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
T#,R
T@"NSString",R,C
render:inDisparity:detectedObjects:humanDetections:transform:outColorBuffer:waitUntilCompleted:gpuCompleted:
copyTemporalState:
reset
setDebug:
effectQuality
setEffectQuality:
initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:faceAttributesNetwork:prevTemporalState:sharedResources:
parseFaceRects:
depthEstimation
setColorSpaceInformation:pixelBuffer:
_device
_library
_pipelineLibrary
_commandQueue
_renderPipeline
_renderState
_raytracingInterpolation
_disparityFixedFocus
_focusDisparityArray
_focusObject
_lastFocus
_msrColorPyramid
_transferFunction
_YCbCrMatrix
_colorPrimaries
_colorYCbCrMatrix
_guidedFilter
_guideRGBAUpscale
_guideRGBACoefficients
_effectRelighting
_rgbaPyramid
_portraitColor
_sdofRenderRequest
_debugLayer
_colorWidth
_colorHeight
_fNumber
_asynchronous
_disparityOpticalFlow
_frameIndex
_networkIndex
_faceRects
_numberOfFaceRects
_focusDepthFixed
_focusDepthMax
_focusDepthOffset
_iirUpdateCoefficientDisparity
_iirUpdateCoefficientNormal
_temporalDisparityTempDropHints
_util
_effectUtil
_focusDisparityUpdateCoefficient
_effectType
_disparityNormalFilter
_focusFaceIndex
_debugType
Tq,VeffectQuality
_getPixelFormatsForType:luma:chroma:
getMetalLumaAndChromaFormats:luma:chroma:
isCompressed:
getNoConcurrentAccessHint:
pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:
isPixelBufferVideoRange:
isPixelBuffer10Bit:
getMTLTextureDescriptor:device:
getMTLTextureFromPixelBuffer:device:
getCVPixelBufferGetPixelFormatType:
isDiscrete
initWithDetectionType:
timeRangeEndForTime:
timeRangeForTime:
timeRange
timeRangeCount
timeRangeAtIndex:
detectionNearestTime:
detectionAtOrBeforeTime:
detectionsInTimeRange:
setTrackIdentifier:
setGroupIdentifier:
setScript:
detectionInFrame:
_trackByTrimmingToTimeRange:subtracting:
_calculateTimeRanges
_addStartTime:endTime:toTimeRanges:
debugTrackIdentifierString
trackType
_asMutableCinematographyDictionary
trackIdentifier
groupIdentifier
detectionType
isUserCreated
setUserCreated:
script
timeRanges
cachedTrackIdentifierString
_userCreated
_trackIdentifier
_groupIdentifier
_detectionType
_script
_timeRanges
_cachedTrackIdentifierString
T@"PTCinematographyScript",W,N,V_script
T@"NSArray",R,N,V_timeRanges
userCreated
TB,N,GisUserCreated,V_userCreated
T@"NSString",R,N,V_cachedTrackIdentifierString
TQ,R,N
Tq,R,N,V_trackIdentifier
Tq,R,N,V_groupIdentifier
TQ,R,N,V_detectionType
discrete
TB,R,N,GisDiscrete
initWithDetection:
initWithFocusDistance:
focusDistance
_fixedFocusDetectionAtTime:
detection
_detection
Tf,R,N
T@"PTCinematographyDetection",R,N,V_detection
initWithDetectionType:trackIdentifier:groupIdentifier:
initWithDetectionType:groupIdentifier:
trackDecisionsInTimeRange:
_calculateTrackDecisions
trackDecisions
_trackDecisions
T@"NSArray",R,N,V_trackDecisions
initWithDetections:
allDetections
applyDetectionSmoothing
detections
setDetections:
_detections
T@"NSArray",&,N,V_detections
T@"NSArray",R,N
initWithTransferFunction:YCbCrMatrix:colorPrimaries:colorSize:metalCommandQueue:effectType:prewarmOnly:useHighResNetwork:prevTemporalState:sharedResources:
_renderStates
_disparityFilter
initWithDevice:
estimateNormalsFromDisparity:inDiparity:outNormal:sensorWidth:focalLength:
_estimateNormalsFromDisparity
initWithTime:colorBuffer:auxBuffer:
time
colorBuffer
auxBuffer
_colorBuffer
_auxBuffer
_time
T{?=qiIq},R,N,V_time
T^{__CVBuffer=},R,N,V_colorBuffer
T^{__CVBuffer=},R,N,V_auxBuffer
enablePostProcessing
containsTweening
requiredSourceTrackIDs
passthroughTrackID
requiredSourceSampleDataTrackIDs
T{?={?=qiIq}{?=qiIq}},R,N
TB,R,N
Ti,R,N
setTimeRange:
videTrackID
setVideTrackID:
auxvTrackID
setAuxvTrackID:
assetReader
setAssetReader:
_videTrackID
_auxvTrackID
_assetReader
_timeRange
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
Ti,N,V_videTrackID
Ti,N,V_auxvTrackID
T@"PTAssetReader",W,N,V_assetReader
renderContextChanged:
startVideoCompositionRequest:
sourcePixelBufferAttributes
requiredPixelBufferAttributesForRenderContext
cancelAllPendingVideoCompositionRequests
anticipateRenderingUsingHint:
prerollForRenderingUsingHint:
supportsWideColorSourceFrames
supportsHDRSourceFrames
canConformColorOfSourceFrames
T@"NSDictionary",R,N
_jsonFriendlyObject:
jsonFriendlyMetadata
setTime:
index
setIndex:
metadata
setMetadata:
setJsonFriendlyMetadata:
metadataTime
setMetadataTime:
setColorBuffer:
colorBufferTime
setColorBufferTime:
colorBufferPreferredTransform
setColorBufferPreferredTransform:
disparityBuffer
setDisparityBuffer:
disparityBufferTime
setDisparityBufferTime:
disparityBufferPreferredTransform
setDisparityBufferPreferredTransform:
_index
_metadata
_jsonFriendlyMetadata
_disparityBuffer
_metadataTime
_colorBufferTime
_disparityBufferTime
_colorBufferPreferredTransform
_disparityBufferPreferredTransform
T{?=qiIq},N,V_time
TQ,N,V_index
T@"NSDictionary",&,N,V_metadata
T@"NSDictionary",&,N,V_jsonFriendlyMetadata
T{?=qiIq},N,V_metadataTime
T^{__CVBuffer=},N,V_colorBuffer
T{?=qiIq},N,V_colorBufferTime
T{CGAffineTransform=dddddd},N,V_colorBufferPreferredTransform
T^{__CVBuffer=},N,V_disparityBuffer
T{?=qiIq},N,V_disparityBufferTime
T{CGAffineTransform=dddddd},N,V_disparityBufferPreferredTransform
initialize
isReadyForReading
pushComposedFrame:
popComposedFrame
updateFormatPropertiesFromAsset:
initWithAsset:
startReadingFrames:
startReadingFrames:error:
startReadingFrames:atTime:error:
stopReadingFrames
estimatedFrameCount
frameCount
globalCinematographyMetadata
globalRenderingMetadata
globalStabilizationMetadata
globalVideoHeaderMetadata
_decodeGlobalMetadata
_decodeMetadata:
nextFrame
asset
estimatedDataRate
formatDescription
frameDuration
colorPrimaries
setColorPrimaries:
transferFunction
setTransferFunction:
YCbCrMatrix
setYCbCrMatrix:
is420YUV10Bit
setIs420YUV10Bit:
metadataAdaptor
videoComposition
videoCompositionOutput
composedFrames
lastDecodedFrameIndex
_cachedAccurateFrameCount
_globalCinematographyMetadata
_globalRenderingMetadata
_globalStabilizationMetadata
_globalVideoHeaderMetadata
_is420YUV10Bit
_asset
_estimatedDataRate
_formatDescription
_frameDuration
T@"AVAsset",R,N,V_asset
TQ,R,N,V_estimatedDataRate
Tr^{opaqueCMFormatDescription=},R,N,V_formatDescription
T{?=qiIq},R,N,V_frameDuration
T@"PTGlobalCinematographyMetadata",R,N
T@"PTGlobalRenderingMetadata",R,N
T@"PTGlobalStabilizationMetadata",R,N
T@"PTGlobalVideoHeaderMetadata",R,N
T@"NSString",&,N,V_colorPrimaries
T@"NSString",&,N,V_transferFunction
T@"NSString",&,N,V_YCbCrMatrix
TB,N,V_is420YUV10Bit
appendFloatParameter:value:toOutput:
appendUIntParameter:value:toOutput:
getFloatParameter:fromPairs:numPairs:didFindValue:
appendCMTimeParameter:value:scale:toOutput:
getFloatParameter:fromPairs:numPairs:
getFloatParameter:fromPairs:numPairs:withDefault:
getUIntParameter:fromPairs:numPairs:didFindValue:
getUIntParameter:fromPairs:numPairs:
getUIntParameter:fromPairs:numPairs:withDefault:didFindValue:
getCMTimeParameter:scale:fromPairs:numPairs:withDefault:
defaultStrategy
defaultEMASampleCount
defaultMaximumVelocity
defaultResistance
initWithExponentialMovingAverageAlpha:
initWithExponentialMovingAverageSampleCount:
alpha
setAlpha:
sampleCount
setSampleCount:
initWithMaximumVelocity:resistance:
setFocusDistance:time:
_emaDelta:
_weightedDialDelta:timeDelta:
pullTowardFocusDistance:time:
pullTowardFocusDistance:time:missing:
_minimumTimestepsToMoveBy:maxddx:
strategy
maximumVelocity
resistance
setFocusDistance:
velocity
setVelocity:
maximumAcceleration
targetDistance
setTargetDistance:
_alpha
_maximumVelocity
_resistance
_focusDistance
_velocity
_maximumAcceleration
_targetDistance
_sampleCount
_strategy
Tf,R,V_maximumAcceleration
Tf,V_alpha
TQ,V_sampleCount
Tf,V_targetDistance
TQ,R,V_strategy
Tf,R,V_maximumVelocity
Tf,R,V_resistance
T{?=qiIq},V_time
Tf,V_focusDistance
Tf,V_velocity
initWithByteWriter:
beginAtomOfType:
appendVersion:flags:
appendBytes:size:
endAtom
_appendBytes:size:
_writeBytes:size:offset:
_setErrorForByteWriterIfNeeded
_errorForByteWriterError:
_errorForVersion:
_errorForSize:
_debugLogBytes:size:
_debugLogAtomWriterState
byteWriter
parentWriter
didBeginAtom
_didBeginAtom
_byteWriter
_parentWriter
TB,R,V_didBeginAtom
T@"<PTByteWriter>",R,V_byteWriter
T@"PTAtomWriter",R,V_parentWriter
copyWithZone:
mutableCopyWithZone:
initWithOptions:
_snapshotPolicy
_setSnapshotPolicy:
_overrideFrameSnapshotPolicy
_setOverrideFrameSnapshotPolicy:
version
setVersion:
fixedFocusNormalizedRectSize
setFixedFocusNormalizedRectSize:
cinematographyParameters
setCinematographyParameters:
_version
_cinematographyParameters
_fixedFocusNormalizedRectSize
TQ,N,S_setSnapshotPolicy:,V_snapshotPolicy
TB,N,S_setOverrideFrameSnapshotPolicy:,V_overrideFrameSnapshotPolicy
TQ,V_version
T{CGSize=dd},V_fixedFocusNormalizedRectSize
T@"NSDictionary",C,V_cinematographyParameters
latestVersion
isSupportedVersion:
_updateDetectionModelFromMetadata:
_updateFocusBlurMapModeFromMetadata:
processColorBuffer:disparityBuffer:metadataDictionary:presentationTime:
endOfStream
adviseDidStartRecording
adviseDidStopRecording
modelVersionString
getGlobalMetadata:
_frameFromDetections:userAperture:snapshotPolicy:disparityPixelBuffer:
_copyUserFocusDetectionFromDetections:
_copyInternalState
_restoreInternalState:
_nextSnapshotForPolicy:
_defaultAperture
_reset
_chooseClosestObjectDetection:
_chooseLargestAreaDetection:
_detectionForFixedFocusDistance:rect:
_floatValueForAssignmentString:
_stringValueForAssignmentString:
_getFocusStrategyIfNeeded
_userDefaultFocusStrategy
_userDefaultNetworkVersion
_userDefaultFixedFocusDisparity
_chooseFocusDetection:
_minimumUserTapSeconds
_userTapLockEndsAtTime:
_userTapEndsForChangedFocusWithDisparityBuffer:
_userTapEndsForBaseFocusDetection:
_userTapFromMetadata:frameDetections:disparityBuffer:
_isValidNormalizedPoint:
_isFixedFocusFTTapRequestMetadata:
_isFixedFocusFTTapRequest:
_isTapToTrackFTTapRequest:
_isSuccessfulTapToTrackFTTapResponse:
_isFailedTapToTrackFTTapResponse:
_fixedFocusRectForPoint:disparityBuffer:
_defaultFixedFocusRectForPoint:disparityBuffer:
_detectionForFixedFocusAtNormalizedPoint:disparityBuffer:
_userTapFromFTTapResponse:frameDetections:disparityBuffer:
_isUserTap:inFrameDetections:
_frameDetectionsFromMetadata:time:disparityBuffer:
_hasFusionTrackerMetadata:
_trackingResultFromFusionTrackerMetadata:
_useSyntheticDDR
_detectorDidRunFromFTTrackingResult:time:
_frameDetectionsFromFusionTrackerMetadata:time:disparityBuffer:
_isInvalidFTTrack:
_sensorSizeFromMetadata:
_validSensorRectFromMetadata:
_autoFocusBlurMapFromMetadata:
_autoFocusRectFromMetadata:
_autoFocusDetectionWithTime:rect:
_copyPreviousISPDetections:toDetections:time:
_updateDetections:ifMissingISPDetectionsFromTrackingResult:time:
_detectionsFromFTTrackingResult:autoFocusRect:focusBlurMap:namedSignalsPerTrack:time:disparityBuffer:
_detectionTypeForFTObjectKind:
_ANODPoseFromFTTrackMetadata:
_namedSignals:addingANODPoseFromFTTrackMetadata:
_mutableDetectionsFromFTTrackingResult:namedSignalsPerTrack:time:
_disparityWeightingValue
_focusDistanceForDetection:lockedDisparityBufferAddress:width:height:bytesPerRow:formatType:
_inFocusRegionForFocusBlurMap:
_focusDistanceForAutoFocusDetection:lockedDisparityBufferAddress:width:height:bytesPerRow:formatType:focusBlurMap:
_setDisparityOfDetections:disparityBuffer:focusBlurMap:
smoothFocusDistance:trackIdentifier:sampleCount:
_logFocusChangeForFrame:
_logUserTap:
_logUnusualDisparity:kind:info:
_logUnusualDetection:info:
delegate
setDelegate:
userAperture
setUserAperture:
activeVersion
options
setOptions:
trackAllocator
setTrackAllocator:
network
setNetwork:
previewFocusPuller
setPreviewFocusPuller:
detectionModel
setDetectionModel:
focusBlurMapMode
setFocusBlurMapMode:
autoFocusUseBlurMap
setAutoFocusUseBlurMap:
autoFocusUseMask
setAutoFocusUseMask:
autoFocusInFocusRegionSelect
setAutoFocusInFocusRegionSelect:
frameIndex
setFrameIndex:
previousRecordingState
setPreviousRecordingState:
previousFrame
setPreviousFrame:
canCopyISPDetectionsIfMissing
setCanCopyISPDetectionsIfMissing:
activeUserTap
setActiveUserTap:
detectorDidRunNextExpectedTime
setDetectorDidRunNextExpectedTime:
didReadFocusStrategyDefault
setDidReadFocusStrategyDefault:
internalDefaultFocusStrategy
setInternalDefaultFocusStrategy:
internalDefaultFixedFocusDisparity
setInternalDefaultFixedFocusDisparity:
internalDefaultNetworkVersion
setInternalDefaultNetworkVersion:
_autoFocusUseBlurMap
_autoFocusUseMask
_canCopyISPDetectionsIfMissing
_didReadFocusStrategyDefault
_userAperture
_internalDefaultFixedFocusDisparity
_delegate
_activeVersion
_options
_trackAllocator
_previewFocusPuller
_detectionModel
_focusBlurMapMode
_autoFocusInFocusRegionSelect
_previousRecordingState
_previousFrame
_activeUserTap
_internalDefaultFocusStrategy
_internalDefaultNetworkVersion
_detectorDidRunNextExpectedTime
T@"PTCinematographyStreamOptions",&,N,V_options
T@"PTCinematographyTrackAllocator",&,N,V_trackAllocator
T@"PTCinematographyNetwork",&,N,V_network
T@"PTCinematographyFocusPuller",&,N,V_previewFocusPuller
TQ,N,V_detectionModel
TQ,N,V_focusBlurMapMode
TB,N,V_autoFocusUseBlurMap
TB,N,V_autoFocusUseMask
TQ,N,V_autoFocusInFocusRegionSelect
TQ,N,V_frameIndex
TQ,N,V_previousRecordingState
T@"PTCinematographyFrame",&,N,V_previousFrame
TB,N,V_canCopyISPDetectionsIfMissing
T@"PTCinematographyUserTap",&,N,V_activeUserTap
T{?=qiIq},N,V_detectorDidRunNextExpectedTime
TB,V_didReadFocusStrategyDefault
TQ,V_internalDefaultFocusStrategy
Tf,V_internalDefaultFixedFocusDisparity
T@"NSString",&,V_internalDefaultNetworkVersion
T@"<PTCinematographyStreamDelegate>",W,N,V_delegate
Tf,N,V_userAperture
TQ,R,V_activeVersion
isFocusStrong
focusStrong
TB,R,N,GisFocusStrong
writeBytes:size:offset:
initWithMutableData:
_errorForSize:offset:
data
setData:
_data
T@"NSError",&,V_error
T@"NSMutableData",&,V_data
addSample:
endSamples
isEndOfSmoothedSamples
isSmoothedSampleAvailable
nextSmoothedSample
lastFocusSmoother
_getSmoothedSample
_advanceToNextSmoothedSample
_padToFill
_padByCount:
_lastAddedSample
minSamplesNeeded
didEndSamples
nextFocusSmoother
setNextFocusSmoother:
cachedSamples
setCachedSamples:
unprocessedSampleCount
setUnprocessedSampleCount:
_didEndSamples
_minSamplesNeeded
_nextFocusSmoother
_cachedSamples
_unprocessedSampleCount
T@"MutableFloatArray",&,V_cachedSamples
TQ,V_unprocessedSampleCount
TQ,R,V_minSamplesNeeded
TB,R,V_didEndSamples
T@"PTCinematographyFocusSmoother",&,V_nextFocusSmoother
T@"PTCinematographyFocusSmoother",R
initWithModelDictionary:
objectAtIndex:
writePayload:toStream:
_flattenArray:
_flattenArray:toMutableArray:
flatten
_flatten
TB,R,V_flatten
initWithKind:
coefficientForNormalizedTime:
linearCoefficientForNormalizedTime:
kind
setKind:
_kind
TQ,N,V_kind
initWithDevice:library:pipelineLibrary:colorSize:disparitySize:debugRendering:verbose:gpuProfiling:config:quality:
renderContinuousWithSource:renderRequest:
prewarm
minimumResourceHeapSize
setResourceHeap:
_config
_debugRendering
_disparitySize
_colorSize
_injectedRGBAPyramid
_focusEdge
_qualitySettings
_raytracingUtils
_raytracingInterpolateResult
_globalReduction
_aperturePointsXY
_randomUChars
_disparityDiffGlobalMinMax
_disparityEdges
_disparityEdgesTemp
_disparityDiff
_focusEdgeMask
_raytracedRGBWeight
_raytracedRGBWeightUpscaled
_disparityDiffDropHints
_dropHintsRaytracing
_dropHintsRGBWeightUpscaled
_doVisualization
_kRayCount
_kColorSize
_kCoverageOverscan
_anamorphicFactor
_edgeTolerance
_raytracingSDOF
interpolateRGBWeightCustomFn
prepareFilter:inRGBA:outDisplacement:
temporalDisparityFilter:inDisplacement:inStatePrev:inDisparity:outDisparity:outState:
temporalDisparityFilter:inDisplacement:inDisparityPrev:inDisparity:outDisparity:disparityBias:
initFilter:
initFilter:sensorPort:
initWithCommandQueue:disparitySize:disparityFilteredSize:disparityPixelFormat:colorSize:colorPixelFormat:sensorPort:
exponentialMovingAverageFilter:inDisplacement:inDemaPrev:inDisparity:outDisparity:outDEMA:
copyDisparity:inDisparity:outDisparity:
_temporalFilterDEMA_LKT
_temporalFilterDEMA_LKT_VisualizeMotion
_resampleDisparity
_frameCount
_opticalFlow
_avgDisplacement
_dumpInputOutputFolder
_disparityFilteredSize
_direction
_motionVisualization
_demaStates
_samplerState
_defaultMinimumRackFocusPullTime
_defaultMaximumRackFocusPullTime
_defaultMaximumDisparityPerSecond
initWithGlobalMetadata:
writeToGlobalMetadata:
minimumRackFocusPullTime
setMinimumRackFocusPullTime:
maximumRackFocusPullTime
setMaximumRackFocusPullTime:
maximumDisparityPerSecond
setMaximumDisparityPerSecond:
_maximumDisparityPerSecond
_minimumRackFocusPullTime
_maximumRackFocusPullTime
T{?=qiIq},N,V_minimumRackFocusPullTime
T{?=qiIq},N,V_maximumRackFocusPullTime
Tf,N,V_maximumDisparityPerSecond
initWithFrames:options:
startIndexForLinearRackFocusPullToFrameAtIndex:
_framesIndex:earlierBy:
frames
setFrames:
_frames
T@"NSArray",&,N,V_frames
T@"PTCinematographyFocusFramesOptions",C,N,V_options
asCinematographyDictionary
_computeScalingFactor:dst_tex:scale_xy_inv:coeff:
initWithDevice:width:height:nscales:
isBidirectional
keypoints
newBufferWithPixelFormat:width:data:
setPreset:
setOutputTexUV:
setOutputTexUVForward:backward:
estimateFlowFromTexReference:target:commandBuffer:
estimateFlowStreamTex:index:doOpticalFlow:commandBuffer:
estimateFlowStreamTex:commandBuffer:
computeKeypointsFromTexForwardFlow:backwardFlow:bidirectionalError:blockSize:outNumKeypoints:commandBuffer:
_setDefaultParameters
_initMemory:height:nscales:
_setupPipelines
_setupBuffer
_computeOpticalFlow:computeFeatureI0:computeFeatureI1:
_computeOpticalFlowBidirectional:
_createImagePyramidWithCommandBuffer:in_tex:I_idx:
_zeroFlowWithCommandBuffer:uv_tex:
_downscale2XWithCommandBuffer:in_tex:out_tex:
_computeFeaturesWithCommandBuffer:in_tex:out_tex:
_computeFeaturesDerivativesWithCommandBuffer:in_tex:out_tex:
_doSolverWithCommandBuffer:scale:in_uv_tex:in_G0_tex:in_G1_tex:in_C0_tex:in_C1_tex:out_uv_tex:out_w_tex:
_enqueueFlowConsistencyWithCommandBuffer:in_uv0_tex:in_uv1_tex:out_uv_tex:
_enqueueKeypointsFromFlowWithCommandBuffer:in_uv_fwd_tex:in_uv_bwd_tex:out_kpt_buf:block_size:bidirectional_error:out_num_keypoints:
_doNLRegularizationWithCommandBuffer:in_uv_tex:join_tex:w_tex:out_uv_tex:
isValid
needConversionBGRA2YUVA
setNeedConversionBGRA2YUVA:
ref_size
aux_size
nscales
streamFrameCount
nwarpings
setNwarpings:
useNonLocalRegularization
setUseNonLocalRegularization:
nlreg_radius
setNlreg_radius:
nlreg_padding
setNlreg_padding:
nlreg_sigma_l
setNlreg_sigma_l:
nlreg_sigma_c
setNlreg_sigma_c:
nlreg_sigma_w
setNlreg_sigma_w:
setIsBidirectional:
isInverse
setIsInverse:
_computePipelines
_maxThreadExecutionWidth
_ref_pyr_size
_aux_pyr_size
_I_tex
_I_u32_alias_tex
_G0_tex
_G1_tex
_C0_tex
_C1_tex
_Adiagb_buf
_Ixy_buf
_idt_buf
_w_tex
_uv_fwd_tex
_uv_bwd_tex
_uv_fwd_u32_alias_tex
_uv_bwd_u32_alias_tex
_current_frame_index
_streamFrameCount
_indexUpdated
_uv_fwd_tex_user_ref
_uv_bwd_tex_user_ref
_kpt_buf
_dropHints
_isValid
_needConversionBGRA2YUVA
_useNonLocalRegularization
_isBidirectional
_isInverse
_nscales
_nwarpings
_nlreg_radius
_nlreg_padding
_nlreg_sigma_l
_nlreg_sigma_c
_nlreg_sigma_w
_ref_size
_aux_size
TB,R,N,V_isValid
TB,N,V_needConversionBGRA2YUVA
T{CGSize=dd},R,N,V_ref_size
T{CGSize=dd},R,N,V_aux_size
Ti,R,N,V_nscales
Ti,R,N,V_streamFrameCount
Ti,N,V_nwarpings
TB,N,V_useNonLocalRegularization
Ti,N,V_nlreg_radius
Ti,N,V_nlreg_padding
Tf,N,V_nlreg_sigma_l
Tf,N,V_nlreg_sigma_c
Tf,N,V_nlreg_sigma_w
TB,N,V_isBidirectional
TB,N,V_isInverse
T@"<MTLBuffer>",R,N
initWithTrackIdentifier:
nextTrackIdentifier
Tq,N,V_trackIdentifier
_timerUncertaintyForPayload:
timerSecondsDivisor
_timerSecondsDivisor
Tf,R,V_timerSecondsDivisor
noiseScaleFactorForHwModelID:sensorID:
hwModelIDFromFigModelSpecificName:
hwModelIDToString:
initWithCommandQueue:
debugTextures:
debugTexturesNames
exponentialMovingAverageFilter:inDisplacement:inDisparityPrev:inDisparity:outDisparity:updateCoefficient:disparityBias:
exponentialMovingAverageFilterNormal:inDisplacement:inNormalPrev:inNormal:outNormal:updateCoefficient:
copyDisparityWithBias:inDisparity:outDisparity:disparityBias:
_temporalFilterExponentialMovingAverageLKTMotion
_temporalFilterExponentialMovingAverageLKTMotionNormal
_copyDisparityWithBias
_iirUpdateCoefficient
renderState
setRenderState:
sourceColor
setSourceColor:
sourceDisparity
setSourceDisparity:
destinationColor
setDestinationColor:
aperture
setAperture:
alphaLowLight
setAlphaLowLight:
setAGC:
highlightBoostFactor
setHighlightBoostFactor:
highlightChromaFactor
setHighlightChromaFactor:
frameId
setFrameId:
disparityMin
setDisparityMin:
disparityMax
setDisparityMax:
scissorRect
setScissorRect:
_aperture
_alphaLowLight
_AGC
_highlightBoostFactor
_highlightChromaFactor
_frameId
_disparityMin
_disparityMax
_sourceColor
_sourceDisparity
_destinationColor
_scissorRect
T@"<PTRenderState>",&,N,V_renderState
T@"PTTexture",&,N,V_sourceColor
T@"<MTLTexture>",&,N,V_sourceDisparity
T@"PTTexture",&,N,V_destinationColor
Tf,N,V_aperture
Tf,N,V_focusDistance
Tf,N,V_alphaLowLight
Ti,N,V_AGC
Tf,N,V_highlightBoostFactor
Tf,N,V_highlightChromaFactor
TI,N,V_frameId
Tf,N,V_disparityMin
Tf,N,V_disparityMax
T{?=QQQQ},N,V_scissorRect
T@"NSDictionary",&,N,V_options
createRGBA:
createYUV420:chroma:
width
height
YCbCrColorDepth
setYCbCrColorDepth:
YCbCrFullRange
setYCbCrFullRange:
_YCbCrFullRange
_YCbCrColorDepth
Tq,N,V_YCbCrColorDepth
TB,N,V_YCbCrFullRange
useSqrtForArea
setUseSqrtForArea:
_useSqrtForArea
TB,V_useSqrtForArea
initWithDevice:colorSize:lktPreset:
initWithDevice:colorSize:lktPreset:allocateDisplacementFWD:needConversionBGRA2YUVA:inverseFlow:
estimateDisplacementStream:index:doOpticalFlow:destRGBA:
estimateDisplacementStream:destRGBA:outDisplacement:
estimateDisplacementFWD:sourceRGBA:destRGBA:
toTextureArray:
warp:inTexture:inDisplacement:outTextureWarped:
displacementFWD
setDisplacementFWD:
_warpTexture
_lktflowgpuContext
_displacementFWD
_allocateDisplacementFWD
_inverseFlow
objectFromData:
sizeOfSerializedObjectWithOptions:
writeToData:withOptions:
initWithMajorVersion:minorVersion:
majorVersion
minorVersion
_majorVersion
_minorVersion
TI,R,N,V_majorVersion
TI,R,N,V_minorVersion
initWithMinorVersion:
initWithData:
focusPullerAlpha
setFocusPullerAlpha:
focusPullerMaxV
setFocusPullerMaxV:
focusPullerResistance
setFocusPullerResistance:
_focusPullerAlpha
_focusPullerMaxV
_focusPullerResistance
Tf,N,V_focusPullerAlpha
Tf,N,V_focusPullerMaxV
Tf,N,V_focusPullerResistance
compare:
allNumbers
T@"NSArray",R
initWithFocusBlurMapData:sensorSize:validSensorRect:
initWithFocusBlurMapDictionary:
_initValidRectFromSensorWidth:height:
inFocusRegion
largestFocusRegion
_inputSensorPixelRect
inputValidNormalizedRect
focusValidNormalizedRect
validNormalizedRectFromRegion:
inputX
inputY
inputWidth
inputHeight
tileWidth
tileHeight
tileCountX
tileCountY
tileXForTile:
tileYForTile:
_nodesForNormalizedRect:
_nodesBetweenBlurMin:blurMax:
_blurExtendedNodes:blurMin:blurMax:
_getBlurRangeOfNodes:blurMin:blurMax:
_blurExtendedNodes:options:
_inFocusNodes
_connectedComponentWithNode:unvisited:
_connectedComponents:
_largestOfComponents:
_validNormalizedRectFromSensorPixelRect:
_normalRectFromPixelRect:
_pixelRectFromNormalRect:
_tileRectFromSensorPixelRect:
_sensorPixelRectFromTileRect:
_tileRectFromNodes:
_nodesFromTileRect:
_sensorPixelRectFromRegion:
_boxFromComponent:
autoFocusRect
setAutoFocusRect:
sensorWidth
sensorHeight
validX
validY
validWidth
validHeight
_map
_sensorWidth
_sensorHeight
_validX
_validY
_validWidth
_validHeight
_autoFocusRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_autoFocusRect
TQ,R,V_sensorWidth
TQ,R,V_sensorHeight
TQ,R,V_validX
TQ,R,V_validY
TQ,R,V_validWidth
TQ,R,V_validHeight
T@"NSIndexSet",R
T{CGRect={CGPoint=dd}{CGSize=dd}},R
initWithDevice:library:pipelineLibrary:imageSize:scale:epsilon:
guidedFilter:image:guideRGBACoefficients:guideRGBAUpscale:sourceColorBitDepth:
computeUpsamplingCoefficients:guideTexture:imageTexture:coeffTexture:weights:guideMultiplier:
averageUpsamplingCoefficients:coeffTexture:coeffAveragedTexture:
applyUpsamplingCoefficients:guideTexture:coeffTexture:upsampledTexture:guideMultiplier:
upscaledTexture
edges
_computeWeightedUpsamplingCoefficients
_computeUpsamplingCoefficients
_averageUpsamplingCoefficients
_applyUpsamplingCoefficients
_coeffTexture
_edges
_coeffAveragedTexture
_upscaledTexture
_textureDropHints
_utils
_useWeightedSampling
_useHighresGuideForComputingCoefficients
_skipBoxFilter
_temporalFilterExponentialMovingAverageColorSimilarities
_inputRGB
prewarmWithFormat:metalCommandQueue:effectType:
prewarmForMediaserverd
disableAsynchronousWork
initWithFormat:metalCommandQueue:effectType:
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:effectQuality:
initWithFormat:metalCommandQueue:availableEffectTypes:activeEffectType:prewarmOnly:effectQuality:
setEffectType:
waitForAsyncInitialization
updateEffectDelegate:
keepOldDelegateAlive:
initWithFormat:metalCommandQueue:effectType:effectQuality:
render:detectedObjects:toColorBuffer:
render:detectedObjects:transform:toColorBuffer:
render:disparity:detectedObjects:transform:toColorBuffer:
_metalCommandQueue
_asyncInitQueue
_effectTypeNew
_pixelTransferSession
_faceAttributesNetwork
_resources
_asyncInitialization
_prewarmOnly
_effectQuality
_effectQualityNew
_humanDetections
_lastFrameTime
_delegateLock
initWithCommandQueue:disparitySize:filteredDisparitySize:disparityPixelFormat:colorSize:colorPixelFormat:sensorPort:
commandQueue
disparitySize
filteredDisparitySize
disparityPixelFormat
colorSize
colorPixelFormat
sensorPort
_disparityPixelFormat
_colorPixelFormat
_sensorPort
_filteredDisparitySize
T@"<MTLCommandQueue>",R,&,V_commandQueue
T{?=QQQ},R,V_disparitySize
T{?=QQQ},R,V_filteredDisparitySize
TQ,R,V_disparityPixelFormat
T{?=QQQ},R,V_colorSize
TQ,R,V_colorPixelFormat
T@"NSString",R,V_sensorPort
prewarmWithDescriptor:
initWithDescriptor:
computeOpticalFlow:outDisplacement:
temporalDisparityFilter:inDisplacement:inDisparityFilteredPrev:outDisparityFiltered:disparityBias:
temporalDisparityFilter:inStatePrev:inDisparity:outDisparityFiltered:outState:
texRGBA
setTexRGBA:
_texRGBA
T@"<MTLTexture>",&,V_texRGBA
texLuma
setTexLuma:
texChroma
setTexChroma:
_texLuma
_texChroma
T@"<MTLTexture>",&,V_texLuma
T@"<MTLTexture>",&,V_texChroma
_networkLabelForDetection:
labelOffset
labelZero
remap
_labelOffset
_labelZero
_remap
Tq,R,V_labelOffset
TQ,R,V_labelZero
T@"NSDictionary",R,V_remap
initWithDevice:library:pipelineLibrary:colorSize:disparitySize:config:
guidedUpsampling:inDisparity:inRGBA:colorDepth:
_upscaleFactor
_disparityUpscaled
_width
_height
_portraitUtil
_guideConversionTexture
_coefficientsTextureArray
_dropHintsTextures
_isShaderHarvesting
createWithQuality:config:
doDisparityUpsampling
updateDescription
quality
setQuality:
numberOfPatternCircles
setNumberOfPatternCircles:
rayMarchAll
setRayMarchAll:
rayMarch
setRayMarch:
disparityUpsampleFactor
setDisparityUpsampleFactor:
disparityGuidedFilterEpsilon
setDisparityGuidedFilterEpsilon:
disableForegroundBlur
setDisableForegroundBlur:
doCenterDisparity
setDoCenterDisparity:
foregroundBlurLimitingFactor
setForegroundBlurLimitingFactor:
doFocusEdgeMask
setDoFocusEdgeMask:
doFirstLevelGaussianDownsample
setDoFirstLevelGaussianDownsample:
usePrecomputedGaussianNoise
setUsePrecomputedGaussianNoise:
doMacroApertureLimit
setDoMacroApertureLimit:
renderDownscale
setRenderDownscale:
doIntermediate2XUpscale
setDoIntermediate2XUpscale:
intermediatePixelFormat
setIntermediatePixelFormat:
useExportQualityNoise
setUseExportQualityNoise:
_description
_rayMarchAll
_rayMarch
_disableForegroundBlur
_doCenterDisparity
_doFocusEdgeMask
_doFirstLevelGaussianDownsample
_usePrecomputedGaussianNoise
_doMacroApertureLimit
_doIntermediate2XUpscale
_useExportQualityNoise
_quality
_numberOfPatternCircles
_disparityUpsampleFactor
_disparityGuidedFilterEpsilon
_foregroundBlurLimitingFactor
_renderDownscale
_intermediatePixelFormat
Ti,V_quality
Ti,V_numberOfPatternCircles
TB,V_rayMarchAll
TB,V_rayMarch
Tf,V_disparityUpsampleFactor
Tf,V_disparityGuidedFilterEpsilon
TB,V_disableForegroundBlur
TB,V_doCenterDisparity
Tf,V_foregroundBlurLimitingFactor
TB,V_doFocusEdgeMask
TB,V_doFirstLevelGaussianDownsample
TB,V_usePrecomputedGaussianNoise
TB,V_doMacroApertureLimit
Tf,V_renderDownscale
TB,V_doIntermediate2XUpscale
TQ,V_intermediatePixelFormat
TB,V_useExportQualityNoise
initWithDevice:library:pipelineLibrary:commandQueue:effectRelighting:disparityNormalFilter:opticalFlow:renderState:util:portraitColor:msrColorPyramid:network:disparityFixedFocus:focusDepthFixed:focusObject:
renderDebugSubjectRelighting:humanDetections:renderRequest:transform:
renderDebugInformation:renderRequest:humanDetections:transform:
renderThumbnails:defaults:renderRequest:
initWithIOSurfaces:names:
tensorWithIndex:
tensorNameWithIndex:
_names
_tensorPair
getEspressoMetalDeviceId:
initPipelineState:library:pipelineLibrary:
initWithUrl:inputNames:outputNames:tensorSwapNames:device:library:pipelineLibrary:commandQueue:reshape:configuration:
bindTensorSwaps:
bindBuffers:toMap:withMode:
getResourceWithName:fromMap:
texture2DArrayToTexture2D:
bindInputResourceWithName:to:
getInputResourceWithName:
getOutputResourceWithName:
convertBindInput
execute
executeAsync:
executeAsync
unInterleaveTexture:input:output:
tensorSwap:
networkVersion
_ctx
_net
_inputsMap
_outputsMap
_inputConversion
_tensorSwap
_espressoCallbackQueue
_unInterleaveTexture
_url
_networkVersion
lastNetworkVersion
initWithDevice:library:pipelineLibrary:commandQueue:colorSize:effectUtil:util:useHighResNetwork:sharedResources:
inRGBA
inPrevDisparity
outDisparity
executeNetwork
rotated
bindColorInputPixelBuffer:
highResNetwork
Tq,V_frameIndex
initWithType:providerClass:
type
setType:
providerClass
setProviderClass:
isAtomContainerType
setIsAtomContainerType:
isProviderArrayType
setIsProviderArrayType:
_isAtomContainerType
_isProviderArrayType
_type
_providerClass
TI,V_type
T#,&,V_providerClass
TB,V_isAtomContainerType
TB,V_isProviderArrayType
supportsVersion:
writeToAtomWriter:options:
registerForSerialization
objectFromAtomStream:
registerSerializationClass:
isValidObject:
sizeOfSerializedObject:options:
objectFromData:error:
dataFromObject:options:error:
_supportedOptions:forObject:
writeObject:toData:options:error:
registerTypeInfo:
infoForType:
classForType:
registerType:providerClass:
_errorUnsupportedVersion
_errorNotSerializable
_errorWithCode:
_errorFromAtomWriter:
_errorFromAtomStream:
_errorFromAtomError:
objectFromData:withMajorVersion:minorVersion:
applyToRenderRequest:
initWithData:minorVersion:
setAgc:
_agc
TI,N,V_agc
_initWithDetectionData_0:
_copyToDetectionData_0:
objectsFromAtomStream:
_detectionsFromInnerAtomStream:
sizeOfSerializedArray:options:
writeArray:toAtomWriter:options:
initWithDevice:commandQueue:inputSize:target:rotateTargetPixelBuffer:sharedResources:
downsampleToQuarterSize:
downsampleQuarterSizeToTargetSize:
_rotate:toDest:synchronous:
rotate:crop:rotationDegree:toDest:synchronous:
_downsample:toDest:useCustomFilter:centerAlignment:synchronous:
pyramidRGBA
targetRGBA
targetRGBAPixelBuffer
_outputPixelbuffer
_outputIOSurface
_pyramidRGBA
_allocatedIOSurfaces
_runOptions
_csRGBLinear
_csSRGB
_colorUtil
_hasMSR
_rotateTargetPixelBuffer
initWithDevice:library:pipelineLibrary:commandQueue:faceAttributesNetwork:effectUtil:util:msrColorPyramid:colorSize:prewarmOnly:sharedResources:
updateSubjectRelighting:inLuma:inChroma:inFaceRects:runOnAsyncCommandQueue:focusFaceIndex:transform:
estimateLightIntensityWithFaceRects:inLuma:inChroma:focusFaceIndex:numberOfFaceRects:transform:humanDetections:
interpolateLightIntensity:
estimateLightIntensity:
debugTextures
srlV2CoeffsBuffer
lightEstimation
faceObservations
_lightEstimation
_mainCommandQueue
_asyncCommandQueue
_segmentationNetwork
_skinMaskRGBA
_subjectRelighting
_faceObservations
_subjectRelightingRunning
srlAsyncQueue
_rgbaPixelBufferCopy
_rgbaTextureCopy
_quarterSizeLumaCopy
_quarterSizeChromaCopy
_lightEstimationBuffer
initWithCount:
initWithZeros:
initWithFloat:repeatCount:
initWithFloatArray:
initWithFloats:count:
floatAtIndex:
floats
isEqualToFloatArray:
isEqualToFloatArray:tolerance:
maximumDifferenceWithFloatArray:
mean
argMinimum
addingConstant:
subtracting:
initWithArray:
asArray
asData
count
_buffer
_count
TQ,R,N,V_count
Tr^f,R,N
initWithCount:capacity:
initWithZeros:capacity:
initWithFloat:repeatCount:capacity:
mutableFloats
setFloat:atIndex:
setFloat:inRange:
setFloats:inRange:
appendFloat:
removeFromStart:
addConstant:
_start
_capacity
T^f,R,N
initWithDevice:library:pipelineLibrary:textureSize:
initWithDevice:library:pipelineLibrary:textureSize:pixelFormat:
parallelReductionAverage:inTexture:outGlobalAverage:
parallelReductionMax:inTexture:globalMaxBuffer:
parallelReductionMin:inTexture:globalMinBuffer:
parallelReductionMinMax:inTexture:globalMinMaxBuffer:
parallelReduction:inTexture:globalBuffer:offset:pipelineState:reductionType:factor:
parallelReductionTextureSimd:inTexture:globalBuffer:offset:reductionType:factor:
parallelReductionTextureMinMaxSimd:inTexture:globalBuffer:
_texPing
_texPong
_simdTextures
_simdMinMaxTextures
_parallelReductionTextureSimd
_parallelReductionTextureMinMaxSimd
_parallelReductionAverage
_parallelReductionMax
_parallelReductionMin
simdReductionThreadsPerGroup
simdReductionThreadGroups
_supportGpuSIMD
readPlist:
maskThreshold
minFaceSize
maxCurveBoost
minCurveBoost
maxTargetRatioDarkening
maxTargetRatioLimit
biasFactorSRLv2
toneSimilaritySigma
faceExpDifThreshold
relightOnlyPersonMask
targetMedian_I
targetMedian_II
targetMedian_III
targetMedian_IV
targetMedian_V
targetMedian_VI
maxBoost_I
maxBoost_II
maxBoost_III
maxBoost_IV
maxBoost_V
maxBoost_VI
initWithDevice:library:pipelineLibrary:commandQueue:effectUtil:util:prewarmOnly:
runSRLForLivePhotosWithInputBuffer:lumaTexture:chromaTexture:skinMaskTexture:personMaskTexture:instanceMaskConfidences:skinToneClassification:validROI:expBias:faceExpRatio:exifOrientation:
_srlV2GlobalHistogramLivePhotos
_srlV2FaceHistogramLivePhotos
_srlV2CalcCoefficientsLivePhotos
_srlV2GlobalStatsBuffer
_srlV2FaceStatsBuffer
_srlV2CoeffsBuffer
_srlV2Plist
_plistSRL
_black
frameDetections:detectorDidRun:presentationTime:
initWithDetections:detectorDidRun:presentationTime:
detectionForTrackIdentifier:
bestDetectionForGroupIdentifier:
bestDetectionForGroupIdentifier:options:
detectionForFocusIdentifier:
allTrackIdentifiers
allTrackIdentifiersForCinematicChoice
_detectionsByTrackIdentifier
allFocusIdentifiers
_detectionsByFocusIdentifier
autoFocusDetection
customDetection
addDetection:
flushCachedDetectionsDictionaries
detectorDidRun
presentationTime
setPresentationTime:
cachedDetectionsByFocusIdentifier
cachedDetectionsByTrackIdentifier
didCacheAutoFocusDetection
setDidCacheAutoFocusDetection:
cachedAutoFocusDetection
setCachedAutoFocusDetection:
didCacheCustomDetection
setDidCacheCustomDetection:
cachedCustomDetection
setCachedCustomDetection:
baseFocusTrackNumberOverride
setBaseFocusTrackNumberOverride:
_didCacheAutoFocusDetection
_didCacheCustomDetection
_detectorDidRun
_cachedDetectionsByFocusIdentifier
_cachedDetectionsByTrackIdentifier
_cachedAutoFocusDetection
_cachedCustomDetection
_baseFocusTrackNumberOverride
_presentationTime
T@"NSDictionary",R,V_cachedDetectionsByFocusIdentifier
T@"NSDictionary",R,V_cachedDetectionsByTrackIdentifier
TB,V_didCacheAutoFocusDetection
T@"PTCinematographyDetection",&,V_cachedAutoFocusDetection
TB,V_didCacheCustomDetection
T@"PTCinematographyDetection",&,V_cachedCustomDetection
T@"NSNumber",&,V_baseFocusTrackNumberOverride
T@"NSArray",R,V_detections
T@"NSNumber",R,V_detectorDidRun
T{?=qiIq},V_presentationTime
T@"PTCinematographyDetection",R
classForVersion:
prepareForRendering:
prepareForRendering
focalLenIn35mmFilm
setFocalLenIn35mmFilm:
conversionGain
setConversionGain:
readNoise_1x
setReadNoise_1x:
readNoise_8x
setReadNoise_8x:
noiseScaleFactor
setNoiseScaleFactor:
rawSensorHeight
setRawSensorHeight:
rawSensorWidth
setRawSensorWidth:
visCropFactor
setVisCropFactor:
sensorID
setSensorID:
totalSensorCrop
setTotalSensorCrop:
sourceColorBitDepth
setSourceColorBitDepth:
renderingVersion
setRenderingVersion:
networkBias
setNetworkBias:
hwModelID
setHwModelID:
Ti,R
Tf,N
Ti,N
T{CGRect={CGPoint=dd}{CGSize=dd}},N
TQ,N
initWithPipelineDescriptor:quality:
adjustScissorRect:
encodeRenderTo:withRenderRequest:
_desc
_renderIntegration
_colorOutputSizeCropped
_renderingVersion
Ti,R,Vquality
Tf,N,VfocalLenIn35mmFilm
Ti,N,VconversionGain
Ti,N,VreadNoise_1x
Ti,N,VreadNoise_8x
Tf,N,VnoiseScaleFactor
Ti,N,VrawSensorHeight
Ti,N,VrawSensorWidth
T,N,VvisCropFactor
Ti,N,VsensorID
T{CGRect={CGPoint=dd}{CGSize=dd}},N,VtotalSensorCrop
Ti,N,VsourceColorBitDepth
Tf,N,VnetworkBias
Ti,N,VhwModelID
T@"NSString",R,C,Vdescription
initWithDevice:library:pipelineLibrary:util:quality:colorSize:disparitySize:pyramidPixelFormat:config:debugTextures:
dependentFrames
randomUChars
setRandomUChars:
randomGaussNoise
setRandomGaussNoise:
focusEdgeMask
setFocusEdgeMask:
doVisualization
setDoVisualization:
setColorSize:
coverageOverscan
setCoverageOverscan:
edgeTolerance
setEdgeTolerance:
rayCount
setRayCount:
raytracingSDOF
setRaytracingSDOF:
aperturePointsXY
setAperturePointsXY:
raytracedRGBRadius
setRaytracedRGBRadius:
raytracedRGBRadiusUpscaled
setRaytracedRGBRadiusUpscaled:
disparityEdges
setDisparityEdges:
disparityEdgesTemp
setDisparityEdgesTemp:
disparityUpscale
setDisparityUpscale:
globalReduction
setGlobalReduction:
disparityDiffGlobalMinMax
setDisparityDiffGlobalMinMax:
anamorphicFactor
setAnamorphicFactor:
raytracingRadiusLocal
setRaytracingRadiusLocal:
qualitySettings
setQualitySettings:
disparityDiff
setDisparityDiff:
disparityDiffDropHints
setDisparityDiffDropHints:
dropHintsRaytracing
setDropHintsRaytracing:
dropHintsRGBRadiusUpscaled
setDropHintsRGBRadiusUpscaled:
_disparityUpscale
_disparityDiffGlobalMax
_randomizedGauss
_rayCount
_raytracingRadiusLocal
_randomGaussNoise
_raytracedRGBRadius
_raytracedRGBRadiusUpscaled
_dropHintsRGBRadiusUpscaled
Ti,V_rayCount
T@"<MTLComputePipelineState>",&,N,V_raytracingSDOF
T@"<MTLBuffer>",&,N,V_randomUChars
T@"<MTLBuffer>",&,N,V_aperturePointsXY
T@"<MTLTexture>",&,N,V_randomGaussNoise
T@"<MTLTexture>",&,N,V_focusEdgeMask
T@"<MTLTexture>",&,N,V_raytracedRGBRadius
T@"<MTLTexture>",&,N,V_raytracedRGBRadiusUpscaled
T@"<MTLTexture>",&,N,V_disparityEdges
T@"<MTLTexture>",&,N,V_disparityEdgesTemp
T@"PTDisparityUpscale",&,N,V_disparityUpscale
T@"PTGlobalReduction",&,N,V_globalReduction
T@"<MTLBuffer>",&,N,V_disparityDiffGlobalMinMax
TB,V_doVisualization
T,V_kColorSize
Tf,V_kCoverageOverscan
Tf,V_anamorphicFactor
Tf,V_raytracingRadiusLocal
Tf,V_edgeTolerance
T@"PTQualitySettings",&,N,V_qualitySettings
T@"<MTLTexture>",&,N,V_disparityDiff
T@"PTMTLDropHints",&,N,V_disparityDiffDropHints
T@"PTMTLDropHints",&,N,V_dropHintsRaytracing
T@"PTMTLDropHints",&,N,V_dropHintsRGBRadiusUpscaled
_bicubicUpscale
globalMetadata
setGlobalMetadata:
rackFocusPullTime
setRackFocusPullTime:
disableDetectionSmoothing
setDisableDetectionSmoothing:
focusFramesOptions
setFocusFramesOptions:
_globalMetadata
_disableDetectionSmoothing
_focusFramesOptions
T@"PTCinematographyFocusFramesOptions",&,V_focusFramesOptions
T@"PTGlobalCinematographyMetadata",C,N
TB,N,V_disableDetectionSmoothing
T{?=qiIq},N
addFrames:
startRecording
stopRecording
endOfFrames
refinedFrames
globalCinematographyDictionary
_moveAlongSmoothedFrames
_endSmoothedFrames
_performRackFocusPullsStartingAtIndex:
_performRackFocusPullToFrameAtIndex:
_logRackFocusPullToFrameAtIndex:fromIndex:label:
_performLinearRackFocusPullToFrameAtIndex:fromIndex:
_extractFramesReturningAll:
_extractFramesToIndex:
_framesIndexForTime:
_needSnapshotForPolicy:
_updateRecordingStateForSnapshot:
_updateGlobalsWithSnapshot:
timeDelayForRefinement
globals
setGlobals:
smoother
setSmoother:
refinedFrameNumber
setRefinedFrameNumber:
firstIndexToLookForTransitions
setFirstIndexToLookForTransitions:
recordingState
setRecordingState:
shouldReturnAllCachedFrames
setShouldReturnAllCachedFrames:
_shouldReturnAllCachedFrames
_globals
_smoother
_refinedFrameNumber
_firstIndexToLookForTransitions
_recordingState
_timeDelayForRefinement
T@"PTCinematographyRefinementOptions",C,N,V_options
T@"NSMutableDictionary",&,N,V_globals
T@"PTCinematographyFrameDetectionSmoother",&,N,V_smoother
T@"NSMutableArray",&,N,V_frames
T@"NSNumber",&,N,V_refinedFrameNumber
TQ,N,V_firstIndexToLookForTransitions
TQ,N,V_recordingState
TB,N,V_shouldReturnAllCachedFrames
T{?=qiIq},R,N,V_timeDelayForRefinement
setEnabled:device:
instance:
setActiveResourceGroups:
_addResourceGroup:toCommandBuffer:
_dropResourceGroup:fromCommandBuffer:
checkForUnreleasedDrophints
_activeGroups
initWithDevice:resources:name:
setDropHintsFor:
dropHintsFor:
enabled
setEnabled:
_resourceGroup
_name
_enabled
TB,V_enabled
scanlineMaskWithFocusBlurMap:region:
scanlineIter
placement
setPlacement:
_placement
T{CGRect={CGPoint=dd}{CGSize=dd}},V_placement
initWithFocusBlurMap:region:
_recalculatePlacementTileSize
pixelRangeForTileRangeX:
pixelRangeForTileRangeY:
region
normalizedTileSize
setNormalizedTileSize:
placementTileSize
setPlacementTileSize:
_region
_normalizedTileSize
_placementTileSize
T{CGSize=dd},V_normalizedTileSize
T{CGSize=dd},V_placementTileSize
T@"PTFocusBlurMap",R,V_map
T@"NSIndexSet",R,V_region
nextRangeY
nextRangeX
resetX
initWithMask:
_advanceToNextTileRow
_advanceToNextTile
mask
currentTileRow
setCurrentTileRow:
currentTile
setCurrentTile:
_mask
_currentTileRow
_currentTile
TQ,V_currentTileRow
TQ,V_currentTile
T@"PTScanlineMask_FocusBlurMap",R,V_mask
initEquidistPoints:samplePatternCircles:
createRandomUChars:rayCount:
createFocusObject:coverageOverscan:anamorphicFactor:raytracingRadiusLocal:rayCount:colorSize:doMacroApertureLimit:
createFocusEdge
focalLength
frameWidth
precomputeNoise:seed:device:
calculateVarReadNoise:
initWithDevice:library:pipelineLibrary:
sNBE
sNLE
interpolateRGBRadiusUsingSourceToDest:renderRequest:inRGBRadius:inRandomGauss:bicubicSampling:
interpolateRGBRadiusToDest:renderRequest:inRGBA:inRGBRadius:inRandomGauss:bicubicSampling:
convertRGBPyramidFromSource:renderRequest:rgbaPyramidArray:skipLevel0:
focusEdgeMask:inDisparityDiff:focusObject:focusEdge:outFocusEdgeMask:
centerDisparityOnFocus:inDisparity:outDisparity:focusObject:
detectDilatedEdges:inDisparity:tempEdges:outEdges:focusObject:disparityDiffMinMax:edgeTolerance:
_interpolateRGBRadiusToDestYUV
_interpolateRGBRadiusToDestRGBA
_interpolateRGBRadiusToDestYUVFromSource
_interpolateRGBRadiusToDestRGBAFromSource
_convertRGBPyramid
_convertRGBPyramidFromYUV
_centerDisparityOnFocus
_sobelEdgeDetector
_edgeDilation
_sNBE
_sNLE
initWithDevice:library:
renderDebugLayer:renderRequest:inDisparity:disparityOffset:focusObject:quality:edgeTolerance:debugTextures:debugRendering:
renderTurbo:inTex:outRGBA:valueOffset:valueMinMax:valueAbs:colorRangeMax:channelMultiplier:region:
renderTurboMix:inTex:inRGBA:outRGBA:valueOffset:valueMinMax:valueAbs:colorRangeMax:channelMultiplier:mixFraction:region:
getBiasedDisparityVisualizationRange:
dumpDebug:renderRequest:debugTextures:
initWithRect:confidence:
rect
setRect:
confidence
setConfidence:
_confidence
_rect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_rect
Tf,V_confidence
isSupported
getRectForPoint:colorBuffer:
addDetectionAndStartTrackingRect:time:colorBuffer:disparityBuffer:
addDetectionForNextFrameAt:colorBuffer:disparityBuffer:
finalizeTrack
resetTrack
addDetectionAtTime:rect:disparityBuffer:
_tmpCurrentRect
_tracker
T@"NSMutableArray",&,N,V_detections
orientationFromTransform:
faceRectsForVision:numberOfFaceRects:transform:
updateFocusObject:faceRectCount:focusDepthOffset:exponentialMovingAverage:isFirstFrame:lastFocus:inFocusDistanceArray:outFocusObject:outFocusFaceIndex:
sampleFaceRects:maxFaceRects:faceRects:numberOfFaceRects:inDisparity:outFocusDistanceArray:
rotateTexture:inTex:outTex:rotationDegrees:
fixedFocusDistanceAndCenterDisparity:inDisparity:outDisparity:focusDepthFixed:focusDepthMax:inFocusObject:
copySingleChannel:inTex:outTex:
clear:outTex:
copyRGBAToBGRA:inTex:outTex:
orientationForTransform:size:
getBoundingBox:
_updateFocusObject
_effectSampleFaceRects
_convertToDisparity
_fixedFocusDistanceAndCenterDisparity
_copySingleChannel
_copyRGBAToBGRA
_clear
initWithTime:detection:missing:
isMissingDetection
_isMissingDetection
T{?=qiIq},R,V_time
T@"PTCinematographyDetection",R,V_detection
TB,R,V_isMissingDetection
initWithDestination:count:
remainingCount
writeZerosWithCount:
writeFloat:
writeFloats:count:
writeOneHot:count:
T^f,R,V_fp
TQ,R,V_count
TQ,V_index
networkSignalWithModelDictionary:
subclassForName:
checkSignalForStream:
name
T@"NSString",R,V_name
setAllDetections:
_detectionTrackNumberSet
_updateDetectionTimes
focusTrackIdentifier
focusGroupIdentifier
isInTransition
primaryFocusDetection
focusBlend
detectionForTrack:
detectionAtPoint:
_frameNumber
_setFrameNumber:
_snapshot
_setSnapshot:
_setDetectorDidRun:
focusDetection
setFocusDetection:
rawFocusDistance
setRawFocusDistance:
focusTrackNumber
setFocusTrackNumber:
baseFocusTrackNumber
setBaseFocusTrackNumber:
userFocusTrackNumber
setUserFocusTrackNumber:
isUserFocusStrong
setUserFocusStrong:
isUserFocusGroup
setUserFocusGroup:
isUserFocusEnd
setUserFocusEnd:
transitionCoefficient
setTransitionCoefficient:
transitionElapsedTime
setTransitionElapsedTime:
transitionDuration
setTransitionDuration:
setFocusBlend:
_userFocusStrong
_userFocusGroup
_userFocusEnd
_rawFocusDistance
_transitionCoefficient
_transitionElapsedTime
_transitionDuration
_focusDetection
_allDetections
_focusTrackNumber
_baseFocusTrackNumber
_userFocusTrackNumber
_focusBlend
Tf,N,V_rawFocusDistance
T@"PTCinematographyDetection",&,N,V_focusDetection
T@"NSArray",&,N,V_allDetections
T@"NSNumber",&,N,V_focusTrackNumber
T@"NSNumber",&,N,V_baseFocusTrackNumber
T@"NSNumber",&,N,V_userFocusTrackNumber
userFocusStrong
TB,N,GisUserFocusStrong,V_userFocusStrong
userFocusGroup
TB,N,GisUserFocusGroup,V_userFocusGroup
userFocusEnd
TB,N,GisUserFocusEnd,V_userFocusEnd
T@"NSNumber",&,N,S_setDetectorDidRun:,V_detectorDidRun
Tf,N,V_transitionCoefficient
Tf,N,V_transitionElapsedTime
Tf,N,V_transitionDuration
T@"NSNumber",&,N,S_setFrameNumber:,V_frameNumber
T@,&,N,S_setSnapshot:,V_snapshot
T@"NSDictionary",R,N,V_cachedDetectionsByFocusIdentifier
T@"NSDictionary",R,N,V_cachedDetectionsByTrackIdentifier
T@"PTCinematographyFocusBlend",&,N,V_focusBlend
Tq,R,N
floatValue
detectionForTrackNumber:
_addDetection:
_removeDetection:
_removeDetectionWithTrackIdentifier:
_flushCachedDetectionsDictionaries
_focusDetectionFromCoefficientsDictionary:coefficient:
_initWithCinematographyDictionary:time:
_restoreOriginal
focusOnNothing
focusOnDetection:
focusOnDetection:focusPuller:
_focusFromDetection:toDetection:rawFocusDistance:focusDistance:transitionCoefficient:elapsedTime:duration:
_framesWithCinematographyDictionaries:
_debugLogFrames:label:
_debugLogFrame:label:
T@"PTCinematographyDetection",&,N
T@"NSArray",&,N
T@"NSSet",R,N
T@"NSNumber",&,N
TB,N,GisUserFocusStrong
TB,N,GisUserFocusGroup
TB,N,GisUserFocusEnd
T@"NSNumber",&,N,S_setDetectorDidRun:
T@"NSNumber",&,N,S_setFrameNumber:
TQ,N,S_setSnapshotPolicy:
T@,&,N,S_setSnapshot:
createRequest
faceLandmarksInPixelBuffer:faceRects:orientation:
_handler
_session
createFocusObject:coverageOverscan:anamorphicFactor:rayCount:colorSize:doMacroApertureLimit:
centerDisparityOnFocus:inDisparity:outDisparity:focusObject:foregroundBlurLimitingFactor:
sobelEdgeDetection:inImage:outEdges:edgeTolerance:
_initWithFrameHeaderData_0:
_copyToFrameHeaderData_0:
_writeHeaderToAtomWriter:options:
_frameFromInnerAtomStream:
_frameHeaderFromAtomStream:
T@"NSDictionary",R,V_params
objectForKey:
initWithURL:
_processInputSchemaDicts:
_defaultSupportedDetectionTypes
setExpectedFPS:
forgetDetectionsAfterSeconds
setForgetDetectionsAfterSeconds:
runOnlyWhenDetectorDidRun
setRunOnlyWhenDetectorDidRun:
supportedDetectionTypes
setSupportedDetectionTypes:
inputSchemas
setInputSchemas:
totalInputFloatCount
_runOnlyWhenDetectorDidRun
_expectedFPS
_forgetDetectionsAfterSeconds
_supportedDetectionTypes
_inputSchemas
_totalInputFloatCount
Tf,V_expectedFPS
Tf,V_forgetDetectionsAfterSeconds
TB,V_runOnlyWhenDetectorDidRun
T@"NSSet",&,V_supportedDetectionTypes
T@"NSArray",&,V_inputSchemas
TQ,R,V_totalInputFloatCount
_indexNearestTime:
_indexAtOrBeforeTime:
_firstIndexAtOrAfterTime:
_indexRangeOfTimeRange:
_timeRangeOfIndexRange:
_indexNearestTime:timeSelector:
_indexAtOrBeforeTime:timeSelector:
_firstIndexAtOrAfterTime:timeSelector:
_indexRangeOfTimeRange:timeSelector:
_timeRangeOfIndexRange:timeSelector:
_timeForObject:timeSelector:
_firstIndexAtOrAfterTime:startIndex:lastIfEqual:timeSelector:
_firstIndexAfterTime:startIndex:timeSelector:
_temporalFilterExponentialMovingAverageLKT
initWithDevice:library:pipelineLibrary:commandQueue:faceAttributesNetwork:effectUtil:util:prewarmOnly:colorSize:msrColorPyramid:sharedResources:
gainMap
updateColorCube
colorCube
smoothFaceRects
commaSeparatedString:toFloatArray:maxCount:
initRelightingParam
updateParamters
computeSmoothFaceRect:transform:
fgBgForDebug:inDisparity:inNormal:inFocusObject:outMask:debugType:
lightMaskDebug:msrColorPyramid:outFaceMask:
estimateLightIntensity:inChroma:inFaceRects:numberOfFaceRects:focusFaceIndex:humanDetections:transform:
studioLight:inLuma:inChroma:inNormal:inDisparity:inFocusObject:outPTTexture:outRgbaPyramid:colorTransferFunction:colorYCbCrMatrix:
filterLightGainApplyToRGB:inRGB:outRGB:filterLightGainMapLowres:
syntheticLight
_studioLight
_createLightMask
_fgBgForDebug
_lightMaskForDebug
_relightFullsizeInput
_studioLightDebug
_lightMaskOutline
_filterLightGainApplyToRGB
_syntheticLight
_parameters
_smoothFaceRects
_weightHeadEye
_eyeRadiusFactor
_lightMasks
_lightGainMapScale
_lightGainMapLowRes
_lightGainMapLowResFiltered
_lightGainMapFiltered
_colorCube
_quarterSizeRGBA
_relightSizeRGBA
_colorCubeType
decisionsDidChangeInScript:timeRange:
framesDidChangeInScript:timeRange:
defaultMinimumUserFocusDuration
loadWithAsset:changesDictionary:completion:
_loadWithAsset:changesDictionary:error:
reloadWithChangesDictionary:
_internalizeLoadedFrames:changesDictionary:reloading:
_internalizeFocusPullerFromFrames:
_internalizeUserApertureFromChangesDictionary:
_internalizeUserDecisionsFromChangesDictionary:
_internalizeUserDecisionsFromFrames:
_userDecisionToFocusOnDetection:time:strong:group:
frameNearestTime:
frameAtTime:tolerance:
framesInTimeRange:
_detectionWithTrackIdentifier:atOrBeforeTime:
_detectionWithGroupIdentifier:atOrBeforeTime:
_updateFramesForDecisions:timeRange:
_updateFramesForDecisions:indexRange:
_updateFramesFromDecision:toDecision:
_updateFramesForFinalDecision:
_updateFramesForDecision:upToTime:
_updateFramesForTransitionFromDecision:toDecision:
_updateFramesForTransitionFromDecision:toDecision:timeRange:
_latestDetectionOfTrackIdentifier:atOrBeforeFrameIndex:timeLimit:
_latestDetectionOfGroupIdentifier:atOrBeforeFrameIndex:timeLimit:
_updateFramesInTimeRange:toFocusOnTrackIdentifier:
_updateFramesInIndexRange:forTransition:fromDetection:toDetection:
_updateFramesInTimeRange:forTransition:fromDetection:toDetection:
_updateFramesInIndexRange:toFocusOnTrackIdentifier:
_updateFramesInIndexRange:toFocusOnDetection:
_updateFramesInIndexRange:forTransition:fromDetection:toDetection:overTimeRange:
_trackDecisionsInTimeRange:
_invalidateTrackDecisions
_addGroupDecision:toTrackDecisions:nextDecision:
_addDecision:toTrackDecisions:
_addDecisions:toTrackDecisions:
_shouldAddTrackDecision:afterDecision:
_existingGroupTrackForGroupIdentifier:
decisionAfterTime:
decisionBeforeTime:
decisionNearestTime:
decisionsInTimeRange:
primaryDecisionAtTime:
secondaryDecisionAtTime:
timeRangeOfTransitionAfterDecision:
timeRangeOfTransitionBeforeDecision:
_timeRangeOfTransitionfromDecision:toDecision:
_timeRangeOfTransitionfromDecision:toDecision:didShortenTransition:
_useFixedTransition
_startTimeOfFixedTransitionToDecision:
decisionAtOrBeforeTime:
userDecisionsInTimeRange:
baseDecisionsInTimeRange:
_internalizeBaseDecisionsFromFrames:
tracks
trackForIdentifier:
trackForGroupIdentifier:
trackForDecision:
_trackAllocatorState
_userCreatedTracks
_reloadTrackAllocator
_internalizeTracksFromFrames:
_internalizeTracksFromChangesDictionary:
_internalizeDetectionsFromTrack:
_internalizeTrackForDetection:
_internalizeGroupTrackForDetection:
_internalizeTrackWithNumberFromDetection:
_internalizeTrackWithGroupNumberFromDetection:
_internalizeTrackNumberForFocusIdentifier:
setFramesAreMutable:
addFrame:
setBaseDecisionsAreMutable:
addBaseDecision:
focusOnTrackIdentifier:atTime:strong:
focusOnGroupIdentifier:atTime:strong:
focusOnDetection:strong:
focusOnTrack:atTime:strong:
_bestDetectionForGroupIdentifier:time:
addUserDecision:
removeUserDecision:
removeAllUserDecisions
_removeUserDecision:
_resolveIfGroupDecision:
_updateDecisionsAndFramesInTimeRange:
_updateEffectiveDecisionsInTimeRange:
_effectiveDecisionsFromBaseDecisionsRange:userDecisionsRange:endTime:
_zipBaseDecisionsRange:userDecisionsRange:
_effectiveDecisionsFromZippedDecisions:endTime:
addTrack:
removeTrack:
_addZeroDisparityTrack
_addTrack:identifier:
_removeTrack:
_isEditCreatedTrack:
_removeAllUserTracksForReloading
_addGroupTrack:
_addDetectionsFromCustomTrack:
_addDetectionsFromFixedFocusTrack:
_removeDetectionsWithTrackIdentifier:
_notifyDelegateOfChangesToDecisionsInTimeRange:
_notifyDelegateOfChangesToFramesInTimeRange:
changesDictionary
_userDecisionDictionaries
_userTrackDictionaries
changesDictionaryTrimmedByTimeRange:
_userDecisionDictionariesTrimmedByTimeRange:
_userTrackDictionariesTrimmedByTimeRange:
changesDelegate
setChangesDelegate:
setAsset:
baseDecisions
setBaseDecisions:
userDecisions
setUserDecisions:
effectiveDecisions
setEffectiveDecisions:
setTrackDecisions:
mutableTracks
setMutableTracks:
trackForNumber
setTrackForNumber:
zeroDisparityTrack
setZeroDisparityTrack:
mutableGroupTracks
setMutableGroupTracks:
trackForGroupNumber
setTrackForGroupNumber:
trackNumberForFocusIdentifier
setTrackNumberForFocusIdentifier:
trackAllocatorForFocusIdentifier
setTrackAllocatorForFocusIdentifier:
didInternalizeTracks
setDidInternalizeTracks:
focusPuller
setFocusPuller:
loadedUserAperture
setLoadedUserAperture:
loadedTrackAllocatorState
setLoadedTrackAllocatorState:
_framesAreMutable
_baseDecisionsAreMutable
_serialQueue
_didInternalizeTracks
_loadedUserAperture
_changesDelegate
_baseDecisions
_userDecisions
_effectiveDecisions
_mutableTracks
_trackForNumber
_zeroDisparityTrack
_mutableGroupTracks
_trackForGroupNumber
_trackNumberForFocusIdentifier
_trackAllocatorForFocusIdentifier
_focusPuller
_loadedTrackAllocatorState
T@"AVAsset",&,N,V_asset
T@"PTGlobalCinematographyMetadata",&,N,V_globals
T@"PTCinematographyFocusFramesOptions",&,N,V_focusFramesOptions
T@"NSArray",&,N,V_baseDecisions
T@"NSMutableArray",&,N,V_userDecisions
T@"NSMutableArray",&,N,V_effectiveDecisions
T@"NSArray",&,N,V_trackDecisions
T@"NSMutableArray",&,N,V_mutableTracks
T@"NSMutableDictionary",&,N,V_trackForNumber
T@"PTCinematographyTrack",&,N,V_zeroDisparityTrack
T@"NSMutableArray",&,N,V_mutableGroupTracks
T@"NSMutableDictionary",&,N,V_trackForGroupNumber
T@"NSMutableDictionary",&,N,V_trackNumberForFocusIdentifier
T@"PTCinematographyTrackAllocator",&,N,V_trackAllocatorForFocusIdentifier
TB,N,V_didInternalizeTracks
T@"PTCinematographyFocusPuller",&,N,V_focusPuller
Tf,N,V_loadedUserAperture
Tq,N,V_loadedTrackAllocatorState
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
T@"<PTCinematographyScriptChanges>",W,N,V_changesDelegate
accessibilityLabelForDetectionType:
initWithTime:rect:focusDistance:
setDetectionType:
setTrackNumber:
focusIdentifier
accessibilityLabel
setFocusIdentifier:
_clearCachedFocusIdentifier
_isInvalid
_setInvalid:
trackNumber
cachedFocusIdentifier
setCachedFocusIdentifier:
cachedFocusIdentifierWasSetByClient
setCachedFocusIdentifierWasSetByClient:
_isExcludedAsCinematicChoice
_setExcludedAsCinematicChoice:
_namedSignals
set_namedSignals:
_cachedFocusIdentifierWasSetByClient
__excludedAsCinematicChoice
_trackNumber
_cachedFocusIdentifier
__namedSignals
T@"NSNumber",&,N,V_trackNumber
T@"NSString",&,N,V_cachedFocusIdentifier
TB,N,V_cachedFocusIdentifierWasSetByClient
_excludedAsCinematicChoice
TB,N,G_isExcludedAsCinematicChoice,S_setExcludedAsCinematicChoice:,V__excludedAsCinematicChoice
T@"NSDictionary",&,N,V__namedSignals
TQ,N,V_detectionType
Tq,N
Tq,N,V_groupIdentifier
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_rect
T@"NSString",R,N
_detectionsFromCinematographyArray:
_cinematographyArrayFromDetections:
_fixMissingTrackIdentifier:
_isEqual:
_detectionByChangingTime:
isAutoFocusDetection
isFixedFocusDetection
isCustomDetection
_detectionsByTrackIdentifierFromArray:
_detectionsByFocusIdentifierFromArray:
_prefixForDetectionType:
_detectionTypeForPrefix:
_invalid
TB,N,G_isInvalid,S_setInvalid:
TB,N,G_isExcludedAsCinematicChoice,S_setExcludedAsCinematicChoice:
T@"NSDictionary",&,N
load3DTextureFromData:cubeSize:metal:outTexture:
init:cubeSize:data:
cubeTexture
_defaultCubeTexture
detectionsRaw
detectionsFiltered
unpactDetections:
filterDetections
initFilterDetections
_detectionsRaw
_detectionsFiltered
Ti,R,V_count
T^{PTHumanDetection=if[2B][2]f},R
newTextureWithDescriptor:
forwardInvocation:
methodSignatureForSelector:
newCommandQueue
newCommandQueueWithMaxCommandBufferCount:
heapTextureSizeAndAlignWithDescriptor:
heapBufferSizeAndAlignWithLength:options:
newHeapWithDescriptor:
newBufferWithLength:options:
newBufferWithBytes:length:options:
newBufferWithBytesNoCopy:length:options:deallocator:
newDepthStencilStateWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
newSamplerStateWithDescriptor:
newDefaultLibrary
newDefaultLibraryWithBundle:error:
newLibraryWithFile:error:
newLibraryWithURL:error:
newLibraryWithData:error:
newLibraryWithSource:options:error:
newLibraryWithSource:options:completionHandler:
newLibraryWithStitchedDescriptor:error:
newLibraryWithStitchedDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:error:
newRenderPipelineStateWithDescriptor:options:reflection:error:
newRenderPipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithDescriptor:options:completionHandler:
newComputePipelineStateWithFunction:error:
newComputePipelineStateWithFunction:options:reflection:error:
newComputePipelineStateWithFunction:completionHandler:
newComputePipelineStateWithFunction:options:completionHandler:
newComputePipelineStateWithDescriptor:options:reflection:error:
newComputePipelineStateWithDescriptor:options:completionHandler:
newFence
supportsFeatureSet:
supportsFamily:
supportsTextureSampleCount:
minimumLinearTextureAlignmentForPixelFormat:
minimumTextureBufferAlignmentForPixelFormat:
newRenderPipelineStateWithTileDescriptor:options:reflection:error:
newRenderPipelineStateWithTileDescriptor:options:completionHandler:
newRenderPipelineStateWithMeshDescriptor:options:reflection:error:
newRenderPipelineStateWithMeshDescriptor:options:completionHandler:
getDefaultSamplePositions:count:
newArgumentEncoderWithArguments:
supportsRasterizationRateMapWithLayerCount:
newRasterizationRateMapWithDescriptor:
newIndirectCommandBufferWithDescriptor:maxCommandCount:options:
newEvent
newSharedEvent
newSharedEventWithHandle:
newIOHandleWithURL:error:
newIOCommandQueueWithDescriptor:error:
newIOHandleWithURL:compressionMethod:error:
sparseTileSizeWithTextureType:pixelFormat:sampleCount:
sparseTileSizeInBytesForSparsePageSize:
sparseTileSizeWithTextureType:pixelFormat:sampleCount:sparsePageSize:
newCounterSampleBufferWithDescriptor:error:
sampleTimestamps:gpuTimestamp:
newArgumentEncoderWithBufferBinding:
supportsCounterSampling:
supportsVertexAmplificationCount:
newDynamicLibrary:error:
newDynamicLibraryWithURL:error:
newBinaryArchiveWithDescriptor:error:
accelerationStructureSizesWithDescriptor:
newAccelerationStructureWithSize:
newAccelerationStructureWithDescriptor:
heapAccelerationStructureSizeAndAlignWithSize:
heapAccelerationStructureSizeAndAlignWithDescriptor:
registryID
maxThreadsPerThreadgroup
isLowPower
isHeadless
isRemovable
hasUnifiedMemory
recommendedMaxWorkingSetSize
isDepth24Stencil8PixelFormatSupported
readWriteTextureSupport
argumentBuffersSupport
areRasterOrderGroupsSupported
supports32BitFloatFiltering
supports32BitMSAA
supportsQueryTextureLOD
supportsBCTextureCompression
supportsPullModelInterpolation
areBarycentricCoordsSupported
supportsShaderBarycentricCoordinates
currentAllocatedSize
maxThreadgroupMemoryLength
maxArgumentBufferSamplerCount
areProgrammableSamplePositionsSupported
sparseTileSizeInBytes
maxBufferLength
counterSets
supportsDynamicLibraries
supportsRenderDynamicLibraries
supportsRaytracing
supportsFunctionPointers
supportsFunctionPointersFromRender
supportsRaytracingFromRender
supportsPrimitiveMotionBlur
convertSparsePixelRegions:toTileRegions:withTileSize:alignmentMode:numRegions:
convertSparseTileRegions:toPixelRegions:withTileSize:numRegions:
T{?=QQQ},R
lowPower
TB,R,GisLowPower
headless
TB,R,GisHeadless
removable
TB,R,GisRemovable
depth24Stencil8PixelFormatSupported
TB,R,GisDepth24Stencil8PixelFormatSupported
rasterOrderGroupsSupported
TB,R,GareRasterOrderGroupsSupported
barycentricCoordsSupported
TB,R,GareBarycentricCoordsSupported
programmableSamplePositionsSupported
TB,R,GareProgrammableSamplePositionsSupported
reportLeaks
allowLibrariesFromOtherPlatforms
vendorName
familyName
productName
getMostCompatibleArchitecture:
compilerPropagatesThreadPriority:
_setDeviceWrapper:
_deviceWrapper
deviceSupportsFeatureSet:
deviceOrFeatureProfileSupportsFeatureSet:
minLinearTextureAlignmentForPixelFormat:
newBufferWithIOSurface:
unloadShaderCaches
libraryCacheStats
pipelineCacheStats
copyShaderCacheToPath:
supportsSampleCount:
newCommandQueueWithDescriptor:
newIndirectArgumentBufferLayoutWithStructType:
newArgumentEncoderWithLayout:
supportsTextureWriteRoundingMode:
newIndirectCommandBufferWithDescriptor:maxCount:options:
newIndirectRenderCommandEncoderWithBuffer:
newIndirectComputeCommandEncoderWithBuffer:
newSharedEventWithMachPort:
setResourcesPurgeableState:newState:oldState:count:
newAccelerationStructureWithSize:resourceIndex:
isCompatibleWithAccelerationStructure:
newAccelerationStructureWithBuffer:offset:
newAccelerationStructureWithBuffer:offset:resourceIndex:
deserializePrimitiveAccelerationStructureFromBytes:withDescriptor:
deserializeInstanceAccelerationStructureFromBytes:primitiveAccelerationStructures:withDescriptor:
newAccelerationStructureWithSize:withDescriptor:
deserializePrimitiveAccelerationStructure:fromBytes:withDescriptor:
deserializeInstanceAccelerationStructure:fromBytes:primitiveAccelerationStructures:withDescriptor:
newDynamicLibrary:computeDescriptor:error:
validateDynamicLibraryDescriptor:error:
newDynamicLibraryWithDescriptor:error:
newDynamicLibraryWithURL:options:error:
newDynamicLibraryFromURL:error:
loadDynamicLibrariesForComputeDescriptor:error:
loadDynamicLibrariesForComputeDescriptor:options:error:
loadDynamicLibrariesForFunction:insertLibraries:error:
loadDynamicLibrariesForFunction:insertLibraries:options:error:
validateDynamicLibrary:state:error:
validateDynamicLibraryURL:error:
newBinaryLibraryWithOptions:url:error:
newVisibleFunctionTableWithDescriptor:
newIntersectionFunctionTableWithDescriptor:
newRenderPipelineStateWithMeshDescriptor:error:
newRenderPipelineStateWithMeshDescriptor:completionHandler:
newProfileWithExecutionSize:
supportsBufferlessClientStorageTexture
supportsComputeMemoryBarrier
supportsRenderMemoryBarrier
supportsArgumentBuffersTier2
supportsReadWriteTextureArgumentsTier2
supportsStreamingCodecSignaling
supportsProgrammableSamplePositions
supportsLargeFramebufferConfigs
supportsCustomBorderColor
supportsSamplerAddressModeClampToHalfBorder
supports3DBCTextures
supportsRGBA10A2Gamma
supportsBGR10A2
supportsPrimitiveRestartOverride
supportsGlobalVariableRelocation
supportsGlobalVariableRelocationRender
supportsGlobalVariableRelocationCompute
supportsTLS
supports32bpcMSAATextures
supportsVertexAmplification
supportsPlacementHeaps
supportsOpenCLTextureWriteSwizzles
supportsInt64
supportsFixedLinePointFillDepthGradient
supportsLateEvalEvent
supportsNonZeroTextureWriteLOD
supportsSharedTextureHandles
supportsBufferPrefetchStatistics
supportsLimitedYUVFormats
supportsNonPrivateDepthStencilTextures
supportsNonPrivateMSAATextures
supportsSharedStorageHeapResources
supportsSharedStorageTextures
supportsLinearTextureFromSharedBuffer
supportsPipelineLibraries
supportsFragmentOnlyEncoders
supportsBufferWithIOSurface
supportsProgrammableBlending
supportsRenderToLinearTextures
supportsMemorylessRenderTargets
supportsFastMathInfNaNPropagation
supportsInvariantVertexPosition
supportsShaderLODAverage
supportsRelaxedTextureViewRequirements
supportsSeparateDepthStencil
supportsGPUStatistics
supportsCompressedTextureViewSPI
supportsRenderTargetTextureRotation
supportsDynamicControlPointCount
supportsIABHashForTools
supportsBinaryArchives
supportsBinaryLibraries
supportsDeadlineProfile
supportsFillTexture
supportsSetThreadgroupPackingDisabled
supportsASTCTextureCompression
supportsExtendedYUVFormats
supportsPublicXR10Formats
supportsSRGBwrites
supportsDepthClipMode
supportsPacked32TextureBufferWrites
supports3DASTCTextures
supportsExtendedXR10Formats
supportsFragmentBufferWrites
supportsCountingOcclusionQuery
supportsBaseVertexInstanceDrawing
supportsIndirectDrawAndDispatch
supportsTessellation
supportsReadWriteBufferArguments
supportsArrayOfTextures
supportsArrayOfSamplers
supportsCombinedMSAAStoreAndResolveAction
supportsMutableTier1ArgumentBuffers
supportsSamplerCompareFunction
supportsMSAADepthResolve
supportsMSAAStencilResolve
supportsMSAADepthResolveFilter
supportsGFXIndirectCommandBuffers
supportsCMPIndirectCommandBuffers
supportsIndirectStageInRegion
supportsIndirectTextures
supportsNorm16BCubicFiltering
supportsTextureOutOfBoundsReads
supportsTextureSwizzle
supportsAlphaYUVFormats
supportsMemoryOrderAtomics
supportsQuadGroup
supportsRenderTextureWrites
supportsImageBlocks
supportsTileShaders
supportsImageBlockSampleCoverageControl
supportsNativeHardwareFP16
supportsPostDepthCoverage
supportsMipLevelsSmallerThanBlockSize
supportsNonUniformThreadgroupSize
supportsReadWriteTextureArguments
supportsReadWriteTextureCubeArguments
supportsTextureCubeArray
supportsQuadShufflesAndBroadcast
supportsConcurrentComputeDispatch
supportsRenderPassWithoutRenderTarget
supportsRasterOrderGroups
supportsRasterOrderGroupsColorAttachment
supportsLinearTexture2DArray
supportsNonSquareTileShaders
supportsSeparateVisibilityAndShadingRate
supports2DLinearTexArraySPI
supportsLayeredRendering
supportsViewportAndScissorArray
supportsIndirectTessellation
supportsMSAAStencilResolveFilter
supportsStencilFeedback
supportsFP32TessFactors
supportsUnalignedVertexFetch
supportsSIMDGroup
supportsShaderMinLODClamp
supportsSIMDShufflesAndBroadcast
supportsWritableArrayOfTextures
supportsVariableRateRasterization
supportsYCBCRFormats
supportsYCBCRFormatsPQ
supportsYCBCRFormats12
supportsYCBCRFormatsXR
supportsASTCHDRTextureCompression
supportsSparseTextures
supportsSparseHeaps
supportsIndirectWritableTextures
supportsStatefulDynamicLibraries
supportsSharedFunctionTables
supportsRayTracingExtendedVertexFormats
supportsHeapAccelerationStructureAllocation
supportsRayTracingPerPrimitiveData
supportsRayTracingBuffersFromTables
supportsRayTracingAccelerationStructureCPUDeserialization
supportsBlackOrWhiteSamplerBorderColors
supportsMirrorClampToEdgeSamplerMode
supportsSIMDReduction
supportsDepthClipModeClampExtended
supportsTexture2DMultisampleArray
supportsForceSeamsOnCubemaps
supportsFloat16BCubicFiltering
supportsFloat16InfNanFiltering
supportsRTZRounding
supportsAnisoSampleFix
supportsYCBCRPackedFormatsPQ
supportsYCBCRPackedFormats12
supportsYCBCRPackedFormatsXR
supportsBufferBoundsChecking
supportsForkJoin
supportsDevicePartitioning
supportsComputeCompressedTextureWrite
supportsSIMDGroupMatrix
supportsInterchangeTiled
supportsQuadReduction
supportsSIMDShuffleAndFill
supportsBfloat16Format
supportsSparseDepthAttachments
supportsLossyCompression
supportsMeshShaders
supportsFunctionPointersFromMesh
supportsMeshShadersInICB
supportsCommandBufferJump
supportsStackOverflowErrorCode
supportsRayTracingICBs
supportsExplicitVisibilityGroups
bufferRobustnessSupport
deviceCreationFlags
areGPUAssertionsEnabled
setGPUAssertionsEnabled:
commandBufferErrorOptions
setCommandBufferErrorOptions:
isBCTextureCompressionSupported
targetDeviceInfo
targetDeviceArchitecture
architecture
halfFPConfig
singleFPConfig
doubleFPConfig
metalAssertionsEnabled
setMetalAssertionsEnabled:
featureProfile
simulatorHostFeatureProfile
limits
maxFramebufferStorageBits
linearTextureArrayAlignmentBytes
linearTextureArrayAlignmentSlice
maxTileBuffers
maxTileTextures
maxTileSamplers
maxTileInlineDataSize
minTilePixels
maxColorAttachments
maxVertexAttributes
maxVertexBuffers
maxVertexTextures
maxVertexSamplers
maxVertexInlineDataSize
maxInterpolants
maxFragmentBuffers
maxFragmentTextures
maxFragmentSamplers
maxFragmentInlineDataSize
maxComputeBuffers
maxComputeTextures
maxComputeSamplers
maxComputeInlineDataSize
maxComputeLocalMemorySizes
maxTotalComputeThreadsPerThreadgroup
maxComputeThreadgroupMemory
maxLineWidth
maxPointSize
maxVisibilityQueryOffset
minConstantBufferAlignmentBytes
minBufferNoCopyAlignmentBytes
maxTextureWidth1D
maxTextureWidth2D
maxTextureHeight2D
maxTextureWidth3D
maxTextureHeight3D
maxTextureDepth3D
maxTextureDimensionCube
maxTextureLayers
linearTextureAlignmentBytes
iosurfaceTextureAlignmentBytes
iosurfaceReadOnlyTextureAlignmentBytes
deviceLinearTextureAlignmentBytes
deviceLinearReadOnlyTextureAlignmentBytes
maxFunctionConstantIndices
maxComputeThreadgroupMemoryAlignmentBytes
maxInterpolatedComponents
maxTessellationFactor
maxIndirectBuffers
maxIndirectTextures
maxIndirectSamplers
maxIndirectSamplersPerDevice
maxFenceInstances
maxViewportCount
maxCustomSamplePositions
maxVertexAmplificationFactor
maxVertexAmplificationCount
maxTextureBufferWidth
maxComputeAttributes
maxIOCommandsInFlight
maxPredicatedNestingDepth
maxConstantBufferArguments
supportPriorityBand
sharedMemorySize
dedicatedMemorySize
indirectArgumentBufferCapabilities
isFloat32FilteringSupported
isMsaa32bSupported
isRTZRoundingSupported
defaultTextureWriteRoundingMode
isAnisoSampleFixSupported
isFixedLinePointFillDepthGradientSupported
isLargeMRTSupported
maxRasterizationRateLayerCount
isPlacementHeapSupported
GPUBVHBuilder
requiresRaytracingEmulation
pluginData
setPluginData:
registerDevices
supportsPrimitiveType:
indirectArgumentBufferDecodingData
setIndirectArgumentBufferDecodingData:
setupMPSFunctionTable:
resourcePatchingTypeForResourceType:
reserveResourceIndicesForResourceType:indices:indexCount:
reserveGPUAddressRange:
newBufferWithLength:options:gpuAddress:
newBufferWithBytes:length:options:gpuAddress:
newBufferWithBytesNoCopy:length:options:gpuAddress:deallocator:
newBufferWithDescriptor:
newLateEvalEvent
mapShaderSampleBufferWithBuffer:capacity:size:
unmapShaderSampleBuffer
newComputePipelineStateWithDescriptor:error:
newComputePipelineStateWithDescriptor:completionHandler:
newRenderPipelineStateWithTileDescriptor:error:
newRenderPipelineStateWithTileDescriptor:completionHandler:
newFunctionWithGLCoreIR:functionType:
newFunctionWithGLCoreIR:inputsDescription:functionType:
newFunctionWithGLESIR:functionType:
newFunctionWithGLESIR:inputsDescription:functionType:
newFunctionWithGLIR:functionType:
newFunctionWithGLIR:inputsDescription:functionType:
getShaderCacheKeys
getBVHBuilderLock
getRawBVHBuilderPtr
setRawBVHBuilderPtr:
newIndirectArgumentEncoderWithArguments:
newComputePipelineStateWithImageFilterFunctionsSPI:imageFilterFunctionInfo:error:
newLibraryWithDAG:functions:error:
newLibraryWithGraphs:functions:error:
newLibraryWithGraphsSPI:functions:error:
newLibraryWithStitchedDescriptorSPI:error:
newLibraryWithDescriptor:error:
newLibraryWithDescriptor:completionHandler:
newLibraryWithDescriptorSPI:error:
newDagStringWithGraphs:
newLibraryWithImageFilterFunctionsSPI:imageFilterFunctionInfo:error:
newLibraryWithCIFilters:imageFilterFunctionInfo:error:
newLibraryWithCIFiltersForComputePipeline:imageFilterFunctionInfo:error:
newPipelineLibraryWithFilePath:error:
startCollectingPipelineDescriptors
startCollectingPipelineDescriptorsUsingPrefixForNames:
endCollectingPipelineDescriptors
serializeRenderPipelineDescriptor:
serializeComputePipelineDescriptor:
newRenderPipelineDescriptorWithSerializedData:deserializationContext:
newComputePipelineDescriptorWithSerializedData:deserializationContext:
serializeStructType:
serializeStructType:version:
newStructTypeWithSerializedData:
newTextureWithBytesNoCopy:length:descriptor:deallocator:
newTextureLayoutWithDescriptor:isHeapOrBufferBacked:
newIndirectArgumentEncoderWithLayout:
tileSizeWithSparsePageSize:textureType:pixelFormat:sampleCount:
compileVisibleFunction:withDescriptor:destinationBinaryArchive:error:
compileVisibleFunction:withDescriptor:error:
compileVisibleFunction:withDescriptor:completionHandler:
newResourceGroupFromResources:count:
deserializeCompileTimeStats:addToDictionary:
shaderDebugInfoCaching
setShaderDebugInfoCaching:
isQuadDataSharingSupported
sparseTexturesSupport
isRGB10A2GammaSupported
isCustomBorderColorSupported
isClampToHalfBorderSupported
gpuAssertionsEnabled
TB,GareGPUAssertionsEnabled,SsetGPUAssertionsEnabled:
BCTextureCompressionSupported
TB,R,GisBCTextureCompressionSupported
Tr^{MTLTargetDeviceArch=QI*},R
T@"MTLTargetDeviceArchitecture",R
T@"MTLArchitecture",R
TB,N
Tr^{?=IIIIIIIIIIIIIIIIIIIIIIIIIIffIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIQ},R
T{IndirectArgumentBufferCapabilities=b1b1b1b29},R
quadDataSharingSupported
TB,R,GisQuadDataSharingSupported
float32FilteringSupported
TB,R,GisFloat32FilteringSupported
msaa32bSupported
TB,R,GisMsaa32bSupported
RTZRoundingSupported
TB,R,GisRTZRoundingSupported
Tq,R
AnisoSampleFixSupported
TB,R,GisAnisoSampleFixSupported
FixedLinePointFillDepthGradientSupported
TB,R,GisFixedLinePointFillDepthGradientSupported
largeMRTSupported
TB,R,GisLargeMRTSupported
RGB10A2GammaSupported
TB,R,GisRGB10A2GammaSupported
CustomBorderColorSupported
TB,R,GisCustomBorderColorSupported
ClampToHalfBorderSupported
TB,R,GisClampToHalfBorderSupported
placementHeapSupported
TB,R,GisPlacementHeapSupported
T@"MTLGPUBVHBuilder",R
T@"NSDictionary",C,N
allocatedTextures
setAllocatedTextures:
_allocatedTextures
T@"<MTLDeviceSPI>",&,V_delegate
T@"NSMutableArray",&,V_allocatedTextures
_reinit
endFrames
isNextFrameAtEnd
isNextFrameAvailable
_updateFocusDetectionForFrame:
_invalidateIsNextFrameAvailableCache
_computeIsNextFrameAvailable
_newFocusSmoother
_activeTrackNumbers
_focusSmootherForReadingWithTrackIdentifier:
_skipToNextFocusSmootherWithTrackIdentifier:
_focusSmootherForAppendingWithTrackIdentifier:
_endFocusSmoothersForTrackNumbers:
_dropAllFocusSmoothersIfLeaked
lastKnownFocusDetection
setLastKnownFocusDetection:
firstFocusSmootherByTrackNumber
setFirstFocusSmootherByTrackNumber:
didEndFrames
setDidEndFrames:
didCacheIsNextFrameAvailable
setDidCacheIsNextFrameAvailable:
isNextFrameAvailableCache
setIsNextFrameAvailableCache:
_didEndFrames
_didCacheIsNextFrameAvailable
_isNextFrameAvailableCache
_lastKnownFocusDetection
_firstFocusSmootherByTrackNumber
T@"NSMutableArray",&,V_frames
T@"PTCinematographyDetection",&,V_lastKnownFocusDetection
T@"NSMutableDictionary",&,V_firstFocusSmootherByTrackNumber
TB,V_didEndFrames
TB,V_didCacheIsNextFrameAvailable
TB,V_isNextFrameAvailableCache
stabilizationHomography
setStabilizationHomography:
estimatedMotionBlur
setEstimatedMotionBlur:
hasStabilizationHomography
hasEstimatedMotionBlur
_stabilizationHomography
_hasStabilizationHomography
_estimatedMotionBlur
_hasEstimatedMotionBlur
T{?=[3]},N
TB,R,V_hasStabilizationHomography
TB,R,V_hasEstimatedMotionBlur
initWithTime:tappedDetection:strong:
initWithTime:tappedDetection:strong:group:
isStrong
isGroupTap
_strong
_groupTap
strong
TB,R,GisStrong,V_strong
T@"NSNumber",R
groupTap
TB,R,GisGroupTap,V_groupTap
initFocusedOnDetection:
initFocusedBetweenDetection:detection:coefficient:
initWithPrimaryDetection:secondaryDetection:primaryCoefficient:
_initWithDetections:coefficients:
_setFocusOnDetection:
_setFocusBetweenDetection:detection:coefficient:
_setFocusOnPrimaryDetection:secondaryDetection:primaryCoefficient:
_initWithDetections:cinematographyDictionary:
_initWithDetections:coefficientsDictionary:
_asCoefficientsDictionary
secondaryFocusDetection
primaryFocusCoefficient
secondaryFocusCoefficient
_primaryFocusCoefficient
_secondaryFocusCoefficient
_primaryFocusDetection
_secondaryFocusDetection
T@"PTCinematographyDetection",R,N,V_primaryFocusDetection
T@"PTCinematographyDetection",R,N,V_secondaryFocusDetection
Tf,R,N,V_primaryFocusCoefficient
Tf,R,N,V_secondaryFocusCoefficient
size
readBytes:size:offset:
T@"NSData",&,V_data
initWithDevice:util:
saveState:network:msrColorPyramid:faceRects:numberOfFaceRects:
restoreState:network:disparityFilter:faceRects:numberOfFaceRects:
_disparityNetworkTemporalState
_lastQuatersizeRGBA
defaultTransition
T@"PTCinematographyTransition",R,N
initWithTime:trackIdentifier:
initWithTime:trackIdentifier:options:
initWithTime:groupIdentifier:options:
_initWithTime:trackIdentifier:groupIdentifier:transition:options:
hasMinimumDuration
hasMaximumDuration
_decisionByChangingTime:
_decisionByRemovingOptions:
isUserDecision
isStrongDecision
isGroupDecision
minimumDuration
setMinimumDuration:
maximumDuration
setMaximumDuration:
transition
_transition
_minimumDuration
_maximumDuration
TQ,R,N,V_options
Tq,N,V_type
T{?=qiIq},N,V_minimumDuration
T{?=qiIq},N,V_maximumDuration
T@"PTCinematographyTransition",R,N,V_transition
userDecision
TB,R,N,GisUserDecision
strongDecision
TB,R,N,GisStrongDecision
groupDecision
TB,R,N,GisGroupDecision
_decisionsWithCinematographyDictionaries:
_mutableDecisionsWithCinematographyDictionaries:
float4x4ToHalf3x4:
colorMatrixAndBiasFor:toRGB:fullRange:colorYCbCrDepth:
getColorTransferFunction:linearToEncoded:
getColorMatrix:
getChromaFactor2BooleanFromPTTexture:
getChromaOffsetFromPTTexture:
convertRGB:inRGBA:outRGBA:colorTransferFunction:rotateCCW:
convertRGB:inRGBA:outRGBA:colorTransferFunction:
convertRGBtoYUV:inRGBA:outLuma:outChroma:colorTransferFunction:colorYCbCrMatrix:colorYCbCrFullRange:colorYCbCrDepthOut:
convertYUVtoRGB:inLuma:inChroma:outRGBA:colorTransferFunction:colorYCbCrMatrix:colorYCbCrFullRange:colorYCbCrDepthIn:
convertRGBLinearFromPTTexture:inPTTexture:outRGBA:
convertRGBLinearToPTTexture:inRGBA:outPTTexture:
_convertRGB
_convertRGBToYUV
_convertYUVToRGB
temporaryDirectory:
findMipmapLevel:largerThan:
findMipmapLevel:largerThan:fromLevel:
reciprocalTex:inTex:outTex:epsilon:
copyTex:inTex:outTex:
multiplyTex:inTex:outTex:multiplier:
addConstant:inTex:outTex:value:
fillWithColor:color:outTex:
_drawTurboLegendTick:outTexture:rect:maxValue:
drawTurboLegend:outLuma:outChroma:rect:maxValue:
drawTurboLegend:outRGBA:rect:maxValue:
gaussianNoise:inNoise:outTex:
sobelFilterSingleChannelColor:input:output:scale:
renderDisparity:inDisparity:outLuma:outChroma:region:drawLegend:
visualizeCircleUsingRect:center:radius:outTexture:
renderRect:rect:color:fill:outTexture:
gaussianFilter3x3:inRGB:outRGB:
_defaultLibrary
_renderDisparity
_kernelCopy
_multiplyTex
_addConstant
_reciprocal
_fillWithColor
_drawTurboLegend
_drawTurboLegendYUV
_gaussianNoise
_sobelFilter
_renderRect
_visualizeCircleUsingRect
_gaussianFilter3x3
effectNetworkPath
setEffectNetworkPath:
effectNetworkConfig
setEffectNetworkConfig:
effectNetwork
setEffectNetwork:
segmentationNetwork
setSegmentationNetwork:
_effectNetworkPath
_effectNetworkConfig
_effectNetwork
T@"NSString",&,N,V_effectNetworkPath
T@"NSString",&,N,V_effectNetworkConfig
T@"PTEspressoGenericExecutor",&,N,V_effectNetwork
T@"PTEspressoGenericExecutor",&,N,V_segmentationNetwork
_originalVideoDimensions
originalVideoDimensions
setOriginalVideoDimensions:
hasOriginalVideoDimensions
_hasOriginalVideoDimensions
T{?=ii},N
TB,R,V_hasOriginalVideoDimensions
initWithDevice:version:colorSize:disparitySize:
initWithDevice:version:colorInputSize:colorOutputSize:disparitySize:
copy
device
colorInputSize
colorOutputSize
debugRendering
setDebugRendering:
verbose
setVerbose:
gpuProfiling
setGpuProfiling:
useRGBA
setUseRGBA:
_verbose
_gpuProfiling
_useRGBA
_colorInputSize
_colorOutputSize
T@"<MTLDevice>",R,&,V_device
TQ,R,V_version
T{CGSize=dd},R,V_colorInputSize
T{CGSize=dd},R,V_colorOutputSize
T{CGSize=dd},R,V_disparitySize
Tq,V_debugRendering
TB,V_verbose
TB,V_gpuProfiling
TB,V_useRGBA
isMetalDeviceSupported:
isRenderVersionSupported:
setActiveVersion:
createRenderStateWithQuality:
_descriptor
initWithDevice:library:pipelineLibrary:colorSize:pixelFormat:skipFullSizeLayer:doFirstLevelGaussianDownsample:mipmapLevelCount:
updatePyramidFromPTTexture:inPTTexture:
updateLevel0FromPTTextureRGBA:inPTTextureRGBA:doFirstLevelGaussianDownsample:
updateLevel0FromPTTextureYUV:inPTTextureYUV:doFirstLevelGaussianDownsample:
updateLevel0and1FromPTTextureRGBA:inPTTextureRGBA:
updateLevel0and1FromPTTextureYUV:inPTTextureYUV:
updatePyramid:offset:
rgbaPyramid
setRgbaPyramid:
rgbaPyramidArray
setRgbaPyramidArray:
bicubic
setBicubic:
dropHints
setDropHints:
_downscaleGaussian3x3
_updateLevel0Gaussian3x3FromRGBA
_updateLevel0Gaussian3x3FromYUV
_updateLevel0and1Gaussian3x3FromRGBA
_updateLevel0and1Gaussian3x3FromYUV
_updateLevel0Box2x2FromRGBA
_updateLevel0Box2x2FromYUV
_rgbaPyramidArray
_skipFullSizeLayer
_bicubic
T@"<MTLTexture>",&,N,V_rgbaPyramid
T@"NSArray",&,N,V_rgbaPyramidArray
TB,N,V_bicubic
T@"PTMTLDropHints",&,N,V_dropHints
deserializeMetadataWithType:fromGlobalMetadata:error:
setMetadata:ofType:
_sizeOfAtomOfType:withOptions:
_atoms
matchesRenderState:
applyToRenderState:
applyToRenderState:error:
TI,N,V_renderingVersion
nanAwareEqual:with:
defaultAperture
setDefaultAperture:
minAperture
setMinAperture:
maxAperture
setMaxAperture:
sensorCropRect
setSensorCropRect:
rawSensorSize
setRawSensorSize:
focalLength35mm
setFocalLength35mm:
extrinsicsMatrix
setExtrinsicsMatrix:
readNoise1x
setReadNoise1x:
readNoise8x
setReadNoise8x:
_minAperture
_maxAperture
_focalLength35mm
_conversionGain
_readNoise1x
_readNoise8x
_rawSensorSize
_sensorCropRect
_extrinsicsMatrix
_visCropFactor
_sensorID
_sourceColorBitDepth
_networkBias
_noiseScaleFactor
_hwModelID
Tf,N,V_defaultAperture
Tf,N,V_minAperture
Tf,N,V_maxAperture
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_sensorCropRect
T{?=ii},N,V_rawSensorSize
Tf,N,V_focalLength35mm
T{?=[4]},N,V_extrinsicsMatrix
TI,N,V_conversionGain
TI,N,V_readNoise1x
TI,N,V_readNoise8x
T,N,V_visCropFactor
TI,N,V_sensorID
TI,N,V_sourceColorBitDepth
Tf,N,V_networkBias
Tf,N,V_noiseScaleFactor
TI,N,V_hwModelID
initWithDevice:library:pipelineLibrary:useExportQualityNoise:
precomputeGaussianFromNumberOfSamples:seed:
interpolateRGBWeightUsingSourceToDest:renderRequest:inRGBWeight:
interpolateRGBWeightUsingSourceToDest:renderRequest:inRGBWeight:inGainMap:inColorCube:
_interpolateRGBWeightSourceYUVDestYUV
_interpolateRGBWeightSourceYUVDestRGBA
_interpolateRGBWeightSourceRGBADestRGBA
_studioLightInterpolateRGBWeightSourceYUVDestYUV
_precomputedGaussian
_sizePrecomputedGaussian
initDisparityFilterWithDevice:disparitySize:updateCoefficientDisparity:
initDisparityNormalFilterWithDevice:disparitySize:updateCoefficientDisparity:updateCoefficientNormal:
prepareFilter:rgbaPyramid:network:
applyFilter:disparity:
debugTexture
filteredDisparity
filteredNormal
normal
_updateCoefficientDisparity
_updateCoefficientNormal
_filteredDisparity
_temporalDisparity
_temporalNormal
_normal
_normalEstimation
initWithDevice:library:pipelineLibrary:commandQueue:effectUtil:util:sharedResources:
outSkinMask
outPersonMask
@16@0:8
@24@0:8Q16
@24@0:8@16
B24@0:8@16
@32@0:8@16@24
v16@0:8
f16@0:8
v48@0:8Q16{?=qiIq}24
B24@0:8Q16
B48@0:8Q16{?=qiIq}24
B40@0:8{?=qiIq}16
v24@0:8@16
Q16@0:8
@32@0:8Q16@24
v60@0:8@16Q24{?=qiIq}32B56
v24@0:8Q16
v40@0:8{?=qiIq}16
B32@0:8Q16Q24
v56@0:8@16Q24{?=qiIq}32
q16@0:8
v24@0:8q16
{?="plan"^v"network_index"i}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
@"NSString"
@"PTCinematographyNetworkParameters"
@"NSArray"
@"PTCinematographyDetection"
@"NSMutableArray"
@"NSMutableIndexSet"
@32@0:8@16Q24
B16@0:8
v40@0:8^v16Q24Q32
@40@0:8Q16Q24Q32
v40@0:8r^v16Q24Q32
I16@0:8
@"<PTByteStream>"
@"PTAtomStream"
@"NSError"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
i116@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32@40{CGAffineTransform=dddddd}48^{__CVBuffer=}96B104@?108
i116@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32@"PTHumanDetections"40{CGAffineTransform=dddddd}48^{__CVBuffer=}96B104@?<v@?@"<MTLCommandBuffer>">108
@"PTEffectTemporalState"24@0:8@"<MTLCommandBuffer>"16
@112@0:8@16@24@32{?=QQQ}40@64Q72B80B84@88@96@104
v24@0:8r^{__CFDictionary=}16
v32@0:8@16^{__CVBuffer=}24
@"<MTLDevice>"
@"<MTLLibrary>"
@"<MTLPipelineLibrary>"
@"<MTLCommandQueueSPI>"
@"PTRenderPipeline"
@"<PTRenderState>"
@"PTRaytracingInterpolateResult"
@"<MTLTexture>"
@"<MTLBuffer>"
@"PTMSRResize"
@"PTGuidedFilter"
@"PTRenderEffectNetwork"
@"PTEffectRelighting"
@"PTPyramidRGB"
@"PTColor"
@"PTRenderRequest"
@"PTEffectDebugLayer"
@"PTOpticalFlow"
@"PTMTLDropHints"
@"PTUtil"
@"PTEffectUtil"
@"PTEffectFilter"
B36@0:8I16^Q20^Q28
B40@0:8^{__CVBuffer=}16^Q24^Q32
B24@0:8^{__CVBuffer=}16
Q24@0:8^{__CVBuffer=}16
I56@0:8@16^{__CVBuffer=}24^@32^@40B48B52
@32@0:8^{__CVBuffer=}16@24
I24@0:8Q16
{?=qiIq}40@0:8{?=qiIq}16
{?={?=qiIq}{?=qiIq}}40@0:8{?=qiIq}16
{?={?=qiIq}{?=qiIq}}16@0:8
{?={?=qiIq}{?=qiIq}}24@0:8Q16
@40@0:8{?=qiIq}16
@64@0:8{?={?=qiIq}{?=qiIq}}16
@88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
v72@0:8{?=qiIq}16{?=qiIq}40@64
v20@0:8B16
@"PTCinematographyScript"
@20@0:8f16
@40@0:8Q16q24q32
@32@0:8Q16q24
@104@0:8@16@24@32{?=QQQ}40@64Q72B80B84@88@96
[3@"PTRenderPipeline"]
[3@"<PTRenderState>"]
v48@0:8@16@24@32f40f44
@"<MTLComputePipelineState>"
@56@0:8{?=qiIq}16^{__CVBuffer=}40^{__CVBuffer=}48
{?=qiIq}16@0:8
^{__CVBuffer=}16@0:8
^{__CVBuffer=}
{?="value"q"timescale"i"flags"I"epoch"q}
i16@0:8
@"NSArray"16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8i16
@"PTAssetReader"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v24@0:8@"AVVideoCompositionRenderContext"16
v24@0:8@"AVAsynchronousVideoCompositionRequest"16
@"NSDictionary"16@0:8
v24@0:8@"AVVideoCompositionRenderHint"16
v24@0:8^{__CVBuffer=}16
{CGAffineTransform=dddddd}16@0:8
v64@0:8{CGAffineTransform=dddddd}16
@"NSDictionary"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
B32@0:8Q16^@24
B56@0:8Q16{?=qiIq}24^@48
r^{opaqueCMFormatDescription=}16@0:8
@"AVAssetReader"
@"AVAssetReaderOutputMetadataAdaptor"
@"AVMutableVideoComposition"
@"AVAssetReaderVideoCompositionOutput"
@"PTGlobalCinematographyMetadata"
@"PTGlobalRenderingMetadata"
@"PTGlobalStabilizationMetadata"
@"PTGlobalVideoHeaderMetadata"
@"AVAsset"
r^{opaqueCMFormatDescription=}
v32@0:8S16f20^^{?}24
v32@0:8S16I20^^{?}24
f40@0:8S16r^{?=SS(?=fiI)}20I28^B32
v56@0:8S16{?=qiIq}20i44^^{?}48
f32@0:8S16r^{?=SS(?=fiI)}20I28
f36@0:8S16r^{?=SS(?=fiI)}20I28f32
I40@0:8S16r^{?=SS(?=fiI)}20I28^B32
I32@0:8S16r^{?=SS(?=fiI)}20I28
I44@0:8S16r^{?=SS(?=fiI)}20I28I32^B36
{?=qiIq}60@0:8S16i20r^{?=SS(?=fiI)}24I32{?=qiIq}36
v20@0:8f16
@24@0:8f16f20
v44@0:8f16{?=qiIq}20
f20@0:8f16
f24@0:8f16f20
f44@0:8f16{?=qiIq}20
f48@0:8f16{?=qiIq}20B44
v20@0:8I16
v32@0:8Q16Q24
v32@0:8r^v16Q24
@"<PTByteWriter>"
@"PTAtomWriter"
@24@0:8^{_NSZone=}16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
{CGSize="width"d"height"d}
@64@0:8^{__CVBuffer=}16^{__CVBuffer=}24@32{?=qiIq}40
@44@0:8@16f24Q28^{__CVBuffer=}36
@52@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20
f24@0:8@16
@40@0:8@16@24^{__CVBuffer=}32
B32@0:8{CGPoint=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
@40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B32@0:8@16@24
@56@0:8@16{?=qiIq}24^{__CVBuffer=}48
B48@0:8@16{?=qiIq}24
{CGSize=dd}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@72@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40
v56@0:8@16@24{?=qiIq}32
@104@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56@64{?=qiIq}72^{__CVBuffer=}96
Q24@0:8Q16
@56@0:8@16@24{?=qiIq}32
f60@0:8@16^v24Q32Q40Q48I56
f68@0:8@16^v24Q32Q40Q48I56@60
v40@0:8@16^{__CVBuffer=}24@32
f36@0:8f16q20Q28
B36@0:8f16@20@28
@"<PTCinematographyStreamDelegate>"
@"PTCinematographyStreamOptions"
@"PTCinematographyTrackAllocator"
@"PTCinematographyNetwork"
@"PTCinematographyFocusPuller"
@"PTCinematographyFrame"
@"PTCinematographyUserTap"
B32@0:8r^v16Q24
B40@0:8r^v16Q24Q32
@"NSError"16@0:8
@32@0:8Q16Q24
@"NSMutableData"
@"PTCinematographyFocusSmoother"
@"MutableFloatArray"
v32@0:8@16@24
@100@0:8@16@24@32{CGSize=dd}40{CGSize=dd}56q72B80B84@88i96
i32@0:8@16@24
@100@0:8@"<MTLDeviceSPI>"16@"<MTLLibrary>"24@"<MTLPipelineLibrary>"32{CGSize=dd}40{CGSize=dd}56q72B80B84@"NSDictionary"88i96
i32@0:8@"<MTLCommandBuffer>"16@"PTRenderRequest"24
v24@0:8@"<MTLHeap>"16
@"PTRenderDebugLayer"
@"<MTLDeviceSPI>"
{PTFocusEdge="width"f"gradientThreshold"f"gradientWeight"f"minMaxThreshold"f}
@"PTQualitySettings"
@"PTRaytracingUtilsV2"
@"PTGlobalReduction"
i40@0:8@16@24@32
i64@0:8@16@24@32@40@48@56
i60@0:8@16@24@32@40@48f56
i40@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32
i64@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32@"<MTLTexture>"40@"<MTLTexture>"48@"<MTLTexture>"56
i60@0:8@"<MTLCommandBuffer>"16@"<MTLTexture>"24@"<MTLTexture>"32@"<MTLTexture>"40@"<MTLTexture>"48f56
@120@0:8@16{?=QQQ}24{?=QQQ}48Q72{?=QQQ}80Q104@112
{?="width"Q"height"Q"depth"Q}
@"<MTLSamplerState>"
q24@0:8Q16
q48@0:8Q16{?=qiIq}24
@"PTCinematographyFocusFramesOptions"
v48@0:8@16@24^32^f40
@36@0:8@16i24i28i32
@36@0:8Q16i24r^v28
i24@0:8@16
i40@0:8@16i24B28@32
i56@0:8@16@24f32i36^S40@48
v28@0:8i16i20i24
i32@0:8@16B24B28
i36@0:8@16@24i32
i84@0:8@16i24@28@36@44@52@60@68@76
i48@0:8@16@24@32@40
i64@0:8@16@24@32@40i48f52^S56
i56@0:8@16@24@32@40@48
[12@"<MTLComputePipelineState>"]
[10{CGSize="width"d"height"d}]
[2[10@"<MTLTexture>"]]
[10@"<MTLTexture>"]
[2@"<MTLBuffer>"]
[2B]
@24@0:8q16
f24@0:8i16i20
@20@0:8i16
@"<MTLCommandQueue>"
i62@0:8@16@24@32@40@48 56f58
i58@0:8@16@24@32@40@48 56
i44@0:8@16@24@32f40
{?=QQQQ}16@0:8
v48@0:8{?=QQQQ}16
@"PTTexture"
{?="x"Q"y"Q"width"Q"height"Q}
@56@0:8@16{?=QQQ}24q48
@68@0:8@16{?=QQQ}24q48B56B60B64
s40@0:8@16i24B28@32
s40@0:8@16@24@32
s48@0:8@16@24@32@40
s24@0:8@16
@"LKTFlowGPU"
I24@0:8@16
I24@0:8@"NSDictionary"16
B32@0:8@"NSMutableData"16@"NSDictionary"24
@24@0:8@"NSData"16
@24@0:8I16I20
@20@0:8I16
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@24@0:8i16i20
@32@0:8@16i24i28
v40@0:8@16^i24^i32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
^{PTFigCaptureStreamFocusBlurMap=C{PTFigCaptureStreamFocusBlurMapHeader=SSSSSSSSSSSCCCCCCff}[512{PTFigCaptureStreamFocusBlurMapTile=sCCCCCC}]}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@72@0:8@16@24@32{?=QQQ}40f64f68
i52@0:8@16@24@32@40i48
v60@0:8@16@24@32@40@48f56
v40@0:8@16@24@32
v52@0:8@16@24@32@40f48
i40@0:8^{opaqueCMFormatDescription=}16@24Q32
@40@0:8^{opaqueCMFormatDescription=}16@24Q32
@48@0:8^{opaqueCMFormatDescription=}16@24Q32Q40
@56@0:8^{opaqueCMFormatDescription=}16@24Q32Q40q48
@60@0:8^{opaqueCMFormatDescription=}16@24Q32Q40B48q52
i24@0:8Q16
i20@0:8B16
@48@0:8^{opaqueCMFormatDescription=}16@24Q32q40
i40@0:8^{__CVBuffer=}16r^{__CFDictionary=}24^{__CVBuffer=}32
i88@0:8^{__CVBuffer=}16r^{__CFDictionary=}24{CGAffineTransform=dddddd}32^{__CVBuffer=}80
i96@0:8^{__CVBuffer=}16^{__CVBuffer=}24r^{__CFDictionary=}32{CGAffineTransform=dddddd}40^{__CVBuffer=}88
@"<PTEffectImpl>"
@"NSObject<OS_dispatch_queue>"
^{OpaqueVTPixelTransferSession=}
@"PTFaceAttributesNetwork"
@"PTEffectResources"
@"PTHumanDetections"
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
{?=QQQ}16@0:8
i52@0:8@16@24@32@40f48
@"<PTAbstractDisparityFilter>"
Q24@0:8@16
@80@0:8@16@24@32{CGSize=dd}40{CGSize=dd}56@72
@48@0:8@16@24@32q40
@"MPSImageSpatioTemporalGuidedFilter"
@28@0:8i16@20
@132@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112f120@124
v88@0:8@16@24@32{CGAffineTransform=dddddd}40
v88@0:8q16@24@32{CGAffineTransform=dddddd}40
@32@0:8^^{__IOSurface}16@24
^{__CVBuffer=}20@0:8i16
[2@"NSString"]
[2^{__CVBuffer}]
@40@0:8@16@24@32
@96@0:8@16@24@32@40@48@56@64@72^{?=QQQ}80@88
s36@0:8@16@24i32
I32@0:8@16^{__CVBuffer=}24
I24@0:8@?16
I20@0:8i16
@"NSMutableDictionary"
@"NSURL"
@100@0:8@16@24@32@40{?=QQQ}48@72@80B88@92
@28@0:8I16#20
v24@0:8#16
Q24@0:8@"NSDictionary"16
B32@0:8@"PTAtomWriter"16@"NSDictionary"24
@24@0:8@"PTAtomStream"16
Q32@0:8@16@24
@32@0:8@16^@24
@40@0:8@16@24^@32
B48@0:8@16@24@32^@40
#20@0:8I16
v28@0:8I16#20
@32@0:8@16I24I28
@28@0:8@16I24
@24@0:8^{DetectionData_0=QQIf[4f]}16
B24@0:8^{DetectionData_0=QQIf[4f]}16
B40@0:8@16@24@32
@"NSArray"24@0:8@"PTAtomStream"16
Q32@0:8@"NSArray"16@"NSDictionary"24
B40@0:8@"NSArray"16@"PTAtomWriter"24@"NSDictionary"32
@76@0:8@16@24{?=QQQ}32@56B64@68
I24@0:8^{__CVBuffer=}16
i36@0:8^{__IOSurface=}16^{__IOSurface=}24B32
I56@0:8^{__IOSurface=}1624i40^{__IOSurface=}44B52
i44@0:8^{__IOSurface=}16^{__IOSurface=}24B32B36B40
[10^{__CVBuffer}]
[10^{__IOSurface}]
^{__CFDictionary=}
^{CGColorSpace=}
@116@0:8@16@24@32@40@48@56@64@72{?=QQQ}80B104@108
v180@0:8^{__CVBuffer=}16@24@32{FaceRectsWrapper=[4]i}40B120@124{CGAffineTransform=dddddd}132
v108@0:8^16@24@32@40i48{CGAffineTransform=dddddd}52@100
@"PTSegmentationNetwork"
{PTSyntheticLightConfig="firstFrame"B"framesSinceLightEstimate"i"lightEstimateFrequency"i"emaCoefficient"f"fgDiffuseMinLightIntensity"f"fgDiffuseMaxLightIntensity"f}
@"PTSubjectRelighting"
@28@0:8f16Q20
@32@0:8r^f16Q24
f24@0:8Q16
r^f16@0:8
B28@0:8@16f24
@36@0:8f16Q20Q28
^f16@0:8
v28@0:8f16Q20
v36@0:8f16{_NSRange=QQ}20
v40@0:8r^f16{_NSRange=QQ}24
@56@0:8@16@24@32{CGSize=dd}40
@64@0:8@16@24@32{CGSize=dd}40Q56
v60@0:8@16@24@32i40@44i52f56
v52@0:8@16@24@32i40i44f48
[2s]
@68@0:8@16@24@32@40@48@56B64
i116@0:8@16@24@32@40@48@56@64{CGRect={CGPoint=dd}{CGSize=dd}}72f104f108i112
@"SRLv2Plist"
@32@0:8q16Q24
@"NSNumber"
#24@0:8Q16
B20@0:8B16
16@0:8
v24@0:816
@28@0:8@16i24
@"PTRenderPipelineDescriptor"
@"<RenderingIntegration>"
@108@0:8@16@24@32@40i48{CGSize=dd}52{CGSize=dd}68Q84@92@100
@"PTDisparityUpscale"
@"PTRaytracingV14RenderState"
@"PTRaytracingUtils"
v40@0:8Q16Q24@32
v32@0:8Q16q24
@20@0:8B16
Q40@0:8{?=qiIq}16
@"PTCinematographyRefinementOptions"
@"PTCinematographyFrameDetectionSmoother"
v28@0:8B16@20
@"<MTLResourceGroupSPI>"
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
@"PTFocusBlurMap"
@"NSIndexSet"
{_NSRange=QQ}16@0:8
@"PTScanlineMask_FocusBlurMap"
v28@0:8^{PTRandomDisk=[94{Half2=  }]i }16i24
{PTFocus=ffffff}52@0:8@16f24f28f32i3640B48
{PTFocusEdge=ffff}16@0:8
@56@0:8{?=QQQ}16q40@48
{PTNoiseValues=ff}24@0:8@16
v52@0:8@16@24@32@40B48
v60@0:8@16@24@32@40@48B56
i44@0:8@16@24@32B40
v96@0:8@16@24{PTFocus=ffffff}32{PTFocusEdge=ffff}72@88
v80@0:8@16@24@32{PTFocus=ffffff}40
i100@0:8@16@24@32@40{PTFocus=ffffff}48@88f96
[9@"<MTLComputePipelineState>"]
v108@0:8@16@24@32f40{PTFocus=ffffff}44i84f88@92q100
v124@0:8@16@24@32f4044B52f5660{?={?=QQQ}{?=QQQ}}76
v136@0:8@16@24@32@40f4852B60f6468f84{?={?=QQQ}{?=QQQ}}88
24@0:8@16
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
B88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?=qiIq}48^{__CVBuffer=}72^{__CVBuffer=}80
v80@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40^{__CVBuffer=}72
@"FTCinematicTapToTrack"
I64@0:8{CGAffineTransform=dddddd}16
@76@0:8^16i24{CGAffineTransform=dddddd}28
v72@0:8@16i24f28f32B36@40@48@56@64
v56@0:8@16i24^28i36@40@48
v44@0:8@16@24@32i40
v56@0:8@16@24@32f40f44@48
i88@0:8{CGAffineTransform=dddddd}16{?=QQQ}64
@52@0:8{?=qiIq}16@40B48
@32@0:8^f16Q24
v32@0:8^f16Q24
#24@0:8@16
@32@0:8{CGPoint=dd}16
@"PTCinematographyFocusBlend"
@32@0:8@16^f24
@48@0:8@16{?=qiIq}24
v52@0:8@16@24f32f36f40f44f48
@36@0:8^{__CVBuffer=}16@24I32
@"VNSequenceRequestHandler"
@"VNSession"
{PTFocus=ffffff}48@0:8@16f24f28i3236B44
v84@0:8@16@24@32{PTFocus=ffffff}40f80
@24@0:8^{FrameHeaderData_0=QQQffffffI}16
B24@0:8^{FrameHeaderData_0=QQQffffffI}16
@"NSSet"
q40@0:8{?=qiIq}16
{_NSRange=QQ}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}32@0:8{_NSRange=QQ}16
q48@0:8{?=qiIq}16:40
Q48@0:8{?=qiIq}16:40
{_NSRange=QQ}72@0:8{?={?=qiIq}{?=qiIq}}16:64
{?={?=qiIq}{?=qiIq}}40@0:8{_NSRange=QQ}16:32
{?=qiIq}32@0:8@16:24
q60@0:8{?=qiIq}16q40B48:52
q56@0:8{?=qiIq}16q40:48
@116@0:8@16@24@32@40@48@56@64B72{?=QQQ}76@100@108
^{SmoothFaceRectData=fffff{?=[2]}[4{SmoothFaceRect=fffff}]}16@0:8
i36@0:8@16^f24i32
v72@0:8@16{CGAffineTransform=dddddd}24
v64@0:8@16@24@32@40@48q56
v108@0:8@16@24^32i40@44@52{CGAffineTransform=dddddd}60
v88@0:8@16@24@32@40@48@56@64@72i80i84
@"PTSyntheticLight"
{RelightingParam="bgLightIntensity"[3f]"bgVignetteLightIntensity"[3f]"bgVignetteFalloff"f"fgOffsetFactorNear"f"fgOffsetFactorFar"f"bgThresholdDisparity"f"bgEffectThresholdDisparity"f"fgLightDesaturation"f"fgLightColor"[3f]"bgToneCurveReciprocal"[3f]}
{SmoothFaceRectData="aspect"f"lightMaskExponent"f"preumbraBendFactor"f"lightMaskWidth"f"lightMaskFaceOffsetY"f"faceEyeWeight""rotation"{?="columns"[2]}"faces"[4{SmoothFaceRect="faceCenter""faceRadius"f"bodyPos""bodySize""leftEyeCenter""leftEyeRadius"f"rightEyeCenter""rightEyeRadius"f"preumbra"f"weight"f}]}
[2f]
@"SingleColorCubeCorrectionStage"
@40@0:8@16@24@?32
B40@0:8@16@24^@32
v36@0:8@16@24B32
@56@0:8@16{?=qiIq}24B48B52
@64@0:8{?=qiIq}16{?=qiIq}40
@48@0:8q16{?=qiIq}24
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
v40@0:8@16{_NSRange=QQ}24
v48@0:8@16{?=qiIq}24
v80@0:8@16@24{?={?=qiIq}{?=qiIq}}32
@56@0:8q16Q24{?=qiIq}32
v72@0:8{?={?=qiIq}{?=qiIq}}16Q64
v56@0:8{_NSRange=QQ}16@32@40@48
v88@0:8{?={?=qiIq}{?=qiIq}}16@64@72@80
v40@0:8{_NSRange=QQ}16q32
v40@0:8{_NSRange=QQ}16@32
v104@0:8{_NSRange=QQ}16@32@40@48{?={?=qiIq}{?=qiIq}}56
{?={?=qiIq}{?=qiIq}}24@0:8@16
{?={?=qiIq}{?=qiIq}}32@0:8@16@24
{?={?=qiIq}{?=qiIq}}40@0:8@16@24^B32
{?=qiIq}24@0:8@16
B52@0:8q16{?=qiIq}24B48
B28@0:8@16B24
B52@0:8@16{?=qiIq}24B48
@72@0:8{_NSRange=QQ}16{_NSRange=QQ}32{?=qiIq}48
@48@0:8{_NSRange=QQ}16{_NSRange=QQ}32
v32@0:8@16q24
@"<PTCinematographyScriptChanges>"
@"PTCinematographyTrack"
@76@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40f72
B24@0:8q16
i44@0:8r*16I24@28^@36
@36@0:8@16I24r*28
^{PTHumanDetection=if[2B][2]f}16@0:8
[4{PTHumanDetection="groupId"i"faceRect""faceRectCenteredEma""faceRectCenteredEmaEma""headRotation""faceConfidenceLevel"f"eyeConfidenceLevel"[2B]"eyeRect"[2]"confidence"f}]
{?=QQ}24@0:8@16
{?=QQ}32@0:8Q16Q24
@40@0:8r^v16Q24Q32
@48@0:8^v16Q24Q32@?40
@40@0:8@16^{__IOSurface=}24Q32
v40@0:8@16@24@?32
v32@0:8@16@?24
@48@0:8@16Q24^@32^@40
v40@0:8@16Q24@?32
v32@0:8^{?=ff}16Q24
@40@0:8@16Q24Q32
@40@0:8@16q24^@32
{?=QQQ}40@0:8Q16Q24Q32
Q24@0:8q16
{?=QQQ}48@0:8Q16Q24Q32q40
v32@0:8^Q16^Q24
{?=QQQ}24@0:8@16
{?=QQ}24@0:8Q16
v72@0:8r^{?={?=QQQ}{?=QQQ}}16^{?={?=QQQ}{?=QQQ}}24{?=QQQ}32Q56Q64
v64@0:8r^{?={?=QQQ}{?=QQQ}}16^{?={?=QQQ}{?=QQQ}}24{?=QQQ}32Q56
@"<MTLCommandQueue>"16@0:8
@"<MTLCommandQueue>"24@0:8Q16
{?=QQ}24@0:8@"MTLTextureDescriptor"16
@"<MTLHeap>"24@0:8@"MTLHeapDescriptor"16
@"<MTLBuffer>"32@0:8Q16Q24
@"<MTLBuffer>"40@0:8r^v16Q24Q32
@"<MTLBuffer>"48@0:8^v16Q24Q32@?<v@?^vQ>40
@"<MTLDepthStencilState>"24@0:8@"MTLDepthStencilDescriptor"16
@"<MTLTexture>"24@0:8@"MTLTextureDescriptor"16
@"<MTLTexture>"40@0:8@"MTLTextureDescriptor"16^{__IOSurface=}24Q32
@"<MTLSamplerState>"24@0:8@"MTLSamplerDescriptor"16
@"<MTLLibrary>"16@0:8
@"<MTLLibrary>"32@0:8@"NSBundle"16^@24
@"<MTLLibrary>"32@0:8@"NSString"16^@24
@"<MTLLibrary>"32@0:8@"NSURL"16^@24
@"<MTLLibrary>"32@0:8@"NSObject<OS_dispatch_data>"16^@24
@"<MTLLibrary>"40@0:8@"NSString"16@"MTLCompileOptions"24^@32
v40@0:8@"NSString"16@"MTLCompileOptions"24@?<v@?@"<MTLLibrary>"@"NSError">32
@"<MTLLibrary>"32@0:8@"MTLStitchedLibraryDescriptor"16^@24
v32@0:8@"MTLStitchedLibraryDescriptor"16@?<v@?@"<MTLLibrary>"@"NSError">24
@"<MTLRenderPipelineState>"32@0:8@"MTLRenderPipelineDescriptor"16^@24
@"<MTLRenderPipelineState>"48@0:8@"MTLRenderPipelineDescriptor"16Q24^@32^@40
v32@0:8@"MTLRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
v40@0:8@"MTLRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"32@0:8@"<MTLFunction>"16^@24
@"<MTLComputePipelineState>"48@0:8@"<MTLFunction>"16Q24^@32^@40
v32@0:8@"<MTLFunction>"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
v40@0:8@"<MTLFunction>"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLComputePipelineState>"48@0:8@"MTLComputePipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLComputePipelineDescriptor"16Q24@?<v@?@"<MTLComputePipelineState>"@"MTLComputePipelineReflection"@"NSError">32
@"<MTLFence>"16@0:8
@"<MTLRenderPipelineState>"48@0:8@"MTLTileRenderPipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLTileRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLRenderPipelineState>"48@0:8@"MTLMeshRenderPipelineDescriptor"16Q24^@32^@40
v40@0:8@"MTLMeshRenderPipelineDescriptor"16Q24@?<v@?@"<MTLRenderPipelineState>"@"MTLRenderPipelineReflection"@"NSError">32
@"<MTLArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLRasterizationRateMap>"24@0:8@"MTLRasterizationRateMapDescriptor"16
@"<MTLIndirectCommandBuffer>"40@0:8@"MTLIndirectCommandBufferDescriptor"16Q24Q32
@"<MTLEvent>"16@0:8
@"<MTLSharedEvent>"16@0:8
@"<MTLSharedEvent>"24@0:8@"MTLSharedEventHandle"16
@"<MTLIOFileHandle>"32@0:8@"NSURL"16^@24
@"<MTLIOCommandQueue>"32@0:8@"MTLIOCommandQueueDescriptor"16^@24
@"<MTLIOFileHandle>"40@0:8@"NSURL"16q24^@32
@"<MTLCounterSampleBuffer>"32@0:8@"MTLCounterSampleBufferDescriptor"16^@24
@"<MTLArgumentEncoder>"24@0:8@"<MTLBufferBinding>"16
@"<MTLDynamicLibrary>"32@0:8@"<MTLLibrary>"16^@24
@"<MTLDynamicLibrary>"32@0:8@"NSURL"16^@24
@"<MTLBinaryArchive>"32@0:8@"MTLBinaryArchiveDescriptor"16^@24
{?=QQQ}24@0:8@"MTLAccelerationStructureDescriptor"16
@"<MTLAccelerationStructure>"24@0:8Q16
@"<MTLAccelerationStructure>"24@0:8@"MTLAccelerationStructureDescriptor"16
{?=QQ}24@0:8@"MTLAccelerationStructureDescriptor"16
@24@0:8^{__IOSurface=}16
{?=II}16@0:8
B44@0:8^@16Q24^Q32i40
B24@0:8{?=II}16
@32@0:8^v16@24
@40@0:8^v16@24@32
v40@0:8@16r^v24@32
v48@0:8@16r^v24@32@40
B32@0:8@16^@24
@40@0:8@16Q24^@32
@48@0:8@16@24Q32^@40
B36@0:8@16B24^@28
@40@0:8Q16@24^@32
r^{MTLTargetDeviceArch=QI*}16@0:8
r^{?=IIIIIIIIIIIIIIIIIIIIIIIIIIffIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIQ}16@0:8
{IndirectArgumentBufferCapabilities=b1b1b1b29}16@0:8
v24@0:8^{MPSFunctionTable=}16
v40@0:8Q16^Q24Q32
B32@0:8{_NSRange=QQ}16
@48@0:8r^v16Q24Q32Q40
@56@0:8^v16Q24Q32Q40@?48
B40@0:8^{?=III}16Q24Q32
@32@0:8^v16Q24
@40@0:8^v16@24Q32
^v16@0:8
^{os_unfair_lock_s=I}16@0:8
@40@0:8@16r^{?=BQ^{?}}24^@32
@48@0:8^v16Q24@32@?40
@28@0:8@16B24
{?=QQQ}48@0:8q16Q24Q32Q40
v48@0:8@16@24@32^@40
v40@0:8@16@24^@32
@32@0:8r^@16Q24
@"MTLArchitecture"24@0:8@"NSArray"16
v24@0:8@"<MTLDeviceSPI>"16
@"<MTLDevice>"16@0:8
@"<MTLBuffer>"24@0:8^{__IOSurface=}16
B24@0:8@"NSString"16
@"<MTLCommandQueue>"24@0:8@"MTLCommandQueueDescriptor"16
@"_MTLIndirectArgumentBufferLayout"24@0:8@"MTLStructType"16
@"<MTLArgumentEncoder>"24@0:8@"_MTLIndirectArgumentBufferLayout"16
@"<MTLBuffer>"40@0:8@"MTLIndirectCommandBufferDescriptor"16Q24Q32
@"<MTLIndirectRenderCommandEncoder>"24@0:8@"<MTLBuffer>"16
@"<MTLIndirectComputeCommandEncoder>"24@0:8@"<MTLBuffer>"16
@"<MTLSharedEvent>"20@0:8I16
@"<MTLAccelerationStructure>"32@0:8Q16Q24
@"<MTLAccelerationStructure>"32@0:8@"<MTLBuffer>"16Q24
@"<MTLAccelerationStructure>"40@0:8@"<MTLBuffer>"16Q24Q32
@"<MTLAccelerationStructure>"32@0:8^v16@"MTLAccelerationStructureDescriptor"24
@"<MTLAccelerationStructure>"40@0:8^v16@"NSArray"24@"MTLAccelerationStructureDescriptor"32
@"<MTLAccelerationStructure>"32@0:8Q16@"MTLAccelerationStructureAllocationDescriptor"24
v40@0:8@"<MTLAccelerationStructure>"16r^v24@"MTLAccelerationStructureDescriptor"32
v48@0:8@"<MTLAccelerationStructure>"16r^v24@"NSArray"32@"MTLAccelerationStructureDescriptor"40
@"<MTLDynamicLibrary>"40@0:8@"<MTLLibrary>"16@"MTLComputePipelineDescriptor"24^@32
B32@0:8@"MTLDynamicLibraryDescriptorSPI"16^@24
@"<MTLDynamicLibrary>"32@0:8@"MTLDynamicLibraryDescriptorSPI"16^@24
@"<MTLDynamicLibrary>"40@0:8@"NSURL"16Q24^@32
@"NSArray"32@0:8@"MTLComputePipelineDescriptor"16^@24
@"NSArray"40@0:8@"MTLComputePipelineDescriptor"16Q24^@32
@"NSArray"40@0:8@"MTLFunction"16@"NSArray"24^@32
@"NSArray"48@0:8@"MTLFunction"16@"NSArray"24Q32^@40
B36@0:8@"<MTLLibrary>"16B24^@28
B32@0:8@"NSURL"16^@24
@"<MTLBinaryArchive>"40@0:8Q16@"NSURL"24^@32
@"<MTLVisibleFunctionTable>"24@0:8@"MTLVisibleFunctionTableDescriptor"16
@"<MTLIntersectionFunctionTable>"24@0:8@"MTLIntersectionFunctionTableDescriptor"16
@"<MTLRenderPipelineState>"32@0:8@"MTLMeshRenderPipelineDescriptor"16^@24
v32@0:8@"MTLMeshRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
@"<MTLDeadlineProfile>"24@0:8Q16
@"MTLTargetDeviceArchitecture"16@0:8
@"MTLArchitecture"16@0:8
@"MTLGPUBVHBuilder"16@0:8
v24@0:8@"NSDictionary"16
@"NSObject<OS_dispatch_data>"16@0:8
v24@0:8@"NSObject<OS_dispatch_data>"16
@"<MTLBuffer>"40@0:8Q16Q24Q32
@"<MTLBuffer>"48@0:8r^v16Q24Q32Q40
@"<MTLBuffer>"56@0:8^v16Q24Q32Q40@?<v@?^vQ>48
@"<MTLBuffer>"24@0:8@"MTLBufferDescriptor"16
@"<MTLLateEvalEvent>"16@0:8
@"<MTLComputePipelineState>"32@0:8@"MTLComputePipelineDescriptor"16^@24
v32@0:8@"MTLComputePipelineDescriptor"16@?<v@?@"<MTLComputePipelineState>"@"NSError">24
@"<MTLRenderPipelineState>"32@0:8@"MTLTileRenderPipelineDescriptor"16^@24
v32@0:8@"MTLTileRenderPipelineDescriptor"16@?<v@?@"<MTLRenderPipelineState>"@"NSError">24
@"<MTLFunction>"32@0:8^v16Q24
@"<MTLFunction>"40@0:8^v16@"NSObject<OS_dispatch_data>"24Q32
v24@0:8@"MTLGPUBVHBuilder"16
@"<MTLIndirectArgumentEncoder>"24@0:8@"NSArray"16
@"<MTLComputePipelineState>"40@0:8@"NSArray"16r^{?=BQ^{?}}24^@32
@"<MTLLibrary>"40@0:8@"NSString"16@"NSArray"24^@32
@"<MTLLibrary>"40@0:8@"NSArray"16@"NSArray"24^@32
@"<MTLLibrary>"32@0:8@"MTLStitchedLibraryDescriptorSPI"16^@24
@"NSString"24@0:8@"NSArray"16
@"<MTLLibrary>"40@0:8@"NSArray"16r^{?=BQ^{?}}24^@32
@"<MTLPipelineLibrarySPI>"32@0:8@"NSString"16^@24
v24@0:8@"NSString"16
@"NSData"16@0:8
@"NSObject<OS_dispatch_data>"24@0:8@"MTLRenderPipelineDescriptor"16
@"NSObject<OS_dispatch_data>"24@0:8@"MTLComputePipelineDescriptor"16
@"MTLRenderPipelineDescriptor"32@0:8@"NSObject<OS_dispatch_data>"16@"<MTLDeserializationContext>"24
@"MTLComputePipelineDescriptor"32@0:8@"NSObject<OS_dispatch_data>"16@"<MTLDeserializationContext>"24
@"NSObject<OS_dispatch_data>"24@0:8@"MTLStructType"16
@"NSObject<OS_dispatch_data>"28@0:8@"MTLStructType"16I24
@"MTLStructType"24@0:8@"NSObject<OS_dispatch_data>"16
@"<MTLTexture>"48@0:8^v16Q24@"MTLTextureDescriptor"32@?<v@?^vQ>40
@"<MTLTextureLayout>"28@0:8@"MTLTextureDescriptor"16B24
@"<MTLIndirectArgumentEncoder>"24@0:8@"_MTLIndirectArgumentBufferLayout"16
v48@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24@"<MTLBinaryArchive>"32^@40
v40@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24^@32
v40@0:8@"<MTLFunction>"16@"MTLFunctionDescriptor"24@?<v@?@"NSError">32
@"<MTLResourceGroupSPI>"32@0:8r^@16Q24
v32@0:8@"NSObject<OS_dispatch_data>"16@"NSMutableDictionary"24
{?=[3]}16@0:8
v64@0:8{?=[3]}16
{?="columns"[3]}
@56@0:8{?=qiIq}16@40B48B52
@36@0:8@16@24f32
v36@0:8@16@24f32
Q40@0:8^v16Q24Q32
@"NSData"
v52@0:8@16@24@32^40i48
v56@0:8@16@24@32^40^i48
@48@0:8{?=qiIq}16q40
@56@0:8{?=qiIq}16q40Q48
@72@0:8{?=qiIq}16q40q48@56Q64
@"PTCinematographyTransition"
{half3x4=[3{half4=[4 ]}]}80@0:8{?=[4]}16
{half3x4=[3{half4=[4 ]}]}32@0:8i16B20B24i28
i28@0:8@16B24
{bool2=BB}24@0:8@16
i48@0:8@16@24@32i40B44
i44@0:8@16@24@32i40
i64@0:8@16@24@32@40i48i52B56i60
@48@0:8@16{?=QQQ}24
@52@0:8@16{?=QQQ}24i48
i48@0:8@1624@40
i84@0:8@16@24{?={?=QQQ}{?=QQQ}}32f80
i92@0:8@16@24@32{?={?=QQQ}{?=QQQ}}40f88
i100@0:8@16@24@32@40{?={?=QQQ}{?=QQQ}}48B96
i44@0:8@1624f32@36
i68@0:8@162440B56@60
@"PTEspressoGenericExecutor"
{?="width"i"height"i}
{?=ii}16@0:8
v24@0:8{?=ii}16
@64@0:8@16Q24{CGSize=dd}32{CGSize=dd}48
@80@0:8@16Q24{CGSize=dd}32{CGSize=dd}48{CGSize=dd}64
@76@0:8@16@24@32{CGSize=dd}40Q56B64B68i72
i36@0:8@16@24B32
i28@0:8@16i24
@36@0:8I16@20^@28
v28@0:8@16I24
I28@0:8I16@20
[5@"NSObject<PTSerializable>"]
B24@0:8f16f20
{?=[4]}16@0:8
v80@0:8{?=[4]}16
{?="columns"[4]}
@44@0:8@16@24@32B40
v24@0:8i16I20
v56@0:8@16@24@32@40@48
@52@0:8@16{?=QQQ}24f48
@56@0:8@16{?=QQQ}24f48f52
I40@0:8@16@24@32
I32@0:8@16@24
[2@"<MTLTexture>"]
@"PTDisparityFilterExponentialMovingAverageLKTMotion"
@"PTNormalEstimation"
@72@0:8@16@24@32@40@48@56@64
f024
v024
f224
v224
02fx
024x
22fx
224x
800L
sidh
