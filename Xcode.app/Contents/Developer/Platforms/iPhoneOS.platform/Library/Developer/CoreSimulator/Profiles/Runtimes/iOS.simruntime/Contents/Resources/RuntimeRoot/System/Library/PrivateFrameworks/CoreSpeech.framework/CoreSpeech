?ffffff
?(knN
$@frmaEVAWffac
fff?
@mcpl
mcpl
Bmcplsupoxeps
Median
+[CSUtils(Statistics) distributionDictionary:]
average:
stddev:
q24@?0@8@16
v8@?0
-[CSGestureMonitor isTriggerHandheld]
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
CSAudioInjectionBuiltInEngine
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
-[CSAudioInjectionBuiltInEngine audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:]_block_invoke
trigger-time
-[NviDataLogger logData:]
-[NviDataLogger stream:handleEvent:]
CSMicUsageReporter
-[CSMicUsageReporter _reportsDynamicActivityAttribute:bundleId:]
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_DICTATION
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_SIRI
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_SIRI_AND_DICTATION
STDynamicActivityAttributionPublisher
Class getSTDynamicActivityAttributionPublisherClass(void)_block_invoke
CSMicUsageReporter.m
Unable to find class %s
void *SystemStatusLibrary(void)
-[CSGestureMonitorPhone _startMonitoringWithQueue:]
v16@?0@8
CMWakeGestureManager
Class getCMWakeGestureManagerClass(void)_block_invoke
CSGestureMonitorPhone.m
void *CoreMotionLibrary(void)
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId:completion:]
CSVoiceTriggerAssetHandler.m
CSAudioSessionController Queue
-[CSAudioSessionController dealloc]
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController _createXPCClientConnectionIfNeeded]
-[CSAudioSessionController _startMonitoring]
-[CSAudioSessionController _stopMonitoring]
-[CSAudioSessionController _registerInterruptionNotification]
-[CSAudioSessionController _registerAudioRouteChangeNotification]
-[CSAudioSessionController _handleInterruption:]_block_invoke
-[CSAudioSessionController _mediaServicesWereLost:]_block_invoke
-[CSAudioSessionController _mediaServicesWereReset:]_block_invoke
-[CSAudioSessionController _audioRouteChanged:]_block_invoke
-[CSAudioSessionController _teardownXPCClientIfNeeded]
-[CSAudioSessionController CSXPCClient:didDisconnect:]_block_invoke
-[CSAudioSessionController coreSpeechDaemonStateMonitor:didReceiveStateChanged:]_block_invoke
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
triggeredPhrase
AttSiri
AttSiriJS
AttSiriCC
AttSiriHS
mitigationModelConfigFile
defaultAFTMValue
nldaConfigFile
allowKeywordFile
allowKeywordCount
useSpkrId
ouresConfig.json
nldaConfig.json
allowList.txt
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
v12@?0I8
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
announcemessage
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSAudioStreamHolding dealloc]
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unknown
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
v16@?0@"NSError"8
-[CSAttSiriServiceClient init]_block_invoke
-[CSAttSiriServiceClient init]
-[CSAttSiriServiceClient startAttendingWithContext:]
com.apple.corespeech.corespeechd.attsiri.service
-[CSAttSiriServiceClient _setupAttSiriSvcXpcConnection]_block_invoke
-[CSAttSiriServiceClient attSiriDidDetectAttendingTrigger:]
-[CSAttSiriServiceClient attSiriAttendingTimeoutTriggered]
-[CSAttSiriServiceClient attSiriAttendingFailed]
firstPassTriggerSource
ApplicationProcessor
Remora
CSPreMyriadCoordinator Queue
-[CSPreMyriadCoordinator _clearPendingRemoraVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]_block_invoke
-[CSPreMyriadCoordinator _clearPendingBuiltInVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]_block_invoke
v32@?0@"NSString"8@"CSPreMyriadVoiceTriggerMetaData"16^B24
-[CSPreMyriadCoordinator secondPassDidStopForClient:deviceId:]
-[CSPreMyriadCoordinator secondPassDidStartForClient:deviceId:withFirstPassEstimate:]
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
v20@?0B8@"NSError"12
-[CSAudioRecordContext(AVVC) avvcContextSettings]
voiceTriggerInfo
route
source
siriVolume.json
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple2
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidMusicVSpreadDeviceSimple2
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidMusicVOffsetDeviceSimple2
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidMusicHOffsetDeviceSimple2
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidMusicSteepnessDeviceSimple2
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimple2OutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCADeviceSimple2OutputMinTargetDB
SSVCADeviceSimple2OutputMaxTargetDB
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAMinTTSSystemVolumeSimple2
SSVCAMaxTTSSystemVolumeSimple2
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceSimple2ASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicDilationFactorDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicVSpreadDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicVOffsetDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicHOffsetDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicSteepnessDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCADeviceSimpleASVOffMinTTSVolume]
-[CSAsset(SmartSiriVolume) _getNumberFromASVDictionaryForKey:category:default:]
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
%@ {recordDeviceInfo = %@, playbackRoute = %@, playbackDevices = %@
-[CSSpeakerRecognitionProxy initWithDelegate:]
-[CSSpeakerRecognitionProxy startXPCConnection]
-[CSSpeakerRecognitionProxy invalidateXPCConnection]
-[CSSpeakerRecognitionProxy didReceiveSpeakerRecognitionScoreCard:]
-[CSSpeakerRecognitionProxy didFinishSpeakerRecognition:]
CSVoiceTriggerXPCService Queue
-[CSVoiceTriggerXPCService enableVoiceTrigger:withAssertion:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setPhraseSpotterBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setRaiseToSpeakBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:]_block_invoke
-[CSVoiceTriggerXPCService fetchVoiceTriggerDailyStats]_block_invoke
-[CSVoiceTriggerXPCService _createXPCClientConnectionIfNeeded:]
-[CSVoiceTriggerXPCService voiceTriggerXPCClient:didDisconnect:]_block_invoke
-[CSVoiceTriggerXPCService _teardownXPCClientIfNeeded]
v12@?0i8
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssets.ma.new-asset-installed
Languages
Footprint
Premium
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _fetchCurrentMetrics]
BeepCancellerMetrics
-[CSOtherAppRecordingStateMonitor handleOtherAppRecordingStateChange:]
-[CSOtherAppRecordingStateMonitor _systemControllerDied:]
com.apple.corespeech.benchmark.xpc
+[CSBenchmarkService pingpong:completion:]_block_invoke
TEST
v16@?0@"NSString"8
+[CSBenchmarkService pingpong:completion:]
+[CSBenchmarkService runLstmPhsModelWithConfig:withUrl:completion:]_block_invoke
+[CSBenchmarkService runVTSecondPassModelWithConfig:locale:withUrl:completion:]_block_invoke
+[CSBenchmarkService runOSDAnalyzerWithConfig:withUrl:completion:]_block_invoke
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
com.apple.assistant
Siri Global
 - %@
CSKeychainValueForAccountAndKey
B8@?0
-[CSSmartSiriVolumeEnablePolicyHomePod _addSmartSiriVolumeEnabledConditions]_block_invoke
-[CSContinuousAudioFingerprintEnabledPolicyHomePod _addContinousAudioFingerprintEnabledConditions]_block_invoke
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
HID event callback queue
cancelled device
Created HID device successfully
Error : Failed in creating device
-[CSHostLauncherDarwin wakeHostForVoiceTrigger]
ReportDescriptor
RequestTimeout
HIDRelaySupport
HIDRelayUSBInterface
SiriHIDDevice
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
com.apple.corespeech.CSAccessorySiriClientBehaviourMonitor
-[CSAccessorySiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyWillStopStream:reason:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStopStream:reason:withEventUUID:forAccessory:]_block_invoke
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstRoutedState:]
-[CSAudioRouteChangeMonitorImplWatch _notifySiriInputSourceOutOfBandState:]
-[CSAudioRouteChangeMonitorImplWatch _systemControllerDied:]
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
CSAudioSampleRateConverter.m
Too many buffers
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
CSLanguageDetectorAssetMonitor
v24@?0@"NSArray"8@"NSError"16
-[CSLanguageDetectorAssetMonitor startMonitor]_block_invoke
en-US
-[CSLanguageDetectorAssetMonitor _supportedLocale:]_block_invoke
v24@?0@"CSAsset"8@"NSError"16
com.apple.MobileAsset.LanguageDetectorAssets.ma.new-asset-installed
-[CSSiriSpeechRecordingContext dealloc]
v24@?0@"NSURL"8@"NSError"16
%@ (sessionUUID = %@)
-[CSSiriSpeechRecordingContext initWithSessionUUID:turnIdentifier:]
com.apple.assistant.request.speech-context
-[CSSiriSpeechRecordingContext becomeCurrent]
-[CSSiriSpeechRecordingContext resignCurrent]
-[CSSiriSpeechRecordingContext updateStartSpeechId:]
-[CSSiriSpeechRecordingContext updateSelectedResultCandidateId:]
-[CSSiriSpeechRecordingContext updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:]
-[CSSiriSpeechRecordingContext getAudioRecordRouteAndDeviceIdentificationWithCompletion:]_block_invoke
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]_block_invoke_2
v16@?0q8
-[CSSiriSpeechRecordingContext updateAudioRecordContext:]
-[CSSiriSpeechRecordingContext updateAudioRecordDeviceInfo:]
-[CSSiriSpeechRecordingContext updateVoiceTriggerInfo:]
-[CSSiriSpeechRecordingContext updateRecordingInfo:]
-[CSSiriSpeechRecordingContext updateRecordingSettings:]
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]
Start Recording
sessionUUID
v16@?0@"<AFAssertionContextMutating>"8
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]_block_invoke
v24@?0@"AFAssertionContext"8@"NSError"16
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]
Two Shot Detection
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke_2
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke
-[CSSiriSpeechRecordingContext willStopRecordingAtHostTime:]
Stop Recording
-[CSSiriSpeechRecordingContext didStopRecordingWithError:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithContext:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithError:]
-[CSSiriSpeechRecordingContext beginRecordingAudioWithAudioStreamBasicDescription:]
-[CSSiriSpeechRecordingContext endRecordingAudio]
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke_2
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke
%@.wav
@"NSString"8@?0
-[CSSiriSpeechRecordingContext _finalizeAudioFileWriterWithCompletion:]
v32@?0@"NSFileHandle"8@"NSURL"16@"NSError"24
-[CSSiriSpeechRecordingContext instrumentSiriCueForAlertType:]_block_invoke
-[CSSiriSpeechRecordingContext emitRequestLinkEventForMHUUID:]
-[CSSiriSpeechRecordingContext _didBecomeCurrent]
-[CSSiriSpeechRecordingContext _didResignCurrent]
Donating recorded audio to CoreSpeech
-[CSSiriSpeechRecordingContext _didResignCurrent]_block_invoke_2
v12@?0B8
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke
ALLOWED
DENIED
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke_2
-[CSSiriSpeechRecordingContext _removeRecordedAudio]
com.apple.CoreSpeech.Connection.Listener
-[CSSmartSiriVolumeClient init]
-[CSSmartSiriVolumeClient getVolumeForTTSType:withContext:]_block_invoke
v24@?0@"NSError"8@"CSSmartSiriVolumeEstimate"16
-[CSSmartSiriVolumeClient setSmartSiriVolumePercentage:]_block_invoke
-[CSSmartSiriVolumeClient setSmartSiriVolumeDirection:]_block_invoke
-[CSSmartSiriVolumeClient setPermanentVolumeOffsetWithDirection:]_block_invoke
-[CSSmartSiriVolumeClient didTTSVolumeChangeForReason:]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]
com.apple.corespeech.corespeechd.ssv.service
-[CSSmartSiriVolumeClient _createClientConnection]_block_invoke
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
BuiltInSpeaker
-[NSString(XPCObject) _cs_initWithXPCObject:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:]
com.apple.corespeech.corespeechd.voiceid.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
voiceTriggerEventInfo
otherCtxt
audioRecordCtx
-[CSVoiceIdXPCClient _notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:]
type
body
result
resultErrorDomain
resultErrorCode
-[CSShadowMicScoreCreator calculateShadowMicScore]
-[CSBluetoothWirelessSplitterMonitorImpIOS updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
CSBluetoothWirelessSplitterMonitorImpIOS.m
-[CSBluetoothWirelessSplitterMonitorImpIOS splitterState:]_block_invoke
v16@?0@"CSBluetoothWirelessSplitterInfo"8
-[CSBluetoothWirelessSplitterMonitorImpIOS _startMonitoringWithQueue:]_block_invoke
-[CSBluetoothWirelessSplitterMonitorImpIOS _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitorImpIOS _stopMonitoring]
v20@?0Q8B16
com.apple.bluetooth.WirelessSplitterOn
NviError
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
com.apple.corespeech.corespeechd.activation.xpc
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
event
modelHash
dictationPriors
earLoggingInfo
interactionId
HistBufferSizeinSecs
NumLeadingFrames
MinSpeechFrames
NumLatestLanguages
CSLanguageDetector
dummy-version
-[CSLanguageDetector _startMonitorLanguageDetectorAssetDownload]
-[CSLanguageDetector _setupLanguageDetectorWithOption:]
-[CSLanguageDetector resetForNewRequest:]_block_invoke_3
-[CSLanguageDetector cancelCurrentRequest]_block_invoke
-[CSLanguageDetector setInteractionIDforCurrentRequest:]_block_invoke
-[CSLanguageDetector _initializeStartOfSpeechDetector:samplingRate:]
-[CSLanguageDetector _constructLangPriors]
-[CSLanguageDetector _setNumLatestLangFromConfigFile:]
CSLanguageDetector.m
Unexpected!! Received dir for: %@
-[CSLanguageDetector _readJsonDictionaryAt:]
-[CSLanguageDetector _logSoSResult:toPath:]
-[CSLanguageDetector _logLanguageDetectorMetricsForLoggingInfo:]
-[CSLanguageDetector languageDetector:result:]
-[CSLanguageDetector languageDetectorDidCompleteProcessing:loggingInfo:]_block_invoke
SpgRegportedStartSampleId
EffectiveStartSampleId
-result.json
-[CSLanguageDetector startOfSpeechDetector:foundStartSampleAt:]_block_invoke
-result.wav
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin splitterState]
-[CSBluetoothWirelessSplitterMonitorImplDarwin _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin _stopMonitoring]
CSStopRecordingReasonDefault
CSStopRecordingForClientEndpoint
CSStopRecordingForServerEndpoint
CSStopRecordingForReleaseAudioSession
CSStopRecordingForRequestCancellation
, %llu
, %f}
triggerEndMachTime
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
FirstPktLatency
TrailingPktLatency
TrailingPktSpeechLatency
-[CSEndpointLatencyInfo addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:]
-[CSEndpointLatencyInfo report]
-[CSCommandControlStreamEventMonitor isStreaming]
CSAVVCRecordingClientMonitor Queue
-[CSAVVCRecordingClientMonitor _startMonitoringWithQueue:]_block_invoke_2
v24@?0Q8@"NSError"16
v20@?0B8Q12
-[CSAVVCRecordingClientMonitor _startMonitoringWithQueue:]
-[CSAVVCRecordingClientMonitor _stopMonitoring]
-[CSAVVCRecordingClientMonitor CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAVVCRecordingClientMonitor _didReceiveAVVCRecordingClientNumberChange:]
CSSiriAudioFileWriterErrorDomain
CSSiriAudioFileWriterExtAudioFileErrorDomain
SavedAudioFile
CSSiriAudioFileWriter.m
Invalid parameter not satisfying: %@
type != AFAudioFileTypeNone
CSSiriAudioFileWriterQueue
-[CSSiriAudioFileWriter _initWithType:pathGenerator:xorFileHandle:priority:]_block_invoke
path
-[CSSiriAudioFileWriter _close]
-[CSSiriAudioFileWriter _delete]
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]
AudioFile Already configured
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]_block_invoke
-[CSSiriAudioFileWriter appendAudioData:]_block_invoke
-[CSSiriAudioFileWriter flushWithCompletion:]_block_invoke
_AudioStreamBasicDescriptionForAFAudioFileType
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
reason
CoreSpeechXPC service invalidated
v32@?0@"NSString"8@"NSString"16@"NSError"24
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
v24@?0@"NSString"8@"NSError"16
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
v32@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSError"24
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
CSHangUpEnabledMonitor queue
-[CSHangUpEnabledMonitor _checkCanUseVoiceTriggerDuringCallEnabled]
-[CSHangUpEnabledMonitor _voiceTriggerDuringCallEnabledDidChange]_block_invoke
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
[requiresHistoricalBuffer = %@]
[useCustomizedRecordSettings = %@]
[lpcmIsFloat = %@]
[isSiri = %@]
[sampleRate = %lf]
[numberOfChannels = %lu]
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
v32@?0Q8q16@"NSError"24
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:]
-[CSSpeechManager _handleClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _startClearLoggingFilesTimer]
-[CSSpeechEndHostTimeEstimator notifyTrailingSilenceDurationAtEndpoint:]
-[CSSpeechEndHostTimeEstimator estimatedSpeechEndHostTime]
CSCommandControlListener
-[CSCommandControlListener startListenWithOption:completion:]
-[CSCommandControlListener _startRequestWithCompletion:]_block_invoke
-[CSCommandControlListener _startRequestWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]_block_invoke
-[CSCommandControlListener audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSCommandControlListener CSXPCClient:didDisconnect:]_block_invoke
FlexKwdSpotter
recognizer_flexKwd.json
flexKwdConfigFile
flexKwd.Thresholds
flexKwdThresholdsFile
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
RecordedAudio
TrimmedAudio
com.apple.corespeech.endpointer.xpc.client
com.apple.corespeech.endpointer.xpc.connection
com.apple.corespeech.endpointer.xpc.delegate
-[CSEndpointerXPCClient endpointerModelVersion]_block_invoke_2
v24@?0@"NSError"8@"NSString"16
-[CSEndpointerXPCClient endpointerModelVersion]
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]_block_invoke_2
v24@?0@"NSError"8d16
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]
-[CSEndpointerXPCClient endPointAnalyzerType]_block_invoke_2
v24@?0@"NSError"8Q16
-[CSEndpointerXPCClient endPointAnalyzerType]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.endpointer.service
-[CSEndpointerXPCClient _createClientConnection]_block_invoke
-[CSEndpointerXPCClient didDetectHardEndpointAtTime:withMetrics:]_block_invoke
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
deque
-[NviDirectionalitySignalProvider initWithDataSource:assetsProvider:]
-[NviDirectionalitySignalProvider addDelegate:]
-[NviDirectionalitySignalProvider removeDelegate:]
-[NviDirectionalitySignalProvider startWithNviContext:didStartHandler:]
-[NviDirectionalitySignalProvider reset]
-[NviDirectionalitySignalProvider stopWithDidStopHandler:]
-[CSConnectionListener initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:queue:]
-[CSConnectionListener dealloc]
-[CSConnectionListener listener:shouldAcceptNewConnection:]
corespeech.corespeechd.xpc
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke
-[CSConnectionListener notifyClientsWithBlock:]_block_invoke
-[CSConnectionListener resumeConnection]
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
triggerStartSampleCount
clientStartSampleCount
triggerFireMachTime
activeChannel
twoShotAudibleFeedbackDelay
hfpTriggerDuringPhoneCall
musicVolume
mediaPlayState
CSSpeechRecordSettingsKey_AudioSessionActiveDelay
CSSpeechRecordSettingsKey_AudioSessionActiveReason
CSSpeechRecordSettingsKey_LanguageDetectorLocales
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguages
CSSpeechRecordSettingsKey_LanguageDetectorCurrentKeyboard
CSSpeechRecordSettingsKey_LanguageDetectorWasLanguageToggled
CSSpeechRecordSettingsKey_LanguageDetectorMultilingualKeyboardLanguages
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardConvoLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardGlobalLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorPreviousMessageLanguage
CSSpeechRecordSettingsKey_LanguageDetectorGlobalLastKeyboardUsed
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorConversationalMessages
CSSpeechRecordSettingsKey_disableEndpointer
CSSpeechRecordSettingsKey_DictationRequestAppName
CSSpeechRecordSettingsKey_DictationRequestAppBundleID
CSSpeechRecordSettingsKey_DictationStartSampleId
CSSpeechRecordSettingsKey_isDucking
CSSpeechRecordSettingsKey_disableLocalSpeechRecognizer
CSSpeechRecordSettingsKey_triggerEventInfo
CSSpeechRecordSettingsKey_requestMHUUID
CSSpeechRecordSettingsKey_siriSessionUUID
CSSpeechRecordSettingsKey_asrOnDevice
CSSpeechRecordSettingsKey_disablePrewarmLocalAsrAtStartRecording
CSSpeechRecordSettingsKey_shouldSkipStartRecordingAlert
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdKnownUserRawScores
spIdUserScoresVersion
spIdKnownUserProfileVersions
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
userIdentityClassification
userClassified
CSSpeechController
CSSpeechController ContextReset
com.apple.corespeech.twoShotAudibleFeedback
MediaPlayingObserverQueue
v16@?0@"NSOrderedSet"8
-[CSSpeechController initializeRecordSessionWithRecordContext:]
-[CSSpeechController startController]
-[CSSpeechController prepareRecordWithSettings:error:]
-[CSSpeechController _fetchLastTriggerInfo]
-[CSSpeechController _fetchLastTriggerInfo]_block_invoke_2
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSSpeechController _currentConfigurationSupportsDucking]
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]
com.apple.corespeech.ducking
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]_block_invoke
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]
-[CSSpeechController _cancelPendingAudioSessionActivateForReason:]
-[CSSpeechController _performPendingAudioSessionActivateForReason:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:error:]
-[CSSpeechController _doActivateAudioSessionWithReason:error:]
-[CSSpeechController _updateRecordContextIfNeeded:]
-[CSSpeechController setCurrentRecordContext:error:]
-[CSSpeechController preheat]
-[CSSpeechController prewarmAudioSession]
-[CSSpeechController resetAudioSession]
-[CSSpeechController reset]
-[CSSpeechController releaseAudioSession]
-[CSSpeechController releaseAudioSession:]
v32@?0@8#16@?<v@?>24
-[CSSpeechController startRecordingWithSettings:error:]
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke_2
-[CSSpeechController _startPhaticDecision]
-[CSSpeechController _startPhaticDecision]_block_invoke
not 
-[CSSpeechController stopRecording]
-[CSSpeechController stopRecordingWithOptions:]
-[CSSpeechController recordRoute]
-[CSSpeechController recordDeviceInfo]
-[CSSpeechController audioDeviceInfo]
-[CSSpeechController playbackRoute]
-[CSSpeechController _didStopForReason:]
-[CSSpeechController audioStreamProvider:didStopStreamUnexpectly:]
-[CSSpeechController _audioStreamProvdider:audioBufferAvailable:]
-[CSSpeechController audioStreamProvider:audioChunkForTVAvailable:]_block_invoke
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]_block_invoke
-[CSSpeechController audioSessionProvider:providerInvalidated:]_block_invoke_2
-[CSSpeechController audioSessionProvider:didChangeContext:]
-[CSSpeechController audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:]
-[CSSpeechController audioSessionProviderBeginInterruption:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]_block_invoke
-[CSSpeechController audioSessionProviderEndInterruption:]
-[CSSpeechController audioSessionProviderEndInterruption:]_block_invoke
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]_block_invoke
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]_block_invoke
-[CSSpeechController didTTSVolumeChange:forReason:]
-[CSSpeechController didTTSVolumeChange:forReason:]_block_invoke
-[CSSpeechController audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:]
-[CSSpeechController setAlertSoundFromURL:forType:force:]
-[CSSpeechController playAlertSoundForType:]
-[CSSpeechController playRecordStartingAlertAndResetEndpointer]
-[CSSpeechController stopEndpointer]
-[CSSpeechController setMeteringEnabled:]
-[CSSpeechController _createAudioPowerMeterIfNeeded]
-[CSSpeechController outputReferenceChannel]
-[CSSpeechController voiceTriggerInfo]
-[CSSpeechController endpointer:detectedTwoShotAtTime:]
-[CSSpeechController keywordDetectorDidDetectKeyword]_block_invoke
-[CSSpeechController _shouldRunHybridSDSDMitigation]
v20@?0B8@"NSArray"12
-[CSSpeechController _fetchAudioDecoderForTV:]
-[CSSpeechController _createAudioProviderFromXPCWithContext:]
Accounts
Speech Identifier
%c%c%c%c
none
-[CSSpeechController endpointerModelVersion]
-[CSSpeechController cancelCurrentLanguageDetectorRequest]_block_invoke
-[CSSpeechController beginWaitingForMyriad]
-[CSSpeechController endWaitingForMyriadWithDecision:]
-[CSSpeechController _setSoundPlayingState]
 NOT
-[CSSpeechController CSXPCClient:didDisconnect:]_block_invoke
-[CSSpeechController _teardownAudioProviderIfNeeded]
-[CSSpeechController _setMediaPlaybackState:isInterrupted:]
-[CSSpeechController _setAlarmIsPlaying:]
-[CSSpeechController _setTimerIsPlaying:]
-[CSSpeechController nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidFire:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidDismiss:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidFire:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidDismiss:]_block_invoke
com.apple.CoreSpeech.Connection.SSR.Client
com.apple.CoreSpeech.Connection.SSR
-[CSSSRXPCClient init]
-[CSSSRXPCClient _getRemoteServiceProxyObject]
-[CSSSRXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.ssr.service
-[CSSSRXPCClient _createClientConnection]_block_invoke
-[CSSSRXPCClient didReceiveSpeakerRecognitionScoreCard:]
-[CSSSRXPCClient didFinishSpeakerRecognition:]
RequestContext
DetectedToken
TriggerMachTime
TriggerAbsStartSampleId
{attendingCtx: %@, detctedToken: %@, triggerMachTime=%llu, triggerStartSampleId=%llu}
rtblobs
adkblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
adklocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
%@ {request = %@, options = %@, player = %@, playerItem = %@}
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]_block_invoke
Unable to create player item.
Unable to replace current item of player.
Timed out when waiting for player item status to change to ready to play.
status
Failed to change player item status to ready to play.
v24@?0@8@16
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when it is already active.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke
Audio playback session is already inactive after preparation.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke_2
Audio playback session is already inactive after player seek to begin.
Player failed to seek to begin.
Stopped playback.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _resetPlayerItem]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemDidPlayToEndTime:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemFailedToPlayToEndTime:]
Player item failed to play to end time.
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
-[CSVoiceTriggerAssetHandlerDarwin _getVoiceTriggerAssetFromAssetManager:]
-[CSVoiceTriggerAssetHandlerDarwin _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerDarwin CSRemoteAssetManagerDidDownloadNewAsset:]
-[CSVoiceTriggerAssetHandlerDarwin CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
-[NviSignalProvidersController initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:]
-[NviSignalProvidersController dealloc]
NviSignalProvidersController.m
No DataSource found for SignalType: %@
-[NviSignalProvidersController _setupSignalProviders:]
-[NviSignalProvidersController _startDataSourcesWithContext:]
-[NviSignalProvidersController _startDataSourcesWithContext:]_block_invoke
-[NviSignalProvidersController _startSignalProvidersWithContext:]
-[NviSignalProvidersController _startSignalProvidersWithContext:]_block_invoke
-[NviSignalProvidersController _stopDataSources]_block_invoke
-[NviSignalProvidersController _stopDataSources]
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]_block_invoke
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]
-[NviSignalProvidersController _iterateSignalMask:withHandler:]
v16@?0@"<NviSignalProvider>"8
CSXPCClient Reply Queue
CSXPCClient connection Queue
-[CSXPCClient connect]_block_invoke
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient _sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
context
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
forceSetAlert
soundPath
alertStartTime
-[CSXPCClient alertStartTime]_block_invoke
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]_block_invoke
-[CSXPCClient averagePowerForChannel:]_block_invoke
-[CSXPCClient audioMetric]_block_invoke
audioMetric
audioStreamRequest
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient audioStreamWithRequest:streamName:completion:]_block_invoke
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
startAudioStreamOption
v16@?0@"NSDictionary"8
-[CSXPCClient acousticSLResultForContext:completion:]
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke_2
acousticSLResult
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke
-[CSXPCClient triggerInfoForContext:completion:]
rtsTriggerInfo
recordRoute
audioDeviceInfo
recordSettings
-[CSXPCClient audioStreamId]
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkFrom:to:channelIdx:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient audioChunkToEndFrom:channelIdx:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
-[CSXPCClient setAnnounceCallsEnabled:withStreamHandleID:]
-[CSXPCClient attachTandemStream:toPrimaryStream:completion:]
deviceID
sessionID
-[CSXPCClient audioSessionIdForDeviceId:]
sampleCount
-[CSXPCClient hostTimeFromSampleCount:]_block_invoke
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
-[CSXPCClient sampleCountFromHostTime:]_block_invoke
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
option
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
stopReason
chunk
hardwareConfig
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
triggerScore
configVersion
languageCode
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
@"NSDictionary"8@?0
com.apple.corespeech.SecondPassWakeUp
unknown
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:withPhrase:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
-[CSSmartSiriVolumeManager CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:]
numImplicitUtt
numExplicitUtt
numFirstPassTriggersPerDay
vtStatistics
vtStatisticsFirstPassPeakScoreHS
vtStatisticsFirstPassPeakScoreJS
vtStatisticsFirstPassTriggerSource
vtStatisticsRecognizerScoreHS
vtStatisticsRecognizerScoreJS
vtStatisticsTriggerScoreHS
vtStatisticsTriggerScoreJS
vtStatisticsMitigationScore
vtStatisticsInvocationTypeId
vtStatisticsFirstPassDetectionTime
vtStatisticsRepetitionSimilarityScore
firstPassDailyMetadata
firstPassDailyMetadataConfigVersion
firstPassDailyMetadataBuildVersion
firstPassDailyMetadataHardwareSampleRate
firstPassDailyMetadataMitigationAssetVersion
isJSEnabled
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
Logs/CrashReporter/CoreSpeech/audio/
-[CSAudioFileLog _getOrCreateAudioLogDirectory]
/tmp
en_US_POSIX
yyyyMMdd-HHmmss
%@/%@%@%@
firstPassEndSampleCount
firstPassStartSampleCount
firstPassGoodness
totalSampleCount
vtEndTime
numSamplesFromHistoricalBuffer
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
uuid
deviceId
activationInfo
vadScore
hosttime
com.apple.corespeech.fakeasset.rolling
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]_block_invoke
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]
Adaptive Siri Volume Disabled
near
medium
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolume:]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolumeOffset:]
com.apple.MobileAsset.VoiceTriggerAssetsMac
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController assetOfType:language:compatibilityVersion:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:query:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
CSAudioInjectionTvRemoteEngine
ApplicationProcessorWithRingtone
v16@?0@"AFSiriActivationResult"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
Trigger was during a ringtone
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay:deviceId:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenBluetoothDevice:deviceId:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:withContext:]_block_invoke
-[CSSiriLauncher notifyDarwinVoiceTrigger:deviceId:myriadPHash:myriadLateActivationExpirationTime:completion:]_block_invoke
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getHearstRouted:]
-[CSAudioRouteChangeMonitor hearstRouted]
-[CSAudioRouteChangeMonitor getSiriInputSourceOutOfBand:]
-[CSAudioRouteChangeMonitor siriInputSourceOutOfBand]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
CSSmartSiriVolumeEnablePolicy queue
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
v16@?0Q8
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
VoiceTrigger Asset Change Monitor
com.apple.corespeech.voicetriggerassetchange
CSAttSiriRequestSourceKey
SiriFollowupforIdleAndQuiet
Dictation
LockScreenNotification
SpeechDetection
-[NviAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[NviAudioFileWriter addSamples:numSamples:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
-[CSBluetoothWirelessSplitterMonitor splitterState]
CSBluetoothWirelessSplitterMonitor.m
-[CSBluetoothWirelessSplitterMonitor updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
-[CSBluetoothWirelessSplitterMonitor splitterState:]
-[CSBluetoothWirelessSplitterMonitor _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitor _stopMonitoring]
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyFetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyPreparedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:reason:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyReleaseAudioSession]_block_invoke
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
estimatedTTSVolume
debugLogPath
com.apple.corespeech.corespeechd.uaapservice
CSSpeechUaapXPCClient
-[CSSpeechUaapXPCClient init]_block_invoke
-[CSSpeechUaapXPCClient _handleConnectionError:]
v32@?0@"NSString"8Q16^B24
bundleId
assetFiles
messageType
message
errorMessage
locale
v32@?0@"NSString"8@"NSArray"16^B24
-[CSSpeechUaapXPCClient invalidate]
CSVoiceTriggerHandlerMacQueue
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke_2
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke_3
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSVoiceTriggerAssetHandlerMac trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
BTDetails_IsHFPRoute
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
Library/nvi
/System/Library/Audio/UISounds/jbl_begin_short.caf
/System/Library/Audio/UISounds/jbl_begin_short_carplay.caf
%@ {activationMode = %.4s, deviceIdentifier = %@, activated = %d}
-[CSSiriAudioActivationInfo initWithSpeechRecordingMode:clientConfiguration:experimentContext:]
-[CSSiriAudioActivationInfo setSpeechRequestOptions:currentActivationInfo:]
-[CSSiriAudioActivationInfo setClientConfiguration:]
-[CSSiriAudioActivationInfo _csAudioRecordTypeForSpeechRequestOptions:useBorealisBuffer:currentClientConfiguration:]
-[CSSiriAudioActivationInfo startRecordingSettingsWithRecordRoute:recordingInfo:playbackRoute:]
-[CSSiriAudioActivationInfo _alertBehaviorForRecordRoute:recordingInfo:playbackRoute:attemptsToUsePastDataBufferFrames:]
-[CSSiriAudioActivationInfo audioAlertStyleForRecordRoute:recordingInfo:playbackRoute:]
-[CSSiriAudioActivationInfo twoShotPromptTypeForRecordRoute:playbackRoute:]
-[CSSiriAudioActivationInfo audioSessionActivationTargetDate]
-[CSSiriAudioActivationInfo dateByAddingTimeIntervalSinceActivation:]
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]_block_invoke
q8@?0
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayCoreSpeechWithType:]
@"NSNumber"16@?0@"NSNumber"8
-[CSSiriAudioActivationInfo _audioSessionActiveDelayUserPerceptionWithType:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayOverride]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayServerConfiguration]
_CSSiriLanguageDetectorSettings
triggerEndSampleCount
triggerEndSeconds
com.apple.voicetrigger
com.apple.nvi
IsNviEnabled
InternalBuild
NviVADSignalType
NviKwdSignalType
NviDirectionalitySignalType
NviAsdAnchorSignalType
NviAsdPayloadSignalType
+[NviUtils strRepForNviSignalType:]
NviUtils.m
Unknown NviSignalTypeString: <%@>
NviAudioDataSrcType
+[NviUtils strRepForNviDataSourceType:]
NviDataSource_END_MARKER
+[NviUtils nviDataSourceTypeForStr:]
+[NviUtils _createDirAtPath:]
yyyyMMdd_HHmmss.SSS
Unexpected!! Received dir for NviConfig: %@
+[NviUtils readJsonDictionaryAt:]
+[NviUtils getValueFromDictionaryOfDictionaries:keypath:]
+[NviUtils createDirAtPath:]
SilenceFramesCountMs
SilenceProbability
SilenceDurationMs
ProcessedAudioMs
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
[requireSingleChannelLookup = %@]
[selectedChannel = %u]
[estimatedStartHostTime = %llu
[disableEndpointer = %d]
[disableLocalSpeechRecognizer = %d]
[disablePrewarmLocalSpeechRecognizer = %d]
[disableBoostForDoAP = %d]
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
requireSingleChannelLookup
selectedChannel
estimatedStartHostTime
disableEndpointer
disableLocalSpeechRecognizer
disablePrewarmLocalSpeechRecognizer
disableBoostForDoAP
requestMHUUID
siriSessionUUID
%@ {request = %@, options = %@, player = %@}
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _prepareWithOptions:audioSession:error:]
Failed to initialize AVAudioPlayer.
Failed to prepare to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when AVAudioPlayer is already playing.
Failed to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]
Stopped playback of AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]_block_invoke
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleBeginInterruption]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleEndInterruption:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didNotStartWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didStopWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDidFinishPlaying:successfully:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDecodeErrorDidOccur:error:]
-[CSSmartSiriVolumeRunPolicyHomePod _addSmartSiriVolumeEnabledConditions]_block_invoke
-[CSContinuousAudioFingerprintEnabledPolicy _addContinousAudioFingerprintEnabledConditions]_block_invoke
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
com.apple.corespeech.rchandling.xpc.connection
-[CSRCHandlingXPCClient processRCWithId:duration:lrnnScore:lrnnThreshold:taskId:forceAccept:completionHandler:]
-[CSRCHandlingXPCClient getMitigationDecisionForRCIdWithCompletion:completion:]
-[CSRCHandlingXPCClient _getRemoteServiceProxyObject]
-[CSRCHandlingXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.rchandling.service
-[CSRCHandlingXPCClient _createClientConnection]_block_invoke
smartSiriVolumeOverrideMediaVolume
com.apple.ssv.clientq
-[CSSmartSiriVolumeController getVolumeForTTSType:withContext:]_block_invoke
-[CSSmartSiriVolumeController _createSSVClientConnectionIfNeeded]
-[CSSmartSiriVolumeController didSmartSiriVolumeChangeForReason:]
-[CSPhraseNDEAPIScorer keywordAnalyzerNDEAPI:hasResultAvailable:forChannel:]
speakerRecognition
satThreshold
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
useSpeakerRecognitionAsset
phrase
-[CSAsset(SpeakerRecognition) satScoreThresholdForPhId:]
recognizer.json
config.txt
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
-[CSAudioTandemStream attachToPrimaryStreamWithCompletion:]
-[CSAudioTandemStream prepareAudioStreamSyncWithRequest:error:]
CSAudioTandemStream.m
-[CSAudioTandemStream prepareAudioStreamWithRequest:completion:]
-[CSAudioTandemStream startAudioStreamWithOption:completion:]
-[CSAudioTandemStream stopAudioStreamWithOption:completion:]
CSAttSiriStateMonitor queue
-[CSAttSiriStateMonitor updateState:]_block_invoke
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.request.generic
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.fetch.parallelrecording
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_VoiceProfilePeerName_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
CSP2P_VoiceProfileiTunesUserID_Key
CSP2P_VoiceProfileiTunesPassword_Key
remote
-triggered
-almost
-rejected
-activation
ssrmeta
ssvmeta
vtei
multiuser
acousticSLmeta
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService sendAcousticGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendGeckoSpeechLogsToCompanion]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:]_block_invoke
q24@?0@"NSURL"8@"NSURL"16
json
B24@?0@"NSURL"8@"NSDictionary"16
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGeckoSpeechLogsToPeerId:]_block_invoke_2
-[CSP2PService _sendGeckoSpeechLogsToPeerId:]_block_invoke
Gecko-
v24@?0@"NSUUID"8@"NSError"16
[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}
.wav
.json
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:]
fileData
fileName
peerId
%@%@
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
CSP2PService.m
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
-SL.json
-synced.wav
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
com.apple.corespeech
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
+[CSPhoneCallStateMonitor sharedInstance]
CSPhoneCallStateMonitor.m
-[CSPhoneCallStateMonitor phoneCallState]
-[CSPhoneCallStateMonitor firstPartyCall]
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider _handleEnablePolicyEvent:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
CSBuiltInSpeakerStateMonitor queue
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateMutedInfo]_block_invoke_2
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateMutedInfo]_block_invoke
muted
not muted
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateActiveInfo]_block_invoke_2
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateActiveInfo]_block_invoke
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invoke_2
active
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invoke
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]
-[CSBuiltinSpeakerStateMonitor _stopMonitoring]_block_invoke
-[CSBuiltinSpeakerStateMonitor _stopMonitoring]
-[CSBuiltinSpeakerStateMonitor CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
SignalTs, ProcessedAudioMs, StartSample, EndSample, Azimuth, EmaAzimuth, Confidence, SpatialSpreadSpectrum
%llu,%f,%lu,%lu,%f,%f,%f,
{%@, {start=%lu, end=%lu, conf=%f, az=%f, estAz=%fdist=%@}
,%d, 
%f, 
CSEndpointMetrics:::totalAudioRecorded
CSEndpointMetrics:::endpointBufferHostTime
CSEndpointMetrics:::featuresAtEndpoint
CSEndpointMetrics:::endpointerType
CSEndpointMetrics:::serverFeatureLatencyDistribution
CSEndpointMetrics:::additionalMetrics
CSEndpointMetrics:::trailingSilenceDurationAtEndpoint
[totalAudioRecorded = %f]
[endpointBufferHostTime = %llu]
[trailingSilenceDurationAtEndpoint = %f]
[endpointerType = %lu]
[featuresAtEndpoint = %@]
[additionalMetrics = %@]
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
override-asset
CSSACInfoMonitor queue
-[CSSACInfoMonitor _startMonitoringWithQueue:]
-[CSSACInfoMonitor _stopMonitoring]
-[CSSACInfoMonitor isDeviceRoleStereo]
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
com.apple.assistant.vibration-manager
com.apple.springboard.ring-vibrate.changed
com.apple.springboard.silent-vibrate.changed
-[CSSiriVibrationManager _fetchRingVibrationValue]
ring-vibrate
-[CSSiriVibrationManager _fetchSilentVibrationValue]
silent-vibrate
-[CSSiriVibrationManager handleRingVibrationValueChange]
-[CSSiriVibrationManager handleSilentVibrationValueChange]
com.apple.springboard
mobile
_fetchVibrationState
::: Initializing NVI logging...
Framework
InitNviLogging_block_invoke
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl pickableRoutesDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAuxStreamSupportDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayIsConnectedDidChange:]
-[CSAudioRouteChangeMonitorImpl _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyHearstRoutedState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifySiriInputSourceOutOfBandState:]
-[CSAudioRouteChangeMonitorImpl _systemControllerDied:]
-[CSAutomaticVolumeEnabledMonitor observeValueForKeyPath:ofObject:change:context:]_block_invoke
-[CSSiriRecordingInfo initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:]
forceSiriPCMAudio
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
Warmup
accessible-extended
accessible-maximum
extraSamplesAtStart
SearchOrMessaging
ExtraDelayMs
EndpointerDecisionLagMs
ClientLagThresholdMsKey
ClampedSFLatencyMsForClientLag
UseDefaultServerFeaturesOnClientLag
extra-delay-frequency
endpoint-threshold
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
com.apple.cs.%@.hybridClassifierfQueue
-[CSHybridEndpointer endpointerModelVersion]_block_invoke
-[CSHybridEndpointer updateEndpointerThreshold:]_block_invoke
-[CSHybridEndpointer updateEndpointerDelayedTrigger:]_block_invoke
-[CSHybridEndpointer setEndpointerOperationMode:]_block_invoke
-[CSHybridEndpointer fetchCurrentEndpointerOperationMode]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke
-[CSHybridEndpointer processServerEndpointFeatures:]
-[CSHybridEndpointer processServerEndpointFeatures:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointer processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_2
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]
endpointerModelVersion
wordCount
eosLikelihood
trailingSilenceDuration
serverFeaturesLatency
clientSilenceProbability
clientSilenceFramesCountMs
endpointResult
-[CSHybridEndpointer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointer terminateProcessing]
-[CSHybridEndpointer recordingStoppedForReason:]
-[CSHybridEndpointer stopEndpointer]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointer _readParametersFromHEPAsset:]_block_invoke
CSHybirdEndpointer.m
CSHybridEndpointer reset called
-[CSHybridEndpointer endpointerAssetManagerDidUpdateAsset:]_block_invoke
cs_hep_marsh.json
cs_hep.json
-[CSHybridEndpointer _getCSHybridEndpointerConfigForAsset:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
com.apple.nvi.csaudiosrc
-[NviCSAudioDataSource startWithNviContext:didStartHandler:]_block_invoke_2
-[NviCSAudioDataSource stopWithDidStopHandler:]_block_invoke_2
-[NviCSAudioDataSource _createAudioStreamWithCurrentNviContext]
-[NviCSAudioDataSource audioStreamProvider:avBufferAvailable:]
-[NviCSAudioDataSource audioStreamProvider:didStopStreamUnexpectly:]
-[NviCSAudioDataSource audioStreamProvider:audioChunkForTVAvailable:]
SPG.nnet
version
CSEndpointerAssetManager queue
-[CSEndpointerAssetManager init]
-[CSEndpointerAssetManager checkFirstUnlocked]
-[CSEndpointerAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]_block_invoke
-[CSEndpointerAssetManager CSAssetManagerDidDownloadNewAsset:]_block_invoke
-[CSEndpointerAssetManager CSFirstUnlockMonitor:didReceiveFirstUnlock:]_block_invoke
-[CSEndpointerAssetManager assetStatus:]
-[CSEndpointerAssetManager _getCurrentHEPAsset]
-[CSEndpointerAssetManager _updateOEPAssetsWithLanguage:]
-[CSEndpointerAssetManager _notifyAssetsUpdate]
-[CSEndpointerAssetManager _fetchEndpointMobileAssetWithLanguage:]
ModelInfo=
-[CSEndpointerAssetManager _getOEPVersionFromPath:]
-[CSEndpointerAssetManager _getFakeEndpointAsset]
-[CSEndpointDelayReporter initWithRequestMHUUID:turnIdentifier:]
-[CSEndpointDelayReporter reset]
leadingSilence
trailingSilence
endTime
-[CSEndpointDelayReporter setSpeechRecognizedContext:withEndpointerMetrics:]
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEventSynchronously:completion:]
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate]
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
-[CSAttSiriAudioSessionStateClient initWithDelegate:]
SiriStateNotificationListener
com.apple.siri.client-state-changed
-[CSAttSiriAudioSessionStateClient notifyObserver:didReceiveNotificationWithToken:]
-[CSAttSiriAudioSessionStateClient notifyObserver:didChangeStateFrom:to:]
-[CSAttSiriAudioSessionStateClient dispatchStateChangedFrom:to:]
Liminal
progChecker.json
progressiveCheckerConfigFile
contionusConversationConfigFile
checkerConfig
validInputOrigins
thresholds
shadowMode
Unspecified
VoiceTrigger
ButtonPress
B32@?0@8@16^B24
v24@?0@8^B16
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssets.ma.cached-metadata-updated
-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:]
+[CSVoiceTriggerEnabledPolicyHelper siriInCallPolicy]
com.apple.assistant.queue-monitor
-[CSSiriQueueMonitor beginMonitoring]
-[CSSiriQueueMonitor endMonitoring]
-[CSSiriQueueMonitor _addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:]
-[CSSiriQueueMonitor _beginMonitoring]
-[CSSiriQueueMonitor _endMonitoring]
-[_CSSiriQueueObserver startWithQueue:]
com.apple.assistant.queue-observer.%s
-[_CSSiriQueueObserver stop]
-[_CSSiriQueueObserver timeoutDetected]
-[CSRemoteVADCircularBuffer copySamplesFrom:to:]
copySamples
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream stopAudioStreamWithOption:completion:]_block_invoke
-[CSAudioStream isStreaming]
-[CSAudioStream updateAudioStreamStartTimeInSampleCount:]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
BluetoothA2DPOutput
BluetoothHFP
BluetoothLE
MicrophoneBuiltIn
Speaker
Headphones
MicrophoneWired
HDMIOutput
LineIn
USBAudio
ADAudioSessionPortOther
-[CSSiriAudioSession currentInputRoute]_block_invoke
v24@?0^v8Q16
-[CSSiriAudioSession currentOutputRoute]_block_invoke_3
_AudioObjectGetScalarArray
v20@?0I8r^{AudioObjectPropertyAddress=III}12
_AudioDeviceRegisterForChangedNotification
v16@?0^v8
_AudioObjectGetCFTypeRef
_AudioObjectGetIntValue
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
-[CoreSpeechXPC installedVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC _handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
fakeModel.json
fakeModel
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]
v40@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSString"24@"NSError"32
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
de-AT
de-DE
de-CH
en-AU
en-CA
en-GB
en-SG
en-IE
en-IN
en-ZA
en-NZ
it-IT
it-CH
ja-JP
zh-CN
zh-TW
nb-NO
nl-BE
nl-NL
sv-SE
tr-TR
fi-FI
he-IL
es-ES
es-US
es-CL
es-MX
fr-FR
fr-BE
fr-CA
fr-CH
ko-KR
zh-HK
yue-CN
da-DK
ms-MY
pt-BR
ru-RU
th-TH
ar-AE
ar-SA
default
Hearst
-[CoreSpeechXPC _fetchVoiceTriggerInstalledAssetWithLanguage:completion:]_block_invoke
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSRawAudioInjectionProvider init]
CSRawAudioInjectionProvider
-[CSRawAudioInjectionProvider dealloc]
-[CSRawAudioInjectionProvider setContext:completion:]
-[CSRawAudioInjectionProvider setCurrentContext:streamHandleId:error:]
-[CSRawAudioInjectionProvider prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
/var/mobile/darwin_test.wav
-[CSRawAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider isRecordingWithRecordDeviceIndicator:]
RawAudioInjection
-[CSRawAudioInjectionProvider prewarmAudioSessionWithStreamHandleId:error:]
-[CSRawAudioInjectionProvider activateAudioSessionWithReason:streamHandleId:error:]
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
CSAudioProvider
CSAudioProvider Stream Handle Queue
CSAudioProvider logging
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider supportsDuckingOnCurrentRouteWithError:]
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke_2
failed
successfully
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _createCircularBufferIfNeededWithNumChannel:playbackRoute:]
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_3
CSAudioProvider.m
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_4
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider _shouldDuckOnBuiltInSpeaker]
-[CSAudioProvider _isDuckingOnSpeakerOutputSupportedWithCurrentRoute]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setDuckOthersOption:]
-[CSAudioProvider setAlertSoundFromURL:forType:force:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke_2
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
com.apple.corespeech.recording
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _onAudioPacketWatchdogFire]
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _updateRemoteDeviceIdFromAVVCIfNeeded]
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
-[CSAlwaysOnProcessorStateMonitor _startMonitoringWithQueue:]_block_invoke
com.apple.audio.AOP.enable
-[CSAlwaysOnProcessorStateMonitor _startMonitoringWithQueue:]_block_invoke_2
-[CSAlwaysOnProcessorStateMonitor _stopMonitoring]
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
com.apple.siri.myriad.in.ear
+[CSMyriadNotifier notifyInEarMyriadTrigger]
-[CSAVCallConnectedMonitor _systemControllerDied:]
+[CSRemoteDeviceProtocolInfo localDeviceProtocolInfo]
protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, deviceProductVersion=%@, deviceProductType=%@
protocolVersion
deviceCategory
buildVersion
deviceProductVersion
deviceProductType
-[CSHybridEndpointAnalyzer init]
com.apple.cs.%@.apQueue
com.apple.cs.%@.osdQueue
-[CSHybridEndpointAnalyzer _loadAndSetupEndpointerAssetIfNecessary]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke
-[CSHybridEndpointAnalyzer updateEndpointerThreshold:]
-[CSHybridEndpointAnalyzer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointAnalyzer processServerEndpointFeatures:]
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_2
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke
-[CSHybridEndpointAnalyzer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointAnalyzer recordingStoppedForReason:]
-[CSHybridEndpointAnalyzer stopEndpointer]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointAnalyzer _readParametersFromHEPAsset:]_block_invoke
CSHybridEndpointAnalyzer.m
CSHybridEndpointAnalyzer reset called
-[CSHybridEndpointAnalyzer CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSHybridEndpointAnalyzer CSAssetManagerDidDownloadNewAsset:]
-[CSHybridEndpointAnalyzer CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSHybridEndpointAnalyzer _updateAssetWithLanguage:]_block_invoke
-[CSHybridEndpointAnalyzer _getCSHybridEndpointerConfigForAsset:]
injectionDevice
com.apple.da
ExperimentGroup
walkabout
carry
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider audioSessionIdForDeviceId:]
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
RouteChangeNotificationInfo
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy updateEndpointerThreshold:]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
CSSiriMobileBluetoothDeviceDataSource
Queue %s did not respond to watchdog and is likely blocked.
-[CSSiriMobileBluetoothDeviceDataSource init]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource _cleanUpDeviceProxies]
-[CSSiriMobileBluetoothDeviceDataSource _detachFromSession]
-[CSSiriMobileBluetoothDeviceDataSource _attachToSession]
-[CSSiriMobileBluetoothDeviceDataSource _sessionAttached:result:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionDetached:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionTerminated:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpLocalDevice]
-[CSSiriMobileBluetoothDeviceDataSource localDevice:event:result:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpAccessoryManager]
-[CSSiriMobileBluetoothDeviceDataSource accessoryManager:event:device:state:]
v16@?0@"AFBluetoothDeviceInfo"8
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithAddress:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithDeviceUID:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTLocalDeviceWithCompletion:]_block_invoke
%@ {deviceUID = %@}
%@ {address = %@}
-[CSSiriMobileBluetoothDeviceProxy dealloc]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneInEarDetectionState:]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneListeningMode:]
-[CSSiriMobileBluetoothDeviceProxy setHeadphoneListeningMode:completion:]
v24@?0^{BTDeviceImpl=}8^{BTAccessoryManagerImpl=}16
-[CSSiriMobileBluetoothDeviceProxy _reload:]
-[CSSiriMobileBluetoothDeviceProxy _reload:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _updateDeviceInfo:]
v16@?0@"<AFBluetoothDeviceObserver>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]
v16@?0@"<AFBluetoothDeviceInfoMutating>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _invalidate]
v24@?0@"<AFBluetoothDeviceObserver>"8^B16
ADBTResult
_CSSiriBTDeviceGetAddress
_CSSiriBTDeviceGetDeviceInfo
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
-[CSFirstUnlockMonitor _stopMonitoring]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection initWithConnection:]
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]_block_invoke
-[CSVoiceIdXPCConnection _handleClientMessage:client:]_block_invoke_2
-[CSVoiceIdXPCConnection _handleClientError:client:]
com.apple.
com.apple.private.
com.apple.assistant.audio-service-workloop
Internal User Classification
kAFPreferencesDidChangeDarwinNotification
Audio Session Active Delay
Server Media Playback Volume Threshold for Audio Session Activation Delay
Server Audio Session Activation Delay Above Media Playback Volume Threshold
Server Audio Session Activation Delay
com.apple.corespeech.mockremoteplugin.xpc
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
CSSPGEndpointAnalyzer
hybridendpointer.json
-[CSSPGEndpointAnalyzer reset]_block_invoke
-[CSSPGEndpointAnalyzer dealloc]
-[CSSPGEndpointAnalyzer stop]_block_invoke
-[CSSPGEndpointAnalyzer clientSilenceFeaturesAvailable:]
-[CSHomePodSettingsMonitor _stopMonitoring]
com.apple.siri.acousticsignature
ADAcousticFingerprinter
-[CSSiriAcousticFingerprinter _connectionInterrupted]
-[CSSiriAcousticFingerprinter _connectionInvalidated]
-[CSSiriAcousticFingerprinter _configureWithCurrentASBD]
-[CSSiriAcousticFingerprinter _convertPCMDataForFingerprinting:]
-[CSSiriAcousticFingerprinter appendPCMData:]_block_invoke
v16@?0@"NSData"8
-[CSSiriAcousticFingerprinter flush]_block_invoke_2
ASXSampleRateFromInt
satScore
selfLoggingMHUUID
CSSiriSpeechRecorder.m
speechController != nil
audioSessionController != nil
audioPlaybackService != nil
-[CSSiriSpeechRecorder initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:]
-[CSSiriSpeechRecorder _currentMHUUID:]
-[CSSiriSpeechRecorder _setSpeechCapturingMode:]
-[CSSiriSpeechRecorder _setEndpointerOperationMode:forceUpdate:]
-[CSSiriSpeechRecorder _setAlertsIfNeeded]
siri-begin-improved
v32@?0@"NSNumber"8@"NSNumber"16^B24
-[CSSiriSpeechRecorder _updateRecordBufferDuration]
Speech controller should not be nil.
-[CSSiriSpeechRecorder _speechControllerWithError:]
-[CSSiriSpeechRecorder _resetSpeechController]
-[CSSiriSpeechRecorder _prepareSpeechControllerWithOptions:error:]
requestDuringActiveCall
since we have no Voice Controller!
-[CSSiriSpeechRecorder _stopRecordingWithReason:hostTime:]
%d.%d
 Forcing two shot mode to NO
-[CSSiriSpeechRecorder _disableEndpointer]
-[CSSiriSpeechRecorder _playAudioAlert:]
-[CSSiriSpeechRecorder _checkAudioLoggingLimits:]
-[CSSiriSpeechRecorder _prepareDirectoryAtPath:]
-[CSSiriSpeechRecorder _setupAudioFileWritingForSpeechController:info:context:]
-[CSSiriSpeechRecorder _setupAudioFileWritingForSpeechController:info:context:]_block_invoke
PCM-%@-%@.wav
v24@?0@"NSURL"8@?<v@?>16
-[CSSiriSpeechRecorder _setEndpointStyle:]
-[CSSiriSpeechRecorder _stopRecordingForEndpointReason:]
-[CSSiriSpeechRecorder eagerlyInitializeAudioRecording]
-[CSSiriSpeechRecorder preheatWithOption:]
-[CSSiriSpeechRecorder preheatWithOption:]_block_invoke
-[CSSiriSpeechRecorder recordingInfoForPreheatWithEvent:]
-[CSSiriSpeechRecorder currentVTSatScore]
-[CSSiriSpeechRecorder prepareForMode:]
-[CSSiriSpeechRecorder prepareForMode:withOptions:]
-[CSSiriSpeechRecorder startSpeechCaptureWithContext:willStartHandler:error:]
kAudioSessionProperty_ActiveSessionDisplayIDs
, playing error alert
-[CSSiriSpeechRecorder updateSpeechSynthesisRecord:]
-[CSSiriSpeechRecorder _audioSessionID]
state
v16@?0@?<v@?@"NSDictionary">8
-[CSSiriSpeechRecorder setSpeechRequestOptions:]
-[CSSiriSpeechRecorder _updateAudioContextWithInfo:reason:]
-[CSSiriSpeechRecorder _setAudioContextWithInfo:forReason:]
-[CSSiriSpeechRecorder _updateAudioContextToPostVoiceForReason:]
-[CSSiriSpeechRecorder _updateAudioContextWithPendingInfoForReason:]
-[CSSiriSpeechRecorder releaseAudioSession]
notify
suppress (keep others interrupted forever)
-[CSSiriSpeechRecorder setSpeechWasRecognizedForElapsedTime:isFinal:]
-[CSSiriSpeechRecorder setFingerprintWasRecognized]
-[CSSiriSpeechRecorder stopSpeechCaptureForEvent:suppressAlert:hostTime:]
-[CSSiriSpeechRecorder cancelSpeechCaptureSuppressingAlert:]
-[CSSiriSpeechRecorder forceSuccessAudioAlertOnStop]
-[CSSiriSpeechRecorder _speechRecordingEventListener]_block_invoke
-[CSSiriSpeechRecorder setClientConfiguration:]
-[CSSiriSpeechRecorder playRecordingStartAlert]_block_invoke
-[CSSiriSpeechRecorder _updateAudioDeviceInfo:forReason:forcesUpdate:]
Unavailable
playbackDeviceTypes
-[CSSiriSpeechRecorder _recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStartRecording:successfully:error:]
Opus
Speex
-[CSSiriSpeechRecorder speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]_block_invoke_2
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:]
-[CSSiriSpeechRecorder getAudioRouteInstrumentationWithRecordingInfo:]
-[CSSiriSpeechRecorder speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:]
audio_recording
empty_lpcm_record_buffer
-[CSSiriSpeechRecorder _speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:]
-[CSSiriSpeechRecorder speechControllerBeginRecordInterruption:withContext:]
-[CSSiriSpeechRecorder speechControllerEndRecordInterruption:]
-[CSSiriSpeechRecorder speechControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSSiriSpeechRecorder speechController:willSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechController:didSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSiriSpeechRecorder _setLanguageDetectorDelegateIfRequired]
-[CSSiriSpeechRecorder _playStopAlertIfNecessaryForReason:endpointMode:error:]
AVVoice_RecordStoppedWithError
AVVoice_RecordStopped
-[CSSiriSpeechRecorder languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]_block_invoke
Two shot feedback
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]
Utterance Grading
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]_block_invoke
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:]
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:completion:]
-[CSSiriSpeechRecorder _speechControllerRequestsOperation:forReason:completion:]
v32@?0d8d16@"NSError"24
-[CSSiriSpeechRecorder speechControllerDidUpdateSmartSiriVolume:forReason:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]_block_invoke
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]
time
additionalMetrics
@"NSMutableDictionary"8@?0
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]_block_invoke
-[CSSiriSpeechRecorder _hardEndpointWasDetectedWithMetrics:atTime:]
-[CSSiriSpeechRecorder _performTwoShotPromptForType:atTime:]
suppressedAlert
timedOut
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]_block_invoke
delegate is nil
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptTimeoutWithUUID:]
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:]
-[CSSiriSpeechRecorder updateEndpointHintForRC:forceAccept:completion:]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted:]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted:]_block_invoke_2
v24@?0B8B12@"NSArray"16
-[CSSiriSpeechRecorder _enforceEndpointHintWithMitigation:]
-[CSSiriSpeechRecorder enforcePreviousEndpointHint]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]_block_invoke
-[CSSiriSpeechRecorder acousticFingerprinter:hasFingerprint:duration:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]_block_invoke
-[CSSiriSpeechRecorder speakerIdentificationDidDetectSpeakerWithScores:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
Siri
DictationSecureOfflineOnly
FingerprintOnly
SiriSecureOfflineOnly
SiriCoreSymptomsReporter
Class getSiriCoreSymptomsReporterClass(void)_block_invoke
void *SiriCoreLibrary(void)
yyyy_MM_dd-HHmmss.SSS
com.apple.assistant.audio-playback-service
-[CSSiriAudioPlaybackService _prewarmRequest:completion:]
-[CSSiriAudioPlaybackService _startRequest:options:preparationHandler:executionHandler:finalizationHandler:]
-[CSSiriAudioPlaybackService _handlePreparationForSession:]
v16@?0@"<CSSiriAudioPlaybackServiceListening>"8
-[CSSiriAudioPlaybackService _handleExecutionForSession:]
-[CSSiriAudioPlaybackService _handleFinalizationForSession:error:]
v32@?0@"AFAudioPlaybackRequest"8@"<CSSiriAudioPlaybackSession>"16^B24
v24@?0@"<CSSiriAudioPlaybackServiceListening>"8^B16
-[CSSiriAudioPlaybackService _evictAllReusableSessionsForReason:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
StartOfSpeech SPG queue
StartOfSpeech queue
-[CSStartOfSpeechDetector initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:]
-[CSStartOfSpeechDetector resetForNewRequest]_block_invoke
-[CSStartOfSpeechDetector clientSilenceFeaturesAvailable:]_block_invoke
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]_block_invoke
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCClient dealloc]
-[CSVoiceTriggerXPCClient _handleListenerEvent:]
-[CSVoiceTriggerXPCClient _handleListenerError:]
enable
assertion
timestamp
phraseSpotterBypass
bypassTimeout
raiseToSpeakBypass
triggerStats
-[CSVoiceTriggerXPCClient fetchVoiceTriggerStats]
v24@?0@"NSObject<OS_xpc_object>"8@?<v@?>16
_RegisterXPCActivity_block_invoke
com.apple.siri.xpc_activity.power-logging
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
-[CSLanguageCodeUpdateMonitorImplDarwin _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImplDarwin _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImplDarwin _didReceiveLanguageCodeUpdate:]
-[CSAttSiriMitigationAssetHandler setCachedAsset:]_block_invoke
-[CSAttSiriMitigationAssetHandler _receivedNewAssetUpdate:]
-[CSAttSiriMitigationAssetHandler trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString = %@}
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]_block_invoke
CSAudioConverter.m
Cannot produce ASPD for PCM
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
CreateAudioConverter
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
CSLanguageCodeUpdateMonitor.m
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor notifySiriLanguageCodeChanged:]
BuiltInMicrophoneDevice
CSVoiceTriggerEventInfoProvider Queue
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]_block_invoke
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]
-[NSData(Nvi) splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:]
CSSmartSiriVolumeRunPolicy queue
-[CSSmartSiriVolumeRunPolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
com.apple.corespeech.audioinjection.xpc
+[CSAudioInjectionServices setAudioInjectionMode:]
+[CSAudioInjectionServices audioInjectionEnabled]
+[CSAudioInjectionServices pingpong:completion:]_block_invoke
+[CSAudioInjectionServices pingpong:completion:]
v28@?0B8@"NSError"12@"NSUUID"20
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]_block_invoke
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
v36@?0B8@"NSError"12Q20Q28
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]_block_invoke_2
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke_2
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke_2
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]
Dpg:%.3f Dpd:%.3f T:%.3f
droppingPrediction
droppedPrediction
voic
carplay
hearst
raisetospeak
auto
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
detector-config
supported-locales
detector.json
sos-options.json
SPG.json
Builtin Microphone
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder userSessionActivateMonitor:didReceivedUserSessionActiveHasChanged:]_block_invoke
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setAnnounceCallsEnabled:withStreamHandleID:]
-[CSAudioRecorder setContext:completion:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjectionWithAVVCContext:]
-[CSAudioRecorder startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioRecorder stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
-[CSAudioRecorder recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
%llu
-[CSAudioRecorder audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
iPhone9,1
iPhone9,2
iPhone9,3
iPhone9,4
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckMixWithOthersForStream:duckOthers:duckToLevelInDB:mixWithOthers:]
+[CSAudioRecorder resetDuckSettings]
-[CSAudioRecorder enableMiniDucking:]
Enable
Disable
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
isBluetoothConnected
-[CSAudioRecorder voiceTriggerInfoWithRecordDeviceIndicator:]
-[CSAudioRecorder isDuckingSupportedOnCurrentRouteWithStreamHandleID:error:]
is not
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder _trackRemoteAccessoryStreamIdIfNeeded:]
-[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
-[CSAudioRecorder playAlertSoundForType:recordDevideIndicator:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _hasLocalPendingTwoShot]_block_invoke
-[CSAudioRecorder _getRecordSettingsWithRequest:]
-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId:streamHandleId:]
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@]
{isVT=%d, requestHistoricalAudio=%d, reqStartAudioSampleId=%lu, reqStartMachAbsTime=%llu}
-[NSData(XPCObject) _cs_initWithXPCObject:]
+[CSEndpointerFactory endpointerProxy]
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
+[NviSignalData headerString]
-[NviSignalData stringForLogging]
{%@:ts=%lld}
%s input dictionary is nil
%s Tagging as handheld as user interacted in last %f secs
%s Tagging as farfield as last user interaction %f secs back
%s Tagging as FarField as user dismissed
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s First Pass Score : %f, First Pass Best Start : %llu, First Pass Best End : %llu
%s Unable to write to o/p stream ! 
%s Got event! %lu
%s Got unhandled evt code %lu 
%s STDynamicActivityAttributionPublisher reporting Dictation with bundleID: %{public}@
%s STDynamicActivityAttributionPublisher reporting Siri
%s STDynamicActivityAttributionPublisher reporting Siri and Dictation
%s Start monitoring: wake Gesture
%s %{public}@ deallocated
%s audioProvider not exist
%s Start Monitoring : AudioSession notification from corespeechd
%s Stop Monitoring : AudioSession notification from corespeechd
%s reset sessionInfoProvider since xpcClient disconnected
%s CoreSpeech Daemon reset notification
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Celestial is not available on this platform.
%s notification = %{public}@
%s MobileTimer is not available on this platform.
%s Dealloc audioStreamHolding : %{public}@
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s ERR: Failed to get remote proxy object for AttSiriXPC: %@
%s _remoteSvcProxy is nil!
%s ctx=%@
%s Client Interruption Handler: %{public}@, client PID: %{public}d)
%s Client Invalidation Handler: %{public}@, client PID: %{public}d exited
%s triggerInfo: %@
%s Clearing pending homekit accessory voice trigger %{private}@
%s Handling Pending Remora VoiceTrigger Event
%s Time since last pending remora voice trigger %f. Ignoring.
%s Clearing pending built-in voice trigger %{private}@
%s Handling Pending BuiltInVoiceTrigger Event
%s Time since last pending builtin voice trigger %f. Ignoring.
%s client: %lu, deviceId: %{private}@
%s Setting mixable to yes as we are in an active call
%s Dilation factor requested for device default!
%s V Spread requested for device default!
%s V Offset requested for device default!
%s H Offset requested for device default!
%s Music steepness requested for device default!
%s Minimum TTS volume for ASV disabled case requested for device default!
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s ERR: Failed to establish XPC connection!
%s Requesting RTS %{public}@ bypass for %{public}lf seconds
%s voiceTriggerXPC client not exist
%s reset xpcClient since it disconnected
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s Another non eligible app is recording
%s CSBenchmarkService Interrupted
%s CSBenchmarkService Invalidated
%s XPC connection not exist?
%s Result: %@
%s Couldn't find keychain value %@ for account %@ %{public}d
%s SmartSiriVolume cannot be resumed since we should not monitor audio
%s ContinousAudioFingerprint cannot be resumed since we should not monitor audio
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s Failed to fetch local deviceId, abort
%s Sending HID report (length = %{public}lu) to host with deviceId info (%{public}@)
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s accessoryId %{private}@
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s Received active route change notification
%s Start monitoring : AudioRouteChangeMonitor
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Routed State : %{public}d
%s Notifying Siri Input Source Out Of Band State : %{public}d
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Override result as 'mpty'
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Cannot start monitoring language detector asset, since we already registered
%s LanguageDetector supported locale is nil : %{public}@
%s %p (sessionUUID = %@)
%s %p (sessionUUID = %@
%s %p
%s %p (startSpeechId = %@)
%s %p (selectedResultCandidateId = %@)
%s %p (allows = %d, resultCandidateId = %@)
%s route = %@, deviceIdentifier = %@, deviceUID = %@
%s %p (recordedAudioFileURL = %@)
%s %p (audioRecordContext = %@)
%s %p (audioRecordDeviceInfo = %@)
%s %p (voiceTriggerInfo = %@)
%s %p (recordingInfo = %@)
%s %p (recordingSettings = %@)
%s %p audioActivationInfo = %@
%s %p effectiveDate = %@ (%f)
%s %p (error = %@)
%s %p (relinquishmentContext = %@)
%s %p startRecordingAudioSessionAssertion = %@
%s %p audioActivationInfo = %@, time = %f
%s %p twoShotDetectionAudioSessionAssertion = %@
%s %p hostTime = %llu
%s %p context = %@
%s %p error = %@
%s %p (_recordedAudioFileURL = %@)
%s %p (_audioFileWriter = %@)
%s recordingSettings was nil
%s No alert behavior in recordingSettings
%s No alert style specified for record starting
%s Myriad won & voice trigger present, donating recorded audio to CoreSpeech.
%s %p No recorded audio.
%s %p Access to payload audio at %@ is %@, setting payload recording flag for CoreSpeech.
%s %p Donating recorded audio at %@...
%s %p Failed to donate recorded audio at %@ for  VoiceID training (error = %@).
%s %p Donated recorded audio at %@ for  Voice VoiceID training.
%s %p Removing recorded audio at %@...
%s %p Removed recorded audio at %@.
%s %p Failed to remove recorded audio at %@ (error = %@).
%s Creating SmartSiriVolume connection
%s SmartSiriVolume Remote Object Proxy is nil
%s SmartSiriVolume Failed to get estimate with %{public}@
%s SmartSiriVolume didChangeForReason: %{public}d
%s ERR: SmartSiriVolume Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SmartSiriVolume ssvConnection is nil
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s Listener connection disconnected
%s connection error: %{public}s
%s Required values is nil, bailout
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s Current wireless splitter info = %{public}@
%s Received WiressSplitterStateChange
%s Start monitoring : Wireless Splitter start
%s Cannot start monitoring Wireless Splitter because it was already started
%s Stop monitoring : Wireless Splitter
%s Not supported on this platform
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Creating LanguageDetector with config: %{public}@
%s Cannot initialize language detector since model file is not exits
%s Cannot access asset : %{public}@
%s Current LanguageDetector request cancelled
%s Setting interaction ID for current request: %@
%s Failed to initialize StartOfSpeechDetector !
%s Recoreded language array: %@ Language Prior Dictionary: %@
%s Setting NumLatestLanguages to %{public}lu 
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Error writing out SoS info meta: %{public}@
%s _EARLanguageDetectorLoggingInfo = %{public}@
%s _EARLanguageDetectorLoggingInfo analytics context %{public}@
%s %{public}@ isConfident %{public}d
%s LanguageDetector State: %ld
%s Saving circular buffer from %{public}lu to %{public}lu
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s splitterState : %{public}lu, shouldDisableSpeakerVerification : %{public}@
%s This call is not supported on darwinOS device (splitterState)
%s Advert data: %{public}@
%s advert data write failed
%s %{public}.2f ms after firstBufferStart
%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu)
%s Invalid timestamp (currentMachTime: %{public}llu arrivalTimestamp: %{public}llu)
%s numOfAudioPackets: %{public}lu, numOfValidTrailingPackets: %{public}lu, numOfValidTrailingSpeechPackets: %{public}lu, 
trailingPktLatencies: %{public}@ 
trailingPktSpeechLatencies: %{public}@
%s Fetching CommandControl Listening State: %d
%s Failed to fetch recording client info, error : %{public}@
%s Start monitoring : AVVC recording client count
%s Stop monitoring : AVVC recording client count
%s Reset AVVC recording client count due to audio server crash
%s update AVVC recording client # : %{public}lu
%s Error getting file path from provided file handle; will create our own path and handle
%s Failure disposing audio file %{public}d
%s Error removing item at URL %{public}@
%s Configuring with asbd %.4s
%s Creating audio file at URL %@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s No file url on flush
%s Failed opening fd for flushed audio file %{public}s
%s inASBD->mChannelsPerFrame = %lu
%s Error getting format info for type %{public}.4s %{public}.4s
%s CoreSpeechXPCConnection Invalidated
%s making connection to corespeechd with (%{public}d)
%s Asking VoiceTrigger locale to corespeechd
%s Current VoiceTrigger Locale = %{public}@
%s Cannot get Current VoiceTrigger Locale, falling back to en-US : %{public}@
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s VoiceTriggerDuringCall enabled = %{public}@
%s VoiceTrigger during a call is already %{public}@, received duplicated notification!
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s No audioRecorder available, return nil for audioProvider
%s have matched audioProvider with stream handle id : %llu
%s provider's streamId(%tu) is invalid, return nil
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s SpeechEndEstimation: trailingSilenceDuration = %{public}f
%s SpeechEndEstimation: TrailingSilenceDuration at endpointer(%{public}f) is longer than threshold(%{public}f), force to make 0
%s SpeechEndEstimation: _lastAudioChunkHostTime = %{public}llu, estimatedSpeechEndHostTime = %{public}llu
%s Start Listening for Command Control
%s Calling didStart of CSCommandControlListener
%s Stopping stopListenWithCompletion
%s Calling didStop of CSCommandControlListener
%s Calling didStopUnexpectly
%s Received xpc disconnection, audioStream is streaming = %{public}d
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Endpointer Failed to get epVersion
%s elapsed time = %{public}lf
%s Endpointer Failed to get elapsedTimeWithNoSpeech
%s Endpointer Failed to get endPointAnalyzerType
%s Creating RemoteServiceProxy
%s ERR: Endpointer Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: Endpointer endpointerConnection is nil
%s Endpointer didDetectHardEndpointAtTime %f withMetrics %@
%s Not supported on this platform.
%s ERR: Mach Service Name is nil - Bailing out
%s ERR: Proxy Object is nil - Bailing out
%s ERR: Exported interface is nil - Bailing out
%s Set up queue for %@
%s Started listening for %{public}@
%s Service %{public}@ dealloced - %{public}@
%s Got connection on service %{public}@
%s [Service:%{public}@] Invalid listener - %{public}@
%s Rejecting connection to %{public}@ due to entitlement
%s [Service:%{public}@] Listener Interruption Handler: %{public}@, client PID: %{public}d)
%s [Service:%{public}@] Listener Invalidation Handler: %{public}@, client PID: %{public}d exited
%s machServiceName(%@) with clientConnCount:%lu 
%s Sending message to remote object: %@
%s RemoteObjectProxy is nil for client PID (%{public}d)
%s [Service:%{public}@]
%s Using audioInjectionProvider as recorder
%s Record Context: %{public}@
%s Calling startController
%s Ignore request since it is already started
%s settings : %{public}@
%s Session Provider does not exist
%s Received special error code that corespeech needs to setContext and activate audio session again
%s CSSpeechController is already streaming audio.., we don't need to create another audio stream here
%s Prepare audio stream succeeded ? %{public}@, error - %{public}@
%s audioStreamWithRequest succeeded ? %{public}@, error - %{public}@
%s Failed to get audioStream : %{public}@
%s AudioStreamProvider is not existing?
%s Skipping audio converter setup
%s Done prepareRecord with result: %{public}@.
%s xpcClient not existing
%s received lastVoiceTriggerInfo %{public}@, lastRTSTriggerInfo %{public}@
%s ConfigSupportsDucking: %{public}d
%s Stream provider does not exist
%s Failed due to error %@.
%s Activating Audio Session Now Sync.
%s Activating Audio Session Now Async.
%s Device supports ducking on speaker output we should check config.
%s StreamProvider is already recording
%s duckingDelayedTime = %{public}f, timeIntervalSinceLastTriggerEnd = %{public}lf
%s Failed activate audio session with %{public}f seconds delay from prepareRecordWithSettings due to error %{public}@.
%s Finished activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Cancelled activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Scheduled activateAudioSession with %{public}f seconds delay in prepareRecordWithSettings.
%s Delayed active audio session: Consumed token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed active audio session: Activating audio session for reason %{public}@.
%s Delayed active audio session: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed active audio session: Successfully activate audio session for reason %{public}@.
%s Delayed active audio session: Ignored activating audio session for reason %{public}@ because the validator rejected.
%s Delayed active audio session: Ignored activate audio session for reason %{public}@ because the scheduled token %{public}@ does not match the current token %{public}@.
%s Delayed active audio session: Scheduled new token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed audio session activate: Cancelled token %{public}@ for reason %{public}@.
%s Delayed audio session activate: Consumed token %{public}@ in advance for reason %{public}@.
%s Delayed audio session activate: Activating audio session for reason %{public}@.
%s Delayed audio session activate: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed audio session activate: Successfully activate audio session for reason %{public}@.
%s Creating fake session activation notification for session activation now
%s Scheduling Lazy Audio Session activation with %f timeout
%s Lazy session activate success
%s Lazy Audio Session is not configured.
%s Creating fake session activation notification for session activation failure : %{public}@
%s Activating audio session now
%s AudioSession activated successfully ? %{public}@
%s AudioSession Provider not available
%s Falling back to button record type for context whose record type previously is set to unspecified for accessory %{private}@.
%s recordContext : %{public}@
%s Will skip setting current record context because we were in active call and context was post or auto
%s Resetting CoreSpeech frameworks
%s Ask start recording with requestMHUUID: %@
%s Disable audio converter since local asr is going to be used
%s Enable audio converter
%s Disable prewarming local asr at startRecording
%s TriggerlessDictation: Ask start recording from: %{public}tu
%s Ask start recording from: %{public}tu
%s Voice trigger to use the current voice triggered channel: %{public}tu
%s Auto prompt to use the last voice triggered channel: %{public}tu
%s SpeechController to receive data from default channel
%s SpeechController to receive data from channel %{public}tu
%s Trying to prepare uncompressed audio logging
%s Local ASR is used, uncompressed audio logging is disabled
%s Ask delay audio session active by %{public}f seconds
%s Postpone calling audio session activation til we receive didStart
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@, audioDeviceInfo = %{public}@
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@
%s Report unexpectedly long launch latency %{publlic}.3f
%s audioStream not existing
%s _activateAudoiSessionWithDelay has failed. startRecordWithSettings has failed
%s Start recording invoked too late (%{public}.3f seconds), override scheduledCheckTime: %{public}llu to currentTime: %{public}llu
%s Scheduled audible feedback decision after %{public}.3fseconds (vtEndMachTime: %{public}llu currentMachTime: %{public}llu)
%s Two shot audible feedback decision not needed since we already stopped recording
%s Two shot audible feedback decision (%{public}.3fs later than the scheduled time), elapsedTimeWithNoSpeech: %{public}.3f
%s Two shot audible feedback is %{public}@needed. (isMediaPlaying = %{public}d, canPlayPhaticDuringMediaPlayback = %{public}d)
%s Two shot audible feedback should notify? [%{public}@]
%s Two shot audible feedback is prevented by Myriad decision.
%s Two shot audible feedback decision timed out while waiting for Myriad decision
%s Audible feedback not needed since we already stopped recording
%s Audible feedback decision elapsedTimeWithNoSpeech: %{public}.3f
%s Notifying scheduled audible feedback playback...
%s Failed to playback audible feedback, error: %{public}@
%s Asking stopRecording when audio stream is not existing
%s Options: %{public}@ at: %{public}llu
%s Reporting didDeliverLastPacket at: %{public}llu
%s SpeechEndEstimation: %{public}llu
%s Scheduling StopRecording After HostTime=%{public}llu
%s Reason : %{public}ld
%s SpeechEndEstimation: Should Estimate SpeechEndHostTime
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu, audioDeviceInfo: %{public}@
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu
%s Currently playing App : %d
%s name : %@, version : %@
%s _didDeliverLastPacket=%d. Dropping Audio packets of size=%lu
%s chunk.hostTime=%{public}llu, chunkSz=%{public}lu, stopOptions=%{public}@, _numTrailingSamplesAfterSchedulingStop=%{public}lu, maxAllowedSamples=%{public}lu
%s STOPRECORDING: Reached MAX allowed trailing samples AFTER stopRecording was scheduled!
%s STOPRECORDING: chunk.hostTime=%{public}llu >= stopOptions=%{public}@
%s SpeechManager still forwarding audio after didStopForwarding, we shouldn't have this
%s STOPRECORDING: chunk.endHostTime=%{public}llu >= stopOptions=%{public}@
%s AudioProvider is invalidated, teardown connection to audioprovider
%s Ignore session active notification
%s SmartSiriVolume update reason: %lu
%s SpeechController is trying to forward encoded audio after didStopForwarding, we shouldn't have this
%s Setting Alert Sounds From : %{public}@ for AlertType : %{public}d, force : %{public}@
%s Creating Audio Power Meter with record route %{public}@
%s We don't need Audio Power Meter with record route %{public}@
%s Not available
%s Reported 2-shot at: %{public}f secs
%s _delegate doesnt respond to speechControllerDidDetectVoiceTriggerTwoShot
%s Requesting QuickStop operation upon detecting keyword
%s _endpointId: %@, _rcHandlingClient: %@, languageCode: %@
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Creating xpcClient
%s Unable to setup audioProvider
%s Establishing xpcClient connection...
%s Unable to prepareAudioProvider in _xpcClient, teardown XPC connection again
%s endpointerModelVersion called when HEP is not supported
%s return hybrid model version for sirix request
%s Queried endpointerModelVersion: %{public}@
%s Cancelling current language detector request !
%s Received Myriad started
%s Received Myriad finished with decision: %tu
%s Detected sound is%{public}@ playing: media(%d) alarm(%d) timer(%d)
%s XPCConnection disconnected
%s reset audioProvider since xpcClient disconnected
%s Playback is active: %{public}d on accessory: %{private}@
%s Alarm is playing: %{public}d on accessory: %{private}@
%s Timer is playing: %{public}d on accessory: %{private}@
%s Now Playing State has changed %d
%s Alarm firing
%s Alarm dismissed
%s Timer firing
%s Timer dismissed
%s SSR Remote Object Proxy is nil
%s Successfully created SSR connection
%s ERR: SSR Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SSR ssrConnection is nil
%s scoreCard is nil!
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%s request = %@, options = %@
%s error = %@
%s prepared
%s Player item %@ status is failed with error %@.
%s Created player item %@ from URL %@.
%s Created player item %@ from WAVE asset with %tu bytes of data .
%s Unable to create player item.
%s Created player %@.
%s Unable to replace current item of player %@. Expected current item is %@, actual current item is %@.
%s Player item %@ status is ready to play.
%s Timed out when waiting for player item %@ status to change to ready to play.
%s Successfully changed player item %@ status to ready to play.
%s Failed to change player item %@ status to ready to play due to error %@.
%s Attempted to start %@ when it is already active.
%s Failed to prepare %@ due to error %@.
%s Failed to start %@ because it is already inactive after preparation.
%s Failed to start %@ because it is already inactive after player seek to begin.
%s Failed to start %@ because player failed to seek to begin.
%s started
%s Reset player item %@.
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s CSVoiceTriggerAsset found: %{public}@
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s Start Recording Host Time = %{public}llu
%s %p created
%s %p dealloced
%s sp=%p
%s %@ not supported yet.
%s Failed to create: %@
%s SigPrvdrs: %@
%s Starting datasrc: %@
%s Failed to start %@. Err=%@
%s >>> All DataSources Started within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources Start timedout. timeout=2secs
%s Starting signal provider: %@
%s Failed to start %@: Err=%@
%s >>> All SignalProviders didStart within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStart. timeout=2secs
%s >>> All DataSources Stopped within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources timedout stopping. timeout=2secs
%s Failed to stop %@: Err=%@
%s >>> All SignalProviders didStop within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStop. timeout=2secs
%s WARN: Cannot find SignalProvider for %@. Skipping
%s Initializing new xpcConnection
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s xpcConnection not exist
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending AcousticSLResult request
%s Failed to get AcousticSLResult reply
%s Received AcousticSLResult %{public}@
%s Failed to parse AcousticSLResult from raw data
%s Message not valid
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s Not implemented
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s xpcConnection not existing
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s ::: incrementing false wakeup to %{public}llu
%s PowerLog : HeySiriFalseTrigger numFalseWakeUp:%{public}d, secondsSinceLastReport:%{public}lf, phrase:%{public}@
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report with current phrases %{public}@
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Automatic Volume State changed to %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Closing file at URL %{public}@, audio size: %{public}u
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s Received notification %@
%s Failed to register for notification %@ (status=%d)
%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f
%s TTS volume offset post lower and upper bounds is: %{public}f
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: assetType: %{public}lu
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Overriding Myriad state as request was made during a ringtone
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Cannot notify wake keyword spoken event : %{public}@
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm success
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm failed : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s Invoked Siri client for voice trigger from Darwin
%s Cannot invoke Siri client for voice trigger from Darwin : %{public}@
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s ::: Error creating output file %{public}@, err: %{public}d
%s ::: Error writing to output wave file. : %{public}ld
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since there is other app recording that is not eligible and we are not in a connected or outgoing call
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s Successfully ? %{public}@
%s Notify release of audio session
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s CSSpeechUaapXPCClient received an empty connection event
%s CSSpeechUaapXPCClient got an event it can't handle
%s CSSpeechUaapXPCClient listener disconnected
%s CSSpeechUaapXPCConnection error: %s
%s Invalidating CSSpeechUaapXPCClient
%s CSVoiceTriggerAsset (%{public}@) found: %{public}@
%s Cannot get a VoiceTrigger mobile asset : %{public}@
%s Trial assets not available, fallback to MA assets
%s First unlock notification received : %{public}d
%s Ignore Trial asset update for type: %lu
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VAD is not present or Hearst routed without phone call
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s CarPlay is connected, we will still run AOP mode
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since siri is in attending state
%s Turn on AP mode since device has ringtone through hfp, connected, or outgoing call.
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s %p speechRecordingMode = %zd, clientConfiguration = %@
%s %p speechRequestOptions = %@, currentActivationInfo = %@
%s activeMediaPlaybackVolume = %f
%s clientConfiguration = %@
%s announcement platform is hearing aids or built in speaker, using CSAudioRecordTypeHomePress
%s recordRoute = %@, playbackRoute = %@
%s Requesting historical buffer of duration %lf seconds
%s recordRoute = %@, playbackRoute = %@, attemptsToUsePastDataBufferFrames = %d
%s alertBehavior = %@
%s AppleTV (isVoiceOverTouchEnabledInAccessibility = %d)
%s HomePod
%s BT Voice trigger during incoming/active phone call
%s Built-in Voice
%s Dictation (deviceRingerSwitchState = %@)
%s Triggerless
%s CarPlay Button Press (recordRoute = %@)
%s Bluetooth Voice Trigger
%s Bluetooth Direct Trigger
%s Car DoNotDisturb
%s VoiceOver Enabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Accessibility Vibration Disabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Overriding default behavior, playing beep because of custom sound ID
%s Playback Route is Hands-Free (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s No Vibration Support
%s Others (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Others (deviceRingerSwitchState = %ld (%@))
%s alertStyle = %ld
%s targetDate = %@ (%f)
%s timeInterval = %f
%s voiceTriggerEndHostTime = %llu
%s buttonDownHostTime = %llu
%s activationHostTime = %llu
%s activationSystemUptime = %f
%s date = %@ (%f)
%s Overriding default behavior to play beep because of custom sound ID
%s Voice Feedback -> PresentationModeVoice
%s Voice Feedback -> PresentationModeSilent
%s Voice Feedback -> None
%s Voice Feedback -> Control with Ring Switch (deviceRingerSwitchState = %ld (%@))
%s Voice Feedback -> Always On
%s Voice Feedback -> Hands-Free Only
%s Voice Feedback -> Unknown
%s audioSessionActiveDelay = %@ (Triggerless Listening)
%s audioSessionActiveDelay = %@ (Audio Session Coordination)
%s audioSessionActiveDelay = %@ (User Perception)
%s audioSessionActiveDelay = %@ (Hearst Voice)
%s audioSessionActiveDelay = %@ (Built In Voice)
%s audioSessionActiveDelay = %@ (Others)
%s audioSessionActiveDelay = %@
%s mediaPlaybackVolumeThreshold = %@
%s audioSessionActiveDelay = %@ (Above Media Playback Volume Threshold)
%s audioSessionActiveDelay = %@ (Default)
%s %{private}@
%s WARN: Invalid sigType: %lu
%s Unknown DataSrc Type: %{public}lu
%s Unknown DataSrcTypeStr(%{public}@)
%s Failed to create dir at: %{public}@
%s Could not find <%{public}@> in Keypath=%{public}@
%s Creating audio player...
%s Failed to create audio player due to error %@.
%s Created audio player %@ with audio session %@.
%s Reused audio player %@ with audio session %@.
%s Audio player %@ is already prepared to play.
%s Preparing audio player %@ to play...
%s Failed to prepare audio player %@ to play.
%s Prepared audio player %@ to play.
%s request = %@
%s Ignored because the session is already active.
%s Ignored because the audio player is already playing.
%s Asking audio player %@ to play...
%s Failed to play audio player %@.
%s Started playing audio player %@.
%s request = %@, immediately = %d
%s Stopping audio player...
%s Ignored because there's no audio player to stop.
%s _request = %@
%s Ignored because there's no audio player to pause.
%s _request = %@, shouldResume = %d
%s Ignored because there's no audio player to resume playing.
%s request = %@, error = %@
%s Ignored because there's no audio player to destroy.
%s request = %@, player = %@, success = %d
%s request = %@, player = %@, error = %@
%s ContinousAudioFingerprint cannot be turned on since Siri is disabled
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s Received RC with id: %lu, duration: %f, lrnnScore: %f, lrnnThreshold: %f, taskId: %@, forceAccept: %d
%s Getting mitigation decision for rdId: %lu
%s ERR: RC Processing Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: RCProcessing rcProcConnection is nil
%s ERR: Failed to get TTS Volume
%s Estimated TTS volume : %{public}f
%s SmartSiriVolume not available
%s Notifying SSV Client on Volume change for reason - %{public}d
%s Dropped SSV Client notification for Volume change with reason - %{public}d
%s EarlyDetectSample = %{public}d
%s PHS threshold for %lu doesn't exist, use default
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
%s primaryStream already torn down
%s Updating attSiri state to: %lu
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s Triggering acoustic data sync with peer - %@
%s Triggering gecko sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Unable to get %@ for file at %@: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Grading log file successfully transfered for file %@ in task %@
%s Grading log file failed to transfer for file %@ in task %@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s Error setting remoteP2Plog file to NSFileProtectionCompleteUntilFirstUserAuthentication. file=%@ Err=%@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s Skipping post build activity on ATV
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Already started listen polling, skip
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s Siri enabled : %{public}d
%s stream stopped unexpectedly : %{public}ld
%s Mediaserverd/bridgeaudiod recovered from crash
%s Failed to fetch speaker state muted info, error : %{public}@
%s Queried built-in speaker mute state as %{public}@
%s Timed-out for fetching speaker state muted info, setting isMuted = YES
%s Failed to fetch builtIn speaker active state, error : %{public}@
%s Queried built-in speaker state as %{public}@active
%s Timed-out for fetching speaker state active info, setting speakerStateActive = NO
%s Speaker state changed : %{public}@
%s Failed to get speaker state from AVVC, default to inactive
%s Speaker mute state changed: %{public}@
%s Failed to enable speakerStateListening: %{public}@
%s Start monitoring : Speaker state from AVVC
%s Failed to disable speakerStateListening: %{public}@
%s Stop monitoring : Speaker state from AVVC
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Start monitoring : SACInfo
%s Stop monitoring : SACInfo
%s Device is in stereo mode : %{public}@
%s vibration state fetched from CFPreferences is NULL, using On as default value
%s ::: NVI logging initialized
%s Received external route change notification
%s Received external pickable route change notification
%s Received CarPlay AuxStream support change notification
%s Received CarPlay connection change notification
%s Notifying Hearst Connection State : %{public}d
%s Notifying Jarvis Connection State : %{public}d
%s Automatic Volume Toggled. Automatic Volume Enabled: %{public}d
%s No SACodec for settings %{public}@
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s endpointerModelVersion is still nil after fetching it from EAREndpointer
%s Updated endpointer threshold: %{public}f
%s Updated endpointer delayed trigger: %{public}d
%s setEndpointerOperationMode : %{public}d
%s current EndpointerOperationMode : %{public}d
%s %{public}@
%s update endpointer threshold to %{public}f for task %{public}@
%s EARSPG: CSServerEndpointFeatures: %{public}@
%s isASRFeatureFromServer = %{public}d
%s Accepting RC: RCTime < 0: Server's processedAudioDuration(%{public}f) > _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s Rejecting RC: SFLatency < 0: Server's processedAudioDuration(%{public}f): _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s rcEpFeatures: %{public}@ shouldAccept: %{public}d
%s first audio buffer host time: %{public}llu
%s Detected speech start at %{public}f of effectiveClientProcessedAudioMs
%s Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%{public}f
%s ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
%s ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
%s ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
%s ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
%s ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
%s HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f] @ %{public}lu [%{public}f, %{public}d]
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, anchorhostTime=%{public}llu, endpointSampleCount=%{public}llu, numSamplesProcessedBeforeAnchorTime=%{public}lu, isAnchorTimeBuffered=%{public}d
%s request timeout with features %{public}@
%s ServerFeaturesLatencyDistribution: %{public}@ additionalMetrics: %{public}@
%s MMEP:: HEP detected at %{public}f but will continue running for MMEP.
%s Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%{public}f
%s Log hybrid endpointer features for event: %{public}@, and locale: %{public}@
%s triggerEndSeconds: %{public}f, _vtEndInSampleCount: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu,  _hepAudioOriginInMs: %{public}f, voiceTriggerInfo: %{public}@,
%s CSHybridEndpointer recordingStoppedForReason: %{public}ld
%s sampleRate=%{public}lu, recordContext=%{public}@
%s CSEndpointAsset exists: %{public}@
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to NNVAD
%s Created HybridClassifier(%{public}@); canProcessCurrentRequest after reset: %{public}d,for sampleRate: %{public}lu, lang=%{public}@, version=%{public}@
%s HEP.logs.hdr: [ServerASR_trailingSilenceDuration,ClientSPG_SilenceFramesCountMs,ServerASR_endOfSentenceLikelihood,ServerASR_wordCount,ServerFeaturesLatency,ClientSPG_SilenceProbabilityHMMFiltered] & [ServerASR_pauseCounts,ServerASR_silencePosterior,ClientSPG_silenceProbailitySPGRaw] @ effectiveClientProcessedAudioMs : [HEPPosteriorOut,HEPDecision]
%s csHepConfig: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d, _extraDelayFrequency: %{public}lu, _taskThresholdMap: %{public}@
%s update assets to: %@
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Start audio stream successfully ? %{public}@, error : %{public}@, startRecordingSampleCount=%lu
%s Stopped audioStream with result=%d, err=%@
%s audioProvider == nil, error : %{public}@
%s provider: %{public}@, unexpectedStop: %{public}ld
%s Device is firstUnlocked. Fetching HEP assets
%s Device is NOT firstUnlocked. Will fetch assets after firstUnlock
%s Language changed to: %{public}@
%s New hybrid endpoint asset downloaded
%s FirstUnlock notification received: %{public}d
%s Bypass Trial Asset
%s Failed to get HEP asset
%s HEP Asset: %{public}@, path: %{public}@
%s installationString: %@, for language: %@
%s File not exist: %{public}@
%s endpointAsset: %{public}@, osdAsset: %{public}@
%s elapsed time to get HEP mobile assets: %{public}lf
%s Fake endpoint asset: %@
%s _requestMHUUID: %@, _turnIdentifier: %@
%s _userSpeakingStartedTimeInMs %{public}f, _userSpeakingEndedTimeInMs: %{public}f, _userSpeakingStartedHostTime: %{public}llu, _userSpeakingEndedHostTime: %{public}llu, _stopRecordingHostTime: %{public}llu, _endpointBufferHostTime: %{public}llu
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s Error reading audio file: %{public}d, skipping...
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s token:%d
%s fromState:%llu, toState:%llu
%s SiriState - isActiveSession:%d
%s SiriState - isActiveRequest:%d
%s SiriState - isListening:%d
%s SiriState - isSpeaking:%d
%s tts Finished:%u
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Replace deviceId(%{public}@) to nil for VoiceTrigger from Gibraltar.
%s Hang up toggle: %d
%s VoiceTrigger cannot be turned on since we are not in the desired call state
%s VoiceTrigger cannot be turned on since we are in a hang up supported call state but it is not first party.
%s VoiceTrigger cannot be turned on because we are in a ringtone and hsPhoneCallCapableHeadsetConnected: %d builtInState: %d isInSplitterMode: %d
%s Queue %@ is already being observed.
%s queue = %@
%s queue = %@, numberOfOccurrences = %tu
%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu
%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldestSampleInBuffer: %{public}lu, latestSampleInBuffer=%{public}lu
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s Delivering didStop to %{public}lu tandem stream(s)
%s AudioStream<%{public}@> is streaming : %{public}d
%s Stream %{public}@ set startTimeInSampleCount : %{public}llu
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Input route changed
%s Output route changed
%s Failed getting audio property %{public}.4s %{public}d
%s Failed getting audio property size %{public}.4s %d{public}
%s Failed registering for property listener %{public}.4s %{public}d
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s Received a request for VoiceTrigger Asset for language code : %{public}@
%s Fake Model Path does not exist : %{public}@
%s fake model meta json does not exist : %{public}@
%s Unable to read fake model meta json : %{public}@
%s Unable to parse fake model meta json : %{public}@
%s Loading FakeModel : %{public}@
%s Cannot create RTModel from %{public}@
%s fake model number(%{public}d) is less than minimum fake model number((%{public}d)
%s Using fake model for the first time : %{public}@
%s Using fake model : %{public}@
%s %{public}@ fake model is selected for download
%s %{public}@ model is selected for fallback
%s Received a request for VoiceTriggerRTModel %{public}@ Firmware Version : %{public}d.%{public}d
%s Asking mobile asset with currentLanguageCode = %{public}@
%s DownloadModel : 
%s preinstalledModels : 
%s Hearst Fake Model request switch turned on, executing stress test mode with fakeModelPath : %{public}@
%s VoiceTriggerAsset is not available : %{public}@
%s Queried model for language:%@ path:%@ configVers:%@ model:%@
%s rtLocaleMap is nil fallback to embedded locale map
%s accessoryRTBlobs are not available for the version(%{public}d.%{public}d) and locale:%{public}@, returning fallback model : %{public}@
%s Hash matched with downloadedModel : %{public}@, accessory will select this model
%s Hash matched with preinstalledModel : %{public}@, accessory will select this model
%s Ask for download : %{public}@, and use %{public}@ as fallback
%s Select keyword language as %{public}@, error : %{public}@
%s Language list and jarvis language not provided
%s current Siri language code : %{public}@
%s Jarvis locale map is nil, fallback to embedded locale map
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Initializing CSRawAudioInjectionProvider
%s Done initializing CSRawAudioInjectionProvider
%s Dealloc CSRawAudioInjectionProvider
%s Calling StreamId for : %@
%s Calling prepare
%s Calling start audio stream : %@
%s Calling stop audio stream
%s Calling isRecording
%s Calling prewarm
%s Calling activate audio session
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s Reset recordDeviceIndicator as we have new audioRecorder
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s Attached stream %{public}@ as tandem to master stream %{public}@ %{public}@, error : %{public}@
%s PrimaryStream is already tandem of stream %{public}@, can't add mutual tandem relation here!
%s Invalid input streams
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Create circular buffer : numChannels(%d), duration(%f)
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@, request : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s Start deliver historical audio buffer immediately
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s Calling unexpected didStop for all weak streams
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:shouldDuckOnBuiltInSpeaker: %{public}@ (audioStreamType: %{public}lu, isPlaybackRouteBuiltInSpeaker: %{public}@, isDuckingOnSpeakerOutputSupported: %{public}@)
%s Failed to fetch duckingSupported result : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s Unable to disable duckOthers in HomePod
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Not handled by this function
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s Forward %d samples from historical audio buffer
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Audio Packet Delivery WatchDog fired, trying to recover
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s Update remote deviceUId fetched from AVVC : %{public}@ (this must be deviceUID of Darwin device only)
%s Failed to fetch remote deviceUId from AVVC
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Hey Siri is enabled. Checking if we are in a call.
%s Hey Siri is disabled. Not checking if we are in a call.
%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone hfp state
%s Listening on watch cannot be turned on since audioInjection is enabled
%s Listening on watch cant be turned on because we are in a ringtone with A2DP, connected or outgoing call
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Failed to fetch listeningEnabled : %{public}@
%s listening property in AOP : %{public}d
%s Failed to fetch listeningEnabledOnNotification : %{public}@
%s Stop monitoring : AOP Listening state
%s Received AOP Listening state change notification : %{public}d
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Send a In-Ear Myriad notification
%s Unsupported protocol for this device
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
%s addAudio first sample offset: %{public}lu
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, isAnchorTimeBuffered=%{public}d
%s CSHybridEndpointAnalyzer recordingStoppedForReason: %{public}ld
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to VAD2
%s Created OSDAnalyzer: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d
%s _currentAsset changed to : %{public}@
%s Session Query Failed : %{public}@
%s Mediaserverd/bridgeaudiod crashed
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Endpointer is disabled in recordOption: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
%s EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s Skip update endpointer threshold from server for accessible endpointer request
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s %@
%s Detaching from session %p
%s Already attaching to session!
%s Attaching to session
%s Failed attaching to bt session %d
%s session = %p, result = %d
%s Session is NULL.
%s Failed getting default local device from session %p (result = %d).
%s Failed adding callbacks to local device %p from session %p (result = %d).
%s localDevice = %p, event = %d, result = %d
%s Failed getting default accessory manager from session %p (result = %d).
%s Failed adding callbacks to accessory manager %p from session %p (result = %d).
%s accessoryManager = %p, accessoryEvent = %d, device = %p, state = %d
%s Failed getting device address from string %d
%s Failed getting device from address %d
%s BTDevice %p for address %@
%s BTAccessoryManager %p
%s Failed getting device from deviceUID %d
%s BTDevice %p for deviceUID %@
%s BTLocalDevice %p
%s Loading device info for %@...
%s Loaded device info %@ for %@.
%s Using slow path...
%s Slow path took %f seconds.
%s Slow path timed out after 4 seconds.
%s Method not supported
%s Reloading device info for %@...
%s Reloaded device info %@ for %@.
%s deviceInfo = %@
%s deviceInfo changed from %@ to %@
%s Fetching device info for %@...
%s Fetched device info %@ for %@.
%s Getting BTDevice and BTAccessoryManager for %@...
%s Got BTDevice %p and BTAccessoryManager %p for %@.
%s Device UID and address of %@ are nil.
%s Data source of %@ is nil.
%s Failed getting BTDevice and BTAccessoryManager for %@.
%s Failed getting address from BTDevice %p (result = %d).
%s Failed getting vendor id and product id from BTDevice %p (result = %d).
%s Failed getting InEar capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting DoAP capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting ANC capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Transparency capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Software Volume capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Messages capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Calls capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Stop monitoring : First unlock
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s Created VoiceIdXpc connection
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Null msg body
%s Null VTEI
%s Null Ctx
%s Null deviceInfo
%s Null audio context
%s Received msg of type %{public}lld for utt %{public}@
%s Fetched latest VT asset %@ for retraining
%s Implicit utterence processing done with error %{public}@
%s Cannot retrain since we cannot look-up SSR asset with error %@
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Failed to initialize caesuraSPG, stopping monitoring
%s Start monitoring : EARCaesuraSilencePosteriorGenerator: %{public}@
%s deallocating EARCaesuraSilencePosteriorGenerator: %{public}@
%s Stopped monitoring : EARCaesuraSilencePosteriorGenerator
%s EARClientSilenceFeatures heartbeat = %{public}lld,                   silScoreEstimate = %{public}f
%s Stop monitoring : HomePod voiceTriggerAssertion
%s Setting sample rate to %d
%s Could not make Fingerprinter decoder: %{public}.4s
%s Error during conversion for fingerprinter %{public}.4s
%s Getting signature for duration %lf
%s Fingerprinter doesn't support rate %{public}ld
%s Set initial info as current %@.
%s Assign new MHUUID here to %@ (force = %@)
%s mode = %ld
%s endpointerOperationMode = %@, forceUpdate = %d
%s Ignored because endpointer operation mode is unspecified.
%s Ignored because endpointer operation mode can not be changed from %@ to %@.
%s Set Use Automatic Endpointing %d
%s Setting up recording alerts for Dictation.
%s Done setting recording alerts for Dictation.
%s Setting up recording alerts for Siri and other non-Dictation modes.
%s Done setting recording alerts for Siri and other non-Dictation modes.
%s Overriding record starting alert for IFD feature group one.
%s Done overriding record starting alert for IFD feature group one (soundURL = %@).
%s Failed overriding record starting alert for IFD feature group one.
%s Done overriding record starting alert from override policy (soundURL = %@).
%s Failed overriding record starting alert from override policy.
%s Trying to set record buffer duration to %lf
%s Failed setting record buffer duration. Duration is %{public}lf
%s Initalizing speech controller with context %@
%s Set pending info as current %@.
%s Done initializing voice controller
%s Preparing CSSpeechController with settings %@
%s Error setting up CSSpeechController %{public}@
%s Done preparing CSSpeechController
%s reason = %d, speechEvent = %zd (%@), hostTime = %llu
%s reason = %d, hostTime = %llu
StopRecording
%s Really stopping recording
UsefulUserFacingResults
%s Someone else has already asked to stop recording.%@
%s Sending stop recording immediately because CSSpeechController isn't recording
%s recordingState = %zd, context = %@
%s Playing alert %ld
%s Checked audio logging limits, count = %d -> %d
%s An item already exists at path %@, but it is not a directory.
%s Failed to create directory at path %@ due to error %@.
%s info = %@, context = %@
%s Created _audioFileWriter %@.
%s Did not create _audioFileWriter because audioFileType = %ld.
%s supportsVoiceIdentificationTraining = %d
%s supportsSpeechExtraction = %d
%s supportsSpeechLogging = %d
%s Configure _audioFileWriter with recordSettings = %@.
%s Ask context %@ to configure and record with recordSettings = %@.
%s Acquired recorded audio for speech logging: %@
%s Speech Log: %@
%s Unable to save recorded audio for speech logging due to error %@.
%s Skipped saving recorded audio for speech logging due to audio logging limit.
%s Unable to prepare directory for speech logging.
%s Unable to acquire recorded audio for speech logging.
%s %ld
%s Ignoring unexpected stop recording while in state %ld
%s Prewarming audio session in speech controller
%s Done prewarm audio session in speech controller
%s Prewarming start alert
%s Failed to prewarm start alert due to %@
%s Done prewarming start alert
%s Preparing instead of preheating since we're not in the default mode
%s Preparing speech capture for %@
%s context:%@, _currentActivationInfo :%@
%s Using Bluetooth audio analyzer style
%s Using driving audio analyzer style
%s Using voice trigger audio analyzer style
%s Using default audio analyzer style
%s Suppressing start alert
%s Playing start alert %@
%s No SoundID URL
%s No start recording alert
%s entering _recordingWillStartGroup
%s Setting delayed start delay %lf
%s Asking CSSpeechController to startRecording with settings %@
StartRecording
%s Done asking CSSpeechController to startRecording
%s context = %@
%s leaving _recordingWillStartGroup
%s Could not set up recording (prepared = %d, started = %d), returning error %{public}@%{public}@ and resetting voice controller.
%s Updated speech synthesis record from %@ to %@.
%s Fetching audio session ID...
%s Done fetching audio session ID %lu.
%s endpointerOperationMode = %@
%s Fingerprinting mode, force (endpointerOperationMode = %@).
%s Legacy property set (useAutomaticEndpointing = %d), override (endpointerOperationMode = %@)
%s info = %@, reason = %@
%s Dropping previous pending activation info %@ for reason %@.
%s Setting audio context %@ for reason %@.
%s Error setting audio context %@ for reason %@ error %{public}@. (%f seconds)
%s Done setting audio context %@ for reason %@. (%f seconds)
%s Ignored setting audio context because there's no speech controller.
%s Updating to post voice for reason %@.
%s Updating using pending info %@ for reason %@.
%s Attempting to release audio session while CSSpeechController is still recording.
%s releaseAudioSessionBehavior = %s
%s Resetting to default audio context on session end
%s %lf %lf
%s Endpointer setStartWaitTime is set to %{public}f
%s (event = %ld, suppressAlert = %d, hostTime = %llu)
%s (suppressAlert = %d)
%s Begin updating audio device info %@. (reason = %@, forcesUpdate = %d)
%s Fetching audio device info from CSSpeechController...
%s Done fetching audio device info from CSSpeechController.
%s End updating audio device info %@. (duration = %f)
%s Creating recording info (speechEvent = %ld (%@), audioAlertStyle = %ld, includeBTInfo = %d, includeRecordDeviceInfo = %d)
%s alertStartTime = %llu
%s Done creating recording info %@.
%s Got a speech start failure after we already got audio buffers?!
AudioStart
%s success = %d, error = %@
%s isTwoShot = %d
%s SPELLING recordSettings codec=%@
%s Sending speech did start to delegate %@
%s Resetting VoiceController on startRecording failure
%s reason = %ld, estimatedSpeechEndHostTime = %llu
%s Synthesizing a didStart callback, on missing didStart
AudioStop
%s reason = %ld, estimatedSpeechEndHostTime = %llu, errorCodeOverride = %ld, underlyingError = %@
%s Ignoring unexpected didStop callback while in state %ld
%s Starting new recording for two shot mode
%s Failed starting recording for two shot mode
%s audioMetrics = %@
RecordBufferAvailable
%s buffers.count = %llu, durationInSec = %f, bufferStartHostTime = %llu
RecordBufferHandleBegin
%s Dropped %f seconds of audio buffers recorded at %llu (%f seconds) due to audio recording restriction (accumulatedBufferDuration = %f seconds).
RecordBufferHandleEnd
%s firstBufferStartHostTime = %llu, firstBufferReceiptHostTime = %llu
%s Getting audio route instrumentation with recording info %@...
%s Done getting audio route instrumentation %@.
%s LPCM record buffer is empty.
%s reason = %zd, estimatedSpeechEndHostTime = %llu, isRecordingStopped = %d
%s Ignoring unexpected last buffer callback while in state %ld
%s Ignoring unexpected last buffer callback without first buffer.
%s %d
%s type = %ld, error = %@
%s type = %ld
%s alertPlaybackGroup is nil.
%s numberOfAVVCAlertPlaybacksByType does not have AVVC alert playbacks of type %ld.
%s numberOfAVVCAlertPlaybacksByType is nil.
%s Language detection delegate is active
%s Language detection delegate is NOT active. %d, %@
%s isSiriMode=%d, speechEvent=%ld, wasRequestCancelled=%d, shouldSuppressAlert=%d, isMonitoringMyriadEvents=%d, didMyriadWin=%d, recordRoute=%@
%s Explicitly playing %@ alert
%s BTLE Myriad Not explicitly playing speech stop alert
%s Not explicitly playing alert
%s Language detector is confident:%{private}d of the detected language:'%{private}@' with language code likelihood: %{private}@
%s time = %lf, wantsAudibleFeedback = %d
%s BTLE waiting for Myriad to finish
%s BTLE Myriad loss cancelled two shot feedback
%s BTLE speech controller began waiting for Myriad decision
%s BTLE speech controller end waiting for Myriad decision %lu
%s opType = %tu, reason = %tu
%s Unknown CSRequestOperationType (opType = %tu).
%s reason = %tu
%s time = %lf
%s Ignoring startpoint from stale CSEndpointAnalyzer
Endpoint
%s exited _recordingWillStartGroup
%s Ignoring hard endpoint from stale CSEndpointAnalyzer
%s Ignoring hard endpoint because (endpointTime = %f, firstBufferTimestamp = %f, mostRecentTTSEndTimestamp = %f, extendedSuppressDuration = %f).
%s Detected hard end-point with metrics - %@
EndpointHandled
SpeechRecorder
%s Overriding timeout and start point on timeout
%s Ignoring hard endpoint since _endpointerOperationMode = %@, _didEnterTwoShotMode = %d
%s promptType = %ld, time = %f
%s suppressesTwoShotAlert = %d
%s done
%s Fake two shot TTS prompt timed out (%@).
%s Fake two shot TTS prompt timeout is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s Fake two shot TTS prompt called back (timestamp = %f, duration = %f, error = %@)
%s Fake two shot TTS prompt callback is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s duration = %lf
%s No endpoint yet, waiting
%s rcID: %lu, duration: %lf, lrnnScore: %f, lrnnThreshold: %f, taskId: %@
%s Eager results - shouldAccept: %d, isMitigated: %d Duration: %lf last duration: %lf
%s Enforce previous endpointHint
%s Got an enforce message without a current completion. Ignoring
%s Processing RC for mitigation, force accept
%s Got an enforce message without a current RC. Stop Recording
%s timeout = %f
%s Done
%s Watchdog timer timed out.
%s duration %lf
%s Starting audio playback request %@...
%s Failed audio playback request %@ due to error %@.
%s Stopped audio playback request %@.
%s scores = %{private}@
%s userInfo = %@
%s Reuse existing session %@ from reusable session pool.
%s Create new session %@.
%s session = %@
%s session = %@, error = %@
%s Add successfully finalized session %@ to reusable session pool.
%s Evict %tu sessions from reusable session pool because %@.
%s Reusable session pool is already empty.
%s Created CSStartOfSpeechDetector: %{public}@ 
%s Reset: Created EARCaesuraSilencePosteriorGenerator: %{public}@
%s Start of speech already reported, ignoring !
%s silProb= %{public}f, silnfcnt=%{public}f, clientProcessedAudioMs=%{public}f curSpeechFrmCnt=%{public}lu
%s Speech prob target reached at %{public}lu from %{public}lu, #samples=%lu, secs=%{public}f
%s Received mediaserverd or bridgeaudiod crashes event
%s Received mediaserverd or bridgeaudiod reset event
%s Start monitoring : Mediaserverd crash / recover event
%s disconnect VoiceTriggerXPCClient
%s ERR: failed to get response !
%s Failed setting activity state to continue
%s Failed setting activity state to done
%s Deferring activity:%@ deferred:%@
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s language code already up-to-date : %{public}@
%s Using override asset: %@
%s Updated cache with new Trial asset %@
%s Cache already contains Trial asset, ignore MA asset update
%s Updated cache with new MA asset %@
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s There is not audio buffer to convert. Skip this.
%s Got asked for %{public}u packets, have %{public}u
%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes
%s %{public}d bytesConsumed from opus coverter, remains %{public}d bytes
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s Providing voiceTriggerEventInfo with deviceId %{public}@
%s Providing built-in voiceTriggerEventInfo
%s Timed-out for fetching voiceTriggerInfo
%s TiggerInfoProviding is nil
%s RequiredSampleCount reached: currSampleCount=%{public}lu, endingSampleCount=%{public}lu
%s SmartSiriVolume cannot be resumed because Siri is not enabled
%s Setting audio injection enabled : %d
%s Fetched audio injection enabled : %d
%s CSAudioInjectionServices Interrupted
%s CSAudioInjectionServices Invalidated
%s Request to create audio injection device type : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Fetching primary device timed-out!!
%s Request to inject audio %@ to deviceUUID %@
%s Request to connect device with UUID %@
%s Connect device timed-out!!
%s Request to disconnect device with UUID %@
%s Disconnect device timed-out!!
%s Request to fetch primary device
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s Tear down _remoteRecordClient if needed
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Setting announced call flag to: %d with stream handle Id: %lu
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = %{public}lu
%s Calling AVVC setContextForStream : %{public}@
%s Tried to setCurrentContext with mode %ld. This method can only be used for auto and post
%s setCurrentContext elapsed time = %{public}lf
%s Remote device with device id: %{private}@ not found
%s Failed to prepare remote device : %{public}@
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Asking startRecording to remote device with context : %{public}@ (original context : %{public}@)
%s Failed to fetch valid context
%s Failed to startRecording : %{public}@
%s startRecordingWithOptions elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Failed to stopRecording to remoteRecordClient : %{public}@
%s stopRecording elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s fetch recordDeviceInfo elapsed time = %{public}lf
%s fetch EndpointDeviceType elapsed time = %{public}lf
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s (darwinOS) : isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu)
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Calling AVVC setDuckOthersForStream(%d) for DuckOthers/MixWithOthers
%s Failed to setDuckOthersForStream : %{public}@
%s setDuckOthersForStream elapsed time = %{public}lf
%s Calling audio session reset ducking settings
%s resetDuckSettings elapsed time = %{public}lf
%s Failed to setDuckToLevelDB : %{public}@
%s %{public}@ miniDucking now
%s enableMiniDucking elapsed time = %{public}lf
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Ducking %{public}@ supported on current route with streamId: %{public}ld
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packets count %{public}d
%s Peak : %f, Avg : %f
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Audio record route is %{private}@ for stream id %{private}lu
%s Calling AVVC playAlertSoundForType to play alert
%s Ignore playing endpoint beep(record stopped beep) since it already played beep in gibraltar
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s hasLocalPendingTwoShot = %{public}d, token : %{public}llu
%s Unsupported audio format!
%s Existing remoteRecordClient (deviceId = %@) doesn't match required one (deviceId = %@), create new remoteRecordClient
%s The input streamHandleId(%{public}lu) is not expected(%{public}lu)
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s endpointer running on corespeechd
%s endpointer running on assistantd
%s Abstract Impl. Returning nil
softlink:r:path:/System/Library/PrivateFrameworks/SystemStatus.framework/SystemStatus
softlink:r:path:/System/Library/Frameworks/CoreMotion.framework/CoreMotion
softlink:r:path:/System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
Statistics
CSGestureMonitor
CSBluetoothWirelessSplitterInfo
CSAudioInjectionBuiltInEngine
CSAudioInjectionEngineDelegate
NSObject
CSVoiceTriggerSecondChanceContext
NviDataLogger
NSStreamDelegate
CSMicUsageReporter
CSGestureMonitorPhone
CMWakeGestureDelegate
CSVoiceTriggerAssetHandler
CSAudioSessionController
CSAudioSessionInfoProvidingDelegate
CSXPCClientDelegate
CSCoreSpeechDaemonStateMonitorDelegate
CSSiriDebugConnection
AttSiri
CSCXPhoneCallStateMonitor
CSCommandControlListenerOption
CSMediaPlayingMonitor
CSAudioInjectionFileOption
CSMSNExceptionManager
CSVolumeMonitor
CSTimerMonitor
CSAlarmMonitor
CSAudioStreamHolding
CSUserIdentityClassifier
CSAssetManagerEnablePolicyFactory
CSAttSiriServiceProtocol
CSAttSiriServiceDelegate
CSAttSiriServiceClient
CSSiriFanInfoManager
CSSiriFanInfo
CSBiometricMatchMonitor
CSPreMyriadVoiceTriggerMetaData
CSPreMyriadCoordinator
CSVoiceTriggerDelegate
CSSecondPassProgressDelegate
CSAudioInjectionHearstEngine
AVVC
SmartSiriVolume
CSAudioDeviceInfo
NSCopying
NSSecureCoding
NSCoding
CSSpeakerRecognitionProxy
CSSSRXPCClientDelegate
CSVoiceTriggerXPCService
CSVoiceTriggerXPCClientDelegate
CSVoiceTriggerAssetDownloadMonitor
CSAsset
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSOtherAppRecordingStateMonitor
CSBenchmarkService
CSSmartSiriVolumeEnablePolicyFactory
CSAssetDownloadingOption
CSSmartSiriVolumeEnablePolicyHomePod
CSContinuousAudioFingerprintEnabledPolicyHomePod
CSBluetoothManager
CSHostLauncherDarwin
CSSiriAssertionMonitor
CSXPCConnectionDelegate
CSAccessorySiriClientBehaviorMonitor
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSPowerAssertionMac
CSAudioFileReader
CSAdBlockerAssetDownloadMonitor
CSAudioRouteChangeMonitorImplWatch
CSAudioSampleRateConverter
CSLanguageDetectorAssetMonitor
CSSiriSpeechRecordingContext
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSSmartSiriVolumeClient
isPluginContext
CSAudioInjectionProvider
XPCObject
CSOpportuneSpeakListener
CSAudioStreamProvidingDelegate
CSSPGEndpointAnalyzerDelegate
CSVoiceIdXPCClient
RMSSample
CSShadowMicScoreCreator
CSBluetoothWirelessSplitterMonitorImpIOS
CSContinuousAudioFingerprintEnabledPolicyFactory
AudioInjectionXPCProtocol
CSVoiceTriggerHeartBeatMetricsProvider
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSActivationXPCClient
CSLanguageDetector
_EARLanguageDetectorDelegate
CSStartOfSpeechDetectorDelegate
LanguageCode
CSBluetoothWirelessSplitterMonitorImplDarwin
CSStopRecordingOptions
CSMacWakeSleepMonitor
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSEndpointLoggingHelper
CSEndpointLatencyInfo
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSAVVCRecordingClientMonitor
CSAudioServerCrashMonitorDelegate
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
Indexing
CSSiriAudioFileWriter
CSCoreSpeechServices
CSHangUpEnabledMonitor
CSAudioStreamRequest
CSOpportuneSpeakListenerDeviceManager
CSAVVoiceTriggerClientManager
CSSpeechManager
CSVoiceTriggerAssetHandlerDelegate
CSActivationEventNotificationHandlerDelegate
CSAudioRecorderDelegate
CSAudioProviderDelegate
CSOpportuneSpeakEventMonitorDelegate
CSSpeechEndHostTimeEstimator
CSClamshellStateMonitor
CSCommandControlListener
FlexKwd
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSEndpointerXPCService
CSEndpointerXPCServiceDelegate
CSEndpointerXPCClient
NviDirectionalitySignalProvider
NviSignalProvider
CSConnectionListener
NSXPCListenerDelegate
CSConnectionServiceDelegate
CSAudioRecorderFactory
CSVoiceTriggerFirstPassMetrics
CSSpeechController
CSAudioConverterDelegate
CSSmartSiriVolumeControllerDelegate
CSAudioAlertProvidingDelegate
CSAudioSessionControllerDelegate
CSAudioDecoderDelegate
CSEndpointAnalyzerImplDelegate
SOMediaNowPlayingListening
SOClockAlarmListening
SOClockTimerListening
CSAudioSessionProvidingDelegate
CSSpeechManagerDelegate
CSContinuousVoiceTriggerDelegate
CSSSRXPCService
CSSSRXPCServiceDelegate
CSSSRXPCClient
CSAttSiriAttendingTriggerEventInfo
RTModel
CSSiriAudioPlaybackSessionImplAVPlayerBased
CSSiriAudioPlaybackSession
SpeechModelTrainingClient
CSVoiceTriggerAssetHandlerDarwin
CSRemoteAssetManagerDelegate
CSXPCClientFactory
SpeechModelTrainingProtocol
NviSignalProvidersController
CSVoiceTriggerFirstPassHearstAP
CSXPCClient
CSAudioSessionProviding
CSFallbackAudioSessionReleaseProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioSessionInfoProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSStateMachine
CSEventMonitor
CSVoiceTriggerStatAggregator
CSDigitalZeroReporting
CSSmartSiriVolumeManager
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSAutomaticVolumeEnabledMonitorDelegate
CSVoiceTriggerDataCollector
CSAudioFileLog
CSActivationEvent
CoreSpeechXPCFakeModelMonitor
CSScreenLockMonitor
CSSmartSiriVolumeUserIntent
CSAssetController
CSEventMonitorDelegate
Utils
CSAudioInjectionTvRemoteEngine
CSSiriLauncher
CSVTSecondPassLatencyMetrics
CSAudioRouteChangeMonitor
CSSmartSiriVolumeEnablePolicy
CSAudioInjectionRemoraEngine
CSAudioInjectionEngine
AudioHardware
CSVoiceTriggerAssetChangeMonitor
CSAttSiriRequestContext
NviAudioFileWriter
CSVoiceTriggerEnabledPolicyNonAOP
CSBluetoothWirelessSplitterMonitor
CSSiriClientBehaviorMonitor
CSSpeechEndpointAssetMetaUpdateMonitor
CSSmartSiriVolumeEstimate
CSSpeechUaapXPCClient
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSSiriClientBehaviorMonitorDelegate
CSOpportuneSpeakBehaviorMonitor
CSMyriadPHash
NviConstants
CSSiriAudioActivationInfo
NviUtils
Logging
CSHostPowerSourceMonitor
CSAudioStartStreamOption
CSAssetControllerFactory
CSSiriAudioPlaybackSessionImplAVAudioPlayerBased
AVAudioPlayerDelegate
CSSmartSiriVolumeRunPolicyHomePod
CSContinuousAudioFingerprintEnabledPolicy
CSVoiceTriggerXPCServiceProxy
CSAdBlockerAssetDecoderV2
CSRCHandlingXPCService
CSRCHandlingXPCClient
CSSmartSiriVolumeController
CSSmartSiriVolumeClientDelegate
CSPhraseNDEAPIScorer
CSKeywordAnalyzerNDEAPIScoreDelegate
SpeakerRecognition
CSAudioTandemStream
CSBluetoothDeviceInfo
CSAttSiriStateMonitor
CSSmartSiriVolumeRunPolicyFactory
CSP2PService
CSVoiceTriggerAwareZeroFilter
CSPhoneCallStateMonitor
CSAlwaysDisabledPolicy
CSPostBuildInstallService
CSContinuousAudioFingerprintProvider
CSBuiltinSpeakerStateMonitor
NviDirectionalitySignalData
CSEndpointerMetrics
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSmartSiriVolumeProcessor
CSVoiceTriggerAssetHandlerFromFile
CSSACInfoMonitor
CSVoiceTriggerRTModel
CSSiriVibrationManager
CSAudioRouteChangeMonitorImpl
CSAutomaticVolumeEnabledMonitor
CSSiriRecordingInfo
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSVoiceProfileRetrainManager
CSVoiceTriggerEnabledMonitor
CSVoiceTriggerSecondPassRequestOption
CSHybridEndpointer
CSEndpointerAssetManagerDelegate
!2!B
CSRemoteRecordClient
CSSiriEnabledMonitor
NviCSAudioDataSource
NviAudioDataSource
NviDataSource
CSAlertBehaviorPredictor
CSDefaultAudioRouteChangeMonitorMac
CSAudioInjectionEngineFactory
CSSiriBluetoothManager
CSEndpointerAssetManager
CSAssetManagerDelegate
CESRTrialAssetDelegate
CSEndpointDelayReporter
CSBenchmarkXPCProtocol
CoreSpeechXPCProtocol
CSActivationEventNotifier
CSLanguageCodeUpdateMonitorImpl
CSVoiceTriggerEventsCoordinator
AudioFile
CSSoftwareUpdateCheckingMonitor
CSPreferences
CSAssetManagerEnablePolicy
CSAttSiriAudioSessionStateClient
AFNotifyObserverDelegate
CSCoreSpeechServiceListenerDelegate
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSBatteryMonitor
Liminal
CSVoiceTriggerAssetMetaUpdateMonitor
CSAudioRecordDeviceIndicator
CSVoiceTriggerEnabledPolicyHelper
CSDarkWakePowerAssertionMac
CSSiriQueueMonitor
_CSSiriQueueObserver
CSAlwaysEnabledPolicy
CSRemoteVADCircularBuffer
CSAdBlockerAssetMetaUpdateMonitor
CSAudioStream
CSSiriAudioSession
CSSiriAudioRoute
CSServerEndpointFeatures
CSActivationEventNotificationHandler
CoreSpeechXPC
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
CSRawAudioInjectionProvider
CSSpringboardStartMonitor
CSAudioProvider
CSAudioPreprocessorDelegate
CSListeningEnabledPolicyWatch
CSAlwaysOnProcessorStateMonitor
CSAdBlockerAssetDecoderFactory
CSMyriadNotifier
CSTUPhoneCallStateMonitor
CSAdBlockerAssetDecoderV1
CSAVCallConnectedMonitor
CSUserSessionActiveMonitor
CSTrialAssetDownloadMonitor
CSRemoteDeviceProtocolInfo
Bitset
CSHybridEndpointAnalyzer
OSDAnalyzerDelegate
8!!!B
CSOpportuneSpeakListenerOption
CSAudioInjectionDevice
CSAudioSessionInfoProvider
CSEndpointerProxy
CSEndpointAnalyzerDelegate
CSSiriMobileBluetoothDeviceDataSource
AFInvalidating
CSSiriMobileBluetoothDeviceProxy
AFBluetoothDevice
CSFirstUnlockMonitor
CSPhraseSpotterEnabledMonitor
CSVoiceIdXPCConnection
NSXPC
CSPhoneCallStateMonitorFactory
CSSiriPreferences
MockRemotePluginXPCProtocol
CSFallbackAudioSessionReleaseProvider
CSSPGEndpointAnalyzer
EARCaesuraSilencePosteriorGeneratorDelegate
CSHomePodSettingsMonitor
CSASXSignatureExtracting
CSSiriAcousticFingerprinter
CSLanguageDetectorOption
CSSiriSpeechRecorder
CSSiriAcousticFingerprinterDelegate
CSSpeechControllerDelegate
CSLanguageDetectorDelegate
CSSpeakerIdentificationDelegate
CSSiriSpeechCapturing
CSSiriAudioPlaybackService
AFMemoryPressureListening
AFAudioPlaybackService
CSTrialAssetManager
CSStartOfSpeechDetector
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSVoiceTriggerXPCClient
CSXPCActivity
CSCoreSpeechDaemonStateMonitor
CSNetworkAvailabilityMonitor
CSSpeechDetectionDevicePresentMonitor
CSLanguageCodeUpdateMonitorImplDarwin
CSAttSiriMitigationAssetHandler
CSAudioRecordDeviceInfo
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSAudioConverter
CSLanguageCodeUpdateMonitor
CSVoiceTriggerEventInfoProvider
CSSmartSiriVolumeRunPolicy
CSAudioInjectionServices
CSRemoteDarwinDeviceInfo
CSAdBlockerAssetDecoderV3
Trial
CSGestureDropEvent
RecordContext
LanguageDetector
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioFileReaderDelegate
CSRemoteRecordClientDelegate
CSUserSessionActiveMonitorDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSCommandControlBehaviorMonitor
CSVoiceProfileContext
NviContext
CSEndpointerFactory
CSJarvisTriggerModeMonitor
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
NviSignalData
CSSRFUserSettingMonitor
dictionaryWithObjects:forKeys:count:
dictionaryWithDictionary:
count
numberWithUnsignedInteger:
setObject:forKeyedSubscript:
expressionForConstantValue:
arrayWithObjects:count:
expressionForFunction:arguments:
expressionValueWithObject:context:
doubleValue
sortUsingComparator:
objectAtIndexedSubscript:
numberWithDouble:
distributionDictionary:
isDarwinOS
sharedInstance
wakeGestureTimestamp
dismissalTimestamp
hostTimeToSeconds:
_startMonitoringWithQueue:
_stopMonitoring
isTriggerHandheld
setWakeGestureTimestamp:
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
TQ,N,V_wakeGestureTimestamp
TQ,N,V_dismissalTimestamp
init
array
string
appendFormat:
countByEnumeratingWithState:objects:count:
address
supportDoAP
splitterState
copy
addObject:
_hasDeviceTemporaryPairedNotInContacts
isTemporaryPairedNotInContacts
description
splitterDeviceList
addDeviceIntoSplitterDeviceList:
shouldDisableSpeakerVerificationInSplitterMode
splitterEnabled
setSplitterEnabled:
.cxx_destruct
_splitterDeviceList
_splitterEnabled
TB,N,V_splitterEnabled
TB,R,N
initWithStreamHandleId:
inputRecordingNumberOfChannels
inputRecordingSampleRate
converterForAudioStreamId:
initWithNumChannels:recordingDuration:samplingRate:audioTimeConverter:
UUID
setConnectedDevice:
enableAlwaysOnVoiceTrigger
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
setDelegate:
dealloc
start
noAlertOption
startAudioStreamWithOption:
stopAudioStream
stop
reset
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
sampleCount
requestHistoricalAudioDataWithHostTime
startRecordingHostTime
objectAtIndex:
objectForKeyedSubscript:
unsignedIntValue
unsignedLongLongValue
getBestSampleCountWithOption:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioStreamHandleId
audioEngineDidStopRecord:audioStreamHandleId:reason:
length
inputRecordingSampleByteDepth
numberWithUnsignedLongLong:
removeObjectAtIndex:
bytes
addSamples:numSamples:
inputRecordingIsFloat
isIOSDeviceSupportingBargeIn
applyNegative32dBGainToFloatBuffer:
applyNegative20dBGainToFloatBuffer:
applyNegative32dBGainToShortBuffer:
applyNegative20dBGainToShortBuffer:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
processAudioChunk:
sharedPreferences
firstPassDebuggingEnabled
getLastResult
bestScore
bestStart
bestEnd
isEarlyDetect
secondsToHostTime:
sharedManagerForCoreSpeechDaemon
builtInMicVoiceTriggerEvent:hostTime:
notifyActivationEvent:completion:
inputRecordingBufferDuration
copybufferFrom:to:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
audioEngineAudioChunkForTvAvailable:audioChunk:
alwaysOnVoiceTriggerEnabled
attachDevice:
isRecording
queue
setQueue:
delegate
keywordAnalyzer
setKeywordAnalyzer:
circularBuffer
setCircularBuffer:
lastForwardedSampleCount
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
uuid
setUuid:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_queue
_delegate
_keywordAnalyzer
_circularBuffer
_lastForwardedSampleCount
_hostTimeBuffer
_uuid
_connectedDevice
_voiceTriggerSampleCount
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
TQ,N,V_lastForwardedSampleCount
T@"NSMutableArray",&,N,V_hostTimeBuffer
T@"NSUUID",&,N,V_uuid
TB,N,V_voiceTriggerEnabled
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
TB,N,V_isForwarding
TQ,N,V_voiceTriggerSampleCount
initWithWindowStartTime:
shouldRunAsSecondChance
secondChanceHotTillMachTime
setSecondChanceHotTillMachTime:
_secondChanceHotTillMachTime
TQ,N,V_secondChanceHotTillMachTime
outputStreamToFileAtPath:append:
currentRunLoop
scheduleInRunLoop:forMode:
open
hasSpaceAvailable
stringWithFormat:
lengthOfBytesUsingEncoding:
cStringUsingEncoding:
write:maxLength:
close
removeFromRunLoop:forMode:
stream:handleEvent:
initWithFilePath:appendHdr:
logData:
endRequest
oStream
setOStream:
_oStream
T@"NSOutputStream",&,N,V_oStream
_reportsDynamicActivityAttribute:bundleId:
setCurrentAttributionKey:andApp:
reportMicUsage:
reportsDynamicActivityAttributeAsync:bundleId:
reportsDynamicActivityAttributeSync:bundleId:
currentHandler
stringWithUTF8String:
handleFailureInFunction:file:lineNumber:description:
isWakeGestureAvailable
sharedManager
startWakeGestureUpdates
_didReceiveWakeGesture
_didReceiveSleepGesture
notifyObserver:
gestureMonitorDidReceiveWakeGesture:
enumerateObserversInQueue:
gestureMonitorDidReceiveSleepGesture:
wakeGestureManager:didUpdateWakeGesture:
wakeGestureManager:didUpdateWakeGesture:detectedAt:
wakeGestureManager:didUpdateWakeGesture:type:detectedAt:
wakeGestureManager:didUpdateWakeGesture:orientation:
wakeGestureManager:didUpdateWakeGesture:orientation:detectedAt:
_gestureManager
isVoiceTriggerAssetOverridingEnabled
weakObjectsHashTable
removeObject:
voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:
sharedHandler
getVoiceTriggerAssetWithEndpointId:completion:
defaultFallbackModelIfNil:
registerObserver:
unregisterObserver:
notifyObservers:endpointId:
observers
setObservers:
_observers
T@"NSHashTable",&,N,V_observers
initWithEndpointId:
_startMonitoring
_getAudioSessionID
_createXPCClientConnectionIfNeeded
UUIDString
sessionInfoProvider
audioSessionIdForDeviceId:
audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
initWithType:
setSessionInfoProvider:
connect
setShouldKeepConnection:
addObserver:
userInfo
_registerInterruptionNotification
_registerAudioRouteChangeNotification
audioSessionController:didReceiveAudioSessionOwnerLostNotification:
_teardownXPCClientIfNeeded
audioSessionController:didReceiveAudioSessionOwnerResetNotification:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
CSXPCClient:didDisconnect:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
getAudioSessionIDWithCompletion:
getAudioSessionID
_handleInterruption:
_mediaServicesWereLost:
_mediaServicesWereReset:
_audioRouteChanged:
xpcClient
setXpcClient:
shouldKeepConnection
endpointId
setEndpointId:
_shouldKeepConnection
_sessionInfoProvider
_xpcClient
_endpointId
T@"<CSAudioSessionInfoProviding>",&,N,V_sessionInfoProvider
T@"CSXPCClient",&,N,V_xpcClient
TB,V_shouldKeepConnection
T@"NSUUID",&,N,V_endpointId
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
launchSiriDebugAppWithMessage:
resourcePath
getStringForKey:category:default:
stringByAppendingPathComponent:
getNumberForKey:category:default:
floatValue
getBoolForKey:category:default:
activationMetadata
isHSVoiceTrigger:
isEqualToString:
mitigatonConfigFile
mitigationModelDefaultAFTMScore
nldaConfigFile
allowKeywordsFile
allowListWordCountThreshold
mitigationConfigFileForCategory:
nldaConfigFileForCategory:
shouldRunSpkrIdForCategory:
getCategoryKeyWithRecordCtx:
Tf,R,N
T@"NSString",R,N
TQ,R,N
firstPartyCall
phoneCallState
defaultOption
_notifyObserver:mediaIsPlayingState:
defaultCenter
_notePossiblePlayPausedStateChange:
addObserver:selector:name:object:
removeObserver:name:object:
objectForKey:
boolValue
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
initializeMediaPlayingState
mediaPlayingState
mediaPlayingStateWithCompletion:
_mediaIsPlaying
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
_outASBD
T@"NSURL",R,N,V_audioURL
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
T^{OpaqueExtAudioFile=},N,V_fFile
Tf,R,N,V_scaleFactor
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
removeObserver:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
initializeTimerState
timerState
_timerFiringState
initializeAlarmState
alarmState
_alarmFiringState
name
setName:
_name
T@"NSString",&,N,V_name
integerValue
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserDeltaScoreThreshold
multiUserConfidentScoreThreshold
mutableCopy
removeObjectForKey:
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
assetManagerEnabledPolicy
_setupAttSiriSvcXpcConnection
synchronousRemoteObjectProxyWithErrorHandler:
startAttendingWithContext:
stopAttendingWithContext:
siriRequestProcessingCompleted
invalidate
initWithMachServiceName:options:
interfaceWithProtocol:
setRemoteObjectInterface:
attSiriDidDetectAttendingTrigger:
attSiriAttendingTimeoutTriggered
attSiriAttendingFailed
setExportedInterface:
setExportedObject:
attSiriSvcConn
processIdentifier
setAttSiriSvcConn:
setInterruptionHandler:
setInvalidationHandler:
resume
remoteSvcProxy
setRemoteSvcProxy:
_attSiriSvcConn
_remoteSvcProxy
T@"NSXPCConnection",&,N,V_attSiriSvcConn
T@,&,N,V_remoteSvcProxy
T@"<CSAttSiriServiceDelegate>",W,N,V_delegate
getCurrentFanInfo:
fanId
setFanId:
currentSpeed
setCurrentSpeed:
targetSpeed
setTargetSpeed:
_fanId
_currentSpeed
_targetSpeed
TQ,N,V_fanId
Tq,N,V_currentSpeed
Tq,N,V_targetSpeed
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
deviceId
setDeviceId:
isSecondPassRunning
setIsSecondPassRunning:
firstPassMyriadGoodnessScore
setFirstPassMyriadGoodnessScore:
_isSecondPassRunning
_firstPassMyriadGoodnessScore
_deviceId
T@"NSString",&,N,V_deviceId
TB,N,V_isSecondPassRunning
Tf,N,V_firstPassMyriadGoodnessScore
dictionary
pendingSecondPassTriggerWasClearedForClient:deviceId:
_clearPendingRemoraVoiceTrigger
voiceTriggerDidDetectKeyword:deviceId:completion:
_clearPendingBuiltInVoiceTrigger
enumerateKeysAndObjectsUsingBlock:
isBultInVoiceTriggerEvent:
isRemoraVoiceTriggerEvent:
voiceTriggerDidDetectKeyword:deviceId:
handlePendingRemoraVoiceTriggerIfNeeded
handlePendingBuiltInVoiceTriggerIfNeeded
voiceTriggerDidDetectNearMiss:deviceId:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:deviceId:
supportHomeKitAccessory
setBuiltInVoiceTriggerMetaData:
accessoryVoiceTriggerMetaDataByDeviceId
setObject:forKey:
voiceTriggerDidDetectKeyword:myriadHash:remoteTriggerType:remoteDeviceId:isTriggeredFromFullWake:completion:
secondPassDidStartForClient:deviceId:withFirstPassEstimate:
secondPassDidStopForClient:deviceId:
initWithTargetQueue:
_getHighestRemoraFirstPassGoodnessScore:
_isRemoraSecondPassRunning
builtInSeconPassProgressProvider
setBuiltInSeconPassProgressProvider:
remoraSecondPassProgressProvider
setRemoraSecondPassProgressProvider:
targetQueue
setTargetQueue:
pendingRemoraVoiceTriggerResult
setPendingRemoraVoiceTriggerResult:
pendingRemoraVoiceTriggerDeviceId
setPendingRemoraVoiceTriggerDeviceId:
pendingRemoraVoiceTriggerCompletionBlk
setPendingRemoraVoiceTriggerCompletionBlk:
pendingRemoraVoiceTriggerDetectedTime
setPendingRemoraVoiceTriggerDetectedTime:
pendingBuiltInVoiceTriggerResult
setPendingBuiltInVoiceTriggerResult:
pendingBuiltInVoiceTriggerCompletionBlk
setPendingBuiltInVoiceTriggerCompletionBlk:
pendingBuiltInVoiceTriggerDetectedTime
setPendingBuiltInVoiceTriggerDetectedTime:
builtInVoiceTriggerMetaData
setAccessoryVoiceTriggerMetaDataByDeviceId:
_builtInSeconPassProgressProvider
_remoraSecondPassProgressProvider
_targetQueue
_pendingRemoraVoiceTriggerResult
_pendingRemoraVoiceTriggerDeviceId
_pendingRemoraVoiceTriggerCompletionBlk
_pendingRemoraVoiceTriggerDetectedTime
_pendingBuiltInVoiceTriggerResult
_pendingBuiltInVoiceTriggerCompletionBlk
_pendingBuiltInVoiceTriggerDetectedTime
_builtInVoiceTriggerMetaData
_accessoryVoiceTriggerMetaDataByDeviceId
T@"NSObject<OS_dispatch_queue>",&,N,V_targetQueue
T@"NSDictionary",&,N,V_pendingRemoraVoiceTriggerResult
T@"NSString",&,N,V_pendingRemoraVoiceTriggerDeviceId
T@?,C,N,V_pendingRemoraVoiceTriggerCompletionBlk
TQ,N,V_pendingRemoraVoiceTriggerDetectedTime
T@"NSDictionary",&,N,V_pendingBuiltInVoiceTriggerResult
T@?,C,N,V_pendingBuiltInVoiceTriggerCompletionBlk
TQ,N,V_pendingBuiltInVoiceTriggerDetectedTime
T@"CSPreMyriadVoiceTriggerMetaData",&,N,V_builtInVoiceTriggerMetaData
T@"NSMutableDictionary",&,N,V_accessoryVoiceTriggerMetaDataByDeviceId
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
T@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProvider
T@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPassProgressProvider
getBestAnalyzedResultsFromAudioChunk:
getThreshold
deviceID
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
avvcContext
unsignedIntegerValue
initWithMode:deviceUID:
supportHandsFree
isRequestDuringActiveCall
supportRingtoneA2DP
setActivationMode:
setAnnounceCallsEnabled:
avvcContextSettings
voiceTriggerEventInfo
route
source
decodeJson:
horsemanDeviceType
getNumElementInBitset:
_getNumberFromASVDictionaryForKey:category:default:
intValue
_adaptiveSiriVolumeDictionary
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
numberWithUnsignedInt:
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
numberWithFloat:
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVDistanceChannelBitset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
TI,R,N
T@"NSDictionary",R,N
Ti,R,N
Td,R,N
initWithXPCObject:
_cs_initWithXPCObject:
initWithRecordDeviceInfo:playbackRoute:playbackDeviceTypeList:
xpcObject
_cs_xpcObject
UTF8String
initWithFormat:
encodeObject:forKey:
decodeObjectOfClass:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
_recordDeviceInfo
_playbackRoute
_playbackDeviceTypeList
T@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfo
T@"NSString",R,C,N,V_playbackRoute
T@"NSArray",R,C,N,V_playbackDeviceTypeList
startXPCConnection
invalidateXPCConnection
didReceiveSpeakerRecognitionScoreCard:
didFinishSpeakerRecognition:
initWithDelegate:
ssrXPCClient
setSsrXPCClient:
_ssrXPCClient
T@"CSSSRXPCClient",&,N,V_ssrXPCClient
T@"<CSSpeakerRecognitionProxyProtocol>",R,W,N,V_delegate
_createXPCClientConnectionIfNeeded:
processInfo
systemUptime
enableVoiceTrigger:withAssertion:timestamp:
enableVoiceTrigger:withAssertion:xpcClient:
setPhraseSpotterBypassing:timeout:
setPhraseSpotterBypassing:timeout:xpcClient:
setRaiseToSpeakBypassing:timeout:
setRaiseToSpeakBypassing:timeout:xpcClient:
notifyVoiceTriggeredSiriSessionCancelled
fetchVoiceTriggerStats
notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:
sharedService
voiceTriggerXPCClient:didDisconnect:
enableVoiceTrigger:withAssertion:
fetchVoiceTriggerDailyStats
T@"CSVoiceTriggerXPCClient",&,N,V_xpcClient
supportMphAssets
_notificationKey
_didInstalledNewVoiceTriggerAsset
_notifyObserver:
enumerateObservers:
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
_notifyToken
getLocalUrl
path
_compatibilityVersion
stringValue
appendString:
_version
_footprint
assetForAssetType:resourcePath:configVersion:
attributes
state
isPremium
getCSAssetOfType:
isDownloading
isCSAssetInstalled
canBePurged
isLatestCompareTo:
supportZeroFilter:
supportBeepCanceller:
setNumChannels:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
resetWithSampleRate:
initWithToken:sampleRate:numChannels:
setSampleRate:
_isNarrowBand:
upsampler
setUpsampler:
zeroFilter
beepCanceller
getZeroStatisticsFromBuffer:entireSamples:
convertSampleRateOfBuffer:
processBuffer:atTime:
cancelBeepFromSamples:timestamp:
audioPreprocessor:hasAvailableBuffer:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
flush
sharedAggregator
stopCountingZeroStatisticsWithReporter:
_reportMetrics
isHeadphoneDeviceWithRecordRoute:playbackRoute:
willBeep
_fetchCurrentMetrics
sharedAnalytics
logEventWithType:context:
metrics
inputRecordingSampleRateNarrowBand
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
initWithSampleRate:withNumberOfChannels:
processBuffer:atTime:arrivalTimestampToAudioRecorder:
willBeepWithRecordRoute:playbackRoute:
reportMetricsForSiriRequestWithUUID:
sampleRate
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
numChannels
_sampleRate
_numChannels
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
Tf,N,V_sampleRate
T@"CSAudioSampleRateConverter",&,N,V_upsampler
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
T@"CSBeepCanceller",&,N,V_beepCanceller
T@"CSAudioZeroCounter",&,N,V_zeroCounter
Ti,N,V_numChannels
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
_startObservingOtherAppRecordingState
isOtherNonEligibleAppRecording
handleOtherAppRecordingStateChange:
_systemControllerDied:
createBenchamrkXPCConnection
remoteObjectProxy
pingpong:completion:
runLstmPhsModelWithConfig:withUrl:completion:
runVTSecondPassModelWithConfig:locale:withUrl:completion:
runOSDAnalyzerWithConfig:withUrl:completion:
smartSiriVolumeEnablePolicy
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
allowVoiceTriggerAccessoryAssetDownloading
setAllowVoiceTriggerAccessoryAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
_allowVoiceTriggerAccessoryAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
TB,N,V_allowEndpointAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
TB,N,V_allowVoiceTriggerAccessoryAssetDownloading
stringByAppendingFormat:
_subscribeEventMonitors
subscribeEventMonitor:
_addSmartSiriVolumeEnabledConditions
shouldAudioMonitoringRecording
addConditions:
_addContinousAudioFingerprintEnabledConditions
_attachBluetoothSession
_getWirelessSplitterInfoFromLocalDevice:
getBTLocalDeviceWithCompletion:
initWithCapacity:
initWithUTF8String:
setAddress:
setSupportDoAP:
setIsTemporaryPairedNotInContacts:
_tearDownLocalDevice
_detachBluetoothSession
_setUpLocalDevice
getWirelessSplitterInfoWithCompletion:
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
T^{BTSessionImpl=},N,V_bluetoothSession
TB,N,V_isAttachingBluetoothSession
T^{BTLocalDeviceImpl=},N,V_localDevice
T@"NSArray",&,N,V_pairedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
propertyDictForDarwin
deviceIdentifier
dataUsingEncoding:
dataWithBytes:length:
appendBytes:length:
wakeHostForVoiceTrigger
_device
_hidCallbackQueue
isEnabled
CSSiriAssertionMonitor:didReceiveEnabled:
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
enableAssertionReceived
disableAssertionReceived
_assertionState
getSerialQueue:withQualityOfService:andTargetQueue:
_init
accessorySiriClientBehaviorMonitor:willStartStreamWithContext:option:forAccessory:
accessorySiriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
accessorySiriClientBehaviorMonitor:willStopStream:reason:forAccessory:
accessorySiriClientBehaviorMonitor:didStopStream:reason:withEventUUID:forAccessory:
notifyWillStartStreamWithContext:option:forAccessory:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
notifyWillStopStream:reason:forAccessory:
notifyDidStopStream:reason:withEventUUID:forAccessory:
isSpeakerRecognitionAvailable
_didInstalledNewAsset
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
initWithTimeout:
_readAudioBufferAndFeed
audioFileReaderDidStartRecording:successfully:error:
dataWithLength:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStopRecording:forReason:
initWithURL:
setRecordBufferDuration:
prepareRecording:
startRecording
stopRecording
readSamplesFromChannelIdx:
_audioFeedTimer
_bufferDuration
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
_didInstalledNewAdBlockerAsset
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
monitor
setMonitor:
_monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
_fetchHearstRoutedState
_fetchSiriInputSourceOutOfBandState
_notifyHearstRoutedState:
_notifySiriInputSourceOutOfBandState:
_startObservingAudioRouteChange
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
currentRoute
siriInputSource
activeAudioRouteDidChange:
getHearstConnected:
hearstConnected
getHearstRouted:
hearstRouted
getJarvisConnected:
jarvisConnected
carPlayConnected
siriInputSourceOutOfBand
getSiriInputSourceOutOfBand:
_isHearstConnected
_isHearstRouted
_isSiriInputSourceOutOfBand
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
mutableBytes
handleFailureInMethod:object:file:lineNumber:description:
setLength:
downsampler
_sampleRateConverter
_outBufferScaleFactor
_inASBD
languageDetectorAssetMonitor:didReceiveNewAssetWithSupportLocale:
_supportedLocale:
supportLanguageDetector
setAssetDownloadingOption:
languageDetectorSupportedLocale
localizedDescription
assetOfType:language:completion:
errorWithDomain:code:userInfo:
startMonitor
supportedLocale:
notifyToken
setNotifyToken:
Ti,N,V_notifyToken
T@"<CSLanguageDetectorAssetMonitorDelegate>",W,N,V_delegate
defaultManager
removeItemAtURL:error:
_finalizeAudioFileWriterWithCompletion:
_removeRecordedAudio
shouldLogForQA
_didBecomeCurrent
_didResignCurrent
remoteDeviceUID
initWithBlock:
invoke
audioSessionActivationTargetDate
timeIntervalSinceNow
setTimestamp:
setReason:
setEffectiveDate:
setUserInfo:
newWithBuilder:
acquireAudioSessionAssertionWithContext:relinquishmentHandler:
dateByAddingTimeIntervalSinceActivation:
date
dateByAddingTimeInterval:
relinquishWithContext:options:
relinquishWithError:options:
_initializeAudioFileWriterWithAudioStreamBasicDescription:
appendAudioData:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
initWithType:pathGenerator:priority:
configureWithAudioStreamBasicDescription:
flushWithCompletion:
_instrumentSiriCue:
setSiriCueType:
logInstrumentation:machAbsoluteTime:turnIdentifier:
_createRequestLinkInfo:component:
setSource:
setTarget:
initWithUUIDString:
initWithNSUUID:
setComponent:
sharedMonitor
_donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:
waitForMyriadDecisionForReason:withCompletion:
containsObject:
numberWithBool:
relativePath
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
initWithSessionUUID:turnIdentifier:
becomeCurrent
resignCurrent
updateStartSpeechId:
updateSelectedResultCandidateId:
updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:
getAudioRecordRouteAndDeviceIdentificationWithCompletion:
acquireRecordedAudioWithHandler:
updateAudioRecordContext:
updateAudioRecordDeviceInfo:
updateVoiceTriggerInfo:
updateRecordingInfo:
updateRecordingSettings:
willPrepareAndStartRecordingWithAudioActivationInfo:
didDetectTwoShotWithAudioActivationInfo:atTime:
willStopRecordingAtHostTime:
didStopRecordingWithError:
relinquishAudioSessionAssertionsWithContext:
relinquishAudioSessionAssertionsWithError:
beginRecordingAudioWithAudioStreamBasicDescription:
appendRecordedAudioBuffer:
endRecordingAudio
instrumentSiriCue:
instrumentSiriCueForAlertType:
emitRequestLinkEventForMHUUID:
sessionUUID
wantsRecordedAudioBufferLogs
_isCurrent
_startSpeechId
_selectedResultCandidateId
_audioRecordContext
_audioRecordDeviceInfo
_voiceTriggerInfo
_recordingSettings
_recordingInfo
_audioFileWriter
_recordedAudioFileURL
_startRecordingAudioSessionAssertion
_twoShotDetectionAudioSessionAssertion
_recordingAudioGroup
_voiceIdentificationTraining_allowsWithoutResultCandidate
_voiceIdentificationTraining_allowedResultCandidateIds
_voiceIdentificationTraining_resultCandidateToSharedUserIdMap
_turnIdentifier
_voiceIdentificationTraining_withoutResultCandidateSharedUserId
_stopRecordingInstrumented
_wantsRecordedAudioBufferLogs
_sessionUUID
T@"NSString",R,C,N,V_sessionUUID
TB,R,N,V_wantsRecordedAudioBufferLogs
_getRemoteServiceProxyObject
getVolumeForTTSType:withContext:reply:
setSmartSiriVolumePercentage:
setSmartSiriVolumeDirection:
setPermanentVolumeOffsetWithDirection:
didSmartSiriVolumeChangeForReason:
_createClientConnection
code
didTTSVolumeChangeForReason:
ssvConnection
setSsvConnection:
getVolumeForTTSType:withContext:
_ssvConnection
T@"NSXPCConnection",&,N,V_ssvConnection
T@"<CSSmartSiriVolumeClientDelegate>",W,N,V_delegate
type
isPluginContext
initWithDeviceType:deviceName:deviceID:productID:
deviceType
_createSpeechDetectionVADIfNeeded
isPluginDevice
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
engineWithDeviceType:streamHandleId:
setInjectionEngine:
removeAllObjects
audioRecorderStreamHandleIdInvalidated:
audioRecorderWillBeDestroyed:
injectionEngine
streamHandleId
deviceName
deviceUID
productIdentifier
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:
useSpeexForAudioInjection
setActive:withOptions:error:
setActive:error:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
streamHandleID
defaultInjectionProvider
createSharedAudioSession
primaryInputDevice
connectDevice:
disconnectDevice:
willDestroy
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setContext:completion:
setCurrentContext:streamHandleId:error:
prepareAudioStreamRecord:recordDeviceIndicator:error:
startAudioStreamWithOption:recordDeviceIndicator:error:
stopAudioStreamWithRecordDeviceIndicator:error:
isRecordingWithRecordDeviceIndicator:
recordRouteWithRecordDeviceIndicator:
audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:
recordSettingsWithStreamHandleId:
recordingSampleRateWithStreamHandleId:
isNarrowBandWithStreamHandleId:
prewarmAudioSessionWithStreamHandleId:error:
activateAudioSessionWithReason:streamHandleId:error:
deactivateAudioSession:streamHandleId:error:
deactivateAudioSession:error:
setRecordMode:streamHandleId:error:
setDuckOthersOption:
duckOthersOption
setAlertSoundFromURL:forType:force:
playRecordStartingAlertAndResetEndpointerFromStream:
playAlertSoundForType:recordDevideIndicator:
alertStartTime
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
isSessionCurrentlyActivated
voiceTriggerInfoWithRecordDeviceIndicator:
enableMiniDucking:
configureAlertBehavior:audioStreamHandleId:
didStartDelayInSeconds
setDidStartDelayInSeconds:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
activateStartTime
setActivateStartTime:
activateEndTime
setActivateEndTime:
deactivateStartTime
setDeactivateStartTime:
deactivateEndTime
setDeactivateEndTime:
atvRemoteDeviceID
setAtvRemoteDeviceID:
_didStartDelayInSeconds
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
_activateStartTime
_activateEndTime
_deactivateStartTime
_deactivateEndTime
_atvRemoteDeviceID
T@"NSMutableArray",&,N,V_connectedDevices
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
TQ,N,V_latestPluginStreamId
TQ,N,V_activateStartTime
TQ,N,V_activateEndTime
TQ,N,V_deactivateStartTime
TQ,N,V_deactivateEndTime
T@"NSString",&,N,V_atvRemoteDeviceID
Tf,N,V_didStartDelayInSeconds
initWithAnalyzeMode
opportuneSpeakingFileLoggingIsEnabled
lpcmNonInterleavedWithRemoteVADASBD
lpcmInterleavedWithRemoteVADASBD
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
contextForHearstVoiceTriggerWithDeviceId:
opportuneSpeakListeningType
contextForOpportuneSpeakerListener
contextForOpportuneSpeakerListenerWithCall
_resetAlignBuffer
prepareAudioProviderWithContext:clientType:error:
_startRequestWithCompletion:
defaultRequestWithContext:
setRequiresHistoricalBuffer:
audioStreamWithRequest:streamName:error:
setAudioStream:
getFrameDurationMs
remoteVADDuration
supportsUnderstandingOnDevice
getSiriLanguageWithFallback:
preheatLocalSpeechRecognitionWithLanguage:source:
startAudioStreamWithOption:completion:
endAudio
audioStream
stopAudioStreamWithOption:completion:
stopListenWithStateReset:completion:
opportuneSpeakListener:didStopUnexpectly:
numSamples
hostTime
processSampleCount:hostTime:
channelForProcessedInput
dataForChannel:
addAudio:numSamples:
remoteVAD
opportuneSpeakListenerBypassEnabled
_addRemoteVADSignal:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
_shouldReportBoron
_popRemoteVADSignal
opportuneSpeakListener:hasRemoteVADAvailable:
hostTimeFromSampleCount:
opportuneSpeakListener:hasVADAvailable:withHostTime:
opportuneSpeakListener:hasVADAvailable:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:
spgEndpointAnalyzerDidDetectEndpoint:
startListenWithOption:completion:
stopListenWithCompletion:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
runningSampleCount
setRunningSampleCount:
audioTimeConverter
setAudioTimeConverter:
_isMediaPlayingNow
_remoteVADSPGRatio
_audioStream
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_runningSampleCount
_audioTimeConverter
T@"CSAudioStream",&,N,V_audioStream
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
Ti,N,V_remoteVADSPGRatio
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
T@"CSAudioRecordContext",&,N,V_latestContext
TB,V_isMediaPlayingNow
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
TQ,N,V_remoteVADAlignCount
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
TQ,N,V_runningSampleCount
T@"CSAudioTimeConverter",&,N,V_audioTimeConverter
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
disconnect
_notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
_handleListenerEvent:
_handleListenerError:
initWithDictionary:
_sendMessage:connection:completion:
_decodeError:
xpcConnection
setXpcConnection:
_xpcConnection
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
RMSScore
initWithRMSScore:lastSampleCount:
compareScoresDesc:
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
Td,N,V_RMSScore
TQ,N,V_lastSampleCount
appendData:
getBytes:range:
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
numberOfVoicingFrames
sortUsingSelector:
addDataToBuffer:
calculateShadowMicScore
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
T@"NSMutableData",&,N,V_audioBuffer
Td,N,V_speechVoiceLevel
TQ,N,V_numberOfVoicingFrames
Tq,N,V_numberOfTotalFramesETFT
TQ,N,V_bestStartDetectSample
TQ,N,V_bestEarlyDetectSample
TQ,N,V_bestEndDetectSample
Td,N,V_shadowMicScore
_didReceiveWirelessSplitterStateChange
_notifyObserver:splitterState:shouldDisableSpeakerVerificationInSplitterMode:
splitterState:
CSBluetoothWirelessSplitterMonitor:didReceiveSplitterStateChange:shouldDisableSpeakerVerificationInSplitterMode:
updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:
_splitterState
continuousAudioFingerprintEnabledPolicy
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:withNumChannels:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
fetchVoiceTriggerHeartBeatMetrics
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
setStartWaitTime:
automaticEndpointingSuspensionEndTime
setAutomaticEndpointingSuspensionEndTime:
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
setEndWaitTime:
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
mhId
setMhId:
Tq,N
Td,N
TB,N
T@"NSString",&,N
resetForNewRequestWithSampleRate:recordContext:
processAudioSamplesAsynchronously:
stopEndpointer
recordingStoppedForReason:
implDelegate
setImplDelegate:
canProcessCurrentRequest
activeChannel
setActiveChannel:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
processOSDFeatures:withFrameDurationMs:
processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:
setEndpointerOperationMode:
fetchCurrentEndpointerOperationMode
logAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
processASRFeatures:fromServer:
processTaskString:
endpointerModelVersion
elapsedTimeWithNoSpeech
T@"<CSEndpointAnalyzerDelegate>",W,N
T@"<CSEndpointAnalyzerImplDelegate>",W,N
TQ,N
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
T@"NSString",&,N,VmhId
_startMonitorLanguageDetectorAssetDownload
hashFromResourcePath
languageDetectorConfigFile
fileExistsAtPath:
_setNumLatestLangFromConfigFile:
initWithConfigFile:
_constructLangPriors
setDictationLanguagePriors:
samplingRate
languageDetectorRequestContext
startRequestWith:context:delegate:
_initializeStartOfSpeechDetector:samplingRate:
_resetStartOfSpeechDetector
defaultController
_setupLanguageDetectorWithOption:
addAudioSamples:count:
resetForNewRequest
startOfSpeechDetectorConfigFile
_readJsonDictionaryAt:
_getDefaultValues
initWithNumChannels:recordingDuration:samplingRate:
spgConfigFile
initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:
_recordRecognitionLanguage:
setObject:atIndexedSubscript:
fileExistsAtPath:isDirectory:
dataWithContentsOfFile:options:error:
JSONObjectWithData:options:error:
dataWithJSONObject:options:error:
writeToFile:atomically:
loggingDict
logEventWithType:context:contextNoCopy:
confidences
isConfident
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
_logLanguageDetectorMetricsForLoggingInfo:
startOfSpeechDetectedAtFrame:
bufferLength
copySamplesFrom:to:
data
startOfSpeechAudioLoggingEnabled
getStartOfSpeechAudioLogFilePath
stringByAppendingString:
_logSoSResult:toPath:
URLWithString:
saveAudioChunck:toURL:
languageDetectorDidCompleteProcessing:loggingInfo:
languageDetector:confidences:
languageDetector:result:
startOfSpeechDetector:foundStartSampleAt:
initWithModelURL:
resetForNewRequest:
cancelCurrentRequest
setInteractionIDforCurrentRequest:
recordRecognitionLanguage:
setMostRecentRecognitionLanguage:
languageDetector
setLanguageDetector:
startOfSpeechDetector
setStartOfSpeechDetector:
circBuffer
setCircBuffer:
startOfSpeechDetected
setStartOfSpeechDetected:
needsToUpdateModel
setNeedsToUpdateModel:
currentState
setCurrentState:
latestDetectedLanguages
setLatestDetectedLanguages:
numLatestLanguages
setNumLatestLanguages:
languageDetectorAssetHash
setLanguageDetectorAssetHash:
currentAsset
setCurrentAsset:
interactionID
setInteractionID:
_startOfSpeechDetected
_needsToUpdateModel
_languageDetector
_startOfSpeechDetector
_circBuffer
_currentState
_latestDetectedLanguages
_numLatestLanguages
_languageDetectorAssetHash
_currentAsset
_interactionID
T@"_EARLanguageDetector",&,N,V_languageDetector
T@"_EARLanguageDetectorAudioBuffer",&,N,V_audioBuffer
T@"CSStartOfSpeechDetector",&,N,V_startOfSpeechDetector
T@"CSAudioCircularBuffer",&,N,V_circBuffer
TB,N,V_startOfSpeechDetected
TB,N,V_needsToUpdateModel
Tq,N,V_currentState
T@"NSMutableArray",&,N,V_latestDetectedLanguages
TQ,N,V_numLatestLanguages
T@"NSString",C,N,V_languageDetectorAssetHash
T@"CSAsset",&,N,V_currentAsset
T@"NSString",C,N,V_interactionID
T@"<CSLanguageDetectorDelegate>",W,N,V_delegate
languageCodeDarwin
getSiriLanguageWithEndpointId:fallbackLanguage:
_shouldDisableSpeakerVerificationInSplitterMode
stringWithString:
initWithStopRecordingReason:expectedStopHostTime:trailingSilenceDurationAtEndpoint:
stopRecordingReason
expectedStopHostTime
trailingSilenceDurationAtEndpoint
_stopRecordingReason
_expectedStopHostTime
_trailingSilenceDurationAtEndpoint
TQ,R,N,V_stopRecordingReason
TQ,R,N,V_expectedStopHostTime
Td,R,N,V_trailingSilenceDurationAtEndpoint
deviceIsInSleep
dataWithCapacity:
myriadHashFilePath
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
reportMHEndpointerAccessibleContextEventWithThresholdType:MhId:
reportServerEndpointWithMhId:
arrayWithCapacity:
_emitMHEndpointLatencyInfo:withRequestMHUUID:
currentContext
initWithInstanceContext:
initWithRequestMHUUID:
addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:
report
firstPktLatency
setFirstPktLatency:
requestMHUUID
setRequestMHUUID:
trailingPktSpeechLatencies
setTrailingPktSpeechLatencies:
trailingPktLatencies
setTrailingPktLatencies:
numOfAudioPackets
setNumOfAudioPackets:
numOfValidTrailingPackets
setNumOfValidTrailingPackets:
numOfValidTrailingSpeechPackets
setNumOfValidTrailingSpeechPackets:
_firstPktLatency
_requestMHUUID
_trailingPktSpeechLatencies
_trailingPktLatencies
_numOfAudioPackets
_numOfValidTrailingPackets
_numOfValidTrailingSpeechPackets
T@"NSMutableArray",&,N,V_trailingPktSpeechLatencies
T@"NSMutableArray",&,N,V_trailingPktLatencies
TQ,N,V_numOfAudioPackets
TQ,N,V_numOfValidTrailingPackets
TQ,N,V_numOfValidTrailingSpeechPackets
Td,N,V_firstPktLatency
T@"NSString",&,N,V_requestMHUUID
_notifyStopCommandControl
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
isStreaming
_isCommandControlStreaming
sharedVoiceTriggerClient
_didReceiveAVVCRecordingClientNumberChange:
siriClientsRecordingCompletionBlock:
setSiriClientRecordStateChangedBlock:
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
numOfAVVCRecordingClients
alwaysOnProcessorController
setAlwaysOnProcessorController:
_numOfAVVCRecordingClients
_alwaysOnProcessorController
T@"AVVoiceTriggerClient",&,N,V_alwaysOnProcessorController
TQ,R,N,V_numOfAVVCRecordingClients
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
initWithCrashMonitor:
getAudioSessionState
setAudioSessionState:
_audioSessionState
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
enumerateObjects:
_savedAudioFilesDirectory
URLByAppendingPathComponent:
_initWithType:pathGenerator:xorFileHandle:priority:
fileDescriptor
defaultCStringEncoding
stringWithCString:encoding:
_close
fileURLWithPath:isDirectory:
_generateTemporaryFileURL
initWithDomain:code:userInfo:
_delete
fileSystemRepresentation
initWithFileDescriptor:closeOnDealloc:
initWithType:fileHandle:priority:
cancel
_type
_url
_path
_audioFile
_asbd
_fileHandle
_underlyingError
initWithServiceName:
getCoreSpeechXPCConnection
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
getCoreSpeechServiceConnection
getCurrentVoiceTriggerLocaleWithEndpointId:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
_checkCanUseVoiceTriggerDuringCallEnabled
_notifyObserver:withEnabled:
_didReceiveCanUseVoiceTriggerDuringCallSettingChangedInQueue:
_voiceTriggerDuringCallEnabledDidChange
_isEnabled
setAudioFormat:
audioConverterBitrate
setEncoderBitRate:
setNumberOfChannels:
inputRecordingSampleBitDepth
setLpcmBitDepth:
setLpcmIsFloat:
setRecordContext:
setUseCustomizedRecordSettings:
recordContext
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
lpcmBitDepth
lpcmIsFloat
numberOfChannels
encoderBitRate
setIsSiri:
requestForLpcmRecordSettingsWithContext:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
initTandemWithRequest:
isSiri
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_recordContext
_audioFormat
T@"NSObject<OS_xpc_object>",R,N
T@"CSAudioRecordContext",&,N,V_recordContext
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
T@"NSString",C,N,V_deviceId
startManager
_createClearLoggingFileTimer
registerPostBuildInstallService
_startClearLoggingFilesTimer
supportHearstVoiceTrigger
setDelegate:forType:
supportRemoraVoiceTrigger
supportJarvisVoiceTrigger
isLocalVoiceTriggerAvailable
supportBluetoothDeviceVoiceTrigger
_getAudioRecorderWithError:
audioProviders
setLatestRecordContext:streamType:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:
setAudioProviderDelegate:
audioStreamId
initWithAudioRecorder:
audioRecorderWithQueue:error:
setAudioRecorder:
setAsset:
daysBeforeRemovingLogFiles
removeLogFilesOlderThanNDays:
removeOpportunisticAudioLoggingOlderThanNDays:
removeRemoteP2PLogFilesOlderThanNDays:
_handleClearLoggingFileTimer
activationEventNotificationHandler:event:completion:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioProviderInvalidated:streamHandleId:
opportuneSpeakEventMonitor:didStreamStateChanged:
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithContext:error:
audioProviderWithStreamID:
fetchFallbackAudioSessionReleaseProvider
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
audioRecorder
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
ssvManager
setSsvManager:
_assetQueryQueue
_audioRecorder
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
_ssvManager
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"CSAudioRecorder",&,N,V_audioRecorder
T@"NSMutableDictionary",&,N,V_audioProviders
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
Tq,N,V_clearLoggingFileTimerCount
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
addNumSamples:hostTime:
notifyTrailingSilenceDurationAtEndpoint:
estimatedSpeechEndHostTime
numAudioSampleForwarded
setNumAudioSampleForwarded:
lastAudioChunkHostTime
setLastAudioChunkHostTime:
endPointNotified
setEndPointNotified:
setTrailingSilenceDurationAtEndpoint:
_endPointNotified
_numAudioSampleForwarded
_lastAudioChunkHostTime
TQ,N,V_numAudioSampleForwarded
TQ,N,V_lastAudioChunkHostTime
TB,N,V_endPointNotified
Td,N,V_trailingSilenceDurationAtEndpoint
_notifyObserver:withClamshellState:
CSClamshellStateMonitor:didReceiveClamshellStateChange:
isClamshellClosed
_didReceiveClamshellStateChangeNotification:
contextForBuiltInVoiceTrigger
commandControlListener:didStopUnexpectly:
commandControlListener:hasLPCMBufferAvailable:
T@"<CSCommandControlListenerDelegate>",W,N,V_delegate
flexKwdConfigFile
flexKwdThresholdFile
initWithDownloadOption:
addObserver:forAssetType:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
setCallback:
_fetchRemoteMetaData
_canFetchRemoteAsset:
assetOfType:language:
installedAssetOfType:language:
allInstalledAssetsOfType:language:
installedAssetOfType:language:completion:
assetOfType:language:compatibilityVersion:completion:
getInstalledAssetofType:forLocale:completion:
fetchRemoteMetaOfType:
supportHybridEndpointer
supportAdBlocker
supportsSpeakerRecognitionAssets
assetForCurrentLanguageOfType:completion:
CSAssetManagerDidDownloadNewAsset:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
CSAssetController:didDownloadNewAssetForType:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
assetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
assetOfType:providerType:language:completion:
currentLanguageCode
removeObserver:forAssetType:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
endpointerOperationMode
useAutomaticEndpointing
csAudioProcessingQueuePriority
rootQueueWithFixedPriority:
getEndpointerModelVersionWithReply:
timeIntervalSinceDate:
wordCount
trailingSilenceDuration
eosLikelihood
pauseCounts
silencePosterior
taskName
processedAudioDurationInMilliseconds
processServerFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
getElapsedTimeNoSpeechWithReply:
getEndPointAnalyzerTypeWithReply:
resetForVoiceTriggerTwoShotWithSampleRate:
setupConnection
didDetectStartpointAtTime:
didDetectHardEndpointAtTime:withMetrics:
_setQueue:
endpointerConnection
xpcConnectionQueue
setEndpointerConnection:
setRemoteObjectProxy:
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
endPointAnalyzerType
resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:
endpointerDelegate
setEndpointerDelegate:
setXpcConnectionQueue:
xpcClientQueue
setXpcClientQueue:
xpcDelegateQueue
setXpcDelegateQueue:
_endpointerDelegate
_endpointerConnection
_xpcConnectionQueue
_xpcClientQueue
_xpcDelegateQueue
_remoteObjectProxy
T@"NSXPCConnection",&,N,V_endpointerConnection
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcConnectionQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcClientQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcDelegateQueue
T@,&,N,V_remoteObjectProxy
initWithDataSource:assetsProvider:
addDelegate:
removeDelegate:
startWithNviContext:didStartHandler:
stopWithDidStopHandler:
sigType
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:queue:
initWithMachServiceName:
xpcConnection:hasEntitlement:
clientConnections
listener:shouldAcceptNewConnection:
notifyClientsWithBlock:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:
resumeConnection
setClientConnections:
machServiceName
setMachServiceName:
_listener
_exportedInterface
_remoteInterface
_proxyObject
_clientConnections
_machServiceName
T@"NSMutableArray",&,N,V_clientConnections
T@"NSString",&,N,V_machServiceName
programmableAudioInjectionEnabled
initWithQueue:error:
_initWithFirstPassInfoGeneratedTime:firstPassInfoProcessedTime:
CSVoiceTriggerFirstPassMetricsWithFirstPassInfoGeneratedTime:firstPassInfoProcessedTime:
firstPassInfoGeneratedTime
firstPassInfoProcessedTime
_firstPassInfoGeneratedTime
_firstPassInfoProcessedTime
T@"NSNumber",R,N,V_firstPassInfoGeneratedTime
T@"NSNumber",R,N,V_firstPassInfoProcessedTime
startController
supportPhatic
supportSessionActivateDelay
supportLazySessionActivation
initWithEndpointId:xpcClientFactory:endpointer:continuousVoiceTrigger:siriVolumeController:mediaPlayingMonitor:alarmMonitor:timerMonitor:sacInfoMonitor:audioSessionController:supportPhatic:supportHearstVoiceTrigger:supportTriagleModeSessionActivationRetry:supportSessionActivateDelay:supportLazySessionActivtion:
setEndpointerImplDelegate:
supportsEndpointingOnATV
initForSidekick
endpointerProxy
_supportsHybridSDSD
twoShotNotificationEnabled
_currentAudioRecorderSampleRate
_shouldUseSoundPlaybackMonitors
_createMediaPlayingMonitor
_initializeMediaPlayingState
_createAlarmMonitor
_initializeAlarmState
_createTimerMonitor
_initializeTimerState
supportSmartVolume
_isHubRequestTV
audioSessionActivationDelay
defaultFactory
initWithQueue:instanceContext:
initWithQueue:
addListener:
_setMediaPlaybackState:isInterrupted:
_setSoundPlayingState
getPlaybackStateWithCompletion:
_setAlarmIsPlaying:
getFiringAlarmIDsWithCompletion:
_setTimerIsPlaying:
getFiringTimerIDsWithCompletion:
setCurrentRecordContext:error:
isAttentiveSiriEnabled
_refreshSpeakerRecognitionAssets
isConnected
_shouldResetContextAtPrepare
audioRecordContext
_fetchAudioProviderWithContext:
sessionProvider
enableSmartRoutingConsideration:
isTriggeredFromHearst
_shouldFetchVoiceTriggerInfo
_shouldFetchRaiseToSpeakInfo
_fetchLastTriggerInfo
_activateAudioSessionWithReason:delay:delayRequested:error:
domain
_activateAudioSessionWithReason:error:
prepareAudioStreamSyncWithRequest:error:
streamProvider
isNarrowBand
_setupDownsamplerIfNeeded
_setupAudioConverter:isNarrowBand:
_createAudioPowerMeterIfNeeded
triggerInfoForContext:completion:
isVoiceTriggered
isServerInvoked
isHomePressed
isTVRemote
supportsDuckingOnCurrentRouteWithError:
isDeviceRoleStereo
supportsDuckingOnSpeakerOutput
_currentConfigurationSupportsDucking
_isDelayedDuckingSupportedContext
hostTimeToTimeInterval:
logHybridEndpointFeaturesWithEvent:locale:
_scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:
_cancelPendingAudioSessionActivateForReason:
_lazyActivateAudioSessionWithReason:error:
speechController:willSetAudioSessionActive:
speechController:didSetAudioSessionActive:
_doActivateAudioSessionWithReason:error:
isDictation
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
isAudioRecordTypeSupportedByRemora
setType:
_updateRecordContextIfNeeded:
setAudioRecordContext:
setCurrentContext:error:
prewarmAudioSessionWithError:
_teardownAudioProviderIfNeeded
_fetchFallbackAudioSessionReleaseProviding
fallbackDeactivateAudioSession:error:
recordSettings
numberWithInt:
lpcmInt16NarrowBandASBD
lpcmInt16ASBD
setDictationLanguages:
setCurrentKeyboard:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setConversationalMessages:
_isRecordRouteBuiltinMic
setAVVCAlertBehavior:
setSkipAlertBehavior:
supportOpportunisticZLL
setUseOpportunisticZLL:
setStartRecordingHostTime:
setRequestHistoricalAudioDataWithHostTime:
setSiriSessionUUID:
setDisableEndpointer:
setDisableLocalSpeechRecognizer:
setDisablePrewarmLocalAsrAtStartRecording:
_shouldSetStartSampleCount
setRequestHistoricalAudioDataSampleCount:
setStartRecordingSampleCount:
_shouldSetStartSampleCountForRTS
setRequireSingleChannelLookup:
setSelectedChannel:
_setupSpeakerRecognitionController
_startPhaticDecision
recordRoute
lpcmMonoNonInterleavedWithRemoteVADASBD
lpcmMonoInterleavedWithRemoteVADASBD
createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:withLoggingUUID:
createAudioFileWriterWithInputFormat:outputFormat:withLoggingUUID:
_shouldUseLanguageDetector:
_createLanguageDetectorIfNeeded
_languageDetectorOptionFromSettings:
setSamplingRate:
languageDetectorDelegate
languageCode
initWithRequestId:languageCode:
prepareLogging
isAlertBehaviorOverridedBeep
notifyWillStartStreamWithContext:option:
audioDeviceInfo
speechControllerDidStartRecording:audioDeviceInfo:successfully:error:
speechControllerDidStartRecording:successfully:error:
_shouldTrackLaunchLatency
submitVoiceTriggerIssueReport:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
_canPlayPhaticDuringMediaPlayback
speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:
speechControllerDidDetectVoiceTriggerTwoShot:atTime:
shouldDelayPhaticForMyriadDecision
_shouldScheduleAudibleFeedbackAtStartRecording
_scheduledAudibleFeedbackDelay
speechControllerRequestsOperation:forReason:completion:
_audibleFeedbackPlaybackReason
isBuiltInVoiceTriggered
isHearstVoiceTriggered
isJarvisVoiceTriggered
isRemoraVoiceTriggered
isRTSTriggered
startRecordingWithSettings:error:
notifyWillStopStream:reason:
_didStopForReason:
speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:
_shouldReportEstimatedSpeechEndHostTime
canPerformDelayedStop
speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:
speechControllerDidStopRecording:forReason:estimatedSpeechEndHostTime:
addContextKey:withContext:
addContextKey:fromMetaFile:
_deviceAudioLoggingWithFileWriter:
notifyDidStopStream:withEventUUID:
_isDuckingAvailableRoute:
playingApps
appName
version
_logRecordingStopErrorIfNeeded:
subChunkFrom:numSamples:
remoteVADSubChunkFrom:numSamples:numAudioSamplesPerRemoteVAD:
setRemoteVAD:
_audioStreamProvdider:audioBufferAvailable:
hasPerformedDelayedStop
setHasPerformedDelayedStop:
convertToShortLPCMBufFromFloatLPCMBuf:
sampleByteDepth
processFloatBuffer:stride:inFrameToProcess:
processShortBuffer:stride:inFrameToProcess:
getAveragePowerDB
getPeakPowerDB
startSampleCount
arrivalHostTimeToAudioRecorder
wasBuffered
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:arrivalHostTimeToAudioRecorder:wasBuffered:remoteVAD:
addSamples:timestamp:arrivalTimestampToAudioRecorder:
speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:
speechControllerLPCMRecordBufferAvailable:buffer:
_fetchAudioDecoderForTV:
packets
timeStamp
addPackets:audioStreamHandleId:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
avgPower
setCachedAvgPower:
peakPower
setCachedPeakPower:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:
defaultConverter
speechControllerRecordHardwareConfigurationDidChange:toConfiguration:
speechControllerDidFinishAlertPlayback:ofType:error:
speechControllerBeginRecordInterruption:
speechControllerBeginRecordInterruption:withContext:
speechControllerEndRecordInterruption:
speechControllerDidUpdateSmartSiriVolume:forReason:
narrowBandOpusConverter
opusConverter
alertProvider
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
audioMeterProvider
cachedPeakPower
cachedAvgPower
initWithSampleRate:
channelForOutputReference
speechControllerRequestsOperation:forReason:
audioMetricProvider
audioMetric
setWithObjects:
_shouldRunHybridSDSDMitigation
processRCWithId:duration:lrnnScore:lrnnThreshold:taskId:forceAccept:completionHandler:
getMitigationDecisionForRCIdWithCompletion:completion:
supportNonInterruptibleSiri
submitAudioIssueReport:
speexASBD
opusASBD
_createAudioProviderFromXPCWithContext:
clientForAudioProviding
_setupAudioProviderFromXPC:
setStreamProvider:
setSessionProvider:
setAlertProvider:
setAudioMeterProvider:
setAudioMetricProvider:
setAudioSessionDelegate:
setAudioAlertDelegate:
clientForFallbackAudioSessionReleaseProviding
allKeys
initWithData:encoding:
_getSpeechIdentifier
generateDeviceAudioLogging:speechId:
isStarkTriggered
debugLogPath
volumeEstimate
getVolumeForTTSType:
setIsMediaPlayingOnAccessory:isMediaPlaying:isInterrupted:interruptedTime:
setIsAlarmPlayingOnAccessory:isAlarmPlaying:
setIsTimerPlayingOnAccessory:isTimerPlaying:
sharedController
isSmartSiriVolumeAvailable
audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:
didTTSVolumeChange:forReason:
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
endpointer:detectedTwoShotAtTime:
endpointer:reportEndpointBufferHostTime:firstBufferHostTime:
nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:
nowPlayingObserverNowPlayingInfoDidChange:
nowPlayingObserver:proxyGroupPlayerStateDidChangeFrom:to:
clockAlarmObserver:alarmDidFire:
clockAlarmObserver:alarmDidDismiss:
clockAlarmObserver:snapshotDidUpdateFrom:to:
clockTimerObserver:timerDidFire:
clockTimerObserver:timerDidDismiss:
clockTimerObserver:snapshotDidUpdateFrom:to:
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
continuousVoiceTrigger:detectedVoiceTriggerResult:
continuousVoiceTrigger:detectedSilenceAfterVoiceTriggerAt:
initializeRecordSessionWithRecordContext:
prepareRecordWithSettings:error:
_performPendingAudioSessionActivateForReason:
prewarmAudioSession
resetAudioSession
releaseAudioSession
releaseAudioSession:
getLPCMAudioStreamBasicDescription
setSynchronousCallbackEnabled:
getRecordBufferDuration
startRecording:
stopRecordingWithOptions:
peakPowerForOutputReference
averagePowerForOutputReference
outputReferenceChannel
voiceTriggerInfo
fetchAudioMetricsWithCompletion:
endpointAnalyzer
setEndpointAnalyzerDelegate:
resetEndpointer
getMitigationDecisionForRCId:completion:
_contextToString:
getSmartSiriVolume
languageDetectorSetMostRecentRecognitionLanguage:
cancelCurrentLanguageDetectorRequest
setLanguageDetectorInteractionID:
beginWaitingForMyriad
endWaitingForMyriadWithDecision:
getAudioConverterForTest
setLanguageDetectorDelegate:
speakerIdDelegate
setSpeakerIdDelegate:
setSupportPhatic:
setSupportHearstVoiceTrigger:
supportTriagleModeSessionActivationRetry
setSupportTriagleModeSessionActivationRetry:
setSupportSessionActivateDelay:
supportLazySessionActivtion
setSupportLazySessionActivtion:
setEndpointerProxy:
isAsrOnDevice
setIsAsrOnDevice:
isOpus
setIsOpus:
isSiriClientListening
setIsSiriClientListening:
setIsNarrowBand:
serverLoggingWriter
setServerLoggingWriter:
volumeController
setVolumeController:
recordEventUUID
setRecordEventUUID:
isAudioSessionActivated
setIsAudioSessionActivated:
deviceRoleIsStereo
setDeviceRoleIsStereo:
speakerRecognitionScores
setSpeakerRecognitionScores:
setTwoShotNotificationEnabled:
isMediaPlaying
setIsMediaPlaying:
isAlarmPlaying
setIsAlarmPlaying:
isTimerPlaying
setIsTimerPlaying:
isSoundPlaying
setIsSoundPlaying:
isRemoteVADAvailableStream
setIsRemoteVADAvailableStream:
myriadPreventingTwoShotFeedback
setMyriadPreventingTwoShotFeedback:
speechEndHostTimeEstimator
setSpeechEndHostTimeEstimator:
bundleIdFromDictation
setBundleIdFromDictation:
shouldUseLanguageDetectorForCurrentRequest
setShouldUseLanguageDetectorForCurrentRequest:
pendingAudioSessionActivationToken
setPendingAudioSessionActivationToken:
pendingAudioSessionActivationCompletion
setPendingAudioSessionActivationCompletion:
pendingAudioSessionActivationReason
setPendingAudioSessionActivationReason:
setAudioSessionActivationDelay:
xpcClientFactory
setXpcClientFactory:
duckAudioXPCClient
setDuckAudioXPCClient:
powerMeter
setPowerMeter:
didDeliverLastBuffer
setDidDeliverLastBuffer:
didDeliverFirstSpeechPacket
setDidDeliverFirstSpeechPacket:
setCanPerformDelayedStop:
requestedStopRecordingOptions
setRequestedStopRecordingOptions:
numTrailingSamplesAfterSchedulingStop
setNumTrailingSamplesAfterSchedulingStop:
maxAllowedTrailingSamplesAfterSchedulingStop
setMaxAllowedTrailingSamplesAfterSchedulingStop:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
logEventUUID
setLogEventUUID:
ssvLogFilePath
setSsvLogFilePath:
mediaPlayingObserverQueue
setMediaPlayingObserverQueue:
mediaPlayingMonitor
setMediaPlayingMonitor:
alarmMonitor
setAlarmMonitor:
timerMonitor
setTimerMonitor:
volumeMonitor
setVolumeMonitor:
setAudioDeviceInfo:
setupStarted
setSetupStarted:
audioSessionController
setAudioSessionController:
sacInfoMonitor
setSacInfoMonitor:
rcHandlingClient
setRcHandlingClient:
uncompressedAudioLogging
setUncompressedAudioLogging:
_contextResetQueue
_opusAudioConverter
_narrowBandOpusConverter
_audioConverter
_downsampler
_requestedRecordSettings
_lastVoiceTriggerInfo
_lastRTSTriggerInfo
_continuousZeroCounter
_audibleFeedbackQueue
_twoShotAudibleFeedbackDecisionGroup
_supportPhatic
_supportHearstVoiceTrigger
_supportTriagleModeSessionActivationRetry
_supportSessionActivateDelay
_supportLazySessionActivtion
_isAsrOnDevice
_isOpus
_isSiriClientListening
_isNarrowBand
_isAudioSessionActivated
_deviceRoleIsStereo
_twoShotNotificationEnabled
_isMediaPlaying
_isAlarmPlaying
_isTimerPlaying
_isSoundPlaying
_isRemoteVADAvailableStream
_myriadPreventingTwoShotFeedback
_shouldUseLanguageDetectorForCurrentRequest
_didDeliverLastBuffer
_didDeliverFirstSpeechPacket
_canPerformDelayedStop
_hasPerformedDelayedStop
_setupStarted
_cachedAvgPower
_cachedPeakPower
_languageDetectorDelegate
_speakerIdDelegate
_endpointerProxy
_streamProvider
_sessionProvider
_alertProvider
_audioMeterProvider
_audioMetricProvider
_serverLoggingWriter
_volumeController
_recordEventUUID
_speakerRecognitionScores
_activeChannel
_speechEndHostTimeEstimator
_bundleIdFromDictation
_pendingAudioSessionActivationToken
_pendingAudioSessionActivationCompletion
_pendingAudioSessionActivationReason
_audioSessionActivationDelay
_xpcClientFactory
_duckAudioXPCClient
_powerMeter
_requestedStopRecordingOptions
_numTrailingSamplesAfterSchedulingStop
_maxAllowedTrailingSamplesAfterSchedulingStop
_decodersForTV
_decoderProcessedSampleCountForTV
_logEventUUID
_ssvLogFilePath
_mediaPlayingObserverQueue
_mediaPlayingMonitor
_alarmMonitor
_timerMonitor
_volumeMonitor
_audioDeviceInfo
_audioSessionController
_sacInfoMonitor
_rcHandlingClient
_uncompressedAudioLogging
TB,N,V_supportPhatic
TB,N,V_supportHearstVoiceTrigger
TB,N,V_supportTriagleModeSessionActivationRetry
TB,N,V_supportSessionActivateDelay
TB,N,V_supportLazySessionActivtion
T@"CSEndpointerProxy",&,N,V_endpointerProxy
T@"CSAudioRecordContext",&,N,V_audioRecordContext
T@"<CSAudioStreamProviding>",&,N,V_streamProvider
T@"<CSAudioSessionProviding>",&,N,V_sessionProvider
T@"<CSAudioAlertProviding>",&,N,V_alertProvider
T@"<CSAudioMeterProviding>",&,N,V_audioMeterProvider
T@"<CSAudioMetricProviding>",&,N,V_audioMetricProvider
TB,N,V_isAsrOnDevice
TB,N,V_isOpus
TB,N,V_isSiriClientListening
TB,N,V_isNarrowBand
T@"CSSelectiveChannelAudioFileWriter",&,N,V_serverLoggingWriter
T@"CSSmartSiriVolumeController",&,N,V_volumeController
T@"NSString",&,N,V_recordEventUUID
TB,N,V_isAudioSessionActivated
TB,N,V_deviceRoleIsStereo
T@"NSDictionary",&,N,V_speakerRecognitionScores
TQ,N,V_activeChannel
TB,N,V_twoShotNotificationEnabled
TB,N,V_isMediaPlaying
TB,N,V_isAlarmPlaying
TB,N,V_isTimerPlaying
TB,N,V_isSoundPlaying
TB,N,V_isRemoteVADAvailableStream
TB,N,V_myriadPreventingTwoShotFeedback
T@"CSSpeechEndHostTimeEstimator",&,N,V_speechEndHostTimeEstimator
T@"NSString",&,N,V_bundleIdFromDictation
T@"CSLanguageDetector",&,N,V_languageDetector
TB,N,V_shouldUseLanguageDetectorForCurrentRequest
T@"NSUUID",&,N,V_pendingAudioSessionActivationToken
T@?,C,N,V_pendingAudioSessionActivationCompletion
TQ,N,V_pendingAudioSessionActivationReason
Td,N,V_audioSessionActivationDelay
T@"CSXPCClientFactory",&,N,V_xpcClientFactory
T@"CSXPCClient",&,N,V_duckAudioXPCClient
Tf,N,V_cachedAvgPower
Tf,N,V_cachedPeakPower
T@"CSAudioPowerMeter",&,N,V_powerMeter
TB,N,V_didDeliverLastBuffer
TB,N,V_didDeliverFirstSpeechPacket
TB,N,V_canPerformDelayedStop
TB,N,V_hasPerformedDelayedStop
T@"CSStopRecordingOptions",&,N,V_requestedStopRecordingOptions
TQ,N,V_numTrailingSamplesAfterSchedulingStop
TQ,N,V_maxAllowedTrailingSamplesAfterSchedulingStop
T@"NSMutableDictionary",&,N,V_decodersForTV
TQ,N,V_decoderProcessedSampleCountForTV
T@"NSString",&,N,V_logEventUUID
T@"NSString",&,N,V_ssvLogFilePath
T@"NSObject<OS_dispatch_queue>",&,N,V_mediaPlayingObserverQueue
T@"SOMediaNowPlayingObserver",&,N,V_mediaPlayingMonitor
T@"SOClockAlarmObserver",&,N,V_alarmMonitor
T@"SOClockTimerObserver",&,N,V_timerMonitor
T@"CSVolumeMonitor",&,N,V_volumeMonitor
T@"CSAudioDeviceInfo",&,N,V_audioDeviceInfo
T@"NSUUID",R,C,N,V_endpointId
TB,N,V_setupStarted
T@"CSAudioSessionController",&,N,V_audioSessionController
T@"CSSACInfoMonitor",&,N,V_sacInfoMonitor
T@"CSRCHandlingXPCClient",&,N,V_rcHandlingClient
T@"CSUncompressedAudioLogging",&,N,V_uncompressedAudioLogging
T@"<CSSpeechControllerDelegate>",W,N,V_delegate
T@"<CSLanguageDetectorDelegate>",W,N,V_languageDetectorDelegate
T@"<CSSpeakerIdentificationDelegate>",W,N,V_speakerIdDelegate
T@"<CSEndpointAnalyzer>",R,N
getSerialQueue:qualityOfService:
ssrConnection
setSsrConnection:
_ssrConnection
T@"NSXPCConnection",&,N,V_ssrConnection
T@"<CSSSRXPCClientDelegate>",W,N,V_delegate
setCtx:
detectedToken
setDetectedToken:
triggerMachTime
setTriggerMachTime:
triggerAbsStartSampleId
setTriggerAbsStartSampleId:
_ctx
_detectedToken
_triggerMachTime
_triggerAbsStartSampleId
T@"CSAttSiriRequestContext",C,N,V_ctx
T@"NSString",&,N,V_detectedToken
TQ,N,V_triggerMachTime
TQ,N,V_triggerAbsStartSampleId
createRTModelWithLocale:
hearstRTModelWithMajorVersion:minorVersion:locale:
dataWithContentsOfFile:
_sha1:
substringWithRange:
_sha256:
initWithData:hash:locale:digest:signature:certificate:
rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:
localeMapWithName:
remoraRTModelLocaleMap
hearstRTModelLocaleMap
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
remoraRTModelWithMajorVersion:minorVersion:locale:
jarvisRTModelLocaleMap
rtModelLocaleMapWithModelType:
_prepareWithOptions:audioSession:completion:
_startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
_stop:
_handleBeginInterruption
_handleEndInterruption:
errorWithCode:
initWithBlock:defaultValue:
status
error
_resetPlayerItem
itemURL
itemData
assetWithData:contentType:options:
initWithAsset:
errorWithCode:description:
invokeWithValue:
initWithDispatchQueue:
volume
setVolume:
setActionAtItemEnd:
setAudioSession:
replaceCurrentItemWithPlayerItem:
currentItem
initWithTimeoutInterval:onQueue:timeoutHandler:
errorWithCode:description:underlyingError:
initWithQueue:qosClass:asynchronous:
_finalizeWithError:
setRate:
playerItemDidPlayToEndTime:
playerItemFailedToPlayToEndTime:
seekToTime:toleranceBefore:toleranceAfter:completionHandler:
seekToTime:toleranceBefore:toleranceAfter:
initWithQueue:request:options:
prepareWithOptions:audioSession:completion:
startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
stop:completion:
handleBeginInterruption
handleEndInterruption:
request
options
T@"AFAudioPlaybackRequest",R,N
_isActive
_player
_playerItem
_audioSession
_completion
_request
_options
T@"AFAudioPlaybackRequest",R,N,V_request
TQ,R,N,V_options
_serviceProxyWithErrorHandler:
upperCaseString:withReply:
firstObject
stringByStandardizingPath
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
buildPhoneticMatchWithLanguage:saveIntermediateFsts:completion:
generateAudioWithTexts:language:completion:
generateConfusionPairsWithUUID:parameters:language:task:samplingRate:recognizedTokens:recognizedText:correctedText:selectedAlternatives:completion:
xpcExitClean
initialize
upperCaseString:completion:
trainPersonalizedLMWithLanguage:directory:completion:
_smtConnection
setCachedAsset:
cachedAsset
_getVoiceTriggerAssetFromAssetManager:
isEqualAsset:
_checkNewAssetAvailablity
CSRemoteAssetManagerDidDownloadNewAsset:
_cachedAsset
T@"CSAsset",&,V_cachedAsset
clientForAudioSessionInfoProviding
clientForSmartSiriVolumeProviding
clientForMacOSDuckAudioDevice
initWithStreamID:atStartHostTime:
avvcAlertBehavior
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
skipAlertBehavior
setSkipAlert:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
numberWithInteger:
avvcStartRecordSettingsWithAudioStreamHandleId:
_setupSignalProviders:
mapTableWithKeyOptions:valueOptions:
strRepForNviSignalType:
strRepForNviDataSourceType:
signalProvidersMapForContext:
hashTableWithOptions:
_startSignalProvidersWithContext:
_startDataSourcesWithContext:
_stopDataSources
_stopCurrentlyRunningSignalProviders
_iterateSignalMask:withHandler:
initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:
startWithNviContext:
registerSignalProviderDelegate:forSignalTypes:
unregisterSignalProviderDelegate:forSignalType:
registerSignalProviderDelegateForAllSignalTypes:
unregisterSignalProviderDelegateForAllSignalTypes:
assetsProvider
setAssetsProvider:
dataSrcMap
setDataSrcMap:
sigProvidersMap
setSigProvidersMap:
currActiveSigProvTypes
setCurrActiveSigProvTypes:
currActiveDataSourceTypes
setCurrActiveDataSourceTypes:
_assetsProvider
_dataSrcMap
_sigProvidersMap
_currActiveSigProvTypes
_currActiveDataSourceTypes
T@"<NviAssetsProvider>",&,N,V_assetsProvider
T@"NSDictionary",&,N,V_dataSrcMap
T@"NSMapTable",&,N,V_sigProvidersMap
T@"NSHashTable",&,N,V_currActiveSigProvTypes
T@"NSHashTable",&,N,V_currActiveDataSourceTypes
_sendXPCClientType
_disconnect
_sendMessageAsync:completion:
sendMessageAndReplySync:error:
sendMessageAsync:completion:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
initWithAudioStreamProvider:streamName:streamRequest:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
audioSessionProvidingDelegate
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
createAudioStreamMessageWithRequest:
reportsDynamicActivityAttribute:bundleId:
audioStreamWithRequest:streamName:completion:
attachTandemStream:toPrimaryStream:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkFrom:to:channelIdx:
audioChunkToEndFrom:
audioChunkToEndFrom:channelIdx:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAnnounceCallsEnabled:withStreamHandleID:
configureAlertBehavior:
sampleCountFromHostTime:
pingpong:
acousticSLResultForContext:completion:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
xpcReplyQueue
setXpcReplyQueue:
activationAssertions
setActivationAssertions:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_xpcReplyQueue
_activationAssertions
_audioSessionInfoObservers
_xpcClientType
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcReplyQueue
T@"NSMutableSet",&,N,V_activationAssertions
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
T@"NSString",R,N,V_UUID
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
addTransitionFromAnyStateTo:for:
performTransitionForEvent:
initialState
setInitialState:
transitions
setTransitions:
eventToStateTransitions
setEventToStateTransitions:
_initialState
_transitions
_eventToStateTransitions
Tq,N,V_initialState
T@"NSMutableDictionary",&,N,V_transitions
T@"NSMutableDictionary",&,N,V_eventToStateTransitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
Tq,R,N,V_currentState
CSEventMonitorDidReceiveEvent:
deviceProductType
systemUpTime
sharedPowerLogger
powerWithNumFalseWakeup:withDuration:withPhraseDict:
numberWithLongLong:
reportDigitalZerosWithAudioZeroRun:
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:withPhrase:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
falseWakePhraseDictionary
setFalseWakePhraseDictionary:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
_falseWakePhraseDictionary
TQ,N,V_numFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
T@"NSMutableDictionary",&,N,V_falseWakePhraseDictionary
initWithSamplingRate:withAsset:
initWithSamplingRate:asset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
didReceiveAlarmChanged:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
utteranceFileASBD
_closeAudioFile
_makeTimestampedAudioLogFilenameWithPrefix:suffix:
baseDir
_audioLogDirectory
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
stringFromDate:
_getOrCreateAudioLogDirectory
_nowString
stringByReplacingOccurrencesOfString:withString:
_audioLength
initWithType:deviceId:activationInfo:vadScore:hosttime:
initWithType:deviceId:activationInfo:hosttime:
_activationTypeString
remoteMicVADEvent:vadScore:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
remoraVoiceTriggerEvent:activationInfo:hostTime:
mediaserverdLaunchedEvent:
activationInfo
hosttime
vadScore
_vadScore
_activationInfo
_hosttime
TQ,R,N,V_type
T@"NSString",R,N,V_deviceId
T@"NSDictionary",R,N,V_activationInfo
TQ,R,N,V_hosttime
Tf,R,N,V_vadScore
componentsSeparatedByString:
shortFormForUUID
_registerForFakeAssetRollNotification
setShouldRollFakeModel:
lastFakeModelUsedHash
setLastFakeModelUsedHash:
shouldRollFakeModel
fakeAssetRollNotificationRegistrationToken
setFakeAssetRollNotificationRegistrationToken:
_shouldRollFakeModel
_fakeAssetRollNotificationRegistrationToken
_lastFakeModelUsedHash
Ti,N,V_fakeAssetRollNotificationRegistrationToken
T@"NSString",&,V_lastFakeModelUsedHash
TB,V_shouldRollFakeModel
isScreenLocked
getASVUserIntent:
setUserIntentValidForSeconds:
applyLowerAndUpperBoundsToVolume:
setASVUserIntent:
initWithStoredInformationAndAsset:
increaseSiriVolumeBasedOnUserIntent
decreaseSiriVolumeBasedOnUserIntent
storeASVStateInformation
applyLowerAndUpperBoundsToVolumeOffset:
userIntentType
setUserIntentType:
userIntentValidForSeconds
userIntentTime
setUserIntentTime:
latestVolumeTime
setLatestVolumeTime:
userIntentVolume
setUserIntentVolume:
latestVolume
setLatestVolume:
permanentOffsetFactor
setPermanentOffsetFactor:
permanentOffsetIsEnabled
setPermanentOffsetIsEnabled:
kSSVCAUserIntentValidForSeconds
kSSVCAUserIntentVolumeIncreaseFactor
kSSVCAUserIntentVolumeDecreaseFactor
kSSVCAUserIntentPermanentOffsetFactorDelta
kSSVCAUserIntentPermanentOffsetFactorLowerBound
kSSVCAUserIntentPermanentOffsetFactorUpperBound
kSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUME
kSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MIN_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME
_permanentOffsetIsEnabled
_userIntentVolume
_latestVolume
_permanentOffsetFactor
_userIntentType
_userIntentValidForSeconds
_userIntentTime
_latestVolumeTime
TQ,N,V_userIntentType
TQ,N,V_userIntentValidForSeconds
Tq,N,V_userIntentTime
Tq,N,V_latestVolumeTime
Tf,N,V_userIntentVolume
Tf,N,V_latestVolume
Tf,N,V_permanentOffsetFactor
TB,N,V_permanentOffsetIsEnabled
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
getAdBlockerAssetTypeString
getSpeakerRecognitionAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
returnTypes:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
sortedArrayUsingComparator:
enumerateObjectsUsingBlock:
installedAssetOfType:withLanguage:completion:
addKeyValuePair:with:
addKeyValuePairForQuery:assetType:
_installedAssetOfType:query:withLanguage:completion:
_fetchRemoteAssetOfType:withLanguage:query:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_findLatestInstalledAsset:
queryMetaData:
isFirstUnlocked
fetchRemoteMetaOfType:allowRetry:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_isRetryRecommendedWithResult:
startCatalogDownload:options:then:
cancelDownloadSync
purgeSync
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
setDiscretionary:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
getAssetTypeStringForType:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
valueForKey:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionCurrentCompatibilityVersion
getVoiceTriggerCurrentCompatibilityVersion
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
speexConverter
setPackets:
setTimeStamp:
setStreamHandleID:
encoder
setEncoder:
_encoder
T@"CSAudioConverter",&,N,V_encoder
initWithData:
setPerceptualAudioHash:
initWithOverrideOption:reason:
setOverrideState:
sharedLogger
logSiriLaunchStartedWithVoiceTriggerEventInfo:
setVoiceTriggerEverUsed
logSiriLaunchCompletedWithVoiceTriggerEventInfo:
initWithServicePort:
deactivateForReason:options:context:completion:
setActivationSource:
setActivationExpirationTime:
sharedLauncher
notifyBuiltInVoiceTriggerPrewarm:completion:
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyWakeKeywordSpokenInBuiltInMic:
notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyWakeKeywordSpokenCarPlay:deviceId:
notifyBluetoothDeviceVoiceTriggerPrewarm:deviceId:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyWakeKeywordSpokenBluetoothDevice:deviceId:
notifyRemoraVoiceTriggerPrewarm:deviceId:completion:
notifyRemoraVoiceTrigger:myriadPHash:deviceId:completion:
notifyWakeKeywordSpokenRemora:deviceId:
deactivateSiriActivationConnectionWithReason:withOptions:withContext:
notifyDarwinVoiceTriggerPrewarmWithCompletion:
notifyDarwinVoiceTrigger:deviceId:myriadPHash:myriadLateActivationExpirationTime:completion:
secondPassAssetQueryStartTime
setSecondPassAssetQueryStartTime:
secondPassAssetQueryCompleteTime
setSecondPassAssetQueryCompleteTime:
secondPassAssetLoadStartTime
setSecondPassAssetLoadStartTime:
secondPassAssetLoadCompleteTime
setSecondPassAssetLoadCompleteTime:
secondPassAudioStreamStartTime
setSecondPassAudioStreamStartTime:
secondPassAudioStreamReadyTime
setSecondPassAudioStreamReadyTime:
secondPassFirstAudioPacketReceptionTime
setSecondPassFirstAudioPacketReceptionTime:
secondPassLastAudioPacketReceptionTime
setSecondPassLastAudioPacketReceptionTime:
secondPassCheckerModelKeywordDetectionStartTime
setSecondPassCheckerModelKeywordDetectionStartTime:
secondPassCheckerModelKeywordDetectionEndTime
setSecondPassCheckerModelKeywordDetectionEndTime:
_secondPassAssetQueryStartTime
_secondPassAssetQueryCompleteTime
_secondPassAssetLoadStartTime
_secondPassAssetLoadCompleteTime
_secondPassAudioStreamStartTime
_secondPassAudioStreamReadyTime
_secondPassFirstAudioPacketReceptionTime
_secondPassLastAudioPacketReceptionTime
_secondPassCheckerModelKeywordDetectionStartTime
_secondPassCheckerModelKeywordDetectionEndTime
TQ,N,V_secondPassAssetQueryStartTime
TQ,N,V_secondPassAssetQueryCompleteTime
TQ,N,V_secondPassAssetLoadStartTime
TQ,N,V_secondPassAssetLoadCompleteTime
TQ,N,V_secondPassAudioStreamStartTime
TQ,N,V_secondPassAudioStreamReadyTime
TQ,N,V_secondPassFirstAudioPacketReceptionTime
TQ,N,V_secondPassLastAudioPacketReceptionTime
TQ,N,V_secondPassCheckerModelKeywordDetectionStartTime
TQ,N,V_secondPassCheckerModelKeywordDetectionEndTime
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
lpcmNonInterleavedASBD
shouldDeinterleaveAudioOnCS
lpcmInterleavedASBD
_deinterleaveBufferIfNeeded:
_compensateChannelDataIfNeeded:receivedNumChannels:
setFileOption:
_defaultOutASBD
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
initWithLength:
initWithBytes:length:
replaceBytesInRange:withBytes:
lpcmFloatASBD
setAudioStreamHandleId:
fileOption
audioFeedTimer
setAudioFeedTimer:
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_audioStreamHandleId
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
_pNonInterleavedABL
TQ,N,V_audioStreamHandleId
T@"CSAudioInjectionFileOption",&,N,V_fileOption
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
TB,N,V_isRecording
Td,N,V_bufferDuration
T@"NSMutableArray",&,N,V_injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
T^{OpaqueAudioConverter=},N,V_deinterleaver
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
hasRemoteBuiltInMic
isRemoteDarwinWithDeviceId:
assetChangeMonitorDidDetectAssetChange:
startMonitoring
notifyVoiceTriggerAssetChanged
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
encodeInteger:forKey:
decodeIntegerForKey:
initWithRequestSource:
reqSrc
setReqSrc:
_reqSrc
TQ,N,V_reqSrc
initWithURL:inputFormat:outputFormat:
fileURL
inASBD
_fileURL
T@"NSURL",R,N,V_fileURL
_addVoiceTriggerEnabledConditions
phoneCallStateMonitor
isPresent
supportHangUp
isSpringboardStarted
batteryState
isRestricted
isSoftwareUpdateCheckingRunning
siriInCallPolicy
siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitor:willStopStream:reason:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
siriClientBehaviorMonitorReleasedAudioSession:
notifyFetchedSiriClientAudioStream:successfully:
notifyPreparedSiriClientAudioStream:successfully:
notifyReleaseAudioSession
setIsStreaming:
_isStreaming
TB,N,V_isStreaming
_didReceiveNewSpeechEndpointAssetMetaData
initWithVolumeEstimate:debugLogFile:
_volumeEstimate
_debugLogPath
T@"NSString",R,N,V_debugLogPath
Tf,R,N,V_volumeEstimate
_handleConnectionError:
registerUaapApp:withAssetFiles:completion:
registerUaapApp:forLocale:withAssetFiles:completion:
registerMultilingualUaapApp:withAssetFiles:completion:
registerDatapackUpdate
connection
setConnection:
_connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
initWithVoiceTriggerAssetDownloadMonitor:languageCodeUpdateMonitor:firstUnlockMonitor:trialAssetDownloadMonitor:assetManager:trialAssetManager:
_getVoiceTriggerAssetFromAssetManagerWithLocale:completion:
_handleVoiceTriggerAssetWithCompletion:
_handleEndpointVoiceTriggerAsset:completion:
cachedEndpointAssets
_checkNewAssetAvailablityForEndpoint
CSFirstUnlockMonitor:didReceiveFirstUnlock:
setCachedEndpointAssets:
voiceTriggerAssetDownloadMonitor
setVoiceTriggerAssetDownloadMonitor:
languageCodeUpdateMonitor
setLanguageCodeUpdateMonitor:
firstUnlockMonitor
setFirstUnlockMonitor:
trialAssetDownloadMonitor
setTrialAssetDownloadMonitor:
assetManager
setAssetManager:
trialAssetManager
setTrialAssetManager:
_cachedEndpointAssets
_voiceTriggerAssetDownloadMonitor
_languageCodeUpdateMonitor
_firstUnlockMonitor
_trialAssetDownloadMonitor
_assetManager
_trialAssetManager
T@"NSMutableDictionary",&,V_cachedEndpointAssets
T@"CSVoiceTriggerAssetDownloadMonitor",&,N,V_voiceTriggerAssetDownloadMonitor
T@"CSLanguageCodeUpdateMonitor",&,N,V_languageCodeUpdateMonitor
T@"CSFirstUnlockMonitor",&,N,V_firstUnlockMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetDownloadMonitor
T@"CSAssetManager",&,N,V_assetManager
T@"CSTrialAssetManager",&,N,V_trialAssetManager
_addVoiceTriggerAOPModeEnabledConditions
forceVoiceTriggerAPMode
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
_isHearstRoutedAndWithNoPhoneCall
currentBuiltinSpeakerState
isSiriClientConsideredAsRecord
pickedRoute
isAttending
setIsSiriClientConsideredAsRecord:
setPendingRecordingStopUUID:
notifyCallbackWithOption:
pendingRecordingStopUUID
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
TB,N,V_isSiriClientConsideredAsRecord
T@"NSString",&,N,V_pendingRecordingStopUUID
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
notifyWillStartStreamWithContext:audioProviderUUID:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
notifyWillStopStream:
notifyDidStopStream:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
T@"NSData",C
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
Ts,N,V_signalEstimate
TC,N,V_signalFractional
inputRecordingFramesPerPacket
inputRecordingBytesPerPacket
inputRecordingBytesPerFrame
numChannelsForNviDirectionality
nviDirectionalityStartingChannelId
nviDirectionalityEndingChannelId
monoChannelLpcmASBD
allChannelsLpcmInterleavedASBD
allChannelsLpcmNonInterleavedASBD
nviDirectionalityLpcmNonInterleavedASBD
nviDirectionalityLpcmInterleavedASBD
nviLogsRootDir
_activationMode
activationEvent
activationEventTime
suppressStartAlert
recordingAlertPolicy
_csAudioRecordTypeForSpeechRequestOptions:useBorealisBuffer:currentClientConfiguration:
speechRecordingMode
activationEventMachAbsoluteTime
homeButtonDownEventMachAbsoluteTime
activationDeviceIdentifier
usePrelisteningMode
isOnPhoneCall
hasPlayedStartAlert
languageDetectionUserContext
dictationInputOrigin
turnIdentifier
applicationDisplayName
applicationBundleIdentifier
presentationMode
mediaPlaybackVolume
dictationVoiceTriggerAbsStartSampleId
_isRequestFromSpokenNotification:
_appendDictationApplicationInfoSettings:
_audioSessionActiveDelayCoreSpeechWithType:
addEntriesFromDictionary:
_csAudioRecordType
initWithRecordType:deviceId:
setIsRequestDuringActiveCall:
setTurnIdentifier:
setActivationMetadata:
setIsRequestFromSpokenNotification:
_csAudioRecordTypeForSpeechEvent:currentClientConfiguration:
announcementPlatform
isDictationVoiceTriggerEnabled
_canUseZLL
hostTimeForSeconds:
secondsForHostTime:
_alertBehaviorForRecordRoute:recordingInfo:playbackRoute:attemptsToUsePastDataBufferFrames:
_shouldSkipStartRecordingAlertForRecordingInfo:
audioAlertStyleForRecordRoute:recordingInfo:playbackRoute:
_eventIsVoiceTrigger
shouldOverrideRecordingStartingAlertBehaviorForAlertStyle:
isEqualToNumber:
isVoiceOverTouchEnabled
invocationFeedbackExperiment
isFeatureGroupOneEnabled
_isVoiceOverTouchEnabledInAccessibility
speechEvent
sharedObserver
isDeviceInCarDNDMode
_isVibrationDisabledInAccessibility
overrideStartingAlertBeepSoundID
vendorId
deviceRingerSwitchState
useDeviceSpeakerForTTS
_audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:
vibratesForDeviceRingerSwitchState:
startAlertEnabled
hasRemoteCoreSpeech
isBluetoothVehicleOutput
URLForSoundID:
startingAlertBehavior
beepSoundID
_audioSessionActiveDelayUserPerceptionWithType:
dateWithTimeIntervalSinceNow:
accessibilityState
isVibrationDisabled
_audioSessionActiveDelayOverride
_audioSessionActiveDelayServerConfiguration
overrideAudioSessionActiveDelay
serverMediaPlaybackVolumeThresholdForAudioSessionActivationDelay
serverAudioSessionActivationDelayAboveMediaPlaybackVolumeThreshold
serverAudioSessionActivationDelay
initWithSpeechRecordingMode:clientConfiguration:experimentContext:
setSpeechRequestOptions:currentActivationInfo:
setClientConfiguration:
event
recordSettingsWithOptions:appendingSettings:
recordContextForSpeechEvent:
startRecordingSettingsWithRecordRoute:recordingInfo:playbackRoute:
audioSessionActivated
needsUpdateToPostVoiceMode
beginUpdateToPostVoice
endUpdateToPostVoiceWithContext:success:
canPrewarm
canPrepareWithoutInterruption
shouldTreatTimeoutAsHardEndpoint
requiresBorealisConsumerCheck
canGetPCMStream
_eventIsRaiseToSpeak
_eventIsTVRemote
canEnterTwoShot
shouldUseVoiceTriggerAnalyzerStyle
shouldExplicitlyPlayAlertOnStart
shouldPlayAlertIfNotPrelistening
shouldSuppressRecordingStopAlert
shouldSuppressRecordingErrorAlert
twoShotPromptTypeForRecordRoute:playbackRoute:
startingAlertBeepURL
useBorealisBuffer
usePrelistening
audioAlertStyle
activationSystemUptime
activationHostTime
buttonDownHostTime
voiceTriggerEndHostTime
setSpeechRecordingMode:
speechEndpointerOperationMode
speechRecordingAlertPolicy
isSpokenNotification
_storedActivationMode
_currentClientConfiguration
_suppressStartAlert
_experimentContext
_isActivated
_activeMediaPlaybackVolume
_useBorealisBuffer
_usePrelistening
_isOnPhoneCall
_hasPlayedStartAlert
_isSpokenNotification
_speechEvent
_audioAlertStyle
_deviceIdentifier
_activationSystemUptime
_activationHostTime
_buttonDownHostTime
_voiceTriggerEndHostTime
_speechRecordingMode
_activationMetadata
_speechEndpointerOperationMode
_speechRecordingAlertPolicy
_presentationMode
_languageDetectionUserContext
_dictationInputOrigin
_applicationDisplayName
_applicationBundleIdentifier
_dictationVoiceTriggerAbsStartSampleId
Tq,R,N,V_speechEvent
TB,R,N,V_useBorealisBuffer
TB,R,N,V_usePrelistening
Tq,R,N,V_audioAlertStyle
T@"NSString",R,C,N,V_deviceIdentifier
Td,R,N,V_activationSystemUptime
TQ,R,N,V_activationHostTime
TQ,R,N,V_buttonDownHostTime
TQ,R,N,V_voiceTriggerEndHostTime
Tq,N,V_speechRecordingMode
TB,R,N,V_isOnPhoneCall
T@"NSDictionary",R,C,N,V_activationMetadata
TB,R,N,V_hasPlayedStartAlert
Tq,R,N,V_speechEndpointerOperationMode
T@"AFSpeechRecordingAlertPolicy",R,N,V_speechRecordingAlertPolicy
Tq,R,N,V_presentationMode
TB,R,N,V_isSpokenNotification
T@"AFLanguageDetectionUserContext",R,C,N,V_languageDetectionUserContext
Tq,R,N,V_dictationInputOrigin
T@"NSUUID",R,C,N,V_turnIdentifier
T@"NSString",R,C,N,V_applicationDisplayName
T@"NSString",R,C,N,V_applicationBundleIdentifier
TQ,R,N,V_dictationVoiceTriggerAbsStartSampleId
languageDetectorUserContext
finalFilteredDictationLanguages
lastObject
isNviEnabled
strRepForNviSignalMask:
nviSignalTypeForStr:
nviDataSourceTypeForStr:
_createDirAtPath:
timeStampString
getVoiceTriggerEndSampleCountFromVTEI:
getVoiceTriggerEndSecsFromVTEI:
readJsonDictionaryAt:
getValueFromDictionaryOfDictionaries:keypath:
createDirAtPath:
silenceFramesCountMs
silenceProbability
silenceDurationMs
processedAudioMs
currentPowerSource
requestHistoricalAudioDataSampleCount
startRecordingSampleCount
useOpportunisticZLL
requireSingleChannelLookup
selectedChannel
disableBoostForDoAP
setDisableBoostForDoAP:
initTandemWithOption:
estimatedStartHostTime
setEstimatedStartHostTime:
disableEndpointer
disableLocalSpeechRecognizer
disablePrewarmLocalAsrAtStartRecording
siriSessionUUID
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_requireSingleChannelLookup
_disableEndpointer
_disableLocalSpeechRecognizer
_disablePrewarmLocalAsrAtStartRecording
_disableBoostForDoAP
_selectedChannel
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_estimatedStartHostTime
_siriSessionUUID
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
TB,N,V_requireSingleChannelLookup
TI,N,V_selectedChannel
TQ,N,V_estimatedStartHostTime
TB,N,V_disableEndpointer
TB,N,V_disableLocalSpeechRecognizer
TB,N,V_disablePrewarmLocalAsrAtStartRecording
TB,N,V_disableBoostForDoAP
T@"NSString",&,N,V_siriSessionUUID
_prepareWithOptions:audioSession:error:
initWithData:error:
initWithContentsOfURL:error:
numberOfLoops
setNumberOfLoops:
fadeInDuration
prepareToPlay
isPlaying
_didNotStartWithError:
play
setVolume:fadeDuration:
fadeOutDuration
_didStopWithError:
pause
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
_isPrepared
initWithAssertionMonitor:
_fetchAssertionMonitor
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
notifyServiceConnectionLost
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
assertionMonitor
setAssertionMonitor:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
_assertionMonitor
TB,N,V_isPhraseSpotterBypassed
TB,N,V_isRaiseToSpeakBypassed
T@"CSSiriAssertionMonitor",&,N,V_assertionMonitor
defaultContinousFingerprintBufferDuration
maxFingerprintBufferSize
shouldResetAdsDictionary
assetVersion
payloadData
setPayloadData:
_maxFingerprintBufferSize
_shouldResetAdsDictionary
_assetVersion
_payloadData
T@"NSData",&,N,V_payloadData
Tf,R,N,V_maxFingerprintBufferSize
T@"NSMutableDictionary",R,N,V_shouldResetAdsDictionary
T@"NSString",R,N,V_assetVersion
rcXPCConnection
setRcXPCConnection:
_rcXPCConnection
T@"NSXPCConnection",&,N,V_rcXPCConnection
_createSSVClientConnectionIfNeeded
ssvClient
setSsvClient:
_ssvClient
T@"CSSmartSiriVolumeClient",&,N,V_ssvClient
T@"<CSSmartSiriVolumeControllerDelegate>",W,N,V_delegate
wearerDetectionConfig
shadowMicScoreThreshold
modelData
initWithBlob:
hearstNumberOfBytesPerChunk
hearstNumberOfSamplesPerChunk
processAudioBytes:withNumberOfSamples:
samplesFed
voiceTriggerPhraseNDEAPIScorerDidDetectedKeyword:bestStartSampleCount:bestEndSampleCount:
keywordAnalyzerNDEAPI:hasResultAvailable:forChannel:
initWithAsset:assetConfig:firstPassSource:activeChannel:siriLanguage:shouldEnableShadowMicScore:
processAudioChunk:activeChannel:
currentShadowMicScore
shadowMicScoreThresholdForVAD
keywordAnalyzerNDEAPI
setKeywordAnalyzerNDEAPI:
hasReceivedNDEAPIResult
setHasReceivedNDEAPIResult:
shadowMicScoreCreator
setShadowMicScoreCreator:
dataBufferNDEAPI
setDataBufferNDEAPI:
dataBufferPositionNDEAPI
setDataBufferPositionNDEAPI:
hasReceivedEarlyDetectNDEAPIResult
setHasReceivedEarlyDetectNDEAPIResult:
_hasReceivedNDEAPIResult
_hasReceivedEarlyDetectNDEAPIResult
_shadowMicScoreThresholdForVAD
_keywordAnalyzerNDEAPI
_shadowMicScoreCreator
_dataBufferNDEAPI
_dataBufferPositionNDEAPI
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzerNDEAPI
TB,N,V_hasReceivedNDEAPIResult
T@"CSShadowMicScoreCreator",&,N,V_shadowMicScoreCreator
T@"NSMutableData",&,N,V_dataBufferNDEAPI
TQ,N,V_dataBufferPositionNDEAPI
TC,N,V_hasReceivedEarlyDetectNDEAPIResult
T@"<CSPhraseNDEAPIScorerDelegate>",W,N,V_delegate
Tf,R,N,V_shadowMicScoreThresholdForVAD
containsCategory:
getValueForKey:category:
satScoreThreshold
containsSpeakerRecognitionCategory
satScoreThresholdForPhId:
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
containsMultiUserThresholds
useSpeakerRecognitionAsset
Tq,R,N
setPrimaryStream:
streamRequest
primaryStream
initWithMasterAudioStream:name:
attachToPrimaryStreamWithCompletion:
prepareAudioStreamWithRequest:completion:
_primaryStream
T@"CSAudioStream",W,N,V_primaryStream
_supportDoAP
_isTemporaryPairedNotInContacts
_address
T@"NSString",C,N,V_address
TB,N,V_supportDoAP
TB,N,V_isTemporaryPairedNotInContacts
attendingState
setAttendingState:
attSiriStateMonitor:didRecieveAttSiriStateChange:
getAttendingState
updateState:
isAttendingForDictation
_attendingState
TQ,N,V_attendingState
smartSiriVolumeRunPolicy
isHeadlessDeviceDataCollectionModeEnabled
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendCoreSpeechGradingDataToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
_sendAcousticGradingDataToPeerId:
_sendGeckoSpeechLogsToPeerId:
_compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
filteredArrayUsingPredicate:
getResourceValue:forKey:error:
compare:
lastPathComponent
containsString:
companionSyncVoiceTriggerUtterancesEnabled
pathExtension
isInternalWithoutProfile
predicateWithBlock:
voiceTriggerAudioLogDirectory
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
URLByDeletingPathExtension
assistantAudioFileLogDirectory
geckoAudioLogDirectory
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:
initWithPattern:options:error:
rangeOfFirstMatchInString:options:range:
mhLogDirectory
stringByDeletingLastPathComponent
initWithString:
replaceMatchesInString:options:range:withTemplate:
numberWithUnsignedLong:
removeItemAtPath:error:
stringByDeletingPathExtension
stringByAppendingPathExtension:
moveItemAtPath:toPath:error:
sendMessageWithPayload:toPeer:withReply:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
writeToFile:options:error:
_spIdSiriDebugGradingDataRootDirectory
dictionaryWithObject:forKey:
setAttributes:ofItemAtPath:error:
temporaryDirectory
_createDirectoryIfDoesNotExist:
writeToURL:atomically:
newVoiceProfileWithLocale:withAppDomain:
initWithVoiceRetrainingContext:error:
_getContentsOfDirectory:
addUtterances:toProfile:withContext:withCompletion:
updateVoiceProfile:withUserName:
profileID
provisionedVoiceProfilesForLocale:
appDomain
profileId
voiceProfileForId:
deleteUserVoiceProfile:
_sendCoreSpeechMagusGradingDataToPeerId:
sharedSiriId
dateAdded
homeId
_getHomeUserIdForSharedSiriId:withCompletion:
userName
initWithObjectsAndKeys:
enter
leave
getHomeUserIdForSharedUserId:completion:
waitWithTimeout:
_sendVoiceProfile:toPeerId:
siriProfileId
locale
contentsOfDirectoryAtPath:error:
fileURLWithPath:
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
URLsForDirectory:inDomains:
remoteP2pLogDirectory
remoteGradingDataDirectory
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
isP2PTransferEnabled
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
sendAcousticGradingDataToNearbyPeer
sendGeckoSpeechLogsToCompanion
_speakerRecognitionAudioLogsGradingDir
_spIdSiriDebugTrainedUsersFilePathForLocale:
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
T@"NSString",&,N,V_lastCommunicatedPeer
T@"NSString",&,N,V_voiceTriggerBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
zeroFilterWindowSizeInMs
getHostClockFrequency
zeroFilterApproxAbsSpeechThreshold
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
vtEndInSampleCount
setVtEndInSampleCount:
numSamplesProcessed
setNumSamplesProcessed:
_vtEndInSampleCount
_numSamplesProcessed
TQ,N,V_vtEndInSampleCount
TQ,N,V_numSamplesProcessed
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
_addDisabledConditions
_performPostBuildInstallWithCompletion:
numberWithLong:
setValue:forKey:
_setMaximumBufferSizeFromInUseServices
_reset
setEnablePolicy:
enablePolicy
_handleEnablePolicyEvent:
_startListenPolling
_stopListening
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:withAccessoryID:
copyBufferWithNumSamplesCopiedIn:
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
isAdBlockerAudioLoggingEnabled
startWithUUID:withMaximumBufferSize:
stopWithUUID:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
currentMaximumBufferSize
setCurrentMaximumBufferSize:
_isListenPollingStarting
_currentMaximumBufferSize
_audioLoggingBuffer
_inUseServices
TB,N,V_isListenPollingStarting
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
T@"NSMutableDictionary",&,N,V_inUseServices
Tf,N,V_currentMaximumBufferSize
T@"CSPolicy",&,N,V_enablePolicy
_fetchSpeakerStateMutedInfo
_fetchSpeakerStateActiveInfo
_didReceiveSpeakerMuteStateChangeNotification:
speakerStateMutedCompletionBlock:
_didReceiveBuiltinSpeakerStateChangeNotification:
speakerStateActiveCompletionBlock:
setSpeakerStateChangedBlock:
setSpeakerMuteStateChangedBlock:
enableSpeakerStateListening:completionBlock:
_notifyObserver:withBuiltinSpeakerState:
CSBuiltinSpeakerStateMonitor:didReceiveBuiltinSpeakerStateChange:
_notifyObserver:isSpeakerMuted:
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
builtInSpeakerState
isSpeakerMuted
setIsSpeakerMuted:
_isSpeakerMuted
_builtInSpeakerState
TQ,N,V_builtInSpeakerState
TB,N,V_isSpeakerMuted
initWithSignalType:timestamp:
sigGenTs
headerString
initWithStartSample:endSample:confidence:azimuth:estimatedAzimuth:
mostSampledAzimuth
stringForLogging
_spatialSpectrumLogStr
startSample
setStartSample:
endSample
setEndSample:
confidence
setConfidence:
azimuth
setAzimuth:
estimatedAzimuth
setEstimatedAzimuth:
processedAudioDurMs
setProcessedAudioDurMs:
spatialSpectrumData
setSpatialSpectrumData:
azDistribution
setAzDistribution:
_confidence
_azimuth
_estimatedAzimuth
_startSample
_endSample
_processedAudioDurMs
_spatialSpectrumData
_azDistribution
TQ,N,V_startSample
TQ,N,V_endSample
Tf,N,V_confidence
Tf,N,V_azimuth
Tf,N,V_estimatedAzimuth
Td,N,V_processedAudioDurMs
T@"NSArray",&,N,V_spatialSpectrumData
T@"NSDictionary",&,N,V_azDistribution
decodeObjectOfClasses:forKey:
initWithTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:trailingSilenceDurationAtEndpoint:
totalAudioRecorded
setTotalAudioRecorded:
endpointBufferHostTime
setEndpointBufferHostTime:
featuresAtEndpoint
setFeaturesAtEndpoint:
endpointerType
setEndpointerType:
serverFeatureLatencyDistribution
setServerFeatureLatencyDistribution:
additionalMetrics
setAdditionalMetrics:
_totalAudioRecorded
_endpointBufferHostTime
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
Td,N,V_totalAudioRecorded
TQ,N,V_endpointBufferHostTime
T@"NSArray",&,N,V_featuresAtEndpoint
Tq,N,V_endpointerType
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_additionalMetrics
_setDefaultParameters
_setAsset:
_convertDB2Mag:
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
_getDevicedBFSForInputLinearVolume:
_resetStartAnalyzeTime
_getFloatBufferData:
iterateBitset:block:
_prepareSoundLevelBufferFromSamples:soundType:
_setStartAnalyzeTime:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_getUserOffsetFromMusicVolumeDB:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
smartSiriVolumeSoftVolumeEnabled
convertToFloatLPCMBufFromShortLPCMBuf:
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_getDeviceSimpledBFSForOutputLinearVolume:
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_startAnalyzeSampleCount
_samplesFed
_processedSampleCount
_isStartSampleCountMarked
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
Tq,N,V_listenPollingTimerCount
fakeVoiceTriggerAssetPath
assetForAssetType:resourcePath:configVersion:assetProvider:
_isDeviceRoleStereo
containsValueForKey:
base64EncodedStringWithOptions:
substringToIndex:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
T@"NSData",R,N,V_modelData
T@"NSString",R,N,V_modelLocale
T@"NSString",R,N,V_modelHash
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
T@"NSData",R,N,V_certificate
_silentVibrationValue
_ringVibrationValue
_fetchRingVibrationValue
_fetchSilentVibrationValue
handleRingVibrationValueChange
handleSilentVibrationValueChange
_ringVibrationState
_silentVibrationState
_fetchHearstConnectionState
_notifyHearstConnectionState:
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
preferredExternalRouteDidChange:
pickableRoutesDidChange:
carPlayAuxStreamSupportDidChange:
carPlayIsConnectedDidChange:
_isJarvisConnected
smartSiriVolumeContextAwareEnabled
_didReceiveAutomaticVolumeToggled:
initWithSuiteName:
addObserver:forKeyPath:options:context:
observeValueForKeyPath:ofObject:change:context:
_isAutomaticVolumeEnabled
retrieveSessionWithID:
inputs
portName
isEarpieceActiveNoiseCancelationEnabled
_fetchBTInfo
currentCarPlayExternalDevice
screenIDs
componentsJoinedByString:
modelName
deviceWithAddress:
deviceWithUID:
deviceInfo
_bluetoothDeviceInfo
vendorID
productID
initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:
initWithDictation:codec:
isBluetooth
headsetAddress
productId
codecIsNarrowband
isFingerprintOnly
isSecureOfflineOnly
codec
mhSource
destination
dspStatus
headsetName
activationAlertStartTimestamp
startRecordingTimestamp
audioSessionID
firstBufferTimestamp
firstBufferHostTime
isDucking
isEndAlertInfo
setIsEndAlertInfo:
triggeredTwoShotBorealis
setTriggeredTwoShotBorealis:
audioSessionSetActiveEndHostTime
setAudioSessionSetActiveEndHostTime:
bluetoothDevice
_headsetAddress
_isDictation
_isFingerprintOnly
_isSecureOfflineOnly
_isDucking
_isEndAlertInfo
_triggeredTwoShotBorealis
_mhSource
_audioSessionID
_codec
_source
_destination
_route
_deviceInfo
_modelName
_dspStatus
_headsetName
_voiceTriggerEventInfo
_activationAlertStartTimestamp
_startRecordingTimestamp
_firstBufferTimestamp
_firstBufferHostTime
_estimatedSpeechEndHostTime
_audioSessionSetActiveEndHostTime
_bluetoothDevice
TB,R,N,V_isDictation
TB,R,N,V_isFingerprintOnly
TB,R,N,V_isSecureOfflineOnly
T@"NSString",R,N,V_codec
T@"NSString",R,N,V_source
Ti,R,N,V_mhSource
T@"NSString",R,N,V_destination
T@"NSString",R,N,V_route
T@"CSAudioRecordDeviceInfo",R,N,V_deviceInfo
T@"NSString",R,N,V_deviceIdentifier
T@"NSString",R,N,V_modelName
T@"NSString",R,N,V_dspStatus
T@"NSString",R,N,V_headsetName
T@"NSDictionary",R,N,V_voiceTriggerEventInfo
Td,R,N,V_activationAlertStartTimestamp
Td,R,N,V_startRecordingTimestamp
TI,R,N,V_audioSessionID
Td,R,N,V_firstBufferTimestamp
TQ,R,N,V_firstBufferHostTime
TQ,R,N,V_estimatedSpeechEndHostTime
TB,R,N,V_isDucking
TB,N,V_isEndAlertInfo
TB,N,V_triggeredTwoShotBorealis
TQ,N,V_audioSessionSetActiveEndHostTime
T@"<AFBluetoothDevice>",R,N,V_bluetoothDevice
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
triggerVoiceProfileRetrainingWithAsset:
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
initWithFirstPassSource:deviceId:audioProviderUUID:firstPassInfo:rejectionMHUUID:isSecondChanceRun:firstpassMetrics:
firstPassSource
audioProviderUUID
firstPassTriggerInfo
rejectionMHUUID
isSecondChanceRun
firstpassMetrics
_isSecondChanceRun
_firstPassSource
_audioProviderUUID
_firstPassTriggerInfo
_rejectionMHUUID
_firstpassMetrics
TQ,R,N,V_firstPassSource
T@"NSString",R,N,V_audioProviderUUID
T@"NSDictionary",R,N,V_firstPassTriggerInfo
T@"NSUUID",R,N,V_rejectionMHUUID
TB,R,N,V_isSecondChanceRun
T@"CSVoiceTriggerFirstPassMetrics",R,N,V_firstpassMetrics
lowercaseString
checkFirstUnlocked
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:processedAudioMs:
getCurrentEndpointerAsset
_readParametersFromHEPAsset:
initWithConfiguration:modelVersion:
submitEndpointerIssueReport:
updateEndpointerThresholdWithValue:
updateEndpointerDelayedTriggerSwitch:
setIsASRFeatureFromServer:
isASRFeatureFromServer
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
acceptEagerResultWithFeatures:featuresToLog:
_shouldUsePhaticWithRecordContext
_multimodalEndpointerEnabled
defaultServerEndpointFeatures
endOfSentenceLikelihood
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:sampleRate:
_emitEndpointDetectedEventWithEndpointTimeMs:endpointBufferHostTime:endpointerFeatures:endpointerDecisionLagInNs:extraDelayMs:endpointScore:asrFeatureLatencies:
_updateEndpointerDelayedTriggerByMhId:
terminateProcessing
requestSupportedWithSamplingRate:
_getCSHybridEndpointerConfigForAsset:
endpointerAssetManagerDidUpdateAsset:
endpointerAssetManagerDidUpdateOSDAsset:
setCanProcessCurrentRequest:
osdFeaturesAtEndpoint
setOsdFeaturesAtEndpoint:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
lastKnownOSDFeatures
setLastKnownOSDFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
lastKnowServerFeaturesLatency
setLastKnowServerFeaturesLatency:
epResult
setEpResult:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
didReceiveServerFeatures
setDidReceiveServerFeatures:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
extraDelayFrequency
setExtraDelayFrequency:
taskThresholdMap
setTaskThresholdMap:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
processedAudioInSeconds
setProcessedAudioInSeconds:
lastEndpointPosterior
setLastEndpointPosterior:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
hepAudioOriginInMs
setHepAudioOriginInMs:
speechEndpointDetected
setSpeechEndpointDetected:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
firstAudioSampleSensorTimestamp
setFirstAudioSampleSensorTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
numSamplesProcessedBeforeAnchorTime
setNumSamplesProcessedBeforeAnchorTime:
anchorMachAbsTime
setAnchorMachAbsTime:
isAnchorTimeBuffered
setIsAnchorTimeBuffered:
isRequestTimeout
setIsRequestTimeout:
recordingDidStop
setRecordingDidStop:
didDetectSpeech
setDidDetectSpeech:
setElapsedTimeWithNoSpeech:
_saveSamplesSeenInReset
_canProcessCurrentRequest
_epResult
_didReceiveServerFeatures
_useDefaultServerFeaturesOnClientLag
_didCommunicateEndpoint
_speechEndpointDetected
_didTimestampFirstAudioPacket
_isAnchorTimeBuffered
_isRequestTimeout
_isASRFeatureFromServer
_recordingDidStop
_didDetectSpeech
_lastEndpointPosterior
_implDelegate
_mhId
_endpointStyle
_endpointMode
_startWaitTime
_endWaitTime
_interspeechWaitTime
_delay
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_osdFeaturesAtEndpoint
_hybridClassifier
_endpointerModelVersion
_serverFeaturesQueue
_lastKnownServerEPFeatures
_lastKnownOSDFeatures
_serverFeatureLatencies
_lastKnowServerFeaturesLatency
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_extraDelayFrequency
_taskThresholdMap
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_processedAudioInSeconds
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_hepAudioOriginInMs
_firstAudioPacketTimestamp
_firstAudioSampleSensorTimestamp
_numSamplesProcessedBeforeAnchorTime
_anchorMachAbsTime
_elapsedTimeWithNoSpeech
_endpointerOperationMode
T@"OSDFeatures",&,N,V_osdFeaturesAtEndpoint
TB,N,V_canProcessCurrentRequest
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
T@"OSDFeatures",&,N,V_lastKnownOSDFeatures
T@"NSMutableArray",&,N,V_serverFeatureLatencies
Td,N,V_lastKnowServerFeaturesLatency
TB,N,V_epResult
Td,N,V_serverFeaturesWarmupLatency
T@"NSDate",&,N,V_lastServerFeatureTimestamp
TB,N,V_didReceiveServerFeatures
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
TQ,N,V_extraDelayFrequency
T@"NSDictionary",&,N,V_taskThresholdMap
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
Td,N,V_lastReportedEndpointTimeMs
Td,N,V_processedAudioInSeconds
Tf,N,V_lastEndpointPosterior
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
TB,N,V_didCommunicateEndpoint
TQ,N,V_currentRequestSampleRate
Td,N,V_vtExtraAudioAtStartInMs
Td,N,V_hepAudioOriginInMs
TB,N,V_speechEndpointDetected
T@"NSDate",&,N,V_firstAudioPacketTimestamp
Td,N,V_firstAudioSampleSensorTimestamp
TB,N,V_didTimestampFirstAudioPacket
TQ,N,V_numSamplesProcessedBeforeAnchorTime
TQ,N,V_anchorMachAbsTime
TB,N,V_isAnchorTimeBuffered
TB,N,V_isRequestTimeout
TB,N,V_isASRFeatureFromServer
TB,N,V_recordingDidStop
TB,N,V_didDetectSpeech
Td,N,V_elapsedTimeWithNoSpeech
Tq,N,V_endpointerOperationMode
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_implDelegate
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
T@"NSString",&,N,V_mhId
initWithDeviceId:audioStreamHandleId:
waitingForConnection:error:
startRecordingWithOptions:error:
stopRecording:
didPlayEndpointBeep
hasPendingTwoShotBeep
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
TQ,R,N,V_audioStreamHandleId
CSSiriEnabledMonitor:didReceiveEnabled:
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
_createAudioStreamWithCurrentNviContext
requestHistoricalAudio
reqStartAudioSampleId
receiveOnlyProcessedChannelData
audioChunkAvailable:numChannels:numSamplesPerChannel:startSampleId:atAbsMachTimestamp:
addReceiver:
removeReceiver:
numBytesPerSample
audioStreamProvider:avBufferAvailable:
nviCtx
setNviCtx:
receivers
setReceivers:
_nviCtx
_receivers
T@"NviContext",&,N,V_nviCtx
T@"NSHashTable",&,N,V_receivers
isDefaultInputBuiltInMic
isDefaultOutputBultInSpeaker
defaultOutputAudioDeviceID
prewarm
prewarmDeviceWithIdentifier:
_dataSource
registerAssetDelegate:assetType:
_updateAssetWithCurrentLanguageForAssetType:
_isOSDIncludedInAsset:
_getCurrentHEPAsset
_updateAssetWithLanguage:assetType:
isEndpointAssetBypassTrialEnabled
setAsrDatapackInstallationStatus:
_fetchEndpointMobileAssetWithLanguage:
_notifyAssetsUpdate
_updateOEPAssetsWithLanguage:
isEndpointAssetOverridingEnabled
_getFakeEndpointAsset
setCurrentOEPAsset:
asrDatapackInstallationStatus
_getModelPathFromInstallationStatusString:
_getOEPVersionFromPath:
currentOEPAsset
currentHEPAsset
fakeEndpointAssetPath
assetStatus:
getCurrentOSDAsset
setCurrentHEPAsset:
_currentHEPAsset
_currentOEPAsset
_asrDatapackInstallationStatus
T@"CSAsset",&,N,V_currentHEPAsset
T@"CSAsset",&,N,V_currentOEPAsset
T@"NSDictionary",&,N,V_asrDatapackInstallationStatus
estimatedUserSpeakingStartedHostTime
estimatedUserSpeakingEndedHostTime
_reportUEIUserSpeakingContext
initWithRequestMHUUID:turnIdentifier:
setSpeechRecognizedContext:withEndpointerMetrics:
reportEndpointDelayIfNeed
endpointTimeInMs
setEndpointTimeInMs:
userSpeakingStartedTimeInMs
setUserSpeakingStartedTimeInMs:
userSpeakingEndedTimeInMs
setUserSpeakingEndedTimeInMs:
userSpeakingStartedHostTime
setUserSpeakingStartedHostTime:
userSpeakingEndedHostTime
setUserSpeakingEndedHostTime:
stopRecordingHostTime
setStopRecordingHostTime:
didReportEndpointDelay
setDidReportEndpointDelay:
_didReportEndpointDelay
_endpointTimeInMs
_userSpeakingStartedTimeInMs
_userSpeakingEndedTimeInMs
_userSpeakingStartedHostTime
_userSpeakingEndedHostTime
_stopRecordingHostTime
Td,N,V_endpointTimeInMs
Td,N,V_userSpeakingStartedTimeInMs
Td,N,V_userSpeakingEndedTimeInMs
TQ,N,V_userSpeakingStartedHostTime
TQ,N,V_userSpeakingEndedHostTime
TQ,N,V_stopRecordingHostTime
T@"NSUUID",&,N,V_turnIdentifier
TB,N,V_didReportEndpointDelay
_createXPCClientConnection
_notifyActivationEvent:completion:
sharedNotifier
notifyActivationEventSynchronously:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
notifySiriLanguageCodeChanged:
readAudioChunksFrom:block:
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
setFileLoggingIsEnabled:
fileLoggingIsEnabled
isPHSSupported
isAttentiveSiriAudioLoggingEnabled
getAttendingTimeoutConfig
setAudioInjectionFilePath:
enableAudioInjection:
useSiriActivationSPIForHomePod
trialBaseAssetDirectory
disableAdaptiveSiriVolume:
isAdaptiveSiriVolumeTemporaryIntentValid
isAdaptiveSiriVolumePermanentOffsetEnabled
adaptiveSiriVolumePermanentOffset
adaptiveSiriVolumeRecentIntent
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
initWithName:options:queue:delegate:
dispatchStateChangedFrom:to:
notifySiriSessionStateTTSOngoing:
notifySiriSessionStateChange:
notifyObserver:didReceiveNotificationWithToken:
notifyObserver:didChangeStateFrom:to:
siriStateObserver
setSiriStateObserver:
stateNotificationQueue
setStateNotificationQueue:
isSpeaking
setIsSpeaking:
isListening
setIsListening:
isActiveRequest
setIsActiveRequest:
isActiveSession
setIsActiveSession:
_isSpeaking
_isListening
_isActiveRequest
_isActiveSession
_siriStateObserver
_stateNotificationQueue
T@"AFNotifyObserver",&,N,V_siriStateObserver
T@"NSObject<OS_dispatch_queue>",&,N,V_stateNotificationQueue
TB,N,V_isSpeaking
TB,N,V_isListening
TB,N,V_isActiveRequest
TB,N,V_isActiveSession
T@"<CSAttSiriSessionStateDelegate>",R,W,N,V_delegate
getTestResponse:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
voiceTriggerAOPModeEnabledPolicy
progCheckerConfigFile
initWithArray:
_mapInputOriginFromAssetToCSAudioRecordType:
contConvConfigFile
keysOfEntriesPassingTest:
supportedInputOrigins
checkerThresholds
progCheckerShadowMode
contConvThresholds
T@"NSArray",R,N
_didReceiveNewVoiceTriggerAssetMetaData
notifyNewVoiceTriggerAssetMetaDataUpdated
initWithRecordContext:deviceId:shouldUseRemoteRecorder:streamHandleId:
updateWithLatestRecordContext:
updateDeviceId:
shouldUseRemoteRecorder
_shouldUseRemoteRecorder
_streamHandleId
T@"CSAudioRecordContext",R,N,V_recordContext
TB,R,N,V_shouldUseRemoteRecorder
TQ,R,N,V_streamHandleId
initWithDescription:timeout:
_addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
_removeQueue:
_beginMonitoring
_endMonitoring
initWithQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
startWithQueue:
allValues
addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
removeQueue:
beginMonitoring
endMonitoring
_numberOfTransactions
_observersByIdentifier
heartBeatFiredWithQueue:
initWithIdentifier:queue:effectiveDate:expirationDuration:heartBeatInterval:heartBeatHandler:invalidationHandler:
timeoutDetected
invokeWithSignal:
cancelIfNotAlreadyCanceled
_numberOfOccurrences
_heartBeat
_heartBeatInterval
_timeoutInterval
_timeoutHandler
_addAlwaysEnabledCondition
initWithRecordingDuration:audioSamplesPerRemoteVAD:audioSampleRate:
remoteVADSampleCount
copySamplesFromAudioSampleCount:toAudioSampleCount:
capacity
size
beginSampleCount
_remoteVADCircularBufferImpl
_audioSamplesPerRemoteVAD
_capacity
_size
_beginSampleCount
TQ,R,N,V_capacity
TQ,R,N,V_size
TQ,R,N,V_beginSampleCount
_didReceiveNewAdBlockerAssetMetaData
setStreaming:
setStreamRequest:
setStreamingUUID:
streamingUUID
tandemStreams
streaming
updateAudioStreamStartTimeInSampleCount:
setStartStreamOption:
setScheduledFutureSample:
audioStreamProvider:audioBufferAvailable:lastForwardedSampleCount:
scheduledFutureSample
startStreamOption
isWeakStream
setIsWeakStream:
needsBoost12dB
setNeedsBoost12dB:
_scheduledFutureSample
_isWeakStream
_needsBoost12dB
_streaming
_startSampleCount
_streamRequest
_startStreamOption
_tandemStreams
_streamingUUID
TB,V_streaming
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
TQ,R,N,V_startSampleCount
TQ,R,N,V_lastForwardedSampleCount
TB,N,SsetScheduledFutureSample:,V_scheduledFutureSample
T@"CSAudioStreamRequest",&,N,V_streamRequest
T@"CSAudioStartStreamOption",&,N,SsetStartStreamOption:,V_startStreamOption
TB,N,V_isWeakStream
T@"NSHashTable",R,N,V_tandemStreams
TB,N,V_needsBoost12dB
initWithAudioDeviceID:
sharedSession
currentInputDeviceUIDArray
currentInputRoute
currentOutputRoute
_inputRoute
_outputRoute
_isBluetooth
_deviceName
_uid
T@"NSString",R,C,N,V_deviceName
T@"NSString",R,C,N,V_uid
TB,R,N,V_isBluetooth
T@"NSString",R,C,N,V_source
T@"NSString",R,C,N,V_destination
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
setWordCount:
setTrailingSilenceDuration:
setEosLikelihood:
setPauseCounts:
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
T@"NSString",C,N,V_taskName
strongToWeakObjectsMapTable
_hasPendingActivationForType:
_isVoiceTriggerEvent:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
T@"NSMapTable",&,N,V_delegates
T@"CSActivationEvent",&,N,V_pendingActivationEvent
T@?,C,N,V_pendingCompletion
accessoryModelTypeToString:
setHearstFirstPassModelVersion:
setHearstSecondPassModelVersion:
fakeHearstModelPath
_handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:
configVersion
getAccessoryFallbackLocalTable
selectFallbackModelForLocale:downloadedModels:preinstalledModels:rtLocaleMap:
_fetchVoiceTriggerInstalledAssetWithLanguage:completion:
voiceTriggerHearstRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
setTriggerMode:
logLanguageMismatchMetricWithJarvisSelectedLocale:jarvisTriggerMode:
getAccessoryFallbackFamilyLocal:fromLocaleMap:
initWithFakeMonitor:
voiceTriggerRemoraRTModelForVersion:minorVersion:locale:endpointId:downloadedModels:preinstalledModels:completion:
fakeAssetMonitor
setFakeAssetMonitor:
_fakeAssetMonitor
T@"CoreSpeechXPCFakeModelMonitor",&,N,V_fakeAssetMonitor
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
_didReceiveRestrictionChangedInQueue:
_isRestricted
enableSmartRoutingConsiderationForStream:enable:
setFp:
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},N,V_fp
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
getFixedPrioritySerialQueueWithLabel:fixedPriority:
setStreamState:
allowExtendedRingBufferSize
_createCircularBufferIfNeededWithNumChannel:playbackRoute:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:phoneCallStateMonitor:
_holdRecordingExceptionIfNeeded:
_updateRemoteDeviceIdFromAVVCIfNeeded
_streamStateName:
setProviderDelegate:
_setLatestRecordContext:
recordDeviceIndicator
isDuckingSupportedOnCurrentRouteWithStreamHandleID:error:
_canSetContext
_prepareAudioStreamSync:request:error:
historicalBufferRequestStreams
_audioStreamWithRequest:streamName:error:
_handleAudioSystemFailure
setVoiceTriggerInfo:deviceId:
inputRecordingDurationInSecs
inputRecordingDurationInSecsExtended
inputRecordingDuration
numInputChannels
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
audioStreamType
startPendingOnStoppingStreams
startPendingOnStoppingStreamToCompletionDict
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
_switchToRecordingMode
circularBufferStartHostTime
circularBufferStartSampleCount
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:sampleRate:
startPendingStreams
pendingStartCompletions
_holdRecordingTransactionIfNeeded
_scheduleAudioPacketWatchDog
_scheduleDidStartRecordingDelegateWatchDog
_resetCircularBufferStartTime
setCircularBufferStartHostTime:
setCircularBufferStartSampleCount:
streams
_deliverHistoricalAudioToStreamsWithRemoteVAD:
_cancelAudioPacketWatchDog
_clearDidStartRecordingDelegateWatchDog
_releaseRecordingTransactionIfNeeded
audioPreprocessor
_clearDidStopRecordingDelegateWatchDog
_preEpilogueAudioStream
stopPendingStreams
pendingStopCompletions
_postEpilogueAudioStream
_shouldHandleStartPendingOnStopping:withStopReason:
objectEnumerator
_stopAudioStream:option:completion:
_cs_isHashTableEmpty
_shouldStopRecording
_scheduleDidStopRecordingDelegateWatchDog
_switchToListeningMode
_audioChunkFrom:to:
_audioChunkFrom:to:channelIdx:
copySamplesFrom:to:channelIdx:
_saveRecordingBufferFrom:to:toURL:
streamHolders
setSessionDelegate:
_shouldDuckOnBuiltInSpeaker
setDuckMixWithOthersForStream:duckOthers:duckToLevelInDB:mixWithOthers:
_isDuckingOnSpeakerOutputSupportedWithCurrentRoute
_deactivateAudioSession:error:
resetDuckSettings
setAlertDelegate:
isVoiceTriggerInfoAvailableLocally:
_processAudioBuffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
providerDelegate
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
_deliverPostprocessAudioChunk:toStream:lastForwardedSampleCount:
addSamples:numSamples:atHostTime:
_forwardAudioChunk:toStream:
chunkForChannel:
gainCompensatedChunk
audioInjectionEnabled
_forwardAudioChunkForTV:toStream:
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
initWithName:clientQueue:
initWithDescription:
_onAudioPacketWatchdogFire
_schduleDidStartRecordingDelegateWatchDogWithToken:
_scheduleDidStopRecordingDelegateWatchDog:
supportRemoteDarwinVoiceTrigger
hasDarwinDeviceConnected
remoteDeviceUIDString
notifyProviderContextChanged
CSPhoneCallStateMonitor:didRecievePhoneCallStateChange:
circularBufferNumInputChannel
circularBufferInputRecordingDuration
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamHandleQueue
setStreamHandleQueue:
streamState
setStartPendingStreams:
setStartPendingOnStoppingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStartPendingOnStoppingStreamToCompletionDict:
setStreamHolders:
setHistoricalBufferRequestStreams:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
audioPacketWatchdog
setAudioPacketWatchdog:
setAudioStreamType:
setRecordDeviceIndicator:
micUsageReporter
setMicUsageReporter:
audioPacketDeliveryCount
setAudioPacketDeliveryCount:
adpAssertion
setAdpAssertion:
setPhoneCallStateMonitor:
setPhoneCallState:
currentSessionShouldDuckOnBuiltInSpeaker
setCurrentSessionShouldDuckOnBuiltInSpeaker:
_audioSystemRecovering
_waitingForAlertFinish
_currentSessionShouldDuckOnBuiltInSpeaker
_recordQueue
_loggingQueue
_streamHandleQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_audioPacketWatchdog
_circularBufferStartHostTime
_circularBufferStartSampleCount
_audioStreamType
_recordDeviceIndicator
_micUsageReporter
_audioPacketDeliveryCount
_adpAssertion
_phoneCallStateMonitor
_phoneCallState
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_streamHandleQueue
TQ,N,V_streamState
T@"NSHashTable",&,N,V_startPendingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_streams
T@"NSHashTable",&,N,V_stopPendingStreams
T@"NSMutableArray",&,N,V_pendingStartCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
T@"NSMutableArray",&,N,V_streamHolders
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
TB,N,V_audioSystemRecovering
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
T@"CSOSTransaction",&,N,V_recordingTransaction
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
TB,N,V_waitingForAlertFinish
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
T@"NSObject<OS_dispatch_source>",&,N,V_audioPacketWatchdog
TQ,N,V_circularBufferStartHostTime
TQ,N,V_circularBufferStartSampleCount
Tq,N,V_audioStreamType
T@"CSAudioRecordDeviceIndicator",&,N,V_recordDeviceIndicator
T@"CSMicUsageReporter",&,N,V_micUsageReporter
TQ,N,V_audioPacketDeliveryCount
T@"CSADPPreventStandbyAssertion",&,N,V_adpAssertion
T@"CSPhoneCallStateMonitor",&,N,V_phoneCallStateMonitor
TQ,N,V_phoneCallState
TB,N,V_currentSessionShouldDuckOnBuiltInSpeaker
_addListeningEnabledConditions
_didReceiveAOPListeningStateChange:
listeningEnabledCompletionBlock:
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_isListeningEnabled
adBlockerAssetDecoderWithVersion:
notifyInEarMyriadTrigger
_startObservingAVCallActiveChange
_handleCallActiveDidChangeNotification:
hasConnectedAVCall
_hasConnectedAVCall
isUserActive
initWithProtocolVersion:buildVersion:deviceProductVersion:deviceProductType:deviceCategory:
deviceBuildVersion
deviceProductVersion
defaultProtocolInfo
localDeviceProtocolInfo
protocolVersion
buildVersion
deviceCategory
_protocolVersion
_buildVersion
_deviceProductVersion
_deviceProductType
_deviceCategory
TQ,R,N,V_protocolVersion
T@"NSString",R,N,V_buildVersion
T@"NSString",R,N,V_deviceProductVersion
T@"NSString",R,N,V_deviceProductType
TQ,R,N,V_deviceCategory
_loadAndSetupEndpointerAssetIfNecessary
subChunkFrom:numSamples:forChannel:
initWithConfigFile:sampleRate:context:queue:delegate:
_updateAssetWithLanguage:
_updateAssetWithCurrentLanguage
osdAnalyzer:didUpdateOSDFeatures:
osdAnalyzer:didDetectStartOfSpeechAt:
osdAnalyzer:didDetectEndOfSpeechAt:
apQueue
setApQueue:
didAddAudio
setDidAddAudio:
osdAnalyzer
setOsdAnalyzer:
osdQueue
setOsdQueue:
_didAddAudio
_apQueue
_osdAnalyzer
_osdQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
TB,N,V_didAddAudio
T@"OSDAnalyzer",&,N,V_osdAnalyzer
T@"NSObject<OS_dispatch_queue>",&,N,V_osdQueue
setOpportuneSpeakListeningType:
_opportuneSpeakListeningType
TQ,N,V_opportuneSpeakListeningType
speakAudio:
speakAudio:withScaleFactor:playbackStarted:completion:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setEnableAlwaysOnVoiceTrigger:
setIsConnected:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
Tq,R,N,V_deviceType
T@"NSString",R,N,V_deviceName
T@"NSString",R,N,V_deviceID
T@"NSUUID",R,N,V_deviceUID
T@"NSString",R,N,V_productIdentifier
TB,N,V_isConnected
TB,N,V_enableAlwaysOnVoiceTrigger
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
initFileURLWithPath:isDirectory:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
internalUserClassification
standardUserDefaults
persistentDomainForName:
_deregisterAudioSessionNotifications
contextForRemoraVoiceTriggerWithDeviceId:
sessionForContext:error:
opaqueSessionID
_registerAudioSessionNotifications
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
_setupNNVADEndpointer
_updateAccessibleEndpointerThresholdIfNeed
accessibleEndpointerThreshold
supportCSTwoShotDecision
isWatchRTSTriggered
logEventWithType:machAbsoluteTime:context:
endpointerImplDelegate
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
accessibleEndpointerEnabled
setAccessibleEndpointerEnabled:
_accessibleEndpointerEnabled
_endpointerImplDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
TB,N,V_accessibleEndpointerEnabled
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_endpointerImplDelegate
_attachToSession
_cleanUpDeviceProxies
_detachFromSession
_tearDownAccessoryManager
_setUpAccessoryManager
_deviceProxies
reload
_reloadForDevice:
getDeviceInfo:
addObjectsFromArray:
getUUIDBytes:
_deviceProxyWithAddress:createsIfAbsent:
_deviceProxyWithUID:createsIfAbsent:
initWithAddress:dataSource:queue:
initWithDeviceUID:dataSource:queue:
accessoryManager:event:device:state:
getBTDeviceWithAddress:completion:
getBTDeviceWithDeviceUID:completion:
_session
_accessoryManager
_attachingToSession
_sessionSetupGroup
_deviceProxiesLock
_deviceProxiesByAddress
_deviceProxiesByDeviceUID
_updateDeviceInfo:
_fetchDeviceInfoWithCompletion:
_reload:
_getDeviceInfo:
_accessBTDeviceAndAccessoryManagerUsingBlock:
_invalidate
bluetoothDevice:deviceInfoDidChangeFrom:to:
_enumerateObserversUsingBlock:
setDeviceUID:
mutatedCopyWithMutator:
bluetoothDeviceDidInvalidate:
setRepresentation
identifier
getHeadphoneInEarDetectionState:
getHeadphoneListeningMode:
setHeadphoneListeningMode:completion:
connect:
disconnect:
updateDeviceInfo:
_headphoneInEarDetectionState
_headphoneListeningMode
T@"NSString",R,C,N,V_address
T@"NSUUID",R,C,N,V_deviceUID
setVendorID:
setProductID:
setIsAdvancedAppleAudioDevice:
setSupportsInEarDetection:
setSupportsVoiceTrigger:
setSupportsSpokenNotification:
setSupportsListeningModeANC:
setSupportsListeningModeTransparency:
setSupportsAnnounceCall:
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
_checkFirstUnlocked
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_firstUnlocked
_checkPhraseSpotterEnabled
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
phraseSpotterEnabled
_didReceivePhraseSpotterSettingChangedInQueue:
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
platformSupportsImplcitUttAddition
_sendReplyMessageWithResult:error:event:client:
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:
initWithConnection:
activateConnection
valueForEntitlement:
supportRelayCall
defaultContext
_instanceContext
createMockRemoteDeviceWithName:deviceID:completion:
injectAudio:toDeviceWithUUID:completion:
listMockRemoteDeviecesWithCompletion:
fallBackAssetResourcePath
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithEndpointThreshold:
caesuraSPG
setCaesuraSPG:
endpointThreshold
setEndpointThreshold:
hasReported
setHasReported:
isAnalyzeMode
setIsAnalyzeMode:
lastSilencePosterior
setLastSilencePosterior:
_hasReported
_isAnalyzeMode
_endpointThreshold
_caesuraSPG
_lastSilencePosterior
T@"EARCaesuraSilencePosteriorGenerator",&,N,V_caesuraSPG
Tf,N,V_endpointThreshold
TB,N,V_hasReported
TB,N,V_isAnalyzeMode
Td,N,V_lastSilencePosterior
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
shouldVoiceTriggerRun
_samplesPerInterval
_cleanUpConnection
appendAcousticData:sampleCount:sampleRate:
getSignature:
_connectionInterrupted
_connectionInvalidated
remoteObjectProxyWithErrorHandler:
_configureWithCurrentASBD
_service
_needsConversion
_convertPCMDataForFingerprinting:
acousticFingerprinter:hasFingerprint:duration:
_serviceWithErrorHandler:
setFingerprintInterval:
setASBD:
appendPCMData:
_asxConnection
_totalSampleCount
_nextFingerprintSampleNumber
_sourceASBD
_interval
_fingerprinterConverter
T@"<CSSiriAcousticFingerprinterDelegate>",W,N,V_delegate
dictationLanguages
currentKeyboard
setCurrentDictationLanguage:
wasLanguageToggled
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
conversationalMessages
setRecentMessages:
_wasLanguageToggled
_samplingRate
_dictationLanguages
_currentKeyboard
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_conversationalMessages
Tf,N,V_samplingRate
T@"NSSet",&,N,V_dictationLanguages
T@"NSString",&,N,V_currentKeyboard
TB,N,V_wasLanguageToggled
T@"NSArray",&,N,V_multilingualKeyboardLanguages
T@"NSDictionary",&,N,V_keyboardConvoLanguagePriors
T@"NSDictionary",&,N,V_keyboardGlobalLanguagePriors
T@"NSString",&,N,V_previousMessageLanguage
T@"NSString",&,N,V_globalLastKeyboardUsed
T@"NSDictionary",&,N,V_dictationLanguagePriors
T@"NSArray",&,N,V_conversationalMessages
_speechController
_setEndpointStyle:
_stopRecordingForEndpointReason:
bundleForClass:
URLForResource:withExtension:
_speechControllerWithError:
_currentMHUUID:
logMHAssistantDaemonAudioInitContextWithMHUUID:withInitStarted:
logMHAssistantDaemonAudioConfigureContextWithMHUUID:withConfigureStarted:
_updateRecordBufferDuration
logMHAssistantDaemonAudioPrepareContextWithMHUUID:withPrepareStarted:
_setAudioContextWithInfo:forReason:
_resetSpeechController
_setLanguageDetectorDelegateIfRequired
_cancelExtendedEndpointTimer
logEventWithType:contextProvider:
logMHAssistantDaemonAudioStopRecordingContextWithMHUUID:withStopRecordingStarted:withADStopRecordingEvent:
_shouldEmitInstrumentation
setStopReasonMajor:
setStopReasonMinor:
speechCapturingWillStopRecordingWithSignpostID:
_logFanState
_speechControllerDidStartRecording:successfully:error:
speechCapturingDidStopRecordingWithError:endpointMode:totalPacketCount:endpointerMetrics:
_updateAudioContextToPostVoiceForReason:
limitedAudioLoggingEnabled
enumeratorAtPath:
nextObject
hasSuffix:
_prepareDirectoryAtPath:
_checkAudioLoggingLimits:
linkItemAtURL:toURL:error:
_stopRecordingWithReason:hostTime:
speechCapturingWillStopRecording
logMHAssistantDaemonAudioPrewarmContextWithMHUUID:withPrewarmStarted:
tapToSiriAudioPlaybackRequest
prewarmRequest:completion:
_prepareSpeechControllerWithOptions:error:
isTest
skipPersonalizedASR
preheatLanguage
_updateAudioDeviceInfo:forReason:forcesUpdate:
_recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:
prepareForMode:withOptions:
_setSpeechCapturingMode:
_setEndpointerOperationMode:forceUpdate:
_mhUUIDFromSpeechRequestOptions:
_setAlertsIfNeeded
_currentRecordRoute
_currentPlaybackRoute
_clearEndpointHint
_startAudioPlaybackRequest:options:completion:
initWithItemURL:itemData:numberOfLoops:volume:fadeInDuration:fadeOutDuration:userInfo:
_currentRecordingInfo
logMHAssistantDaemonAudioStartRecordingContextWithMHUUID:withStartRecordingContext:withFanInfoArray:withActiveSessionDisplayIDs:
_playAudioAlert:
_scheduleExtendedEndpointTimer
beginTimestamp
endTimestamp
initWithQueue:delegate:
logMHAssistantDaemonAudioBluetoothInfoWithMHUUID:withWirelessSplitterSessionState:withAudioDeviceCategory:
getStateWithCompletion:
logEventWithType:contextResolver:
_updateAudioContextWithInfo:reason:
recordDeviceIdentifier
_updateAudioContextWithPendingInfoForReason:
suppressInterruptionEndedNotifications
setSuppressInterruptionEndedNotifications:
_logAudioMetrics:mhUUID:
speechCapturingDidUpdateAudioDeviceInfo:
initWithListenerEndpoint:
_currentRecordDeviceInfo
logMHAssistantDaemonAudioFetchRouteContextWithMHUUID:withFetchRouteContextStarted:
_audioDeviceID
_speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:
getAudioRouteInstrumentationWithRecordingInfo:
audioInputRoute
convertSISchemaAudioInputRouteToMHRoute:withRecordingInfo:
hardwareInterfaceVendorID
interfaceVendorID
interfaceProductID
logMHAssistantDaemonAudioRecordingContextWithMHUUID:withAudioRecordingStarted:withAudioInputRoute:withAudioSource:withAudioInterfaceVendorId:withAudioInterfaceProductId:
logMHASRAudioConfigureStartedWithMHUUID:withAudioCodecString:withAudioSkippedNumSamples:
secondsToNs:
logMHASRAudioConfigureStartedWithMHUUID:withAudioCodecString:withAudioSkippedTimeInNs:
_logBluetoothStateWithMHUUID:
_logVoiceTriggerInfo:withMHUUID:
speechCapturingDidUpdateRecordingInfo:
speechCapturingDidStartRecordingSuccessfully:error:withInfo:
_setupAudioFileWritingForSpeechController:info:context:
_speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:
_playStopAlertIfNecessaryForReason:endpointMode:error:
_speechRecordingEventListener
handleSpeechRecordingEvent:
speechCapturing:didFinishWritingAudioFile:error:
logMHAssistantDaemonAudioRecordingMissedBufferDetectedWithMHUUID:
_speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:
speechCapturingDidRecordSpeechPackets:atTimestamp:totalPacketCount:
logEventWithType:machAbsoluteTime:context:contextNoCopy:
hostTimeToNs:
logMHAssistantDaemonAudioLateBufferDetectedWithMHUUID:withBufferReceiptTimeInNs:
logMHAssistantDaemonAudioRecordingFirstBufferWithMHUUID:withStartEvent:withFirstBufferStartTimeOffsetNs:withFirstBufferReceiptTimeOffsetNs:
setInterfaceVendorID:
setInterfaceProductID:
setHardwareInterfaceVendorID:
setAudioInputRoute:
_fingerprinter
speechCapturingDidRecordPCMAudioData:
reportIssueForType:subType:context:processIdentifier:walkboutStatus:
logMHAssistantDaemonAudioRecordingLastBufferWithMHUUID:withStartEvent:withLastBufferStartTimeOffsetNs:withLastBufferReceiptTimeOffsetNs:
speechCapturingDidReceiveLastAudioBufferWithEndpointMode:totalPacketCount:endpointerMetrics:
logMHAssistantDaemonAudioRecordingInterruptionContextWithMHUUID:withStartEvent:withLinkID:withAvAudioSessionInterruptorName:withAVAudioSessionInterrupterType:
logMHAssistantDaemonAudioRecordingInterruptionStartedTier1WithMHUUID:withLinkID:withActiveSessionDisplayIDs:
speechCapturing:willSetAudioSessionActive:
speechCapturing:didSetAudioSessionActive:
didWin
isMonitoring
speechCapturing:didDetectLanguage:confidenceScores:isConfident:
logTwoShotDetectedWithMHUUID:
_performTwoShotPromptForType:atTime:
_speechControllerRequestsOperation:forReason:completion:
speechCapturingDidRequestQuickStop:
speechCapturingDidRequestShutdownUI:
_playPhaticWithCompletion:
performBlockAfterAlerts:timeout:
speechCapturingDidRequestUpdateSiriOutputVolume:
speechCapturing:didDetectStartpointAtTime:
_hardEndpointWasDetectedWithMetrics:atTime:
_checkIfLastEndpointHintShouldBeAccepted:
speechCapturing:didDetectEndpointAtTime:
logTwoShotStartEventWithPromptType:withMHUUID:
logTwoShotEndEventWithSuppresedAlert:withTimedOut:withMHUUID:
twoShotAudioPlaybackRequest
_handleFakeTwoShotPromptTimeoutWithUUID:
_handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:
speechCapturing:performTwoShotPromptWithType:completion:
processedAudioDuration
resultId
latticeRnnMitigatorScore
latticeRnnMitigatorThreshold
speechRecognitionTask
_enforceEndpointHintWithMitigation:
speechCapturing:didReceiveFingerprint:duration:
startRequest:options:completion:
speechCapturingDidProvideConfidenceScores:classification:classifiedUser:unknownUserScore:duration:version:thresholdingType:assetVersion:
speechCapturing:didInterruptAudioSession:
speechCapturing:didLoseAudioSessionOwnerOrMediaServices:
speechControllerDidDetectStartpoint:
speechControllerDidDetectEndpoint:ofType:atTime:
speakerIdentificationDidDetectSpeakerWithScores:
initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:
suspendAutomaticEndpointingInRange:
setSpeechRequestOptions:
setSpeechWasRecognizedForElapsedTime:isFinal:
setFingerprintWasRecognized
stopSpeechCaptureForEvent:suppressAlert:hostTime:
cancelSpeechCaptureSuppressingAlert:
setFingerprintingEnabled:
forceSuccessAudioAlertOnStop
setIsDriving:
getLastStartpointTimestampAndCurrentTime:
playRecordingStartAlert
updateServerEndpointFeatures:
updateEndpointHintForRC:forceAccept:completion:
enforcePreviousEndpointHint
disableSpeechPacketGeneration:
_mapInstrumentationEndpointTypeFromStopRecordingReason:
eagerlyInitializeAudioRecording
preheatWithOption:
preheatRecognizerWithOption:
prepareSpeechCaptureWithOptions:error:
recordingInfoForPreheatWithEvent:
currentVTSatScore
prepareForMode:
startSpeechCaptureWithContext:willStartHandler:error:
updateSpeechSynthesisRecord:
fetchAudioSessionID
fetchRecordingInfo
fetchAudioDeviceInfo
_getFanInfoArray
setAudioFileType:
setAudioFileHandle:
setSpeechRecordingEventListeningEndpoint:
suppressUtteranceGradingIfRequired
setEndpointerThreshold:
setEndpointerDelayedTrigger:
setSpeechRecognizedContext:
setEARLanguageDetectorSpeechRequestId:
_setDictationAudioModeEnabled:
_setAudioDuckingEnabled:
_isSpeechControllerInitialized
_audioPlaybackService
_packetCount
_speechCapturingMode
_recordingAlertsConfiguration
_extendedEndpointTimer
_endpointAnalyzer
_context
_currentActivationInfo
_pendingActivationInfo
_currentAudioDeviceInfo
_fingerprintingEnabled
_audioFileType
_needsAVVCLPCMCallbacks
_hasReceivedEmptyLPCMRecordBuffer
_audioFileHandle
_startEvent
_recordingState
_didReceiveFirstBuffer
_didReceiveLastBuffer
_didDetectStartpoint
_didDetectEndpoint
_didEnterTwoShotMode
_didFakeTwoShotWithAlert
_fakeTwoShotTTSPromptUUID
_serverDidRecognizeSpeech
_fingerprintWasRecognized
_serverDidEndpoint
_didTimeout
_wasCanceled
_suppressRecordingStoppedAlert
_isRecordingUsingBTRoute
_twoShotStartTime
_didPerformTwoShotPrompt
_forceSuccessAlertOnStop
_isDriving
_shouldDisableSpeechPacketGeneration
_lastPrepareTimestamp
_accumulatedBufferDuration
_decoder
_expectedFirstBufferTimestamp
_recordDevice
_audioDuckingEnabled
_speechRecordingEventListenerConnection
_fakeTwoShotTTSPromptWatchdogTimer
_lastAudioRecordBufferStartTime
_lastAudioRecordBufferReceiptTime
_lastEndpointerMetrics
_endpointDelayReporter
_lastEndpointHintFeatures
_lastEndpointHintCompletion
_lastEndpointHintRC
_lastEndpointHintRCProcessedForMitigation
_mostRecentSpeechSynthesisRecord
_alertPlaybackGroup
_numberOfAVVCAlertPlaybacksByType
_bluetoothWirelessSplitterSessionStateObserver
_mhUUID
_suppressInterruptionEndedNotifications
TB,N,V_suppressInterruptionEndedNotifications
initWithAudioSessionController:
initWithOptions:capacity:
_startRequest:options:preparationHandler:executionHandler:finalizationHandler:
_prewarmRequest:completion:
startRequest:options:preparationHandler:executionHandler:finalizationHandler:
_stopRequest:immediately:
_stopAllRequests:completion:
_stopAllRequestsSynchronously
_createAudioPlaybackSessionWithRequest:options:
_handlePreparationForSession:
_handleExecutionForSession:
_handleFinalizationForSession:error:
audioPlaybackService:willStartRequest:
_enumerateListenersUsingBlock:
audioPlaybackService:didStartRequest:
audioPlaybackService:didStopRequest:error:
removeListener:
_setAudioSessionID:
_evictAllReusableSessionsForReason:
memoryPressureObserver:didChangeFromCondition:toCondition:
stopRequest:immediately:
stopAllRequests:completion:
stopAllRequestsSynchronously
removeAllListeners
_listeners
_activeSessionsByRequest
_reusableSessionsByRequest
initWithConfigFile:samplingRate:queue:
configFile
setConfigFile:
startDetected
setStartDetected:
minSpeechFrames
setMinSpeechFrames:
curSpeechFrames
setCurSpeechFrames:
numLeadingFrames
setNumLeadingFrames:
prevAudioProcessedMs
setPrevAudioProcessedMs:
spgQueue
setSpgQueue:
sosQueue
setSosQueue:
_startDetected
_prevAudioProcessedMs
_configFile
_minSpeechFrames
_curSpeechFrames
_numLeadingFrames
_spgQueue
_sosQueue
T@"NSString",&,N,V_configFile
TB,N,V_startDetected
TQ,N,V_minSpeechFrames
TQ,N,V_curSpeechFrames
TQ,N,V_numLeadingFrames
Tf,N,V_prevAudioProcessedMs
TQ,N,V_samplingRate
T@"NSObject<OS_dispatch_queue>",&,N,V_spgQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sosQueue
T@"<CSStartOfSpeechDetectorDelegate>",W,N,V_delegate
_didReceiveMediaserverNotification:
setServerCrashedBlock:
setServerResetBlock:
_notifyObserver:withMediaserverState:
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
serverState
setServerState:
_serverState
TQ,N,V_serverState
T@"<CSVoiceTriggerXPCClientDelegate>",W,N,V_delegate
registerXPCActivities
powerLoggingCurrentLanguage
powerLoggingCurrentAssetConfigVersion
powerLogSiriConfigWithVoiceTriggerEnabled:withLanguage:withModelVersion:
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
notifyDaemonStateChanged:
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_startObservingSpeechDetectionVADPresence
handleSpeechDetectionVADPresentChange:
setSiriLanguageCodeDarwin:
_didReceiveLanguageCodeUpdate:
isMitigationAssetOverridingEnabled
fakeMitigationAssetPath
initWithAssetManager:withTrialAssetManager:withTrialDownloadMonitor:withVTAssetHandler:withAssetOverrideFlag:withOverrideAssetPath:
assetProvider
_receivedNewAssetUpdate:
getMitigationAssetWithEndpointId:completion:
trialDownloadMonitor
setTrialDownloadMonitor:
vtAssetHandler
setVtAssetHandler:
overrideEnabled
setOverrideEnabled:
overridePath
setOverridePath:
_overrideEnabled
_trialDownloadMonitor
_vtAssetHandler
_overridePath
T@"CSTrialAssetDownloadMonitor",&,N,V_trialDownloadMonitor
T@"CSVoiceTriggerAssetHandler",&,N,V_vtAssetHandler
TB,N,V_overrideEnabled
T@"NSString",&,N,V_overridePath
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:remoteDeviceUIDString:
isRemoteDevice
remoteProductIdentifier
initWithAVVCRecordDeviceInfo:
remoteDeviceProductIdentifier
_isRemoteDevice
_remoteDeviceUID
_remoteDeviceProductIdentifier
_remoteDeviceUIDString
T@"NSString",R,C,N,V_remoteDeviceUIDString
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
listener
opusNarrowBandASBD
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:
replaceBytesInRange:withBytes:length:
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_lastArrivalTimestampToAudioRecorder
_outPacketSizeInSec
T@"<CSAudioConverterDelegate>",W,V_delegate
_isBuiltInDeviceFromDeviceId:
isDarwinVoiceTriggered
fetchDeviceUUIDStringFromUID:
getMachTimeAdjustedVoiceTriggerEventInfoForDeviceUUID:
fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:
rtsTriggerInfo
setRtsTriggerInfo:
triggerNotifiedMachTime
setTriggerNotifiedMachTime:
_accessoryVoiceTriggerEvents
_builtInVoiceTriggerEvent
_rtsTriggerInfo
_triggerNotifiedMachTime
T@"NSDictionary",C,N,V_rtsTriggerInfo
TQ,N,V_triggerNotifiedMachTime
subdataWithRange:
splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:
rawMicChannelsDataWithNumSamplesPerChannel:
strRepForFloatData
enableProgrammableAudioInjection:
getAudioInjectionXPCConnection
injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:
setAudioInjectionMode:
injectAudio:toDeviceWithUUID:withNumChannels:completion:
deviceConnectedWithUUID:
deviceDisconnectedWithUUID:
allDeviceDisconnected
notifyVoiceTriggerEnabledWithDeviceUUID:
notifyVoiceTriggerDisabledWithDeviceUUID:
hasDarwinDeviceHandleVoiceTrigger
isRemoteDarwinConnectedWithUUID:
fetchRichDeviceUIDStringFromUUID:
isPrimaryVoiceTriggerDeviceWithUUID:
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
timestamp
_droppingPrediction
_droppedPrediction
_timestamp
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
isRecordContextBuiltInVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextDarwinVoiceTrigger:
isRecordContextRemoraVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextAutoPrompt:
isRecordContextVoiceTrigger:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextJarvisButtonPress:
isValidRecordContext:
recordContextString:
activationMode
activationDeviceUID
announceCallsEnabled
streamID
startHostTime
startAlert
stopAlert
stopOnErrorAlert
skipAlert
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
remoteVoiceActivityVADBuffer
_voiceControllerWithError:
initWithBackingStoreCapacity:minimalNumberOfBackingStores:maximumNumberOfBackingStores:backingStoreIdleTimeout:
initWithConfiguration:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
setRecordDelegate:
initWithError:
setAnnounceCallsEnabledForStream:enable:
setContext:streamType:error:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
_fetchRemoteRecordClientWithDeviceId:streamHandleId:
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_trackRemoteAccessoryStreamIdIfNeeded:
_logResourceNotAvailableErrorIfNeeded:
_shouldInjectAudio
_needResetAudioInjectionIndex:
audioInjectionFilePath
_hasLocalPendingTwoShot
playAlertSoundForType:overrideMode:
_startAudioStreamForAudioInjectionWithAVVCContext:
startRecordForStream:error:
stopRecordForStream:error:
getCurrentSessionState
getCurrentStreamState:
isRemoteDeviceGibraltar
isRemoteDeviceDarwin
getRecordDeviceInfoForStream:
outputs
endpointType
getRecordSettingsForStream:
isUpsamplingSourceAudio
activateAudioSessionForStream:isPrewarm:error:
_shouldLogResourceNotAvailableError
activateAudioSessionForStream:isPrewarm:recordMode:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
deactivateAudioSessionForStream:withOptions:error:
setIAmTheAssistant:error:
setAllowMixableAudioWhileRecording:error:
enableSmartRoutingConsiderationForStream:enable:error:
initWithDuckOthers:duckToLevel:mixWithOthers:
setIsBlur:
setDuckOverride:
setDuckOthersForStream:withSettings:error:
setDuckToLevelDB:error:
_updateLanguageCodeForRemoteVTEIResult:
isDuckingSupportedOnPickedRouteForStream:error:
_audioIsFromRemoteAccessory:
channels
packetDescriptionCount
bytesDataSize
packetDescriptions
updateMeterForStream:
getPeakPowerForStream:forChannel:
getAveragePowerForStream:forChannel:
setPeakPower:
setAvgPower:
streamDescription
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
setAlertSoundFromURL:forType:
_stopTrackingRemoteAccessoryStreamId:
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_audioRecorderDidStopRecordingForReason:streamHandleID:
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
remoteRecordDidStartRecordingWithStreamHandleId:error:
remoteRecordDidStopRecordingWithWithStreamHandleId:error:
remoteRecordLPCMBufferAvailable:streamHandleId:
remoteRecordTwoShotDetectedAtTime:
remoteRecordConnectionDisconnected:
userSessionActivateMonitor:didReceivedUserSessionActiveHasChanged:
_shouldUseRemoteBuiltInMic:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
remoteAccessoryStreamIdSet
setRemoteAccessoryStreamIdSet:
_voiceController
_interleavedABL
_remoteRecordClient
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_audioBufferPool
_hasSetAlertDictionary
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
_remoteAccessoryStreamIdSet
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
T@"NSMutableSet",&,N,V_remoteAccessoryStreamIdSet
notifyDidStartStreamWithContext:successfully:option:
initWithSharedSiriId:languageCode:productCategory:version:sharedHomeId:userName:
setProfileId:
setLanguageCode:
productCategory
setProductCategory:
setVersion:
onboardType
setOnboardType:
setHomeId:
setUserName:
_profileId
_languageCode
_productCategory
_onboardType
_homeId
_userName
T@"NSString",&,N,V_profileId
T@"NSString",&,N,V_languageCode
T@"NSString",&,N,V_productCategory
T@"NSNumber",&,N,V_version
TQ,N,V_onboardType
T@"NSString",&,N,V_homeId
T@"NSString",&,N,V_userName
setVoiceTriggerInfo:
setRequestHistoricalAudio:
setReqStartAudioSampleId:
reqStartMachAbsTime
setReqStartMachAbsTime:
shouldLogRawSensorData
setShouldLogRawSensorData:
rootLogDir
setRootLogDir:
_requestHistoricalAudio
_shouldLogRawSensorData
_reqStartAudioSampleId
_reqStartMachAbsTime
_rootLogDir
T@"NSDictionary",&,N,V_voiceTriggerInfo
TB,N,V_requestHistoricalAudio
TQ,N,V_reqStartAudioSampleId
TQ,N,V_reqStartMachAbsTime
TB,N,V_shouldLogRawSensorData
T@"NSString",&,N,V_rootLogDir
triggerModeStringDescription:
getTriggerMode
_notifyStopOpportuneSpeakWithDelay:
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_token
TB,N,V_isOpportuneSpeakListening
T@"NSString",&,N,V_audioProviderUUID
T@"NSUUID",&,N,V_token
decodeInt64ForKey:
encodeInt64:forKey:
setSigType:
setSigGenTs:
_sigType
_sigGenTs
TQ,N,V_sigType
TQ,N,V_sigGenTs
isSiriRestrictedOnLockScreen
@24@0:8@16
@16@0:8
v24@0:8@16
v16@0:8
B16@0:8
Q16@0:8
v24@0:8Q16
v20@0:8B16
@"NSMutableArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v44@0:8@16Q24B32@36
v40@0:8@16Q24Q32
v56@0:8@16Q24@32@40Q48
v32@0:8@16@24
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@24@0:8Q16
B44@0:8@16f24@?28@?36
q24@0:8@16
@"NSObject<OS_dispatch_queue>"
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSAudioCircularBuffer"
@"NSUUID"
@"CSAudioInjectionDevice"
v32@0:8@16Q24
v32@0:8@"NSStream"16Q24
@32@0:8@16@24
@"NSOutputStream"
v32@0:8Q16@24
v32@0:8@16q24
v40@0:8@16q24Q32
v48@0:8@16q24q32Q40
v36@0:8@16q24i32
v44@0:8@16q24i32Q36
v32@0:8@"CMWakeGestureManager"16q24
v40@0:8@"CMWakeGestureManager"16q24Q32
v48@0:8@"CMWakeGestureManager"16q24q32Q40
v36@0:8@"CMWakeGestureManager"16q24i32
v44@0:8@"CMWakeGestureManager"16q24i32Q36
@"CMWakeGestureManager"
v32@0:8@16@?24
@"NSHashTable"
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
v28@0:8@16B24
v28@0:8@"CSXPCClient"16B24
v32@0:8@"CSCoreSpeechDaemonStateMonitor"16Q24
v24@0:8@?16
I16@0:8
@"<CSAudioSessionInfoProviding>"
@"CSXPCClient"
f16@0:8
q16@0:8
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
@"NSURL"
^{OpaqueExtAudioFile=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSString"
Q40@0:8@16@24@32
v24@0:8@"CSAttSiriRequestContext"16
v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16
@"<CSAttSiriServiceDelegate>"
@"NSXPCConnection"
v24@0:8q16
B32@0:8^B16^Q24
Q24@0:8Q16
@"<CSBiometricMatchMonitorDelegate>"
v20@0:8f16
v40@0:8@16@24@?32
v60@0:8@16@24Q32@40B48@?52
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSDictionary"16
v24@0:8@"NSData"16
v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40B48@?<v@?>52
v40@0:8Q16@24d32
v40@0:8Q16@"NSString"24d32
v32@0:8Q16@"NSString"24
@?16@0:8
@"<CSVoiceTriggerDelegate>"
@"<CSSecondPassProgressProviding>"
@"NSDictionary"
@"CSPreMyriadVoiceTriggerMetaData"
@"NSMutableDictionary"
@"CSKeywordAnalyzerNDAPI"
i16@0:8
d16@0:8
@40@0:8@16@24@32
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"CSAudioRecordDeviceInfo"
@"NSArray"
@"CSSSRXPCClient"
@"<CSSpeakerRecognitionProxyProtocol>"
v28@0:8@"CSVoiceTriggerXPCClient"16B24
v36@0:8B16@20@28
v28@0:8B16@20
v36@0:8B16d20@28
v28@0:8B16d20
@"CSVoiceTriggerXPCClient"
r*16@0:8
v40@0:8@16@24Q32
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@24@0:8f16i20
v32@0:8f16B20@24
B20@0:8f16
v20@0:8i16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
v48@0:8@16@24@32@?40
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
@"NSObject<OS_dispatch_group>"
^{__IOHIDUserDevice=}
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v52@0:8@16B24@28@36@44
v40@0:8@16Q24@32
v48@0:8@16Q24@32@40
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@24@0:8d16
B24@0:8d16
@20@0:8I16
@"NSObject<OS_dispatch_source>"
@"<CSAudioFileReaderDelegate>"
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
@"<CSLanguageDetectorAssetMonitorDelegate>"
v32@0:8@16d24
v24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
@28@0:8@16i24
@"CSAudioRecordContext"
@"CSSiriRecordingInfo"
@"CSSiriAudioFileWriter"
@"<AFRelinquishableAssertion>"
@"NSMutableSet"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
@32@0:8Q16@24
@"<CSSmartSiriVolumeClientDelegate>"
B40@0:8@16Q24^@32
B40@0:8@16@24^@32
B32@0:8@16^@24
f24@0:8Q16
B24@0:8Q16
B32@0:8Q16^@24
B40@0:8Q16Q24^@32
B40@0:8q16Q24^@32
B36@0:8@16q24B32
B32@0:8q16@24
@"CSAudioInjectionEngine"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
v36@0:8@16d24f32
v36@0:8@"CSSPGEndpointAnalyzer"16d24f32
v24@0:8@"CSSPGEndpointAnalyzer"16
v28@0:8B16@?20
@"<CSOpportuneSpeakListenerDelegate>"
@"CSAudioStream"
@"CSSPGEndpointAnalyzer"
@"<CSAudioStreamProviding>"
@"<CSAudioSessionProviding>"
@"CSPlainAudioFileWriter"
@"CSAudioTimeConverter"
v64@0:8@16@24@32@40@48@?56
@"NSObject<OS_xpc_object>"
@32@0:8d16Q24
v24@0:8d16
d24@0:8[80s]16
@"NSMutableData"
v28@0:8Q16B24
v36@0:8@16Q24B32
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v48@0:8@16@24f32i36@?40
v32@0:8@"NSString"16@?<v@?@"NSString">24
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v48@0:8@"NSURL"16@"NSUUID"24f32i36@?<v@?B@"NSError"QQ>40
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
v24@0:8@"NSString"16
v32@0:8d16@?24
v36@0:8Q16Q24B32
v32@0:8Q16@"CSAudioRecordContext"24
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8d16@?<v@?B@"NSArray">24
v32@0:8@"NSString"16@"NSString"24
v32@0:8@"OSDFeatures"16d24
v32@0:8@"NSDate"16Q24
v28@0:8@"CSServerEndpointFeatures"16B24
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
v32@0:8@"_EARLanguageDetector"16@"_EARLanguageDetectorLoggingInfo"24
v32@0:8@"_EARLanguageDetector"16@"NSDictionary"24
v32@0:8@"_EARLanguageDetector"16@"_EARLanguageDetectorResult"24
v32@0:8@"CSStartOfSpeechDetector"16Q24
v28@0:8@16f24
@"<CSLanguageDetectorDelegate>"
@"_EARLanguageDetector"
@"_EARLanguageDetectorAudioBuffer"
@"CSStartOfSpeechDetector"
@"CSAsset"
@40@0:8Q16Q24d32
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
v40@0:8Q16Q24Q32
v44@0:8@16@24B32@36
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
v24@0:8@"CSAudioServerCrashMonitor"16
@"AVVoiceTriggerClient"
@36@0:8q16@?24I32
@36@0:8q16@24I32
@44@0:8q16@?24@32I40
@"NSFileHandle"
@"NSError"
v64@0:8Q16Q24q32@40@48@?56
v72@0:8Q16Q24q32@40@48@56@?64
v56@0:8Q16Q24@32@40@?48
v20@0:8I16
v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v68@0:8@16Q24@32@40Q48Q56i64
v40@0:8@16Q24q32
v40@0:8@16q24@32
v68@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v32@0:8@"CSAudioRecorder"16@"NSError"24
v32@0:8@"CSAudioProvider"16Q24
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
@32@0:8@16^@24
@24@0:8^@16
@"CSAudioRecorder"
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
@"CSSmartSiriVolumeManager"
v32@0:8Q16Q24
@"<CSCommandControlListenerDelegate>"
v32@0:8@"CSAssetController"16Q24
v32@0:8@16@"NSString"24
v32@0:8Q16@?24
v48@0:8Q16@24Q32@?40
v48@0:8Q16Q24@32@?40
@"CSPolicy"
@"CSAssetDownloadingOption"
v72@0:8q16q24d32@40d48@56q64
v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64
v24@0:8@?<v@?@"NSError"@"NSString">16
v24@0:8@?<v@?@"NSError"d>16
v24@0:8@?<v@?@"NSError"Q>16
v32@0:8d16@24
v32@0:8d16@"CSEndpointerMetrics"24
v48@0:8Q16@24@32@40
@32@0:8@"<NviDataSource>"16@"<NviAssetsProvider>"24
v24@0:8@"<NviSignalProviderDelegate>"16
v32@0:8@"NviContext"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError">16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@?<v@?@>16
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
@"NSXPCListener"
@"NSXPCInterface"
@32@0:8Q16Q24
@"NSNumber"
v52@0:8@16@24f32Q36Q44
v52@0:8@"CSAudioConverter"16@"NSArray"24f32Q36Q44
v32@0:8@"CSSmartSiriVolumeController"16Q24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v32@0:8@"CSAudioSessionController"16@"NSDictionary"24
v72@0:8@16Q24@32@40Q48Q56B64I68
v72@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48Q56B64I68
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v40@0:8@"<CSEndpointAnalyzerImpl>"16Q24Q32
v48@0:8@16q24q32@40
v32@0:8@16B24B28
v48@0:8@"SOMediaNowPlayingObserver"16q24q32@"NSDate"40
v24@0:8@"SOMediaNowPlayingObserver"16
v32@0:8@"SOMediaNowPlayingObserver"16B24B28
v32@0:8@"SOClockAlarmObserver"16@"NSUUID"24
v40@0:8@"SOClockAlarmObserver"16@"AFClockAlarmSnapshot"24@"AFClockAlarmSnapshot"32
v32@0:8@"SOClockTimerObserver"16@"NSUUID"24
v40@0:8@"SOClockTimerObserver"16@"AFClockTimerSnapshot"24@"AFClockTimerSnapshot"32
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
v32@0:8@"CSContinuousVoiceTrigger"16@"NSDictionary"24
v32@0:8@"CSContinuousVoiceTrigger"16d24
@116@0:8@16@24@32@40@48@56@64@72@80@88B96B100B104B108B112
B44@0:8Q16d24B32^@36
v56@0:8d16Q24@32@?40@?48
B24@0:8^@16
B24@0:8B16B20
B24@0:8q16
v68@0:8Q16d24d32d40@48B56@?60
v24@0:8B16B20
@"CSAudioConverter"
@"<CSSpeechControllerDelegate>"
@"<CSSpeakerIdentificationDelegate>"
@"CSEndpointerProxy"
@"<CSAudioAlertProviding>"
@"<CSAudioMeterProviding>"
@"<CSAudioMetricProviding>"
@"CSSelectiveChannelAudioFileWriter"
@"CSSmartSiriVolumeController"
@"CSSpeechEndHostTimeEstimator"
@"CSLanguageDetector"
@"CSXPCClientFactory"
@"CSAudioPowerMeter"
@"CSStopRecordingOptions"
@"SOMediaNowPlayingObserver"
@"SOClockAlarmObserver"
@"SOClockTimerObserver"
@"CSVolumeMonitor"
@"CSAudioDeviceInfo"
@"CSAudioSessionController"
@"CSSACInfoMonitor"
@"CSRCHandlingXPCClient"
@"CSUncompressedAudioLogging"
@"<CSSSRXPCClientDelegate>"
@"CSAttSiriRequestContext"
@48@0:8q16Q24Q32@40
@40@0:8Q16Q24@32
@24@0:8q16
@40@0:8@16@24Q32
v56@0:8Q16@24@?32@?40@?48
@40@0:8@"NSObject<OS_dispatch_queue>"16@"AFAudioPlaybackRequest"24Q32
v40@0:8Q16@"AVAudioSession"24@?<v@?@"NSError">32
v56@0:8Q16@"AVAudioSession"24@?<v@?>32@?<v@?>40@?<v@?@"NSError">48
v28@0:8B16@?<v@?>20
@"AFAudioPlaybackRequest"16@0:8
@"AVPlayer"
@"AVPlayerItem"
@"AVAudioSession"
@"AFAudioPlaybackRequest"
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
v36@0:8@16B24@?28
v96@0:8@16@24@32@40Q48@56@64@72@80@?88
v24@0:8@"CSRemoteAssetManager"16
q24@0:8q16
v48@0:8@16@24B32B36@?40
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v32@0:8@"NSURL"16@?<v@?@"NSError">24
v36@0:8@"NSString"16B24@?<v@?@"NSDictionary"@"NSError">28
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?@"NSDictionary"@"NSError">32
v96@0:8@"NSString"16@"NSDictionary"24@"NSString"32@"NSString"40Q48@"NSArray"56@"NSString"64@"NSString"72@"NSArray"80@?<v@?@"NSArray"@"NSError">88
@"<NviAssetsProvider>"
@"NSMapTable"
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
@40@0:8@16@24^@32
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@32
@32@0:8@16d24
v28@0:8B16Q20
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStream"24@?<v@?B@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"40@0:8Q16Q24Q32
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"CSAudioDeviceInfo"16@0:8
@"NSDictionary"16@0:8
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B36@0:8@"NSURL"16q24B32
I24@0:8@16
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
I24@0:8@"NSString"16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
v40@0:8q16q24q32
v32@0:8q16q24
@"<CSStateMachineDelegate>"
v32@0:8i16@20B28
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@"CSVolumeMonitor"16f24
v28@0:8@"CSAutomaticVolumeEnabledMonitor"16B24
@28@0:8f16@20
@40@0:8Q16@24Q32
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
@36@0:8@16f24Q28
@32@0:8@16Q24
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
d20@0:8f16
v48@0:8Q16@24@32@?40
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
v40@0:8q16Q24@32
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@28@0:8@16I24
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"<CSVoiceTriggerAssetChangeDelegate>"
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
v32@0:8r^v16q24
v44@0:8@16B24@28@36
v28@0:8@"CSFirstUnlockMonitor"16B24
@64@0:8@16@24@32@40@48@56
@"CSVoiceTriggerAssetDownloadMonitor"
@"CSLanguageCodeUpdateMonitor"
@"CSFirstUnlockMonitor"
@"CSAssetManager"
@"CSTrialAssetManager"
v52@0:8@16@24B32@36@44
v36@0:8@16@24B32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v36@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStream"24B32
v24@0:8@"CSSiriClientBehaviorMonitor"16
@28@0:8Q16B24
@28@0:8@16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
@40@0:8q16@24@32
q32@0:8q16@24
q36@0:8@16B24@28
@44@0:8@16@24@32B40
q40@0:8@16@24@32
q32@0:8@16@24
q44@0:8@16@24B32q36
@"AFClientConfiguration"
@"AFExperimentContext"
@"AFSpeechRecordingAlertPolicy"
@"AFLanguageDetectionUserContext"
Q24@0:8@16
d24@0:8@16
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
B40@0:8Q16@24^@32
@"AVAudioPlayer"
v36@0:8B16@20d28
@"CSSiriAssertionMonitor"
@"NSData"
v68@0:8Q16d24d32d40@"NSString"48B56@?<v@?BB@"NSArray">60
v32@0:8Q16@?<v@?B>24
@"<CSSmartSiriVolumeControllerDelegate>"
@"CSSmartSiriVolumeClient"
v40@0:8@"CSKeywordAnalyzerNDEAPI"16@"CSKeywordAnalyzerNDEAPIResult"24Q32
@60@0:8@16@24Q32Q40@48B56
@"<CSPhraseNDEAPIScorerDelegate>"
@"CSShadowMicScoreCreator"
v44@0:8@16@24B32@?36
v72@0:8@16@24@32B40Q44@52B60@64
@80@0:8@16@24@32B40Q44@52B60@64@?72
@"<CSADCompanionServiceProvider>"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@44@0:8Q16Q24f32f36f40
@72@0:8d16Q24@32q40@48@56d64
v32@0:8@"CSMediaPlayingMonitor"16q24
@28@0:8f16@"CSAsset"20
v24@0:8@"CSAsset"16
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="__value_"^{SmartSiriVolume}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSUserDefaults"
v48@0:8@16@24@32^v40
@144@0:8B16B20B24q28@36@44@52@60I68I72@76d84d92d100Q108Q116@124B132q136
@28@0:8B16@20
@"<AFBluetoothDevice>"
@68@0:8Q16@24@32@40@48B56@60
@"CSVoiceTriggerFirstPassMetrics"
v72@0:8d16Q24@32d40Q48d56@64
@"OSDFeatures"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v24@0:8@"<NviDataReceiver>"16
@"NviContext"
@32@0:8q16Q24
@"CSSiriMobileBluetoothDeviceDataSource"
v24@0:8@"CSAssetManager"16
v48@0:8@"NSString"16@"NSString"24@"NSURL"32@?<v@?@"NSString">40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
v80@0:8Q16Q24q32@40@48@56@64@?72
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v80@0:8Q16Q24q32@"NSString"40@"NSUUID"48@"NSArray"56@"NSArray"64@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">72
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
B32@0:8@16@?24
B20@0:8B16
v28@0:8@16i24
v28@0:8@"AFNotifyObserver"16i24
v40@0:8@"AFNotifyObserver"16Q24Q32
@"<CSAttSiriSessionStateDelegate>"
@"AFNotifyObserver"
Vv24@0:8@?16
Vv32@0:8@16@?24
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv32@0:8@"NSString"16@?<v@?@"NSString">24
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@44@0:8@16@24B32Q36
v48@0:8@16d24d32@?40
@48@0:8@16d24d32@?40
@"AFHeartBeat"
@28@0:8f16i20f24
v32@0:8r^v16Q24
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned char>, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned char> *, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__value_"^v}}
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
@"CSSiriAudioRoute"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
@"CSActivationEvent"
v64@0:8@16Q24Q32@40@48@?56
v72@0:8Q16Q24@32@40@48@56@?64
@"CoreSpeechXPCFakeModelMonitor"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
v24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
v52@0:8@16@24Q32Q40i48
v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40i48
@56@0:8Q16q24@32@40@48
@48@0:8Q16q24@32@40
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"CSAudioRecordDeviceIndicator"
@"CSMicUsageReporter"
@"CSADPPreventStandbyAssertion"
@"CSPhoneCallStateMonitor"
@56@0:8Q16@24@32@40Q48
I24@0:8Q16
v32@0:8@"OSDAnalyzer"16@"OSDFeatures"24
v32@0:8@"OSDAnalyzer"16d24
@"OSDAnalyzer"
@48@0:8q16@24@32@40
v40@0:8@16d24@32
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
@"<CSEndpointAnalyzerImpl>"
v40@0:8^{BTAccessoryManagerImpl=}16i24^{BTDeviceImpl=}28i36
v24@0:8^{BTDeviceImpl=}16
^{BTAccessoryManagerImpl=}
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
v32@0:8q16@?24
@"AFBluetoothDeviceInfo"16@0:8
v24@0:8@?<v@?@"AFBluetoothDeviceInfo">16
v24@0:8@?<v@?@"AFBluetoothHeadphoneInEarDetectionState">16
v24@0:8@?<v@?q>16
v32@0:8q16@?<v@?@"NSError">24
v24@0:8@"<AFBluetoothDeviceObserver>"16
@"AFBluetoothDeviceInfo"
@"AFBluetoothHeadphoneInEarDetectionState"
v44@0:8B16@20@28@36
@"AFInstanceContext"
v40@0:8@"NSString"16@"NSString"24@?<v@?B@"NSError"@"NSUUID">32
v40@0:8@"NSURL"16@"NSUUID"24@?<v@?B@"NSError"QQ>32
v24@0:8@?<v@?@"NSMutableArray">16
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
@20@0:8f16
@"<CSSPGEndpointAnalyzerDelegate>"
@"EARCaesuraSilencePosteriorGenerator"
Vv20@0:8i16
Vv32@0:8@16i24i28
Vv32@0:8@"NSData"16i24i28
Vv24@0:8@?<v@?@"NSData">16
v24@0:8^{AudioStreamBasicDescription=dIIIIIIII}16
@"<CSSiriAcousticFingerprinterDelegate>"
@"NSSet"
v40@0:8@16@24d32
v40@0:8@"CSSiriAcousticFingerprinter"16@"NSData"24d32
v44@0:8@16@24f32Q36
v52@0:8@16@24f32Q36@44
v36@0:8@16d24B32
v36@0:8@16B24@28
v48@0:8@16@24q32Q40
v40@0:8@16q24d32
v40@0:8Q16Q24@?32
v32@0:8@"CSSpeechController"16@"NSData"24
v40@0:8@"CSSpeechController"16@"NSData"24Q32
v44@0:8@"CSSpeechController"16@"NSArray"24f32Q36
v52@0:8@"CSSpeechController"16@"NSArray"24f32Q36@"CSAudioDeviceInfo"44
v32@0:8@"CSSpeechController"16d24
v36@0:8@"CSSpeechController"16d24B32
v36@0:8@"CSSpeechController"16B24@"NSError"28
v44@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24B32@"NSError"36
v40@0:8@"CSSpeechController"16q24Q32
v48@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24q32Q40
v24@0:8@"CSSpeechController"16
v40@0:8@"CSSpeechController"16q24d32
v32@0:8@"CSSpeechController"16q24
v32@0:8@"CSSpeechController"16Q24
v40@0:8@"CSSpeechController"16q24@"NSError"32
v32@0:8@"CSSpeechController"16@"NSDictionary"24
v28@0:8@"CSSpeechController"16B24
v40@0:8Q16Q24@?<v@?@"NSError">32
v36@0:8@"NSString"16@"NSDictionary"24B32
v32@0:8{AFTimeRange=dd}16
v28@0:8d16B24
v36@0:8q16B24Q28
@56@0:8@"NSObject<OS_dispatch_queue>"16@"CSSpeechController"24@"CSAudioSessionController"32@"CSSiriAudioPlaybackService"40@"AFExperimentContext"48
v24@0:8@"<CSSiriSpeechCapturingDelegate>"16
v24@0:8@"AFSpeechRequestOptions"16
v24@0:8@?<v@?dd>16
v36@0:8@"SASResultCandidate"16B24@?<v@?BB@"NSArray">28
@20@0:8B16
v28@0:8q16B24
v28@0:8(?={?=SS}I)16Q20
i20@0:8(?={?=SS}I)16
v20@0:8(?={?=SS}I)16
v32@0:8q16@24
B40@0:8@16@?24^@32
@40@0:8q16q24B32B36
v64@0:8@16@24q32Q40q48@56
i28@0:8i16@20
v44@0:8@16q24Q32B40
v40@0:8q16q24@32
v32@0:8q16d24
v48@0:8@16d24d32@40
v32@0:8@?16d24
B40@0:8@16Q24@?32
@"<CSSiriSpeechCapturingDelegate>"
@"CSSpeechController"
@"CSSiriAudioPlaybackService"
@"<CSEndpointAnalyzer>"
@"CSSiriSpeechRecordingContext"
@"CSSiriAudioActivationInfo"
@"CSSiriAcousticFingerprinter"
@"AFWatchdogTimer"
@"CSEndpointerMetrics"
@"CSEndpointDelayReporter"
@"SASResultCandidate"
@"AFSpeechSynthesisRecord"
@"AFBluetoothWirelessSplitterSessionStateObserver"
v40@0:8@16q24q32
v40@0:8@"AFMemoryPressureObserver"16q24q32
v32@0:8@"AFAudioPlaybackRequest"16@?<v@?@"NSError">24
v40@0:8@"AFAudioPlaybackRequest"16Q24@?<v@?@"NSError">32
v28@0:8@"AFAudioPlaybackRequest"16B24
v56@0:8@16Q24@?32@?40@?48
@56@0:8@16Q24Q32Q40@48
@"<CSStartOfSpeechDetectorDelegate>"
@"<CSVoiceTriggerXPCClientDelegate>"
@60@0:8@16@24@32@40B48@52
@"CSVoiceTriggerAssetHandler"
@44@0:8@16B24@28@36
@52@0:8@16B24@28@36@44
v32@0:8@16B24f28
v28@0:8@"CSOpportuneSpeakListener"16B24
v32@0:8@"CSOpportuneSpeakListener"16B24f28
@"CSOpportuneSpeakListener"
v44@0:8@16B24Q28Q36
@"<CSAudioConverterDelegate>"
v48@0:8@16@24^@32^@40
v48@0:8Q16Q24Q32@?40
v48@0:8@16@24Q32@?40
@40@0:8d16d24d32
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v32@0:8Q16@"NSError"24
v32@0:8@"NSData"16Q24
v24@0:8@"CSRemoteRecordClient"16
v28@0:8@"CSUserSessionActiveMonitor"16B24
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
v40@0:8Q16B24@28B36
v60@0:8@16Q24@32Q40Q48i56
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"CSReusableBufferPool"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
v48@0:8@16@24@32@40
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
xeps
supo
supo
mcpl
33s@
333?
fff?
333?
333333
333333
333333
ffffff
?(knN
@mcpl
frmaEVAWffac
fff?
mcpl,
!$'*-
<<<9
++++++L
@mcpl
mcpl
mcplsupoxeps
Median
+[CSUtils(Statistics) distributionDictionary:]
average:
stddev:
q24@?0@8@16
v8@?0
-[CSGestureMonitor isTriggerHandheld]
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
CSAudioInjectionBuiltInEngine
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
-[CSAudioInjectionBuiltInEngine audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:]_block_invoke
trigger-time
-[NviDataLogger logData:]
-[NviDataLogger stream:handleEvent:]
CSMicUsageReporter
-[CSMicUsageReporter _reportsDynamicActivityAttribute:bundleId:]
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_DICTATION
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_SIRI
CORESPEECH_DAEMON_ACCESS_AUDIO_FOR_SIRI_AND_DICTATION
STDynamicActivityAttributionPublisher
Class getSTDynamicActivityAttributionPublisherClass(void)_block_invoke
CSMicUsageReporter.m
Unable to find class %s
void *SystemStatusLibrary(void)
-[CSGestureMonitorPhone _startMonitoringWithQueue:]
v16@?0@8
CMWakeGestureManager
Class getCMWakeGestureManagerClass(void)_block_invoke
CSGestureMonitorPhone.m
void *CoreMotionLibrary(void)
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAssetWithEndpointId:completion:]
CSVoiceTriggerAssetHandler.m
CSAudioSessionController Queue
-[CSAudioSessionController dealloc]
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController _createXPCClientConnectionIfNeeded]
-[CSAudioSessionController _startMonitoring]
-[CSAudioSessionController _stopMonitoring]
-[CSAudioSessionController _registerInterruptionNotification]
-[CSAudioSessionController _registerAudioRouteChangeNotification]
-[CSAudioSessionController _handleInterruption:]_block_invoke
-[CSAudioSessionController _mediaServicesWereLost:]_block_invoke
-[CSAudioSessionController _mediaServicesWereReset:]_block_invoke
-[CSAudioSessionController _audioRouteChanged:]_block_invoke
-[CSAudioSessionController _teardownXPCClientIfNeeded]
-[CSAudioSessionController CSXPCClient:didDisconnect:]_block_invoke
-[CSAudioSessionController coreSpeechDaemonStateMonitor:didReceiveStateChanged:]_block_invoke
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
triggeredPhrase
AttSiri
AttSiriJS
AttSiriCC
AttSiriHS
mitigationModelConfigFile
defaultAFTMValue
nldaConfigFile
allowKeywordFile
allowKeywordCount
useSpkrId
ouresConfig.json
nldaConfig.json
allowList.txt
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
v12@?0I8
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
announcemessage
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSAudioStreamHolding dealloc]
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unknown
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
v16@?0@"NSError"8
-[CSAttSiriServiceClient init]_block_invoke
-[CSAttSiriServiceClient init]
-[CSAttSiriServiceClient startAttendingWithContext:]
com.apple.corespeech.corespeechd.attsiri.service
-[CSAttSiriServiceClient _setupAttSiriSvcXpcConnection]_block_invoke
-[CSAttSiriServiceClient attSiriDidDetectAttendingTrigger:]
-[CSAttSiriServiceClient attSiriAttendingTimeoutTriggered]
-[CSAttSiriServiceClient attSiriAttendingFailed]
firstPassTriggerSource
ApplicationProcessor
Remora
CSPreMyriadCoordinator Queue
-[CSPreMyriadCoordinator _clearPendingRemoraVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingRemoraVoiceTriggerIfNeeded]_block_invoke
-[CSPreMyriadCoordinator _clearPendingBuiltInVoiceTrigger]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]
-[CSPreMyriadCoordinator handlePendingBuiltInVoiceTriggerIfNeeded]_block_invoke
v32@?0@"NSString"8@"CSPreMyriadVoiceTriggerMetaData"16^B24
-[CSPreMyriadCoordinator secondPassDidStopForClient:deviceId:]
-[CSPreMyriadCoordinator secondPassDidStartForClient:deviceId:withFirstPassEstimate:]
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
v20@?0B8@"NSError"12
-[CSAudioRecordContext(AVVC) avvcContextSettings]
voiceTriggerInfo
route
source
siriVolume.json
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple2
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidMusicVSpreadDeviceSimple2
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidMusicVOffsetDeviceSimple2
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidMusicHOffsetDeviceSimple2
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidMusicSteepnessDeviceSimple2
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimple2OutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCADeviceSimple2OutputMinTargetDB
SSVCADeviceSimple2OutputMaxTargetDB
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAMinTTSSystemVolumeSimple2
SSVCAMaxTTSSystemVolumeSimple2
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceSimple2ASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicDilationFactorDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicVSpreadDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicVOffsetDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicHOffsetDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCASignalToSigmoidMusicSteepnessDeviceSimple]
-[CSAsset(SmartSiriVolume) SSVCADeviceSimpleASVOffMinTTSVolume]
-[CSAsset(SmartSiriVolume) _getNumberFromASVDictionaryForKey:category:default:]
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
%@ {recordDeviceInfo = %@, playbackRoute = %@, playbackDevices = %@
-[CSSpeakerRecognitionProxy initWithDelegate:]
-[CSSpeakerRecognitionProxy startXPCConnection]
-[CSSpeakerRecognitionProxy invalidateXPCConnection]
-[CSSpeakerRecognitionProxy didReceiveSpeakerRecognitionScoreCard:]
-[CSSpeakerRecognitionProxy didFinishSpeakerRecognition:]
CSVoiceTriggerXPCService Queue
-[CSVoiceTriggerXPCService enableVoiceTrigger:withAssertion:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setPhraseSpotterBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setRaiseToSpeakBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:]_block_invoke
-[CSVoiceTriggerXPCService fetchVoiceTriggerDailyStats]_block_invoke
-[CSVoiceTriggerXPCService _createXPCClientConnectionIfNeeded:]
-[CSVoiceTriggerXPCService voiceTriggerXPCClient:didDisconnect:]_block_invoke
-[CSVoiceTriggerXPCService _teardownXPCClientIfNeeded]
v12@?0i8
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerHSAssets.ma.new-asset-installed
Languages
Footprint
Premium
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
ZeroFilterMetrics
-[CSAudioPreprocessor _fetchCurrentMetrics]
BeepCancellerMetrics
-[CSOtherAppRecordingStateMonitor handleOtherAppRecordingStateChange:]
-[CSOtherAppRecordingStateMonitor _systemControllerDied:]
com.apple.corespeech.benchmark.xpc
+[CSBenchmarkService pingpong:completion:]_block_invoke
TEST
v16@?0@"NSString"8
+[CSBenchmarkService pingpong:completion:]
+[CSBenchmarkService runLstmPhsModelWithConfig:withUrl:completion:]_block_invoke
+[CSBenchmarkService runVTSecondPassModelWithConfig:locale:withUrl:completion:]_block_invoke
+[CSBenchmarkService runOSDAnalyzerWithConfig:withUrl:completion:]_block_invoke
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
com.apple.assistant
Siri Global
 - %@
CSKeychainValueForAccountAndKey
B8@?0
-[CSSmartSiriVolumeEnablePolicyHomePod _addSmartSiriVolumeEnabledConditions]_block_invoke
-[CSContinuousAudioFingerprintEnabledPolicyHomePod _addContinousAudioFingerprintEnabledConditions]_block_invoke
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
HID event callback queue
cancelled device
Created HID device successfully
Error : Failed in creating device
-[CSHostLauncherDarwin wakeHostForVoiceTrigger]
ReportDescriptor
RequestTimeout
HIDRelaySupport
HIDRelayUSBInterface
SiriHIDDevice
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
com.apple.corespeech.CSAccessorySiriClientBehaviourMonitor
-[CSAccessorySiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyWillStopStream:reason:forAccessory:]_block_invoke
-[CSAccessorySiriClientBehaviorMonitor notifyDidStopStream:reason:withEventUUID:forAccessory:]_block_invoke
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstRoutedState:]
-[CSAudioRouteChangeMonitorImplWatch _notifySiriInputSourceOutOfBandState:]
-[CSAudioRouteChangeMonitorImplWatch _systemControllerDied:]
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
CSAudioSampleRateConverter.m
Too many buffers
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
CSLanguageDetectorAssetMonitor
v24@?0@"NSArray"8@"NSError"16
-[CSLanguageDetectorAssetMonitor startMonitor]_block_invoke
en-US
-[CSLanguageDetectorAssetMonitor _supportedLocale:]_block_invoke
v24@?0@"CSAsset"8@"NSError"16
com.apple.MobileAsset.LanguageDetectorAssets.ma.new-asset-installed
-[CSSiriSpeechRecordingContext dealloc]
v24@?0@"NSURL"8@"NSError"16
%@ (sessionUUID = %@)
-[CSSiriSpeechRecordingContext initWithSessionUUID:turnIdentifier:]
com.apple.assistant.request.speech-context
-[CSSiriSpeechRecordingContext becomeCurrent]
-[CSSiriSpeechRecordingContext resignCurrent]
-[CSSiriSpeechRecordingContext updateStartSpeechId:]
-[CSSiriSpeechRecordingContext updateSelectedResultCandidateId:]
-[CSSiriSpeechRecordingContext updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:]
-[CSSiriSpeechRecordingContext getAudioRecordRouteAndDeviceIdentificationWithCompletion:]_block_invoke
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]
-[CSSiriSpeechRecordingContext acquireRecordedAudioWithHandler:]_block_invoke_2
v16@?0q8
-[CSSiriSpeechRecordingContext updateAudioRecordContext:]
-[CSSiriSpeechRecordingContext updateAudioRecordDeviceInfo:]
-[CSSiriSpeechRecordingContext updateVoiceTriggerInfo:]
-[CSSiriSpeechRecordingContext updateRecordingInfo:]
-[CSSiriSpeechRecordingContext updateRecordingSettings:]
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]
Start Recording
sessionUUID
v16@?0@"<AFAssertionContextMutating>"8
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]_block_invoke_2
-[CSSiriSpeechRecordingContext willPrepareAndStartRecordingWithAudioActivationInfo:]_block_invoke
v24@?0@"AFAssertionContext"8@"NSError"16
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]
Two Shot Detection
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke_2
-[CSSiriSpeechRecordingContext didDetectTwoShotWithAudioActivationInfo:atTime:]_block_invoke
-[CSSiriSpeechRecordingContext willStopRecordingAtHostTime:]
Stop Recording
-[CSSiriSpeechRecordingContext didStopRecordingWithError:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithContext:]
-[CSSiriSpeechRecordingContext relinquishAudioSessionAssertionsWithError:]
-[CSSiriSpeechRecordingContext beginRecordingAudioWithAudioStreamBasicDescription:]
-[CSSiriSpeechRecordingContext endRecordingAudio]
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke_2
-[CSSiriSpeechRecordingContext endRecordingAudio]_block_invoke
%@.wav
@"NSString"8@?0
-[CSSiriSpeechRecordingContext _finalizeAudioFileWriterWithCompletion:]
v32@?0@"NSFileHandle"8@"NSURL"16@"NSError"24
-[CSSiriSpeechRecordingContext instrumentSiriCueForAlertType:]_block_invoke
-[CSSiriSpeechRecordingContext emitRequestLinkEventForMHUUID:]
-[CSSiriSpeechRecordingContext _didBecomeCurrent]
-[CSSiriSpeechRecordingContext _didResignCurrent]
Donating recorded audio to CoreSpeech
-[CSSiriSpeechRecordingContext _didResignCurrent]_block_invoke_2
v12@?0B8
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke
ALLOWED
DENIED
-[CSSiriSpeechRecordingContext _donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:]_block_invoke_2
-[CSSiriSpeechRecordingContext _removeRecordedAudio]
com.apple.CoreSpeech.Connection.Listener
-[CSSmartSiriVolumeClient init]
-[CSSmartSiriVolumeClient getVolumeForTTSType:withContext:]_block_invoke
v24@?0@"NSError"8@"CSSmartSiriVolumeEstimate"16
-[CSSmartSiriVolumeClient setSmartSiriVolumePercentage:]_block_invoke
-[CSSmartSiriVolumeClient setSmartSiriVolumeDirection:]_block_invoke
-[CSSmartSiriVolumeClient setPermanentVolumeOffsetWithDirection:]_block_invoke
-[CSSmartSiriVolumeClient didTTSVolumeChangeForReason:]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]
com.apple.corespeech.corespeechd.ssv.service
-[CSSmartSiriVolumeClient _createClientConnection]_block_invoke
-[CSSmartSiriVolumeClient _createClientConnection]_block_invoke_2
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
BuiltInSpeaker
-[NSString(XPCObject) _cs_initWithXPCObject:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:]
com.apple.corespeech.corespeechd.voiceid.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
voiceTriggerEventInfo
otherCtxt
audioRecordCtx
-[CSVoiceIdXPCClient _notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:]
type
body
result
resultErrorDomain
resultErrorCode
-[CSShadowMicScoreCreator calculateShadowMicScore]
-[CSBluetoothWirelessSplitterMonitorImpIOS updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
CSBluetoothWirelessSplitterMonitorImpIOS.m
-[CSBluetoothWirelessSplitterMonitorImpIOS splitterState:]_block_invoke
v16@?0@"CSBluetoothWirelessSplitterInfo"8
-[CSBluetoothWirelessSplitterMonitorImpIOS _startMonitoringWithQueue:]_block_invoke
-[CSBluetoothWirelessSplitterMonitorImpIOS _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitorImpIOS _stopMonitoring]
v20@?0Q8B16
com.apple.bluetooth.WirelessSplitterOn
NviError
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
com.apple.corespeech.corespeechd.activation.xpc
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
event
modelHash
dictationPriors
earLoggingInfo
interactionId
HistBufferSizeinSecs
NumLeadingFrames
MinSpeechFrames
NumLatestLanguages
CSLanguageDetector
dummy-version
-[CSLanguageDetector _startMonitorLanguageDetectorAssetDownload]
-[CSLanguageDetector _setupLanguageDetectorWithOption:]
-[CSLanguageDetector resetForNewRequest:]_block_invoke_3
-[CSLanguageDetector cancelCurrentRequest]_block_invoke
-[CSLanguageDetector setInteractionIDforCurrentRequest:]_block_invoke
-[CSLanguageDetector _initializeStartOfSpeechDetector:samplingRate:]
-[CSLanguageDetector _constructLangPriors]
-[CSLanguageDetector _setNumLatestLangFromConfigFile:]
CSLanguageDetector.m
Unexpected!! Received dir for: %@
-[CSLanguageDetector _readJsonDictionaryAt:]
-[CSLanguageDetector _logSoSResult:toPath:]
-[CSLanguageDetector _logLanguageDetectorMetricsForLoggingInfo:]
-[CSLanguageDetector languageDetector:result:]
-[CSLanguageDetector languageDetectorDidCompleteProcessing:loggingInfo:]_block_invoke
SpgRegportedStartSampleId
EffectiveStartSampleId
-result.json
-[CSLanguageDetector startOfSpeechDetector:foundStartSampleAt:]_block_invoke
-result.wav
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin splitterState]
-[CSBluetoothWirelessSplitterMonitorImplDarwin _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitorImplDarwin _stopMonitoring]
CSStopRecordingReasonDefault
CSStopRecordingForClientEndpoint
CSStopRecordingForServerEndpoint
CSStopRecordingForReleaseAudioSession
CSStopRecordingForRequestCancellation
, %llu
, %f}
triggerEndMachTime
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
FirstPktLatency
TrailingPktLatency
TrailingPktSpeechLatency
-[CSEndpointLatencyInfo addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:]
-[CSEndpointLatencyInfo report]
-[CSCommandControlStreamEventMonitor isStreaming]
CSAVVCRecordingClientMonitor Queue
-[CSAVVCRecordingClientMonitor _startMonitoringWithQueue:]_block_invoke_2
v24@?0Q8@"NSError"16
v20@?0B8Q12
-[CSAVVCRecordingClientMonitor _startMonitoringWithQueue:]
-[CSAVVCRecordingClientMonitor _stopMonitoring]
-[CSAVVCRecordingClientMonitor CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAVVCRecordingClientMonitor _didReceiveAVVCRecordingClientNumberChange:]
CSSiriAudioFileWriterErrorDomain
CSSiriAudioFileWriterExtAudioFileErrorDomain
SavedAudioFile
CSSiriAudioFileWriter.m
Invalid parameter not satisfying: %@
type != AFAudioFileTypeNone
CSSiriAudioFileWriterQueue
-[CSSiriAudioFileWriter _initWithType:pathGenerator:xorFileHandle:priority:]_block_invoke
path
-[CSSiriAudioFileWriter _close]
-[CSSiriAudioFileWriter _delete]
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]
AudioFile Already configured
-[CSSiriAudioFileWriter configureWithAudioStreamBasicDescription:]_block_invoke
-[CSSiriAudioFileWriter appendAudioData:]_block_invoke
-[CSSiriAudioFileWriter flushWithCompletion:]_block_invoke
_AudioStreamBasicDescriptionForAFAudioFileType
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
reason
CoreSpeechXPC service invalidated
v32@?0@"NSString"8@"NSString"16@"NSError"24
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
v24@?0@"NSString"8@"NSError"16
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]
+[CSCoreSpeechServices getCurrentVoiceTriggerLocaleWithEndpointId:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
v32@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSError"24
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
CSHangUpEnabledMonitor queue
-[CSHangUpEnabledMonitor _checkCanUseVoiceTriggerDuringCallEnabled]
-[CSHangUpEnabledMonitor _voiceTriggerDuringCallEnabledDidChange]_block_invoke
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
[requiresHistoricalBuffer = %@]
[useCustomizedRecordSettings = %@]
[lpcmIsFloat = %@]
[isSiri = %@]
[sampleRate = %lf]
[numberOfChannels = %lu]
requiresHistoricalBuffer
useCustomizedRecordSettings
audioFormat
sampleRate
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
v32@?0Q8q16@"NSError"24
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke_2
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:]
-[CSSpeechManager _handleClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _startClearLoggingFilesTimer]
-[CSSpeechEndHostTimeEstimator notifyTrailingSilenceDurationAtEndpoint:]
-[CSSpeechEndHostTimeEstimator estimatedSpeechEndHostTime]
CSCommandControlListener
-[CSCommandControlListener startListenWithOption:completion:]
-[CSCommandControlListener _startRequestWithCompletion:]_block_invoke
-[CSCommandControlListener _startRequestWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]_block_invoke
-[CSCommandControlListener audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSCommandControlListener CSXPCClient:didDisconnect:]_block_invoke
FlexKwdSpotter
recognizer_flexKwd.json
flexKwdConfigFile
flexKwd.Thresholds
flexKwdThresholdsFile
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
RecordedAudio
TrimmedAudio
com.apple.corespeech.endpointer.xpc.client
com.apple.corespeech.endpointer.xpc.connection
com.apple.corespeech.endpointer.xpc.delegate
-[CSEndpointerXPCClient endpointerModelVersion]_block_invoke_2
v24@?0@"NSError"8@"NSString"16
-[CSEndpointerXPCClient endpointerModelVersion]
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]_block_invoke_2
v24@?0@"NSError"8d16
-[CSEndpointerXPCClient elapsedTimeWithNoSpeech]
-[CSEndpointerXPCClient endPointAnalyzerType]_block_invoke_2
v24@?0@"NSError"8Q16
-[CSEndpointerXPCClient endPointAnalyzerType]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]
-[CSEndpointerXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.endpointer.service
-[CSEndpointerXPCClient _createClientConnection]_block_invoke
-[CSEndpointerXPCClient _createClientConnection]_block_invoke_2
-[CSEndpointerXPCClient didDetectHardEndpointAtTime:withMetrics:]_block_invoke
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
deque
-[NviDirectionalitySignalProvider initWithDataSource:assetsProvider:]
-[NviDirectionalitySignalProvider addDelegate:]
-[NviDirectionalitySignalProvider removeDelegate:]
-[NviDirectionalitySignalProvider startWithNviContext:didStartHandler:]
-[NviDirectionalitySignalProvider reset]
-[NviDirectionalitySignalProvider stopWithDidStopHandler:]
-[CSConnectionListener initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:queue:]
-[CSConnectionListener dealloc]
-[CSConnectionListener listener:shouldAcceptNewConnection:]
corespeech.corespeechd.xpc
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke
-[CSConnectionListener listener:shouldAcceptNewConnection:]_block_invoke_2
-[CSConnectionListener notifyClientsWithBlock:]_block_invoke
-[CSConnectionListener resumeConnection]
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
triggerStartSampleCount
clientStartSampleCount
triggerFireMachTime
activeChannel
twoShotAudibleFeedbackDelay
hfpTriggerDuringPhoneCall
musicVolume
mediaPlayState
CSSpeechRecordSettingsKey_AudioSessionActiveDelay
CSSpeechRecordSettingsKey_AudioSessionActiveReason
CSSpeechRecordSettingsKey_LanguageDetectorLocales
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguages
CSSpeechRecordSettingsKey_LanguageDetectorCurrentKeyboard
CSSpeechRecordSettingsKey_LanguageDetectorWasLanguageToggled
CSSpeechRecordSettingsKey_LanguageDetectorMultilingualKeyboardLanguages
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardConvoLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardGlobalLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorPreviousMessageLanguage
CSSpeechRecordSettingsKey_LanguageDetectorGlobalLastKeyboardUsed
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorConversationalMessages
CSSpeechRecordSettingsKey_disableEndpointer
CSSpeechRecordSettingsKey_DictationRequestAppName
CSSpeechRecordSettingsKey_DictationRequestAppBundleID
CSSpeechRecordSettingsKey_DictationStartSampleId
CSSpeechRecordSettingsKey_isDucking
CSSpeechRecordSettingsKey_disableLocalSpeechRecognizer
CSSpeechRecordSettingsKey_triggerEventInfo
CSSpeechRecordSettingsKey_requestMHUUID
CSSpeechRecordSettingsKey_siriSessionUUID
CSSpeechRecordSettingsKey_asrOnDevice
CSSpeechRecordSettingsKey_disablePrewarmLocalAsrAtStartRecording
CSSpeechRecordSettingsKey_shouldSkipStartRecordingAlert
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdKnownUserRawScores
spIdUserScoresVersion
spIdKnownUserProfileVersions
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
userIdentityClassification
userClassified
CSSpeechController
CSSpeechController ContextReset
com.apple.corespeech.twoShotAudibleFeedback
MediaPlayingObserverQueue
v16@?0@"NSOrderedSet"8
-[CSSpeechController initializeRecordSessionWithRecordContext:]
-[CSSpeechController startController]
-[CSSpeechController prepareRecordWithSettings:error:]
-[CSSpeechController _fetchLastTriggerInfo]
-[CSSpeechController _fetchLastTriggerInfo]_block_invoke_2
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSSpeechController _currentConfigurationSupportsDucking]
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]
com.apple.corespeech.ducking
-[CSSpeechController _activateAudioSessionWithReason:delay:delayRequested:error:]_block_invoke_2
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]_block_invoke
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]
-[CSSpeechController _cancelPendingAudioSessionActivateForReason:]
-[CSSpeechController _performPendingAudioSessionActivateForReason:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:error:]
-[CSSpeechController _doActivateAudioSessionWithReason:error:]
-[CSSpeechController _updateRecordContextIfNeeded:]
-[CSSpeechController setCurrentRecordContext:error:]
-[CSSpeechController preheat]
-[CSSpeechController prewarmAudioSession]
-[CSSpeechController resetAudioSession]
-[CSSpeechController reset]
-[CSSpeechController releaseAudioSession]
-[CSSpeechController releaseAudioSession:]
v32@?0@8#16@?<v@?>24
-[CSSpeechController startRecordingWithSettings:error:]
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke_3
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke_2
-[CSSpeechController _startPhaticDecision]
-[CSSpeechController _startPhaticDecision]_block_invoke
not 
-[CSSpeechController stopRecording]
-[CSSpeechController stopRecordingWithOptions:]
-[CSSpeechController recordRoute]
-[CSSpeechController recordDeviceInfo]
-[CSSpeechController audioDeviceInfo]
-[CSSpeechController playbackRoute]
-[CSSpeechController _didStopForReason:]
-[CSSpeechController audioStreamProvider:didStopStreamUnexpectly:]
-[CSSpeechController _audioStreamProvdider:audioBufferAvailable:]
-[CSSpeechController audioStreamProvider:audioChunkForTVAvailable:]_block_invoke
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]_block_invoke
-[CSSpeechController audioSessionProvider:providerInvalidated:]_block_invoke_2
-[CSSpeechController audioSessionProvider:didChangeContext:]
-[CSSpeechController audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:]
-[CSSpeechController audioSessionProviderBeginInterruption:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]_block_invoke
-[CSSpeechController audioSessionProviderEndInterruption:]
-[CSSpeechController audioSessionProviderEndInterruption:]_block_invoke
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]_block_invoke
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]_block_invoke
-[CSSpeechController didTTSVolumeChange:forReason:]
-[CSSpeechController didTTSVolumeChange:forReason:]_block_invoke
-[CSSpeechController audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:]
-[CSSpeechController setAlertSoundFromURL:forType:force:]
-[CSSpeechController playAlertSoundForType:]
-[CSSpeechController playRecordStartingAlertAndResetEndpointer]
-[CSSpeechController stopEndpointer]
-[CSSpeechController setMeteringEnabled:]
-[CSSpeechController _createAudioPowerMeterIfNeeded]
-[CSSpeechController outputReferenceChannel]
-[CSSpeechController voiceTriggerInfo]
-[CSSpeechController endpointer:detectedTwoShotAtTime:]
-[CSSpeechController keywordDetectorDidDetectKeyword]_block_invoke
-[CSSpeechController _shouldRunHybridSDSDMitigation]
v20@?0B8@"NSArray"12
-[CSSpeechController _fetchAudioDecoderForTV:]
-[CSSpeechController _createAudioProviderFromXPCWithContext:]
Accounts
Speech Identifier
%c%c%c%c
none
-[CSSpeechController endpointerModelVersion]
-[CSSpeechController cancelCurrentLanguageDetectorRequest]_block_invoke
-[CSSpeechController beginWaitingForMyriad]
-[CSSpeechController endWaitingForMyriadWithDecision:]
-[CSSpeechController _setSoundPlayingState]
 NOT
-[CSSpeechController CSXPCClient:didDisconnect:]_block_invoke
-[CSSpeechController _teardownAudioProviderIfNeeded]
-[CSSpeechController _setMediaPlaybackState:isInterrupted:]
-[CSSpeechController _setAlarmIsPlaying:]
-[CSSpeechController _setTimerIsPlaying:]
-[CSSpeechController nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidFire:]_block_invoke
-[CSSpeechController clockAlarmObserver:alarmDidDismiss:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidFire:]_block_invoke
-[CSSpeechController clockTimerObserver:timerDidDismiss:]_block_invoke
com.apple.CoreSpeech.Connection.SSR.Client
com.apple.CoreSpeech.Connection.SSR
-[CSSSRXPCClient init]
-[CSSSRXPCClient _getRemoteServiceProxyObject]
-[CSSSRXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.ssr.service
-[CSSSRXPCClient _createClientConnection]_block_invoke
-[CSSSRXPCClient _createClientConnection]_block_invoke_2
-[CSSSRXPCClient didReceiveSpeakerRecognitionScoreCard:]
-[CSSSRXPCClient didFinishSpeakerRecognition:]
RequestContext
DetectedToken
TriggerMachTime
TriggerAbsStartSampleId
{attendingCtx: %@, detctedToken: %@, triggerMachTime=%llu, triggerStartSampleId=%llu}
rtblobs
adkblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
adklocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
%@ {request = %@, options = %@, player = %@, playerItem = %@}
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]_block_invoke
Unable to create player item.
Unable to replace current item of player.
Timed out when waiting for player item status to change to ready to play.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _prepareWithOptions:audioSession:completion:]_block_invoke_2
status
Failed to change player item status to ready to play.
v24@?0@8@16
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when it is already active.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke
Audio playback session is already inactive after preparation.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]_block_invoke_2
Audio playback session is already inactive after player seek to begin.
Player failed to seek to begin.
Stopped playback.
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased _resetPlayerItem]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemDidPlayToEndTime:]
-[CSSiriAudioPlaybackSessionImplAVPlayerBased playerItemFailedToPlayToEndTime:]
Player item failed to play to end time.
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
-[CSVoiceTriggerAssetHandlerDarwin _getVoiceTriggerAssetFromAssetManager:]
-[CSVoiceTriggerAssetHandlerDarwin _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerDarwin CSRemoteAssetManagerDidDownloadNewAsset:]
-[CSVoiceTriggerAssetHandlerDarwin CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
-[NviSignalProvidersController initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:]
-[NviSignalProvidersController dealloc]
NviSignalProvidersController.m
No DataSource found for SignalType: %@
-[NviSignalProvidersController _setupSignalProviders:]
-[NviSignalProvidersController _startDataSourcesWithContext:]
-[NviSignalProvidersController _startDataSourcesWithContext:]_block_invoke
-[NviSignalProvidersController _startSignalProvidersWithContext:]
-[NviSignalProvidersController _startSignalProvidersWithContext:]_block_invoke
-[NviSignalProvidersController _stopDataSources]_block_invoke
-[NviSignalProvidersController _stopDataSources]
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]_block_invoke
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]
-[NviSignalProvidersController _iterateSignalMask:withHandler:]
v16@?0@"<NviSignalProvider>"8
CSXPCClient Reply Queue
CSXPCClient connection Queue
-[CSXPCClient connect]_block_invoke
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient _sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
context
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
forceSetAlert
soundPath
alertStartTime
-[CSXPCClient alertStartTime]_block_invoke
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]_block_invoke
-[CSXPCClient averagePowerForChannel:]_block_invoke
-[CSXPCClient audioMetric]_block_invoke
audioMetric
audioStreamRequest
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient audioStreamWithRequest:streamName:completion:]_block_invoke
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
startAudioStreamOption
v16@?0@"NSDictionary"8
-[CSXPCClient acousticSLResultForContext:completion:]
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke_2
acousticSLResult
-[CSXPCClient acousticSLResultForContext:completion:]_block_invoke
-[CSXPCClient triggerInfoForContext:completion:]
rtsTriggerInfo
recordRoute
audioDeviceInfo
recordSettings
-[CSXPCClient audioStreamId]
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkFrom:to:channelIdx:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient audioChunkToEndFrom:channelIdx:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
-[CSXPCClient setAnnounceCallsEnabled:withStreamHandleID:]
-[CSXPCClient attachTandemStream:toPrimaryStream:completion:]
deviceID
sessionID
-[CSXPCClient audioSessionIdForDeviceId:]
sampleCount
-[CSXPCClient hostTimeFromSampleCount:]_block_invoke
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
-[CSXPCClient sampleCountFromHostTime:]_block_invoke
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
option
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
stopReason
chunk
hardwareConfig
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
triggerScore
configVersion
languageCode
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
@"NSDictionary"8@?0
com.apple.corespeech.SecondPassWakeUp
unknown
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:withPhrase:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
-[CSSmartSiriVolumeManager CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:]
numImplicitUtt
numExplicitUtt
numFirstPassTriggersPerDay
vtStatistics
vtStatisticsFirstPassPeakScoreHS
vtStatisticsFirstPassPeakScoreJS
vtStatisticsFirstPassTriggerSource
vtStatisticsRecognizerScoreHS
vtStatisticsRecognizerScoreJS
vtStatisticsTriggerScoreHS
vtStatisticsTriggerScoreJS
vtStatisticsMitigationScore
vtStatisticsInvocationTypeId
vtStatisticsFirstPassDetectionTime
vtStatisticsRepetitionSimilarityScore
firstPassDailyMetadata
firstPassDailyMetadataConfigVersion
firstPassDailyMetadataBuildVersion
firstPassDailyMetadataHardwareSampleRate
firstPassDailyMetadataMitigationAssetVersion
isJSEnabled
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
Logs/CrashReporter/CoreSpeech/audio/
-[CSAudioFileLog _getOrCreateAudioLogDirectory]
/tmp
en_US_POSIX
yyyyMMdd-HHmmss
%@/%@%@%@
firstPassEndSampleCount
firstPassStartSampleCount
firstPassGoodness
totalSampleCount
vtEndTime
numSamplesFromHistoricalBuffer
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
uuid
deviceId
activationInfo
vadScore
hosttime
com.apple.corespeech.fakeasset.rolling
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]_block_invoke
-[CoreSpeechXPCFakeModelMonitor _registerForFakeAssetRollNotification]
Adaptive Siri Volume Disabled
near
medium
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolume:]
-[CSSmartSiriVolumeUserIntent applyLowerAndUpperBoundsToVolumeOffset:]
com.apple.MobileAsset.VoiceTriggerAssetsMac
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController assetOfType:language:compatibilityVersion:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:query:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:query:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
CSAudioInjectionTvRemoteEngine
ApplicationProcessorWithRingtone
v16@?0@"AFSiriActivationResult"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
Trigger was during a ringtone
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyWakeKeywordSpokenInBuiltInMic:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke_2
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenCarPlay:deviceId:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher notifyWakeKeywordSpokenBluetoothDevice:deviceId:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:withContext:]_block_invoke
-[CSSiriLauncher notifyDarwinVoiceTrigger:deviceId:myriadPHash:myriadLateActivationExpirationTime:completion:]_block_invoke_2
-[CSSiriLauncher notifyDarwinVoiceTrigger:deviceId:myriadPHash:myriadLateActivationExpirationTime:completion:]_block_invoke
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getHearstRouted:]
-[CSAudioRouteChangeMonitor hearstRouted]
-[CSAudioRouteChangeMonitor getSiriInputSourceOutOfBand:]
-[CSAudioRouteChangeMonitor siriInputSourceOutOfBand]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
CSSmartSiriVolumeEnablePolicy queue
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
v16@?0Q8
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
VoiceTrigger Asset Change Monitor
com.apple.corespeech.voicetriggerassetchange
CSAttSiriRequestSourceKey
SiriFollowupforIdleAndQuiet
Dictation
LockScreenNotification
SpeechDetection
-[NviAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[NviAudioFileWriter addSamples:numSamples:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
-[CSBluetoothWirelessSplitterMonitor splitterState]
CSBluetoothWirelessSplitterMonitor.m
-[CSBluetoothWirelessSplitterMonitor updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:]
-[CSBluetoothWirelessSplitterMonitor splitterState:]
-[CSBluetoothWirelessSplitterMonitor _startMonitoringWithQueue:]
-[CSBluetoothWirelessSplitterMonitor _stopMonitoring]
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyFetchedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyPreparedSiriClientAudioStream:successfully:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:reason:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyReleaseAudioSession]_block_invoke
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.SpeechEndpointAssets.ma.cached-metadata-updated
estimatedTTSVolume
debugLogPath
com.apple.corespeech.corespeechd.uaapservice
CSSpeechUaapXPCClient
-[CSSpeechUaapXPCClient init]_block_invoke
-[CSSpeechUaapXPCClient _handleConnectionError:]
v32@?0@"NSString"8Q16^B24
bundleId
assetFiles
messageType
message
errorMessage
locale
v32@?0@"NSString"8@"NSArray"16^B24
-[CSSpeechUaapXPCClient invalidate]
CSVoiceTriggerHandlerMacQueue
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManagerWithLocale:completion:]_block_invoke_2
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke_3
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablityForEndpoint]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSVoiceTriggerAssetHandlerMac trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
BTDetails_IsHFPRoute
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
Library/nvi
/System/Library/Audio/UISounds/jbl_begin_short.caf
/System/Library/Audio/UISounds/jbl_begin_short_carplay.caf
%@ {activationMode = %.4s, deviceIdentifier = %@, activated = %d}
-[CSSiriAudioActivationInfo initWithSpeechRecordingMode:clientConfiguration:experimentContext:]
-[CSSiriAudioActivationInfo setSpeechRequestOptions:currentActivationInfo:]
-[CSSiriAudioActivationInfo setClientConfiguration:]
-[CSSiriAudioActivationInfo _csAudioRecordTypeForSpeechRequestOptions:useBorealisBuffer:currentClientConfiguration:]
-[CSSiriAudioActivationInfo startRecordingSettingsWithRecordRoute:recordingInfo:playbackRoute:]
-[CSSiriAudioActivationInfo _alertBehaviorForRecordRoute:recordingInfo:playbackRoute:attemptsToUsePastDataBufferFrames:]
-[CSSiriAudioActivationInfo audioAlertStyleForRecordRoute:recordingInfo:playbackRoute:]
-[CSSiriAudioActivationInfo twoShotPromptTypeForRecordRoute:playbackRoute:]
-[CSSiriAudioActivationInfo audioSessionActivationTargetDate]
-[CSSiriAudioActivationInfo dateByAddingTimeIntervalSinceActivation:]
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]_block_invoke
q8@?0
-[CSSiriAudioActivationInfo _audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayCoreSpeechWithType:]
@"NSNumber"16@?0@"NSNumber"8
-[CSSiriAudioActivationInfo _audioSessionActiveDelayUserPerceptionWithType:]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayOverride]
-[CSSiriAudioActivationInfo _audioSessionActiveDelayServerConfiguration]
_CSSiriLanguageDetectorSettings
triggerEndSampleCount
triggerEndSeconds
com.apple.voicetrigger
com.apple.nvi
IsNviEnabled
InternalBuild
NviVADSignalType
NviKwdSignalType
NviDirectionalitySignalType
NviAsdAnchorSignalType
NviAsdPayloadSignalType
+[NviUtils strRepForNviSignalType:]
NviUtils.m
Unknown NviSignalTypeString: <%@>
NviAudioDataSrcType
+[NviUtils strRepForNviDataSourceType:]
NviDataSource_END_MARKER
+[NviUtils nviDataSourceTypeForStr:]
+[NviUtils _createDirAtPath:]
yyyyMMdd_HHmmss.SSS
Unexpected!! Received dir for NviConfig: %@
+[NviUtils readJsonDictionaryAt:]
+[NviUtils getValueFromDictionaryOfDictionaries:keypath:]
+[NviUtils createDirAtPath:]
SilenceFramesCountMs
SilenceProbability
SilenceDurationMs
ProcessedAudioMs
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
[requireSingleChannelLookup = %@]
[selectedChannel = %u]
[estimatedStartHostTime = %llu
[disableEndpointer = %d]
[disableLocalSpeechRecognizer = %d]
[disablePrewarmLocalSpeechRecognizer = %d]
[disableBoostForDoAP = %d]
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
requireSingleChannelLookup
selectedChannel
estimatedStartHostTime
disableEndpointer
disableLocalSpeechRecognizer
disablePrewarmLocalSpeechRecognizer
disableBoostForDoAP
requestMHUUID
siriSessionUUID
%@ {request = %@, options = %@, player = %@}
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _prepareWithOptions:audioSession:error:]
Failed to initialize AVAudioPlayer.
Failed to prepare to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:]
Attempted to start audio playback session when AVAudioPlayer is already playing.
Failed to play AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]
Stopped playback of AVAudioPlayer.
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _stop:]_block_invoke
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleBeginInterruption]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _handleEndInterruption:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didNotStartWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _didStopWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased _finalizeWithError:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDidFinishPlaying:successfully:]
-[CSSiriAudioPlaybackSessionImplAVAudioPlayerBased audioPlayerDecodeErrorDidOccur:error:]
-[CSSmartSiriVolumeRunPolicyHomePod _addSmartSiriVolumeEnabledConditions]_block_invoke
-[CSContinuousAudioFingerprintEnabledPolicy _addContinousAudioFingerprintEnabledConditions]_block_invoke
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
com.apple.corespeech.rchandling.xpc.connection
-[CSRCHandlingXPCClient processRCWithId:duration:lrnnScore:lrnnThreshold:taskId:forceAccept:completionHandler:]
-[CSRCHandlingXPCClient getMitigationDecisionForRCIdWithCompletion:completion:]
-[CSRCHandlingXPCClient _getRemoteServiceProxyObject]
-[CSRCHandlingXPCClient _getRemoteServiceProxyObject]_block_invoke
com.apple.corespeech.corespeechd.rchandling.service
-[CSRCHandlingXPCClient _createClientConnection]_block_invoke
-[CSRCHandlingXPCClient _createClientConnection]_block_invoke_2
smartSiriVolumeOverrideMediaVolume
com.apple.ssv.clientq
-[CSSmartSiriVolumeController getVolumeForTTSType:withContext:]_block_invoke
-[CSSmartSiriVolumeController _createSSVClientConnectionIfNeeded]
-[CSSmartSiriVolumeController didSmartSiriVolumeChangeForReason:]
-[CSPhraseNDEAPIScorer keywordAnalyzerNDEAPI:hasResultAvailable:forChannel:]
speakerRecognition
satThreshold
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
useSpeakerRecognitionAsset
phrase
-[CSAsset(SpeakerRecognition) satScoreThresholdForPhId:]
recognizer.json
config.txt
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
-[CSAudioTandemStream attachToPrimaryStreamWithCompletion:]
-[CSAudioTandemStream prepareAudioStreamSyncWithRequest:error:]
CSAudioTandemStream.m
-[CSAudioTandemStream prepareAudioStreamWithRequest:completion:]
-[CSAudioTandemStream startAudioStreamWithOption:completion:]
-[CSAudioTandemStream stopAudioStreamWithOption:completion:]
CSAttSiriStateMonitor queue
-[CSAttSiriStateMonitor updateState:]_block_invoke
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.request.generic
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.fetch.parallelrecording
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_VoiceProfilePeerName_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
CSP2P_VoiceProfileiTunesUserID_Key
CSP2P_VoiceProfileiTunesPassword_Key
remote
-triggered
-almost
-rejected
-activation
ssrmeta
ssvmeta
vtei
multiuser
acousticSLmeta
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService sendAcousticGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendGeckoSpeechLogsToCompanion]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:]_block_invoke
q24@?0@"NSURL"8@"NSURL"16
json
B24@?0@"NSURL"8@"NSDictionary"16
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGeckoSpeechLogsToPeerId:]_block_invoke_2
-[CSP2PService _sendGeckoSpeechLogsToPeerId:]_block_invoke
Gecko-
v24@?0@"NSUUID"8@"NSError"16
[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}
.wav
.json
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechMagusGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:]
fileData
fileName
peerId
%@%@
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
CSP2PService.m
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
-SL.json
-synced.wav
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendAcousticGradingDataToPeerId:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
com.apple.corespeech
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
+[CSPhoneCallStateMonitor sharedInstance]
CSPhoneCallStateMonitor.m
-[CSPhoneCallStateMonitor phoneCallState]
-[CSPhoneCallStateMonitor firstPartyCall]
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]
-[CSContinuousAudioFingerprintProvider startWithUUID:withMaximumBufferSize:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_3
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider _handleEnablePolicyEvent:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
CSBuiltInSpeakerStateMonitor queue
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateMutedInfo]_block_invoke_2
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateMutedInfo]_block_invoke
muted
not muted
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateActiveInfo]_block_invoke_2
-[CSBuiltinSpeakerStateMonitor _fetchSpeakerStateActiveInfo]_block_invoke
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invoke_2
active
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]_block_invoke
-[CSBuiltinSpeakerStateMonitor _startMonitoringWithQueue:]
-[CSBuiltinSpeakerStateMonitor _stopMonitoring]_block_invoke
-[CSBuiltinSpeakerStateMonitor _stopMonitoring]
-[CSBuiltinSpeakerStateMonitor CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
SignalTs, ProcessedAudioMs, StartSample, EndSample, Azimuth, EmaAzimuth, Confidence, SpatialSpreadSpectrum
%llu,%f,%lu,%lu,%f,%f,%f,
{%@, {start=%lu, end=%lu, conf=%f, az=%f, estAz=%fdist=%@}
,%d, 
%f, 
CSEndpointMetrics:::totalAudioRecorded
CSEndpointMetrics:::endpointBufferHostTime
CSEndpointMetrics:::featuresAtEndpoint
CSEndpointMetrics:::endpointerType
CSEndpointMetrics:::serverFeatureLatencyDistribution
CSEndpointMetrics:::additionalMetrics
CSEndpointMetrics:::trailingSilenceDurationAtEndpoint
[totalAudioRecorded = %f]
[endpointBufferHostTime = %llu]
[trailingSilenceDurationAtEndpoint = %f]
[endpointerType = %lu]
[featuresAtEndpoint = %@]
[additionalMetrics = %@]
isMediaPlaying
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isAlarmPlaying
isTimerPlaying
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_3
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
override-asset
CSSACInfoMonitor queue
-[CSSACInfoMonitor _startMonitoringWithQueue:]
-[CSSACInfoMonitor _stopMonitoring]
-[CSSACInfoMonitor isDeviceRoleStereo]
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
com.apple.assistant.vibration-manager
com.apple.springboard.ring-vibrate.changed
com.apple.springboard.silent-vibrate.changed
-[CSSiriVibrationManager _fetchRingVibrationValue]
ring-vibrate
-[CSSiriVibrationManager _fetchSilentVibrationValue]
silent-vibrate
-[CSSiriVibrationManager handleRingVibrationValueChange]
-[CSSiriVibrationManager handleSilentVibrationValueChange]
com.apple.springboard
mobile
_fetchVibrationState
::: Initializing NVI logging...
Framework
InitNviLogging_block_invoke
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl pickableRoutesDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAuxStreamSupportDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayIsConnectedDidChange:]
-[CSAudioRouteChangeMonitorImpl _startMonitoringWithQueue:]
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyHearstRoutedState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifySiriInputSourceOutOfBandState:]
-[CSAudioRouteChangeMonitorImpl _systemControllerDied:]
-[CSAutomaticVolumeEnabledMonitor observeValueForKeyPath:ofObject:change:context:]_block_invoke
-[CSSiriRecordingInfo initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:]
forceSiriPCMAudio
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
Warmup
accessible-extended
accessible-maximum
extraSamplesAtStart
SearchOrMessaging
ExtraDelayMs
EndpointerDecisionLagMs
ClientLagThresholdMsKey
ClampedSFLatencyMsForClientLag
UseDefaultServerFeaturesOnClientLag
extra-delay-frequency
endpoint-threshold
com.apple.cs.%@.stateserialqueue
com.apple.cs.%@.sepfQueue
com.apple.cs.%@.hybridClassifierfQueue
-[CSHybridEndpointer endpointerModelVersion]_block_invoke
-[CSHybridEndpointer updateEndpointerThreshold:]_block_invoke
-[CSHybridEndpointer updateEndpointerDelayedTrigger:]_block_invoke
-[CSHybridEndpointer setEndpointerOperationMode:]_block_invoke
-[CSHybridEndpointer fetchCurrentEndpointerOperationMode]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke
-[CSHybridEndpointer processTaskString:]_block_invoke_2
-[CSHybridEndpointer processServerEndpointFeatures:]
-[CSHybridEndpointer processServerEndpointFeatures:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointer processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_3
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke_2
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]_block_invoke
-[CSHybridEndpointer processOSDFeatures:withFrameDurationMs:]
endpointerModelVersion
wordCount
eosLikelihood
trailingSilenceDuration
serverFeaturesLatency
clientSilenceProbability
clientSilenceFramesCountMs
endpointResult
-[CSHybridEndpointer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointer terminateProcessing]
-[CSHybridEndpointer recordingStoppedForReason:]
-[CSHybridEndpointer stopEndpointer]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointer _readParametersFromHEPAsset:]_block_invoke
CSHybirdEndpointer.m
CSHybridEndpointer reset called
-[CSHybridEndpointer endpointerAssetManagerDidUpdateAsset:]_block_invoke
cs_hep_marsh.json
cs_hep.json
-[CSHybridEndpointer _getCSHybridEndpointerConfigForAsset:]
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
com.apple.nvi.csaudiosrc
-[NviCSAudioDataSource startWithNviContext:didStartHandler:]_block_invoke_2
-[NviCSAudioDataSource stopWithDidStopHandler:]_block_invoke_2
-[NviCSAudioDataSource _createAudioStreamWithCurrentNviContext]
-[NviCSAudioDataSource audioStreamProvider:avBufferAvailable:]
-[NviCSAudioDataSource audioStreamProvider:didStopStreamUnexpectly:]
-[NviCSAudioDataSource audioStreamProvider:audioChunkForTVAvailable:]
SPG.nnet
version
CSEndpointerAssetManager queue
-[CSEndpointerAssetManager init]
-[CSEndpointerAssetManager checkFirstUnlocked]
-[CSEndpointerAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]_block_invoke
-[CSEndpointerAssetManager CSAssetManagerDidDownloadNewAsset:]_block_invoke
-[CSEndpointerAssetManager CSFirstUnlockMonitor:didReceiveFirstUnlock:]_block_invoke
-[CSEndpointerAssetManager assetStatus:]
-[CSEndpointerAssetManager _getCurrentHEPAsset]
-[CSEndpointerAssetManager _updateOEPAssetsWithLanguage:]
-[CSEndpointerAssetManager _notifyAssetsUpdate]
-[CSEndpointerAssetManager _fetchEndpointMobileAssetWithLanguage:]
ModelInfo=
-[CSEndpointerAssetManager _getOEPVersionFromPath:]
-[CSEndpointerAssetManager _getFakeEndpointAsset]
-[CSEndpointDelayReporter initWithRequestMHUUID:turnIdentifier:]
-[CSEndpointDelayReporter reset]
leadingSilence
trailingSilence
endTime
-[CSEndpointDelayReporter setSpeechRecognizedContext:withEndpointerMetrics:]
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEventSynchronously:completion:]
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
-[CSLanguageCodeUpdateMonitorImpl _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImpl _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImpl _didReceiveLanguageCodeUpdate]
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
-[CSAttSiriAudioSessionStateClient initWithDelegate:]
SiriStateNotificationListener
com.apple.siri.client-state-changed
-[CSAttSiriAudioSessionStateClient notifyObserver:didReceiveNotificationWithToken:]
-[CSAttSiriAudioSessionStateClient notifyObserver:didChangeStateFrom:to:]
-[CSAttSiriAudioSessionStateClient dispatchStateChangedFrom:to:]
Liminal
progChecker.json
progressiveCheckerConfigFile
contionusConversationConfigFile
checkerConfig
validInputOrigins
thresholds
shadowMode
Unspecified
VoiceTrigger
ButtonPress
B32@?0@8@16^B24
v24@?0@8^B16
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsTV.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerHSAssets.ma.cached-metadata-updated
-[CSAudioRecordDeviceIndicator updateWithLatestRecordContext:]
+[CSVoiceTriggerEnabledPolicyHelper siriInCallPolicy]
com.apple.assistant.queue-monitor
-[CSSiriQueueMonitor beginMonitoring]
-[CSSiriQueueMonitor endMonitoring]
-[CSSiriQueueMonitor _addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:]
-[CSSiriQueueMonitor _beginMonitoring]
-[CSSiriQueueMonitor _endMonitoring]
-[_CSSiriQueueObserver startWithQueue:]
com.apple.assistant.queue-observer.%s
-[_CSSiriQueueObserver stop]
-[_CSSiriQueueObserver timeoutDetected]
-[CSRemoteVADCircularBuffer copySamplesFrom:to:]
copySamples
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream stopAudioStreamWithOption:completion:]_block_invoke
-[CSAudioStream isStreaming]
-[CSAudioStream updateAudioStreamStartTimeInSampleCount:]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
BluetoothA2DPOutput
BluetoothHFP
BluetoothLE
MicrophoneBuiltIn
Speaker
Headphones
MicrophoneWired
HDMIOutput
LineIn
USBAudio
ADAudioSessionPortOther
-[CSSiriAudioSession currentInputRoute]_block_invoke
v24@?0^v8Q16
-[CSSiriAudioSession currentOutputRoute]_block_invoke_3
_AudioObjectGetScalarArray
v20@?0I8r^{AudioObjectPropertyAddress=III}12
_AudioDeviceRegisterForChangedNotification
v16@?0^v8
_AudioObjectGetCFTypeRef
_AudioObjectGetIntValue
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
-[CoreSpeechXPC installedVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC _handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
fakeModel.json
fakeModel
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]
v40@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSString"24@"NSError"32
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
de-AT
de-DE
de-CH
en-AU
en-CA
en-GB
en-SG
en-IE
en-IN
en-ZA
en-NZ
it-IT
it-CH
ja-JP
zh-CN
zh-TW
nb-NO
nl-BE
nl-NL
sv-SE
tr-TR
fi-FI
he-IL
es-ES
es-US
es-CL
es-MX
fr-FR
fr-BE
fr-CA
fr-CH
ko-KR
zh-HK
yue-CN
da-DK
ms-MY
pt-BR
ru-RU
th-TH
ar-AE
ar-SA
default
Hearst
-[CoreSpeechXPC _fetchVoiceTriggerInstalledAssetWithLanguage:completion:]_block_invoke
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSRawAudioInjectionProvider init]
CSRawAudioInjectionProvider
-[CSRawAudioInjectionProvider dealloc]
-[CSRawAudioInjectionProvider setContext:completion:]
-[CSRawAudioInjectionProvider setCurrentContext:streamHandleId:error:]
-[CSRawAudioInjectionProvider prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider startAudioStreamWithOption:recordDeviceIndicator:error:]
/var/mobile/darwin_test.wav
-[CSRawAudioInjectionProvider stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSRawAudioInjectionProvider isRecordingWithRecordDeviceIndicator:]
RawAudioInjection
-[CSRawAudioInjectionProvider prewarmAudioSessionWithStreamHandleId:error:]
-[CSRawAudioInjectionProvider activateAudioSessionWithReason:streamHandleId:error:]
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
CSAudioProvider
CSAudioProvider Stream Handle Queue
CSAudioProvider logging
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider supportsDuckingOnCurrentRouteWithError:]
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke_2
failed
successfully
-[CSAudioProvider attachTandemStream:toPrimaryStream:completion:]_block_invoke
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _createCircularBufferIfNeededWithNumChannel:playbackRoute:]
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke_3
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_4
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_3
CSAudioProvider.m
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider _shouldDuckOnBuiltInSpeaker]
-[CSAudioProvider _isDuckingOnSpeakerOutputSupportedWithCurrentRoute]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setDuckOthersOption:]
-[CSAudioProvider setAlertSoundFromURL:forType:force:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke_2
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]_block_invoke
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
com.apple.corespeech.recording
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _onAudioPacketWatchdogFire]
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _updateRemoteDeviceIdFromAVVCIfNeeded]
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8Q16^B24
-[CSAlwaysOnProcessorStateMonitor _startMonitoringWithQueue:]_block_invoke
com.apple.audio.AOP.enable
-[CSAlwaysOnProcessorStateMonitor _startMonitoringWithQueue:]_block_invoke_2
-[CSAlwaysOnProcessorStateMonitor _stopMonitoring]
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
com.apple.siri.myriad.in.ear
+[CSMyriadNotifier notifyInEarMyriadTrigger]
-[CSAVCallConnectedMonitor _systemControllerDied:]
+[CSRemoteDeviceProtocolInfo localDeviceProtocolInfo]
protocolVersion=%lu, deviceCategory=%lu, buildVersion=%@, deviceProductVersion=%@, deviceProductType=%@
protocolVersion
deviceCategory
buildVersion
deviceProductVersion
deviceProductType
-[CSHybridEndpointAnalyzer init]
com.apple.cs.%@.apQueue
com.apple.cs.%@.osdQueue
-[CSHybridEndpointAnalyzer _loadAndSetupEndpointerAssetIfNecessary]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke
-[CSHybridEndpointAnalyzer processAudioSamplesAsynchronously:]_block_invoke_2
-[CSHybridEndpointAnalyzer updateEndpointerThreshold:]
-[CSHybridEndpointAnalyzer updateEndpointerDelayedTrigger:]
-[CSHybridEndpointAnalyzer processServerEndpointFeatures:]
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke_2
-[CSHybridEndpointAnalyzer shouldAcceptEagerResultForDuration:resultsCompletionHandler:]_block_invoke
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_3
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke_2
-[CSHybridEndpointAnalyzer osdAnalyzer:didUpdateOSDFeatures:]_block_invoke
-[CSHybridEndpointAnalyzer logFeaturesWithEvent:locale:]_block_invoke
-[CSHybridEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]_block_invoke
-[CSHybridEndpointAnalyzer recordingStoppedForReason:]
-[CSHybridEndpointAnalyzer stopEndpointer]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]
-[CSHybridEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:]_block_invoke
-[CSHybridEndpointAnalyzer _readParametersFromHEPAsset:]_block_invoke
CSHybridEndpointAnalyzer.m
CSHybridEndpointAnalyzer reset called
-[CSHybridEndpointAnalyzer CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSHybridEndpointAnalyzer CSAssetManagerDidDownloadNewAsset:]
-[CSHybridEndpointAnalyzer CSFirstUnlockMonitor:didReceiveFirstUnlock:]
-[CSHybridEndpointAnalyzer _updateAssetWithLanguage:]_block_invoke
-[CSHybridEndpointAnalyzer _getCSHybridEndpointerConfigForAsset:]
injectionDevice
com.apple.da
ExperimentGroup
walkabout
carry
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider audioSessionIdForDeviceId:]
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
RouteChangeNotificationInfo
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy updateEndpointerThreshold:]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
CSSiriMobileBluetoothDeviceDataSource
Queue %s did not respond to watchdog and is likely blocked.
-[CSSiriMobileBluetoothDeviceDataSource init]_block_invoke_2
-[CSSiriMobileBluetoothDeviceDataSource _cleanUpDeviceProxies]
-[CSSiriMobileBluetoothDeviceDataSource _detachFromSession]
-[CSSiriMobileBluetoothDeviceDataSource _attachToSession]
-[CSSiriMobileBluetoothDeviceDataSource _sessionAttached:result:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionDetached:]
-[CSSiriMobileBluetoothDeviceDataSource _sessionTerminated:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpLocalDevice]
-[CSSiriMobileBluetoothDeviceDataSource localDevice:event:result:]
-[CSSiriMobileBluetoothDeviceDataSource _setUpAccessoryManager]
-[CSSiriMobileBluetoothDeviceDataSource accessoryManager:event:device:state:]
v16@?0@"AFBluetoothDeviceInfo"8
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithAddress:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTDeviceWithDeviceUID:completion:]_block_invoke
-[CSSiriMobileBluetoothDeviceDataSource getBTLocalDeviceWithCompletion:]_block_invoke
%@ {deviceUID = %@}
%@ {address = %@}
-[CSSiriMobileBluetoothDeviceProxy dealloc]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithAddress:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]
-[CSSiriMobileBluetoothDeviceProxy initWithDeviceUID:dataSource:queue:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy deviceInfo]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneInEarDetectionState:]
-[CSSiriMobileBluetoothDeviceProxy getHeadphoneListeningMode:]
-[CSSiriMobileBluetoothDeviceProxy setHeadphoneListeningMode:completion:]
v24@?0^{BTDeviceImpl=}8^{BTAccessoryManagerImpl=}16
-[CSSiriMobileBluetoothDeviceProxy _reload:]
-[CSSiriMobileBluetoothDeviceProxy _reload:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _updateDeviceInfo:]
v16@?0@"<AFBluetoothDeviceObserver>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]
v16@?0@"<AFBluetoothDeviceInfoMutating>"8
-[CSSiriMobileBluetoothDeviceProxy _fetchDeviceInfoWithCompletion:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]_block_invoke
-[CSSiriMobileBluetoothDeviceProxy _accessBTDeviceAndAccessoryManagerUsingBlock:]_block_invoke_2
-[CSSiriMobileBluetoothDeviceProxy _invalidate]
v24@?0@"<AFBluetoothDeviceObserver>"8^B16
ADBTResult
_CSSiriBTDeviceGetAddress
_CSSiriBTDeviceGetDeviceInfo
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
-[CSFirstUnlockMonitor _stopMonitoring]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection initWithConnection:]
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]_block_invoke
-[CSVoiceIdXPCConnection _handleClientMessage:client:]_block_invoke_2
-[CSVoiceIdXPCConnection _handleClientError:client:]
com.apple.
com.apple.private.
com.apple.assistant.audio-service-workloop
Internal User Classification
kAFPreferencesDidChangeDarwinNotification
Audio Session Active Delay
Server Media Playback Volume Threshold for Audio Session Activation Delay
Server Audio Session Activation Delay Above Media Playback Volume Threshold
Server Audio Session Activation Delay
com.apple.corespeech.mockremoteplugin.xpc
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
CSSPGEndpointAnalyzer
hybridendpointer.json
-[CSSPGEndpointAnalyzer reset]_block_invoke
-[CSSPGEndpointAnalyzer dealloc]
-[CSSPGEndpointAnalyzer stop]_block_invoke
-[CSSPGEndpointAnalyzer clientSilenceFeaturesAvailable:]
-[CSHomePodSettingsMonitor _stopMonitoring]
com.apple.siri.acousticsignature
ADAcousticFingerprinter
-[CSSiriAcousticFingerprinter _connectionInterrupted]
-[CSSiriAcousticFingerprinter _connectionInvalidated]
-[CSSiriAcousticFingerprinter _configureWithCurrentASBD]
-[CSSiriAcousticFingerprinter _convertPCMDataForFingerprinting:]
-[CSSiriAcousticFingerprinter appendPCMData:]_block_invoke
v16@?0@"NSData"8
-[CSSiriAcousticFingerprinter flush]_block_invoke_2
ASXSampleRateFromInt
satScore
selfLoggingMHUUID
CSSiriSpeechRecorder.m
speechController != nil
audioSessionController != nil
audioPlaybackService != nil
-[CSSiriSpeechRecorder initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:]
-[CSSiriSpeechRecorder _currentMHUUID:]
-[CSSiriSpeechRecorder _setSpeechCapturingMode:]
-[CSSiriSpeechRecorder _setEndpointerOperationMode:forceUpdate:]
-[CSSiriSpeechRecorder _setAlertsIfNeeded]
siri-begin-improved
v32@?0@"NSNumber"8@"NSNumber"16^B24
-[CSSiriSpeechRecorder _updateRecordBufferDuration]
Speech controller should not be nil.
-[CSSiriSpeechRecorder _speechControllerWithError:]
-[CSSiriSpeechRecorder _resetSpeechController]
-[CSSiriSpeechRecorder _prepareSpeechControllerWithOptions:error:]
requestDuringActiveCall
since we have no Voice Controller!
-[CSSiriSpeechRecorder _stopRecordingWithReason:hostTime:]
%d.%d
 Forcing two shot mode to NO
-[CSSiriSpeechRecorder _disableEndpointer]
-[CSSiriSpeechRecorder _playAudioAlert:]
-[CSSiriSpeechRecorder _checkAudioLoggingLimits:]
-[CSSiriSpeechRecorder _prepareDirectoryAtPath:]
-[CSSiriSpeechRecorder _setupAudioFileWritingForSpeechController:info:context:]
-[CSSiriSpeechRecorder _setupAudioFileWritingForSpeechController:info:context:]_block_invoke
PCM-%@-%@.wav
v24@?0@"NSURL"8@?<v@?>16
-[CSSiriSpeechRecorder _setEndpointStyle:]
-[CSSiriSpeechRecorder _stopRecordingForEndpointReason:]
-[CSSiriSpeechRecorder eagerlyInitializeAudioRecording]
-[CSSiriSpeechRecorder preheatWithOption:]
-[CSSiriSpeechRecorder preheatWithOption:]_block_invoke
-[CSSiriSpeechRecorder recordingInfoForPreheatWithEvent:]
-[CSSiriSpeechRecorder currentVTSatScore]
-[CSSiriSpeechRecorder prepareForMode:]
-[CSSiriSpeechRecorder prepareForMode:withOptions:]
-[CSSiriSpeechRecorder startSpeechCaptureWithContext:willStartHandler:error:]
kAudioSessionProperty_ActiveSessionDisplayIDs
, playing error alert
-[CSSiriSpeechRecorder updateSpeechSynthesisRecord:]
-[CSSiriSpeechRecorder _audioSessionID]
state
v16@?0@?<v@?@"NSDictionary">8
-[CSSiriSpeechRecorder setSpeechRequestOptions:]
-[CSSiriSpeechRecorder _updateAudioContextWithInfo:reason:]
-[CSSiriSpeechRecorder _setAudioContextWithInfo:forReason:]
-[CSSiriSpeechRecorder _updateAudioContextToPostVoiceForReason:]
-[CSSiriSpeechRecorder _updateAudioContextWithPendingInfoForReason:]
-[CSSiriSpeechRecorder releaseAudioSession]
notify
suppress (keep others interrupted forever)
-[CSSiriSpeechRecorder setSpeechWasRecognizedForElapsedTime:isFinal:]
-[CSSiriSpeechRecorder setFingerprintWasRecognized]
-[CSSiriSpeechRecorder stopSpeechCaptureForEvent:suppressAlert:hostTime:]
-[CSSiriSpeechRecorder cancelSpeechCaptureSuppressingAlert:]
-[CSSiriSpeechRecorder forceSuccessAudioAlertOnStop]
-[CSSiriSpeechRecorder _speechRecordingEventListener]_block_invoke
-[CSSiriSpeechRecorder setClientConfiguration:]
-[CSSiriSpeechRecorder playRecordingStartAlert]_block_invoke
-[CSSiriSpeechRecorder _updateAudioDeviceInfo:forReason:forcesUpdate:]
Unavailable
playbackDeviceTypes
-[CSSiriSpeechRecorder _recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]
-[CSSiriSpeechRecorder speechControllerDidStartRecording:audioDeviceInfo:successfully:error:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStartRecording:successfully:error:]
Opus
Speex
-[CSSiriSpeechRecorder speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]
-[CSSiriSpeechRecorder speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]
-[CSSiriSpeechRecorder _speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:]_block_invoke_2
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]
-[CSSiriSpeechRecorder speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:]_block_invoke
-[CSSiriSpeechRecorder _speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:]
-[CSSiriSpeechRecorder getAudioRouteInstrumentationWithRecordingInfo:]
-[CSSiriSpeechRecorder speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:]
audio_recording
empty_lpcm_record_buffer
-[CSSiriSpeechRecorder _speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:]
-[CSSiriSpeechRecorder speechControllerBeginRecordInterruption:withContext:]
-[CSSiriSpeechRecorder speechControllerEndRecordInterruption:]
-[CSSiriSpeechRecorder speechControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSSiriSpeechRecorder speechController:willSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechController:didSetAudioSessionActive:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]
-[CSSiriSpeechRecorder speechControllerDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSiriSpeechRecorder _setLanguageDetectorDelegateIfRequired]
-[CSSiriSpeechRecorder _playStopAlertIfNecessaryForReason:endpointMode:error:]
AVVoice_RecordStoppedWithError
AVVoice_RecordStopped
-[CSSiriSpeechRecorder languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]_block_invoke_2
Two shot feedback
-[CSSiriSpeechRecorder speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:]_block_invoke
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]
Utterance Grading
-[CSSiriSpeechRecorder suppressUtteranceGradingIfRequired]_block_invoke
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:]
-[CSSiriSpeechRecorder speechControllerRequestsOperation:forReason:completion:]
-[CSSiriSpeechRecorder _speechControllerRequestsOperation:forReason:completion:]
v32@?0d8d16@"NSError"24
-[CSSiriSpeechRecorder speechControllerDidUpdateSmartSiriVolume:forReason:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]
-[CSSiriSpeechRecorder endpointer:didDetectStartpointAtTime:]_block_invoke
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]
time
additionalMetrics
@"NSMutableDictionary"8@?0
-[CSSiriSpeechRecorder endpointer:didDetectHardEndpointAtTime:withMetrics:]_block_invoke
-[CSSiriSpeechRecorder _hardEndpointWasDetectedWithMetrics:atTime:]
-[CSSiriSpeechRecorder _performTwoShotPromptForType:atTime:]
suppressedAlert
timedOut
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]
-[CSSiriSpeechRecorder _playPhaticWithCompletion:]_block_invoke
delegate is nil
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptTimeoutWithUUID:]
-[CSSiriSpeechRecorder _handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:]
-[CSSiriSpeechRecorder updateEndpointHintForRC:forceAccept:completion:]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted:]
-[CSSiriSpeechRecorder _checkIfLastEndpointHintShouldBeAccepted:]_block_invoke_2
v24@?0B8B12@"NSArray"16
-[CSSiriSpeechRecorder _enforceEndpointHintWithMitigation:]
-[CSSiriSpeechRecorder enforcePreviousEndpointHint]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]
-[CSSiriSpeechRecorder performBlockAfterAlerts:timeout:]_block_invoke
-[CSSiriSpeechRecorder acousticFingerprinter:hasFingerprint:duration:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]
-[CSSiriSpeechRecorder _startAudioPlaybackRequest:options:completion:]_block_invoke
-[CSSiriSpeechRecorder speakerIdentificationDidDetectSpeakerWithScores:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriSpeechRecorder audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
Siri
DictationSecureOfflineOnly
FingerprintOnly
SiriSecureOfflineOnly
SiriCoreSymptomsReporter
Class getSiriCoreSymptomsReporterClass(void)_block_invoke
void *SiriCoreLibrary(void)
yyyy_MM_dd-HHmmss.SSS
com.apple.assistant.audio-playback-service
-[CSSiriAudioPlaybackService _prewarmRequest:completion:]
-[CSSiriAudioPlaybackService _startRequest:options:preparationHandler:executionHandler:finalizationHandler:]
-[CSSiriAudioPlaybackService _handlePreparationForSession:]
v16@?0@"<CSSiriAudioPlaybackServiceListening>"8
-[CSSiriAudioPlaybackService _handleExecutionForSession:]
-[CSSiriAudioPlaybackService _handleFinalizationForSession:error:]
v32@?0@"AFAudioPlaybackRequest"8@"<CSSiriAudioPlaybackSession>"16^B24
v24@?0@"<CSSiriAudioPlaybackServiceListening>"8^B16
-[CSSiriAudioPlaybackService _evictAllReusableSessionsForReason:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerLostNotification:]
-[CSSiriAudioPlaybackService audioSessionController:didReceiveAudioSessionOwnerResetNotification:]
StartOfSpeech SPG queue
StartOfSpeech queue
-[CSStartOfSpeechDetector initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:]
-[CSStartOfSpeechDetector resetForNewRequest]_block_invoke
-[CSStartOfSpeechDetector clientSilenceFeaturesAvailable:]_block_invoke
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]_block_invoke
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCClient dealloc]
-[CSVoiceTriggerXPCClient _handleListenerEvent:]
-[CSVoiceTriggerXPCClient _handleListenerError:]
enable
assertion
timestamp
phraseSpotterBypass
bypassTimeout
raiseToSpeakBypass
triggerStats
-[CSVoiceTriggerXPCClient fetchVoiceTriggerStats]
v24@?0@"NSObject<OS_xpc_object>"8@?<v@?>16
_RegisterXPCActivity_block_invoke
com.apple.siri.xpc_activity.power-logging
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
-[CSLanguageCodeUpdateMonitorImplDarwin _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitorImplDarwin _stopMonitoring]
-[CSLanguageCodeUpdateMonitorImplDarwin _didReceiveLanguageCodeUpdate:]
-[CSAttSiriMitigationAssetHandler setCachedAsset:]_block_invoke
-[CSAttSiriMitigationAssetHandler _receivedNewAssetUpdate:]
-[CSAttSiriMitigationAssetHandler trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@, remoteDeviceUIDString = %@}
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:]_block_invoke
CSAudioConverter.m
Cannot produce ASPD for PCM
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
CreateAudioConverter
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
CSLanguageCodeUpdateMonitor.m
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor notifySiriLanguageCodeChanged:]
BuiltInMicrophoneDevice
CSVoiceTriggerEventInfoProvider Queue
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]_block_invoke
-[CSVoiceTriggerEventInfoProvider fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:]
-[NSData(Nvi) splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:]
CSSmartSiriVolumeRunPolicy queue
-[CSSmartSiriVolumeRunPolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
com.apple.corespeech.audioinjection.xpc
+[CSAudioInjectionServices setAudioInjectionMode:]
+[CSAudioInjectionServices audioInjectionEnabled]
+[CSAudioInjectionServices pingpong:completion:]_block_invoke
+[CSAudioInjectionServices pingpong:completion:]
v28@?0B8@"NSError"12@"NSUUID"20
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]_block_invoke_2
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]_block_invoke
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
v36@?0B8@"NSError"12Q20Q28
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]_block_invoke_2
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]_block_invoke_2
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withNumChannels:completion:]
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]_block_invoke_2
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke_2
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke_2
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]
Dpg:%.3f Dpd:%.3f T:%.3f
droppingPrediction
droppedPrediction
voic
carplay
hearst
raisetospeak
auto
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
detector-config
supported-locales
detector.json
sos-options.json
SPG.json
Builtin Microphone
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder userSessionActivateMonitor:didReceivedUserSessionActiveHasChanged:]_block_invoke
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke_2
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setAnnounceCallsEnabled:withStreamHandleID:]
-[CSAudioRecorder setContext:completion:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:recordDeviceIndicator:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjectionWithAVVCContext:]
-[CSAudioRecorder startAudioStreamWithOption:recordDeviceIndicator:error:]
-[CSAudioRecorder stopAudioStreamWithRecordDeviceIndicator:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
-[CSAudioRecorder recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
%llu
-[CSAudioRecorder audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:]
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
iPhone9,1
iPhone9,2
iPhone9,3
iPhone9,4
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
-[CSAudioRecorder deactivateAudioSession:streamHandleId:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckMixWithOthersForStream:duckOthers:duckToLevelInDB:mixWithOthers:]
+[CSAudioRecorder resetDuckSettings]
-[CSAudioRecorder enableMiniDucking:]
Enable
Disable
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
isBluetoothConnected
-[CSAudioRecorder voiceTriggerInfoWithRecordDeviceIndicator:]
-[CSAudioRecorder isDuckingSupportedOnCurrentRouteWithStreamHandleID:error:]
is not
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder _trackRemoteAccessoryStreamIdIfNeeded:]
-[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
-[CSAudioRecorder playAlertSoundForType:recordDevideIndicator:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _hasLocalPendingTwoShot]_block_invoke
-[CSAudioRecorder _getRecordSettingsWithRequest:]
-[CSAudioRecorder _fetchRemoteRecordClientWithDeviceId:streamHandleId:]
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@]
{isVT=%d, requestHistoricalAudio=%d, reqStartAudioSampleId=%lu, reqStartMachAbsTime=%llu}
-[NSData(XPCObject) _cs_initWithXPCObject:]
+[CSEndpointerFactory endpointerProxy]
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
+[NviSignalData headerString]
-[NviSignalData stringForLogging]
{%@:ts=%lld}
%s input dictionary is nil
%s Tagging as handheld as user interacted in last %f secs
%s Tagging as farfield as last user interaction %f secs back
%s Tagging as FarField as user dismissed
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s First Pass Score : %f, First Pass Best Start : %llu, First Pass Best End : %llu
%s Unable to write to o/p stream ! 
%s Got event! %lu
%s Got unhandled evt code %lu 
%s STDynamicActivityAttributionPublisher reporting Dictation with bundleID: %{public}@
%s STDynamicActivityAttributionPublisher reporting Siri
%s STDynamicActivityAttributionPublisher reporting Siri and Dictation
%s Start monitoring: wake Gesture
%s %{public}@ deallocated
%s audioProvider not exist
%s Start Monitoring : AudioSession notification from corespeechd
%s Stop Monitoring : AudioSession notification from corespeechd
%s reset sessionInfoProvider since xpcClient disconnected
%s CoreSpeech Daemon reset notification
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Celestial is not available on this platform.
%s notification = %{public}@
%s MobileTimer is not available on this platform.
%s Dealloc audioStreamHolding : %{public}@
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s ERR: Failed to get remote proxy object for AttSiriXPC: %@
%s _remoteSvcProxy is nil!
%s ctx=%@
%s Client Interruption Handler: %{public}@, client PID: %{public}d)
%s Client Invalidation Handler: %{public}@, client PID: %{public}d exited
%s triggerInfo: %@
%s Clearing pending homekit accessory voice trigger %{private}@
%s Handling Pending Remora VoiceTrigger Event
%s Time since last pending remora voice trigger %f. Ignoring.
%s Clearing pending built-in voice trigger %{private}@
%s Handling Pending BuiltInVoiceTrigger Event
%s Time since last pending builtin voice trigger %f. Ignoring.
%s client: %lu, deviceId: %{private}@
%s Setting mixable to yes as we are in an active call
%s Dilation factor requested for device default!
%s V Spread requested for device default!
%s V Offset requested for device default!
%s H Offset requested for device default!
%s Music steepness requested for device default!
%s Minimum TTS volume for ASV disabled case requested for device default!
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s ERR: Failed to establish XPC connection!
%s Requesting RTS %{public}@ bypass for %{public}lf seconds
%s voiceTriggerXPC client not exist
%s reset xpcClient since it disconnected
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Zero Filter Metrics: %{public}@
%s Beep Canceller Metrics : %{public}@
%s Another non eligible app is recording
%s CSBenchmarkService Interrupted
%s CSBenchmarkService Invalidated
%s XPC connection not exist?
%s Result: %@
%s Couldn't find keychain value %@ for account %@ %{public}d
%s SmartSiriVolume cannot be resumed since we should not monitor audio
%s ContinousAudioFingerprint cannot be resumed since we should not monitor audio
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s Failed to fetch local deviceId, abort
%s Sending HID report (length = %{public}lu) to host with deviceId info (%{public}@)
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s accessoryId %{private}@
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s Received active route change notification
%s Start monitoring : AudioRouteChangeMonitor
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Routed State : %{public}d
%s Notifying Siri Input Source Out Of Band State : %{public}d
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Override result as 'mpty'
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Cannot start monitoring language detector asset, since we already registered
%s LanguageDetector supported locale is nil : %{public}@
%s %p (sessionUUID = %@)
%s %p (sessionUUID = %@
%s %p
%s %p (startSpeechId = %@)
%s %p (selectedResultCandidateId = %@)
%s %p (allows = %d, resultCandidateId = %@)
%s route = %@, deviceIdentifier = %@, deviceUID = %@
%s %p (recordedAudioFileURL = %@)
%s %p (audioRecordContext = %@)
%s %p (audioRecordDeviceInfo = %@)
%s %p (voiceTriggerInfo = %@)
%s %p (recordingInfo = %@)
%s %p (recordingSettings = %@)
%s %p audioActivationInfo = %@
%s %p effectiveDate = %@ (%f)
%s %p (error = %@)
%s %p (relinquishmentContext = %@)
%s %p startRecordingAudioSessionAssertion = %@
%s %p audioActivationInfo = %@, time = %f
%s %p twoShotDetectionAudioSessionAssertion = %@
%s %p hostTime = %llu
%s %p context = %@
%s %p error = %@
%s %p (_recordedAudioFileURL = %@)
%s %p (_audioFileWriter = %@)
%s recordingSettings was nil
%s No alert behavior in recordingSettings
%s No alert style specified for record starting
%s Myriad won & voice trigger present, donating recorded audio to CoreSpeech.
%s %p No recorded audio.
%s %p Access to payload audio at %@ is %@, setting payload recording flag for CoreSpeech.
%s %p Donating recorded audio at %@...
%s %p Failed to donate recorded audio at %@ for  VoiceID training (error = %@).
%s %p Donated recorded audio at %@ for  Voice VoiceID training.
%s %p Removing recorded audio at %@...
%s %p Removed recorded audio at %@.
%s %p Failed to remove recorded audio at %@ (error = %@).
%s Creating SmartSiriVolume connection
%s SmartSiriVolume Remote Object Proxy is nil
%s SmartSiriVolume Failed to get estimate with %{public}@
%s SmartSiriVolume didChangeForReason: %{public}d
%s ERR: SmartSiriVolume Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SmartSiriVolume ssvConnection is nil
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s Listener connection disconnected
%s connection error: %{public}s
%s Required values is nil, bailout
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s Current wireless splitter info = %{public}@
%s Received WiressSplitterStateChange
%s Start monitoring : Wireless Splitter start
%s Cannot start monitoring Wireless Splitter because it was already started
%s Stop monitoring : Wireless Splitter
%s Not supported on this platform
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s Creating LanguageDetector with config: %{public}@
%s Cannot initialize language detector since model file is not exits
%s Cannot access asset : %{public}@
%s Current LanguageDetector request cancelled
%s Setting interaction ID for current request: %@
%s Failed to initialize StartOfSpeechDetector !
%s Recoreded language array: %@ Language Prior Dictionary: %@
%s Setting NumLatestLanguages to %{public}lu 
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Error writing out SoS info meta: %{public}@
%s _EARLanguageDetectorLoggingInfo = %{public}@
%s _EARLanguageDetectorLoggingInfo analytics context %{public}@
%s %{public}@ isConfident %{public}d
%s LanguageDetector State: %ld
%s Saving circular buffer from %{public}lu to %{public}lu
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s splitterState : %{public}lu, shouldDisableSpeakerVerification : %{public}@
%s This call is not supported on darwinOS device (splitterState)
%s Advert data: %{public}@
%s advert data write failed
%s %{public}.2f ms after firstBufferStart
%s Invalid timestamp (currentMachTime: %{public}llu timestamp: %{public}llu)
%s Invalid timestamp (currentMachTime: %{public}llu arrivalTimestamp: %{public}llu)
%s numOfAudioPackets: %{public}lu, numOfValidTrailingPackets: %{public}lu, numOfValidTrailingSpeechPackets: %{public}lu, 
trailingPktLatencies: %{public}@ 
trailingPktSpeechLatencies: %{public}@
%s Fetching CommandControl Listening State: %d
%s Failed to fetch recording client info, error : %{public}@
%s Start monitoring : AVVC recording client count
%s Stop monitoring : AVVC recording client count
%s Reset AVVC recording client count due to audio server crash
%s update AVVC recording client # : %{public}lu
%s Error getting file path from provided file handle; will create our own path and handle
%s Failure disposing audio file %{public}d
%s Error removing item at URL %{public}@
%s Configuring with asbd %.4s
%s Creating audio file at URL %@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s No file url on flush
%s Failed opening fd for flushed audio file %{public}s
%s inASBD->mChannelsPerFrame = %lu
%s Error getting format info for type %{public}.4s %{public}.4s
%s CoreSpeechXPCConnection Invalidated
%s making connection to corespeechd with (%{public}d)
%s Asking VoiceTrigger locale to corespeechd
%s Current VoiceTrigger Locale = %{public}@
%s Cannot get Current VoiceTrigger Locale, falling back to en-US : %{public}@
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s VoiceTriggerDuringCall enabled = %{public}@
%s VoiceTrigger during a call is already %{public}@, received duplicated notification!
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s No audioRecorder available, return nil for audioProvider
%s have matched audioProvider with stream handle id : %llu
%s provider's streamId(%tu) is invalid, return nil
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s SpeechEndEstimation: trailingSilenceDuration = %{public}f
%s SpeechEndEstimation: TrailingSilenceDuration at endpointer(%{public}f) is longer than threshold(%{public}f), force to make 0
%s SpeechEndEstimation: _lastAudioChunkHostTime = %{public}llu, estimatedSpeechEndHostTime = %{public}llu
%s Start Listening for Command Control
%s Calling didStart of CSCommandControlListener
%s Stopping stopListenWithCompletion
%s Calling didStop of CSCommandControlListener
%s Calling didStopUnexpectly
%s Received xpc disconnection, audioStream is streaming = %{public}d
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s %@
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Endpointer Failed to get epVersion
%s elapsed time = %{public}lf
%s Endpointer Failed to get elapsedTimeWithNoSpeech
%s Endpointer Failed to get endPointAnalyzerType
%s Creating RemoteServiceProxy
%s ERR: Endpointer Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: Endpointer endpointerConnection is nil
%s Endpointer didDetectHardEndpointAtTime %f withMetrics %@
%s Not supported on this platform.
%s ERR: Mach Service Name is nil - Bailing out
%s ERR: Proxy Object is nil - Bailing out
%s ERR: Exported interface is nil - Bailing out
%s Set up queue for %@
%s Started listening for %{public}@
%s Service %{public}@ dealloced - %{public}@
%s Got connection on service %{public}@
%s [Service:%{public}@] Invalid listener - %{public}@
%s Rejecting connection to %{public}@ due to entitlement
%s [Service:%{public}@] Listener Interruption Handler: %{public}@, client PID: %{public}d)
%s [Service:%{public}@] Listener Invalidation Handler: %{public}@, client PID: %{public}d exited
%s machServiceName(%@) with clientConnCount:%lu 
%s Sending message to remote object: %@
%s RemoteObjectProxy is nil for client PID (%{public}d)
%s [Service:%{public}@]
%s Using audioInjectionProvider as recorder
%s Record Context: %{public}@
%s Calling startController
%s Ignore request since it is already started
%s settings : %{public}@
%s Session Provider does not exist
%s Received special error code that corespeech needs to setContext and activate audio session again
%s CSSpeechController is already streaming audio.., we don't need to create another audio stream here
%s Prepare audio stream succeeded ? %{public}@, error - %{public}@
%s audioStreamWithRequest succeeded ? %{public}@, error - %{public}@
%s Failed to get audioStream : %{public}@
%s AudioStreamProvider is not existing?
%s Skipping audio converter setup
%s Done prepareRecord with result: %{public}@.
%s xpcClient not existing
%s received lastVoiceTriggerInfo %{public}@, lastRTSTriggerInfo %{public}@
%s ConfigSupportsDucking: %{public}d
%s Stream provider does not exist
%s Failed due to error %@.
%s Activating Audio Session Now Sync.
%s Activating Audio Session Now Async.
%s Device supports ducking on speaker output we should check config.
%s StreamProvider is already recording
%s duckingDelayedTime = %{public}f, timeIntervalSinceLastTriggerEnd = %{public}lf
%s Failed activate audio session with %{public}f seconds delay from prepareRecordWithSettings due to error %{public}@.
%s Finished activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Cancelled activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Scheduled activateAudioSession with %{public}f seconds delay in prepareRecordWithSettings.
%s Delayed active audio session: Consumed token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed active audio session: Activating audio session for reason %{public}@.
%s Delayed active audio session: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed active audio session: Successfully activate audio session for reason %{public}@.
%s Delayed active audio session: Ignored activating audio session for reason %{public}@ because the validator rejected.
%s Delayed active audio session: Ignored activate audio session for reason %{public}@ because the scheduled token %{public}@ does not match the current token %{public}@.
%s Delayed active audio session: Scheduled new token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed audio session activate: Cancelled token %{public}@ for reason %{public}@.
%s Delayed audio session activate: Consumed token %{public}@ in advance for reason %{public}@.
%s Delayed audio session activate: Activating audio session for reason %{public}@.
%s Delayed audio session activate: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed audio session activate: Successfully activate audio session for reason %{public}@.
%s Creating fake session activation notification for session activation now
%s Scheduling Lazy Audio Session activation with %f timeout
%s Lazy session activate success
%s Lazy Audio Session is not configured.
%s Creating fake session activation notification for session activation failure : %{public}@
%s Activating audio session now
%s AudioSession activated successfully ? %{public}@
%s AudioSession Provider not available
%s Falling back to button record type for context whose record type previously is set to unspecified for accessory %{private}@.
%s recordContext : %{public}@
%s Will skip setting current record context because we were in active call and context was post or auto
%s Resetting CoreSpeech frameworks
%s Ask start recording with requestMHUUID: %@
%s Disable audio converter since local asr is going to be used
%s Enable audio converter
%s Disable prewarming local asr at startRecording
%s TriggerlessDictation: Ask start recording from: %{public}tu
%s Ask start recording from: %{public}tu
%s Voice trigger to use the current voice triggered channel: %{public}tu
%s Auto prompt to use the last voice triggered channel: %{public}tu
%s SpeechController to receive data from default channel
%s SpeechController to receive data from channel %{public}tu
%s Trying to prepare uncompressed audio logging
%s Local ASR is used, uncompressed audio logging is disabled
%s Ask delay audio session active by %{public}f seconds
%s Postpone calling audio session activation til we receive didStart
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@, audioDeviceInfo = %{public}@
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@
%s Report unexpectedly long launch latency %{publlic}.3f
%s audioStream not existing
%s _activateAudoiSessionWithDelay has failed. startRecordWithSettings has failed
%s Start recording invoked too late (%{public}.3f seconds), override scheduledCheckTime: %{public}llu to currentTime: %{public}llu
%s Scheduled audible feedback decision after %{public}.3fseconds (vtEndMachTime: %{public}llu currentMachTime: %{public}llu)
%s Two shot audible feedback decision not needed since we already stopped recording
%s Two shot audible feedback decision (%{public}.3fs later than the scheduled time), elapsedTimeWithNoSpeech: %{public}.3f
%s Two shot audible feedback is %{public}@needed. (isMediaPlaying = %{public}d, canPlayPhaticDuringMediaPlayback = %{public}d)
%s Two shot audible feedback should notify? [%{public}@]
%s Two shot audible feedback is prevented by Myriad decision.
%s Two shot audible feedback decision timed out while waiting for Myriad decision
%s Audible feedback not needed since we already stopped recording
%s Audible feedback decision elapsedTimeWithNoSpeech: %{public}.3f
%s Notifying scheduled audible feedback playback...
%s Failed to playback audible feedback, error: %{public}@
%s Asking stopRecording when audio stream is not existing
%s Options: %{public}@ at: %{public}llu
%s Reporting didDeliverLastPacket at: %{public}llu
%s SpeechEndEstimation: %{public}llu
%s Scheduling StopRecording After HostTime=%{public}llu
%s %{public}@
%s Reason : %{public}ld
%s SpeechEndEstimation: Should Estimate SpeechEndHostTime
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu, audioDeviceInfo: %{public}@
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu
%s Currently playing App : %d
%s name : %@, version : %@
%s _didDeliverLastPacket=%d. Dropping Audio packets of size=%lu
%s chunk.hostTime=%{public}llu, chunkSz=%{public}lu, stopOptions=%{public}@, _numTrailingSamplesAfterSchedulingStop=%{public}lu, maxAllowedSamples=%{public}lu
%s STOPRECORDING: Reached MAX allowed trailing samples AFTER stopRecording was scheduled!
%s STOPRECORDING: chunk.hostTime=%{public}llu >= stopOptions=%{public}@
%s SpeechManager still forwarding audio after didStopForwarding, we shouldn't have this
%s STOPRECORDING: chunk.endHostTime=%{public}llu >= stopOptions=%{public}@
%s AudioProvider is invalidated, teardown connection to audioprovider
%s Ignore session active notification
%s SmartSiriVolume update reason: %lu
%s SpeechController is trying to forward encoded audio after didStopForwarding, we shouldn't have this
%s Setting Alert Sounds From : %{public}@ for AlertType : %{public}d, force : %{public}@
%s Creating Audio Power Meter with record route %{public}@
%s We don't need Audio Power Meter with record route %{public}@
%s Not available
%s Reported 2-shot at: %{public}f secs
%s _delegate doesnt respond to speechControllerDidDetectVoiceTriggerTwoShot
%s Requesting QuickStop operation upon detecting keyword
%s _endpointId: %@, _rcHandlingClient: %@, languageCode: %@
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Creating xpcClient
%s Unable to setup audioProvider
%s Establishing xpcClient connection...
%s Unable to prepareAudioProvider in _xpcClient, teardown XPC connection again
%s endpointerModelVersion called when HEP is not supported
%s return hybrid model version for sirix request
%s Queried endpointerModelVersion: %{public}@
%s Cancelling current language detector request !
%s Received Myriad started
%s Received Myriad finished with decision: %tu
%s Detected sound is%{public}@ playing: media(%d) alarm(%d) timer(%d)
%s XPCConnection disconnected
%s reset audioProvider since xpcClient disconnected
%s Playback is active: %{public}d on accessory: %{private}@
%s Alarm is playing: %{public}d on accessory: %{private}@
%s Timer is playing: %{public}d on accessory: %{private}@
%s Now Playing State has changed %d
%s Alarm firing
%s Alarm dismissed
%s Timer firing
%s Timer dismissed
%s SSR Remote Object Proxy is nil
%s Successfully created SSR connection
%s ERR: SSR Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SSR ssrConnection is nil
%s scoreCard is nil!
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%s request = %@, options = %@
%s prepared
%s Player item %@ status is failed with error %@.
%s Created player item %@ from URL %@.
%s Created player item %@ from WAVE asset with %tu bytes of data .
%s Unable to create player item.
%s Created player %@.
%s Unable to replace current item of player %@. Expected current item is %@, actual current item is %@.
%s Player item %@ status is ready to play.
%s Timed out when waiting for player item %@ status to change to ready to play.
%s Successfully changed player item %@ status to ready to play.
%s Failed to change player item %@ status to ready to play due to error %@.
%s Attempted to start %@ when it is already active.
%s Failed to prepare %@ due to error %@.
%s Failed to start %@ because it is already inactive after preparation.
%s Failed to start %@ because it is already inactive after player seek to begin.
%s Failed to start %@ because player failed to seek to begin.
%s started
%s error = %@
%s Reset player item %@.
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s CSVoiceTriggerAsset found: %{public}@
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s Start Recording Host Time = %{public}llu
%s %p created
%s %p dealloced
%s sp=%p
%s %@ not supported yet.
%s Failed to create: %@
%s SigPrvdrs: %@
%s Starting datasrc: %@
%s Failed to start %@. Err=%@
%s >>> All DataSources Started within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources Start timedout. timeout=2secs
%s Starting signal provider: %@
%s Failed to start %@: Err=%@
%s >>> All SignalProviders didStart within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStart. timeout=2secs
%s >>> All DataSources Stopped within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources timedout stopping. timeout=2secs
%s Failed to stop %@: Err=%@
%s >>> All SignalProviders didStop within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStop. timeout=2secs
%s WARN: Cannot find SignalProvider for %@. Skipping
%s Initializing new xpcConnection
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s xpcConnection not exist
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending AcousticSLResult request
%s Failed to get AcousticSLResult reply
%s Received AcousticSLResult %{public}@
%s Failed to parse AcousticSLResult from raw data
%s Message not valid
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s Not implemented
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s xpcConnection not existing
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s context : %{public}@
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s ::: incrementing false wakeup to %{public}llu
%s PowerLog : HeySiriFalseTrigger numFalseWakeUp:%{public}d, secondsSinceLastReport:%{public}lf, phrase:%{public}@
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report with current phrases %{public}@
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Automatic Volume State changed to %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Closing file at URL %{public}@, audio size: %{public}u
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s Received notification %@
%s Failed to register for notification %@ (status=%d)
%s SmartSiriVolumeContextAware TTS volume post lower and upper bounds is: %f
%s TTS volume offset post lower and upper bounds is: %{public}f
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: assetType: %{public}lu
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Overriding Myriad state as request was made during a ringtone
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Cannot notify wake keyword spoken event : %{public}@
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm success
%s AFSiriActivationCarPlayDeviceVoiceTriggerPrewarm failed : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s Invoked Siri client for voice trigger from Darwin
%s Cannot invoke Siri client for voice trigger from Darwin : %{public}@
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s ::: Error creating output file %{public}@, err: %{public}d
%s ::: Error writing to output wave file. : %{public}ld
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since there is other app recording that is not eligible and we are not in a connected or outgoing call
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s Successfully ? %{public}@
%s Notify release of audio session
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s CSSpeechUaapXPCClient received an empty connection event
%s CSSpeechUaapXPCClient got an event it can't handle
%s CSSpeechUaapXPCClient listener disconnected
%s CSSpeechUaapXPCConnection error: %s
%s Invalidating CSSpeechUaapXPCClient
%s CSVoiceTriggerAsset (%{public}@) found: %{public}@
%s Cannot get a VoiceTrigger mobile asset : %{public}@
%s Trial assets not available, fallback to MA assets
%s First unlock notification received : %{public}d
%s Ignore Trial asset update for type: %lu
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VAD is not present or Hearst routed without phone call
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s CarPlay is connected, we will still run AOP mode
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since siri is in attending state
%s Turn on AP mode since device has ringtone through hfp, connected, or outgoing call.
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s %p speechRecordingMode = %zd, clientConfiguration = %@
%s %p speechRequestOptions = %@, currentActivationInfo = %@
%s activeMediaPlaybackVolume = %f
%s clientConfiguration = %@
%s announcement platform is hearing aids or built in speaker, using CSAudioRecordTypeHomePress
%s recordRoute = %@, playbackRoute = %@
%s Requesting historical buffer of duration %lf seconds
%s recordRoute = %@, playbackRoute = %@, attemptsToUsePastDataBufferFrames = %d
%s alertBehavior = %@
%s AppleTV (isVoiceOverTouchEnabledInAccessibility = %d)
%s HomePod
%s BT Voice trigger during incoming/active phone call
%s Built-in Voice
%s Dictation (deviceRingerSwitchState = %@)
%s Triggerless
%s CarPlay Button Press (recordRoute = %@)
%s Bluetooth Voice Trigger
%s Bluetooth Direct Trigger
%s Car DoNotDisturb
%s VoiceOver Enabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Accessibility Vibration Disabled (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Overriding default behavior, playing beep because of custom sound ID
%s Playback Route is Hands-Free (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s No Vibration Support
%s Others (activationMode = %.4s, speechEvent = %ld (%@), recordRoute = %@)
%s Others (deviceRingerSwitchState = %ld (%@))
%s alertStyle = %ld
%s targetDate = %@ (%f)
%s timeInterval = %f
%s voiceTriggerEndHostTime = %llu
%s buttonDownHostTime = %llu
%s activationHostTime = %llu
%s activationSystemUptime = %f
%s date = %@ (%f)
%s Overriding default behavior to play beep because of custom sound ID
%s Voice Feedback -> PresentationModeVoice
%s Voice Feedback -> PresentationModeSilent
%s Voice Feedback -> None
%s Voice Feedback -> Control with Ring Switch (deviceRingerSwitchState = %ld (%@))
%s Voice Feedback -> Always On
%s Voice Feedback -> Hands-Free Only
%s Voice Feedback -> Unknown
%s audioSessionActiveDelay = %@ (Triggerless Listening)
%s audioSessionActiveDelay = %@ (Audio Session Coordination)
%s audioSessionActiveDelay = %@ (User Perception)
%s audioSessionActiveDelay = %@ (Hearst Voice)
%s audioSessionActiveDelay = %@ (Built In Voice)
%s audioSessionActiveDelay = %@ (Others)
%s audioSessionActiveDelay = %@
%s mediaPlaybackVolumeThreshold = %@
%s audioSessionActiveDelay = %@ (Above Media Playback Volume Threshold)
%s audioSessionActiveDelay = %@ (Default)
%s %{private}@
%s WARN: Invalid sigType: %lu
%s Unknown DataSrc Type: %{public}lu
%s Unknown DataSrcTypeStr(%{public}@)
%s Failed to create dir at: %{public}@
%s Could not find <%{public}@> in Keypath=%{public}@
%s Creating audio player...
%s Failed to create audio player due to error %@.
%s Created audio player %@ with audio session %@.
%s Reused audio player %@ with audio session %@.
%s Audio player %@ is already prepared to play.
%s Preparing audio player %@ to play...
%s Failed to prepare audio player %@ to play.
%s Prepared audio player %@ to play.
%s request = %@
%s Ignored because the session is already active.
%s Ignored because the audio player is already playing.
%s Asking audio player %@ to play...
%s Failed to play audio player %@.
%s Started playing audio player %@.
%s request = %@, immediately = %d
%s Stopping audio player...
%s Ignored because there's no audio player to stop.
%s _request = %@
%s Ignored because there's no audio player to pause.
%s _request = %@, shouldResume = %d
%s Ignored because there's no audio player to resume playing.
%s request = %@, error = %@
%s Ignored because there's no audio player to destroy.
%s request = %@, player = %@, success = %d
%s request = %@, player = %@, error = %@
%s ContinousAudioFingerprint cannot be turned on since Siri is disabled
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s Received RC with id: %lu, duration: %f, lrnnScore: %f, lrnnThreshold: %f, taskId: %@, forceAccept: %d
%s Getting mitigation decision for rdId: %lu
%s ERR: RC Processing Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: RCProcessing rcProcConnection is nil
%s ERR: Failed to get TTS Volume
%s Estimated TTS volume : %{public}f
%s SmartSiriVolume not available
%s Notifying SSV Client on Volume change for reason - %{public}d
%s Dropped SSV Client notification for Volume change with reason - %{public}d
%s EarlyDetectSample = %{public}d
%s PHS threshold for %lu doesn't exist, use default
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
%s primaryStream already torn down
%s Updating attSiri state to: %lu
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s Triggering acoustic data sync with peer - %@
%s Triggering gecko sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Unable to get %@ for file at %@: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Grading log file successfully transfered for file %@ in task %@
%s Grading log file failed to transfer for file %@ in task %@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s Error setting remoteP2Plog file to NSFileProtectionCompleteUntilFirstUserAuthentication. file=%@ Err=%@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s Skipping post build activity on ATV
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Already started listen polling, skip
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s Siri enabled : %{public}d
%s stream stopped unexpectedly : %{public}ld
%s Mediaserverd/bridgeaudiod recovered from crash
%s Failed to fetch speaker state muted info, error : %{public}@
%s Queried built-in speaker mute state as %{public}@
%s Timed-out for fetching speaker state muted info, setting isMuted = YES
%s Failed to fetch builtIn speaker active state, error : %{public}@
%s Queried built-in speaker state as %{public}@active
%s Timed-out for fetching speaker state active info, setting speakerStateActive = NO
%s Speaker state changed : %{public}@
%s Failed to get speaker state from AVVC, default to inactive
%s Speaker mute state changed: %{public}@
%s Failed to enable speakerStateListening: %{public}@
%s Start monitoring : Speaker state from AVVC
%s Failed to disable speakerStateListening: %{public}@
%s Stop monitoring : Speaker state from AVVC
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Start monitoring : SACInfo
%s Stop monitoring : SACInfo
%s Device is in stereo mode : %{public}@
%s vibration state fetched from CFPreferences is NULL, using On as default value
%s ::: NVI logging initialized
%s Received external route change notification
%s Received external pickable route change notification
%s Received CarPlay AuxStream support change notification
%s Received CarPlay connection change notification
%s Notifying Hearst Connection State : %{public}d
%s Notifying Jarvis Connection State : %{public}d
%s Automatic Volume Toggled. Automatic Volume Enabled: %{public}d
%s No SACodec for settings %{public}@
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s endpointerModelVersion is still nil after fetching it from EAREndpointer
%s Updated endpointer threshold: %{public}f
%s Updated endpointer delayed trigger: %{public}d
%s setEndpointerOperationMode : %{public}d
%s current EndpointerOperationMode : %{public}d
%s update endpointer threshold to %{public}f for task %{public}@
%s EARSPG: CSServerEndpointFeatures: %{public}@
%s isASRFeatureFromServer = %{public}d
%s Accepting RC: RCTime < 0: Server's processedAudioDuration(%{public}f) > _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s Rejecting RC: SFLatency < 0: Server's processedAudioDuration(%{public}f): _lastReportedEndpointTimeMs(%{public}f): sfLatency: %{public}f, rcTimeMs: %{public}f
%s rcEpFeatures: %{public}@ shouldAccept: %{public}d
%s first audio buffer host time: %{public}llu
%s Detected speech start at %{public}f of effectiveClientProcessedAudioMs
%s Already communicated end-pt: Not Invoking hybridClassifier for silposnf=%{public}f
%s ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
%s ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
%s ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
%s ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
%s ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
%s HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f] @ %{public}lu [%{public}f, %{public}d]
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, anchorhostTime=%{public}llu, endpointSampleCount=%{public}llu, numSamplesProcessedBeforeAnchorTime=%{public}lu, isAnchorTimeBuffered=%{public}d
%s request timeout with features %{public}@
%s ServerFeaturesLatencyDistribution: %{public}@ additionalMetrics: %{public}@
%s MMEP:: HEP detected at %{public}f but will continue running for MMEP.
%s Already communicated end-pt: Not scheduling work for hybridClassifierQueue for silposnf=%{public}f
%s Log hybrid endpointer features for event: %{public}@, and locale: %{public}@
%s triggerEndSeconds: %{public}f, _vtEndInSampleCount: %{public}lu, _vtExtraAudioAtStartInMs: %{public}lu,  _hepAudioOriginInMs: %{public}f, voiceTriggerInfo: %{public}@,
%s CSHybridEndpointer recordingStoppedForReason: %{public}ld
%s sampleRate=%{public}lu, recordContext=%{public}@
%s CSEndpointAsset exists: %{public}@
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to NNVAD
%s Created HybridClassifier(%{public}@); canProcessCurrentRequest after reset: %{public}d,for sampleRate: %{public}lu, lang=%{public}@, version=%{public}@
%s HEP.logs.hdr: [ServerASR_trailingSilenceDuration,ClientSPG_SilenceFramesCountMs,ServerASR_endOfSentenceLikelihood,ServerASR_wordCount,ServerFeaturesLatency,ClientSPG_SilenceProbabilityHMMFiltered] & [ServerASR_pauseCounts,ServerASR_silencePosterior,ClientSPG_silenceProbailitySPGRaw] @ effectiveClientProcessedAudioMs : [HEPPosteriorOut,HEPDecision]
%s csHepConfig: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d, _extraDelayFrequency: %{public}lu, _taskThresholdMap: %{public}@
%s update assets to: %@
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Start audio stream successfully ? %{public}@, error : %{public}@, startRecordingSampleCount=%lu
%s Stopped audioStream with result=%d, err=%@
%s audioProvider == nil, error : %{public}@
%s provider: %{public}@, unexpectedStop: %{public}ld
%s Device is firstUnlocked. Fetching HEP assets
%s Device is NOT firstUnlocked. Will fetch assets after firstUnlock
%s Language changed to: %{public}@
%s New hybrid endpoint asset downloaded
%s FirstUnlock notification received: %{public}d
%s Bypass Trial Asset
%s Failed to get HEP asset
%s HEP Asset: %{public}@, path: %{public}@
%s installationString: %@, for language: %@
%s File not exist: %{public}@
%s endpointAsset: %{public}@, osdAsset: %{public}@
%s elapsed time to get HEP mobile assets: %{public}lf
%s Fake endpoint asset: %@
%s _requestMHUUID: %@, _turnIdentifier: %@
%s _userSpeakingStartedTimeInMs %{public}f, _userSpeakingEndedTimeInMs: %{public}f, _userSpeakingStartedHostTime: %{public}llu, _userSpeakingEndedHostTime: %{public}llu, _stopRecordingHostTime: %{public}llu, _endpointBufferHostTime: %{public}llu
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s Error reading audio file: %{public}d, skipping...
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s token:%d
%s fromState:%llu, toState:%llu
%s SiriState - isActiveSession:%d
%s SiriState - isActiveRequest:%d
%s SiriState - isListening:%d
%s SiriState - isSpeaking:%d
%s tts Finished:%u
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Replace deviceId(%{public}@) to nil for VoiceTrigger from Gibraltar.
%s Hang up toggle: %d
%s VoiceTrigger cannot be turned on since we are not in the desired call state
%s VoiceTrigger cannot be turned on since we are in a hang up supported call state but it is not first party.
%s VoiceTrigger cannot be turned on because we are in a ringtone and hsPhoneCallCapableHeadsetConnected: %d builtInState: %d isInSplitterMode: %d
%s Queue %@ is already being observed.
%s queue = %@
%s queue = %@, numberOfOccurrences = %tu
%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu
%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldestSampleInBuffer: %{public}lu, latestSampleInBuffer=%{public}lu
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s Delivering didStop to %{public}lu tandem stream(s)
%s AudioStream<%{public}@> is streaming : %{public}d
%s Stream %{public}@ set startTimeInSampleCount : %{public}llu
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Input route changed
%s Output route changed
%s Failed getting audio property %{public}.4s %{public}d
%s Failed getting audio property size %{public}.4s %d{public}
%s Failed registering for property listener %{public}.4s %{public}d
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s Received a request for VoiceTrigger Asset for language code : %{public}@
%s Fake Model Path does not exist : %{public}@
%s fake model meta json does not exist : %{public}@
%s Unable to read fake model meta json : %{public}@
%s Unable to parse fake model meta json : %{public}@
%s Loading FakeModel : %{public}@
%s Cannot create RTModel from %{public}@
%s fake model number(%{public}d) is less than minimum fake model number((%{public}d)
%s Using fake model for the first time : %{public}@
%s Using fake model : %{public}@
%s %{public}@ fake model is selected for download
%s %{public}@ model is selected for fallback
%s Received a request for VoiceTriggerRTModel %{public}@ Firmware Version : %{public}d.%{public}d
%s Asking mobile asset with currentLanguageCode = %{public}@
%s DownloadModel : 
%s preinstalledModels : 
%s Hearst Fake Model request switch turned on, executing stress test mode with fakeModelPath : %{public}@
%s VoiceTriggerAsset is not available : %{public}@
%s Queried model for language:%@ path:%@ configVers:%@ model:%@
%s rtLocaleMap is nil fallback to embedded locale map
%s accessoryRTBlobs are not available for the version(%{public}d.%{public}d) and locale:%{public}@, returning fallback model : %{public}@
%s Hash matched with downloadedModel : %{public}@, accessory will select this model
%s Hash matched with preinstalledModel : %{public}@, accessory will select this model
%s Ask for download : %{public}@, and use %{public}@ as fallback
%s Select keyword language as %{public}@, error : %{public}@
%s Language list and jarvis language not provided
%s current Siri language code : %{public}@
%s Jarvis locale map is nil, fallback to embedded locale map
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Initializing CSRawAudioInjectionProvider
%s Done initializing CSRawAudioInjectionProvider
%s Dealloc CSRawAudioInjectionProvider
%s Calling StreamId for : %@
%s Calling prepare
%s Calling start audio stream : %@
%s Calling stop audio stream
%s Calling isRecording
%s Calling prewarm
%s Calling activate audio session
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s Reset recordDeviceIndicator as we have new audioRecorder
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s Attached stream %{public}@ as tandem to master stream %{public}@ %{public}@, error : %{public}@
%s PrimaryStream is already tandem of stream %{public}@, can't add mutual tandem relation here!
%s Invalid input streams
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Create circular buffer : numChannels(%d), duration(%f)
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@, request : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s Start deliver historical audio buffer immediately
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s Calling unexpected didStop for all weak streams
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:shouldDuckOnBuiltInSpeaker: %{public}@ (audioStreamType: %{public}lu, isPlaybackRouteBuiltInSpeaker: %{public}@, isDuckingOnSpeakerOutputSupported: %{public}@)
%s Failed to fetch duckingSupported result : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s Unable to disable duckOthers in HomePod
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Not handled by this function
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s Forward %d samples from historical audio buffer
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Audio Packet Delivery WatchDog fired, trying to recover
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s Update remote deviceUId fetched from AVVC : %{public}@ (this must be deviceUID of Darwin device only)
%s Failed to fetch remote deviceUId from AVVC
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Hey Siri is enabled. Checking if we are in a call.
%s Hey Siri is disabled. Not checking if we are in a call.
%s Listening on watch cannot be turned on since Siri assertion is disabled and or its not in a ringtone hfp state
%s Listening on watch cannot be turned on since audioInjection is enabled
%s Listening on watch cant be turned on because we are in a ringtone with A2DP, connected or outgoing call
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Failed to fetch listeningEnabled : %{public}@
%s listening property in AOP : %{public}d
%s Failed to fetch listeningEnabledOnNotification : %{public}@
%s Stop monitoring : AOP Listening state
%s Received AOP Listening state change notification : %{public}d
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Send a In-Ear Myriad notification
%s Unsupported protocol for this device
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously: Not queueing
%s HEP::RecordingDidStop: Ignoring processAudioSamplesAsynchronously
%s addAudio first sample offset: %{public}lu
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable, Not queuing
%s HEP::RecordingDidStop: Ignoring silenceScoreEstimateAvailable
%s HEP.posterior=%{public}f, result=1, endpointedBuffer.hostTime=%{public}llu, isAnchorTimeBuffered=%{public}d
%s CSHybridEndpointAnalyzer recordingStoppedForReason: %{public}ld
%s No asset for CSHybridEndpointer for currentLanguage: %{public}@. Fallback to VAD2
%s Created OSDAnalyzer: %{public}@
%s _clientHepConfig: %{public}f, _clampedSFLatencyForClientLag: %{public}f, _useDefaultServerFeaturesOnClientLag: %{public}d
%s _currentAsset changed to : %{public}@
%s Session Query Failed : %{public}@
%s Mediaserverd/bridgeaudiod crashed
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Endpointer is disabled in recordOption: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s EP_PROXY::RecordingDidStop: Ignoring startPoint-reporting
%s EP_PROXY::RecordingDidStop: Ignoring didDetectHardpoint-reporting
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s Skip update endpointer threshold from server for accessible endpointer request
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s Detaching from session %p
%s Already attaching to session!
%s Attaching to session
%s Failed attaching to bt session %d
%s session = %p, result = %d
%s Session is NULL.
%s Failed getting default local device from session %p (result = %d).
%s Failed adding callbacks to local device %p from session %p (result = %d).
%s localDevice = %p, event = %d, result = %d
%s Failed getting default accessory manager from session %p (result = %d).
%s Failed adding callbacks to accessory manager %p from session %p (result = %d).
%s accessoryManager = %p, accessoryEvent = %d, device = %p, state = %d
%s Failed getting device address from string %d
%s Failed getting device from address %d
%s BTDevice %p for address %@
%s BTAccessoryManager %p
%s Failed getting device from deviceUID %d
%s BTDevice %p for deviceUID %@
%s BTLocalDevice %p
%s Loading device info for %@...
%s Loaded device info %@ for %@.
%s Using slow path...
%s Slow path took %f seconds.
%s Slow path timed out after 4 seconds.
%s Method not supported
%s Reloading device info for %@...
%s Reloaded device info %@ for %@.
%s deviceInfo = %@
%s deviceInfo changed from %@ to %@
%s Fetching device info for %@...
%s Fetched device info %@ for %@.
%s Getting BTDevice and BTAccessoryManager for %@...
%s Got BTDevice %p and BTAccessoryManager %p for %@.
%s Device UID and address of %@ are nil.
%s Data source of %@ is nil.
%s Failed getting BTDevice and BTAccessoryManager for %@.
%s Failed getting address from BTDevice %p (result = %d).
%s Failed getting vendor id and product id from BTDevice %p (result = %d).
%s Failed getting InEar capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting DoAP capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting ANC capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Transparency capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Software Volume capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Messages capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Failed getting Announce Calls capability from BTDevice %p via BTAccessoryManager %p (result = %d).
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Stop monitoring : First unlock
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s Created VoiceIdXpc connection
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Null msg body
%s Null VTEI
%s Null Ctx
%s Null deviceInfo
%s Null audio context
%s Received msg of type %{public}lld for utt %{public}@
%s Fetched latest VT asset %@ for retraining
%s Implicit utterence processing done with error %{public}@
%s Cannot retrain since we cannot look-up SSR asset with error %@
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Failed to initialize caesuraSPG, stopping monitoring
%s Start monitoring : EARCaesuraSilencePosteriorGenerator: %{public}@
%s deallocating EARCaesuraSilencePosteriorGenerator: %{public}@
%s Stopped monitoring : EARCaesuraSilencePosteriorGenerator
%s EARClientSilenceFeatures heartbeat = %{public}lld,                   silScoreEstimate = %{public}f
%s Stop monitoring : HomePod voiceTriggerAssertion
%s Setting sample rate to %d
%s Could not make Fingerprinter decoder: %{public}.4s
%s Error during conversion for fingerprinter %{public}.4s
%s Getting signature for duration %lf
%s Fingerprinter doesn't support rate %{public}ld
%s Set initial info as current %@.
%s Assign new MHUUID here to %@ (force = %@)
%s mode = %ld
%s endpointerOperationMode = %@, forceUpdate = %d
%s Ignored because endpointer operation mode is unspecified.
%s Ignored because endpointer operation mode can not be changed from %@ to %@.
%s Set Use Automatic Endpointing %d
%s Setting up recording alerts for Dictation.
%s Done setting recording alerts for Dictation.
%s Setting up recording alerts for Siri and other non-Dictation modes.
%s Done setting recording alerts for Siri and other non-Dictation modes.
%s Overriding record starting alert for IFD feature group one.
%s Done overriding record starting alert for IFD feature group one (soundURL = %@).
%s Failed overriding record starting alert for IFD feature group one.
%s Done overriding record starting alert from override policy (soundURL = %@).
%s Failed overriding record starting alert from override policy.
%s Trying to set record buffer duration to %lf
%s Failed setting record buffer duration. Duration is %{public}lf
%s Initalizing speech controller with context %@
%s Set pending info as current %@.
%s Done initializing voice controller
%s Preparing CSSpeechController with settings %@
%s Error setting up CSSpeechController %{public}@
%s Done preparing CSSpeechController
%s reason = %d, speechEvent = %zd (%@), hostTime = %llu
%s reason = %d, hostTime = %llu
StopRecording
SpeechRecorder
%s Really stopping recording
UsefulUserFacingResults
%s Someone else has already asked to stop recording.%@
%s Sending stop recording immediately because CSSpeechController isn't recording
%s recordingState = %zd, context = %@
%s Playing alert %ld
%s Checked audio logging limits, count = %d -> %d
%s An item already exists at path %@, but it is not a directory.
%s Failed to create directory at path %@ due to error %@.
%s info = %@, context = %@
%s Created _audioFileWriter %@.
%s Did not create _audioFileWriter because audioFileType = %ld.
%s supportsVoiceIdentificationTraining = %d
%s supportsSpeechExtraction = %d
%s supportsSpeechLogging = %d
%s Configure _audioFileWriter with recordSettings = %@.
%s Ask context %@ to configure and record with recordSettings = %@.
%s Acquired recorded audio for speech logging: %@
%s Speech Log: %@
%s Unable to save recorded audio for speech logging due to error %@.
%s Skipped saving recorded audio for speech logging due to audio logging limit.
%s Unable to prepare directory for speech logging.
%s Unable to acquire recorded audio for speech logging.
%s Done
%s %ld
%s Ignoring unexpected stop recording while in state %ld
%s Prewarming audio session in speech controller
%s Done prewarm audio session in speech controller
%s Prewarming start alert
%s Failed to prewarm start alert due to %@
%s Done prewarming start alert
%s Preparing instead of preheating since we're not in the default mode
%s Preparing speech capture for %@
%s context:%@, _currentActivationInfo :%@
%s Using Bluetooth audio analyzer style
%s Using driving audio analyzer style
%s Using voice trigger audio analyzer style
%s Using default audio analyzer style
%s Suppressing start alert
%s Playing start alert %@
%s No SoundID URL
%s No start recording alert
%s entering _recordingWillStartGroup
%s Setting delayed start delay %lf
%s Asking CSSpeechController to startRecording with settings %@
StartRecording
%s Done asking CSSpeechController to startRecording
%s context = %@
%s leaving _recordingWillStartGroup
%s Could not set up recording (prepared = %d, started = %d), returning error %{public}@%{public}@ and resetting voice controller.
%s Updated speech synthesis record from %@ to %@.
%s Fetching audio session ID...
%s Done fetching audio session ID %lu.
%s endpointerOperationMode = %@
%s Fingerprinting mode, force (endpointerOperationMode = %@).
%s Legacy property set (useAutomaticEndpointing = %d), override (endpointerOperationMode = %@)
%s info = %@, reason = %@
%s Dropping previous pending activation info %@ for reason %@.
%s Setting audio context %@ for reason %@.
%s Error setting audio context %@ for reason %@ error %{public}@. (%f seconds)
%s Done setting audio context %@ for reason %@. (%f seconds)
%s Ignored setting audio context because there's no speech controller.
%s Updating to post voice for reason %@.
%s Updating using pending info %@ for reason %@.
%s Attempting to release audio session while CSSpeechController is still recording.
%s releaseAudioSessionBehavior = %s
%s Resetting to default audio context on session end
%s %lf %lf
%s Endpointer setStartWaitTime is set to %{public}f
%s (event = %ld, suppressAlert = %d, hostTime = %llu)
%s (suppressAlert = %d)
%s Begin updating audio device info %@. (reason = %@, forcesUpdate = %d)
%s Fetching audio device info from CSSpeechController...
%s Done fetching audio device info from CSSpeechController.
%s End updating audio device info %@. (duration = %f)
%s Creating recording info (speechEvent = %ld (%@), audioAlertStyle = %ld, includeBTInfo = %d, includeRecordDeviceInfo = %d)
%s alertStartTime = %llu
%s Done creating recording info %@.
%s Got a speech start failure after we already got audio buffers?!
AudioStart
%s success = %d, error = %@
%s isTwoShot = %d
%s SPELLING recordSettings codec=%@
%s Sending speech did start to delegate %@
%s Resetting VoiceController on startRecording failure
%s reason = %ld, estimatedSpeechEndHostTime = %llu
%s Synthesizing a didStart callback, on missing didStart
AudioStop
%s reason = %ld, estimatedSpeechEndHostTime = %llu, errorCodeOverride = %ld, underlyingError = %@
%s Ignoring unexpected didStop callback while in state %ld
%s Starting new recording for two shot mode
%s Failed starting recording for two shot mode
%s audioMetrics = %@
RecordBufferAvailable
%s buffers.count = %llu, durationInSec = %f, bufferStartHostTime = %llu
RecordBufferHandleBegin
%s Dropped %f seconds of audio buffers recorded at %llu (%f seconds) due to audio recording restriction (accumulatedBufferDuration = %f seconds).
RecordBufferHandleEnd
%s firstBufferStartHostTime = %llu, firstBufferReceiptHostTime = %llu
%s Getting audio route instrumentation with recording info %@...
%s Done getting audio route instrumentation %@.
%s LPCM record buffer is empty.
%s reason = %zd, estimatedSpeechEndHostTime = %llu, isRecordingStopped = %d
%s Ignoring unexpected last buffer callback while in state %ld
%s Ignoring unexpected last buffer callback without first buffer.
%s %d
%s type = %ld, error = %@
%s type = %ld
%s alertPlaybackGroup is nil.
%s numberOfAVVCAlertPlaybacksByType does not have AVVC alert playbacks of type %ld.
%s numberOfAVVCAlertPlaybacksByType is nil.
%s Language detection delegate is active
%s Language detection delegate is NOT active. %d, %@
%s isSiriMode=%d, speechEvent=%ld, wasRequestCancelled=%d, shouldSuppressAlert=%d, isMonitoringMyriadEvents=%d, didMyriadWin=%d, recordRoute=%@
%s Explicitly playing %@ alert
%s BTLE Myriad Not explicitly playing speech stop alert
%s Not explicitly playing alert
%s Language detector is confident:%{private}d of the detected language:'%{private}@' with language code likelihood: %{private}@
%s time = %lf, wantsAudibleFeedback = %d
%s BTLE waiting for Myriad to finish
%s BTLE Myriad loss cancelled two shot feedback
%s BTLE speech controller began waiting for Myriad decision
%s BTLE speech controller end waiting for Myriad decision %lu
%s opType = %tu, reason = %tu
%s Unknown CSRequestOperationType (opType = %tu).
%s reason = %tu
%s time = %lf
%s Ignoring startpoint from stale CSEndpointAnalyzer
Endpoint
%s exited _recordingWillStartGroup
%s Ignoring hard endpoint from stale CSEndpointAnalyzer
%s Ignoring hard endpoint because (endpointTime = %f, firstBufferTimestamp = %f, mostRecentTTSEndTimestamp = %f, extendedSuppressDuration = %f).
%s Detected hard end-point with metrics - %@
EndpointHandled
%s Overriding timeout and start point on timeout
%s Ignoring hard endpoint since _endpointerOperationMode = %@, _didEnterTwoShotMode = %d
%s promptType = %ld, time = %f
%s suppressesTwoShotAlert = %d
%s done
%s Fake two shot TTS prompt timed out (%@).
%s Fake two shot TTS prompt timeout is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s Fake two shot TTS prompt called back (timestamp = %f, duration = %f, error = %@)
%s Fake two shot TTS prompt callback is not handled due to context mismatch (fakeTwoShotPromptUUID = %@, _fakeTwoShotPromptUUID = %@).
%s duration = %lf
%s No endpoint yet, waiting
%s rcID: %lu, duration: %lf, lrnnScore: %f, lrnnThreshold: %f, taskId: %@
%s Eager results - shouldAccept: %d, isMitigated: %d Duration: %lf last duration: %lf
%s Enforce previous endpointHint
%s Got an enforce message without a current completion. Ignoring
%s Processing RC for mitigation, force accept
%s Got an enforce message without a current RC. Stop Recording
%s timeout = %f
%s Watchdog timer timed out.
%s duration %lf
%s Starting audio playback request %@...
%s Failed audio playback request %@ due to error %@.
%s Stopped audio playback request %@.
%s scores = %{private}@
%s userInfo = %@
%s Reuse existing session %@ from reusable session pool.
%s Create new session %@.
%s session = %@
%s session = %@, error = %@
%s Add successfully finalized session %@ to reusable session pool.
%s Evict %tu sessions from reusable session pool because %@.
%s Reusable session pool is already empty.
%s Created CSStartOfSpeechDetector: %{public}@ 
%s Reset: Created EARCaesuraSilencePosteriorGenerator: %{public}@
%s Start of speech already reported, ignoring !
%s silProb= %{public}f, silnfcnt=%{public}f, clientProcessedAudioMs=%{public}f curSpeechFrmCnt=%{public}lu
%s Speech prob target reached at %{public}lu from %{public}lu, #samples=%lu, secs=%{public}f
%s Received mediaserverd or bridgeaudiod crashes event
%s Received mediaserverd or bridgeaudiod reset event
%s Start monitoring : Mediaserverd crash / recover event
%s disconnect VoiceTriggerXPCClient
%s ERR: failed to get response !
%s Failed setting activity state to continue
%s Failed setting activity state to done
%s Deferring activity:%@ deferred:%@
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s language code already up-to-date : %{public}@
%s Using override asset: %@
%s Updated cache with new Trial asset %@
%s Cache already contains Trial asset, ignore MA asset update
%s Updated cache with new MA asset %@
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s There is not audio buffer to convert. Skip this.
%s Got asked for %{public}u packets, have %{public}u
%s [%{public}02u of %{public}02u %{public}fs] Opus packet with %u bytes
%s %{public}d bytesConsumed from opus coverter, remains %{public}d bytes
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s Providing voiceTriggerEventInfo with deviceId %{public}@
%s Providing built-in voiceTriggerEventInfo
%s Timed-out for fetching voiceTriggerInfo
%s TiggerInfoProviding is nil
%s RequiredSampleCount reached: currSampleCount=%{public}lu, endingSampleCount=%{public}lu
%s SmartSiriVolume cannot be resumed because Siri is not enabled
%s Setting audio injection enabled : %d
%s Fetched audio injection enabled : %d
%s CSAudioInjectionServices Interrupted
%s CSAudioInjectionServices Invalidated
%s Request to create audio injection device type : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Fetching primary device timed-out!!
%s Request to inject audio %@ to deviceUUID %@
%s Request to connect device with UUID %@
%s Connect device timed-out!!
%s Request to disconnect device with UUID %@
%s Disconnect device timed-out!!
%s Request to fetch primary device
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s Tear down _remoteRecordClient if needed
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Setting announced call flag to: %d with stream handle Id: %lu
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf, streamHandleId = %{public}lu, streamType = %{public}lu
%s Calling AVVC setContextForStream : %{public}@
%s Tried to setCurrentContext with mode %ld. This method can only be used for auto and post
%s setCurrentContext elapsed time = %{public}lf
%s Remote device with device id: %{private}@ not found
%s Failed to prepare remote device : %{public}@
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Asking startRecording to remote device with context : %{public}@ (original context : %{public}@)
%s Failed to fetch valid context
%s Failed to startRecording : %{public}@
%s startRecordingWithOptions elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Failed to stopRecording to remoteRecordClient : %{public}@
%s stopRecording elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s fetch recordDeviceInfo elapsed time = %{public}lf
%s fetch EndpointDeviceType elapsed time = %{public}lf
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s (darwinOS) : isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation with streamId(%{public}lu)
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Calling AVVC setSessionActivate for deactivation for stream %d: %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Calling AVVC setDuckOthersForStream(%d) for DuckOthers/MixWithOthers
%s Failed to setDuckOthersForStream : %{public}@
%s setDuckOthersForStream elapsed time = %{public}lf
%s Calling audio session reset ducking settings
%s resetDuckSettings elapsed time = %{public}lf
%s Failed to setDuckToLevelDB : %{public}@
%s %{public}@ miniDucking now
%s enableMiniDucking elapsed time = %{public}lf
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Ducking %{public}@ supported on current route with streamId: %{public}ld
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packets count %{public}d
%s Peak : %f, Avg : %f
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Audio record route is %{private}@ for stream id %{private}lu
%s Calling AVVC playAlertSoundForType to play alert
%s Ignore playing endpoint beep(record stopped beep) since it already played beep in gibraltar
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s hasLocalPendingTwoShot = %{public}d, token : %{public}llu
%s Unsupported audio format!
%s Existing remoteRecordClient (deviceId = %@) doesn't match required one (deviceId = %@), create new remoteRecordClient
%s The input streamHandleId(%{public}lu) is not expected(%{public}lu)
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s endpointer running on corespeechd
%s endpointer running on assistantd
%s Abstract Impl. Returning nil
softlink:r:path:/System/Library/PrivateFrameworks/SystemStatus.framework/SystemStatus
softlink:r:path:/System/Library/Frameworks/CoreMotion.framework/CoreMotion
softlink:r:path:/System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
Statistics
CSGestureMonitor
CSBluetoothWirelessSplitterInfo
CSAudioInjectionBuiltInEngine
CSAudioInjectionEngineDelegate
NSObject
CSVoiceTriggerSecondChanceContext
NviDataLogger
NSStreamDelegate
CSMicUsageReporter
CSGestureMonitorPhone
CMWakeGestureDelegate
CSVoiceTriggerAssetHandler
CSAudioSessionController
CSAudioSessionInfoProvidingDelegate
CSXPCClientDelegate
CSCoreSpeechDaemonStateMonitorDelegate
CSSiriDebugConnection
AttSiri
CSCXPhoneCallStateMonitor
CSCommandControlListenerOption
CSMediaPlayingMonitor
CSAudioInjectionFileOption
CSMSNExceptionManager
CSVolumeMonitor
CSTimerMonitor
CSAlarmMonitor
CSAudioStreamHolding
CSUserIdentityClassifier
CSAssetManagerEnablePolicyFactory
CSAttSiriServiceProtocol
CSAttSiriServiceDelegate
CSAttSiriServiceClient
CSSiriFanInfoManager
CSSiriFanInfo
CSBiometricMatchMonitor
CSPreMyriadVoiceTriggerMetaData
CSPreMyriadCoordinator
CSVoiceTriggerDelegate
CSSecondPassProgressDelegate
CSAudioInjectionHearstEngine
AVVC
SmartSiriVolume
CSAudioDeviceInfo
NSCopying
NSSecureCoding
NSCoding
CSSpeakerRecognitionProxy
CSSSRXPCClientDelegate
CSVoiceTriggerXPCService
CSVoiceTriggerXPCClientDelegate
CSVoiceTriggerAssetDownloadMonitor
CSAsset
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSOtherAppRecordingStateMonitor
CSBenchmarkService
CSSmartSiriVolumeEnablePolicyFactory
CSAssetDownloadingOption
CSSmartSiriVolumeEnablePolicyHomePod
CSContinuousAudioFingerprintEnabledPolicyHomePod
CSBluetoothManager
CSHostLauncherDarwin
CSSiriAssertionMonitor
CSXPCConnectionDelegate
CSAccessorySiriClientBehaviorMonitor
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSPowerAssertionMac
CSAudioFileReader
CSAdBlockerAssetDownloadMonitor
CSAudioRouteChangeMonitorImplWatch
CSAudioSampleRateConverter
CSLanguageDetectorAssetMonitor
CSSiriSpeechRecordingContext
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSSmartSiriVolumeClient
isPluginContext
CSAudioInjectionProvider
XPCObject
CSOpportuneSpeakListener
CSAudioStreamProvidingDelegate
CSSPGEndpointAnalyzerDelegate
CSVoiceIdXPCClient
RMSSample
CSShadowMicScoreCreator
CSBluetoothWirelessSplitterMonitorImpIOS
CSContinuousAudioFingerprintEnabledPolicyFactory
AudioInjectionXPCProtocol
CSVoiceTriggerHeartBeatMetricsProvider
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSActivationXPCClient
CSLanguageDetector
_EARLanguageDetectorDelegate
CSStartOfSpeechDetectorDelegate
LanguageCode
CSBluetoothWirelessSplitterMonitorImplDarwin
CSStopRecordingOptions
CSMacWakeSleepMonitor
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
CSEndpointLoggingHelper
CSEndpointLatencyInfo
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSAVVCRecordingClientMonitor
CSAudioServerCrashMonitorDelegate
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
Indexing
CSSiriAudioFileWriter
CSCoreSpeechServices
CSHangUpEnabledMonitor
CSAudioStreamRequest
CSOpportuneSpeakListenerDeviceManager
CSAVVoiceTriggerClientManager
CSSpeechManager
CSVoiceTriggerAssetHandlerDelegate
CSActivationEventNotificationHandlerDelegate
CSAudioRecorderDelegate
CSAudioProviderDelegate
CSOpportuneSpeakEventMonitorDelegate
CSSpeechEndHostTimeEstimator
CSClamshellStateMonitor
CSCommandControlListener
FlexKwd
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
CSEndpointerXPCService
CSEndpointerXPCServiceDelegate
CSEndpointerXPCClient
NviDirectionalitySignalProvider
NviSignalProvider
CSConnectionListener
NSXPCListenerDelegate
CSConnectionServiceDelegate
CSAudioRecorderFactory
CSVoiceTriggerFirstPassMetrics
CSSpeechController
CSAudioConverterDelegate
CSSmartSiriVolumeControllerDelegate
CSAudioAlertProvidingDelegate
CSAudioSessionControllerDelegate
CSAudioDecoderDelegate
CSEndpointAnalyzerImplDelegate
SOMediaNowPlayingListening
SOClockAlarmListening
SOClockTimerListening
CSAudioSessionProvidingDelegate
CSSpeechManagerDelegate
CSContinuousVoiceTriggerDelegate
CSSSRXPCService
CSSSRXPCServiceDelegate
CSSSRXPCClient
CSAttSiriAttendingTriggerEventInfo
RTModel
CSSiriAudioPlaybackSessionImplAVPlayerBased
CSSiriAudioPlaybackSession
SpeechModelTrainingClient
CSVoiceTriggerAssetHandlerDarwin
CSRemoteAssetManagerDelegate
CSXPCClientFactory
SpeechModelTrainingProtocol
NviSignalProvidersController
CSVoiceTriggerFirstPassHearstAP
CSXPCClient
CSAudioSessionProviding
CSFallbackAudioSessionReleaseProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioSessionInfoProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSStateMachine
CSEventMonitor
CSVoiceTriggerStatAggregator
CSDigitalZeroReporting
CSSmartSiriVolumeManager
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSAutomaticVolumeEnabledMonitorDelegate
CSVoiceTriggerDataCollector
CSAudioFileLog
CSActivationEvent
CoreSpeechXPCFakeModelMonitor
CSScreenLockMonitor
CSSmartSiriVolumeUserIntent
CSAssetController
CSEventMonitorDelegate
Utils
CSAudioInjectionTvRemoteEngine
CSSiriLauncher
CSVTSecondPassLatencyMetrics
CSAudioRouteChangeMonitor
CSSmartSiriVolumeEnablePolicy
CSAudioInjectionRemoraEngine
CSAudioInjectionEngine
AudioHardware
CSVoiceTriggerAssetChangeMonitor
CSAttSiriRequestContext
NviAudioFileWriter
CSVoiceTriggerEnabledPolicyNonAOP
CSBluetoothWirelessSplitterMonitor
CSSiriClientBehaviorMonitor
CSSpeechEndpointAssetMetaUpdateMonitor
CSSmartSiriVolumeEstimate
CSSpeechUaapXPCClient
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSSiriClientBehaviorMonitorDelegate
CSOpportuneSpeakBehaviorMonitor
CSMyriadPHash
NviConstants
CSSiriAudioActivationInfo
NviUtils
Logging
CSHostPowerSourceMonitor
CSAudioStartStreamOption
CSAssetControllerFactory
CSSiriAudioPlaybackSessionImplAVAudioPlayerBased
AVAudioPlayerDelegate
CSSmartSiriVolumeRunPolicyHomePod
CSContinuousAudioFingerprintEnabledPolicy
CSVoiceTriggerXPCServiceProxy
CSAdBlockerAssetDecoderV2
CSRCHandlingXPCService
CSRCHandlingXPCClient
CSSmartSiriVolumeController
CSSmartSiriVolumeClientDelegate
CSPhraseNDEAPIScorer
CSKeywordAnalyzerNDEAPIScoreDelegate
SpeakerRecognition
CSAudioTandemStream
CSBluetoothDeviceInfo
CSAttSiriStateMonitor
CSSmartSiriVolumeRunPolicyFactory
CSP2PService
CSVoiceTriggerAwareZeroFilter
CSPhoneCallStateMonitor
CSAlwaysDisabledPolicy
CSPostBuildInstallService
CSContinuousAudioFingerprintProvider
CSBuiltinSpeakerStateMonitor
NviDirectionalitySignalData
CSEndpointerMetrics
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSmartSiriVolumeProcessor
CSVoiceTriggerAssetHandlerFromFile
CSSACInfoMonitor
CSVoiceTriggerRTModel
CSSiriVibrationManager
CSAudioRouteChangeMonitorImpl
CSAutomaticVolumeEnabledMonitor
CSSiriRecordingInfo
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSVoiceProfileRetrainManager
CSVoiceTriggerEnabledMonitor
CSVoiceTriggerSecondPassRequestOption
CSHybridEndpointer
CSEndpointerAssetManagerDelegate
!2!B
CSRemoteRecordClient
CSSiriEnabledMonitor
NviCSAudioDataSource
NviAudioDataSource
NviDataSource
CSAlertBehaviorPredictor
CSDefaultAudioRouteChangeMonitorMac
CSAudioInjectionEngineFactory
CSSiriBluetoothManager
CSEndpointerAssetManager
CSAssetManagerDelegate
CESRTrialAssetDelegate
CSEndpointDelayReporter
CSBenchmarkXPCProtocol
CoreSpeechXPCProtocol
CSActivationEventNotifier
CSLanguageCodeUpdateMonitorImpl
CSVoiceTriggerEventsCoordinator
AudioFile
CSSoftwareUpdateCheckingMonitor
CSPreferences
CSAssetManagerEnablePolicy
CSAttSiriAudioSessionStateClient
AFNotifyObserverDelegate
CSCoreSpeechServiceListenerDelegate
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSBatteryMonitor
Liminal
CSVoiceTriggerAssetMetaUpdateMonitor
CSAudioRecordDeviceIndicator
CSVoiceTriggerEnabledPolicyHelper
CSDarkWakePowerAssertionMac
CSSiriQueueMonitor
_CSSiriQueueObserver
CSAlwaysEnabledPolicy
CSRemoteVADCircularBuffer
CSAdBlockerAssetMetaUpdateMonitor
CSAudioStream
CSSiriAudioSession
CSSiriAudioRoute
CSServerEndpointFeatures
CSActivationEventNotificationHandler
CoreSpeechXPC
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
CSRawAudioInjectionProvider
CSSpringboardStartMonitor
CSAudioProvider
CSAudioPreprocessorDelegate
CSListeningEnabledPolicyWatch
CSAlwaysOnProcessorStateMonitor
CSAdBlockerAssetDecoderFactory
CSMyriadNotifier
CSTUPhoneCallStateMonitor
CSAdBlockerAssetDecoderV1
CSAVCallConnectedMonitor
CSUserSessionActiveMonitor
CSTrialAssetDownloadMonitor
CSRemoteDeviceProtocolInfo
Bitset
CSHybridEndpointAnalyzer
OSDAnalyzerDelegate
8!!!B
CSOpportuneSpeakListenerOption
CSAudioInjectionDevice
CSAudioSessionInfoProvider
CSEndpointerProxy
CSEndpointAnalyzerDelegate
CSSiriMobileBluetoothDeviceDataSource
AFInvalidating
CSSiriMobileBluetoothDeviceProxy
AFBluetoothDevice
CSFirstUnlockMonitor
CSPhraseSpotterEnabledMonitor
CSVoiceIdXPCConnection
NSXPC
CSPhoneCallStateMonitorFactory
CSSiriPreferences
MockRemotePluginXPCProtocol
CSFallbackAudioSessionReleaseProvider
CSSPGEndpointAnalyzer
EARCaesuraSilencePosteriorGeneratorDelegate
CSHomePodSettingsMonitor
CSASXSignatureExtracting
CSSiriAcousticFingerprinter
CSLanguageDetectorOption
CSSiriSpeechRecorder
CSSiriAcousticFingerprinterDelegate
CSSpeechControllerDelegate
CSLanguageDetectorDelegate
CSSpeakerIdentificationDelegate
CSSiriSpeechCapturing
CSSiriAudioPlaybackService
AFMemoryPressureListening
AFAudioPlaybackService
CSTrialAssetManager
CSStartOfSpeechDetector
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSVoiceTriggerXPCClient
CSXPCActivity
CSCoreSpeechDaemonStateMonitor
CSNetworkAvailabilityMonitor
CSSpeechDetectionDevicePresentMonitor
CSLanguageCodeUpdateMonitorImplDarwin
CSAttSiriMitigationAssetHandler
CSAudioRecordDeviceInfo
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSAudioConverter
CSLanguageCodeUpdateMonitor
CSVoiceTriggerEventInfoProvider
CSSmartSiriVolumeRunPolicy
CSAudioInjectionServices
CSRemoteDarwinDeviceInfo
CSAdBlockerAssetDecoderV3
Trial
CSGestureDropEvent
RecordContext
LanguageDetector
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioFileReaderDelegate
CSRemoteRecordClientDelegate
CSUserSessionActiveMonitorDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSCommandControlBehaviorMonitor
CSVoiceProfileContext
NviContext
CSEndpointerFactory
CSJarvisTriggerModeMonitor
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
NviSignalData
CSSRFUserSettingMonitor
objCType
objectAtIndex:
updateVoiceProfile:withUserName:
currentRoute
appendData:
removeAllObjects
setNumberOfLoops:
submitAudioIssueReport:
skipAlert
cancelIfNotAlreadyCanceled
initWithAppBundleIdentifier:
isStarkTriggered
serverFeaturesLatency
objectAtIndexedSubscript:
appendFormat:
currentRunLoop
logTwoShotDetectedWithMHUUID:
setObject:atIndexedSubscript:
submitEndpointerIssueReport:
setSupportsAnnounceCall:
initWithArray:
getNumberForKey:category:default:
data
submitVoiceTriggerIssueReport:
logTwoShotEndEventWithSuppresedAlert:withTimedOut:withMHUUID:
objectEnumerator
removeFromRunLoop:forMode:
setObject:forKey:
startOfSpeechAudioLoggingEnabled
setSupportsInEarDetection:
initWithSampleRate:
skipPersonalizedASR
isTVRemote
logTwoShotStartEventWithPromptType:withMHUUID:
setDateFormat:
objectForKey:
subscribeEventMonitor:
dataForChannel:
getPeakPowerDB
loggingDict
sessionForContext:error:
removeItemAtPath:error:
setSupportsListeningModeANC:
initWithAsset:
appendString:
dataUsingEncoding:
removeItemAtURL:error:
channelForOutputReference
substringToIndex:
useAutomaticEndpointing
setSupportsListeningModeTransparency:
getPeakPowerForStream:forChannel:
dataWithBytes:length:
getPlaybackStateWithCompletion:
longLongValue
isAudioRecordTypeSupportedByRemora
isTest
substringWithRange:
channelForProcessedInput
setOverrideState:
lowercaseString
acceptEagerResultWithFeatures:featuresToLog:
isTriggeredFromHearst
setSupportsSpokenNotification:
dataWithCapacity:
supportAdBlocker
smartSiriVolumeSoftVolumeEnabled
opaqueSessionID
lpcmASBD
setSupportsVoiceTrigger:
removeLogFilesOlderThanNDays:
setPackets:
sortUsingComparator:
accessibilityState
open
supportBeepCanceller:
dataWithContentsOfFile:
useDeviceSpeakerForTTS
removeObject:
channels
initWithServicePort:
sortUsingSelector:
domain
isVibrationDisabled
isUpsamplingSourceAudio
getRecordDeviceInfoForStream:
processAudioBytes:withNumberOfSamples:
applyNegative20dBGainToFloatBuffer:
dataWithContentsOfFile:options:error:
supportBluetoothDeviceVoiceTrigger
setDeviceUID:
accessibleEndpointerThreshold
isBluetoothVehicleOutput
removeObjectAtIndex:
lpcmFloatASBD
setPeakPower:
doubleValue
processAudioChunk:
initWithSilenceFramesCountMs:silenceProbability:silenceDurationMs:processedAudioMs:
getRecordSettingsForStream:
sortedArrayUsingComparator:
applyNegative20dBGainToShortBuffer:
setTarget:
usePrelisteningMode
dataWithJSONObject:options:error:
isBuiltInVoiceTriggered
chunkForChannel:
setASVUserIntent:
removeObjectForKey:
lpcmInt16ASBD
setPerceptualAudioHash:
getResourceValue:forKey:error:
isVoiceTriggerAssetOverridingEnabled
supportCSTwoShotDecision
applyNegative32dBGainToFloatBuffer:
dataWithLength:
accessorySiriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
startRecordForStream:error:
setTimeStamp:
lpcmInt16NarrowBandASBD
useSpeexForAudioInjection
spaceCheck:
applyNegative32dBGainToShortBuffer:
supportHandsFree
setTimestamp:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
getSerialQueue:qualityOfService:
setActionAtItemEnd:
removeObserver:name:object:
effectiveBoolValueForSetting:
accessorySiriClientBehaviorMonitor:didStopStream:reason:withEventUUID:forAccessory:
userInfo
isVoiceTriggered
fileDescriptor
array
getSerialQueue:withQualityOfService:andTargetQueue:
date
lpcmInterleavedASBD
isConfident
setActivationExpirationTime:
speakerStateActiveCompletionBlock:
supportHangUp
accessorySiriClientBehaviorMonitor:willStartStreamWithContext:option:forAccessory:
lpcmInterleavedWithRemoteVADASBD
fileExistsAtPath:
removeOpportunisticAudioLoggingOlderThanNDays:
isWakeGestureAvailable
initWithStreamID:atStartHostTime:
arrayWithCapacity:
speakerStateMutedCompletionBlock:
accessorySiriClientBehaviorMonitor:willStopStream:reason:forAccessory:
fileExistsAtPath:isDirectory:
setActivationMetadata:
removeRemoteP2PLogFilesOlderThanNDays:
dateAdded
initWithBackingStoreCapacity:minimalNumberOfBackingStores:maximumNumberOfBackingStores:backingStoreIdleTimeout:
processFloatBuffer:stride:inFrameToProcess:
isDarwinOS
arrayWithObjects:count:
supportHomeKitAccessory
utteranceFileASBD
setActivationMode:
dateByAddingTimeInterval:
initWithBlob:
lpcmMonoInterleavedWithRemoteVADASBD
initWithStreamID:settings:bufferDuration:
replaceBytesInRange:withBytes:
processIdentifier
initWithBlock:
setDiscretionary:
speechCapturing:didDetectEndpointAtTime:
initWithString:
clientSilenceFramesCountMs
supportHybridEndpointer
setType:
valueForEntitlement:
arrivalHostTimeToAudioRecorder
fileSystemRepresentation
lpcmMonoNonInterleavedWithRemoteVADASBD
setActivationSource:
initWithSuiteName:
speechCapturing:didDetectLanguage:confidenceScores:isConfident:
processInfo
itemData
initWithBlock:defaultValue:
clientSilenceProbability
valueForKey:
setProductID:
isDarwinVoiceTriggered
setActive:error:
supportJarvisVoiceTrigger
replaceBytesInRange:withBytes:length:
isDeviceInCarDNDMode
initWithTaskDeliverer:
dateWithTimeIntervalSinceNow:
lpcmNarrowBandASBD
acquireAudioSessionAssertionWithContext:relinquishmentHandler:
speechCapturing:didDetectStartpointAtTime:
itemURL
vendorID
supportLanguageDetector
setActive:withOptions:error:
opportuneSpeakListenerBypassEnabled
replaceCurrentItemWithPlayerItem:
initWithBool:
daysBeforeRemovingLogFiles
fileURLWithPath:
code
fileURLWithPath:isDirectory:
speechCapturing:didFinishWritingAudioFile:error:
initWithTimeoutInterval:onQueue:timeoutHandler:
lpcmNonInterleavedASBD
assetChangeMonitorDidDetectAssetChange:
replaceMatchesInString:options:range:withTemplate:
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
setDuckOthersForStream:withSettings:error:
initWithBytes:length:
assetForAssetType:resourcePath:configVersion:
supportLazySessionActivation
initWithToken:sampleRate:numChannels:
lpcmNonInterleavedWithRemoteVADASBD
initWithCapacity:
processSampleCount:hostTime:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
speechCapturing:didInterruptAudioSession:
supportMphAssets
setUserInfo:
opportuneSpeakingFileLoggingIsEnabled
isDictationVoiceTriggerEnabled
startRequestWith:context:delegate:
speechCapturing:didLoseAudioSessionOwnerOrMediaServices:
assetForAssetType:resourcePath:configVersion:assetProvider:
mapTableWithKeyOptions:valueOptions:
activateAudioSessionForStream:isPrewarm:error:
enableProgrammableAudioInjection:
filteredArrayUsingPredicate:
setDuckOverride:
getStateWithCompletion:
getStringForKey:category:default:
supportNonInterruptibleSiri
reportIssueForType:subType:context:processIdentifier:walkboutStatus:
activateAudioSessionForStream:isPrewarm:recordMode:error:
setRate:
speechCapturing:didReceiveFingerprint:duration:
setEffectiveDate:
initWithConfigFile:
mediaPlaybackVolume
setDuckToLevelDB:error:
deactivateAudioSessionForStream:withOptions:error:
voiceProfileForId:
getThreshold
supportOpportunisticZLL
opusASBD
finalFilteredDictationLanguages
processShortBuffer:stride:inFrameToProcess:
speechCapturing:didSetAudioSessionActive:
deactivateAudioSessionWithOptions:
keysOfEntriesPassingTest:
deactivateForReason:options:context:completion:
initWithConfigFile:sampleRate:context:queue:delegate:
setReason:
firstObject
setValue:forKey:
activationDeviceIdentifier
getUUIDBytes:
speechCapturing:performTwoShotPromptWithType:completion:
isDuckingSupportedOnPickedRouteForStream:error:
enableSmartRoutingConsiderationForStream:enable:error:
setAlertSoundFromURL:forType:
isEarlyDetect
enableSpeakerStateListening:completionBlock:
supportPremiumAssets
getValueForKey:category:
startWakeGestureUpdates
setVendorID:
speechCapturing:willSetAudioSessionActive:
opusNarrowBandASBD
initWithConfigFile:samplingRate:queue:
setRecentMessages:
setVoiceTriggerEverUsed
activationDeviceUID
firstPassDebuggingEnabled
processedAudioDuration
speechCapturingDidProvideConfidenceScores:classification:classifiedUser:unknownUserScore:duration:version:thresholdingType:assetVersion:
languageCodeDarwin
isEarpieceActiveNoiseCancelationEnabled
activationEvent
initWithConfiguration:
mhLogDirectory
supportRelayCall
outputStreamToFileAtPath:append:
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
supportRemoraVoiceTrigger
initWithConfiguration:modelVersion:
activationEventMachAbsoluteTime
companionSyncVoiceTriggerUtterancesEnabled
speechCapturingDidReceiveLastAudioBufferWithEndpointMode:totalPacketCount:endpointerMetrics:
processedAudioMs
decodeInt64ForKey:
initWithContentsOfURL:error:
setVolume:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
decodeIntegerForKey:
isEndpointAssetBypassTrialEnabled
floatValue
initWithUTF8String:
speechCapturingDidRecordPCMAudioData:
supportRemoteDarwinVoiceTrigger
compare:
assetProvider
encodeInt64:forKey:
outputs
supportRingtoneA2DP
decodeJson:
assetServerUrl
getVoiceTriggerCurrentCompatibilityVersion
encodeInteger:forKey:
setRecordDelegate:
initWithUUIDString:
productID
setVolume:fadeDuration:
activationEventTime
encodeObject:forKey:
isEndpointAssetOverridingEnabled
componentsJoinedByString:
speechCapturingDidRecordSpeechPackets:atTimestamp:totalPacketCount:
JSONObjectWithData:options:error:
setAllowMixableAudioWhileRecording:error:
initWithData:encoding:
decodeObjectOfClass:forKey:
setRemoteObjectInterface:
componentsSeparatedByString:
assetWithData:contentType:options:
speechCapturingDidRequestQuickStop:
initWithUnsignedLongLong:
setWithArray:
supportSmartVolume
isEqualAsset:
initWithData:error:
assistantAudioFileLogDirectory
confidences
profileID
decodeObjectOfClasses:forKey:
forceVoiceTriggerAPMode
startingAlertBehavior
initWithVoiceRetrainingContext:error:
speechCapturingDidRequestShutdownUI:
packetDescriptionCount
supportZeroFilter:
defaultCStringEncoding
state
setRemoteVAD:
setWithObjects:
activationMode
isEqualToNumber:
moveItemAtPath:toPath:error:
speechCapturingDidRequestUpdateSiriOutputVolume:
configVersion
packetDescriptions
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:arrivalHostTimeToAudioRecorder:wasBuffered:remoteVAD:
isEqualToString:
defaultCenter
gainCompensatedChunk
packets
setAllowsCellularAccess:
status
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
speechCapturingDidStartRecordingSuccessfully:error:withInfo:
programmableAudioInjectionEnabled
geckoAudioLogDirectory
endAudioAndFetchAnyTrailingZerosPacket:
supportsDuckingOnSpeakerOutput
isFeatureGroupOneEnabled
setRepresentation
speechCapturingDidStopRecordingWithError:endpointMode:totalPacketCount:endpointerMetrics:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
defaultContext
setAnnounceCallsEnabled:
getZeroStatisticsFromBuffer:entireSamples:
supportsEndpointingOnATV
languageDetectorUserContext
endOfSentenceLikelihood
defaultContinousFingerprintBufferDuration
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:eagerResultEndTime:
requestSupportedWithSamplingRate:
setExportedInterface:
pathExtension
supportsSpeakerRecognitionAssets
pause
shadowMicScoreThreshold
generateDeviceAudioLogging:speechId:
speechCapturingDidUpdateRecordingInfo:
setExportedObject:
supportsUnderstandingOnDevice
provisionedVoiceProfilesForLocale:
defaultConverter
addAudioSamples:count:
initWithDescription:
stopAlert
speechCapturingWillStopRecording
purgeSync
containsCategory:
endTimestamp
setAnnounceCallsEnabledForStream:enable:
voiceTriggerPhraseNDEAPIScorerDidDetectedKeyword:bestStartSampleCount:bestEndSampleCount:
isHeadphoneDeviceWithRecordRoute:playbackRoute:
sharedAnalytics
peakPower
attachProgressCallBack:
addConditions:
speechCapturingWillStopRecordingWithSignpostID:
containsObject:
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
handleFailureInFunction:file:lineNumber:description:
queryMetaData:
isHearstVoiceTriggered
lastObject
suppressStartAlert
mutableBytes
addContextKey:fromMetaFile:
sharedConnection
getASVUserIntent:
containsString:
queryMetaDataSync
synchronousRemoteObjectProxyWithErrorHandler:
handleFailureInMethod:object:file:lineNumber:description:
lastPathComponent
isHomePressed
mutableCopy
addContextKey:withContext:
containsValueForKey:
isIOSDeviceSupportingBargeIn
queryParams
pendingSecondPassTriggerWasClearedForClient:deviceId:
attributes
defaultManager
contentsOfDirectoryAtPath:error:
systemUpTime
initWithDictionary:
systemUptime
mutatedCopyWithMutator:
myriadHashFilePath
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
endpointType
volume
initWithDispatchQueue:
isJarvisVoiceTriggered
sharedLogger
setAttributes:ofItemAtPath:error:
defaultServerEndpointFeatures
contextForBuiltInVoiceTrigger
stopCountingZeroStatisticsWithReporter:
avgPower
initWithDomain:code:userInfo:
setHardwareInterfaceVendorID:
contextForHearstVoiceTriggerWithDeviceId:
rangeOfFirstMatchInString:options:range:
tapToSiriAudioPlaybackRequest
addEntriesFromDictionary:
waitForMyriadDecisionForReason:withCompletion:
latticeRnnMitigatorScore
isLocalVoiceTriggerAvailable
setHearstFirstPassModelVersion:
setServerCrashedBlock:
deleteUserVoiceProfile:
contextForOpportuneSpeakerListener
initWithDouble:
addKeyValuePair:with:
latticeRnnMitigatorThreshold
avvcContext
persistentDomainForName:
handleSiriRequest:deliveryHandler:completionHandler:
setServerResetBlock:
waitWithTimeout:
contextForOpportuneSpeakerListenerWithCall
temporaryDirectory
receiveOnlyProcessedChannelData
audioChunkAvailable:numChannels:numSamplesPerChannel:startSampleId:atAbsMachTimestamp:
setHearstSecondPassModelVersion:
leave
audioConverterBitrate
sharedObserver
resetWithSampleRate:
setIAmTheAssistant:error:
newVoiceProfileWithLocale:withAppDomain:
length
initWithDuckOthers:duckToLevel:mixWithOthers:
contextForRemoraVoiceTriggerWithDeviceId:
isMitigationAssetOverridingEnabled
timeIntervalSinceDate:
sharedPowerLogger
deviceBuildVersion
phraseSpotterEnabled
newWithBuilder:
handleSpeechRecordingEvent:
stopOnErrorAlert
setAudioInputRoute:
lengthOfBytesUsingEncoding:
isMonitoring
timeIntervalSinceNow
resourcePath
addObject:
base64EncodedStringWithOptions:
wasBuffered
nextObject
baseDir
timeStamp
limitedAudioLoggingEnabled
inputRecordingBufferDuration
stopRecordForStream:error:
getAveragePowerDB
initWithFileDescriptor:closeOnDealloc:
initWithError:
addObjectsFromArray:
hardwareInterfaceVendorID
pickedRoute
linkItemAtURL:toURL:error:
resultId
sharedSiriId
recordDeviceIdentifier
setSiriClientRecordStateChangedBlock:
results
setInterfaceProductID:
weakObjectsHashTable
initWithFormat:
getAveragePowerForStream:forChannel:
resume
setSiriCueType:
listeningEnabledCompletionBlock:
setInterruptionHandler:
notifyCallbackWithOption:
setInterfaceVendorID:
convertToFloatLPCMBufFromShortLPCMBuf:
beepSoundID
convertToShortLPCMBufFromFloatLPCMBuf:
addObserver:forKeyPath:options:context:
wearerDetectionConfig
retrieveSessionWithID:
inputRecordingDuration
isP2PTransferEnabled
initWithIdentifier:queue:effectiveDate:expirationDuration:heartBeatInterval:heartBeatHandler:invalidationHandler:
willBeep
platformSupportsImplcitUttAddition
setSiriLanguageCodeDarwin:
converterForAudioStreamId:
addObserver:selector:name:object:
locale
totalExpected
setInvalidationHandler:
play
returnTypes:
_setQueue:
inputRecordingDurationInSecs
setAudioSession:
enter
totalWritten
copy
getBestAnalyzedResultsFromAudioChunk:
rootQueueWithFixedPriority:
shouldDeinterleaveAudioOnCS
addPackets:audioStreamHandleId:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
isPlaying
enumerateKeysAndObjectsUsingBlock:
setSkipAlert:
localeWithLocaleIdentifier:
shouldDelayPhaticForMyriadDecision
inputRecordingDurationInSecsExtended
deviceRingerSwitchState
hasRemoteCoreSpeech
initWithItemURL:itemData:numberOfLoops:volume:fadeInDuration:fadeOutDuration:userInfo:
beginTimestamp
copyBufferWithNumSamplesCopiedIn:
playAlertSoundForType:overrideMode:
enumerateObjectsUsingBlock:
hasSpaceAvailable
initWithLength:
inputRecordingIsFloat
getBoolForKey:category:default:
setIsAdvancedAppleAudioDevice:
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:
setIsAlarmPlayingOnAccessory:isAlarmPlaying:
initWithListenerEndpoint:
streamDescription
streamHandleID
getBytes:range:
bestEnd
hasSuffix:
logEventWithType:context:
shouldLogForQA
copySamplesFrom:to:channelIdx:
copybufferFrom:to:
initWithLongLong:
setSource:
addSamples:numSamples:atHostTime:
write:maxLength:
bestScore
logEventWithType:context:contextNoCopy:
setIsBlur:
hashFromResourcePath
isRTSTriggered
recordingAlertPolicy
enumeratorAtPath:
addUtterances:toProfile:withContext:withCompletion:
bestStart
writeToFile:atomically:
initWithMachServiceName:
audioInjectionFilePath
setIsMediaPlayingOnAccessory:isMediaPlaying:isInterrupted:interruptedTime:
hashTableWithOptions:
count
logEventWithType:contextProvider:
speechRecognitionTask
initWithMachServiceName:options:
audioInputRoute
setSpeakerMuteStateChangedBlock:
error
setIsRequestDuringActiveCall:
playingApps
writeToFile:options:error:
hearstNumberOfBytesPerChunk
countByEnumeratingWithState:objects:count:
inputRecordingSampleRateNarrowBand
streamID
logEventWithType:contextResolver:
sampleByteDepth
initWithMessage:makeAppFrontmost:
setAvgPower:
hearstNumberOfSamplesPerChunk
setSpeakerStateChangedBlock:
setIsRequestFromSpokenNotification:
writeToURL:atomically:
portName
sampleCount
registerAssetDelegate:assetType:
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:withAccessoryID:
logEventWithType:machAbsoluteTime:context:
initWithMode:deviceUID:
inputs
speexASBD
errorWithCode:
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
getCurrentSessionState
powerLogSiriConfigWithVoiceTriggerEnabled:withLanguage:withModelVersion:
boolValue
logEventWithType:machAbsoluteTime:context:contextNoCopy:
initWithNSUUID:
errorWithCode:description:
audioPlaybackService:didStartRequest:
getCurrentStreamState:
createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:withLoggingUUID:
powerLoggingCurrentAssetConfigVersion
relativePath
bufferLength
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:sampleRate:
dictionaryWithDictionary:
errorWithCode:description:underlyingError:
createAudioFileWriterWithInputFormat:outputFormat:withLoggingUUID:
audioPlaybackService:didStopRequest:error:
errorWithDomain:code:userInfo:
powerLoggingCurrentLanguage
logInstrumentation:machAbsoluteTime:turnIdentifier:
initWithName:clientQueue:
powerWithNumFalseWakeup:withDuration:withPhraseDict:
dictionaryWithObject:forKey:
initWithName:options:queue:delegate:
string
twoShotAudioPlaybackRequest
samplesFed
audioPlaybackService:willStartRequest:
relinquishWithContext:options:
initWithNumChannels:recordingDuration:samplingRate:
setIsTimerPlayingOnAccessory:isTimerPlaying:
dictionaryWithObjects:forKeys:count:
predicateWithBlock:
stringByAppendingFormat:
initWithNumChannels:recordingDuration:samplingRate:audioTimeConverter:
relinquishWithError:options:
signalProvidersMapForContext:
homeButtonDownEventMachAbsoluteTime
stringByAppendingPathComponent:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
setStartAlert:
bundleForClass:
bytes
logMHASRAudioConfigureStartedWithMHUUID:withAudioCodecString:withAudioSkippedNumSamples:
numInputChannels
initWithObjectsAndKeys:
setCallback:
silenceDurationMs
numSamples
saveAudioChunck:toURL:
logMHASRAudioConfigureStartedWithMHUUID:withAudioCodecString:withAudioSkippedTimeInNs:
zeroFilterApproxAbsSpeechThreshold
stringByAppendingPathExtension:
horsemanDeviceType
setCanUseLocalCacheServer:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
silenceFramesCountMs
intValue
stringByAppendingString:
logMHAssistantDaemonAudioBluetoothInfoWithMHUUID:withWirelessSplitterSessionState:withAudioDeviceCategory:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
initWithOptions:capacity:
allKeys
cStringUsingEncoding:
URLByAppendingPathComponent:
bytesDataSize
initWithOverrideOption:reason:
unsignedIntValue
preheatLocalSpeechRecognitionWithLanguage:source:
preheatLanguage
hostTime
zeroFilterWindowSizeInMs
scheduleInRunLoop:forMode:
integerValue
getFiringAlarmIDsWithCompletion:
logMHAssistantDaemonAudioConfigureContextWithMHUUID:withConfigureStarted:
URLByDeletingPathExtension
initWithPattern:options:error:
numberOfLoops
stringByDeletingLastPathComponent
unsignedIntegerValue
standardUserDefaults
isRemoraVoiceTriggered
didIgnoreEvent:from:
logMHAssistantDaemonAudioFetchRouteContextWithMHUUID:withFetchRouteContextStarted:
hostTimeForSeconds:
silenceProbability
allValues
getFiringTimerIDsWithCompletion:
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
stringByDeletingPathExtension
unsignedLongLongValue
setClasses:forSelector:argumentIndex:ofReply:
interfaceProductID
numberWithBool:
URLForResource:withExtension:
stringByReplacingOccurrencesOfString:withString:
setLength:
initWithQueue:
expectedTimeRemaining
logMHAssistantDaemonAudioInitContextWithMHUUID:withInitStarted:
screenIDs
URLForSoundID:
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:sampleRate:
interfaceVendorID
interfaceWithProtocol:
numberWithDouble:
stringByStandardizingPath
logMHAssistantDaemonAudioLateBufferDetectedWithMHUUID:withBufferReceiptTimeInNs:
setStopAlert:
startAlert
expressionForConstantValue:
URLWithString:
isRemoteDeviceDarwin
secondsForHostTime:
setLocale:
setComponent:
remoteGradingDataDirectory
allowExtendedRingBufferSize
secondsToHostTime:
numberWithFloat:
logMHAssistantDaemonAudioPrepareContextWithMHUUID:withPrepareStarted:
getFixedPrioritySerialQueueWithLabel:fixedPriority:
hostTimeToNs:
initWithQueue:delegate:
csAudioProcessingQueuePriority
expressionForFunction:arguments:
isRemoteDeviceGibraltar
startAlertEnabled
stringFromDate:
hostTimeToSeconds:
isRequestDuringActiveCall
URLsForDirectory:inDomains:
stringValue
numberWithInt:
setStopOnErrorAlert:
logMHAssistantDaemonAudioPrewarmContextWithMHUUID:withPrewarmStarted:
getHomeUserIdForSharedUserId:completion:
expressionValueWithObject:context:
UTF8String
hostTimeToTimeInterval:
secondsToNs:
stringWithCString:encoding:
seekToTime:toleranceBefore:toleranceAfter:
numberWithInteger:
logMHAssistantDaemonAudioRecordingContextWithMHUUID:withAudioRecordingStarted:withAudioInputRoute:withAudioSource:withAudioInterfaceVendorId:withAudioInterfaceProductId:
initWithQueue:instanceContext:
getHostClockFrequency
remoteObjectProxyWithErrorHandler:
prepareLogging
stringWithCapacity:
setStopReasonMajor:
seekToTime:toleranceBefore:toleranceAfter:completionHandler:
logMHAssistantDaemonAudioRecordingFirstBufferWithMHUUID:withStartEvent:withFirstBufferStartTimeOffsetNs:withFirstBufferReceiptTimeOffsetNs:
invocationFeedbackExperiment
UUIDString
setContext:streamType:error:
numberWithLong:
initWithQueue:qosClass:asynchronous:
fadeInDuration
currentCarPlayExternalDevice
remoteP2pLogDirectory
stringWithFormat:
invoke
currentContext
updateEndpointerDelayedTriggerSwitch:
numberWithLongLong:
setStopReasonMinor:
setContextForStream:forStream:error:
logMHAssistantDaemonAudioRecordingInterruptionContextWithMHUUID:withStartEvent:withLinkID:withAvAudioSessionInterruptorName:withAVAudioSessionInterrupterType:
fadeOutDuration
prepareRecordForStream:error:
isServerInvoked
logMHAssistantDaemonAudioRecordingInterruptionStartedTier1WithMHUUID:withLinkID:withActiveSessionDisplayIDs:
numberWithUnsignedInt:
initFileURLWithPath:isDirectory:
stringWithString:
announceCallsEnabled
remoteProductIdentifier
setStreamHandleID:
remoteVAD
announcementPlatform
fakeEndpointAssetPath
siriClientsRecordingCompletionBlock:
updateEndpointerThresholdWithValue:
invokeWithSignal:
numberWithUnsignedInteger:
stringWithUTF8String:
currentHandler
logMHAssistantDaemonAudioRecordingLastBufferWithMHUUID:withStartEvent:withLastBufferStartTimeOffsetNs:withLastBufferReceiptTimeOffsetNs:
invokeWithValue:
remoteVADDuration
startCatalogDownload:options:then:
fakeHearstModelPath
setCurrentAttributionKey:andApp:
appDomain
getLastResult
appName
logMHAssistantDaemonAudioRecordingMissedBufferDetectedWithMHUUID:
prepareToPlay
currentItem
numberWithUnsignedLong:
remoteVADSubChunkFrom:numSamples:numAudioSamplesPerRemoteVAD:
updateMeterForStream:
siriInputSource
didTransitFrom:to:by:
numberWithUnsignedLongLong:
getLocalUrl
logMHAssistantDaemonAudioStartRecordingContextWithMHUUID:withStartRecordingContext:withFanInfoArray:withActiveSessionDisplayIDs:
subChunkFrom:numSamples:
strongToWeakObjectsMapTable
sendMessageWithPayload:toPeer:withReply:
fakeMitigationAssetPath
isAdBlockerAudioLoggingEnabled
cancelBeepFromSamples:timestamp:
startDownload:then:
initWithRecordType:deviceId:
fakeVoiceTriggerAssetPath
siriProfileId
logMHAssistantDaemonAudioStopRecordingContextWithMHUUID:withStopRecordingStarted:withADStopRecordingEvent:
didWin
remoteVoiceActivityAvailable
initWithRequestId:languageCode:
logSiriLaunchCompletedWithVoiceTriggerEventInfo:
isSpeakerRecognitionAvailable
subChunkFrom:numSamples:forChannel:
fallBackAssetResourcePath
startHostTime
getMachTimeAdjustedVoiceTriggerEventInfoForDeviceUUID:
appendBytes:length:
remoteVoiceActivityVAD
cancelDownloadSync
logSiriLaunchStartedWithVoiceTriggerEventInfo:
setCurrentDictationLanguage:
subdataWithRange:
distributionDictionary:
sharedInstance
_startMonitoringWithQueue:
_stopMonitoring
isTriggerHandheld
wakeGestureTimestamp
setWakeGestureTimestamp:
dismissalTimestamp
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
TQ,N,V_wakeGestureTimestamp
TQ,N,V_dismissalTimestamp
init
description
splitterDeviceList
addDeviceIntoSplitterDeviceList:
splitterState
shouldDisableSpeakerVerificationInSplitterMode
_hasDeviceTemporaryPairedNotInContacts
splitterEnabled
setSplitterEnabled:
.cxx_destruct
_splitterDeviceList
_splitterEnabled
TB,N,V_splitterEnabled
TB,R,N
initWithStreamHandleId:
setDelegate:
dealloc
start
startAudioStreamWithOption:
stopAudioStream
stop
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioEngineDidStopRecord:audioStreamHandleId:reason:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
audioEngineAudioChunkForTvAvailable:audioChunk:
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
alwaysOnVoiceTriggerEnabled
attachDevice:
isRecording
getBestSampleCountWithOption:
queue
setQueue:
delegate
keywordAnalyzer
setKeywordAnalyzer:
circularBuffer
setCircularBuffer:
lastForwardedSampleCount
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
uuid
setUuid:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
setConnectedDevice:
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_queue
_delegate
_keywordAnalyzer
_circularBuffer
_lastForwardedSampleCount
_hostTimeBuffer
_uuid
_connectedDevice
_voiceTriggerSampleCount
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
TQ,N,V_lastForwardedSampleCount
T@"NSMutableArray",&,N,V_hostTimeBuffer
T@"NSUUID",&,N,V_uuid
TB,N,V_voiceTriggerEnabled
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
TB,N,V_isForwarding
TQ,N,V_voiceTriggerSampleCount
initWithWindowStartTime:
shouldRunAsSecondChance
secondChanceHotTillMachTime
setSecondChanceHotTillMachTime:
_secondChanceHotTillMachTime
TQ,N,V_secondChanceHotTillMachTime
stream:handleEvent:
initWithFilePath:appendHdr:
logData:
endRequest
oStream
setOStream:
_oStream
T@"NSOutputStream",&,N,V_oStream
reportMicUsage:
reportsDynamicActivityAttributeAsync:bundleId:
reportsDynamicActivityAttributeSync:bundleId:
_reportsDynamicActivityAttribute:bundleId:
gestureMonitorDidReceiveWakeGesture:
enumerateObserversInQueue:
gestureMonitorDidReceiveSleepGesture:
wakeGestureManager:didUpdateWakeGesture:
wakeGestureManager:didUpdateWakeGesture:detectedAt:
wakeGestureManager:didUpdateWakeGesture:type:detectedAt:
wakeGestureManager:didUpdateWakeGesture:orientation:
wakeGestureManager:didUpdateWakeGesture:orientation:detectedAt:
_didReceiveWakeGesture
_didReceiveSleepGesture
_gestureManager
voiceTriggerAssetHandler:endpointId:didChangeCachedAsset:
sharedHandler
getVoiceTriggerAssetWithEndpointId:completion:
defaultFallbackModelIfNil:
registerObserver:
unregisterObserver:
notifyObservers:endpointId:
observers
setObservers:
_observers
T@"NSHashTable",&,N,V_observers
audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionOwnerLostNotification:
audioSessionController:didReceiveAudioSessionOwnerResetNotification:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
CSXPCClient:didDisconnect:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
initWithEndpointId:
getAudioSessionIDWithCompletion:
_getAudioSessionID
getAudioSessionID
_createXPCClientConnectionIfNeeded
_startMonitoring
_registerInterruptionNotification
_registerAudioRouteChangeNotification
_handleInterruption:
_mediaServicesWereLost:
_mediaServicesWereReset:
_audioRouteChanged:
_teardownXPCClientIfNeeded
sessionInfoProvider
setSessionInfoProvider:
xpcClient
setXpcClient:
shouldKeepConnection
setShouldKeepConnection:
endpointId
setEndpointId:
_shouldKeepConnection
_sessionInfoProvider
_xpcClient
_endpointId
T@"<CSAudioSessionInfoProviding>",&,N,V_sessionInfoProvider
T@"CSXPCClient",&,N,V_xpcClient
TB,V_shouldKeepConnection
T@"NSUUID",&,N,V_endpointId
launchSiriDebugAppWithMessage:
mitigatonConfigFile
mitigationModelDefaultAFTMScore
nldaConfigFile
allowKeywordsFile
allowListWordCountThreshold
mitigationConfigFileForCategory:
nldaConfigFileForCategory:
shouldRunSpkrIdForCategory:
getCategoryKeyWithRecordCtx:
isHSVoiceTrigger:
Tf,R,N
T@"NSString",R,N
TQ,R,N
firstPartyCall
phoneCallState
defaultOption
_notePossiblePlayPausedStateChange:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
initializeMediaPlayingState
_notifyObserver:mediaIsPlayingState:
mediaPlayingState
mediaPlayingStateWithCompletion:
_mediaIsPlaying
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
_outASBD
T@"NSURL",R,N,V_audioURL
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
T^{OpaqueExtAudioFile=},N,V_fFile
Tf,R,N,V_scaleFactor
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
musicVolume
musicVolumeWithCompletion:
alarmVolume
fetchVolumeFromAVSystemControllerForAudioCategory:
systemVolumeDidChange:
systemControllerDied:
startObservingSystemVolumes
_startObservingSystemControllerLifecycle
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
initializeTimerState
timerState
_timerFiringState
initializeAlarmState
alarmState
_alarmFiringState
name
setName:
_name
T@"NSString",&,N,V_name
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
assetManagerEnabledPolicy
startAttendingWithContext:
stopAttendingWithContext:
siriRequestProcessingCompleted
attSiriDidDetectAttendingTrigger:
attSiriAttendingTimeoutTriggered
attSiriAttendingFailed
invalidate
_setupAttSiriSvcXpcConnection
attSiriSvcConn
setAttSiriSvcConn:
remoteSvcProxy
setRemoteSvcProxy:
_attSiriSvcConn
_remoteSvcProxy
T@"NSXPCConnection",&,N,V_attSiriSvcConn
T@,&,N,V_remoteSvcProxy
T@"<CSAttSiriServiceDelegate>",W,N,V_delegate
sharedManager
getCurrentFanInfo:
fanId
setFanId:
currentSpeed
setCurrentSpeed:
targetSpeed
setTargetSpeed:
_fanId
_currentSpeed
_targetSpeed
TQ,N,V_fanId
Tq,N,V_currentSpeed
Tq,N,V_targetSpeed
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
deviceId
setDeviceId:
isSecondPassRunning
setIsSecondPassRunning:
firstPassMyriadGoodnessScore
setFirstPassMyriadGoodnessScore:
_isSecondPassRunning
_firstPassMyriadGoodnessScore
_deviceId
T@"NSString",&,N,V_deviceId
TB,N,V_isSecondPassRunning
Tf,N,V_firstPassMyriadGoodnessScore
voiceTriggerDidDetectKeyword:deviceId:
voiceTriggerDidDetectKeyword:deviceId:completion:
voiceTriggerDidDetectNearMiss:deviceId:
voiceTriggerDidDetectSpeakerReject:
keywordDetectorDidDetectKeyword
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:deviceId:
voiceTriggerDidDetectKeyword:myriadHash:remoteTriggerType:remoteDeviceId:isTriggeredFromFullWake:completion:
secondPassDidStartForClient:deviceId:withFirstPassEstimate:
secondPassDidStopForClient:deviceId:
initWithTargetQueue:
isBultInVoiceTriggerEvent:
isRemoraVoiceTriggerEvent:
_clearPendingRemoraVoiceTrigger
handlePendingRemoraVoiceTriggerIfNeeded
_clearPendingBuiltInVoiceTrigger
handlePendingBuiltInVoiceTriggerIfNeeded
_getHighestRemoraFirstPassGoodnessScore:
_isRemoraSecondPassRunning
builtInSeconPassProgressProvider
setBuiltInSeconPassProgressProvider:
remoraSecondPassProgressProvider
setRemoraSecondPassProgressProvider:
targetQueue
setTargetQueue:
pendingRemoraVoiceTriggerResult
setPendingRemoraVoiceTriggerResult:
pendingRemoraVoiceTriggerDeviceId
setPendingRemoraVoiceTriggerDeviceId:
pendingRemoraVoiceTriggerCompletionBlk
setPendingRemoraVoiceTriggerCompletionBlk:
pendingRemoraVoiceTriggerDetectedTime
setPendingRemoraVoiceTriggerDetectedTime:
pendingBuiltInVoiceTriggerResult
setPendingBuiltInVoiceTriggerResult:
pendingBuiltInVoiceTriggerCompletionBlk
setPendingBuiltInVoiceTriggerCompletionBlk:
pendingBuiltInVoiceTriggerDetectedTime
setPendingBuiltInVoiceTriggerDetectedTime:
builtInVoiceTriggerMetaData
setBuiltInVoiceTriggerMetaData:
accessoryVoiceTriggerMetaDataByDeviceId
setAccessoryVoiceTriggerMetaDataByDeviceId:
_builtInSeconPassProgressProvider
_remoraSecondPassProgressProvider
_targetQueue
_pendingRemoraVoiceTriggerResult
_pendingRemoraVoiceTriggerDeviceId
_pendingRemoraVoiceTriggerCompletionBlk
_pendingRemoraVoiceTriggerDetectedTime
_pendingBuiltInVoiceTriggerResult
_pendingBuiltInVoiceTriggerCompletionBlk
_pendingBuiltInVoiceTriggerDetectedTime
_builtInVoiceTriggerMetaData
_accessoryVoiceTriggerMetaDataByDeviceId
T@"NSObject<OS_dispatch_queue>",&,N,V_targetQueue
T@"NSDictionary",&,N,V_pendingRemoraVoiceTriggerResult
T@"NSString",&,N,V_pendingRemoraVoiceTriggerDeviceId
T@?,C,N,V_pendingRemoraVoiceTriggerCompletionBlk
TQ,N,V_pendingRemoraVoiceTriggerDetectedTime
T@"NSDictionary",&,N,V_pendingBuiltInVoiceTriggerResult
T@?,C,N,V_pendingBuiltInVoiceTriggerCompletionBlk
TQ,N,V_pendingBuiltInVoiceTriggerDetectedTime
T@"CSPreMyriadVoiceTriggerMetaData",&,N,V_builtInVoiceTriggerMetaData
T@"NSMutableDictionary",&,N,V_accessoryVoiceTriggerMetaDataByDeviceId
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
T@"<CSSecondPassProgressProviding>",W,N,V_builtInSeconPassProgressProvider
T@"<CSSecondPassProgressProviding>",W,N,V_remoraSecondPassProgressProvider
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
avvcContextSettings
_adaptiveSiriVolumeDictionary
SSVEnergyBufferSize
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
SSVNoiseMicSensitivityOffset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVDistanceChannelBitset
SSVCAMaxFrameSize
SSVCAVoiceTriggerBasedTTSValidForSeconds
SSVCASmartSiriVolumeUnsyncedMetricLogsToRetain
SSVCASmartSiriVolumeSyncedMetricLogsToRetain
SSVCAVoiceTriggerInitialSilenceDurationSeconds
SSVCADistanceInputBufferDurationSeconds
SSVCAListenPollingIntervalAtStartInSeconds
SSVCADefaultZeroFloatingPointValue
SSVCAAnnouncementStatusFetchTimeoutMs
SSVCADefaultOutputTTSVolume
SSVCANoiseActivityCountThreshold
SSVCASpeakerDistanceFarBoostFactor
SSVCASpeakerDistanceMidBoostFactor
SSVCASpeakerDistanceNearBoostFactor
SSVCADistanceModelConfidenceThreshold
SSVCAMinimumLinearSoundLevel
SSVCAMaximumLinearSoundLevel
SSVCALinearToDecibelConstantMultiplier
SSVCADecibelToLinearLogBase
SSVCASignalToSigmoidNoiseDilationFactor
SSVCASignalToSigmoidMusicDilationFactorDeviceDefault
SSVCASignalToSigmoidMusicDilationFactorDeviceSimple
SSVCASignalToSigmoidSpeechDilationFactor
SSVCASignalToSigmoidNoiseVSpread
SSVCASignalToSigmoidMusicVSpreadDeviceDefault
SSVCASignalToSigmoidMusicVSpreadDeviceSimple
SSVCASignalToSigmoidSpeechVSpread
SSVCASignalToSigmoidNoiseVOffset
SSVCASignalToSigmoidMusicVOffsetDeviceDefault
SSVCASignalToSigmoidMusicVOffsetDeviceSimple
SSVCASignalToSigmoidSpeechVOffset
SSVCASignalToSigmoidNoiseHOffset
SSVCASignalToSigmoidMusicHOffsetDeviceDefault
SSVCASignalToSigmoidMusicHOffsetDeviceSimple
SSVCASignalToSigmoidSpeechHOffset
SSVCASignalToSigmoidMusicSteepnessDeviceDefault
SSVCASignalToSigmoidMusicSteepnessDeviceSimple
SSVCASignalToSigmoidNoiseSteepness
SSVCASignalToSigmoidSpeechSteepness
SSVCADBToTTSMinimumOutput
SSVCADBToTTSMaximumOutput
SSVCADBToTTSTransitionPoint
SSVCADBToTTSPreTransitionOffset
SSVCADBToTTSPreTransitionMultiplier
SSVCADBToTTSPostTransitionOffset
SSVCADBToTTSPostTransitionDC
SSVCADBToTTSPostTransitionMultiplier
SSVCAMinimumDistanceUpdateWaitPeriodSeconds
SSVCANoiseActivityThreshold
SSVCANoiseResultsBufferSize
SSVCAMusicResultsBufferSize
SSVCADefaultSpeechStrength
SSVCADefaultMusicStrength
SSVCANoiseActivityHistoricalSampleCount
SSVCADspCoefsCount
SSVCADspNumStages
SSVCADistanceResultsBufferSize
SSVCAExponentialDistanceHistoryDegradationFactor
SSVCADistanceResultSampleCountTolerance
SSVCAMusicHistoricalSamplesInSeconds
SSVCADeviceSimpleOutputMinTargetDB
SSVCADeviceSimpleOutputMaxTargetDB
SSVCADeviceSimpleOutputSlope
SSVCADeviceSimpleMinTargetDB
SSVCADeviceSimpleMaxTargetDB
SSVCADeviceSimpleDBToSystemVolSlope
SSVCADeviceSimpleMicSensitivityOffset
SSVCADeviceSimplePreTriggerSilenceSampleCount
SSVCAMinTTSSystemVolume
SSVCAMaxTTSSystemVolume
SSVCAUserIntentValidForSeconds
SSVCAUserIntentVolumeIncreaseFactor
SSVCAUserIntentVolumeDecreaseFactor
SSVCAUserIntentPermanentOffsetFactorDelta
SSVCAUserIntentPermanentOffsetFactorLowerBound
SSVCAUserIntentPermanentOffsetFactorUpperBound
SSVCADeviceSimpleMinTTSVolume
SSVCADeviceSimpleMaxTTSVolume
SSVCADeviceDefaultMinTTSVolume
SSVCADeviceDefaultMaxTTSVolume
SSVCADeviceDefaultASVOffMinTTSVolume
SSVCADeviceSimpleASVOffMinTTSVolume
SSVCADeviceDefaultMicSensitivityOffset
SSVCAVolumeHalfLifeSeconds
SSVCAHistoricalVolumeBufferSize
SSVCAMaximumCompensatedSpeechLevelNearField
_getNumberFromASVDictionaryForKey:category:default:
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
TI,R,N
T@"NSDictionary",R,N
Ti,R,N
Td,R,N
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
initWithRecordDeviceInfo:playbackRoute:playbackDeviceTypeList:
initWithXPCObject:
xpcObject
recordDeviceInfo
playbackRoute
playbackDeviceTypeList
_recordDeviceInfo
_playbackRoute
_playbackDeviceTypeList
T@"CSAudioRecordDeviceInfo",R,C,N,V_recordDeviceInfo
T@"NSString",R,C,N,V_playbackRoute
T@"NSArray",R,C,N,V_playbackDeviceTypeList
didReceiveSpeakerRecognitionScoreCard:
didFinishSpeakerRecognition:
initWithDelegate:
startXPCConnection
invalidateXPCConnection
ssrXPCClient
setSsrXPCClient:
_ssrXPCClient
T@"CSSSRXPCClient",&,N,V_ssrXPCClient
T@"<CSSpeakerRecognitionProxyProtocol>",R,W,N,V_delegate
sharedService
voiceTriggerXPCClient:didDisconnect:
enableVoiceTrigger:withAssertion:xpcClient:
enableVoiceTrigger:withAssertion:
setPhraseSpotterBypassing:timeout:xpcClient:
setPhraseSpotterBypassing:timeout:
setRaiseToSpeakBypassing:timeout:xpcClient:
setRaiseToSpeakBypassing:timeout:
notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:
fetchVoiceTriggerDailyStats
notifyVoiceTriggeredSiriSessionCancelled
_createXPCClientConnectionIfNeeded:
T@"CSVoiceTriggerXPCClient",&,N,V_xpcClient
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
_notificationKey
_didInstalledNewVoiceTriggerAsset
_notifyObserver:
_notifyToken
getCSAssetOfType:
_footprint
_version
_compatibilityVersion
isPremium
path
isDownloading
isCSAssetInstalled
canBePurged
isLatestCompareTo:
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
initWithSampleRate:withNumberOfChannels:
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
processBuffer:atTime:arrivalTimestampToAudioRecorder:
flush
willBeepWithRecordRoute:playbackRoute:
reportMetricsForSiriRequestWithUUID:
_reportMetrics
_fetchCurrentMetrics
_isNarrowBand:
sampleRate
setSampleRate:
upsampler
setUpsampler:
zeroFilter
setZeroFilter:
beepCanceller
setBeepCanceller:
zeroCounter
setZeroCounter:
numChannels
setNumChannels:
_sampleRate
_numChannels
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
Tf,N,V_sampleRate
T@"CSAudioSampleRateConverter",&,N,V_upsampler
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
T@"CSBeepCanceller",&,N,V_beepCanceller
T@"CSAudioZeroCounter",&,N,V_zeroCounter
Ti,N,V_numChannels
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
handleOtherAppRecordingStateChange:
isOtherNonEligibleAppRecording
_startObservingOtherAppRecordingState
_systemControllerDied:
createBenchamrkXPCConnection
pingpong:completion:
runLstmPhsModelWithConfig:withUrl:completion:
runVTSecondPassModelWithConfig:locale:withUrl:completion:
runOSDAnalyzerWithConfig:withUrl:completion:
smartSiriVolumeEnablePolicy
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
allowVoiceTriggerAccessoryAssetDownloading
setAllowVoiceTriggerAccessoryAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
_allowVoiceTriggerAccessoryAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
TB,N,V_allowEndpointAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
TB,N,V_allowVoiceTriggerAccessoryAssetDownloading
_subscribeEventMonitors
_addSmartSiriVolumeEnabledConditions
_addContinousAudioFingerprintEnabledConditions
getBTLocalDeviceWithCompletion:
getWirelessSplitterInfoWithCompletion:
_getWirelessSplitterInfoFromLocalDevice:
_detachBluetoothSession
_attachBluetoothSession
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
_setUpLocalDevice
_tearDownLocalDevice
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
T^{BTSessionImpl=},N,V_bluetoothSession
TB,N,V_isAttachingBluetoothSession
T^{BTLocalDeviceImpl=},N,V_localDevice
T@"NSArray",&,N,V_pairedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
propertyDictForDarwin
wakeHostForVoiceTrigger
_device
_hidCallbackQueue
CSSiriAssertionMonitor:didReceiveEnabled:
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
enableAssertionReceived
disableAssertionReceived
isEnabled
_assertionState
_init
notifyWillStartStreamWithContext:option:forAccessory:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:forAccessory:
notifyWillStopStream:reason:forAccessory:
notifyDidStopStream:reason:withEventUUID:forAccessory:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
_didInstalledNewAsset
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
initWithTimeout:
audioFileReaderDidStartRecording:successfully:error:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStopRecording:forReason:
initWithURL:
setRecordBufferDuration:
prepareRecording:
startRecording
_readAudioBufferAndFeed
stopRecording
readSamplesFromChannelIdx:
close
_audioFeedTimer
_bufferDuration
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
_didInstalledNewAdBlockerAsset
monitor
setMonitor:
_monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
getHearstConnected:
hearstConnected
getHearstRouted:
hearstRouted
getJarvisConnected:
jarvisConnected
carPlayConnected
siriInputSourceOutOfBand
getSiriInputSourceOutOfBand:
activeAudioRouteDidChange:
_startObservingAudioRouteChange
_fetchHearstRoutedState
_notifyHearstRoutedState:
_fetchSiriInputSourceOutOfBandState
_notifySiriInputSourceOutOfBandState:
_isHearstConnected
_isHearstRouted
_isSiriInputSourceOutOfBand
downsampler
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
convertSampleRateOfBuffer:
_sampleRateConverter
_outBufferScaleFactor
_inASBD
languageDetectorAssetMonitor:didReceiveNewAssetWithSupportLocale:
startMonitor
supportedLocale:
_supportedLocale:
notifyToken
setNotifyToken:
Ti,N,V_notifyToken
T@"<CSLanguageDetectorAssetMonitorDelegate>",W,N,V_delegate
initWithSessionUUID:turnIdentifier:
becomeCurrent
resignCurrent
updateStartSpeechId:
updateSelectedResultCandidateId:
updateAccessToRecordedAudioForVoiceIdentificationTraining:forResultCandidateId:sharedUserId:
getAudioRecordRouteAndDeviceIdentificationWithCompletion:
acquireRecordedAudioWithHandler:
updateAudioRecordContext:
updateAudioRecordDeviceInfo:
updateVoiceTriggerInfo:
updateRecordingInfo:
updateRecordingSettings:
willPrepareAndStartRecordingWithAudioActivationInfo:
didDetectTwoShotWithAudioActivationInfo:atTime:
willStopRecordingAtHostTime:
didStopRecordingWithError:
relinquishAudioSessionAssertionsWithContext:
relinquishAudioSessionAssertionsWithError:
beginRecordingAudioWithAudioStreamBasicDescription:
appendRecordedAudioBuffer:
endRecordingAudio
_initializeAudioFileWriterWithAudioStreamBasicDescription:
_finalizeAudioFileWriterWithCompletion:
instrumentSiriCue:
_instrumentSiriCue:
instrumentSiriCueForAlertType:
emitRequestLinkEventForMHUUID:
_createRequestLinkInfo:component:
_didBecomeCurrent
_didResignCurrent
_donateRecordedAudioForVoiceIdentificationTrainingWithCompletion:
_removeRecordedAudio
sessionUUID
wantsRecordedAudioBufferLogs
_isCurrent
_startSpeechId
_selectedResultCandidateId
_audioRecordContext
_audioRecordDeviceInfo
_voiceTriggerInfo
_recordingSettings
_recordingInfo
_audioFileWriter
_recordedAudioFileURL
_startRecordingAudioSessionAssertion
_twoShotDetectionAudioSessionAssertion
_recordingAudioGroup
_voiceIdentificationTraining_allowsWithoutResultCandidate
_voiceIdentificationTraining_allowedResultCandidateIds
_voiceIdentificationTraining_resultCandidateToSharedUserIdMap
_turnIdentifier
_voiceIdentificationTraining_withoutResultCandidateSharedUserId
_stopRecordingInstrumented
_wantsRecordedAudioBufferLogs
_sessionUUID
T@"NSString",R,C,N,V_sessionUUID
TB,R,N,V_wantsRecordedAudioBufferLogs
didSmartSiriVolumeChangeForReason:
getVolumeForTTSType:withContext:reply:
setSmartSiriVolumePercentage:
setSmartSiriVolumeDirection:
setPermanentVolumeOffsetWithDirection:
didTTSVolumeChangeForReason:
getVolumeForTTSType:withContext:
_getRemoteServiceProxyObject
_createClientConnection
ssvConnection
setSsvConnection:
_ssvConnection
T@"NSXPCConnection",&,N,V_ssvConnection
T@"<CSSmartSiriVolumeClientDelegate>",W,N,V_delegate
isPluginContext
audioRecorderStreamHandleIdInvalidated:
audioRecorderWillBeDestroyed:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
defaultInjectionProvider
createSharedAudioSession
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
_createSpeechDetectionVADIfNeeded
primaryInputDevice
connectDevice:
disconnectDevice:
willDestroy
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setContext:completion:
setCurrentContext:streamHandleId:error:
prepareAudioStreamRecord:recordDeviceIndicator:error:
startAudioStreamWithOption:recordDeviceIndicator:error:
stopAudioStreamWithRecordDeviceIndicator:error:
isRecordingWithRecordDeviceIndicator:
recordRouteWithRecordDeviceIndicator:
recordDeviceInfoWithStreamHandleId:recordDeviceIndicator:
audioDeviceInfoWithStreamHandleId:recordDeviceIndicator:
recordSettingsWithStreamHandleId:
recordingSampleRateWithStreamHandleId:
isNarrowBandWithStreamHandleId:
prewarmAudioSessionWithStreamHandleId:error:
activateAudioSessionWithReason:streamHandleId:error:
deactivateAudioSession:streamHandleId:error:
deactivateAudioSession:error:
setRecordMode:streamHandleId:error:
setDuckOthersOption:
duckOthersOption
setAlertSoundFromURL:forType:force:
playRecordStartingAlertAndResetEndpointerFromStream:
playAlertSoundForType:recordDevideIndicator:
alertStartTime
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
isSessionCurrentlyActivated
voiceTriggerInfoWithRecordDeviceIndicator:
enableMiniDucking:
metrics
configureAlertBehavior:audioStreamHandleId:
didStartDelayInSeconds
setDidStartDelayInSeconds:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
activateStartTime
setActivateStartTime:
activateEndTime
setActivateEndTime:
deactivateStartTime
setDeactivateStartTime:
deactivateEndTime
setDeactivateEndTime:
atvRemoteDeviceID
setAtvRemoteDeviceID:
_didStartDelayInSeconds
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
_activateStartTime
_activateEndTime
_deactivateStartTime
_deactivateEndTime
_atvRemoteDeviceID
T@"NSMutableArray",&,N,V_connectedDevices
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
TQ,N,V_latestPluginStreamId
TQ,N,V_activateStartTime
TQ,N,V_activateEndTime
TQ,N,V_deactivateStartTime
TQ,N,V_deactivateEndTime
T@"NSString",&,N,V_atvRemoteDeviceID
Tf,N,V_didStartDelayInSeconds
_cs_initWithXPCObject:
_cs_xpcObject
opportuneSpeakListener:didStopUnexpectly:
opportuneSpeakListener:hasRemoteVADAvailable:
opportuneSpeakListener:hasVADAvailable:withHostTime:
opportuneSpeakListener:hasVADAvailable:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
spgEndpointAnalyzer:hasSilenceScoreEstimate:clientProcessedAudioTimeMS:
spgEndpointAnalyzerDidDetectEndpoint:
startListenWithOption:completion:
_resetAlignBuffer
_startRequestWithCompletion:
stopListenWithStateReset:completion:
stopListenWithCompletion:
_addRemoteVADSignal:
_popRemoteVADSignal
_shouldReportBoron
audioStream
setAudioStream:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
runningSampleCount
setRunningSampleCount:
audioTimeConverter
setAudioTimeConverter:
_isMediaPlayingNow
_remoteVADSPGRatio
_audioStream
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_runningSampleCount
_audioTimeConverter
T@"CSAudioStream",&,N,V_audioStream
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
Ti,N,V_remoteVADSPGRatio
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
T@"CSAudioRecordContext",&,N,V_latestContext
TB,V_isMediaPlayingNow
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
TQ,N,V_remoteVADAlignCount
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
TQ,N,V_runningSampleCount
T@"CSAudioTimeConverter",&,N,V_audioTimeConverter
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
connect
disconnect
_handleListenerEvent:
_handleListenerError:
_notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
_sendMessage:connection:completion:
_decodeError:
xpcConnection
setXpcConnection:
_xpcConnection
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
initWithRMSScore:lastSampleCount:
compareScoresDesc:
RMSScore
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
Td,N,V_RMSScore
TQ,N,V_lastSampleCount
addDataToBuffer:
calculateShadowMicScore
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
numberOfVoicingFrames
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
T@"NSMutableData",&,N,V_audioBuffer
Td,N,V_speechVoiceLevel
TQ,N,V_numberOfVoicingFrames
Tq,N,V_numberOfTotalFramesETFT
TQ,N,V_bestStartDetectSample
TQ,N,V_bestEarlyDetectSample
TQ,N,V_bestEndDetectSample
Td,N,V_shadowMicScore
CSBluetoothWirelessSplitterMonitor:didReceiveSplitterStateChange:shouldDisableSpeakerVerificationInSplitterMode:
updateSplitterState:shouldDisableSpeakerVerificationInSplitterMode:
splitterState:
_didReceiveWirelessSplitterStateChange
_notifyObserver:splitterState:shouldDisableSpeakerVerificationInSplitterMode:
_splitterState
continuousAudioFingerprintEnabledPolicy
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:withNumChannels:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
fetchVoiceTriggerHeartBeatMetrics
reset
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
setStartWaitTime:
automaticEndpointingSuspensionEndTime
setAutomaticEndpointingSuspensionEndTime:
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
setEndWaitTime:
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
mhId
setMhId:
Tq,N
Td,N
TB,N
T@"NSString",&,N
resetForNewRequestWithSampleRate:recordContext:
processAudioSamplesAsynchronously:
stopEndpointer
recordingStoppedForReason:
implDelegate
setImplDelegate:
canProcessCurrentRequest
activeChannel
setActiveChannel:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
processOSDFeatures:withFrameDurationMs:
processFirstAudioPacketTimestamp:firstAudioSampleSensorTimestamp:
setEndpointerOperationMode:
fetchCurrentEndpointerOperationMode
logAnchorMachAbsTime:numSamplesProcessedBeforeAnchorTime:isAnchorTimeBuffered:
processASRFeatures:fromServer:
processTaskString:
endpointerModelVersion
elapsedTimeWithNoSpeech
T@"<CSEndpointAnalyzerDelegate>",W,N
T@"<CSEndpointAnalyzerImplDelegate>",W,N
TQ,N
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
T@"NSString",&,N,VmhId
notifyActivationEvent:completion:
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startOfSpeechDetectedAtFrame:
languageDetectorDidCompleteProcessing:loggingInfo:
languageDetector:confidences:
languageDetector:result:
startOfSpeechDetector:foundStartSampleAt:
initWithModelURL:
_startMonitorLanguageDetectorAssetDownload
_setupLanguageDetectorWithOption:
resetForNewRequest:
addSamples:numSamples:
endAudio
_resetStartOfSpeechDetector
cancelCurrentRequest
setInteractionIDforCurrentRequest:
_initializeStartOfSpeechDetector:samplingRate:
recordRecognitionLanguage:
_recordRecognitionLanguage:
setMostRecentRecognitionLanguage:
_constructLangPriors
_setNumLatestLangFromConfigFile:
_readJsonDictionaryAt:
_getDefaultValues
_logSoSResult:toPath:
_logLanguageDetectorMetricsForLoggingInfo:
languageDetector
setLanguageDetector:
startOfSpeechDetector
setStartOfSpeechDetector:
circBuffer
setCircBuffer:
startOfSpeechDetected
setStartOfSpeechDetected:
needsToUpdateModel
setNeedsToUpdateModel:
currentState
setCurrentState:
latestDetectedLanguages
setLatestDetectedLanguages:
numLatestLanguages
setNumLatestLanguages:
languageDetectorAssetHash
setLanguageDetectorAssetHash:
currentAsset
setCurrentAsset:
interactionID
setInteractionID:
_startOfSpeechDetected
_needsToUpdateModel
_languageDetector
_startOfSpeechDetector
_circBuffer
_currentState
_latestDetectedLanguages
_numLatestLanguages
_languageDetectorAssetHash
_currentAsset
_interactionID
T@"_EARLanguageDetector",&,N,V_languageDetector
T@"_EARLanguageDetectorAudioBuffer",&,N,V_audioBuffer
T@"CSStartOfSpeechDetector",&,N,V_startOfSpeechDetector
T@"CSAudioCircularBuffer",&,N,V_circBuffer
TB,N,V_startOfSpeechDetected
TB,N,V_needsToUpdateModel
Tq,N,V_currentState
T@"NSMutableArray",&,N,V_latestDetectedLanguages
TQ,N,V_numLatestLanguages
T@"NSString",C,N,V_languageDetectorAssetHash
T@"CSAsset",&,N,V_currentAsset
T@"NSString",C,N,V_interactionID
T@"<CSLanguageDetectorDelegate>",W,N,V_delegate
getSiriLanguageWithFallback:
getSiriLanguageWithEndpointId:fallbackLanguage:
_shouldDisableSpeakerVerificationInSplitterMode
initWithStopRecordingReason:expectedStopHostTime:trailingSilenceDurationAtEndpoint:
stopRecordingReason
expectedStopHostTime
trailingSilenceDurationAtEndpoint
_stopRecordingReason
_expectedStopHostTime
_trailingSilenceDurationAtEndpoint
TQ,R,N,V_stopRecordingReason
TQ,R,N,V_expectedStopHostTime
Td,R,N,V_trailingSilenceDurationAtEndpoint
deviceIsInSleep
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
reportMHEndpointerAccessibleContextEventWithThresholdType:MhId:
reportServerEndpointWithMhId:
initWithRequestMHUUID:
addPktInfoWithTimestamp:arrivalTimestamp:currentMachTime:
report
_emitMHEndpointLatencyInfo:withRequestMHUUID:
firstPktLatency
setFirstPktLatency:
requestMHUUID
setRequestMHUUID:
trailingPktSpeechLatencies
setTrailingPktSpeechLatencies:
trailingPktLatencies
setTrailingPktLatencies:
numOfAudioPackets
setNumOfAudioPackets:
numOfValidTrailingPackets
setNumOfValidTrailingPackets:
numOfValidTrailingSpeechPackets
setNumOfValidTrailingSpeechPackets:
_firstPktLatency
_requestMHUUID
_trailingPktSpeechLatencies
_trailingPktLatencies
_numOfAudioPackets
_numOfValidTrailingPackets
_numOfValidTrailingSpeechPackets
T@"NSMutableArray",&,N,V_trailingPktSpeechLatencies
T@"NSMutableArray",&,N,V_trailingPktLatencies
TQ,N,V_numOfAudioPackets
TQ,N,V_numOfValidTrailingPackets
TQ,N,V_numOfValidTrailingSpeechPackets
Td,N,V_firstPktLatency
T@"NSString",&,N,V_requestMHUUID
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
isStreaming
_notifyStopCommandControl
_isCommandControlStreaming
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
_didReceiveAVVCRecordingClientNumberChange:
numOfAVVCRecordingClients
alwaysOnProcessorController
setAlwaysOnProcessorController:
_numOfAVVCRecordingClients
_alwaysOnProcessorController
T@"AVVoiceTriggerClient",&,N,V_alwaysOnProcessorController
TQ,R,N,V_numOfAVVCRecordingClients
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
initWithCrashMonitor:
getAudioSessionState
setAudioSessionState:
_audioSessionState
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
objectForKeyedSubscript:
setObject:forKeyedSubscript:
enumerateObjects:
_savedAudioFilesDirectory
_generateTemporaryFileURL
initWithType:pathGenerator:priority:
initWithType:fileHandle:priority:
_initWithType:pathGenerator:xorFileHandle:priority:
_close
_delete
configureWithAudioStreamBasicDescription:
appendAudioData:
flushWithCompletion:
cancel
_type
_url
_path
_audioFile
_asbd
_fileHandle
_underlyingError
getCoreSpeechServiceConnection
getCoreSpeechXPCConnection
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
getCurrentVoiceTriggerLocaleWithEndpointId:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
_didReceiveCanUseVoiceTriggerDuringCallSettingChangedInQueue:
_notifyObserver:withEnabled:
_checkCanUseVoiceTriggerDuringCallEnabled
_voiceTriggerDuringCallEnabledDidChange
_isEnabled
defaultRequestWithContext:
requestForLpcmRecordSettingsWithContext:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
initTandemWithRequest:
recordContext
setRecordContext:
requiresHistoricalBuffer
setRequiresHistoricalBuffer:
useCustomizedRecordSettings
setUseCustomizedRecordSettings:
audioFormat
setAudioFormat:
lpcmBitDepth
setLpcmBitDepth:
lpcmIsFloat
setLpcmIsFloat:
numberOfChannels
setNumberOfChannels:
encoderBitRate
setEncoderBitRate:
isSiri
setIsSiri:
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_numberOfChannels
_encoderBitRate
_recordContext
_audioFormat
T@"NSObject<OS_xpc_object>",R,N
T@"CSAudioRecordContext",&,N,V_recordContext
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
T@"NSString",C,N,V_deviceId
sharedVoiceTriggerClient
sharedManagerForCoreSpeechDaemon
activationEventNotificationHandler:event:completion:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioProviderInvalidated:streamHandleId:
opportuneSpeakEventMonitor:didStreamStateChanged:
startManager
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithContext:error:
audioProviderWithStreamID:
fetchFallbackAudioSessionReleaseProvider
_getAudioRecorderWithError:
_reinitializeSmartSiriVolumeWithAsset:
_handleClearLoggingFileTimer
_createClearLoggingFileTimer
_startClearLoggingFilesTimer
assetQueryQueue
setAssetQueryQueue:
audioRecorder
setAudioRecorder:
audioProviders
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
ssvManager
setSsvManager:
_assetQueryQueue
_audioRecorder
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
_ssvManager
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"CSAudioRecorder",&,N,V_audioRecorder
T@"NSMutableDictionary",&,N,V_audioProviders
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
Tq,N,V_clearLoggingFileTimerCount
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
addNumSamples:hostTime:
notifyTrailingSilenceDurationAtEndpoint:
estimatedSpeechEndHostTime
numAudioSampleForwarded
setNumAudioSampleForwarded:
lastAudioChunkHostTime
setLastAudioChunkHostTime:
endPointNotified
setEndPointNotified:
setTrailingSilenceDurationAtEndpoint:
_endPointNotified
_numAudioSampleForwarded
_lastAudioChunkHostTime
TQ,N,V_numAudioSampleForwarded
TQ,N,V_lastAudioChunkHostTime
TB,N,V_endPointNotified
Td,N,V_trailingSilenceDurationAtEndpoint
CSClamshellStateMonitor:didReceiveClamshellStateChange:
isClamshellClosed
_didReceiveClamshellStateChangeNotification:
_notifyObserver:withClamshellState:
commandControlListener:didStopUnexpectly:
commandControlListener:hasLPCMBufferAvailable:
T@"<CSCommandControlListenerDelegate>",W,N,V_delegate
flexKwdConfigFile
flexKwdThresholdFile
CSAssetManagerDidDownloadNewAsset:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
CSAssetController:didDownloadNewAssetForType:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
initWithDownloadOption:
setAssetDownloadingOption:
assetForCurrentLanguageOfType:
allInstalledAssetsOfType:language:
assetForCurrentLanguageOfType:completion:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
assetOfType:language:
assetOfType:language:completion:
assetOfType:language:compatibilityVersion:completion:
installedAssetOfType:language:
installedAssetOfType:language:completion:
assetOfType:providerType:language:completion:
_fetchRemoteMetaData
_canFetchRemoteAsset:
currentLanguageCode
addObserver:forAssetType:
removeObserver:forAssetType:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
setupConnection
processServerFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
getEndpointerModelVersionWithReply:
getElapsedTimeNoSpeechWithReply:
getEndPointAnalyzerTypeWithReply:
resetForVoiceTriggerTwoShotWithSampleRate:
didDetectStartpointAtTime:
didDetectHardEndpointAtTime:withMetrics:
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
endPointAnalyzerType
resetForNewRequestWithSampleRate:recordContext:recordOption:voiceTriggerInfo:
endpointerDelegate
setEndpointerDelegate:
endpointerConnection
setEndpointerConnection:
xpcConnectionQueue
setXpcConnectionQueue:
xpcClientQueue
setXpcClientQueue:
xpcDelegateQueue
setXpcDelegateQueue:
remoteObjectProxy
setRemoteObjectProxy:
_endpointerDelegate
_endpointerConnection
_xpcConnectionQueue
_xpcClientQueue
_xpcDelegateQueue
_remoteObjectProxy
T@"NSXPCConnection",&,N,V_endpointerConnection
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcConnectionQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcClientQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcDelegateQueue
T@,&,N,V_remoteObjectProxy
initWithDataSource:assetsProvider:
addDelegate:
removeDelegate:
startWithNviContext:didStartHandler:
stopWithDidStopHandler:
sigType
listener:shouldAcceptNewConnection:
notifyClientsWithBlock:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:
initWithMachService:withServiceInterface:withServiceObject:withDelegateInterface:queue:
resumeConnection
clientConnections
setClientConnections:
machServiceName
setMachServiceName:
_listener
_exportedInterface
_remoteInterface
_proxyObject
_clientConnections
_machServiceName
T@"NSMutableArray",&,N,V_clientConnections
T@"NSString",&,N,V_machServiceName
audioRecorderWithQueue:error:
CSVoiceTriggerFirstPassMetricsWithFirstPassInfoGeneratedTime:firstPassInfoProcessedTime:
_initWithFirstPassInfoGeneratedTime:firstPassInfoProcessedTime:
firstPassInfoGeneratedTime
firstPassInfoProcessedTime
_firstPassInfoGeneratedTime
_firstPassInfoProcessedTime
T@"NSNumber",R,N,V_firstPassInfoGeneratedTime
T@"NSNumber",R,N,V_firstPassInfoProcessedTime
speechController:willSetAudioSessionActive:
speechController:didSetAudioSessionActive:
speechControllerDidStartRecording:audioDeviceInfo:successfully:error:
speechControllerDidStartRecording:successfully:error:
speechControllerDidDetectVoiceTriggerTwoShot:atTime:wantsAudibleFeedback:
speechControllerDidDetectVoiceTriggerTwoShot:atTime:
speechControllerRequestsOperation:forReason:completion:
speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:
speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:
speechControllerDidStopRecording:forReason:estimatedSpeechEndHostTime:
speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:
speechControllerLPCMRecordBufferAvailable:buffer:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:audioDeviceInfo:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:
speechControllerRecordHardwareConfigurationDidChange:toConfiguration:
speechControllerDidFinishAlertPlayback:ofType:error:
speechControllerBeginRecordInterruption:
speechControllerBeginRecordInterruption:withContext:
speechControllerEndRecordInterruption:
speechControllerDidUpdateSmartSiriVolume:forReason:
speechControllerRequestsOperation:forReason:
sharedController
isSmartSiriVolumeAvailable
audioConverterDidConvertPackets:packets:durationInSec:timestamp:arrivalTimestampToAudioRecorder:
didTTSVolumeChange:forReason:
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:arrivalTimestampToAudioRecorder:wasBuffered:receivedNumChannels:
endpointer:detectedTwoShotAtTime:
endpointer:reportEndpointBufferHostTime:firstBufferHostTime:
nowPlayingObserver:playbackStateDidChangeFrom:to:lastPlayingDate:
nowPlayingObserverNowPlayingInfoDidChange:
nowPlayingObserver:proxyGroupPlayerStateDidChangeFrom:to:
clockAlarmObserver:alarmDidFire:
clockAlarmObserver:alarmDidDismiss:
clockAlarmObserver:snapshotDidUpdateFrom:to:
clockTimerObserver:timerDidFire:
clockTimerObserver:timerDidDismiss:
clockTimerObserver:snapshotDidUpdateFrom:to:
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
continuousVoiceTrigger:detectedVoiceTriggerResult:
continuousVoiceTrigger:detectedSilenceAfterVoiceTriggerAt:
initWithEndpointId:xpcClientFactory:endpointer:continuousVoiceTrigger:siriVolumeController:mediaPlayingMonitor:alarmMonitor:timerMonitor:sacInfoMonitor:audioSessionController:supportPhatic:supportHearstVoiceTrigger:supportTriagleModeSessionActivationRetry:supportSessionActivateDelay:supportLazySessionActivtion:
_supportsHybridSDSD
_createMediaPlayingMonitor
_createAlarmMonitor
_createTimerMonitor
_initializeMediaPlayingState
_initializeAlarmState
_initializeTimerState
initializeRecordSessionWithRecordContext:
startController
_isHubRequestTV
_shouldResetContextAtPrepare
prepareRecordWithSettings:error:
_fetchLastTriggerInfo
_isDelayedDuckingSupportedContext
_currentConfigurationSupportsDucking
_activateAudioSessionWithReason:delay:delayRequested:error:
_scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:
_cancelPendingAudioSessionActivateForReason:
_performPendingAudioSessionActivateForReason:
_lazyActivateAudioSessionWithReason:error:
_activateAudioSessionWithReason:error:
_doActivateAudioSessionWithReason:error:
_updateRecordContextIfNeeded:
setCurrentRecordContext:error:
prewarmAudioSession
resetAudioSession
releaseAudioSession
releaseAudioSession:
recordSettings
getLPCMAudioStreamBasicDescription
setSynchronousCallbackEnabled:
getRecordBufferDuration
_refreshSpeakerRecognitionAssets
_setupSpeakerRecognitionController
_languageDetectorOptionFromSettings:
startRecordingWithSettings:error:
_startPhaticDecision
_createLanguageDetectorIfNeeded
_shouldUseLanguageDetector:
_shouldSetStartSampleCount
_shouldSetStartSampleCountForRTS
startRecording:
stopRecordingWithOptions:
_shouldReportEstimatedSpeechEndHostTime
_isRecordRouteBuiltinMic
recordRoute
audioDeviceInfo
_shouldFetchVoiceTriggerInfo
_shouldFetchRaiseToSpeakInfo
_didStopForReason:
_isDuckingAvailableRoute:
_audioStreamProvdider:audioBufferAvailable:
_setupDownsamplerIfNeeded
_setupAudioConverter:isNarrowBand:
playAlertSoundForType:
playRecordStartingAlertAndResetEndpointer
peakPowerForOutputReference
averagePowerForOutputReference
_createAudioPowerMeterIfNeeded
outputReferenceChannel
voiceTriggerInfo
fetchAudioMetricsWithCompletion:
endpointAnalyzer
setEndpointAnalyzerDelegate:
_currentAudioRecorderSampleRate
resetEndpointer
_shouldRunHybridSDSDMitigation
processRCWithId:duration:lrnnScore:lrnnThreshold:taskId:forceAccept:completionHandler:
getMitigationDecisionForRCId:completion:
_shouldUseSoundPlaybackMonitors
_shouldTrackLaunchLatency
_logRecordingStopErrorIfNeeded:
_fetchAudioDecoderForTV:
_fetchAudioProviderWithContext:
_createAudioProviderFromXPCWithContext:
_setupAudioProviderFromXPC:
_fetchFallbackAudioSessionReleaseProviding
_getSpeechIdentifier
_deviceAudioLoggingWithFileWriter:
_contextToString:
_canPlayPhaticDuringMediaPlayback
_shouldScheduleAudibleFeedbackAtStartRecording
_scheduledAudibleFeedbackDelay
_audibleFeedbackPlaybackReason
getVolumeForTTSType:
getSmartSiriVolume
languageDetectorSetMostRecentRecognitionLanguage:
cancelCurrentLanguageDetectorRequest
setLanguageDetectorInteractionID:
beginWaitingForMyriad
endWaitingForMyriadWithDecision:
_setSoundPlayingState
_teardownAudioProviderIfNeeded
_setMediaPlaybackState:isInterrupted:
_setAlarmIsPlaying:
_setTimerIsPlaying:
getAudioConverterForTest
languageDetectorDelegate
setLanguageDetectorDelegate:
speakerIdDelegate
setSpeakerIdDelegate:
supportPhatic
setSupportPhatic:
supportHearstVoiceTrigger
setSupportHearstVoiceTrigger:
supportTriagleModeSessionActivationRetry
setSupportTriagleModeSessionActivationRetry:
supportSessionActivateDelay
setSupportSessionActivateDelay:
supportLazySessionActivtion
setSupportLazySessionActivtion:
endpointerProxy
setEndpointerProxy:
audioRecordContext
setAudioRecordContext:
streamProvider
setStreamProvider:
sessionProvider
setSessionProvider:
alertProvider
setAlertProvider:
audioMeterProvider
setAudioMeterProvider:
audioMetricProvider
setAudioMetricProvider:
isAsrOnDevice
setIsAsrOnDevice:
isOpus
setIsOpus:
isSiriClientListening
setIsSiriClientListening:
isNarrowBand
setIsNarrowBand:
serverLoggingWriter
setServerLoggingWriter:
volumeController
setVolumeController:
recordEventUUID
setRecordEventUUID:
isAudioSessionActivated
setIsAudioSessionActivated:
deviceRoleIsStereo
setDeviceRoleIsStereo:
speakerRecognitionScores
setSpeakerRecognitionScores:
twoShotNotificationEnabled
setTwoShotNotificationEnabled:
isMediaPlaying
setIsMediaPlaying:
isAlarmPlaying
setIsAlarmPlaying:
isTimerPlaying
setIsTimerPlaying:
isSoundPlaying
setIsSoundPlaying:
isRemoteVADAvailableStream
setIsRemoteVADAvailableStream:
myriadPreventingTwoShotFeedback
setMyriadPreventingTwoShotFeedback:
speechEndHostTimeEstimator
setSpeechEndHostTimeEstimator:
bundleIdFromDictation
setBundleIdFromDictation:
shouldUseLanguageDetectorForCurrentRequest
setShouldUseLanguageDetectorForCurrentRequest:
pendingAudioSessionActivationToken
setPendingAudioSessionActivationToken:
pendingAudioSessionActivationCompletion
setPendingAudioSessionActivationCompletion:
pendingAudioSessionActivationReason
setPendingAudioSessionActivationReason:
audioSessionActivationDelay
setAudioSessionActivationDelay:
xpcClientFactory
setXpcClientFactory:
duckAudioXPCClient
setDuckAudioXPCClient:
cachedAvgPower
setCachedAvgPower:
cachedPeakPower
setCachedPeakPower:
powerMeter
setPowerMeter:
didDeliverLastBuffer
setDidDeliverLastBuffer:
didDeliverFirstSpeechPacket
setDidDeliverFirstSpeechPacket:
canPerformDelayedStop
setCanPerformDelayedStop:
hasPerformedDelayedStop
setHasPerformedDelayedStop:
requestedStopRecordingOptions
setRequestedStopRecordingOptions:
numTrailingSamplesAfterSchedulingStop
setNumTrailingSamplesAfterSchedulingStop:
maxAllowedTrailingSamplesAfterSchedulingStop
setMaxAllowedTrailingSamplesAfterSchedulingStop:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
logEventUUID
setLogEventUUID:
ssvLogFilePath
setSsvLogFilePath:
mediaPlayingObserverQueue
setMediaPlayingObserverQueue:
mediaPlayingMonitor
setMediaPlayingMonitor:
alarmMonitor
setAlarmMonitor:
timerMonitor
setTimerMonitor:
volumeMonitor
setVolumeMonitor:
setAudioDeviceInfo:
setupStarted
setSetupStarted:
audioSessionController
setAudioSessionController:
sacInfoMonitor
setSacInfoMonitor:
rcHandlingClient
setRcHandlingClient:
uncompressedAudioLogging
setUncompressedAudioLogging:
_contextResetQueue
_opusAudioConverter
_narrowBandOpusConverter
_audioConverter
_downsampler
_requestedRecordSettings
_lastVoiceTriggerInfo
_lastRTSTriggerInfo
_continuousZeroCounter
_audibleFeedbackQueue
_twoShotAudibleFeedbackDecisionGroup
_supportPhatic
_supportHearstVoiceTrigger
_supportTriagleModeSessionActivationRetry
_supportSessionActivateDelay
_supportLazySessionActivtion
_isAsrOnDevice
_isOpus
_isSiriClientListening
_isNarrowBand
_isAudioSessionActivated
_deviceRoleIsStereo
_twoShotNotificationEnabled
_isMediaPlaying
_isAlarmPlaying
_isTimerPlaying
_isSoundPlaying
_isRemoteVADAvailableStream
_myriadPreventingTwoShotFeedback
_shouldUseLanguageDetectorForCurrentRequest
_didDeliverLastBuffer
_didDeliverFirstSpeechPacket
_canPerformDelayedStop
_hasPerformedDelayedStop
_setupStarted
_cachedAvgPower
_cachedPeakPower
_languageDetectorDelegate
_speakerIdDelegate
_endpointerProxy
_streamProvider
_sessionProvider
_alertProvider
_audioMeterProvider
_audioMetricProvider
_serverLoggingWriter
_volumeController
_recordEventUUID
_speakerRecognitionScores
_activeChannel
_speechEndHostTimeEstimator
_bundleIdFromDictation
_pendingAudioSessionActivationToken
_pendingAudioSessionActivationCompletion
_pendingAudioSessionActivationReason
_audioSessionActivationDelay
_xpcClientFactory
_duckAudioXPCClient
_powerMeter
_requestedStopRecordingOptions
_numTrailingSamplesAfterSchedulingStop
_maxAllowedTrailingSamplesAfterSchedulingStop
_decodersForTV
_decoderProcessedSampleCountForTV
_logEventUUID
_ssvLogFilePath
_mediaPlayingObserverQueue
_mediaPlayingMonitor
_alarmMonitor
_timerMonitor
_volumeMonitor
_audioDeviceInfo
_audioSessionController
_sacInfoMonitor
_rcHandlingClient
_uncompressedAudioLogging
TB,N,V_supportPhatic
TB,N,V_supportHearstVoiceTrigger
TB,N,V_supportTriagleModeSessionActivationRetry
TB,N,V_supportSessionActivateDelay
TB,N,V_supportLazySessionActivtion
T@"CSEndpointerProxy",&,N,V_endpointerProxy
T@"CSAudioRecordContext",&,N,V_audioRecordContext
T@"<CSAudioStreamProviding>",&,N,V_streamProvider
T@"<CSAudioSessionProviding>",&,N,V_sessionProvider
T@"<CSAudioAlertProviding>",&,N,V_alertProvider
T@"<CSAudioMeterProviding>",&,N,V_audioMeterProvider
T@"<CSAudioMetricProviding>",&,N,V_audioMetricProvider
TB,N,V_isAsrOnDevice
TB,N,V_isOpus
TB,N,V_isSiriClientListening
TB,N,V_isNarrowBand
T@"CSSelectiveChannelAudioFileWriter",&,N,V_serverLoggingWriter
T@"CSSmartSiriVolumeController",&,N,V_volumeController
T@"NSString",&,N,V_recordEventUUID
TB,N,V_isAudioSessionActivated
TB,N,V_deviceRoleIsStereo
T@"NSDictionary",&,N,V_speakerRecognitionScores
TQ,N,V_activeChannel
TB,N,V_twoShotNotificationEnabled
TB,N,V_isMediaPlaying
TB,N,V_isAlarmPlaying
TB,N,V_isTimerPlaying
TB,N,V_isSoundPlaying
TB,N,V_isRemoteVADAvailableStream
TB,N,V_myriadPreventingTwoShotFeedback
T@"CSSpeechEndHostTimeEstimator",&,N,V_speechEndHostTimeEstimator
T@"NSString",&,N,V_bundleIdFromDictation
T@"CSLanguageDetector",&,N,V_languageDetector
TB,N,V_shouldUseLanguageDetectorForCurrentRequest
T@"NSUUID",&,N,V_pendingAudioSessionActivationToken
T@?,C,N,V_pendingAudioSessionActivationCompletion
TQ,N,V_pendingAudioSessionActivationReason
Td,N,V_audioSessionActivationDelay
T@"CSXPCClientFactory",&,N,V_xpcClientFactory
T@"CSXPCClient",&,N,V_duckAudioXPCClient
Tf,N,V_cachedAvgPower
Tf,N,V_cachedPeakPower
T@"CSAudioPowerMeter",&,N,V_powerMeter
TB,N,V_didDeliverLastBuffer
TB,N,V_didDeliverFirstSpeechPacket
TB,N,V_canPerformDelayedStop
TB,N,V_hasPerformedDelayedStop
T@"CSStopRecordingOptions",&,N,V_requestedStopRecordingOptions
TQ,N,V_numTrailingSamplesAfterSchedulingStop
TQ,N,V_maxAllowedTrailingSamplesAfterSchedulingStop
T@"NSMutableDictionary",&,N,V_decodersForTV
TQ,N,V_decoderProcessedSampleCountForTV
T@"NSString",&,N,V_logEventUUID
T@"NSString",&,N,V_ssvLogFilePath
T@"NSObject<OS_dispatch_queue>",&,N,V_mediaPlayingObserverQueue
T@"SOMediaNowPlayingObserver",&,N,V_mediaPlayingMonitor
T@"SOClockAlarmObserver",&,N,V_alarmMonitor
T@"SOClockTimerObserver",&,N,V_timerMonitor
T@"CSVolumeMonitor",&,N,V_volumeMonitor
T@"CSAudioDeviceInfo",&,N,V_audioDeviceInfo
T@"NSUUID",R,C,N,V_endpointId
TB,N,V_setupStarted
T@"CSAudioSessionController",&,N,V_audioSessionController
T@"CSSACInfoMonitor",&,N,V_sacInfoMonitor
T@"CSRCHandlingXPCClient",&,N,V_rcHandlingClient
T@"CSUncompressedAudioLogging",&,N,V_uncompressedAudioLogging
T@"<CSSpeechControllerDelegate>",W,N,V_delegate
T@"<CSLanguageDetectorDelegate>",W,N,V_languageDetectorDelegate
T@"<CSSpeakerIdentificationDelegate>",W,N,V_speakerIdDelegate
T@"<CSEndpointAnalyzer>",R,N
ssrConnection
setSsrConnection:
_ssrConnection
T@"NSXPCConnection",&,N,V_ssrConnection
T@"<CSSSRXPCClientDelegate>",W,N,V_delegate
setCtx:
detectedToken
setDetectedToken:
triggerMachTime
setTriggerMachTime:
triggerAbsStartSampleId
setTriggerAbsStartSampleId:
_ctx
_detectedToken
_triggerMachTime
_triggerAbsStartSampleId
T@"CSAttSiriRequestContext",C,N,V_ctx
T@"NSString",&,N,V_detectedToken
TQ,N,V_triggerMachTime
TQ,N,V_triggerAbsStartSampleId
createRTModelWithLocale:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
rtModelWithAccessoryRTModelType:majorVersion:minorVersion:locale:
remoraRTModelWithMajorVersion:minorVersion:locale:
hearstRTModelWithMajorVersion:minorVersion:locale:
hearstRTModelLocaleMap
jarvisRTModelLocaleMap
remoraRTModelLocaleMap
rtModelLocaleMapWithModelType:
localeMapWithName:
_sha1:
_sha256:
playerItemDidPlayToEndTime:
playerItemFailedToPlayToEndTime:
initWithQueue:request:options:
prepareWithOptions:audioSession:completion:
startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
stop:completion:
handleBeginInterruption
handleEndInterruption:
request
options
T@"AFAudioPlaybackRequest",R,N
_prepareWithOptions:audioSession:completion:
_startWithOptions:audioSession:preparationHandler:executionHandler:finalizationHandler:
_stop:
_handleBeginInterruption
_handleEndInterruption:
_finalizeWithError:
_resetPlayerItem
_isActive
_player
_playerItem
_audioSession
_completion
_request
_options
T@"AFAudioPlaybackRequest",R,N,V_request
TQ,R,N,V_options
initialize
initWithServiceName:
_serviceProxyWithErrorHandler:
upperCaseString:completion:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:directory:completion:
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
buildPhoneticMatchWithLanguage:saveIntermediateFsts:completion:
generateAudioWithTexts:language:completion:
generateConfusionPairsWithUUID:parameters:language:task:samplingRate:recognizedTokens:recognizedText:correctedText:selectedAlternatives:completion:
xpcExitClean
_smtConnection
CSRemoteAssetManagerDidDownloadNewAsset:
_getVoiceTriggerAssetFromAssetManager:
_checkNewAssetAvailablity
cachedAsset
setCachedAsset:
_cachedAsset
T@"CSAsset",&,V_cachedAsset
defaultFactory
clientForAudioProviding
clientForAudioSessionInfoProviding
clientForSmartSiriVolumeProviding
clientForMacOSDuckAudioDevice
clientForFallbackAudioSessionReleaseProviding
avvcStartRecordSettingsWithAudioStreamHandleId:
setAVVCAlertBehavior:
avvcAlertBehavior
isAlertBehaviorOverridedBeep
_avvcAlertOverrideType:
_alertBehaviorTypeFromAVVCOberrideType:
upperCaseString:withReply:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:
_setupSignalProviders:
_startDataSourcesWithContext:
_startSignalProvidersWithContext:
startWithNviContext:
_stopDataSources
_stopCurrentlyRunningSignalProviders
_iterateSignalMask:withHandler:
registerSignalProviderDelegate:forSignalTypes:
unregisterSignalProviderDelegate:forSignalType:
registerSignalProviderDelegateForAllSignalTypes:
unregisterSignalProviderDelegateForAllSignalTypes:
assetsProvider
setAssetsProvider:
dataSrcMap
setDataSrcMap:
sigProvidersMap
setSigProvidersMap:
currActiveSigProvTypes
setCurrActiveSigProvTypes:
currActiveDataSourceTypes
setCurrActiveDataSourceTypes:
_assetsProvider
_dataSrcMap
_sigProvidersMap
_currActiveSigProvTypes
_currActiveDataSourceTypes
T@"<NviAssetsProvider>",&,N,V_assetsProvider
T@"NSDictionary",&,N,V_dataSrcMap
T@"NSMapTable",&,N,V_sigProvidersMap
T@"NSHashTable",&,N,V_currActiveSigProvTypes
T@"NSHashTable",&,N,V_currActiveDataSourceTypes
setAsset:
createAudioStreamMessageWithRequest:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
setAudioSessionDelegate:
prewarmAudioSessionWithError:
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
enableSmartRoutingConsideration:
reportsDynamicActivityAttribute:bundleId:
fallbackDeactivateAudioSession:error:
UUID
audioStreamId
setCurrentContext:error:
audioStreamWithRequest:streamName:error:
audioStreamWithRequest:streamName:completion:
attachTandemStream:toPrimaryStream:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkFrom:to:channelIdx:
audioChunkToEndFrom:
audioChunkToEndFrom:channelIdx:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
setAnnounceCallsEnabled:withStreamHandleID:
supportsDuckingOnCurrentRouteWithError:
setAudioAlertDelegate:
configureAlertBehavior:
audioSessionIdForDeviceId:
audioMetric
hostTimeFromSampleCount:
sampleCountFromHostTime:
triggerInfoForContext:completion:
initWithType:
isConnected
_disconnect
_sendXPCClientType
prepareAudioProviderWithContext:clientType:error:
pingpong:
acousticSLResultForContext:completion:
sendMessageAsync:completion:
_sendMessageAsync:completion:
sendMessageAndReplySync:error:
_handleListenerMessage:
_handleListenerDisconnectedError:
_handleAlertProvidingDelegateMessageBody:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
_handleSessionProvidingDelegateMessageBody:
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
_handleSessionInfoProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateMessageBody:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
audioSessionProvidingDelegate
setAudioSessionProvidingDelegate:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
audioAlertProvidingDelegate
setAudioAlertProvidingDelegate:
xpcReplyQueue
setXpcReplyQueue:
activationAssertions
setActivationAssertions:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_xpcReplyQueue
_activationAssertions
_audioSessionInfoObservers
_xpcClientType
T@"NSObject<OS_dispatch_queue>",&,N,V_xpcReplyQueue
T@"NSMutableSet",&,N,V_activationAssertions
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
T@"NSString",R,N,V_UUID
initWithInitialState:
addTransitionFrom:to:for:
addTransitionFromAnyStateTo:for:
performTransitionForEvent:
initialState
setInitialState:
transitions
setTransitions:
eventToStateTransitions
setEventToStateTransitions:
_initialState
_transitions
_eventToStateTransitions
Tq,N,V_initialState
T@"NSMutableDictionary",&,N,V_transitions
T@"NSMutableDictionary",&,N,V_eventToStateTransitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
Tq,R,N,V_currentState
CSEventMonitorDidReceiveEvent:
type
addObserver:
removeObserver:
enumerateObservers:
notifyObserver:
sharedAggregator
reportDigitalZerosWithAudioZeroRun:
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:withPhrase:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
falseWakePhraseDictionary
setFalseWakePhraseDictionary:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
_falseWakePhraseDictionary
TQ,N,V_numFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
T@"NSMutableDictionary",&,N,V_falseWakePhraseDictionary
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
CSAutomaticVolumeEnabledMonitor:didReceiveEnabled:
initWithSamplingRate:withAsset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
_closeAudioFile
_audioLogDirectory
_getOrCreateAudioLogDirectory
_nowString
_makeTimestampedAudioLogFilenameWithPrefix:suffix:
_audioLength
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
remoteMicVADEvent:vadScore:hostTime:
builtInMicVoiceTriggerEvent:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
remoraVoiceTriggerEvent:activationInfo:hostTime:
mediaserverdLaunchedEvent:
initWithType:deviceId:activationInfo:vadScore:hosttime:
initWithType:deviceId:activationInfo:hosttime:
localizedDescription
_activationTypeString
activationInfo
hosttime
vadScore
_vadScore
_activationInfo
_hosttime
TQ,R,N,V_type
T@"NSString",R,N,V_deviceId
T@"NSDictionary",R,N,V_activationInfo
TQ,R,N,V_hosttime
Tf,R,N,V_vadScore
shortFormForUUID
_registerForFakeAssetRollNotification
lastFakeModelUsedHash
setLastFakeModelUsedHash:
shouldRollFakeModel
setShouldRollFakeModel:
fakeAssetRollNotificationRegistrationToken
setFakeAssetRollNotificationRegistrationToken:
_shouldRollFakeModel
_fakeAssetRollNotificationRegistrationToken
_lastFakeModelUsedHash
Ti,N,V_fakeAssetRollNotificationRegistrationToken
T@"NSString",&,V_lastFakeModelUsedHash
TB,V_shouldRollFakeModel
isScreenLocked
applyLowerAndUpperBoundsToVolume:
initWithStoredInformationAndAsset:
increaseSiriVolumeBasedOnUserIntent
decreaseSiriVolumeBasedOnUserIntent
storeASVStateInformation
applyLowerAndUpperBoundsToVolumeOffset:
userIntentType
setUserIntentType:
userIntentValidForSeconds
setUserIntentValidForSeconds:
userIntentTime
setUserIntentTime:
latestVolumeTime
setLatestVolumeTime:
userIntentVolume
setUserIntentVolume:
latestVolume
setLatestVolume:
permanentOffsetFactor
setPermanentOffsetFactor:
permanentOffsetIsEnabled
setPermanentOffsetIsEnabled:
kSSVCAUserIntentValidForSeconds
kSSVCAUserIntentVolumeIncreaseFactor
kSSVCAUserIntentVolumeDecreaseFactor
kSSVCAUserIntentPermanentOffsetFactorDelta
kSSVCAUserIntentPermanentOffsetFactorLowerBound
kSSVCAUserIntentPermanentOffsetFactorUpperBound
kSSVCA_DEVICE_SIMPLE_MIN_TTS_VOLUME
kSSVCA_DEVICE_SIMPLE_MAX_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MIN_TTS_VOLUME
kSSVCA_DEVICE_DEFAULT_MAX_TTS_VOLUME
_permanentOffsetIsEnabled
_userIntentVolume
_latestVolume
_permanentOffsetFactor
_userIntentType
_userIntentValidForSeconds
_userIntentTime
_latestVolumeTime
TQ,N,V_userIntentType
TQ,N,V_userIntentValidForSeconds
Tq,N,V_userIntentTime
Tq,N,V_latestVolumeTime
Tf,N,V_userIntentVolume
Tf,N,V_latestVolume
Tf,N,V_permanentOffsetFactor
TB,N,V_permanentOffsetIsEnabled
getAssetTypeStringForType:
_cleanUpMobileAssetV1Directory
installedAssetOfType:withLanguage:
installedAssetOfType:withLanguage:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_installedAssetOfType:query:withLanguage:completion:
_findLatestInstalledAsset:
_assetQueryForAssetType:
_runAssetQuery:completion:
_isReadyToUse
fetchRemoteMetaOfType:
fetchRemoteMetaOfType:allowRetry:
_fetchRemoteAssetOfType:withLanguage:completion:
_fetchRemoteAssetOfType:withLanguage:query:completion:
_downloadAssetCatalogForAssetType:complete:
_isRetryRecommendedWithResult:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_downloadAsset:withComplete:
_startDownloadingAsset:progress:completion:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
filteredAssetsForAssets:assetType:language:
addKeyValuePairForQuery:assetType:
getVoiceTriggerAssetTypeString
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetTypeString
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorAssetTypeString
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerAssetTypeString
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionAssetTypeString
getSpeakerRecognitionCurrentCompatibilityVersion
encoder
setEncoder:
_encoder
T@"CSAudioConverter",&,N,V_encoder
sharedLauncher
notifyBuiltInVoiceTriggerPrewarm:completion:
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyWakeKeywordSpokenInBuiltInMic:
notifyCarPlayVoiceTriggerPrewarm:deviceId:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyWakeKeywordSpokenCarPlay:deviceId:
notifyBluetoothDeviceVoiceTriggerPrewarm:deviceId:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyWakeKeywordSpokenBluetoothDevice:deviceId:
notifyRemoraVoiceTriggerPrewarm:deviceId:completion:
notifyRemoraVoiceTrigger:myriadPHash:deviceId:completion:
notifyWakeKeywordSpokenRemora:deviceId:
deactivateSiriActivationConnectionWithReason:withOptions:withContext:
notifyDarwinVoiceTriggerPrewarmWithCompletion:
notifyDarwinVoiceTrigger:deviceId:myriadPHash:myriadLateActivationExpirationTime:completion:
secondPassAssetQueryStartTime
setSecondPassAssetQueryStartTime:
secondPassAssetQueryCompleteTime
setSecondPassAssetQueryCompleteTime:
secondPassAssetLoadStartTime
setSecondPassAssetLoadStartTime:
secondPassAssetLoadCompleteTime
setSecondPassAssetLoadCompleteTime:
secondPassAudioStreamStartTime
setSecondPassAudioStreamStartTime:
secondPassAudioStreamReadyTime
setSecondPassAudioStreamReadyTime:
secondPassFirstAudioPacketReceptionTime
setSecondPassFirstAudioPacketReceptionTime:
secondPassLastAudioPacketReceptionTime
setSecondPassLastAudioPacketReceptionTime:
secondPassCheckerModelKeywordDetectionStartTime
setSecondPassCheckerModelKeywordDetectionStartTime:
secondPassCheckerModelKeywordDetectionEndTime
setSecondPassCheckerModelKeywordDetectionEndTime:
_secondPassAssetQueryStartTime
_secondPassAssetQueryCompleteTime
_secondPassAssetLoadStartTime
_secondPassAssetLoadCompleteTime
_secondPassAudioStreamStartTime
_secondPassAudioStreamReadyTime
_secondPassFirstAudioPacketReceptionTime
_secondPassLastAudioPacketReceptionTime
_secondPassCheckerModelKeywordDetectionStartTime
_secondPassCheckerModelKeywordDetectionEndTime
TQ,N,V_secondPassAssetQueryStartTime
TQ,N,V_secondPassAssetQueryCompleteTime
TQ,N,V_secondPassAssetLoadStartTime
TQ,N,V_secondPassAssetLoadCompleteTime
TQ,N,V_secondPassAudioStreamStartTime
TQ,N,V_secondPassAudioStreamReadyTime
TQ,N,V_secondPassFirstAudioPacketReceptionTime
TQ,N,V_secondPassLastAudioPacketReceptionTime
TQ,N,V_secondPassCheckerModelKeywordDetectionStartTime
TQ,N,V_secondPassCheckerModelKeywordDetectionEndTime
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
_deinterleaveBufferIfNeeded:
_compensateChannelDataIfNeeded:receivedNumChannels:
_defaultOutASBD
audioStreamHandleId
setAudioStreamHandleId:
fileOption
setFileOption:
audioFeedTimer
setAudioFeedTimer:
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_audioStreamHandleId
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
_pNonInterleavedABL
TQ,N,V_audioStreamHandleId
T@"CSAudioInjectionFileOption",&,N,V_fileOption
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
TB,N,V_isRecording
Td,N,V_bufferDuration
T@"NSMutableArray",&,N,V_injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
T^{OpaqueAudioConverter=},N,V_deinterleaver
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
hasRemoteBuiltInMic
isRemoteDarwinWithDeviceId:
sharedMonitor
startMonitoring
notifyVoiceTriggerAssetChanged
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
initWithRequestSource:
reqSrc
setReqSrc:
_reqSrc
TQ,N,V_reqSrc
initWithURL:inputFormat:outputFormat:
fileURL
inASBD
_fileURL
T@"NSURL",R,N,V_fileURL
_addVoiceTriggerEnabledConditions
siriClientBehaviorMonitor:fetchedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:preparedSiriClientAudioStream:successfully:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitorReleasedAudioSession:
notifyFetchedSiriClientAudioStream:successfully:
notifyPreparedSiriClientAudioStream:successfully:
notifyWillStartStreamWithContext:option:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
notifyWillStopStream:reason:
notifyDidStopStream:withEventUUID:
notifyReleaseAudioSession
setIsStreaming:
_isStreaming
TB,N,V_isStreaming
_didReceiveNewSpeechEndpointAssetMetaData
initWithVolumeEstimate:debugLogFile:
volumeEstimate
debugLogPath
_volumeEstimate
_debugLogPath
T@"NSString",R,N,V_debugLogPath
Tf,R,N,V_volumeEstimate
_handleConnectionError:
registerUaapApp:withAssetFiles:completion:
registerUaapApp:forLocale:withAssetFiles:completion:
registerMultilingualUaapApp:withAssetFiles:completion:
registerDatapackUpdate
connection
setConnection:
_connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
CSFirstUnlockMonitor:didReceiveFirstUnlock:
initWithVoiceTriggerAssetDownloadMonitor:languageCodeUpdateMonitor:firstUnlockMonitor:trialAssetDownloadMonitor:assetManager:trialAssetManager:
_handleVoiceTriggerAssetWithCompletion:
_handleEndpointVoiceTriggerAsset:completion:
_getVoiceTriggerAssetFromAssetManagerWithLocale:completion:
_checkNewAssetAvailablityForEndpoint
cachedEndpointAssets
setCachedEndpointAssets:
voiceTriggerAssetDownloadMonitor
setVoiceTriggerAssetDownloadMonitor:
languageCodeUpdateMonitor
setLanguageCodeUpdateMonitor:
firstUnlockMonitor
setFirstUnlockMonitor:
trialAssetDownloadMonitor
setTrialAssetDownloadMonitor:
assetManager
setAssetManager:
trialAssetManager
setTrialAssetManager:
_cachedEndpointAssets
_voiceTriggerAssetDownloadMonitor
_languageCodeUpdateMonitor
_firstUnlockMonitor
_trialAssetDownloadMonitor
_assetManager
_trialAssetManager
T@"NSMutableDictionary",&,V_cachedEndpointAssets
T@"CSVoiceTriggerAssetDownloadMonitor",&,N,V_voiceTriggerAssetDownloadMonitor
T@"CSLanguageCodeUpdateMonitor",&,N,V_languageCodeUpdateMonitor
T@"CSFirstUnlockMonitor",&,N,V_firstUnlockMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetDownloadMonitor
T@"CSAssetManager",&,N,V_assetManager
T@"CSTrialAssetManager",&,N,V_trialAssetManager
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:willStopStream:reason:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
_addVoiceTriggerAOPModeEnabledConditions
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
_isHearstRoutedAndWithNoPhoneCall
isSiriClientConsideredAsRecord
setIsSiriClientConsideredAsRecord:
pendingRecordingStopUUID
setPendingRecordingStopUUID:
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
TB,N,V_isSiriClientConsideredAsRecord
T@"NSString",&,N,V_pendingRecordingStopUUID
notifyWillStartStreamWithContext:audioProviderUUID:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
notifyWillStopStream:
notifyDidStopStream:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
T@"NSData",C
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
Ts,N,V_signalEstimate
TC,N,V_signalFractional
inputRecordingSampleRate
inputRecordingFramesPerPacket
inputRecordingBytesPerFrame
inputRecordingBytesPerPacket
inputRecordingNumberOfChannels
numChannelsForNviDirectionality
inputRecordingSampleBitDepth
inputRecordingSampleByteDepth
nviDirectionalityStartingChannelId
nviDirectionalityEndingChannelId
monoChannelLpcmASBD
allChannelsLpcmInterleavedASBD
allChannelsLpcmNonInterleavedASBD
nviDirectionalityLpcmNonInterleavedASBD
nviDirectionalityLpcmInterleavedASBD
nviLogsRootDir
initWithSpeechRecordingMode:clientConfiguration:experimentContext:
setSpeechRequestOptions:currentActivationInfo:
setClientConfiguration:
event
_appendDictationApplicationInfoSettings:
recordSettingsWithOptions:appendingSettings:
_activationMode
_csAudioRecordType
recordContextForSpeechEvent:
_csAudioRecordTypeForSpeechEvent:currentClientConfiguration:
_isRequestFromSpokenNotification:
_csAudioRecordTypeForSpeechRequestOptions:useBorealisBuffer:currentClientConfiguration:
startRecordingSettingsWithRecordRoute:recordingInfo:playbackRoute:
_alertBehaviorForRecordRoute:recordingInfo:playbackRoute:attemptsToUsePastDataBufferFrames:
shouldOverrideRecordingStartingAlertBehaviorForAlertStyle:
_shouldSkipStartRecordingAlertForRecordingInfo:
audioAlertStyleForRecordRoute:recordingInfo:playbackRoute:
audioSessionActivated
needsUpdateToPostVoiceMode
beginUpdateToPostVoice
endUpdateToPostVoiceWithContext:success:
canPrewarm
canPrepareWithoutInterruption
shouldTreatTimeoutAsHardEndpoint
requiresBorealisConsumerCheck
canGetPCMStream
_canUseZLL
_eventIsVoiceTrigger
_eventIsRaiseToSpeak
_eventIsTVRemote
canEnterTwoShot
shouldUseVoiceTriggerAnalyzerStyle
shouldExplicitlyPlayAlertOnStart
shouldPlayAlertIfNotPrelistening
shouldSuppressRecordingStopAlert
shouldSuppressRecordingErrorAlert
twoShotPromptTypeForRecordRoute:playbackRoute:
isVoiceOverTouchEnabled
startingAlertBeepURL
overrideStartingAlertBeepSoundID
audioSessionActivationTargetDate
dateByAddingTimeIntervalSinceActivation:
_isVoiceOverTouchEnabledInAccessibility
_isVibrationDisabledInAccessibility
_audioAlertStyleForListenAfterSpeakingWithRecordRoute:playbackRoute:echoCancellation:useDeviceSpeakerForTTS:
_audioSessionActiveDelayCoreSpeechWithType:
_audioSessionActiveDelayUserPerceptionWithType:
_audioSessionActiveDelayOverride
_audioSessionActiveDelayServerConfiguration
speechEvent
useBorealisBuffer
usePrelistening
audioAlertStyle
deviceIdentifier
activationSystemUptime
activationHostTime
buttonDownHostTime
voiceTriggerEndHostTime
speechRecordingMode
setSpeechRecordingMode:
isOnPhoneCall
activationMetadata
hasPlayedStartAlert
speechEndpointerOperationMode
speechRecordingAlertPolicy
presentationMode
isSpokenNotification
languageDetectionUserContext
dictationInputOrigin
turnIdentifier
applicationDisplayName
applicationBundleIdentifier
dictationVoiceTriggerAbsStartSampleId
_storedActivationMode
_currentClientConfiguration
_suppressStartAlert
_experimentContext
_isActivated
_activeMediaPlaybackVolume
_useBorealisBuffer
_usePrelistening
_isOnPhoneCall
_hasPlayedStartAlert
_isSpokenNotification
_speechEvent
_audioAlertStyle
_deviceIdentifier
_activationSystemUptime
_activationHostTime
_buttonDownHostTime
_voiceTriggerEndHostTime
_speechRecordingMode
_activationMetadata
_speechEndpointerOperationMode
_speechRecordingAlertPolicy
_presentationMode
_languageDetectionUserContext
_dictationInputOrigin
_applicationDisplayName
_applicationBundleIdentifier
_dictationVoiceTriggerAbsStartSampleId
Tq,R,N,V_speechEvent
TB,R,N,V_useBorealisBuffer
TB,R,N,V_usePrelistening
Tq,R,N,V_audioAlertStyle
T@"NSString",R,C,N,V_deviceIdentifier
Td,R,N,V_activationSystemUptime
TQ,R,N,V_activationHostTime
TQ,R,N,V_buttonDownHostTime
TQ,R,N,V_voiceTriggerEndHostTime
Tq,N,V_speechRecordingMode
TB,R,N,V_isOnPhoneCall
T@"NSDictionary",R,C,N,V_activationMetadata
TB,R,N,V_hasPlayedStartAlert
Tq,R,N,V_speechEndpointerOperationMode
T@"AFSpeechRecordingAlertPolicy",R,N,V_speechRecordingAlertPolicy
Tq,R,N,V_presentationMode
TB,R,N,V_isSpokenNotification
T@"AFLanguageDetectionUserContext",R,C,N,V_languageDetectionUserContext
Tq,R,N,V_dictationInputOrigin
T@"NSUUID",R,C,N,V_turnIdentifier
T@"NSString",R,C,N,V_applicationDisplayName
T@"NSString",R,C,N,V_applicationBundleIdentifier
TQ,R,N,V_dictationVoiceTriggerAbsStartSampleId
isNviEnabled
strRepForNviSignalType:
strRepForNviSignalMask:
nviSignalTypeForStr:
strRepForNviDataSourceType:
nviDataSourceTypeForStr:
_createDirAtPath:
timeStampString
getVoiceTriggerEndSampleCountFromVTEI:
getVoiceTriggerEndSecsFromVTEI:
readJsonDictionaryAt:
getValueFromDictionaryOfDictionaries:keypath:
createDirAtPath:
dictionary
currentPowerSource
noAlertOption
initTandemWithOption:
requestHistoricalAudioDataWithHostTime
setRequestHistoricalAudioDataWithHostTime:
requestHistoricalAudioDataSampleCount
setRequestHistoricalAudioDataSampleCount:
startRecordingHostTime
setStartRecordingHostTime:
startRecordingSampleCount
setStartRecordingSampleCount:
useOpportunisticZLL
setUseOpportunisticZLL:
startAlertBehavior
setStartAlertBehavior:
stopAlertBehavior
setStopAlertBehavior:
errorAlertBehavior
setErrorAlertBehavior:
skipAlertBehavior
setSkipAlertBehavior:
requireSingleChannelLookup
setRequireSingleChannelLookup:
selectedChannel
setSelectedChannel:
estimatedStartHostTime
setEstimatedStartHostTime:
disableEndpointer
setDisableEndpointer:
disableLocalSpeechRecognizer
setDisableLocalSpeechRecognizer:
disablePrewarmLocalAsrAtStartRecording
setDisablePrewarmLocalAsrAtStartRecording:
disableBoostForDoAP
setDisableBoostForDoAP:
siriSessionUUID
setSiriSessionUUID:
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_requireSingleChannelLookup
_disableEndpointer
_disableLocalSpeechRecognizer
_disablePrewarmLocalAsrAtStartRecording
_disableBoostForDoAP
_selectedChannel
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
_estimatedStartHostTime
_siriSessionUUID
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
TB,N,V_requireSingleChannelLookup
TI,N,V_selectedChannel
TQ,N,V_estimatedStartHostTime
TB,N,V_disableEndpointer
TB,N,V_disableLocalSpeechRecognizer
TB,N,V_disablePrewarmLocalAsrAtStartRecording
TB,N,V_disableBoostForDoAP
T@"NSString",&,N,V_siriSessionUUID
defaultController
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
_prepareWithOptions:audioSession:error:
_didNotStartWithError:
_didStopWithError:
_isPrepared
initWithAssertionMonitor:
_fetchAssertionMonitor
enableVoiceTrigger:withAssertion:timestamp:
notifyServiceConnectionLost
fetchVoiceTriggerStats
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
assertionMonitor
setAssertionMonitor:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
_assertionMonitor
TB,N,V_isPhraseSpotterBypassed
TB,N,V_isRaiseToSpeakBypassed
T@"CSSiriAssertionMonitor",&,N,V_assertionMonitor
initWithData:
maxFingerprintBufferSize
shouldResetAdsDictionary
assetVersion
payloadData
setPayloadData:
_maxFingerprintBufferSize
_shouldResetAdsDictionary
_assetVersion
_payloadData
T@"NSData",&,N,V_payloadData
Tf,R,N,V_maxFingerprintBufferSize
T@"NSMutableDictionary",R,N,V_shouldResetAdsDictionary
T@"NSString",R,N,V_assetVersion
getMitigationDecisionForRCIdWithCompletion:completion:
rcXPCConnection
setRcXPCConnection:
_rcXPCConnection
T@"NSXPCConnection",&,N,V_rcXPCConnection
_createSSVClientConnectionIfNeeded
ssvClient
setSsvClient:
_ssvClient
T@"CSSmartSiriVolumeClient",&,N,V_ssvClient
T@"<CSSmartSiriVolumeControllerDelegate>",W,N,V_delegate
keywordAnalyzerNDEAPI:hasResultAvailable:forChannel:
initWithAsset:assetConfig:firstPassSource:activeChannel:siriLanguage:shouldEnableShadowMicScore:
processAudioChunk:activeChannel:
currentShadowMicScore
shadowMicScoreThresholdForVAD
keywordAnalyzerNDEAPI
setKeywordAnalyzerNDEAPI:
hasReceivedNDEAPIResult
setHasReceivedNDEAPIResult:
shadowMicScoreCreator
setShadowMicScoreCreator:
dataBufferNDEAPI
setDataBufferNDEAPI:
dataBufferPositionNDEAPI
setDataBufferPositionNDEAPI:
hasReceivedEarlyDetectNDEAPIResult
setHasReceivedEarlyDetectNDEAPIResult:
_hasReceivedNDEAPIResult
_hasReceivedEarlyDetectNDEAPIResult
_shadowMicScoreThresholdForVAD
_keywordAnalyzerNDEAPI
_shadowMicScoreCreator
_dataBufferNDEAPI
_dataBufferPositionNDEAPI
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzerNDEAPI
TB,N,V_hasReceivedNDEAPIResult
T@"CSShadowMicScoreCreator",&,N,V_shadowMicScoreCreator
T@"NSMutableData",&,N,V_dataBufferNDEAPI
TQ,N,V_dataBufferPositionNDEAPI
TC,N,V_hasReceivedEarlyDetectNDEAPIResult
T@"<CSPhraseNDEAPIScorerDelegate>",W,N,V_delegate
Tf,R,N,V_shadowMicScoreThresholdForVAD
containsSpeakerRecognitionCategory
satScoreThresholdForPhId:
satScoreThreshold
multiUserLowScoreThreshold
multiUserHighScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
containsMultiUserThresholds
useSpeakerRecognitionAsset
Tq,R,N
initWithMasterAudioStream:name:
attachToPrimaryStreamWithCompletion:
prepareAudioStreamSyncWithRequest:error:
prepareAudioStreamWithRequest:completion:
startAudioStreamWithOption:completion:
stopAudioStreamWithOption:completion:
primaryStream
setPrimaryStream:
_primaryStream
T@"CSAudioStream",W,N,V_primaryStream
address
setAddress:
supportDoAP
setSupportDoAP:
isTemporaryPairedNotInContacts
setIsTemporaryPairedNotInContacts:
_supportDoAP
_isTemporaryPairedNotInContacts
_address
T@"NSString",C,N,V_address
TB,N,V_supportDoAP
TB,N,V_isTemporaryPairedNotInContacts
attSiriStateMonitor:didRecieveAttSiriStateChange:
getAttendingState
updateState:
isAttending
isAttendingForDictation
attendingState
setAttendingState:
_attendingState
TQ,N,V_attendingState
smartSiriVolumeRunPolicy
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
sendAcousticGradingDataToNearbyPeer
sendGeckoSpeechLogsToCompanion
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
_compressFilesInDirectory:matchingPredicate:sortedByCreationDate:compressedFileAvailable:
_sendVoiceTriggerGradingDataToPeerId:
_sendCoreSpeechGradingDataToPeerId:
_sendGeckoSpeechLogsToPeerId:
_sendCoreSpeechMagusGradingDataToPeerId:
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:withFilePrefix:withCompletion:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_getHomeUserIdForSharedSiriId:withCompletion:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_sendVoiceProfile:toPeerId:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
_sendAcousticGradingDataToPeerId:
_speakerRecognitionAudioLogsGradingDir
_createDirectoryIfDoesNotExist:
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugGradingDataRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
_spIdSiriDebugTrainedUsersFilePathForLocale:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
_getContentsOfDirectory:
isHeadlessDeviceDataCollectionModeEnabled
isInternalWithoutProfile
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
T@"NSString",&,N,V_lastCommunicatedPeer
T@"NSString",&,N,V_voiceTriggerBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
processBuffer:atTime:
vtEndInSampleCount
setVtEndInSampleCount:
numSamplesProcessed
setNumSamplesProcessed:
_vtEndInSampleCount
_numSamplesProcessed
TQ,N,V_vtEndInSampleCount
TQ,N,V_numSamplesProcessed
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
_addDisabledConditions
registerPostBuildInstallService
_performPostBuildInstallWithCompletion:
_setMaximumBufferSizeFromInUseServices
startWithUUID:withMaximumBufferSize:
stopWithUUID:
_reset
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
_startListenPolling
_stopListening
_handleEnablePolicyEvent:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
currentMaximumBufferSize
setCurrentMaximumBufferSize:
enablePolicy
setEnablePolicy:
_isListenPollingStarting
_currentMaximumBufferSize
_audioLoggingBuffer
_inUseServices
TB,N,V_isListenPollingStarting
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
T@"NSMutableDictionary",&,N,V_inUseServices
Tf,N,V_currentMaximumBufferSize
T@"CSPolicy",&,N,V_enablePolicy
CSBuiltinSpeakerStateMonitor:didReceiveBuiltinSpeakerStateChange:
_fetchSpeakerStateMutedInfo
_fetchSpeakerStateActiveInfo
currentBuiltinSpeakerState
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
_didReceiveBuiltinSpeakerStateChangeNotification:
_notifyObserver:withBuiltinSpeakerState:
_didReceiveSpeakerMuteStateChangeNotification:
_notifyObserver:isSpeakerMuted:
builtInSpeakerState
isSpeakerMuted
setIsSpeakerMuted:
_isSpeakerMuted
_builtInSpeakerState
TQ,N,V_builtInSpeakerState
TB,N,V_isSpeakerMuted
initWithSignalType:timestamp:
headerString
initWithStartSample:endSample:confidence:azimuth:estimatedAzimuth:
mostSampledAzimuth
stringForLogging
_spatialSpectrumLogStr
startSample
setStartSample:
endSample
setEndSample:
confidence
setConfidence:
azimuth
setAzimuth:
estimatedAzimuth
setEstimatedAzimuth:
processedAudioDurMs
setProcessedAudioDurMs:
spatialSpectrumData
setSpatialSpectrumData:
azDistribution
setAzDistribution:
_confidence
_azimuth
_estimatedAzimuth
_startSample
_endSample
_processedAudioDurMs
_spatialSpectrumData
_azDistribution
TQ,N,V_startSample
TQ,N,V_endSample
Tf,N,V_confidence
Tf,N,V_azimuth
Tf,N,V_estimatedAzimuth
Td,N,V_processedAudioDurMs
T@"NSArray",&,N,V_spatialSpectrumData
T@"NSDictionary",&,N,V_azDistribution
initWithTotalAudioRecorded:endpointBufferHostTime:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:trailingSilenceDurationAtEndpoint:
totalAudioRecorded
setTotalAudioRecorded:
endpointBufferHostTime
setEndpointBufferHostTime:
featuresAtEndpoint
setFeaturesAtEndpoint:
endpointerType
setEndpointerType:
serverFeatureLatencyDistribution
setServerFeatureLatencyDistribution:
additionalMetrics
setAdditionalMetrics:
_totalAudioRecorded
_endpointBufferHostTime
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
Td,N,V_totalAudioRecorded
TQ,N,V_endpointBufferHostTime
T@"NSArray",&,N,V_featuresAtEndpoint
Tq,N,V_endpointerType
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_additionalMetrics
initWithSamplingRate:asset:
didReceiveAlarmChanged:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
fetchInitSystemVolumes
_setAsset:
_prepareSoundLevelBufferFromSamples:soundType:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
_processAudioChunk:soundType:
estimateSoundLevelbySoundType:
_pauseSSVProcessing
_resumeSSVProcessing
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_getDeviceSimpledBFSForOutputLinearVolume:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getFloatBufferData:
_resetStartAnalyzeTime
_setStartAnalyzeTime:
_setDefaultParameters
_convertDB2Mag:
_getDevicedBFSForInputLinearVolume:
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_getUserOffsetFromMusicVolumeDB:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_startAnalyzeSampleCount
_samplesFed
_processedSampleCount
_isStartSampleCountMarked
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
Tq,N,V_listenPollingTimerCount
isDeviceRoleStereo
_isDeviceRoleStereo
initWithData:hash:locale:digest:signature:certificate:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
T@"NSData",R,N,V_modelData
T@"NSString",R,N,V_modelLocale
T@"NSString",R,N,V_modelHash
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
T@"NSData",R,N,V_certificate
vibratesForDeviceRingerSwitchState:
_ringVibrationValue
_silentVibrationValue
_fetchRingVibrationValue
_fetchSilentVibrationValue
handleRingVibrationValueChange
handleSilentVibrationValueChange
_ringVibrationState
_silentVibrationState
preferredExternalRouteDidChange:
pickableRoutesDidChange:
carPlayAuxStreamSupportDidChange:
carPlayIsConnectedDidChange:
_fetchHearstConnectionState
_fetchJarvisConnectionState
_notifyHearstConnectionState:
_notifyJarvisConnectionState:
_isJarvisConnected
observeValueForKeyPath:ofObject:change:context:
_didReceiveAutomaticVolumeToggled:
_isAutomaticVolumeEnabled
initWithDictation:fingerprintOnly:secureOfflineOnly:audioAlertStyle:recordSettings:recordRoute:recordDeviceInfo:playbackRoute:audioDeviceID:audioSessionID:voiceTriggerEventInfo:activationAlertStartTimestamp:startRecordingTimestamp:firstBufferTimestamp:firstBufferHostTime:estimatedSpeechEndHostTime:deviceIdentifier:includeBTInfo:speechEvent:
initWithDictation:codec:
isBluetooth
_fetchBTInfo
_bluetoothDeviceInfo
headsetAddress
vendorId
productId
codecIsNarrowband
isDictation
isFingerprintOnly
isSecureOfflineOnly
codec
source
mhSource
destination
route
deviceInfo
modelName
dspStatus
headsetName
voiceTriggerEventInfo
activationAlertStartTimestamp
startRecordingTimestamp
audioSessionID
firstBufferTimestamp
firstBufferHostTime
isDucking
isEndAlertInfo
setIsEndAlertInfo:
triggeredTwoShotBorealis
setTriggeredTwoShotBorealis:
audioSessionSetActiveEndHostTime
setAudioSessionSetActiveEndHostTime:
bluetoothDevice
_headsetAddress
_isDictation
_isFingerprintOnly
_isSecureOfflineOnly
_isDucking
_isEndAlertInfo
_triggeredTwoShotBorealis
_mhSource
_audioSessionID
_codec
_source
_destination
_route
_deviceInfo
_modelName
_dspStatus
_headsetName
_voiceTriggerEventInfo
_activationAlertStartTimestamp
_startRecordingTimestamp
_firstBufferTimestamp
_firstBufferHostTime
_estimatedSpeechEndHostTime
_audioSessionSetActiveEndHostTime
_bluetoothDevice
TB,R,N,V_isDictation
TB,R,N,V_isFingerprintOnly
TB,R,N,V_isSecureOfflineOnly
T@"NSString",R,N,V_codec
T@"NSString",R,N,V_source
Ti,R,N,V_mhSource
T@"NSString",R,N,V_destination
T@"NSString",R,N,V_route
T@"CSAudioRecordDeviceInfo",R,N,V_deviceInfo
T@"NSString",R,N,V_deviceIdentifier
T@"NSString",R,N,V_modelName
T@"NSString",R,N,V_dspStatus
T@"NSString",R,N,V_headsetName
T@"NSDictionary",R,N,V_voiceTriggerEventInfo
Td,R,N,V_activationAlertStartTimestamp
Td,R,N,V_startRecordingTimestamp
TI,R,N,V_audioSessionID
Td,R,N,V_firstBufferTimestamp
TQ,R,N,V_firstBufferHostTime
TQ,R,N,V_estimatedSpeechEndHostTime
TB,R,N,V_isDucking
TB,N,V_isEndAlertInfo
TB,N,V_triggeredTwoShotBorealis
TQ,N,V_audioSessionSetActiveEndHostTime
T@"<AFBluetoothDevice>",R,N,V_bluetoothDevice
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
triggerVoiceProfileRetrainingWithAsset:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_didReceiveVoiceTriggerSettingChanged:
_checkVoiceTriggerEnabled
_isVoiceTriggerEnabled
initWithFirstPassSource:deviceId:audioProviderUUID:firstPassInfo:rejectionMHUUID:isSecondChanceRun:firstpassMetrics:
firstPassSource
audioProviderUUID
firstPassTriggerInfo
rejectionMHUUID
isSecondChanceRun
firstpassMetrics
_isSecondChanceRun
_firstPassSource
_audioProviderUUID
_firstPassTriggerInfo
_rejectionMHUUID
_firstpassMetrics
TQ,R,N,V_firstPassSource
T@"NSString",R,N,V_audioProviderUUID
T@"NSDictionary",R,N,V_firstPassTriggerInfo
T@"NSUUID",R,N,V_rejectionMHUUID
TB,R,N,V_isSecondChanceRun
T@"CSVoiceTriggerFirstPassMetrics",R,N,V_firstpassMetrics
endpointerAssetManagerDidUpdateAsset:
endpointerAssetManagerDidUpdateOSDAsset:
_updateEndpointerDelayedTriggerByMhId:
_emitEndpointDetectedEventWithEndpointTimeMs:endpointBufferHostTime:endpointerFeatures:endpointerDecisionLagInNs:extraDelayMs:endpointScore:asrFeatureLatencies:
terminateProcessing
_readParametersFromHEPAsset:
_getCSHybridEndpointerConfigForAsset:
_shouldUsePhaticWithRecordContext
_multimodalEndpointerEnabled
setCanProcessCurrentRequest:
osdFeaturesAtEndpoint
setOsdFeaturesAtEndpoint:
hybridClassifier
setHybridClassifier:
setEndpointerModelVersion:
serverFeaturesQueue
setServerFeaturesQueue:
lastKnownServerEPFeatures
setLastKnownServerEPFeatures:
lastKnownOSDFeatures
setLastKnownOSDFeatures:
serverFeatureLatencies
setServerFeatureLatencies:
lastKnowServerFeaturesLatency
setLastKnowServerFeaturesLatency:
epResult
setEpResult:
serverFeaturesWarmupLatency
setServerFeaturesWarmupLatency:
lastServerFeatureTimestamp
setLastServerFeatureTimestamp:
didReceiveServerFeatures
setDidReceiveServerFeatures:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
extraDelayFrequency
setExtraDelayFrequency:
taskThresholdMap
setTaskThresholdMap:
hybridClassifierQueue
setHybridClassifierQueue:
lastReportedEndpointTimeMs
setLastReportedEndpointTimeMs:
processedAudioInSeconds
setProcessedAudioInSeconds:
lastEndpointPosterior
setLastEndpointPosterior:
stateSerialQueue
setStateSerialQueue:
didCommunicateEndpoint
setDidCommunicateEndpoint:
currentRequestSampleRate
setCurrentRequestSampleRate:
vtExtraAudioAtStartInMs
setVtExtraAudioAtStartInMs:
hepAudioOriginInMs
setHepAudioOriginInMs:
speechEndpointDetected
setSpeechEndpointDetected:
firstAudioPacketTimestamp
setFirstAudioPacketTimestamp:
firstAudioSampleSensorTimestamp
setFirstAudioSampleSensorTimestamp:
didTimestampFirstAudioPacket
setDidTimestampFirstAudioPacket:
numSamplesProcessedBeforeAnchorTime
setNumSamplesProcessedBeforeAnchorTime:
anchorMachAbsTime
setAnchorMachAbsTime:
isAnchorTimeBuffered
setIsAnchorTimeBuffered:
isRequestTimeout
setIsRequestTimeout:
isASRFeatureFromServer
setIsASRFeatureFromServer:
recordingDidStop
setRecordingDidStop:
didDetectSpeech
setDidDetectSpeech:
setElapsedTimeWithNoSpeech:
endpointerOperationMode
_saveSamplesSeenInReset
_canProcessCurrentRequest
_epResult
_didReceiveServerFeatures
_useDefaultServerFeaturesOnClientLag
_didCommunicateEndpoint
_speechEndpointDetected
_didTimestampFirstAudioPacket
_isAnchorTimeBuffered
_isRequestTimeout
_isASRFeatureFromServer
_recordingDidStop
_didDetectSpeech
_lastEndpointPosterior
_implDelegate
_mhId
_endpointStyle
_endpointMode
_startWaitTime
_endWaitTime
_interspeechWaitTime
_delay
_automaticEndpointingSuspensionEndTime
_minimumDurationForEndpointer
_osdFeaturesAtEndpoint
_hybridClassifier
_endpointerModelVersion
_serverFeaturesQueue
_lastKnownServerEPFeatures
_lastKnownOSDFeatures
_serverFeatureLatencies
_lastKnowServerFeaturesLatency
_serverFeaturesWarmupLatency
_lastServerFeatureTimestamp
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_extraDelayFrequency
_taskThresholdMap
_hybridClassifierQueue
_lastReportedEndpointTimeMs
_processedAudioInSeconds
_stateSerialQueue
_currentRequestSampleRate
_vtExtraAudioAtStartInMs
_hepAudioOriginInMs
_firstAudioPacketTimestamp
_firstAudioSampleSensorTimestamp
_numSamplesProcessedBeforeAnchorTime
_anchorMachAbsTime
_elapsedTimeWithNoSpeech
_endpointerOperationMode
T@"OSDFeatures",&,N,V_osdFeaturesAtEndpoint
TB,N,V_canProcessCurrentRequest
T@"_EAREndpointer",&,N,V_hybridClassifier
T@"NSString",&,N,V_endpointerModelVersion
T@"NSObject<OS_dispatch_queue>",&,N,V_serverFeaturesQueue
T@"CSServerEndpointFeatures",&,N,V_lastKnownServerEPFeatures
T@"OSDFeatures",&,N,V_lastKnownOSDFeatures
T@"NSMutableArray",&,N,V_serverFeatureLatencies
Td,N,V_lastKnowServerFeaturesLatency
TB,N,V_epResult
Td,N,V_serverFeaturesWarmupLatency
T@"NSDate",&,N,V_lastServerFeatureTimestamp
TB,N,V_didReceiveServerFeatures
Td,N,V_clientLagThresholdMs
Td,N,V_clampedSFLatencyMsForClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
TQ,N,V_extraDelayFrequency
T@"NSDictionary",&,N,V_taskThresholdMap
T@"NSObject<OS_dispatch_queue>",&,N,V_hybridClassifierQueue
Td,N,V_lastReportedEndpointTimeMs
Td,N,V_processedAudioInSeconds
Tf,N,V_lastEndpointPosterior
T@"NSObject<OS_dispatch_queue>",&,N,V_stateSerialQueue
TB,N,V_didCommunicateEndpoint
TQ,N,V_currentRequestSampleRate
Td,N,V_vtExtraAudioAtStartInMs
Td,N,V_hepAudioOriginInMs
TB,N,V_speechEndpointDetected
T@"NSDate",&,N,V_firstAudioPacketTimestamp
Td,N,V_firstAudioSampleSensorTimestamp
TB,N,V_didTimestampFirstAudioPacket
TQ,N,V_numSamplesProcessedBeforeAnchorTime
TQ,N,V_anchorMachAbsTime
TB,N,V_isAnchorTimeBuffered
TB,N,V_isRequestTimeout
TB,N,V_isASRFeatureFromServer
TB,N,V_recordingDidStop
TB,N,V_didDetectSpeech
Td,N,V_elapsedTimeWithNoSpeech
Tq,N,V_endpointerOperationMode
T@"<CSEndpointAnalyzerDelegate>",W,N,V_delegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_implDelegate
Tq,N,V_endpointStyle
Td,N,V_delay
Td,N,V_startWaitTime
Td,N,V_automaticEndpointingSuspensionEndTime
Td,N,V_minimumDurationForEndpointer
Tq,N,V_endpointMode
Td,N,V_interspeechWaitTime
Td,N,V_endWaitTime
TB,N,V_saveSamplesSeenInReset
T@"NSString",&,N,V_mhId
initWithDeviceId:audioStreamHandleId:
waitingForConnection:error:
startRecordingWithOptions:error:
stopRecording:
didPlayEndpointBeep
hasPendingTwoShotBeep
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
TQ,R,N,V_audioStreamHandleId
CSSiriEnabledMonitor:didReceiveEnabled:
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
addReceiver:
removeReceiver:
numBytesPerSample
_createAudioStreamWithCurrentNviContext
audioStreamProvider:avBufferAvailable:
nviCtx
setNviCtx:
receivers
setReceivers:
_nviCtx
_receivers
T@"NviContext",&,N,V_nviCtx
T@"NSHashTable",&,N,V_receivers
isDefaultInputBuiltInMic
isDefaultOutputBultInSpeaker
defaultOutputAudioDeviceID
engineWithDeviceType:streamHandleId:
prewarmDeviceWithIdentifier:
deviceWithAddress:
deviceWithUID:
_dataSource
assetStatus:
checkFirstUnlocked
getCurrentOSDAsset
getCurrentEndpointerAsset
_getCurrentHEPAsset
_updateAssetWithCurrentLanguageForAssetType:
_updateAssetWithLanguage:assetType:
_updateOEPAssetsWithLanguage:
_notifyAssetsUpdate
_fetchEndpointMobileAssetWithLanguage:
_getModelPathFromInstallationStatusString:
_isOSDIncludedInAsset:
_getOEPVersionFromPath:
_getFakeEndpointAsset
currentHEPAsset
setCurrentHEPAsset:
currentOEPAsset
setCurrentOEPAsset:
asrDatapackInstallationStatus
setAsrDatapackInstallationStatus:
_currentHEPAsset
_currentOEPAsset
_asrDatapackInstallationStatus
T@"CSAsset",&,N,V_currentHEPAsset
T@"CSAsset",&,N,V_currentOEPAsset
T@"NSDictionary",&,N,V_asrDatapackInstallationStatus
initWithRequestMHUUID:turnIdentifier:
estimatedUserSpeakingStartedHostTime
estimatedUserSpeakingEndedHostTime
setSpeechRecognizedContext:withEndpointerMetrics:
reportEndpointDelayIfNeed
_reportUEIUserSpeakingContext
endpointTimeInMs
setEndpointTimeInMs:
userSpeakingStartedTimeInMs
setUserSpeakingStartedTimeInMs:
userSpeakingEndedTimeInMs
setUserSpeakingEndedTimeInMs:
userSpeakingStartedHostTime
setUserSpeakingStartedHostTime:
userSpeakingEndedHostTime
setUserSpeakingEndedHostTime:
stopRecordingHostTime
setStopRecordingHostTime:
setTurnIdentifier:
didReportEndpointDelay
setDidReportEndpointDelay:
_didReportEndpointDelay
_endpointTimeInMs
_userSpeakingStartedTimeInMs
_userSpeakingEndedTimeInMs
_userSpeakingStartedHostTime
_userSpeakingEndedHostTime
_stopRecordingHostTime
Td,N,V_endpointTimeInMs
Td,N,V_userSpeakingStartedTimeInMs
Td,N,V_userSpeakingEndedTimeInMs
TQ,N,V_userSpeakingStartedHostTime
TQ,N,V_userSpeakingEndedHostTime
TQ,N,V_stopRecordingHostTime
T@"NSUUID",&,N,V_turnIdentifier
TB,N,V_didReportEndpointDelay
voiceTriggerRTModelForVersion:minorVersion:accessoryRTModelType:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
sharedNotifier
_notifyActivationEvent:completion:
notifyActivationEventSynchronously:completion:
notifyActivationEvent:deviceId:activationInfo:completion:
_createXPCClientConnection
_didReceiveLanguageCodeUpdate
_notifyObserver:withLanguageCode:
notifySiriLanguageCodeChanged:
readAudioChunksFrom:block:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_checkSoftwareUpdateCheckingState
_softwareUpdateCheckingState
isSoftwareUpdateCheckingRunning
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_didReceiveSoftwareUpdateCheckingStateChanged:
_notifyObserver:withSoftwareUpdateCheckingRunning:
_isSoftwareUpdateCheckingRunning
sharedPreferences
setFileLoggingIsEnabled:
fileLoggingIsEnabled
voiceTriggerAudioLogDirectory
isPHSSupported
isAttentiveSiriEnabled
isAttentiveSiriAudioLoggingEnabled
getAttendingTimeoutConfig
getStartOfSpeechAudioLogFilePath
setAudioInjectionFilePath:
enableAudioInjection:
useSiriActivationSPIForHomePod
trialBaseAssetDirectory
smartSiriVolumeContextAwareEnabled
disableAdaptiveSiriVolume:
isAdaptiveSiriVolumeTemporaryIntentValid
isAdaptiveSiriVolumePermanentOffsetEnabled
adaptiveSiriVolumePermanentOffset
adaptiveSiriVolumeRecentIntent
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
notifySiriSessionStateTTSOngoing:
notifySiriSessionStateChange:
notifyObserver:didReceiveNotificationWithToken:
notifyObserver:didChangeStateFrom:to:
dispatchStateChangedFrom:to:
siriStateObserver
setSiriStateObserver:
stateNotificationQueue
setStateNotificationQueue:
isSpeaking
setIsSpeaking:
isListening
setIsListening:
isActiveRequest
setIsActiveRequest:
isActiveSession
setIsActiveSession:
_isSpeaking
_isListening
_isActiveRequest
_isActiveSession
_siriStateObserver
_stateNotificationQueue
T@"AFNotifyObserver",&,N,V_siriStateObserver
T@"NSObject<OS_dispatch_queue>",&,N,V_stateNotificationQueue
TB,N,V_isSpeaking
TB,N,V_isListening
TB,N,V_isActiveRequest
TB,N,V_isActiveSession
T@"<CSAttSiriSessionStateDelegate>",R,W,N,V_delegate
getTestResponse:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerAOPModeEnabledPolicy
batteryState
progCheckerConfigFile
supportedInputOrigins
checkerThresholds
progCheckerShadowMode
contConvConfigFile
contConvThresholds
_mapInputOriginFromAssetToCSAudioRecordType:
T@"NSArray",R,N
notifyNewVoiceTriggerAssetMetaDataUpdated
_didReceiveNewVoiceTriggerAssetMetaData
initWithRecordContext:deviceId:shouldUseRemoteRecorder:streamHandleId:
updateWithLatestRecordContext:
updateDeviceId:
shouldUseRemoteRecorder
streamHandleId
_shouldUseRemoteRecorder
_streamHandleId
T@"CSAudioRecordContext",R,N,V_recordContext
TB,R,N,V_shouldUseRemoteRecorder
TQ,R,N,V_streamHandleId
siriInCallPolicy
initWithDescription:timeout:
addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
removeQueue:
beginMonitoring
endMonitoring
_addQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
_removeQueue:
_beginMonitoring
_endMonitoring
_numberOfTransactions
_observersByIdentifier
initWithQueue:heartBeatInterval:timeoutInterval:timeoutHandler:
startWithQueue:
heartBeatFiredWithQueue:
timeoutDetected
_numberOfOccurrences
_heartBeat
_heartBeatInterval
_timeoutInterval
_timeoutHandler
_addAlwaysEnabledCondition
initWithRecordingDuration:audioSamplesPerRemoteVAD:audioSampleRate:
remoteVADSampleCount
copySamplesFromAudioSampleCount:toAudioSampleCount:
copySamplesFrom:to:
capacity
size
beginSampleCount
_remoteVADCircularBufferImpl
_audioSamplesPerRemoteVAD
_capacity
_size
_beginSampleCount
TQ,R,N,V_capacity
TQ,R,N,V_size
TQ,R,N,V_beginSampleCount
_didReceiveNewAdBlockerAssetMetaData
initWithAudioStreamProvider:streamName:streamRequest:
updateAudioStreamStartTimeInSampleCount:
setStartStreamOption:
setScheduledFutureSample:
audioStreamProvider:audioBufferAvailable:lastForwardedSampleCount:
startSampleCount
scheduledFutureSample
streamRequest
setStreamRequest:
startStreamOption
isWeakStream
setIsWeakStream:
tandemStreams
needsBoost12dB
setNeedsBoost12dB:
streaming
setStreaming:
streamingUUID
setStreamingUUID:
_scheduledFutureSample
_isWeakStream
_needsBoost12dB
_streaming
_startSampleCount
_streamRequest
_startStreamOption
_tandemStreams
_streamingUUID
TB,V_streaming
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
TQ,R,N,V_startSampleCount
TQ,R,N,V_lastForwardedSampleCount
TB,N,SsetScheduledFutureSample:,V_scheduledFutureSample
T@"CSAudioStreamRequest",&,N,V_streamRequest
T@"CSAudioStartStreamOption",&,N,SsetStartStreamOption:,V_startStreamOption
TB,N,V_isWeakStream
T@"NSHashTable",R,N,V_tandemStreams
TB,N,V_needsBoost12dB
sharedSession
currentInputDeviceUIDArray
currentInputRoute
currentOutputRoute
_inputRoute
_outputRoute
initWithAudioDeviceID:
deviceName
_isBluetooth
_deviceName
_uid
T@"NSString",R,C,N,V_deviceName
T@"NSString",R,C,N,V_uid
TB,R,N,V_isBluetooth
T@"NSString",R,C,N,V_source
T@"NSString",R,C,N,V_destination
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
taskName
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
Tq,N,V_wordCount
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
Tq,N,V_processedAudioDurationInMilliseconds
T@"NSString",C,N,V_taskName
setDelegate:forType:
_isVoiceTriggerEvent:
_hasPendingActivationForType:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
T@"NSMapTable",&,N,V_delegates
T@"CSActivationEvent",&,N,V_pendingActivationEvent
T@?,C,N,V_pendingCompletion
accessoryModelTypeToString:
logLanguageMismatchMetricWithJarvisSelectedLocale:jarvisTriggerMode:
initWithFakeMonitor:
_handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:
voiceTriggerRemoraRTModelForVersion:minorVersion:locale:endpointId:downloadedModels:preinstalledModels:completion:
voiceTriggerHearstRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
getAccessoryFallbackLocalTable
getAccessoryFallbackFamilyLocal:fromLocaleMap:
selectFallbackModelForLocale:downloadedModels:preinstalledModels:rtLocaleMap:
_fetchVoiceTriggerInstalledAssetWithLanguage:completion:
fakeAssetMonitor
setFakeAssetMonitor:
_fakeAssetMonitor
T@"CoreSpeechXPCFakeModelMonitor",&,N,V_fakeAssetMonitor
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
isRestricted
_checkSiriRestrictedOnLockScreen
_didReceiveRestrictionChangedInQueue:
_didReceiveRestrictionChanged:
_notifyObserver:withRestricted:
_isRestricted
enableSmartRoutingConsiderationForStream:enable:
setFp:
T^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq},N,V_fp
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
isSpringboardStarted
_checkSpringBoardStarted
_isSpringBoardStarted
audioPreprocessor:hasAvailableBuffer:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:phoneCallStateMonitor:
initWithAudioStreamHandleId:audioStreamType:audioRecordContext:audioRecorder:
setStreamState:
setAudioProviderDelegate:
setLatestRecordContext:streamType:
_setLatestRecordContext:
_canSetContext
_audioStreamWithRequest:streamName:error:
_prepareAudioStreamSync:request:error:
_prepareAudioStream:request:completion:
_createCircularBufferIfNeededWithNumChannel:playbackRoute:
_startAudioStream:option:completion:
_switchToRecordingMode
_switchToListeningMode
_resetCircularBufferStartTime
_handleDidStartAudioStreamWithResult:error:
_preEpilogueAudioStream
_postEpilogueAudioStream
_handleDidStopAudioStreamWithReason:
_stopAudioStream:option:completion:
_audioChunkFrom:to:
_audioChunkFrom:to:channelIdx:
_saveRecordingBufferFrom:to:toURL:
_shouldDuckOnBuiltInSpeaker
_isDuckingOnSpeakerOutputSupportedWithCurrentRoute
_deactivateAudioSession:error:
_didPlayStartAlertSoundForSiri:audioStream:
_shouldStopRecording
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
_deliverHistoricalAudioToStreamsWithRemoteVAD:
_processAudioBuffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_forwardAudioChunk:toStream:
_deliverPostprocessAudioChunk:toStream:lastForwardedSampleCount:
_forwardAudioChunkForTV:toStream:
_scheduleAlertFinishTimeout:
_didReceiveFinishStartAlertPlaybackAt:
notifyProviderContextChanged
_handleAudioSystemFailure
_streamStateName:
_holdRecordingTransactionIfNeeded
_releaseRecordingTransactionIfNeeded
_holdRecordingExceptionIfNeeded:
_scheduleAudioPacketWatchDog
_cancelAudioPacketWatchDog
_onAudioPacketWatchdogFire
_scheduleDidStartRecordingDelegateWatchDog
_schduleDidStartRecordingDelegateWatchDogWithToken:
_clearDidStartRecordingDelegateWatchDog
_scheduleDidStopRecordingDelegateWatchDog
_scheduleDidStopRecordingDelegateWatchDog:
_clearDidStopRecordingDelegateWatchDog
_shouldHandleStartPendingOnStopping:withStopReason:
_updateRemoteDeviceIdFromAVVCIfNeeded
CSPhoneCallStateMonitor:didRecievePhoneCallStateChange:
circularBufferNumInputChannel
circularBufferInputRecordingDuration
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamHandleQueue
setStreamHandleQueue:
streamState
startPendingStreams
setStartPendingStreams:
startPendingOnStoppingStreams
setStartPendingOnStoppingStreams:
alertPlaybackFinishWaitingStreams
setAlertPlaybackFinishWaitingStreams:
streams
setStreams:
stopPendingStreams
setStopPendingStreams:
pendingStartCompletions
setPendingStartCompletions:
alertPlaybackFinishWaitingCompletions
setAlertPlaybackFinishWaitingCompletions:
pendingStopCompletions
setPendingStopCompletions:
startPendingOnStoppingStreamToCompletionDict
setStartPendingOnStoppingStreamToCompletionDict:
providerDelegate
setProviderDelegate:
sessionDelegate
setSessionDelegate:
streamHolders
setStreamHolders:
historicalBufferRequestStreams
setHistoricalBufferRequestStreams:
alertDelegate
setAlertDelegate:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
audioPreprocessor
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
audioPacketWatchdog
setAudioPacketWatchdog:
circularBufferStartHostTime
setCircularBufferStartHostTime:
circularBufferStartSampleCount
setCircularBufferStartSampleCount:
audioStreamType
setAudioStreamType:
recordDeviceIndicator
setRecordDeviceIndicator:
micUsageReporter
setMicUsageReporter:
audioPacketDeliveryCount
setAudioPacketDeliveryCount:
adpAssertion
setAdpAssertion:
phoneCallStateMonitor
setPhoneCallStateMonitor:
setPhoneCallState:
currentSessionShouldDuckOnBuiltInSpeaker
setCurrentSessionShouldDuckOnBuiltInSpeaker:
_audioSystemRecovering
_waitingForAlertFinish
_currentSessionShouldDuckOnBuiltInSpeaker
_recordQueue
_loggingQueue
_streamHandleQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_audioPacketWatchdog
_circularBufferStartHostTime
_circularBufferStartSampleCount
_audioStreamType
_recordDeviceIndicator
_micUsageReporter
_audioPacketDeliveryCount
_adpAssertion
_phoneCallStateMonitor
_phoneCallState
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_streamHandleQueue
TQ,N,V_streamState
T@"NSHashTable",&,N,V_startPendingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_streams
T@"NSHashTable",&,N,V_stopPendingStreams
T@"NSMutableArray",&,N,V_pendingStartCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
T@"NSMutableArray",&,N,V_streamHolders
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
TB,N,V_audioSystemRecovering
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
T@"CSOSTransaction",&,N,V_recordingTransaction
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
TB,N,V_waitingForAlertFinish
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
T@"NSObject<OS_dispatch_source>",&,N,V_audioPacketWatchdog
TQ,N,V_circularBufferStartHostTime
TQ,N,V_circularBufferStartSampleCount
Tq,N,V_audioStreamType
T@"CSAudioRecordDeviceIndicator",&,N,V_recordDeviceIndicator
T@"CSMicUsageReporter",&,N,V_micUsageReporter
TQ,N,V_audioPacketDeliveryCount
T@"CSADPPreventStandbyAssertion",&,N,V_adpAssertion
T@"CSPhoneCallStateMonitor",&,N,V_phoneCallStateMonitor
TQ,N,V_phoneCallState
TB,N,V_currentSessionShouldDuckOnBuiltInSpeaker
_addListeningEnabledConditions
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
adBlockerAssetDecoderWithVersion:
notifyInEarMyriadTrigger
_handleCallActiveDidChangeNotification:
hasConnectedAVCall
_startObservingAVCallActiveChange
_hasConnectedAVCall
isUserActive
defaultProtocolInfo
localDeviceProtocolInfo
initWithProtocolVersion:buildVersion:deviceProductVersion:deviceProductType:deviceCategory:
protocolVersion
buildVersion
deviceProductVersion
deviceProductType
deviceCategory
_protocolVersion
_buildVersion
_deviceProductVersion
_deviceProductType
_deviceCategory
TQ,R,N,V_protocolVersion
T@"NSString",R,N,V_buildVersion
T@"NSString",R,N,V_deviceProductVersion
T@"NSString",R,N,V_deviceProductType
TQ,R,N,V_deviceCategory
getNumElementInBitset:
iterateBitset:block:
osdAnalyzer:didUpdateOSDFeatures:
osdAnalyzer:didDetectStartOfSpeechAt:
osdAnalyzer:didDetectEndOfSpeechAt:
_loadAndSetupEndpointerAssetIfNecessary
_updateAssetWithLanguage:
_updateAssetWithCurrentLanguage
apQueue
setApQueue:
didAddAudio
setDidAddAudio:
osdAnalyzer
setOsdAnalyzer:
osdQueue
setOsdQueue:
_didAddAudio
_apQueue
_osdAnalyzer
_osdQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_apQueue
TB,N,V_didAddAudio
T@"OSDAnalyzer",&,N,V_osdAnalyzer
T@"NSObject<OS_dispatch_queue>",&,N,V_osdQueue
opportuneSpeakListeningType
setOpportuneSpeakListeningType:
_opportuneSpeakListeningType
TQ,N,V_opportuneSpeakListeningType
initWithDeviceType:deviceName:deviceID:productID:
isPluginDevice
speakAudio:
speakAudio:withScaleFactor:playbackStarted:completion:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setEnableAlwaysOnVoiceTrigger:
deviceType
deviceID
deviceUID
productIdentifier
setIsConnected:
enableAlwaysOnVoiceTrigger
injectionEngine
setInjectionEngine:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
Tq,R,N,V_deviceType
T@"NSString",R,N,V_deviceName
T@"NSString",R,N,V_deviceID
T@"NSUUID",R,N,V_deviceUID
T@"NSString",R,N,V_productIdentifier
TB,N,V_isConnected
TB,N,V_enableAlwaysOnVoiceTrigger
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
_registerAudioSessionNotifications
_deregisterAudioSessionNotifications
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
initForSidekick
_setupNNVADEndpointer
_updateAccessibleEndpointerThresholdIfNeed
isWatchRTSTriggered
logHybridEndpointFeaturesWithEvent:locale:
endpointerImplDelegate
setEndpointerImplDelegate:
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
accessibleEndpointerEnabled
setAccessibleEndpointerEnabled:
_accessibleEndpointerEnabled
_endpointerImplDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
TB,N,V_accessibleEndpointerEnabled
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,V_endpointerImplDelegate
_cleanUpDeviceProxies
_detachFromSession
_attachToSession
_setUpAccessoryManager
_tearDownAccessoryManager
accessoryManager:event:device:state:
_reloadForDevice:
_deviceProxies
getBTDeviceWithAddress:completion:
getBTDeviceWithDeviceUID:completion:
_deviceProxyWithAddress:createsIfAbsent:
_deviceProxyWithUID:createsIfAbsent:
_session
_accessoryManager
_attachingToSession
_sessionSetupGroup
_deviceProxiesLock
_deviceProxiesByAddress
_deviceProxiesByDeviceUID
bluetoothDevice:deviceInfoDidChangeFrom:to:
bluetoothDeviceDidInvalidate:
prewarm
identifier
getDeviceInfo:
getHeadphoneInEarDetectionState:
getHeadphoneListeningMode:
setHeadphoneListeningMode:completion:
connect:
disconnect:
initWithAddress:dataSource:queue:
initWithDeviceUID:dataSource:queue:
updateDeviceInfo:
reload
_reload:
_getDeviceInfo:
_updateDeviceInfo:
_fetchDeviceInfoWithCompletion:
_accessBTDeviceAndAccessoryManagerUsingBlock:
_invalidate
_enumerateObserversUsingBlock:
_headphoneInEarDetectionState
_headphoneListeningMode
T@"NSString",R,C,N,V_address
T@"NSUUID",R,C,N,V_deviceUID
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
isFirstUnlocked
_checkFirstUnlocked
_firstUnlocked
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
_didReceivePhraseSpotterSettingChangedInQueue:
_checkPhraseSpotterEnabled
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
initWithConnection:
activateConnection
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
_sendReplyMessageWithResult:error:event:client:
xpcConnection:hasEntitlement:
initWithInstanceContext:
overrideAudioSessionActiveDelay
serverMediaPlaybackVolumeThresholdForAudioSessionActivationDelay
serverAudioSessionActivationDelayAboveMediaPlaybackVolumeThreshold
serverAudioSessionActivationDelay
internalUserClassification
_instanceContext
createMockRemoteDeviceWithName:deviceID:completion:
injectAudio:toDeviceWithUUID:completion:
listMockRemoteDeviecesWithCompletion:
initWithAudioRecorder:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
initWithEndpointThreshold:
initWithAnalyzeMode
getFrameDurationMs
addAudio:numSamples:
caesuraSPG
setCaesuraSPG:
endpointThreshold
setEndpointThreshold:
hasReported
setHasReported:
isAnalyzeMode
setIsAnalyzeMode:
lastSilencePosterior
setLastSilencePosterior:
_hasReported
_isAnalyzeMode
_endpointThreshold
_caesuraSPG
_lastSilencePosterior
T@"EARCaesuraSilencePosteriorGenerator",&,N,V_caesuraSPG
Tf,N,V_endpointThreshold
TB,N,V_hasReported
TB,N,V_isAnalyzeMode
Td,N,V_lastSilencePosterior
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
shouldVoiceTriggerRun
shouldAudioMonitoringRecording
appendAcousticData:sampleCount:sampleRate:
getSignature:
_connectionInterrupted
_connectionInvalidated
_cleanUpConnection
_service
_serviceWithErrorHandler:
_samplesPerInterval
setFingerprintInterval:
setASBD:
_configureWithCurrentASBD
_needsConversion
_convertPCMDataForFingerprinting:
appendPCMData:
_asxConnection
_totalSampleCount
_nextFingerprintSampleNumber
_sourceASBD
_interval
_fingerprinterConverter
T@"<CSSiriAcousticFingerprinterDelegate>",W,N,V_delegate
languageDetectorRequestContext
samplingRate
setSamplingRate:
dictationLanguages
setDictationLanguages:
currentKeyboard
setCurrentKeyboard:
wasLanguageToggled
setWasLanguageToggled:
multilingualKeyboardLanguages
setMultilingualKeyboardLanguages:
keyboardConvoLanguagePriors
setKeyboardConvoLanguagePriors:
keyboardGlobalLanguagePriors
setKeyboardGlobalLanguagePriors:
previousMessageLanguage
setPreviousMessageLanguage:
globalLastKeyboardUsed
setGlobalLastKeyboardUsed:
dictationLanguagePriors
setDictationLanguagePriors:
conversationalMessages
setConversationalMessages:
_wasLanguageToggled
_samplingRate
_dictationLanguages
_currentKeyboard
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_conversationalMessages
Tf,N,V_samplingRate
T@"NSSet",&,N,V_dictationLanguages
T@"NSString",&,N,V_currentKeyboard
TB,N,V_wasLanguageToggled
T@"NSArray",&,N,V_multilingualKeyboardLanguages
T@"NSDictionary",&,N,V_keyboardConvoLanguagePriors
T@"NSDictionary",&,N,V_keyboardGlobalLanguagePriors
T@"NSString",&,N,V_previousMessageLanguage
T@"NSString",&,N,V_globalLastKeyboardUsed
T@"NSDictionary",&,N,V_dictationLanguagePriors
T@"NSArray",&,N,V_conversationalMessages
speechCapturingDidUpdateAudioDeviceInfo:
acousticFingerprinter:hasFingerprint:duration:
speechControllerDidDetectStartpoint:
speechControllerDidDetectEndpoint:ofType:atTime:
speakerIdentificationDidDetectSpeakerWithScores:
initWithQueue:speechController:audioSessionController:audioPlaybackService:experimentContext:
suspendAutomaticEndpointingInRange:
setSpeechRequestOptions:
setSpeechWasRecognizedForElapsedTime:isFinal:
setFingerprintWasRecognized
stopSpeechCaptureForEvent:suppressAlert:hostTime:
cancelSpeechCaptureSuppressingAlert:
setFingerprintingEnabled:
forceSuccessAudioAlertOnStop
setIsDriving:
getLastStartpointTimestampAndCurrentTime:
playRecordingStartAlert
updateServerEndpointFeatures:
updateEndpointHintForRC:forceAccept:completion:
enforcePreviousEndpointHint
disableSpeechPacketGeneration:
_currentMHUUID:
_mhUUIDFromSpeechRequestOptions:
_setSpeechCapturingMode:
_setEndpointerOperationMode:forceUpdate:
_setAlertsIfNeeded
_updateRecordBufferDuration
_speechController
_speechControllerWithError:
_resetSpeechController
_fingerprinter
_prepareSpeechControllerWithOptions:error:
_stopRecordingWithReason:hostTime:
_shouldEmitInstrumentation
_mapInstrumentationEndpointTypeFromStopRecordingReason:
_playAudioAlert:
_checkAudioLoggingLimits:
_prepareDirectoryAtPath:
_setupAudioFileWritingForSpeechController:info:context:
_setEndpointStyle:
_scheduleExtendedEndpointTimer
_cancelExtendedEndpointTimer
_stopRecordingForEndpointReason:
eagerlyInitializeAudioRecording
preheatWithOption:
preheatRecognizerWithOption:
prepareSpeechCaptureWithOptions:error:
recordingInfoForPreheatWithEvent:
currentVTSatScore
prepareForMode:
prepareForMode:withOptions:
startSpeechCaptureWithContext:willStartHandler:error:
updateSpeechSynthesisRecord:
fetchAudioSessionID
fetchRecordingInfo
fetchAudioDeviceInfo
_logFanState
_getFanInfoArray
_logBluetoothStateWithMHUUID:
_logVoiceTriggerInfo:withMHUUID:
_logAudioMetrics:mhUUID:
_updateAudioContextWithInfo:reason:
_setAudioContextWithInfo:forReason:
_updateAudioContextToPostVoiceForReason:
_updateAudioContextWithPendingInfoForReason:
setAudioFileType:
setAudioFileHandle:
setSpeechRecordingEventListeningEndpoint:
_speechRecordingEventListener
_currentRecordRoute
_currentRecordDeviceInfo
_currentPlaybackRoute
_updateAudioDeviceInfo:forReason:forcesUpdate:
_currentRecordingInfo
_recordingInfoForEvent:audioAlertStyle:includeBTInfo:includeRecordDeviceInfo:
_speechControllerDidStartRecording:successfully:error:
_speechControllerDidStopRecording:audioDeviceInfo:forReason:estimatedSpeechEndHostTime:errorCodeOverride:underlyingError:
_speechControllerDidReceiveFirstAudioRecordBufferWithHostTime:atHostTime:mhUUID:
convertSISchemaAudioInputRouteToMHRoute:withRecordingInfo:
getAudioRouteInstrumentationWithRecordingInfo:
_speechControllerDidReceiveLastAudioRecordBuffer:forReason:estimatedSpeechEndHostTime:isRecordingStopped:
_setLanguageDetectorDelegateIfRequired
_playStopAlertIfNecessaryForReason:endpointMode:error:
suppressUtteranceGradingIfRequired
_speechControllerRequestsOperation:forReason:completion:
_hardEndpointWasDetectedWithMetrics:atTime:
_performTwoShotPromptForType:atTime:
_playPhaticWithCompletion:
_handleFakeTwoShotPromptTimeoutWithUUID:
_handleFakeTwoShotPromptCallbackWithUUID:timestamp:duration:error:
_checkIfLastEndpointHintShouldBeAccepted:
_clearEndpointHint
_enforceEndpointHintWithMitigation:
setEndpointerThreshold:
setEndpointerDelayedTrigger:
setSpeechRecognizedContext:
performBlockAfterAlerts:timeout:
setEARLanguageDetectorSpeechRequestId:
_startAudioPlaybackRequest:options:completion:
_audioDeviceID
_setDictationAudioModeEnabled:
_setAudioDuckingEnabled:
suppressInterruptionEndedNotifications
setSuppressInterruptionEndedNotifications:
_isSpeechControllerInitialized
_audioPlaybackService
_packetCount
_speechCapturingMode
_recordingAlertsConfiguration
_extendedEndpointTimer
_endpointAnalyzer
_context
_currentActivationInfo
_pendingActivationInfo
_currentAudioDeviceInfo
_fingerprintingEnabled
_audioFileType
_needsAVVCLPCMCallbacks
_hasReceivedEmptyLPCMRecordBuffer
_audioFileHandle
_startEvent
_recordingState
_didReceiveFirstBuffer
_didReceiveLastBuffer
_didDetectStartpoint
_didDetectEndpoint
_didEnterTwoShotMode
_didFakeTwoShotWithAlert
_fakeTwoShotTTSPromptUUID
_serverDidRecognizeSpeech
_fingerprintWasRecognized
_serverDidEndpoint
_didTimeout
_wasCanceled
_suppressRecordingStoppedAlert
_isRecordingUsingBTRoute
_twoShotStartTime
_didPerformTwoShotPrompt
_forceSuccessAlertOnStop
_isDriving
_shouldDisableSpeechPacketGeneration
_lastPrepareTimestamp
_accumulatedBufferDuration
_decoder
_expectedFirstBufferTimestamp
_recordDevice
_audioDuckingEnabled
_speechRecordingEventListenerConnection
_fakeTwoShotTTSPromptWatchdogTimer
_lastAudioRecordBufferStartTime
_lastAudioRecordBufferReceiptTime
_lastEndpointerMetrics
_endpointDelayReporter
_lastEndpointHintFeatures
_lastEndpointHintCompletion
_lastEndpointHintRC
_lastEndpointHintRCProcessedForMitigation
_mostRecentSpeechSynthesisRecord
_alertPlaybackGroup
_numberOfAVVCAlertPlaybacksByType
_bluetoothWirelessSplitterSessionStateObserver
_mhUUID
_suppressInterruptionEndedNotifications
TB,N,V_suppressInterruptionEndedNotifications
memoryPressureObserver:didChangeFromCondition:toCondition:
prewarmRequest:completion:
startRequest:options:completion:
stopRequest:immediately:
stopAllRequests:completion:
stopAllRequestsSynchronously
initWithAudioSessionController:
startRequest:options:preparationHandler:executionHandler:finalizationHandler:
addListener:
removeListener:
removeAllListeners
_prewarmRequest:completion:
_startRequest:options:preparationHandler:executionHandler:finalizationHandler:
_handlePreparationForSession:
_handleExecutionForSession:
_handleFinalizationForSession:error:
_stopRequest:immediately:
_stopAllRequests:completion:
_stopAllRequestsSynchronously
_enumerateListenersUsingBlock:
_evictAllReusableSessionsForReason:
_setAudioSessionID:
_createAudioPlaybackSessionWithRequest:options:
_listeners
_activeSessionsByRequest
_reusableSessionsByRequest
getInstalledAssetofType:forLocale:completion:
initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:
resetForNewRequest
configFile
setConfigFile:
startDetected
setStartDetected:
minSpeechFrames
setMinSpeechFrames:
curSpeechFrames
setCurSpeechFrames:
numLeadingFrames
setNumLeadingFrames:
prevAudioProcessedMs
setPrevAudioProcessedMs:
spgQueue
setSpgQueue:
sosQueue
setSosQueue:
_startDetected
_prevAudioProcessedMs
_configFile
_minSpeechFrames
_curSpeechFrames
_numLeadingFrames
_spgQueue
_sosQueue
T@"NSString",&,N,V_configFile
TB,N,V_startDetected
TQ,N,V_minSpeechFrames
TQ,N,V_curSpeechFrames
TQ,N,V_numLeadingFrames
Tf,N,V_prevAudioProcessedMs
TQ,N,V_samplingRate
T@"NSObject<OS_dispatch_queue>",&,N,V_spgQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sosQueue
T@"<CSStartOfSpeechDetectorDelegate>",W,N,V_delegate
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
serverState
setServerState:
_serverState
TQ,N,V_serverState
T@"<CSVoiceTriggerXPCClientDelegate>",W,N,V_delegate
registerXPCActivities
notifyDaemonStateChanged:
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
isAvailable
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
handleSpeechDetectionVADPresentChange:
isPresent
_startObservingSpeechDetectionVADPresence
_didReceiveLanguageCodeUpdate:
initWithAssetManager:withTrialAssetManager:withTrialDownloadMonitor:withVTAssetHandler:withAssetOverrideFlag:withOverrideAssetPath:
getMitigationAssetWithEndpointId:completion:
_receivedNewAssetUpdate:
trialDownloadMonitor
setTrialDownloadMonitor:
vtAssetHandler
setVtAssetHandler:
overrideEnabled
setOverrideEnabled:
overridePath
setOverridePath:
_overrideEnabled
_trialDownloadMonitor
_vtAssetHandler
_overridePath
T@"CSTrialAssetDownloadMonitor",&,N,V_trialDownloadMonitor
T@"CSVoiceTriggerAssetHandler",&,N,V_vtAssetHandler
TB,N,V_overrideEnabled
T@"NSString",&,N,V_overridePath
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:remoteDeviceUIDString:
initWithAVVCRecordDeviceInfo:
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
remoteDeviceUIDString
_isRemoteDevice
_remoteDeviceUID
_remoteDeviceProductIdentifier
_remoteDeviceUIDString
T@"NSString",R,C,N,V_remoteDeviceUIDString
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
listener
opusConverter
narrowBandOpusConverter
speexConverter
addSamples:timestamp:arrivalTimestampToAudioRecorder:
_convertBufferedLPCM:allowPartial:timestamp:arrivalTimestampToAudioRecorder:
_configureAudioConverter:
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_lastArrivalTimestampToAudioRecorder
_outPacketSizeInSec
T@"<CSAudioConverterDelegate>",W,V_delegate
isVoiceTriggerInfoAvailableLocally:
setVoiceTriggerInfo:deviceId:
fetchVoiceTriggerInfoWithAudioContext:triggerInfoProviding:resultVoiceTriggerInfo:resultRTSTriggerInfo:
_isBuiltInDeviceFromDeviceId:
rtsTriggerInfo
setRtsTriggerInfo:
triggerNotifiedMachTime
setTriggerNotifiedMachTime:
_accessoryVoiceTriggerEvents
_builtInVoiceTriggerEvent
_rtsTriggerInfo
_triggerNotifiedMachTime
T@"NSDictionary",C,N,V_rtsTriggerInfo
TQ,N,V_triggerNotifiedMachTime
_cs_isHashTableEmpty
splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:
rawMicChannelsDataWithNumSamplesPerChannel:
strRepForFloatData
getAudioInjectionXPCConnection
setAudioInjectionMode:
audioInjectionEnabled
injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:
injectAudio:toDeviceWithUUID:withNumChannels:completion:
deviceConnectedWithUUID:
deviceDisconnectedWithUUID:
allDeviceDisconnected
notifyVoiceTriggerEnabledWithDeviceUUID:
notifyVoiceTriggerDisabledWithDeviceUUID:
fetchDeviceUUIDStringFromUID:
hasDarwinDeviceConnected
hasDarwinDeviceHandleVoiceTrigger
isRemoteDarwinConnectedWithUUID:
fetchRichDeviceUIDStringFromUUID:
isPrimaryVoiceTriggerDeviceWithUUID:
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
timestamp
_droppingPrediction
_droppedPrediction
_timestamp
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
isRecordContextVoiceTrigger:
isRecordContextBuiltInVoiceTrigger:
isRecordContextDarwinVoiceTrigger:
isRecordContextRemoraVoiceTrigger:
isRecordContextHomeButtonPress:
isRecordContextAutoPrompt:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextHearstDoubleTap:
isRecordContextRaiseToSpeak:
isRecordContextJarvisVoiceTrigger:
isRecordContextJarvisButtonPress:
isValidRecordContext:
recordContextString:
languageDetectorSupportedLocale
languageDetectorConfigFile
startOfSpeechDetectorConfigFile
spgConfigFile
remoteVoiceActivityVADBuffer
_convertDeactivateOption:
resetDuckSettings
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
remoteRecordDidStartRecordingWithStreamHandleId:error:
remoteRecordDidStopRecordingWithWithStreamHandleId:error:
remoteRecordLPCMBufferAvailable:streamHandleId:
remoteRecordTwoShotDetectedAtTime:
remoteRecordConnectionDisconnected:
userSessionActivateMonitor:didReceivedUserSessionActiveHasChanged:
initWithQueue:error:
_destroyVoiceController
_voiceControllerWithError:
_shouldInjectAudio
_startAudioStreamForAudioInjectionWithAVVCContext:
_shouldLogResourceNotAvailableError
_logResourceNotAvailableErrorIfNeeded:
setDuckMixWithOthersForStream:duckOthers:duckToLevelInDB:mixWithOthers:
isDuckingSupportedOnCurrentRouteWithStreamHandleID:error:
_updateLanguageCodeForRemoteVTEIResult:
_shouldUseRemoteBuiltInMic:
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_trackRemoteAccessoryStreamIdIfNeeded:
_stopTrackingRemoteAccessoryStreamId:
_audioIsFromRemoteAccessory:
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
_audioRecorderDidStopRecordingForReason:streamHandleID:
_hasLocalPendingTwoShot
_needResetAudioInjectionIndex:
_getRecordSettingsWithRequest:
_fetchRemoteRecordClientWithDeviceId:streamHandleId:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
remoteAccessoryStreamIdSet
setRemoteAccessoryStreamIdSet:
_voiceController
_interleavedABL
_remoteRecordClient
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_audioBufferPool
_hasSetAlertDictionary
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
_remoteAccessoryStreamIdSet
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
T@"NSMutableSet",&,N,V_remoteAccessoryStreamIdSet
notifyDidStartStreamWithContext:successfully:option:
initWithSharedSiriId:languageCode:productCategory:version:sharedHomeId:userName:
profileId
setProfileId:
languageCode
setLanguageCode:
productCategory
setProductCategory:
version
setVersion:
onboardType
setOnboardType:
homeId
setHomeId:
userName
setUserName:
_profileId
_languageCode
_productCategory
_onboardType
_homeId
_userName
T@"NSString",&,N,V_profileId
T@"NSString",&,N,V_languageCode
T@"NSString",&,N,V_productCategory
T@"NSNumber",&,N,V_version
TQ,N,V_onboardType
T@"NSString",&,N,V_homeId
T@"NSString",&,N,V_userName
setVoiceTriggerInfo:
requestHistoricalAudio
setRequestHistoricalAudio:
reqStartAudioSampleId
setReqStartAudioSampleId:
reqStartMachAbsTime
setReqStartMachAbsTime:
shouldLogRawSensorData
setShouldLogRawSensorData:
rootLogDir
setRootLogDir:
_requestHistoricalAudio
_shouldLogRawSensorData
_reqStartAudioSampleId
_reqStartMachAbsTime
_rootLogDir
T@"NSDictionary",&,N,V_voiceTriggerInfo
TB,N,V_requestHistoricalAudio
TQ,N,V_reqStartAudioSampleId
TQ,N,V_reqStartMachAbsTime
TB,N,V_shouldLogRawSensorData
T@"NSString",&,N,V_rootLogDir
triggerModeStringDescription:
setTriggerMode:
getTriggerMode
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
_notifyStopOpportuneSpeakWithDelay:
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_token
TB,N,V_isOpportuneSpeakListening
T@"NSString",&,N,V_audioProviderUUID
T@"NSUUID",&,N,V_token
setSigType:
sigGenTs
setSigGenTs:
_sigType
_sigGenTs
TQ,N,V_sigType
TQ,N,V_sigGenTs
isSiriRestrictedOnLockScreen
@24@0:8@16
@16@0:8
v24@0:8@16
v16@0:8
B16@0:8
Q16@0:8
v24@0:8Q16
v20@0:8B16
@"NSMutableArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v44@0:8@16Q24B32@36
v40@0:8@16Q24Q32
v56@0:8@16Q24@32@40Q48
v32@0:8@16@24
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@24@0:8Q16
B44@0:8@16f24@?28@?36
q24@0:8@16
@"NSObject<OS_dispatch_queue>"
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSAudioCircularBuffer"
@"NSUUID"
@"CSAudioInjectionDevice"
v32@0:8@16Q24
v32@0:8@"NSStream"16Q24
@32@0:8@16@24
@"NSOutputStream"
v32@0:8Q16@24
v32@0:8@16q24
v40@0:8@16q24Q32
v48@0:8@16q24q32Q40
v36@0:8@16q24i32
v44@0:8@16q24i32Q36
v32@0:8@"CMWakeGestureManager"16q24
v40@0:8@"CMWakeGestureManager"16q24Q32
v48@0:8@"CMWakeGestureManager"16q24q32Q40
v36@0:8@"CMWakeGestureManager"16q24i32
v44@0:8@"CMWakeGestureManager"16q24i32Q36
@"CMWakeGestureManager"
v32@0:8@16@?24
@"NSHashTable"
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
v28@0:8@16B24
v28@0:8@"CSXPCClient"16B24
v32@0:8@"CSCoreSpeechDaemonStateMonitor"16Q24
v24@0:8@?16
I16@0:8
@"<CSAudioSessionInfoProviding>"
@"CSXPCClient"
f16@0:8
q16@0:8
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
@"NSURL"
^{OpaqueExtAudioFile=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSString"
Q40@0:8@16@24@32
v24@0:8@"CSAttSiriRequestContext"16
v24@0:8@"CSAttSiriAttendingTriggerEventInfo"16
@"<CSAttSiriServiceDelegate>"
@"NSXPCConnection"
v24@0:8q16
B32@0:8^B16^Q24
Q24@0:8Q16
@"<CSBiometricMatchMonitorDelegate>"
v20@0:8f16
v40@0:8@16@24@?32
v60@0:8@16@24Q32@40B48@?52
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSDictionary"16
v24@0:8@"NSData"16
v60@0:8@"NSDictionary"16@"NSData"24Q32@"NSString"40B48@?<v@?>52
v40@0:8Q16@24d32
v40@0:8Q16@"NSString"24d32
v32@0:8Q16@"NSString"24
@?16@0:8
@"<CSVoiceTriggerDelegate>"
@"<CSSecondPassProgressProviding>"
@"NSDictionary"
@"CSPreMyriadVoiceTriggerMetaData"
@"NSMutableDictionary"
@"CSKeywordAnalyzerNDAPI"
i16@0:8
d16@0:8
@40@0:8@16@24@32
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"CSAudioRecordDeviceInfo"
@"NSArray"
@"CSSSRXPCClient"
@"<CSSpeakerRecognitionProxyProtocol>"
v28@0:8@"CSVoiceTriggerXPCClient"16B24
v36@0:8B16@20@28
v28@0:8B16@20
v36@0:8B16d20@28
v28@0:8B16d20
@"CSVoiceTriggerXPCClient"
r*16@0:8
v40@0:8@16@24Q32
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@24@0:8f16i20
v32@0:8f16B20@24
B20@0:8f16
v20@0:8i16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
v48@0:8@16@24@32@?40
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
@"NSObject<OS_dispatch_group>"
^{__IOHIDUserDevice=}
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v52@0:8@16B24@28@36@44
v40@0:8@16Q24@32
v48@0:8@16Q24@32@40
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@24@0:8d16
B24@0:8d16
@20@0:8I16
@"NSObject<OS_dispatch_source>"
@"<CSAudioFileReaderDelegate>"
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
@"<CSLanguageDetectorAssetMonitorDelegate>"
v32@0:8@16d24
v24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
@28@0:8@16i24
@"CSAudioRecordContext"
@"CSSiriRecordingInfo"
@"CSSiriAudioFileWriter"
@"<AFRelinquishableAssertion>"
@"NSMutableSet"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
@32@0:8Q16@24
@"<CSSmartSiriVolumeClientDelegate>"
B40@0:8@16Q24^@32
B40@0:8@16@24^@32
B32@0:8@16^@24
f24@0:8Q16
B24@0:8Q16
B32@0:8Q16^@24
B40@0:8Q16Q24^@32
B40@0:8q16Q24^@32
B36@0:8@16q24B32
B32@0:8q16@24
@"CSAudioInjectionEngine"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
v36@0:8@16d24f32
v36@0:8@"CSSPGEndpointAnalyzer"16d24f32
v24@0:8@"CSSPGEndpointAnalyzer"16
v28@0:8B16@?20
@"<CSOpportuneSpeakListenerDelegate>"
@"CSAudioStream"
@"CSSPGEndpointAnalyzer"
@"<CSAudioStreamProviding>"
@"<CSAudioSessionProviding>"
@"CSPlainAudioFileWriter"
@"CSAudioTimeConverter"
v64@0:8@16@24@32@40@48@?56
@"NSObject<OS_xpc_object>"
@32@0:8d16Q24
v24@0:8d16
d24@0:8[80s]16
@"NSMutableData"
v28@0:8Q16B24
v36@0:8@16Q24B32
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v48@0:8@16@24f32i36@?40
v32@0:8@"NSString"16@?<v@?@"NSString">24
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v48@0:8@"NSURL"16@"NSUUID"24f32i36@?<v@?B@"NSError"QQ>40
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
v24@0:8@"NSString"16
v32@0:8d16@?24
v36@0:8Q16Q24B32
v32@0:8Q16@"CSAudioRecordContext"24
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8d16@?<v@?B@"NSArray">24
v32@0:8@"NSString"16@"NSString"24
v32@0:8@"OSDFeatures"16d24
v32@0:8@"NSDate"16Q24
v28@0:8@"CSServerEndpointFeatures"16B24
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
v32@0:8@"_EARLanguageDetector"16@"_EARLanguageDetectorLoggingInfo"24
v32@0:8@"_EARLanguageDetector"16@"NSDictionary"24
v32@0:8@"_EARLanguageDetector"16@"_EARLanguageDetectorResult"24
v32@0:8@"CSStartOfSpeechDetector"16Q24
v28@0:8@16f24
@"<CSLanguageDetectorDelegate>"
@"_EARLanguageDetector"
@"_EARLanguageDetectorAudioBuffer"
@"CSStartOfSpeechDetector"
@"CSAsset"
@40@0:8Q16Q24d32
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
v40@0:8Q16Q24Q32
v44@0:8@16@24B32@36
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
v24@0:8@"CSAudioServerCrashMonitor"16
@"AVVoiceTriggerClient"
@36@0:8q16@?24I32
@36@0:8q16@24I32
@44@0:8q16@?24@32I40
@"NSFileHandle"
@"NSError"
v64@0:8Q16Q24q32@40@48@?56
v72@0:8Q16Q24q32@40@48@56@?64
v56@0:8Q16Q24@32@40@?48
v20@0:8I16
v40@0:8@"CSVoiceTriggerAssetHandler"16@"NSString"24@"CSAsset"32
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v68@0:8@16Q24@32@40Q48Q56i64
v40@0:8@16Q24q32
v40@0:8@16q24@32
v68@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v32@0:8@"CSAudioRecorder"16@"NSError"24
v32@0:8@"CSAudioProvider"16Q24
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
@32@0:8@16^@24
@24@0:8^@16
@"CSAudioRecorder"
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
@"CSSmartSiriVolumeManager"
v32@0:8Q16Q24
@"<CSCommandControlListenerDelegate>"
v32@0:8@"CSAssetController"16Q24
v32@0:8@16@"NSString"24
v32@0:8Q16@?24
v48@0:8Q16@24Q32@?40
v48@0:8Q16Q24@32@?40
@"CSPolicy"
@"CSAssetDownloadingOption"
v72@0:8q16q24d32@40d48@56q64
v72@0:8q16q24d32@"NSArray"40d48@"NSString"56q64
v24@0:8@?<v@?@"NSError"@"NSString">16
v24@0:8@?<v@?@"NSError"d>16
v24@0:8@?<v@?@"NSError"Q>16
v32@0:8d16@24
v32@0:8d16@"CSEndpointerMetrics"24
v48@0:8Q16@24@32@40
@32@0:8@"<NviDataSource>"16@"<NviAssetsProvider>"24
v24@0:8@"<NviSignalProviderDelegate>"16
v32@0:8@"NviContext"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError">16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@?<v@?@>16
@48@0:8@16@24@32@40
@56@0:8@16@24@32@40@48
@"NSXPCListener"
@"NSXPCInterface"
@32@0:8Q16Q24
@"NSNumber"
v52@0:8@16@24f32Q36Q44
v52@0:8@"CSAudioConverter"16@"NSArray"24f32Q36Q44
v32@0:8@"CSSmartSiriVolumeController"16Q24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v32@0:8@"CSAudioSessionController"16@"NSDictionary"24
v72@0:8@16Q24@32@40Q48Q56B64I68
v72@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48Q56B64I68
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v40@0:8@"<CSEndpointAnalyzerImpl>"16Q24Q32
v48@0:8@16q24q32@40
v32@0:8@16B24B28
v48@0:8@"SOMediaNowPlayingObserver"16q24q32@"NSDate"40
v24@0:8@"SOMediaNowPlayingObserver"16
v32@0:8@"SOMediaNowPlayingObserver"16B24B28
v32@0:8@"SOClockAlarmObserver"16@"NSUUID"24
v40@0:8@"SOClockAlarmObserver"16@"AFClockAlarmSnapshot"24@"AFClockAlarmSnapshot"32
v32@0:8@"SOClockTimerObserver"16@"NSUUID"24
v40@0:8@"SOClockTimerObserver"16@"AFClockTimerSnapshot"24@"AFClockTimerSnapshot"32
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
v32@0:8@"CSContinuousVoiceTrigger"16@"NSDictionary"24
v32@0:8@"CSContinuousVoiceTrigger"16d24
@116@0:8@16@24@32@40@48@56@64@72@80@88B96B100B104B108B112
B44@0:8Q16d24B32^@36
v56@0:8d16Q24@32@?40@?48
B24@0:8^@16
B24@0:8B16B20
B24@0:8q16
v68@0:8Q16d24d32d40@48B56@?60
v24@0:8B16B20
@"CSAudioConverter"
@"<CSSpeechControllerDelegate>"
@"<CSSpeakerIdentificationDelegate>"
@"CSEndpointerProxy"
@"<CSAudioAlertProviding>"
@"<CSAudioMeterProviding>"
@"<CSAudioMetricProviding>"
@"CSSelectiveChannelAudioFileWriter"
@"CSSmartSiriVolumeController"
@"CSSpeechEndHostTimeEstimator"
@"CSLanguageDetector"
@"CSXPCClientFactory"
@"CSAudioPowerMeter"
@"CSStopRecordingOptions"
@"SOMediaNowPlayingObserver"
@"SOClockAlarmObserver"
@"SOClockTimerObserver"
@"CSVolumeMonitor"
@"CSAudioDeviceInfo"
@"CSAudioSessionController"
@"CSSACInfoMonitor"
@"CSRCHandlingXPCClient"
@"CSUncompressedAudioLogging"
@"<CSSSRXPCClientDelegate>"
@"CSAttSiriRequestContext"
@48@0:8q16Q24Q32@40
@40@0:8Q16Q24@32
@24@0:8q16
@40@0:8@16@24Q32
v56@0:8Q16@24@?32@?40@?48
@40@0:8@"NSObject<OS_dispatch_queue>"16@"AFAudioPlaybackRequest"24Q32
v40@0:8Q16@"AVAudioSession"24@?<v@?@"NSError">32
v56@0:8Q16@"AVAudioSession"24@?<v@?>32@?<v@?>40@?<v@?@"NSError">48
v28@0:8B16@?<v@?>20
@"AFAudioPlaybackRequest"16@0:8
@"AVPlayer"
@"AVPlayerItem"
@"AVAudioSession"
@"AFAudioPlaybackRequest"
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
v36@0:8@16B24@?28
v96@0:8@16@24@32@40Q48@56@64@72@80@?88
v24@0:8@"CSRemoteAssetManager"16
q24@0:8q16
v48@0:8@16@24B32B36@?40
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v32@0:8@"NSURL"16@?<v@?@"NSError">24
v36@0:8@"NSString"16B24@?<v@?@"NSDictionary"@"NSError">28
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?@"NSDictionary"@"NSError">32
v96@0:8@"NSString"16@"NSDictionary"24@"NSString"32@"NSString"40Q48@"NSArray"56@"NSString"64@"NSString"72@"NSArray"80@?<v@?@"NSArray"@"NSError">88
@"<NviAssetsProvider>"
@"NSMapTable"
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
@40@0:8@16@24^@32
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@32
@32@0:8@16d24
v28@0:8B16Q20
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStream"24@?<v@?B@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"40@0:8Q16Q24Q32
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"CSAudioDeviceInfo"16@0:8
@"NSDictionary"16@0:8
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B36@0:8@"NSURL"16q24B32
I24@0:8@16
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
I24@0:8@"NSString"16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
v40@0:8q16q24q32
v32@0:8q16q24
@"<CSStateMachineDelegate>"
v32@0:8i16@20B28
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@"CSVolumeMonitor"16f24
v28@0:8@"CSAutomaticVolumeEnabledMonitor"16B24
@28@0:8f16@20
@40@0:8Q16@24Q32
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
@36@0:8@16f24Q28
@32@0:8@16Q24
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
d20@0:8f16
v48@0:8Q16@24@32@?40
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
v40@0:8q16Q24@32
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@28@0:8@16I24
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"<CSVoiceTriggerAssetChangeDelegate>"
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
v32@0:8r^v16q24
v44@0:8@16B24@28@36
v28@0:8@"CSFirstUnlockMonitor"16B24
@64@0:8@16@24@32@40@48@56
@"CSVoiceTriggerAssetDownloadMonitor"
@"CSLanguageCodeUpdateMonitor"
@"CSFirstUnlockMonitor"
@"CSAssetManager"
@"CSTrialAssetManager"
v52@0:8@16@24B32@36@44
v36@0:8@16@24B32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24Q32
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v36@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStream"24B32
v24@0:8@"CSSiriClientBehaviorMonitor"16
@28@0:8Q16B24
@28@0:8@16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
@40@0:8q16@24@32
q32@0:8q16@24
q36@0:8@16B24@28
@44@0:8@16@24@32B40
q40@0:8@16@24@32
q32@0:8@16@24
q44@0:8@16@24B32q36
@"AFClientConfiguration"
@"AFExperimentContext"
@"AFSpeechRecordingAlertPolicy"
@"AFLanguageDetectionUserContext"
Q24@0:8@16
d24@0:8@16
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
B40@0:8Q16@24^@32
@"AVAudioPlayer"
v36@0:8B16@20d28
@"CSSiriAssertionMonitor"
@"NSData"
v68@0:8Q16d24d32d40@"NSString"48B56@?<v@?BB@"NSArray">60
v32@0:8Q16@?<v@?B>24
@"<CSSmartSiriVolumeControllerDelegate>"
@"CSSmartSiriVolumeClient"
v40@0:8@"CSKeywordAnalyzerNDEAPI"16@"CSKeywordAnalyzerNDEAPIResult"24Q32
@60@0:8@16@24Q32Q40@48B56
@"<CSPhraseNDEAPIScorerDelegate>"
@"CSShadowMicScoreCreator"
v44@0:8@16@24B32@?36
v72@0:8@16@24@32B40Q44@52B60@64
@80@0:8@16@24@32B40Q44@52B60@64@?72
@"<CSADCompanionServiceProvider>"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@44@0:8Q16Q24f32f36f40
@72@0:8d16Q24@32q40@48@56d64
v32@0:8@"CSMediaPlayingMonitor"16q24
@28@0:8f16@"CSAsset"20
v24@0:8@"CSAsset"16
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::default_delete<SmartSiriVolume>>="__ptr_"{__compressed_pair<SmartSiriVolume *, std::default_delete<SmartSiriVolume>>="__value_"^{SmartSiriVolume}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"NSUserDefaults"
v48@0:8@16@24@32^v40
@144@0:8B16B20B24q28@36@44@52@60I68I72@76d84d92d100Q108Q116@124B132q136
@28@0:8B16@20
@"<AFBluetoothDevice>"
@68@0:8Q16@24@32@40@48B56@60
@"CSVoiceTriggerFirstPassMetrics"
v72@0:8d16Q24@32d40Q48d56@64
@"OSDFeatures"
@"_EAREndpointer"
@"CSServerEndpointFeatures"
@"NSDate"
B32@0:8d16^@24
@"<CSRemoteRecordClientDelegate>"
v24@0:8@"<NviDataReceiver>"16
@"NviContext"
@32@0:8q16Q24
@"CSSiriMobileBluetoothDeviceDataSource"
v24@0:8@"CSAssetManager"16
v48@0:8@"NSString"16@"NSString"24@"NSURL"32@?<v@?@"NSString">40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
v80@0:8Q16Q24q32@40@48@56@64@?72
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v80@0:8Q16Q24q32@"NSString"40@"NSUUID"48@"NSArray"56@"NSArray"64@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">72
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
B32@0:8@16@?24
B20@0:8B16
v28@0:8@16i24
v28@0:8@"AFNotifyObserver"16i24
v40@0:8@"AFNotifyObserver"16Q24Q32
@"<CSAttSiriSessionStateDelegate>"
@"AFNotifyObserver"
Vv24@0:8@?16
Vv32@0:8@16@?24
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv32@0:8@"NSString"16@?<v@?@"NSString">24
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@44@0:8@16@24B32Q36
v48@0:8@16d24d32@?40
@48@0:8@16d24d32@?40
@"AFHeartBeat"
@28@0:8f16i20f24
v32@0:8r^v16Q24
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned char>, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned char> *, std::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char>>>="__value_"^v}}
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
@"CSSiriAudioRoute"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
@"CSActivationEvent"
v64@0:8@16Q24Q32@40@48@?56
v72@0:8Q16Q24@32@40@48@56@?64
@"CoreSpeechXPCFakeModelMonitor"
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16@0:8
v24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
v52@0:8@16@24Q32Q40i48
v52@0:8@"CSAudioPreprocessor"16@"NSData"24Q32Q40i48
@56@0:8Q16q24@32@40@48
@48@0:8Q16q24@32@40
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@"CSAudioRecordDeviceIndicator"
@"CSMicUsageReporter"
@"CSADPPreventStandbyAssertion"
@"CSPhoneCallStateMonitor"
@56@0:8Q16@24@32@40Q48
I24@0:8Q16
v32@0:8@"OSDAnalyzer"16@"OSDFeatures"24
v32@0:8@"OSDAnalyzer"16d24
@"OSDAnalyzer"
@48@0:8q16@24@32@40
v40@0:8@16d24@32
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
@"<CSEndpointAnalyzerImpl>"
v40@0:8^{BTAccessoryManagerImpl=}16i24^{BTDeviceImpl=}28i36
v24@0:8^{BTDeviceImpl=}16
^{BTAccessoryManagerImpl=}
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
v32@0:8q16@?24
@"AFBluetoothDeviceInfo"16@0:8
v24@0:8@?<v@?@"AFBluetoothDeviceInfo">16
v24@0:8@?<v@?@"AFBluetoothHeadphoneInEarDetectionState">16
v24@0:8@?<v@?q>16
v32@0:8q16@?<v@?@"NSError">24
v24@0:8@"<AFBluetoothDeviceObserver>"16
@"AFBluetoothDeviceInfo"
@"AFBluetoothHeadphoneInEarDetectionState"
v44@0:8B16@20@28@36
@"AFInstanceContext"
v40@0:8@"NSString"16@"NSString"24@?<v@?B@"NSError"@"NSUUID">32
v40@0:8@"NSURL"16@"NSUUID"24@?<v@?B@"NSError"QQ>32
v24@0:8@?<v@?@"NSMutableArray">16
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
@20@0:8f16
@"<CSSPGEndpointAnalyzerDelegate>"
@"EARCaesuraSilencePosteriorGenerator"
Vv20@0:8i16
Vv32@0:8@16i24i28
Vv32@0:8@"NSData"16i24i28
Vv24@0:8@?<v@?@"NSData">16
v24@0:8^{AudioStreamBasicDescription=dIIIIIIII}16
@"<CSSiriAcousticFingerprinterDelegate>"
@"NSSet"
v40@0:8@16@24d32
v40@0:8@"CSSiriAcousticFingerprinter"16@"NSData"24d32
v44@0:8@16@24f32Q36
v52@0:8@16@24f32Q36@44
v36@0:8@16d24B32
v36@0:8@16B24@28
v48@0:8@16@24q32Q40
v40@0:8@16q24d32
v40@0:8Q16Q24@?32
v32@0:8@"CSSpeechController"16@"NSData"24
v40@0:8@"CSSpeechController"16@"NSData"24Q32
v44@0:8@"CSSpeechController"16@"NSArray"24f32Q36
v52@0:8@"CSSpeechController"16@"NSArray"24f32Q36@"CSAudioDeviceInfo"44
v32@0:8@"CSSpeechController"16d24
v36@0:8@"CSSpeechController"16d24B32
v36@0:8@"CSSpeechController"16B24@"NSError"28
v44@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24B32@"NSError"36
v40@0:8@"CSSpeechController"16q24Q32
v48@0:8@"CSSpeechController"16@"CSAudioDeviceInfo"24q32Q40
v24@0:8@"CSSpeechController"16
v40@0:8@"CSSpeechController"16q24d32
v32@0:8@"CSSpeechController"16q24
v32@0:8@"CSSpeechController"16Q24
v40@0:8@"CSSpeechController"16q24@"NSError"32
v32@0:8@"CSSpeechController"16@"NSDictionary"24
v28@0:8@"CSSpeechController"16B24
v40@0:8Q16Q24@?<v@?@"NSError">32
v36@0:8@"NSString"16@"NSDictionary"24B32
v32@0:8{AFTimeRange=dd}16
v28@0:8d16B24
v36@0:8q16B24Q28
@56@0:8@"NSObject<OS_dispatch_queue>"16@"CSSpeechController"24@"CSAudioSessionController"32@"CSSiriAudioPlaybackService"40@"AFExperimentContext"48
v24@0:8@"<CSSiriSpeechCapturingDelegate>"16
v24@0:8@"AFSpeechRequestOptions"16
v24@0:8@?<v@?dd>16
v36@0:8@"SASResultCandidate"16B24@?<v@?BB@"NSArray">28
@20@0:8B16
v28@0:8q16B24
v28@0:8(?={?=SS}I)16Q20
i20@0:8(?={?=SS}I)16
v20@0:8(?={?=SS}I)16
v32@0:8q16@24
B40@0:8@16@?24^@32
@40@0:8q16q24B32B36
v64@0:8@16@24q32Q40q48@56
i28@0:8i16@20
v44@0:8@16q24Q32B40
v40@0:8q16q24@32
v32@0:8q16d24
v48@0:8@16d24d32@40
v32@0:8@?16d24
B40@0:8@16Q24@?32
@"<CSSiriSpeechCapturingDelegate>"
@"CSSpeechController"
@"CSSiriAudioPlaybackService"
@"<CSEndpointAnalyzer>"
@"CSSiriSpeechRecordingContext"
@"CSSiriAudioActivationInfo"
@"CSSiriAcousticFingerprinter"
@"AFWatchdogTimer"
@"CSEndpointerMetrics"
@"CSEndpointDelayReporter"
@"SASResultCandidate"
@"AFSpeechSynthesisRecord"
@"AFBluetoothWirelessSplitterSessionStateObserver"
v40@0:8@16q24q32
v40@0:8@"AFMemoryPressureObserver"16q24q32
v32@0:8@"AFAudioPlaybackRequest"16@?<v@?@"NSError">24
v40@0:8@"AFAudioPlaybackRequest"16Q24@?<v@?@"NSError">32
v28@0:8@"AFAudioPlaybackRequest"16B24
v56@0:8@16Q24@?32@?40@?48
@56@0:8@16Q24Q32Q40@48
@"<CSStartOfSpeechDetectorDelegate>"
@"<CSVoiceTriggerXPCClientDelegate>"
@60@0:8@16@24@32@40B48@52
@"CSVoiceTriggerAssetHandler"
@44@0:8@16B24@28@36
@52@0:8@16B24@28@36@44
v32@0:8@16B24f28
v28@0:8@"CSOpportuneSpeakListener"16B24
v32@0:8@"CSOpportuneSpeakListener"16B24f28
@"CSOpportuneSpeakListener"
v44@0:8@16B24Q28Q36
@"<CSAudioConverterDelegate>"
v48@0:8@16@24^@32^@40
v48@0:8Q16Q24Q32@?40
v48@0:8@16@24Q32@?40
@40@0:8d16d24d32
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v32@0:8Q16@"NSError"24
v32@0:8@"NSData"16Q24
v24@0:8@"CSRemoteRecordClient"16
v28@0:8@"CSUserSessionActiveMonitor"16B24
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
v40@0:8Q16B24@28B36
v60@0:8@16Q24@32Q40Q48i56
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"CSReusableBufferPool"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
v48@0:8@16@24@32@40
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
xeps
supo
supo
mcpl
33s@
333?
fff?
333?
333333
333333
333333
