_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
supportsSecureCoding
TB,R
bundleIdentifier
T@"NSString",C,N,V_bundleIdentifier
compatibilityVersion
T@"NSNumber",C,N,V_compatibilityVersion
contentVersion
T@"NSNumber",C,N,V_contentVersion
masteredVersion
T@"NSString",C,N,V_masteredVersion
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_promptCount
_sourceOfTTS
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
_audioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
v8@?0
character_count
voice_asset_key
voice_resource_asset_key
is_warm_start
tts_synthesis_latency
tts_total_latency
audio_queue_latency
audio_duration
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
prompt_count
source_of_tts
audio_output_route
is_server_tts
is_server_stream_tts
is_server_timeout
can_use_server_tts
is_server_tts_racing
is_cache_hit_from_disk
is_cache_hit_from_memory
synthesis_to_speech_time
wait_for_synthesis_to_finish_time
audio_start_timestamp_diffs
utterance
T@"NSString",C,V_utterance
voiceAssetKey
T@"NSString",C,V_voiceAssetKey
voiceResourceAssetKey
T@"NSString",C,V_voiceResourceAssetKey
audioOutputRoute
T@"NSString",C,V_audioOutputRoute
requestCreatedTimestamp
Tq,V_requestCreatedTimestamp
eagerRequestCreatedTimeStampDiffs
Tq,V_eagerRequestCreatedTimeStampDiffs
synthesisBeginTimestamp
Tq,V_synthesisBeginTimestamp
synthesisEndTimestamp
Tq,V_synthesisEndTimestamp
speechBeginTimestamp
Tq,V_speechBeginTimestamp
speechEndTimestamp
Tq,V_speechEndTimestamp
audioStartTimestampDiffs
Tq,V_audioStartTimestampDiffs
audioDuration
Td,V_audioDuration
isWarmStart
TB,V_isWarmStart
isServerTTS
TB,V_isServerTTS
isServerStreamTTS
TB,V_isServerStreamTTS
isServerTimeout
TB,V_isServerTimeout
isServerTTSRacing
TB,V_isServerTTSRacing
canUseServerTTS
TB,V_canUseServerTTS
promptCount
Tq,V_promptCount
sourceOfTTS
Tq,V_sourceOfTTS
isSpeechRequest
TB,V_isSpeechRequest
synthesisToSpeechTimeGap
Tq,V_synthesisToSpeechTimeGap
waitForSynthesisToFinishTimeDelay
Tq,V_waitForSynthesisToFinishTimeDelay
isCacheHitFromDisk
TB,V_isCacheHitFromDisk
isCacheHitFromMemory
TB,V_isCacheHitFromMemory
VSMobileAssetServiceErrorDomain
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
%@:%@:%@:%@:%@:%@
%@.tmp
/BuildRoot/Library/Caches/com.apple.xbs/Sources/VoiceServices_Sim/VoiceServices-541/Framework/VSMobileAssetsManager.m
<Unknown File>
negative size
voiceData
T@"VSVoiceAsset",&,V_voiceData
asset
T@"MAAsset",&,V_asset
builtInVoicePath
T@"NSString",&,V_builtInVoicePath
voicePath
T@"NSString",&,N,V_voicePath
com.apple.voiced.downloadQueue
v16@?0q8
com.apple.voiced.assetQueryQueue
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"VSVoiceResourceAsset"8@"VSVoiceResourceAsset"16
en-US
VSMobileAssetManager
Cleaning voice assets is disabled in internal setting.
v24@?0@"NSMutableArray"8q16
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
v20@?0d8f16
B24@?0@"MAAsset"8@"NSDictionary"16
v16@?0@"NSError"8
Unable to cancel download
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
/var/mobile/Library/VoiceServices/voices/%@_%@/AssetData
local_voice
q24@?0@"MAAsset"8@"MAAsset"16
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
AXAccessibilitySiriVoicesInUse
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
disableNewBackend
enableAudioDump
DisableCaching
DisableAssetCleaning
EnableLocalVoices
EnableHomePodSimulation
whisper
ServerTTSTimeout
defaultVolume
forceServerTTS
disableServerTTS
disableDeviceRacing
disableOsprey
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
isInternalBuild
TB,N,V_isInternalBuild
internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
internalBuild
TB,R,N,V_internalBuild
TB,N
disableCache
disableAssetCleaning
enableLocalVoices
enableHomePodSimulation
Tf,N
serverTTSTimeout
streamBufferDuration
T@"NSString",&,N
tts_languages
plist
tts_language_fallbacks
_VSServerConnection
com.apple.voiced
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
s5l8942x
s5l8947x
s7002
t8002
HardwarePlatform
DeviceClassNumber
InternalBuild
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
\mrk=%@=%@\
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
female
male
wordTimings
T@"NSDictionary",&,N,V_wordTimings
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
v32@?0@"NSData"8Q16^B24
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %d
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
%@_%@
lproj
DeviceSetup
could not create recognition instance
recognition already attempted or in progress
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
server_voices
legacy
premiumhigh
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@, CV: %@, MV: %@
_languages
_searchPathURL
%@:%@:%@
DisableGryphon
voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
rate
Tf,N,V_rate
pitch
Tf,N,V_pitch
volume
Tf,N,V_volume
vocalizerConfig
T@"NSDictionary",&,N,V_vocalizerConfig
languages
T@"NSArray",C,N,V_languages
resourceList
T@"NSArray",C,N,V_resourceList
resourceMimeTypes
T@"NSDictionary",C,N,V_resourceMimeTypes
searchPathURL
T@"NSURL",C,N,V_searchPathURL
_startTime
_textRange
startTime
Td,N,V_startTime
textRange
T{_NSRange=QQ},N,V_textRange
model <%@> class <%@>
com.apple.yn
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_clientBundleIdentifier
_text
_identifier
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@
clientBundleIdentifier
T@"NSString",C,N,V_clientBundleIdentifier
pcmDataSize
TQ,N,V_pcmDataSize
stopHandler
T@?,C,N,V_stopHandler
audioSessionID
TI,N,V_audioSessionID
audioData
T@"NSData",R,C,N,V_audioData
decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
playerStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
enqueue
TB,N,V_enqueue
text
T@"NSString",&,N,V_text
identifier
T@"NSString",&,N,V_identifier
TQ,N,V_requestCreatedTimestamp
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
text:'%@', language:%@, type:%@, gender:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, canUseServerTTS:%d, shouldCache:%d, contextInfo:%@
textForAttributes
attributes
_languageCode
_voiceName
_footprint
_useCustomVoice
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_maintainsInput
_audioSessionIDIsValid
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_audioQueueFlags
_resourceListURL
_resourceSearchPathURL
_contextInfo
_pointer
%@%@: %@
v32@?0@8@16^B24
attributedText
T@"NSAttributedString",C,N,V_attributedText
useCustomVoice
TB,N,V_useCustomVoice
audioSessionIDIsValid
TB,N,V_audioSessionIDIsValid
maintainsInput
TB,N,V_maintainsInput
audioQueueFlags
TI,N,V_audioQueueFlags
pauseHandler
T@?,C,N,V_pauseHandler
pointer
Tq,N,V_pointer
voiceName
T@"NSString",C,N,V_voiceName
T@"NSString",C,N,V_text
languageCode
T@"NSString",C,N,V_languageCode
footprint
Tq,N,V_footprint
voiceType
Tq,N,V_voiceType
gender
Tq,N,V_gender
outputPath
T@"NSURL",C,N,V_outputPath
shouldCache
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
contextInfo
T@"NSDictionary",C,N,V_contextInfo
disableCompactVoiceFallback
TB,N,V_disableCompactVoiceFallback
TB,N,V_forceServerTTS
TB,N,V_canUseServerTTS
resourceListURL
T@"NSURL",C,N,V_resourceListURL
resourceSearchPathURL
T@"NSURL",C,N,V_resourceSearchPathURL
%02x
%@ %ld
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
VoiceServicesErrorDomain
completion
T@?,C,N,V_completion
nil request
input text is not set
audio data is invalid
v16@?0@"VSVoiceResourceAsset"8
%@_%@_legacy.caf
%@_%@.caf
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
language_fallbacks
VSSpeechSynthesizer_%p@%@_%d
nil languageCode
not currently speaking
Missing text of this request
Either identifier or audio information must be non-nil
no active speech job
ar-sa
da-dk
it-it
ja-JP
nb-no
nl-nl
ru-ru
sv-se
%@:%d
v32@?0@"VSSpeechRequest"8@"VSInstrumentMetrics"16@"NSError"24
language
T@"NSString",C,N,V_language
durationRequests
T@"NSMutableDictionary",&,N,V_durationRequests
delegate
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
voice
T@"NSString",&,N,V_voice
autoDownloadedAssets
lastTTSRequestDate
deviceID
com.apple.AssistantServices
defaults
T@"NSUserDefaults",&,N,V_defaults
T@"NSDate",&,N
deviceUUID
T@"NSString",R,N
audioType
Tq,N,V_audioType
active
TB,N,V_active
keepAudioSessionActive
TB,N,V_keepAudioSessionActive
com.apple.voiceservices.xpcconnection
Connection invalidated during request
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
v12@?0B8
v16@?0@"NSArray"8
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
xpcConnection
T@"NSXPCConnection",&,N,V_xpcConnection
delegateWrapper
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
threadSafeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
request
T@"VSSpeechRequest",R,N
presynthesizedAudioRequest
T@"VSPresynthesizedAudioRequest",R,N
T@"VSSpeechRequest",&,N,V_request
concurrentSynthesisRequests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_presynthesizedAudioRequest
connection
T@"VSSpeechConnection",W,N,V_connection
compact
premium
beta
vocalizer
custom
gryphon
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
MasteredVersion
ContentVersion
T@"NSString",C,N,V_name
type
Tq,N,V_type
isInstalled
TB,N,V_isInstalled
isBuiltInVoice
TB,N,V_isBuiltInVoice
v16@?0@8
_endpoint
endpoint
T@"NSXPCListenerEndpoint",&,N,V_endpoint
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
listener
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
MbP?
@mcpl
@mcpl
@supo
@mcpl
|?5^
#MobileAsset migrate '%@', error: %lld
#MobileAsset migrate '%@', success
#MobileAsset Missing language in voice data:%@
#MobileAsset Can't find VoiceResources for %@
#MobileAsset Skip asset that is used by Accessibility, %@
#MobileAsset Skip currently in-use asset, %@
Cleaning unused voice assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#MobileAsset Purged asset: %@
#MobileAsset Unable to clean asset: %@, error:%d
#MobileAsset Search local voices for lang: %@, gender: %@
#MobileAsset Built in voice is requested.
#MobileAsset Search beta voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
#MobileAsset Search voice asset for lang: %{public}@, type: %@, gender: %@, footprint: %@
#MobileAsset Gryphon voice not found, search premium custom voice asset with same gender
#MobileAsset Search voice asset with same type but undefined gender
#MobileAsset Search voices in pre-installed location as fallback
#MobileAsset Search custom compact voice assets with same gender
#MobileAsset Search available vocalizer voice assets with same gender
#MobileAsset Fallback to built-in compact voice for lang: %@
#MobileAsset Selected %{public}@
#MobileAsset Unable to download voice that is not well defined: %@
#MobileAsset Enqueued downloading: %@
#MobileAsset Start querying: %@
#MobileAsset Can't download due to unfound asset: %@
#MobileAsset Asset is installed already: %@
#MobileAsset Enqueued download cancellation for: %@
#MobileAsset Removing voice: %@
#MobileAsset Start downloading: %@
#MobileAsset Asset not found for %@
#MobileAsset WARNING query '%@', error: %ld
#MobileAsset Catalog '%@' download error: %d
#MobileAsset err %d, unable to download asset %@
#MobileAsset Finished downloading asset %@
#MobileAsset Begin %@ download: %@
#MobileAsset Asset is already downloading: %@
#MobileAsset Asset is already installed: %@
#MobileAsset Asset is in an unknown state: %@
#MobileAsset purge asset: %@
#MobileAsset purge error: %d
#MobileAsset cancel downloading asset: %@
#MobileAsset Cancel download error: %d
#MobileAsset Purge cannot find asset: %@
#MobileAsset not removed because it is required by the OS: %@
#MobileAsset Couldn't found any built in voice for lang: %@
Failed to convert %ld recognition results
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for text: '%@'
Invalid target asbd: %@
Could not create Opus decoder: %{public}d
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%@', '%@'
Unable to find '%@' OOB string for key '%@', return en-US 
Unable to find OOB string for key '%@'
Out of word boundary: %ld - %ld
Enqueuing request: %@
Queue is now:
Unable to locate preview sample file for %@
#PrewarmRequest from client:%@, language: %@
Error #SpeechPauseRequest not currently speaking
#SynthesisRequest %p client:%@, %@
Start #SpeechRequest %p from client:%@, %@
#PresynthesizedAudioRequest: %@
Presynthesized audio request failed validation
Cache #PresynthesizedAudioRequest: %@
#SpeechStopRequest client:%@, boundary: %@, synchronously: %@
Error #SpeechStopRequest %@
#SpeechStopPresynthesizedAudioRequest client:%@, synchronously: %@
Error #PresynthesizedAudioStopRequest %@
#SpeechPauseRequest client:%@, boundary: %@, synchronously: %@
#SpeechResumeRequest client:%@
Error #SpeechResumeRequest no active speech job
#AudioPower Begin update
#AudioPower End update
#AutoDownloadRequest #MobileAsset, client: %@, language: %@, gender: %ld, type: %ld, footprint: %ld, name: %@
%@ is not TTS language, fallback to %@
Closing xpc connection %p
Error updateWithConnectionIdentifier: %@
Can't prewarm %@
Error at %s , %@ 
Error %@ asking for voices
%s, Error: %@
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
VSExtras
VSVoiceAssetSelection
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VoiceServices
VSUtilities
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSRecognitionRecognizeAction
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
NSCopying
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
Hash
VSAudioPreviewDelegate
AVAudioPlayerDelegate
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
encodeObject:forKey:
init
decodeObjectOfClass:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
.cxx_destruct
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
dictionaryMetrics
description
encodeInteger:forKey:
encodeInt64:forKey:
encodeDouble:forKey:
encodeBool:forKey:
decodeIntegerForKey:
decodeInt64ForKey:
decodeDoubleForKey:
decodeBoolForKey:
_clockFactor
length
numberWithUnsignedInteger:
numberWithBool:
ttsSynthesisLatency
numberWithDouble:
timeToSpeakLatency
audioQueueLatency
eagerRequestTimeGap
isSynthesisCached
numberWithInteger:
synthesisToSpeechTime
waitForSynthesisToFinishTime
numberWithLongLong:
dictionaryWithObjects:forKeys:count:
synthesisLatency
ttsTotalLatency
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
audioOutputRoute
setAudioOutputRoute:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimeStampDiffs
setEagerRequestCreatedTimeStampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
isServerTTS
setIsServerTTS:
isServerStreamTTS
setIsServerStreamTTS:
isServerTimeout
setIsServerTimeout:
isServerTTSRacing
setIsServerTTSRacing:
canUseServerTTS
setCanUseServerTTS:
promptCount
setPromptCount:
sourceOfTTS
setSourceOfTTS:
isSpeechRequest
setIsSpeechRequest:
synthesisToSpeechTimeGap
setSynthesisToSpeechTimeGap:
waitForSynthesisToFinishTimeDelay
setWaitForSynthesisToFinishTimeDelay:
isCacheHitFromDisk
setIsCacheHitFromDisk:
isCacheHitFromMemory
setIsCacheHitFromMemory:
_isWarmStart
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_canUseServerTTS
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_requestCreatedTimestamp
_eagerRequestCreatedTimeStampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_audioDuration
_promptCount
_sourceOfTTS
_synthesisToSpeechTimeGap
_waitForSynthesisToFinishTimeDelay
state
vs_isInstalled
voiceData
voiceKey
languages
firstObject
type
typeStringFromType:
gender
genderStringFromGender:
footprint
footprintStringFromFootprint:
name
stringWithFormat:
asset
getLocalUrl
path
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
attributes
objectForKeyedSubscript:
integerValue
stringWithUTF8String:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
descriptiveKey
voicePath
size
isInstalled
isDownloading
setVoiceData:
setAsset:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
_voiceData
_asset
_builtInVoicePath
_voicePath
migrateAssetIfNeededWithAssetType:
initWithType:
downloadCatalog:options:completion:
queryMetaData:
numberWithLong:
arrayWithObjects:count:
countByEnumeratingWithState:objects:count:
longValue
_getVoiceAssetsForType:voicename:language:gender:footprint:
voiceDataFromAsset:
addObject:
pickCorrectAssetFromLocalAssets:
legacyLocalVocalizerVoiceAssetForLanguage:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
setIsInstalled:
setIsBuiltInVoice:
genderFromString:
setGender:
_languagesFromAttributes:
setLanguages:
typeFromString:
setType:
setName:
footprintFromString:
setFootprint:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:
queryForVoiceResourceAsset:
_getResults:
voiceResourceFromAsset:
sortUsingComparator:
lastObject
initWithCapacity:
copy
bundleIdentifierForVoiceType:
addKeyValuePair:with:
addKeyValueArray:with:
selectVoiceResourceAssetForLanguage:
defaultVoiceType
defaultVoiceGender
defaultVoiceFootprint
sharedManager
amendVoiceWithDefaultSettings:
defaultInstance
autoDownloadedVoicesForClientID:
selectVoiceForLang:type:gender:footprint:
activeVoiceAssets
installedAssetsForType:voicename:language:gender:footprint:
assetType
containsObject:
valueForKey:
standardInstance
disableAssetCleaning
errorWithDomain:code:userInfo:
inactiveVoiceAssets
purge:
resetCache
dictionary
setObject:forKeyedSubscript:
_purgeAsset:
predicateWithBlock:
filterUsingPredicate:
installedVoiceResources
enableLocalVoices
_localVoiceForLanguage:gender:
_builtInVoiceForLanguage:
useBetaVoice
_nonCacheVoiceSelectionForLanguage:type:gender:footprint:
isAudioAccessory
selectPreinstalledVoiceForLanguage:gender:
downloadVoiceAsset:discretionary:useBattery:progressUpdateHandler:
isVoiceAssetWellDefined:
setAllowsCellularAccess:
setDiscretionary:
setRequiresPowerPluggedIn:
assetQueryQueue
downloadCatalog:options:
filteredArrayUsingPredicate:
getLatestAssetFromArray:
_downloadAsset:options:progress:completion:
cancelDownload:
count
results
queryMetaDataSync
queryForType:voicename:gender:footprint:
startCatalogDownload:options:then:
isStalled
expectedTimeRemaining
totalExpected
totalWritten
discretionary
attachProgressCallBack:
startDownload:then:
arrayWithCapacity:
getLocalFileUrl
setSearchPathURL:
sortedArrayUsingComparator:
populateVoiceData:fromAsset:
voiceTypeForBundleIdentifier:
migrateAssets
cleanUnusedVoiceAssets
cleanOldVoiceResources
downloadVoiceAsset:useBattery:progressUpdateHandler:
downloadVoiceAsset:discretionary:progressUpdateHandler:
cancelDownload:completion:
removeVoiceAsset:completion:
downloadVoiceResource:discretionary:completion:
removeVoiceResource:completion:
voiceAssetWithName:localOnly:outError:
purgeAsset:
setAssetQueryQueue:
_downloadQueue
_assetQueryQueue
initWithSuiteName:
addObserver:forKeyPath:options:context:
defaultCenter
removeObserver:
dealloc
willChangeValueForKey:
didChangeValueForKey:
objectForKey:
boolForKey:
setBool:forKey:
synchronize
floatForKey:
setFloat:forKey:
stringForKey:
setObject:forKey:
observeValueForKeyPath:ofObject:change:context:
enableAudioDump
setEnableAudioDump:
disableCache
setDisableCache:
setDisableAssetCleaning:
setEnableLocalVoices:
enableHomePodSimulation
setEnableHomePodSimulation:
whisper
setWhisper:
serverTTSTimeout
setServerTTSTimeout:
defaultVolume
setDefaultVolume:
forceServerTTS
setForceServerTTS:
disableServerTTS
setDisableServerTTS:
disableDeviceRacing
setDisableDeviceRacing:
disableOsprey
setDisableOsprey:
disableOspreyStreaming
setDisableOspreyStreaming:
disableNewBackend
setDisableNewBackend:
streamBufferDuration
setStreamBufferDuration:
setUseBetaVoice:
ospreyEndpointURL
setOspreyEndpointURL:
internalBuild
isInternalBuild
setIsInternalBuild:
internalDefaults
setInternalDefaults:
_internalBuild
_isInternalBuild
_internalDefaults
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
stringByReplacingOccurrencesOfString:withString:
availableLanguages
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
resourceValuesForKeys:error:
fileURLWithPath:
removeItemAtURL:error:
getResourceValue:forKey:error:
compare:
subarrayWithRange:
timeIntervalSinceDate:
directorySize:
removeDirectory:
cleanDirectory:withLRULimit:
cleanDirectory:withDateOlderThan:
legacyPlatforms
hardwarePlatform
isWatch
isSeedBuild
initWithFormat:
initWithContentsOfFile:
removeObjectForKey:
stringWithString:
rangeOfString:options:range:
stringByAppendingString:
replaceCharactersInRange:withString:
string
appendString:
vs_markerStringForContext:
regularExpressionWithPattern:options:error:
matchesInString:options:range:
characterAtIndex:
whitespaceCharacterSet
characterIsMember:
punctuationCharacterSet
rangeAtIndex:
_vs_countPhoneticSyllables_lhp:
numberOfRanges
hasPrefix:
containsString:
_vs_countPhoneticSyllables_xsampa:
stringByReplacingMatchesInString:options:range:withTemplate:
addCharactersInRange:
vs_isCJKCharacter:
vs_textifyEmojiWithLanguage:
vs_substituteAudioWithLocalPath
vs_insertContextInfo:
vs_measurePauses
vs_countPhoneticSyllables
vs_removePhonetics
vs_removeSpeechTags
vs_hasCJKCharacter
stringByStandardizingPath
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
allKeys
allValues
doubleValue
setTextRange:
setStartTime:
localizations
preferredLocalizationsFromArray:forPreferences:
pathForResource:ofType:inDirectory:forLocalization:
timingPlistForLanguage:
timingInfosFrom:withText:
estimatedTTSWordTimingForText:withLanguage:withGender:
wordTimings
setWordTimings:
_wordTimings
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
alloc
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
reset
_init
cancel
setDelegate:
setActive:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
postNotificationName:object:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
removeAllObjects
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
startSpeakingAttributedString:toURL:withLanguageCode:error:
startSpeakingString:withLanguageCode:error:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeaking:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_synthesizer
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
beginChunkDecoderForStreamDescription:
decodeChunk:outError:
appendData:
enumerateObjectsUsingBlock:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
bytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_asbd
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
uppercaseString
localizedStringForKey:value:table:
localizedOOBStringForKey:language:gender:
arrayWithObject:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
addObjectsFromArray:
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
componentsJoinedByString:
decodeObjectOfClasses:forKey:
vocalizerConfig
floatValue
searchPathURL
URLByAppendingPathComponent:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
voiceConfig
defaultVoice
rate
pitch
volume
resourceMimeTypes
resourceList
serverVoiceNameForGender:
defaultTypeString
defaultFootprintString
setVoiceConfig:
setRate:
setPitch:
setVolume:
setVocalizerConfig:
setResourceList:
setResourceMimeTypes:
_rate
_pitch
_volume
_languages
_searchPathURL
_voiceConfig
_vocalizerConfig
_resourceList
_resourceMimeTypes
rangeValue
valueWithRange:
whitespaceAndNewlineCharacterSet
textRange
UTF8String
lengthOfBytesUsingEncoding:
startTime
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
wordTimingInfoFrom:timestamps:
utf16TimingInfoWithUTF8Range:withText:
_startTime
_textRange
stopListening
lock
_spokenLanguageChanged:
addObserver:selector:name:object:
unlock
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
dateWithTimeIntervalSinceNow:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
_initShared
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
initFileURLWithPath:
pathForResource:ofType:inDirectory:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:
decodeInt32ForKey:
numberWithUnsignedLongLong:
copyWithZone:
initWithAudioData:playerStreamDescription:
initWithIdentifier:
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
text
setText:
identifier
setIdentifier:
clientBundleIdentifier
setClientBundleIdentifier:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_text
_identifier
_clientBundleIdentifier
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
initWithDictionaryRepresentation:
matchedString:forTokenInRange:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
contextInfoString
languageCode
contextInfo
isEqualToDictionary:
voiceType
allocWithZone:
setLanguageCode:
setVoiceType:
outputPath
setOutputPath:
shouldCache
setShouldCache:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
decodePropertyListForKey:
appendFormat:
enumerateKeysAndObjectsUsingBlock:
isSimilarTo:
attributedText
setAttributedText:
useCustomVoice
setUseCustomVoice:
audioSessionIDIsValid
setAudioSessionIDIsValid:
maintainsInput
setMaintainsInput:
audioQueueFlags
setAudioQueueFlags:
pauseHandler
setPauseHandler:
pointer
setPointer:
voiceName
setVoiceName:
_shouldCache
_disableCompactVoiceFallback
_forceServerTTS
_useCustomVoice
_audioSessionIDIsValid
_maintainsInput
_audioQueueFlags
_languageCode
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_attributedText
_pauseHandler
_pointer
_voiceName
stringWithCapacity:
stringByAppendingFormat:
md5hash
preinstalledAudioHashForLanguage:gender:
completion
audioPlayerDidFinishPlaying:successfully:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerBeginInterruption:
audioPlayerEndInterruption:withOptions:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:
setCompletion:
_completion
errorWithReason:
getVoiceResourceForLanguage:reply:
isPlaying
stop
category
setActive:withOptions:error:
setCategory:error:
initWithContentsOfURL:error:
setActive:error:
play
mainBundle
preferredLocalizations
processInfo
processName
processIdentifier
opaqueSessionID
prewarmIfNeededWithRequest:
queryPhaticCapabilityWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizerDidPauseSpeaking:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
presynthesizedAudioRequest
isSystemSpeaking
stopPresynthesizedAudioRequest
request
stopCurrentSpeechRequestAtMark:
pauseCurrentSpeechRequestAtMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
_stopSpeakingPresynthesizedAudioRequest:synchronously:error:
startSpeechRequest:
validatePresynthesizedAudioRequest:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
isSystemSpeakingOnBehalfOfCurrentConnection
continueCurrentSpeechRequest
decimalDigitCharacterSet
numberWithInt:
characterClassCountForUtterance:language:
objectAtIndexedSubscript:
unsignedIntegerValue
estimateDurationOfRequest:
durationRequests
valueWithNonretainedObject:
startSynthesizingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
setLogToFile:
getLogToFile:
language
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
startSpeakingRequest:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:synchronously:error:
availableVoicesForLanguageCode:
availableLanguageCodes
availableFootprintsForVoice:languageCode:
getTTSServerVoicesWithFilter:reply:
forwardStreamObject:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoiceAssets:
getLocalVoiceResources:
setAutoDownloadedVoiceAssets:withClientID:
getAutoDownloadedVoiceAssetsWithClientID:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
playVoicePreviewForLanguageCode:gender:
availableVoices
getAllVoiceAssets:
getVoiceInfoForLanguageCode:footprint:gender:custom:reply:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
queryPhaticCapability:
startSpeakingPresynthesizedAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
isSpeaking
speechString
minimumRate
maximumRate
stopSpeakingRequest:atNextBoundary:synchronously:error:
estimateDurationOfRequest:completion:
setMaintainPersistentConnection:
setMaintainInactivePersistentConnection:
prewarmIfNeeded
startSpeakingString:request:error:
startSpeakingString:toURL:request:error:
startSpeakingString:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingRequest:withError:
useSharedAudioSession:
useSpecificAudioSession:
useAudioQueueFlags:
startSynthesizingString:toFileURL:shouldCache:request:
startSpeakingString:error:
startSpeakingString:toURL:error:
continueSpeakingWithError:
delegate
voice
setVoice:
setLanguage:
setDurationRequests:
_queue
_callbackQueue
_xpcConnection
_synthesizerFlags
_voice
_language
_durationRequests
migrateDefaults
arrayForKey:
dictionaryForKey:
dictionaryRepresentation
UUID
UUIDString
setAutoDownloadedVoices:withClientID:
setLastTTSRequestDate:
lastTTSRequestDate
deviceUUID
defaults
setDefaults:
_defaults
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
queryPhaticCapabilityWithRequest:reply:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesReply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setExportedInterface:
delegateWrapper
setExportedObject:
xpcConnection
remoteObjectProxyWithErrorHandler:
concurrentSynthesisRequests
setXpcConnection:
setRequest:
setPresynthesizedAudioRequest:
setConcurrentSynthesisRequests:
_remoteObjectWithErrorHandler:
synchronousRemoteObjectProxyWithErrorHandler:
_remoteObject
localizedDescription
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
connection
_request
_concurrentSynthesisRequests
_presynthesizedAudioRequest
_connection
lowercaseString
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_name
_type
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
_block
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v16@0:8
@16@0:8
@"NSString"
@"NSNumber"
d16@0:8
q16@0:8
v24@0:8q16
v24@0:8d16
v20@0:8B16
Q16@0:8
@"VSVoiceAsset"
@"MAAsset"
@48@0:8q16@24q32q40
@56@0:8q16@24@32q40q48
@48@0:8@16q24q32q40
@24@0:8q16
q24@0:8@16
B24@0:8@16
@32@0:8@16q24
v36@0:8@16B24@?28
v40@0:8@16B24B28@?32
v32@0:8@16@?24
@36@0:8@16B24^@28
@32@0:8@16@24
v40@0:8@16@24@?32
v48@0:8@16@24@?32@?40
v32@0:8@16@24
@"NSObject<OS_dispatch_queue>"
v48@0:8@16@24@32^v40
f16@0:8
v20@0:8f16
@"NSUserDefaults"
Q24@0:8@16
v32@0:8@16Q24
B20@0:8S16
@40@0:8@16@24q32
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
@40@0:8@16@24@32
B40@0:8^@16^@24q32
B20@0:8B16
@20@0:8B16
v40@0:8@16@24@32
v24@0:8Q16
^{__CFDictionary=}16@0:8
v36@0:8@16B24@28
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@32@0:8@16^@24
^{OpaqueAudioConverter=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSLock"
@"NSMutableArray"
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@28@0:8@16B24
@24@0:8^{_NSZone=}16
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
@?16@0:8
v24@0:8@?16
@"NSData"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
v28@0:8@16B24
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
B32@0:8@16q24
v52@0:8@16q24q32B40@?44
v56@0:8@16q24q32q40@?48
v52@0:8@16@24B32@36@44
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
B36@0:8@16B24^@28
B44@0:8@16q24B32^@36
B36@0:8q16B24^@28
B28@0:8B16^@20
B32@0:8@16^@24
d24@0:8@16
B48@0:8@16@24@32^@40
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B40@0:8@16q24^@32
B32@0:8q16^@24
B64@0:8@16@24@32@40^@48^@56
@44@0:8@16@24B32^@36
B40@0:8@16@24^@32
B24@0:8^@16
@"VSSpeechConnection"
{?="delegateStart"b1"delegateFinish"b1"delegateFinishWithPhonemesSpoken"b1"delegatePause"b1"delegateContinue"b1"delegateWillSpeak"b1"delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"willUseInput"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv24@0:8@16
Vv32@0:8@16@?24
Vv24@0:8q16
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv32@0:8@16@24
Vv56@0:8@16q24q32q40@?48
Vv20@0:8B16
Vv24@0:8@"NSString"16
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv56@0:8@"NSString"16q24q32q40@?<v@?@"VSVoiceAsset">48
Vv32@0:8@"VSVoiceAsset"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv40@0:8q16{_NSRange=QQ}24
Vv36@0:8B16@20@28
Vv40@0:8@16@24@32
Vv28@0:8B16@20
Vv36@0:8B16@"NSString"20@"NSError"28
Vv24@0:8@"VSInstrumentMetrics"16
Vv24@0:8@"NSArray"16
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv28@0:8B16@"NSError"20
Vv32@0:8@"VSInstrumentMetrics"16@"NSError"24
@24@0:8@?16
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
