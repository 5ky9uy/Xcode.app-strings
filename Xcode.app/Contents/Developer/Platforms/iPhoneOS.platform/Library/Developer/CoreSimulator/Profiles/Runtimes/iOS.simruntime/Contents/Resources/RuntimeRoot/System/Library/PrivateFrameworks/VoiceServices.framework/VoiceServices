_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_isPurgeable
_storage
v8@?0
audio_duration
audio_output_route
audio_queue_latency
can_use_server_tts
character_count
client_bundle_identifier
error_code
experiment_identifier
is_server_stream_tts
is_server_timeout
is_server_tts_racing
is_speech_request
is_synthesis_cached
is_warm_start
neural_alignment_stall
neural_audio_click
neural_fallback
prompt_count
real_time_factor
server_first_packet_latency
server_last_packet_latency
server_streamed_audio_duration
source_of_tts
synthesis_to_speech_time_gap
tts_and_playback_total_latency
tts_synthesis_latency
tts_total_latency
voice_asset_key
voice_resource_asset_key
  "%@": %@,
  "%@": "%@",
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_promptCount
_sourceOfTTS
_errorCode
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_audioDuration
_serverStreamedAudioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
is_server_tts
osprey_round_trip
osprey_streaming
ace_round_trip
ace_inline_streaming
device
inline_tts
audio_request
device_cached_synthesis
unknown
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.notification.voice-purge
VSMobileAssetServiceErrorDomain
VSTrialServiceErrorDomain
MobileAssetProperties
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
/private/var/mobile/Library/VoiceServices/voices/
%@.tmp
VSMobileAssetsManager.m
negative size
v16@?0q8
com.apple.voiced.assetQueryQueue
%@_%@_%@_%@_%@
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"MAAsset"8@"MAAsset"16
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
VSMobileAssetsManager
Cleaning voice assets is disabled in internal setting.
v24@?0@"NSMutableArray"8q16
%@_%@
B24@?0@"VSTrialVoice"8@"NSDictionary"16
q24@?0@"VSTrialVoice"8@"VSTrialVoice"16
v20@?0d8f16
v12@?0f8
v16@?0@"NSError"8
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
Info.plist
CFBundleIdentifier
@"NSString"8@?0
local_voice
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
enableTrial
enableAudioDump
logSensitiveText
DisableCaching
DisableAssetCleaning
AllowAnyAssetSubscription
EnableLocalVoices
whisper
ServerTTSTimeout
DeviceTTSWaitTime
defaultVolume
forceServerTTS
disableServerTTS
disableInlineStreamTTS
disableDeviceRacing
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
simulateNetworkStall
disableDeviceNeuralTTS
useSSMLInput
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
defaultToNonDiscretionaryDownloads
tts_languages
plist
tts_language_fallbacks
en-US
_VSServerConnection
com.apple.voiced
%@:%@:%@
allowing_cellular
download_size
download_duration
download_progress
setup_duration
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
VoiceServices
lowPowerDeviceNeural
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
DeviceClassNumber
InternalBuild
HardwarePlatform
t8030
_languageCode
_voiceName
_previewType
VSVocalizerEngine
path
mimeType
TTSSynthesizer::load_voice_resource
unknown path
unknown mime-type
i12@?0i8
tts.neural.use_fallback
tts.metrics.alignment_stall
tts.metrics.audio_has_click
tts.feature.phonemes
TTSSynthesizer::synthesize_text_with_markers_async
application/edct-bin-dictionary
application/x-vocalizer-rettt+text
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/
\mrk=%@=%@\
\toi=lhp\
\toi=orth\
\tn=normal\
\tn=
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
<speak>
speak
<phoneme alphabet="lhp" ph="
phoneme
"></phoneme>
SSML error
unbalanced phoneme tag
say-as
</say-as>
unbalanced say-as tag
Error in tn override tag, ignore
<say-as interpret-as="%@">
</%@>
NSString *soft_AXSpeechTransformTextWithLanguage(NSString *__strong, AXSpeechTransformOptions, NSString * _Nullable __strong, NSMutableArray * _Nullable __strong)
NSString+VSSpeechService.m
AXSpeechTransformTextWithLanguage
void *AccessibilityUtilitiesLibrary(void)
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/Contents/MacOS/AccessibilityUtilities
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
/System/Library/PrivateFrameworks/VoiceServices.framework/
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
_clientID
_accessoryID
_voice
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
@"AVAudioBuffer"20@?0I8^q12
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %@
<private>
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_NETWORK_STALL
_MALE
strings
%@_%d
Interstitials
DeviceSetup
VSSpeechLangCharset
CharacterBinaryMaps
could not create recognition instance
recognition already attempted or in progress
com.apple.voiceservices.metrics
com.apple.voiceservices.download
@"NSDictionary"8@?0
com.apple.AssistantServices
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@_CV%@
_languages
_searchPathURL
_startTime
_textRange
model <%@> class <%@>
com.apple.yn
0x%x
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_text
_identifier
_siriRequestId
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@, accessoryID:%@
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
textForAttributes
attributes
startTime: %llu, language:%@, name:%@, gender:%@, type:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, shouldWhisper:%d, canUseServerTTS:%d, disableCompactFallback:%d, disableDeviceRacing:%d, shouldWaitCurrentSpeaking:%d, shouldCache:%d, contextInfo:%@, customResourceURLs:%@, session:%d, accessoryID:%@, text:'%@'
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_shouldWhisper
_shouldCache
_disableCompactVoiceFallback
_disableDeviceRacing
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_shouldWaitCurrentSpeaking
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_contextInfo
_pointer
%@%@: %@
v32@?0@8@16^B24
VSMappedData%p
%02x
 %@ %@
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
VoiceServicesErrorDomain
com.apple.voiceservices.notification.synthesis-done
Request is nil.
language is not set.
Request has been used before. Please make a new copy of it.
text is not set.
Audio request has invalid audio data.
Missing text of inline streaming request.
Invalid audio request. Audio is invalid.
Audio caching request must be either inline streaming or audio request.
v20@?0d8B16
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
com.apple.assistantd
VSSpeechSynthesizer_%p@%@_%d
stop presynthesized request timeout
stop request timeout
pause request timeout
ar-SA
da-DK
it-IT
ja-JP
nb-NO
nl-NL
ru-RU
sv-SE
%@:%d
generic
-[VSSpeechSynthesizer estimateDurationOfRequest:completion:]_block_invoke
v24@?0d8@"NSError"16
-[VSSpeechSynthesizer connection:speechRequest:didStopAtEnd:phonemesSpoken:error:]_block_invoke
-[VSSpeechSynthesizer connection:synthesisRequest:didFinishWithInstrumentMetrics:error:]_block_invoke
@"NSArray"16@?0@"NSArray"8
%@:%@:%@:%@
Auto Downloaded Assets
autoDownloadedAssets
subscribedAssets
OOBTriggeredDate
OOBNeedsToBeMeasured
lastTTSRequestDate
deviceID
com.apple.voiceservices.xpcconnection
-[VSSpeechConnection _remoteObjectSync]_block_invoke
v32@?0@"VSSpeechRequest"8Q16^B24
v32@?0@"VSPresynthesizedAudioRequest"8Q16^B24
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
v12@?0B8
v16@?0@"NSArray"8
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
audioData
packetDescription
packetCount
asbd
undefined
compact
premium
premiumhigh
beta
male
female
neutral
vocalizer
custom
gryphon
neural
MasteredVersion
ContentVersion
builtin
%@:%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, downloadSize: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
B24@?0@8@"NSDictionary"16
v16@?0@8
_endpoint
SIRI_TEXT_TO_SPEECH
com.apple.siri.tts
com.apple.siri.tts.voice
com.apple.siri.tts.resource
.version
assetSize
ttsCompatibilityVersion
ttsContentVersion
gender
%@.voice.%@.%@.%@.%@
Voice factor name: %@
%@.resource.%@
VSTrialService.downloadQueue
v16@?0@"<TRINamespaceUpdateProtocol>"8
immediateDownloadForNamespaceNames cannot use discretionary download option.
v16@?0Q8
v20@?0B8@"NSError"12
mcpl
#<NSt3__110__function6__funcIU8__strongU13block_pointerFiN14TTSSynthesizer15CallbackMessageEENS_9allocatorIS6_EES4_EE
NSt3__110__function6__baseIFiN14TTSSynthesizer15CallbackMessageEEEE
U13block_pointerFiN14TTSSynthesizer15CallbackMessageEE
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3
MbP?
@mcpl
@mcpl
@supo
@supo
@mcpl
ASAttributeCompatibilityVersion should be NSNumber, got NSString for %@
CV: %@
Compatibility: %@
#MobileAsset migrate '%@', error: %@
#MobileAsset migrate '%@', success
#MobileAsset Ignore cached voice selection for voice query key %@ since it is not installed anymore.
#MobileAsset Ignore neural voice due to thermal critical condition.
#MobileAsset Found cached voice selection %@ for voice query key %@
#MobileAsset Ignore neural voices since device neural TTS is disabled.
#MobileAsset Selected %{public}@ and will cache it for %{public}@
Purging corrupted VoiceResource '%{public}@', error: %{public}@
#MobileAsset Found cached voice resource %@ for %{public}@
#MobileAsset Cached voice resource is corrupted %@
#MobileAsset Unable to find asset for VoiceResources %{public}@
#MobileAsset Found voice resource %@ for %{public}@
#MobileAsset current in-use asset, %@
#MobileAsset ignore VoiceOver asset, %@
#Trial current in-use asset, %@
Cleaning unused assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#Trial Search voice asset for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no suitable installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial Found suitable voice: %{public}@
Parameter language can't be nil for voice selection
Searching voice asset for lang: %{public}@, name: %{public}@, type: %{public0}@, gender: %{public}@, footprint: %{public}@
Search local voices for lang: %{public}@, name: %{public}@
Built-in voice is requested.
Search voices in Trial
Search voices in MobileAsset
Search voices in pre-installed location as fallback
Fallback to custom compact voice
Fallback to built-in compact voice
Selected voice %{public}@
#Trial Found local voice, skip downloading. Target voice: %@
#Trial Found local MobileAsset voice with same or higher version, skip downloading. Target voice: %@
Language must be provided for voice download.
#Trial Enqueued downloading: %{public}@
#Trial Unable to download namespace to download voice: %@, error: %@
#Trial Unable to find suitable voice to download for voice criteria: %@
Target voice to download: %@
#Trial Removing voice: %@
#Trial Unable to remove voice %@, error: %@
#Trial Removed voice: %@
#Trial Cancelling voice download: %{public}@
Removing voice: %{public}@
Asset not removed because it is not present: %@
#Trial Cannot find any Trial resource, skip downloading. Target resource: %@
#Trial Found local resource, skip downloading. Target resource: %@
#Trial No MobileAsset resource found, will download Trial resource. Target resource: %@
#Trial Found same or newer resource in MobileAsset, skip downloading. Target resource: %@
#Trial Enqueue downloading resource: %@
#Trial Error downloading resource: %@, error: %@
#Trial Start downloading for: %@
#MobileAsset ERROR query '%@', timeout after 1 sec
#MobileAsset WARNING query '%@', error: %@
#MobileAsset Catalog '%@' download error: %@
#MobileAsset err %@, unable to download asset %{public}@
#MobileAsset Finished downloading asset %{public}@
#MobileAsset Begin %@ download, allowing cellular %{BOOL}d: %@
#MobileAsset Asset is already downloading: %{public}@
#MobileAsset download skipped, asset is already installed: %{public}@
#MobileAsset download skipped, asset is in an unknown state: %{public}@
#MobileAsset purge asset: %{public}@
#MobileAsset purge error: %@
#MobileAsset cancel downloading asset: %{public}@
#MobileAsset Cancel download error: %@
#MobileAsset Purge cannot find asset: %{public}@
#MobileAsset not removed because it is required by the OS: %{public}@
Ignoring all neural voices due to disableDeviceNeuralTTS
Ignoring neural voice %@. Current states as H12 platform: %{BOOL}d, thermal state:%d, low power enabled:%{BOOL}d
#MobileAsset Couldn't find any built-in voice for language: %{public}@
Unable to query local voice directory, %@
Failed to convert %ld recognition results
process is not running as user Mobile: it won't share the same UserDefaults as voiced
No cache directory from which to get the size: %@
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
Exception: %s
voice path '%@', resource path '%@'
%d files under voice path:
- %@
Failed to initialize synthesizer due to missing voice path.
Initializing engine with voice path: %@
Failed to initialize synthesizer: %s
Failed to initialize synthesizer: %zu
Error setPitch 0x%zx
Error setRate 0x%zx
Error setVolume 0x%zx
Unable to load resource '%@'
Url doesn't conform to RFC 1808 '%@'
Loading resource: %@, mime-type: %@
Unable to find mime-type for '%@'
Unknown voice resource handle to unload: %@
VSSpeechEngine %p started synthesis.
VSSpeechEngine %p finished synthesis.
Engine preheating latency: %.3f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %{public}@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for voice '%@', text: '%@'
converter.maximumOutputPacketSize is 0. Falling back to maximumPacketSize 1024. Converter is %@
AVAudioConverter.maximumOutputPacketSize is 0.
Invalid target asbd: %@
Could not create Opus decoder: %{public}@
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%{public}@'
Unable to find '%{public}@' localized string for key '%@', return empty string
Searching predefined string for '%@' in '%{public}@'
Unable to find '%{public}@' predefined string for key '%@', return default en-US string
Unable to find '%{public}@' predefined string for key '%@', return empty string
CoreAnalytics eventName:%@ not sent. Event name must not be in current config
Successfully reportEvent with domain '%@'
OOB subscription completion observed with %@ %@
Unable to load plist at '%{public}@', error: %{public}@
Unable to read voice_configs.plist
voice_configs.plist does not have key '_voices'
You're using a deprecated method [VSVoiceResourceAsset defaultVoiceType]; use `VSSpeechVoiceDataTypeUndefined` or `[VSVoiceResourceAsset defaultVoiceNameForGender:]` instead
You're using a deprecated method [VSVoiceResourceAsset defaultVoice]; use `defaultVoiceGender` instead
Out of word boundary: %ld is greater than %ld
Enqueuing request: %@
Queue is now:
Dispatching open URL: %@
Open URL failed: %@
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file, errno: %d, error: %s
%{public}@ is not TTS language, VSSpeechSynthesizer fallback to %{public}@
Invalid #PrewarmRequest: %@, error: %@
#PrewarmRequest %llu from client:%@, request: %@
Stop #SpeechPresynthesizedAudioRequest %llu from client:%@, synchronously: %{BOOL}d
Stop #SpeechPresynthesizedAudioRequest from client:%{public}@ was ignored, no request to stop
Stop #SpeechRequest from client:%{public}@ was ignored, no request to stop
Stop #SpeechRequest %llu from client:%{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest %llu from client:%@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest from client:%{public}@ was ignored, no request to pause
Invalid #SynthesisRequest: %@, error: %@
Start #SynthesisRequest %llu from client:%@, %@
Invalid #SpeechRequest: %@, error: %@
Start #SpeechRequest %llu from client:%@, %{public}@
Invalid #PresynthesizedAudioRequest: %@, error: %@
Start #PresynthesizedAudioRequest %llu: %@
Invalid #AudioCachingRequest: %@, error: %@
Cache #PresynthesizedAudioRequest %llu: %@
Cancel #SpeechRequest from client:%{public}@ was ignored, no request to stop
Cancel #SpeechRequest %llu from client:%{public}@
Cancel #PresynthesizedAudioRequest from client:%{public}@ was ignored, no request to stop
Cancel #PresynthesizedAudioRequest %llu from client:%{public}@
Error Stop #SpeechRequest %@
Error Stop #PresynthesizedAudioRequest %@
Resume #SpeechRequest %llu from client:%@
Resume #SpeechRequest from client:%{public}@ was ignored, no request to resume
#RoughEstimateDuration Request utterance: %@
#RoughEstimateDuration calculated duration: %.2f, using %@ locale, for text: %@
#EstimateDuration Request text: %@
Error %s, %@
#EstimateDuration Received duration: %.2f, for text: %@
%s, callback received in framework. %@
Current xpc connection %@ does not match %@
Notify daemon crash from: %@
#AudioPower Begin update
#AudioPower End update
#VoiceSubscription, client: %{public}@, accessory: %@, requested voices: %@
#VoiceSubscription, client: %{public}@, accessory: %@, deduped voices: %@
Request to download with cellular, client: %{public}@, language: %{public}@, gender: %ld, type: %ld, footprint: %ld, name: %{public}@
%{public}@ is not TTS language, fallback to %{public}@
clearing auto-downloaded voice preferences for accessory %@
Closing xpc connection %p
%s, error: %@
Error updateWithConnectionIdentifier: %@
Can't prewarm: %@
Error at %s , %@ 
Error estimateDurationWithRequest:reply: %@
Error %@ asking for voices
Error %@ asking for voice footprints
Can't start VoicePreview: %@
Can't get subscribed voice assets: %@
Can't get all subscribed voice assets: %@
Can't get VoiceResource: %@
Can't get voice info: %@
%s, Error: %@
Failed is_neural_voice_ready: %s
Failed should_use_neural_voice: %s
Failed has_compact_neural_fallback: %s
Failed check_thermal_critical_conditions: %s
Failed has_ota_ane_model: %s
Failed is_ane_model_compiled: %s
Failed compile_ane_model: %s
#Trial Unexpected voice factor name: %@
#Trial Error: Factor has no level. It will be ignored. Factor name: %@
#Trial Error: voice should be as directory. Factor name: %@
#Trial Error: voice is not deployed. It will be ignored. Factor name: %@
#Trial Unexpected resource factor name: %@
#Trial Error: resource should be as directory. Factor name: %@
#Trial Received namespace 'SIRI_TEXT_TO_SPEECH' update
#Trial Unable to find asset for factor name '%@'.
#Trial Factor '%@' doesn't seem to be directory.
#Trial Factor '%@' is not downloaded yet.
#Trial Factor '%@' doesn't seem to be a file.
Skip immediate namespace download due to discretionary download option.
#Trial Start downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Unable to download Trial namespace. Error: %@
#Trial Finished downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Downloading asset with factor name: %@, discretionary:%d, allowCellular:%d
#Trial Unable to download asset with factor name: %@, error: %@
#Trial Downloaded asset with factor name: %@
#Trial Removing asset with factor name: %@
#Trial Unable to remove asset with factor name '%@', error: %@
#Trial Removed asset with factor name: %@
Unexpected multiple voices.
Unexpected multiple resources from Trial.
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
MobileAsset
VSVoiceAssetSelection
Trial
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSDownloadMetrics
VoiceServices
VSFeatureFlags
VSUtilities
VSPreviewRequest
NSCopying
VSSpeechEngineVoiceResource
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSVoiceSubscription
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusEncoder
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSAnalytics
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VS4CC
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
VSMappedData
Hash
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSAudioData
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
VSNeuralTTSUtils
VSTrialVoice
VSDownloadOptions
VSTrialVoiceResource
VSTrialService
Voice
VoiceResource
encodeObject:forKey:
encodeBool:forKey:
encodeInteger:forKey:
init
decodeObjectOfClass:forKey:
decodeBoolForKey:
decodeIntegerForKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
downloadSize
setDownloadSize:
isPurgeable
setIsPurgeable:
storage
setStorage:
.cxx_destruct
_isPurgeable
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_storage
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
T@"NSNumber",C,N,V_downloadSize
TB,N,V_isPurgeable
Tq,N,V_storage
setMinimumFractionDigits:
setMaximumFractionDigits:
stringWithString:
dictionaryMetrics
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
descriptionFormatter
stringFromNumber:
appendFormat:
appendString:
encodeInt64:forKey:
encodeDouble:forKey:
decodeInt64ForKey:
decodeDoubleForKey:
_clockFactor
timeToSpeakLatency
ttsSynthesisLatency
realTimeFactor
length
numberWithUnsignedInteger:
numberWithBool:
numberWithDouble:
timeToPlaybackLatency
audioQueueLatency
eagerRequestTimeGap
isSynthesisCached
numberWithInteger:
serverStreamFirstPacketLatency
serverStreamLastPacketLatency
cappedRealTimeFactor
dictionaryWithObjects:forKeys:count:
stringOfSourceOfTTS:
description
speechEstimatedOutputBeginTimestamp
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
audioOutputRoute
setAudioOutputRoute:
clientBundleIdentifier
setClientBundleIdentifier:
experimentIdentifier
setExperimentIdentifier:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimestampDiffs
setEagerRequestCreatedTimestampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
serverFirstPacketTimestamp
setServerFirstPacketTimestamp:
serverLastPacketTimestamp
setServerLastPacketTimestamp:
serverStreamedAudioDuration
setServerStreamedAudioDuration:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
isServerTTS
setIsServerTTS:
isServerStreamTTS
setIsServerStreamTTS:
isServerTimeout
setIsServerTimeout:
isServerTTSRacing
setIsServerTTSRacing:
canUseServerTTS
setCanUseServerTTS:
neuralAlignmentStall
setNeuralAlignmentStall:
neuralAudioClick
setNeuralAudioClick:
neuralFallback
setNeuralFallback:
promptCount
setPromptCount:
errorCode
setErrorCode:
sourceOfTTS
setSourceOfTTS:
isSpeechRequest
setIsSpeechRequest:
isCacheHitFromDisk
setIsCacheHitFromDisk:
isCacheHitFromMemory
setIsCacheHitFromMemory:
_isWarmStart
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_canUseServerTTS
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_requestCreatedTimestamp
_eagerRequestCreatedTimestampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_serverLastPacketTimestamp
_serverStreamedAudioDuration
_audioDuration
_promptCount
_errorCode
_sourceOfTTS
T@"NSString",C,V_utterance
T@"NSString",C,V_voiceAssetKey
T@"NSString",C,V_voiceResourceAssetKey
T@"NSString",C,V_audioOutputRoute
T@"NSString",C,V_clientBundleIdentifier
T@"NSString",C,V_experimentIdentifier
Tq,V_requestCreatedTimestamp
Tq,V_eagerRequestCreatedTimestampDiffs
Tq,V_synthesisBeginTimestamp
Tq,V_synthesisEndTimestamp
Tq,V_speechBeginTimestamp
Tq,R
Tq,V_speechEndTimestamp
Tq,V_audioStartTimestampDiffs
Tq,V_serverFirstPacketTimestamp
Tq,V_serverLastPacketTimestamp
Td,V_serverStreamedAudioDuration
Td,V_audioDuration
TB,V_isWarmStart
TB,V_isServerTTS
TB,V_isServerStreamTTS
TB,V_isServerTimeout
TB,V_isServerTTSRacing
TB,V_canUseServerTTS
TB,V_neuralAlignmentStall
TB,V_neuralAudioClick
TB,V_neuralFallback
Tq,V_promptCount
Tq,V_errorCode
Tq,V_sourceOfTTS
TB,V_isSpeechRequest
TB,V_isCacheHitFromDisk
TB,V_isCacheHitFromMemory
languagesFromMobileAssetAttributes:
setLanguages:
genderFromString:
setGender:
typeFromString:
setType:
footprintFromString:
setFootprint:
amendNameVersionAndSizeWithMobileAssetAttributes:
name
setName:
compatibilityVersionFromMobileAssetAttributes:
count
arrayWithCapacity:
stringByReplacingOccurrencesOfString:withString:
addObject:
arrayWithObjects:count:
integerValue
initFromMobileAssetAttributes:
language
type
footprint
gender
version
isLocal
setIsInstalled:
setIsBuiltInVoice:
assetSize
path
isNeuralVoiceReady:
setIsVoiceReadyToUse:
dealloc
voiceData
voiceKey
descriptiveKey
asset
getLocalUrl
languages
firstObject
stringWithFormat:
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
attributes
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
wasLocal
state
isVoiceReadyToUse
floatValue
initWithTrialVoice:
voicePath
size
isInstalled
isDownloading
preferenceScore
setVoiceData:
setAsset:
trialVoice
setTrialVoice:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
voicePathLock
setVoicePathLock:
_voiceData
_asset
_trialVoice
_builtInVoicePath
_voicePath
_voicePathLock
T@"VSVoiceAsset",&,V_voiceData
T@"MAAsset",&,V_asset
T@"VSTrialVoice",&,V_trialVoice
T@"NSString",&,V_builtInVoicePath
T@"NSString",&,N,V_voicePath
T{_opaque_pthread_mutex_t=q[56c]},N,V_voicePathLock
fileURLWithPath:
setSearchPathURL:
resourceFromTrial:
migrateAssetIfNeededWithAssetType:
initWithType:
returnTypes:
downloadCatalog:options:completion:
queryMetaData:
sharedService
setCountLimit:
numberWithLong:
cachedMAVoiceSelections
objectForKey:
removeObjectForKey:
processInfo
thermalState
standardInstance
ignorePowerAndThermalState
disableDeviceNeuralTTS
longValue
_getVoiceAssetsForType:voiceName:language:gender:footprint:returnTypes:
voiceDataFromAsset:
pickCorrectAssetFromLocalAssets:
setObject:forKey:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:name:
allKeys
_builtInVoiceForLanguage:
queryForVoiceResourceAsset:returnTypes:
_getResults:
sortUsingComparator:
getLocalFileUrl
contentsOfDirectoryAtPath:error:
_purgeMobileAsset:
selectVoiceResourceWithLanguage:
cachedMAVoiceResources
searchPathURL
_installedVoiceResourceAssetForLanguage:
voiceResourceFromAsset:
_trialVoiceResourceWithLanguage:
_mobileAssetVoiceResourceWithLanguage:
initWithCapacity:
engineMinimumCompatibility
engineCurrentCompatibility
bundleIdentifierForVoiceType:
arrayWithObjects:
addKeyValueArray:with:
arrayWithObject:
typeStringFromType:
addKeyValuePair:with:
footprintStringFromFootprint:
genderStringFromGender:
intValue
definedVoicesWithLanguage:name:type:footprint:
voice
selectVoiceForLang:name:type:gender:footprint:
installedAssetsForType:voicename:language:gender:footprint:
sortedArrayUsingComparator:
lastObject
defaultInstance
subscribedVoicesForClientID:accessoryID:
voiceAssetsForSubscription:
addObjectsFromArray:
activeVoiceAssets
assetId
factorName
containsObject:
assetType
disableAssetCleaning
errorWithDomain:code:userInfo:
inactiveVoiceAssets
_removeTrialVoices:completion:
installedTrialVoiceResources
removeTrialVoiceResource:completion:
cleanMobileAssetVoiceResourcesWithActiveLanguages:
resetCache
availableLanguages
dictionary
setObject:forKeyedSubscript:
removeAllObjects
installedTrialVoicesForType:voiceName:language:footprint:
arrayWithArray:
definedVoiceResourcesWithLanguage:
enableLocalVoices
_localVoiceForLanguageAndNamePath:
_trialVoiceWithLanguage:name:type:footprint:
_mobileAssetVoiceForLanguage:name:type:gender:footprint:
selectPreinstalledVoiceForLanguage:gender:name:
defaultToNonDiscretionaryDownloads
setDiscretionary:
setRequiresPowerPluggedIn:
downloadOptionsWithBattery:
downloadVoiceAsset:options:progressUpdateHandler:
candidateToDownloadForVoice:
isNeuralTTSPlatform
isHomePod
isWatch
predicateWithBlock:
filteredArrayUsingPredicate:
allowsCellularAccess
setAllowCellularData:
discretionary
setAllowDiscretionary:
shouldDownloadTrialVoice:
UTF8String
downloadVoice:withOptions:progress:completion:
downloadNamespaceImmediatelyIfNeededWithOption:completion:
removeVoice:completion:
purgeAsset:
downloadVoiceResource:options:completion:
shouldDownloadTrialResource:
initWithLanguage:
downloadVoiceResource:withOptions:progress:completion:
downloadTrialVoiceResource:options:completion:
removeVoiceResource:completion:
removeMobileAssetVoiceResource:completion:
results
queryForLanguage:forType:voiceName:gender:footprint:returnTypes:
setAllowsCellularAccess:
lastFetchDate
date
timeIntervalSinceDate:
currentRunLoop
dateWithTimeIntervalSinceNow:
runUntilDate:
startCatalogDownload:options:then:
isStalled
expectedTimeRemaining
totalExpected
totalWritten
attachProgressCallBack:
startDownload:then:
removeTrialVoice:completion:
defaultCenter
postNotificationName:object:
purgeSync
cancelDownloadSync
wasPurgeable
shouldUseNeuralVoice:
isH12Platform
isLowPowerModeEnabled
pathWithComponents:
voiceDataWithBundleIdentifier:attributes:voicePathCallback:
componentsSeparatedByString:
typeFromBundleIdentifier:
sharedManager
getLatestAssetFromArray:
isVoiceAssetWellDefined:
migrateAssetsWithProgress:
builtInVoices
selectVoiceResourceAssetForLanguage:
definedVoicesForLanguage:voiceName:type:footprint:
cleanUnusedAssets
cleanOldMobileAssetVoiceResources
resetResourcesCache
installedVoiceResources
downloadVoiceAsset:useBattery:progressUpdateHandler:
preferredDownloadForVoice:
cancelDownload:completion:
removeVoiceAsset:completion:
downloadVoiceResource:completion:
downloadVoiceResourceCatalogWithCompletion:
downloadCatalog:options:
_downloadAsset:options:progress:completion:
installedLocalVoices
assetQueryQueue
setAssetQueryQueue:
setCachedMAVoiceSelections:
setCachedMAVoiceResources:
trialService
setTrialService:
_assetQueryQueue
_cachedMAVoiceSelections
_cachedMAVoiceResources
_trialService
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"NSCache",&,N,V_cachedMAVoiceSelections
T@"NSCache",&,N,V_cachedMAVoiceResources
T@"VSTrialService",&,N,V_trialService
isInternalBuild
initWithSuiteName:
boolForKey:
setBool:forKey:
floatForKey:
setFloat:forKey:
stringForKey:
enableAudioDump
setEnableAudioDump:
logSensitiveText
setLogSensitiveText:
disableCache
setDisableCache:
setDisableAssetCleaning:
allowAnyAssetSubscriber
setAllowAnyAssetSubscriber:
setEnableLocalVoices:
whisper
setWhisper:
serverTTSTimeout
setServerTTSTimeout:
deviceTTSWaitTime
setDeviceTTSWaitTime:
defaultVolume
setDefaultVolume:
forceServerTTS
setForceServerTTS:
disableServerTTS
setDisableServerTTS:
disableInlineStreamTTS
setDisableInlineStreamTTS:
disableDeviceRacing
setDisableDeviceRacing:
disableOspreyStreaming
setDisableOspreyStreaming:
streamBufferDuration
setStreamBufferDuration:
useBetaVoice
setUseBetaVoice:
ospreyEndpointURL
setOspreyEndpointURL:
simulateNetworkStall
setSimulateNetworkStall:
setDisableDeviceNeuralTTS:
useSSMLInput
disableMobileAssetURLReset
setIgnorePowerAndThermalState:
disableAssetUpdate
setDisableAssetUpdate:
setDefaultToNonDiscretionaryDownloads:
internalDefaults
setInternalDefaults:
_internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
TB,N
Tf,N
T@"NSString",C,N
TB,R,N
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
downloadDuration
numberWithFloat:
initWithVoiceName:languageCode:gender:
endMetrics
isCellularAllowed
setIsCellularAllowed:
downloadProgress
setDownloadProgress:
setupTimeInterval
setSetupTimeInterval:
voiceDownloadKey
downloadBeginTimestamp
downloadEndTimestamp
_isCellularAllowed
_discretionary
_downloadProgress
_setupTimeInterval
_voiceDownloadKey
_downloadBeginTimestamp
_downloadEndTimestamp
T@"NSString",R,V_voiceDownloadKey
Tq,R,V_downloadBeginTimestamp
Tq,R,V_downloadEndTimestamp
TB,V_isCellularAllowed
TB,V_discretionary
T@"NSNumber",C,V_downloadSize
Tf,V_downloadProgress
Td,V_setupTimeInterval
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
code
resourceValuesForKeys:error:
longLongValue
removeItemAtURL:error:
getResourceValue:forKey:error:
compare:
subarrayWithRange:
directorySize:
removeDirectory:
cleanDirectory:withLRULimit:
cleanDirectory:withDateOlderThan:
isTrialEnabled
isLowPowerDeviceNeuralEnabled
hasANE
hasAMX
isHomeHub
isSeedBuild
languageCode
setLanguageCode:
voiceName
setVoiceName:
previewType
setPreviewType:
copyWithZone:
_languageCode
_voiceName
_previewType
T@"NSString",C,N,V_languageCode
T@"NSString",C,N,V_voiceName
Tq,N,V_previewType
TQ,N,V_requestCreatedTimestamp
resource
setResource:
.cxx_construct
_resource
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_resource
asbd
processMarkerBuffer
dataWithBytesNoCopy:length:freeWhenDone:
characterAtIndex:
utf8BytesForChar:
setStartTime:
utf16OffsetFromUTF8:
setTextRange:
stringWithUTF8String:
initWithCallback:
synthesisCallback:
pcmData
mutablePCMData
sampleBuffer
markerBuffer
wordTimingInfos
phonemeBuffer
phonemes
setState:
error
setError:
numOfPromptsTriggered
setNumOfPromptsTriggered:
neuralDidFallback
setNeuralDidFallback:
hasAlignmentStall
setHasAlignmentStall:
hasAudioClick
setHasAudioClick:
text
setText:
stopMark
setStopMark:
callback
setCallback:
wordTimings
setWordTimings:
setAsbd:
samplesProcessed
setSamplesProcessed:
lastUTF8Offset
setLastUTF8Offset:
lastUTF16Offset
setLastUTF16Offset:
_samples
_markers
_phonemeBuffer
_neuralDidFallback
_hasAlignmentStall
_hasAudioClick
_state
_error
_numOfPromptsTriggered
_text
_stopMark
_callback
_wordTimings
_samplesProcessed
_lastUTF8Offset
_lastUTF16Offset
_asbd
T@"NSString",&,N,V_text
Tq,N,V_stopMark
T@?,C,N,V_callback
Tq,N,V_state
T@"NSError",&,N,V_error
T@"NSMutableArray",&,N,V_wordTimings
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
TQ,N,V_samplesProcessed
TQ,N,V_lastUTF8Offset
TQ,N,V_lastUTF16Offset
TQ,N,V_numOfPromptsTriggered
TB,N,V_neuralDidFallback
TB,N,V_hasAlignmentStall
TB,N,V_hasAudioClick
initializeWithResourcePath:
lock
unlock
pathExtension
mimeForFileExtension:
loadResourceAtPath:mimeType:error:
currentCallbackResult
domain
isUserCancelError:
hasPhaticResponses:
initWithVoicePath:resourcePath:
setPitch:
setRate:
setVolume:
loadResource:error:
unloadResource:
synthesizeText:loggable:callback:
stopAtMarker:
preheat
pcmBufferSize
setPcmBufferSize:
rate
pitch
volume
synthesizer
setSynthesizer:
setCurrentCallbackResult:
synthesisLock
setSynthesisLock:
_rate
_pitch
_volume
_pcmBufferSize
_synthesizer
_currentCallbackResult
_synthesisLock
T^v,N,V_synthesizer
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
T@"NSLock",&,N,V_synthesisLock
TQ,N,V_pcmBufferSize
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
initWithFormat:
initWithContentsOfFile:
rangeOfString:options:range:
hasPrefix:
hasSuffix:
insertString:atIndex:
replaceCharactersInRange:withString:
string
vs_markerStringForContext:
stringByAppendingString:
regularExpressionWithPattern:options:error:
matchesInString:options:range:
whitespaceCharacterSet
characterIsMember:
punctuationCharacterSet
rangeAtIndex:
_vs_countPhoneticSyllables_lhp:
numberOfRanges
containsString:
_vs_countPhoneticSyllables_xsampa:
stringByReplacingMatchesInString:options:range:withTemplate:
addCharactersInRange:
vs_isCJKCharacter:
initWithString:
removeLastObject
raise:format:
vs_textifyEmojiWithLanguage:
vs_substituteAudioWithLocalPath
vs_insertContextInfo:
vs_measurePauses
vs_countPhoneticSyllables
vs_removePhonetics
vs_removeSpeechTags
vs_hasCJKCharacter
vs_convertToSSML
handleFailureInFunction:file:lineNumber:description:
stringByStandardizingPath
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
textRange
allValues
doubleValue
pathForResource:ofType:inDirectory:
timingPlistForLanguage:
timingInfosFrom:withText:
estimatedTTSWordTimingForText:withLanguage:voiceName:
T@"NSDictionary",&,N,V_wordTimings
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
initWithClient:accessory:voice:
clientID
setClientID:
accessoryID
setAccessoryID:
setVoice:
_clientID
_accessoryID
_voice
T@"NSString",&,N,V_clientID
T@"NSString",&,N,V_accessoryID
T@"VSVoiceAsset",&,N,V_voice
reset
_init
cancel
setDelegate:
setActive:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:openURL:completion:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:synchronously:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
setAttributedText:
setOutputPath:
startSpeakingRequest:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:completion:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
initWithStreamDescription:
initFromFormat:toFormat:
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
streamDescription
data
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
bytes
convertToBuffer:error:withInputFromBlock:
audioBufferList
appendBytes:length:
packetCount
packetDescriptions
encodeChunk:
initWithSourceASBD:
setOpusDataHandler:
setErrorHandler:
beginEncoding
endEncoding
opusDataHandler
errorHandler
fromFormat
setFromFormat:
toFormat
setToFormat:
converter
setConverter:
outputBuffer
setOutputBuffer:
opusDataOffset
setOpusDataOffset:
_opusDataHandler
_errorHandler
_fromFormat
_toFormat
_converter
_outputBuffer
_opusDataOffset
T@?,C,N,V_opusDataHandler
T@?,C,N,V_errorHandler
T@"AVAudioFormat",&,N,V_fromFormat
T@"AVAudioFormat",&,N,V_toFormat
T@"AVAudioConverter",&,N,V_converter
T@"AVAudioCompressedBuffer",&,N,V_outputBuffer
Tq,N,V_opusDataOffset
vs_stringFrom4CC:
beginChunkDecoderForStreamDescription:
decodeChunk:outError:
appendData:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
localizations
preferredLocalizationsFromArray:forPreferences:
URLForResource:withExtension:subdirectory:localization:
predefinedStringForKey:language:table:
appendRandomizationKey:withCount:
localizedStringForKey:language:table:
localizedOOBStringForKey:language:
localizedInterstitialStringForKey:language:
localizedOOBStringForKey:language:gender:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSet
valueWithRange:
unspeakableRangeOfText:
setCharacterSet:
_characterSet
T@"NSCharacterSet",&,N,V_characterSet
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
reportEvent:payload:
OOBNeedsToBeMeasured
OOBTriggeredDate
setOOBNeedsToBeMeasured:
reportInstrumentMetrics:
reportDownloadMetrics:
componentsJoinedByString:
decodeObjectOfClasses:forKey:
vocalizerConfig
URLByAppendingPathComponent:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
voiceConfig
_defaultVoices
defaultVoiceNameForGender:
resourceMimeTypes
resourceList
defaultVoiceGender
defaultVoiceType
defaultVoice
setVoiceConfig:
setVocalizerConfig:
setResourceList:
setResourceMimeTypes:
_languages
_searchPathURL
_voiceConfig
_vocalizerConfig
_resourceList
_resourceMimeTypes
T@"NSDictionary",C,N,V_voiceConfig
T@"NSDictionary",&,N,V_vocalizerConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSDictionary",C,N,V_resourceMimeTypes
T@"NSURL",C,N,V_searchPathURL
rangeValue
allocWithZone:
startTime
whitespaceAndNewlineCharacterSet
lengthOfBytesUsingEncoding:
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
wordTimingInfoFrom:timestamps:
utf16TimingInfoWithUTF8Range:withText:
adjustWordTimingInfo:forContext:
_startTime
_textRange
Td,N,V_startTime
T{_NSRange=QQ},N,V_textRange
stopListening
_initShared
_spokenLanguageChanged:
addObserver:selector:name:object:
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
canLogRequestText
copy
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:size:
decodeInt32ForKey:
numberWithUnsignedLongLong:
logText
initWithAudioData:playerStreamDescription:
initWithIdentifier:
hasValidAudio
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
identifier
setIdentifier:
siriRequestId
setSiriRequestId:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_identifier
_siriRequestId
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
T@"NSString",C,N,V_clientBundleIdentifier
T@"NSUUID",C,N,V_accessoryID
TQ,N,V_pcmDataSize
T@?,C,N,V_stopHandler
TI,N,V_audioSessionID
T@"NSData",R,C,N,V_audioData
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
TB,N,V_enqueue
T@"NSString",&,N,V_identifier
T@"NSUUID",&,N,V_siriRequestId
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
initWithDictionaryRepresentation:
matchedString:forTokenInRange:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
contextInfoString
contextInfo
isEqualToDictionary:
voiceType
shouldWhisper
customResourceURLs
isEqualToArray:
setVoiceType:
outputPath
shouldCache
setShouldCache:
shouldWaitCurrentSpeaking
setShouldWaitCurrentSpeaking:
setShouldWhisper:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
setCustomResourceURLs:
decodePropertyListForKey:
enumerateKeysAndObjectsUsingBlock:
logUtterance
isSimilarTo:
retryDeviceOnNetworkStall
setRetryDeviceOnNetworkStall:
attributedText
shouldStreamAudioData
setShouldStreamAudioData:
pauseHandler
setPauseHandler:
pointer
setPointer:
_shouldWaitCurrentSpeaking
_disableDeviceRacing
_shouldCache
_shouldWhisper
_disableCompactVoiceFallback
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_attributedText
_pauseHandler
_pointer
T@"NSAttributedString",C,N,V_attributedText
TB,N,V_shouldStreamAudioData
T@"NSString",C,N,V_utterance
T@?,C,N,V_pauseHandler
Tq,N,V_pointer
T@"NSString",C,N,V_text
Tq,N,V_footprint
Tq,N,V_voiceType
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
TB,N,V_shouldWaitCurrentSpeaking
TB,N,V_disableDeviceRacing
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_shouldWhisper
T@"NSDictionary",C,N,V_contextInfo
TB,N,V_disableCompactVoiceFallback
TB,N,V_forceServerTTS
TB,N,V_canUseServerTTS
TB,N,V_retryDeviceOnNetworkStall
T@"NSURL",C,N,V_resourceListURL
T@"NSURL",C,N,V_resourceSearchPathURL
T@"NSArray",&,N,V_customResourceURLs
createFileAtPath:contents:attributes:
fileHandleForUpdatingAtPath:
fileDescriptor
closeFile
initWithFilePath:initialSize:
removeItemAtPath:error:
_convertToFallbackMemory
_appendToFallbackMemory:
_appendToMappedMemory:
bytesAtOffset:
filePath
setFilePath:
totalLength
setTotalLength:
mmappedData
setMmappedData:
mappedLength
setMappedLength:
fallbackInMemoryData
setFallbackInMemoryData:
shouldCleanFile
setShouldCleanFile:
_shouldCleanFile
_filePath
_totalLength
_mmappedData
_mappedLength
_fallbackInMemoryData
T@"NSString",&,N,V_filePath
TQ,N,V_totalLength
T^v,N,V_mmappedData
TQ,N,V_mappedLength
T@"NSMutableData",&,N,V_fallbackInMemoryData
TB,N,V_shouldCleanFile
stringWithCapacity:
stringByAppendingFormat:
sha256hex
preinstalledAudioHashForLanguage:name:
completion
setCompletion:
_completion
T@?,C,N,V_completion
validatePrewarmRequest:
playVoicePreviewForLanguageCode:voiceName:previewType:completion:
startVoicePreviewRequest:reply:
stopPlayingVoicePreview
stopVoicePreview
initWithAccessoryID:
mainBundle
preferredLocalizations
processName
processIdentifier
opaqueSessionID
speechSynthesizer:didFinishPrewarmRequest:withError:
prewarmIfNeededWithRequest:reply:
queryPhaticCapabilityWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didStartPlayingPreviewRequest:
stopPresynthesizedAudioRequest:
stopSpeechRequest:atMark:
currentRequest
pauseSpeechRequest:atMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
startSpeechRequest:
validateAudioRequest:
startPresynthesizedAudioRequest:
validateAudioCachingRequest:
cachePresynthesizedAudioRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:
currentAudioRequest
_stopSpeakingPresynthesizedAudioRequest:synchronously:
_pauseSpeakingRequestAtNextBoundary:synchronously:
_continueSpeakingRequest
isSystemSpeakingOnBehalfOfCurrentConnection
isSystemSpeaking
continueSpeechRequest:
decimalDigitCharacterSet
numberWithInt:
characterClassCountForUtterance:language:
objectAtIndexedSubscript:
unsignedIntegerValue
estimateDurationWithRequest:reply:
speechSynthesizer:withRequest:didReceiveTimingInfo:
valueWithNonretainedObject:
durationRequests
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:daemonDidCrashWithError:
forwardStreamObject:
invokeDaemon:
killDaemon
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoiceAssetsForLanguage:reply:
getLocalVoiceResources:
getVoiceResourceForLanguage:reply:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
triggerCellularDownloadedVoiceAssets:withClientID:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getAllVoiceSubscriptionsWithReply:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
availableVoicesForLanguageCode:
availableFootprintsForVoice:languageCode:
errorWithReason:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:speechRequest:didGenerateAudioChunk:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
connection:previewRequestDidStartPlaying:
connection:invalidatedWithError:
prewarmIfNeededWithRequest:
queryPhaticCapability:
startSynthesizingRequest:
startSpeakingPresynthesizedAudioRequest:
cancelRequest:
cancelAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
continueSpeakingWithError:
isSpeaking
speechString
minimumRate
maximumRate
estimateDurationOfRequest:
estimateDurationOfRequest:completion:
getLocalVoiceAssets:
setAutoDownloadedVoiceAssets:
triggerCellularDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getAllAutoDownloadedVoiceAssets:
availableLanguageCodes
delegate
setLanguage:
setDurationRequests:
_queue
_callbackQueue
_xpcConnection
_synthesizerFlags
_language
_durationRequests
T@"NSString",C,N,V_language
T@"NSMutableDictionary",&,N,V_durationRequests
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
T@"NSString",&,N,V_voice
migrateDefaults
arrayForKey:
dictionaryForKey:
dictionaryRepresentation
dictionaryRepresentationOfVoices:
UUID
UUIDString
T@"VSPreferencesInterface",R
setSubscribedVoices:forClientID:accessoryID:
removeSubscriptionsForAccessory:
setOOBTriggeredDate:
setLastTTSRequestDate:
lastTTSRequestDate
deviceUUID
defaults
setDefaults:
setLock:
_defaults
T@"NSUserDefaults",&,N,V_defaults
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T@"NSDate",&,N
T@"NSString",R,N
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
Tq,N,V_audioType
TB,N,V_active
TB,N,V_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
queryPhaticCapabilityWithRequest:reply:
startSpeechRequest:reply:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesForLanguage:reply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
xpcConnection
speechRequestDidStart:
speechRequestDidPause:
speechRequestDidContinue:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequest:didReportInstrumentMetrics:
speechRequest:didReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didFinishWithInstrumentMetrics:error:
audioRequestDidStart:
audioRequest:didStopAtEnd:error:
audioRequest:didReportInstrumentMetrics:error:
previewRequestDidStartPlaying:
setExportedInterface:
delegateWrapper
setExportedObject:
synchronousRemoteObjectProxyWithErrorHandler:
remoteObjectProxyWithErrorHandler:
requests
enumerateObjectsUsingBlock:
audioRequests
concurrentSynthesisRequests
setXpcConnection:
_remoteObjectWithErrorHandler:
getLocalPreviewRequest:
previewRequests
_remoteObject
insertObject:atIndex:
_remoteObjectSync
localizedDescription
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
T@"NSXPCConnection",&,N,V_xpcConnection
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
getLocalRequest:
getLocalAudioRequest:
setCurrentRequest:
setRequests:
setConcurrentSynthesisRequests:
setCurrentAudioRequest:
setAudioRequests:
setPreviewRequests:
connection
_currentRequest
_concurrentSynthesisRequests
_currentAudioRequest
_audioRequests
_previewRequests
_connection
T@"VSSpeechRequest",&,N,V_currentRequest
T@"NSMutableArray",&,N,V_requests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_currentAudioRequest
T@"NSMutableArray",&,N,V_audioRequests
T@"NSMutableArray",&,N,V_previewRequests
T@"VSSpeechConnection",W,N,V_connection
setAudioData:
setPacketCount:
setPacketDescriptions:
mutableAudioData
mutableDescription
setData:
encodeBytes:length:forKey:
decodeBytesForKey:returnedLength:
duration
totalFrames
concatenateWithAudio:
setMutableAudioData:
setMutableDescription:
_packetCount
_mutableAudioData
_mutableDescription
T@"NSMutableData",&,N,V_mutableAudioData
T@"NSMutableData",&,N,V_mutableDescription
T@"NSData",&,N
Tq,N,V_packetCount
nameKey
lowercaseString
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
_name
_type
T@"NSString",C,N,V_name
Tq,N,V_type
TB,N,V_isInstalled
TB,N,V_isBuiltInVoice
TB,N,V_isVoiceReadyToUse
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
T@"NSXPCListenerEndpoint",&,N,V_endpoint
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
_block
hasCompactNeuralFallback:
isNeuralFallbackCondition
hasOTAANEModel:
isANEModelCompiled:
compileANEModel:
isANECompilationPlatform
initWithLanguage:name:
factor
initWithFactorName:
hasLevel
level
directoryValue
hasAsset
hasPath
metadata
initWithFactorLevel:
setPath:
setVersion:
setAssetSize:
_path
_version
_assetSize
T@"NSString",&,N,V_path
TQ,N,V_version
TQ,N,V_assetSize
Tq,N,V_compatibilityVersion
allowCellularData
allowDiscretionary
_allowCellularData
_allowDiscretionary
TB,N,V_allowCellularData
TB,N,V_allowDiscretionary
clientWithIdentifier:
refreshTrialClient
addUpdateHandlerForNamespaceName:usingBlock:
removeUpdateHandlerForToken:
refresh
factorLevelsWithNamespaceName:
setDiscretionaryBehavior:
levelForFactor:withNamespaceName:
fileValue
rolloutIdentifiersWithNamespaceName:
setWithObject:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
defaultDownloadOptions
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
removeLevelsForFactors:withNamespace:queue:completion:
versionFactorNameWithFactorName:
T@"VSTrialService",R,N
cachedVoices
cachedResources
_directoryOfFactorName:
_fileOfFactorName:
_downloadFactorName:withOptions:progress:completion:
_removeAssetWithFactorName:completion:
triClient
setTriClient:
setCachedVoices:
setCachedResources:
trialNotificationToken
setTrialNotificationToken:
downloadQueue
setDownloadQueue:
clientRefreshLock
setClientRefreshLock:
_triClient
_cachedVoices
_cachedResources
_trialNotificationToken
_downloadQueue
_clientRefreshLock
T@"TRIClient",&,N,V_triClient
T@"NSArray",&,N,V_cachedVoices
T@"NSArray",&,N,V_cachedResources
T@"<TRINotificationToken>",&,N,V_trialNotificationToken
T@"NSObject<OS_dispatch_queue>",&,N,V_downloadQueue
T@"NSLock",&,N,V_clientRefreshLock
selectVoiceWithLanguage:name:type:footprint:
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
v20@0:8B16
q16@0:8
v24@0:8q16
v16@0:8
@"NSString"
@"NSNumber"
@24@0:8q16
d16@0:8
v24@0:8d16
Q16@0:8
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
@"VSVoiceAsset"
@"MAAsset"
@"VSTrialVoice"
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8@16q24@32q40q48q56
@32@0:8@16q24
@20@0:8B16
q24@0:8@16
B24@0:8@16
B24@0:8@?16
@56@0:8@16@24q32q40q48
@40@0:8@16q24@32
@48@0:8@16@24q32q40
@48@0:8q16@24@32q40
@56@0:8q16@24@32q40q48
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@16@?24
v24@0:8@?16
@64@0:8q16@24@32q40q48q56
@32@0:8@16@24
v48@0:8@16@24@?32@?40
@40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSCache"
@"VSTrialService"
f16@0:8
v20@0:8f16
@"NSUserDefaults"
@40@0:8@16@24q32
Q24@0:8@16
v32@0:8@16Q24
v32@0:8@16@24
@24@0:8^{_NSZone=}16
v24@0:8Q16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
@24@0:8@?16
i20@0:8i16
^v16@0:8
Q20@0:8S16
Q24@0:8Q16
@?16@0:8
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<TTSSynthesizer::Marker, std::allocator<TTSSynthesizer::Marker>>="__begin_"^{Marker}"__end_"^{Marker}"__end_cap_"{__compressed_pair<TTSSynthesizer::Marker *, std::allocator<TTSSynthesizer::Marker>>="__value_"^{Marker}}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@"NSError"
@"NSMutableArray"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@40@0:8@16@24^@32
@32@0:8@16^@24
@36@0:8@16B24@?28
v24@0:8^v16
@"VSSpeechSynthesisCallbackResult"
@"NSLock"
B20@0:8S16
@40@0:8@16@24@32
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
B40@0:8^@16^@24q32
B20@0:8B16
v40@0:8@16@24@32
^{__CFDictionary=}16@0:8
v52@0:8@16@24B32@36@44
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateOpenURLAsync"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@"AVAudioFormat"
@"AVAudioConverter"
@"AVAudioCompressedBuffer"
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
^{OpaqueAudioConverter=}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
@28@0:8@16i24
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
@"NSCharacterSet"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@20@0:8i16
@28@0:8@16B24
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
@"NSData"
@"NSUUID"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
@32@0:8@16Q24
{_NSRange=QQ}24@0:8@16
^v24@0:8Q16
@"NSMutableData"
B48@0:8@16@24q32@?40
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPreviewRequest"24
v32@0:8@"VSSpeechConnection"16@"NSError"24
v48@0:8@16@24q32@?40
@36@0:8@16q24B32
@28@0:8q16B24
B36@0:8q16B24^@28
B28@0:8B16^@20
B24@0:8^@16
d24@0:8@16
v64@0:8@16@24q32q40q48@?56
@"VSSpeechConnection"
{?="delegateStartWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateStreamSynthesisAudioData"b1"willUseInput"b1"delegateDidStartPreviewRequest"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv24@0:8@16
Vv32@0:8@16@?24
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv24@0:8@"NSString"16
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
v32@0:8@16q24
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@"TRIClient"
@"<TRINotificationToken>"
|?5^
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_isPurgeable
_storage
v8@?0
audio_duration
audio_output_route
audio_queue_latency
can_use_server_tts
character_count
client_bundle_identifier
error_code
experiment_identifier
is_server_stream_tts
is_server_timeout
is_server_tts_racing
is_speech_request
is_synthesis_cached
is_warm_start
neural_alignment_stall
neural_audio_click
neural_fallback
prompt_count
real_time_factor
server_first_packet_latency
server_last_packet_latency
server_streamed_audio_duration
source_of_tts
synthesis_to_speech_time_gap
tts_and_playback_total_latency
tts_synthesis_latency
tts_total_latency
voice_asset_key
voice_resource_asset_key
  "%@": %@,
  "%@": "%@",
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_promptCount
_sourceOfTTS
_errorCode
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_audioDuration
_serverStreamedAudioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
is_server_tts
osprey_round_trip
osprey_streaming
ace_round_trip
ace_inline_streaming
device
inline_tts
audio_request
device_cached_synthesis
unknown
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.notification.voice-purge
VSMobileAssetServiceErrorDomain
VSTrialServiceErrorDomain
MobileAssetProperties
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
/private/var/mobile/Library/VoiceServices/voices/
%@.tmp
VSMobileAssetsManager.m
negative size
v16@?0q8
com.apple.voiced.assetQueryQueue
%@_%@_%@_%@_%@
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"MAAsset"8@"MAAsset"16
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
VSMobileAssetsManager
Cleaning voice assets is disabled in internal setting.
v24@?0@"NSMutableArray"8q16
%@_%@
B24@?0@"VSTrialVoice"8@"NSDictionary"16
q24@?0@"VSTrialVoice"8@"VSTrialVoice"16
v20@?0d8f16
v12@?0f8
v16@?0@"NSError"8
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
Info.plist
CFBundleIdentifier
@"NSString"8@?0
local_voice
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
enableTrial
enableAudioDump
logSensitiveText
DisableCaching
DisableAssetCleaning
AllowAnyAssetSubscription
EnableLocalVoices
whisper
ServerTTSTimeout
DeviceTTSWaitTime
defaultVolume
forceServerTTS
disableServerTTS
disableInlineStreamTTS
disableDeviceRacing
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
simulateNetworkStall
disableDeviceNeuralTTS
useSSMLInput
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
defaultToNonDiscretionaryDownloads
tts_languages
plist
tts_language_fallbacks
en-US
_VSServerConnection
com.apple.voiced
%@:%@:%@
allowing_cellular
download_size
download_duration
download_progress
setup_duration
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
VoiceServices
lowPowerDeviceNeural
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
DeviceClassNumber
InternalBuild
HardwarePlatform
t8030
_languageCode
_voiceName
_previewType
VSVocalizerEngine
path
mimeType
TTSSynthesizer::load_voice_resource
unknown path
unknown mime-type
i12@?0i8
tts.neural.use_fallback
tts.metrics.alignment_stall
tts.metrics.audio_has_click
tts.feature.phonemes
TTSSynthesizer::synthesize_text_with_markers_async
application/edct-bin-dictionary
application/x-vocalizer-rettt+text
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/
\mrk=%@=%@\
\toi=lhp\
\toi=orth\
\tn=normal\
\tn=
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
<speak>
speak
<phoneme alphabet="lhp" ph="
phoneme
"></phoneme>
SSML error
unbalanced phoneme tag
say-as
</say-as>
unbalanced say-as tag
Error in tn override tag, ignore
<say-as interpret-as="%@">
</%@>
NSString *soft_AXSpeechTransformTextWithLanguage(NSString *__strong, AXSpeechTransformOptions, NSString * _Nullable __strong, NSMutableArray * _Nullable __strong)
NSString+VSSpeechService.m
AXSpeechTransformTextWithLanguage
void *AccessibilityUtilitiesLibrary(void)
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/Contents/MacOS/AccessibilityUtilities
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
/System/Library/PrivateFrameworks/VoiceServices.framework/
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
_clientID
_accessoryID
_voice
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
@"AVAudioBuffer"20@?0I8^q12
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %@
<private>
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_NETWORK_STALL
_MALE
strings
%@_%d
Interstitials
DeviceSetup
VSSpeechLangCharset
CharacterBinaryMaps
could not create recognition instance
recognition already attempted or in progress
com.apple.voiceservices.metrics
com.apple.voiceservices.download
@"NSDictionary"8@?0
com.apple.AssistantServices
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@_CV%@
_languages
_searchPathURL
_startTime
_textRange
model <%@> class <%@>
com.apple.yn
0x%x
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_text
_identifier
_siriRequestId
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@, accessoryID:%@
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
textForAttributes
attributes
startTime: %llu, language:%@, name:%@, gender:%@, type:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, shouldWhisper:%d, canUseServerTTS:%d, disableCompactFallback:%d, disableDeviceRacing:%d, shouldWaitCurrentSpeaking:%d, shouldCache:%d, contextInfo:%@, customResourceURLs:%@, session:%d, accessoryID:%@, text:'%@'
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_shouldWhisper
_shouldCache
_disableCompactVoiceFallback
_disableDeviceRacing
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_shouldWaitCurrentSpeaking
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_contextInfo
_pointer
%@%@: %@
v32@?0@8@16^B24
VSMappedData%p
%02x
 %@ %@
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
VoiceServicesErrorDomain
com.apple.voiceservices.notification.synthesis-done
Request is nil.
language is not set.
Request has been used before. Please make a new copy of it.
text is not set.
Audio request has invalid audio data.
Missing text of inline streaming request.
Invalid audio request. Audio is invalid.
Audio caching request must be either inline streaming or audio request.
v20@?0d8B16
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
com.apple.assistantd
VSSpeechSynthesizer_%p@%@_%d
stop presynthesized request timeout
stop request timeout
pause request timeout
ar-SA
da-DK
it-IT
ja-JP
nb-NO
nl-NL
ru-RU
sv-SE
%@:%d
generic
-[VSSpeechSynthesizer estimateDurationOfRequest:completion:]_block_invoke
v24@?0d8@"NSError"16
-[VSSpeechSynthesizer connection:speechRequest:didStopAtEnd:phonemesSpoken:error:]_block_invoke
-[VSSpeechSynthesizer connection:synthesisRequest:didFinishWithInstrumentMetrics:error:]_block_invoke
@"NSArray"16@?0@"NSArray"8
%@:%@:%@:%@
Auto Downloaded Assets
autoDownloadedAssets
subscribedAssets
OOBTriggeredDate
OOBNeedsToBeMeasured
lastTTSRequestDate
deviceID
com.apple.voiceservices.xpcconnection
-[VSSpeechConnection _remoteObjectSync]_block_invoke
v32@?0@"VSSpeechRequest"8Q16^B24
v32@?0@"VSPresynthesizedAudioRequest"8Q16^B24
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
v12@?0B8
v16@?0@"NSArray"8
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
audioData
packetDescription
packetCount
asbd
undefined
compact
premium
premiumhigh
beta
male
female
neutral
vocalizer
custom
gryphon
neural
MasteredVersion
ContentVersion
builtin
%@:%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, downloadSize: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
B24@?0@8@"NSDictionary"16
v16@?0@8
_endpoint
SIRI_TEXT_TO_SPEECH
com.apple.siri.tts
com.apple.siri.tts.voice
com.apple.siri.tts.resource
.version
assetSize
ttsCompatibilityVersion
ttsContentVersion
gender
%@.voice.%@.%@.%@.%@
Voice factor name: %@
%@.resource.%@
VSTrialService.downloadQueue
v16@?0@"<TRINamespaceUpdateProtocol>"8
immediateDownloadForNamespaceNames cannot use discretionary download option.
v16@?0Q8
v20@?0B8@"NSError"12
||#\NSt3__110__function6__funcIU8__strongU13block_pointerFiN14TTSSynthesizer15CallbackMessageEENS_9allocatorIS6_EES4_EE
NSt3__110__function6__baseIFiN14TTSSynthesizer15CallbackMessageEEEE
U13block_pointerFiN14TTSSynthesizer15CallbackMessageEE
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3
mcpl
MbP?
@mcpl
@mcpl
@supo
@supo
@mcpl
ASAttributeCompatibilityVersion should be NSNumber, got NSString for %@
CV: %@
Compatibility: %@
#MobileAsset migrate '%@', error: %@
#MobileAsset migrate '%@', success
#MobileAsset Ignore cached voice selection for voice query key %@ since it is not installed anymore.
#MobileAsset Ignore neural voice due to thermal critical condition.
#MobileAsset Found cached voice selection %@ for voice query key %@
#MobileAsset Ignore neural voices since device neural TTS is disabled.
#MobileAsset Selected %{public}@ and will cache it for %{public}@
Purging corrupted VoiceResource '%{public}@', error: %{public}@
#MobileAsset Found cached voice resource %@ for %{public}@
#MobileAsset Cached voice resource is corrupted %@
#MobileAsset Unable to find asset for VoiceResources %{public}@
#MobileAsset Found voice resource %@ for %{public}@
#MobileAsset current in-use asset, %@
#MobileAsset ignore VoiceOver asset, %@
#Trial current in-use asset, %@
Cleaning unused assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#Trial Search voice asset for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no suitable installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial Found suitable voice: %{public}@
Parameter language can't be nil for voice selection
Searching voice asset for lang: %{public}@, name: %{public}@, type: %{public0}@, gender: %{public}@, footprint: %{public}@
Search local voices for lang: %{public}@, name: %{public}@
Built-in voice is requested.
Search voices in Trial
Search voices in MobileAsset
Search voices in pre-installed location as fallback
Fallback to custom compact voice
Fallback to built-in compact voice
Selected voice %{public}@
#Trial Found local voice, skip downloading. Target voice: %@
#Trial Found local MobileAsset voice with same or higher version, skip downloading. Target voice: %@
Language must be provided for voice download.
#Trial Enqueued downloading: %{public}@
#Trial Unable to download namespace to download voice: %@, error: %@
#Trial Unable to find suitable voice to download for voice criteria: %@
Target voice to download: %@
#Trial Removing voice: %@
#Trial Unable to remove voice %@, error: %@
#Trial Removed voice: %@
#Trial Cancelling voice download: %{public}@
Removing voice: %{public}@
Asset not removed because it is not present: %@
#Trial Cannot find any Trial resource, skip downloading. Target resource: %@
#Trial Found local resource, skip downloading. Target resource: %@
#Trial No MobileAsset resource found, will download Trial resource. Target resource: %@
#Trial Found same or newer resource in MobileAsset, skip downloading. Target resource: %@
#Trial Enqueue downloading resource: %@
#Trial Error downloading resource: %@, error: %@
#Trial Start downloading for: %@
#MobileAsset ERROR query '%@', timeout after 1 sec
#MobileAsset WARNING query '%@', error: %@
#MobileAsset Catalog '%@' download error: %@
#MobileAsset err %@, unable to download asset %{public}@
#MobileAsset Finished downloading asset %{public}@
#MobileAsset Begin %@ download, allowing cellular %{BOOL}d: %@
#MobileAsset Asset is already downloading: %{public}@
#MobileAsset download skipped, asset is already installed: %{public}@
#MobileAsset download skipped, asset is in an unknown state: %{public}@
#MobileAsset purge asset: %{public}@
#MobileAsset purge error: %@
#MobileAsset cancel downloading asset: %{public}@
#MobileAsset Cancel download error: %@
#MobileAsset Purge cannot find asset: %{public}@
#MobileAsset not removed because it is required by the OS: %{public}@
Ignoring all neural voices due to disableDeviceNeuralTTS
Ignoring neural voice %@. Current states as H12 platform: %{BOOL}d, thermal state:%d, low power enabled:%{BOOL}d
#MobileAsset Couldn't find any built-in voice for language: %{public}@
Unable to query local voice directory, %@
Failed to convert %ld recognition results
process is not running as user Mobile: it won't share the same UserDefaults as voiced
No cache directory from which to get the size: %@
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
Exception: %s
voice path '%@', resource path '%@'
%d files under voice path:
- %@
Failed to initialize synthesizer due to missing voice path.
Initializing engine with voice path: %@
Failed to initialize synthesizer: %s
Failed to initialize synthesizer: %zu
Error setPitch 0x%zx
Error setRate 0x%zx
Error setVolume 0x%zx
Unable to load resource '%@'
Url doesn't conform to RFC 1808 '%@'
Loading resource: %@, mime-type: %@
Unable to find mime-type for '%@'
Unknown voice resource handle to unload: %@
VSSpeechEngine %p started synthesis.
VSSpeechEngine %p finished synthesis.
Engine preheating latency: %.3f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %{public}@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for voice '%@', text: '%@'
converter.maximumOutputPacketSize is 0. Falling back to maximumPacketSize 1024. Converter is %@
AVAudioConverter.maximumOutputPacketSize is 0.
Invalid target asbd: %@
Could not create Opus decoder: %{public}@
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%{public}@'
Unable to find '%{public}@' localized string for key '%@', return empty string
Searching predefined string for '%@' in '%{public}@'
Unable to find '%{public}@' predefined string for key '%@', return default en-US string
Unable to find '%{public}@' predefined string for key '%@', return empty string
CoreAnalytics eventName:%@ not sent. Event name must not be in current config
Successfully reportEvent with domain '%@'
OOB subscription completion observed with %@ %@
Unable to load plist at '%{public}@', error: %{public}@
Unable to read voice_configs.plist
voice_configs.plist does not have key '_voices'
You're using a deprecated method [VSVoiceResourceAsset defaultVoiceType]; use `VSSpeechVoiceDataTypeUndefined` or `[VSVoiceResourceAsset defaultVoiceNameForGender:]` instead
You're using a deprecated method [VSVoiceResourceAsset defaultVoice]; use `defaultVoiceGender` instead
Out of word boundary: %ld is greater than %ld
Enqueuing request: %@
Queue is now:
Dispatching open URL: %@
Open URL failed: %@
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file, errno: %d, error: %s
%{public}@ is not TTS language, VSSpeechSynthesizer fallback to %{public}@
Invalid #PrewarmRequest: %@, error: %@
#PrewarmRequest %llu from client:%@, request: %@
Stop #SpeechPresynthesizedAudioRequest %llu from client:%@, synchronously: %{BOOL}d
Stop #SpeechPresynthesizedAudioRequest from client:%{public}@ was ignored, no request to stop
Stop #SpeechRequest from client:%{public}@ was ignored, no request to stop
Stop #SpeechRequest %llu from client:%{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest %llu from client:%@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest from client:%{public}@ was ignored, no request to pause
Invalid #SynthesisRequest: %@, error: %@
Start #SynthesisRequest %llu from client:%@, %@
Invalid #SpeechRequest: %@, error: %@
Start #SpeechRequest %llu from client:%@, %{public}@
Invalid #PresynthesizedAudioRequest: %@, error: %@
Start #PresynthesizedAudioRequest %llu: %@
Invalid #AudioCachingRequest: %@, error: %@
Cache #PresynthesizedAudioRequest %llu: %@
Cancel #SpeechRequest from client:%{public}@ was ignored, no request to stop
Cancel #SpeechRequest %llu from client:%{public}@
Cancel #PresynthesizedAudioRequest from client:%{public}@ was ignored, no request to stop
Cancel #PresynthesizedAudioRequest %llu from client:%{public}@
Error Stop #SpeechRequest %@
Error Stop #PresynthesizedAudioRequest %@
Resume #SpeechRequest %llu from client:%@
Resume #SpeechRequest from client:%{public}@ was ignored, no request to resume
#RoughEstimateDuration Request utterance: %@
#RoughEstimateDuration calculated duration: %.2f, using %@ locale, for text: %@
#EstimateDuration Request text: %@
Error %s, %@
#EstimateDuration Received duration: %.2f, for text: %@
%s, callback received in framework. %@
Current xpc connection %@ does not match %@
Notify daemon crash from: %@
#AudioPower Begin update
#AudioPower End update
#VoiceSubscription, client: %{public}@, accessory: %@, requested voices: %@
#VoiceSubscription, client: %{public}@, accessory: %@, deduped voices: %@
Request to download with cellular, client: %{public}@, language: %{public}@, gender: %ld, type: %ld, footprint: %ld, name: %{public}@
%{public}@ is not TTS language, fallback to %{public}@
clearing auto-downloaded voice preferences for accessory %@
Closing xpc connection %p
%s, error: %@
Error updateWithConnectionIdentifier: %@
Can't prewarm: %@
Error at %s , %@ 
Error estimateDurationWithRequest:reply: %@
Error %@ asking for voices
Error %@ asking for voice footprints
Can't start VoicePreview: %@
Can't get subscribed voice assets: %@
Can't get all subscribed voice assets: %@
Can't get VoiceResource: %@
Can't get voice info: %@
%s, Error: %@
Failed is_neural_voice_ready: %s
Failed should_use_neural_voice: %s
Failed has_compact_neural_fallback: %s
Failed check_thermal_critical_conditions: %s
Failed has_ota_ane_model: %s
Failed is_ane_model_compiled: %s
Failed compile_ane_model: %s
#Trial Unexpected voice factor name: %@
#Trial Error: Factor has no level. It will be ignored. Factor name: %@
#Trial Error: voice should be as directory. Factor name: %@
#Trial Error: voice is not deployed. It will be ignored. Factor name: %@
#Trial Unexpected resource factor name: %@
#Trial Error: resource should be as directory. Factor name: %@
#Trial Received namespace 'SIRI_TEXT_TO_SPEECH' update
#Trial Unable to find asset for factor name '%@'.
#Trial Factor '%@' doesn't seem to be directory.
#Trial Factor '%@' is not downloaded yet.
#Trial Factor '%@' doesn't seem to be a file.
Skip immediate namespace download due to discretionary download option.
#Trial Start downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Unable to download Trial namespace. Error: %@
#Trial Finished downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Downloading asset with factor name: %@, discretionary:%d, allowCellular:%d
#Trial Unable to download asset with factor name: %@, error: %@
#Trial Downloaded asset with factor name: %@
#Trial Removing asset with factor name: %@
#Trial Unable to remove asset with factor name '%@', error: %@
#Trial Removed asset with factor name: %@
Unexpected multiple voices.
Unexpected multiple resources from Trial.
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
MobileAsset
VSVoiceAssetSelection
Trial
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSDownloadMetrics
VoiceServices
VSFeatureFlags
VSUtilities
VSPreviewRequest
NSCopying
VSSpeechEngineVoiceResource
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
VSVoiceSubscription
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusEncoder
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSAnalytics
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VS4CC
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
VSMappedData
Hash
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSAudioData
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
VSNeuralTTSUtils
VSTrialVoice
VSDownloadOptions
VSTrialVoiceResource
VSTrialService
Voice
VoiceResource
encodeObject:forKey:
encodeBool:forKey:
encodeInteger:forKey:
init
decodeObjectOfClass:forKey:
decodeBoolForKey:
decodeIntegerForKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
downloadSize
setDownloadSize:
isPurgeable
setIsPurgeable:
storage
setStorage:
.cxx_destruct
_isPurgeable
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_storage
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
T@"NSNumber",C,N,V_downloadSize
TB,N,V_isPurgeable
Tq,N,V_storage
setMinimumFractionDigits:
setMaximumFractionDigits:
stringWithString:
dictionaryMetrics
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
descriptionFormatter
stringFromNumber:
appendFormat:
appendString:
encodeInt64:forKey:
encodeDouble:forKey:
decodeInt64ForKey:
decodeDoubleForKey:
_clockFactor
timeToSpeakLatency
ttsSynthesisLatency
realTimeFactor
length
numberWithUnsignedInteger:
numberWithBool:
numberWithDouble:
timeToPlaybackLatency
audioQueueLatency
eagerRequestTimeGap
isSynthesisCached
numberWithInteger:
serverStreamFirstPacketLatency
serverStreamLastPacketLatency
cappedRealTimeFactor
dictionaryWithObjects:forKeys:count:
stringOfSourceOfTTS:
description
speechEstimatedOutputBeginTimestamp
utterance
setUtterance:
voiceAssetKey
setVoiceAssetKey:
voiceResourceAssetKey
setVoiceResourceAssetKey:
audioOutputRoute
setAudioOutputRoute:
clientBundleIdentifier
setClientBundleIdentifier:
experimentIdentifier
setExperimentIdentifier:
requestCreatedTimestamp
setRequestCreatedTimestamp:
eagerRequestCreatedTimestampDiffs
setEagerRequestCreatedTimestampDiffs:
synthesisBeginTimestamp
setSynthesisBeginTimestamp:
synthesisEndTimestamp
setSynthesisEndTimestamp:
speechBeginTimestamp
setSpeechBeginTimestamp:
speechEndTimestamp
setSpeechEndTimestamp:
audioStartTimestampDiffs
setAudioStartTimestampDiffs:
serverFirstPacketTimestamp
setServerFirstPacketTimestamp:
serverLastPacketTimestamp
setServerLastPacketTimestamp:
serverStreamedAudioDuration
setServerStreamedAudioDuration:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
isServerTTS
setIsServerTTS:
isServerStreamTTS
setIsServerStreamTTS:
isServerTimeout
setIsServerTimeout:
isServerTTSRacing
setIsServerTTSRacing:
canUseServerTTS
setCanUseServerTTS:
neuralAlignmentStall
setNeuralAlignmentStall:
neuralAudioClick
setNeuralAudioClick:
neuralFallback
setNeuralFallback:
promptCount
setPromptCount:
errorCode
setErrorCode:
sourceOfTTS
setSourceOfTTS:
isSpeechRequest
setIsSpeechRequest:
isCacheHitFromDisk
setIsCacheHitFromDisk:
isCacheHitFromMemory
setIsCacheHitFromMemory:
_isWarmStart
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_canUseServerTTS
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
_isSpeechRequest
_isCacheHitFromDisk
_isCacheHitFromMemory
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_requestCreatedTimestamp
_eagerRequestCreatedTimestampDiffs
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_serverLastPacketTimestamp
_serverStreamedAudioDuration
_audioDuration
_promptCount
_errorCode
_sourceOfTTS
T@"NSString",C,V_utterance
T@"NSString",C,V_voiceAssetKey
T@"NSString",C,V_voiceResourceAssetKey
T@"NSString",C,V_audioOutputRoute
T@"NSString",C,V_clientBundleIdentifier
T@"NSString",C,V_experimentIdentifier
Tq,V_requestCreatedTimestamp
Tq,V_eagerRequestCreatedTimestampDiffs
Tq,V_synthesisBeginTimestamp
Tq,V_synthesisEndTimestamp
Tq,V_speechBeginTimestamp
Tq,R
Tq,V_speechEndTimestamp
Tq,V_audioStartTimestampDiffs
Tq,V_serverFirstPacketTimestamp
Tq,V_serverLastPacketTimestamp
Td,V_serverStreamedAudioDuration
Td,V_audioDuration
TB,V_isWarmStart
TB,V_isServerTTS
TB,V_isServerStreamTTS
TB,V_isServerTimeout
TB,V_isServerTTSRacing
TB,V_canUseServerTTS
TB,V_neuralAlignmentStall
TB,V_neuralAudioClick
TB,V_neuralFallback
Tq,V_promptCount
Tq,V_errorCode
Tq,V_sourceOfTTS
TB,V_isSpeechRequest
TB,V_isCacheHitFromDisk
TB,V_isCacheHitFromMemory
languagesFromMobileAssetAttributes:
setLanguages:
genderFromString:
setGender:
typeFromString:
setType:
footprintFromString:
setFootprint:
amendNameVersionAndSizeWithMobileAssetAttributes:
name
setName:
compatibilityVersionFromMobileAssetAttributes:
count
arrayWithCapacity:
stringByReplacingOccurrencesOfString:withString:
addObject:
arrayWithObjects:count:
integerValue
initFromMobileAssetAttributes:
language
type
footprint
gender
version
isLocal
setIsInstalled:
setIsBuiltInVoice:
assetSize
path
isNeuralVoiceReady:
setIsVoiceReadyToUse:
dealloc
voiceData
voiceKey
descriptiveKey
asset
getLocalUrl
languages
firstObject
stringWithFormat:
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:
attributes
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
wasLocal
state
isVoiceReadyToUse
floatValue
initWithTrialVoice:
voicePath
size
isInstalled
isDownloading
preferenceScore
setVoiceData:
setAsset:
trialVoice
setTrialVoice:
builtInVoicePath
setBuiltInVoicePath:
setVoicePath:
voicePathLock
setVoicePathLock:
_voiceData
_asset
_trialVoice
_builtInVoicePath
_voicePath
_voicePathLock
T@"VSVoiceAsset",&,V_voiceData
T@"MAAsset",&,V_asset
T@"VSTrialVoice",&,V_trialVoice
T@"NSString",&,V_builtInVoicePath
T@"NSString",&,N,V_voicePath
T{_opaque_pthread_mutex_t=q[56c]},N,V_voicePathLock
fileURLWithPath:
setSearchPathURL:
resourceFromTrial:
migrateAssetIfNeededWithAssetType:
initWithType:
returnTypes:
downloadCatalog:options:completion:
queryMetaData:
sharedService
setCountLimit:
numberWithLong:
cachedMAVoiceSelections
objectForKey:
removeObjectForKey:
processInfo
thermalState
standardInstance
ignorePowerAndThermalState
disableDeviceNeuralTTS
longValue
_getVoiceAssetsForType:voiceName:language:gender:footprint:returnTypes:
voiceDataFromAsset:
pickCorrectAssetFromLocalAssets:
setObject:forKey:
bundleWithIdentifier:
bundlePath
preinstallAssetsDirectory
dictionaryWithContentsOfFile:
preinstallAssetsMetadata
array
isEqualToString:
voiceAssetFromPreinstallMetadata:
preinstalledVoicesForLanguage:gender:name:
allKeys
_builtInVoiceForLanguage:
queryForVoiceResourceAsset:returnTypes:
_getResults:
sortUsingComparator:
getLocalFileUrl
contentsOfDirectoryAtPath:error:
_purgeMobileAsset:
selectVoiceResourceWithLanguage:
cachedMAVoiceResources
searchPathURL
_installedVoiceResourceAssetForLanguage:
voiceResourceFromAsset:
_trialVoiceResourceWithLanguage:
_mobileAssetVoiceResourceWithLanguage:
initWithCapacity:
engineMinimumCompatibility
engineCurrentCompatibility
bundleIdentifierForVoiceType:
arrayWithObjects:
addKeyValueArray:with:
arrayWithObject:
typeStringFromType:
addKeyValuePair:with:
footprintStringFromFootprint:
genderStringFromGender:
intValue
definedVoicesWithLanguage:name:type:footprint:
voice
selectVoiceForLang:name:type:gender:footprint:
installedAssetsForType:voicename:language:gender:footprint:
sortedArrayUsingComparator:
lastObject
defaultInstance
subscribedVoicesForClientID:accessoryID:
voiceAssetsForSubscription:
addObjectsFromArray:
activeVoiceAssets
assetId
factorName
containsObject:
assetType
disableAssetCleaning
errorWithDomain:code:userInfo:
inactiveVoiceAssets
_removeTrialVoices:completion:
installedTrialVoiceResources
removeTrialVoiceResource:completion:
cleanMobileAssetVoiceResourcesWithActiveLanguages:
resetCache
availableLanguages
dictionary
setObject:forKeyedSubscript:
removeAllObjects
installedTrialVoicesForType:voiceName:language:footprint:
arrayWithArray:
definedVoiceResourcesWithLanguage:
enableLocalVoices
_localVoiceForLanguageAndNamePath:
_trialVoiceWithLanguage:name:type:footprint:
_mobileAssetVoiceForLanguage:name:type:gender:footprint:
selectPreinstalledVoiceForLanguage:gender:name:
defaultToNonDiscretionaryDownloads
setDiscretionary:
setRequiresPowerPluggedIn:
downloadOptionsWithBattery:
downloadVoiceAsset:options:progressUpdateHandler:
candidateToDownloadForVoice:
isNeuralTTSPlatform
isHomePod
isWatch
predicateWithBlock:
filteredArrayUsingPredicate:
allowsCellularAccess
setAllowCellularData:
discretionary
setAllowDiscretionary:
shouldDownloadTrialVoice:
UTF8String
downloadVoice:withOptions:progress:completion:
downloadNamespaceImmediatelyIfNeededWithOption:completion:
removeVoice:completion:
purgeAsset:
downloadVoiceResource:options:completion:
shouldDownloadTrialResource:
initWithLanguage:
downloadVoiceResource:withOptions:progress:completion:
downloadTrialVoiceResource:options:completion:
removeVoiceResource:completion:
removeMobileAssetVoiceResource:completion:
results
queryForLanguage:forType:voiceName:gender:footprint:returnTypes:
setAllowsCellularAccess:
lastFetchDate
date
timeIntervalSinceDate:
currentRunLoop
dateWithTimeIntervalSinceNow:
runUntilDate:
startCatalogDownload:options:then:
isStalled
expectedTimeRemaining
totalExpected
totalWritten
attachProgressCallBack:
startDownload:then:
removeTrialVoice:completion:
defaultCenter
postNotificationName:object:
purgeSync
cancelDownloadSync
wasPurgeable
shouldUseNeuralVoice:
isH12Platform
isLowPowerModeEnabled
pathWithComponents:
voiceDataWithBundleIdentifier:attributes:voicePathCallback:
componentsSeparatedByString:
typeFromBundleIdentifier:
sharedManager
getLatestAssetFromArray:
isVoiceAssetWellDefined:
migrateAssetsWithProgress:
builtInVoices
selectVoiceResourceAssetForLanguage:
definedVoicesForLanguage:voiceName:type:footprint:
cleanUnusedAssets
cleanOldMobileAssetVoiceResources
resetResourcesCache
installedVoiceResources
downloadVoiceAsset:useBattery:progressUpdateHandler:
preferredDownloadForVoice:
cancelDownload:completion:
removeVoiceAsset:completion:
downloadVoiceResource:completion:
downloadVoiceResourceCatalogWithCompletion:
downloadCatalog:options:
_downloadAsset:options:progress:completion:
installedLocalVoices
assetQueryQueue
setAssetQueryQueue:
setCachedMAVoiceSelections:
setCachedMAVoiceResources:
trialService
setTrialService:
_assetQueryQueue
_cachedMAVoiceSelections
_cachedMAVoiceResources
_trialService
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
T@"NSCache",&,N,V_cachedMAVoiceSelections
T@"NSCache",&,N,V_cachedMAVoiceResources
T@"VSTrialService",&,N,V_trialService
isInternalBuild
initWithSuiteName:
boolForKey:
setBool:forKey:
floatForKey:
setFloat:forKey:
stringForKey:
enableAudioDump
setEnableAudioDump:
logSensitiveText
setLogSensitiveText:
disableCache
setDisableCache:
setDisableAssetCleaning:
allowAnyAssetSubscriber
setAllowAnyAssetSubscriber:
setEnableLocalVoices:
whisper
setWhisper:
serverTTSTimeout
setServerTTSTimeout:
deviceTTSWaitTime
setDeviceTTSWaitTime:
defaultVolume
setDefaultVolume:
forceServerTTS
setForceServerTTS:
disableServerTTS
setDisableServerTTS:
disableInlineStreamTTS
setDisableInlineStreamTTS:
disableDeviceRacing
setDisableDeviceRacing:
disableOspreyStreaming
setDisableOspreyStreaming:
streamBufferDuration
setStreamBufferDuration:
useBetaVoice
setUseBetaVoice:
ospreyEndpointURL
setOspreyEndpointURL:
simulateNetworkStall
setSimulateNetworkStall:
setDisableDeviceNeuralTTS:
useSSMLInput
disableMobileAssetURLReset
setIgnorePowerAndThermalState:
disableAssetUpdate
setDisableAssetUpdate:
setDefaultToNonDiscretionaryDownloads:
internalDefaults
setInternalDefaults:
_internalDefaults
T@"NSUserDefaults",&,N,V_internalDefaults
TB,N
Tf,N
T@"NSString",C,N
TB,R,N
bundleForClass:
pathForResource:ofType:
arrayWithContentsOfFile:
setWithArray:
rangeOfString:
substringWithRange:
fallbackLanguageForLanguage:
downloadDuration
numberWithFloat:
initWithVoiceName:languageCode:gender:
endMetrics
isCellularAllowed
setIsCellularAllowed:
downloadProgress
setDownloadProgress:
setupTimeInterval
setSetupTimeInterval:
voiceDownloadKey
downloadBeginTimestamp
downloadEndTimestamp
_isCellularAllowed
_discretionary
_downloadProgress
_setupTimeInterval
_voiceDownloadKey
_downloadBeginTimestamp
_downloadEndTimestamp
T@"NSString",R,V_voiceDownloadKey
Tq,R,V_downloadBeginTimestamp
Tq,R,V_downloadEndTimestamp
TB,V_isCellularAllowed
TB,V_discretionary
T@"NSNumber",C,V_downloadSize
Tf,V_downloadProgress
Td,V_setupTimeInterval
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
code
resourceValuesForKeys:error:
longLongValue
removeItemAtURL:error:
getResourceValue:forKey:error:
compare:
subarrayWithRange:
directorySize:
removeDirectory:
cleanDirectory:withLRULimit:
cleanDirectory:withDateOlderThan:
isTrialEnabled
isLowPowerDeviceNeuralEnabled
hasANE
hasAMX
isHomeHub
isSeedBuild
languageCode
setLanguageCode:
voiceName
setVoiceName:
previewType
setPreviewType:
copyWithZone:
_languageCode
_voiceName
_previewType
T@"NSString",C,N,V_languageCode
T@"NSString",C,N,V_voiceName
Tq,N,V_previewType
TQ,N,V_requestCreatedTimestamp
resource
setResource:
.cxx_construct
_resource
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_resource
asbd
processMarkerBuffer
dataWithBytesNoCopy:length:freeWhenDone:
characterAtIndex:
utf8BytesForChar:
setStartTime:
utf16OffsetFromUTF8:
setTextRange:
stringWithUTF8String:
initWithCallback:
synthesisCallback:
pcmData
mutablePCMData
sampleBuffer
markerBuffer
wordTimingInfos
phonemeBuffer
phonemes
setState:
error
setError:
numOfPromptsTriggered
setNumOfPromptsTriggered:
neuralDidFallback
setNeuralDidFallback:
hasAlignmentStall
setHasAlignmentStall:
hasAudioClick
setHasAudioClick:
text
setText:
stopMark
setStopMark:
callback
setCallback:
wordTimings
setWordTimings:
setAsbd:
samplesProcessed
setSamplesProcessed:
lastUTF8Offset
setLastUTF8Offset:
lastUTF16Offset
setLastUTF16Offset:
_samples
_markers
_phonemeBuffer
_neuralDidFallback
_hasAlignmentStall
_hasAudioClick
_state
_error
_numOfPromptsTriggered
_text
_stopMark
_callback
_wordTimings
_samplesProcessed
_lastUTF8Offset
_lastUTF16Offset
_asbd
T@"NSString",&,N,V_text
Tq,N,V_stopMark
T@?,C,N,V_callback
Tq,N,V_state
T@"NSError",&,N,V_error
T@"NSMutableArray",&,N,V_wordTimings
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
TQ,N,V_samplesProcessed
TQ,N,V_lastUTF8Offset
TQ,N,V_lastUTF16Offset
TQ,N,V_numOfPromptsTriggered
TB,N,V_neuralDidFallback
TB,N,V_hasAlignmentStall
TB,N,V_hasAudioClick
initializeWithResourcePath:
lock
unlock
pathExtension
mimeForFileExtension:
loadResourceAtPath:mimeType:error:
currentCallbackResult
domain
isUserCancelError:
hasPhaticResponses:
initWithVoicePath:resourcePath:
setPitch:
setRate:
setVolume:
loadResource:error:
unloadResource:
synthesizeText:loggable:callback:
stopAtMarker:
preheat
pcmBufferSize
setPcmBufferSize:
rate
pitch
volume
synthesizer
setSynthesizer:
setCurrentCallbackResult:
synthesisLock
setSynthesisLock:
_rate
_pitch
_volume
_pcmBufferSize
_synthesizer
_currentCallbackResult
_synthesisLock
T^v,N,V_synthesizer
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
T@"NSLock",&,N,V_synthesisLock
TQ,N,V_pcmBufferSize
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
initWithFormat:
initWithContentsOfFile:
rangeOfString:options:range:
hasPrefix:
hasSuffix:
insertString:atIndex:
replaceCharactersInRange:withString:
string
vs_markerStringForContext:
stringByAppendingString:
regularExpressionWithPattern:options:error:
matchesInString:options:range:
whitespaceCharacterSet
characterIsMember:
punctuationCharacterSet
rangeAtIndex:
_vs_countPhoneticSyllables_lhp:
numberOfRanges
containsString:
_vs_countPhoneticSyllables_xsampa:
stringByReplacingMatchesInString:options:range:withTemplate:
addCharactersInRange:
vs_isCJKCharacter:
initWithString:
removeLastObject
raise:format:
vs_textifyEmojiWithLanguage:
vs_substituteAudioWithLocalPath
vs_insertContextInfo:
vs_measurePauses
vs_countPhoneticSyllables
vs_removePhonetics
vs_removeSpeechTags
vs_hasCJKCharacter
vs_convertToSSML
handleFailureInFunction:file:lineNumber:description:
stringByStandardizingPath
initWithContentsOfURL:
filePathURL
attributesOfItemAtPath:error:
textRange
allValues
doubleValue
pathForResource:ofType:inDirectory:
timingPlistForLanguage:
timingInfosFrom:withText:
estimatedTTSWordTimingForText:withLanguage:voiceName:
T@"NSDictionary",&,N,V_wordTimings
objectAtIndex:
mutableCopy
removeObjectAtIndex:
replaceObjectAtIndex:withObject:
modelIdentifier
recognitionResultWithModelIdentifier:classIdentifiers:values:
elementCount
getElementClassIdentifier:value:atIndex:
bundleWithPath:
load
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
TQ,R
T#,R
T@"NSString",R,C
actionForRecognitionResult:
actionForRecognitionResults:
instancesRespondToSelector:
initialize
recognitionResultByReplacingValueForClassIdentifier:withValue:
valueOfFirstElementWithClassIdentifier:
createHandler
setRecognitionAction:
recognitionAction
initWithClient:accessory:voice:
clientID
setClientID:
accessoryID
setAccessoryID:
setVoice:
_clientID
_accessoryID
_voice
T@"NSString",&,N,V_clientID
T@"NSString",&,N,V_accessoryID
T@"VSVoiceAsset",&,N,V_voice
reset
_init
cancel
setDelegate:
setActive:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
recognitionSession:openURL:
recognitionSession:openURL:completion:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
_notifyDelegateActionStarted
_continueAfterDeferredStart
perform
_hasDeferredStartCallback
_currentRecognizeAction
_debugDumpPath
setAudioType:
setKeepAudioSessionActive:
initWithModelIdentifier:
_setAction:
_isRecognizing
_isActivelyRecognizing
completionType
_setBluetoothInputAllowed:
invalidate
stopSpeakingAtNextBoundary:synchronously:error:
cancelMaintainingKeepAlive:
methodSignatureForSelector:
invocationWithMethodSignature:
setSelector:
setTarget:
setArgument:atIndex:
retainArguments
scheduledTimerWithTimeInterval:invocation:repeats:
_setSession:
_setDebugDumpPath:
_setDebugDumpEnabled:
_setPreferredEngine:
_setAudioInputPath:
_setInputLevelUpdateInterval:
_setEngineResetRequired:
_handledThreadedResults:nextAction:
spokenFeedbackString
spokenFeedbackAttributedString
resultDisplayString
statusDisplayString
_inputLevel
_inputLevelDB
_keywordAtIndex:
_keywordCount
_scrambledKeywordsAndAddToSet:
_nextKeywordUsingCursors:
removeObject:
allObjects
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_topLevelKeywords
_keywordIndexChanged
postNotificationName:object:userInfo:
_beginSpeakingAttributedString:
beginSpeakingString:
_beginSpeakingString:attributedString:
_notifyDelegateFinishedSpeakingWithError:
initForInputFeedback
setAttributedText:
setOutputPath:
startSpeakingRequest:
beginNextAction
isRecognizing
isActivelyRecognizing
isFinished
isValid
hasDeferredAction
isBusy
nextActionWillTerminateSession
nextActionWillRecognize
setSensitiveActionsEnabled:
sensitiveActionsEnabled
setBluetoothInputAllowed:
_actionCompleted:nextAction:error:
_actionStarted:
_notifyDelegateOpenURL:completion:
_recognitionResultHandlingThread
recognitionResultHandlingThread:didHandleResults:nextAction:
displayResultString
displayStatusString
setInputLevelUpdateInterval:
inputLevel
inputLevelDB
setKeywordPhase:
keywordAtIndex:
keywordCount
_keywordsForModelIdentifier:
beginSpeakingFeedbackString
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
setDebugDumpEnabled:
debugDumpPath
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setPreferredEngine:
setPerformRecognitionHandlerActions:
_modelIdentifier
_keepAlive
_delegate
_currentAction
_handlingThread
_languageID
_audioInputPath
_levelInterval
_keywordPhase
_sessionFlags
exchangeObjectAtIndex:withObjectAtIndex:
initWithStreamDescription:
initFromFormat:toFormat:
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
streamDescription
data
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
bytes
convertToBuffer:error:withInputFromBlock:
audioBufferList
appendBytes:length:
packetCount
packetDescriptions
encodeChunk:
initWithSourceASBD:
setOpusDataHandler:
setErrorHandler:
beginEncoding
endEncoding
opusDataHandler
errorHandler
fromFormat
setFromFormat:
toFormat
setToFormat:
converter
setConverter:
outputBuffer
setOutputBuffer:
opusDataOffset
setOpusDataOffset:
_opusDataHandler
_errorHandler
_fromFormat
_toFormat
_converter
_outputBuffer
_opusDataOffset
T@?,C,N,V_opusDataHandler
T@?,C,N,V_errorHandler
T@"AVAudioFormat",&,N,V_fromFormat
T@"AVAudioFormat",&,N,V_toFormat
T@"AVAudioConverter",&,N,V_converter
T@"AVAudioCompressedBuffer",&,N,V_outputBuffer
Tq,N,V_opusDataOffset
vs_stringFrom4CC:
beginChunkDecoderForStreamDescription:
decodeChunk:outError:
appendData:
endChunkDecoding
_opusDecoder:
initWithLength:
mutableBytes
dataWithBytes:length:
sharedInstance
decodeChunks:streamDescription:outError:
_decoder
_session
setResultDisplayString:
setStatusDisplayString:
setSpokenFeedbackString:
setSpokenFeedbackAttributedString:
completeWithNextAction:error:
_resultString
_statusString
_spokenString
_spokenStringIsAttributed
localizations
preferredLocalizationsFromArray:forPreferences:
URLForResource:withExtension:subdirectory:localization:
predefinedStringForKey:language:table:
appendRandomizationKey:withCount:
localizedStringForKey:language:table:
localizedOOBStringForKey:language:
localizedInterstitialStringForKey:language:
localizedOOBStringForKey:language:gender:
_disambiguationContext
_reset
setRepeatedSpokenFeedbackString:
repeatedSpokenFeedbackString
sequenceTag
setSequenceTag:
knownValueForClassIdentifier:
setKnownValue:phoneticValue:forClassIdentifier:
knownValuesForClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
ambiguousValuesForClassIdentifier:
setAmbiguousValues:phoneticValues:forClassIdentifier:
_keywords
setKeywords:
_createRecognitionInstanceWithCallbacks:info:
_actionForEmptyResults
_repeatedSpokenFeedbackString
_sequenceTag
_knownValues
_knownPhoneticValues
_ambiguousValues
_ambiguousPhoneticValues
_context
languageMapping
dataWithContentsOfFile:
characterSetWithBitmapRepresentation:
characterSet
valueWithRange:
unspeakableRangeOfText:
setCharacterSet:
_characterSet
T@"NSCharacterSet",&,N,V_characterSet
_setDebugDumpEnabled:dumpPath:
_configureNewRecognitionInstance
_setResults:
_releaseFromPrepare
requiresThreadedProcessing
handleResults:withHandler:
makeObjectsPerformSelector:withObject:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handleRecognitionCompleted:withResults:error:
_recognition
_results
_recognizeFlags
reportEvent:payload:
OOBNeedsToBeMeasured
OOBTriggeredDate
setOOBNeedsToBeMeasured:
reportInstrumentMetrics:
reportDownloadMetrics:
componentsJoinedByString:
decodeObjectOfClasses:forKey:
vocalizerConfig
URLByAppendingPathComponent:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
voiceConfig
_defaultVoices
defaultVoiceNameForGender:
resourceMimeTypes
resourceList
defaultVoiceGender
defaultVoiceType
defaultVoice
setVoiceConfig:
setVocalizerConfig:
setResourceList:
setResourceMimeTypes:
_languages
_searchPathURL
_voiceConfig
_vocalizerConfig
_resourceList
_resourceMimeTypes
T@"NSDictionary",C,N,V_voiceConfig
T@"NSDictionary",&,N,V_vocalizerConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSDictionary",C,N,V_resourceMimeTypes
T@"NSURL",C,N,V_searchPathURL
rangeValue
allocWithZone:
startTime
whitespaceAndNewlineCharacterSet
lengthOfBytesUsingEncoding:
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
wordTimingInfoFrom:timestamps:
utf16TimingInfoWithUTF8Range:withText:
adjustWordTimingInfo:forContext:
_startTime
_textRange
Td,N,V_startTime
T{_NSRange=QQ},N,V_textRange
stopListening
_initShared
_spokenLanguageChanged:
addObserver:selector:name:object:
beginReportingChanges
makeObjectsPerformSelector:
stopReportingChanges
removeObserver:name:object:
_flush
initWithModelIdentifier:classIdentifier:
_enqueueRequest:
performUpdateForModelIdentifier:classIdentifier:
coalescedRequest:
timerWithTimeInterval:target:selector:userInfo:repeats:
mainRunLoop
addTimer:forMode:
setFireDate:
classIdentifier
sharedListener
sharedListenerIfExists
startListening
_lock
_updateRequestQueue
_dataProviders
_flushTimer
_isListening
_modelID
_classID
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
_setConfirmed:
setConfirmedAction:
confirmedAction
setDeniedAction:
deniedAction
_confirmedAction
_deniedAction
_confirmFlags
setURL:
_url
pathForResource:ofType:inDirectory:forLocalization:
initFileURLWithPath:
initWithSpokenFeedbackString:willTerminate:
_shouldTerminate
canLogRequestText
copy
encodeValueOfObjCType:at:
encodeInt32:forKey:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
decodeValueOfObjCType:at:size:
decodeInt32ForKey:
numberWithUnsignedLongLong:
logText
initWithAudioData:playerStreamDescription:
initWithIdentifier:
hasValidAudio
audioSessionID
setAudioSessionID:
audioData
decoderStreamDescription
playerStreamDescription
enqueue
setEnqueue:
identifier
setIdentifier:
siriRequestId
setSiriRequestId:
pcmDataSize
setPcmDataSize:
stopHandler
setStopHandler:
_enqueue
_audioSessionID
_audioData
_identifier
_siriRequestId
_pcmDataSize
_stopHandler
_decoderStreamDescription
_playerStreamDescription
T@"NSString",C,N,V_clientBundleIdentifier
T@"NSUUID",C,N,V_accessoryID
TQ,N,V_pcmDataSize
T@?,C,N,V_stopHandler
TI,N,V_audioSessionID
T@"NSData",R,C,N,V_audioData
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
TB,N,V_enqueue
T@"NSString",&,N,V_identifier
T@"NSUUID",&,N,V_siriRequestId
initWithCondition:
initWithHandler:results:
_handleRequests
detachNewThreadSelector:toTarget:withObject:
unlockWithCondition:
nextAction
lockWhenCondition:
handler
setNextAction:
_notifyRequestHandled:
performSelectorOnMainThread:withObject:waitUntilDone:
_requests
_resultHandlingFlags
_handler
_action
initWithDictionaryRepresentation:
matchedString:forTokenInRange:
initWithContentsOfPath:languageIdentifier:
processedTextFromString:
_rules
_tokenizer
boolValue
_matchPattern
_replacement
_caseSensitive
_eatPunctuation
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
formattedArg
setAttributes:range:
contextInfoString
contextInfo
isEqualToDictionary:
voiceType
shouldWhisper
customResourceURLs
isEqualToArray:
setVoiceType:
outputPath
shouldCache
setShouldCache:
shouldWaitCurrentSpeaking
setShouldWaitCurrentSpeaking:
setShouldWhisper:
setContextInfo:
disableCompactVoiceFallback
setDisableCompactVoiceFallback:
resourceListURL
setResourceListURL:
resourceSearchPathURL
setResourceSearchPathURL:
setCustomResourceURLs:
decodePropertyListForKey:
enumerateKeysAndObjectsUsingBlock:
logUtterance
isSimilarTo:
retryDeviceOnNetworkStall
setRetryDeviceOnNetworkStall:
attributedText
shouldStreamAudioData
setShouldStreamAudioData:
pauseHandler
setPauseHandler:
pointer
setPointer:
_shouldWaitCurrentSpeaking
_disableDeviceRacing
_shouldCache
_shouldWhisper
_disableCompactVoiceFallback
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_footprint
_voiceType
_gender
_outputPath
_contextInfo
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_attributedText
_pauseHandler
_pointer
T@"NSAttributedString",C,N,V_attributedText
TB,N,V_shouldStreamAudioData
T@"NSString",C,N,V_utterance
T@?,C,N,V_pauseHandler
Tq,N,V_pointer
T@"NSString",C,N,V_text
Tq,N,V_footprint
Tq,N,V_voiceType
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
TB,N,V_shouldWaitCurrentSpeaking
TB,N,V_disableDeviceRacing
TB,N,V_shouldCache
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_shouldWhisper
T@"NSDictionary",C,N,V_contextInfo
TB,N,V_disableCompactVoiceFallback
TB,N,V_forceServerTTS
TB,N,V_canUseServerTTS
TB,N,V_retryDeviceOnNetworkStall
T@"NSURL",C,N,V_resourceListURL
T@"NSURL",C,N,V_resourceSearchPathURL
T@"NSArray",&,N,V_customResourceURLs
createFileAtPath:contents:attributes:
fileHandleForUpdatingAtPath:
fileDescriptor
closeFile
initWithFilePath:initialSize:
removeItemAtPath:error:
_convertToFallbackMemory
_appendToFallbackMemory:
_appendToMappedMemory:
bytesAtOffset:
filePath
setFilePath:
totalLength
setTotalLength:
mmappedData
setMmappedData:
mappedLength
setMappedLength:
fallbackInMemoryData
setFallbackInMemoryData:
shouldCleanFile
setShouldCleanFile:
_shouldCleanFile
_filePath
_totalLength
_mmappedData
_mappedLength
_fallbackInMemoryData
T@"NSString",&,N,V_filePath
TQ,N,V_totalLength
T^v,N,V_mmappedData
TQ,N,V_mappedLength
T@"NSMutableData",&,N,V_fallbackInMemoryData
TB,N,V_shouldCleanFile
stringWithCapacity:
stringByAppendingFormat:
sha256hex
preinstalledAudioHashForLanguage:name:
completion
setCompletion:
_completion
T@?,C,N,V_completion
validatePrewarmRequest:
playVoicePreviewForLanguageCode:voiceName:previewType:completion:
startVoicePreviewRequest:reply:
stopPlayingVoicePreview
stopVoicePreview
initWithAccessoryID:
mainBundle
preferredLocalizations
processName
processIdentifier
opaqueSessionID
speechSynthesizer:didFinishPrewarmRequest:withError:
prewarmIfNeededWithRequest:reply:
queryPhaticCapabilityWithRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
speechSynthesizer:didStartPlayingPreviewRequest:
stopPresynthesizedAudioRequest:
stopSpeechRequest:atMark:
currentRequest
pauseSpeechRequest:atMark:
_setDelegate:
validateRequest:
startSynthesisRequest:
startSpeechRequest:
validateAudioRequest:
startPresynthesizedAudioRequest:
validateAudioCachingRequest:
cachePresynthesizedAudioRequest:
_stopSpeakingRequest:atNextBoundary:synchronously:
currentAudioRequest
_stopSpeakingPresynthesizedAudioRequest:synchronously:
_pauseSpeakingRequestAtNextBoundary:synchronously:
_continueSpeakingRequest
isSystemSpeakingOnBehalfOfCurrentConnection
isSystemSpeaking
continueSpeechRequest:
decimalDigitCharacterSet
numberWithInt:
characterClassCountForUtterance:language:
objectAtIndexedSubscript:
unsignedIntegerValue
estimateDurationWithRequest:reply:
speechSynthesizer:withRequest:didReceiveTimingInfo:
valueWithNonretainedObject:
durationRequests
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:daemonDidCrashWithError:
forwardStreamObject:
invokeDaemon:
killDaemon
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
cleanUnusedAssets:
getLocalVoiceAssetsForLanguage:reply:
getLocalVoiceResources:
getVoiceResourceForLanguage:reply:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
triggerCellularDownloadedVoiceAssets:withClientID:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getAllVoiceSubscriptionsWithReply:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
availableVoicesForLanguageCode:
availableFootprintsForVoice:languageCode:
errorWithReason:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:didReceiveTimingInfo:
connection:speechRequest:didGenerateAudioChunk:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
connection:previewRequestDidStartPlaying:
connection:invalidatedWithError:
prewarmIfNeededWithRequest:
queryPhaticCapability:
startSynthesizingRequest:
startSpeakingPresynthesizedAudioRequest:
cancelRequest:
cancelAudioRequest:
stopSpeakingPresynthesizedAudioSynchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
continueSpeakingWithError:
isSpeaking
speechString
minimumRate
maximumRate
estimateDurationOfRequest:
estimateDurationOfRequest:completion:
getLocalVoiceAssets:
setAutoDownloadedVoiceAssets:
triggerCellularDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
getAllAutoDownloadedVoiceAssets:
availableLanguageCodes
delegate
setLanguage:
setDurationRequests:
_queue
_callbackQueue
_xpcConnection
_synthesizerFlags
_language
_durationRequests
T@"NSString",C,N,V_language
T@"NSMutableDictionary",&,N,V_durationRequests
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
T@"NSString",&,N,V_voice
migrateDefaults
arrayForKey:
dictionaryForKey:
dictionaryRepresentation
dictionaryRepresentationOfVoices:
UUID
UUIDString
T@"VSPreferencesInterface",R
setSubscribedVoices:forClientID:accessoryID:
removeSubscriptionsForAccessory:
setOOBTriggeredDate:
setLastTTSRequestDate:
lastTTSRequestDate
deviceUUID
defaults
setDefaults:
setLock:
_defaults
T@"NSUserDefaults",&,N,V_defaults
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T@"NSDate",&,N
T@"NSString",R,N
initWithMachServiceName:options:
maintainWithAudioType:keepAudioSessionActive:
interfaceWithProtocol:
setRemoteObjectInterface:
_ensureKeepAliveMaintenance
setInterruptionHandler:
resume
_serverConnection
remoteObjectProxy
_remoteKeepAlive
audioType
active
keepAudioSessionActive
_audioType
_active
_keepAudioSessionActive
Tq,N,V_audioType
TB,N,V_active
TB,N,V_keepAudioSessionActive
setConnection:
updateWithConnectionIdentifier:
queryPhaticCapabilityWithRequest:reply:
startSpeechRequest:reply:
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
getLocalVoicesForLanguage:reply:
getLocalVoiceResourcesReply:
setClasses:forSelector:argumentIndex:ofReply:
_connectionInvalidated
setInvalidationHandler:
xpcConnection
speechRequestDidStart:
speechRequestDidPause:
speechRequestDidContinue:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequest:didReportInstrumentMetrics:
speechRequest:didReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didFinishWithInstrumentMetrics:error:
audioRequestDidStart:
audioRequest:didStopAtEnd:error:
audioRequest:didReportInstrumentMetrics:error:
previewRequestDidStartPlaying:
setExportedInterface:
delegateWrapper
setExportedObject:
synchronousRemoteObjectProxyWithErrorHandler:
remoteObjectProxyWithErrorHandler:
requests
enumerateObjectsUsingBlock:
audioRequests
concurrentSynthesisRequests
setXpcConnection:
_remoteObjectWithErrorHandler:
getLocalPreviewRequest:
previewRequests
_remoteObject
insertObject:atIndex:
_remoteObjectSync
localizedDescription
setDelegateWrapper:
threadSafeQueue
setThreadSafeQueue:
_delegateWrapper
_threadSafeQueue
T@"NSXPCConnection",&,N,V_xpcConnection
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
getLocalRequest:
getLocalAudioRequest:
setCurrentRequest:
setRequests:
setConcurrentSynthesisRequests:
setCurrentAudioRequest:
setAudioRequests:
setPreviewRequests:
connection
_currentRequest
_concurrentSynthesisRequests
_currentAudioRequest
_audioRequests
_previewRequests
_connection
T@"VSSpeechRequest",&,N,V_currentRequest
T@"NSMutableArray",&,N,V_requests
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
T@"VSPresynthesizedAudioRequest",&,N,V_currentAudioRequest
T@"NSMutableArray",&,N,V_audioRequests
T@"NSMutableArray",&,N,V_previewRequests
T@"VSSpeechConnection",W,N,V_connection
setAudioData:
setPacketCount:
setPacketDescriptions:
mutableAudioData
mutableDescription
setData:
encodeBytes:length:forKey:
decodeBytesForKey:returnedLength:
duration
totalFrames
concatenateWithAudio:
setMutableAudioData:
setMutableDescription:
_packetCount
_mutableAudioData
_mutableDescription
T@"NSMutableData",&,N,V_mutableAudioData
T@"NSMutableData",&,N,V_mutableDescription
T@"NSData",&,N
Tq,N,V_packetCount
nameKey
lowercaseString
isBuiltInVoice
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
_name
_type
T@"NSString",C,N,V_name
Tq,N,V_type
TB,N,V_isInstalled
TB,N,V_isBuiltInVoice
TB,N,V_isVoiceReadyToUse
anonymousListener
setQueue:
setHandler:
setListener:
endpoint
setEndpoint:
_setQueue:
invokeUpdateWithObject:
initWithBlock:
initWithListenerEndpoint:
configuredEndpointWithUpdateHandler:withConnection:
remoteUpdateHanderForEndpoint:
listener:shouldAcceptNewConnection:
queue
listener
_endpoint
_listener
T@"NSXPCListenerEndpoint",&,N,V_endpoint
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
T@"NSXPCListener",&,N,V_listener
T@?,C,N,V_handler
_block
hasCompactNeuralFallback:
isNeuralFallbackCondition
hasOTAANEModel:
isANEModelCompiled:
compileANEModel:
isANECompilationPlatform
initWithLanguage:name:
factor
initWithFactorName:
hasLevel
level
directoryValue
hasAsset
hasPath
metadata
initWithFactorLevel:
setPath:
setVersion:
setAssetSize:
_path
_version
_assetSize
T@"NSString",&,N,V_path
TQ,N,V_version
TQ,N,V_assetSize
Tq,N,V_compatibilityVersion
allowCellularData
allowDiscretionary
_allowCellularData
_allowDiscretionary
TB,N,V_allowCellularData
TB,N,V_allowDiscretionary
clientWithIdentifier:
refreshTrialClient
addUpdateHandlerForNamespaceName:usingBlock:
removeUpdateHandlerForToken:
refresh
factorLevelsWithNamespaceName:
setDiscretionaryBehavior:
levelForFactor:withNamespaceName:
fileValue
rolloutIdentifiersWithNamespaceName:
setWithObject:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
defaultDownloadOptions
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
removeLevelsForFactors:withNamespace:queue:completion:
versionFactorNameWithFactorName:
T@"VSTrialService",R,N
cachedVoices
cachedResources
_directoryOfFactorName:
_fileOfFactorName:
_downloadFactorName:withOptions:progress:completion:
_removeAssetWithFactorName:completion:
triClient
setTriClient:
setCachedVoices:
setCachedResources:
trialNotificationToken
setTrialNotificationToken:
downloadQueue
setDownloadQueue:
clientRefreshLock
setClientRefreshLock:
_triClient
_cachedVoices
_cachedResources
_trialNotificationToken
_downloadQueue
_clientRefreshLock
T@"TRIClient",&,N,V_triClient
T@"NSArray",&,N,V_cachedVoices
T@"NSArray",&,N,V_cachedResources
T@"<TRINotificationToken>",&,N,V_trialNotificationToken
T@"NSObject<OS_dispatch_queue>",&,N,V_downloadQueue
T@"NSLock",&,N,V_clientRefreshLock
selectVoiceWithLanguage:name:type:footprint:
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
v20@0:8B16
q16@0:8
v24@0:8q16
v16@0:8
@"NSString"
@"NSNumber"
@24@0:8q16
d16@0:8
v24@0:8d16
Q16@0:8
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
@"VSVoiceAsset"
@"MAAsset"
@"VSTrialVoice"
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8@16q24@32q40q48q56
@32@0:8@16q24
@20@0:8B16
q24@0:8@16
B24@0:8@16
B24@0:8@?16
@56@0:8@16@24q32q40q48
@40@0:8@16q24@32
@48@0:8@16@24q32q40
@48@0:8q16@24@32q40
@56@0:8q16@24@32q40q48
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@16@?24
v24@0:8@?16
@64@0:8q16@24@32q40q48q56
@32@0:8@16@24
v48@0:8@16@24@?32@?40
@40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSCache"
@"VSTrialService"
f16@0:8
v20@0:8f16
@"NSUserDefaults"
@40@0:8@16@24q32
Q24@0:8@16
v32@0:8@16Q24
v32@0:8@16@24
@24@0:8^{_NSZone=}16
v24@0:8Q16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
@24@0:8@?16
i20@0:8i16
^v16@0:8
Q20@0:8S16
Q24@0:8Q16
@?16@0:8
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<TTSSynthesizer::Marker, std::allocator<TTSSynthesizer::Marker>>="__begin_"^{Marker}"__end_"^{Marker}"__end_cap_"{__compressed_pair<TTSSynthesizer::Marker *, std::allocator<TTSSynthesizer::Marker>>="__value_"^{Marker}}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@"NSError"
@"NSMutableArray"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@40@0:8@16@24^@32
@32@0:8@16^@24
@36@0:8@16B24@?28
v24@0:8^v16
@"VSSpeechSynthesisCallbackResult"
@"NSLock"
B20@0:8S16
@40@0:8@16@24@32
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
B40@0:8^@16^@24q32
B20@0:8B16
v40@0:8@16@24@32
^{__CFDictionary=}16@0:8
v52@0:8@16@24B32@36@44
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateOpenURLAsync"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@"AVAudioFormat"
@"AVAudioConverter"
@"AVAudioCompressedBuffer"
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
^{OpaqueAudioConverter=}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
@28@0:8@16i24
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
@"NSCharacterSet"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@20@0:8i16
@28@0:8@16B24
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
@"NSData"
@"NSUUID"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
@32@0:8@16Q24
{_NSRange=QQ}24@0:8@16
^v24@0:8Q16
@"NSMutableData"
B48@0:8@16@24q32@?40
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPreviewRequest"24
v32@0:8@"VSSpeechConnection"16@"NSError"24
v48@0:8@16@24q32@?40
@36@0:8@16q24B32
@28@0:8q16B24
B36@0:8q16B24^@28
B28@0:8B16^@20
B24@0:8^@16
d24@0:8@16
v64@0:8@16@24q32q40q48@?56
@"VSSpeechConnection"
{?="delegateStartWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateStreamSynthesisAudioData"b1"willUseInput"b1"delegateDidStartPreviewRequest"b1}
@"<VSSpeechSynthesizerDelegate>"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv24@0:8@16
Vv32@0:8@16@?24
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv24@0:8@"NSString"16
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
v32@0:8@16q24
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@"TRIClient"
@"<TRINotificationToken>"
|?5^
