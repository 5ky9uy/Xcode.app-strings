_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_isPurgeable
_storage
v8@?0
audio_duration
audio_output_route
audio_queue_latency
can_use_server_tts
character_count
client_bundle_identifier
error_code
experiment_identifier
is_server_stream_tts
is_server_timeout
is_server_tts_racing
is_speech_request
is_synthesis_cached
is_warm_start
neural_alignment_stall
neural_audio_click
neural_fallback
prompt_count
real_time_factor
server_first_packet_latency
server_last_packet_latency
server_streamed_audio_duration
source_of_tts
synthesis_to_speech_time_gap
tts_and_playback_total_latency
tts_synthesis_latency
tts_total_latency
voice_asset_key
voice_resource_asset_key
  "%@": %@,
  "%@": "%@",
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_promptCount
_sourceOfTTS
_errorCode
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_audioDuration
_serverStreamedAudioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
is_server_tts
osprey_round_trip
osprey_streaming
ace_round_trip
ace_inline_streaming
device
inline_tts
audio_request
device_cached_synthesis
unknown
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.notification.voice-purge
VSMobileAssetServiceErrorDomain
VSTrialServiceErrorDomain
MobileAssetProperties
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
/private/var/mobile/Library/VoiceServices/voices/
%@.tmp
VSMobileAssetsManager.m
negative size
v16@?0q8
com.apple.voiced.assetQueryQueue
%@_%@_%@_%@_%@
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"MAAsset"8@"MAAsset"16
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
VSMobileAssetsManager
Cleaning voice assets is disabled in internal setting.
v16@?0@"NSError"8
v24@?0@"NSMutableArray"8q16
%@_%@
B24@?0@"VSTrialVoice"8@"NSDictionary"16
q24@?0@"VSTrialVoice"8@"VSTrialVoice"16
v20@?0d8f16
v12@?0f8
v20@?0B8@"NSError"12
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
Info.plist
CFBundleIdentifier
@"NSString"8@?0
local_voice
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
enableTrial
enableAudioDump
logSensitiveText
DisableCaching
DisableAssetCleaning
AllowAnyAssetSubscription
EnableLocalVoices
whisper
ServerTTSTimeout
DeviceTTSWaitTime
defaultVolume
defaultPitch
defaultRate
forceServerTTS
disableServerTTS
disableInlineStreamTTS
disableDeviceRacing
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
simulateNetworkStall
disableDeviceNeuralTTS
useSSMLInput
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
defaultToNonDiscretionaryDownloads
tts_languages
plist
tts_language_fallbacks
en-US
_VSServerConnection
com.apple.voiced
%@:%@:%@
allowing_cellular
download_size
download_duration
download_progress
setup_duration
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
VoiceServices
lowPowerDeviceNeural
use_SiriTTSService
use_SiriTTSServiceV2
lowInactiveMemory
VoiceServicesErrorDomain
basic_string
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
DeviceClassNumber
InternalBuild
HardwarePlatform
t8030
_languageCode
_voiceName
_previewType
VSVocalizerEngine
path
mimeType
TTSSynthesizer::load_voice_resource
unknown path
unknown mime-type
i12@?0i8
tts.neural.use_fallback
tts.metrics.alignment_stall
tts.metrics.audio_has_click
tts.feature.phonemes
TTSSynthesizer::synthesize_text_with_markers_async
application/edct-bin-dictionary
application/x-vocalizer-rettt+text
vector
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/
AssistantEtiquette.wav
\mrk=%@=%@\
\toi=lhp\
\toi=orth\
\tn=normal\
\tn=
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
<speak>
speak
<phoneme alphabet="lhp" ph="
phoneme
"></phoneme>
SSML error
unbalanced phoneme tag
say-as
</say-as>
unbalanced say-as tag
Error in tn override tag, ignore
<say-as interpret-as="%@">
</%@>
NSString *soft_AXSpeechTransformTextWithLanguage(NSString *__strong, AXSpeechTransformOptions, NSString * _Nullable __strong, NSMutableArray * _Nullable __strong)
NSString+VSSpeechService.m
AXSpeechTransformTextWithLanguage
void *libAXSpeechManagerLibrary(void)
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
/System/Library/PrivateFrameworks/VoiceServices.framework/
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
_clientID
_accessoryID
_voice
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
@"AVAudioBuffer"20@?0I8^q12
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %@
<private>
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_NETWORK_STALL
_MALE
strings
%@_%d
Interstitials
DeviceSetup
VSSpeechLangCharset
CharacterBinaryMaps
could not create recognition instance
recognition already attempted or in progress
com.apple.voiceservices.metrics
com.apple.voiceservices.download
@"NSDictionary"8@?0
com.apple.AssistantServices
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@_CV%@
_languages
_searchPathURL
_startTime
_textRange
<VSSpeechWordTimingInfo>{startTime = %.3f; textRange = %@}
model <%@> class <%@>
com.apple.yn
0x%x
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_text
_identifier
_siriRequestId
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@, accessoryID:%@
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
textForAttributes
attributes
startTime: %llu, language:%@, name:%@, gender:%@, type:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, shouldWhisper:%d, canUseServerTTS:%d, disableCompactFallback:%d, disableDeviceRacing:%d, shouldWaitCurrentSpeaking:%d, shouldCache:%d, contextInfo:%@, customResourceURLs:%@, session:%d, accessoryID:%@, text:'%@'
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_shouldWhisper
_shouldCache
_disableCompactVoiceFallback
_disableDeviceRacing
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_shouldWaitCurrentSpeaking
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_contextInfo
_pointer
_powerProfile
%@%@: %@
v32@?0@8@16^B24
VSMappedData%p
%02x
 %@ %@
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
com.apple.voiceservices.notification.synthesis-done
Request is nil.
language is not set.
Request has been used before. Please make a new copy of it.
text is not set.
Audio request has invalid audio data.
Missing text of inline streaming request.
Invalid audio request. Audio is invalid.
Audio caching request must be either inline streaming or audio request.
v20@?0d8B16
v16@?0@"AFXPCWrapper"8
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
com.apple.assistantd
com.apple.accessibility.axassetsd
com.apple.accessibility.AccessibilityUIServer
VSSpeechSynthesizer_%p@%@_%d
q16@?0q8
v16@?0@"SiriTTSInstrumentationMetrics"8
v16@?0@"SiriTTSAudioData"8
v16@?0@8
v24@?0@"NSString"8@"NSError"16
v12@?0B8
v16@?0@"NSArray"8
v24@?0@"SiriTTSSynthesisVoice"8@"NSError"16
stop presynthesized request timeout
stop request timeout
pause request timeout
ar-SA
da-DK
it-IT
ja-JP
nb-NO
nl-NL
ru-RU
sv-SE
generic
-[VSSpeechSynthesizer estimateDurationOfRequest:completion:]_block_invoke
v24@?0d8@"NSError"16
-[VSSpeechSynthesizer connection:speechRequest:didStopAtEnd:phonemesSpoken:error:]_block_invoke
-[VSSpeechSynthesizer connection:synthesisRequest:didFinishWithInstrumentMetrics:error:]_block_invoke
VSAudioPowerUpdateQueue
v16@?0f8f12
@"NSArray"16@?0@"NSArray"8
%@:%@:%@:%@
v24@?0@"VSVoiceAsset"8@"NSError"16
v16@?0@"VSVoiceAsset"8
v24@?0@"NSArray"8@"NSError"16
AFAudioPowerXPCProvider
Class getAFAudioPowerXPCProviderClass(void)_block_invoke
VSSpeechSynthesizer.m
Unable to find class %s
void *AssistantServicesLibrary(void)
AFAudioPowerUpdater
Class getAFAudioPowerUpdaterClass(void)_block_invoke
Auto Downloaded Assets
autoDownloadedAssets
subscribedAssets
OOBTriggeredDate
OOBNeedsToBeMeasured
lastTTSRequestDate
deviceID
com.apple.voiceservices.xpcconnection
-[VSSpeechConnection _remoteObjectSync]_block_invoke
v32@?0@"VSSpeechRequest"8Q16^B24
v32@?0@"VSPresynthesizedAudioRequest"8Q16^B24
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
audioData
packetDescription
packetCount
asbd
undefined
compact
premium
premiumhigh
beta
male
female
neutral
vocalizer
custom
gryphon
neural
MasteredVersion
ContentVersion
builtin
%@:%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, downloadSize: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
B24@?0@8@"NSDictionary"16
_endpoint
SIRI_TEXT_TO_SPEECH
com.apple.siri.tts
com.apple.siri.tts.voice
com.apple.siri.tts.resource
.version
assetSize
ttsCompatibilityVersion
ttsContentVersion
gender
%@.voice.%@.%@.%@.%@
Voice factor name: %@
%@.resource.%@
VSTrialService.downloadQueue
v16@?0@"<TRINamespaceUpdateProtocol>"8
immediateDownloadForNamespaceNames cannot use discretionary download option.
v16@?0Q8
mcpl
#<NSt3__110__function6__funcIU8__strongU13block_pointerFiN14TTSSynthesizer15CallbackMessageEENS_9allocatorIS6_EES4_EE
NSt3__110__function6__baseIFiN14TTSSynthesizer15CallbackMessageEEEE
U13block_pointerFiN14TTSSynthesizer15CallbackMessageEE
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3
MbP?
@mcpl
@mcpl
@supo
@supo
@mcpl
ASAttributeCompatibilityVersion should be NSNumber, got NSString for %@
CV: %@
Compatibility: %@
#MobileAsset migrate '%@', error: %@
#MobileAsset migrate '%@', success
#MobileAsset Ignore cached voice selection for voice query key %@ since it is not installed anymore.
#MobileAsset Ignore neural voice due to thermal critical condition.
#MobileAsset Found cached voice selection %@ for voice query key %@
#MobileAsset Ignore neural voices since device neural TTS is disabled.
#MobileAsset Selected %{public}@ and will cache it for %{public}@
Purging corrupted VoiceResource '%{public}@', error: %{public}@
#MobileAsset Found cached voice resource %@ for %{public}@
#MobileAsset Cached voice resource is corrupted %@
#MobileAsset Unable to find asset for VoiceResources %{public}@
#MobileAsset Found voice resource %@ for %{public}@
#MobileAsset current in-use asset, %@
#MobileAsset ignore VoiceOver asset, %@
#Trial current in-use asset, %@
Cleaning unused assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#Trial Search voice asset for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no suitable installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial Found suitable voice: %{public}@
Parameter language can't be nil for voice selection
Searching voice asset for lang: %{public}@, name: %{public}@, type: %{public0}@, gender: %{public}@, footprint: %{public}@
Search local voices for lang: %{public}@, name: %{public}@
Built-in voice is requested.
Search voices in Trial
Search voices in MobileAsset
Search voices in pre-installed location as fallback
Fallback to custom compact voice
Fallback to built-in compact voice
Selected voice %{public}@
#Trial Found local voice, skip downloading. Target voice: %@
#Trial Found local MobileAsset voice with same or higher version, skip downloading. Target voice: %@
Language must be provided for voice download.
#Trial Enqueued downloading: %{public}@
#Trial Unable to download namespace to download voice: %@, error: %@
#Trial Unable to find suitable voice to download for voice criteria: %@
Target voice to download: %@
#Trial Removing voice: %@
#Trial Unable to remove voice %@, error: %@
#Trial Removed voice: %@
#Trial Cancelling voice downloads: %{public}@
#Trial Cancelling voice download: %{public}@
Removing voice: %{public}@
Asset not removed because it is not present: %@
#Trial Cannot find any Trial resource, skip downloading. Target resource: %@
#Trial Found local resource, skip downloading. Target resource: %@
#Trial No MobileAsset resource found, will download Trial resource. Target resource: %@
#Trial Found same or newer resource in MobileAsset, skip downloading. Target resource: %@
#Trial Enqueue downloading resource: %@
#Trial Error downloading resource: %@, error: %@
#Trial Start downloading for: %@
#MobileAsset ERROR query '%@', timeout after 1 sec
#MobileAsset WARNING query '%@', error: %@
#MobileAsset Catalog '%@' download error: %@
#MobileAsset err %@, unable to download asset %{public}@
#MobileAsset Finished downloading asset %{public}@
#MobileAsset Begin %@ download, allowing cellular %{BOOL}d: %@
#MobileAsset Asset is already downloading: %{public}@
#MobileAsset download skipped, asset is already installed: %{public}@
#MobileAsset download skipped, asset is in an unknown state: %{public}@
#MobileAsset purge asset: %{public}@
#MobileAsset purge error: %@
#MobileAsset cancel downloading asset: %{public}@
#MobileAsset Cancel download error: %@
#MobileAsset Purge cannot find asset: %{public}@
#MobileAsset not removed because it is required by the OS: %{public}@
Ignoring all neural voices due to disableDeviceNeuralTTS
Ignoring neural voice %@. Current states as H12 platform: %{BOOL}d, thermal state:%d, low power enabled:%{BOOL}d
#MobileAsset Couldn't find any built-in voice for language: %{public}@
Unable to query local voice directory, %@
Failed to convert %ld recognition results
process is not running as user Mobile: it won't share the same UserDefaults as voiced
No cache directory from which to get the size: %@
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
Failed siritts_create_text_to_phoneme for voice %@, system %ld, with error: %s
Exception: %s
voice path '%@', resource path '%@'
%d files under voice path:
- %@
Failed to initialize synthesizer due to missing voice path.
Initializing engine with voice path: %@
Failed to initialize synthesizer: %s
Failed to initialize synthesizer: %zu
Error setPitch 0x%zx
Error setRate 0x%zx
Error setVolume 0x%zx
Unable to load resource '%@'
Url doesn't conform to RFC 1808 '%@'
Loading resource: %@, mime-type: %@
Unable to find mime-type for '%@'
Unknown voice resource handle to unload: %@
VSSpeechEngine %p started synthesis.
VSSpeechEngine %p finished synthesis.
Engine preheating latency: %.3f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %{public}@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for voice '%@', text: '%@'
converter.maximumOutputPacketSize is 0. Falling back to maximumPacketSize 1024. Converter is %@
AVAudioConverter.maximumOutputPacketSize is 0.
Invalid target asbd: %@
Could not create Opus decoder: %{public}@
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%{public}@'
Unable to find '%{public}@' localized string for key '%@', return empty string
Searching predefined string for '%@' in '%{public}@'
Unable to find '%{public}@' predefined string for key '%@', return default en-US string
Unable to find '%{public}@' predefined string for key '%@', return empty string
CoreAnalytics eventName:%@ not sent. Event name must not be in current config
Successfully reportEvent with domain '%@'
OOB subscription completion observed with %@ %@
Unable to load plist at '%{public}@', error: %{public}@
Unable to read voice_configs.plist
voice_configs.plist does not have key '_voices'
You're using a deprecated method [VSVoiceResourceAsset defaultVoiceType]; use `VSSpeechVoiceDataTypeUndefined` or `[VSVoiceResourceAsset defaultVoiceNameForGender:]` instead
You're using a deprecated method [VSVoiceResourceAsset defaultVoice]; use `defaultVoiceGender` instead
Out of word boundary: %ld is greater than %ld
Enqueuing request: %@
Queue is now:
Dispatching open URL: %@
Open URL failed: %@
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file, errno: %d, error: %s
%{public}@ is not TTS language, VSSpeechSynthesizer fallback to %{public}@
Cancel #PresynthesizedAudioRequest from client %{public}@ was ignored, no request to stop
Unable to subscribe voice, error %@
Unable to get synthesis voice, error %@
VSSpeechSynthesizer keepActive must be true before prewarming.
Invalid #PrewarmRequest: %@, error: %@
#PrewarmRequest %llu from client %{public}@, request: %@
Stop #SpeechPresynthesizedAudioRequest %llu from client %{public}@, synchronously: %{BOOL}d
Stop #SpeechPresynthesizedAudioRequest from client %{public}@ was ignored, no request to stop
Stop #SpeechRequest from client %{public}@ was ignored, no request to stop
Stop #SpeechRequest %llu from client %{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest %llu from client %{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest from client %{public}@ was ignored, no request to pause
Invalid #SynthesisRequest: %@, error: %@
Start #SynthesisRequest %llu from client %{public}@, %@
Invalid #SpeechRequest: %@, error: %@
Start #SpeechRequest %llu from client %{public}@, %{public}@
Invalid #PresynthesizedAudioRequest: %@, error: %@
Start #PresynthesizedAudioRequest %llu: %@
Invalid #AudioCachingRequest: %@, error: %@
Cache #PresynthesizedAudioRequest %llu: %@
Cancel #SpeechRequest from client %{public}@ was ignored, no request to stop
Cancel #SpeechRequest %llu from client %{public}@
Cancel #PresynthesizedAudioRequest %llu from client %{public}@
Error Stop #SpeechRequest %@
Error Stop #PresynthesizedAudioRequest %@
Resume #SpeechRequest %llu from client %{public}@
Resume #SpeechRequest from client %{public}@ was ignored, no request to resume
#RoughEstimateDuration Request utterance: %@
#RoughEstimateDuration calculated duration: %.2f, using %@ locale, for text: %@
#EstimateDuration Request text: %@
Error %s, %@
#EstimateDuration Received duration: %.2f, for text: %@
Invalid #TTPRequest from client %{public}@: %@, error: %@
Start #TTPRequest %llu from client %{public}@
Error #TTPRequest %@
#TTPRequest %llu Received phonemes: %@, for text: %{public}@
%s, callback received in framework. %@
Current xpc connection %@ does not match %@
Notify daemon crash from: %@
#AudioPower Begin update
#AudioPower End update
#VoiceSubscription, client: %{public}@, accessory: %@, requested voices: %@
Ignore voice subscription due to null clientId.
#VoiceSubscription, client: %{public}@, accessory: %@, deduped voices: %@
Request to download with cellular, client: %{public}@, language: %{public}@, gender: %ld, type: %ld, footprint: %ld, name: %{public}@
Ignore get voice subscription due to null clientId.
%{public}@ is not TTS language, fallback to %{public}@
clearing auto-downloaded voice preferences for accessory %@
Closing xpc connection %p
%s, error: %@
Error updateWithConnectionIdentifier: %@
Can't prewarm: %@
Error at %s , %@ 
Error estimateDurationWithRequest:reply: %@
Error %@ asking for voices
Error %@ asking for voice footprints
Can't start VoicePreview: %@
Can't start PhonemesRequest: %@
Can't get subscribed voice assets: %@
Can't get all subscribed voice assets: %@
Can't get VoiceResource: %@
Can't get voice info: %@
%s, Error: %@
Failed is_neural_voice_ready %@ with error: %s
Failed should_use_neural_voice %@ with error: %s
Failed has_compact_neural_fallback %@ with error: %s
Failed check_thermal_critical_conditions: %s
Failed has_ota_ane_model %@ with error: %s
Failed is_ane_model_compiled %@ with error: %s
Failed compile_ane_model %@ with error: %s
#Trial Unexpected voice factor name: %@
#Trial Error: Factor has no level. It will be ignored. Factor name: %@
#Trial Error: voice should be as directory. Factor name: %@
#Trial Error: voice is not deployed. It will be ignored. Factor name: %@
#Trial Unexpected resource factor name: %@
#Trial Error: resource should be as directory. Factor name: %@
#Trial Received namespace 'SIRI_TEXT_TO_SPEECH' update
#Trial Unable to find asset for factor name '%@'.
#Trial Factor '%@' doesn't seem to be directory.
#Trial Factor '%@' is not downloaded yet.
#Trial Factor '%@' doesn't seem to be a file.
Skip immediate namespace download due to discretionary download option.
#Trial Start downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Unable to download Trial namespace. Error: %@
#Trial Finished downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Downloading asset with factor name: %@, discretionary:%d, allowCellular:%d
#Trial Unable to download asset with factor name: %@, error: %@
#Trial Downloaded asset with factor name: %@
#Trial Removing asset with factor name: %@
#Trial Unable to remove asset with factor name '%@', error: %@
#Trial Removed asset with factor name: %@
Unexpected multiple voices.
#Trial Cannot find any Trial resource for language %@
Unexpected multiple resources from Trial.
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
MobileAsset
VSVoiceAssetSelection
Trial
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSDownloadMetrics
VoiceServices
VSFeatureFlags
VSPhonemeTool
VSUtilities
VSPreviewRequest
NSCopying
VSSpeechEngineVoiceResource
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
SiriTTSServiceBridge
VSVoiceSubscription
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusEncoder
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSAnalytics
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VS4CC
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
VSMappedData
Hash
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
AFAudioPowerProviding
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSAudioData
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
VSNeuralTTSUtils
VSTrialVoice
VSDownloadOptions
VSTrialVoiceResource
VSTrialService
Voice
VoiceResource
T@"NSNumber",C,N,V_downloadSize
.cxx_destruct
T@"NSURL",C,N,V_resourceListURL
OOBTriggeredDate
T@"VSTrialVoice",&,V_trialVoice
STS_cancelRequest:
Tq,V_serverFirstPacketTimestamp
STS_estimateDurationOfRequest:
_action
STS_forwardStreamObject:
_active
STS_isSpeaking
_audioInputPath
STS_queryPhaticCapabilityWithRequest:reply:
_beginSpeakingAttributedString:
STS_startSpeakingAudioRequest:
_currentRequest
STS_startSynthesizingRequest:
_forceServerTTS
STS_subscribedVoices:
_handleRequests
STS_textToPhonemesWithRequest:phonemeSystem:completion:
_isBuiltInVoice
T@"<TRINotificationToken>",&,N,V_trialNotificationToken
_neuralFallback
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
_recognizeFlags
T@"AFAudioPowerXPCProvider",&,N,V_previewAudioPowerXPCProvider
_vs_countPhoneticSyllables_lhp:
T@"AVAudioConverter",&,N,V_converter
arrayWithArray:
T@"AVAudioFormat",&,N,V_toFormat
assetQueryQueue
T@"NSArray",&,N,V_cachedResources
availableVoicesForLanguageCode:
T@"NSArray",&,N,V_customResourceURLs
beginNextAction
T@"NSArray",C,N,V_resourceList
bundleWithPath:
T@"NSCache",&,N,V_cachedMAVoiceResources
canUseServerTTS
T@"NSCharacterSet",&,N,V_characterSet
confirmedAction
T@"NSData",R,C,N,V_audioData
containsString:
T@"NSDictionary",&,N,V_vocalizerConfig
defaultInstance
T@"NSDictionary",C,N,V_contextInfo
downloadedVoicesMatching:reply:
T@"NSDictionary",C,N,V_voiceConfig
enqueue
T@"NSLock",&,N,V_clientRefreshLock
getLocalFileUrl
T@"NSMutableArray",&,N,V_audioRequests
handler
T@"NSMutableArray",&,N,V_requests
hasPath
T@"NSMutableData",&,N,V_fallbackInMemoryData
initWithFormat:
T@"NSMutableData",&,N,V_mutableDescription
initWithNSUUID:
T@"NSMutableDictionary",&,N,V_durationRequests
initWithVoicePath:resourcePath:
T@"NSNumber",C,N,V_compatibilityVersion
isEqualToArray:
T@"NSNumber",C,V_downloadSize
isLocal
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdaterQueue
isServerTimeout
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
isValid
T@"NSString",&,N,V_accessoryID
T@"NSString",&,N,V_filePath
languageMapping
T@"NSString",&,N,V_path
logText
T@"NSString",&,N,V_voice
masteredVersion
T@"NSString",&,V_builtInVoicePath
modelIdentifier
T@"NSString",C,N,V_bundleIdentifier
T@"NSString",C,N,V_language
numberWithLong:
T@"NSString",C,N,V_name
opusDataHandler
T@"NSString",C,N,V_utterance
perform
T@"NSString",C,V_audioOutputRoute
preferenceScore
T@"NSString",C,V_experimentIdentifier
previewRequests
T@"NSString",C,V_voiceAssetKey
release
T@"NSString",R,C
resourceListURL
T@"NSString",R,V_voiceDownloadKey
retainArguments
T@"NSURL",C,N,V_resourceSearchPathURL
setAccessoryID:
T@"NSUUID",&,N,V_siriRequestId
setConcurrentSynthesisRequests:
T@"NSUserDefaults",&,N,V_defaults
setDefaultRate:
T@"NSXPCConnection",&,N,V_xpcConnection
setFrameLength:
T@"NSXPCListenerEndpoint",&,N,V_endpoint
setIsPurgeable:
T@"TRIClient",&,N,V_triClient
setIsWarmStart:
T@"VSPresynthesizedAudioRequest",&,N,V_currentAudioRequest
setPacketCount:
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
setPreviewType:
T@"VSTrialService",&,N,V_trialService
setSequenceTag:
T@"VSVoiceAsset",&,N,V_voice
setShouldCache:
T@?,C,N,V_callback
setStopHandler:
T@?,C,N,V_errorHandler
setTotalLength:
T@?,C,N,V_opusDataHandler
setVoiceConfig:
T@?,C,N,V_stopHandler
shouldCleanFile
TB,N,V_active
startVoicePreviewRequest:reply:
TB,N,V_allowDiscretionary
storage
TB,N,V_disableCompactVoiceFallback
threadSafeQueue
TB,N,V_enqueue
unloadResource:
TB,N,V_hasAlignmentStall
version
TB,N,V_isBuiltInVoice
vs_substituteAudioWithLocalPath
TB,N,V_isPlayingPreview
wordTimingInfos
.cxx_construct
T@"NSString",C,N,V_languageCode
OOBNeedsToBeMeasured
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
STS_cancelAudioRequest:
Tq,N,V_stopMark
STS_downloadedVoicesMatching:reply:
STS_estimateDurationOfRequest:completion:
_actionStarted:
STS_getSynthesisVoiceMatching:reply:
_attributedText
STS_prewarmRequest:
_audioSessionID
STS_signalInlineStreaming:
_contentVersion
STS_startSpeakingRequest:
_eatPunctuation
STS_subscribeVoices:
_gender
STS_subscribedVoicesWithClientID:reply:
_handlingThread
T#,R
_lastUTF8Offset
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
_opusDataOffset
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
_volume
T@"AVAudioCompressedBuffer",&,N,V_outputBuffer
allKeys
T@"AVAudioFormat",&,N,V_fromFormat
assetId
T@"MAAsset",&,V_asset
audioBufferList
T@"NSArray",&,N,V_cachedVoices
beginAudioPowerUpdateWithReply:
T@"NSArray",C,N,V_languages
bundleForClass:
T@"NSAttributedString",C,N,V_attributedText
cachedResources
T@"NSCache",&,N,V_cachedMAVoiceSelections
classIdentifier
T@"NSData",&,N
containsObject:
T@"NSDate",&,N
dealloc
T@"NSDictionary",&,N,V_wordTimings
delegateWrapper
T@"NSDictionary",C,N,V_resourceMimeTypes
enableAudioDump
T@"NSError",&,N,V_error
formatSpecifier
T@"NSLock",&,N,V_synthesisLock
getVoiceNamesForLanguage:reply:
T@"NSMutableArray",&,N,V_previewRequests
hasOTAANEModel:
T@"NSMutableArray",&,N,V_wordTimings
initWithClient:accessory:voice:
T@"NSMutableData",&,N,V_mutableAudioData
initWithLength:
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
initWithString:
T@"NSMutableDictionary",&,N,V_stsRequestMapping
isCacheValidityIdentifierValid:
T@"NSNumber",C,N,V_contentVersion
isInternalBuild
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
isProxy
T@"NSObject<OS_dispatch_queue>",&,N,V_downloadQueue
isSpeechRequest
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
isWatch
T@"NSString",&,N,V_clientID
keywordAtIndex:
T@"NSString",&,N,V_identifier
lastUTF16Offset
T@"NSString",&,N,V_text
lowercaseString
T@"NSString",&,N,V_voicePath
migrateDefaults
T@"NSString",C,N
nameKey
T@"NSString",C,N,V_clientBundleIdentifier
numberWithBool:
T@"NSString",C,N,V_masteredVersion
opaqueSessionID
T@"NSString",C,N,V_text
pcmData
T@"NSString",C,N,V_voiceName
pointer
T@"NSString",C,V_clientBundleIdentifier
preheat
T@"NSString",C,V_utterance
refresh
T@"NSString",C,V_voiceResourceAssetKey
removeVoiceResource:completion:
T@"NSString",R,N
results
T@"NSURL",C,N,V_outputPath
T@"NSURL",C,N,V_searchPathURL
setBool:forKey:
T@"NSUUID",C,N,V_accessoryID
setContextInfo:
T@"NSUserDefaults",&,N,V_internalDefaults
setDisableCompactVoiceFallback:
T@"NSXPCListener",&,N,V_listener
setIsInstalled:
T@"SiriTTSDaemonSession",&,N,V_proxySession
setIsServerTTS:
T@"VSPreferencesInterface",R
setMmappedData:
T@"VSSpeechConnection",W,N,V_connection
setPcmDataSize:
T@"VSSpeechRequest",&,N,V_currentRequest
setPromptCount:
T@"VSTrialService",R,N
setServerStreamedAudioDuration:
T@"VSVoiceAsset",&,V_voiceData
setSourceOfTTS:
T@?,C,N,V_completion
setSynthesizer:
T@?,C,N,V_handler
setURL:
T@?,C,N,V_pauseHandler
setWordTimings:
TB,N
speechBeginTime
TB,N,V_allowCellularData
stopPresynthesizedAudioRequest:
TB,N,V_canUseServerTTS
stringByAppendingPathComponent:
TB,N,V_disableDeviceRacing
typeFromString:
TB,N,V_forceServerTTS
valueWithRange:
TB,N,V_hasAudioClick
vocalizerConfig
TB,N,V_isInstalled
whisper
TB,N,V_isPurgeable
TB,N,V_isVoiceReadyToUse
TB,N,V_keepActive
TB,N,V_keepAudioSessionActive
TB,N,V_neuralDidFallback
TB,N,V_retryDeviceOnNetworkStall
TB,N,V_shouldCache
TB,N,V_shouldCleanFile
TB,N,V_shouldStreamAudioData
TB,N,V_shouldWaitCurrentSpeaking
TB,N,V_shouldWhisper
TB,R
TB,R,N
TB,V_canUseServerTTS
TB,V_discretionary
TB,V_isCacheHitFromDisk
TB,V_isCacheHitFromMemory
TB,V_isCellularAllowed
TB,V_isServerStreamTTS
TB,V_isServerTTS
TB,V_isServerTTSRacing
TB,V_isServerTimeout
TB,V_isSpeechRequest
TB,V_isWarmStart
TB,V_neuralAlignmentStall
TB,V_neuralAudioClick
TB,V_neuralFallback
TI,N,V_audioSessionID
TQ,N,V_assetSize
TQ,N,V_lastUTF16Offset
TQ,N,V_lastUTF8Offset
TQ,N,V_mappedLength
TQ,N,V_numOfPromptsTriggered
TQ,N,V_pcmBufferSize
TQ,N,V_pcmDataSize
TQ,N,V_requestCreatedTimestamp
TQ,N,V_samplesProcessed
TQ,N,V_totalLength
TQ,N,V_version
TQ,R
T^v,N,V_mmappedData
T^v,N,V_synthesizer
Td,N,V_pitch
Td,N,V_rate
Td,N,V_startTime
Td,N,V_volume
Td,V_audioDuration
Td,V_serverStreamedAudioDuration
Td,V_setupTimeInterval
Tf,N
Tf,N,V_pitch
Tf,N,V_rate
Tf,N,V_volume
Tf,V_downloadProgress
Tq,N,V_audioType
Tq,N,V_compatibilityVersion
Tq,N,V_footprint
Tq,N,V_gender
Tq,N,V_opusDataOffset
Tq,N,V_packetCount
Tq,N,V_pointer
Tq,N,V_powerProfile
Tq,N,V_previewType
Tq,N,V_state
Tq,N,V_storage
Tq,N,V_type
Tq,N,V_voiceType
Tq,R
Tq,R,V_downloadBeginTimestamp
Tq,R,V_downloadEndTimestamp
Tq,V_audioStartTimestampDiffs
Tq,V_eagerRequestCreatedTimestampDiffs
Tq,V_errorCode
Tq,V_promptCount
Tq,V_requestCreatedTimestamp
Tq,V_serverLastPacketTimestamp
Tq,V_sourceOfTTS
Tq,V_speechBeginTimestamp
Tq,V_speechEndTimestamp
Tq,V_synthesisBeginTimestamp
Tq,V_synthesisEndTimestamp
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
T{_NSRange=QQ},N,V_textRange
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T{_opaque_pthread_mutex_t=q[56c]},N,V_voicePathLock
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_resource
UAFFactorLevelsWithNamespaceName:
UAFLevelForFactor:withNamespaceName:withLanguage:
URLByAppendingPathComponent:
URLForResource:withExtension:subdirectory:localization:
UTF8String
UUID
UUIDString
_accessoryID
_actionCompleted:nextAction:error:
_actionForEmptyResults
_allowCellularData
_allowDiscretionary
_ambiguousPhoneticValues
_ambiguousValues
_appendToFallbackMemory:
_appendToMappedMemory:
_asbd
_asset
_assetQueryQueue
_assetSize
_audioData
_audioDuration
_audioOutputRoute
_audioPowerUpdater
_audioPowerUpdaterQueue
_audioRequests
_audioStartTimestampDiffs
_audioType
_beginSpeakingString:attributedString:
_block
_builtInVoiceForLanguage:
_builtInVoicePath
_bundleIdentifier
_cachedMAVoiceResources
_cachedMAVoiceSelections
_cachedResources
_cachedVoices
_callback
_callbackQueue
_canUseServerTTS
_caseSensitive
_characterSet
_classID
_clientBundleIdentifier
_clientID
_clientRefreshLock
_clockFactor
_compatibilityVersion
_completion
_concurrentSynthesisRequests
_configureNewRecognitionInstance
_confirmFlags
_confirmedAction
_connection
_connectionInvalidated
_context
_contextInfo
_continueAfterDeferredStart
_continueSpeakingRequest
_convertToFallbackMemory
_converter
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_createRecognitionInstanceWithCallbacks:info:
_currentAction
_currentAudioRequest
_currentCallbackResult
_currentRecognizeAction
_customResourceURLs
_dataProviders
_debugDumpPath
_decoder
_decoderStreamDescription
_defaultVoices
_defaults
_definedVoicesWithLanguage:name:type:footprint:
_delegate
_delegateWrapper
_deniedAction
_directoryOfFactorName:
_disableCompactVoiceFallback
_disableDeviceRacing
_disambiguationContext
_discretionary
_downloadAsset:options:progress:completion:
_downloadBeginTimestamp
_downloadEndTimestamp
_downloadFactorName:withOptions:progress:completion:
_downloadProgress
_downloadQueue
_downloadSize
_durationRequests
_eagerRequestCreatedTimestampDiffs
_endpoint
_enqueue
_enqueueRequest:
_ensureKeepAliveMaintenance
_error
_errorCode
_errorHandler
_experimentIdentifier
_fallbackInMemoryData
_fileOfFactorName:
_filePath
_flush
_flushTimer
_footprint
_fromFormat
_getResults:
_getVoiceAssetsForType:voiceName:language:gender:footprint:returnTypes:
_handleRecognitionCompleted:withResults:error:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handledThreadedResults:nextAction:
_handler
_hasAlignmentStall
_hasAudioClick
_hasDeferredStartCallback
_identifier
_init
_initShared
_inputLevel
_inputLevelDB
_installedVoiceResourceAssetForLanguage:
_internalDefaults
_isActivelyRecognizing
_isCacheHitFromDisk
_isCacheHitFromMemory
_isCellularAllowed
_isInstalled
_isListening
_isPlayingPreview
_isPurgeable
_isRecognizing
_isServerStreamTTS
_isServerTTS
_isServerTTSRacing
_isServerTimeout
_isSpeechRequest
_isVoiceReadyToUse
_isWarmStart
_keepActive
_keepAlive
_keepAudioSessionActive
_keywordAtIndex:
_keywordCount
_keywordIndexChanged
_keywordPhase
_keywords
_keywordsForModelIdentifier:
_knownPhoneticValues
_knownValues
_language
_languageCode
_languageID
_languages
_lastUTF16Offset
_levelInterval
_listener
_localVoiceForLanguageAndNamePath:
_lock
_mappedLength
_markers
_masteredVersion
_matchPattern
_mmappedData
_mobileAssetVoiceForLanguage:name:type:gender:footprint:
_mobileAssetVoiceResourceWithLanguage:
_modelID
_modelIdentifier
_mutableAudioData
_mutableDescription
_name
_neuralAlignmentStall
_neuralAudioClick
_neuralDidFallback
_nextKeywordUsingCursors:
_notifyDelegateActionStarted
_notifyDelegateFinishedSpeakingWithError:
_notifyDelegateOpenURL:completion:
_notifyRequestHandled:
_numOfPromptsTriggered
_opusDataHandler
_opusDecoder:
_outputBuffer
_outputPath
_packetCount
_path
_pauseHandler
_pauseSpeakingRequestAtNextBoundary:synchronously:
_pcmBufferSize
_pcmDataSize
_phonemeBuffer
_pitch
_playerStreamDescription
_pointer
_powerProfile
_previewAudioPowerXPCProvider
_previewRequests
_previewType
_promptCount
_proxySession
_purgeMobileAsset:
_queue
_rate
_recognition
_recognitionResultHandlingThread
_releaseFromPrepare
_remoteKeepAlive
_remoteObject
_remoteObjectSync
_remoteObjectWithErrorHandler:
_removeAssetWithFactorName:completion:
_removeTrialVoices:completion:
_repeatedSpokenFeedbackString
_replacement
_requestCreatedTimestamp
_requests
_reset
_resource
_resourceList
_resourceListURL
_resourceMimeTypes
_resourceSearchPathURL
_resultHandlingFlags
_resultString
_results
_retryDeviceOnNetworkStall
_rules
_samples
_samplesProcessed
_scrambledKeywordsAndAddToSet:
_searchPathURL
_sequenceTag
_serverConnection
_serverFirstPacketTimestamp
_serverLastPacketTimestamp
_serverStreamedAudioDuration
_session
_sessionFlags
_setAction:
_setAudioInputPath:
_setBluetoothInputAllowed:
_setConfirmed:
_setDebugDumpEnabled:
_setDebugDumpEnabled:dumpPath:
_setDebugDumpPath:
_setDelegate:
_setEngineResetRequired:
_setInputLevelUpdateInterval:
_setPreferredEngine:
_setQueue:
_setResults:
_setSession:
_setupTimeInterval
_shouldCache
_shouldCleanFile
_shouldStreamAudioData
_shouldTerminate
_shouldWaitCurrentSpeaking
_shouldWhisper
_siriRequestId
_sourceOfTTS
_speechBeginTimestamp
_speechEndTimestamp
_spokenLanguageChanged:
_spokenString
_spokenStringIsAttributed
_startTime
_state
_statusString
_stopHandler
_stopMark
_stopSpeakingPresynthesizedAudioRequest:synchronously:
_stopSpeakingRequest:atNextBoundary:synchronously:
_storage
_stsRequestMapping
_synthesisBeginTimestamp
_synthesisEndTimestamp
_synthesisLock
_synthesizer
_synthesizerFlags
_text
_textRange
_threadSafeQueue
_toFormat
_tokenizer
_topLevelKeywords
_totalLength
_triClient
_trialNotificationToken
_trialService
_trialVoice
_trialVoiceResourceWithLanguage:
_trialVoiceWithLanguage:name:type:footprint:
_type
_updateRequestQueue
_url
_utterance
_version
_vocalizerConfig
_voice
_voiceAssetKey
_voiceConfig
_voiceData
_voiceDownloadKey
_voiceName
_voicePath
_voicePathLock
_voiceResourceAssetKey
_voiceType
_vs_countPhoneticSyllables_xsampa:
_wordTimings
_xpcConnection
accessoryID
accessoryId
actionForRecognitionResult:
actionForRecognitionResults:
active
activeVoiceAssets
addCharactersInRange:
addKeyValueArray:with:
addKeyValuePair:with:
addObject:
addObjectsFromArray:
addObserver:selector:name:object:
addTimer:forMode:
addUpdateHandlerForNamespaceName:usingBlock:
adjustWordTimingInfo:forContext:
allObjects
allValues
allocWithZone:
allowAnyAssetSubscriber
allowCellularData
allowDiscretionary
allowsCellularAccess
ambiguousValuesForClassIdentifier:
amendNameVersionAndSizeWithMobileAssetAttributes:
anonymousListener
appendBytes:length:
appendData:
appendFormat:
appendRandomizationKey:withCount:
appendString:
appendString:withAttributes:
array
arrayForKey:
arrayWithCapacity:
arrayWithContentsOfFile:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
asbd
asset
assetSize
assetType
attachProgressCallBack:
attributedStringWithFormatAndAttributes:
attributedText
attributes
attributesOfItemAtPath:error:
audioData
audioDuration
audioOutputRoute
audioPowerUpdater
audioPowerUpdaterQueue
audioQueueLatency
audioRequest:didReportInstrumentMetrics:error:
audioRequest:didStopAtEnd:error:
audioRequestDidStart:
audioRequests
audioSessionID
audioStartLatency
audioStartTimestampDiffs
audioType
autorelease
availableFootprintsForVoice:languageCode:
availableLanguageCodes
availableLanguages
beginChunkDecoderForStreamDescription:
beginEncoding
beginReportingChanges
beginSpeakingFeedbackString
beginSpeakingString:
beginUpdate
boolForKey:
boolValue
builtInVoicePath
builtInVoices
bundleIdentifier
bundleIdentifierForVoiceType:
bundlePath
bundleWithIdentifier:
bytes
bytesAtOffset:
cachePresynthesizedAudioRequest:
cacheValidityIdentifier
cachedMAVoiceResources
cachedMAVoiceSelections
cachedVoices
callback
canLogRequestText
cancel
cancelAudioRequest:
cancelDownload:completion:
cancelDownloadSync
cancelDownloads:completion:
cancelMaintainingKeepAlive:
cancelRequest:
cancelWithRequest:
candidateToDownloadForVoice:
cappedRealTimeFactor
characterAtIndex:
characterClassCountForUtterance:language:
characterIsMember:
characterSet
characterSetWithBitmapRepresentation:
class
cleanDirectory:withDateOlderThan:
cleanDirectory:withLRULimit:
cleanMobileAssetVoiceResourcesWithActiveLanguages:
cleanOldMobileAssetVoiceResources
cleanUnusedAssets
cleanUnusedAssets:
clientBundleIdentifier
clientID
clientId
clientRefreshLock
clientWithIdentifier:
closeFile
coalescedRequest:
code
compare:
compatibilityVersion
compatibilityVersionFromMobileAssetAttributes:
compileANEModel:
completeWithNextAction:error:
completion
completionType
componentsJoinedByString:
componentsSeparatedByString:
concatenateWithAudio:
concurrentSynthesisRequests
configuredEndpointWithUpdateHandler:withConnection:
conformsToProtocol:
connection
connection:invalidatedWithError:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:previewRequestDidStartPlaying:
connection:speechRequest:didGenerateAudioChunk:
connection:speechRequest:didReceiveTimingInfo:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequestDidContinue:
connection:speechRequestDidPause:
connection:speechRequestDidStart:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
contentVersion
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextInfo
contextInfoString
continueSpeakingWithError:
continueSpeechRequest:
convertToBuffer:error:withInputFromBlock:
converter
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createFileAtPath:contents:attributes:
createHandler
createNewXPCWrapperWithCompletion:
currentAudioRequest
currentCallbackResult
currentHandler
currentRequest
currentRunLoop
customResourceURLs
data
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
date
dateWithTimeIntervalSinceNow:
debugDescription
debugDumpPath
decimalDigitCharacterSet
decodeBoolForKey:
decodeBytesForKey:returnedLength:
decodeChunk:outError:
decodeChunks:streamDescription:outError:
decodeDoubleForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodePropertyListForKey:
decodeValueOfObjCType:at:size:
decoderStreamDescription
defaultCenter
defaultDownloadOptions
defaultManager
defaultPitch
defaultRate
defaultToNonDiscretionaryDownloads
defaultVoice
defaultVoiceGender
defaultVoiceNameForGender:
defaultVoiceType
defaultVolume
defaults
definedVoiceResourcesWithLanguage:
definedVoicesForLanguage:voiceName:type:footprint:
definedVoicesWithAssets:
definedVoicesWithLanguage:name:type:footprint:
delegate
deniedAction
derivedIdentifierForComponentName:fromSourceIdentifier:
description
descriptionFormatter
descriptiveKey
detachNewThreadSelector:toTarget:withObject:
deviceTTSWaitTime
deviceUUID
dictionary
dictionaryForKey:
dictionaryMetrics
dictionaryRepresentation
dictionaryRepresentationOfVoices:
dictionaryWithContentsOfFile:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
dictionaryWithObjects:forKeys:count:
didEndAccessPower
directorySize:
directoryValue
disableAssetCleaning
disableAssetUpdate
disableCache
disableCompactVoiceFallback
disableDeviceNeuralTTS
disableDeviceRacing
disableInlineStreamTTS
disableMobileAssetURLReset
disableOspreyStreaming
disableServerTTS
discretionary
displayResultString
displayStatusString
domain
doubleValue
downloadBeginTimestamp
downloadCatalog:options:
downloadCatalog:options:completion:
downloadDuration
downloadEndTimestamp
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
downloadNamespaceImmediatelyIfNeededWithOption:completion:
downloadOptionsWithBattery:
downloadProgress
downloadQueue
downloadSize
downloadTrialVoiceResource:options:completion:
downloadVoice:withOptions:progress:completion:
downloadVoiceAsset:options:progressUpdateHandler:
downloadVoiceAsset:useBattery:progressUpdateHandler:
downloadVoiceResource:completion:
downloadVoiceResource:options:completion:
downloadVoiceResource:withOptions:progress:completion:
downloadVoiceResourceCatalogWithCompletion:
duration
durationRequests
eagerRequestCreatedTimestampDiffs
eagerRequestGapInterval
eagerRequestTimeGap
elementCount
emitMessage:
enableLocalVoices
encodeBool:forKey:
encodeBytes:length:forKey:
encodeChunk:
encodeDouble:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeValueOfObjCType:at:
encodeWithCoder:
endAudioPowerUpdate
endChunkDecoding
endEncoding
endMetrics
endUpdate
endpoint
engineCurrentCompatibility
engineMinimumCompatibility
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
error
errorCode
errorFromSTSError:
errorHandler
errorWithDomain:code:userInfo:
errorWithReason:
estimateDurationOfRequest:
estimateDurationOfRequest:completion:
estimateDurationWithRequest:didFinish:
estimateDurationWithRequest:reply:
estimatedTTSWordTimingForText:withLanguage:voiceName:
eventMetadata
exchangeObjectAtIndex:withObjectAtIndex:
expectedTimeRemaining
experimentIdentifier
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
factor
factorName
fallbackInMemoryData
fallbackLanguageForLanguage:
fileDescriptor
fileExistsAtPath:
fileHandleForUpdatingAtPath:
filePath
filePathURL
fileURLWithPath:
fileURLWithPath:isDirectory:
fileValue
filteredArrayUsingPredicate:
firstObject
floatForKey:
floatValue
footprint
footprintFromString:
footprintStringFromFootprint:
forceServerTTS
formattedArg
forwardStreamObject:
forwardWithStreamObject:
fromFormat
gender
genderFromString:
genderStringFromGender:
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAllAutoDownloadedVoiceAssets:
getAllVoiceSubscriptionsWithReply:
getAudioPower:
getAutoDownloadedVoiceAssets:
getAveragePower:andPeakPower:
getElementClassIdentifier:value:atIndex:
getFootprintsForVoiceName:languageCode:reply:
getLatestAssetFromArray:
getLocalAudioRequest:
getLocalPreviewRequest:
getLocalRequest:
getLocalUrl
getLocalVoiceAssets:
getLocalVoiceAssetsForLanguage:reply:
getLocalVoiceResources:
getLocalVoiceResourcesReply:
getLocalVoicesForLanguage:reply:
getResourceValue:forKey:error:
getSpeechIsActiveForConnectionReply:
getSpeechIsActiveReply:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getSynthesisVoiceMatching:reply:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
getVoiceInfoForLanguageCode:name:type:footprint:reply:
getVoiceResourceForLanguage:reply:
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handleResults:withHandler:
hasAMX
hasANE
hasAlignmentStall
hasAsset
hasAudioClick
hasCompactNeuralFallback:
hasDeferredAction
hasLevel
hasPhaticResponses:
hasPrefix:
hasSuffix:
hasValidAudio
hash
identifier
ignorePowerAndThermalState
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
inactiveVoiceAssets
init
initFileURLWithPath:
initForInputFeedback
initFromFormat:toFormat:
initFromMobileAssetAttributes:
initWithAccessoryID:
initWithAccessoryId:
initWithAudio:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
initWithAudioData:playerStreamDescription:
initWithBlock:
initWithCallback:
initWithCapacity:
initWithCoder:
initWithCondition:
initWithContentsOfFile:
initWithContentsOfPath:languageIdentifier:
initWithContentsOfURL:
initWithDictionaryRepresentation:
initWithFactorLevel:
initWithFactorName:
initWithFilePath:initialSize:
initWithFormat:packetCapacity:maximumPacketSize:
initWithHandler:results:
initWithIdentifier:
initWithLanguage:
initWithLanguage:name:
initWithListenerEndpoint:
initWithMachServiceName:options:
initWithModelIdentifier:
initWithModelIdentifier:classIdentifier:
initWithPCMFormat:frameCapacity:
initWithProvider:queue:frequency:delegate:
initWithSourceASBD:
initWithSpokenFeedbackString:willTerminate:
initWithStreamDescription:
initWithSuiteName:
initWithText:identifier:
initWithText:voice:
initWithText:voice:phonemeSystem:
initWithTrialVoice:
initWithType:
initWithVoiceName:languageCode:gender:
initWithXPCWrapper:
initialize
initializeWithResourcePath:
inputLevel
inputLevelDB
insertObject:atIndex:
insertString:atIndex:
installedAssetsForType:voicename:language:gender:footprint:
installedLocalVoices
installedTrialVoiceResources
installedTrialVoicesForType:voiceName:language:footprint:
installedVoiceResources
instancesRespondToSelector:
intValue
integerValue
interfaceWithProtocol:
internalDefaults
invalidate
invocationWithMethodSignature:
invokeDaemon:
invokeUpdateWithObject:
isANECompilationPlatform
isANEModelCompiled:
isActivelyRecognizing
isBuiltInVoice
isBusy
isCacheHitFromDisk
isCacheHitFromMemory
isCellularAllowed
isDownloading
isEqual:
isEqualToDictionary:
isEqualToString:
isFinished
isH12Platform
isHomeHub
isHomePod
isInstalled
isKindOfClass:
isLowPowerDeviceNeuralEnabled
isLowPowerModeEnabled
isMemberOfClass:
isNeuralFallbackCondition
isNeuralTTSPlatform
isNeuralVoiceReady:
isPlayingPreview
isPurgeable
isRecognizing
isSeedBuild
isServerStreamTTS
isServerTTS
isServerTTSRacing
isSimilarTo:
isSpeaking
isSpeaking:
isStalled
isSynthesisCached
isSystemSpeaking
isSystemSpeakingOnBehalfOfCurrentConnection
isTrialEnabled
isUserCancelError:
isVoiceAssetWellDefined:
isVoiceReadyToUse
isWarmStart
keepActive
keepAudioSessionActive
keywordCount
killDaemon
knownValueForClassIdentifier:
knownValuesForClassIdentifier:
language
languageCode
languages
languagesFromMobileAssetAttributes:
lastFetchDate
lastObject
lastPathComponent
lastTTSRequestDate
lastUTF8Offset
length
lengthOfBytesUsingEncoding:
level
listener
listener:shouldAcceptNewConnection:
load
loadResource:error:
loadResourceAtPath:mimeType:error:
localizations
localizedDescription
localizedInterstitialStringForKey:language:
localizedOOBStringForKey:language:
localizedOOBStringForKey:language:gender:
localizedStringForKey:language:table:
lock
lockWhenCondition:
logSensitiveText
logUtterance
longLongValue
longValue
lowInactiveMemory
mainBundle
mainRunLoop
maintainWithAudioType:keepAudioSessionActive:
makeObjectsPerformSelector:
makeObjectsPerformSelector:withObject:
mappedLength
markerBuffer
matchedString:forTokenInRange:
matchesInString:options:range:
maximumOutputPacketSize
maximumRate
metadata
methodSignatureForSelector:
migrateAssetIfNeededWithAssetType:
migrateAssetsWithProgress:
mimeForFileExtension:
minimumRate
mmappedData
mutableAudioBufferList
mutableAudioData
mutableBytes
mutableCopy
mutableDescription
mutablePCMData
name
neuralAlignmentStall
neuralAudioClick
neuralDidFallback
neuralFallback
nextAction
nextActionWillRecognize
nextActionWillTerminateSession
numOfPromptsTriggered
numberOfRanges
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInteger:
numberWithUnsignedLongLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
opusDataOffset
ospreyEndpointURL
outputBuffer
outputPath
packetCount
packetDescriptions
path
pathExtension
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pathForResource:ofType:inDirectory:forLocalization:
pathWithComponents:
pauseHandler
pauseSpeakingAtNextBoundary:synchronously:error:
pauseSpeechRequest:atMark:
pcmBufferSize
pcmDataSize
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSelectorOnMainThread:withObject:waitUntilDone:
performUpdateForModelIdentifier:classIdentifier:
phonemeBuffer
phonemes
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
pickCorrectAssetFromLocalAssets:
pitch
playVoicePreviewForLanguageCode:voiceName:previewType:completion:
playerStreamDescription
postNotificationName:object:
postNotificationName:object:userInfo:
powerProfile
predefinedStringForKey:language:table:
predicateWithBlock:
preferredDownloadForVoice:
preferredLocalizations
preferredLocalizationsFromArray:forPreferences:
preinstallAssetsDirectory
preinstallAssetsMetadata
preinstalledAudioHashForLanguage:name:
preinstalledVoicesForLanguage:gender:name:
previewAudioPowerXPCProvider
previewRequestDidStartPlaying:
previewType
prewarmIfNeededWithRequest:
prewarmIfNeededWithRequest:reply:
prewarmWithRequest:didFinish:
privacySensitive
processIdentifier
processInfo
processMarkerBuffer
processName
processedTextFromString:
promptCount
proxySession
punctuationCharacterSet
purgeAsset:
purgeSync
queryForLanguage:forType:voiceName:gender:footprint:returnTypes:
queryForVoiceResourceAsset:returnTypes:
queryMetaData:
queryPhaticCapability:
queryPhaticCapabilityWithRequest:
queryPhaticCapabilityWithRequest:reply:
queryPhaticCapabilityWithVoice:reply:
queue
raise:format:
rangeAtIndex:
rangeOfString:
rangeOfString:options:range:
rangeValue
rate
realTimeFactor
recognitionAction
recognitionResultByReplacingValueForClassIdentifier:withValue:
recognitionResultHandlingThread:didHandleResults:nextAction:
recognitionResultWithModelIdentifier:classIdentifiers:values:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
recognitionSession:openURL:
recognitionSession:openURL:completion:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
refreshTrialClient
regularExpressionWithPattern:options:error:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
remoteUpdateHanderForEndpoint:
removeAllObjects
removeDirectory:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeLevelsForFactors:withNamespace:queue:completion:
removeMobileAssetVoiceResource:completion:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObserver:name:object:
removeSubscriptionsForAccessory:
removeTrialVoice:completion:
removeTrialVoiceResource:completion:
removeUpdateHandlerForToken:
removeVoice:completion:
removeVoiceAsset:completion:
repeatedSpokenFeedbackString
replaceCharactersInRange:withString:
replaceObjectAtIndex:withObject:
reportDownloadMetrics:
reportEvent:payload:
reportInstrumentMetrics:
requestCreatedTime
requestCreatedTimestamp
requests
requiresThreadedProcessing
reset
resetCache
resetResourcesCache
resource
resourceFromTrial:
resourceList
resourceMimeTypes
resourceSearchPathURL
resourceValuesForKeys:error:
respondsToSelector:
resultDisplayString
resume
retain
retainCount
retryDeviceOnNetworkStall
returnTypes:
rolloutIdentifiersWithNamespaceName:
roughEstimationWithRequest:
runUntilDate:
sampleBuffer
samplesProcessed
scheduledTimerWithTimeInterval:invocation:repeats:
searchPathURL
selectPreinstalledVoiceForLanguage:gender:name:
selectVoiceForLang:name:type:gender:footprint:
selectVoiceResourceAssetForLanguage:
selectVoiceResourceWithLanguage:
selectVoiceWithLanguage:name:type:footprint:
self
sensitiveActionsEnabled
sequenceTag
serverFirstPacketTime
serverFirstPacketTimestamp
serverLastPacketTime
serverLastPacketTimestamp
serverStreamFirstPacketLatency
serverStreamLastPacketLatency
serverStreamedAudioDuration
serverTTSTimeout
setActive:
setAllowAnyAssetSubscriber:
setAllowCellularData:
setAllowDiscretionary:
setAllowsCellularAccess:
setAmbiguousValues:phoneticValues:forClassIdentifier:
setArgument:atIndex:
setAsbd:
setAsset:
setAssetQueryQueue:
setAssetSize:
setAttributedText:
setAttributes:range:
setAudioData:
setAudioDuration:
setAudioOutputRoute:
setAudioPowerUpdater:
setAudioPowerUpdaterQueue:
setAudioRequests:
setAudioSessionID:
setAudioSessionId:
setAudioStartTimestampDiffs:
setAudioType:
setAutoDownloadedVoiceAssets:
setBluetoothInputAllowed:
setBuiltInVoicePath:
setBundleIdentifier:
setCachedMAVoiceResources:
setCachedMAVoiceSelections:
setCachedResources:
setCachedVoices:
setCallback:
setCanUseServerTTS:
setCharacterSet:
setClasses:forSelector:argumentIndex:ofReply:
setClientBundleIdentifier:
setClientID:
setClientRefreshLock:
setCompatibilityVersion:
setCompletion:
setConfirmedAction:
setConnection:
setContentVersion:
setContextId:
setConverter:
setCountLimit:
setCurrentAudioRequest:
setCurrentCallbackResult:
setCurrentRequest:
setCustomResourceURLs:
setData:
setDebugDumpEnabled:
setDefaultPitch:
setDefaultToNonDiscretionaryDownloads:
setDefaultVolume:
setDefaults:
setDelegate:
setDelegateWrapper:
setDeniedAction:
setDeviceTTSWaitTime:
setDidGenerateAudio:
setDidGenerateWordTimings:
setDidReportInstrument:
setDidStartSpeaking:
setDisableAssetCleaning:
setDisableAssetUpdate:
setDisableCache:
setDisableCompactVoice:
setDisableDeviceNeuralTTS:
setDisableDeviceRacing:
setDisableInlineStreamTTS:
setDisableOspreyStreaming:
setDisableServerTTS:
setDiscretionary:
setDiscretionaryBehavior:
setDownloadProgress:
setDownloadQueue:
setDownloadSize:
setDurationRequests:
setEagerRequestCreatedTimestampDiffs:
setEnableAudioDump:
setEnableLocalVoices:
setEndpoint:
setEnqueue:
setError:
setErrorCode:
setErrorCodes:
setErrorHandler:
setEventMetadata:
setExperimentIdentifier:
setExportedInterface:
setExportedObject:
setFailed:
setFallbackInMemoryData:
setFilePath:
setFireDate:
setFloat:forKey:
setFootprint:
setForceServerTTS:
setFromFormat:
setGender:
setHandler:
setHasAlignmentStall:
setHasAudioClick:
setIdentifier:
setIgnorePowerAndThermalState:
setImmediate:
setInputLevelUpdateInterval:
setInternalDefaults:
setInterruptionHandler:
setInvalidationHandler:
setIsBuiltInVoice:
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
setIsCellularAllowed:
setIsPlayingPreview:
setIsServerStreamTTS:
setIsServerTTSRacing:
setIsServerTimeout:
setIsSpeechRequest:
setIsVoiceReadyToUse:
setKeepActive:
setKeepAudioSessionActive:
setKeywordPhase:
setKeywords:
setKnownValue:phoneticValue:forClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
setLanguage:
setLanguageCode:
setLanguages:
setLastTTSRequestDate:
setLastUTF16Offset:
setLastUTF8Offset:
setListener:
setLock:
setLogSensitiveText:
setMappedLength:
setMasteredVersion:
setMaximumFractionDigits:
setMinimumFractionDigits:
setMutableAudioData:
setMutableDescription:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralDidFallback:
setNeuralFallback:
setNextAction:
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setNumOfPromptsTriggered:
setOOBNeedsToBeMeasured:
setOOBTriggeredDate:
setObject:forKey:
setObject:forKeyedSubscript:
setOpusDataHandler:
setOpusDataOffset:
setOspreyEndpointURL:
setOutputBuffer:
setOutputPath:
setPacketDescriptions:
setPath:
setPauseHandler:
setPcmBufferSize:
setPerformRecognitionHandlerActions:
setPitch:
setPointer:
setPowerProfile:
setPreferredEngine:
setPreviewAudioPowerXPCProvider:
setPreviewRequests:
setPrivacySensitive:
setProxySession:
setQueue:
setRate:
setRecognitionAction:
setRemoteObjectInterface:
setRepeatedSpokenFeedbackString:
setRequestCreatedTimestamp:
setRequests:
setRequiresPowerPluggedIn:
setResource:
setResourceList:
setResourceListURL:
setResourceMimeTypes:
setResourceSearchPathURL:
setResultDisplayString:
setRetryDeviceOnNetworkStall:
setSamplesProcessed:
setSearchPathURL:
setSelector:
setSensitiveActionsEnabled:
setServerFirstPacketTimestamp:
setServerLastPacketTimestamp:
setServerTTSTimeout:
setSetupTimeInterval:
setShouldCleanFile:
setShouldStreamAudioData:
setShouldWaitCurrentSpeaking:
setShouldWhisper:
setSimulateNetworkStall:
setSiriRequestId:
setSpeechBeginTimestamp:
setSpeechContext:
setSpeechEndTimestamp:
setSpokenFeedbackAttributedString:
setSpokenFeedbackString:
setStartTime:
setState:
setStatusDisplayString:
setStopMark:
setStorage:
setStreamBufferDuration:
setStsRequestMapping:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
setSubscribedVoices:forClientID:accessoryID:
setSynthesisBeginTimestamp:
setSynthesisEndTimestamp:
setSynthesisLock:
setSynthesisProfile:
setTarget:
setText:
setTextRange:
setThreadSafeQueue:
setToFormat:
setTriClient:
setTrialNotificationToken:
setTrialService:
setTrialVoice:
setTtsId:
setType:
setUseBetaVoice:
setUtterance:
setVersion:
setVocalizerConfig:
setVoice:
setVoiceAssetKey:
setVoiceData:
setVoiceName:
setVoicePath:
setVoicePathLock:
setVoiceResourceAssetKey:
setVoiceType:
setVolume:
setWhisper:
setWithArray:
setWithObject:
setXpcConnection:
setupTimeInterval
sha256hex
sharedInstance
sharedListener
sharedListenerIfExists
sharedManager
sharedService
sharedStream
shouldCache
shouldDownloadTrialResource:
shouldDownloadTrialVoice:
shouldStreamAudioData
shouldUseNeuralVoice:
shouldWaitCurrentSpeaking
shouldWhisper
signalWithInlineStreaming:
simulateNetworkStall
siriRequestId
size
sortUsingComparator:
sortedArrayUsingComparator:
sourceOfTTS
speakWithAudioRequest:didFinish:
speakWithSpeechRequest:didFinish:
speechBeginTimestamp
speechEndTime
speechEndTimestamp
speechEstimatedOutputBeginTimestamp
speechRequest:didReceiveTimingInfo:
speechRequest:didReportInstrumentMetrics:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequestDidContinue:
speechRequestDidPause:
speechRequestDidStart:
speechString
speechSynthesizer:daemonDidCrashWithError:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didStartPlayingPreviewRequest:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
spokenFeedbackAttributedString
spokenFeedbackString
standardInstance
startCatalogDownload:options:then:
startDownload:then:
startListening
startPhonemesRequest:phonemeSystem:reply:
startPresynthesizedAudioRequest:
startSpeakingPresynthesizedAudioRequest:
startSpeakingRequest:
startSpeechRequest:
startSpeechRequest:reply:
startSynthesisRequest:
startSynthesizingRequest:
startTime
state
statusDisplayString
stopAtMarker:
stopHandler
stopListening
stopMark
stopPlayingVoicePreview
stopReportingChanges
stopSpeakingAtNextBoundary:synchronously:error:
stopSpeakingPresynthesizedAudioSynchronously:error:
stopSpeechRequest:atMark:
stopVoicePreview
streamBufferDuration
streamDescription
string
stringByAppendingFormat:
stringByAppendingString:
stringByReplacingMatchesInString:options:range:withTemplate:
stringByReplacingOccurrencesOfString:withString:
stringByStandardizingPath
stringForKey:
stringFromNumber:
stringOfSourceOfTTS:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
stsRequestMapping
subarrayWithRange:
subscribeWithVoices:reply:
subscribedVoicesForClientID:accessoryID:
subscribedVoicesWithClientId:reply:
subscribedVoicesWithReply:
substringWithRange:
superclass
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
synthesisBeginTime
synthesisBeginTimestamp
synthesisCallback:
synthesisEndTime
synthesisEndTimestamp
synthesisLock
synthesisRequest:didFinishWithInstrumentMetrics:error:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didReceiveTimingInfo:
synthesizeText:loggable:callback:
synthesizeWithRequest:didFinish:
synthesizer
text
textRange
textToPhonemeWithRequest:didFinish:
textToPhonemesWithRequest:phonemeSystem:completion:
thermalState
timeIntervalSinceDate:
timeToPlaybackLatency
timeToSpeakLatency
timerWithTimeInterval:target:selector:userInfo:repeats:
timingInfosFrom:withText:
timingPlistForLanguage:
toFormat
totalExpected
totalFrames
totalLength
totalWritten
triClient
trialNotificationToken
trialService
trialVoice
triggerCellularDownloadedVoiceAssets:
triggerCellularDownloadedVoiceAssets:withClientID:
ttsSynthesisLatency
type
typeFromBundleIdentifier:
typeStringFromType:
unlock
unlockWithCondition:
unsignedIntegerValue
unspeakableRangeOfText:
updateWithConnectionIdentifier:keepActive:
useBetaVoice
useSSMLInput
useSiriTTSService
useSiriTTSServiceV2
userInfo
utf16OffsetFromUTF8:
utf16TimingInfoWithUTF8Range:withText:
utf8BytesForChar:
utterance
validateAudioCachingRequest:
validateAudioRequest:
validatePrewarmRequest:
validateRequest:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueOfFirstElementWithClassIdentifier:
valueWithNonretainedObject:
versionFactorNameWithFactorName:
voice
voiceAssetFromPreinstallMetadata:
voiceAssetKey
voiceAssetsForSubscription:
voiceConfig
voiceData
voiceDataFromAsset:
voiceDataWithBundleIdentifier:attributes:voicePathCallback:
voiceDownloadKey
voiceKey
voiceName
voicePath
voicePathLock
voiceResourceAssetKey
voiceResourceFromAsset:
voiceType
volume
vs_convertToSSML
vs_countPhoneticSyllables
vs_hasCJKCharacter
vs_insertContextInfo:
vs_isCJKCharacter:
vs_markerStringForContext:
vs_measurePauses
vs_metricsFromSTSMetrics:
vs_removePhonetics
vs_removeSpeechTags
vs_stringFrom4CC:
vs_textifyEmojiWithLanguage:
wasLocal
wasPurgeable
whitespaceAndNewlineCharacterSet
whitespaceCharacterSet
willBeginAccessPower
wordTimingInfoFrom:timestamps:
wordTimings
xpcConnection
zone
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
v20@0:8B16
q16@0:8
v24@0:8q16
v16@0:8
@"NSString"
@"NSNumber"
@24@0:8q16
d16@0:8
v24@0:8d16
Q16@0:8
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
@"VSVoiceAsset"
@"MAAsset"
@"VSTrialVoice"
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8@16q24@32q40q48q56
@32@0:8@16q24
@20@0:8B16
q24@0:8@16
B24@0:8@16
B24@0:8@?16
@56@0:8@16@24q32q40q48
@40@0:8@16q24@32
@48@0:8@16@24q32q40
@48@0:8q16@24@32q40
@56@0:8q16@24@32q40q48
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@16@?24
v24@0:8@?16
@64@0:8q16@24@32q40q48q56
@32@0:8@16@24
v48@0:8@16@24@?32@?40
@40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSCache"
@"VSTrialService"
f16@0:8
v20@0:8f16
@"NSUserDefaults"
@40@0:8@16@24q32
Q24@0:8@16
v32@0:8@16Q24
v32@0:8@16@24
@48@0:8@16@24q32^@40
@24@0:8^{_NSZone=}16
v24@0:8Q16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
@24@0:8@?16
i20@0:8i16
^v16@0:8
Q20@0:8S16
Q24@0:8Q16
@?16@0:8
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<TTSSynthesizer::Marker, std::allocator<TTSSynthesizer::Marker>>="__begin_"^{Marker}"__end_"^{Marker}"__end_cap_"{__compressed_pair<TTSSynthesizer::Marker *, std::allocator<TTSSynthesizer::Marker>>="__value_"^{Marker}}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@"NSError"
@"NSMutableArray"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@40@0:8@16@24^@32
@32@0:8@16^@24
@36@0:8@16B24@?28
v24@0:8^v16
@"VSSpeechSynthesisCallbackResult"
@"NSLock"
B20@0:8S16
@40@0:8@16@24@32
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
B40@0:8^@16^@24q32
B20@0:8B16
v40@0:8@16@24@32
^{__CFDictionary=}16@0:8
v52@0:8@16@24B32@36@44
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateOpenURLAsync"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@"AVAudioFormat"
@"AVAudioConverter"
@"AVAudioCompressedBuffer"
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
^{OpaqueAudioConverter=}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
@28@0:8@16i24
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
@"NSCharacterSet"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@20@0:8i16
@28@0:8@16B24
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
@"NSData"
@"NSUUID"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
@32@0:8@16Q24
{_NSRange=QQ}24@0:8@16
^v24@0:8Q16
@"NSMutableData"
B48@0:8@16@24q32@?40
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPreviewRequest"24
v32@0:8@"VSSpeechConnection"16@"NSError"24
B32@0:8^f16^f24
v48@0:8@16@24q32@?40
d24@0:8@16
v40@0:8@16q24@?32
@36@0:8@16q24B32
@28@0:8q16B24
B36@0:8q16B24^@28
B28@0:8B16^@20
B24@0:8^@16
v64@0:8@16@24q32q40q48@?56
v56@0:8@16@24q32q40@?48
@"VSSpeechConnection"
{?="delegateStartWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateStreamSynthesisAudioData"b1"willUseInput"b1"delegateDidStartPreviewRequest"b1}
@"<VSSpeechSynthesizerDelegate>"
@"SiriTTSDaemonSession"
@"AFAudioPowerUpdater"
@"AFAudioPowerXPCProvider"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv28@0:8@16B24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16q24@?32
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv28@0:8@"NSString"16B24
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv40@0:8@"VSSpeechRequest"16q24@?<v@?@"NSString"@"NSError">32
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset"@"NSError">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
v28@0:8@16B24
v32@0:8@16q24
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@"TRIClient"
@"<TRINotificationToken>"
|?5^
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
_downloadSize
_isPurgeable
_storage
v8@?0
audio_duration
audio_output_route
audio_queue_latency
can_use_server_tts
character_count
client_bundle_identifier
error_code
experiment_identifier
is_server_stream_tts
is_server_timeout
is_server_tts_racing
is_speech_request
is_synthesis_cached
is_warm_start
neural_alignment_stall
neural_audio_click
neural_fallback
prompt_count
real_time_factor
server_first_packet_latency
server_last_packet_latency
server_streamed_audio_duration
source_of_tts
synthesis_to_speech_time_gap
tts_and_playback_total_latency
tts_synthesis_latency
tts_total_latency
voice_asset_key
voice_resource_asset_key
  "%@": %@,
  "%@": "%@",
_utterance
_voiceAssetKey
_voiceResourceAssetKey
_audioOutputRoute
_clientBundleIdentifier
_experimentIdentifier
_promptCount
_sourceOfTTS
_errorCode
_requestCreatedTimestamp
_synthesisBeginTimestamp
_synthesisEndTimestamp
_speechBeginTimestamp
_speechEndTimestamp
_audioStartTimestampDiffs
_serverFirstPacketTimestamp
_audioDuration
_serverStreamedAudioDuration
_isWarmStart
_isCacheHitFromDisk
_isCacheHitFromMemory
_isSpeechRequest
_canUseServerTTS
_isServerTTS
_isServerStreamTTS
_isServerTimeout
_isServerTTSRacing
_neuralAlignmentStall
_neuralAudioClick
_neuralFallback
is_server_tts
osprey_round_trip
osprey_streaming
ace_round_trip
ace_inline_streaming
device
inline_tts
audio_request
device_cached_synthesis
unknown
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.notification.voice-purge
VSMobileAssetServiceErrorDomain
VSTrialServiceErrorDomain
MobileAssetProperties
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
Name
Languages
LanguagesCompatibility
Language
Gender
Footprint
Type
TTSResources/PreinstallAssets/
/private/var/mobile/Library/VoiceServices/voices/
%@.tmp
VSMobileAssetsManager.m
negative size
v16@?0q8
com.apple.voiced.assetQueryQueue
%@_%@_%@_%@_%@
com.apple.voiceservices
preinstall_metadata.plist
_RelativePath
AssetData
Assets
q24@?0@"MAAsset"8@"MAAsset"16
q24@?0@"VSVoiceAssetSelection"8@"VSVoiceAssetSelection"16
VSMobileAssetsManager
Cleaning voice assets is disabled in internal setting.
v16@?0@"NSError"8
v24@?0@"NSMutableArray"8q16
%@_%@
B24@?0@"VSTrialVoice"8@"NSDictionary"16
q24@?0@"VSTrialVoice"8@"VSTrialVoice"16
v20@?0d8f16
v12@?0f8
v20@?0B8@"NSError"12
B24@?0@"VSVoiceAssetSelection"8@"NSDictionary"16
Unable to download catalog
v16@?0@"MAProgressNotification"8
Unable to download asset
discretionary
immediate
Asset is in an unknown state
Info.plist
CFBundleIdentifier
@"NSString"8@?0
local_voice
_default
VSRecognition
<VSRecognition: %p model=%@>
recognition is already active
recognition reuse attempted
error converting disambiguation context to server
error converting audio input path to server
error converting model identifier
connection failure
recognition request denied
couldn't establish connection
recognition cancelled
connection lost
com.apple.voiceserviceslogging
default
event
enableTrial
enableAudioDump
logSensitiveText
DisableCaching
DisableAssetCleaning
AllowAnyAssetSubscription
EnableLocalVoices
whisper
ServerTTSTimeout
DeviceTTSWaitTime
defaultVolume
defaultPitch
defaultRate
forceServerTTS
disableServerTTS
disableInlineStreamTTS
disableDeviceRacing
disableOspreyStreaming
StreamBufferDuration
useBetaVoice
ospreyEndpointURL
simulateNetworkStall
disableDeviceNeuralTTS
useSSMLInput
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
defaultToNonDiscretionaryDownloads
tts_languages
plist
tts_language_fallbacks
en-US
_VSServerConnection
com.apple.voiced
%@:%@:%@
allowing_cellular
download_size
download_duration
download_progress
setup_duration
note.server.died
note.recog.prepare
note.recog.start
note.recog.results
note.recog.cancel
note.recog.error
key.recog.results
key.recog.errordesc
key.recog.errorcode
VSErrorDomain
vsplist
yyyy-MM-dd-HH-mm-ss'.vslog'
Library
Logs
CrashReporter
VoiceServicesRecognition
Latest.vslog
HH-mm-ss-
MaxLogCount
q24@?0@"NSURL"8@"NSURL"16
classes
phrases
modelid
handler
) <%@>
VSRecognitionResult
%@:%@
seqtag
known
knownp
ambig
ambigp
VSRecognitionDisambiguationContext
<VSRecognitionDisambiguationContext %p [%@]> 
 will disambiguate with sequence tag %@
 known class values:
constrained ambiguous classes:
  %@ = "%@" (%@)
  %@ = "%@"
  %@ =
     "%@" (%@)
     "%@"
VoiceServices
lowPowerDeviceNeural
use_SiriTTSService
use_SiriTTSServiceV2
lowInactiveMemory
VoiceServicesErrorDomain
basic_string
com.apple.voiceservices.kwidxchanged
top-level
class-kws
__model-kws
DeviceClassNumber
InternalBuild
HardwarePlatform
t8030
_languageCode
_voiceName
_previewType
VSVocalizerEngine
path
mimeType
TTSSynthesizer::load_voice_resource
unknown path
unknown mime-type
i12@?0i8
tts.neural.use_fallback
tts.metrics.alignment_stall
tts.metrics.audio_has_click
tts.feature.phonemes
TTSSynthesizer::synthesize_text_with_markers_async
application/edct-bin-dictionary
application/x-vocalizer-rettt+text
vector
com.apple.voiceservices.logging
VSLogLevel
VSOutputLevel
com.apple.voiceservices.language
lang-id
%@Library/Managed Preferences/mobile/%@.plist
mobile
com.apple.AppSupport.loggingDefaultsChanged
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
TTSResources
language_fallbacks.plist
zh-Hans
zh-CN
com.apple.language.changed
range
\audio=
\audio="%@"\
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/
AssistantEtiquette.wav
\mrk=%@=%@\
\toi=lhp\
\toi=orth\
\tn=normal\
\tn=
.wav
\\pause=['"]?([0-9]+)['"]?\\
<break time=['"]([0-9]+)ms['"]\s*/>
\\toi=lhp\\([^
'(?:[^'\\]|\\.)*'
"(?:[^"\\]|\\.)*"
(?:%@|%@)
\w+=%@
<phoneme\s+(%@)\s+(%@)\s*/>
alphabet=
\\toi=\w+\\.*?
\\toi=orth\\
\\toi=\w+\\.*
<phoneme.*?/>
\\\w+=.+?\\
</?.*?>
<speak>
speak
<phoneme alphabet="lhp" ph="
phoneme
"></phoneme>
SSML error
unbalanced phoneme tag
say-as
</say-as>
unbalanced say-as tag
Error in tn override tag, ignore
<say-as interpret-as="%@">
</%@>
NSString *soft_AXSpeechTransformTextWithLanguage(NSString *__strong, AXSpeechTransformOptions, NSString * _Nullable __strong, NSMutableArray * _Nullable __strong)
NSString+VSSpeechService.m
AXSpeechTransformTextWithLanguage
void *libAXSpeechManagerLibrary(void)
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
com.apple.voiceservices.assetInstalled
common
Library/VoiceServices/Assets
FormatVersion
/System/Library/PrivateFrameworks/VoiceServices.framework/
.migrated
NotForSiri
voice_format_version.plist
broker.hdr
broker.hdr.tmp
broker.hdr.asset
Tones
%@%@
.tmp
word_timings
TTSWordTimings
_clientID
_accessoryID
_voice
VSRecognitionSessionKeywordsDidChangeNotification
action already in progress
session is finished or invalid
session is invalid or not finished
session is already speaking
VSSpeechServiceDecoderErrorDomain
@"AVAudioBuffer"20@?0I8^q12
Failed to create opus decoder
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
decoder gave us %d bytes bytes but we really only expected %d
Could not finish decoding, res %@
<private>
recognition action not implemented
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_TRY_SAY_1
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_NETWORK_STALL
_MALE
strings
%@_%d
Interstitials
DeviceSetup
VSSpeechLangCharset
CharacterBinaryMaps
could not create recognition instance
recognition already attempted or in progress
com.apple.voiceservices.metrics
com.apple.voiceservices.download
@"NSDictionary"8@?0
com.apple.AssistantServices
voice_configs.plist
vocalizer_resource_order
vocalizer_resources
_voices
VoiceServices-Config.plist
voice_speech_rate
voice_speech_pitch
voice_speech_volume
VoiceResource: %@_CV%@
_languages
_searchPathURL
_startTime
_textRange
<VSSpeechWordTimingInfo>{startTime = %.3f; textRange = %@}
model <%@> class <%@>
com.apple.yn
0x%x
no URL to launch
{AudioStreamBasicDescription=dIIIIIIII}
_audioData
_text
_identifier
_siriRequestId
_audioSessionID
_enqueue
%@%@kHz
Opus
PCM%@KHz
sessionId %u, clientId %@, %@ bytes, input format %@, output format %@, requestCreatedTime %@, text '%@', identifier: %@, accessoryID:%@
match
replace
case-sensitive
eat-punct
com.apple.voiceservices.class
title
name
textForAttributes
attributes
startTime: %llu, language:%@, name:%@, gender:%@, type:%@, footprint:%@, rate:%.2f, pitch:%.2f, volume:%.2f, shouldWhisper:%d, canUseServerTTS:%d, disableCompactFallback:%d, disableDeviceRacing:%d, shouldWaitCurrentSpeaking:%d, shouldCache:%d, contextInfo:%@, customResourceURLs:%@, session:%d, accessoryID:%@, text:'%@'
_footprint
_voiceType
_gender
_outputPath
_rate
_pitch
_volume
_shouldWhisper
_shouldCache
_disableCompactVoiceFallback
_disableDeviceRacing
_forceServerTTS
_retryDeviceOnNetworkStall
_shouldStreamAudioData
_shouldWaitCurrentSpeaking
_resourceListURL
_resourceSearchPathURL
_customResourceURLs
_contextInfo
_pointer
_powerProfile
%@%@: %@
v32@?0@8@16^B24
VSMappedData%p
%02x
 %@ %@
com.apple.voiceservices.keepalive
com.apple.voiceservices.tts
com.apple.voiceservices.notification.synthesis-done
Request is nil.
language is not set.
Request has been used before. Please make a new copy of it.
text is not set.
Audio request has invalid audio data.
Missing text of inline streaming request.
Invalid audio request. Audio is invalid.
Audio caching request must be either inline streaming or audio request.
v20@?0d8B16
v16@?0@"AFXPCWrapper"8
VSSpeechSynthesizer
VSSpeechSynthesizerCallbackThread
com.apple.assistantd
com.apple.accessibility.axassetsd
com.apple.accessibility.AccessibilityUIServer
VSSpeechSynthesizer_%p@%@_%d
q16@?0q8
v16@?0@"SiriTTSInstrumentationMetrics"8
v16@?0@"SiriTTSAudioData"8
v16@?0@8
v24@?0@"NSString"8@"NSError"16
v12@?0B8
v16@?0@"NSArray"8
v24@?0@"SiriTTSSynthesisVoice"8@"NSError"16
stop presynthesized request timeout
stop request timeout
pause request timeout
ar-SA
da-DK
it-IT
ja-JP
nb-NO
nl-NL
ru-RU
sv-SE
generic
-[VSSpeechSynthesizer estimateDurationOfRequest:completion:]_block_invoke
v24@?0d8@"NSError"16
-[VSSpeechSynthesizer connection:speechRequest:didStopAtEnd:phonemesSpoken:error:]_block_invoke
-[VSSpeechSynthesizer connection:synthesisRequest:didFinishWithInstrumentMetrics:error:]_block_invoke
VSAudioPowerUpdateQueue
v16@?0f8f12
@"NSArray"16@?0@"NSArray"8
%@:%@:%@:%@
v24@?0@"VSVoiceAsset"8@"NSError"16
v16@?0@"VSVoiceAsset"8
v24@?0@"NSArray"8@"NSError"16
AFAudioPowerXPCProvider
Class getAFAudioPowerXPCProviderClass(void)_block_invoke
VSSpeechSynthesizer.m
Unable to find class %s
void *AssistantServicesLibrary(void)
AFAudioPowerUpdater
Class getAFAudioPowerUpdaterClass(void)_block_invoke
Auto Downloaded Assets
autoDownloadedAssets
subscribedAssets
OOBTriggeredDate
OOBNeedsToBeMeasured
lastTTSRequestDate
deviceID
com.apple.voiceservices.xpcconnection
-[VSSpeechConnection _remoteObjectSync]_block_invoke
v32@?0@"VSSpeechRequest"8Q16^B24
v32@?0@"VSPresynthesizedAudioRequest"8Q16^B24
v32@?0@"NSValue"8@"VSSpeechRequest"16^B24
-[VSSpeechConnection queryPhaticCapabilityWithRequest:]_block_invoke
-[VSSpeechConnection isSystemSpeaking]_block_invoke
-[VSSpeechConnection isSystemSpeakingOnBehalfOfCurrentConnection]_block_invoke
-[VSSpeechConnection forwardStreamObject:]_block_invoke
audioData
packetDescription
packetCount
asbd
undefined
compact
premium
premiumhigh
beta
male
female
neutral
vocalizer
custom
gryphon
neural
MasteredVersion
ContentVersion
builtin
%@:%@:%@:%@:%@:%@
%@:%@:%@:%@:%@:CV%@:MV%@:Compatibility%@
Type:%@, Name: %@, Languages: %@, Gender: %@, Footprint: %@, Installed: %@, ContentVersion: %@, MasteredVersion: %@, downloadSize: %@, isBuiltIn: %@
_name
_type
_isInstalled
_isBuiltInVoice
_isVoiceReadyToUse
B24@?0@8@"NSDictionary"16
_endpoint
SIRI_TEXT_TO_SPEECH
com.apple.siri.tts
com.apple.siri.tts.voice
com.apple.siri.tts.resource
.version
assetSize
ttsCompatibilityVersion
ttsContentVersion
gender
%@.voice.%@.%@.%@.%@
Voice factor name: %@
%@.resource.%@
VSTrialService.downloadQueue
v16@?0@"<TRINamespaceUpdateProtocol>"8
immediateDownloadForNamespaceNames cannot use discretionary download option.
v16@?0Q8
gNSt3__110__function6__funcIU8__strongU13block_pointerFiN14TTSSynthesizer15CallbackMessageEENS_9allocatorIS6_EES4_EE
NSt3__110__function6__baseIFiN14TTSSynthesizer15CallbackMessageEEEE
U13block_pointerFiN14TTSSynthesizer15CallbackMessageEE
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_0
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_1
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_2
NSt3__110__function6__funcIZ51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z51-[VSSpeechEngine synthesizeText:loggable:callback:]E3$_3
mcpl
MbP?
@mcpl
@mcpl
@supo
@supo
@mcpl
ASAttributeCompatibilityVersion should be NSNumber, got NSString for %@
CV: %@
Compatibility: %@
#MobileAsset migrate '%@', error: %@
#MobileAsset migrate '%@', success
#MobileAsset Ignore cached voice selection for voice query key %@ since it is not installed anymore.
#MobileAsset Ignore neural voice due to thermal critical condition.
#MobileAsset Found cached voice selection %@ for voice query key %@
#MobileAsset Ignore neural voices since device neural TTS is disabled.
#MobileAsset Selected %{public}@ and will cache it for %{public}@
Purging corrupted VoiceResource '%{public}@', error: %{public}@
#MobileAsset Found cached voice resource %@ for %{public}@
#MobileAsset Cached voice resource is corrupted %@
#MobileAsset Unable to find asset for VoiceResources %{public}@
#MobileAsset Found voice resource %@ for %{public}@
#MobileAsset current in-use asset, %@
#MobileAsset ignore VoiceOver asset, %@
#Trial current in-use asset, %@
Cleaning unused assets.
#MobileAsset Cleaning voice assets is disabled in internal setting. Skip cleaning...
#Trial Search voice asset for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial no suitable installed voices found for lang: %{public}@, name: %{public}@, type: %{public}@, footprint: %{public}@
#Trial Found suitable voice: %{public}@
Parameter language can't be nil for voice selection
Searching voice asset for lang: %{public}@, name: %{public}@, type: %{public0}@, gender: %{public}@, footprint: %{public}@
Search local voices for lang: %{public}@, name: %{public}@
Built-in voice is requested.
Search voices in Trial
Search voices in MobileAsset
Search voices in pre-installed location as fallback
Fallback to custom compact voice
Fallback to built-in compact voice
Selected voice %{public}@
#Trial Found local voice, skip downloading. Target voice: %@
#Trial Found local MobileAsset voice with same or higher version, skip downloading. Target voice: %@
Language must be provided for voice download.
#Trial Enqueued downloading: %{public}@
#Trial Unable to download namespace to download voice: %@, error: %@
#Trial Unable to find suitable voice to download for voice criteria: %@
Target voice to download: %@
#Trial Removing voice: %@
#Trial Unable to remove voice %@, error: %@
#Trial Removed voice: %@
#Trial Cancelling voice downloads: %{public}@
#Trial Cancelling voice download: %{public}@
Removing voice: %{public}@
Asset not removed because it is not present: %@
#Trial Cannot find any Trial resource, skip downloading. Target resource: %@
#Trial Found local resource, skip downloading. Target resource: %@
#Trial No MobileAsset resource found, will download Trial resource. Target resource: %@
#Trial Found same or newer resource in MobileAsset, skip downloading. Target resource: %@
#Trial Enqueue downloading resource: %@
#Trial Error downloading resource: %@, error: %@
#Trial Start downloading for: %@
#MobileAsset ERROR query '%@', timeout after 1 sec
#MobileAsset WARNING query '%@', error: %@
#MobileAsset Catalog '%@' download error: %@
#MobileAsset err %@, unable to download asset %{public}@
#MobileAsset Finished downloading asset %{public}@
#MobileAsset Begin %@ download, allowing cellular %{BOOL}d: %@
#MobileAsset Asset is already downloading: %{public}@
#MobileAsset download skipped, asset is already installed: %{public}@
#MobileAsset download skipped, asset is in an unknown state: %{public}@
#MobileAsset purge asset: %{public}@
#MobileAsset purge error: %@
#MobileAsset cancel downloading asset: %{public}@
#MobileAsset Cancel download error: %@
#MobileAsset Purge cannot find asset: %{public}@
#MobileAsset not removed because it is required by the OS: %{public}@
Ignoring all neural voices due to disableDeviceNeuralTTS
Ignoring neural voice %@. Current states as H12 platform: %{BOOL}d, thermal state:%d, low power enabled:%{BOOL}d
#MobileAsset Couldn't find any built-in voice for language: %{public}@
Unable to query local voice directory, %@
Failed to convert %ld recognition results
process is not running as user Mobile: it won't share the same UserDefaults as voiced
No cache directory from which to get the size: %@
Error getting cache path: %@, error: %@
Unable to get URL: %@, URL resources: %@
Can't remove file '%@', error: %@
Cleaned directory: '%@', LRU limit: %d, latency: %f
Failed siritts_create_text_to_phoneme for voice %@, system %ld, with error: %s
Exception: %s
voice path '%@', resource path '%@'
%d files under voice path:
- %@
Failed to initialize synthesizer due to missing voice path.
Initializing engine with voice path: %@
Failed to initialize synthesizer: %s
Failed to initialize synthesizer: %zu
Error setPitch 0x%zx
Error setRate 0x%zx
Error setVolume 0x%zx
Unable to load resource '%@'
Url doesn't conform to RFC 1808 '%@'
Loading resource: %@, mime-type: %@
Unable to find mime-type for '%@'
Unknown voice resource handle to unload: %@
VSSpeechEngine %p started synthesis.
VSSpeechEngine %p finished synthesis.
Engine preheating latency: %.3f
compact explicitly specified, look at framework asset first
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %{public}@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Trying to migrate asset because it's not valid: %@
After migrating asset, it's still not valid -- sorry
---> asset's version is %@
---> engine's version is %@
Couldn't get asset's version and/or language
Deleting the asset located here: %@ because the format versions don't match
***ERROR*** There was an error (%d - %s) when trying to symlink %s to %s
Symlinked %s to %s
Successfully appended broker header files
***ERROR*** couldn't append broker header files (%d - %s)
***ERROR*** couldn't move broker header file to final location (%d - %s)
Couldn't initialize the engine voice format versions
Unable to lock temporary asset: %s; presumably peer was first - error: %d
Temporary asset: %s has moved; presumably peer was first - error: %d
Couldn't move the temporary asset: %s to the real asset: %s - error: %d
Moved the temporary asset: %s to the real asset: %s
Couldn't get the contents of the assets directory (error %ld)
Deleting asset at url: %@
Unable to locate word '%@' in '%@'
Found prepared word timing info for voice '%@', text: '%@'
converter.maximumOutputPacketSize is 0. Falling back to maximumPacketSize 1024. Converter is %@
AVAudioConverter.maximumOutputPacketSize is 0.
Invalid target asbd: %@
Could not create Opus decoder: %{public}@
Only expecting to get 1 packet at a time, not %lu
Localize for '%@' in '%{public}@'
Unable to find '%{public}@' localized string for key '%@', return empty string
Searching predefined string for '%@' in '%{public}@'
Unable to find '%{public}@' predefined string for key '%@', return default en-US string
Unable to find '%{public}@' predefined string for key '%@', return empty string
CoreAnalytics eventName:%@ not sent. Event name must not be in current config
Successfully reportEvent with domain '%@'
OOB subscription completion observed with %@ %@
Unable to load plist at '%{public}@', error: %{public}@
Unable to read voice_configs.plist
voice_configs.plist does not have key '_voices'
You're using a deprecated method [VSVoiceResourceAsset defaultVoiceType]; use `VSSpeechVoiceDataTypeUndefined` or `[VSVoiceResourceAsset defaultVoiceNameForGender:]` instead
You're using a deprecated method [VSVoiceResourceAsset defaultVoice]; use `defaultVoiceGender` instead
Out of word boundary: %ld is greater than %ld
Enqueuing request: %@
Queue is now:
Dispatching open URL: %@
Open URL failed: %@
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file, errno: %d, error: %s
%{public}@ is not TTS language, VSSpeechSynthesizer fallback to %{public}@
Cancel #PresynthesizedAudioRequest from client %{public}@ was ignored, no request to stop
Unable to subscribe voice, error %@
Unable to get synthesis voice, error %@
VSSpeechSynthesizer keepActive must be true before prewarming.
Invalid #PrewarmRequest: %@, error: %@
#PrewarmRequest %llu from client %{public}@, request: %@
Stop #SpeechPresynthesizedAudioRequest %llu from client %{public}@, synchronously: %{BOOL}d
Stop #SpeechPresynthesizedAudioRequest from client %{public}@ was ignored, no request to stop
Stop #SpeechRequest from client %{public}@ was ignored, no request to stop
Stop #SpeechRequest %llu from client %{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest %llu from client %{public}@, boundary: %@, synchronously: %{BOOL}d
Pause #SpeechRequest from client %{public}@ was ignored, no request to pause
Invalid #SynthesisRequest: %@, error: %@
Start #SynthesisRequest %llu from client %{public}@, %@
Invalid #SpeechRequest: %@, error: %@
Start #SpeechRequest %llu from client %{public}@, %{public}@
Invalid #PresynthesizedAudioRequest: %@, error: %@
Start #PresynthesizedAudioRequest %llu: %@
Invalid #AudioCachingRequest: %@, error: %@
Cache #PresynthesizedAudioRequest %llu: %@
Cancel #SpeechRequest from client %{public}@ was ignored, no request to stop
Cancel #SpeechRequest %llu from client %{public}@
Cancel #PresynthesizedAudioRequest %llu from client %{public}@
Error Stop #SpeechRequest %@
Error Stop #PresynthesizedAudioRequest %@
Resume #SpeechRequest %llu from client %{public}@
Resume #SpeechRequest from client %{public}@ was ignored, no request to resume
#RoughEstimateDuration Request utterance: %@
#RoughEstimateDuration calculated duration: %.2f, using %@ locale, for text: %@
#EstimateDuration Request text: %@
Error %s, %@
#EstimateDuration Received duration: %.2f, for text: %@
Invalid #TTPRequest from client %{public}@: %@, error: %@
Start #TTPRequest %llu from client %{public}@
Error #TTPRequest %@
#TTPRequest %llu Received phonemes: %@, for text: %{public}@
%s, callback received in framework. %@
Current xpc connection %@ does not match %@
Notify daemon crash from: %@
#AudioPower Begin update
#AudioPower End update
#VoiceSubscription, client: %{public}@, accessory: %@, requested voices: %@
Ignore voice subscription due to null clientId.
#VoiceSubscription, client: %{public}@, accessory: %@, deduped voices: %@
Request to download with cellular, client: %{public}@, language: %{public}@, gender: %ld, type: %ld, footprint: %ld, name: %{public}@
Ignore get voice subscription due to null clientId.
%{public}@ is not TTS language, fallback to %{public}@
clearing auto-downloaded voice preferences for accessory %@
Closing xpc connection %p
%s, error: %@
Error updateWithConnectionIdentifier: %@
Can't prewarm: %@
Error at %s , %@ 
Error estimateDurationWithRequest:reply: %@
Error %@ asking for voices
Error %@ asking for voice footprints
Can't start VoicePreview: %@
Can't start PhonemesRequest: %@
Can't get subscribed voice assets: %@
Can't get all subscribed voice assets: %@
Can't get VoiceResource: %@
Can't get voice info: %@
%s, Error: %@
Failed is_neural_voice_ready %@ with error: %s
Failed should_use_neural_voice %@ with error: %s
Failed has_compact_neural_fallback %@ with error: %s
Failed check_thermal_critical_conditions: %s
Failed has_ota_ane_model %@ with error: %s
Failed is_ane_model_compiled %@ with error: %s
Failed compile_ane_model %@ with error: %s
#Trial Unexpected voice factor name: %@
#Trial Error: Factor has no level. It will be ignored. Factor name: %@
#Trial Error: voice should be as directory. Factor name: %@
#Trial Error: voice is not deployed. It will be ignored. Factor name: %@
#Trial Unexpected resource factor name: %@
#Trial Error: resource should be as directory. Factor name: %@
#Trial Received namespace 'SIRI_TEXT_TO_SPEECH' update
#Trial Unable to find asset for factor name '%@'.
#Trial Factor '%@' doesn't seem to be directory.
#Trial Factor '%@' is not downloaded yet.
#Trial Factor '%@' doesn't seem to be a file.
Skip immediate namespace download due to discretionary download option.
#Trial Start downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Unable to download Trial namespace. Error: %@
#Trial Finished downloading SIRI_TEXT_TO_SPEECH namespace.
#Trial Downloading asset with factor name: %@, discretionary:%d, allowCellular:%d
#Trial Unable to download asset with factor name: %@, error: %@
#Trial Downloaded asset with factor name: %@
#Trial Removing asset with factor name: %@
#Trial Unable to remove asset with factor name '%@', error: %@
#Trial Removed asset with factor name: %@
Unexpected multiple voices.
#Trial Cannot find any Trial resource for language %@
Unexpected multiple resources from Trial.
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
VSAssetBase
NSSecureCoding
NSCoding
VSInstrumentMetrics
MobileAsset
VSVoiceAssetSelection
Trial
VSMobileAssetsManager
VSSpeechInternalSettings
VSSpeechSynthesizerPreference
VSDownloadMetrics
VoiceServices
VSFeatureFlags
VSPhonemeTool
VSUtilities
VSPreviewRequest
NSCopying
VSSpeechEngineVoiceResource
VSSpeechSynthesisCallbackResult
VSSpeechEngine
VSSpeechService
VSWordTimingService
VSRecognitionResultHandler
NSObject
VSRecognitionResult
SiriTTSServiceBridge
VSVoiceSubscription
VSRecognitionSession
VSRecognitionSessionKeywords
VSOpusEncoder
VSOpusDecoder
VSRecognitionAction
VSLocalizedString
VSRecognitionDisambiguateAction
VSSpeechCharacterSet
VSRecognitionRecognizeAction
VSAnalytics
VSVoiceResourceAsset
VSSpeechWordTimingInfo
VSCacheUpdateListener
VSCacheUpdateRequest
VSRecognitionModelDataProvider
VSRecognitionConfirmAction
VS4CC
VSRecognitionURLAction
VSRecognitionSpeakAction
VSPresynthesizedAudioRequest
VSRecognitionResultHandlingThread
VSRecognitionResultHandlingRequest
VSTextPreProcessor
VSTextPreProcessorRule
VSSpeechAdditions
VSFormatArgument
VSSpeechRequest
VSMappedData
Hash
VSDurationRequest
VSSpeechSynthesizer
VSSpeechConnectionDelegate
AFAudioPowerProviding
VSPreferencesInterface
VSRemoteKeepAlive
VSKeepAlive
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSSpeechConnection
VSSpeechConnectionDelegateWrapper
VSAudioData
VSVoiceAsset
VSGenericUpdate
VSGenericUpdateEndpoint
NSXPCListenerDelegate
VSGenericBlockHolder
VSNeuralTTSUtils
VSTrialVoice
VSDownloadOptions
VSTrialVoiceResource
VSTrialService
Voice
VoiceResource
T@"NSNumber",C,N,V_downloadSize
.cxx_destruct
T@"NSURL",C,N,V_resourceListURL
OOBTriggeredDate
T@"VSTrialVoice",&,V_trialVoice
STS_cancelRequest:
Tq,V_serverFirstPacketTimestamp
STS_estimateDurationOfRequest:
_action
STS_forwardStreamObject:
_active
STS_isSpeaking
_audioInputPath
STS_queryPhaticCapabilityWithRequest:reply:
_beginSpeakingAttributedString:
STS_startSpeakingAudioRequest:
_currentRequest
STS_startSynthesizingRequest:
_forceServerTTS
STS_subscribedVoices:
_handleRequests
STS_textToPhonemesWithRequest:phonemeSystem:completion:
_isBuiltInVoice
T@"<TRINotificationToken>",&,N,V_trialNotificationToken
_neuralFallback
T@"<VSSpeechSynthesizerDelegate>",W,N,V_delegate
_recognizeFlags
T@"AFAudioPowerXPCProvider",&,N,V_previewAudioPowerXPCProvider
_vs_countPhoneticSyllables_lhp:
T@"AVAudioConverter",&,N,V_converter
arrayWithArray:
T@"AVAudioFormat",&,N,V_toFormat
assetQueryQueue
T@"NSArray",&,N,V_cachedResources
availableVoicesForLanguageCode:
T@"NSArray",&,N,V_customResourceURLs
beginNextAction
T@"NSArray",C,N,V_resourceList
bundleWithPath:
T@"NSCache",&,N,V_cachedMAVoiceResources
canUseServerTTS
T@"NSCharacterSet",&,N,V_characterSet
confirmedAction
T@"NSData",R,C,N,V_audioData
containsString:
T@"NSDictionary",&,N,V_vocalizerConfig
defaultInstance
T@"NSDictionary",C,N,V_contextInfo
downloadedVoicesMatching:reply:
T@"NSDictionary",C,N,V_voiceConfig
enqueue
T@"NSLock",&,N,V_clientRefreshLock
getLocalFileUrl
T@"NSMutableArray",&,N,V_audioRequests
handler
T@"NSMutableArray",&,N,V_requests
hasPath
T@"NSMutableData",&,N,V_fallbackInMemoryData
initWithFormat:
T@"NSMutableData",&,N,V_mutableDescription
initWithNSUUID:
T@"NSMutableDictionary",&,N,V_durationRequests
initWithVoicePath:resourcePath:
T@"NSNumber",C,N,V_compatibilityVersion
isEqualToArray:
T@"NSNumber",C,V_downloadSize
isLocal
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdaterQueue
isServerTimeout
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
isValid
T@"NSString",&,N,V_accessoryID
T@"NSString",&,N,V_filePath
languageMapping
T@"NSString",&,N,V_path
logText
T@"NSString",&,N,V_voice
masteredVersion
T@"NSString",&,V_builtInVoicePath
modelIdentifier
T@"NSString",C,N,V_bundleIdentifier
T@"NSString",C,N,V_language
numberWithLong:
T@"NSString",C,N,V_name
opusDataHandler
T@"NSString",C,N,V_utterance
perform
T@"NSString",C,V_audioOutputRoute
preferenceScore
T@"NSString",C,V_experimentIdentifier
previewRequests
T@"NSString",C,V_voiceAssetKey
release
T@"NSString",R,C
resourceListURL
T@"NSString",R,V_voiceDownloadKey
retainArguments
T@"NSURL",C,N,V_resourceSearchPathURL
setAccessoryID:
T@"NSUUID",&,N,V_siriRequestId
setConcurrentSynthesisRequests:
T@"NSUserDefaults",&,N,V_defaults
setDefaultRate:
T@"NSXPCConnection",&,N,V_xpcConnection
setFrameLength:
T@"NSXPCListenerEndpoint",&,N,V_endpoint
setIsPurgeable:
T@"TRIClient",&,N,V_triClient
setIsWarmStart:
T@"VSPresynthesizedAudioRequest",&,N,V_currentAudioRequest
setPacketCount:
T@"VSSpeechConnectionDelegateWrapper",&,N,V_delegateWrapper
setPreviewType:
T@"VSTrialService",&,N,V_trialService
setSequenceTag:
T@"VSVoiceAsset",&,N,V_voice
setShouldCache:
T@?,C,N,V_callback
setStopHandler:
T@?,C,N,V_errorHandler
setTotalLength:
T@?,C,N,V_opusDataHandler
setVoiceConfig:
T@?,C,N,V_stopHandler
shouldCleanFile
TB,N,V_active
startVoicePreviewRequest:reply:
TB,N,V_allowDiscretionary
storage
TB,N,V_disableCompactVoiceFallback
threadSafeQueue
TB,N,V_enqueue
unloadResource:
TB,N,V_hasAlignmentStall
version
TB,N,V_isBuiltInVoice
vs_substituteAudioWithLocalPath
TB,N,V_isPlayingPreview
wordTimingInfos
.cxx_construct
T@"NSString",C,N,V_languageCode
OOBNeedsToBeMeasured
T@"VSSpeechSynthesisCallbackResult",&,N,V_currentCallbackResult
STS_cancelAudioRequest:
Tq,N,V_stopMark
STS_downloadedVoicesMatching:reply:
STS_estimateDurationOfRequest:completion:
_actionStarted:
STS_getSynthesisVoiceMatching:reply:
_attributedText
STS_prewarmRequest:
_audioSessionID
STS_signalInlineStreaming:
_contentVersion
STS_startSpeakingRequest:
_eatPunctuation
STS_subscribeVoices:
_gender
STS_subscribedVoicesWithClientID:reply:
_handlingThread
T#,R
_lastUTF8Offset
T@"<VSSpeechConnectionDelegate>",W,N,V_delegate
_opusDataOffset
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
_volume
T@"AVAudioCompressedBuffer",&,N,V_outputBuffer
allKeys
T@"AVAudioFormat",&,N,V_fromFormat
assetId
T@"MAAsset",&,V_asset
audioBufferList
T@"NSArray",&,N,V_cachedVoices
beginAudioPowerUpdateWithReply:
T@"NSArray",C,N,V_languages
bundleForClass:
T@"NSAttributedString",C,N,V_attributedText
cachedResources
T@"NSCache",&,N,V_cachedMAVoiceSelections
classIdentifier
T@"NSData",&,N
containsObject:
T@"NSDate",&,N
dealloc
T@"NSDictionary",&,N,V_wordTimings
delegateWrapper
T@"NSDictionary",C,N,V_resourceMimeTypes
enableAudioDump
T@"NSError",&,N,V_error
formatSpecifier
T@"NSLock",&,N,V_synthesisLock
getVoiceNamesForLanguage:reply:
T@"NSMutableArray",&,N,V_previewRequests
hasOTAANEModel:
T@"NSMutableArray",&,N,V_wordTimings
initWithClient:accessory:voice:
T@"NSMutableData",&,N,V_mutableAudioData
initWithLength:
T@"NSMutableDictionary",&,N,V_concurrentSynthesisRequests
initWithString:
T@"NSMutableDictionary",&,N,V_stsRequestMapping
isCacheValidityIdentifierValid:
T@"NSNumber",C,N,V_contentVersion
isInternalBuild
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
isProxy
T@"NSObject<OS_dispatch_queue>",&,N,V_downloadQueue
isSpeechRequest
T@"NSObject<OS_dispatch_queue>",&,N,V_threadSafeQueue
isWatch
T@"NSString",&,N,V_clientID
keywordAtIndex:
T@"NSString",&,N,V_identifier
lastUTF16Offset
T@"NSString",&,N,V_text
lowercaseString
T@"NSString",&,N,V_voicePath
migrateDefaults
T@"NSString",C,N
nameKey
T@"NSString",C,N,V_clientBundleIdentifier
numberWithBool:
T@"NSString",C,N,V_masteredVersion
opaqueSessionID
T@"NSString",C,N,V_text
pcmData
T@"NSString",C,N,V_voiceName
pointer
T@"NSString",C,V_clientBundleIdentifier
preheat
T@"NSString",C,V_utterance
refresh
T@"NSString",C,V_voiceResourceAssetKey
removeVoiceResource:completion:
T@"NSString",R,N
results
T@"NSURL",C,N,V_outputPath
T@"NSURL",C,N,V_searchPathURL
setBool:forKey:
T@"NSUUID",C,N,V_accessoryID
setContextInfo:
T@"NSUserDefaults",&,N,V_internalDefaults
setDisableCompactVoiceFallback:
T@"NSXPCListener",&,N,V_listener
setIsInstalled:
T@"SiriTTSDaemonSession",&,N,V_proxySession
setIsServerTTS:
T@"VSPreferencesInterface",R
setMmappedData:
T@"VSSpeechConnection",W,N,V_connection
setPcmDataSize:
T@"VSSpeechRequest",&,N,V_currentRequest
setPromptCount:
T@"VSTrialService",R,N
setServerStreamedAudioDuration:
T@"VSVoiceAsset",&,V_voiceData
setSourceOfTTS:
T@?,C,N,V_completion
setSynthesizer:
T@?,C,N,V_handler
setURL:
T@?,C,N,V_pauseHandler
setWordTimings:
TB,N
speechBeginTime
TB,N,V_allowCellularData
stopPresynthesizedAudioRequest:
TB,N,V_canUseServerTTS
stringByAppendingPathComponent:
TB,N,V_disableDeviceRacing
typeFromString:
TB,N,V_forceServerTTS
valueWithRange:
TB,N,V_hasAudioClick
vocalizerConfig
TB,N,V_isInstalled
whisper
TB,N,V_isPurgeable
TB,N,V_isVoiceReadyToUse
TB,N,V_keepActive
TB,N,V_keepAudioSessionActive
TB,N,V_neuralDidFallback
TB,N,V_retryDeviceOnNetworkStall
TB,N,V_shouldCache
TB,N,V_shouldCleanFile
TB,N,V_shouldStreamAudioData
TB,N,V_shouldWaitCurrentSpeaking
TB,N,V_shouldWhisper
TB,R
TB,R,N
TB,V_canUseServerTTS
TB,V_discretionary
TB,V_isCacheHitFromDisk
TB,V_isCacheHitFromMemory
TB,V_isCellularAllowed
TB,V_isServerStreamTTS
TB,V_isServerTTS
TB,V_isServerTTSRacing
TB,V_isServerTimeout
TB,V_isSpeechRequest
TB,V_isWarmStart
TB,V_neuralAlignmentStall
TB,V_neuralAudioClick
TB,V_neuralFallback
TI,N,V_audioSessionID
TQ,N,V_assetSize
TQ,N,V_lastUTF16Offset
TQ,N,V_lastUTF8Offset
TQ,N,V_mappedLength
TQ,N,V_numOfPromptsTriggered
TQ,N,V_pcmBufferSize
TQ,N,V_pcmDataSize
TQ,N,V_requestCreatedTimestamp
TQ,N,V_samplesProcessed
TQ,N,V_totalLength
TQ,N,V_version
TQ,R
T^v,N,V_mmappedData
T^v,N,V_synthesizer
Td,N,V_pitch
Td,N,V_rate
Td,N,V_startTime
Td,N,V_volume
Td,V_audioDuration
Td,V_serverStreamedAudioDuration
Td,V_setupTimeInterval
Tf,N
Tf,N,V_pitch
Tf,N,V_rate
Tf,N,V_volume
Tf,V_downloadProgress
Tq,N,V_audioType
Tq,N,V_compatibilityVersion
Tq,N,V_footprint
Tq,N,V_gender
Tq,N,V_opusDataOffset
Tq,N,V_packetCount
Tq,N,V_pointer
Tq,N,V_powerProfile
Tq,N,V_previewType
Tq,N,V_state
Tq,N,V_storage
Tq,N,V_type
Tq,N,V_voiceType
Tq,R
Tq,R,V_downloadBeginTimestamp
Tq,R,V_downloadEndTimestamp
Tq,V_audioStartTimestampDiffs
Tq,V_eagerRequestCreatedTimestampDiffs
Tq,V_errorCode
Tq,V_promptCount
Tq,V_requestCreatedTimestamp
Tq,V_serverLastPacketTimestamp
Tq,V_sourceOfTTS
Tq,V_speechBeginTimestamp
Tq,V_speechEndTimestamp
Tq,V_synthesisBeginTimestamp
Tq,V_synthesisEndTimestamp
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_decoderStreamDescription
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_playerStreamDescription
T{_NSRange=QQ},N,V_textRange
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T{_opaque_pthread_mutex_t=q[56c]},N,V_voicePathLock
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_resource
UAFFactorLevelsWithNamespaceName:
UAFLevelForFactor:withNamespaceName:withLanguage:
URLByAppendingPathComponent:
URLForResource:withExtension:subdirectory:localization:
UTF8String
UUID
UUIDString
_accessoryID
_actionCompleted:nextAction:error:
_actionForEmptyResults
_allowCellularData
_allowDiscretionary
_ambiguousPhoneticValues
_ambiguousValues
_appendToFallbackMemory:
_appendToMappedMemory:
_asbd
_asset
_assetQueryQueue
_assetSize
_audioData
_audioDuration
_audioOutputRoute
_audioPowerUpdater
_audioPowerUpdaterQueue
_audioRequests
_audioStartTimestampDiffs
_audioType
_beginSpeakingString:attributedString:
_block
_builtInVoiceForLanguage:
_builtInVoicePath
_bundleIdentifier
_cachedMAVoiceResources
_cachedMAVoiceSelections
_cachedResources
_cachedVoices
_callback
_callbackQueue
_canUseServerTTS
_caseSensitive
_characterSet
_classID
_clientBundleIdentifier
_clientID
_clientRefreshLock
_clockFactor
_compatibilityVersion
_completion
_concurrentSynthesisRequests
_configureNewRecognitionInstance
_confirmFlags
_confirmedAction
_connection
_connectionInvalidated
_context
_contextInfo
_continueAfterDeferredStart
_continueSpeakingRequest
_convertToFallbackMemory
_converter
_createKeywordIndex
_createPhaseSortedKeywordsFromArray:
_createRecognitionInstanceWithCallbacks:info:
_currentAction
_currentAudioRequest
_currentCallbackResult
_currentRecognizeAction
_customResourceURLs
_dataProviders
_debugDumpPath
_decoder
_decoderStreamDescription
_defaultVoices
_defaults
_definedVoicesWithLanguage:name:type:footprint:
_delegate
_delegateWrapper
_deniedAction
_directoryOfFactorName:
_disableCompactVoiceFallback
_disableDeviceRacing
_disambiguationContext
_discretionary
_downloadAsset:options:progress:completion:
_downloadBeginTimestamp
_downloadEndTimestamp
_downloadFactorName:withOptions:progress:completion:
_downloadProgress
_downloadQueue
_downloadSize
_durationRequests
_eagerRequestCreatedTimestampDiffs
_endpoint
_enqueue
_enqueueRequest:
_ensureKeepAliveMaintenance
_error
_errorCode
_errorHandler
_experimentIdentifier
_fallbackInMemoryData
_fileOfFactorName:
_filePath
_flush
_flushTimer
_footprint
_fromFormat
_getResults:
_getVoiceAssetsForType:voiceName:language:gender:footprint:returnTypes:
_handleRecognitionCompleted:withResults:error:
_handleRecognitionPrepared:
_handleRecognitionStarted:
_handledThreadedResults:nextAction:
_handler
_hasAlignmentStall
_hasAudioClick
_hasDeferredStartCallback
_identifier
_init
_initShared
_inputLevel
_inputLevelDB
_installedVoiceResourceAssetForLanguage:
_internalDefaults
_isActivelyRecognizing
_isCacheHitFromDisk
_isCacheHitFromMemory
_isCellularAllowed
_isInstalled
_isListening
_isPlayingPreview
_isPurgeable
_isRecognizing
_isServerStreamTTS
_isServerTTS
_isServerTTSRacing
_isServerTimeout
_isSpeechRequest
_isVoiceReadyToUse
_isWarmStart
_keepActive
_keepAlive
_keepAudioSessionActive
_keywordAtIndex:
_keywordCount
_keywordIndexChanged
_keywordPhase
_keywords
_keywordsForModelIdentifier:
_knownPhoneticValues
_knownValues
_language
_languageCode
_languageID
_languages
_lastUTF16Offset
_levelInterval
_listener
_localVoiceForLanguageAndNamePath:
_lock
_mappedLength
_markers
_masteredVersion
_matchPattern
_mmappedData
_mobileAssetVoiceForLanguage:name:type:gender:footprint:
_mobileAssetVoiceResourceWithLanguage:
_modelID
_modelIdentifier
_mutableAudioData
_mutableDescription
_name
_neuralAlignmentStall
_neuralAudioClick
_neuralDidFallback
_nextKeywordUsingCursors:
_notifyDelegateActionStarted
_notifyDelegateFinishedSpeakingWithError:
_notifyDelegateOpenURL:completion:
_notifyRequestHandled:
_numOfPromptsTriggered
_opusDataHandler
_opusDecoder:
_outputBuffer
_outputPath
_packetCount
_path
_pauseHandler
_pauseSpeakingRequestAtNextBoundary:synchronously:
_pcmBufferSize
_pcmDataSize
_phonemeBuffer
_pitch
_playerStreamDescription
_pointer
_powerProfile
_previewAudioPowerXPCProvider
_previewRequests
_previewType
_promptCount
_proxySession
_purgeMobileAsset:
_queue
_rate
_recognition
_recognitionResultHandlingThread
_releaseFromPrepare
_remoteKeepAlive
_remoteObject
_remoteObjectSync
_remoteObjectWithErrorHandler:
_removeAssetWithFactorName:completion:
_removeTrialVoices:completion:
_repeatedSpokenFeedbackString
_replacement
_requestCreatedTimestamp
_requests
_reset
_resource
_resourceList
_resourceListURL
_resourceMimeTypes
_resourceSearchPathURL
_resultHandlingFlags
_resultString
_results
_retryDeviceOnNetworkStall
_rules
_samples
_samplesProcessed
_scrambledKeywordsAndAddToSet:
_searchPathURL
_sequenceTag
_serverConnection
_serverFirstPacketTimestamp
_serverLastPacketTimestamp
_serverStreamedAudioDuration
_session
_sessionFlags
_setAction:
_setAudioInputPath:
_setBluetoothInputAllowed:
_setConfirmed:
_setDebugDumpEnabled:
_setDebugDumpEnabled:dumpPath:
_setDebugDumpPath:
_setDelegate:
_setEngineResetRequired:
_setInputLevelUpdateInterval:
_setPreferredEngine:
_setQueue:
_setResults:
_setSession:
_setupTimeInterval
_shouldCache
_shouldCleanFile
_shouldStreamAudioData
_shouldTerminate
_shouldWaitCurrentSpeaking
_shouldWhisper
_siriRequestId
_sourceOfTTS
_speechBeginTimestamp
_speechEndTimestamp
_spokenLanguageChanged:
_spokenString
_spokenStringIsAttributed
_startTime
_state
_statusString
_stopHandler
_stopMark
_stopSpeakingPresynthesizedAudioRequest:synchronously:
_stopSpeakingRequest:atNextBoundary:synchronously:
_storage
_stsRequestMapping
_synthesisBeginTimestamp
_synthesisEndTimestamp
_synthesisLock
_synthesizer
_synthesizerFlags
_text
_textRange
_threadSafeQueue
_toFormat
_tokenizer
_topLevelKeywords
_totalLength
_triClient
_trialNotificationToken
_trialService
_trialVoice
_trialVoiceResourceWithLanguage:
_trialVoiceWithLanguage:name:type:footprint:
_type
_updateRequestQueue
_url
_utterance
_version
_vocalizerConfig
_voice
_voiceAssetKey
_voiceConfig
_voiceData
_voiceDownloadKey
_voiceName
_voicePath
_voicePathLock
_voiceResourceAssetKey
_voiceType
_vs_countPhoneticSyllables_xsampa:
_wordTimings
_xpcConnection
accessoryID
accessoryId
actionForRecognitionResult:
actionForRecognitionResults:
active
activeVoiceAssets
addCharactersInRange:
addKeyValueArray:with:
addKeyValuePair:with:
addObject:
addObjectsFromArray:
addObserver:selector:name:object:
addTimer:forMode:
addUpdateHandlerForNamespaceName:usingBlock:
adjustWordTimingInfo:forContext:
allObjects
allValues
allocWithZone:
allowAnyAssetSubscriber
allowCellularData
allowDiscretionary
allowsCellularAccess
ambiguousValuesForClassIdentifier:
amendNameVersionAndSizeWithMobileAssetAttributes:
anonymousListener
appendBytes:length:
appendData:
appendFormat:
appendRandomizationKey:withCount:
appendString:
appendString:withAttributes:
array
arrayForKey:
arrayWithCapacity:
arrayWithContentsOfFile:
arrayWithObject:
arrayWithObjects:
arrayWithObjects:count:
asbd
asset
assetSize
assetType
attachProgressCallBack:
attributedStringWithFormatAndAttributes:
attributedText
attributes
attributesOfItemAtPath:error:
audioData
audioDuration
audioOutputRoute
audioPowerUpdater
audioPowerUpdaterQueue
audioQueueLatency
audioRequest:didReportInstrumentMetrics:error:
audioRequest:didStopAtEnd:error:
audioRequestDidStart:
audioRequests
audioSessionID
audioStartLatency
audioStartTimestampDiffs
audioType
autorelease
availableFootprintsForVoice:languageCode:
availableLanguageCodes
availableLanguages
beginChunkDecoderForStreamDescription:
beginEncoding
beginReportingChanges
beginSpeakingFeedbackString
beginSpeakingString:
beginUpdate
boolForKey:
boolValue
builtInVoicePath
builtInVoices
bundleIdentifier
bundleIdentifierForVoiceType:
bundlePath
bundleWithIdentifier:
bytes
bytesAtOffset:
cachePresynthesizedAudioRequest:
cacheValidityIdentifier
cachedMAVoiceResources
cachedMAVoiceSelections
cachedVoices
callback
canLogRequestText
cancel
cancelAudioRequest:
cancelDownload:completion:
cancelDownloadSync
cancelDownloads:completion:
cancelMaintainingKeepAlive:
cancelRequest:
cancelWithRequest:
candidateToDownloadForVoice:
cappedRealTimeFactor
characterAtIndex:
characterClassCountForUtterance:language:
characterIsMember:
characterSet
characterSetWithBitmapRepresentation:
class
cleanDirectory:withDateOlderThan:
cleanDirectory:withLRULimit:
cleanMobileAssetVoiceResourcesWithActiveLanguages:
cleanOldMobileAssetVoiceResources
cleanUnusedAssets
cleanUnusedAssets:
clientBundleIdentifier
clientID
clientId
clientRefreshLock
clientWithIdentifier:
closeFile
coalescedRequest:
code
compare:
compatibilityVersion
compatibilityVersionFromMobileAssetAttributes:
compileANEModel:
completeWithNextAction:error:
completion
completionType
componentsJoinedByString:
componentsSeparatedByString:
concatenateWithAudio:
concurrentSynthesisRequests
configuredEndpointWithUpdateHandler:withConnection:
conformsToProtocol:
connection
connection:invalidatedWithError:
connection:presynthesizedAudioRequest:didStopAtEnd:error:
connection:presynthesizedAudioRequest:successWithInstrumentMetrics:error:
connection:presynthesizedAudioRequestDidStart:
connection:previewRequestDidStartPlaying:
connection:speechRequest:didGenerateAudioChunk:
connection:speechRequest:didReceiveTimingInfo:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:successWithInstrumentMetrics:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequestDidContinue:
connection:speechRequestDidPause:
connection:speechRequestDidStart:
connection:synthesisRequest:didFinishWithInstrumentMetrics:error:
contentVersion
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextInfo
contextInfoString
continueSpeakingWithError:
continueSpeechRequest:
convertToBuffer:error:withInputFromBlock:
converter
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createFileAtPath:contents:attributes:
createHandler
createNewXPCWrapperWithCompletion:
currentAudioRequest
currentCallbackResult
currentHandler
currentRequest
currentRunLoop
customResourceURLs
data
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithContentsOfFile:
date
dateWithTimeIntervalSinceNow:
debugDescription
debugDumpPath
decimalDigitCharacterSet
decodeBoolForKey:
decodeBytesForKey:returnedLength:
decodeChunk:outError:
decodeChunks:streamDescription:outError:
decodeDoubleForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decodePropertyListForKey:
decodeValueOfObjCType:at:size:
decoderStreamDescription
defaultCenter
defaultDownloadOptions
defaultManager
defaultPitch
defaultRate
defaultToNonDiscretionaryDownloads
defaultVoice
defaultVoiceGender
defaultVoiceNameForGender:
defaultVoiceType
defaultVolume
defaults
definedVoiceResourcesWithLanguage:
definedVoicesForLanguage:voiceName:type:footprint:
definedVoicesWithAssets:
definedVoicesWithLanguage:name:type:footprint:
delegate
deniedAction
derivedIdentifierForComponentName:fromSourceIdentifier:
description
descriptionFormatter
descriptiveKey
detachNewThreadSelector:toTarget:withObject:
deviceTTSWaitTime
deviceUUID
dictionary
dictionaryForKey:
dictionaryMetrics
dictionaryRepresentation
dictionaryRepresentationOfVoices:
dictionaryWithContentsOfFile:
dictionaryWithContentsOfURL:
dictionaryWithContentsOfURL:error:
dictionaryWithObjects:forKeys:count:
didEndAccessPower
directorySize:
directoryValue
disableAssetCleaning
disableAssetUpdate
disableCache
disableCompactVoiceFallback
disableDeviceNeuralTTS
disableDeviceRacing
disableInlineStreamTTS
disableMobileAssetURLReset
disableOspreyStreaming
disableServerTTS
discretionary
displayResultString
displayStatusString
domain
doubleValue
downloadBeginTimestamp
downloadCatalog:options:
downloadCatalog:options:completion:
downloadDuration
downloadEndTimestamp
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
downloadNamespaceImmediatelyIfNeededWithOption:completion:
downloadOptionsWithBattery:
downloadProgress
downloadQueue
downloadSize
downloadTrialVoiceResource:options:completion:
downloadVoice:withOptions:progress:completion:
downloadVoiceAsset:options:progressUpdateHandler:
downloadVoiceAsset:useBattery:progressUpdateHandler:
downloadVoiceResource:completion:
downloadVoiceResource:options:completion:
downloadVoiceResource:withOptions:progress:completion:
downloadVoiceResourceCatalogWithCompletion:
duration
durationRequests
eagerRequestCreatedTimestampDiffs
eagerRequestGapInterval
eagerRequestTimeGap
elementCount
emitMessage:
enableLocalVoices
encodeBool:forKey:
encodeBytes:length:forKey:
encodeChunk:
encodeDouble:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeValueOfObjCType:at:
encodeWithCoder:
endAudioPowerUpdate
endChunkDecoding
endEncoding
endMetrics
endUpdate
endpoint
engineCurrentCompatibility
engineMinimumCompatibility
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
error
errorCode
errorFromSTSError:
errorHandler
errorWithDomain:code:userInfo:
errorWithReason:
estimateDurationOfRequest:
estimateDurationOfRequest:completion:
estimateDurationWithRequest:didFinish:
estimateDurationWithRequest:reply:
estimatedTTSWordTimingForText:withLanguage:voiceName:
eventMetadata
exchangeObjectAtIndex:withObjectAtIndex:
expectedTimeRemaining
experimentIdentifier
extraBytesFromUTF8ToUTF16With:totalLength:begin:end:
factor
factorName
fallbackInMemoryData
fallbackLanguageForLanguage:
fileDescriptor
fileExistsAtPath:
fileHandleForUpdatingAtPath:
filePath
filePathURL
fileURLWithPath:
fileURLWithPath:isDirectory:
fileValue
filteredArrayUsingPredicate:
firstObject
floatForKey:
floatValue
footprint
footprintFromString:
footprintStringFromFootprint:
forceServerTTS
formattedArg
forwardStreamObject:
forwardWithStreamObject:
fromFormat
gender
genderFromString:
genderStringFromGender:
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAllAutoDownloadedVoiceAssets:
getAllVoiceSubscriptionsWithReply:
getAudioPower:
getAutoDownloadedVoiceAssets:
getAveragePower:andPeakPower:
getElementClassIdentifier:value:atIndex:
getFootprintsForVoiceName:languageCode:reply:
getLatestAssetFromArray:
getLocalAudioRequest:
getLocalPreviewRequest:
getLocalRequest:
getLocalUrl
getLocalVoiceAssets:
getLocalVoiceAssetsForLanguage:reply:
getLocalVoiceResources:
getLocalVoiceResourcesReply:
getLocalVoicesForLanguage:reply:
getResourceValue:forKey:error:
getSpeechIsActiveForConnectionReply:
getSpeechIsActiveReply:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getSynthesisVoiceMatching:reply:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
getVoiceInfoForLanguageCode:name:type:footprint:reply:
getVoiceResourceForLanguage:reply:
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handleResults:withHandler:
hasAMX
hasANE
hasAlignmentStall
hasAsset
hasAudioClick
hasCompactNeuralFallback:
hasDeferredAction
hasLevel
hasPhaticResponses:
hasPrefix:
hasSuffix:
hasValidAudio
hash
identifier
ignorePowerAndThermalState
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
inactiveVoiceAssets
init
initFileURLWithPath:
initForInputFeedback
initFromFormat:toFormat:
initFromMobileAssetAttributes:
initWithAccessoryID:
initWithAccessoryId:
initWithAudio:
initWithAudioData:decoderStreamDescription:playerStreamDescription:
initWithAudioData:playerStreamDescription:
initWithBlock:
initWithCallback:
initWithCapacity:
initWithCoder:
initWithCondition:
initWithContentsOfFile:
initWithContentsOfPath:languageIdentifier:
initWithContentsOfURL:
initWithDictionaryRepresentation:
initWithFactorLevel:
initWithFactorName:
initWithFilePath:initialSize:
initWithFormat:packetCapacity:maximumPacketSize:
initWithHandler:results:
initWithIdentifier:
initWithLanguage:
initWithLanguage:name:
initWithListenerEndpoint:
initWithMachServiceName:options:
initWithModelIdentifier:
initWithModelIdentifier:classIdentifier:
initWithPCMFormat:frameCapacity:
initWithProvider:queue:frequency:delegate:
initWithSourceASBD:
initWithSpokenFeedbackString:willTerminate:
initWithStreamDescription:
initWithSuiteName:
initWithText:identifier:
initWithText:voice:
initWithText:voice:phonemeSystem:
initWithTrialVoice:
initWithType:
initWithVoiceName:languageCode:gender:
initWithXPCWrapper:
initialize
initializeWithResourcePath:
inputLevel
inputLevelDB
insertObject:atIndex:
insertString:atIndex:
installedAssetsForType:voicename:language:gender:footprint:
installedLocalVoices
installedTrialVoiceResources
installedTrialVoicesForType:voiceName:language:footprint:
installedVoiceResources
instancesRespondToSelector:
intValue
integerValue
interfaceWithProtocol:
internalDefaults
invalidate
invocationWithMethodSignature:
invokeDaemon:
invokeUpdateWithObject:
isANECompilationPlatform
isANEModelCompiled:
isActivelyRecognizing
isBuiltInVoice
isBusy
isCacheHitFromDisk
isCacheHitFromMemory
isCellularAllowed
isDownloading
isEqual:
isEqualToDictionary:
isEqualToString:
isFinished
isH12Platform
isHomeHub
isHomePod
isInstalled
isKindOfClass:
isLowPowerDeviceNeuralEnabled
isLowPowerModeEnabled
isMemberOfClass:
isNeuralFallbackCondition
isNeuralTTSPlatform
isNeuralVoiceReady:
isPlayingPreview
isPurgeable
isRecognizing
isSeedBuild
isServerStreamTTS
isServerTTS
isServerTTSRacing
isSimilarTo:
isSpeaking
isSpeaking:
isStalled
isSynthesisCached
isSystemSpeaking
isSystemSpeakingOnBehalfOfCurrentConnection
isTrialEnabled
isUserCancelError:
isVoiceAssetWellDefined:
isVoiceReadyToUse
isWarmStart
keepActive
keepAudioSessionActive
keywordCount
killDaemon
knownValueForClassIdentifier:
knownValuesForClassIdentifier:
language
languageCode
languages
languagesFromMobileAssetAttributes:
lastFetchDate
lastObject
lastPathComponent
lastTTSRequestDate
lastUTF8Offset
length
lengthOfBytesUsingEncoding:
level
listener
listener:shouldAcceptNewConnection:
load
loadResource:error:
loadResourceAtPath:mimeType:error:
localizations
localizedDescription
localizedInterstitialStringForKey:language:
localizedOOBStringForKey:language:
localizedOOBStringForKey:language:gender:
localizedStringForKey:language:table:
lock
lockWhenCondition:
logSensitiveText
logUtterance
longLongValue
longValue
lowInactiveMemory
mainBundle
mainRunLoop
maintainWithAudioType:keepAudioSessionActive:
makeObjectsPerformSelector:
makeObjectsPerformSelector:withObject:
mappedLength
markerBuffer
matchedString:forTokenInRange:
matchesInString:options:range:
maximumOutputPacketSize
maximumRate
metadata
methodSignatureForSelector:
migrateAssetIfNeededWithAssetType:
migrateAssetsWithProgress:
mimeForFileExtension:
minimumRate
mmappedData
mutableAudioBufferList
mutableAudioData
mutableBytes
mutableCopy
mutableDescription
mutablePCMData
name
neuralAlignmentStall
neuralAudioClick
neuralDidFallback
neuralFallback
nextAction
nextActionWillRecognize
nextActionWillTerminateSession
numOfPromptsTriggered
numberOfRanges
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInteger:
numberWithUnsignedLongLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
opusDataOffset
ospreyEndpointURL
outputBuffer
outputPath
packetCount
packetDescriptions
path
pathExtension
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pathForResource:ofType:inDirectory:forLocalization:
pathWithComponents:
pauseHandler
pauseSpeakingAtNextBoundary:synchronously:error:
pauseSpeechRequest:atMark:
pcmBufferSize
pcmDataSize
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSelectorOnMainThread:withObject:waitUntilDone:
performUpdateForModelIdentifier:classIdentifier:
phonemeBuffer
phonemes
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
pickCorrectAssetFromLocalAssets:
pitch
playVoicePreviewForLanguageCode:voiceName:previewType:completion:
playerStreamDescription
postNotificationName:object:
postNotificationName:object:userInfo:
powerProfile
predefinedStringForKey:language:table:
predicateWithBlock:
preferredDownloadForVoice:
preferredLocalizations
preferredLocalizationsFromArray:forPreferences:
preinstallAssetsDirectory
preinstallAssetsMetadata
preinstalledAudioHashForLanguage:name:
preinstalledVoicesForLanguage:gender:name:
previewAudioPowerXPCProvider
previewRequestDidStartPlaying:
previewType
prewarmIfNeededWithRequest:
prewarmIfNeededWithRequest:reply:
prewarmWithRequest:didFinish:
privacySensitive
processIdentifier
processInfo
processMarkerBuffer
processName
processedTextFromString:
promptCount
proxySession
punctuationCharacterSet
purgeAsset:
purgeSync
queryForLanguage:forType:voiceName:gender:footprint:returnTypes:
queryForVoiceResourceAsset:returnTypes:
queryMetaData:
queryPhaticCapability:
queryPhaticCapabilityWithRequest:
queryPhaticCapabilityWithRequest:reply:
queryPhaticCapabilityWithVoice:reply:
queue
raise:format:
rangeAtIndex:
rangeOfString:
rangeOfString:options:range:
rangeValue
rate
realTimeFactor
recognitionAction
recognitionResultByReplacingValueForClassIdentifier:withValue:
recognitionResultHandlingThread:didHandleResults:nextAction:
recognitionResultWithModelIdentifier:classIdentifiers:values:
recognitionSession:didCompleteActionWithError:
recognitionSession:didFinishSpeakingFeedbackStringWithError:
recognitionSession:openURL:
recognitionSession:openURL:completion:
recognitionSessionDidBeginAction:
recognitionSessionWillBeginAction:
refreshTrialClient
regularExpressionWithPattern:options:error:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
remoteUpdateHanderForEndpoint:
removeAllObjects
removeDirectory:
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeLevelsForFactors:withNamespace:queue:completion:
removeMobileAssetVoiceResource:completion:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObserver:name:object:
removeSubscriptionsForAccessory:
removeTrialVoice:completion:
removeTrialVoiceResource:completion:
removeUpdateHandlerForToken:
removeVoice:completion:
removeVoiceAsset:completion:
repeatedSpokenFeedbackString
replaceCharactersInRange:withString:
replaceObjectAtIndex:withObject:
reportDownloadMetrics:
reportEvent:payload:
reportInstrumentMetrics:
requestCreatedTime
requestCreatedTimestamp
requests
requiresThreadedProcessing
reset
resetCache
resetResourcesCache
resource
resourceFromTrial:
resourceList
resourceMimeTypes
resourceSearchPathURL
resourceValuesForKeys:error:
respondsToSelector:
resultDisplayString
resume
retain
retainCount
retryDeviceOnNetworkStall
returnTypes:
rolloutIdentifiersWithNamespaceName:
roughEstimationWithRequest:
runUntilDate:
sampleBuffer
samplesProcessed
scheduledTimerWithTimeInterval:invocation:repeats:
searchPathURL
selectPreinstalledVoiceForLanguage:gender:name:
selectVoiceForLang:name:type:gender:footprint:
selectVoiceResourceAssetForLanguage:
selectVoiceResourceWithLanguage:
selectVoiceWithLanguage:name:type:footprint:
self
sensitiveActionsEnabled
sequenceTag
serverFirstPacketTime
serverFirstPacketTimestamp
serverLastPacketTime
serverLastPacketTimestamp
serverStreamFirstPacketLatency
serverStreamLastPacketLatency
serverStreamedAudioDuration
serverTTSTimeout
setActive:
setAllowAnyAssetSubscriber:
setAllowCellularData:
setAllowDiscretionary:
setAllowsCellularAccess:
setAmbiguousValues:phoneticValues:forClassIdentifier:
setArgument:atIndex:
setAsbd:
setAsset:
setAssetQueryQueue:
setAssetSize:
setAttributedText:
setAttributes:range:
setAudioData:
setAudioDuration:
setAudioOutputRoute:
setAudioPowerUpdater:
setAudioPowerUpdaterQueue:
setAudioRequests:
setAudioSessionID:
setAudioSessionId:
setAudioStartTimestampDiffs:
setAudioType:
setAutoDownloadedVoiceAssets:
setBluetoothInputAllowed:
setBuiltInVoicePath:
setBundleIdentifier:
setCachedMAVoiceResources:
setCachedMAVoiceSelections:
setCachedResources:
setCachedVoices:
setCallback:
setCanUseServerTTS:
setCharacterSet:
setClasses:forSelector:argumentIndex:ofReply:
setClientBundleIdentifier:
setClientID:
setClientRefreshLock:
setCompatibilityVersion:
setCompletion:
setConfirmedAction:
setConnection:
setContentVersion:
setContextId:
setConverter:
setCountLimit:
setCurrentAudioRequest:
setCurrentCallbackResult:
setCurrentRequest:
setCustomResourceURLs:
setData:
setDebugDumpEnabled:
setDefaultPitch:
setDefaultToNonDiscretionaryDownloads:
setDefaultVolume:
setDefaults:
setDelegate:
setDelegateWrapper:
setDeniedAction:
setDeviceTTSWaitTime:
setDidGenerateAudio:
setDidGenerateWordTimings:
setDidReportInstrument:
setDidStartSpeaking:
setDisableAssetCleaning:
setDisableAssetUpdate:
setDisableCache:
setDisableCompactVoice:
setDisableDeviceNeuralTTS:
setDisableDeviceRacing:
setDisableInlineStreamTTS:
setDisableOspreyStreaming:
setDisableServerTTS:
setDiscretionary:
setDiscretionaryBehavior:
setDownloadProgress:
setDownloadQueue:
setDownloadSize:
setDurationRequests:
setEagerRequestCreatedTimestampDiffs:
setEnableAudioDump:
setEnableLocalVoices:
setEndpoint:
setEnqueue:
setError:
setErrorCode:
setErrorCodes:
setErrorHandler:
setEventMetadata:
setExperimentIdentifier:
setExportedInterface:
setExportedObject:
setFailed:
setFallbackInMemoryData:
setFilePath:
setFireDate:
setFloat:forKey:
setFootprint:
setForceServerTTS:
setFromFormat:
setGender:
setHandler:
setHasAlignmentStall:
setHasAudioClick:
setIdentifier:
setIgnorePowerAndThermalState:
setImmediate:
setInputLevelUpdateInterval:
setInternalDefaults:
setInterruptionHandler:
setInvalidationHandler:
setIsBuiltInVoice:
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
setIsCellularAllowed:
setIsPlayingPreview:
setIsServerStreamTTS:
setIsServerTTSRacing:
setIsServerTimeout:
setIsSpeechRequest:
setIsVoiceReadyToUse:
setKeepActive:
setKeepAudioSessionActive:
setKeywordPhase:
setKeywords:
setKnownValue:phoneticValue:forClassIdentifier:
setKnownValues:phoneticValues:forClassIdentifier:
setLanguage:
setLanguageCode:
setLanguages:
setLastTTSRequestDate:
setLastUTF16Offset:
setLastUTF8Offset:
setListener:
setLock:
setLogSensitiveText:
setMappedLength:
setMasteredVersion:
setMaximumFractionDigits:
setMinimumFractionDigits:
setMutableAudioData:
setMutableDescription:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralDidFallback:
setNeuralFallback:
setNextAction:
setNextRecognitionAudioInputPath:
setNextRecognitionRequiresReset:
setNumOfPromptsTriggered:
setOOBNeedsToBeMeasured:
setOOBTriggeredDate:
setObject:forKey:
setObject:forKeyedSubscript:
setOpusDataHandler:
setOpusDataOffset:
setOspreyEndpointURL:
setOutputBuffer:
setOutputPath:
setPacketDescriptions:
setPath:
setPauseHandler:
setPcmBufferSize:
setPerformRecognitionHandlerActions:
setPitch:
setPointer:
setPowerProfile:
setPreferredEngine:
setPreviewAudioPowerXPCProvider:
setPreviewRequests:
setPrivacySensitive:
setProxySession:
setQueue:
setRate:
setRecognitionAction:
setRemoteObjectInterface:
setRepeatedSpokenFeedbackString:
setRequestCreatedTimestamp:
setRequests:
setRequiresPowerPluggedIn:
setResource:
setResourceList:
setResourceListURL:
setResourceMimeTypes:
setResourceSearchPathURL:
setResultDisplayString:
setRetryDeviceOnNetworkStall:
setSamplesProcessed:
setSearchPathURL:
setSelector:
setSensitiveActionsEnabled:
setServerFirstPacketTimestamp:
setServerLastPacketTimestamp:
setServerTTSTimeout:
setSetupTimeInterval:
setShouldCleanFile:
setShouldStreamAudioData:
setShouldWaitCurrentSpeaking:
setShouldWhisper:
setSimulateNetworkStall:
setSiriRequestId:
setSpeechBeginTimestamp:
setSpeechContext:
setSpeechEndTimestamp:
setSpokenFeedbackAttributedString:
setSpokenFeedbackString:
setStartTime:
setState:
setStatusDisplayString:
setStopMark:
setStorage:
setStreamBufferDuration:
setStsRequestMapping:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
setSubscribedVoices:forClientID:accessoryID:
setSynthesisBeginTimestamp:
setSynthesisEndTimestamp:
setSynthesisLock:
setSynthesisProfile:
setTarget:
setText:
setTextRange:
setThreadSafeQueue:
setToFormat:
setTriClient:
setTrialNotificationToken:
setTrialService:
setTrialVoice:
setTtsId:
setType:
setUseBetaVoice:
setUtterance:
setVersion:
setVocalizerConfig:
setVoice:
setVoiceAssetKey:
setVoiceData:
setVoiceName:
setVoicePath:
setVoicePathLock:
setVoiceResourceAssetKey:
setVoiceType:
setVolume:
setWhisper:
setWithArray:
setWithObject:
setXpcConnection:
setupTimeInterval
sha256hex
sharedInstance
sharedListener
sharedListenerIfExists
sharedManager
sharedService
sharedStream
shouldCache
shouldDownloadTrialResource:
shouldDownloadTrialVoice:
shouldStreamAudioData
shouldUseNeuralVoice:
shouldWaitCurrentSpeaking
shouldWhisper
signalWithInlineStreaming:
simulateNetworkStall
siriRequestId
size
sortUsingComparator:
sortedArrayUsingComparator:
sourceOfTTS
speakWithAudioRequest:didFinish:
speakWithSpeechRequest:didFinish:
speechBeginTimestamp
speechEndTime
speechEndTimestamp
speechEstimatedOutputBeginTimestamp
speechRequest:didReceiveTimingInfo:
speechRequest:didReportInstrumentMetrics:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequestDidContinue:
speechRequestDidPause:
speechRequestDidStart:
speechString
speechSynthesizer:daemonDidCrashWithError:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didStartPlayingPreviewRequest:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:
spokenFeedbackAttributedString
spokenFeedbackString
standardInstance
startCatalogDownload:options:then:
startDownload:then:
startListening
startPhonemesRequest:phonemeSystem:reply:
startPresynthesizedAudioRequest:
startSpeakingPresynthesizedAudioRequest:
startSpeakingRequest:
startSpeechRequest:
startSpeechRequest:reply:
startSynthesisRequest:
startSynthesizingRequest:
startTime
state
statusDisplayString
stopAtMarker:
stopHandler
stopListening
stopMark
stopPlayingVoicePreview
stopReportingChanges
stopSpeakingAtNextBoundary:synchronously:error:
stopSpeakingPresynthesizedAudioSynchronously:error:
stopSpeechRequest:atMark:
stopVoicePreview
streamBufferDuration
streamDescription
string
stringByAppendingFormat:
stringByAppendingString:
stringByReplacingMatchesInString:options:range:withTemplate:
stringByReplacingOccurrencesOfString:withString:
stringByStandardizingPath
stringForKey:
stringFromNumber:
stringOfSourceOfTTS:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
stsRequestMapping
subarrayWithRange:
subscribeWithVoices:reply:
subscribedVoicesForClientID:accessoryID:
subscribedVoicesWithClientId:reply:
subscribedVoicesWithReply:
substringWithRange:
superclass
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
synthesisBeginTime
synthesisBeginTimestamp
synthesisCallback:
synthesisEndTime
synthesisEndTimestamp
synthesisLock
synthesisRequest:didFinishWithInstrumentMetrics:error:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didReceiveTimingInfo:
synthesizeText:loggable:callback:
synthesizeWithRequest:didFinish:
synthesizer
text
textRange
textToPhonemeWithRequest:didFinish:
textToPhonemesWithRequest:phonemeSystem:completion:
thermalState
timeIntervalSinceDate:
timeToPlaybackLatency
timeToSpeakLatency
timerWithTimeInterval:target:selector:userInfo:repeats:
timingInfosFrom:withText:
timingPlistForLanguage:
toFormat
totalExpected
totalFrames
totalLength
totalWritten
triClient
trialNotificationToken
trialService
trialVoice
triggerCellularDownloadedVoiceAssets:
triggerCellularDownloadedVoiceAssets:withClientID:
ttsSynthesisLatency
type
typeFromBundleIdentifier:
typeStringFromType:
unlock
unlockWithCondition:
unsignedIntegerValue
unspeakableRangeOfText:
updateWithConnectionIdentifier:keepActive:
useBetaVoice
useSSMLInput
useSiriTTSService
useSiriTTSServiceV2
userInfo
utf16OffsetFromUTF8:
utf16TimingInfoWithUTF8Range:withText:
utf8BytesForChar:
utterance
validateAudioCachingRequest:
validateAudioRequest:
validatePrewarmRequest:
validateRequest:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueOfFirstElementWithClassIdentifier:
valueWithNonretainedObject:
versionFactorNameWithFactorName:
voice
voiceAssetFromPreinstallMetadata:
voiceAssetKey
voiceAssetsForSubscription:
voiceConfig
voiceData
voiceDataFromAsset:
voiceDataWithBundleIdentifier:attributes:voicePathCallback:
voiceDownloadKey
voiceKey
voiceName
voicePath
voicePathLock
voiceResourceAssetKey
voiceResourceFromAsset:
voiceType
volume
vs_convertToSSML
vs_countPhoneticSyllables
vs_hasCJKCharacter
vs_insertContextInfo:
vs_isCJKCharacter:
vs_markerStringForContext:
vs_measurePauses
vs_metricsFromSTSMetrics:
vs_removePhonetics
vs_removeSpeechTags
vs_stringFrom4CC:
vs_textifyEmojiWithLanguage:
wasLocal
wasPurgeable
whitespaceAndNewlineCharacterSet
whitespaceCharacterSet
willBeginAccessPower
wordTimingInfoFrom:timestamps:
wordTimings
xpcConnection
zone
B16@0:8
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
v20@0:8B16
q16@0:8
v24@0:8q16
v16@0:8
@"NSString"
@"NSNumber"
@24@0:8q16
d16@0:8
v24@0:8d16
Q16@0:8
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
@"VSVoiceAsset"
@"MAAsset"
@"VSTrialVoice"
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8@16q24@32q40q48q56
@32@0:8@16q24
@20@0:8B16
q24@0:8@16
B24@0:8@16
B24@0:8@?16
@56@0:8@16@24q32q40q48
@40@0:8@16q24@32
@48@0:8@16@24q32q40
@48@0:8q16@24@32q40
@56@0:8q16@24@32q40q48
v36@0:8@16B24@?28
v40@0:8@16@24@?32
v32@0:8@16@?24
v24@0:8@?16
@64@0:8q16@24@32q40q48q56
@32@0:8@16@24
v48@0:8@16@24@?32@?40
@40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSCache"
@"VSTrialService"
f16@0:8
v20@0:8f16
@"NSUserDefaults"
@40@0:8@16@24q32
Q24@0:8@16
v32@0:8@16Q24
v32@0:8@16@24
@48@0:8@16@24q32^@40
@24@0:8^{_NSZone=}16
v24@0:8Q16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
@24@0:8@?16
i20@0:8i16
^v16@0:8
Q20@0:8S16
Q24@0:8Q16
@?16@0:8
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<TTSSynthesizer::Marker, std::allocator<TTSSynthesizer::Marker>>="__begin_"^{Marker}"__end_"^{Marker}"__end_cap_"{__compressed_pair<TTSSynthesizer::Marker *, std::allocator<TTSSynthesizer::Marker>>="__value_"^{Marker}}}
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
@"NSError"
@"NSMutableArray"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@40@0:8@16@24^@32
@32@0:8@16^@24
@36@0:8@16B24@?28
v24@0:8^v16
@"VSSpeechSynthesisCallbackResult"
@"NSLock"
B20@0:8S16
@40@0:8@16@24@32
@"NSDictionary"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"VSRecognitionAction"24@0:8@"VSRecognitionResult"16
@"VSRecognitionAction"24@0:8@"NSArray"16
B40@0:8^@16^@24q32
B20@0:8B16
v40@0:8@16@24@32
^{__CFDictionary=}16@0:8
v52@0:8@16@24B32@36@44
B20@0:8i16
@"VSKeepAlive"
@"<VSRecognitionSessionDelegate>"
@"VSRecognitionAction"
@"NSArray"
@"VSSpeechSynthesizer"
{?="delegateWillBegin"b1"delegateBegin"b1"delegateOpenURL"b1"delegateOpenURLAsync"b1"delegateFinishedSpeaking"b1"delegateComplete"b1"debugDumpEnabled"b1"preferredEngine"b2"performHandlerActions"b1"allowSensitiveActions"b1"bluetoothAllowed"b1"resetNextAction"b1"isSpeaking"b1"actionBegan"b1"actionBeginning"b1"actionBeginDeferred"b1"invalid"b1"observeKeywordChange"b1}
@24@0:8^{__CFDictionary=}16
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@"AVAudioFormat"
@"AVAudioConverter"
@"AVAudioCompressedBuffer"
^{OpaqueAudioConverter=}56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
@72@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24^@64
^{OpaqueAudioConverter=}
i16@0:8
(?="stringValue"@"NSString""attributedStringValue"@"NSAttributedString")
@"VSRecognitionSession"
@28@0:8@16i24
^{__VSRecognitionDisambiguationContext=}16@0:8
^{__VSRecognition=}32@0:8^{?=^?^?^?}16^v24
@"NSMutableDictionary"
@"NSCharacterSet"
B24@0:8d16
B28@0:8B16@20
v24@0:8^{__VSRecognition=}16
v40@0:8^{__VSRecognition=}16^{__CFArray=}24^{__CFError=}32
{?="debugDumpEnabled"b1"preferredEngine"b2"resetEngine"b1"bluetoothAllowed"b1"hasStarted"b1}
@"NSURL"
Q48@0:8r*16Q24Q32Q40
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"NSTimer"
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
{?="initializing"b1"confirmed"b1}
@20@0:8i16
@28@0:8@16B24
@64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
I16@0:8
v20@0:8I16
@"NSData"
@"NSUUID"
@"<VSRecognitionResultHandlingThreadDelegate>"
@"NSConditionLock"
{?="running"b1"delegateDidHandleResults"b1"valid"b1}
@"<VSRecognitionResultHandler>"
^{__CFStringTokenizer=}
@32@0:8@16^{?=qq}24
@"NSAttributedString"
@32@0:8@16Q24
{_NSRange=QQ}24@0:8@16
^v24@0:8Q16
@"NSMutableData"
B48@0:8@16@24q32@?40
v56@0:8@16@24q32{_NSRange=QQ}40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v32@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24
v52@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"NSArray"32
v40@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSAudioData"32
v48@0:8@"VSSpeechConnection"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechConnection"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechConnection"16@"VSPreviewRequest"24
v32@0:8@"VSSpeechConnection"16@"NSError"24
B32@0:8^f16^f24
v48@0:8@16@24q32@?40
d24@0:8@16
v40@0:8@16q24@?32
@36@0:8@16q24B32
@28@0:8q16B24
B36@0:8q16B24^@28
B28@0:8B16^@20
B24@0:8^@16
v64@0:8@16@24q32q40q48@?56
v56@0:8@16@24q32q40@?48
@"VSSpeechConnection"
{?="delegateStartWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegateSuccessWithInstrumentMetrics"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateStreamSynthesisAudioData"b1"willUseInput"b1"delegateDidStartPreviewRequest"b1}
@"<VSSpeechSynthesizerDelegate>"
@"SiriTTSDaemonSession"
@"AFAudioPowerUpdater"
@"AFAudioPowerXPCProvider"
Vv28@0:8q16B24
@"NSXPCConnection"
Vv28@0:8@16B24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16q24@?32
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv28@0:8@"NSString"16B24
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv40@0:8@"VSSpeechRequest"16q24@?<v@?@"NSString"@"NSError">32
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset"@"NSError">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
v28@0:8@16B24
v32@0:8@16q24
@"<VSSpeechConnectionDelegate>"
@"VSSpeechConnectionDelegateWrapper"
@"VSSpeechRequest"
@"VSPresynthesizedAudioRequest"
@32@0:8@?16@24
@?24@0:8@16
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListenerEndpoint"
@"NSXPCListener"
@"TRIClient"
@"<TRINotificationToken>"
|?5^
