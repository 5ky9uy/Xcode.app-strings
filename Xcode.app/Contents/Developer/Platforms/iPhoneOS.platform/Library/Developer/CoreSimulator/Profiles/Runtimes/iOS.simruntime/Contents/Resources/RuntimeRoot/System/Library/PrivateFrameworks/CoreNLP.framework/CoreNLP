@(#)PROGRAM:CoreNLP  PROJECT:CoreNLP-269
p@N7CoreNLP13SubWordTaggerE
 9 : 0
N7CoreNLP13AbstractModelE
?NSt3__119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N7CoreNLP15ParagraphTaggerE
N7CoreNLP9MeCabImplE
N7CoreNLP14MeCabInterfaceE
N7CoreNLP16BERTANEEmbeddingE
N7CoreNLP17AbstractEmbeddingE
N6corelm4util9DirectoryE
N6corelm4util4PathE
N5boost10filesystem4pathE
N7CoreNLP13BERTEmbeddingE
NSt3__110__function6__funcIZN6corelm4util6MatrixIfE3rowEmEUlmmE_NS_9allocatorIS6_EEFmmmEEE
NSt3__110__function6__baseIFmmmEEE
ZN6corelm4util6MatrixIfE3rowEmEUlmmE_
N7CoreNLP23ContextualWordEmbeddingE
N6corelm4util6InFileE
N6corelm4util4FileE
N5boost6detail15sp_counted_baseE
N7CoreNLP26NLModelContainerParseErrorE
N7CoreNLP34NLModelContainerIncompatibleFormatE
N7CoreNLP34NLModelContainerSerializationErrorE
NSt3__114basic_ifstreamIcNS_11char_traitsIcEEEE
NSt3__113basic_filebufIcNS_11char_traitsIcEEEE
NSt3__114basic_ofstreamIcNS_11char_traitsIcEEEE
NSt3__118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N7CoreNLP16GazetteerWrapperE
_N7CoreNLP18WordDispatchTaggerE
N7CoreNLP10WordTaggerE
N6corelm19LanguageModelForANEE
N6corelm22LanguageModelWithStateE
N7CoreNLP19TransferSeqTagModelE
?N7CoreNLP6TaggerE
N7CoreNLP10TopicModelE
N7CoreNLP29ReadOnlyFileCreationExceptionE
N7CoreNLP25ResourceCreationExceptionE
N7CoreNLP20DefaultSubWordTaggerE
/usr/share/tokenizer/ja
/usr/share/tokenizer/zh/Hans
/usr/share/tokenizer/zh/Hant
/usr/share/tokenizer/zh/yue-Hant
/usr/share/tokenizer/ko
N7CoreNLP17MeCabSubTokenizerE
N7CoreNLP21SubTokenizerInterfaceE
NSt3__117bad_function_callE
NSt3__110__function6__funcIPFPK10__CFStringPN7CoreNLP14MeCabInterfaceEPK12mecab_node_tmbENS_9allocatorISC_EESB_EE
NSt3__110__function6__baseIFPK10__CFStringPN7CoreNLP14MeCabInterfaceEPK12mecab_node_tmbEEE
PFPK10__CFStringPN7CoreNLP14MeCabInterfaceEPK12mecab_node_tmbE
FPK10__CFStringPN7CoreNLP14MeCabInterfaceEPK12mecab_node_tmbE
NSt3__110__function6__funcIPF7CFRangePKtPPK12mecab_node_tbmENS_9allocatorISA_EES9_EE
NSt3__110__function6__baseIF7CFRangePKtPPK12mecab_node_tbmEEE
PF7CFRangePKtPPK12mecab_node_tbmE
F7CFRangePKtPPK12mecab_node_tbmE
NSt3__110__function6__funcIPFvPK12mecab_node_tP7NLTokenmENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFvPK12mecab_node_tP7NLTokenmEEE
PFvPK12mecab_node_tP7NLTokenmE
FvPK12mecab_node_tP7NLTokenmE
NSt3__110__function6__funcIPF23NLTokenizerPartOfSpeechPK12mecab_node_tENS_9allocatorIS7_EES6_EE
NSt3__110__function6__baseIF23NLTokenizerPartOfSpeechPK12mecab_node_tEEE
PF23NLTokenizerPartOfSpeechPK12mecab_node_tE
F23NLTokenizerPartOfSpeechPK12mecab_node_tE
NSt3__110__function6__funcIPFbPK12mecab_node_tENS_9allocatorIS6_EES5_EE
NSt3__110__function6__baseIFbPK12mecab_node_tEEE
PFbPK12mecab_node_tE
FbPK12mecab_node_tE
NSt3__110__function6__funcIZN7CoreNLP17MeCabSubTokenizer12initFunctorsEvE3$_0NS_9allocatorIS4_EEFbPK12mecab_node_tEEE
ZN7CoreNLP17MeCabSubTokenizer12initFunctorsEvE3$_0
NSt3__110__function6__funcINS_6__bindIRFmPKtiEJRKNS_12placeholders4__phILi1EEERKNS8_ILi2EEEEEENS_9allocatorISF_EES5_EE
NSt3__110__function6__baseIFmPKtiEEE
NSt3__16__bindIRFmPKtiEJRKNS_12placeholders4__phILi1EEERKNS6_ILi2EEEEEE
NSt3__118__weak_result_typeIPFmPKtiEEE
NSt3__115binary_functionIPKtimEE
A!"$%&'()*DEFGHIAR!"$%&'()*pqrstuARS|}~
OPQ!"$%&'()*pqrstuARS!"$%&'()*pqrstu|}~
ARS!"$%&'()*pqrstu|}~
wxyz{TUVWXYZ[\]^_`abcdefghijklmnoN7CoreNLP23TaggingFeatureExtractorE
N7CoreNLP24AbstractFeatureExtractorE
@N7CoreNLP19KoreanSubWordTaggerE
>N7CoreNLP17SentenceEmbeddingE
N7CoreNLP21JapaneseSubWordTaggerE
N7CoreNLP12UStringPieceE
N7CoreNLP20ChineseSubWordTaggerE
N7CoreNLP15LineBreakTaggerE
?333333
N7CoreNLP5mecab20DefaultNameTokenizerE
N7CoreNLP5mecab22NameTokenizerInterfaceE
N7CoreNLP5mecab21JapaneseNameTokenizerE
N7CoreNLP5mecab30SimplifiedChineseNameTokenizerE
N7CoreNLP5mecab19KoreanNameTokenizerE
@N7CoreNLP8crfsuite8InstanceE
NSt3__120__shared_ptr_pointerIPN7CoreNLP12ReadOnlyFileIcEENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN7CoreNLP12ReadOnlyFileIcEEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_pointerIPN7CoreNLP13TaggerManagerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7CoreNLP13TaggerManagerEE27__shared_ptr_default_deleteIS2_S2_EE
N7CoreNLP12ICUTextBreakE
N7CoreNLP19ModelTrainerWrapperE
?333333
?ffffff
?333333
?ffffff
?N7CoreNLP14SentimentModelE
N8minijson11parse_errorE
N8minijson6detail14encoding_errorE
N8minijson6detail18number_parse_errorE
N7CoreNLP14SentenceTaggerE
;N6corelm13GreedySamplerE
N6corelm20LanguageModelSamplerE
N6corelm11TopKSamplerE
N7CoreNLP6CFTypeE
N7CoreNLP28ICUTextBreakWithBuiltInRulesE
N7CoreNLP16EmbeddingWrapperE
?333333
333333
N7CoreNLP15CompositeTaggerE
N7CoreNLP21ModelContainerWrapperE
N7CoreNLP13WordEmbeddingE
N7CoreNLP12EmotionModelE
N7CoreNLP20TaggerManagerWrapperE
NSt3__120__shared_ptr_pointerIPN7CoreNLP14ModelContainerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7CoreNLP14ModelContainerEE27__shared_ptr_default_deleteIS2_S2_EE
N7CoreNLP31ICUTextBreakWithCustomizedRulesE
N7CoreNLP11OrthographyE
N7CoreNLP8CNNModelE
Nk[lQY[lQk[
NN7CoreNLP15CNNModelWrapperE
NSt3__120__shared_ptr_pointerIPN7CoreNLP15CNNModelHandlerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7CoreNLP15CNNModelHandlerEE27__shared_ptr_default_deleteIS2_S2_EE
N6corelm20OutOfVocabularyErrorE
N6corelm19TokenListVocabularyE
N6corelm18AbstractVocabularyE
N6corelm23SentencePieceVocabularyE
N5boost16exception_detail10clone_implINS0_19error_info_injectorISt12out_of_rangeEEEE
N5boost16exception_detail19error_info_injectorISt12out_of_rangeEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
NSt3__113basic_fstreamIcNS_11char_traitsIcEEEE
N6corelm18CharacterTokenizerE
N6corelm17AbstractTokenizerE
N6corelm19WhitespaceTokenizerE
N7CoreNLP17ThaiSubWordTaggerE
N7CoreNLP8CRFModel18modelLoadExceptionE
N7CoreNLP8CRFModelE
NSt3__120__shared_ptr_pointerIPN7CoreNLP14NLModelTrainerENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7CoreNLP14NLModelTrainerEE27__shared_ptr_default_deleteIS2_S2_EE
N5boost6system14error_category12std_categoryE
N5boost6system12_GLOBAL__N_121system_error_categoryE
N5boost6system14error_categoryE
N5boost12noncopyable_11noncopyableE
N5boost6system12_GLOBAL__N_122generic_error_categoryE
N5boost10filesystem16filesystem_errorE
N5boost6system12system_errorE
N5boost6detail17sp_counted_impl_pINS_10filesystem16filesystem_error5m_impEEE
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
@?N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
v8@?0
zh-Hans
Arab
Cyrl
Deva
Hans
Latn
Hebr
Grek
Thai
Kore
zh-Hant
entr
/System/Library/PrivateFrameworks/LinguisticData.framework/LinguisticData
/System/Library/PrivateFrameworks/LanguageModeling.framework/LanguageModeling
/System/Library/PrivateFrameworks/Espresso.framework/Espresso
/System/Library/PrivateFrameworks/Montreal.framework/Montreal
[[:Hani:]]
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
string_view::substr
Could not construct
Could not convert
 -l1
MRLNeuralNetworkOptionModelURLKey
MRLNeuralNetworkGetOutput
/System/Library/PrivateFrameworks/Montreal.framework/Contents/MacOS/Montreal
input
position
temperature
InputDimension
SequenceLength
MRLNeuralNetworkTensorCreate
MRLNeuralNetworkTensorAppendData
MRLNeuralNetworkSetInputTensor
/model.espresso.net
qk_mask
 not found
MRLNeuralNetworkDeclareOutput
ShapeDimension
Width
Height
Channel
/unilm.espresso.bin
Unable to load model
elmo_input
elmo_embedding
elmo_lstm0
elmo_lstm1
output
com.apple.CoreNLP
Embedding
.nlmodel
Header
Model Type
Model Subtype
Format Version
Model Revision
Model Count
Info Offset
Info Length
Model Offset
Model Length
Invalid info dictionary
Invalid model data dictionary
Invalid data type in model data array
Failed to open the given file 
Given container data is null
Given array contains non-data elements
Failed to mmap the given file 
Given input does not contain the expected file header
Given input cannot be parsed, as the file format has a higher number
Failed to read complete info dictionary
Failed to deserialize info dictionary
Cannot serialize the info dictionary
Failed to open the temp file
Failed to get the file size of 
Open failed
Failed to read the model data completely at index: 
, only read 
 vs expected 
Failed to read 
GazetteerWrapper
v24@?0{?=qq}8
Should not be here as default tagger should handle everything.
com.apple.CoreNLPFramework
Default
kCoreLMVocabularyTypeKey
kCoreLMLocaleKey
kCoreLMArchitectureKey
kCoreLMSamplingMethodKey
kCoreLMSamplingNumberKey
kCoreLMSamplingMaxLengthKey
kCoreLMSamplingTopKKey
kCoreLMSamplingTopPKey
kCoreLMArchitectureLSTM
kCoreLMArchitectureTransformer
kCoreLMEngineKey
kCoreLMEngineCPU
kCoreLMEngineANE
kCoreLMVocabularyTypeCharacter
kCoreLMVocabularyTypeFragment
kCoreLMSamplingMethodGREEDY
kCoreLMSamplingMethodTOPK
kCoreLMSamplingMethodTOPP
model.dat
model.espresso.bin
model.espresso.net
modelInfo.plist
MaximumSequenceLength
modelInfo.plist should have keys MaximumSequenceLength
SupportedBatchSizesAndSequenceLengths
modelInfo.plist not found
Unknown runtime error.
Creation options does not contain all required keys (kCoreLMVocabularyTypeKey, kCoreLMArchitectureKey, kCoreLMLocaleKey).
unilm.bundle
Unable to locate model. Should be of the format unilm.espresso.bin
unilm.espresso.bin
Invalid Engine type. Should be either kCoreLMEngineCPU or kCoreLMEngineANE
unilm.espresso.net
Unable to locate espresso model inside the unilm bundle
Unable to determine model locale from options
/System/Library/PrivateFrameworks/CVNLP.framework/Models/
/System/Library/PrivateFrameworks/CVNLP.framework/Resources/Models/
LSTM architecture only supports CPU
Requested core language model (locale, vocabulary type, architecture type) is not supported.
Model directory does not exist: 
Unknown exception
kCoreLMURLKey
Could not find item
CoreLanguageModel
CoreLanguageModelWithState
input batch size is zero
input seqence length is zero
input batch size not supported
input seq length not supported
NOT supported on ANE
updateWithContextIDs is not supported
maxLength
batchSize
TransferTaggingEmbeddingTypeKey
TransferTaggingEmbeddingVesionKey
Embedding Creation Failed. Please check you have downloaded CoreNLP OTA Assets.
Infrastructure Error
Transfer Tagging API failed to generate a model.
map::at:  key not found
com.apple.CoreNLP.CopyPossibleStringLanguages
v40@?0^{?={?=qq}Q}8^{__CFString=}16Q24^B32
v24@?0^{?={?=qq}Q}8^B16
NLStringTokenizer
v16@?0^B8
TopicModel
topic.bundle
output1
v40@?0{?={?=qq}Q}8^B32
^v8@?0
root
com.apple.CoreNLP.SingletonResourceManager
unknown open mode for file 
could not open file 
failed to get file size for 
mmap failed for 
failed to read from 
unknown error opening 
v40@?0{?=qq}8^B24@?<v@?^{?={?=qq}Q}^B>32
Katakana; Latin; NFD
NumericPinyin-Latin
BOSBOS
EOSEOS
OtherWord
Latin-NumericPinyin
lid_arbc.dat
lid_cyrl.dat
lid_devn.dat
lid_han.dat
lid_latn.dat
LanguageIdentification
fileLocation
MRLModelCreate
MRLModelGetIOMappings
MRLModelGetOutputSize
MRLModelRecognize
MRLModelRelease
MRLModelSetMaxSequenceLength
MRLModelReset
Unable to load contextual embedding model.
Unable to load sentence embedding model
Unable to load similarity model
No contextual embedding found.
LMLanguageModelCreate
LMLanguageModelRelease
LMLanguageModelGetTokenIDForString
LMLanguageModelCreateStringForTokenID
LMLanguageModelGetLemmaForTokenWithPOS
LMLanguageModelEnumerateLemmasForToken
kLMLanguageModelLocaleKey
kLMLanguageModelAdaptationEnabledKey
kLMLanguageModelUseMontrealKey
LMLanguageModelHasLemmas
com.apple.CoreNLP.LemmaTagger
en_US
es_ES
pt_BR
came
v24@?0I8C12^B16
have
will
LegacyTokenBreak
LSTMLanguageIdentifier
LineBreak
NLTaggerRetainString
CustomModelPropertyArray
CustomModelPropertyLanguage
CustomModelPropertyScheme
CustomModelPropertyModelPath
CustomModelPropertyGazetteerPath
CustomModelPropertyGazetteerMaxTokenSize
TokenType
Language
Script
LexicalClass
NameType
NameTypeOrLexicalClass
Lemma
Transcription
DerivedSubToken
Sentiment
Topic
Emotion
InternalClass
Word
Punctuation
Whitespace
Other
Noun
Verb
Adjective
Adverb
Pronoun
Determiner
Particle
Preposition
Number
Conjunction
Interjection
Classifier
Idiom
SentenceTerminator
OpenQuote
CloseQuote
OpenParenthesis
CloseParenthesis
WordJoiner
Dash
ParagraphBreak
PersonalName
PlaceName
OrganizationName
Anger
Fear
Happiness
Love
Sadness
Surprise
NeutralEmotion
com.apple.CoreNLP.LanguageIdentifier
yue-Hant
subDimension
version
numberOfTrees
locale
modelPath
modelData
embedingModelType
embedingModelTypeCompressedWordEmbedding
embedingModelTypeContextualWordEmbedding
embedingModelTypeSentenceEmbedding
embedding.dat
NONE
B-PER
I-PER
B-LOC
I-LOC
B-ORG
I-ORG
OTHER
NNPS
PRPD
PRPR
PRPS
PRPT
suggestd
Tagging
pos.dat
ner_v2.dat
ner.dat
^{USet=}8@?0
EmbeddingNodeName
EmbeddingDimension
modelInfo.plist should have keys EmbeddingNodeName, EmbeddingDimension and MaximumSequenceLength
bilm.dat
sentence.dat
similarity.dat
Unable to locate model
Unsupported version
Unable to locate sentence embedding model
Unable to locate similarity model
Unsupported embedding model type
Missing locale
Unsupported locale
MRLNeuralNetworkOptionModelDataKey
kMRLNeuralNetworkOptionModelTypeKey
FlatModel
MRLNeuralNetworkCreate
MRLNeuralNetworkGetOutputDimension
MRLNeuralNetworkSetInput
MRLNeuralNetworkPredict
MRLNeuralNetworkClear
MRLNeuralNetworkAddNode
MRLNeuralNetworkConnectNodes
MRLNeuralNetworkSave
MRLNeuralNetworkCopyModelData
Unknown tokenization unit: %u
v32@?0{unique_ptr<CoreNLP::Resource, std::default_delete<CoreNLP::Resource>>={__compressed_pair<CoreNLP::Resource *, std::default_delete<CoreNLP::Resource>>=^{Resource}}}8^{__CFString=}16^B24
sentiment.bundle
emotion.dat
ModelTrainerWrapper
sentiment.nlmodel
char_id.json
This line should never be reached, please file a bug report
Unknown parse error
Expected opening quote
Expected UTF-16 low surrogate
Invalid escape sequence
Invalid UTF-16 character
Expected closing quote
Invalid value
Unterminated value
Expected opening bracket
Expected colon
Expected comma or closing bracket
Nested object or array not parsed
Exceeded nesting limit (32)
Invalid write call, please file a bug report
true
false
null
standard
/dev/urandom
NLGazetteerEntities
NLGazetteerFalsePositiveRate
NLGazetteerLocale
NLGazetteerCompressedModelData
NLGazetteerCompressedModelURL
com.apple.CoreNLPFramework.Gazetteer
NLGazetteer
bloom filter loading too small buffer
unsupported bloom filter version
BloomFilter
Improper sub-dimension 
 , dimenion 
must be devided by sub-dimention
EmbeddingWrapper
%.1f
Automotives
Books
Romance
Pets
Home
Family
Games
Holidays
Movies
Politics
Health
School
Music
Science
Outdoors
Party
Others
Restaurant
Sports
Television
Shopping
Travel
Work
Education
Technology
Unknown
ModelContainerWrapper
feature.minfreq
feature.possible_states
feature.possible_transitions
3000
max_iterations
num_memories
1e-5
epsilon
period
delta
MoreThuente
linesearch
max_linesearch
numEpochs
deviceType
language
Unable to load Transfer Tagging model
Unsupported Model Method Type
SYS_NONE
AppleTextBreakLocale
AppleLanguages
Hant
IPHONE_SIMULATOR_ROOT
EmotionModel
TaggerManagerWrapper
com.apple.NLModelContainer
NLModelLanguage
NLModelAuthor
NLModelDescription
NLModelLicense
NLModelVersionString
NLModelCreationDate
NLModelInputLabelArray
NLModelOutputLabelArray
MRLNeuralNetworkCreate returned nullptr
kMRLNeuralNetworkOptionModelURLKey
MRLNeuralNetworkCopyInputNamesAndDimensions
MRLNeuralNetworkCopyOutputNamesAndDimensions
MRLNeuralNetworkCopyStates
DictionaryRef_iterator iterator out of range.
com.apple.CoreNLP.defaultICURule
tokruleLE.data
/System/Library/LinguisticData/en/tokcompound.dat
pa-Guru
iu-Cans
mn-Mong
Jpan
Armn
Beng
Guru
Gujr
Orya
Taml
Telu
Knda
Mlym
Sinh
Laoo
Tibt
Mymr
Geor
Ethi
Cher
Cans
Khmr
Mong
com.apple.CoreNLP.Orthography
embedding_annex.json
layer_shapes
.net
.shape
Loading a character based CNN Model
Loading a word based CNN Model
Cannot find the PAD mapping
Cannot find the UNK mapping
Cannot find the PAD mapping in annex
Cannot find the UNK mapping in annex
input1
Failed to execute the plan to extract from char CNN
Failed to execute the plan to extract from word CNN
Cannot extract one of the dimensions
espresso_create_context
espresso_context_destroy
espresso_create_plan
espresso_plan_destroy
espresso_plan_add_network
espresso_plan_build
espresso_network_bind_buffer
espresso_plan_execute_sync
espresso_network_declare_output
espresso_network_declare_input
CNNModelWrapper
Unknown TokenID: 
Special token 
 not found in vocab!
Unknown Token: 
Input text should not contain BOS token!
<unk>
</s>
<pad>
OutOfVocabularyError: 
bimap<>: invalid key
Cannot load the given model files
Dealloced FeatureExtraction
v24@?0^{__CFString=}8^B16
INFO: Created BF Number of Elements: 
 False PositiveRate: 
 Number of Hashes: 
 Size of bitmap(Byte): 
--> expected: 
ERROR: Unexpected Annotation (needs at least two columns): 
ERROR: could not open directory 
ERROR: cannot open 
INFO: Reading data from
WARN: will use 1% of training data for evaluation.
INFO: total number of sentences: 
.extractorData
Info: Model Size(bytes) 
INFO: Testing token data from
ERROR: Not able to determine the expected tag for unexposed label: 
INFO: item accuracy: 
INFO: Performance by label (#match, #model, #ref) (precision, recall, F1):
INFO: Average precision, recall, F1: (
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
LDEnumerateAssetDataItems
sp.model
vocab.txt
special_map.txt
sp.dat
Unable to find vocab file.
dictionary
train/%s/%s
crf1d
lbfgs
ERROR: Not supported CRF model version for setData: 
Raw Attribute Nb :
Hashed Attribute Nb :
Average collisionRate :
Mixed-Attribute
Occurrence
CRFModel
Failed to load bloom filter from file
Failed to load bloom filter from data
Gazetteer
FeatureCategory
MaxIterationNumber
RegularizationCoefficient
ModelMethodType
ModelDeviceType
SampleDataText
SampleDataRangeLocationArray
SampleDataRangeLengthArray
SampleDataLabelTypesArray
SampleDataLabelArray
SampleDataLabelsArray
SampleDataProbabilitiesArray
SampleDataFeatureArray
TrainingTokenLocations
ValidationTokenLocations
TrainingTokenLengths
ValidationTokenLengths
TrainingSentences
ValidationSentences
TrainingSentenceIds
ValidationSentenceIds
GoldTrainingLabels
GoldValidationLabels
PredictedTrainingLabels
PredictedValidationLabels
ModelData
ModelDataArray
ModelMetadata
ModelParams
system
generic
Unknown error
ENOMEM
boost::filesystem::canonical
boost::filesystem::current_path
boost::filesystem::read_symlink
boost::filesystem::status
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
Unknown extra_option type
reverse
option 
 is not available.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/SentencePiece-24/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
TMPDIR
/tmp
/nlptemp-XXXXXX
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
NLEmbeddingShape_Batch_Components_Words_Fragments shape is supported by fragment based embedding type
Received unsupported CFType for locale.
Received unsupported model format. Could be either Montreal or Espresso
%s=%@
Created vocab with size %zu
vocabulary ids are not incremental from 0
RECEIVED EMPTY CONTEXT. No update to the language model state.
Missing sampling method specified by kCoreLMSamplingMethodKey
Missing kCoreLMSamplingMaxLengthKey
Missing kCoreLMSamplingNumberKey
Missing kCoreLMSamplingTopKKey
Missing kCoreLMSamplingTopPKey
Invalid sampling method
Unable to locate Asset for contextual word embedding model for local %s.
Unable to locate Asset for sentence embedding model for local %s.
Unsupported locale %s.
failed to create gazetteer: %s
bloom filter buffer is too short: %zu
failed to read V1 header
failed to read V2 header
Failed to locate emotion model for '%s' locale
Failed to load contextual embeddings for '%s' locale
Empty input
Tokenization: %s
Model assigned %lu label with %.2f score
Unexpected unknown exception caught in Orthography
Unexpected exception %s: 
Expected token=%s to get converted into single TokenID, but got %zu tokenIDs: %s. Returning UNK TokenID as fallback.
CRFModel V2 file for %{public}d scheme too small
CRFModel V3 file for %{public}d scheme too small
Gazetteer buffer is too short
Failed to read label from Gazetter buffer
Failed to read filter size from Gazetteer buffer
Failed to read filter from Gazetteer buffer
BundleHelper
NLResourceWrapper
stringWithUTF8String:
length
enumerateSubstringsInRange:options:usingBlock:
dictionaryWithContentsOfFile:
allKeys
containsObject:
objectForKeyedSubscript:
countByEnumeratingWithState:objects:count:
intValue
objectForKey:
bundleForClass:
createBundle
UTF8String
localeWithLocaleIdentifier:
dictionaryWithObjects:forKeys:count:
stringWithFormat:
exceptionWithName:reason:userInfo:
raise
array
objectAtIndexedSubscript:
substringWithRange:
addObject:
copy
copyAssetURLWithLocale:contentType:contentName:
arrayWithObjects:count:
count
characterAtIndex:
lowercaseString
setObject:atIndexedSubscript:
stringByAppendingPathComponent:
fileURLWithPath:
dictionary
setDictionary:
numberWithFloat:
setObject:forKeyedSubscript:
localeIdentifier
fileSystemRepresentation
arrayWithCapacity:
componentsJoinedByString:
dataWithContentsOfFile:
JSONObjectWithData:options:error:
unsignedIntegerValue
objectAtIndex:
floatValue
@16@0:8
@40@0:8@16@24@32
