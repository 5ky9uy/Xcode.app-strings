@(#)PROGRAM:CoreEmbeddedSpeechRecognition  PROJECT:CoreSpeech-1
PreferOverServer
SupportsContinuousListening
SupportsOnDeviceSearch
SupportsAutoPunctuation
SupportsEmojiRecognition
com.apple.siri.asr.dictation.audio.sampling
com.apple.siri.asr.assistant.audio.sampling
v8@?0
CESRTrialAssetManager Queue
Siri
unified_asset_namespace
+[CESRTrialAssetManager getAssetTypeForNamespace:]
-[CESRTrialAssetManager trialIdsForAssetType:]
com.apple.siri.asr.hammer.
com.apple.siri.asr.assistant.
com.apple.siri.asr.dictation.
com.apple.siri.asr.geolm.regionMapping.
com.apple.siri.asr.geolm.
+[CESRTrialAssetManager factorPrefixForAssetType:]
+[CESRTrialAssetManager factorNameForAssetType:language:regionId:]
daily_hammer.json
geolm-mini.json
geo-config.json
+[CESRTrialAssetManager jsonFilenameForAssetType:]
-[CESRTrialAssetManager installationStatusForLanguagesForAssetType:includeDetailedStatus:error:]
%@ModelInfo=%@
v24@?0d8Q16
-[CESRTrialAssetManager installationStatusForLanguagesForAssetType:includeDetailedStatus:error:]_block_invoke
%@: %@: AssetId=%@:
-[CESRTrialAssetManager _installedAssetWithConfig:regionId:triggerDownload:]
-[CESRTrialAssetManager _installedAssetWithConfig:regionId:triggerDownload:]_block_invoke
v16@?0Q8
v20@?0B8@"NSError"12
-[CESRTrialAssetManager installedFileAssetOfAssetType:factorName:]
-[CESRTrialAssetManager setAssetsProvisionalForAssetType:]
-[CESRTrialAssetManager promoteAssetsForAssetType:]
-[CESRTrialAssetManager switchToNewAssetsForAssetType:]
forceUpgrade=YES requires urgent=YES
Trial namespace could not be resolved for assetType=%lu
Factor name could not be resolved for assetType=%lu
-[CESRTrialAssetManager downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:]
-[CESRTrialAssetManager downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:]_block_invoke
Asset not available even after downloading. It's possible that we only subscribed and the actual download will happen later.
-[CESRTrialAssetManager downloadStatusWithConfig:progressHandler:completionHandler:]_block_invoke
-[CESRTrialAssetManager _purgeLegacyDictationAssetForLanguage:]
-[CESRTrialAssetManager _purgeLegacyDictationAssetForLanguage:]_block_invoke
-[CESRTrialAssetManager _purgeInstalledAssetsExceptLanguages:assetType:error:]
-[CESRTrialAssetManager purgeInstalledAssetForAssetType:language:regionId:error:]
-[CESRTrialAssetManager setAssetsPurgeabilityExceptLanguages:assetType:]
-[CESRTrialAssetManager registerAssetDelegate:assetType:]
-[CESRTrialAssetManager registerAssetDelegate:assetType:]_block_invoke
v16@?0@"<TRINamespaceUpdateProtocol>"8
-[CESRTrialAssetManager releaseClients]
-[CESRTrialAssetManager releaseClientsForAssetType:]
-[CESRTrialAssetManager _scheduleCleanupTimer]
-[CESRTrialAssetManager _cancelCleanupTimer]
-[CESRTrialAssetManager _cleanupTimerFired]
-[CESRTrialAssetManager modelQualityTypeStatusStringWithConfig:]
: %@
%@: ModelInfo=%@: AssetId=%@:
-[CESRTrialAssetManager startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:]_block_invoke
-[CESRTrialAssetManager startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:]
overrideAssetPath
overrideAssetStatus
-[CESRTrialAssetManager removeAssetsForFactors:withNamespace:withClient:error:]_block_invoke
-[CESRTrialAssetManager removeAssetsForFactors:withNamespace:withClient:error:]
Installed
Installing
Not Installing
Unknown
Hammer
CESRAssetTypeToString
Assistant
Dictation
GeoLMRegionMapping
GeoLMRegionSpecific
invalid enum
ar-SA
es-419
es-US
CESRAssetConfig::language
CESRAssetConfig::assetType
modelVersion
modelType
modelRoot
%@ {%@}
modelVersion = %@
modelType = %@
modelRoot = %@
CESRModelProperties::modelVersion
CESRModelProperties::modelType
CESRModelProperties::modelRoot
numberOfRequestsTillNow
isDeviceSampledFromConfig
CESRDictationOnDeviceSampling file queue
-[CESRDictationOnDeviceSampling decrementRequestCount]
-[CESRDictationOnDeviceSampling isRequestSelectedForSamplingFromConfigForLanguage:]
%@/%@
+[CESRDictationOnDeviceSampling _readDictationSampledPlist]
-[CESRDictationOnDeviceSampling _createDictationSampledPlistIfItDoesNotExist]
-[CESRDictationOnDeviceSampling _writeDictationSamplingVariablesToFile:]
ResultCandidateId
SpeechProfile
EARUserProfileContainerLoadDate
+[CESRUtilities speechProfileRootDirectories]
+[CESRUtilities speechProfilePathsWithLanguage:]
+[CESRUtilities loadSpeechProfiles:language:]
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
Param
v32@?0{_NSRange=QQ}8^B24
v32@?0@"EARVoiceCommandArgument"8Q16^B24
@"NSArray"24@?0@"NSArray"8@"NSArray"16
+[CESRUtilities AFSpeechInfoPackageForEARSpeechRecognitionResultPackage:]_block_invoke
v32@?0@"NSArray"8Q16^B24
unconstrained
reduced
avoid
AFSpeechLatticeMitigatorResultForEar
com.apple.fides.asr
+[CESRFidesASRRecord recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:]
+[CESRFidesASRRecord recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:]
SiriCoreLocalSpeechUserData
+[CESRFidesASRRecord recordFromData:]
%@, language=%@, task=%@, context=%@, samplingRate=%ld, profile(length)=%ld, UUIDString=%@, originalAudioFileURL=%@, audioPackets(duration)=%f, farField=%d, interactionIdentifier=%@, asrSelfComponentIdentifier=%@, correctedText=%@, recognizedText=%@, personalizedLMUsed=%d, applicationName=%@, date=%@, timestamp=%f
_language
_task
_context
_samplingRate
_profile
_userData
_UUIDString
_originalAudioFileURL
_audioPackets
_farField
_interactionIdentifier
_asrSelfComponentIdentifier
_correctedText
_recognizedText
_personalizedLMUsed
_applicationName
_date
_timestamp
-[CESRFidesASRRecord encodeWithCoder:]
language
task
context
samplingRate
farField
interactionIdentifier
asrSelfComponentIdentifier
personalizedLMUsed
applicationName
audioPacketsDuration
date
-[CESRFidesASRRecord _recordData]
-[CESRFidesASRRecord save]
-[CESRFidesASRRecord save]_block_invoke
v24@?0@"NSUUID"8@"NSError"16
yyyyMMdd
-[CESRFidesASRRecord saveOneRecordPerDay]_block_invoke_2
-[CESRFidesASRRecord saveOneRecordPerDay]_block_invoke
v16@?0@"NSError"8
v24@?0@"NSDictionary"8@"NSError"16
+[CESRFidesASRRecord deleteAllRecordsForPlugin:completion:]_block_invoke
CESRProfileErrorDomain
\NT-contact
\NT-action
\NT-payaccount
\NT-savedactivity
\NT-notetitle
\NT-notefolder
\NT-phototag
\NT-photoalbum
\NT-house
\NT-room
\NT-zone
\NT-group
\NT-device
\NT-scene
\NT-playlist
\NT-artist
\NT-appname
\NT-searchterm
\NT-location
\NT-calevent
\NT-unknown
\NT-entity
\NT-correction
\NT-appvocab
CESRSpeechProfileBuilderIsBoosted
/Assistant
-[CESRSpeechProfileBuilder dealloc]
com.apple.siri.embeddedspeech
CESRSpeechProfileBuilder
-[CESRSpeechProfileBuilder _newConnection]_block_invoke
-[CESRSpeechProfileBuilder _setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:]_block_invoke
-[CESRSpeechProfileBuilder getVersionForCategory:error:]_block_invoke
v24@?0q8@"NSError"16
-[CESRSpeechProfileBuilder beginWithCategoriesAndVersions:bundleId:error:]_block_invoke
-[CESRSpeechProfileBuilder _flushItemsWithError:]_block_invoke
-[CESRSpeechProfileBuilder cancelCategoriesWithError:]_block_invoke
-[CESRSpeechProfileBuilder finishAndSaveProfile:error:]_block_invoke
0000000000000000
Connection to the profile builder service was interrupted
Connection to the profile builder service was rejected
\contact-first
\contact-last
\contact-middle
\contact-nickname
\company-first
\contact-first-phonetic
\contact-last-phonetic
\contact-middle-phonetic
\company-first-phonetic
 language=%@, contactWordsWithFrequency count=%ld, vocabularyWords total count=%ld, appNames count=%ld, interactionSenderDisplayNames count=%ld, searchEventValues count=%ld, locationOfInterestNames count=%ld, keyboardLMDynamicVocabularyItems count=%ld eventTitles count=%ld eventLocationNames count=%ld, pexNamedEntityNames count=%ld, corrections count=%ld
 language=%@, contactWordsWithFrequency=%@, vocabularyWords=%@, appNames=%@, interactionSenderDisplayNames=%@, searchEventValues=%@, locationOfInterestNames=%@, keyboardLMDynamicVocabularyItems=%@ eventTitles=%@ eventLocationNames=%@, pexNamedEntityNames=%@, corrections=%@
_contactWordsWithFrequency
_contactsWords
-[CESRUserData initWithCoder:]
_vocabularyWords
_appNames
_interactionSenderDisplayNames
_interactionRecords
senderDisplayName
-[CESRUserData initWithCoder:]_block_invoke
v32@?0@"NSString"8@"NSNumber"16^B24
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_keyboardLMDynamicVocabularyItems
_eventTitles
_eventLocationNames
_pexNamedEntityNames
_corrections
contactWordsWithFrequency
vocabularyWords
appNames
interactionSenderDisplayNames
searchEventValues
locationOfInterestNames
spatialLocationOfInterestNames
keyboardLMDynamicVocabularyItems
eventTitles
eventLocationNames
pexNamedEntityNames
corrections
-[CESRUserData populateUserDataFromItems:]
v32@?0@"KVField"8Q16^B24
-[CESRUserData _handleItems:forKVFieldTypes:withCategory:]
-[CESRUserData _handleContacts:]
-[CESRUserData _handleKeyboardLMDynamicVocabularyItems:]
v24@?0@"NSString"8@"NSString"16
\artist-first
\playlist-first
\podcastTitle-first
\photoTags-first
\photoAlbumName-first
\carName-first
\paymentsOrganizationName-first
\paymentsAccountName-first
\healthActivity-first
\notebookTitle-first
\notebookFolderTitle-first
\voiceCommandName-first
\appMusicArtistName-first
\appPlaylistTitle-first
\appAudiobookTitle-first
\appShowTitle-first
\house-first
\room-first
\zone-first
\scene-first
\group-first
\device-first
\app-first
\unknown-first
-[CESRUserData _handleVocabularyWords:template:]
_components
_frequency
components
frequency
 components=%@, frequency=%lu
_templateName
_tagName
templateName
tagName
 templateName=%@, tagName=%@
WebSearch
v24@?0@"PPScoredItem"8^B16
-[CESRContextualData fetchNamedEntitiesWithTimeInterval:]_block_invoke
v40@?0@"NSSet"8@"NSDate"16@"NSDate"24Q32
v32@?0@"_PSSuggestion"8Q16^B24
v36@?0@"NSString"8@"NSDate"16B24Q28
v32@?0@"NSString"8@"NSString"16^B24
(%@,%@)
v32@?0@"CESRVocabularyCategory"8@"NSSet"16^B24
mini.json
dictation_emoji_recognition
-[CESRFormatter formatSpeechTokensWithAutoPunctuation:]
asrLocale
samplingPolicies
filterDimensions
< asrLocale=%@ >
< ruleDimension=%@, samplingRate=%.2f, numDimension=%zd >
-[CESRAudioSamplingConfig initWithConfigDictionary:]
q24@?0@"CESRAudioSamplingPolicy"8@"CESRAudioSamplingPolicy"16
-[CESRAudioSamplingConfig initWithConfigPath:]
-[CESRAudioSamplingConfig getSamplingRateFromDimension:]
%@ %@
orthography
apg_id
tts_version
token_offset
tts_pronunciations
asr_pronunciation_data
requestIdentifier
dictationUIInteractionIdentifier
loggingContext
profile
overrides
modelOverrideURL
originalAudioFileURL
codec
narrowband
detectUtterances
censorSpeech
secureOfflineOnly
shouldStoreAudioOnDevice
continuousListening
shouldHandleCapitalization
isSpeechAPIRequest
maximumRecognitionDuration
endpointStart
inputOrigin
location
jitGrammar
deliverEagerPackage
disableDeliveringAsrFeatures
enableEmojiRecognition
enableAutoPunctuation
enableVoiceCommands
sharedUserInfos
prefixText
postfixText
selectedText
powerContext
language = %@
requestIdentifier = %@
dictationUIInteractionIdentifier = %@
task = %@
loggingContext = %@
applicationName = %@
profile = (%ld bytes)
overrides = %@
modelOverrideURL = %@
originalAudioFileURL = %@
codec = %@
narrowband = %@
detectUtterances = %@
censorSpeech = %@
farField = %@
secureOfflineOnly = %@
shouldStoreAudioOnDevice = %@
continuousListening = %@
shouldHandleCapitalization = %@
isSpeechAPIRequest = %@
maximumRecognitionDuration = %@
endpointStart = %@
inputOrigin = %@
location = %@
jitGrammar = %@
deliverEagerPackage = %@
disableDeliveringAsrFeatures = %@
enableEmojiRecognition = %@
enableAutoPunctuation = %@
enableVoiceCommands = %@
sharedUserInfos = %@
prefixText = %@
postfixText = %@
selectedText = %@
powerContext = %@
CESRSpeechParameters::language
CESRSpeechParameters::requestIdentifier
CESRSpeechParameters::dictationUIInteractionIdentifier
CESRSpeechParameters::task
CESRSpeechParameters::loggingContext
CESRSpeechParameters::applicationName
CESRSpeechParameters::profile
CESRSpeechParameters::overrides
CESRSpeechParameters::modelOverrideURL
CESRSpeechParameters::originalAudioFileURL
CESRSpeechParameters::codec
CESRSpeechParameters::narrowband
CESRSpeechParameters::detectUtterances
CESRSpeechParameters::censorSpeech
CESRSpeechParameters::farField
CESRSpeechParameters::secureOfflineOnly
CESRSpeechParameters::shouldStoreAudioOnDevice
CESRSpeechParameters::continuousListening
CESRSpeechParameters::shouldHandleCapitalization
CESRSpeechParameters::isSpeechAPIRequest
CESRSpeechParameters::maximumRecognitionDuration
CESRSpeechParameters::endpointStart
CESRSpeechParameters::inputOrigin
CESRSpeechParameters::location
CESRSpeechParameters::jitGrammar
CESRSpeechParameters::deliverEagerPackage
CESRSpeechParameters::disableDeliveringAsrFeatures
CESRSpeechParameters::enableEmojiRecognition
CESRSpeechParameters::enableAutoPunctuation
CESRSpeechParameters::enableVoiceCommands
CESRSpeechParameters::sharedUserInfos
CESRSpeechParameters::prefixText
CESRSpeechParameters::postfixText
CESRSpeechParameters::selectedText
CESRSpeechParameters::powerContext
-[CESRAudioSamplingConfigManager _createConfigFromProductType:]
-[CESRAudioSamplingConfigManager shouldSampleFromConfigForProductType:language:]
corrected_text
pronunciation_data
spelling_corrections_count
tap2edit_corrections_count
alternatives_corrections_count
version
data
assetPath
SiriDictation
SearchOrMessaging
Tshot
VoiceMail
Beto
BetoDictation
-[CoreEmbeddedSpeechRecognizer initWithDelegate:instanceUUID:]
CoreEmbeddedSpeechRecognizer
-[CoreEmbeddedSpeechRecognizer dealloc]
-[CoreEmbeddedSpeechRecognizer _connection]_block_invoke
-[CoreEmbeddedSpeechRecognizer _serviceWithFunctionName:errorHandler:]_block_invoke
-[CoreEmbeddedSpeechRecognizer preheatSpeechRecognitionWithLanguage:modelOverrideURL:]_block_invoke
v24@?0@"NSData"8@"NSString"16
-[CoreEmbeddedSpeechRecognizer preheatSpeechRecognitionWithAssetConfig:preheatSource:modelOverrideURL:]_block_invoke
+[CoreEmbeddedSpeechRecognizer resetCacheAndCompileAllAssets]
+[CoreEmbeddedSpeechRecognizer resetCacheAndCompileAllAssets]_block_invoke
v24@?0@"CESRModelProperties"8@"NSError"16
-[CoreEmbeddedSpeechRecognizer startSpeechRecognitionWithParameters:didStartHandlerWithInfo:]_block_invoke
Language is nil
v16@?0@"<CESRSpeechParametersMutating>"8
-[CoreEmbeddedSpeechRecognizer sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke
-[CoreEmbeddedSpeechRecognizer sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer updateSpeechProfileWithLanguage:modelOverridePath:completion:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer updateSpeechProfileWithLanguage:modelOverridePath:completion:]_block_invoke_4
v32@?0@"NSData"8@"NSString"16@"NSError"24
-[CoreEmbeddedSpeechRecognizer getOfflineAssetStatusIgnoringCache:assetType:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer getOfflineDictationStatusIgnoringCache:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer runAdaptationRecipeEvaluation:recordData:attachments:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer runAdaptationRecipeEvaluation:recordData:attachments:completion:]_block_invoke_3
v32@?0@"NSDictionary"8@"NSData"16@"NSError"24
-[CoreEmbeddedSpeechRecognizer runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke_3
-[CoreEmbeddedSpeechRecognizer readProfileAndUserDataWithLanguage:allowOverride:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer readProfileAndUserDataWithLanguage:allowOverride:completion:]_block_invoke_2
+[CoreEmbeddedSpeechRecognizer dictionaryWithContentsProfilePathForLanguage:errorOut:]
-[CoreEmbeddedSpeechRecognizer resetDESWithCompletion:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer fetchAssetsForLanguage:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer fetchAssetsForAssetConfig:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer modelPropertiesForAssetConfig:error:]
v24@?0@"NSNumber"8@"NSError"16
+[CoreEmbeddedSpeechRecognizer setAssetsPurgeabilityExceptLanguages:assetType:]
-[CoreEmbeddedSpeechRecognizer writeDESRecord]_block_invoke
-[CoreEmbeddedSpeechRecognizer deleteAllDESRecordsForDictationPersonalization]_block_invoke
-[CoreEmbeddedSpeechRecognizer deleteAllDESRecordsForDictationPersonalization]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer speechServiceDidFinishRecognitionWithStatistics:error:]
No API is available to fetch user data.
-[CoreEmbeddedSpeechRecognizer startMissingAssetDownload]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidatePersonalizedLM]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidatePersonalizedLM]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer removePersonalizedLMForFidesOnly:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer removePersonalizedLMForFidesOnly:]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidateUaapLM]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidateUaapLM]_block_invoke_2
WriteSpeechProfileData
%s CESRDictationAssetType has been deprecated. Using CESRAssistantAssetType instead.
%s trialIdsForAssetType: Unknown assetType %lu 
%s factorPrefixForAssetType: Unknown assetType %lu . Returning empty string
%s Language passed to `factorNameForAssetType` is nil.
%s factorNameForAssetType: regionId cannot be nil for assetType %lu 
%s factorNameForAssetType: Unknown assetType %lu 
%s jsonFilenameForAssetType: Unknown assetType %lu 
%s assetType: %lu includeDetailedStatus: %@
%s Unexpected factor type for factor: %@
%s Factor is already installed: %@ for language: %@
%s Asset Download Progress is stalled, ~%.f%% completed
%s Trial claims factor %@ is available but it doesn't have a path
%s Returning installation status for %lu: %@
%s Using overrided path for `installedAssetWithConfig`, assetType=%lu, asset path=%@
%s Language passed to `installedAssetWithConfig` is nil.
%s Trial namespace could not be resolved for assetType=%lu
%s Language:%@ AssetType:%lu is not supported on-device by ASR
%s No level available for factor:%@
%s Triggering download. Urgent: %@
%s Asset %@ download is %lu%% complete
%s Asset %@ download completed with error: %@, success=%d
%s Asset %@ download completed successfully
%s Got asset file from Trial at: %@ for language: %@
%s setAssetsProvisionalForAssetType: Failed to set %@ as provisional: %@
%s promoteAssetsForAssetType: Failed to promote %@: %@
%s Switching to new assets for asset type: %lu
%s Got asset file from Trial at: %@ for language: %@ urgent: %d forceUpgrade: %d
%s Asset %@ download completed with error, %@, %d
%s Asset %@ download is %lu%% complete, isStalled=%@
%s Assistant asset already exists for %@, purging legacy dictation asset.
%s Encountered error trying to purge legacy dictation asset: %@
%s Ignoring Purging asset: %@, language %@
%s No factors available to remove
%s Factors available to remove: %lu
%s Starting deletion of asset for assetType=%lu, namespace=%@, language=%@, updatedLanguage=%@, factorName=%@
%s Ignoring setting purgeability level for trial asset: %@, language %@
%s No factors available to set purgeability level
%s Factors available to register CacheDelete by Trial: %lu
%s New trial update for %@
%s Removed update handler for %@
%s Cancelling the cleanup timer since we're registering an asset delegate
%s Releasing all clients
%s Releasing clients for asset type
%s Cleanup timer scheduled
%s Cleanup timer canceled
%s Cleanup timer fired. This generally means that this process is not handling the TRIClient lifecycle properly. You need to call `releaseClients` once you no longer need the assets. This might cause the assets to be removed from disk. Also make sure to call `switchToNewAssetsForAssetType` at the beginning of new requests to get updated assets.
%s Cleanup timer fired
%s Immediate download for namespace %@ completed with error, %@, %d
%s Starting download of asset %@: urgent=%d options=%@
%s Can't download assets. Already reached the limit of assets on device.
%s Success:%d Error:%@
%s Removed factors: %@ error:%@
%s Failed to purge assets for namespace: %@ error:%@
%s Dictation Sampling: Done decrementing total number of dictation requests by 1, for the current sampling date.
%s Dictation Sampling: HIPAA Device, Sampling is DISABLED.
%s Dictation Sampling: Sampling is DISABLED.
%s Dictation Sampling: User is NOT opted in.
%s Dictation Sampling: isDeviceSampledFromConfig = %d
%s Dictation Sampling: Selected for sampling - Sampling all audio for Internal Install
%s Dictation Sampling: Selected for sampling - number of requests was 0.
%s Dictation Sampling: Selected for sampling - Sampling Date has been changed.
%s Dictation Sampling: Selected for sampling.
%s Dictation Sampling: NOT Selected for sampling
%s Dictation Sampling: Device is Not Participating in Sampling Today
%s Dictation Sampling: Error while reading plist at location %@ - %@
%s Dictation Sampling: Error while creating directory - %@
%s Dictation Sampling: Error while creating plist file. The dictationSampledPlistPath - %@ - is returned as Directory. Should not happen.
%s Dictation Sampling: Error while writing _dictationSamplingVaribles to plist - %@
%s Root directories for new type of speech profile: %{private}@
%s speechProfilePathsWithLanguage was incorrectly called with language=nil
%s Mapped language=nil
%s loadSpeechProfiles was incorrectly called with profiles=nil
%s Reused new type of speech profile: path=%{private}@
%s Loaded new type of speech profile: path=%{private}@ profile=%d
%s Count of command interpretation sets does not match count of speech recognition results
%s AFSpeechLatticeMitigatorResult Score = %f, Threshold = %f
%s AFSpeechLatticeMitigatorResult nil
%s Lost the lottery: not creating DES record this time
%s Lost the downsampled lottery: not creating DES record this time
%s DES record unarchive error: %@
%s Skipping audio bytes and save originalAudioFileURL instead
%s Unable to serialize DES record: %@
%s Skip DES record creation because of no recognition
%s Creating DES record (SPI v2): %{public}@, %{public}zu bytes
%s Could not write DES record for SPI v2 %{public}@: %{public}@
%s DES Record created for SPI v2 %@: %@
%s Failed to delete record: %@
%s Deleted record(%@)
%s Failed to fetch records.
%s Failed to delete all records for plugin=%@ with error=%@
%s Successfully deleted all records for plugin=%@
%s %@ deallocating
%s %@ cancelling instance %@
%s Can't decode _contactWordsWithFrequency or _contactsWords
%s _vocabularyWords is not an NSDictionary
%s Expected CESRVocabularyCategory in _vocabularyWords
%s Expected set in _vocabularyWords
%s Element in set in _vocabularyWords is not a string
%s interactionRecords is not NSArray
%s entry in interactionRecords is not NSDictionary
%s _interactionSenderDisplayNames is not NSDictionary
%s key in interactionSenderDisplayNames is not NSString
%s object in interactionSenderDisplayNames is not NSNumber
%s Processing KVItems for the following speech categories: %@
%s %d fields were empty while processing KVItems from %@ for speech profile.
%s Error fetching Proactive named entities, error: %s
%s Method 'formatWords' not found in EARFormatter
%s Added Policy: %@
%s Can't Parse JSON From %@, Error: %@
%s Can't Read File From %@, Error: %@
%s The dimension %@ matches the sampling policy %@ .
%s No Sampling Policy Available
%s Loading Sampling Config for Factor Name: %@
%s No File Path for Factor Name: %@
%s File Path for Factor Name: %@ is %@
%s No Sampling Config Available
%s No Sampling Rate Returned
%s Sampled with sampling rate = %lf, sampled result = %d
%s ASR: Using QoS class %#02X.
%s CoreEmbeddedSpeechRecognizer Dealloc
%s %@ Interrupted
%s %@ Invalidated
%s %@: Local speech recognition not reachable: %@
%s Preheat loading profile with language %@
%s Loaded preheat-loaded speech profile
%s Failed to load speech profile during preheat
%s Device not compatible with ANE, so ignoring model compilation
%s Starting to compile all assets
%s Error with model compilation: %@
%s Local speech recognizer restarted while already recognizing
%s Invalid nil language
%s Local speech recognition completed
%s Failed to start local recognition: %@
%s Using preheat-loaded speech profile
%s Loading speech profile for language %@
%s Failed to send speech correction info: %@
%s Update skipped for %@, not propagating an error
%s DES recipe evaluation was successful, made user profile of %lu bytes
%s DES recipe evaluation was successful, but no user data profile was created
%s DES recipe evaluation was successful
%s %@
%s Using user profile from %@
%s Error deleting all DES records (SPI v2): %{public}@
%s Not fetching assets for nil language
%s Successfully registered CacheDelete by Trial, asset type %{public}@, with exceptLanguages: %@
%s Failed to register CacheDelete by Trial
%s Initiating DES record write
%s Failed to delete DES Records for Dictation Personalization with error=%@
%s No speech recognized, synthesizing local speech error
%s PLM: Invalidation error %@
%s PLM: Removal error %@
%s PLM: Removed
%s UaaP: Invalidation error %@
%s Serialization of  %@ speech profile failed with error=%{public}@
%s Serialization of %@ speech profile done.
%s Persisting %@ speech profile to disk failed with error=%{public}@
%s Persisted %@ speech profile to path=%@
TrialNamespaceProjectPair
CESRAdditions
CESRTrialAssetManager
CESRSpeechProfileBuilderService
NSObject
CESRAssistantOnDeviceSampling
CESRAssetConfig
NSSecureCoding
NSCoding
CESRModelProperties
NSCopying
_CESRModelPropertiesMutation
CESRModelPropertiesMutating
CESRModelPropertiesMutability
CESRDictationOnDeviceSampling
InterfaceCompatibility
CESRXPCActivity
CESRUtilitiesAdditions
CESRUtilities
ResultCandidateId
CESRAudioSamplingUtilities
CESRFidesASRRecord
CESRSpeechProfileBuilder
CESRUserData
CESRUserDataContactWord
CESRVocabularyCategory
CESRContextualData
CESRFormatter
CESRSpeechService
CESRSpeechServiceDelegate
CESRSamplingDimension
CESRAudioSamplingPolicy
CESRAudioSamplingConfig
CESRCorrectionPronunciation
CESRSpeechParameters
_CESRSpeechParametersMutation
CESRSpeechParametersMutating
CESRSpeechParametersMutability
CESRAudioSamplingConfigManager
CESRUserCorrectionsProfileEntry
CoreEmbeddedSpeechRecognizer
CoreEmbeddedSpeechRecognizerProvider
projectId
setProjectId:
namespace
setNamespace:
.cxx_destruct
_projectId
_namespace
Ti,N,V_projectId
T@"NSString",&,N,V_namespace
factor
name
componentsSeparatedByString:
lastObject
level
directoryValue
asset
assetId
metadata
objectForKey:
boolValue
_cesr_language
_cesr_assetId
_cesr_preferOverServer
_cesr_supportsContinuousListening
_cesr_supportsOnDeviceSearch
_cesr_supportsAutoPunctuation
_cesr_supportsEmojiRecognition
initWithClients:cleanupDuration:
init
dictionary
_scheduleCleanupTimer
_cancelCleanupTimer
dealloc
namespaceNameFromId:
isEqualToString:
stringByReplacingOccurrencesOfString:withString:
factorPrefixForAssetType:
stringByAppendingString:
factorNameForAssetType:language:regionId:
containsString:
trialIdsForAssetType:
_trialClientForProject:
factorLevelsWithNamespaceName:
overrideAssetPath:
countByEnumeratingWithState:objects:count:
factorName:belongsToAssetType:
levelOneOfCase
_overrideAssetStatus:
stringWithFormat:
setObject:forKey:
hasPath
path
length
arrayWithObjects:count:
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
modelTypeStatusStringAndVersionWithAsset:
modelAttributesStatusStringWithAsset:
initWithLanguage:assetType:
installedAssetWithConfig:
installedAssetWithConfig:regionId:
installedAssetWithConfig:regionId:triggerDownload:
assetType
language
_installedAssetWithConfig:regionId:triggerDownload:
supportedLanguagesWithAssetType:
containsObject:
levelForFactor:withNamespaceName:
startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:
fileValue
setFactorsProvisionalForNamespace:error:
promoteFactorsForNamespace:error:
refresh
downloadAssetOfType:language:urgent:progressHandler:completionHandler:
downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
factorNameForAssetType:language:
clientWithIdentifier:
addObject:
purgeInstalledAssetForAssetType:language:regionId:error:
removeObject:
array
_languageFromFactorName:assetType:
count
removeAssetsForFactors:withNamespace:withClient:error:
dictationIsEnabled
_purgeInstalledAssetsExceptLanguages:assetType:error:
hasAsset
numberWithInt:
setPurgeabilityLevelsForFactors:withNamespaceName:
installationStatusForLanguagesForAssetType:includeDetailedStatus:error:
assetStatus:
removeUpdateHandlerForToken:
addUpdateHandlerForNamespaceName:usingBlock:
removeAllObjects
removeObjectForKey:
allObjects
_cleanupTimerFired
releaseClients
objectAtIndex:
stringByAppendingFormat:
isBelowLocaleLimit
setWithObject:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
standardUserDefaults
initWithString:
appendString:
copy
sharedPreferences
removeLevelsForFactors:withNamespace:queue:completion:
initialize
sharedInstance
getAssetTypeForNamespace:
jsonFilenameForAssetType:
triClients
installedAssetOfType:language:
installedFileAssetOfAssetType:factorName:
setAssetsProvisionalForAssetType:
promoteAssetsForAssetType:
switchToNewAssetsForAssetType:
downloadAssetOfType:language:progressHandler:completionHandler:
downloadStatusWithConfig:progressHandler:completionHandler:
_purgeLegacyDictationAssetForLanguage:
purgeInstalledAssetsExceptLanguages:assetType:error:
setAssetsPurgeabilityExceptLanguages:assetType:
registerAssetDelegate:assetType:
releaseClientsForAssetType:
modelQualityTypeStatusStringWithConfig:
wait
_queue
_trialClientDict
_cleanupTimer
_cleanupDuration
_purgedLegacyDictationAssetCache
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:completion:
getVersionForCategory:completion:
beginWithCategoriesAndVersions:bundleId:completion:
addVocabularyItems:isBoosted:completion:
cancelWithCompletion:
finishAndSaveProfile:completion:
interfaceWithProtocol:
sharedManager
isRequestSelectedForSamplingForTask:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
encodeObject:forKey:
encodeInteger:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
initWithLanguage:task:
_language
_assetType
T@"NSString",R,C,N,V_language
TQ,R,N,V_assetType
_descriptionWithIndent:
initWithFormat:
componentsJoinedByString:
modelVersion
modelType
modelRoot
initWithModelVersion:modelType:modelRoot:
copyWithZone:
_modelVersion
_modelType
_modelRoot
T@"NSString",R,C,N,V_modelVersion
T@"NSString",R,C,N,V_modelType
T@"NSString",R,C,N,V_modelRoot
initWithBaseModel:
setModelVersion:
setModelType:
setModelRoot:
generate
_baseModel
_mutationFlags
mutatedCopyWithMutator:
newWithBuilder:
_readDictationSampledPlist
updateDateToCurrent
resetRequestCount
sampledCurrentSamplingDateKey
integerValue
setRequestCount:
incrementRequestCount
numberWithInteger:
setObject:forKeyedSubscript:
createDictationSampledPlistIfItDoesNotExist
date
currentCalendar
components:fromDate:
date:matchesComponents:
isDictationHIPAACompliant
isDictationOnDeviceSamplingDisabled
siriDataSharingOptInStatus
isSamplingDateCurrent
shouldSampleFromConfigForProductType:language:
numberWithBool:
isRequestSelectedForSamplingFromConfigForLanguage:
sampledLibraryDirectoryPath
sampledPlistFileName
fileURLWithPath:
dictionaryWithContentsOfURL:error:
mutableCopy
_createDictationSampledPlistIfItDoesNotExist
createSamplingDirectory
stringByAppendingPathComponent:
defaultManager
fileExistsAtPath:isDirectory:
_writeDictationSamplingVariablesToFile:
writeToFile:atomically:
updateRequestCountWithFlag:
decrementRequestCount
isRequestSelectedForSampling
numberOfRequestsTillNow
setNumberOfRequestsTillNow:
currentSamplingDate
setCurrentSamplingDate:
dictationSamplingVaribles
setDictationSamplingVaribles:
isRequestConsideredForSampling
setIsRequestConsideredForSampling:
isDeviceSampledFromConfig
setIsDeviceSampledFromConfig:
fileQueue
setFileQueue:
_isRequestConsideredForSampling
_isDeviceSampledFromConfig
_numberOfRequestsTillNow
_currentSamplingDate
_dictationSamplingVaribles
_fileQueue
Tq,N,V_numberOfRequestsTillNow
T@"NSDate",&,N,V_currentSamplingDate
T@"NSMutableDictionary",&,N,V_dictationSamplingVaribles
TB,N,V_isRequestConsideredForSampling
TB,N,V_isDeviceSampledFromConfig
T@"NSObject<OS_dispatch_queue>",&,N,V_fileQueue
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:enableEmojiRecognition:enableAutoPunctuation:enableVoiceCommands:sharedUserInfos:prefixText:postfixText:selectedText:powerContext:
initWithLanguage:requestIdentifier:interactionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
initWithLanguage:requestIdentifier:interactionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:sharedUserIds:enableEmojiRecognition:enableAutoPunctuation:
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:sharedUserIds:enableEmojiRecognition:enableAutoPunctuation:enableVoiceCommands:
registerXPCActivities
loadDate
setLoadDate:
T@"NSDate",C,N
timeZoneWithAbbreviation:
setTimeZone:
doubleValue
dateWithTimeIntervalSince1970:
components:fromDate:toDate:options:
recognition
utterances
interpretationIndices
initWithCapacity:
tokenName
setText:
phoneSequence
setPhoneSequence:
start
setStartTime:
silenceStart
setSilenceStartTime:
setEndTime:
setRemoveSpaceBefore:
hasSpaceAfter
confidence
setConfidenceScore:
ipaPhoneSequence
setIpaPhoneSequence:
tokenSausage
initWithPhrases:utterances:processedAudioDuration:
afRecognitionForEARSausage:processedAudioDuration:
preITNRecognition
audioAnalytics
latticeMitigatorResult
isFinal
resultCandidateId
intValue
utteranceStart
recognitionPaused
initWithRecognition:unfilteredRecognition:rawRecognition:audioAnalytics:isFinal:utteranceStart:latticeMitigatorResult:recognitionPaused:speechProfileUsed:resultCandidateId:
speechProfileRootDirectories
enumeratorAtPath:
pathWithComponents:
fileExistsAtPath:
speechProfilePathsWithLanguage:
objectForKeyedSubscript:
attributesOfItemAtPath:error:
timeIntervalSinceReferenceDate
addEntriesFromDictionary:
initWithPath:error:
hasSpaceBefore
enumerateObjectsUsingBlock:
arguments
presence
indexes
substringWithRange:
enumerateRangesUsingBlock:
initWithText:
voiceCommandsParamKeyBuilder:
commandIdentifier
initWithCommandId:isComplete:paramMatches:
initWithUtterance:parseCandidates:
tokens
earTokensToString:
voiceCommandInterpretations
afVoiceCommandGrammarParseResultForEARTokenString:withEARVoiceCommandInterpretations:
preITNTokens
preITNVoiceCommandInterpretations
initWithNBestParses:preITNNBestParses:
initWithCommandGrammarParsePackage:
nBest
nBestVoiceCommandInterpretations
preITNNBestVoiceCommandInterpretations
text
startTime
endTime
silenceStartTime
confidenceScore
removeSpaceAfter
removeSpaceBefore
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:appendedAutoPunctuation:
calculateDiffInDaysFromTimestamp:
hasRecognizedAnythingInAFSpeechPackage:
afTokensForEARTokens:removeSpaceBefore:
afSpeechPackageForEARPackage:processedAudioDuration:speechProfileUsed:
loadSpeechProfiles:language:
AFSpeechInfoPackageForEARSpeechRecognitionResult:
AFSpeechInfoPackageForEARSpeechRecognitionResultPackage:
earTokensForAFTokens:appendedAutoPunctuation:
mapContextOptionToString:
languageStringForLocaleString:
localeStringForLanguageString:
isFilePathValid:
setResultCandidateId:
T@"NSNumber",&,N
orderedSetWithArray:
initWithInterpretationIndices:confidenceScore:
setSource:
objectAtIndexedSubscript:
unsignedIntegerValue
setTokens:
indexOfObject:
numberWithUnsignedInteger:
arrayByAddingObject:
setInterpretationIndices:
firstObject
setInterpretations:
setIsLowConfidence:
interpretations
acousticFeatures
setValue:forKey:
speechRecognitionFeatures
initWithSpeechRecognitionFeatures:acousticFeatures:snr:
acousticFeatureValuePerFrame
frameDuration
initWithAcousticFeatureValue:frameDuration:
score
threshold
version
initWithResults:score:threshold:
isUniformlySampled:fromTotal:
isUniformlySampledWithPercentage:
isUniformlySampledWithSamplingRate:
initWithBundleIdentifier:
shouldMakeRecord
initWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
shouldMakeRecordWithFrequency:
initForReadingFromData:error:
setClass:forClassName:
finishDecoding
UUID
UUIDString
timeIntervalSince1970
appendData:
_audioPacketsDuration
setWithArray:
decodeObjectOfClasses:forKey:
decodeBoolForKey:
decodeDoubleForKey:
encodeBool:forKey:
encodeDouble:forKey:
numberWithDouble:
archivedDataWithRootObject:requiringSecureCoding:error:
todaysDate
_recordInfo
_recordData
logDESRecordingForLanguage:error:
saveRecordWithData:recordInfo:completion:
setDateFormat:
stringFromDate:
allKeys
save
deleteSavedRecordWithIdentfier:completion:
fetchSavedRecordInfoWithCompletion:
deleteAllSavedRecordsWithCompletion:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:
recordFromData:
deleteAllRecordsForPlugin:completion:
addAudioPacket:
hasData
markRecognition
concatenatedAudioPackets
setCorrectedText:
saveOneRecordPerDay
pluginId
task
samplingRate
farField
context
audioPackets
hasRecognizedAnything
interactionIdentifier
asrSelfComponentIdentifier
correctedText
recognizedText
setRecognizedText:
personalizedLMUsed
setPersonalizedLMUsed:
applicationName
setApplicationName:
setDate:
timestamp
profile
setProfile:
userData
setUserData:
originalAudioFileURL
setOriginalAudioFileURL:
_collectedAudioDurationMS
_audioExceededMaxDuration
_farField
_hasRecognizedAnything
_personalizedLMUsed
_pluginId
_task
_samplingRate
_context
_UUIDString
_audioPackets
_interactionIdentifier
_asrSelfComponentIdentifier
_correctedText
_recognizedText
_applicationName
_date
_timestamp
_profile
_userData
_originalAudioFileURL
T@"NSString",R,C,N,V_pluginId
T@"NSString",R,C,N,V_task
TQ,R,N,V_samplingRate
TB,R,N,V_farField
T@"NSArray",R,C,N,V_context
T@"NSString",R,C,N,V_UUIDString
T@"NSMutableArray",R,C,N,V_audioPackets
TB,R,N,V_hasRecognizedAnything
T@"NSString",R,C,N,V_interactionIdentifier
T@"NSString",R,C,N,V_asrSelfComponentIdentifier
T@"NSString",C,N,V_correctedText
T@"NSArray",C,N,V_recognizedText
TB,N,V_personalizedLMUsed
T@"NSString",C,N,V_applicationName
T@"NSString",C,N,V_date
Td,R,N,V_timestamp
T@"NSData",&,N,V_profile
T@"CESRUserData",&,N,V_userData
T@"NSURL",C,N,V_originalAudioFileURL
_newConnection
localeIdentifier
_setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:
invalidate
initWithServiceName:
setRemoteObjectInterface:
initWithUUIDBytes:
_setUUID:
_setQueue:
_UUID
setInterruptionHandler:
setInvalidationHandler:
resume
CESRErrorForXPCError:
synchronousRemoteObjectProxyWithErrorHandler:
buffer
getGlobalItemsMemoryLimitInBytes
_flushItemsWithError:
addVocabularyItem:isBoosted:error:
categoryToFieldTypeMap
initWithArray:
initWithLocaleIdentifier:
profileDirPathFromBasePath:language:userId:
removeItemAtPath:error:
contentsOfDirectoryAtPath:error:
hasPrefix:
code
categoryToLimitHintMap
supportedCategories
shouldOverrideDeferralForCategory:updateMode:
getSpeechLocaleForLocale:
deleteProfileAtDirectory:locale:userId:error:
deleteLegacyProfiles
profileFilePathFromBasePath:language:userId:
initWithDirectory:locale:userId:dataProtectionClass:
getVersionForCategory:error:
beginWithCategoriesAndVersions:bundleId:error:
addVocabularyItem:error:
cancelCategoriesWithError:
finishAndSaveProfile:error:
directory
locale
userId
dataProtectionClass
_connection
_serializedItems
_isBoosted
_summedCommittedItemsMemoryInBytes
_uncommittedItemsMemoryInBytes
_directory
_locale
_userId
_dataProtectionClass
T@"NSURL",R,N,V_directory
T@"NSLocale",R,N,V_locale
T@"NSString",R,N,V_userId
Tq,R,N,V_dataProtectionClass
setIsBoosted:
isBoosted
allValues
decodeArrayOfObjectsOfClass:forKey:
initWithComponents:frequency:
decodePropertyListForKey:
numberWithLong:
enumerateKeysAndObjectsUsingBlock:
_initWithLanguage:
populateUserDataFromItems:
_handleContacts:
_handleItems:forKVFieldTypes:withCategory:
_handleKeyboardLMDynamicVocabularyItems:
_vocabularyWordCategories
_handleVocabularyWords:template:
value
fieldType
enumerateFieldsWithLocaleType:usingBlock:
personNameComponentsFromString:
givenName
middleName
familyName
initWithTemplateName:tagName:
initWithObjects:
dictionaryRepresentation
initWithItems:language:
contactWordsWithFrequency
setContactWordsWithFrequency:
vocabularyWords
setVocabularyWords:
appNames
setAppNames:
interactionSenderDisplayNames
setInteractionSenderDisplayNames:
searchEventValues
setSearchEventValues:
locationOfInterestNames
setLocationOfInterestNames:
spatialLocationOfInterestNames
setSpatialLocationOfInterestNames:
eventTitles
setEventTitles:
eventLocationNames
setEventLocationNames:
keyboardLMDynamicVocabularyItems
setKeyboardLMDynamicVocabularyItems:
pexNamedEntityNames
setPexNamedEntityNames:
corrections
setCorrections:
_contactWordsWithFrequency
_vocabularyWords
_appNames
_interactionSenderDisplayNames
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_eventTitles
_eventLocationNames
_keyboardLMDynamicVocabularyItems
_pexNamedEntityNames
_corrections
T@"NSArray",C,N,V_contactWordsWithFrequency
T@"NSDictionary",C,N,V_vocabularyWords
T@"NSArray",C,N,V_appNames
T@"NSDictionary",C,N,V_interactionSenderDisplayNames
T@"NSDictionary",C,N,V_searchEventValues
T@"NSArray",C,N,V_locationOfInterestNames
T@"NSArray",C,N,V_spatialLocationOfInterestNames
T@"NSArray",C,N,V_eventTitles
T@"NSArray",C,N,V_eventLocationNames
T@"NSDictionary",C,N,V_keyboardLMDynamicVocabularyItems
T@"NSArray",C,N,V_pexNamedEntityNames
T@"NSArray",C,N,V_corrections
T@"NSDictionary",R,N
decodeDictionaryWithKeysOfClass:objectsOfClass:forKey:
decodeInt32ForKey:
encodeInt32:forKey:
components
frequency
_frequency
_components
T@"NSDictionary",R,C,N,V_components
Ti,R,N,V_frequency
templateName
tagName
_templateName
_tagName
T@"NSString",R,C,N,V_templateName
T@"NSString",R,C,N,V_tagName
initWithConfiguration:
metrics
containsEntity
setMatchingSourceBundleIds:
dateByAddingTimeInterval:
setFromDate:
setToDate:
defaultStore
item
bestLanguage
category
addNamedEntity2:metadata:
iterRankedNamedEntitiesWithQuery:error:block:
UTF8String
iterNamedEntitySourceWithApplication:task:block:
setBundleID:
setSuggestionDate:
rankedGlobalSuggestionsFromContext:contactsOnly:
recipients
displayName
iterRankedContactSourceWithApplication:task:block:
initWithConfiguration:taskName:applicationName:
fetchNamedEntitiesWithTimeInterval:
contextualData
taskName
_contextualData
_taskName
T@"NSString",R,N,V_applicationName
T@"NSString",R,N,V_taskName
T@"_EARContextualData",R,N,V_contextualData
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:
formatWords:task:autoPunctuate:
formatWords:task:autoPunctuate:recognizeEmoji:
initWithAssetConfig:
formatSpeechTokensWithAutoPunctuation:
_formatter
_assetConfig
resetCacheAndCompileAllAssetsWithCompletion:
preheatSpeechRecognitionWithLanguage:modelOverrideURL:
preheatSpeechRecognitionWithAssetConfig:preheatSource:modelOverrideURL:
startRequestActivityWithCompletion:
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
startSpeechRecognitionWithParameters:didStartHandler:
finishAudio
createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:
updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:
getOfflineAssetStatusIgnoringCache:assetType:withCompletion:
getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:
getOfflineDictationStatusIgnoringCache:withCompletion:
fetchAssetsForLanguage:completion:
fetchAssetsForAssetConfig:completion:
fetchModelPropertiesForAssetConfig:completion:
runAdaptationRecipeEvaluation:recordData:attachments:completion:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
readProfileAndUserDataWithLanguage:allowOverride:completion:
purgeInstalledAssetsExceptLanguages:completion:
purgeInstalledAssetsExceptLanguages:assetType:completion:
writeDESRecord
startMissingAssetDownload
sendSpeechCorrectionInfo:interactionIdentifier:
invalidatePersonalizedLM
removePersonalizedLMForFidesOnly:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
deleteAllDESRecordsForDictationPersonalizationWithCompletion:
invalidateUaapLm
pauseRecognition
resumeRecognitionWithPrefixText:postfixText:selectedText:
setClasses:forSelector:argumentIndex:ofReply:
speechServiceDidSelectRecognitionModelWithModelProperties:
speechServiceDidRecognizeTokens:
speechServiceDidProcessAudioDuration:
speechServiceDidRecognizeRawEagerRecognitionCandidate:
speechServiceDidRecognizePackage:
speechServiceDidFinishRecognitionWithStatistics:error:
speechServiceDidProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechServiceDidProduceLoggablePackage:
speechServiceDidRecognizeTokens:withMetadata:
speechServiceDidRecognizePackage:withMetadata:
speechServiceDidRecognizeFinalResultCandidatePackage:
asrLocale
initWithAsrLocale:
matches:
_asrLocale
T@"NSString",R,C,N,V_asrLocale
ruleDimension
floatValue
numDimension
initWithRuleDimension:samplingRate:numDimension:
isMatchedSamplingDimension:
_ruleDimension
_numDimension
T@"CESRSamplingDimension",R,C,N,V_ruleDimension
T@"NSNumber",R,C,N,V_samplingRate
Tq,R,N,V_numDimension
sortWithOptions:usingComparator:
dataWithContentsOfFile:options:error:
JSONObjectWithData:options:error:
initWithConfigDictionary:
initWithConfigPath:
getSamplingRateFromDimension:
samplingPolicies
_samplingPolicies
T@"NSArray",R,C,N,V_samplingPolicies
addTtsPronunciations:
setOrthography:
setLanguage:
setApgId:
setTtsVersion:
ttsPronunciationsCount
clearTtsPronunciations
ttsPronunciationsAtIndex:
setAsrPronunciationData:
allocWithZone:
ttsPronunciationsType
hasOrthography
hasLanguage
hasApgId
hasTtsVersion
setTokenOffset:
setHasTokenOffset:
hasTokenOffset
hasAsrPronunciationData
readFrom:
writeTo:
copyTo:
mergeFrom:
orthography
apgId
ttsVersion
tokenOffset
ttsPronunciations
setTtsPronunciations:
asrPronunciationData
_apgId
_asrPronunciationData
_orthography
_tokenOffset
_ttsPronunciations
_ttsVersion
_has
TB,R,N
T@"NSString",&,N,V_orthography
T@"NSString",&,N,V_language
T@"NSString",&,N,V_apgId
T@"NSString",&,N,V_ttsVersion
TB,N
Ti,N,V_tokenOffset
T@"NSMutableArray",&,N,V_ttsPronunciations
T@"NSData",&,N,V_asrPronunciationData
narrowband
detectUtterances
censorSpeech
secureOfflineOnly
shouldStoreAudioOnDevice
continuousListening
shouldHandleCapitalization
isSpeechAPIRequest
maximumRecognitionDuration
endpointStart
deliverEagerPackage
disableDeliveringAsrFeatures
enableEmojiRecognition
enableAutoPunctuation
enableVoiceCommands
requestIdentifier
dictationUIInteractionIdentifier
loggingContext
overrides
modelOverrideURL
codec
inputOrigin
location
distanceFromLocation:
jitGrammar
sharedUserInfos
prefixText
postfixText
selectedText
powerContext
setWithObjects:
_narrowband
_detectUtterances
_censorSpeech
_secureOfflineOnly
_shouldStoreAudioOnDevice
_continuousListening
_shouldHandleCapitalization
_isSpeechAPIRequest
_deliverEagerPackage
_disableDeliveringAsrFeatures
_enableEmojiRecognition
_enableAutoPunctuation
_enableVoiceCommands
_requestIdentifier
_dictationUIInteractionIdentifier
_loggingContext
_overrides
_modelOverrideURL
_codec
_maximumRecognitionDuration
_endpointStart
_inputOrigin
_location
_jitGrammar
_sharedUserInfos
_prefixText
_postfixText
_selectedText
_powerContext
T@"NSString",R,C,N,V_requestIdentifier
T@"NSString",R,C,N,V_dictationUIInteractionIdentifier
T@"NSArray",R,C,N,V_loggingContext
T@"NSString",R,C,N,V_applicationName
T@"NSData",R,C,N,V_profile
T@"NSDictionary",R,C,N,V_overrides
T@"NSURL",R,C,N,V_modelOverrideURL
T@"NSURL",R,C,N,V_originalAudioFileURL
T@"NSString",R,C,N,V_codec
TB,R,N,V_narrowband
TB,R,N,V_detectUtterances
TB,R,N,V_censorSpeech
TB,R,N,V_secureOfflineOnly
TB,R,N,V_shouldStoreAudioOnDevice
TB,R,N,V_continuousListening
TB,R,N,V_shouldHandleCapitalization
TB,R,N,V_isSpeechAPIRequest
Td,R,N,V_maximumRecognitionDuration
Td,R,N,V_endpointStart
T@"NSString",R,C,N,V_inputOrigin
T@"CLLocation",R,C,N,V_location
T@"NSArray",R,C,N,V_jitGrammar
TB,R,N,V_deliverEagerPackage
TB,R,N,V_disableDeliveringAsrFeatures
TB,R,N,V_enableEmojiRecognition
TB,R,N,V_enableAutoPunctuation
TB,R,N,V_enableVoiceCommands
T@"NSArray",R,C,N,V_sharedUserInfos
T@"NSString",R,C,N,V_prefixText
T@"NSString",R,C,N,V_postfixText
T@"NSString",R,C,N,V_selectedText
T@"AFPowerContextPolicy",R,C,N,V_powerContext
setRequestIdentifier:
setDictationUIInteractionIdentifier:
setTask:
setLoggingContext:
setOverrides:
setModelOverrideURL:
setCodec:
setNarrowband:
setDetectUtterances:
setCensorSpeech:
setFarField:
setSecureOfflineOnly:
setShouldStoreAudioOnDevice:
setContinuousListening:
setShouldHandleCapitalization:
setIsSpeechAPIRequest:
setMaximumRecognitionDuration:
setEndpointStart:
setInputOrigin:
setLocation:
setJitGrammar:
setDeliverEagerPackage:
setDisableDeliveringAsrFeatures:
setEnableEmojiRecognition:
setEnableAutoPunctuation:
setEnableVoiceCommands:
setSharedUserInfos:
setPrefixText:
setPostfixText:
setSelectedText:
setPowerContext:
initWithAudioSamplingConfigDict:
loadConfigs
_createConfigFromProductType:
audioSamplingConfigDict
_audioSamplingConfigDict
numberWithUnsignedInt:
setPronunciationData:
hasCorrectedText
hasPronunciationData
setSpellingCorrectionsCount:
setHasSpellingCorrectionsCount:
hasSpellingCorrectionsCount
setTap2editCorrectionsCount:
setHasTap2editCorrectionsCount:
hasTap2editCorrectionsCount
setAlternativesCorrectionsCount:
setHasAlternativesCorrectionsCount:
hasAlternativesCorrectionsCount
pronunciationData
spellingCorrectionsCount
tap2editCorrectionsCount
alternativesCorrectionsCount
_alternativesCorrectionsCount
_pronunciationData
_spellingCorrectionsCount
_tap2editCorrectionsCount
T@"NSString",&,N,V_correctedText
T@"CESRCorrectionPronunciation",&,N,V_pronunciationData
TI,N,V_spellingCorrectionsCount
TI,N,V_tap2editCorrectionsCount
TI,N,V_alternativesCorrectionsCount
infersQoSFromInstanceUUIDForEAR
setExportedInterface:
setExportedObject:
localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
_service
initWithDelegate:instanceUUID:
stringWithUTF8String:
_serviceWithFunctionName:errorHandler:
localizedDescription
domain
_synchronousServiceWithErrorHandler:
profilePathForLanguage:errorOut:
initWithContentsOfFile:options:error:
propertyListWithData:options:format:error:
localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:
localSpeechRecognizer:didRecognizeTokens:
localSpeechRecognizer:didRecognizeTokens:withMetadata:
localSpeechRecognizer:didProcessAudioDuration:
localSpeechRecognizer:didRecognizeRawEagerRecognitionCandidate:
localSpeechRecognizer:didRecognizeFinalResultCandidatePackage:
localSpeechRecognizer:didRecognizePackage:
localSpeechRecognizer:didRecognizePackage:withMetadata:
localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
localSpeechRecognizer:didProduceLoggablePackage:
initWithDomain:code:userInfo:
resetCacheAndCompileAllAssets
speechProfileDataLastModifiedDataForLanguage:
dictionaryWithContentsProfilePathForLanguage:errorOut:
purgeInstalledAssetsExceptLanguages:error:
offlineDictationStatusIgnoringCache:error:
updateSpeechProfileWithLanguage:modelOverridePath:completion:
getOfflineDictationStatusWithCompletion:
modelPropertiesForAssetConfig:error:
resetDESWithCompletion:
fetchUserDataForLanguage:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
removePersonalizedLMForFidesOnly:
deleteAllDESRecordsForDictationPersonalization
instanceUUID
invalidateUaapLM
delegate
_recognitionActive
_esConnection
_instanceUUID
_currentLanguage
_recognitionError
_preheatedProfileAssetPath
_preheatedProfile
_delegate
T@"<CoreEmbeddedSpeechRecognizerDelegate>",R,W,N,V_delegate
dataWithPropertyList:format:options:error:
writeToFile:options:error:
i16@0:8
v20@0:8i16
@16@0:8
v24@0:8@16
v16@0:8
@"NSString"
B16@0:8
Q24@0:8@16
@24@0:8Q16
@40@0:8Q16@24@32
@32@0:8Q16@24
B32@0:8@16Q24
@32@0:8@16Q24
@36@0:8Q16B24^@28
@24@0:8@16
@32@0:8@16@24
@36@0:8@16@24B32
v24@0:8Q16
v48@0:8Q16@24@?32@?40
v52@0:8Q16@24B32@?36@?44
v56@0:8Q16@24B32B36@?40@?48
v40@0:8@16@?24@?32
B40@0:8@16Q24^@32
B48@0:8Q16@24@32^@40
v32@0:8@16Q24
@20@0:8i16
v68@0:8Q16@24@32@40B48@?52@?60
B48@0:8@16@24@32^@40
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSObject<OS_dispatch_source>"
@"NSMutableSet"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
Vv56@0:8@16@24@32q40@?48
Vv32@0:8@16@?24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv28@0:8B16@?20
Vv56@0:8@"NSString"16@"NSString"24@"NSString"32q40@?<v@?B@"NSError">48
Vv32@0:8@"NSString"16@?<v@?q@"NSError">24
Vv40@0:8@"NSDictionary"16@"NSString"24@?<v@?B@"NSError">32
Vv40@0:8@"NSArray"16@"NSArray"24@?<v@?B@"NSError">32
Vv24@0:8@?<v@?B@"NSError">16
Vv28@0:8B16@?<v@?B@"NSError">20
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
@40@0:8@16@24@32
v24@0:8@"NSString"16
@"CESRModelProperties"
{_mutationFlags="isDirty"b1"hasModelVersion"b1"hasModelType"b1"hasModelRoot"b1}
@24@0:8@?16
v20@0:8B16
v24@0:8q16
q16@0:8
@"NSDate"
@184@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132d136d144@152@160@168B176B180
@188@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184
@204@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184@188B196B200
@208@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184@188B196B200B204
q24@0:8@16
@28@0:8@16B24
@32@0:8@16d24
@36@0:8@16d24B32
v32@0:8@16@24
B32@0:8Q16Q24
B24@0:8Q16
B20@0:8f16
@72@0:8@16@24@32B40B44@48@56@64
@80@0:8@16@24@32B40B44@48@56@64Q72
v32@0:8@16@?24
d16@0:8
@"NSArray"
@"NSMutableArray"
@"NSData"
@"CESRUserData"
@"NSURL"
@48@0:8@16@24@32q40
B48@0:8@16@24@32q40
q32@0:8@16^@24
B40@0:8@16@24^@32
B36@0:8@16B24^@28
B32@0:8@16^@24
B24@0:8^@16
B28@0:8B16^@20
@"NSXPCConnection"
@"NSLocale"
@"NSDictionary"
@28@0:8@16i24
v24@0:8d16
@"_EARContextualData"
@"_EARFormatter"
@"CESRAssetConfig"
Vv32@0:8@16@24
Vv40@0:8@16@24@32
Vv24@0:8@16
Vv48@0:8@16@24@32@?40
Vv56@0:8@16@24@32@40@?48
Vv36@0:8B16Q20@?28
Vv40@0:8B16Q20B28@?32
Vv72@0:8@16@24@32Q40B48B52@56@?64
Vv36@0:8@16B24@?28
Vv40@0:8@16Q24@?32
Vv32@0:8@16Q24
Vv76@0:8@16@24@32@40@48@56B64@?68
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@"NSURL"24
Vv40@0:8@"CESRAssetConfig"16@"NSString"24@"NSURL"32
Vv24@0:8@?<v@?>16
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
Vv24@0:8@"NSData"16
Vv48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
Vv56@0:8@"NSString"16@"NSString"24@"NSData"32@"NSString"40@?<v@?@"NSData"@"NSString"@"NSError">48
Vv36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
Vv40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
Vv28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
Vv32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSData"@"NSError">40
Vv72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
Vv36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
Vv32@0:8@"NSSet"16@?<v@?@"NSNumber"@"NSError">24
Vv40@0:8@"NSSet"16Q24@?<v@?B@"NSError">32
Vv32@0:8@"NSSet"16Q24
Vv32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
Vv28@0:8B16@?<v@?>20
Vv76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
Vv40@0:8@"NSString"16@"NSString"24@"NSString"32
Vv24@0:8d16
Vv64@0:8q16q24d32@40d48q56
Vv24@0:8@"CESRModelProperties"16
Vv24@0:8@"NSArray"16
Vv24@0:8@"AFSpeechRecognition"16
Vv24@0:8@"AFSpeechPackage"16
Vv32@0:8@"NSDictionary"16@"NSError"24
Vv64@0:8q16q24d32@"NSArray"40d48q56
Vv32@0:8@"NSArray"16@"AFSpeechInfoPackage"24
Vv32@0:8@"AFSpeechPackage"16@"AFSpeechInfoPackage"24
@40@0:8@16@24q32
@"CESRSamplingDimension"
@"NSNumber"
{?="tokenOffset"b1}
@240@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184B188B192B196@200@208@216@224@232
@"CLLocation"
@"AFPowerContextPolicy"
v24@0:8@"NSArray"16
v24@0:8@"NSData"16
v24@0:8@"NSDictionary"16
v24@0:8@"NSURL"16
v24@0:8@"CLLocation"16
v24@0:8@"AFPowerContextPolicy"16
@"CESRSpeechParameters"
{_mutationFlags="isDirty"b1"hasLanguage"b1"hasRequestIdentifier"b1"hasDictationUIInteractionIdentifier"b1"hasTask"b1"hasLoggingContext"b1"hasApplicationName"b1"hasProfile"b1"hasOverrides"b1"hasModelOverrideURL"b1"hasOriginalAudioFileURL"b1"hasCodec"b1"hasNarrowband"b1"hasDetectUtterances"b1"hasCensorSpeech"b1"hasFarField"b1"hasSecureOfflineOnly"b1"hasShouldStoreAudioOnDevice"b1"hasContinuousListening"b1"hasShouldHandleCapitalization"b1"hasIsSpeechAPIRequest"b1"hasMaximumRecognitionDuration"b1"hasEndpointStart"b1"hasInputOrigin"b1"hasLocation"b1"hasJitGrammar"b1"hasDeliverEagerPackage"b1"hasDisableDeliveringAsrFeatures"b1"hasEnableEmojiRecognition"b1"hasEnableAutoPunctuation"b1"hasEnableVoiceCommands"b1"hasSharedUserInfos"b1"hasPrefixText"b1"hasPostfixText"b1"hasSelectedText"b1"hasPowerContext"b1}
@24@0:8q16
B32@0:8q16@24
v20@0:8I16
I16@0:8
@"CESRCorrectionPronunciation"
{?="alternativesCorrectionsCount"b1"spellingCorrectionsCount"b1"tap2editCorrectionsCount"b1}
@32@0:8@16^@24
@28@0:8B16^@20
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
v36@0:8B16Q20@?28
v40@0:8B16Q20B28@?32
v24@0:8@?16
v28@0:8B16@?20
v72@0:8@16@24@32Q40B48B52@56@?64
v36@0:8@16B24@?28
v68@0:8@16@24@32@40@48B56@?60
v76@0:8@16@24@32@40@48@56B64@?68
^[16C]16@0:8
v32@0:8@"NSString"16@"NSURL"24
v40@0:8@"CESRAssetConfig"16@"NSString"24@"NSURL"32
v32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
v32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
v48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
v40@0:8@"NSString"16@"NSString"24@?<v@?@"NSError">32
v36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
v40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
v24@0:8@?<v@?@"NSDictionary"@"NSError">16
v28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
v32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
@"CESRModelProperties"32@0:8@"CESRAssetConfig"16^@24
v48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSError">40
v72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
v36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
v24@0:8@?<v@?@"NSError">16
v32@0:8@"NSString"16@?<v@?@"NSError"@"NSData">24
v32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
v68@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSString"40@"NSString"48B56@?<v@?@"NSDictionary"@"NSError">60
v76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
v40@0:8@"NSString"16@"NSString"24@"NSString"32
@"NSDate"24@0:8@"NSString"16
@"NSNumber"32@0:8@"NSSet"16^@24
B40@0:8@"NSSet"16Q24^@32
v32@0:8@"NSSet"16Q24
@"NSString"32@0:8@"NSString"16^@24
@"NSDictionary"32@0:8@"NSString"16^@24
@"NSDictionary"28@0:8B16^@20
@32@0:8@16[16C]24
@32@0:8@16@?24
[16C]
@"NSError"
@"<CoreEmbeddedSpeechRecognizerDelegate>"
F>C:J
@(#)PROGRAM:CoreEmbeddedSpeechRecognition  PROJECT:CoreSpeech-1
PreferOverServer
SupportsContinuousListening
SupportsOnDeviceSearch
SupportsAutoPunctuation
SupportsEmojiRecognition
com.apple.siri.asr.dictation.audio.sampling
com.apple.siri.asr.assistant.audio.sampling
v8@?0
CESRTrialAssetManager Queue
Siri
unified_asset_namespace
+[CESRTrialAssetManager getAssetTypeForNamespace:]
-[CESRTrialAssetManager trialIdsForAssetType:]
com.apple.siri.asr.hammer.
com.apple.siri.asr.assistant.
com.apple.siri.asr.dictation.
com.apple.siri.asr.geolm.regionMapping.
com.apple.siri.asr.geolm.
+[CESRTrialAssetManager factorPrefixForAssetType:]
+[CESRTrialAssetManager factorNameForAssetType:language:regionId:]
daily_hammer.json
geolm-mini.json
geo-config.json
+[CESRTrialAssetManager jsonFilenameForAssetType:]
-[CESRTrialAssetManager installationStatusForLanguagesForAssetType:includeDetailedStatus:error:]
%@ModelInfo=%@
v24@?0d8Q16
-[CESRTrialAssetManager installationStatusForLanguagesForAssetType:includeDetailedStatus:error:]_block_invoke
%@: %@: AssetId=%@:
-[CESRTrialAssetManager _installedAssetWithConfig:regionId:triggerDownload:]
-[CESRTrialAssetManager _installedAssetWithConfig:regionId:triggerDownload:]_block_invoke
v16@?0Q8
v20@?0B8@"NSError"12
-[CESRTrialAssetManager installedFileAssetOfAssetType:factorName:]
-[CESRTrialAssetManager setAssetsProvisionalForAssetType:]
-[CESRTrialAssetManager promoteAssetsForAssetType:]
-[CESRTrialAssetManager switchToNewAssetsForAssetType:]
forceUpgrade=YES requires urgent=YES
Trial namespace could not be resolved for assetType=%lu
Factor name could not be resolved for assetType=%lu
-[CESRTrialAssetManager downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:]
-[CESRTrialAssetManager downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:]_block_invoke
Asset not available even after downloading. It's possible that we only subscribed and the actual download will happen later.
-[CESRTrialAssetManager downloadStatusWithConfig:progressHandler:completionHandler:]_block_invoke
-[CESRTrialAssetManager _purgeLegacyDictationAssetForLanguage:]
-[CESRTrialAssetManager _purgeLegacyDictationAssetForLanguage:]_block_invoke
-[CESRTrialAssetManager _purgeInstalledAssetsExceptLanguages:assetType:error:]
-[CESRTrialAssetManager purgeInstalledAssetForAssetType:language:regionId:error:]
-[CESRTrialAssetManager setAssetsPurgeabilityExceptLanguages:assetType:]
-[CESRTrialAssetManager registerAssetDelegate:assetType:]
-[CESRTrialAssetManager registerAssetDelegate:assetType:]_block_invoke
v16@?0@"<TRINamespaceUpdateProtocol>"8
-[CESRTrialAssetManager releaseClients]
-[CESRTrialAssetManager releaseClientsForAssetType:]
-[CESRTrialAssetManager _scheduleCleanupTimer]
-[CESRTrialAssetManager _cancelCleanupTimer]
-[CESRTrialAssetManager _cleanupTimerFired]
-[CESRTrialAssetManager modelQualityTypeStatusStringWithConfig:]
: %@
%@: ModelInfo=%@: AssetId=%@:
-[CESRTrialAssetManager startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:]_block_invoke
-[CESRTrialAssetManager startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:]
overrideAssetPath
overrideAssetStatus
-[CESRTrialAssetManager removeAssetsForFactors:withNamespace:withClient:error:]_block_invoke
-[CESRTrialAssetManager removeAssetsForFactors:withNamespace:withClient:error:]
Installed
Installing
Not Installing
Unknown
Hammer
CESRAssetTypeToString
Assistant
Dictation
GeoLMRegionMapping
GeoLMRegionSpecific
invalid enum
ar-SA
es-419
es-US
CESRAssetConfig::language
CESRAssetConfig::assetType
modelVersion
modelType
modelRoot
%@ {%@}
modelVersion = %@
modelType = %@
modelRoot = %@
CESRModelProperties::modelVersion
CESRModelProperties::modelType
CESRModelProperties::modelRoot
numberOfRequestsTillNow
isDeviceSampledFromConfig
CESRDictationOnDeviceSampling file queue
-[CESRDictationOnDeviceSampling decrementRequestCount]
-[CESRDictationOnDeviceSampling isRequestSelectedForSamplingFromConfigForLanguage:]
%@/%@
+[CESRDictationOnDeviceSampling _readDictationSampledPlist]
-[CESRDictationOnDeviceSampling _createDictationSampledPlistIfItDoesNotExist]
-[CESRDictationOnDeviceSampling _writeDictationSamplingVariablesToFile:]
ResultCandidateId
SpeechProfile
EARUserProfileContainerLoadDate
+[CESRUtilities speechProfileRootDirectories]
+[CESRUtilities speechProfilePathsWithLanguage:]
+[CESRUtilities loadSpeechProfiles:language:]
v32@?0@"_EARSpeechRecognitionToken"8Q16^B24
Param
v32@?0{_NSRange=QQ}8^B24
v32@?0@"EARVoiceCommandArgument"8Q16^B24
@"NSArray"24@?0@"NSArray"8@"NSArray"16
+[CESRUtilities AFSpeechInfoPackageForEARSpeechRecognitionResultPackage:]_block_invoke
v32@?0@"NSArray"8Q16^B24
unconstrained
reduced
avoid
AFSpeechLatticeMitigatorResultForEar
com.apple.fides.asr
+[CESRFidesASRRecord recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:]
+[CESRFidesASRRecord recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:]
SiriCoreLocalSpeechUserData
+[CESRFidesASRRecord recordFromData:]
%@, language=%@, task=%@, context=%@, samplingRate=%ld, profile(length)=%ld, UUIDString=%@, originalAudioFileURL=%@, audioPackets(duration)=%f, farField=%d, interactionIdentifier=%@, asrSelfComponentIdentifier=%@, correctedText=%@, recognizedText=%@, personalizedLMUsed=%d, applicationName=%@, date=%@, timestamp=%f
_language
_task
_context
_samplingRate
_profile
_userData
_UUIDString
_originalAudioFileURL
_audioPackets
_farField
_interactionIdentifier
_asrSelfComponentIdentifier
_correctedText
_recognizedText
_personalizedLMUsed
_applicationName
_date
_timestamp
-[CESRFidesASRRecord encodeWithCoder:]
language
task
context
samplingRate
farField
interactionIdentifier
asrSelfComponentIdentifier
personalizedLMUsed
applicationName
audioPacketsDuration
date
-[CESRFidesASRRecord _recordData]
-[CESRFidesASRRecord save]
-[CESRFidesASRRecord save]_block_invoke
v24@?0@"NSUUID"8@"NSError"16
yyyyMMdd
-[CESRFidesASRRecord saveOneRecordPerDay]_block_invoke_2
-[CESRFidesASRRecord saveOneRecordPerDay]_block_invoke
v16@?0@"NSError"8
v24@?0@"NSDictionary"8@"NSError"16
+[CESRFidesASRRecord deleteAllRecordsForPlugin:completion:]_block_invoke
CESRProfileErrorDomain
\NT-contact
\NT-action
\NT-payaccount
\NT-savedactivity
\NT-notetitle
\NT-notefolder
\NT-phototag
\NT-photoalbum
\NT-house
\NT-room
\NT-zone
\NT-group
\NT-device
\NT-scene
\NT-playlist
\NT-artist
\NT-appname
\NT-searchterm
\NT-location
\NT-calevent
\NT-unknown
\NT-entity
\NT-correction
\NT-appvocab
CESRSpeechProfileBuilderIsBoosted
/Assistant
-[CESRSpeechProfileBuilder dealloc]
com.apple.siri.embeddedspeech
CESRSpeechProfileBuilder
-[CESRSpeechProfileBuilder _newConnection]_block_invoke
-[CESRSpeechProfileBuilder _setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:]_block_invoke
-[CESRSpeechProfileBuilder getVersionForCategory:error:]_block_invoke
v24@?0q8@"NSError"16
-[CESRSpeechProfileBuilder beginWithCategoriesAndVersions:bundleId:error:]_block_invoke
-[CESRSpeechProfileBuilder _flushItemsWithError:]_block_invoke
-[CESRSpeechProfileBuilder cancelCategoriesWithError:]_block_invoke
-[CESRSpeechProfileBuilder finishAndSaveProfile:error:]_block_invoke
0000000000000000
Connection to the profile builder service was interrupted
Connection to the profile builder service was rejected
\contact-first
\contact-last
\contact-middle
\contact-nickname
\company-first
\contact-first-phonetic
\contact-last-phonetic
\contact-middle-phonetic
\company-first-phonetic
 language=%@, contactWordsWithFrequency count=%ld, vocabularyWords total count=%ld, appNames count=%ld, interactionSenderDisplayNames count=%ld, searchEventValues count=%ld, locationOfInterestNames count=%ld, keyboardLMDynamicVocabularyItems count=%ld eventTitles count=%ld eventLocationNames count=%ld, pexNamedEntityNames count=%ld, corrections count=%ld
 language=%@, contactWordsWithFrequency=%@, vocabularyWords=%@, appNames=%@, interactionSenderDisplayNames=%@, searchEventValues=%@, locationOfInterestNames=%@, keyboardLMDynamicVocabularyItems=%@ eventTitles=%@ eventLocationNames=%@, pexNamedEntityNames=%@, corrections=%@
_contactWordsWithFrequency
_contactsWords
-[CESRUserData initWithCoder:]
_vocabularyWords
_appNames
_interactionSenderDisplayNames
_interactionRecords
senderDisplayName
-[CESRUserData initWithCoder:]_block_invoke
v32@?0@"NSString"8@"NSNumber"16^B24
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_keyboardLMDynamicVocabularyItems
_eventTitles
_eventLocationNames
_pexNamedEntityNames
_corrections
contactWordsWithFrequency
vocabularyWords
appNames
interactionSenderDisplayNames
searchEventValues
locationOfInterestNames
spatialLocationOfInterestNames
keyboardLMDynamicVocabularyItems
eventTitles
eventLocationNames
pexNamedEntityNames
corrections
-[CESRUserData populateUserDataFromItems:]
v32@?0@"KVField"8Q16^B24
-[CESRUserData _handleItems:forKVFieldTypes:withCategory:]
-[CESRUserData _handleContacts:]
-[CESRUserData _handleKeyboardLMDynamicVocabularyItems:]
v24@?0@"NSString"8@"NSString"16
\artist-first
\playlist-first
\podcastTitle-first
\photoTags-first
\photoAlbumName-first
\carName-first
\paymentsOrganizationName-first
\paymentsAccountName-first
\healthActivity-first
\notebookTitle-first
\notebookFolderTitle-first
\voiceCommandName-first
\appMusicArtistName-first
\appPlaylistTitle-first
\appAudiobookTitle-first
\appShowTitle-first
\house-first
\room-first
\zone-first
\scene-first
\group-first
\device-first
\app-first
\unknown-first
-[CESRUserData _handleVocabularyWords:template:]
_components
_frequency
components
frequency
 components=%@, frequency=%lu
_templateName
_tagName
templateName
tagName
 templateName=%@, tagName=%@
WebSearch
v24@?0@"PPScoredItem"8^B16
-[CESRContextualData fetchNamedEntitiesWithTimeInterval:]_block_invoke
v40@?0@"NSSet"8@"NSDate"16@"NSDate"24Q32
v32@?0@"_PSSuggestion"8Q16^B24
v36@?0@"NSString"8@"NSDate"16B24Q28
v32@?0@"NSString"8@"NSString"16^B24
(%@,%@)
v32@?0@"CESRVocabularyCategory"8@"NSSet"16^B24
mini.json
dictation_emoji_recognition
-[CESRFormatter formatSpeechTokensWithAutoPunctuation:]
asrLocale
samplingPolicies
filterDimensions
< asrLocale=%@ >
< ruleDimension=%@, samplingRate=%.2f, numDimension=%zd >
-[CESRAudioSamplingConfig initWithConfigDictionary:]
q24@?0@"CESRAudioSamplingPolicy"8@"CESRAudioSamplingPolicy"16
-[CESRAudioSamplingConfig initWithConfigPath:]
-[CESRAudioSamplingConfig getSamplingRateFromDimension:]
%@ %@
orthography
apg_id
tts_version
token_offset
tts_pronunciations
asr_pronunciation_data
requestIdentifier
dictationUIInteractionIdentifier
loggingContext
profile
overrides
modelOverrideURL
originalAudioFileURL
codec
narrowband
detectUtterances
censorSpeech
secureOfflineOnly
shouldStoreAudioOnDevice
continuousListening
shouldHandleCapitalization
isSpeechAPIRequest
maximumRecognitionDuration
endpointStart
inputOrigin
location
jitGrammar
deliverEagerPackage
disableDeliveringAsrFeatures
enableEmojiRecognition
enableAutoPunctuation
enableVoiceCommands
sharedUserInfos
prefixText
postfixText
selectedText
powerContext
language = %@
requestIdentifier = %@
dictationUIInteractionIdentifier = %@
task = %@
loggingContext = %@
applicationName = %@
profile = (%ld bytes)
overrides = %@
modelOverrideURL = %@
originalAudioFileURL = %@
codec = %@
narrowband = %@
detectUtterances = %@
censorSpeech = %@
farField = %@
secureOfflineOnly = %@
shouldStoreAudioOnDevice = %@
continuousListening = %@
shouldHandleCapitalization = %@
isSpeechAPIRequest = %@
maximumRecognitionDuration = %@
endpointStart = %@
inputOrigin = %@
location = %@
jitGrammar = %@
deliverEagerPackage = %@
disableDeliveringAsrFeatures = %@
enableEmojiRecognition = %@
enableAutoPunctuation = %@
enableVoiceCommands = %@
sharedUserInfos = %@
prefixText = %@
postfixText = %@
selectedText = %@
powerContext = %@
CESRSpeechParameters::language
CESRSpeechParameters::requestIdentifier
CESRSpeechParameters::dictationUIInteractionIdentifier
CESRSpeechParameters::task
CESRSpeechParameters::loggingContext
CESRSpeechParameters::applicationName
CESRSpeechParameters::profile
CESRSpeechParameters::overrides
CESRSpeechParameters::modelOverrideURL
CESRSpeechParameters::originalAudioFileURL
CESRSpeechParameters::codec
CESRSpeechParameters::narrowband
CESRSpeechParameters::detectUtterances
CESRSpeechParameters::censorSpeech
CESRSpeechParameters::farField
CESRSpeechParameters::secureOfflineOnly
CESRSpeechParameters::shouldStoreAudioOnDevice
CESRSpeechParameters::continuousListening
CESRSpeechParameters::shouldHandleCapitalization
CESRSpeechParameters::isSpeechAPIRequest
CESRSpeechParameters::maximumRecognitionDuration
CESRSpeechParameters::endpointStart
CESRSpeechParameters::inputOrigin
CESRSpeechParameters::location
CESRSpeechParameters::jitGrammar
CESRSpeechParameters::deliverEagerPackage
CESRSpeechParameters::disableDeliveringAsrFeatures
CESRSpeechParameters::enableEmojiRecognition
CESRSpeechParameters::enableAutoPunctuation
CESRSpeechParameters::enableVoiceCommands
CESRSpeechParameters::sharedUserInfos
CESRSpeechParameters::prefixText
CESRSpeechParameters::postfixText
CESRSpeechParameters::selectedText
CESRSpeechParameters::powerContext
-[CESRAudioSamplingConfigManager _createConfigFromProductType:]
-[CESRAudioSamplingConfigManager shouldSampleFromConfigForProductType:language:]
corrected_text
pronunciation_data
spelling_corrections_count
tap2edit_corrections_count
alternatives_corrections_count
version
data
assetPath
SiriDictation
SearchOrMessaging
Tshot
VoiceMail
Beto
BetoDictation
-[CoreEmbeddedSpeechRecognizer initWithDelegate:instanceUUID:]
CoreEmbeddedSpeechRecognizer
-[CoreEmbeddedSpeechRecognizer dealloc]
-[CoreEmbeddedSpeechRecognizer _connection]_block_invoke
-[CoreEmbeddedSpeechRecognizer _serviceWithFunctionName:errorHandler:]_block_invoke
-[CoreEmbeddedSpeechRecognizer preheatSpeechRecognitionWithLanguage:modelOverrideURL:]_block_invoke
v24@?0@"NSData"8@"NSString"16
-[CoreEmbeddedSpeechRecognizer preheatSpeechRecognitionWithAssetConfig:preheatSource:modelOverrideURL:]_block_invoke
+[CoreEmbeddedSpeechRecognizer resetCacheAndCompileAllAssets]
+[CoreEmbeddedSpeechRecognizer resetCacheAndCompileAllAssets]_block_invoke
v24@?0@"CESRModelProperties"8@"NSError"16
-[CoreEmbeddedSpeechRecognizer startSpeechRecognitionWithParameters:didStartHandlerWithInfo:]_block_invoke
Language is nil
v16@?0@"<CESRSpeechParametersMutating>"8
-[CoreEmbeddedSpeechRecognizer startSpeechRecognitionWithParameters:didStartHandlerWithInfo:]_block_invoke_4
-[CoreEmbeddedSpeechRecognizer sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke
-[CoreEmbeddedSpeechRecognizer sendSpeechCorrectionInfo:interactionIdentifier:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer updateSpeechProfileWithLanguage:modelOverridePath:completion:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer updateSpeechProfileWithLanguage:modelOverridePath:completion:]_block_invoke_4
v32@?0@"NSData"8@"NSString"16@"NSError"24
-[CoreEmbeddedSpeechRecognizer getOfflineAssetStatusIgnoringCache:assetType:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer getOfflineDictationStatusIgnoringCache:withCompletion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer runAdaptationRecipeEvaluation:recordData:attachments:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer runAdaptationRecipeEvaluation:recordData:attachments:completion:]_block_invoke_3
v32@?0@"NSDictionary"8@"NSData"16@"NSError"24
-[CoreEmbeddedSpeechRecognizer runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:]_block_invoke_3
-[CoreEmbeddedSpeechRecognizer runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:]_block_invoke_3
-[CoreEmbeddedSpeechRecognizer readProfileAndUserDataWithLanguage:allowOverride:completion:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer readProfileAndUserDataWithLanguage:allowOverride:completion:]_block_invoke_3
+[CoreEmbeddedSpeechRecognizer dictionaryWithContentsProfilePathForLanguage:errorOut:]
-[CoreEmbeddedSpeechRecognizer resetDESWithCompletion:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer fetchAssetsForLanguage:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer fetchAssetsForAssetConfig:completion:]_block_invoke
-[CoreEmbeddedSpeechRecognizer modelPropertiesForAssetConfig:error:]
v24@?0@"NSNumber"8@"NSError"16
+[CoreEmbeddedSpeechRecognizer setAssetsPurgeabilityExceptLanguages:assetType:]
-[CoreEmbeddedSpeechRecognizer writeDESRecord]_block_invoke
-[CoreEmbeddedSpeechRecognizer deleteAllDESRecordsForDictationPersonalization]_block_invoke
-[CoreEmbeddedSpeechRecognizer deleteAllDESRecordsForDictationPersonalization]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer speechServiceDidFinishRecognitionWithStatistics:error:]
No API is available to fetch user data.
-[CoreEmbeddedSpeechRecognizer startMissingAssetDownload]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidatePersonalizedLM]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidatePersonalizedLM]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer removePersonalizedLMForFidesOnly:]_block_invoke_2
-[CoreEmbeddedSpeechRecognizer removePersonalizedLMForFidesOnly:]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidateUaapLM]_block_invoke
-[CoreEmbeddedSpeechRecognizer invalidateUaapLM]_block_invoke_2
WriteSpeechProfileData
%s CESRDictationAssetType has been deprecated. Using CESRAssistantAssetType instead.
%s trialIdsForAssetType: Unknown assetType %lu 
%s factorPrefixForAssetType: Unknown assetType %lu . Returning empty string
%s Language passed to `factorNameForAssetType` is nil.
%s factorNameForAssetType: regionId cannot be nil for assetType %lu 
%s factorNameForAssetType: Unknown assetType %lu 
%s jsonFilenameForAssetType: Unknown assetType %lu 
%s assetType: %lu includeDetailedStatus: %@
%s Unexpected factor type for factor: %@
%s Factor is already installed: %@ for language: %@
%s Asset Download Progress is stalled, ~%.f%% completed
%s Trial claims factor %@ is available but it doesn't have a path
%s Returning installation status for %lu: %@
%s Using overrided path for `installedAssetWithConfig`, assetType=%lu, asset path=%@
%s Language passed to `installedAssetWithConfig` is nil.
%s Trial namespace could not be resolved for assetType=%lu
%s Language:%@ AssetType:%lu is not supported on-device by ASR
%s No level available for factor:%@
%s Triggering download. Urgent: %@
%s Asset %@ download is %lu%% complete
%s Asset %@ download completed with error: %@, success=%d
%s Asset %@ download completed successfully
%s Got asset file from Trial at: %@ for language: %@
%s setAssetsProvisionalForAssetType: Failed to set %@ as provisional: %@
%s promoteAssetsForAssetType: Failed to promote %@: %@
%s Switching to new assets for asset type: %lu
%s Got asset file from Trial at: %@ for language: %@ urgent: %d forceUpgrade: %d
%s Asset %@ download completed with error, %@, %d
%s Asset %@ download is %lu%% complete, isStalled=%@
%s Assistant asset already exists for %@, purging legacy dictation asset.
%s Encountered error trying to purge legacy dictation asset: %@
%s Ignoring Purging asset: %@, language %@
%s No factors available to remove
%s Factors available to remove: %lu
%s Starting deletion of asset for assetType=%lu, namespace=%@, language=%@, updatedLanguage=%@, factorName=%@
%s Ignoring setting purgeability level for trial asset: %@, language %@
%s No factors available to set purgeability level
%s Factors available to register CacheDelete by Trial: %lu
%s New trial update for %@
%s Removed update handler for %@
%s Cancelling the cleanup timer since we're registering an asset delegate
%s Releasing all clients
%s Releasing clients for asset type
%s Cleanup timer scheduled
%s Cleanup timer canceled
%s Cleanup timer fired. This generally means that this process is not handling the TRIClient lifecycle properly. You need to call `releaseClients` once you no longer need the assets. This might cause the assets to be removed from disk. Also make sure to call `switchToNewAssetsForAssetType` at the beginning of new requests to get updated assets.
%s Cleanup timer fired
%s Immediate download for namespace %@ completed with error, %@, %d
%s Starting download of asset %@: urgent=%d options=%@
%s Can't download assets. Already reached the limit of assets on device.
%s Success:%d Error:%@
%s Removed factors: %@ error:%@
%s Failed to purge assets for namespace: %@ error:%@
%s Dictation Sampling: Done decrementing total number of dictation requests by 1, for the current sampling date.
%s Dictation Sampling: HIPAA Device, Sampling is DISABLED.
%s Dictation Sampling: Sampling is DISABLED.
%s Dictation Sampling: User is NOT opted in.
%s Dictation Sampling: isDeviceSampledFromConfig = %d
%s Dictation Sampling: Selected for sampling - Sampling all audio for Internal Install
%s Dictation Sampling: Selected for sampling - number of requests was 0.
%s Dictation Sampling: Selected for sampling - Sampling Date has been changed.
%s Dictation Sampling: Selected for sampling.
%s Dictation Sampling: NOT Selected for sampling
%s Dictation Sampling: Device is Not Participating in Sampling Today
%s Dictation Sampling: Error while reading plist at location %@ - %@
%s Dictation Sampling: Error while creating directory - %@
%s Dictation Sampling: Error while creating plist file. The dictationSampledPlistPath - %@ - is returned as Directory. Should not happen.
%s Dictation Sampling: Error while writing _dictationSamplingVaribles to plist - %@
%s Root directories for new type of speech profile: %{private}@
%s speechProfilePathsWithLanguage was incorrectly called with language=nil
%s Mapped language=nil
%s loadSpeechProfiles was incorrectly called with profiles=nil
%s Reused new type of speech profile: path=%{private}@
%s Loaded new type of speech profile: path=%{private}@ profile=%d
%s Count of command interpretation sets does not match count of speech recognition results
%s AFSpeechLatticeMitigatorResult Score = %f, Threshold = %f
%s AFSpeechLatticeMitigatorResult nil
%s Lost the lottery: not creating DES record this time
%s Lost the downsampled lottery: not creating DES record this time
%s DES record unarchive error: %@
%s Skipping audio bytes and save originalAudioFileURL instead
%s Unable to serialize DES record: %@
%s Skip DES record creation because of no recognition
%s Creating DES record (SPI v2): %{public}@, %{public}zu bytes
%s Could not write DES record for SPI v2 %{public}@: %{public}@
%s DES Record created for SPI v2 %@: %@
%s Failed to delete record: %@
%s Deleted record(%@)
%s Failed to fetch records.
%s Failed to delete all records for plugin=%@ with error=%@
%s Successfully deleted all records for plugin=%@
%s %@ deallocating
%s %@ cancelling instance %@
%s %@
%s Can't decode _contactWordsWithFrequency or _contactsWords
%s _vocabularyWords is not an NSDictionary
%s Expected CESRVocabularyCategory in _vocabularyWords
%s Expected set in _vocabularyWords
%s Element in set in _vocabularyWords is not a string
%s interactionRecords is not NSArray
%s entry in interactionRecords is not NSDictionary
%s _interactionSenderDisplayNames is not NSDictionary
%s key in interactionSenderDisplayNames is not NSString
%s object in interactionSenderDisplayNames is not NSNumber
%s Processing KVItems for the following speech categories: %@
%s %d fields were empty while processing KVItems from %@ for speech profile.
%s Error fetching Proactive named entities, error: %s
%s Method 'formatWords' not found in EARFormatter
%s Added Policy: %@
%s Can't Parse JSON From %@, Error: %@
%s Can't Read File From %@, Error: %@
%s The dimension %@ matches the sampling policy %@ .
%s No Sampling Policy Available
%s Loading Sampling Config for Factor Name: %@
%s No File Path for Factor Name: %@
%s File Path for Factor Name: %@ is %@
%s No Sampling Config Available
%s No Sampling Rate Returned
%s Sampled with sampling rate = %lf, sampled result = %d
%s ASR: Using QoS class %#02X.
%s CoreEmbeddedSpeechRecognizer Dealloc
%s %@ Interrupted
%s %@ Invalidated
%s %@: Local speech recognition not reachable: %@
%s Preheat loading profile with language %@
%s Loaded preheat-loaded speech profile
%s Failed to load speech profile during preheat
%s Device not compatible with ANE, so ignoring model compilation
%s Starting to compile all assets
%s Error with model compilation: %@
%s Local speech recognizer restarted while already recognizing
%s Invalid nil language
%s Local speech recognition completed
%s Failed to start local recognition: %@
%s Using preheat-loaded speech profile
%s Loading speech profile for language %@
%s Failed to send speech correction info: %@
%s Update skipped for %@, not propagating an error
%s DES recipe evaluation was successful, made user profile of %lu bytes
%s DES recipe evaluation was successful, but no user data profile was created
%s DES recipe evaluation was successful
%s Using user profile from %@
%s Error deleting all DES records (SPI v2): %{public}@
%s Not fetching assets for nil language
%s Successfully registered CacheDelete by Trial, asset type %{public}@, with exceptLanguages: %@
%s Failed to register CacheDelete by Trial
%s Initiating DES record write
%s Failed to delete DES Records for Dictation Personalization with error=%@
%s No speech recognized, synthesizing local speech error
%s PLM: Invalidation error %@
%s PLM: Removal error %@
%s PLM: Removed
%s UaaP: Invalidation error %@
%s Serialization of  %@ speech profile failed with error=%{public}@
%s Serialization of %@ speech profile done.
%s Persisting %@ speech profile to disk failed with error=%{public}@
%s Persisted %@ speech profile to path=%@
TrialNamespaceProjectPair
CESRAdditions
CESRTrialAssetManager
CESRSpeechProfileBuilderService
NSObject
CESRAssistantOnDeviceSampling
CESRAssetConfig
NSSecureCoding
NSCoding
CESRModelProperties
NSCopying
_CESRModelPropertiesMutation
CESRModelPropertiesMutating
CESRModelPropertiesMutability
CESRDictationOnDeviceSampling
InterfaceCompatibility
CESRXPCActivity
CESRUtilitiesAdditions
CESRUtilities
ResultCandidateId
CESRAudioSamplingUtilities
CESRFidesASRRecord
CESRSpeechProfileBuilder
CESRUserData
CESRUserDataContactWord
CESRVocabularyCategory
CESRContextualData
CESRFormatter
CESRSpeechService
CESRSpeechServiceDelegate
CESRSamplingDimension
CESRAudioSamplingPolicy
CESRAudioSamplingConfig
CESRCorrectionPronunciation
CESRSpeechParameters
_CESRSpeechParametersMutation
CESRSpeechParametersMutating
CESRSpeechParametersMutability
CESRAudioSamplingConfigManager
CESRUserCorrectionsProfileEntry
CoreEmbeddedSpeechRecognizer
CoreEmbeddedSpeechRecognizerProvider
initWithFormat:
contentsOfDirectoryAtPath:error:
writeToFile:options:error:
setClass:forClassName:
latticeMitigatorResult
enumerateObjectsUsingBlock:
timeIntervalSince1970
displayName
setObject:forKeyedSubscript:
rankedGlobalSuggestionsFromContext:contactsOnly:
decodeInt32ForKey:
setWithArray:
setBundleID:
enumerateKeysAndObjectsUsingBlock:
namespaceNameFromId:
bestLanguage
containsString:
lastObject
localizedDescription
start
initWithConfiguration:
personNameComponentsFromString:
decodeDoubleForKey:
threshold
initWithString:
fileValue
setObject:forKey:
hasSpaceBefore
setValue:forKey:
writeToFile:atomically:
enumerateFieldsWithLocaleType:usingBlock:
decodeDictionaryWithKeysOfClass:objectsOfClass:forKey:
standardUserDefaults
containsObject:
text
initWithSpeechRecognitionFeatures:acousticFeatures:snr:
fileURLWithPath:
audioAnalytics
hasSpaceAfter
ipaPhoneSequence
name
directoryValue
setMatchingSourceBundleIds:
pathWithComponents:
speechRecognitionFeatures
hasPrefix:
initWithServiceName:
localeIdentifier
setTokens:
decodeBoolForKey:
fileExistsAtPath:isDirectory:
nBestVoiceCommandInterpretations
attributesOfItemAtPath:error:
dictionaryWithObjects:forKeys:count:
removeUpdateHandlerForToken:
endTime
propertyListWithData:options:format:error:
confidenceScore
path
setToDate:
decodeArrayOfObjectsOfClass:forKey:
removeSpaceBefore
fileExistsAtPath:
nBest
voiceCommandInterpretations
dictionaryWithContentsOfURL:error:
JSONObjectWithData:options:error:
hasPath
iterRankedNamedEntitiesWithQuery:error:block:
initWithCommandId:isComplete:paramMatches:
confidence
fieldType
initWithResults:score:threshold:
addUpdateHandlerForNamespaceName:usingBlock:
promoteFactorsForNamespace:error:
removeSpaceAfter
version
hasAsset
sortWithOptions:usingComparator:
assetStatus:
setTimeZone:
iterRankedContactSourceWithApplication:task:block:
localSpeechRecognizer:didRecognizeTokens:
initWithCommandGrammarParsePackage:
encodeObject:forKey:
componentsSeparatedByString:
synchronousRemoteObjectProxyWithErrorHandler:
givenName
fetchSavedRecordInfoWithCompletion:
initWithRecognition:unfilteredRecognition:rawRecognition:audioAnalytics:isFinal:utteranceStart:latticeMitigatorResult:recognitionPaused:speechProfileUsed:resultCandidateId:
value
setIsLowConfidence:
dateWithTimeIntervalSince1970:
mutableCopy
assetId
dictionary
interpretations
setText:
iterNamedEntitySourceWithApplication:task:block:
localSpeechRecognizer:didRecognizeRawEagerRecognitionCandidate:
componentsJoinedByString:
encodeInteger:forKey:
setSuggestionDate:
initWithQuasarConfig:overrideConfigFiles:supportEmojiRecognition:language:
dateByAddingTimeInterval:
setIpaPhoneSequence:
addObject:
item
utterances
interpretationIndices
encodeInt32:forKey:
removeObjectForKey:
asset
score
orderedSetWithArray:
initWithCapacity:
components:fromDate:toDate:options:
siriDataSharingOptInStatus
addNamedEntity2:metadata:
setInvalidationHandler:
substringWithRange:
initWithPhrases:utterances:processedAudioDuration:
date:matchesComponents:
utteranceStart
setStartTime:
interfaceWithProtocol:
saveRecordWithData:recordInfo:completion:
removeObject:
encodeDouble:forKey:
localSpeechRecognizer:didRecognizePackage:
initWithBundleIdentifier:
silenceStartTime
objectForKeyedSubscript:
components:fromDate:
stringWithUTF8String:
setInterruptionHandler:
addEntriesFromDictionary:
initWithPath:error:
setSource:
integerValue
removeLevelsForFactors:withNamespace:queue:completion:
arrayWithObjects:count:
encodeBool:forKey:
silenceStart
objectForKey:
dataWithPropertyList:format:options:error:
initWithObjects:
presence
setInterpretations:
stringWithFormat:
setSilenceStartTime:
removeItemAtPath:error:
arrayByAddingObject:
intValue
objectAtIndexedSubscript:
commandIdentifier
dataWithContentsOfFile:options:error:
stringFromDate:
setInterpretationIndices:
initWithNBestParses:preITNNBestParses:
acousticFeatures
familyName
_UUID
UUID
array
unsignedIntegerValue
sampledPlistFileName
objectAtIndex:
setFromDate:
acousticFeatureValuePerFrame
currentCalendar
stringByReplacingOccurrencesOfString:withString:
deleteSavedRecordWithIdentfier:completion:
arguments
setRemoveSpaceBefore:
removeAllObjects
code
localSpeechRecognizer:didProcessAudioDuration:
initWithArray:
shouldMakeRecordWithFrequency:
numberWithUnsignedInteger:
sampledLibraryDirectoryPath
remoteObjectProxyWithErrorHandler:
initWithLocaleIdentifier:
numberWithUnsignedInt:
setFactorsProvisionalForNamespace:error:
stringByAppendingString:
middleName
setRemoteObjectInterface:
deleteAllSavedRecordsWithCompletion:
archivedDataWithRootObject:requiringSecureCoding:error:
shouldMakeRecord
localSpeechRecognizer:didCompletionRecognitionWithStatistics:error:
initWithAcousticFeatureValue:frameDuration:
setExportedObject:
sampledCurrentSamplingDateKey
clientWithIdentifier:
preITNVoiceCommandInterpretations
remoteObjectProxy
createSamplingDirectory
stringByAppendingPathComponent:
setExportedInterface:
setPurgeabilityLevelsForFactors:withNamespaceName:
UTF8String
preITNTokens
numberWithLong:
initForReadingFromData:error:
defaultStore
stringByAppendingFormat:
frameDuration
tokens
appendString:
metadata
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
numberWithInteger:
preITNRecognition
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
countByEnumeratingWithState:objects:count:
factorLevelsWithNamespaceName:
setEndTime:
formatWords:task:autoPunctuate:recognizeEmoji:
appendData:
refresh
infersQoSFromInstanceUUIDForEAR
tokenSausage
defaultManager
_setUUID:
isFinal
setDateFormat:
sharedPreferences
numberWithInt:
startTime
preITNNBestVoiceCommandInterpretations
initWithInterpretationIndices:confidenceScore:
allocWithZone:
count
levelOneOfCase
factor
floatValue
decodePropertyListForKey:
initWithUtterance:parseCandidates:
recognitionPaused
tokenName
category
numberWithDouble:
indexes
isEqualToString:
_setQueue:
phoneSequence
errorWithDomain:code:userInfo:
levelForFactor:withNamespaceName:
allValues
initWithUUIDBytes:
decodeObjectOfClasses:forKey:
firstObject
recognition
initWithDomain:code:userInfo:
indexOfObject:
doubleValue
numberWithBool:
enumeratorAtPath:
recipients
setConfidenceScore:
copy
level
finishDecoding
domain
initWithTokenName:start:end:silenceStart:confidence:hasSpaceAfter:hasSpaceBefore:phoneSequence:ipaPhoneSequence:appendedAutoPunctuation:
setPhoneSequence:
setWithObjects:
timeZoneWithAbbreviation:
decodeObjectOfClass:forKey:
allObjects
buffer
resume
isDictationOnDeviceSamplingDisabled
setClasses:forSelector:argumentIndex:ofReply:
enumerateRangesUsingBlock:
length
allKeys
logDESRecordingForLanguage:error:
distanceFromLocation:
initWithText:
timeIntervalSinceReferenceDate
decodeIntegerForKey:
initWithContentsOfFile:options:error:
isDictationHIPAACompliant
setWithObject:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
boolValue
projectId
setProjectId:
namespace
setNamespace:
.cxx_destruct
_projectId
_namespace
Ti,N,V_projectId
T@"NSString",&,N,V_namespace
_cesr_language
_cesr_assetId
_cesr_preferOverServer
_cesr_supportsContinuousListening
_cesr_supportsOnDeviceSearch
_cesr_supportsAutoPunctuation
_cesr_supportsEmojiRecognition
init
dealloc
initialize
sharedInstance
getAssetTypeForNamespace:
factorPrefixForAssetType:
factorNameForAssetType:language:regionId:
factorNameForAssetType:language:
jsonFilenameForAssetType:
factorName:belongsToAssetType:
initWithClients:cleanupDuration:
triClients
trialIdsForAssetType:
installationStatusForLanguagesForAssetType:includeDetailedStatus:error:
installedAssetOfType:language:
installedAssetWithConfig:
installedAssetWithConfig:regionId:
installedAssetWithConfig:regionId:triggerDownload:
_installedAssetWithConfig:regionId:triggerDownload:
installedFileAssetOfAssetType:factorName:
setAssetsProvisionalForAssetType:
promoteAssetsForAssetType:
switchToNewAssetsForAssetType:
downloadAssetOfType:language:progressHandler:completionHandler:
downloadAssetOfType:language:urgent:progressHandler:completionHandler:
downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:
downloadStatusWithConfig:progressHandler:completionHandler:
_purgeLegacyDictationAssetForLanguage:
_purgeInstalledAssetsExceptLanguages:assetType:error:
purgeInstalledAssetsExceptLanguages:assetType:error:
purgeInstalledAssetForAssetType:language:regionId:error:
setAssetsPurgeabilityExceptLanguages:assetType:
registerAssetDelegate:assetType:
releaseClients
releaseClientsForAssetType:
supportedLanguagesWithAssetType:
_scheduleCleanupTimer
_cancelCleanupTimer
_cleanupTimerFired
_languageFromFactorName:assetType:
_trialClientForProject:
modelQualityTypeStatusStringWithConfig:
modelAttributesStatusStringWithAsset:
modelTypeStatusStringAndVersionWithAsset:
startDownloadLevelsForAsset:withFactor:withClient:withNamespace:urgent:progress:completion:
overrideAssetPath:
_overrideAssetStatus:
wait
isBelowLocaleLimit
dictationIsEnabled
removeAssetsForFactors:withNamespace:withClient:error:
_queue
_trialClientDict
_cleanupTimer
_cleanupDuration
_purgedLegacyDictationAssetCache
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:completion:
getVersionForCategory:completion:
beginWithCategoriesAndVersions:bundleId:completion:
addVocabularyItems:isBoosted:completion:
cancelWithCompletion:
finishAndSaveProfile:completion:
sharedManager
isRequestSelectedForSamplingForTask:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
initWithLanguage:assetType:
initWithLanguage:task:
language
assetType
_language
_assetType
T@"NSString",R,C,N,V_language
TQ,R,N,V_assetType
copyWithZone:
initWithModelVersion:modelType:modelRoot:
_descriptionWithIndent:
modelVersion
modelType
modelRoot
_modelVersion
_modelType
_modelRoot
T@"NSString",R,C,N,V_modelVersion
T@"NSString",R,C,N,V_modelType
T@"NSString",R,C,N,V_modelRoot
setModelVersion:
setModelType:
setModelRoot:
initWithBaseModel:
generate
_baseModel
_mutationFlags
mutatedCopyWithMutator:
newWithBuilder:
_readDictationSampledPlist
resetRequestCount
incrementRequestCount
updateRequestCountWithFlag:
decrementRequestCount
setRequestCount:
updateDateToCurrent
isSamplingDateCurrent
isRequestSelectedForSamplingFromConfigForLanguage:
isRequestSelectedForSampling
createDictationSampledPlistIfItDoesNotExist
_createDictationSampledPlistIfItDoesNotExist
_writeDictationSamplingVariablesToFile:
numberOfRequestsTillNow
setNumberOfRequestsTillNow:
currentSamplingDate
setCurrentSamplingDate:
dictationSamplingVaribles
setDictationSamplingVaribles:
isRequestConsideredForSampling
setIsRequestConsideredForSampling:
isDeviceSampledFromConfig
setIsDeviceSampledFromConfig:
fileQueue
setFileQueue:
_isRequestConsideredForSampling
_isDeviceSampledFromConfig
_numberOfRequestsTillNow
_currentSamplingDate
_dictationSamplingVaribles
_fileQueue
Tq,N,V_numberOfRequestsTillNow
T@"NSDate",&,N,V_currentSamplingDate
T@"NSMutableDictionary",&,N,V_dictationSamplingVaribles
TB,N,V_isRequestConsideredForSampling
TB,N,V_isDeviceSampledFromConfig
T@"NSObject<OS_dispatch_queue>",&,N,V_fileQueue
initWithLanguage:requestIdentifier:interactionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
initWithLanguage:requestIdentifier:interactionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:sharedUserIds:enableEmojiRecognition:enableAutoPunctuation:
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:sharedUserIds:enableEmojiRecognition:enableAutoPunctuation:enableVoiceCommands:
registerXPCActivities
loadDate
setLoadDate:
T@"NSDate",C,N
calculateDiffInDaysFromTimestamp:
hasRecognizedAnythingInAFSpeechPackage:
afTokensForEARTokens:removeSpaceBefore:
afRecognitionForEARSausage:processedAudioDuration:
afSpeechPackageForEARPackage:processedAudioDuration:speechProfileUsed:
speechProfileRootDirectories
speechProfilePathsWithLanguage:
loadSpeechProfiles:language:
earTokensToString:
voiceCommandsParamKeyBuilder:
afVoiceCommandGrammarParseResultForEARTokenString:withEARVoiceCommandInterpretations:
AFSpeechInfoPackageForEARSpeechRecognitionResult:
AFSpeechInfoPackageForEARSpeechRecognitionResultPackage:
earTokensForAFTokens:appendedAutoPunctuation:
mapContextOptionToString:
languageStringForLocaleString:
localeStringForLanguageString:
isFilePathValid:
setResultCandidateId:
resultCandidateId
T@"NSNumber",&,N
isUniformlySampled:fromTotal:
isUniformlySampledWithPercentage:
isUniformlySampledWithSamplingRate:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
recordWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:frequency:
recordFromData:
deleteAllRecordsForPlugin:completion:
initWithLanguage:task:context:narrowband:farField:interactionIdentifier:asrSelfComponentIdentifier:pluginId:
addAudioPacket:
hasData
markRecognition
_audioPacketsDuration
concatenatedAudioPackets
setCorrectedText:
_recordInfo
_recordData
save
todaysDate
saveOneRecordPerDay
pluginId
task
samplingRate
farField
context
UUIDString
audioPackets
hasRecognizedAnything
interactionIdentifier
asrSelfComponentIdentifier
correctedText
recognizedText
setRecognizedText:
personalizedLMUsed
setPersonalizedLMUsed:
applicationName
setApplicationName:
date
setDate:
timestamp
profile
setProfile:
userData
setUserData:
originalAudioFileURL
setOriginalAudioFileURL:
_collectedAudioDurationMS
_audioExceededMaxDuration
_farField
_hasRecognizedAnything
_personalizedLMUsed
_pluginId
_task
_samplingRate
_context
_UUIDString
_audioPackets
_interactionIdentifier
_asrSelfComponentIdentifier
_correctedText
_recognizedText
_applicationName
_date
_timestamp
_profile
_userData
_originalAudioFileURL
T@"NSString",R,C,N,V_pluginId
T@"NSString",R,C,N,V_task
TQ,R,N,V_samplingRate
TB,R,N,V_farField
T@"NSArray",R,C,N,V_context
T@"NSString",R,C,N,V_UUIDString
T@"NSMutableArray",R,C,N,V_audioPackets
TB,R,N,V_hasRecognizedAnything
T@"NSString",R,C,N,V_interactionIdentifier
T@"NSString",R,C,N,V_asrSelfComponentIdentifier
T@"NSString",C,N,V_correctedText
T@"NSArray",C,N,V_recognizedText
TB,N,V_personalizedLMUsed
T@"NSString",C,N,V_applicationName
T@"NSString",C,N,V_date
Td,R,N,V_timestamp
T@"NSData",&,N,V_profile
T@"CESRUserData",&,N,V_userData
T@"NSURL",C,N,V_originalAudioFileURL
categoryToLimitHintMap
supportedCategories
categoryToFieldTypeMap
shouldOverrideDeferralForCategory:updateMode:
getSpeechLocaleForLocale:
deleteProfileAtDirectory:locale:userId:error:
deleteLegacyProfiles
profileDirPathFromBasePath:language:userId:
profileFilePathFromBasePath:language:userId:
CESRErrorForXPCError:
initWithDirectory:locale:userId:dataProtectionClass:
_newConnection
_setProfileConfigWithLanguage:profileDir:userId:dataProtectionClass:
getVersionForCategory:error:
beginWithCategoriesAndVersions:bundleId:error:
addVocabularyItem:isBoosted:error:
addVocabularyItem:error:
_flushItemsWithError:
cancelCategoriesWithError:
finishAndSaveProfile:error:
getGlobalItemsMemoryLimitInBytes
directory
locale
userId
dataProtectionClass
_connection
_serializedItems
_isBoosted
_summedCommittedItemsMemoryInBytes
_uncommittedItemsMemoryInBytes
_directory
_locale
_userId
_dataProtectionClass
T@"NSURL",R,N,V_directory
T@"NSLocale",R,N,V_locale
T@"NSString",R,N,V_userId
Tq,R,N,V_dataProtectionClass
setIsBoosted:
isBoosted
_vocabularyWordCategories
_initWithLanguage:
dictionaryRepresentation
initWithItems:language:
populateUserDataFromItems:
_handleItems:forKVFieldTypes:withCategory:
_handleContacts:
_handleKeyboardLMDynamicVocabularyItems:
_handleVocabularyWords:template:
contactWordsWithFrequency
setContactWordsWithFrequency:
vocabularyWords
setVocabularyWords:
appNames
setAppNames:
interactionSenderDisplayNames
setInteractionSenderDisplayNames:
searchEventValues
setSearchEventValues:
locationOfInterestNames
setLocationOfInterestNames:
spatialLocationOfInterestNames
setSpatialLocationOfInterestNames:
eventTitles
setEventTitles:
eventLocationNames
setEventLocationNames:
keyboardLMDynamicVocabularyItems
setKeyboardLMDynamicVocabularyItems:
pexNamedEntityNames
setPexNamedEntityNames:
corrections
setCorrections:
_contactWordsWithFrequency
_vocabularyWords
_appNames
_interactionSenderDisplayNames
_searchEventValues
_locationOfInterestNames
_spatialLocationOfInterestNames
_eventTitles
_eventLocationNames
_keyboardLMDynamicVocabularyItems
_pexNamedEntityNames
_corrections
T@"NSArray",C,N,V_contactWordsWithFrequency
T@"NSDictionary",C,N,V_vocabularyWords
T@"NSArray",C,N,V_appNames
T@"NSDictionary",C,N,V_interactionSenderDisplayNames
T@"NSDictionary",C,N,V_searchEventValues
T@"NSArray",C,N,V_locationOfInterestNames
T@"NSArray",C,N,V_spatialLocationOfInterestNames
T@"NSArray",C,N,V_eventTitles
T@"NSArray",C,N,V_eventLocationNames
T@"NSDictionary",C,N,V_keyboardLMDynamicVocabularyItems
T@"NSArray",C,N,V_pexNamedEntityNames
T@"NSArray",C,N,V_corrections
T@"NSDictionary",R,N
initWithComponents:frequency:
components
frequency
_frequency
_components
T@"NSDictionary",R,C,N,V_components
Ti,R,N,V_frequency
initWithTemplateName:tagName:
templateName
tagName
_templateName
_tagName
T@"NSString",R,C,N,V_templateName
T@"NSString",R,C,N,V_tagName
initWithConfiguration:taskName:applicationName:
metrics
containsEntity
fetchNamedEntitiesWithTimeInterval:
contextualData
taskName
_contextualData
_taskName
T@"NSString",R,N,V_applicationName
T@"NSString",R,N,V_taskName
T@"_EARContextualData",R,N,V_contextualData
formatWords:task:autoPunctuate:
initWithAssetConfig:
formatSpeechTokensWithAutoPunctuation:
_formatter
_assetConfig
resetCacheAndCompileAllAssetsWithCompletion:
preheatSpeechRecognitionWithLanguage:modelOverrideURL:
preheatSpeechRecognitionWithAssetConfig:preheatSource:modelOverrideURL:
startRequestActivityWithCompletion:
startSpeechRecognitionWithParameters:didStartHandlerWithInfo:
startSpeechRecognitionWithParameters:didStartHandler:
finishAudio
createSpeechProfileWithLanguage:modelOverridePath:JSONData:completion:
updateSpeechProfileWithLanguage:modelOverridePath:existingProfile:existingAssetPath:completion:
getOfflineAssetStatusIgnoringCache:assetType:withCompletion:
getOfflineAssetStatusIgnoringCache:assetType:withDetailedStatus:withCompletion:
getOfflineDictationStatusIgnoringCache:withCompletion:
fetchAssetsForLanguage:completion:
fetchAssetsForAssetConfig:completion:
fetchModelPropertiesForAssetConfig:completion:
runAdaptationRecipeEvaluation:recordData:attachments:completion:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
readProfileAndUserDataWithLanguage:allowOverride:completion:
purgeInstalledAssetsExceptLanguages:completion:
purgeInstalledAssetsExceptLanguages:assetType:completion:
writeDESRecord
startMissingAssetDownload
sendSpeechCorrectionInfo:interactionIdentifier:
invalidatePersonalizedLM
removePersonalizedLMForFidesOnly:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
deleteAllDESRecordsForDictationPersonalizationWithCompletion:
invalidateUaapLm
pauseRecognition
resumeRecognitionWithPrefixText:postfixText:selectedText:
speechServiceDidSelectRecognitionModelWithModelProperties:
speechServiceDidRecognizeTokens:
speechServiceDidProcessAudioDuration:
speechServiceDidRecognizeRawEagerRecognitionCandidate:
speechServiceDidRecognizePackage:
speechServiceDidFinishRecognitionWithStatistics:error:
speechServiceDidProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechServiceDidProduceLoggablePackage:
speechServiceDidRecognizeTokens:withMetadata:
speechServiceDidRecognizePackage:withMetadata:
speechServiceDidRecognizeFinalResultCandidatePackage:
initWithAsrLocale:
matches:
asrLocale
_asrLocale
T@"NSString",R,C,N,V_asrLocale
initWithRuleDimension:samplingRate:numDimension:
isMatchedSamplingDimension:
ruleDimension
numDimension
_ruleDimension
_numDimension
T@"CESRSamplingDimension",R,C,N,V_ruleDimension
T@"NSNumber",R,C,N,V_samplingRate
Tq,R,N,V_numDimension
initWithConfigDictionary:
initWithConfigPath:
getSamplingRateFromDimension:
samplingPolicies
_samplingPolicies
T@"NSArray",R,C,N,V_samplingPolicies
ttsPronunciationsType
hasOrthography
hasLanguage
hasApgId
hasTtsVersion
setTokenOffset:
setHasTokenOffset:
hasTokenOffset
clearTtsPronunciations
addTtsPronunciations:
ttsPronunciationsCount
ttsPronunciationsAtIndex:
hasAsrPronunciationData
readFrom:
writeTo:
copyTo:
mergeFrom:
orthography
setOrthography:
setLanguage:
apgId
setApgId:
ttsVersion
setTtsVersion:
tokenOffset
ttsPronunciations
setTtsPronunciations:
asrPronunciationData
setAsrPronunciationData:
_apgId
_asrPronunciationData
_orthography
_tokenOffset
_ttsPronunciations
_ttsVersion
_has
TB,R,N
T@"NSString",&,N,V_orthography
T@"NSString",&,N,V_language
T@"NSString",&,N,V_apgId
T@"NSString",&,N,V_ttsVersion
TB,N
Ti,N,V_tokenOffset
T@"NSMutableArray",&,N,V_ttsPronunciations
T@"NSData",&,N,V_asrPronunciationData
initWithLanguage:requestIdentifier:dictationUIInteractionIdentifier:task:loggingContext:applicationName:profile:overrides:modelOverrideURL:originalAudioFileURL:codec:narrowband:detectUtterances:censorSpeech:farField:secureOfflineOnly:shouldStoreAudioOnDevice:continuousListening:shouldHandleCapitalization:isSpeechAPIRequest:maximumRecognitionDuration:endpointStart:inputOrigin:location:jitGrammar:deliverEagerPackage:disableDeliveringAsrFeatures:enableEmojiRecognition:enableAutoPunctuation:enableVoiceCommands:sharedUserInfos:prefixText:postfixText:selectedText:powerContext:
requestIdentifier
dictationUIInteractionIdentifier
loggingContext
overrides
modelOverrideURL
codec
narrowband
detectUtterances
censorSpeech
secureOfflineOnly
shouldStoreAudioOnDevice
continuousListening
shouldHandleCapitalization
isSpeechAPIRequest
maximumRecognitionDuration
endpointStart
inputOrigin
location
jitGrammar
deliverEagerPackage
disableDeliveringAsrFeatures
enableEmojiRecognition
enableAutoPunctuation
enableVoiceCommands
sharedUserInfos
prefixText
postfixText
selectedText
powerContext
_narrowband
_detectUtterances
_censorSpeech
_secureOfflineOnly
_shouldStoreAudioOnDevice
_continuousListening
_shouldHandleCapitalization
_isSpeechAPIRequest
_deliverEagerPackage
_disableDeliveringAsrFeatures
_enableEmojiRecognition
_enableAutoPunctuation
_enableVoiceCommands
_requestIdentifier
_dictationUIInteractionIdentifier
_loggingContext
_overrides
_modelOverrideURL
_codec
_maximumRecognitionDuration
_endpointStart
_inputOrigin
_location
_jitGrammar
_sharedUserInfos
_prefixText
_postfixText
_selectedText
_powerContext
T@"NSString",R,C,N,V_requestIdentifier
T@"NSString",R,C,N,V_dictationUIInteractionIdentifier
T@"NSArray",R,C,N,V_loggingContext
T@"NSString",R,C,N,V_applicationName
T@"NSData",R,C,N,V_profile
T@"NSDictionary",R,C,N,V_overrides
T@"NSURL",R,C,N,V_modelOverrideURL
T@"NSURL",R,C,N,V_originalAudioFileURL
T@"NSString",R,C,N,V_codec
TB,R,N,V_narrowband
TB,R,N,V_detectUtterances
TB,R,N,V_censorSpeech
TB,R,N,V_secureOfflineOnly
TB,R,N,V_shouldStoreAudioOnDevice
TB,R,N,V_continuousListening
TB,R,N,V_shouldHandleCapitalization
TB,R,N,V_isSpeechAPIRequest
Td,R,N,V_maximumRecognitionDuration
Td,R,N,V_endpointStart
T@"NSString",R,C,N,V_inputOrigin
T@"CLLocation",R,C,N,V_location
T@"NSArray",R,C,N,V_jitGrammar
TB,R,N,V_deliverEagerPackage
TB,R,N,V_disableDeliveringAsrFeatures
TB,R,N,V_enableEmojiRecognition
TB,R,N,V_enableAutoPunctuation
TB,R,N,V_enableVoiceCommands
T@"NSArray",R,C,N,V_sharedUserInfos
T@"NSString",R,C,N,V_prefixText
T@"NSString",R,C,N,V_postfixText
T@"NSString",R,C,N,V_selectedText
T@"AFPowerContextPolicy",R,C,N,V_powerContext
setRequestIdentifier:
setDictationUIInteractionIdentifier:
setTask:
setLoggingContext:
setOverrides:
setModelOverrideURL:
setCodec:
setNarrowband:
setDetectUtterances:
setCensorSpeech:
setFarField:
setSecureOfflineOnly:
setShouldStoreAudioOnDevice:
setContinuousListening:
setShouldHandleCapitalization:
setIsSpeechAPIRequest:
setMaximumRecognitionDuration:
setEndpointStart:
setInputOrigin:
setLocation:
setJitGrammar:
setDeliverEagerPackage:
setDisableDeliveringAsrFeatures:
setEnableEmojiRecognition:
setEnableAutoPunctuation:
setEnableVoiceCommands:
setSharedUserInfos:
setPrefixText:
setPostfixText:
setSelectedText:
setPowerContext:
initWithAudioSamplingConfigDict:
loadConfigs
audioSamplingConfigDict
_createConfigFromProductType:
shouldSampleFromConfigForProductType:language:
_audioSamplingConfigDict
hasCorrectedText
hasPronunciationData
setSpellingCorrectionsCount:
setHasSpellingCorrectionsCount:
hasSpellingCorrectionsCount
setTap2editCorrectionsCount:
setHasTap2editCorrectionsCount:
hasTap2editCorrectionsCount
setAlternativesCorrectionsCount:
setHasAlternativesCorrectionsCount:
hasAlternativesCorrectionsCount
pronunciationData
setPronunciationData:
spellingCorrectionsCount
tap2editCorrectionsCount
alternativesCorrectionsCount
_alternativesCorrectionsCount
_pronunciationData
_spellingCorrectionsCount
_tap2editCorrectionsCount
T@"NSString",&,N,V_correctedText
T@"CESRCorrectionPronunciation",&,N,V_pronunciationData
TI,N,V_spellingCorrectionsCount
TI,N,V_tap2editCorrectionsCount
TI,N,V_alternativesCorrectionsCount
localSpeechRecognizer:didSelectRecognitionModelWithModelProperties:
localSpeechRecognizer:didRecognizeTokens:withMetadata:
localSpeechRecognizer:didRecognizeFinalResultCandidatePackage:
localSpeechRecognizer:didRecognizePackage:withMetadata:
localSpeechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
localSpeechRecognizer:didProduceLoggablePackage:
resetCacheAndCompileAllAssets
speechProfileDataLastModifiedDataForLanguage:
profilePathForLanguage:errorOut:
dictionaryWithContentsProfilePathForLanguage:errorOut:
purgeInstalledAssetsExceptLanguages:error:
offlineDictationStatusIgnoringCache:error:
updateSpeechProfileWithLanguage:modelOverridePath:completion:
getOfflineDictationStatusWithCompletion:
modelPropertiesForAssetConfig:error:
resetDESWithCompletion:
fetchUserDataForLanguage:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
invalidate
removePersonalizedLMForFidesOnly:
deleteAllDESRecordsForDictationPersonalization
instanceUUID
invalidateUaapLM
initWithDelegate:instanceUUID:
_service
_serviceWithFunctionName:errorHandler:
_synchronousServiceWithErrorHandler:
delegate
_recognitionActive
_esConnection
_instanceUUID
_currentLanguage
_recognitionError
_preheatedProfileAssetPath
_preheatedProfile
_delegate
T@"<CoreEmbeddedSpeechRecognizerDelegate>",R,W,N,V_delegate
i16@0:8
v20@0:8i16
@16@0:8
v24@0:8@16
v16@0:8
@"NSString"
B16@0:8
Q24@0:8@16
@24@0:8Q16
@40@0:8Q16@24@32
@32@0:8Q16@24
B32@0:8@16Q24
@32@0:8@16Q24
@36@0:8Q16B24^@28
@24@0:8@16
@32@0:8@16@24
@36@0:8@16@24B32
v24@0:8Q16
v48@0:8Q16@24@?32@?40
v52@0:8Q16@24B32@?36@?44
v56@0:8Q16@24B32B36@?40@?48
v40@0:8@16@?24@?32
B40@0:8@16Q24^@32
B48@0:8Q16@24@32^@40
v32@0:8@16Q24
@20@0:8i16
v68@0:8Q16@24@32@40B48@?52@?60
B48@0:8@16@24@32^@40
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
@"NSObject<OS_dispatch_source>"
@"NSMutableSet"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
Vv56@0:8@16@24@32q40@?48
Vv32@0:8@16@?24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv28@0:8B16@?20
Vv56@0:8@"NSString"16@"NSString"24@"NSString"32q40@?<v@?B@"NSError">48
Vv32@0:8@"NSString"16@?<v@?q@"NSError">24
Vv40@0:8@"NSDictionary"16@"NSString"24@?<v@?B@"NSError">32
Vv40@0:8@"NSArray"16@"NSArray"24@?<v@?B@"NSError">32
Vv24@0:8@?<v@?B@"NSError">16
Vv28@0:8B16@?<v@?B@"NSError">20
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
@40@0:8@16@24@32
v24@0:8@"NSString"16
@"CESRModelProperties"
{_mutationFlags="isDirty"b1"hasModelVersion"b1"hasModelType"b1"hasModelRoot"b1}
@24@0:8@?16
v20@0:8B16
v24@0:8q16
q16@0:8
@"NSDate"
@184@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132d136d144@152@160@168B176B180
@188@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184
@204@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184@188B196B200
@208@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184@188B196B200B204
q24@0:8@16
@28@0:8@16B24
@32@0:8@16d24
@36@0:8@16d24B32
v32@0:8@16@24
B32@0:8Q16Q24
B24@0:8Q16
B20@0:8f16
@72@0:8@16@24@32B40B44@48@56@64
@80@0:8@16@24@32B40B44@48@56@64Q72
v32@0:8@16@?24
d16@0:8
@"NSArray"
@"NSMutableArray"
@"NSData"
@"CESRUserData"
@"NSURL"
@48@0:8@16@24@32q40
B48@0:8@16@24@32q40
q32@0:8@16^@24
B40@0:8@16@24^@32
B36@0:8@16B24^@28
B32@0:8@16^@24
B24@0:8^@16
B28@0:8B16^@20
@"NSXPCConnection"
@"NSLocale"
@"NSDictionary"
@28@0:8@16i24
v24@0:8d16
@"_EARContextualData"
@"_EARFormatter"
@"CESRAssetConfig"
Vv32@0:8@16@24
Vv40@0:8@16@24@32
Vv24@0:8@16
Vv48@0:8@16@24@32@?40
Vv56@0:8@16@24@32@40@?48
Vv36@0:8B16Q20@?28
Vv40@0:8B16Q20B28@?32
Vv72@0:8@16@24@32Q40B48B52@56@?64
Vv36@0:8@16B24@?28
Vv40@0:8@16Q24@?32
Vv32@0:8@16Q24
Vv76@0:8@16@24@32@40@48@56B64@?68
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@"NSURL"24
Vv40@0:8@"CESRAssetConfig"16@"NSString"24@"NSURL"32
Vv24@0:8@?<v@?>16
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
Vv24@0:8@"NSData"16
Vv48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
Vv56@0:8@"NSString"16@"NSString"24@"NSData"32@"NSString"40@?<v@?@"NSData"@"NSString"@"NSError">48
Vv36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
Vv40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
Vv28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
Vv32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
Vv32@0:8@"CESRAssetConfig"16@?<v@?@"CESRModelProperties"@"NSError">24
Vv48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSData"@"NSError">40
Vv72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
Vv36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
Vv32@0:8@"NSSet"16@?<v@?@"NSNumber"@"NSError">24
Vv40@0:8@"NSSet"16Q24@?<v@?B@"NSError">32
Vv32@0:8@"NSSet"16Q24
Vv32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
Vv28@0:8B16@?<v@?>20
Vv76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
Vv40@0:8@"NSString"16@"NSString"24@"NSString"32
Vv24@0:8d16
Vv64@0:8q16q24d32@40d48q56
Vv24@0:8@"CESRModelProperties"16
Vv24@0:8@"NSArray"16
Vv24@0:8@"AFSpeechRecognition"16
Vv24@0:8@"AFSpeechPackage"16
Vv32@0:8@"NSDictionary"16@"NSError"24
Vv64@0:8q16q24d32@"NSArray"40d48q56
Vv32@0:8@"NSArray"16@"AFSpeechInfoPackage"24
Vv32@0:8@"AFSpeechPackage"16@"AFSpeechInfoPackage"24
@40@0:8@16@24q32
@"CESRSamplingDimension"
@"NSNumber"
{?="tokenOffset"b1}
@240@0:8@16@24@32@40@48@56@64@72@80@88@96B104B108B112B116B120B124B128B132B136d140d148@156@164@172B180B184B188B192B196@200@208@216@224@232
@"CLLocation"
@"AFPowerContextPolicy"
v24@0:8@"NSArray"16
v24@0:8@"NSData"16
v24@0:8@"NSDictionary"16
v24@0:8@"NSURL"16
v24@0:8@"CLLocation"16
v24@0:8@"AFPowerContextPolicy"16
@"CESRSpeechParameters"
{_mutationFlags="isDirty"b1"hasLanguage"b1"hasRequestIdentifier"b1"hasDictationUIInteractionIdentifier"b1"hasTask"b1"hasLoggingContext"b1"hasApplicationName"b1"hasProfile"b1"hasOverrides"b1"hasModelOverrideURL"b1"hasOriginalAudioFileURL"b1"hasCodec"b1"hasNarrowband"b1"hasDetectUtterances"b1"hasCensorSpeech"b1"hasFarField"b1"hasSecureOfflineOnly"b1"hasShouldStoreAudioOnDevice"b1"hasContinuousListening"b1"hasShouldHandleCapitalization"b1"hasIsSpeechAPIRequest"b1"hasMaximumRecognitionDuration"b1"hasEndpointStart"b1"hasInputOrigin"b1"hasLocation"b1"hasJitGrammar"b1"hasDeliverEagerPackage"b1"hasDisableDeliveringAsrFeatures"b1"hasEnableEmojiRecognition"b1"hasEnableAutoPunctuation"b1"hasEnableVoiceCommands"b1"hasSharedUserInfos"b1"hasPrefixText"b1"hasPostfixText"b1"hasSelectedText"b1"hasPowerContext"b1}
@24@0:8q16
B32@0:8q16@24
v20@0:8I16
I16@0:8
@"CESRCorrectionPronunciation"
{?="alternativesCorrectionsCount"b1"spellingCorrectionsCount"b1"tap2editCorrectionsCount"b1}
@32@0:8@16^@24
@28@0:8B16^@20
v40@0:8@16@24@32
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
v36@0:8B16Q20@?28
v40@0:8B16Q20B28@?32
v24@0:8@?16
v28@0:8B16@?20
v72@0:8@16@24@32Q40B48B52@56@?64
v36@0:8@16B24@?28
v68@0:8@16@24@32@40@48B56@?60
v76@0:8@16@24@32@40@48@56B64@?68
^[16C]16@0:8
v32@0:8@"NSString"16@"NSURL"24
v40@0:8@"CESRAssetConfig"16@"NSString"24@"NSURL"32
v32@0:8@"CESRSpeechParameters"16@?<v@?@"NSString"@"NSString"@"NSError">24
v32@0:8@"CESRSpeechParameters"16@?<v@?@"CESRModelProperties"@"NSError">24
v48@0:8@"NSString"16@"NSString"24@"NSData"32@?<v@?@"NSData"@"NSError">40
v40@0:8@"NSString"16@"NSString"24@?<v@?@"NSError">32
v36@0:8B16Q20@?<v@?@"NSDictionary"@"NSError">28
v40@0:8B16Q20B28@?<v@?@"NSDictionary"@"NSError">32
v24@0:8@?<v@?@"NSDictionary"@"NSError">16
v28@0:8B16@?<v@?@"NSDictionary"@"NSError">20
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSError">24
v32@0:8@"CESRAssetConfig"16@?<v@?@"NSString"@"NSError">24
@"CESRModelProperties"32@0:8@"CESRAssetConfig"16^@24
v48@0:8@"NSDictionary"16@"NSData"24@"NSArray"32@?<v@?@"NSDictionary"@"NSError">40
v72@0:8@"NSDictionary"16@"NSDictionary"24@"NSString"32Q40B48B52@"NSSet"56@?<v@?@"NSDictionary"@"NSError">64
v36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSString">28
v24@0:8@?<v@?@"NSError">16
v32@0:8@"NSString"16@?<v@?@"NSError"@"NSData">24
v32@0:8@"AFSpeechCorrectionInfo"16@"NSString"24
v68@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSString"40@"NSString"48B56@?<v@?@"NSDictionary"@"NSError">60
v76@0:8@"NSDictionary"16@"NSString"24@"NSDictionary"32@"NSArray"40@"NSString"48@"NSString"56B64@?<v@?@"NSDictionary"@"NSError">68
v40@0:8@"NSString"16@"NSString"24@"NSString"32
@"NSDate"24@0:8@"NSString"16
@"NSNumber"32@0:8@"NSSet"16^@24
B40@0:8@"NSSet"16Q24^@32
v32@0:8@"NSSet"16Q24
@"NSString"32@0:8@"NSString"16^@24
@"NSDictionary"32@0:8@"NSString"16^@24
@"NSDictionary"28@0:8B16^@20
@32@0:8@16[16C]24
@32@0:8@16@?24
[16C]
@"NSError"
@"<CoreEmbeddedSpeechRecognizerDelegate>"
F>C:J
