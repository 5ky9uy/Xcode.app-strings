@(#)PROGRAM:MediaAnalysisServices  PROJECT:MediaAnalysis-1
<%@ %p, 
results: %@, 
error: %@>
QueryID
Location
ImageURL
ReferralURL
ImageType
FeatureIdentifier
queryID: %@, 
location: %@, 
imageURL: %@, 
referralURL: %@, 
imageType: %@, 
featureIdentifier: %@, 
Results
Error
com.apple.mediaanalysisd.service.public
TimeRangeStartValue
TimeRangeStartTimescale
TimeRangeStartFlags
TimeRangeStartEpoch
TimeRangeDurationValue
TimeRangeDurationTimescale
TimeRangeDurationFlags
TimeRangeDurationEpoch
ExecutionNanoseconds
TopLeft
TopRight
BottomLeft
BottomRight
Symbology
Payload
Descriptor
topLeft: (%0.2f, %0.2f), 
topRight: (%0.2f, %0.2f), 
bottomLeft: (%0.2f, %0.2f), 
bottomRight: (%0.2f, %0.2f), 
symbology: '%@', 
payload: %@, 
descriptor: %@>
Observations
observations: %@>
CIBarcodeDescriptor
Unable to find class %s
v8@?0
/System/Library/Frameworks/CoreImage.framework/CoreImage
/System/Library/Frameworks/CoreImage.framework/Contents/MacOS/CoreImage
VNBarcodeObservation
/System/Library/Frameworks/Vision.framework/Vision
/System/Library/Frameworks/Vision.framework/Contents/MacOS/Vision
Symbologies
symbologies: %@, 
EmbeddingType
AssetCreationDate
Data
Checksum
asset creation date: %@ 
embedding (type: %lu): 
checksum (SHA256+base64): %@>
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.client
Entitled
Not entitled
MADService.connectionQueue
CVPixelBuffer must be IOSurface-backed
v16@?0@"NSError"8
v24@?0@"NSArray"8@"NSError"16
Error allocating CVPixelBuffer
Error allocating CGContext
v20@?0i8@"NSError"12
Failed to create sandbox extension for %@
v16@?0Q8
Photos asset processing not available
Failed to transfer CGImage to IOSurface
v16@?0@"NSDictionary"8
Languages
MaximumCandidateCount
UsesLanguageDetection
languages: %@, 
maximumCandidateCount: %lu, 
usesLanguageDetection: %d, 
GatingResultItems
GatingPayload
UIScale
gatingResultItems: %@, 
gatingPayload: %@, 
uiScale: %@, 
StagedText
ConversationIdentifier
stagedText: %@, 
conversationIdentifier: %@, 
Domain
KnowledgeGraphID
Title
ThumbnailURL
ThumbnailAspectRatio
ShortDescription
DetailedDescription
WebURL
KnowledgeProperties
domain: '%@', 
knowledgeGraphID: '%@', 
title: '%@', 
thumbnailURL: '%@', 
thumbnailAspectRatio: %0.2f, 
shortDescription: '%@', 
detailedDescription: '%@', 
webURL: '%@', 
knowledgeProperties: %@
NormalizedBoundingBox
RegionAttributes
SearchSections
normalizedBoundingBox: %0.2fx%0.2f @ (%0.2f, %0.2f), 
regionAttributes: %@, 
searchSections: %@>
ResultItems
resultItems: %@>
SFResultSection
/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
/System/Library/PrivateFrameworks/SearchFoundation.framework/Contents/MacOS/SearchFoundation
observations: 
%s%@ transcript="%@"
VNDocumentObservation
com.apple.mediaanalysisservices
signpost
Label
GlyphName
HasFocalPoint
FocalPoint
domain: %@, 
label: %@, 
glyphName: %@, 
hasFocalPoint: %d, 
focalPoint: (%0.2f, %0.2f)>
Domains
domains: %@>
resultItems: %@, 
payload: %@>
IsSensitive
Attributes
isSensitive: %d,
attributes: %@>
softlink:r:path:/System/Library/Frameworks/CoreImage.framework/CoreImage
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
Process is %s
[MADService init] unavialable; please call [MADService service]
[MADService] Client XPC connection interrupted
[MADService] Client XPC connection invalidated
Request: %d Identifier: %@
MADService_performRequestsOnPixelBuffer
[MADService] Error connecting to analysis service
MADService_performRequestsOnImageURL
[MADService] Error connecting to background analysis service
MADService_performRequestsOnAsset
Request: %d cloudIdentifier: %@
MADService protocol not implemented; service in failed state
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
MADEmbeddingGenerationRequest
MADVIVisualSearchGatingRequest
MADRequest
NSSecureCoding
NSCoding
VCPMADServicePublicServerProtocol
MADServicePublic
MADResult
MADVIMachineReadableCodeDetectionResultItem
MADVIMachineReadableCodeDetectionResult
MADVIMachineReadableCodeDetectionRequest
MADEmbeddingGenerationResult
VCPMediaAnalysisServerProtocol
MADServicePrivate
MADServiceProxy
VCPMediaAnalysisClientProtocol
MADService
Photos
Performance
ProtocolDefaults
MADServiceProtocol
VIAnalytics
MADVIDocumentRecognitionRequest
MADVIVisualSearchRequest
MADImageSafetyClassificationRequest
MADVIVisualSearchRegionAttributes
MADVIVisualSearchResultItem
MADVIVisualSearchResult
MADVIDocumentRecognitionResult
MADVIVisualSearchGatingDomainInfo
MADVIVisualSearchGatingResultItem
MADVIVisualSearchGatingResult
MADImageSafetyClassificationResult
string
appendFormat:
results
error
supportsSecureCoding
description
initWithCoder:
decodeObjectOfClass:forKey:
encodeWithCoder:
encodeObject:forKey:
queryID
setQueryID:
location
setLocation:
imageURL
setImageURL:
referralURL
setReferralURL:
imageType
setImageType:
featureIdentifier
setFeatureIdentifier:
.cxx_destruct
_queryID
_location
_imageURL
_referralURL
_imageType
_featureIdentifier
T@"NSNumber",C,N,V_queryID
T@"CLLocation",C,N,V_location
T@"NSURL",C,N,V_imageURL
T@"NSURL",C,N,V_referralURL
T@"NSNumber",C,N,V_imageType
T@"NSString",C,N,V_featureIdentifier
init
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
TB,R
setResults:
setError:
_results
_error
T@"NSArray",R,N,V_results
T@"NSError",R,N,V_error
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
currentOutstandingTasksWithReply:
cancelRequest:
cancelAllRequests
startEntryPointWithQueryID:
endEntryPoint
serviceName
serverProtocol
allowedClasses
decodeInt64ForKey:
decodeInt32ForKey:
encodeInt64:forKey:
encodeInt32:forKey:
executionNanoseconds
setExecutionNanoseconds:
executionTimeInterval
timerange
_executionNanoseconds
_timerange
TQ,R
Td,R
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
decodePointForKey:
encodePoint:forKey:
initWithTopLeft:topRight:bottomLeft:bottomRight:symbology:payload:andDescriptor:
normalizedBoundingBox
topLeft
topRight
bottomLeft
bottomRight
symbology
payload
descriptor
_symbology
_payload
_descriptor
_topLeft
_topRight
_bottomLeft
_bottomRight
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_bottomRight
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T@"NSString",R,N,V_symbology
T@"NSString",R,N,V_payload
T@"CIBarcodeDescriptor",R,N,V_descriptor
array
countByEnumeratingWithState:objects:count:
payloadStringValue
barcodeDescriptor
addObject:
initWithObservations:
resultItems
observations
_observations
T@"NSArray",R,N
T@"NSArray",R,N,V_observations
initWithSymbologies:
copy
symbologies
_symbologies
T@"NSArray",R,N,V_symbologies
decodeIntegerForKey:
encodeInteger:forKey:
bytes
length
appendString:
dataWithBytes:length:
base64EncodedStringWithOptions:
initWithEmbeddingType:assetCreationDate:data:andChecksum:
embeddingType
assetCreationDate
data
checksum
_embeddingType
_assetCreationDate
_data
_checksum
TQ,R,N,V_embeddingType
T@"NSDate",R,&,N,V_assetCreationDate
T@"NSData",R,&,N,V_data
T@"NSData",R,&,N,V_checksum
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestImageProcessing:forAssetWithLocalIdentifier:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
queryPerformanceMeasurementsWithReply:
resetPerformanceMeasurements
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
cancelBackgroundActivityWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
configureServerInterface:
setClasses:forSelector:argumentIndex:ofReply:
reportProgress:forRequest:
initWithService:
_service
isEntitled
initInternal
invalidate
dealloc
initWithMachServiceName:options:
setExportedObject:
interfaceWithProtocol:
setExportedInterface:
setRemoteObjectInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
stringWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
connection
remoteObjectProxyWithErrorHandler:
count
objectAtIndexedSubscript:
performRequests:onPixelBuffer:withOrientation:andIdentifier:completionHandler:
pixelBuffer
extent
colorSpace
context
render:toCVPixelBuffer:
path
UTF8String
stringWithUTF8String:
sandboxExtensionForURL:error:
performRequests:onImageURL:withIdentifier:completionHandler:
synchronousRemoteObjectProxyWithErrorHandler:
service
renderCGImage:toCVPixelBuffer:
performRequests:onCGImage:withOrientation:andIdentifier:completionHandler:
performRequests:onCIImage:withOrientation:andIdentifier:completionHandler:
performRequests:onPixelBuffer:withOrientation:completionHandler:
performRequests:onImageURL:completionHandler:
cancelRequestID:
currentOutstandingTasks
_connectionQueue
_connection
_requestID
_performRequests:onIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onAssetWithLocalIdentifier:fromPhotoLibraryWithURL:completionHandler:
performRequests:onPixelBuffer:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onCGImage:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onAssetWithCloudIdentifier:completionHandler:
queryPerformanceMeasurements
T@"NSString",R,N
T@"Protocol",R,N
T@"NSSet",R,N
initWithLanguages:
decodeBoolForKey:
encodeBool:forKey:
languages
setLanguages:
maximumCandidateCount
setMaximumCandidateCount:
usesLanguageDetection
setUsesLanguageDetection:
_usesLanguageDetection
_languages
_maximumCandidateCount
T@"NSArray",C,N,V_languages
TQ,N,V_maximumCandidateCount
TB,N,V_usesLanguageDetection
initWithGatingResultItems:andPayload:
gatingResultItems
gatingPayload
uiScale
setUiScale:
_gatingResultItems
_gatingPayload
_uiScale
T@"NSData",R,N
T@"NSNumber",C,N,V_uiScale
stagedText
setStagedText:
conversationIdentifier
setConversationIdentifier:
_stagedText
_conversationIdentifier
T@"NSString",C,N,V_stagedText
T@"NSString",C,N,V_conversationIdentifier
decodeFloatForKey:
encodeFloat:forKey:
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
domain
knowledgeGraphID
title
thumbnailURL
thumbnailAspectRatio
shortDescription
detailedDescription
webURL
knowledgeProperties
_thumbnailAspectRatio
_domain
_knowledgeGraphID
_title
_thumbnailURL
_shortDescription
_detailedDescription
_webURL
_knowledgeProperties
T@"NSString",R,N,V_domain
T@"NSString",R,N,V_knowledgeGraphID
T@"NSString",R,N,V_title
T@"NSURL",R,N,V_thumbnailURL
Tf,R,N,V_thumbnailAspectRatio
T@"NSString",R,N,V_shortDescription
T@"NSString",R,N,V_detailedDescription
T@"NSURL",R,N,V_webURL
T@"NSDictionary",R,N,V_knowledgeProperties
decodeRectForKey:
encodeRect:forKey:
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
regionAttributes
searchSections
_regionAttributes
_searchSections
_normalizedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_normalizedBoundingBox
T@"NSArray",R,N,V_regionAttributes
T@"NSArray",R,N,V_searchSections
initWithResultItems:
_resultItems
T@"NSArray",R,N,V_resultItems
getTranscript
newlineCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
initWithDomain:label:glyphName:hasFocalPoint:andFocalPoint:
label
glyphName
hasFocalPoint
focalPoint
_hasFocalPoint
_label
_glyphName
_focalPoint
T@"NSString",R,N,V_label
T@"NSString",R,N,V_glyphName
TB,R,N,V_hasFocalPoint
T{CGPoint=dd},R,N,V_focalPoint
initWithNormalizedBoundingBox:andDomains:
domains
_domains
T@"NSArray",R,N,V_domains
initWithResultItems:andPayload:
passedGating
T@"NSData",R,N,V_payload
TB,R,N
initWithIsSensitive:andAttributes:
isSensitive
attributes
_isSensitive
_attributes
TB,R,N,V_isSensitive
T@"NSDictionary",R,N,V_attributes
B16@0:8
@16@0:8
@24@0:8@16
v24@0:8@16
v16@0:8
@"NSNumber"
@"CLLocation"
@"NSURL"
@"NSString"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"NSArray"
@"NSError"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v24@0:8@?16
v20@0:8i16
v24@0:8Q16
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v24@0:8@?<v@?Q>16
Q16@0:8
d16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@104@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64@80@88@96
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
{CGPoint=dd}16@0:8
@"CIBarcodeDescriptor"
{CGPoint="x"d"y"d}
@48@0:8Q16@24@32@40
@"NSDate"
@"NSData"
v32@0:8@16@?24
v52@0:8@16@24@32i40@?44
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v60@0:8i16@20@28Q36@44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v52@0:8@"NSArray"16@"NSString"24@"NSURL"32i40@?<v@?@"NSArray"@"NSError">44
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
@"MADService"
i52@0:8@16^{__CVBuffer=}24I32@36@?44
i32@0:8^{CGImage=}16^^{__CVBuffer}24
i52@0:8@16^{CGImage=}24I32@36@?44
i52@0:8@16@24I32@36@?44
i44@0:8@16^{__CVBuffer=}24I32@?36
@32@0:8@16^@24
i48@0:8@16@24@32@?40
i40@0:8@16@24@?32
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i60@0:8@16@24I32@36@44@?52
i60@0:8@16^{__CVBuffer=}24I32@36@44@?52
i60@0:8@16^{CGImage=}24I32@36@44@?52
@"NSString"16@0:8
@"Protocol"16@0:8
@"NSSet"16@0:8
v20@0:8B16
@32@0:8@16@24
@84@0:8@16@24@32@40f48@52@60@68@76
f16@0:8
@"NSDictionary"
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@60@0:8@16@24@32B40{CGPoint=dd}44
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@28@0:8B16@20
