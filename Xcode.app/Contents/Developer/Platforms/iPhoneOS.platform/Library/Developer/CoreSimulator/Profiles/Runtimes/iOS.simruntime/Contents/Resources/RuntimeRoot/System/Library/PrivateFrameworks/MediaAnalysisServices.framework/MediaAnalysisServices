@(#)PROGRAM:MediaAnalysisServices  PROJECT:MediaAnalysis-1
QueryTerm
HintDomain
SurroundingText
NormalizedBoundingBoxes
QueryID
UIScale
<%@ %p, 
queryTerm: %@, 
hintDomain: %@, 
surroundingText: %@, 
normalizedBoundingBoxes: %@, 
queryID: %@, 
uiScale: %@, 
results: %@, 
error: %@>
BoundingBox
Confidence
PersonIdentifier
PersonName
person-identifier: %@, 
person-name: %@, 
bounding-box: %@, 
confidence: %.*f>
ResultItems
result items: %@>
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
SearchSections
searchSections:
<results:[
(title: %@)
maxInitiallyVisibleResults:%lu 
isInitiallyHidden:%@ 
identifier:%@ 
bundleIdentifier:%@ 
title:%@ 
moreText:%@ 
button:%@ 
rankingScore:%lf>
SFResultSection
Unable to find class %s
v8@?0
com.apple.argos.domain_key.art
com.apple.argos.domain_key.media
com.apple.argos.domain_key.packagedProducts
ARKitThirdParty
Location
ImageURL
ReferralURL
ImageType
Domains
FeatureIdentifier
location: %@, 
imageURL: <redacted>, 
referralURL: <redacted>, 
imageType: %@, 
domains: %@, 
featureIdentifier: %@, 
Results
Error
com.apple.mediaanalysisd.service.public
TimeRangeStartValue
TimeRangeStartTimescale
TimeRangeStartFlags
TimeRangeStartEpoch
TimeRangeDurationValue
TimeRangeDurationTimescale
TimeRangeDurationFlags
TimeRangeDurationEpoch
ExecutionNanoseconds
TopLeft
TopRight
BottomLeft
BottomRight
Symbology
Payload
Descriptor
topLeft: (%0.2f, %0.2f), 
topRight: (%0.2f, %0.2f), 
bottomLeft: (%0.2f, %0.2f), 
bottomRight: (%0.2f, %0.2f), 
symbology: '%@', 
payload: %@, 
descriptor: %@>
Observations
observations: %@>
CIBarcodeDescriptor
VNBarcodeObservation
ReportIdentifier
reportIdentifier: %@, 
Symbologies
symbologies: %@, 
EmbeddingType
AssetCreationDate
Data
Checksum
Thumbnail
asset creation date: %@ 
embedding (type: %lu): 
checksum (SHA256+base64): %@ 
thumbnail: %lu Bytes>
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.client
Entitled
Not entitled
MADService.connectionQueue
CVPixelBuffer must be IOSurface-backed
v16@?0@"NSError"8
v24@?0@"NSArray"8@"NSError"16
Error allocating CVPixelBuffer
Error allocating CGContext
v20@?0i8@"NSError"12
Failed to create sandbox extension for %@
v16@?0Q8
Photos asset processing not available
Request: %d Identifier: (%lu)%@
Failed to transfer CGImage to IOSurface
v32@?0@"NSString"8@"NSArray"16^B24
v24@?0@"NSDictionary"8@"NSError"16
v16@?0@"NSDictionary"8
MinimumAspectRatio
MaximumAspectRatio
QuadratureTolerance
MinimumSize
MinimumConfidence
MaximumObservations
minimumAspectRatio: %0.2f, 
maximumAspectRatio: %0.2f, 
quadratureTolerance: %0.2f, 
minimumSize: %0.2f, 
minimumConfidence: %0.2f, 
maximumObservations: %lu, 
Languages
MaximumCandidateCount
UsesLanguageDetection
languages: %@, 
maximumCandidateCount: %lu, 
usesLanguageDetection: %d, 
StagedText
ConversationIdentifier
stagedText: %@, 
conversationIdentifier: %@, 
GatingResultItems
GatingPayload
CatalogIDs
DocumentObservations
gatingResultItems: %@, 
gatingPayload: %@, 
catalogIDs: %@, 
documentObservations: %@, 
VNDocumentObservation
FaceDetectorVisionRevision
AllowOnDemand
MaximumFaceCount
faceDetectorVisionRevision: %lu, 
allowOnDemand: %@, 
maximumFaceCount: %lu, 
ObjectIdentifier
ThumbnailURL
Metadata
objectIdentifier: '%@'
, imageURL: '%@'
, thumbnailURL: '%@'
, metadata: '%@'
Domain
KnowledgeGraphID
Title
ThumbnailAspectRatio
ShortDescription
DetailedDescription
WebURL
KnowledgeProperties
ThirdPartyObject
domain: '%@', 
knowledgeGraphID: '%@', 
title: '%@', 
thumbnailURL: '%@', 
thumbnailAspectRatio: %0.2f, 
shortDescription: '%@', 
detailedDescription: '%@', 
webURL: '%@', 
knowledgeProperties: %@
, thirdPartyObject: %@
NormalizedBoundingBox
RegionAttributes
normalizedBoundingBox: %0.2fx%0.2f @ (%0.2f, %0.2f), 
regionAttributes: %@, 
searchSections: %@>
UserFeedbackPayload
resultItems: %@ 
userFeedbackPayload: %@>
observations: 
%s%@ transcript="%@"
Surface
CropRect
surface: %@, 
cropRect: %0.2fx%0.2f @ (%0.2f, %0.2f), 
confidence: %0.2f>
com.apple.mediaanalysisservices
signpost
PerformInPlace
CropToFit
ReturnMask
performInPlace: %d, 
cropToFit: %d, 
returnMask: %d, 
Label
GlyphName
HasFocalPoint
FocalPoint
DisplayLabel
DisplayMessage
domain: %@, 
label: %@, 
glyphName: %@, 
hasFocalPoint: %d, 
focalPoint: (%0.2f, %0.2f), 
displayLabel: %@, 
displayMessage: %@>
domains: %@>
resultItems: %@, 
payload: %@>
VNRectangleObservation
IsSensitive
Attributes
isSensitive: %d,
attributes: %@>
softlink:r:path:/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
softlink:r:path:/System/Library/Frameworks/CoreImage.framework/CoreImage
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
[MADEmbeddingGenerationResult] Invalid Checksum data
Process is %s
[MADService init] unavialable; please call [MADService service]
[MADService] Client XPC connection interrupted
[MADService] Client XPC connection invalidated
Request: %d Identifier: %@
MADService_performRequestsOnPixelBuffer
[MADService] Error connecting to analysis service
MADService_performRequestsOnCGImage
MADService_performRequestsOnImageURL
MADService_performRequestsOnImageData
MADService_performRequestsOnImageDataSync
[MADService] Error connecting to analysis service (synchronous)
[MADService] Error during analysis service for RequestID %d (synchronous)
[MADService] Analysis returns for RequestID %d (synchronous)
[MADService] Error connecting to background analysis service
MADService_performRequestsOnAsset
MADService_performRequestsOnAssetSync
Request: %d cloudIdentifier: %@
[MADService RequestID %d]: %lu cloudIdentifiers
MADService protocol not implemented; service in failed state
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to create CVPixelBufferRef from IOSurface (%d)
Failed to create CGDataProviderRef for IOSurface
Failed to create CGImageRef from IOSurface
[GetBytePointer] Failed to lock IOSurface
[GetBytePointer] Invalid context (NULL)
[ReleaseBytePointer] Invalid context (NULL)
[ReleaseInfo] Invalid context (NULL)
MADVITextLookupRequest
MADEmbeddingGenerationRequest
MADPersonIdentificationResultItem
NSSecureCoding
NSCoding
MADPersonIdentificationResult
MADVITextLookupResult
MADVIVisualSearchGatingRequest
MADRequest
VCPMADServicePublicServerProtocol
MADServicePublic
MADResult
MADVIMachineReadableCodeDetectionResultItem
MADVIMachineReadableCodeDetectionResult
MADVIUserFeedbackRequest
MADVIMachineReadableCodeDetectionRequest
MADEmbeddingGenerationResult
VCPMediaAnalysisServerProtocol
MADServicePrivate
MADServiceProxy
VCPMediaAnalysisClientProtocol
MADService
Photos
Performance
ProtocolDefaults
MADServiceProtocol
VIAnalytics
MADVIRectangleDetectionRequest
MADVIDocumentRecognitionRequest
MADImageSafetyClassificationRequest
MADVIVisualSearchRequest
MADPersonIdentificationRequest
MADVIVisualSearchThirdPartyObject
MADVIVisualSearchRegionAttributes
MADVIVisualSearchResultItem
MADVIVisualSearchResult
MADVIDocumentRecognitionResult
MADVIRemoveBackgroundResult
MADVIRemoveBackgroundRequest
MADVIVisualSearchGatingDomainInfo
MADVIVisualSearchGatingResultItem
MADVIVisualSearchGatingResult
MADVIRectangleDetectionResult
MADVIUserFeedbackResult
MADImageSafetyClassificationResult
init
copy
initWithQueryTerm:domain:textContext:
initWithCoder:
decodeObjectOfClass:forKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
encodeWithCoder:
encodeObject:forKey:
string
appendFormat:
results
error
supportsSecureCoding
initWithQueryTerm:
description
hintDomain
setHintDomain:
surroundingText
setSurroundingText:
normalizedBoundingBoxes
setNormalizedBoundingBoxes:
queryTerm
queryID
setQueryID:
uiScale
setUiScale:
.cxx_destruct
_hintDomain
_surroundingText
_normalizedBoundingBoxes
_queryTerm
_queryID
_uiScale
T@"NSString",R,C,N,V_queryTerm
T@"NSNumber",C,N,V_queryID
T@"NSNumber",C,N,V_uiScale
T@"NSString",C,N,V_hintDomain
T@"NSString",C,N,V_surroundingText
T@"NSArray",C,N,V_normalizedBoundingBoxes
decodeRectForKey:
decodeFloatForKey:
encodeRect:forKey:
encodeFloat:forKey:
TB,R
initWithPersonIdentifier:personName:boundingBox:andConfidence:
personIdentifier
personName
boundingBox
confidence
_confidence
_personIdentifier
_personName
_boundingBox
T@"NSString",R,N,V_personIdentifier
T@"NSString",R,N,V_personName
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
Tf,R,N,V_confidence
initWithResultItems:
resultItems
_resultItems
T@"NSArray",R,N,V_resultItems
stringWithFormat:
count
objectAtIndexedSubscript:
title
text
maxInitiallyVisibleResults
isInitiallyHidden
identifier
bundleIdentifier
moreText
button
rankingScore
initWithSearchSections:
searchSections
_searchSections
T@"NSArray",R,N,V_searchSections
location
setLocation:
imageURL
setImageURL:
referralURL
setReferralURL:
imageType
setImageType:
domains
setDomains:
featureIdentifier
setFeatureIdentifier:
_location
_imageURL
_referralURL
_imageType
_domains
_featureIdentifier
T@"CLLocation",C,N,V_location
T@"NSURL",C,N,V_imageURL
T@"NSURL",C,N,V_referralURL
T@"NSNumber",C,N,V_imageType
T@"NSArray",C,N,V_domains
T@"NSString",C,N,V_featureIdentifier
setResults:
setError:
_results
_error
T@"NSArray",R,N,V_results
T@"NSError",R,N,V_error
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
currentOutstandingTasksWithReply:
cancelRequest:
cancelAllRequests
startEntryPointWithQueryID:
cacheHitWithQueryID:cachedResultQueryID:
endEntryPoint
serviceName
serverProtocol
allowedClasses
decodeInt64ForKey:
decodeInt32ForKey:
encodeInt64:forKey:
encodeInt32:forKey:
executionNanoseconds
setExecutionNanoseconds:
executionTimeInterval
timerange
_executionNanoseconds
_timerange
TQ,R
Td,R
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
decodePointForKey:
encodePoint:forKey:
initWithTopLeft:topRight:bottomLeft:bottomRight:symbology:payload:andDescriptor:
normalizedBoundingBox
topLeft
topRight
bottomLeft
bottomRight
symbology
payload
descriptor
_symbology
_payload
_descriptor
_topLeft
_topRight
_bottomLeft
_bottomRight
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_bottomRight
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T@"NSString",R,N,V_symbology
T@"NSString",R,N,V_payload
T@"CIBarcodeDescriptor",R,N,V_descriptor
array
countByEnumeratingWithState:objects:count:
payloadStringValue
barcodeDescriptor
addObject:
initWithObservations:
observations
_observations
T@"NSArray",R,N
T@"NSArray",R,N,V_observations
initWithPayload:andReportIdentifier:
reportIdentifier
_reportIdentifier
T@"NSData",R,N,V_payload
T@"NSString",R,N,V_reportIdentifier
initWithSymbologies:
symbologies
_symbologies
T@"NSArray",R,N,V_symbologies
decodeIntegerForKey:
length
encodeInteger:forKey:
bytes
appendString:
dataWithBytes:length:
base64EncodedStringWithOptions:
initWithEmbeddingType:assetCreationDate:data:checksum:andThumbnail:
embeddingType
assetCreationDate
data
checksum
thumbnail
_embeddingType
_assetCreationDate
_data
_checksum
_thumbnail
TQ,R,N,V_embeddingType
T@"NSDate",R,&,N,V_assetCreationDate
T@"NSData",R,&,N,V_data
T@"NSData",R,&,N,V_checksum
T@"NSData",R,&,N,V_thumbnail
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
queryPerformanceMeasurementsWithReply:
resetPerformanceMeasurements
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
cancelBackgroundActivityWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
configureServerInterface:
setClasses:forSelector:argumentIndex:ofReply:
reportProgress:forRequest:
initWithService:
_service
isEntitled
initInternal
invalidate
dealloc
initWithMachServiceName:options:
setExportedObject:
interfaceWithProtocol:
setExportedInterface:
setRemoteObjectInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
connection
remoteObjectProxyWithErrorHandler:
performRequests:onPixelBuffer:withOrientation:andIdentifier:completionHandler:
pixelBuffer
extent
colorSpace
context
render:toCVPixelBuffer:
path
UTF8String
stringWithUTF8String:
sandboxExtensionForURL:error:
performRequests:onImageURL:withIdentifier:completionHandler:
synchronousRemoteObjectProxyWithErrorHandler:
service
renderCGImage:toCVPixelBuffer:
performRequests:onCGImage:withOrientation:andIdentifier:completionHandler:
performRequests:onCIImage:withOrientation:andIdentifier:completionHandler:
performRequests:onPixelBuffer:withOrientation:completionHandler:
performRequests:onImageURL:completionHandler:
performRequests:onImageData:withUniformTypeIdentifier:andIdentifier:completionHandler:
performRequests:onImageData:withUniformTypeIdentifier:andIdentifier:error:
cancelRequestID:
currentOutstandingTasks
_connectionQueue
_connection
_requestID
performRequests:onAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:completionHandler:
performRequests:onAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:error:
_performRequests:onIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
objectForKeyedSubscript:
enumerateKeysAndObjectsUsingBlock:
performRequests:onAssetWithLocalIdentifier:fromPhotoLibraryWithURL:completionHandler:
performRequests:onAssetWithSyndicationIdentifier:error:
performRequests:onPixelBuffer:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onCGImage:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onAssetWithCloudIdentifier:completionHandler:
performRequestsWithCloudIdentifiers:completionHandler:
queryPerformanceMeasurements
T@"NSString",R,N
T@"Protocol",R,N
T@"NSSet",R,N
minimumAspectRatio
setMinimumAspectRatio:
maximumAspectRatio
setMaximumAspectRatio:
quadratureTolerance
setQuadratureTolerance:
minimumSize
setMinimumSize:
minimumConfidence
setMinimumConfidence:
maximumObservations
setMaximumObservations:
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_minimumConfidence
_maximumObservations
Tf,N,V_minimumAspectRatio
Tf,N,V_maximumAspectRatio
Tf,N,V_quadratureTolerance
Tf,N,V_minimumSize
Tf,N,V_minimumConfidence
TQ,N,V_maximumObservations
initWithLanguages:
decodeBoolForKey:
encodeBool:forKey:
languages
setLanguages:
maximumCandidateCount
setMaximumCandidateCount:
usesLanguageDetection
setUsesLanguageDetection:
_usesLanguageDetection
_languages
_maximumCandidateCount
T@"NSArray",C,N,V_languages
TQ,N,V_maximumCandidateCount
TB,N,V_usesLanguageDetection
stagedText
setStagedText:
conversationIdentifier
setConversationIdentifier:
_stagedText
_conversationIdentifier
T@"NSString",C,N,V_stagedText
T@"NSString",C,N,V_conversationIdentifier
initWithGatingResultItems:payload:documentObservations:
initWithGatingResultItems:andPayload:
gatingResultItems
gatingPayload
documentObservations
catalogIDs
setCatalogIDs:
_gatingResultItems
_gatingPayload
_documentObservations
_catalogIDs
T@"NSData",R,N
T@"NSArray",C,N,V_catalogIDs
faceDetectorVisionRevision
setFaceDetectorVisionRevision:
allowOnDemand
setAllowOnDemand:
maximumFaceCount
setMaximumFaceCount:
_allowOnDemand
_faceDetectorVisionRevision
_maximumFaceCount
TQ,N,V_faceDetectorVisionRevision
TB,N,V_allowOnDemand
TQ,N,V_maximumFaceCount
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
objectIdentifier
thumbnailURL
metadata
_objectIdentifier
_thumbnailURL
_metadata
T@"NSString",R,N,V_objectIdentifier
T@"NSString",R,N,V_imageURL
T@"NSString",R,N,V_thumbnailURL
T@"NSData",R,N,V_metadata
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
setThirdPartyObject:
domain
knowledgeGraphID
thumbnailAspectRatio
shortDescription
detailedDescription
webURL
knowledgeProperties
thirdPartyObject
_thumbnailAspectRatio
_domain
_knowledgeGraphID
_title
_shortDescription
_detailedDescription
_webURL
_knowledgeProperties
_thirdPartyObject
T@"MADVIVisualSearchThirdPartyObject",R,N,V_thirdPartyObject
T@"NSString",R,N,V_domain
T@"NSString",R,N,V_knowledgeGraphID
T@"NSString",R,N,V_title
T@"NSURL",R,N,V_thumbnailURL
Tf,R,N,V_thumbnailAspectRatio
T@"NSString",R,N,V_shortDescription
T@"NSString",R,N,V_detailedDescription
T@"NSURL",R,N,V_webURL
T@"NSDictionary",R,N,V_knowledgeProperties
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
regionAttributes
_regionAttributes
_normalizedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_normalizedBoundingBox
T@"NSArray",R,N,V_regionAttributes
initWithResultItems:andUserFeedbackPayload:
userFeedbackPayload
_userFeedbackPayload
T@"NSData",R,N,V_userFeedbackPayload
getTranscript
newlineCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
initWithSurface:cropRect:confidence:
pixelFormat
width
height
bytesPerRow
initWithSurface:
image
cropRect
.cxx_construct
_surface
_pixelBuffer
_image
_cropRect
T^{__CVBuffer=},R,N
T^{CGImage=},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_cropRect
performInPlace
setPerformInPlace:
cropToFit
setCropToFit:
returnMask
setReturnMask:
_performInPlace
_cropToFit
_returnMask
TB,N,V_performInPlace
TB,N,V_cropToFit
TB,N,V_returnMask
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
label
glyphName
hasFocalPoint
focalPoint
displayLabel
displayMessage
_hasFocalPoint
_label
_glyphName
_displayLabel
_displayMessage
_focalPoint
T@"NSString",R,N,V_label
T@"NSString",R,N,V_glyphName
TB,R,N,V_hasFocalPoint
T{CGPoint=dd},R,N,V_focalPoint
T@"NSString",R,N,V_displayLabel
T@"NSString",R,N,V_displayMessage
initWithNormalizedBoundingBox:andDomains:
T@"NSArray",R,N,V_domains
initWithResultItems:andPayload:
passedGating
TB,R,N
initWithIsSensitive:andAttributes:
isSensitive
attributes
_isSensitive
_attributes
TB,R,N,V_isSensitive
T@"NSDictionary",R,N,V_attributes
B16@0:8
@40@0:8@16@24@32
@24@0:8@16
v24@0:8@16
@16@0:8
v16@0:8
@"NSString"
@"NSArray"
@"NSNumber"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@68@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
f16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@"CLLocation"
@"NSURL"
@"NSError"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v24@0:8@?16
v20@0:8i16
v24@0:8Q16
v32@0:8Q16Q24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v24@0:8@?<v@?Q>16
Q16@0:8
d16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@104@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64@80@88@96
{CGPoint=dd}16@0:8
@"CIBarcodeDescriptor"
{CGPoint="x"d"y"d}
@32@0:8@16@24
@"NSData"
@56@0:8Q16@24@32@40@48
@"NSDate"
v32@0:8@16@?24
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
@"MADService"
i52@0:8@16^{__CVBuffer=}24I32@36@?44
i32@0:8^{CGImage=}16^^{__CVBuffer}24
i52@0:8@16^{CGImage=}24I32@36@?44
i52@0:8@16@24I32@36@?44
i44@0:8@16^{__CVBuffer=}24I32@?36
@32@0:8@16^@24
i48@0:8@16@24@32@?40
i40@0:8@16@24@?32
i56@0:8@16@24@32@40@?48
B56@0:8@16@24@32@40^@48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i56@0:8@16@24Q32@40@?48
B56@0:8@16@24Q32@40^@48
B40@0:8@16@24^@32
i60@0:8@16@24I32@36@44@?52
i60@0:8@16^{__CVBuffer=}24I32@36@44@?52
i60@0:8@16^{CGImage=}24I32@36@44@?52
i32@0:8@16@?24
@"NSString"16@0:8
@"Protocol"16@0:8
@"NSSet"16@0:8
v20@0:8f16
v20@0:8B16
@48@0:8@16@24@32@40
@84@0:8@16@24@32@40f48@52@60@68@76
@"NSDictionary"
@"MADVIVisualSearchThirdPartyObject"
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
@60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
^{__CVBuffer=}16@0:8
^{CGImage=}16@0:8
@"IOSurface"
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
{CF<CGImage *>="value_"^{CGImage}}
@76@0:8@16@24@32B40{CGPoint=dd}44@60@68
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@28@0:8B16@20
@(#)PROGRAM:MediaAnalysisServices  PROJECT:MediaAnalysis-1
QueryTerm
HintDomain
SurroundingText
NormalizedBoundingBoxes
QueryID
UIScale
<%@ %p, 
queryTerm: %@, 
hintDomain: %@, 
surroundingText: %@, 
normalizedBoundingBoxes: %@, 
queryID: %@, 
uiScale: %@, 
results: %@, 
error: %@>
BoundingBox
Confidence
PersonIdentifier
PersonName
person-identifier: %@, 
person-name: %@, 
bounding-box: %@, 
confidence: %.*f>
ResultItems
result items: %@>
{{x:%.*f, y:%.*f}, {width:%.*f, height:%.*f}} 
SearchSections
searchSections:
<results:[
(title: %@)
maxInitiallyVisibleResults:%lu 
isInitiallyHidden:%@ 
identifier:%@ 
bundleIdentifier:%@ 
title:%@ 
moreText:%@ 
button:%@ 
rankingScore:%lf>
SFResultSection
Unable to find class %s
v8@?0
com.apple.argos.domain_key.art
com.apple.argos.domain_key.media
com.apple.argos.domain_key.packagedProducts
ARKitThirdParty
Location
ImageURL
ReferralURL
ImageType
Domains
FeatureIdentifier
location: %@, 
imageURL: <redacted>, 
referralURL: <redacted>, 
imageType: %@, 
domains: %@, 
featureIdentifier: %@, 
Results
Error
com.apple.mediaanalysisd.service.public
TimeRangeStartValue
TimeRangeStartTimescale
TimeRangeStartFlags
TimeRangeStartEpoch
TimeRangeDurationValue
TimeRangeDurationTimescale
TimeRangeDurationFlags
TimeRangeDurationEpoch
ExecutionNanoseconds
TopLeft
TopRight
BottomLeft
BottomRight
Symbology
Payload
Descriptor
topLeft: (%0.2f, %0.2f), 
topRight: (%0.2f, %0.2f), 
bottomLeft: (%0.2f, %0.2f), 
bottomRight: (%0.2f, %0.2f), 
symbology: '%@', 
payload: %@, 
descriptor: %@>
Observations
observations: %@>
CIBarcodeDescriptor
VNBarcodeObservation
ReportIdentifier
reportIdentifier: %@, 
Symbologies
symbologies: %@, 
EmbeddingType
AssetCreationDate
Data
Checksum
Thumbnail
asset creation date: %@ 
embedding (type: %lu): 
checksum (SHA256+base64): %@ 
thumbnail: %lu Bytes>
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.client
Entitled
Not entitled
MADService.connectionQueue
CVPixelBuffer must be IOSurface-backed
v16@?0@"NSError"8
v24@?0@"NSArray"8@"NSError"16
Error allocating CVPixelBuffer
Error allocating CGContext
v20@?0i8@"NSError"12
Failed to create sandbox extension for %@
v16@?0Q8
Photos asset processing not available
Request: %d Identifier: (%lu)%@
Failed to transfer CGImage to IOSurface
v32@?0@"NSString"8@"NSArray"16^B24
v24@?0@"NSDictionary"8@"NSError"16
v16@?0@"NSDictionary"8
MinimumAspectRatio
MaximumAspectRatio
QuadratureTolerance
MinimumSize
MinimumConfidence
MaximumObservations
minimumAspectRatio: %0.2f, 
maximumAspectRatio: %0.2f, 
quadratureTolerance: %0.2f, 
minimumSize: %0.2f, 
minimumConfidence: %0.2f, 
maximumObservations: %lu, 
Languages
MaximumCandidateCount
UsesLanguageDetection
languages: %@, 
maximumCandidateCount: %lu, 
usesLanguageDetection: %d, 
StagedText
ConversationIdentifier
stagedText: %@, 
conversationIdentifier: %@, 
GatingResultItems
GatingPayload
CatalogIDs
DocumentObservations
gatingResultItems: %@, 
gatingPayload: %@, 
catalogIDs: %@, 
documentObservations: %@, 
VNDocumentObservation
FaceDetectorVisionRevision
AllowOnDemand
MaximumFaceCount
faceDetectorVisionRevision: %lu, 
allowOnDemand: %@, 
maximumFaceCount: %lu, 
ObjectIdentifier
ThumbnailURL
Metadata
objectIdentifier: '%@'
, imageURL: '%@'
, thumbnailURL: '%@'
, metadata: '%@'
Domain
KnowledgeGraphID
Title
ThumbnailAspectRatio
ShortDescription
DetailedDescription
WebURL
KnowledgeProperties
ThirdPartyObject
domain: '%@', 
knowledgeGraphID: '%@', 
title: '%@', 
thumbnailURL: '%@', 
thumbnailAspectRatio: %0.2f, 
shortDescription: '%@', 
detailedDescription: '%@', 
webURL: '%@', 
knowledgeProperties: %@
, thirdPartyObject: %@
NormalizedBoundingBox
RegionAttributes
normalizedBoundingBox: %0.2fx%0.2f @ (%0.2f, %0.2f), 
regionAttributes: %@, 
searchSections: %@>
UserFeedbackPayload
resultItems: %@ 
userFeedbackPayload: %@>
observations: 
%s%@ transcript="%@"
Surface
CropRect
surface: %@, 
cropRect: %0.2fx%0.2f @ (%0.2f, %0.2f), 
confidence: %0.2f>
com.apple.mediaanalysisservices
signpost
PerformInPlace
CropToFit
ReturnMask
performInPlace: %d, 
cropToFit: %d, 
returnMask: %d, 
Label
GlyphName
HasFocalPoint
FocalPoint
DisplayLabel
DisplayMessage
domain: %@, 
label: %@, 
glyphName: %@, 
hasFocalPoint: %d, 
focalPoint: (%0.2f, %0.2f), 
displayLabel: %@, 
displayMessage: %@>
domains: %@>
resultItems: %@, 
payload: %@>
VNRectangleObservation
IsSensitive
Attributes
isSensitive: %d,
attributes: %@>
softlink:r:path:/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
softlink:r:path:/System/Library/Frameworks/CoreImage.framework/CoreImage
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/SearchFoundation.framework/SearchFoundation
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
[MADEmbeddingGenerationResult] Invalid Checksum data
Process is %s
[MADService init] unavialable; please call [MADService service]
[MADService] Client XPC connection interrupted
[MADService] Client XPC connection invalidated
Request: %d Identifier: %@
MADService_performRequestsOnPixelBuffer
[MADService] Error connecting to analysis service
MADService_performRequestsOnCGImage
MADService_performRequestsOnImageURL
MADService_performRequestsOnImageData
MADService_performRequestsOnImageDataSync
[MADService] Error connecting to analysis service (synchronous)
[MADService] Error during analysis service for RequestID %d (synchronous)
[MADService] Analysis returns for RequestID %d (synchronous)
[MADService] Error connecting to background analysis service
MADService_performRequestsOnAsset
MADService_performRequestsOnAssetSync
Request: %d cloudIdentifier: %@
[MADService RequestID %d]: %lu cloudIdentifiers
MADService protocol not implemented; service in failed state
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Failed to create CVPixelBufferRef from IOSurface (%d)
Failed to create CGDataProviderRef for IOSurface
Failed to create CGImageRef from IOSurface
[GetBytePointer] Failed to lock IOSurface
[GetBytePointer] Invalid context (NULL)
[ReleaseBytePointer] Invalid context (NULL)
[ReleaseInfo] Invalid context (NULL)
MADVITextLookupRequest
MADEmbeddingGenerationRequest
MADPersonIdentificationResultItem
NSSecureCoding
NSCoding
MADPersonIdentificationResult
MADVITextLookupResult
MADVIVisualSearchGatingRequest
MADRequest
VCPMADServicePublicServerProtocol
MADServicePublic
MADResult
MADVIMachineReadableCodeDetectionResultItem
MADVIMachineReadableCodeDetectionResult
MADVIUserFeedbackRequest
MADVIMachineReadableCodeDetectionRequest
MADEmbeddingGenerationResult
VCPMediaAnalysisServerProtocol
MADServicePrivate
MADServiceProxy
VCPMediaAnalysisClientProtocol
MADService
Photos
Performance
ProtocolDefaults
MADServiceProtocol
VIAnalytics
MADVIRectangleDetectionRequest
MADVIDocumentRecognitionRequest
MADImageSafetyClassificationRequest
MADVIVisualSearchRequest
MADPersonIdentificationRequest
MADVIVisualSearchThirdPartyObject
MADVIVisualSearchRegionAttributes
MADVIVisualSearchResultItem
MADVIVisualSearchResult
MADVIDocumentRecognitionResult
MADVIRemoveBackgroundResult
MADVIRemoveBackgroundRequest
MADVIVisualSearchGatingDomainInfo
MADVIVisualSearchGatingResultItem
MADVIVisualSearchGatingResult
MADVIRectangleDetectionResult
MADVIUserFeedbackResult
MADImageSafetyClassificationResult
decodeIntegerForKey:
encodeInt64:forKey:
path
initWithMachServiceName:options:
setInvalidationHandler:
arrayWithObjects:count:
string
getTranscript
remoteObjectProxyWithErrorHandler:
text
length
objectForKeyedSubscript:
setInterruptionHandler:
encodeInt32:forKey:
decodeInt64ForKey:
width
decodeRectForKey:
encodeRect:forKey:
synchronousRemoteObjectProxyWithErrorHandler:
extent
rankingScore
countByEnumeratingWithState:objects:count:
isInitiallyHidden
componentsSeparatedByCharactersInSet:
setExportedObject:
bytesPerRow
decodeInt32ForKey:
objectAtIndexedSubscript:
count
bytes
base64EncodedStringWithOptions:
encodeFloat:forKey:
encodePoint:forKey:
decodePointForKey:
setWithArray:
newlineCharacterSet
barcodeDescriptor
errorWithDomain:code:userInfo:
bundleIdentifier
copy
decodeFloatForKey:
pixelFormat
setExportedInterface:
encodeBool:forKey:
appendFormat:
decodeObjectOfClasses:forKey:
decodeBoolForKey:
encodeObject:forKey:
colorSpace
stringWithUTF8String:
resume
invalidate
UTF8String
appendString:
array
identifier
moreText
addObject:
setRemoteObjectInterface:
encodeInteger:forKey:
enumerateKeysAndObjectsUsingBlock:
payloadStringValue
decodeObjectOfClass:forKey:
dictionaryWithObjects:forKeys:count:
interfaceWithProtocol:
height
button
stringWithFormat:
context
componentsJoinedByString:
render:toCVPixelBuffer:
setClasses:forSelector:argumentIndex:ofReply:
dataWithBytes:length:
maxInitiallyVisibleResults
init
initWithCoder:
encodeWithCoder:
supportsSecureCoding
initWithQueryTerm:domain:textContext:
initWithQueryTerm:
description
hintDomain
setHintDomain:
surroundingText
setSurroundingText:
normalizedBoundingBoxes
setNormalizedBoundingBoxes:
queryTerm
queryID
setQueryID:
uiScale
setUiScale:
.cxx_destruct
_hintDomain
_surroundingText
_normalizedBoundingBoxes
_queryTerm
_queryID
_uiScale
T@"NSString",R,C,N,V_queryTerm
T@"NSNumber",C,N,V_queryID
T@"NSNumber",C,N,V_uiScale
T@"NSString",C,N,V_hintDomain
T@"NSString",C,N,V_surroundingText
T@"NSArray",C,N,V_normalizedBoundingBoxes
TB,R
initWithPersonIdentifier:personName:boundingBox:andConfidence:
personIdentifier
personName
boundingBox
confidence
_confidence
_personIdentifier
_personName
_boundingBox
T@"NSString",R,N,V_personIdentifier
T@"NSString",R,N,V_personName
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_boundingBox
Tf,R,N,V_confidence
initWithResultItems:
resultItems
_resultItems
T@"NSArray",R,N,V_resultItems
initWithSearchSections:
searchSections
_searchSections
T@"NSArray",R,N,V_searchSections
location
setLocation:
imageURL
setImageURL:
referralURL
setReferralURL:
imageType
setImageType:
domains
setDomains:
featureIdentifier
setFeatureIdentifier:
_location
_imageURL
_referralURL
_imageType
_domains
_featureIdentifier
T@"CLLocation",C,N,V_location
T@"NSURL",C,N,V_imageURL
T@"NSURL",C,N,V_referralURL
T@"NSNumber",C,N,V_imageType
T@"NSArray",C,N,V_domains
T@"NSString",C,N,V_featureIdentifier
setResults:
setError:
results
error
_results
_error
T@"NSArray",R,N,V_results
T@"NSError",R,N,V_error
requestImageProcessing:forIOSurface:withOrientation:identifier:requestID:andReply:
requestImageProcessing:forAssetURL:withSandboxToken:identifier:requestID:andReply:
currentOutstandingTasksWithReply:
cancelRequest:
cancelAllRequests
startEntryPointWithQueryID:
cacheHitWithQueryID:cachedResultQueryID:
endEntryPoint
serviceName
serverProtocol
allowedClasses
executionNanoseconds
setExecutionNanoseconds:
executionTimeInterval
timerange
_executionNanoseconds
_timerange
TQ,R
Td,R
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
initWithTopLeft:topRight:bottomLeft:bottomRight:symbology:payload:andDescriptor:
normalizedBoundingBox
topLeft
topRight
bottomLeft
bottomRight
symbology
payload
descriptor
_symbology
_payload
_descriptor
_topLeft
_topRight
_bottomLeft
_bottomRight
T{CGPoint=dd},R,N,V_topLeft
T{CGPoint=dd},R,N,V_topRight
T{CGPoint=dd},R,N,V_bottomLeft
T{CGPoint=dd},R,N,V_bottomRight
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T@"NSString",R,N,V_symbology
T@"NSString",R,N,V_payload
T@"CIBarcodeDescriptor",R,N,V_descriptor
initWithObservations:
observations
_observations
T@"NSArray",R,N
T@"NSArray",R,N,V_observations
initWithPayload:andReportIdentifier:
reportIdentifier
_reportIdentifier
T@"NSData",R,N,V_payload
T@"NSString",R,N,V_reportIdentifier
initWithSymbologies:
symbologies
_symbologies
T@"NSArray",R,N,V_symbologies
initWithEmbeddingType:assetCreationDate:data:checksum:andThumbnail:
embeddingType
assetCreationDate
data
checksum
thumbnail
_embeddingType
_assetCreationDate
_data
_checksum
_thumbnail
TQ,R,N,V_embeddingType
T@"NSDate",R,&,N,V_assetCreationDate
T@"NSData",R,&,N,V_data
T@"NSData",R,&,N,V_checksum
T@"NSData",R,&,N,V_thumbnail
requestMediaAnalysisDatabaseAccessSandboxExtensionWithPhotoLibraryURL:andReply:
requestImageProcessing:forImageData:withUniformTypeIdentifier:identifier:requestID:andReply:
requestImageProcessing:forAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:requestID:andReply:
requestImageProcessing:forIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:requestID:andReply:
requestImageProcessing:forAssetWithCloudIdentifier:requestID:andReply:
requestImageProcessingWithCloudIdentifierRequests:requestID:andReply:
queryPerformanceMeasurementsWithReply:
resetPerformanceMeasurements
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:analysisTypes:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
requestWallpaperUpgrade:atSourceURL:toDestinationURL:withOptions:sandboxTokens:andReply:
cancelBackgroundActivityWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestResetPetClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:forModelType:andReply:
queryAutoCounterOptInStatus:withPhotoLibraryURL:personLocalIdentifiers:andReply:
requestOptInAutoCounter:withPhotoLibraryURL:persons:andReply:
requestDumpAutoCounter:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:andReply:
requestAutoCounterAccuracyCalculation:withPhotoLibraryURL:clusterStateURL:groundTruthURL:andReply:
requestAutoCounterSIMLValidation:withPhotoLibraryURL:simlGroundTruthURL:andReply:
requestIdentificationOfFacesWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:withRequestID:andReply:
configureServerInterface:
reportProgress:forRequest:
initWithService:
_service
dealloc
isEntitled
service
initInternal
connection
performRequests:onPixelBuffer:withOrientation:andIdentifier:completionHandler:
renderCGImage:toCVPixelBuffer:
performRequests:onCGImage:withOrientation:andIdentifier:completionHandler:
performRequests:onCIImage:withOrientation:andIdentifier:completionHandler:
performRequests:onPixelBuffer:withOrientation:completionHandler:
sandboxExtensionForURL:error:
performRequests:onImageURL:withIdentifier:completionHandler:
performRequests:onImageURL:completionHandler:
performRequests:onImageData:withUniformTypeIdentifier:andIdentifier:completionHandler:
performRequests:onImageData:withUniformTypeIdentifier:andIdentifier:error:
cancelRequestID:
currentOutstandingTasks
_connectionQueue
_connection
_requestID
performRequests:onAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:completionHandler:
performRequests:onAssetWithLocalIdentifier:fromPhotoLibraryWithURL:completionHandler:
performRequests:onAssetWithIdentifier:identifierType:fromPhotoLibraryWithURL:error:
performRequests:onAssetWithSyndicationIdentifier:error:
_performRequests:onIOSurface:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onPixelBuffer:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onCGImage:withOrientation:assetLocalIdentifier:photoLibraryURL:completionHandler:
performRequests:onAssetWithCloudIdentifier:completionHandler:
performRequestsWithCloudIdentifiers:completionHandler:
queryPerformanceMeasurements
T@"NSString",R,N
T@"Protocol",R,N
T@"NSSet",R,N
minimumAspectRatio
setMinimumAspectRatio:
maximumAspectRatio
setMaximumAspectRatio:
quadratureTolerance
setQuadratureTolerance:
minimumSize
setMinimumSize:
minimumConfidence
setMinimumConfidence:
maximumObservations
setMaximumObservations:
_minimumAspectRatio
_maximumAspectRatio
_quadratureTolerance
_minimumSize
_minimumConfidence
_maximumObservations
Tf,N,V_minimumAspectRatio
Tf,N,V_maximumAspectRatio
Tf,N,V_quadratureTolerance
Tf,N,V_minimumSize
Tf,N,V_minimumConfidence
TQ,N,V_maximumObservations
initWithLanguages:
languages
setLanguages:
maximumCandidateCount
setMaximumCandidateCount:
usesLanguageDetection
setUsesLanguageDetection:
_usesLanguageDetection
_languages
_maximumCandidateCount
T@"NSArray",C,N,V_languages
TQ,N,V_maximumCandidateCount
TB,N,V_usesLanguageDetection
stagedText
setStagedText:
conversationIdentifier
setConversationIdentifier:
_stagedText
_conversationIdentifier
T@"NSString",C,N,V_stagedText
T@"NSString",C,N,V_conversationIdentifier
initWithGatingResultItems:payload:documentObservations:
initWithGatingResultItems:andPayload:
gatingResultItems
gatingPayload
documentObservations
catalogIDs
setCatalogIDs:
_gatingResultItems
_gatingPayload
_documentObservations
_catalogIDs
T@"NSData",R,N
T@"NSArray",C,N,V_catalogIDs
faceDetectorVisionRevision
setFaceDetectorVisionRevision:
allowOnDemand
setAllowOnDemand:
maximumFaceCount
setMaximumFaceCount:
_allowOnDemand
_faceDetectorVisionRevision
_maximumFaceCount
TQ,N,V_faceDetectorVisionRevision
TB,N,V_allowOnDemand
TQ,N,V_maximumFaceCount
initWithObjectIdentifier:imageURL:thumbnailURL:metadata:
objectIdentifier
thumbnailURL
metadata
_objectIdentifier
_thumbnailURL
_metadata
T@"NSString",R,N,V_objectIdentifier
T@"NSString",R,N,V_imageURL
T@"NSString",R,N,V_thumbnailURL
T@"NSData",R,N,V_metadata
initWithDomain:knowledgeGraphID:title:thumbnailURL:thumbnailAspectRatio:shortDescription:detailedDescription:webURL:knowledgeProperties:
setThirdPartyObject:
domain
knowledgeGraphID
title
thumbnailAspectRatio
shortDescription
detailedDescription
webURL
knowledgeProperties
thirdPartyObject
_thumbnailAspectRatio
_domain
_knowledgeGraphID
_title
_shortDescription
_detailedDescription
_webURL
_knowledgeProperties
_thirdPartyObject
T@"MADVIVisualSearchThirdPartyObject",R,N,V_thirdPartyObject
T@"NSString",R,N,V_domain
T@"NSString",R,N,V_knowledgeGraphID
T@"NSString",R,N,V_title
T@"NSURL",R,N,V_thumbnailURL
Tf,R,N,V_thumbnailAspectRatio
T@"NSString",R,N,V_shortDescription
T@"NSString",R,N,V_detailedDescription
T@"NSURL",R,N,V_webURL
T@"NSDictionary",R,N,V_knowledgeProperties
initWithNormalizedBoundingBox:regionAttributes:andSearchSections:
regionAttributes
_regionAttributes
_normalizedBoundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_normalizedBoundingBox
T@"NSArray",R,N,V_regionAttributes
initWithResultItems:andUserFeedbackPayload:
userFeedbackPayload
_userFeedbackPayload
T@"NSData",R,N,V_userFeedbackPayload
initWithSurface:cropRect:confidence:
initWithSurface:
pixelBuffer
image
cropRect
.cxx_construct
_surface
_pixelBuffer
_image
_cropRect
T^{__CVBuffer=},R,N
T^{CGImage=},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_cropRect
performInPlace
setPerformInPlace:
cropToFit
setCropToFit:
returnMask
setReturnMask:
_performInPlace
_cropToFit
_returnMask
TB,N,V_performInPlace
TB,N,V_cropToFit
TB,N,V_returnMask
initWithDomain:label:glyphName:hasFocalPoint:focalPoint:displayLabel:displayMessage:
label
glyphName
hasFocalPoint
focalPoint
displayLabel
displayMessage
_hasFocalPoint
_label
_glyphName
_displayLabel
_displayMessage
_focalPoint
T@"NSString",R,N,V_label
T@"NSString",R,N,V_glyphName
TB,R,N,V_hasFocalPoint
T{CGPoint=dd},R,N,V_focalPoint
T@"NSString",R,N,V_displayLabel
T@"NSString",R,N,V_displayMessage
initWithNormalizedBoundingBox:andDomains:
T@"NSArray",R,N,V_domains
initWithResultItems:andPayload:
passedGating
TB,R,N
initWithIsSensitive:andAttributes:
isSensitive
attributes
_isSensitive
_attributes
TB,R,N,V_isSensitive
T@"NSDictionary",R,N,V_attributes
B16@0:8
@40@0:8@16@24@32
@24@0:8@16
v24@0:8@16
@16@0:8
v16@0:8
@"NSString"
@"NSArray"
@"NSNumber"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@68@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32f64
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
f16@0:8
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@"CLLocation"
@"NSURL"
@"NSError"
v56@0:8@16@24I32@36i44@?48
v60@0:8@16@24@32@40i48@?52
v24@0:8@?16
v20@0:8i16
v24@0:8Q16
v32@0:8Q16Q24
v56@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36i44@?<v@?@"NSArray"@"NSError">48
v60@0:8@"NSArray"16@"NSURL"24@"NSString"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v24@0:8@?<v@?Q>16
Q16@0:8
d16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
@104@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64@80@88@96
{CGPoint=dd}16@0:8
@"CIBarcodeDescriptor"
{CGPoint="x"d"y"d}
@32@0:8@16@24
@"NSData"
@56@0:8Q16@24@32@40@48
@"NSDate"
v32@0:8@16@?24
v60@0:8@16@24Q32@40i48@?52
v64@0:8@16@24I32@36@44i52@?56
v44@0:8@16@24i32@?36
v36@0:8@16i24@?28
v60@0:8i16@20@28Q36@44@?52
v60@0:8i16@20@28@36Q44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v40@0:8@16Q24@?32
v52@0:8i16@20@28@36@?44
v52@0:8Q16@24@32i40@?44
v32@0:8@"NSURL"16@?<v@?@"NSString">24
v60@0:8@"NSArray"16@"NSData"24@"UTType"32@"NSString"40i48@?<v@?@"NSArray"@"NSError">52
v60@0:8@"NSArray"16@"NSString"24Q32@"NSURL"40i48@?<v@?@"NSArray"@"NSError">52
v64@0:8@"NSArray"16@"IOSurface"24I32@"NSString"36@"NSURL"44i52@?<v@?@"NSArray"@"NSError">56
v44@0:8@"NSArray"16@"NSString"24i32@?<v@?@"NSArray"@"NSError">36
v36@0:8@"NSDictionary"16i24@?<v@?@"NSDictionary"@"NSError">28
v24@0:8@?<v@?@"NSDictionary">16
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSArray"20@"NSURL"28@"NSDictionary"36Q44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v60@0:8i16@"NSURL"20@"NSURL"28@"NSDictionary"36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSURL"16Q24@?<v@?@"NSString"@"NSError">32
v44@0:8i16@"NSURL"20@"NSArray"28@?<v@?@"NSDictionary"@"NSError">36
v52@0:8i16@"NSURL"20@"NSURL"28@"NSURL"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSURL"20@"NSURL"28@?<v@?@"NSDictionary"@"NSError">36
v44@0:8@"NSArray"16@"NSURL"24i32@?<v@?@"NSDictionary"@"NSError">36
v52@0:8Q16@"NSArray"24@"NSURL"32i40@?<v@?@"NSError">44
v28@0:8d16i24
@"MADService"
i52@0:8@16^{__CVBuffer=}24I32@36@?44
i32@0:8^{CGImage=}16^^{__CVBuffer}24
i52@0:8@16^{CGImage=}24I32@36@?44
i52@0:8@16@24I32@36@?44
i44@0:8@16^{__CVBuffer=}24I32@?36
@32@0:8@16^@24
i48@0:8@16@24@32@?40
i40@0:8@16@24@?32
i56@0:8@16@24@32@40@?48
B56@0:8@16@24@32@40^@48
@"NSObject<OS_dispatch_queue>"
@"NSXPCConnection"
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i56@0:8@16@24Q32@40@?48
B56@0:8@16@24Q32@40^@48
B40@0:8@16@24^@32
i60@0:8@16@24I32@36@44@?52
i60@0:8@16^{__CVBuffer=}24I32@36@44@?52
i60@0:8@16^{CGImage=}24I32@36@44@?52
i32@0:8@16@?24
@"NSString"16@0:8
@"Protocol"16@0:8
@"NSSet"16@0:8
v20@0:8f16
v20@0:8B16
@48@0:8@16@24@32@40
@84@0:8@16@24@32@40f48@52@60@68@76
@"NSDictionary"
@"MADVIVisualSearchThirdPartyObject"
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
@60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
^{__CVBuffer=}16@0:8
^{CGImage=}16@0:8
@"IOSurface"
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
{CF<CGImage *>="value_"^{CGImage}}
@76@0:8@16@24@32B40{CGPoint=dd}44@60@68
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@28@0:8B16@20
