com.apple.corespeech
Framework
v8@?0
en_US_POSIX
yyyyMMdd-HHmmss
CSLogInitIfNeeded_block_invoke
gitrelno_unavailable
com.apple.ssr
SSRLogInitIfNeeded_block_invoke
-[CSVTUIEndpointAnalyzer init]
-[CSVTUIEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSVTUIEndpointAnalyzer recordingStoppedForReason:]
-[CSVTUIEndpointAnalyzer stopEndpointer]
-[CSVTUIEndpointAnalyzer resetForNewRequestWithSampleRate:]
-[CSVTUIEndpointAnalyzer setStartWaitTime:]
-[CSVTUIEndpointAnalyzer setEndWaitTime:]
-[CSAudioRecordContext(AVVC) avvcContextSettings]
com.apple.ssr.vad.spg
-[SSRVoiceActivityDetector initWithContext:delegate:]
-[SSRVoiceActivityDetector processAudioData:numSamples:]
-[SSRVoiceActivityDetector clientSilenceFeaturesAvailable:]
triggerStartSampleCount
triggerEndSampleCount
triggerFireSampleCount
isTriggerEvent
totalSampleCount
triggerScore
recognizerScore
recognizerThresholdOffset
recognizerScaleFactor
triggeredPhrase
triggeredPhraseId
-[CSVTUITwoPassKeywordDetector initWithAsset:]
config_1st.txt
-[CSVTUITwoPassKeywordDetector analyze:]
SSRSpeakerRecognizerPSR.m
Incorrect ctx for VTSpeakerRecognizer: %@
com.apple.ssr.psrq
-[SSRSpeakerRecognizerPSR initWithContext:delegate:]
extraSamplesAtStart
triggerEndSeconds
-[SSRSpeakerRecognizerPSR dealloc]
-[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:]
extraAudioAtStartInMs
tdEndInMs
-[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
com.apple.speakerrecognition
recognition
-[SSRSpeakerRecognitionOrchestrator initWithContext:withDelegate:error:]
ERR: Failed to init PSR and SAT recognizers - Bailing out
reason
ERR: Failed to init VAD - Bailing out
com.apple.ssr.orchestratorq
SAT+PSR
-[SSRSpeakerRecognitionOrchestrator dealloc]
-[SSRSpeakerRecognitionOrchestrator processAudio:numSamples:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator resetWithContext:]_block_invoke
SSRSpeakerRecognitionOrchestrator-%@
-[SSRSpeakerRecognitionOrchestrator _logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:]
finished
reported
%@_%d
json
-[SSRSpeakerRecognitionOrchestrator getLatestVoiceRecognitionInfo]
-[SSRSpeakerRecognitionOrchestrator speakerRecognizer:hasSpeakerIdInfo:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectStartPointAt:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectEndPointAt:]_block_invoke
+[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]
com.apple.fides.phs
+[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]_block_invoke
Name
MetaInfo
v24@?0@"NSUUID"8@"NSError"16
v32@?0@"NSNumber"8@"NSString"16@"NSError"24
ERR: received nil dob: %@ / name: %@
+[SSRDESRecordWriter fetchMedicalDataWithCompletion:]_block_invoke
v24@?0@"_HKMedicalIDData"8@"NSError"16
com.apple.VoiceTriggerUI.TrainingSessionQueue
com.apple.VoiceTriggerUI.TrainingManager
-[SSRVTUITrainingManager updateTrainingManagerForDevice:trainingDeviceUUIDList:]
-[SSRVTUITrainingManager setLocaleIdentifier:]
-[SSRVTUITrainingManager createKeywordDetector]
-[SSRVTUITrainingManager prepareWithCompletion:]_block_invoke
-[SSRVTUITrainingManager cleanupWithCompletion:]
-[SSRVTUITrainingManager cleanupWithCompletion:]_block_invoke
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]_block_invoke_2
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]_block_invoke
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]_block_invoke_2
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]_block_invoke
-[SSRVTUITrainingManager cancelTrainingForID:]
-[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:withCompletion:]
-[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:completionWithResult:]
-[SSRVTUITrainingManager _shouldShowHeadsetDisconnectionMessage]
-[SSRVTUITrainingManager _startAudioSession]
-[SSRVTUITrainingManager setSuspendAudio:]
-[SSRVTUITrainingManager setSuspendAudio:]_block_invoke
-[SSRVTUITrainingManager CSVTUITrainingSessionStopListen]
-[SSRVTUITrainingManager CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:]
-[SSRVTUITrainingManager audioSessionDidStopRecording:]
-[SSRVoiceProfileRetrainerFactory init]
Borealis Input
com.apple.VoiceTriggerUI.RecordSessionQueue
-[CSVTUIAudioSessionRecorder init]
-[CSVTUIAudioSessionRecorder _audioRecorder]
-[CSVTUIAudioSessionRecorder prepareRecord]
-[CSVTUIAudioSessionRecorder startRecording]
-[CSVTUIAudioSessionRecorder stopRecording]
-[CSVTUIAudioSessionRecorder _hasCorrectInputAudioRoute]
-[CSVTUIAudioSessionRecorder _hasCorrectOutputAudioRoute]
-[SSRVoiceProfileMetaContext initWithVoiceProfile:]
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@, pitch:%@ Hz]
+[SSRTriggerPhraseDetector filterVTAudioFiles:withLocale:withAsset:]
v20@?0@"NSError"8f16
-[SSRTriggerPhraseDetector initWithLocale:asset:]
-[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]
-[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]_block_invoke
v44@?0{AudioBufferList=I[1{AudioBuffer=II^v}]}8B32@"NSError"36
NDAPI: missing best_score for %@
best_score
Quasar: missing best_score for %@
Languages
Footprint
Premium
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
isMaximized
-[CSVTUIKeywordDetector initWithAsset:]
config.txt
VoiceTriggerEventInfo
locale
asset
profileUpdateFailedExplicitUttScore
profileUpdateDiscardImplicitUttScore
profileUpdateExplicitUttScore
profileUpdateImplicitUttScore
profileUpdateNumPrunedUttsPHS
profileUpdateNumDiscardedUttsPHS
profileUpdateNumRetainedUttsPHS
profileUpdateScoreMSE
profileUpdateFailCode
speakerRecognitionWaitTimeMs
speakerRecognitionProcessingStatus
retrainingWaitTimeMs
retrainingStatusCode
TdPsrSATRetrainingTimedOut
TdPsrExtraAudioSamplesProcessed
TdPsrFailedDuringSATDetection
xx_XX
unknown
@"NSDictionary"8@?0
%@.%d
-[SSRLoggingAggregator pushAnalytics]
voic
carplay
hearst
raisetospeak
auto
B24@?0@"SSRVoiceProfile"8@"NSDictionary"16
-[SSRVoiceProfileStoreCleaner filterDuplicatedSiriProfilesFrom:]
Primary
-[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]
kAFAssistantErrorDomain
-[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]_block_invoke
v24@?0@"NSString"8@"NSError"16
-[SSRVoiceProfileStoreCleaner cleanupProfileStore]
ERR: Failed to get appdomain for profile %@
-[SSRVoiceProfileStoreCleaner cleanupProfileStore]_block_invoke
v32@?0@"SSRVoiceProfile"8Q16^B24
-[SSRVoiceProfileStoreCleaner deleteInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:]
-[SSRVoiceProfileStoreCleaner _cleanupAppDomain:]
-[SSRVoiceProfileStoreCleaner _cleanuplanguageCodePath:forAppDomain:]
-[SSRVoiceProfileStoreCleaner _cleanupImplicitUtteranceCacheForProfile:]
-[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:]
-[SSRVoiceProfileStoreCleaner _cleanupContentsOfSatFolder:]
-[SSRVoiceProfileStoreCleaner _cleanupInvalidAudioFiles:]
Failed reading contents of audioDir: %@, err: %@
-[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesAtURL:]
enrollment_completed
-[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]
obsoleteCutOffDate is nil - Bailing out
v32@?0@"NSURL"8Q16^B24
-[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]_block_invoke
Error reading contents of modelDir: %@, err: %@
-[SSRVoiceProfileStoreCleaner _cleanupModelFilesAtDir:forAssetArray:]
-[CSVTUISelfLoggingDigitalZeroReporter logDigitalZeroDetectionComplete]
UserVoiceProfileDateTrained
UserVoiceProfileLocale
UserVoiceProfileAppDomain
UserVoiceProfilePitch
UserVoiceProfilePath
UserVoiceProfileID
UserSharedSiriID
UserVoiceProfileUserName
VoiceProfileIdentifier
VoiceProfileCompatabiltyVersion
VoiceProfileProductType
VoiceProfileSWVersion
VoiceProfileCategoryType
UserVoiceProfileOnboardType
UserVoiceProfileExpSatVecCount
VoiceProfilePruningCookie
-[SSRVoiceProfile initNewVoiceProfileWithLocale:withAppDomain:]
Creating SSRVoiceProfile with no profileId vpDict: %@
audio
-[SSRVoiceProfile _copyExplicitAudio:withSpIdType:]
-[SSRVoiceProfile importVoiceProfileAtPath:]
ERR: Too less audio files (%ld) for onboarding
utterances passed is nil!
-[SSRVoiceProfile addUtterances:spIdType:]
Failed to copy utterances with error %@
-[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]
-[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]_block_invoke
B24@?0@"NSURL"8@"NSDictionary"16
audiocache
td-sr-model
model
-[SSRVoiceProfile deleteModelForSpidType:recognizerType:]
enrollment_migrated
-[SSRVoiceProfile _isSATMarkedWithMarker:]
-[SSRVoiceProfile _markSATEnrollmentWithMarker:]
-[SSRVoiceProfile _updateVoiceProfileVersionFile]
-[SSRVoiceProfile updatePruningCookie:]
Dictation
-[SSRTriggerPhraseDetectorQuasar initWithLocale:configPath:resourcePath:]
-[SSRTriggerPhraseDetectorQuasar reset]
Second Pass
-[SSRTriggerPhraseDetectorQuasar analyzeWavData:numSamples:]
-[SSRTriggerPhraseDetectorQuasar endAudio]
totalSamplesAtEndOfCapture
productType
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdUserScoresVersion
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
bestVoiceTriggerScore
sessionId
segmentStartTime
segmentCounter
myriad
ssrMeta
voiceTriggerRequestUID
numEnrollmentUtt
combinationWeight
numSpeakerVectors
numExplicitUtt
numImplicitUtt
profileID
lowScoreThreshold
psrContext
spIdKnownUserPSRScores
spIdKnownUserPSRExpScores
satContext
spIdKnownUserSATScores
spIdKnownUserSATExpScores
Unknown InvocationStyle: %lu
tdti
tdtiexplicit
tdexplicit
Unknown CSSpIdType: %lu
+[SSRUtils spIdTypeForString:]
Unknown SpeakerRecognizerType: %lu
Unknown VoiceProfileRetrainerType: %lu
config_td_spid.txt
config_sr_sat.txt
+[SSRUtils satConfigFileNameForCSSpIdType:]
config_tdti_spid.txt
+[SSRUtils psrConfigFileNameForCSSpIdType:]
config_ti_spid.txt
+[SSRUtils satConfigFileNameForCSSpIdType:forModelType:forAssetType:]
spid-imported
+[SSRUtils createDirectoryIfDoesNotExist:]
Library/Logs/CrashReporter/ssr
self ENDSWITH '.wav'
+[SSRUtils ssrAudioLogsCountWithinPrivacyLimit]
+[SSRUtils cleanupOrphanedVoiceIdGradingFiles]
v32@?0@"NSString"8@"NSURL"16^B24
+[SSRUtils cleanupOrphanedVoiceIdGradingFiles]_block_invoke
VoiceProfileCache
AudioFileOpenURL Failed : %@
EARTests
AudioFileOpenURL failed: %@
ExtAudioFileWrapAudioFileID failed: %@
Error reading audio-file: %d
EOF. Num bytes read: %lu
+[SSRUtils isSpeakerRecognitionSupportedInLocale:]
+[SSRUtils readJsonFileAtPath:]
kCSDeviceCategory_Unknown
kCSDeviceCategory_iOS_NonAop
kCSDeviceCategory_iOS_Aop
kCSDeviceCategory_macOS
kCSDeviceCategory_audioAccessory
kCSDeviceCategory_iOS_Aop_Explicit
iPad3,4
iPad3,5
iPad3,6
iPad4,1
iPad4,2
iPad4,3
iPad4,4
iPad4,5
iPad4,6
iPad4,7
iPad4,8
iPad4,9
iPad5,1
iPad5,2
iPad5,3
iPad5,4
iPad6,7
iPad6,8
iPad6,11
iPad6,12
iPhone5,1
iPhone5,2
iPhone5,3
iPhone5,4
iPhone6,1
iPhone6,2
iPhone7,1
iPhone7,2
iPod
iPad
iPhone
Accessory
AppleTV
+[SSRUtils deviceCategoryForDeviceProductType:]
+[SSRUtils isCurrentDeviceCompatibleWithNewerVoiceProfileAt:]
+[SSRUtils isCurrentDeviceCompatibleWithVoiceProfileAt:]
pathExtension='json'
Caches/VoiceTrigger/ImplicitUtterences
+[SSRUtils getNumberOfAudioFilesInDirectory:]
v32@?0@"NSString"8Q16^B24
+[SSRUtils dumpFilesInDirectory:]
+[SSRUtils getContentsOfDirectory:]
+[SSRUtils getHomeUserIdForVoiceProfile:withCompletion:]
+[SSRUtils getHomeUserIdForVoiceProfile:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
+[SSRUtils getVoiceProfileForSiriProfileId:forLanguageCode:]
+[SSRUtils logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:]
.wav
ERR: Audio path is nil - Bailing out
+[SSRUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]
ERR: Failed initializing loggers at %@ and %@
+[SSRUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]_block_invoke
ERR: Failed to read file: %@
+[SSRUtils getEnrollmentUtterancesFromDirectory:]
+[SSRUtils getExplicitEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils getExplicitEnrollmentUtterancesFromDirectory:]
q24@?0@"NSURL"8@"NSURL"16
+[SSRUtils getExplicitMarkedEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils getImplicitEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils _getUtterancesFromDirectory:]
self.absoluteString ENDSWITH '.wav'
+[SSRUtils removeItemAtPath:]
Failed to get contents of %@ with error %@
+[SSRUtils moveContentsOfSrcDirectory:toDestDirectory:]
Failed to move %@ to %@ with error %@
+[SSRUtils combineScoreFromPSR:fromSAT:withCombinedWt:]
pruning
-[SSRVoiceProfilePruner pruneVoiceProfile:forSpIdType:withAsset:]
v32@?0f8f12f16f20@"NSError"24
-[SSRVoiceProfilePruner _getScoresForAudio:withController:withDetector:forProfile:withCompletion:]
Failed to get scoreCard - Bailing out
v16@?0@"NSError"8
Pruner: Timeout (%fms) waiting for retraining - Bailing out
-[SSRVoiceProfilePruner _retrainVoiceProfile:withAsset:]
-[SSRVoiceProfilePruner _deleteUtterances:]
SSRVoiceRetrainingVoiceProfile
SSRVoiceRetrainingCompareVoiceProfiles
SSRVoiceRetrainingCompareVoiceProfilesSpIdType
SSRVoiceRetrainingAsset
SSRVoiceRetrainingSpIdType
SSRVoiceRetrainingFilterToVoiceTriggerUtterances
SSRVoiceRetrainingForce
SSRVoiceRetrainingPayloadProfile
retraining
ERR: VoiceProfile is invalid - Bailing out
-[SSRVoiceProfileRetrainingContext initWithVoiceRetrainingContext:error:]
ERR: Last known assets are nil - Bailing out
ERR: _modelsContext is nil - Bailing out
[SessionId: %@, Asset: %@, ProfileID: %@]
meta_version.json
enrollment_version.json
meta_version
trainingType
explicit
implicit
handheld
near-field
far-field
utteranceWav
productVersion
triggerSource
audioInputSource
otherSourceProfileMatch
containsPayload
grainedDate
buildVersion
+[SSRVoiceProfileMetadataManager saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:]
+[SSRVoiceProfileMetadataManager _getBaseMetaDictionaryForUtterancePath:]
+[SSRVoiceProfileMetadataManager _writeMetaDict:forUtterancePath:]
.json
+[SSRVoiceProfileMetadataManager isUtteranceImplicitlyTrained:]
+[SSRVoiceProfileMetadataManager getUtteranceEnrollmentType:]
+[SSRVoiceProfileMetadataManager recordedTimeStampOfFile:]
yyyyMMdd
+[SSRVoiceProfileMetadataManager recordedTimeStampFromFileName:]
+[CSVTUIRegularExpressionMatcher matchWithString:TrailingStr:LeadingStr:Pattern:]
-[CSVTUITrainingSessionWithPayload _firedVoiceTriggerTimeout]
-[CSVTUITrainingSessionWithPayload _firedEndPointTimeout]
v16@?0@"NSDictionary"8
-[CSVTUITrainingSessionWithPayload handleAudioInput:]_block_invoke
-[CSVTUITrainingSessionWithPayload audioSessionDidStartRecording:error:]
-[CSVTUITrainingSessionWithPayload audioSessionDidStopRecording:]
-[CSVTUITrainingSessionWithPayload didDetectBeginOfSpeech]
-[CSVTUITrainingSessionWithPayload didDetectEndOfSpeech:]
-[CSVTUITrainingSessionWithPayload closeSessionWithStatus:successfully:]
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didHypothesizeTranscription:]_block_invoke
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishRecognition:]_block_invoke
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishSuccessfully:]_block_invoke
-[CSVTUITrainingSessionWithPayload matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:]
-[CSVTUITrainingSession closeSessionWithStatus:successfully:]
-[CSVTUITrainingSession closeSessionWithStatus:successfully:complete:]_block_invoke
-[CSVTUITrainingSession closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:]_block_invoke
-[CSVTUITrainingSession suspendTraining]
-[CSVTUITrainingSession suspendTraining]_block_invoke
-[CSVTUITrainingSession resumeTraining]
-[CSVTUITrainingSession resumeTraining]_block_invoke
-[CSVTUITrainingSession setupPhraseSpotter]
-[CSVTUITrainingSession handleAudioInput:]_block_invoke_2
-[CSVTUITrainingSession handleAudioBufferForVTWithAudioInput:withDetectedBlock:]
-[CSVTUITrainingSession feedSpeechRecognitionTrailingSamplesWithCompletedBlock:]
-[CSVTUITrainingSession trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:]
-[CSVTUITrainingSession audioSessionUnsupportedAudioRoute]
-[CSVTUITrainingSession didDetectBeginOfSpeech]
-[CSVTUITrainingSession didDetectEndOfSpeech:]
PHS explicit training utterance
[%ld] VTUISession Number:[%ld]
-[CSVTUITrainingSession startMasterTimerWithTimeout:]
-[CSVTUITrainingSession handleMasterTimeout:]
-[CSVTUITrainingSession stopMasterTimer]
-[CSVTUITrainingSession speechRecognitionTask:didHypothesizeTranscription:]
triggerFireMachTime
satTriggered
firstPassTriggerSource
deviceHandHeld
languageCode
ApplicationProcessor
com.apple.voicetrigger.PHSProfileDownloadTrigger
com.apple.voicetrigger.speakermodelUpdated
com.apple.voicetrigger.retrainRequired
com.apple.voicetrigger.voiceprofilesync
VoiceProfileAvailabilityMetaBlobVersion
+[SSRVoiceProfileManager sharedInstanceWithEndpointId:]
com.apple.cs.profileManager
/var/mobile
Library
VoiceTrigger/SAT
-[SSRVoiceProfileManager discardSiriEnrollmentForProfileId:forLanguageCode:]
-[SSRVoiceProfileManager _getVoiceProfilesForSiriProfileId:withLanguageCode:]
ERR: profile is nil - Bailing out
-[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]
ERR: Context is nil - Bailing out
ERR: Failed to copy %@ to %@, error: %@
-[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]_block_invoke
ERR: Failed in marking Enrollment as Successful for profile %@
v20@?0B8@"NSError"12
-[SSRVoiceProfileManager isImplicitTrainingRequiredForVoiceProfileId:locale:completion:]_block_invoke
-[SSRVoiceProfileManager isImplicitTrainingRequiredForVoiceProfileId:locale:completion:]
ImplicitTraining
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]_block_invoke
primary
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]_block_invoke_2
can not connect to remote audio device
Failed to get asset for locale %@
%lld
ERR: Voice Profile not found for %@ - Bailing out
ERR: Voice Profile locale %@ not matching with %@ - Bailing out
v32@?0@"NSError"8@"NSURL"16@"NSURL"24
-[SSRVoiceProfileManager notifyUserVoiceProfileDownloadReadyForUser:getData:completion:]_block_invoke
Primary User
Missing downloadTriggerBlock - Bailing out
Unknown device category for device type %@ - Bailing out
-[SSRVoiceProfileManager notifyUserVoiceProfileUpdateReady]_block_invoke
userAddition timedout after %fms
Enable VoiceTrigger Upon VoiceProfile Sync For Language
-[SSRVoiceProfileManager _checkIfDownloadRequiredForProfileId:]
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]_block_invoke_2
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]_block_invoke
v24@?0@"NSError"8@"NSString"16
@"NSError"16@?0Q8
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]
-[SSRVoiceProfileManager _downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:]
SAT download path is nil - Bailing out
Download for %@ failed with %@
-[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]
Skipping profile Update for %@ in %@
ERR: Failed to import profile %@ for %@
ERR: Migrated language %@ for %@ but failed to mark SAT enrollment
ERR: Failed to mark migrated for %@ in language %@
Failed to init retrainCtxt for profileID %@ with error %@
-[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]_block_invoke
userAddition timedout for siriProfileId %@ after %fms
Failed to enroll user - %@
SourcePath (%@) or DestinationPath (%@) is nil - Bailing out
-[SSRVoiceProfileManager _enableVoiceTriggerIfLanguageMatches:]
Caches/VoiceTrigger/SATUpdate
Caches/VoiceTrigger/SATUpdateNewerZone
_%d_%d
-[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:]
-[SSRVoiceProfileManager notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:]_block_invoke
-[SSRVoiceProfileManager uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:]_block_invoke
@"NSError"24@?0@"SSRVoiceProfileMetaContext"8@"NSString"16
-[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]
-[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]_block_invoke
-[SSRVoiceProfileManager notifyUserVoiceProfileUploadComplete]_block_invoke
-[SSRVoiceProfileManager _getVoiceProfilePathsToBeUploadedForSiriProfileId:]
-[SSRVoiceProfileManager _copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:]
Failed to copy to SATUpload Diretory : %@
v24@?0@"NSError"8Q16
-[SSRVoiceProfileManager _copyVoiceProfileAtPath:toPath:]
ERR: Number of training utterances copied from %@ to %@ is too less %ld
Cannot delete existing SATUpload Diretory : %@
-[SSRVoiceProfileManager _prepareVoiceProfileWithSiriProfileId:withUploadBlock:]
Cannot create SAT Upload Directory : %@
Failed to upload %@ with error %@ - Bailing out
-[SSRVoiceProfileManager _markVoiceProfileTrainingSyncForLanguage:]
Enable VoiceProfile Training Sync For Language
-[SSRVoiceProfileManager _isMarkedForVoiceProfileTrainingSyncForLanguage:]
-[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]
-[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]_block_invoke
v24@?0@"NSDictionary"8@"NSError"16
-[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:]
ERR: Unknown product type. Returning false, language: %@
-[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]
ERR: Unknown device-category for device: %@, languageCode: %@
ERR: Improper VoiceProfile detected: %@, languageCode: %@
-[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]_block_invoke
-[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:]
-[SSRVoiceProfileManager enableVoiceTriggerUponVoiceProfileSyncForLanguage:]
-[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]
-[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]_block_invoke
v16@?0@"NSArray"8
Caches/VoiceTrigger/SATLegacyUpload
-[SSRVoiceProfileManager provisionedVoiceProfilesForAppDomain:withLocale:]
q24@?0@"SSRVoiceProfile"8@"SSRVoiceProfile"16
-[SSRVoiceProfileManager provisionedVoiceProfilesForLocale:]
-[SSRVoiceProfileManager getVoiceProfileAnalyticsForAppDomain:withLocale:]
ERR: Voice Profile sent as nil - Bailing out
-[SSRVoiceProfileManager triggerRetrainingVoiceProfile:withContext:withCompletion:]
ERR: Voice Profile not found for Id %@ - Bailing out
-[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]
-[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]_block_invoke
-[SSRVoiceProfileManager isSATEnrolledForSiriProfileId:forLanguageCode:]
ERR: Voice Profile passed is nil - Bailing out
-[SSRVoiceProfileManager deleteUserVoiceProfile:]
-[SSRVoiceProfileManager deleteAllVoiceProfilesForAppDomain:]
Library/Caches/VoiceTrigger
Caches/VoiceTrigger
Caches/VoiceTrigger/SATUpload
td/audio
-[SSRVoiceProfileManager _isLegacyEnrollmentMarkedWith:forLanguageCode:]
-[SSRVoiceProfileManager importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:]_block_invoke
No path, app domain or locale provided
-[SSRVoiceProfileManager importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:]
%@/%@
file://%@/%@
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
VoiceControllerCreationQueue
-[CSVTUIAudioRecorder initWithQueue:error:]
-[CSVTUIAudioRecorder dealloc]
-[CSVTUIAudioRecorder _destroyVoiceController]
-[CSVTUIAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSVTUIAudioRecorder _voiceControllerWithError:]
-[CSVTUIAudioRecorder setContext:error:]
-[CSVTUIAudioRecorder prepareAudioStreamRecordWithStreamHandleId:error:]
-[CSVTUIAudioRecorder startAudioStreamWithStreamHandleId:error:]
-[CSVTUIAudioRecorder stopAudioStreamWithStreamHandleId:error:]
Builtin Microphone
-[CSVTUIAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSVTUIAudioRecorder deactivateAudioSession:error:]
useRemoteBuiltInMic
-[CSVTUIAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSVTUIAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSVTUIAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSVTUIAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSVTUIAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSVTUIAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSVTUIAudioRecorder voiceControllerEndRecordInterruption:]
-[CSVTUIAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSVTUIAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSVTUIAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSVTUIAudioRecorder voiceControllerMediaServicesWereReset:]
Serial SSRAssetManager queue
en-US
-[SSRAssetManager init]
Trial
-[SSRAssetManager allInstalledAssetsOfType:forLanguage:]_block_invoke_2
-[SSRAssetManager allInstalledAssetsOfType:forLanguage:]_block_invoke
v32@?0@"<SSRAssetProviding>"8Q16^B24
-[SSRAssetManager _latestVersionedAssetOfType:fromProviders:forLocale:]_block_invoke
-[SSRSpeakerRecognitionController voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:]
ERR: Scorecard not available in score dictionary - %@
-[SSRSpeakerRecognitionController voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:]
-[SSRMobileAssetProvider installedAssetOfType:forLanguageCode:]
-[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]
q24@?0@"MAAsset"8@"MAAsset"16
-[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]_block_invoke_2
v32@?0@"MAAsset"8Q16^B24
com.apple.MobileAsset.SpeakerRecognitionAssets
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
-[SSRMobileAssetProvider _buildAssetQueryForAssetType:]
-[SSRMobileAssetProvider _installedMobileAssetOfType:forLanguage:]
-[SSRMobileAssetProvider _findLatestInstalledAsset:]
com.apple.corespeech.voiceprofilestore
-[SSRVoiceProfileStore userVoiceProfilesForAppDomain:]
-[SSRVoiceProfileStore userVoiceProfilesForLocale:]
-[SSRVoiceProfileStore migrateVoiceProfilesIfNeededWithCompletionBlock:]_block_invoke
Filtered languages is nil - %@
spid
trained_users.json
Could not read existing %@ file: err: %@
-[SSRVoiceProfileStore cleanupDuplicatedProfiles]_block_invoke
-[SSRVoiceProfileStore cleanupInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:]
-[SSRVoiceProfileStore cleanupVoiceProfileStore:]_block_invoke_2
-[SSRVoiceProfileStore cleanupVoiceProfileStore:]_block_invoke
-[SSRVoiceProfileStore cleanupVoiceProfileModelFilesForLocale:]_block_invoke
-[SSRVoiceProfileStore _synchronizeSiriVoiceProfilesWithAssistant]_block_invoke
com.apple.siri.corespeech.voiceprofilelist.change
-[SSRVoiceProfileStore isImplicitTrainingRequiredToVoiceProfile:withAsset:completion:]_block_invoke
-[SSRVoiceProfileStore addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:]_block_invoke
Profile %@ is full - Ignoring
Utterance %@ in profile %@ not satisfied the implicit VT policy
Rejecting Implicit utterance %@ for profile %@
@"NSError"24@?0@"NSURL"8@"NSDictionary"16
Utterance %@ rejected for profile %@
v32@?0@"NSError"8@"NSDictionary"16@"NSDictionary"24
Utterance %@ in profile %@ not satisfied the implicit policy
-[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]
B16@?0@"NSDictionary"8
-[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]_block_invoke
v32@?0@"<SSRVoiceProfileRetrainer>"8Q16^B24
-[SSRVoiceProfileStore evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:]
v32@?0@"NSString"8@"NSNumber"16^B24
Profile is nil!
-[SSRVoiceProfileStore addUserVoiceProfile:withContext:withCompletion:]_block_invoke
-[SSRVoiceProfileStore _deleteUserVoiceProfile:]
Deleting profile data at %@ failed with error %@
Profile path is nil!
-[SSRVoiceProfileStore checkIfVoiceProfile:needsUpdatedWith:withCategory:]
-[SSRVoiceProfileStore _checkIfRetrainingRequiredForProfile:]_block_invoke
Failed to init retrainers for profileID %@ with ctxt %@
B16@?0Q8
-[SSRVoiceProfileStore retrainVoiceProfile:withContext:withCompletion:]_block_invoke
-[SSRVoiceProfileStore _enrolledVoiceProfiles]
-[SSRVoiceProfileStore _updateTrainedUsersWithAction:UserVoiceProfile:]
Voice Profile not found for profileId: %@ - Bailing out
-[SSRVoiceProfileStore updateVoiceProfile:withUserName:]
-[SSRVoiceProfileStore _retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:]
VoiceProfile is nil - Bailing out
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:]
context is nil - Bailing out
Invalid spIdType %d - Bailing out
SSRVoiceProfileStore retrainer - %@
Too less (%d) audio files in %@ 
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]_block_invoke
Failed to copy %@ to %@ with error %@
-[SSRVoiceProfileStore copyAudioFiles:toProfile:forModelType:]
-[SSRBiometricMatch init]
-[SSRBiometricMatch getLastBiometricMatchForVoiceTriggerTimeStamp:]
MATCH
MIS-MATCH
-[SSRBiometricMatch _getLastBiometricMatchEvent:atTime:]
BKDevice
Class getBKDeviceClass(void)_block_invoke
SSRBiometricMatch.m
Unable to find class %s
void *BiometricKitLibrary(void)
BKDeviceManager
Class getBKDeviceManagerClass(void)_block_invoke
+[SSREnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveMetadata:isExplicitEnrollment:]
+[SSREnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
+[SSREnrollmentDataManager writeMetaDict:atMetaPath:]
Known User Voice Profiles
Voice Profile Store Version
mobile
SSRSpeakerRecognitionStyle
SSRSpeakerRecognitionAsset
SSRSpeakerRecognitionAssetArray
SSRSpeakerRecognitionVADAssetPath
SSRSpeakerRecognitionLocale
SSRSpeakerRecognitionVTEventInfo
SSRSpeakerRecognitionProfileArray
SSRSpeakerRecognitionUsePayloadProfile
SSRSpeakerRecognitionMaxAudioSecs
SSRSpeakerRecognitionOSTransactionReqd
SSRSpeakerRecognitionEndpointId
com.apple.siri
com.apple.siridebug
com.apple.siri.cc
-[SSRSpeakerRecognitionContext initWithVoiceRecognitionContext:error:]
ERR: SpeakerRecognition not enabled - Bailing out
ERR: Invalid Speaker Recognition style - Bailing out
ERR: Asset not picked - Bailing out
ERR: Endpointer Asset not picked - Bailing out
v24@?0@"NSDictionary"8@"NSDictionary"16
ERR: ModelsContext is nil for locale %@ - Bailing out
%@_%@_%@
[SessionId: %@, RecognitionStyle:(%lu)%@, Asset: %@, vtEventInfo: %@]
-[SSRSpeakerRecognitionContext composeModelContextsForProfiles:forSpIdType:forAsset:completion:]
-[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:withAssetArray:]
-[SSRSpeakerRecognitionContext dealloc]
regex.json
Cannot parse to JSON
Cannot find the file
trailing_garbage
leading_garbage
regex
speakerRecognition
satThreshold
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
useSpeakerRecognitionAsset
phrase
-[CSAsset(SpeakerRecognition) satScoreThresholdForPhId:]
recognizer.json
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
%s ::: CoreSpeech logging initialized (%s)
%s ::: SSR logging initialized (%s)
%s Not supported on this platform
%s Setting mixable to yes as we are in an active call
%s SpkrId:: ERR: Hybrid endpointer not ready for processing request
%s SpkrId:: VAD processed %f secs of audio
%s SpkrId:: Endpoint already reported. Not scheduling
%s SpkrId:: Found Endpoint at: [%f %f %f %f]
%s SpkrId:: Found startpoint at: [%f %f %f %f]
%s Cannot create CSVTUIKeywordDetector since there is no asset available
%s Cannot create CSVTUIKeywordDetector since we cannot initialize NDAPI
%s Unable to create audio chunk, not feeding to analyzer
%s FirstPass triggered, score %f start %lu end %lu fire %lu
%s Waiting for the entire audio... samplesInBuffer %lu triggerSampleFedCount %lu
%s numSamplesinAudioChunk %lu not matching requiredNumSamples %lu !
%s Second pass set to analyze %lu samples, stop feeding
%s Phrase detector result: %@
%s SpkrId:: Failed to create SSRSpeakerRecognizerPSR
%s SpkrId:: %@::uniqueUttTag: %@, extraSamplesAtStart: %lu, _tdEndInSampleCount: %lu(%f ms)
%s SpkrId:: CSSpIdVTSpeakerRecognizer dealloc
%s SpkrId:: Discarded ScoreCard for mismatch session - {%{public}@, %{public}@}
%s SSROrch[%{public}@]:: Failed to create PSR Recognizer
%s SSROrch[%{public}@]:: Failed to create SAT Recognizer
%s SSROrch[%{public}@]:: Successfully initialized with {%{public}@, %{public}@}
%s SpkrId:: Released OS transaction for %{public}@
%s SSROrch[%{public}@]:: Ignoring addAudio, endAudio: %d procSamples: %lu maxProcSamples: %lu
%s SSROrch[%{public}@]:: Released OS transaction for %{public}@
%s SSROrch[%{public}@]:: Creating OS transaction for %{public}@
%s SSROrch[%{public}@]:: Scorecard %{public}@ with delay:%{public}ldms, processed:%{public}ldms, await:%{public}ldms
%s ERR: Posting diagnostic report for abnormal score delay - %ldms
%s SSROrch[%{public}@]:: Sync score report with %{public}f delay - with known user scores %{public}@
%s SSROrch[%{public}@]:: ERR: VoiceInfo is nil from recognizer %{public}@
%s SSROrch[%{public}@]:: Discarded speaker scores for session - %{public}@
%s SSROrch[%{public}@]:: EndAudioCalled is false, returning for recognizer %{public}@
%s SSROrch[%{public}@]:: PSR Analyzer finished the session with %{public}@
%s SSROrch[%{public}@]:: SAT Analyzer finished the session with %{public}@
%s SSROrch[%{public}@]:: Wait for %{public}@ analyzer to complete the session - %{public}@
%s SSROrch[%{public}@]:: FilePath:%@, combinedScores - %{public}@
%s SSROrch[%{public}@]:: Finished the session with known user scores %{public}@
%s SSROrch[%{public}@]:: Discarded speaker scores for session
%s SSROrch[%{public}@]:: Speech started at - %ldms
%s SSROrch[%{public}@]:: Starting a new segment of speech - %ldms
%s SAT Supervector created
%s Skipping PHS DES record creation
%s ERR: failed to create PHS DES recored with error: %@
%s Failed to create PHS DES record: %{public}@
%s Created PHS DES record with identifier: %{public}@
%s %@
%s Remote device type: %zu, Remote device UUID list: %{private}@
%s CSVoiceTriggerAsset found: %{public}@
%s Locale: [%{public}@]
%s No locale set when creating phrase spotter.
%s Creation of Keyword Detector failed.
%s %s async called
%s %{public}s async called
%s Waiting for didStop
%s Done waiting for didStop
%s Called before completion called
%s %{public}s Called
%s BEGIN num:%{public}ld use:%{public}d
%s AudioSession setup failed
%s Has wrong audio routing, ask user to unplug headset
%s Start Audio Session failed
%s Resetting zero counter
%s _sessionNumber [%{public}ld]
%s CoreSpeech received the UUID from UI: %@
%s %{public}s Canceling Training
%s Called with status : %{public}d
%s %{public}s called
%s AudioSession StartRecording Failed
%s Setting suspendAudio:[%{public}d]
%s Resume training
%s Suspend training
%s Stop Listening
%s ERR: Failed to save explicit utterance
%s audioSessionDidStopRecording
%s ERR: SpeakerRecognition is not available on this platform
%s Creating audioRecorder has failed
%s AudioRecorder creation failed : %@
%s AudioStream Handle ID is invalid : %{public}@
%s audioRecorder %p created
%s Cannot prepare since audio recorder does not exist
%s Failed to activate audio session, error : %{public}@
%s AudioRecorder is already recording, do not prepare anymore
%s Failed to prepareAudioStreamRecord : %{public}@
%s Failed to startAudioStream : %{public}@
%s failed to stopRecording : %{public}@
%s audioInput:[%@]
%s audioOutput:[%@]
%s ERR: voiceProfile is nil - Bailing out
%s ERR: Failed to create TriggerPhraseDetector in %{public}@ with %{public}@
%s ERR: Failed in trigger processing %{public}@ with %{public}@
%s Trigger Score %{public}f not satisfied implicit VT threshold %f
%s Using recognizer scale factor: %f for phrase detector
%s ERR: Failed to create trigger phrase detectors
%s Processing %{public}@ for trigger word detection
%s ERR: Failed to read file: %@
%s ERR: Failed processing %{public}@ with error %{public}@
%s ERR: %{public}@
%s Best trigger score for %{public}@ is %{public}f (%{public}f, %{public}f)
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s Sending Analytics Event - %{public}@
%s Processing onboarded Siri user: %{public}@
%s Detected matching %{public}d users: %{public}@
%s Valid profile not found %{public}@ and %{public}@ - defaulting to %{public}@
%s Adding invalid user for deletion - %{public}@
%s Skipping retaining user %{public}@
%s Detected invalid user: %{public}@
%s File path doesnt exist - %{public}@
%s ERR: Failed reading contents of SAT root %{public}@ with %{public}@
%s App domains in use - %{public}@
%s ERR: Failed determining if file is dir-entry url=%{public}@ with %{public}@
%s Deleting invalid file %{public}@
%s Deleting invalid domain %{public}@ not part of domains %{public}@
%s Processing domain - %{public}@
%s Found profile %{public}@ with no enrollment utts
%s Deleted voiceprofile with error %{public}@
%s ERR: Failed reading AppDomain %{public}@ at %{public}@ with %{public}@
%s Processing locale - %{public}@
%s Deleting invalid locale %{public}@ not supported in set %{public}@ and current language %{public}@
%s Processing profile - %{public}@
%s Deleting invalid profile %{public}@
%s Removing Implicit utterance cache directory at %{public}@
%s Processing profile %{public}@ with version %{public}d and identity %{public}@
%s Found legacy voice profile - Skipping
%s Deleting invalid SAT entry: %{public}@
%s ERR: Failed to get atrributes of file %{public}@, err %{public}@, size %{public}llu
%s Deleting invalid SAT entry: %{public}@ %{public}@
%s Found non-meta file: %{public}@
%s Deleting invalid SAT entry: %{public}@ : <%{public}@>
%s Processed %{public}@ with %{public}d explicit and %{public}d implicit utterances
%s ObsoleteCutOffDate is nil - Bailing out
%s Checking payload utterances prior to %{public}@ for profile %{public}@ and modelType %d
%s Deleting lifetimeexpired SAT entry %{public}@
%s Deleted lifetimeexpired metafile %{public}@
%s Deleting model file %{public}@ with err %{public}@
%s CSVTUI continuousZeros detected.
%s CSVTUI continuousZeros not detected.
%s SpkrId:: ERR: missing arguments to create voice profile - Bailing out
%s Importing %{public}@ of %{public}@ from import Dir %{public}@
%s Successfully imported %{publice}@ %{public}lu(%{public}lu) utterances to profile %{public}@
%s Failed in importing %{public}@ of %{public}@ from import Dir %{public}@
%s Copied %{public}@ to %{public}@ with error %{public}@
%s Copied TD audio files %{public}lu to TDTI which now has %{public}lu(%{public}lu) utterances
%s Error to copy utterance from %{public}@ to %{public}@, error: %{public}@
%s Copied Utterance from %{public}@ to %{public}@
%s Error to copy jsonFile from %{public}@ to %{public}@, error: %{public}@
%s Successfully copied %{public}lu(%{public}lu) utterances to profile %{public}@
%s ERR: date is nil - Bailing out
%s Filtered %@ with enrolled date %@
%s Couldn't delete invalidated speaker model at path %{public}@ %{public}@
%s ERR: Removing %{public}@ as explicit utterances %{public}d from audio dir - %{public}@
%s SAT path doesnt exist - %@
%s Coudn't mark SAT enrollment %{public}@ at path %{public}@
%s Marked SAT enrollment %{public}@ at path %{public}@
%s We can't mark SAT %{public}@ when there is no audio directory
%s ERR: Unknown device-category for device: %{public}@
%s Unable to read data from file: %@
%s Could not read existing %@ file: err: %@
%s ERR: error creating updatedVoiceProfileJsonData from: %@, err: %@
%s ERR: error removing voice profile version file at: %@, err: %@
%s ERR: Error writing voice profile version file at: %@, err:%@
%s ERR: Profile dict is nil - Bailing out
%s ERR: error updating updatedVoiceProfileJsonData from: %@, err: %@
%s ERR: Failed initialization in _EARSyncSpeechRecognizer initWithConfiguration
%s ERR: processAudioChunk failed
%s ERR: endAudio failed
%s SpkrId:: Unknown CSSpIdType string: %@
%s ERR: Unknown CSSpIdType: %lu
%s Unknown CSSpIdType: %lu
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s SpkrId:: Exceeded privacy limit for grading utterances : %ld (%d)
%s ERR: reading contents of gradingDir: %{public}@ with error %{public}@
%s Deleting orphaned grading file %{public}@
%s SpkrId:: VoiceId not supported in language %{public}@
%s SpkrId:: ERR: filePath passed as nil - Bailing out
%s SpkrId:: ERR: Could not read existing %@ file: err: %@
%s SpkrId:: ERR: %@ is a directory
%s SpkrId:: ERR: file do not exist - %@
%s Unknown Device category for deviceProduceType: %@
%s ERR: Unknown device. returning false: %{public}@
%s ERR: satLanguagePath is nil. returning false
%s Voice Profile Mismatch - CurrentDeviceCategory %@ VoiceProfileCategory %@
%s Malformed audio-dir URL for string <%{public}@>:url
%s ERR: reading contents of audioDir: %{public}@
%s No jsonFiles found in %{public}@: jsonFiles.count=%{public}lu
%s Unexpected: empty JSON data for file: %{public}@
%s Error reading metaDict at path: %{public}@
%s metaProductType: %{public}@
%s vtprofile: currDevice=[%{public}@:%{public}@] ; vpDirDevice=[%{public}@:%{public}@]
%s VoiceProfile MATCH
%s VoiceProfile MIS-MATCH
%s Could not find productType in VT-Meta file, trying next one
%s No compatible VT profile found for CurrDevice: %{public}@
%s ERR: fetching contents of %{public}@ failed with error %{public}@
%s ERR: Directory is nil - Bailing out
%s ERR: %{public}@ doesnt exist - Bailing out
%s Dump content of %{public}@ - %{public}@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: Seeing more than one voice profiles for Siri App Domain
%s SpkrId:: uttMetaPath is nil!
%s SpkrId:: scoreCard is nil!
%s SpkrId:: Error creating uttMetaJsonData: %@
%s SpkrId:: Failed to create UttMeta...
%s Setting payloadstartSample %lu for trigger duration of %fsecs
%s ERR: Setting max payloadstartSample %lu for trigger duration of %fsecs
%s Failed to read file: %@
%s Deleted file %{public}@
%s EOF: utteranceLength: %lums, tdlength: %lums tdtiLength: %lums tdtiDiscardedLength: %lums
%s satAudioDirectory is nil - Bailing out
%s metaVersionFile %{public}@ doesnt exist
%s Found %{public}d ambiguous explicit utterances
%s metaVersionFile %{public}@ doesnt exist - Skipping
%s ERR: Fetching contents of %{public}@ failed with error - %{public}@
%s ERR: Failed to delete %{public}@ with error %{public}@
%s ERR: Scores for profileId %{public}@ not present in %{public}@ - Skipping
%s Called with explicit spId type %{public}d - Bailing out
%s Voice Profile pruning cookie from Asset %{public}@ lastCookie %{public}@
%s Pruning cookie unavailable from asset - Bailing out
%s Already pruned voice profile - Bailing out
%s ERR: Failed updating pruning cookie
%s Explicit utterances: %{public}@, Implicit utterances: %{public}@
%s ERR: No explicit utterances!!! - Bailing out
%s ERR: Low explicit utterances - Bailing out
%s Zero implicit utterances - Bailing out
%s Pruning(1)::----------------------------- Retrain profile to create explicit model ---------------------------------------
%s ERR: Failed to create SSR context with error %{public}@ - Bailing out
%s Pruning(2)::----------------------------- Check Explicit Utterance scores ---------------------------------------
%s Low Score Explicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Explicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f(%{public}.3f) C:%{public}.3f
%s ERR: Detected explicit utterances with lower scores, Bailing out
%s Pruning(3)::----------------------------- Implicit selection ---------------------------------------
%s ERR: ScoreCard is nil in voice profile pruning - Bailing out
%s Deleting low Score Implicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Implicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Pruning(4)::----------------------------- Implicit sampling ---------------------------------------
%s Utterance selection totalImplicit: %{public}lu selectionIndex: %{public}lu retentionCount: %{public}lu deleteCount: %{public}lu 
%s Deleting implicit utterances(%lu) - %{public}@
%s Pruning(5)::----------------------------- Retrain the voice profile ---------------------------------------
%s ERR: creating pruning voice profile failed with %{public}@
%s ERR: Failed in processing %{public}@ with %{public}@
%s ERR: %@
%s Deleting %{public}@
%s %{public}@
%s Skipping SAT Model {%{public}@, %{public}@} for %{public}@
%s Skipping model {%{public}@, %{public}@} for %{public}@
%s Added model context {%{public}@, %{public}@} for %{public}@
%s ERR: uttPath is nil -  Bailing out
%s ERR: uttPath is nil - Bailing out
%s ERR: uttMeta is nil - Bailing out
%s ::: Error creating json Metadata: %{public}@
%s ERR: uttMetaURL is nil, defaulting to NO
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s ERR: uttMetaURL is nil - Bailing out
%s metaData is nil for %{public}@ - Bailing out
%s ERR: read metafile %{public}@ failed with %{public}@ - Bailing out
%s ERR: metaDict from file %{public}@ isnt a dictionary - %{public}@
%s ERR: %{public}@ is not present
%s ERR: Unexpected. metaVersionFileData is empty while the file exists at: %{public}@
%s Json-Err reading metaVersionFile: %{public}@: err: %{public}@
%s ERR: filePath is nil!
%s Testing [%@] against regex.
%s Fired VoiceTrigger Timeout
%s Stop right now since ASR has issue
%s EOS Timeout Fired
%s Force endpoint fired
%s Discarding surplus audio of %{public}lu samples, audio sample available %{public}lu (%{public}lu, %{public}lu, %{public}lu)
%s AudioSession Started
%s AudioSession Stopped
%s Begin of speech detected
%s End of speech detected with endpoint type: %{public}ld
%s unknown endpoint type
%s Called with status : %{public}d and success : %{public}d utteranceStored : %{public}d
%s ERR: Failed to store utterance, overiding status
%s Non Final: [%{public}@]
%s NON Final Matching
%s Final: [%{public}@]
%s Final Matching
%s Final Not Matching
%s SPEECH RECOGNITION TASK FINISH UNSUCCESSFULLY
%s %{public}@ %{public}@ %{public}ld %{public}@
%s Recog Result: [%{public}ld]
%s closeSession tracking bool, calling old completion
%s returning status to UI : %{public}d
%s Already reported status or no callback
%s Will suspend training
%s Will resume training
%s Decide to delay ending ASR: [%{public}ld] samples
%s Triggered! Event info: %{public}@
%{public}9lld %{public}9lld %{public}9lld
%s analyzing.... score so far: %{public}5.3f (%{public}ld)
%s feeding tailing: [%{public}ld] samples
%s correctSampleSize:    [%{public}ld]
%s accumSampleSize:      [%{public}ld]
%s startBufferIndex:     [%{public}ld]
%s startBufferSampleSize:[%{public}ld]
%s samplesToBeDeleted:   [%{public}ld]
%s Total Number of buffs:[%{public}ld]
%s Adjusting the start buffer
%s Adjusting the array elements
%s Unsupported
%s %{public}s CALLED
%s Master Timeout Fired
%s recognized text = %{public}@
%s sharedVoiceProfileManager already instantiated with a different endpointUUID. existing-endpointUUID:%@ requested-endpointUUID:%@
%s ERR: Profile not available for %{public}@ & %{public}@ - Bailing out
%s ERR: No configured Siri Profiles
%s ERR: More than one Siri Voice Profiles - %{public}@
%s ERR: Failed to add profile into the store with error %{public}@
%s isImplicitTraining required for profileId %{public}@, locale(%{public}@) ? %{public}@
%s Implicit training not needed since: asset(%{public}@), profileStore(%{public}@), profile(%{public}@), profile locale(%{public}@)
%s ERR: Finished implicit training for %@ with error %{public}@
%s Finished implicit training for %@
%s Received implicit utterance for %{public}@ from %{public}@ with context %d
%s ERR: FilePath is nil - Bailing out
%s ERR: Training utterance doesnt exist at %@ - Bailing out
%s ERR: Training utterance is marked as directory at %@ - Bailing out
%s VoiceTriggerEventInfo is nil - Bailing out
%s kVTEILanguageCode is nil - Bailing out
%s ERR: trigger score not found in VTEI - Bailing out
%s ERR: SAT did not trigger!!! - Bailing out
%s Failed to add implicit training utterance to remote, error: %{public}@
%s Using asset %{public}@ provided by caller
%s Implicit training not enabled for %{public}@
%s sharedSiriId is nil - Bailing out
%s Rejecting barge-in utterance from adding to voice profile
%s Privacy disallowed implicit utterance %{public}@ - skipping
%s ERR: Failed to segment %{public}@ with %{public}@ - Bailing out
%s Processed implicit utterance %{public}@ successfully
%s Voice Profile is full - Ignoring
%s Implicit Policy not satisfied - Ignoring
%s ERR: Failed to process implicit utterance %{public}@ with error %{public}@
%s Enrolling voice profile of %@ 
%s Skipping download for voice profile: %{public}@
%s Failed enrolling %@ with error %@
%s Failed to get device hash list %{public}@
%s Processing sync data from device hash: %{public}@
%s Skipping language [%{public}@] since we already have enrollment data for this language
%s Skipping language [%{public}@] as file path doesnt exist - %{public}@
%s Skipping language [%{public}@] as voice profile not compatible
%s Error to copy profile from %{public}@ to %{public}@, error: %{public}@
%s Adding voiceprofile for %{public}@ in language %{public}@ completed with error %{public}@
%s ERR: Failed migrating Voice profile for language %{public}@ with error %{public}@
%s Successfully added %{public}@ in %.2fms
%s language: %{public}@, enableVTAfterSyncLanguage: %{public}@, currSiriLanguage: %{public}@
%s Enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@ and enrolled language: %{public}@
%s VoiceTrigger does not exist for this platform, not setting VoiceTriggerEnabled
%s Not enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@
%s Sucessfully migrated language %{public}@
%s Migrated language %{public}@ but failed to mark SAT enrollment
%s Sucessfully marked as migrated for language : %{public}@
%s Failed to mark migrated for language : %{public}@
%s Failed to remove update path [%{public}@] upon migration completion, error: %{public}@
%s Skipping download for unsupported OS
%s Skipping download for tvOS when shared id is nil
%s Skipping download for language [%{public}@] since we already have enrollment data for this language
%s Failed to download voice profile with error %{public}@ and category %{public}@ 
%s Successfully enrolled voice profile %@ with %{public}@ profile
%s Triggering profile sync check
%s Skipped enrolling voice profile %@ with %{public}@ profile
%s ERR: Failed in enrolling Voice profile %@ with category %{public}@ profile
%s Failed to enroll siriProfileId %@ with %{public}@
%s endPointId:%@, currentLanguageCode:%@
%s Language %{public}@ not supported in %{public}@ - Skipping
%s Skipping profile download for %{public}@ - %{public}@ not matching current %{public}@
%s Skipping profile download for %{public}@ - voiceId not supported in %{public}@
%s ERR: Failed migrating Voice profile with ID %{public}@ for language %{public}@ with error %{public}@
%s Sucessfully enrolled %{public}@ for language %{public}@
%s PHS update directory already exists, remove before we move forward
%s Failed to delete PHS update directory
%s Failed to create PHS update directory
%s Upload of Voice Profile for %@ completed with error %{public}@
%s Upload of Voice Profile for %@ completed successfully
%s ERR: Failed to delete existing SATUpload diretory : %{public}@
%s Upload trigger of voice profile of %@ 
%s Upload not supported on %{public}@
%s Legacy upload API called on Horseman - Bailing out
%s Cannot delete existing SATUpload Diretory : %{public}@
%s Cannot create SAT Upload Directory : %{public}@
%s Cannot create %{public}@ with error %{public}@ - Skipping language
%s Cannot create directory(%{public}@)
%s Cannot copy file: %{public}@ to %{public}@
%s ERR: siriProfileId is nil - Bailing out
%s Unsupported languagecode %{public}@ in %{public}@ - Skipping
%s Skipping uploading %{public}@ legacy version (%lu) of voice profile, current version %lu
%s Skipping uploading %{public}@ voice profile for profileId %@
%s Skipping audiocache file %@
%s Cannot copy file %{public}@ to %{public}@ with error %{public}@
%s ERR: Failed to copy from %{public}@ to %{public}@ with error %{public}@
%s ERR: Cannot copy file %{public}@ to %{public}@ with error %{public}@
%s Successfully copied {%{public}d,%{public}d} utterances from %@ to %@
%s Cannot copy voice profile from %@ to %@ with error %{public}@
%s Triggering upload of voice profile %@
%s Upload of voice profile at %@ with category %{public}@ completed successfully
%s Triggering upload of explicit voice profile %@
%s Upload of explicit voice profile at %@ completed successfully
%s Setting VoiceProfile Training Sync for language: %{public}@
%s ERR: %{public}s: Bailing out as language is nil!
%s VoiceProfile training sync language: %{public}@, VoiceProfile language: %{public}@
%s ERR: Unknown device - returning nil
%s NonAOP device-category - returning nil
%s ERR: Fetching cached devices resulted in error %{public}@
%s Devices with voice profile is nil!
%s Skipping %{public}@ not locally present
%s ERR: error creating profilesJsonData: %@, err: %@
%s Cached devices with VoiceProfile in iCloud: %{public}@
%s CachedVoiceProfileFetch: Done Waiting with timedOut=%ld, waitTimeMs: %fms
%s ERR: metaBlob is nil. Returning false, language: %{public}@
%s ERR: Unknown device. Returning false, language: %{public}@
%s ERR: Unknown device-category for device: %{public}@, languageCode: %{public}@
%s ERR: Failed to deserialize metaBlob with error %{public}@
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in metablob %{public}@
%s currDevice=[%{public}@ : {%{public}@}] ; syncedDevice=[%{public}@ : {%{public}@}]
%s CurrDevice: [%{public}@ : {%{public}@}] DOES NOT have VoiceProfile synced in iCloud
%s Triggering VoiceProfile upload for %{public}@
%s Querying VoiceProfile upload state on %{public}@
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in devices %{public}@
%s VoiceProfile available locally for %{public}@, not uploaded yet
%s Searching for synced-VoiceProfile for CurrDevice: %{public}@{%{public}@}
%s Will Enable VoiceTrigger after VoiceProfile sync for language: %{public}@
languageCode: %{public}@
%s Devices with VoiceProfile in iCloud for language: %{public}@:%{public}@
%s Timedout waiting for AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage: %{public}ld, waitedFor: %{public}d, Returning nil
%s timeToRet(AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage:): %{public}fms
%s voiceProfileArray is nil for %{public}@ and %{public}@!
%s voiceProfileArray is nil!
%s Profiles already migrated, check for enrollment on %{public}@ on profile %{public}@
%s ERR: Failed to delete Voice Profile %{public}@ with error %{public}@
%s Couldn't delete SAT directory at path %@ %@
%s Couldn't delete SAT cache directory at path %@ %@
%s No Audio file exists when enrollment marker is set, remove marker
%s Contents of audio dir - %{public}@
%s Language Code is nil!
%s No completionBlock provided to importVoice Profile
%s fileList - %@
%s ERR: Fetching contents of %@ failed with error - %@
%s wavList - %@
%s Adding utterances to profileID: %@ finished with err: %@
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s Failed to teardown AVVC : %{public}@
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s toConfiguration : %{public}d
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s ERR: Failed to create asset providers - Bailing out
%s parsing provider: %@ name: %@
%s ERR: got nil assets from provider: %@
%s Got asset with version: %@ from provider: %@
%s ERR: Asset not available from provider: %@
%s SpkrId:: Scorecard for {%{public}d, %{public}.2fsec %dms} - %{public}@
%s SpkrId:: %@
%s SpkrId:: Discarded speaker scores for session - %{public}@
%s SpkrId:: Final - %@
%s Locale doesn't match, return nil
%s ::: found %{public}lu installed assets for matching query: %{public}@
%s ERR: Failed to asset for %{public}@
%s Error running query: %{public}@, error: %{public}lu
%s Failed to get assetString for assetType %{public}d
%s ::: found %{public}lu assets matching query: %{public}@
%s Error running asset-query: %{public}@, error: %{public}lu
%s Asset state : %{public}ld
%s Chosen Asset %{public}@
%s SpkrId:: ERR: appDomain passed as nil
%s SpkrId:: ERR: locale passed as nil
%s Profiles already migrated - Bailing out
%s Migration of voice profile is triggered...
%s Sat directory doesnt exist %@
%s Language %{public}@ not supported in %{public}@ - Deleting
%s Migrating voice profiles in languages - %{public}@
%s Voice profile migration for language - %{public}@
%s Skipped migrating non-siri landed profile - %{public}@, %{public}@
%s voice profile created is nil!!! - Skipping %{public}@
%s Moving contents from %{public}@ to %{public}@ failed with error %{public}@
%s Completed migrating voiceprofile for %{public}@ in language %{public}@
%s Triggered cleanup duplicated profiles
%s ERR: Deleted duplicated voiceprofile(%lu): %{public}@
%s Found %{public}d duplicated profiles
%s Deleted invalid Siri profile with err: %{public}@
%s Triggering voice profiles download
%s ERR: Failed retraining LiveOn onboarded users with error %{public}@
%s Successfully retrained LiveOn onboarded users
%s Cleanup model files with assets %{public}@
%s Synchronize voiceprofiles with Assistant...
%s ERR: Deleted stale voiceprofile(%lu): %@
%s Missing user models - Triggering voice profiles download
%s Needs retraining - Triggering voice profiles download
%s Skip SAT retrainer since combination weight is 1
%s ERR: Failed in adding %{public}@ to %{public}@ with error %{public}@
%s Added Implicit SAT vector from %{public}@ to profile %{public}@
%s Locale is nil - Bail out
%s assetForLocale is nil - Bail out
%s ERR: Failed purging profile %{public}@ with error - %{public}@
%s ERR: Failed to get top scorer in %{public}@ - Bailing out
%s ERR: Utterance scored %{public}f (%{public}@) with next top score %{public}f (%{public}@) for profileId %{public}@
%s Utterance scored %{public}f (%{public}@) with next top score %{public}f (%{public}@) and thresholds (%{public}f, %{public}f)
%s Utterance scored %{public}f for %{public}@ and thresholds (%{public}f, %{public}f)
%s Skipping retraining for language %{public}@, current %{public}@
%s Detected mean pitch for explicit utterances = %{public}f Hz
%s Deleting VoiceProfile %{public}@
%s Err: %@
%s Needs Retraining Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Needs Retraining storage for Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Skipping Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Needs Retraining %{public}@ model update for profile %{public}@ 
%s Retraining %{public}@ for locale %{public}@
%s Needs retraining %{public}@ - Triggering voice profiles download
%s Retraining successfully finished for %{public}@ in %{public}fms
%s ERR: Retraining failed for %{public}@ with error %{public}@ in %{public}fms
%s voiceProfile is nil!
%s Adding User Voice Profile %@
%s Updating User Voice Profile to %@ from %@
%s Deleting User Voice Profile %@
%s User Voice Profile not found %@ - Bailing out
%s ERR: UserVoiceProfile Action undefined %ld - Bailing out
%s Updating profile %{public}@ with userName %{public}@
%s Retraining for locale %{public}@ with force %d
%s Retraining finished for %@ with error %@ in %fms
%s Creating OS Transaction %p for %{public}@
%s No Implicit audio - ignoring filterToVoiceTriggerUtterances
%s ERR: ignoring filtering option as %{public}@ or %{public}@ is nil
%s ERR: ignoring filtering option as VTAssets not found on %{public}@
%s ERR: Failed training %{public}@ of %{public}@ with error %{public}@
%s Failed to create %{public}@ model with error %{public}@ for profile %{public}@
%s Releasing OS Transaction %{public}@
%s Skipping retraining for %{public}@ - for {%{public}@, %{public}@}
%s ERR: Failed resetting for %{public}@ - for {%{public}@, %{public}@}
%s ERR: Failed in retraining %{public}@ with error %{public}@
%s ERR: Failed to delete the model at %{public}@
%s Added utterance %{public}@ to {%{public}@, %{public}@, %{public}@, %{public}@} with score %{public}@
%s Rejected utterance %{public}@ with error %{public}@
%s Failed to create biometricdevice with error %@
%s triggerTimeStamp is nil - Bailing out
%s Biometric match happened in last %f secs
%s Biometric match result: %@ happened in last %f secs
%s No biometric information available
%s BiometricMatchEvent: result = %u, timeStamp = %llu
%s BiometricMatchEvents unavailable with error %@
%s ERR: Biometric device is nil - Bailing out
%s Saving utterance and meta as %{public}@ training.
%s Failed to write utterance into %{public}@
%s Saving %{public}@ at %{public}@ as %{public}@ training.
%s numSamplesToWrite %{public}lu
%s Failed to get CSAudioFileWriter:
%s Failed to addSamples to CSAudioFileWriter: %{public}@
%s Failed to endAudio on CSAudioFileWriter: %{public}@
%s ERR: called with nil metaPath
%s ERR: called with nil uttPath
%s ERR: called with nil uttMeta
%s Cannot create json file : %{public}@
%s endpointUUID: %{public}@
%s Skipping Model {%{public}@, %{public}@} for %{public}@
%s Skipping Model {%{public}@, %{public}@} as file doesnt exist at %{public}@
%s ERR: triggering profile retrain for asset %{publiic}@
%s PHS threshold for %lu doesn't exist, use default
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
333333
softlink:r:path:/System/Library/PrivateFrameworks/BiometricKit.framework/BiometricKit
CSVTUIEndpointAnalyzer
AVVC
SSRVoiceActivityDetector
EARCaesuraSilencePosteriorGeneratorDelegate
NSObject
CSVTUITwoPassKeywordDetector
SSRSpeakerAnalyzerPSR
SSRSpeakerRecognizerPSR
SSRSpeakerAnalyzerPSRDelegate
SSRSpeakerRecognizer
SSRTriggerPhraseDetectorNDAPI
SSRSpeakerRecognitionOrchestrator
SSRSpeakerRecognizerDelegate
SSRVoiceActivityDetectorDelegate
SSRVoiceProfileRetrainerSAT
SSRVoiceProfileRetrainer
SSRDESRecordWriter
SSRSpeakerRecognitionScorer
SSRVTUITrainingManager
CSVTUITrainingSessionDelegate
CSVTUIAudioSessionDelegate
CSVTUIEndpointAnalyzerDelegate
SSRVoiceProfileRetrainerFactory
CSVTUIAudioSessionRecorder
CSVTUIAudioRecorderDelegate
CSVTUIAudioSession
SSRVoiceProfileMetaContext
SSRTriggerPhraseDetector
CSAsset
SSRRemoteControlClient
LanguageCode
SSRTrialAssetProvider
SSRAssetProviding
CSVTUIKeywordDetector
SSRVoiceProfileComposer
SSRVoiceProfileRetrainerPSR
SSRLoggingAggregator
RecordContext
SSRSpeakerRecognizerSAT
SSRVoiceProfileStoreCleaner
CSVTUIRemoteRecordClient
CSVTUISelfLoggingDigitalZeroReporter
CSDigitalZeroReporting
SSRVoiceProfile
NSSecureCoding
NSCoding
SSRTriggerPhraseDetectorQuasar
SSRUtils
CSVTUIEditDistance
SSRVoiceProfilePruner
SSRSpeakerRecognitionControllerDelegate
SSRVoiceProfileRetrainingContext
SSRVoiceProfileModelContext
SSRVoiceProfileMetadataManager
CSVTUIRegularExpressionMatcher
CSVTUITrainingSessionWithPayload
SFSpeechRecognitionTaskDelegate
CSVTUIEndPointDelegate
CSVTUITrainingSession
SSRVoiceProfileManager
debugDescription
CSVTUIAudioRecorderRemoteDeviceContext
CSVTUIAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
SSRAssetManager
SSRSpeakerRecognitionController
SSRSpeakerRecognitionOrchestratorDelegate
SSRMobileAssetProvider
SSRVoiceProfileStore
SSRBiometricMatch
BKDeviceDelegate
SSRSpeakerAnalyzerSAT
SSREnrollmentDataManager
SSRVoiceProfileStorePrefs
SSRSpeakerRecognitionContext
SSRSpeakerRecognitionModelContext
CSVTUIASRGrammars
NSURLSessionDelegate
SSRPitchExtractor
SSRAESKeyManager
SpeakerRecognition
AudioHardware
CSVTUITrainingResult
CSVTUITrainingSessionStopListen
CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:
T@"NSNumber",&,N,V_profilePitch
JSONObjectWithData:options:error:
T@"NSString",&,N,V_sharedSiriId
SSRSpeakerProfilesBasePath
TQ,N,V_spIdType
SSRVoiceActivityDetector:didDetectStartPointAt:
_CSSATCachePath
T@"<CSAudioFileWriter>",&,N,V_ssrUttLogger
_cleanupOrphanedMetafilesAtURL:
T@"<CSVTUIEndpointAnalyzerDelegate>",W,N,V_delegate
_configFilePath
T@"<SSRAssetManagerDelegate>",W,N,V_delegate
_detectorQuasar
T@"<SSRSpeakerRecognitionOrchestratorDelegate>",W,N,V_delegate
_endAudioCalled
T@"<SSRSpeakerRecognizer>",&,N,V_satRecognizer
_getVoiceTriggerAssetTypeString
T@"<SSRVTUITrainingManagerDelegate>",W,N,V_delegate
_interleavedABL
T@"BKDevice",&,N,V_biometricDevice
_mhUUID
T@"CSAudioPowerMeter",&,N,V_powerMeter
_phraseDetector
T@"CSVTUIAudioRecorderRemoteDeviceContext",&,N,V_remoteDeviceContext
_retrainVoiceProfile:withAsset:
T@"NSArray",&,N,V_assetProviders
_sessionProcess
T@"NSArray",&,N,V_voiceProfileArray
_stringByStrippingLeadingNoise:
T@"NSDate",&,N,V_dateAdded
audioFileWriter
T@"NSDictionary",&,N,V_combinedScores
bestEnd
T@"NSDictionary",&,N,V_lastSpeakerInfo
bundleForClass:
T@"NSDictionary",&,N,V_psrLastSpeakerInfo
containsObject:
T@"NSDictionary",&,N,V_satLastSpeakerInfo
context
T@"NSDictionary",R,N
dataForChannel:
T@"NSDictionary",R,N,V_expModelsContext
dealloc
T@"NSDictionary",R,N,V_voiceProfilesModelFilePaths
formattedString
T@"NSMutableArray",&,V_voiceProfileArray
getPitchForUtteranceAudioFiles:
T@"NSNumber",&,N,V_version
initWithConfigFilePath:withModelPath:withCompareModelFilePaths:
T@"NSObject<OS_dispatch_queue>",&,N,V_spgQueue
initWithLocale:
T@"NSObject<OS_os_transaction>",&,N,V_transaction
initWithVoiceRetrainingContext:
T@"NSString",&,N,V_currentLanguageCode
isRecordContextHearstDoubleTap:
T@"NSString",&,N,V_debugUtteranceJsonFilePath
isRunningQuasar
T@"NSString",&,N,V_invocationStyleStr
logDigitalZeroDetectionComplete
T@"NSString",&,N,V_productCategory
notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:
T@"NSString",&,N,V_profileId
processingEnded
T@"NSString",&,N,V_transDesc
profileBasePath
T@"NSString",R,C
recognizerScore
T@"NSString",R,N,V_appDomain
remoteDeviceUID
T@"NSString",R,N,V_debugUtteranceAudioFile
results
T@"NSString",R,N,V_deviceId
satConfigFileNameForCSSpIdType:
T@"NSString",R,N,V_profileID
setDefSepFeats:
T@"NSString",R,N,V_psrConfigRoot
setFrameLength:
T@"NSString",R,N,V_siriProfileId
setRms:
T@"NSURL",R,N
setVad:
T@"NSURL",R,N,V_resourceFilePath
spIdCtx
T@"NSURL",R,N,VmodelFilePath
stopMasterTimer
T@"SSRLoggingAggregator",&,N,V_logAggregator
stringByAppendingPathComponent:
T@"SSRSpeakerAnalyzerPSR",&,N,V_psrAnalyzer
stringForSpeakerRecognizerType:
T@"SSRSpeakerRecognitionContext",&,N,V_spIdCtx
updateDebugFilePathsForSegment:
T@"SSRTriggerPhraseDetectorNDAPI",&,N,V_detectorNDAPI
vadResourcePath
T@"SSRVoiceActivityDetector",&,N,V_vad
.cxx_destruct
T@"NSHashTable",&,N,V_observers
CSVTUITrainingSessionRMSAvailable:
T@"NSString",&,N,V_languageCode
SSRBasePathForAppDomain:
T@"NSURL",R,N,V_vadResourcePath
SSRVoiceActivityDetector:didDetectEndPointAt:
TQ,R,N,V_maxAllowedAudioSamples
T#,R
_assetProviders
T@"<CSVTUIAudioSessionDelegate>",W,N,V_delegate
_combinedScores
T@"<CSVTUIRemoteRecordClientDelegate>",W,N,V_delegate
_copyVoiceProfileAtPath:toPath:
T@"<SSRSpeakerRecognitionControllerDelegate>",W,N,V_delegate
_earSpg
T@"<SSRSpeakerRecognizer>",&,N,V_psrRecognizer
_filterToVoiceTriggerUtterances
T@"<SSRSpeakerRecognizerDelegate>",W,N,V_delegate
_homeId
T@"<SSRVoiceActivityDetectorDelegate>",W,N,V_delegate
_locale
T@"CSAsset",&,N,V_asset
_numConsecutiveNonSilenceFrames
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
_resultReported
T@"EARCaesuraSilencePosteriorGenerator",&,N,V_earSpg
_segmentCounter
T@"NSArray",&,N,V_compareVoiceProfileArray
_status
T@"NSArray",R,C,N,V_remoteTrainingDeviceUUIDList
_syncRecognizer
T@"NSDate",R,N,V_dateAdded
baseDir
T@"NSDictionary",&,N,V_lastScoreCard
biometricDevice
T@"NSDictionary",&,N,V_psrFinalSpeakerInfo
clientSilenceFeaturesAvailable:
T@"NSDictionary",&,N,V_satFinalSpeakerInfo
containsString:
T@"NSDictionary",&,N,V_voiceTriggerEventInfo
currentCalendar
T@"NSDictionary",R,N,V_compareModelFilePaths
dateFromString:
T@"NSDictionary",R,N,V_modelsContext
fetchMedicalDataWithCompletion:
T@"NSDictionary",R,N,V_vtEventInfo
getBoolForKey:category:default:
T@"NSNumber",&,N,V_pitch
implicitDiscardedUtteranceIndex
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
initWithLength:
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
initWithString:
T@"NSString",&,N,V_appDomain
isProxy
T@"NSString",&,N,V_debugUtteranceAudioFilePath
isRecordContextHomeButtonPress:
T@"NSString",&,N,V_homeId
lastSpeakerInfo
T@"NSString",&,N,V_locale
lowercaseString
T@"NSString",&,N,V_profileBasePath
numberWithBool:
T@"NSString",&,N,V_sessionId
productCategory
T@"NSString",&,N,V_userName
psrConfigFileNameForCSSpIdType:
T@"NSString",R,N
release
T@"NSString",R,N,V_configVersion
resetEndPointer
T@"NSString",R,N,V_debugUtteranceMetaFile
T@"NSString",R,N,V_locale
setDebugUtteranceAudioFilePath:
T@"NSString",R,N,V_psrConfigFilePath
setEndWaitTime:
T@"NSString",R,N,V_sessionId
setPsrAnalyzer:
T@"NSString",R,N,V_sysConfigRoot
setTransaction:
T@"NSURL",R,N,V_configFilePath
setWithObjects:
T@"NSURL",R,N,V_voiceProfileModelFilePath
ssrAudioLogsDir
T@"NSUUID",&,N,V_endpointUUID
stopRMS
T@"SSRRemoteControlClient",&,N,V_remoteControlClient
stringByAppendingPathExtension:
T@"SSRSpeakerRecognitionContext",&,N,V_context
suspendTraining
T@"SSRSpeakerRecognitionOrchestrator",&,N,V_orchestrator
T@"SSRTriggerPhraseDetectorQuasar",&,N,V_detectorQuasar
version
T@"SSRVoiceProfile",&,N,V_voiceProfile
T@"SSRVoiceProfile",R
T@"SSRVoiceProfileStorePrefs",&,N,V_storePrefs
T@"_EARDefaultServerEndpointFeatures",&,N,V_defSepFeats
T@"_EAREndpointer",&,N,V_hybridClassifier
TB,N,V_endpointReported
TB,N,V_processingEnded
TB,N,V_startpointReported
TB,R
TB,R,N
TB,R,N,V_filterToVoiceTriggerUtterances
TB,R,N,V_forceRetrain
TB,R,N,V_osTransactionReqd
TB,R,N,V_satModelAvailable
TB,R,N,VimplicitTrainingRequired
TB,R,V_speechRecognizerAvailable
TQ,N,V_activeChannel
TQ,N,V_audioStreamHandleId
TQ,N,V_currentDeviceCategory
TQ,N,V_endInSampleCount
TQ,N,V_extraSamplesAtStart
TQ,N,V_myriadResult
TQ,N,V_numSamplesProcessed
TQ,N,V_speakerRecognitionPSRProcessingStatus
TQ,N,V_speakerRecognitionProcessingStatus
TQ,N,V_speakerRecognitionSATProcessingStatus
TQ,N,V_totalNumSamplesReceived
TQ,N,V_voiceProfileDiscardedUtteranceCount
TQ,N,V_voiceProfilePrunedUtteranceCount
TQ,N,V_voiceProfilePruningFailureReasonCode
TQ,N,V_voiceProfileRetainedUtteranceCount
TQ,N,V_voiceProfileRetrainingFailureReasonCode
TQ,N,V_vtEndInSampleCount
TQ,R
TQ,R,N
TQ,R,N,V_activeChannel
TQ,R,N,V_audioStreamHandleId
TQ,R,N,V_maxAllowedSpeakerVectors
TQ,R,N,V_recognitionStyle
TQ,R,N,V_remoteTrainingDeviceType
TQ,R,N,V_scoreType
TQ,R,N,V_spIdType
TQ,R,N,VretrainerType
Td,N,V_retrainingWaitTime
Td,N,V_speakerRecognitionWaitTime
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_voiceProfileUpdateScoreMSE
Tf,R,N
Tf,R,N,V_combinationWeight
Tf,V_rms
Ti,R,N,V_audioStatus
Ti,R,N,V_sessionStatus
Tq,N,V_segmentStartPointSampleCount
Tq,R,N
Tq,R,N,V_sessionId
URLByAppendingPathComponent:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLByDeletingPathExtension
URLSession:didBecomeInvalidWithError:
URLSession:didReceiveChallenge:completionHandler:
URLSessionDidFinishEventsForBackgroundURLSession:
URLWithString:
URLsForDirectory:inDomains:
UTF8String
UUID
UUIDString
VTUITrainingManagerFeedLevel:
VTUITrainingManagerStopListening
_ASRErrorOccured
_ASRResultReceived
_CSSATCachePathForAppDomain:
_CSSATDownloadPath
_CSSATLegacyUploadPath
_CSSATUploadPathForSiriProfileId:
_activeChannel
_analyzerTrailingSamples
_appDomain
_asset
_audioAnalyzer
_audioBuffer
_audioFileWriter
_audioRecorder
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
_audioRecorderDidStopRecordingForReason:streamHandleID:
_audioSession
_audioSource
_audioStatus
_audioStreamHandleId
_audioZeroCounter
_beginOfSpeechDetected
_bestTriggerSampleStart
_biometricDevice
_buildAssetQueryForAssetType:
_caseInsensitiveHasMatchInEnumeration:
_checkIfDownloadRequiredForProfileId:
_checkIfModelsPresentForProfiles:forSpIdType:forAsset:
_checkIfRetrainingRequiredForProfile:
_cleanupAppDomain:
_cleanupCompletion
_cleanupContentsOfSatFolder:
_cleanupImplicitUtteranceCacheForProfile:
_cleanupInvalidAudioFiles:
_cleanupModelFilesAtDir:forAssetArray:
_cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:
_cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:
_cleanuplanguageCodePath:forAppDomain:
_combinationWeight
_compareModelFilePaths
_compareVoiceProfileArray
_compatibilityVersion
_compensateChannelDataIfNeeded:receivedNumChannels:
_configVersion
_context
_continuousZeroCounter
_convertDeactivateOption:
_convertVersionStringToFloat:
_copyExplicitAudio:withSpIdType:
_copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:
_createAudioAnalyzer
_currentAsset
_currentDeviceCategory
_currentLanguageCode
_currentTrainingSession
_dateAdded
_debugUtteranceAudioFile
_debugUtteranceAudioFilePath
_debugUtteranceJsonFilePath
_debugUtteranceMetaFile
_defSepFeats
_delegate
_deleteUserVoiceProfile:
_deleteUtterances:
_destroyAudioSession
_destroyVoiceController
_detectBOS
_detectorNDAPI
_deviceId
_didStopWaitingGroup
_downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:
_downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:
_enableVoiceTriggerIfLanguageMatches:
_endInSampleCount
_endOfSpeechDetected
_endpointReported
_endpointUUID
_enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:
_enrolledVoiceProfiles
_eventContext
_eventString
_expModelsContext
_extraSamplesAtStart
_filteredAssets:forLanguage:
_findLatestInstalledAsset:
_firedEndPointTimeout
_firedVoiceTriggerTimeout
_firstMatchesForRegularExpression:
_firstMatchesForRegularExpressions:
_firstPassResult
_footprint
_forceRetrain
_getBaseMetaDictionaryForUtterancePath:
_getEndpointAssetCurrentCompatibilityVersion
_getEndpointAssetTypeString
_getLMEWithGrammar:withLocale:
_getLastBiometricMatchEvent:atTime:
_getLeadingPatternsWithGrammars:withLocale:
_getPitchHzFromRawData:
_getProfileVersionFilePath
_getRecordSettingsWithRequest
_getRegexPatternsWithGrammars:withUtt:withLocale:
_getSSRAssetCurrentCompatibilityVersion
_getSSRAssetTypeString
_getScoresForAudio:withController:withDetector:forProfile:withCompletion:
_getTopScoringProfileIdFromScores:
_getTrailingPatternsWithGrammars:withLocale:
_getUserVoiceProfileDownloadCacheDirectoryForProfileId:forDeviceCategory:forVoiceProfileVersion:
_getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:
_getUtterancesFromDirectory:
_getVoiceProfilePathsToBeUploadedForSiriProfileId:
_getVoiceProfilesForSiriProfileId:withLanguageCode:
_getVoiceTriggerAssetCurrentCompatibilityVersion
_getVoicingProbFromRawData:
_grammar
_handleDidStopWithReason:
_hasCorrectInputAudioRoute
_hasCorrectOutputAudioRoute
_hasSubstring:
_hybridClassifier
_initializeSPGWithContext:
_initializeWithContext:
_installedMobileAssetOfType:forLanguage:
_invocationStyleStr
_isDirectory:
_isFirstPassTriggered
_isLegacyEnrollmentMarkedWith:forLanguageCode:
_isMarkedForVoiceProfileTrainingSyncForLanguage:
_isMaxNumContinuousZerosOverThreshold
_isRemoteVoiceTriggerAvailable
_isSATMarkedWithMarker:
_keywordAnalyzer
_keywordDetector
_keywordThreshold
_languageCode
_lastKeywordScore
_lastScoreCard
_lastScoreReportTimeStamp
_lastSegmentStartTime
_lastSpeakerInfo
_latestContext
_latestVersionedAssetOfType:fromProviders:forLocale:
_loadVoiceProfiles
_logAggregator
_logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:
_logVoiceProfileConfusionWithCleanup:
_markSATEnrollmentWithMarker:
_markVoiceProfileTrainingSyncForLanguage:
_masterTimer
_matchesRegularExpression:
_maxAllowedAudioSamples
_maxAllowedSpeakerVectors
_maxNumAllowedContinuousZeros
_maxNumContinuousZeros
_modelsContext
_myriadResult
_numRequiredTrailingSamples
_numSamplesAddedToSpeakerRecognizers
_numSamplesFed
_numSamplesProcessed
_numTrailingSamples
_observers
_orchestrator
_osTransactionReqd
_pNonInterleavedABL
_pageNumber
_pcmBufArray
_performRMS
_phId
_pitch
_powerMeter
_prepareVoiceProfileWithSiriProfileId:withUploadBlock:
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_processAudioFileURL:
_processingEnded
_productCategory
_profile
_profileBasePath
_profileID
_profileId
_profilePitch
_psrAnalyzer
_psrConfigFilePath
_psrConfigRoot
_psrFinalSpeakerInfo
_psrLastSpeakerInfo
_psrRecognizer
_queue
_recognitionStyle
_recognizerScoreScaleFactor
_registerEndPointTimeout
_registerForceEndPointTimeout
_registerVoiceTriggerTimeout
_remoteControlClient
_remoteDeviceContext
_remoteRecordClient
_remoteTrainingDeviceType
_remoteTrainingDeviceUUIDList
_reportStopListening
_reportedStopListening
_resetWithContext:
_resourceFilePath
_retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:
_retrainVoiceProfile:withContext:
_retrainVoiceProfile:withContext:withUtterances:
_retrainingWaitTime
_rms
_sampleLengthFrom:To:
_satFinalSpeakerInfo
_satLastSpeakerInfo
_satModelAvailable
_satRecognizer
_saveTrainedUsers:
_scoreType
_segmentStartPointSampleCount
_sessionDelegate
_sessionId
_sessionNumber
_sessionStatus
_sessionSuspended
_setVoiceTriggerEventInfo:
_setupAudioSession
_sharedSiriId
_shouldShowHeadsetDisconnectionMessage
_shouldUseRemoteBuiltInMic:
_siriProfileId
_siriSetupID
_spIdCtx
_spIdType
_speakerRecognitionPSRProcessingStatus
_speakerRecognitionProcessingStatus
_speakerRecognitionSATProcessingStatus
_speakerRecognitionWaitTime
_speechRecognitionRequest
_speechRecognitionTask
_speechRecognizer
_speechRecognizerAvailable
_spgQueue
_ssrUttLogger
_startAudioSession
_startPointReported
_startpointReported
_stopAudioSession
_storePrefs
_stringByFixingNamePattern:
_stringByStrippingNoiseLeadingNoise:TrailingNoise:
_stringByStrippingTrailingNoise:
_suspendAudio
_synchronizeSiriVoiceProfilesWithAssistant
_sysConfigRoot
_totalNumSamplesReceived
_trainingCompletion
_trainingCompletionWithResult
_trainingSessions
_transDesc
_transaction
_updateTrainedUsersWithAction:UserVoiceProfile:
_updateVoiceProfileVersionFile
_userName
_utteranceId
_utteranceStored
_vad
_vadResourcePath
_version
_voiceController
_voiceControllerCreationQueue
_voiceControllerWithError:
_voiceProfile
_voiceProfileArray
_voiceProfileDiscardedUtteranceCount
_voiceProfileModelFilePath
_voiceProfilePathForSpidType:
_voiceProfilePrunedUtteranceCount
_voiceProfilePruningFailureReasonCode
_voiceProfileRetainedUtteranceCount
_voiceProfileRetrainingFailureReasonCode
_voiceProfileUpdateScoreMSE
_voiceProfilesModelFilePaths
_voiceTriggerEventInfo
_vtEndInSampleCount
_vtEventInfo
_waitingForDidStart
_writeMetaDict:forUtterancePath:
absoluteString
activateAudioSessionForStream:isPrewarm:recordMode:error:
activateAudioSessionWithReason:streamHandleId:error:
activationDeviceUID
activationMode
activeChannel
addAudio:numSamples:
addEntriesFromDictionary:
addImplicitTrainingUtteranceToRemoteFilePath:forVoiceProfileId:withVoiceTriggerCtxt:locale:withOtherCtxt:completion:
addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:
addKeyValuePair:with:
addObject:
addObjectsFromArray:
addSamples:numSamples:
addUserVoiceProfile:withContext:withCompletion:
addUtterance:toProfile:
addUtterance:toProfile:withAsset:
addUtterances:spIdType:
addUtterances:toProfile:withContext:withCompletion:
addUtterances:withPolicy:withCompletion:
allInstalledAssetsOfType:forLanguage:
allObjects
analyze:
analyzeSpeakerVector:withDimensions:withThresholdType:
analyzeSuperVector:withDimensions:withThresholdType:
analyzeWavData:numSamples:
announceCallsEnabled
appDomain
appendAudioPCMBuffer:
appendFormat:
appendString:
appendVoiceProfileDiscardedImplicitUtteranceScoreWith:
appendVoiceProfileExplicitUtteranceScoreWith:
appendVoiceProfileFailedExplicitUtteranceScoreWith:
appendVoiceProfileImplicitUtteranceScoreWith:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
asset
assetForAssetType:resourcePath:configVersion:
assetForCurrentLanguageOfType:
assetProvider
assetProviders
attributes
attributesOfItemAtPath:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderDisconnected:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioSessionDidStartRecording:error:
audioSessionDidStopRecording:
audioSessionErrorDidOccur:
audioSessionRecordBufferAvailable:
audioSessionUnsupportedAudioRoute
audioSource
audioStatus
audioStreamHandleId
autorelease
availableDevices
averagePower
avvcContext
avvcContextSettings
bestScore
bestStart
bestTranscription
boolValue
bundlePath
bytes
bytesDataSize
canBePurged
cancelTrainingForID:
channelForProcessedInput
checkIfVoiceProfile:needsUpdatedWith:withCategory:
class
cleanupDuplicatedProfiles
cleanupInvalidModelsForProfile:withAssetArray:
cleanupInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:
cleanupOrphanedVoiceIdGradingFiles
cleanupProfileStore
cleanupVoiceProfileModelFilesForLocale:
cleanupVoiceProfileStore:
cleanupWithCompletion:
closeSessionBeforeStartWithStatus:successfully:completionWithResult:
closeSessionBeforeStartWithStatus:successfully:withCompletion:
closeSessionWithCompletion:
closeSessionWithStatus:successfully:
closeSessionWithStatus:successfully:complete:
closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:
code
combinationWeight
combineScoreFromPSR:fromSAT:withCombinedWt:
combinedScore
combinedScores
compare:
compare:options:
compareModelFilePaths
compareVoiceProfileArray
components:fromDate:
components:fromDateComponents:toDateComponents:options:
componentsSeparatedByString:
composeModelContextsForProfiles:forSpIdType:forAsset:completion:
computeRequiredTrailingSamples
computeTriggerConfidenceForAudio:withCompletion:
confidence
configFilePath
configVersion
conformsToProtocol:
containsCategory:
containsMultiUserThresholds
containsSpeakerRecognitionCategory
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextForVoiceTriggerTraining
convertStopReason:
copy
copyAudioFiles:toProfile:forModelType:
copyItemAtPath:toPath:error:
copyItemAtURL:toURL:error:
copySamplesFrom:to:
count
countByEnumeratingWithState:objects:count:
createAVAudioPCMBufferWithNSData:
createAudioFileWriterForPHSTrainingWithInputFormat:outputFormat:
createDESRecordWithSuperVector:withMetaInfo:
createDigitalZeroReporterWithVoiceTriggerEventInfo:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryIfDoesNotExist:
createFileAtPath:contents:attributes:
createGrammars
createKeywordDetector
createSpeechRecognizer
createVoiceScorersWithVoiceProfiles:withConfigFile:withResourceFile:withOffsetsType:
csAudioProcessingQueuePriority
currentDeviceCategory
currentDirectoryPath
currentHandler
currentLanguageCode
data
dataWithBytes:length:
dataWithCapacity:
dataWithContentsOfFile:
dataWithContentsOfURL:
dataWithJSONObject:options:error:
date
dateAdded
dateWithTimeIntervalSince1970:
dateWithTimeIntervalSinceNow:
deactivateAudioSession:error:
deactivateAudioSessionWithOptions:
debugDescription
debugUtteranceAudioFile
debugUtteranceAudioFilePath
debugUtteranceJsonFilePath
debugUtteranceMetaFile
decision
decodeConfigFrom:
decodeConfigFrom:forFirstPassSource:
decodeObjectOfClass:forKey:
defSepFeats
defaultCenter
defaultManager
defaultServerEndpointFeatures
delegate
deleteAESKeyWithApplicationTag:keyLabel:
deleteAllVoiceProfilesForAppDomain:
deleteInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:
deleteModelForSpidType:recognizerType:
deleteUserVoiceProfile:
deleteVectorAtIndex:
description
destroySpeakerTrainer
detectorNDAPI
detectorQuasar
device:matchEventOccurred:
deviceBuildVersion
deviceCategoryForDeviceProductType:
deviceCategoryStringRepresentationForCategoryType:
deviceId
deviceProductType
deviceProductVersion
deviceWithDescriptor:error:
devicesWithVoiceProfileIniCloudForLanguage:
dictionary
dictionaryRepresentation
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didDetectBeginOfSpeech
didDetectEndOfSpeech:
didDetectForceEndPoint
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
didPlayEndpointBeep
digitalZeroDetected
discardSiriEnrollmentForLanguageCode:
discardSiriEnrollmentForProfileId:forLanguageCode:
domain
doubleValue
dumpFilesInDirectory:
earSpg
enableVoiceTriggerUponVoiceProfileSyncForLanguage:
encodeObject:forKey:
encodeWithCoder:
encryptFileAt:andSaveTo:error:
endAudio
endInSampleCount
endOfSentenceLikelihood
endpointReported
endpointUUID
endpointer:didDetectHardEndpointAtTime:
endpointer:didDetectStartpointAtTime:
enter
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
enumeratorAtPath:
errorWithDomain:code:userInfo:
evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:
expModelsContext
explicitFailedUtteranceIndex
explicitSpIdTypeForSpId:
explicitUtteranceIndex
extraSamplesAtStart
feedSpeechRecognitionTrailingSamplesWithCompletedBlock:
feedSpeechRecognitionWithPCMBuffer
fetchMedicalIDDataWithCompletion:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSize
fileURLWithPath:
fileURLWithPathComponents:
filterDuplicatedSiriProfilesFrom:
filterInvalidSiriProfilesFrom:
filterToVoiceTriggerUtterances
filterVTAudioFiles:withLocale:withAsset:
filteredArrayUsingPredicate:
finish
finishSpeechRecognitionTask
firstMatchInString:options:range:
firstObject
floatValue
forceRetrain
frameLength
generateAESKeyWithKeySizeInBits:
generateIfNecessaryAESKeyWithKeySizeInBits:applicationTag:keyLabel:shouldGenerateIfNecessary:
generateIfNecessaryVoiceTriggerProfilesAESKey
getAESKeyFromKeychainWithApplicationTag:keyLabel:
getAnalyzedResultFromAudioChunk:
getAnalyzedResultFromFlushedAudio
getAnalyzedResultsFromAudioChunk:
getAssetProviderType
getAveragePowerDB
getCSAssetOfType:
getCacheDirectoryForAppDomain:
getCachedVoiceProfileAvailabilityMetaBlob
getContentsOfDirectory:
getCurrentStreamState:
getDevicesWithAvailablePHSAssetsForLanguage:completion:
getDevicesWithAvailablePHSAssetsOnDeviceCheck:
getEnrollmentUtterancesCountFromDirectory:withCountBlock:
getEnrollmentUtterancesForModelType:
getEnrollmentUtterancesFromDirectory:
getExplicitEnrollmentUtterancesForType:
getExplicitEnrollmentUtterancesFromDirectory:
getExplicitMarkedEnrollmentUtterancesForType:
getExplicitMarkedEnrollmentUtterancesFromDirectory:
getFixedHighPrioritySerialQueueWithLabel:priority:
getHomeUserIdForSharedUserId:completion:
getHomeUserIdForVoiceProfile:withCompletion:
getImplicitEnrollmentUtterancesForType:
getImplicitEnrollmentUtterancesFromDirectory:
getImplicitEnrollmentUtterancesPriorTo:forType:
getImplicitUtteranceCacheDirectory
getKeychainAttributesForAESKeyWithApplicationTag:keyLabel:
getLMEforLocale:
getLastBiometricMatchForVoiceTriggerTimeStamp:
getLatestSpeakerInfo
getLatestVoiceRecognitionInfo
getLeadingPatternsForUtt:Locale:
getLocalUrl
getNumberForKey:category:default:
getNumberOfAudioFilesInDirectory:
getRecordDeviceInfoForStream:
getRegexPatternsForUtt:Locale:
getResourceValue:forKey:error:
getSATEnrollmentPath
getSATVectorCount
getSiriLanguageWithEndpointId:fallbackLanguage:
getSiriLanguageWithFallback:
getSpeakerVectorAtIndex:
getStringForKey:category:default:
getSuperVectorWithEndPoint:
getTrailingPatternsForUtt:Locale:
getTrainingAudioStatusWithVTEI:digitalZeroReporter:
getUserVoiceProfileUpdateDirectory
getUserVoiceProfileUploadPathWithEnrolledLanguageList:
getUtteranceEnrollmentType:
getValueForKey:category:
getVoiceProfileAnalyticsForAppDomain:withLocale:
getVoiceProfileForSiriProfileId:forLanguageCode:
getVoiceProfileIdentityFromVersionFilePath:
getVoiceProfileProductCategoryFromVersionFilePath:
getVoiceProfileStoreVersion
getVoiceProfilesForSiriProfileId:
getVoiceRecognizerResults
getVoiceTriggerAssetTypeString
getVoiceTriggerCurrentCompatibilityVersion
getVoiceTriggerProfilesAESKey
getZeroStatisticsFromBuffer:entireSamples:
gregorianBirthday
handleAudioBufferForVTWithAudioInput:withDetectedBlock:
handleAudioInput:
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handleMasterTimeout:
hasAudioRoute
hasCorrectAudioRoute
hasPendingTwoShotBeep
hasPrefix:
hasRemoteBuiltInMic
hasRemoteCoreSpeech
hasSuffix:
hasVoiceProfileIniCloudForLanguageCode:
hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:
hash
hashFromResourcePath
homeId
hybridClassifier
implicitTrainingRequired
implicitUtteranceIndex
importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:
importVoiceProfileAtPath:
init
initNewVoiceProfileWithLocale:withAppDomain:
initStore
initWithAsset:
initWithBundleIdentifier:
initWithBytes:length:
initWithCapacity:
initWithCoder:
initWithCommonFormat:sampleRate:channels:interleaved:
initWithConfigFile:samplingRate:queue:
initWithConfigFilePath:withModelFilePaths:
initWithConfigPath:resourcePath:
initWithConfigPath:resourcePath:phId:
initWithConfiguration:
initWithConfiguration:modelVersion:
initWithContext:delegate:
initWithContext:withDelegate:error:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
initWithDescription:
initWithDeviceId:audioStreamHandleId:
initWithDictionary:
initWithEndpointId:
initWithError:
initWithEvent:locale:configVersion:
initWithHealthStore:
initWithLocale:asset:
initWithLocale:configPath:resourcePath:
initWithLocaleIdentifier:withAudioSession:withAppDomain:
initWithMode:deviceUID:
initWithNumChannels:recordingDuration:samplingRate:
initWithPCMFormat:frameCapacity:
initWithProfileID:withModelFile:withConfigFile:withResourceFile:withOffsetsType:
initWithQueue:error:
initWithRemoteDeviceUUID:
initWithRemoteTrainingDeviceType:remoteTrainingDeviceUUIDList:
initWithSampleRate:
initWithSessionId:sessionStatus:audioStatus:
initWithSharedSiriId:languageCode:productCategory:version:
initWithSiriSetupID:PageNumber:withPhId:
initWithStreamID:atStartHostTime:
initWithStreamID:settings:bufferDuration:
initWithToken:sampleRate:numChannels:
initWithType:
initWithURL:inputFormat:outputFormat:
initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:mhUUID:zeroCounter:completionWithResult:
initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:zeroCounter:completion:
initWithVoiceProfile:
initWithVoiceRecognitionContext:delegate:queue:
initWithVoiceRecognitionContext:error:
initWithVoiceRetrainingContext:error:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
inputRecordingBufferDuration
inputRecordingBytesPerFrame
inputRecordingDurationInSecs
inputRecordingIsFloat
inputRecordingNumberOfChannels
inputRecordingSampleBitDepth
inputRecordingSampleByteDepth
inputRecordingSampleRate
insertObject:atIndex:
installedAssetOfType:forLanguage:
installedAssetOfType:forLanguageCode:
intValue
integerValue
invalidate
invocationStyleStr
isAbsolutePath
isAvailable
isCSAssetInstalled
isConnected
isCurrentDeviceCompatibleWithNewerVoiceProfileAt:
isCurrentDeviceCompatibleWithVoiceProfileAt:
isDarwinOS
isDownloading
isEqual:
isEqualToString:
isIOSDeviceSupportingBargeIn
isImplicitTrainingRequiredForVoiceProfileId:locale:completion:
isImplicitTrainingRequiredToVoiceProfile:withAsset:completion:
isKindOfClass:
isLatestCompareTo:
isMarkedSATEnrolled
isMarkedSATMigrated
isMemberOfClass:
isPermitted
isPremium
isRecordContextAutoPrompt:
isRecordContextBuiltInVoiceTrigger:
isRecordContextDarwinVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisButtonPress:
isRecordContextJarvisVoiceTrigger:
isRecordContextRaiseToSpeak:
isRecordContextRemoraVoiceTrigger:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextVoiceTrigger:
isRecording
isRecordingWithStreamHandleId:
isRemoteDarwinWithDeviceId:
isRequestDuringActiveCall
isSATEnrolledForSiriProfileId:forLanguageCode:
isSATEnrollmentMigratedForSiriProfileId:forLanguageCode:
isSpeakerRecognitionAvailable
isSpeakerRecognitionSupportedInLocale:
isUtteranceImplicitlyTrained:
isValidRecordContext:
isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:
keywordDetectorNDAPIConfigFilePath
keywordDetectorQuasarConfigFilePath
languageCode
languageCodeDarwin
lastMatchEventWithError:
lastObject
lastPathComponent
lastScoreCard
leave
length
loadKnownUserVoiceProfiles
locale
localeWithLocaleIdentifier:
localizedDescription
logAggregator
logSiriSetupPHSEnrollmentDigitalZeroDetectionCompletedWithSiriSetupID:withPageNumber:withPhId:withMaxNumContinuousZeros:withMaxNumAllowedContinuousZeros:withIsMaxNumContinuousZerosOverThreshold:
logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:
logTrainingSessionCompleteWithVoiceTriggerEventInfo:
logVoiceProfileConfusionWithCleanup:
lpcmInt16ASBD
markSATEnrollmentMigrated
markSATEnrollmentSuccess
markSATEnrollmentSuccessForVoiceProfile:
matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:
matchWithString:TrailingStr:LeadingStr:Pattern:
maxAllowedAudioSamples
maxAllowedEnrollmentUtterances
maxAllowedSpeakerVectors
migrateVoiceProfilesIfNeededWithCompletionBlock:
minusSet:
modelDirectoryPathForProfile:
modelFilePath
modelsContext
moveContentsOfSrcDirectory:toDestDirectory:
moveItemAtPath:toPath:error:
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
multiUserHighScoreThreshold
multiUserLowScoreThreshold
mutableAudioBufferList
mutableBytes
mutableCopy
myriadResult
name
ndapiResult
needsRetrainingWithAudioFiles:
newVoiceProfileWithLocale:withAppDomain:
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:
notifyUserVoiceProfileDownloadReadyForUser:getData:completion:
notifyUserVoiceProfileUpdateReady
notifyUserVoiceProfileUploadComplete
numEnrollmentUtterances
numSamples
numSamplesInPCMBuffer
numSamplesProcessed
numberOfMatchesInString:options:range:
numberOfRanges
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInt:
numberWithUnsignedInteger:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observers
orchestrator
orchestratorScoresWithPSRScores:withSATScores:withSegmentStartTime:
osTransactionReqd
path
pathExtension
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phId
phraseConfig
phraseConfigs
phraseDetectorInfoFromPhId:
pickAssetForProfiles:forSpIdType:
pickAssetForProfiles:forSpIdType:withAssetArray:
pitch
playbackRoute
postNotificationName:object:
powerMeter
preTriggerAudioTime
predicateWithBlock:
predicateWithFormat:
prepareAudioStreamRecordWithStreamHandleId:error:
prepareRecord
prepareRecordForStream:error:
prepareWithCompletion:
processAudio:numSamples:
processAudio:withNumberOfSamples:
processAudioData:
processAudioData:numSamples:
processAudioSamplesAsynchronously:
processFloatBuffer:stride:inFrameToProcess:
processShortBuffer:stride:inFrameToProcess:
processedAudioMs
profileID
profileId
profileLocallyAvailable
profilePitch
provisionedVoiceProfilesForAppDomain:withLocale:
provisionedVoiceProfilesForLocale:
pruneImplicitUtterancesOfProfile:withAsset:
pruneVoiceProfile:forSpIdType:withAsset:
pruningCookie
pruningExplicitUttThresholdPSR
pruningExplicitUttThresholdSAT
pruningNumRetentionUtterance
pruningThresholdPSR
pruningThresholdSAT
psrAnalyzer
psrCombinationWeight
psrConfigFilePath
psrConfigRoot
psrFinalSpeakerInfo
psrLastSpeakerInfo
psrRecognizer
purgeConfusionInformationWithPolicy:
purgeLastSpeakerEmbedding
pushAnalytics
pushAnalyticsWithLazyBlock:
pushAudioInputIntoPCMBuffer:
queryMetaDataSync
queryParams
queue
rangeAtIndex:
rangeOfString:options:
readJsonFileAtPath:
recognitionStyle
recognitionTaskWithRequest:delegate:
recognizerScoreOffset
recognizerScoreScaleFactor
recordContextString:
recordRoute
recordRouteWithStreamHandleId:
recordedTimeStampFromFileName:
recordedTimeStampOfFile:
recordingStoppedForReason:
registerObserver:
regularExpressionWithPattern:options:error:
releaseAudioSession
reloadForLocale:
remoteControlClient
remoteDeviceContext
remoteTrainingDeviceType
remoteTrainingDeviceUUIDList
removeAllObjects
removeItemAtPath:
removeItemAtPath:error:
removeItemAtURL:error:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsInRange:
replaceBytesInRange:withBytes:
replaceMatchesInString:options:range:withTemplate:
replaceObjectAtIndex:withObject:
reportDigitalZerosWithAudioZeroRun:
requestSupportedWithSamplingRate:
requestTriggeredUtterance:
reset
resetForNewRequest
resetForNewRequestWithSampleRate:
resetModelForRetraining
resetScorerWithModelFilePath:
resetWithContext:
resetWithSampleRate:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resourceFilePath
resourcePath
respondsToSelector:
result
resultAlreadyReported
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithEndedAudio
resumeTraining
retain
retainCount
retrainVoiceProfile:withContext:withCompletion:
retrainerType
retrainingWaitTime
returnTypes:
reverseObjectEnumerator
route
sampleCount
samplesAtFire
samplesFed
satConfigFileNameForCSSpIdType:forModelType:forAssetType:
satFinalSpeakerInfo
satImplicitProfileDeltaThreshold
satImplicitProfileThreshold
satImplicitTrainingEnabled
satLastSpeakerInfo
satModelAvailable
satRecognizer
satScoreThreshold
satScoreThresholdForPhId:
satVTImplicitThreshold
saveKnownUserVoiceProfiles:
saveMetadata:isExplicitEnrollment:
saveRawUtteranceAndMetadata:to:isExplicitEnrollment:
saveRecordWithData:recordInfo:completion:
saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:
saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:
saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:
scanFloat:
scannerWithString:
scheduledTimerWithTimeInterval:target:selector:userInfo:repeats:
scoreSpeakerVector:withDimensions:withThresholdType:
scoreType
segmentStartPointSampleCount
segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:
self
sessionId
sessionStatus
setActivationMode:
setActiveChannel:
setAnnounceCallsEnabled:
setAppDomain:
setAsset:
setAssetProviders:
setAudioFileWriter:
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setAudioStreamHandleId:
setBiometricDevice:
setCombinedScores:
setCompareVoiceProfileArray:
setConfig:
setContext:
setContext:error:
setContextualStrings:
setCurrentDeviceCategory:
setCurrentLanguageCode:
setDateAdded:
setDateFormat:
setDebugUtteranceJsonFilePath:
setDelegate:
setDetectorNDAPI:
setDetectorQuasar:
setEarSpg:
setEndInSampleCount:
setEndpointReported:
setEndpointUUID:
setEndpointerDelegate:
setExtraSamplesAtStart:
setHomeId:
setHybridClassifier:
setInvocationStyleStr:
setLanguageCode:
setLastScoreCard:
setLastSpeakerInfo:
setLocale:
setLocaleIdentifier:
setLogAggregator:
setMeteringEnabled:
setMyriadResult:
setNumSamplesProcessed:
setObject:forKey:
setObject:forKeyedSubscript:
setObservers:
setOrchestrator:
setPitch:
setPowerMeter:
setProcessingEnded:
setProductCategory:
setProfileBasePath:
setProfileId:
setProfilePitch:
setPsrFinalSpeakerInfo:
setPsrLastSpeakerInfo:
setPsrRecognizer:
setQueue:
setRecognizerScoreScaleFactor:
setRecordDelegate:
setRemoteControlClient:
setRemoteDeviceContext:
setRetrainingWaitTime:
setSatFinalSpeakerInfo:
setSatLastSpeakerInfo:
setSatRecognizer:
setSegmentStartPointSampleCount:
setSessionId:
setSharedSiriId:
setSharedSiriProfileId:
setSkipAlert:
setSpIdCtx:
setSpIdType:
setSpeakerRecognitionPSRProcessingStatus:
setSpeakerRecognitionProcessingStatus:
setSpeakerRecognitionSATProcessingStatus:
setSpeakerRecognitionWaitTime:
setSpgQueue:
setSsrUttLogger:
setStartAlert:
setStartWaitTime:
setStartpointReported:
setStopAlert:
setStopOnErrorAlert:
setStorePrefs:
setSuspendAudio:
setSynchronousCallbackEnabled:
setTaskHint:
setTotalNumSamplesReceived:
setTransDesc:
setUserName:
setValue:forKey:
setVersion:
setVoiceControllerCreationQueue:
setVoiceProfile:
setVoiceProfileArray:
setVoiceProfileDiscardedUtteranceCount:
setVoiceProfilePrunedUtteranceCount:
setVoiceProfilePruningFailureReasonCode:
setVoiceProfileRetainedUtteranceCount:
setVoiceProfileRetrainingFailureReasonCode:
setVoiceProfileStoreVersion:
setVoiceProfileUpdateScoreMSE:
setVoiceTriggerEventInfo:
setVtEndInSampleCount:
setWithArray:
setupPhraseSpotter
setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:
setvoiceProfilePrunedUtteranceCount:
sharedGrammars
sharedInstance
sharedInstanceWithEndpointId:
sharedLogger
sharedManager
sharedPreferences
sharedSiriId
sharedStorePrefs
sharedTrainer
sharedtrainingSessionQueue
shouldHandleSession
shouldMakeRecordWithFrequency:
shouldMatchPayload
shouldPerformRMS
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
silenceDurationMs
silenceFramesCountMs
silencePosterior
silenceProbability
siriProfileId
skipAlert
sortedArrayUsingComparator:
spIdType
spIdTypeForString:
spIdVoiceProfileImportRootDir
speakerIdScoreReportingType
speakerRecognitionAudioLoggingEnabled
speakerRecognitionController:hasSpeakerInfo:
speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:
speakerRecognitionPSRProcessingStatus
speakerRecognitionProcessingStatus
speakerRecognitionSATProcessingStatus
speakerRecognitionWaitTime
speakerRecognizer:hasSpeakerIdInfo:
speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:
speechRecognitionDidDetectSpeech:
speechRecognitionTask:didFinishRecognition:
speechRecognitionTask:didFinishSuccessfully:
speechRecognitionTask:didHypothesizeTranscription:
speechRecognitionTaskFinishedReadingAudio:
speechRecognitionTaskWasCancelled:
speechRecognizerAvailable
spgQueue
spidAudioTrainUtterancesDir
ssrAudioLogsCountWithinPrivacyLimit
ssrUttLogger
startAlert
startAudioStreamWithStreamHandleId:error:
startHostTime
startMasterTimerWithTimeout:
startRMS
startRecordForStream:error:
startRecording
startRecordingWithOptions:error:
startTraining
startpointReported
state
stopAlert
stopAudioStreamWithStreamHandleId:error:
stopCountingZeroStatisticsWithReporter:
stopEndpointer
stopOnErrorAlert
stopRecordForStream:error:
stopRecording
stopRecording:
storeAESKeyInKeychain:applicationTag:keyLabel:
storePrefs
streamAudioFromFileUrl:audioStreamBasicDescriptor:samplesPerStreamChunk:audioDataAvailableHandler:
streamDescription
streamID
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringByTrimmingCharactersInSet:
stringForCSSpIdType:
stringForInvocationStyle:
stringForVoiceProfileRetrainerType:
stringValue
stringWithFormat:
stringWithUTF8String:
subdataWithRange:
submitVoiceIdIssueReport:
subpathsOfDirectoryAtPath:error:
substringFromIndex:
substringWithRange:
superclass
supportHandsFree
supportPremiumModel
supportRingtoneA2DP
supportsSecureCoding
supportsSpeakerRecognitionAssets
suspendAudio
sysConfigRoot
teardownWithError:
threshold
timeIntervalSince1970
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeStamp
timeStampWithSaltGrain
tokens
totalNumSamplesReceived
trailingAudioTime
trailingSilenceDuration
trailingSilenceDurationAtEndpoint
trainUtterance:shouldUseASR:completion:
trainUtterance:shouldUseASR:mhUUID:completionWithResult:
trainingManagerWithLocaleID:withAppDomain:
transDesc
transaction
triggerInvalidSiriProfileCleanupFromPersonalDevicesForLanguage:appDomain:
triggerRetrainingVoiceProfile:withContext:withCompletion:
triggerVoiceProfileCleanupWithCompletion:
triggerVoiceProfileDownload
triggerVoiceProfileDuplicatesCleanup
triggerVoiceProfileMigrationWithCompletion:
triggeredUtterance:
trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:
type
unregisterObserver:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
updateAudioRecorderForTrainingDevice:deviceUUIDs:
updateMeterAndForward
updateMeters
updatePruningCookie:
updateSAT
updateTrainingManagerForDevice:trainingDeviceUUIDList:
updateVoiceProfile:withUserName:
uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:
useRecognizerCombination
useSpeakerRecognitionAsset
userName
userVoiceProfileForVoiceProfileID:
userVoiceProfilesForAppDomain:
userVoiceProfilesForAppDomain:forLocale:
userVoiceProfilesForLocale:
utteranceFileASBD
valueForKey:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerCreationQueue
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerDidDetectStartpoint:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerEndRecordInterruption:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerStreamInvalidated:forStream:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceProfile
voiceProfileArray
voiceProfileAudioDirPathForSpidType:
voiceProfileBasePath
voiceProfileDiscardedUtteranceCount
voiceProfileForId:
voiceProfileIdentity
voiceProfileImplicitCacheDirPath
voiceProfileModelDirForSpidType:recognizerType:
voiceProfileModelFilePath
voiceProfileModelFilePathForRecognizerType:spIdType:
voiceProfilePrunedUtteranceCount
voiceProfilePruningCookie
voiceProfilePruningFailureReasonCode
voiceProfileRetainedUtteranceCount
voiceProfileRetrainingFailureReasonCode
voiceProfileUpdateScoreMSE
voiceProfileVersion
voiceProfilesModelFilePaths
voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:
voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:
voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:
voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:
voiceRetrainersWithContext:
voiceTriggerEnabled
voiceTriggerEventInfo
vtEndInSampleCount
vtEventInfo
waitWithTimeout:
waitingForConnection:error:
weakObjectsHashTable
whitespaceAndNewlineCharacterSet
wordCount
writeMetaDict:atMetaPath:
writeToFile:atomically:
writeToFile:options:error:
year
zeroFilterWindowSizeInMsForReport
zone
@16@0:8
v24@0:8@16
v24@0:8q16
v16@0:8
v24@0:8Q16
d16@0:8
v24@0:8d16
Q16@0:8
@"<CSVTUIEndpointAnalyzerDelegate>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
@32@0:8@16@24
v32@0:8@16Q24
q16@0:8
v20@0:8B16
@"SSRSpeakerRecognitionContext"
@"<SSRVoiceActivityDetectorDelegate>"
@"EARCaesuraSilencePosteriorGenerator"
@"_EAREndpointer"
@"_EARDefaultServerEndpointFeatures"
@"NSObject<OS_dispatch_queue>"
@24@0:8@16
Q24@0:8I16I20
@"CSKeywordAnalyzerNDAPI"
@"CSPhraseDetector"
@"CSAudioCircularBuffer"
@"CSKeywordAnalyzerNDAPIResult"
@40@0:8@16@24@32
v32@0:8@16@24
v32@0:8@"SSRSpeakerAnalyzerPSR"16@"NSDictionary"24
@32@0:8@"SSRSpeakerRecognitionContext"16@"<SSRSpeakerRecognizerDelegate>"24
v32@0:8@"NSData"16Q24
v24@0:8@"SSRSpeakerRecognitionContext"16
@"NSDictionary"16@0:8
@"NSString"
@"NSDictionary"
@"<SSRSpeakerRecognizerDelegate>"
@"SSRSpeakerAnalyzerPSR"
@40@0:8@16@24Q32
@32@0:8@16Q24
@24@0:8Q16
v32@0:8@"<SSRSpeakerRecognizer>"16@"NSDictionary"24
v32@0:8@"SSRVoiceActivityDetector"16Q24
@40@0:8@16@24^@32
v28@0:8@16B24
@40@0:8@16@24d32
@"<SSRSpeakerRecognitionOrchestratorDelegate>"
@"<CSAudioFileWriter>"
@"<SSRSpeakerRecognizer>"
@"SSRVoiceActivityDetector"
@"NSObject<OS_os_transaction>"
v40@0:8@16@?24@?32
@24@0:8@?16
@24@0:8@"SSRVoiceProfileRetrainingContext"16
v40@0:8@"NSArray"16@?<@"NSError"@?@"NSURL"@"NSDictionary">24@?<v@?@"NSError"@"NSDictionary"@"NSDictionary">32
B24@0:8@"NSArray"16
@"NSError"24@0:8@?<B@?@"NSDictionary">16
@"NSURL"16@0:8
@"NSURL"
v24@0:8@?16
@48@0:8@16@24@32Q40
@56@0:8@16@24@32@40Q48
f40@0:8@16Q24Q32
v20@0:8i16
v20@0:8f16
B44@0:8@16@24@32B40
B44@0:8@"CSVTUITrainingSession"16@"NSData"24@"NSString"32B40
v28@0:8B16@20
v28@0:8B16@"NSError"20
v24@0:8@"NSData"16
v24@0:8@"NSError"16
v32@0:8@16d24
v32@0:8@"CSVTUIEndpointAnalyzer"16d24
@32@0:8Q16@24
q36@0:8q16B24@?28
q44@0:8q16B24@28@?36
B24@0:8q16
v32@0:8i16B20@?24
f16@0:8
@"<CSVTUIAudioSession>"
@"CSVTUIEndpointAnalyzer"
@"CSVTUIKeywordDetector"
@"NSMutableArray"
@"CSVTUITrainingSession"
@"SFSpeechRecognizer"
@"CSAsset"
@"SSRVoiceProfile"
@"CSDispatchGroup"
@"NSUUID"
@"CSAudioZeroCounter"
@"<SSRVTUITrainingManagerDelegate>"
@"CSPlainAudioFileWriter"
v68@0:8@16Q24@32@40Q48Q56i64
v44@0:8@16Q24B32@36
v40@0:8@16Q24q32
v32@0:8@16q24
v68@0:8@"CSVTUIAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v44@0:8@"CSVTUIAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSVTUIAudioRecorder"16Q24q32
v32@0:8@"CSVTUIAudioRecorder"16q24
v24@0:8@"CSVTUIAudioRecorder"16
v32@0:8Q16@24
v24@0:8@"<CSVTUIAudioSessionDelegate>"16
v32@0:8Q16@"NSArray"24
v24@0:8@"<Endpointer>"16
q24@0:8q16
@"CSVTUIAudioRecorder"
@"<CSVTUIAudioSessionDelegate>"
@"CSAudioPowerMeter"
@48@0:8@16@24@32@40
@"NSNumber"
@"NSDate"
v32@0:8@16@?24
@"SSRTriggerPhraseDetectorNDAPI"
@"SSRTriggerPhraseDetectorQuasar"
B32@0:8d16^@24
v64@0:8@16@24@32@40@48@?56
@"CSAsset"32@0:8Q16@"NSString"24
@"NSArray"32@0:8Q16@"NSString"24
B32@0:8@16@24
B40@0:8@16@24@32
@"NSMutableDictionary"
@32@0:8@16q24
@40@0:8@16Q24q32
B32@0:8@16^@24
B24@0:8^@16
@"<CSVTUIRemoteRecordClientDelegate>"
@36@0:8@16i24@28
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8Q16Q24
Q32@0:8@16Q24
B32@0:8Q16Q24
@"_EARSyncSpeechRecognizer"
Q24@0:8Q16
Q24@0:8@16
@40@0:8Q16Q24Q32
v80@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24Q64@?72
q24@0:8@16
v44@0:8@16@24B32@?36
B40@0:8@16@24^@32
@36@0:8@16@24f32
v32@0:8@"SSRSpeakerRecognitionController"16@"NSDictionary"24
v40@0:8@16Q24@32
v56@0:8@16@24@32@40@?48
@32@0:8@16^@24
@"NSArray"
@"SSRLoggingAggregator"
v64@0:8@16@24B32@36@44Q52B60
q48@0:8@16@24@32@40
v24@0:8@"SFSpeechRecognitionTask"16
v32@0:8@"SFSpeechRecognitionTask"16@"SFTranscription"24
v32@0:8@"SFSpeechRecognitionTask"16@"SFSpeechRecognitionResult"24
v28@0:8@"SFSpeechRecognitionTask"16B24
v24@0:8i16B20
@104@0:8q16q24@32@40@48@56@64@72@80@88@?96
@112@0:8q16q24@32@40@48@56@64@72@80@88@96@?104
v40@0:8i16B20@24@?32
i32@0:8@16@24
@"SFSpeechAudioBufferRecognitionRequest"
@"SFSpeechRecognitionTask"
@"NSTimer"
@"<CSVTUITrainingSessionDelegate>"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
v80@0:8@16@24@32@40@48@56@64@?72
@32@0:8@16@?24
v48@0:8@16Q24@?32@?40
@40@0:8@16Q24Q32
@24@0:8^@16
@"SSRRemoteControlClient"
v36@0:8@16B24@28
v28@0:8@16i24
v36@0:8@16i24d28
v36@0:8@16i24@28
v40@0:8@16@24@32
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
Q32@0:8@16^@24
B32@0:8Q16^@24
B24@0:8Q16
B40@0:8Q16Q24^@32
v60@0:8@16Q24@32Q40Q48i56
v40@0:8@16Q24Q32
@28@0:8@16I24
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"CSVTUIRemoteRecordClient"
@"NSHashTable"
@"CSVTUIAudioRecorderRemoteDeviceContext"
f24@0:8@16
@40@0:8Q16@24@32
@"<SSRAssetManagerDelegate>"
v32@0:8@"SSRSpeakerRecognitionOrchestrator"16@"NSDictionary"24
@"<SSRSpeakerRecognitionControllerDelegate>"
@"SSRSpeakerRecognitionOrchestrator"
B40@0:8@16@24f32f36
B40@0:8@16@24Q32
v36@0:8@16B24@?28
@"SSRVoiceProfileStorePrefs"
v32@0:8@"BKDevice"16@"BKMatchEvent"24
B32@0:8^B16^Q24
@"BKDevice"
v36@0:8@16@24B32
B36@0:8@16@24B32
B44@0:8@16@24Q32B40
B28@0:8@16B24
v48@0:8@16Q24@32@?40
B40@0:8@16Q24@32
@40@0:8@16Q24@32
v32@0:8@"NSURLSession"16@"NSError"24
v40@0:8@"NSURLSession"16@"NSURLAuthenticationChallenge"24@?<v@?q@"NSURLCredential">32
v24@0:8@"NSURLSession"16
@32@0:8q16@24
@40@0:8@16q24@32
f20@0:8f16
@44@0:8Q16@24@32B40
f24@0:8Q16
@32@0:8q16i24i28
i16@0:8
333333
333333
com.apple.corespeech
Framework
v8@?0
en_US_POSIX
yyyyMMdd-HHmmss
CSLogInitIfNeeded_block_invoke
gitrelno_unavailable
com.apple.ssr
SSRLogInitIfNeeded_block_invoke
-[CSVTUIEndpointAnalyzer init]
-[CSVTUIEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSVTUIEndpointAnalyzer recordingStoppedForReason:]
-[CSVTUIEndpointAnalyzer stopEndpointer]
-[CSVTUIEndpointAnalyzer resetForNewRequestWithSampleRate:]
-[CSVTUIEndpointAnalyzer setStartWaitTime:]
-[CSVTUIEndpointAnalyzer setEndWaitTime:]
-[CSAudioRecordContext(AVVC) avvcContextSettings]
com.apple.ssr.vad.spg
-[SSRVoiceActivityDetector initWithContext:delegate:]
-[SSRVoiceActivityDetector processAudioData:numSamples:]
-[SSRVoiceActivityDetector clientSilenceFeaturesAvailable:]
triggerStartSampleCount
triggerEndSampleCount
triggerFireSampleCount
isTriggerEvent
totalSampleCount
triggerScore
recognizerScore
recognizerThresholdOffset
recognizerScaleFactor
triggeredPhrase
triggeredPhraseId
-[CSVTUITwoPassKeywordDetector initWithAsset:]
config_1st.txt
-[CSVTUITwoPassKeywordDetector analyze:]
SSRSpeakerRecognizerPSR.m
Incorrect ctx for VTSpeakerRecognizer: %@
com.apple.ssr.psrq
-[SSRSpeakerRecognizerPSR initWithContext:delegate:]
extraSamplesAtStart
triggerEndSeconds
-[SSRSpeakerRecognizerPSR dealloc]
-[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:]
extraAudioAtStartInMs
tdEndInMs
-[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
com.apple.speakerrecognition
recognition
-[SSRSpeakerRecognitionOrchestrator initWithContext:withDelegate:error:]
ERR: Failed to init PSR and SAT recognizers - Bailing out
reason
ERR: Failed to init VAD - Bailing out
com.apple.ssr.orchestratorq
SAT+PSR
-[SSRSpeakerRecognitionOrchestrator dealloc]
-[SSRSpeakerRecognitionOrchestrator processAudio:numSamples:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator resetWithContext:]_block_invoke
SSRSpeakerRecognitionOrchestrator-%@
-[SSRSpeakerRecognitionOrchestrator _logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:]
finished
reported
%@_%d
json
-[SSRSpeakerRecognitionOrchestrator getLatestVoiceRecognitionInfo]
-[SSRSpeakerRecognitionOrchestrator speakerRecognizer:hasSpeakerIdInfo:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectStartPointAt:]_block_invoke
-[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectEndPointAt:]_block_invoke
+[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]
com.apple.fides.phs
+[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]_block_invoke
Name
MetaInfo
v24@?0@"NSUUID"8@"NSError"16
v32@?0@"NSNumber"8@"NSString"16@"NSError"24
ERR: received nil dob: %@ / name: %@
+[SSRDESRecordWriter fetchMedicalDataWithCompletion:]_block_invoke
v24@?0@"_HKMedicalIDData"8@"NSError"16
com.apple.VoiceTriggerUI.TrainingSessionQueue
com.apple.VoiceTriggerUI.TrainingManager
-[SSRVTUITrainingManager updateTrainingManagerForDevice:trainingDeviceUUIDList:]
-[SSRVTUITrainingManager setLocaleIdentifier:]
-[SSRVTUITrainingManager createKeywordDetector]
-[SSRVTUITrainingManager prepareWithCompletion:]_block_invoke
-[SSRVTUITrainingManager cleanupWithCompletion:]
-[SSRVTUITrainingManager cleanupWithCompletion:]_block_invoke
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]_block_invoke_2
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]_block_invoke
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]_block_invoke_2
-[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]_block_invoke
-[SSRVTUITrainingManager cancelTrainingForID:]
-[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:withCompletion:]
-[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:completionWithResult:]
-[SSRVTUITrainingManager _shouldShowHeadsetDisconnectionMessage]
-[SSRVTUITrainingManager _startAudioSession]
-[SSRVTUITrainingManager setSuspendAudio:]
-[SSRVTUITrainingManager setSuspendAudio:]_block_invoke
-[SSRVTUITrainingManager CSVTUITrainingSessionStopListen]
-[SSRVTUITrainingManager CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:]
-[SSRVTUITrainingManager audioSessionDidStopRecording:]
-[SSRVoiceProfileRetrainerFactory init]
Borealis Input
com.apple.VoiceTriggerUI.RecordSessionQueue
-[CSVTUIAudioSessionRecorder init]
-[CSVTUIAudioSessionRecorder _audioRecorder]
-[CSVTUIAudioSessionRecorder prepareRecord]
-[CSVTUIAudioSessionRecorder startRecording]
-[CSVTUIAudioSessionRecorder stopRecording]
-[CSVTUIAudioSessionRecorder _hasCorrectInputAudioRoute]
-[CSVTUIAudioSessionRecorder _hasCorrectOutputAudioRoute]
-[SSRVoiceProfileMetaContext initWithVoiceProfile:]
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@, pitch:%@ Hz]
+[SSRTriggerPhraseDetector filterVTAudioFiles:withLocale:withAsset:]
v20@?0@"NSError"8f16
-[SSRTriggerPhraseDetector initWithLocale:asset:]
-[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]
-[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]_block_invoke
v44@?0{AudioBufferList=I[1{AudioBuffer=II^v}]}8B32@"NSError"36
NDAPI: missing best_score for %@
best_score
Quasar: missing best_score for %@
Languages
Footprint
Premium
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
isMaximized
-[CSVTUIKeywordDetector initWithAsset:]
config.txt
VoiceTriggerEventInfo
locale
asset
profileUpdateFailedExplicitUttScore
profileUpdateDiscardImplicitUttScore
profileUpdateExplicitUttScore
profileUpdateImplicitUttScore
profileUpdateNumPrunedUttsPHS
profileUpdateNumDiscardedUttsPHS
profileUpdateNumRetainedUttsPHS
profileUpdateScoreMSE
profileUpdateFailCode
speakerRecognitionWaitTimeMs
speakerRecognitionProcessingStatus
retrainingWaitTimeMs
retrainingStatusCode
TdPsrSATRetrainingTimedOut
TdPsrExtraAudioSamplesProcessed
TdPsrFailedDuringSATDetection
xx_XX
unknown
@"NSDictionary"8@?0
%@.%d
-[SSRLoggingAggregator pushAnalytics]
voic
carplay
hearst
raisetospeak
auto
B24@?0@"SSRVoiceProfile"8@"NSDictionary"16
-[SSRVoiceProfileStoreCleaner filterDuplicatedSiriProfilesFrom:]
Primary
-[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]
kAFAssistantErrorDomain
-[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]_block_invoke
v24@?0@"NSString"8@"NSError"16
-[SSRVoiceProfileStoreCleaner cleanupProfileStore]
ERR: Failed to get appdomain for profile %@
-[SSRVoiceProfileStoreCleaner cleanupProfileStore]_block_invoke
v32@?0@"SSRVoiceProfile"8Q16^B24
-[SSRVoiceProfileStoreCleaner deleteInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:]
-[SSRVoiceProfileStoreCleaner _cleanupAppDomain:]
-[SSRVoiceProfileStoreCleaner _cleanuplanguageCodePath:forAppDomain:]
-[SSRVoiceProfileStoreCleaner _cleanupImplicitUtteranceCacheForProfile:]
-[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:]
-[SSRVoiceProfileStoreCleaner _cleanupContentsOfSatFolder:]
-[SSRVoiceProfileStoreCleaner _cleanupInvalidAudioFiles:]
Failed reading contents of audioDir: %@, err: %@
-[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesAtURL:]
enrollment_completed
-[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]
obsoleteCutOffDate is nil - Bailing out
v32@?0@"NSURL"8Q16^B24
-[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]_block_invoke
Error reading contents of modelDir: %@, err: %@
-[SSRVoiceProfileStoreCleaner _cleanupModelFilesAtDir:forAssetArray:]
-[CSVTUISelfLoggingDigitalZeroReporter logDigitalZeroDetectionComplete]
UserVoiceProfileDateTrained
UserVoiceProfileLocale
UserVoiceProfileAppDomain
UserVoiceProfilePitch
UserVoiceProfilePath
UserVoiceProfileID
UserSharedSiriID
UserVoiceProfileUserName
VoiceProfileIdentifier
VoiceProfileCompatabiltyVersion
VoiceProfileProductType
VoiceProfileSWVersion
VoiceProfileCategoryType
UserVoiceProfileOnboardType
UserVoiceProfileExpSatVecCount
VoiceProfilePruningCookie
-[SSRVoiceProfile initNewVoiceProfileWithLocale:withAppDomain:]
Creating SSRVoiceProfile with no profileId vpDict: %@
audio
-[SSRVoiceProfile _copyExplicitAudio:withSpIdType:]
-[SSRVoiceProfile importVoiceProfileAtPath:]
ERR: Too less audio files (%ld) for onboarding
utterances passed is nil!
-[SSRVoiceProfile addUtterances:spIdType:]
Failed to copy utterances with error %@
-[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]
-[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]_block_invoke
B24@?0@"NSURL"8@"NSDictionary"16
audiocache
td-sr-model
model
-[SSRVoiceProfile deleteModelForSpidType:recognizerType:]
enrollment_migrated
-[SSRVoiceProfile _isSATMarkedWithMarker:]
-[SSRVoiceProfile _markSATEnrollmentWithMarker:]
-[SSRVoiceProfile _updateVoiceProfileVersionFile]
-[SSRVoiceProfile updatePruningCookie:]
Dictation
-[SSRTriggerPhraseDetectorQuasar initWithLocale:configPath:resourcePath:]
-[SSRTriggerPhraseDetectorQuasar reset]
Second Pass
-[SSRTriggerPhraseDetectorQuasar analyzeWavData:numSamples:]
-[SSRTriggerPhraseDetectorQuasar endAudio]
totalSamplesAtEndOfCapture
productType
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdUserScoresVersion
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
bestVoiceTriggerScore
sessionId
segmentStartTime
segmentCounter
myriad
ssrMeta
voiceTriggerRequestUID
numEnrollmentUtt
combinationWeight
numSpeakerVectors
numExplicitUtt
numImplicitUtt
profileID
lowScoreThreshold
psrContext
spIdKnownUserPSRScores
spIdKnownUserPSRExpScores
satContext
spIdKnownUserSATScores
spIdKnownUserSATExpScores
Unknown InvocationStyle: %lu
tdti
tdtiexplicit
tdexplicit
Unknown CSSpIdType: %lu
+[SSRUtils spIdTypeForString:]
Unknown SpeakerRecognizerType: %lu
Unknown VoiceProfileRetrainerType: %lu
config_td_spid.txt
config_sr_sat.txt
+[SSRUtils satConfigFileNameForCSSpIdType:]
config_tdti_spid.txt
+[SSRUtils psrConfigFileNameForCSSpIdType:]
config_ti_spid.txt
+[SSRUtils satConfigFileNameForCSSpIdType:forModelType:forAssetType:]
spid-imported
+[SSRUtils createDirectoryIfDoesNotExist:]
Library/Logs/CrashReporter/ssr
self ENDSWITH '.wav'
+[SSRUtils ssrAudioLogsCountWithinPrivacyLimit]
+[SSRUtils cleanupOrphanedVoiceIdGradingFiles]
v32@?0@"NSString"8@"NSURL"16^B24
+[SSRUtils cleanupOrphanedVoiceIdGradingFiles]_block_invoke
VoiceProfileCache
AudioFileOpenURL Failed : %@
EARTests
AudioFileOpenURL failed: %@
ExtAudioFileWrapAudioFileID failed: %@
Error reading audio-file: %d
EOF. Num bytes read: %lu
+[SSRUtils isSpeakerRecognitionSupportedInLocale:]
+[SSRUtils readJsonFileAtPath:]
kCSDeviceCategory_Unknown
kCSDeviceCategory_iOS_NonAop
kCSDeviceCategory_iOS_Aop
kCSDeviceCategory_macOS
kCSDeviceCategory_audioAccessory
kCSDeviceCategory_iOS_Aop_Explicit
iPad3,4
iPad3,5
iPad3,6
iPad4,1
iPad4,2
iPad4,3
iPad4,4
iPad4,5
iPad4,6
iPad4,7
iPad4,8
iPad4,9
iPad5,1
iPad5,2
iPad5,3
iPad5,4
iPad6,7
iPad6,8
iPad6,11
iPad6,12
iPhone5,1
iPhone5,2
iPhone5,3
iPhone5,4
iPhone6,1
iPhone6,2
iPhone7,1
iPhone7,2
iPod
iPad
iPhone
Accessory
AppleTV
+[SSRUtils deviceCategoryForDeviceProductType:]
+[SSRUtils isCurrentDeviceCompatibleWithNewerVoiceProfileAt:]
+[SSRUtils isCurrentDeviceCompatibleWithVoiceProfileAt:]
pathExtension='json'
Caches/VoiceTrigger/ImplicitUtterences
+[SSRUtils getNumberOfAudioFilesInDirectory:]
v32@?0@"NSString"8Q16^B24
+[SSRUtils dumpFilesInDirectory:]
+[SSRUtils getContentsOfDirectory:]
+[SSRUtils getHomeUserIdForVoiceProfile:withCompletion:]
+[SSRUtils getHomeUserIdForVoiceProfile:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
+[SSRUtils getVoiceProfileForSiriProfileId:forLanguageCode:]
+[SSRUtils logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:]
.wav
ERR: Audio path is nil - Bailing out
+[SSRUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]
ERR: Failed initializing loggers at %@ and %@
+[SSRUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]_block_invoke
ERR: Failed to read file: %@
+[SSRUtils getEnrollmentUtterancesFromDirectory:]
+[SSRUtils getExplicitEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils getExplicitEnrollmentUtterancesFromDirectory:]
q24@?0@"NSURL"8@"NSURL"16
+[SSRUtils getExplicitMarkedEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils getImplicitEnrollmentUtterancesFromDirectory:]_block_invoke
+[SSRUtils _getUtterancesFromDirectory:]
self.absoluteString ENDSWITH '.wav'
+[SSRUtils removeItemAtPath:]
Failed to get contents of %@ with error %@
+[SSRUtils moveContentsOfSrcDirectory:toDestDirectory:]
Failed to move %@ to %@ with error %@
+[SSRUtils combineScoreFromPSR:fromSAT:withCombinedWt:]
pruning
-[SSRVoiceProfilePruner pruneVoiceProfile:forSpIdType:withAsset:]
v32@?0f8f12f16f20@"NSError"24
-[SSRVoiceProfilePruner _getScoresForAudio:withController:withDetector:forProfile:withCompletion:]
Failed to get scoreCard - Bailing out
v16@?0@"NSError"8
Pruner: Timeout (%fms) waiting for retraining - Bailing out
-[SSRVoiceProfilePruner _retrainVoiceProfile:withAsset:]
-[SSRVoiceProfilePruner _deleteUtterances:]
SSRVoiceRetrainingVoiceProfile
SSRVoiceRetrainingCompareVoiceProfiles
SSRVoiceRetrainingCompareVoiceProfilesSpIdType
SSRVoiceRetrainingAsset
SSRVoiceRetrainingSpIdType
SSRVoiceRetrainingFilterToVoiceTriggerUtterances
SSRVoiceRetrainingForce
SSRVoiceRetrainingPayloadProfile
retraining
ERR: VoiceProfile is invalid - Bailing out
-[SSRVoiceProfileRetrainingContext initWithVoiceRetrainingContext:error:]
ERR: Last known assets are nil - Bailing out
ERR: _modelsContext is nil - Bailing out
[SessionId: %@, Asset: %@, ProfileID: %@]
meta_version.json
enrollment_version.json
meta_version
trainingType
explicit
implicit
handheld
near-field
far-field
utteranceWav
productVersion
triggerSource
audioInputSource
otherSourceProfileMatch
containsPayload
grainedDate
buildVersion
+[SSRVoiceProfileMetadataManager saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:]
+[SSRVoiceProfileMetadataManager _getBaseMetaDictionaryForUtterancePath:]
+[SSRVoiceProfileMetadataManager _writeMetaDict:forUtterancePath:]
.json
+[SSRVoiceProfileMetadataManager isUtteranceImplicitlyTrained:]
+[SSRVoiceProfileMetadataManager getUtteranceEnrollmentType:]
+[SSRVoiceProfileMetadataManager recordedTimeStampOfFile:]
yyyyMMdd
+[SSRVoiceProfileMetadataManager recordedTimeStampFromFileName:]
+[CSVTUIRegularExpressionMatcher matchWithString:TrailingStr:LeadingStr:Pattern:]
-[CSVTUITrainingSessionWithPayload _firedVoiceTriggerTimeout]
-[CSVTUITrainingSessionWithPayload _firedEndPointTimeout]
v16@?0@"NSDictionary"8
-[CSVTUITrainingSessionWithPayload handleAudioInput:]_block_invoke
-[CSVTUITrainingSessionWithPayload audioSessionDidStartRecording:error:]
-[CSVTUITrainingSessionWithPayload audioSessionDidStopRecording:]
-[CSVTUITrainingSessionWithPayload didDetectBeginOfSpeech]
-[CSVTUITrainingSessionWithPayload didDetectEndOfSpeech:]
-[CSVTUITrainingSessionWithPayload closeSessionWithStatus:successfully:]
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didHypothesizeTranscription:]_block_invoke
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishRecognition:]_block_invoke
-[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishSuccessfully:]_block_invoke
-[CSVTUITrainingSessionWithPayload matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:]
-[CSVTUITrainingSession closeSessionWithStatus:successfully:]
-[CSVTUITrainingSession closeSessionWithStatus:successfully:complete:]_block_invoke
-[CSVTUITrainingSession closeSessionWithStatus:successfully:complete:]_block_invoke_2
-[CSVTUITrainingSession closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:]_block_invoke
-[CSVTUITrainingSession closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:]_block_invoke_2
-[CSVTUITrainingSession suspendTraining]
-[CSVTUITrainingSession suspendTraining]_block_invoke
-[CSVTUITrainingSession resumeTraining]
-[CSVTUITrainingSession resumeTraining]_block_invoke
-[CSVTUITrainingSession setupPhraseSpotter]
-[CSVTUITrainingSession handleAudioInput:]_block_invoke_2
-[CSVTUITrainingSession handleAudioBufferForVTWithAudioInput:withDetectedBlock:]
-[CSVTUITrainingSession feedSpeechRecognitionTrailingSamplesWithCompletedBlock:]
-[CSVTUITrainingSession trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:]
-[CSVTUITrainingSession audioSessionUnsupportedAudioRoute]
-[CSVTUITrainingSession didDetectBeginOfSpeech]
-[CSVTUITrainingSession didDetectEndOfSpeech:]
PHS explicit training utterance
[%ld] VTUISession Number:[%ld]
-[CSVTUITrainingSession startMasterTimerWithTimeout:]
-[CSVTUITrainingSession handleMasterTimeout:]
-[CSVTUITrainingSession stopMasterTimer]
-[CSVTUITrainingSession speechRecognitionTask:didHypothesizeTranscription:]
triggerFireMachTime
satTriggered
firstPassTriggerSource
deviceHandHeld
languageCode
ApplicationProcessor
com.apple.voicetrigger.PHSProfileDownloadTrigger
com.apple.voicetrigger.speakermodelUpdated
com.apple.voicetrigger.retrainRequired
com.apple.voicetrigger.voiceprofilesync
VoiceProfileAvailabilityMetaBlobVersion
+[SSRVoiceProfileManager sharedInstanceWithEndpointId:]
com.apple.cs.profileManager
/var/mobile
Library
VoiceTrigger/SAT
-[SSRVoiceProfileManager discardSiriEnrollmentForProfileId:forLanguageCode:]
-[SSRVoiceProfileManager _getVoiceProfilesForSiriProfileId:withLanguageCode:]
ERR: profile is nil - Bailing out
-[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]
ERR: Context is nil - Bailing out
ERR: Failed to copy %@ to %@, error: %@
-[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]_block_invoke
ERR: Failed in marking Enrollment as Successful for profile %@
v20@?0B8@"NSError"12
-[SSRVoiceProfileManager isImplicitTrainingRequiredForVoiceProfileId:locale:completion:]_block_invoke
-[SSRVoiceProfileManager isImplicitTrainingRequiredForVoiceProfileId:locale:completion:]
ImplicitTraining
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]_block_invoke
primary
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]
-[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]_block_invoke_2
can not connect to remote audio device
Failed to get asset for locale %@
%lld
ERR: Voice Profile not found for %@ - Bailing out
ERR: Voice Profile locale %@ not matching with %@ - Bailing out
v32@?0@"NSError"8@"NSURL"16@"NSURL"24
-[SSRVoiceProfileManager notifyUserVoiceProfileDownloadReadyForUser:getData:completion:]_block_invoke
Primary User
Missing downloadTriggerBlock - Bailing out
Unknown device category for device type %@ - Bailing out
-[SSRVoiceProfileManager notifyUserVoiceProfileUpdateReady]_block_invoke
userAddition timedout after %fms
Enable VoiceTrigger Upon VoiceProfile Sync For Language
-[SSRVoiceProfileManager _checkIfDownloadRequiredForProfileId:]
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]_block_invoke_2
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]_block_invoke
v24@?0@"NSError"8@"NSString"16
@"NSError"16@?0Q8
-[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]
-[SSRVoiceProfileManager _downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:]
SAT download path is nil - Bailing out
Download for %@ failed with %@
-[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]
Skipping profile Update for %@ in %@
ERR: Failed to import profile %@ for %@
ERR: Migrated language %@ for %@ but failed to mark SAT enrollment
ERR: Failed to mark migrated for %@ in language %@
Failed to init retrainCtxt for profileID %@ with error %@
-[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]_block_invoke
userAddition timedout for siriProfileId %@ after %fms
Failed to enroll user - %@
SourcePath (%@) or DestinationPath (%@) is nil - Bailing out
-[SSRVoiceProfileManager _enableVoiceTriggerIfLanguageMatches:]
Caches/VoiceTrigger/SATUpdate
Caches/VoiceTrigger/SATUpdateNewerZone
_%d_%d
-[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:]
-[SSRVoiceProfileManager notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:]_block_invoke
-[SSRVoiceProfileManager uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:]_block_invoke
@"NSError"24@?0@"SSRVoiceProfileMetaContext"8@"NSString"16
-[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]
-[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]_block_invoke
-[SSRVoiceProfileManager notifyUserVoiceProfileUploadComplete]_block_invoke
-[SSRVoiceProfileManager _getVoiceProfilePathsToBeUploadedForSiriProfileId:]
-[SSRVoiceProfileManager _copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:]
Failed to copy to SATUpload Diretory : %@
v24@?0@"NSError"8Q16
-[SSRVoiceProfileManager _copyVoiceProfileAtPath:toPath:]
ERR: Number of training utterances copied from %@ to %@ is too less %ld
Cannot delete existing SATUpload Diretory : %@
-[SSRVoiceProfileManager _prepareVoiceProfileWithSiriProfileId:withUploadBlock:]
Cannot create SAT Upload Directory : %@
Failed to upload %@ with error %@ - Bailing out
-[SSRVoiceProfileManager _markVoiceProfileTrainingSyncForLanguage:]
Enable VoiceProfile Training Sync For Language
-[SSRVoiceProfileManager _isMarkedForVoiceProfileTrainingSyncForLanguage:]
-[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]
-[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]_block_invoke
v24@?0@"NSDictionary"8@"NSError"16
-[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:]
ERR: Unknown product type. Returning false, language: %@
-[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]
ERR: Unknown device-category for device: %@, languageCode: %@
ERR: Improper VoiceProfile detected: %@, languageCode: %@
-[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]_block_invoke
-[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:]
-[SSRVoiceProfileManager enableVoiceTriggerUponVoiceProfileSyncForLanguage:]
-[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]
-[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]_block_invoke
v16@?0@"NSArray"8
Caches/VoiceTrigger/SATLegacyUpload
-[SSRVoiceProfileManager provisionedVoiceProfilesForAppDomain:withLocale:]
q24@?0@"SSRVoiceProfile"8@"SSRVoiceProfile"16
-[SSRVoiceProfileManager provisionedVoiceProfilesForLocale:]
-[SSRVoiceProfileManager getVoiceProfileAnalyticsForAppDomain:withLocale:]
ERR: Voice Profile sent as nil - Bailing out
-[SSRVoiceProfileManager triggerRetrainingVoiceProfile:withContext:withCompletion:]
ERR: Voice Profile not found for Id %@ - Bailing out
-[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]
-[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]_block_invoke
-[SSRVoiceProfileManager isSATEnrolledForSiriProfileId:forLanguageCode:]
ERR: Voice Profile passed is nil - Bailing out
-[SSRVoiceProfileManager deleteUserVoiceProfile:]
-[SSRVoiceProfileManager deleteAllVoiceProfilesForAppDomain:]
Library/Caches/VoiceTrigger
Caches/VoiceTrigger
Caches/VoiceTrigger/SATUpload
td/audio
-[SSRVoiceProfileManager _isLegacyEnrollmentMarkedWith:forLanguageCode:]
-[SSRVoiceProfileManager importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:]_block_invoke
No path, app domain or locale provided
-[SSRVoiceProfileManager importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:]
%@/%@
file://%@/%@
[Context = %ld]
[DeviceId = %@]
[Announced = %d]
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
VoiceControllerCreationQueue
-[CSVTUIAudioRecorder initWithQueue:error:]
-[CSVTUIAudioRecorder dealloc]
-[CSVTUIAudioRecorder _destroyVoiceController]
-[CSVTUIAudioRecorder _voiceControllerWithError:]_block_invoke_2
-[CSVTUIAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSVTUIAudioRecorder _voiceControllerWithError:]
-[CSVTUIAudioRecorder setContext:error:]
-[CSVTUIAudioRecorder prepareAudioStreamRecordWithStreamHandleId:error:]
-[CSVTUIAudioRecorder startAudioStreamWithStreamHandleId:error:]
-[CSVTUIAudioRecorder stopAudioStreamWithStreamHandleId:error:]
Builtin Microphone
-[CSVTUIAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSVTUIAudioRecorder deactivateAudioSession:error:]
useRemoteBuiltInMic
-[CSVTUIAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
-[CSVTUIAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSVTUIAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSVTUIAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSVTUIAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSVTUIAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSVTUIAudioRecorder voiceControllerEndRecordInterruption:]
-[CSVTUIAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSVTUIAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSVTUIAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSVTUIAudioRecorder voiceControllerMediaServicesWereReset:]
Serial SSRAssetManager queue
en-US
-[SSRAssetManager init]
Trial
-[SSRAssetManager allInstalledAssetsOfType:forLanguage:]_block_invoke_2
-[SSRAssetManager allInstalledAssetsOfType:forLanguage:]_block_invoke
v32@?0@"<SSRAssetProviding>"8Q16^B24
-[SSRAssetManager _latestVersionedAssetOfType:fromProviders:forLocale:]_block_invoke
-[SSRSpeakerRecognitionController voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:]
ERR: Scorecard not available in score dictionary - %@
-[SSRSpeakerRecognitionController voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:]
-[SSRMobileAssetProvider installedAssetOfType:forLanguageCode:]
-[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]
q24@?0@"MAAsset"8@"MAAsset"16
-[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]_block_invoke_2
v32@?0@"MAAsset"8Q16^B24
com.apple.MobileAsset.SpeakerRecognitionAssets
com.apple.MobileAsset.SpeechEndpointAssets
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.SpeechEndpointAssetsTV
-[SSRMobileAssetProvider _buildAssetQueryForAssetType:]
-[SSRMobileAssetProvider _installedMobileAssetOfType:forLanguage:]
-[SSRMobileAssetProvider _findLatestInstalledAsset:]
com.apple.corespeech.voiceprofilestore
-[SSRVoiceProfileStore userVoiceProfilesForAppDomain:]
-[SSRVoiceProfileStore userVoiceProfilesForLocale:]
-[SSRVoiceProfileStore migrateVoiceProfilesIfNeededWithCompletionBlock:]_block_invoke
Filtered languages is nil - %@
spid
trained_users.json
Could not read existing %@ file: err: %@
-[SSRVoiceProfileStore cleanupDuplicatedProfiles]_block_invoke
-[SSRVoiceProfileStore cleanupInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:]
-[SSRVoiceProfileStore cleanupVoiceProfileStore:]_block_invoke_2
-[SSRVoiceProfileStore cleanupVoiceProfileStore:]_block_invoke
-[SSRVoiceProfileStore cleanupVoiceProfileModelFilesForLocale:]_block_invoke
-[SSRVoiceProfileStore _synchronizeSiriVoiceProfilesWithAssistant]_block_invoke
com.apple.siri.corespeech.voiceprofilelist.change
-[SSRVoiceProfileStore isImplicitTrainingRequiredToVoiceProfile:withAsset:completion:]_block_invoke
-[SSRVoiceProfileStore addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:]_block_invoke
Profile %@ is full - Ignoring
Utterance %@ in profile %@ not satisfied the implicit VT policy
Rejecting Implicit utterance %@ for profile %@
@"NSError"24@?0@"NSURL"8@"NSDictionary"16
Utterance %@ rejected for profile %@
v32@?0@"NSError"8@"NSDictionary"16@"NSDictionary"24
Utterance %@ in profile %@ not satisfied the implicit policy
-[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]
B16@?0@"NSDictionary"8
-[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]_block_invoke
v32@?0@"<SSRVoiceProfileRetrainer>"8Q16^B24
-[SSRVoiceProfileStore evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:]
v32@?0@"NSString"8@"NSNumber"16^B24
Profile is nil!
-[SSRVoiceProfileStore addUserVoiceProfile:withContext:withCompletion:]_block_invoke
-[SSRVoiceProfileStore _deleteUserVoiceProfile:]
Deleting profile data at %@ failed with error %@
Profile path is nil!
-[SSRVoiceProfileStore checkIfVoiceProfile:needsUpdatedWith:withCategory:]
-[SSRVoiceProfileStore _checkIfRetrainingRequiredForProfile:]_block_invoke
Failed to init retrainers for profileID %@ with ctxt %@
B16@?0Q8
-[SSRVoiceProfileStore retrainVoiceProfile:withContext:withCompletion:]_block_invoke
-[SSRVoiceProfileStore _enrolledVoiceProfiles]
-[SSRVoiceProfileStore _updateTrainedUsersWithAction:UserVoiceProfile:]
Voice Profile not found for profileId: %@ - Bailing out
-[SSRVoiceProfileStore updateVoiceProfile:withUserName:]
-[SSRVoiceProfileStore _retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:]
VoiceProfile is nil - Bailing out
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:]
context is nil - Bailing out
Invalid spIdType %d - Bailing out
SSRVoiceProfileStore retrainer - %@
Too less (%d) audio files in %@ 
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]
-[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]_block_invoke
Failed to copy %@ to %@ with error %@
-[SSRVoiceProfileStore copyAudioFiles:toProfile:forModelType:]
-[SSRBiometricMatch init]
-[SSRBiometricMatch getLastBiometricMatchForVoiceTriggerTimeStamp:]
MATCH
MIS-MATCH
-[SSRBiometricMatch _getLastBiometricMatchEvent:atTime:]
BKDevice
Class getBKDeviceClass(void)_block_invoke
SSRBiometricMatch.m
Unable to find class %s
void *BiometricKitLibrary(void)
BKDeviceManager
Class getBKDeviceManagerClass(void)_block_invoke
+[SSREnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveMetadata:isExplicitEnrollment:]
+[SSREnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
+[SSREnrollmentDataManager writeMetaDict:atMetaPath:]
Known User Voice Profiles
Voice Profile Store Version
mobile
SSRSpeakerRecognitionStyle
SSRSpeakerRecognitionAsset
SSRSpeakerRecognitionAssetArray
SSRSpeakerRecognitionVADAssetPath
SSRSpeakerRecognitionLocale
SSRSpeakerRecognitionVTEventInfo
SSRSpeakerRecognitionProfileArray
SSRSpeakerRecognitionUsePayloadProfile
SSRSpeakerRecognitionMaxAudioSecs
SSRSpeakerRecognitionOSTransactionReqd
SSRSpeakerRecognitionEndpointId
com.apple.siri
com.apple.siridebug
com.apple.siri.cc
-[SSRSpeakerRecognitionContext initWithVoiceRecognitionContext:error:]
ERR: SpeakerRecognition not enabled - Bailing out
ERR: Invalid Speaker Recognition style - Bailing out
ERR: Asset not picked - Bailing out
ERR: Endpointer Asset not picked - Bailing out
v24@?0@"NSDictionary"8@"NSDictionary"16
ERR: ModelsContext is nil for locale %@ - Bailing out
%@_%@_%@
[SessionId: %@, RecognitionStyle:(%lu)%@, Asset: %@, vtEventInfo: %@]
-[SSRSpeakerRecognitionContext composeModelContextsForProfiles:forSpIdType:forAsset:completion:]
-[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:withAssetArray:]
-[SSRSpeakerRecognitionContext dealloc]
regex.json
Cannot parse to JSON
Cannot find the file
trailing_garbage
leading_garbage
regex
speakerRecognition
satThreshold
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
useSpeakerRecognitionAsset
phrase
-[CSAsset(SpeakerRecognition) satScoreThresholdForPhId:]
recognizer.json
-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
%s ::: CoreSpeech logging initialized (%s)
%s ::: SSR logging initialized (%s)
%s Not supported on this platform
%s Setting mixable to yes as we are in an active call
%s SpkrId:: ERR: Hybrid endpointer not ready for processing request
%s SpkrId:: VAD processed %f secs of audio
%s SpkrId:: Endpoint already reported. Not scheduling
%s SpkrId:: Found Endpoint at: [%f %f %f %f]
%s SpkrId:: Found startpoint at: [%f %f %f %f]
%s Cannot create CSVTUIKeywordDetector since there is no asset available
%s Cannot create CSVTUIKeywordDetector since we cannot initialize NDAPI
%s Unable to create audio chunk, not feeding to analyzer
%s FirstPass triggered, score %f start %lu end %lu fire %lu
%s Waiting for the entire audio... samplesInBuffer %lu triggerSampleFedCount %lu
%s numSamplesinAudioChunk %lu not matching requiredNumSamples %lu !
%s Second pass set to analyze %lu samples, stop feeding
%s Phrase detector result: %@
%s SpkrId:: Failed to create SSRSpeakerRecognizerPSR
%s SpkrId:: %@::uniqueUttTag: %@, extraSamplesAtStart: %lu, _tdEndInSampleCount: %lu(%f ms)
%s SpkrId:: CSSpIdVTSpeakerRecognizer dealloc
%s SpkrId:: Discarded ScoreCard for mismatch session - {%{public}@, %{public}@}
%s SSROrch[%{public}@]:: Failed to create PSR Recognizer
%s SSROrch[%{public}@]:: Failed to create SAT Recognizer
%s %{public}@
%s SSROrch[%{public}@]:: Successfully initialized with {%{public}@, %{public}@}
%s SpkrId:: Released OS transaction for %{public}@
%s SSROrch[%{public}@]:: Ignoring addAudio, endAudio: %d procSamples: %lu maxProcSamples: %lu
%s SSROrch[%{public}@]:: Released OS transaction for %{public}@
%s SSROrch[%{public}@]:: Creating OS transaction for %{public}@
%s SSROrch[%{public}@]:: Scorecard %{public}@ with delay:%{public}ldms, processed:%{public}ldms, await:%{public}ldms
%s ERR: Posting diagnostic report for abnormal score delay - %ldms
%s SSROrch[%{public}@]:: Sync score report with %{public}f delay - with known user scores %{public}@
%s SSROrch[%{public}@]:: ERR: VoiceInfo is nil from recognizer %{public}@
%s SSROrch[%{public}@]:: Discarded speaker scores for session - %{public}@
%s SSROrch[%{public}@]:: EndAudioCalled is false, returning for recognizer %{public}@
%s SSROrch[%{public}@]:: PSR Analyzer finished the session with %{public}@
%s SSROrch[%{public}@]:: SAT Analyzer finished the session with %{public}@
%s SSROrch[%{public}@]:: Wait for %{public}@ analyzer to complete the session - %{public}@
%s SSROrch[%{public}@]:: FilePath:%@, combinedScores - %{public}@
%s SSROrch[%{public}@]:: Finished the session with known user scores %{public}@
%s SSROrch[%{public}@]:: Discarded speaker scores for session
%s SSROrch[%{public}@]:: Speech started at - %ldms
%s SSROrch[%{public}@]:: Starting a new segment of speech - %ldms
%s SAT Supervector created
%s Skipping PHS DES record creation
%s ERR: failed to create PHS DES recored with error: %@
%s Failed to create PHS DES record: %{public}@
%s Created PHS DES record with identifier: %{public}@
%s %@
%s Remote device type: %zu, Remote device UUID list: %{private}@
%s CSVoiceTriggerAsset found: %{public}@
%s Locale: [%{public}@]
%s No locale set when creating phrase spotter.
%s Creation of Keyword Detector failed.
%s %s async called
%s %{public}s async called
%s Waiting for didStop
%s Done waiting for didStop
%s Called before completion called
%s %{public}s Called
%s BEGIN num:%{public}ld use:%{public}d
%s AudioSession setup failed
%s Has wrong audio routing, ask user to unplug headset
%s Start Audio Session failed
%s Resetting zero counter
%s _sessionNumber [%{public}ld]
%s CoreSpeech received the UUID from UI: %@
%s %{public}s Canceling Training
%s Called with status : %{public}d
%s %{public}s called
%s AudioSession StartRecording Failed
%s Setting suspendAudio:[%{public}d]
%s Resume training
%s Suspend training
%s Stop Listening
%s ERR: Failed to save explicit utterance
%s audioSessionDidStopRecording
%s ERR: SpeakerRecognition is not available on this platform
%s Creating audioRecorder has failed
%s AudioRecorder creation failed : %@
%s AudioStream Handle ID is invalid : %{public}@
%s audioRecorder %p created
%s Cannot prepare since audio recorder does not exist
%s Failed to activate audio session, error : %{public}@
%s AudioRecorder is already recording, do not prepare anymore
%s Failed to prepareAudioStreamRecord : %{public}@
%s Failed to startAudioStream : %{public}@
%s failed to stopRecording : %{public}@
%s audioInput:[%@]
%s audioOutput:[%@]
%s ERR: voiceProfile is nil - Bailing out
%s ERR: Failed to create TriggerPhraseDetector in %{public}@ with %{public}@
%s ERR: Failed in trigger processing %{public}@ with %{public}@
%s Trigger Score %{public}f not satisfied implicit VT threshold %f
%s Using recognizer scale factor: %f for phrase detector
%s ERR: Failed to create trigger phrase detectors
%s Processing %{public}@ for trigger word detection
%s ERR: Failed to read file: %@
%s ERR: Failed processing %{public}@ with error %{public}@
%s ERR: %{public}@
%s Best trigger score for %{public}@ is %{public}f (%{public}f, %{public}f)
%s Siri language is nil, falling back to %@
%s endpointUUID not provided, fallback to legacy query
%s Failed to query language code with endpointId %@, trying legacy query
%s Sending Analytics Event - %{public}@
%s Processing onboarded Siri user: %{public}@
%s Detected matching %{public}d users: %{public}@
%s Valid profile not found %{public}@ and %{public}@ - defaulting to %{public}@
%s Adding invalid user for deletion - %{public}@
%s Skipping retaining user %{public}@
%s Detected invalid user: %{public}@
%s File path doesnt exist - %{public}@
%s ERR: Failed reading contents of SAT root %{public}@ with %{public}@
%s App domains in use - %{public}@
%s ERR: Failed determining if file is dir-entry url=%{public}@ with %{public}@
%s Deleting invalid file %{public}@
%s Deleting invalid domain %{public}@ not part of domains %{public}@
%s Processing domain - %{public}@
%s Found profile %{public}@ with no enrollment utts
%s Deleted voiceprofile with error %{public}@
%s ERR: Failed reading AppDomain %{public}@ at %{public}@ with %{public}@
%s Processing locale - %{public}@
%s Deleting invalid locale %{public}@ not supported in set %{public}@ and current language %{public}@
%s Processing profile - %{public}@
%s Deleting invalid profile %{public}@
%s Removing Implicit utterance cache directory at %{public}@
%s Processing profile %{public}@ with version %{public}d and identity %{public}@
%s Found legacy voice profile - Skipping
%s Deleting invalid SAT entry: %{public}@
%s ERR: Failed to get atrributes of file %{public}@, err %{public}@, size %{public}llu
%s Deleting invalid SAT entry: %{public}@ %{public}@
%s Found non-meta file: %{public}@
%s Deleting invalid SAT entry: %{public}@ : <%{public}@>
%s Processed %{public}@ with %{public}d explicit and %{public}d implicit utterances
%s ObsoleteCutOffDate is nil - Bailing out
%s Checking payload utterances prior to %{public}@ for profile %{public}@ and modelType %d
%s Deleting lifetimeexpired SAT entry %{public}@
%s Deleted lifetimeexpired metafile %{public}@
%s Deleting model file %{public}@ with err %{public}@
%s CSVTUI continuousZeros detected.
%s CSVTUI continuousZeros not detected.
%s SpkrId:: ERR: missing arguments to create voice profile - Bailing out
%s Importing %{public}@ of %{public}@ from import Dir %{public}@
%s Successfully imported %{publice}@ %{public}lu(%{public}lu) utterances to profile %{public}@
%s Failed in importing %{public}@ of %{public}@ from import Dir %{public}@
%s Copied %{public}@ to %{public}@ with error %{public}@
%s Copied TD audio files %{public}lu to TDTI which now has %{public}lu(%{public}lu) utterances
%s Error to copy utterance from %{public}@ to %{public}@, error: %{public}@
%s Copied Utterance from %{public}@ to %{public}@
%s Error to copy jsonFile from %{public}@ to %{public}@, error: %{public}@
%s Successfully copied %{public}lu(%{public}lu) utterances to profile %{public}@
%s ERR: date is nil - Bailing out
%s Filtered %@ with enrolled date %@
%s Couldn't delete invalidated speaker model at path %{public}@ %{public}@
%s ERR: Removing %{public}@ as explicit utterances %{public}d from audio dir - %{public}@
%s SAT path doesnt exist - %@
%s Coudn't mark SAT enrollment %{public}@ at path %{public}@
%s Marked SAT enrollment %{public}@ at path %{public}@
%s We can't mark SAT %{public}@ when there is no audio directory
%s ERR: Unknown device-category for device: %{public}@
%s Unable to read data from file: %@
%s Could not read existing %@ file: err: %@
%s ERR: error creating updatedVoiceProfileJsonData from: %@, err: %@
%s ERR: error removing voice profile version file at: %@, err: %@
%s ERR: Error writing voice profile version file at: %@, err:%@
%s ERR: Profile dict is nil - Bailing out
%s ERR: error updating updatedVoiceProfileJsonData from: %@, err: %@
%s ERR: Failed initialization in _EARSyncSpeechRecognizer initWithConfiguration
%s ERR: processAudioChunk failed
%s ERR: endAudio failed
%s SpkrId:: Unknown CSSpIdType string: %@
%s ERR: Unknown CSSpIdType: %lu
%s Unknown CSSpIdType: %lu
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s SpkrId:: Exceeded privacy limit for grading utterances : %ld (%d)
%s ERR: reading contents of gradingDir: %{public}@ with error %{public}@
%s Deleting orphaned grading file %{public}@
%s SpkrId:: VoiceId not supported in language %{public}@
%s SpkrId:: ERR: filePath passed as nil - Bailing out
%s SpkrId:: ERR: Could not read existing %@ file: err: %@
%s SpkrId:: ERR: %@ is a directory
%s SpkrId:: ERR: file do not exist - %@
%s Unknown Device category for deviceProduceType: %@
%s ERR: Unknown device. returning false: %{public}@
%s ERR: satLanguagePath is nil. returning false
%s Voice Profile Mismatch - CurrentDeviceCategory %@ VoiceProfileCategory %@
%s Malformed audio-dir URL for string <%{public}@>:url
%s ERR: reading contents of audioDir: %{public}@
%s No jsonFiles found in %{public}@: jsonFiles.count=%{public}lu
%s Unexpected: empty JSON data for file: %{public}@
%s Error reading metaDict at path: %{public}@
%s metaProductType: %{public}@
%s vtprofile: currDevice=[%{public}@:%{public}@] ; vpDirDevice=[%{public}@:%{public}@]
%s VoiceProfile MATCH
%s VoiceProfile MIS-MATCH
%s Could not find productType in VT-Meta file, trying next one
%s No compatible VT profile found for CurrDevice: %{public}@
%s ERR: fetching contents of %{public}@ failed with error %{public}@
%s ERR: Directory is nil - Bailing out
%s ERR: %{public}@ doesnt exist - Bailing out
%s Dump content of %{public}@ - %{public}@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: Seeing more than one voice profiles for Siri App Domain
%s SpkrId:: uttMetaPath is nil!
%s SpkrId:: scoreCard is nil!
%s SpkrId:: Error creating uttMetaJsonData: %@
%s SpkrId:: Failed to create UttMeta...
%s Setting payloadstartSample %lu for trigger duration of %fsecs
%s ERR: Setting max payloadstartSample %lu for trigger duration of %fsecs
%s Failed to read file: %@
%s Deleted file %{public}@
%s EOF: utteranceLength: %lums, tdlength: %lums tdtiLength: %lums tdtiDiscardedLength: %lums
%s satAudioDirectory is nil - Bailing out
%s metaVersionFile %{public}@ doesnt exist
%s Found %{public}d ambiguous explicit utterances
%s metaVersionFile %{public}@ doesnt exist - Skipping
%s ERR: Fetching contents of %{public}@ failed with error - %{public}@
%s ERR: Failed to delete %{public}@ with error %{public}@
%s ERR: Scores for profileId %{public}@ not present in %{public}@ - Skipping
%s Called with explicit spId type %{public}d - Bailing out
%s Voice Profile pruning cookie from Asset %{public}@ lastCookie %{public}@
%s Pruning cookie unavailable from asset - Bailing out
%s Already pruned voice profile - Bailing out
%s ERR: Failed updating pruning cookie
%s Explicit utterances: %{public}@, Implicit utterances: %{public}@
%s ERR: No explicit utterances!!! - Bailing out
%s ERR: Low explicit utterances - Bailing out
%s Zero implicit utterances - Bailing out
%s Pruning(1)::----------------------------- Retrain profile to create explicit model ---------------------------------------
%s ERR: Failed to create SSR context with error %{public}@ - Bailing out
%s Pruning(2)::----------------------------- Check Explicit Utterance scores ---------------------------------------
%s Low Score Explicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Explicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f(%{public}.3f) C:%{public}.3f
%s ERR: Detected explicit utterances with lower scores, Bailing out
%s Pruning(3)::----------------------------- Implicit selection ---------------------------------------
%s ERR: ScoreCard is nil in voice profile pruning - Bailing out
%s Deleting low Score Implicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Implicit utterance[%{public}d]: %{public}@ --> T:(%{public}.3f, %{public}.3f) S:(%{public}.3f, %{public}.3f) P:(%{public}.3f, %{public}.3f) C:%{public}.3f
%s Pruning(4)::----------------------------- Implicit sampling ---------------------------------------
%s Utterance selection totalImplicit: %{public}lu selectionIndex: %{public}lu retentionCount: %{public}lu deleteCount: %{public}lu 
%s Deleting implicit utterances(%lu) - %{public}@
%s Pruning(5)::----------------------------- Retrain the voice profile ---------------------------------------
%s ERR: creating pruning voice profile failed with %{public}@
%s ERR: Failed in processing %{public}@ with %{public}@
%s Deleting %{public}@
%s Skipping SAT Model {%{public}@, %{public}@} for %{public}@
%s Skipping model {%{public}@, %{public}@} for %{public}@
%s Added model context {%{public}@, %{public}@} for %{public}@
%s ERR: uttPath is nil -  Bailing out
%s ERR: uttPath is nil - Bailing out
%s ERR: uttMeta is nil - Bailing out
%s ::: Error creating json Metadata: %{public}@
%s ERR: uttMetaURL is nil, defaulting to NO
%s ERR: metaData is nil, defaulting to NO for %{public}@
%s ERR: read metafile %{public}@ failed with %{public}@ - defaulting to NO
%s ERR: uttMetaURL is nil - Bailing out
%s metaData is nil for %{public}@ - Bailing out
%s ERR: read metafile %{public}@ failed with %{public}@ - Bailing out
%s ERR: metaDict from file %{public}@ isnt a dictionary - %{public}@
%s ERR: %{public}@ is not present
%s ERR: Unexpected. metaVersionFileData is empty while the file exists at: %{public}@
%s Json-Err reading metaVersionFile: %{public}@: err: %{public}@
%s ERR: filePath is nil!
%s Testing [%@] against regex.
%s Fired VoiceTrigger Timeout
%s Stop right now since ASR has issue
%s EOS Timeout Fired
%s Force endpoint fired
%s Discarding surplus audio of %{public}lu samples, audio sample available %{public}lu (%{public}lu, %{public}lu, %{public}lu)
%s AudioSession Started
%s AudioSession Stopped
%s Begin of speech detected
%s End of speech detected with endpoint type: %{public}ld
%s unknown endpoint type
%s Called with status : %{public}d and success : %{public}d utteranceStored : %{public}d
%s ERR: Failed to store utterance, overiding status
%s Non Final: [%{public}@]
%s NON Final Matching
%s Final: [%{public}@]
%s Final Matching
%s Final Not Matching
%s SPEECH RECOGNITION TASK FINISH UNSUCCESSFULLY
%s %{public}@ %{public}@ %{public}ld %{public}@
%s Recog Result: [%{public}ld]
%s closeSession tracking bool, calling old completion
%s returning status to UI : %{public}d
%s Already reported status or no callback
%s Will suspend training
%s Will resume training
%s Decide to delay ending ASR: [%{public}ld] samples
%s Triggered! Event info: %{public}@
%{public}9lld %{public}9lld %{public}9lld
%s analyzing.... score so far: %{public}5.3f (%{public}ld)
%s feeding tailing: [%{public}ld] samples
%s correctSampleSize:    [%{public}ld]
%s accumSampleSize:      [%{public}ld]
%s startBufferIndex:     [%{public}ld]
%s startBufferSampleSize:[%{public}ld]
%s samplesToBeDeleted:   [%{public}ld]
%s Total Number of buffs:[%{public}ld]
%s Adjusting the start buffer
%s Adjusting the array elements
%s Unsupported
%s %{public}s CALLED
%s Master Timeout Fired
%s recognized text = %{public}@
%s sharedVoiceProfileManager already instantiated with a different endpointUUID. existing-endpointUUID:%@ requested-endpointUUID:%@
%s ERR: Profile not available for %{public}@ & %{public}@ - Bailing out
%s ERR: No configured Siri Profiles
%s ERR: More than one Siri Voice Profiles - %{public}@
%s ERR: Failed to add profile into the store with error %{public}@
%s isImplicitTraining required for profileId %{public}@, locale(%{public}@) ? %{public}@
%s Implicit training not needed since: asset(%{public}@), profileStore(%{public}@), profile(%{public}@), profile locale(%{public}@)
%s ERR: Finished implicit training for %@ with error %{public}@
%s Finished implicit training for %@
%s Received implicit utterance for %{public}@ from %{public}@ with context %d
%s ERR: FilePath is nil - Bailing out
%s ERR: Training utterance doesnt exist at %@ - Bailing out
%s ERR: Training utterance is marked as directory at %@ - Bailing out
%s VoiceTriggerEventInfo is nil - Bailing out
%s kVTEILanguageCode is nil - Bailing out
%s ERR: trigger score not found in VTEI - Bailing out
%s ERR: SAT did not trigger!!! - Bailing out
%s Failed to add implicit training utterance to remote, error: %{public}@
%s Using asset %{public}@ provided by caller
%s Implicit training not enabled for %{public}@
%s sharedSiriId is nil - Bailing out
%s Rejecting barge-in utterance from adding to voice profile
%s Privacy disallowed implicit utterance %{public}@ - skipping
%s ERR: Failed to segment %{public}@ with %{public}@ - Bailing out
%s Processed implicit utterance %{public}@ successfully
%s Voice Profile is full - Ignoring
%s Implicit Policy not satisfied - Ignoring
%s ERR: Failed to process implicit utterance %{public}@ with error %{public}@
%s Enrolling voice profile of %@ 
%s Skipping download for voice profile: %{public}@
%s Failed enrolling %@ with error %@
%s Failed to get device hash list %{public}@
%s Processing sync data from device hash: %{public}@
%s Skipping language [%{public}@] since we already have enrollment data for this language
%s Skipping language [%{public}@] as file path doesnt exist - %{public}@
%s Skipping language [%{public}@] as voice profile not compatible
%s Error to copy profile from %{public}@ to %{public}@, error: %{public}@
%s Adding voiceprofile for %{public}@ in language %{public}@ completed with error %{public}@
%s ERR: Failed migrating Voice profile for language %{public}@ with error %{public}@
%s Successfully added %{public}@ in %.2fms
%s language: %{public}@, enableVTAfterSyncLanguage: %{public}@, currSiriLanguage: %{public}@
%s Enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@ and enrolled language: %{public}@
%s VoiceTrigger does not exist for this platform, not setting VoiceTriggerEnabled
%s Not enabling VoiceTrigger Upon VoiceProfile sync for language: %{public}@
%s Sucessfully migrated language %{public}@
%s Migrated language %{public}@ but failed to mark SAT enrollment
%s Sucessfully marked as migrated for language : %{public}@
%s Failed to mark migrated for language : %{public}@
%s Failed to remove update path [%{public}@] upon migration completion, error: %{public}@
%s Skipping download for unsupported OS
%s Skipping download for tvOS when shared id is nil
%s Skipping download for language [%{public}@] since we already have enrollment data for this language
%s Failed to download voice profile with error %{public}@ and category %{public}@ 
%s Successfully enrolled voice profile %@ with %{public}@ profile
%s Triggering profile sync check
%s Skipped enrolling voice profile %@ with %{public}@ profile
%s ERR: Failed in enrolling Voice profile %@ with category %{public}@ profile
%s Failed to enroll siriProfileId %@ with %{public}@
%s endPointId:%@, currentLanguageCode:%@
%s Language %{public}@ not supported in %{public}@ - Skipping
%s Skipping profile download for %{public}@ - %{public}@ not matching current %{public}@
%s Skipping profile download for %{public}@ - voiceId not supported in %{public}@
%s ERR: Failed migrating Voice profile with ID %{public}@ for language %{public}@ with error %{public}@
%s Sucessfully enrolled %{public}@ for language %{public}@
%s PHS update directory already exists, remove before we move forward
%s Failed to delete PHS update directory
%s Failed to create PHS update directory
%s Upload of Voice Profile for %@ completed with error %{public}@
%s Upload of Voice Profile for %@ completed successfully
%s ERR: Failed to delete existing SATUpload diretory : %{public}@
%s Upload trigger of voice profile of %@ 
%s Upload not supported on %{public}@
%s Legacy upload API called on Horseman - Bailing out
%s Cannot delete existing SATUpload Diretory : %{public}@
%s Cannot create SAT Upload Directory : %{public}@
%s Cannot create %{public}@ with error %{public}@ - Skipping language
%s Cannot create directory(%{public}@)
%s Cannot copy file: %{public}@ to %{public}@
%s ERR: siriProfileId is nil - Bailing out
%s Unsupported languagecode %{public}@ in %{public}@ - Skipping
%s Skipping uploading %{public}@ legacy version (%lu) of voice profile, current version %lu
%s Skipping uploading %{public}@ voice profile for profileId %@
%s Skipping audiocache file %@
%s Cannot copy file %{public}@ to %{public}@ with error %{public}@
%s ERR: Failed to copy from %{public}@ to %{public}@ with error %{public}@
%s ERR: Cannot copy file %{public}@ to %{public}@ with error %{public}@
%s Successfully copied {%{public}d,%{public}d} utterances from %@ to %@
%s Cannot copy voice profile from %@ to %@ with error %{public}@
%s Triggering upload of voice profile %@
%s Upload of voice profile at %@ with category %{public}@ completed successfully
%s Triggering upload of explicit voice profile %@
%s Upload of explicit voice profile at %@ completed successfully
%s Setting VoiceProfile Training Sync for language: %{public}@
%s ERR: %{public}s: Bailing out as language is nil!
%s VoiceProfile training sync language: %{public}@, VoiceProfile language: %{public}@
%s ERR: Unknown device - returning nil
%s NonAOP device-category - returning nil
%s ERR: Fetching cached devices resulted in error %{public}@
%s Devices with voice profile is nil!
%s Skipping %{public}@ not locally present
%s ERR: error creating profilesJsonData: %@, err: %@
%s Cached devices with VoiceProfile in iCloud: %{public}@
%s CachedVoiceProfileFetch: Done Waiting with timedOut=%ld, waitTimeMs: %fms
%s ERR: metaBlob is nil. Returning false, language: %{public}@
%s ERR: Unknown device. Returning false, language: %{public}@
%s ERR: Unknown device-category for device: %{public}@, languageCode: %{public}@
%s ERR: Failed to deserialize metaBlob with error %{public}@
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in metablob %{public}@
%s currDevice=[%{public}@ : {%{public}@}] ; syncedDevice=[%{public}@ : {%{public}@}]
%s CurrDevice: [%{public}@ : {%{public}@}] DOES NOT have VoiceProfile synced in iCloud
%s Triggering VoiceProfile upload for %{public}@
%s Querying VoiceProfile upload state on %{public}@
%s Looking VoiceProfile for CurrDevice: %{public}@{%{public}@} in devices %{public}@
%s VoiceProfile available locally for %{public}@, not uploaded yet
%s Searching for synced-VoiceProfile for CurrDevice: %{public}@{%{public}@}
%s Will Enable VoiceTrigger after VoiceProfile sync for language: %{public}@
languageCode: %{public}@
%s Devices with VoiceProfile in iCloud for language: %{public}@:%{public}@
%s Timedout waiting for AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage: %{public}ld, waitedFor: %{public}d, Returning nil
%s timeToRet(AFSettingsConnection:getDevicesWithAvailablePHSAssetsForLanguage:): %{public}fms
%s voiceProfileArray is nil for %{public}@ and %{public}@!
%s voiceProfileArray is nil!
%s Profiles already migrated, check for enrollment on %{public}@ on profile %{public}@
%s ERR: Failed to delete Voice Profile %{public}@ with error %{public}@
%s Couldn't delete SAT directory at path %@ %@
%s Couldn't delete SAT cache directory at path %@ %@
%s No Audio file exists when enrollment marker is set, remove marker
%s Contents of audio dir - %{public}@
%s Language Code is nil!
%s No completionBlock provided to importVoice Profile
%s fileList - %@
%s ERR: Fetching contents of %@ failed with error - %@
%s wavList - %@
%s Adding utterances to profileID: %@ finished with err: %@
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s Failed to teardown AVVC : %{public}@
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Calling AVVC setContext : %@
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s toConfiguration : %{public}d
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s ERR: Failed to create asset providers - Bailing out
%s parsing provider: %@ name: %@
%s ERR: got nil assets from provider: %@
%s Got asset with version: %@ from provider: %@
%s ERR: Asset not available from provider: %@
%s SpkrId:: Scorecard for {%{public}d, %{public}.2fsec %dms} - %{public}@
%s SpkrId:: %@
%s SpkrId:: Discarded speaker scores for session - %{public}@
%s SpkrId:: Final - %@
%s Locale doesn't match, return nil
%s ::: found %{public}lu installed assets for matching query: %{public}@
%s ERR: Failed to asset for %{public}@
%s Error running query: %{public}@, error: %{public}lu
%s Failed to get assetString for assetType %{public}d
%s ::: found %{public}lu assets matching query: %{public}@
%s Error running asset-query: %{public}@, error: %{public}lu
%s Asset state : %{public}ld
%s Chosen Asset %{public}@
%s SpkrId:: ERR: appDomain passed as nil
%s SpkrId:: ERR: locale passed as nil
%s Profiles already migrated - Bailing out
%s Migration of voice profile is triggered...
%s Sat directory doesnt exist %@
%s Language %{public}@ not supported in %{public}@ - Deleting
%s Migrating voice profiles in languages - %{public}@
%s Voice profile migration for language - %{public}@
%s Skipped migrating non-siri landed profile - %{public}@, %{public}@
%s voice profile created is nil!!! - Skipping %{public}@
%s Moving contents from %{public}@ to %{public}@ failed with error %{public}@
%s Completed migrating voiceprofile for %{public}@ in language %{public}@
%s Triggered cleanup duplicated profiles
%s ERR: Deleted duplicated voiceprofile(%lu): %{public}@
%s Found %{public}d duplicated profiles
%s Deleted invalid Siri profile with err: %{public}@
%s Triggering voice profiles download
%s ERR: Failed retraining LiveOn onboarded users with error %{public}@
%s Successfully retrained LiveOn onboarded users
%s Cleanup model files with assets %{public}@
%s Synchronize voiceprofiles with Assistant...
%s ERR: Deleted stale voiceprofile(%lu): %@
%s Missing user models - Triggering voice profiles download
%s Needs retraining - Triggering voice profiles download
%s Skip SAT retrainer since combination weight is 1
%s ERR: Failed in adding %{public}@ to %{public}@ with error %{public}@
%s Added Implicit SAT vector from %{public}@ to profile %{public}@
%s Locale is nil - Bail out
%s assetForLocale is nil - Bail out
%s ERR: Failed purging profile %{public}@ with error - %{public}@
%s ERR: Failed to get top scorer in %{public}@ - Bailing out
%s ERR: Utterance scored %{public}f (%{public}@) with next top score %{public}f (%{public}@) for profileId %{public}@
%s Utterance scored %{public}f (%{public}@) with next top score %{public}f (%{public}@) and thresholds (%{public}f, %{public}f)
%s Utterance scored %{public}f for %{public}@ and thresholds (%{public}f, %{public}f)
%s Skipping retraining for language %{public}@, current %{public}@
%s Detected mean pitch for explicit utterances = %{public}f Hz
%s Deleting VoiceProfile %{public}@
%s Err: %@
%s Needs Retraining Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Needs Retraining storage for Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Skipping Profile %{public}@ - existing {%{public}@} downloaded {%{public}@, %{public}d}
%s Needs Retraining %{public}@ model update for profile %{public}@ 
%s Retraining %{public}@ for locale %{public}@
%s Needs retraining %{public}@ - Triggering voice profiles download
%s Retraining successfully finished for %{public}@ in %{public}fms
%s ERR: Retraining failed for %{public}@ with error %{public}@ in %{public}fms
%s voiceProfile is nil!
%s Adding User Voice Profile %@
%s Updating User Voice Profile to %@ from %@
%s Deleting User Voice Profile %@
%s User Voice Profile not found %@ - Bailing out
%s ERR: UserVoiceProfile Action undefined %ld - Bailing out
%s Updating profile %{public}@ with userName %{public}@
%s Retraining for locale %{public}@ with force %d
%s Retraining finished for %@ with error %@ in %fms
%s Creating OS Transaction %p for %{public}@
%s No Implicit audio - ignoring filterToVoiceTriggerUtterances
%s ERR: ignoring filtering option as %{public}@ or %{public}@ is nil
%s ERR: ignoring filtering option as VTAssets not found on %{public}@
%s ERR: Failed training %{public}@ of %{public}@ with error %{public}@
%s Failed to create %{public}@ model with error %{public}@ for profile %{public}@
%s Releasing OS Transaction %{public}@
%s Skipping retraining for %{public}@ - for {%{public}@, %{public}@}
%s ERR: Failed resetting for %{public}@ - for {%{public}@, %{public}@}
%s ERR: Failed in retraining %{public}@ with error %{public}@
%s ERR: Failed to delete the model at %{public}@
%s Added utterance %{public}@ to {%{public}@, %{public}@, %{public}@, %{public}@} with score %{public}@
%s Rejected utterance %{public}@ with error %{public}@
%s Failed to create biometricdevice with error %@
%s triggerTimeStamp is nil - Bailing out
%s Biometric match happened in last %f secs
%s Biometric match result: %@ happened in last %f secs
%s No biometric information available
%s BiometricMatchEvent: result = %u, timeStamp = %llu
%s BiometricMatchEvents unavailable with error %@
%s ERR: Biometric device is nil - Bailing out
%s Saving utterance and meta as %{public}@ training.
%s Failed to write utterance into %{public}@
%s Saving %{public}@ at %{public}@ as %{public}@ training.
%s numSamplesToWrite %{public}lu
%s Failed to get CSAudioFileWriter:
%s Failed to addSamples to CSAudioFileWriter: %{public}@
%s Failed to endAudio on CSAudioFileWriter: %{public}@
%s ERR: called with nil metaPath
%s ERR: called with nil uttPath
%s ERR: called with nil uttMeta
%s Cannot create json file : %{public}@
%s endpointUUID: %{public}@
%s Skipping Model {%{public}@, %{public}@} for %{public}@
%s Skipping Model {%{public}@, %{public}@} as file doesnt exist at %{public}@
%s ERR: triggering profile retrain for asset %{publiic}@
%s PHS threshold for %lu doesn't exist, use default
%s %{public}@ doesnt exist
%s Could not read: %{public}@
%s Could not decode contents of: %{public}@: err: %{public}@
@333333
softlink:r:path:/System/Library/PrivateFrameworks/BiometricKit.framework/BiometricKit
CSVTUIEndpointAnalyzer
AVVC
SSRVoiceActivityDetector
EARCaesuraSilencePosteriorGeneratorDelegate
NSObject
CSVTUITwoPassKeywordDetector
SSRSpeakerAnalyzerPSR
SSRSpeakerRecognizerPSR
SSRSpeakerAnalyzerPSRDelegate
SSRSpeakerRecognizer
SSRTriggerPhraseDetectorNDAPI
SSRSpeakerRecognitionOrchestrator
SSRSpeakerRecognizerDelegate
SSRVoiceActivityDetectorDelegate
SSRVoiceProfileRetrainerSAT
SSRVoiceProfileRetrainer
SSRDESRecordWriter
SSRSpeakerRecognitionScorer
SSRVTUITrainingManager
CSVTUITrainingSessionDelegate
CSVTUIAudioSessionDelegate
CSVTUIEndpointAnalyzerDelegate
SSRVoiceProfileRetrainerFactory
CSVTUIAudioSessionRecorder
CSVTUIAudioRecorderDelegate
CSVTUIAudioSession
SSRVoiceProfileMetaContext
SSRTriggerPhraseDetector
CSAsset
SSRRemoteControlClient
LanguageCode
SSRTrialAssetProvider
SSRAssetProviding
CSVTUIKeywordDetector
SSRVoiceProfileComposer
SSRVoiceProfileRetrainerPSR
SSRLoggingAggregator
RecordContext
SSRSpeakerRecognizerSAT
SSRVoiceProfileStoreCleaner
CSVTUIRemoteRecordClient
CSVTUISelfLoggingDigitalZeroReporter
CSDigitalZeroReporting
SSRVoiceProfile
NSSecureCoding
NSCoding
SSRTriggerPhraseDetectorQuasar
SSRUtils
CSVTUIEditDistance
SSRVoiceProfilePruner
SSRSpeakerRecognitionControllerDelegate
SSRVoiceProfileRetrainingContext
SSRVoiceProfileModelContext
SSRVoiceProfileMetadataManager
CSVTUIRegularExpressionMatcher
CSVTUITrainingSessionWithPayload
SFSpeechRecognitionTaskDelegate
CSVTUIEndPointDelegate
CSVTUITrainingSession
SSRVoiceProfileManager
debugDescription
CSVTUIAudioRecorderRemoteDeviceContext
CSVTUIAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
SSRAssetManager
SSRSpeakerRecognitionController
SSRSpeakerRecognitionOrchestratorDelegate
SSRMobileAssetProvider
SSRVoiceProfileStore
SSRBiometricMatch
BKDeviceDelegate
SSRSpeakerAnalyzerSAT
SSREnrollmentDataManager
SSRVoiceProfileStorePrefs
SSRSpeakerRecognitionContext
SSRSpeakerRecognitionModelContext
CSVTUIASRGrammars
NSURLSessionDelegate
SSRPitchExtractor
SSRAESKeyManager
SpeakerRecognition
AudioHardware
CSVTUITrainingResult
CSVTUITrainingSessionStopListen
CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:
T@"NSNumber",&,N,V_profilePitch
JSONObjectWithData:options:error:
T@"NSString",&,N,V_sharedSiriId
SSRSpeakerProfilesBasePath
TQ,N,V_spIdType
SSRVoiceActivityDetector:didDetectStartPointAt:
_CSSATCachePath
T@"<CSAudioFileWriter>",&,N,V_ssrUttLogger
_cleanupOrphanedMetafilesAtURL:
T@"<CSVTUIEndpointAnalyzerDelegate>",W,N,V_delegate
_configFilePath
T@"<SSRAssetManagerDelegate>",W,N,V_delegate
_detectorQuasar
T@"<SSRSpeakerRecognitionOrchestratorDelegate>",W,N,V_delegate
_endAudioCalled
T@"<SSRSpeakerRecognizer>",&,N,V_satRecognizer
_getVoiceTriggerAssetTypeString
T@"<SSRVTUITrainingManagerDelegate>",W,N,V_delegate
_interleavedABL
T@"BKDevice",&,N,V_biometricDevice
_mhUUID
T@"CSAudioPowerMeter",&,N,V_powerMeter
_phraseDetector
T@"CSVTUIAudioRecorderRemoteDeviceContext",&,N,V_remoteDeviceContext
_retrainVoiceProfile:withAsset:
T@"NSArray",&,N,V_assetProviders
_sessionProcess
T@"NSArray",&,N,V_voiceProfileArray
_stringByStrippingLeadingNoise:
T@"NSDate",&,N,V_dateAdded
audioFileWriter
T@"NSDictionary",&,N,V_combinedScores
bestEnd
T@"NSDictionary",&,N,V_lastSpeakerInfo
bundleForClass:
T@"NSDictionary",&,N,V_psrLastSpeakerInfo
containsObject:
T@"NSDictionary",&,N,V_satLastSpeakerInfo
context
T@"NSDictionary",R,N
dataForChannel:
T@"NSDictionary",R,N,V_expModelsContext
dealloc
T@"NSDictionary",R,N,V_voiceProfilesModelFilePaths
formattedString
T@"NSMutableArray",&,V_voiceProfileArray
getPitchForUtteranceAudioFiles:
T@"NSNumber",&,N,V_version
initWithConfigFilePath:withModelPath:withCompareModelFilePaths:
T@"NSObject<OS_dispatch_queue>",&,N,V_spgQueue
initWithLocale:
T@"NSObject<OS_os_transaction>",&,N,V_transaction
initWithVoiceRetrainingContext:
T@"NSString",&,N,V_currentLanguageCode
isRecordContextHearstDoubleTap:
T@"NSString",&,N,V_debugUtteranceJsonFilePath
isRunningQuasar
T@"NSString",&,N,V_invocationStyleStr
logDigitalZeroDetectionComplete
T@"NSString",&,N,V_productCategory
notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:
T@"NSString",&,N,V_profileId
processingEnded
T@"NSString",&,N,V_transDesc
profileBasePath
T@"NSString",R,C
recognizerScore
T@"NSString",R,N,V_appDomain
remoteDeviceUID
T@"NSString",R,N,V_debugUtteranceAudioFile
results
T@"NSString",R,N,V_deviceId
satConfigFileNameForCSSpIdType:
T@"NSString",R,N,V_profileID
setDefSepFeats:
T@"NSString",R,N,V_psrConfigRoot
setFrameLength:
T@"NSString",R,N,V_siriProfileId
setRms:
T@"NSURL",R,N
setVad:
T@"NSURL",R,N,V_resourceFilePath
spIdCtx
T@"NSURL",R,N,VmodelFilePath
stopMasterTimer
T@"SSRLoggingAggregator",&,N,V_logAggregator
stringByAppendingPathComponent:
T@"SSRSpeakerAnalyzerPSR",&,N,V_psrAnalyzer
stringForSpeakerRecognizerType:
T@"SSRSpeakerRecognitionContext",&,N,V_spIdCtx
updateDebugFilePathsForSegment:
T@"SSRTriggerPhraseDetectorNDAPI",&,N,V_detectorNDAPI
vadResourcePath
T@"SSRVoiceActivityDetector",&,N,V_vad
.cxx_destruct
T@"NSHashTable",&,N,V_observers
CSVTUITrainingSessionRMSAvailable:
T@"NSString",&,N,V_languageCode
SSRBasePathForAppDomain:
T@"NSURL",R,N,V_vadResourcePath
SSRVoiceActivityDetector:didDetectEndPointAt:
TQ,R,N,V_maxAllowedAudioSamples
T#,R
_assetProviders
T@"<CSVTUIAudioSessionDelegate>",W,N,V_delegate
_combinedScores
T@"<CSVTUIRemoteRecordClientDelegate>",W,N,V_delegate
_copyVoiceProfileAtPath:toPath:
T@"<SSRSpeakerRecognitionControllerDelegate>",W,N,V_delegate
_earSpg
T@"<SSRSpeakerRecognizer>",&,N,V_psrRecognizer
_filterToVoiceTriggerUtterances
T@"<SSRSpeakerRecognizerDelegate>",W,N,V_delegate
_homeId
T@"<SSRVoiceActivityDetectorDelegate>",W,N,V_delegate
_locale
T@"CSAsset",&,N,V_asset
_numConsecutiveNonSilenceFrames
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
_resultReported
T@"EARCaesuraSilencePosteriorGenerator",&,N,V_earSpg
_segmentCounter
T@"NSArray",&,N,V_compareVoiceProfileArray
_status
T@"NSArray",R,C,N,V_remoteTrainingDeviceUUIDList
_syncRecognizer
T@"NSDate",R,N,V_dateAdded
baseDir
T@"NSDictionary",&,N,V_lastScoreCard
biometricDevice
T@"NSDictionary",&,N,V_psrFinalSpeakerInfo
clientSilenceFeaturesAvailable:
T@"NSDictionary",&,N,V_satFinalSpeakerInfo
containsString:
T@"NSDictionary",&,N,V_voiceTriggerEventInfo
currentCalendar
T@"NSDictionary",R,N,V_compareModelFilePaths
dateFromString:
T@"NSDictionary",R,N,V_modelsContext
fetchMedicalDataWithCompletion:
T@"NSDictionary",R,N,V_vtEventInfo
getBoolForKey:category:default:
T@"NSNumber",&,N,V_pitch
implicitDiscardedUtteranceIndex
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
initWithLength:
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
initWithString:
T@"NSString",&,N,V_appDomain
isProxy
T@"NSString",&,N,V_debugUtteranceAudioFilePath
isRecordContextHomeButtonPress:
T@"NSString",&,N,V_homeId
lastSpeakerInfo
T@"NSString",&,N,V_locale
lowercaseString
T@"NSString",&,N,V_profileBasePath
numberWithBool:
T@"NSString",&,N,V_sessionId
productCategory
T@"NSString",&,N,V_userName
psrConfigFileNameForCSSpIdType:
T@"NSString",R,N
release
T@"NSString",R,N,V_configVersion
resetEndPointer
T@"NSString",R,N,V_debugUtteranceMetaFile
T@"NSString",R,N,V_locale
setDebugUtteranceAudioFilePath:
T@"NSString",R,N,V_psrConfigFilePath
setEndWaitTime:
T@"NSString",R,N,V_sessionId
setPsrAnalyzer:
T@"NSString",R,N,V_sysConfigRoot
setTransaction:
T@"NSURL",R,N,V_configFilePath
setWithObjects:
T@"NSURL",R,N,V_voiceProfileModelFilePath
ssrAudioLogsDir
T@"NSUUID",&,N,V_endpointUUID
stopRMS
T@"SSRRemoteControlClient",&,N,V_remoteControlClient
stringByAppendingPathExtension:
T@"SSRSpeakerRecognitionContext",&,N,V_context
suspendTraining
T@"SSRSpeakerRecognitionOrchestrator",&,N,V_orchestrator
T@"SSRTriggerPhraseDetectorQuasar",&,N,V_detectorQuasar
version
T@"SSRVoiceProfile",&,N,V_voiceProfile
T@"SSRVoiceProfile",R
T@"SSRVoiceProfileStorePrefs",&,N,V_storePrefs
T@"_EARDefaultServerEndpointFeatures",&,N,V_defSepFeats
T@"_EAREndpointer",&,N,V_hybridClassifier
TB,N,V_endpointReported
TB,N,V_processingEnded
TB,N,V_startpointReported
TB,R
TB,R,N
TB,R,N,V_filterToVoiceTriggerUtterances
TB,R,N,V_forceRetrain
TB,R,N,V_osTransactionReqd
TB,R,N,V_satModelAvailable
TB,R,N,VimplicitTrainingRequired
TB,R,V_speechRecognizerAvailable
TQ,N,V_activeChannel
TQ,N,V_audioStreamHandleId
TQ,N,V_currentDeviceCategory
TQ,N,V_endInSampleCount
TQ,N,V_extraSamplesAtStart
TQ,N,V_myriadResult
TQ,N,V_numSamplesProcessed
TQ,N,V_speakerRecognitionPSRProcessingStatus
TQ,N,V_speakerRecognitionProcessingStatus
TQ,N,V_speakerRecognitionSATProcessingStatus
TQ,N,V_totalNumSamplesReceived
TQ,N,V_voiceProfileDiscardedUtteranceCount
TQ,N,V_voiceProfilePrunedUtteranceCount
TQ,N,V_voiceProfilePruningFailureReasonCode
TQ,N,V_voiceProfileRetainedUtteranceCount
TQ,N,V_voiceProfileRetrainingFailureReasonCode
TQ,N,V_vtEndInSampleCount
TQ,R
TQ,R,N
TQ,R,N,V_activeChannel
TQ,R,N,V_audioStreamHandleId
TQ,R,N,V_maxAllowedSpeakerVectors
TQ,R,N,V_recognitionStyle
TQ,R,N,V_remoteTrainingDeviceType
TQ,R,N,V_scoreType
TQ,R,N,V_spIdType
TQ,R,N,VretrainerType
Td,N,V_retrainingWaitTime
Td,N,V_speakerRecognitionWaitTime
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_voiceProfileUpdateScoreMSE
Tf,R,N
Tf,R,N,V_combinationWeight
Tf,V_rms
Ti,R,N,V_audioStatus
Ti,R,N,V_sessionStatus
Tq,N,V_segmentStartPointSampleCount
Tq,R,N
Tq,R,N,V_sessionId
URLByAppendingPathComponent:
URLByAppendingPathExtension:
URLByDeletingLastPathComponent
URLByDeletingPathExtension
URLSession:didBecomeInvalidWithError:
URLSession:didReceiveChallenge:completionHandler:
URLSessionDidFinishEventsForBackgroundURLSession:
URLWithString:
URLsForDirectory:inDomains:
UTF8String
UUID
UUIDString
VTUITrainingManagerFeedLevel:
VTUITrainingManagerStopListening
_ASRErrorOccured
_ASRResultReceived
_CSSATCachePathForAppDomain:
_CSSATDownloadPath
_CSSATLegacyUploadPath
_CSSATUploadPathForSiriProfileId:
_activeChannel
_analyzerTrailingSamples
_appDomain
_asset
_audioAnalyzer
_audioBuffer
_audioFileWriter
_audioRecorder
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
_audioRecorderDidStopRecordingForReason:streamHandleID:
_audioSession
_audioSource
_audioStatus
_audioStreamHandleId
_audioZeroCounter
_beginOfSpeechDetected
_bestTriggerSampleStart
_biometricDevice
_buildAssetQueryForAssetType:
_caseInsensitiveHasMatchInEnumeration:
_checkIfDownloadRequiredForProfileId:
_checkIfModelsPresentForProfiles:forSpIdType:forAsset:
_checkIfRetrainingRequiredForProfile:
_cleanupAppDomain:
_cleanupCompletion
_cleanupContentsOfSatFolder:
_cleanupImplicitUtteranceCacheForProfile:
_cleanupInvalidAudioFiles:
_cleanupModelFilesAtDir:forAssetArray:
_cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:
_cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:
_cleanuplanguageCodePath:forAppDomain:
_combinationWeight
_compareModelFilePaths
_compareVoiceProfileArray
_compatibilityVersion
_compensateChannelDataIfNeeded:receivedNumChannels:
_configVersion
_context
_continuousZeroCounter
_convertDeactivateOption:
_convertVersionStringToFloat:
_copyExplicitAudio:withSpIdType:
_copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:
_createAudioAnalyzer
_currentAsset
_currentDeviceCategory
_currentLanguageCode
_currentTrainingSession
_dateAdded
_debugUtteranceAudioFile
_debugUtteranceAudioFilePath
_debugUtteranceJsonFilePath
_debugUtteranceMetaFile
_defSepFeats
_delegate
_deleteUserVoiceProfile:
_deleteUtterances:
_destroyAudioSession
_destroyVoiceController
_detectBOS
_detectorNDAPI
_deviceId
_didStopWaitingGroup
_downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:
_downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:
_enableVoiceTriggerIfLanguageMatches:
_endInSampleCount
_endOfSpeechDetected
_endpointReported
_endpointUUID
_enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:
_enrolledVoiceProfiles
_eventContext
_eventString
_expModelsContext
_extraSamplesAtStart
_filteredAssets:forLanguage:
_findLatestInstalledAsset:
_firedEndPointTimeout
_firedVoiceTriggerTimeout
_firstMatchesForRegularExpression:
_firstMatchesForRegularExpressions:
_firstPassResult
_footprint
_forceRetrain
_getBaseMetaDictionaryForUtterancePath:
_getEndpointAssetCurrentCompatibilityVersion
_getEndpointAssetTypeString
_getLMEWithGrammar:withLocale:
_getLastBiometricMatchEvent:atTime:
_getLeadingPatternsWithGrammars:withLocale:
_getPitchHzFromRawData:
_getProfileVersionFilePath
_getRecordSettingsWithRequest
_getRegexPatternsWithGrammars:withUtt:withLocale:
_getSSRAssetCurrentCompatibilityVersion
_getSSRAssetTypeString
_getScoresForAudio:withController:withDetector:forProfile:withCompletion:
_getTopScoringProfileIdFromScores:
_getTrailingPatternsWithGrammars:withLocale:
_getUserVoiceProfileDownloadCacheDirectoryForProfileId:forDeviceCategory:forVoiceProfileVersion:
_getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:
_getUtterancesFromDirectory:
_getVoiceProfilePathsToBeUploadedForSiriProfileId:
_getVoiceProfilesForSiriProfileId:withLanguageCode:
_getVoiceTriggerAssetCurrentCompatibilityVersion
_getVoicingProbFromRawData:
_grammar
_handleDidStopWithReason:
_hasCorrectInputAudioRoute
_hasCorrectOutputAudioRoute
_hasSubstring:
_hybridClassifier
_initializeSPGWithContext:
_initializeWithContext:
_installedMobileAssetOfType:forLanguage:
_invocationStyleStr
_isDirectory:
_isFirstPassTriggered
_isLegacyEnrollmentMarkedWith:forLanguageCode:
_isMarkedForVoiceProfileTrainingSyncForLanguage:
_isMaxNumContinuousZerosOverThreshold
_isRemoteVoiceTriggerAvailable
_isSATMarkedWithMarker:
_keywordAnalyzer
_keywordDetector
_keywordThreshold
_languageCode
_lastKeywordScore
_lastScoreCard
_lastScoreReportTimeStamp
_lastSegmentStartTime
_lastSpeakerInfo
_latestContext
_latestVersionedAssetOfType:fromProviders:forLocale:
_loadVoiceProfiles
_logAggregator
_logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:
_logVoiceProfileConfusionWithCleanup:
_markSATEnrollmentWithMarker:
_markVoiceProfileTrainingSyncForLanguage:
_masterTimer
_matchesRegularExpression:
_maxAllowedAudioSamples
_maxAllowedSpeakerVectors
_maxNumAllowedContinuousZeros
_maxNumContinuousZeros
_modelsContext
_myriadResult
_numRequiredTrailingSamples
_numSamplesAddedToSpeakerRecognizers
_numSamplesFed
_numSamplesProcessed
_numTrailingSamples
_observers
_orchestrator
_osTransactionReqd
_pNonInterleavedABL
_pageNumber
_pcmBufArray
_performRMS
_phId
_pitch
_powerMeter
_prepareVoiceProfileWithSiriProfileId:withUploadBlock:
_processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
_processAudioFileURL:
_processingEnded
_productCategory
_profile
_profileBasePath
_profileID
_profileId
_profilePitch
_psrAnalyzer
_psrConfigFilePath
_psrConfigRoot
_psrFinalSpeakerInfo
_psrLastSpeakerInfo
_psrRecognizer
_queue
_recognitionStyle
_recognizerScoreScaleFactor
_registerEndPointTimeout
_registerForceEndPointTimeout
_registerVoiceTriggerTimeout
_remoteControlClient
_remoteDeviceContext
_remoteRecordClient
_remoteTrainingDeviceType
_remoteTrainingDeviceUUIDList
_reportStopListening
_reportedStopListening
_resetWithContext:
_resourceFilePath
_retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:
_retrainVoiceProfile:withContext:
_retrainVoiceProfile:withContext:withUtterances:
_retrainingWaitTime
_rms
_sampleLengthFrom:To:
_satFinalSpeakerInfo
_satLastSpeakerInfo
_satModelAvailable
_satRecognizer
_saveTrainedUsers:
_scoreType
_segmentStartPointSampleCount
_sessionDelegate
_sessionId
_sessionNumber
_sessionStatus
_sessionSuspended
_setVoiceTriggerEventInfo:
_setupAudioSession
_sharedSiriId
_shouldShowHeadsetDisconnectionMessage
_shouldUseRemoteBuiltInMic:
_siriProfileId
_siriSetupID
_spIdCtx
_spIdType
_speakerRecognitionPSRProcessingStatus
_speakerRecognitionProcessingStatus
_speakerRecognitionSATProcessingStatus
_speakerRecognitionWaitTime
_speechRecognitionRequest
_speechRecognitionTask
_speechRecognizer
_speechRecognizerAvailable
_spgQueue
_ssrUttLogger
_startAudioSession
_startPointReported
_startpointReported
_stopAudioSession
_storePrefs
_stringByFixingNamePattern:
_stringByStrippingNoiseLeadingNoise:TrailingNoise:
_stringByStrippingTrailingNoise:
_suspendAudio
_synchronizeSiriVoiceProfilesWithAssistant
_sysConfigRoot
_totalNumSamplesReceived
_trainingCompletion
_trainingCompletionWithResult
_trainingSessions
_transDesc
_transaction
_updateTrainedUsersWithAction:UserVoiceProfile:
_updateVoiceProfileVersionFile
_userName
_utteranceId
_utteranceStored
_vad
_vadResourcePath
_version
_voiceController
_voiceControllerCreationQueue
_voiceControllerWithError:
_voiceProfile
_voiceProfileArray
_voiceProfileDiscardedUtteranceCount
_voiceProfileModelFilePath
_voiceProfilePathForSpidType:
_voiceProfilePrunedUtteranceCount
_voiceProfilePruningFailureReasonCode
_voiceProfileRetainedUtteranceCount
_voiceProfileRetrainingFailureReasonCode
_voiceProfileUpdateScoreMSE
_voiceProfilesModelFilePaths
_voiceTriggerEventInfo
_vtEndInSampleCount
_vtEventInfo
_waitingForDidStart
_writeMetaDict:forUtterancePath:
absoluteString
activateAudioSessionForStream:isPrewarm:recordMode:error:
activateAudioSessionWithReason:streamHandleId:error:
activationDeviceUID
activationMode
activeChannel
addAudio:numSamples:
addEntriesFromDictionary:
addImplicitTrainingUtteranceToRemoteFilePath:forVoiceProfileId:withVoiceTriggerCtxt:locale:withOtherCtxt:completion:
addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:
addKeyValuePair:with:
addObject:
addObjectsFromArray:
addSamples:numSamples:
addUserVoiceProfile:withContext:withCompletion:
addUtterance:toProfile:
addUtterance:toProfile:withAsset:
addUtterances:spIdType:
addUtterances:toProfile:withContext:withCompletion:
addUtterances:withPolicy:withCompletion:
allInstalledAssetsOfType:forLanguage:
allObjects
analyze:
analyzeSpeakerVector:withDimensions:withThresholdType:
analyzeSuperVector:withDimensions:withThresholdType:
analyzeWavData:numSamples:
announceCallsEnabled
appDomain
appendAudioPCMBuffer:
appendFormat:
appendString:
appendVoiceProfileDiscardedImplicitUtteranceScoreWith:
appendVoiceProfileExplicitUtteranceScoreWith:
appendVoiceProfileFailedExplicitUtteranceScoreWith:
appendVoiceProfileImplicitUtteranceScoreWith:
array
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
asset
assetForAssetType:resourcePath:configVersion:
assetForCurrentLanguageOfType:
assetProvider
assetProviders
attributes
attributesOfItemAtPath:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderDisconnected:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioSessionDidStartRecording:error:
audioSessionDidStopRecording:
audioSessionErrorDidOccur:
audioSessionRecordBufferAvailable:
audioSessionUnsupportedAudioRoute
audioSource
audioStatus
audioStreamHandleId
autorelease
availableDevices
averagePower
avvcContext
avvcContextSettings
bestScore
bestStart
bestTranscription
boolValue
bundlePath
bytes
bytesDataSize
canBePurged
cancelTrainingForID:
channelForProcessedInput
checkIfVoiceProfile:needsUpdatedWith:withCategory:
class
cleanupDuplicatedProfiles
cleanupInvalidModelsForProfile:withAssetArray:
cleanupInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:
cleanupOrphanedVoiceIdGradingFiles
cleanupProfileStore
cleanupVoiceProfileModelFilesForLocale:
cleanupVoiceProfileStore:
cleanupWithCompletion:
closeSessionBeforeStartWithStatus:successfully:completionWithResult:
closeSessionBeforeStartWithStatus:successfully:withCompletion:
closeSessionWithCompletion:
closeSessionWithStatus:successfully:
closeSessionWithStatus:successfully:complete:
closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:
code
combinationWeight
combineScoreFromPSR:fromSAT:withCombinedWt:
combinedScore
combinedScores
compare:
compare:options:
compareModelFilePaths
compareVoiceProfileArray
components:fromDate:
components:fromDateComponents:toDateComponents:options:
componentsSeparatedByString:
composeModelContextsForProfiles:forSpIdType:forAsset:completion:
computeRequiredTrailingSamples
computeTriggerConfidenceForAudio:withCompletion:
confidence
configFilePath
configVersion
conformsToProtocol:
containsCategory:
containsMultiUserThresholds
containsSpeakerRecognitionCategory
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextForVoiceTriggerTraining
convertStopReason:
copy
copyAudioFiles:toProfile:forModelType:
copyItemAtPath:toPath:error:
copyItemAtURL:toURL:error:
copySamplesFrom:to:
count
countByEnumeratingWithState:objects:count:
createAVAudioPCMBufferWithNSData:
createAudioFileWriterForPHSTrainingWithInputFormat:outputFormat:
createDESRecordWithSuperVector:withMetaInfo:
createDigitalZeroReporterWithVoiceTriggerEventInfo:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryIfDoesNotExist:
createFileAtPath:contents:attributes:
createGrammars
createKeywordDetector
createSpeechRecognizer
createVoiceScorersWithVoiceProfiles:withConfigFile:withResourceFile:withOffsetsType:
csAudioProcessingQueuePriority
currentDeviceCategory
currentDirectoryPath
currentHandler
currentLanguageCode
data
dataWithBytes:length:
dataWithCapacity:
dataWithContentsOfFile:
dataWithContentsOfURL:
dataWithJSONObject:options:error:
date
dateAdded
dateWithTimeIntervalSince1970:
dateWithTimeIntervalSinceNow:
deactivateAudioSession:error:
deactivateAudioSessionWithOptions:
debugDescription
debugUtteranceAudioFile
debugUtteranceAudioFilePath
debugUtteranceJsonFilePath
debugUtteranceMetaFile
decision
decodeConfigFrom:
decodeConfigFrom:forFirstPassSource:
decodeObjectOfClass:forKey:
defSepFeats
defaultCenter
defaultManager
defaultServerEndpointFeatures
delegate
deleteAESKeyWithApplicationTag:keyLabel:
deleteAllVoiceProfilesForAppDomain:
deleteInvalidSiriProfilesFromPersonalDevicesForLanguage:appDomain:
deleteModelForSpidType:recognizerType:
deleteUserVoiceProfile:
deleteVectorAtIndex:
description
destroySpeakerTrainer
detectorNDAPI
detectorQuasar
device:matchEventOccurred:
deviceBuildVersion
deviceCategoryForDeviceProductType:
deviceCategoryStringRepresentationForCategoryType:
deviceId
deviceProductType
deviceProductVersion
deviceWithDescriptor:error:
devicesWithVoiceProfileIniCloudForLanguage:
dictionary
dictionaryRepresentation
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didDetectBeginOfSpeech
didDetectEndOfSpeech:
didDetectForceEndPoint
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
didPlayEndpointBeep
digitalZeroDetected
discardSiriEnrollmentForLanguageCode:
discardSiriEnrollmentForProfileId:forLanguageCode:
domain
doubleValue
dumpFilesInDirectory:
earSpg
enableVoiceTriggerUponVoiceProfileSyncForLanguage:
encodeObject:forKey:
encodeWithCoder:
encryptFileAt:andSaveTo:error:
endAudio
endInSampleCount
endOfSentenceLikelihood
endpointReported
endpointUUID
endpointer:didDetectHardEndpointAtTime:
endpointer:didDetectStartpointAtTime:
enter
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
enumeratorAtPath:
errorWithDomain:code:userInfo:
evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:
expModelsContext
explicitFailedUtteranceIndex
explicitSpIdTypeForSpId:
explicitUtteranceIndex
extraSamplesAtStart
feedSpeechRecognitionTrailingSamplesWithCompletedBlock:
feedSpeechRecognitionWithPCMBuffer
fetchMedicalIDDataWithCompletion:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileSize
fileURLWithPath:
fileURLWithPathComponents:
filterDuplicatedSiriProfilesFrom:
filterInvalidSiriProfilesFrom:
filterToVoiceTriggerUtterances
filterVTAudioFiles:withLocale:withAsset:
filteredArrayUsingPredicate:
finish
finishSpeechRecognitionTask
firstMatchInString:options:range:
firstObject
floatValue
forceRetrain
frameLength
generateAESKeyWithKeySizeInBits:
generateIfNecessaryAESKeyWithKeySizeInBits:applicationTag:keyLabel:shouldGenerateIfNecessary:
generateIfNecessaryVoiceTriggerProfilesAESKey
getAESKeyFromKeychainWithApplicationTag:keyLabel:
getAnalyzedResultFromAudioChunk:
getAnalyzedResultFromFlushedAudio
getAnalyzedResultsFromAudioChunk:
getAssetProviderType
getAveragePowerDB
getCSAssetOfType:
getCacheDirectoryForAppDomain:
getCachedVoiceProfileAvailabilityMetaBlob
getContentsOfDirectory:
getCurrentStreamState:
getDevicesWithAvailablePHSAssetsForLanguage:completion:
getDevicesWithAvailablePHSAssetsOnDeviceCheck:
getEnrollmentUtterancesCountFromDirectory:withCountBlock:
getEnrollmentUtterancesForModelType:
getEnrollmentUtterancesFromDirectory:
getExplicitEnrollmentUtterancesForType:
getExplicitEnrollmentUtterancesFromDirectory:
getExplicitMarkedEnrollmentUtterancesForType:
getExplicitMarkedEnrollmentUtterancesFromDirectory:
getFixedHighPrioritySerialQueueWithLabel:priority:
getHomeUserIdForSharedUserId:completion:
getHomeUserIdForVoiceProfile:withCompletion:
getImplicitEnrollmentUtterancesForType:
getImplicitEnrollmentUtterancesFromDirectory:
getImplicitEnrollmentUtterancesPriorTo:forType:
getImplicitUtteranceCacheDirectory
getKeychainAttributesForAESKeyWithApplicationTag:keyLabel:
getLMEforLocale:
getLastBiometricMatchForVoiceTriggerTimeStamp:
getLatestSpeakerInfo
getLatestVoiceRecognitionInfo
getLeadingPatternsForUtt:Locale:
getLocalUrl
getNumberForKey:category:default:
getNumberOfAudioFilesInDirectory:
getRecordDeviceInfoForStream:
getRegexPatternsForUtt:Locale:
getResourceValue:forKey:error:
getSATEnrollmentPath
getSATVectorCount
getSiriLanguageWithEndpointId:fallbackLanguage:
getSiriLanguageWithFallback:
getSpeakerVectorAtIndex:
getStringForKey:category:default:
getSuperVectorWithEndPoint:
getTrailingPatternsForUtt:Locale:
getTrainingAudioStatusWithVTEI:digitalZeroReporter:
getUserVoiceProfileUpdateDirectory
getUserVoiceProfileUploadPathWithEnrolledLanguageList:
getUtteranceEnrollmentType:
getValueForKey:category:
getVoiceProfileAnalyticsForAppDomain:withLocale:
getVoiceProfileForSiriProfileId:forLanguageCode:
getVoiceProfileIdentityFromVersionFilePath:
getVoiceProfileProductCategoryFromVersionFilePath:
getVoiceProfileStoreVersion
getVoiceProfilesForSiriProfileId:
getVoiceRecognizerResults
getVoiceTriggerAssetTypeString
getVoiceTriggerCurrentCompatibilityVersion
getVoiceTriggerProfilesAESKey
getZeroStatisticsFromBuffer:entireSamples:
gregorianBirthday
handleAudioBufferForVTWithAudioInput:withDetectedBlock:
handleAudioInput:
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handleMasterTimeout:
hasAudioRoute
hasCorrectAudioRoute
hasPendingTwoShotBeep
hasPrefix:
hasRemoteBuiltInMic
hasRemoteCoreSpeech
hasSuffix:
hasVoiceProfileIniCloudForLanguageCode:
hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:
hash
hashFromResourcePath
homeId
hybridClassifier
implicitTrainingRequired
implicitUtteranceIndex
importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:
importVoiceProfileAtPath:
init
initNewVoiceProfileWithLocale:withAppDomain:
initStore
initWithAsset:
initWithBundleIdentifier:
initWithBytes:length:
initWithCapacity:
initWithCoder:
initWithCommonFormat:sampleRate:channels:interleaved:
initWithConfigFile:samplingRate:queue:
initWithConfigFilePath:withModelFilePaths:
initWithConfigPath:resourcePath:
initWithConfigPath:resourcePath:phId:
initWithConfiguration:
initWithConfiguration:modelVersion:
initWithContext:delegate:
initWithContext:withDelegate:error:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
initWithDescription:
initWithDeviceId:audioStreamHandleId:
initWithDictionary:
initWithEndpointId:
initWithError:
initWithEvent:locale:configVersion:
initWithHealthStore:
initWithLocale:asset:
initWithLocale:configPath:resourcePath:
initWithLocaleIdentifier:withAudioSession:withAppDomain:
initWithMode:deviceUID:
initWithNumChannels:recordingDuration:samplingRate:
initWithPCMFormat:frameCapacity:
initWithProfileID:withModelFile:withConfigFile:withResourceFile:withOffsetsType:
initWithQueue:error:
initWithRemoteDeviceUUID:
initWithRemoteTrainingDeviceType:remoteTrainingDeviceUUIDList:
initWithSampleRate:
initWithSessionId:sessionStatus:audioStatus:
initWithSharedSiriId:languageCode:productCategory:version:
initWithSiriSetupID:PageNumber:withPhId:
initWithStreamID:atStartHostTime:
initWithStreamID:settings:bufferDuration:
initWithToken:sampleRate:numChannels:
initWithType:
initWithURL:inputFormat:outputFormat:
initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:mhUUID:zeroCounter:completionWithResult:
initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:zeroCounter:completion:
initWithVoiceProfile:
initWithVoiceRecognitionContext:delegate:queue:
initWithVoiceRecognitionContext:error:
initWithVoiceRetrainingContext:error:
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
inputRecordingBufferDuration
inputRecordingBytesPerFrame
inputRecordingDurationInSecs
inputRecordingIsFloat
inputRecordingNumberOfChannels
inputRecordingSampleBitDepth
inputRecordingSampleByteDepth
inputRecordingSampleRate
insertObject:atIndex:
installedAssetOfType:forLanguage:
installedAssetOfType:forLanguageCode:
intValue
integerValue
invalidate
invocationStyleStr
isAbsolutePath
isAvailable
isCSAssetInstalled
isConnected
isCurrentDeviceCompatibleWithNewerVoiceProfileAt:
isCurrentDeviceCompatibleWithVoiceProfileAt:
isDarwinOS
isDownloading
isEqual:
isEqualToString:
isIOSDeviceSupportingBargeIn
isImplicitTrainingRequiredForVoiceProfileId:locale:completion:
isImplicitTrainingRequiredToVoiceProfile:withAsset:completion:
isKindOfClass:
isLatestCompareTo:
isMarkedSATEnrolled
isMarkedSATMigrated
isMemberOfClass:
isPermitted
isPremium
isRecordContextAutoPrompt:
isRecordContextBuiltInVoiceTrigger:
isRecordContextDarwinVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisButtonPress:
isRecordContextJarvisVoiceTrigger:
isRecordContextRaiseToSpeak:
isRecordContextRemoraVoiceTrigger:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextVoiceTrigger:
isRecording
isRecordingWithStreamHandleId:
isRemoteDarwinWithDeviceId:
isRequestDuringActiveCall
isSATEnrolledForSiriProfileId:forLanguageCode:
isSATEnrollmentMigratedForSiriProfileId:forLanguageCode:
isSpeakerRecognitionAvailable
isSpeakerRecognitionSupportedInLocale:
isUtteranceImplicitlyTrained:
isValidRecordContext:
isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:
keywordDetectorNDAPIConfigFilePath
keywordDetectorQuasarConfigFilePath
languageCode
languageCodeDarwin
lastMatchEventWithError:
lastObject
lastPathComponent
lastScoreCard
leave
length
loadKnownUserVoiceProfiles
locale
localeWithLocaleIdentifier:
localizedDescription
logAggregator
logSiriSetupPHSEnrollmentDigitalZeroDetectionCompletedWithSiriSetupID:withPageNumber:withPhId:withMaxNumContinuousZeros:withMaxNumAllowedContinuousZeros:withIsMaxNumContinuousZerosOverThreshold:
logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:
logTrainingSessionCompleteWithVoiceTriggerEventInfo:
logVoiceProfileConfusionWithCleanup:
lpcmInt16ASBD
markSATEnrollmentMigrated
markSATEnrollmentSuccess
markSATEnrollmentSuccessForVoiceProfile:
matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:
matchWithString:TrailingStr:LeadingStr:Pattern:
maxAllowedAudioSamples
maxAllowedEnrollmentUtterances
maxAllowedSpeakerVectors
migrateVoiceProfilesIfNeededWithCompletionBlock:
minusSet:
modelDirectoryPathForProfile:
modelFilePath
modelsContext
moveContentsOfSrcDirectory:toDestDirectory:
moveItemAtPath:toPath:error:
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
multiUserHighScoreThreshold
multiUserLowScoreThreshold
mutableAudioBufferList
mutableBytes
mutableCopy
myriadResult
name
ndapiResult
needsRetrainingWithAudioFiles:
newVoiceProfileWithLocale:withAppDomain:
notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:
notifyUserVoiceProfileDownloadReadyForUser:getData:completion:
notifyUserVoiceProfileUpdateReady
notifyUserVoiceProfileUploadComplete
numEnrollmentUtterances
numSamples
numSamplesInPCMBuffer
numSamplesProcessed
numberOfMatchesInString:options:range:
numberOfRanges
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithUnsignedInt:
numberWithUnsignedInteger:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observers
orchestrator
orchestratorScoresWithPSRScores:withSATScores:withSegmentStartTime:
osTransactionReqd
path
pathExtension
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phId
phraseConfig
phraseConfigs
phraseDetectorInfoFromPhId:
pickAssetForProfiles:forSpIdType:
pickAssetForProfiles:forSpIdType:withAssetArray:
pitch
playbackRoute
postNotificationName:object:
powerMeter
preTriggerAudioTime
predicateWithBlock:
predicateWithFormat:
prepareAudioStreamRecordWithStreamHandleId:error:
prepareRecord
prepareRecordForStream:error:
prepareWithCompletion:
processAudio:numSamples:
processAudio:withNumberOfSamples:
processAudioData:
processAudioData:numSamples:
processAudioSamplesAsynchronously:
processFloatBuffer:stride:inFrameToProcess:
processShortBuffer:stride:inFrameToProcess:
processedAudioMs
profileID
profileId
profileLocallyAvailable
profilePitch
provisionedVoiceProfilesForAppDomain:withLocale:
provisionedVoiceProfilesForLocale:
pruneImplicitUtterancesOfProfile:withAsset:
pruneVoiceProfile:forSpIdType:withAsset:
pruningCookie
pruningExplicitUttThresholdPSR
pruningExplicitUttThresholdSAT
pruningNumRetentionUtterance
pruningThresholdPSR
pruningThresholdSAT
psrAnalyzer
psrCombinationWeight
psrConfigFilePath
psrConfigRoot
psrFinalSpeakerInfo
psrLastSpeakerInfo
psrRecognizer
purgeConfusionInformationWithPolicy:
purgeLastSpeakerEmbedding
pushAnalytics
pushAnalyticsWithLazyBlock:
pushAudioInputIntoPCMBuffer:
queryMetaDataSync
queryParams
queue
rangeAtIndex:
rangeOfString:options:
readJsonFileAtPath:
recognitionStyle
recognitionTaskWithRequest:delegate:
recognizerScoreOffset
recognizerScoreScaleFactor
recordContextString:
recordRoute
recordRouteWithStreamHandleId:
recordedTimeStampFromFileName:
recordedTimeStampOfFile:
recordingStoppedForReason:
registerObserver:
regularExpressionWithPattern:options:error:
releaseAudioSession
reloadForLocale:
remoteControlClient
remoteDeviceContext
remoteTrainingDeviceType
remoteTrainingDeviceUUIDList
removeAllObjects
removeItemAtPath:
removeItemAtPath:error:
removeItemAtURL:error:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectsInRange:
replaceBytesInRange:withBytes:
replaceMatchesInString:options:range:withTemplate:
replaceObjectAtIndex:withObject:
reportDigitalZerosWithAudioZeroRun:
requestSupportedWithSamplingRate:
requestTriggeredUtterance:
reset
resetForNewRequest
resetForNewRequestWithSampleRate:
resetModelForRetraining
resetScorerWithModelFilePath:
resetWithContext:
resetWithSampleRate:
resetWithSamplingRate:language:taskType:userId:sessionId:deviceId:farField:audioSource:maxAudioBufferSizeSeconds:
resourceFilePath
resourcePath
respondsToSelector:
result
resultAlreadyReported
resultsWithAddedAudio:numberOfSamples:taskName:
resultsWithEndedAudio
resumeTraining
retain
retainCount
retrainVoiceProfile:withContext:withCompletion:
retrainerType
retrainingWaitTime
returnTypes:
reverseObjectEnumerator
route
sampleCount
samplesAtFire
samplesFed
satConfigFileNameForCSSpIdType:forModelType:forAssetType:
satFinalSpeakerInfo
satImplicitProfileDeltaThreshold
satImplicitProfileThreshold
satImplicitTrainingEnabled
satLastSpeakerInfo
satModelAvailable
satRecognizer
satScoreThreshold
satScoreThresholdForPhId:
satVTImplicitThreshold
saveKnownUserVoiceProfiles:
saveMetadata:isExplicitEnrollment:
saveRawUtteranceAndMetadata:to:isExplicitEnrollment:
saveRecordWithData:recordInfo:completion:
saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:
saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:
saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:
scanFloat:
scannerWithString:
scheduledTimerWithTimeInterval:target:selector:userInfo:repeats:
scoreSpeakerVector:withDimensions:withThresholdType:
scoreType
segmentStartPointSampleCount
segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:
self
sessionId
sessionStatus
setActivationMode:
setActiveChannel:
setAnnounceCallsEnabled:
setAppDomain:
setAsset:
setAssetProviders:
setAudioFileWriter:
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setAudioStreamHandleId:
setBiometricDevice:
setCombinedScores:
setCompareVoiceProfileArray:
setConfig:
setContext:
setContext:error:
setContextualStrings:
setCurrentDeviceCategory:
setCurrentLanguageCode:
setDateAdded:
setDateFormat:
setDebugUtteranceJsonFilePath:
setDelegate:
setDetectorNDAPI:
setDetectorQuasar:
setEarSpg:
setEndInSampleCount:
setEndpointReported:
setEndpointUUID:
setEndpointerDelegate:
setExtraSamplesAtStart:
setHomeId:
setHybridClassifier:
setInvocationStyleStr:
setLanguageCode:
setLastScoreCard:
setLastSpeakerInfo:
setLocale:
setLocaleIdentifier:
setLogAggregator:
setMeteringEnabled:
setMyriadResult:
setNumSamplesProcessed:
setObject:forKey:
setObject:forKeyedSubscript:
setObservers:
setOrchestrator:
setPitch:
setPowerMeter:
setProcessingEnded:
setProductCategory:
setProfileBasePath:
setProfileId:
setProfilePitch:
setPsrFinalSpeakerInfo:
setPsrLastSpeakerInfo:
setPsrRecognizer:
setQueue:
setRecognizerScoreScaleFactor:
setRecordDelegate:
setRemoteControlClient:
setRemoteDeviceContext:
setRetrainingWaitTime:
setSatFinalSpeakerInfo:
setSatLastSpeakerInfo:
setSatRecognizer:
setSegmentStartPointSampleCount:
setSessionId:
setSharedSiriId:
setSharedSiriProfileId:
setSkipAlert:
setSpIdCtx:
setSpIdType:
setSpeakerRecognitionPSRProcessingStatus:
setSpeakerRecognitionProcessingStatus:
setSpeakerRecognitionSATProcessingStatus:
setSpeakerRecognitionWaitTime:
setSpgQueue:
setSsrUttLogger:
setStartAlert:
setStartWaitTime:
setStartpointReported:
setStopAlert:
setStopOnErrorAlert:
setStorePrefs:
setSuspendAudio:
setSynchronousCallbackEnabled:
setTaskHint:
setTotalNumSamplesReceived:
setTransDesc:
setUserName:
setValue:forKey:
setVersion:
setVoiceControllerCreationQueue:
setVoiceProfile:
setVoiceProfileArray:
setVoiceProfileDiscardedUtteranceCount:
setVoiceProfilePrunedUtteranceCount:
setVoiceProfilePruningFailureReasonCode:
setVoiceProfileRetainedUtteranceCount:
setVoiceProfileRetrainingFailureReasonCode:
setVoiceProfileStoreVersion:
setVoiceProfileUpdateScoreMSE:
setVoiceTriggerEventInfo:
setVtEndInSampleCount:
setWithArray:
setupPhraseSpotter
setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:
setvoiceProfilePrunedUtteranceCount:
sharedGrammars
sharedInstance
sharedInstanceWithEndpointId:
sharedLogger
sharedManager
sharedPreferences
sharedSiriId
sharedStorePrefs
sharedTrainer
sharedtrainingSessionQueue
shouldHandleSession
shouldMakeRecordWithFrequency:
shouldMatchPayload
shouldPerformRMS
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
silenceDurationMs
silenceFramesCountMs
silencePosterior
silenceProbability
siriProfileId
skipAlert
sortedArrayUsingComparator:
spIdType
spIdTypeForString:
spIdVoiceProfileImportRootDir
speakerIdScoreReportingType
speakerRecognitionAudioLoggingEnabled
speakerRecognitionController:hasSpeakerInfo:
speakerRecognitionFinishedProcessing:withFinalSpeakerInfo:
speakerRecognitionPSRProcessingStatus
speakerRecognitionProcessingStatus
speakerRecognitionSATProcessingStatus
speakerRecognitionWaitTime
speakerRecognizer:hasSpeakerIdInfo:
speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:
speechRecognitionDidDetectSpeech:
speechRecognitionTask:didFinishRecognition:
speechRecognitionTask:didFinishSuccessfully:
speechRecognitionTask:didHypothesizeTranscription:
speechRecognitionTaskFinishedReadingAudio:
speechRecognitionTaskWasCancelled:
speechRecognizerAvailable
spgQueue
spidAudioTrainUtterancesDir
ssrAudioLogsCountWithinPrivacyLimit
ssrUttLogger
startAlert
startAudioStreamWithStreamHandleId:error:
startHostTime
startMasterTimerWithTimeout:
startRMS
startRecordForStream:error:
startRecording
startRecordingWithOptions:error:
startTraining
startpointReported
state
stopAlert
stopAudioStreamWithStreamHandleId:error:
stopCountingZeroStatisticsWithReporter:
stopEndpointer
stopOnErrorAlert
stopRecordForStream:error:
stopRecording
stopRecording:
storeAESKeyInKeychain:applicationTag:keyLabel:
storePrefs
streamAudioFromFileUrl:audioStreamBasicDescriptor:samplesPerStreamChunk:audioDataAvailableHandler:
streamDescription
streamID
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringByTrimmingCharactersInSet:
stringForCSSpIdType:
stringForInvocationStyle:
stringForVoiceProfileRetrainerType:
stringValue
stringWithFormat:
stringWithUTF8String:
subdataWithRange:
submitVoiceIdIssueReport:
subpathsOfDirectoryAtPath:error:
substringFromIndex:
substringWithRange:
superclass
supportHandsFree
supportPremiumModel
supportRingtoneA2DP
supportsSecureCoding
supportsSpeakerRecognitionAssets
suspendAudio
sysConfigRoot
teardownWithError:
threshold
timeIntervalSince1970
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeStamp
timeStampWithSaltGrain
tokens
totalNumSamplesReceived
trailingAudioTime
trailingSilenceDuration
trailingSilenceDurationAtEndpoint
trainUtterance:shouldUseASR:completion:
trainUtterance:shouldUseASR:mhUUID:completionWithResult:
trainingManagerWithLocaleID:withAppDomain:
transDesc
transaction
triggerInvalidSiriProfileCleanupFromPersonalDevicesForLanguage:appDomain:
triggerRetrainingVoiceProfile:withContext:withCompletion:
triggerVoiceProfileCleanupWithCompletion:
triggerVoiceProfileDownload
triggerVoiceProfileDuplicatesCleanup
triggerVoiceProfileMigrationWithCompletion:
triggeredUtterance:
trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:
type
unregisterObserver:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
updateAudioRecorderForTrainingDevice:deviceUUIDs:
updateMeterAndForward
updateMeters
updatePruningCookie:
updateSAT
updateTrainingManagerForDevice:trainingDeviceUUIDList:
updateVoiceProfile:withUserName:
uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:
useRecognizerCombination
useSpeakerRecognitionAsset
userName
userVoiceProfileForVoiceProfileID:
userVoiceProfilesForAppDomain:
userVoiceProfilesForAppDomain:forLocale:
userVoiceProfilesForLocale:
utteranceFileASBD
valueForKey:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerCreationQueue
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerDidDetectStartpoint:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerEndRecordInterruption:
voiceControllerLPCMAudioCallback:forStream:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerStreamInvalidated:forStream:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceProfile
voiceProfileArray
voiceProfileAudioDirPathForSpidType:
voiceProfileBasePath
voiceProfileDiscardedUtteranceCount
voiceProfileForId:
voiceProfileIdentity
voiceProfileImplicitCacheDirPath
voiceProfileModelDirForSpidType:recognizerType:
voiceProfileModelFilePath
voiceProfileModelFilePathForRecognizerType:spIdType:
voiceProfilePrunedUtteranceCount
voiceProfilePruningCookie
voiceProfilePruningFailureReasonCode
voiceProfileRetainedUtteranceCount
voiceProfileRetrainingFailureReasonCode
voiceProfileUpdateScoreMSE
voiceProfileVersion
voiceProfilesModelFilePaths
voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:
voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:
voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:
voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:
voiceRetrainersWithContext:
voiceTriggerEnabled
voiceTriggerEventInfo
vtEndInSampleCount
vtEventInfo
waitWithTimeout:
waitingForConnection:error:
weakObjectsHashTable
whitespaceAndNewlineCharacterSet
wordCount
writeMetaDict:atMetaPath:
writeToFile:atomically:
writeToFile:options:error:
year
zeroFilterWindowSizeInMsForReport
zone
@16@0:8
v24@0:8@16
v24@0:8q16
v16@0:8
v24@0:8Q16
d16@0:8
v24@0:8d16
Q16@0:8
@"<CSVTUIEndpointAnalyzerDelegate>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
@32@0:8@16@24
v32@0:8@16Q24
q16@0:8
v20@0:8B16
@"SSRSpeakerRecognitionContext"
@"<SSRVoiceActivityDetectorDelegate>"
@"EARCaesuraSilencePosteriorGenerator"
@"_EAREndpointer"
@"_EARDefaultServerEndpointFeatures"
@"NSObject<OS_dispatch_queue>"
@24@0:8@16
Q24@0:8I16I20
@"CSKeywordAnalyzerNDAPI"
@"CSPhraseDetector"
@"CSAudioCircularBuffer"
@"CSKeywordAnalyzerNDAPIResult"
@40@0:8@16@24@32
v32@0:8@16@24
v32@0:8@"SSRSpeakerAnalyzerPSR"16@"NSDictionary"24
@32@0:8@"SSRSpeakerRecognitionContext"16@"<SSRSpeakerRecognizerDelegate>"24
v32@0:8@"NSData"16Q24
v24@0:8@"SSRSpeakerRecognitionContext"16
@"NSDictionary"16@0:8
@"NSString"
@"NSDictionary"
@"<SSRSpeakerRecognizerDelegate>"
@"SSRSpeakerAnalyzerPSR"
@40@0:8@16@24Q32
@32@0:8@16Q24
@24@0:8Q16
v32@0:8@"<SSRSpeakerRecognizer>"16@"NSDictionary"24
v32@0:8@"SSRVoiceActivityDetector"16Q24
@40@0:8@16@24^@32
v28@0:8@16B24
@40@0:8@16@24d32
@"<SSRSpeakerRecognitionOrchestratorDelegate>"
@"<CSAudioFileWriter>"
@"<SSRSpeakerRecognizer>"
@"SSRVoiceActivityDetector"
@"NSObject<OS_os_transaction>"
v40@0:8@16@?24@?32
@24@0:8@?16
@24@0:8@"SSRVoiceProfileRetrainingContext"16
v40@0:8@"NSArray"16@?<@"NSError"@?@"NSURL"@"NSDictionary">24@?<v@?@"NSError"@"NSDictionary"@"NSDictionary">32
B24@0:8@"NSArray"16
@"NSError"24@0:8@?<B@?@"NSDictionary">16
@"NSURL"16@0:8
@"NSURL"
v24@0:8@?16
@48@0:8@16@24@32Q40
@56@0:8@16@24@32@40Q48
f40@0:8@16Q24Q32
v20@0:8i16
v20@0:8f16
B44@0:8@16@24@32B40
B44@0:8@"CSVTUITrainingSession"16@"NSData"24@"NSString"32B40
v28@0:8B16@20
v28@0:8B16@"NSError"20
v24@0:8@"NSData"16
v24@0:8@"NSError"16
v32@0:8@16d24
v32@0:8@"CSVTUIEndpointAnalyzer"16d24
@32@0:8Q16@24
q36@0:8q16B24@?28
q44@0:8q16B24@28@?36
B24@0:8q16
v32@0:8i16B20@?24
f16@0:8
@"<CSVTUIAudioSession>"
@"CSVTUIEndpointAnalyzer"
@"CSVTUIKeywordDetector"
@"NSMutableArray"
@"CSVTUITrainingSession"
@"SFSpeechRecognizer"
@"CSAsset"
@"SSRVoiceProfile"
@"CSDispatchGroup"
@"NSUUID"
@"CSAudioZeroCounter"
@"<SSRVTUITrainingManagerDelegate>"
@"CSPlainAudioFileWriter"
v68@0:8@16Q24@32@40Q48Q56i64
v44@0:8@16Q24B32@36
v40@0:8@16Q24q32
v32@0:8@16q24
v68@0:8@"CSVTUIAudioRecorder"16Q24@"NSData"32@"NSData"40Q48Q56i64
v44@0:8@"CSVTUIAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSVTUIAudioRecorder"16Q24q32
v32@0:8@"CSVTUIAudioRecorder"16q24
v24@0:8@"CSVTUIAudioRecorder"16
v32@0:8Q16@24
v24@0:8@"<CSVTUIAudioSessionDelegate>"16
v32@0:8Q16@"NSArray"24
v24@0:8@"<Endpointer>"16
q24@0:8q16
@"CSVTUIAudioRecorder"
@"<CSVTUIAudioSessionDelegate>"
@"CSAudioPowerMeter"
@48@0:8@16@24@32@40
@"NSNumber"
@"NSDate"
v32@0:8@16@?24
@"SSRTriggerPhraseDetectorNDAPI"
@"SSRTriggerPhraseDetectorQuasar"
B32@0:8d16^@24
v64@0:8@16@24@32@40@48@?56
@"CSAsset"32@0:8Q16@"NSString"24
@"NSArray"32@0:8Q16@"NSString"24
B32@0:8@16@24
B40@0:8@16@24@32
@"NSMutableDictionary"
@32@0:8@16q24
@40@0:8@16Q24q32
B32@0:8@16^@24
B24@0:8^@16
@"<CSVTUIRemoteRecordClientDelegate>"
@36@0:8@16i24@28
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8Q16Q24
Q32@0:8@16Q24
B32@0:8Q16Q24
@"_EARSyncSpeechRecognizer"
Q24@0:8Q16
Q24@0:8@16
@40@0:8Q16Q24Q32
v80@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24Q64@?72
q24@0:8@16
v44@0:8@16@24B32@?36
B40@0:8@16@24^@32
@36@0:8@16@24f32
v32@0:8@"SSRSpeakerRecognitionController"16@"NSDictionary"24
v40@0:8@16Q24@32
v56@0:8@16@24@32@40@?48
@32@0:8@16^@24
@"NSArray"
@"SSRLoggingAggregator"
v64@0:8@16@24B32@36@44Q52B60
q48@0:8@16@24@32@40
v24@0:8@"SFSpeechRecognitionTask"16
v32@0:8@"SFSpeechRecognitionTask"16@"SFTranscription"24
v32@0:8@"SFSpeechRecognitionTask"16@"SFSpeechRecognitionResult"24
v28@0:8@"SFSpeechRecognitionTask"16B24
v24@0:8i16B20
@104@0:8q16q24@32@40@48@56@64@72@80@88@?96
@112@0:8q16q24@32@40@48@56@64@72@80@88@96@?104
v40@0:8i16B20@24@?32
i32@0:8@16@24
@"SFSpeechAudioBufferRecognitionRequest"
@"SFSpeechRecognitionTask"
@"NSTimer"
@"<CSVTUITrainingSessionDelegate>"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
v80@0:8@16@24@32@40@48@56@64@?72
@32@0:8@16@?24
v48@0:8@16Q24@?32@?40
@40@0:8@16Q24Q32
@24@0:8^@16
@"SSRRemoteControlClient"
v36@0:8@16B24@28
v28@0:8@16i24
v36@0:8@16i24d28
v36@0:8@16i24@28
v40@0:8@16@24@32
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
Q32@0:8@16^@24
B32@0:8Q16^@24
B24@0:8Q16
B40@0:8Q16Q24^@32
v60@0:8@16Q24@32Q40Q48i56
v40@0:8@16Q24Q32
@28@0:8@16I24
v36@0:8B16Q20@28
v32@0:8q16Q24
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"CSVTUIRemoteRecordClient"
@"NSHashTable"
@"CSVTUIAudioRecorderRemoteDeviceContext"
f24@0:8@16
@40@0:8Q16@24@32
@"<SSRAssetManagerDelegate>"
v32@0:8@"SSRSpeakerRecognitionOrchestrator"16@"NSDictionary"24
@"<SSRSpeakerRecognitionControllerDelegate>"
@"SSRSpeakerRecognitionOrchestrator"
B40@0:8@16@24f32f36
B40@0:8@16@24Q32
v36@0:8@16B24@?28
@"SSRVoiceProfileStorePrefs"
v32@0:8@"BKDevice"16@"BKMatchEvent"24
B32@0:8^B16^Q24
@"BKDevice"
v36@0:8@16@24B32
B36@0:8@16@24B32
B44@0:8@16@24Q32B40
B28@0:8@16B24
v48@0:8@16Q24@32@?40
B40@0:8@16Q24@32
@40@0:8@16Q24@32
v32@0:8@"NSURLSession"16@"NSError"24
v40@0:8@"NSURLSession"16@"NSURLAuthenticationChallenge"24@?<v@?q@"NSURLCredential">32
v24@0:8@"NSURLSession"16
@32@0:8q16@24
@40@0:8@16q24@32
f20@0:8f16
@44@0:8Q16@24@32B40
f24@0:8Q16
@32@0:8q16i24i28
i16@0:8
333333
333333
