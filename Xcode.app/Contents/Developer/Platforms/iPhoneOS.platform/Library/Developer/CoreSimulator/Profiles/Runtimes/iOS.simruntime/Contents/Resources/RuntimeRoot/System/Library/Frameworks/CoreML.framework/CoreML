N8nlohmann6detail9exceptionE
N8nlohmann6detail10type_errorE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail12out_of_rangeE
false
NSt3__117bad_function_callE
N8nlohmann6detail11parse_errorE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail21output_stream_adapterIcEENS_9allocatorIS4_EEEE
N8nlohmann6detail21output_stream_adapterIcEE
N8nlohmann6detail23output_adapter_protocolIcEE
000102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798990001020304050607080910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989900010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
U1(\Q
mSx@
b}$l
~)p$w
11eU%
z^KD
NSt3__120__shared_ptr_emplaceIN3MPL6detail24ModelPackageItemInfoImplENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN3MPL20ModelPackageItemInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3MPL6detail16ModelPackageImplENS_9allocatorIS3_EEEE
rKa@
yTW 
P@&x
X_<p
G!c?m
]6MNw<@mY
f}/@
il]@
@ko#!(
@(#)PROGRAM:CoreML  PROJECT:CoreML-1404
@6Kernel
7QMatrix
6Solver
9Solver_NU
5SVC_Q
11ONE_CLASS_Q
5SVR_Q
NSt3__120__shared_ptr_emplaceIN6CoreML16MultiArrayBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPhZ105-[MLMultiArray initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:]E3$_0NS_9allocatorIhEEEE
Z105-[MLMultiArray initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:]E3$_0
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1INS_11__wrap_iterIPNS_10shared_ptrIKS3_EEEEEET_SB_mNS2_10ScalarTypeENS2_12StorageOrderEEUlS1_E_NS_9allocatorIhEEEE
ZN6CoreML16MultiArrayBufferC1INSt3__111__wrap_iterIPNS2_10shared_ptrIKS0_EEEEEET_S9_mNS_10ScalarTypeENS_12StorageOrderEEUlPhE_
N6CoreML10NNCompiler7Backend13NeuralNetwork18EspressoNetBackendE
NSt3__120__shared_ptr_pointerIPKN6CoreML10NNCompiler11MLModelInfoENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIKN6CoreML10NNCompiler11MLModelInfoEEE
NSt3__120__shared_ptr_pointerIPKN3MIL9IRProgramENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL9IRProgramEEE
N6CoreML10NNCompiler7Backend3MIL5Ios1612Ios16BackendE
N8Archiver20_IDataBlobMemoryImplE
NSt3__120__shared_ptr_pointerIPN3MIL7IRBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL7IRBlockEEE
NSt3__120__shared_ptr_pointerIPN3MIL11IROperationENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL11IROperationEEE
N8Archiver17_OArchiveDiskImplE
N8Archiver19_OArchiveMemoryImplE
NSt3__120__shared_ptr_pointerIPN8Archiver14_ODataBlobImplENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN8Archiver14_ODataBlobImplEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_emplaceIN8Archiver14_ODataBlobImplENS_9allocatorIS2_EEEE
N8Archiver14_IDataBlobImplE
NSt3__120__shared_ptr_pointerIPNS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_10shared_ptrINS_13basic_istreamIcS3_EEE27__shared_ptr_default_deleteIS8_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrINS_13basic_istreamIcNS_11char_traitsIcEEEEE27__shared_ptr_default_deleteIS4_NS_14basic_ifstreamIcS3_EEEE
NSt3__120__shared_ptr_pointerIPN8Archiver11MMappedFileENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN8Archiver11MMappedFileEE27__shared_ptr_default_deleteIS2_S2_EE
N6CoreML13TreeEnsembles8Internal30incompatible_execution_profileE
N6CoreML10NNCompiler7Backend3MIL5Ios1512Ios15BackendE
NSt3__110__function6__funcIZN6CoreML13TreeEnsembles8Internal16gatherPropertiesERKNS_10shared_ptrINS3_13_TreeEnsembleEEEE3$_2NS_9allocatorISA_EEFvRKNS5_INS3_20_TreeComputationNodeEEEEEE
NSt3__110__function6__baseIFvRKNS_10shared_ptrIN6CoreML13TreeEnsembles20_TreeComputationNodeEEEEEE
ZN6CoreML13TreeEnsembles8Internal16gatherPropertiesERKNSt3__110shared_ptrINS0_13_TreeEnsembleEEEE3$_2
NSt3__120__shared_ptr_emplaceIN8Archiver19_OArchiveMemoryImplENS_9allocatorIS2_EEEE
N6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorE
NSt3__114default_deleteIN3MIL16IRNamedValueTypeEEE
N8Archiver18_IDataBlobENMLImplE
NSt3__120__shared_ptr_emplaceIN8Archiver7mmapbufENS_9allocatorIS2_EEEE
N8Archiver7mmapbufE
NSt3__120__shared_ptr_emplaceINS_13basic_istreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
N6CoreML10NNCompiler11MLModelInfoE
NSt3__110__function6__funcIZN12_GLOBAL__N_119ParseClassifierInfoERKN3MIL7IRBlockEE3$_0NS_9allocatorIS7_EEFbRKNS3_11IROperationEEEE
NSt3__110__function6__baseIFbRKN3MIL11IROperationEEEE
ZN12_GLOBAL__N_119ParseClassifierInfoERKN3MIL7IRBlockEE3$_0
NSt3__120__shared_ptr_pointerIPNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEENS_14default_deleteISH_EENS5_ISH_EEEE
NSt3__114default_deleteINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEEEE
NSt3__120__shared_ptr_pointerIPN3MIL10MILContextENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10MILContextEEE
N6CoreML16MultiArrayBufferE
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ERKNS_6vectorImNS_9allocatorImEEEENS2_10ScalarTypeENS2_12StorageOrderEmE3$_0NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1ERKNSt3__16vectorImNS1_9allocatorImEEEENS_10ScalarTypeENS_12StorageOrderEmE3$_0
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ERKNS_6vectorImNS_9allocatorImEEEENS2_10ScalarTypeENS2_12StorageOrderEmE3$_1NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1ERKNSt3__16vectorImNS1_9allocatorImEEEENS_10ScalarTypeENS_12StorageOrderEmE3$_1
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ES1_RKNS_6vectorImNS_9allocatorImEEEES9_NS2_10ScalarTypeEE3$_2NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1EPhRKNSt3__16vectorImNS2_9allocatorImEEEES8_NS_10ScalarTypeEE3$_2
NSt3__120__shared_ptr_pointerIPhZNK6CoreML16MultiArrayBuffer34lockAndGetBaseAddressOfPixelBufferEP10__CVBufferE3$_3NS_9allocatorIhEEEE
ZNK6CoreML16MultiArrayBuffer34lockAndGetBaseAddressOfPixelBufferEP10__CVBufferE3$_3
N6CoreML10NNCompiler7Backend3MIL5Ios1620Ios16LayerTranslatorE
NSt3__120__shared_ptr_pointerIP21_MLModelSpecificationNS_10shared_ptrIS1_E27__shared_ptr_default_deleteIS1_S1_EENS_9allocatorIS1_EEEE
NSt3__110shared_ptrI21_MLModelSpecificationE27__shared_ptr_default_deleteIS1_S1_EE
N12_GLOBAL__N_110imemstreamE
N12_GLOBAL__N_16membufE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10unique_ptrIN3MIL4Blob13StorageReaderENS_14default_deleteISB_EEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SE_EEEEEENS5_ISN_EEEE
NSt3__110__function6__funcIZN12_GLOBAL__N_121GetBlobReaderFunctionEvE3$_0NS_9allocatorIS3_EEFN3MIL4Util4SpanIKhLm18446744073709551615EEERKNS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEyEEE
NSt3__110__function6__baseIFN3MIL4Util4SpanIKhLm18446744073709551615EEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEyEEE
ZN12_GLOBAL__N_121GetBlobReaderFunctionEvE3$_0
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
N6CoreML10NNCompiler7Backend8IBackendE
N6CoreML10NNCompiler7Backend13NeuralNetwork38UpdatableNeuralNetworkMLComputeBackendE
NSt3__120__shared_ptr_pointerIPNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN8Espresso17net_configurationENS_4lessIS7_EENS5_INS_4pairIKS7_S9_EEEEEENS_14default_deleteISG_EENS5_ISG_EEEE
NSt3__114default_deleteINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN8Espresso17net_configurationENS_4lessIS7_EENS5_INS_4pairIKS7_S9_EEEEEEEE
NSt3__120__shared_ptr_pointerIPN6CoreML10NNCompiler16MLClassifierInfoENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6CoreML10NNCompiler16MLClassifierInfoEEE
NSt3__120__shared_ptr_pointerIPN6CoreML10NNCompiler13NeuralNetwork28ImagePreprocessingParametersENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN6CoreML10NNCompiler13NeuralNetwork28ImagePreprocessingParametersEEE
NSt3__120__shared_ptr_pointerIPN3MIL10IRFunctionENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10IRFunctionEEE
NSt3__120__shared_ptr_pointerIPN3MIL9IRProgramENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL9IRProgramEEE
N6CoreML10NNCompiler7Backend3MIL10Ios16Train17Ios16TrainBackendE
N6CoreML16MLModelExceptionE
N8Archiver17_IArchiveDiskImplE
N8Archiver13_IArchiveImplE
N8Archiver19_IArchiveMemoryImplE
NSt3__120__shared_ptr_emplaceIN8Archiver18_IDataBlobENMLImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver20MMappedInputENMLFileENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver14_IDataBlobImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver17_IArchiveDiskImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver14_MemoryIStreamENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver20_IDataBlobMemoryImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver19_IArchiveMemoryImplENS_9allocatorIS2_EEEE
N6CoreML10NNCompiler7Backend3MIL10Ios16Train25Ios16TrainLayerTranslatorE
N6CoreML10NNCompiler7Backend3MIL5Ios1520Ios15LayerTranslatorE
NSt3__110__function6__funcINS_6__bindIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS6_20LayerTranslationInfoERKN3MIL11IROperationERNS6_15MILBlockBuilderEEJRKNS_12placeholders4__phILi1EEERKNSM_ILi2EEERKNSM_ILi3EEERKNSM_ILi4EEEEEENS_9allocatorISZ_EESJ_EE
NSt3__110__function6__baseIFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS5_20LayerTranslationInfoERKN3MIL11IROperationERNS5_15MILBlockBuilderEEEE
NSt3__16__bindIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS4_20LayerTranslationInfoERKN3MIL11IROperationERNS4_15MILBlockBuilderEEJRKNS_12placeholders4__phILi1EEERKNSK_ILi2EEERKNSK_ILi3EEERKNSK_ILi4EEEEEE
NSt3__118__weak_result_typeIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS4_20LayerTranslationInfoERKN3MIL11IROperationERNS4_15MILBlockBuilderEEEE
N6CoreML10NNCompiler13NeuralNetwork22NeuralNetworkSpecProxyE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification13NeuralNetworkEEE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification22NeuralNetworkRegressorEEE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification23NeuralNetworkClassifierEEE
N8Archiver20MMappedInputENMLFileE
N6CoreML10NNCompiler7Backend13NeuralNetwork31NeuralNetworkEspressoNetBackendE
NSt3__110__function6__funcIZL13ConvertLayersRKN6CoreML13Specification5ModelERKNS2_10NNCompiler11MLModelInfoERN8Espresso18sequential_builderERNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENSB_11layer_shapeENS_4lessISK_EENSI_INS_4pairIKSK_SL_EEEEEERN14EspressoCommon18compileModelResultERU8__strongP7NSErrorE3$_1NSI_IS11_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
ZL13ConvertLayersRKN6CoreML13Specification5ModelERKNS_10NNCompiler11MLModelInfoERN8Espresso18sequential_builderERNSt3__13mapINSB_12basic_stringIcNSB_11char_traitsIcEENSB_9allocatorIcEEEENS8_11layer_shapeENSB_4lessISI_EENSG_INSB_4pairIKSI_SJ_EEEEEERN14EspressoCommon18compileModelResultERU8__strongP7NSErrorE3$_1
22MLCustomLayerException
NSt3__110__function6__funcIZL15BuildFromShapesRN8Espresso18sequential_builderERKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS2_11layer_shapeENS_4lessISB_EENS9_INS_4pairIKSB_SC_EEEEEEbRU8__strongP7NSErrorPbE3$_0NS9_ISR_EEFNS_10shared_ptrINS2_3netEEEvEEE
NSt3__110__function6__baseIFNS_10shared_ptrIN8Espresso3netEEEvEEE
ZL15BuildFromShapesRN8Espresso18sequential_builderERKNSt3__13mapINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS_11layer_shapeENS2_4lessIS9_EENS7_INS2_4pairIKS9_SA_EEEEEEbRU8__strongP7NSErrorPbE3$_0
NSt3__120__shared_ptr_emplaceIN8Archiver17_OArchiveDiskImplENS_9allocatorIS2_EEEE
N8Archiver13_OArchiveImplE
CoreML_InputDefaultValues
CoreML_IsRank5ArrayMapping
NSt3__120__shared_ptr_pointerIPKN3MIL13IRTensorValueENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL13IRTensorValueEEE
NSt3__120__shared_ptr_pointerIPKN3MIL17IRDictionaryValueENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL17IRDictionaryValueEEE
N8Archiver11MMappedFileE
NSt3__120__shared_ptr_emplaceIN6CoreML24BayesianProbitRegression24BayesianProbitRegressionENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML24BayesianProbitRegression13FeatureValuesENS_9allocatorIS3_EEEE
N8Archiver16_MemoryStreamBufE
N8Archiver17_MemoryIStreamBufE
N8Archiver17_MemoryOStreamBufE
N8Archiver14_MemoryIStreamE
N8Archiver14_MemoryOStreamE
N6CoreML10NNCompiler7Backend13NeuralNetwork40UpdatableNeuralNetworkEspressoNetBackendE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIcLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIcLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi4EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi4EEE
NSt3__120__shared_ptr_pointerIPN3MIL11IRParameterENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL11IRParameterEEE
NSt3__120__shared_ptr_pointerIPNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10shared_ptrIN3MIL11IRParameterEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SB_EEEEEENS_14default_deleteISK_EENS5_ISK_EEEE
NSt3__114default_deleteINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10shared_ptrIN3MIL11IRParameterEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SB_EEEEEEEE
NSt3__120__shared_ptr_pointerIPNS_6vectorINS_10shared_ptrIN3MIL11IRParameterEEENS_9allocatorIS5_EEEENS_14default_deleteIS8_EENS6_IS8_EEEE
NSt3__114default_deleteINS_6vectorINS_10shared_ptrIN3MIL11IRParameterEEENS_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIPFN3MIL16ValidationResultERKNS2_11IROperationEENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFN3MIL16ValidationResultERKNS2_11IROperationEEEE
PFN3MIL16ValidationResultERKNS_11IROperationEE
FN3MIL16ValidationResultERKNS_11IROperationEE
N6CoreML22MLModelResultExceptionE
N6CoreML3MIL6Opsets12CoreML5OpsetE
N6CoreML3MIL6Opsets12CoreML6OpsetE
N6CoreML3MIL6Opsets18CoreML6_trainOpsetE
NSt3__120__shared_ptr_pointerIPN3MIL10IROperatorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10IROperatorEEE
N6CoreML13Specification12CoreMLModels23AudioFeaturePrint_SoundE
N6CoreML13Specification12CoreMLModels17AudioFeaturePrintE
N6CoreML13Specification18CategoricalMappingE
N6CoreML13Specification8PipelineE
N6CoreML13Specification18PipelineClassifierE
N6CoreML13Specification17PipelineRegressorE
N6CoreML13Specification18FeatureDescriptionE
N6CoreML13Specification8MetadataE
N6CoreML13Specification16ModelDescriptionE
N6CoreML13Specification15SerializedModelE
N6CoreML13Specification5ModelE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES9_LNS1_14WireFormatLite9FieldTypeE9ELSB_9ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESA_LNS1_14WireFormatLite9FieldTypeE9ELSC_9ELi0EEENS0_11MessageLiteESA_SA_LSC_9ELSC_9ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEES8_E8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESA_LNS1_14WireFormatLite9FieldTypeE9ELSC_9ELi0EEENS0_11MessageLiteESA_SA_LSC_9ELSC_9ELi0EE15MapEntryWrapperE
N6CoreML5ModelE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification5ModelENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6CoreML13Specification5ModelENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6CoreML13Specification5ModelEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification8MetadataENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification16ModelDescriptionENS_9allocatorIS3_EEEE
N6CoreML13Specification8IdentityE
N6CoreML13Specification12CoreMLModels24VisionFeaturePrint_SceneE
N6CoreML13Specification12CoreMLModels26VisionFeaturePrint_ObjectsE
N6CoreML13Specification12CoreMLModels18VisionFeaturePrintE
N6CoreML13Specification13OneHotEncoderE
N6CoreML13Specification12CoreMLModels14TextClassifierE
N6CoreML13Specification7MILSpec7ProgramE
N6CoreML13Specification7MILSpec8FunctionE
N6CoreML13Specification7MILSpec5BlockE
N6CoreML13Specification7MILSpec16Argument_BindingE
N6CoreML13Specification7MILSpec8ArgumentE
N6CoreML13Specification7MILSpec9OperationE
N6CoreML13Specification7MILSpec14NamedValueTypeE
N6CoreML13Specification7MILSpec9ValueTypeE
N6CoreML13Specification7MILSpec10TensorTypeE
N6CoreML13Specification7MILSpec9TupleTypeE
N6CoreML13Specification7MILSpec8ListTypeE
N6CoreML13Specification7MILSpec14DictionaryTypeE
N6CoreML13Specification7MILSpec27Dimension_ConstantDimensionE
N6CoreML13Specification7MILSpec26Dimension_UnknownDimensionE
N6CoreML13Specification7MILSpec9DimensionE
N6CoreML13Specification7MILSpec20Value_ImmediateValueE
N6CoreML13Specification7MILSpec19Value_BlobFileValueE
N6CoreML13Specification7MILSpec5ValueE
N6CoreML13Specification7MILSpec26TensorValue_RepeatedFloatsE
N6CoreML13Specification7MILSpec27TensorValue_RepeatedDoublesE
N6CoreML13Specification7MILSpec24TensorValue_RepeatedIntsE
N6CoreML13Specification7MILSpec28TensorValue_RepeatedLongIntsE
N6CoreML13Specification7MILSpec25TensorValue_RepeatedBoolsE
N6CoreML13Specification7MILSpec27TensorValue_RepeatedStringsE
N6CoreML13Specification7MILSpec25TensorValue_RepeatedBytesE
N6CoreML13Specification7MILSpec11TensorValueE
N6CoreML13Specification7MILSpec10TupleValueE
N6CoreML13Specification7MILSpec9ListValueE
N6CoreML13Specification7MILSpec28DictionaryValue_KeyValuePairE
N6CoreML13Specification7MILSpec15DictionaryValueE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification6ScalerE
N6CoreML19HashOutputStreamBufE
NSt3__120__shared_ptr_pointerIPN6CoreML6detail23HashOutputStreamBufImplENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6CoreML6detail23HashOutputStreamBufImplEE27__shared_ptr_default_deleteIS3_S3_EE
N6CoreML13Specification12CoreMLModels33SoundAnalysisPreprocessing_VggishE
N6CoreML13Specification12CoreMLModels26SoundAnalysisPreprocessingE
N6CoreML13Specification25GLMClassifier_DoubleArrayE
N6CoreML13Specification13GLMClassifierE
N6CoreML13Specification7ImputerE
N6CoreML13Specification33CustomModel_CustomModelParamValueE
N6CoreML13Specification11CustomModelE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSE_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification12LinearKernelE
N6CoreML13Specification9RBFKernelE
N6CoreML13Specification10PolyKernelE
N6CoreML13Specification13SigmoidKernelE
N6CoreML13Specification6KernelE
N6CoreML13Specification10SparseNodeE
N6CoreML13Specification12SparseVectorE
N6CoreML13Specification20SparseSupportVectorsE
N6CoreML13Specification11DenseVectorE
N6CoreML13Specification19DenseSupportVectorsE
N6CoreML13Specification12CoefficientsE
N6CoreML13Specification22SupportVectorRegressorE
N6CoreML13Specification23SupportVectorClassifierE
N6CoreML13Specification12CoreMLModels9GazetteerE
N6CoreML13Specification10NormalizerE
N6CoreML13Specification16StringToInt64MapE
N6CoreML13Specification16Int64ToStringMapE
N6CoreML13Specification17StringToDoubleMapE
N6CoreML13Specification16Int64ToDoubleMapE
N6CoreML13Specification12StringVectorE
N6CoreML13Specification11Int64VectorE
N6CoreML13Specification11FloatVectorE
N6CoreML13Specification12DoubleVectorE
N6CoreML13Specification10Int64RangeE
N6CoreML13Specification8Int64SetE
N6CoreML13Specification11DoubleRangeE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSB_3ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSC_3ELi0EEENS0_11MessageLiteESA_xLSC_9ELSC_3ELi0EEE
N6google8protobuf8internal12MapEntryLiteIxNSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSB_9ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSC_9ELi0EEENS0_11MessageLiteExSA_LSC_3ELSC_9ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSB_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSC_1ELi0EEENS0_11MessageLiteESA_dLSC_9ELSC_1ELi0EEE
N6google8protobuf8internal12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS4_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS5_1ELi0EEENS0_11MessageLiteExdLS5_3ELS5_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSC_3ELi0EEENS0_11MessageLiteESA_xLSC_9ELSC_3ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSC_9ELi0EEENS0_11MessageLiteExSA_LSC_3ELSC_9ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSC_1ELi0EEENS0_11MessageLiteESA_dLSC_9ELSC_1ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS5_1ELi0EEENS0_11MessageLiteExdLS5_3ELS5_1ELi0EE15MapEntryWrapperE
N6CoreML13Specification32BayesianProbitRegressor_GaussianE
N6CoreML13Specification42BayesianProbitRegressor_FeatureValueWeightE
N6CoreML13Specification37BayesianProbitRegressor_FeatureWeightE
N6CoreML13Specification23BayesianProbitRegressorE
N6CoreML13Specification12CoreMLModels13WordEmbeddingE
N6CoreML13Specification14Int64ParameterE
N6CoreML13Specification15DoubleParameterE
N6CoreML13Specification15StringParameterE
N6CoreML13Specification13BoolParameterE
NSt3__120__shared_ptr_emplaceIN6CoreML13TreeEnsembles20_TreeComputationNodeENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML13TreeEnsembles13_TreeEnsembleENS_9allocatorIS3_EEEE
N6CoreML13Specification29NonMaximumSuppression_PickTopE
N6CoreML13Specification21NonMaximumSuppressionE
NSt3__120__shared_ptr_emplaceIN6CoreML11Recommender30_ItemSimilarityRecommenderDataENS_9allocatorIS3_EEEE
N6CoreML13Specification39ItemSimilarityRecommender_ConnectedItemE
N6CoreML13Specification38ItemSimilarityRecommender_SimilarItemsE
N6CoreML13Specification25ItemSimilarityRecommenderE
N6CoreML13Specification29FeatureVectorizer_InputColumnE
N6CoreML13Specification17FeatureVectorizerE
N6CoreML13Specification12CoreMLModels10WordTaggerE
N6CoreML13Specification46TreeEnsembleParameters_TreeNode_EvaluationInfoE
N6CoreML13Specification31TreeEnsembleParameters_TreeNodeE
N6CoreML13Specification22TreeEnsembleParametersE
N6CoreML13Specification22TreeEnsembleClassifierE
N6CoreML13Specification21TreeEnsembleRegressorE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification11FeatureTypeENS_9allocatorIS3_EEEE
N6CoreML13Specification14DictVectorizerE
N6CoreML13Specification13NeuralNetworkE
N6CoreML13Specification24NeuralNetworkImageScalerE
N6CoreML13Specification22NeuralNetworkMeanImageE
N6CoreML13Specification26NeuralNetworkPreprocessingE
N6CoreML13Specification14ActivationReLUE
N6CoreML13Specification19ActivationLeakyReLUE
N6CoreML13Specification14ActivationTanhE
N6CoreML13Specification20ActivationScaledTanhE
N6CoreML13Specification17ActivationSigmoidE
N6CoreML13Specification16ActivationLinearE
N6CoreML13Specification21ActivationSigmoidHardE
N6CoreML13Specification15ActivationPReLUE
N6CoreML13Specification13ActivationELUE
N6CoreML13Specification25ActivationThresholdedReLUE
N6CoreML13Specification18ActivationSoftsignE
N6CoreML13Specification18ActivationSoftplusE
N6CoreML13Specification28ActivationParametricSoftplusE
N6CoreML13Specification16ActivationParamsE
N6CoreML13Specification6TensorE
N6CoreML13Specification18NeuralNetworkLayerE
N6CoreML13Specification17BranchLayerParamsE
N6CoreML13Specification15LoopLayerParamsE
N6CoreML13Specification20LoopBreakLayerParamsE
N6CoreML13Specification23LoopContinueLayerParamsE
N6CoreML13Specification15CopyLayerParamsE
N6CoreML13Specification22GreaterThanLayerParamsE
N6CoreML13Specification23GreaterEqualLayerParamsE
N6CoreML13Specification19LessThanLayerParamsE
N6CoreML13Specification20LessEqualLayerParamsE
N6CoreML13Specification16EqualLayerParamsE
N6CoreML13Specification19NotEqualLayerParamsE
N6CoreML13Specification21LogicalAndLayerParamsE
N6CoreML13Specification20LogicalOrLayerParamsE
N6CoreML13Specification21LogicalXorLayerParamsE
N6CoreML13Specification21LogicalNotLayerParamsE
N6CoreML13Specification23BorderAmounts_EdgeSizesE
N6CoreML13Specification13BorderAmountsE
N6CoreML13Specification12ValidPaddingE
N6CoreML13Specification11SamePaddingE
N6CoreML13Specification12SamplingModeE
N6CoreML13Specification18BoxCoordinatesModeE
N6CoreML13Specification12WeightParamsE
N6CoreML13Specification18QuantizationParamsE
N6CoreML13Specification24LinearQuantizationParamsE
N6CoreML13Specification29LookUpTableQuantizationParamsE
N6CoreML13Specification22ConvolutionLayerParamsE
N6CoreML13Specification24Convolution3DLayerParamsE
N6CoreML13Specification23InnerProductLayerParamsE
N6CoreML13Specification20EmbeddingLayerParamsE
N6CoreML13Specification22EmbeddingNDLayerParamsE
N6CoreML13Specification20BatchnormLayerParamsE
N6CoreML13Specification39PoolingLayerParams_ValidCompletePaddingE
N6CoreML13Specification18PoolingLayerParamsE
N6CoreML13Specification20Pooling3DLayerParamsE
N6CoreML13Specification26GlobalPooling3DLayerParamsE
N6CoreML13Specification34PaddingLayerParams_PaddingConstantE
N6CoreML13Specification36PaddingLayerParams_PaddingReflectionE
N6CoreML13Specification37PaddingLayerParams_PaddingReplicationE
N6CoreML13Specification18PaddingLayerParamsE
N6CoreML13Specification17ConcatLayerParamsE
N6CoreML13Specification14LRNLayerParamsE
N6CoreML13Specification18SoftmaxLayerParamsE
N6CoreML13Specification16SplitLayerParamsE
N6CoreML13Specification14AddLayerParamsE
N6CoreML13Specification19MultiplyLayerParamsE
N6CoreML13Specification24UnaryFunctionLayerParamsE
N6CoreML13Specification19UpsampleLayerParamsE
N6CoreML13Specification25ResizeBilinearLayerParamsE
N6CoreML13Specification21CropResizeLayerParamsE
N6CoreML13Specification15BiasLayerParamsE
N6CoreML13Specification16ScaleLayerParamsE
N6CoreML13Specification23LoadConstantLayerParamsE
N6CoreML13Specification22L2NormalizeLayerParamsE
N6CoreML13Specification18FlattenLayerParamsE
N6CoreML13Specification18ReshapeLayerParamsE
N6CoreML13Specification18PermuteLayerParamsE
N6CoreML13Specification25ReorganizeDataLayerParamsE
N6CoreML13Specification16SliceLayerParamsE
N6CoreML13Specification17ReduceLayerParamsE
N6CoreML13Specification15CropLayerParamsE
N6CoreML13Specification18AverageLayerParamsE
N6CoreML13Specification14MaxLayerParamsE
N6CoreML13Specification14MinLayerParamsE
N6CoreML13Specification21DotProductLayerParamsE
N6CoreML13Specification32MeanVarianceNormalizeLayerParamsE
N6CoreML13Specification25SequenceRepeatLayerParamsE
N6CoreML13Specification26SimpleRecurrentLayerParamsE
N6CoreML13Specification14GRULayerParamsE
N6CoreML13Specification10LSTMParamsE
N6CoreML13Specification16LSTMWeightParamsE
N6CoreML13Specification29UniDirectionalLSTMLayerParamsE
N6CoreML13Specification28BiDirectionalLSTMLayerParamsE
N6CoreML13Specification39CustomLayerParams_CustomLayerParamValueE
N6CoreML13Specification17CustomLayerParamsE
N6CoreML13Specification20TransposeLayerParamsE
N6CoreML13Specification24BatchedMatMulLayerParamsE
N6CoreML13Specification19ConcatNDLayerParamsE
N6CoreML13Specification20SoftmaxNDLayerParamsE
N6CoreML13Specification18ReverseLayerParamsE
N6CoreML13Specification21ReverseSeqLayerParamsE
N6CoreML13Specification25LoadConstantNDLayerParamsE
N6CoreML13Specification19FillLikeLayerParamsE
N6CoreML13Specification21FillStaticLayerParamsE
N6CoreML13Specification22FillDynamicLayerParamsE
N6CoreML13Specification29WhereBroadcastableLayerParamsE
N6CoreML13Specification14SinLayerParamsE
N6CoreML13Specification14CosLayerParamsE
N6CoreML13Specification14TanLayerParamsE
N6CoreML13Specification15AsinLayerParamsE
N6CoreML13Specification15AcosLayerParamsE
N6CoreML13Specification15AtanLayerParamsE
N6CoreML13Specification15SinhLayerParamsE
N6CoreML13Specification15CoshLayerParamsE
N6CoreML13Specification15TanhLayerParamsE
N6CoreML13Specification16AsinhLayerParamsE
N6CoreML13Specification16AcoshLayerParamsE
N6CoreML13Specification16AtanhLayerParamsE
N6CoreML13Specification27PowBroadcastableLayerParamsE
N6CoreML13Specification15Exp2LayerParamsE
N6CoreML13Specification23WhereNonZeroLayerParamsE
N6CoreML13Specification25MatrixBandPartLayerParamsE
N6CoreML13Specification26UpperTriangularLayerParamsE
N6CoreML13Specification26LowerTriangularLayerParamsE
N6CoreML13Specification26BroadcastToLikeLayerParamsE
N6CoreML13Specification28BroadcastToStaticLayerParamsE
N6CoreML13Specification29BroadcastToDynamicLayerParamsE
N6CoreML13Specification27AddBroadcastableLayerParamsE
N6CoreML13Specification27MaxBroadcastableLayerParamsE
N6CoreML13Specification27MinBroadcastableLayerParamsE
N6CoreML13Specification27ModBroadcastableLayerParamsE
N6CoreML13Specification32FloorDivBroadcastableLayerParamsE
N6CoreML13Specification32SubtractBroadcastableLayerParamsE
N6CoreML13Specification32MultiplyBroadcastableLayerParamsE
N6CoreML13Specification30DivideBroadcastableLayerParamsE
N6CoreML13Specification17GatherLayerParamsE
N6CoreML13Specification18ScatterLayerParamsE
N6CoreML13Specification19GatherNDLayerParamsE
N6CoreML13Specification20ScatterNDLayerParamsE
N6CoreML13Specification26GatherAlongAxisLayerParamsE
N6CoreML13Specification27ScatterAlongAxisLayerParamsE
N6CoreML13Specification16StackLayerParamsE
N6CoreML13Specification32RankPreservingReshapeLayerParamsE
N6CoreML13Specification26ConstantPaddingLayerParamsE
N6CoreML13Specification27RandomNormalLikeLayerParamsE
N6CoreML13Specification29RandomNormalStaticLayerParamsE
N6CoreML13Specification30RandomNormalDynamicLayerParamsE
N6CoreML13Specification28RandomUniformLikeLayerParamsE
N6CoreML13Specification30RandomUniformStaticLayerParamsE
N6CoreML13Specification31RandomUniformDynamicLayerParamsE
N6CoreML13Specification30RandomBernoulliLikeLayerParamsE
N6CoreML13Specification32RandomBernoulliStaticLayerParamsE
N6CoreML13Specification33RandomBernoulliDynamicLayerParamsE
N6CoreML13Specification34CategoricalDistributionLayerParamsE
N6CoreML13Specification19ReduceL1LayerParamsE
N6CoreML13Specification19ReduceL2LayerParamsE
N6CoreML13Specification20ReduceMaxLayerParamsE
N6CoreML13Specification20ReduceMinLayerParamsE
N6CoreML13Specification20ReduceSumLayerParamsE
N6CoreML13Specification21ReduceProdLayerParamsE
N6CoreML13Specification21ReduceMeanLayerParamsE
N6CoreML13Specification23ReduceLogSumLayerParamsE
N6CoreML13Specification26ReduceSumSquareLayerParamsE
N6CoreML13Specification26ReduceLogSumExpLayerParamsE
N6CoreML13Specification21ExpandDimsLayerParamsE
N6CoreML13Specification22FlattenTo2DLayerParamsE
N6CoreML13Specification24ReshapeStaticLayerParamsE
N6CoreML13Specification22ReshapeLikeLayerParamsE
N6CoreML13Specification25ReshapeDynamicLayerParamsE
N6CoreML13Specification18SqueezeLayerParamsE
N6CoreML13Specification15TopKLayerParamsE
N6CoreML13Specification17ArgMaxLayerParamsE
N6CoreML13Specification17ArgMinLayerParamsE
N6CoreML13Specification18SplitNDLayerParamsE
N6CoreML13Specification15CeilLayerParamsE
N6CoreML13Specification16RoundLayerParamsE
N6CoreML13Specification16FloorLayerParamsE
N6CoreML13Specification15SignLayerParamsE
N6CoreML13Specification15ClipLayerParamsE
N6CoreML13Specification22SliceStaticLayerParamsE
N6CoreML13Specification23SliceDynamicLayerParamsE
N6CoreML13Specification15TileLayerParamsE
N6CoreML13Specification19GetShapeLayerParamsE
N6CoreML13Specification14ErfLayerParamsE
N6CoreML13Specification15GeluLayerParamsE
N6CoreML13Specification22RangeStaticLayerParamsE
N6CoreML13Specification23RangeDynamicLayerParamsE
N6CoreML13Specification25SlidingWindowsLayerParamsE
N6CoreML13Specification29LayerNormalizationLayerParamsE
N6CoreML13Specification32NonMaximumSuppressionLayerParamsE
N6CoreML13Specification22ClampedReLULayerParamsE
N6CoreML13Specification18ArgSortLayerParamsE
N6CoreML13Specification22SliceBySizeLayerParamsE
N6CoreML13Specification23NeuralNetworkClassifierE
N6CoreML13Specification17OneHotLayerParamsE
N6CoreML13Specification17CumSumLayerParamsE
N6CoreML13Specification22NeuralNetworkRegressorE
N6CoreML13Specification23NetworkUpdateParametersE
N6CoreML13Specification9LossLayerE
N6CoreML13Specification32CategoricalCrossEntropyLossLayerE
N6CoreML13Specification25MeanSquaredErrorLossLayerE
N6CoreML13Specification9OptimizerE
N6CoreML13Specification12SGDOptimizerE
N6CoreML13Specification13AdamOptimizerE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSE_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EEE
N6google8protobuf4hashINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification27KNearestNeighborsClassifierE
N6CoreML13Specification21NearestNeighborsIndexE
N6CoreML13Specification16UniformWeightingE
N6CoreML13Specification24InverseDistanceWeightingE
N6CoreML13Specification11LinearIndexE
N6CoreML13Specification17SingleKdTreeIndexE
N6CoreML13Specification24SquaredEuclideanDistanceE
N6CoreML13Specification11LinkedModelE
N6CoreML13Specification15LinkedModelFileE
N6CoreML13Specification21ArrayFeatureExtractorE
N6CoreML13Specification24GLMRegressor_DoubleArrayE
N6CoreML13Specification12GLMRegressorE
N6CoreML13Specification16Int64FeatureTypeE
N6CoreML13Specification17DoubleFeatureTypeE
N6CoreML13Specification17StringFeatureTypeE
N6CoreML13Specification9SizeRangeE
N6CoreML13Specification26ImageFeatureType_ImageSizeE
N6CoreML13Specification37ImageFeatureType_EnumeratedImageSizesE
N6CoreML13Specification31ImageFeatureType_ImageSizeRangeE
N6CoreML13Specification16ImageFeatureTypeE
N6CoreML13Specification22ArrayFeatureType_ShapeE
N6CoreML13Specification33ArrayFeatureType_EnumeratedShapesE
N6CoreML13Specification27ArrayFeatureType_ShapeRangeE
N6CoreML13Specification16ArrayFeatureTypeE
N6CoreML13Specification21DictionaryFeatureTypeE
N6CoreML13Specification19SequenceFeatureTypeE
N6CoreML13Specification11FeatureTypeE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N6CoreML16TreeEnsembleBaseE
N6CoreML22TreeEnsembleClassifierE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18CopyingInputStreamE
N6google8protobuf2io25CopyingInputStreamAdaptorE
N6google8protobuf2io19CopyingOutputStreamE
N6google8protobuf2io26CopyingOutputStreamAdaptorE
N6google8protobuf2io19ZeroCopyInputStreamE
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io18IstreamInputStreamE
N6google8protobuf2io18IstreamInputStream25CopyingIstreamInputStreamE
N6google8protobuf2io19OstreamOutputStreamE
N6google8protobuf2io19OstreamOutputStream26CopyingOstreamOutputStreamE
N6google8protobuf11MessageLiteE
>o
@~
@~
@~
@~
@~
>r
>r
>r
>o
@~
4c
Input stream is not valid
assert_invariant
json.hpp
m_type != value_t::object || m_value.object != nullptr
m_type != value_t::array || m_value.array != nullptr
m_type != value_t::string || m_value.string != nullptr
m_type != value_t::binary || m_value.binary != nullptr
[json.exception.
cannot create object from initializer list
cannot use operator[] with a numeric argument with 
null
object
array
string
boolean
binary
discarded
number
type_error
iter_impl
m_object != nullptr
set_begin
set_end
cannot compare iterators of different containers
operator==
invalid_iterator
operator++
cannot use key() for non-object iterators
key '
' not found
cannot use at() with 
map::at:  key not found
out_of_range
type must be string, but is 
cannot use operator[] with a string argument with 
get_decimal_point
loc != nullptr
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
unget
!token_string.empty()
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
scan_literal
std::char_traits<char_type>::to_char_type(current) == literal_text[0]
scan_string
current == '\"'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
0x00 <= codepoint && codepoint <= 0x10FFFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
get_codepoint
current == 'u'
0x0000 <= codepoint && codepoint <= 0xFFFF
next_byte_in_range
ranges.size() == 2 || ranges.size() == 4 || ranges.size() == 6
scan_number
false
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
endptr == token_buffer.data() + token_buffer.size()
value
object key
object separator
number overflow parsing '
sax_parse_internal
!states.empty()
excessive object size: 
handle_value
!keep_stack.empty()
ref_stack.back()->is_array() || ref_stack.back()->is_object()
!key_keep_stack.empty()
object_element
end_object
!ref_stack.empty()
operator->
m_it.object_iterator != m_object->m_value.object->end()
m_it.array_iterator != m_object->m_value.array->end()
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
excessive array size: 
end_array
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
dump
i != val.m_value.object->cend()
std::next(i) == val.m_value.object->cend()
!val.m_value.array->empty()
"bytes": [
"subtype": 
{"bytes":[
],"subtype":
null}
true
<discarded>
\u%04x
\u%04x\u%04x
%.2X
invalid UTF-8 byte at index 
: 0x
dump_escaped
incomplete UTF-8 string; last byte: 0x
\ufffd
decode
index < 400
dump_integer
n_chars < number_buffer.size() - 1
to_chars
std::isfinite(value)
last - first >= std::numeric_limits<FloatType>::max_digits10
len <= std::numeric_limits<FloatType>::max_digits10
last - first >= 2 + (-kMinExp - 1) + std::numeric_limits<FloatType>::max_digits10
last - first >= std::numeric_limits<FloatType>::max_digits10 + 6
grisu2
value > 0
compute_boundaries
normalize
x.f != 0
normalize_to
delta >= 0
((x.f << delta) >> delta) == x.f
m_plus.e == m_minus.e
m_plus.e == v.e
get_cached_power_for_binary_exponent
e >= -1500
e <= 1500
index >= 0
static_cast<std::size_t>(index) < kCachedPowers.size()
kAlpha <= cached.e + e + 64
kGamma >= cached.e + e + 64
grisu2_digit_gen
M_plus.e >= kAlpha
M_plus.e <= kGamma
p1 > 0
d <= 9
p2 > delta
p2 <= (std::numeric_limits<std::uint64_t>::max)() / 10
x.e == y.e
x.f >= y.f
grisu2_round
len >= 1
dist <= delta
rest <= delta
ten_k > 0
buf[len - 1] != '0'
format_buffer
min_exp < 0
max_exp > 0
k > n
append_exponent
e > -1000
e < 1000
A valid manifest does not exist at path: 
Failed to create model package at path: 
Failed to create data directory at path: 
Failed to open model package at path: 
File format version must be in the form of major.minor.patch, but the specified value was: 
Failed to parse file format version: 
 because: 
File format version uses negative number(s): 
Unsupported version: 
Invalid itemInfo for identifier: 
Item does not exist for identifier: 
Failed to look up root model
Manifest.json
Data
fileFormatVersion
path
name
author
description
itemInfoEntries
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
rootModelIdentifier
classify:topK:error be implemented by derived class!
e5BundleURL parameter must not be nil.
functionName parameter must not be nil.
com.apple.coreml.MLE5Engine.operationPoolQueue
Data provided in input: %@ is missing feature value for training input: %@
Data provided for %@ has insufficient shape
MLMultiArray value for %@ does not comply with constraint: %@
Failed to create multi array of shape %@
Failed to copy over input multi array
Shape for multi array value of %@ is not allowed
_MultiArray
Image value for %@ does not comply with constraint: %@
Failed to copy over image input
Value for %@ does not comply with constraint in description: %@ (%@)
Failed to derive valid training input from class label
Predicted class is not in expected format
Invalid class label %@ provided as input
Input %@ is not in the expected format, expected: %@
WARNING: using -h 0 may be faster
WARNING: reaching max number of iterations
optimization finished, #iter = %d
WARNING: training data in only one class. See README for details.
WARNING: class label %d specified in weight is not found
Total nSV = %d
WARNING: # folds > # data. Will use # folds = # data instead (i.e., leave-one-out cross validation)
Model doesn't contain information for SVR probability inference
svm_type %s
kernel_type %s
degree %d
gamma %g
coef0 %g
nr_class %d
total_sv %d
probA
probB
nr_sv
%.16g 
0:%d 
%d:%.8g 
%80s
unknown svm type.
unknown kernel function.
unknown text in model file: [%s]
ERROR: fscanf failed to read model
unknown svm type
unknown kernel type
gamma < 0
degree of polynomial kernel < 0
cache_size <= 0
eps <= 0
C <= 0
nu <= 0 or nu > 1
p < 0
shrinking != 0 and shrinking != 1
probability != 0 and probability != 1
one-class SVM probability output not supported yet
specified nu is infeasible
Prob. model for test data: target value = predicted value + z,
z: Laplace distribution e^(-|z|/sigma)/(2sigma),sigma= %g
obj = %f, rho = %f
nSV = %d, nBSV = %d
nu = %f
C = %f
epsilon = %f
Line search fails in two-class probability estimates
Reaching maximal iterations in two-class probability estimates
Exceeds max_iter in multiclass_prob
c_svc
nu_svc
one_class
epsilon_svr
nu_svr
linear
polynomial
sigmoid
precomputed
MLDictionaryConstraint cannot check undefined values
MLDictionaryConstraint only allows Dictionary values
Dicitonary keys are not all expected type %@
keyType
inputRanks
outputRanks
inputShapes
outputShapes
MLModelDescriptionKey
MLModelVersionStringKey
MLModelAuthorKey
MLModelCreatorDefinedKey
MLModelLicenseKey
axes
/System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis
_MLNLPSentenceClassifierModel
NaturalLanguage framework not available on this OS version
com.apple
Must only have one string input feature
Must only have one string output feature
parameters['modelData'] does not exist or is not a string
initialization of classifier model with model data failed
Input string feature '%@' not found
Prediction failed
%@ %@
key_id
model_name
team_id
signed_key
raw_key
PBUNSET
(unknown: %i)
MLModelCollectionDidChangeNotification
Failed to begin access for model collection with identifier '%@': invalid identifier
v16@?0@"NSString"8
Failed to begin access for model collection with identifier '%@': internal error
Failed to begin access for model collection with identifier '%@': internal registration failed
v16@?0Q8
Failed to begin access for model collection with identifier '%@': download failed
Failed to end access for model collection with identifier '%@': invalid identifier
Failed to end access for model collection with identifier '%@': internal error
An error occurred ending access for model collection with identifier '%@': internal error
v20@?0B8@"NSError"12
v16@?0@"<TRINamespaceUpdateProtocol>"8
%@.%@
TRIClient
Unable to find class %s
TRIExperimentIdentifiers
TRIDownloadOptions
TRIFactorLevel
TRILevel
TRIFile
TRIFactor
SplitND layer: Invalid value of the argument 'axis'.
numSplits
splitSizes
axis
taskIdentifier
modelURL
modelConfiguration
predictionOptions
reps
localOutlierFactorScore
Local Outlier Factor can not override numberOfNeighbors with value of class=%@.
Local Outlier Factor should have at least numberOfNeighbors(%lu) + 1 data points, but we got (%lu) data points.
using wrong sized neighbors with size=
Missing input name in model description for %@.
Invalid MLFeatureTypeMultiArray value for %@.
Shape of input MLMultiArray is %@, expected [%lu]
Fail to compute LOF: %s
%@ does not have a parameter for requested key %@.
Failed to get tensor descriptor.ESRT: %s (%d)
%@ x %@
pixelsWide
pixelsHigh
Unknown error loading MIL model
Error loading MIL model: 
Error parsing MIL model: 
Validation error parsing MIL model: 
Failed to copy weights during compilation.
 Error description: 
Initialization of Gazetteer parameters failed
Model type is not a Gazetteer
Model description is invalid
Invalid parameters for Gazetteer
parameters.modelParameterData does not exist or is not a NSData
initialization of gazetteer model with model data failed
Gazette does not contain input string '%@'. %@
Gazette does not contain input string '%@'. 
This is a gazetteer model (version %lu) which classifies %@ text according to set {
This is a gazetteer model (version %lu) which classifies text according to set {
Unable to save model to %@. %s
MLMultiArrayDataTypeInvalid (%d)
pixelBuffer must not be NULL.
The pixel format type must be kCVPixelFormatType_OneComponent16Half. (%c%c%c%c is specified.)
The pixel buffer must use IOSurface.
The shape is nil or empty.
The shape's last dimension (%zu) doesn't match the pixel buffer's width (%zu)
The product of dimensions in the shape ([%@]) except last one must match the pixel buffer's height (%zu)
Could not fetch NSNumber at offset %zu because it is beyond the end of the multi array.
Could not store NSNumber at offset %zu because it is beyond the end of the multi array.
v32@?0^v8q16@"NSArray"24
 vector
 matrix
 array
dataType
shape
strides
isBackedByPixelBuffer
The buffer is %zd bytes but it is smaller than the expected length (%zu bytes). This is a programming error.
dataPointer
v24@?0r^v8Q16
shape is nil or empty.
scalars must be a non-empty array of NSNumbers.
MLMultiArray of shape: %@ should have %zu element(s), but the `scalars` argument has %td element(s).
Empty dimension was found at axis %tu.
The element type is neither NSArray nor NSNumber at axis %tu.
Dimension mismatch at axis %tu; some have %tu element(s) but others have %tu element(s).
B32@?0@8Q16^B24
Invalid element type at axis %tu.
v32@?0@"NSArray"8Q16^B24
Unable to copy %@ into %@
Unable to vectorize %@ into %@
value count (%@) does not match array count (%@)
-[MLMultiArray initWithShape:dataType:error:] was supposed to use first-major contiguous memory layout, but it doesn't.
The array of array is not a matrix: some row's length is %lu, but another row's length is %lu
multiArrays shall not be empty.
The first input MLMultiArray has too many dimensions (%@)
%@-th input MLMultiArray has shape (%@), which is different from the first input's shape: (%@).
%@-th input MLMultiArray has shape (%@), but %@-th dimension shall not be negative.
%@-th input MLMultiArray has shape (%@) but the first input's shape is (%@); %@-th dimension doesn't match.
v32@?0@"MLMultiArray"8Q16^B24
The sum of the dimensions at the concatenating axis was too big and caused an integer overflow.
setRangeWithRawData: range out of bounds.
setRangeWithRawData: non-contiguous %@d destination unsupported
setRangeWithRawData: failed to vectorize source
Invalid origin %@ for slicing %@
Invalid shape %@ for slicing %@
Slice at %@ with shape %@ is out of bounds
Shape %@ is not squeezable at dimensions %@
The mutable shaped buffer provider has reported incorrect dimensions of strides.
Nothing to concatenate.
The first multi array has a shape with size 
 but another multi array's shape size is 
The first multi array has a shape 
 but another multi array's shape is 
; they cannot be concatenate along with axis: 
is_output
in_memory_model
defaultValue
numericConstraint
parameterKey: %@
defaultValue: %@
numericConstraint: %@
Cannot determine valueDescription for this regressor
Cannot determine predictedFeatureName for this regressor
Invalid regressor: predicted feature '%@' is not described as double or MultiArray
Predicted feature named '%@' was not output by pipeline
Predicted feature '%@' is of type %@ not the expected %@
Regressed feature named '%@' is not a Double or MultiArray
Internal error: support vectors not set.
Shape must have at least 3 dimensions, The third dimension to the last (channels) must be 3, and any earlier dimensions must have a size of 1.
Shape must have at least 2 dimensions, and if more, the first dimensions should have a size of 1.
Failed to create BGRA image %@ x %@
Failed to lock pixel buffer
v24@?0r^f8q16
Failed to convert planar to OneComponent8: Code=%@
Invalid array shape [%@] for converting to BGR image. %@
Shape's width (%d) doesn't match the pixel buffer's width (%d)
Shape's height (%d) doesn't match the pixel buffer's height (%d)
Failed to create temporary buffer for conversion to image
Failed to convert planar to BGRAX888: Code=%@
pixel format type %c%c%c%c is not supported.
Invalid array shape [%@] for converting to gray image. %@
FailedToComputeHash
Attempted to compile a non-neural-network model as a neural network.
Encountered an unexpected error while compiling a neural network model.
Encountered an error while compiling a neural network model: %@
generic
Program main function does not have an opset specialization with an associated backend.
coremlc
com.apple.MIL
CFBundleVersion
compiler major version for compiled model is %@ and is more recent than this framework major version %@.
placeHolderInputName
Neural network classifier does not contain class labels.
The size of the output layer '%@' in the neural network does not match the number of classes in the classifier.
Classify can only be called on neural network classifiers.
Regress can only be called on neural network regressors.
Failed to lock pixel buffer while populating outputs
com.apple.CoreMLBatchProcessingQueue
com.apple.CoreMLNNProcessingQueue
In-memory program only supports main function.
The in-memory compiled model is neither MLProgram nor NNv1. This is a logic error.
Model file not found.
compute_unit_mask
espresso_context_set_int_option for ANE|CPU returned status = %d
For input feature '%@', the provided shape %@ is not compatible with the model's feature description.
The model expects input feature %@ to be an image, but the input (%@) is of type %ld.
Input image feature %@ does not match model description
Required input feature not passed to neural network.
Unsupported input pixel format type `%c%c%c%c`.
Invalid multi-array data type: %08x.
Unsupported input feature type: %@
Unable to bind pixel buffer directly to the feature named %@ due to error: %d
Failed to lock CVPixelBuffer when binding input image with error: %d
Unexpected pixel format type %c%c%c%c
Failed to bind image through vImage with error: %d
Failed to bind the input buffer %@: %d
Espresso doesn't report the output shape; we cannot verify the output backing's shape. Error: %d
Failed to set shape of rank %zu to Espresso Buffer. Error: %d
The output backing MLMultiArray's shape (shape.count = %zu) doesn't match to Espresso's output shape (shape.count = %zu) even after squeezed. This is most likely a framework programming error.
Output backing for %@ is not compatible with the model's output feature description.
Output feature %@ doesn't support an output backing.
The underlying pixel buffer (%p) used in the output backing MLMultiArray object for feature %@ has been locked. The output backing cannot use such an object. Typically, the error occurs when the caller has invoked MLMultiArray's data accessing properties before the inference, or they used a locked pixel buffer to initialize the multi array. Use a newly created pixel buffer and MLMultiArray to avoid this error.
Output feature %@ doesn't have a description for the image constraints.
%@ image output feature must use a pixel buffer of kCVPixelFormatType_32BGRA as the output backing, but kCVPixelFormatType_32ARGB pixel buffer was specified.
The output backing object must be either CVPixelBuffer or MLMultiArray.
Output backings cannot be used for a dynamic output feature: %@.
Forced automatic output backings was requested but we couldn't bind the output buffer for feature: %@
Error binding output buffer: %@
Error checking if an output blob is dynamic or not, %@, %d.
Forced automatic output backings was requested but we couldn't fabricate the output buffer for feature: %@
Error computing NN outputs.
Failure in binding dynamic outputs. (err=%d)
The specified output backing object is not compatible with the output feature type: %@
Image output %@ is missing width, height, and pixel info in its description
Batch or sequence image output is unsupported for image output %@
Invalid shape for output feature '%@': %@
MLNeuralNetworkEngine doesn't support MLImagePixelType %tu yet.
Failed to convert output %@ to image
None of the features required to evaulate this model are produced by the feature provider which is first among the batch of input feature providers.
The model requires these input features:
    %@
The first batch input feature provider provides these input features:
Ensure that each of the batch input feature providers provides all the input features with types matching those required to evaluate the model.
Failed to build clean before reshape.
Unable to select network configuration for: %@
Failure dynamically resizing for sequence length.
Passing empty input dictionary for resetSizes.
Incorrect input number of dimensions (must be between 1, 3, or 5 dimensions.
Incorrect input number of dimensions (must be 1 or greater).
Cannot evaluate a batch of size %@, which is larger than maximum of %@.
Cannot evaluate a sequence of length %@, which is longer than maximum of %@ for bidirectional models.
Failure setting up to dynamically allocate for sequence size.
Error in passing image pre-processing parameters to network.
Error in re-declaring input '%@'.
Error in declaring output '%@'.
Error in building plan.
Unable to verify the first input of the batch.
Unable to reset sizes for an element of a batch computation.
Error calling plan submit.
v16@?0^{?=ii*}8
Error calling plan_submit in batch processing.
Error calling plan submit for batch processing.
Failure checking availability of plan submit.
This neural network model does not have a parameter for requested key %@. Note: only updatable neural network models can provide parameter values and these values are only accessible in the context of an MLUpdateTask completion or progress handler.
context_transfer
%@:%@:%@
Error in declaring network.
Unknown
Gray8
RGB8
BGR8
Gray16Half
momentum
shuffle
linkedModelFileName
linkedModelSearchPath
maxDepth
numTrees
numClasses
minChildWeight
updateType
Parameter '%@' has no value
Custom model implmenetantion class named '%@' does not conform to MLCustomModel protocol
Model type is not a CustomModel
CPU Only
GPU and CPU
CPU and NeuralEngine
computeUnits
useSPIforScribble
allowLowPrecisionAccumulationOnGPU
allowBackgroundGPUCompute
MPSDeviceOptions
enableTestVectorMode
rootModelURL
profilingOptions
usePreloadedKey
forceMLComputeTraining
parentModelName
modelName
 computeUnits: %@,             
 useWatchSPIForScribble: %s,             
 allowLowPrecisionAccumulationOnGPU: %s,             
 allowBackgroundGPUComputeSetting: %s,             
 preferredMetalDevice: %@,             
 enableTestVectorMode: %s,             
 parameters: %@,             
 rootModelURL: %@,             
 profilingOptions: %lu,             
 usePreloadedKey: %s,             
 trainWithMLCompute: %s,             
 parentModelName: %@,             
 modelName: %@,             
com.apple.coreml.MLE5Engine.streamPoolQueue
encryption_key
encryption_iv
Error: asMMappedFile is not supported by _IDataBlobMemoryImpl
The must be the same value count for each feature. Feature '%@' has %@ values. Expected %@
Failed to determine type of feature '%@'.
Error initializing sample %@ of feature `%@`
kNumDimensions
kDescription
kLabelsForDataPoints
kLabelType
kIndexType
kIndex
kDefaultLabel
kWeightingScheme
kNearestLabelsFeatureName
kNearestDistancesFeatureName
kParameterContainer
Index type is invalid for this model.
Missing input name for K Nearest Neighbor model.
K Nearest Neighbor models only accept multi array input types.
_debugNearestLabels
_debugNearestDistances
Missing MLMultiArray for MLFeatureProvider
Shape of input MLMultiArray is %@, expected %@
Error computing pairwise distances in k-nearest neighbors model.
Error predicting class due to missing data points and default label.
Unable to load class labels for k-Nearest-Neighbor model.
Invalid k-nearest neighbor model -- the length of the data vector is not a multiple of the given dimensionality.
Failed to unarchive model parameters.
Failed to archive model parameters.
notreesyet
Received nil MLFeatureProvider for index %d from training data MLBatchProvider
Missing MLMultiArrayValue for feature named %@
Shape of training data point %d MLMultiArray is %@, expected %@
Failed to convert training data to the right format
Missing MLFeatureValue for feature named %@
Label type must be one of MLFeatureTypeString or MLFeatureTypeInt64
Failed to update model with training data
Failed to create directory at %@
Failed archive updated model
Failed save updated model to %@
Nearest Neighbor Classifier Model does not have a parameter for requested key %@.
modelParameters
inputs: %@
outputs: %@
predictedFeatureName: %@
predictedProbabilitiesName: %@
updatable: %@
trainingInputs: %@
parameters: %@
metadata: %@
inputDescriptionsByName
outputDescriptionsByName
predictedFeatureName
predictedProbabilitiesName
trainingInputDescriptionsByName
isUpdatable
parameterDescriptionsByKey
metadata
Classifier must specify predictedFeatureName and/or predictedProbabilitiesName
Regressor must specify predictedFeatureName.
Unable to extract configurations from a multi-array feature type without enumerated shapes.
Unable to extract configurations from an image feature type without enumerated shapes.
Unable to extract configurations from a feature that is not a multi-array or image.
We don't currently use configurations if there are multiple inputs with enumerated shapes.
Bad neural network input.
Attempting to extract shape from non-image or multi-array feature
Invalid multi-array constraint found when extracting configurations.
Multi-array of shape less than 1 found when extracting configurations.
Failed to get shape from the tensor description. E5RT: %s (%d)
Failed to get strides from the tensor description. E5RT: %s (%d)
Failed to get data type of the tensor. E5RT: %s (%d)
Failed to get component size. E5RT: %s (%d)
Failed to get component data type. E5RT: %s (%d)
E5 tensor with componentSize = %d and componentDataType = %d is not supported.
MultiArray %@-d shape is not allowed, expected %@-d
Size (%@) of dimension (%@) is not in allowed range (%@..%@)
MultiArray shape (%@) does not match the shape (%@) specified in the model description
MultiArray Shape (%@) was not in enumerated set of allowed shapes
sizeRangeForDimension
type
shapeSet
Interface type is not an ItemSimilarityRecommender
Could not construct item similarity recommender: %s
Internal error: model too large to be compiled.
Internal Error: item index out of bounds.
Input sequence of items for item similarity recommender must be strings or integers.
Input sequence of items for item similarity recommender with string item ids must be strings.
Input sequence of items for item similarity recommender with integer item ids must be integers.
String items require string item ids to be be set.
Input sequence of items for item similarity recommender must be integers or strings.
Input items for item similarity recommender must be a dictionary or a sequence.
Input restriction list of items for item similarity recommender must be a sequence.
Input exclusion list of items for item similarity recommender must be a sequence.
Cannot extract data for image feature: %@
Cannot transform the %@ feature value to one hot encoded format.
Failed to convert planar8 to planarF: Code=%@
Failed to convert ARGB8888 to PlanarF: Code=%@
<MLE5IOPort: %p> %@
Error: Attempted multiple write-open of data blob 
.DAT
Error: setObject is not supported by _OArchiveDiskImpl
Error: Archive doesn't exist at path: 
Error: Invalid path: 
Error: Failed to open writable stream at path: 
non-directory file already exists at archive path
existing archive path is not a writable directory
error creating directory: %@
%lld.%lld.%lld
%@%@
Error opening file stream: 
 already opened as stream attempted to open as mmapped file.
v24@?0^v8Q16
Failed to set parameter value because of nil key
Parameter value type %@ does not conform with default value's type %@
%@ is not a valid value given constraint %@ for key %@
currentParameterValues
parameterKeys
parameterDescriptions
currentParameterValues: %@
parameterKeys: %@
parameterDescriptions: %@
MLKeyName
MLKeyScope
task: %p, 
model: %p, 
event: %@, 
metrics: %@, 
parameters: %@
success
error
Result
profile_number
debug_fatpack
engine_version
Unrecognized profile number 
class labels not set.
SVM has invalid number of support vectors or clases
engineName
Error creating Core ML custom layer implementation from factory for layer "
Core ML custom Layer implementation '
' does not conform to the MLCustomLayer protocol
Error getting Core ML custom layer output shapes for layer "
Evaluation on Core ML custom layer "
" called before the layer is constructed.
Error evaluating Core ML custom layer "
" on CPU.
_internal_NDMode
' does not conform to the MLCustomLayer protocol'
Error initializing Core ML custom layer implementation with parameter dictionary for layer "
Error setting weights in Core ML custom layer "
" on GPU.
PersistentKeyStorage_v2
com.apple.coreml.PersistentKeyStore
keyBlob is nil
keyIdentifier is nil
%@.bin
Failed to persist Key Blob
Feature '%@' not provided.
Feature type %@ cannot be vectorized
Failed to vectorize %@ (%p)
Internal programming error.
Incorrect 'doubleVector' length of %@ (expected %@)
Interface type is not an TreeEnsembleRegressor
Could not construct tree ensemble compiler.
Dimension must equal one when using scalarRegress.
32RGBA
32BGRA
32ARGB
OneComponent8
OneComponent16Half
24RGB
24BGRA
Unsupported (%@)
32BGRA or 32ARGB
Image constraint can not accept missing values.
Image is not expected type %@, instead is %@
Image constraint doesn't have size constraint
%@, %@ x %@
Color
pixelType
sizeConstraint
model.mlmodel
%@ does not exist
%@ is not a file: URL
failed to obtain NSURLCanonicalPathKey for %@
NSURLCanonicalPathKey not available for %@
(Loaded)
(Failed Load)
(Not loaded)
Model is not a classifier.
MLModelAsset: classifierWithError: load failed.
Model is not a regressor.
B24@?0@"NSURL"8@"NSError"16
.espresso.net
Failed to check cached ANE binary: argument result must not be nil
Failed to check cached ANE binary because espresso_ane_cache_has_network returned status=%d for network at %@.
Failed to purge cached ANE binary because espresso_ane_cache_purge_network returned status=%d for network at %@
Error reading protobuf spec. %s
%@ : %@
Dictionary keys must be NSStrings or NSNumbers.
Object not consistent with type supplied
Attempting to hash an MLFeatureValue that is not an image or multi array.
undefined
width
height
format
rowBytes
Failed to lock CVPixelBuffer's base address for serialization.
attributes
transposeA
transposeB
learning_rate_0
The program argument to MLProgramTrainer is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
The program has no train function.
Failed to add lr to training data.
.inferenceModel property is not implemented yet. See rdar://81339842.
The trainable weights should be Float32, but it is %@.
The copyCurrentTrainingDelta failed to extract initial weights.
IllegalOperation
InternalError
MLModel does not conform to MLWritable
ProgramLayerTranslator | No main function found.
ProgramLayerTranslator | Function is not written exclusively in MIL<
Can't find op 
 in source opset 
Can't find op with the same typename "
" in destination opset 
_MLVNScenePrintCustomModel
MLScenePrintRequestRevision
MLScenePrintConfiguration
ScenePrint not available on this version
Must only have one input image feature
Must only have one output multiarray feature
Must allow %lu-element vector as output
Input image feature '%@' not found
CodedObject
_MLNLPWordTaggingModel
Must only have three sequence output features
initialization of sequence model with model data failed
unknown direction=
invalid offset=
, dir=
Error initializing model.
Loss layer type not recognized.
Error initializing loss layer %s.
Error initializing training variables.
Optimizer type not recognized.
Error initializing optimizer.
Invalid value for computeUnits in model configuration.
Error initializing espresso task.
Error in initalizing container.
None
ImageBuffer
Cannot get current weights or biases for layer %@.
Failed to set weights or biases for layer name: %@
B32@?0Q8@"<ETDataProvider>"16@"<ETTaskContext>"24
Cannot get current learning rate.
Failed to copy original model files to the new destionation: %@
Failed to save model to %@. This issue may occur when saving a dense layer that does not contain a bias, if this is the case please file a bug report.
Failed to save model to %@.
Failed to copy updated model to %@
model_updatable.espresso.net
model_updatable.espresso.weights
model_updatable.espresso.shape
Updated neural network model does not have a parameter for requested key %@.
Updatable neural network failed to retrive parameter for layer %@.
/System/Library/Frameworks/Vision.framework/Vision
VNScenePrintsFromPixelBuffers
VNScenePrintsFromPixelBuffersUsesCPUOnly
VNElementCountForScenePrintRequestRevision
VNLengthInBytesForScenePrintRequestRevision
VNImageBuffer
VNDetectionPrintsFromPixelBuffers
VNDetectionPrintsFromPixelBuffersUsesCPUOnly
VNDetectionPrintShapes
VNDetectionPrintSupportedRevisions
VNImageOptionImageOrientation
Failed to form pixel buffer from %@
Failed to form pixel buffer from CGImage
/System/Library/
com.apple.app-sandbox.read
nil value for URL
com.apple.CoreMLModelSecurityService
v24@?0@"MLSecureModel"8@"NSError"16
com.apple.CoreMLModelSecutiyServiceToClient.%lu
v24@?0@"MLDictionaryFeatureProvider"8@"NSError"16
v24@?0@"MLArrayDictionaryFeatureProvider"8@"NSError"16
v24@?0@8@"NSError"16
congfiguration
modelDescription
cryptoKey
Interface type is not an TreeEnsembleClassifier
Could not construct tree ensemble regressor.
.mlmodelc
.xgboost
Cannot initialize Tree Ensemble Classifier model which contains a trained model.
INTERNAL ERROR -- feature not present that should have been.
Incorrect number of classes given (TreeEnsembleClassifier).
_MLSNVGGishFeatureEmbedding
_SNVGGishFeatureEmbeddingCustomModel
Framework not available on this version
Feature embedding not available on this version
Frontend processing does not conform to custom model protocol
Feature embedding failed to init
URL is not a file:// URL: %@
Invalid URL for .mlmodel.
Unable to load model: %@. Compile the model with Xcode or `MLModel.compileModel(at:)`. 
Updating encrypted model %@ is not supported.
Model at %@ is not in the expected format
Failed to open model at %@
Failed to unarchive model at %@
IO Error loading model from compiled model archive: %s
Unable to load model
Loading class must conform to serializable protocols
Selected model loader does not support updatable models.
com.apple.
Unable to extract model type from stream in compiled model: %s
No known class for loading model type %@
Unknown Failure
isOrderedBgr
isGrayScale
blueBias
greenBias
redBias
grayBias
layers
encoder_bidirectional_mode
bottom
Error in parsing network information from compiled model path %@.
.espresso.shape
model_updatable.params
transform_params
layer_shapes
_rank
Error in reading in-memory network.
Error in unarchiving updatable params.
unordered_map::at: key not found
The program (%@) has no init function, which means all the functions are stateless. Do not try to create a context on such a program.
_updated
B32@?0@"NSString"8Q16^B24
The provided input(s): [%@] does not exist in the %@ function.
The provided input(s) missing argument(s): [%@] for the %@ function.
Duplicate image preprocessing directive for feature '%s'.
There are no inputs that are of type image, but still 'scale_image' op for preprocessing has been provided.
Unable to map image preprocessing feature name to any given image input name.
startValue
endValue
stepSizeValue
Step size in the range layer cannot be 0
withBase2
signed_key_request
raw_request
Expected feature of type %@ but got %@
Feature description does not allow missing %@ values
%@ : Dictionary (%@)%@
%@ : Image (%@)%@
%@ : MultiArray (%@)%@
%@ : Sequence (%@)%@
%@ : %@%@
optional
constraints
kVPoints
kVPointsL2Squared
kNumDataPoints
invalid queryPoint.size()=
Unexpected dimensionality of update data
Training data is empty
modelNames
.model%lluv%@
Failed to evaluate model %@ in pipeline
Failed to carry forward results for model %@ in pipeline
Pipeline Model contains multiple models that have parameter for requested key %@. Use parameter scoping to disambiguate.
Pipeline Model does not contain a model that has a parameter for requested key %@.
Model specification does not contain an ML Program.
ML Program does not contain a function named main.
ML Program main function is not written in an opset that is supported by CoreML compiler.
Unknown class type.
Op "classify" can only be defined once per ML program.
Op "classify" is only valid when defined inside a function level block.
while_loop
Mismatch between rank of input/output tensors and the length of axes.
Invalid axes argument
Invalid input shape
Invalid shape of first argument.
Invalid shape of second argument.
Invalid rank of output.
Invalid rank of output
Incompatible shapes for matrix multiplication.
Mismatch between ranks of input and output tensors.
Invalid value of the argument 'axis'.
Invalid ranks of input tensors.
Invalid shape of input tensors.
BroadcastTo layer: Invalid target shape.
BroadcastTo layer: Invalid shapes for broadcasting.
Gather layer: Invalid rank of Output.
Gather layer: Invalid value of the argument 'axis'.
Gather layer: Invalid indices.
Gather tree layer: Parent out of bound.
StackND layer: Invalid shapes of input tensors.
StackND layer: Invalid rank of output tensor.
StackND layer: Invalid value of the argument 'axis'.
Split layer: Invalid number or size of splits.
SliceND layer: Mismatch between the input rank and the number of elements in begin_ids.
SliceND layer: Mismatch between the input rank and the number of elements in end_ids.
SliceND layer: Mismatch between the input rank and the number of elements in begin_masks.
SliceND layer: Mismatch between the input rank and the number of elements in end_masks.
SliceND layer: Mismatch between the input rank and the number of elements in strides.
SliceND layer: Invalid values in begin_ids.
SliceND layer: Invalid values in end_ids.
SliceND layer: Invalid values in strides.
SliceND layer: Invalid values in arguments (begin_ids, end_ids, strides)
Tile layer: Mismatch between input rank and the number of elements in multiples.
Tile layer: Invalid values in multiples.
Sliding Windows Layer: Mismatch between ranks of input and output tensors.
Sliding Windows Layer: Window size can't be less than 1
Sliding Windows Layer: Step can't be less than 1
Sliding Windows Layer: Invalid value of the argument 'axis'.
Sliding Windows Layer: Window Size can't be larger than the dimension length.
Sliding Windows Layer: Invalid values in arguments (axis, window_size, step)
Input feature length mismatch. Got features of length %d expected length of at least %d
Input feature length mismatch. Got features of length %d expected length of %d
Input feature length mismatch. Got features of length %d expected length %@
strides must be 
 elements for shape
Shape must have at least one element
_MLSNVGGishFrontendProcessing
_SNVGGishFrontEndProcessingCustomModel
Frontend processing not available on this version
Frontend processing failed to init
_SNSoundPrintAFeatureEmbeddingCustomModel
parameters == nil.
Not conforming custom model protocol.
Audio feature extractor failed to init
Model type is not an audio feature print
Audio feature print not available on this OS version
Must only have one input multiarray feature
Audio feature print type not set
targetShape
action
GKDecisionTree->CoreML
attribute
children
branch
branchValue
model.pb
attributes.gk
model.mlmodelc
@"NSDictionary"8@?0
fileURL is nil
Input file too large to hash
Failed to hash the input file.
Failed to hash the input file: %s
SliceND layer: mismatch between rank of the input and the length of 'begin ids' parameter
begin_ids
begin_masks
end_ids
end_masks
Number of elements along each dimension needs to be positive.
Mismatch between lengths of shape and strides.
Invalid multi_index.
Invalid rank encountered while converting Espresso Shapes to N-dimensional shape.
Invalid Shapes encountered while converting objective C NSArray shape to std:vector shape
Invalid shapes for broadcasting
values
com.apple.coreml.DecrptSessionManager
Operation not supported on this platform.
_MLSNSoundPrint
Framework not available on this version.
Sound Print not available on this version.
Sound print model does not conform to custom model protocol.
Sound print failed to init.
neural_network_optionals
Direct
BufferCopy
MLE5DirectMode has invalid value: %d
IOSurface-backed MultiArray
Memory-backed MultiArray
IOSurface-backed PixelBuffer
Memory-backed PixelBuffer
e5rt_io_port_is_tensor failed. E5RT: %s (%d)
e5rt_io_port_is_surface failed. E5RT: %s (%d)
The combination of port trait %@ and feature trait %@ is not supported.
The combination of port trait %@, feature trait %@, and direct bind mode %@ is not supported.
MultiArray shape %@ doesn't match the port's expected shape %@.
Failed to get width from E5 surface descriptor. E5RT: %s (%d)
Pixel buffer frame size %zu x %zu doesn't match the port's expected image size %zu x %zu.
Failed to get number of planes from E5 surface descriptor. E5RT: %s (%d)
The inference engine expects multi-planer format (plane count = %zu). CoreML doesn't support such models yet.
Failed to get buffer object's base pointer. E5RT: %s (%d)
Failed to create MLMultiArray: %@.
Failed to bind the input feature value.ESRT: %s (%d)
The port trait %@ is not supported.
The combination of port trait %@ and feature type %@ is not supported.
The combination of port trait %@, feature type %@, and direct bind mode %@ is not supported.
Failed to bind the output buffer object.ESRT: %s (%d)
Failed to bind the output surface object.ESRT: %s (%d)
MLE5Engine doesn't support MLImagePixelType %tu yet.
Failed to get E5 tensor descriptor. E5RT: %s (%d)
The port's shape is %@, which doesn't have enough dimensions to map width and height.
Failed to get E5 surface descriptor. E5RT: %s (%d)
Failed to allocate E5 buffer object. E5RT: %s (%d)
Failed to create E5 buffer object from IOSurface. E5RT: %s (%d)
Failed to create E5 surface object from surface descriptor. E5RT: %s (%d)
com.apple.coreml.MLE5Engine.outputPortBinder
Explicit output backing is not implemented yet for the E5 engine
compiler error: 
mlmodelc
%@ Error reading protobuf spec. %s
1404
9999.0.1
enc_%@
SC_Info
%@.sinf
%@.mlsinf
Key ID has to be specified while encrypting model.
Specified Key ID %@ is not in UUID format.
encryptionInfo
%@ No known class for compiling model type %@
%@ Invalid compiling class %@ for model type %@
No known class for compiling model type %@
Invalid compiling class %@ for model type %@
model%d
MLModelType_pipelineClassifier
MLModelType_pipelineRegressor
MLModelType_pipeline
MLModelType_glmRegressor
MLModelType_supportVectorRegressor
MLModelType_treeEnsembleRegressor
MLModelType_neuralNetworkRegressor
MLModelType_bayesianProbitRegressor
MLModelType_glmClassifier
MLModelType_supportVectorClassifier
MLModelType_treeEnsembleClassifier
MLModelType_neuralNetworkClassifier
MLModelType_kNearestNeighborsClassifier
MLModelType_neuralNetwork
MLModelType_itemSimilarityRecommender
MLModelType_mlProgram
MLModelType_customModel
MLModelType_linkedModel
MLModelType_oneHotEncoder
MLModelType_imputer
MLModelType_featureVectorizer
MLModelType_dictVectorizer
MLModelType_scaler
MLModelType_categoricalMapping
MLModelType_normalizer
MLModelType_arrayFeatureExtractor
MLModelType_nonMaximumSuppression
MLModelType_identity
MLModelType_textClassifier
MLModelType_wordTagger
MLModelType_visionFeaturePrint
MLModelType_soundAnalysisPreprocessing
MLModelType_gazetteer
MLModelType_wordEmbedding
MLModelType_audioFeaturePrint
MLModelType_serializedModel
Failed to add a ML Program to the compiled model: 
model0
Cannot add ML Program to this model because it is not eligible.
Found errors while adding ML Programs to sub-models in the pipeline:
     %@ : %@
Specialization 
 already exists.
URL has nil fileSystemRepresentation
model does not implement protocol MLModelSpecificationSaver
Unable to extract model type from stream in compiled model: %@
0.0.0
Serializing model to compiled format is not yet supported.  Try with compilerOptions=nil
Failed to create a working directory URL
Failed to copy model from %@ to %@
Failed to replace model from %@ to %@
Cannot determine predictedFeatureName for this classifier
Invalid classifier: predicted feature '%@' is not described as int or string
Invalid classifier: predicted probs '%@' is not described as dictionary
Predicted probabilities '%@' is of type %@ not the expected %@
/private/var/mobile/Library/Trial
/System/Library/AssetsV2/
/private/var/MobileAsset/AssetsV2
coreml
com.apple.private.coreml.tracing-allowed
/Library/Trial
com.apple.coreml
sparse features not yet supported
an error occurred when trying to create specification for BayesianProbitRegression
Training Begin
Epoch End
Mini Batch End
Training End
interestedEvents: ()
interestedEvents: %@
Supplied
Not Supplied
progressHandler: %@
completionHandler: %@
<%@: %p, id: %@>
The input feature provider cannot be nil.
Unable to classify the input because the model description doesn't have predictedFeatureName property.
Unable to classify the input because the model description doesn't have class labels.
There must be at least one class to return.
MLMultiArray for class probabilities must be Float64 or Float32.
There is no output feature named %@.
Output feature named %@ is supposed to be a MLMultiArray representing class probabilities but it is %@.
Class probability feature named %@ has %tu classes, but there are %zd class labels.
Class probability feature named %@ must be a MLMultiArray of Float32 or Float64.
Class probability feature named %@ must be a contiguous MLMultiArray.
Unable to regress the input because the model description doesn't have predictedFeatureName property.
The predicted feature value for the regressor model must be a multi array but it was %@. This error should have been caught by the validator.
lossValue
epochIndex
miniBatchIndex
Missing predictionFromFeatures:error implementation
modelDescription: %@, 
configuration: %@
Model does not have a parameter for requested key %@.
Initialization of sceneprint parameters failed
Initialization of image feature extractor parameters failed
Invalid parameters for vision feature print
Model type is not a vision feature print
Vision framework not available for scene print on this OS version
Vision framework not available for object print on this OS version
ObjectPrint unable to get expected shapes
Output count %lu does not match expected %lu from object print
Output count %lu does not match expected %lu in the request revision %lu
Output name %@ not found in the outputs specified in object print
Output %@ is not a MultiArray
Must allow (%@, %@, %@) vector for output feature %@
Feature extractor type not set
v16@?0^v8
Expected feature '%@' of type 'image' was not present in input
Vision framework for scene print not available on this OS version
Vision framework for object print not available on this OS version
q24@?0@"NSArray"8@"NSArray"16
Error empty specificationURL: %@
Error replacing MLProgram with in-memory MLProgram : %@
Error loading program as in-memory program: 
@model_path
UnSupported DataType
com.apple.CoreML
Error in initalizing the classifier.
Invalid objective and/or numClasses.
Error in initalizing labels.
Cannot load the trained model.
Prediction failed since the tree was not trained with any data point.
Prediction failed since data could not be transformed properly.
Prediction failed.
Shape of training data point %i MLMultiArray is %@, expected %@
Input data other than MLFeatureTypeMultiArray is not supported for training.
Missing input name for Tree Ensemble Classifier.
Received nil MLFeatureProvider for index %ld from training data MLBatchProvider for training input: %@
Shape of training data point %li MLMultiArray is %@, expected %@
Failed to convert training data to the right format.
Data provided in input is missing feature value for training input: %@
Label must be of type MLFeatureTypeString or MLFeatureTypeInt64
Label %@ not found for data index: %ld.
Cannot create MLBatchProvider.
Cannot create MLFeatureProvider.
binary:logistic
multi:softprob
Current objective not supported. Supported objectives are multi:softprob and binary:logistic.
Data processing failed.
numClasses parameter must be provided.
objective parameter must be provided.
Objective and number of classes does not match. numClasses for 'binary:logistic' must be defined as 1.
XGBoosterPredict
XGBoosterLoadModel
XGBoosterFree
regress:error must be implemented by derived class!
UpdatableNeuralNetworkMLComputeBackend doesn't support in-memory compilation.
Failed to archive update parameters.
Failed to archive entire spec.
entireSpec
Data provided has unsupported shape (%@)
Failed to extract output tensor
Output is not in the expected format
com.apple.CoreML.MLLoader
com.apple.CoreML.MLPrediction
com.apple.CoreML.MLCompiler
modelType
modelVersion
compilerVersion
modelCompiledWithVersion
modelLoadTime
modelOrigin
modelHash
modelDimension
nnModelNetHash
nnModelShapeHash
nnModelWeightsHash
modelLoadError
bundleIdentifier
firstPartyExecutable
modelIsEncrypted
modelProgramValidationError
modelProgramParsingError
milUpgradeStatus
milUpgradeFailureReason
featuresPredictionDuration
featuresPredictionCountSoFar
com.apple.createml.version
com.apple.createml.app.version
com.github.apple.turicreate.version
com.apple.developer.machine-learning.models.version
com.github.apple.coremltools.source
keras
tensorflow
onnx
torch
scikit-learn
xgboost
libsvm
com.apple.da
AutomatedDeviceGroup
COREML_AUTOMATED_TESTS
Failed to unarchive update parameters. Model should be re-compiled.
Failed to unarchive update parameters.
Inconsistent value types in array
Cannot form description from nothing
Inconsistent value constraints in array
Image found with unsupported pixel type
.values
MultiArray
Dictionary
Image
Sequence
UnknownValue
Illegal value in MLFeatureType enum
v32@?0@"NSNumber"8Q16^B24
$BUNDLE_MAIN
$BUNDLE_IDENTIFIER
%@ is missing feature '%@'
%@ feature '%@' is inconsistent with '%@'
Model type is not linked model as expected
Model linking could not find model (%@) in search path (%@) relative to (%@)
Linked model
Root/Loaded model
Linked Model does not have a parameter for requested key %@.
@min.doubleValue
@max.doubleValue
minNumber
maxNumber
enumeratedNumbers
minValue: %@
maxValue: %@
enumeratedNumbers: %@
com.apple.coreml.modelkeystore
mks-production
fetchKey2
Fetching decryption key from server failed.
Fetching decryption key from server failed: %s. Make sure the encryption key was generated with correct team ID.
Fetching decryption key from server failed: response with neither hasError nor hasSuccess.
v24@?0@"ModelKeyServerAPIFetchKeyResponse"8@"NSError"16
Fetching decryption key from server timed out. Make sure the device is online.
Model output names must not be duplicated.
Unknown class label type.
Input image has invalid colorspace.
A model for tagging words constructed in memory
labels
Output labels
locations
Output locations
lengths
Output lengths
modelData
A model for classifying sentences constructed in memory
Input sentence
Output label
kMLLayerComputeUnitHintFallbackFromGPU
kMLLayerComputeUnitHintFallbackFromNE
kMLLayerComputeUnitHintFallbackFromCPU
hint_fallback_from_metal
hint_fallback_from_cpu
hint_fallback_from_ane
'model.espresso.net' file not found at the given compiled model path: %@.
Unable to load information from compiled model path %@.
Compiled model path: '%@', must be a directory.
Compiled model path: '%@', must be a writable directory.
.bckp
Unable to create backup of .net file at compiled model directory, with error: %@
Failed to serialize new .net data after updating schedule hints, underlying error message: %@
Execution Profile not recognized.
ERROR: profile=
; idx=
; ref_value=
; pred=
Validation failure loading ML tree model; possibly corrupt image.
ML Program does not have a function named main.
MLModel Specification does not declare a classifier, but the ML program does declare one.
MLModel Specification and ML program classifier predicted feature name do not match.
MLModel Specification and ML program classifier predicted probabilities name do not match.
MLModel Specification declares a classifier, but the ML program does not contain a 'classify' op.
parameters
Model and main function must have same number of inputs.
ML Program is missing MLModel Specification input 
Neural Networks require 
 to be images or MLMultiArray.
Model 
' is not a supported data type. Only int32, float32, or float16 data types are supported for MLMultiArray 
s to ML Program models.
parameter
return value
Unexpected 
 type.
' is not a tensor.
' has a different type than its corresponding 
 to main.
' has a different rank than its corresponding 
' has a different shape than its corresponding 
main 
' must be a tensor of type Float32 or Float16
Model image 
' has empty height or width.
' is not a dictionary.
' has invalid key type.
return values
Model and main function must have same number of outputs.
MLModel Specification output 
 does not have the same name as the ML program output at the same index.
Version
KeyIdentifier
UsesCodeSigningIdentityForEncryption
SINF
AAADgHNpbmYAAAAMZnJtYQAAAAAAAAAUc2NobQAAAABpdHVuAAAAAAAAA1hzY2hpAAAADHVzZXIAAAAAAAAADGtleSAAAAABAAAAGGl2aXbZofvYoEHG+Bnh6TFdS4nRAAAAWHJpZ2hwbGF0AAAAAnRyYW7aSnJxdG9vbEQ5OTltZWRpAAAAgG1vZGUAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQhuYW1lAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcBwcml2dHT7EFcJPPVjnUp9b53GcsqIfPZ2Zwq2GeQ3aigPDGVuD0OGm6NZEzuiK3dNectFh1Z5LE06hTFwi67WA/4z+7xXmX0aMBmYfYmL9dVVxwOKwJ1bpkkZkXyil21zxsKwHVn6ZSgegaKm9C5YQcyL/uY9aqYkLS2+qKVWyx/3pBVY1cAAPyNpVDBsNIpNGguNmEEA4l7IhB8Q+m1VAPCcxgngaFT6ztBjdUfseVYj3fh28t7NXhdQbZB7PNDxU2VToqvN2t1f6Gco/qc8fRXXGo12pLH346qDQezYMlbBS0w76GtyWoK+oLu3FTMjjCi7Kg1SyDDBbbDsg0RVMkyHhZ3TOFmwJklAYL7HxsWa+rCRM4Q4YOJobScLgeZ/7daGTAeX03OMT/iWgPHf+ejCVQGje+Mm+a8P5UzKpHhV9ruwF2usDUoynhmyIYr/EnrcUyQdPjLX8wG7BYMJMhh/vuaIfkwVt1M2kgFJ9T8Kz+JczEJSfLIwhW6Uy+ltyRrVnlaGfoPdrohv4P4FgaBuaUFSoKiXMuZr4IXhEHh9sCoAv6sSDIAFURgBX1wtn9HWAAAAAAAAAAA=
saveToFile URL (%@) should be different from fileURL (%@)
Error creating file %s
Error saving ENML header to %s
Error saving data to %s
Key length %lu does not match encryption block size %u
IV is specified but it's length %lu does not match encryption block size %u
Failed to encrypt data
Encryption outputSize does not match outputWritten
dictionary
Pipeline is not marked as updatable to perform update.
Updatable model index is out of range.
model
Failed to load updatable sub-model at %lu
Failed to carry forward results for model %llu in pipeline
model%llu
%@/%@
MIL program input, '%s', not found in Core ML model inputs
Core ML model input, '%@', not found in MIL main program's inputs
Error in reading the MIL network.
Error in reading the in-memory MIL network.
CompiledObject
_MLVNDetectionPrintCustomModel
MLDetectionPrintRequestRevision
MLDetectionPrintConfiguration
DetectionPrint not available on this version
DetectionPrint unable to get supported revisions
Must only have one input feature of image type
DetectionPrint unable to get expected shapes
Output feature %@ not expected
Failed to compute detection print
size
step
lossType
optimizerType
optimizerParameters
lossParameters
trainableLayerNames
Error in archiving updatable params.
MLNeuralNetworksCompileTimeParams
message
Initialization of Text classifier parameters failed
Model type is not a Word tagger
Invalid parameters for Text Classifier
initialization of text classifier model with model data failed
Text label
This model is a text classifier (version %lu) which classifies %@ text according to set {
This model is a text classifier (version %lu) which classifies text according to set {
This PipelineClassifier was created with unreleased beta CoreML and is no longer supported. Please re-create/convert your model with the the current Core ML
Invalid model type found in compiled pipeline model.
The program argument to MLProgramEvaluator is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
.model property is not implemented yet. See rdar://86160890.
Ios16TrainBackend doesn't support in-memory compilation.
Cannot find main function in translated program.
model_train.mil
Cannot generate training program.
Cannot save training program.
kLeafSize
kVData
kVIndices
kRoot
splitIndex
splitDimension
splitValue
startingIndex
count
rightChild
leftChild
intervals
isLeaf
Splitting node along dimension %lu, by value %.4f
Found split index %lu
dataPoints.size() % dimensionality != 0
invalid point.size()=
invalid k=
A Core ML custom neural network layer requires an implementation named '
' which was not found in the global namespace.
A custom neural network layer implementation class named '
' does not conform to the MLCustomLayer protocol.
Model type is not a NonMaximumSuppression
Data type error for NonMaximumSuppression: confidence and coordinates must be MLMultiArray of a same type and it must be either DOUBLE or FLOAT32. However, confidence uses %@ and coordinates uses %@
Dimension 1 of input confidence (%@) is not consistent with the number of classes (%lu)
Batch produced nil feature provider for index %@
Failed to obtain prediction for sample %@
Error: getObject is not supported by _OArchiveDiskImpl
Failed to open file: 
. It is not a valid .mlmodelc file. 
Failed to read first word from 
 is not a valid .mlmodelc file because the first word (
) is not recognizable. 
coremldata.bin
Failed to create a stream. E5RT: %s (%d)
Failed to add operation to E5 stream. E5RT: %s (%d)
Failed to execute E5 stream.ESRT: %s (%d)
Failed to reset the stream. E5RT: %s (%d)
Invalid NeuralNetwork Specification type
com.apple.coreml.mlupdatetask_update_queue
kUpdateParametersKey
Model is no longer valid outside update callback
v16@?0@"MLUpdateContext"8
updatableModelURL: %@
trainingData: %@  count: %zd
progressHandlers: %@
state: %@
/System/Library/Frameworks/NaturalLanguage.framework/NaturalLanguage
NLPSequenceModelCopyPredictedTokensAndLabelsForText
NLPSequenceModelCreateWithData
NLPSequenceModelGetRevision
NLPSequenceModelIsRevisionSupported
NLPSequenceModelGetCurrentRevision
NLPClassifierModelCopyPredictedLabelForText
NLPClassifierModelCreateWithData
NLPClassifierModelGetRevision
NLPClassifierModelIsRevisionSupported
NLPClassifierModelGetCurrentRevision
NLPGazetteerModelCopyLabelForString
NLPGazetteerModelCreateWithData
NLPGazetteerModelGetRevision
NLPGazetteerModelIsRevisionSupported
NLPGazetteerModelGetCurrentRevision
NLPEmbeddingModelCopyVectorForString
NLPEmbeddingModelCreateWithData
NLPEmbeddingModelGetRevision
NLPEmbeddingModelIsRevisionSupported
NLPEmbeddingModelGetCurrentRevision
Model revision %ld not supported by NaturalLanguage framwork on this OS version (support revision %ld).
v16@?0@"NSError"8
v24@?0@"NSString"8@"NSError"16
MPSGraph
MPSGraphFP16
features.%@
Error reading from archive.
Error writing to archive.
com.apple.CoreML.MLPredictionEvent
MLAutomaticOutputBackingModeEnabled
MLAutomaticOutputBackingModeDisabled
MLAutomaticOutputBackingModeForced
usesCPUOnly
classifyTopK
maxComputationBatchSize
parentSignpostID
Initialization of word tagger parameters failed
Model type is not a word tagger
Invalid parameters for Word Tagger
initialization of word tagger model with model data failed
Input text
Token tags
Token lengths
Token locations
Tokens
This model is a word tagger (version %lu) which tags %@ words according to set {
This model is a word tagger (version %lu) which tags words according to set {
Feature '%@' is not provided
Cannot merge batch of size %@ with batch of size %@
Invalid window starting at %@ of length %@ for batch size %@
Expected to vectorize into matrix, but was passed a %@ multiarray
Row count of matrix (%@) does not match batch size (%@)
data
Interface type is not an Support Vector Classifier
Failed to prepare E5 execution stream operation for encode.ESRT: %s (%d)
The operation was never prepared or has been reset
Failed to build output feature provider with error %@.
Failed to create E5 execution stream operation. The library path was %s and the function name was %s.ESRT: %s (%d)
Failed to retain E5 execution stream operation input port %@ E5RT: %s (%d)
The input feature provider doesn't have a feature %@ or it is undefined.
Failed to get the number of inputs for operation. E5RT: %s (%d)
Failed to get input port names for operation. E5RT: %s (%d)
Failed to get the number of outputs for operation E5RT: %s (%d)
Failed to get output port names for operation. E5RT: %s (%d)
CoreMLInference: %@ (%@)
Sound analysis preprocessing does not conform to custom model protocol
Sound analysis preprocessing failed to init
Model type is not a sound analysis preprocessing
Sound analysis framework not available on this OS version
Sound analysis preprocessing not available on this version
Preprocessing type not set
file does not contain encrypted model header
unrecognized magic word in the encrypted model header
unsupported major version = 
file does not contain any payload, sizeOfHeader = 
illegal value for original file size = 
illegal value for number of encrypted pages = 
illegal number of encrypted pages = 
failed to invoke mremap_encrypted with result = 
, error = 
Only integer values with magnitude less than 2^48 are supported in the imputer.
imputer
MLimputer
imputed feature value not set.
MLImputer Input
MLImputer Output
Invalid combination of replace value type and input/output/feature value types.
Could not determine minimum sequence length to construct the model.
Could not convert neural network model layers.
Could not build inference network.
allowSoftmaxApproximation
Unable to create IR context.
Failed to process net for upgrade.
Failed to read model from disk.
Inappropriate model type for upgrade.
Model requires a sequence longer than the maximum.
Error in neural network compiler computing minimum sequence length for the model.
Invalid height and width for the image input.
Input MLMultiArray cannot be %d dimensional (must be between 1 and 5 dimensions).
Neural networks only accept image and array inputs.
Input MLMultiArray cannot be %d dimensional (must have at least 1 dimension).
Error in compiling custom layer model.
Unknown error in compiling network layers.
Error in laying out custom layer model in memory.
Unknown error in building network shapes.
spec
Model does not exist at %@
Failed to read model package at %@. Error: %s
Input feature length mismatch. Got features of length %@ expected length %@
MLSequenceConstraint cannot check undefined values
MLSequenceConstraint only allows MLSequence values
MLSequenceConstraint count constraint does not allow count of %@
MLSequenceConstraint only allows sequence value of type %@. This sequence is type %@
Value at index %d of sequence is not allowed
valueDescription
countRange_len
countRange_loc
Uninitialized
Input, '
' is not of type tensor
' does not have fixed rank
Dimension of the input, '
' consists variadic dimension which is not supported
Rank of the input, '
, but it should be between 1 and 5
, but it should be between 0 and 5
Provided default shape of 
 doesn't match with declared shape in function
No default shape provided for 
 which has unknown dimensions.
Invalid rank: 
Unsupported key type for dictionary feature
Unsupported sequence type
Could not save MLModelDescription to MLModelSpecification
%@: There must be at least %tu features, but there is only %tu.
%@: There must be at most %tu features, but there is %tu.
%@: The feature type must be one of {%@}, but it is %@.
treeRefresh
treeAddition
Error in initalizing model interface.
Error in initalizing update Engine for compiled archive.
Error in initalizing model parameters.
Objective must be either multi:softprob or binary:logistic.
Update type must be either %@ or %@.
label
Cannot create update instance.
numTrees Parameter must be provided and it should be > 1.
Failed to train at iteration number: %lu
learningRate Parameter must be provided.
maxDepth Parameter must be provided.
minChildWeight parameter must be provided.
max_depth
num_class
min_child_weight
objective
process_type
update
updater
refresh
Updated tree ensemble classifier model does not have a parameter for requested key %@.
Cannot save the trained model.
XGDMatrixCreateFromMat
XGDMatrixSetFloatInfo
XGBoosterCreate
XGDMatrixFree
XGBoosterUpdateOneIter
XGBoosterSetParam
XGBoosterSaveModel
Error opening file 
Error reading file statistics of 
File 
: not a regular file.
: error opening mmap: 
name: %@, version: %@ author: %@ description: %@ creatorDefined: %@
feature vectorizer
MLFeatureVectorizer Input
MLFeatureVectorizer Output
Expected value for feature '%@'.
MLFeatureVectorizer: Array length incorrect.
MLFeatureVectorizer: Dictionary key type must be NSNumber.
MLFeatureVectorizer: Dictionary index out of range.
MLFeatureVectorizer: Incorrect Type.
MLFeatureVectorizer: Dict key type must be NSNumber.
MLFeatureVectorizer: Dict idx out of range.
MLFeatureValueImageOptionCropAndScale
MLFeatureValueImageOptionCropRect
{CGRect={CGPoint=dd}{CGSize=dd}}
Functionality unavailable
Operation failed due to missing or zero crop parameters in image constraint.
dict vectorizer
MLDictVectorizer
MLDictVectorizer Inputs
MLDictVectorizer Outputs
Expected input column '%@ not present.
Type of input not dictionary as expected.
Failed to get the temporary directory for the current user.
Failed to create NSURL object for path: %@
Failed to create a working directory appropriate for URL: %@
_%@.mlmodelc
com.apple.runtime-issues
CoreML
analytics
SpecificationDetails
NeuralNetworkModelDetails
PipelineModelDetails
model.espresso.net
model.espresso.shape
model.espresso.weights
model.mil
UpgradeMetadata
main
train
init
forward
Unnamed_Model
normalizer
MLNormalizer
MLNormalizer Input
MLNormalizer Output
Initialization of Word Embedding parameters failed
Model type is not a Word Embedding
Invalid parameters for Word Embedding
initialization of word embedding model with model data failed
Embedding does not contain input string '%@'. %@
Embedding does not contain input string '%@'. 
word
vector
This model is a word embedding (version %lu) which represents an %@ word in a vector space.
This model is a word embedding (version %lu) which represents a word in a vector space.
com.apple.coreml.mltask_work_queue
v8@?0
Task Suspended
Task Running
Task Cancelling
Task Completed
Task Failed
categorical mapping
MLCategoricalMapping Inputs
MLCategoricalMapping Outputs
MLCategoricalMapping: Unknown input value.
Var name 
 shadowed.
scaler
one hot encoder
MLOneHotEncoder
MLOneHotEncoder Inputs
MLOneHotEncoder Outputs
%@: Output description type must be MLTypeDictionary (ouputSparse On) or                       MLFeatureTypeMultiArray (ouputSparse Off) 
MLOneHotEncoder: unknown category %@, expected one of %@
+N9mZUAHooNvMiQnjeTJ8g
restrictNeuralNetworksToUseCPUOnly
restrictNeuralNetworksFromUsingANE
Interface type is not a Bayesian Online Probit Regressor
no features
require feature type of MLMultiArray with one of Int32 values
incorrect number of features: expected %d but got %d
invalid prediction feature type
invalid prediction features
updateModelFromFeatures failed
labels is nil
class probability multiArray must use Float32 or Float64 scalars.
There are %tu class labels but class probability multiArray has only %tu entries.
The probability multiArray must have contiguous first-major layout.
Probability index %tu is out of range because there are only %tu classes.
v24@?0r^v8q16
The number of labels (%tu) is greater than the number of probabilities (%tu).
probabilities is nil.
sharedKeySet must be created with +[MLProbabilityDictionary sharedKeySetForKeys:].
UpdatableNeuralNetworkEspressoNetBackend doesn't support in-memory compilation.
NetworkUpdateParameters
updateParameters
_lossValue
Error in initalizing categorical cross entropy loss layer. This loss layer might be invalid.
Error in initalizing mean squared error loss layer. This loss layer might be invalid.
Current loss layer is not supported.
Current optimizer is not supported.
Error in initializing updatable model.
Error in creating updatable model.
kUpdateLossTargetName
kUpdateLossInputName
kUpdateLossOutputName
Error in initalizing optimizer. The parameters might be invalid..
MultiArray dataType should be %@ but is %@
MultiArrayConstraint cannot check undefined values
MultiArrayConstraint only allows MultiArrays
Neural network model expects vector inputs, but non-unit height or width dimensions were provided.
Neural Network (<=version 3) inputs can only be of size 1, 3, or 5.
According to model description, feature '%@' must be of rank %@, instead got a multi-array value of rank %@.
%@, %@
shapeConstraint
Image width (%@) is not in allowed range (%@..%@)
Image height (%@) is not in allowed range (%@..%@)
Image size %@ not in allowed set of image sizes
imageSizeSet
pixelsWideRange_len
pixelsWideRange_loc
pixelsHighRange_len
pixelsHighRange_loc
array feature extractor
arrayFeatureExtractor
MLArrayFeatureExtractor Inputs
MLArrayFeatureExtractor Outputs
got nil array input to MLArrayFeatureExtractor predict:error:
Lossy cast to integer by ArrayFeatureExtractor; use double as output type.
Invalid output type of ArrayFeatureExtractor.
CoreML Background Watchdog Queue
': output blob channel dimension size is 0.
': output blob height dimension size is 0.
': output blob width dimension size is 0.
Scatter layer: '
_leaky_relu
numerator
denominator
_numerator_reduce_mean_
reduce_mean
_temp
temp
_denominator_reduce_l2_
reduce_l2
square_of_denominator
_denominator_
numerator_div_denominator
numerator_div_denominator_mul_gamma
_max_loop_iters
_load_iterator
cf_loop
_loop_start
_loop_cond_check
_loop_count_check
_loop_joint_condition
_increment_iterator
_jump
_end_loop_if
_end_loop
tensor_zero_pad
Dot product layer: '
Split layer: '
' , number of outputs = 
 do not divide the input dimension = 
Split layer :
 , number of outputs (
) do not match the parameter nOutputs (
outputChannels = 
inputDim = 
Embedding layer '
Embedding layer: '
': channel dimension of the input blob must be 1.
fill
_lrn_out
_mul
Average Layer must have exactly 1 output
sum_out
_sum
_sum_
non_maximum_suppression
Mismatched specLayer.slicestatic().*_size values.
A params.* static array would be referenced out of bounds.
batchnorm
Batchnorm layer: 
has insufficient bytes in quantized 
 ,size of 
 must be equal to the number of channels.
 is smaller than the total bytes required for 
The weight blob
 of layer 
 cannot be compiled.
Unsupported Pooling Type: 
Unsupported Padding Type: 
load_random
log_
gumbel_max
Crop layer: 
 , crop border amounts must be specified for both height and width, if set
Crop Layer: 
 , must be provided exactly 2 offset values when it has 2 inputs
Crop Layer: '
': unable to determine the spatial dimensions of the second input blob. 
range
cf_if
cf_else
_else
cf_end
_end
Pooling layer: 
 , if set, kernel size must be of length 2
 , kernel size cannot be 0
 , if set, stride must be of length 2
 , stride cannot be 0
 , for valid padding, padding border amounts must be specified for both height and width, if set
 , for include last pixel padding, padding amounts must be of length 2, if set
Gelu layer: '
activation
PReLU
PReLU Layer: 
 , number of alpha parameters (
) is not equal to the channel dimension (
) of the input
 has insufficent bytes for quantized alpha parameters
params_prelu
ParametricSoftplus
Parametric Softplus: alpha and beta parameters must have the same size
Parametric Softplus layer '
' has invalid alpha/beta size
Parametric Softplus: alpha and beta parameters are not provided
softplus_alphas
softplus_betas
' is unable to infer the size of channels dimension (axis=-3) in the input, which is required when the weight size is 1 or when weights are quantized to lower than equal to 8 bits.
topk
_value
_index_rank_preserved
_squeeze_after_arg
', input channels must be divisible by the number of groups.
', output channels cannot be 0
', input channels cannot be 0
Convolution 3D layer: '
' , if set, output shape must be of length 3
Convolution3D padding type not set
deconv3d
conv3d
' , size of weight parameter not equal to the product of kernel sizes, number of kernels, and kernel channels
' quantized weights are not currently supported
' quantized bias is not currently supported
': argmax reduction operation is only supported along single dimensions C, H or W.
Input
Unrecognizable Neural Network type.
Failed to copy empty or invalid weights to kernel
Unsupported recurrent non-linearity type.
Unable to read 
weight elements.
quantized weight elements from byte stream.
Unrecognizable weight parameter type.
Error converting float16 biases
_tmp_
Invalid network: Layer name missing.
Invalid network: Expected at least one input for layer: '
Invalid network: Expected at least one output for layer: '
Input shapes must be equal for layer: '
Input shapes (height and width dimensions) must be equal for layer: '
Input '
' of layer '
' not found in any of the outputs of the preceeding layers.
Invalid data blob: '
' shape (C,H,W = 
) for output of layer: '
Validate number of inputs and outputs: Unknown layer type
Invalid number of inputs (
) and outputs (
) to layer: '
Layer name: '
'. Input and output data blob names cannot be the same.
Mean image preprocessor input blob ('
') not found. 
_preprocessed
mean_image_
Mean Image Preprocessing: mean image size must be same as input image size.
load_constant_mean_image_
elementwise_add_mean_image_
GRU layer: must provide 2 activations
GRU layer: '
Bias Layer: shape cannot be of size 0
Bias Layer: shape must be of size 1 or 3
constant_in
Bias Layer: bias size does not match provided shape
Bias Layer: Must accept exactly 1 input and produce 1 output
Upsample layer: 
 , Fractional scaling only compatible with align_corners=true or align_corners=false bilinear mode.
 , Only one of scalingFactor and fractionalScalingFactor can be set, and if set, must be of size 2.
Upsample layer: '
': unknown value for parameter 'linearupsamplemode'.
embedding size = 
vocab size = 
 is not equal to size of the product of input dims and output channels = 
EmbeddingND layer '
' has insufficient bytes for 
units in weight
 is not equal to the output dims = 
units in bias
Reorganize Data layer: '
' unknown value for parameter 'mode'.
Reorganize data layer: '
': 'blockSize' must divide height dimension of the input.
': 'blockSize' must divide width dimension of the input.
': 'blockSize' square must divide channel dimension of the input.
 layer: weight size incorrect
 layer : insufficient units in quantized weight byte stream
 layer : all the weight matrices must have same type
 layer: weight matrix size incorrect
 layer : all the weight matrices must have same quantization level
 layer : all quantized weight matrices must have same number of bytes
 layer : all weight matrices must have either linear quantization or LUT
_per_ch_qscale
_per_ch_qbias
_lut_to_float32
 layer: bias size incorrect
 layer: insufficient units in quantized bias byte stream
Reshape Layer: target shape must of length 3 or 4
Reshape layer: '
': product of new shape must equal the product of input blob dimensions.
LSTM layer: must provide 3 activations
LSTM layer: '
MLCustomLayerWrapper
In custom layer 
, parameter key 
 has no value.
brick
MLCustomLayerWeights
matrix_band_part
ScatterND layer: '
Load Constant: shape must be of size 3
Bi dir LSTM layer: must have two weight params
Bi dir LSTM layer (forward lstm): must provide 3 activations
Bi dir LSTM layer (backward lstm): must provide 3 activations
Uni-directional LSTM
W_x_reverse
W_h_reverse
Bi-directional LSTM
b_reverse
p_reverse
BLSTM layer: '
output size = 
input size = 
Recurrent layer: too many output blobs.
Recurrent layer: too few output blobs.
Recurrent layer: too many input blobs.
Recurrent layer: too few input blobs.
_prereverse
sequence_reverse
rnn_arch
Recurrent layer: '
': height dimension of the input blob must be 1.
': width dimension of the input blob must be 1.
_post_scale
_post_scale_shift
_scale
_shift
Lookup table size incorrect.
Unrecognizable quantization parameters
Unrecognizable linear quantization scale parameter length.
Quantization bias should have the same length as scale if it exists
per_ch_qscale
per_ch_qbias
lut_to_float32
cf_jump
_break
_continue
int8 dynamic quantization not valid with >1 input
batch_matmul
 :                            when flag 'int8DynamicQuantize' is set to true, weights must be stored in the int8 format.
 :                           Number of bits must equal 8 when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization must be used when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization scale must be size 1 when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization bias must be empty when flag 'int8DynamicQuantize' is set to true.
 is not equal to size of the product of the first and second dimensions provided as layer parameters = 
 in Batched-MatMul layer 
 is smaller than the total bytes required for the product of the first and second dimensions provided as layer parameters = 
-bit quantization in Batched-MatMul layer 
 is not equal to the second dimension of the matrix = 
Size of quantized bias is insufficient for Batched-MatMul layer 
Rank preserving reshape layer '
': input/output rank greater than 5 not supported currently
__prelog
__squared
__exp
_presqueeze
reduce
__reduction_axis__
squeeze
Load Constant: shape must be of non empty
Load Constant: can only handle rank 1 to 5
Load Constant: data size does not match provided shape
ScatterAlongAxis layer: '
': unknown value for parameter 'mode'.
broadcast
inner_product
number of output channels = 
 not allowed in layer 
number of input channels = 
_dynamic_quantize_
_post_quantization_blob_
_activation_quantization_scale_
_dynamic_dequantize_
_pre_dequantization_blob_
dynamic_quantize
dynamic_dequantize
Layer: 
 does not satisfy int8 quantization requirements.
W_int8
biases
Incorrect weight type 
 in layer 
Size of weights = 
 is not equal to size of the product of input and output channels = 
Size of quantized weights (in bytes) = 
 is smaller than the total bytes required for the product of input and output channels = 
for 
-bit quantization in layer 
Size of bias = 
 is not equal to the output channels = 
Size of quantized bias is insufficient for Inner Product layer 
Inner product layer: '
' : Product of input blob dimensions C,H,W (
) must be equal to the parameter 'inputChannels' (
reshape
Resize bilinear layer: 
Sampling mode not set in resize bilinear layer.
Scale Layer: Scale shape cannot be of size 0
Scale Layer: Scale shape must be of size less than or equal to 3
Scale Layer: Scale size does not match provided shape
constant_in_scale
Scale Layer: Must accept exactly 1 input and produce 1 output
Scale Layer: Bias shape cannot be of size 0
Scale Layer: Bias shape must be of size less than or equal to 3
Scale Layer: Bias size does not match provided shape
constant_in_bias
mul_out
sequence_concat
concat
' , deconvolution does not support weight as input tensor.
' , input channels must be divisible by the number of groups.
' , output channels cannot be 0
' , kernel channels cannot be 0
' , if set, kernel size must be of length 2
' , kernel size cannot be 0
' , if set, stride must be of length 2
' , stride cannot be 0
' , if set, dilation factor must be of length 2
' , dilation factor cannot be 0
' , if set, output shape must be of length 2
' , for valid padding, padding border amounts must be specified for both height and width, if set
Same Padding Mode not recognized
deconvolution
convolution
' , size of weight parameter not equal to the product of kernel sizes, number of kernels and kernel channels
' has insufficient convolution weights
' , size of bias parameter not equal to the number of output channels
Insufficient quantized bias elements in 
' input's channel dimension (
) is not equal to the number of layer parameters  (
Permute Layer: axis parameter must of length 4
Crop resize bilinear layer: 
 , target size must be of length 2, if set
Sampling mode not set in crop resize layer.
Box coordinates mode not set in crop resize layer.
Padding layer: 
 , pad amounts must be specified for both height and width, if set
Padding Type not set
general_padding
Unknown layer type
_axis
cumsum
_load_constant_
load_constant
elementwise
general_slice
classify
Failed to inherit operator '
' from opset '
 because the operator is already registered.
CoreML5
CoreML6_train
probabilities
classes
Classifier probabilities can have a maximum of one dimension that is not rank 1.
Classifier probabilities must have a fully known shape.
Arguments not of the same length in classify operation
Incorrect type for class prediction output of classify operation
Incorrect type for probabilities output of classify operation
CoreML.Specification.CoreMLModels.AudioFeaturePrint.Sound
CoreML.Specification.CoreMLModels.AudioFeaturePrint
Must provide training inputs for updatable neural network (expecting both input and target for loss function).
Training inputs don't describe required inputs for the loss (needs both the input and the target).
The training inputs must include at least one input from the model itself as required for training (should have at least one input in common with those used for prediction).
The type of the training input provided: 
 doesn't match the expected type of the classifier. Found: 
, expected: 
The training inputs don't include the target of the classifier: 
The training inputs don't include the loss layer's target: 
The layer named '
' is marked as updatable, however it is not supported as the type of this layer is neither convolution nor inner-product.
The model is marked as updatable, but none of the layers are updatable.
An updatable layer, named '
', has quantized weights/bias param. Quantized weights/bias not supported for update.
', has a weight/bias param which is not marked as updatable.
The updatable model has a name collision for: '
', i.e., there are more than one layers or loss layers with this name.
This model has more than one loss layers specified, which is not supported at the moment.
Failed to look up node for '
There is a layer (
), which does not support backpropagation, between an updatable marked layer and the loss function.
For the categorical cross entropy loss layer named '
', input is not generated from a softmax output.
For the cross entropy loss layer named '
', target is generated within the graph.
For the MSE loss layer named '
', input is not generated within the graph.
Loss function is not recognized in the loss layer named '
', only cross entropy loss and MSE are supported.
SGD optimizer should include learningRate parameter.
learningRate
SGD optimizer should include miniBatchSize parameter.
miniBatchSize
ADAM optimizer should include learningRate parameter.
ADAM optimizer should include miniBatchSize parameter.
ADAM optimizer should include beta1 parameter.
beta1
ADAM optimizer should include beta2 parameter.
beta2
ADAM optimizer should include eps (epslion) parameter.
Optimizer is not recognized.
Epochs should be included in neural network update parameters.
epochs
seed
CoreML.Specification.CategoricalMapping.strValue
CoreML.Specification.CategoricalMapping
CoreML.Specification.Pipeline.names
CoreML.Specification.Pipeline
CoreML.Specification.PipelineClassifier
CoreML.Specification.PipelineRegressor
CoreML.Specification.FeatureDescription.name
CoreML.Specification.FeatureDescription.shortDescription
CoreML.Specification.FeatureDescription
CoreML.Specification.Metadata.shortDescription
CoreML.Specification.Metadata.versionString
CoreML.Specification.Metadata.author
CoreML.Specification.Metadata.license
CoreML.Specification.Metadata.UserDefinedEntry.key
CoreML.Specification.Metadata.UserDefinedEntry.value
CoreML.Specification.Metadata
CoreML.Specification.ModelDescription.predictedFeatureName
CoreML.Specification.ModelDescription.predictedProbabilitiesName
CoreML.Specification.ModelDescription
CoreML.Specification.SerializedModel.identifier
CoreML.Specification.SerializedModel
CoreML.Specification.Model
/dev/urandom
Convolution
Convolution Layer '
' does not support weight as input tensor when RANK5_ARRAY_MAPPING == true.
Padding type for convolution layer '
' is not set.
Deconvolution Layer '
' does not support weight as input tensor.
Convolution layer: '
' , dilated convolution does not support weight as input tensor.
' with dynamic weight does not support static bias.
Convolution layer '
'  has invalid weights/bias fields.
Convolution layer 
has unmatched precisions of weights/bias They should either be half or full precision.
Deconvolution layer '
' has weight matrix of size 
 to encode a 
 convolution.
weight
Layer 
has not specified weights.
' has a bias vector of size 
 but should be 
bias
has not specified bias.
Convolution3D
Convolution3D layer: '
', convolution3D does not support weight as input tensor.
Input Channels
Output Channels
Groups
Kernel Depth
Kernel Height
Kernel Width
Stride Depth
Stride Height
Stride Width
Dilation Depth
Dilation Height
Dilation Width
Custom Padding Front must be non-negative, got '
Custom Padding Back must be non-negative, got '
Custom Padding Top must be non-negative, got '
Custom Padding Bottom must be non-negative, got '
customPadding Left must be non-negative, got '
customPadding Right must be non-negative, got '
Convolution3D layer '
' has unmatched precisions of weights/bias They should either be half or full precision.
Deconvolution3D Layer '
' Output Shape is supported for Deconvolution layer.
Deconvolution3D layer: '
' , if set, output shape must be of length 3.
' has invalid weights field. Quantized 
weights are not supported.
Convolution3D 
weights
' has invalid bias field. Quantized 
bias is not supported.
InnerProduct
Batchnorm
Batchnorm layer '
' parameters have values for both full and half precision. Parameters should either be specified in half or full precision, mixed parameters are not supported.
BatchNorm
gamma
beta
' is missing mean and variance.
mean
variance
ActivationPReLU
ActivationParametricSoftplus
Pooling
Padding type for the pooling layer '
Pooling3d
Front
Back
Bottom
Left
Right
Padding
Padding layer 
 specifies 
 padding amounts but it must either specify 2 (for x and y axes), or 0 for the default values.
 padding type is not set.
LRNLayer
Parameter 'K' for the LRN layer '
' must be positive.
Split
' of type 'Split' must have equal ranks for its outputs, but they are not equal.
Unary
Upsample
Invalid scaling factor in upsampling layer '
'. Only one of scalingFactor and fractionalScalingFactor can be set, and if set, must be of size 2. Found scalingFactor of size 
 and fractionalScalingFactor of size 
Invalid upsample layer '
'. Fractional upsample only compatible with align_corners=true or align_corners=false
' of type Upsample uses Nearest Neighbors but uses linear upsampling mode other than DEFAULT.
Bias
Bias product layer '
' has both full precision and half precision weights and/or bias fields populated
Bias layer '
' cannot be 
 dimensional. Must be 1D or 3D.
L2Normalize
Reshape
Reshape layer '
' target shape must be 3D or 4D.
Flatten
Permute
Permute layer '
' must have 4D axis parameters.
Reduce
Reduce layer: '
': unknown value for parameter 'axis'.
Reduce layer '
': input's rank is smaller than the dimensions provided in the axis parameter
ReorganizeData
Block size for layer '
' must be > 1.
Slice
Slice layer: '
Slice layer '
': input's rank is smaller than the dimension provided in the axis parameter
Stride length for the slice layer '
Slice layer 
 has an end index before the start index.
LoadConstant
output
Load constant layer '
' has both full precision and half precision weight fields populated
' must be a 3D constant.
constants
Scale
Scale layer '
' has invalid scale/bias fields.
' has invalid scale/bias fields. Field value types should match and should either be half or full precision.
The shape vector for the scale layer '
' is 
 dimensional but should be 1D or 3D.
scale
The bias vector for scale layer '
 dimensional but should be either 1D or 3D.
SimpleRecurrent
Simple recurrent layer '
' has invalid weightMatrix/recusionMatrix/Bias fields.
' has invalid weightMatrix/recusionMatrix/Bias fields. Field value types should match and should either be half or full precision.
SimpleRNN
WeightMatrix
RecursionMatrix
BiasVector
GRU layer '
' has invalid weight/recursion matrix or bias fields. Field value types should match and should be either half or full precision
update gate weight matrix
reset gate weight matrix
output gate weight matrix
update gate recursion matrix
reset gate recursion matrix
output gate recursion matrix
update gate bias vector
reset gate bias vector
output gate bias vector
UniDirectionalLSTM
Unidirectional LSTM layer:
 must provide 3 activations
Unidirectional LSTM
input gate weight matrix
forget gate weight matrix
block input gate weight matrix
input gate recursion matrix
forget gate recursion matrix
block input gate recursion matrix
input gate bias vector
forget gate bias vector
block input bias vector
input gate peep hole vector
forget gate peep hole vector
output gate peep hole vector
BiDirectionalLSTM
Bidirectional LSTM layer:
 forward lstm must provide 3 activations
 backward lstm must provide 3 activations
Bidirectional LSTM
forward input gate weight matrix
forward forget gate weight matrix
forward block input gate weight matrix
forward output gate weight matrix
forward input gate recursion matrix
forward forget gate recursion matrix
forward block input gate recursion matrix
forward output gate recursion matrix
backward input gate weight matrix
backward forget gate weight matrix
backward block input gate weight matrix
backward output gate weight matrix
backward input gate recursion matrix
backward forget gate recursion matrix
backward block input gate recursion matrix
backward output gate recursion matrix
forward input gate bias vector
forward forget gate bias vector
forward block input bias vector
forward output gate bias vector
backward input gate bias vector
backward forget gate bias vector
backward block input bias vector
backward output gate bias vector
forward input gate peephole vector
forward forget gate peephole vector
forward output gate peephole vector
backward input gate peephole vector
backward forget gate peephole vector
backward output gate peephole vector
Crop
' of type 'Crop' expects equal ranks for its inputs, but they are not equal.
cropAmounts parameter for the crop layer '
' is of length 
 but requires exactly two crop constraints (for X,Y axes).
Offset parameter for the crop layer '
 but requires exactly two offsets (for X,Y axes).
DotProduct
' of type 'DotProduct' expects equal ranks for its inputs, but they are not equal.
MeanVarianceNormalize
Embedding
EmbeddingND
SequenceRepeat
Softmax
Concat
' of type 'Concat' expects equal ranks for its inputs, but they are not equal.
Custom layer 
 has an empty 'className' field. This field is required in order for Core ML to link to the implementation for this custom class.
 has a weights parameter with multiple types filled in.  The WeightParams message should be treated as a oneof.
ResizeBilinear
Target Size in the resize bilinear layer '
' must be a vector of size 2 (i.e height, width) but is a vector of size 
CropResize
' of type 'CropResize' expects equal ranks for its inputs, but they are not equal.
Target Size in the crop resize layer '
Branch Layer '
' input's length cannot be more than 1
' requires the condition blob '
' which is not present in the network prior to this layer.
' has an empty If branch
Axes are required parameters for '
' layer.
Copy layer '
' has identical input and output names.
BatchedMatMul layer '
': given ranks of the two inputs, rank of the output is incorrect.
': has one input, in this case, output and input ranks must be equal but they are not.
': has two inputs and 'hasBias' flag is set to True.However, bias is only supported when the layer has 1 input.
': cannot use dynamic quantization with 2 inputs.
BatchedMatMul
Value of axis must be in the range [-rank(tensor), rank(tensor)) for '
Invalid size of reverse_dim for '
Target shape is required parameter for '
Scatter layer must have 3 input tensor fields filled
Input ranks of Scatter layer '
' are invalid.
Scatter layer must have 1 output tensor fields filled
Output rank of Scatter layer '
' does not match container input.
Shapes of all inputs must match for '
Value of axis must be in the range [-rank(tensor), rank(tensor)] for '
Either split_sizes or num_splits should be provided for '
Value of num_splits should match size of output names for '
Value of minval should be smaller than maxval for '
Begin IDs are required parameters for '
End IDs are required parameters for '
Strides are required parameters for '
Begin masks are required parameters for '
End masks are required parameters for '
Loop Layer '
' has an empty body network
': condition variable must be provided if condition network exists and vice versa.
': has no input, no condition network and max loop iterations is 0.
': has conditionVar named '
' which is not produced by the condition network
Loop Break Layer '
' must be inside the bodyNetwork of a loop layer.
Loop Continue Layer '
RankPreservingReshape Layer '
': input and output rank must be equal.
': input rank must be same as the length of the target shape property.
ExpandDims Layer '
': length of the 'axes' parameter cannot be 0.
': all the values in the 'axes' parameter must be unique.
': input rank plus the length of the axes parameter must equal output rank.
': axes parameter list cannot have the same value more than once.
': axes refers to a dimension that exceeds the output rank.
Squeeze Layer '
': output rank plus the length of the axes parameter must equal input rank.
': axes refers to a dimension that exceeds the input rank.
Range
LoadConstantND layer '
'can only accept shape of length 1 to 5
LoadConstantND
Value of prob should be in range [0: 1] for '
TopK
' of type 'TopK' expects equal ranks for its input and second output, but they are not equal.
ArgMax
ArgMin
Normalized shape is required parameter for '
Gamma is required parameter for '
Beta is required parameter for '
Gamma and Beta should not be quantized for '
Shape of gamma should match normalized_shape for '
Shape of beta should match normalized_shape for '
ConstantPad
In 'ConstantPad' layer '
', length of 'padAmounts' parameter is 
, an odd value, which is not allowed.
', length of 'padAmounts' cannot be zero when only 1 input is provided.
', 'padToGivenOutputSizeMode' is true, and both padding values corresponding to dimension 
 are non zero, which is invalid. Only one value can be non-zero.
Argsort
Value of 'axis' is negative for layer of type 'ArgSort' and name '
', which is not supported. It must be positive.
Value of 'axis' is 
, but it must be in the range [0,
) for layer of type 'ArgSort' and name '
Unsupported layer type (
) for layer '
' of type 
 has 
 inputs but expects exactly 
 inputs but expects at least 
 inputs but expects at most 
 outputs but expects exactly 
 outputs but expects at least 
 outputs but expects at most 
' of type '
' expects equal ranks for its input and output, but they are not equal.
input
' has incorrect 
 size 
 (expected 
' has insufficient bytes for quantized 
 with 
units.
' has invalid quantization parameters for quantized 
' has unspecified 
' has empty 
 must be positive, got 
Inner product
 layer '
' has invalid weights/bias fields.
 has incorrect weight matrix size 
' has incorrect bias vector size 
Nonlinearity type 
 has inconsistent weight parameter types.
 is not supported in this version of CoreML.
MLActivationParamsNonlinearityType_linear
MLActivationParamsNonlinearityType_ReLU
MLActivationParamsNonlinearityType_leakyReLU
MLActivationParamsNonlinearityType_thresholdedReLU
MLActivationParamsNonlinearityType_PReLU
MLActivationParamsNonlinearityType_tanh
MLActivationParamsNonlinearityType_scaledTanh
MLActivationParamsNonlinearityType_sigmoid
MLActivationParamsNonlinearityType_sigmoidHard
MLActivationParamsNonlinearityType_ELU
MLActivationParamsNonlinearityType_softsign
MLActivationParamsNonlinearityType_softplus
MLActivationParamsNonlinearityType_parametricSoftplus
Custom Padding 
 must be non-negative, got 
 cannot be non-zero (got 
) unless padding type is CUSTOM (got 
' has 
 rank 
 but expects rank exactly 
 but expects rank at least 
 but expects rank at most 
Recurrent non-linearity type 
LSTM weight parameters have inconsistent field value types. Types should match and should be either half or full precision
' has invalid weights/bias fields. Field value types should match and should either be half or full precision.
' must have rank specified for its input and output.
Model specification version field missing or corrupt.
The model supplied is of version 
, intended for a newer version of Xcode. This version of Xcode supports model version 
 or earlier.
Model specification version for an updatable model must be '
' or above.
Model did not specify a valid model-parameter type.
unable to open file for read
unable to open file for write
unable to deserialize object
unable to serialize object
Dimension size must be greater tha zero.
Feature descriptions exceeded 
". Should be one of: 
Int64 class labels must be supplied for SVM classifier.
coefficient array must be size numberOfClasses - 1 (
). Instead it is size 
Must specify sparse or dense support vectors
numberOfSupportVectoresPerClass array must be size numberOfClasses 
 instead it is size 
sum of numberOfSupportVectorsPerClass 
 must sum to total number of support vectors 
Incorrect number of coefficients: There should be 
 not 
probA and probB must be same size
Expected length of probA is number of class pairs: 
The number of coefficients must match the number of support vectors.
Gamma must be greater than or equal to zero
Degree must be greater than or equal to zero
You must specify a supported kernel type
CoreML.Specification.Identity
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects.output
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects
CoreML.Specification.CoreMLModels.VisionFeaturePrint
Size range is invalid (
Feature description must have a non-empty name.
Feature description 
 must specify a valid feature type.
Description of multiarray feature '
' has enumerated zero permitted sizes.
' has enumerated shapes with zero dimensions.
' has a default shape specified 
 which is not within the allowed enumerated shapes specified.
' has an invalid range for dimension 
' has a default 
-d shape but a 
-d shape range
' has a default shape that is out of the specified shape range
' has missing shape constraints.
' has an invalid shape. Element 
 has non-positive value 
. This model has version 
' has FLOAT16 dataType, which is only valid in specification version >= 
' has an invalid or unspecified dataType. It must be specified as DOUBLE, FLOAT32, FLOAT16 or INT32
' has mistmatch between dataType and the type of default optional value.
Description of dictionary feature '
' must contain a key type of either Int64 or String.
Description of image feature '
' has a default size of 
 which is not within the allowed enumerated sizes specified.
' has an invalid flexible width range. 
' has an invalid flexible height range. 
' default width 
 is not within specified flexible width range
' default height 
 is not within specified flexible height range
' has missing or non-positive width 
' has missing or non-positive height 
' has GRAYSCALE_FLOAT16 colorspace, which is only valid in specification version >= 
' has missing or invalid colorspace. It must be RGB, BGR or GRAYSCALE.
Sequence types are only valid in specification verison >= 
Description of sequence feature '
' has invalid allowed sizes. 
' has invalid or missing type. Only Int64 and String sequences are currently supported
Feature description has an unspecified or invalid type for feature '
Models must have one or more inputs.
Models must have one or more outputs.
Specification is missing regressor predictedFeatureName.
Specification is missing classifier predictedFeatureName
This model type is not supported for on-device update.
Default optional values are only allowed for neural networks.
Default value for optional inputs is supported from specification 5 (iOS 14) onwards!
At least one feature for a neural network must NOT be optional.
Features cannot be optional to this type of model.
Outputs cannot be optional.
' to the model is not present in the model description.
For this neural network classifier, the probabilities are obtained from the layer '
' which was not found in the network.
Output layer '
' is not produced by any layer of the neural network.
outputs
Interface specifies output '
' which is not produced by any layer in the neural network.
Neural Network Multi-Array input shape mapping cannot be 'RANK5_ARRAY_MAPPING' if the network contains a layer added in version 4 (iOS 13) or later. Use 'EXACT_ARRAY_MAPPING' instead.
Neural Network Multi-Array input shape mapping cannot be 'RANK5_ARRAY_MAPPING' if the image input Shape mapping is not 'RANK5_IMAGE_MAPPING'
Neural networks require at least one input.
Neural networks produce at least one output.
Neural networks require at least one layer.
Neural networks require at least one non-optional input.
inputs
__input
Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).
Error determining network blob shapes: 
Input MLMultiArray to neural networks must have at least 1 dimension.
For MLMultiArray input: Rank of the flexible shape range must match the rank of the default shape.
Layer '
''s input and inputTensors have different lengths
''s input '
' is also an input to the model. However, for this tensor the rank provided in the layer description
 does not match the one provided in the model description
Inconsistent rank for the blob named '
''s output and "outputTensors" property have different lengths
''s output '
' is also an output of the model. However, for this tensor the rank provided in the layer description
' consumes an input named '
' which is not present in this network.
' produces an output named '
' which is also an output produced by the layer '
Tensor in layer '
': rank must match the length of dimValue
CoreML.Specification.OneHotEncoder
CoreML.Specification.CoreMLModels.TextClassifier.language
CoreML.Specification.CoreMLModels.TextClassifier
CoreML.Specification.MILSpec.Program.FunctionsEntry.key
CoreML.Specification.MILSpec.Program.docString
CoreML.Specification.MILSpec.Program.AttributesEntry.key
CoreML.Specification.MILSpec.Program
CoreML.Specification.MILSpec.Function.opset
CoreML.Specification.MILSpec.Function.BlockSpecializationsEntry.key
CoreML.Specification.MILSpec.Function.AttributesEntry.key
CoreML.Specification.MILSpec.Function
CoreML.Specification.MILSpec.Block.outputs
CoreML.Specification.MILSpec.Block.AttributesEntry.key
CoreML.Specification.MILSpec.Block
CoreML.Specification.MILSpec.Argument.Binding.name
CoreML.Specification.MILSpec.Argument.Binding
CoreML.Specification.MILSpec.Argument
CoreML.Specification.MILSpec.Operation.type
CoreML.Specification.MILSpec.Operation.InputsEntry.key
CoreML.Specification.MILSpec.Operation.AttributesEntry.key
CoreML.Specification.MILSpec.Operation
CoreML.Specification.MILSpec.NamedValueType.name
CoreML.Specification.MILSpec.NamedValueType
CoreML.Specification.MILSpec.ValueType
CoreML.Specification.MILSpec.TensorType.AttributesEntry.key
CoreML.Specification.MILSpec.TensorType
CoreML.Specification.MILSpec.TupleType
CoreML.Specification.MILSpec.ListType
CoreML.Specification.MILSpec.DictionaryType
CoreML.Specification.MILSpec.Dimension.ConstantDimension
CoreML.Specification.MILSpec.Dimension.UnknownDimension
CoreML.Specification.MILSpec.Dimension
CoreML.Specification.MILSpec.Value.ImmediateValue
CoreML.Specification.MILSpec.Value.BlobFileValue.fileName
CoreML.Specification.MILSpec.Value.BlobFileValue
CoreML.Specification.MILSpec.Value.docString
CoreML.Specification.MILSpec.Value
CoreML.Specification.MILSpec.TensorValue.RepeatedFloats
CoreML.Specification.MILSpec.TensorValue.RepeatedDoubles
CoreML.Specification.MILSpec.TensorValue.RepeatedInts
CoreML.Specification.MILSpec.TensorValue.RepeatedLongInts
CoreML.Specification.MILSpec.TensorValue.RepeatedBools
CoreML.Specification.MILSpec.TensorValue.RepeatedStrings.values
CoreML.Specification.MILSpec.TensorValue.RepeatedStrings
CoreML.Specification.MILSpec.TensorValue.RepeatedBytes
CoreML.Specification.MILSpec.TensorValue
CoreML.Specification.MILSpec.TupleValue
CoreML.Specification.MILSpec.ListValue
CoreML.Specification.MILSpec.DictionaryValue.KeyValuePair
CoreML.Specification.MILSpec.DictionaryValue
Convolution padding type not set
Pooling padding type not set
Reduce layer axis not set -- should have been caught in validator.
Ranges axis index is out of bounds in shapePermuteLayer.
Slice layer axis incorrect -- should be caught in validator.
Layer type not found.
Shape inference not implemented for this layer type.
CoreML6
Default Value (
) for '
' expected to be a positive value.
Non-positive value (
) in Allowed Values Set for '
' is not allowed.
Specified Default Value (
) not found in Allowed Values Set for '
Non-positive min value (
) in Allowed Value Range for '
Non-positive max value (
) out of Allowed Value Range for '
Specified minimum value (
) greater than maximum value for '
CoreML.Specification.Scaler
Weights and offsets must be the same size.
All weight coefficients must be the same size.
Invalid post evaluation transform
Invalid class encoding
The number of DoubleArrays in weights must be greater than zero
The number of DoubleArrays in weights must match number of offsets
With ReferenceClass encoding the number of DoubleArrays in weights must be one less than number of classes
When using OneVsRest encoding for only two classes, the number of DoubleArrays in weights must be one
With OneVsRest encoding the number of DoubleArrays in weights must equal the number of classes
Probit post evaluation transform is only supported for binary classification
Weight DoubleArrays must have nonzero length
Weight DoubleArrays must have the same length
Classifier declared to have Int64 class labels must provide labels.
Classifier declared to have String class labels must provide labels.
Classifier models must provide class labels.
Attempting to access unbound size_t val from RangeVal.
Dividing range 
 by 0.
Constructing invalid ShapeRange with 
Constructing invalid ShapeRange unbound minimum value.
Dividing ShapeRange 
 by negative or zero value 
Invalid setLower 
 for range: 
Invalid setUpper 
Invalid setValue 
Invalid intersection between 
 and 
Attempting to constrain an input or output feature "
" with an invalid array shape constraint.
Attempting to update feature constraint 
 with a type description which is not a multi array or image.
Invalid sequence range in blob 
Invalid batch range in blob 
Invalid channel range in blob 
Invalid height range in blob 
Invalid width range in blob 
Incorrect input shape, should be 1-dimension, of length: 
Incorrect output shape, should be 3-dimension, of size: 
Type for sound analysis preprocessing not set
Only 1 dimensional arrays input features are supported by the imputer.
Shape of imputed array value does not match shape of input array.
Imputer parameter must be set.
Type of input feature "
" is not compatible with given imputed value type.
Type of given replace value not compatible with input feature type.
CoreML.Specification.CoreMLModels.SoundAnalysisPreprocessing.Vggish
CoreML.Specification.CoreMLModels.SoundAnalysisPreprocessing
CoreML.Specification.GLMClassifier.DoubleArray
CoreML.Specification.GLMClassifier
CoreML.Specification.Imputer.imputedStringValue
CoreML.Specification.Imputer.replaceStringValue
CoreML.Specification.Imputer
CoreML.Specification.CustomModel.CustomModelParamValue.stringValue
CoreML.Specification.CustomModel.CustomModelParamValue
CoreML.Specification.CustomModel.className
CoreML.Specification.CustomModel.ParametersEntry.key
CoreML.Specification.CustomModel.description
CoreML.Specification.CustomModel
LinkedModel cannot be marked as updatable
LinkedModel.LinkType not set.
LinkedModel.linkedModelFile.linkedModeFileName.defaultValue cannot be empty.
CoreML.Specification.LinearKernel
CoreML.Specification.RBFKernel
CoreML.Specification.PolyKernel
CoreML.Specification.SigmoidKernel
CoreML.Specification.Kernel
CoreML.Specification.SparseNode
CoreML.Specification.SparseVector
CoreML.Specification.SparseSupportVectors
CoreML.Specification.DenseVector
CoreML.Specification.DenseSupportVectors
CoreML.Specification.Coefficients
CoreML.Specification.SupportVectorRegressor
CoreML.Specification.SupportVectorClassifier
CoreML.Specification.CoreMLModels.Gazetteer.language
CoreML.Specification.CoreMLModels.Gazetteer
CoreML.Specification.Normalizer
Input feature '
' was not requested by any of the input feature names (e.g. confidenceInputFeatureName).
' (as defined by confidenceInputFeatureName) to the model is not present in the model description.
' (as defined by coordinatesInputFeatureName) to the model is not present in the model description.
' was not requested by any of the output feature names (e.g. confidenceOutputFeatureName).
' (as defined by confidenceOutputFeatureName) from the model is not present in the model description.
' (as defined by coordinatesOutputFeatureName) from the model is not present in the model description.
iouThreshold must be a value between 0.0 and 1.0.
confidenceThreshold must be a non-negative value. If you do not want to eliminate any predictions based on confidence, set it to 0.0.
'confidence' and 'coordinates' must use a same element type, but 
'input confidence' is 
'output confidence' is 
'input coordinates' are 
and 'output coordinates' are 
The element data type of 'confidence' and 'coordinates' must be either MultiArray<DOUBLE> or MultiArray<FLOAT32>, but 
The element data type of 'confidence' and 'coordinates' must be MultiArray<DOUBLE> for model specification version earlier than 
, but 
To enable MultiArray<FLOAT32>, use the model specification version 
 or later.
If shape information is provided for confidence output, 2 dimensions must be specified using either shape (deprecated) or allowedShapes.
Confidence and coordinates output shapes must be consistent (must have the same size along dimension 0).
Confidence and coordinates output shapes fexibility must both be ranges
Confidence and coordinates output shapes must be consistent (must have the same range of sizes along dimension 0).
Number of classes is not consistent for class labels (
) and dimension 1 of output confidence shape (
) and dimension 1 of output confidence shape range
CoreML.Specification.StringToInt64Map.MapEntry.key
CoreML.Specification.StringToInt64Map
CoreML.Specification.Int64ToStringMap.MapEntry.value
CoreML.Specification.Int64ToStringMap
CoreML.Specification.StringToDoubleMap.MapEntry.key
CoreML.Specification.StringToDoubleMap
CoreML.Specification.Int64ToDoubleMap
CoreML.Specification.StringVector.vector
CoreML.Specification.StringVector
CoreML.Specification.Int64Vector
CoreML.Specification.FloatVector
CoreML.Specification.DoubleVector
CoreML.Specification.Int64Range
CoreML.Specification.Int64Set
CoreML.Specification.DoubleRange
Pipeline must contain one or more models.
Pipeline: the input '
' of model '
' does not present in pipeline input or previous model.
' does not match the type previously specified by the pipeline input or the output of a previous model.
 For the second case, make sure the input and previous model's output has the matching name and shapes.
Pipeline output '
' not present in pipeline input or a contained model.
Type of pipeline output '
' does not match type produced in pipeline input.
Only the last model in the pipeline can be updatable. Model at position '
' is marked as updatable.
Last model in an updatable pipeline model should be marked as updatable.
Found an updatable model at '
' inside a non-updatable pipeline.
The number of pipeline model names '
' doesn't match the number of models '
Pipeline model name '
' at index '
 has already been used for previous models
CoreML.Specification.BayesianProbitRegressor.Gaussian
CoreML.Specification.BayesianProbitRegressor.FeatureValueWeight
CoreML.Specification.BayesianProbitRegressor.FeatureWeight
CoreML.Specification.BayesianProbitRegressor.regressionInputFeatureName
CoreML.Specification.BayesianProbitRegressor.optimismInputFeatureName
CoreML.Specification.BayesianProbitRegressor.samplingScaleInputFeatureName
CoreML.Specification.BayesianProbitRegressor.samplingTruncationInputFeatureName
CoreML.Specification.BayesianProbitRegressor.meanOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.varianceOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.pessimisticProbabilityOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.sampledProbabilityOutputFeatureName
CoreML.Specification.BayesianProbitRegressor
Version for scene is invalid
Version for objects is invalid
Two outputs for objects need to be provided
Model description declares an output: 
 but it is not declared in Vision Feature Print output
Type for vision feature print not set
CoreML.Specification.CoreMLModels.WordEmbedding.language
CoreML.Specification.CoreMLModels.WordEmbedding
CoreML.Specification.Int64Parameter
CoreML.Specification.DoubleParameter
CoreML.Specification.StringParameter.defaultValue
CoreML.Specification.StringParameter
CoreML.Specification.BoolParameter
Model is not a tree ensemble.
Given output dimension equals 0.
Tree Node with TreeID=
and NodeID=
 duplicated in specification.
False child and parent have same ID (TreeID=
, NodeID=
In TreeID=
, false child of NodeID=
 is already the child of node NodeID=
True child and parent have same ID (TreeID=
, true child of NodeID=
Tree TreeID=
 has multiple root nodes: 
NodeID=
Internal error: null child node; likely specification error.
Node detected that are not connected to any single root node. Note: 
(TreeID=
Dimension of default value array (
) does not match specified output dimension (
Specified output dimension (
) does not match the given number of classes (
Error(s) in tree structure: 
FATAL: 
  FATAL: maximum number of errors reached; aborting processing.
Errors encountered during processing tree model:
Branch mode hit bad value -- this is confusing; error in validator?
Leaf Node (TreeID=
) has no evaluation value(s) specified.
) specifies evaluation value applied to dimension 
; which is out of range. Dimension must be less than 
) specifies multipule evaluation values applied to dimension 
 and NodeID=
 referenced but not declared in specification.
Exactly one input array column must be specified.
If output type is Double in interface, exactly one extraction index must be specified.
CoreML.Specification.NonMaximumSuppression.PickTop
CoreML.Specification.NonMaximumSuppression.confidenceInputFeatureName
CoreML.Specification.NonMaximumSuppression.coordinatesInputFeatureName
CoreML.Specification.NonMaximumSuppression.iouThresholdInputFeatureName
CoreML.Specification.NonMaximumSuppression.confidenceThresholdInputFeatureName
CoreML.Specification.NonMaximumSuppression.confidenceOutputFeatureName
CoreML.Specification.NonMaximumSuppression.coordinatesOutputFeatureName
CoreML.Specification.NonMaximumSuppression
OneHotEncoder parameter incorrect type
More model output features than the output features of the word tagger model.
Output feature '
' was not required by the output features of the word tagger model.
Expected feature '
' (defined by tokenTagsOutputFeatureName) to the model is not present in the model description.
". Should be: 
Model output tags not set. Must have at least one tag
Model revision number not set. Must be >= 1
Only integer item ids or string item ids can be specified in the same model.
List of integer item ids specified must be large enough to index all item ids specified.  The largest item index is 
, whereas there are  only 
 item ids given.
List of integer item ids specified must be unique; list contains duplicates.
List of string item ids specified must be large enough to index all item ids specified.  The largest item index is 
List of string item ids specified must be unique; list contains duplicates.
Name of column for item input data not specified.
No output columns specified.
NormalizerValidator normLx invalid
CoreML.Specification.ItemSimilarityRecommender.ConnectedItem
CoreML.Specification.ItemSimilarityRecommender.SimilarItems
CoreML.Specification.ItemSimilarityRecommender.itemInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.numRecommendationsInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.itemRestrictionInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.itemExclusionInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.recommendedItemListOutputFeatureName
CoreML.Specification.ItemSimilarityRecommender.recommendedItemScoreOutputFeatureName
CoreML.Specification.ItemSimilarityRecommender
Input type Int64 must output to Int64 or Double.
Type of input feature does not match the output type feature.
Only 1 dimensional arrays input features are supported by the scaler.
Shape of output array does not match shape of input array.
For input type array, specified shift values must be empty, a scalar, or a vector of the matching length.
For input type array, specified scale values must be empty, a scalar, or a vector of the matching length.
For a scalar imput type, specified shift value must be empty or a scalar.
For input type array, specified scale values must be empty or a scalar.
CoreML.Specification.FeatureVectorizer.InputColumn.inputColumn
CoreML.Specification.FeatureVectorizer.InputColumn
CoreML.Specification.FeatureVectorizer
DictVectorizerValidator parameter not set
CoreML.Specification.CoreMLModels.WordTagger.language
CoreML.Specification.CoreMLModels.WordTagger.tokensOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenTagsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenLocationsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenLengthsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger
CoreML.Specification.TreeEnsembleParameters.TreeNode.EvaluationInfo
CoreML.Specification.TreeEnsembleParameters.TreeNode
CoreML.Specification.TreeEnsembleParameters
CoreML.Specification.TreeEnsembleClassifier
CoreML.Specification.TreeEnsembleRegressor
not an error
validator error: 
Double
Int64
String
Invalid
Int32
Float32
Float16
Grayscale
Grayscale16Half
CoreML.Specification.DictVectorizer
CoreML.Specification.NeuralNetwork
CoreML.Specification.NeuralNetworkImageScaler
CoreML.Specification.NeuralNetworkMeanImage
CoreML.Specification.NeuralNetworkPreprocessing.featureName
CoreML.Specification.NeuralNetworkPreprocessing
CoreML.Specification.ActivationReLU
CoreML.Specification.ActivationLeakyReLU
CoreML.Specification.ActivationTanh
CoreML.Specification.ActivationScaledTanh
CoreML.Specification.ActivationSigmoid
CoreML.Specification.ActivationLinear
CoreML.Specification.ActivationSigmoidHard
CoreML.Specification.ActivationPReLU
CoreML.Specification.ActivationELU
CoreML.Specification.ActivationThresholdedReLU
CoreML.Specification.ActivationSoftsign
CoreML.Specification.ActivationSoftplus
CoreML.Specification.ActivationParametricSoftplus
CoreML.Specification.ActivationParams
CoreML.Specification.Tensor
CoreML.Specification.NeuralNetworkLayer.name
CoreML.Specification.NeuralNetworkLayer.input
CoreML.Specification.NeuralNetworkLayer.output
CoreML.Specification.NeuralNetworkLayer
CoreML.Specification.BranchLayerParams
CoreML.Specification.LoopLayerParams.conditionVar
CoreML.Specification.LoopLayerParams
CoreML.Specification.LoopBreakLayerParams
CoreML.Specification.LoopContinueLayerParams
CoreML.Specification.CopyLayerParams
CoreML.Specification.GreaterThanLayerParams
CoreML.Specification.GreaterEqualLayerParams
CoreML.Specification.LessThanLayerParams
CoreML.Specification.LessEqualLayerParams
CoreML.Specification.EqualLayerParams
CoreML.Specification.NotEqualLayerParams
CoreML.Specification.LogicalAndLayerParams
CoreML.Specification.LogicalOrLayerParams
CoreML.Specification.LogicalXorLayerParams
CoreML.Specification.LogicalNotLayerParams
CoreML.Specification.BorderAmounts.EdgeSizes
CoreML.Specification.BorderAmounts
CoreML.Specification.ValidPadding
CoreML.Specification.SamePadding
CoreML.Specification.SamplingMode
CoreML.Specification.BoxCoordinatesMode
CoreML.Specification.WeightParams
CoreML.Specification.QuantizationParams
CoreML.Specification.LinearQuantizationParams
CoreML.Specification.LookUpTableQuantizationParams
CoreML.Specification.ConvolutionLayerParams
CoreML.Specification.Convolution3DLayerParams
CoreML.Specification.InnerProductLayerParams
CoreML.Specification.EmbeddingLayerParams
CoreML.Specification.EmbeddingNDLayerParams
CoreML.Specification.BatchnormLayerParams
CoreML.Specification.PoolingLayerParams.ValidCompletePadding
CoreML.Specification.PoolingLayerParams
CoreML.Specification.Pooling3DLayerParams
CoreML.Specification.GlobalPooling3DLayerParams
CoreML.Specification.PaddingLayerParams.PaddingConstant
CoreML.Specification.PaddingLayerParams.PaddingReflection
CoreML.Specification.PaddingLayerParams.PaddingReplication
CoreML.Specification.PaddingLayerParams
CoreML.Specification.ConcatLayerParams
CoreML.Specification.LRNLayerParams
CoreML.Specification.SoftmaxLayerParams
CoreML.Specification.SplitLayerParams
CoreML.Specification.AddLayerParams
CoreML.Specification.MultiplyLayerParams
CoreML.Specification.UnaryFunctionLayerParams
CoreML.Specification.UpsampleLayerParams
CoreML.Specification.ResizeBilinearLayerParams
CoreML.Specification.CropResizeLayerParams
CoreML.Specification.BiasLayerParams
CoreML.Specification.ScaleLayerParams
CoreML.Specification.LoadConstantLayerParams
CoreML.Specification.L2NormalizeLayerParams
CoreML.Specification.FlattenLayerParams
CoreML.Specification.ReshapeLayerParams
CoreML.Specification.PermuteLayerParams
CoreML.Specification.ReorganizeDataLayerParams
CoreML.Specification.SliceLayerParams
CoreML.Specification.ReduceLayerParams
CoreML.Specification.CropLayerParams
CoreML.Specification.AverageLayerParams
CoreML.Specification.MaxLayerParams
CoreML.Specification.MinLayerParams
CoreML.Specification.DotProductLayerParams
CoreML.Specification.MeanVarianceNormalizeLayerParams
CoreML.Specification.SequenceRepeatLayerParams
CoreML.Specification.SimpleRecurrentLayerParams
CoreML.Specification.GRULayerParams
CoreML.Specification.LSTMParams
CoreML.Specification.LSTMWeightParams
CoreML.Specification.UniDirectionalLSTMLayerParams
CoreML.Specification.BiDirectionalLSTMLayerParams
CoreML.Specification.CustomLayerParams.CustomLayerParamValue.stringValue
CoreML.Specification.CustomLayerParams.CustomLayerParamValue
CoreML.Specification.CustomLayerParams.className
CoreML.Specification.CustomLayerParams.ParametersEntry.key
CoreML.Specification.CustomLayerParams.description
CoreML.Specification.CustomLayerParams
CoreML.Specification.TransposeLayerParams
CoreML.Specification.BatchedMatMulLayerParams
CoreML.Specification.ConcatNDLayerParams
CoreML.Specification.SoftmaxNDLayerParams
CoreML.Specification.ReverseLayerParams
CoreML.Specification.ReverseSeqLayerParams
CoreML.Specification.LoadConstantNDLayerParams
CoreML.Specification.FillLikeLayerParams
CoreML.Specification.FillStaticLayerParams
CoreML.Specification.FillDynamicLayerParams
CoreML.Specification.WhereBroadcastableLayerParams
CoreML.Specification.SinLayerParams
CoreML.Specification.CosLayerParams
CoreML.Specification.TanLayerParams
CoreML.Specification.AsinLayerParams
CoreML.Specification.AcosLayerParams
CoreML.Specification.AtanLayerParams
CoreML.Specification.SinhLayerParams
CoreML.Specification.CoshLayerParams
CoreML.Specification.TanhLayerParams
CoreML.Specification.AsinhLayerParams
CoreML.Specification.AcoshLayerParams
CoreML.Specification.AtanhLayerParams
CoreML.Specification.PowBroadcastableLayerParams
CoreML.Specification.Exp2LayerParams
CoreML.Specification.WhereNonZeroLayerParams
CoreML.Specification.MatrixBandPartLayerParams
CoreML.Specification.UpperTriangularLayerParams
CoreML.Specification.LowerTriangularLayerParams
CoreML.Specification.BroadcastToLikeLayerParams
CoreML.Specification.BroadcastToStaticLayerParams
CoreML.Specification.BroadcastToDynamicLayerParams
CoreML.Specification.AddBroadcastableLayerParams
CoreML.Specification.MaxBroadcastableLayerParams
CoreML.Specification.MinBroadcastableLayerParams
CoreML.Specification.ModBroadcastableLayerParams
CoreML.Specification.FloorDivBroadcastableLayerParams
CoreML.Specification.SubtractBroadcastableLayerParams
CoreML.Specification.MultiplyBroadcastableLayerParams
CoreML.Specification.DivideBroadcastableLayerParams
CoreML.Specification.GatherLayerParams
CoreML.Specification.ScatterLayerParams
CoreML.Specification.GatherNDLayerParams
CoreML.Specification.ScatterNDLayerParams
CoreML.Specification.GatherAlongAxisLayerParams
CoreML.Specification.ScatterAlongAxisLayerParams
CoreML.Specification.StackLayerParams
CoreML.Specification.RankPreservingReshapeLayerParams
CoreML.Specification.ConstantPaddingLayerParams
CoreML.Specification.RandomNormalLikeLayerParams
CoreML.Specification.RandomNormalStaticLayerParams
CoreML.Specification.RandomNormalDynamicLayerParams
CoreML.Specification.RandomUniformLikeLayerParams
CoreML.Specification.RandomUniformStaticLayerParams
CoreML.Specification.RandomUniformDynamicLayerParams
CoreML.Specification.RandomBernoulliLikeLayerParams
CoreML.Specification.RandomBernoulliStaticLayerParams
CoreML.Specification.RandomBernoulliDynamicLayerParams
CoreML.Specification.CategoricalDistributionLayerParams
CoreML.Specification.ReduceL1LayerParams
CoreML.Specification.ReduceL2LayerParams
CoreML.Specification.ReduceMaxLayerParams
CoreML.Specification.ReduceMinLayerParams
CoreML.Specification.ReduceSumLayerParams
CoreML.Specification.ReduceProdLayerParams
CoreML.Specification.ReduceMeanLayerParams
CoreML.Specification.ReduceLogSumLayerParams
CoreML.Specification.ReduceSumSquareLayerParams
CoreML.Specification.ReduceLogSumExpLayerParams
CoreML.Specification.ExpandDimsLayerParams
CoreML.Specification.FlattenTo2DLayerParams
CoreML.Specification.ReshapeStaticLayerParams
CoreML.Specification.ReshapeLikeLayerParams
CoreML.Specification.ReshapeDynamicLayerParams
CoreML.Specification.SqueezeLayerParams
CoreML.Specification.TopKLayerParams
CoreML.Specification.ArgMaxLayerParams
CoreML.Specification.ArgMinLayerParams
CoreML.Specification.SplitNDLayerParams
CoreML.Specification.CeilLayerParams
CoreML.Specification.RoundLayerParams
CoreML.Specification.FloorLayerParams
CoreML.Specification.SignLayerParams
CoreML.Specification.ClipLayerParams
CoreML.Specification.SliceStaticLayerParams
CoreML.Specification.SliceDynamicLayerParams
CoreML.Specification.TileLayerParams
CoreML.Specification.GetShapeLayerParams
CoreML.Specification.ErfLayerParams
CoreML.Specification.GeluLayerParams
CoreML.Specification.RangeStaticLayerParams
CoreML.Specification.RangeDynamicLayerParams
CoreML.Specification.SlidingWindowsLayerParams
CoreML.Specification.LayerNormalizationLayerParams
CoreML.Specification.NonMaximumSuppressionLayerParams
CoreML.Specification.ClampedReLULayerParams
CoreML.Specification.ArgSortLayerParams
CoreML.Specification.SliceBySizeLayerParams
CoreML.Specification.NeuralNetworkClassifier.labelProbabilityLayerName
CoreML.Specification.NeuralNetworkClassifier
CoreML.Specification.OneHotLayerParams
CoreML.Specification.CumSumLayerParams
CoreML.Specification.NeuralNetworkRegressor
CoreML.Specification.NetworkUpdateParameters
CoreML.Specification.LossLayer.name
CoreML.Specification.LossLayer
CoreML.Specification.CategoricalCrossEntropyLossLayer.input
CoreML.Specification.CategoricalCrossEntropyLossLayer.target
CoreML.Specification.CategoricalCrossEntropyLossLayer
CoreML.Specification.MeanSquaredErrorLossLayer.input
CoreML.Specification.MeanSquaredErrorLossLayer.target
CoreML.Specification.MeanSquaredErrorLossLayer
CoreML.Specification.Optimizer
CoreML.Specification.SGDOptimizer
CoreML.Specification.AdamOptimizer
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/map_entry_lite.h
CHECK failed: default_instance_ != NULL: 
CoreML.Specification.KNearestNeighborsClassifier.defaultStringLabel
CoreML.Specification.KNearestNeighborsClassifier
CoreML.Specification.NearestNeighborsIndex
CoreML.Specification.UniformWeighting
CoreML.Specification.InverseDistanceWeighting
CoreML.Specification.LinearIndex
CoreML.Specification.SingleKdTreeIndex
CoreML.Specification.SquaredEuclideanDistance
numberOfNeighbors
KNearestNeighborsClassifier requires a weighting scheme to be set.
KNearestNeighborsClassifier's class label and default class label have different types.
KNearestNeighborsClassifier should specify default class labels when class labels are not specified.
KNearestNeighborsClassifier has no data points.
Unexpected number of labels "
" for the given number of examples: "
Unexpected length "
" given the provided number of dimensions "
KNearestNeighborsClassifier has no index type specified.
KNearestNeighborsClassifier requires leaf size to be a positive integer.
KNearestNeighborsClassifier requires a distance function to be set.
Classifier declared with Int64 class labels must provide exclusively Int64 class labels.
Classifier declared with String class labels must provide exclusively String class labels.
CoreML.Specification.LinkedModel
CoreML.Specification.LinkedModelFile
ValueOnUnknown set to string value while mapping produces int64.
ValueOnUnknown set to Int64 value while mapping produces string.
Mapping not set.
Input sequence type does not match input type 
of categorical mapping.
Output of a sequence categorical mapping must be a sequence
Output sequence type does not match input type 
Version for sound is invalid
Type for audio feature print not set
CoreML.Specification.ArrayFeatureExtractor
CoreML.Specification.GLMRegressor.DoubleArray
CoreML.Specification.GLMRegressor
CoreML.Specification.Int64FeatureType
CoreML.Specification.DoubleFeatureType
CoreML.Specification.StringFeatureType
CoreML.Specification.SizeRange
CoreML.Specification.ImageFeatureType.ImageSize
CoreML.Specification.ImageFeatureType.EnumeratedImageSizes
CoreML.Specification.ImageFeatureType.ImageSizeRange
CoreML.Specification.ImageFeatureType
CoreML.Specification.ArrayFeatureType.Shape
CoreML.Specification.ArrayFeatureType.EnumeratedShapes
CoreML.Specification.ArrayFeatureType.ShapeRange
CoreML.Specification.ArrayFeatureType
CoreML.Specification.DictionaryFeatureType
CoreML.Specification.SequenceFeatureType
CoreML.Specification.FeatureType
Model revision number missing or invalid. Must be >= 2
Model output class label not set. Must have at least one class label
Model parameter data not set
, nodeID=
Setup routine called multiple times for treeId=
Unsupported type "
" for feature "
Should be of: 
 with data type of: 
Unsupported array type "
Unsupported array rank 
 should be in range [
MLFeatureTypeType_int64Type
MLFeatureTypeType_doubleType
MLFeatureTypeType_stringType
MLFeatureTypeType_imageType
MLFeatureTypeType_multiArrayType
MLFeatureTypeType_dictionaryType
MLFeatureTypeType_sequenceType
INVALID
MLArrayDataTypeFLOAT32
MLArrayDataTypeDOUBLE
MLArrayDataTypeINT32
MLArrayDataTypeFLOAT16
CustomModel must have non-empty className.
CustomModel.parameters must have non-empty string keys.
CustomModel.parameters['
'] does not have a set value
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/arena.cc
CHECK failed: (n) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/stubs/common.cc
INFO
WARNING
ERROR
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
parsing
serializing
 '%s'
String field
 contains invalid 
UTF-8 data when 
 a protocol 
buffer. Use the 'bytes' type if you intend to send raw 
bytes. 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
Exceeded maximum protobuf size of 2GB: 
parse
Can't 
 message of type "
" because it is missing required fields: 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
 was modified concurrently during serialization.
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
This shouldn't be called if all the sizes are equal.
%@: unable to initialize client due to soft-link failure
%@: namespace (%@) registration failed. %@
%@: download completion (%@): %d
%@: namespace (%@) download failed. %@
%@: namespace (%@) download timed out.
%@: unable to initialize download options due to soft-link failure
%@: failed to deregister namespace (%@). %@
%@: namespace (%@) updated
%@: unexpected update notification for namespace (%@)
%@: experimentId unexpectedly not returned
%@: set deployment id: %@
%@: missing factorLevel information: %@
%@: set %lu model entries
%@: unable to extract team identifier for the client. error:%@
Task must be a MLBackgroundPredictionTask or MLBackgroundModelUpdateTask.
Unable to archive task %@: %@
Failed to get tensor descriptor.ESRT: %s (%d)
The default initializer of MLMultiArray will be removed soon. Please don't use.
dataType %zd is not supported.
Failed to unarchive dataPointer.
shape's dimensions is zero.
shape's dimensions (%tu) is different from strides' dimensions (%tu).
dataPointer should be a buffer of size %zu but the unarchived buffer has size of %zu.
Unexpected error while calculating the expected buffer size: %s.
CVPixelBufferCreate failed with error code: %d
copyIntoMultiArray failed decoding MLMultiArray backed by a CVPixelBuffer. Code: %ld
Invalid dataType decoding MLMultiArray backed by a CVPixelBuffer. %@
Failed to allocate MLMultiArray. error: %s
shape is nil or empty.
scalars must be a non-empty array of NSNumbers.
MLMultiArray of shape: %@ should have %zu element(s), but the `scalars` argument has %td element(s).
Failed to lock pixel buffer with error: %d
Setting optimize parameter to use half precision
Failed to create CVPixelBuffer because CVPixelBufferPoolCreatePixelBuffer returned %d.
Faield to create a CVPixelBufferPool object for converting input pixel format type because CVPixelBufferPoolCreate returned %d.
Failed to initialize VTPixelTransferSession with error %i.
Failed to transfer a pixel buffer (IOSurface-backed: %s, format: %c%c%c%c) to destination pixel buffer [IOSurface-backed: %s: format: %c%c%c%c] with error %i.
The output backing for feature %@ uses %s, which is not MLMultiArray. It will fail when the inference engine populates the backing with the prediction.
The output backing for feature %@ must be CVPixelBuffer, but it is not. It will fail when the inference engine populates the backing with the prediction.
Finding model in: %s
Adding in-memory network to plan
File: %s not found.
espresso_context_set_int_option for ANE|CPU returned status = %d
Plan created, now adding network
Unable to set Espresso tracing name due to error: %d
Input feature %s required but not passed to neural network.
Unsupported input pixel format type `%c%c%c%c`.
Invalid multi-array data type: %08x.
Unsupported input feature type: %@
Unable to bind pixel buffer directly to the feature named %@ due to error: %d
Failed to lock CVPixelBuffer when binding input image with error: %d
Unexpected pixel format type %c%c%c%c
Failed to bind image through vImage with error: %d
Failed to bind the input buffer %@: %d
Espresso doesn't report the output shape; we cannot verify the output backing's shape. Error: %d
Failed to set shape of rank %zu to Espresso Buffer. Error: %d
The output backing MLMultiArray's shape (shape.count = %zu) doesn't match to Espresso's output shape (shape.count = %zu) even after squeezed. This is most likely a framework programming error.
Output backing for %@ is not compatible with the model's output feature description.
Output feature %@ doesn't have a description for the MultiArray constraints.
Output feature %@ doesn't have a description for the image constraints.
%@ image output feature must use a pixel buffer of kCVPixelFormatType_32BGRA as the output backing, but kCVPixelFormatType_32ARGB pixel buffer was specified.
Output backings cannot be used for a dynamic output feature: %@
Failed to directly bind output CVPixelBuffer for output feature: %@, with espresso error: %i. Continuing with non-direct output binding.
Forced automatic output backings was requested but we couldn't bind the fabricate output buffer for feature: %@
Error binding output buffer %s: %d
Failure verifying inputs.
Failure in resetSizes.
Error checking if an output blob is dynamic or not, %s: %d
Failed to create a pixel buffer for an automatic backing multi-array with shape %@
espresso_network_query_blob_shape couldn't get the output shape for feature: %s to fabricate the output backing buffer (err: %d). This is not expected but we go on without output backing.
espresso_buffer_pack_tensor_shape failed for feature: %s to fabricate the output backing buffer (err: %d). This is not expected but we go on without output backing.
espresso_network_query_blob_shape returned rank != 4 for image output. Unknown how to handle an image with rank: %lu, proceeding without output backing.
Output image feature uses unsupported color space (%tu). This is not expected but we go on without output backing.
Failed to create automatic backing pixel buffer for feature %@
Forced automatic output backings was requested but we couldn't fabricate the output buffer for feature: %@
Failure in -bindInputFeatures:bufferIndex:allocatedImageData:error:.
Failure in -updateDynamicOutputBlobIndicatorCacheAndReturnError:.
Failure in -completeOutputBackings:error:.
Failure in -bindOutputBuffers:outputBackings:error:.
Failure in -executePlan:error:.
Failure in binding outputs after calling execute sync.
Error computing NN outputs %d
Error computing NN outputs, caught unknown exception.
Runtime error in NN execution.
Error in computing user-provided custom layer during neural network evaluation.
Failure in binding dynamic outputs.
WARNING: The computed output shape does not match any output shape allowed in the model's description. Please update the model description.
Model description's MLMultiArrayConstraint states unknown data type (%ld), which should never happen.
MLNeuralNetworkEngine doesn't support MLImagePixelType %tu yet.
Failed to build clean before reshape.
Failure dynamically resizing for sequence length
Error in computing user-provided custom layer output shapes during neural network construction.
Failure dynamically resizing for sequence length.
Empty input feature dictionary passed to resetSizes.
Incorrect input number of dimensions %lul (must be 1, 3, or 5 dimensions.
Incorrect input number of dimensions %lul (must be 1 or greater)
Cannot evaluate a batch of size %d on GPU, which is larger than maximum of %d.
Cannot evaluate a sequence of length %d, which is longer than maximum of %d for bidirectional models.
Failure setting up to dynamically allocate for sequence size.
Error in passing image pre-processing parameters for %s to network.
Error in declaring input %d.
inputLayer: %s
Error in declaring output: %d.
outputLayer: %s
Error plan build: %d.
Hardware fall back after plan build failure.
Failure in resetSizes in batch computation.
Failure verifying input %@ in batch computation.
Failure in bindInputsAndOutputs in batch computation.
This model is not suitable for faster batch prediction, so it is falling back on a for-loop-based approach.
Called dumpTestVectors but configuration didn't specify enableTestVectorMode.
Profiler: MLNeuralNetworkEngine::executionSchedule
model-name:%slayer-name:%splatform:%s
Model Layer Info
Profiler: MLNeuralNetworkEngine::executionSchedule %lu layers
Model-signpost-id:%lluModel-name:%sModel-address:%lluEspresso-network-id:%llu
MLModel_Net_Discover
Error in adding network %d.
Failed to get shape from the tensor description. E5RT: %s (%d)
Failed to get strides from the tensor description. E5RT: %s (%d)
Failed to get data type of the tensor. E5RT: %s (%d)
Failed to get component size. E5RT: %s (%d)
Failed to get component data type. E5RT: %s (%d)
E5 tensor with componentSize = %d and componentDataType = %d is not supported.
%s thrown on construction
Error creating Core ML custom layer implementation from factory for layer "%s".
Core ML custom Layer implementation '%s' does not conform to the MLCustomLayer protocol.
Error getting Core ML custom layer output shapes for layer "%s".
Evaluation on Core ML custom layer "%s" called before the layer is constructed.
Error evaluating Core ML custom layer "%s" on CPU.
Core ML custom Layer implementation '%s' does not conform to the MLCustomLayer protocol'
Error initializing Core ML custom layer implementation with parameter dictionary for layer "%s".
Error setting weights in Core ML custom layer "%s".
Error evaluating Core ML custom layer "%s" on GPU.
Key blob is nil
Key Identifier is nil
Failed to persist Key Blob
MLModelAsset: load has already been run successfully.
MLModelAsset: load failed with error %@
MLModelAsset: load failed.
MLModelAsset: modelWithError: load failed with error %@
MLModelAsset: classifierWithError: load failed.
MLModelAsset: regressorWithError: load failed.
Failed to fetch Espresso Nets for compiled models at %@ with error %@
Failed to check cached ANE binary for compiled models at %@ with error %@
Failed to purge cached ANE binary for compiled models at %@ with error: %@
Model-name:%s
MLModel_Compile
The program argument to MLProgramTrainer is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
The program has no train function.
.inferenceModel property is not implemented yet. See rdar://81339842.
The trainable weights should be Float32, but it is %@.
The copyCurrentTrainingDelta failed to extract initial weights.
%@: modelPathStr=%@
%@: sandbox_extension_issue_file() returned NULL. path=%@
%@: sandboxExtensionToken=%@
Entered interruptionHandler!
Entered invalidationHandler!
Could not create connection to %@ : error=%@
Could not create secure model via XPC: error=%@
Could not predict from secure model via XPC: error=%@
Could not batch predict from secure model via XPC: error=%@
Could not obtain parameterValueForKey from secure model via XPC: error=%@
Incorrect number of classes given (TreeEnsembleClassifier).
Updating encrypted model %@ is not supported.
Model-name:%sParent-model-name:%s
MLModel_Load
Model-name:%sParent-model-name:%sModel-id:%llu
%@ class has successfully loaded the model at %s.
%@ class was unable to load the model at %s with error: %@; The model loader is going to use another class.
The program (%@) has no init function, which means all the functions are stateless. Do not try to create a context on such a program.
The provided input(s): [%@] does not exist in the %@ function.
The provided input(s) missing argument(s): [%@] for the %@ function.
This pipeline contains multiple sub-models with class labels. As a result, the classLabel property of the pipeline instance will not be populated.
Profiler: MLPipeline::executionSchedule %lu networks
Profiler: [schedule] Model in pipeline does not have a schedule
Failed to allocate MultiArrayBuffer with shape %s due to integer overflow
Failed to create URL from base directory %@ and the unique string %@
Failed to create a temporary directory at: %@. Error: %@
Failed to delete the temporary directory: %@. Error: %@
Failed to convert string %s to integer with exception message: %s. Fellback to 0.
Operation not supported on this platform.
Could not create decrypt session for %@ : error=%@
MLE5DirectMode has invalid value: %d
e5rt_io_port_is_tensor failed. E5RT: %s (%d)
e5rt_io_port_is_surface failed. E5RT: %s (%d)
The combination of port trait %@ and feature trait %@ is not supported.
The combination of port trait %@, feature trait %@, and direct bind mode %@ is not supported.
MultiArray shape %@ doesn't match the port's expected shape %@.
Failed to get width from E5 surface descriptor. E5RT: %s (%d)
Pixel buffer frame size %zu x %zu doesn't match the port's expected image size %zu x %zu.
Failed to get number of planes from E5 surface descriptor. E5RT: %s (%d)
The inference engine expects multi-planer format (plane count = %zu). CoreML doesn't support such models yet.
Failed to get buffer object's base pointer. E5RT: %s (%d)
Failed to create MLMultiArray: %@.
Failed to bind the input feature value.ESRT: %s (%d)
The port trait %@ is not supported.
The combination of port trait %@ and feature type %@ is not supported.
The combination of port trait %@, feature type %@, and direct bind mode %@ is not supported.
Failed to bind the output buffer object.ESRT: %s (%d)
Failed to bind the output surface object.ESRT: %s (%d)
MLE5Engine doesn't support MLImagePixelType %tu yet.
Failed to get E5 tensor descriptor. E5RT: %s (%d)
The port's shape is %@, which doesn't have enough dimensions to map width and height.
Failed to get E5 surface descriptor. E5RT: %s (%d)
Failed to allocate E5 buffer object. E5RT: %s (%d)
Failed to create E5 buffer object from IOSurface. E5RT: %s (%d)
Failed to create E5 surface object from surface descriptor. E5RT: %s (%d)
Explicit output backing is not implemented yet for the E5 engine
Fail to clean up path=%@, error=%@
Failed to list all output files with destURL=%@, error=%@
Failed to encrypt %@ with error=%@
Failed to store encryption information in compiled model with error=%@
Failed to encrypt file at URL: %@, to file at URL: %@
Failed to copy file from %@ to %@
Failed to remove file at URL: %@
Failed to create SC_Info at URL: %@
Failed to write SINF to URL: %@
Failed to write encryption info metadata.
Failed to get the home directory when checking model path.
Couldn't create os_log_t coreChannel
Unable to classify the input because the model description doesn't have predictedFeatureName property.
Unable to classify the input because the model description doesn't have class labels.
There must be at least one class to return.
MLMultiArray for class probabilities must be Float64 or Float32.
There is no output feature named %@.
Output feature named %@ is supposed to be a MLMultiArray representing class probabilities but it is %@.
Class probability feature named %@ has %tu classes, but there are %zd class labels.
Class probability feature named %@ must be a MLMultiArray of Float32 or Float64.
Class probability feature named %@ must be a contiguous MLMultiArray.
Unable to regress the input because the model description doesn't have predictedFeatureName property.
The predicted feature value for the regressor model must be a multi array but it was %@. This error should have been caught by the validator.
nil value for URL
Model-signpost-id:%lluModel-name:%sModel-address:%llu
MLModel_Generic_Discover
CoreMLModelSecurity function fetchKey completed
Fetching decryption key from server failed. Operation failed with error code %ld (%s)
Fetching decryption key from server failed. Key server responded back with error: %s
Fetching decryption key from server failed. Key response from server is not in the expected format.
Fetching decryption key from server failed: response with neither hasError nor hasSuccess.
Fetching decryption key from server timed out.
Creating a backup of .net file at location %@
The program argument to MLProgramEvaluator is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
.model property is not implemented yet. See rdar://86160890.
A Core ML custom neural network layer requires an implementation named '%s' which was not found in the global namespace.
A Core ML custom neural network layer implementation class named '%s' does not conform to the MLCustomLayer protocol.
Failed to create a stream. E5RT: %s (%d)
Failed to add operation to E5 stream. E5RT: %s (%d)
Failed to execute E5 stream.ESRT: %s (%d)
Failed to reset the stream. E5RT: %s (%d)
Could not create team identifier error=%@
Failed to prepare E5 execution stream operation for encode.ESRT: %s (%d)
The operation was never prepared or has been reset
Failed to build output feature provider with error %@.
Failed to create E5 execution stream operation. The library path was %s and the function name was %s.ESRT: %s (%d)
Failed to retain E5 execution stream operation input port %@ E5RT: %s (%d)
The input feature provider doesn't have a feature %@ or it is undefined.
Failed to get the number of inputs for operation. E5RT: %s (%d)
Failed to get input port names for operation. E5RT: %s (%d)
Failed to get the number of outputs for operation E5RT: %s (%d)
Failed to get output port names for operation. E5RT: %s (%d)
Error computing shape information for Neural Network model. This model may be invalid.
IMPORTANT: new sequence length computation failed, falling back to old path.
Model requires sequence length greater than %d
Error in neural network compiler computing minimum sequence length.
Invalid height and width for the image input.
Input MLMultiArray cannot be %d dimensional (must be between 1 and 5 dimensions).
Input MLMultiArray cannot be %d dimensional (must have at least 1 dimension).
Unsupported Engine type %d.
Cannot create context, Caught exception: %s
IOS 11 Legacy code found sequence length %d
Image descripition included empty set of enumerated sizes
Using the default size
Image descripition width and height and are not valid according to the enumerated sizes
Changing default height and width to be the first enumerated size
Image descripition width and height and are not valid according to the specified flexible ranges
Changing default height and width to minimum size in range
Model does not exist at %@
Failed to read model package at %@. Error: %s
%{public}@: There must be at least %tu features, but there is only %tu.
%{public}@: There must be at most %tu features, but there is %tu.
%{public}@: The feature type must be one of {%{public}@}, but it is %{public}@.
updateType can only be used for personalization use case while the current use case is not personalization. This parameter is ignored.
File %s: error unmapping memory; msg=%{errno}d
Value for %@ must respond to 'unsignedIntegerValue' selector. Will default to VNImageCropAndScaleOptionScaleFill = 2
This method should not be called on the main thread as it may lead to UI unresponsiveness.
Error compiling updatable model.
%@ watchdog timer timeout
Watchdog timer timeout
softlink:r:path:/System/Library/PrivateFrameworks/Trial.framework/Trial
softlink:r:path:/System/Library/PrivateFrameworks/TrialProto.framework/TrialProto
softlink:r:path:/System/Library/PrivateFrameworks/XGBoostFramework.framework/XGBoostFramework
softlink:r:path:/System/Library/PrivateFrameworks/XGBoostFramework.framework/XGBoostFramework
MLClassifier
MLModeling
MLE5ExecutionStreamOperationPool
_MLDataSource
ETDataProvider
NSObject
MLCompilerEvent
CUTCoreAnalyticsMetric
CUTMetric
MLDictionaryConstraint
MLFeatureValueConstraint
NSSecureCoding
NSCoding
NSCopying
MLParameterUtils
MLSubtractBroadcastableBrick
EspressoBrick
MLTransposeBrick
_MLSNFrameworkHandle
MLE5InputPortBinder
MLE5PortBinder
_MLNLPSentenceClassifierModel
MLCustomModel
ModelKeyServerAPIFetchKeyResult
MLModelCollection
MLSplitNDBrick
MLBackgroundTask
MLBackgroundPredictionTask
MLTileBrick
MLLocalOutlierFactor
MLStackNDBrick
MLE5Utils
MLImageSize
MLAddBroadcastableBrick
MLSoftmaxNDBrick
MLAppleGazetteerParameters
MLAppleGazetteer
MLModelSpecificationLoader
MLMultiArrayUtils
MLMultiArray
ScopedBufferAccess
Attributes
PrivateConstruction
CopyingAndVectorization
ConvenientConstruction
Concatenating
Filling
MLMultiArrayAsNSArrayWrapper
MLMultiArrayView
Views
RawAccess
MLCompilerNeuralNetworkOutput
QuickLook
MLParameterDescription
Utilities
MLSVREngine
ModelConstructible
ImageUtils
MLModelErrorUtils
MLNeuralNetworkCompiler
MLSpecificationCompiler
MLNeuralNetworkContainer
PixelBufferPoolKey
MLNeuralNetworkEngine
MLNeuralNetwork
MLRegressor
MLCompiledModelLoader
MLParameterKey
MLLinkedModelParameters
MLScopedParameters
MLNeuralNetworkParameters
MLTreeEnsmebleModelParameters
MLCustomModelLoader
MLCustomModelWrapper
MLModelConfiguration
MLE5ExecutionStreamPool
ModelKeyServerAPIRawKey
MLSVRLoader
MLLayerExecutionSchedule
MLSineBrick
MLArrayBatchProvider
MLBatchProvider
MLKNearestNeighborsClassifier
MLUpdatable
MLWritable
MLMultiplyBroadcastableBrick
MLModelDescription
MLCosineBrick
ModelSpecification
MLPipelineClassifier
MLMultiArrayShapeConstraint
MLErfActivationBrick
MLItemSimilarityRecommender
MLObjectBoundingBoxOutputDescription
MLObjectBoundingBoxOutput
MLComputeDataSource
Model
MLE5IOPort
MLNeuralNetworkMLComputeUpdateEngine
MLIdentity
MLVersionInfo
MLParameterContainer
MLKey
MLUpdateContext
ModelKeyServerAPIFetchKeyResponse
MLSVMEngine
MLCustomLayer
MLCustomLayerWrapper
MLPersistentKeyStorage
MLFeatureProviderUtils
MLLazyUnionFeatureProvider
MLFeatureProvider
MLNewProviderConstruction
MLTreeEnsembleRegressor
ModelAsset
MLImageConstraint
MLModelAsset
MLFloorBrick
MLFeatureValue
MLBatchedMatMulBrick
MLProgramInternal
MLProgram
MLProgramTrainer
MLWrappedModel
MLWritableWrappedModel
MLDivideBroadcastableBrick
_MLVNScenePrintCustomModel
MLPowBroadcastableBrick
MLArchivingUtils
_MLNLPWordTaggingModel
MLModelTypeRegistry
MLNeuralNetworkUpdateEngine
_MLVNFrameworkHandle
CoreMLModelSecurityProtocol
CoreMLModelSecurityServiceToClientProtocol
MLSecureModel
MLSecureModelDecryptCredential
CoreMLModelSecurityServiceToClient
MLArrayDictionaryFeatureProvider
MLTreeEnsembleClassifier
MLComputeBatchDataSource
MLComputeDataProvider
_MLSNVGGishFeatureEmbedding
MLLoader
_NNLayerInfo
_OnDiskArchiveReader
_ArchiveReader
_InMemoryArchiveReader
MLNeuralNetworkV1Container
MLMultiFunctionProgramContainer
MLMultiFunctionProgramEngine
MLRangeBrick
MLExpBrick
ModelKeyServerAPIFetchKeyRequest
MLCeilBrick
MLFeatureDescription
MLNearestNeighborsLinearIndex
MLNearestNeighborsIndex
MLModelVisionFeaturePrintInfo
MLPipeline
MLSupportVectorRegressor
MLGLMRegression
MLProgramContext
CoreMLVersion
_MLSNVGGishFrontendProcessing
MLTemporaryDirectory
MLAppleAudioFeatureExtractorSoundPrintParameters
MLAppleAudioFeatureExtractorParameters
MLAppleAudioFeatureExtractor
MLModelExecutionSchedule
MLProgramTrainingDelta
MLLoaderEventExtensions
MLLoaderEvent
MLGatherBrick
MLBroadcastToBrick
MLGKDecisionTree
MLReporter
CUTMetricLogger
MLReporterUtils
MLSliceNDBrick
MLSequence
MLSequnceAsFeatureValueArray
MLFeatureValueAccess
_MLBatchDataSource
MLFairPlayDecryptSessionManager
MLFairPlayDecryptSession
_MLSNSoundPrint
MLGeluActivationBrick
MLKNearestNeighborsClassifierParameters
MLE5OutputPortBinder
MLBackgroundRunner
_DASExtensionRunner
MLCompilerOptions
MLCompilerResult
MLCompiler
Internal
MLModelSpecificationSaver
MLSaver
MLLogging
MLUpdateProgressHandlersUtils
MLUpdateProgressHandlers
MLModelCollectionEntry
MLE5Engine
MLMetricKey
MLModel
MLAppleImageFeatureExtractorScenePrintParameters
MLAppleImageFeatureExtractorObjectPrintParameters
MLAppleImageFeatureExtractorParameters
MLAppleImageFeatureExtractor
ExternalReferenceFlatteningAddition
MLTreeEnsembleXGBoostClassifier
MLRegressorResult
MLDataConversionUtils
MLNeuralNetworkUpdateUtils
MLFeatureTypeUtils
MLLinkedModel
MLNumericConstraint
MessageMutation
CKCodeOperationMessageMutation
MLCloudSession
_MLInternalNLPModelWriter
MLNNLayerComputeUnitSelectionUtils
InternalCustomTileLike
MLModelEncryptionUtils
MLDictionaryFeatureProvider
NSFastEnumeration
FromGenericFeatureProvider
MLPipelineRegressor
MLSupportVectorClassifier
MLKeyManager
MLPipelineUpdateEngine
MLProgramContainer
MLNeuralNetworkV1Engine
MLClassifierResult
_MLVNDetectionPrintCustomModel
MLSlidingWindowsBrick
MLNeuralNetworksCompileTimeParams
ModelKeyServerAPIResultError
MLAppleTextClassifierParameters
MLAppleTextClassifier
MLPipelineLoader
MLProgramEvaluator
_KDNode
MLNearestNeighborsSingleKdTreeIndex
MLShufflingBatchProvider
MLDefaultCustomLayerFactory
MLCustomLayerFactory
MLProgramEvaluationResult
MLNonMaximumSuppressionParameters
MLNonMaximumSuppression
MLClipBrick
MLE5ExecutionStream
InternalCustomGatherTree
MLProgramEngine
MLUpdateTask
MLTaskStateTransitionDelegate
_MLNLPFrameworkHandle
MLCloudDeploymentUtils
MLFeatureFlags
MLPredictionEvent
MLPredictionOptions
MLAppleWordTaggerParameters
MLAppleWordTagger
MLBatchProviderUtils
MLLazyUnionBatchProvider
MLWindowedBatchProvider
MLIndexedBatchProvider
MLNewBatchConstruction
MLBatchCopyToMultiArray
MLConcatNDBrick
ModelKeyServerAPISignedKey
MLSVMLoader
MLE5ExecutionStreamOperation
MLAppleSoundAnalysisPreprocessing
MLImputer
MLSupervisedOnlineUpdateOptions
MLModelIOUtils
MLGLMClassification
MLSequenceConstraint
MLFairPlayKeyLoadingSession
MLModelDescriptionUtils
MLTreeEnsembleXGBoostUpdateEngine
MLModelMetadata
MLFeatureVectorizer
MLImageConversion
MLDictVectorizer
MLModelCompilation
MLFillBrick
MLNormalizer
MLAppleWordEmbeddingParameters
MLAppleWordEmbedding
MLTask
MLCategoricalMapping
MLScaler
SpecConstructible
MLOneHotEncoder
MLInternalSettings
MLBayesianProbitRegression
MLSupervisedOnlineUpdatable
MLProbabilityDictionarySharedKeySet
MLProbabilityDictionaryMultiArrayStorage
MLProbabilityDictionaryStorage
MLProbabilityDictionaryFloat64Storage
MLProbabilityDictionaryArrayStorage
MLProbabilityDictionary
MLLayerPath
MLMultiArrayConstraint
MLImageSizeConstraint
ClosestAllowedSize
MLArrayFeatureExtractor
MLBackgroundWatchdog
validateAsClassifierDescriptionAndReturnError:
initWithDescription:configuration:
defaultOptions
predictionFromFeatures:classifier:options:error:
genericErrorWithFormat:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionsFromBatch:error:
predictionsFromBatch:options:error:
executionSchedule
setModelPath:modelName:
modelPath
modelDescription
setModelDescription:
metadata
T@"MLModelDescription",&,N
T@"MLModelMetadata",R
classLabels
classify:options:error:
initWithDescription:configuration:error:
raise:format:
init
copy
serialQueue
pool
anyObject
e5BundleURL
functionName
outputDescriptionsByName
initWithContentsOfURL:functionName:outputDescriptionsByName:debugLabel:
removeObject:
addObject:
initWithE5BundleAtURL:functionName:outputDescriptionsByName:
takeOut
putBack:
.cxx_destruct
_e5BundleURL
_functionName
_outputDescriptionsByName
_pool
_serialQueue
T@"NSURL",R,C,V_e5BundleURL
T@"NSString",R,V_functionName
T@"NSDictionary",R,V_outputDescriptionsByName
T@"NSMutableSet",R,V_pool
T@"NSObject<OS_dispatch_queue>",R,V_serialQueue
inputDescriptionsByName
trainingInputDescriptionsByName
dictionary
espressoInputShapes
dictionaryWithDictionary:
espressoInputStrides
allKeys
countByEnumeratingWithState:objects:count:
featureValueForName:
objectForKeyedSubscript:
isOptional
type
multiArrayValue
shape
count
sequenceConcatConsumesOptionalInputNamed:
multiArrayConstraint
initWithShape:dataType:error:
fillWithNumber:
featureValueWithMultiArray:
ndArrayInterpretation
objectAtIndexedSubscript:
arrayWithObjects:count:
arrayWithArray:
setObject:atIndexedSubscript:
errorWithCode:underlyingError:format:
predictedFeatureName
isEqualToString:
lossTargetName
isAllowedValue:isNeuralNetworkInputOrOutput:usingRank5Mapping:featureName:error:
errorWithCode:format:
copyIntoMultiArray:error:
populateEspressoShapeAndStridesFromInputShape:ndRepresentation:espressoShape:espressoStrides:error:
setObject:forKeyedSubscript:
mutableBytes
initWithData:type:shape:strides:
stringByAppendingString:
imageConstraint
isAllowedValue:error:
imageBufferValue
imagePreprocessingParameters
initWithCVPixelBuffer:imageParameters:error:
classLabelToIndexMap
stringValue
int64Value
numberWithLongLong:
setEspressoInputShapes:
setEspressoInputStrides:
dataTensorDictionary
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
dataPointAtIndex:error:
numberOfDataPoints
prepareForEpoch
initWithMLFeatureProvider:forPrediction:neuralNetworkEngine:error:
setDataTensorDictionary:
_dataTensorDictionary
T@"NSDictionary",&,N,V_dataTensorDictionary
modelName
modelHash
modelType
modelOrigin
modelVersion
modelCompiledWithVersion
compilerVersion
milUpgradeStatus
milUpgradeFailureReason
name
T@"NSString",R
dictionaryRepresentation
T@"NSDictionary",R
setModelName:
setModelHash:
setModelType:
setModelOrigin:
setModelVersion:
setModelCompiledWithVersion:
setCompilerVersion:
setMilUpgradeStatus:
setMilUpgradeFailureReason:
_modelName
_modelHash
_modelType
_modelOrigin
_modelVersion
_modelCompiledWithVersion
_compilerVersion
_milUpgradeStatus
_milUpgradeFailureReason
T@"NSString",C,N,V_modelName
T@"NSString",C,N,V_modelHash
T@"NSNumber",C,N,V_modelType
T@"NSNumber",C,N,V_modelOrigin
T@"NSString",C,N,V_modelVersion
T@"NSString",C,N,V_modelCompiledWithVersion
T@"NSString",C,N,V_compilerVersion
T@"NSNumber",C,N,V_milUpgradeStatus
T@"NSString",C,N,V_milUpgradeFailureReason
initWithKeyType:
isUndefined
dictionaryValue
featureTypeErrorWithFormat:
descriptionForType:
allocWithZone:
stringWithFormat:
keyType
encodeInteger:forKey:
decodeIntegerForKey:
constraintWithStringKeys
constraintWithInt64Keys
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
_keyType
Tq,R,N,V_keyType
objectForKey:class:dictionary:
mutableCopy
hasGlobalScope
deletingPrefixingScope:
parameterDescriptionsByKey
setParameterDescriptionsByKey:
stringForKey:inDictionary:
numberForKey:inDictionary:
deScopeParameters:byDeletingPrefixingScope:
appendParameterDescriptions:toModelDescription:
unsignedIntegerValue
integerValue
rawPointer
setupForInputShapes:withParameters:
initWithParameters:
hasGPUSupport
setMappedWeights:sizeInBytes:
computeOnCPUWithInputTensors:outputTensors:
encodeToMetalCommandBuffer:inputTensors:outputTensors:
hasDynamicOutputShape:
computeDynamicOutputShape:
shapeInfoNeeded
inputRanks
outputRanks
inputShapes
outputShapes
_shapeInfoNeeded
_inputRanks
_outputRanks
_inputShapes
_outputShapes
TB,R,N,V_shapeInfoNeeded
T@"NSArray",R,N,V_inputRanks
T@"NSArray",R,N,V_outputRanks
T@"NSArray",R,N,V_inputShapes
T@"NSArray",R,N,V_outputShapes
setSequence:
setBatch:
setChannels:
setHeight:
setWidth:
intValue
setRank:
width
height
channels
batch
sequence
axes
_axes
T@"NSArray",R,N,V_axes
sharedHandle
setFeatureValue:
portHandle
featureValue
T@"MLFeatureValue",R
initWithPort:
bindFeatureValue:error:
_portHandle
_featureValue
T^{e5rt_io_port=},R,V_portHandle
T@"MLFeatureValue",&,V_featureValue
isValid
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
allValues
initializeSentenceClassifierModelWithData:error:
dealloc
predictLabelsForSentenceString:inputString:error:
initWithDictionary:error:
initWithModelDescription:parameterDictionary:error:
_sentenceClassifierModel
_modelDescription
T@"MLModelDescription",&,V_modelDescription
clearOneofValuesForKey
setObject:forKey:
setKeyId:
setTeamId:
setSignedKey:
setRawKey:
mergeFrom:
hasKeyId
hasModelName
hasTeamId
hasSignedKey
hasRawKey
setKey:
setHasKey:
hasKey
keyAsString:
StringAsKey:
readFrom:
writeTo:
copyTo:
keyId
teamId
signedKey
rawKey
_key
_keyId
_rawKey
_signedKey
_teamId
_has
TB,R,N
T@"NSString",&,N,V_keyId
T@"NSString",&,N,V_modelName
T@"NSString",&,N,V_teamId
T@"ModelKeyServerAPISignedKey",&,N,V_signedKey
T@"ModelKeyServerAPIRawKey",&,N,V_rawKey
TB,N
Ti,N,V_key
progressWithTotalUnitCount:
setCancellable:
setPausable:
addChild:withPendingUnitCount:
setCompletedUnitCount:
errorWithCode:underlyingError:format:args:
length
initWithIdentifier:
identifier
_register
_downloadWithProgress:
_populateEntries
_setDeploymentID
_registerForUpdates
_endAccess
_namespaceNameFromCollectionIdentifier:
getTrialClientClass
clientWithIdentifier:
coreChannel
trialClient
namespaceName
registerNamespaceName:compatibilityVersion:defaultsFileURL:applicationGroup:cloudKitContainerId:error:
_downloadOptions
downloadNamespaceWithName:options:progress:completion:
getTrialDownloadOptionsClass
setAllowsCellularAccess:
setDiscretionaryBehavior:
_handleTrialUpdateForNamespaceName:
addUpdateHandlerForNamespaceName:usingBlock:
deregisterNamespaceName:error:
defaultCenter
postNotificationName:object:
experimentIdentifiersWithNamespaceName:
experimentId
setDeploymentID:
deploymentID
refresh
factorLevelsWithNamespaceName:
setEntries:
factor
level
directoryValue
path
fileURLWithPath:
entryWithModelIdentifier:modelURL:
entries
extractTeamIdentifierAndReturnError:
beginAccessingModelCollectionWithIdentifier:completionHandler:
endAccessingModelCollectionWithIdentifier:completionHandler:
getTrialExperimentIdentifiersClass
getTrialFactorLevelClass
getTrialLevelClass
getTrialFileClass
getTrialFactorClass
_identifier
_entries
_deploymentID
_namespaceName
_trialClient
T@"NSDictionary",C,N,V_entries
T@"NSString",C,N,V_deploymentID
T@"NSString",R,N,V_namespaceName
T@"TRIClient",R,N,V_trialClient
T@"NSString",R,C,N,V_identifier
numberWithUnsignedLong:
axis
numSplits
splitSizes
_axis
_numSplits
_splitSizes
T@"NSNumber",R,N,V_axis
T@"NSNumber",R,N,V_numSplits
T@"NSArray",R,N,V_splitSizes
archivedDataWithRootObject:requiringSecureCoding:error:
taskIdentifier
encodeObject:forKey:
decodeObjectOfClass:forKey:
setTaskIdentifier:
scheduleTask:
cancelTaskWithIdentifier:
cancelAllTasks
taskIsScheduledWithIdentifier:
activityForScheduling
_taskIdentifier
T@"NSString",C,N,V_taskIdentifier
setModelURL:
setModelConfiguration:
setPredictionOptions:
taskRunnerClass
modelURL
modelConfiguration
predictionOptions
_modelURL
_modelConfiguration
_predictionOptions
T@"NSURL",C,N,V_modelURL
T@"MLModelConfiguration",C,N,V_modelConfiguration
T@"MLPredictionOptions",C,N,V_predictionOptions
reps
_reps
T@"NSArray",R,N,V_reps
modelWithContentsOfURL:error:
numberOfNeighbors
parameterValueForKey:error:
featureDescriptionWithName:type:optional:constraints:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
configuration
numberOfDimensions
index
dataPointCount
parameters
parameterErrorWithUnderlyingError:format:
parameterContainerFor:descriptions:
numberWithUnsignedInteger:
setCurrentValue:forKey:error:
findNearestNeighbors:toQueryPoint:
updateToValidDistance:
findNearestNeighbors:toIndex:
findNearestNeighborsToIndex:
kDistanceToIndex:
localReachabilityDensityOfNeighbors:
findNearestNeighborsToQueryPoint:
floatValue
localReachabilityDensityForIndex:
localReachabilityDensityForQeuryPoint:
firstObject
predictionEvent
signpostID
parentSignpostID
inputMultiArray:error:
computeLOFForQueryPoint:
numberWithDouble:
initWithFeatureValueDictionary:
currentParameterValues
initWithKNearestNeighborsModelAtURL:configuration:error:
.cxx_construct
_index
_numberOfDimensions
_numberOfNeighbors
_cachedKDistances
_parameterContainer
maybeLogPredictionEvent:
initWithDataPointer:shape:dataType:strides:deallocator:error:
multiArrayOwningBufferObjectOfPort:error:
pixelsWide
pixelsHigh
isEqualToImageSize:
numberWithInteger:
initWithPixelsWide:pixelsHigh:
_pixelsWide
_pixelsHigh
Tq,R,V_pixelsWide
Tq,R,V_pixelsHigh
outputWithMILProgram:
defaultManager
fileExistsAtPath:
removeItemAtPath:error:
copyItemAtPath:toPath:error:
localizedDescription
UTF8String
defaultCStringEncoding
stringWithCString:encoding:
stringByAppendingPathComponent:
initWithData:language:inputFeatureName:outputFeatureName:modelData:labelNames:metadata:error:
revision
setRevision:
language
setLanguage:
inputFeatureName
setInputFeatureName:
outputFeatureName
setOutputFeatureName:
modelParameterData
setModelParameterData:
labelNames
setLabelNames:
setMetadata:
_revision
_language
_inputFeatureName
_outputFeatureName
_modelParameterData
_labelNames
_metadata
TQ,V_revision
T@"NSString",&,V_language
T@"NSString",&,V_inputFeatureName
T@"NSString",&,V_outputFeatureName
T@"NSData",&,V_modelParameterData
T@"NSArray",&,V_labelNames
T@"NSDictionary",&,V_metadata
IOErrorWithFormat:
initWithModelDescriptionSpecification:error:
stringWithUTF8String:
setClassLabels:
dataWithBytes:length:
initWithParameters:modelDescription:nlpHandle:configuration:error:
initializeGazetteerModelWithData:error:
enableInstrumentsTracingIfNeeded
predictLabelForWordString:inputString:error:
bytes
stringByAppendingFormat:
stringByReplacingCharactersInRange:withString:
fileSystemRepresentation
loadModelFromSpecification:configuration:error:
saveAppleGazetteerModelToURL:gazetteerParameters:error:
gazetteerModel
_parameters
T@"MLAppleGazetteerParameters",R,V_parameters
stringForDataType:
initWithShape:dataType:storageOrder:error:
initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:
unsignedIntValue
enumerateObjectsUsingBlock:
componentsJoinedByString:
initWithMultiArrayBuffer:
numberOfBytesPerElement
dataType
numberWithFloat:
numberWithInt:
getBytesWithHandler:
doubleValue
getMutableBytesWithHandler:
numberAtOffset:
setNumber:atOffset:
offsetForKeyedSubscript:
string
appendString:
appendFormat:
encodeInt:forKey:
strides
pixelBuffer
encodeBool:forKey:
encodeBytes:length:forKey:
decodeIntForKey:
decodeBytesForKey:returnedLength:
decodeArrayOfObjectsOfClass:forKey:
decodeBoolForKey:
initWithPixelBuffer:shape:
code
dataPointer
_storageManager
_shape
T^v,R,N
Tq,R,N
T@"NSArray",R,N,V_shape
T@"NSArray",R,N
T^{__CVBuffer=},R,N
cppStorageOrder:
isEqualToMultiArray:
isContiguous
isContiguousInOrder:
doublePointer
float32Pointer
Tr^v,R,N
TQ,R,N
contiguous
TB,R,N,GisContiguous
_shapeOfNestedArray:error:
exceptionWithName:reason:userInfo:
indexOfObjectPassingTest:
initWithShape:dataType:storageOrder:bufferAlignment:
initWithBytesNoCopy:shape:dataType:strides:mutableShapedBufferProvider:
initWithArray:dataType:
initWithScalars:shape:dataType:
validateNestedArray:error:
vectorizeIntoMultiArray:storageOrder:error:
getShapeOfArrayOfSameLengthArrays:numberOfRows:numberOfColumns:error:
doubleMultiArrayWithCopyOfMultiArray:
doubleVectorWithValues:
doubleMultiArrayWithShape:valueArray:error:
doubleMatrixWithValues:error:
float32MatrixWithValues:error:
validateMultiArrays:forConcatenatingAlongAxis:normalizedAxis:reason:
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
initWrappingMultiArray:
setRangeWithRawData:destIndex:error:
numberArray
objectAtIndex:
multiArray
setMultiArray:
_multiArray
T@"MLMultiArray",&,V_multiArray
isSqueezableShape:
squeezeShape:strides:resultingShape:resultingStrides:
isSqueezableShape:dimensions:
indexSet
addIndex:
removeObjectsAtIndexes:
addObjectsFromArray:
insertObject:atIndex:
subarrayWithRange:
initSlicingMultiArray:origin:shape:squeeze:error:
initSqueezingMultiArray:dimensions:error:
initExpandingDimensionsOfMultiArray:axis:
parent
_parent
T@"MLMultiArray",R,N,V_parent
sliceAtOrigin:shape:squeeze:error:
squeeze
squeezeDimensions:error:
multiArrayViewExpandingDimensionsAtAxis:
multiArrayBuffer
unsignedLongLongValue
arrayWithCapacity:
lastObject
initWithEspressoNetwork:
initWithMILProgram:
outputWithEspressoNetwork:
network
program
_network
_program
T{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}},R,N,V_network
T{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}},R,N,V_program
debugQuickLookObject
setDefaultValue:
setNumericConstraint:
defaultValue
numericConstraint
allowedClasses
unionSet:
decodeTopLevelObjectOfClasses:forKey:error:
parameterDescriptionForKey:defaultValue:numericConstraint:
_defaultValue
_numericConstraint
T@"MLParameterKey",&,N,V_key
T@,&,N,V_defaultValue
T@"MLNumericConstraint",&,N,V_numericConstraint
dictionaryWithCapacity:
additionalFeatures
initWithFeatureProvider:
predictedValue
featureValueWithDouble:
asFeatureDictionaryWithPredictedValueDescription:
regress:options:error:
predictedValueFeatureDescription
resultWithValue:additionalFeatures:
regressorResultFromOutputFeatures:error:
predictionFromFeatures:regressor:options:error:
initWithSVMModel:freeOnDealloc:isInputSizeLowerBoundOnly:inputSize:
allocSVMNodeVector:
fillSVMNodeVector:values:count:
deallocSVMNodeVector:
initWithLibSVMFile:
predict:
isInputSizeLowerBoundOnly
inputSize
model
setModel:
freeModelOnDealloc
setFreeModelOnDealloc:
_isInputSizeLowerBoundOnly
_freeModelOnDealloc
_inputSize
_model
T^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii},V_model
TB,V_freeModelOnDealloc
TB,R,V_isInputSizeLowerBoundOnly
TQ,R,V_inputSize
renderToOneComponent8PixelBuffer:error:
renderToOneComponent16HalfPixelBuffer:error:
getContiguousFirstMajorFloat32BufferWithHandler:
numberWithLong:
renderTo32BGRAPixelBuffer:channelOrderIsBGR:error:
renderToCVPixelBuffer:channelOrderIsBGR:error:
pixelBufferGray8FromMultiArrayHW:error:
pixelBufferGray16HalfFromMultiArrayHW:error:
pixelBufferBGRA8FromMultiArrayCHW:channelOrderIsBGR:error:
initWithFormat:arguments:
errorWithIntegerCode:underlyingError:format:args:
errorWithCode:format:args:
privateErrorWithCode:underlyingError:format:args:
updateErrorWithFormat:
programValidationAtLoadErrorWithReason:format:
programParsingAtLoadErrorWithReason:format:
customLayerErrorWithUnderlyingError:withFormat:
modelEncryptionErrorWithUnderlyingError:format:
modelDecryptionKeyFetchErrorWithUnderlyingError:format:
modelDecryptionErrorWithUnderlyingError:format:
programEvaluationErrorWithUnderlyingError:format:
URLByAppendingPathComponent:
hashFileAt:error:
numberWithUnsignedLongLong:
collectEspressoModelDetails:modelPath:
archiveModelDetails:withName:toArchive:error:
serializeMetadataAndInterfaceFromSpecification:archive:error:
collectNNModelDetailsFromArchive:spec:error:
versionInfoWithMajor:minor:patch:variant:
compileSpecification:toArchive:options:error:
compiledVersionForSpecification:options:error:
resultWithArchive:
trainWithMLCompute
specURL
URLByDeletingLastPathComponent
versionInfo
versionString
bundleWithIdentifier:
infoDictionary
valueForKey:
initWithFilePath:inputLayerNames:outputLayerNames:parameters:
majorVersion
versionNumberString
deserializeMetadataAndInterfaceFromArchive:error:
readIsClassifier:
olderThan:
initWithFeatureDescriptions:transformDesc:outputLayerNames:classScoreVectorName:classLabels:isEncrypted:modelVersionInfo:compilerVersionInfo:
containerFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
containerFromFilePath:inputLayerNames:outputLayerNames:parameters:
containerFromCompiledArchiveCommon:filename:modelVersionInfo:compilerVersionInfo:configuration:error:
initWithFeatureDescriptions:transformDesc:outputLayerNames:classScoreVectorName:classLabels:isEncrypted:modelVersionInfo:
activeFunction
modelFilePath
setModelFilePath:
inputLayerNames
setInputLayerNames:
outputLayerNames
setOutputLayerNames:
setName:
inputDescription
setInputDescription:
outputDescription
setOutputDescription:
imageParameters
setImageParameters:
imagePreprocessingParams
setImagePreprocessingParams:
configurationList
setConfigurationList:
hasBidirectionalLayer
setHasBidirectionalLayer:
hasOptionalInputSequenceConcat
setHasOptionalInputSequenceConcat:
hasDynamicLayer
setHasDynamicLayer:
classScoreVectorName
setClassScoreVectorName:
transformDesc
setTransformDesc:
setNdArrayInterpretation:
updatableModelCompiledParams
setUpdatableModelCompiledParams:
optionalInputDefaultValues
setOptionalInputDefaultValues:
modelIsEncrypted
setModelIsEncrypted:
modelVersionInfo
setModelVersionInfo:
modelIsMIL
setModelIsMIL:
modelIsTrainingProgram
setModelIsTrainingProgram:
precision
setPrecision:
engine
setEngine:
optionalInputTypes
setOptionalInputTypes:
compilerVersionInfo
setCompilerVersionInfo:
compilerOutput
setCompilerOutput:
widths
heights
batches
sequences
ranks
_hasBidirectionalLayer
_hasOptionalInputSequenceConcat
_hasDynamicLayer
_ndArrayInterpretation
_modelIsEncrypted
_modelIsMIL
_modelIsTrainingProgram
_precision
_engine
_modelFilePath
_inputLayerNames
_outputLayerNames
_name
_inputDescription
_outputDescription
_imageParameters
_imagePreprocessingParams
_configurationList
_classLabels
_classScoreVectorName
_transformDesc
_updatableModelCompiledParams
_optionalInputDefaultValues
_modelVersionInfo
_optionalInputTypes
_compilerVersionInfo
_compilerOutput
Ti,N,V_precision
Ti,N,V_engine
T@"NSArray",&,N,V_outputLayerNames
T@"NSArray",&,N,V_inputLayerNames
T@"NSDictionary",&,N,V_optionalInputTypes
T@"MLVersionInfo",&,N,V_compilerVersionInfo
T@"NSString",R,N
T@"MLCompilerNeuralNetworkOutput",&,N,V_compilerOutput
T@"NSString",&,N,V_modelFilePath
T@"NSString",&,N,V_name
T@"NSDictionary",&,N,V_inputDescription
T@"NSDictionary",&,N,V_outputDescription
T@"NSDictionary",&,N,V_imageParameters
T@"NSDictionary",&,N,V_imagePreprocessingParams
T@"NSArray",&,N,V_configurationList
TB,N,V_hasBidirectionalLayer
TB,N,V_hasOptionalInputSequenceConcat
TB,N,V_hasDynamicLayer
T@"NSArray",&,V_classLabels
T@"NSString",&,V_classScoreVectorName
T@"MLModel",&,V_transformDesc
TB,V_ndArrayInterpretation
T@"MLNeuralNetworksCompileTimeParams",&,N,V_updatableModelCompiledParams
T@"NSDictionary",&,N,V_optionalInputDefaultValues
TB,N,V_modelIsEncrypted
T@"MLVersionInfo",&,N,V_modelVersionInfo
TB,N,V_modelIsMIL
TB,N,V_modelIsTrainingProgram
frameSize
pixelFormatType
initWithSize:pixelFormatType:
_pixelFormatType
_frameSize
T{CGSize=dd},R,V_frameSize
TI,R,V_pixelFormatType
classifyTopK
initWithCapacity:
initWithLabels:probabilities:
probabilityDictionarySharedKeySet
initWithSharedKeySet:probabilities:
classLabelOfMaxProbability
resultWithClassProbability:additionalFeatures:classLabelOfMaxProbability:
convertPredictionToClassifierResult:withOptions:error:
predictedClassFeatureDescription
classProbabilityFeatureDescription
asFeatureDictionaryWithPredictedClassDescription:classProbabilityDescription:
resultWithValue:
initWithUTF8String:
copyPixelBufferFromPixelBuffer:usingPixelFormat:
featureValueWithPixelBuffer:
pixelBufferPoolWithSize:pixelFormat:
transferPixelBuffer:toPixelBuffer:
numberWithUnsignedInt:
inputBlobNameToLastBackingMode
outputBlobNameToLastBackingMode
containerClass
initWithContainer:configuration:error:
predictionUsesCPU
globalSettings
restrictNeuralNetworksToUseCPUOnly
computeUnits
_deallocContextAndPlan
_setupContextAndPlanWithForceCPU:error:
neuralNetworkFromContainer:configuration:error:
_espressoDeviceForConfiguration:error:
gpuEngine
deviceHasANE
sharedKeySetForLabels:
boolValue
allowBackgroundGPUCompute
collectParametersFromContainer:configuration:error:
_setupContextAndPlanWithConfiguration:error:
_setupContextAndPlanWithConfiguration:usingCPU:error:
_setupContextAndPlanWithConfiguration:usingCPU:reshapeWithContainer:error:
_addCompiledNetworkOrProgramToPlan:error:
restrictNeuralNetworksFromUsingANE
gpuPrecision
allowLowPrecisionAccumulationOnGPU
enableTestVectorMode
_setMultipleBuffersOnPlan:error:
_addNetworkToPlan:error:
modelDisplayName
setEspressoBlobShapes:widths:heights:ks:batches:sequences:ranks:error:
removeAllObjects
profilingOptions
setEspressoProfileInfo:
rebuildPlan:
evaluateInputs:options:error:
featureNames
setValue:forKey:
objectForKey:
bindInputFeatures:bufferIndex:cleanUpBlocks:error:
bindOutputBuffers:outputBackings:automaticOutputBackingMode:directlyBoundOutputFeatureNames:error:
inputBindStateForFeatureValue:error:
imageFeatureValueFromPixelBuffer:usingPixelFormat:
bindInputFeatureNamed:pixelBuffer:cleanUpBlocks:error:
bindDirectlyInputFeatureNamed:pixelBuffer:cleanUpBlocks:error:
bindInputFeatureNamed:convertingMultiArray:bufferIndex:error:
prepareBlobNamed:forNewBlobBackingMode:bindMode:
lockPixelBuffer:cleanUpBlocks:error:
pixelType
bindInputFeatureNamed:featureValue:bufferIndex:cleanUpBlocks:error:
isAllowedValue:
_espressoOutputShapeForFeatureName:matchesShapeOfMLMultiArray:
_setMultiArrayOutputBacking:forOutputFeatureName:toEbuf:error:
isAllowedShape:error:
verifyMultiArrayOutputBacking:forFeature:error:
verifyPixelBufferOutputBacking:forFeature:error:
verifyOutputBacking:forFeature:error:
pixelBufferFromOutputBacking:forFeature:
tryToSetOutputBacking:forFeatureName:toEbuf:reportPointerFlags:error:
evaluateInputs:options:verifyInputs:error:
verifyInputs:error:
resetSizes:error:
obtainBuffer
evaluateInputs:bufferIndex:options:error:
releaseBuffer:
shapeConstraint
populateShapeAndStrideFor:inputShape:outputShape:outputStrides:error:
shapeSet
stridesForShape:
populateMultiArrayShape:strides:forEbuf:featureDescription:ndArrayInterpretation:
pixelBufferBackedMultiArrayWithShape:
outputBackingMultiArrayForFeatureName:
updateDynamicOutputBlobIndicatorCacheAndReturnError:
outputBackings
automaticOutputBackingMode
completeOutputBackings:automaticOutputBackingMode:error:
plan
executePlan:error:
reverseObjectEnumerator
bindDynamicOutputBuffers:error:
populateOutputs:outputBackings:directlyBoundOutputFeatureNames:error:
submitSemaphore
containsObject:
imageFeatureValueFromEbuf:backingCVPixelBuffer:description:error:
opacifyAndPermutePixelBuffer:bufferContainsBGRA:error:
multiArrayFeatureValueFromEbuf:backingMultiArray:description:outputName:error:
sizeConstraint
allowedImageSizeClosestToPixelsWide:pixelsHigh:preferDownScaling:preferInputAspectRatio:
copyEbuf:ofPixelType:toPixelBuffer:error:
_pixelBufferFromEbuf:description:error:
featuresAtIndex:
stringWithString:
getFeatureSize:ndArrayMode:
lazyBatchIndexIntoBatch:indices:error:
usingEspressoConfigurations
resetSizesWithEspressoConfigurations:error:
resetSizesNoAutoRelease:error:
rebuildPlan:error:
isEspressoBiasPreprocessingShared
inputLayers
copyImagePreprocessingParametersTo:error:
setIsANEPathForbidden:
setHardwareFallbackDetected:
null
_matchEngineToOptions:error:
espressoQueue
bindInputsAndOutputs:cleanUpBlocks:bufferIndex:options:error:
addClassifierInformationToOutput:options:error:
initWithFeatureProviderArray:
predictionsFromLoopingOverBatch:model:options:error:
sortBatchByShape:withMap:error:
evaluateBatch:options:error:
per_platform_support
supported
main_engine_support
espressoProfileInfo
layers
selected_runtime_engine
debug_name
componentsSeparatedByString:
supportFromEspressoLayerInfo:
supportFromEspressoPlatform:
initWithComputeUnits:layerName:layerError:layerTypeName:supportedComputeUnits:layerIndex:
scopedModelNames
initWithScopedModelAndLayerName:layerName:
addEntriesFromDictionary:
setModelExecutionSchedule:
modelExecutionSchedule
loadModelFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
neuralNetworkFromContainer:error:
evaluate:error:
sequenceNamed:
availableOutputBlobList
initWithContainer:error:
dumpTestVectorsToPath:
enableInstrumentsTracing
outputLayers
hardwareFallbackDetected
setImagePreprocessingParameters:
numInputs
numOutputs
usingCPU
setUsingCPU:
setPlan:
setQos:
context
setContext:
setIsEspressoBiasPreprocessingShared:
setProbabilityDictionarySharedKeySet:
bufferSemaphore
setBufferSemaphore:
setEspressoQueue:
predictionsQueue
setPredictionsQueue:
setSubmitSemaphore:
isGPUPathForbidden
setIsGPUPathForbidden:
isANEPathForbidden
setNetwork:
defaultOptionalValues
setDefaultOptionalValues:
setActiveFunction:
_inputBuffers
_outputBuffers
_params
_widths
_heights
_batches
_sequences
_ranks
_bufferAvailable
_flexibleShapesConfigNamesInNet
_currentConfigurationName
_OutputBlobIsDynamic
_pixelBufferPoolCache
_transferSession
_hardwareFallbackDetected
_usingCPU
_isEspressoBiasPreprocessingShared
_isGPUPathForbidden
_isANEPathForbidden
_qos
_inputLayers
_outputLayers
_imagePreprocessingParameters
_espressoInputShapes
_espressoInputStrides
_numInputs
_numOutputs
_plan
_context
_probabilityDictionarySharedKeySet
_bufferSemaphore
_espressoQueue
_predictionsQueue
_submitSemaphore
_inputBlobNameToLastBackingMode
_outputBlobNameToLastBackingMode
_espressoProfileInfo
_defaultOptionalValues
_activeFunction
TQ,R,N,V_numInputs
TQ,R,N,V_numOutputs
TB,N,V_usingCPU
T^v,N,V_plan
Ti,N,V_qos
T^v,N,V_context
TB,N,V_isEspressoBiasPreprocessingShared
T@"NSArray",&,N,V_classLabels
T@"NSString",&,N,V_classScoreVectorName
T@,&,N,V_probabilityDictionarySharedKeySet
TB,R,N,V_modelIsEncrypted
T@"NSObject<OS_dispatch_semaphore>",&,V_bufferSemaphore
T@"NSObject<OS_dispatch_queue>",&,V_espressoQueue
T@"NSObject<OS_dispatch_queue>",&,V_predictionsQueue
T@"NSObject<OS_dispatch_semaphore>",&,V_submitSemaphore
TB,V_isGPUPathForbidden
TB,V_isANEPathForbidden
T@"NSMutableDictionary",R,N,V_inputBlobNameToLastBackingMode
T@"NSMutableDictionary",R,N,V_outputBlobNameToLastBackingMode
TB,N,V_ndArrayInterpretation
T@"NSDictionary",&,N,V_imagePreprocessingParameters
T@"EspressoProfilingNetworkInfo",&,N,V_espressoProfileInfo
T@"NSDictionary",R,N,V_optionalInputTypes
T{?=^vi},N,V_network
T@"NSDictionary",&,N,V_defaultOptionalValues
T@"MLVersionInfo",R,&,N,V_compilerVersionInfo
T@"NSString",&,N,V_activeFunction
T@"NSArray",R,&,N,V_inputLayers
T@"NSArray",R,&,N,V_outputLayers
TB,N,V_hardwareFallbackDetected
T@"NSDictionary",&,N,V_espressoInputShapes
T@"NSDictionary",&,N,V_espressoInputStrides
T@"MLVersionInfo",R,N,V_modelVersionInfo
initWithKeyName:
learningRate
momentum
miniBatchSize
beta1
beta2
epochs
shuffle
seed
T@"MLParameterKey",R,N
linkedModelFileName
linkedModelSearchPath
scopedTo:
weights
biases
maxDepth
objective
numTrees
numClasses
minChildWeight
updateType
numberWithBool:
initWithModelDescription:configuration:parameterDictionary:error:
instancesRespondToSelector:
parametersFromCustomModelSpec:error:
customModelWithName:modelDescription:modelConfiguration:parameterDictionary:error:
initWithModelDescription:customModel:configuration:
customModel
setCustomModel:
_customModel
T@"NSObject<MLCustomModel>",&,V_customModel
initWithComputeUnits:
setAllowLowPrecisionAccumulationOnGPU:
preferredMetalDevice
setPreferredMetalDevice:
allowBackgroundGPUComputeSetting
setComputeUnits:
useWatchSPIForScribble
setUseWatchSPIForScribble:
setAllowBackgroundGPUComputeSetting:
setEnableTestVectorMode:
setParameters:
rootModelURL
setRootModelURL:
setProfilingOptions:
usePreloadedKey
setUsePreloadedKey:
setTrainWithMLCompute:
parentModelName
setParentModelName:
setModelDisplayName:
allowsInstrumentation
setAllowsInstrumentation:
isEqualToModelConfiguration:
isEqualToDictionary:
setWithObjects:
decodeObjectOfClasses:forKey:
computeUnitsToString:
defaultConfiguration
allowFloat16AccumulationOnGPU
setAllowFloat16AccumulationOnGPU:
preferredMTLDevice
setPreferredMTLDevice:
setAllowBackgroundGPUCompute:
_allowBackgroundGPUComputeSetting
_trainWithMLCompute
_useWatchSPIForScribble
_allowLowPrecisionAccumulationOnGPU
_enableTestVectorMode
_usePreloadedKey
_allowsInstrumentation
_modelDisplayName
_computeUnits
_preferredMetalDevice
_rootModelURL
_profilingOptions
_parentModelName
TB,V_allowBackgroundGPUComputeSetting
TB,V_trainWithMLCompute
TB,N,V_useWatchSPIForScribble
TB,V_allowLowPrecisionAccumulationOnGPU
T@"<MTLDevice>",&,N
T@"<MTLDevice>",&,N,V_preferredMetalDevice
TB,N,V_enableTestVectorMode
T@"NSDictionary",&,V_parameters
T@"NSURL",&,V_rootModelURL
Tq,N,V_profilingOptions
TB,N,V_usePreloadedKey
T@"NSString",&,N,V_parentModelName
TB,N,V_allowsInstrumentation
T@"NSString",C,V_modelDisplayName
Tq,V_computeUnits
setEncryptionKey:
setEncryptionIv:
hasEncryptionKey
hasEncryptionIv
encryptionKey
encryptionIv
_encryptionIv
_encryptionKey
T@"NSData",&,N,V_encryptionKey
T@"NSData",&,N,V_encryptionIv
initWithModelSpecification:error:
initWithEngine:description:configuration:error:
initWithLayerError:
layerError
layerName
preferredComputeUnit
layerTypeName
supportedComputeUnits
layerIndex
_layerError
_layerName
_preferredComputeUnit
_layerTypeName
_supportedComputeUnits
_layerIndex
Tq,R,N,V_layerError
T@"NSString",R,C,N,V_layerName
TQ,R,N,V_preferredComputeUnit
T@"NSString",R,C,N,V_layerTypeName
TQ,R,N,V_supportedComputeUnits
Tq,R,N,V_layerIndex
sharedKeySetForKeys:
dictionaryWithSharedKeySet:
featureTypeForValuesInArray:error:
featureValueOfType:fromObject:error:
array
_array
T@"NSArray",R,N,V_array
initWithDescription:
orderedSetWithArray:
defaultLabel
weightingScheme
nearestLabelsFeatureName
nearestDistancesFeatureName
indexType
initWithDataset:numberOfDimensions:
leafSize
initWithDataset:numberOfDimensions:leafSize:error:
parameterContainer
labelsForDataPoints
labelsSet
labelType
sequenceWithStringArray:
featureValueWithSequence:
sequenceWithInt64Array:
sequenceFromArray:error:
predictedProbabilitiesName
computeKClosestLabels:
computeClassProbabilities:from:
extractNearestNeighborLabels:distances:from:
packageOutputWithPredictedLabel:classProbabilities:nearestLabels:nearestDistances:
setNumberOfDimensions:
setDefaultLabel:
setNearestLabelsFeatureName:
setNearestDistancesFeatureName:
setWeightingScheme:
setIndexType:
setLeafSize:
parameterDescriptionForKey:int64ParameterSpec:
initWithDescription:configuration:parameters:dataPoints:labels:error:
setProgressHandlers:
setProgressHandlersDispatchQueue:
setContinueWithUpdate:
initWithArray:copyItems:
progressHandlers
progressHandlersDispatchQueue
dispatchTrainingCompletionHandlerWithError:onQueue:
dispatchTrainingBeginProgressHandlerWithMetrics:parameters:onQueue:
continueWithUpdate
setLabelsForDataPoints:
setLabelsSet:
updateWithData:error:
dispatchTrainingCompletionHandlerWithMetrics:parameters:onQueue:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
codedObjectURLFromOutputArchiver:
writeToURL:options:error:
decodeTopLevelObjectOfClass:forKey:error:
writeToURL:error:
setUpdateProgressHandlers:dispatchQueue:
updateModelWithData:
resumeUpdateWithParameters:
resumeUpdate
cancelUpdate
updateParameters
setUpdateParameters:
setParameterContainer:
setIndex:
setLabelType:
_continueWithUpdate
_progressHandlers
_progressHandlersDispatchQueue
_updateParameters
_indexType
_labelType
_labelsForDataPoints
_labelsSet
_defaultLabel
_weightingScheme
_nearestLabelsFeatureName
_nearestDistancesFeatureName
T@"MLUpdateProgressHandlers",&,N,V_progressHandlers
T@"NSObject<OS_dispatch_queue>",&,N,V_progressHandlersDispatchQueue
T@"NSDictionary",&,N,V_updateParameters
TB,N,V_continueWithUpdate
T@"MLParameterContainer",&,N,V_parameterContainer
TQ,N,V_numberOfDimensions
Tq,N,V_indexType
T@"<MLNearestNeighborsIndex>",&,N,V_index
Tq,N,V_labelType
T@"NSArray",&,N,V_labelsForDataPoints
T@"NSOrderedSet",&,N,V_labelsSet
T@"NSObject",&,N,V_defaultLabel
Tq,N,V_weightingScheme
T@"NSString",&,N,V_nearestLabelsFeatureName
T@"NSString",&,N,V_nearestDistancesFeatureName
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:trainingInputDescriptions:orderedInputFeatureNames:orderedOutputFeatureNames:metadata:
inputDescriptionFromInterface:
outputDescriptionFromInterface:
orderedFeatureNamesFromInterface:forInput:
trainingInputDescriptionFromInterface:
metadataWithFormat:
isUpdatable
isEqualToDescription:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:trainingInputDescriptions:metadata:
setIsUpdatable:
metadataWithSpecification:
verifyInput:error:
validateAsRegressorDescriptionAndReturnError:
setTrainingInputDescriptionsByName:
setModelPath:
inputFeatureNames
outputFeatureNames
_isUpdatable
_inputDescriptionsByName
_predictedFeatureName
_predictedProbabilitiesName
_trainingInputDescriptionsByName
_parameterDescriptionsByKey
_modelPath
_inputFeatureNames
_outputFeatureNames
T@"NSArray",C,N,V_classLabels
T@"NSURL",&,N,V_modelURL
TB,N,V_isUpdatable
T@"NSDictionary",&,N,V_trainingInputDescriptionsByName
T@"NSDictionary",&,N,V_parameterDescriptionsByKey
T@"MLLayerPath",&,N,V_modelPath
T@"MLFeatureDescription",R,C,N
T@"MLFeatureDescription",R
T@"NSOrderedSet",R,V_inputFeatureNames
T@"NSOrderedSet",R,V_outputFeatureNames
T@"NSDictionary",R,N,V_inputDescriptionsByName
T@"NSDictionary",R,N,V_outputDescriptionsByName
T@"NSString",R,C,N,V_predictedFeatureName
T@"NSString",R,C,N,V_predictedProbabilitiesName
T@"NSDictionary",R,N,V_metadata
initDescriptionOnlyWithSpecification:configuration:error:
setSignpostID:
setPredictionEvent:
classifierResultFromOutputFeatures:error:
pipeline
T@"MLPipeline",&,V_engine
T@"MLPipeline",R
initUnspecified
valueWithRange:
rangeValue
enumeratedShapes
canShapeArrayBePromotedFrom:to:
sizeRangeForDimension
initWithSizeRangeForDimension:
initWithEnumeratedShapes:
findAvailableShape:
_type
_sizeRangeForDimension
_shapeSet
T@"NSOrderedSet",R,N,V_shapeSet
Tq,R,N,V_type
T@"NSArray",R,N,V_sizeRangeForDimension
size
_size
TQ,R,N,V_size
loadModelFromSpecificationWithCompilationOptions:options:error:
serializeInterfaceAndMetadata:toArchive:error:
longValue
initInterfaceAndMetadataWithCompiledArchive:error:
int64Values
unsignedLongValue
stringValues
sequenceValue
_mapItemSequence:dest:error:
modelData
_itemForIndex:error:
featureValueWithDictionary:error:
m_cached_model
m_model_data
m_num_items
m_item_data_feature_name
m_num_recommendations_feature_name
m_item_restriction_feature_name
m_item_exclusion_feature_name
m_item_list_output_feature_name
m_item_score_output_feature_name
m_item_mapping
m_item_string_list
m_item_integer_list
_m_scores
_m_items
_m_item_buffer
_m_item_invalid_mask
_m_item_predictions
_m_item_heap
format
setFormat:
confidenceFeatureName
setConfidenceFeatureName:
coordinatesFeatureName
setCoordinatesFeatureName:
_format
_confidenceFeatureName
_coordinatesFeatureName
Ti,V_format
T@"NSString",&,V_confidenceFeatureName
T@"NSString",&,V_coordinatesFeatureName
models
objectBoundingBoxOutputDescription
dataCHWFromPixelBuffer:channelOrderIsBGR:error:
oneHotEncodedDataFromFeatureValue:withNNEngine:error:
dataCHWFromPixelTypeGray8:error:
dataCHWFromChanneledPixelType:channelOrderIsBGR:error:
dataWithBytesNoCopy:length:freeWhenDone:
classifierOutputIsSigmoidOutput
initWithFeatureProvider:forPrediction:neuralNetworkEngine:error:
dataDictionary
_dataDictionary
T@"NSDictionary",R,N,V_dataDictionary
binder
setBinder:
featureDescription
initWithPort:featureDescription:
setOutputBacking:
bindAndReturnError:
initWithPortHandle:name:featureDescription:
prepareAndReturnError:
_inputFeatureValue
_featureDescription
_binder
T@"MLFeatureDescription",R,V_featureDescription
T@"<MLE5PortBinder>",&,V_binder
T@"NSString",R,V_name
T@"MLFeatureValue",&
setClassifierOutputIsSigmoidOutput:
_classifierOutputIsSigmoidOutput
_classLabelToIndexMap
_lossTargetName
T@"NSDictionary",R,N,V_classLabelToIndexMap
TB,N,V_classifierOutputIsSigmoidOutput
T@"NSString",R,N,V_lossTargetName
pathComponents
data
fileExistsAtPath:isDirectory:
isWritableFileAtPath:
initWithConfiguration:
initWithMajor:minor:patch:variant:
scannerWithString:
scanInteger:
decimalDigitCharacterSet
scanUpToCharactersFromSet:intoString:
scanUpToString:intoString:
minorVersion
patchVersion
versionInfoWithString:
versionInfoWithStringProgressive:
variantString
_majorVersion
_minorVersion
_patchVersion
_variantString
Tq,R,V_majorVersion
Tq,R,V_minorVersion
Tq,R,V_patchVersion
T@"NSString",R,V_variantString
initWithBytesNoCopy:length:deallocator:
setCurrentParameterValues:
setParameterKeys:
setParameterDescriptions:
parameterKeys
parameterDescriptions
isSubclassOfClass:
validateParameterValue:givenConstraint:
enumeratedNumbers
minNumber
maxNumber
_currentParameterValues
_parameterKeys
_parameterDescriptions
T@"NSMutableDictionary",&,N,V_currentParameterValues
T@"NSArray",&,N,V_parameterKeys
T@"NSDictionary",&,N,V_parameterDescriptions
initWithKeyName:scope:
scope
hasPrefix:
hasSuffix:
substringFromIndex:
hasSameNameAsKey:
_scope
T@"NSString",R,N,V_name
T@"NSString",R,N,V_scope
setTask:
setEvent:
setMetrics:
updateContextWithTask:model:event:metrics:parameters:
setError:
task
event
progressEventsToString:
metrics
updateContextForEvent:metrics:parameters:error:
error
_task
_event
_metrics
_error
T@"MLUpdateTask",&,N,V_task
T@"MLModel<MLWritable>",&,N,V_model
Tq,N,V_event
T@"NSDictionary",&,N,V_metrics
T@"NSDictionary",&,N,V_parameters
T@"NSError",&,N,V_error
clearOneofValuesForResult
setSuccess:
hasSuccess
hasError
result
setResult:
setHasResult:
hasResult
resultAsString:
StringAsResult:
success
_result
_success
T@"ModelKeyServerAPIFetchKeyResult",&,N,V_success
T@"ModelKeyServerAPIResultError",&,N,V_error
Ti,N,V_result
initWithSVMModel:freeOnDealloc:isInputSizeLowerBoundOnly:inputSize:classLabels:
initWithLibSVMFile:classLabels:
numberOfClasses
hasProbabilityPredictionEnabled
predictProbabilities:probabilities:
setIsInputSizeLowerBoundOnly:
setInputSize:
TB,V_isInputSizeLowerBoundOnly
TQ,V_inputSize
rank
espressoShapeToCoremlShape:ndMode:
coremlShapeToEspressoShape:ndMode:
getStrides:
texture
espressoTensorToCoremlTensor:ndMode:
espressoShapesToCoremlShapes:ndMode:
factory
createCustomLayer:withParameters:error:
initWithParameterDictionary:error:
setWeightData:error:
outputShapesForInputShapes:error:
evaluateOnCPUWithInputs:outputs:error:
encodeToCommandBuffer:inputs:outputs:error:
coremlShapesToEspressoShapes:ndMode:
espressoTensorsToCoremlTensors:ndMode:
removeObjectForKey:
espressoTensorsToCoremlTensorsGPU:
ndMode
className
customImpl
setCustomImpl:
_ndMode
_className
_customImpl
TB,R,N,V_ndMode
T@"NSString",R,N,V_className
T@"NSObject<MLCustomLayer>",&,N,V_customImpl
URLsForDirectory:inDomains:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
persistentKeyStorageURL
syncQueue
setResourceValue:forKey:error:
dataWithContentsOfURL:
storeKeyBlob:forKeyIdentifier:error:
retrieveKeyBlobForKeyIdentifier:
_featureValuesForNames:providedBy:error:
_vectorizedSizeOfFeatureValues:error:
_vectorizeWithoutSizeCheckFeatureValues:intoDoubleVector:stride:error:
canVectorizeFeatureWithDescription:
vectorizeFeaturesProvidedBy:featureNames:intoDoubleVector:length:stride:error:
vectorizeFeaturesProvidedBy:featureNames:error:
canVectorizeAllFeaturesWithDescriptions:
setByAddingObjectsFromSet:
allObjects
T@"NSSet",R,N
initWithFeaturesFrom:addedToFeaturesFrom:
unionFeatureProvider
first
setFirst:
second
setSecond:
_first
_second
T@"<MLFeatureProvider>",&,N,V_first
T@"<MLFeatureProvider>",&,N,V_second
providerWithSubsetOfFeaturesNamed:providedBy:
lazyProviderWithFeaturesProvidedBy:addedToFeaturesProvidedBy:
vectorizeInput:error:
scalarRegress:error:
scalarRegress:
vectorRegress:dest:
_model_data
_cached_model
num_dimensions
output_classes
deserializeInterfaceFormat:archive:error:
serializeInterfaceFormat:archive:error:
initWithPixelsWide:pixelsHigh:pixelType:sizeConstraint:
initWithEnumeratedImageSizes:
constraintWithPixelsWide:pixelsHigh:pixelType:sizeConstraint:
osType:isAcceptedForPixelType:
_stringForAllowedOSTypes
_stringForOSType:
isAllowedImageSize:error:
constraintWithPixelsWide:pixelsHigh:pixelType:
imagePixelTypeFromOSType:
osType
imageHeight
imageWidth
_sizeConstraint
_pixelType
TQ,R,V_pixelType
TI,R
Tq,R,N,V_pixelsHigh
Tq,R,N,V_pixelsWide
TI,R,N
T@"MLImageSizeConstraint",R,N,V_sizeConstraint
modelAssetWithURL:configuration:error:
initWithURL:configuration:error:
modelAssetWithSpecification:compilerOptions:error:
uniqueDirectoryURLInPath:
modelAssetWithSpecificationURL:compilerOptions:error:
removeItemAndReturnError:
_compileModelAtURL:options:error:
initWithURL:error:
isFileURL
getResourceValue:forKey:error:
compiledURL
loadConfiguration
loadModelFromArchive:configuration:error:
loadModelFromAssetAtURL:configuration:error:
modelWithError:
load:
setLoadConfiguration:
classifierWithError:
regressorWithError:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
lastPathComponent
relativePath
URLByAppendingPathComponent:isDirectory:
isANESupported
fetchNetworkURLFromCompiledModelAtURL:error:
purgeANEBinaryForModelAtURL:error:
initWithArchiveData:
modelAssetWithURL:error:
modelAssetWithSpecification:error:
modelAssetWithSpecificationURL:error:
needsANECompilationForModelAtURL:result:error:
purgeANEIRForModelAtURL:error:
modelAssetWithSpecificationData:error:
modelWithConfiguration:error:
classifier
regressor
ranLoad
setRanLoad:
asset
setAsset:
archiveData
_ranLoad
_compiledURL
_asset
_loadConfiguration
_archiveData
TB,V_ranLoad
T@"NSObject<MLModeling>",&,V_asset
T@"MLModelConfiguration",&,N,V_loadConfiguration
T@"NSDictionary",R,N,V_archiveData
T@"NSURL",R,V_compiledURL
T@"<MLModeling>",R,N
T@"<MLRegressor>",R,N
T@"<MLClassifier>",R,N
longLongValue
initWithUndefinedValueAndType:
initWithValue:type:
undefinedFeatureValueWithType:
featureTypeForObject:
initWithArray:type:
values
value
isEqualToNumber:
isEqualToArray:
isEqualToFeatureValue:
featureValueWithInt64:
featureValueWithString:
featureValueWithStringKeyDictionary:
featureValueWithInt64KeyDictionary:
objectValue
getFeatureSize:
setValue:
setObjectValue:
_undefined
_value
_objectValue
T@,&,V_value
T@"NSObject",&,N,V_objectValue
undefined
TB,R,N,GisUndefined,V_undefined
Td,R,N
T@"NSString",R,C,N
T@"MLMultiArray",R,N
T@"NSDictionary",R,N
T@"MLSequence",R,N
transposeA
transposeB
_transposeA
_transposeB
T@"NSNumber",R,N,V_transposeA
T@"NSNumber",R,N,V_transposeB
evaluateFunction:arguments:error:
newContextAndReturnError:
removeEngineForFunctionName:
initWithProgram:error:
functionNameToInputLayersNames
trainUsingTrainingData:evaluationMetricNames:error:
evaluateUsingTestData:evaluationMetricNames:evaluateOnTrainFunction:error:
attachLearningRateToFeatures:
evaluator
evaluateFunction:arguments:context:error:
trainFunctionLossName
setLoss:
orderedTrainableWeightsNames
functionNameToStateMap
setCurrentUpdatedWeights:
evaluateUsingTestData:evaluationMetricNames:error:
evaluateFunction:arguments:context:updateContext:error:
forwardFunctionLossName
setEvaluationMetrics:
dataWithCapacity:
setLength:
functionNameToOutputLayersNames
executionState
flattenFeatures:orderedFeatures:
currentUpdatedWeights
dataWithLength:
initWithFlattenedModelUpdate:
initWithProgram:learningRate:error:
trainUsingTrainingData:error:
evaluateUsingTestData:error:
inferenceModel
copyCurrentTrainingDelta
setLearningRate:
setProgram:
setEvaluator:
_learningRate
_evaluator
_currentUpdatedWeights
T@"<MLProgramInternal>",&,N,V_program
T@"MLProgramContext",&,N,V_context
T@"MLProgramEvaluator",&,N,V_evaluator
T@"<MLFeatureProvider>",&,N,V_currentUpdatedWeights
Td,N,V_learningRate
T@"<MLModeling>",R,C
setInnerModel:
setReason:
innerModel
reason
initWithInnerModel:
clearInnerModelWithReason:
_innerModel
_reason
T@"MLModel",&,V_innerModel
T@"NSString",&,N,V_reason
wrapperAroundWritableModel:
elementCountForScenePrintRequestRevision:
scenePrintsFromPixelBuffers:version:augmentationOptions:useCPUOnly:error:
featureValueFromScenePrint:elementSize:
scenePrintRequestRevision
_scenePrintRequestRevision
_configuration
T@"MLModelDescription",R,N,V_modelDescription
TQ,R,N,V_scenePrintRequestRevision
T@"MLModelConfiguration",R,N,V_configuration
fileURLWithPath:isDirectory:
codedObjectURLFromInputArchiver:
initializeWordTaggingModelWithData:error:
predictTokensLabelsLocationsLengthsForString:inputString:error:
_wordTaggingModel
classesForLoadingModelType:isUpdatable:trainWithMLCompute:
loadNeuralNetworkClasses:trainWithMLCompute:
sharedInstance
classesForLoadingModelType:
classForCompilingModelType:
initWithInferenceNetworkPath:inferenceInputs:inferenceOutputs:error:
crossEntropyLossWithInputName:targetInputName:lossOutputName:
L2LossWithInputName:targetInputName:lossOutputName:
initForLayers:error:
parameterValueForKey:
initWithOptimizationAlgorithm:parameters:error:
initWithModelDefinition:lossDefinition:variablesDefinition:optimizerDefinition:forPlatform:error:
createCoreMLToEspressoParamsMap
loadUpdateParameters:fromCompiledArchive:error:
loadParameterDescriptionsAndContainerFromUpdateParameters:modelDescription:
loadLossInputName:updatableLayerNames:fromCompiledArchive:
loadLossTargetName:lossOutputName:fromUpdateParameters:
createEspressoTaskFrom:updateParameters:lossInputName:lossTargetName:lossOutputName:updatableLayerNames:configuration:error:
taskState
createClassLabelToIndexMapWith:
updateWeightsAndBiasesFromConfigParams:error:
espressoDataProviderFromFeatureProvider:forPrediction:neuralNetworkEngine:error:
doInferenceOnData:error:
featureProviderFromEspressoDataProvider:neuralNetworkEngine:options:error:
espressoDataProviderFromBatchProvider:forPrediction:neuralNetworkEngine:error:
batchProviderFromEspressoDataProvider:neuralNetworkEngine:options:error:
setWeightsOrBiasesForLayer:layerType:value:error:
getParameterOfType:forLayerNamed:error:
setParameterOfType:forLayerNamed:withValue:error:
initWithCompiledArchive:nnContainer:configuration:error:
epochIndex
collectMetricsFromTaskContext:isInCallBack:
lossValue
dispatchEpochEndProgressHandlerWithMetrics:parameters:onQueue:
updateLearningRateWithTaskContext:isInCallBack:error:
shuffableTrainingData
miniBatchIndex
dispatchMiniBatchEndProgressHandlerWithMetrics:parameters:onQueue:
initWithBatchProvider:seed:
setShuffableTrainingData:
interestedEvents
doTrainingOnData:forNumberOfEpochs:withCallback:error:
setSnapshot:
coreMLToEspressoParamsMap
getTensorNamed:
setTensorNamed:withValue:error:
lossOutputName
copyModelAtURL:toURL:error:
saveNetwork:inplace:error:
removeItemAtURL:error:
paramsForLayer:parameterType:error:
weightsForLayer:error:
biasForLayer:error:
snapshot
setLossTargetName:
setCoreMLToEspressoParamsMap:
setLossOutputName:
_snapshot
_coreMLToEspressoParamsMap
_lossOutputName
_shuffableTrainingData
T@"NSDictionary",&,N,V_coreMLToEspressoParamsMap
T@"NSString",&,N,V_lossOutputName
T@"NSString",&,N,V_lossTargetName
T@"MLShufflingBatchProvider",&,N,V_shuffableTrainingData
T@"ETTaskState",&,N,V_snapshot
T@"ETTaskDefinition",&,N,V_task
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:
initWithURL:options:
createPixelBufferFromVNImageBuffer:constraint:cropRect:cropAndScaleOption:options:error:
initWithCGImage:options:
addOrientation:toOptions:
lengthInBytesForScenePrintRequestRevision:
createPixelBufferFromImageAtURL:constraint:cropRect:cropAndScaleOption:options:error:
createPixelBufferFromCGImage:constraint:cropRect:cropAndScaleOption:options:error:
detectionPrintsFromPixelBuffers:version:augmentationOptions:useCPUOnly:error:
detectionPrintShapes:
detectionPrintSupportedRevisions
scenePrintsFromPixelBuffersImpl
scenePrintsFromPixelBuffersUsesCPUOnlyImpl
scenePrintElementCountImpl
scenePrintLengthImpl
VNImageBufferClass
detectionPrintsFromPixelBuffersImpl
detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
detectionPrintShapesImpl
detectionPrintSupportedRevisionsImpl
_validForSceneprint
_validForObjectprint
_scenePrintsFromPixelBuffersImpl
_scenePrintsFromPixelBuffersUsesCPUOnlyImpl
_scenePrintElementCountImpl
_scenePrintLengthImpl
_VNImageBufferClass
_detectionPrintsFromPixelBuffersImpl
_detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
_detectionPrintShapesImpl
_detectionPrintSupportedRevisionsImpl
T^?,R,N,V_scenePrintsFromPixelBuffersImpl
T^?,R,N,V_scenePrintsFromPixelBuffersUsesCPUOnlyImpl
T^?,R,N,V_scenePrintElementCountImpl
T^?,R,N,V_scenePrintLengthImpl
T#,R,N,V_VNImageBufferClass
T^?,R,N,V_detectionPrintsFromPixelBuffersImpl
T^?,R,N,V_detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
T^?,R,N,V_detectionPrintShapesImpl
T^?,R,N,V_detectionPrintSupportedRevisionsImpl
validForSceneprint
TB,R,N,GisValid,V_validForSceneprint
validForObjectprint
TB,R,N,GisValid,V_validForObjectprint
hasDirectoryPath
sandboxExtensionPathsForModelURL:
initWithServiceName:
secureModelWithContentsOfURL:sandboxExtensionToken:configuration:decryptCredential:withReply:
securePredictionFromLazyFeatures:options:withReply:
securePredictionFromLazyBatch:options:withReply:
secureParameterValueForKey:withReply:
secureModelMLFeatureValue:withReply:
secureModelMLDictionaryFeatureProvider:withReply:
secureModelMLModelDescription:withReply:
secureModelMLFeatureDescription:withReply:
createPersistentKeyBlobForKeyID:usesCodeSigningIdentityForEncryption:completionBlock:
startDecryptionOfModelAtPath:usingKeyBlob:usesCodeSigningIdentityForEncryption:completionBlock:
stopDecryptionOfModelAtPath:completionBlock:
extractTeamIdentifierWithReply:
interfaceWithProtocol:
setRemoteObjectInterface:
setInterruptionHandler:
setInvalidationHandler:
clientFeatureValueForName:uniqueKeyForProvider:withReply:
clientFeatureNames:withReply:
setExportedInterface:
setExportedObject:
resume
synchronousRemoteObjectProxyWithErrorHandler:
sandboxExtensionTokenForModelURL:
setConnectionToModelSecurityService:
setSecureModelProxy:
connectionToModelSecurityService
exportedObject
setServiceToClientQueue:
modelWithContentsOfURL:configuration:decryptCredential:error:
serviceToClientQueue
featureProviderCount
featureProviderMap
secureModelProxy
countForObject:
invalidate
modelWithContentsOfURL:decryptCredential:error:
_connectionToModelSecurityService
_secureModelProxy
T@"NSXPCConnection",&,N,V_connectionToModelSecurityService
T@"NSObject<CoreMLModelSecurityProtocol>",&,N,V_secureModelProxy
cryptoKey
setCryptoKey:
_cryptoKey
Tq,N,V_cryptoKey
setFeatureProviderMap:
setFeatureProviderCount:
_featureProviderMap
_featureProviderCount
_serviceToClientQueue
T@"NSMutableDictionary",&,N,V_featureProviderMap
T@"NSCountedSet",&,N,V_featureProviderCount
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceToClientQueue
initWithDictionaryFeatureProviderArray:
_convertStringClassVector:int64ClassVector:dimensions:toClassLabel:classType:andReturnError:
_setSingleArrayLookupField
stringByReplacingOccurrencesOfString:withString:
initWithDescription:configuration:indexToStringLabelArray:indexToIntLabelArray:modelURL:error:
resultWithIntClassProbability:
resultWithStringClassProbability:
prepareInput:error:
_buildClassificationClasses:topk:error:
_classes_by_string
_classes_by_int64_t
_class_type
_class_values
_single_array_key
initWithBatchProvider:batchSize:forPrediction:neuralNetworkEngine:error:
_featureEmbeddingModel
checkResourceIsReachableAndReturnError:
isModelEncrypted:
decryptSessionForModelAtURL:error:
loadModelFromAssetAtURL:configuration:loaderEvent:error:
setModelLoadError:
reporter
logMetric:
checkAssetPath:error:
createDecryptSessionForModelAtURL:configuration:decryptSession:loaderEvent:error:
loadModelFromArchive:configuration:loaderEvent:error:
setDecryptSession:
loadUpdatableModelFromArchive:configuration:error:
initWithContentsOfURL:options:error:
setWithArray:
unarchivedObjectOfClasses:fromData:error:
loadFromModelSpecificationInArchive:withClass:versionInfo:configuration:error:
URLByDeletingPathExtension
modelOriginNumberFromUserDefinedDictionary:
setModelLoadTime:
mainBundle
bundleIdentifier
setBundleIdentifier:
setFirstPartyExecutable:
firstPartyExecutable
loadModelFromArchive:configuration:loaderEvent:useUpdatableModelLoaders:error:
extractAndSetModelDetailsFromArchive:
unarchiveCodedModelFrom:to:error:
deserializeVersionInfoFromArchive:error:
loadUpdatableModelWithClass:fromArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
loadModelWithClass:fromArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
domain
userInfo
setModelProgramValidationError:
setModelProgramParsingError:
populateLoaderAndPredictionEvent:model:configuration:loadTimeDuration:
loadModelFromAssetAtURL:error:
loadUpdatableModelFromAssetAtURL:configuration:error:
loadModelFromArchive:error:
initWithType:concatenatedInputNames:bidirectional:
bidirectional
concatenatedInputNames
_bidirectional
_concatenatedInputNames
TB,R,N,V_bidirectional
T@"NSString",R,C,N,V_type
T@"NSString",R,C,N,V_concatenatedInputNames
JSONObjectWithData:options:error:
modelNetFileName
parseCompiledNetworkBlobWithName:archive:error:
modelShapeFileName
initWithNetJson:shapeJson:modelPath:
isReadableFileAtPath:
unarchiveUpdatableParamsAtURL:error:
netJson
shapeJson
readerFromArchiver:error:
loadUpdatableParams:
copyLayerShapesToContainer:
transformParams
layerInfos
_layerInfos
_netJson
_shapeJson
T@"NSDictionary",R,C,N,V_netJson
T@"NSDictionary",R,C,N,V_shapeJson
T@"NSString",R,C,N,V_modelPath
T@"NSArray",R,N,V_layerInfos
initWithNetwork:
readerFromArchive:error:
arrayWithObjects:
containsString:
initWithCString:encoding:
loadProgramFromCompiledArchive:error:
initWithContainer:program:error:
populateInputNameToShapeMap:fromContainer:forFunction:program:withValidation:error:
setFunctionNameToOutputLayersNames:
setFunctionNameToInputLayersNames:
functionNameToInputShapes
_functionNameToOutputLayersNames
_functionNameToInputLayersNames
T@"NSDictionary",&,N,V_functionNameToOutputLayersNames
T@"NSDictionary",&,N,V_functionNameToInputLayersNames
T@"NSString",&,N
initWithProgramContainer:configuration:error:
programEngineForFunction:error:
container
modelFileBasePath
initWithExecutionState:functionNameToStateMap:
setTrainFunctionLossName:
setForwardFunctionLossName:
updateModelFilePath:
setWithSet:
minusSet:
verifyArgumentNames:functionName:error:
_functionNameToEngineMap
_container
_modelFileBasePath
T@"MLMultiFunctionProgramContainer",R,N,V_container
T@"NSString",R,N,V_modelFileBasePath
start
stepSize
startValueParameter
endValueParameter
stepSizeValueParameter
_start
_stepSize
_startValueParameter
_endValueParameter
_stepSizeValueParameter
Ti,R,N,V_size
Tf,R,N,V_start
Tf,R,N,V_stepSize
Tf,R,N,V_startValueParameter
Tf,R,N,V_endValueParameter
Tf,R,N,V_stepSizeValueParameter
withBase2
_withBase2
TB,R,N,V_withBase2
setSignedKeyRequest:
hasSignedKeyRequest
setRawRequest:
setHasRawRequest:
hasRawRequest
signedKeyRequest
rawRequest
_signedKeyRequest
_rawRequest
T@"NSData",&,N,V_signedKeyRequest
TB,N,V_rawRequest
initWithName:type:optional:contraints:
dictionaryConstraint
sequenceConstraint
valueConstraints
allowsValuesWithDescription:
setValueConstraints:
multiArrayConstraintCached
imageConstraintCached
dictionaryConstraintCached
sequenceConstraintCached
_optional
_valueConstraints
_multiArrayConstraintCached
_imageConstraintCached
_dictionaryConstraintCached
_sequenceConstraintCached
T@"NSDictionary",&,V_valueConstraints
T@"MLMultiArrayConstraint",R,N,V_multiArrayConstraintCached
T@"MLImageConstraint",R,N,V_imageConstraintCached
T@"MLDictionaryConstraint",R,N,V_dictionaryConstraintCached
T@"MLSequenceConstraint",R,N,V_sequenceConstraintCached
T@"NSString",R,C,N,V_name
optional
TB,R,N,GisOptional,V_optional
numDimensions
numDataPoints
setNumDataPoints:
encodeInt64:forKey:
decodeInt64ForKey:
containsValueForKey:
setNumDimensions:
vData
vDataL2Squared
_numDataPoints
_numDimensions
TQ,N,V_numDataPoints
TQ,N,V_numDimensions
version
setVersion:
featureExtractorParameters
setFeatureExtractorParameters:
postVisionFeaturePrintModel
setPostVisionFeaturePrintModel:
_version
_featureExtractorParameters
_postVisionFeaturePrintModel
T@,&,N,V_featureExtractorParameters
TQ,N,V_version
T@"MLModel",&,N,V_postVisionFeaturePrintModel
initWithModels:modelNames:description:configuration:
scenePrintVersion
objectPrintVersion
pipelineOfPostVisionFeaturePrintModelsFromPipeline:
visionFeaturePrintInfo
archivePipelineUpdateParameterForModels:to:updatable:
archiveCustomModelNames:to:
archivePipelineModelDetailsFrom:toArchive:error:
compileWithModelsInPipeline:toArchive:options:updatable:error:
modelNames
extractModelNamesFromArchive:numModels:
classLabelsForPipelineFromSubModelArray:predictedFeatureName:
updateParameterDescriptionsByKeyBasedOnSubModel
lazyBatchWithFeaturesInBatch:addedToBatch:error:
batchWithSubsetOfFeaturesNamed:fromBatch:
setParentSignpostID:
setModels:
initModelFromMetadataAndArchive:versionInfo:description:configuration:error:
replaceModelAtIndex:with:
setModelNames:
_models
_modelNames
T@"NSArray",&,V_models
T@"NSArray",&,V_modelNames
T@"MLSVREngine",&,V_engine
initWithLRSpec:configuration:error:
initWithSpecification:configuration:error:
intercept
postEvalTransForm
m_spec
setExecutionState:
setFunctionNameToStateMap:
_executionState
_trainFunctionLossName
_forwardFunctionLossName
_functionNameToStateMap
T@"<MLFeatureProvider>",&,N,V_executionState
T@"NSString",&,N,V_trainFunctionLossName
T@"NSString",&,N,V_forwardFunctionLossName
T@"NSDictionary",&,N,V_functionNameToStateMap
setFrameworkVersionNumber:
frameworkVersionNumber
getInternalFrameworkVersion
_frameworkVersionNumber
T@"NSNumber",C,N,V_frameworkVersionNumber
_frontendProcessingModel
processInfo
globallyUniqueString
initSoundPrintParameters:
soundPrintVersion
_soundPrintVersion
Tq,R,V_soundPrintVersion
initWithSoundPrintParameters:
T@,R,V_featureExtractorParameters
initWithParameters:modelDescription:configuration:error:
T@"MLAppleAudioFeatureExtractorParameters",R,V_parameters
_modelExecutionSchedule
T@"NSDictionary",C,N,V_modelExecutionSchedule
flattenedModelUpdate
_flattenedModelUpdate
T@"NSData",R,N,V_flattenedModelUpdate
modelLoadTime
modelDimension
nnModelNetHash
nnModelShapeHash
nnModelWeightsHash
modelLoadError
modelProgramValidationError
modelProgramParsingError
setNnModelNetHash:
setNnModelShapeHash:
setNnModelWeightsHash:
numberFromCString:
setModelDimension:
_modelLoadTime
_modelLoadError
_bundleIdentifier
_firstPartyExecutable
_modelProgramValidationError
_modelProgramParsingError
_nnModelNetHash
_nnModelShapeHash
_nnModelWeightsHash
_modelDimension
T@"NSString",C,N,V_nnModelNetHash
T@"NSString",C,N,V_nnModelShapeHash
T@"NSString",C,N,V_nnModelWeightsHash
T@"NSNumber",C,N,V_modelDimension
T@"NSNumber",C,N,V_modelLoadTime
T@"NSNumber",C,N,V_computeUnits
T@"NSNumber",C,N,V_modelLoadError
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_firstPartyExecutable
T@"NSNumber",C,N,V_modelIsEncrypted
T@"NSNumber",C,N,V_modelProgramValidationError
T@"NSNumber",C,N,V_modelProgramParsingError
targetShape
_targetShape
T@"NSArray",R,N,V_targetShape
_init
set_attributes:
set_objectStore:
_objectStore
_attributes
indexOfObject:
predicateFormat
characterAtIndex:
compileSpecificationAtURL:toURL:options:error:
predictedClass
_initWithFlattenedTree:
_saveModelAssetWithModelToPath:withError:
_loadModelAssetWithModelAtPath:withError:
_makeInferenceFromAnswers:withError:
_trc
_treeClassifier
__attributes
__objectStore
T@"NSMutableArray",&,N,V__attributes
T@"NSMutableOrderedSet",&,N,V__objectStore
base64EncodedStringWithOptions:
begin_ids
begin_masks
end_ids
end_masks
_rank
_begin_ids
_begin_masks
_end_ids
_end_masks
_strides
Ti,R,N,V_rank
T@"NSArray",R,N,V_begin_ids
T@"NSArray",R,N,V_begin_masks
T@"NSArray",R,N,V_end_ids
T@"NSArray",R,N,V_end_masks
T@"NSArray",R,N,V_strides
emptySequenceWithType:
_values
T@"NSArray",R,N,V_values
initWrappingSequence:
_sequence
T@"MLSequence",R,N,V_sequence
featureValues
batchProvider
useForPrediction
nnEngine
initWithMLBatchProvider:forPrediction:neuralNetworkEngine:error:
_useForPrediction
_batchProvider
_nnEngine
T@"<MLBatchProvider>",R,N,V_batchProvider
T@"MLNeuralNetworkEngine",R,N,V_nnEngine
TB,R,N,V_useForPrediction
startDecryptionOfModelAtPath:usingKeyBlob:teamIdentifier:error:
stopDecryptionOfModelAtPath:error:
modelPathToSessionID
_modelPathToSessionID
_syncQueue
T@"NSMutableDictionary",R,&,V_modelPathToSessionID
T@"NSObject<OS_dispatch_queue>",R,&,V_syncQueue
setXpcConnection:
setXpcProxy:
decryptSessionForModelAtPath:usesCodeSigningIdentityForEncryption:keyBlob:error:
xpcConnection
xpcProxy
_xpcConnection
_xpcProxy
T@"NSString",C,N,V_modelPath
T@"NSXPCConnection",&,N,V_xpcConnection
T@"NSObject<CoreMLModelSecurityProtocol>",&,N,V_xpcProxy
_leafSize
TQ,V_numberOfDimensions
Tq,V_weightingScheme
Tq,V_indexType
TQ,V_leafSize
T@"NSObject",&,V_defaultLabel
T@"NSString",&,V_nearestLabelsFeatureName
T@"NSString",&,V_nearestDistancesFeatureName
outputBacking
_makeFeatureValueAndReturnError:
_outputBacking
T@,&,V_outputBacking
createExtensionDataSourceWithInfoKey:conformingToProtocol:
activity
dataSource
_activity
_dataSource
T@"NSString",R,N,V_activity
T@"MLBackgroundTask",R,N,V_task
T@"<NSObject>",R,N,V_dataSource
dryRun
setDryRun:
platform
setPlatform:
platformVersion
setPlatformVersion:
containerIsCloud
setContainerIsCloud:
allowsPixelBufferDirectBinding
setAllowsPixelBufferDirectBinding:
encryptModel
setEncryptModel:
keyInfoVersion
setKeyInfoVersion:
keyID
setKeyID:
usesCodeSigningIdentityForEncryption
setUsesCodeSigningIdentityForEncryption:
setIv:
sinf
setSinf:
mlsinf
setMlsinf:
setSpecURL:
mlProgramAddDuringCompilationMode
setMlProgramAddDuringCompilationMode:
_dryRun
_containerIsCloud
_allowsPixelBufferDirectBinding
_encryptModel
_usesCodeSigningIdentityForEncryption
_mlProgramAddDuringCompilationMode
_platform
_platformVersion
_keyInfoVersion
_keyID
_sinf
_mlsinf
_specURL
TB,V_dryRun
T@"NSString",&,V_platform
T@"NSString",&,V_platformVersion
TB,V_containerIsCloud
TB,V_allowsPixelBufferDirectBinding
TB,V_encryptModel
T@"NSNumber",C,V_keyInfoVersion
T@"NSString",C,V_keyID
T@"NSData",C,V_key
TB,V_usesCodeSigningIdentityForEncryption
T@"NSData",C,V_iv
T@"NSData",C,V_sinf
T@"NSData",C,V_mlsinf
T@"NSURL",C,V_specURL
Ti,V_mlProgramAddDuringCompilationMode
setOutputFiles:
resultWithOutputFiles:
outputFiles
_outputFiles
T@"NSArray",&,V_outputFiles
stringByDeletingPathExtension
absoluteString
_compileSpecificationAtURL:toURL:compiledModelName:overridingModelDescription:options:error:
_loadSpecificationAtURL:to:error:
_updateSpecification:withModelDescription:
stringByAppendingPathExtension:
compileSpecification:toArchive:options:compilerEvent:error:
hashSpecificationAtURL:
fingerprintSpecificationAtURL:toArchive:hash:error:
encryptCompiledModelAtURL:options:error:
shortDescription
_updateMetadata:withMetadata:
inputDescriptions
_updateFeatures:withFeatures:
outputDescriptions
trainingInputDescriptions
contentsOfDirectoryAtURL:error:
encryptFileAtURL:options:error:
storeEncryptionInfoInCompiledArchive:options:error:
encryptFile:withKey:iv:saveToFile:error:
copyItemAtURL:toURL:error:
writeToURL:atomically:
initWithUUIDString:
addEncryptionHeaderToUnencryptedFile:saveToFile:error:
URLWithString:
serializeVersionInfo:archive:error:
initWithDictionary:
addMLProgramToCompiledModelAtURL:withCompilationMode:dryRun:oarchiveForModelCompilation:compilerEvent:error:
arrayByAddingObjectsFromArray:
serializeSpecification:toArchive:error:
versionForSerializedSpecification:options:error:
specificationURLFromModelAtURL:error:
initWithContentsOfURL:error:
fillCompilerEvent:withMetadataFromModelAt:error:
canAddMLProgramToCompiledModelAtURL:
compiledVersionForSpecificationAtURL:options:error:
compileModelAtURL:toURL:options:error:
addMLProgramToCompiledModelAtURL:error:
compiledVersionForModelAtURL:options:error:
saveModelToArchive:model:error:
saveModelToArchive:model:compilerOptions:error:
saveModelToSpecification:
URLForDirectory:inDomain:appropriateForURL:create:error:
replaceItemAtURL:withItemAtURL:backupItemName:options:resultingItemURL:error:
saveModelToAssetAtURL:model:error:
classProbability
predictedClassFeatureType
resultWithIntClassProbability:additionalFeatures:
resultWithStringClassProbability:additionalFeatures:
completionHandler
progressHandler
_dispatchUpdateProgressHandlerForEvent:metrics:parameters:error:onQueue:
initForEvents:progressHandler:completionHandler:
setInterestedEvents:
setProgressHandler:
setCompletionHandler:
_interestedEvents
_progressHandler
_completionHandler
Tq,V_interestedEvents
T@?,C,V_progressHandler
T@?,C,V_completionHandler
_initWithModelIdentifier:modelUrl:
modelIdentifier
isEqualToModelCollectionEntry:
_modelIdentifier
T@"NSString",R,N,V_modelIdentifier
T@"NSURL",R,N,V_modelURL
_predictionFromFeatures:options:error:
streamPool
operationPool
_predictionFromFeatures:options:usingStream:operation:error:
setInputFeatures:
setOperations:
executeAndReturnError:
operations
outputFeatures
_outputFeaturesByAddingClassifierResultTo:classifyTopK:error:
reset
_classifierResultFromOutputFeatures:classifyTopK:error:
_classProbabilitiesInOutputFeatures:error:
classLabelsSharedKey
initWithSharedKeySet:probabilityMultiArray:
_probabilityDictionaryWithMultiArray:classifyTopK:
initWithLabels:probabilityArray:
classProbabilitiesFeatureName
initWithE5BundleAtURL:modelDescription:classProbabilitiesFeatureName:
_streamPool
_operationPool
_classProbabilitiesFeatureName
_classLabelsSharedKey
T@"MLE5ExecutionStreamPool",R,V_streamPool
T@"MLE5ExecutionStreamOperationPool",R,V_operationPool
T@"NSString",R,V_classProbabilitiesFeatureName
T@,R,V_classLabelsSharedKey
T@"MLMetricKey",R,N
generateSignpostId
appendPathComponent:
modelWithContentsOfURL:configuration:error:
loadContentsOfURL:configuration:completionHandler:
loadModelAsset:configuration:completionHandler:
initWithName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
decryptSession
setConfiguration:
_emittedDetailsToInstruments
_decryptSession
_predictionEvent
_signpostID
TQ,N,V_signpostID
T@"MLPredictionEvent",&,N,V_predictionEvent
T@"MLModelDescription",&,N,V_modelDescription
T@"MLModelConfiguration",&,N,V_configuration
T@"MLFairPlayDecryptSession",&,N,V_decryptSession
T@"<MLProgram>",R
T@"MLModelMetadata",R,V_metadata
initScenePrintParameters:error:
_scenePrintVersion
TQ,R,V_scenePrintVersion
initObjectPrintParameters:expectedShapes:expectedKeys:error:
expectedShapes
expectedKeys
_objectPrintVersion
_expectedShapes
_expectedKeys
TQ,R,V_objectPrintVersion
T@"NSArray",R,V_expectedShapes
T@"NSArray",R,V_expectedKeys
initWithScenePrintParameters:error:
initWithObjectPrintParameters:error:
initWithParameters:modelDescription:featureExtractorType:configuration:error:
computeScenePrintFeatures:handle:useCPUOnly:error:
featureValueFromObjectPrint:key:shape:
_outputDataType
_extractorType
T@"MLAppleImageFeatureExtractorParameters",R,V_parameters
compare:
keysSortedByValueUsingComparator:
resolveExternalReferencesInSpecificationData:specificationURL:error:
initializeAndvalidateObjectiveAndNumClassesWithConfiguration:error:
loadLabelsWithStringLabels:intLabels:
initializeBoosterIfOneExists
booster
xgBoostDataFormatFromFeatureProvider:error:
featureProviderFromXGboostResults:length:error:
xgBoostDataFormatFromBatchProvider:needLabels:error:
batchProviderFromXGboostResults:length:error:
populateXGBoostDataFormat:trainingData:dataIndex:inputName:needLabels:error:
featureProviderArrayFromXGBoostResult:length:error:
packageOutputWithPredictedLabel:classProbabilities:
setObjective:
setNumClasses:
setBooster:
_objective
_numClasses
_booster
T@"NSString",&,N,V_objective
TQ,N,V_numClasses
T^v,N,V_booster
initWithValue:additionalFeatures:
_predictedValue
_additionalFeatures
T@"MLMultiArray",R,V_predictedValue
T@"<MLFeatureProvider>",R,V_additionalFeatures
batchProviderFromMLComputeDataProvider:neuralNetworkEngine:options:error:
mlComputeDataProviderFromBatchProvider:batchSize:forPrediction:neuralNetworkEngine:error:
featureProviderFomMLComputeDataProvider:neuralNetworkEngine:options:error:
mlComputeDataTypeSize:
sizeFromShape:
parameterDescriptionForKey:boolParameterSpec:
parameterDescriptionForKey:doubleParameterSpec:
constraintWithShape:dataType:
featureDescriptionWithName:consistentWithFeatureValues:error:
initWithValueDescription:countRange:
featureValuesWithConsistentTypeFromArray:error:
characterSetWithCharactersInString:
componentsSeparatedByCharactersInSet:
pathForResource:ofType:
stringByTrimmingCharactersInSet:
isAbsolutePath
stringByStandardizingPath
parameterDescriptionForKey:stringParameterSpec:
stringByDeletingLastPathComponent
findFile:inSearchPath:basePath:
areFeaturesIn:modelNamed:aSubsetOf:error:
initWithLinkedModel:modelFileName:modelSearchPath:configuration:
updateParameterDescriptionsByUnarchivingSpecification:
linkedModel
modelFileName
modelSearchPath
setLinkedModel:
setModelFileName:
setModelSearchPath:
_linkedModel
_modelFileName
_modelSearchPath
T@"MLModel",&,V_linkedModel
T@"NSString",&,V_modelFileName
T@"NSString",&,V_modelSearchPath
setMinNumber:
setMaxNumber:
setEnumeratedNumbers:
valueForKeyPath:
decodeObjectForKey:
numericConstraintWithEnumeratedNumbers:
numericConstraintWithMinNumber:maxNumber:
_minNumber
_maxNumber
_enumeratedNumbers
T@"NSNumber",&,N,V_minNumber
T@"NSNumber",&,N,V_maxNumber
T@"NSSet",&,N,V_enumeratedNumbers
extractRecordTransports
substituteRecordTransports:
containerIDForContainerIdentifier:environment:
initWithContainerID:
serviceName
initWithServiceName:functionName:responseClass:
teamIdentifier
setRequest:
setQualityOfService:
message
setCodeOperationCompletionBlock:
publicCloudDatabase
addOperation:
initWithTeamIdentifier:
fetchKeyResponseFromServerForKeyID:signedKeyRequest:error:
setServiceName:
setContainer:
_serviceName
_teamIdentifier
T@"NSString",&,N,V_serviceName
T@"CKContainer",&,N,V_container
T@"NSString",R,C,N,V_teamIdentifier
saveCustomWordTaggingModelToURL:modelData:stringInputName:classname:NSError:
saveCustomSentenceClassifierModelToURL:modelData:stringInputName:classname:NSError:
saveCustomSequenceModelToURL:modelData:stringInputName:classname:NSError:
saveCustomSentenceModelToURL:modelData:stringInputName:classname:NSError:
dataWithContentsOfFile:
getNetJson:error:
dataWithJSONObject:options:error:
writeToFile:atomically:
moveItemAtPath:toPath:error:
getLayerTypes:error:
getLayerHints:error:
updateHints:hints:error:
undoLastHintUpdate:error:
inputRank
multiples
inputShape
outputShape
_inputRank
_multiples
_inputShape
_outputShape
TQ,R,N,V_inputRank
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_multiples
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_inputShape
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_outputShape
initWithBase64EncodedString:options:
filePathURL
sinfData
T@"NSData",R,&,N
setDictionary:
_dictionary
T@"NSDictionary",&,N,V_dictionary
initWithFeatureProvider:featureNames:
featureValueWithObject:
T@"MLSVMEngine",&,V_engine
initFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
setDispatchQueue:
dispatchQueue
updatableModelIndicies
_dispatchQueue
_updatableModelIndicies
T{vector<unsigned long long, std::allocator<unsigned long long>>=^Q^Q{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>=^Q}},R,V_updatableModelIndicies
T@"MLUpdateProgressHandlers",&,V_progressHandlers
T@"NSObject<OS_dispatch_queue>",&,V_dispatchQueue
loadProgramAtURL:error:
updateOptionalDefaultValueParametersInContainer:usingProgram:
initWithStringClassProbability:classFeatureType:additionalFeatures:
initWithIntClassProbability:classFeatureType:additionalFeatures:
initWithClassProbability:additionalFeatures:classLabelOfMaxProbability:
_predictedClass
_classProbability
_predictedClassFeatureType
T@"MLFeatureValue",R,V_predictedClass
T@"NSDictionary",R,V_classProbability
Tq,R,V_predictedClassFeatureType
featureValueFromDetectionPrint:featureName:
detectionPrintRequestRevision
expectedOutputShapeV1
_detectionPrintRequestRevision
_expectedOutputShapeV1
TQ,R,N,V_detectionPrintRequestRevision
T@"NSDictionary",R,N,V_expectedOutputShapeV1
step
_step
T@"NSNumber",R,N,V_step
T@"NSNumber",R,N,V_size
lossType
optimizerType
optimizerParameters
lossParameters
trainableLayerNames
setClass:forClassName:
initWithLossType:optimizerType:optimizerParameters:lossParameters:trainableLayerNames:updateParameters:
writeUpdatableParamsToURL:error:
setLossType:
setOptimizerType:
setOptimizerParameters:
setLossParameters:
setTrainableLayerNames:
_lossType
_optimizerType
_optimizerParameters
_lossParameters
_trainableLayerNames
Tq,N,V_lossType
Tq,N,V_optimizerType
T@"NSDictionary",&,N,V_optimizerParameters
T@"NSDictionary",&,N,V_lossParameters
T@"NSArray",&,N,V_trainableLayerNames
setMessage:
hasMessage
_message
T@"NSString",&,N,V_message
initWithData:language:inputFeatureName:outputFeatureName:modelData:labelNames:error:
saveAppleTextClassifierModelToURL:textClassifierParameters:error:
textClassifierModel
T@"MLAppleTextClassifierParameters",R,V_parameters
intersectsSet:
prepareArgumentsFromFeatures:context:forFunctionName:
updateContext:functionName:result:
splitIndex
splitDimension
encodeFloat:forKey:
startingIndex
rightChild
leftChild
boundingBox
isLeaf
decodeFloatForKey:
splitValue
setSplitIndex:
findMin:andMax:alongDimension:data:indices:numDimensions:
setSplitDimension:
setSplitValue:
partitionDataPoints:indices:numDimensions:
assignSplitsForData:indices:numDimensions:
print
setStartingIndex:
setCount:
setLeftChild:
setRightChild:
setBoundingBox:
setIsLeaf:
_isLeaf
_splitValue
_splitDimension
_splitIndex
_startingIndex
_count
_leftChild
_rightChild
_boundingBox
TQ,N,V_splitDimension
TQ,N,V_splitIndex
Tf,N,V_splitValue
TQ,N,V_startingIndex
TQ,N,V_count
T@"_KDNode",&,N,V_leftChild
T@"_KDNode",&,N,V_rightChild
T{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q},N,V_boundingBox
TB,N,V_isLeaf
constructTree
root
findK:nearestNeighbors:toQueryPoint:inTree:
constructTreeForPointsBoundedBy:startingIndex:count:
calculateDistancesForNodesBetweenLeft:andRight:toQueryPoint:
setRoot:
vIndices
_root
TQ,N,V_leafSize
T@"_KDNode",&,N,V_root
setBatchProvider:
indices
randomNumberGenerator
T@"<MLBatchProvider>",&,V_batchProvider
stringWithCapacity:
loss
evaluationMetrics
_loss
_evaluationMetrics
Td,V_loss
T@"<MLBatchProvider>",&,V_evaluationMetrics
confidenceOutputFeatureName
coordinatesOutputFeatureName
suppressionMethod
setSuppressionMethod:
iouThreshold
setIouThreshold:
confidenceThreshold
setConfidenceThreshold:
minBoxes
setMinBoxes:
maxBoxes
setMaxBoxes:
perClass
setPerClass:
confidenceInputFeatureName
setConfidenceInputFeatureName:
coordinatesInputFeatureName
setCoordinatesInputFeatureName:
iouThresholdInputFeatureName
setIouThresholdInputFeatureName:
confidenceThresholdInputFeatureName
setConfidenceThresholdInputFeatureName:
setConfidenceOutputFeatureName:
setCoordinatesOutputFeatureName:
_perClass
_suppressionMethod
_iouThreshold
_confidenceThreshold
_minBoxes
_maxBoxes
_confidenceInputFeatureName
_coordinatesInputFeatureName
_iouThresholdInputFeatureName
_confidenceThresholdInputFeatureName
_confidenceOutputFeatureName
_coordinatesOutputFeatureName
Ti,V_suppressionMethod
Td,V_iouThreshold
Td,V_confidenceThreshold
TQ,V_minBoxes
Tq,V_maxBoxes
TQ,V_numClasses
TB,V_perClass
T@"NSString",&,V_confidenceInputFeatureName
T@"NSString",&,V_coordinatesInputFeatureName
T@"NSString",&,V_iouThresholdInputFeatureName
T@"NSString",&,V_confidenceThresholdInputFeatureName
T@"NSString",&,V_confidenceOutputFeatureName
T@"NSString",&,V_coordinatesOutputFeatureName
T@"MLNonMaximumSuppressionParameters",R,V_parameters
lazyBatchWindowIntoBatch:startIndex:windowLength:error:
batchFromConcatinatingBatches:
predictionsFromSubbatchingBatch:maxSubbatchLength:predictionBlock:options:error:
operationHandle
_executeStream:error:
streamHandle
setStreamHandle:
_operations
_streamHandle
T^{e5rt_execution_stream=},V_streamHandle
T@"NSArray",C,V_operations
T{vector<int, std::allocator<int>>=^i^i{__compressed_pair<int *, std::allocator<int>>=^i}},R,N,V_shape
sharedFeatureFlags
isMPSGraphEnabled
isMPSGraphFP16Enabled
initWithState:
_progressHandlerBlock
_completionHandlerBlock
updateTaskForModelAtURL:trainingData:configuration:progressHandlers:error:
updateTaskForModelAtURL:trainingData:configuration:completionHandler:error:
initWithModelAtURL:trainingData:configuration:progressHandlers:error:
resumeWithTaskContext:
updatableModel
updateHasStarted
setUpdateHasStarted:
updateQueue
trainingData
_invokeProgressHandlerForContext:
suspendWithTaskContext:
failWithError:taskContext:
completeWithTaskContext:
updatableModelURL
state
taskStatesToString:
updateModelAtURL:trainingData:configuration:writeToURL:error:
updateTaskForModelAtURL:trainingData:completionHandler:error:
updateTaskForModelAtURL:trainingData:progressHandlers:error:
onResumptionWithTaskContext:
onSuspensionWithTaskContext:
onCancellation
onCompletionWithTaskContext:
onFailureWithTaskContext:
resumeWithParameters:
_updateHasStarted
_updatableModel
_trainingData
_updateQueue
_updatableModelURL
T@"MLModel<MLUpdatable>",R,N,V_updatableModel
T@"<MLBatchProvider>",R,N,V_trainingData
T@"MLUpdateProgressHandlers",R,N,V_progressHandlers
TB,N,V_updateHasStarted
T@"NSObject<OS_dispatch_queue>",R,N,V_updateQueue
T@"NSURL",R,N,V_updatableModelURL
initializeEmbeddingModelWithData:error:
predictVectorForString:inputString:error:
NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
NLPSequenceModelCreateWithDataImpl
NLPSequenceModelGetRevisionImpl
NLPSequenceModelIsRevisionSupportedImpl
NLPSequenceModelGetCurrentRevisionImpl
NLPClassifierModelCopyPredictedLabelForTextImpl
NLPClassifierModelCreateWithDataImpl
NLPClassifierModelGetRevisionImpl
NLPClassifierModelIsRevisionSupportedImpl
NLPClassifierModelGetCurrentRevisionImpl
NLPGazetteerModelCopyLabelForStringImpl
NLPGazetteerModelCreateWithDataImpl
NLPGazetteerModelGetRevisionImpl
NLPGazetteerModelIsRevisionSupportedImpl
NLPGazetteerModelGetCurrentRevisionImpl
NLPEmbeddingModelCopyVectorForStringImpl
NLPEmbeddingModelCreateWithDataImpl
NLPEmbeddingModelGetRevisionImpl
NLPEmbeddingModelIsRevisionSupportedImpl
NLPEmbeddingModelGetCurrentRevisionImpl
_valid
_NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
_NLPSequenceModelCreateWithDataImpl
_NLPSequenceModelGetRevisionImpl
_NLPSequenceModelIsRevisionSupportedImpl
_NLPSequenceModelGetCurrentRevisionImpl
_NLPClassifierModelCopyPredictedLabelForTextImpl
_NLPClassifierModelCreateWithDataImpl
_NLPClassifierModelGetRevisionImpl
_NLPClassifierModelIsRevisionSupportedImpl
_NLPClassifierModelGetCurrentRevisionImpl
_NLPGazetteerModelCopyLabelForStringImpl
_NLPGazetteerModelCreateWithDataImpl
_NLPGazetteerModelGetRevisionImpl
_NLPGazetteerModelIsRevisionSupportedImpl
_NLPGazetteerModelGetCurrentRevisionImpl
_NLPEmbeddingModelCopyVectorForStringImpl
_NLPEmbeddingModelCreateWithDataImpl
_NLPEmbeddingModelGetRevisionImpl
_NLPEmbeddingModelIsRevisionSupportedImpl
_NLPEmbeddingModelGetCurrentRevisionImpl
T^?,R,N,V_NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
T^?,R,N,V_NLPSequenceModelCreateWithDataImpl
T^?,R,N,V_NLPSequenceModelGetRevisionImpl
T^?,R,N,V_NLPSequenceModelIsRevisionSupportedImpl
T^?,R,N,V_NLPSequenceModelGetCurrentRevisionImpl
T^?,R,N,V_NLPClassifierModelCopyPredictedLabelForTextImpl
T^?,R,N,V_NLPClassifierModelCreateWithDataImpl
T^?,R,N,V_NLPClassifierModelGetRevisionImpl
T^?,R,N,V_NLPClassifierModelIsRevisionSupportedImpl
T^?,R,N,V_NLPClassifierModelGetCurrentRevisionImpl
T^?,R,N,V_NLPGazetteerModelCopyLabelForStringImpl
T^?,R,N,V_NLPGazetteerModelCreateWithDataImpl
T^?,R,N,V_NLPGazetteerModelGetRevisionImpl
T^?,R,N,V_NLPGazetteerModelIsRevisionSupportedImpl
T^?,R,N,V_NLPGazetteerModelGetCurrentRevisionImpl
T^?,R,N,V_NLPEmbeddingModelCopyVectorForStringImpl
T^?,R,N,V_NLPEmbeddingModelCreateWithDataImpl
T^?,R,N,V_NLPEmbeddingModelGetRevisionImpl
T^?,R,N,V_NLPEmbeddingModelIsRevisionSupportedImpl
T^?,R,N,V_NLPEmbeddingModelGetCurrentRevisionImpl
valid
TB,R,N,GisValid,V_valid
addFeature:withControlName:defaultValue:
isFeatureEnabled:
standardUserDefaults
defineFeatures
flags
controlKeyForFeature:
userDefaults
registerDefaults:
environment
boolForKey:
overrideOriginalValues
setOverride:forFeature:
removeOverrideForFeature:
_userDefaults
_flags
_overrideOriginalValues
T@"NSUserDefaults",R,N,V_userDefaults
T@"NSMutableDictionary",R,N,V_flags
T@"NSMutableDictionary",R,N,V_overrideOriginalValues
featuresPredictionDuration
featuresPredictionCountSoFar
predictionEventQueue
_featuresPredictionCountSoFar
_featuresPredictionDuration
initWithUsesCPUOnly:
maxComputationBatchSize
setClassifyTopK:
setMaxComputationBatchSize:
setOutputBackings:
setAutomaticOutputBackingMode:
usesCPUOnly
setUsesCPUOnly:
enablePixelBufferDirectBinding
setEnablePixelBufferDirectBinding:
_usesCPUOnly
_enablePixelBufferDirectBinding
_outputBackings
_parentSignpostID
_classifyTopK
_automaticOutputBackingMode
_maxComputationBatchSize
TQ,N,V_parentSignpostID
TQ,V_classifyTopK
T@"NSDictionary",C,N,V_automaticOutputBackingMode
TQ,V_maxComputationBatchSize
TB,N,V_enablePixelBufferDirectBinding
TB,N,V_usesCPUOnly
T@"NSDictionary",C,N,V_outputBackings
initWithData:language:inputFeatureName:tokensFeatureName:tokenTagsFeatureName:tokenLocationsFeatureName:tokenLengthsFeatureName:modelData:tagNames:metadata:error:
initWithData:language:inputFeatureName:tokensFeatureName:tokenTagsFeatureName:tokenLocationsFeatureName:tokenLengthsFeatureName:modelData:tagNames:error:
tokensOutputFeatureName
setTokensOutputFeatureName:
tokenTagsOutputFeatureName
setTokenTagsOutputFeatureName:
tokenLocationsOutputFeatureName
setTokenLocationsOutputFeatureName:
tokenLengthsOutputFeatureName
setTokenLengthsOutputFeatureName:
tagNames
setTagNames:
_tokensOutputFeatureName
_tokenTagsOutputFeatureName
_tokenLocationsOutputFeatureName
_tokenLengthsOutputFeatureName
_tagNames
T@"NSString",&,V_tokensOutputFeatureName
T@"NSString",&,V_tokenTagsOutputFeatureName
T@"NSString",&,V_tokenLocationsOutputFeatureName
T@"NSString",&,V_tokenLengthsOutputFeatureName
T@"NSArray",&,V_tagNames
saveAppleWordTaggingModelToURL:wordTaggerParameters:error:
wordTaggingModel
T@"MLAppleWordTaggerParameters",R,V_parameters
featureNamesInBatch:
dictionaryFromBatch:featureNames:
dictionaryFromBatch:
featureProviderArrayFromBatch:
featureValueArrayForName:batch:error:
featureDescriptionsByNameForBatch:error:
initWithFeaturesFrom:addedToFeaturesFrom:error:
T@"<MLBatchProvider>",&,N,V_first
T@"<MLBatchProvider>",&,N,V_second
initWithBatch:startIndex:windowLength:error:
fullBatch
setFullBatch:
startIndex
setStartIndex:
windowLength
setWindowLength:
_fullBatch
_startIndex
_windowLength
T@"<MLBatchProvider>",&,N,V_fullBatch
Tq,N,V_startIndex
Tq,N,V_windowLength
initWithBatch:indices:error:
setIndices:
_indices
T@"NSArray",&,N,V_indices
vectorizeFeaturesNamed:fromBatch:intoRowsOfDoubleMatrix:error:
setData:
hasData
_data
T@"NSData",&,N,V_data
_createOperationAndReturnError:
setOperationHandle:
inputFeatures
_newArrayOfInputPortsBoundToFeatures:error:
setInputPorts:
inputPorts
_newArrayOfBoundedOutputPortsUsingOutputBackings:error:
setOutputPorts:
outputPorts
setState:
debugLabel
_inputPortNames
_newArrayOfUnboundedPortsForPortNames:featureDescriptionsByName:portFactoryFunction:error:
_outputPortNames
_inputFeatures
_operationHandle
_debugLabel
_inputPorts
_outputPorts
_state
T@"NSString",R,C,V_functionName
T^{e5rt_execution_stream_operation=},V_operationHandle
T@"NSArray",C,V_inputPorts
T@"NSArray",C,V_outputPorts
Tq,V_state
T@"<MLFeatureProvider>",&,V_inputFeatures
T@"<MLFeatureProvider>",R
T@"NSString",R,C,V_debugLabel
initWith:imputeValue:replaceValue:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
validateAllFeatureDescriptions:hasAnyFeatureTypeIn:minimalCount:maximumCount:debugLabel:error:
imputeValueFrom:replaceValue:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
imputeValueFrom:replaceValue:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
imputeValue
replaceValue
_imputeValue
_replaceValue
T@"MLFeatureValue",R,N,V_imputeValue
T@"MLFeatureValue",R,N,V_replaceValue
rangeFromAllowedSizeRangeProtoMessage:
initWithPixelsWideRange:pixelsHighRange:
populateConstraintsForImageFeatureDescription:
constraintWithShape:dataType:shapeConstraint:
populateConstraintsForFeatureDescription:
descriptionFromProto:
orderedNamesFromProto:
populateConstraintsForImageFeatureDescriptionElement:
calculateClassProbability:input:error:
classify:error:
classify:topK:error:
classType
classEncoding
valueDescription
countRange
_valueDescription
_countRange
T@"MLFeatureDescription",R,N,V_valueDescription
T{_NSRange=QQ},R,N,V_countRange
transformKeyIdentifier:error:
generateKeyRequestForKeyIdentifier:teamIdentifier:error:
generatePersistentKeyBlobFromKeyResponse:error:
keyIdentifier
setKeyIdentifier:
sessionID
setSessionID:
_sessionID
_keyIdentifier
T@"NSString",C,V_keyIdentifier
TI,V_sessionID
getImageFeatureTypeFromConstraint:
getArrayFeatureTypeFromConstraint:
getDictionaryFeatureTypeFromConstraint:error:
getSequenceFeatureTypeFromConstraint:error:
createFeatureTypeFromFeatureDescription:error:
createMetaData:
copyFeatureDescriptionFrom:to:error:
createModelDescription:error:
saveModelDescription:toSpecification:error:
initWithCompiledArchive:configuration:error:
classesByString
classesByInt
loadParameterDescriptionsAndContainerFromConfiguration:modelDescription:error:
setPersonalization:
setBoosterParameters:error:
personalization
setClassesByString:
setClassesByInt:
mmappedModel
setMmappedModel:
cachedModel
setCachedModel:
_personalization
_mmappedModel
_classesByString
_classesByInt
_cachedModel
TB,N,V_personalization
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_classesByString
T{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}},N,V_classesByInt
T{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}},N,V_mmappedModel
T{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}},N,V_cachedModel
initWithName:shortDescription:versionString:author:license:creatorDefined:
initWithName:
author
license
creatorDefined
_shortDescription
_versionString
_author
_license
_creatorDefined
T@"NSString",R,V_shortDescription
T@"NSString",R,V_versionString
T@"NSString",R,V_author
T@"NSString",R,V_license
T@"NSDictionary",R,V_creatorDefined
initWith:dimensionEncoding:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
replaceObjectAtIndex:withObject:
vectorizeOneHotEncoderDict:index:error:
columnNameEncoding
dimensionEncoding
_output_array_shape
index_mapping
_columnNameEncoding
_dimensionEncoding
T@"NSArray",R,N,V_columnNameEncoding
T@"NSArray",R,N,V_dimensionEncoding
objCType
getValue:size:
featureValueWithImageAtURL:constraint:options:error:
cropRectFromOptions:
visionCropAndScaleOptionFromOptions:
featureValueWithCGImage:constraint:options:error:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:orientation:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:orientation:constraint:options:error:
featureValueWithCGImage:orientation:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithCGImage:orientation:constraint:options:error:
initWith:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
initWithArray:
constructDictionary:error:
categoryName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
categoryName:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
categoryName
_categoryName
T@"NSOrderedSet",R,N,V_categoryName
initFileURLWithPath:isDirectory:
moveItemAtURL:toURL:error:
UUID
UUIDString
currentProcess
isApplication
compileModelWithoutAutoreleaseAtURL:options:error:
compileModelAtURL:error:
compileModelAtURL:completionHandler:
initWith:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
inputDescriptionFrom:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
normFrom:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
normFrom:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
norm
_norm
Ti,R,N,V_norm
initWithData:language:inputFeatureName:outputFeatureName:modelData:metadata:error:
initWithData:language:inputFeatureName:outputFeatureName:modelData:error:
saveAppleWordEmbeddingModelToURL:wordEmbeddingParameters:error:
wordEmbeddingModel
T@"MLAppleWordEmbeddingParameters",R,V_parameters
_canResume
_resumeWithTaskContext:
_canCancel
_canSuspend
_canComplete
_canFail
cancel
T@"NSError",C,V_error
T@"NSObject<OS_dispatch_queue>",R,N,V_syncQueue
T@"NSString",R,C,N,V_taskIdentifier
initWithMapping:valueOnUnknown:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
mapFeature:error:
mapping
valueOnUnknown
_mapping
_valueOnUnknown
T@"NSDictionary",R,N,V_mapping
T@"MLFeatureValue",R,N,V_valueOnUnknown
initWith:scaleValue:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
shiftValue
scaleValue
_shiftValue
_scaleValue
T@"MLFeatureValue",R,N,V_shiftValue
T@"MLFeatureValue",R,N,V_scaleValue
initWith:dataTransformerName:ouputSparse:handleUnknown:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
encodeFeatureValue:
encodeFeatureValueIntString:
handleUnknown
unknownDenseVector
featureEncoderFrom:inputDescription:orderedInputFeatureNames:
featureEncoderFrom:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
featureEncoderFrom:dataTransformerName:ouputSparse:handleUnknown:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
featureEncoding
ouputSparse
_ouputSparse
_handleUnknown
_featureEncoding
T@"NSOrderedSet",R,N,V_featureEncoding
TB,R,N,V_ouputSparse
TB,R,N,V_handleUnknown
setRestrictNeuralNetworksFromUsingANE:
setRestrictNeuralNetworksToUseCPUOnly:
globalSettingsFromSettings:
isNeuralNetworkGPUPathForbidden
_restrictNeuralNetworksToUseCPUOnly
_restrictNeuralNetworksFromUsingANE
_isNeuralNetworkGPUPathForbidden
TB,V_restrictNeuralNetworksToUseCPUOnly
TB,V_restrictNeuralNetworksFromUsingANE
TB,R,N,V_isNeuralNetworkGPUPathForbidden
setFeatureName:to:descriptions:
setInputFeatureName:to:
setOutputFeatureName:to:
validateModelDescription:
initWithDescription:numberOfFeatures:priorMean:regressionInputName:optimismInputName:samplingScaleInputName:samplingTruncationInputName:meanOutputName:varianceOutputName:pessimisticProbabilityOutputName:sampledProbabilityOutputName:
getArrayFeatureValue:
getFeatureValue:forName:withType:
getOneHotFeatureValues:error:
getOptimism:
getSamplingScale:
getSamplingTruncation:
createRegressorResult:
updateModelFromFeatures:toTarget:error:
convertOutputFeatureToPredictionValues:event:importance:error:
isEqualToBopr:
updateModelFromFeatures:toTarget:options:error:
setFeatureCount:
FeatureCount
initWithDescription:numberOfFeatures:priorMean:
createCheckpoint
resetToLastCheckpointBeforeDate:
_regressionInputFeatureName
_optimismInputFeatureName
_meanOutputFeatureName
_varianceOutputFeatureName
_pessimisticProbabilityOutputFeatureName
_sampledProbabilityOutputFeatureName
_samplingScaleInputFeatureName
_samplingTruncationInputFeatureName
getBytes:range:
replaceBytesInRange:withBytes:
keyEnumerator
initWithLabels:
indexOfLabel:
uniqueLabelCount
labelAtIndex:
labelEnumerator
_labelToIndex
_labels
T@"NSEnumerator",R,N
probabilityAtIndex:
maxElementIndex
initWithMultiArray:count:
initWithFloat64CArray:count:
initWithArray:count:
initWithLabelIndexMap:storage:
initWithSharedKeySet:probabilityArray:
storage
labelIndexMap
initWithObjects:forKeys:count:
_labelIndexMap
_storage
T@"MLProbabilityDictionarySharedKeySet",R,V_labelIndexMap
T@"<MLProbabilityDictionaryStorage>",R,V_storage
arrayByAddingObject:
setScopedModelNames:
setLayerName:
isEqualToMLLayerPath:
_scopedModelNames
T@"NSString",C,N,V_layerName
T@"NSArray",C,N,V_scopedModelNames
initWithShape:dataType:shapeConstraint:
isAllowedDataType:error:
_dataType
_shapeConstraint
Tq,R,N,V_dataType
T@"MLMultiArrayShapeConstraint",R,N,V_shapeConstraint
imageSizeSet
pixelsWideRange
pixelsHighRange
enumeratedImageSizes
_imageSizeSet
_pixelsWideRange
_pixelsHighRange
T@"NSOrderedSet",R,N,V_imageSizeSet
T{_NSRange=QQ},R,N,V_pixelsWideRange
T{_NSRange=QQ},R,N,V_pixelsHighRange
locationClosestTo:inRange:
closestImageSizeInArray:toImageSize:preferDownScaling:
closestImageSizeInPixelsWideRange:pixelsHighRange:toImageSize:preferInputAspectRatio:
initWith:indices:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
extractArrayElement:indices:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
extractArrayElement:indices:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
arrayColumnName
extractIndices
outputType
_arrayColumnName
_extractIndices
_outputType
T@"NSString",R,N,V_arrayColumnName
T@"NSArray",R,N,V_extractIndices
Tq,R,N,V_outputType
watchdogWithTimeout:label:queue:
setTimer:
timer
watchdogWithTimeout:queue:
_timer
T@"NSObject<OS_dispatch_source>",&,V_timer
registerBrickClass:
initWithData:encoding:
@32@0:8@16^@24
@40@0:8@16@24^@32
@16@0:8
v32@0:8@16@24
v24@0:8@16
@"<MLFeatureProvider>"32@0:8@"<MLFeatureProvider>"16^@24
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"32@0:8@"<MLBatchProvider>"16^@24
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelExecutionSchedule"16@0:8
v32@0:8@"MLLayerPath"16@"NSString"24
@"MLLayerPath"16@0:8
@"MLModelDescription"16@0:8
v24@0:8@"MLModelDescription"16
@"MLModelMetadata"16@0:8
@"NSArray"16@0:8
@"MLClassifierResult"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@40@0:8@16@24@32
v16@0:8
@"NSURL"
@"NSString"
@"NSDictionary"
@"NSMutableSet"
@"NSObject<OS_dispatch_queue>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16^@24
@"NSDictionary"32@0:8Q16^@24
@44@0:8@16B24@28^@36
@"NSDictionary"16@0:8
@"NSNumber"
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B32@0:8@16^@24
B32@0:8@"MLFeatureValue"16^@24
@24@0:8^{_NSZone=}16
@24@0:8q16
q16@0:8
@40@0:8@16#24@32
@32@0:8@16@24
v32@0:8^v16Q24
v40@0:8@16@24@32
B24@0:8Q16
@"NSArray"32@0:8@"NSArray"16@"NSDictionary"24
@24@0:8@"NSDictionary"16
v32@0:8@"NSArray"16@"NSArray"24
v40@0:8@"<MTLCommandBuffer>"16@"NSArray"24@"NSArray"32
@"NSArray"24@0:8@"NSArray"16
@"NSArray"
@"MLFeatureValue"16@0:8
@24@0:8^{e5rt_io_port=}16
^{e5rt_io_port=}16@0:8
^{e5rt_io_port=}
@"MLFeatureValue"
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"MLModelDescription"
i16@0:8
v20@0:8i16
v20@0:8B16
@20@0:8i16
i24@0:8@16
@"ModelKeyServerAPIRawKey"
@"ModelKeyServerAPISignedKey"
{?="key"b1}
@32@0:8@16@?24
v32@0:8@16@?24
B24@0:8@?16
@"TRIClient"
@"MLModelConfiguration"
@"MLPredictionOptions"
v24@0:8^v16
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8r^v16
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8Q16
f24@0:8Q16
d24@0:8r^v16
d24@0:8Q16
d24@0:8@16
@"<MLNearestNeighborsIndex>"
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"MLParameterContainer"
@32@0:8^{e5rt_io_port=}16^@24
@32@0:8q16q24
@80@0:8Q16@24@32@40@48@56@64^@72
v24@0:8Q16
@"NSData"
@40@0:8^v16@24^@32
B40@0:8@16@24^@32
@"<MLModeling>"40@0:8^v16@"MLModelConfiguration"24^@32
@56@0:8@16@24@32@40^@48
@"MLAppleGazetteerParameters"
@40@0:8@16q24^@32
@72@0:8^v16@24q32@40@?48@?56^@64
@64@0:8^v16@24q32@40@?48^@56
@32@0:8{shared_ptr<CoreML::MultiArrayBuffer>=^{MultiArrayBuffer}^{__shared_weak_count}}16
@32@0:8^{__CVBuffer=}16@24
@24@0:8Q16
v32@0:8@16Q24
v32@0:8@16q24
Q24@0:8@16
^v16@0:8
^{__CVBuffer=}16@0:8
{unique_ptr<StorageManager, std::default_delete<StorageManager>>="__ptr_"{__compressed_pair<StorageManager *, std::default_delete<StorageManager>>="__value_"^{StorageManager}}}
v24@0:8@?16
r^v16@0:8
B24@0:8q16
^d16@0:8
^f16@0:8
i24@0:8q16
@48@0:8@16q24q32^@40
@48@0:8@16q24q32Q40
@56@0:8^v16@24q32@40@?48
@32@0:8@16q24
@40@0:8@16@24q32
B40@0:8@16q24^@32
B48@0:8@16^Q24^Q32^@40
B48@0:8@16q24^Q32^@40
@40@0:8@16q24q32
B40@0:8@16Q24^@32
@"MLMultiArray"
B32@0:8@16@24
v48@0:8@16@24^@32^@40
@52@0:8@16@24@32B40^@44
@44@0:8@16@24B32^@36
@32@0:8{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}}16
@24@0:8{unique_ptr<MIL::IRProgram, std::default_delete<MIL::IRProgram>>={__compressed_pair<MIL::IRProgram *, std::default_delete<MIL::IRProgram>>=^{IRProgram}}}16
@32@0:8{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}16
{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}}16@0:8
{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}16@0:8
{shared_ptr<Espresso::net>="__ptr_"^{net}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<MIL::IRProgram>="__ptr_"^{IRProgram}"__cntrl_"^{__shared_weak_count}}
@"MLParameterKey"
@"MLNumericConstraint"
@48@0:8@16@24@32^@40
@40@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16B24B28Q32
^{svm_node=id}24@0:8Q16
v40@0:8^{svm_node=id}16r^d24Q32
v24@0:8^{svm_node=id}16
^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16@0:8
v24@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16
^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}
B32@0:8^{__CVBuffer=}16^@24
B36@0:8^{__CVBuffer=}16B24^@28
^{__CVBuffer=}32@0:8@16^@24
^{__CVBuffer=}36@0:8@16B24^@28
@48@0:8q16@24@32[1{__va_list_tag=II^v^v}]40
@40@0:8q16@24[1{__va_list_tag=II^v^v}]32
@40@0:8q16@24@32
@32@0:8q16@24
@28@0:8i16@20
v32@0:8^v16r^v24
B40@0:8^v16^v24^@32
@48@0:8^v16^v24@32^@40
@"MLCompilerResult"48@0:8^v16^v24@"MLCompilerOptions"32^@40
@"MLVersionInfo"40@0:8^v16@"MLCompilerOptions"24^@32
@48@0:8@16@24@32@40
B24@0:8^v16
@64@0:8^v16@24@32@40@48^@56
@56@0:8^v16@24@32@40^@48
@68@0:8@16@24@32@40@48B56@60
@76@0:8@16@24@32@40@48B56@60@68
{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}
@"MLModel"
@"MLNeuralNetworksCompileTimeParams"
@"MLVersionInfo"
@"MLCompilerNeuralNetworkOutput"
@36@0:8{CGSize=dd}16I32
{CGSize=dd}16@0:8
I16@0:8
{CGSize="width"d"height"d}
@"MLRegressorResult"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@56@0:8^v16@"MLVersionInfo"24@"MLVersionInfo"32@"MLModelConfiguration"40^@48
@28@0:8^{__CVBuffer=}16I24
^{__CVBuffer=}28@0:8^{__CVBuffer=}16I24
^{__CVPixelBufferPool=}36@0:8{CGSize=dd}16I32
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
^{__CVBuffer=}32@0:8@16@24
v36@0:8@16q24i32
i32@0:8@16^@24
B28@0:8B16^@20
B36@0:8@16B24^@28
B32@0:8^v16^@24
B40@0:8@16B24B28^@32
B56@0:8@16@24Q32@40^@48
q32@0:8@16^@24
B48@0:8@16^{__CVBuffer=}24@32^@40
B40@0:8^{__CVBuffer=}16@24^@32
B48@0:8@16@24Q32^@40
B48@0:8@16Q24@32^@40
B48@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^@40
B56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^i40^@48
B56@0:8r^v16@24@32@40^@48
B24@0:8^@16
v52@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32@40B48
@48@0:8@16Q24@32^@40
B32@0:8r^v16^@24
@48@0:8Q16@24@32^@40
B48@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16Q24^{__CVBuffer=}32^@40
@48@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^{__CVBuffer=}24@32^@40
@56@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32@40^@48
^{__CVBuffer=}40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
@40@0:8@16^@24^@32
B80@0:8^v16^v24^v32^v40^v48^v56^v64^@72
Q20@0:8i16
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{vector<std::map<std::string, espresso_buffer_t *>, std::allocator<std::map<std::string, espresso_buffer_t *>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::map<std::string, espresso_buffer_t *> *, std::allocator<std::map<std::string, espresso_buffer_t *>>>="__value_"^v}}
{map<std::string, Espresso::vimage2espresso_param, std::less<std::string>, std::allocator<std::pair<const std::string, Espresso::vimage2espresso_param>>>="__tree_"{__tree<std::__value_type<std::string, Espresso::vimage2espresso_param>, std::__map_value_compare<std::string, std::__value_type<std::string, Espresso::vimage2espresso_param>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, Espresso::vimage2espresso_param>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, Espresso::vimage2espresso_param>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, Espresso::vimage2espresso_param>, std::less<std::string>, true>>="__value_"Q}}}
{vector<bool, std::allocator<bool>>="__begin_"^Q"__size_"Q"__cap_alloc_"{__compressed_pair<unsigned long, std::allocator<unsigned long>>="__value_"Q}}
{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}
{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__cap_"Q"__size_"Q"__data_"*}"__s"{__short=""(?="__size_"C"__lx"c)"__data_"[23c]}"__r"{__raw="__words"[3Q]})}}}
{map<std::string, bool, std::less<std::string>, std::allocator<std::pair<const std::string, bool>>>="__tree_"{__tree<std::__value_type<std::string, bool>, std::__map_value_compare<std::string, std::__value_type<std::string, bool>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, bool>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, bool>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, bool>, std::less<std::string>, true>>="__value_"Q}}}
@"NSMutableDictionary"
^{OpaqueVTPixelTransferSession=}
@"NSObject<OS_dispatch_semaphore>"
@"EspressoProfilingNetworkInfo"
{?="plan"^v"network_index"i}
@32@0:8^v16^@24
@"NSObject<MLCustomModel>"
v24@0:8q16
@"<MTLDevice>"
@64@0:8Q16@24q32@40Q48q56
@"<MLFeatureProvider>"24@0:8q16
B32@0:8@"NSURL"16^@24
v32@0:8@"MLUpdateProgressHandlers"16@"NSObject<OS_dispatch_queue>"24
v24@0:8@"<MLBatchProvider>"16
v24@0:8@"NSDictionary"16
@"MLModel<MLUpdatable>"56@0:8^v16@"MLVersionInfo"24@"MLVersionInfo"32@"MLModelConfiguration"40^@48
@64@0:8@16@24@32^v40@48^@56
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8@16
v32@0:8^@16^v24
v56@0:8^@16^@24{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32
@"MLUpdateProgressHandlers"
@"NSOrderedSet"
@"NSObject"
@24@0:8^v16
@80@0:8@16@24@32@40@48@56@64@72
@64@0:8@16@24@32@40@48@56
@56@0:8@16@24@32@40@48
@"MLLayerPath"
@"MLPipeline"
r*16@0:8
B40@0:8@16^v24^@32
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long long, std::allocator<unsigned long long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>="__value_"^Q}}
{vector<std::pair<unsigned long long, double>, std::allocator<std::pair<unsigned long long, double>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<unsigned long long, double> *, std::allocator<std::pair<unsigned long long, double>>>="__value_"^v}}
@36@0:8^{__CVBuffer=}16B24^@28
@32@0:8^{__CVBuffer=}16^@24
@40@0:8^{e5rt_io_port=}16@24@32
@"MLFeatureDescription"
@"<MLE5PortBinder>"
@40@0:8^{_MLModelSpecification=}16@24^@32
@56@0:8^{_MLModelInputArchiver=}16@24@32@40^@48
@48@0:8q16q24q32@40
@56@0:8@16@24q32@40@48
@48@0:8q16@24@32@40
@"MLUpdateTask"
@"MLModel<MLWritable>"
@"NSError"
@"ModelKeyServerAPIResultError"
@"ModelKeyServerAPIFetchKeyResult"
{?="result"b1}
@48@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16B24B28Q32@40
v32@0:8@16^d24
B48@0:8@16@24@32^@40
@32@0:8@"NSDictionary"16^@24
B32@0:8@"NSArray"16^@24
@"NSArray"32@0:8@"NSArray"16^@24
B40@0:8@"NSArray"16@"NSArray"24^@32
B48@0:8@"<MTLCommandBuffer>"16@"NSArray"24@"NSArray"32^@40
@28@0:8@16B24
@"NSObject<MLCustomLayer>"
B48@0:8@16^d24Q32^@40
B64@0:8@16@24^d32Q40Q48^@56
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"<MLFeatureProvider>"
d32@0:8@16^@24
d24@0:8^d16
v32@0:8^d16^d24
B28@0:8I16Q20
@48@0:8q16q24Q32@40
@40@0:8q16q24Q32
@20@0:8I16
Q20@0:8I16
@"MLImageSizeConstraint"
B40@0:8@16^B24^@32
@24@0:8^@16
@"NSObject<MLModeling>"
@24@0:8d16
@24@0:8^{__CVBuffer=}16
@40@0:8q16@24^@32
d16@0:8
@28@0:8^@16B24
@"<MLFeatureProvider>"40@0:8@"NSString"16@"<MLFeatureProvider>"24^@32
@"MLProgramContext"24@0:8^@16
v24@0:8@"NSString"16
@40@0:8@16d24^@32
v24@0:8d16
@"<MLProgramInternal>"
@"MLProgramContext"
@"MLProgramEvaluator"
@32@0:8@16Q24
@28@0:8i16B20B24
#20@0:8i16
@24@0:8B16B20
@80@0:8@16^v24@32@40@48@56@64^@72
v40@0:8^@16^@24^v32
@48@0:8^v16@24@32^@40
@40@0:8@16Q24^@32
@"ETTaskState"
@"ETTaskDefinition"
@"MLShufflingBatchProvider"
@28@0:8I16@20
@52@0:8^{__CVBuffer=}16Q24@32B40^@44
Q24@0:8Q16
^{__CVBuffer=}88@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32Q64@72^@80
^{__CVBuffer=}88@0:8^{CGImage=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32Q64@72^@80
^?16@0:8
v56@0:8@16@24@32@40@?48
v40@0:8@16@24@?32
v36@0:8@16B24@?28
v44@0:8@16@24B32@?36
v56@0:8@"NSURL"16@"NSString"24@"MLModelConfiguration"32@"MLSecureModelDecryptCredential"40@?<v@?@"MLSecureModel"@"NSError">48
v40@0:8@"NSNumber"16@"MLPredictionOptions"24@?<v@?@"MLDictionaryFeatureProvider"@"NSError">32
v40@0:8@"NSArray"16@"MLPredictionOptions"24@?<v@?@"MLArrayDictionaryFeatureProvider"@"NSError">32
v32@0:8@"MLKey"16@?<v@?@@"NSError">24
v32@0:8@"MLFeatureValue"16@?<v@?@"MLFeatureValue"@"NSString">24
v32@0:8@"MLDictionaryFeatureProvider"16@?<v@?@"MLDictionaryFeatureProvider"@"NSString">24
v32@0:8@"MLModelDescription"16@?<v@?@"MLModelDescription"@"NSString">24
v32@0:8@"MLFeatureDescription"16@?<v@?@"MLFeatureDescription"@"NSString">24
v36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSError">28
v44@0:8@"NSString"16@"NSData"24B32@?<v@?@"NSError">36
v32@0:8@"NSString"16@?<v@?@"NSError">24
v24@0:8@?<v@?@"NSString"@"NSError">16
v40@0:8@"NSString"16@"NSNumber"24@?<v@?@"MLFeatureValue"@"NSError">32
v32@0:8@"NSNumber"16@?<v@?@"NSSet"@"NSError">24
@"NSXPCConnection"
@"NSObject<CoreMLModelSecurityProtocol>"
@"NSCountedSet"
B64@0:8r^v16r^v24Q32^@40^q48^@56
@40@0:8^d16Q24^@32
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
{vector<long long, std::allocator<long long>>="__begin_"^q"__end_"^q"__end_cap_"{__compressed_pair<long long *, std::allocator<long long>>="__value_"^q}}
@52@0:8@16Q24B32@36^@44
@"<MLCustomModel>"
B56@0:8@16@24^@32@40^@48
B40@0:8^v16^@24^@32
@64@0:8#16^v24@32@40@48^@56
v48@0:8@16@24@32Q40
@52@0:8^v16@24@32B40^@44
@36@0:8@16@24B32
@40@0:8@16^v24^@32
@"MLNeuralNetworksCompileTimeParams"24@0:8^@16
v24@0:8@"MLNeuralNetworkContainer"16
@40@0:8@16r^v24^@32
{map<std::string, InputNameToShapes, std::less<std::string>, std::allocator<std::pair<const std::string, InputNameToShapes>>>="__tree_"{__tree<std::__value_type<std::string, InputNameToShapes>, std::__map_value_compare<std::string, std::__value_type<std::string, InputNameToShapes>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, InputNameToShapes>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, InputNameToShapes>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, InputNameToShapes>, std::less<std::string>, true>>="__value_"Q}}}
@"MLMultiFunctionProgramContainer"
f16@0:8
{?="rawRequest"b1}
@44@0:8@16q24B32@36
@"MLMultiArrayConstraint"
@"MLImageConstraint"
@"MLDictionaryConstraint"
@"MLSequenceConstraint"
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32@0:8Q16r^v24
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32@0:8Q16Q24
@48@0:8{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}16Q40
v36@0:8r^v16^v24B32
v32@0:8r^v16^v24
B40@0:8r^v16^v24^@32
@52@0:8r^v16^v24@32B40^@44
@32@0:8^v16Q24
v32@0:8Q16@24
@"MLSVREngine"
{vector<std::vector<double>, std::allocator<std::vector<double>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<double> *, std::allocator<std::vector<double>>>="__value_"^v}}
{shared_ptr<CoreML::Specification::Model>="__ptr_"^{Model}"__cntrl_"^{__shared_weak_count}}
@"MLAppleAudioFeatureExtractorParameters"
@24@0:8r*16
@"MLTreeEnsembleClassifier"
@"NSMutableArray"
@"NSMutableOrderedSet"
v24@0:8@"<CUTMetric>"16
B48@0:8r^v16r^v24^v32^@40
@"MLSequence"
@"<MLBatchProvider>"
@"MLNeuralNetworkEngine"
@32@0:8^{e5rt_io_port=}16@24
@"MLBackgroundTask"
@"<NSObject>"
@64@0:8@16@24@32@40@48^@56
v32@0:8^v16@24
B40@0:8^v16@24^@32
B48@0:8@16^v24@32^@40
@56@0:8^v16^v24@32@40^@48
@56@0:8@16i24B28^v32@40^@48
^v24@0:8^@16
B48@0:8^v16@24@32^@40
@40@0:8q16@?24@?32
v56@0:8q16@24@32@40@48
@?16@0:8
@"MLE5ExecutionStreamPool"
@"MLE5ExecutionStreamOperationPool"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"MLModelMetadata"
@"MLFairPlayDecryptSession"
@"MLPredictionEvent"
@52@0:8@16@24i32@36^@44
@44@0:8^{__CVBuffer=}16@24B32^@36
@"MLAppleImageFeatureExtractorParameters"
@96@0:8@16@24{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}32{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}56@80^@88
{?={vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}QQ}32@0:8@16^@24
{?={vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}QQ}36@0:8@16B24^@28
v60@0:8^v16@24q32@40B48^@52
@40@0:8r^f16Q24^@32
@64@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}40
B52@0:8@16B24^@28^@36^@44
B56@0:8@16@24^@32^@40^@48
Q24@0:8q16
@32@0:8r^v16@24
q24@0:8@16
v24@0:8r^v16
@"NSSet"
v24@0:8@"NSArray"16
@"CKContainer"
B56@0:8@16@24@32@40^@48
{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}16@0:8
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@"MLSVMEngine"
{vector<unsigned long long, std::allocator<unsigned long long>>=^Q^Q{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>=^Q}}16@0:8
B60@0:8^v16@24r^v32r^v40B48^@52
v32@0:8@16r^v24
{unique_ptr<MIL::IRProgram, std::default_delete<MIL::IRProgram>>={__compressed_pair<MIL::IRProgram *, std::default_delete<MIL::IRProgram>>=^{IRProgram}}}32@0:8@16^@24
{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}32@0:8^v16^@24
@40@0:8@16q24@32
@64@0:8q16q24@32@40@48@56
@72@0:8Q16@24@32@40@48@56^@64
@"MLAppleTextClassifierParameters"
v64@0:8^f16^f24Q32r^f40r^Q48Q56
v40@0:8r^f16^Q24Q32
v20@0:8f16
{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q}16@0:8
v48@0:8{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q}16
@"_KDNode"
{_KDBoundingBox="_intervals"{vector<_KDInterval, std::allocator<_KDInterval>>="__begin_"^{_KDInterval}"__end_"^{_KDInterval}"__end_cap_"{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>="__value_"^{_KDInterval}}}"_numDimensions"Q}
@48@0:8^v16Q24Q32^@40
@40@0:8^v16Q24Q32
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}40@0:8Q16Q24r^v32
v48@0:8Q16^v24r^v32@40
{vector<long, std::allocator<long>>="__begin_"^q"__end_"^q"__end_cap_"{__compressed_pair<long *, std::allocator<long>>="__value_"^q}}
{linear_congruential_engine<unsigned int, 48271U, 0U, 2147483647U>="__x_"I}
@"NSObject<MLCustomLayer>"40@0:8@"NSString"16@"NSDictionary"24^@32
@"MLNonMaximumSuppressionParameters"
@56@0:8@16q24@?32@40^@48
B32@0:8^{e5rt_execution_stream=}16^@24
^{e5rt_execution_stream=}16@0:8
v24@0:8^{e5rt_execution_stream=}16
^{e5rt_execution_stream=}
{vector<int, std::allocator<int>>=^i^i{__compressed_pair<int *, std::allocator<int>>=^i}}16@0:8
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@56@0:8@16@24@32@?40^@48
@48@0:8@16@24@?32^@40
v24@0:8@"NSObject"16
@"MLModel<MLUpdatable>"
r^v32@0:8@16^@24
v36@0:8@16@24B32
B28@0:8B16@20
@"NSUserDefaults"
@20@0:8B16
@104@0:8Q16@24@32@40@48@56@64@72@80@88^@96
@96@0:8Q16@24@32@40@48@56@64@72@80^@88
@"MLAppleWordTaggerParameters"
@48@0:8@16Q24Q32^@40
^{e5rt_execution_stream_operation=}24@0:8^@16
@48@0:8@16@24^?32^@40
^{e5rt_execution_stream_operation=}16@0:8
v24@0:8^{e5rt_execution_stream_operation=}16
^{e5rt_execution_stream_operation=}
@72@0:8@16@24@32@40@48@56^@64
@80@0:8@16@24@32@40@48@56@64^@72
@88@0:8@16@24@32@40@48@56@64@72^@80
@56@0:8^v16#24@32@40^@48
@40@0:8^v16^v24^@32
{_NSRange=QQ}24@0:8r^v16
@24@0:8r^v16
@28@0:8^v16B24
B40@0:8^d16@24^@32
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
v20@0:8I16
^v24@0:8@16
^v32@0:8@16^@24
v40@0:8@16^v24^@32
B64@0:8@16@24Q32Q40@48^@56
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}16@0:8
v40@0:8{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}16
{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}}16
{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16@0:8
v40@0:8{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16
{shared_ptr<Archiver::MMappedFile>="__ptr_"^{MMappedFile}"__cntrl_"^{__shared_weak_count}}
{vector<std::pair<unsigned long, unsigned long>, std::allocator<std::pair<unsigned long, unsigned long>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<unsigned long, unsigned long> *, std::allocator<std::pair<unsigned long, unsigned long>>>="__value_"^v}}
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@60@0:8@16q24q32I40@44^@52
@60@0:8^{CGImage=}16q24q32I40@44^@52
@48@0:8^{CGImage=}16@24@32^@40
@64@0:8@16I24q28q36I44@48^@56
@52@0:8@16I24@28@36^@44
@64@0:8^{CGImage=}16I24q28q36I44@48^@56
@52@0:8^{CGImage=}16I24@28@36^@44
@52@0:8i16@20@28@36@44
@60@0:8i16@20@28@36@44@52
@68@0:8i16@20@28@36@44@52@60
@64@0:8Q16@24@32@40@48^@56
@"MLAppleWordEmbeddingParameters"
@32@0:8@16r^v24
@72@0:8@16@24B32B36@40@48@56@64
@80@0:8@16@24B32B36@40@48@56@64@72
B40@0:8^@16@24@32
B48@0:8@"<MLFeatureProvider>"16@"<MLFeatureProvider>"24@"MLSupervisedOnlineUpdateOptions"32^@40
B32@0:8^@16@24
@104@0:8@16q24@32@40@48@56@64@72@80@88@96
{shared_ptr<CoreML::BayesianProbitRegression::FeatureValues>=^{FeatureValues}^{__shared_weak_count}}32@0:8@16^@24
@24@0:8^{Prediction=dddddB}16
d40@0:8@16@24q32
B48@0:8@16^B24^d32^@40
{shared_ptr<CoreML::BayesianProbitRegression::BayesianProbitRegression>=^{BayesianProbitRegression}^{__shared_weak_count}}16@0:8
{shared_ptr<CoreML::BayesianProbitRegression::BayesianProbitRegression>="__ptr_"^{BayesianProbitRegression}"__cntrl_"^{__shared_weak_count}}
@"NSNumber"24@0:8Q16
@32@0:8r^d16Q24
@32@0:8@16r^d24
@40@0:8r^@16r^@24Q32
@"MLProbabilityDictionarySharedKeySet"
@"<MLProbabilityDictionaryStorage>"
B32@0:8q16^@24
B48@0:8@16B24B28@32^@40
@"MLMultiArrayShapeConstraint"
@48@0:8{_NSRange=QQ}16{_NSRange=QQ}32
@40@0:8q16q24B32B36
Q40@0:8Q16{_NSRange=QQ}24
@60@0:8{_NSRange=QQ}16{_NSRange=QQ}32@48B56
@72@0:8@16@24@32@40@48@56@64
@32@0:8d16@24
@40@0:8d16@24@32
@"NSObject<OS_dispatch_source>"
####!
;TTTTTTTTTA
*$-
TWIZ]N8nlohmann6detail9exceptionE
N8nlohmann6detail10type_errorE
N8nlohmann6detail16invalid_iteratorE
N8nlohmann6detail12out_of_rangeE
false
NSt3__117bad_function_callE
N8nlohmann6detail11parse_errorE
NSt3__120__shared_ptr_emplaceIN8nlohmann6detail21output_stream_adapterIcEENS_9allocatorIS4_EEEE
N8nlohmann6detail21output_stream_adapterIcEE
N8nlohmann6detail23output_adapter_protocolIcEE
000102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798990001020304050607080910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989900010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
U1(\Q
mSx@
b}$l
~)p$w
11eU%
z^KD
NSt3__120__shared_ptr_emplaceIN3MPL6detail24ModelPackageItemInfoImplENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN3MPL20ModelPackageItemInfoENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN3MPL6detail16ModelPackageImplENS_9allocatorIS3_EEEE
rKa@
yTW 
P@&x
X_<p
G!c?m
&G.5
\_1b
TWZ]I`cIfi
Y\_beh
f]cT
_Y\Ven
\_be
TWZ]q`cqfi
X[^adg
?KDCaN
K0L0
5230
a1c1
rux{
HKNQ
ilowz}
'<QPP
 (0PP
1=6PP
1=6CC
1=6CC
3!AI+Q
 %*/PP
1=6NN
0<5PP
1=6NN
0<5mm
QV\hh
KVal
IIIIII6
(3@LWj
$0<HT`lx
&>U]em
&7<AF
*8FT
@7@(#)PROGRAM:CoreML  PROJECT:CoreML-1404
@6Kernel
7QMatrix
6Solver
9Solver_NU
5SVC_Q
11ONE_CLASS_Q
5SVR_Q
NSt3__120__shared_ptr_emplaceIN6CoreML16MultiArrayBufferENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPhZ105-[MLMultiArray initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:]E3$_0NS_9allocatorIhEEEE
Z105-[MLMultiArray initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:]E3$_0
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1INS_11__wrap_iterIPNS_10shared_ptrIKS3_EEEEEET_SB_mNS2_10ScalarTypeENS2_12StorageOrderEEUlS1_E_NS_9allocatorIhEEEE
ZN6CoreML16MultiArrayBufferC1INSt3__111__wrap_iterIPNS2_10shared_ptrIKS0_EEEEEET_S9_mNS_10ScalarTypeENS_12StorageOrderEEUlPhE_
N6CoreML10NNCompiler7Backend13NeuralNetwork18EspressoNetBackendE
NSt3__120__shared_ptr_pointerIPKN6CoreML10NNCompiler11MLModelInfoENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIKN6CoreML10NNCompiler11MLModelInfoEEE
NSt3__120__shared_ptr_pointerIPKN3MIL9IRProgramENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL9IRProgramEEE
N6CoreML10NNCompiler7Backend3MIL5Ios1612Ios16BackendE
N8Archiver20_IDataBlobMemoryImplE
NSt3__120__shared_ptr_pointerIPN3MIL7IRBlockENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL7IRBlockEEE
NSt3__120__shared_ptr_pointerIPN3MIL11IROperationENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL11IROperationEEE
N8Archiver17_OArchiveDiskImplE
N8Archiver19_OArchiveMemoryImplE
NSt3__120__shared_ptr_pointerIPN8Archiver14_ODataBlobImplENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN8Archiver14_ODataBlobImplEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN8Archiver14_ODataBlobImplEEE
NSt3__120__shared_ptr_emplaceIN8Archiver14_ODataBlobImplENS_9allocatorIS2_EEEE
N8Archiver14_IDataBlobImplE
NSt3__120__shared_ptr_pointerIPNS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_10shared_ptrINS_13basic_istreamIcS3_EEE27__shared_ptr_default_deleteIS8_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrINS_13basic_istreamIcNS_11char_traitsIcEEEEE27__shared_ptr_default_deleteIS4_NS_14basic_ifstreamIcS3_EEEE
NSt3__114default_deleteINS_14basic_ifstreamIcNS_11char_traitsIcEEEEEE
NSt3__120__shared_ptr_pointerIPN8Archiver11MMappedFileENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN8Archiver11MMappedFileEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN8Archiver11MMappedFileEEE
N6CoreML13TreeEnsembles8Internal30incompatible_execution_profileE
N6CoreML10NNCompiler7Backend3MIL5Ios1512Ios15BackendE
NSt3__110__function6__funcIZN6CoreML13TreeEnsembles8Internal16gatherPropertiesERKNS_10shared_ptrINS3_13_TreeEnsembleEEEE3$_2NS_9allocatorISA_EEFvRKNS5_INS3_20_TreeComputationNodeEEEEEE
NSt3__110__function6__baseIFvRKNS_10shared_ptrIN6CoreML13TreeEnsembles20_TreeComputationNodeEEEEEE
ZN6CoreML13TreeEnsembles8Internal16gatherPropertiesERKNSt3__110shared_ptrINS0_13_TreeEnsembleEEEE3$_2
NSt3__120__shared_ptr_emplaceIN8Archiver19_OArchiveMemoryImplENS_9allocatorIS2_EEEE
N6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorE
N8Archiver18_IDataBlobENMLImplE
NSt3__120__shared_ptr_emplaceIN8Archiver7mmapbufENS_9allocatorIS2_EEEE
N8Archiver7mmapbufE
NSt3__120__shared_ptr_emplaceINS_13basic_istreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
N6CoreML10NNCompiler11MLModelInfoE
NSt3__110__function6__funcIZN12_GLOBAL__N_119ParseClassifierInfoERKN3MIL7IRBlockEE3$_0NS_9allocatorIS7_EEFbRKNS3_11IROperationEEEE
NSt3__110__function6__baseIFbRKN3MIL11IROperationEEEE
ZN12_GLOBAL__N_119ParseClassifierInfoERKN3MIL7IRBlockEE3$_0
NSt3__120__shared_ptr_pointerIPNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEENS_14default_deleteISH_EENS5_ISH_EEEE
NSt3__114default_deleteINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorIiNS5_IiEEEENS_4lessIS7_EENS5_INS_4pairIKS7_SA_EEEEEEEE
NSt3__120__shared_ptr_pointerIPN3MIL10MILContextENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10MILContextEEE
N6CoreML16MultiArrayBufferE
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ERKNS_6vectorImNS_9allocatorImEEEENS2_10ScalarTypeENS2_12StorageOrderEmE3$_0NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1ERKNSt3__16vectorImNS1_9allocatorImEEEENS_10ScalarTypeENS_12StorageOrderEmE3$_0
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ERKNS_6vectorImNS_9allocatorImEEEENS2_10ScalarTypeENS2_12StorageOrderEmE3$_1NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1ERKNSt3__16vectorImNS1_9allocatorImEEEENS_10ScalarTypeENS_12StorageOrderEmE3$_1
NSt3__120__shared_ptr_pointerIPhZN6CoreML16MultiArrayBufferC1ES1_RKNS_6vectorImNS_9allocatorImEEEES9_NS2_10ScalarTypeEE3$_2NS5_IhEEEE
ZN6CoreML16MultiArrayBufferC1EPhRKNSt3__16vectorImNS2_9allocatorImEEEES8_NS_10ScalarTypeEE3$_2
NSt3__120__shared_ptr_pointerIPhZNK6CoreML16MultiArrayBuffer34lockAndGetBaseAddressOfPixelBufferEP10__CVBufferE3$_3NS_9allocatorIhEEEE
ZNK6CoreML16MultiArrayBuffer34lockAndGetBaseAddressOfPixelBufferEP10__CVBufferE3$_3
N6CoreML10NNCompiler7Backend3MIL5Ios1620Ios16LayerTranslatorE
NSt3__120__shared_ptr_pointerIP21_MLModelSpecificationNS_10shared_ptrIS1_E27__shared_ptr_default_deleteIS1_S1_EENS_9allocatorIS1_EEEE
NSt3__110shared_ptrI21_MLModelSpecificationE27__shared_ptr_default_deleteIS1_S1_EE
NSt3__114default_deleteI21_MLModelSpecificationEE
N12_GLOBAL__N_110imemstreamE
N12_GLOBAL__N_16membufE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10unique_ptrIN3MIL4Blob13StorageReaderENS_14default_deleteISB_EEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SE_EEEEEENS5_ISN_EEEE
NSt3__110__function6__funcIZN12_GLOBAL__N_121GetBlobReaderFunctionEvE3$_0NS_9allocatorIS3_EEFN3MIL4Util4SpanIKhLm18446744073709551615EEERKNS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEyEEE
NSt3__110__function6__baseIFN3MIL4Util4SpanIKhLm18446744073709551615EEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEyEEE
ZN12_GLOBAL__N_121GetBlobReaderFunctionEvE3$_0
NSt3__120__shared_ptr_emplaceINS_6vectorIhNS_9allocatorIhEEEENS2_IS4_EEEE
N6CoreML10NNCompiler7Backend8IBackendE
N6CoreML10NNCompiler7Backend13NeuralNetwork38UpdatableNeuralNetworkMLComputeBackendE
NSt3__120__shared_ptr_pointerIPNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN8Espresso17net_configurationENS_4lessIS7_EENS5_INS_4pairIKS7_S9_EEEEEENS_14default_deleteISG_EENS5_ISG_EEEE
NSt3__114default_deleteINS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN8Espresso17net_configurationENS_4lessIS7_EENS5_INS_4pairIKS7_S9_EEEEEEEE
NSt3__120__shared_ptr_pointerIPN6CoreML10NNCompiler16MLClassifierInfoENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIN6CoreML10NNCompiler16MLClassifierInfoEEE
NSt3__120__shared_ptr_pointerIPN6CoreML10NNCompiler13NeuralNetwork28ImagePreprocessingParametersENS_14default_deleteIS4_EENS_9allocatorIS4_EEEE
NSt3__114default_deleteIN6CoreML10NNCompiler13NeuralNetwork28ImagePreprocessingParametersEEE
NSt3__120__shared_ptr_pointerIPN3MIL10IRFunctionENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10IRFunctionEEE
NSt3__120__shared_ptr_pointerIPN3MIL9IRProgramENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL9IRProgramEEE
N6CoreML10NNCompiler7Backend3MIL10Ios16Train17Ios16TrainBackendE
N6CoreML16MLModelExceptionE
N8Archiver17_IArchiveDiskImplE
N8Archiver13_IArchiveImplE
N8Archiver19_IArchiveMemoryImplE
NSt3__120__shared_ptr_emplaceIN8Archiver18_IDataBlobENMLImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver20MMappedInputENMLFileENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver14_IDataBlobImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver17_IArchiveDiskImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver14_MemoryIStreamENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver20_IDataBlobMemoryImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceINS_14basic_ifstreamIcNS_11char_traitsIcEEEENS_9allocatorIS4_EEEE
NSt3__120__shared_ptr_emplaceIN8Archiver19_IArchiveMemoryImplENS_9allocatorIS2_EEEE
N6CoreML10NNCompiler7Backend3MIL10Ios16Train25Ios16TrainLayerTranslatorE
N6CoreML10NNCompiler7Backend3MIL5Ios1520Ios15LayerTranslatorE
NSt3__110__function6__funcINS_6__bindIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS6_20LayerTranslationInfoERKN3MIL11IROperationERNS6_15MILBlockBuilderEEJRKNS_12placeholders4__phILi1EEERKNSM_ILi2EEERKNSM_ILi3EEERKNSM_ILi4EEEEEENS_9allocatorISZ_EESJ_EE
NSt3__110__function6__baseIFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS5_20LayerTranslationInfoERKN3MIL11IROperationERNS5_15MILBlockBuilderEEEE
NSt3__16__bindIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS4_20LayerTranslationInfoERKN3MIL11IROperationERNS4_15MILBlockBuilderEEJRKNS_12placeholders4__phILi1EEERKNSK_ILi2EEERKNSK_ILi3EEERKNSK_ILi4EEEEEE
NSt3__118__weak_result_typeIPFvRKN6CoreML10NNCompiler7Backend3MIL22ProgramLayerTranslatorERKNS4_20LayerTranslationInfoERKN3MIL11IROperationERNS4_15MILBlockBuilderEEEE
N6CoreML10NNCompiler13NeuralNetwork22NeuralNetworkSpecProxyE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification13NeuralNetworkEEE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification22NeuralNetworkRegressorEEE
N12_GLOBAL__N_126NeuralNetworkSpecProxyImplIN6CoreML13Specification23NeuralNetworkClassifierEEE
N8Archiver20MMappedInputENMLFileE
N6CoreML10NNCompiler7Backend13NeuralNetwork31NeuralNetworkEspressoNetBackendE
NSt3__110__function6__funcIZL13ConvertLayersRKN6CoreML13Specification5ModelERKNS2_10NNCompiler11MLModelInfoERN8Espresso18sequential_builderERNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENSB_11layer_shapeENS_4lessISK_EENSI_INS_4pairIKSK_SL_EEEEEERN14EspressoCommon18compileModelResultERU8__strongP7NSErrorE3$_1NSI_IS11_EEFbvEEE
NSt3__110__function6__baseIFbvEEE
ZL13ConvertLayersRKN6CoreML13Specification5ModelERKNS_10NNCompiler11MLModelInfoERN8Espresso18sequential_builderERNSt3__13mapINSB_12basic_stringIcNSB_11char_traitsIcEENSB_9allocatorIcEEEENS8_11layer_shapeENSB_4lessISI_EENSG_INSB_4pairIKSI_SJ_EEEEEERN14EspressoCommon18compileModelResultERU8__strongP7NSErrorE3$_1
22MLCustomLayerException
NSt3__110__function6__funcIZL15BuildFromShapesRN8Espresso18sequential_builderERKNS_3mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS2_11layer_shapeENS_4lessISB_EENS9_INS_4pairIKSB_SC_EEEEEEbRU8__strongP7NSErrorPbE3$_0NS9_ISR_EEFNS_10shared_ptrINS2_3netEEEvEEE
NSt3__110__function6__baseIFNS_10shared_ptrIN8Espresso3netEEEvEEE
ZL15BuildFromShapesRN8Espresso18sequential_builderERKNSt3__13mapINS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEENS_11layer_shapeENS2_4lessIS9_EENS7_INS2_4pairIKS9_SA_EEEEEEbRU8__strongP7NSErrorPbE3$_0
NSt3__120__shared_ptr_emplaceIN8Archiver17_OArchiveDiskImplENS_9allocatorIS2_EEEE
N8Archiver13_OArchiveImplE
CoreML_InputDefaultValues
CoreML_IsRank5ArrayMapping
NSt3__120__shared_ptr_pointerIPKN3MIL13IRTensorValueENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL13IRTensorValueEEE
NSt3__120__shared_ptr_pointerIPKN3MIL17IRDictionaryValueENS_14default_deleteIS3_EENS_9allocatorIS3_EEEE
NSt3__114default_deleteIKN3MIL17IRDictionaryValueEEE
N8Archiver11MMappedFileE
NSt3__120__shared_ptr_emplaceIN6CoreML24BayesianProbitRegression24BayesianProbitRegressionENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML24BayesianProbitRegression13FeatureValuesENS_9allocatorIS3_EEEE
N8Archiver16_MemoryStreamBufE
N8Archiver17_MemoryIStreamBufE
N8Archiver17_MemoryOStreamBufE
N8Archiver14_MemoryIStreamE
N8Archiver14_MemoryOStreamE
N6CoreML10NNCompiler7Backend13NeuralNetwork40UpdatableNeuralNetworkEspressoNetBackendE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIcLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIcLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi1EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi1EEE
NSt3__120__shared_ptr_emplaceIN8Espresso4blobIfLi4EEENS_9allocatorIS3_EEEE
N8Espresso4blobIfLi4EEE
NSt3__120__shared_ptr_pointerIPN3MIL11IRParameterENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL11IRParameterEEE
NSt3__120__shared_ptr_pointerIPNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10shared_ptrIN3MIL11IRParameterEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SB_EEEEEENS_14default_deleteISK_EENS5_ISK_EEEE
NSt3__114default_deleteINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_10shared_ptrIN3MIL11IRParameterEEENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SB_EEEEEEEE
NSt3__120__shared_ptr_pointerIPNS_6vectorINS_10shared_ptrIN3MIL11IRParameterEEENS_9allocatorIS5_EEEENS_14default_deleteIS8_EENS6_IS8_EEEE
NSt3__114default_deleteINS_6vectorINS_10shared_ptrIN3MIL11IRParameterEEENS_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIPFN3MIL16ValidationResultERKNS2_11IROperationEENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFN3MIL16ValidationResultERKNS2_11IROperationEEEE
PFN3MIL16ValidationResultERKNS_11IROperationEE
FN3MIL16ValidationResultERKNS_11IROperationEE
N6CoreML22MLModelResultExceptionE
N6CoreML3MIL6Opsets12CoreML5OpsetE
N6CoreML3MIL6Opsets12CoreML6OpsetE
N6CoreML3MIL6Opsets18CoreML6_trainOpsetE
NSt3__120__shared_ptr_pointerIPN3MIL10IROperatorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN3MIL10IROperatorEEE
N6CoreML13Specification12CoreMLModels23AudioFeaturePrint_SoundE
N6CoreML13Specification12CoreMLModels17AudioFeaturePrintE
N6CoreML13Specification18CategoricalMappingE
N6CoreML13Specification8PipelineE
N6CoreML13Specification18PipelineClassifierE
N6CoreML13Specification17PipelineRegressorE
N6CoreML13Specification18FeatureDescriptionE
N6CoreML13Specification8MetadataE
N6CoreML13Specification16ModelDescriptionE
N6CoreML13Specification15SerializedModelE
N6CoreML13Specification5ModelE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES9_LNS1_14WireFormatLite9FieldTypeE9ELSB_9ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESA_LNS1_14WireFormatLite9FieldTypeE9ELSC_9ELi0EEENS0_11MessageLiteESA_SA_LSC_9ELSC_9ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEES8_E8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESA_LNS1_14WireFormatLite9FieldTypeE9ELSC_9ELi0EEENS0_11MessageLiteESA_SA_LSC_9ELSC_9ELi0EE15MapEntryWrapperE
N6CoreML5ModelE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification5ModelENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_pointerIPN6CoreML13Specification5ModelENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6CoreML13Specification5ModelEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6CoreML13Specification5ModelEEE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification8MetadataENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification16ModelDescriptionENS_9allocatorIS3_EEEE
N6CoreML13Specification8IdentityE
N6CoreML13Specification12CoreMLModels24VisionFeaturePrint_SceneE
N6CoreML13Specification12CoreMLModels26VisionFeaturePrint_ObjectsE
N6CoreML13Specification12CoreMLModels18VisionFeaturePrintE
N6CoreML13Specification13OneHotEncoderE
N6CoreML13Specification12CoreMLModels14TextClassifierE
N6CoreML13Specification7MILSpec7ProgramE
N6CoreML13Specification7MILSpec8FunctionE
N6CoreML13Specification7MILSpec5BlockE
N6CoreML13Specification7MILSpec16Argument_BindingE
N6CoreML13Specification7MILSpec8ArgumentE
N6CoreML13Specification7MILSpec9OperationE
N6CoreML13Specification7MILSpec14NamedValueTypeE
N6CoreML13Specification7MILSpec9ValueTypeE
N6CoreML13Specification7MILSpec10TensorTypeE
N6CoreML13Specification7MILSpec9TupleTypeE
N6CoreML13Specification7MILSpec8ListTypeE
N6CoreML13Specification7MILSpec14DictionaryTypeE
N6CoreML13Specification7MILSpec27Dimension_ConstantDimensionE
N6CoreML13Specification7MILSpec26Dimension_UnknownDimensionE
N6CoreML13Specification7MILSpec9DimensionE
N6CoreML13Specification7MILSpec20Value_ImmediateValueE
N6CoreML13Specification7MILSpec19Value_BlobFileValueE
N6CoreML13Specification7MILSpec5ValueE
N6CoreML13Specification7MILSpec26TensorValue_RepeatedFloatsE
N6CoreML13Specification7MILSpec27TensorValue_RepeatedDoublesE
N6CoreML13Specification7MILSpec24TensorValue_RepeatedIntsE
N6CoreML13Specification7MILSpec28TensorValue_RepeatedLongIntsE
N6CoreML13Specification7MILSpec25TensorValue_RepeatedBoolsE
N6CoreML13Specification7MILSpec27TensorValue_RepeatedStringsE
N6CoreML13Specification7MILSpec25TensorValue_RepeatedBytesE
N6CoreML13Specification7MILSpec11TensorValueE
N6CoreML13Specification7MILSpec10TupleValueE
N6CoreML13Specification7MILSpec9ListValueE
N6CoreML13Specification7MILSpec28DictionaryValue_KeyValuePairE
N6CoreML13Specification7MILSpec15DictionaryValueE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8FunctionELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5ValueELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec5BlockELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification7MILSpec8ArgumentELNS1_14WireFormatLite9FieldTypeE9ELSG_11ELi0EEENS0_11MessageLiteESA_SE_LSG_9ELSG_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification6ScalerE
N6CoreML19HashOutputStreamBufE
NSt3__120__shared_ptr_pointerIPN6CoreML6detail23HashOutputStreamBufImplENS_10shared_ptrIS3_E27__shared_ptr_default_deleteIS3_S3_EENS_9allocatorIS3_EEEE
NSt3__110shared_ptrIN6CoreML6detail23HashOutputStreamBufImplEE27__shared_ptr_default_deleteIS3_S3_EE
NSt3__114default_deleteIN6CoreML6detail23HashOutputStreamBufImplEEE
N6CoreML13Specification12CoreMLModels33SoundAnalysisPreprocessing_VggishE
N6CoreML13Specification12CoreMLModels26SoundAnalysisPreprocessingE
N6CoreML13Specification25GLMClassifier_DoubleArrayE
N6CoreML13Specification13GLMClassifierE
N6CoreML13Specification7ImputerE
N6CoreML13Specification33CustomModel_CustomModelParamValueE
N6CoreML13Specification11CustomModelE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSE_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EEE
N6google8protobuf3MapINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueEE8InnerMapE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification33CustomModel_CustomModelParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification12LinearKernelE
N6CoreML13Specification9RBFKernelE
N6CoreML13Specification10PolyKernelE
N6CoreML13Specification13SigmoidKernelE
N6CoreML13Specification6KernelE
N6CoreML13Specification10SparseNodeE
N6CoreML13Specification12SparseVectorE
N6CoreML13Specification20SparseSupportVectorsE
N6CoreML13Specification11DenseVectorE
N6CoreML13Specification19DenseSupportVectorsE
N6CoreML13Specification12CoefficientsE
N6CoreML13Specification22SupportVectorRegressorE
N6CoreML13Specification23SupportVectorClassifierE
N6CoreML13Specification12CoreMLModels9GazetteerE
N6CoreML13Specification10NormalizerE
N6CoreML13Specification16StringToInt64MapE
N6CoreML13Specification16Int64ToStringMapE
N6CoreML13Specification17StringToDoubleMapE
N6CoreML13Specification16Int64ToDoubleMapE
N6CoreML13Specification12StringVectorE
N6CoreML13Specification11Int64VectorE
N6CoreML13Specification11FloatVectorE
N6CoreML13Specification12DoubleVectorE
N6CoreML13Specification10Int64RangeE
N6CoreML13Specification8Int64SetE
N6CoreML13Specification11DoubleRangeE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSB_3ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSC_3ELi0EEENS0_11MessageLiteESA_xLSC_9ELSC_3ELi0EEE
N6google8protobuf8internal12MapEntryLiteIxNSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSB_9ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSC_9ELi0EEENS0_11MessageLiteExSA_LSC_3ELSC_9ELi0EEE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSB_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSC_1ELi0EEENS0_11MessageLiteESA_dLSC_9ELSC_1ELi0EEE
N6google8protobuf8internal12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS4_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS5_1ELi0EEENS0_11MessageLiteExdLS5_3ELS5_1ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEExLNS1_14WireFormatLite9FieldTypeE9ELSC_3ELi0EEENS0_11MessageLiteESA_xLSC_9ELSC_3ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEELNS1_14WireFormatLite9FieldTypeE3ELSC_9ELi0EEENS0_11MessageLiteExSA_LSC_3ELSC_9ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEdLNS1_14WireFormatLite9FieldTypeE9ELSC_1ELi0EEENS0_11MessageLiteESA_dLSC_9ELSC_1ELi0EE15MapEntryWrapperE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteIxdLNS1_14WireFormatLite9FieldTypeE3ELS5_1ELi0EEENS0_11MessageLiteExdLS5_3ELS5_1ELi0EE15MapEntryWrapperE
N6CoreML13Specification32BayesianProbitRegressor_GaussianE
N6CoreML13Specification42BayesianProbitRegressor_FeatureValueWeightE
N6CoreML13Specification37BayesianProbitRegressor_FeatureWeightE
N6CoreML13Specification23BayesianProbitRegressorE
N6CoreML13Specification12CoreMLModels13WordEmbeddingE
N6CoreML13Specification14Int64ParameterE
N6CoreML13Specification15DoubleParameterE
N6CoreML13Specification15StringParameterE
N6CoreML13Specification13BoolParameterE
NSt3__120__shared_ptr_emplaceIN6CoreML13TreeEnsembles20_TreeComputationNodeENS_9allocatorIS3_EEEE
NSt3__120__shared_ptr_emplaceIN6CoreML13TreeEnsembles13_TreeEnsembleENS_9allocatorIS3_EEEE
N6CoreML13Specification29NonMaximumSuppression_PickTopE
N6CoreML13Specification21NonMaximumSuppressionE
NSt3__120__shared_ptr_emplaceIN6CoreML11Recommender30_ItemSimilarityRecommenderDataENS_9allocatorIS3_EEEE
N6CoreML13Specification39ItemSimilarityRecommender_ConnectedItemE
N6CoreML13Specification38ItemSimilarityRecommender_SimilarItemsE
N6CoreML13Specification25ItemSimilarityRecommenderE
N6CoreML13Specification29FeatureVectorizer_InputColumnE
N6CoreML13Specification17FeatureVectorizerE
N6CoreML13Specification12CoreMLModels10WordTaggerE
N6CoreML13Specification46TreeEnsembleParameters_TreeNode_EvaluationInfoE
N6CoreML13Specification31TreeEnsembleParameters_TreeNodeE
N6CoreML13Specification22TreeEnsembleParametersE
N6CoreML13Specification22TreeEnsembleClassifierE
N6CoreML13Specification21TreeEnsembleRegressorE
NSt3__120__shared_ptr_emplaceIN6CoreML13Specification11FeatureTypeENS_9allocatorIS3_EEEE
N6CoreML13Specification14DictVectorizerE
N6CoreML13Specification13NeuralNetworkE
N6CoreML13Specification24NeuralNetworkImageScalerE
N6CoreML13Specification22NeuralNetworkMeanImageE
N6CoreML13Specification26NeuralNetworkPreprocessingE
N6CoreML13Specification14ActivationReLUE
N6CoreML13Specification19ActivationLeakyReLUE
N6CoreML13Specification14ActivationTanhE
N6CoreML13Specification20ActivationScaledTanhE
N6CoreML13Specification17ActivationSigmoidE
N6CoreML13Specification16ActivationLinearE
N6CoreML13Specification21ActivationSigmoidHardE
N6CoreML13Specification15ActivationPReLUE
N6CoreML13Specification13ActivationELUE
N6CoreML13Specification25ActivationThresholdedReLUE
N6CoreML13Specification18ActivationSoftsignE
N6CoreML13Specification18ActivationSoftplusE
N6CoreML13Specification28ActivationParametricSoftplusE
N6CoreML13Specification16ActivationParamsE
N6CoreML13Specification6TensorE
N6CoreML13Specification18NeuralNetworkLayerE
N6CoreML13Specification17BranchLayerParamsE
N6CoreML13Specification15LoopLayerParamsE
N6CoreML13Specification20LoopBreakLayerParamsE
N6CoreML13Specification23LoopContinueLayerParamsE
N6CoreML13Specification15CopyLayerParamsE
N6CoreML13Specification22GreaterThanLayerParamsE
N6CoreML13Specification23GreaterEqualLayerParamsE
N6CoreML13Specification19LessThanLayerParamsE
N6CoreML13Specification20LessEqualLayerParamsE
N6CoreML13Specification16EqualLayerParamsE
N6CoreML13Specification19NotEqualLayerParamsE
N6CoreML13Specification21LogicalAndLayerParamsE
N6CoreML13Specification20LogicalOrLayerParamsE
N6CoreML13Specification21LogicalXorLayerParamsE
N6CoreML13Specification21LogicalNotLayerParamsE
N6CoreML13Specification23BorderAmounts_EdgeSizesE
N6CoreML13Specification13BorderAmountsE
N6CoreML13Specification12ValidPaddingE
N6CoreML13Specification11SamePaddingE
N6CoreML13Specification12SamplingModeE
N6CoreML13Specification18BoxCoordinatesModeE
N6CoreML13Specification12WeightParamsE
N6CoreML13Specification18QuantizationParamsE
N6CoreML13Specification24LinearQuantizationParamsE
N6CoreML13Specification29LookUpTableQuantizationParamsE
N6CoreML13Specification22ConvolutionLayerParamsE
N6CoreML13Specification24Convolution3DLayerParamsE
N6CoreML13Specification23InnerProductLayerParamsE
N6CoreML13Specification20EmbeddingLayerParamsE
N6CoreML13Specification22EmbeddingNDLayerParamsE
N6CoreML13Specification20BatchnormLayerParamsE
N6CoreML13Specification39PoolingLayerParams_ValidCompletePaddingE
N6CoreML13Specification18PoolingLayerParamsE
N6CoreML13Specification20Pooling3DLayerParamsE
N6CoreML13Specification26GlobalPooling3DLayerParamsE
N6CoreML13Specification34PaddingLayerParams_PaddingConstantE
N6CoreML13Specification36PaddingLayerParams_PaddingReflectionE
N6CoreML13Specification37PaddingLayerParams_PaddingReplicationE
N6CoreML13Specification18PaddingLayerParamsE
N6CoreML13Specification17ConcatLayerParamsE
N6CoreML13Specification14LRNLayerParamsE
N6CoreML13Specification18SoftmaxLayerParamsE
N6CoreML13Specification16SplitLayerParamsE
N6CoreML13Specification14AddLayerParamsE
N6CoreML13Specification19MultiplyLayerParamsE
N6CoreML13Specification24UnaryFunctionLayerParamsE
N6CoreML13Specification19UpsampleLayerParamsE
N6CoreML13Specification25ResizeBilinearLayerParamsE
N6CoreML13Specification21CropResizeLayerParamsE
N6CoreML13Specification15BiasLayerParamsE
N6CoreML13Specification16ScaleLayerParamsE
N6CoreML13Specification23LoadConstantLayerParamsE
N6CoreML13Specification22L2NormalizeLayerParamsE
N6CoreML13Specification18FlattenLayerParamsE
N6CoreML13Specification18ReshapeLayerParamsE
N6CoreML13Specification18PermuteLayerParamsE
N6CoreML13Specification25ReorganizeDataLayerParamsE
N6CoreML13Specification16SliceLayerParamsE
N6CoreML13Specification17ReduceLayerParamsE
N6CoreML13Specification15CropLayerParamsE
N6CoreML13Specification18AverageLayerParamsE
N6CoreML13Specification14MaxLayerParamsE
N6CoreML13Specification14MinLayerParamsE
N6CoreML13Specification21DotProductLayerParamsE
N6CoreML13Specification32MeanVarianceNormalizeLayerParamsE
N6CoreML13Specification25SequenceRepeatLayerParamsE
N6CoreML13Specification26SimpleRecurrentLayerParamsE
N6CoreML13Specification14GRULayerParamsE
N6CoreML13Specification10LSTMParamsE
N6CoreML13Specification16LSTMWeightParamsE
N6CoreML13Specification29UniDirectionalLSTMLayerParamsE
N6CoreML13Specification28BiDirectionalLSTMLayerParamsE
N6CoreML13Specification39CustomLayerParams_CustomLayerParamValueE
N6CoreML13Specification17CustomLayerParamsE
N6CoreML13Specification20TransposeLayerParamsE
N6CoreML13Specification24BatchedMatMulLayerParamsE
N6CoreML13Specification19ConcatNDLayerParamsE
N6CoreML13Specification20SoftmaxNDLayerParamsE
N6CoreML13Specification18ReverseLayerParamsE
N6CoreML13Specification21ReverseSeqLayerParamsE
N6CoreML13Specification25LoadConstantNDLayerParamsE
N6CoreML13Specification19FillLikeLayerParamsE
N6CoreML13Specification21FillStaticLayerParamsE
N6CoreML13Specification22FillDynamicLayerParamsE
N6CoreML13Specification29WhereBroadcastableLayerParamsE
N6CoreML13Specification14SinLayerParamsE
N6CoreML13Specification14CosLayerParamsE
N6CoreML13Specification14TanLayerParamsE
N6CoreML13Specification15AsinLayerParamsE
N6CoreML13Specification15AcosLayerParamsE
N6CoreML13Specification15AtanLayerParamsE
N6CoreML13Specification15SinhLayerParamsE
N6CoreML13Specification15CoshLayerParamsE
N6CoreML13Specification15TanhLayerParamsE
N6CoreML13Specification16AsinhLayerParamsE
N6CoreML13Specification16AcoshLayerParamsE
N6CoreML13Specification16AtanhLayerParamsE
N6CoreML13Specification27PowBroadcastableLayerParamsE
N6CoreML13Specification15Exp2LayerParamsE
N6CoreML13Specification23WhereNonZeroLayerParamsE
N6CoreML13Specification25MatrixBandPartLayerParamsE
N6CoreML13Specification26UpperTriangularLayerParamsE
N6CoreML13Specification26LowerTriangularLayerParamsE
N6CoreML13Specification26BroadcastToLikeLayerParamsE
N6CoreML13Specification28BroadcastToStaticLayerParamsE
N6CoreML13Specification29BroadcastToDynamicLayerParamsE
N6CoreML13Specification27AddBroadcastableLayerParamsE
N6CoreML13Specification27MaxBroadcastableLayerParamsE
N6CoreML13Specification27MinBroadcastableLayerParamsE
N6CoreML13Specification27ModBroadcastableLayerParamsE
N6CoreML13Specification32FloorDivBroadcastableLayerParamsE
N6CoreML13Specification32SubtractBroadcastableLayerParamsE
N6CoreML13Specification32MultiplyBroadcastableLayerParamsE
N6CoreML13Specification30DivideBroadcastableLayerParamsE
N6CoreML13Specification17GatherLayerParamsE
N6CoreML13Specification18ScatterLayerParamsE
N6CoreML13Specification19GatherNDLayerParamsE
N6CoreML13Specification20ScatterNDLayerParamsE
N6CoreML13Specification26GatherAlongAxisLayerParamsE
N6CoreML13Specification27ScatterAlongAxisLayerParamsE
N6CoreML13Specification16StackLayerParamsE
N6CoreML13Specification32RankPreservingReshapeLayerParamsE
N6CoreML13Specification26ConstantPaddingLayerParamsE
N6CoreML13Specification27RandomNormalLikeLayerParamsE
N6CoreML13Specification29RandomNormalStaticLayerParamsE
N6CoreML13Specification30RandomNormalDynamicLayerParamsE
N6CoreML13Specification28RandomUniformLikeLayerParamsE
N6CoreML13Specification30RandomUniformStaticLayerParamsE
N6CoreML13Specification31RandomUniformDynamicLayerParamsE
N6CoreML13Specification30RandomBernoulliLikeLayerParamsE
N6CoreML13Specification32RandomBernoulliStaticLayerParamsE
N6CoreML13Specification33RandomBernoulliDynamicLayerParamsE
N6CoreML13Specification34CategoricalDistributionLayerParamsE
N6CoreML13Specification19ReduceL1LayerParamsE
N6CoreML13Specification19ReduceL2LayerParamsE
N6CoreML13Specification20ReduceMaxLayerParamsE
N6CoreML13Specification20ReduceMinLayerParamsE
N6CoreML13Specification20ReduceSumLayerParamsE
N6CoreML13Specification21ReduceProdLayerParamsE
N6CoreML13Specification21ReduceMeanLayerParamsE
N6CoreML13Specification23ReduceLogSumLayerParamsE
N6CoreML13Specification26ReduceSumSquareLayerParamsE
N6CoreML13Specification26ReduceLogSumExpLayerParamsE
N6CoreML13Specification21ExpandDimsLayerParamsE
N6CoreML13Specification22FlattenTo2DLayerParamsE
N6CoreML13Specification24ReshapeStaticLayerParamsE
N6CoreML13Specification22ReshapeLikeLayerParamsE
N6CoreML13Specification25ReshapeDynamicLayerParamsE
N6CoreML13Specification18SqueezeLayerParamsE
N6CoreML13Specification15TopKLayerParamsE
N6CoreML13Specification17ArgMaxLayerParamsE
N6CoreML13Specification17ArgMinLayerParamsE
N6CoreML13Specification18SplitNDLayerParamsE
N6CoreML13Specification15CeilLayerParamsE
N6CoreML13Specification16RoundLayerParamsE
N6CoreML13Specification16FloorLayerParamsE
N6CoreML13Specification15SignLayerParamsE
N6CoreML13Specification15ClipLayerParamsE
N6CoreML13Specification22SliceStaticLayerParamsE
N6CoreML13Specification23SliceDynamicLayerParamsE
N6CoreML13Specification15TileLayerParamsE
N6CoreML13Specification19GetShapeLayerParamsE
N6CoreML13Specification14ErfLayerParamsE
N6CoreML13Specification15GeluLayerParamsE
N6CoreML13Specification22RangeStaticLayerParamsE
N6CoreML13Specification23RangeDynamicLayerParamsE
N6CoreML13Specification25SlidingWindowsLayerParamsE
N6CoreML13Specification29LayerNormalizationLayerParamsE
N6CoreML13Specification32NonMaximumSuppressionLayerParamsE
N6CoreML13Specification22ClampedReLULayerParamsE
N6CoreML13Specification18ArgSortLayerParamsE
N6CoreML13Specification22SliceBySizeLayerParamsE
N6CoreML13Specification23NeuralNetworkClassifierE
N6CoreML13Specification17OneHotLayerParamsE
N6CoreML13Specification17CumSumLayerParamsE
N6CoreML13Specification22NeuralNetworkRegressorE
N6CoreML13Specification23NetworkUpdateParametersE
N6CoreML13Specification9LossLayerE
N6CoreML13Specification32CategoricalCrossEntropyLossLayerE
N6CoreML13Specification25MeanSquaredErrorLossLayerE
N6CoreML13Specification9OptimizerE
N6CoreML13Specification12SGDOptimizerE
N6CoreML13Specification13AdamOptimizerE
N6google8protobuf8internal12MapEntryLiteINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSE_11ELi0EEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EEE
N6google8protobuf4hashINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal12MapEntryImplINS1_12MapEntryLiteINSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEN6CoreML13Specification39CustomLayerParams_CustomLayerParamValueELNS1_14WireFormatLite9FieldTypeE9ELSF_11ELi0EEENS0_11MessageLiteESA_SD_LSF_9ELSF_11ELi0EE15MapEntryWrapperE
N6CoreML13Specification27KNearestNeighborsClassifierE
N6CoreML13Specification21NearestNeighborsIndexE
N6CoreML13Specification16UniformWeightingE
N6CoreML13Specification24InverseDistanceWeightingE
N6CoreML13Specification11LinearIndexE
N6CoreML13Specification17SingleKdTreeIndexE
N6CoreML13Specification24SquaredEuclideanDistanceE
N6CoreML13Specification11LinkedModelE
N6CoreML13Specification15LinkedModelFileE
N6CoreML13Specification21ArrayFeatureExtractorE
N6CoreML13Specification24GLMRegressor_DoubleArrayE
N6CoreML13Specification12GLMRegressorE
N6CoreML13Specification16Int64FeatureTypeE
N6CoreML13Specification17DoubleFeatureTypeE
N6CoreML13Specification17StringFeatureTypeE
N6CoreML13Specification9SizeRangeE
N6CoreML13Specification26ImageFeatureType_ImageSizeE
N6CoreML13Specification37ImageFeatureType_EnumeratedImageSizesE
N6CoreML13Specification31ImageFeatureType_ImageSizeRangeE
N6CoreML13Specification16ImageFeatureTypeE
N6CoreML13Specification22ArrayFeatureType_ShapeE
N6CoreML13Specification33ArrayFeatureType_EnumeratedShapesE
N6CoreML13Specification27ArrayFeatureType_ShapeRangeE
N6CoreML13Specification16ArrayFeatureTypeE
N6CoreML13Specification21DictionaryFeatureTypeE
N6CoreML13Specification19SequenceFeatureTypeE
N6CoreML13Specification11FeatureTypeE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N6CoreML16TreeEnsembleBaseE
N6CoreML22TreeEnsembleClassifierE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18CopyingInputStreamE
N6google8protobuf2io25CopyingInputStreamAdaptorE
N6google8protobuf2io19CopyingOutputStreamE
N6google8protobuf2io26CopyingOutputStreamAdaptorE
N6google8protobuf2io19ZeroCopyInputStreamE
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io18IstreamInputStreamE
N6google8protobuf2io18IstreamInputStream25CopyingIstreamInputStreamE
N6google8protobuf2io19OstreamOutputStreamE
N6google8protobuf2io19OstreamOutputStream26CopyingOstreamOutputStreamE
N6google8protobuf11MessageLiteE
]6MNw<@mY
f}/@
il]@
@ko#!(
,$|
<x
Input stream is not valid
assert_invariant
json.hpp
m_type != value_t::object || m_value.object != nullptr
m_type != value_t::array || m_value.array != nullptr
m_type != value_t::string || m_value.string != nullptr
m_type != value_t::binary || m_value.binary != nullptr
[json.exception.
cannot create object from initializer list
cannot use operator[] with a numeric argument with 
null
object
array
string
boolean
binary
discarded
number
type_error
iter_impl
m_object != nullptr
set_begin
set_end
cannot compare iterators of different containers
operator==
invalid_iterator
operator++
cannot use key() for non-object iterators
key '
' not found
cannot use at() with 
map::at:  key not found
out_of_range
type must be string, but is 
cannot use operator[] with a string argument with 
get_decimal_point
loc != nullptr
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid literal
unget
!token_string.empty()
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
scan_literal
std::char_traits<char_type>::to_char_type(current) == literal_text[0]
scan_string
current == '\"'
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
0x00 <= codepoint && codepoint <= 0x10FFFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: ill-formed UTF-8 byte
get_codepoint
current == 'u'
0x0000 <= codepoint && codepoint <= 0xFFFF
next_byte_in_range
ranges.size() == 2 || ranges.size() == 4 || ranges.size() == 6
scan_number
false
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
endptr == token_buffer.data() + token_buffer.size()
value
object key
object separator
number overflow parsing '
sax_parse_internal
!states.empty()
excessive object size: 
handle_value
!keep_stack.empty()
ref_stack.back()->is_array() || ref_stack.back()->is_object()
!key_keep_stack.empty()
object_element
end_object
!ref_stack.empty()
operator->
m_it.object_iterator != m_object->m_value.object->end()
m_it.array_iterator != m_object->m_value.array->end()
cannot get value
iterator does not fit current value
iterator out of range
cannot use erase() with 
excessive array size: 
end_array
<U+%.4X>
parse_error
parse error
 at line 
, column 
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
<uninitialized>
true literal
false literal
null literal
string literal
number literal
<parse error>
end of input
'[', '{', or a literal
unknown token
dump
i != val.m_value.object->cend()
std::next(i) == val.m_value.object->cend()
!val.m_value.array->empty()
"bytes": [
"subtype": 
{"bytes":[
],"subtype":
null}
true
<discarded>
\u%04x
\u%04x\u%04x
%.2X
invalid UTF-8 byte at index 
: 0x
dump_escaped
incomplete UTF-8 string; last byte: 0x
\ufffd
decode
index < 400
dump_integer
n_chars < number_buffer.size() - 1
to_chars
std::isfinite(value)
last - first >= std::numeric_limits<FloatType>::max_digits10
len <= std::numeric_limits<FloatType>::max_digits10
last - first >= 2 + (-kMinExp - 1) + std::numeric_limits<FloatType>::max_digits10
last - first >= std::numeric_limits<FloatType>::max_digits10 + 6
grisu2
value > 0
compute_boundaries
normalize
x.f != 0
normalize_to
delta >= 0
((x.f << delta) >> delta) == x.f
m_plus.e == m_minus.e
m_plus.e == v.e
get_cached_power_for_binary_exponent
e >= -1500
e <= 1500
index >= 0
static_cast<std::size_t>(index) < kCachedPowers.size()
kAlpha <= cached.e + e + 64
kGamma >= cached.e + e + 64
grisu2_digit_gen
M_plus.e >= kAlpha
M_plus.e <= kGamma
p1 > 0
d <= 9
p2 > delta
p2 <= (std::numeric_limits<std::uint64_t>::max)() / 10
x.e == y.e
x.f >= y.f
grisu2_round
len >= 1
dist <= delta
rest <= delta
ten_k > 0
buf[len - 1] != '0'
format_buffer
min_exp < 0
max_exp > 0
k > n
append_exponent
e > -1000
e < 1000
A valid manifest does not exist at path: 
Failed to create model package at path: 
Failed to create data directory at path: 
Failed to open model package at path: 
File format version must be in the form of major.minor.patch, but the specified value was: 
Failed to parse file format version: 
 because: 
File format version uses negative number(s): 
Unsupported version: 
Invalid itemInfo for identifier: 
Item does not exist for identifier: 
Failed to look up root model
Manifest.json
Data
fileFormatVersion
path
name
author
description
itemInfoEntries
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
rootModelIdentifier
classify:topK:error be implemented by derived class!
e5BundleURL parameter must not be nil.
functionName parameter must not be nil.
com.apple.coreml.MLE5Engine.operationPoolQueue
Data provided in input: %@ is missing feature value for training input: %@
Data provided for %@ has insufficient shape
MLMultiArray value for %@ does not comply with constraint: %@
Failed to create multi array of shape %@
Failed to copy over input multi array
Shape for multi array value of %@ is not allowed
_MultiArray
Image value for %@ does not comply with constraint: %@
Failed to copy over image input
Value for %@ does not comply with constraint in description: %@ (%@)
Failed to derive valid training input from class label
Predicted class is not in expected format
Invalid class label %@ provided as input
Input %@ is not in the expected format, expected: %@
WARNING: using -h 0 may be faster
WARNING: reaching max number of iterations
optimization finished, #iter = %d
WARNING: training data in only one class. See README for details.
WARNING: class label %d specified in weight is not found
Total nSV = %d
WARNING: # folds > # data. Will use # folds = # data instead (i.e., leave-one-out cross validation)
Model doesn't contain information for SVR probability inference
svm_type %s
kernel_type %s
degree %d
gamma %g
coef0 %g
nr_class %d
total_sv %d
probA
probB
nr_sv
%.16g 
0:%d 
%d:%.8g 
%80s
unknown svm type.
unknown kernel function.
unknown text in model file: [%s]
ERROR: fscanf failed to read model
unknown svm type
unknown kernel type
gamma < 0
degree of polynomial kernel < 0
cache_size <= 0
eps <= 0
C <= 0
nu <= 0 or nu > 1
p < 0
shrinking != 0 and shrinking != 1
probability != 0 and probability != 1
one-class SVM probability output not supported yet
specified nu is infeasible
Prob. model for test data: target value = predicted value + z,
z: Laplace distribution e^(-|z|/sigma)/(2sigma),sigma= %g
obj = %f, rho = %f
nSV = %d, nBSV = %d
nu = %f
C = %f
epsilon = %f
Line search fails in two-class probability estimates
Reaching maximal iterations in two-class probability estimates
Exceeds max_iter in multiclass_prob
c_svc
nu_svc
one_class
epsilon_svr
nu_svr
linear
polynomial
sigmoid
precomputed
MLDictionaryConstraint cannot check undefined values
MLDictionaryConstraint only allows Dictionary values
Dicitonary keys are not all expected type %@
keyType
inputRanks
outputRanks
inputShapes
outputShapes
MLModelDescriptionKey
MLModelVersionStringKey
MLModelAuthorKey
MLModelCreatorDefinedKey
MLModelLicenseKey
axes
/System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis
_MLNLPSentenceClassifierModel
NaturalLanguage framework not available on this OS version
com.apple
Must only have one string input feature
Must only have one string output feature
parameters['modelData'] does not exist or is not a string
initialization of classifier model with model data failed
Input string feature '%@' not found
Prediction failed
%@ %@
key_id
model_name
team_id
signed_key
raw_key
PBUNSET
(unknown: %i)
MLModelCollectionDidChangeNotification
Failed to begin access for model collection with identifier '%@': invalid identifier
v16@?0@"NSString"8
Failed to begin access for model collection with identifier '%@': internal error
Failed to begin access for model collection with identifier '%@': internal registration failed
v16@?0Q8
Failed to begin access for model collection with identifier '%@': download failed
Failed to end access for model collection with identifier '%@': invalid identifier
Failed to end access for model collection with identifier '%@': internal error
An error occurred ending access for model collection with identifier '%@': internal error
v20@?0B8@"NSError"12
v16@?0@"<TRINamespaceUpdateProtocol>"8
%@.%@
TRIClient
Unable to find class %s
TRIExperimentIdentifiers
TRIDownloadOptions
TRIFactorLevel
TRILevel
TRIFile
TRIFactor
SplitND layer: Invalid value of the argument 'axis'.
numSplits
splitSizes
axis
taskIdentifier
modelURL
modelConfiguration
predictionOptions
reps
localOutlierFactorScore
Local Outlier Factor can not override numberOfNeighbors with value of class=%@.
Local Outlier Factor should have at least numberOfNeighbors(%lu) + 1 data points, but we got (%lu) data points.
using wrong sized neighbors with size=
Missing input name in model description for %@.
Invalid MLFeatureTypeMultiArray value for %@.
Shape of input MLMultiArray is %@, expected [%lu]
Fail to compute LOF: %s
%@ does not have a parameter for requested key %@.
Failed to get tensor descriptor.ESRT: %s (%d)
%@ x %@
pixelsWide
pixelsHigh
Unknown error loading MIL model
Error loading MIL model: 
Error parsing MIL model: 
Validation error parsing MIL model: 
Failed to copy weights during compilation.
 Error description: 
Initialization of Gazetteer parameters failed
Model type is not a Gazetteer
Model description is invalid
Invalid parameters for Gazetteer
parameters.modelParameterData does not exist or is not a NSData
initialization of gazetteer model with model data failed
Gazette does not contain input string '%@'. %@
Gazette does not contain input string '%@'. 
This is a gazetteer model (version %lu) which classifies %@ text according to set {
This is a gazetteer model (version %lu) which classifies text according to set {
Unable to save model to %@. %s
MLMultiArrayDataTypeInvalid (%d)
pixelBuffer must not be NULL.
The pixel format type must be kCVPixelFormatType_OneComponent16Half. (%c%c%c%c is specified.)
The pixel buffer must use IOSurface.
The shape is nil or empty.
The shape's last dimension (%zu) doesn't match the pixel buffer's width (%zu)
The product of dimensions in the shape ([%@]) except last one must match the pixel buffer's height (%zu)
Could not fetch NSNumber at offset %zu because it is beyond the end of the multi array.
Could not store NSNumber at offset %zu because it is beyond the end of the multi array.
v32@?0^v8q16@"NSArray"24
 vector
 matrix
 array
dataType
shape
strides
isBackedByPixelBuffer
The buffer is %zd bytes but it is smaller than the expected length (%zu bytes). This is a programming error.
dataPointer
v24@?0r^v8Q16
shape is nil or empty.
scalars must be a non-empty array of NSNumbers.
MLMultiArray of shape: %@ should have %zu element(s), but the `scalars` argument has %td element(s).
Empty dimension was found at axis %tu.
The element type is neither NSArray nor NSNumber at axis %tu.
Dimension mismatch at axis %tu; some have %tu element(s) but others have %tu element(s).
B32@?0@8Q16^B24
Invalid element type at axis %tu.
v32@?0@"NSArray"8Q16^B24
Unable to copy %@ into %@
Unable to vectorize %@ into %@
value count (%@) does not match array count (%@)
-[MLMultiArray initWithShape:dataType:error:] was supposed to use first-major contiguous memory layout, but it doesn't.
The array of array is not a matrix: some row's length is %lu, but another row's length is %lu
multiArrays shall not be empty.
The first input MLMultiArray has too many dimensions (%@)
%@-th input MLMultiArray has shape (%@), which is different from the first input's shape: (%@).
%@-th input MLMultiArray has shape (%@), but %@-th dimension shall not be negative.
%@-th input MLMultiArray has shape (%@) but the first input's shape is (%@); %@-th dimension doesn't match.
v32@?0@"MLMultiArray"8Q16^B24
The sum of the dimensions at the concatenating axis was too big and caused an integer overflow.
setRangeWithRawData: range out of bounds.
setRangeWithRawData: non-contiguous %@d destination unsupported
setRangeWithRawData: failed to vectorize source
Invalid origin %@ for slicing %@
Invalid shape %@ for slicing %@
Slice at %@ with shape %@ is out of bounds
Shape %@ is not squeezable at dimensions %@
The mutable shaped buffer provider has reported incorrect dimensions of strides.
Nothing to concatenate.
The first multi array has a shape with size 
 but another multi array's shape size is 
The first multi array has a shape 
 but another multi array's shape is 
; they cannot be concatenate along with axis: 
is_output
in_memory_model
defaultValue
numericConstraint
parameterKey: %@
defaultValue: %@
numericConstraint: %@
Cannot determine valueDescription for this regressor
Cannot determine predictedFeatureName for this regressor
Invalid regressor: predicted feature '%@' is not described as double or MultiArray
Predicted feature named '%@' was not output by pipeline
Predicted feature '%@' is of type %@ not the expected %@
Regressed feature named '%@' is not a Double or MultiArray
Internal error: support vectors not set.
Shape must have at least 3 dimensions, The third dimension to the last (channels) must be 3, and any earlier dimensions must have a size of 1.
Shape must have at least 2 dimensions, and if more, the first dimensions should have a size of 1.
Failed to create BGRA image %@ x %@
Failed to lock pixel buffer
v24@?0r^f8q16
Failed to convert planar to OneComponent8: Code=%@
Invalid array shape [%@] for converting to BGR image. %@
Shape's width (%d) doesn't match the pixel buffer's width (%d)
Shape's height (%d) doesn't match the pixel buffer's height (%d)
Failed to create temporary buffer for conversion to image
Failed to convert planar to BGRAX888: Code=%@
pixel format type %c%c%c%c is not supported.
Invalid array shape [%@] for converting to gray image. %@
FailedToComputeHash
Attempted to compile a non-neural-network model as a neural network.
Encountered an unexpected error while compiling a neural network model.
Encountered an error while compiling a neural network model: %@
generic
Program main function does not have an opset specialization with an associated backend.
coremlc
com.apple.MIL
CFBundleVersion
compiler major version for compiled model is %@ and is more recent than this framework major version %@.
placeHolderInputName
Neural network classifier does not contain class labels.
The size of the output layer '%@' in the neural network does not match the number of classes in the classifier.
Classify can only be called on neural network classifiers.
Regress can only be called on neural network regressors.
Failed to lock pixel buffer while populating outputs
com.apple.CoreMLBatchProcessingQueue
com.apple.CoreMLNNProcessingQueue
In-memory program only supports main function.
The in-memory compiled model is neither MLProgram nor NNv1. This is a logic error.
Model file not found.
compute_unit_mask
espresso_context_set_int_option for ANE|CPU returned status = %d
For input feature '%@', the provided shape %@ is not compatible with the model's feature description.
The model expects input feature %@ to be an image, but the input (%@) is of type %ld.
Input image feature %@ does not match model description
Required input feature not passed to neural network.
Unsupported input pixel format type `%c%c%c%c`.
Invalid multi-array data type: %08x.
Unsupported input feature type: %@
Unable to bind pixel buffer directly to the feature named %@ due to error: %d
Failed to lock CVPixelBuffer when binding input image with error: %d
Unexpected pixel format type %c%c%c%c
Failed to bind image through vImage with error: %d
Failed to bind the input buffer %@: %d
Espresso doesn't report the output shape; we cannot verify the output backing's shape. Error: %d
Failed to set shape of rank %zu to Espresso Buffer. Error: %d
The output backing MLMultiArray's shape (shape.count = %zu) doesn't match to Espresso's output shape (shape.count = %zu) even after squeezed. This is most likely a framework programming error.
Output backing for %@ is not compatible with the model's output feature description.
Output feature %@ doesn't support an output backing.
The underlying pixel buffer (%p) used in the output backing MLMultiArray object for feature %@ has been locked. The output backing cannot use such an object. Typically, the error occurs when the caller has invoked MLMultiArray's data accessing properties before the inference, or they used a locked pixel buffer to initialize the multi array. Use a newly created pixel buffer and MLMultiArray to avoid this error.
Output feature %@ doesn't have a description for the image constraints.
%@ image output feature must use a pixel buffer of kCVPixelFormatType_32BGRA as the output backing, but kCVPixelFormatType_32ARGB pixel buffer was specified.
The output backing object must be either CVPixelBuffer or MLMultiArray.
Output backings cannot be used for a dynamic output feature: %@.
Forced automatic output backings was requested but we couldn't bind the output buffer for feature: %@
Error binding output buffer: %@
Error checking if an output blob is dynamic or not, %@, %d.
Forced automatic output backings was requested but we couldn't fabricate the output buffer for feature: %@
Error computing NN outputs.
Failure in binding dynamic outputs. (err=%d)
The specified output backing object is not compatible with the output feature type: %@
Image output %@ is missing width, height, and pixel info in its description
Batch or sequence image output is unsupported for image output %@
Invalid shape for output feature '%@': %@
MLNeuralNetworkEngine doesn't support MLImagePixelType %tu yet.
Failed to convert output %@ to image
None of the features required to evaulate this model are produced by the feature provider which is first among the batch of input feature providers.
The model requires these input features:
    %@
The first batch input feature provider provides these input features:
Ensure that each of the batch input feature providers provides all the input features with types matching those required to evaluate the model.
Failed to build clean before reshape.
Unable to select network configuration for: %@
Failure dynamically resizing for sequence length.
Passing empty input dictionary for resetSizes.
Incorrect input number of dimensions (must be between 1, 3, or 5 dimensions.
Incorrect input number of dimensions (must be 1 or greater).
Cannot evaluate a batch of size %@, which is larger than maximum of %@.
Cannot evaluate a sequence of length %@, which is longer than maximum of %@ for bidirectional models.
Failure setting up to dynamically allocate for sequence size.
Error in passing image pre-processing parameters to network.
Error in re-declaring input '%@'.
Error in declaring output '%@'.
Error in building plan.
Unable to verify the first input of the batch.
Unable to reset sizes for an element of a batch computation.
Error calling plan submit.
v16@?0^{?=ii*}8
Error calling plan_submit in batch processing.
Error calling plan submit for batch processing.
Failure checking availability of plan submit.
This neural network model does not have a parameter for requested key %@. Note: only updatable neural network models can provide parameter values and these values are only accessible in the context of an MLUpdateTask completion or progress handler.
context_transfer
%@:%@:%@
Error in declaring network.
Unknown
Gray8
RGB8
BGR8
Gray16Half
momentum
shuffle
linkedModelFileName
linkedModelSearchPath
maxDepth
numTrees
numClasses
minChildWeight
updateType
Parameter '%@' has no value
Custom model implmenetantion class named '%@' does not conform to MLCustomModel protocol
Model type is not a CustomModel
CPU Only
GPU and CPU
CPU and NeuralEngine
computeUnits
useSPIforScribble
allowLowPrecisionAccumulationOnGPU
allowBackgroundGPUCompute
MPSDeviceOptions
enableTestVectorMode
rootModelURL
profilingOptions
usePreloadedKey
forceMLComputeTraining
parentModelName
modelName
 computeUnits: %@,             
 useWatchSPIForScribble: %s,             
 allowLowPrecisionAccumulationOnGPU: %s,             
 allowBackgroundGPUComputeSetting: %s,             
 preferredMetalDevice: %@,             
 enableTestVectorMode: %s,             
 parameters: %@,             
 rootModelURL: %@,             
 profilingOptions: %lu,             
 usePreloadedKey: %s,             
 trainWithMLCompute: %s,             
 parentModelName: %@,             
 modelName: %@,             
com.apple.coreml.MLE5Engine.streamPoolQueue
encryption_key
encryption_iv
Error: asMMappedFile is not supported by _IDataBlobMemoryImpl
The must be the same value count for each feature. Feature '%@' has %@ values. Expected %@
Failed to determine type of feature '%@'.
Error initializing sample %@ of feature `%@`
kNumDimensions
kDescription
kLabelsForDataPoints
kLabelType
kIndexType
kIndex
kDefaultLabel
kWeightingScheme
kNearestLabelsFeatureName
kNearestDistancesFeatureName
kParameterContainer
Index type is invalid for this model.
Missing input name for K Nearest Neighbor model.
K Nearest Neighbor models only accept multi array input types.
_debugNearestLabels
_debugNearestDistances
Missing MLMultiArray for MLFeatureProvider
Shape of input MLMultiArray is %@, expected %@
Error computing pairwise distances in k-nearest neighbors model.
Error predicting class due to missing data points and default label.
Unable to load class labels for k-Nearest-Neighbor model.
Invalid k-nearest neighbor model -- the length of the data vector is not a multiple of the given dimensionality.
Failed to unarchive model parameters.
Failed to archive model parameters.
notreesyet
Received nil MLFeatureProvider for index %d from training data MLBatchProvider
Missing MLMultiArrayValue for feature named %@
Shape of training data point %d MLMultiArray is %@, expected %@
Failed to convert training data to the right format
Missing MLFeatureValue for feature named %@
Label type must be one of MLFeatureTypeString or MLFeatureTypeInt64
Failed to update model with training data
Failed to create directory at %@
Failed archive updated model
Failed save updated model to %@
Nearest Neighbor Classifier Model does not have a parameter for requested key %@.
modelParameters
inputs: %@
outputs: %@
predictedFeatureName: %@
predictedProbabilitiesName: %@
updatable: %@
trainingInputs: %@
parameters: %@
metadata: %@
inputDescriptionsByName
outputDescriptionsByName
predictedFeatureName
predictedProbabilitiesName
trainingInputDescriptionsByName
isUpdatable
parameterDescriptionsByKey
metadata
Classifier must specify predictedFeatureName and/or predictedProbabilitiesName
Regressor must specify predictedFeatureName.
Unable to extract configurations from a multi-array feature type without enumerated shapes.
Unable to extract configurations from an image feature type without enumerated shapes.
Unable to extract configurations from a feature that is not a multi-array or image.
We don't currently use configurations if there are multiple inputs with enumerated shapes.
Bad neural network input.
Attempting to extract shape from non-image or multi-array feature
Invalid multi-array constraint found when extracting configurations.
Multi-array of shape less than 1 found when extracting configurations.
Failed to get shape from the tensor description. E5RT: %s (%d)
Failed to get strides from the tensor description. E5RT: %s (%d)
Failed to get data type of the tensor. E5RT: %s (%d)
Failed to get component size. E5RT: %s (%d)
Failed to get component data type. E5RT: %s (%d)
E5 tensor with componentSize = %d and componentDataType = %d is not supported.
MultiArray %@-d shape is not allowed, expected %@-d
Size (%@) of dimension (%@) is not in allowed range (%@..%@)
MultiArray shape (%@) does not match the shape (%@) specified in the model description
MultiArray Shape (%@) was not in enumerated set of allowed shapes
sizeRangeForDimension
type
shapeSet
Interface type is not an ItemSimilarityRecommender
Could not construct item similarity recommender: %s
Internal error: model too large to be compiled.
Internal Error: item index out of bounds.
Input sequence of items for item similarity recommender must be strings or integers.
Input sequence of items for item similarity recommender with string item ids must be strings.
Input sequence of items for item similarity recommender with integer item ids must be integers.
String items require string item ids to be be set.
Input sequence of items for item similarity recommender must be integers or strings.
Input items for item similarity recommender must be a dictionary or a sequence.
Input restriction list of items for item similarity recommender must be a sequence.
Input exclusion list of items for item similarity recommender must be a sequence.
Cannot extract data for image feature: %@
Cannot transform the %@ feature value to one hot encoded format.
Failed to convert planar8 to planarF: Code=%@
Failed to convert ARGB8888 to PlanarF: Code=%@
<MLE5IOPort: %p> %@
Error: Attempted multiple write-open of data blob 
.DAT
Error: setObject is not supported by _OArchiveDiskImpl
Error: Archive doesn't exist at path: 
Error: Invalid path: 
Error: Failed to open writable stream at path: 
non-directory file already exists at archive path
existing archive path is not a writable directory
error creating directory: %@
%lld.%lld.%lld
%@%@
Error opening file stream: 
 already opened as stream attempted to open as mmapped file.
v24@?0^v8Q16
Failed to set parameter value because of nil key
Parameter value type %@ does not conform with default value's type %@
%@ is not a valid value given constraint %@ for key %@
currentParameterValues
parameterKeys
parameterDescriptions
currentParameterValues: %@
parameterKeys: %@
parameterDescriptions: %@
MLKeyName
MLKeyScope
task: %p, 
model: %p, 
event: %@, 
metrics: %@, 
parameters: %@
success
error
Result
profile_number
debug_fatpack
engine_version
Unrecognized profile number 
class labels not set.
SVM has invalid number of support vectors or clases
engineName
Error creating Core ML custom layer implementation from factory for layer "
Core ML custom Layer implementation '
' does not conform to the MLCustomLayer protocol
Error getting Core ML custom layer output shapes for layer "
Evaluation on Core ML custom layer "
" called before the layer is constructed.
Error evaluating Core ML custom layer "
" on CPU.
_internal_NDMode
' does not conform to the MLCustomLayer protocol'
Error initializing Core ML custom layer implementation with parameter dictionary for layer "
Error setting weights in Core ML custom layer "
" on GPU.
PersistentKeyStorage_v2
com.apple.coreml.PersistentKeyStore
keyBlob is nil
keyIdentifier is nil
%@.bin
Failed to persist Key Blob
Feature '%@' not provided.
Feature type %@ cannot be vectorized
Failed to vectorize %@ (%p)
Internal programming error.
Incorrect 'doubleVector' length of %@ (expected %@)
Interface type is not an TreeEnsembleRegressor
Could not construct tree ensemble compiler.
Dimension must equal one when using scalarRegress.
32RGBA
32BGRA
32ARGB
OneComponent8
OneComponent16Half
24RGB
24BGRA
Unsupported (%@)
32BGRA or 32ARGB
Image constraint can not accept missing values.
Image is not expected type %@, instead is %@
Image constraint doesn't have size constraint
%@, %@ x %@
Color
pixelType
sizeConstraint
model.mlmodel
%@ does not exist
%@ is not a file: URL
failed to obtain NSURLCanonicalPathKey for %@
NSURLCanonicalPathKey not available for %@
(Loaded)
(Failed Load)
(Not loaded)
Model is not a classifier.
MLModelAsset: classifierWithError: load failed.
Model is not a regressor.
B24@?0@"NSURL"8@"NSError"16
.espresso.net
Failed to check cached ANE binary: argument result must not be nil
Failed to check cached ANE binary because espresso_ane_cache_has_network returned status=%d for network at %@.
Failed to purge cached ANE binary because espresso_ane_cache_purge_network returned status=%d for network at %@
Error reading protobuf spec. %s
%@ : %@
Dictionary keys must be NSStrings or NSNumbers.
Object not consistent with type supplied
Attempting to hash an MLFeatureValue that is not an image or multi array.
undefined
width
height
format
rowBytes
Failed to lock CVPixelBuffer's base address for serialization.
attributes
transposeA
transposeB
learning_rate_0
The program argument to MLProgramTrainer is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
The program has no train function.
Failed to add lr to training data.
.inferenceModel property is not implemented yet. See rdar://81339842.
The trainable weights should be Float32, but it is %@.
The copyCurrentTrainingDelta failed to extract initial weights.
IllegalOperation
InternalError
MLModel does not conform to MLWritable
ProgramLayerTranslator | No main function found.
ProgramLayerTranslator | Function is not written exclusively in MIL<
Can't find op 
 in source opset 
Can't find op with the same typename "
" in destination opset 
_MLVNScenePrintCustomModel
MLScenePrintRequestRevision
MLScenePrintConfiguration
ScenePrint not available on this version
Must only have one input image feature
Must only have one output multiarray feature
Must allow %lu-element vector as output
Input image feature '%@' not found
CodedObject
_MLNLPWordTaggingModel
Must only have three sequence output features
initialization of sequence model with model data failed
unknown direction=
invalid offset=
, dir=
Error initializing model.
Loss layer type not recognized.
Error initializing loss layer %s.
Error initializing training variables.
Optimizer type not recognized.
Error initializing optimizer.
Invalid value for computeUnits in model configuration.
Error initializing espresso task.
Error in initalizing container.
None
ImageBuffer
Cannot get current weights or biases for layer %@.
Failed to set weights or biases for layer name: %@
B32@?0Q8@"<ETDataProvider>"16@"<ETTaskContext>"24
Cannot get current learning rate.
Failed to copy original model files to the new destionation: %@
Failed to save model to %@. This issue may occur when saving a dense layer that does not contain a bias, if this is the case please file a bug report.
Failed to save model to %@.
Failed to copy updated model to %@
model_updatable.espresso.net
model_updatable.espresso.weights
model_updatable.espresso.shape
Updated neural network model does not have a parameter for requested key %@.
Updatable neural network failed to retrive parameter for layer %@.
/System/Library/Frameworks/Vision.framework/Vision
VNScenePrintsFromPixelBuffers
VNScenePrintsFromPixelBuffersUsesCPUOnly
VNElementCountForScenePrintRequestRevision
VNLengthInBytesForScenePrintRequestRevision
VNImageBuffer
VNDetectionPrintsFromPixelBuffers
VNDetectionPrintsFromPixelBuffersUsesCPUOnly
VNDetectionPrintShapes
VNDetectionPrintSupportedRevisions
VNImageOptionImageOrientation
Failed to form pixel buffer from %@
Failed to form pixel buffer from CGImage
/System/Library/
com.apple.app-sandbox.read
nil value for URL
com.apple.CoreMLModelSecurityService
v24@?0@"MLSecureModel"8@"NSError"16
com.apple.CoreMLModelSecutiyServiceToClient.%lu
v24@?0@"MLDictionaryFeatureProvider"8@"NSError"16
v24@?0@"MLArrayDictionaryFeatureProvider"8@"NSError"16
v24@?0@8@"NSError"16
congfiguration
modelDescription
cryptoKey
Interface type is not an TreeEnsembleClassifier
Could not construct tree ensemble regressor.
.mlmodelc
.xgboost
Cannot initialize Tree Ensemble Classifier model which contains a trained model.
INTERNAL ERROR -- feature not present that should have been.
Incorrect number of classes given (TreeEnsembleClassifier).
_MLSNVGGishFeatureEmbedding
_SNVGGishFeatureEmbeddingCustomModel
Framework not available on this version
Feature embedding not available on this version
Frontend processing does not conform to custom model protocol
Feature embedding failed to init
URL is not a file:// URL: %@
Invalid URL for .mlmodel.
Unable to load model: %@. Compile the model with Xcode or `MLModel.compileModel(at:)`. 
Updating encrypted model %@ is not supported.
Model at %@ is not in the expected format
Failed to open model at %@
Failed to unarchive model at %@
IO Error loading model from compiled model archive: %s
Unable to load model
Loading class must conform to serializable protocols
Selected model loader does not support updatable models.
com.apple.
Unable to extract model type from stream in compiled model: %s
No known class for loading model type %@
Unknown Failure
isOrderedBgr
isGrayScale
blueBias
greenBias
redBias
grayBias
layers
encoder_bidirectional_mode
bottom
Error in parsing network information from compiled model path %@.
.espresso.shape
model_updatable.params
transform_params
layer_shapes
_rank
Error in reading in-memory network.
Error in unarchiving updatable params.
unordered_map::at: key not found
The program (%@) has no init function, which means all the functions are stateless. Do not try to create a context on such a program.
_updated
B32@?0@"NSString"8Q16^B24
The provided input(s): [%@] does not exist in the %@ function.
The provided input(s) missing argument(s): [%@] for the %@ function.
Duplicate image preprocessing directive for feature '%s'.
There are no inputs that are of type image, but still 'scale_image' op for preprocessing has been provided.
Unable to map image preprocessing feature name to any given image input name.
startValue
endValue
stepSizeValue
Step size in the range layer cannot be 0
withBase2
signed_key_request
raw_request
Expected feature of type %@ but got %@
Feature description does not allow missing %@ values
%@ : Dictionary (%@)%@
%@ : Image (%@)%@
%@ : MultiArray (%@)%@
%@ : Sequence (%@)%@
%@ : %@%@
optional
constraints
kVPoints
kVPointsL2Squared
kNumDataPoints
invalid queryPoint.size()=
Unexpected dimensionality of update data
Training data is empty
modelNames
.model%lluv%@
Failed to evaluate model %@ in pipeline
Failed to carry forward results for model %@ in pipeline
Pipeline Model contains multiple models that have parameter for requested key %@. Use parameter scoping to disambiguate.
Pipeline Model does not contain a model that has a parameter for requested key %@.
Model specification does not contain an ML Program.
ML Program does not contain a function named main.
ML Program main function is not written in an opset that is supported by CoreML compiler.
Unknown class type.
Op "classify" can only be defined once per ML program.
Op "classify" is only valid when defined inside a function level block.
while_loop
Mismatch between rank of input/output tensors and the length of axes.
Invalid axes argument
Invalid input shape
Invalid shape of first argument.
Invalid shape of second argument.
Invalid rank of output.
Invalid rank of output
Incompatible shapes for matrix multiplication.
Mismatch between ranks of input and output tensors.
Invalid value of the argument 'axis'.
Invalid ranks of input tensors.
Invalid shape of input tensors.
BroadcastTo layer: Invalid target shape.
BroadcastTo layer: Invalid shapes for broadcasting.
Gather layer: Invalid rank of Output.
Gather layer: Invalid value of the argument 'axis'.
Gather layer: Invalid indices.
Gather tree layer: Parent out of bound.
StackND layer: Invalid shapes of input tensors.
StackND layer: Invalid rank of output tensor.
StackND layer: Invalid value of the argument 'axis'.
Split layer: Invalid number or size of splits.
SliceND layer: Mismatch between the input rank and the number of elements in begin_ids.
SliceND layer: Mismatch between the input rank and the number of elements in end_ids.
SliceND layer: Mismatch between the input rank and the number of elements in begin_masks.
SliceND layer: Mismatch between the input rank and the number of elements in end_masks.
SliceND layer: Mismatch between the input rank and the number of elements in strides.
SliceND layer: Invalid values in begin_ids.
SliceND layer: Invalid values in end_ids.
SliceND layer: Invalid values in strides.
SliceND layer: Invalid values in arguments (begin_ids, end_ids, strides)
Tile layer: Mismatch between input rank and the number of elements in multiples.
Tile layer: Invalid values in multiples.
Sliding Windows Layer: Mismatch between ranks of input and output tensors.
Sliding Windows Layer: Window size can't be less than 1
Sliding Windows Layer: Step can't be less than 1
Sliding Windows Layer: Invalid value of the argument 'axis'.
Sliding Windows Layer: Window Size can't be larger than the dimension length.
Sliding Windows Layer: Invalid values in arguments (axis, window_size, step)
Input feature length mismatch. Got features of length %d expected length of at least %d
Input feature length mismatch. Got features of length %d expected length of %d
Input feature length mismatch. Got features of length %d expected length %@
strides must be 
 elements for shape
Shape must have at least one element
_MLSNVGGishFrontendProcessing
_SNVGGishFrontEndProcessingCustomModel
Frontend processing not available on this version
Frontend processing failed to init
_SNSoundPrintAFeatureEmbeddingCustomModel
parameters == nil.
Not conforming custom model protocol.
Audio feature extractor failed to init
Model type is not an audio feature print
Audio feature print not available on this OS version
Must only have one input multiarray feature
Audio feature print type not set
targetShape
action
GKDecisionTree->CoreML
attribute
children
branch
branchValue
model.pb
attributes.gk
model.mlmodelc
@"NSDictionary"8@?0
fileURL is nil
Input file too large to hash
Failed to hash the input file.
Failed to hash the input file: %s
SliceND layer: mismatch between rank of the input and the length of 'begin ids' parameter
begin_ids
begin_masks
end_ids
end_masks
Number of elements along each dimension needs to be positive.
Mismatch between lengths of shape and strides.
Invalid multi_index.
Invalid rank encountered while converting Espresso Shapes to N-dimensional shape.
Invalid Shapes encountered while converting objective C NSArray shape to std:vector shape
Invalid shapes for broadcasting
values
com.apple.coreml.DecrptSessionManager
Operation not supported on this platform.
_MLSNSoundPrint
Framework not available on this version.
Sound Print not available on this version.
Sound print model does not conform to custom model protocol.
Sound print failed to init.
neural_network_optionals
Direct
BufferCopy
MLE5DirectMode has invalid value: %d
IOSurface-backed MultiArray
Memory-backed MultiArray
IOSurface-backed PixelBuffer
Memory-backed PixelBuffer
e5rt_io_port_is_tensor failed. E5RT: %s (%d)
e5rt_io_port_is_surface failed. E5RT: %s (%d)
The combination of port trait %@ and feature trait %@ is not supported.
The combination of port trait %@, feature trait %@, and direct bind mode %@ is not supported.
MultiArray shape %@ doesn't match the port's expected shape %@.
Failed to get width from E5 surface descriptor. E5RT: %s (%d)
Pixel buffer frame size %zu x %zu doesn't match the port's expected image size %zu x %zu.
Failed to get number of planes from E5 surface descriptor. E5RT: %s (%d)
The inference engine expects multi-planer format (plane count = %zu). CoreML doesn't support such models yet.
Failed to get buffer object's base pointer. E5RT: %s (%d)
Failed to create MLMultiArray: %@.
Failed to bind the input feature value.ESRT: %s (%d)
The port trait %@ is not supported.
The combination of port trait %@ and feature type %@ is not supported.
The combination of port trait %@, feature type %@, and direct bind mode %@ is not supported.
Failed to bind the output buffer object.ESRT: %s (%d)
Failed to bind the output surface object.ESRT: %s (%d)
MLE5Engine doesn't support MLImagePixelType %tu yet.
Failed to get E5 tensor descriptor. E5RT: %s (%d)
The port's shape is %@, which doesn't have enough dimensions to map width and height.
Failed to get E5 surface descriptor. E5RT: %s (%d)
Failed to allocate E5 buffer object. E5RT: %s (%d)
Failed to create E5 buffer object from IOSurface. E5RT: %s (%d)
Failed to create E5 surface object from surface descriptor. E5RT: %s (%d)
com.apple.coreml.MLE5Engine.outputPortBinder
Explicit output backing is not implemented yet for the E5 engine
compiler error: 
mlmodelc
%@ Error reading protobuf spec. %s
1404
9999.0.1
enc_%@
SC_Info
%@.sinf
%@.mlsinf
Key ID has to be specified while encrypting model.
Specified Key ID %@ is not in UUID format.
encryptionInfo
%@ No known class for compiling model type %@
%@ Invalid compiling class %@ for model type %@
No known class for compiling model type %@
Invalid compiling class %@ for model type %@
model%d
MLModelType_pipelineClassifier
MLModelType_pipelineRegressor
MLModelType_pipeline
MLModelType_glmRegressor
MLModelType_supportVectorRegressor
MLModelType_treeEnsembleRegressor
MLModelType_neuralNetworkRegressor
MLModelType_bayesianProbitRegressor
MLModelType_glmClassifier
MLModelType_supportVectorClassifier
MLModelType_treeEnsembleClassifier
MLModelType_neuralNetworkClassifier
MLModelType_kNearestNeighborsClassifier
MLModelType_neuralNetwork
MLModelType_itemSimilarityRecommender
MLModelType_mlProgram
MLModelType_customModel
MLModelType_linkedModel
MLModelType_oneHotEncoder
MLModelType_imputer
MLModelType_featureVectorizer
MLModelType_dictVectorizer
MLModelType_scaler
MLModelType_categoricalMapping
MLModelType_normalizer
MLModelType_arrayFeatureExtractor
MLModelType_nonMaximumSuppression
MLModelType_identity
MLModelType_textClassifier
MLModelType_wordTagger
MLModelType_visionFeaturePrint
MLModelType_soundAnalysisPreprocessing
MLModelType_gazetteer
MLModelType_wordEmbedding
MLModelType_audioFeaturePrint
MLModelType_serializedModel
Failed to add a ML Program to the compiled model: 
model0
Cannot add ML Program to this model because it is not eligible.
Found errors while adding ML Programs to sub-models in the pipeline:
     %@ : %@
Specialization 
 already exists.
URL has nil fileSystemRepresentation
model does not implement protocol MLModelSpecificationSaver
Unable to extract model type from stream in compiled model: %@
0.0.0
Serializing model to compiled format is not yet supported.  Try with compilerOptions=nil
Failed to create a working directory URL
Failed to copy model from %@ to %@
Failed to replace model from %@ to %@
Cannot determine predictedFeatureName for this classifier
Invalid classifier: predicted feature '%@' is not described as int or string
Invalid classifier: predicted probs '%@' is not described as dictionary
Predicted probabilities '%@' is of type %@ not the expected %@
/private/var/mobile/Library/Trial
/System/Library/AssetsV2/
/private/var/MobileAsset/AssetsV2
coreml
com.apple.private.coreml.tracing-allowed
/Library/Trial
com.apple.coreml
sparse features not yet supported
an error occurred when trying to create specification for BayesianProbitRegression
Training Begin
Epoch End
Mini Batch End
Training End
interestedEvents: ()
interestedEvents: %@
Supplied
Not Supplied
progressHandler: %@
completionHandler: %@
<%@: %p, id: %@>
The input feature provider cannot be nil.
Unable to classify the input because the model description doesn't have predictedFeatureName property.
Unable to classify the input because the model description doesn't have class labels.
There must be at least one class to return.
MLMultiArray for class probabilities must be Float64 or Float32.
There is no output feature named %@.
Output feature named %@ is supposed to be a MLMultiArray representing class probabilities but it is %@.
Class probability feature named %@ has %tu classes, but there are %zd class labels.
Class probability feature named %@ must be a MLMultiArray of Float32 or Float64.
Class probability feature named %@ must be a contiguous MLMultiArray.
Unable to regress the input because the model description doesn't have predictedFeatureName property.
The predicted feature value for the regressor model must be a multi array but it was %@. This error should have been caught by the validator.
lossValue
epochIndex
miniBatchIndex
Missing predictionFromFeatures:error implementation
modelDescription: %@, 
configuration: %@
Model does not have a parameter for requested key %@.
Initialization of sceneprint parameters failed
Initialization of image feature extractor parameters failed
Invalid parameters for vision feature print
Model type is not a vision feature print
Vision framework not available for scene print on this OS version
Vision framework not available for object print on this OS version
ObjectPrint unable to get expected shapes
Output count %lu does not match expected %lu from object print
Output count %lu does not match expected %lu in the request revision %lu
Output name %@ not found in the outputs specified in object print
Output %@ is not a MultiArray
Must allow (%@, %@, %@) vector for output feature %@
Feature extractor type not set
v16@?0^v8
Expected feature '%@' of type 'image' was not present in input
Vision framework for scene print not available on this OS version
Vision framework for object print not available on this OS version
q24@?0@"NSArray"8@"NSArray"16
Error empty specificationURL: %@
Error replacing MLProgram with in-memory MLProgram : %@
Error loading program as in-memory program: 
@model_path
UnSupported DataType
com.apple.CoreML
Error in initalizing the classifier.
Invalid objective and/or numClasses.
Error in initalizing labels.
Cannot load the trained model.
Prediction failed since the tree was not trained with any data point.
Prediction failed since data could not be transformed properly.
Prediction failed.
Shape of training data point %i MLMultiArray is %@, expected %@
Input data other than MLFeatureTypeMultiArray is not supported for training.
Missing input name for Tree Ensemble Classifier.
Received nil MLFeatureProvider for index %ld from training data MLBatchProvider for training input: %@
Shape of training data point %li MLMultiArray is %@, expected %@
Failed to convert training data to the right format.
Data provided in input is missing feature value for training input: %@
Label must be of type MLFeatureTypeString or MLFeatureTypeInt64
Label %@ not found for data index: %ld.
Cannot create MLBatchProvider.
Cannot create MLFeatureProvider.
binary:logistic
multi:softprob
Current objective not supported. Supported objectives are multi:softprob and binary:logistic.
Data processing failed.
numClasses parameter must be provided.
objective parameter must be provided.
Objective and number of classes does not match. numClasses for 'binary:logistic' must be defined as 1.
XGBoosterPredict
XGBoosterLoadModel
XGBoosterFree
regress:error must be implemented by derived class!
UpdatableNeuralNetworkMLComputeBackend doesn't support in-memory compilation.
Failed to archive update parameters.
Failed to archive entire spec.
entireSpec
Data provided has unsupported shape (%@)
Failed to extract output tensor
Output is not in the expected format
com.apple.CoreML.MLLoader
com.apple.CoreML.MLPrediction
com.apple.CoreML.MLCompiler
modelType
modelVersion
compilerVersion
modelCompiledWithVersion
modelLoadTime
modelOrigin
modelHash
modelDimension
nnModelNetHash
nnModelShapeHash
nnModelWeightsHash
modelLoadError
bundleIdentifier
firstPartyExecutable
modelIsEncrypted
modelProgramValidationError
modelProgramParsingError
milUpgradeStatus
milUpgradeFailureReason
featuresPredictionDuration
featuresPredictionCountSoFar
com.apple.createml.version
com.apple.createml.app.version
com.github.apple.turicreate.version
com.apple.developer.machine-learning.models.version
com.github.apple.coremltools.source
keras
tensorflow
onnx
torch
scikit-learn
xgboost
libsvm
com.apple.da
AutomatedDeviceGroup
COREML_AUTOMATED_TESTS
Failed to unarchive update parameters. Model should be re-compiled.
Failed to unarchive update parameters.
Inconsistent value types in array
Cannot form description from nothing
Inconsistent value constraints in array
Image found with unsupported pixel type
.values
MultiArray
Dictionary
Image
Sequence
UnknownValue
Illegal value in MLFeatureType enum
v32@?0@"NSNumber"8Q16^B24
$BUNDLE_MAIN
$BUNDLE_IDENTIFIER
%@ is missing feature '%@'
%@ feature '%@' is inconsistent with '%@'
Model type is not linked model as expected
Model linking could not find model (%@) in search path (%@) relative to (%@)
Linked model
Root/Loaded model
Linked Model does not have a parameter for requested key %@.
@min.doubleValue
@max.doubleValue
minNumber
maxNumber
enumeratedNumbers
minValue: %@
maxValue: %@
enumeratedNumbers: %@
com.apple.coreml.modelkeystore
mks-production
fetchKey2
Fetching decryption key from server failed.
Fetching decryption key from server failed: %s. Make sure the encryption key was generated with correct team ID.
Fetching decryption key from server failed: response with neither hasError nor hasSuccess.
v24@?0@"ModelKeyServerAPIFetchKeyResponse"8@"NSError"16
Fetching decryption key from server timed out. Make sure the device is online.
Model output names must not be duplicated.
Unknown class label type.
Input image has invalid colorspace.
A model for tagging words constructed in memory
labels
Output labels
locations
Output locations
lengths
Output lengths
modelData
A model for classifying sentences constructed in memory
Input sentence
Output label
kMLLayerComputeUnitHintFallbackFromGPU
kMLLayerComputeUnitHintFallbackFromNE
kMLLayerComputeUnitHintFallbackFromCPU
hint_fallback_from_metal
hint_fallback_from_cpu
hint_fallback_from_ane
'model.espresso.net' file not found at the given compiled model path: %@.
Unable to load information from compiled model path %@.
Compiled model path: '%@', must be a directory.
Compiled model path: '%@', must be a writable directory.
.bckp
Unable to create backup of .net file at compiled model directory, with error: %@
Failed to serialize new .net data after updating schedule hints, underlying error message: %@
Execution Profile not recognized.
ERROR: profile=
; idx=
; ref_value=
; pred=
Validation failure loading ML tree model; possibly corrupt image.
ML Program does not have a function named main.
MLModel Specification does not declare a classifier, but the ML program does declare one.
MLModel Specification and ML program classifier predicted feature name do not match.
MLModel Specification and ML program classifier predicted probabilities name do not match.
MLModel Specification declares a classifier, but the ML program does not contain a 'classify' op.
parameters
Model and main function must have same number of inputs.
ML Program is missing MLModel Specification input 
Neural Networks require 
 to be images or MLMultiArray.
Model 
' is not a supported data type. Only int32, float32, or float16 data types are supported for MLMultiArray 
s to ML Program models.
parameter
return value
Unexpected 
 type.
' is not a tensor.
' has a different type than its corresponding 
 to main.
' has a different rank than its corresponding 
' has a different shape than its corresponding 
main 
' must be a tensor of type Float32 or Float16
Model image 
' has empty height or width.
' is not a dictionary.
' has invalid key type.
return values
Model and main function must have same number of outputs.
MLModel Specification output 
 does not have the same name as the ML program output at the same index.
Version
KeyIdentifier
UsesCodeSigningIdentityForEncryption
SINF
AAADgHNpbmYAAAAMZnJtYQAAAAAAAAAUc2NobQAAAABpdHVuAAAAAAAAA1hzY2hpAAAADHVzZXIAAAAAAAAADGtleSAAAAABAAAAGGl2aXbZofvYoEHG+Bnh6TFdS4nRAAAAWHJpZ2hwbGF0AAAAAnRyYW7aSnJxdG9vbEQ5OTltZWRpAAAAgG1vZGUAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQhuYW1lAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcBwcml2dHT7EFcJPPVjnUp9b53GcsqIfPZ2Zwq2GeQ3aigPDGVuD0OGm6NZEzuiK3dNectFh1Z5LE06hTFwi67WA/4z+7xXmX0aMBmYfYmL9dVVxwOKwJ1bpkkZkXyil21zxsKwHVn6ZSgegaKm9C5YQcyL/uY9aqYkLS2+qKVWyx/3pBVY1cAAPyNpVDBsNIpNGguNmEEA4l7IhB8Q+m1VAPCcxgngaFT6ztBjdUfseVYj3fh28t7NXhdQbZB7PNDxU2VToqvN2t1f6Gco/qc8fRXXGo12pLH346qDQezYMlbBS0w76GtyWoK+oLu3FTMjjCi7Kg1SyDDBbbDsg0RVMkyHhZ3TOFmwJklAYL7HxsWa+rCRM4Q4YOJobScLgeZ/7daGTAeX03OMT/iWgPHf+ejCVQGje+Mm+a8P5UzKpHhV9ruwF2usDUoynhmyIYr/EnrcUyQdPjLX8wG7BYMJMhh/vuaIfkwVt1M2kgFJ9T8Kz+JczEJSfLIwhW6Uy+ltyRrVnlaGfoPdrohv4P4FgaBuaUFSoKiXMuZr4IXhEHh9sCoAv6sSDIAFURgBX1wtn9HWAAAAAAAAAAA=
saveToFile URL (%@) should be different from fileURL (%@)
Error creating file %s
Error saving ENML header to %s
Error saving data to %s
Key length %lu does not match encryption block size %u
IV is specified but it's length %lu does not match encryption block size %u
Failed to encrypt data
Encryption outputSize does not match outputWritten
dictionary
Pipeline is not marked as updatable to perform update.
Updatable model index is out of range.
model
Failed to load updatable sub-model at %lu
Failed to carry forward results for model %llu in pipeline
model%llu
%@/%@
MIL program input, '%s', not found in Core ML model inputs
Core ML model input, '%@', not found in MIL main program's inputs
Error in reading the MIL network.
Error in reading the in-memory MIL network.
CompiledObject
_MLVNDetectionPrintCustomModel
MLDetectionPrintRequestRevision
MLDetectionPrintConfiguration
DetectionPrint not available on this version
DetectionPrint unable to get supported revisions
Must only have one input feature of image type
DetectionPrint unable to get expected shapes
Output feature %@ not expected
Failed to compute detection print
size
step
lossType
optimizerType
optimizerParameters
lossParameters
trainableLayerNames
Error in archiving updatable params.
MLNeuralNetworksCompileTimeParams
message
Initialization of Text classifier parameters failed
Model type is not a Word tagger
Invalid parameters for Text Classifier
initialization of text classifier model with model data failed
Text label
This model is a text classifier (version %lu) which classifies %@ text according to set {
This model is a text classifier (version %lu) which classifies text according to set {
This PipelineClassifier was created with unreleased beta CoreML and is no longer supported. Please re-create/convert your model with the the current Core ML
Invalid model type found in compiled pipeline model.
The program argument to MLProgramEvaluator is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
.model property is not implemented yet. See rdar://86160890.
Ios16TrainBackend doesn't support in-memory compilation.
Cannot find main function in translated program.
model_train.mil
Cannot generate training program.
Cannot save training program.
kLeafSize
kVData
kVIndices
kRoot
splitIndex
splitDimension
splitValue
startingIndex
count
rightChild
leftChild
intervals
isLeaf
Splitting node along dimension %lu, by value %.4f
Found split index %lu
dataPoints.size() % dimensionality != 0
invalid point.size()=
invalid k=
A Core ML custom neural network layer requires an implementation named '
' which was not found in the global namespace.
A custom neural network layer implementation class named '
' does not conform to the MLCustomLayer protocol.
Model type is not a NonMaximumSuppression
Data type error for NonMaximumSuppression: confidence and coordinates must be MLMultiArray of a same type and it must be either DOUBLE or FLOAT32. However, confidence uses %@ and coordinates uses %@
Dimension 1 of input confidence (%@) is not consistent with the number of classes (%lu)
Batch produced nil feature provider for index %@
Failed to obtain prediction for sample %@
Error: getObject is not supported by _OArchiveDiskImpl
Failed to open file: 
. It is not a valid .mlmodelc file. 
Failed to read first word from 
 is not a valid .mlmodelc file because the first word (
) is not recognizable. 
coremldata.bin
Failed to create a stream. E5RT: %s (%d)
Failed to add operation to E5 stream. E5RT: %s (%d)
Failed to execute E5 stream.ESRT: %s (%d)
Failed to reset the stream. E5RT: %s (%d)
Invalid NeuralNetwork Specification type
com.apple.coreml.mlupdatetask_update_queue
kUpdateParametersKey
Model is no longer valid outside update callback
v16@?0@"MLUpdateContext"8
updatableModelURL: %@
trainingData: %@  count: %zd
progressHandlers: %@
state: %@
/System/Library/Frameworks/NaturalLanguage.framework/NaturalLanguage
NLPSequenceModelCopyPredictedTokensAndLabelsForText
NLPSequenceModelCreateWithData
NLPSequenceModelGetRevision
NLPSequenceModelIsRevisionSupported
NLPSequenceModelGetCurrentRevision
NLPClassifierModelCopyPredictedLabelForText
NLPClassifierModelCreateWithData
NLPClassifierModelGetRevision
NLPClassifierModelIsRevisionSupported
NLPClassifierModelGetCurrentRevision
NLPGazetteerModelCopyLabelForString
NLPGazetteerModelCreateWithData
NLPGazetteerModelGetRevision
NLPGazetteerModelIsRevisionSupported
NLPGazetteerModelGetCurrentRevision
NLPEmbeddingModelCopyVectorForString
NLPEmbeddingModelCreateWithData
NLPEmbeddingModelGetRevision
NLPEmbeddingModelIsRevisionSupported
NLPEmbeddingModelGetCurrentRevision
Model revision %ld not supported by NaturalLanguage framwork on this OS version (support revision %ld).
v16@?0@"NSError"8
v24@?0@"NSString"8@"NSError"16
MPSGraph
MPSGraphFP16
features.%@
Error reading from archive.
Error writing to archive.
com.apple.CoreML.MLPredictionEvent
MLAutomaticOutputBackingModeEnabled
MLAutomaticOutputBackingModeDisabled
MLAutomaticOutputBackingModeForced
usesCPUOnly
classifyTopK
maxComputationBatchSize
parentSignpostID
Initialization of word tagger parameters failed
Model type is not a word tagger
Invalid parameters for Word Tagger
initialization of word tagger model with model data failed
Input text
Token tags
Token lengths
Token locations
Tokens
This model is a word tagger (version %lu) which tags %@ words according to set {
This model is a word tagger (version %lu) which tags words according to set {
Feature '%@' is not provided
Cannot merge batch of size %@ with batch of size %@
Invalid window starting at %@ of length %@ for batch size %@
Expected to vectorize into matrix, but was passed a %@ multiarray
Row count of matrix (%@) does not match batch size (%@)
data
Interface type is not an Support Vector Classifier
Failed to prepare E5 execution stream operation for encode.ESRT: %s (%d)
The operation was never prepared or has been reset
Failed to build output feature provider with error %@.
Failed to create E5 execution stream operation. The library path was %s and the function name was %s.ESRT: %s (%d)
Failed to retain E5 execution stream operation input port %@ E5RT: %s (%d)
The input feature provider doesn't have a feature %@ or it is undefined.
Failed to get the number of inputs for operation. E5RT: %s (%d)
Failed to get input port names for operation. E5RT: %s (%d)
Failed to get the number of outputs for operation E5RT: %s (%d)
Failed to get output port names for operation. E5RT: %s (%d)
CoreMLInference: %@ (%@)
Sound analysis preprocessing does not conform to custom model protocol
Sound analysis preprocessing failed to init
Model type is not a sound analysis preprocessing
Sound analysis framework not available on this OS version
Sound analysis preprocessing not available on this version
Preprocessing type not set
file does not contain encrypted model header
unrecognized magic word in the encrypted model header
unsupported major version = 
file does not contain any payload, sizeOfHeader = 
illegal value for original file size = 
illegal value for number of encrypted pages = 
illegal number of encrypted pages = 
failed to invoke mremap_encrypted with result = 
, error = 
Only integer values with magnitude less than 2^48 are supported in the imputer.
imputer
MLimputer
imputed feature value not set.
MLImputer Input
MLImputer Output
Invalid combination of replace value type and input/output/feature value types.
Could not determine minimum sequence length to construct the model.
Could not convert neural network model layers.
Could not build inference network.
allowSoftmaxApproximation
Unable to create IR context.
Failed to process net for upgrade.
Failed to read model from disk.
Inappropriate model type for upgrade.
Model requires a sequence longer than the maximum.
Error in neural network compiler computing minimum sequence length for the model.
Invalid height and width for the image input.
Input MLMultiArray cannot be %d dimensional (must be between 1 and 5 dimensions).
Neural networks only accept image and array inputs.
Input MLMultiArray cannot be %d dimensional (must have at least 1 dimension).
Error in compiling custom layer model.
Unknown error in compiling network layers.
Error in laying out custom layer model in memory.
Unknown error in building network shapes.
spec
Model does not exist at %@
Failed to read model package at %@. Error: %s
Input feature length mismatch. Got features of length %@ expected length %@
MLSequenceConstraint cannot check undefined values
MLSequenceConstraint only allows MLSequence values
MLSequenceConstraint count constraint does not allow count of %@
MLSequenceConstraint only allows sequence value of type %@. This sequence is type %@
Value at index %d of sequence is not allowed
valueDescription
countRange_len
countRange_loc
Uninitialized
Input, '
' is not of type tensor
' does not have fixed rank
Dimension of the input, '
' consists variadic dimension which is not supported
Rank of the input, '
, but it should be between 1 and 5
, but it should be between 0 and 5
Provided default shape of 
 doesn't match with declared shape in function
No default shape provided for 
 which has unknown dimensions.
Invalid rank: 
Unsupported key type for dictionary feature
Unsupported sequence type
Could not save MLModelDescription to MLModelSpecification
%@: There must be at least %tu features, but there is only %tu.
%@: There must be at most %tu features, but there is %tu.
%@: The feature type must be one of {%@}, but it is %@.
treeRefresh
treeAddition
Error in initalizing model interface.
Error in initalizing update Engine for compiled archive.
Error in initalizing model parameters.
Objective must be either multi:softprob or binary:logistic.
Update type must be either %@ or %@.
label
Cannot create update instance.
numTrees Parameter must be provided and it should be > 1.
Failed to train at iteration number: %lu
learningRate Parameter must be provided.
maxDepth Parameter must be provided.
minChildWeight parameter must be provided.
max_depth
num_class
min_child_weight
objective
process_type
update
updater
refresh
Updated tree ensemble classifier model does not have a parameter for requested key %@.
Cannot save the trained model.
XGDMatrixCreateFromMat
XGDMatrixSetFloatInfo
XGBoosterCreate
XGDMatrixFree
XGBoosterUpdateOneIter
XGBoosterSetParam
XGBoosterSaveModel
Error opening file 
Error reading file statistics of 
File 
: not a regular file.
: error opening mmap: 
name: %@, version: %@ author: %@ description: %@ creatorDefined: %@
feature vectorizer
MLFeatureVectorizer Input
MLFeatureVectorizer Output
Expected value for feature '%@'.
MLFeatureVectorizer: Array length incorrect.
MLFeatureVectorizer: Dictionary key type must be NSNumber.
MLFeatureVectorizer: Dictionary index out of range.
MLFeatureVectorizer: Incorrect Type.
MLFeatureVectorizer: Dict key type must be NSNumber.
MLFeatureVectorizer: Dict idx out of range.
MLFeatureValueImageOptionCropAndScale
MLFeatureValueImageOptionCropRect
{CGRect={CGPoint=dd}{CGSize=dd}}
Functionality unavailable
Operation failed due to missing or zero crop parameters in image constraint.
dict vectorizer
MLDictVectorizer
MLDictVectorizer Inputs
MLDictVectorizer Outputs
Expected input column '%@ not present.
Type of input not dictionary as expected.
Failed to get the temporary directory for the current user.
Failed to create NSURL object for path: %@
Failed to create a working directory appropriate for URL: %@
_%@.mlmodelc
com.apple.runtime-issues
CoreML
analytics
SpecificationDetails
NeuralNetworkModelDetails
PipelineModelDetails
model.espresso.net
model.espresso.shape
model.espresso.weights
model.mil
UpgradeMetadata
main
train
init
forward
Unnamed_Model
normalizer
MLNormalizer
MLNormalizer Input
MLNormalizer Output
Initialization of Word Embedding parameters failed
Model type is not a Word Embedding
Invalid parameters for Word Embedding
initialization of word embedding model with model data failed
Embedding does not contain input string '%@'. %@
Embedding does not contain input string '%@'. 
word
vector
This model is a word embedding (version %lu) which represents an %@ word in a vector space.
This model is a word embedding (version %lu) which represents a word in a vector space.
com.apple.coreml.mltask_work_queue
v8@?0
Task Suspended
Task Running
Task Cancelling
Task Completed
Task Failed
categorical mapping
MLCategoricalMapping Inputs
MLCategoricalMapping Outputs
MLCategoricalMapping: Unknown input value.
Var name 
 shadowed.
scaler
one hot encoder
MLOneHotEncoder
MLOneHotEncoder Inputs
MLOneHotEncoder Outputs
%@: Output description type must be MLTypeDictionary (ouputSparse On) or                       MLFeatureTypeMultiArray (ouputSparse Off) 
MLOneHotEncoder: unknown category %@, expected one of %@
+N9mZUAHooNvMiQnjeTJ8g
restrictNeuralNetworksToUseCPUOnly
restrictNeuralNetworksFromUsingANE
Interface type is not a Bayesian Online Probit Regressor
no features
require feature type of MLMultiArray with one of Int32 values
incorrect number of features: expected %d but got %d
invalid prediction feature type
invalid prediction features
updateModelFromFeatures failed
labels is nil
class probability multiArray must use Float32 or Float64 scalars.
There are %tu class labels but class probability multiArray has only %tu entries.
The probability multiArray must have contiguous first-major layout.
Probability index %tu is out of range because there are only %tu classes.
v24@?0r^v8q16
The number of labels (%tu) is greater than the number of probabilities (%tu).
probabilities is nil.
sharedKeySet must be created with +[MLProbabilityDictionary sharedKeySetForKeys:].
UpdatableNeuralNetworkEspressoNetBackend doesn't support in-memory compilation.
NetworkUpdateParameters
updateParameters
_lossValue
Error in initalizing categorical cross entropy loss layer. This loss layer might be invalid.
Error in initalizing mean squared error loss layer. This loss layer might be invalid.
Current loss layer is not supported.
Current optimizer is not supported.
Error in initializing updatable model.
Error in creating updatable model.
kUpdateLossTargetName
kUpdateLossInputName
kUpdateLossOutputName
Error in initalizing optimizer. The parameters might be invalid..
MultiArray dataType should be %@ but is %@
MultiArrayConstraint cannot check undefined values
MultiArrayConstraint only allows MultiArrays
Neural network model expects vector inputs, but non-unit height or width dimensions were provided.
Neural Network (<=version 3) inputs can only be of size 1, 3, or 5.
According to model description, feature '%@' must be of rank %@, instead got a multi-array value of rank %@.
%@, %@
shapeConstraint
Image width (%@) is not in allowed range (%@..%@)
Image height (%@) is not in allowed range (%@..%@)
Image size %@ not in allowed set of image sizes
imageSizeSet
pixelsWideRange_len
pixelsWideRange_loc
pixelsHighRange_len
pixelsHighRange_loc
array feature extractor
arrayFeatureExtractor
MLArrayFeatureExtractor Inputs
MLArrayFeatureExtractor Outputs
got nil array input to MLArrayFeatureExtractor predict:error:
Lossy cast to integer by ArrayFeatureExtractor; use double as output type.
Invalid output type of ArrayFeatureExtractor.
CoreML Background Watchdog Queue
': output blob channel dimension size is 0.
': output blob height dimension size is 0.
': output blob width dimension size is 0.
Scatter layer: '
_leaky_relu
numerator
denominator
_numerator_reduce_mean_
reduce_mean
_temp
temp
_denominator_reduce_l2_
reduce_l2
square_of_denominator
_denominator_
numerator_div_denominator
numerator_div_denominator_mul_gamma
_max_loop_iters
_load_iterator
cf_loop
_loop_start
_loop_cond_check
_loop_count_check
_loop_joint_condition
_increment_iterator
_jump
_end_loop_if
_end_loop
tensor_zero_pad
general_concat
Dot product layer: '
Split layer: '
' , number of outputs = 
 do not divide the input dimension = 
Split layer :
 , number of outputs (
) do not match the parameter nOutputs (
outputChannels = 
inputDim = 
Embedding layer '
Embedding layer: '
': channel dimension of the input blob must be 1.
fill
_lrn_out
_mul
Average Layer must have exactly 1 output
sum_out
_sum
_sum_
non_maximum_suppression
Mismatched specLayer.slicestatic().*_size values.
A params.* static array would be referenced out of bounds.
batchnorm
Batchnorm layer: 
has insufficient bytes in quantized 
 ,size of 
 must be equal to the number of channels.
 is smaller than the total bytes required for 
The weight blob
 of layer 
 cannot be compiled.
Unsupported Pooling Type: 
Unsupported Padding Type: 
load_random
log_
gumbel_max
Crop layer: 
 , crop border amounts must be specified for both height and width, if set
Crop Layer: 
 , must be provided exactly 2 offset values when it has 2 inputs
Crop Layer: '
': unable to determine the spatial dimensions of the second input blob. 
range
cf_if
cf_else
_else
cf_end
_end
Pooling layer: 
 , if set, kernel size must be of length 2
 , kernel size cannot be 0
 , if set, stride must be of length 2
 , stride cannot be 0
 , for valid padding, padding border amounts must be specified for both height and width, if set
 , for include last pixel padding, padding amounts must be of length 2, if set
Gelu layer: '
activation
PReLU
PReLU Layer: 
 , number of alpha parameters (
) is not equal to the channel dimension (
) of the input
 has insufficent bytes for quantized alpha parameters
params_prelu
ParametricSoftplus
Parametric Softplus: alpha and beta parameters must have the same size
Parametric Softplus layer '
' has invalid alpha/beta size
Parametric Softplus: alpha and beta parameters are not provided
softplus_alphas
softplus_betas
' is unable to infer the size of channels dimension (axis=-3) in the input, which is required when the weight size is 1 or when weights are quantized to lower than equal to 8 bits.
topk
_value
_index_rank_preserved
_squeeze_after_arg
', input channels must be divisible by the number of groups.
', output channels cannot be 0
', input channels cannot be 0
Convolution 3D layer: '
' , if set, output shape must be of length 3
Convolution3D padding type not set
deconv3d
conv3d
' , size of weight parameter not equal to the product of kernel sizes, number of kernels, and kernel channels
' quantized weights are not currently supported
' quantized bias is not currently supported
': argmax reduction operation is only supported along single dimensions C, H or W.
Input
Unrecognizable Neural Network type.
Failed to copy empty or invalid weights to kernel
Unsupported recurrent non-linearity type.
Unable to read 
weight elements.
quantized weight elements from byte stream.
Unrecognizable weight parameter type.
Error converting float16 biases
_tmp_
Invalid network: Layer name missing.
Invalid network: Expected at least one input for layer: '
Invalid network: Expected at least one output for layer: '
Input shapes must be equal for layer: '
Input shapes (height and width dimensions) must be equal for layer: '
Input '
' of layer '
' not found in any of the outputs of the preceeding layers.
Invalid data blob: '
' shape (C,H,W = 
) for output of layer: '
Validate number of inputs and outputs: Unknown layer type
Invalid number of inputs (
) and outputs (
) to layer: '
Layer name: '
'. Input and output data blob names cannot be the same.
Mean image preprocessor input blob ('
') not found. 
_preprocessed
mean_image_
Mean Image Preprocessing: mean image size must be same as input image size.
load_constant_mean_image_
elementwise_add_mean_image_
GRU layer: must provide 2 activations
GRU layer: '
Bias Layer: shape cannot be of size 0
Bias Layer: shape must be of size 1 or 3
constant_in
Bias Layer: bias size does not match provided shape
Bias Layer: Must accept exactly 1 input and produce 1 output
Upsample layer: 
 , Fractional scaling only compatible with align_corners=true or align_corners=false bilinear mode.
 , Only one of scalingFactor and fractionalScalingFactor can be set, and if set, must be of size 2.
Upsample layer: '
': unknown value for parameter 'linearupsamplemode'.
embedding size = 
vocab size = 
 is not equal to size of the product of input dims and output channels = 
EmbeddingND layer '
' has insufficient bytes for 
units in weight
 is not equal to the output dims = 
units in bias
Reorganize Data layer: '
' unknown value for parameter 'mode'.
space_to_depth
Reorganize data layer: '
': 'blockSize' must divide height dimension of the input.
': 'blockSize' must divide width dimension of the input.
': 'blockSize' square must divide channel dimension of the input.
softmax_nd
 layer: weight size incorrect
 layer : insufficient units in quantized weight byte stream
 layer : all the weight matrices must have same type
 layer: weight matrix size incorrect
 layer : all the weight matrices must have same quantization level
 layer : all quantized weight matrices must have same number of bytes
 layer : all weight matrices must have either linear quantization or LUT
_per_ch_qscale
_per_ch_qbias
_lut_to_float32
 layer: bias size incorrect
 layer: insufficient units in quantized bias byte stream
Reshape Layer: target shape must of length 3 or 4
Reshape layer: '
': product of new shape must equal the product of input blob dimensions.
LSTM layer: must provide 3 activations
LSTM layer: '
MLCustomLayerWrapper
In custom layer 
, parameter key 
 has no value.
brick
MLCustomLayerWeights
matrix_band_part
ScatterND layer: '
Load Constant: shape must be of size 3
get_shape
Bi dir LSTM layer: must have two weight params
Bi dir LSTM layer (forward lstm): must provide 3 activations
Bi dir LSTM layer (backward lstm): must provide 3 activations
Uni-directional LSTM
W_x_reverse
W_h_reverse
Bi-directional LSTM
b_reverse
p_reverse
BLSTM layer: '
output size = 
input size = 
Recurrent layer: too many output blobs.
Recurrent layer: too few output blobs.
Recurrent layer: too many input blobs.
Recurrent layer: too few input blobs.
_prereverse
sequence_reverse
rnn_arch
Recurrent layer: '
': height dimension of the input blob must be 1.
': width dimension of the input blob must be 1.
_post_scale
_post_scale_shift
_scale
_shift
Lookup table size incorrect.
Unrecognizable quantization parameters
Unrecognizable linear quantization scale parameter length.
Quantization bias should have the same length as scale if it exists
per_ch_qscale
per_ch_qbias
lut_to_float32
l2_normalize
cf_jump
_break
_continue
int8 dynamic quantization not valid with >1 input
batch_matmul
 :                            when flag 'int8DynamicQuantize' is set to true, weights must be stored in the int8 format.
 :                           Number of bits must equal 8 when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization must be used when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization scale must be size 1 when flag 'int8DynamicQuantize' is set to true.
 :                           Linear quantization bias must be empty when flag 'int8DynamicQuantize' is set to true.
 is not equal to size of the product of the first and second dimensions provided as layer parameters = 
 in Batched-MatMul layer 
 is smaller than the total bytes required for the product of the first and second dimensions provided as layer parameters = 
-bit quantization in Batched-MatMul layer 
 is not equal to the second dimension of the matrix = 
Size of quantized bias is insufficient for Batched-MatMul layer 
Rank preserving reshape layer '
': input/output rank greater than 5 not supported currently
__prelog
__squared
__exp
_presqueeze
reduce
__reduction_axis__
squeeze
reverse_seq
Load Constant: shape must be of non empty
Load Constant: can only handle rank 1 to 5
Load Constant: data size does not match provided shape
ScatterAlongAxis layer: '
': unknown value for parameter 'mode'.
scatter_nd
broadcast
gather_nd
inner_product
number of output channels = 
 not allowed in layer 
number of input channels = 
_dynamic_quantize_
_post_quantization_blob_
_activation_quantization_scale_
_dynamic_dequantize_
_pre_dequantization_blob_
dynamic_quantize
dynamic_dequantize
Layer: 
 does not satisfy int8 quantization requirements.
W_int8
biases
Incorrect weight type 
 in layer 
Size of weights = 
 is not equal to size of the product of input and output channels = 
Size of quantized weights (in bytes) = 
 is smaller than the total bytes required for the product of input and output channels = 
for 
-bit quantization in layer 
Size of bias = 
 is not equal to the output channels = 
Size of quantized bias is insufficient for Inner Product layer 
Inner product layer: '
' : Product of input blob dimensions C,H,W (
) must be equal to the parameter 'inputChannels' (
reshape
Resize bilinear layer: 
Sampling mode not set in resize bilinear layer.
sequence_repeat
sliding_windows
Scale Layer: Scale shape cannot be of size 0
Scale Layer: Scale shape must be of size less than or equal to 3
Scale Layer: Scale size does not match provided shape
constant_in_scale
Scale Layer: Must accept exactly 1 input and produce 1 output
Scale Layer: Bias shape cannot be of size 0
Scale Layer: Bias shape must be of size less than or equal to 3
Scale Layer: Bias size does not match provided shape
constant_in_bias
mul_out
sequence_concat
concat
' , deconvolution does not support weight as input tensor.
' , input channels must be divisible by the number of groups.
' , output channels cannot be 0
' , kernel channels cannot be 0
' , if set, kernel size must be of length 2
' , kernel size cannot be 0
' , if set, stride must be of length 2
' , stride cannot be 0
' , if set, dilation factor must be of length 2
' , dilation factor cannot be 0
' , if set, output shape must be of length 2
' , for valid padding, padding border amounts must be specified for both height and width, if set
Same Padding Mode not recognized
deconvolution
convolution
' , size of weight parameter not equal to the product of kernel sizes, number of kernels and kernel channels
' has insufficient convolution weights
' , size of bias parameter not equal to the number of output channels
Insufficient quantized bias elements in 
' input's channel dimension (
) is not equal to the number of layer parameters  (
Permute Layer: axis parameter must of length 4
transpose
Crop resize bilinear layer: 
 , target size must be of length 2, if set
Sampling mode not set in crop resize layer.
Box coordinates mode not set in crop resize layer.
crop_and_resize
expand_dims
Padding layer: 
 , pad amounts must be specified for both height and width, if set
Padding Type not set
general_padding
Unknown layer type
_axis
cumsum
_load_constant_
load_constant
elementwise
general_slice
classify
Failed to inherit operator '
' from opset '
 because the operator is already registered.
CoreML5
CoreML6_train
probabilities
classes
Classifier probabilities can have a maximum of one dimension that is not rank 1.
Classifier probabilities must have a fully known shape.
Arguments not of the same length in classify operation
Incorrect type for class prediction output of classify operation
Incorrect type for probabilities output of classify operation
CoreML.Specification.CoreMLModels.AudioFeaturePrint.Sound
CoreML.Specification.CoreMLModels.AudioFeaturePrint
Must provide training inputs for updatable neural network (expecting both input and target for loss function).
Training inputs don't describe required inputs for the loss (needs both the input and the target).
The training inputs must include at least one input from the model itself as required for training (should have at least one input in common with those used for prediction).
The type of the training input provided: 
 doesn't match the expected type of the classifier. Found: 
, expected: 
The training inputs don't include the target of the classifier: 
The training inputs don't include the loss layer's target: 
The layer named '
' is marked as updatable, however it is not supported as the type of this layer is neither convolution nor inner-product.
The model is marked as updatable, but none of the layers are updatable.
An updatable layer, named '
', has quantized weights/bias param. Quantized weights/bias not supported for update.
', has a weight/bias param which is not marked as updatable.
The updatable model has a name collision for: '
', i.e., there are more than one layers or loss layers with this name.
This model has more than one loss layers specified, which is not supported at the moment.
Failed to look up node for '
There is a layer (
), which does not support backpropagation, between an updatable marked layer and the loss function.
For the categorical cross entropy loss layer named '
', input is not generated from a softmax output.
For the cross entropy loss layer named '
', target is generated within the graph.
For the MSE loss layer named '
', input is not generated within the graph.
Loss function is not recognized in the loss layer named '
', only cross entropy loss and MSE are supported.
SGD optimizer should include learningRate parameter.
learningRate
SGD optimizer should include miniBatchSize parameter.
miniBatchSize
ADAM optimizer should include learningRate parameter.
ADAM optimizer should include miniBatchSize parameter.
ADAM optimizer should include beta1 parameter.
beta1
ADAM optimizer should include beta2 parameter.
beta2
ADAM optimizer should include eps (epslion) parameter.
Optimizer is not recognized.
Epochs should be included in neural network update parameters.
epochs
seed
CoreML.Specification.CategoricalMapping.strValue
CoreML.Specification.CategoricalMapping
CoreML.Specification.Pipeline.names
CoreML.Specification.Pipeline
CoreML.Specification.PipelineClassifier
CoreML.Specification.PipelineRegressor
CoreML.Specification.FeatureDescription.name
CoreML.Specification.FeatureDescription.shortDescription
CoreML.Specification.FeatureDescription
CoreML.Specification.Metadata.shortDescription
CoreML.Specification.Metadata.versionString
CoreML.Specification.Metadata.author
CoreML.Specification.Metadata.license
CoreML.Specification.Metadata.UserDefinedEntry.key
CoreML.Specification.Metadata.UserDefinedEntry.value
CoreML.Specification.Metadata
CoreML.Specification.ModelDescription.predictedFeatureName
CoreML.Specification.ModelDescription.predictedProbabilitiesName
CoreML.Specification.ModelDescription
CoreML.Specification.SerializedModel.identifier
CoreML.Specification.SerializedModel
CoreML.Specification.Model
/dev/urandom
Convolution
Convolution Layer '
' does not support weight as input tensor when RANK5_ARRAY_MAPPING == true.
Padding type for convolution layer '
' is not set.
Deconvolution Layer '
' does not support weight as input tensor.
Convolution layer: '
' , dilated convolution does not support weight as input tensor.
' with dynamic weight does not support static bias.
Convolution layer '
'  has invalid weights/bias fields.
Convolution layer 
has unmatched precisions of weights/bias They should either be half or full precision.
Deconvolution layer '
' has weight matrix of size 
 to encode a 
 convolution.
weight
Layer 
has not specified weights.
' has a bias vector of size 
 but should be 
bias
has not specified bias.
Convolution3D
Convolution3D layer: '
', convolution3D does not support weight as input tensor.
Input Channels
Output Channels
Groups
Kernel Depth
Kernel Height
Kernel Width
Stride Depth
Stride Height
Stride Width
Dilation Depth
Dilation Height
Dilation Width
Custom Padding Front must be non-negative, got '
Custom Padding Back must be non-negative, got '
Custom Padding Top must be non-negative, got '
Custom Padding Bottom must be non-negative, got '
customPadding Left must be non-negative, got '
customPadding Right must be non-negative, got '
Convolution3D layer '
' has unmatched precisions of weights/bias They should either be half or full precision.
Deconvolution3D Layer '
' Output Shape is supported for Deconvolution layer.
Deconvolution3D layer: '
' , if set, output shape must be of length 3.
' has invalid weights field. Quantized 
weights are not supported.
Convolution3D 
weights
' has invalid bias field. Quantized 
bias is not supported.
InnerProduct
Batchnorm
Batchnorm layer '
' parameters have values for both full and half precision. Parameters should either be specified in half or full precision, mixed parameters are not supported.
BatchNorm
gamma
beta
' is missing mean and variance.
mean
variance
ActivationPReLU
ActivationParametricSoftplus
Pooling
Padding type for the pooling layer '
Pooling3d
Front
Back
Bottom
Left
Right
Padding
Padding layer 
 specifies 
 padding amounts but it must either specify 2 (for x and y axes), or 0 for the default values.
 padding type is not set.
LRNLayer
Parameter 'K' for the LRN layer '
' must be positive.
Split
' of type 'Split' must have equal ranks for its outputs, but they are not equal.
Unary
Upsample
Invalid scaling factor in upsampling layer '
'. Only one of scalingFactor and fractionalScalingFactor can be set, and if set, must be of size 2. Found scalingFactor of size 
 and fractionalScalingFactor of size 
Invalid upsample layer '
'. Fractional upsample only compatible with align_corners=true or align_corners=false
' of type Upsample uses Nearest Neighbors but uses linear upsampling mode other than DEFAULT.
Bias
Bias product layer '
' has both full precision and half precision weights and/or bias fields populated
Bias layer '
' cannot be 
 dimensional. Must be 1D or 3D.
L2Normalize
Reshape
Reshape layer '
' target shape must be 3D or 4D.
Flatten
Permute
Permute layer '
' must have 4D axis parameters.
Reduce
Reduce layer: '
': unknown value for parameter 'axis'.
Reduce layer '
': input's rank is smaller than the dimensions provided in the axis parameter
ReorganizeData
Block size for layer '
' must be > 1.
Slice
Slice layer: '
Slice layer '
': input's rank is smaller than the dimension provided in the axis parameter
Stride length for the slice layer '
Slice layer 
 has an end index before the start index.
LoadConstant
output
Load constant layer '
' has both full precision and half precision weight fields populated
' must be a 3D constant.
constants
Scale
Scale layer '
' has invalid scale/bias fields.
' has invalid scale/bias fields. Field value types should match and should either be half or full precision.
The shape vector for the scale layer '
' is 
 dimensional but should be 1D or 3D.
scale
The bias vector for scale layer '
 dimensional but should be either 1D or 3D.
SimpleRecurrent
Simple recurrent layer '
' has invalid weightMatrix/recusionMatrix/Bias fields.
' has invalid weightMatrix/recusionMatrix/Bias fields. Field value types should match and should either be half or full precision.
SimpleRNN
WeightMatrix
RecursionMatrix
BiasVector
GRU layer '
' has invalid weight/recursion matrix or bias fields. Field value types should match and should be either half or full precision
update gate weight matrix
reset gate weight matrix
output gate weight matrix
update gate recursion matrix
reset gate recursion matrix
output gate recursion matrix
update gate bias vector
reset gate bias vector
output gate bias vector
UniDirectionalLSTM
Unidirectional LSTM layer:
 must provide 3 activations
Unidirectional LSTM
input gate weight matrix
forget gate weight matrix
block input gate weight matrix
input gate recursion matrix
forget gate recursion matrix
block input gate recursion matrix
input gate bias vector
forget gate bias vector
block input bias vector
input gate peep hole vector
forget gate peep hole vector
output gate peep hole vector
BiDirectionalLSTM
Bidirectional LSTM layer:
 forward lstm must provide 3 activations
 backward lstm must provide 3 activations
Bidirectional LSTM
forward input gate weight matrix
forward forget gate weight matrix
forward block input gate weight matrix
forward output gate weight matrix
forward input gate recursion matrix
forward forget gate recursion matrix
forward block input gate recursion matrix
forward output gate recursion matrix
backward input gate weight matrix
backward forget gate weight matrix
backward block input gate weight matrix
backward output gate weight matrix
backward input gate recursion matrix
backward forget gate recursion matrix
backward block input gate recursion matrix
backward output gate recursion matrix
forward input gate bias vector
forward forget gate bias vector
forward block input bias vector
forward output gate bias vector
backward input gate bias vector
backward forget gate bias vector
backward block input bias vector
backward output gate bias vector
forward input gate peephole vector
forward forget gate peephole vector
forward output gate peephole vector
backward input gate peephole vector
backward forget gate peephole vector
backward output gate peephole vector
Crop
' of type 'Crop' expects equal ranks for its inputs, but they are not equal.
cropAmounts parameter for the crop layer '
' is of length 
 but requires exactly two crop constraints (for X,Y axes).
Offset parameter for the crop layer '
 but requires exactly two offsets (for X,Y axes).
DotProduct
' of type 'DotProduct' expects equal ranks for its inputs, but they are not equal.
MeanVarianceNormalize
Embedding
EmbeddingND
SequenceRepeat
Softmax
Concat
' of type 'Concat' expects equal ranks for its inputs, but they are not equal.
Custom layer 
 has an empty 'className' field. This field is required in order for Core ML to link to the implementation for this custom class.
 has a weights parameter with multiple types filled in.  The WeightParams message should be treated as a oneof.
ResizeBilinear
Target Size in the resize bilinear layer '
' must be a vector of size 2 (i.e height, width) but is a vector of size 
CropResize
' of type 'CropResize' expects equal ranks for its inputs, but they are not equal.
Target Size in the crop resize layer '
Branch Layer '
' input's length cannot be more than 1
' requires the condition blob '
' which is not present in the network prior to this layer.
' has an empty If branch
Axes are required parameters for '
' layer.
Copy layer '
' has identical input and output names.
BatchedMatMul layer '
': given ranks of the two inputs, rank of the output is incorrect.
': has one input, in this case, output and input ranks must be equal but they are not.
': has two inputs and 'hasBias' flag is set to True.However, bias is only supported when the layer has 1 input.
': cannot use dynamic quantization with 2 inputs.
BatchedMatMul
Value of axis must be in the range [-rank(tensor), rank(tensor)) for '
Invalid size of reverse_dim for '
Target shape is required parameter for '
Scatter layer must have 3 input tensor fields filled
Input ranks of Scatter layer '
' are invalid.
Scatter layer must have 1 output tensor fields filled
Output rank of Scatter layer '
' does not match container input.
Shapes of all inputs must match for '
Value of axis must be in the range [-rank(tensor), rank(tensor)] for '
Either split_sizes or num_splits should be provided for '
Value of num_splits should match size of output names for '
Value of minval should be smaller than maxval for '
Begin IDs are required parameters for '
End IDs are required parameters for '
Strides are required parameters for '
Begin masks are required parameters for '
End masks are required parameters for '
Loop Layer '
' has an empty body network
': condition variable must be provided if condition network exists and vice versa.
': has no input, no condition network and max loop iterations is 0.
': has conditionVar named '
' which is not produced by the condition network
Loop Break Layer '
' must be inside the bodyNetwork of a loop layer.
Loop Continue Layer '
RankPreservingReshape Layer '
': input and output rank must be equal.
': input rank must be same as the length of the target shape property.
ExpandDims Layer '
': length of the 'axes' parameter cannot be 0.
': all the values in the 'axes' parameter must be unique.
': input rank plus the length of the axes parameter must equal output rank.
': axes parameter list cannot have the same value more than once.
': axes refers to a dimension that exceeds the output rank.
Squeeze Layer '
': output rank plus the length of the axes parameter must equal input rank.
': axes refers to a dimension that exceeds the input rank.
Range
LoadConstantND layer '
'can only accept shape of length 1 to 5
LoadConstantND
Value of prob should be in range [0: 1] for '
TopK
' of type 'TopK' expects equal ranks for its input and second output, but they are not equal.
ArgMax
ArgMin
Normalized shape is required parameter for '
Gamma is required parameter for '
Beta is required parameter for '
Gamma and Beta should not be quantized for '
Shape of gamma should match normalized_shape for '
Shape of beta should match normalized_shape for '
ConstantPad
In 'ConstantPad' layer '
', length of 'padAmounts' parameter is 
, an odd value, which is not allowed.
', length of 'padAmounts' cannot be zero when only 1 input is provided.
', 'padToGivenOutputSizeMode' is true, and both padding values corresponding to dimension 
 are non zero, which is invalid. Only one value can be non-zero.
Argsort
Value of 'axis' is negative for layer of type 'ArgSort' and name '
', which is not supported. It must be positive.
Value of 'axis' is 
, but it must be in the range [0,
) for layer of type 'ArgSort' and name '
Unsupported layer type (
) for layer '
' of type 
 has 
 inputs but expects exactly 
 inputs but expects at least 
 inputs but expects at most 
 outputs but expects exactly 
 outputs but expects at least 
 outputs but expects at most 
' of type '
' expects equal ranks for its input and output, but they are not equal.
input
' has incorrect 
 size 
 (expected 
' has insufficient bytes for quantized 
 with 
units.
' has invalid quantization parameters for quantized 
' has unspecified 
' has empty 
 must be positive, got 
Inner product
 layer '
' has invalid weights/bias fields.
 has incorrect weight matrix size 
' has incorrect bias vector size 
Nonlinearity type 
 has inconsistent weight parameter types.
 is not supported in this version of CoreML.
MLActivationParamsNonlinearityType_linear
MLActivationParamsNonlinearityType_ReLU
MLActivationParamsNonlinearityType_leakyReLU
MLActivationParamsNonlinearityType_thresholdedReLU
MLActivationParamsNonlinearityType_PReLU
MLActivationParamsNonlinearityType_tanh
MLActivationParamsNonlinearityType_scaledTanh
MLActivationParamsNonlinearityType_sigmoid
MLActivationParamsNonlinearityType_sigmoidHard
MLActivationParamsNonlinearityType_ELU
MLActivationParamsNonlinearityType_softsign
MLActivationParamsNonlinearityType_softplus
MLActivationParamsNonlinearityType_parametricSoftplus
Custom Padding 
 must be non-negative, got 
 cannot be non-zero (got 
) unless padding type is CUSTOM (got 
' has 
 rank 
 but expects rank exactly 
 but expects rank at least 
 but expects rank at most 
Recurrent non-linearity type 
LSTM weight parameters have inconsistent field value types. Types should match and should be either half or full precision
' has invalid weights/bias fields. Field value types should match and should either be half or full precision.
' must have rank specified for its input and output.
Model specification version field missing or corrupt.
The model supplied is of version 
, intended for a newer version of Xcode. This version of Xcode supports model version 
 or earlier.
Model specification version for an updatable model must be '
' or above.
Model did not specify a valid model-parameter type.
unable to open file for read
unable to open file for write
unable to deserialize object
unable to serialize object
Dimension size must be greater tha zero.
Feature descriptions exceeded 
". Should be one of: 
Int64 class labels must be supplied for SVM classifier.
coefficient array must be size numberOfClasses - 1 (
). Instead it is size 
Must specify sparse or dense support vectors
numberOfSupportVectoresPerClass array must be size numberOfClasses 
 instead it is size 
sum of numberOfSupportVectorsPerClass 
 must sum to total number of support vectors 
Incorrect number of coefficients: There should be 
 not 
probA and probB must be same size
Expected length of probA is number of class pairs: 
The number of coefficients must match the number of support vectors.
Gamma must be greater than or equal to zero
Degree must be greater than or equal to zero
You must specify a supported kernel type
CoreML.Specification.Identity
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Scene
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects.output
CoreML.Specification.CoreMLModels.VisionFeaturePrint.Objects
CoreML.Specification.CoreMLModels.VisionFeaturePrint
Size range is invalid (
Feature description must have a non-empty name.
Feature description 
 must specify a valid feature type.
Description of multiarray feature '
' has enumerated zero permitted sizes.
' has enumerated shapes with zero dimensions.
' has a default shape specified 
 which is not within the allowed enumerated shapes specified.
' has an invalid range for dimension 
' has a default 
-d shape but a 
-d shape range
' has a default shape that is out of the specified shape range
' has missing shape constraints.
' has an invalid shape. Element 
 has non-positive value 
. This model has version 
' has FLOAT16 dataType, which is only valid in specification version >= 
' has an invalid or unspecified dataType. It must be specified as DOUBLE, FLOAT32, FLOAT16 or INT32
' has mistmatch between dataType and the type of default optional value.
Description of dictionary feature '
' must contain a key type of either Int64 or String.
Description of image feature '
' has a default size of 
 which is not within the allowed enumerated sizes specified.
' has an invalid flexible width range. 
' has an invalid flexible height range. 
' default width 
 is not within specified flexible width range
' default height 
 is not within specified flexible height range
' has missing or non-positive width 
' has missing or non-positive height 
' has GRAYSCALE_FLOAT16 colorspace, which is only valid in specification version >= 
' has missing or invalid colorspace. It must be RGB, BGR or GRAYSCALE.
Sequence types are only valid in specification verison >= 
Description of sequence feature '
' has invalid allowed sizes. 
' has invalid or missing type. Only Int64 and String sequences are currently supported
Feature description has an unspecified or invalid type for feature '
Models must have one or more inputs.
Models must have one or more outputs.
Specification is missing regressor predictedFeatureName.
Specification is missing classifier predictedFeatureName
This model type is not supported for on-device update.
Default optional values are only allowed for neural networks.
Default value for optional inputs is supported from specification 5 (iOS 14) onwards!
At least one feature for a neural network must NOT be optional.
Features cannot be optional to this type of model.
Outputs cannot be optional.
' to the model is not present in the model description.
For this neural network classifier, the probabilities are obtained from the layer '
' which was not found in the network.
Output layer '
' is not produced by any layer of the neural network.
outputs
Interface specifies output '
' which is not produced by any layer in the neural network.
Neural Network Multi-Array input shape mapping cannot be 'RANK5_ARRAY_MAPPING' if the network contains a layer added in version 4 (iOS 13) or later. Use 'EXACT_ARRAY_MAPPING' instead.
Neural Network Multi-Array input shape mapping cannot be 'RANK5_ARRAY_MAPPING' if the image input Shape mapping is not 'RANK5_IMAGE_MAPPING'
Neural networks require at least one input.
Neural networks produce at least one output.
Neural networks require at least one layer.
Neural networks require at least one non-optional input.
inputs
__input
Input MLMultiArray to neural networks must have dimension 1 (vector) or 3 (image-like arrays).
Error determining network blob shapes: 
Input MLMultiArray to neural networks must have at least 1 dimension.
For MLMultiArray input: Rank of the flexible shape range must match the rank of the default shape.
Layer '
''s input and inputTensors have different lengths
''s input '
' is also an input to the model. However, for this tensor the rank provided in the layer description
 does not match the one provided in the model description
Inconsistent rank for the blob named '
''s output and "outputTensors" property have different lengths
''s output '
' is also an output of the model. However, for this tensor the rank provided in the layer description
' consumes an input named '
' which is not present in this network.
' produces an output named '
' which is also an output produced by the layer '
Tensor in layer '
': rank must match the length of dimValue
CoreML.Specification.OneHotEncoder
CoreML.Specification.CoreMLModels.TextClassifier.language
CoreML.Specification.CoreMLModels.TextClassifier
CoreML.Specification.MILSpec.Program.FunctionsEntry.key
CoreML.Specification.MILSpec.Program.docString
CoreML.Specification.MILSpec.Program.AttributesEntry.key
CoreML.Specification.MILSpec.Program
CoreML.Specification.MILSpec.Function.opset
CoreML.Specification.MILSpec.Function.BlockSpecializationsEntry.key
CoreML.Specification.MILSpec.Function.AttributesEntry.key
CoreML.Specification.MILSpec.Function
CoreML.Specification.MILSpec.Block.outputs
CoreML.Specification.MILSpec.Block.AttributesEntry.key
CoreML.Specification.MILSpec.Block
CoreML.Specification.MILSpec.Argument.Binding.name
CoreML.Specification.MILSpec.Argument.Binding
CoreML.Specification.MILSpec.Argument
CoreML.Specification.MILSpec.Operation.type
CoreML.Specification.MILSpec.Operation.InputsEntry.key
CoreML.Specification.MILSpec.Operation.AttributesEntry.key
CoreML.Specification.MILSpec.Operation
CoreML.Specification.MILSpec.NamedValueType.name
CoreML.Specification.MILSpec.NamedValueType
CoreML.Specification.MILSpec.ValueType
CoreML.Specification.MILSpec.TensorType.AttributesEntry.key
CoreML.Specification.MILSpec.TensorType
CoreML.Specification.MILSpec.TupleType
CoreML.Specification.MILSpec.ListType
CoreML.Specification.MILSpec.DictionaryType
CoreML.Specification.MILSpec.Dimension.ConstantDimension
CoreML.Specification.MILSpec.Dimension.UnknownDimension
CoreML.Specification.MILSpec.Dimension
CoreML.Specification.MILSpec.Value.ImmediateValue
CoreML.Specification.MILSpec.Value.BlobFileValue.fileName
CoreML.Specification.MILSpec.Value.BlobFileValue
CoreML.Specification.MILSpec.Value.docString
CoreML.Specification.MILSpec.Value
CoreML.Specification.MILSpec.TensorValue.RepeatedFloats
CoreML.Specification.MILSpec.TensorValue.RepeatedDoubles
CoreML.Specification.MILSpec.TensorValue.RepeatedInts
CoreML.Specification.MILSpec.TensorValue.RepeatedLongInts
CoreML.Specification.MILSpec.TensorValue.RepeatedBools
CoreML.Specification.MILSpec.TensorValue.RepeatedStrings.values
CoreML.Specification.MILSpec.TensorValue.RepeatedStrings
CoreML.Specification.MILSpec.TensorValue.RepeatedBytes
CoreML.Specification.MILSpec.TensorValue
CoreML.Specification.MILSpec.TupleValue
CoreML.Specification.MILSpec.ListValue
CoreML.Specification.MILSpec.DictionaryValue.KeyValuePair
CoreML.Specification.MILSpec.DictionaryValue
Convolution padding type not set
Pooling padding type not set
Reduce layer axis not set -- should have been caught in validator.
Ranges axis index is out of bounds in shapePermuteLayer.
Slice layer axis incorrect -- should be caught in validator.
Layer type not found.
Shape inference not implemented for this layer type.
CoreML6
Default Value (
) for '
' expected to be a positive value.
Non-positive value (
) in Allowed Values Set for '
' is not allowed.
Specified Default Value (
) not found in Allowed Values Set for '
Non-positive min value (
) in Allowed Value Range for '
Non-positive max value (
) out of Allowed Value Range for '
Specified minimum value (
) greater than maximum value for '
CoreML.Specification.Scaler
Weights and offsets must be the same size.
All weight coefficients must be the same size.
Invalid post evaluation transform
Invalid class encoding
The number of DoubleArrays in weights must be greater than zero
The number of DoubleArrays in weights must match number of offsets
With ReferenceClass encoding the number of DoubleArrays in weights must be one less than number of classes
When using OneVsRest encoding for only two classes, the number of DoubleArrays in weights must be one
With OneVsRest encoding the number of DoubleArrays in weights must equal the number of classes
Probit post evaluation transform is only supported for binary classification
Weight DoubleArrays must have nonzero length
Weight DoubleArrays must have the same length
Classifier declared to have Int64 class labels must provide labels.
Classifier declared to have String class labels must provide labels.
Classifier models must provide class labels.
Attempting to access unbound size_t val from RangeVal.
Dividing range 
 by 0.
Constructing invalid ShapeRange with 
Constructing invalid ShapeRange unbound minimum value.
Dividing ShapeRange 
 by negative or zero value 
Invalid setLower 
 for range: 
Invalid setUpper 
Invalid setValue 
Invalid intersection between 
 and 
Attempting to constrain an input or output feature "
" with an invalid array shape constraint.
Attempting to update feature constraint 
 with a type description which is not a multi array or image.
Invalid sequence range in blob 
Invalid batch range in blob 
Invalid channel range in blob 
Invalid height range in blob 
Invalid width range in blob 
Incorrect input shape, should be 1-dimension, of length: 
Incorrect output shape, should be 3-dimension, of size: 
Type for sound analysis preprocessing not set
Only 1 dimensional arrays input features are supported by the imputer.
Shape of imputed array value does not match shape of input array.
Imputer parameter must be set.
Type of input feature "
" is not compatible with given imputed value type.
Type of given replace value not compatible with input feature type.
CoreML.Specification.CoreMLModels.SoundAnalysisPreprocessing.Vggish
CoreML.Specification.CoreMLModels.SoundAnalysisPreprocessing
CoreML.Specification.GLMClassifier.DoubleArray
CoreML.Specification.GLMClassifier
CoreML.Specification.Imputer.imputedStringValue
CoreML.Specification.Imputer.replaceStringValue
CoreML.Specification.Imputer
CoreML.Specification.CustomModel.CustomModelParamValue.stringValue
CoreML.Specification.CustomModel.CustomModelParamValue
CoreML.Specification.CustomModel.className
CoreML.Specification.CustomModel.ParametersEntry.key
CoreML.Specification.CustomModel.description
CoreML.Specification.CustomModel
LinkedModel cannot be marked as updatable
LinkedModel.LinkType not set.
LinkedModel.linkedModelFile.linkedModeFileName.defaultValue cannot be empty.
CoreML.Specification.LinearKernel
CoreML.Specification.RBFKernel
CoreML.Specification.PolyKernel
CoreML.Specification.SigmoidKernel
CoreML.Specification.Kernel
CoreML.Specification.SparseNode
CoreML.Specification.SparseVector
CoreML.Specification.SparseSupportVectors
CoreML.Specification.DenseVector
CoreML.Specification.DenseSupportVectors
CoreML.Specification.Coefficients
CoreML.Specification.SupportVectorRegressor
CoreML.Specification.SupportVectorClassifier
CoreML.Specification.CoreMLModels.Gazetteer.language
CoreML.Specification.CoreMLModels.Gazetteer
CoreML.Specification.Normalizer
Input feature '
' was not requested by any of the input feature names (e.g. confidenceInputFeatureName).
' (as defined by confidenceInputFeatureName) to the model is not present in the model description.
' (as defined by coordinatesInputFeatureName) to the model is not present in the model description.
' was not requested by any of the output feature names (e.g. confidenceOutputFeatureName).
' (as defined by confidenceOutputFeatureName) from the model is not present in the model description.
' (as defined by coordinatesOutputFeatureName) from the model is not present in the model description.
iouThreshold must be a value between 0.0 and 1.0.
confidenceThreshold must be a non-negative value. If you do not want to eliminate any predictions based on confidence, set it to 0.0.
'confidence' and 'coordinates' must use a same element type, but 
'input confidence' is 
'output confidence' is 
'input coordinates' are 
and 'output coordinates' are 
The element data type of 'confidence' and 'coordinates' must be either MultiArray<DOUBLE> or MultiArray<FLOAT32>, but 
The element data type of 'confidence' and 'coordinates' must be MultiArray<DOUBLE> for model specification version earlier than 
, but 
To enable MultiArray<FLOAT32>, use the model specification version 
 or later.
If shape information is provided for confidence output, 2 dimensions must be specified using either shape (deprecated) or allowedShapes.
Confidence and coordinates output shapes must be consistent (must have the same size along dimension 0).
Confidence and coordinates output shapes fexibility must both be ranges
Confidence and coordinates output shapes must be consistent (must have the same range of sizes along dimension 0).
Number of classes is not consistent for class labels (
) and dimension 1 of output confidence shape (
) and dimension 1 of output confidence shape range
CoreML.Specification.StringToInt64Map.MapEntry.key
CoreML.Specification.StringToInt64Map
CoreML.Specification.Int64ToStringMap.MapEntry.value
CoreML.Specification.Int64ToStringMap
CoreML.Specification.StringToDoubleMap.MapEntry.key
CoreML.Specification.StringToDoubleMap
CoreML.Specification.Int64ToDoubleMap
CoreML.Specification.StringVector.vector
CoreML.Specification.StringVector
CoreML.Specification.Int64Vector
CoreML.Specification.FloatVector
CoreML.Specification.DoubleVector
CoreML.Specification.Int64Range
CoreML.Specification.Int64Set
CoreML.Specification.DoubleRange
Pipeline must contain one or more models.
Pipeline: the input '
' of model '
' does not present in pipeline input or previous model.
' does not match the type previously specified by the pipeline input or the output of a previous model.
 For the second case, make sure the input and previous model's output has the matching name and shapes.
Pipeline output '
' not present in pipeline input or a contained model.
Type of pipeline output '
' does not match type produced in pipeline input.
Only the last model in the pipeline can be updatable. Model at position '
' is marked as updatable.
Last model in an updatable pipeline model should be marked as updatable.
Found an updatable model at '
' inside a non-updatable pipeline.
The number of pipeline model names '
' doesn't match the number of models '
Pipeline model name '
' at index '
 has already been used for previous models
CoreML.Specification.BayesianProbitRegressor.Gaussian
CoreML.Specification.BayesianProbitRegressor.FeatureValueWeight
CoreML.Specification.BayesianProbitRegressor.FeatureWeight
CoreML.Specification.BayesianProbitRegressor.regressionInputFeatureName
CoreML.Specification.BayesianProbitRegressor.optimismInputFeatureName
CoreML.Specification.BayesianProbitRegressor.samplingScaleInputFeatureName
CoreML.Specification.BayesianProbitRegressor.samplingTruncationInputFeatureName
CoreML.Specification.BayesianProbitRegressor.meanOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.varianceOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.pessimisticProbabilityOutputFeatureName
CoreML.Specification.BayesianProbitRegressor.sampledProbabilityOutputFeatureName
CoreML.Specification.BayesianProbitRegressor
Version for scene is invalid
Version for objects is invalid
Two outputs for objects need to be provided
Model description declares an output: 
 but it is not declared in Vision Feature Print output
Type for vision feature print not set
CoreML.Specification.CoreMLModels.WordEmbedding.language
CoreML.Specification.CoreMLModels.WordEmbedding
CoreML.Specification.Int64Parameter
CoreML.Specification.DoubleParameter
CoreML.Specification.StringParameter.defaultValue
CoreML.Specification.StringParameter
CoreML.Specification.BoolParameter
Model is not a tree ensemble.
Given output dimension equals 0.
Tree Node with TreeID=
and NodeID=
 duplicated in specification.
False child and parent have same ID (TreeID=
, NodeID=
In TreeID=
, false child of NodeID=
 is already the child of node NodeID=
True child and parent have same ID (TreeID=
, true child of NodeID=
Tree TreeID=
 has multiple root nodes: 
NodeID=
Internal error: null child node; likely specification error.
Node detected that are not connected to any single root node. Note: 
(TreeID=
Dimension of default value array (
) does not match specified output dimension (
Specified output dimension (
) does not match the given number of classes (
Error(s) in tree structure: 
FATAL: 
  FATAL: maximum number of errors reached; aborting processing.
Errors encountered during processing tree model:
Branch mode hit bad value -- this is confusing; error in validator?
Leaf Node (TreeID=
) has no evaluation value(s) specified.
) specifies evaluation value applied to dimension 
; which is out of range. Dimension must be less than 
) specifies multipule evaluation values applied to dimension 
 and NodeID=
 referenced but not declared in specification.
Exactly one input array column must be specified.
If output type is Double in interface, exactly one extraction index must be specified.
CoreML.Specification.NonMaximumSuppression.PickTop
CoreML.Specification.NonMaximumSuppression.confidenceInputFeatureName
CoreML.Specification.NonMaximumSuppression.coordinatesInputFeatureName
CoreML.Specification.NonMaximumSuppression.iouThresholdInputFeatureName
CoreML.Specification.NonMaximumSuppression.confidenceThresholdInputFeatureName
CoreML.Specification.NonMaximumSuppression.confidenceOutputFeatureName
CoreML.Specification.NonMaximumSuppression.coordinatesOutputFeatureName
CoreML.Specification.NonMaximumSuppression
OneHotEncoder parameter incorrect type
More model output features than the output features of the word tagger model.
Output feature '
' was not required by the output features of the word tagger model.
Expected feature '
' (defined by tokenTagsOutputFeatureName) to the model is not present in the model description.
". Should be: 
Model output tags not set. Must have at least one tag
Model revision number not set. Must be >= 1
Only integer item ids or string item ids can be specified in the same model.
List of integer item ids specified must be large enough to index all item ids specified.  The largest item index is 
, whereas there are  only 
 item ids given.
List of integer item ids specified must be unique; list contains duplicates.
List of string item ids specified must be large enough to index all item ids specified.  The largest item index is 
List of string item ids specified must be unique; list contains duplicates.
Name of column for item input data not specified.
No output columns specified.
NormalizerValidator normLx invalid
CoreML.Specification.ItemSimilarityRecommender.ConnectedItem
CoreML.Specification.ItemSimilarityRecommender.SimilarItems
CoreML.Specification.ItemSimilarityRecommender.itemInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.numRecommendationsInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.itemRestrictionInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.itemExclusionInputFeatureName
CoreML.Specification.ItemSimilarityRecommender.recommendedItemListOutputFeatureName
CoreML.Specification.ItemSimilarityRecommender.recommendedItemScoreOutputFeatureName
CoreML.Specification.ItemSimilarityRecommender
Input type Int64 must output to Int64 or Double.
Type of input feature does not match the output type feature.
Only 1 dimensional arrays input features are supported by the scaler.
Shape of output array does not match shape of input array.
For input type array, specified shift values must be empty, a scalar, or a vector of the matching length.
For input type array, specified scale values must be empty, a scalar, or a vector of the matching length.
For a scalar imput type, specified shift value must be empty or a scalar.
For input type array, specified scale values must be empty or a scalar.
CoreML.Specification.FeatureVectorizer.InputColumn.inputColumn
CoreML.Specification.FeatureVectorizer.InputColumn
CoreML.Specification.FeatureVectorizer
DictVectorizerValidator parameter not set
CoreML.Specification.CoreMLModels.WordTagger.language
CoreML.Specification.CoreMLModels.WordTagger.tokensOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenTagsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenLocationsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger.tokenLengthsOutputFeatureName
CoreML.Specification.CoreMLModels.WordTagger
CoreML.Specification.TreeEnsembleParameters.TreeNode.EvaluationInfo
CoreML.Specification.TreeEnsembleParameters.TreeNode
CoreML.Specification.TreeEnsembleParameters
CoreML.Specification.TreeEnsembleClassifier
CoreML.Specification.TreeEnsembleRegressor
not an error
validator error: 
Double
Int64
String
Invalid
Int32
Float32
Float16
Grayscale
Grayscale16Half
CoreML.Specification.DictVectorizer
CoreML.Specification.NeuralNetwork
CoreML.Specification.NeuralNetworkImageScaler
CoreML.Specification.NeuralNetworkMeanImage
CoreML.Specification.NeuralNetworkPreprocessing.featureName
CoreML.Specification.NeuralNetworkPreprocessing
CoreML.Specification.ActivationReLU
CoreML.Specification.ActivationLeakyReLU
CoreML.Specification.ActivationTanh
CoreML.Specification.ActivationScaledTanh
CoreML.Specification.ActivationSigmoid
CoreML.Specification.ActivationLinear
CoreML.Specification.ActivationSigmoidHard
CoreML.Specification.ActivationPReLU
CoreML.Specification.ActivationELU
CoreML.Specification.ActivationThresholdedReLU
CoreML.Specification.ActivationSoftsign
CoreML.Specification.ActivationSoftplus
CoreML.Specification.ActivationParametricSoftplus
CoreML.Specification.ActivationParams
CoreML.Specification.Tensor
CoreML.Specification.NeuralNetworkLayer.name
CoreML.Specification.NeuralNetworkLayer.input
CoreML.Specification.NeuralNetworkLayer.output
CoreML.Specification.NeuralNetworkLayer
CoreML.Specification.BranchLayerParams
CoreML.Specification.LoopLayerParams.conditionVar
CoreML.Specification.LoopLayerParams
CoreML.Specification.LoopBreakLayerParams
CoreML.Specification.LoopContinueLayerParams
CoreML.Specification.CopyLayerParams
CoreML.Specification.GreaterThanLayerParams
CoreML.Specification.GreaterEqualLayerParams
CoreML.Specification.LessThanLayerParams
CoreML.Specification.LessEqualLayerParams
CoreML.Specification.EqualLayerParams
CoreML.Specification.NotEqualLayerParams
CoreML.Specification.LogicalAndLayerParams
CoreML.Specification.LogicalOrLayerParams
CoreML.Specification.LogicalXorLayerParams
CoreML.Specification.LogicalNotLayerParams
CoreML.Specification.BorderAmounts.EdgeSizes
CoreML.Specification.BorderAmounts
CoreML.Specification.ValidPadding
CoreML.Specification.SamePadding
CoreML.Specification.SamplingMode
CoreML.Specification.BoxCoordinatesMode
CoreML.Specification.WeightParams
CoreML.Specification.QuantizationParams
CoreML.Specification.LinearQuantizationParams
CoreML.Specification.LookUpTableQuantizationParams
CoreML.Specification.ConvolutionLayerParams
CoreML.Specification.Convolution3DLayerParams
CoreML.Specification.InnerProductLayerParams
CoreML.Specification.EmbeddingLayerParams
CoreML.Specification.EmbeddingNDLayerParams
CoreML.Specification.BatchnormLayerParams
CoreML.Specification.PoolingLayerParams.ValidCompletePadding
CoreML.Specification.PoolingLayerParams
CoreML.Specification.Pooling3DLayerParams
CoreML.Specification.GlobalPooling3DLayerParams
CoreML.Specification.PaddingLayerParams.PaddingConstant
CoreML.Specification.PaddingLayerParams.PaddingReflection
CoreML.Specification.PaddingLayerParams.PaddingReplication
CoreML.Specification.PaddingLayerParams
CoreML.Specification.ConcatLayerParams
CoreML.Specification.LRNLayerParams
CoreML.Specification.SoftmaxLayerParams
CoreML.Specification.SplitLayerParams
CoreML.Specification.AddLayerParams
CoreML.Specification.MultiplyLayerParams
CoreML.Specification.UnaryFunctionLayerParams
CoreML.Specification.UpsampleLayerParams
CoreML.Specification.ResizeBilinearLayerParams
CoreML.Specification.CropResizeLayerParams
CoreML.Specification.BiasLayerParams
CoreML.Specification.ScaleLayerParams
CoreML.Specification.LoadConstantLayerParams
CoreML.Specification.L2NormalizeLayerParams
CoreML.Specification.FlattenLayerParams
CoreML.Specification.ReshapeLayerParams
CoreML.Specification.PermuteLayerParams
CoreML.Specification.ReorganizeDataLayerParams
CoreML.Specification.SliceLayerParams
CoreML.Specification.ReduceLayerParams
CoreML.Specification.CropLayerParams
CoreML.Specification.AverageLayerParams
CoreML.Specification.MaxLayerParams
CoreML.Specification.MinLayerParams
CoreML.Specification.DotProductLayerParams
CoreML.Specification.MeanVarianceNormalizeLayerParams
CoreML.Specification.SequenceRepeatLayerParams
CoreML.Specification.SimpleRecurrentLayerParams
CoreML.Specification.GRULayerParams
CoreML.Specification.LSTMParams
CoreML.Specification.LSTMWeightParams
CoreML.Specification.UniDirectionalLSTMLayerParams
CoreML.Specification.BiDirectionalLSTMLayerParams
CoreML.Specification.CustomLayerParams.CustomLayerParamValue.stringValue
CoreML.Specification.CustomLayerParams.CustomLayerParamValue
CoreML.Specification.CustomLayerParams.className
CoreML.Specification.CustomLayerParams.ParametersEntry.key
CoreML.Specification.CustomLayerParams.description
CoreML.Specification.CustomLayerParams
CoreML.Specification.TransposeLayerParams
CoreML.Specification.BatchedMatMulLayerParams
CoreML.Specification.ConcatNDLayerParams
CoreML.Specification.SoftmaxNDLayerParams
CoreML.Specification.ReverseLayerParams
CoreML.Specification.ReverseSeqLayerParams
CoreML.Specification.LoadConstantNDLayerParams
CoreML.Specification.FillLikeLayerParams
CoreML.Specification.FillStaticLayerParams
CoreML.Specification.FillDynamicLayerParams
CoreML.Specification.WhereBroadcastableLayerParams
CoreML.Specification.SinLayerParams
CoreML.Specification.CosLayerParams
CoreML.Specification.TanLayerParams
CoreML.Specification.AsinLayerParams
CoreML.Specification.AcosLayerParams
CoreML.Specification.AtanLayerParams
CoreML.Specification.SinhLayerParams
CoreML.Specification.CoshLayerParams
CoreML.Specification.TanhLayerParams
CoreML.Specification.AsinhLayerParams
CoreML.Specification.AcoshLayerParams
CoreML.Specification.AtanhLayerParams
CoreML.Specification.PowBroadcastableLayerParams
CoreML.Specification.Exp2LayerParams
CoreML.Specification.WhereNonZeroLayerParams
CoreML.Specification.MatrixBandPartLayerParams
CoreML.Specification.UpperTriangularLayerParams
CoreML.Specification.LowerTriangularLayerParams
CoreML.Specification.BroadcastToLikeLayerParams
CoreML.Specification.BroadcastToStaticLayerParams
CoreML.Specification.BroadcastToDynamicLayerParams
CoreML.Specification.AddBroadcastableLayerParams
CoreML.Specification.MaxBroadcastableLayerParams
CoreML.Specification.MinBroadcastableLayerParams
CoreML.Specification.ModBroadcastableLayerParams
CoreML.Specification.FloorDivBroadcastableLayerParams
CoreML.Specification.SubtractBroadcastableLayerParams
CoreML.Specification.MultiplyBroadcastableLayerParams
CoreML.Specification.DivideBroadcastableLayerParams
CoreML.Specification.GatherLayerParams
CoreML.Specification.ScatterLayerParams
CoreML.Specification.GatherNDLayerParams
CoreML.Specification.ScatterNDLayerParams
CoreML.Specification.GatherAlongAxisLayerParams
CoreML.Specification.ScatterAlongAxisLayerParams
CoreML.Specification.StackLayerParams
CoreML.Specification.RankPreservingReshapeLayerParams
CoreML.Specification.ConstantPaddingLayerParams
CoreML.Specification.RandomNormalLikeLayerParams
CoreML.Specification.RandomNormalStaticLayerParams
CoreML.Specification.RandomNormalDynamicLayerParams
CoreML.Specification.RandomUniformLikeLayerParams
CoreML.Specification.RandomUniformStaticLayerParams
CoreML.Specification.RandomUniformDynamicLayerParams
CoreML.Specification.RandomBernoulliLikeLayerParams
CoreML.Specification.RandomBernoulliStaticLayerParams
CoreML.Specification.RandomBernoulliDynamicLayerParams
CoreML.Specification.CategoricalDistributionLayerParams
CoreML.Specification.ReduceL1LayerParams
CoreML.Specification.ReduceL2LayerParams
CoreML.Specification.ReduceMaxLayerParams
CoreML.Specification.ReduceMinLayerParams
CoreML.Specification.ReduceSumLayerParams
CoreML.Specification.ReduceProdLayerParams
CoreML.Specification.ReduceMeanLayerParams
CoreML.Specification.ReduceLogSumLayerParams
CoreML.Specification.ReduceSumSquareLayerParams
CoreML.Specification.ReduceLogSumExpLayerParams
CoreML.Specification.ExpandDimsLayerParams
CoreML.Specification.FlattenTo2DLayerParams
CoreML.Specification.ReshapeStaticLayerParams
CoreML.Specification.ReshapeLikeLayerParams
CoreML.Specification.ReshapeDynamicLayerParams
CoreML.Specification.SqueezeLayerParams
CoreML.Specification.TopKLayerParams
CoreML.Specification.ArgMaxLayerParams
CoreML.Specification.ArgMinLayerParams
CoreML.Specification.SplitNDLayerParams
CoreML.Specification.CeilLayerParams
CoreML.Specification.RoundLayerParams
CoreML.Specification.FloorLayerParams
CoreML.Specification.SignLayerParams
CoreML.Specification.ClipLayerParams
CoreML.Specification.SliceStaticLayerParams
CoreML.Specification.SliceDynamicLayerParams
CoreML.Specification.TileLayerParams
CoreML.Specification.GetShapeLayerParams
CoreML.Specification.ErfLayerParams
CoreML.Specification.GeluLayerParams
CoreML.Specification.RangeStaticLayerParams
CoreML.Specification.RangeDynamicLayerParams
CoreML.Specification.SlidingWindowsLayerParams
CoreML.Specification.LayerNormalizationLayerParams
CoreML.Specification.NonMaximumSuppressionLayerParams
CoreML.Specification.ClampedReLULayerParams
CoreML.Specification.ArgSortLayerParams
CoreML.Specification.SliceBySizeLayerParams
CoreML.Specification.NeuralNetworkClassifier.labelProbabilityLayerName
CoreML.Specification.NeuralNetworkClassifier
CoreML.Specification.OneHotLayerParams
CoreML.Specification.CumSumLayerParams
CoreML.Specification.NeuralNetworkRegressor
CoreML.Specification.NetworkUpdateParameters
CoreML.Specification.LossLayer.name
CoreML.Specification.LossLayer
CoreML.Specification.CategoricalCrossEntropyLossLayer.input
CoreML.Specification.CategoricalCrossEntropyLossLayer.target
CoreML.Specification.CategoricalCrossEntropyLossLayer
CoreML.Specification.MeanSquaredErrorLossLayer.input
CoreML.Specification.MeanSquaredErrorLossLayer.target
CoreML.Specification.MeanSquaredErrorLossLayer
CoreML.Specification.Optimizer
CoreML.Specification.SGDOptimizer
CoreML.Specification.AdamOptimizer
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/map_entry_lite.h
CHECK failed: default_instance_ != NULL: 
CoreML.Specification.KNearestNeighborsClassifier.defaultStringLabel
CoreML.Specification.KNearestNeighborsClassifier
CoreML.Specification.NearestNeighborsIndex
CoreML.Specification.UniformWeighting
CoreML.Specification.InverseDistanceWeighting
CoreML.Specification.LinearIndex
CoreML.Specification.SingleKdTreeIndex
CoreML.Specification.SquaredEuclideanDistance
numberOfNeighbors
KNearestNeighborsClassifier requires a weighting scheme to be set.
KNearestNeighborsClassifier's class label and default class label have different types.
KNearestNeighborsClassifier should specify default class labels when class labels are not specified.
KNearestNeighborsClassifier has no data points.
Unexpected number of labels "
" for the given number of examples: "
Unexpected length "
" given the provided number of dimensions "
KNearestNeighborsClassifier has no index type specified.
KNearestNeighborsClassifier requires leaf size to be a positive integer.
KNearestNeighborsClassifier requires a distance function to be set.
Classifier declared with Int64 class labels must provide exclusively Int64 class labels.
Classifier declared with String class labels must provide exclusively String class labels.
CoreML.Specification.LinkedModel
CoreML.Specification.LinkedModelFile
ValueOnUnknown set to string value while mapping produces int64.
ValueOnUnknown set to Int64 value while mapping produces string.
Mapping not set.
Input sequence type does not match input type 
of categorical mapping.
Output of a sequence categorical mapping must be a sequence
Output sequence type does not match input type 
Version for sound is invalid
Type for audio feature print not set
CoreML.Specification.ArrayFeatureExtractor
CoreML.Specification.GLMRegressor.DoubleArray
CoreML.Specification.GLMRegressor
CoreML.Specification.Int64FeatureType
CoreML.Specification.DoubleFeatureType
CoreML.Specification.StringFeatureType
CoreML.Specification.SizeRange
CoreML.Specification.ImageFeatureType.ImageSize
CoreML.Specification.ImageFeatureType.EnumeratedImageSizes
CoreML.Specification.ImageFeatureType.ImageSizeRange
CoreML.Specification.ImageFeatureType
CoreML.Specification.ArrayFeatureType.Shape
CoreML.Specification.ArrayFeatureType.EnumeratedShapes
CoreML.Specification.ArrayFeatureType.ShapeRange
CoreML.Specification.ArrayFeatureType
CoreML.Specification.DictionaryFeatureType
CoreML.Specification.SequenceFeatureType
CoreML.Specification.FeatureType
Model revision number missing or invalid. Must be >= 2
Model output class label not set. Must have at least one class label
Model parameter data not set
, nodeID=
Setup routine called multiple times for treeId=
Unsupported type "
" for feature "
Should be of: 
 with data type of: 
Unsupported array type "
Unsupported array rank 
 should be in range [
MLFeatureTypeType_int64Type
MLFeatureTypeType_doubleType
MLFeatureTypeType_stringType
MLFeatureTypeType_imageType
MLFeatureTypeType_multiArrayType
MLFeatureTypeType_dictionaryType
MLFeatureTypeType_sequenceType
INVALID
MLArrayDataTypeFLOAT32
MLArrayDataTypeDOUBLE
MLArrayDataTypeINT32
MLArrayDataTypeFLOAT16
CustomModel must have non-empty className.
CustomModel.parameters must have non-empty string keys.
CustomModel.parameters['
'] does not have a set value
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/arena.cc
CHECK failed: (n) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/stubs/common.cc
INFO
WARNING
ERROR
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
parsing
serializing
 '%s'
String field
 contains invalid 
UTF-8 data when 
 a protocol 
buffer. Use the 'bytes' type if you intend to send raw 
bytes. 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
 BackUp() can only be called after Next().
CHECK failed: (count) <= (buffer_used_): 
 Can't back up over more bytes than were returned by the last call to Next().
 Parameter to BackUp() can't be negative.
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/coremltools/deps/protobuf/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
Exceeded maximum protobuf size of 2GB: 
parse
Can't 
 message of type "
" because it is missing required fields: 
CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): 
 was modified concurrently during serialization.
CHECK failed: (bytes_produced_by_serialization) == (byte_size_before_serialization): 
Byte size calculation and serialization were inconsistent.  This may indicate a bug in protocol buffers or it may be caused by concurrent modification of 
This shouldn't be called if all the sizes are equal.
%@: unable to initialize client due to soft-link failure
%@: namespace (%@) registration failed. %@
%@: download completion (%@): %d
%@: namespace (%@) download failed. %@
%@: namespace (%@) download timed out.
%@: unable to initialize download options due to soft-link failure
%@: failed to deregister namespace (%@). %@
%@: namespace (%@) updated
%@: unexpected update notification for namespace (%@)
%@: experimentId unexpectedly not returned
%@: set deployment id: %@
%@: missing factorLevel information: %@
%@: set %lu model entries
%@: unable to extract team identifier for the client. error:%@
Task must be a MLBackgroundPredictionTask or MLBackgroundModelUpdateTask.
Unable to archive task %@: %@
Failed to get tensor descriptor.ESRT: %s (%d)
The default initializer of MLMultiArray will be removed soon. Please don't use.
dataType %zd is not supported.
Failed to unarchive dataPointer.
shape's dimensions is zero.
shape's dimensions (%tu) is different from strides' dimensions (%tu).
dataPointer should be a buffer of size %zu but the unarchived buffer has size of %zu.
Unexpected error while calculating the expected buffer size: %s.
CVPixelBufferCreate failed with error code: %d
copyIntoMultiArray failed decoding MLMultiArray backed by a CVPixelBuffer. Code: %ld
Invalid dataType decoding MLMultiArray backed by a CVPixelBuffer. %@
Failed to allocate MLMultiArray. error: %s
shape is nil or empty.
scalars must be a non-empty array of NSNumbers.
MLMultiArray of shape: %@ should have %zu element(s), but the `scalars` argument has %td element(s).
Failed to lock pixel buffer with error: %d
Setting optimize parameter to use half precision
Failed to create CVPixelBuffer because CVPixelBufferPoolCreatePixelBuffer returned %d.
Faield to create a CVPixelBufferPool object for converting input pixel format type because CVPixelBufferPoolCreate returned %d.
Failed to initialize VTPixelTransferSession with error %i.
Failed to transfer a pixel buffer (IOSurface-backed: %s, format: %c%c%c%c) to destination pixel buffer [IOSurface-backed: %s: format: %c%c%c%c] with error %i.
The output backing for feature %@ uses %s, which is not MLMultiArray. It will fail when the inference engine populates the backing with the prediction.
The output backing for feature %@ must be CVPixelBuffer, but it is not. It will fail when the inference engine populates the backing with the prediction.
Finding model in: %s
Adding in-memory network to plan
File: %s not found.
espresso_context_set_int_option for ANE|CPU returned status = %d
Plan created, now adding network
Unable to set Espresso tracing name due to error: %d
Input feature %s required but not passed to neural network.
Unsupported input pixel format type `%c%c%c%c`.
Invalid multi-array data type: %08x.
Unsupported input feature type: %@
Unable to bind pixel buffer directly to the feature named %@ due to error: %d
Failed to lock CVPixelBuffer when binding input image with error: %d
Unexpected pixel format type %c%c%c%c
Failed to bind image through vImage with error: %d
Failed to bind the input buffer %@: %d
Espresso doesn't report the output shape; we cannot verify the output backing's shape. Error: %d
Failed to set shape of rank %zu to Espresso Buffer. Error: %d
The output backing MLMultiArray's shape (shape.count = %zu) doesn't match to Espresso's output shape (shape.count = %zu) even after squeezed. This is most likely a framework programming error.
Output backing for %@ is not compatible with the model's output feature description.
Output feature %@ doesn't have a description for the MultiArray constraints.
Output feature %@ doesn't have a description for the image constraints.
%@ image output feature must use a pixel buffer of kCVPixelFormatType_32BGRA as the output backing, but kCVPixelFormatType_32ARGB pixel buffer was specified.
Output backings cannot be used for a dynamic output feature: %@
Failed to directly bind output CVPixelBuffer for output feature: %@, with espresso error: %i. Continuing with non-direct output binding.
Forced automatic output backings was requested but we couldn't bind the fabricate output buffer for feature: %@
Error binding output buffer %s: %d
Failure verifying inputs.
Failure in resetSizes.
Error checking if an output blob is dynamic or not, %s: %d
Failed to create a pixel buffer for an automatic backing multi-array with shape %@
espresso_network_query_blob_shape couldn't get the output shape for feature: %s to fabricate the output backing buffer (err: %d). This is not expected but we go on without output backing.
espresso_buffer_pack_tensor_shape failed for feature: %s to fabricate the output backing buffer (err: %d). This is not expected but we go on without output backing.
espresso_network_query_blob_shape returned rank != 4 for image output. Unknown how to handle an image with rank: %lu, proceeding without output backing.
Output image feature uses unsupported color space (%tu). This is not expected but we go on without output backing.
Failed to create automatic backing pixel buffer for feature %@
Forced automatic output backings was requested but we couldn't fabricate the output buffer for feature: %@
Failure in -bindInputFeatures:bufferIndex:allocatedImageData:error:.
Failure in -updateDynamicOutputBlobIndicatorCacheAndReturnError:.
Failure in -completeOutputBackings:error:.
Failure in -bindOutputBuffers:outputBackings:error:.
Failure in -executePlan:error:.
Failure in binding outputs after calling execute sync.
Error computing NN outputs %d
Error computing NN outputs, caught unknown exception.
Runtime error in NN execution.
Error in computing user-provided custom layer during neural network evaluation.
Failure in binding dynamic outputs.
WARNING: The computed output shape does not match any output shape allowed in the model's description. Please update the model description.
Model description's MLMultiArrayConstraint states unknown data type (%ld), which should never happen.
MLNeuralNetworkEngine doesn't support MLImagePixelType %tu yet.
Failed to build clean before reshape.
Failure dynamically resizing for sequence length
Error in computing user-provided custom layer output shapes during neural network construction.
Failure dynamically resizing for sequence length.
Empty input feature dictionary passed to resetSizes.
Incorrect input number of dimensions %lul (must be 1, 3, or 5 dimensions.
Incorrect input number of dimensions %lul (must be 1 or greater)
Cannot evaluate a batch of size %d on GPU, which is larger than maximum of %d.
Cannot evaluate a sequence of length %d, which is longer than maximum of %d for bidirectional models.
Failure setting up to dynamically allocate for sequence size.
Error in passing image pre-processing parameters for %s to network.
Error in declaring input %d.
inputLayer: %s
Error in declaring output: %d.
outputLayer: %s
Error plan build: %d.
Hardware fall back after plan build failure.
Failure in resetSizes in batch computation.
Failure verifying input %@ in batch computation.
Failure in bindInputsAndOutputs in batch computation.
This model is not suitable for faster batch prediction, so it is falling back on a for-loop-based approach.
Called dumpTestVectors but configuration didn't specify enableTestVectorMode.
Profiler: MLNeuralNetworkEngine::executionSchedule
model-name:%slayer-name:%splatform:%s
Model Layer Info
Profiler: MLNeuralNetworkEngine::executionSchedule %lu layers
Model-signpost-id:%lluModel-name:%sModel-address:%lluEspresso-network-id:%llu
MLModel_Net_Discover
Error in adding network %d.
Failed to get shape from the tensor description. E5RT: %s (%d)
Failed to get strides from the tensor description. E5RT: %s (%d)
Failed to get data type of the tensor. E5RT: %s (%d)
Failed to get component size. E5RT: %s (%d)
Failed to get component data type. E5RT: %s (%d)
E5 tensor with componentSize = %d and componentDataType = %d is not supported.
%s thrown on construction
Error creating Core ML custom layer implementation from factory for layer "%s".
Core ML custom Layer implementation '%s' does not conform to the MLCustomLayer protocol.
Error getting Core ML custom layer output shapes for layer "%s".
Evaluation on Core ML custom layer "%s" called before the layer is constructed.
Error evaluating Core ML custom layer "%s" on CPU.
Core ML custom Layer implementation '%s' does not conform to the MLCustomLayer protocol'
Error initializing Core ML custom layer implementation with parameter dictionary for layer "%s".
Error setting weights in Core ML custom layer "%s".
Error evaluating Core ML custom layer "%s" on GPU.
Key blob is nil
Key Identifier is nil
Failed to persist Key Blob
MLModelAsset: load has already been run successfully.
MLModelAsset: load failed with error %@
MLModelAsset: load failed.
MLModelAsset: modelWithError: load failed with error %@
MLModelAsset: classifierWithError: load failed.
MLModelAsset: regressorWithError: load failed.
Failed to fetch Espresso Nets for compiled models at %@ with error %@
Failed to check cached ANE binary for compiled models at %@ with error %@
Failed to purge cached ANE binary for compiled models at %@ with error: %@
Model-name:%s
MLModel_Compile
The program argument to MLProgramTrainer is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
The program has no train function.
.inferenceModel property is not implemented yet. See rdar://81339842.
The trainable weights should be Float32, but it is %@.
The copyCurrentTrainingDelta failed to extract initial weights.
%@: modelPathStr=%@
%@: sandbox_extension_issue_file() returned NULL. path=%@
%@: sandboxExtensionToken=%@
Entered interruptionHandler!
Entered invalidationHandler!
Could not create connection to %@ : error=%@
Could not create secure model via XPC: error=%@
Could not predict from secure model via XPC: error=%@
Could not batch predict from secure model via XPC: error=%@
Could not obtain parameterValueForKey from secure model via XPC: error=%@
Incorrect number of classes given (TreeEnsembleClassifier).
Updating encrypted model %@ is not supported.
Model-name:%sParent-model-name:%s
Model-name:%sParent-model-name:%sModel-id:%llu
MLModel_Load
%@ class has successfully loaded the model at %s.
%@ class was unable to load the model at %s with error: %@; The model loader is going to use another class.
The program (%@) has no init function, which means all the functions are stateless. Do not try to create a context on such a program.
The provided input(s): [%@] does not exist in the %@ function.
The provided input(s) missing argument(s): [%@] for the %@ function.
This pipeline contains multiple sub-models with class labels. As a result, the classLabel property of the pipeline instance will not be populated.
Profiler: MLPipeline::executionSchedule %lu networks
Profiler: [schedule] Model in pipeline does not have a schedule
Failed to allocate MultiArrayBuffer with shape %s due to integer overflow
Failed to create URL from base directory %@ and the unique string %@
Failed to create a temporary directory at: %@. Error: %@
Failed to delete the temporary directory: %@. Error: %@
Failed to convert string %s to integer with exception message: %s. Fellback to 0.
Operation not supported on this platform.
Could not create decrypt session for %@ : error=%@
MLE5DirectMode has invalid value: %d
e5rt_io_port_is_tensor failed. E5RT: %s (%d)
e5rt_io_port_is_surface failed. E5RT: %s (%d)
The combination of port trait %@ and feature trait %@ is not supported.
The combination of port trait %@, feature trait %@, and direct bind mode %@ is not supported.
MultiArray shape %@ doesn't match the port's expected shape %@.
Failed to get width from E5 surface descriptor. E5RT: %s (%d)
Pixel buffer frame size %zu x %zu doesn't match the port's expected image size %zu x %zu.
Failed to get number of planes from E5 surface descriptor. E5RT: %s (%d)
The inference engine expects multi-planer format (plane count = %zu). CoreML doesn't support such models yet.
Failed to get buffer object's base pointer. E5RT: %s (%d)
Failed to create MLMultiArray: %@.
Failed to bind the input feature value.ESRT: %s (%d)
The port trait %@ is not supported.
The combination of port trait %@ and feature type %@ is not supported.
The combination of port trait %@, feature type %@, and direct bind mode %@ is not supported.
Failed to bind the output buffer object.ESRT: %s (%d)
Failed to bind the output surface object.ESRT: %s (%d)
MLE5Engine doesn't support MLImagePixelType %tu yet.
Failed to get E5 tensor descriptor. E5RT: %s (%d)
The port's shape is %@, which doesn't have enough dimensions to map width and height.
Failed to get E5 surface descriptor. E5RT: %s (%d)
Failed to allocate E5 buffer object. E5RT: %s (%d)
Failed to create E5 buffer object from IOSurface. E5RT: %s (%d)
Failed to create E5 surface object from surface descriptor. E5RT: %s (%d)
Explicit output backing is not implemented yet for the E5 engine
Fail to clean up path=%@, error=%@
Failed to list all output files with destURL=%@, error=%@
Failed to encrypt %@ with error=%@
Failed to store encryption information in compiled model with error=%@
Failed to encrypt file at URL: %@, to file at URL: %@
Failed to copy file from %@ to %@
Failed to remove file at URL: %@
Failed to create SC_Info at URL: %@
Failed to write SINF to URL: %@
Failed to write encryption info metadata.
Failed to get the home directory when checking model path.
Couldn't create os_log_t coreChannel
Unable to classify the input because the model description doesn't have predictedFeatureName property.
Unable to classify the input because the model description doesn't have class labels.
There must be at least one class to return.
MLMultiArray for class probabilities must be Float64 or Float32.
There is no output feature named %@.
Output feature named %@ is supposed to be a MLMultiArray representing class probabilities but it is %@.
Class probability feature named %@ has %tu classes, but there are %zd class labels.
Class probability feature named %@ must be a MLMultiArray of Float32 or Float64.
Class probability feature named %@ must be a contiguous MLMultiArray.
Unable to regress the input because the model description doesn't have predictedFeatureName property.
The predicted feature value for the regressor model must be a multi array but it was %@. This error should have been caught by the validator.
nil value for URL
Model-signpost-id:%lluModel-name:%sModel-address:%llu
MLModel_Generic_Discover
CoreMLModelSecurity function fetchKey completed
Fetching decryption key from server failed. Operation failed with error code %ld (%s)
Fetching decryption key from server failed. Key server responded back with error: %s
Fetching decryption key from server failed. Key response from server is not in the expected format.
Fetching decryption key from server failed: response with neither hasError nor hasSuccess.
Fetching decryption key from server timed out.
Creating a backup of .net file at location %@
The program argument to MLProgramEvaluator is not conforming to some internal requirements. Do not implement MLProgram protocol by yourself. Use the one returned by MLModel's .program property.
.model property is not implemented yet. See rdar://86160890.
A Core ML custom neural network layer requires an implementation named '%s' which was not found in the global namespace.
A Core ML custom neural network layer implementation class named '%s' does not conform to the MLCustomLayer protocol.
Failed to create a stream. E5RT: %s (%d)
Failed to add operation to E5 stream. E5RT: %s (%d)
Failed to execute E5 stream.ESRT: %s (%d)
Failed to reset the stream. E5RT: %s (%d)
Could not create team identifier error=%@
Failed to prepare E5 execution stream operation for encode.ESRT: %s (%d)
The operation was never prepared or has been reset
Failed to build output feature provider with error %@.
Failed to create E5 execution stream operation. The library path was %s and the function name was %s.ESRT: %s (%d)
Failed to retain E5 execution stream operation input port %@ E5RT: %s (%d)
The input feature provider doesn't have a feature %@ or it is undefined.
Failed to get the number of inputs for operation. E5RT: %s (%d)
Failed to get input port names for operation. E5RT: %s (%d)
Failed to get the number of outputs for operation E5RT: %s (%d)
Failed to get output port names for operation. E5RT: %s (%d)
Error computing shape information for Neural Network model. This model may be invalid.
IMPORTANT: new sequence length computation failed, falling back to old path.
Model requires sequence length greater than %d
Error in neural network compiler computing minimum sequence length.
Invalid height and width for the image input.
Input MLMultiArray cannot be %d dimensional (must be between 1 and 5 dimensions).
Input MLMultiArray cannot be %d dimensional (must have at least 1 dimension).
Unsupported Engine type %d.
Cannot create context, Caught exception: %s
IOS 11 Legacy code found sequence length %d
Image descripition included empty set of enumerated sizes
Using the default size
Image descripition width and height and are not valid according to the enumerated sizes
Changing default height and width to be the first enumerated size
Image descripition width and height and are not valid according to the specified flexible ranges
Changing default height and width to minimum size in range
Model does not exist at %@
Failed to read model package at %@. Error: %s
%{public}@: There must be at least %tu features, but there is only %tu.
%{public}@: There must be at most %tu features, but there is %tu.
%{public}@: The feature type must be one of {%{public}@}, but it is %{public}@.
updateType can only be used for personalization use case while the current use case is not personalization. This parameter is ignored.
File %s: error unmapping memory; msg=%{errno}d
Value for %@ must respond to 'unsignedIntegerValue' selector. Will default to VNImageCropAndScaleOptionScaleFill = 2
This method should not be called on the main thread as it may lead to UI unresponsiveness.
Error compiling updatable model.
%@ watchdog timer timeout
Watchdog timer timeout
softlink:r:path:/System/Library/PrivateFrameworks/Trial.framework/Trial
softlink:r:path:/System/Library/PrivateFrameworks/TrialProto.framework/TrialProto
softlink:r:path:/System/Library/PrivateFrameworks/XGBoostFramework.framework/XGBoostFramework
softlink:r:path:/System/Library/PrivateFrameworks/XGBoostFramework.framework/XGBoostFramework
MLClassifier
MLModeling
MLE5ExecutionStreamOperationPool
_MLDataSource
ETDataProvider
NSObject
MLCompilerEvent
CUTCoreAnalyticsMetric
CUTMetric
MLDictionaryConstraint
MLFeatureValueConstraint
NSSecureCoding
NSCoding
NSCopying
MLParameterUtils
MLSubtractBroadcastableBrick
EspressoBrick
MLTransposeBrick
_MLSNFrameworkHandle
MLE5InputPortBinder
MLE5PortBinder
_MLNLPSentenceClassifierModel
MLCustomModel
ModelKeyServerAPIFetchKeyResult
MLModelCollection
MLSplitNDBrick
MLBackgroundTask
MLBackgroundPredictionTask
MLTileBrick
MLLocalOutlierFactor
MLStackNDBrick
MLE5Utils
MLImageSize
MLAddBroadcastableBrick
MLSoftmaxNDBrick
MLAppleGazetteerParameters
MLAppleGazetteer
MLModelSpecificationLoader
MLMultiArrayUtils
MLMultiArray
ScopedBufferAccess
Attributes
PrivateConstruction
CopyingAndVectorization
ConvenientConstruction
Concatenating
Filling
MLMultiArrayAsNSArrayWrapper
MLMultiArrayView
Views
RawAccess
MLCompilerNeuralNetworkOutput
QuickLook
MLParameterDescription
Utilities
MLSVREngine
ModelConstructible
ImageUtils
MLModelErrorUtils
MLNeuralNetworkCompiler
MLSpecificationCompiler
MLNeuralNetworkContainer
PixelBufferPoolKey
MLNeuralNetworkEngine
MLNeuralNetwork
MLRegressor
MLCompiledModelLoader
MLParameterKey
MLLinkedModelParameters
MLScopedParameters
MLNeuralNetworkParameters
MLTreeEnsmebleModelParameters
MLCustomModelLoader
MLCustomModelWrapper
MLModelConfiguration
MLE5ExecutionStreamPool
ModelKeyServerAPIRawKey
MLSVRLoader
MLLayerExecutionSchedule
MLSineBrick
MLArrayBatchProvider
MLBatchProvider
MLKNearestNeighborsClassifier
MLUpdatable
MLWritable
MLMultiplyBroadcastableBrick
MLModelDescription
MLCosineBrick
ModelSpecification
MLPipelineClassifier
MLMultiArrayShapeConstraint
MLErfActivationBrick
MLItemSimilarityRecommender
MLObjectBoundingBoxOutputDescription
MLObjectBoundingBoxOutput
MLComputeDataSource
Model
MLE5IOPort
MLNeuralNetworkMLComputeUpdateEngine
MLIdentity
MLVersionInfo
MLParameterContainer
MLKey
MLUpdateContext
ModelKeyServerAPIFetchKeyResponse
MLSVMEngine
MLCustomLayer
MLCustomLayerWrapper
MLPersistentKeyStorage
MLFeatureProviderUtils
MLLazyUnionFeatureProvider
MLFeatureProvider
MLNewProviderConstruction
MLTreeEnsembleRegressor
ModelAsset
MLImageConstraint
MLModelAsset
MLFloorBrick
MLFeatureValue
MLBatchedMatMulBrick
MLProgramInternal
MLProgram
MLProgramTrainer
MLWrappedModel
MLWritableWrappedModel
MLDivideBroadcastableBrick
_MLVNScenePrintCustomModel
MLPowBroadcastableBrick
MLArchivingUtils
_MLNLPWordTaggingModel
MLModelTypeRegistry
MLNeuralNetworkUpdateEngine
_MLVNFrameworkHandle
CoreMLModelSecurityProtocol
CoreMLModelSecurityServiceToClientProtocol
MLSecureModel
MLSecureModelDecryptCredential
CoreMLModelSecurityServiceToClient
MLArrayDictionaryFeatureProvider
MLTreeEnsembleClassifier
MLComputeBatchDataSource
MLComputeDataProvider
_MLSNVGGishFeatureEmbedding
MLLoader
_NNLayerInfo
_OnDiskArchiveReader
_ArchiveReader
_InMemoryArchiveReader
MLNeuralNetworkV1Container
MLMultiFunctionProgramContainer
MLMultiFunctionProgramEngine
MLRangeBrick
MLExpBrick
ModelKeyServerAPIFetchKeyRequest
MLCeilBrick
MLFeatureDescription
MLNearestNeighborsLinearIndex
MLNearestNeighborsIndex
MLModelVisionFeaturePrintInfo
MLPipeline
MLSupportVectorRegressor
MLGLMRegression
MLProgramContext
CoreMLVersion
_MLSNVGGishFrontendProcessing
MLTemporaryDirectory
MLAppleAudioFeatureExtractorSoundPrintParameters
MLAppleAudioFeatureExtractorParameters
MLAppleAudioFeatureExtractor
MLModelExecutionSchedule
MLProgramTrainingDelta
MLLoaderEventExtensions
MLLoaderEvent
MLGatherBrick
MLBroadcastToBrick
MLGKDecisionTree
MLReporter
CUTMetricLogger
MLReporterUtils
MLSliceNDBrick
MLSequence
MLSequnceAsFeatureValueArray
MLFeatureValueAccess
_MLBatchDataSource
MLFairPlayDecryptSessionManager
MLFairPlayDecryptSession
_MLSNSoundPrint
MLGeluActivationBrick
MLKNearestNeighborsClassifierParameters
MLE5OutputPortBinder
MLBackgroundRunner
_DASExtensionRunner
MLCompilerOptions
MLCompilerResult
MLCompiler
Internal
MLModelSpecificationSaver
MLSaver
MLLogging
MLUpdateProgressHandlersUtils
MLUpdateProgressHandlers
MLModelCollectionEntry
MLE5Engine
MLMetricKey
MLModel
MLAppleImageFeatureExtractorScenePrintParameters
MLAppleImageFeatureExtractorObjectPrintParameters
MLAppleImageFeatureExtractorParameters
MLAppleImageFeatureExtractor
ExternalReferenceFlatteningAddition
MLTreeEnsembleXGBoostClassifier
MLRegressorResult
MLDataConversionUtils
MLNeuralNetworkUpdateUtils
MLFeatureTypeUtils
MLLinkedModel
MLNumericConstraint
MessageMutation
CKCodeOperationMessageMutation
MLCloudSession
_MLInternalNLPModelWriter
MLNNLayerComputeUnitSelectionUtils
InternalCustomTileLike
MLModelEncryptionUtils
MLDictionaryFeatureProvider
NSFastEnumeration
FromGenericFeatureProvider
MLPipelineRegressor
MLSupportVectorClassifier
MLKeyManager
MLPipelineUpdateEngine
MLProgramContainer
MLNeuralNetworkV1Engine
MLClassifierResult
_MLVNDetectionPrintCustomModel
MLSlidingWindowsBrick
MLNeuralNetworksCompileTimeParams
ModelKeyServerAPIResultError
MLAppleTextClassifierParameters
MLAppleTextClassifier
MLPipelineLoader
MLProgramEvaluator
_KDNode
MLNearestNeighborsSingleKdTreeIndex
MLShufflingBatchProvider
MLDefaultCustomLayerFactory
MLCustomLayerFactory
MLProgramEvaluationResult
MLNonMaximumSuppressionParameters
MLNonMaximumSuppression
MLClipBrick
MLE5ExecutionStream
InternalCustomGatherTree
MLProgramEngine
MLUpdateTask
MLTaskStateTransitionDelegate
_MLNLPFrameworkHandle
MLCloudDeploymentUtils
MLFeatureFlags
MLPredictionEvent
MLPredictionOptions
MLAppleWordTaggerParameters
MLAppleWordTagger
MLBatchProviderUtils
MLLazyUnionBatchProvider
MLWindowedBatchProvider
MLIndexedBatchProvider
MLNewBatchConstruction
MLBatchCopyToMultiArray
MLConcatNDBrick
ModelKeyServerAPISignedKey
MLSVMLoader
MLE5ExecutionStreamOperation
MLAppleSoundAnalysisPreprocessing
MLImputer
MLSupervisedOnlineUpdateOptions
MLModelIOUtils
MLGLMClassification
MLSequenceConstraint
MLFairPlayKeyLoadingSession
MLModelDescriptionUtils
MLTreeEnsembleXGBoostUpdateEngine
MLModelMetadata
MLFeatureVectorizer
MLImageConversion
MLDictVectorizer
MLModelCompilation
MLFillBrick
MLNormalizer
MLAppleWordEmbeddingParameters
MLAppleWordEmbedding
MLTask
MLCategoricalMapping
MLScaler
SpecConstructible
MLOneHotEncoder
MLInternalSettings
MLBayesianProbitRegression
MLSupervisedOnlineUpdatable
MLProbabilityDictionarySharedKeySet
MLProbabilityDictionaryMultiArrayStorage
MLProbabilityDictionaryStorage
MLProbabilityDictionaryFloat64Storage
MLProbabilityDictionaryArrayStorage
MLProbabilityDictionary
MLLayerPath
MLMultiArrayConstraint
MLImageSizeConstraint
ClosestAllowedSize
MLArrayFeatureExtractor
MLBackgroundWatchdog
replaceBytesInRange:withBytes:
isApplication
initWithArray:
initWithArray:copyItems:
initWithBase64EncodedString:options:
lastObject
lastPathComponent
errorWithDomain:code:userInfo:
copy
isEqualToArray:
isEqualToDictionary:
copyItemAtPath:toPath:error:
copyItemAtURL:toURL:error:
firstObject
floatValue
postNotificationName:object:
predicateFormat
moveItemAtPath:toPath:error:
moveItemAtURL:toURL:error:
mutableCopy
JSONObjectWithData:options:error:
selected_runtime_engine
insertObject:atIndex:
URLByDeletingPathExtension
URLForDirectory:inDomain:appropriateForURL:create:error:
URLWithString:
compare:
numberWithBool:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLong:
numberWithLongLong:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
initWithDictionary:
initWithModelDefinition:lossDefinition:variablesDefinition:optimizerDefinition:forPlatform:error:
numberWithUnsignedLongLong:
objCType
factor
factorLevelsWithNamespaceName:
initWithUTF8String:
initWithUUIDString:
getTensorNamed:
getValue:size:
globallyUniqueString
allowedClasses
code
isEqualToNumber:
isEqualToString:
isFileURL
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
downloadNamespaceWithName:options:progress:completion:
initWithBytesNoCopy:length:deallocator:
initWithCGImage:options:
initWithCString:encoding:
initWithCVPixelBuffer:imageParameters:error:
initWithCapacity:
countForObject:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
bundleWithIdentifier:
initWithFormat:arguments:
decodeBoolForKey:
decodeBytesForKey:returnedLength:
decodeFloatForKey:
decodeInt64ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeObjectForKey:
decodeObjectOfClass:forKey:
initWithContainerID:
initWithContentsOfURL:error:
saveNetwork:inplace:error:
scanInteger:
scanUpToCharactersFromSet:intoString:
scanUpToString:intoString:
scannerWithString:
encodeBool:forKey:
encodeBytes:length:forKey:
encodeFloat:forKey:
encodeInt64:forKey:
encodeInt:forKey:
encodeInteger:forKey:
encodeObject:forKey:
hasDirectoryPath
hasPrefix:
orderedSetWithArray:
outputDescriptions
dictionaryWithCapacity:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithSharedKeySet:
directoryValue
defaultManager
deregisterNamespaceName:error:
isReadableFileAtPath:
isSubclassOfClass:
archivedDataWithRootObject:requiringSecureCoding:error:
arrayByAddingObject:
arrayByAddingObjectsFromArray:
decodeObjectOfClasses:forKey:
decodeTopLevelObjectOfClass:forKey:error:
decodeTopLevelObjectOfClasses:forKey:error:
defaultCStringEncoding
defaultCenter
getParameterOfType:forLayerNamed:error:
getResourceValue:forKey:error:
base64EncodedStringWithOptions:
batch
exceptionWithName:reason:userInfo:
minusSet:
hasSuffix:
height
enumerateObjectsUsingBlock:
enumeratorAtURL:includingPropertiesForKeys:options:errorHandler:
environment
cropAndScaleBufferWithWidth:height:cropRect:format:imageCropAndScaleOption:options:error:calculatedNormalizedOriginOffset:calculatedScaleX:calculatedScaleY:
crossEntropyLossWithInputName:targetInputName:lossOutputName:
currentProcess
URLByDeletingLastPathComponent
isWritableFileAtPath:
keysSortedByValueUsingComparator:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileExistsAtPath:
fileExistsAtPath:isDirectory:
filePathURL
fileSystemRepresentation
fileURLWithPath:
fileURLWithPath:isDirectory:
null
URLByAppendingPathComponent:
addIndex:
addObject:
addObjectsFromArray:
addOperation:
indexOfObject:
indexOfObjectPassingTest:
indexSet
infoDictionary
clientWithIdentifier:
channels
characterAtIndex:
characterSetWithCharactersInString:
length
level
getBytes:range:
doInferenceOnData:error:
doTrainingOnData:forNumberOfEpochs:withCallback:error:
domain
dataWithJSONObject:options:error:
dataWithLength:
debug_name
decimalDigitCharacterSet
decodeArrayOfObjectsOfClass:forKey:
path
pathComponents
pathForResource:ofType:
per_platform_support
initWithOptimizationAlgorithm:parameters:error:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithCapacity:
dataWithContentsOfFile:
dataWithContentsOfURL:
containerIDForContainerIdentifier:environment:
containsObject:
containsString:
containsValueForKey:
mainBundle
main_engine_support
experimentId
experimentIdentifiersWithNamespaceName:
exportedObject
L2LossWithInputName:targetInputName:lossOutputName:
initWithInferenceNetworkPath:inferenceInputs:inferenceOutputs:error:
layers
initFileURLWithPath:isDirectory:
initForLayers:error:
initWithServiceName:
initWithServiceName:functionName:responseClass:
instancesRespondToSelector:
intValue
integerValue
interfaceWithProtocol:
intersectsSet:
initWithURL:options:
URLByAppendingPathComponent:isDirectory:
arrayWithArray:
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
localizedDescription
longLongValue
longValue
setByAddingObjectsFromSet:
setCancellable:
setChannels:
setClass:forClassName:
setCodeOperationCompletionBlock:
setCompletedUnitCount:
progressWithTotalUnitCount:
publicCloudDatabase
raise:format:
rangeValue
inputDescriptions
URLsForDirectory:inDomains:
UTF8String
UUID
UUIDString
checkResourceIsReachableAndReturnError:
processInfo
initWithContentsOfURL:options:error:
initWithData:encoding:
initWithData:type:shape:strides:
replaceItemAtURL:withItemAtURL:backupItemName:options:resultingItemURL:error:
replaceObjectAtIndex:withObject:
absoluteString
addChild:withPendingUnitCount:
addEntriesFromDictionary:
addUpdateHandlerForNamespaceName:usingBlock:
allKeys
allObjects
allValues
allocWithZone:
rawPointer
refresh
registerBrickClass:
registerDefaults:
registerNamespaceName:compatibilityVersion:defaultsFileURL:applicationGroup:cloudKitContainerId:error:
anyObject
appendFormat:
appendString:
setDiscretionaryBehavior:
setExportedInterface:
setExportedObject:
setHeight:
setInterruptionHandler:
setInvalidationHandler:
setLength:
setObject:forKey:
setParameterOfType:forLayerNamed:withValue:error:
setPausable:
setQualityOfService:
setRank:
setRemoteObjectInterface:
setRequest:
setResourceValue:forKey:error:
setSequence:
setTensorNamed:withValue:error:
setValue:forKey:
setWidth:
setWithArray:
setWithObjects:
setWithSet:
sharedKeySetForKeys:
standardUserDefaults
string
stringByAppendingFormat:
stringByAppendingPathComponent:
stringByAppendingPathExtension:
stringByAppendingString:
stringByDeletingLastPathComponent
stringByDeletingPathExtension
stringByReplacingCharactersInRange:withString:
stringByReplacingOccurrencesOfString:withString:
stringByStandardizingPath
stringByTrimmingCharactersInSet:
stringWithCString:encoding:
stringWithCapacity:
stringWithFormat:
stringWithString:
stringWithUTF8String:
subarrayWithRange:
substringFromIndex:
supported
synchronousRemoteObjectProxyWithErrorHandler:
taskState
texture
trainingInputDescriptions
unarchivedObjectOfClasses:fromData:error:
unionSet:
unsignedIntValue
unsignedLongLongValue
unsignedLongValue
valueForKey:
userInfo
valueForKeyPath:
valueWithRange:
width
writeToFile:atomically:
writeToURL:atomically:
writeToURL:options:error:
setAllowsCellularAccess:
setBatch:
reverseObjectEnumerator
boolForKey:
boolValue
relativePath
removeAllObjects
removeItemAtPath:error:
removeItemAtURL:error:
removeObject:
removeObjectForKey:
removeObjectsAtIndexes:
isAbsolutePath
initWithDescription:configuration:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionsFromBatch:error:
predictionsFromBatch:options:error:
executionSchedule
setModelPath:modelName:
modelPath
modelDescription
setModelDescription:
metadata
T@"MLModelDescription",&,N
T@"MLModelMetadata",R
classLabels
classify:options:error:
initWithDescription:configuration:error:
init
initWithE5BundleAtURL:functionName:outputDescriptionsByName:
takeOut
putBack:
e5BundleURL
functionName
outputDescriptionsByName
pool
serialQueue
.cxx_destruct
_e5BundleURL
_functionName
_outputDescriptionsByName
_pool
_serialQueue
T@"NSURL",R,C,V_e5BundleURL
T@"NSString",R,V_functionName
T@"NSDictionary",R,V_outputDescriptionsByName
T@"NSMutableSet",R,V_pool
T@"NSObject<OS_dispatch_queue>",R,V_serialQueue
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
dataPointAtIndex:error:
numberOfDataPoints
prepareForEpoch
initWithMLFeatureProvider:forPrediction:neuralNetworkEngine:error:
dataTensorDictionary
setDataTensorDictionary:
_dataTensorDictionary
T@"NSDictionary",&,N,V_dataTensorDictionary
name
T@"NSString",R
dictionaryRepresentation
T@"NSDictionary",R
modelName
setModelName:
modelHash
setModelHash:
modelType
setModelType:
modelOrigin
setModelOrigin:
modelVersion
setModelVersion:
modelCompiledWithVersion
setModelCompiledWithVersion:
compilerVersion
setCompilerVersion:
milUpgradeStatus
setMilUpgradeStatus:
milUpgradeFailureReason
setMilUpgradeFailureReason:
_modelName
_modelHash
_modelType
_modelOrigin
_modelVersion
_modelCompiledWithVersion
_compilerVersion
_milUpgradeStatus
_milUpgradeFailureReason
T@"NSString",C,N,V_modelName
T@"NSString",C,N,V_modelHash
T@"NSNumber",C,N,V_modelType
T@"NSNumber",C,N,V_modelOrigin
T@"NSString",C,N,V_modelVersion
T@"NSString",C,N,V_modelCompiledWithVersion
T@"NSString",C,N,V_compilerVersion
T@"NSNumber",C,N,V_milUpgradeStatus
T@"NSString",C,N,V_milUpgradeFailureReason
constraintWithStringKeys
constraintWithInt64Keys
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
isAllowedValue:error:
copyWithZone:
initWithKeyType:
keyType
_keyType
Tq,R,N,V_keyType
objectForKey:class:dictionary:
stringForKey:inDictionary:
numberForKey:inDictionary:
deScopeParameters:byDeletingPrefixingScope:
appendParameterDescriptions:toModelDescription:
setupForInputShapes:withParameters:
initWithParameters:
hasGPUSupport
setMappedWeights:sizeInBytes:
computeOnCPUWithInputTensors:outputTensors:
encodeToMetalCommandBuffer:inputTensors:outputTensors:
hasDynamicOutputShape:
computeDynamicOutputShape:
shapeInfoNeeded
inputRanks
outputRanks
inputShapes
outputShapes
_shapeInfoNeeded
_inputRanks
_outputRanks
_inputShapes
_outputShapes
TB,R,N,V_shapeInfoNeeded
T@"NSArray",R,N,V_inputRanks
T@"NSArray",R,N,V_outputRanks
T@"NSArray",R,N,V_inputShapes
T@"NSArray",R,N,V_outputShapes
axes
_axes
T@"NSArray",R,N,V_axes
sharedHandle
featureValue
T@"MLFeatureValue",R
initWithPort:
bindFeatureValue:error:
portHandle
setFeatureValue:
_portHandle
_featureValue
T^{e5rt_io_port=},R,V_portHandle
T@"MLFeatureValue",&,V_featureValue
dealloc
initWithModelDescription:parameterDictionary:error:
_sentenceClassifierModel
_modelDescription
T@"MLModelDescription",&,V_modelDescription
hasKeyId
hasModelName
hasTeamId
hasSignedKey
setSignedKey:
hasRawKey
setRawKey:
setKey:
setHasKey:
hasKey
keyAsString:
StringAsKey:
clearOneofValuesForKey
readFrom:
writeTo:
copyTo:
mergeFrom:
keyId
setKeyId:
teamId
setTeamId:
signedKey
rawKey
_key
_keyId
_rawKey
_signedKey
_teamId
_has
TB,R,N
T@"NSString",&,N,V_keyId
T@"NSString",&,N,V_modelName
T@"NSString",&,N,V_teamId
T@"ModelKeyServerAPISignedKey",&,N,V_signedKey
T@"ModelKeyServerAPIRawKey",&,N,V_rawKey
TB,N
Ti,N,V_key
beginAccessingModelCollectionWithIdentifier:completionHandler:
endAccessingModelCollectionWithIdentifier:completionHandler:
getTrialClientClass
getTrialExperimentIdentifiersClass
getTrialDownloadOptionsClass
getTrialFactorLevelClass
getTrialLevelClass
getTrialFileClass
getTrialFactorClass
_namespaceNameFromCollectionIdentifier:
initWithIdentifier:
_register
_downloadWithProgress:
_downloadOptions
_registerForUpdates
_endAccess
_handleTrialUpdateForNamespaceName:
_setDeploymentID
_populateEntries
identifier
entries
setEntries:
deploymentID
setDeploymentID:
namespaceName
trialClient
_identifier
_entries
_deploymentID
_namespaceName
_trialClient
T@"NSDictionary",C,N,V_entries
T@"NSString",C,N,V_deploymentID
T@"NSString",R,N,V_namespaceName
T@"TRIClient",R,N,V_trialClient
T@"NSString",R,C,N,V_identifier
axis
numSplits
splitSizes
_axis
_numSplits
_splitSizes
T@"NSNumber",R,N,V_axis
T@"NSNumber",R,N,V_numSplits
T@"NSArray",R,N,V_splitSizes
scheduleTask:
cancelTaskWithIdentifier:
cancelAllTasks
taskIsScheduledWithIdentifier:
activityForScheduling
taskIdentifier
setTaskIdentifier:
_taskIdentifier
T@"NSString",C,N,V_taskIdentifier
taskRunnerClass
modelURL
setModelURL:
modelConfiguration
setModelConfiguration:
predictionOptions
setPredictionOptions:
_modelURL
_modelConfiguration
_predictionOptions
T@"NSURL",C,N,V_modelURL
T@"MLModelConfiguration",C,N,V_modelConfiguration
T@"MLPredictionOptions",C,N,V_predictionOptions
reps
_reps
T@"NSArray",R,N,V_reps
initWithKNearestNeighborsModelAtURL:configuration:error:
updateToValidDistance:
findNearestNeighborsToQueryPoint:
findNearestNeighborsToIndex:
kDistanceToIndex:
localReachabilityDensityOfNeighbors:
localReachabilityDensityForIndex:
localReachabilityDensityForQeuryPoint:
computeLOFForQueryPoint:
inputMultiArray:error:
parameterValueForKey:error:
.cxx_construct
_index
_numberOfDimensions
_numberOfNeighbors
_cachedKDistances
_parameterContainer
multiArrayOwningBufferObjectOfPort:error:
initWithPixelsWide:pixelsHigh:
isEqualToImageSize:
pixelsWide
pixelsHigh
_pixelsWide
_pixelsHigh
Tq,R,V_pixelsWide
Tq,R,V_pixelsHigh
initWithData:language:inputFeatureName:outputFeatureName:modelData:labelNames:metadata:error:
revision
setRevision:
language
setLanguage:
inputFeatureName
setInputFeatureName:
outputFeatureName
setOutputFeatureName:
modelParameterData
setModelParameterData:
labelNames
setLabelNames:
setMetadata:
_revision
_language
_inputFeatureName
_outputFeatureName
_modelParameterData
_labelNames
_metadata
TQ,V_revision
T@"NSString",&,V_language
T@"NSString",&,V_inputFeatureName
T@"NSString",&,V_outputFeatureName
T@"NSData",&,V_modelParameterData
T@"NSArray",&,V_labelNames
T@"NSDictionary",&,V_metadata
loadModelFromSpecification:configuration:error:
saveAppleGazetteerModelToURL:gazetteerParameters:error:
initWithParameters:modelDescription:nlpHandle:configuration:error:
parameters
gazetteerModel
_parameters
T@"MLAppleGazetteerParameters",R,V_parameters
stringForDataType:
initWithShape:dataType:error:
initWithBytesNoCopy:shape:dataType:strides:deallocator:mutableShapedBufferProvider:error:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithMultiArrayBuffer:
initWithPixelBuffer:shape:
numberAtOffset:
setNumber:atOffset:
objectAtIndexedSubscript:
setObject:atIndexedSubscript:
offsetForKeyedSubscript:
objectForKeyedSubscript:
setObject:forKeyedSubscript:
dataPointer
count
strides
pixelBuffer
dataType
shape
_storageManager
_shape
T^v,R,N
Tq,R,N
T@"NSArray",R,N,V_shape
T@"NSArray",R,N
T^{__CVBuffer=},R,N
getBytesWithHandler:
getMutableBytesWithHandler:
mutableBytes
bytes
numberOfBytesPerElement
isContiguous
isContiguousInOrder:
isEqualToMultiArray:
doublePointer
float32Pointer
cppStorageOrder:
Tr^v,R,N
TQ,R,N
contiguous
TB,R,N,GisContiguous
initWithShape:dataType:storageOrder:error:
initWithShape:dataType:storageOrder:bufferAlignment:
initWithBytesNoCopy:shape:dataType:strides:mutableShapedBufferProvider:
initWithArray:dataType:
initWithScalars:shape:dataType:
validateNestedArray:error:
_shapeOfNestedArray:error:
copyIntoMultiArray:error:
vectorizeIntoMultiArray:storageOrder:error:
doubleMultiArrayWithCopyOfMultiArray:
doubleVectorWithValues:
doubleMultiArrayWithShape:valueArray:error:
getShapeOfArrayOfSameLengthArrays:numberOfRows:numberOfColumns:error:
doubleMatrixWithValues:error:
float32MatrixWithValues:error:
validateMultiArrays:forConcatenatingAlongAxis:normalizedAxis:reason:
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
fillWithNumber:
setRangeWithRawData:destIndex:error:
numberArray
initWrappingMultiArray:
objectAtIndex:
multiArray
setMultiArray:
_multiArray
T@"MLMultiArray",&,V_multiArray
isSqueezableShape:
isSqueezableShape:dimensions:
squeezeShape:strides:resultingShape:resultingStrides:
initSlicingMultiArray:origin:shape:squeeze:error:
initSqueezingMultiArray:dimensions:error:
initExpandingDimensionsOfMultiArray:axis:
parent
_parent
T@"MLMultiArray",R,N,V_parent
sliceAtOrigin:shape:squeeze:error:
squeeze
squeezeDimensions:error:
multiArrayViewExpandingDimensionsAtAxis:
multiArrayBuffer
outputWithEspressoNetwork:
outputWithMILProgram:
initWithEspressoNetwork:
initWithMILProgram:
network
program
_network
_program
T{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}},R,N,V_network
T{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}},R,N,V_program
debugQuickLookObject
parameterDescriptionForKey:defaultValue:numericConstraint:
defaultValue
setDefaultValue:
numericConstraint
setNumericConstraint:
_defaultValue
_numericConstraint
T@"MLParameterKey",&,N,V_key
T@,&,N,V_defaultValue
T@"MLNumericConstraint",&,N,V_numericConstraint
asFeatureDictionaryWithPredictedValueDescription:
regressorResultFromOutputFeatures:error:
predictionFromFeatures:regressor:options:error:
initWithLibSVMFile:
initWithSVMModel:freeOnDealloc:isInputSizeLowerBoundOnly:inputSize:
allocSVMNodeVector:
fillSVMNodeVector:values:count:
deallocSVMNodeVector:
predict:
isInputSizeLowerBoundOnly
inputSize
model
setModel:
freeModelOnDealloc
setFreeModelOnDealloc:
_isInputSizeLowerBoundOnly
_freeModelOnDealloc
_inputSize
_model
T^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii},V_model
TB,V_freeModelOnDealloc
TB,R,V_isInputSizeLowerBoundOnly
TQ,R,V_inputSize
getContiguousFirstMajorFloat32BufferWithHandler:
renderToOneComponent8PixelBuffer:error:
renderToOneComponent16HalfPixelBuffer:error:
renderTo32BGRAPixelBuffer:channelOrderIsBGR:error:
renderToCVPixelBuffer:channelOrderIsBGR:error:
pixelBufferGray8FromMultiArrayHW:error:
pixelBufferGray16HalfFromMultiArrayHW:error:
pixelBufferBGRA8FromMultiArrayCHW:channelOrderIsBGR:error:
errorWithIntegerCode:underlyingError:format:args:
errorWithCode:underlyingError:format:args:
errorWithCode:format:args:
privateErrorWithCode:underlyingError:format:args:
errorWithCode:underlyingError:format:
errorWithCode:format:
genericErrorWithFormat:
updateErrorWithFormat:
featureTypeErrorWithFormat:
IOErrorWithFormat:
programValidationAtLoadErrorWithReason:format:
programParsingAtLoadErrorWithReason:format:
customLayerErrorWithUnderlyingError:withFormat:
parameterErrorWithUnderlyingError:format:
modelEncryptionErrorWithUnderlyingError:format:
modelDecryptionKeyFetchErrorWithUnderlyingError:format:
modelDecryptionErrorWithUnderlyingError:format:
programEvaluationErrorWithUnderlyingError:format:
collectEspressoModelDetails:modelPath:
collectNNModelDetailsFromArchive:spec:error:
compileSpecification:toArchive:options:error:
compiledVersionForSpecification:options:error:
containerFromFilePath:inputLayerNames:outputLayerNames:parameters:
readIsClassifier:
containerFromCompiledArchiveCommon:filename:modelVersionInfo:compilerVersionInfo:configuration:error:
containerFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
initWithFilePath:inputLayerNames:outputLayerNames:parameters:
initWithFeatureDescriptions:transformDesc:outputLayerNames:classScoreVectorName:classLabels:isEncrypted:modelVersionInfo:
initWithFeatureDescriptions:transformDesc:outputLayerNames:classScoreVectorName:classLabels:isEncrypted:modelVersionInfo:compilerVersionInfo:
activeFunction
modelFilePath
setModelFilePath:
inputLayerNames
setInputLayerNames:
outputLayerNames
setOutputLayerNames:
setName:
inputDescription
setInputDescription:
outputDescription
setOutputDescription:
imageParameters
setImageParameters:
imagePreprocessingParams
setImagePreprocessingParams:
configurationList
setConfigurationList:
hasBidirectionalLayer
setHasBidirectionalLayer:
hasOptionalInputSequenceConcat
setHasOptionalInputSequenceConcat:
hasDynamicLayer
setHasDynamicLayer:
setClassLabels:
classScoreVectorName
setClassScoreVectorName:
transformDesc
setTransformDesc:
ndArrayInterpretation
setNdArrayInterpretation:
updatableModelCompiledParams
setUpdatableModelCompiledParams:
optionalInputDefaultValues
setOptionalInputDefaultValues:
modelIsEncrypted
setModelIsEncrypted:
modelVersionInfo
setModelVersionInfo:
modelIsMIL
setModelIsMIL:
modelIsTrainingProgram
setModelIsTrainingProgram:
precision
setPrecision:
engine
setEngine:
optionalInputTypes
setOptionalInputTypes:
compilerVersionInfo
setCompilerVersionInfo:
compilerOutput
setCompilerOutput:
widths
heights
batches
sequences
ranks
_hasBidirectionalLayer
_hasOptionalInputSequenceConcat
_hasDynamicLayer
_ndArrayInterpretation
_modelIsEncrypted
_modelIsMIL
_modelIsTrainingProgram
_precision
_engine
_modelFilePath
_inputLayerNames
_outputLayerNames
_name
_inputDescription
_outputDescription
_imageParameters
_imagePreprocessingParams
_configurationList
_classLabels
_classScoreVectorName
_transformDesc
_updatableModelCompiledParams
_optionalInputDefaultValues
_modelVersionInfo
_optionalInputTypes
_compilerVersionInfo
_compilerOutput
Ti,N,V_precision
Ti,N,V_engine
T@"NSArray",&,N,V_outputLayerNames
T@"NSArray",&,N,V_inputLayerNames
T@"NSDictionary",&,N,V_optionalInputTypes
T@"MLVersionInfo",&,N,V_compilerVersionInfo
T@"NSString",R,N
T@"MLCompilerNeuralNetworkOutput",&,N,V_compilerOutput
T@"NSString",&,N,V_modelFilePath
T@"NSString",&,N,V_name
T@"NSDictionary",&,N,V_inputDescription
T@"NSDictionary",&,N,V_outputDescription
T@"NSDictionary",&,N,V_imageParameters
T@"NSDictionary",&,N,V_imagePreprocessingParams
T@"NSArray",&,N,V_configurationList
TB,N,V_hasBidirectionalLayer
TB,N,V_hasOptionalInputSequenceConcat
TB,N,V_hasDynamicLayer
T@"NSArray",&,V_classLabels
T@"NSString",&,V_classScoreVectorName
T@"MLModel",&,V_transformDesc
TB,V_ndArrayInterpretation
T@"MLNeuralNetworksCompileTimeParams",&,N,V_updatableModelCompiledParams
T@"NSDictionary",&,N,V_optionalInputDefaultValues
TB,N,V_modelIsEncrypted
T@"MLVersionInfo",&,N,V_modelVersionInfo
TB,N,V_modelIsMIL
TB,N,V_modelIsTrainingProgram
initWithSize:pixelFormatType:
frameSize
pixelFormatType
_pixelFormatType
_frameSize
T{CGSize=dd},R,V_frameSize
TI,R,V_pixelFormatType
gpuEngine
gpuPrecision
containerClass
loadModelFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
neuralNetworkFromContainer:error:
neuralNetworkFromContainer:configuration:error:
evaluate:error:
regress:options:error:
usingEspressoConfigurations
sequenceConcatConsumesOptionalInputNamed:
sequenceNamed:
convertPredictionToClassifierResult:withOptions:error:
addClassifierInformationToOutput:options:error:
availableOutputBlobList
imageFeatureValueFromPixelBuffer:usingPixelFormat:
copyPixelBufferFromPixelBuffer:usingPixelFormat:
pixelBufferPoolWithSize:pixelFormat:
transferPixelBuffer:toPixelBuffer:
pixelBufferFromOutputBacking:forFeature:
opacifyAndPermutePixelBuffer:bufferContainsBGRA:error:
prepareBlobNamed:forNewBlobBackingMode:bindMode:
_matchEngineToOptions:error:
initWithContainer:error:
collectParametersFromContainer:configuration:error:
initWithContainer:configuration:error:
_espressoDeviceForConfiguration:error:
_setupContextAndPlanWithForceCPU:error:
_setupContextAndPlanWithConfiguration:error:
_setupContextAndPlanWithConfiguration:usingCPU:error:
_setMultipleBuffersOnPlan:error:
_addCompiledNetworkOrProgramToPlan:error:
_addNetworkToPlan:error:
_setupContextAndPlanWithConfiguration:usingCPU:reshapeWithContainer:error:
verifyInputs:error:
obtainBuffer
releaseBuffer:
bindInputsAndOutputs:cleanUpBlocks:bufferIndex:options:error:
bindInputFeatureNamed:featureValue:bufferIndex:cleanUpBlocks:error:
inputBindStateForFeatureValue:error:
bindDirectlyInputFeatureNamed:pixelBuffer:cleanUpBlocks:error:
lockPixelBuffer:cleanUpBlocks:error:
bindInputFeatureNamed:pixelBuffer:cleanUpBlocks:error:
bindInputFeatureNamed:convertingMultiArray:bufferIndex:error:
bindInputFeatures:bufferIndex:cleanUpBlocks:error:
_setMultiArrayOutputBacking:forOutputFeatureName:toEbuf:error:
_espressoOutputShapeForFeatureName:matchesShapeOfMLMultiArray:
tryToSetOutputBacking:forFeatureName:toEbuf:reportPointerFlags:error:
verifyMultiArrayOutputBacking:forFeature:error:
verifyPixelBufferOutputBacking:forFeature:error:
verifyOutputBacking:forFeature:error:
bindOutputBuffers:outputBackings:automaticOutputBackingMode:directlyBoundOutputFeatureNames:error:
evaluateInputs:options:error:
evaluateInputs:options:verifyInputs:error:
updateDynamicOutputBlobIndicatorCacheAndReturnError:
populateMultiArrayShape:strides:forEbuf:featureDescription:ndArrayInterpretation:
pixelBufferBackedMultiArrayWithShape:
outputBackingMultiArrayForFeatureName:
completeOutputBackings:automaticOutputBackingMode:error:
evaluateInputs:bufferIndex:options:error:
executePlan:error:
bindDynamicOutputBuffers:error:
populateOutputs:outputBackings:directlyBoundOutputFeatureNames:error:
copyEbuf:ofPixelType:toPixelBuffer:error:
imageFeatureValueFromEbuf:backingCVPixelBuffer:description:error:
multiArrayFeatureValueFromEbuf:backingMultiArray:description:outputName:error:
_pixelBufferFromEbuf:description:error:
_deallocContextAndPlan
sortBatchByShape:withMap:error:
resetSizes:error:
resetSizesWithEspressoConfigurations:error:
setEspressoBlobShapes:widths:heights:ks:batches:sequences:ranks:error:
resetSizesNoAutoRelease:error:
copyImagePreprocessingParametersTo:error:
rebuildPlan:
rebuildPlan:error:
evaluateBatch:options:error:
dumpTestVectorsToPath:
supportFromEspressoLayerInfo:
supportFromEspressoPlatform:
enableInstrumentsTracing
inputLayers
outputLayers
hardwareFallbackDetected
setHardwareFallbackDetected:
imagePreprocessingParameters
setImagePreprocessingParameters:
espressoInputShapes
setEspressoInputShapes:
espressoInputStrides
setEspressoInputStrides:
numInputs
numOutputs
usingCPU
setUsingCPU:
plan
setPlan:
setQos:
context
setContext:
isEspressoBiasPreprocessingShared
setIsEspressoBiasPreprocessingShared:
probabilityDictionarySharedKeySet
setProbabilityDictionarySharedKeySet:
bufferSemaphore
setBufferSemaphore:
espressoQueue
setEspressoQueue:
predictionsQueue
setPredictionsQueue:
submitSemaphore
setSubmitSemaphore:
isGPUPathForbidden
setIsGPUPathForbidden:
isANEPathForbidden
setIsANEPathForbidden:
inputBlobNameToLastBackingMode
outputBlobNameToLastBackingMode
espressoProfileInfo
setEspressoProfileInfo:
setNetwork:
defaultOptionalValues
setDefaultOptionalValues:
setActiveFunction:
_inputBuffers
_outputBuffers
_params
_widths
_heights
_batches
_sequences
_ranks
_bufferAvailable
_flexibleShapesConfigNamesInNet
_currentConfigurationName
_OutputBlobIsDynamic
_pixelBufferPoolCache
_transferSession
_hardwareFallbackDetected
_usingCPU
_isEspressoBiasPreprocessingShared
_isGPUPathForbidden
_isANEPathForbidden
_qos
_inputLayers
_outputLayers
_imagePreprocessingParameters
_espressoInputShapes
_espressoInputStrides
_numInputs
_numOutputs
_plan
_context
_probabilityDictionarySharedKeySet
_bufferSemaphore
_espressoQueue
_predictionsQueue
_submitSemaphore
_inputBlobNameToLastBackingMode
_outputBlobNameToLastBackingMode
_espressoProfileInfo
_defaultOptionalValues
_activeFunction
TQ,R,N,V_numInputs
TQ,R,N,V_numOutputs
TB,N,V_usingCPU
T^v,N,V_plan
Ti,N,V_qos
T^v,N,V_context
TB,N,V_isEspressoBiasPreprocessingShared
T@"NSArray",&,N,V_classLabels
T@"NSString",&,N,V_classScoreVectorName
T@,&,N,V_probabilityDictionarySharedKeySet
TB,R,N,V_modelIsEncrypted
T@"NSObject<OS_dispatch_semaphore>",&,V_bufferSemaphore
T@"NSObject<OS_dispatch_queue>",&,V_espressoQueue
T@"NSObject<OS_dispatch_queue>",&,V_predictionsQueue
T@"NSObject<OS_dispatch_semaphore>",&,V_submitSemaphore
TB,V_isGPUPathForbidden
TB,V_isANEPathForbidden
T@"NSMutableDictionary",R,N,V_inputBlobNameToLastBackingMode
T@"NSMutableDictionary",R,N,V_outputBlobNameToLastBackingMode
TB,N,V_ndArrayInterpretation
T@"NSDictionary",&,N,V_imagePreprocessingParameters
T@"EspressoProfilingNetworkInfo",&,N,V_espressoProfileInfo
T@"NSDictionary",R,N,V_optionalInputTypes
T{?=^vi},N,V_network
T@"NSDictionary",&,N,V_defaultOptionalValues
T@"MLVersionInfo",R,&,N,V_compilerVersionInfo
T@"NSString",&,N,V_activeFunction
T@"NSArray",R,&,N,V_inputLayers
T@"NSArray",R,&,N,V_outputLayers
TB,N,V_hardwareFallbackDetected
T@"NSDictionary",&,N,V_espressoInputShapes
T@"NSDictionary",&,N,V_espressoInputStrides
T@"MLVersionInfo",R,N,V_modelVersionInfo
initWithKeyName:
learningRate
momentum
miniBatchSize
beta1
beta2
epochs
shuffle
seed
numberOfNeighbors
T@"MLParameterKey",R,N
linkedModelFileName
linkedModelSearchPath
scopedTo:
deletingPrefixingScope:
weights
biases
maxDepth
objective
numTrees
numClasses
minChildWeight
updateType
initWithModelDescription:configuration:parameterDictionary:error:
parametersFromCustomModelSpec:error:
customModelWithName:modelDescription:modelConfiguration:parameterDictionary:error:
initWithModelDescription:customModel:configuration:
customModel
setCustomModel:
_customModel
T@"NSObject<MLCustomModel>",&,V_customModel
defaultConfiguration
computeUnitsToString:
initWithComputeUnits:
allowFloat16AccumulationOnGPU
setAllowFloat16AccumulationOnGPU:
preferredMTLDevice
setPreferredMTLDevice:
allowBackgroundGPUCompute
setAllowBackgroundGPUCompute:
isEqualToModelConfiguration:
modelDisplayName
setModelDisplayName:
computeUnits
setComputeUnits:
allowBackgroundGPUComputeSetting
setAllowBackgroundGPUComputeSetting:
trainWithMLCompute
setTrainWithMLCompute:
useWatchSPIForScribble
setUseWatchSPIForScribble:
allowLowPrecisionAccumulationOnGPU
setAllowLowPrecisionAccumulationOnGPU:
preferredMetalDevice
setPreferredMetalDevice:
enableTestVectorMode
setEnableTestVectorMode:
setParameters:
rootModelURL
setRootModelURL:
profilingOptions
setProfilingOptions:
usePreloadedKey
setUsePreloadedKey:
parentModelName
setParentModelName:
allowsInstrumentation
setAllowsInstrumentation:
_allowBackgroundGPUComputeSetting
_trainWithMLCompute
_useWatchSPIForScribble
_allowLowPrecisionAccumulationOnGPU
_enableTestVectorMode
_usePreloadedKey
_allowsInstrumentation
_modelDisplayName
_computeUnits
_preferredMetalDevice
_rootModelURL
_profilingOptions
_parentModelName
TB,V_allowBackgroundGPUComputeSetting
TB,V_trainWithMLCompute
TB,N,V_useWatchSPIForScribble
TB,V_allowLowPrecisionAccumulationOnGPU
T@"<MTLDevice>",&,N
T@"<MTLDevice>",&,N,V_preferredMetalDevice
TB,N,V_enableTestVectorMode
T@"NSDictionary",&,V_parameters
T@"NSURL",&,V_rootModelURL
Tq,N,V_profilingOptions
TB,N,V_usePreloadedKey
T@"NSString",&,N,V_parentModelName
TB,N,V_allowsInstrumentation
T@"NSString",C,V_modelDisplayName
Tq,V_computeUnits
hasEncryptionKey
hasEncryptionIv
encryptionKey
setEncryptionKey:
encryptionIv
setEncryptionIv:
_encryptionIv
_encryptionKey
T@"NSData",&,N,V_encryptionKey
T@"NSData",&,N,V_encryptionIv
initWithLayerError:
initWithComputeUnits:layerName:layerError:layerTypeName:supportedComputeUnits:layerIndex:
layerError
layerName
preferredComputeUnit
layerTypeName
supportedComputeUnits
layerIndex
_layerError
_layerName
_preferredComputeUnit
_layerTypeName
_supportedComputeUnits
_layerIndex
Tq,R,N,V_layerError
T@"NSString",R,C,N,V_layerName
TQ,R,N,V_preferredComputeUnit
T@"NSString",R,C,N,V_layerTypeName
TQ,R,N,V_supportedComputeUnits
Tq,R,N,V_layerIndex
featuresAtIndex:
initWithFeatureProviderArray:
initWithDictionary:error:
array
_array
T@"NSArray",R,N,V_array
initWithDescription:
writeToURL:error:
setUpdateProgressHandlers:dispatchQueue:
updateModelWithData:
resumeUpdateWithParameters:
resumeUpdate
cancelUpdate
initWithDescription:configuration:parameters:dataPoints:labels:error:
computeKClosestLabels:
computeClassProbabilities:from:
packageOutputWithPredictedLabel:classProbabilities:nearestLabels:nearestDistances:
extractNearestNeighborLabels:distances:from:
progressHandlers
setProgressHandlers:
progressHandlersDispatchQueue
setProgressHandlersDispatchQueue:
updateParameters
setUpdateParameters:
continueWithUpdate
setContinueWithUpdate:
parameterContainer
setParameterContainer:
numberOfDimensions
setNumberOfDimensions:
indexType
setIndexType:
index
setIndex:
labelType
setLabelType:
labelsForDataPoints
setLabelsForDataPoints:
labelsSet
setLabelsSet:
defaultLabel
setDefaultLabel:
weightingScheme
setWeightingScheme:
nearestLabelsFeatureName
setNearestLabelsFeatureName:
nearestDistancesFeatureName
setNearestDistancesFeatureName:
_continueWithUpdate
_progressHandlers
_progressHandlersDispatchQueue
_updateParameters
_indexType
_labelType
_labelsForDataPoints
_labelsSet
_defaultLabel
_weightingScheme
_nearestLabelsFeatureName
_nearestDistancesFeatureName
T@"MLUpdateProgressHandlers",&,N,V_progressHandlers
T@"NSObject<OS_dispatch_queue>",&,N,V_progressHandlersDispatchQueue
T@"NSDictionary",&,N,V_updateParameters
TB,N,V_continueWithUpdate
T@"MLParameterContainer",&,N,V_parameterContainer
TQ,N,V_numberOfDimensions
Tq,N,V_indexType
T@"<MLNearestNeighborsIndex>",&,N,V_index
Tq,N,V_labelType
T@"NSArray",&,N,V_labelsForDataPoints
T@"NSOrderedSet",&,N,V_labelsSet
T@"NSObject",&,N,V_defaultLabel
Tq,N,V_weightingScheme
T@"NSString",&,N,V_nearestLabelsFeatureName
T@"NSString",&,N,V_nearestDistancesFeatureName
metadataWithSpecification:
metadataWithFormat:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:trainingInputDescriptions:orderedInputFeatureNames:orderedOutputFeatureNames:metadata:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:trainingInputDescriptions:metadata:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
initWithModelDescriptionSpecification:error:
initWithModelSpecification:error:
isEqualToDescription:
verifyInput:error:
predictedValueFeatureDescription
predictedClassFeatureDescription
classProbabilityFeatureDescription
validateAsClassifierDescriptionAndReturnError:
validateAsRegressorDescriptionAndReturnError:
inputDescriptionsByName
predictedFeatureName
predictedProbabilitiesName
isUpdatable
setIsUpdatable:
trainingInputDescriptionsByName
setTrainingInputDescriptionsByName:
parameterDescriptionsByKey
setParameterDescriptionsByKey:
setModelPath:
inputFeatureNames
outputFeatureNames
_isUpdatable
_inputDescriptionsByName
_predictedFeatureName
_predictedProbabilitiesName
_trainingInputDescriptionsByName
_parameterDescriptionsByKey
_modelPath
_inputFeatureNames
_outputFeatureNames
T@"NSArray",C,N,V_classLabels
T@"NSURL",&,N,V_modelURL
TB,N,V_isUpdatable
T@"NSDictionary",&,N,V_trainingInputDescriptionsByName
T@"NSDictionary",&,N,V_parameterDescriptionsByKey
T@"MLLayerPath",&,N,V_modelPath
T@"MLFeatureDescription",R,C,N
T@"MLFeatureDescription",R
T@"NSOrderedSet",R,V_inputFeatureNames
T@"NSOrderedSet",R,V_outputFeatureNames
T@"NSDictionary",R,N,V_inputDescriptionsByName
T@"NSDictionary",R,N,V_outputDescriptionsByName
T@"NSString",R,C,N,V_predictedFeatureName
T@"NSString",R,C,N,V_predictedProbabilitiesName
T@"NSDictionary",R,N,V_metadata
initDescriptionOnlyWithSpecification:configuration:error:
pipeline
initWithEngine:description:configuration:error:
T@"MLPipeline",&,V_engine
T@"MLPipeline",R
initUnspecified
initWithSizeRangeForDimension:
initWithEnumeratedShapes:
enumeratedShapes
isAllowedShape:error:
findAvailableShape:
type
sizeRangeForDimension
shapeSet
_type
_sizeRangeForDimension
_shapeSet
T@"NSOrderedSet",R,N,V_shapeSet
Tq,R,N,V_type
T@"NSArray",R,N,V_sizeRangeForDimension
size
_size
TQ,R,N,V_size
loadModelFromSpecificationWithCompilationOptions:options:error:
modelData
_itemForIndex:error:
_mapItemSequence:dest:error:
m_cached_model
m_model_data
m_num_items
m_item_data_feature_name
m_num_recommendations_feature_name
m_item_restriction_feature_name
m_item_exclusion_feature_name
m_item_list_output_feature_name
m_item_score_output_feature_name
m_item_mapping
m_item_string_list
m_item_integer_list
_m_scores
_m_items
_m_item_buffer
_m_item_invalid_mask
_m_item_predictions
_m_item_heap
format
setFormat:
confidenceFeatureName
setConfidenceFeatureName:
coordinatesFeatureName
setCoordinatesFeatureName:
_format
_confidenceFeatureName
_coordinatesFeatureName
Ti,V_format
T@"NSString",&,V_confidenceFeatureName
T@"NSString",&,V_coordinatesFeatureName
objectBoundingBoxOutputDescription
initWithFeatureProvider:forPrediction:neuralNetworkEngine:error:
dataCHWFromPixelBuffer:channelOrderIsBGR:error:
dataCHWFromPixelTypeGray8:error:
dataCHWFromChanneledPixelType:channelOrderIsBGR:error:
oneHotEncodedDataFromFeatureValue:withNNEngine:error:
dataDictionary
_dataDictionary
T@"NSDictionary",R,N,V_dataDictionary
initWithPortHandle:name:featureDescription:
prepareAndReturnError:
featureDescription
binder
setBinder:
_inputFeatureValue
_featureDescription
_binder
T@"MLFeatureDescription",R,V_featureDescription
T@"<MLE5PortBinder>",&,V_binder
T@"NSString",R,V_name
T@"MLFeatureValue",&
classLabelToIndexMap
classifierOutputIsSigmoidOutput
setClassifierOutputIsSigmoidOutput:
lossTargetName
_classifierOutputIsSigmoidOutput
_classLabelToIndexMap
_lossTargetName
T@"NSDictionary",R,N,V_classLabelToIndexMap
TB,N,V_classifierOutputIsSigmoidOutput
T@"NSString",R,N,V_lossTargetName
initWithConfiguration:
versionInfoWithMajor:minor:patch:variant:
versionInfoWithString:
versionInfoWithStringProgressive:
initWithMajor:minor:patch:variant:
versionNumberString
versionString
olderThan:
majorVersion
minorVersion
patchVersion
variantString
_majorVersion
_minorVersion
_patchVersion
_variantString
Tq,R,V_majorVersion
Tq,R,V_minorVersion
Tq,R,V_patchVersion
T@"NSString",R,V_variantString
parameterContainerFor:descriptions:
setCurrentValue:forKey:error:
validateParameterValue:givenConstraint:
currentParameterValues
setCurrentParameterValues:
parameterKeys
setParameterKeys:
parameterDescriptions
setParameterDescriptions:
_currentParameterValues
_parameterKeys
_parameterDescriptions
T@"NSMutableDictionary",&,N,V_currentParameterValues
T@"NSArray",&,N,V_parameterKeys
T@"NSDictionary",&,N,V_parameterDescriptions
initWithKeyName:scope:
hasGlobalScope
hasSameNameAsKey:
scope
_scope
T@"NSString",R,N,V_name
T@"NSString",R,N,V_scope
updateContextWithTask:model:event:metrics:parameters:
updateContextForEvent:metrics:parameters:error:
task
setTask:
event
setEvent:
metrics
setMetrics:
error
setError:
_task
_event
_metrics
_error
T@"MLUpdateTask",&,N,V_task
T@"MLModel<MLWritable>",&,N,V_model
Tq,N,V_event
T@"NSDictionary",&,N,V_metrics
T@"NSDictionary",&,N,V_parameters
T@"NSError",&,N,V_error
hasSuccess
setSuccess:
hasError
result
setResult:
setHasResult:
hasResult
resultAsString:
StringAsResult:
clearOneofValuesForResult
success
_result
_success
T@"ModelKeyServerAPIFetchKeyResult",&,N,V_success
T@"ModelKeyServerAPIResultError",&,N,V_error
Ti,N,V_result
initWithLibSVMFile:classLabels:
initWithSVMModel:freeOnDealloc:isInputSizeLowerBoundOnly:inputSize:classLabels:
numberOfClasses
hasProbabilityPredictionEnabled
predictProbabilities:probabilities:
setIsInputSizeLowerBoundOnly:
setInputSize:
TB,V_isInputSizeLowerBoundOnly
TQ,V_inputSize
initWithParameterDictionary:error:
setWeightData:error:
outputShapesForInputShapes:error:
evaluateOnCPUWithInputs:outputs:error:
encodeToCommandBuffer:inputs:outputs:error:
espressoShapeToCoremlShape:ndMode:
espressoShapesToCoremlShapes:ndMode:
coremlShapeToEspressoShape:ndMode:
coremlShapesToEspressoShapes:ndMode:
getStrides:
espressoTensorToCoremlTensor:ndMode:
espressoTensorsToCoremlTensorsGPU:
espressoTensorsToCoremlTensors:ndMode:
factory
ndMode
className
customImpl
setCustomImpl:
_ndMode
_className
_customImpl
TB,R,N,V_ndMode
T@"NSString",R,N,V_className
T@"NSObject<MLCustomLayer>",&,N,V_customImpl
persistentKeyStorageURL
syncQueue
storeKeyBlob:forKeyIdentifier:error:
retrieveKeyBlobForKeyIdentifier:
_featureValuesForNames:providedBy:error:
_vectorizedSizeOfFeatureValues:error:
_vectorizeWithoutSizeCheckFeatureValues:intoDoubleVector:stride:error:
vectorizeFeaturesProvidedBy:featureNames:intoDoubleVector:length:stride:error:
vectorizeFeaturesProvidedBy:featureNames:error:
canVectorizeFeatureWithDescription:
canVectorizeAllFeaturesWithDescriptions:
featureValueForName:
featureNames
T@"NSSet",R,N
initWithFeaturesFrom:addedToFeaturesFrom:
unionFeatureProvider
first
setFirst:
second
setSecond:
_first
_second
T@"<MLFeatureProvider>",&,N,V_first
T@"<MLFeatureProvider>",&,N,V_second
providerWithSubsetOfFeaturesNamed:providedBy:
lazyProviderWithFeaturesProvidedBy:addedToFeaturesProvidedBy:
scalarRegress:error:
scalarRegress:
vectorRegress:dest:
_model_data
_cached_model
num_dimensions
output_classes
initInterfaceAndMetadataWithCompiledArchive:error:
serializeInterfaceAndMetadata:toArchive:error:
osType:isAcceptedForPixelType:
constraintWithPixelsWide:pixelsHigh:pixelType:sizeConstraint:
constraintWithPixelsWide:pixelsHigh:pixelType:
_stringForOSType:
imagePixelTypeFromOSType:
initWithPixelsWide:pixelsHigh:pixelType:sizeConstraint:
_stringForAllowedOSTypes
osType
imageHeight
imageWidth
sizeConstraint
pixelType
_sizeConstraint
_pixelType
TQ,R,V_pixelType
TI,R
Tq,R,N,V_pixelsHigh
Tq,R,N,V_pixelsWide
TI,R,N
T@"MLImageSizeConstraint",R,N,V_sizeConstraint
modelAssetWithURL:error:
modelAssetWithURL:configuration:error:
modelAssetWithSpecification:error:
modelAssetWithSpecification:compilerOptions:error:
modelAssetWithSpecificationURL:error:
modelAssetWithSpecificationURL:compilerOptions:error:
isANESupported
fetchNetworkURLFromCompiledModelAtURL:error:
needsANECompilationForModelAtURL:result:error:
purgeANEBinaryForModelAtURL:error:
purgeANEIRForModelAtURL:error:
modelAssetWithSpecificationData:error:
initWithURL:error:
initWithURL:configuration:error:
load:
modelWithError:
modelWithConfiguration:error:
classifier
classifierWithError:
regressor
regressorWithError:
initWithArchiveData:
compiledURL
ranLoad
setRanLoad:
asset
setAsset:
loadConfiguration
setLoadConfiguration:
archiveData
_ranLoad
_compiledURL
_asset
_loadConfiguration
_archiveData
TB,V_ranLoad
T@"NSObject<MLModeling>",&,V_asset
T@"MLModelConfiguration",&,N,V_loadConfiguration
T@"NSDictionary",R,N,V_archiveData
T@"NSURL",R,V_compiledURL
T@"<MLModeling>",R,N
T@"<MLRegressor>",R,N
T@"<MLClassifier>",R,N
undefinedFeatureValueWithType:
featureValueWithInt64:
featureValueWithDouble:
featureValueWithString:
featureValueWithPixelBuffer:
featureValueWithMultiArray:
featureValueWithSequence:
featureValueWithDictionary:error:
featureValueWithStringKeyDictionary:
featureValueWithInt64KeyDictionary:
featureValueOfType:fromObject:error:
initWithValue:type:
initWithUndefinedValueAndType:
int64Value
doubleValue
stringValue
dictionaryValue
imageBufferValue
multiArrayValue
sequenceValue
objectValue
isEqualToFeatureValue:
getFeatureSize:
getFeatureSize:ndArrayMode:
isUndefined
value
setValue:
setObjectValue:
_undefined
_value
_objectValue
T@,&,V_value
T@"NSObject",&,N,V_objectValue
undefined
TB,R,N,GisUndefined,V_undefined
Td,R,N
T@"NSString",R,C,N
T@"MLMultiArray",R,N
T@"NSDictionary",R,N
T@"MLSequence",R,N
transposeA
transposeB
_transposeA
_transposeB
T@"NSNumber",R,N,V_transposeA
T@"NSNumber",R,N,V_transposeB
evaluateFunction:arguments:error:
newContextAndReturnError:
removeEngineForFunctionName:
initWithProgram:learningRate:error:
trainUsingTrainingData:error:
trainUsingTrainingData:evaluationMetricNames:error:
evaluateUsingTestData:error:
evaluateUsingTestData:evaluationMetricNames:error:
evaluateUsingTestData:evaluationMetricNames:evaluateOnTrainFunction:error:
attachLearningRateToFeatures:
inferenceModel
flattenFeatures:orderedFeatures:
orderedTrainableWeightsNames
copyCurrentTrainingDelta
setLearningRate:
setProgram:
evaluator
setEvaluator:
currentUpdatedWeights
setCurrentUpdatedWeights:
_learningRate
_evaluator
_currentUpdatedWeights
T@"<MLProgramInternal>",&,N,V_program
T@"MLProgramContext",&,N,V_context
T@"MLProgramEvaluator",&,N,V_evaluator
T@"<MLFeatureProvider>",&,N,V_currentUpdatedWeights
Td,N,V_learningRate
T@"<MLModeling>",R,C
initWithInnerModel:
clearInnerModelWithReason:
innerModel
setInnerModel:
reason
setReason:
_innerModel
_reason
T@"MLModel",&,V_innerModel
T@"NSString",&,N,V_reason
wrapperAroundWritableModel:
featureValueFromScenePrint:elementSize:
scenePrintRequestRevision
configuration
_scenePrintRequestRevision
_configuration
T@"MLModelDescription",R,N,V_modelDescription
TQ,R,N,V_scenePrintRequestRevision
T@"MLModelConfiguration",R,N,V_configuration
codedObjectURLFromInputArchiver:
codedObjectURLFromOutputArchiver:
_wordTaggingModel
sharedInstance
classesForLoadingModelType:
classesForLoadingModelType:isUpdatable:trainWithMLCompute:
classForCompilingModelType:
loadNeuralNetworkClasses:trainWithMLCompute:
createCoreMLToEspressoParamsMap
createEspressoTaskFrom:updateParameters:lossInputName:lossTargetName:lossOutputName:updatableLayerNames:configuration:error:
loadLossInputName:updatableLayerNames:fromCompiledArchive:
loadLossTargetName:lossOutputName:fromUpdateParameters:
initWithCompiledArchive:nnContainer:configuration:error:
updateWeightsAndBiasesFromConfigParams:error:
setWeightsOrBiasesForLayer:layerType:value:error:
updateLearningRateWithTaskContext:isInCallBack:error:
collectMetricsFromTaskContext:isInCallBack:
parameterValueForKey:
paramsForLayer:parameterType:error:
weightsForLayer:error:
biasForLayer:error:
snapshot
setSnapshot:
setLossTargetName:
coreMLToEspressoParamsMap
setCoreMLToEspressoParamsMap:
lossOutputName
setLossOutputName:
shuffableTrainingData
setShuffableTrainingData:
_snapshot
_coreMLToEspressoParamsMap
_lossOutputName
_shuffableTrainingData
T@"NSDictionary",&,N,V_coreMLToEspressoParamsMap
T@"NSString",&,N,V_lossOutputName
T@"NSString",&,N,V_lossTargetName
T@"MLShufflingBatchProvider",&,N,V_shuffableTrainingData
T@"ETTaskState",&,N,V_snapshot
T@"ETTaskDefinition",&,N,V_task
addOrientation:toOptions:
scenePrintsFromPixelBuffers:version:augmentationOptions:useCPUOnly:error:
elementCountForScenePrintRequestRevision:
lengthInBytesForScenePrintRequestRevision:
createPixelBufferFromVNImageBuffer:constraint:cropRect:cropAndScaleOption:options:error:
createPixelBufferFromImageAtURL:constraint:cropRect:cropAndScaleOption:options:error:
createPixelBufferFromCGImage:constraint:cropRect:cropAndScaleOption:options:error:
detectionPrintsFromPixelBuffers:version:augmentationOptions:useCPUOnly:error:
detectionPrintShapes:
detectionPrintSupportedRevisions
isValid
scenePrintsFromPixelBuffersImpl
scenePrintsFromPixelBuffersUsesCPUOnlyImpl
scenePrintElementCountImpl
scenePrintLengthImpl
VNImageBufferClass
detectionPrintsFromPixelBuffersImpl
detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
detectionPrintShapesImpl
detectionPrintSupportedRevisionsImpl
_validForSceneprint
_validForObjectprint
_scenePrintsFromPixelBuffersImpl
_scenePrintsFromPixelBuffersUsesCPUOnlyImpl
_scenePrintElementCountImpl
_scenePrintLengthImpl
_VNImageBufferClass
_detectionPrintsFromPixelBuffersImpl
_detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
_detectionPrintShapesImpl
_detectionPrintSupportedRevisionsImpl
T^?,R,N,V_scenePrintsFromPixelBuffersImpl
T^?,R,N,V_scenePrintsFromPixelBuffersUsesCPUOnlyImpl
T^?,R,N,V_scenePrintElementCountImpl
T^?,R,N,V_scenePrintLengthImpl
T#,R,N,V_VNImageBufferClass
T^?,R,N,V_detectionPrintsFromPixelBuffersImpl
T^?,R,N,V_detectionPrintsFromPixelBuffersUsesCPUOnlyImpl
T^?,R,N,V_detectionPrintShapesImpl
T^?,R,N,V_detectionPrintSupportedRevisionsImpl
validForSceneprint
TB,R,N,GisValid,V_validForSceneprint
validForObjectprint
TB,R,N,GisValid,V_validForObjectprint
secureModelWithContentsOfURL:sandboxExtensionToken:configuration:decryptCredential:withReply:
securePredictionFromLazyFeatures:options:withReply:
securePredictionFromLazyBatch:options:withReply:
secureParameterValueForKey:withReply:
secureModelMLFeatureValue:withReply:
secureModelMLDictionaryFeatureProvider:withReply:
secureModelMLModelDescription:withReply:
secureModelMLFeatureDescription:withReply:
createPersistentKeyBlobForKeyID:usesCodeSigningIdentityForEncryption:completionBlock:
startDecryptionOfModelAtPath:usingKeyBlob:usesCodeSigningIdentityForEncryption:completionBlock:
stopDecryptionOfModelAtPath:completionBlock:
extractTeamIdentifierWithReply:
clientFeatureValueForName:uniqueKeyForProvider:withReply:
clientFeatureNames:withReply:
sandboxExtensionPathsForModelURL:
sandboxExtensionTokenForModelURL:
modelWithContentsOfURL:configuration:decryptCredential:error:
modelWithContentsOfURL:decryptCredential:error:
connectionToModelSecurityService
setConnectionToModelSecurityService:
secureModelProxy
setSecureModelProxy:
_connectionToModelSecurityService
_secureModelProxy
T@"NSXPCConnection",&,N,V_connectionToModelSecurityService
T@"NSObject<CoreMLModelSecurityProtocol>",&,N,V_secureModelProxy
cryptoKey
setCryptoKey:
_cryptoKey
Tq,N,V_cryptoKey
featureProviderMap
setFeatureProviderMap:
featureProviderCount
setFeatureProviderCount:
serviceToClientQueue
setServiceToClientQueue:
_featureProviderMap
_featureProviderCount
_serviceToClientQueue
T@"NSMutableDictionary",&,N,V_featureProviderMap
T@"NSCountedSet",&,N,V_featureProviderCount
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceToClientQueue
initWithDictionaryFeatureProviderArray:
_convertStringClassVector:int64ClassVector:dimensions:toClassLabel:classType:andReturnError:
_setSingleArrayLookupField
_buildClassificationClasses:topk:error:
prepareInput:error:
_classes_by_string
_classes_by_int64_t
_class_type
_class_values
_single_array_key
initWithBatchProvider:batchSize:forPrediction:neuralNetworkEngine:error:
_featureEmbeddingModel
checkAssetPath:error:
createDecryptSessionForModelAtURL:configuration:decryptSession:loaderEvent:error:
loadModelFromAssetAtURL:error:
loadModelFromAssetAtURL:configuration:error:
loadModelFromAssetAtURL:configuration:loaderEvent:error:
loadUpdatableModelFromAssetAtURL:configuration:error:
unarchiveCodedModelFrom:to:error:
loadModelWithClass:fromArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
loadUpdatableModelWithClass:fromArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
populateLoaderAndPredictionEvent:model:configuration:loadTimeDuration:
loadModelFromArchive:error:
loadModelFromArchive:configuration:error:
loadModelFromArchive:configuration:loaderEvent:error:
loadUpdatableModelFromArchive:configuration:error:
loadModelFromArchive:configuration:loaderEvent:useUpdatableModelLoaders:error:
initWithType:concatenatedInputNames:bidirectional:
bidirectional
concatenatedInputNames
_bidirectional
_concatenatedInputNames
TB,R,N,V_bidirectional
T@"NSString",R,C,N,V_type
T@"NSString",R,C,N,V_concatenatedInputNames
parseCompiledNetworkBlobWithName:archive:error:
readerFromArchiver:error:
modelNetFileName
modelShapeFileName
loadUpdatableParams:
copyLayerShapesToContainer:
transformParams
layerInfos
initWithNetJson:shapeJson:modelPath:
netJson
shapeJson
_layerInfos
_netJson
_shapeJson
T@"NSDictionary",R,C,N,V_netJson
T@"NSDictionary",R,C,N,V_shapeJson
T@"NSString",R,C,N,V_modelPath
T@"NSArray",R,N,V_layerInfos
initWithNetwork:
readerFromArchive:error:
initWithContainer:program:error:
functionNameToOutputLayersNames
setFunctionNameToOutputLayersNames:
functionNameToInputLayersNames
setFunctionNameToInputLayersNames:
functionNameToInputShapes
_functionNameToOutputLayersNames
_functionNameToInputLayersNames
T@"NSDictionary",&,N,V_functionNameToOutputLayersNames
T@"NSDictionary",&,N,V_functionNameToInputLayersNames
T@"NSString",&,N
initWithProgramContainer:configuration:error:
updateModelFilePath:
programEngineForFunction:error:
verifyArgumentNames:functionName:error:
container
modelFileBasePath
_functionNameToEngineMap
_container
_modelFileBasePath
T@"MLMultiFunctionProgramContainer",R,N,V_container
T@"NSString",R,N,V_modelFileBasePath
start
stepSize
startValueParameter
endValueParameter
stepSizeValueParameter
_start
_stepSize
_startValueParameter
_endValueParameter
_stepSizeValueParameter
Ti,R,N,V_size
Tf,R,N,V_start
Tf,R,N,V_stepSize
Tf,R,N,V_startValueParameter
Tf,R,N,V_endValueParameter
Tf,R,N,V_stepSizeValueParameter
withBase2
_withBase2
TB,R,N,V_withBase2
hasSignedKeyRequest
setRawRequest:
setHasRawRequest:
hasRawRequest
signedKeyRequest
setSignedKeyRequest:
rawRequest
_signedKeyRequest
_rawRequest
T@"NSData",&,N,V_signedKeyRequest
TB,N,V_rawRequest
featureDescriptionWithName:type:optional:constraints:
initWithName:type:optional:contraints:
isAllowedValue:
multiArrayConstraint
imageConstraint
dictionaryConstraint
sequenceConstraint
allowsValuesWithDescription:
isOptional
valueConstraints
setValueConstraints:
multiArrayConstraintCached
imageConstraintCached
dictionaryConstraintCached
sequenceConstraintCached
_optional
_valueConstraints
_multiArrayConstraintCached
_imageConstraintCached
_dictionaryConstraintCached
_sequenceConstraintCached
T@"NSDictionary",&,V_valueConstraints
T@"MLMultiArrayConstraint",R,N,V_multiArrayConstraintCached
T@"MLImageConstraint",R,N,V_imageConstraintCached
T@"MLDictionaryConstraint",R,N,V_dictionaryConstraintCached
T@"MLSequenceConstraint",R,N,V_sequenceConstraintCached
T@"NSString",R,C,N,V_name
optional
TB,R,N,GisOptional,V_optional
findNearestNeighbors:toQueryPoint:
findNearestNeighbors:toIndex:
updateWithData:error:
dataPointCount
initWithDataset:numberOfDimensions:
numDataPoints
setNumDataPoints:
numDimensions
setNumDimensions:
vData
vDataL2Squared
_numDataPoints
_numDimensions
TQ,N,V_numDataPoints
TQ,N,V_numDimensions
version
setVersion:
featureExtractorParameters
setFeatureExtractorParameters:
postVisionFeaturePrintModel
setPostVisionFeaturePrintModel:
_version
_featureExtractorParameters
_postVisionFeaturePrintModel
T@,&,N,V_featureExtractorParameters
TQ,N,V_version
T@"MLModel",&,N,V_postVisionFeaturePrintModel
pipelineOfPostVisionFeaturePrintModelsFromPipeline:
visionFeaturePrintInfo
archivePipelineUpdateParameterForModels:to:updatable:
archiveCustomModelNames:to:
archivePipelineModelDetailsFrom:toArchive:error:
compileWithModelsInPipeline:toArchive:options:updatable:error:
classLabelsForPipelineFromSubModelArray:predictedFeatureName:
extractModelNamesFromArchive:numModels:
updateParameterDescriptionsByKeyBasedOnSubModel
initModelFromMetadataAndArchive:versionInfo:description:configuration:error:
initWithModels:modelNames:description:configuration:
replaceModelAtIndex:with:
models
setModels:
modelNames
setModelNames:
_models
_modelNames
T@"NSArray",&,V_models
T@"NSArray",&,V_modelNames
T@"MLSVREngine",&,V_engine
initWithSpecification:configuration:error:
initWithLRSpec:configuration:error:
intercept
postEvalTransForm
m_spec
initWithExecutionState:functionNameToStateMap:
executionState
setExecutionState:
trainFunctionLossName
setTrainFunctionLossName:
forwardFunctionLossName
setForwardFunctionLossName:
functionNameToStateMap
setFunctionNameToStateMap:
_executionState
_trainFunctionLossName
_forwardFunctionLossName
_functionNameToStateMap
T@"<MLFeatureProvider>",&,N,V_executionState
T@"NSString",&,N,V_trainFunctionLossName
T@"NSString",&,N,V_forwardFunctionLossName
T@"NSDictionary",&,N,V_functionNameToStateMap
getInternalFrameworkVersion
frameworkVersionNumber
setFrameworkVersionNumber:
_frameworkVersionNumber
T@"NSNumber",C,N,V_frameworkVersionNumber
_frontendProcessingModel
removeItemAndReturnError:
uniqueDirectoryURLInPath:
initSoundPrintParameters:
soundPrintVersion
_soundPrintVersion
Tq,R,V_soundPrintVersion
initWithSoundPrintParameters:
T@,R,V_featureExtractorParameters
initWithParameters:modelDescription:configuration:error:
T@"MLAppleAudioFeatureExtractorParameters",R,V_parameters
modelExecutionSchedule
setModelExecutionSchedule:
_modelExecutionSchedule
T@"NSDictionary",C,N,V_modelExecutionSchedule
initWithFlattenedModelUpdate:
flattenedModelUpdate
_flattenedModelUpdate
T@"NSData",R,N,V_flattenedModelUpdate
modelOriginNumberFromUserDefinedDictionary:
extractAndSetModelDetailsFromArchive:
numberFromCString:
modelLoadTime
setModelLoadTime:
modelLoadError
setModelLoadError:
bundleIdentifier
setBundleIdentifier:
firstPartyExecutable
setFirstPartyExecutable:
modelProgramValidationError
setModelProgramValidationError:
modelProgramParsingError
setModelProgramParsingError:
nnModelNetHash
setNnModelNetHash:
nnModelShapeHash
setNnModelShapeHash:
nnModelWeightsHash
setNnModelWeightsHash:
modelDimension
setModelDimension:
_modelLoadTime
_modelLoadError
_bundleIdentifier
_firstPartyExecutable
_modelProgramValidationError
_modelProgramParsingError
_nnModelNetHash
_nnModelShapeHash
_nnModelWeightsHash
_modelDimension
T@"NSString",C,N,V_nnModelNetHash
T@"NSString",C,N,V_nnModelShapeHash
T@"NSString",C,N,V_nnModelWeightsHash
T@"NSNumber",C,N,V_modelDimension
T@"NSNumber",C,N,V_modelLoadTime
T@"NSNumber",C,N,V_computeUnits
T@"NSNumber",C,N,V_modelLoadError
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_firstPartyExecutable
T@"NSNumber",C,N,V_modelIsEncrypted
T@"NSNumber",C,N,V_modelProgramValidationError
T@"NSNumber",C,N,V_modelProgramParsingError
targetShape
_targetShape
T@"NSArray",R,N,V_targetShape
_init
_initWithFlattenedTree:
_saveModelAssetWithModelToPath:withError:
_loadModelAssetWithModelAtPath:withError:
_makeInferenceFromAnswers:withError:
_attributes
set_attributes:
_objectStore
set_objectStore:
_trc
_treeClassifier
__attributes
__objectStore
T@"NSMutableArray",&,N,V__attributes
T@"NSMutableOrderedSet",&,N,V__objectStore
reporter
logMetric:
hashFileAt:error:
archiveModelDetails:withName:toArchive:error:
rank
begin_ids
begin_masks
end_ids
end_masks
_rank
_begin_ids
_begin_masks
_end_ids
_end_masks
_strides
Ti,R,N,V_rank
T@"NSArray",R,N,V_begin_ids
T@"NSArray",R,N,V_begin_masks
T@"NSArray",R,N,V_end_ids
T@"NSArray",R,N,V_end_masks
T@"NSArray",R,N,V_strides
emptySequenceWithType:
sequenceFromArray:error:
sequenceWithStringArray:
sequenceWithInt64Array:
initWithArray:type:
stringValues
int64Values
values
_values
T@"NSArray",R,N,V_values
initWrappingSequence:
sequence
_sequence
T@"MLSequence",R,N,V_sequence
featureValues
initWithMLBatchProvider:forPrediction:neuralNetworkEngine:error:
batchProvider
nnEngine
useForPrediction
_useForPrediction
_batchProvider
_nnEngine
T@"<MLBatchProvider>",R,N,V_batchProvider
T@"MLNeuralNetworkEngine",R,N,V_nnEngine
TB,R,N,V_useForPrediction
startDecryptionOfModelAtPath:usingKeyBlob:teamIdentifier:error:
stopDecryptionOfModelAtPath:error:
modelPathToSessionID
_modelPathToSessionID
_syncQueue
T@"NSMutableDictionary",R,&,V_modelPathToSessionID
T@"NSObject<OS_dispatch_queue>",R,&,V_syncQueue
decryptSessionForModelAtPath:usesCodeSigningIdentityForEncryption:keyBlob:error:
xpcConnection
setXpcConnection:
xpcProxy
setXpcProxy:
_xpcConnection
_xpcProxy
T@"NSString",C,N,V_modelPath
T@"NSXPCConnection",&,N,V_xpcConnection
T@"NSObject<CoreMLModelSecurityProtocol>",&,N,V_xpcProxy
leafSize
setLeafSize:
_leafSize
TQ,V_numberOfDimensions
Tq,V_weightingScheme
Tq,V_indexType
TQ,V_leafSize
T@"NSObject",&,V_defaultLabel
T@"NSString",&,V_nearestLabelsFeatureName
T@"NSString",&,V_nearestDistancesFeatureName
initWithPort:featureDescription:
bindAndReturnError:
_makeFeatureValueAndReturnError:
outputBacking
setOutputBacking:
_outputBacking
T@,&,V_outputBacking
createExtensionDataSourceWithInfoKey:conformingToProtocol:
activity
dataSource
_activity
_dataSource
T@"NSString",R,N,V_activity
T@"MLBackgroundTask",R,N,V_task
T@"<NSObject>",R,N,V_dataSource
defaultOptions
dryRun
setDryRun:
platform
setPlatform:
platformVersion
setPlatformVersion:
containerIsCloud
setContainerIsCloud:
allowsPixelBufferDirectBinding
setAllowsPixelBufferDirectBinding:
encryptModel
setEncryptModel:
keyInfoVersion
setKeyInfoVersion:
keyID
setKeyID:
usesCodeSigningIdentityForEncryption
setUsesCodeSigningIdentityForEncryption:
setIv:
sinf
setSinf:
mlsinf
setMlsinf:
specURL
setSpecURL:
mlProgramAddDuringCompilationMode
setMlProgramAddDuringCompilationMode:
_dryRun
_containerIsCloud
_allowsPixelBufferDirectBinding
_encryptModel
_usesCodeSigningIdentityForEncryption
_mlProgramAddDuringCompilationMode
_platform
_platformVersion
_keyInfoVersion
_keyID
_sinf
_mlsinf
_specURL
TB,V_dryRun
T@"NSString",&,V_platform
T@"NSString",&,V_platformVersion
TB,V_containerIsCloud
TB,V_allowsPixelBufferDirectBinding
TB,V_encryptModel
T@"NSNumber",C,V_keyInfoVersion
T@"NSString",C,V_keyID
T@"NSData",C,V_key
TB,V_usesCodeSigningIdentityForEncryption
T@"NSData",C,V_iv
T@"NSData",C,V_sinf
T@"NSData",C,V_mlsinf
T@"NSURL",C,V_specURL
Ti,V_mlProgramAddDuringCompilationMode
resultWithOutputFiles:
resultWithArchive:
outputFiles
setOutputFiles:
_outputFiles
T@"NSArray",&,V_outputFiles
compileSpecificationAtURL:toURL:options:error:
_compileSpecificationAtURL:toURL:compiledModelName:overridingModelDescription:options:error:
_updateMetadata:withMetadata:
_updateFeatures:withFeatures:
_updateSpecification:withModelDescription:
_loadSpecificationAtURL:to:error:
encryptCompiledModelAtURL:options:error:
versionInfo
encryptFileAtURL:options:error:
storeEncryptionInfoInCompiledArchive:options:error:
contentsOfDirectoryAtURL:error:
hashSpecificationAtURL:
fingerprintSpecificationAtURL:toArchive:hash:error:
compileSpecification:toArchive:options:compilerEvent:error:
compiledVersionForSpecificationAtURL:options:error:
compileModelAtURL:toURL:options:error:
addMLProgramToCompiledModelAtURL:error:
canAddMLProgramToCompiledModelAtURL:
compiledVersionForModelAtURL:options:error:
addMLProgramToCompiledModelAtURL:withCompilationMode:dryRun:oarchiveForModelCompilation:compilerEvent:error:
fillCompilerEvent:withMetadataFromModelAt:error:
saveModelToSpecification:
saveModelToAssetAtURL:model:error:
saveModelToArchive:model:error:
saveModelToArchive:model:compilerOptions:error:
copyModelAtURL:toURL:error:
asFeatureDictionaryWithPredictedClassDescription:classProbabilityDescription:
classifierResultFromOutputFeatures:error:
predictionFromFeatures:classifier:options:error:
coreChannel
progressEventsToString:
initForEvents:progressHandler:completionHandler:
_dispatchUpdateProgressHandlerForEvent:metrics:parameters:error:onQueue:
dispatchTrainingBeginProgressHandlerWithMetrics:parameters:onQueue:
dispatchEpochEndProgressHandlerWithMetrics:parameters:onQueue:
dispatchMiniBatchEndProgressHandlerWithMetrics:parameters:onQueue:
dispatchTrainingCompletionHandlerWithMetrics:parameters:onQueue:
dispatchTrainingCompletionHandlerWithError:onQueue:
interestedEvents
setInterestedEvents:
progressHandler
setProgressHandler:
completionHandler
setCompletionHandler:
_interestedEvents
_progressHandler
_completionHandler
Tq,V_interestedEvents
T@?,C,V_progressHandler
T@?,C,V_completionHandler
entryWithModelIdentifier:modelURL:
isEqualToModelCollectionEntry:
_initWithModelIdentifier:modelUrl:
modelIdentifier
_modelIdentifier
T@"NSString",R,N,V_modelIdentifier
T@"NSURL",R,N,V_modelURL
initWithE5BundleAtURL:modelDescription:classProbabilitiesFeatureName:
_predictionFromFeatures:options:error:
_predictionFromFeatures:options:usingStream:operation:error:
_outputFeaturesByAddingClassifierResultTo:classifyTopK:error:
_classifierResultFromOutputFeatures:classifyTopK:error:
_probabilityDictionaryWithMultiArray:classifyTopK:
_classProbabilitiesInOutputFeatures:error:
streamPool
operationPool
classProbabilitiesFeatureName
classLabelsSharedKey
_streamPool
_operationPool
_classProbabilitiesFeatureName
_classLabelsSharedKey
T@"MLE5ExecutionStreamPool",R,V_streamPool
T@"MLE5ExecutionStreamOperationPool",R,V_operationPool
T@"NSString",R,V_classProbabilitiesFeatureName
T@,R,V_classLabelsSharedKey
lossValue
epochIndex
miniBatchIndex
T@"MLMetricKey",R,N
generateSignpostId
modelWithContentsOfURL:error:
modelWithContentsOfURL:configuration:error:
loadContentsOfURL:configuration:completionHandler:
loadModelAsset:configuration:completionHandler:
initWithName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
enableInstrumentsTracingIfNeeded
decryptSession
setDecryptSession:
predictionEvent
setPredictionEvent:
signpostID
setSignpostID:
setConfiguration:
_emittedDetailsToInstruments
_decryptSession
_predictionEvent
_signpostID
TQ,N,V_signpostID
T@"MLPredictionEvent",&,N,V_predictionEvent
T@"MLModelDescription",&,N,V_modelDescription
T@"MLModelConfiguration",&,N,V_configuration
T@"MLFairPlayDecryptSession",&,N,V_decryptSession
T@"<MLProgram>",R
T@"MLModelMetadata",R,V_metadata
initScenePrintParameters:error:
scenePrintVersion
_scenePrintVersion
TQ,R,V_scenePrintVersion
initObjectPrintParameters:expectedShapes:expectedKeys:error:
objectPrintVersion
expectedShapes
expectedKeys
_objectPrintVersion
_expectedShapes
_expectedKeys
TQ,R,V_objectPrintVersion
T@"NSArray",R,V_expectedShapes
T@"NSArray",R,V_expectedKeys
initWithScenePrintParameters:error:
initWithObjectPrintParameters:error:
initWithParameters:modelDescription:featureExtractorType:configuration:error:
computeScenePrintFeatures:handle:useCPUOnly:error:
featureValueFromObjectPrint:key:shape:
_outputDataType
_extractorType
T@"MLAppleImageFeatureExtractorParameters",R,V_parameters
resolveExternalReferencesInSpecificationData:specificationURL:error:
initWithDescription:configuration:indexToStringLabelArray:indexToIntLabelArray:modelURL:error:
xgBoostDataFormatFromFeatureProvider:error:
xgBoostDataFormatFromBatchProvider:needLabels:error:
populateXGBoostDataFormat:trainingData:dataIndex:inputName:needLabels:error:
batchProviderFromXGboostResults:length:error:
featureProviderFromXGboostResults:length:error:
featureProviderArrayFromXGBoostResult:length:error:
packageOutputWithPredictedLabel:classProbabilities:
initializeBoosterIfOneExists
loadLabelsWithStringLabels:intLabels:
initializeAndvalidateObjectiveAndNumClassesWithConfiguration:error:
setObjective:
setNumClasses:
booster
setBooster:
_objective
_numClasses
_booster
T@"NSString",&,N,V_objective
TQ,N,V_numClasses
T^v,N,V_booster
resultWithValue:
resultWithValue:additionalFeatures:
initWithValue:additionalFeatures:
predictedValue
additionalFeatures
_predictedValue
_additionalFeatures
T@"MLMultiArray",R,V_predictedValue
T@"<MLFeatureProvider>",R,V_additionalFeatures
stridesForShape:
populateEspressoShapeAndStridesFromInputShape:ndRepresentation:espressoShape:espressoStrides:error:
populateShapeAndStrideFor:inputShape:outputShape:outputStrides:error:
espressoDataProviderFromFeatureProvider:forPrediction:neuralNetworkEngine:error:
espressoDataProviderFromBatchProvider:forPrediction:neuralNetworkEngine:error:
featureProviderFromEspressoDataProvider:neuralNetworkEngine:options:error:
batchProviderFromEspressoDataProvider:neuralNetworkEngine:options:error:
mlComputeDataProviderFromBatchProvider:batchSize:forPrediction:neuralNetworkEngine:error:
featureProviderFomMLComputeDataProvider:neuralNetworkEngine:options:error:
batchProviderFromMLComputeDataProvider:neuralNetworkEngine:options:error:
mlComputeDataTypeSize:
sizeFromShape:
loadUpdateParameters:fromCompiledArchive:error:
loadParameterDescriptionsAndContainerFromUpdateParameters:modelDescription:
createClassLabelToIndexMapWith:
featureTypeForObject:
featureTypeForValuesInArray:error:
featureDescriptionWithName:consistentWithFeatureValues:error:
featureValuesWithConsistentTypeFromArray:error:
descriptionForType:
canShapeArrayBePromotedFrom:to:
findFile:inSearchPath:basePath:
areFeaturesIn:modelNamed:aSubsetOf:error:
updateParameterDescriptionsByUnarchivingSpecification:
initWithLinkedModel:modelFileName:modelSearchPath:configuration:
linkedModel
setLinkedModel:
modelFileName
setModelFileName:
modelSearchPath
setModelSearchPath:
_linkedModel
_modelFileName
_modelSearchPath
T@"MLModel",&,V_linkedModel
T@"NSString",&,V_modelFileName
T@"NSString",&,V_modelSearchPath
numericConstraintWithMinNumber:maxNumber:
numericConstraintWithEnumeratedNumbers:
minNumber
setMinNumber:
maxNumber
setMaxNumber:
enumeratedNumbers
setEnumeratedNumbers:
_minNumber
_maxNumber
_enumeratedNumbers
T@"NSNumber",&,N,V_minNumber
T@"NSNumber",&,N,V_maxNumber
T@"NSSet",&,N,V_enumeratedNumbers
extractRecordTransports
substituteRecordTransports:
initWithTeamIdentifier:
fetchKeyResponseFromServerForKeyID:signedKeyRequest:error:
serviceName
setServiceName:
setContainer:
teamIdentifier
_serviceName
_teamIdentifier
T@"NSString",&,N,V_serviceName
T@"CKContainer",&,N,V_container
T@"NSString",R,C,N,V_teamIdentifier
saveCustomSequenceModelToURL:modelData:stringInputName:classname:NSError:
saveCustomWordTaggingModelToURL:modelData:stringInputName:classname:NSError:
saveCustomSentenceModelToURL:modelData:stringInputName:classname:NSError:
saveCustomSentenceClassifierModelToURL:modelData:stringInputName:classname:NSError:
getNetJson:error:
getLayerTypes:error:
getLayerHints:error:
updateHints:hints:error:
undoLastHintUpdate:error:
inputRank
multiples
inputShape
outputShape
_inputRank
_multiples
_inputShape
_outputShape
TQ,R,N,V_inputRank
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_multiples
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_inputShape
T{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}},R,N,V_outputShape
sinfData
addEncryptionHeaderToUnencryptedFile:saveToFile:error:
encryptFile:withKey:iv:saveToFile:error:
T@"NSData",R,&,N
countByEnumeratingWithState:objects:count:
dictionary
setDictionary:
_dictionary
T@"NSDictionary",&,N,V_dictionary
initWithFeatureProvider:featureNames:
initWithFeatureProvider:
initWithFeatureValueDictionary:
featureValueWithObject:
T@"MLSVMEngine",&,V_engine
isModelEncrypted:
decryptSessionForModelAtURL:error:
initFromCompiledArchive:modelVersionInfo:compilerVersionInfo:configuration:error:
updatableModelIndicies
dispatchQueue
setDispatchQueue:
_dispatchQueue
_updatableModelIndicies
T{vector<unsigned long long, std::allocator<unsigned long long>>=^Q^Q{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>=^Q}},R,V_updatableModelIndicies
T@"MLUpdateProgressHandlers",&,V_progressHandlers
T@"NSObject<OS_dispatch_queue>",&,V_dispatchQueue
populateInputNameToShapeMap:fromContainer:forFunction:program:withValidation:error:
updateOptionalDefaultValueParametersInContainer:usingProgram:
loadProgramAtURL:error:
loadProgramFromCompiledArchive:error:
resultWithStringClassProbability:
resultWithIntClassProbability:
resultWithStringClassProbability:additionalFeatures:
resultWithIntClassProbability:additionalFeatures:
resultWithClassProbability:additionalFeatures:classLabelOfMaxProbability:
initWithStringClassProbability:classFeatureType:additionalFeatures:
initWithIntClassProbability:classFeatureType:additionalFeatures:
initWithClassProbability:additionalFeatures:classLabelOfMaxProbability:
predictedClass
classProbability
predictedClassFeatureType
_predictedClass
_classProbability
_predictedClassFeatureType
T@"MLFeatureValue",R,V_predictedClass
T@"NSDictionary",R,V_classProbability
Tq,R,V_predictedClassFeatureType
featureValueFromDetectionPrint:featureName:
detectionPrintRequestRevision
expectedOutputShapeV1
_detectionPrintRequestRevision
_expectedOutputShapeV1
TQ,R,N,V_detectionPrintRequestRevision
T@"NSDictionary",R,N,V_expectedOutputShapeV1
step
_step
T@"NSNumber",R,N,V_step
T@"NSNumber",R,N,V_size
initWithLossType:optimizerType:optimizerParameters:lossParameters:trainableLayerNames:updateParameters:
writeUpdatableParamsToURL:error:
unarchiveUpdatableParamsAtURL:error:
lossType
setLossType:
optimizerType
setOptimizerType:
optimizerParameters
setOptimizerParameters:
lossParameters
setLossParameters:
trainableLayerNames
setTrainableLayerNames:
_lossType
_optimizerType
_optimizerParameters
_lossParameters
_trainableLayerNames
Tq,N,V_lossType
Tq,N,V_optimizerType
T@"NSDictionary",&,N,V_optimizerParameters
T@"NSDictionary",&,N,V_lossParameters
T@"NSArray",&,N,V_trainableLayerNames
hasMessage
message
setMessage:
_message
T@"NSString",&,N,V_message
initWithData:language:inputFeatureName:outputFeatureName:modelData:labelNames:error:
saveAppleTextClassifierModelToURL:textClassifierParameters:error:
textClassifierModel
T@"MLAppleTextClassifierParameters",R,V_parameters
initWithProgram:error:
updateContext:functionName:result:
prepareArgumentsFromFeatures:context:forFunctionName:
evaluateFunction:arguments:context:updateContext:error:
evaluateFunction:arguments:context:error:
findMin:andMax:alongDimension:data:indices:numDimensions:
partitionDataPoints:indices:numDimensions:
assignSplitsForData:indices:numDimensions:
print
splitDimension
setSplitDimension:
splitIndex
setSplitIndex:
splitValue
setSplitValue:
startingIndex
setStartingIndex:
setCount:
leftChild
setLeftChild:
rightChild
setRightChild:
boundingBox
setBoundingBox:
isLeaf
setIsLeaf:
_isLeaf
_splitValue
_splitDimension
_splitIndex
_startingIndex
_count
_leftChild
_rightChild
_boundingBox
TQ,N,V_splitDimension
TQ,N,V_splitIndex
Tf,N,V_splitValue
TQ,N,V_startingIndex
TQ,N,V_count
T@"_KDNode",&,N,V_leftChild
T@"_KDNode",&,N,V_rightChild
T{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q},N,V_boundingBox
TB,N,V_isLeaf
initWithDataset:numberOfDimensions:leafSize:error:
constructTree
constructTreeForPointsBoundedBy:startingIndex:count:
calculateDistancesForNodesBetweenLeft:andRight:toQueryPoint:
findK:nearestNeighbors:toQueryPoint:inTree:
root
setRoot:
vIndices
_root
TQ,N,V_leafSize
T@"_KDNode",&,N,V_root
initWithBatchProvider:seed:
setBatchProvider:
indices
randomNumberGenerator
T@"<MLBatchProvider>",&,V_batchProvider
createCustomLayer:withParameters:error:
loss
setLoss:
evaluationMetrics
setEvaluationMetrics:
_loss
_evaluationMetrics
Td,V_loss
T@"<MLBatchProvider>",&,V_evaluationMetrics
suppressionMethod
setSuppressionMethod:
iouThreshold
setIouThreshold:
confidenceThreshold
setConfidenceThreshold:
minBoxes
setMinBoxes:
maxBoxes
setMaxBoxes:
perClass
setPerClass:
confidenceInputFeatureName
setConfidenceInputFeatureName:
coordinatesInputFeatureName
setCoordinatesInputFeatureName:
iouThresholdInputFeatureName
setIouThresholdInputFeatureName:
confidenceThresholdInputFeatureName
setConfidenceThresholdInputFeatureName:
confidenceOutputFeatureName
setConfidenceOutputFeatureName:
coordinatesOutputFeatureName
setCoordinatesOutputFeatureName:
_perClass
_suppressionMethod
_iouThreshold
_confidenceThreshold
_minBoxes
_maxBoxes
_confidenceInputFeatureName
_coordinatesInputFeatureName
_iouThresholdInputFeatureName
_confidenceThresholdInputFeatureName
_confidenceOutputFeatureName
_coordinatesOutputFeatureName
Ti,V_suppressionMethod
Td,V_iouThreshold
Td,V_confidenceThreshold
TQ,V_minBoxes
Tq,V_maxBoxes
TQ,V_numClasses
TB,V_perClass
T@"NSString",&,V_confidenceInputFeatureName
T@"NSString",&,V_coordinatesInputFeatureName
T@"NSString",&,V_iouThresholdInputFeatureName
T@"NSString",&,V_confidenceThresholdInputFeatureName
T@"NSString",&,V_confidenceOutputFeatureName
T@"NSString",&,V_coordinatesOutputFeatureName
T@"MLNonMaximumSuppressionParameters",R,V_parameters
vectorizeInput:error:
predictionsFromLoopingOverBatch:model:options:error:
predictionsFromSubbatchingBatch:maxSubbatchLength:predictionBlock:options:error:
executeAndReturnError:
_executeStream:error:
reset
operations
setOperations:
streamHandle
setStreamHandle:
_operations
_streamHandle
T^{e5rt_execution_stream=},V_streamHandle
T@"NSArray",C,V_operations
T{vector<int, std::allocator<int>>=^i^i{__compressed_pair<int *, std::allocator<int>>=^i}},R,N,V_shape
initWithState:
resumeWithTaskContext:
updateModelAtURL:trainingData:configuration:writeToURL:error:
updateTaskForModelAtURL:trainingData:configuration:completionHandler:error:
updateTaskForModelAtURL:trainingData:completionHandler:error:
updateTaskForModelAtURL:trainingData:configuration:progressHandlers:error:
updateTaskForModelAtURL:trainingData:progressHandlers:error:
onResumptionWithTaskContext:
onSuspensionWithTaskContext:
onCancellation
onCompletionWithTaskContext:
onFailureWithTaskContext:
initWithModelAtURL:trainingData:configuration:progressHandlers:error:
resumeWithParameters:
_invokeProgressHandlerForContext:
_progressHandlerBlock
_completionHandlerBlock
updatableModel
trainingData
updateHasStarted
setUpdateHasStarted:
updateQueue
updatableModelURL
_updateHasStarted
_updatableModel
_trainingData
_updateQueue
_updatableModelURL
T@"MLModel<MLUpdatable>",R,N,V_updatableModel
T@"<MLBatchProvider>",R,N,V_trainingData
T@"MLUpdateProgressHandlers",R,N,V_progressHandlers
TB,N,V_updateHasStarted
T@"NSObject<OS_dispatch_queue>",R,N,V_updateQueue
T@"NSURL",R,N,V_updatableModelURL
initializeWordTaggingModelWithData:error:
initializeSentenceClassifierModelWithData:error:
initializeGazetteerModelWithData:error:
initializeEmbeddingModelWithData:error:
predictTokensLabelsLocationsLengthsForString:inputString:error:
predictLabelsForSentenceString:inputString:error:
predictLabelForWordString:inputString:error:
predictVectorForString:inputString:error:
NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
NLPSequenceModelCreateWithDataImpl
NLPSequenceModelGetRevisionImpl
NLPSequenceModelIsRevisionSupportedImpl
NLPSequenceModelGetCurrentRevisionImpl
NLPClassifierModelCopyPredictedLabelForTextImpl
NLPClassifierModelCreateWithDataImpl
NLPClassifierModelGetRevisionImpl
NLPClassifierModelIsRevisionSupportedImpl
NLPClassifierModelGetCurrentRevisionImpl
NLPGazetteerModelCopyLabelForStringImpl
NLPGazetteerModelCreateWithDataImpl
NLPGazetteerModelGetRevisionImpl
NLPGazetteerModelIsRevisionSupportedImpl
NLPGazetteerModelGetCurrentRevisionImpl
NLPEmbeddingModelCopyVectorForStringImpl
NLPEmbeddingModelCreateWithDataImpl
NLPEmbeddingModelGetRevisionImpl
NLPEmbeddingModelIsRevisionSupportedImpl
NLPEmbeddingModelGetCurrentRevisionImpl
_valid
_NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
_NLPSequenceModelCreateWithDataImpl
_NLPSequenceModelGetRevisionImpl
_NLPSequenceModelIsRevisionSupportedImpl
_NLPSequenceModelGetCurrentRevisionImpl
_NLPClassifierModelCopyPredictedLabelForTextImpl
_NLPClassifierModelCreateWithDataImpl
_NLPClassifierModelGetRevisionImpl
_NLPClassifierModelIsRevisionSupportedImpl
_NLPClassifierModelGetCurrentRevisionImpl
_NLPGazetteerModelCopyLabelForStringImpl
_NLPGazetteerModelCreateWithDataImpl
_NLPGazetteerModelGetRevisionImpl
_NLPGazetteerModelIsRevisionSupportedImpl
_NLPGazetteerModelGetCurrentRevisionImpl
_NLPEmbeddingModelCopyVectorForStringImpl
_NLPEmbeddingModelCreateWithDataImpl
_NLPEmbeddingModelGetRevisionImpl
_NLPEmbeddingModelIsRevisionSupportedImpl
_NLPEmbeddingModelGetCurrentRevisionImpl
T^?,R,N,V_NLPSequenceModelCopyPredictedTokensAndLabelsForTextImpl
T^?,R,N,V_NLPSequenceModelCreateWithDataImpl
T^?,R,N,V_NLPSequenceModelGetRevisionImpl
T^?,R,N,V_NLPSequenceModelIsRevisionSupportedImpl
T^?,R,N,V_NLPSequenceModelGetCurrentRevisionImpl
T^?,R,N,V_NLPClassifierModelCopyPredictedLabelForTextImpl
T^?,R,N,V_NLPClassifierModelCreateWithDataImpl
T^?,R,N,V_NLPClassifierModelGetRevisionImpl
T^?,R,N,V_NLPClassifierModelIsRevisionSupportedImpl
T^?,R,N,V_NLPClassifierModelGetCurrentRevisionImpl
T^?,R,N,V_NLPGazetteerModelCopyLabelForStringImpl
T^?,R,N,V_NLPGazetteerModelCreateWithDataImpl
T^?,R,N,V_NLPGazetteerModelGetRevisionImpl
T^?,R,N,V_NLPGazetteerModelIsRevisionSupportedImpl
T^?,R,N,V_NLPGazetteerModelGetCurrentRevisionImpl
T^?,R,N,V_NLPEmbeddingModelCopyVectorForStringImpl
T^?,R,N,V_NLPEmbeddingModelCreateWithDataImpl
T^?,R,N,V_NLPEmbeddingModelGetRevisionImpl
T^?,R,N,V_NLPEmbeddingModelIsRevisionSupportedImpl
T^?,R,N,V_NLPEmbeddingModelGetCurrentRevisionImpl
valid
TB,R,N,GisValid,V_valid
extractTeamIdentifierAndReturnError:
sharedFeatureFlags
defineFeatures
isMPSGraphEnabled
isMPSGraphFP16Enabled
addFeature:withControlName:defaultValue:
isFeatureEnabled:
controlKeyForFeature:
setOverride:forFeature:
removeOverrideForFeature:
userDefaults
flags
overrideOriginalValues
_userDefaults
_flags
_overrideOriginalValues
T@"NSUserDefaults",R,N,V_userDefaults
T@"NSMutableDictionary",R,N,V_flags
T@"NSMutableDictionary",R,N,V_overrideOriginalValues
predictionEventQueue
featuresPredictionCountSoFar
featuresPredictionDuration
maybeLogPredictionEvent:
_featuresPredictionCountSoFar
_featuresPredictionDuration
initWithUsesCPUOnly:
predictionUsesCPU
usesCPUOnly
setUsesCPUOnly:
outputBackings
setOutputBackings:
parentSignpostID
setParentSignpostID:
classifyTopK
setClassifyTopK:
automaticOutputBackingMode
setAutomaticOutputBackingMode:
maxComputationBatchSize
setMaxComputationBatchSize:
enablePixelBufferDirectBinding
setEnablePixelBufferDirectBinding:
_usesCPUOnly
_enablePixelBufferDirectBinding
_outputBackings
_parentSignpostID
_classifyTopK
_automaticOutputBackingMode
_maxComputationBatchSize
TQ,N,V_parentSignpostID
TQ,V_classifyTopK
T@"NSDictionary",C,N,V_automaticOutputBackingMode
TQ,V_maxComputationBatchSize
TB,N,V_enablePixelBufferDirectBinding
TB,N,V_usesCPUOnly
T@"NSDictionary",C,N,V_outputBackings
initWithData:language:inputFeatureName:tokensFeatureName:tokenTagsFeatureName:tokenLocationsFeatureName:tokenLengthsFeatureName:modelData:tagNames:metadata:error:
initWithData:language:inputFeatureName:tokensFeatureName:tokenTagsFeatureName:tokenLocationsFeatureName:tokenLengthsFeatureName:modelData:tagNames:error:
tokensOutputFeatureName
setTokensOutputFeatureName:
tokenTagsOutputFeatureName
setTokenTagsOutputFeatureName:
tokenLocationsOutputFeatureName
setTokenLocationsOutputFeatureName:
tokenLengthsOutputFeatureName
setTokenLengthsOutputFeatureName:
tagNames
setTagNames:
_tokensOutputFeatureName
_tokenTagsOutputFeatureName
_tokenLocationsOutputFeatureName
_tokenLengthsOutputFeatureName
_tagNames
T@"NSString",&,V_tokensOutputFeatureName
T@"NSString",&,V_tokenTagsOutputFeatureName
T@"NSString",&,V_tokenLocationsOutputFeatureName
T@"NSString",&,V_tokenLengthsOutputFeatureName
T@"NSArray",&,V_tagNames
saveAppleWordTaggingModelToURL:wordTaggerParameters:error:
wordTaggingModel
T@"MLAppleWordTaggerParameters",R,V_parameters
featureNamesInBatch:
featureProviderArrayFromBatch:
dictionaryFromBatch:featureNames:
dictionaryFromBatch:
featureValueArrayForName:batch:error:
featureDescriptionsByNameForBatch:error:
initWithFeaturesFrom:addedToFeaturesFrom:error:
T@"<MLBatchProvider>",&,N,V_first
T@"<MLBatchProvider>",&,N,V_second
initWithBatch:startIndex:windowLength:error:
fullBatch
setFullBatch:
startIndex
setStartIndex:
windowLength
setWindowLength:
_fullBatch
_startIndex
_windowLength
T@"<MLBatchProvider>",&,N,V_fullBatch
Tq,N,V_startIndex
Tq,N,V_windowLength
initWithBatch:indices:error:
setIndices:
_indices
T@"NSArray",&,N,V_indices
lazyBatchWindowIntoBatch:startIndex:windowLength:error:
lazyBatchIndexIntoBatch:indices:error:
lazyBatchWithFeaturesInBatch:addedToBatch:error:
batchFromConcatinatingBatches:
batchWithSubsetOfFeaturesNamed:fromBatch:
vectorizeFeaturesNamed:fromBatch:intoRowsOfDoubleMatrix:error:
hasData
data
setData:
_data
T@"NSData",&,N,V_data
initWithContentsOfURL:functionName:outputDescriptionsByName:debugLabel:
outputFeatures
_createOperationAndReturnError:
_newArrayOfUnboundedPortsForPortNames:featureDescriptionsByName:portFactoryFunction:error:
_newArrayOfInputPortsBoundToFeatures:error:
_newArrayOfBoundedOutputPortsUsingOutputBackings:error:
_inputPortNames
_outputPortNames
inputFeatures
setInputFeatures:
operationHandle
setOperationHandle:
debugLabel
inputPorts
setInputPorts:
outputPorts
setOutputPorts:
state
setState:
_inputFeatures
_operationHandle
_debugLabel
_inputPorts
_outputPorts
_state
T@"NSString",R,C,V_functionName
T^{e5rt_execution_stream_operation=},V_operationHandle
T@"NSArray",C,V_inputPorts
T@"NSArray",C,V_outputPorts
Tq,V_state
T@"<MLFeatureProvider>",&,V_inputFeatures
T@"<MLFeatureProvider>",R
T@"NSString",R,C,V_debugLabel
imputeValueFrom:replaceValue:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
imputeValueFrom:replaceValue:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
initWith:imputeValue:replaceValue:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
imputeValue
replaceValue
_imputeValue
_replaceValue
T@"MLFeatureValue",R,N,V_imputeValue
T@"MLFeatureValue",R,N,V_replaceValue
loadFromModelSpecificationInArchive:withClass:versionInfo:configuration:error:
versionForSerializedSpecification:options:error:
serializeSpecification:toArchive:error:
serializeInterfaceFormat:archive:error:
deserializeInterfaceFormat:archive:error:
rangeFromAllowedSizeRangeProtoMessage:
populateConstraintsForImageFeatureDescription:
populateConstraintsForImageFeatureDescriptionElement:
populateConstraintsForFeatureDescription:
descriptionFromProto:
orderedNamesFromProto:
serializeVersionInfo:archive:error:
deserializeVersionInfoFromArchive:error:
serializeMetadataAndInterfaceFromSpecification:archive:error:
deserializeMetadataAndInterfaceFromArchive:error:
inputDescriptionFromInterface:
outputDescriptionFromInterface:
trainingInputDescriptionFromInterface:
orderedFeatureNamesFromInterface:forInput:
specificationURLFromModelAtURL:error:
classify:error:
calculateClassProbability:input:error:
classify:topK:error:
classType
classEncoding
initWithValueDescription:countRange:
valueDescription
countRange
_valueDescription
_countRange
T@"MLFeatureDescription",R,N,V_valueDescription
T{_NSRange=QQ},R,N,V_countRange
transformKeyIdentifier:error:
generateKeyRequestForKeyIdentifier:teamIdentifier:error:
generatePersistentKeyBlobFromKeyResponse:error:
keyIdentifier
setKeyIdentifier:
sessionID
setSessionID:
_sessionID
_keyIdentifier
T@"NSString",C,V_keyIdentifier
TI,V_sessionID
createMetaData:
getImageFeatureTypeFromConstraint:
getArrayFeatureTypeFromConstraint:
getDictionaryFeatureTypeFromConstraint:error:
getSequenceFeatureTypeFromConstraint:error:
createFeatureTypeFromFeatureDescription:error:
copyFeatureDescriptionFrom:to:error:
createModelDescription:error:
saveModelDescription:toSpecification:error:
validateAllFeatureDescriptions:hasAnyFeatureTypeIn:minimalCount:maximumCount:debugLabel:error:
initWithCompiledArchive:configuration:error:
loadParameterDescriptionsAndContainerFromConfiguration:modelDescription:error:
setBoosterParameters:error:
personalization
setPersonalization:
classesByString
setClassesByString:
classesByInt
setClassesByInt:
mmappedModel
setMmappedModel:
cachedModel
setCachedModel:
_personalization
_mmappedModel
_classesByString
_classesByInt
_cachedModel
TB,N,V_personalization
T{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}},N,V_classesByString
T{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}},N,V_classesByInt
T{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}},N,V_mmappedModel
T{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}},N,V_cachedModel
initWithName:
initWithName:shortDescription:versionString:author:license:creatorDefined:
shortDescription
author
license
creatorDefined
_shortDescription
_versionString
_author
_license
_creatorDefined
T@"NSString",R,V_shortDescription
T@"NSString",R,V_versionString
T@"NSString",R,V_author
T@"NSString",R,V_license
T@"NSDictionary",R,V_creatorDefined
initWith:dimensionEncoding:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
vectorizeOneHotEncoderDict:index:error:
columnNameEncoding
dimensionEncoding
_output_array_shape
index_mapping
_columnNameEncoding
_dimensionEncoding
T@"NSArray",R,N,V_columnNameEncoding
T@"NSArray",R,N,V_dimensionEncoding
unsignedIntegerValue
visionCropAndScaleOptionFromOptions:
cropRectFromOptions:
featureValueWithImageAtURL:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:constraint:options:error:
featureValueWithCGImage:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithCGImage:constraint:options:error:
featureValueWithImageAtURL:orientation:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithImageAtURL:orientation:constraint:options:error:
featureValueWithCGImage:orientation:pixelsWide:pixelsHigh:pixelFormatType:options:error:
featureValueWithCGImage:orientation:constraint:options:error:
categoryName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
categoryName:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:error:
initWith:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
constructDictionary:error:
categoryName
_categoryName
T@"NSOrderedSet",R,N,V_categoryName
compileModelWithoutAutoreleaseAtURL:options:error:
_compileModelAtURL:options:error:
compileModelAtURL:error:
compileModelAtURL:completionHandler:
inputDescriptionFrom:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
normFrom:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
normFrom:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
initWith:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
norm
_norm
Ti,R,N,V_norm
initWithData:language:inputFeatureName:outputFeatureName:modelData:metadata:error:
initWithData:language:inputFeatureName:outputFeatureName:modelData:error:
saveAppleWordEmbeddingModelToURL:wordEmbeddingParameters:error:
wordEmbeddingModel
T@"MLAppleWordEmbeddingParameters",R,V_parameters
_canResume
_canCancel
_canSuspend
_canComplete
_canFail
_resumeWithTaskContext:
resume
cancel
suspendWithTaskContext:
completeWithTaskContext:
failWithError:taskContext:
taskStatesToString:
T@"NSError",C,V_error
T@"NSObject<OS_dispatch_queue>",R,N,V_syncQueue
T@"NSString",R,C,N,V_taskIdentifier
initWithMapping:valueOnUnknown:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
mapFeature:error:
mapping
valueOnUnknown
_mapping
_valueOnUnknown
T@"NSDictionary",R,N,V_mapping
T@"MLFeatureValue",R,N,V_valueOnUnknown
initWith:scaleValue:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:error:
shiftValue
scaleValue
_shiftValue
_scaleValue
T@"MLFeatureValue",R,N,V_shiftValue
T@"MLFeatureValue",R,N,V_scaleValue
parameterDescriptionForKey:int64ParameterSpec:
parameterDescriptionForKey:doubleParameterSpec:
parameterDescriptionForKey:stringParameterSpec:
parameterDescriptionForKey:boolParameterSpec:
featureEncoderFrom:inputDescription:orderedInputFeatureNames:
featureEncoderFrom:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
featureEncoderFrom:dataTransformerName:ouputSparse:handleUnknown:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
initWith:dataTransformerName:ouputSparse:handleUnknown:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
encodeFeatureValue:
unknownDenseVector
encodeFeatureValueIntString:
featureEncoding
ouputSparse
handleUnknown
_ouputSparse
_handleUnknown
_featureEncoding
T@"NSOrderedSet",R,N,V_featureEncoding
TB,R,N,V_ouputSparse
TB,R,N,V_handleUnknown
globalSettings
globalSettingsFromSettings:
deviceHasANE
restrictNeuralNetworksToUseCPUOnly
setRestrictNeuralNetworksToUseCPUOnly:
restrictNeuralNetworksFromUsingANE
setRestrictNeuralNetworksFromUsingANE:
isNeuralNetworkGPUPathForbidden
_restrictNeuralNetworksToUseCPUOnly
_restrictNeuralNetworksFromUsingANE
_isNeuralNetworkGPUPathForbidden
TB,V_restrictNeuralNetworksToUseCPUOnly
TB,V_restrictNeuralNetworksFromUsingANE
TB,R,N,V_isNeuralNetworkGPUPathForbidden
setFeatureName:to:descriptions:
validateModelDescription:
updateModelFromFeatures:toTarget:options:error:
setInputFeatureName:to:
setOutputFeatureName:to:
setFeatureCount:
FeatureCount
initWithDescription:numberOfFeatures:priorMean:regressionInputName:optimismInputName:samplingScaleInputName:samplingTruncationInputName:meanOutputName:varianceOutputName:pessimisticProbabilityOutputName:sampledProbabilityOutputName:
initWithDescription:numberOfFeatures:priorMean:
getArrayFeatureValue:
getOneHotFeatureValues:error:
createRegressorResult:
getFeatureValue:forName:withType:
getOptimism:
getSamplingScale:
getSamplingTruncation:
convertOutputFeatureToPredictionValues:event:importance:error:
updateModelFromFeatures:toTarget:error:
isEqualToBopr:
createCheckpoint
resetToLastCheckpointBeforeDate:
_regressionInputFeatureName
_optimismInputFeatureName
_meanOutputFeatureName
_varianceOutputFeatureName
_pessimisticProbabilityOutputFeatureName
_sampledProbabilityOutputFeatureName
_samplingScaleInputFeatureName
_samplingTruncationInputFeatureName
initWithLabels:
indexOfLabel:
uniqueLabelCount
labelAtIndex:
labelEnumerator
_labelToIndex
_labels
T@"NSEnumerator",R,N
probabilityAtIndex:
maxElementIndex
initWithMultiArray:count:
initWithFloat64CArray:count:
initWithArray:count:
sharedKeySetForLabels:
initWithLabelIndexMap:storage:
initWithSharedKeySet:probabilityMultiArray:
initWithSharedKeySet:probabilities:
initWithSharedKeySet:probabilityArray:
initWithLabels:probabilityArray:
initWithLabels:probabilities:
initWithObjects:forKeys:count:
classLabelOfMaxProbability
objectForKey:
keyEnumerator
labelIndexMap
storage
_labelIndexMap
_storage
T@"MLProbabilityDictionarySharedKeySet",R,V_labelIndexMap
T@"<MLProbabilityDictionaryStorage>",R,V_storage
initWithScopedModelAndLayerName:layerName:
appendPathComponent:
isEqualToMLLayerPath:
scopedModelNames
setScopedModelNames:
setLayerName:
_scopedModelNames
T@"NSString",C,N,V_layerName
T@"NSArray",C,N,V_scopedModelNames
constraintWithShape:dataType:shapeConstraint:
constraintWithShape:dataType:
initWithShape:dataType:shapeConstraint:
isAllowedDataType:error:
isAllowedValue:isNeuralNetworkInputOrOutput:usingRank5Mapping:featureName:error:
shapeConstraint
_dataType
_shapeConstraint
Tq,R,N,V_dataType
T@"MLMultiArrayShapeConstraint",R,N,V_shapeConstraint
initWithPixelsWideRange:pixelsHighRange:
initWithEnumeratedImageSizes:
enumeratedImageSizes
isAllowedImageSize:error:
pixelsWideRange
pixelsHighRange
imageSizeSet
_imageSizeSet
_pixelsWideRange
_pixelsHighRange
T@"NSOrderedSet",R,N,V_imageSizeSet
T{_NSRange=QQ},R,N,V_pixelsWideRange
T{_NSRange=QQ},R,N,V_pixelsHighRange
allowedImageSizeClosestToPixelsWide:pixelsHigh:preferDownScaling:preferInputAspectRatio:
locationClosestTo:inRange:
closestImageSizeInPixelsWideRange:pixelsHighRange:toImageSize:preferInputAspectRatio:
closestImageSizeInArray:toImageSize:preferDownScaling:
extractArrayElement:indices:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
extractArrayElement:indices:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:
initWith:indices:dataTransformerName:inputDescription:outputDescription:orderedInputFeatureNames:orderedOutputFeatureNames:configuration:
arrayColumnName
extractIndices
outputType
_arrayColumnName
_extractIndices
_outputType
T@"NSString",R,N,V_arrayColumnName
T@"NSArray",R,N,V_extractIndices
Tq,R,N,V_outputType
watchdogWithTimeout:queue:
watchdogWithTimeout:label:queue:
invalidate
timer
setTimer:
_timer
T@"NSObject<OS_dispatch_source>",&,V_timer
@32@0:8@16^@24
@40@0:8@16@24^@32
@16@0:8
v32@0:8@16@24
v24@0:8@16
@"<MLFeatureProvider>"32@0:8@"<MLFeatureProvider>"16^@24
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"32@0:8@"<MLBatchProvider>"16^@24
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelExecutionSchedule"16@0:8
v32@0:8@"MLLayerPath"16@"NSString"24
@"MLLayerPath"16@0:8
@"MLModelDescription"16@0:8
v24@0:8@"MLModelDescription"16
@"MLModelMetadata"16@0:8
@"NSArray"16@0:8
@"MLClassifierResult"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@40@0:8@16@24@32
v16@0:8
@"NSURL"
@"NSString"
@"NSDictionary"
@"NSMutableSet"
@"NSObject<OS_dispatch_queue>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@32@0:8Q16^@24
@"NSDictionary"32@0:8Q16^@24
@44@0:8@16B24@28^@36
@"NSDictionary"16@0:8
@"NSNumber"
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B32@0:8@16^@24
B32@0:8@"MLFeatureValue"16^@24
@24@0:8^{_NSZone=}16
@24@0:8q16
q16@0:8
@40@0:8@16#24@32
@32@0:8@16@24
v32@0:8^v16Q24
v40@0:8@16@24@32
B24@0:8Q16
@"NSArray"32@0:8@"NSArray"16@"NSDictionary"24
@24@0:8@"NSDictionary"16
v32@0:8@"NSArray"16@"NSArray"24
v40@0:8@"<MTLCommandBuffer>"16@"NSArray"24@"NSArray"32
@"NSArray"24@0:8@"NSArray"16
@"NSArray"
@"MLFeatureValue"16@0:8
@24@0:8^{e5rt_io_port=}16
^{e5rt_io_port=}16@0:8
^{e5rt_io_port=}
@"MLFeatureValue"
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"MLModelDescription"
i16@0:8
v20@0:8i16
v20@0:8B16
@20@0:8i16
i24@0:8@16
@"ModelKeyServerAPIRawKey"
@"ModelKeyServerAPISignedKey"
{?="key"b1}
@32@0:8@16@?24
v32@0:8@16@?24
B24@0:8@?16
@"TRIClient"
@"MLModelConfiguration"
@"MLPredictionOptions"
v24@0:8^v16
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8r^v16
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8Q16
f24@0:8Q16
d24@0:8r^v16
d24@0:8Q16
d24@0:8@16
@"<MLNearestNeighborsIndex>"
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"MLParameterContainer"
@32@0:8^{e5rt_io_port=}16^@24
@32@0:8q16q24
@80@0:8Q16@24@32@40@48@56@64^@72
v24@0:8Q16
@"NSData"
@40@0:8^v16@24^@32
B40@0:8@16@24^@32
@"<MLModeling>"40@0:8^v16@"MLModelConfiguration"24^@32
@56@0:8@16@24@32@40^@48
@"MLAppleGazetteerParameters"
@40@0:8@16q24^@32
@72@0:8^v16@24q32@40@?48@?56^@64
@64@0:8^v16@24q32@40@?48^@56
@32@0:8{shared_ptr<CoreML::MultiArrayBuffer>=^{MultiArrayBuffer}^{__shared_weak_count}}16
@32@0:8^{__CVBuffer=}16@24
@24@0:8Q16
v32@0:8@16Q24
v32@0:8@16q24
Q24@0:8@16
^v16@0:8
^{__CVBuffer=}16@0:8
{unique_ptr<StorageManager, std::default_delete<StorageManager>>="__ptr_"{__compressed_pair<StorageManager *, std::default_delete<StorageManager>>="__value_"^{StorageManager}}}
v24@0:8@?16
r^v16@0:8
B24@0:8q16
^d16@0:8
^f16@0:8
i24@0:8q16
@48@0:8@16q24q32^@40
@48@0:8@16q24q32Q40
@56@0:8^v16@24q32@40@?48
@32@0:8@16q24
@40@0:8@16@24q32
B40@0:8@16q24^@32
B48@0:8@16^Q24^Q32^@40
B48@0:8@16q24^Q32^@40
@40@0:8@16q24q32
B40@0:8@16Q24^@32
@"MLMultiArray"
B32@0:8@16@24
v48@0:8@16@24^@32^@40
@52@0:8@16@24@32B40^@44
@44@0:8@16@24B32^@36
@32@0:8{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}}16
@24@0:8{unique_ptr<MIL::IRProgram, std::default_delete<MIL::IRProgram>>={__compressed_pair<MIL::IRProgram *, std::default_delete<MIL::IRProgram>>=^{IRProgram}}}16
@32@0:8{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}16
{shared_ptr<Espresso::net>=^{net}^{__shared_weak_count}}16@0:8
{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}16@0:8
{shared_ptr<Espresso::net>="__ptr_"^{net}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<MIL::IRProgram>="__ptr_"^{IRProgram}"__cntrl_"^{__shared_weak_count}}
@"MLParameterKey"
@"MLNumericConstraint"
@48@0:8@16@24@32^@40
@40@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16B24B28Q32
^{svm_node=id}24@0:8Q16
v40@0:8^{svm_node=id}16r^d24Q32
v24@0:8^{svm_node=id}16
^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16@0:8
v24@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16
^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}
B32@0:8^{__CVBuffer=}16^@24
B36@0:8^{__CVBuffer=}16B24^@28
^{__CVBuffer=}32@0:8@16^@24
^{__CVBuffer=}36@0:8@16B24^@28
@48@0:8q16@24@32*40
@40@0:8q16@24*32
@40@0:8q16@24@32
@32@0:8q16@24
@28@0:8i16@20
v32@0:8^v16r^v24
B40@0:8^v16^v24^@32
@48@0:8^v16^v24@32^@40
@"MLCompilerResult"48@0:8^v16^v24@"MLCompilerOptions"32^@40
@"MLVersionInfo"40@0:8^v16@"MLCompilerOptions"24^@32
@48@0:8@16@24@32@40
B24@0:8^v16
@64@0:8^v16@24@32@40@48^@56
@56@0:8^v16@24@32@40^@48
@68@0:8@16@24@32@40@48B56@60
@76@0:8@16@24@32@40@48B56@60@68
{map<std::string, int, std::less<std::string>, std::allocator<std::pair<const std::string, int>>>="__tree_"{__tree<std::__value_type<std::string, int>, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, int>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, int>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, int>, std::less<std::string>, true>>="__value_"Q}}}
@"MLModel"
@"MLNeuralNetworksCompileTimeParams"
@"MLVersionInfo"
@"MLCompilerNeuralNetworkOutput"
@36@0:8{CGSize=dd}16I32
{CGSize=dd}16@0:8
I16@0:8
{CGSize="width"d"height"d}
@"MLRegressorResult"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@56@0:8^v16@"MLVersionInfo"24@"MLVersionInfo"32@"MLModelConfiguration"40^@48
@28@0:8^{__CVBuffer=}16I24
^{__CVBuffer=}28@0:8^{__CVBuffer=}16I24
^{__CVPixelBufferPool=}36@0:8{CGSize=dd}16I32
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
^{__CVBuffer=}32@0:8@16@24
v36@0:8@16q24i32
i32@0:8@16^@24
B28@0:8B16^@20
B36@0:8@16B24^@28
B32@0:8^v16^@24
B40@0:8@16B24B28^@32
B56@0:8@16@24Q32@40^@48
q32@0:8@16^@24
B48@0:8@16^{__CVBuffer=}24@32^@40
B40@0:8^{__CVBuffer=}16@24^@32
B48@0:8@16@24Q32^@40
B48@0:8@16Q24@32^@40
B48@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^@40
B56@0:8@16@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32^i40^@48
B56@0:8r^v16@24@32@40^@48
B24@0:8^@16
v52@0:8^@16^@24^{?=^v^v[4Q][4Q]QQQQQQQQQQi}32@40B48
@48@0:8@16Q24@32^@40
B32@0:8r^v16^@24
@48@0:8Q16@24@32^@40
B48@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16Q24^{__CVBuffer=}32^@40
@48@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16^{__CVBuffer=}24@32^@40
@56@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24@32@40^@48
^{__CVBuffer=}40@0:8^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@24^@32
@40@0:8@16^@24^@32
B80@0:8^v16^v24^v32^v40^v48^v56^v64^@72
Q20@0:8i16
{?=^vi}16@0:8
v32@0:8{?=^vi}16
{vector<std::map<std::string, espresso_buffer_t *>, std::allocator<std::map<std::string, espresso_buffer_t *>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::map<std::string, espresso_buffer_t *> *, std::allocator<std::map<std::string, espresso_buffer_t *>>>="__value_"^v}}
{map<std::string, Espresso::vimage2espresso_param, std::less<std::string>, std::allocator<std::pair<const std::string, Espresso::vimage2espresso_param>>>="__tree_"{__tree<std::__value_type<std::string, Espresso::vimage2espresso_param>, std::__map_value_compare<std::string, std::__value_type<std::string, Espresso::vimage2espresso_param>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, Espresso::vimage2espresso_param>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, Espresso::vimage2espresso_param>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, Espresso::vimage2espresso_param>, std::less<std::string>, true>>="__value_"Q}}}
{vector<bool, std::allocator<bool>>="__begin_"^Q"__size_"Q"__cap_alloc_"{__compressed_pair<unsigned long, std::allocator<unsigned long>>="__value_"Q}}
{set<std::string, std::less<std::string>, std::allocator<std::string>>="__tree_"{__tree<std::string, std::less<std::string>, std::allocator<std::string>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::string, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::less<std::string>>="__value_"Q}}}
{basic_string<char, std::char_traits<char>, std::allocator<char>>="__r_"{__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>="__value_"{__rep=""(?="__l"{__long="__data_"*"__size_"Q"__cap_"Q}"__s"{__short="__data_"[23c]""{?="__size_"C}}"__r"{__raw="__words"[3Q]})}}}
{map<std::string, bool, std::less<std::string>, std::allocator<std::pair<const std::string, bool>>>="__tree_"{__tree<std::__value_type<std::string, bool>, std::__map_value_compare<std::string, std::__value_type<std::string, bool>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, bool>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, bool>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, bool>, std::less<std::string>, true>>="__value_"Q}}}
@"NSMutableDictionary"
^{OpaqueVTPixelTransferSession=}
@"NSObject<OS_dispatch_semaphore>"
@"EspressoProfilingNetworkInfo"
{?="plan"^v"network_index"i}
@32@0:8^v16^@24
@"NSObject<MLCustomModel>"
v24@0:8q16
@"<MTLDevice>"
@64@0:8Q16@24q32@40Q48q56
@"<MLFeatureProvider>"24@0:8q16
B32@0:8@"NSURL"16^@24
v32@0:8@"MLUpdateProgressHandlers"16@"NSObject<OS_dispatch_queue>"24
v24@0:8@"<MLBatchProvider>"16
v24@0:8@"NSDictionary"16
@"MLModel<MLUpdatable>"56@0:8^v16@"MLVersionInfo"24@"MLVersionInfo"32@"MLModelConfiguration"40^@48
@64@0:8@16@24@32^v40@48^@56
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}24@0:8@16
v32@0:8^@16^v24
v56@0:8^@16^@24{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32
@"MLUpdateProgressHandlers"
@"NSOrderedSet"
@"NSObject"
@24@0:8^v16
@80@0:8@16@24@32@40@48@56@64@72
@64@0:8@16@24@32@40@48@56
@56@0:8@16@24@32@40@48
@"MLLayerPath"
@"MLPipeline"
r*16@0:8
B40@0:8@16^v24^@32
{vector<unsigned char, std::allocator<unsigned char>>="__begin_"*"__end_"*"__end_cap_"{__compressed_pair<unsigned char *, std::allocator<unsigned char>>="__value_"*}}
{vector<double, std::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::allocator<double>>="__value_"^d}}
{vector<unsigned long long, std::allocator<unsigned long long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>="__value_"^Q}}
{vector<std::pair<unsigned long long, double>, std::allocator<std::pair<unsigned long long, double>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<unsigned long long, double> *, std::allocator<std::pair<unsigned long long, double>>>="__value_"^v}}
@36@0:8^{__CVBuffer=}16B24^@28
@32@0:8^{__CVBuffer=}16^@24
@40@0:8^{e5rt_io_port=}16@24@32
@"MLFeatureDescription"
@"<MLE5PortBinder>"
@40@0:8^{_MLModelSpecification=}16@24^@32
@56@0:8^{_MLModelInputArchiver=}16@24@32@40^@48
@48@0:8q16q24q32@40
@56@0:8@16@24q32@40@48
@48@0:8q16@24@32@40
@"MLUpdateTask"
@"MLModel<MLWritable>"
@"NSError"
@"ModelKeyServerAPIResultError"
@"ModelKeyServerAPIFetchKeyResult"
{?="result"b1}
@48@0:8^{svm_model={svm_parameter=iiidddddi^i^dddii}ii^^{svm_node}^^d^d^d^d^i^i^ii}16B24B28Q32@40
v32@0:8@16^d24
B48@0:8@16@24@32^@40
@32@0:8@"NSDictionary"16^@24
B32@0:8@"NSArray"16^@24
@"NSArray"32@0:8@"NSArray"16^@24
B40@0:8@"NSArray"16@"NSArray"24^@32
B48@0:8@"<MTLCommandBuffer>"16@"NSArray"24@"NSArray"32^@40
@28@0:8@16B24
@"NSObject<MLCustomLayer>"
B48@0:8@16^d24Q32^@40
B64@0:8@16@24^d32Q40Q48^@56
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"<MLFeatureProvider>"
d32@0:8@16^@24
d24@0:8^d16
v32@0:8^d16^d24
B28@0:8I16Q20
@48@0:8q16q24Q32@40
@40@0:8q16q24Q32
@20@0:8I16
Q20@0:8I16
@"MLImageSizeConstraint"
B40@0:8@16^B24^@32
@24@0:8^@16
@"NSObject<MLModeling>"
@24@0:8d16
@24@0:8^{__CVBuffer=}16
@40@0:8q16@24^@32
d16@0:8
@28@0:8^@16B24
@"<MLFeatureProvider>"40@0:8@"NSString"16@"<MLFeatureProvider>"24^@32
@"MLProgramContext"24@0:8^@16
v24@0:8@"NSString"16
@40@0:8@16d24^@32
v24@0:8d16
@"<MLProgramInternal>"
@"MLProgramContext"
@"MLProgramEvaluator"
@32@0:8@16Q24
@28@0:8i16B20B24
#20@0:8i16
@24@0:8B16B20
@80@0:8@16^v24@32@40@48@56@64^@72
v40@0:8^@16^@24^v32
@48@0:8^v16@24@32^@40
@40@0:8@16Q24^@32
@"ETTaskState"
@"ETTaskDefinition"
@"MLShufflingBatchProvider"
@28@0:8I16@20
@52@0:8^{__CVBuffer=}16Q24@32B40^@44
Q24@0:8Q16
^{__CVBuffer=}88@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32Q64@72^@80
^{__CVBuffer=}88@0:8^{CGImage=}16@24{CGRect={CGPoint=dd}{CGSize=dd}}32Q64@72^@80
^?16@0:8
v56@0:8@16@24@32@40@?48
v40@0:8@16@24@?32
v36@0:8@16B24@?28
v44@0:8@16@24B32@?36
v56@0:8@"NSURL"16@"NSString"24@"MLModelConfiguration"32@"MLSecureModelDecryptCredential"40@?<v@?@"MLSecureModel"@"NSError">48
v40@0:8@"NSNumber"16@"MLPredictionOptions"24@?<v@?@"MLDictionaryFeatureProvider"@"NSError">32
v40@0:8@"NSArray"16@"MLPredictionOptions"24@?<v@?@"MLArrayDictionaryFeatureProvider"@"NSError">32
v32@0:8@"MLKey"16@?<v@?@@"NSError">24
v32@0:8@"MLFeatureValue"16@?<v@?@"MLFeatureValue"@"NSString">24
v32@0:8@"MLDictionaryFeatureProvider"16@?<v@?@"MLDictionaryFeatureProvider"@"NSString">24
v32@0:8@"MLModelDescription"16@?<v@?@"MLModelDescription"@"NSString">24
v32@0:8@"MLFeatureDescription"16@?<v@?@"MLFeatureDescription"@"NSString">24
v36@0:8@"NSString"16B24@?<v@?@"NSData"@"NSError">28
v44@0:8@"NSString"16@"NSData"24B32@?<v@?@"NSError">36
v32@0:8@"NSString"16@?<v@?@"NSError">24
v24@0:8@?<v@?@"NSString"@"NSError">16
v40@0:8@"NSString"16@"NSNumber"24@?<v@?@"MLFeatureValue"@"NSError">32
v32@0:8@"NSNumber"16@?<v@?@"NSSet"@"NSError">24
@"NSXPCConnection"
@"NSObject<CoreMLModelSecurityProtocol>"
@"NSCountedSet"
B64@0:8r^v16r^v24Q32^@40^q48^@56
@40@0:8^d16Q24^@32
{vector<std::string, std::allocator<std::string>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::string *, std::allocator<std::string>>="__value_"^v}}
{vector<long long, std::allocator<long long>>="__begin_"^q"__end_"^q"__end_cap_"{__compressed_pair<long long *, std::allocator<long long>>="__value_"^q}}
@52@0:8@16Q24B32@36^@44
@"<MLCustomModel>"
B56@0:8@16@24^@32@40^@48
B40@0:8^v16^@24^@32
@64@0:8#16^v24@32@40@48^@56
v48@0:8@16@24@32Q40
@52@0:8^v16@24@32B40^@44
@36@0:8@16@24B32
@40@0:8@16^v24^@32
@"MLNeuralNetworksCompileTimeParams"24@0:8^@16
v24@0:8@"MLNeuralNetworkContainer"16
@40@0:8@16r^v24^@32
{map<std::string, InputNameToShapes, std::less<std::string>, std::allocator<std::pair<const std::string, InputNameToShapes>>>="__tree_"{__tree<std::__value_type<std::string, InputNameToShapes>, std::__map_value_compare<std::string, std::__value_type<std::string, InputNameToShapes>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, InputNameToShapes>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, InputNameToShapes>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, InputNameToShapes>, std::less<std::string>, true>>="__value_"Q}}}
@"MLMultiFunctionProgramContainer"
f16@0:8
{?="rawRequest"b1}
@44@0:8@16q24B32@36
@"MLMultiArrayConstraint"
@"MLImageConstraint"
@"MLDictionaryConstraint"
@"MLSequenceConstraint"
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32@0:8Q16r^v24
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}32@0:8Q16Q24
@48@0:8{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}16Q40
v36@0:8r^v16^v24B32
v32@0:8r^v16^v24
B40@0:8r^v16^v24^@32
@52@0:8r^v16^v24@32B40^@44
@32@0:8^v16Q24
v32@0:8Q16@24
@"MLSVREngine"
{vector<std::vector<double>, std::allocator<std::vector<double>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::vector<double> *, std::allocator<std::vector<double>>>="__value_"^v}}
{shared_ptr<CoreML::Specification::Model>="__ptr_"^{Model}"__cntrl_"^{__shared_weak_count}}
@"MLAppleAudioFeatureExtractorParameters"
@24@0:8r*16
@"MLTreeEnsembleClassifier"
@"NSMutableArray"
@"NSMutableOrderedSet"
v24@0:8@"<CUTMetric>"16
B48@0:8r^v16r^v24^v32^@40
@"MLSequence"
@"<MLBatchProvider>"
@"MLNeuralNetworkEngine"
@32@0:8^{e5rt_io_port=}16@24
@"MLBackgroundTask"
@"<NSObject>"
@64@0:8@16@24@32@40@48^@56
v32@0:8^v16@24
B40@0:8^v16@24^@32
B48@0:8@16^v24@32^@40
@56@0:8^v16^v24@32@40^@48
@56@0:8@16i24B28^v32@40^@48
^v24@0:8^@16
B48@0:8^v16@24@32^@40
@40@0:8q16@?24@?32
v56@0:8q16@24@32@40@48
@?16@0:8
@"MLE5ExecutionStreamPool"
@"MLE5ExecutionStreamOperationPool"
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
@"MLModelMetadata"
@"MLFairPlayDecryptSession"
@"MLPredictionEvent"
@52@0:8@16@24i32@36^@44
@44@0:8^{__CVBuffer=}16@24B32^@36
@"MLAppleImageFeatureExtractorParameters"
@96@0:8@16@24{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}32{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}56@80^@88
{?={vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}QQ}32@0:8@16^@24
{?={vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}QQ}36@0:8@16B24^@28
v60@0:8^v16@24q32@40B48^@52
@40@0:8r^f16Q24^@32
@64@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}40
B52@0:8@16B24^@28^@36^@44
B56@0:8@16@24^@32^@40^@48
Q24@0:8q16
@32@0:8r^v16@24
q24@0:8@16
v24@0:8r^v16
@"NSSet"
v24@0:8@"NSArray"16
@"CKContainer"
B56@0:8@16@24@32@40^@48
{vector<unsigned long, std::allocator<unsigned long>>=^Q^Q{__compressed_pair<unsigned long *, std::allocator<unsigned long>>=^Q}}16@0:8
{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
@"MLSVMEngine"
{vector<unsigned long long, std::allocator<unsigned long long>>=^Q^Q{__compressed_pair<unsigned long long *, std::allocator<unsigned long long>>=^Q}}16@0:8
B60@0:8^v16@24r^v32r^v40B48^@52
v32@0:8@16r^v24
{unique_ptr<MIL::IRProgram, std::default_delete<MIL::IRProgram>>={__compressed_pair<MIL::IRProgram *, std::default_delete<MIL::IRProgram>>=^{IRProgram}}}32@0:8@16^@24
{shared_ptr<MIL::IRProgram>=^{IRProgram}^{__shared_weak_count}}32@0:8^v16^@24
@40@0:8@16q24@32
@64@0:8q16q24@32@40@48@56
@72@0:8Q16@24@32@40@48@56^@64
@"MLAppleTextClassifierParameters"
v64@0:8^f16^f24Q32r^f40r^Q48Q56
v40@0:8r^f16^Q24Q32
v20@0:8f16
{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q}16@0:8
v48@0:8{_KDBoundingBox={vector<_KDInterval, std::allocator<_KDInterval>>=^{_KDInterval}^{_KDInterval}{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>=^{_KDInterval}}}Q}16
@"_KDNode"
{_KDBoundingBox="_intervals"{vector<_KDInterval, std::allocator<_KDInterval>>="__begin_"^{_KDInterval}"__end_"^{_KDInterval}"__end_cap_"{__compressed_pair<_KDInterval *, std::allocator<_KDInterval>>="__value_"^{_KDInterval}}}"_numDimensions"Q}
@48@0:8^v16Q24Q32^@40
@40@0:8^v16Q24Q32
{vector<std::pair<unsigned long, float>, std::allocator<std::pair<unsigned long, float>>>=^v^v{__compressed_pair<std::pair<unsigned long, float> *, std::allocator<std::pair<unsigned long, float>>>=^v}}40@0:8Q16Q24r^v32
v48@0:8Q16^v24r^v32@40
{vector<long, std::allocator<long>>="__begin_"^q"__end_"^q"__end_cap_"{__compressed_pair<long *, std::allocator<long>>="__value_"^q}}
{linear_congruential_engine<unsigned int, 48271U, 0U, 2147483647U>="__x_"I}
@"NSObject<MLCustomLayer>"40@0:8@"NSString"16@"NSDictionary"24^@32
@"MLNonMaximumSuppressionParameters"
@56@0:8@16q24@?32@40^@48
B32@0:8^{e5rt_execution_stream=}16^@24
^{e5rt_execution_stream=}16@0:8
v24@0:8^{e5rt_execution_stream=}16
^{e5rt_execution_stream=}
{vector<int, std::allocator<int>>=^i^i{__compressed_pair<int *, std::allocator<int>>=^i}}16@0:8
{vector<int, std::allocator<int>>="__begin_"^i"__end_"^i"__end_cap_"{__compressed_pair<int *, std::allocator<int>>="__value_"^i}}
@56@0:8@16@24@32@?40^@48
@48@0:8@16@24@?32^@40
v24@0:8@"NSObject"16
@"MLModel<MLUpdatable>"
r^v32@0:8@16^@24
v36@0:8@16@24B32
B28@0:8B16@20
@"NSUserDefaults"
@20@0:8B16
@104@0:8Q16@24@32@40@48@56@64@72@80@88^@96
@96@0:8Q16@24@32@40@48@56@64@72@80^@88
@"MLAppleWordTaggerParameters"
@48@0:8@16Q24Q32^@40
^{e5rt_execution_stream_operation=}24@0:8^@16
@48@0:8@16@24^?32^@40
^{e5rt_execution_stream_operation=}16@0:8
v24@0:8^{e5rt_execution_stream_operation=}16
^{e5rt_execution_stream_operation=}
@72@0:8@16@24@32@40@48@56^@64
@80@0:8@16@24@32@40@48@56@64^@72
@88@0:8@16@24@32@40@48@56@64@72^@80
@56@0:8^v16#24@32@40^@48
@40@0:8^v16^v24^@32
{_NSRange=QQ}24@0:8r^v16
@24@0:8r^v16
@28@0:8^v16B24
B40@0:8^d16@24^@32
@40@0:8@16{_NSRange=QQ}24
{_NSRange=QQ}16@0:8
{_NSRange="location"Q"length"Q}
v20@0:8I16
^v24@0:8@16
^v32@0:8@16^@24
v40@0:8@16^v24^@32
B64@0:8@16@24Q32Q40@48^@56
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16@0:8
v40@0:8{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}16
{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}16@0:8
v40@0:8{vector<long long, std::allocator<long long>>=^q^q{__compressed_pair<long long *, std::allocator<long long>>=^q}}16
{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<Archiver::MMappedFile>=^{MMappedFile}^{__shared_weak_count}}16
{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16@0:8
v40@0:8{vector<unsigned char, std::allocator<unsigned char>>=**{__compressed_pair<unsigned char *, std::allocator<unsigned char>>=*}}16
{shared_ptr<Archiver::MMappedFile>="__ptr_"^{MMappedFile}"__cntrl_"^{__shared_weak_count}}
{vector<std::pair<unsigned long, unsigned long>, std::allocator<std::pair<unsigned long, unsigned long>>>="__begin_"^v"__end_"^v"__end_cap_"{__compressed_pair<std::pair<unsigned long, unsigned long> *, std::allocator<std::pair<unsigned long, unsigned long>>>="__value_"^v}}
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
@60@0:8@16q24q32I40@44^@52
@60@0:8^{CGImage=}16q24q32I40@44^@52
@48@0:8^{CGImage=}16@24@32^@40
@64@0:8@16I24q28q36I44@48^@56
@52@0:8@16I24@28@36^@44
@64@0:8^{CGImage=}16I24q28q36I44@48^@56
@52@0:8^{CGImage=}16I24@28@36^@44
@52@0:8i16@20@28@36@44
@60@0:8i16@20@28@36@44@52
@68@0:8i16@20@28@36@44@52@60
@64@0:8Q16@24@32@40@48^@56
@"MLAppleWordEmbeddingParameters"
@32@0:8@16r^v24
@72@0:8@16@24B32B36@40@48@56@64
@80@0:8@16@24B32B36@40@48@56@64@72
B40@0:8^@16@24@32
B48@0:8@"<MLFeatureProvider>"16@"<MLFeatureProvider>"24@"MLSupervisedOnlineUpdateOptions"32^@40
B32@0:8^@16@24
@104@0:8@16q24@32@40@48@56@64@72@80@88@96
{shared_ptr<CoreML::BayesianProbitRegression::FeatureValues>=^{FeatureValues}^{__shared_weak_count}}32@0:8@16^@24
@24@0:8^{Prediction=dddddB}16
d40@0:8@16@24q32
B48@0:8@16^B24^d32^@40
{shared_ptr<CoreML::BayesianProbitRegression::BayesianProbitRegression>=^{BayesianProbitRegression}^{__shared_weak_count}}16@0:8
{shared_ptr<CoreML::BayesianProbitRegression::BayesianProbitRegression>="__ptr_"^{BayesianProbitRegression}"__cntrl_"^{__shared_weak_count}}
@"NSNumber"24@0:8Q16
@32@0:8r^d16Q24
@32@0:8@16r^d24
@40@0:8r^@16r^@24Q32
@"MLProbabilityDictionarySharedKeySet"
@"<MLProbabilityDictionaryStorage>"
B32@0:8q16^@24
B48@0:8@16B24B28@32^@40
@"MLMultiArrayShapeConstraint"
@48@0:8{_NSRange=QQ}16{_NSRange=QQ}32
@40@0:8q16q24B32B36
Q40@0:8Q16{_NSRange=QQ}24
@60@0:8{_NSRange=QQ}16{_NSRange=QQ}32@48B56
@72@0:8@16@24@32@40@48@56@64
@32@0:8d16@24
@40@0:8d16@24@32
@"NSObject<OS_dispatch_source>"
