@(#)PROGRAM:SiriTTSService  PROJECT:SiriTTSService-1
?mcpl
?NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_0NS_9allocatorIS2_EEFvRKNS_6vectorIfNS3_IfEEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIfNS_9allocatorIfEEEEEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_0
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_1
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_2NS_9allocatorIS2_EEFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS3_IS7_EEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS_9allocatorIS4_EEEEEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_2
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_3
N5apple4aiml12flatbuffers216DefaultAllocatorE
N5apple4aiml12flatbuffers29AllocatorE
SiriTTSService
AudioPlaybackError
AudioRouteInfo
AudioData
AudioPlayback
BufferedAudioPlayback
AudioPower
AudioPowerProviding
AudioInterface
AudioQueueInterface
AudioQueueBufferUserData
_NSRange
CMSampleBuffer
NCMSampleBufferRef
CMTime
AudioTimeStamp
ThermalState
NNSProcessInfoThermalState
URLResourceKey
NNSURLResourceKey
Name
NNSNotificationName
AudioQueueLevelMeterState
AudioStreamPacketDescription
AudioStreamBasicDescription
Foundation
TRIOnDemandFactorDownloadStatus
CFString
NCFStringRef
TTSAssetVoiceGender
TTSAssetProperty
CMTimeFlags
AudioTimeStampFlags
SMPTETime
SMPTETimeFlags
SMPTETimeType
SiriTTSService
DiagnosticService
MetricsJsonKeys
CacheReadingAction
VoiceAttribute
TTSAssetStubStrategy
MappedData
PassThroughAction
SynthesisConfigProviding
InlineStreamingStorage
EngineCachingService
SignpostHandler
MobileGestalt
Features
NeuralUtils
Locked
Flags
RetryTextModificationAction
OspreyClient
r@TTSAssetTrialAsset
TTSAssetTrialVoiceAsset
TTSAssetTrialResourceAsset
TTSAssetAdhocStrategy
TextToPhonemeAction
TTSAssetStrategy
SiriFeatures
TTSAssetFeatures
Event
NotificationHandling
OptionalNotificationHandling
TTSAssetTrialProxyInstantiatedAsset
TTSAssetProxyCallback
TTSAssetProxyProgressCallback
TTSAssetProxyPathCallback
TTSAssetProxyStrategy
ProxyKey
TTSAssetMAStrategy
DownloadSourceExtractor
OSVersion
TTSAssetTrialStrategy
AssetClass
WorkflowErrorHandler
Workflow
DataContainer
Buffer
Actionable
Conditional
AsynchronousContext
Asynchronous
WorkflowNode
WorkflowCondition
SynthesisCacheWritingAction
Constants
DaemonXPCAllowedTypeSets
Entitlements
TTSAssetProxyAsset
SynthesisEngineSelectionAction
DependencyInjectable
ObjectPool
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-GD
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
TTSAssetMAAsset
TTSAssetMACompactAsset
DefaultMacinTalkProperties
DefaultVocalizerProperties
PreinstalledWordTimingStorage
AudioPowerHandler
supo
OpusEncodingAction
InternalSettings
Default
InlineStreamingAction
TTSError
TTSErrorCode
DirectedAcyclicGraph
Languages
RequestPreprocessAction
TTSAssetStaticVoice
TTSAssetAdhocVoice
TTSAssetPreinstalledVoice
TTSAssetStaticResource
TTSAssetAdhocResource
Localization
DelegateHandler
AudioFile
AudioDumpAction
AssistantAsset
AssistantVoiceMaps
HasAudioCondition
CoreAnalyticsInterface
CoreAnalyticsService
CoreAnalyticsSynthesisHandler
TrialAssetProvider
VoiceAsset
ResourceAsset
LocalAssetProvider
BuiltInVoiceProvider
VocalizerCustomVoiceProvider
PreinstalledVoiceProvider
OspreyTTSAction
VoiceSelectionAction
RequestParsingAction
Logger
AVSBARPlayback
AudioMappedInfoAVSBAR
AudioPlaybackServiceState
Timeout
AudioPlaybackAction
TTSAssetPreinstalledStrategy
DeviceSynthesisAction
Preferences
OpusEncoder
CacheStorage
SynthesisCacheFile
SynthesisCacheChunkIterator
SynthesisCache
CodingKeys
TTSAssetLegacyAsset
VoiceDescription
VoiceSpec
PreinstalledAudioStorage
OspreyConfigProviding
OspreyBuiltInConfig
OspreyChainedConfigs
WeakDaemonDelegateWrapper
DaemonConnection
SiriTTSService
WordTimingInfo
InstrumentationMetrics
SourceOfTTS
AudibleContext
ProsodyProperties
SynthesisContext
SynthesisProfile
BaseRequest
AudioRequest
SynthesisRequest
PhonemeRequest
PhonemeSystem
SpeechRequest
SynthesisVoice
Footprint
VoiceType
VoiceGender
SynthesisVoiceSubscription
SynthesisResource
InlineStreamingSignal
DaemonSession
OspreyTTSPrewarmAction
SiriAnalyticsHandler
female
male
unspecifB
Partition
SiriTTSPhonemeTool
Unknown phoneme system: %d
service
SiriTTSSynthesisEngine
Empty voice path cannot be used.
TTSSynthesizer::initialize error: %@
mimeType
TTSSynthesizer::load_voice_resource
tts.feature.prompt
tts.neural.use_fallback
TTSSynthesizer::synthesize_text
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
SiriTTSNeuralUtils
fe_feature
fe_feature_only
quality
channel_type
app_id
context_info
dialog_identifier
experiment_identifier
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
phonemes
word_phonemes
prompts
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data
resources
return_log
voice_asset_path
resource_asset_path
return_server_info
sample_rate
pcm_data
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
speech_id
session_id
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
value
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
stream_id
error_code
error_str
decoder_description
playback_description
streaming_playback_buffer_size_in_seconds
current_pkt_number
word_timing_info
feature
total_pkt_number
content_type
content
v24@?0^v8Q16
v32@?0@8Q16^B24
v20@?0r*8I16
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
cur_
scratch_end
scratch_
scratch_data
buf_
Finished
finished
ReferTo
off && off <= GetSize()
EndVector
i < size()
Finish
strlen(file_identifier) == kFileIdentifierLength
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
v16@?0@"OspreyMutableRequest"8
OspreyTTSService
Corrupted Osprey response.
-[SiriTTSOspreyChannel streamTTS:beginHandler:chunkHandler:completion:]_block_invoke
Unknown response from Osprey for streaming TTS
AXSpeechTransformTextWithLanguage
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
TTSAXResourceManager
Unable to find class %s
com.apple.ttsasset.NewAssetNotification
com.apple.trial.client
, isAppleProduct:
packetDescriptions
, packet count: 
AudioData: Unable to read audio file from 
AudioData: Unable to get audio file format, errno 
AudioData: Unable to get audio data byte count, errno 
AudioData: Unable to get audio data packet count, errno 
AudioData: Unable to get maximum packet size, errno 
AudioData: Unable to get audio data, errno 
Invalid chunk size: %ld at offset %ld, bytes count = %ld
SiriTTSService.AudioPlayback
siritts_audio_playback_queue
AudioService: Unable to create output audio queue, errno 
Unable to dispose AudioQueue, errorCode: %s
AudioService: Unable to start AudioQueue, error 
Unable to begin access power, error: %s
Unable to allocate AudioQueue Buffer, code: 
Unable to enqueue audio data, code: 
Detected stalled audio generation, will enqueue %f silence frame to compensate.
AudioService: Unable to stop AudioQueue immediately, errno 
Unable to get audio power, error: %s
Unable to end access power, error: %s
asbd
audioData
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
VoiceSynthesizerNumericID
VoiceNumericID
VoiceName
VoiceLocalizedNames
VoiceNameRoot
VoiceIdentifier
VoiceAge
VoiceGender
VoiceDemoText
VoiceLanguage
VoiceLocaleIdentifier
VoiceVersion
VoiceScriptCode
VoiceGroup
VoiceType
VoiceRelativeDesirability
VoiceSupportedCharacters
VoiceIndividuallySpokenCharacters
VoiceDiskSize
VoiceAssetDescription
VoiceGenderMale
VoiceGenderFemale
VoiceGenderNeutral
VoiceGenderNeuter
 {}. 
Dobr
 den, jmenuji se {}. Jsem 
 hlas.
Hej, jeg hedder {}. Jeg er en dansk stemme.
Hallo, ich hei
e {} und ich bin eine deutsche Stimme.
 {}. 
Hello, my name is {}. I am an Australian-English voice.
Hello, my name is {}. I am a British-English voice.
Hello, my name is {}. I am an Irish-English voice.
Hello, my name is {}. I am an Indian-English voice.
Hello, my name is {}. I am an American-English voice.
Hello, my name is {}. I am a South African-English voice.
Hello, my name is {}. I am a Scottish-English voice.
Hola, me llamo {} y soy una voz espa
ola.
Hola, me llamo {} y soy una voz mexicana.
Hei, minun nimeni on {}. Olen suomalainen 
Bonjour, je m
appelle {}. Je suis une voix canadienne.
Bonjour, je m
appelle {}. Je suis une voix fran
aise.
m! {} vagyok. 
n vagyok a magyar hang.
Halo, nama saya {}. Saya berbahasa Indonesia.
Salve, mi chiamo {} e sono una voce italiana.
Hallo, mijn naam is {}. Ik ben een Belgische stem.
Hallo, mijn naam is {}. Ik ben een Nederlandse stem.
Hei, jeg heter {}. Jeg er en norsk stemme.
Witaj. Mam na imi
 {}, jestem g
osem kobiecym dla j
zyka polskiego.
, o meu nome 
 {} e a minha voz corresponde ao portugu
s que 
 falado no Brasil
, chamo-me {} e dou voz ao portugu
s falado em Portugal.
 cheam
 {}. Sunt o voce rom
neasc
 {}. 
Ahoj. Vol
m sa {}. Som hlas v slovenskom jazyku.
Hej, jag heter {}. Jag 
r en svensk r
Merhaba, benim ad
m {}. Ben T
e bir sesim.
 Siri!
Hej, jeg er Siri.
Hallo, ich bin Siri.
Hello, I'm Siri.
Hei, min
 olen Siri.
Bonjour, je suis Siri.
 Siri.
Ciao, sono Siri.
Siri
 Siri
Hei, jeg er Siri.
Hallo, ik ben Siri.
Oi, meu nome 
 Siri.
 Siri.
Hej, jag heter Siri.
 Siri
Merhaba, ben Siri.
Siri
Hello
Siri
Siri
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
cookie
authTokens
SIRI_TEXT_TO_SPEECH
voice
SIRITTSSERVICE_NETWORK_STALL_1
SIRITTSSERVICE_NETWORK_STALL_2
SIRITTSSERVICE_NETWORK_STALL_3
ca-ES_Montserrat
paused
started
waitForFinish
stopped
magicVersion
timingInfos
com.apple.springboard
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
com.apple.voicetool
com.apple.siri.tts.SiriTTSServiceIntegrationTests.xctrunner
com.apple.siritts-tool
synthesisContext
SiriTTSAudioData
supportsSecureCoding
TB,N
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
v24@0:8q16
@24@0:8@16
T{AudioStreamBasicDescription=dIIIIIIII},N,Vasbd
T@"NSData",N,C
Tq,N,VpacketCount
T@"NSString",N,R
B24@0:8@16
audioInterface
audioOperationQueue
playbackError
audioSequence
_TtC14SiriTTSService19AudioQueueInterface
discontinuedDuringPlayback
outputRouteInfo
audioQueue
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
_TtCC14SiriTTSService19AudioQueueInterfaceP33_D074378E45DF23C69F519544CB6674D224AudioQueueBufferUserData
expectedPlaySampleTime
SiriTTSServiceAudioPlayback
Unable to query kAudioQueueProperty_IsRunning, %s
Unexpected to have startTime == 0
Enqueued audio buffer #%ld, packet count: %ld, bytes: %ld
Played audio buffer #%ld, packet count: %ld, bytes: %ld
Current route info: {%s}
Started AudioQueue.
Starting AudioQueue...
OS_xpc_object
SiriTTSSynthesizingRequestProtocol
T@"SiriTTSSynthesisContext",N,&
@"SiriTTSSynthesisContext"16@0:8
v24@0:8@"SiriTTSSynthesisContext"16
AVQueuedSampleBufferRendering
^{OpaqueCMTimebase=}16@0:8
v24@0:8^{opaqueCMSampleBuffer=}16
v32@0:8@16@?24
timebase
T^{OpaqueCMTimebase=},N,R
readyForMoreMediaData
hasSufficientMediaDataForReliablePlaybackStart
v32@0:8@"OS_dispatch_queue"16@?<v@?>24
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
hash
superclass
T#,N,R
debugDescription
B24@0:8@"Protocol"16
@"NSString"16@0:8
SiriTTSAudibleRequestProtocol
T@"SiriTTSAudibleContext",N,&
@"SiriTTSAudibleContext"16@0:8
v24@0:8@"SiriTTSAudibleContext"16
TRINotificationToken
_TtP14SiriTTSService22DaemonDelegateProtocol_
v32@0:8Q16@"SiriTTSInstrumentationMetrics"24
v32@0:8Q16@"SiriTTSAudioData"24
v32@0:8Q16@"NSArray"24
v24@0:8@?<v@?>16
_TtP14SiriTTSService14DaemonProtocol_
v28@0:8B16@?20
v28@0:8B16@?<v@?@"NSError">20
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSAudioRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSSpeechRequest"16@?<v@?@"NSError">24
v24@0:8@"SiriTTSBaseRequest"16
v32@0:8@"SiriTTSPhonemeRequest"16@?<v@?@"NSString"@"NSError">24
v24@0:8@"SiriTTSInlineStreamingSignal"16
v24@0:8@"SATTSSpeechSynthesisStreaming"16
v24@0:8@"NSArray"16
v32@0:8@"NSString"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?ff>24
SiriAnalyticsMessageStream
v32@0:8@16Q24
v48@0:8@16@24@32@?40
v24@0:8@"SISchemaTopLevelUnionType"16
v32@0:8@"SISchemaTopLevelUnionType"16Q24
v48@0:8@"NSString"16@"NSUUID"24@"SISchemaInstrumentationMessage"32@?<v@?B@"NSError">40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
Unable to remove file %s
_TtC14SiriTTSService17DiagnosticService
notificationCenter
observers
requestId
Unable to encode json data
Unable to locate data dump directory
Unable to write json metrics at %s, %s
Json metrics saved to: %s
Instrumentation Metrics Data (id: %llu):
v16@?0@"NSNotification"8
Event '%s' expect associated object as %s, got: %s
SynthesisResource
InstrumentationMetrics
Array<WordTimingInfo>
AudioPowerProviding
siriInlineOneShot
siriInlineStreaming
siriServerRoundTrip
Unable to list content of directory %{public}s
No request is provided. Ignore reading cache.
No cache storage is provided. Ignore reading cache.
No voice is provided. Ignore reading cache.
No resource is provided. Ignore reading cache.
Synthesis cache is found for request %@
Preinstalled audio is found for request %@
Ignore reading cache due to internal settings disables caching.
_TtC14SiriTTSService18CacheReadingAction
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
VoiceGroupCustom
Swift/Dictionary.swift
VoiceGroupCustomCompact
VoiceGroupCompact
SupportedCharacters
com.apple.siri.SiriTTSService
_TtC14SiriTTSService20TTSAssetStubStrategy
_TtC14SiriTTSService10MappedData
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
Unable to handle mmap file, errno: %d, error: %s
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file to length: %ld, errno: %d, error: %s
Unable to mmap file at path: %{public}s, errno: %d, error: %s
_TtC14SiriTTSService17PassThroughAction
SiriTTSService
v44@0:8@16B24@?28@?36
v24@0:8@?16
v20@0:8B16
Cleared inline streaming object storage.
Notification for %s has not started. Cache object %@
Found cached objects %@
Start streaming for %s
_TtC14SiriTTSService22InlineStreamingStorage
storage
streamingHandlers
signals
lock
Notification for %s is on-going. Posting object immediately %@
InlineStreamStorage
_TtC14SiriTTSService20EngineCachingService
_activeSessionCount
_cachedEngine
_TtC14SiriTTSService15SignpostHandler
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
TTSPlayback
[Error] Interval already ended
TTSStartAudio
TTSServerFirstPacket
TTSEngineSelect
engineTag=%s
TTSVoiceSelect
voice=%s
TTSSynthesis
source=%s
HardwarePlatform
lowInactiveMemory
VoiceServices
VoiceSelectionAction: Cannot find synthesizing request
_TtC14SiriTTSService27RetryTextModificationAction
v16@?0@"SiriTTSOspreyStreamingBeginResponse"8
v16@?0@"SiriTTSOspreyStreamingPartialResponse"8
v16@?0@"NSError"8
_TtC14SiriTTSService12OspreyClient
grpcChannel
speechId
https://carry-dejavu.siri.apple.com
https://dejavu.apple.com
ttsContentVersion
Trial asset %{public}@ not downloading, unable to cancel
Trial asset %{public}@ already downloaded, unable to cancel
v20@?0B8@"NSError"12
SiriTTSService.TTSAssetTrialAsset
_TtC14SiriTTSService18TTSAssetTrialAsset
factorName
assetAttr
isDownloading
downloadToken
assetSource
T@"TTSAssetSource",N,R
versionDescription
diskSize
T@"NSNumber",N,R
supportedLanguages
T@"NSArray",N,R
T@"NSBundle",N,R
locallyAvailable
_TtC14SiriTTSService23TTSAssetTrialVoiceAsset
T@"TTSAssetType",N,R
technology
T@"TTSAssetTechnology",N,R
T@"TTSAssetQuality",N,R
name
identifier
gender
T@"NSDictionary",N,R
_TtC14SiriTTSService26TTSAssetTrialResourceAsset
com.apple.speech.synthesis.voice.
com.apple.speech.synthesis.voice.custom.siri.
Missing name for voice
Missing footprint for voice
Unknown footprint for voice: %@
Missing asset type for voice
Unknown asset type for voice: %@
Asset %s attributes %s level %@
Unable to initialize asset bundle from path: %{public}s
MobileAssetProperties
Asset %s path %s
Unable to get level for factor name '%{public}s'
Trial asset %{public}@ immediate removal failed with error %@
Trial asset %{public}@ immediate removal succeeded
Trial asset %{public}@ deferred removal failed with error %@
Trial asset %{public}@ deferred removal succeeded
Trial asset %{public}@ download cancellation failed with error %@
Trial asset %{public}@ download cancelled
Trial asset %{public}@ start download
Trial asset %{public}@ download failed with error %@
Trial asset %{public}@ download succeeded
Trial download %u%% done, %.2fs left %d written status %d
v24@?0d8Q16
_TtC14SiriTTSService21TTSAssetAdhocStrategy
Skip invalid voice folder '%s'
Skip invalid resource folder '%s'
#Local listing assets for types: %s, filter: %s
Unable to list resource folder %s
/private/var/mobile/Library/VoiceServices/resources/
Unable to list voice folder %s
/private/var/mobile/Library/VoiceServices/voices/
/System/Library/PrivateFrameworks/TTSAsset.framework/Voices/
TextToPhoneme request is not set
TextToPhoneme voice is not found
_TtC14SiriTTSService19TextToPhonemeAction
engineCachingService
ObjectPool: Unregistered type 
ObjectPool: Constructed wrong object type 
TTSAsset encountered unknown asset type %{public}@ and tentatively tried to handle through Trial
enable_adhoc_voice
use_trial
TTSAsset
sirix
Siri
SiriTTSService.Event.taskCompletion
SiriTTSService.Event.audioPowerProviderAvailable
SiriTTSService.Event.neuralFallback
SiriTTSService.Event.neuralAudioClick
SiriTTSService.Event.neuralAlignmentStall
SiriTTSService.Event.synthesisUsedPrompt
SiriTTSService.Event.encounteredError
SiriTTSService.Event.synthesisEngineChanged
SiriTTSService.Event.receivedServerLastPacket
SiriTTSService.Event.voiceResourceSelected
SiriTTSService.Event.synthesisError
SiriTTSService.Event.eagerRequestDetected
SiriTTSService.Event.cancellationRequested
SiriTTSService.Event.phonemesGenerated
SiriTTSService.Event.audioPlaybackEnded
SiriTTSService.Event.audioPlaybackEnqueued
SiriTTSService.Event.audioPlaybackStarted
SiriTTSService.Event.audioPlaybackStarting
SiriTTSService.Event.receivedServerFirstPacket
SiriTTSService.Event.engineSelectEnd
SiriTTSService.Event.engineSelectStart
SiriTTSService.Event.voiceSelected
SiriTTSService.Event.voiceSelectStart
SiriTTSService.Event.synthesisStarted
SiriTTSService.Event.audioGenerated
SiriTTSService.Event.wordTimingGenerated
SiriTTSService.Event.synthesisEnded
SiriTTSService.Event.encounteredIssue
SiriTTSService.Event.instrumentationMetricsAvailable
SiriTTSService.Event.requestReceived
SiriTTSService1
B40@0:8@16@24@32
_TtC14SiriTTSService35TTSAssetTrialProxyInstantiatedAsset
registry
_TtC14SiriTTSService29TTSAssetProxyProgressCallback
_TtC14SiriTTSService25TTSAssetProxyPathCallback
_TtC14SiriTTSService21TTSAssetProxyStrategy
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
TrialXP (by Proxy)
Failed to establish connection, return empty result from proxy assets
Failed to get value from xpc reply, return empty results from proxy assets
<- %d assets
B24@?0q8@"<OS_xpc_object>"16
Listing asset types %{public}s through XPC service...
Failed to establish connection & sandbox
Failed to get sandbox extensions
Failed to consume sandbox extension %s
Consume sandbox extension %s
v16@?0@"<OS_xpc_object>"8
com.apple.SiriTTSService.TrialProxy
v16@?0@"TTSAsset"8
v32@?0d8q16q24
Unable to issue sandbox extension to path '%{public}s'
Unable to convert C string into Swift string for authToken'
Issued sandbox extension to path %s
Unexpected non Trial asset %{public}@
Unable to get bundle path for factor name %s
com.apple.private.sirittsservice.modify-proxy-assets
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
compact
premium
premiumhigh
beta
production
T@"TTSAssetServer",N,R
livability
staging
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
_TtC14SiriTTSService18TTSAssetMAStrategy
stagingURL
_TtCC14SiriTTSService18TTSAssetMAStrategy23DownloadSourceExtractor
v56@0:8@16@24@32@40@48
v48@0:8@16@24@32@40
v32@0:8@16@24
inKey
wantValue
source
#MobileAsset Unable to create query
Query for %{public}@ failed: %d
Download asset catalogs, sync: %{bool}
#MobileAsset listing assets for type '%@', filter: '%{public}s'
v16@?0q8
Catalog %{public}@ download failed: %d
/var/MobileAsset/AssetsV2/
https://mesu.apple.com/assets/
https://basejumper.apple.com/livability/
Server (default) for %{public}@
Server %{public}@ for %{public}@: %d
https://basejumper.apple.com/assets/
https://basejumper.apple.com/assets
https://basejumper.apple.com/
NSXMLParserDelegate
v24@0:8@16
v40@0:8@16@24@32
@40@0:8@16@24@32
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
NSObject
q16@0:8
description
_TtC14SiriTTSService21TTSAssetTrialStrategy
#Trial Synchronous namespace download took %.1fs
#Trial listing assets for class '%s', types: '%{public}s', filter: '%{public}s'
com.apple.siri.tts.
Factor %s does not have %ld components as expected.
Encountered entirely unexpected factor %s.
Refreshing stale trial client
TTSAsset Trial Callbacks
/private/var/MobileAsset/AssetsV2/com_apple_MobileAsset_Trial_Siri_SiriTextToSpeech/
/Library/Trial/Treatments/
v16@?0@"<TRINamespaceUpdateProtocol>"8
Get namespace update, refreshing trial client
Workflow: waitDequeue timed out in 
Workflow: waitDequeue timed out in %s
Encountered error: %s
Encountered error during error handling: %s
Gracefully handle error: %s
_TtC14SiriTTSService8Workflow
graph
errorHandlers
_isCancelled
cancellationLock
_TtC14SiriTTSService13DataContainer
idContainer
_TtC14SiriTTSService6Buffer
bufferCondition
_TtC14SiriTTSService19AsynchronousContext
isProcessing
asyncError
waitTimeout
isProcessingCondition
_TtC14SiriTTSService12WorkflowNode
action
_TtCC14SiriTTSService12WorkflowNode17WorkflowCondition
conditional
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
(AudioMappedInfoAVSBAR in _4791274A894FA1CB92EFFF8F61E0C16D)
SynthesisVoiceSubscription
Conditional node has no next node, %s
TTSAssetTrialProxyInstantiatedAsset
InlineStreamingSignal
com.apple.ttsasset
SiriTTSService2
B32@0:8@16@24
v8@?0
Ignore writing cache due to missing cache storage
Ignore writing cache due to missing audio data
Ignore writing cache due to missing request info
Ignore writing cache due to missing voice info
Ignore writing cache due to missing voice resource info
Unable to create cache file, error: 
Ignore writing cache with empty data, probably audio prime data
Ignore writing cache since audio is from cache already
Ignore writing cache due to internal settings disable caching
_TtC14SiriTTSService27SynthesisCacheWritingAction
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
Unable to write cache, %s
Invalidate synthesis caching. %s
Synthesis cache %s is written.
Synthesis cache %s is cancelled.
Unable to close cache file, %s
Detected synthesis error.
Detected neural alignment stall.
Detected neural audio click.
Detected neural fallback.
Cancellation is requested.
com.apple.sirittsd
com.apple.sirittsd.can-dump-audio
No bundle path from proxy presentation
Invalid bundle path %{public}s
Constructed bundle %s
Trial proxy download status check failed, unable to establish server connection
-> %@
<- %@
Failed to get download status
Trial proxy asset [%@] not downloading, unable to cancel
Trial proxy asset download cancellation failed, unable to establish server connection
Trial proxy asset [%@] cancelling download.
SiriTTSService.TTSAssetProxyAsset
_TtC14SiriTTSService18TTSAssetProxyAsset
assetQuality
bundlePath
authorizedBundle
proxy_attr
assetType
versionNumber
Tq,N,R
attributes
purgeable
Trial proxy asset [%@] download cancelled.
Trial proxy asset [%@] download cancellation failed.
Trial proxy asset download failed, unable to establish server connection
Trial proxy asset [%@] download starting.
Trial proxy asset [%@] already locally available, no download necessary
Trial proxy asset [%@] download failed.
Trial proxy asset [%@] download succeeded.
.siri.tts.resource.
DeviceSynthesisAction: No voice asset was set
gryphon_frontend
Unable to load resource %s, error: %s
_TtC14SiriTTSService30SynthesisEngineSelectionAction
voice_configs.plist
Unable to load voice_configs.plist from %s
vocalizer_resources
Unable to parse vocalizer_resources
vocalizer_resource_order
Unable to parse vocalizer_resources_order
Unknown mime-type for file %s
_TtC14SiriTTSService10ObjectPool
constructorRegistry
objectPool
speech.synthesis.voice
_MasteredVersion
_CompatibilityVersion
LanguagesCompatibility
SiriTTSService.TTSAssetMAAsset
_TtC14SiriTTSService15TTSAssetMAAsset
asset
bundle
_TtC14SiriTTSService22TTSAssetMACompactAsset
v16@?0@"MAProgressNotification"8
Preposterous string version %{public}@ for key %{public}@ in %@
Preposterous integer version %d for key %{public}@ in %@
_TtC14SiriTTSService29PreinstalledWordTimingStorage
storageURL
voice name is required for preinstalled word timings.
No preinstalled word timings plist file at path %{public}s
Unable to convert raw plist to expected format.
No word timing found voice name %{public}s
Missing word_timings field
Unable to find word '%s'
Missing word timing pair
_TtC14SiriTTSService17AudioPowerHandler
audioPowerProvider
OpusEncodingAction: no audio found
OpusEncodingAction: Audio is already opus encoded
_TtC14SiriTTSService18OpusEncodingAction
encoder
_TtC14SiriTTSService16InternalSettings
_enableDiagnostic
_logSensitiveText
_disableCache
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
logSensitiveText
DisableAssetCleaning
AllowAnyAssetSubscription
defaultToNonDiscretionaryDownloads
EnableLocalVoices
ServerTTSTimeout
DeviceTTSWaitTime
disableDeviceRacing
disableServerTTS
disableInlineStreamTTS
disableOspreyStreaming
streamBufferDuration
ospreyEndpointURL
simulateNetworkStall
simulateAudioStall
disableDeviceNeuralTTS
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
com.apple.voiceservices
process is not running as user Mobile: it's not accessing our shared UserDefaults
InlineStreamingAction: Cannot find request
InlineStreamingAction: Cannot find streaming signal for 
_TtC14SiriTTSService21InlineStreamingAction
asyncContext
streamingStorage
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
InlineStreamingAction: Unknown stream object 
InlineStreamingAction: Unknown inline streaming error 
Received streaming audio chunk before receiving streaming audio begin
Simulate network stall is on, ignore inline streaming objects
InlineStreamingAction: Unsupported inline streaming audio format 
Inline streaming timed out
Inline streaming network stall
Internal setting specifies timeout: %f
sirittsd crashed
RequestParser: Cannot find request.
Overriding whisper with internal default
Overwriting pitch with internal default: %f
Overwriting rate with internal default: %f
Overwriting volume with internal default: %f
_TtC14SiriTTSService9Languages
_TtC14SiriTTSService23RequestPreprocessAction
settings
Error in tn override tag, ignore
<say-as interpret-as="
SSMLConversion: Unbalanced say-as tag
SSMLConversion: Unbalanced phoneme tag
<phoneme alphabet="lhp" ph="
AssistantEtiquette
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/AssistantEtiquette
%{public}s is not TTS language, fallback to %{public}s
tts_language_fallbacks
SiriTTSService/RequestPreprocessAction.swift
_TtC14SiriTTSService19TTSAssetStaticVoice
attr
_TtC14SiriTTSService18TTSAssetAdhocVoice
_TtC14SiriTTSService25TTSAssetPreinstalledVoice
_TtC14SiriTTSService22TTSAssetStaticResource
_TtC14SiriTTSService21TTSAssetAdhocResource
Resource Asset %s path %s attributes %s
SiriTTSService.TTSAssetStaticResource
SiriTTSService/TTSAssetStaticAsset.swift
Subclasses of TTSAssetStaticResource must override assetSource
SiriTTSService.TTSAssetStaticVoice
Subclasses of TTSAssetStaticVoice must override assetSource
_TtC14SiriTTSService12Localization
LocalizedStrings
Unable to find retry phrase '%{public}s', %{public}s
_TtC14SiriTTSService15DelegateHandler
delegate
com.apple.voiceservices.notification.synthesis-done
audibleContext
Unable to create directory at %s, error: %s
%s is not a directory!
Unable to get Library directory for audio dumping
AudioDump: Cannot find audio data.
Unable to find request of AudioDumpAction
Audio saved to: %s
Ignore writing audio file due to missing entitlement. Please add 'com.apple.sirittsd.can-dump-audio'.
_TtC14SiriTTSService9AudioFile
audioFile
packetOffset
_TtC14SiriTTSService15AudioDumpAction
entitlements
diagnosticAudioFile
synthesizedAudioFile
AudioFile: Unable to close audio file, code: 
AudioFile: Unable to write audio data, code: 
AudioFile: Unable to create audio file at path 
Unable to write diagnostic audio file, error: %s
SiriTTSService.AssistantAsset
SiriTTSService.AssistantVoiceMaps
AssistantVoiceMap
VoicePitchRangeDescriptors
TTSAssistantAsset
assistantGender
assistantOrder
Tq,N,R,VassistantGender
Tq,N,R,VassistantOrder
isCustom
TB,N,R
primaryLanguage
TTSAssistantVoiceMaps
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
SiriTTSService3
assistantVoiceMaps
T@"TTSAssistantVoiceMaps",N,R
_TtC14SiriTTSService17HasAudioCondition
voice_resource_asset_key
tts_synthesis_latency
tts_total_latency
audio_queue_latency
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
audio_output_route
client_bundle_identifier
privacy_sensitive
server_first_packet_latency
server_last_packet_latency
com.apple.voiceservices.metrics
real_time_factor
neural_alignment_stall
neural_audio_click
_TtC14SiriTTSService20CoreAnalyticsService
_TtC14SiriTTSService29CoreAnalyticsSynthesisHandler
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
Unrecognized request type in handleRequestReceived, got: %s
_TtC14SiriTTSService10VoiceAsset
path
_TtC14SiriTTSService13ResourceAsset
resource
_TtC14SiriTTSService18TrialAssetProvider
downloadQueue
_TtC14SiriTTSService18LocalAssetProvider
_TtC14SiriTTSService20BuiltInVoiceProvider
_TtC14SiriTTSService28VocalizerCustomVoiceProvider
_TtC14SiriTTSService25PreinstalledVoiceProvider
Unfound built-in voice for language %{public}s
Falling back to no-NO voice since nb-NO is not available
Unable to download SIRI_TEXT_TO_SPEECH namespace
Unable to download SIRI_TEXT_TO_SPEECH namespace.
Unable to find best asset for 
SIRI_TEXT_TO_SPEECH namespace is not downloaded yet. Downloading now.
Unable to download asset: 
OspreyTTSAction: Cannot find synthesizing request
Updating osprey cache
Osprey cache is found, requestId: %llu
Missing voice name or gender for Osprey { id: 
_TtC14SiriTTSService15OspreyTTSAction
ospreyClient
ospreyConfig
streamingStartedDate
Updated osprey cache
OspreyTTSAction: error when updating osprey cache, %s
Osprey streaming network stall { id: 
Osprey streaming timed out { id: 
Encountered Osprey error: %s, { id: %llu }
Simulate network stall is on, ignore audio object
Invalid server audio format
Server voice: %@, resource: %@, buffer size: %f
Default Osprey timeout: 1.0
Osprey config specifies timeout: %f
VoiceSelectionAction cannot find synthesizing request
Cannot find suitable voice for 
Select voice: {%{public}s}, resource: {%{public}s}, request: {client: %{public}s, id: %s}
Ignore neural voice since it's not suitable. Current thermal level: %s, low power mode: %{bool}d, voice: %{public}@, neural platform: %{bool}d, requestId: %llu
Ignore neural voice since internal settings disable device neural TTS. requestId: %llu }
_TtC14SiriTTSService20VoiceSelectionAction
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
VoiceSelectionAction does not support request: 
RequestParsingAction cannot find request
RequestParsingAction found unknown request: 
_TtC14SiriTTSService20RequestParsingAction
com.apple.siri.tts
B24@?0r*8@"<OS_xpc_object>"16
VSAudioPlaybackServiceAVSBARQueue
Can't retrieve session with ID: 
Can't instantiate AVSampleBufferAudioRenderer or AVSampleBufferRenderSynchronizer. Search (AVFCore) and [com.apple.coremedia:] for the underlying error.
VSAudioPlaybackService init latency: %f
#AVSBAR initialized with session ID: %u, reusing previous synchronizer: %{bool}d
#AVSBAR empty audio data: will not enqueue it
Did add to enqueuedMappedAudioInfo: %f sec
Will add to enqueuedMappedAudioInfo: %f sec
#AVSBAR already stopped or waiting for finish: will not enqueue more
Timeout waiting for AVSampleBufferRenderSynchronizer
#AVSBAR Synchronizer is stalled with rate %f at time %f.
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR already stopped or waiting for finish
#AVSBAR waitUntilFinished
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
synchronizer stop rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f. Then renderer will be flushed.
Stopping synchronizer and renderer
synchronizer pause rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f.
Pausing synchronizer
_TtC14SiriTTSService14AVSBARPlayback
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
state
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
_TtCC14SiriTTSService14AVSBARPlaybackP33_4791274A894FA1CB92EFFF8F61E0C16D21AudioMappedInfoAVSBAR
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
mediaserverd reset
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %ld
renderer enqueueSampleBuffer high latency: %f sec
#AVSBAR Enqueuing to %@: %f sec
#AVSBAR Call to provide more audio data during state %s.
Error in creating block buffer for Silence buffer
Error in creating block buffer for Silence buffer, code: %s
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioFormatDescriptionCreate from Silence buffer creation, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer, code: %s
Error in creating block buffer for Sample buffer
Error in creating block buffer for Sample buffer, code: %s
Error in CMAudioFormatDescriptionCreate
Error in CMAudioFormatDescriptionCreate, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in CMAudioSampleBufferCreateWithPacketDescriptions, code: %s
#AVSBAR renderer was flushed
#AVSBAR Synchronizer reached endTime
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
synchronizer play rate high latency: %f sec
#AVSBAR already stopped or paused: will not resume rate
#AVSBAR Dropping %ld enqueued data
_TtC14SiriTTSService7Timeout
timeoutDate
waitCondition
queue
shouldStop
Skip waiting, no active audio playback found.
Unable to stop audio playback.
Unable to wait audio playback finished.
Audio playback finished for request_id: %llu.
AudioPlayback: Cannot find audio data.
AudioPlayback: Cannot find audible request.
Audio playback started for request_id: %llu
_TtC14SiriTTSService19AudioPlaybackAction
buffer
audioPlayback
audibleRequest
Cancelling audio playback
_TtC14SiriTTSService28TTSAssetPreinstalledStrategy
#Local listing voices for types: %{public}s, filter: %{public}s
Searching in preinstalled voice directory: '%s'
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/PreinstallAssets/
Unable to list voice folder
Skip invalid voice folder '%{public}s'
SiriTTSService4
DeviceSynthesisAction: Engine is not set
DeviceSynthesisAction: Request is not set
v16@?0@"NSData"8
v16@?0@"NSString"8
v16@?0@"NSArray"8
_TtC14SiriTTSService21DeviceSynthesisAction
synthesisConfig
DeviceSynthesisAction: low RTF is detected during synthesis.
DeviceSynthesisAction: no audio data is generated.
Neural voice fell back to compact neural synthesis.
Received word timings: %s
Synthesized with prompt: '%s'
Low synthesis RTF detected, will likely results in stuttering. Missing: %f
Unable to get defaults 'com.apple.voiceservices'
subscribedAssets
_TtC14SiriTTSService11Preferences
defaults
Preferences: Unable to find preference suite 
SiriTTSService5
B16@0:8
@16@0:8
downloading
OpusEncoder: Unknown asbd 
OpusEncoder: Opus not supported
OpusEncoder: Unable to create converter, source asbd 
@"AVAudioBuffer"20@?0I8^q12
OpusEncoder: Unable to encode chunk, error: 
_TtC14SiriTTSService11OpusEncoder
fromFormat
toFormat
converter
OpusEncoder: Unable to create input buffer
CacheStorage: Unable to create cache file at path 
Failed reading cache, error: %s
SynthesisCacheFile: invalid file, probably not closed properly, or incompatible.
Cleaned cache storage: %{public}s
Unable to remove cache file at path: %s
Cleaning cache storage: %{public}s
SynthesisCache: incorrect magic version
SynthesisCache: Unable to decode audio
SynthesisCache: Unable to decode timing info
_TtC14SiriTTSService12CacheStorage
Unable to list directory, error: %s
Missing bundle identifier for CacheStorage
Unable to create CacheStorage, error: %s
Unable to get Cache directory
CacheStorage: Path 
 is an existing file!
CFBundleShortVersionString
Failed to delete legacy asset %@: %@
SiriTTSService.TTSAssetLegacyAsset
_TtC14SiriTTSService19TTSAssetLegacyAsset
$__lazy_storage_$_voiceDesc
Swift/NativeDictionary.swift
Duplicate values for key: '
_TtC14SiriTTSService24PreinstalledAudioStorage
_TtC14SiriTTSService19OspreyBuiltInConfig
deviceWaitTime
allowedAppIdentifiers
_TtC14SiriTTSService20OspreyChainedConfigs
configs
_TtC14SiriTTSService25WeakDaemonDelegateWrapper
v24@0:8Q16
_TtC14SiriTTSService16DaemonConnection
connection
weakDelegate
asyncProxy
syncProxy
SiriTTSService.DaemonConnection
init()
Connection interrupted
Connection invalidated
experimentIdentifier
synthesisBeginTime
synthesisEndTime
speechEstimatedOutputBeginTime
serverFirstPacketTime
serverLastPacketTime
audioStartLatency
eagerRequestGapInterval
serverStreamedAudioDuration
isServerTTSRacing
 "audio_duration": 
 "audio_output_route": "
 "audio_queue_latency": 
 "character_count": 
 "error_code": 
 "experiment": "
 "is_speech_request": 
 "is_synthesis_cached": 
 "is_warm_start": 
 "neural_alignment_stall": 
 "neural_audio_click": 
 "neural_fallback": 
 "prompt_count": 
 "real_time_factor": 
 "server_first_packet_latency": 
 "server_last_packet_latency": 
 "source_of_tts": "
 "synthesis_to_speech_time_gap": 
 "tts_synthesis_latency": 
 "tts_total_latency": 
 "voice_resource": "
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
v16@?0@"SiriTTSAudioData"8
customResourceURLs
disableCompactVoice
synthesisProfile
prosodyProperties
", privacySensitive: 
SiriTTSService.SynthesisContext
v16@?0@"SiriTTSInstrumentationMetrics"8
text: "<privacySensitive, length: 
SiriTTSService.SynthesisVoice
SiriTTSService.SynthesisVoiceSubscription
SiriTTSService.SynthesisResource
SiriTTSService.InlineStreamingSignal
DaemonSession %@ sets keepActive: %{bool}d
Init DaemonSession %@
Init DaemonSession %@, with accessory %s
Deinit DaemonSession %@
DaemonSession keepActive must be true before prewarming.
Start #PrewarmRequest, %{public}s
Start #SynthesisRequest %{public}s
TTSRequestReceived
id %llu
Start #SpeechRequest %{public}s
Start #AudioRequest, %{public}@
#CancelRequest, %@
#InlineStreaming signal %@
#InlineStreaming object %@
v12@?0B8
v16@?0f8f12
v24@?0@"NSString"8@"NSError"16
#TextToPhoneme %s
Unable to subscribe voice due to missing bundle identifier
Unable to get bundle identifier for current client
Can't find alive request with timestamp %llu didStartSpeaking.
Request is not audible, but called with didStartSpeaking. %@
Can't find alive request with timestamp %llu didReportInstrument.
Can't find alive request with timestamp %llu didGenerateAudio.
Expecting synthesizing request, but got %@
Can't find alive request with timestamp %llu didGenerateWordTimings.
SiriTTSWordTimingInfo
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@40@0:8d16{_NSRange=QQ}24
startTime
textRange
Td,N,VstartTime
T{_NSRange=QQ},N,VtextRange
SiriTTSInstrumentationMetrics
v16@0:8
utterance
speechBeginTime
speechEndTime
T@"NSString",N,C
T@"SiriTTSSynthesisVoice",N,&,Vvoice
T@"SiriTTSSynthesisResource",N,&,Vresource
TQ,N,VrequestCreatedTime
Td,N,VeagerRequestGapInterval
TQ,N,VsynthesisBeginTime
TQ,N,VsynthesisEndTime
TQ,N,VspeechBeginTime
TQ,N,VspeechEndTime
TQ,N,VspeechEstimatedOutputBeginTime
Td,N,VaudioStartLatency
TQ,N,VserverFirstPacketTime
TQ,N,VserverLastPacketTime
Td,N,VserverStreamedAudioDuration
Td,N,VaudioDuration
TB,N,VisWarmStart
Tq,N,VsourceOfTTS
TB,N,VprivacySensitive
Tq,N,VerrorCode
TB,N,VisServerTTSRacing
Tq,N,VpromptCount
TB,N,VneuralAlignmentStall
TB,N,VneuralAudioClick
TB,N,VneuralFallback
TB,N,VisAudibleRequest
voiceResourceAssetKey
SiriTTSAudibleContext
I16@0:8
v20@0:8I16
@?16@0:8
audioSessionId
immediate
siriRequestId
didStartSpeaking
TI,N,VaudioSessionId
TB,N,Vimmediate
T@"NSUUID",N,C
T@?,N,C
SiriTTSProsodyProperties
f16@0:8
v20@0:8f16
Tf,N,VneuralSentencePitch
Tf,N,VneuralSentencePitchRange
Tf,N,VneuralSentenceDuration
Tf,N,VneuralSentenceEnergy
Tf,N,VneuralSentenceTilt
SiriTTSSynthesisContext
text
contextInfo
rate
pitch
volume
didGenerateAudio
didGenerateWordTimings
whisper
forceOspreyTTS
T@"NSDictionary",N,C
Tf,N,Vrate
Tf,N,Vpitch
Tf,N,Vvolume
T@"NSArray",N,C
Tq,N,VsynthesisProfile
TB,N,VdisableCompactVoice
TB,N,Vwhisper
T@"SiriTTSProsodyProperties",N,&,VprosodyProperties
TB,N,VforceOspreyTTS
SiriTTSBaseRequest
clientBundleId
accessoryId
outputPath
didReportInstrument
T@"NSURL",N,C
SiriTTSAudioRequest
audio
T@"SiriTTSAudioData",N,R,Vaudio
T@"SiriTTSAudibleContext",N,&,VaudibleContext
SiriTTSSynthesisRequest
@32@0:8@16@24
T@"SiriTTSSynthesisContext",N,&,VsynthesisContext
SiriTTSPhonemeRequest
@40@0:8@16@24q32
phonemeSystem
Tq,N,VphonemeSystem
SiriTTSSpeechRequest
SiriTTSSynthesisVoice
language
footprint
type
version
Tq,N,Vfootprint
Tq,N,Vtype
Tq,N,Vgender
Tq,N,Vversion
SiriTTSVoiceSubscription
clientId
SiriTTSSynthesisResource
SiriTTSInlineStreamingSignal
SiriTTSDaemonSession
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
keepActive
v32@0:8Q16@24
SiriTTSService.SpeechRequest
SiriTTSService.PhonemeRequest
SiriTTSService.SynthesisRequest
SiriTTSService.AudioRequest
#Success #AudioRequest id %llu
#Error #AudioRequest id %llu, error: %s
#Success #SpeechRequest id %llu
#Error #SpeechRequest id %llu, error: %s
#Success #SynthesisRequest id %llu
#Error #SynthesisRequest id %llu, error: %s
#Success #PrewarmRequest id %llu
#Error #PrewarmRequest id %llu, error: %s
NSSecureCoding
NSCoding
_TtC14SiriTTSService22OspreyTTSPrewarmAction
Error in Osprey prewarm: %s
_TtC14SiriTTSService20SiriAnalyticsHandler
ttsId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
Ignore Siri logging due to missing Siri request id
Ignore Siri logging due to non Siri client
Ignore Siri logging due to unmatched Siri request id
SiriTTSService6
@20@0:8B16
Found '%{public}s' assets %{public}s
Listing asset types: '%{public}s', filter: '%{public}s'
voice path '%@', resource path '%@'
%d files under voice path:
%d files under resource path:
- %@
Replace: `%@' -> `%@'
Prompt: "%@"
Phonemes: %@
Norm Text: `%@'
Neural Phonemes: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@', request_id '%llu'
Corrupted Osprey response, stream ID: %@, request_id: %llu
Osprey streaming received Begin response with non 200 status: %d, request_id: %llu
Osprey streaming received Begin response %@, request_id: %llu
Osprey streaming received Chunk response with non 200 status: %d, request_id: %llu
Osprey streaming received Chunk response, pkt number: %d, request_id: %llu
Osprey streaming received End response with non 200 status: %d, request_id: %llu
Osprey streaming received End response, total pkt: %d, request_id: %llu
%s, Unknown response from Osprey for streaming TTS, request_id: %llu
Osprey streaming invokes completion with error %@, request_id: %llu
Osprey streaming invokes completion callback, request_id: %llu
softlink:r:path:/System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
ypSg
_pSg
G0R0_
$sSY
So8NSObjectC
$s14SiriTTSService13AudioPlaybackP
So17OS_dispatch_queueC
_pSg
$s14SiriTTSService19AudioPowerProvidingP
$s14SiriTTSService14AudioInterfaceP
_pSgc
So8NSStringC
$ss21_ObjectiveCBridgeableP
yyXlG
So13OS_xpc_object_p
yypG
_yXlt
_yXltG
So8NSObject_p
ySSG
SS_ypt
ySS_yptG
ySsG
SDySSypG
ySDySSypGG
ySiG
SaySiG
ySaySiGG
G0R3_
_A13At
SgXw
SSSg
So20NSNotificationCenterC
SaySo8NSObject_pG
Iegn_
ypSgm
SdIegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
GIegn_
So14NSUserDefaultsCSg
SdSg
SfSg
_pIegn_
SSIegn_
So8NSObjectCSg
So20NSNotificationCenterCSg
_ypt
ySSSaySDySSypGGG
ySSSDySSSaySDySSypGGGG
_ypt
ySSSo8NSObjectCG
ySSSDyS2SGG
yS2SG
ySSypycG
So13OS_xpc_object_pG
ySSySo29SATTSSpeechSynthesisStreamingCcG
ySSypG
So8TTSAssetC
_yptG
3key_yp5valuet
SaySDySSSiGG
ySS_SStG
SDySSSiG
SvSg
$s14SiriTTSService24SynthesisConfigProvidingP
So29SATTSSpeechSynthesisStreamingCytIegnr_
So29SATTSSpeechSynthesisStreamingC
So29SATTSSpeechSynthesisStreamingCIegg_
SaySo29SATTSSpeechSynthesisStreamingCG
SDySSySo29SATTSSpeechSynthesisStreamingCcG
So15NSRecursiveLockC
So34SiriTTSSynthesizingRequestProtocol_
So22SiriTTSSynthesisEngineCSg
SgXw
Ieg_
So6NSLockC
SaySJG
Iegggyc_
GIeggg_
_pSgIegg_
So20SiriTTSOspreyChannelC
SdS2iIeyByyy_
So8TTSAssetCSgIeyBy_
So8TTSAssetCSgIegg_
So20TRINotificationToken_pSg
SaySSG
Sdz_Xx
Siz_Xx
SdS2iIegyyy_
Iegyy_
_pSgIegyg_
3key_yp5valuet
_pmm
_pSg
_pmm
_pSg
So20NSNotificationCenterCm
So20NSNotificationCenterCmm
$s14SiriTTSService16TTSAssetStrategyP
xIegn_
$s14SiriTTSService20NotificationHandlingP
$s14SiriTTSService28OptionalNotificationHandlingP
yySd_S2itcG
yySSSgcG
So13OS_xpc_object_pSg
So21OS_dispatch_semaphoreC
3key_yp5valuetSg
_So13OS_xpc_object_ptG
SaySo8TTSAssetCG
SiSo13OS_xpc_object_pSbIgygd_
SaySo13TTSStringEnumCG
SaySbG
SaySDySSypGG
SS3key_yp5valuet
So12TTSAssetTypeC
ySi_
ySSG
SaySo15TTSAssetQualityCG
SaySo18TTSAssetTechnologyCG
$ss12CaseIterableP
_pSg
$s14SiriTTSService20WorkflowErrorHandlerP
ySbG
So11NSConditionC
$s14SiriTTSService10ActionableP
$s14SiriTTSService11ConditionalP
$s14SiriTTSService12AsynchronousP
_pSg
_pSg
SgXw
$s14SiriTTSService14DaemonProtocolP
$s14SiriTTSService22DaemonDelegateProtocolP
yXlXp
So8NSStringCm
So12NSDictionaryCm
So6NSUUIDCm
So5NSURLCm
So15TTSAssetQualityC
So8NSBundleCSg
SDyS2SG
xIegr_
$s14SiriTTSService20DependencyInjectableP
SDySSypycG
ypSg_AAt
So7MAAssetC
3key_yp5valuet
SS3key_yp5valuetSg
ySS_
ySS_
ySbG
ySSSgG
ySJG
SDySSSDySSSaySDySSSdGGGG
SgXw
y_SbG
y_SfSgG
y_SdSgG
y_SSSgG
xypcSg
SgXw
_pSgSbt
SayxG
SaySaySiGG
SnySiG
So8NSBundleC
SgXw
Sbz_Xx
SgXwz_Xx
14SiriTTSService22DaemonDelegateProtocol_pSgXw
SaySDyS2SGG
SDySSSaySDySSypGGG
SDySSSay
SDySSSDyS2SGG
yXlG
ySS_SDyS2SGtG
ySSSay
ySSSiG
ySSSgcG
ySd_S2itcG
ySo12TTSAssetTypeCSay
_pGG
ySSSaySo8TTSAssetCGG
_pSg
SgXw
ySS_So8NSObjectCtG
$s14SiriTTSService22CoreAnalyticsInterfaceP
SfIegy_Sg
XDXMT
_yptG
SaySo14TTSAssetSourceCG
SgXw
Sgz_Xx
XDXMT
Gz_Xx
_pSg
GSo13OS_xpc_object_pSbIgygd_
SayypG
So29AVQueuedSampleBufferRendering_p
So7NSErrorCSg
So27AVSampleBufferAudioRendererC
So32AVSampleBufferRenderSynchronizerC
So21OS_dispatch_semaphoreCSg
_pSgcSg
SgXw
SbIegy_
SgXw
_pSg
So29SiriTTSAudibleRequestProtocol_
So29SiriTTSAudibleRequestProtocol_
XcSg
So22SiriTTSSynthesisEngineC
Gz_Xx
z_Xx
XDXMT
So29SiriTTSSynthesisEngineRequestC
So14NSUserDefaultsC
ySSSgc
ySd_S2itc
ySo29SATTSSpeechSynthesisStreamingCc
So13AVAudioFormatC
So16AVAudioConverterC
So23AVAudioCompressedBufferC
$sSt
$sST
So12NSFileHandleC
ySnySiGG
ypGSg
3key_yp5valuetSg
SaySsG
_A63At
_A255At
_A3At
$s14SiriTTSService21OspreyConfigProvidingP
SaySSGSg
So15NSXPCConnectionC
14SiriTTSService14DaemonProtocol_p
IeyB_
_pIegg_
IeyBy_
So7NSArrayCIeyBy_
SDyS2SGSg
IeyBy_
So7NSErrorCSgIeyBy_
IeyBy_
S2fIegyy_
S2fIeyByy_
SSSg
_pSgIeggg_
So8NSStringCSgSo7NSErrorCSgIeyByy_
GIegg_
GIegg_
yycSg
$s14SiriTTSService22AudibleRequestProtocolP
ySay
GcSg
$s14SiriTTSService27SynthesizingRequestProtocolP
ytIegnr_
Iegg_
GytIegnr_
GIegg_
ytIegnr_
Iegg_
ytIegr_
yyXlXpG
So7NSArrayCm
SDySo8NSStringCABG
SgXw
So26SiriAnalyticsMessageStream_p
So14SPIPowerLoggerCSg
SgXw
_SStG
SDySSSaySo8TTSAssetCGG
SaySo12TTSAssetTypeCG
RawValue
audioSessionNotFound
avsbarNotInstantiated
playbackStalled
audioRouteName
isBluetoothRoute
isAppleProduct
vendorID
productID
asbd
audioData
packetCount
packetDescriptions
audioInterface
audioOperationQueue
playbackError
audioSequence
averagePower
peakPower
discontinuedDuringPlayback
outputRouteInfo
audioQueue
startTime
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
expectedPlaySampleTime
callback
mStartOffset
mVariableFramesInPacket
mDataByteSize
mAveragePower
mPeakPower
_rawValue
mSampleTime
mHostTime
mRateScalar
mWordClockTime
mSMPTETime
mFlags
mReserved
value
timescale
flags
epoch
location
length
mSampleRate
mFormatID
mFormatFlags
mBytesPerPacket
mFramesPerPacket
mBytesPerFrame
mChannelsPerFrame
mBitsPerChannel
_ObjectiveCType
mSubframes
mSubframeDivisor
mCounter
mType
mHours
mMinutes
mSeconds
mFrames
rawValue
notificationCenter
observers
requestId
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
utterance
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
RawValue
cacheStorage
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
synthesizerID
voiceID
name
localizedNames
nameRoot
identifier
gender
demo
language
locale
version
scriptCode
voiceGroup
voiceType
desirability
supportedCharacters
individuallySpokenCharacters
diskSize
description
RawValue
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
storage
streamingHandlers
signals
lock
queue
_activeSessionCount
_cachedEngine
notificationCenter
observers
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
lock
value
lowInactiveMemory
grpcChannel
speechId
factorName
assetAttr
path
isDownloading
downloadToken
notification
engineCachingService
use_trial
enable_adhoc_voice
sirix
audioPlaybackStarted
synthesisStarted
synthesisEnded
requestReceived
audioGenerated
wordTimingGenerated
phonemesGenerated
voiceSelected
engineSelectEnd
voiceResourceSelected
encounteredError
encounteredIssue
audioPowerProviderAvailable
instrumentationMetricsAvailable
cancellationRequested
eagerRequestDetected
audioPlaybackStarting
audioPlaybackEnded
voiceSelectStart
engineSelectStart
receivedServerFirstPacket
receivedServerLastPacket
synthesisEngineChanged
synthesisUsedPrompt
neuralAlignmentStall
neuralAudioClick
neuralFallback
taskCompletion
registry
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
message
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
attributes
cookie
bundle
authTokens
quality
downloading
RawValue
stagingURL
inKey
wantValue
text
source
name
firstMinor
voice
resource
AllCases
RawValue
graph
errorHandlers
_isCancelled
cancellationLock
notification
idContainer
buffer
bufferCondition
isProcessing
asyncError
waitTimeout
isProcessingCondition
action
conditional
asyncContext
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
internalSettings
notificationCenter
observers
canDumpAudio
cookie
assetQuality
bundlePath
authorizedBundle
proxy_attr
engineCachingService
notification
constructorRegistry
objectPool
asset
name
gender
quality
storageURL
notificationCenter
observers
audioPowerProvider
encoder
_enableDiagnostic
_logSensitiveText
_disableCache
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
defaults
stringKey
defaultValue
transform
asyncContext
streamingStorage
notificationCenter
observers
internalSettings
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
RawValue
code
description
success
unknown
crash
cancelled
noVoice
invalidVoice
lowSynthesisRTF
compactNeural
audioUnknownError
audioDiscontinuity
ospreyUnknownError
ospreyNetworkTimeout
ospreyNetworkStall
ospreyInvalidAudioFormat
inlineStreamUnknownError
inlineStreamNetworkStall
inlineStreamTimeout
nodes
edges
settings
asset
attr
assetAttr
RawValue
networkStall1
networkStall2
networkStall3
notificationCenter
observers
delegate
request
audioFile
packetOffset
asyncContext
queue
settings
entitlements
diagnosticAudioFile
synthesizedAudioFile
supportedLanguages
name
identifier
assistantGender
assistantOrder
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
notificationCenter
observers
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
voice
path
resource
downloadQueue
notificationCenter
observers
asyncContext
internalSettings
ospreyClient
ospreyConfig
timeout
cacheStorage
streamingStartedDate
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
notification
internalSettings
buffer
notificationCenter
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
state
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
asbd
discontinuedDuringPlayback
audioPowerProvider
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
paused
started
waitForFinish
stopped
RawValue
timeoutDate
waitCondition
queue
shouldStop
asyncContext
buffer
audioPlayback
audibleRequest
notificationCenter
observers
asyncContext
queue
notificationCenter
observers
internalSettings
synthesisConfig
_isCancelled
defaults
fromFormat
toFormat
converter
buffer
Element
Iterator
storageURL
fileURL
handle
voice
resource
audio
timingInfos
magicVersion
RawValue
asset
$__lazy_storage_$_voiceDesc
length
voice
version
name
comment
gender
script
language
region
reserved
creator
storageURL
timeout
deviceWaitTime
allowedAppIdentifiers
configs
delegate
connection
weakDelegate
asyncProxy
syncProxy
RawValue
startTime
textRange
utterance
voice
resource
audioOutputRoute
clientBundleIdentifier
experimentIdentifier
requestCreatedTime
eagerRequestGapInterval
synthesisBeginTime
synthesisEndTime
speechBeginTime
speechEndTime
speechEstimatedOutputBeginTime
audioStartLatency
serverFirstPacketTime
serverLastPacketTime
serverStreamedAudioDuration
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
isServerTTSRacing
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
audioSessionId
immediate
siriRequestId
didStartSpeaking
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
text
contextInfo
rate
pitch
volume
customResourceURLs
synthesisProfile
disableCompactVoice
didGenerateAudio
didGenerateWordTimings
whisper
prosodyProperties
forceOspreyTTS
clientBundleId
accessoryId
outputPath
didReportInstrument
audio
audibleContext
synthesisContext
phonemeSystem
language
name
footprint
type
gender
version
clientId
identifier
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
asyncContext
notificationCenter
observers
ospreyClient
notificationCenter
observers
ttsId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
sources
assetTypes
SiriTTSPhonemeTool
SiriTTSSynthesisEngineResource
SiriTTSSynthesisEngineWordTimings
SiriTTSSynthesisEngineRequest
SiriTTSSynthesisEngine
SiriTTSNeuralUtils
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequestProsodyControlConfig
OPTTSMutableTTSWordPhonemes
OPTTSMutableTTSPhonemeSequence
OPTTSMutableTTSNeuralPhonemeSequence
OPTTSMutableTTSPrompts
OPTTSMutableTTSReplacement
OPTTSMutableTTSNormalizedText
OPTTSMutableTextToSpeechFeature
OPTTSMutableTextToSpeechRequestDebug
OPTTSMutableTextToSpeechVoiceResource
OPTTSMutableTextToSpeechUserProfile
OPTTSMutableTextToSpeechRequestDevConfig
OPTTSMutableTextToSpeechSpeechFeatureInputWave
OPTTSMutableTextToSpeechUserVoiceProfile
OPTTSMutableTextToSpeechRequestProsodyTransferConfig
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequestProsodyControlConfig
OPTTSTTSWordPhonemes
OPTTSTTSPhonemeSequence
OPTTSTTSNeuralPhonemeSequence
OPTTSTTSPrompts
OPTTSTTSReplacement
OPTTSTTSNormalizedText
OPTTSTextToSpeechFeature
OPTTSTextToSpeechRequestDebug
OPTTSTextToSpeechVoiceResource
OPTTSTextToSpeechUserProfile
OPTTSTextToSpeechRequestDevConfig
OPTTSTextToSpeechSpeechFeatureInputWave
OPTTSTextToSpeechUserVoiceProfile
OPTTSTextToSpeechRequestProsodyTransferConfig
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
SiriTTSService_Bridge
SiriTTSOspreyRequest
OspreyBridge
SiriTTSOspreyStreamingBeginResponse
SiriTTSOspreyWordTimingInfo
SiriTTSOspreyStreamingPartialResponse
SiriTTSOspreyChannel
SiriTTSService_TTSAXResource
SiriTTSService_TTSAXResourceManager
SiriTTSAudioHardware
TTSAsset
TTSStringEnum
TTSAssetQuality
TTSAssetServer
TTSAssetSource
TTSAssetTechnology
TTSAssetType
SwiftProxy
stringWithFormat:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
UTF8String
stringWithUTF8String:
generateTTSPhonemes:voicePath:phonemeSystem:error:
path
setPath:
mimeType
setMimeType:
handle
setHandle:
.cxx_destruct
.cxx_construct
_path
_mimeType
_handle
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_handle
T@"NSString",&,N,V_path
T@"NSString",&,N,V_mimeType
startTime
setStartTime:
textRange
setTextRange:
_startTime
_textRange
Td,N,V_startTime
T{_NSRange=QQ},N,V_textRange
text
setText:
privacySensitive
setPrivacySensitive:
rate
setRate:
pitch
setPitch:
volume
setVolume:
profile
setProfile:
neuralSentencePitch
setNeuralSentencePitch:
neuralSentencePitchRange
setNeuralSentencePitchRange:
neuralSentenceDuration
setNeuralSentenceDuration:
neuralSentenceEnergy
setNeuralSentenceEnergy:
neuralSentenceTilt
setNeuralSentenceTilt:
audioHandler
setAudioHandler:
promptHandler
setPromptHandler:
wordTimingsHandler
setWordTimingsHandler:
neuralFallbackHandler
setNeuralFallbackHandler:
_privacySensitive
_rate
_pitch
_volume
_neuralSentencePitch
_neuralSentencePitchRange
_neuralSentenceDuration
_neuralSentenceEnergy
_neuralSentenceTilt
_text
_profile
_audioHandler
_promptHandler
_wordTimingsHandler
_neuralFallbackHandler
T@"NSString",&,N,V_text
TB,N,V_privacySensitive
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
TQ,N,V_profile
Tf,N,V_neuralSentencePitch
Tf,N,V_neuralSentencePitchRange
Tf,N,V_neuralSentenceDuration
Tf,N,V_neuralSentenceEnergy
Tf,N,V_neuralSentenceTilt
T@?,C,N,V_audioHandler
T@?,C,N,V_promptHandler
T@?,C,N,V_wordTimingsHandler
T@?,C,N,V_neuralFallbackHandler
init
length
defaultManager
contentsOfDirectoryAtPath:error:
count
countByEnumeratingWithState:objects:count:
dealloc
hasPhaticResponsesWithVoicePath:
initWithVoicePath:resourcePath:error:
loadResourceWithPath:error:
unloadResource:
synthesize:error:
stopSynthesis
preheatWithError:
asbd
setAsbd:
voicePath
resourcePath
setTag:
synthesizer
setSynthesizer:
_voicePath
_resourcePath
_tag
_synthesizer
_asbd
T^v,N,V_synthesizer
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T@"NSString",R,N,V_voicePath
T@"NSString",R,N,V_resourcePath
T@"NSString",&,N,V_tag
dataWithBytesNoCopy:length:freeWhenDone:
array
addObject:
hasAMX
hasANE
isANEOnly
isNeuralPlatform
isH12Platform
shouldUseNeuralVoice:
isANEModelCompiled:
compileANEModel:error:
dictionary
allocWithZone:
copy
objectForKeyedSubscript:
boolValue
initWithBool:
setObject:forKeyedSubscript:
copyWithZone:
fe_feature
setFe_feature:
fe_feature_only
setFe_feature_only:
TB,N
language
setLanguage:
gender
setGender:
name
setName:
version
setVersion:
quality
setQuality:
type
setType:
T@"NSString",C,N
voice
setVoice:
resource
setResource:
T@"OPTTSTextToSpeechVoice",C,N
T@"OPTTSTextToSpeechResource",C,N
integerValue
initWithInteger:
channel_type
setChannel_type:
app_id
setApp_id:
Tq,N
context_info
setContext_info:
dialog_identifier
setDialog_identifier:
T@"NSArray",C,N
experiment_identifier
setExperiment_identifier:
floatValue
initWithFloat:
global_rate
setGlobal_rate:
global_pitch
setGlobal_pitch:
global_energy
setGlobal_energy:
global_sent_pitch
setGlobal_sent_pitch:
global_sent_pitchrange
setGlobal_sent_pitchrange:
global_sent_duration
setGlobal_sent_duration:
global_sent_energy
setGlobal_sent_energy:
global_sent_tilt
setGlobal_sent_tilt:
Tf,N
phonemes
setPhonemes:
word_phonemes
setWord_phonemes:
prompts_v2
bytes
prompts
setPrompts:
setPrompts_v2:
prompts_v2:
T@"NSData",C,N
original
setOriginal:
replacement
setReplacement:
normalized_text
setNormalized_text:
phoneme_sequence
setPhoneme_sequence:
neural_phoneme_sequence
setNeural_phoneme_sequence:
force_use_tts_service
setForce_use_tts_service:
disable_cache
setDisable_cache:
data
setData:
data:
resources
setResources:
return_log
setReturn_log:
voice_asset_path
setVoice_asset_path:
resource_asset_path
setResource_asset_path:
return_server_info
setReturn_server_info:
intValue
initWithInt:
pcm_data
sample_rate
setSample_rate:
setPcm_data:
pcm_data:
Ti,N
pitch_mean
setPitch_mean:
pitch_std
setPitch_std:
energy_mean
setEnergy_mean:
energy_std
setEnergy_std:
duration_mean
setDuration_mean:
duration_std
setDuration_std:
wave_data
setWave_data:
user_voice_profile
setUser_voice_profile:
user_voice_profile_url
setUser_voice_profile_url:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",C,N
T@"OPTTSTextToSpeechUserVoiceProfile",C,N
speech_id
setSpeech_id:
session_id
setSession_id:
audio_type
setAudio_type:
enable_word_timing_info
setEnable_word_timing_info:
voice_name
setVoice_name:
preferred_voice_type
setPreferred_voice_type:
meta_info
setMeta_info:
context
setContext:
experiment
setExperiment:
feature_flags
setFeature_flags:
debug
setDebug:
dev_config
setDev_config:
prosody_config
setProsody_config:
prosody_control_config
setProsody_control_config:
T@"OPTTSTextToSpeechRequestMeta",C,N
T@"OPTTSTextToSpeechRequestContext",C,N
T@"OPTTSTextToSpeechRequestExperiment",C,N
T@"OPTTSTTSRequestFeatureFlags",C,N
T@"OPTTSTextToSpeechRequestDebug",C,N
T@"OPTTSTextToSpeechUserProfile",C,N
T@"OPTTSTextToSpeechRequestDevConfig",C,N
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",C,N
T@"OPTTSTextToSpeechRequestProsodyControlConfig",C,N
setKey:
value
setValue:
doubleValue
initWithDouble:
unsignedIntegerValue
initWithUnsignedInteger:
format_id
setFormat_id:
format_flags
setFormat_flags:
bytes_per_packet
setBytes_per_packet:
frames_per_packet
setFrames_per_packet:
bytes_per_frame
setBytes_per_frame:
channels_per_frame
setChannels_per_frame:
bits_per_channel
setBits_per_channel:
reserved
setReserved:
Td,N
TI,N
word
setWord:
sample_idx
setSample_idx:
offset
setOffset:
setLength:
timestamp
setTimestamp:
stream_id
setStream_id:
error_code
setError_code:
error_str
setError_str:
decoder_description
setDecoder_description:
playback_description
setPlayback_description:
streaming_playback_buffer_size_in_seconds
setStreaming_playback_buffer_size_in_seconds:
T@"OPTTSAudioDescription",C,N
T@"OPTTSTextToSpeechMeta",C,N
audio
current_pkt_number
setCurrent_pkt_number:
setAudio:
audio:
word_timing_info
setWord_timing_info:
feature
setFeature:
T@"OPTTSTextToSpeechFeature",C,N
total_pkt_number
setTotal_pkt_number:
content_type
setContent_type:
content_typeForObject:
isMemberOfClass:
content_mutableClassForType:
content_typeForMutableObject:
contentAsOPTTSStartTextToSpeechStreamingRequest
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContent:
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
content
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
contentAsOPTTSBeginTextToSpeechStreamingResponse
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
contentAsOPTTSPartialTextToSpeechStreamingResponse
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
contentAsOPTTSFinalTextToSpeechStreamingResponse
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
initWithFlatbuffData:root:verify:
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
_storage
_data
_root
TB,R,N
initWithBytes:length:encoding:
T@"NSString",R,N
T@"OPTTSTextToSpeechVoice",R,N
T@"OPTTSTextToSpeechResource",R,N
Tq,R,N
context_info_enumerateObjectsUsingBlock:
objectAtIndexedSubscript:
enumerateObjectsUsingBlock:
context_info_objectAtIndex:
context_info_count
T@"NSArray",R,N
Tf,R,N
phonemes_enumerateObjectsUsingBlock:
phonemes_objectAtIndex:
phonemes_count
word_phonemes_enumerateObjectsUsingBlock:
word_phonemes_objectAtIndex:
word_phonemes_count
prompts_enumerateObjectsUsingBlock:
dataWithBytes:length:
prompts_objectAtIndex:
prompts_count
T@"NSData",R,N
normalized_text_enumerateObjectsUsingBlock:
phoneme_sequence_enumerateObjectsUsingBlock:
replacement_enumerateObjectsUsingBlock:
neural_phoneme_sequence_enumerateObjectsUsingBlock:
normalized_text_objectAtIndex:
normalized_text_count
phoneme_sequence_objectAtIndex:
phoneme_sequence_count
replacement_objectAtIndex:
replacement_count
neural_phoneme_sequence_objectAtIndex:
neural_phoneme_sequence_count
resources_enumerateObjectsUsingBlock:
resources_objectAtIndex:
resources_count
Ti,R,N
T@"OPTTSTextToSpeechSpeechFeatureInputWave",R,N
T@"OPTTSTextToSpeechUserVoiceProfile",R,N
T@"OPTTSTextToSpeechRequestMeta",R,N
T@"OPTTSTextToSpeechRequestContext",R,N
T@"OPTTSTextToSpeechRequestExperiment",R,N
T@"OPTTSTTSRequestFeatureFlags",R,N
T@"OPTTSTextToSpeechRequestDebug",R,N
T@"OPTTSTextToSpeechUserProfile",R,N
T@"OPTTSTextToSpeechRequestDevConfig",R,N
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",R,N
T@"OPTTSTextToSpeechRequestProsodyControlConfig",R,N
Td,R,N
TI,R,N
T@"OPTTSAudioDescription",R,N
T@"OPTTSTextToSpeechMeta",R,N
word_timing_info_enumerateObjectsUsingBlock:
word_timing_info_objectAtIndex:
word_timing_info_count
T@"OPTTSTextToSpeechFeature",R,N
content_immutableClassForType:
content_typeForImmutableObject:
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
initWithCurrentProcess
loggerForCurrentProcess
speechId
UUID
UUIDString
voiceName
serverLogs
appId
experimentId
underlyingRequest
setVoiceName:
setSpeechId:
setAppId:
setExperimentId:
requestCreatedTime
setRequestCreatedTime:
setServerLogs:
_serverLogs
_language
_voiceName
_speechId
_appId
_experimentId
_requestCreatedTime
T@"NSString",C,N,V_language
T@"NSString",C,N,V_text
T@"NSString",C,N,V_voiceName
T@"NSString",C,N,V_speechId
T@"NSString",C,N,V_appId
T@"NSString",C,N,V_experimentId
TQ,N,V_requestCreatedTime
TB,N,V_serverLogs
audioStreamBasicDescription
stringByReplacingOccurrencesOfString:withString:
initWithOspreyBeginResponse:
voiceLanguage
voiceFootprint
voiceType
voiceGender
voiceVersion
resourceLanguage
resourceVersion
bufferDuration
_voiceLanguage
_voiceFootprint
_voiceType
_voiceGender
_voiceVersion
_resourceLanguage
_resourceVersion
_bufferDuration
T@"NSString",R,N,V_voiceLanguage
T@"NSString",R,N,V_voiceName
T@"NSString",R,N,V_voiceFootprint
T@"NSString",R,N,V_voiceType
T@"NSString",R,N,V_voiceGender
Tq,R,N,V_voiceVersion
T@"NSString",R,N,V_resourceLanguage
Tq,R,N,V_resourceVersion
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
Td,R,N,V_bufferDuration
_timestamp
Td,N,V_timestamp
componentsJoinedByString:
processServerLogs:
initWithOspreyPartialResponse:
audioData
timingInfos
_audioData
_timingInfos
T@"NSData",R,N,V_audioData
T@"NSArray",R,N,V_timingInfos
initWithURL:configuration:
setUseCompression:
setClientTraceIdentifier:
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
initializeDeviceAuthenticationSessionWithCompletion:
preconnect
streamTTS:beginHandler:chunkHandler:completion:
grpcChannel
setGrpcChannel:
_grpcChannel
T@"OspreyChannel",&,N,V_grpcChannel
_name
T@"NSString",&,N,V_language
T@"NSString",&,N,V_name
resourcesWithType:subType:
isInstalled
primaryLanguage
contentPath
sharedInstance
T@"SiriTTSService_TTSAXResourceManager",R,N
allCompactResources
setAllCompactResources:
axManager
setAxManager:
_allCompactResources
_axManager
T@"NSArray",&,N,V_allCompactResources
T@"TTSAXResourceManager",&,N,V_axManager
fetchHardwareInfo
defaultOutput
routeType
isBluetooth
isAppleProduct
vendorId
productId
_isBluetooth
_isAppleProduct
_routeType
_vendorId
_productId
T@"NSString",R,V_routeType
TB,R,V_isBluetooth
TB,R,V_isAppleProduct
Tq,R,V_vendorId
Tq,R,V_productId
NewAssetNotification
_postNewAssetNotification
_hasTrialEntitlements
_gryphonVoiceCompatibility
assetType
assetSource
technology
identifier
versionNumber
versionDescription
supportedLanguages
diskSize
attributes
bundle
_assetType
_assetSource
_technology
_quality
_identifier
_versionNumber
_versionDescription
_supportedLanguages
_primaryLanguage
_gender
_age
_diskSize
_attributes
_bundle
T@"TTSAssetType",R,N,V_assetType
T@"TTSAssetSource",R,N,V_assetSource
T@"TTSAssetTechnology",R,N,V_technology
T@"TTSAssetQuality",R,N,V_quality
T@"NSString",R,N,V_name
T@"NSString",R,N,V_identifier
Tq,R,N,V_versionNumber
T@"NSString",R,N,V_versionDescription
T@"NSArray",R,N,V_supportedLanguages
T@"NSString",R,N,V_primaryLanguage
Tq,R,N,V_gender
T@"NSNumber",R,N,V_age
T@"NSNumber",R,N,V_diskSize
T@"NSDictionary",R,N,V_attributes
T@"NSBundle",R,N,V_bundle
initWithString:
description
string
_string
T@"NSString",R,N,V_string
audibleContext
audioSessionId
setAudioSessionId:
immediate
setImmediate:
siriRequestId
setSiriRequestId:
didStartSpeaking
setDidStartSpeaking:
T@"SiriTTSAudibleContext",&,D,N
synthesisContext
contextInfo
setContextInfo:
customResourceURLs
setCustomResourceURLs:
disableCompactVoice
setDisableCompactVoice:
synthesisProfile
setSynthesisProfile:
prosodyProperties
setProsodyProperties:
didGenerateAudio
setDidGenerateAudio:
didGenerateWordTimings
setDidGenerateWordTimings:
whisper
setWhisper:
T@"SiriTTSSynthesisContext",&,D,N
encodeObject:forKey:
encodeInteger:forKey:
lock
unlock
sleepForTimeInterval:
supportsSecureCoding
setSupportsSecureCoding:
setAudioData:
packetCount
setPacketCount:
packetDescriptions
setPacketDescriptions:
encodeWithCoder:
initWithCoder:
isEqual:
initWithDomain:code:userInfo:
getBytes:length:
decodeIntegerForKey:
setSynthesisContext:
timebase
enqueueSampleBuffer:
flush
isReadyForMoreMediaData
requestMediaDataWhenReadyOnQueue:usingBlock:
stopRequestingMediaData
hasSufficientMediaDataForReliablePlaybackStart
hash
superclass
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
debugDescription
setAudibleContext:
didStartSpeakingWithRequestId:
didReportInstrumentWithRequestId:instrumentationMetrics:
didGenerateAudioWithRequestId:audio:
didGenerateWordTimingsWithRequestId:wordTimingInfo:
pingWithReply:
keepActive:reply:
prewarmWithRequest:reply:
speakWithAudioRequest:reply:
speakWithSpeechRequest:reply:
cancelWithRequest:
synthesizeWithRequest:reply:
textToPhonemeWithRequest:reply:
signalWithInlineStreaming:
forwardWithStreamObject:
subscribeWithVoices:
subscribedVoicesWithClientId:reply:
downloadedVoicesMatching:reply:
queryPhaticCapabilityWithVoice:reply:
isSpeakingWithAccessoryId:reply:
getAudioPowerWithAccessoryId:reply:
killDaemon
emitMessage:
emitMessage:timestamp:
resolvePartialMessage:
resolvePartialMessage:timestamp:
enqueueLargeMessageObjectFromPath:assetIdentifier:messageMetadata:completion:
barrierWithCompletion:
removeItemAtURL:error:
voiceAssetKey
voiceResourceAssetKey
removeObserver:
addObserverForName:object:queue:usingBlock:
objectForKey:
stringForKey:
floatForKey:
boolForKey:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
postNotificationName:object:
infoDictionary
URLForResource:withExtension:subdirectory:
initWithContentsOfURL:
bundleWithIdentifier:
fileHandleForUpdatingAtPath:
fileDescriptor
removeItemAtPath:error:
temporaryDirectory
URLForDirectory:inDomain:appropriateForURL:create:error:
processInfo
globallyUniqueString
fileExistsAtPath:
createFileAtPath:contents:attributes:
closeFile
purge
downloadWithReservation:useBattery:progress:then:
cancelDownloadingThen:
purgeImmediately:
legacyAssetWithBundle:
streamId
defaultSessionConfiguration
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
initWithPath:
locallyAvailable
isDeletableFileAtPath:
downloading
removeLevelsForFactors:withNamespace:queue:completion:
removeLevelsForFactorsImmediately:withNamespace:queue:completion:
purgeable
factor
level
directoryValue
hasAsset
metadata
hasPath
levelForFactor:withNamespaceName:
setAllowsCellularAccess:
setDiscretionaryBehavior:
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
removeDownloadStatusHandlersWithToken:
initWithURL:
handleProxyEvent:reply:connection:
bundlePath
pathComponent
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
compact
premium
premiumhigh
beta
production
livability
staging
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didEndElement:namespaceURI:qualifiedName:
parser:foundCharacters:
initWithType:
returnTypes:
setDoNotBlockBeforeFirstUnlock:
setDoNotBlockOnNetworkStatus:
queryMetaDataSync
isCatalogFetchedWithinThePastFewDays:
results
setDiscretionary:
setAllowsExpensiveAccess:
startCatalogDownload:options:then:
waitUntilDate:
broadcast
addKeyValueArray:with:
setDelegate:
parse
operatingSystemVersion
waitForCatalogUpdates
parserDidStartDocument:
parserDidEndDocument:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundElementDeclarationWithName:model:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:didStartMappingPrefix:toURI:
parser:didEndMappingPrefix:
parser:foundIgnorableWhitespace:
parser:foundProcessingInstructionWithTarget:data:
parser:foundComment:
parser:foundCDATA:
parser:resolveExternalEntityName:systemID:
parser:parseErrorOccurred:
parser:validationErrorOccurred:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
refresh
factorLevelsWithNamespaceName:
numberOfMatchesInString:options:range:
clientWithIdentifier:
addUpdateHandlerForNamespaceName:queue:usingBlock:
wait
setServer:forType:
setServer:forType:source:
getServerForType:
getServerForType:source:
describeServer:forType:
describeServer:source:
initWithArray:
valueForEntitlement:
__swift_objectForKeyedSubscript:
getLocalFileUrl
state
wasLocal
cancelDownload:
purgeSync
refreshState
setRequiresPowerPluggedIn:
attachProgressCallBack:
startDownload:then:
expectedTimeRemaining
totalWritten
totalExpected
bundleForClass:
bundleURL
initWithContentsOfFile:
setObject:forKey:
integerForKey:
initWithSuiteName:
removeObjectForKey:
errorCode
errorMessage
signal
streamingPlaybackBufferSize
decoderStreamDescription
sampleRate
formatID
unsignedIntValue
formatFlags
bytesPerPacket
framesPerPacket
bytesPerFrame
channelsPerFrame
bitsPerChannel
speechSynthesisResource
languageCode
speechSynthesisVoice
contentVersion
audioInfo
wordTimingInfoList
URLForResource:withExtension:
propertyListWithData:options:format:error:
bundleIdentifier
predefinedStringOf:language:table:
pathForResource:ofType:inDirectory:
URLsForDirectory:inDomains:
fileExistsAtPath:isDirectory:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
pathForResource:ofType:
assistantGender
assistantOrder
isCustom
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
assistantVoiceMaps
rolloutIdWithNamespaceName:
thermalState
isLowPowerModeEnabled
initWithUUIDBytes:
retrieveSessionWithID:
setAudioSession:
setDelaysRateChangeUntilHasSufficientMediaData:
addRenderer:
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
renderers
audioSession
opaqueSessionID
currentTime
valueWithCMTime:
addBoundaryTimeObserverForTimes:queue:usingBlock:
removeTimeObserver:
setRate:time:
isOlder:
isNewer:
dictionaryForKey:
initWithStreamDescription:
initFromFormat:toFormat:
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
reset
streamDescription
convertToBuffer:error:withInputFromBlock:
localizedDescription
audioBufferList
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
seekToOffset:error:
closeAndReturnError:
writeData:
archivedDataWithRootObject:requiringSecureCoding:error:
readDataOfLength:
fileHandleForUpdatingURL:error:
mainBundle
objectForInfoDictionaryKey:
initWithContentsOfURL:options:error:
currentDirectoryPath
invalidate
remoteObjectProxyWithErrorHandler:
encodeDouble:forKey:
valueWithRange:
encodeInt64:forKey:
encodeBool:forKey:
encodeInt32:forKey:
encodeFloat:forKey:
initWithStartTiming:textRange:
utterance
setUtterance:
audioOutputRoute
setAudioOutputRoute:
clientBundleIdentifier
setClientBundleIdentifier:
experimentIdentifier
setExperimentIdentifier:
eagerRequestGapInterval
setEagerRequestGapInterval:
synthesisBeginTime
setSynthesisBeginTime:
synthesisEndTime
setSynthesisEndTime:
speechBeginTime
setSpeechBeginTime:
speechEndTime
setSpeechEndTime:
speechEstimatedOutputBeginTime
setSpeechEstimatedOutputBeginTime:
audioStartLatency
setAudioStartLatency:
serverFirstPacketTime
setServerFirstPacketTime:
serverLastPacketTime
setServerLastPacketTime:
serverStreamedAudioDuration
setServerStreamedAudioDuration:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
sourceOfTTS
setSourceOfTTS:
setErrorCode:
isServerTTSRacing
setIsServerTTSRacing:
promptCount
setPromptCount:
neuralAlignmentStall
setNeuralAlignmentStall:
neuralAudioClick
setNeuralAudioClick:
neuralFallback
setNeuralFallback:
isAudibleRequest
setIsAudibleRequest:
forceOspreyTTS
setForceOspreyTTS:
outputPath
setOutputPath:
didReportInstrument
setDidReportInstrument:
initWithAudio:
initWithText:voice:
phonemeSystem
setPhonemeSystem:
initWithText:voice:phonemeSystem:
footprint
setFootprint:
initWithLanguage:name:
clientId
setClientId:
accessoryId
setAccessoryId:
initWithLanguage:
initWithText:identifier:
keepActive
setKeepActive:
initWithAccessoryId:
prewarmWithRequest:didFinish:
synthesizeWithRequest:didFinish:
speakWithSpeechRequest:didFinish:
speakWithAudioRequest:didFinish:
isSpeaking:
getAudioPower:
estimateDurationWithSynthesisRequest:didFinish:
textToPhonemeWithRequest:didFinish:
sharedStream
derivedIdentifierForComponentName:fromSourceIdentifier:
initWithMachServiceName:options:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
setRemoteObjectInterface:
setInvalidationHandler:
setInterruptionHandler:
setExportedInterface:
setExportedObject:
synchronousRemoteObjectProxyWithErrorHandler:
resume
decodeInt64ForKey:
decodeBoolForKey:
decodeFloatForKey:
decodeObjectForKey:
decodeInt32ForKey:
decodeDoubleForKey:
rangeValue
setSpeechContext:
setEventMetadata:
eventMetadata
initWithNSUUID:
setTtsId:
captureSnapshot
logWithEventContext:ttsIdentifier:
setEnded:
setContextId:
setSynthesizedAudioDurationInSecond:
setSynthesisLatencyInSecond:
setSynthesisRealTimeFactor:
setErrorCodes:
setVoiceFallbackOccurred:
setVoiceSettings:
voiceSettings
setVoiceGender:
convertLanguageCodeToSchemaLocale:
setVoiceAccent:
setVoiceType:
setVoiceFootprint:
setVoiceVersion:
setFailed:
setCancelled:
setExists:
setRequestReceivedTier1:
setRequestReceived:
linkId
setLinkId:
setRequestedVoiceContext:
requestedVoiceContext
setInputTextLength:
setTextToSynthesize:
setSource:
setTarget:
setUuid:
setComponent:
setStartedOrChanged:
setAudioInterface:
audioInterface
setVendorId:
setProductId:
setCustomerPerceivedLatencyInSecond:
setSynthesisSource:
setVoiceContext:
voiceContext
setResourceVersion:
setSynthesisEffect:
relatedAssetsWithOnlyAvailable:
listAssetsOfTypes:matching:
bestAssetOfTypes:matching:
@48@0:8@16@24q32^@40
@16@0:8
v24@0:8@16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
v16@0:8
@"NSString"
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
B16@0:8
v20@0:8B16
f16@0:8
v20@0:8f16
Q16@0:8
v24@0:8Q16
@?16@0:8
v24@0:8@?16
B24@0:8@16
@40@0:8@16@24^@32
B32@0:8@16^@24
B24@0:8^@16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^v16@0:8
v24@0:8^v16
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8q16
i16@0:8
v20@0:8i16
I16@0:8
v20@0:8I16
#24@0:8q16
q24@0:8@16
@"NSData"16@0:8
@24@0:8@16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
@"NSData"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
@24@0:8Q16
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@"NSArray"
@32@0:8@16@24
v48@0:8@16@?24@?32@?40
@"OspreyChannel"
@"TTSAXResourceManager"
@"TTSAssetType"
@"TTSAssetSource"
@"TTSAssetTechnology"
@"TTSAssetQuality"
@"NSNumber"
@"NSDictionary"
@"NSBundle"
ar-SA
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
en-scotland
es-AR
es-CO
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
nb-NO
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
ar-SA
da-DK
de-DE
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-CL
Hola, soy Siri.
es-ES
Hola, soy Siri.
es-MX
Hola, soy Siri.
fi-FI
fr-CA
fr-FR
he-IL
it-IT
ja-JP
ko-KR
nb-NO
nl-BE
nl-NL
pt-BR
ru-RU
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
oren
O-ren
O-ren
O-ren
limu
Li-mu
Li-mu
Li-mu
Yu-shu
Yu-shu
Sin-ji
Sin-Ji
Azul
Sydney
Star
StarBravo
SkyE
SkyEcho
speak
oren
sakura
hattori
hiro
ar-001_Maged
ar-SA
ca-ES
cs-CZ_Zuzana
cs-CZ
da-DK_Sara
da-DK
de-DE_Anna
de-DE
el-GR_Melina
el-GR
en-AU_Karen
en-AU
en-GB_Daniel
en-GB
en-IE_Moira
en-IE
en-IN_Rishi
en-IN
en-US_Samantha
en-US
en-ZA_Tessa
en-ZA
es-ES_Monica
es-ES
es-MX_Paulina
es-MX
fi-FI_Satu
fi-FI
fr-CA_Amelie
fr-CA
fr-FR_Thomas
fr-FR
he-IL_Carmit
he-IL
hi-IN_Lekha
hi-IN
hr-HR_Lana
hr-HR
hu-HU_Mariska
hu-HU
id-ID_Damayanti
id-ID
it-IT_Alice
it-IT
ja-JP_Kyoko
ja-JP
ko-KR_Yuna
ko-KR
ms-MY_Amira
ms-MY
nl-BE_Ellen
nl-BE
nl-NL_Xander
nl-NL
nb-NO_Nora
no-NO
pl-PL_Zosia
pl-PL
pt-BR_Luciana
pt-BR
pt-PT_Joana
pt-PT
ro-RO_Ioana
ro-RO
ru-RU_Milena
ru-RU
sk-SK_Laura
sk-SK
sv-SE_Alva
sv-SE
th-TH_Kanya
th-TH
tr-TR_Yelda
tr-TR
uk-UA_Lesya
uk-UA
vi-VN_Linh
vi-VN
zh-CN_Tingting
zh-CN
zh-HK_Sinji
zh-HK
zh-TW_Meijia
zh-TW
com.apple.siri
com.apple.siri
Name
Language
Gender
Technology
Quality
Available
Obsolete
Source
@(#)PROGRAM:SiriTTSService  PROJECT:SiriTTSService-1
?mcpl
L?NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_0NS_9allocatorIS2_EEFvRKNS_6vectorIfNS3_IfEEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIfNS_9allocatorIfEEEEEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_0
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_1
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_2NS_9allocatorIS2_EEFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS3_IS7_EEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS_9allocatorIS4_EEEEEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_2
NSt3__110__function6__funcIZ43-[SiriTTSSynthesisEngine synthesize:error:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z43-[SiriTTSSynthesisEngine synthesize:error:]E3$_3
N5apple4aiml12flatbuffers216DefaultAllocatorE
N5apple4aiml12flatbuffers29AllocatorE
SiriTTSService
AudioPlaybackError
AudioRouteInfo
AudioData
AudioPlayback
BufferedAudioPlayback
AudioPower
AudioPowerProviding
AudioInterface
AudioQueueInterface
AudioQueueBufferUserData
_NSRange
CMSampleBuffer
NCMSampleBufferRef
CMTime
AudioTimeStamp
ThermalState
NNSProcessInfoThermalState
URLResourceKey
NNSURLResourceKey
Name
NNSNotificationName
AudioQueueLevelMeterState
AudioStreamPacketDescription
AudioStreamBasicDescription
Foundation
TRIOnDemandFactorDownloadStatus
CFString
NCFStringRef
TTSAssetVoiceGender
TTSAssetProperty
CMTimeFlags
AudioTimeStampFlags
SMPTETime
SMPTETimeFlags
SMPTETimeType
"*2{
#&)/5>GORYailu
DiagnosticService
MetricsJsonKeys
"(09@BJSZaeimv
%-7?JLVajsvy
J!S&+Z06
$+bj2r;}BI
SiriTTSService
CacheReadingAction
$*2;DGOX_fjnt}
VoiceAttribute
TTSAssetStubStrategy
MappedData
PassThroughAction
SynthesisConfigProviding
InlineStreamingStorage
EngineCachingService
SignpostHandler
MobileGestalt
Features
NeuralUtils
Locked
Flags
RetryTextModificationAction
OspreyClient
TTSAssetTrialAsset
TTSAssetTrialVoiceAsset
TTSAssetTrialResourceAsset
TTSAssetAdhocStrategy
TextToPhonemeAction
TTSAssetStrategy
SiriFeatures
TTSAssetFeatures
 $(,04:BK
"&*04:>FP\
#'+/5;A
Event
NotificationHandling
OptionalNotificationHandling
 &-6;BGLTZ
TTSAssetTrialProxyInstantiatedAsset
TTSAssetProxyCallback
TTSAssetProxyProgressCallback
TTSAssetProxyPathCallback
TTSAssetProxyStrategy
ProxyKey
TTSAssetMAStrategy
DownloadSourceExtractor
OSVersion
TTSAssetTrialStrategy
AssetClass
WorkflowErrorHandler
Workflow
DataContainer
Buffer
Actionable
Conditional
AsynchronousContext
Asynchronous
WorkflowNode
WorkflowCondition
SynthesisCacheWritingAction
Constants
DaemonXPCAllowedTypeSets
Entitlements
TTSAssetProxyAsset
SynthesisEngineSelectionAction
DependencyInjectable
ObjectPool
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-GD
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
TTSAssetMAAsset
TTSAssetMACompactAsset
DefaultMacinTalkProperties
DefaultVocalizerProperties
PreinstalledWordTimingStorage
AudioPowerHandler
supo
OpusEncodingAction
InternalSettings
Default
InlineStreamingAction
$$$$$$$
%')+
TTSError
TTSErrorCode
DirectedAcyclicGraph
Languages
RequestPreprocessAction
TTSAssetStaticVoice
TTSAssetAdhocVoice
TTSAssetPreinstalledVoice
TTSAssetStaticResource
TTSAssetAdhocResource
Localization
DelegateHandler
AudioFile
AudioDumpAction
AssistantAsset
AssistantVoiceMaps
HasAudioCondition
CoreAnalyticsInterface
CoreAnalyticsService
CoreAnalyticsSynthesisHandler
TrialAssetProvider
VoiceAsset
ResourceAsset
LocalAssetProvider
BuiltInVoiceProvider
VocalizerCustomVoiceProvider
PreinstalledVoiceProvider
OspreyTTSAction
VoiceSelectionAction
RequestParsingAction
Logger
AVSBARPlayback
AudioMappedInfoAVSBAR
AudioPlaybackServiceState
Timeout
AudioPlaybackAction
TTSAssetPreinstalledStrategy
DeviceSynthesisAction
Preferences
OpusEncoder
CacheStorage
SynthesisCacheFile
SynthesisCacheChunkIterator
SynthesisCache
CodingKeys
TTSAssetLegacyAsset
VoiceDescription
VoiceSpec
PreinstalledAudioStorage
OspreyConfigProviding
OspreyBuiltInConfig
OspreyChainedConfigs
WeakDaemonDelegateWrapper
DaemonConnection
SiriTTSService
WordTimingInfo
InstrumentationMetrics
SourceOfTTS
AudibleContext
ProsodyProperties
SynthesisContext
SynthesisProfile
BaseRequest
AudioRequest
SynthesisRequest
PhonemeRequest
PhonemeSystem
SpeechRequest
SynthesisVoice
Footprint
VoiceType
VoiceGender
SynthesisVoiceSubscription
SynthesisResource
InlineStreamingSignal
DaemonSession
OspreyTTSPrewarmAction
SiriAnalyticsHandler
female
male
unspecifB
Partition
SiriTTSPhonemeTool
Unknown phoneme system: %d
service
SiriTTSSynthesisEngine
Empty voice path cannot be used.
TTSSynthesizer::initialize error: %@
mimeType
TTSSynthesizer::load_voice_resource
tts.feature.prompt
tts.neural.use_fallback
TTSSynthesizer::synthesize_text
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
SiriTTSNeuralUtils
fe_feature
fe_feature_only
quality
channel_type
app_id
context_info
dialog_identifier
experiment_identifier
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
phonemes
word_phonemes
prompts
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data
resources
return_log
voice_asset_path
resource_asset_path
return_server_info
sample_rate
pcm_data
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
speech_id
session_id
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
value
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
stream_id
error_code
error_str
decoder_description
playback_description
streaming_playback_buffer_size_in_seconds
current_pkt_number
word_timing_info
feature
total_pkt_number
content_type
content
v24@?0^v8Q16
v32@?0@8Q16^B24
v20@?0r*8I16
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
cur_
scratch_end
scratch_
scratch_data
buf_
Finished
finished
ReferTo
off && off <= GetSize()
EndVector
i < size()
Finish
strlen(file_identifier) == kFileIdentifierLength
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
v16@?0@"OspreyMutableRequest"8
OspreyTTSService
Corrupted Osprey response.
-[SiriTTSOspreyChannel streamTTS:beginHandler:chunkHandler:completion:]_block_invoke
Unknown response from Osprey for streaming TTS
AXSpeechTransformTextWithLanguage
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
TTSAXResourceManager
Unable to find class %s
com.apple.ttsasset.NewAssetNotification
com.apple.trial.client
, isAppleProduct:
packetDescriptions
, packet count: 
AudioData: Unable to read audio file from 
AudioData: Unable to get audio file format, errno 
AudioData: Unable to get audio data byte count, errno 
AudioData: Unable to get audio data packet count, errno 
AudioData: Unable to get maximum packet size, errno 
AudioData: Unable to get audio data, errno 
Invalid chunk size: %ld at offset %ld, bytes count = %ld
SiriTTSService.AudioPlayback
siritts_audio_playback_queue
AudioService: Unable to create output audio queue, errno 
Unable to dispose AudioQueue, errorCode: %s
AudioService: Unable to start AudioQueue, error 
Unable to begin access power, error: %s
Unable to allocate AudioQueue Buffer, code: 
Unable to enqueue audio data, code: 
Detected stalled audio generation, will enqueue %f silence frame to compensate.
AudioService: Unable to stop AudioQueue immediately, errno 
Unable to get audio power, error: %s
Unable to end access power, error: %s
asbd
audioData
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
VoiceSynthesizerNumericID
VoiceNumericID
VoiceName
VoiceLocalizedNames
VoiceNameRoot
VoiceIdentifier
VoiceAge
VoiceGender
VoiceDemoText
VoiceLanguage
VoiceLocaleIdentifier
VoiceVersion
VoiceScriptCode
VoiceGroup
VoiceType
VoiceRelativeDesirability
VoiceSupportedCharacters
VoiceIndividuallySpokenCharacters
VoiceDiskSize
VoiceAssetDescription
VoiceGenderMale
VoiceGenderFemale
VoiceGenderNeutral
VoiceGenderNeuter
 {}. 
Dobr
 den, jmenuji se {}. Jsem 
 hlas.
Hej, jeg hedder {}. Jeg er en dansk stemme.
Hallo, ich hei
e {} und ich bin eine deutsche Stimme.
 {}. 
Hello, my name is {}. I am an Australian-English voice.
Hello, my name is {}. I am a British-English voice.
Hello, my name is {}. I am an Irish-English voice.
Hello, my name is {}. I am an Indian-English voice.
Hello, my name is {}. I am an American-English voice.
Hello, my name is {}. I am a South African-English voice.
Hello, my name is {}. I am a Scottish-English voice.
Hola, me llamo {} y soy una voz espa
ola.
Hola, me llamo {} y soy una voz mexicana.
Hei, minun nimeni on {}. Olen suomalainen 
Bonjour, je m
appelle {}. Je suis une voix canadienne.
Bonjour, je m
appelle {}. Je suis une voix fran
aise.
m! {} vagyok. 
n vagyok a magyar hang.
Halo, nama saya {}. Saya berbahasa Indonesia.
Salve, mi chiamo {} e sono una voce italiana.
Hallo, mijn naam is {}. Ik ben een Belgische stem.
Hallo, mijn naam is {}. Ik ben een Nederlandse stem.
Hei, jeg heter {}. Jeg er en norsk stemme.
Witaj. Mam na imi
 {}, jestem g
osem kobiecym dla j
zyka polskiego.
, o meu nome 
 {} e a minha voz corresponde ao portugu
s que 
 falado no Brasil
, chamo-me {} e dou voz ao portugu
s falado em Portugal.
 cheam
 {}. Sunt o voce rom
neasc
 {}. 
Ahoj. Vol
m sa {}. Som hlas v slovenskom jazyku.
Hej, jag heter {}. Jag 
r en svensk r
Merhaba, benim ad
m {}. Ben T
e bir sesim.
 Siri!
Hej, jeg er Siri.
Hallo, ich bin Siri.
Hello, I'm Siri.
Hei, min
 olen Siri.
Bonjour, je suis Siri.
 Siri.
Ciao, sono Siri.
Siri
 Siri
Hei, jeg er Siri.
Hallo, ik ben Siri.
Oi, meu nome 
 Siri.
 Siri.
Hej, jag heter Siri.
 Siri
Merhaba, ben Siri.
Siri
Hello
Siri
Siri
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
cookie
authTokens
SIRI_TEXT_TO_SPEECH
voice
SIRITTSSERVICE_NETWORK_STALL_1
SIRITTSSERVICE_NETWORK_STALL_2
SIRITTSSERVICE_NETWORK_STALL_3
ca-ES_Montserrat
paused
started
waitForFinish
stopped
magicVersion
timingInfos
com.apple.springboard
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
com.apple.voicetool
com.apple.siri.tts.SiriTTSServiceIntegrationTests.xctrunner
com.apple.siritts-tool
synthesisContext
SiriTTSAudioData
supportsSecureCoding
TB,N
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
v24@0:8q16
@24@0:8@16
T{AudioStreamBasicDescription=dIIIIIIII},N,Vasbd
T@"NSData",N,C
Tq,N,VpacketCount
T@"NSString",N,R
B24@0:8@16
audioInterface
audioOperationQueue
playbackError
audioSequence
_TtC14SiriTTSService19AudioQueueInterface
discontinuedDuringPlayback
outputRouteInfo
audioQueue
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
_TtCC14SiriTTSService19AudioQueueInterfaceP33_D074378E45DF23C69F519544CB6674D224AudioQueueBufferUserData
expectedPlaySampleTime
SiriTTSServiceAudioPlayback
Unable to query kAudioQueueProperty_IsRunning, %s
Unexpected to have startTime == 0
Enqueued audio buffer #%ld, packet count: %ld, bytes: %ld
Played audio buffer #%ld, packet count: %ld, bytes: %ld
Current route info: {%s}
Started AudioQueue.
Starting AudioQueue...
OS_xpc_object
SiriTTSSynthesizingRequestProtocol
T@"SiriTTSSynthesisContext",N,&
@"SiriTTSSynthesisContext"16@0:8
v24@0:8@"SiriTTSSynthesisContext"16
AVQueuedSampleBufferRendering
^{OpaqueCMTimebase=}16@0:8
v24@0:8^{opaqueCMSampleBuffer=}16
v32@0:8@16@?24
timebase
T^{OpaqueCMTimebase=},N,R
readyForMoreMediaData
hasSufficientMediaDataForReliablePlaybackStart
v32@0:8@"OS_dispatch_queue"16@?<v@?>24
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
hash
superclass
T#,N,R
debugDescription
B24@0:8@"Protocol"16
@"NSString"16@0:8
SiriTTSAudibleRequestProtocol
T@"SiriTTSAudibleContext",N,&
@"SiriTTSAudibleContext"16@0:8
v24@0:8@"SiriTTSAudibleContext"16
TRINotificationToken
_TtP14SiriTTSService22DaemonDelegateProtocol_
v32@0:8Q16@"SiriTTSInstrumentationMetrics"24
v32@0:8Q16@"SiriTTSAudioData"24
v32@0:8Q16@"NSArray"24
v24@0:8@?<v@?>16
_TtP14SiriTTSService14DaemonProtocol_
v28@0:8B16@?20
v28@0:8B16@?<v@?@"NSError">20
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSAudioRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSSpeechRequest"16@?<v@?@"NSError">24
v24@0:8@"SiriTTSBaseRequest"16
v32@0:8@"SiriTTSPhonemeRequest"16@?<v@?@"NSString"@"NSError">24
v24@0:8@"SiriTTSInlineStreamingSignal"16
v24@0:8@"SATTSSpeechSynthesisStreaming"16
v24@0:8@"NSArray"16
v32@0:8@"NSString"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?ff>24
SiriAnalyticsMessageStream
v32@0:8@16Q24
v48@0:8@16@24@32@?40
v24@0:8@"SISchemaTopLevelUnionType"16
v32@0:8@"SISchemaTopLevelUnionType"16Q24
v48@0:8@"NSString"16@"NSUUID"24@"SISchemaInstrumentationMessage"32@?<v@?B@"NSError">40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
Unable to remove file %s
_TtC14SiriTTSService17DiagnosticService
notificationCenter
observers
requestId
Unable to encode json data
Unable to locate data dump directory
Unable to write json metrics at %s, %s
Json metrics saved to: %s
Instrumentation Metrics Data (id: %llu):
v16@?0@"NSNotification"8
Event '%s' expect associated object as %s, got: %s
SynthesisResource
InstrumentationMetrics
Array<WordTimingInfo>
AudioPowerProviding
siriInlineOneShot
siriInlineStreaming
siriServerRoundTrip
Unable to list content of directory %{public}s
No request is provided. Ignore reading cache.
No cache storage is provided. Ignore reading cache.
No voice is provided. Ignore reading cache.
No resource is provided. Ignore reading cache.
Synthesis cache is found for request %@
Preinstalled audio is found for request %@
Ignore reading cache due to internal settings disables caching.
_TtC14SiriTTSService18CacheReadingAction
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
VoiceGroupCustom
Swift/Dictionary.swift
VoiceGroupCustomCompact
VoiceGroupCompact
SupportedCharacters
com.apple.siri.SiriTTSService
_TtC14SiriTTSService20TTSAssetStubStrategy
_TtC14SiriTTSService10MappedData
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
Unable to handle mmap file, errno: %d, error: %s
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file to length: %ld, errno: %d, error: %s
Unable to mmap file at path: %{public}s, errno: %d, error: %s
_TtC14SiriTTSService17PassThroughAction
SiriTTSService
v44@0:8@16B24@?28@?36
v24@0:8@?16
v20@0:8B16
Cleared inline streaming object storage.
Notification for %s has not started. Cache object %@
Found cached objects %@
Start streaming for %s
_TtC14SiriTTSService22InlineStreamingStorage
storage
streamingHandlers
signals
lock
Notification for %s is on-going. Posting object immediately %@
InlineStreamStorage
_TtC14SiriTTSService20EngineCachingService
_activeSessionCount
_cachedEngine
_TtC14SiriTTSService15SignpostHandler
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
TTSPlayback
[Error] Interval already ended
TTSStartAudio
TTSServerFirstPacket
TTSEngineSelect
engineTag=%s
TTSVoiceSelect
voice=%s
TTSSynthesis
source=%s
HardwarePlatform
lowInactiveMemory
VoiceServices
VoiceSelectionAction: Cannot find synthesizing request
_TtC14SiriTTSService27RetryTextModificationAction
v16@?0@"SiriTTSOspreyStreamingBeginResponse"8
v16@?0@"SiriTTSOspreyStreamingPartialResponse"8
v16@?0@"NSError"8
_TtC14SiriTTSService12OspreyClient
grpcChannel
speechId
https://carry-dejavu.siri.apple.com
https://dejavu.apple.com
ttsContentVersion
Trial asset %{public}@ not downloading, unable to cancel
Trial asset %{public}@ already downloaded, unable to cancel
v20@?0B8@"NSError"12
SiriTTSService.TTSAssetTrialAsset
_TtC14SiriTTSService18TTSAssetTrialAsset
factorName
assetAttr
isDownloading
downloadToken
assetSource
T@"TTSAssetSource",N,R
versionDescription
diskSize
T@"NSNumber",N,R
supportedLanguages
T@"NSArray",N,R
T@"NSBundle",N,R
locallyAvailable
_TtC14SiriTTSService23TTSAssetTrialVoiceAsset
T@"TTSAssetType",N,R
technology
T@"TTSAssetTechnology",N,R
T@"TTSAssetQuality",N,R
name
identifier
gender
T@"NSDictionary",N,R
_TtC14SiriTTSService26TTSAssetTrialResourceAsset
com.apple.speech.synthesis.voice.
com.apple.speech.synthesis.voice.custom.siri.
Missing name for voice
Missing footprint for voice
Unknown footprint for voice: %@
Missing asset type for voice
Unknown asset type for voice: %@
Asset %s attributes %s level %@
Unable to initialize asset bundle from path: %{public}s
MobileAssetProperties
Asset %s path %s
Unable to get level for factor name '%{public}s'
Trial asset %{public}@ immediate removal failed with error %@
Trial asset %{public}@ immediate removal succeeded
Trial asset %{public}@ deferred removal failed with error %@
Trial asset %{public}@ deferred removal succeeded
Trial asset %{public}@ download cancellation failed with error %@
Trial asset %{public}@ download cancelled
Trial asset %{public}@ start download
Trial asset %{public}@ download failed with error %@
Trial asset %{public}@ download succeeded
Trial download %u%% done, %.2fs left %d written status %d
v24@?0d8Q16
_TtC14SiriTTSService21TTSAssetAdhocStrategy
Skip invalid voice folder '%s'
Skip invalid resource folder '%s'
#Local listing assets for types: %s, filter: %s
Unable to list resource folder %s
/private/var/mobile/Library/VoiceServices/resources/
Unable to list voice folder %s
/private/var/mobile/Library/VoiceServices/voices/
/System/Library/PrivateFrameworks/TTSAsset.framework/Voices/
TextToPhoneme request is not set
TextToPhoneme voice is not found
_TtC14SiriTTSService19TextToPhonemeAction
engineCachingService
ObjectPool: Unregistered type 
ObjectPool: Constructed wrong object type 
TTSAsset encountered unknown asset type %{public}@ and tentatively tried to handle through Trial
enable_adhoc_voice
use_trial
TTSAsset
sirix
Siri
SiriTTSService.Event.taskCompletion
SiriTTSService.Event.audioPowerProviderAvailable
SiriTTSService.Event.neuralFallback
SiriTTSService.Event.neuralAudioClick
SiriTTSService.Event.neuralAlignmentStall
SiriTTSService.Event.synthesisUsedPrompt
SiriTTSService.Event.encounteredError
SiriTTSService.Event.synthesisEngineChanged
SiriTTSService.Event.receivedServerLastPacket
SiriTTSService.Event.voiceResourceSelected
SiriTTSService.Event.synthesisError
SiriTTSService.Event.eagerRequestDetected
SiriTTSService.Event.cancellationRequested
SiriTTSService.Event.phonemesGenerated
SiriTTSService.Event.audioPlaybackEnded
SiriTTSService.Event.audioPlaybackEnqueued
SiriTTSService.Event.audioPlaybackStarted
SiriTTSService.Event.audioPlaybackStarting
SiriTTSService.Event.receivedServerFirstPacket
SiriTTSService.Event.engineSelectEnd
SiriTTSService.Event.engineSelectStart
SiriTTSService.Event.voiceSelected
SiriTTSService.Event.voiceSelectStart
SiriTTSService.Event.synthesisStarted
SiriTTSService.Event.audioGenerated
SiriTTSService.Event.wordTimingGenerated
SiriTTSService.Event.synthesisEnded
SiriTTSService.Event.encounteredIssue
SiriTTSService.Event.instrumentationMetricsAvailable
SiriTTSService.Event.requestReceived
SiriTTSService1
B40@0:8@16@24@32
_TtC14SiriTTSService35TTSAssetTrialProxyInstantiatedAsset
registry
_TtC14SiriTTSService29TTSAssetProxyProgressCallback
_TtC14SiriTTSService25TTSAssetProxyPathCallback
_TtC14SiriTTSService21TTSAssetProxyStrategy
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
TrialXP (by Proxy)
Failed to establish connection, return empty result from proxy assets
Failed to get value from xpc reply, return empty results from proxy assets
<- %d assets
B24@?0q8@"<OS_xpc_object>"16
Listing asset types %{public}s through XPC service...
Failed to establish connection & sandbox
Failed to get sandbox extensions
Failed to consume sandbox extension %s
Consume sandbox extension %s
v16@?0@"<OS_xpc_object>"8
com.apple.SiriTTSService.TrialProxy
v16@?0@"TTSAsset"8
v32@?0d8q16q24
Unable to issue sandbox extension to path '%{public}s'
Unable to convert C string into Swift string for authToken'
Issued sandbox extension to path %s
Unexpected non Trial asset %{public}@
Unable to get bundle path for factor name %s
com.apple.private.sirittsservice.modify-proxy-assets
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
compact
premium
premiumhigh
beta
production
T@"TTSAssetServer",N,R
livability
staging
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
_TtC14SiriTTSService18TTSAssetMAStrategy
stagingURL
_TtCC14SiriTTSService18TTSAssetMAStrategy23DownloadSourceExtractor
v56@0:8@16@24@32@40@48
v48@0:8@16@24@32@40
v32@0:8@16@24
inKey
wantValue
source
#MobileAsset Unable to create query
Query for %{public}@ failed: %d
Download asset catalogs, sync: %{bool}
#MobileAsset listing assets for type '%@', filter: '%{public}s'
v16@?0q8
Catalog %{public}@ download failed: %d
/var/MobileAsset/AssetsV2/
https://mesu.apple.com/assets/
https://basejumper.apple.com/livability/
Server (default) for %{public}@
Server %{public}@ for %{public}@: %d
https://basejumper.apple.com/assets/
https://basejumper.apple.com/assets
https://basejumper.apple.com/
NSXMLParserDelegate
v24@0:8@16
v40@0:8@16@24@32
@40@0:8@16@24@32
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
NSObject
q16@0:8
description
_TtC14SiriTTSService21TTSAssetTrialStrategy
#Trial Synchronous namespace download took %.1fs
#Trial listing assets for class '%s', types: '%{public}s', filter: '%{public}s'
com.apple.siri.tts.
Factor %s does not have %ld components as expected.
Encountered entirely unexpected factor %s.
Refreshing stale trial client
TTSAsset Trial Callbacks
/private/var/MobileAsset/AssetsV2/com_apple_MobileAsset_Trial_Siri_SiriTextToSpeech/
/Library/Trial/Treatments/
v16@?0@"<TRINamespaceUpdateProtocol>"8
Get namespace update, refreshing trial client
Workflow: waitDequeue timed out in 
Workflow: waitDequeue timed out in %s
Encountered error: %s
Encountered error during error handling: %s
Gracefully handle error: %s
_TtC14SiriTTSService8Workflow
graph
errorHandlers
_isCancelled
cancellationLock
_TtC14SiriTTSService13DataContainer
idContainer
_TtC14SiriTTSService6Buffer
bufferCondition
_TtC14SiriTTSService19AsynchronousContext
isProcessing
asyncError
waitTimeout
isProcessingCondition
_TtC14SiriTTSService12WorkflowNode
action
_TtCC14SiriTTSService12WorkflowNode17WorkflowCondition
conditional
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
(AudioMappedInfoAVSBAR in _4791274A894FA1CB92EFFF8F61E0C16D)
SynthesisVoiceSubscription
Conditional node has no next node, %s
TTSAssetTrialProxyInstantiatedAsset
InlineStreamingSignal
com.apple.ttsasset
SiriTTSService2
B32@0:8@16@24
v8@?0
Ignore writing cache due to missing cache storage
Ignore writing cache due to missing audio data
Ignore writing cache due to missing request info
Ignore writing cache due to missing voice info
Ignore writing cache due to missing voice resource info
Unable to create cache file, error: 
Ignore writing cache with empty data, probably audio prime data
Ignore writing cache since audio is from cache already
Ignore writing cache due to internal settings disable caching
_TtC14SiriTTSService27SynthesisCacheWritingAction
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
Unable to write cache, %s
Invalidate synthesis caching. %s
Synthesis cache %s is written.
Synthesis cache %s is cancelled.
Unable to close cache file, %s
Detected synthesis error.
Detected neural alignment stall.
Detected neural audio click.
Detected neural fallback.
Cancellation is requested.
com.apple.sirittsd
com.apple.sirittsd.can-dump-audio
No bundle path from proxy presentation
Invalid bundle path %{public}s
Constructed bundle %s
Trial proxy download status check failed, unable to establish server connection
-> %@
<- %@
Failed to get download status
Trial proxy asset [%@] not downloading, unable to cancel
Trial proxy asset download cancellation failed, unable to establish server connection
Trial proxy asset [%@] cancelling download.
SiriTTSService.TTSAssetProxyAsset
_TtC14SiriTTSService18TTSAssetProxyAsset
assetQuality
bundlePath
authorizedBundle
proxy_attr
assetType
versionNumber
Tq,N,R
attributes
purgeable
Trial proxy asset [%@] download cancelled.
Trial proxy asset [%@] download cancellation failed.
Trial proxy asset download failed, unable to establish server connection
Trial proxy asset [%@] download starting.
Trial proxy asset [%@] already locally available, no download necessary
Trial proxy asset [%@] download failed.
Trial proxy asset [%@] download succeeded.
.siri.tts.resource.
DeviceSynthesisAction: No voice asset was set
gryphon_frontend
Unable to load resource %s, error: %s
_TtC14SiriTTSService30SynthesisEngineSelectionAction
voice_configs.plist
Unable to load voice_configs.plist from %s
vocalizer_resources
Unable to parse vocalizer_resources
vocalizer_resource_order
Unable to parse vocalizer_resources_order
Unknown mime-type for file %s
_TtC14SiriTTSService10ObjectPool
constructorRegistry
objectPool
speech.synthesis.voice
_MasteredVersion
_CompatibilityVersion
LanguagesCompatibility
SiriTTSService.TTSAssetMAAsset
_TtC14SiriTTSService15TTSAssetMAAsset
asset
bundle
_TtC14SiriTTSService22TTSAssetMACompactAsset
v16@?0@"MAProgressNotification"8
Preposterous string version %{public}@ for key %{public}@ in %@
Preposterous integer version %d for key %{public}@ in %@
_TtC14SiriTTSService29PreinstalledWordTimingStorage
storageURL
voice name is required for preinstalled word timings.
No preinstalled word timings plist file at path %{public}s
Unable to convert raw plist to expected format.
No word timing found voice name %{public}s
Missing word_timings field
Unable to find word '%s'
Missing word timing pair
_TtC14SiriTTSService17AudioPowerHandler
audioPowerProvider
OpusEncodingAction: no audio found
OpusEncodingAction: Audio is already opus encoded
_TtC14SiriTTSService18OpusEncodingAction
encoder
_TtC14SiriTTSService16InternalSettings
_enableDiagnostic
_logSensitiveText
_disableCache
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
logSensitiveText
DisableAssetCleaning
AllowAnyAssetSubscription
defaultToNonDiscretionaryDownloads
EnableLocalVoices
ServerTTSTimeout
DeviceTTSWaitTime
disableDeviceRacing
disableServerTTS
disableInlineStreamTTS
disableOspreyStreaming
streamBufferDuration
ospreyEndpointURL
simulateNetworkStall
simulateAudioStall
disableDeviceNeuralTTS
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
com.apple.voiceservices
process is not running as user Mobile: it's not accessing our shared UserDefaults
InlineStreamingAction: Cannot find request
InlineStreamingAction: Cannot find streaming signal for 
_TtC14SiriTTSService21InlineStreamingAction
asyncContext
streamingStorage
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
InlineStreamingAction: Unknown stream object 
InlineStreamingAction: Unknown inline streaming error 
Received streaming audio chunk before receiving streaming audio begin
Simulate network stall is on, ignore inline streaming objects
InlineStreamingAction: Unsupported inline streaming audio format 
Inline streaming timed out
Inline streaming network stall
Internal setting specifies timeout: %f
sirittsd crashed
RequestParser: Cannot find request.
Overriding whisper with internal default
Overwriting pitch with internal default: %f
Overwriting rate with internal default: %f
Overwriting volume with internal default: %f
_TtC14SiriTTSService9Languages
_TtC14SiriTTSService23RequestPreprocessAction
settings
Error in tn override tag, ignore
<say-as interpret-as="
SSMLConversion: Unbalanced say-as tag
SSMLConversion: Unbalanced phoneme tag
<phoneme alphabet="lhp" ph="
AssistantEtiquette
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/AssistantEtiquette
%{public}s is not TTS language, fallback to %{public}s
tts_language_fallbacks
SiriTTSService/RequestPreprocessAction.swift
_TtC14SiriTTSService19TTSAssetStaticVoice
attr
_TtC14SiriTTSService18TTSAssetAdhocVoice
_TtC14SiriTTSService25TTSAssetPreinstalledVoice
_TtC14SiriTTSService22TTSAssetStaticResource
_TtC14SiriTTSService21TTSAssetAdhocResource
Resource Asset %s path %s attributes %s
SiriTTSService.TTSAssetStaticResource
SiriTTSService/TTSAssetStaticAsset.swift
Subclasses of TTSAssetStaticResource must override assetSource
SiriTTSService.TTSAssetStaticVoice
Subclasses of TTSAssetStaticVoice must override assetSource
_TtC14SiriTTSService12Localization
LocalizedStrings
Unable to find retry phrase '%{public}s', %{public}s
_TtC14SiriTTSService15DelegateHandler
delegate
com.apple.voiceservices.notification.synthesis-done
audibleContext
Unable to create directory at %s, error: %s
%s is not a directory!
Unable to get Library directory for audio dumping
AudioDump: Cannot find audio data.
Unable to find request of AudioDumpAction
Audio saved to: %s
Ignore writing audio file due to missing entitlement. Please add 'com.apple.sirittsd.can-dump-audio'.
_TtC14SiriTTSService9AudioFile
audioFile
packetOffset
_TtC14SiriTTSService15AudioDumpAction
entitlements
diagnosticAudioFile
synthesizedAudioFile
AudioFile: Unable to close audio file, code: 
AudioFile: Unable to write audio data, code: 
AudioFile: Unable to create audio file at path 
Unable to write diagnostic audio file, error: %s
SiriTTSService.AssistantAsset
SiriTTSService.AssistantVoiceMaps
AssistantVoiceMap
VoicePitchRangeDescriptors
TTSAssistantAsset
assistantGender
assistantOrder
Tq,N,R,VassistantGender
Tq,N,R,VassistantOrder
isCustom
TB,N,R
primaryLanguage
TTSAssistantVoiceMaps
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
SiriTTSService3
assistantVoiceMaps
T@"TTSAssistantVoiceMaps",N,R
_TtC14SiriTTSService17HasAudioCondition
voice_resource_asset_key
tts_synthesis_latency
tts_total_latency
audio_queue_latency
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
audio_output_route
client_bundle_identifier
privacy_sensitive
server_first_packet_latency
server_last_packet_latency
com.apple.voiceservices.metrics
real_time_factor
neural_alignment_stall
neural_audio_click
_TtC14SiriTTSService20CoreAnalyticsService
_TtC14SiriTTSService29CoreAnalyticsSynthesisHandler
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
Unrecognized request type in handleRequestReceived, got: %s
_TtC14SiriTTSService10VoiceAsset
path
_TtC14SiriTTSService13ResourceAsset
resource
_TtC14SiriTTSService18TrialAssetProvider
downloadQueue
_TtC14SiriTTSService18LocalAssetProvider
_TtC14SiriTTSService20BuiltInVoiceProvider
_TtC14SiriTTSService28VocalizerCustomVoiceProvider
_TtC14SiriTTSService25PreinstalledVoiceProvider
Unfound built-in voice for language %{public}s
Falling back to no-NO voice since nb-NO is not available
Unable to download SIRI_TEXT_TO_SPEECH namespace
Unable to download SIRI_TEXT_TO_SPEECH namespace.
Unable to find best asset for 
SIRI_TEXT_TO_SPEECH namespace is not downloaded yet. Downloading now.
Unable to download asset: 
OspreyTTSAction: Cannot find synthesizing request
Updating osprey cache
Osprey cache is found, requestId: %llu
Missing voice name or gender for Osprey { id: 
_TtC14SiriTTSService15OspreyTTSAction
ospreyClient
ospreyConfig
streamingStartedDate
Updated osprey cache
OspreyTTSAction: error when updating osprey cache, %s
Osprey streaming network stall { id: 
Osprey streaming timed out { id: 
Encountered Osprey error: %s, { id: %llu }
Simulate network stall is on, ignore audio object
Invalid server audio format
Server voice: %@, resource: %@, buffer size: %f
Default Osprey timeout: 1.0
Osprey config specifies timeout: %f
VoiceSelectionAction cannot find synthesizing request
Cannot find suitable voice for 
Select voice: {%{public}s}, resource: {%{public}s}, request: {client: %{public}s, id: %s}
Ignore neural voice since it's not suitable. Current thermal level: %s, low power mode: %{bool}d, voice: %{public}@, neural platform: %{bool}d, requestId: %llu
Ignore neural voice since internal settings disable device neural TTS. requestId: %llu }
_TtC14SiriTTSService20VoiceSelectionAction
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
VoiceSelectionAction does not support request: 
RequestParsingAction cannot find request
RequestParsingAction found unknown request: 
_TtC14SiriTTSService20RequestParsingAction
com.apple.siri.tts
B24@?0r*8@"<OS_xpc_object>"16
VSAudioPlaybackServiceAVSBARQueue
Can't retrieve session with ID: 
Can't instantiate AVSampleBufferAudioRenderer or AVSampleBufferRenderSynchronizer. Search (AVFCore) and [com.apple.coremedia:] for the underlying error.
VSAudioPlaybackService init latency: %f
#AVSBAR initialized with session ID: %u, reusing previous synchronizer: %{bool}d
#AVSBAR empty audio data: will not enqueue it
Did add to enqueuedMappedAudioInfo: %f sec
Will add to enqueuedMappedAudioInfo: %f sec
#AVSBAR already stopped or waiting for finish: will not enqueue more
Timeout waiting for AVSampleBufferRenderSynchronizer
#AVSBAR Synchronizer is stalled with rate %f at time %f.
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR already stopped or waiting for finish
#AVSBAR waitUntilFinished
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
synchronizer stop rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f. Then renderer will be flushed.
Stopping synchronizer and renderer
synchronizer pause rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f.
Pausing synchronizer
_TtC14SiriTTSService14AVSBARPlayback
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
state
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
_TtCC14SiriTTSService14AVSBARPlaybackP33_4791274A894FA1CB92EFFF8F61E0C16D21AudioMappedInfoAVSBAR
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
mediaserverd reset
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %ld
renderer enqueueSampleBuffer high latency: %f sec
#AVSBAR Enqueuing to %@: %f sec
#AVSBAR Call to provide more audio data during state %s.
Error in creating block buffer for Silence buffer
Error in creating block buffer for Silence buffer, code: %s
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioFormatDescriptionCreate from Silence buffer creation, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer, code: %s
Error in creating block buffer for Sample buffer
Error in creating block buffer for Sample buffer, code: %s
Error in CMAudioFormatDescriptionCreate
Error in CMAudioFormatDescriptionCreate, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in CMAudioSampleBufferCreateWithPacketDescriptions, code: %s
#AVSBAR renderer was flushed
#AVSBAR Synchronizer reached endTime
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
synchronizer play rate high latency: %f sec
#AVSBAR already stopped or paused: will not resume rate
#AVSBAR Dropping %ld enqueued data
_TtC14SiriTTSService7Timeout
timeoutDate
waitCondition
queue
shouldStop
Skip waiting, no active audio playback found.
Unable to stop audio playback.
Unable to wait audio playback finished.
Audio playback finished for request_id: %llu.
AudioPlayback: Cannot find audio data.
AudioPlayback: Cannot find audible request.
Audio playback started for request_id: %llu
_TtC14SiriTTSService19AudioPlaybackAction
buffer
audioPlayback
audibleRequest
Cancelling audio playback
_TtC14SiriTTSService28TTSAssetPreinstalledStrategy
#Local listing voices for types: %{public}s, filter: %{public}s
Searching in preinstalled voice directory: '%s'
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/PreinstallAssets/
Unable to list voice folder
Skip invalid voice folder '%{public}s'
SiriTTSService4
DeviceSynthesisAction: Engine is not set
DeviceSynthesisAction: Request is not set
v16@?0@"NSData"8
v16@?0@"NSString"8
v16@?0@"NSArray"8
_TtC14SiriTTSService21DeviceSynthesisAction
synthesisConfig
DeviceSynthesisAction: low RTF is detected during synthesis.
DeviceSynthesisAction: no audio data is generated.
Neural voice fell back to compact neural synthesis.
Received word timings: %s
Synthesized with prompt: '%s'
Low synthesis RTF detected, will likely results in stuttering. Missing: %f
Unable to get defaults 'com.apple.voiceservices'
subscribedAssets
_TtC14SiriTTSService11Preferences
defaults
Preferences: Unable to find preference suite 
SiriTTSService5
B16@0:8
@16@0:8
downloading
OpusEncoder: Unknown asbd 
OpusEncoder: Opus not supported
OpusEncoder: Unable to create converter, source asbd 
@"AVAudioBuffer"20@?0I8^q12
OpusEncoder: Unable to encode chunk, error: 
_TtC14SiriTTSService11OpusEncoder
fromFormat
toFormat
converter
OpusEncoder: Unable to create input buffer
CacheStorage: Unable to create cache file at path 
Failed reading cache, error: %s
SynthesisCacheFile: invalid file, probably not closed properly, or incompatible.
Cleaned cache storage: %{public}s
Unable to remove cache file at path: %s
Cleaning cache storage: %{public}s
SynthesisCache: incorrect magic version
SynthesisCache: Unable to decode audio
SynthesisCache: Unable to decode timing info
_TtC14SiriTTSService12CacheStorage
Unable to list directory, error: %s
Missing bundle identifier for CacheStorage
Unable to create CacheStorage, error: %s
Unable to get Cache directory
CacheStorage: Path 
 is an existing file!
CFBundleShortVersionString
Failed to delete legacy asset %@: %@
SiriTTSService.TTSAssetLegacyAsset
_TtC14SiriTTSService19TTSAssetLegacyAsset
$__lazy_storage_$_voiceDesc
Swift/NativeDictionary.swift
Duplicate values for key: '
_TtC14SiriTTSService24PreinstalledAudioStorage
_TtC14SiriTTSService19OspreyBuiltInConfig
deviceWaitTime
allowedAppIdentifiers
_TtC14SiriTTSService20OspreyChainedConfigs
configs
_TtC14SiriTTSService25WeakDaemonDelegateWrapper
v24@0:8Q16
_TtC14SiriTTSService16DaemonConnection
connection
weakDelegate
asyncProxy
syncProxy
SiriTTSService.DaemonConnection
init()
Connection interrupted
Connection invalidated
experimentIdentifier
synthesisBeginTime
synthesisEndTime
speechEstimatedOutputBeginTime
serverFirstPacketTime
serverLastPacketTime
audioStartLatency
eagerRequestGapInterval
serverStreamedAudioDuration
isServerTTSRacing
 "audio_duration": 
 "audio_output_route": "
 "audio_queue_latency": 
 "character_count": 
 "error_code": 
 "experiment": "
 "is_speech_request": 
 "is_synthesis_cached": 
 "is_warm_start": 
 "neural_alignment_stall": 
 "neural_audio_click": 
 "neural_fallback": 
 "prompt_count": 
 "real_time_factor": 
 "server_first_packet_latency": 
 "server_last_packet_latency": 
 "source_of_tts": "
 "synthesis_to_speech_time_gap": 
 "tts_synthesis_latency": 
 "tts_total_latency": 
 "voice_resource": "
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
v16@?0@"SiriTTSAudioData"8
customResourceURLs
disableCompactVoice
synthesisProfile
prosodyProperties
", privacySensitive: 
SiriTTSService.SynthesisContext
v16@?0@"SiriTTSInstrumentationMetrics"8
text: "<privacySensitive, length: 
SiriTTSService.SynthesisVoice
SiriTTSService.SynthesisVoiceSubscription
SiriTTSService.SynthesisResource
SiriTTSService.InlineStreamingSignal
DaemonSession %@ sets keepActive: %{bool}d
Init DaemonSession %@
Init DaemonSession %@, with accessory %s
Deinit DaemonSession %@
DaemonSession keepActive must be true before prewarming.
Start #PrewarmRequest, %{public}s
Start #SynthesisRequest %{public}s
TTSRequestReceived
id %llu
Start #SpeechRequest %{public}s
Start #AudioRequest, %{public}@
#CancelRequest, %@
#InlineStreaming signal %@
#InlineStreaming object %@
v12@?0B8
v16@?0f8f12
v24@?0@"NSString"8@"NSError"16
#TextToPhoneme %s
Unable to subscribe voice due to missing bundle identifier
Unable to get bundle identifier for current client
Can't find alive request with timestamp %llu didStartSpeaking.
Request is not audible, but called with didStartSpeaking. %@
Can't find alive request with timestamp %llu didReportInstrument.
Can't find alive request with timestamp %llu didGenerateAudio.
Expecting synthesizing request, but got %@
Can't find alive request with timestamp %llu didGenerateWordTimings.
SiriTTSWordTimingInfo
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@40@0:8d16{_NSRange=QQ}24
startTime
textRange
Td,N,VstartTime
T{_NSRange=QQ},N,VtextRange
SiriTTSInstrumentationMetrics
v16@0:8
utterance
speechBeginTime
speechEndTime
T@"NSString",N,C
T@"SiriTTSSynthesisVoice",N,&,Vvoice
T@"SiriTTSSynthesisResource",N,&,Vresource
TQ,N,VrequestCreatedTime
Td,N,VeagerRequestGapInterval
TQ,N,VsynthesisBeginTime
TQ,N,VsynthesisEndTime
TQ,N,VspeechBeginTime
TQ,N,VspeechEndTime
TQ,N,VspeechEstimatedOutputBeginTime
Td,N,VaudioStartLatency
TQ,N,VserverFirstPacketTime
TQ,N,VserverLastPacketTime
Td,N,VserverStreamedAudioDuration
Td,N,VaudioDuration
TB,N,VisWarmStart
Tq,N,VsourceOfTTS
TB,N,VprivacySensitive
Tq,N,VerrorCode
TB,N,VisServerTTSRacing
Tq,N,VpromptCount
TB,N,VneuralAlignmentStall
TB,N,VneuralAudioClick
TB,N,VneuralFallback
TB,N,VisAudibleRequest
voiceResourceAssetKey
SiriTTSAudibleContext
I16@0:8
v20@0:8I16
@?16@0:8
audioSessionId
immediate
siriRequestId
didStartSpeaking
TI,N,VaudioSessionId
TB,N,Vimmediate
T@"NSUUID",N,C
T@?,N,C
SiriTTSProsodyProperties
f16@0:8
v20@0:8f16
Tf,N,VneuralSentencePitch
Tf,N,VneuralSentencePitchRange
Tf,N,VneuralSentenceDuration
Tf,N,VneuralSentenceEnergy
Tf,N,VneuralSentenceTilt
SiriTTSSynthesisContext
text
contextInfo
rate
pitch
volume
didGenerateAudio
didGenerateWordTimings
whisper
forceOspreyTTS
T@"NSDictionary",N,C
Tf,N,Vrate
Tf,N,Vpitch
Tf,N,Vvolume
T@"NSArray",N,C
Tq,N,VsynthesisProfile
TB,N,VdisableCompactVoice
TB,N,Vwhisper
T@"SiriTTSProsodyProperties",N,&,VprosodyProperties
TB,N,VforceOspreyTTS
SiriTTSBaseRequest
clientBundleId
accessoryId
outputPath
didReportInstrument
T@"NSURL",N,C
SiriTTSAudioRequest
audio
T@"SiriTTSAudioData",N,R,Vaudio
T@"SiriTTSAudibleContext",N,&,VaudibleContext
SiriTTSSynthesisRequest
@32@0:8@16@24
T@"SiriTTSSynthesisContext",N,&,VsynthesisContext
SiriTTSPhonemeRequest
@40@0:8@16@24q32
phonemeSystem
Tq,N,VphonemeSystem
SiriTTSSpeechRequest
SiriTTSSynthesisVoice
language
footprint
type
version
Tq,N,Vfootprint
Tq,N,Vtype
Tq,N,Vgender
Tq,N,Vversion
SiriTTSVoiceSubscription
clientId
SiriTTSSynthesisResource
SiriTTSInlineStreamingSignal
SiriTTSDaemonSession
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
keepActive
v32@0:8Q16@24
SiriTTSService.SpeechRequest
SiriTTSService.PhonemeRequest
SiriTTSService.SynthesisRequest
SiriTTSService.AudioRequest
#Success #AudioRequest id %llu
#Error #AudioRequest id %llu, error: %s
#Success #SpeechRequest id %llu
#Error #SpeechRequest id %llu, error: %s
#Success #SynthesisRequest id %llu
#Error #SynthesisRequest id %llu, error: %s
#Success #PrewarmRequest id %llu
#Error #PrewarmRequest id %llu, error: %s
NSSecureCoding
NSCoding
_TtC14SiriTTSService22OspreyTTSPrewarmAction
Error in Osprey prewarm: %s
_TtC14SiriTTSService20SiriAnalyticsHandler
ttsId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
Ignore Siri logging due to missing Siri request id
Ignore Siri logging due to non Siri client
Ignore Siri logging due to unmatched Siri request id
SiriTTSService6
@20@0:8B16
Found '%{public}s' assets %{public}s
Listing asset types: '%{public}s', filter: '%{public}s'
voice path '%@', resource path '%@'
%d files under voice path:
%d files under resource path:
- %@
Replace: `%@' -> `%@'
Prompt: "%@"
Phonemes: %@
Norm Text: `%@'
Neural Phonemes: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@', request_id '%llu'
Corrupted Osprey response, stream ID: %@, request_id: %llu
Osprey streaming received Begin response with non 200 status: %d, request_id: %llu
Osprey streaming received Begin response %@, request_id: %llu
Osprey streaming received Chunk response with non 200 status: %d, request_id: %llu
Osprey streaming received Chunk response, pkt number: %d, request_id: %llu
Osprey streaming received End response with non 200 status: %d, request_id: %llu
Osprey streaming received End response, total pkt: %d, request_id: %llu
%s, Unknown response from Osprey for streaming TTS, request_id: %llu
Osprey streaming invokes completion with error %@, request_id: %llu
Osprey streaming invokes completion callback, request_id: %llu
softlink:r:path:/System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
ypSg
_pSg
G0R0_
$sSY
So8NSObjectC
$s14SiriTTSService13AudioPlaybackP
So17OS_dispatch_queueC
_pSg
$s14SiriTTSService19AudioPowerProvidingP
$s14SiriTTSService14AudioInterfaceP
_pSgc
So8NSStringC
$ss21_ObjectiveCBridgeableP
yyXlG
So13OS_xpc_object_p
yypG
_yXlt
_yXltG
So8NSObject_p
ySSG
SS_ypt
ySS_yptG
ySsG
SDySSypG
ySDySSypGG
ySiG
SaySiG
ySaySiGG
G0R3_
_A13At
SgXw
SSSg
So20NSNotificationCenterC
SaySo8NSObject_pG
Iegn_
ypSgm
SdIegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
GIegn_
So14NSUserDefaultsCSg
SdSg
SfSg
_pIegn_
SSIegn_
So8NSObjectCSg
So20NSNotificationCenterCSg
_ypt
ySSSaySDySSypGGG
ySSSDySSSaySDySSypGGGG
_ypt
ySSSo8NSObjectCG
ySSSDyS2SGG
yS2SG
ySSypycG
So13OS_xpc_object_pG
ySSySo29SATTSSpeechSynthesisStreamingCcG
ySSypG
So8TTSAssetC
_yptG
3key_yp5valuet
SaySDySSSiGG
ySS_SStG
SDySSSiG
SvSg
$s14SiriTTSService24SynthesisConfigProvidingP
So29SATTSSpeechSynthesisStreamingCytIegnr_
So29SATTSSpeechSynthesisStreamingC
So29SATTSSpeechSynthesisStreamingCIegg_
SaySo29SATTSSpeechSynthesisStreamingCG
SDySSySo29SATTSSpeechSynthesisStreamingCcG
So15NSRecursiveLockC
So34SiriTTSSynthesizingRequestProtocol_
So22SiriTTSSynthesisEngineCSg
SgXw
Ieg_
So6NSLockC
SaySJG
Iegggyc_
GIeggg_
_pSgIegg_
So20SiriTTSOspreyChannelC
SdS2iIeyByyy_
So8TTSAssetCSgIeyBy_
So8TTSAssetCSgIegg_
So20TRINotificationToken_pSg
SaySSG
Sdz_Xx
Siz_Xx
SdS2iIegyyy_
Iegyy_
_pSgIegyg_
3key_yp5valuet
_pmm
_pSg
_pmm
_pSg
So20NSNotificationCenterCm
So20NSNotificationCenterCmm
$s14SiriTTSService16TTSAssetStrategyP
xIegn_
$s14SiriTTSService20NotificationHandlingP
$s14SiriTTSService28OptionalNotificationHandlingP
yySd_S2itcG
yySSSgcG
So13OS_xpc_object_pSg
So21OS_dispatch_semaphoreC
3key_yp5valuetSg
_So13OS_xpc_object_ptG
SaySo8TTSAssetCG
SiSo13OS_xpc_object_pSbIgygd_
SaySo13TTSStringEnumCG
SaySbG
SaySDySSypGG
SS3key_yp5valuet
So12TTSAssetTypeC
ySi_
ySSG
SaySo15TTSAssetQualityCG
SaySo18TTSAssetTechnologyCG
$ss12CaseIterableP
_pSg
$s14SiriTTSService20WorkflowErrorHandlerP
ySbG
So11NSConditionC
$s14SiriTTSService10ActionableP
$s14SiriTTSService11ConditionalP
$s14SiriTTSService12AsynchronousP
_pSg
_pSg
SgXw
$s14SiriTTSService14DaemonProtocolP
$s14SiriTTSService22DaemonDelegateProtocolP
yXlXp
So8NSStringCm
So12NSDictionaryCm
So6NSUUIDCm
So5NSURLCm
So15TTSAssetQualityC
So8NSBundleCSg
SDyS2SG
xIegr_
$s14SiriTTSService20DependencyInjectableP
SDySSypycG
ypSg_AAt
So7MAAssetC
3key_yp5valuet
SS3key_yp5valuetSg
ySS_
ySS_
ySbG
ySSSgG
ySJG
SDySSSDySSSaySDySSSdGGGG
SgXw
y_SbG
y_SfSgG
y_SdSgG
y_SSSgG
xypcSg
SgXw
_pSgSbt
SayxG
SaySaySiGG
SnySiG
So8NSBundleC
SgXw
Sbz_Xx
SgXwz_Xx
14SiriTTSService22DaemonDelegateProtocol_pSgXw
SaySDyS2SGG
SDySSSaySDySSypGGG
SDySSSay
SDySSSDyS2SGG
yXlG
ySS_SDyS2SGtG
ySSSay
ySSSiG
ySSSgcG
ySd_S2itcG
ySo12TTSAssetTypeCSay
_pGG
ySSSaySo8TTSAssetCGG
_pSg
SgXw
ySS_So8NSObjectCtG
$s14SiriTTSService22CoreAnalyticsInterfaceP
SfIegy_Sg
XDXMT
_yptG
SaySo14TTSAssetSourceCG
SgXw
Sgz_Xx
XDXMT
Gz_Xx
_pSg
GSo13OS_xpc_object_pSbIgygd_
SayypG
So29AVQueuedSampleBufferRendering_p
So7NSErrorCSg
So27AVSampleBufferAudioRendererC
So32AVSampleBufferRenderSynchronizerC
So21OS_dispatch_semaphoreCSg
_pSgcSg
SgXw
SbIegy_
SgXw
_pSg
So29SiriTTSAudibleRequestProtocol_
So29SiriTTSAudibleRequestProtocol_
XcSg
So22SiriTTSSynthesisEngineC
Gz_Xx
z_Xx
XDXMT
So29SiriTTSSynthesisEngineRequestC
So14NSUserDefaultsC
ySSSgc
ySd_S2itc
ySo29SATTSSpeechSynthesisStreamingCc
So13AVAudioFormatC
So16AVAudioConverterC
So23AVAudioCompressedBufferC
$sSt
$sST
So12NSFileHandleC
ySnySiGG
ypGSg
3key_yp5valuetSg
SaySsG
_A63At
_A255At
_A3At
$s14SiriTTSService21OspreyConfigProvidingP
SaySSGSg
So15NSXPCConnectionC
14SiriTTSService14DaemonProtocol_p
IeyB_
_pIegg_
IeyBy_
So7NSArrayCIeyBy_
SDyS2SGSg
IeyBy_
So7NSErrorCSgIeyBy_
IeyBy_
S2fIegyy_
S2fIeyByy_
SSSg
_pSgIeggg_
So8NSStringCSgSo7NSErrorCSgIeyByy_
GIegg_
GIegg_
yycSg
$s14SiriTTSService22AudibleRequestProtocolP
ySay
GcSg
$s14SiriTTSService27SynthesizingRequestProtocolP
ytIegnr_
Iegg_
GytIegnr_
GIegg_
ytIegnr_
Iegg_
ytIegr_
yyXlXpG
So7NSArrayCm
SDySo8NSStringCABG
SgXw
So26SiriAnalyticsMessageStream_p
So14SPIPowerLoggerCSg
SgXw
_SStG
SDySSSaySo8TTSAssetCGG
SaySo12TTSAssetTypeCG
RawValue
audioSessionNotFound
avsbarNotInstantiated
playbackStalled
audioRouteName
isBluetoothRoute
isAppleProduct
vendorID
productID
asbd
audioData
packetCount
packetDescriptions
audioInterface
audioOperationQueue
playbackError
audioSequence
averagePower
peakPower
discontinuedDuringPlayback
outputRouteInfo
audioQueue
startTime
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
expectedPlaySampleTime
callback
mStartOffset
mVariableFramesInPacket
mDataByteSize
mAveragePower
mPeakPower
_rawValue
mSampleTime
mHostTime
mRateScalar
mWordClockTime
mSMPTETime
mFlags
mReserved
value
timescale
flags
epoch
location
length
mSampleRate
mFormatID
mFormatFlags
mBytesPerPacket
mFramesPerPacket
mBytesPerFrame
mChannelsPerFrame
mBitsPerChannel
_ObjectiveCType
mSubframes
mSubframeDivisor
mCounter
mType
mHours
mMinutes
mSeconds
mFrames
rawValue
notificationCenter
observers
requestId
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
utterance
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
RawValue
cacheStorage
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
synthesizerID
voiceID
name
localizedNames
nameRoot
identifier
gender
demo
language
locale
version
scriptCode
voiceGroup
voiceType
desirability
supportedCharacters
individuallySpokenCharacters
diskSize
description
RawValue
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
storage
streamingHandlers
signals
lock
queue
_activeSessionCount
_cachedEngine
notificationCenter
observers
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
lock
value
lowInactiveMemory
grpcChannel
speechId
factorName
assetAttr
path
isDownloading
downloadToken
notification
engineCachingService
use_trial
enable_adhoc_voice
sirix
audioPlaybackStarted
synthesisStarted
synthesisEnded
requestReceived
audioGenerated
wordTimingGenerated
phonemesGenerated
voiceSelected
engineSelectEnd
voiceResourceSelected
encounteredError
encounteredIssue
audioPowerProviderAvailable
instrumentationMetricsAvailable
cancellationRequested
eagerRequestDetected
audioPlaybackStarting
audioPlaybackEnded
voiceSelectStart
engineSelectStart
receivedServerFirstPacket
receivedServerLastPacket
synthesisEngineChanged
synthesisUsedPrompt
neuralAlignmentStall
neuralAudioClick
neuralFallback
taskCompletion
registry
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
message
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
attributes
cookie
bundle
authTokens
quality
downloading
RawValue
stagingURL
inKey
wantValue
text
source
name
firstMinor
voice
resource
AllCases
RawValue
graph
errorHandlers
_isCancelled
cancellationLock
notification
idContainer
buffer
bufferCondition
isProcessing
asyncError
waitTimeout
isProcessingCondition
action
conditional
asyncContext
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
internalSettings
notificationCenter
observers
canDumpAudio
cookie
assetQuality
bundlePath
authorizedBundle
proxy_attr
engineCachingService
notification
constructorRegistry
objectPool
asset
name
gender
quality
storageURL
notificationCenter
observers
audioPowerProvider
encoder
_enableDiagnostic
_logSensitiveText
_disableCache
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
defaults
stringKey
defaultValue
transform
asyncContext
streamingStorage
notificationCenter
observers
internalSettings
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
RawValue
code
description
success
unknown
crash
cancelled
noVoice
invalidVoice
lowSynthesisRTF
compactNeural
audioUnknownError
audioDiscontinuity
ospreyUnknownError
ospreyNetworkTimeout
ospreyNetworkStall
ospreyInvalidAudioFormat
inlineStreamUnknownError
inlineStreamNetworkStall
inlineStreamTimeout
nodes
edges
settings
asset
attr
assetAttr
RawValue
networkStall1
networkStall2
networkStall3
notificationCenter
observers
delegate
request
audioFile
packetOffset
asyncContext
queue
settings
entitlements
diagnosticAudioFile
synthesizedAudioFile
supportedLanguages
name
identifier
assistantGender
assistantOrder
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
notificationCenter
observers
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
voice
path
resource
downloadQueue
notificationCenter
observers
asyncContext
internalSettings
ospreyClient
ospreyConfig
timeout
cacheStorage
streamingStartedDate
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
notification
internalSettings
buffer
notificationCenter
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
state
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
asbd
discontinuedDuringPlayback
audioPowerProvider
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
paused
started
waitForFinish
stopped
RawValue
timeoutDate
waitCondition
queue
shouldStop
asyncContext
buffer
audioPlayback
audibleRequest
notificationCenter
observers
asyncContext
queue
notificationCenter
observers
internalSettings
synthesisConfig
_isCancelled
defaults
fromFormat
toFormat
converter
buffer
Element
Iterator
storageURL
fileURL
handle
voice
resource
audio
timingInfos
magicVersion
RawValue
asset
$__lazy_storage_$_voiceDesc
length
voice
version
name
comment
gender
script
language
region
reserved
creator
storageURL
timeout
deviceWaitTime
allowedAppIdentifiers
configs
delegate
connection
weakDelegate
asyncProxy
syncProxy
RawValue
startTime
textRange
utterance
voice
resource
audioOutputRoute
clientBundleIdentifier
experimentIdentifier
requestCreatedTime
eagerRequestGapInterval
synthesisBeginTime
synthesisEndTime
speechBeginTime
speechEndTime
speechEstimatedOutputBeginTime
audioStartLatency
serverFirstPacketTime
serverLastPacketTime
serverStreamedAudioDuration
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
isServerTTSRacing
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
audioSessionId
immediate
siriRequestId
didStartSpeaking
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
text
contextInfo
rate
pitch
volume
customResourceURLs
synthesisProfile
disableCompactVoice
didGenerateAudio
didGenerateWordTimings
whisper
prosodyProperties
forceOspreyTTS
clientBundleId
accessoryId
outputPath
didReportInstrument
audio
audibleContext
synthesisContext
phonemeSystem
language
name
footprint
type
gender
version
clientId
identifier
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
asyncContext
notificationCenter
observers
ospreyClient
notificationCenter
observers
ttsId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
sources
assetTypes
SiriTTSPhonemeTool
SiriTTSSynthesisEngineResource
SiriTTSSynthesisEngineWordTimings
SiriTTSSynthesisEngineRequest
SiriTTSSynthesisEngine
SiriTTSNeuralUtils
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequestProsodyControlConfig
OPTTSMutableTTSWordPhonemes
OPTTSMutableTTSPhonemeSequence
OPTTSMutableTTSNeuralPhonemeSequence
OPTTSMutableTTSPrompts
OPTTSMutableTTSReplacement
OPTTSMutableTTSNormalizedText
OPTTSMutableTextToSpeechFeature
OPTTSMutableTextToSpeechRequestDebug
OPTTSMutableTextToSpeechVoiceResource
OPTTSMutableTextToSpeechUserProfile
OPTTSMutableTextToSpeechRequestDevConfig
OPTTSMutableTextToSpeechSpeechFeatureInputWave
OPTTSMutableTextToSpeechUserVoiceProfile
OPTTSMutableTextToSpeechRequestProsodyTransferConfig
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequestProsodyControlConfig
OPTTSTTSWordPhonemes
OPTTSTTSPhonemeSequence
OPTTSTTSNeuralPhonemeSequence
OPTTSTTSPrompts
OPTTSTTSReplacement
OPTTSTTSNormalizedText
OPTTSTextToSpeechFeature
OPTTSTextToSpeechRequestDebug
OPTTSTextToSpeechVoiceResource
OPTTSTextToSpeechUserProfile
OPTTSTextToSpeechRequestDevConfig
OPTTSTextToSpeechSpeechFeatureInputWave
OPTTSTextToSpeechUserVoiceProfile
OPTTSTextToSpeechRequestProsodyTransferConfig
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
SiriTTSService_Bridge
SiriTTSOspreyRequest
OspreyBridge
SiriTTSOspreyStreamingBeginResponse
SiriTTSOspreyWordTimingInfo
SiriTTSOspreyStreamingPartialResponse
SiriTTSOspreyChannel
SiriTTSService_TTSAXResource
SiriTTSService_TTSAXResourceManager
SiriTTSAudioHardware
TTSAsset
TTSStringEnum
TTSAssetQuality
TTSAssetServer
TTSAssetSource
TTSAssetTechnology
TTSAssetType
SwiftProxy
stringWithUTF8String:
setClientTraceIdentifier:
initWithBytes:length:encoding:
enumerateObjectsUsingBlock:
addObject:
initWithUnsignedInteger:
initWithBytesNoCopy:length:deallocator:
objectAtIndexedSubscript:
errorWithDomain:code:userInfo:
dataWithBytes:length:
objectForKeyedSubscript:
initWithCurrentProcess
dataWithBytesNoCopy:length:freeWhenDone:
setObject:forKeyedSubscript:
floatValue
intValue
componentsJoinedByString:
integerValue
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
UTF8String
isInstalled
initWithFloat:
copy
count
initWithInt:
UUID
unsignedIntegerValue
allocWithZone:
countByEnumeratingWithState:objects:count:
stringByReplacingOccurrencesOfString:withString:
resourcesWithType:subType:
UUIDString
stringWithFormat:
setUseCompression:
contentPath
dictionary
bytes
array
dictionaryWithObjects:forKeys:count:
generateTTSPhonemes:voicePath:phonemeSystem:error:
path
setPath:
mimeType
setMimeType:
handle
setHandle:
.cxx_destruct
.cxx_construct
_path
_mimeType
_handle
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_handle
T@"NSString",&,N,V_path
T@"NSString",&,N,V_mimeType
startTime
setStartTime:
textRange
setTextRange:
_startTime
_textRange
Td,N,V_startTime
T{_NSRange=QQ},N,V_textRange
text
setText:
privacySensitive
setPrivacySensitive:
rate
setRate:
pitch
setPitch:
volume
setVolume:
profile
setProfile:
neuralSentencePitch
setNeuralSentencePitch:
neuralSentencePitchRange
setNeuralSentencePitchRange:
neuralSentenceDuration
setNeuralSentenceDuration:
neuralSentenceEnergy
setNeuralSentenceEnergy:
neuralSentenceTilt
setNeuralSentenceTilt:
audioHandler
setAudioHandler:
promptHandler
setPromptHandler:
wordTimingsHandler
setWordTimingsHandler:
neuralFallbackHandler
setNeuralFallbackHandler:
_privacySensitive
_rate
_pitch
_volume
_neuralSentencePitch
_neuralSentencePitchRange
_neuralSentenceDuration
_neuralSentenceEnergy
_neuralSentenceTilt
_text
_profile
_audioHandler
_promptHandler
_wordTimingsHandler
_neuralFallbackHandler
T@"NSString",&,N,V_text
TB,N,V_privacySensitive
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
TQ,N,V_profile
Tf,N,V_neuralSentencePitch
Tf,N,V_neuralSentencePitchRange
Tf,N,V_neuralSentenceDuration
Tf,N,V_neuralSentenceEnergy
Tf,N,V_neuralSentenceTilt
T@?,C,N,V_audioHandler
T@?,C,N,V_promptHandler
T@?,C,N,V_wordTimingsHandler
T@?,C,N,V_neuralFallbackHandler
init
dealloc
hasPhaticResponsesWithVoicePath:
initWithVoicePath:resourcePath:error:
loadResourceWithPath:error:
unloadResource:
synthesize:error:
stopSynthesis
preheatWithError:
asbd
setAsbd:
voicePath
resourcePath
setTag:
synthesizer
setSynthesizer:
_voicePath
_resourcePath
_tag
_synthesizer
_asbd
T^v,N,V_synthesizer
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T@"NSString",R,N,V_voicePath
T@"NSString",R,N,V_resourcePath
T@"NSString",&,N,V_tag
hasAMX
hasANE
isANEOnly
isNeuralPlatform
isH12Platform
shouldUseNeuralVoice:
isANEModelCompiled:
compileANEModel:error:
copyWithZone:
fe_feature
setFe_feature:
fe_feature_only
setFe_feature_only:
TB,N
language
setLanguage:
gender
setGender:
name
setName:
version
setVersion:
quality
setQuality:
type
setType:
T@"NSString",C,N
voice
setVoice:
resource
setResource:
T@"OPTTSTextToSpeechVoice",C,N
T@"OPTTSTextToSpeechResource",C,N
channel_type
setChannel_type:
app_id
setApp_id:
Tq,N
context_info
setContext_info:
dialog_identifier
setDialog_identifier:
T@"NSArray",C,N
experiment_identifier
setExperiment_identifier:
global_rate
setGlobal_rate:
global_pitch
setGlobal_pitch:
global_energy
setGlobal_energy:
global_sent_pitch
setGlobal_sent_pitch:
global_sent_pitchrange
setGlobal_sent_pitchrange:
global_sent_duration
setGlobal_sent_duration:
global_sent_energy
setGlobal_sent_energy:
global_sent_tilt
setGlobal_sent_tilt:
Tf,N
phonemes
setPhonemes:
word_phonemes
setWord_phonemes:
prompts
setPrompts:
prompts_v2
setPrompts_v2:
prompts_v2:
T@"NSData",C,N
original
setOriginal:
replacement
setReplacement:
normalized_text
setNormalized_text:
phoneme_sequence
setPhoneme_sequence:
neural_phoneme_sequence
setNeural_phoneme_sequence:
force_use_tts_service
setForce_use_tts_service:
disable_cache
setDisable_cache:
data
setData:
data:
resources
setResources:
return_log
setReturn_log:
voice_asset_path
setVoice_asset_path:
resource_asset_path
setResource_asset_path:
return_server_info
setReturn_server_info:
sample_rate
setSample_rate:
pcm_data
setPcm_data:
pcm_data:
Ti,N
pitch_mean
setPitch_mean:
pitch_std
setPitch_std:
energy_mean
setEnergy_mean:
energy_std
setEnergy_std:
duration_mean
setDuration_mean:
duration_std
setDuration_std:
wave_data
setWave_data:
user_voice_profile
setUser_voice_profile:
user_voice_profile_url
setUser_voice_profile_url:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",C,N
T@"OPTTSTextToSpeechUserVoiceProfile",C,N
speech_id
setSpeech_id:
session_id
setSession_id:
audio_type
setAudio_type:
enable_word_timing_info
setEnable_word_timing_info:
voice_name
setVoice_name:
preferred_voice_type
setPreferred_voice_type:
meta_info
setMeta_info:
context
setContext:
experiment
setExperiment:
feature_flags
setFeature_flags:
debug
setDebug:
dev_config
setDev_config:
prosody_config
setProsody_config:
prosody_control_config
setProsody_control_config:
T@"OPTTSTextToSpeechRequestMeta",C,N
T@"OPTTSTextToSpeechRequestContext",C,N
T@"OPTTSTextToSpeechRequestExperiment",C,N
T@"OPTTSTTSRequestFeatureFlags",C,N
T@"OPTTSTextToSpeechRequestDebug",C,N
T@"OPTTSTextToSpeechUserProfile",C,N
T@"OPTTSTextToSpeechRequestDevConfig",C,N
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",C,N
T@"OPTTSTextToSpeechRequestProsodyControlConfig",C,N
setKey:
value
setValue:
format_id
setFormat_id:
format_flags
setFormat_flags:
bytes_per_packet
setBytes_per_packet:
frames_per_packet
setFrames_per_packet:
bytes_per_frame
setBytes_per_frame:
channels_per_frame
setChannels_per_frame:
bits_per_channel
setBits_per_channel:
reserved
setReserved:
Td,N
TI,N
word
setWord:
sample_idx
setSample_idx:
offset
setOffset:
length
setLength:
timestamp
setTimestamp:
stream_id
setStream_id:
error_code
setError_code:
error_str
setError_str:
decoder_description
setDecoder_description:
playback_description
setPlayback_description:
streaming_playback_buffer_size_in_seconds
setStreaming_playback_buffer_size_in_seconds:
T@"OPTTSAudioDescription",C,N
T@"OPTTSTextToSpeechMeta",C,N
current_pkt_number
setCurrent_pkt_number:
audio
setAudio:
audio:
word_timing_info
setWord_timing_info:
feature
setFeature:
T@"OPTTSTextToSpeechFeature",C,N
total_pkt_number
setTotal_pkt_number:
content_mutableClassForType:
content_typeForMutableObject:
content_typeForObject:
content_type
setContent_type:
contentAsOPTTSStartTextToSpeechStreamingRequest
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContent:
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
content
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
contentAsOPTTSBeginTextToSpeechStreamingResponse
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
contentAsOPTTSPartialTextToSpeechStreamingResponse
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
contentAsOPTTSFinalTextToSpeechStreamingResponse
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
addObjectToBuffer:
_storage
_data
_root
TB,R,N
T@"NSString",R,N
T@"OPTTSTextToSpeechVoice",R,N
T@"OPTTSTextToSpeechResource",R,N
Tq,R,N
context_info_objectAtIndex:
context_info_count
context_info_enumerateObjectsUsingBlock:
T@"NSArray",R,N
Tf,R,N
phonemes_objectAtIndex:
phonemes_count
phonemes_enumerateObjectsUsingBlock:
word_phonemes_objectAtIndex:
word_phonemes_count
word_phonemes_enumerateObjectsUsingBlock:
prompts_objectAtIndex:
prompts_count
prompts_enumerateObjectsUsingBlock:
T@"NSData",R,N
normalized_text_objectAtIndex:
normalized_text_count
normalized_text_enumerateObjectsUsingBlock:
phoneme_sequence_objectAtIndex:
phoneme_sequence_count
phoneme_sequence_enumerateObjectsUsingBlock:
replacement_objectAtIndex:
replacement_count
replacement_enumerateObjectsUsingBlock:
neural_phoneme_sequence_objectAtIndex:
neural_phoneme_sequence_count
neural_phoneme_sequence_enumerateObjectsUsingBlock:
resources_objectAtIndex:
resources_count
resources_enumerateObjectsUsingBlock:
Ti,R,N
T@"OPTTSTextToSpeechSpeechFeatureInputWave",R,N
T@"OPTTSTextToSpeechUserVoiceProfile",R,N
T@"OPTTSTextToSpeechRequestMeta",R,N
T@"OPTTSTextToSpeechRequestContext",R,N
T@"OPTTSTextToSpeechRequestExperiment",R,N
T@"OPTTSTTSRequestFeatureFlags",R,N
T@"OPTTSTextToSpeechRequestDebug",R,N
T@"OPTTSTextToSpeechUserProfile",R,N
T@"OPTTSTextToSpeechRequestDevConfig",R,N
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",R,N
T@"OPTTSTextToSpeechRequestProsodyControlConfig",R,N
Td,R,N
TI,R,N
T@"OPTTSAudioDescription",R,N
T@"OPTTSTextToSpeechMeta",R,N
word_timing_info_objectAtIndex:
word_timing_info_count
word_timing_info_enumerateObjectsUsingBlock:
T@"OPTTSTextToSpeechFeature",R,N
content_immutableClassForType:
content_typeForImmutableObject:
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
loggerForCurrentProcess
underlyingRequest
voiceName
setVoiceName:
speechId
setSpeechId:
appId
setAppId:
experimentId
setExperimentId:
requestCreatedTime
setRequestCreatedTime:
serverLogs
setServerLogs:
_serverLogs
_language
_voiceName
_speechId
_appId
_experimentId
_requestCreatedTime
T@"NSString",C,N,V_language
T@"NSString",C,N,V_text
T@"NSString",C,N,V_voiceName
T@"NSString",C,N,V_speechId
T@"NSString",C,N,V_appId
T@"NSString",C,N,V_experimentId
TQ,N,V_requestCreatedTime
TB,N,V_serverLogs
audioStreamBasicDescription
initWithOspreyBeginResponse:
voiceLanguage
voiceFootprint
voiceType
voiceGender
voiceVersion
resourceLanguage
resourceVersion
bufferDuration
_voiceLanguage
_voiceFootprint
_voiceType
_voiceGender
_voiceVersion
_resourceLanguage
_resourceVersion
_bufferDuration
T@"NSString",R,N,V_voiceLanguage
T@"NSString",R,N,V_voiceName
T@"NSString",R,N,V_voiceFootprint
T@"NSString",R,N,V_voiceType
T@"NSString",R,N,V_voiceGender
Tq,R,N,V_voiceVersion
T@"NSString",R,N,V_resourceLanguage
Tq,R,N,V_resourceVersion
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
Td,R,N,V_bufferDuration
_timestamp
Td,N,V_timestamp
processServerLogs:
initWithOspreyPartialResponse:
audioData
timingInfos
_audioData
_timingInfos
T@"NSData",R,N,V_audioData
T@"NSArray",R,N,V_timingInfos
initWithURL:configuration:
streamTTS:beginHandler:chunkHandler:completion:
initializeDeviceAuthenticationSessionWithCompletion:
preconnect
grpcChannel
setGrpcChannel:
_grpcChannel
T@"OspreyChannel",&,N,V_grpcChannel
_name
T@"NSString",&,N,V_language
T@"NSString",&,N,V_name
sharedInstance
T@"SiriTTSService_TTSAXResourceManager",R,N
allCompactResources
setAllCompactResources:
axManager
setAxManager:
_allCompactResources
_axManager
T@"NSArray",&,N,V_allCompactResources
T@"TTSAXResourceManager",&,N,V_axManager
defaultOutput
fetchHardwareInfo
routeType
isBluetooth
isAppleProduct
vendorId
productId
_isBluetooth
_isAppleProduct
_routeType
_vendorId
_productId
T@"NSString",R,V_routeType
TB,R,V_isBluetooth
TB,R,V_isAppleProduct
Tq,R,V_vendorId
Tq,R,V_productId
NewAssetNotification
_postNewAssetNotification
_hasTrialEntitlements
_gryphonVoiceCompatibility
assetType
assetSource
technology
identifier
versionNumber
versionDescription
supportedLanguages
primaryLanguage
diskSize
attributes
bundle
_assetType
_assetSource
_technology
_quality
_identifier
_versionNumber
_versionDescription
_supportedLanguages
_primaryLanguage
_gender
_age
_diskSize
_attributes
_bundle
T@"TTSAssetType",R,N,V_assetType
T@"TTSAssetSource",R,N,V_assetSource
T@"TTSAssetTechnology",R,N,V_technology
T@"TTSAssetQuality",R,N,V_quality
T@"NSString",R,N,V_name
T@"NSString",R,N,V_identifier
Tq,R,N,V_versionNumber
T@"NSString",R,N,V_versionDescription
T@"NSArray",R,N,V_supportedLanguages
T@"NSString",R,N,V_primaryLanguage
Tq,R,N,V_gender
T@"NSNumber",R,N,V_age
T@"NSNumber",R,N,V_diskSize
T@"NSDictionary",R,N,V_attributes
T@"NSBundle",R,N,V_bundle
initWithString:
description
string
_string
T@"NSString",R,N,V_string
audioSessionId
setAudioSessionId:
immediate
setImmediate:
siriRequestId
setSiriRequestId:
didStartSpeaking
setDidStartSpeaking:
audibleContext
T@"SiriTTSAudibleContext",&,D,N
contextInfo
setContextInfo:
customResourceURLs
setCustomResourceURLs:
disableCompactVoice
setDisableCompactVoice:
synthesisProfile
setSynthesisProfile:
prosodyProperties
setProsodyProperties:
didGenerateAudio
setDidGenerateAudio:
didGenerateWordTimings
setDidGenerateWordTimings:
whisper
setWhisper:
synthesisContext
T@"SiriTTSSynthesisContext",&,D,N
encodeObject:forKey:
encodeInteger:forKey:
lock
unlock
sleepForTimeInterval:
supportsSecureCoding
setSupportsSecureCoding:
setAudioData:
packetCount
setPacketCount:
packetDescriptions
setPacketDescriptions:
encodeWithCoder:
initWithCoder:
isEqual:
initWithDomain:code:userInfo:
getBytes:length:
decodeIntegerForKey:
setSynthesisContext:
timebase
enqueueSampleBuffer:
flush
isReadyForMoreMediaData
requestMediaDataWhenReadyOnQueue:usingBlock:
stopRequestingMediaData
hasSufficientMediaDataForReliablePlaybackStart
hash
superclass
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
debugDescription
setAudibleContext:
didStartSpeakingWithRequestId:
didReportInstrumentWithRequestId:instrumentationMetrics:
didGenerateAudioWithRequestId:audio:
didGenerateWordTimingsWithRequestId:wordTimingInfo:
pingWithReply:
keepActive:reply:
prewarmWithRequest:reply:
speakWithAudioRequest:reply:
speakWithSpeechRequest:reply:
cancelWithRequest:
synthesizeWithRequest:reply:
textToPhonemeWithRequest:reply:
signalWithInlineStreaming:
forwardWithStreamObject:
subscribeWithVoices:
subscribedVoicesWithClientId:reply:
downloadedVoicesMatching:reply:
queryPhaticCapabilityWithVoice:reply:
isSpeakingWithAccessoryId:reply:
getAudioPowerWithAccessoryId:reply:
killDaemon
emitMessage:
emitMessage:timestamp:
resolvePartialMessage:
resolvePartialMessage:timestamp:
enqueueLargeMessageObjectFromPath:assetIdentifier:messageMetadata:completion:
barrierWithCompletion:
removeItemAtURL:error:
voiceAssetKey
voiceResourceAssetKey
removeObserver:
addObserverForName:object:queue:usingBlock:
objectForKey:
stringForKey:
floatForKey:
boolForKey:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
postNotificationName:object:
infoDictionary
URLForResource:withExtension:subdirectory:
initWithContentsOfURL:
bundleWithIdentifier:
fileHandleForUpdatingAtPath:
fileDescriptor
defaultManager
removeItemAtPath:error:
temporaryDirectory
URLForDirectory:inDomain:appropriateForURL:create:error:
processInfo
globallyUniqueString
fileExistsAtPath:
createFileAtPath:contents:attributes:
closeFile
purge
downloadWithReservation:useBattery:progress:then:
cancelDownloadingThen:
purgeImmediately:
legacyAssetWithBundle:
streamId
defaultSessionConfiguration
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
initWithInteger:
initWithPath:
locallyAvailable
isDeletableFileAtPath:
downloading
removeLevelsForFactors:withNamespace:queue:completion:
removeLevelsForFactorsImmediately:withNamespace:queue:completion:
purgeable
factor
level
directoryValue
hasAsset
metadata
hasPath
levelForFactor:withNamespaceName:
setAllowsCellularAccess:
setDiscretionaryBehavior:
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
removeDownloadStatusHandlersWithToken:
initWithURL:
handleProxyEvent:reply:connection:
bundlePath
boolValue
pathComponent
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
compact
premium
premiumhigh
beta
production
livability
staging
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didEndElement:namespaceURI:qualifiedName:
parser:foundCharacters:
initWithType:
returnTypes:
setDoNotBlockBeforeFirstUnlock:
setDoNotBlockOnNetworkStatus:
queryMetaDataSync
isCatalogFetchedWithinThePastFewDays:
results
setDiscretionary:
setAllowsExpensiveAccess:
startCatalogDownload:options:then:
waitUntilDate:
broadcast
addKeyValueArray:with:
setDelegate:
parse
operatingSystemVersion
waitForCatalogUpdates
parserDidStartDocument:
parserDidEndDocument:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundElementDeclarationWithName:model:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:didStartMappingPrefix:toURI:
parser:didEndMappingPrefix:
parser:foundIgnorableWhitespace:
parser:foundProcessingInstructionWithTarget:data:
parser:foundComment:
parser:foundCDATA:
parser:resolveExternalEntityName:systemID:
parser:parseErrorOccurred:
parser:validationErrorOccurred:
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
refresh
factorLevelsWithNamespaceName:
numberOfMatchesInString:options:range:
clientWithIdentifier:
addUpdateHandlerForNamespaceName:queue:usingBlock:
wait
setServer:forType:
setServer:forType:source:
getServerForType:
getServerForType:source:
describeServer:forType:
describeServer:source:
initWithArray:
valueForEntitlement:
__swift_objectForKeyedSubscript:
getLocalFileUrl
state
wasLocal
cancelDownload:
purgeSync
refreshState
setRequiresPowerPluggedIn:
attachProgressCallBack:
startDownload:then:
expectedTimeRemaining
totalWritten
totalExpected
bundleForClass:
bundleURL
initWithContentsOfFile:
setObject:forKey:
integerForKey:
initWithSuiteName:
removeObjectForKey:
errorCode
errorMessage
signal
streamingPlaybackBufferSize
decoderStreamDescription
sampleRate
doubleValue
formatID
unsignedIntValue
formatFlags
bytesPerPacket
framesPerPacket
bytesPerFrame
channelsPerFrame
bitsPerChannel
speechSynthesisResource
languageCode
speechSynthesisVoice
contentVersion
audioInfo
wordTimingInfoList
URLForResource:withExtension:
propertyListWithData:options:format:error:
bundleIdentifier
predefinedStringOf:language:table:
pathForResource:ofType:inDirectory:
URLsForDirectory:inDomains:
fileExistsAtPath:isDirectory:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
pathForResource:ofType:
assistantGender
assistantOrder
isCustom
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
assistantVoiceMaps
initWithBool:
initWithDouble:
rolloutIdWithNamespaceName:
thermalState
isLowPowerModeEnabled
initWithUUIDBytes:
retrieveSessionWithID:
setAudioSession:
setDelaysRateChangeUntilHasSufficientMediaData:
addRenderer:
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
renderers
audioSession
opaqueSessionID
currentTime
valueWithCMTime:
addBoundaryTimeObserverForTimes:queue:usingBlock:
removeTimeObserver:
setRate:time:
isOlder:
isNewer:
dictionaryForKey:
initWithStreamDescription:
initFromFormat:toFormat:
maximumOutputPacketSize
initWithFormat:packetCapacity:maximumPacketSize:
reset
streamDescription
convertToBuffer:error:withInputFromBlock:
localizedDescription
audioBufferList
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
seekToOffset:error:
closeAndReturnError:
writeData:
archivedDataWithRootObject:requiringSecureCoding:error:
readDataOfLength:
contentsOfDirectoryAtPath:error:
fileHandleForUpdatingURL:error:
mainBundle
objectForInfoDictionaryKey:
initWithContentsOfURL:options:error:
currentDirectoryPath
invalidate
remoteObjectProxyWithErrorHandler:
encodeDouble:forKey:
valueWithRange:
encodeInt64:forKey:
encodeBool:forKey:
encodeInt32:forKey:
encodeFloat:forKey:
initWithStartTiming:textRange:
utterance
setUtterance:
audioOutputRoute
setAudioOutputRoute:
clientBundleIdentifier
setClientBundleIdentifier:
experimentIdentifier
setExperimentIdentifier:
eagerRequestGapInterval
setEagerRequestGapInterval:
synthesisBeginTime
setSynthesisBeginTime:
synthesisEndTime
setSynthesisEndTime:
speechBeginTime
setSpeechBeginTime:
speechEndTime
setSpeechEndTime:
speechEstimatedOutputBeginTime
setSpeechEstimatedOutputBeginTime:
audioStartLatency
setAudioStartLatency:
serverFirstPacketTime
setServerFirstPacketTime:
serverLastPacketTime
setServerLastPacketTime:
serverStreamedAudioDuration
setServerStreamedAudioDuration:
audioDuration
setAudioDuration:
isWarmStart
setIsWarmStart:
sourceOfTTS
setSourceOfTTS:
setErrorCode:
isServerTTSRacing
setIsServerTTSRacing:
promptCount
setPromptCount:
neuralAlignmentStall
setNeuralAlignmentStall:
neuralAudioClick
setNeuralAudioClick:
neuralFallback
setNeuralFallback:
isAudibleRequest
setIsAudibleRequest:
forceOspreyTTS
setForceOspreyTTS:
outputPath
setOutputPath:
didReportInstrument
setDidReportInstrument:
initWithAudio:
initWithText:voice:
phonemeSystem
setPhonemeSystem:
initWithText:voice:phonemeSystem:
footprint
setFootprint:
initWithLanguage:name:
clientId
setClientId:
accessoryId
setAccessoryId:
initWithLanguage:
initWithText:identifier:
keepActive
setKeepActive:
initWithAccessoryId:
prewarmWithRequest:didFinish:
synthesizeWithRequest:didFinish:
speakWithSpeechRequest:didFinish:
speakWithAudioRequest:didFinish:
isSpeaking:
getAudioPower:
estimateDurationWithSynthesisRequest:didFinish:
textToPhonemeWithRequest:didFinish:
sharedStream
derivedIdentifierForComponentName:fromSourceIdentifier:
initWithMachServiceName:options:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
setRemoteObjectInterface:
setInvalidationHandler:
setInterruptionHandler:
setExportedInterface:
setExportedObject:
synchronousRemoteObjectProxyWithErrorHandler:
resume
decodeInt64ForKey:
decodeBoolForKey:
decodeFloatForKey:
decodeObjectForKey:
decodeInt32ForKey:
decodeDoubleForKey:
rangeValue
setSpeechContext:
setEventMetadata:
eventMetadata
initWithNSUUID:
setTtsId:
captureSnapshot
logWithEventContext:ttsIdentifier:
setEnded:
setContextId:
setSynthesizedAudioDurationInSecond:
setSynthesisLatencyInSecond:
setSynthesisRealTimeFactor:
setErrorCodes:
setVoiceFallbackOccurred:
setVoiceSettings:
voiceSettings
setVoiceGender:
convertLanguageCodeToSchemaLocale:
setVoiceAccent:
setVoiceType:
setVoiceFootprint:
setVoiceVersion:
setFailed:
setCancelled:
setExists:
setRequestReceivedTier1:
setRequestReceived:
linkId
setLinkId:
setRequestedVoiceContext:
requestedVoiceContext
setInputTextLength:
setTextToSynthesize:
setSource:
setTarget:
setUuid:
setComponent:
setStartedOrChanged:
setAudioInterface:
audioInterface
setVendorId:
setProductId:
setCustomerPerceivedLatencyInSecond:
setSynthesisSource:
setVoiceContext:
voiceContext
setResourceVersion:
setSynthesisEffect:
relatedAssetsWithOnlyAvailable:
listAssetsOfTypes:matching:
bestAssetOfTypes:matching:
@48@0:8@16@24q32^@40
@16@0:8
v24@0:8@16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
v16@0:8
@"NSString"
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
B16@0:8
v20@0:8B16
f16@0:8
v20@0:8f16
Q16@0:8
v24@0:8Q16
@?16@0:8
v24@0:8@?16
B24@0:8@16
@40@0:8@16@24^@32
B32@0:8@16^@24
B24@0:8^@16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^v16@0:8
v24@0:8^v16
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8q16
i16@0:8
v20@0:8i16
I16@0:8
v20@0:8I16
#24@0:8q16
q24@0:8@16
@"NSData"16@0:8
@24@0:8@16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
@"NSData"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
@24@0:8Q16
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@"NSArray"
@32@0:8@16@24
v48@0:8@16@?24@?32@?40
@"OspreyChannel"
@"TTSAXResourceManager"
@"TTSAssetType"
@"TTSAssetSource"
@"TTSAssetTechnology"
@"TTSAssetQuality"
@"NSNumber"
@"NSDictionary"
@"NSBundle"
ar-SA
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
en-scotland
es-AR
es-CO
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
nb-NO
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
ar-SA
da-DK
de-DE
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-CL
Hola, soy Siri.
es-ES
Hola, soy Siri.
es-MX
Hola, soy Siri.
fi-FI
fr-CA
fr-FR
he-IL
it-IT
ja-JP
ko-KR
nb-NO
nl-BE
nl-NL
pt-BR
ru-RU
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
oren
O-ren
O-ren
O-ren
limu
Li-mu
Li-mu
Li-mu
Yu-shu
Yu-shu
Sin-ji
Sin-Ji
Azul
Sydney
Star
StarBravo
SkyE
SkyEcho
speak
oren
sakura
hattori
hiro
ar-001_Maged
ar-SA
ca-ES
cs-CZ_Zuzana
cs-CZ
da-DK_Sara
da-DK
de-DE_Anna
de-DE
el-GR_Melina
el-GR
en-AU_Karen
en-AU
en-GB_Daniel
en-GB
en-IE_Moira
en-IE
en-IN_Rishi
en-IN
en-US_Samantha
en-US
en-ZA_Tessa
en-ZA
es-ES_Monica
es-ES
es-MX_Paulina
es-MX
fi-FI_Satu
fi-FI
fr-CA_Amelie
fr-CA
fr-FR_Thomas
fr-FR
he-IL_Carmit
he-IL
hi-IN_Lekha
hi-IN
hr-HR_Lana
hr-HR
hu-HU_Mariska
hu-HU
id-ID_Damayanti
id-ID
it-IT_Alice
it-IT
ja-JP_Kyoko
ja-JP
ko-KR_Yuna
ko-KR
ms-MY_Amira
ms-MY
nl-BE_Ellen
nl-BE
nl-NL_Xander
nl-NL
nb-NO_Nora
no-NO
pl-PL_Zosia
pl-PL
pt-BR_Luciana
pt-BR
pt-PT_Joana
pt-PT
ro-RO_Ioana
ro-RO
ru-RU_Milena
ru-RU
sk-SK_Laura
sk-SK
sv-SE_Alva
sv-SE
th-TH_Kanya
th-TH
tr-TR_Yelda
tr-TR
uk-UA_Lesya
uk-UA
vi-VN_Linh
vi-VN
zh-CN_Tingting
zh-CN
zh-HK_Sinji
zh-HK
zh-TW_Meijia
zh-TW
com.apple.siri
com.apple.siri
Name
Language
Gender
Technology
Quality
Available
Obsolete
Source
