@(#)PROGRAM:SiriTTSService  PROJECT:SiriTTSService-1
?mcpl
L?NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_0NS_9allocatorIS2_EEFvRKNS_6vectorIfNS3_IfEEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIfNS_9allocatorIfEEEEEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_0
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_1
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_2NS_9allocatorIS2_EEFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS3_IS7_EEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS_9allocatorIS4_EEEEEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_2
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_3
N5apple4aiml12flatbuffers216DefaultAllocatorE
N5apple4aiml12flatbuffers29AllocatorE
SiriTTSService
AudioPlaybackError
AudioRouteInfo
AudioData
AudioPlayback
BufferedAudioPlayback
AudioPower
AudioPowerProviding
AudioInterface
AudioQueueInterface
AudioQueueBufferUserData
_NSRange
CMSampleBuffer
NCMSampleBufferRef
CMTime
AudioTimeStamp
ThermalState
NNSProcessInfoThermalState
os_unfair_lock_s
TTSAssetProperty
URLResourceKey
NNSURLResourceKey
Name
NNSNotificationName
AudioStreamBasicDescription
Foundation
AudioStreamPacketDescription
TRIOnDemandFactorDownloadStatus
MatchingFlags
NNSMatchingFlags
CFString
NCFStringRef
TTSAssetVoiceGender
CMTimeFlags
AudioTimeStampFlags
SMPTETime
SMPTETimeFlags
SMPTETimeType
DiagnosticService
MetricsJsonKeys
CacheReadingAction
VoiceAttribute
TTSAssetStubStrategy
MappedData
PassThroughAction
SynthesisConfigProviding
InlineStreamingStorage
EngineCachingService
SignpostHandler
MobileGestalt
Features
NeuralUtils
Locked
Flags
RetryTextModificationAction
OspreyClient
TTSAssetTrialAsset
TTSAssetTrialVoiceAsset
TTSAssetTrialResourceAsset
TTSAssetAdhocStrategy
TextToPhonemeAction
TTSAssetStrategy
SiriFeatures
TTSAssetFeatures
Event
NotificationHandling
OptionalNotificationHandling
TTSAssetTrialProxyInstantiatedAsset
TTSAssetProxyCallback
TTSAssetProxyProgressCallback
TTSAssetProxyPathCallback
TTSAssetProxyStrategy
ProxyKey
TTSAssetMAStrategy
DownloadSourceExtractor
OSVersion
TTSAssetTrialStrategy
AssetClass
WorkflowErrorHandler
Workflow
DataContainer
Buffer
Actionable
Conditional
AsynchronousContext
Asynchronous
WorkflowNode
WorkflowCondition
SynthesisCacheWritingAction
Constants
DaemonXPCAllowedTypeSets
Entitlements
supo
OpusDecoder
TTSAssetProxyAsset
SynthesisEngineSelectionAction
DependencyInjectable
ObjectPool
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-GD
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
ms-MY
nl-BE
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
vi-VN
zh-CN
zh-HK
zh-TW
TTSAssetMAAsset
TTSAssetMACompactAsset
DefaultMacinTalkProperties
DefaultVocalizerProperties
PreinstalledWordTimingStorage
AudioPowerHandler
OpusEncodingAction
InternalSettings
Default
InlineStreamingAction
TTSError
TTSErrorCode
DirectedAcyclicGraph
RequestPreprocessAction
TTSAssetStaticVoice
TTSAssetAdhocVoice
TTSAssetPreinstalledVoice
TTSAssetStaticResource
TTSAssetAdhocResource
Localization
HomePodSetupStringKey
DelegateHandler
AudioFile
AudioDumpAction
AssistantAsset
AssistantVoiceMaps
HasAudioCondition
CoreAnalyticsInterface
CoreAnalyticsService
CoreAnalyticsSynthesisHandler
TrialAssetProvider
VoiceAsset
ResourceAsset
DownloadOption
LocalAssetProvider
BuiltInVoiceProvider
VocalizerCustomVoiceProvider
PreinstalledVoiceProvider
OspreyTTSAction
VoiceSelectionAction
RequestParsingAction
Logger
AVSBARPlayback
AudioMappedInfoAVSBAR
AudioPlaybackServiceState
Timeout
|?>q=
%>?5^>`
>B`e>
?5^>
y=q=
->J
N>?5^>
SSMLSimpleParser
RoughDurationEstimationAction
DurationEstimator
PhonemeElement
AudioPlaybackAction
TTSAssetPreinstalledStrategy
DeviceSynthesisAction
Preferences
OpusEncoder
CacheStorage
SynthesisCacheFile
SynthesisCacheChunkIterator
SynthesisCache
CodingKeys
TTSAssetLegacyAsset
Languages
PreinstalledAudioStorage
OspreyConfigProviding
OspreyBuiltInConfig
OspreyChainedConfigs
WeakDaemonDelegateWrapper
DaemonConnection
SiriTTSService
WordTimingInfo
InstrumentationMetrics
SourceOfTTS
AudibleContext
ProsodyProperties
SynthesisContext
SynthesisProfile
BaseRequest
AudioRequest
SynthesisRequest
PhonemeRequest
PhonemeSystem
SpeechRequest
SynthesisVoice
Footprint
VoiceType
VoiceGender
SynthesisVoiceSubscription
SynthesisResource
InlineStreamingSignal
DaemonSession
OspreyTTSPrewarmAction
SiriAnalyticsHandler
female
male
unspecifB
Partition
SiriTTSPhonemeTool
Unknown phoneme system: %d
basic_string
service
SiriTTSSynthesisEngine
Empty voice path cannot be used.
TTSSynthesizer::initialize error: %@
mimeType
TTSSynthesizer::load_voice_resource
tts.feature.prompt
tts.neural.use_fallback
TTSSynthesizer::synthesize_text error: %@
vector
SiriTTSNeuralUtils
fe_feature
fe_feature_only
quality
channel_type
app_id
context_info
dialog_identifier
experiment_identifier
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
phonemes
word_phonemes
prompts
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data
resources
return_log
voice_asset_path
resource_asset_path
return_server_info
sample_rate
pcm_data
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
speech_id
session_id
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
value
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
stream_id
error_code
error_str
decoder_description
playback_description
streaming_playback_buffer_size_in_seconds
current_pkt_number
word_timing_info
feature
total_pkt_number
content_type
content
v24@?0^v8Q16
v32@?0@8Q16^B24
v20@?0r*8I16
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
cur_
scratch_end
scratch_
scratch_data
buf_
Finished
finished
ReferTo
off && off <= GetSize()
EndVector
i < size()
Finish
strlen(file_identifier) == kFileIdentifierLength
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
v16@?0@"OspreyMutableRequest"8
OspreyTTSService
Corrupted Osprey response.
-[SiriTTSOspreyChannel streamTTS:beginHandler:chunkHandler:completion:]_block_invoke
Unknown response from Osprey for streaming TTS
AXSpeechTransformTextWithLanguage
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
TTSAXResourceManager
Unable to find class %s
com.apple.ttsasset.NewAssetNotification
com.apple.trial.client
, isAppleProduct:
packetDescriptions
, packet count: 
AudioData: Unable to read audio file from 
AudioData: Unable to get audio file format, errno 
AudioData: Unable to get audio data byte count, errno 
AudioData: Unable to get audio data packet count, errno 
AudioData: Unable to get maximum packet size, errno 
AudioData: Unable to get audio data, errno 
Invalid chunk size: %ld at offset %ld, bytes count = %ld
SiriTTSService.AudioPlayback
siritts_audio_playback_queue
AudioService: Unable to create output audio queue, errno 
Unable to dispose AudioQueue, errorCode: %s
AudioService: Unable to start AudioQueue, error 
Unable to begin access power, error: %s
Unable to allocate AudioQueue Buffer, code: 
Unable to enqueue audio data, code: 
Detected stalled audio generation, will enqueue %f silence frame to compensate.
AudioService: Unable to stop AudioQueue immediately, errno 
Unable to get audio power, error: %s
Unable to end access power, error: %s
asbd
audioData
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
VoiceSynthesizerNumericID
VoiceNumericID
VoiceName
VoiceLocalizedNames
VoiceNameRoot
VoiceIdentifier
VoiceAge
VoiceGender
VoiceDemoText
VoiceLanguage
VoiceLocaleIdentifier
VoiceVersion
VoiceScriptCode
VoiceGroup
VoiceType
VoiceRelativeDesirability
VoiceSupportedCharacters
VoiceIndividuallySpokenCharacters
VoiceDiskSize
VoiceAssetDescription
VoiceGenderMale
VoiceGenderFemale
VoiceGenderNeutral
VoiceGenderNeuter
 {}. 
Dobr
 den, jmenuji se {}. Jsem 
 hlas.
Hej, jeg hedder {}. Jeg er en dansk stemme.
Hallo, ich hei
e {} und ich bin eine deutsche Stimme.
 {}. 
Hello, my name is {}. I am an Australian-English voice.
Hello, my name is {}. I am a British-English voice.
Hello, my name is {}. I am an Irish-English voice.
Hello, my name is {}. I am an Indian-English voice.
Hello, my name is {}. I am an American-English voice.
Hello, my name is {}. I am a South African-English voice.
Hello, my name is {}. I am a Scottish-English voice.
Hola, me llamo {} y soy una voz espa
ola.
Hola, me llamo {} y soy una voz mexicana.
Hei, minun nimeni on {}. Olen suomalainen 
Bonjour, je m
appelle {}. Je suis une voix canadienne.
Bonjour, je m
appelle {}. Je suis une voix fran
aise.
m! {} vagyok. 
n vagyok a magyar hang.
Halo, nama saya {}. Saya berbahasa Indonesia.
Salve, mi chiamo {} e sono una voce italiana.
Hallo, mijn naam is {}. Ik ben een Belgische stem.
Hallo, mijn naam is {}. Ik ben een Nederlandse stem.
Hei, jeg heter {}. Jeg er en norsk stemme.
Witaj. Mam na imi
 {}, jestem g
osem kobiecym dla j
zyka polskiego.
, o meu nome 
 {} e a minha voz corresponde ao portugu
s que 
 falado no Brasil
, chamo-me {} e dou voz ao portugu
s falado em Portugal.
 cheam
 {}. Sunt o voce rom
neasc
 {}. 
Ahoj. Vol
m sa {}. Som hlas v slovenskom jazyku.
Hej, jag heter {}. Jag 
r en svensk r
Merhaba, benim ad
m {}. Ben T
e bir sesim.
 Siri!
Hej, jeg er Siri.
Hallo, ich bin Siri.
Hello, I'm Siri.
Hei, min
 olen Siri.
Bonjour, je suis Siri.
 Siri.
Ciao, sono Siri.
Siri
 Siri
Hei, jeg er Siri.
Hallo, ik ben Siri.
Oi, meu nome 
 Siri.
 Siri.
Hej, jag heter Siri.
 Siri
Merhaba, ben Siri.
Siri
Hello
Siri
Siri
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
cookie
authTokens
SIRI_TEXT_TO_SPEECH
voice
\u001B\\pause=['"]?([0-9]+)['"]?
<break time=['"]([0-9]+)ms['"]\s*\/>
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_TRY_SAY_1
ca-ES_Montserrat
paused
started
waitForFinish
stopped
magicVersion
timingInfos
com.apple.springboard
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
com.apple.voicetool
com.apple.siri.tts.SiriTTSServiceIntegrationTests.xctrunner
com.apple.siritts-tool
synthesisContext
SiriTTSAudioData
supportsSecureCoding
TB,N
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
q16@0:8
v24@0:8q16
@24@0:8@16
T{AudioStreamBasicDescription=dIIIIIIII},N,Vasbd
T@"NSData",N,C
Tq,N,VpacketCount
T@"NSString",N,R
B24@0:8@16
hash
audioInterface
audioOperationQueue
playbackError
audioSequence
_TtC14SiriTTSService19AudioQueueInterface
discontinuedDuringPlayback
outputRouteInfo
audioQueue
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
_TtCC14SiriTTSService19AudioQueueInterfaceP33_D074378E45DF23C69F519544CB6674D224AudioQueueBufferUserData
expectedPlaySampleTime
SiriTTSServiceAudioPlayback
Unable to query kAudioQueueProperty_IsRunning, %s
Unexpected to have startTime == 0
Enqueued audio buffer #%ld, packet count: %ld, bytes: %ld
Played audio buffer #%ld, packet count: %ld, bytes: %ld
Current route info: {%s}
Started AudioQueue.
Starting AudioQueue...
SiriTTSSynthesizingRequestProtocol
T@"SiriTTSSynthesisContext",N,&
@"SiriTTSSynthesisContext"16@0:8
v24@0:8@"SiriTTSSynthesisContext"16
SiriTTSAudibleRequestProtocol
T@"SiriTTSAudibleContext",N,&
@"SiriTTSAudibleContext"16@0:8
v24@0:8@"SiriTTSAudibleContext"16
_TtP14SiriTTSService22DaemonDelegateProtocol_
v32@0:8Q16@"SiriTTSInstrumentationMetrics"24
v32@0:8Q16@"SiriTTSAudioData"24
v32@0:8Q16@"NSArray"24
v24@0:8@?<v@?>16
_TtP14SiriTTSService14DaemonProtocol_
v28@0:8B16@?20
v32@0:8@16@?24
v48@0:8@16@24@32@?40
v28@0:8B16@?<v@?@"NSError">20
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSAudioRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSSpeechRequest"16@?<v@?@"NSError">24
v24@0:8@"SiriTTSBaseRequest"16
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?d@"NSError">24
v32@0:8@"SiriTTSPhonemeRequest"16@?<v@?@"NSString"@"NSError">24
v24@0:8@"SiriTTSInlineStreamingSignal"16
v24@0:8@"SATTSSpeechSynthesisStreaming"16
v48@0:8@"NSArray"16@"NSString"24@"NSString"32@?<v@?@"NSError">40
v32@0:8@"NSString"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"SiriTTSSynthesisVoice"@"NSError">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?ff>24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B@"NSError">24
Unable to remove file %s
_TtC14SiriTTSService17DiagnosticService
notificationCenter
observers
Unable to encode json data
Unable to locate data dump directory
Unable to write json metrics at %s, %s
Json metrics saved to: %s
Instrumentation Metrics Data (id: %llu):
v16@?0@"NSNotification"8
Event '%s' expect associated object as %s, got: %s
SynthesisResource
InstrumentationMetrics
Array<WordTimingInfo>
AudioPowerProviding
siriInlineOneShot
siriInlineStreaming
siriServerRoundTrip
Unable to list content of directory %{public}s
No request is provided. Ignore reading cache.
No cache storage is provided. Ignore reading cache.
No voice is provided. Ignore reading cache.
No resource is provided. Ignore reading cache.
\mrk=play=phat\
Synthesis cache is found for request %@
Ignore reading cache since phatic prompt should have randomness.
Preinstalled audio is found for request %@
Ignore reading cache due to internal settings disables caching.
_TtC14SiriTTSService18CacheReadingAction
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
VoiceGroupCustom
Swift/Dictionary.swift
VoiceGroupCustomCompact
VoiceGroupCompact
SupportedCharacters
com.apple.siri.SiriTTSService
_TtC14SiriTTSService20TTSAssetStubStrategy
_TtC14SiriTTSService10MappedData
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
Unable to handle mmap file, errno: %d, error: %s
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file to length: %ld, errno: %d, error: %s
Unable to mmap file at path: %{public}s, errno: %d, error: %s
_TtC14SiriTTSService17PassThroughAction
SiriTTSService
v44@0:8@16B24@?28@?36
v24@0:8@?16
v20@0:8B16
Cleared inline streaming object storage.
Notification for %s has not started. Cache object %@
Found cached objects %@
Start streaming for %s
_TtC14SiriTTSService22InlineStreamingStorage
storage
streamingHandlers
signals
lock
Notification for %s is on-going. Posting object immediately %@
InlineStreamStorage
_TtC14SiriTTSService20EngineCachingService
_activeSessionCount
_cachedEngine
No active session now, unloading cached engine with path %s
_TtC14SiriTTSService15SignpostHandler
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
TTSStartAudio
[Error] Interval already ended
TTSServerFirstPacket
TTSEngineSelect
engineTag=%s
TTSVoiceSelect
voice=%s
TTSSynthesis
source=%s
TTSPlayback
HardwarePlatform
lowInactiveMemory
VoiceServices
VoiceSelectionAction: Cannot find synthesizing request
_TtC14SiriTTSService27RetryTextModificationAction
v16@?0@"SiriTTSOspreyStreamingBeginResponse"8
v16@?0@"SiriTTSOspreyStreamingPartialResponse"8
v16@?0@"NSError"8
_TtC14SiriTTSService12OspreyClient
grpcChannel
speechId
https://seed-dejavu.siri.apple.com
ttsContentVersion
Trial asset %{public}@ not downloading, unable to cancel
Trial asset %{public}@ already downloaded, unable to cancel
v20@?0B8@"NSError"12
SiriTTSService.TTSAssetTrialAsset
_TtC14SiriTTSService18TTSAssetTrialAsset
factorName
assetAttr
isDownloading
downloadToken
progressQueue
assetSource
T@"TTSAssetSource",N,R
versionDescription
diskSize
T@"NSNumber",N,R
supportedLanguages
T@"NSArray",N,R
T@"NSBundle",N,R
locallyAvailable
_TtC14SiriTTSService23TTSAssetTrialVoiceAsset
T@"TTSAssetType",N,R
technology
T@"TTSAssetTechnology",N,R
T@"TTSAssetQuality",N,R
name
identifier
gender
T@"NSDictionary",N,R
_TtC14SiriTTSService26TTSAssetTrialResourceAsset
TrialAssetDownloadProgress
com.apple.speech.synthesis.voice.
com.apple.speech.synthesis.voice.custom.siri.
Missing name for voice
Missing footprint for voice
Unknown footprint for voice: %@
Missing asset type for voice
Unknown asset type for voice: %@
Asset %s attributes %s level %@
Unable to initialize asset bundle from path: %{public}s
MobileAssetProperties
Asset %s path %s
Unable to get level for factor name '%{public}s'
Trial asset %{public}@ immediate removal failed with error %@
Trial asset %{public}@ immediate removal succeeded
Trial asset %{public}@ deferred removal failed with error %@
Trial asset %{public}@ deferred removal succeeded
Trial asset %{public}@ download cancellation failed with error %@
Trial asset %{public}@ download cancelled
Trial asset %{public}@ start download with option %{public}@
Trial asset %{public}@ download failed with error %@
Trial asset %{public}@ download succeeded
Trial download %u%% done, %.2fs left %d written status %d
v24@?0d8Q16
_TtC14SiriTTSService21TTSAssetAdhocStrategy
Skip invalid voice folder '%s'
Skip invalid resource folder '%s'
#Local listing assets for types: %s, filter: %s
Unable to list resource folder %s
/private/var/mobile/Library/VoiceServices/resources/
Unable to list voice folder %s
/private/var/mobile/Library/VoiceServices/voices/
/System/Library/PrivateFrameworks/TTSAsset.framework/Voices/
TextToPhoneme request is not set
TextToPhoneme voice is not found
_TtC14SiriTTSService19TextToPhonemeAction
engineCachingService
ObjectPool: Unregistered type 
ObjectPool: Constructed wrong object type 
TTSAsset encountered unknown asset type %{public}@ and tentatively tried to handle through Trial
enable_adhoc_voice
use_trial
TTSAsset
sirix
Siri
SiriTTSService.Event.taskCompletion
SiriTTSService.Event.audioPowerProviderAvailable
SiriTTSService.Event.neuralFallback
SiriTTSService.Event.neuralAudioClick
SiriTTSService.Event.neuralAlignmentStall
SiriTTSService.Event.synthesisUsedPrompt
SiriTTSService.Event.encounteredError
SiriTTSService.Event.synthesisEngineChanged
SiriTTSService.Event.receivedServerLastPacket
SiriTTSService.Event.voiceResourceSelected
SiriTTSService.Event.synthesisError
SiriTTSService.Event.eagerRequestDetected
SiriTTSService.Event.cancellationRequested
SiriTTSService.Event.phonemesGenerated
SiriTTSService.Event.audioPlaybackEnded
SiriTTSService.Event.audioPlaybackEnqueued
SiriTTSService.Event.audioPlaybackStarted
SiriTTSService.Event.audioPlaybackStarting
SiriTTSService.Event.receivedServerFirstPacket
SiriTTSService.Event.engineSelectEnd
SiriTTSService.Event.engineSelectStart
SiriTTSService.Event.voiceSelected
SiriTTSService.Event.voiceSelectStart
SiriTTSService.Event.synthesisStarted
SiriTTSService.Event.audioGenerated
SiriTTSService.Event.wordTimingGenerated
SiriTTSService.Event.synthesisEnded
SiriTTSService.Event.encounteredIssue
SiriTTSService.Event.instrumentationMetricsAvailable
SiriTTSService.Event.requestReceived
SiriTTSService1
B40@0:8@16@24@32
_TtC14SiriTTSService35TTSAssetTrialProxyInstantiatedAsset
registry
_TtC14SiriTTSService29TTSAssetProxyProgressCallback
_TtC14SiriTTSService25TTSAssetProxyPathCallback
_TtC14SiriTTSService21TTSAssetProxyStrategy
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
TrialXP (by Proxy)
Failed to establish connection, return empty result from proxy assets
Failed to get value from xpc reply, return empty results from proxy assets
<- %d assets
B24@?0q8@"<OS_xpc_object>"16
Listing asset types %{public}s through XPC service...
Failed to establish connection & sandbox
Failed to get sandbox extensions
Failed to consume sandbox extension %s
Consume sandbox extension %s
v16@?0@"<OS_xpc_object>"8
com.apple.SiriTTSService.TrialProxy
v16@?0@"TTSAsset"8
v32@?0d8q16q24
Unable to issue sandbox extension to path '%{public}s'
Unable to convert C string into Swift string for authToken'
Issued sandbox extension to path %s
Unexpected non Trial asset %{public}@
Unable to get bundle path for factor name %s
com.apple.private.sirittsservice.modify-proxy-assets
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
neuralAX
compact
premium
premiumhigh
beta
production
T@"TTSAssetServer",N,R
livability
staging
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
_TtC14SiriTTSService18TTSAssetMAStrategy
stagingURL
_TtCC14SiriTTSService18TTSAssetMAStrategy23DownloadSourceExtractor
v56@0:8@16@24@32@40@48
v48@0:8@16@24@32@40
v32@0:8@16@24
inKey
wantValue
source
#MobileAsset Unable to create query
Query for %{public}@ failed: %d
Download asset catalogs, sync: %{bool}
#MobileAsset listing assets for type '%@', filter: '%{public}s'
v16@?0q8
Catalog %{public}@ download failed: %d
/var/MobileAsset/AssetsV2/
https://mesu.apple.com/assets/
https://basejumper.apple.com/livability/
Server (default) for %{public}@
Server %{public}@ for %{public}@: %d
https://basejumper.apple.com/assets/
https://basejumper.apple.com/assets
https://basejumper.apple.com/
_TtC14SiriTTSService21TTSAssetTrialStrategy
#Trial Synchronous namespace download took %.1fs
#Trial listing assets for class '%s', types: '%{public}s', filter: '%{public}s'
com.apple.siri.tts.
Factor %s does not have %ld components as expected.
Encountered entirely unexpected factor %s.
Refreshing stale trial client
TTSAsset Trial Callbacks
/private/var/MobileAsset/AssetsV2/com_apple_MobileAsset_Trial_Siri_SiriTextToSpeech/
/Library/Trial/Treatments/
v16@?0@"<TRINamespaceUpdateProtocol>"8
Get namespace update, refreshing trial client
Workflow: waitDequeue timed out in 
Workflow: waitDequeue timed out in %s
Encountered error: %s
Encountered error during error handling: %s
Gracefully handle error: %s
_TtC14SiriTTSService8Workflow
graph
errorHandlers
_isCancelled
cancellationLock
_TtC14SiriTTSService13DataContainer
idContainer
_TtC14SiriTTSService6Buffer
bufferCondition
_TtC14SiriTTSService19AsynchronousContext
isProcessing
asyncError
waitTimeout
isProcessingCondition
_TtC14SiriTTSService12WorkflowNode
action
_TtCC14SiriTTSService12WorkflowNode17WorkflowCondition
conditional
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
(AudioMappedInfoAVSBAR in _4791274A894FA1CB92EFFF8F61E0C16D)
SynthesisVoiceSubscription
AVQueuedSampleBufferRendering
Conditional node has no next node, %s
TTSAssetTrialProxyInstantiatedAsset
InlineStreamingSignal
com.apple.ttsasset
SiriTTSService2
B32@0:8@16@24
v8@?0
Ignore writing cache due to missing cache storage
Ignore writing cache due to missing audio data
Ignore writing cache due to missing request info
Ignore writing cache due to missing voice info
Ignore writing cache due to missing voice resource info
Unable to create cache file, error: 
Ignore writing cache with empty data, probably audio prime data
Ignore writing cache since phat prompt should have randomness.
Ignore writing cache since audio is from cache already
Ignore writing cache due to internal settings disable caching
_TtC14SiriTTSService27SynthesisCacheWritingAction
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
Unable to write cache, %s
Invalidate synthesis caching. %s
Synthesis cache %s is written.
Synthesis cache %s is cancelled.
Unable to close cache file, %s
Detected synthesis error.
Detected neural alignment stall.
Detected neural audio click.
Detected neural fallback.
Cancellation is requested.
com.apple.sirittsd
com.apple.sirittsd.can-dump-audio
v24@0:8@16
OpusDecoder: Opus not supported)
OpusDecoder: Opus unknown asbd 
OpusDecoder: Unable to create converter, source asbd 
OpusDecoder: Unable to create pcm buffer
@"AVAudioBuffer"20@?0I8^q12
OpusDecoder: Unable to decode chunk, error: 
_TtC14SiriTTSService11OpusDecoder
fromFormat
toFormat
converter
No bundle path from proxy presentation
Invalid bundle path %{public}s
Constructed bundle %s
Trial proxy download status check failed, unable to establish server connection
-> %@
<- %@
Failed to get download status
Trial proxy asset [%@] not downloading, unable to cancel
Trial proxy asset download cancellation failed, unable to establish server connection
Trial proxy asset [%@] cancelling download.
SiriTTSService.TTSAssetProxyAsset
_TtC14SiriTTSService18TTSAssetProxyAsset
assetQuality
bundlePath
authorizedBundle
proxy_attr
assetType
versionNumber
Tq,N,R
attributes
purgeable
Trial proxy asset [%@] download cancelled.
Trial proxy asset [%@] download cancellation failed.
Trial proxy asset download failed, unable to establish server connection
Trial proxy asset [%@] download starting.
Trial proxy asset [%@] already locally available, no download necessary
Trial proxy asset [%@] download failed.
Trial proxy asset [%@] download succeeded.
.siri.tts.resource.
DeviceSynthesisAction: No voice asset was set
gryphon_frontend
Unable to load resource %s, error: %s
_TtC14SiriTTSService30SynthesisEngineSelectionAction
voice_configs.plist
Unable to load voice_configs.plist from %s
vocalizer_resources
Unable to parse vocalizer_resources
vocalizer_resource_order
Unable to parse vocalizer_resources_order
Unknown mime-type for file %s
_TtC14SiriTTSService10ObjectPool
constructorRegistry
objectPool
speech.synthesis.voice
_MasteredVersion
_CompatibilityVersion
LanguagesCompatibility
SiriTTSService.TTSAssetMAAsset
_TtC14SiriTTSService15TTSAssetMAAsset
asset
bundle
_TtC14SiriTTSService22TTSAssetMACompactAsset
v16@?0@"MAProgressNotification"8
Preposterous string version %{public}@ for key %{public}@ in %@
Preposterous integer version %d for key %{public}@ in %@
_TtC14SiriTTSService29PreinstalledWordTimingStorage
storageURL
voice name is required for preinstalled word timings.
No preinstalled word timings plist file at path %{public}s
Unable to convert to expected format file at path %{public}s
Missing word_timings field in file at path %{public}s
Unable to find word '%s' in word timing pair in file at path %{public}s
Missing word timing pair in file at path %{public}s
No preinstalled word timings for %{public}s %s. Falling back to %s
_TtC14SiriTTSService17AudioPowerHandler
audioPowerProvider
OpusEncodingAction: no audio found
OpusEncodingAction: Audio is already opus encoded
_TtC14SiriTTSService18OpusEncodingAction
encoder
_TtC14SiriTTSService16InternalSettings
_disableTTS
_enableDiagnostic
_logSensitiveText
_disableCache
_overrideRequestsText
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
logSensitiveText
overrideRequestsText
DisableAssetCleaning
AllowAnyAssetSubscription
defaultToNonDiscretionaryDownloads
EnableLocalVoices
ServerTTSTimeout
DeviceTTSWaitTime
disableDeviceRacing
disableServerTTS
disableInlineStreamTTS
disableOspreyStreaming
streamBufferDuration
ospreyEndpointURL
simulateNetworkStall
simulateAudioStall
disableDeviceNeuralTTS
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
com.apple.voiceservices
process is not running as user Mobile: it's not accessing our shared UserDefaults
InlineStreamingAction: Cannot find request
InlineStreamingAction: Cannot find streaming signal for 
_TtC14SiriTTSService21InlineStreamingAction
asyncContext
streamingStorage
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
InlineStreamingAction: Unknown stream object 
InlineStreamingAction: Unknown inline streaming error 
Received streaming audio chunk before receiving streaming audio begin
Simulate network stall is on, ignore inline streaming objects
InlineStreamingAction: Unsupported inline streaming audio format 
Inline streaming timed out
Inline streaming network stall
Internal setting specifies timeout: %f
sirittsd crashed
RequestParser: Cannot find request.
Overriding text with internal default: %s
Overriding whisper with internal default
Overwriting pitch with internal default: %f
Overwriting rate with internal default: %f
Overwriting volume with internal default: %f
_TtC14SiriTTSService23RequestPreprocessAction
settings
SSMLConversion: Unsupported tag: 
Error in pause tag, ignore
Error in tn override tag, ignore
<say-as interpret-as="
SSMLConversion: Unbalanced say-as tag
SSMLConversion: Unbalanced phoneme tag
<phoneme alphabet="lhp" ph="
AssistantEtiquette
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/AssistantEtiquette
%{public}s is not TTS language, fallback to %{public}s
_TtC14SiriTTSService19TTSAssetStaticVoice
attr
_TtC14SiriTTSService18TTSAssetAdhocVoice
_TtC14SiriTTSService25TTSAssetPreinstalledVoice
_TtC14SiriTTSService22TTSAssetStaticResource
_TtC14SiriTTSService21TTSAssetAdhocResource
Resource Asset %s path %s attributes %s
SiriTTSService.TTSAssetStaticResource
SiriTTSService/TTSAssetStaticAsset.swift
Subclasses of TTSAssetStaticResource must override assetSource
SiriTTSService.TTSAssetStaticVoice
Subclasses of TTSAssetStaticVoice must override assetSource
SiriTTSLocalization
HomePodDeviceSetup
Unable to find HomePod setup string for key '%s', %s
LocalizedStrings
SIRITTSSERVICE_NETWORK_STALL_3
Unable to find retry phrase '%s', %s
SIRITTSSERVICE_NETWORK_STALL_2
SIRITTSSERVICE_NETWORK_STALL_1
_TtC14SiriTTSService15DelegateHandler
delegate
com.apple.voiceservices.notification.synthesis-done
audibleContext
Unable to create directory at %s, error: %s
%s is not a directory!
Unable to get Library directory for audio dumping
AudioDump: Cannot find audio data.
Unable to find request of AudioDumpAction
Audio saved to: %s
Ignore writing audio file due to missing entitlement. Please add 'com.apple.sirittsd.can-dump-audio'.
_TtC14SiriTTSService9AudioFile
audioFile
packetOffset
_TtC14SiriTTSService15AudioDumpAction
entitlements
diagnosticAudioFile
synthesizedAudioFile
diagnosticTag
AudioFile: Unable to close audio file, code: 
AudioFile: Unable to write audio data, code: 
AudioFile: Unable to create audio file at path 
Unable to write diagnostic audio file, error: %s
SiriTTSService.AssistantAsset
SiriTTSService.AssistantVoiceMaps
AssistantVoiceMap
VoicePitchRangeDescriptors
TTSAssistantAsset
assistantGender
assistantOrder
Tq,N,R,VassistantGender
Tq,N,R,VassistantOrder
isCustom
TB,N,R
primaryLanguage
TTSAssistantVoiceMaps
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
SiriTTSService3
assistantVoiceMaps
T@"TTSAssistantVoiceMaps",N,R
_TtC14SiriTTSService17HasAudioCondition
voice_resource_asset_key
tts_synthesis_latency
tts_total_latency
audio_queue_latency
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
audio_output_route
client_bundle_identifier
privacy_sensitive
server_first_packet_latency
server_last_packet_latency
com.apple.voiceservices.metrics
real_time_factor
neural_alignment_stall
neural_audio_click
_TtC14SiriTTSService20CoreAnalyticsService
_TtC14SiriTTSService29CoreAnalyticsSynthesisHandler
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
Unrecognized request type in handleRequestReceived, got: %s
Unable to cancel download of non-TTSAssetTrialAsset asset
_TtC14SiriTTSService10VoiceAsset
path
_TtC14SiriTTSService13ResourceAsset
resource
_TtC14SiriTTSService18TrialAssetProvider
downloadQueue
_TtC14SiriTTSService18LocalAssetProvider
_TtC14SiriTTSService20BuiltInVoiceProvider
_TtC14SiriTTSService28VocalizerCustomVoiceProvider
_TtC14SiriTTSService25PreinstalledVoiceProvider
Unfound built-in voice for language %{public}s
Falling back to no-NO voice since nb-NO is not available
Unable to find resource for 
Resource asset is locally available: %s
Unable to download resource: 
Unable to download namespace, %s
Unable to find best voice for 
Voice is locally available already: %@
Unable to download voice: 
Unable to download SIRI_TEXT_TO_SPEECH namespace
Download namespace requires non-discretionary option
SIRI_TEXT_TO_SPEECH namespace is not downloaded yet. Try downloading now.
OspreyTTSAction: Cannot find synthesizing request
Updating osprey cache
Osprey cache is found, requestId: %llu
Missing voice name or gender for Osprey { id: 
_TtC14SiriTTSService15OspreyTTSAction
ospreyClient
ospreyConfig
streamingStartedDate
Updated osprey cache
OspreyTTSAction: error when updating osprey cache, %s
Osprey streaming network stall { id: 
Osprey streaming timed out { id: 
Encountered Osprey error: %s, { id: %llu }
Simulate network stall is on, ignore audio object
Invalid server audio format
Server voice: %@, resource: %@, buffer size: %f
Default Osprey timeout: 1.0
Osprey config specifies timeout: %f
Cannot find suitable voice for 
Ignore neural voice since it's not suitable. Current thermal level: %s, low power mode: %{bool}d, voice: %{public}@, neural platform: %{bool}d, requestId: %llu
Ignore neural voice since internal settings disable device neural TTS. requestId: %llu }
VoiceSelectionAction cannot find synthesizing request
Select voice: {%{public}s}, resource: {%{public}s}, request: {client: %{public}s, id: %s}
_TtC14SiriTTSService20VoiceSelectionAction
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
VoiceSelectionAction does not support request: 
RequestParsingAction cannot find request
RequestParsingAction found unknown request: 
_TtC14SiriTTSService20RequestParsingAction
com.apple.siri.tts
B24@?0r*8@"<OS_xpc_object>"16
VSAudioPlaybackServiceAVSBARQueue
Can't retrieve session with ID: 
Can't instantiate AVSampleBufferAudioRenderer or AVSampleBufferRenderSynchronizer. Search (AVFCore) and [com.apple.coremedia:] for the underlying error.
VSAudioPlaybackService init latency: %f
#AVSBAR initialized with session ID: %u, reusing previous synchronizer: %{bool}d
#AVSBAR already stopped or waiting for finish: will not enqueue more
Did add to enqueuedMappedAudioInfo: %f sec
Will add to enqueuedMappedAudioInfo: %f sec
#AVSBAR empty audio data: will not enqueue it
#AVSBAR already stopped or waiting for finish
Timeout waiting for AVSampleBufferRenderSynchronizer
#AVSBAR Synchronizer is stalled with rate %f at time %f.
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR waitUntilFinished
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
synchronizer stop rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f. Then renderer will be flushed.
Stopping synchronizer and renderer
synchronizer pause rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f.
Pausing synchronizer
_TtC14SiriTTSService14AVSBARPlayback
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
_TtCC14SiriTTSService14AVSBARPlaybackP33_4791274A894FA1CB92EFFF8F61E0C16D21AudioMappedInfoAVSBAR
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %ld
renderer enqueueSampleBuffer high latency: %f sec
#AVSBAR Enqueuing to %@: %f sec
#AVSBAR Call to provide more audio data during state %s.
Error in creating block buffer for Silence buffer
Error in creating block buffer for Silence buffer, code: %s
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioFormatDescriptionCreate from Silence buffer creation, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer, code: %s
Error in creating block buffer for Sample buffer
Error in creating block buffer for Sample buffer, code: %s
Error in CMAudioFormatDescriptionCreate
Error in CMAudioFormatDescriptionCreate, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in CMAudioSampleBufferCreateWithPacketDescriptions, code: %s
mediaserverd reset
#AVSBAR renderer was flushed
#AVSBAR Synchronizer reached endTime
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
synchronizer play rate high latency: %f sec
#AVSBAR already stopped or paused: will not resume rate
#AVSBAR Dropping %ld enqueued data
_TtC14SiriTTSService7Timeout
timeoutDate
waitCondition
queue
shouldStop
RoughDurationEstimation: No synthesizing request is provided
_TtC14SiriTTSService16SSMLSimpleParser
_TtC14SiriTTSService29RoughDurationEstimationAction
estimationDictionary
SiriTTSDurationEstimator
d24@0:8@16
DurationEstimator: error during process: %@
DurationEstimator: Unable to get output
DurationEstimator: DurationEstimator: Missing duration
\u001B\\\w+=.+?\\
\u001B\\toi=\w+\\.*?\u001B\\toi=orth\\
\u001B\\toi=\w+\\.*
\u001B\\toi=lhp\\([^\u001B]*)
v32@?0@"NSTextCheckingResult"8Q16^B24
Skip waiting, no active audio playback found.
Unable to stop audio playback.
Unable to wait audio playback finished.
Audio playback finished for request_id: %llu.
AudioPlayback: Cannot find audio data.
AudioPlayback: Cannot find audible request.
Audio playback started for request_id: %llu
_TtC14SiriTTSService19AudioPlaybackAction
buffer
audioPlayback
audibleRequest
Cancelling audio playback
_TtC14SiriTTSService28TTSAssetPreinstalledStrategy
#Local listing voices for types: %{public}s, filter: %{public}s
Searching in preinstalled voice directory: '%s'
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/PreinstallAssets/
Unable to list voice folder
Skip invalid voice folder '%{public}s'
SiriTTSService4
DeviceSynthesisAction: Engine is not set
DeviceSynthesisAction: Request is not set
v16@?0@"NSData"8
v16@?0@"NSString"8
v16@?0@"NSArray"8
_TtC14SiriTTSService21DeviceSynthesisAction
synthesisConfig
DeviceSynthesisAction: low RTF is detected during synthesis.
DeviceSynthesisAction: no audio data is generated.
Neural voice fell back to compact neural synthesis.
Received word timings: %s
Synthesized with prompt: '%s'
Low synthesis RTF detected, will likely results in stuttering. Missing: %f
offset element 
Unable to get defaults 'com.apple.voiceservices'
subscribedAssets
_TtC14SiriTTSService11Preferences
defaults
Preferences: Unable to find preference suite 
SiriTTSService5
B16@0:8
@16@0:8
downloading
OpusEncoder: Unknown asbd 
OpusEncoder: Opus not supported
OpusEncoder: Unable to create converter, source asbd 
OpusEncoder: Unable to encode chunk, error: 
_TtC14SiriTTSService11OpusEncoder
OpusEncoder: Unable to create input buffer
CacheStorage: Unable to create cache file at path 
Failed reading cache, error: %s
SynthesisCacheFile: invalid file, probably not closed properly, or incompatible.
Cleaned cache storage: %{public}s
Unable to remove cache file at path: %s
Cleaning cache storage: %{public}s
SynthesisCache: incorrect magic version
SynthesisCache: Unable to decode audio
SynthesisCache: Unable to decode timing info
_TtC14SiriTTSService12CacheStorage
Unable to list directory, error: %s
Missing bundle identifier for CacheStorage
Unable to create CacheStorage, error: %s
Unable to get Cache directory
CacheStorage: Path 
 is an existing file!
CFBundleShortVersionString
Failed to delete legacy asset %@: %@
SiriTTSService.TTSAssetLegacyAsset
_TtC14SiriTTSService19TTSAssetLegacyAsset
$__lazy_storage_$_voiceDesc
VoiceDescription
Swift/NativeDictionary.swift
Duplicate values for key: '
SiriTTSLanguages
availableLanguages
T@"NSSet",N,R
_TtC14SiriTTSService24PreinstalledAudioStorage
_TtC14SiriTTSService19OspreyBuiltInConfig
deviceWaitTime
allowedAppIdentifiers
_TtC14SiriTTSService20OspreyChainedConfigs
configs
_TtC14SiriTTSService25WeakDaemonDelegateWrapper
v24@0:8Q16
_TtC14SiriTTSService16DaemonConnection
connection
weakDelegate
asyncProxy
syncProxy
SiriTTSService.DaemonConnection
init()
Connection interrupted
Connection invalidated
experimentIdentifier
synthesisBeginTime
synthesisEndTime
speechEstimatedOutputBeginTime
serverFirstPacketTime
serverLastPacketTime
audioStartLatency
eagerRequestGapInterval
serverStreamedAudioDuration
isServerTTSRacing
 "audio_duration": 
 "audio_output_route": "
 "audio_queue_latency": 
 "character_count": 
 "error_code": 
 "experiment": "
 "is_speech_request": 
 "is_synthesis_cached": 
 "is_warm_start": 
 "neural_alignment_stall": 
 "neural_audio_click": 
 "neural_fallback": 
 "prompt_count": 
 "real_time_factor": 
 "server_first_packet_latency": 
 "server_last_packet_latency": 
 "source_of_tts": "
 "synthesis_to_speech_time_gap": 
 "tts_synthesis_latency": 
 "tts_total_latency": 
 "voice_resource": "
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
customResourceURLs
disableCompactVoice
synthesisProfile
prosodyProperties
", privacySensitive: 
SiriTTSService.SynthesisContext
text: "<privacySensitive, length: 
SiriTTSService.SynthesisVoice
SiriTTSService.SynthesisVoiceSubscription
SiriTTSService.SynthesisResource
SiriTTSService.InlineStreamingSignal
DaemonSession %@ sets keepActive: %{bool}d
Init DaemonSession %@
Init DaemonSession %@, with accessory %s
Deinit DaemonSession %@
DaemonSession keepActive must be true before prewarming.
Start #PrewarmRequest, %{public}s
Skipped #PrewarmRequest: TTS is disabled.
Start #SynthesisRequest %{public}s
TTSRequestReceived
id %llu
Skipped #SynthesisRequest: TTS is disabled.
Start #SpeechRequest %{public}s
Skipped #SpeechRequest: TTS is disabled.
Start #AudioRequest, %{public}@
Skipped #AudioRequest: TTS is disabled.
#CancelRequest, %@
#InlineStreaming signal %@
#InlineStreaming object %@
v12@?0B8
v16@?0f8f12
v24@?0d8@"NSError"16
Start #EstimateDuration %{public}s
Skipped #EstimateDuration: TTS is disabled.
v24@?0@"NSString"8@"NSError"16
#TextToPhoneme %s
Skipped #TextToPhoneme: TTS is disabled.
Unable to subscribe voice due to missing bundle identifier
Unable to get bundle identifier for current client
v24@?0@"SiriTTSSynthesisVoice"8@"NSError"16
Can't find alive request with timestamp %llu didStartSpeaking.
Request is not audible, but called with didStartSpeaking. %@
Can't find alive request with timestamp %llu didReportInstrument.
Can't find alive request with timestamp %llu didGenerateAudio.
Expecting synthesizing request, but got %@
Can't find alive request with timestamp %llu didGenerateWordTimings.
SiriTTSWordTimingInfo
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@40@0:8d16{_NSRange=QQ}24
startTime
textRange
Td,N,VstartTime
T{_NSRange=QQ},N,VtextRange
description
SiriTTSInstrumentationMetrics
Q16@0:8
v16@0:8
utterance
speechBeginTime
speechEndTime
T@"NSString",N,C
T@"SiriTTSSynthesisVoice",N,&,Vvoice
T@"SiriTTSSynthesisResource",N,&,Vresource
TQ,N,VrequestCreatedTime
Td,N,VeagerRequestGapInterval
TQ,N,VsynthesisBeginTime
TQ,N,VsynthesisEndTime
TQ,N,VspeechBeginTime
TQ,N,VspeechEndTime
TQ,N,VspeechEstimatedOutputBeginTime
Td,N,VaudioStartLatency
TQ,N,VserverFirstPacketTime
TQ,N,VserverLastPacketTime
Td,N,VserverStreamedAudioDuration
Td,N,VaudioDuration
TB,N,VisWarmStart
Tq,N,VsourceOfTTS
TB,N,VprivacySensitive
Tq,N,VerrorCode
TB,N,VisServerTTSRacing
Tq,N,VpromptCount
TB,N,VneuralAlignmentStall
TB,N,VneuralAudioClick
TB,N,VneuralFallback
TB,N,VisAudibleRequest
voiceResourceAssetKey
SiriTTSAudibleContext
I16@0:8
v20@0:8I16
@?16@0:8
audioSessionId
immediate
siriRequestId
didStartSpeaking
TI,N,VaudioSessionId
TB,N,Vimmediate
T@"NSUUID",N,C
T@?,N,C
SiriTTSProsodyProperties
f16@0:8
v20@0:8f16
Tf,N,VneuralSentencePitch
Tf,N,VneuralSentencePitchRange
Tf,N,VneuralSentenceDuration
Tf,N,VneuralSentenceEnergy
Tf,N,VneuralSentenceTilt
SiriTTSSynthesisContext
text
contextInfo
rate
pitch
volume
didGenerateAudio
didGenerateWordTimings
whisper
forceOspreyTTS
T@"NSDictionary",N,C
Tf,N,Vrate
Tf,N,Vpitch
Tf,N,Vvolume
T@"NSArray",N,C
Tq,N,VsynthesisProfile
TB,N,VdisableCompactVoice
TB,N,Vwhisper
T@"SiriTTSProsodyProperties",N,&,VprosodyProperties
TB,N,VforceOspreyTTS
SiriTTSBaseRequest
clientBundleId
accessoryId
outputPath
didReportInstrument
T@"NSURL",N,C
SiriTTSAudioRequest
audio
T@"SiriTTSAudioData",N,R,Vaudio
T@"SiriTTSAudibleContext",N,&,VaudibleContext
SiriTTSSynthesisRequest
@32@0:8@16@24
T@"SiriTTSSynthesisContext",N,&,VsynthesisContext
SiriTTSPhonemeRequest
@40@0:8@16@24q32
phonemeSystem
Tq,N,VphonemeSystem
SiriTTSSpeechRequest
SiriTTSSynthesisVoice
language
footprint
type
version
Tq,N,Vfootprint
Tq,N,Vtype
Tq,N,Vgender
Tq,N,Vversion
SiriTTSVoiceSubscription
@40@0:8@16@24@32
clientId
SiriTTSSynthesisResource
SiriTTSInlineStreamingSignal
SiriTTSDaemonSession
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
keepActive
v32@0:8Q16@24
SiriTTSService.SpeechRequest
SiriTTSService.PhonemeRequest
SiriTTSService.SynthesisRequest
SiriTTSService.AudioRequest
v16@?0@"SiriTTSInstrumentationMetrics"8
v16@?0@"SiriTTSAudioData"8
#Success #AudioRequest id %llu
#Error #AudioRequest id %llu, error: %s
#Success #SpeechRequest id %llu
#Error #SpeechRequest id %llu, error: %s
#Success #SynthesisRequest id %llu
#Error #SynthesisRequest id %llu, error: %s
#Success #PrewarmRequest id %llu
#Error #PrewarmRequest id %llu, error: %s
_TtC14SiriTTSService22OspreyTTSPrewarmAction
Error in Osprey prewarm: %s
_TtC14SiriTTSService20SiriAnalyticsHandler
ttsId
requestId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
com.apple.siri.audio
Captured EndTTSTime in UserDefaults
Ignore Siri logging due to missing Siri request id
Ignore Siri logging due to non Siri client
Ignore Siri logging due to unmatched Siri request id
SiriTTSService6
@20@0:8B16
Found '%{public}s' assets %{public}s
Listing asset types: '%{public}s', filter: '%{public}s'
voice path '%@', resource path '%@'
%d files under voice path:
%d files under resource path:
- %@
Failed is_neural_voice_ready %@ with error: %s
Failed should_use_neural_voice %@ with error: %s
Failed is_ane_model_compiled %@ with error: %s
Failed compile_ane_model %@ with error: %s
Replace: `%@' -> `%@'
Prompt: "%@"
Phonemes: %@
Norm Text: `%@'
Neural Phonemes: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@', request_id '%llu'
Corrupted Osprey response, stream ID: %@, request_id: %llu
Osprey streaming received Begin response with non 200 status: %d, request_id: %llu
Osprey streaming received Begin response %@, request_id: %llu
Osprey streaming received Chunk response with non 200 status: %d, request_id: %llu
Osprey streaming received Chunk response, pkt number: %d, request_id: %llu
Osprey streaming received End response with non 200 status: %d, request_id: %llu
Osprey streaming received End response, total pkt: %d, request_id: %llu
%s, Unknown response from Osprey for streaming TTS, request_id: %llu
Osprey streaming invokes completion with error %@, request_id: %llu
Osprey streaming invokes completion callback, request_id: %llu
softlink:r:path:/System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
ypSg
_pSg
G0R0_
$sSY
So8NSObjectC
$s14SiriTTSService13AudioPlaybackP
So17OS_dispatch_queueC
_pSg
$s14SiriTTSService19AudioPowerProvidingP
$s14SiriTTSService14AudioInterfaceP
_pSgc
So8NSStringC
$ss21_ObjectiveCBridgeableP
yyXlG
So13OS_xpc_object_p
yypG
_yXltG
_yXlt
So8NSObject_p
ySSG
ySS_yptG
SS_ypt
ySsG
ySDySSypGG
SDySSypG
ySny
ySiG
ySaySiGG
SaySiG
G0R3_
SgXw
SSSg
So20NSNotificationCenterC
SaySo8NSObject_pG
SdIegn_
ypSgm
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
GIegn_
So14NSUserDefaultsCSg
SdSg
SfSg
_pIegn_
SSIegn_
So8NSObjectCSg
So20NSNotificationCenterCSg
_ypt
ySSSaySDySSypGGG
ySSSDySSSaySDySSypGGGG
ySSSf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7letterstG
_ypt
ySSSo8NSObjectCG
ySSSDyS2SGG
yS2SG
ySSypycG
So13OS_xpc_object_pG
ySSySo29SATTSSpeechSynthesisStreamingCcG
ySSypG
So8TTSAssetC
_yptG
3key_yp5valuet
SaySDySSSiGG
ySS_SStG
SDySSSiG
SvSg
$s14SiriTTSService24SynthesisConfigProvidingP
So29SATTSSpeechSynthesisStreamingCytIegnr_
So29SATTSSpeechSynthesisStreamingC
So29SATTSSpeechSynthesisStreamingCIegg_
SaySo29SATTSSpeechSynthesisStreamingCG
SDySSySo29SATTSSpeechSynthesisStreamingCcG
So15NSRecursiveLockC
So34SiriTTSSynthesizingRequestProtocol_
So6NSLockC
So22SiriTTSSynthesisEngineCSg
SgXw
Ieg_
SaySJG
Iegggyi_
GIeggg_
_pSgIegg_
So20SiriTTSOspreyChannelC
So8TTSAssetCSgIegg_
So20TRINotificationToken_pSg
SaySSG
So8TTSAssetCSgIeyBy_
SdS2iIeyByyy_
Sdz_Xx
Siz_Xx
SdS2iIegyyy_
Iegyy_
_pSgIegyg_
3key_yp5valuet
_pmm
_pSg
_pmm
_pSg
So20NSNotificationCenterCm
So20NSNotificationCenterCmm
$s14SiriTTSService16TTSAssetStrategyP
xIegn_
$s14SiriTTSService20NotificationHandlingP
$s14SiriTTSService28OptionalNotificationHandlingP
yySd_S2itcG
yySSSgcG
So13OS_xpc_object_pSg
So21OS_dispatch_semaphoreC
3key_yp5valuetSg
_So13OS_xpc_object_ptG
SaySo8TTSAssetCG
SiSo13OS_xpc_object_pSbIgygd_
SaySo13TTSStringEnumCG
SaySbG
SaySDySSypGG
So12TTSAssetTypeC
ySi_
ySSG
SaySo15TTSAssetQualityCG
SaySo18TTSAssetTechnologyCG
$ss12CaseIterableP
_pSg
$s14SiriTTSService20WorkflowErrorHandlerP
ySbG
So11NSConditionC
$s14SiriTTSService10ActionableP
$s14SiriTTSService11ConditionalP
$s14SiriTTSService12AsynchronousP
_pSg
_pSg
SgXw
$s14SiriTTSService14DaemonProtocolP
$s14SiriTTSService22DaemonDelegateProtocolP
yXlXp
So8NSStringCm
So12NSDictionaryCm
So6NSUUIDCm
So5NSURLCm
So23AVAudioCompressedBufferC
So13AVAudioFormatC
So16AVAudioConverterC
So16AVAudioPCMBufferC
So15TTSAssetQualityC
So8NSBundleCSg
SDyS2SG
xIegr_
$s14SiriTTSService20DependencyInjectableP
SDySSypycG
ypSg_AAt
So7MAAssetC
ySi6offset_
7elementtG
Si6offset_
7elementt
3key_yp5valuet
SS3key_yp5valuetSg
ySS_
ySS_
ySbG
ySSSgG
ySJG
SDySSSDySSSaySDySSSdGGGG
SgXw
y_SbG
y_SSSgG
y_SfSgG
y_SdSgG
xypcSg
SgXw
SayxG
SaySaySiGG
So8NSBundleC
SgXw
Sbz_Xx
SgXwz_Xx
14SiriTTSService22DaemonDelegateProtocol_pSgXw
SaySDyS2SGG
SDySSSaySDySSypGGG
SDySSSay
SDySSSDyS2SGG
yXlG
ySS_SDyS2SGtG
ySSSay
ySSSiG
ySSSgcG
ySd_S2itcG
ySo12TTSAssetTypeCSay
_pGG
ySSSaySo8TTSAssetCGG
_pSg
SgXw
ySS_So8NSObjectCtG
$s14SiriTTSService22CoreAnalyticsInterfaceP
ypIegn_Sg
SfIegy_Sg
XDXMT
_yptG
SaySo14TTSAssetSourceCG
SgXw
Sgz_Xx
XDXMT
Gz_Xx
_pSg
GSo13OS_xpc_object_pSbIgygd_
SayypG
So29AVQueuedSampleBufferRendering_p
So7NSErrorCSg
So27AVSampleBufferAudioRendererC
So32AVSampleBufferRenderSynchronizerC
So21OS_dispatch_semaphoreCSg
SnySiG
_pSgcSg
SgXw
SbIegy_
ySS_Sf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7lettersttG
SDySSSf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7letterstG
So20NSTextCheckingResultCSg
GIggyy_
SaySny
SgXw
_pSg
So29SiriTTSAudibleRequestProtocol_
So29SiriTTSAudibleRequestProtocol_
XcSg
So22SiriTTSSynthesisEngineC
Gz_Xx
z_Xx
XDXMT
So29SiriTTSSynthesisEngineRequestC
SS3key_yp5valuet
So14NSUserDefaultsC
$sSt
$sST
So12NSFileHandleC
ySnySiGG
ypGSg
3key_yp5valuetSg
SaySsG
$s14SiriTTSService21OspreyConfigProvidingP
SaySSGSg
So15NSXPCConnectionC
14SiriTTSService14DaemonProtocol_p
IeyB_
_pIegg_
SDyS2SGSg
S2fIegyy_
_pSgIegyg_
SSSg
_pSgIeggg_
GIegg_
GIegg_
_pSgIeggg_
yycSg
$s14SiriTTSService22AudibleRequestProtocolP
ySay
GcSg
$s14SiriTTSService27SynthesizingRequestProtocolP
So7NSErrorCSgIeyByy_
IeyBy_
SgSo7NSErrorCSgIeyByy_
So7NSArrayCIeyBy_
So7NSErrorCSgIeyBy_
So8NSStringCSgSo7NSErrorCSgIeyByy_
SdSo7NSErrorCSgIeyByy_
S2fIeyByy_
IeyBy_
IeyBy_
ytIegnr_
Iegg_
GytIegnr_
GIegg_
ytIegnr_
Iegg_
ytIegr_
yyXlXpG
So7NSArrayCm
SDySo8NSStringCABG
SgXw
SgXw
So26SiriAnalyticsMessageStream_p
So14SPIPowerLoggerCSg
_SStG
_SSt
SDySSSaySo8TTSAssetCGG
SaySo12TTSAssetTypeCG
RawValue
audioSessionNotFound
avsbarNotInstantiated
playbackStalled
audioRouteName
isBluetoothRoute
isAppleProduct
vendorID
productID
volume
asbd
audioData
packetCount
packetDescriptions
audioInterface
audioOperationQueue
playbackError
audioSequence
averagePower
peakPower
discontinuedDuringPlayback
outputRouteInfo
audioQueue
startTime
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
expectedPlaySampleTime
callback
_rawValue
_os_unfair_lock_opaque
mSampleTime
mHostTime
mRateScalar
mWordClockTime
mSMPTETime
mFlags
mReserved
value
timescale
flags
epoch
location
length
mSampleRate
mFormatID
mFormatFlags
mBytesPerPacket
mFramesPerPacket
mBytesPerFrame
mChannelsPerFrame
mBitsPerChannel
_ObjectiveCType
mSubframes
mSubframeDivisor
mCounter
mType
mHours
mMinutes
mSeconds
mFrames
rawValue
mStartOffset
mVariableFramesInPacket
mDataByteSize
notificationCenter
observers
requestId
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
utterance
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
RawValue
cacheStorage
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
synthesizerID
voiceID
name
localizedNames
nameRoot
identifier
gender
demo
language
locale
version
scriptCode
voiceGroup
voiceType
desirability
supportedCharacters
individuallySpokenCharacters
diskSize
description
RawValue
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
storage
streamingHandlers
signals
lock
queue
lock
_activeSessionCount
_cachedEngine
notificationCenter
observers
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
lock
value
lowInactiveMemory
grpcChannel
speechId
factorName
assetAttr
path
isDownloading
downloadToken
progressQueue
notification
engineCachingService
use_trial
enable_adhoc_voice
sirix
audioPlaybackStarted
synthesisStarted
synthesisEnded
requestReceived
audioGenerated
wordTimingGenerated
phonemesGenerated
voiceSelected
engineSelectEnd
voiceResourceSelected
encounteredError
encounteredIssue
audioPowerProviderAvailable
instrumentationMetricsAvailable
cancellationRequested
eagerRequestDetected
audioPlaybackStarting
audioPlaybackEnded
voiceSelectStart
engineSelectStart
receivedServerFirstPacket
receivedServerLastPacket
synthesisEngineChanged
synthesisUsedPrompt
neuralAlignmentStall
neuralAudioClick
neuralFallback
taskCompletion
registry
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
message
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
attributes
cookie
bundle
authTokens
quality
downloading
RawValue
stagingURL
inKey
wantValue
text
source
name
firstMinor
voice
resource
AllCases
RawValue
graph
errorHandlers
_isCancelled
cancellationLock
notification
idContainer
buffer
bufferCondition
isProcessing
asyncError
waitTimeout
isProcessingCondition
action
conditional
asyncContext
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
internalSettings
notificationCenter
observers
canDumpAudio
fromFormat
toFormat
converter
buffer
cookie
assetQuality
bundlePath
authorizedBundle
proxy_attr
engineCachingService
notification
constructorRegistry
objectPool
asset
name
gender
quality
storageURL
notificationCenter
observers
audioPowerProvider
encoder
_disableTTS
_enableDiagnostic
_logSensitiveText
_disableCache
_overrideRequestsText
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
defaults
stringKey
defaultValue
transform
asyncContext
streamingStorage
notificationCenter
observers
internalSettings
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
RawValue
code
description
success
unknown
crash
cancelled
noVoice
invalidVoice
lowSynthesisRTF
compactNeural
audioUnknownError
audioDiscontinuity
ospreyUnknownError
ospreyNetworkTimeout
ospreyNetworkStall
ospreyInvalidAudioFormat
inlineStreamUnknownError
inlineStreamNetworkStall
inlineStreamTimeout
nodes
edges
settings
asset
attr
assetAttr
RawValue
AllCases
heySiriCapabilities
heySiriClock
heySiriClockPlankTimer
heySiriHome
heySiriMusic
heySiriNews
heySiriWeather
heySiriWeather2
siriCapabilities
siriCapabilityClock
siriCapabilityHome
siriCapabilityMusic
siriCapabilityNews
siriCapabilityWeather
siriIntro
trySay0
trySay1
notificationCenter
observers
delegate
request
audioFile
packetOffset
asyncContext
queue
settings
entitlements
diagnosticAudioFile
synthesizedAudioFile
diagnosticTag
supportedLanguages
name
identifier
assistantGender
assistantOrder
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
notificationCenter
observers
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
voice
path
resource
allowExpensiveData
allowDiscretionary
downloadQueue
notificationCenter
observers
asyncContext
internalSettings
ospreyClient
ospreyConfig
timeout
cacheStorage
streamingStartedDate
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
notification
internalSettings
buffer
notificationCenter
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
asbd
discontinuedDuringPlayback
audioPowerProvider
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
paused
started
waitForFinish
stopped
RawValue
timeoutDate
waitCondition
queue
shouldStop
phonemes
estimationDictionary
alphabet
phoneme
asyncContext
buffer
audioPlayback
audibleRequest
notificationCenter
observers
asyncContext
queue
notificationCenter
observers
internalSettings
synthesisConfig
_isCancelled
defaults
fromFormat
toFormat
converter
buffer
Element
Iterator
storageURL
fileURL
handle
voice
resource
audio
timingInfos
magicVersion
RawValue
asset
$__lazy_storage_$_voiceDesc
storageURL
timeout
deviceWaitTime
allowedAppIdentifiers
configs
delegate
connection
weakDelegate
asyncProxy
syncProxy
RawValue
startTime
textRange
utterance
voice
resource
audioOutputRoute
clientBundleIdentifier
experimentIdentifier
requestCreatedTime
eagerRequestGapInterval
synthesisBeginTime
synthesisEndTime
speechBeginTime
speechEndTime
speechEstimatedOutputBeginTime
audioStartLatency
serverFirstPacketTime
serverLastPacketTime
serverStreamedAudioDuration
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
isServerTTSRacing
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
audioSessionId
immediate
siriRequestId
didStartSpeaking
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
text
contextInfo
rate
pitch
volume
customResourceURLs
synthesisProfile
disableCompactVoice
didGenerateAudio
didGenerateWordTimings
whisper
prosodyProperties
forceOspreyTTS
clientBundleId
accessoryId
outputPath
didReportInstrument
audio
audibleContext
synthesisContext
phonemeSystem
language
name
footprint
type
gender
version
clientId
identifier
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
asyncContext
notificationCenter
observers
ospreyClient
notificationCenter
observers
ttsId
requestId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
sources
assetTypes
SiriTTSPhonemeTool
SiriTTSSynthesisEngineResource
SiriTTSSynthesisEngineWordTimings
SiriTTSSynthesisEngineRequest
SiriTTSSynthesisEngine
SiriTTSNeuralUtils
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequestProsodyControlConfig
OPTTSMutableTTSWordPhonemes
OPTTSMutableTTSPhonemeSequence
OPTTSMutableTTSNeuralPhonemeSequence
OPTTSMutableTTSPrompts
OPTTSMutableTTSReplacement
OPTTSMutableTTSNormalizedText
OPTTSMutableTextToSpeechFeature
OPTTSMutableTextToSpeechRequestDebug
OPTTSMutableTextToSpeechVoiceResource
OPTTSMutableTextToSpeechUserProfile
OPTTSMutableTextToSpeechRequestDevConfig
OPTTSMutableTextToSpeechSpeechFeatureInputWave
OPTTSMutableTextToSpeechUserVoiceProfile
OPTTSMutableTextToSpeechRequestProsodyTransferConfig
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequestProsodyControlConfig
OPTTSTTSWordPhonemes
OPTTSTTSPhonemeSequence
OPTTSTTSNeuralPhonemeSequence
OPTTSTTSPrompts
OPTTSTTSReplacement
OPTTSTTSNormalizedText
OPTTSTextToSpeechFeature
OPTTSTextToSpeechRequestDebug
OPTTSTextToSpeechVoiceResource
OPTTSTextToSpeechUserProfile
OPTTSTextToSpeechRequestDevConfig
OPTTSTextToSpeechSpeechFeatureInputWave
OPTTSTextToSpeechUserVoiceProfile
OPTTSTextToSpeechRequestProsodyTransferConfig
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
SiriTTSService_Bridge
SiriTTSOspreyRequest
OspreyBridge
SiriTTSOspreyStreamingBeginResponse
SiriTTSOspreyWordTimingInfo
SiriTTSOspreyStreamingPartialResponse
SiriTTSOspreyChannel
SiriTTSService_TTSAXResource
SiriTTSService_TTSAXResourceManager
SiriTTSAudioHardware
TTSAsset
TTSStringEnum
TTSAssetQuality
TTSAssetServer
TTSAssetSource
TTSAssetTechnology
TTSAssetType
SwiftProxy
OS_xpc_object
AVQueuedSampleBufferRendering
NSSecureCoding
NSObject
TRINotificationToken
SiriAnalyticsMessageStream
NSCoding
NSXMLParserDelegate
T@"NSArray",C,N
.cxx_destruct
T@"NSString",C,N,V_experimentId
T#,R
T@"SiriTTSAudibleContext",&,D,N
T@"NSArray",R,N,V_supportedLanguages
Tf,N,V_neuralSentencePitchRange
T@"NSBundle",R,N,V_bundle
Tq,R,V_vendorId
T@"NSData",R,N
_bundle
T@"NSDictionary",R,N,V_attributes
_handle
T@"NSNumber",R,N,V_age
_string
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
_volume
T@"NSString",&,N,V_language
assistantGender
T@"NSString",&,N,V_name
bundleForClass:
T@"NSString",&,N,V_tag
cancelDownload:
T@"NSString",C,N
compact
T@"NSString",C,N,V_language
content_typeForImmutableObject:
T@"NSString",C,N,V_text
dealloc
T@"NSString",R,C
fe_feature_only
T@"NSString",R,N,V_identifier
fileHandleForUpdatingURL:error:
T@"NSString",R,N,V_primaryLanguage
getLocalFileUrl
T@"NSString",R,N,V_string
hasPath
T@"NSString",R,N,V_voiceFootprint
initWithNSUUID:
T@"NSString",R,N,V_voiceLanguage
isProxy
T@"NSString",R,N,V_voicePath
normalized_text
T@"NSString",R,V_routeType
opaqueSessionID
T@"OPTTSAudioDescription",R,N
phoneme_sequence_objectAtIndex:
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
primaryLanguage
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
prompts
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
refresh
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
release
T@"OPTTSTTSRequestFeatureFlags",R,N
resourceVersion
T@"OPTTSTextToSpeechFeature",R,N
results
T@"OPTTSTextToSpeechMeta",R,N
setContextInfo:
T@"OPTTSTextToSpeechRequestContext",R,N
setEnergy_mean:
T@"OPTTSTextToSpeechRequestDebug",R,N
setGlobal_rate:
T@"OPTTSTextToSpeechRequestDevConfig",R,N
setIsWarmStart:
T@"OPTTSTextToSpeechRequestExperiment",R,N
setPacketCount:
T@"OPTTSTextToSpeechRequestMeta",R,N
setReplacement:
T@"OPTTSTextToSpeechRequestProsodyControlConfig",R,N
setServerStreamedAudioDuration:
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",R,N
setSynthesizer:
T@"OPTTSTextToSpeechResource",R,N
setVoiceAccent:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",R,N
speechBeginTime
T@"OPTTSTextToSpeechUserProfile",R,N
T@"OPTTSTextToSpeechUserVoiceProfile",R,N
unloadResource:
T@"OPTTSTextToSpeechVoice",R,N
version
T@"SiriTTSService_TTSAXResourceManager",R,N
word_timing_info_objectAtIndex:
.cxx_construct
T@"NSArray",R,N
NewAssetNotification
T@"NSString",R,N,V_resourcePath
T@"NSArray",&,N,V_allCompactResources
T@?,C,N,V_neuralFallbackHandler
T@"NSArray",R,N,V_timingInfos
Tq,R,N,V_gender
T@"NSData",C,N
_bufferDuration
T@"NSData",R,N,V_audioData
_gender
T@"NSLock",&,N,V_lock
_isAppleProduct
T@"NSNumber",R,N,V_diskSize
_voiceFootprint
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
T@"NSString",&,N,V_mimeType
audioBufferList
T@"NSString",&,N,V_path
bytes_per_frame
T@"NSString",&,N,V_text
captureSnapshot
T@"NSString",C,N,V_appId
content
T@"NSString",C,N,V_speechId
context
T@"NSString",C,N,V_voiceName
downloadedVoicesMatching:reply:
T@"NSString",R,N
feature
T@"NSString",R,N,V_name
framesPerPacket
T@"NSString",R,N,V_resourceLanguage
gryphon
T@"NSString",R,N,V_versionDescription
initWithDouble:
T@"NSString",R,N,V_voiceGender
initWithString:
T@"NSString",R,N,V_voiceName
T@"NSString",R,N,V_voiceType
T@"OPTTSAudioDescription",C,N
parser:validationErrorOccurred:
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
premium
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
profile
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
quality
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
relatedAssetsWithOnlyAvailable:
T@"OPTTSTTSRequestFeatureFlags",C,N
removeObserver:
T@"OPTTSTextToSpeechFeature",C,N
resources_count
T@"OPTTSTextToSpeechMeta",C,N
setAccessoryId:
T@"OPTTSTextToSpeechRequestContext",C,N
setDoNotBlockBeforeFirstUnlock:
T@"OPTTSTextToSpeechRequestDebug",C,N
setFrameLength:
T@"OPTTSTextToSpeechRequestDevConfig",C,N
setGrpcChannel:
T@"OPTTSTextToSpeechRequestExperiment",C,N
setKey:
T@"OPTTSTextToSpeechRequestMeta",C,N
setPromptCount:
T@"OPTTSTextToSpeechRequestProsodyControlConfig",C,N
setSample_rate:
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",C,N
setSourceOfTTS:
T@"OPTTSTextToSpeechResource",C,N
setTag:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",C,N
setVoiceGender:
T@"OPTTSTextToSpeechUserProfile",C,N
staging
T@"OPTTSTextToSpeechUserVoiceProfile",C,N
textToPhonemeWithRequest:reply:
T@"OPTTSTextToSpeechVoice",C,N
valueWithRange:
T@"OspreyChannel",&,N,V_grpcChannel
whisper
T@"SiriTTSSynthesisContext",&,D,N
T@"TTSAXResourceManager",&,N,V_axManager
T@"TTSAssetQuality",R,N,V_quality
T@"TTSAssetSource",R,N,V_assetSource
T@"TTSAssetTechnology",R,N,V_technology
T@"TTSAssetType",R,N,V_assetType
T@?,C,N,V_audioHandler
T@?,C,N,V_promptHandler
T@?,C,N,V_wordTimingsHandler
TB,N
TB,N,V_privacySensitive
TB,N,V_serverLogs
TB,R
TB,R,GisReadyForMoreMediaData
TB,R,N
TB,R,V_isAppleProduct
TB,R,V_isBluetooth
TI,N
TI,R,N
TQ,N,V_profile
TQ,N,V_requestCreatedTime
TQ,R
T^v,N,V_synthesizer
T^{OpaqueCMTimebase=},R,&
Td,N
Td,N,V_startTime
Td,N,V_timestamp
Td,R,N
Td,R,N,V_bufferDuration
Tf,N
Tf,N,V_neuralSentenceDuration
Tf,N,V_neuralSentenceEnergy
Tf,N,V_neuralSentencePitch
Tf,N,V_neuralSentenceTilt
Tf,N,V_pitch
Tf,N,V_rate
Tf,N,V_volume
Tf,R,N
Tf,R,V_volume
Ti,N
Ti,R,N
Tq,N
Tq,R,N
Tq,R,N,V_resourceVersion
Tq,R,N,V_versionNumber
Tq,R,N,V_voiceVersion
Tq,R,V_productId
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{_NSRange=QQ},N,V_textRange
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_handle
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLForResource:withExtension:subdirectory:
URLsForDirectory:inDomains:
UTF8String
UUID
UUIDString
__swift_objectForKeyedSubscript:
_age
_allCompactResources
_appId
_asbd
_assetSource
_assetType
_attributes
_audioData
_audioHandler
_axManager
_data
_diskSize
_experimentId
_grpcChannel
_gryphonVoiceCompatibility
_hasTrialEntitlements
_identifier
_isBluetooth
_language
_lock
_mimeType
_name
_neuralFallbackHandler
_neuralSentenceDuration
_neuralSentenceEnergy
_neuralSentencePitch
_neuralSentencePitchRange
_neuralSentenceTilt
_path
_pitch
_postNewAssetNotification
_preheatWithError:
_primaryLanguage
_privacySensitive
_productId
_profile
_promptHandler
_quality
_rate
_requestCreatedTime
_resourceLanguage
_resourcePath
_resourceVersion
_root
_routeType
_serverLogs
_speechId
_startTime
_storage
_supportedLanguages
_synthesizer
_tag
_technology
_text
_textRange
_timestamp
_timingInfos
_unlockedLoadResourceWithPath:error:
_unlockedStopSynthesis
_unlockedSynthesize:error:
_unlockedUnloadResource:
_vendorId
_versionDescription
_versionNumber
_voiceGender
_voiceLanguage
_voiceName
_voicePath
_voiceType
_voiceVersion
_wordTimingsHandler
accessoryId
addBoundaryTimeObserverForTimes:queue:usingBlock:
addKeyValueArray:with:
addObject:
addObjectToBuffer:
addObserver:selector:name:object:
addObserverForName:object:queue:usingBlock:
addRenderer:
addUpdateHandlerForNamespaceName:queue:usingBlock:
adhoc
allCompactResources
allocWithZone:
appId
app_id
archivedDataWithRootObject:requiringSecureCoding:error:
array
asbd
assetSource
assetType
assistantOrder
assistantVoiceMaps
attachProgressCallBack:
attributes
audibleContext
audio
audio:
audioData
audioDuration
audioHandler
audioInfo
audioInterface
audioOutputRoute
audioSession
audioSessionId
audioStartLatency
audioStreamBasicDescription
audio_type
autorelease
availableLanguages
axManager
barrierWithCompletion:
bestAssetOfTypes:matching:
beta
bitsPerChannel
bits_per_channel
boolForKey:
boolValue
broadcast
bufferDuration
bundle
bundleIdentifier
bundlePath
bundleURL
bundleWithIdentifier:
bytes
bytesPerFrame
bytesPerPacket
bytes_per_packet
cancelDownloadingThen:
cancelWithRequest:
channel_type
channelsPerFrame
channels_per_frame
class
clientBundleIdentifier
clientId
clientWithIdentifier:
closeAndReturnError:
closeFile
combinedVoice
compileANEModel:error:
componentsJoinedByString:
conformsToProtocol:
contentAsOPTTSBeginTextToSpeechStreamingResponse
contentAsOPTTSFinalTextToSpeechStreamingResponse
contentAsOPTTSPartialTextToSpeechStreamingResponse
contentAsOPTTSStartTextToSpeechStreamingRequest
contentPath
contentVersion
content_immutableClassForType:
content_mutableClassForType:
content_type
content_typeForMutableObject:
content_typeForObject:
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextInfo
context_info
context_info_count
context_info_enumerateObjectsUsingBlock:
context_info_objectAtIndex:
convertLanguageCodeToSchemaLocale:
convertToBuffer:error:withInputFromBlock:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createFileAtPath:contents:attributes:
currentTime
current_pkt_number
custom
customResourceURLs
customVoice
data
data:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
debug
debugDescription
decodeBoolForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntegerForKey:
decodeObjectForKey:
decoderStreamDescription
decoder_description
defaultCenter
defaultManager
defaultOutput
defaultSessionConfiguration
deprecatedVoicesMap
derivedIdentifierForComponentName:fromSourceIdentifier:
describeServer:forType:
describeServer:source:
description
dev_config
dialog_identifier
dictionary
dictionaryForKey:
dictionaryWithObjects:forKeys:count:
didGenerateAudio
didGenerateAudioWithRequestId:audio:
didGenerateWordTimings
didGenerateWordTimingsWithRequestId:wordTimingInfo:
didReportInstrument
didReportInstrumentWithRequestId:instrumentationMetrics:
didStartSpeaking
didStartSpeakingWithRequestId:
directoryValue
disableCompactVoice
disable_cache
diskSize
doubleValue
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
downloadWithReservation:useBattery:progress:then:
downloading
duration_mean
duration_std
eagerRequestGapInterval
emitMessage:
emitMessage:timestamp:
enable_word_timing_info
encodeBool:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeWithCoder:
energy_mean
energy_std
enqueueLargeMessageObjectFromPath:assetIdentifier:messageMetadata:completion:
enqueueSampleBuffer:
enumerateMatchesInString:options:range:usingBlock:
enumerateObjectsUsingBlock:
errorCode
errorMessage
errorWithDomain:code:userInfo:
error_code
error_str
estimateDurationWithRequest:didFinish:
estimateDurationWithRequest:reply:
eventMetadata
expectedTimeRemaining
experiment
experimentId
experimentIdentifier
experiment_identifier
factor
factorLevelsWithNamespaceName:
fallbackLanguageFor:
fe_feature
feature_flags
fetchHardwareInfo
fileDescriptor
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
flatbuffData
floatForKey:
floatValue
flush
footprint
forceOspreyTTS
force_use_tts_service
formatFlags
formatID
format_flags
format_id
forwardWithStreamObject:
frameLength
frames_per_packet
gender
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAudioPower:
getAudioPowerWithAccessoryId:reply:
getBytes:length:
getServerForType:
getServerForType:source:
getSynthesisVoiceMatching:reply:
global_energy
global_pitch
global_rate
global_sent_duration
global_sent_energy
global_sent_pitch
global_sent_pitchrange
global_sent_tilt
globallyUniqueString
grpcChannel
gryphonVoice
handle
handleMediaServerReset
handleProxyEvent:reply:connection:
hasAMX
hasANE
hasAsset
hasPhaticResponsesWithVoicePath:
hasSufficientMediaDataForReliablePlaybackStart
hash
homepodSetupStringWithKey:language:
identifier
identifiersForVoicesMap
immediate
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
infoDictionary
init
initAndVerifyWithFlatbuffData:
initFromFormat:toFormat:
initWithAccessoryId:
initWithArray:
initWithAudio:
initWithBool:
initWithBytes:length:encoding:
initWithBytesNoCopy:length:deallocator:
initWithCoder:
initWithContentsOfFile:
initWithContentsOfURL:
initWithContentsOfURL:options:error:
initWithCurrentProcess
initWithData:
initWithDomain:code:userInfo:
initWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
initWithFloat:
initWithFormat:packetCapacity:maximumPacketSize:
initWithInt:
initWithInteger:
initWithLanguage:
initWithLanguage:name:
initWithMachServiceName:options:
initWithOspreyBeginResponse:
initWithOspreyPartialResponse:
initWithPCMFormat:frameCapacity:
initWithPath:
initWithPattern:options:error:
initWithStartTiming:textRange:
initWithStreamDescription:
initWithSuiteName:
initWithText:identifier:
initWithText:voice:
initWithText:voice:phonemeSystem:
initWithType:
initWithURL:
initWithURL:configuration:
initWithUUIDBytes:
initWithUnsignedInteger:
initWithVoice:clientId:accessoryId:
initWithVoicePath:resourcePath:error:
initializeDeviceAuthenticationSessionWithCompletion:
intValue
integerForKey:
integerValue
interfaceWithProtocol:
invalidate
isANEModelCompiled:
isANEModelCompiledMatching:reply:
isANEOnly
isAppleProduct
isAudibleRequest
isBluetooth
isCatalogFetchedWithinThePastFewDays:
isCustom
isDeletableFileAtPath:
isEqual:
isH12Platform
isInstalled
isKindOfClass:
isLowPowerModeEnabled
isMemberOfClass:
isNeuralPlatform
isNeuralVoiceReady:
isNewer:
isOlder:
isReadyForMoreMediaData
isServerTTSRacing
isSpeaking:
isSpeakingWithAccessoryId:reply:
isWarmStart
keepActive
keepActive:reply:
killDaemon
language
languageCode
legacyAssetWithBundle:
length
level
levelForFactor:withNamespaceName:
linkId
listAssetsOfTypes:matching:
livability
loadResourceWithPath:error:
localizedDescription
locallyAvailable
lock
logWithEventContext:ttsIdentifier:
loggerForCurrentProcess
macintalk
macintalkVoice
macosLegacy
mainBundle
maximumOutputPacketSize
meta_info
metadata
mimeType
mobileAsset
mutableAudioBufferList
name
neural
neuralAX
neuralAlignmentStall
neuralAudioClick
neuralFallback
neuralFallbackHandler
neuralSentenceDuration
neuralSentenceEnergy
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceTilt
neural_phoneme_sequence
neural_phoneme_sequence_count
neural_phoneme_sequence_enumerateObjectsUsingBlock:
neural_phoneme_sequence_objectAtIndex:
normalized_text_count
normalized_text_enumerateObjectsUsingBlock:
normalized_text_objectAtIndex:
numberOfMatchesInString:options:range:
objectAtIndexedSubscript:
objectForInfoDictionaryKey:
objectForKey:
objectForKeyedSubscript:
offset
operatingSystemVersion
original
outputPath
packetCount
packetDescriptions
parse
parser:didEndElement:namespaceURI:qualifiedName:
parser:didEndMappingPrefix:
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didStartMappingPrefix:toURI:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundCDATA:
parser:foundCharacters:
parser:foundComment:
parser:foundElementDeclarationWithName:model:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:foundIgnorableWhitespace:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundProcessingInstructionWithTarget:data:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:parseErrorOccurred:
parser:resolveExternalEntityName:systemID:
parserDidEndDocument:
parserDidStartDocument:
path
pathComponent
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pcm_data
pcm_data:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phonemeSystem
phoneme_sequence
phoneme_sequence_count
phoneme_sequence_enumerateObjectsUsingBlock:
phonemes
phonemes_count
phonemes_enumerateObjectsUsingBlock:
phonemes_objectAtIndex:
pingWithReply:
pitch
pitch_mean
pitch_std
playback_description
postNotificationName:object:
preconnect
preferred_voice_type
preheatWithError:
preinstalled
premiumhigh
prewarmWithRequest:didFinish:
prewarmWithRequest:reply:
privacySensitive
processInfo
processServerLogs:
productId
production
promptCount
promptHandler
prompts_count
prompts_enumerateObjectsUsingBlock:
prompts_objectAtIndex:
prompts_v2
prompts_v2:
prosodyProperties
prosody_config
prosody_control_config
purge
purgeImmediately:
purgeSync
purgeable
queryMetaDataSync
queryPhaticCapabilityWithVoice:reply:
rangeAtIndex:
rangeValue
rate
readDataOfLength:
readyForMoreMediaData
refreshState
relativeOrderForVoicesMap
relativePitchOrderForVoicesMap
remoteObjectProxyWithErrorHandler:
removeDownloadStatusHandlersWithToken:
removeItemAtPath:error:
removeItemAtURL:error:
removeLevelsForFactors:withNamespace:queue:completion:
removeLevelsForFactorsImmediately:withNamespace:queue:completion:
removeObjectForKey:
removeTimeObserver:
renderers
replacement
replacement_count
replacement_enumerateObjectsUsingBlock:
replacement_objectAtIndex:
requestCreatedTime
requestMediaDataWhenReadyOnQueue:usingBlock:
requestedVoiceContext
reserved
reset
resolvePartialMessage:
resolvePartialMessage:timestamp:
resource
resourceLanguage
resourcePath
resourceURL
resource_asset_path
resources
resourcesWithType:subType:
resources_enumerateObjectsUsingBlock:
resources_objectAtIndex:
respondsToSelector:
resume
retain
retainCount
retrieveSessionWithID:
returnTypes:
return_log
return_server_info
rolloutIdentifiersWithNamespaceName:
roughEstimationWithRequest:
routeType
sampleRate
sample_idx
sample_rate
seekToOffset:error:
self
serverFirstPacketTime
serverLastPacketTime
serverLogs
serverStreamedAudioDuration
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
session_id
setAllCompactResources:
setAllowsCellularAccess:
setAllowsExpensiveAccess:
setAppId:
setApp_id:
setAsbd:
setAudibleContext:
setAudio:
setAudioData:
setAudioDuration:
setAudioHandler:
setAudioInterface:
setAudioOutputRoute:
setAudioSession:
setAudioSessionId:
setAudioStartLatency:
setAudio_type:
setAxManager:
setBits_per_channel:
setByteLength:
setBytes_per_frame:
setBytes_per_packet:
setCancelled:
setChannel_type:
setChannels_per_frame:
setClasses:forSelector:argumentIndex:ofReply:
setClientBundleIdentifier:
setClientId:
setClientTraceIdentifier:
setComponent:
setContent:
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContent_type:
setContext:
setContextId:
setContext_info:
setCurrent_pkt_number:
setCustomResourceURLs:
setCustomerPerceivedLatencyInSecond:
setData:
setDebug:
setDecoder_description:
setDelaysRateChangeUntilHasSufficientMediaData:
setDelegate:
setDev_config:
setDialog_identifier:
setDidGenerateAudio:
setDidGenerateWordTimings:
setDidReportInstrument:
setDidStartSpeaking:
setDisableCompactVoice:
setDisable_cache:
setDiscretionary:
setDiscretionaryBehavior:
setDoNotBlockOnNetworkStatus:
setDuration_mean:
setDuration_std:
setEagerRequestGapInterval:
setEnable_word_timing_info:
setEnded:
setEnergy_std:
setErrorCode:
setErrorCodes:
setError_code:
setError_str:
setEventMetadata:
setExists:
setExperiment:
setExperimentId:
setExperimentIdentifier:
setExperiment_identifier:
setExportedInterface:
setExportedObject:
setFailed:
setFe_feature:
setFe_feature_only:
setFeature:
setFeature_flags:
setFootprint:
setForceOspreyTTS:
setForce_use_tts_service:
setFormat_flags:
setFormat_id:
setFrames_per_packet:
setGender:
setGlobal_energy:
setGlobal_pitch:
setGlobal_sent_duration:
setGlobal_sent_energy:
setGlobal_sent_pitch:
setGlobal_sent_pitchrange:
setGlobal_sent_tilt:
setHandle:
setImmediate:
setInputTextLength:
setInterruptionHandler:
setInvalidationHandler:
setIsAudibleRequest:
setIsServerTTSRacing:
setKeepActive:
setLanguage:
setLength:
setLinkId:
setLock:
setMeta_info:
setMimeType:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralFallback:
setNeuralFallbackHandler:
setNeuralSentenceDuration:
setNeuralSentenceEnergy:
setNeuralSentencePitch:
setNeuralSentencePitchRange:
setNeuralSentenceTilt:
setNeural_phoneme_sequence:
setNormalized_text:
setObject:forKey:
setObject:forKeyedSubscript:
setOffset:
setOriginal:
setOutputPath:
setPacketDescriptions:
setPath:
setPcm_data:
setPhonemeSystem:
setPhoneme_sequence:
setPhonemes:
setPitch:
setPitch_mean:
setPitch_std:
setPlayback_description:
setPreferred_voice_type:
setPrivacySensitive:
setProductId:
setProfile:
setPromptHandler:
setPrompts:
setPrompts_v2:
setProsodyProperties:
setProsody_config:
setProsody_control_config:
setQuality:
setRate:
setRate:time:
setRemoteObjectInterface:
setRequestCreatedTime:
setRequestId:
setRequestReceived:
setRequestReceivedTier1:
setRequestedVoiceContext:
setRequiresPowerPluggedIn:
setReserved:
setResource:
setResourceVersion:
setResource_asset_path:
setResources:
setReturn_log:
setReturn_server_info:
setSample_idx:
setServer:forType:
setServer:forType:source:
setServerFirstPacketTime:
setServerLastPacketTime:
setServerLogs:
setSession_id:
setSiriRequestId:
setSource:
setSpeechBeginTime:
setSpeechContext:
setSpeechEndTime:
setSpeechEstimatedOutputBeginTime:
setSpeechId:
setSpeech_id:
setStartTime:
setStartedOrChanged:
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setSupportsSecureCoding:
setSynthesisBeginTime:
setSynthesisContext:
setSynthesisEffect:
setSynthesisEndTime:
setSynthesisLatencyInSecond:
setSynthesisProfile:
setSynthesisRealTimeFactor:
setSynthesisSource:
setSynthesizedAudioDurationInSecond:
setTarget:
setText:
setTextRange:
setTextToSynthesize:
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
setTimestamp:
setTotal_pkt_number:
setTtsId:
setType:
setUseCompression:
setUser_voice_profile:
setUser_voice_profile_url:
setUtterance:
setUuid:
setValue:
setVendorId:
setVersion:
setVoice:
setVoiceContext:
setVoiceFallbackOccurred:
setVoiceFootprint:
setVoiceName:
setVoiceSettings:
setVoiceType:
setVoiceVersion:
setVoice_asset_path:
setVoice_name:
setVolume:
setWave_data:
setWhisper:
setWord:
setWordTimingsHandler:
setWord_phonemes:
setWord_timing_info:
sharedInstance
sharedStream
shouldUseNeuralVoice:
signal
signalWithInlineStreaming:
siriRequestId
sleepForTimeInterval:
sourceOfTTS
speakWithAudioRequest:didFinish:
speakWithAudioRequest:reply:
speakWithSpeechRequest:didFinish:
speakWithSpeechRequest:reply:
speechEndTime
speechEstimatedOutputBeginTime
speechId
speechSynthesisResource
speechSynthesisVoice
speech_id
startCatalogDownload:options:then:
startDownload:then:
startTime
state
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
stopRequestingMediaData
stopSynthesis
streamDescription
streamId
streamTTS:beginHandler:chunkHandler:completion:
stream_id
streamingPlaybackBufferSize
streaming_playback_buffer_size_in_seconds
string
stringByReplacingOccurrencesOfString:withString:
stringForKey:
stringWithFormat:
stringWithUTF8String:
subscribeWithVoices:clientId:accessoryId:reply:
subscribeWithVoices:reply:
subscribedVoicesWithClientId:reply:
subscribedVoicesWithReply:
superclass
supportedLanguages
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
synthesisBeginTime
synthesisContext
synthesisEndTime
synthesisProfile
synthesize:error:
synthesizeWithRequest:didFinish:
synthesizeWithRequest:reply:
synthesizer
technology
temporaryDirectory
text
textRange
textToPhonemeWithRequest:didFinish:
thermalState
timebase
timestamp
timingInfos
totalExpected
totalWritten
total_pkt_number
turiTrial
type
underlyingRequest
unlock
unsignedIntValue
unsignedIntegerValue
user_voice_profile
user_voice_profile_url
utterance
value
valueForEntitlement:
valueWithCMTime:
vendorId
versionDescription
versionNumber
vocalizer
vocalizerVoice
voice
voiceAssetKey
voiceContext
voiceFootprint
voiceGender
voiceLanguage
voiceName
voicePath
voiceResourceAssetKey
voiceResources
voiceSettings
voiceType
voiceVersion
voice_asset_path
voice_name
voicesForLanguageMap
volume
wait
waitForCatalogUpdates
waitUntilDate:
wasLocal
wave_data
word
wordTimingInfoList
wordTimingsHandler
word_phonemes
word_phonemes_count
word_phonemes_enumerateObjectsUsingBlock:
word_phonemes_objectAtIndex:
word_timing_info
word_timing_info_count
word_timing_info_enumerateObjectsUsingBlock:
zone
@48@0:8@16@24q32^@40
@16@0:8
v24@0:8@16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
v16@0:8
@"NSString"
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
B16@0:8
v20@0:8B16
f16@0:8
v20@0:8f16
Q16@0:8
v24@0:8Q16
@?16@0:8
v24@0:8@?16
B24@0:8@16
@40@0:8@16@24^@32
B32@0:8@16^@24
B24@0:8^@16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^v16@0:8
v24@0:8^v16
@"NSLock"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8q16
i16@0:8
v20@0:8i16
I16@0:8
v20@0:8I16
#24@0:8q16
q24@0:8@16
@"NSData"16@0:8
@24@0:8@16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
@"NSData"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
@24@0:8Q16
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@"NSArray"
@32@0:8@16@24
v48@0:8@16@?24@?32@?40
@"OspreyChannel"
@"TTSAXResourceManager"
@"TTSAssetType"
@"TTSAssetSource"
@"TTSAssetTechnology"
@"TTSAssetQuality"
@"NSNumber"
@"NSDictionary"
@"NSBundle"
v24@0:8^{opaqueCMSampleBuffer=}16
v32@0:8@16@?24
^{OpaqueCMTimebase=}16@0:8
v32@0:8@"OS_dispatch_queue"16@?<v@?>24
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16Q24
v48@0:8@16@24@32@?40
v24@0:8@"SISchemaTopLevelUnionType"16
v32@0:8@"SISchemaTopLevelUnionType"16Q24
v48@0:8@"NSString"16@"NSUUID"24@"SISchemaInstrumentationMessage"32@?<v@?B@"NSError">40
v24@0:8@?<v@?>16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
v40@0:8@16@24@32
v32@0:8@16@24
@40@0:8@16@24@32
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
Logs
SiriTTSService
ar-SA
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
en-scotland
es-AR
es-CO
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
nb-NO
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
ar-SA
da-DK
de-DE
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-CL
Hola, soy Siri.
es-ES
Hola, soy Siri.
es-MX
Hola, soy Siri.
fi-FI
fr-CA
fr-FR
he-IL
it-IT
ja-JP
ko-KR
nb-NO
nl-BE
nl-NL
pt-BR
ru-RU
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
oren
O-ren
O-ren
O-ren
limu
Li-mu
Li-mu
Li-mu
Yu-shu
Yu-shu
Sin-ji
Sin-Ji
Azul
Sydney
Star
StarBravo
SkyE
SkyEcho
speak
oren
sakura
hattori
hiro
ar-001_Maged
ar-SA
ca-ES
cs-CZ_Zuzana
cs-CZ
da-DK_Sara
da-DK
de-DE_Anna
de-DE
el-GR_Melina
el-GR
en-AU_Karen
en-AU
en-GB_Daniel
en-GB
en-IE_Moira
en-IE
en-IN_Rishi
en-IN
en-US_Samantha
en-US
en-ZA_Tessa
en-ZA
es-ES_Monica
es-ES
es-MX_Paulina
es-MX
fi-FI_Satu
fi-FI
fr-CA_Amelie
fr-CA
fr-FR_Thomas
fr-FR
he-IL_Carmit
he-IL
hi-IN_Lekha
hi-IN
hr-HR_Lana
hr-HR
hu-HU_Mariska
hu-HU
id-ID_Damayanti
id-ID
it-IT_Alice
it-IT
ja-JP_Kyoko
ja-JP
ko-KR_Yuna
ko-KR
ms-MY_Amira
ms-MY
nl-BE_Ellen
nl-BE
nl-NL_Xander
nl-NL
nb-NO_Nora
no-NO
pl-PL_Zosia
pl-PL
pt-BR_Luciana
pt-BR
pt-PT_Joana
pt-PT
ro-RO_Ioana
ro-RO
ru-RU_Milena
ru-RU
sk-SK_Laura
sk-SK
sv-SE_Alva
sv-SE
th-TH_Kanya
th-TH
tr-TR_Yelda
tr-TR
uk-UA_Lesya
uk-UA
vi-VN_Linh
vi-VN
zh-CN_Tingting
zh-CN
zh-HK_Sinji
zh-HK
zh-TW_Meijia
zh-TW
ar-SA
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
ms-MY
nb-NO
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
vi-VN
zh-CN
zh-HK
zh-TW
ar-SA
es-ES
ca-ES
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-US
en-NZ
en-AU
en-SG
en-GB
es-ES
es-419
es-MX
es-CL
es-MX
es-CO
es-MX
es-US
es-MX
fi-FI
fr-FR
he-IL
hi-IN
hr-HR
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
id-ID
ms-MY
ms-MY
nb-NO
nl-NL
no-NO
no-NO
pl-PL
pt-BR
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
uk-UA
vi-VN
yue-CN
zh-HK
zh-TW
zh-Hans
zh-CN
zh-Hans-CN
zh-CN
zh-Hans-HK
zh-HK
zh-Hans-MO
zh-HK
zh-Hant-HK
zh-HK
zh-Hant-MO
zh-HK
zh-Hant-TW
zh-TW
zh-MO
zh-HK
TTSResources
PreinstallCache
com.apple.siri
com.apple.siri
Name
Language
Gender
Technology
Quality
Available
Obsolete
Source
@(#)PROGRAM:SiriTTSService  PROJECT:SiriTTSService-1
?mcpl
L?NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_0NS_9allocatorIS2_EEFvRKNS_6vectorIfNS3_IfEEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIfNS_9allocatorIfEEEEEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_0
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_1NS_9allocatorIS2_EEFvPKvEEE
NSt3__110__function6__baseIFvPKvEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_1
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_2NS_9allocatorIS2_EEFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS3_IS7_EEEEEEE
NSt3__110__function6__baseIFvRKNS_6vectorIN14TTSSynthesizer6MarkerENS_9allocatorIS4_EEEEEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_2
NSt3__110__function6__funcIZ52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_3NS_9allocatorIS2_EEFvPKvEEE
Z52-[SiriTTSSynthesisEngine _unlockedSynthesize:error:]E3$_3
N5apple4aiml12flatbuffers216DefaultAllocatorE
N5apple4aiml12flatbuffers29AllocatorE
SiriTTSService
AudioPlaybackError
AudioRouteInfo
AudioData
AudioPlayback
BufferedAudioPlayback
AudioPower
AudioPowerProviding
AudioInterface
AudioQueueInterface
AudioQueueBufferUserData
_NSRange
CMSampleBuffer
NCMSampleBufferRef
CMTime
AudioTimeStamp
ThermalState
NNSProcessInfoThermalState
os_unfair_lock_s
TTSAssetProperty
URLResourceKey
NNSURLResourceKey
Name
NNSNotificationName
AudioStreamBasicDescription
Foundation
AudioStreamPacketDescription
TRIOnDemandFactorDownloadStatus
MatchingFlags
NNSMatchingFlags
CFString
NCFStringRef
TTSAssetVoiceGender
CMTimeFlags
AudioTimeStampFlags
SMPTETime
SMPTETimeFlags
SMPTETimeType
"*2{
#&)/5>GORYailu
DiagnosticService
MetricsJsonKeys
"(09@BJSZaeimv
%-7?JLVajsvy
J!S&+Z06
$+bj2r;}BI
SiriTTSService
CacheReadingAction
$*2;DGOX_fjnt}
VoiceAttribute
TTSAssetStubStrategy
MappedData
PassThroughAction
SynthesisConfigProviding
InlineStreamingStorage
EngineCachingService
SignpostHandler
MobileGestalt
Features
NeuralUtils
Locked
Flags
RetryTextModificationAction
OspreyClient
TTSAssetTrialAsset
TTSAssetTrialVoiceAsset
TTSAssetTrialResourceAsset
TTSAssetAdhocStrategy
TextToPhonemeAction
TTSAssetStrategy
SiriFeatures
TTSAssetFeatures
"&*.26<DM
 $(,26<@HR^
#'+/5;A
Event
NotificationHandling
OptionalNotificationHandling
 &-6;BGLTZ
TTSAssetTrialProxyInstantiatedAsset
TTSAssetProxyCallback
TTSAssetProxyProgressCallback
TTSAssetProxyPathCallback
TTSAssetProxyStrategy
ProxyKey
TTSAssetMAStrategy
DownloadSourceExtractor
OSVersion
TTSAssetTrialStrategy
AssetClass
WorkflowErrorHandler
Workflow
DataContainer
Buffer
Actionable
Conditional
AsynchronousContext
Asynchronous
WorkflowNode
WorkflowCondition
SynthesisCacheWritingAction
Constants
DaemonXPCAllowedTypeSets
Entitlements
supo
OpusDecoder
TTSAssetProxyAsset
SynthesisEngineSelectionAction
DependencyInjectable
ObjectPool
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-GD
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
ms-MY
nl-BE
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
vi-VN
zh-CN
zh-HK
zh-TW
TTSAssetMAAsset
TTSAssetMACompactAsset
DefaultMacinTalkProperties
DefaultVocalizerProperties
PreinstalledWordTimingStorage
AudioPowerHandler
OpusEncodingAction
InternalSettings
Default
InlineStreamingAction
$$$$$$$
%')+
TTSError
TTSErrorCode
DirectedAcyclicGraph
RequestPreprocessAction
TTSAssetStaticVoice
TTSAssetAdhocVoice
TTSAssetPreinstalledVoice
TTSAssetStaticResource
TTSAssetAdhocResource
 #'*.26:
Localization
HomePodSetupStringKey
DelegateHandler
AudioFile
AudioDumpAction
AssistantAsset
AssistantVoiceMaps
HasAudioCondition
CoreAnalyticsInterface
CoreAnalyticsService
CoreAnalyticsSynthesisHandler
TrialAssetProvider
VoiceAsset
ResourceAsset
DownloadOption
LocalAssetProvider
BuiltInVoiceProvider
VocalizerCustomVoiceProvider
PreinstalledVoiceProvider
OspreyTTSAction
VoiceSelectionAction
RequestParsingAction
Logger
AVSBARPlayback
AudioMappedInfoAVSBAR
AudioPlaybackServiceState
Timeout
|?>q=
%>?5^>`
>B`e>
?5^>
y=q=
->J
N>?5^>
SSMLSimpleParser
RoughDurationEstimationAction
DurationEstimator
PhonemeElement
AudioPlaybackAction
TTSAssetPreinstalledStrategy
DeviceSynthesisAction
Preferences
OpusEncoder
CacheStorage
SynthesisCacheFile
SynthesisCacheChunkIterator
SynthesisCache
CodingKeys
TTSAssetLegacyAsset
Languages
PreinstalledAudioStorage
OspreyConfigProviding
OspreyBuiltInConfig
OspreyChainedConfigs
WeakDaemonDelegateWrapper
DaemonConnection
SiriTTSService
WordTimingInfo
InstrumentationMetrics
SourceOfTTS
AudibleContext
ProsodyProperties
SynthesisContext
SynthesisProfile
BaseRequest
AudioRequest
SynthesisRequest
PhonemeRequest
PhonemeSystem
SpeechRequest
SynthesisVoice
Footprint
VoiceType
VoiceGender
SynthesisVoiceSubscription
SynthesisResource
InlineStreamingSignal
DaemonSession
OspreyTTSPrewarmAction
SiriAnalyticsHandler
female
male
unspecifB
Partition
SiriTTSPhonemeTool
Unknown phoneme system: %d
basic_string
service
SiriTTSSynthesisEngine
Empty voice path cannot be used.
TTSSynthesizer::initialize error: %@
mimeType
TTSSynthesizer::load_voice_resource
tts.feature.prompt
tts.neural.use_fallback
TTSSynthesizer::synthesize_text error: %@
vector
SiriTTSNeuralUtils
fe_feature
fe_feature_only
quality
channel_type
app_id
context_info
dialog_identifier
experiment_identifier
global_rate
global_pitch
global_energy
global_sent_pitch
global_sent_pitchrange
global_sent_duration
global_sent_energy
global_sent_tilt
phonemes
word_phonemes
prompts
prompts_v2
original
replacement
normalized_text
phoneme_sequence
neural_phoneme_sequence
force_use_tts_service
disable_cache
data
resources
return_log
voice_asset_path
resource_asset_path
return_server_info
sample_rate
pcm_data
pitch_mean
pitch_std
energy_mean
energy_std
duration_mean
duration_std
wave_data
user_voice_profile
user_voice_profile_url
speech_id
session_id
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
meta_info
context
experiment
feature_flags
debug
profile
dev_config
prosody_config
prosody_control_config
value
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
stream_id
error_code
error_str
decoder_description
playback_description
streaming_playback_buffer_size_in_seconds
current_pkt_number
word_timing_info
feature
total_pkt_number
content_type
content
v24@?0^v8Q16
v32@?0@8Q16^B24
v20@?0r*8I16
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
cur_
scratch_end
scratch_
scratch_data
buf_
Finished
finished
ReferTo
off && off <= GetSize()
EndVector
i < size()
Finish
strlen(file_identifier) == kFileIdentifierLength
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
v16@?0@"OspreyMutableRequest"8
OspreyTTSService
Corrupted Osprey response.
-[SiriTTSOspreyChannel streamTTS:beginHandler:chunkHandler:completion:]_block_invoke
Unknown response from Osprey for streaming TTS
AXSpeechTransformTextWithLanguage
/usr/lib/libAXSpeechManager.dylib
/usr/local/lib/libAXSpeechManager.dylib
TTSAXResourceManager
Unable to find class %s
com.apple.ttsasset.NewAssetNotification
com.apple.trial.client
, isAppleProduct:
packetDescriptions
, packet count: 
AudioData: Unable to read audio file from 
AudioData: Unable to get audio file format, errno 
AudioData: Unable to get audio data byte count, errno 
AudioData: Unable to get audio data packet count, errno 
AudioData: Unable to get maximum packet size, errno 
AudioData: Unable to get audio data, errno 
Invalid chunk size: %ld at offset %ld, bytes count = %ld
SiriTTSService.AudioPlayback
siritts_audio_playback_queue
AudioService: Unable to create output audio queue, errno 
Unable to dispose AudioQueue, errorCode: %s
AudioService: Unable to start AudioQueue, error 
Unable to begin access power, error: %s
Unable to allocate AudioQueue Buffer, code: 
Unable to enqueue audio data, code: 
Detected stalled audio generation, will enqueue %f silence frame to compensate.
AudioService: Unable to stop AudioQueue immediately, errno 
Unable to get audio power, error: %s
Unable to end access power, error: %s
asbd
audioData
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
VoiceSynthesizerNumericID
VoiceNumericID
VoiceName
VoiceLocalizedNames
VoiceNameRoot
VoiceIdentifier
VoiceAge
VoiceGender
VoiceDemoText
VoiceLanguage
VoiceLocaleIdentifier
VoiceVersion
VoiceScriptCode
VoiceGroup
VoiceType
VoiceRelativeDesirability
VoiceSupportedCharacters
VoiceIndividuallySpokenCharacters
VoiceDiskSize
VoiceAssetDescription
VoiceGenderMale
VoiceGenderFemale
VoiceGenderNeutral
VoiceGenderNeuter
 {}. 
Dobr
 den, jmenuji se {}. Jsem 
 hlas.
Hej, jeg hedder {}. Jeg er en dansk stemme.
Hallo, ich hei
e {} und ich bin eine deutsche Stimme.
 {}. 
Hello, my name is {}. I am an Australian-English voice.
Hello, my name is {}. I am a British-English voice.
Hello, my name is {}. I am an Irish-English voice.
Hello, my name is {}. I am an Indian-English voice.
Hello, my name is {}. I am an American-English voice.
Hello, my name is {}. I am a South African-English voice.
Hello, my name is {}. I am a Scottish-English voice.
Hola, me llamo {} y soy una voz espa
ola.
Hola, me llamo {} y soy una voz mexicana.
Hei, minun nimeni on {}. Olen suomalainen 
Bonjour, je m
appelle {}. Je suis une voix canadienne.
Bonjour, je m
appelle {}. Je suis une voix fran
aise.
m! {} vagyok. 
n vagyok a magyar hang.
Halo, nama saya {}. Saya berbahasa Indonesia.
Salve, mi chiamo {} e sono una voce italiana.
Hallo, mijn naam is {}. Ik ben een Belgische stem.
Hallo, mijn naam is {}. Ik ben een Nederlandse stem.
Hei, jeg heter {}. Jeg er en norsk stemme.
Witaj. Mam na imi
 {}, jestem g
osem kobiecym dla j
zyka polskiego.
, o meu nome 
 {} e a minha voz corresponde ao portugu
s que 
 falado no Brasil
, chamo-me {} e dou voz ao portugu
s falado em Portugal.
 cheam
 {}. Sunt o voce rom
neasc
 {}. 
Ahoj. Vol
m sa {}. Som hlas v slovenskom jazyku.
Hej, jag heter {}. Jag 
r en svensk r
Merhaba, benim ad
m {}. Ben T
e bir sesim.
 Siri!
Hej, jeg er Siri.
Hallo, ich bin Siri.
Hello, I'm Siri.
Hei, min
 olen Siri.
Bonjour, je suis Siri.
 Siri.
Ciao, sono Siri.
Siri
 Siri
Hei, jeg er Siri.
Hallo, ik ben Siri.
Oi, meu nome 
 Siri.
 Siri.
Hej, jag heter Siri.
 Siri
Merhaba, ben Siri.
Siri
Hello
Siri
Siri
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
cookie
authTokens
SIRI_TEXT_TO_SPEECH
voice
\u001B\\pause=['"]?([0-9]+)['"]?
<break time=['"]([0-9]+)ms['"]\s*\/>
VOICE_SERVICES_OOB_HEY_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK
VOICE_SERVICES_OOB_HEY_SIRI_CLOCK_PLANK_TIMER
VOICE_SERVICES_OOB_HEY_SIRI_HOME
VOICE_SERVICES_OOB_HEY_SIRI_MUSIC
VOICE_SERVICES_OOB_HEY_SIRI_NEWS
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER
VOICE_SERVICES_OOB_HEY_SIRI_WEATHER_2
VOICE_SERVICES_OOB_SIRI_CAPABILITIES
VOICE_SERVICES_OOB_SIRI_CAPABILITY_CLOCK
VOICE_SERVICES_OOB_SIRI_CAPABILITY_HOME
VOICE_SERVICES_OOB_SIRI_CAPABILITY_MUSIC
VOICE_SERVICES_OOB_SIRI_CAPABILITY_NEWS
VOICE_SERVICES_OOB_SIRI_CAPABILITY_WEATHER
VOICE_SERVICES_OOB_SIRI_INTRO
VOICE_SERVICES_OOB_TRY_SAY_0
VOICE_SERVICES_OOB_TRY_SAY_1
ca-ES_Montserrat
paused
started
waitForFinish
stopped
magicVersion
timingInfos
com.apple.springboard
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
com.apple.voicetool
com.apple.siri.tts.SiriTTSServiceIntegrationTests.xctrunner
com.apple.siritts-tool
synthesisContext
SiriTTSAudioData
supportsSecureCoding
TB,N
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
q16@0:8
v24@0:8q16
@24@0:8@16
T{AudioStreamBasicDescription=dIIIIIIII},N,Vasbd
T@"NSData",N,C
Tq,N,VpacketCount
T@"NSString",N,R
B24@0:8@16
hash
audioInterface
audioOperationQueue
playbackError
audioSequence
_TtC14SiriTTSService19AudioQueueInterface
discontinuedDuringPlayback
outputRouteInfo
audioQueue
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
_TtCC14SiriTTSService19AudioQueueInterfaceP33_D074378E45DF23C69F519544CB6674D224AudioQueueBufferUserData
expectedPlaySampleTime
SiriTTSServiceAudioPlayback
Unable to query kAudioQueueProperty_IsRunning, %s
Unexpected to have startTime == 0
Enqueued audio buffer #%ld, packet count: %ld, bytes: %ld
Played audio buffer #%ld, packet count: %ld, bytes: %ld
Current route info: {%s}
Started AudioQueue.
Starting AudioQueue...
SiriTTSSynthesizingRequestProtocol
T@"SiriTTSSynthesisContext",N,&
@"SiriTTSSynthesisContext"16@0:8
v24@0:8@"SiriTTSSynthesisContext"16
SiriTTSAudibleRequestProtocol
T@"SiriTTSAudibleContext",N,&
@"SiriTTSAudibleContext"16@0:8
v24@0:8@"SiriTTSAudibleContext"16
_TtP14SiriTTSService22DaemonDelegateProtocol_
v32@0:8Q16@"SiriTTSInstrumentationMetrics"24
v32@0:8Q16@"SiriTTSAudioData"24
v32@0:8Q16@"NSArray"24
v24@0:8@?<v@?>16
_TtP14SiriTTSService14DaemonProtocol_
v28@0:8B16@?20
v32@0:8@16@?24
v48@0:8@16@24@32@?40
v28@0:8B16@?<v@?@"NSError">20
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSAudioRequest"16@?<v@?@"NSError">24
v32@0:8@"SiriTTSSpeechRequest"16@?<v@?@"NSError">24
v24@0:8@"SiriTTSBaseRequest"16
v32@0:8@"SiriTTSSynthesisRequest"16@?<v@?d@"NSError">24
v32@0:8@"SiriTTSPhonemeRequest"16@?<v@?@"NSString"@"NSError">24
v24@0:8@"SiriTTSInlineStreamingSignal"16
v24@0:8@"SATTSSpeechSynthesisStreaming"16
v48@0:8@"NSArray"16@"NSString"24@"NSString"32@?<v@?@"NSError">40
v32@0:8@"NSString"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"NSArray">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?@"SiriTTSSynthesisVoice"@"NSError">24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?B>24
v32@0:8@"NSUUID"16@?<v@?ff>24
v32@0:8@"SiriTTSSynthesisVoice"16@?<v@?B@"NSError">24
Unable to remove file %s
_TtC14SiriTTSService17DiagnosticService
notificationCenter
observers
Unable to encode json data
Unable to locate data dump directory
Unable to write json metrics at %s, %s
Json metrics saved to: %s
Instrumentation Metrics Data (id: %llu):
v16@?0@"NSNotification"8
Event '%s' expect associated object as %s, got: %s
SynthesisResource
InstrumentationMetrics
Array<WordTimingInfo>
AudioPowerProviding
siriInlineOneShot
siriInlineStreaming
siriServerRoundTrip
Unable to list content of directory %{public}s
No request is provided. Ignore reading cache.
No cache storage is provided. Ignore reading cache.
No voice is provided. Ignore reading cache.
No resource is provided. Ignore reading cache.
\mrk=play=phat\
Synthesis cache is found for request %@
Ignore reading cache since phatic prompt should have randomness.
Preinstalled audio is found for request %@
Ignore reading cache due to internal settings disables caching.
_TtC14SiriTTSService18CacheReadingAction
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
VoiceGroupCustom
Swift/Dictionary.swift
VoiceGroupCustomCompact
VoiceGroupCompact
SupportedCharacters
com.apple.siri.SiriTTSService
_TtC14SiriTTSService20TTSAssetStubStrategy
_TtC14SiriTTSService10MappedData
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
Unable to handle mmap file, errno: %d, error: %s
Unable to resize mapped file, errno: %d, error: %s
Unable to mmap file to length: %ld, errno: %d, error: %s
Unable to mmap file at path: %{public}s, errno: %d, error: %s
_TtC14SiriTTSService17PassThroughAction
SiriTTSService
v44@0:8@16B24@?28@?36
v24@0:8@?16
v20@0:8B16
Cleared inline streaming object storage.
Notification for %s has not started. Cache object %@
Found cached objects %@
Start streaming for %s
_TtC14SiriTTSService22InlineStreamingStorage
storage
streamingHandlers
signals
lock
Notification for %s is on-going. Posting object immediately %@
InlineStreamStorage
_TtC14SiriTTSService20EngineCachingService
_activeSessionCount
_cachedEngine
No active session now, unloading cached engine with path %s
_TtC14SiriTTSService15SignpostHandler
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
TTSStartAudio
[Error] Interval already ended
TTSServerFirstPacket
TTSEngineSelect
engineTag=%s
TTSVoiceSelect
voice=%s
TTSSynthesis
source=%s
TTSPlayback
HardwarePlatform
lowInactiveMemory
VoiceServices
VoiceSelectionAction: Cannot find synthesizing request
_TtC14SiriTTSService27RetryTextModificationAction
v16@?0@"SiriTTSOspreyStreamingBeginResponse"8
v16@?0@"SiriTTSOspreyStreamingPartialResponse"8
v16@?0@"NSError"8
_TtC14SiriTTSService12OspreyClient
grpcChannel
speechId
https://seed-dejavu.siri.apple.com
ttsContentVersion
Trial asset %{public}@ not downloading, unable to cancel
Trial asset %{public}@ already downloaded, unable to cancel
v20@?0B8@"NSError"12
SiriTTSService.TTSAssetTrialAsset
_TtC14SiriTTSService18TTSAssetTrialAsset
factorName
assetAttr
isDownloading
downloadToken
progressQueue
assetSource
T@"TTSAssetSource",N,R
versionDescription
diskSize
T@"NSNumber",N,R
supportedLanguages
T@"NSArray",N,R
T@"NSBundle",N,R
locallyAvailable
_TtC14SiriTTSService23TTSAssetTrialVoiceAsset
T@"TTSAssetType",N,R
technology
T@"TTSAssetTechnology",N,R
T@"TTSAssetQuality",N,R
name
identifier
gender
T@"NSDictionary",N,R
_TtC14SiriTTSService26TTSAssetTrialResourceAsset
TrialAssetDownloadProgress
com.apple.speech.synthesis.voice.
com.apple.speech.synthesis.voice.custom.siri.
Missing name for voice
Missing footprint for voice
Unknown footprint for voice: %@
Missing asset type for voice
Unknown asset type for voice: %@
Asset %s attributes %s level %@
Unable to initialize asset bundle from path: %{public}s
MobileAssetProperties
Asset %s path %s
Unable to get level for factor name '%{public}s'
Trial asset %{public}@ immediate removal failed with error %@
Trial asset %{public}@ immediate removal succeeded
Trial asset %{public}@ deferred removal failed with error %@
Trial asset %{public}@ deferred removal succeeded
Trial asset %{public}@ download cancellation failed with error %@
Trial asset %{public}@ download cancelled
Trial asset %{public}@ start download with option %{public}@
Trial asset %{public}@ download failed with error %@
Trial asset %{public}@ download succeeded
Trial download %u%% done, %.2fs left %d written status %d
v24@?0d8Q16
_TtC14SiriTTSService21TTSAssetAdhocStrategy
Skip invalid voice folder '%s'
Skip invalid resource folder '%s'
#Local listing assets for types: %s, filter: %s
Unable to list resource folder %s
/private/var/mobile/Library/VoiceServices/resources/
Unable to list voice folder %s
/private/var/mobile/Library/VoiceServices/voices/
/System/Library/PrivateFrameworks/TTSAsset.framework/Voices/
TextToPhoneme request is not set
TextToPhoneme voice is not found
_TtC14SiriTTSService19TextToPhonemeAction
engineCachingService
ObjectPool: Unregistered type 
ObjectPool: Constructed wrong object type 
TTSAsset encountered unknown asset type %{public}@ and tentatively tried to handle through Trial
enable_adhoc_voice
use_trial
TTSAsset
sirix
Siri
SiriTTSService.Event.taskCompletion
SiriTTSService.Event.audioPowerProviderAvailable
SiriTTSService.Event.neuralFallback
SiriTTSService.Event.neuralAudioClick
SiriTTSService.Event.neuralAlignmentStall
SiriTTSService.Event.synthesisUsedPrompt
SiriTTSService.Event.encounteredError
SiriTTSService.Event.synthesisEngineChanged
SiriTTSService.Event.receivedServerLastPacket
SiriTTSService.Event.voiceResourceSelected
SiriTTSService.Event.synthesisError
SiriTTSService.Event.eagerRequestDetected
SiriTTSService.Event.cancellationRequested
SiriTTSService.Event.phonemesGenerated
SiriTTSService.Event.audioPlaybackEnded
SiriTTSService.Event.audioPlaybackEnqueued
SiriTTSService.Event.audioPlaybackStarted
SiriTTSService.Event.audioPlaybackStarting
SiriTTSService.Event.receivedServerFirstPacket
SiriTTSService.Event.engineSelectEnd
SiriTTSService.Event.engineSelectStart
SiriTTSService.Event.voiceSelected
SiriTTSService.Event.voiceSelectStart
SiriTTSService.Event.synthesisStarted
SiriTTSService.Event.audioGenerated
SiriTTSService.Event.wordTimingGenerated
SiriTTSService.Event.synthesisEnded
SiriTTSService.Event.encounteredIssue
SiriTTSService.Event.instrumentationMetricsAvailable
SiriTTSService.Event.requestReceived
SiriTTSService1
B40@0:8@16@24@32
_TtC14SiriTTSService35TTSAssetTrialProxyInstantiatedAsset
registry
_TtC14SiriTTSService29TTSAssetProxyProgressCallback
_TtC14SiriTTSService25TTSAssetProxyPathCallback
_TtC14SiriTTSService21TTSAssetProxyStrategy
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
TrialXP (by Proxy)
Failed to establish connection, return empty result from proxy assets
Failed to get value from xpc reply, return empty results from proxy assets
<- %d assets
B24@?0q8@"<OS_xpc_object>"16
Listing asset types %{public}s through XPC service...
Failed to establish connection & sandbox
Failed to get sandbox extensions
Failed to consume sandbox extension %s
Consume sandbox extension %s
v16@?0@"<OS_xpc_object>"8
com.apple.SiriTTSService.TrialProxy
v16@?0@"TTSAsset"8
v32@?0d8q16q24
Unable to issue sandbox extension to path '%{public}s'
Unable to convert C string into Swift string for authToken'
Issued sandbox extension to path %s
Unexpected non Trial asset %{public}@
Unable to get bundle path for factor name %s
com.apple.private.sirittsservice.modify-proxy-assets
macintalkVoice
vocalizerVoice
combinedVoice
customVoice
gryphonVoice
voiceResources
macosLegacy
mobileAsset
turiTrial
adhoc
preinstalled
vocalizer
custom
macintalk
gryphon
neural
neuralAX
compact
premium
premiumhigh
beta
production
T@"TTSAssetServer",N,R
livability
staging
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
_TtC14SiriTTSService18TTSAssetMAStrategy
stagingURL
_TtCC14SiriTTSService18TTSAssetMAStrategy23DownloadSourceExtractor
v56@0:8@16@24@32@40@48
v48@0:8@16@24@32@40
v32@0:8@16@24
inKey
wantValue
source
#MobileAsset Unable to create query
Query for %{public}@ failed: %d
Download asset catalogs, sync: %{bool}
#MobileAsset listing assets for type '%@', filter: '%{public}s'
v16@?0q8
Catalog %{public}@ download failed: %d
/var/MobileAsset/AssetsV2/
https://mesu.apple.com/assets/
https://basejumper.apple.com/livability/
Server (default) for %{public}@
Server %{public}@ for %{public}@: %d
https://basejumper.apple.com/assets/
https://basejumper.apple.com/assets
https://basejumper.apple.com/
_TtC14SiriTTSService21TTSAssetTrialStrategy
#Trial Synchronous namespace download took %.1fs
#Trial listing assets for class '%s', types: '%{public}s', filter: '%{public}s'
com.apple.siri.tts.
Factor %s does not have %ld components as expected.
Encountered entirely unexpected factor %s.
Refreshing stale trial client
TTSAsset Trial Callbacks
/private/var/MobileAsset/AssetsV2/com_apple_MobileAsset_Trial_Siri_SiriTextToSpeech/
/Library/Trial/Treatments/
v16@?0@"<TRINamespaceUpdateProtocol>"8
Get namespace update, refreshing trial client
Workflow: waitDequeue timed out in 
Workflow: waitDequeue timed out in %s
Encountered error: %s
Encountered error during error handling: %s
Gracefully handle error: %s
_TtC14SiriTTSService8Workflow
graph
errorHandlers
_isCancelled
cancellationLock
_TtC14SiriTTSService13DataContainer
idContainer
_TtC14SiriTTSService6Buffer
bufferCondition
_TtC14SiriTTSService19AsynchronousContext
isProcessing
asyncError
waitTimeout
isProcessingCondition
_TtC14SiriTTSService12WorkflowNode
action
_TtCC14SiriTTSService12WorkflowNode17WorkflowCondition
conditional
Fatal error
Down-casted Array element failed to match the target type
Expected 
NSArray element failed to match the Swift Array Element type
Expected 
(AudioMappedInfoAVSBAR in _4791274A894FA1CB92EFFF8F61E0C16D)
SynthesisVoiceSubscription
AVQueuedSampleBufferRendering
Conditional node has no next node, %s
TTSAssetTrialProxyInstantiatedAsset
InlineStreamingSignal
com.apple.ttsasset
SiriTTSService2
B32@0:8@16@24
v8@?0
Ignore writing cache due to missing cache storage
Ignore writing cache due to missing audio data
Ignore writing cache due to missing request info
Ignore writing cache due to missing voice info
Ignore writing cache due to missing voice resource info
Unable to create cache file, error: 
Ignore writing cache with empty data, probably audio prime data
Ignore writing cache since phat prompt should have randomness.
Ignore writing cache since audio is from cache already
Ignore writing cache due to internal settings disable caching
_TtC14SiriTTSService27SynthesisCacheWritingAction
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
Unable to write cache, %s
Invalidate synthesis caching. %s
Synthesis cache %s is written.
Synthesis cache %s is cancelled.
Unable to close cache file, %s
Detected synthesis error.
Detected neural alignment stall.
Detected neural audio click.
Detected neural fallback.
Cancellation is requested.
com.apple.sirittsd
com.apple.sirittsd.can-dump-audio
v24@0:8@16
OpusDecoder: Opus not supported)
OpusDecoder: Opus unknown asbd 
OpusDecoder: Unable to create converter, source asbd 
OpusDecoder: Unable to create pcm buffer
@"AVAudioBuffer"20@?0I8^q12
OpusDecoder: Unable to decode chunk, error: 
_TtC14SiriTTSService11OpusDecoder
fromFormat
toFormat
converter
No bundle path from proxy presentation
Invalid bundle path %{public}s
Constructed bundle %s
Trial proxy download status check failed, unable to establish server connection
-> %@
<- %@
Failed to get download status
Trial proxy asset [%@] not downloading, unable to cancel
Trial proxy asset download cancellation failed, unable to establish server connection
Trial proxy asset [%@] cancelling download.
SiriTTSService.TTSAssetProxyAsset
_TtC14SiriTTSService18TTSAssetProxyAsset
assetQuality
bundlePath
authorizedBundle
proxy_attr
assetType
versionNumber
Tq,N,R
attributes
purgeable
Trial proxy asset [%@] download cancelled.
Trial proxy asset [%@] download cancellation failed.
Trial proxy asset download failed, unable to establish server connection
Trial proxy asset [%@] download starting.
Trial proxy asset [%@] already locally available, no download necessary
Trial proxy asset [%@] download failed.
Trial proxy asset [%@] download succeeded.
.siri.tts.resource.
DeviceSynthesisAction: No voice asset was set
gryphon_frontend
Unable to load resource %s, error: %s
_TtC14SiriTTSService30SynthesisEngineSelectionAction
voice_configs.plist
Unable to load voice_configs.plist from %s
vocalizer_resources
Unable to parse vocalizer_resources
vocalizer_resource_order
Unable to parse vocalizer_resources_order
Unknown mime-type for file %s
_TtC14SiriTTSService10ObjectPool
constructorRegistry
objectPool
speech.synthesis.voice
_MasteredVersion
_CompatibilityVersion
LanguagesCompatibility
SiriTTSService.TTSAssetMAAsset
_TtC14SiriTTSService15TTSAssetMAAsset
asset
bundle
_TtC14SiriTTSService22TTSAssetMACompactAsset
v16@?0@"MAProgressNotification"8
Preposterous string version %{public}@ for key %{public}@ in %@
Preposterous integer version %d for key %{public}@ in %@
_TtC14SiriTTSService29PreinstalledWordTimingStorage
storageURL
voice name is required for preinstalled word timings.
No preinstalled word timings plist file at path %{public}s
Unable to convert to expected format file at path %{public}s
Missing word_timings field in file at path %{public}s
Unable to find word '%s' in word timing pair in file at path %{public}s
Missing word timing pair in file at path %{public}s
No preinstalled word timings for %{public}s %s. Falling back to %s
_TtC14SiriTTSService17AudioPowerHandler
audioPowerProvider
OpusEncodingAction: no audio found
OpusEncodingAction: Audio is already opus encoded
_TtC14SiriTTSService18OpusEncodingAction
encoder
_TtC14SiriTTSService16InternalSettings
_disableTTS
_enableDiagnostic
_logSensitiveText
_disableCache
_overrideRequestsText
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
logSensitiveText
overrideRequestsText
DisableAssetCleaning
AllowAnyAssetSubscription
defaultToNonDiscretionaryDownloads
EnableLocalVoices
ServerTTSTimeout
DeviceTTSWaitTime
disableDeviceRacing
disableServerTTS
disableInlineStreamTTS
disableOspreyStreaming
streamBufferDuration
ospreyEndpointURL
simulateNetworkStall
simulateAudioStall
disableDeviceNeuralTTS
disableMobileAssetURLReset
ignoreThermalState
disableAssetUpdate
com.apple.voiceservices
process is not running as user Mobile: it's not accessing our shared UserDefaults
InlineStreamingAction: Cannot find request
InlineStreamingAction: Cannot find streaming signal for 
_TtC14SiriTTSService21InlineStreamingAction
asyncContext
streamingStorage
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
InlineStreamingAction: Unknown stream object 
InlineStreamingAction: Unknown inline streaming error 
Received streaming audio chunk before receiving streaming audio begin
Simulate network stall is on, ignore inline streaming objects
InlineStreamingAction: Unsupported inline streaming audio format 
Inline streaming timed out
Inline streaming network stall
Internal setting specifies timeout: %f
sirittsd crashed
RequestParser: Cannot find request.
Overriding text with internal default: %s
Overriding whisper with internal default
Overwriting pitch with internal default: %f
Overwriting rate with internal default: %f
Overwriting volume with internal default: %f
_TtC14SiriTTSService23RequestPreprocessAction
settings
SSMLConversion: Unsupported tag: 
Error in pause tag, ignore
Error in tn override tag, ignore
<say-as interpret-as="
SSMLConversion: Unbalanced say-as tag
SSMLConversion: Unbalanced phoneme tag
<phoneme alphabet="lhp" ph="
AssistantEtiquette
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/Tones/AssistantEtiquette
%{public}s is not TTS language, fallback to %{public}s
_TtC14SiriTTSService19TTSAssetStaticVoice
attr
_TtC14SiriTTSService18TTSAssetAdhocVoice
_TtC14SiriTTSService25TTSAssetPreinstalledVoice
_TtC14SiriTTSService22TTSAssetStaticResource
_TtC14SiriTTSService21TTSAssetAdhocResource
Resource Asset %s path %s attributes %s
SiriTTSService.TTSAssetStaticResource
SiriTTSService/TTSAssetStaticAsset.swift
Subclasses of TTSAssetStaticResource must override assetSource
SiriTTSService.TTSAssetStaticVoice
Subclasses of TTSAssetStaticVoice must override assetSource
SiriTTSLocalization
HomePodDeviceSetup
Unable to find HomePod setup string for key '%s', %s
LocalizedStrings
SIRITTSSERVICE_NETWORK_STALL_3
Unable to find retry phrase '%s', %s
SIRITTSSERVICE_NETWORK_STALL_2
SIRITTSSERVICE_NETWORK_STALL_1
_TtC14SiriTTSService15DelegateHandler
delegate
com.apple.voiceservices.notification.synthesis-done
audibleContext
Unable to create directory at %s, error: %s
%s is not a directory!
Unable to get Library directory for audio dumping
AudioDump: Cannot find audio data.
Unable to find request of AudioDumpAction
Audio saved to: %s
Ignore writing audio file due to missing entitlement. Please add 'com.apple.sirittsd.can-dump-audio'.
_TtC14SiriTTSService9AudioFile
audioFile
packetOffset
_TtC14SiriTTSService15AudioDumpAction
entitlements
diagnosticAudioFile
synthesizedAudioFile
diagnosticTag
AudioFile: Unable to close audio file, code: 
AudioFile: Unable to write audio data, code: 
AudioFile: Unable to create audio file at path 
Unable to write diagnostic audio file, error: %s
SiriTTSService.AssistantAsset
SiriTTSService.AssistantVoiceMaps
AssistantVoiceMap
VoicePitchRangeDescriptors
TTSAssistantAsset
assistantGender
assistantOrder
Tq,N,R,VassistantGender
Tq,N,R,VassistantOrder
isCustom
TB,N,R
primaryLanguage
TTSAssistantVoiceMaps
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
SiriTTSService3
assistantVoiceMaps
T@"TTSAssistantVoiceMaps",N,R
_TtC14SiriTTSService17HasAudioCondition
voice_resource_asset_key
tts_synthesis_latency
tts_total_latency
audio_queue_latency
is_speech_request
synthesis_to_speech_time_gap
is_synthesis_cached
audio_output_route
client_bundle_identifier
privacy_sensitive
server_first_packet_latency
server_last_packet_latency
com.apple.voiceservices.metrics
real_time_factor
neural_alignment_stall
neural_audio_click
_TtC14SiriTTSService20CoreAnalyticsService
_TtC14SiriTTSService29CoreAnalyticsSynthesisHandler
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
Unrecognized request type in handleRequestReceived, got: %s
Unable to cancel download of non-TTSAssetTrialAsset asset
_TtC14SiriTTSService10VoiceAsset
path
_TtC14SiriTTSService13ResourceAsset
resource
_TtC14SiriTTSService18TrialAssetProvider
downloadQueue
_TtC14SiriTTSService18LocalAssetProvider
_TtC14SiriTTSService20BuiltInVoiceProvider
_TtC14SiriTTSService28VocalizerCustomVoiceProvider
_TtC14SiriTTSService25PreinstalledVoiceProvider
Unfound built-in voice for language %{public}s
Falling back to no-NO voice since nb-NO is not available
Unable to find resource for 
Resource asset is locally available: %s
Unable to download resource: 
Unable to download namespace, %s
Unable to find best voice for 
Voice is locally available already: %@
Unable to download voice: 
Unable to download SIRI_TEXT_TO_SPEECH namespace
Download namespace requires non-discretionary option
SIRI_TEXT_TO_SPEECH namespace is not downloaded yet. Try downloading now.
OspreyTTSAction: Cannot find synthesizing request
Updating osprey cache
Osprey cache is found, requestId: %llu
Missing voice name or gender for Osprey { id: 
_TtC14SiriTTSService15OspreyTTSAction
ospreyClient
ospreyConfig
streamingStartedDate
Updated osprey cache
OspreyTTSAction: error when updating osprey cache, %s
Osprey streaming network stall { id: 
Osprey streaming timed out { id: 
Encountered Osprey error: %s, { id: %llu }
Simulate network stall is on, ignore audio object
Invalid server audio format
Server voice: %@, resource: %@, buffer size: %f
Default Osprey timeout: 1.0
Osprey config specifies timeout: %f
Cannot find suitable voice for 
Ignore neural voice since it's not suitable. Current thermal level: %s, low power mode: %{bool}d, voice: %{public}@, neural platform: %{bool}d, requestId: %llu
Ignore neural voice since internal settings disable device neural TTS. requestId: %llu }
VoiceSelectionAction cannot find synthesizing request
Select voice: {%{public}s}, resource: {%{public}s}, request: {client: %{public}s, id: %s}
_TtC14SiriTTSService20VoiceSelectionAction
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
VoiceSelectionAction does not support request: 
RequestParsingAction cannot find request
RequestParsingAction found unknown request: 
_TtC14SiriTTSService20RequestParsingAction
com.apple.siri.tts
B24@?0r*8@"<OS_xpc_object>"16
VSAudioPlaybackServiceAVSBARQueue
Can't retrieve session with ID: 
Can't instantiate AVSampleBufferAudioRenderer or AVSampleBufferRenderSynchronizer. Search (AVFCore) and [com.apple.coremedia:] for the underlying error.
VSAudioPlaybackService init latency: %f
#AVSBAR initialized with session ID: %u, reusing previous synchronizer: %{bool}d
#AVSBAR already stopped or waiting for finish: will not enqueue more
Did add to enqueuedMappedAudioInfo: %f sec
Will add to enqueuedMappedAudioInfo: %f sec
#AVSBAR empty audio data: will not enqueue it
#AVSBAR already stopped or waiting for finish
Timeout waiting for AVSampleBufferRenderSynchronizer
#AVSBAR Synchronizer is stalled with rate %f at time %f.
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR waitUntilFinished
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
synchronizer stop rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f. Then renderer will be flushed.
Stopping synchronizer and renderer
synchronizer pause rate high latency: %f sec
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f.
Pausing synchronizer
_TtC14SiriTTSService14AVSBARPlayback
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
_TtCC14SiriTTSService14AVSBARPlaybackP33_4791274A894FA1CB92EFFF8F61E0C16D21AudioMappedInfoAVSBAR
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %ld
renderer enqueueSampleBuffer high latency: %f sec
#AVSBAR Enqueuing to %@: %f sec
#AVSBAR Call to provide more audio data during state %s.
Error in creating block buffer for Silence buffer
Error in creating block buffer for Silence buffer, code: %s
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioFormatDescriptionCreate from Silence buffer creation, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer, code: %s
Error in creating block buffer for Sample buffer
Error in creating block buffer for Sample buffer, code: %s
Error in CMAudioFormatDescriptionCreate
Error in CMAudioFormatDescriptionCreate, code: %s
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in CMAudioSampleBufferCreateWithPacketDescriptions, code: %s
mediaserverd reset
#AVSBAR renderer was flushed
#AVSBAR Synchronizer reached endTime
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
synchronizer play rate high latency: %f sec
#AVSBAR already stopped or paused: will not resume rate
#AVSBAR Dropping %ld enqueued data
_TtC14SiriTTSService7Timeout
timeoutDate
waitCondition
queue
shouldStop
RoughDurationEstimation: No synthesizing request is provided
_TtC14SiriTTSService16SSMLSimpleParser
_TtC14SiriTTSService29RoughDurationEstimationAction
estimationDictionary
SiriTTSDurationEstimator
d24@0:8@16
DurationEstimator: error during process: %@
DurationEstimator: Unable to get output
DurationEstimator: DurationEstimator: Missing duration
\u001B\\\w+=.+?\\
\u001B\\toi=\w+\\.*?\u001B\\toi=orth\\
\u001B\\toi=\w+\\.*
\u001B\\toi=lhp\\([^\u001B]*)
v32@?0@"NSTextCheckingResult"8Q16^B24
Skip waiting, no active audio playback found.
Unable to stop audio playback.
Unable to wait audio playback finished.
Audio playback finished for request_id: %llu.
AudioPlayback: Cannot find audio data.
AudioPlayback: Cannot find audible request.
Audio playback started for request_id: %llu
_TtC14SiriTTSService19AudioPlaybackAction
buffer
audioPlayback
audibleRequest
Cancelling audio playback
_TtC14SiriTTSService28TTSAssetPreinstalledStrategy
#Local listing voices for types: %{public}s, filter: %{public}s
Searching in preinstalled voice directory: '%s'
/System/Library/PrivateFrameworks/VoiceServices.framework/TTSResources/PreinstallAssets/
Unable to list voice folder
Skip invalid voice folder '%{public}s'
SiriTTSService4
DeviceSynthesisAction: Engine is not set
DeviceSynthesisAction: Request is not set
v16@?0@"NSData"8
v16@?0@"NSString"8
v16@?0@"NSArray"8
_TtC14SiriTTSService21DeviceSynthesisAction
synthesisConfig
DeviceSynthesisAction: low RTF is detected during synthesis.
DeviceSynthesisAction: no audio data is generated.
Neural voice fell back to compact neural synthesis.
Received word timings: %s
Synthesized with prompt: '%s'
Low synthesis RTF detected, will likely results in stuttering. Missing: %f
offset element 
Unable to get defaults 'com.apple.voiceservices'
subscribedAssets
_TtC14SiriTTSService11Preferences
defaults
Preferences: Unable to find preference suite 
SiriTTSService5
B16@0:8
@16@0:8
downloading
OpusEncoder: Unknown asbd 
OpusEncoder: Opus not supported
OpusEncoder: Unable to create converter, source asbd 
OpusEncoder: Unable to encode chunk, error: 
_TtC14SiriTTSService11OpusEncoder
OpusEncoder: Unable to create input buffer
CacheStorage: Unable to create cache file at path 
Failed reading cache, error: %s
SynthesisCacheFile: invalid file, probably not closed properly, or incompatible.
Cleaned cache storage: %{public}s
Unable to remove cache file at path: %s
Cleaning cache storage: %{public}s
SynthesisCache: incorrect magic version
SynthesisCache: Unable to decode audio
SynthesisCache: Unable to decode timing info
_TtC14SiriTTSService12CacheStorage
Unable to list directory, error: %s
Missing bundle identifier for CacheStorage
Unable to create CacheStorage, error: %s
Unable to get Cache directory
CacheStorage: Path 
 is an existing file!
CFBundleShortVersionString
Failed to delete legacy asset %@: %@
SiriTTSService.TTSAssetLegacyAsset
_TtC14SiriTTSService19TTSAssetLegacyAsset
$__lazy_storage_$_voiceDesc
VoiceDescription
Swift/NativeDictionary.swift
Duplicate values for key: '
SiriTTSLanguages
availableLanguages
T@"NSSet",N,R
_TtC14SiriTTSService24PreinstalledAudioStorage
_TtC14SiriTTSService19OspreyBuiltInConfig
deviceWaitTime
allowedAppIdentifiers
_TtC14SiriTTSService20OspreyChainedConfigs
configs
_TtC14SiriTTSService25WeakDaemonDelegateWrapper
v24@0:8Q16
_TtC14SiriTTSService16DaemonConnection
connection
weakDelegate
asyncProxy
syncProxy
SiriTTSService.DaemonConnection
init()
Connection interrupted
Connection invalidated
experimentIdentifier
synthesisBeginTime
synthesisEndTime
speechEstimatedOutputBeginTime
serverFirstPacketTime
serverLastPacketTime
audioStartLatency
eagerRequestGapInterval
serverStreamedAudioDuration
isServerTTSRacing
 "audio_duration": 
 "audio_output_route": "
 "audio_queue_latency": 
 "character_count": 
 "error_code": 
 "experiment": "
 "is_speech_request": 
 "is_synthesis_cached": 
 "is_warm_start": 
 "neural_alignment_stall": 
 "neural_audio_click": 
 "neural_fallback": 
 "prompt_count": 
 "real_time_factor": 
 "server_first_packet_latency": 
 "server_last_packet_latency": 
 "source_of_tts": "
 "synthesis_to_speech_time_gap": 
 "tts_synthesis_latency": 
 "tts_total_latency": 
 "voice_resource": "
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
customResourceURLs
disableCompactVoice
synthesisProfile
prosodyProperties
", privacySensitive: 
SiriTTSService.SynthesisContext
text: "<privacySensitive, length: 
SiriTTSService.SynthesisVoice
SiriTTSService.SynthesisVoiceSubscription
SiriTTSService.SynthesisResource
SiriTTSService.InlineStreamingSignal
DaemonSession %@ sets keepActive: %{bool}d
Init DaemonSession %@
Init DaemonSession %@, with accessory %s
Deinit DaemonSession %@
DaemonSession keepActive must be true before prewarming.
Start #PrewarmRequest, %{public}s
Skipped #PrewarmRequest: TTS is disabled.
Start #SynthesisRequest %{public}s
TTSRequestReceived
id %llu
Skipped #SynthesisRequest: TTS is disabled.
Start #SpeechRequest %{public}s
Skipped #SpeechRequest: TTS is disabled.
Start #AudioRequest, %{public}@
Skipped #AudioRequest: TTS is disabled.
#CancelRequest, %@
#InlineStreaming signal %@
#InlineStreaming object %@
v12@?0B8
v16@?0f8f12
v24@?0d8@"NSError"16
Start #EstimateDuration %{public}s
Skipped #EstimateDuration: TTS is disabled.
v24@?0@"NSString"8@"NSError"16
#TextToPhoneme %s
Skipped #TextToPhoneme: TTS is disabled.
Unable to subscribe voice due to missing bundle identifier
Unable to get bundle identifier for current client
v24@?0@"SiriTTSSynthesisVoice"8@"NSError"16
Can't find alive request with timestamp %llu didStartSpeaking.
Request is not audible, but called with didStartSpeaking. %@
Can't find alive request with timestamp %llu didReportInstrument.
Can't find alive request with timestamp %llu didGenerateAudio.
Expecting synthesizing request, but got %@
Can't find alive request with timestamp %llu didGenerateWordTimings.
SiriTTSWordTimingInfo
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@40@0:8d16{_NSRange=QQ}24
startTime
textRange
Td,N,VstartTime
T{_NSRange=QQ},N,VtextRange
description
SiriTTSInstrumentationMetrics
Q16@0:8
v16@0:8
utterance
speechBeginTime
speechEndTime
T@"NSString",N,C
T@"SiriTTSSynthesisVoice",N,&,Vvoice
T@"SiriTTSSynthesisResource",N,&,Vresource
TQ,N,VrequestCreatedTime
Td,N,VeagerRequestGapInterval
TQ,N,VsynthesisBeginTime
TQ,N,VsynthesisEndTime
TQ,N,VspeechBeginTime
TQ,N,VspeechEndTime
TQ,N,VspeechEstimatedOutputBeginTime
Td,N,VaudioStartLatency
TQ,N,VserverFirstPacketTime
TQ,N,VserverLastPacketTime
Td,N,VserverStreamedAudioDuration
Td,N,VaudioDuration
TB,N,VisWarmStart
Tq,N,VsourceOfTTS
TB,N,VprivacySensitive
Tq,N,VerrorCode
TB,N,VisServerTTSRacing
Tq,N,VpromptCount
TB,N,VneuralAlignmentStall
TB,N,VneuralAudioClick
TB,N,VneuralFallback
TB,N,VisAudibleRequest
voiceResourceAssetKey
SiriTTSAudibleContext
I16@0:8
v20@0:8I16
@?16@0:8
audioSessionId
immediate
siriRequestId
didStartSpeaking
TI,N,VaudioSessionId
TB,N,Vimmediate
T@"NSUUID",N,C
T@?,N,C
SiriTTSProsodyProperties
f16@0:8
v20@0:8f16
Tf,N,VneuralSentencePitch
Tf,N,VneuralSentencePitchRange
Tf,N,VneuralSentenceDuration
Tf,N,VneuralSentenceEnergy
Tf,N,VneuralSentenceTilt
SiriTTSSynthesisContext
text
contextInfo
rate
pitch
volume
didGenerateAudio
didGenerateWordTimings
whisper
forceOspreyTTS
T@"NSDictionary",N,C
Tf,N,Vrate
Tf,N,Vpitch
Tf,N,Vvolume
T@"NSArray",N,C
Tq,N,VsynthesisProfile
TB,N,VdisableCompactVoice
TB,N,Vwhisper
T@"SiriTTSProsodyProperties",N,&,VprosodyProperties
TB,N,VforceOspreyTTS
SiriTTSBaseRequest
clientBundleId
accessoryId
outputPath
didReportInstrument
T@"NSURL",N,C
SiriTTSAudioRequest
audio
T@"SiriTTSAudioData",N,R,Vaudio
T@"SiriTTSAudibleContext",N,&,VaudibleContext
SiriTTSSynthesisRequest
@32@0:8@16@24
T@"SiriTTSSynthesisContext",N,&,VsynthesisContext
SiriTTSPhonemeRequest
@40@0:8@16@24q32
phonemeSystem
Tq,N,VphonemeSystem
SiriTTSSpeechRequest
SiriTTSSynthesisVoice
language
footprint
type
version
Tq,N,Vfootprint
Tq,N,Vtype
Tq,N,Vgender
Tq,N,Vversion
SiriTTSVoiceSubscription
@40@0:8@16@24@32
clientId
SiriTTSSynthesisResource
SiriTTSInlineStreamingSignal
SiriTTSDaemonSession
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
keepActive
v32@0:8Q16@24
SiriTTSService.SpeechRequest
SiriTTSService.PhonemeRequest
SiriTTSService.SynthesisRequest
SiriTTSService.AudioRequest
v16@?0@"SiriTTSInstrumentationMetrics"8
v16@?0@"SiriTTSAudioData"8
#Success #AudioRequest id %llu
#Error #AudioRequest id %llu, error: %s
#Success #SpeechRequest id %llu
#Error #SpeechRequest id %llu, error: %s
#Success #SynthesisRequest id %llu
#Error #SynthesisRequest id %llu, error: %s
#Success #PrewarmRequest id %llu
#Error #PrewarmRequest id %llu, error: %s
_TtC14SiriTTSService22OspreyTTSPrewarmAction
Error in Osprey prewarm: %s
_TtC14SiriTTSService20SiriAnalyticsHandler
ttsId
requestId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
com.apple.siri.audio
Captured EndTTSTime in UserDefaults
Ignore Siri logging due to missing Siri request id
Ignore Siri logging due to non Siri client
Ignore Siri logging due to unmatched Siri request id
SiriTTSService6
@20@0:8B16
Found '%{public}s' assets %{public}s
Listing asset types: '%{public}s', filter: '%{public}s'
voice path '%@', resource path '%@'
%d files under voice path:
%d files under resource path:
- %@
Failed is_neural_voice_ready %@ with error: %s
Failed should_use_neural_voice %@ with error: %s
Failed is_ane_model_compiled %@ with error: %s
Failed compile_ane_model %@ with error: %s
Replace: `%@' -> `%@'
Prompt: "%@"
Phonemes: %@
Norm Text: `%@'
Neural Phonemes: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@', request_id '%llu'
Corrupted Osprey response, stream ID: %@, request_id: %llu
Osprey streaming received Begin response with non 200 status: %d, request_id: %llu
Osprey streaming received Begin response %@, request_id: %llu
Osprey streaming received Chunk response with non 200 status: %d, request_id: %llu
Osprey streaming received Chunk response, pkt number: %d, request_id: %llu
Osprey streaming received End response with non 200 status: %d, request_id: %llu
Osprey streaming received End response, total pkt: %d, request_id: %llu
%s, Unknown response from Osprey for streaming TTS, request_id: %llu
Osprey streaming invokes completion with error %@, request_id: %llu
Osprey streaming invokes completion callback, request_id: %llu
softlink:r:path:/System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
ypSg
_pSg
G0R0_
$sSY
So8NSObjectC
$s14SiriTTSService13AudioPlaybackP
So17OS_dispatch_queueC
_pSg
$s14SiriTTSService19AudioPowerProvidingP
$s14SiriTTSService14AudioInterfaceP
_pSgc
So8NSStringC
$ss21_ObjectiveCBridgeableP
yyXlG
So13OS_xpc_object_p
yypG
_yXltG
_yXlt
So8NSObject_p
ySSG
ySS_yptG
SS_ypt
ySsG
ySDySSypGG
SDySSypG
ySny
ySiG
ySaySiGG
SaySiG
G0R3_
SgXw
SSSg
So20NSNotificationCenterC
SaySo8NSObject_pG
SdIegn_
ypSgm
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
Iegn_
GIegn_
So14NSUserDefaultsCSg
SdSg
SfSg
_pIegn_
SSIegn_
So8NSObjectCSg
So20NSNotificationCenterCSg
_ypt
ySSSaySDySSypGGG
ySSSDySSSaySDySSypGGGG
ySSSf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7letterstG
_ypt
ySSSo8NSObjectCG
ySSSDyS2SGG
yS2SG
ySSypycG
So13OS_xpc_object_pG
ySSySo29SATTSSpeechSynthesisStreamingCcG
ySSypG
So8TTSAssetC
_yptG
3key_yp5valuet
SaySDySSSiGG
ySS_SStG
SDySSSiG
SvSg
$s14SiriTTSService24SynthesisConfigProvidingP
So29SATTSSpeechSynthesisStreamingCytIegnr_
So29SATTSSpeechSynthesisStreamingC
So29SATTSSpeechSynthesisStreamingCIegg_
SaySo29SATTSSpeechSynthesisStreamingCG
SDySSySo29SATTSSpeechSynthesisStreamingCcG
So15NSRecursiveLockC
So34SiriTTSSynthesizingRequestProtocol_
So6NSLockC
So22SiriTTSSynthesisEngineCSg
SgXw
Ieg_
SaySJG
Iegggyi_
GIeggg_
_pSgIegg_
So20SiriTTSOspreyChannelC
So8TTSAssetCSgIegg_
So20TRINotificationToken_pSg
SaySSG
So8TTSAssetCSgIeyBy_
SdS2iIeyByyy_
Sdz_Xx
Siz_Xx
SdS2iIegyyy_
Iegyy_
_pSgIegyg_
3key_yp5valuet
_pmm
_pSg
_pmm
_pSg
So20NSNotificationCenterCm
So20NSNotificationCenterCmm
$s14SiriTTSService16TTSAssetStrategyP
xIegn_
$s14SiriTTSService20NotificationHandlingP
$s14SiriTTSService28OptionalNotificationHandlingP
yySd_S2itcG
yySSSgcG
So13OS_xpc_object_pSg
So21OS_dispatch_semaphoreC
3key_yp5valuetSg
_So13OS_xpc_object_ptG
SaySo8TTSAssetCG
SiSo13OS_xpc_object_pSbIgygd_
SaySo13TTSStringEnumCG
SaySbG
SaySDySSypGG
So12TTSAssetTypeC
ySi_
ySSG
SaySo15TTSAssetQualityCG
SaySo18TTSAssetTechnologyCG
$ss12CaseIterableP
_pSg
$s14SiriTTSService20WorkflowErrorHandlerP
ySbG
So11NSConditionC
$s14SiriTTSService10ActionableP
$s14SiriTTSService11ConditionalP
$s14SiriTTSService12AsynchronousP
_pSg
_pSg
SgXw
$s14SiriTTSService14DaemonProtocolP
$s14SiriTTSService22DaemonDelegateProtocolP
yXlXp
So8NSStringCm
So12NSDictionaryCm
So6NSUUIDCm
So5NSURLCm
So23AVAudioCompressedBufferC
So13AVAudioFormatC
So16AVAudioConverterC
So16AVAudioPCMBufferC
So15TTSAssetQualityC
So8NSBundleCSg
SDyS2SG
xIegr_
$s14SiriTTSService20DependencyInjectableP
SDySSypycG
ypSg_AAt
So7MAAssetC
ySi6offset_
7elementtG
Si6offset_
7elementt
3key_yp5valuet
SS3key_yp5valuetSg
ySS_
ySS_
ySbG
ySSSgG
ySJG
SDySSSDySSSaySDySSSdGGGG
SgXw
y_SbG
y_SSSgG
y_SfSgG
y_SdSgG
xypcSg
SgXw
SayxG
SaySaySiGG
So8NSBundleC
SgXw
Sbz_Xx
SgXwz_Xx
14SiriTTSService22DaemonDelegateProtocol_pSgXw
SaySDyS2SGG
SDySSSaySDySSypGGG
SDySSSay
SDySSSDyS2SGG
yXlG
ySS_SDyS2SGtG
ySSSay
ySSSiG
ySSSgcG
ySd_S2itcG
ySo12TTSAssetTypeCSay
_pGG
ySSSaySo8TTSAssetCGG
_pSg
SgXw
ySS_So8NSObjectCtG
$s14SiriTTSService22CoreAnalyticsInterfaceP
ypIegn_Sg
SfIegy_Sg
XDXMT
_yptG
SaySo14TTSAssetSourceCG
SgXw
Sgz_Xx
XDXMT
Gz_Xx
_pSg
GSo13OS_xpc_object_pSbIgygd_
SayypG
So29AVQueuedSampleBufferRendering_p
So7NSErrorCSg
So27AVSampleBufferAudioRendererC
So32AVSampleBufferRenderSynchronizerC
So21OS_dispatch_semaphoreCSg
SnySiG
_pSgcSg
SgXw
SbIegy_
ySS_Sf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7lettersttG
SDySSSf9syllables_Sf12punctuationsSf6digitsSf4CJKsSf7letterstG
So20NSTextCheckingResultCSg
GIggyy_
SaySny
SgXw
_pSg
So29SiriTTSAudibleRequestProtocol_
So29SiriTTSAudibleRequestProtocol_
XcSg
So22SiriTTSSynthesisEngineC
Gz_Xx
z_Xx
XDXMT
So29SiriTTSSynthesisEngineRequestC
SS3key_yp5valuet
So14NSUserDefaultsC
$sSt
$sST
So12NSFileHandleC
ySnySiGG
ypGSg
3key_yp5valuetSg
SaySsG
$s14SiriTTSService21OspreyConfigProvidingP
SaySSGSg
So15NSXPCConnectionC
14SiriTTSService14DaemonProtocol_p
IeyB_
_pIegg_
SDyS2SGSg
S2fIegyy_
_pSgIegyg_
SSSg
_pSgIeggg_
GIegg_
GIegg_
_pSgIeggg_
yycSg
$s14SiriTTSService22AudibleRequestProtocolP
ySay
GcSg
$s14SiriTTSService27SynthesizingRequestProtocolP
So7NSErrorCSgIeyByy_
IeyBy_
SgSo7NSErrorCSgIeyByy_
So7NSArrayCIeyBy_
So7NSErrorCSgIeyBy_
So8NSStringCSgSo7NSErrorCSgIeyByy_
SdSo7NSErrorCSgIeyByy_
S2fIeyByy_
IeyBy_
IeyBy_
ytIegnr_
Iegg_
GytIegnr_
GIegg_
ytIegnr_
Iegg_
ytIegr_
yyXlXpG
So7NSArrayCm
SDySo8NSStringCABG
SgXw
SgXw
So26SiriAnalyticsMessageStream_p
So14SPIPowerLoggerCSg
_SStG
_SSt
SDySSSaySo8TTSAssetCGG
SaySo12TTSAssetTypeCG
RawValue
audioSessionNotFound
avsbarNotInstantiated
playbackStalled
audioRouteName
isBluetoothRoute
isAppleProduct
vendorID
productID
volume
asbd
audioData
packetCount
packetDescriptions
audioInterface
audioOperationQueue
playbackError
audioSequence
averagePower
peakPower
discontinuedDuringPlayback
outputRouteInfo
audioQueue
startTime
enqueuedDuration
startSampleTime
enqueuedSampleCount
audioPlaybackAudioQueueUID
expectedPlaySampleTime
callback
_rawValue
_os_unfair_lock_opaque
mSampleTime
mHostTime
mRateScalar
mWordClockTime
mSMPTETime
mFlags
mReserved
value
timescale
flags
epoch
location
length
mSampleRate
mFormatID
mFormatFlags
mBytesPerPacket
mFramesPerPacket
mBytesPerFrame
mChannelsPerFrame
mBitsPerChannel
_ObjectiveCType
mSubframes
mSubframeDivisor
mCounter
mType
mHours
mMinutes
mSeconds
mFrames
rawValue
mStartOffset
mVariableFramesInPacket
mDataByteSize
notificationCenter
observers
requestId
realTimeFactor
ttsSynthesisLatency
ttsTotalLatency
audioQueueLatency
utterance
voiceAssetKey
resourceAssetKey
audioOutputRoute
clientBundleIdentifier
requestCreatedTime
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
RawValue
cacheStorage
preinstalledAudioStorage
preinstalledWordTimingStorage
notification
internalSettings
synthesizerID
voiceID
name
localizedNames
nameRoot
identifier
gender
demo
language
locale
version
scriptCode
voiceGroup
voiceType
desirability
supportedCharacters
individuallySpokenCharacters
diskSize
description
RawValue
filePath
count
mmappedData
mappedLength
fallbackInMemoryData
shouldCleanFile
storage
streamingHandlers
signals
lock
queue
lock
_activeSessionCount
_cachedEngine
notificationCenter
observers
signposter
synthesisInterval
voiceSelectionInternal
engineSelectionInterval
audioStartingInterval
playbackInterval
lock
value
lowInactiveMemory
grpcChannel
speechId
factorName
assetAttr
path
isDownloading
downloadToken
progressQueue
notification
engineCachingService
use_trial
enable_adhoc_voice
sirix
audioPlaybackStarted
synthesisStarted
synthesisEnded
requestReceived
audioGenerated
wordTimingGenerated
phonemesGenerated
voiceSelected
engineSelectEnd
voiceResourceSelected
encounteredError
encounteredIssue
audioPowerProviderAvailable
instrumentationMetricsAvailable
cancellationRequested
eagerRequestDetected
audioPlaybackStarting
audioPlaybackEnded
voiceSelectStart
engineSelectStart
receivedServerFirstPacket
receivedServerLastPacket
synthesisEngineChanged
synthesisUsedPrompt
neuralAlignmentStall
neuralAudioClick
neuralFallback
taskCompletion
registry
serverIdent
serverConnection
sandboxHandles
serverMutex
progressCallbacks
downloadedCallbacks
cancelledCallbacks
message
types
filter
reservation
immediately
callback
timeLeft
bytesDone
bytesRemaining
assets
attributes
cookie
bundle
authTokens
quality
downloading
RawValue
stagingURL
inKey
wantValue
text
source
name
firstMinor
voice
resource
AllCases
RawValue
graph
errorHandlers
_isCancelled
cancellationLock
notification
idContainer
buffer
bufferCondition
isProcessing
asyncError
waitTimeout
isProcessingCondition
action
conditional
asyncContext
_invalidated
cacheStorage
cacheFile
cacheHashKey
cachingQueue
internalSettings
notificationCenter
observers
canDumpAudio
fromFormat
toFormat
converter
buffer
cookie
assetQuality
bundlePath
authorizedBundle
proxy_attr
engineCachingService
notification
constructorRegistry
objectPool
asset
name
gender
quality
storageURL
notificationCenter
observers
audioPowerProvider
encoder
_disableTTS
_enableDiagnostic
_logSensitiveText
_disableCache
_overrideRequestsText
_disableAssetCleaning
_allowAnyAssetSubscriber
_defaultToNonDiscretionaryDownloads
_enableLocalVoices
_defaultVolume
_defaultPitch
_defaultRate
_whisper
_serverLogs
_serverTTSTimeout
_deviceTTSWaitTime
_disableDeviceRacing
_forceServerTTS
_disableServerTTS
_disableInlineStreamTTS
_disableOspreyStreaming
_streamBufferDuration
_useBetaVoice
_ospreyEndpointURL
_simulateNetworkStall
_simulateAudioStall
_disableDeviceNeuralTTS
_useSSMLInput
_disableMobileAssetURLReset
_ignorePowerAndThermalState
_disableAssetUpdate
defaults
stringKey
defaultValue
transform
asyncContext
streamingStorage
notificationCenter
observers
internalSettings
decoderDescription
signal
request
receivedAudioDuration
bufferDuration
bufferedOutput
timeout
RawValue
code
description
success
unknown
crash
cancelled
noVoice
invalidVoice
lowSynthesisRTF
compactNeural
audioUnknownError
audioDiscontinuity
ospreyUnknownError
ospreyNetworkTimeout
ospreyNetworkStall
ospreyInvalidAudioFormat
inlineStreamUnknownError
inlineStreamNetworkStall
inlineStreamTimeout
nodes
edges
settings
asset
attr
assetAttr
RawValue
AllCases
heySiriCapabilities
heySiriClock
heySiriClockPlankTimer
heySiriHome
heySiriMusic
heySiriNews
heySiriWeather
heySiriWeather2
siriCapabilities
siriCapabilityClock
siriCapabilityHome
siriCapabilityMusic
siriCapabilityNews
siriCapabilityWeather
siriIntro
trySay0
trySay1
notificationCenter
observers
delegate
request
audioFile
packetOffset
asyncContext
queue
settings
entitlements
diagnosticAudioFile
synthesizedAudioFile
diagnosticTag
supportedLanguages
name
identifier
assistantGender
assistantOrder
voicesForLanguageMap
deprecatedVoicesMap
relativePitchOrderForVoicesMap
relativeOrderForVoicesMap
identifiersForVoicesMap
notificationCenter
observers
coreAnalyticsService
instrumentationMetrics
audioStartingTimestamp
voice
path
resource
allowExpensiveData
allowDiscretionary
downloadQueue
notificationCenter
observers
asyncContext
internalSettings
ospreyClient
ospreyConfig
timeout
cacheStorage
streamingStartedDate
localAssetProvider
trialAssetProvider
builtInVoiceProvider
vocalizerCustomVoiceProvider
preinstalledVoiceProvider
notification
internalSettings
buffer
notificationCenter
error
audioQueueBufferLock
renderer
synchronizer
dataQueue
stateLock
mappedAudioQueuedTimeStamp
rendererEnqueuedAudioDuration
mappedData
enqueuedMappedAudioInfo
startedProvidingData
noRemainTasks
asbd
discontinuedDuringPlayback
audioPowerProvider
sampleBuffer
audioBytesRange
packetCount
packetDescriptionsRange
endOfSiriTTSUtterance
finishCallback
paused
started
waitForFinish
stopped
RawValue
timeoutDate
waitCondition
queue
shouldStop
phonemes
estimationDictionary
alphabet
phoneme
asyncContext
buffer
audioPlayback
audibleRequest
notificationCenter
observers
asyncContext
queue
notificationCenter
observers
internalSettings
synthesisConfig
_isCancelled
defaults
fromFormat
toFormat
converter
buffer
Element
Iterator
storageURL
fileURL
handle
voice
resource
audio
timingInfos
magicVersion
RawValue
asset
$__lazy_storage_$_voiceDesc
storageURL
timeout
deviceWaitTime
allowedAppIdentifiers
configs
delegate
connection
weakDelegate
asyncProxy
syncProxy
RawValue
startTime
textRange
utterance
voice
resource
audioOutputRoute
clientBundleIdentifier
experimentIdentifier
requestCreatedTime
eagerRequestGapInterval
synthesisBeginTime
synthesisEndTime
speechBeginTime
speechEndTime
speechEstimatedOutputBeginTime
audioStartLatency
serverFirstPacketTime
serverLastPacketTime
serverStreamedAudioDuration
audioDuration
isWarmStart
sourceOfTTS
privacySensitive
errorCode
isServerTTSRacing
promptCount
neuralAlignmentStall
neuralAudioClick
neuralFallback
isAudibleRequest
audioSessionId
immediate
siriRequestId
didStartSpeaking
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceDuration
neuralSentenceEnergy
neuralSentenceTilt
text
contextInfo
rate
pitch
volume
customResourceURLs
synthesisProfile
disableCompactVoice
didGenerateAudio
didGenerateWordTimings
whisper
prosodyProperties
forceOspreyTTS
clientBundleId
accessoryId
outputPath
didReportInstrument
audio
audibleContext
synthesisContext
phonemeSystem
language
name
footprint
type
gender
version
clientId
identifier
$__lazy_storage_$__sessionConnection
_connectionLock
requestsLock
requests
_keepActive
_clientId
asyncContext
notificationCenter
observers
ospreyClient
notificationCenter
observers
ttsId
requestId
contextId
siriStream
siriPowerLogger
metrics
expectedVoice
selectedVoice
selectedResource
routeInfo
encounteredIssues
sources
assetTypes
SiriTTSPhonemeTool
SiriTTSSynthesisEngineResource
SiriTTSSynthesisEngineWordTimings
SiriTTSSynthesisEngineRequest
SiriTTSSynthesisEngine
SiriTTSNeuralUtils
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequestProsodyControlConfig
OPTTSMutableTTSWordPhonemes
OPTTSMutableTTSPhonemeSequence
OPTTSMutableTTSNeuralPhonemeSequence
OPTTSMutableTTSPrompts
OPTTSMutableTTSReplacement
OPTTSMutableTTSNormalizedText
OPTTSMutableTextToSpeechFeature
OPTTSMutableTextToSpeechRequestDebug
OPTTSMutableTextToSpeechVoiceResource
OPTTSMutableTextToSpeechUserProfile
OPTTSMutableTextToSpeechRequestDevConfig
OPTTSMutableTextToSpeechSpeechFeatureInputWave
OPTTSMutableTextToSpeechUserVoiceProfile
OPTTSMutableTextToSpeechRequestProsodyTransferConfig
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequestProsodyControlConfig
OPTTSTTSWordPhonemes
OPTTSTTSPhonemeSequence
OPTTSTTSNeuralPhonemeSequence
OPTTSTTSPrompts
OPTTSTTSReplacement
OPTTSTTSNormalizedText
OPTTSTextToSpeechFeature
OPTTSTextToSpeechRequestDebug
OPTTSTextToSpeechVoiceResource
OPTTSTextToSpeechUserProfile
OPTTSTextToSpeechRequestDevConfig
OPTTSTextToSpeechSpeechFeatureInputWave
OPTTSTextToSpeechUserVoiceProfile
OPTTSTextToSpeechRequestProsodyTransferConfig
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
SiriTTSService_Bridge
SiriTTSOspreyRequest
OspreyBridge
SiriTTSOspreyStreamingBeginResponse
SiriTTSOspreyWordTimingInfo
SiriTTSOspreyStreamingPartialResponse
SiriTTSOspreyChannel
SiriTTSService_TTSAXResource
SiriTTSService_TTSAXResourceManager
SiriTTSAudioHardware
TTSAsset
TTSStringEnum
TTSAssetQuality
TTSAssetServer
TTSAssetSource
TTSAssetTechnology
TTSAssetType
SwiftProxy
OS_xpc_object
AVQueuedSampleBufferRendering
NSSecureCoding
NSObject
TRINotificationToken
SiriAnalyticsMessageStream
NSCoding
NSXMLParserDelegate
T@"NSArray",C,N
.cxx_destruct
T@"NSString",C,N,V_experimentId
T#,R
T@"SiriTTSAudibleContext",&,D,N
T@"NSArray",R,N,V_supportedLanguages
Tf,N,V_neuralSentencePitchRange
T@"NSBundle",R,N,V_bundle
Tq,R,V_vendorId
T@"NSData",R,N
_bundle
T@"NSDictionary",R,N,V_attributes
_handle
T@"NSNumber",R,N,V_age
_string
T@"NSObject<FLTBFBufferAccessor><NSCopying>",C,D,N
_volume
T@"NSString",&,N,V_language
assistantGender
T@"NSString",&,N,V_name
bundleForClass:
T@"NSString",&,N,V_tag
cancelDownload:
T@"NSString",C,N
compact
T@"NSString",C,N,V_language
content_typeForImmutableObject:
T@"NSString",C,N,V_text
dealloc
T@"NSString",R,C
fe_feature_only
T@"NSString",R,N,V_identifier
fileHandleForUpdatingURL:error:
T@"NSString",R,N,V_primaryLanguage
getLocalFileUrl
T@"NSString",R,N,V_string
hasPath
T@"NSString",R,N,V_voiceFootprint
initWithNSUUID:
T@"NSString",R,N,V_voiceLanguage
isProxy
T@"NSString",R,N,V_voicePath
normalized_text
T@"NSString",R,V_routeType
opaqueSessionID
T@"OPTTSAudioDescription",R,N
phoneme_sequence_objectAtIndex:
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
primaryLanguage
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
prompts
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
refresh
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
release
T@"OPTTSTTSRequestFeatureFlags",R,N
resourceVersion
T@"OPTTSTextToSpeechFeature",R,N
results
T@"OPTTSTextToSpeechMeta",R,N
setContextInfo:
T@"OPTTSTextToSpeechRequestContext",R,N
setEnergy_mean:
T@"OPTTSTextToSpeechRequestDebug",R,N
setGlobal_rate:
T@"OPTTSTextToSpeechRequestDevConfig",R,N
setIsWarmStart:
T@"OPTTSTextToSpeechRequestExperiment",R,N
setPacketCount:
T@"OPTTSTextToSpeechRequestMeta",R,N
setReplacement:
T@"OPTTSTextToSpeechRequestProsodyControlConfig",R,N
setServerStreamedAudioDuration:
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",R,N
setSynthesizer:
T@"OPTTSTextToSpeechResource",R,N
setVoiceAccent:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",R,N
speechBeginTime
T@"OPTTSTextToSpeechUserProfile",R,N
T@"OPTTSTextToSpeechUserVoiceProfile",R,N
unloadResource:
T@"OPTTSTextToSpeechVoice",R,N
version
T@"SiriTTSService_TTSAXResourceManager",R,N
word_timing_info_objectAtIndex:
.cxx_construct
T@"NSArray",R,N
NewAssetNotification
T@"NSString",R,N,V_resourcePath
T@"NSArray",&,N,V_allCompactResources
T@?,C,N,V_neuralFallbackHandler
T@"NSArray",R,N,V_timingInfos
Tq,R,N,V_gender
T@"NSData",C,N
_bufferDuration
T@"NSData",R,N,V_audioData
_gender
T@"NSLock",&,N,V_lock
_isAppleProduct
T@"NSNumber",R,N,V_diskSize
_voiceFootprint
T@"NSObject<FLTBFBufferAccessor><NSCopying>",R,N
T@"NSString",&,N,V_mimeType
audioBufferList
T@"NSString",&,N,V_path
bytes_per_frame
T@"NSString",&,N,V_text
captureSnapshot
T@"NSString",C,N,V_appId
content
T@"NSString",C,N,V_speechId
context
T@"NSString",C,N,V_voiceName
downloadedVoicesMatching:reply:
T@"NSString",R,N
feature
T@"NSString",R,N,V_name
framesPerPacket
T@"NSString",R,N,V_resourceLanguage
gryphon
T@"NSString",R,N,V_versionDescription
initWithDouble:
T@"NSString",R,N,V_voiceGender
initWithString:
T@"NSString",R,N,V_voiceName
T@"NSString",R,N,V_voiceType
T@"OPTTSAudioDescription",C,N
parser:validationErrorOccurred:
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
premium
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
profile
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
quality
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
relatedAssetsWithOnlyAvailable:
T@"OPTTSTTSRequestFeatureFlags",C,N
removeObserver:
T@"OPTTSTextToSpeechFeature",C,N
resources_count
T@"OPTTSTextToSpeechMeta",C,N
setAccessoryId:
T@"OPTTSTextToSpeechRequestContext",C,N
setDoNotBlockBeforeFirstUnlock:
T@"OPTTSTextToSpeechRequestDebug",C,N
setFrameLength:
T@"OPTTSTextToSpeechRequestDevConfig",C,N
setGrpcChannel:
T@"OPTTSTextToSpeechRequestExperiment",C,N
setKey:
T@"OPTTSTextToSpeechRequestMeta",C,N
setPromptCount:
T@"OPTTSTextToSpeechRequestProsodyControlConfig",C,N
setSample_rate:
T@"OPTTSTextToSpeechRequestProsodyTransferConfig",C,N
setSourceOfTTS:
T@"OPTTSTextToSpeechResource",C,N
setTag:
T@"OPTTSTextToSpeechSpeechFeatureInputWave",C,N
setVoiceGender:
T@"OPTTSTextToSpeechUserProfile",C,N
staging
T@"OPTTSTextToSpeechUserVoiceProfile",C,N
textToPhonemeWithRequest:reply:
T@"OPTTSTextToSpeechVoice",C,N
valueWithRange:
T@"OspreyChannel",&,N,V_grpcChannel
whisper
T@"SiriTTSSynthesisContext",&,D,N
T@"TTSAXResourceManager",&,N,V_axManager
T@"TTSAssetQuality",R,N,V_quality
T@"TTSAssetSource",R,N,V_assetSource
T@"TTSAssetTechnology",R,N,V_technology
T@"TTSAssetType",R,N,V_assetType
T@?,C,N,V_audioHandler
T@?,C,N,V_promptHandler
T@?,C,N,V_wordTimingsHandler
TB,N
TB,N,V_privacySensitive
TB,N,V_serverLogs
TB,R
TB,R,GisReadyForMoreMediaData
TB,R,N
TB,R,V_isAppleProduct
TB,R,V_isBluetooth
TI,N
TI,R,N
TQ,N,V_profile
TQ,N,V_requestCreatedTime
TQ,R
T^v,N,V_synthesizer
T^{OpaqueCMTimebase=},R,&
Td,N
Td,N,V_startTime
Td,N,V_timestamp
Td,R,N
Td,R,N,V_bufferDuration
Tf,N
Tf,N,V_neuralSentenceDuration
Tf,N,V_neuralSentenceEnergy
Tf,N,V_neuralSentencePitch
Tf,N,V_neuralSentenceTilt
Tf,N,V_pitch
Tf,N,V_rate
Tf,N,V_volume
Tf,R,N
Tf,R,V_volume
Ti,N
Ti,R,N
Tq,N
Tq,R,N
Tq,R,N,V_resourceVersion
Tq,R,N,V_versionNumber
Tq,R,N,V_voiceVersion
Tq,R,V_productId
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{_NSRange=QQ},N,V_textRange
T{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}},V_handle
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLForResource:withExtension:subdirectory:
URLsForDirectory:inDomains:
UTF8String
UUID
UUIDString
__swift_objectForKeyedSubscript:
_age
_allCompactResources
_appId
_asbd
_assetSource
_assetType
_attributes
_audioData
_audioHandler
_axManager
_data
_diskSize
_experimentId
_grpcChannel
_gryphonVoiceCompatibility
_hasTrialEntitlements
_identifier
_isBluetooth
_language
_lock
_mimeType
_name
_neuralFallbackHandler
_neuralSentenceDuration
_neuralSentenceEnergy
_neuralSentencePitch
_neuralSentencePitchRange
_neuralSentenceTilt
_path
_pitch
_postNewAssetNotification
_preheatWithError:
_primaryLanguage
_privacySensitive
_productId
_profile
_promptHandler
_quality
_rate
_requestCreatedTime
_resourceLanguage
_resourcePath
_resourceVersion
_root
_routeType
_serverLogs
_speechId
_startTime
_storage
_supportedLanguages
_synthesizer
_tag
_technology
_text
_textRange
_timestamp
_timingInfos
_unlockedLoadResourceWithPath:error:
_unlockedStopSynthesis
_unlockedSynthesize:error:
_unlockedUnloadResource:
_vendorId
_versionDescription
_versionNumber
_voiceGender
_voiceLanguage
_voiceName
_voicePath
_voiceType
_voiceVersion
_wordTimingsHandler
accessoryId
addBoundaryTimeObserverForTimes:queue:usingBlock:
addKeyValueArray:with:
addObject:
addObjectToBuffer:
addObserver:selector:name:object:
addObserverForName:object:queue:usingBlock:
addRenderer:
addUpdateHandlerForNamespaceName:queue:usingBlock:
adhoc
allCompactResources
allocWithZone:
appId
app_id
archivedDataWithRootObject:requiringSecureCoding:error:
array
asbd
assetSource
assetType
assistantOrder
assistantVoiceMaps
attachProgressCallBack:
attributes
audibleContext
audio
audio:
audioData
audioDuration
audioHandler
audioInfo
audioInterface
audioOutputRoute
audioSession
audioSessionId
audioStartLatency
audioStreamBasicDescription
audio_type
autorelease
availableLanguages
axManager
barrierWithCompletion:
bestAssetOfTypes:matching:
beta
bitsPerChannel
bits_per_channel
boolForKey:
boolValue
broadcast
bufferDuration
bundle
bundleIdentifier
bundlePath
bundleURL
bundleWithIdentifier:
bytes
bytesPerFrame
bytesPerPacket
bytes_per_packet
cancelDownloadingThen:
cancelWithRequest:
channel_type
channelsPerFrame
channels_per_frame
class
clientBundleIdentifier
clientId
clientWithIdentifier:
closeAndReturnError:
closeFile
combinedVoice
compileANEModel:error:
componentsJoinedByString:
conformsToProtocol:
contentAsOPTTSBeginTextToSpeechStreamingResponse
contentAsOPTTSFinalTextToSpeechStreamingResponse
contentAsOPTTSPartialTextToSpeechStreamingResponse
contentAsOPTTSStartTextToSpeechStreamingRequest
contentPath
contentVersion
content_immutableClassForType:
content_mutableClassForType:
content_type
content_typeForMutableObject:
content_typeForObject:
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
contextInfo
context_info
context_info_count
context_info_enumerateObjectsUsingBlock:
context_info_objectAtIndex:
convertLanguageCodeToSchemaLocale:
convertToBuffer:error:withInputFromBlock:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createFileAtPath:contents:attributes:
currentTime
current_pkt_number
custom
customResourceURLs
customVoice
data
data:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
debug
debugDescription
decodeBoolForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntegerForKey:
decodeObjectForKey:
decoderStreamDescription
decoder_description
defaultCenter
defaultManager
defaultOutput
defaultSessionConfiguration
deprecatedVoicesMap
derivedIdentifierForComponentName:fromSourceIdentifier:
describeServer:forType:
describeServer:source:
description
dev_config
dialog_identifier
dictionary
dictionaryForKey:
dictionaryWithObjects:forKeys:count:
didGenerateAudio
didGenerateAudioWithRequestId:audio:
didGenerateWordTimings
didGenerateWordTimingsWithRequestId:wordTimingInfo:
didReportInstrument
didReportInstrumentWithRequestId:instrumentationMetrics:
didStartSpeaking
didStartSpeakingWithRequestId:
directoryValue
disableCompactVoice
disable_cache
diskSize
doubleValue
downloadLevelsForFactors:withNamespace:queue:options:progress:completion:
downloadWithReservation:useBattery:progress:then:
downloading
duration_mean
duration_std
eagerRequestGapInterval
emitMessage:
emitMessage:timestamp:
enable_word_timing_info
encodeBool:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeWithCoder:
energy_mean
energy_std
enqueueLargeMessageObjectFromPath:assetIdentifier:messageMetadata:completion:
enqueueSampleBuffer:
enumerateMatchesInString:options:range:usingBlock:
enumerateObjectsUsingBlock:
errorCode
errorMessage
errorWithDomain:code:userInfo:
error_code
error_str
estimateDurationWithRequest:didFinish:
estimateDurationWithRequest:reply:
eventMetadata
expectedTimeRemaining
experiment
experimentId
experimentIdentifier
experiment_identifier
factor
factorLevelsWithNamespaceName:
fallbackLanguageFor:
fe_feature
feature_flags
fetchHardwareInfo
fileDescriptor
fileExistsAtPath:
fileExistsAtPath:isDirectory:
fileHandleForUpdatingAtPath:
flatbuffData
floatForKey:
floatValue
flush
footprint
forceOspreyTTS
force_use_tts_service
formatFlags
formatID
format_flags
format_id
forwardWithStreamObject:
frameLength
frames_per_packet
gender
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAudioPower:
getAudioPowerWithAccessoryId:reply:
getBytes:length:
getServerForType:
getServerForType:source:
getSynthesisVoiceMatching:reply:
global_energy
global_pitch
global_rate
global_sent_duration
global_sent_energy
global_sent_pitch
global_sent_pitchrange
global_sent_tilt
globallyUniqueString
grpcChannel
gryphonVoice
handle
handleMediaServerReset
handleProxyEvent:reply:connection:
hasAMX
hasANE
hasAsset
hasPhaticResponsesWithVoicePath:
hasSufficientMediaDataForReliablePlaybackStart
hash
homepodSetupStringWithKey:language:
identifier
identifiersForVoicesMap
immediate
immediateDownloadForNamespaceNames:allowExpensiveNetworking:error:
infoDictionary
init
initAndVerifyWithFlatbuffData:
initFromFormat:toFormat:
initWithAccessoryId:
initWithArray:
initWithAudio:
initWithBool:
initWithBytes:length:encoding:
initWithBytesNoCopy:length:deallocator:
initWithCoder:
initWithContentsOfFile:
initWithContentsOfURL:
initWithContentsOfURL:options:error:
initWithCurrentProcess
initWithData:
initWithDomain:code:userInfo:
initWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
initWithFloat:
initWithFormat:packetCapacity:maximumPacketSize:
initWithInt:
initWithInteger:
initWithLanguage:
initWithLanguage:name:
initWithMachServiceName:options:
initWithOspreyBeginResponse:
initWithOspreyPartialResponse:
initWithPCMFormat:frameCapacity:
initWithPath:
initWithPattern:options:error:
initWithStartTiming:textRange:
initWithStreamDescription:
initWithSuiteName:
initWithText:identifier:
initWithText:voice:
initWithText:voice:phonemeSystem:
initWithType:
initWithURL:
initWithURL:configuration:
initWithUUIDBytes:
initWithUnsignedInteger:
initWithVoice:clientId:accessoryId:
initWithVoicePath:resourcePath:error:
initializeDeviceAuthenticationSessionWithCompletion:
intValue
integerForKey:
integerValue
interfaceWithProtocol:
invalidate
isANEModelCompiled:
isANEModelCompiledMatching:reply:
isANEOnly
isAppleProduct
isAudibleRequest
isBluetooth
isCatalogFetchedWithinThePastFewDays:
isCustom
isDeletableFileAtPath:
isEqual:
isH12Platform
isInstalled
isKindOfClass:
isLowPowerModeEnabled
isMemberOfClass:
isNeuralPlatform
isNeuralVoiceReady:
isNewer:
isOlder:
isReadyForMoreMediaData
isServerTTSRacing
isSpeaking:
isSpeakingWithAccessoryId:reply:
isWarmStart
keepActive
keepActive:reply:
killDaemon
language
languageCode
legacyAssetWithBundle:
length
level
levelForFactor:withNamespaceName:
linkId
listAssetsOfTypes:matching:
livability
loadResourceWithPath:error:
localizedDescription
locallyAvailable
lock
logWithEventContext:ttsIdentifier:
loggerForCurrentProcess
macintalk
macintalkVoice
macosLegacy
mainBundle
maximumOutputPacketSize
meta_info
metadata
mimeType
mobileAsset
mutableAudioBufferList
name
neural
neuralAX
neuralAlignmentStall
neuralAudioClick
neuralFallback
neuralFallbackHandler
neuralSentenceDuration
neuralSentenceEnergy
neuralSentencePitch
neuralSentencePitchRange
neuralSentenceTilt
neural_phoneme_sequence
neural_phoneme_sequence_count
neural_phoneme_sequence_enumerateObjectsUsingBlock:
neural_phoneme_sequence_objectAtIndex:
normalized_text_count
normalized_text_enumerateObjectsUsingBlock:
normalized_text_objectAtIndex:
numberOfMatchesInString:options:range:
objectAtIndexedSubscript:
objectForInfoDictionaryKey:
objectForKey:
objectForKeyedSubscript:
offset
operatingSystemVersion
original
outputPath
packetCount
packetDescriptions
parse
parser:didEndElement:namespaceURI:qualifiedName:
parser:didEndMappingPrefix:
parser:didStartElement:namespaceURI:qualifiedName:attributes:
parser:didStartMappingPrefix:toURI:
parser:foundAttributeDeclarationWithName:forElement:type:defaultValue:
parser:foundCDATA:
parser:foundCharacters:
parser:foundComment:
parser:foundElementDeclarationWithName:model:
parser:foundExternalEntityDeclarationWithName:publicID:systemID:
parser:foundIgnorableWhitespace:
parser:foundInternalEntityDeclarationWithName:value:
parser:foundNotationDeclarationWithName:publicID:systemID:
parser:foundProcessingInstructionWithTarget:data:
parser:foundUnparsedEntityDeclarationWithName:publicID:systemID:notationName:
parser:parseErrorOccurred:
parser:resolveExternalEntityName:systemID:
parserDidEndDocument:
parserDidStartDocument:
path
pathComponent
pathForResource:ofType:
pathForResource:ofType:inDirectory:
pcm_data
pcm_data:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
phonemeSystem
phoneme_sequence
phoneme_sequence_count
phoneme_sequence_enumerateObjectsUsingBlock:
phonemes
phonemes_count
phonemes_enumerateObjectsUsingBlock:
phonemes_objectAtIndex:
pingWithReply:
pitch
pitch_mean
pitch_std
playback_description
postNotificationName:object:
preconnect
preferred_voice_type
preheatWithError:
preinstalled
premiumhigh
prewarmWithRequest:didFinish:
prewarmWithRequest:reply:
privacySensitive
processInfo
processServerLogs:
productId
production
promptCount
promptHandler
prompts_count
prompts_enumerateObjectsUsingBlock:
prompts_objectAtIndex:
prompts_v2
prompts_v2:
prosodyProperties
prosody_config
prosody_control_config
purge
purgeImmediately:
purgeSync
purgeable
queryMetaDataSync
queryPhaticCapabilityWithVoice:reply:
rangeAtIndex:
rangeValue
rate
readDataOfLength:
readyForMoreMediaData
refreshState
relativeOrderForVoicesMap
relativePitchOrderForVoicesMap
remoteObjectProxyWithErrorHandler:
removeDownloadStatusHandlersWithToken:
removeItemAtPath:error:
removeItemAtURL:error:
removeLevelsForFactors:withNamespace:queue:completion:
removeLevelsForFactorsImmediately:withNamespace:queue:completion:
removeObjectForKey:
removeTimeObserver:
renderers
replacement
replacement_count
replacement_enumerateObjectsUsingBlock:
replacement_objectAtIndex:
requestCreatedTime
requestMediaDataWhenReadyOnQueue:usingBlock:
requestedVoiceContext
reserved
reset
resolvePartialMessage:
resolvePartialMessage:timestamp:
resource
resourceLanguage
resourcePath
resourceURL
resource_asset_path
resources
resourcesWithType:subType:
resources_enumerateObjectsUsingBlock:
resources_objectAtIndex:
respondsToSelector:
resume
retain
retainCount
retrieveSessionWithID:
returnTypes:
return_log
return_server_info
rolloutIdentifiersWithNamespaceName:
roughEstimationWithRequest:
routeType
sampleRate
sample_idx
sample_rate
seekToOffset:error:
self
serverFirstPacketTime
serverLastPacketTime
serverLogs
serverStreamedAudioDuration
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
session_id
setAllCompactResources:
setAllowsCellularAccess:
setAllowsExpensiveAccess:
setAppId:
setApp_id:
setAsbd:
setAudibleContext:
setAudio:
setAudioData:
setAudioDuration:
setAudioHandler:
setAudioInterface:
setAudioOutputRoute:
setAudioSession:
setAudioSessionId:
setAudioStartLatency:
setAudio_type:
setAxManager:
setBits_per_channel:
setByteLength:
setBytes_per_frame:
setBytes_per_packet:
setCancelled:
setChannel_type:
setChannels_per_frame:
setClasses:forSelector:argumentIndex:ofReply:
setClientBundleIdentifier:
setClientId:
setClientTraceIdentifier:
setComponent:
setContent:
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContent_type:
setContext:
setContextId:
setContext_info:
setCurrent_pkt_number:
setCustomResourceURLs:
setCustomerPerceivedLatencyInSecond:
setData:
setDebug:
setDecoder_description:
setDelaysRateChangeUntilHasSufficientMediaData:
setDelegate:
setDev_config:
setDialog_identifier:
setDidGenerateAudio:
setDidGenerateWordTimings:
setDidReportInstrument:
setDidStartSpeaking:
setDisableCompactVoice:
setDisable_cache:
setDiscretionary:
setDiscretionaryBehavior:
setDoNotBlockOnNetworkStatus:
setDuration_mean:
setDuration_std:
setEagerRequestGapInterval:
setEnable_word_timing_info:
setEnded:
setEnergy_std:
setErrorCode:
setErrorCodes:
setError_code:
setError_str:
setEventMetadata:
setExists:
setExperiment:
setExperimentId:
setExperimentIdentifier:
setExperiment_identifier:
setExportedInterface:
setExportedObject:
setFailed:
setFe_feature:
setFe_feature_only:
setFeature:
setFeature_flags:
setFootprint:
setForceOspreyTTS:
setForce_use_tts_service:
setFormat_flags:
setFormat_id:
setFrames_per_packet:
setGender:
setGlobal_energy:
setGlobal_pitch:
setGlobal_sent_duration:
setGlobal_sent_energy:
setGlobal_sent_pitch:
setGlobal_sent_pitchrange:
setGlobal_sent_tilt:
setHandle:
setImmediate:
setInputTextLength:
setInterruptionHandler:
setInvalidationHandler:
setIsAudibleRequest:
setIsServerTTSRacing:
setKeepActive:
setLanguage:
setLength:
setLinkId:
setLock:
setMeta_info:
setMimeType:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralFallback:
setNeuralFallbackHandler:
setNeuralSentenceDuration:
setNeuralSentenceEnergy:
setNeuralSentencePitch:
setNeuralSentencePitchRange:
setNeuralSentenceTilt:
setNeural_phoneme_sequence:
setNormalized_text:
setObject:forKey:
setObject:forKeyedSubscript:
setOffset:
setOriginal:
setOutputPath:
setPacketDescriptions:
setPath:
setPcm_data:
setPhonemeSystem:
setPhoneme_sequence:
setPhonemes:
setPitch:
setPitch_mean:
setPitch_std:
setPlayback_description:
setPreferred_voice_type:
setPrivacySensitive:
setProductId:
setProfile:
setPromptHandler:
setPrompts:
setPrompts_v2:
setProsodyProperties:
setProsody_config:
setProsody_control_config:
setQuality:
setRate:
setRate:time:
setRemoteObjectInterface:
setRequestCreatedTime:
setRequestId:
setRequestReceived:
setRequestReceivedTier1:
setRequestedVoiceContext:
setRequiresPowerPluggedIn:
setReserved:
setResource:
setResourceVersion:
setResource_asset_path:
setResources:
setReturn_log:
setReturn_server_info:
setSample_idx:
setServer:forType:
setServer:forType:source:
setServerFirstPacketTime:
setServerLastPacketTime:
setServerLogs:
setSession_id:
setSiriRequestId:
setSource:
setSpeechBeginTime:
setSpeechContext:
setSpeechEndTime:
setSpeechEstimatedOutputBeginTime:
setSpeechId:
setSpeech_id:
setStartTime:
setStartedOrChanged:
setStream_id:
setStreaming_playback_buffer_size_in_seconds:
setSupportsSecureCoding:
setSynthesisBeginTime:
setSynthesisContext:
setSynthesisEffect:
setSynthesisEndTime:
setSynthesisLatencyInSecond:
setSynthesisProfile:
setSynthesisRealTimeFactor:
setSynthesisSource:
setSynthesizedAudioDurationInSecond:
setTarget:
setText:
setTextRange:
setTextToSynthesize:
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
setTimestamp:
setTotal_pkt_number:
setTtsId:
setType:
setUseCompression:
setUser_voice_profile:
setUser_voice_profile_url:
setUtterance:
setUuid:
setValue:
setVendorId:
setVersion:
setVoice:
setVoiceContext:
setVoiceFallbackOccurred:
setVoiceFootprint:
setVoiceName:
setVoiceSettings:
setVoiceType:
setVoiceVersion:
setVoice_asset_path:
setVoice_name:
setVolume:
setWave_data:
setWhisper:
setWord:
setWordTimingsHandler:
setWord_phonemes:
setWord_timing_info:
sharedInstance
sharedStream
shouldUseNeuralVoice:
signal
signalWithInlineStreaming:
siriRequestId
sleepForTimeInterval:
sourceOfTTS
speakWithAudioRequest:didFinish:
speakWithAudioRequest:reply:
speakWithSpeechRequest:didFinish:
speakWithSpeechRequest:reply:
speechEndTime
speechEstimatedOutputBeginTime
speechId
speechSynthesisResource
speechSynthesisVoice
speech_id
startCatalogDownload:options:then:
startDownload:then:
startTime
state
statusOfDownloadForFactors:withNamespace:token:queue:progress:completion:
stopRequestingMediaData
stopSynthesis
streamDescription
streamId
streamTTS:beginHandler:chunkHandler:completion:
stream_id
streamingPlaybackBufferSize
streaming_playback_buffer_size_in_seconds
string
stringByReplacingOccurrencesOfString:withString:
stringForKey:
stringWithFormat:
stringWithUTF8String:
subscribeWithVoices:clientId:accessoryId:reply:
subscribeWithVoices:reply:
subscribedVoicesWithClientId:reply:
subscribedVoicesWithReply:
superclass
supportedLanguages
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
synthesisBeginTime
synthesisContext
synthesisEndTime
synthesisProfile
synthesize:error:
synthesizeWithRequest:didFinish:
synthesizeWithRequest:reply:
synthesizer
technology
temporaryDirectory
text
textRange
textToPhonemeWithRequest:didFinish:
thermalState
timebase
timestamp
timingInfos
totalExpected
totalWritten
total_pkt_number
turiTrial
type
underlyingRequest
unlock
unsignedIntValue
unsignedIntegerValue
user_voice_profile
user_voice_profile_url
utterance
value
valueForEntitlement:
valueWithCMTime:
vendorId
versionDescription
versionNumber
vocalizer
vocalizerVoice
voice
voiceAssetKey
voiceContext
voiceFootprint
voiceGender
voiceLanguage
voiceName
voicePath
voiceResourceAssetKey
voiceResources
voiceSettings
voiceType
voiceVersion
voice_asset_path
voice_name
voicesForLanguageMap
volume
wait
waitForCatalogUpdates
waitUntilDate:
wasLocal
wave_data
word
wordTimingInfoList
wordTimingsHandler
word_phonemes
word_phonemes_count
word_phonemes_enumerateObjectsUsingBlock:
word_phonemes_objectAtIndex:
word_timing_info
word_timing_info_count
word_timing_info_enumerateObjectsUsingBlock:
zone
@48@0:8@16@24q32^@40
@16@0:8
v24@0:8@16
{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16@0:8
v32@0:8{shared_ptr<SiriTTS::VoiceResource>=^{VoiceResource}^{__shared_weak_count}}16
v16@0:8
@"NSString"
{shared_ptr<SiriTTS::VoiceResource>="__ptr_"^{VoiceResource}"__cntrl_"^{__shared_weak_count}}
d16@0:8
v24@0:8d16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
B16@0:8
v20@0:8B16
f16@0:8
v20@0:8f16
Q16@0:8
v24@0:8Q16
@?16@0:8
v24@0:8@?16
B24@0:8@16
@40@0:8@16@24^@32
B32@0:8@16^@24
B24@0:8^@16
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^v16@0:8
v24@0:8^v16
@"NSLock"
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8q16
i16@0:8
v20@0:8i16
I16@0:8
v20@0:8I16
#24@0:8q16
q24@0:8@16
@"NSData"16@0:8
@24@0:8@16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
@"NSData"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
@24@0:8Q16
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyControlConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyControlConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyControlConfig=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^v16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^v16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSNeuralPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNeuralPhonemeSequence>=I}24@0:8^v16
r^{TTSNeuralPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^v16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^v16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^v16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^v16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^v16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^v16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^v16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDevConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDevConfig>=I}24@0:8^v16
r^{TextToSpeechRequestDevConfig=[1C]}
@32@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24
@36@0:8@16r^{TextToSpeechSpeechFeatureInputWave=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechSpeechFeatureInputWave>=I}24@0:8^v16
r^{TextToSpeechSpeechFeatureInputWave=[1C]}
@32@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserVoiceProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserVoiceProfile>=I}24@0:8^v16
r^{TextToSpeechUserVoiceProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24
@36@0:8@16r^{TextToSpeechRequestProsodyTransferConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestProsodyTransferConfig>=I}24@0:8^v16
r^{TextToSpeechRequestProsodyTransferConfig=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@"NSArray"
@32@0:8@16@24
v48@0:8@16@?24@?32@?40
@"OspreyChannel"
@"TTSAXResourceManager"
@"TTSAssetType"
@"TTSAssetSource"
@"TTSAssetTechnology"
@"TTSAssetQuality"
@"NSNumber"
@"NSDictionary"
@"NSBundle"
v24@0:8^{opaqueCMSampleBuffer=}16
v32@0:8@16@?24
^{OpaqueCMTimebase=}16@0:8
v32@0:8@"OS_dispatch_queue"16@?<v@?>24
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16Q24
v48@0:8@16@24@32@?40
v24@0:8@"SISchemaTopLevelUnionType"16
v32@0:8@"SISchemaTopLevelUnionType"16Q24
v48@0:8@"NSString"16@"NSUUID"24@"SISchemaInstrumentationMessage"32@?<v@?B@"NSError">40
v24@0:8@?<v@?>16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
v40@0:8@16@24@32
v32@0:8@16@24
@40@0:8@16@24@32
v24@0:8@"NSXMLParser"16
v48@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSString"48
v40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v56@0:8@"NSXMLParser"16@"NSString"24@"NSString"32@"NSString"40@"NSDictionary"48
v32@0:8@"NSXMLParser"16@"NSString"24
v32@0:8@"NSXMLParser"16@"NSData"24
@"NSData"40@0:8@"NSXMLParser"16@"NSString"24@"NSString"32
v32@0:8@"NSXMLParser"16@"NSError"24
Logs
SiriTTSService
ar-SA
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
en-scotland
es-AR
es-CO
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hu-HU
id-ID
it-IT
ja-JP
ko-KR
nl-BE
nl-NL
nb-NO
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
ar-SA
da-DK
de-DE
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-CL
Hola, soy Siri.
es-ES
Hola, soy Siri.
es-MX
Hola, soy Siri.
fi-FI
fr-CA
fr-FR
he-IL
it-IT
ja-JP
ko-KR
nb-NO
nl-BE
nl-NL
pt-BR
ru-RU
sv-SE
th-TH
tr-TR
zh-CN
zh-HK
zh-TW
oren
O-ren
O-ren
O-ren
limu
Li-mu
Li-mu
Li-mu
Yu-shu
Yu-shu
Sin-ji
Sin-Ji
Azul
Sydney
Star
StarBravo
SkyE
SkyEcho
speak
oren
sakura
hattori
hiro
ar-001_Maged
ar-SA
ca-ES
cs-CZ_Zuzana
cs-CZ
da-DK_Sara
da-DK
de-DE_Anna
de-DE
el-GR_Melina
el-GR
en-AU_Karen
en-AU
en-GB_Daniel
en-GB
en-IE_Moira
en-IE
en-IN_Rishi
en-IN
en-US_Samantha
en-US
en-ZA_Tessa
en-ZA
es-ES_Monica
es-ES
es-MX_Paulina
es-MX
fi-FI_Satu
fi-FI
fr-CA_Amelie
fr-CA
fr-FR_Thomas
fr-FR
he-IL_Carmit
he-IL
hi-IN_Lekha
hi-IN
hr-HR_Lana
hr-HR
hu-HU_Mariska
hu-HU
id-ID_Damayanti
id-ID
it-IT_Alice
it-IT
ja-JP_Kyoko
ja-JP
ko-KR_Yuna
ko-KR
ms-MY_Amira
ms-MY
nl-BE_Ellen
nl-BE
nl-NL_Xander
nl-NL
nb-NO_Nora
no-NO
pl-PL_Zosia
pl-PL
pt-BR_Luciana
pt-BR
pt-PT_Joana
pt-PT
ro-RO_Ioana
ro-RO
ru-RU_Milena
ru-RU
sk-SK_Laura
sk-SK
sv-SE_Alva
sv-SE
th-TH_Kanya
th-TH
tr-TR_Yelda
tr-TR
uk-UA_Lesya
uk-UA
vi-VN_Linh
vi-VN
zh-CN_Tingting
zh-CN
zh-HK_Sinji
zh-HK
zh-TW_Meijia
zh-TW
ar-SA
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-AU
en-GB
en-IE
en-IN
en-US
en-ZA
es-ES
es-MX
fi-FI
fr-CA
fr-FR
he-IL
hi-IN
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
ms-MY
nb-NO
nl-NL
no-NO
pl-PL
pt-BR
pt-PT
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
vi-VN
zh-CN
zh-HK
zh-TW
ar-SA
es-ES
ca-ES
ca-ES
cs-CZ
da-DK
de-DE
el-GR
en-US
en-NZ
en-AU
en-SG
en-GB
es-ES
es-419
es-MX
es-CL
es-MX
es-CO
es-MX
es-US
es-MX
fi-FI
fr-FR
he-IL
hi-IN
hr-HR
hr-HR
hu-HU
id-ID
it-IT
ja-JP
ko-KR
id-ID
ms-MY
ms-MY
nb-NO
nl-NL
no-NO
no-NO
pl-PL
pt-BR
ro-RO
ru-RU
sk-SK
sv-SE
th-TH
tr-TR
uk-UA
uk-UA
vi-VN
yue-CN
zh-HK
zh-TW
zh-Hans
zh-CN
zh-Hans-CN
zh-CN
zh-Hans-HK
zh-HK
zh-Hans-MO
zh-HK
zh-Hant-HK
zh-HK
zh-Hant-MO
zh-HK
zh-Hant-TW
zh-TW
zh-MO
zh-HK
TTSResources
PreinstallCache
com.apple.siri
com.apple.siri
Name
Language
Gender
Technology
Quality
Available
Obsolete
Source
