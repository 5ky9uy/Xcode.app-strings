MbP?
AXSpeechAction
AXSpeechManager
rate
v16@?0@"AXSpeechAction"8
v32@?0@"AXSpeechAction"8{_NSRange=QQ}16
v20@?0@"AXSpeechAction"8B16
AXAlternativeVoices
v8@?0
AXSettings
B32@?0@"AVSpeechSynthesisVoice"8Q16^B24
en-US
Enhanced
System/Library/PrivateFrameworks/AccessibilityUtilities.framework
ENHANCED_VOICE_NAME
%@ (Enhanced)
GeneralAccessibility
create-voices-avspeech
com.apple.shortcuts
AVAlexSpeechSynthesisVoice
IPHONE_SIMULATOR_ROOT
/usr/lib/libAXSpeechManager.dylib
AXSpeechActionPublicImplementation
Error loading AXSpeechManager: %@
UIAccessibilityTokenBrailleDisplayOnly
kAXPidKey
kAXNotificationDataKey
AXPushNotificationToSystemForBroadcast
AFLocalization
Unable to find class %s
language
quality
[%@ %p] String: %@
Voice: %@
Rate: %.2f
Volume: %.2f
Pitch Multiplier: %.2f
Delays: Pre: %.2f(s) Post: %.2f(s)
com.apple.Accessibility
Last
First
Middle
-->Parent: %p
-->Range Offset: %lu
-->Position: %@
AVSpeechSynthesizer
An AVSpeechUtterance shall not be enqueued twice
WebSpeechSynthesisWrapper
identifier
nonLocalizedNameWithoutQuality
installed
canBeDownloaded
default
fallbackDefault
assetSize
isCombinedVoice
nonCombinedVoiceId
gender
synthesisProviderVoice
nameWithoutQuality
 (Installed: %d, Size: %d, Can be downloaded: %d)
[%@ %p] Language: %@, Name: %@, Quality: %@ [%@]%@
Default
voice
ssmlRepresentation
SSML Length: %@, Voice: %@
AXIsInternalInstall
Using AT preferred settings for voice and rate for: %@
utterance had bad voice, remaking it %{public}@
Updating voice on utterance to match preferred technology
Search for possible voices secondary backup: %{public}@
Using voice from language %{public}@ default: %{public}@
Building voices right now, using placeholder: %{public}@
No identifier for voice, %@
Attempting to use SSML initialization but framework isn't available
SSML was invalid! %@, Location: %@, Hint: %@
Utterance creation error: %@
No utterances created from given utterance %{public}@
Generated utterances: %@
Changing audio session and category options for WebKit usage
Could not find any name for this voice: %@
Could not generate SSML from AVSpeechUtterance! Error:%@ Hint:%@ Location:%@ 
 Utterance: %@ 
Transformed to SSML: %@
Could not parse SSML: %@
softlink:r:path:/System/Library/PrivateFrameworks/AXRuntime.framework/AXRuntime
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
__AXSpeechActionPublicImplementation_super
SafeCategory
Implementation_iOS
AXSpeechActionPublicImplementation
AXSIMDFloat4x4Wrapper
PrivateAttributes
Implementation
AXSpeechPublicInterface
Implementation_Shared
AXSpeechPublicInterface_Private
safeCategoryTargetClassName
safeCategoryBaseClass
setAction:
action
utterance
dealloc
setUtterance:
init
initWithValue:
value
setValue:
_value
T{?=[4]},N,V_value
numberWithBool:
boolValue
prefersAssistiveTechnologyExceptions
setPrefersAssistiveTechnologyExceptions:
setProcessEmoticons:
processEmoticons
useMonarchStyleSpeechRate
setUseMonarchStyleSpeechRate:
TB,N
T@"NSArray",&,N
speechManager
outputChannels
setOutputChannels:
setSkipLuthorRules:
setSupportsAccurateWordCallbacks:
setActiveOptions
setSetActiveOptions:
setAudioSessionCategory:
audioSessionCategory
setAudioSessionCategoryOptions:
audioSessionCategoryOptions
usesAuxiliarySession
setUsesAuxiliarySession:
audioQueueFlags
setAudioQueueFlags:
prepareSpeechManager
actionWithString:shouldQueue:
dispatchSpeechAction:
isSpeaking
stopSpeaking
tearDown
inflightUtterance
setOnSpeechStartCallback:
setOnPauseCallback:
setOnResumeCallback:
setOnWillSpeakRangeCallback:
setCompletionCallback:
defaultCenter
removeObserver:
tearDownWarmupManager
isInAudioInterruption
audioSession
isPaused
setAudioSessionInactiveTimeout:
voice
identifier
rate
pitchMultiplier
volume
prefersAssistiveTechnologySettings
language
currentLanguageCode
sharedInstance
speechVoiceIdentifierForLanguage:source:exists:
_voiceFromInternalVoiceListWithIdentifier:
containsObject:
voiceOverSpeakingRateForLanguage:
voiceOverPitch
assistiveTouchScannerSpeechEnabled
assistiveTouchScannerSpeechRate
voiceWithLanguage:
voiceIdentifierUsedForLanguage:
setIdentifier:
setVoice:
isSiriVoiceIdentifier:
isInternalSynth
externalVoiceIdentifierUsedForLanguage:
isEqualToString:
voiceWithIdentifier:
setInflightUtterance:
preUtteranceDelay
isSynthesisProviderVoice
pauseMarkupString:
stringWithFormat:
setVoiceIdentifier:
ssmlRepresentation
actionWithSSMLRepresentation:shouldQueue:
attributedSpeechString
actionWithAttributedString:shouldQueue:
speechString
setLanguage:
audioBufferCallback
setAudioBufferCallback:
markerCallback
setMarkerCallback:
setSynthesizeSilently:
setSpeakingRate:
setPitch:
setVolume:
setShouldProcessEmoji:
setShouldProcessEmoticons:
string
dictionaryWithObjects:forKeys:count:
initWithString:attributes:
attributedString
initWithAttributedString:
length
setAttributes:range:
numberWithInt:
null
delegate
speechSynthesizer:didStartSpeechUtterance:
parentUtterance
isFirstChildOfParentUtterance
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
parentUtteranceRangeOffset
_handleSpeechDone:successful:
supportsAccurateWordCallbacks
skipLuthorRules
postUtteranceDelay
processSpeechJobFinished:successful:
speechQueue
count
_convertBoundary:
stopSpeaking:
clearSpeechQueue
removeObjectsInRange:
pauseSpeaking:
continueSpeaking
setIsInternalSynth:
usesApplicationAudioSession
setUsesApplicationAudioSession:
mixToTelephonyUplink
setMixToTelephonyUplink:
_initUnified
_unifiedDealloc
_unifiedIsInAudioInterruption
_unifiedIsSpeaking
_unifiedIsPaused
_unifiedSpeakUtterance:
_unifiedStopSpeakingAtBoundary:
_unifiedPauseSpeakingAtBoundary:
_unifiedContinueSpeaking
audioFileSettingsForVoice:
_voiceWithIdentifier:includingSiri:
remapVoiceIdentifier:
_remapOldIdentifierIfNecessary:
objectForKeyedSubscript:
_speechVoicesIncludingSiri
speechVoices
countByEnumeratingWithState:objects:count:
nonCombinedVoiceId
quality
remapLanguageCode:
lowercaseString
isDefault
isFallbackDefault
hasPrefix:
indexOfObjectPassingTest:
objectAtIndex:
setQuality:
nonLocalizedNameWithoutQuality
setNonLocalizedNameWithoutQuality:
synthesisProviderVoice
setSynthesisProviderVoice:
outputVoiceDescriptorForOutputLanguageCode:voiceName:
localizedDisplay
nameWithoutQuality
containsString:
_localizedNameFormat
stringByAppendingPathComponent:
bundleWithPath:
localizedStringForKey:value:table:
_speechVoicesIncludingSiri:
array
addObjectsFromArray:
availableSuperCompactVoices
mainBundle
bundleIdentifier
availableVoices
isNeuralSiriVoiceIdentifier:
addObject:
setObject:forKeyedSubscript:
isAlexAvailableForLanguage:
alexLocalAssetURL
inUnitTestMode
copy
mutableCopy
_unifiedAudioFileSettings
_initUnifiedWithLanguage:
siriDisplayName
_unifiedName
_unifiedVoiceWithIdentifier:
_speechVoicesIncludingSiriAndSuperCompact
_unifiedSpeechVoices
_unifiedCurrentLanguageCode
test_speechVoices
test_setSpeechVoices:
test_setInternalSpeechVoices:
stringWithUTF8String:
stringByAppendingString:
fileSystemRepresentation
assetFlushedCallback
warningSquelcher
rangeOfString:
substringToIndex:
sortDescriptorWithKey:ascending:
arrayWithObjects:count:
sortUsingDescriptors:
initWithString:
initWithSSMLRepresentation:
setPitchMultiplier:
setRate:
setSpeechString:
setAttributedSpeechString:
shared
parseSSMLToPlainText:
error
location
hint
plainTextResult
setSsmlRepresentation:
isLastChildOfParentUtterance
description
speechUtteranceWithString:
speechUtteranceWithAttributedString:
speechUtteranceWithSSMLRepresentation:
_macStopSpeakingAtBoundary:
_macIsSpeaking
_macDealloc
_macIsPaused
_macContinueSpeaking
_macPauseSpeakingAtBoundary:
_macSpeakUtterance:
_macIsInAudioInterruption
speakUtterance:
writeUtterance:toBufferCallback:
_applyWebKitBehaviors
detectSSMLAndModifyUtterances
transformUtteranceBasedOnSSMLIfDetected:
indexOfObjectIdenticalTo:
raise:format:
_effectiveUtterancesFromUtterance:
_enqueueNextJob
hasGeneratedSSML
supportsSSML
parseSSMLToAVSpeechUtterances:
utteranceResult
setParentUtterance:
setParentUtteranceRangeOffset:
setIsFirstChildOfParentUtterance:
setIsLastChildOfParentUtterance:
removeObjectIdenticalTo:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
_speakUtterance:
initializedWebKitUsage
setDetectSSMLAndModifyUtterances:
setInitializedWebKitUsage:
stopSpeakingAtBoundary:
pauseSpeakingAtBoundary:
writeUtterance:toBufferCallback:toMarkerCallback:
setAssetFlushedCallback:
T@"AVSpeechUtterance",&,N
initWithLanguage:
_macCurrentLanguageCode
_macVoiceWithIdentifier:
_macSpeechVoices
_initMacWithLanguage:
encodeObject:forKey:
encodeInteger:forKey:
isInstalled
encodeBool:forKey:
canBeDownloaded
assetSize
encodeInt64:forKey:
isCombinedVoice
gender
decodeObjectOfClass:forKey:
setBackupName:
decodeIntegerForKey:
decodeInt64ForKey:
setAssetSize:
decodeBoolForKey:
setIsDefault:
setIsFallbackDefault:
setCanBeDownloaded:
setIsInstalled:
setIsCombinedVoice:
setNonCombinedVoiceId:
setGender:
name
numberWithInteger:
integerValue
isSystemVoice:
nameForVoiceIdentifier:
backupName
localizedName:forLanguage:
voiceForIdentifier:
unsignedIntegerValue
numberWithLongLong:
_macName
_macLanguage
_macAudioFileSettings
encodeWithCoder:
initWithCoder:
isSystemVoice
nonLocalizedName
isEqual:
audioFileSettings
_generateSSML
generateSSMLFromAVSpeechUtterance:
ssmlResult
T@?,C,N
T@"NSString",&,N
generatedSSML
TB,R,N,GhasGeneratedSSML
numberWithUnsignedInteger:
hash
initWithSSMLRepresentation:voice:
setMark:
setTextRange:
setByteSampleOffset:
initWithMarkerType:forTextRange:atByteSampleOffset:
@16@0:8
#16@0:8
v24@0:8@16
v16@0:8
@80@0:8{?=[4]}16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
{?="columns"[4]}
v20@0:8B16
B16@0:8
Q16@0:8
v24@0:8Q16
I16@0:8
v20@0:8I16
i24@0:8q16
v24@0:8d16
v28@0:8@16B24
B24@0:8q16
@24@0:8@16
@28@0:8@16B24
@20@0:8B16
v32@0:8@16@?24
v40@0:8@16@?24@?32
v24@0:8@?16
@?16@0:8
v24@0:8q16
q16@0:8
B24@0:8@16
@32@0:8@16@24
@48@0:8q16{_NSRange=QQ}24Q40
MbP?
AXSpeechAction
AXSpeechManager
rate
v16@?0@"AXSpeechAction"8
v32@?0@"AXSpeechAction"8{_NSRange=QQ}16
v20@?0@"AXSpeechAction"8B16
AXAlternativeVoices
v8@?0
AXSettings
B32@?0@"AVSpeechSynthesisVoice"8Q16^B24
en-US
Enhanced
System/Library/PrivateFrameworks/AccessibilityUtilities.framework
ENHANCED_VOICE_NAME
%@ (Enhanced)
GeneralAccessibility
create-voices-avspeech
com.apple.shortcuts
AVAlexSpeechSynthesisVoice
IPHONE_SIMULATOR_ROOT
/usr/lib/libAXSpeechManager.dylib
AXSpeechActionPublicImplementation
Error loading AXSpeechManager: %@
UIAccessibilityTokenBrailleDisplayOnly
kAXPidKey
kAXNotificationDataKey
AXPushNotificationToSystemForBroadcast
AFLocalization
Unable to find class %s
language
quality
[%@ %p] String: %@
Voice: %@
Rate: %.2f
Volume: %.2f
Pitch Multiplier: %.2f
Delays: Pre: %.2f(s) Post: %.2f(s)
com.apple.Accessibility
Last
First
Middle
-->Parent: %p
-->Range Offset: %lu
-->Position: %@
AVSpeechSynthesizer
An AVSpeechUtterance shall not be enqueued twice
WebSpeechSynthesisWrapper
identifier
nonLocalizedNameWithoutQuality
installed
canBeDownloaded
default
fallbackDefault
assetSize
isCombinedVoice
nonCombinedVoiceId
gender
synthesisProviderVoice
nameWithoutQuality
 (Installed: %d, Size: %d, Can be downloaded: %d)
[%@ %p] Language: %@, Name: %@, Quality: %@ [%@]%@
Default
voice
ssmlRepresentation
SSML Length: %@, Voice: %@
AXIsInternalInstall
Using AT preferred settings for voice and rate for: %@
utterance had bad voice, remaking it %{public}@
Updating voice on utterance to match preferred technology
Search for possible voices secondary backup: %{public}@
Using voice from language %{public}@ default: %{public}@
Building voices right now, using placeholder: %{public}@
No identifier for voice, %@
Attempting to use SSML initialization but framework isn't available
SSML was invalid! %@, Location: %@, Hint: %@
Utterance creation error: %@
No utterances created from given utterance %{public}@
Generated utterances: %@
Changing audio session and category options for WebKit usage
Could not find any name for this voice: %@
Could not generate SSML from AVSpeechUtterance! Error:%@ Hint:%@ Location:%@ 
 Utterance: %@ 
Transformed to SSML: %@
Could not parse SSML: %@
softlink:r:path:/System/Library/PrivateFrameworks/AXRuntime.framework/AXRuntime
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
__AXSpeechActionPublicImplementation_super
SafeCategory
Implementation_iOS
AXSpeechActionPublicImplementation
AXSIMDFloat4x4Wrapper
PrivateAttributes
Implementation
AXSpeechPublicInterface
Implementation_Shared
AXSpeechPublicInterface_Private
volume
voiceOverSpeakingRateForLanguage:
voiceOverPitch
voiceIdentifierUsedForLanguage:
voiceForIdentifier:
utteranceResult
usesAuxiliarySession
unsignedIntegerValue
tearDown
substringToIndex:
stringWithUTF8String:
stringWithFormat:
stringByAppendingString:
stringByAppendingPathComponent:
string
stopSpeaking:
stopSpeaking
ssmlResult
speechVoiceIdentifierForLanguage:source:exists:
speechString
sortUsingDescriptors:
sortDescriptorWithKey:ascending:
sharedInstance
shared
setVolume:
setVoiceIdentifier:
setUsesAuxiliarySession:
setTextRange:
setSynthesizeSilently:
setSpeechString:
setSpeakingRate:
setShouldProcessEmoticons:
setShouldProcessEmoji:
setRate:
setPitchMultiplier:
setPitch:
setOnWillSpeakRangeCallback:
setOnSpeechStartCallback:
setOnResumeCallback:
setOnPauseCallback:
setObject:forKeyedSubscript:
setMark:
setCompletionCallback:
setByteSampleOffset:
setAttributes:range:
setAttributedSpeechString:
removeObserver:
removeObjectsInRange:
removeObjectIdenticalTo:
remapVoiceIdentifier:
remapLanguageCode:
rate
rangeOfString:
raise:format:
prefersAssistiveTechnologySettings
preUtteranceDelay
postUtteranceDelay
plainTextResult
pitchMultiplier
pauseSpeaking:
pauseMarkupString:
parseSSMLToPlainText:
parseSSMLToAVSpeechUtterances:
outputVoiceDescriptorForOutputLanguageCode:voiceName:
objectForKeyedSubscript:
objectAtIndex:
numberWithUnsignedInteger:
numberWithLongLong:
numberWithInteger:
numberWithInt:
numberWithBool:
nameForVoiceIdentifier:
mutableCopy
mainBundle
lowercaseString
location
localizedStringForKey:value:table:
localizedName:forLanguage:
localizedDisplay
length
isSystemVoice:
isSiriVoiceIdentifier:
isNeuralSiriVoiceIdentifier:
isEqualToString:
isAlexAvailableForLanguage:
integerValue
initWithString:attributes:
indexOfObjectPassingTest:
indexOfObjectIdenticalTo:
inUnitTestMode
hint
hasPrefix:
generateSSMLFromAVSpeechUtterance:
fileSystemRepresentation
externalVoiceIdentifierUsedForLanguage:
error
encodeObject:forKey:
encodeInteger:forKey:
encodeInt64:forKey:
encodeBool:forKey:
dispatchSpeechAction:
dictionaryWithObjects:forKeys:count:
delegate
defaultCenter
decodeObjectOfClass:forKey:
decodeIntegerForKey:
decodeInt64ForKey:
decodeBoolForKey:
countByEnumeratingWithState:objects:count:
count
copy
containsString:
containsObject:
clearSpeechQueue
bundleWithPath:
bundleIdentifier
boolValue
availableVoices
availableSuperCompactVoices
audioFileSettingsForVoice:
attributedString
attributedSpeechString
assistiveTouchScannerSpeechRate
assistiveTouchScannerSpeechEnabled
arrayWithObjects:count:
array
alexLocalAssetURL
addObjectsFromArray:
addObject:
actionWithString:shouldQueue:
actionWithSSMLRepresentation:shouldQueue:
actionWithAttributedString:shouldQueue:
_macVoiceWithIdentifier:
_macStopSpeakingAtBoundary:
_macSpeechVoices
_macSpeakUtterance:
_macPauseSpeakingAtBoundary:
_macName
_macLanguage
_macIsSpeaking
_macIsPaused
_macIsInAudioInterruption
_macDealloc
_macCurrentLanguageCode
_macContinueSpeaking
_macAudioFileSettings
_initMacWithLanguage:
safeCategoryTargetClassName
safeCategoryBaseClass
setAction:
action
dealloc
setUtterance:
utterance
init
initWithValue:
value
setValue:
_value
T{?=[4]},N,V_value
prefersAssistiveTechnologyExceptions
setPrefersAssistiveTechnologyExceptions:
setProcessEmoticons:
processEmoticons
useMonarchStyleSpeechRate
setUseMonarchStyleSpeechRate:
TB,N
T@"NSArray",&,N
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
speechManager
outputChannels
setOutputChannels:
skipLuthorRules
setSkipLuthorRules:
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
setActiveOptions
isInternalSynth
setIsInternalSynth:
setSetActiveOptions:
setAudioSessionCategory:
audioSessionCategory
setAudioSessionCategoryOptions:
audioSessionCategoryOptions
usesApplicationAudioSession
setUsesApplicationAudioSession:
audioQueueFlags
setAudioQueueFlags:
mixToTelephonyUplink
setMixToTelephonyUplink:
_initUnified
prepareSpeechManager
tearDownWarmupManager
_unifiedDealloc
_unifiedIsInAudioInterruption
audioSession
_convertBoundary:
_unifiedIsSpeaking
_unifiedIsPaused
setAudioSessionInactiveTimeout:
_unifiedSpeakUtterance:
_handleSpeechDone:successful:
_unifiedStopSpeakingAtBoundary:
_unifiedPauseSpeakingAtBoundary:
_unifiedContinueSpeaking
_unifiedAudioFileSettings
setSynthesisProviderVoice:
synthesisProviderVoice
_initUnifiedWithLanguage:
siriDisplayName
_unifiedName
_localizedNameFormat
_voiceFromInternalVoiceListWithIdentifier:
_unifiedVoiceWithIdentifier:
_remapOldIdentifierIfNecessary:
_voiceWithIdentifier:includingSiri:
_speechVoicesIncludingSiri
_speechVoicesIncludingSiriAndSuperCompact
_unifiedSpeechVoices
_speechVoicesIncludingSiri:
_unifiedCurrentLanguageCode
test_speechVoices
test_setSpeechVoices:
test_setInternalSpeechVoices:
warningSquelcher
initWithString:
initWithAttributedString:
initWithSSMLRepresentation:
description
speechUtteranceWithString:
speechUtteranceWithAttributedString:
speechUtteranceWithSSMLRepresentation:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
stopSpeakingAtBoundary:
isSpeaking
isPaused
continueSpeaking
pauseSpeakingAtBoundary:
_speakUtterance:
isInAudioInterruption
writeUtterance:toBufferCallback:
writeUtterance:toBufferCallback:toMarkerCallback:
speakUtterance:
_effectiveUtterancesFromUtterance:
processSpeechJobFinished:successful:
_enqueueNextJob
setInflightUtterance:
inflightUtterance
speechQueue
initializedWebKitUsage
setInitializedWebKitUsage:
detectSSMLAndModifyUtterances
setDetectSSMLAndModifyUtterances:
_applyWebKitBehaviors
setAssetFlushedCallback:
assetFlushedCallback
T@"AVSpeechUtterance",&,N
initWithLanguage:
encodeWithCoder:
isSynthesisProviderVoice
supportsSSML
initWithCoder:
setQuality:
quality
setBackupName:
backupName
isSystemVoice
setNonLocalizedNameWithoutQuality:
nonLocalizedNameWithoutQuality
nameWithoutQuality
setGender:
gender
nonLocalizedName
setIsCombinedVoice:
isCombinedVoice
setAssetSize:
assetSize
setNonCombinedVoiceId:
nonCombinedVoiceId
setCanBeDownloaded:
canBeDownloaded
setIsDefault:
isDefault
setIsFallbackDefault:
isFallbackDefault
setIsInstalled:
isInstalled
setIdentifier:
identifier
isEqual:
name
setLanguage:
language
audioFileSettings
voiceWithLanguage:
currentLanguageCode
voiceWithIdentifier:
speechVoices
setAudioBufferCallback:
audioBufferCallback
setMarkerCallback:
markerCallback
ssmlRepresentation
setSsmlRepresentation:
hasGeneratedSSML
_generateSSML
parentUtterance
setParentUtterance:
setParentUtteranceRangeOffset:
parentUtteranceRangeOffset
setIsFirstChildOfParentUtterance:
isFirstChildOfParentUtterance
setIsLastChildOfParentUtterance:
isLastChildOfParentUtterance
transformUtteranceBasedOnSSMLIfDetected:
T@?,C,N
T@"NSString",&,N
generatedSSML
TB,R,N,GhasGeneratedSSML
initWithSSMLRepresentation:voice:
setVoice:
voice
hash
initWithMarkerType:forTextRange:atByteSampleOffset:
@16@0:8
#16@0:8
v24@0:8@16
v16@0:8
@80@0:8{?=[4]}16
{?=[4]}16@0:8
v80@0:8{?=[4]}16
{?="columns"[4]}
v20@0:8B16
B16@0:8
Q16@0:8
v24@0:8Q16
I16@0:8
v20@0:8I16
i24@0:8q16
v24@0:8d16
v28@0:8@16B24
B24@0:8q16
@24@0:8@16
@28@0:8@16B24
@20@0:8B16
v32@0:8@16@?24
v40@0:8@16@?24@?32
v24@0:8@?16
@?16@0:8
v24@0:8q16
q16@0:8
B24@0:8@16
@32@0:8@16@24
@48@0:8q16{_NSRange=QQ}24Q40
