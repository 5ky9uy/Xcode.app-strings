MbP?
AXSpeechAction
language
quality
[%@ %p] String: %@
Voice: %@
Rate: %.2f
Volume: %.2f
Pitch Multiplier: %.2f
Delays: Pre: %.2f(s) Post: %.2f(s)
com.apple.Accessibility
Last
First
Middle
-->Parent: %p
-->Range Offset: %lu
-->Position: %@
AXSpeechManager
rate
v16@?0@"AXSpeechAction"8
v32@?0@"AXSpeechAction"8{_NSRange=QQ}16
v20@?0@"AXSpeechAction"8B16
com.apple.WorkflowKit.BackgroundShortcutRunner
AVSpeechSynthesizer
An AVSpeechUtterance shall not be enqueued twice
WebSpeechSynthesisWrapper
AXAlternativeVoices
v8@?0
AXSettings
B32@?0@"AVSpeechSynthesisVoice"8Q16^B24
en-US
Enhanced
Premium
System/Library/PrivateFrameworks/AccessibilityUtilities.framework
ENHANCED_VOICE_NAME
%@ (Enhanced)
GeneralAccessibility
PREMIUM_VOICE_NAME
%@ (Premium)
create-voices-avspeech
com.apple.shortcuts
@16@?0@"TTSAXResource"8
AVAlexSpeechSynthesisVoice
identifier
nonLocalizedNameWithoutQuality
installed
canBeDownloaded
default
fallbackDefault
assetSize
isCombinedVoice
nonCombinedVoiceId
gender
synthesisProviderVoice
nameWithoutQuality
 (Installed: %d, Size: %d, Can be downloaded: %d)
[%@ %p] Language: %@, Name: %@, Quality: %@ [%@]%@
Default
voice
ssmlRepresentation
SSML Length: %@, Voice: %@
IPHONE_SIMULATOR_ROOT
/usr/lib/libAXSpeechManager.dylib
AXSpeechActionPublicImplementation
Error loading AXSpeechManager: %@
UIAccessibilityTokenBrailleDisplayOnly
kAXPidKey
kAXNotificationDataKey
AXPushNotificationToSystemForBroadcast
AFLocalization
Unable to find class %s
AXIsInternalInstall
Attempting to use SSML initialization but framework isn't available
SSML was invalid! %@, Location: %@, Hint: %@
Using AT preferred settings for voice and rate for: %@
utterance had bad voice, remaking it %{public}@
Updating voice on utterance to match preferred technology
Skipping accurate word callbacks for Shortcuts
Utterance creation error: %@
No utterances created from given utterance %{public}@
Generated utterances: %@
Changing audio session and category options for WebKit usage
Search for possible voices secondary backup: %{public}@
Using voice from language %{public}@ default: %{public}@
Building voices right now, using placeholder: %{public}@
No identifier for voice, %@
Could not find any name for this voice: %@
Could not generate SSML from AVSpeechUtterance! Error:%@ Hint:%@ Location:%@ 
 Utterance: %@ 
Transformed to SSML: %@
Could not parse SSML: %@
softlink:r:path:/System/Library/PrivateFrameworks/AXRuntime.framework/AXRuntime
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
__AXSpeechActionPublicImplementation_super
SafeCategory
AXSpeechPublicInterface
Implementation
PrivateAttributes
AXSpeechActionPublicImplementation
Implementation_Shared
AXSpeechPublicInterface_Private
safeCategoryTargetClassName
safeCategoryBaseClass
warningSquelcher
countByEnumeratingWithState:objects:count:
rangeOfString:
substringToIndex:
sortDescriptorWithKey:ascending:
arrayWithObjects:count:
sortUsingDescriptors:
initWithString:
initWithAttributedString:
initWithSSMLRepresentation:
init
setVolume:
setPitchMultiplier:
setRate:
setSpeechString:
string
setAttributedSpeechString:
shared
parseSSMLToPlainText:
error
location
hint
plainTextResult
setSsmlRepresentation:
speechString
voice
rate
volume
pitchMultiplier
preUtteranceDelay
postUtteranceDelay
stringWithFormat:
parentUtterance
isLastChildOfParentUtterance
isFirstChildOfParentUtterance
parentUtteranceRangeOffset
stringByAppendingString:
description
setAction:
action
speechUtteranceWithString:
speechUtteranceWithAttributedString:
speechUtteranceWithSSMLRepresentation:
numberWithBool:
boolValue
prefersAssistiveTechnologyExceptions
setPrefersAssistiveTechnologyExceptions:
setProcessEmoticons:
processEmoticons
useMonarchStyleSpeechRate
setUseMonarchStyleSpeechRate:
TB,N
T@"NSArray",&,N
utterance
dealloc
setUtterance:
speechManager
outputChannels
setOutputChannels:
setSkipLuthorRules:
setSupportsAccurateWordCallbacks:
setActiveOptions
setSetActiveOptions:
setAudioSessionCategory:
audioSessionCategory
setAudioSessionCategoryOptions:
audioSessionCategoryOptions
usesAuxiliarySession
setUsesAuxiliarySession:
audioQueueFlags
setAudioQueueFlags:
actionWithString:shouldQueue:
dispatchSpeechAction:
isSpeaking
stopSpeaking
tearDown
isInAudioInterruption
audioSession
isPaused
setAudioSessionInactiveTimeout:
tearDownWarmupManager
identifier
prefersAssistiveTechnologySettings
language
currentLanguageCode
sharedInstance
speechVoiceIdentifierForLanguage:source:exists:
_voiceFromInternalVoiceListWithIdentifier:
containsObject:
voiceOverSpeakingRateForLanguage:
voiceOverPitch
assistiveTouchScannerSpeechEnabled
assistiveTouchScannerSpeechRate
quickSpeakSpeakingRate
voiceWithLanguage:
voiceIdentifierUsedForLanguage:
setIdentifier:
setVoice:
isSiriVoiceIdentifier:
isInternalSynth
externalVoiceIdentifierUsedForLanguage:
isEqualToString:
voiceWithIdentifier:
setInflightUtterance:
isSynthesisProviderVoice
pauseMarkupString:
setVoiceIdentifier:
ssmlRepresentation
actionWithSSMLRepresentation:shouldQueue:
attributedSpeechString
actionWithAttributedString:shouldQueue:
setLanguage:
audioBufferCallback
setAudioBufferCallback:
markerCallback
setMarkerCallback:
setSynthesizeSilently:
setSpeakingRate:
setPitch:
setShouldProcessEmoji:
setShouldProcessEmoticons:
dictionaryWithObjects:forKeys:count:
initWithString:attributes:
attributedString
length
setAttributes:range:
numberWithInt:
null
delegate
speechSynthesizer:didStartSpeechUtterance:
setOnSpeechStartCallback:
speechSynthesizer:didPauseSpeechUtterance:
setOnPauseCallback:
speechSynthesizer:didContinueSpeechUtterance:
setOnResumeCallback:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
setOnWillSpeakRangeCallback:
_handleSpeechDone:successful:
setCompletionCallback:
supportsAccurateWordCallbacks
mainBundle
bundleIdentifier
skipLuthorRules
processSpeechJobFinished:successful:
inflightUtterance
speechQueue
count
_convertBoundary:
stopSpeaking:
clearSpeechQueue
removeObjectsInRange:
pauseSpeaking:
continueSpeaking
prepareSpeechManager
defaultCenter
removeObserver:
speakUtterance:
writeUtterance:toBufferCallback:
_applyWebKitBehaviors
detectSSMLAndModifyUtterances
transformUtteranceBasedOnSSMLIfDetected:
indexOfObjectIdenticalTo:
raise:format:
_effectiveUtterancesFromUtterance:
addObject:
_enqueueNextJob
array
hasGeneratedSSML
supportsSSML
parseSSMLToAVSpeechUtterances:
utteranceResult
setParentUtterance:
setParentUtteranceRangeOffset:
setIsFirstChildOfParentUtterance:
setIsLastChildOfParentUtterance:
removeObjectIdenticalTo:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
objectAtIndex:
_speakUtterance:
initializedWebKitUsage
setUsesApplicationAudioSession:
setDetectSSMLAndModifyUtterances:
setInitializedWebKitUsage:
setIsInternalSynth:
usesApplicationAudioSession
mixToTelephonyUplink
setMixToTelephonyUplink:
stopSpeakingAtBoundary:
pauseSpeakingAtBoundary:
writeUtterance:toBufferCallback:toMarkerCallback:
setAssetFlushedCallback:
assetFlushedCallback
T@"AVSpeechUtterance",&,N
audioFileSettingsForVoice:
_voiceWithIdentifier:includingSiri:
remapVoiceIdentifier:
_remapOldIdentifierIfNecessary:
objectForKeyedSubscript:
remapLanguageCode:
lowercaseString
speechVoices
isDefault
isFallbackDefault
hasPrefix:
indexOfObjectPassingTest:
quality
setQuality:
nonLocalizedNameWithoutQuality
setNonLocalizedNameWithoutQuality:
synthesisProviderVoice
setSynthesisProviderVoice:
outputVoiceDescriptorForOutputLanguageCode:voiceName:
localizedDisplay
nameWithoutQuality
containsString:
_enhancedLocalizedNameFormat
_premiumLocalizedNameFormat
stringByAppendingPathComponent:
bundleWithPath:
localizedStringForKey:value:table:
_speechVoicesIncludingSiri:
_speechVoicesIncludingSiri
addObjectsFromArray:
availableSuperCompactVoices
availableVoices
mutableCopy
resourcesWithType:subType:
isInstalled
speechVoice
ax_flatMappedArrayUsingBlock:
avSpeechVoicesForTTSSpeechVoices:
isNeuralSiriVoiceIdentifier:
setObject:forKeyedSubscript:
isAlexAvailableForLanguage:
resourceWithVoiceId:
inUnitTestMode
copy
initWithLanguage:
encodeObject:forKey:
encodeInteger:forKey:
encodeBool:forKey:
canBeDownloaded
assetSize
encodeInt64:forKey:
isCombinedVoice
nonCombinedVoiceId
gender
decodeObjectOfClass:forKey:
setBackupName:
decodeIntegerForKey:
decodeInt64ForKey:
setAssetSize:
decodeBoolForKey:
setIsDefault:
setIsFallbackDefault:
setCanBeDownloaded:
setIsInstalled:
setIsCombinedVoice:
setNonCombinedVoiceId:
setGender:
name
numberWithInteger:
integerValue
isSystemVoice:
nameForVoiceIdentifier:
backupName
localizedName:forLanguage:
voiceForIdentifier:
unsignedIntegerValue
numberWithLongLong:
audioFileSettings
siriDisplayName
encodeWithCoder:
initWithCoder:
isSystemVoice
nonLocalizedName
isEqual:
_speechVoicesIncludingSiriAndSuperCompact
test_speechVoices
test_setSpeechVoices:
test_setInternalSpeechVoices:
_generateSSML
generateSSMLFromAVSpeechUtterance:
ssmlResult
T@?,C,N
T@"NSString",&,N
generatedSSML
TB,R,N,GhasGeneratedSSML
numberWithUnsignedInteger:
hash
initWithSSMLRepresentation:voice:
setMark:
setTextRange:
setByteSampleOffset:
initWithMarkerType:forTextRange:atByteSampleOffset:
stringWithUTF8String:
fileSystemRepresentation
@16@0:8
#16@0:8
v16@0:8
@24@0:8@16
v24@0:8@16
v20@0:8B16
B16@0:8
Q16@0:8
v24@0:8Q16
I16@0:8
v20@0:8I16
i24@0:8q16
v24@0:8d16
v28@0:8@16B24
B24@0:8q16
v32@0:8@16@?24
v40@0:8@16@?24@?32
v24@0:8@?16
@?16@0:8
v24@0:8q16
q16@0:8
B24@0:8@16
@28@0:8@16B24
@20@0:8B16
@32@0:8@16@24
@48@0:8q16{_NSRange=QQ}24Q40
MbP?
AXSpeechAction
language
quality
[%@ %p] String: %@
Voice: %@
Rate: %.2f
Volume: %.2f
Pitch Multiplier: %.2f
Delays: Pre: %.2f(s) Post: %.2f(s)
com.apple.Accessibility
Last
First
Middle
-->Parent: %p
-->Range Offset: %lu
-->Position: %@
AXSpeechManager
rate
v16@?0@"AXSpeechAction"8
v32@?0@"AXSpeechAction"8{_NSRange=QQ}16
v20@?0@"AXSpeechAction"8B16
com.apple.WorkflowKit.BackgroundShortcutRunner
AVSpeechSynthesizer
An AVSpeechUtterance shall not be enqueued twice
WebSpeechSynthesisWrapper
AXAlternativeVoices
v8@?0
AXSettings
B32@?0@"AVSpeechSynthesisVoice"8Q16^B24
en-US
Enhanced
Premium
System/Library/PrivateFrameworks/AccessibilityUtilities.framework
ENHANCED_VOICE_NAME
%@ (Enhanced)
GeneralAccessibility
PREMIUM_VOICE_NAME
%@ (Premium)
create-voices-avspeech
com.apple.shortcuts
@16@?0@"TTSAXResource"8
AVAlexSpeechSynthesisVoice
identifier
nonLocalizedNameWithoutQuality
installed
canBeDownloaded
default
fallbackDefault
assetSize
isCombinedVoice
nonCombinedVoiceId
gender
synthesisProviderVoice
nameWithoutQuality
 (Installed: %d, Size: %d, Can be downloaded: %d)
[%@ %p] Language: %@, Name: %@, Quality: %@ [%@]%@
Default
voice
ssmlRepresentation
SSML Length: %@, Voice: %@
IPHONE_SIMULATOR_ROOT
/usr/lib/libAXSpeechManager.dylib
AXSpeechActionPublicImplementation
Error loading AXSpeechManager: %@
UIAccessibilityTokenBrailleDisplayOnly
kAXPidKey
kAXNotificationDataKey
AXPushNotificationToSystemForBroadcast
AFLocalization
Unable to find class %s
AXIsInternalInstall
Attempting to use SSML initialization but framework isn't available
SSML was invalid! %@, Location: %@, Hint: %@
Using AT preferred settings for voice and rate for: %@
utterance had bad voice, remaking it %{public}@
Updating voice on utterance to match preferred technology
Skipping accurate word callbacks for Shortcuts
Utterance creation error: %@
No utterances created from given utterance %{public}@
Generated utterances: %@
Changing audio session and category options for WebKit usage
Search for possible voices secondary backup: %{public}@
Using voice from language %{public}@ default: %{public}@
Building voices right now, using placeholder: %{public}@
No identifier for voice, %@
Could not find any name for this voice: %@
Could not generate SSML from AVSpeechUtterance! Error:%@ Hint:%@ Location:%@ 
 Utterance: %@ 
Transformed to SSML: %@
Could not parse SSML: %@
softlink:r:path:/System/Library/PrivateFrameworks/AXRuntime.framework/AXRuntime
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/AccessibilityUtilities.framework/AccessibilityUtilities
__AXSpeechActionPublicImplementation_super
SafeCategory
AXSpeechPublicInterface
Implementation
PrivateAttributes
AXSpeechActionPublicImplementation
Implementation_Shared
AXSpeechPublicInterface_Private
containsString:
avSpeechVoicesForTTSSpeechVoices:
setSynthesizeSilently:
mainBundle
isSiriVoiceIdentifier:
parseSSMLToPlainText:
defaultCenter
removeObserver:
sharedInstance
numberWithInt:
containsObject:
parseSSMLToAVSpeechUtterances:
string
voiceOverSpeakingRateForLanguage:
lowercaseString
indexOfObjectPassingTest:
externalVoiceIdentifierUsedForLanguage:
decodeObjectOfClass:forKey:
setPitchMultiplier:
removeObjectsInRange:
indexOfObjectIdenticalTo:
shared
numberWithBool:
isNeuralSiriVoiceIdentifier:
stopSpeaking:
clearSpeechQueue
location
voiceOverPitch
decodeIntegerForKey:
setPitch:
isAlexAvailableForLanguage:
error
removeObjectIdenticalTo:
inUnitTestMode
setVolume:
encodeObject:forKey:
null
tearDown
arrayWithObjects:count:
localizedStringForKey:value:table:
prefersAssistiveTechnologySettings
setMark:
stopSpeaking
integerValue
voiceIdentifierUsedForLanguage:
decodeInt64ForKey:
ssmlResult
localizedName:forLanguage:
remapVoiceIdentifier:
array
setVoiceIdentifier:
voiceForIdentifier:
bundleWithPath:
encodeInteger:forKey:
setSpeechString:
outputVoiceDescriptorForOutputLanguageCode:voiceName:
decodeBoolForKey:
setAttributes:range:
speechString
addObjectsFromArray:
localizedDisplay
remapLanguageCode:
encodeInt64:forKey:
setSpeakingRate:
bundleIdentifier
preUtteranceDelay
hint
setAttributedSpeechString:
rate
audioFileSettingsForVoice:
initWithString:attributes:
length
addObject:
setCompletionCallback:
boolValue
encodeBool:forKey:
postUtteranceDelay
objectForKeyedSubscript:
nameForVoiceIdentifier:
utteranceResult
setOnWillSpeakRangeCallback:
actionWithString:shouldQueue:
setUsesAuxiliarySession:
substringToIndex:
countByEnumeratingWithState:objects:count:
rangeOfString:
objectAtIndex:
hasPrefix:
speechVoiceIdentifierForLanguage:source:exists:
setShouldProcessEmoticons:
plainTextResult
attributedString
stringWithUTF8String:
setOnSpeechStartCallback:
dispatchSpeechAction:
setByteSampleOffset:
raise:format:
isSystemVoice:
count
actionWithSSMLRepresentation:shouldQueue:
speechVoice
numberWithUnsignedInteger:
ax_flatMappedArrayUsingBlock:
pitchMultiplier
setShouldProcessEmoji:
attributedSpeechString
usesAuxiliarySession
sortUsingDescriptors:
dictionaryWithObjects:forKeys:count:
setOnResumeCallback:
copy
generateSSMLFromAVSpeechUtterance:
mutableCopy
quickSpeakSpeakingRate
numberWithLongLong:
actionWithAttributedString:shouldQueue:
stringWithFormat:
availableVoices
resourcesWithType:subType:
pauseSpeaking:
volume
setTextRange:
assistiveTouchScannerSpeechRate
isEqualToString:
sortDescriptorWithKey:ascending:
setOnPauseCallback:
availableSuperCompactVoices
stringByAppendingString:
unsignedIntegerValue
pauseMarkupString:
numberWithInteger:
setRate:
resourceWithVoiceId:
setObject:forKeyedSubscript:
stringByAppendingPathComponent:
fileSystemRepresentation
assistiveTouchScannerSpeechEnabled
delegate
safeCategoryTargetClassName
safeCategoryBaseClass
warningSquelcher
init
initWithString:
initWithAttributedString:
initWithSSMLRepresentation:
description
setAction:
action
speechUtteranceWithString:
speechUtteranceWithAttributedString:
speechUtteranceWithSSMLRepresentation:
prefersAssistiveTechnologyExceptions
setPrefersAssistiveTechnologyExceptions:
setProcessEmoticons:
processEmoticons
useMonarchStyleSpeechRate
setUseMonarchStyleSpeechRate:
TB,N
T@"NSArray",&,N
dealloc
setUtterance:
utterance
speechSynthesizer:didStartSpeechUtterance:
speechSynthesizer:didPauseSpeechUtterance:
speechSynthesizer:didContinueSpeechUtterance:
speechSynthesizer:willSpeakRangeOfSpeechString:utterance:
speechSynthesizer:didFinishSpeechUtterance:
speechSynthesizer:didCancelSpeechUtterance:
speechManager
outputChannels
setOutputChannels:
skipLuthorRules
setSkipLuthorRules:
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
setActiveOptions
isInternalSynth
setIsInternalSynth:
setSetActiveOptions:
setAudioSessionCategory:
audioSessionCategory
setAudioSessionCategoryOptions:
audioSessionCategoryOptions
usesApplicationAudioSession
setUsesApplicationAudioSession:
audioQueueFlags
setAudioQueueFlags:
mixToTelephonyUplink
setMixToTelephonyUplink:
prepareSpeechManager
tearDownWarmupManager
isInAudioInterruption
audioSession
_convertBoundary:
isSpeaking
isPaused
setAudioSessionInactiveTimeout:
_speakUtterance:
_handleSpeechDone:successful:
stopSpeakingAtBoundary:
pauseSpeakingAtBoundary:
continueSpeaking
writeUtterance:toBufferCallback:
writeUtterance:toBufferCallback:toMarkerCallback:
speakUtterance:
_effectiveUtterancesFromUtterance:
processSpeechJobFinished:successful:
_enqueueNextJob
setInflightUtterance:
inflightUtterance
speechQueue
initializedWebKitUsage
setInitializedWebKitUsage:
detectSSMLAndModifyUtterances
setDetectSSMLAndModifyUtterances:
_applyWebKitBehaviors
setAssetFlushedCallback:
assetFlushedCallback
T@"AVSpeechUtterance",&,N
audioFileSettings
setSynthesisProviderVoice:
synthesisProviderVoice
initWithLanguage:
siriDisplayName
name
_enhancedLocalizedNameFormat
_premiumLocalizedNameFormat
encodeWithCoder:
isSynthesisProviderVoice
supportsSSML
initWithCoder:
setQuality:
quality
setBackupName:
backupName
isSystemVoice
setNonLocalizedNameWithoutQuality:
nonLocalizedNameWithoutQuality
nameWithoutQuality
setGender:
gender
nonLocalizedName
setIsCombinedVoice:
isCombinedVoice
setAssetSize:
assetSize
setNonCombinedVoiceId:
nonCombinedVoiceId
setCanBeDownloaded:
canBeDownloaded
setIsDefault:
isDefault
setIsFallbackDefault:
isFallbackDefault
setIsInstalled:
isInstalled
setIdentifier:
identifier
isEqual:
setLanguage:
language
_voiceFromInternalVoiceListWithIdentifier:
voiceWithIdentifier:
_remapOldIdentifierIfNecessary:
_voiceWithIdentifier:includingSiri:
_speechVoicesIncludingSiri
_speechVoicesIncludingSiriAndSuperCompact
speechVoices
_speechVoicesIncludingSiri:
currentLanguageCode
test_speechVoices
test_setSpeechVoices:
test_setInternalSpeechVoices:
voiceWithLanguage:
setAudioBufferCallback:
audioBufferCallback
setMarkerCallback:
markerCallback
ssmlRepresentation
setSsmlRepresentation:
hasGeneratedSSML
_generateSSML
parentUtterance
setParentUtterance:
setParentUtteranceRangeOffset:
parentUtteranceRangeOffset
setIsFirstChildOfParentUtterance:
isFirstChildOfParentUtterance
setIsLastChildOfParentUtterance:
isLastChildOfParentUtterance
transformUtteranceBasedOnSSMLIfDetected:
T@?,C,N
T@"NSString",&,N
generatedSSML
TB,R,N,GhasGeneratedSSML
initWithSSMLRepresentation:voice:
setVoice:
voice
hash
initWithMarkerType:forTextRange:atByteSampleOffset:
@16@0:8
#16@0:8
v16@0:8
@24@0:8@16
v24@0:8@16
v20@0:8B16
B16@0:8
Q16@0:8
v24@0:8Q16
I16@0:8
v20@0:8I16
i24@0:8q16
v24@0:8d16
v28@0:8@16B24
B24@0:8q16
v32@0:8@16@?24
v40@0:8@16@?24@?32
v24@0:8@?16
@?16@0:8
v24@0:8q16
q16@0:8
B24@0:8@16
@28@0:8@16B24
@20@0:8B16
@32@0:8@16@24
@48@0:8q16{_NSRange=QQ}24Q40
