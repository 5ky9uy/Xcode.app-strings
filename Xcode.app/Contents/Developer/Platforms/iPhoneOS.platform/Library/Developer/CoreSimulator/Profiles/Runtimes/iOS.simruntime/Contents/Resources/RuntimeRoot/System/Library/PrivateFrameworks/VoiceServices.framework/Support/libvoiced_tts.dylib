VoiceServicesErrorDomain
Synthesis is cancelled/interrupted.
writeWaveToFilePath failed.
v8@?0
@"NSError"16@?0@"VSSpeechSynthesisCallbackResult"8
v16@?0@"VSSpeechWordTimingInfo"8
VSAudioPlaybackServiceAVSBARQueue
Error in creating block buffer for Sample buffer
Error in CMAudioFormatDescriptionCreate
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in creating block buffer for Silence buffer
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
{?=qiIq}
Timeout waiting for AVSampleBufferRenderSynchronizer
q24@?0@"NSValue"8@"NSValue"16
v32@?0@"NSValue"8Q16^B24
cached_engine_%@_%@
Use `initWithRequest:`.
%@ %@ %@ %@ %.2f %.2f %.2f %@ %@
Speech is cancelled/interrupted.
v20@?0B8@"NSString"12
ServerTTSErrorDomain
Use `initWithRequest:shouldSpeak:`.
%@ %@
v40@?0@"NSData"8Q16@"NSData"24^B32
Unable to create playback service
EagerTTS:%@:%@:%@:%@:%@:%@:%@:%@:%@
Cancelled
Finished
speaking
synthesizing
voice
(null)
is_eager
is_one_shot
is_time_out
is_device_tts
source_of_tts
com.apple.springboard
com.apple.siri
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
\mrk=emo=whisper\
com.apple.voiced.can-dump-audio
com.apple.voiced.request.durationestimation
com.apple.voiced.request.speech
com.apple.voiced.request.presynthesis
unknown:unknown:PresynthesizedAudio
unknown:PresynthesizedAudio:unknown
com.apple.voiced.request.synthesis
com.apple.voiced.request.text_to_phonemes
VSAudioPowerUpdateQueue
-[VSSpeechXPCHandler beginAudioPowerUpdateWithReply:]
v16@?0@"AFXPCWrapper"8
-[VSSpeechXPCHandler endAudioPowerUpdate]
%@:%@:%@:%@
Missing languageCode
-[VSSpeechXPCHandler getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:]
VSOspreyTTSCoreCallbackQueue
v24@?0@"VSAudioData"8@"NSArray"16
v16@?0@"NSError"8
Osprey round-trip TTS timed out
v28@?0@"VSVoiceAsset"8@"VSVoiceResourceAsset"16f24
Osprey streaming network stall
Osprey streaming TTS timed out
Osprey core is not able to provide audio in time
com.apple.voiced.postInstall
v20@?0f8^B12
v16@?0@"NSObject<OS_xpc_object>"8
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.voiced.voicePreviewQueue
com.apple.voiceservices
VoicePreviews
_Buddy
%@_%@%@.caf
v20@?0d8B16
InvalidCache
Audio duration too short
duration %.2f second
TTSResources/PreinstallCache/
VSSpeechCacheErrorDomain
-[VSSpeechCache initWithStorePath:]
VoiceServices
Cache type name too long
-[VSSpeechCache addCache:]
%@_%@
%@:%@:%@:%@:%@:%@
gryphon
unknown
premium
%@:%@:%@
preinstalledCache
FlatBuffers 1.12.0
v24@?0^v8Q16
resource
context_info
meta_info
context
experiment
feature_flags
decoder_description
playback_description
word_timing_info
v20@?0r*8I16
content
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
data
cur_
scratch_end
scratch_
scratch_data
buf_
finished
ReferTo
off && off <= GetSize()
EndVector
Finish
strlen(file_identifier) == kFileIdentifierLength
vector
'%c%c%c%c', %.0fhz, %d bits, %d FPP, 
%@:%@
voiced_tts_playback_queue
Error AudioQueueStart
Error AudioQueueFlush
Error AudioQueueStop
Error AudioQueuePause
Error AudioQueueAddPropertyListener
Error AudioQueueRemovePropertyListener
YYYY-MM-dd hh:mm:ss:SSS
Error AudioQueueGetProperty isRunning
Unable to enable kAudioQueueProperty_EnableLevelMetering
Unable to disable kAudioQueueProperty_EnableLevelMetering
-[VSAudioPlaybackServiceAT getAveragePower:andPeakPower:]
Unable to get kAudioQueueProperty_CurrentLevelMeterDB
hdft
Hdft
usbD
hx90
wx90
rhac
wdef
com.apple.voiceservices.notification.voice-update
Missing utterance in the request (preprocessing missing?).
No voice available
Compact voice is explicitly disabled.
Voice is deleted already.
Can't create VSSpeechEngine
CACHE_DELETE_AMOUNT
CACHE_DELETE_VOLUME
com.apple.voiced.CacheDelete
r^{__CFDictionary=}20@?0i8r^{__CFDictionary=}12
com.apple.voiced.downloadQueue
on accessory %@
q24@?0@"VSVoiceAsset"8@"VSVoiceAsset"16
v20@?0d8f16
com.apple.sirittsd.neuralCompiling
v12@?0i8
com.apple.voiced.neural-compiling
https://dejavu.apple.com
https://seed-dejavu.siri.apple.com
https://carry-dejavu.siri.apple.com
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
v16@?0@"OspreyMutableRequest"8
-[OspreyTTSService roundTripTTS:responseHandler:]_block_invoke
Empty data
Invalid data
Error %d in response: %@
v24@?0@"NSData"8@"NSError"16
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
Corrupted Osprey response.
-[OspreyTTSService streamTTS:beginHandler:chunkHandler:endHandler:completion:]_block_invoke
v16@?0@"NSData"8
/private/var/mobile/Library/Logs/CrashReporter/VoiceServices/
mobile
-[VSDiagnosticService createDirectoryIfNeeded]
yyyy_MM_dd-HHmmss.SSS
TTS-%@
.tmp
.wav
TTSMetrics-%lld
.json
default
ServerTTSTimeoutV2
DeviceWaitTimeV2
TTSExperimentConfig
identifier
method
delayed
AllowedAppId
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
Use `initWithRequest:withStreamID:`.
Unknown inline streaming error %d, %@
Missing utterance in the request (preprocessing missing?). Can't fallback to device TTS.
voice_resource
task: inprogress %@, request: %@
Can't create VSAudioPlaybackService
Can't decode audio data
audio_duration
com.apple.voiced.VSInlineStreamService
fe_feature
fe_feature_only
language
gender
name
version
quality
type
channel_type
app_id
dialog_identifier
experiment_identifier
speech_id
session_id
text
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
value
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
error_code
error_str
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
content_type
com.apple.voiceservices.notification.voice-purge
com.apple.voiced.prewarmQueue
Prewarm textify emoji
gryphon_frontend
VoiceServices/config
-[VSServerTTSClient ospreyStartSynthesisRequest:responseHandler:completion:]_block_invoke
Unable to process audio data.
v24@?0@"OPTTSTextToSpeechResponse"8@"NSError"16
v16@?0@"OPTTSBeginTextToSpeechStreamingResponse"8
v16@?0@"OPTTSPartialTextToSpeechStreamingResponse"8
v16@?0@"OPTTSFinalTextToSpeechStreamingResponse"8
rate
pitch
volume
isEager
neuralIssue
com.apple.voiced.cachingQueue
v32@?0@"NSData"8Q16@"NSData"24
Speaker
CarAudioOutput
com.apple.voiced.pthreadQueue
com.apple.voiced.speakingQueue
audioDataFromFile:error:
AudioFileOpenURL
AudioFileGetProperty kAudioFilePropertyDataFormat
AudioFileGetProperty kAudioFilePropertyAudioDataByteCount
AudioFileGetProperty kAudioFilePropertyAudioDataPacketCount
+[VSAudioData(SAUIAudioData) audioDataWithASBD:rawData:]
male
female
neutral
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
SynthesisTask done synthesize %lu characters, audio duration %f, error %@
Task %llu reported word time info
Device SpeakTask %llu: Instrument metric: %@
Task %llu started speaking
Device EagerTask %llu: Instrument metric: %@
Task %llu reported finish, error: %@
Can't retrieve session with ID: %d
#AVSBAR initialized with session ID: %d, reusing previous synchronizer: %{BOOL}d
VSAudioPlaybackService %p init latency: %.3f
mediaserverd reset
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR already stopped or paused: will not resume rate
_synchronizer play rate high latency: %.3f sec
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
Invalid sample buffer
Invalid silence buffer
Error in creating block buffer for Sample buffer
Error in CMAudioFormatDescriptionCreate
Error in CMAudioSampleBufferCreateWithPacketDescriptions
#AVSBAR already stopped or waiting for finish: will not enqueue more
#AVSBAR empty audio data: will not enqueue it
Adding to enqueuedMappedAudioInfo: %f sec
Error in creating block buffer for Silence buffer
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR Call to provide more audio data during state %ld.
#AVSBAR Enqueuing to %@: %f sec
_renderer enqueueSampleBuffer high latency: %.3f sec
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %lu
#AVSBAR flushAndStop
#AVSBAR already stopped or waiting for finish
#AVSBAR Synchronizer reached endTime
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR Synchronizer is stalled with rate %f at time %f.
Stopping synchronizer and renderer
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f). Then renderer will be flushed.
_synchronizer stop rate high latency: %.3f sec
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
#AVSBAR renderer was flushed
Pausing synchronizer
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f).
_synchronizer pause rate high latency: %.3f sec
#AVSBAR Dropping %lu enqueued data
Error AudioUnitSetProperty _floatConverter %@
Error AudioUnitSetProperty _integerConverter %@
Error AudioComponentInstanceNew _voiceBoostUnit %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_MaximumFramesPerSlice %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, %@
Error AudioUnitInitialize _voiceBoostUnit %@
Error AudioUnitSetParameter %@
Error AudioConverterConvertComplexBuffer _floatConverter %@
Error AudioUnitProcess _voiceBoostUnit %@
Error AudioConverterConvertComplexBuffer _integerConverter %@
Using timestamp inside voiced for Estimation task
Created Estimation task %llu
Unable to create engine for request %@
Estimated duration: %.2f, for utterance: %@
Using timestamp inside voiced for task
Created Task %llu (%p)
Starting speech task %llu
Short-term cached synthesis is found for text '%@'
Detected synthesis stall, starting tailspin
Finished tail spin, success:%d, file: %@
Holding audio playback before we get fast synthesis.
SpeakTask done synthesize %lu characters, audio duration %f, error %@
Device task %llu: Instrument metric: %@
Using requestCreatedTimestamp inside voiced for Server task
Created Server task %llu: shouldSpeak %{BOOL}d
Received server TTS response. Use Server TTS.
Received device synthesis previously, ignore server TTS.
Encountered Osprey streaming network stall. Retry with device TTS.
Server network error: %@
Start device synthesis fallback.
Start playing device synthesis instead.
Received server TTS previously, ignore device TTS
Received audio from device synthesis. Use device synthesis immediately.
Received audio from device synthesis, but it's deferred.
Inline server TTS is previously cached.
Eager server TTS is previously cached.
Device TTS is racing with Server TTS
Device TTS wait time for server audio: %.2f
Device TTS will not race
Server task %llu started speaking
Server task %llu: Instrument metric: %@
Error in server task %llu, error: %@
Server task %llu: %@ %@ utterance: '%@', %{public}@
Invalidate VSSpeechXPCHandler, cancelling all related tasks
%{public}@ is not TTS language, fallback to %{public}@
Use SSML input: %@
Utterance to synthesize for request %llu: '%@'
Overwriting volume with internal default: %.3f
Overwriting rate with internal default: %.3f
Overwriting pitch with internal default: %.3f
Process is not entitled for dumping audio. Ignore outputPath
Unexpected client '%{public}@' sets Siri request ID.
Overriding disableDeviceRacing with internal default
Update with connection identifier: %{public}@, keepActive:%{BOOL}d
Keep active session for '%@'
Remove active session for '%@'
Find on-going task: %@, ignoring prewarm request: %@
Server Inline Streaming TTS is disabled in internal settings
Server TTS is disabled in internal settings
Created stream speak task %llu
Created server speak task %llu
Created speak task %llu
Created presynthesized task %llu
Cache #PresynthesizedRequest %llu with text: %@
Cache #PresynthesizedRequest %llu skipped: no audio
Ignore stopPresynthesizedAudioRequest. Cannot find task with associated request %llu.
Created server synthesis task %llu
Created synthesis task %llu
Found matched inline streaming request, cancel synthesis task %llu
Ignore pauseSpeechRequest. Current request is different than requested request.
Ignore continueSpeechRequest. Current request is different than requested request.
Ignore stopSpeechRequest. Cannot find task with associated request %llu.
Created phonemes task %llu
ignored client '%{public}@' setting auto-download for a non-existing accessoryId '%@'
client '%{public}@' and accessory '%@' set auto download voice assets:%{public}@
Preparing cellular download for %@
Start cellular download for %@
Begin getVoiceInfoForLanguageCode: %{public}@, %@, %@
%s override voice info for server TTS platform, %@
End getVoiceInfoForLanguageCode: %@
Ignore stream object with nil stream ID: %@
Enqueue stream object %@, streamId: %@
Received invokeDaemon, I'm listening
Received killDaemon, shutting down
Simulate network stall is on, ignore audio object
Refresh timeout value as %.2f
Simulate network stall is on, ignore completion callback
Network stall in osprey streaming
Timeout in osprey streaming
Osprey core %p is cancelled
Registered xpc activity com.apple.voiced.postInstall
Running activity com.apple.voiced.postInstall
com.apple.voiced.postInstall is requested to be deferred.
Unable to set defer state for com.apple.voiced.postInstall
Assets migration progress: %f
Re-triggering neural compiling afer OS upgrade.
Migration service finished.
xpc activity com.apple.voiced.postInstall, failed to set state to done.
Unexpected xpc activity state %d for 'com.apple.voiced.postInstall'
Defaults disables reset, skip resetting MobileAsset default URL
Resetting MobileAsset default URL
Unable to locate preview sample file at '%@'
StartVoicePreview for languageCode %@ voiceName %@ previewType %ld
Preview ignored for %@
Unable to play preview sample file at '%@'
StopVoicePreview for file '%@'
Reading cache %@ error: %@
Error %s, %@
Cache type name too long %@
{public}%@ is not TTS language, falling back to %{public}@
Error in reading audio data from file: %@ error:%@
Error AudioQueueNewOutputWithAudioSession %@
Unable to set kAudioQueueProperty_ClientUID, errno: %@
Error CMTimebaseCreateWithSourceClock: %@
AudioQueue initialized with session ID: %d
Error AudioQueueDispose %@
Signal AudioQueue running state change
Error AudioQueueStart %@
VSAudioPlaybackService %p success AudioQueueStart
Error AudioQueueAllocateBuffer %@
Audio queue start sample time: %.0f
Detected stalled audio generation, will enqueue %d silence frame to compensate.
Error AudioQueueEnqueueBuffer %@
VSAudioPlaybackService %p enqueued audio buffer at sample time: %.2f, size: %ld, total enqueued samples: %.0f, discontinuity: %{BOOL}d
AudioQueue will flushAndStop
Timeout in AudioQueue dequeue condition.
Error AudioQueueFlush %@
Error AudioQueueStop %@
AudioQueue will stop
Error AudioQueuePause %@
VSAudioPlaybackService %p success AudioQueuePause
Error AudioQueueAddPropertyListener %@
Error AudioQueueRemovePropertyListener %@
Detected stall of audio queue, based on NSDate. Now: %@, supposed end time: %@, Tolerance: %.2f
Error AudioQueueGetProperty isRunning %@
Unable to enable kAudioQueueProperty_EnableLevelMetering, err: %@
Unable to disable kAudioQueueProperty_EnableLevelMetering, err: %@
Error: %s, errno: %@
VSAudioPlaybackService %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %@
Current audio output route: %@
AudioPlayback
Device core %p is cancelled
On-disk cached synthesis %@ is found.
In-memory cached synthesis %@ is found.
Reset MobileAsset query cache and retry selecting voice
No voice available
Compact voice is explicitly disabled.
Voice is deleted at path '%@'
#CacheDelete asset cleaning is disabled in internal setting. Skip purgeable assets for urgency %d
#CacheDelete purgeable active voice asset: %@
#CacheDelete purgeable inactive voice asset: %@
#CacheDelete query purgeable size, urgency: %d / %d, info: %@
#CacheDelete purge, urgency: %d / %d, info: %@
#CacheDelete periodic purge, urgency: %d / %d, info: %@
Asset update is disabled in internal settings.
Start updating voice and voice resources.
%@ %@ has a subscribed voice: %{public}@
Voice download is in progress, skip new download. %@
Updating target voice: %@
Voice update decision: shouldDownload:%d, canUseBattery:%d. Reason: triggerType:%d, compactVoiceSelected:%d, mismatchedVoiceName:%d, activeSiriUser:%d, serverExperimentDelay:%d
Downloaded voice is not ready to use. Start ANE compiling immediately for voice: %@
Voice asset downloading progress: %.2f, remainingTime: %.2f, voice: %@
Start ANE compiling immediately for voice: %@
Updating VoiceResource for '%{public}@'
Triggered 'com.apple.sirittsd.neuralCompiling' with error %d
Triggered 'com.apple.voiced.neural-compiling' with error %d
Sent Osprey grpc request with speech_id '%@', session_id '%@', app_id '%@'
%s, Error: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@'
Corrupted Osprey response, stream ID: %@
Osprey streaming received Begin response with non 200 status: %d
Osprey streaming received Begin response %@
Osprey streaming received Chunk response with non 200 status: %d
Osprey streaming received Chunk response, pkt number: %d
Osprey streaming received End response with non 200 status: %d
Osprey streaming received End response, total pkt: %d
%s, Unknown response from Osprey for streaming TTS
Osprey streaming invokes completion with error %@
Osprey streaming invokes completion callback
Created audio dump directory %@
No compressed audio do dump
Unable to create intermediate audio dump at '%@'
Unable to create audio dump at '%@', error: %@
Audio save as %@
No audio do dump
No json data to dump
Unable to parse json for dictionary '%@', error: %@
Unable to create instrument metrics json dump at '%@'
Instrument metrics json dump saved as %@
Unable to parse json for key '%@', error: %@
JSON for key '%@' is not dictionary
Added short term cache:%@ for key:'%@'
Removed short term cache for key:'%@'
Removed short term cache for all keys
Using timestamp inside voiced for Stream task
Created Stream task %llu: streamID %@
Simulate network stall is on, ignore object %@
Unknown streaming object: %@
Handle stream begin with streamId: %@, text: %@, decoder: %@
Ignoring stream begin: error already occurred: %ld
Handle stream chunk with streamId: %@
Reached buffer threshold. Start playing audio.
Handle stream end with streamId: %@, count: %@
Stream TTS network stall.
Inline streaming TTS timeout.
Streaming error: %@, error_code: %d
Error in stream task %llu, error: %@
Stream task %llu: %@ speaking text: '%@', %{public}@
Stream task %llu: Instrument metric: %@
Initializing fallback playback service
Using timestamp inside voiced for Presynthesized task
Created Presynthesized Task %llu
Speaking pre-synthesized audio: %@
Error in audio task %llu, error: %@
Audio task %llu: %@ speaking utterance '%@', %{public}@
Received inline streaming TTS with id %@, text: %@
Notification for %@ is on-going. Posting object immediately %@
Notification for %@ has not started. Cache object %@
Start notifying for: %@
No cached object found for notification %@.
%d cached objects found for notification: %@
Notify %@ with cached object %@
Remove notification %@
Prewarming: Invoked with request: '%@'
Unable to initialize Device Authentication session: %@
Device Authentication session is initialized
Unable to prewarm, error: %@
Can't prewarm engine with path '%@'
Prewarm finished. Latency: %.3f
Prewarming: Completed with request: '%@'
Can't create engine with path '%@'
Voice specific resources found.
Specified resource file '%@' does not exist at: '%@'
disableServerTTS is enabled by user default, disable server TTS
forceServerTTS is enabled by user default, force server TTS
forceServerTTS is enabled by speech request, force server TTS
Preinstalled cache is found, disable server TTS
Neural voice is found on device without fallback condition, disable server TTS
Short term cache is found for the text, use server TTS
Server TTS is disabled since '%{public}@' is not in the list of allowed apps
%s, %@
Unable to get power policy from Siri, error: %@
playbackService is initialized already.
Can't create VSAudioPlaybackService
Starting AudioQueue
Task %llu fetched voice %@
Error in device task %llu, error: %@
Device task %llu: %@ %@ utterance: '%@', %{public}@
Cached streamAudio in task %llu with hash %@ in memory
Cached audio in task %llu with hash %@ in memory
Error converting audio during caching. %@
Error converting stream audio during caching. %@
Caching is disabled. Skipping caching.
Unrecognized audio object, skip caching
Audio duration is too short: %.2f second, skip caching
Audio duration is too long: %.2f second, skip caching
Compressing audio for caching.
Audio compressed for caching.
Can't add audio cache, error: %@
Preinstalled cached synthesis %@ is found.
AssistantSiriAnalytics should always derive an identifier for SISchemaComponentName_COMPONENTNAME_TTS
Error AudioFileCreateWithURL: '%@', code: %@
Unable to begin OPUS decoder, %@
Error during decoding, %@
Error AudioFileWriteBytes: '%@', code: %@
Error AudioFileClose: '%@', code: %@
Start spinNextTask
Dispatch speaking task %llu
Starting task %llu
PresynthesisTask %llu requested to wait another speaking task %llu
New speak task %llu interrupts speaking task %llu
New speak task %llu waits for speaking task %llu
%llu interrupt task %llu
Speak task %llu is attached to eager task %llu
Dispatch synthesis task %llu
Finish spinNextTask
Starting text to phonemes task %llu
Finished text to phonemes task %llu
decoderStreamDescription formatID: %@, sample rate: %@
Unknown server audio format ID: %d
%s, invalid opus data
%s, Unknown format: %d
Invalid chunk size: %d at offset %d, bytes count = %d
Unable to convert OPUS to PCM. %@
Decoding opus for dumping.
Opus decoded for dumping.
OPTTSTextToSpeechResponse word timing info, offset: %ld, length: %ld, word: %@, sampleIndex: %d, timestamp: %.2f
Unable to madvise file '%@' MADV_DONTNEED, error: %s
Unable to munmap file '%@', error: %s
Unable to open file '%s', error: %s
Unable to get size of file '%s', error: %s
Unable to mmap '%s', error: %s
fcntl called on file '%@', size: %lu
0Emcpl
C333333
N11flatbuffers16DefaultAllocatorE
N11flatbuffers9AllocatorE
VSSpeechSynthesisTask
VSSpeechEagerProtocol
VSSpeechSpeakableProtocol
VSSpeechTaskProtocol
NSObject
VSAudioMappedInfoAVSBAR
VSAudioMappedInfo
VSAudioPlaybackServiceAVSBAR
VSAudioPlaybackServiceProtocol
AFAudioPowerProviding
VSVoiceBooster
VSDurationEstimationTask
VSHMHomeManager
VSSpeechSpeakTask
VSSpeechServerTask
VSDeviceTTSCoreDelegate
VSOspreyTTSCoreDelegate
VSSpeechXPCHandler
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSOspreyTTSCore
VSPostInstallService
VSVoicePreviewTask
AVAudioPlayerDelegate
VSSpeechCacheAudio
VSSpeechCacheItem
VSSpeechCache
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSTextToSpeechResponse
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
VSAceObjectUtility
VSHHManagementClient
VSAudioMappedInfoAT
VSOccasionalTimesObserver
VSAudioPlaybackServiceAT
VSAudioRouteInfo
VSAudioPlaybackService
VSDeviceTTSCore
VSCacheDeleteService
VSTimeoutCondition
VSDownloadService
OspreyTTSService
SpeechService
VSDiagnosticService
VSSiriServerConfiguration
VSShortTermCache
VSSiriInlineTTSStreamTask
VSSpeechPresynthesizedTask
VSSpeechAudioPowerService
VSInlineStreamService
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableTextToSpeechResponse
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
VSPrewarmService
VSServerTTSClient
Utilities
VSCachingService
VSSiriInstrumentation
VSStreamAudioMappedInfo
VSStreamAudioData
VSSpeechTaskQueue
VSTextToPhonemesTask
SAUIAudioData
VSHelpers
VSMemoryMap
T@"NSArray",C,N
CMTimeValue
T@"NSError",&,N
T#,R
T@"VSSpeechEngine",&,N,V_engine
T@"<VSAudioPlaybackServiceProtocol><AFAudioPowerProviding>",&,N,V_implementation
_audioTimeStamp
T@"<VSOspreyTTSCoreDelegate>",W,N,V_delegate
_engine
T@"<VSSpeechServiceDelegate>",W,N,V_delegate
_floatConverter
T@"AVAudioPlayer",&,N,V_previewPlayer
_inMemoryCaches
T@"AVSampleBufferRenderSynchronizer",&,N,V_synchronizer
_prewarmService
T@"NSArray",&,N,V_deferredTTSTimingInfo
_streamingVoice
T@"NSArray",&,N,V_timingInfos
_voiceBoostUnit
T@"NSArray",R,N,V_timingInfos
_wordTimingInfo
T@"NSCondition",&,N,V_dequeueCondition
beginAudioPowerUpdateWithReply:
T@"NSCondition",&,N,V_refreshTimeoutCondition
cachedEngineForVoice:resources:
T@"NSData",&,N,V_packetDescriptions
captureSnapshot
T@"NSData",R,N
containsObject:
T@"NSDate",&,N,V_audioQueueStartDate
dataWithLength:
T@"NSDictionary",&,N,V_audioDumpFileAttributes
defaultInstance
T@"NSError",&,N,V_error
dirPath
T@"NSLock",&,N,V_updateLock
enableAudioDump
T@"NSMutableArray",&,N,V_enqueuedMappedAudioInfo
fe_feature_only
T@"NSMutableArray",&,N,V_inMemoryCaches
finalTimingInfo
T@"NSMutableArray",&,N,V_speakTasks
getBytes:range:
T@"NSMutableData",&,N,V_audioData
initWithClient:accessory:voice:
T@"NSMutableDictionary",&,N,V_queuedNotification
initWithNSUUID:
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdateQueue
isInternalBuild
T@"NSObject<OS_dispatch_queue>",&,N,V_dataQueue
isServerTimeout
T@"NSObject<OS_dispatch_queue>",&,N,V_notifyQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_speakingQueue
logText
T@"NSObject<OS_dispatch_semaphore>",&,N,V_neuralPlaybackSemaphore
madvise
T@"NSObject<OS_os_transaction>",&,N,V_synthesizerTransaction
mappedAudioInfo
T@"NSString",&,N,V_audioDumpPath
numberWithLong:
T@"NSString",&,N,V_deviceID
outputRouteInfo
T@"NSString",&,N,V_key
playbackService
T@"NSString",&,N,V_preinstalledCacheDir
provideMoreData
T@"NSString",C,N
refresh
T@"NSString",R,N
removeDirectory
T@"NSString",R,N,V_voiceKey
removeStreamId:
T@"NSURL",C,N,V_currentPreviewURL
reportProcessingWordTimingInfo:
T@"NSUUID",&,N,V_siriRequestId
resourceVersion
T@"OPTTSAudioDescription",C,N
serverTTSConfig
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
setCurrentTask:
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
setIsServerTTS:
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
setKey:
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
setOutputRoute:
T@"OPTTSTTSRequestFeatureFlags",C,N
setPromptCount:
T@"OPTTSTextToSpeechMeta",C,N
setSample_rate:
T@"OPTTSTextToSpeechRequestContext",C,N
setServerStreamedAudioDuration:
T@"OPTTSTextToSpeechRequestExperiment",C,N
setSourceOfTTS:
T@"OPTTSTextToSpeechRequestMeta",C,N
setStreamAudio:
T@"OPTTSTextToSpeechResource",C,N
setTimingInfos:
T@"OPTTSTextToSpeechVoice",C,N
setVoiceGender:
T@"SATTSSpeechSynthesisResource",&,N,V_streamingResource
standardService
T@"VSAudioData",&,N,V_compressedAudio
stopPresynthesizedAudioRequest:
T@"VSAudioData",R,N,V_audio
stringByAppendingPathExtension:
T@"VSAudioPlaybackService",&,N,V_playbackService
suspend
T@"VSAudioRouteInfo",R,N,V_outputRouteInfo
timeout
T@"VSDeviceTTSCore",&,N,V_deviceCore
unloadResource:
T@"VSDeviceTTSCore",&,N,V_synthesisCore
vs_substituteAudioWithLocalPath
T@"VSHMHomeManager",&,N,V_homeManager
whisper
T@"VSInstrumentMetrics",W,N,V_instrumentMetrics
.cxx_destruct
T@"NSArray",R,N
JSONObjectWithData:options:error:
T@"NSError",R,N
T@"<AFAudioPowerProviding>",W,N,V_previousProvider
T@?,C,N,V_reply
T@"<VSDeviceTTSCoreDelegate>",W,N,V_delegate
_cachingService
T@"<VSSpeechCacheItem>",&,N,V_speechCache
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
_implementation
T@"AVSampleBufferAudioRenderer",&,N,V_renderer
_knowledgeStore
T@"CKKnowledgeStore",&,N,V_knowledgeStore
_shortTermCache
T@"NSArray",&,N,V_phonemes
_timingObserver
T@"NSArray",&,N,V_wordTimingInfo
_voiceSelection
T@"NSCache",&,N,V_cache
audioBytesRange
T@"NSCondition",&,N,V_didReceiveAudioCondition
bytes_per_frame
T@"NSData",&,N,V_audioData
canUseServerTTS
T@"NSData",C,N
compressedAudio
T@"NSDate",&,N,V_audioQueueFutureEndDate
context
T@"NSDate",&,N,V_playbackBeginDate
dealloc
T@"NSDictionary",R,N,V_routeInfo
didReceiveAudio
T@"NSLock",&,N,V_threadLock
dumpCompressedAudio:forRequest:
T@"NSMutableArray",&,N,V_eagerTasks
enqueue
T@"NSMutableArray",&,N,V_finalTimingInfo
fetchVoiceAsset
T@"NSMutableArray",&,N,V_mappedAudioInfo
framesPerPacket
T@"NSMutableArray",&,N,V_streamRequestQueue
getVoiceNamesForLanguage:reply:
T@"NSMutableDictionary",&,N,V_cacheTimer
initWithDouble:
T@"NSMutableSet",&,N,V_ongoingNotifications
initWithVoicePath:resourcePath:
T@"NSObject<OS_dispatch_queue>",&,N,V_cachingQueue
isProxy
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateCallbackQueue
isWatch
T@"NSObject<OS_dispatch_queue>",&,N,V_prewarmQueue
loadedResources
T@"NSObject<OS_dispatch_queue>",&,N,V_taskAuxiliaryQueue
lowercaseString
T@"NSObject<OS_dispatch_semaphore>",&,N,V_noRemainTasks
mainDeviceQueue
T@"NSOperation<VSSpeechTaskProtocol>",&,N,V_currentTask
numberWithBool:
T@"NSString",&,N,V_connectionIdentifier
opaqueSessionID
T@"NSString",&,N,V_dirPath
outputs
T@"NSString",&,N,V_outputRoute
preheat
T@"NSString",&,N,V_streamID
quality
T@"NSString",R,C
release
T@"NSString",R,N,V_filePath
removeObserver:
T@"NSString",R,N,V_voiceResourceKey
removeVoiceResource:completion:
T@"NSUUID",&,N,V_contextId
request
T@"NSUUID",&,N,V_ttsId
serverTTSClient
T@"OPTTSAudioDescription",R,N
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
setHomeManager:
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
setIsWarmStart:
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
setNotifyQueue:
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
setPacketCount:
T@"OPTTSTTSRequestFeatureFlags",R,N
setRacingMutex:
T@"OPTTSTextToSpeechMeta",R,N
setServerAudio:
T@"OPTTSTextToSpeechRequestContext",R,N
setShouldSpeak:
T@"OPTTSTextToSpeechRequestExperiment",R,N
setSpeechCache:
T@"OPTTSTextToSpeechRequestMeta",R,N
setThreadMutex:
T@"OPTTSTextToSpeechResource",R,N
setVoiceAccent:
T@"OPTTSTextToSpeechVoice",R,N
setWithObjects:
T@"SATTSSpeechSynthesisVoice",&,N,V_streamingVoice
startVoicePreviewRequest:reply:
T@"VSAudioData",&,N,V_serverAudio
stringByAppendingPathComponent:
T@"VSAudioData",R,N,V_compressedAudio
stringFromDate:
T@"VSAudioPlaybackService",&,N,V_playbackServices
threadMutexAttr
T@"VSCachingService",&,N,V_cachingService
typeFromString:
T@"VSDeviceTTSCore",&,N,V_deviceTTSCore
version
T@"VSHHManagementClient",&,N,V_hubManagementClient
waitForNewData:
T@"VSInstrumentMetrics",&,N,V_instrumentMetrics
wordTimingInfos
T@"VSMappedData",&,N,V_mappedData
T@"VSMobileAssetsManager",&,N,V_assetsManager
T@"VSOspreyTTSCore",&,N,V_ospreyCore
T@"VSPreferencesInterface",&,N,V_preferenceInterface
T@"VSPresynthesizedAudioRequest",R,N,V_request
T@"VSPrewarmService",&,N,V_prewarmService
T@"VSServerTTSClient",&,N,V_serverTTSClient
T@"VSShortTermCache",&,N,V_shortTermCache
T@"VSSiriInstrumentation",&,N,V_siriInstrumentation
T@"VSSiriServerConfiguration",&,N,V_serverConfig
T@"VSSiriServerConfiguration",&,N,V_serverTTSConfig
T@"VSSpeechCache",&,N,V_cacheStore
T@"VSSpeechCache",R
T@"VSSpeechEngine",&,N,V_cachedEngine
T@"VSSpeechInternalSettings",&,N,V_internalSettings
T@"VSSpeechRequest",&,N,V_lastSynthesisRequest
T@"VSSpeechRequest",&,N,V_request
T@"VSSpeechRequest",R,N,V_request
T@"VSSpeechServerTask",&,N,V_speakTask
T@"VSSpeechSpeakTask",&,N,V_speakTask
T@"VSStreamAudioData",&,N,V_streamAudio
T@"VSStreamAudioData",R,N,V_streamAudio
T@"VSTimeoutCondition",&,N,V_timeoutCondition
T@"VSVoiceAsset",&,N,V_voice
T@"VSVoiceAssetSelection",&,N,V_selectedVoice
T@"VSVoiceAssetSelection",&,N,V_voiceSelection
T@"VSVoiceBooster",&,N,V_voiceBooster
T@"VSVoiceResourceAsset",&,N,V_loadedResources
T@"VSVoiceResourceAsset",&,N,V_selectedVoiceResource
T@"VSVoiceResourceAsset",&,N,V_voiceResource
T@,&,N,V_timingObserver
T@?,C,N,V_completion
TB,N
TB,N,V_didReceiveAudio
TB,N,V_endOfSiriTTSUtterance
TB,N,V_isEagerCache
TB,N,V_isNeuralFallbackCondition
TB,N,V_readyForEagerTask
TB,N,V_shouldSpeak
TB,N,V_shouldStop
TB,N,V_speechStartReported
TB,N,V_startedProvidingData
TB,N,V_synthesisHasIssue
TB,N,V_useDeviceSynthesis
TB,N,V_useServerResponse
TB,R,N
TB,R,N,V_discontinuedDuringPlayback
TI,N
TI,N,V_sessionID
TI,R,N
TQ,N
TQ,N,V_lastSynthesisRequestCreatedTimeStamp
TQ,N,V_packetCount
TQ,N,V_pcmBufferSize
TQ,N,V_playbackIntervalId
TQ,N,V_playingBufferCount
TQ,R
TQ,R,N,V_fileSize
TQ,R,N,V_type
T^v,R,N,V_mappedData
T^{OpaqueAudioComponentInstance=},N,V_voiceBoostUnit
T^{OpaqueAudioConverter=},N,V_floatConverter
T^{OpaqueAudioConverter=},N,V_integerConverter
T^{OpaqueAudioQueue=},N,V_audioQueue
T^{OpaqueCMTimebase=},N,V_timebase
T^{OpaqueCMTimebase=},R,V_timebase
Td,N
Td,N,V_bufferDurationLimit
Td,N,V_deviceTTSWaitTime
Td,N,V_enqueuedSampleCount
Td,N,V_rendererEnqueuedAudioDuration
Td,N,V_timeoutValue
Td,R,N
Td,R,N,V_estimatedDuration
Tf,N
Tf,N,V_voiceBoostGainDecibels
Tf,R,N
Ti,N
Ti,R,N
Ti,R,N,V_fd
Tq,N
Tq,N,V_activeSessionCount
Tq,N,V_packetCount
Tq,N,V_phonemeSystem
Tq,N,V_state
Tq,R,N
Tq,R,N,V_magicVersion
T{?=qiIq},N,V_mappedAudioQueuedTimeStamp
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II},N,V_audioStartTimeStamp
T{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II},N,V_audioTimeStamp
T{_NSRange=QQ},N
T{_NSRange=QQ},N,V_audioBytesRange
T{_NSRange=QQ},N,V_packetDescriptionsRange
T{_opaque_pthread_cond_t=q[40c]},N,V_stateChangeCondition
T{_opaque_pthread_cond_t=q[40c]},N,V_timeoutCondition
T{_opaque_pthread_mutex_t=q[56c]},N,V_audioQueueBufferLock
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T{_opaque_pthread_mutex_t=q[56c]},N,V_racingMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_stateLock
T{_opaque_pthread_mutex_t=q[56c]},N,V_threadMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_waitForStateChangeMutex
T{_opaque_pthread_mutexattr_t=q[8c]},N,V_recursiveLockAttr
T{_opaque_pthread_mutexattr_t=q[8c]},N,V_threadMutexAttr
URLWithString:
UTF8String
UUID
UUIDString
_activeSessionCount
_asbd
_assetsManager
_audio
_audioBytesRange
_audioData
_audioDumpFileAttributes
_audioDumpPath
_audioPowerUpdateQueue
_audioPowerUpdater
_audioQueue
_audioQueueBufferLock
_audioQueueFutureEndDate
_audioQueueStartDate
_audioStartTimeStamp
_block
_bufferDurationLimit
_cache
_cacheStore
_cacheTimer
_cachedEngine
_cachedEngineForVoice:resources:
_cachingQueue
_completion
_compressedAudio
_connection
_connectionIdentifier
_contextId
_currentPreviewURL
_currentTask
_data
_dataQueue
_deferredTTSTimingInfo
_delegate
_delegateCallbackQueue
_dequeueCondition
_deviceCore
_deviceID
_deviceTTSCore
_deviceTTSWaitTime
_didReceiveAudio
_didReceiveAudioCondition
_dirPath
_discontinuedDuringPlayback
_eagerTasks
_endOfSiriTTSUtterance
_engineForVoice:resources:
_enqueueAudioBytesLength:audioBytes:packetCount:packetDescriptions:
_enqueueCacheWithHash:audioObject:timingInfo:voiceKey:voiceResourceKey:completion:
_enqueuedMappedAudioInfo
_enqueuedSampleCount
_error
_estimatedDuration
_fetchVoiceAsset_NoRetry
_filePath
_fileSize
_finalTimingInfo
_homeManager
_hubManagementClient
_inMemoryCacheForHash:
_instrumentMetrics
_integerConverter
_internalSettings
_invalid
_isEagerCache
_isNeuralFallbackCondition
_key
_lastSynthesisRequest
_lastSynthesisRequestCreatedTimeStamp
_loadVoiceResources:forEngine:
_loadedResources
_lock
_magicVersion
_mappedAudioInfo
_mappedAudioQueuedTimeStamp
_mappedData
_neuralPlaybackSemaphore
_nextFireTime
_noRemainTasks
_notifyQueue
_onDiskCacheForHash:
_ongoingNotifications
_ospreyCore
_outputRoute
_outputRouteInfo
_packetCount
_packetDescriptions
_packetDescriptionsRange
_pcmBufferSize
_phonemeSystem
_phonemes
_play
_playbackBeginDate
_playbackIntervalId
_playbackService
_playbackServices
_playingBufferCount
_preferenceInterface
_preinstalledCacheDir
_previewPlayer
_previousProvider
_prewarmQueue
_queuedNotification
_racingMutex
_readyForEagerTask
_reallyInvalidate
_recursiveLockAttr
_refreshTimeoutCondition
_renderer
_rendererEnqueuedAudioDuration
_reply
_request
_resetNextFireTime
_root
_routeInfo
_selectedVoice
_selectedVoiceResource
_serverAudio
_serverConfig
_serverTTSClient
_serverTTSConfig
_sessionID
_shouldSpeak
_shouldStop
_siriInstrumentation
_siriRequestId
_speakTask
_speakTasks
_speakingQueue
_speechCache
_speechStartReported
_startProvidingData
_startedProvidingData
_state
_stateChangeCondition
_stateLock
_storage
_streamAudio
_streamID
_streamRequestQueue
_streamingResource
_synchronizer
_synthesisCore
_synthesisHasIssue
_synthesizerTransaction
_taskAuxiliaryQueue
_threadLock
_threadMutex
_threadMutexAttr
_timebase
_timeoutCondition
_timeoutValue
_timerQueue
_timerSource
_times
_timingInfos
_ttsId
_type
_updateLock
_useDeviceSynthesis
_useServerResponse
_voice
_voiceBoostGainDecibels
_voiceBooster
_voiceKey
_voiceResource
_voiceResourceKey
_waitForStateChangeMutex
_waitForTimeInterval:
accessoryID
activeSessionCount
activeVoiceAssets
addBoundaryTimeObserverForTimes:queue:usingBlock:
addBoundaryTimeObserverForTimes:usingBlock:
addCache:
addEndOfDataAttachment
addInProgressDownloadVoiceKey:
addInlineStreamRequest:
addObject:
addObjectToBuffer:
addObjectsFromArray:
addObserver:selector:name:object:
addRenderer:
addTask:
addTimer:forMode:
adjustWordTimingInfo:forContext:
allValues
allocWithZone:
allowedAppID
app_id
appendAudioData:packetCount:packetDescriptions:
appendBytes:length:
appendData:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayWithCapacity:
arrayWithObjects:count:
asbd
asbdFromDescription:
assetsManager
attributeForKey:
audio
audio:
audioBuffer
audioData
audioDataFromFile:error:
audioDataFromPresynthesisRequest:
audioDataFromSAUIAudioData:
audioDataWithASBD:rawData:
audioDumpFileAttributes
audioDumpPath
audioDuration
audioPlayerBeginInterruption:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerDidFinishPlaying:successfully:
audioPlayerEndInterruption:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:withOptions:
audioPowerProvider
audioPowerUpdateQueue
audioPowerUpdater
audioQueue
audioQueueBufferLock
audioQueueFutureEndDate
audioQueueStartDate
audioRequest:didReportInstrumentMetrics:error:
audioRequest:didStopAtEnd:error:
audioRequestDidStart:
audioRouteName
audioSession
audioSessionID
audioStartTimeStamp
audioStartTimestampDiffs
audioStreamBasicDescription
audioTimeStamp
audio_type
autorelease
availableLanguages
averagePowerForChannel:
beginChunkDecoderForStreamDescription:
beginEncoding
beginUpdate
bitsPerChannel
bits_per_channel
boolValue
broadcast
broadcastTimeoutCondition
bufferDurationLimit
bundlePath
bundleWithIdentifier:
bytes
bytesAtOffset:
bytesOfDuration:withAudioDescription:
bytesPerFrame
bytesPerPacket
bytes_per_packet
cache
cacheDataForKey:
cachePresynthesizedAudioRequest:
cacheStore
cacheTimer
cachedEngine
cachingQueue
cachingService
canLogRequestText
cancel
cancelDownloadForAssets:
cancelDownloads:completion:
cancelTask:
cancelTasksWithDelegate:
cappedRealTimeFactor
channel_type
channelsPerFrame
channels_per_frame
class
cleanCache
cleanDirectory:withDateOlderThan:
cleanDirectory:withLRULimit:
cleanUnknownAccessoriesPreferences
cleanUnusedAssets
cleanUnusedAssets:
clearSynthesisCache
clientBundleIdentifier
clientID
code
collectTailspin:
completion
componentsJoinedByString:
componentsSeparatedByString:
compressAudio:
compressStreamAudio:
concatenateWithAudio:
configForAppId:key:
conformsToProtocol:
connectionIdentifier
contentAsOPTTSBeginTextToSpeechStreamingResponse
contentAsOPTTSFinalTextToSpeechStreamingResponse
contentAsOPTTSPartialTextToSpeechStreamingResponse
contentAsOPTTSStartTextToSpeechStreamingRequest
contentVersion
content_type
contextId
contextInfo
context_info
continueSpeechRequest:
convertLanguageCodeToSchemaLocale:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryIfNeeded
createFileAtPath:contents:attributes:
createNewXPCWrapperWithCompletion:
createSampleBuffer:
createSampleBufferIdNeeded:
createSilenceEndBuffer
createdTimestampWithTask:
currentPowerPolicyWithError:
currentPreviewURL
currentRoute
currentTask
currentTime
current_pkt_number
customResourceURLs
data
dataQueue
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithCapacity:
dataWithContentsOfFile:
dataWithJSONObject:options:error:
date
dateByAddingTimeInterval:
dateWithTimeIntervalSinceNow:
debugDescription
decodeChunk:outError:
decodeChunks:streamDescription:outError:
decoderStreamDescription
decoder_description
defaultCacheStore
defaultCenter
defaultConfig
defaultManager
defaultPitch
defaultRate
defaultService
defaultSessionConfiguration
defaultVoiceGender
defaultVoiceNameForGender:
defaultVolume
deferredTTSTimingInfo
delegate
delegateCallbackQueue
deleteCache
dequeueAvailableMappedAudio
dequeueCondition
derivedIdentifierForComponentName:fromSourceIdentifier:
description
descriptiveKey
deviceCore
deviceID
deviceTTSCore
deviceTTSWaitTime
deviceUUID
deviceWaitTimeForAppId:
dialog_identifier
dictForKey:
dictionary
dictionaryMetrics
dictionaryRepresentation
dictionaryWithObjects:forKeys:count:
didEndAccessPower
didReceiveAudioCondition
directorySize:
disableAssetCleaning
disableAssetUpdate
disableCache
disableCompactVoiceFallback
disableDeviceRacing
disableInlineStreamTTS
disableMobileAssetURLReset
disableOspreyStreaming
disableServerTTS
discontinuedDuringPlayback
domain
doubleValue
downloadOptionsWithBattery:
downloadQueue
downloadVoiceAsset:options:progressUpdateHandler:
downloadVoiceResource:options:completion:
dumpInstrumentMetrics:withTimestamp:
dumpStreamAudio:forRequest:
duration
duration:
durationOfAudioDataLength:withAudioDescription:
eagerRequestCreatedTimestampDiffs
eagerTaskHashForRequest:
eagerTasks
emitMessage:
enable_word_timing_info
encodeChunk:
endAudioPowerUpdate
endChunkDecoding
endEncoding
endOfSiriTTSUtterance
endUpdate
engine
enqueue:packetCount:packetDescriptions:
enqueueAudioData:
enqueueCache
enqueueCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueCacheWithHash:streamAudio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueSampleBuffer:
enqueueShortTermCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueStreamId:withObject:
enqueuedMappedAudioInfo
enqueuedSampleCount
enumerateAudioWithBlock:
enumerateObjectsWithOptions:usingBlock:
error
errorCode
errorMessage
errorWithDomain:code:userInfo:
error_code
error_str
estimateDurationWithRequest:reply:
estimatedDuration
estimatedTTSWordTimingForText:withLanguage:voiceName:
eventMetadata
exceptionWithName:reason:userInfo:
experiment
experimentIdentifier
experiment_identifier
fallbackLanguageForLanguage:
fallbackToDeviceSynthesis
fe_feature
feature_flags
fetchCacheForTask:
fetchVoiceResource
fileExistsAtPath:
fileExistsAtPath:isDirectory:
filePath
fileSize
fileURLWithPath:
fileURLWithPathComponents:
firstObject
flatbuffData
floatConverter
floatValue
flush
flushAndStop
footprint
footprintFromString:
footprintStringFromFootprint:
forceServerTTS
formatFlags
formatID
format_flags
format_id
forwardStreamObject:
frames_per_packet
freeAudioQueue
gainDecibelWithVolume:
gender
genderFromString:
genderStringFromGender:
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAllVoiceSubscriptionsWithReply:
getAveragePower:andPeakPower:
getCacheForHash:
getCurrentAudioPowerProvider
getFootprintsForVoiceName:languageCode:reply:
getLocalVoiceResourcesReply:
getLocalVoicesForLanguage:reply:
getSpeechIsActiveForConnectionReply:
getSpeechIsActiveReply:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
getVoiceResourceForLanguage:reply:
handleBegin:
handleChunk:
handleDeviceSynthesis:timingInfo:
handleEnd:
handleMediaServerReset
handleServerResponse:timingInfo:
handleStreamNotification:
handleVoiceSelectionPurge:
hasAlignmentStall
hasAudioClick
hasInlineStreamRequestForSpeakRequest:
hasPhaticResponses:
hash
homeManager
hubManagementClient
identifier
implementation
inMemoryCacheForHash:
inMemoryCaches
inProgressDownloadVoiceKeys
inactiveVoiceAssets
init
initAndVerifyWithFlatbuffData:
initWithASBD:
initWithArray:copyItems:
initWithAudioSessionID:asbd:
initWithAudioSessionID:asbd:useAVSBAR:
initWithBool:
initWithBytes:length:encoding:
initWithBytesNoCopy:length:deallocator:
initWithCache:shortTermMemory:
initWithConnection:
initWithContentsOfURL:fileTypeHint:error:
initWithCurrentProcess
initWithData:encoding:
initWithDirectory:
initWithFilePath:
initWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
initWithFloat:
initWithInt:
initWithInteger:
initWithKey:audio:wordTimingInfo:voiceKey:voiceResourceKey:
initWithKey:data:
initWithProvider:queue:frequency:delegate:
initWithRequest:
initWithRequest:shouldSpeak:
initWithRequest:withStreamID:
initWithRouteAttributes:
initWithSiriRequestId:
initWithSourceASBD:
initWithStorePath:
initWithStreamDescription:pcmBufferSize:
initWithTimebase:times:queue:block:
initWithTimeoutValue:
initWithType:
initWithType:assetsManager:
initWithURL:configuration:
initWithUnsignedInteger:
initialize
initializeDeviceAuthenticationSessionWithCompletion:
installedAssetsForType:voicename:language:gender:footprint:
installedVoiceResources
instrumentMetrics
instrumentPowerEvent:ttsId:
instrumentRequestReceivedWithText:requestedVoiceType:requestedVoiceFootprint:isPrivate:
instrumentSpeechCancelled
instrumentSpeechEndedWithAudioDuration:synthesisLatency:realTimeFactor:promptCount:errorCode:
instrumentSpeechFailedWithErrorCodes:
instrumentSpeechStartedWithSource:customerPerceivedLatency:audioOutputRoute:voiceType:voiceFootprint:voiceVersion:resourceVersion:isWhisper:
instrumentVoiceFallbackOccurredWithVoice:resource:
instrumentVoicedProcessStartedPowerEvent
intValue
integerConverter
integerValue
internalSettings
invalidate
invokeDaemon:
isANECompilationPlatform
isAppleProduct
isAudioQueueRunning
isAudioQueueStalled
isBluetoothRoute
isCancelled
isEagerCache
isEqual:
isEqualToDictionary:
isEqualToString:
isExecuting
isExistingAccessoryId:
isFinished
isHomeHub
isHomePod
isKindOfClass:
isMemberOfClass:
isNeuralFallbackCondition
isPreinstalledCacheAvailableForRequest:
isReadableFileAtPath:
isReadyForMoreMediaData
isSeedBuild
isServerTTS
isSimilarTo:
isSiriClientBundleIdentifier:
isSpeaking
isSynthesisCached
isVoiceReadyToUse
isWarmStart
killDaemon
knowledgeStore
language
languageCode
languages
lastObject
lastPathComponent
lastSynthesisRequest
lastSynthesisRequestCreatedTimeStamp
lastTTSRequestDate
length
linkId
loadEngineForVoice:resources:
loadResource:error:
loadResourceAtPath:mimeType:error:
localizedDescription
localizedInterstitialStringForKey:language:
lock
logFinish
logUtterance
logWithEventContext:
logWithEventContext:ttsIdentifier:
longLongValue
lowInactiveMemory
magicVersion
main
mainRunLoop
makeRequestLinkEvent
mappedAudioQueuedTimeStamp
mappedData
meta_info
migrateAssetsWithProgress:
mmap
moveItemAtPath:toPath:error:
mutableBytes
mutablePCMData
name
neuralAlignmentStall
neuralAudioClick
neuralDidFallback
neuralFallback
neuralPlaybackSemaphore
noRemainTasks
notifyQueue
numOfPromptsTriggered
numberWithDouble:
numberWithInt:
numberWithInteger:
numberWithLongLong:
object
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
offset
onDiskCacheForHash:
ongoingNotifications
orderedSet
ospreyCore
ospreyCore:didFinishWithError:
ospreyCore:didReceiveAudio:wordTimingInfo:
ospreyEndpointURL
ospreyServiceEndpointURL
ospreyStartStreamingRequest:dataHandler:metaInfoHandler:completion:
ospreyStartSynthesisRequest:responseHandler:completion:
outputPath
outputRoute
outputRouteFromRouteInfo:
packetCount
packetDescriptions
packetDescriptionsRange
parallelQueueWithIdentifier:
path
pathWithComponents:
pause
pausePlayback
pauseSpeechRequest:atMark:
pcmAudioDataFromOpusAudio:
pcmBufferSize
peakPowerForChannel:
performLanguageFallBackIfNeededWithRequest:
performRoundTripOspreyTTS
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performStreamingOspreyTTS
periodic:urgency:
phonemeSystem
phonemes
pitch
play
playbackBeginDate
playbackIntervalId
playbackServices
playback_description
playerStreamDescription
playingBufferCount
popInlineStreamRequestForSpeakRequest:
popShortTermCacheForHash:
populatePCMDataWithSiriOpusSData:withOpusASBD:
populateWithOpusData:
populateWithPCMData:
portType
postNotificationName:object:
powerProfile
precomposedStringWithCanonicalMapping
preferenceInterface
preferredDownloadForVoice:
preferred_voice_type
preinstalledAudioHashForLanguage:name:
preinstalledCacheDir
preinstalledCacheForText:language:name:
prepareForSynthesis
preprocessRequestBeforeSynthesis:
previewAudioURLForLanguage:voiceName:previewType:
previewPlayer
previewRequestDidStartPlaying:
previewType
previousProvider
prewarmIfNeededWithRequest:reply:
prewarmQueue
prewarmService
prewarmWithRequest:
proceedWithServerTTS
proceedWithSpeechCache:
processData:
promptCount
purge:urgency:
purgeAsset:
purgeImpl:urgency:
purgeable:urgency:
purgeableAssetsWithInfo:urgency:
queryPhaticCapabilityWithRequest:reply:
queuedNotification
racingMutex
rate
readyForEagerTask
recursiveLockAttr
refreshTimeoutCondition
registerCacheDelete
registerPostInstallActivity
remoteObjectProxy
removeAllObjects
removeDirectory:
removeInProgressDownloadVoiceKey:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeOldFiles
removeTimeObserver:
renderer
rendererEnqueuedAudioDuration
renderers
reply
reportAudio:
reportFinish
reportInstrumentMetrics
reportInstrumentMetrics:
reportSpeechStart
reportTimingInfo
reportWordTimingInfo:
requestCreatedTimestamp
requestFromVSRequest:
requestMediaDataWhenReadyOnQueue:usingBlock:
requestedVoiceContext
reserved
resetCache
resetMobileAssetDefaults
resource
resourceList
resourceMimeTypes
resourcePath
respondsToSelector:
resume
resumeCurrentTask
resumePlayback
retain
retainCount
retrieveSessionWithID:
retryDeviceOnNetworkStall
roundTripTTS:responseHandler:
routeInfo
sampleBuffer
sampleRate
sample_idx
sample_rate
schemaFootprintFromFootprint:
schemaVoiceGenderFromGender:
schemaVoiceTypeFromType:
searchPathURL
selectVoiceForLang:name:type:gender:footprint:
selectVoiceResourceAssetForLanguage:
selectedVoice
selectedVoiceResource
self
serializedData
serverAudio
serverConfig
serverFirstPacketTimestamp
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
serverTTSTimeout
sessionID
session_id
setActive:error:
setActive:withOptions:error:
setActiveSessionCount:
setAllowsCellularAccess:
setApp_id:
setAsbd:
setAssetsManager:
setAudio:
setAudioBytesRange:
setAudioData:
setAudioDumpFileAttributes:
setAudioDumpPath:
setAudioDuration:
setAudioOutputRoute:
setAudioPowerUpdateQueue:
setAudioPowerUpdater:
setAudioQueue:
setAudioQueueBufferLock:
setAudioQueueFutureEndDate:
setAudioQueueStartDate:
setAudioSession:
setAudioStartTimeStamp:
setAudioStartTimestampDiffs:
setAudioTimeStamp:
setAudio_type:
setBits_per_channel:
setBoundaryTimeObserverForTimingInfos:usingBlock:
setBufferDurationLimit:
setBytes_per_frame:
setBytes_per_packet:
setCache:
setCacheStore:
setCacheTimer:
setCachedEngine:
setCachingQueue:
setCachingService:
setCanUseServerTTS:
setCancelled:
setCategory:error:
setChannel_type:
setChannels_per_frame:
setClientBundleIdentifier:
setClientTraceIdentifier:
setCompletion:
setCompletionBlock:
setComponent:
setCompressedAudio:
setConnectionIdentifier:
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContentVersion:
setContent_type:
setContext:
setContextId:
setContext_info:
setCurrentPreviewURL:
setCurrent_pkt_number:
setCustomerPerceivedLatencyInSecond:
setDataQueue:
setDateFormat:
setDecoder_description:
setDeferredTTSTimingInfo:
setDelaysRateChangeUntilHasSufficientMediaData:
setDelegate:
setDelegateCallbackQueue:
setDequeueCondition:
setDeviceCore:
setDeviceID:
setDeviceTTSCore:
setDeviceTTSWaitTime:
setDialog_identifier:
setDidReceiveAudio:
setDidReceiveAudioCondition:
setDirPath:
setDisableDeviceRacing:
setEagerRequestCreatedTimestampDiffs:
setEagerTasks:
setEnable_word_timing_info:
setEndOfSiriTTSUtterance:
setEnded:
setEngine:
setEnqueuedMappedAudioInfo:
setEnqueuedSampleCount:
setError:
setErrorCode:
setErrorCodes:
setErrorHandler:
setError_code:
setError_str:
setEventMetadata:
setExists:
setExperiment:
setExperimentIdentifier:
setExperiment_identifier:
setFailed:
setFe_feature:
setFe_feature_only:
setFeature_flags:
setFinalTimingInfo:
setFloatConverter:
setFootprint:
setFormat_flags:
setFormat_id:
setFrames_per_packet:
setGender:
setHubManagementClient:
setImplementation:
setInMemoryCaches:
setInputTextLength:
setInstrumentMetrics:
setIntegerConverter:
setInternalSettings:
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
setIsEagerCache:
setIsNeuralFallbackCondition:
setIsServerStreamTTS:
setIsServerTTSRacing:
setIsServerTimeout:
setIsSpeechRequest:
setKnowledgeStore:
setLanguage:
setLanguageCode:
setLanguages:
setLastSynthesisRequest:
setLastSynthesisRequestCreatedTimeStamp:
setLastTTSRequestDate:
setLength:
setLinkId:
setLoadedResources:
setLock:
setMappedAudioInfo:
setMappedAudioQueuedTimeStamp:
setMappedData:
setMeta_info:
setMeteringEnabled:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralFallback:
setNeuralPlaybackSemaphore:
setNoRemainTasks:
setObject:forKey:
setObject:forKey:timeToLive:
setObject:forKeyedSubscript:
setObserverForWordTimings:
setOffset:
setOngoingNotifications:
setOpusDataHandler:
setOspreyCore:
setOutputPath:
setPacketDescriptions:
setPacketDescriptionsRange:
setPcmBufferSize:
setPhonemeSystem:
setPhonemes:
setPitch:
setPlaybackBeginDate:
setPlaybackIntervalId:
setPlaybackService:
setPlaybackServices:
setPlayback_description:
setPlayingBufferCount:
setPowerProfile:
setPreferenceInterface:
setPreferred_voice_type:
setPreinstalledCacheDir:
setPreviewPlayer:
setPreviousProvider:
setPrewarmQueue:
setPrewarmService:
setQuality:
setQueuedNotification:
setRate:
setRate:time:
setReadyForEagerTask:
setRecursiveLockAttr:
setRefreshTimeoutCondition:
setRenderer:
setRendererEnqueuedAudioDuration:
setReply:
setRequest:
setRequestCreatedTimestamp:
setRequestReceived:
setRequestReceivedTier1:
setRequestedVoiceContext:
setReserved:
setResource:
setResourceVersion:
setSample_idx:
setSearchPathURL:
setSelectedVoice:
setSelectedVoiceResource:
setServerConfig:
setServerFirstPacketTimestamp:
setServerLastPacketTimestamp:
setServerTTSClient:
setServerTTSConfig:
setSessionID:
setSession_id:
setShortTermCache:
setShouldStop:
setSiriInstrumentation:
setSiriRequestId:
setSource:
setSpeakTask:
setSpeakTasks:
setSpeakingQueue:
setSpeechBeginTimestamp:
setSpeechContext:
setSpeechEndTimestamp:
setSpeechStartReported:
setSpeech_id:
setStartTime:
setStartedOrChanged:
setStartedProvidingData:
setState:
setStateChangeCondition:
setStateLock:
setStreamID:
setStreamRequestQueue:
setStream_id:
setStreamingResource:
setStreamingVoice:
setStreaming_playback_buffer_size_in_seconds:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
setSubscribedVoices:forClientID:accessoryID:
setSynchronizer:
setSynthesisBeginTimestamp:
setSynthesisCore:
setSynthesisEffect:
setSynthesisEndTimestamp:
setSynthesisHasIssue:
setSynthesisLatencyInSecond:
setSynthesisRealTimeFactor:
setSynthesisSource:
setSynthesizedAudioDurationInSecond:
setSynthesizerTransaction:
setTarget:
setTaskAuxiliaryQueue:
setText:
setTextRange:
setTextToSynthesize:
setThreadLock:
setThreadMutexAttr:
setTimebase:
setTimeoutCondition:
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
setTimeoutValue:
setTimestamp:
setTimingObserver:
setTotal_pkt_number:
setTtsId:
setType:
setUpdateLock:
setUseCompression:
setUseDeviceSynthesis:
setUseServerResponse:
setUtterance:
setUuid:
setValue:
setVersion:
setVoice:
setVoiceAssetKey:
setVoiceBoostGainDecibels:
setVoiceBoostUnit:
setVoiceBooster:
setVoiceContext:
setVoiceFallbackOccurred:
setVoiceFootprint:
setVoiceName:
setVoiceResource:
setVoiceResourceAssetKey:
setVoiceSelection:
setVoiceSettings:
setVoiceType:
setVoiceVersion:
setVoice_name:
setVolume:
setWaitForStateChangeMutex:
setWithArray:
setWord:
setWordTimingInfo:
setWord_timing_info:
sha256hex
sharedAVSystemController
sharedInstance
sharedManager
sharedPowerLogger
sharedService
sharedServices
sharedStream
shortTermCache
shortTermCacheForHash:
shortTermCachedEngineForVoice:voiceResource:
shortTermCachedEngines
shouldCache
shouldDeferDeviceTTS
shouldDelayVoiceUpdate
shouldRelyOnServerTTS
shouldSpeak
shouldStop
shouldStreamAudioData
shouldUseServerTTSForRequest:
shouldWaitCurrentSpeaking
shouldWhisper
signal
signalNewDataWithError:
signalQueueRunningStateChange
simulateNetworkStall
siriInstrumentation
siriRequestId
size
sortedArrayUsingComparator:
sourceOfTTS
speakCachedAudio
speakRetryPhrase
speakTask
speakTasks
speakingQueue
speechBeginTimestamp
speechCache
speechEndTimestamp
speechRequest:didReceiveTimingInfo:
speechRequest:didReportInstrumentMetrics:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequestDidContinue:
speechRequestDidPause:
speechRequestDidStart:
speechStartReported
speechSynthesisResource
speechSynthesisVoice
speech_id
spinNextTask
standardInstance
start
startPhonemesRequest:phonemeSystem:reply:
startPlayback
startPlaybackServiceWithAudioSessionID:
startPresynthesizedAudioRequest:
startSpeechRequest:reply:
startStreamingWithId:
startSynthesisRequest:
startVoicePreviewForLanguageCode:voiceName:previewType:startedPlaying:completion:
startVoicePreviewWithURL:startedPlaying:completion:
startedProvidingData
state
stateChangeCondition
stateLock
stop
stopAtMarker:
stopRequestingMediaData
stopSpeechRequest:atMark:
stopVoicePreview
stopWaiting
streamAudio
streamBufferDuration
streamID
streamId
streamRequestQueue
streamTTS:beginHandler:chunkHandler:endHandler:completion:
stream_id
streamingPlaybackBufferSize
streamingResource
streamingVoice
streaming_playback_buffer_size_in_seconds
stringByAppendingString:
stringByReplacingOccurrencesOfString:withString:
stringOfSourceOfTTS:
stringWithFormat:
stringWithUTF8String:
subdataWithRange:
subscribedVoicesForClientID:accessoryID:
superclass
suspendCurrentTask
synchronizer
synthesisBeginTimestamp
synthesisCore
synthesisCore:didReceiveAudio:
synthesisCore:didReceiveProcessingWordTimingInfo:
synthesisCore:didReceiveWordTimingInfo:
synthesisEndTimestamp
synthesisHasIssue
synthesisRequest:didFinishWithInstrumentMetrics:error:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didReceiveTimingInfo:
synthesisSourceFromSource:
synthesize
synthesizeAndSpeak
synthesizeText:loggable:callback:
synthesizerTransaction
taskAuxiliaryQueue
taskHash
taskWithCreatedTimeStamp:
tasksWithDelegate:
text
textRange
threadLock
threadMutex
timeIntervalSinceDate:
timeIntervalSinceNow
timeToLiveTimerFired:
timeToSpeakLatency
timebase
timeoutCondition
timeoutForAppId:
timeoutValue
timerWithTimeInterval:target:selector:userInfo:repeats:
timestamp
timingInfos
timingObserver
totalCacheSize
totalDiagnosticFileSize
totalSizeOfAssets:
total_pkt_number
transferPreinstallErrorMessagesOfLanguage:voiceName:forAccessoryID:
triggerCellularDownloadedVoiceAssets:withClientID:
triggerNeuralCompiling
ttsId
ttsPolicy
ttsSynthesisLatency
type
typeStringFromType:
unarchivedObjectOfClasses:fromData:error:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
uninitialize
unloadCachedEngineWithVoice:
unloadEngine
unlock
unsignedIntValue
unsignedIntegerValue
updateLock
updateMeters
updateTrialVoiceResourceWithLanguage:
updateVoiceIfNeeded:
updateVoicesAndVoiceResources
updateWithConnectionIdentifier:keepActive:
useDeviceSynthesis
useSSMLInput
useServerResponse
useSiriTTSService
userDefaultsKnowledgeStore
userInfo
utf16TimingInfoWithUTF8Range:withText:
utterance
value
valueForEntitlement:
valueForKey:
valueWithBytes:objCType:
voice
voiceAssetKey
voiceAssetsForSubscription:
voiceBoostGainDecibels
voiceBoostUnit
voiceBooster
voiceContext
voiceData
voiceKey
voiceName
voicePath
voiceResource
voiceResourceAssetKey
voiceResourceKey
voiceSelection
voiceSelectionWithRequest:error:
voiceSelection_noRetry_WithRequest:error:
voiceSettings
voiceType
voice_name
volume
vsDescription
vs_convertToSSML
vs_insertContextInfo:
vs_stringFrom4CC:
vs_textifyEmojiWithLanguage:
vs_voice
vs_voiceResource
vs_wordTimingInfos:withText:
wait
waitForAudioQueueStop
waitForStateChangeMutex
waitUntilAudioFinished
waitUntilDate:
waitUntilFinished
waitUntilFinishedIfAudioReceivedWithin:
waitUntilPrewarmFinish
willBeginAccessPower
word
wordTimingInfo
word_timing_info
writeAudioIfNeeded:
writeToFile:atomically:
writeToFile:options:error:
writeToFilePath:
writeWaveToFilePath:
zone
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v16@0:8
@"VSInstrumentMetrics"16@0:8
v24@0:8@16
v24@0:8@"NSArray"16
@"VSSpeechRequest"16@0:8
v24@0:8@"VSSiriInstrumentation"16
@"<AFAudioPowerProviding>"16@0:8
v24@0:8@"<VSSpeechSpeakableProtocol>"16
@24@0:8@16
v20@0:8B16
@"VSSpeechSpeakTask"
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v24@0:8Q16
^{opaqueCMSampleBuffer=}
{_NSRange="location"Q"length"Q}
@60@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20
v40@0:8@16q24@32
@32@0:8@16@?24
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
I16@0:8
v20@0:8I16
v40@0:8@"NSData"16q24@"NSData"32
@"NSError"16@0:8
@32@0:8@"NSArray"16@?<v@?{?=qiIq}>24
v24@0:8@"NSError"16
B32@0:8^f16^f24
^{opaqueCMSampleBuffer=}24@0:8@16
d24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
q16@0:8
v24@0:8q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
d16@0:8
v24@0:8d16
@"NSError"
@"AVSampleBufferAudioRenderer"
@"AVSampleBufferRenderSynchronizer"
@"NSObject<OS_dispatch_queue>"
@"NSString"
@"VSMappedData"
@"NSMutableArray"
@"NSObject<OS_dispatch_semaphore>"
{?="value"q"timescale"i"flags"I"epoch"q}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16Q56
v20@0:8f16
f16@0:8
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{OpaqueAudioComponentInstance=}16@0:8
v24@0:8^{OpaqueAudioComponentInstance=}16
{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16@0:8
v80@0:8{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16
^{OpaqueAudioConverter=}
^{OpaqueAudioComponentInstance=}
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
@32@0:8@16@24
@"VSSpeechRequest"
@"VSInstrumentMetrics"
@"VSDeviceTTSCore"
v40@0:8@16@24@32
@"NSArray"
@"<VSSpeechServiceDelegate>"
@"VSSpeechEngine"
@"VSVoiceBooster"
@"VSAudioPlaybackService"
@"VSVoiceAssetSelection"
@"VSVoiceResourceAsset"
@"VSCachingService"
@"VSPrewarmService"
@"VSSiriInstrumentation"
@"<VSSpeechCacheItem>"
@"VSAudioData"
@"VSStreamAudioData"
v32@0:8@16@24
v32@0:8@"VSDeviceTTSCore"16@"VSAudioData"24
v32@0:8@"VSDeviceTTSCore"16@"NSArray"24
v40@0:8@"VSOspreyTTSCore"16@"VSAudioData"24@"NSArray"32
v32@0:8@"VSOspreyTTSCore"16@"NSError"24
@28@0:8@16B24
{_opaque_pthread_cond_t=q[40c]}16@0:8
v64@0:8{_opaque_pthread_cond_t=q[40c]}16
@"VSSpeechServerTask"
@"VSSpeechInternalSettings"
@"VSOspreyTTSCore"
@"VSSiriServerConfiguration"
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
Vv28@0:8@16B24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16q24@?32
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv28@0:8@"NSString"16B24
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv40@0:8@"VSSpeechRequest"16q24@?<v@?@"NSString"@"NSError">32
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset"@"NSError">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
@"NSXPCConnection"
@"VSHHManagementClient"
@"VSHMHomeManager"
@"AFAudioPowerUpdater"
@"NSObject<OS_os_transaction>"
@"<VSOspreyTTSCoreDelegate>"
@"VSVoiceAsset"
@"VSServerTTSClient"
@"VSTimeoutCondition"
@"NSCondition"
@40@0:8@16@24q32
v56@0:8@16@24q32@?40@?48
v28@0:8@16B24
v32@0:8@16Q24
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
v40@0:8@16@?24@?32
@?16@0:8
v24@0:8@?16
@"AVAudioPlayer"
@"NSURL"
@"NSData"16@0:8
@32@0:8@"NSString"16@"NSData"24
@56@0:8@16@24@32@40@48
@"NSData"
@40@0:8@16@24@32
@24@0:8^{_NSZone=}16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
i16@0:8
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@48@0:8^{OpaqueCMTimebase=}16@24@32@?40
^{OpaqueCMTimebase=}16@0:8
@"NSObject<OS_dispatch_source>"
^{OpaqueCMTimebase=}
@44@0:8I16r^v20q28r^v36
^{OpaqueAudioQueue=}16@0:8
v24@0:8^{OpaqueAudioQueue=}16
v24@0:8^{OpaqueCMTimebase=}16
^{OpaqueAudioQueue=}
@"NSDate"
@"NSDictionary"
d64@0:8Q16{AudioStreamBasicDescription=dIIIIIIII}24
Q64@0:8d16{AudioStreamBasicDescription=dIIIIIIII}24
@64@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20B60
v32@0:8@16@?24
@"VSAudioRouteInfo"
@"<VSAudioPlaybackServiceProtocol><AFAudioPowerProviding>"
@32@0:8@16^@24
@"<VSDeviceTTSCoreDelegate>"
@28@0:8@16i24
q24@0:8@16
@24@0:8d16
B24@0:8d16
@24@0:8Q16
@32@0:8Q16@24
@"VSMobileAssetsManager"
@"VSPreferencesInterface"
@"NSLock"
v56@0:8@16@?24@?32@?40@?48
f24@0:8d16
v32@0:8@16q24
@"CKKnowledgeStore"
v40@0:8@16@24d32
@"NSCache"
@"SATTSSpeechSynthesisResource"
@"SATTSSpeechSynthesisVoice"
@"VSPresynthesizedAudioRequest"
@"NSMutableData"
@"<AFAudioPowerProviding>"
{_opaque_pthread_mutexattr_t=q[8c]}16@0:8
v32@0:8{_opaque_pthread_mutexattr_t=q[8c]}16
@"NSMutableSet"
{_opaque_pthread_mutexattr_t="__sig"q"__opaque"[8c]}
v20@0:8i16
v48@0:8@16@?24@?32@?40
v64@0:8@16@24@32@40@48@?56
@"VSSpeechCache"
@"VSShortTermCache"
i24@0:8q16
i24@0:8@16
v44@0:8@16q24q32B40
v76@0:8q16d24@32q40q48Q56Q64B72
v56@0:8d16d24d32Q40q48
@"NSUUID"
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
v40@0:8@16Q24@32
Q24@0:8@16
@"NSOperation<VSSpeechTaskProtocol>"
B64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
{AudioStreamBasicDescription=dIIIIIIII}24@0:8@16
@24@0:8q16
^v16@0:8
mcpl
xfuakrfc
333333
N11flatbuffers16DefaultAllocatorE
N11flatbuffers9AllocatorE
VoiceServicesErrorDomain
Synthesis is cancelled/interrupted.
writeWaveToFilePath failed.
v8@?0
@"NSError"16@?0@"VSSpeechSynthesisCallbackResult"8
v16@?0@"VSSpeechWordTimingInfo"8
VSAudioPlaybackServiceAVSBARQueue
Error in creating block buffer for Sample buffer
Error in CMAudioFormatDescriptionCreate
Error in CMAudioSampleBufferCreateWithPacketDescriptions
Error in creating block buffer for Silence buffer
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
{?=qiIq}
Timeout waiting for AVSampleBufferRenderSynchronizer
q24@?0@"NSValue"8@"NSValue"16
v32@?0@"NSValue"8Q16^B24
cached_engine_%@_%@
Use `initWithRequest:`.
%@ %@ %@ %@ %.2f %.2f %.2f %@ %@
Speech is cancelled/interrupted.
v20@?0B8@"NSString"12
ServerTTSErrorDomain
Use `initWithRequest:shouldSpeak:`.
%@ %@
v40@?0@"NSData"8Q16@"NSData"24^B32
Unable to create playback service
EagerTTS:%@:%@:%@:%@:%@:%@:%@:%@:%@
Cancelled
Finished
speaking
synthesizing
voice
(null)
is_eager
is_one_shot
is_time_out
is_device_tts
source_of_tts
com.apple.springboard
com.apple.siri
com.apple.CarPlayApp
com.apple.Carousel
com.apple.AssistantServices
com.apple.SiriHeadlessService
\mrk=emo=whisper\
com.apple.voiced.can-dump-audio
com.apple.voiced.request.durationestimation
com.apple.voiced.request.speech
com.apple.voiced.request.presynthesis
unknown:unknown:PresynthesizedAudio
unknown:PresynthesizedAudio:unknown
com.apple.voiced.request.synthesis
com.apple.voiced.request.text_to_phonemes
VSAudioPowerUpdateQueue
-[VSSpeechXPCHandler beginAudioPowerUpdateWithReply:]
v16@?0@"AFXPCWrapper"8
-[VSSpeechXPCHandler endAudioPowerUpdate]
%@:%@:%@:%@
Missing languageCode
-[VSSpeechXPCHandler getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:]
VSOspreyTTSCoreCallbackQueue
v24@?0@"VSAudioData"8@"NSArray"16
v16@?0@"NSError"8
Osprey round-trip TTS timed out
v28@?0@"VSVoiceAsset"8@"VSVoiceResourceAsset"16f24
Osprey streaming network stall
Osprey streaming TTS timed out
Osprey core is not able to provide audio in time
com.apple.voiced.postInstall
v20@?0f8^B12
v16@?0@"NSObject<OS_xpc_object>"8
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.VoiceResources
com.apple.voiced.voicePreviewQueue
com.apple.voiceservices
VoicePreviews
_Buddy
%@_%@%@.caf
v20@?0d8B16
InvalidCache
Audio duration too short
duration %.2f second
TTSResources/PreinstallCache/
VSSpeechCacheErrorDomain
-[VSSpeechCache initWithStorePath:]
VoiceServices
Cache type name too long
-[VSSpeechCache addCache:]
%@_%@
%@:%@:%@:%@:%@:%@
gryphon
unknown
premium
%@:%@:%@
preinstalledCache
FlatBuffers 1.12.0
v24@?0^v8Q16
resource
context_info
meta_info
context
experiment
feature_flags
decoder_description
playback_description
word_timing_info
v20@?0r*8I16
content
Verifier
flatbuffers.h
size_ < FLATBUFFERS_MAX_BUFFER_SIZE
NotNested
!nested
!num_field_loc
ensure_space
cur_ >= scratch_ && scratch_ >= buf_
size() < FLATBUFFERS_MAX_BUFFER_SIZE
reallocate_downward
new_size > old_size
EndTable
nested
table_object_size < 0x10000
!ReadScalar<voffset_t>(buf_.data() + field_location->id)
data
cur_
scratch_end
scratch_
scratch_data
buf_
finished
ReferTo
off && off <= GetSize()
EndVector
Finish
strlen(file_identifier) == kFileIdentifierLength
vector
'%c%c%c%c', %.0fhz, %d bits, %d FPP, 
%@:%@
voiced_tts_playback_queue
Error AudioQueueStart
Error AudioQueueFlush
Error AudioQueueStop
Error AudioQueuePause
Error AudioQueueAddPropertyListener
Error AudioQueueRemovePropertyListener
YYYY-MM-dd hh:mm:ss:SSS
Error AudioQueueGetProperty isRunning
Unable to enable kAudioQueueProperty_EnableLevelMetering
Unable to disable kAudioQueueProperty_EnableLevelMetering
-[VSAudioPlaybackServiceAT getAveragePower:andPeakPower:]
Unable to get kAudioQueueProperty_CurrentLevelMeterDB
hdft
Hdft
usbD
hx90
wx90
rhac
wdef
com.apple.voiceservices.notification.voice-update
Missing utterance in the request (preprocessing missing?).
No voice available
Compact voice is explicitly disabled.
Voice is deleted already.
Can't create VSSpeechEngine
CACHE_DELETE_AMOUNT
CACHE_DELETE_VOLUME
com.apple.voiced.CacheDelete
r^{__CFDictionary=}20@?0i8r^{__CFDictionary=}12
com.apple.voiced.downloadQueue
on accessory %@
q24@?0@"VSVoiceAsset"8@"VSVoiceAsset"16
v20@?0d8f16
com.apple.sirittsd.neuralCompiling
v12@?0i8
com.apple.voiced.neural-compiling
https://dejavu.apple.com
https://seed-dejavu.siri.apple.com
https://carry-dejavu.siri.apple.com
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
v16@?0@"OspreyMutableRequest"8
-[OspreyTTSService roundTripTTS:responseHandler:]_block_invoke_2
Empty data
-[OspreyTTSService roundTripTTS:responseHandler:]_block_invoke
Invalid data
Error %d in response: %@
v24@?0@"NSData"8@"NSError"16
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
Corrupted Osprey response.
-[OspreyTTSService streamTTS:beginHandler:chunkHandler:endHandler:completion:]_block_invoke
v16@?0@"NSData"8
/private/var/mobile/Library/Logs/CrashReporter/VoiceServices/
mobile
-[VSDiagnosticService createDirectoryIfNeeded]
yyyy_MM_dd-HHmmss.SSS
TTS-%@
.tmp
.wav
TTSMetrics-%lld
.json
default
ServerTTSTimeoutV2
DeviceWaitTimeV2
TTSExperimentConfig
identifier
method
delayed
AllowedAppId
com.apple.MapsSupport
com.apple.Translate
com.apple.SessionTrackerApp
Use `initWithRequest:withStreamID:`.
Unknown inline streaming error %d, %@
Missing utterance in the request (preprocessing missing?). Can't fallback to device TTS.
voice_resource
task: inprogress %@, request: %@
Can't create VSAudioPlaybackService
Can't decode audio data
audio_duration
com.apple.voiced.VSInlineStreamService
fe_feature
fe_feature_only
language
gender
name
version
quality
type
channel_type
app_id
dialog_identifier
experiment_identifier
speech_id
session_id
text
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
value
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
error_code
error_str
audio
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
content_type
com.apple.voiceservices.notification.voice-purge
com.apple.voiced.prewarmQueue
Prewarm textify emoji
gryphon_frontend
VoiceServices/config
-[VSServerTTSClient ospreyStartSynthesisRequest:responseHandler:completion:]_block_invoke
Unable to process audio data.
v24@?0@"OPTTSTextToSpeechResponse"8@"NSError"16
v16@?0@"OPTTSBeginTextToSpeechStreamingResponse"8
v16@?0@"OPTTSPartialTextToSpeechStreamingResponse"8
v16@?0@"OPTTSFinalTextToSpeechStreamingResponse"8
rate
pitch
volume
isEager
neuralIssue
com.apple.voiced.cachingQueue
v32@?0@"NSData"8Q16@"NSData"24
Speaker
CarAudioOutput
com.apple.voiced.pthreadQueue
com.apple.voiced.speakingQueue
audioDataFromFile:error:
AudioFileOpenURL
AudioFileGetProperty kAudioFilePropertyDataFormat
AudioFileGetProperty kAudioFilePropertyAudioDataByteCount
AudioFileGetProperty kAudioFilePropertyAudioDataPacketCount
+[VSAudioData(SAUIAudioData) audioDataWithASBD:rawData:]
male
female
neutral
\vol=%d\%@
\rate=%d\%@
\pitch=%d\%@
SynthesisTask done synthesize %lu characters, audio duration %f, error %@
Task %llu reported word time info
Device SpeakTask %llu: Instrument metric: %@
Task %llu started speaking
Device EagerTask %llu: Instrument metric: %@
Task %llu reported finish, error: %@
Can't retrieve session with ID: %d
#AVSBAR initialized with session ID: %d, reusing previous synchronizer: %{BOOL}d
VSAudioPlaybackService %p init latency: %.3f
mediaserverd reset
#AVSBAR synchronizer.rate will be set to 1 with enqueued audio duration %f sec. Previous rate: %f
#AVSBAR already stopped or paused: will not resume rate
_synchronizer play rate high latency: %.3f sec
#AVSBAR synchronizer.rate was set to 1. Current rate: %f
Invalid sample buffer
Invalid silence buffer
Error in creating block buffer for Sample buffer
Error in CMAudioFormatDescriptionCreate
Error in CMAudioSampleBufferCreateWithPacketDescriptions
#AVSBAR already stopped or waiting for finish: will not enqueue more
#AVSBAR empty audio data: will not enqueue it
Adding to enqueuedMappedAudioInfo: %f sec
Error in creating block buffer for Silence buffer
Error in CMAudioFormatDescriptionCreate from Silence buffer creation
Error in CMAudioSampleBufferCreateWithPacketDescriptions from silence buffer
#AVSBAR EndOfDataAttachment ready for enqueuing
#AVSBAR Call to provide more audio data during state %ld.
#AVSBAR Enqueuing to %@: %f sec
_renderer enqueueSampleBuffer high latency: %.3f sec
#AVSBAR Renderer %@ not anymore ready for more media data. enqueuedMappedAudioInfo count left: %lu
#AVSBAR flushAndStop
#AVSBAR already stopped or waiting for finish
#AVSBAR Synchronizer reached endTime
#AVSBAR Waiting for synchronizer finishing playing between current %f sec and until %f sec
#AVSBAR Synchronizer is stalled with rate %f at time %f.
Stopping synchronizer and renderer
#AVSBAR synchronizer.rate will be set to 0 and time set to 0 (from current time: %f). Then renderer will be flushed.
_synchronizer stop rate high latency: %.3f sec
#AVSBAR synchronizer.rate was set to 0. Current rate: %f
#AVSBAR renderer was flushed
Pausing synchronizer
#AVSBAR synchronizer.rate will be set to 0 (at current time: %f).
_synchronizer pause rate high latency: %.3f sec
#AVSBAR Dropping %lu enqueued data
Error AudioUnitSetProperty _floatConverter %@
Error AudioUnitSetProperty _integerConverter %@
Error AudioComponentInstanceNew _voiceBoostUnit %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_MaximumFramesPerSlice %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input %@
Error AudioUnitSetProperty _voiceBoostUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, %@
Error AudioUnitInitialize _voiceBoostUnit %@
Error AudioUnitSetParameter %@
Error AudioConverterConvertComplexBuffer _floatConverter %@
Error AudioUnitProcess _voiceBoostUnit %@
Error AudioConverterConvertComplexBuffer _integerConverter %@
Using timestamp inside voiced for Estimation task
Created Estimation task %llu
Unable to create engine for request %@
Estimated duration: %.2f, for utterance: %@
Using timestamp inside voiced for task
Created Task %llu (%p)
Starting speech task %llu
Short-term cached synthesis is found for text '%@'
Detected synthesis stall, starting tailspin
Finished tail spin, success:%d, file: %@
Holding audio playback before we get fast synthesis.
SpeakTask done synthesize %lu characters, audio duration %f, error %@
Device task %llu: Instrument metric: %@
Using requestCreatedTimestamp inside voiced for Server task
Created Server task %llu: shouldSpeak %{BOOL}d
Received server TTS response. Use Server TTS.
Received device synthesis previously, ignore server TTS.
Encountered Osprey streaming network stall. Retry with device TTS.
Server network error: %@
Start device synthesis fallback.
Start playing device synthesis instead.
Received server TTS previously, ignore device TTS
Received audio from device synthesis. Use device synthesis immediately.
Received audio from device synthesis, but it's deferred.
Inline server TTS is previously cached.
Eager server TTS is previously cached.
Device TTS is racing with Server TTS
Device TTS wait time for server audio: %.2f
Device TTS will not race
Server task %llu started speaking
Server task %llu: Instrument metric: %@
Error in server task %llu, error: %@
Server task %llu: %@ %@ utterance: '%@', %{public}@
Invalidate VSSpeechXPCHandler, cancelling all related tasks
%{public}@ is not TTS language, fallback to %{public}@
Use SSML input: %@
Utterance to synthesize for request %llu: '%@'
Overwriting volume with internal default: %.3f
Overwriting rate with internal default: %.3f
Overwriting pitch with internal default: %.3f
Process is not entitled for dumping audio. Ignore outputPath
Unexpected client '%{public}@' sets Siri request ID.
Overriding disableDeviceRacing with internal default
Update with connection identifier: %{public}@, keepActive:%{BOOL}d
Keep active session for '%@'
Remove active session for '%@'
Find on-going task: %@, ignoring prewarm request: %@
Server Inline Streaming TTS is disabled in internal settings
Server TTS is disabled in internal settings
Created stream speak task %llu
Created server speak task %llu
Created speak task %llu
Created presynthesized task %llu
Cache #PresynthesizedRequest %llu with text: %@
Cache #PresynthesizedRequest %llu skipped: no audio
Ignore stopPresynthesizedAudioRequest. Cannot find task with associated request %llu.
Created server synthesis task %llu
Created synthesis task %llu
Found matched inline streaming request, cancel synthesis task %llu
Ignore pauseSpeechRequest. Current request is different than requested request.
Ignore continueSpeechRequest. Current request is different than requested request.
Ignore stopSpeechRequest. Cannot find task with associated request %llu.
Created phonemes task %llu
ignored client '%{public}@' setting auto-download for a non-existing accessoryId '%@'
client '%{public}@' and accessory '%@' set auto download voice assets:%{public}@
Preparing cellular download for %@
Start cellular download for %@
Begin getVoiceInfoForLanguageCode: %{public}@, %@, %@
%s override voice info for server TTS platform, %@
End getVoiceInfoForLanguageCode: %@
Ignore stream object with nil stream ID: %@
Enqueue stream object %@, streamId: %@
Received invokeDaemon, I'm listening
Received killDaemon, shutting down
Simulate network stall is on, ignore audio object
Refresh timeout value as %.2f
Simulate network stall is on, ignore completion callback
Network stall in osprey streaming
Timeout in osprey streaming
Osprey core %p is cancelled
Registered xpc activity com.apple.voiced.postInstall
Running activity com.apple.voiced.postInstall
com.apple.voiced.postInstall is requested to be deferred.
Unable to set defer state for com.apple.voiced.postInstall
Assets migration progress: %f
Re-triggering neural compiling afer OS upgrade.
Migration service finished.
xpc activity com.apple.voiced.postInstall, failed to set state to done.
Unexpected xpc activity state %d for 'com.apple.voiced.postInstall'
Defaults disables reset, skip resetting MobileAsset default URL
Resetting MobileAsset default URL
Unable to locate preview sample file at '%@'
StartVoicePreview for languageCode %@ voiceName %@ previewType %ld
Preview ignored for %@
Unable to play preview sample file at '%@'
StopVoicePreview for file '%@'
Reading cache %@ error: %@
Error %s, %@
Cache type name too long %@
{public}%@ is not TTS language, falling back to %{public}@
Error in reading audio data from file: %@ error:%@
Error AudioQueueNewOutputWithAudioSession %@
Unable to set kAudioQueueProperty_ClientUID, errno: %@
Error CMTimebaseCreateWithSourceClock: %@
AudioQueue initialized with session ID: %d
Error AudioQueueDispose %@
Signal AudioQueue running state change
Error AudioQueueStart %@
VSAudioPlaybackService %p success AudioQueueStart
Error AudioQueueAllocateBuffer %@
Audio queue start sample time: %.0f
Detected stalled audio generation, will enqueue %d silence frame to compensate.
Error AudioQueueEnqueueBuffer %@
VSAudioPlaybackService %p enqueued audio buffer at sample time: %.2f, size: %ld, total enqueued samples: %.0f, discontinuity: %{BOOL}d
AudioQueue will flushAndStop
Timeout in AudioQueue dequeue condition.
Error AudioQueueFlush %@
Error AudioQueueStop %@
AudioQueue will stop
Error AudioQueuePause %@
VSAudioPlaybackService %p success AudioQueuePause
Error AudioQueueAddPropertyListener %@
Error AudioQueueRemovePropertyListener %@
Detected stall of audio queue, based on NSDate. Now: %@, supposed end time: %@, Tolerance: %.2f
Error AudioQueueGetProperty isRunning %@
Unable to enable kAudioQueueProperty_EnableLevelMetering, err: %@
Unable to disable kAudioQueueProperty_EnableLevelMetering, err: %@
Error: %s, errno: %@
VSAudioPlaybackService %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %@
Current audio output route: %@
AudioPlayback
Device core %p is cancelled
On-disk cached synthesis %@ is found.
In-memory cached synthesis %@ is found.
Reset MobileAsset query cache and retry selecting voice
No voice available
Compact voice is explicitly disabled.
Voice is deleted at path '%@'
#CacheDelete asset cleaning is disabled in internal setting. Skip purgeable assets for urgency %d
#CacheDelete purgeable active voice asset: %@
#CacheDelete purgeable inactive voice asset: %@
#CacheDelete query purgeable size, urgency: %d / %d, info: %@
#CacheDelete purge, urgency: %d / %d, info: %@
#CacheDelete periodic purge, urgency: %d / %d, info: %@
Asset update is disabled in internal settings.
Start updating voice and voice resources.
%@ %@ has a subscribed voice: %{public}@
Voice download is in progress, skip new download. %@
Updating target voice: %@
Voice update decision: shouldDownload:%d, canUseBattery:%d. Reason: triggerType:%d, compactVoiceSelected:%d, mismatchedVoiceName:%d, activeSiriUser:%d, serverExperimentDelay:%d
Downloaded voice is not ready to use. Start ANE compiling immediately for voice: %@
Voice asset downloading progress: %.2f, remainingTime: %.2f, voice: %@
Start ANE compiling immediately for voice: %@
Updating VoiceResource for '%{public}@'
Triggered 'com.apple.sirittsd.neuralCompiling' with error %d
Triggered 'com.apple.voiced.neural-compiling' with error %d
Sent Osprey grpc request with speech_id '%@', session_id '%@', app_id '%@'
%s, Error: %@
Sent Osprey streaming request with speech_id '%@', session_id '%@', stream_id '%@', app_id '%@'
Corrupted Osprey response, stream ID: %@
Osprey streaming received Begin response with non 200 status: %d
Osprey streaming received Begin response %@
Osprey streaming received Chunk response with non 200 status: %d
Osprey streaming received Chunk response, pkt number: %d
Osprey streaming received End response with non 200 status: %d
Osprey streaming received End response, total pkt: %d
%s, Unknown response from Osprey for streaming TTS
Osprey streaming invokes completion with error %@
Osprey streaming invokes completion callback
Created audio dump directory %@
No compressed audio do dump
Unable to create intermediate audio dump at '%@'
Unable to create audio dump at '%@', error: %@
Audio save as %@
No audio do dump
No json data to dump
Unable to parse json for dictionary '%@', error: %@
Unable to create instrument metrics json dump at '%@'
Instrument metrics json dump saved as %@
Unable to parse json for key '%@', error: %@
JSON for key '%@' is not dictionary
Added short term cache:%@ for key:'%@'
Removed short term cache for key:'%@'
Removed short term cache for all keys
Using timestamp inside voiced for Stream task
Created Stream task %llu: streamID %@
Simulate network stall is on, ignore object %@
Unknown streaming object: %@
Handle stream begin with streamId: %@, text: %@, decoder: %@
Ignoring stream begin: error already occurred: %ld
Handle stream chunk with streamId: %@
Reached buffer threshold. Start playing audio.
Handle stream end with streamId: %@, count: %@
Stream TTS network stall.
Inline streaming TTS timeout.
Streaming error: %@, error_code: %d
Error in stream task %llu, error: %@
Stream task %llu: %@ speaking text: '%@', %{public}@
Stream task %llu: Instrument metric: %@
Initializing fallback playback service
Using timestamp inside voiced for Presynthesized task
Created Presynthesized Task %llu
Speaking pre-synthesized audio: %@
Error in audio task %llu, error: %@
Audio task %llu: %@ speaking utterance '%@', %{public}@
Received inline streaming TTS with id %@, text: %@
Notification for %@ is on-going. Posting object immediately %@
Notification for %@ has not started. Cache object %@
Start notifying for: %@
No cached object found for notification %@.
%d cached objects found for notification: %@
Notify %@ with cached object %@
Remove notification %@
Prewarming: Invoked with request: '%@'
Unable to initialize Device Authentication session: %@
Device Authentication session is initialized
Unable to prewarm, error: %@
Can't prewarm engine with path '%@'
Prewarm finished. Latency: %.3f
Prewarming: Completed with request: '%@'
Can't create engine with path '%@'
Voice specific resources found.
Specified resource file '%@' does not exist at: '%@'
disableServerTTS is enabled by user default, disable server TTS
forceServerTTS is enabled by user default, force server TTS
forceServerTTS is enabled by speech request, force server TTS
Preinstalled cache is found, disable server TTS
Neural voice is found on device without fallback condition, disable server TTS
Short term cache is found for the text, use server TTS
Server TTS is disabled since '%{public}@' is not in the list of allowed apps
%s, %@
Unable to get power policy from Siri, error: %@
playbackService is initialized already.
Can't create VSAudioPlaybackService
Starting AudioQueue
Task %llu fetched voice %@
Error in device task %llu, error: %@
Device task %llu: %@ %@ utterance: '%@', %{public}@
Cached streamAudio in task %llu with hash %@ in memory
Cached audio in task %llu with hash %@ in memory
Error converting audio during caching. %@
Error converting stream audio during caching. %@
Caching is disabled. Skipping caching.
Unrecognized audio object, skip caching
Audio duration is too short: %.2f second, skip caching
Audio duration is too long: %.2f second, skip caching
Compressing audio for caching.
Audio compressed for caching.
Can't add audio cache, error: %@
Preinstalled cached synthesis %@ is found.
AssistantSiriAnalytics should always derive an identifier for SISchemaComponentName_COMPONENTNAME_TTS
Error AudioFileCreateWithURL: '%@', code: %@
Unable to begin OPUS decoder, %@
Error during decoding, %@
Error AudioFileWriteBytes: '%@', code: %@
Error AudioFileClose: '%@', code: %@
Start spinNextTask
Dispatch speaking task %llu
Starting task %llu
PresynthesisTask %llu requested to wait another speaking task %llu
New speak task %llu interrupts speaking task %llu
New speak task %llu waits for speaking task %llu
%llu interrupt task %llu
Speak task %llu is attached to eager task %llu
Dispatch synthesis task %llu
Finish spinNextTask
Starting text to phonemes task %llu
Finished text to phonemes task %llu
decoderStreamDescription formatID: %@, sample rate: %@
Unknown server audio format ID: %d
%s, invalid opus data
%s, Unknown format: %d
Invalid chunk size: %d at offset %d, bytes count = %d
Unable to convert OPUS to PCM. %@
Decoding opus for dumping.
Opus decoded for dumping.
OPTTSTextToSpeechResponse word timing info, offset: %ld, length: %ld, word: %@, sampleIndex: %d, timestamp: %.2f
Unable to madvise file '%@' MADV_DONTNEED, error: %s
Unable to munmap file '%@', error: %s
Unable to open file '%s', error: %s
Unable to get size of file '%s', error: %s
Unable to mmap '%s', error: %s
fcntl called on file '%@', size: %lu
VSSpeechSynthesisTask
VSSpeechEagerProtocol
VSSpeechSpeakableProtocol
VSSpeechTaskProtocol
NSObject
VSAudioMappedInfoAVSBAR
VSAudioMappedInfo
VSAudioPlaybackServiceAVSBAR
VSAudioPlaybackServiceProtocol
AFAudioPowerProviding
VSVoiceBooster
VSDurationEstimationTask
VSHMHomeManager
VSSpeechSpeakTask
VSSpeechServerTask
VSDeviceTTSCoreDelegate
VSOspreyTTSCoreDelegate
VSSpeechXPCHandler
VSSpeechXPCServiceProtocol
VSSpeechServiceDelegate
VSOspreyTTSCore
VSPostInstallService
VSVoicePreviewTask
AVAudioPlayerDelegate
VSSpeechCacheAudio
VSSpeechCacheItem
VSSpeechCache
OPTTSTTSRequestFeatureFlags
FLTBFBufferAccessor
NSCopying
OPTTSTextToSpeechVoice
OPTTSTextToSpeechResource
OPTTSTextToSpeechMeta
OPTTSTextToSpeechRequestMeta
OPTTSTextToSpeechRequestContext
OPTTSTextToSpeechRequestExperiment
OPTTSTextToSpeechRequest
OPTTSTextToSpeechRequest_ContextInfoEntry
OPTTSAudioDescription
OPTTSWordTimingInfo
OPTTSTextToSpeechResponse
OPTTSStartTextToSpeechStreamingRequest
OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSBeginTextToSpeechStreamingResponse
OPTTSPartialTextToSpeechStreamingResponse
OPTTSFinalTextToSpeechStreamingResponse
OPTTSTextToSpeechRouterStreamingStreamingRequest
OPTTSTextToSpeechRouterStreamingStreamingResponse
VSAceObjectUtility
VSHHManagementClient
VSAudioMappedInfoAT
VSOccasionalTimesObserver
VSAudioPlaybackServiceAT
VSAudioRouteInfo
VSAudioPlaybackService
VSDeviceTTSCore
VSCacheDeleteService
VSTimeoutCondition
VSDownloadService
OspreyTTSService
SpeechService
VSDiagnosticService
VSSiriServerConfiguration
VSShortTermCache
VSSiriInlineTTSStreamTask
VSSpeechPresynthesizedTask
VSSpeechAudioPowerService
VSInlineStreamService
OPTTSMutableTTSRequestFeatureFlags
OPTTSMutableTextToSpeechVoice
OPTTSMutableTextToSpeechResource
OPTTSMutableTextToSpeechMeta
OPTTSMutableTextToSpeechRequestMeta
OPTTSMutableTextToSpeechRequestContext
OPTTSMutableTextToSpeechRequestExperiment
OPTTSMutableTextToSpeechRequest
OPTTSMutableTextToSpeechRequest_ContextInfoEntry
OPTTSMutableAudioDescription
OPTTSMutableWordTimingInfo
OPTTSMutableTextToSpeechResponse
OPTTSMutableStartTextToSpeechStreamingRequest
OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
OPTTSMutableBeginTextToSpeechStreamingResponse
OPTTSMutablePartialTextToSpeechStreamingResponse
OPTTSMutableFinalTextToSpeechStreamingResponse
OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
VSPrewarmService
VSServerTTSClient
Utilities
VSCachingService
VSSiriInstrumentation
VSStreamAudioMappedInfo
VSStreamAudioData
VSSpeechTaskQueue
VSTextToPhonemesTask
SAUIAudioData
VSHelpers
VSMemoryMap
T@"NSArray",C,N
CMTimeValue
T@"NSError",&,N
T#,R
T@"VSSpeechEngine",&,N,V_engine
T@"<VSAudioPlaybackServiceProtocol><AFAudioPowerProviding>",&,N,V_implementation
_audioTimeStamp
T@"<VSOspreyTTSCoreDelegate>",W,N,V_delegate
_engine
T@"<VSSpeechServiceDelegate>",W,N,V_delegate
_floatConverter
T@"AVAudioPlayer",&,N,V_previewPlayer
_inMemoryCaches
T@"AVSampleBufferRenderSynchronizer",&,N,V_synchronizer
_prewarmService
T@"NSArray",&,N,V_deferredTTSTimingInfo
_streamingVoice
T@"NSArray",&,N,V_timingInfos
_voiceBoostUnit
T@"NSArray",R,N,V_timingInfos
_wordTimingInfo
T@"NSCondition",&,N,V_dequeueCondition
beginAudioPowerUpdateWithReply:
T@"NSCondition",&,N,V_refreshTimeoutCondition
cachedEngineForVoice:resources:
T@"NSData",&,N,V_packetDescriptions
captureSnapshot
T@"NSData",R,N
containsObject:
T@"NSDate",&,N,V_audioQueueStartDate
dataWithLength:
T@"NSDictionary",&,N,V_audioDumpFileAttributes
defaultInstance
T@"NSError",&,N,V_error
dirPath
T@"NSLock",&,N,V_updateLock
enableAudioDump
T@"NSMutableArray",&,N,V_enqueuedMappedAudioInfo
fe_feature_only
T@"NSMutableArray",&,N,V_inMemoryCaches
finalTimingInfo
T@"NSMutableArray",&,N,V_speakTasks
getBytes:range:
T@"NSMutableData",&,N,V_audioData
initWithClient:accessory:voice:
T@"NSMutableDictionary",&,N,V_queuedNotification
initWithNSUUID:
T@"NSObject<OS_dispatch_queue>",&,N,V_audioPowerUpdateQueue
isInternalBuild
T@"NSObject<OS_dispatch_queue>",&,N,V_dataQueue
isServerTimeout
T@"NSObject<OS_dispatch_queue>",&,N,V_notifyQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_speakingQueue
logText
T@"NSObject<OS_dispatch_semaphore>",&,N,V_neuralPlaybackSemaphore
madvise
T@"NSObject<OS_os_transaction>",&,N,V_synthesizerTransaction
mappedAudioInfo
T@"NSString",&,N,V_audioDumpPath
numberWithLong:
T@"NSString",&,N,V_deviceID
outputRouteInfo
T@"NSString",&,N,V_key
playbackService
T@"NSString",&,N,V_preinstalledCacheDir
provideMoreData
T@"NSString",C,N
refresh
T@"NSString",R,N
removeDirectory
T@"NSString",R,N,V_voiceKey
removeStreamId:
T@"NSURL",C,N,V_currentPreviewURL
reportProcessingWordTimingInfo:
T@"NSUUID",&,N,V_siriRequestId
resourceVersion
T@"OPTTSAudioDescription",C,N
serverTTSConfig
T@"OPTTSBeginTextToSpeechStreamingResponse",C,N
setCurrentTask:
T@"OPTTSFinalTextToSpeechStreamingResponse",C,N
setIsServerTTS:
T@"OPTTSPartialTextToSpeechStreamingResponse",C,N
setKey:
T@"OPTTSStartTextToSpeechStreamingRequest",C,N
setOutputRoute:
T@"OPTTSTTSRequestFeatureFlags",C,N
setPromptCount:
T@"OPTTSTextToSpeechMeta",C,N
setSample_rate:
T@"OPTTSTextToSpeechRequestContext",C,N
setServerStreamedAudioDuration:
T@"OPTTSTextToSpeechRequestExperiment",C,N
setSourceOfTTS:
T@"OPTTSTextToSpeechRequestMeta",C,N
setStreamAudio:
T@"OPTTSTextToSpeechResource",C,N
setTimingInfos:
T@"OPTTSTextToSpeechVoice",C,N
setVoiceGender:
T@"SATTSSpeechSynthesisResource",&,N,V_streamingResource
standardService
T@"VSAudioData",&,N,V_compressedAudio
stopPresynthesizedAudioRequest:
T@"VSAudioData",R,N,V_audio
stringByAppendingPathExtension:
T@"VSAudioPlaybackService",&,N,V_playbackService
suspend
T@"VSAudioRouteInfo",R,N,V_outputRouteInfo
timeout
T@"VSDeviceTTSCore",&,N,V_deviceCore
unloadResource:
T@"VSDeviceTTSCore",&,N,V_synthesisCore
vs_substituteAudioWithLocalPath
T@"VSHMHomeManager",&,N,V_homeManager
whisper
T@"VSInstrumentMetrics",W,N,V_instrumentMetrics
.cxx_destruct
T@"NSArray",R,N
JSONObjectWithData:options:error:
T@"NSError",R,N
T@"<AFAudioPowerProviding>",W,N,V_previousProvider
T@?,C,N,V_reply
T@"<VSDeviceTTSCoreDelegate>",W,N,V_delegate
_cachingService
T@"<VSSpeechCacheItem>",&,N,V_speechCache
T@"AFAudioPowerUpdater",&,N,V_audioPowerUpdater
_implementation
T@"AVSampleBufferAudioRenderer",&,N,V_renderer
_knowledgeStore
T@"CKKnowledgeStore",&,N,V_knowledgeStore
_shortTermCache
T@"NSArray",&,N,V_phonemes
_timingObserver
T@"NSArray",&,N,V_wordTimingInfo
_voiceSelection
T@"NSCache",&,N,V_cache
audioBytesRange
T@"NSCondition",&,N,V_didReceiveAudioCondition
bytes_per_frame
T@"NSData",&,N,V_audioData
canUseServerTTS
T@"NSData",C,N
compressedAudio
T@"NSDate",&,N,V_audioQueueFutureEndDate
context
T@"NSDate",&,N,V_playbackBeginDate
dealloc
T@"NSDictionary",R,N,V_routeInfo
didReceiveAudio
T@"NSLock",&,N,V_threadLock
dumpCompressedAudio:forRequest:
T@"NSMutableArray",&,N,V_eagerTasks
enqueue
T@"NSMutableArray",&,N,V_finalTimingInfo
fetchVoiceAsset
T@"NSMutableArray",&,N,V_mappedAudioInfo
framesPerPacket
T@"NSMutableArray",&,N,V_streamRequestQueue
getVoiceNamesForLanguage:reply:
T@"NSMutableDictionary",&,N,V_cacheTimer
initWithDouble:
T@"NSMutableSet",&,N,V_ongoingNotifications
initWithVoicePath:resourcePath:
T@"NSObject<OS_dispatch_queue>",&,N,V_cachingQueue
isProxy
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateCallbackQueue
isWatch
T@"NSObject<OS_dispatch_queue>",&,N,V_prewarmQueue
loadedResources
T@"NSObject<OS_dispatch_queue>",&,N,V_taskAuxiliaryQueue
lowercaseString
T@"NSObject<OS_dispatch_semaphore>",&,N,V_noRemainTasks
mainDeviceQueue
T@"NSOperation<VSSpeechTaskProtocol>",&,N,V_currentTask
numberWithBool:
T@"NSString",&,N,V_connectionIdentifier
opaqueSessionID
T@"NSString",&,N,V_dirPath
outputs
T@"NSString",&,N,V_outputRoute
preheat
T@"NSString",&,N,V_streamID
quality
T@"NSString",R,C
release
T@"NSString",R,N,V_filePath
removeObserver:
T@"NSString",R,N,V_voiceResourceKey
removeVoiceResource:completion:
T@"NSUUID",&,N,V_contextId
request
T@"NSUUID",&,N,V_ttsId
serverTTSClient
T@"OPTTSAudioDescription",R,N
T@"OPTTSBeginTextToSpeechStreamingResponse",R,N
setHomeManager:
T@"OPTTSFinalTextToSpeechStreamingResponse",R,N
setIsWarmStart:
T@"OPTTSPartialTextToSpeechStreamingResponse",R,N
setNotifyQueue:
T@"OPTTSStartTextToSpeechStreamingRequest",R,N
setPacketCount:
T@"OPTTSTTSRequestFeatureFlags",R,N
setRacingMutex:
T@"OPTTSTextToSpeechMeta",R,N
setServerAudio:
T@"OPTTSTextToSpeechRequestContext",R,N
setShouldSpeak:
T@"OPTTSTextToSpeechRequestExperiment",R,N
setSpeechCache:
T@"OPTTSTextToSpeechRequestMeta",R,N
setThreadMutex:
T@"OPTTSTextToSpeechResource",R,N
setVoiceAccent:
T@"OPTTSTextToSpeechVoice",R,N
setWithObjects:
T@"SATTSSpeechSynthesisVoice",&,N,V_streamingVoice
startVoicePreviewRequest:reply:
T@"VSAudioData",&,N,V_serverAudio
stringByAppendingPathComponent:
T@"VSAudioData",R,N,V_compressedAudio
stringFromDate:
T@"VSAudioPlaybackService",&,N,V_playbackServices
threadMutexAttr
T@"VSCachingService",&,N,V_cachingService
typeFromString:
T@"VSDeviceTTSCore",&,N,V_deviceTTSCore
version
T@"VSHHManagementClient",&,N,V_hubManagementClient
waitForNewData:
T@"VSInstrumentMetrics",&,N,V_instrumentMetrics
wordTimingInfos
T@"VSMappedData",&,N,V_mappedData
T@"VSMobileAssetsManager",&,N,V_assetsManager
T@"VSOspreyTTSCore",&,N,V_ospreyCore
T@"VSPreferencesInterface",&,N,V_preferenceInterface
T@"VSPresynthesizedAudioRequest",R,N,V_request
T@"VSPrewarmService",&,N,V_prewarmService
T@"VSServerTTSClient",&,N,V_serverTTSClient
T@"VSShortTermCache",&,N,V_shortTermCache
T@"VSSiriInstrumentation",&,N,V_siriInstrumentation
T@"VSSiriServerConfiguration",&,N,V_serverConfig
T@"VSSiriServerConfiguration",&,N,V_serverTTSConfig
T@"VSSpeechCache",&,N,V_cacheStore
T@"VSSpeechCache",R
T@"VSSpeechEngine",&,N,V_cachedEngine
T@"VSSpeechInternalSettings",&,N,V_internalSettings
T@"VSSpeechRequest",&,N,V_lastSynthesisRequest
T@"VSSpeechRequest",&,N,V_request
T@"VSSpeechRequest",R,N,V_request
T@"VSSpeechServerTask",&,N,V_speakTask
T@"VSSpeechSpeakTask",&,N,V_speakTask
T@"VSStreamAudioData",&,N,V_streamAudio
T@"VSStreamAudioData",R,N,V_streamAudio
T@"VSTimeoutCondition",&,N,V_timeoutCondition
T@"VSVoiceAsset",&,N,V_voice
T@"VSVoiceAssetSelection",&,N,V_selectedVoice
T@"VSVoiceAssetSelection",&,N,V_voiceSelection
T@"VSVoiceBooster",&,N,V_voiceBooster
T@"VSVoiceResourceAsset",&,N,V_loadedResources
T@"VSVoiceResourceAsset",&,N,V_selectedVoiceResource
T@"VSVoiceResourceAsset",&,N,V_voiceResource
T@,&,N,V_timingObserver
T@?,C,N,V_completion
TB,N
TB,N,V_didReceiveAudio
TB,N,V_endOfSiriTTSUtterance
TB,N,V_isEagerCache
TB,N,V_isNeuralFallbackCondition
TB,N,V_readyForEagerTask
TB,N,V_shouldSpeak
TB,N,V_shouldStop
TB,N,V_speechStartReported
TB,N,V_startedProvidingData
TB,N,V_synthesisHasIssue
TB,N,V_useDeviceSynthesis
TB,N,V_useServerResponse
TB,R,N
TB,R,N,V_discontinuedDuringPlayback
TI,N
TI,N,V_sessionID
TI,R,N
TQ,N
TQ,N,V_lastSynthesisRequestCreatedTimeStamp
TQ,N,V_packetCount
TQ,N,V_pcmBufferSize
TQ,N,V_playbackIntervalId
TQ,N,V_playingBufferCount
TQ,R
TQ,R,N,V_fileSize
TQ,R,N,V_type
T^v,R,N,V_mappedData
T^{OpaqueAudioComponentInstance=},N,V_voiceBoostUnit
T^{OpaqueAudioConverter=},N,V_floatConverter
T^{OpaqueAudioConverter=},N,V_integerConverter
T^{OpaqueAudioQueue=},N,V_audioQueue
T^{OpaqueCMTimebase=},N,V_timebase
T^{OpaqueCMTimebase=},R,V_timebase
Td,N
Td,N,V_bufferDurationLimit
Td,N,V_deviceTTSWaitTime
Td,N,V_enqueuedSampleCount
Td,N,V_rendererEnqueuedAudioDuration
Td,N,V_timeoutValue
Td,R,N
Td,R,N,V_estimatedDuration
Tf,N
Tf,N,V_voiceBoostGainDecibels
Tf,R,N
Ti,N
Ti,R,N
Ti,R,N,V_fd
Tq,N
Tq,N,V_activeSessionCount
Tq,N,V_packetCount
Tq,N,V_phonemeSystem
Tq,N,V_state
Tq,R,N
Tq,R,N,V_magicVersion
T{?=qiIq},N,V_mappedAudioQueuedTimeStamp
T{AudioStreamBasicDescription=dIIIIIIII},N,V_asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
T{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II},N,V_audioStartTimeStamp
T{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II},N,V_audioTimeStamp
T{_NSRange=QQ},N
T{_NSRange=QQ},N,V_audioBytesRange
T{_NSRange=QQ},N,V_packetDescriptionsRange
T{_opaque_pthread_cond_t=q[40c]},N,V_stateChangeCondition
T{_opaque_pthread_cond_t=q[40c]},N,V_timeoutCondition
T{_opaque_pthread_mutex_t=q[56c]},N,V_audioQueueBufferLock
T{_opaque_pthread_mutex_t=q[56c]},N,V_lock
T{_opaque_pthread_mutex_t=q[56c]},N,V_racingMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_stateLock
T{_opaque_pthread_mutex_t=q[56c]},N,V_threadMutex
T{_opaque_pthread_mutex_t=q[56c]},N,V_waitForStateChangeMutex
T{_opaque_pthread_mutexattr_t=q[8c]},N,V_recursiveLockAttr
T{_opaque_pthread_mutexattr_t=q[8c]},N,V_threadMutexAttr
URLWithString:
UTF8String
UUID
UUIDString
_activeSessionCount
_asbd
_assetsManager
_audio
_audioBytesRange
_audioData
_audioDumpFileAttributes
_audioDumpPath
_audioPowerUpdateQueue
_audioPowerUpdater
_audioQueue
_audioQueueBufferLock
_audioQueueFutureEndDate
_audioQueueStartDate
_audioStartTimeStamp
_block
_bufferDurationLimit
_cache
_cacheStore
_cacheTimer
_cachedEngine
_cachedEngineForVoice:resources:
_cachingQueue
_completion
_compressedAudio
_connection
_connectionIdentifier
_contextId
_currentPreviewURL
_currentTask
_data
_dataQueue
_deferredTTSTimingInfo
_delegate
_delegateCallbackQueue
_dequeueCondition
_deviceCore
_deviceID
_deviceTTSCore
_deviceTTSWaitTime
_didReceiveAudio
_didReceiveAudioCondition
_dirPath
_discontinuedDuringPlayback
_eagerTasks
_endOfSiriTTSUtterance
_engineForVoice:resources:
_enqueueAudioBytesLength:audioBytes:packetCount:packetDescriptions:
_enqueueCacheWithHash:audioObject:timingInfo:voiceKey:voiceResourceKey:completion:
_enqueuedMappedAudioInfo
_enqueuedSampleCount
_error
_estimatedDuration
_fetchVoiceAsset_NoRetry
_filePath
_fileSize
_finalTimingInfo
_homeManager
_hubManagementClient
_inMemoryCacheForHash:
_instrumentMetrics
_integerConverter
_internalSettings
_invalid
_isEagerCache
_isNeuralFallbackCondition
_key
_lastSynthesisRequest
_lastSynthesisRequestCreatedTimeStamp
_loadVoiceResources:forEngine:
_loadedResources
_lock
_magicVersion
_mappedAudioInfo
_mappedAudioQueuedTimeStamp
_mappedData
_neuralPlaybackSemaphore
_nextFireTime
_noRemainTasks
_notifyQueue
_onDiskCacheForHash:
_ongoingNotifications
_ospreyCore
_outputRoute
_outputRouteInfo
_packetCount
_packetDescriptions
_packetDescriptionsRange
_pcmBufferSize
_phonemeSystem
_phonemes
_play
_playbackBeginDate
_playbackIntervalId
_playbackService
_playbackServices
_playingBufferCount
_preferenceInterface
_preinstalledCacheDir
_previewPlayer
_previousProvider
_prewarmQueue
_queuedNotification
_racingMutex
_readyForEagerTask
_reallyInvalidate
_recursiveLockAttr
_refreshTimeoutCondition
_renderer
_rendererEnqueuedAudioDuration
_reply
_request
_resetNextFireTime
_root
_routeInfo
_selectedVoice
_selectedVoiceResource
_serverAudio
_serverConfig
_serverTTSClient
_serverTTSConfig
_sessionID
_shouldSpeak
_shouldStop
_siriInstrumentation
_siriRequestId
_speakTask
_speakTasks
_speakingQueue
_speechCache
_speechStartReported
_startProvidingData
_startedProvidingData
_state
_stateChangeCondition
_stateLock
_storage
_streamAudio
_streamID
_streamRequestQueue
_streamingResource
_synchronizer
_synthesisCore
_synthesisHasIssue
_synthesizerTransaction
_taskAuxiliaryQueue
_threadLock
_threadMutex
_threadMutexAttr
_timebase
_timeoutCondition
_timeoutValue
_timerQueue
_timerSource
_times
_timingInfos
_ttsId
_type
_updateLock
_useDeviceSynthesis
_useServerResponse
_voice
_voiceBoostGainDecibels
_voiceBooster
_voiceKey
_voiceResource
_voiceResourceKey
_waitForStateChangeMutex
_waitForTimeInterval:
accessoryID
activeSessionCount
activeVoiceAssets
addBoundaryTimeObserverForTimes:queue:usingBlock:
addBoundaryTimeObserverForTimes:usingBlock:
addCache:
addEndOfDataAttachment
addInProgressDownloadVoiceKey:
addInlineStreamRequest:
addObject:
addObjectToBuffer:
addObjectsFromArray:
addObserver:selector:name:object:
addRenderer:
addTask:
addTimer:forMode:
adjustWordTimingInfo:forContext:
allValues
allocWithZone:
allowedAppID
app_id
appendAudioData:packetCount:packetDescriptions:
appendBytes:length:
appendData:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayWithCapacity:
arrayWithObjects:count:
asbd
asbdFromDescription:
assetsManager
attributeForKey:
audio
audio:
audioBuffer
audioData
audioDataFromFile:error:
audioDataFromPresynthesisRequest:
audioDataFromSAUIAudioData:
audioDataWithASBD:rawData:
audioDumpFileAttributes
audioDumpPath
audioDuration
audioPlayerBeginInterruption:
audioPlayerDecodeErrorDidOccur:error:
audioPlayerDidFinishPlaying:successfully:
audioPlayerEndInterruption:
audioPlayerEndInterruption:withFlags:
audioPlayerEndInterruption:withOptions:
audioPowerProvider
audioPowerUpdateQueue
audioPowerUpdater
audioQueue
audioQueueBufferLock
audioQueueFutureEndDate
audioQueueStartDate
audioRequest:didReportInstrumentMetrics:error:
audioRequest:didStopAtEnd:error:
audioRequestDidStart:
audioRouteName
audioSession
audioSessionID
audioStartTimeStamp
audioStartTimestampDiffs
audioStreamBasicDescription
audioTimeStamp
audio_type
autorelease
availableLanguages
averagePowerForChannel:
beginChunkDecoderForStreamDescription:
beginEncoding
beginUpdate
bitsPerChannel
bits_per_channel
boolValue
broadcast
broadcastTimeoutCondition
bufferDurationLimit
bundlePath
bundleWithIdentifier:
bytes
bytesAtOffset:
bytesOfDuration:withAudioDescription:
bytesPerFrame
bytesPerPacket
bytes_per_packet
cache
cacheDataForKey:
cachePresynthesizedAudioRequest:
cacheStore
cacheTimer
cachedEngine
cachingQueue
cachingService
canLogRequestText
cancel
cancelDownloadForAssets:
cancelDownloads:completion:
cancelTask:
cancelTasksWithDelegate:
cappedRealTimeFactor
channel_type
channelsPerFrame
channels_per_frame
class
cleanCache
cleanDirectory:withDateOlderThan:
cleanDirectory:withLRULimit:
cleanUnknownAccessoriesPreferences
cleanUnusedAssets
cleanUnusedAssets:
clearSynthesisCache
clientBundleIdentifier
clientID
code
collectTailspin:
completion
componentsJoinedByString:
componentsSeparatedByString:
compressAudio:
compressStreamAudio:
concatenateWithAudio:
configForAppId:key:
conformsToProtocol:
connectionIdentifier
contentAsOPTTSBeginTextToSpeechStreamingResponse
contentAsOPTTSFinalTextToSpeechStreamingResponse
contentAsOPTTSPartialTextToSpeechStreamingResponse
contentAsOPTTSStartTextToSpeechStreamingRequest
contentVersion
content_type
contextId
contextInfo
context_info
continueSpeechRequest:
convertLanguageCodeToSchemaLocale:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryIfNeeded
createFileAtPath:contents:attributes:
createNewXPCWrapperWithCompletion:
createSampleBuffer:
createSampleBufferIdNeeded:
createSilenceEndBuffer
createdTimestampWithTask:
currentPowerPolicyWithError:
currentPreviewURL
currentRoute
currentTask
currentTime
current_pkt_number
customResourceURLs
data
dataQueue
dataUsingEncoding:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithCapacity:
dataWithContentsOfFile:
dataWithJSONObject:options:error:
date
dateByAddingTimeInterval:
dateWithTimeIntervalSinceNow:
debugDescription
decodeChunk:outError:
decodeChunks:streamDescription:outError:
decoderStreamDescription
decoder_description
defaultCacheStore
defaultCenter
defaultConfig
defaultManager
defaultPitch
defaultRate
defaultService
defaultSessionConfiguration
defaultVoiceGender
defaultVoiceNameForGender:
defaultVolume
deferredTTSTimingInfo
delegate
delegateCallbackQueue
deleteCache
dequeueAvailableMappedAudio
dequeueCondition
derivedIdentifierForComponentName:fromSourceIdentifier:
description
descriptiveKey
deviceCore
deviceID
deviceTTSCore
deviceTTSWaitTime
deviceUUID
deviceWaitTimeForAppId:
dialog_identifier
dictForKey:
dictionary
dictionaryMetrics
dictionaryRepresentation
dictionaryWithObjects:forKeys:count:
didEndAccessPower
didReceiveAudioCondition
directorySize:
disableAssetCleaning
disableAssetUpdate
disableCache
disableCompactVoiceFallback
disableDeviceRacing
disableInlineStreamTTS
disableMobileAssetURLReset
disableOspreyStreaming
disableServerTTS
discontinuedDuringPlayback
domain
doubleValue
downloadOptionsWithBattery:
downloadQueue
downloadVoiceAsset:options:progressUpdateHandler:
downloadVoiceResource:options:completion:
dumpInstrumentMetrics:withTimestamp:
dumpStreamAudio:forRequest:
duration
duration:
durationOfAudioDataLength:withAudioDescription:
eagerRequestCreatedTimestampDiffs
eagerTaskHashForRequest:
eagerTasks
emitMessage:
enable_word_timing_info
encodeChunk:
endAudioPowerUpdate
endChunkDecoding
endEncoding
endOfSiriTTSUtterance
endUpdate
engine
enqueue:packetCount:packetDescriptions:
enqueueAudioData:
enqueueCache
enqueueCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueCacheWithHash:streamAudio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueSampleBuffer:
enqueueShortTermCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:
enqueueStreamId:withObject:
enqueuedMappedAudioInfo
enqueuedSampleCount
enumerateAudioWithBlock:
enumerateObjectsWithOptions:usingBlock:
error
errorCode
errorMessage
errorWithDomain:code:userInfo:
error_code
error_str
estimateDurationWithRequest:reply:
estimatedDuration
estimatedTTSWordTimingForText:withLanguage:voiceName:
eventMetadata
exceptionWithName:reason:userInfo:
experiment
experimentIdentifier
experiment_identifier
fallbackLanguageForLanguage:
fallbackToDeviceSynthesis
fe_feature
feature_flags
fetchCacheForTask:
fetchVoiceResource
fileExistsAtPath:
fileExistsAtPath:isDirectory:
filePath
fileSize
fileURLWithPath:
fileURLWithPathComponents:
firstObject
flatbuffData
floatConverter
floatValue
flush
flushAndStop
footprint
footprintFromString:
footprintStringFromFootprint:
forceServerTTS
formatFlags
formatID
format_flags
format_id
forwardStreamObject:
frames_per_packet
freeAudioQueue
gainDecibelWithVolume:
gender
genderFromString:
genderStringFromGender:
generateTTSPhonemes:voicePath:phonemeSystem:error:
getAllVoiceSubscriptionsWithReply:
getAveragePower:andPeakPower:
getCacheForHash:
getCurrentAudioPowerProvider
getFootprintsForVoiceName:languageCode:reply:
getLocalVoiceResourcesReply:
getLocalVoicesForLanguage:reply:
getSpeechIsActiveForConnectionReply:
getSpeechIsActiveReply:
getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:
getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:
getVoiceResourceForLanguage:reply:
handleBegin:
handleChunk:
handleDeviceSynthesis:timingInfo:
handleEnd:
handleMediaServerReset
handleServerResponse:timingInfo:
handleStreamNotification:
handleVoiceSelectionPurge:
hasAlignmentStall
hasAudioClick
hasInlineStreamRequestForSpeakRequest:
hasPhaticResponses:
hash
homeManager
hubManagementClient
identifier
implementation
inMemoryCacheForHash:
inMemoryCaches
inProgressDownloadVoiceKeys
inactiveVoiceAssets
init
initAndVerifyWithFlatbuffData:
initWithASBD:
initWithArray:copyItems:
initWithAudioSessionID:asbd:
initWithAudioSessionID:asbd:useAVSBAR:
initWithBool:
initWithBytes:length:encoding:
initWithBytesNoCopy:length:deallocator:
initWithCache:shortTermMemory:
initWithConnection:
initWithContentsOfURL:fileTypeHint:error:
initWithCurrentProcess
initWithData:encoding:
initWithDirectory:
initWithFilePath:
initWithFlatbuffData:
initWithFlatbuffData:root:
initWithFlatbuffData:root:verify:
initWithFloat:
initWithInt:
initWithInteger:
initWithKey:audio:wordTimingInfo:voiceKey:voiceResourceKey:
initWithKey:data:
initWithProvider:queue:frequency:delegate:
initWithRequest:
initWithRequest:shouldSpeak:
initWithRequest:withStreamID:
initWithRouteAttributes:
initWithSiriRequestId:
initWithSourceASBD:
initWithStorePath:
initWithStreamDescription:pcmBufferSize:
initWithTimebase:times:queue:block:
initWithTimeoutValue:
initWithType:
initWithType:assetsManager:
initWithURL:configuration:
initWithUnsignedInteger:
initialize
initializeDeviceAuthenticationSessionWithCompletion:
installedAssetsForType:voicename:language:gender:footprint:
installedVoiceResources
instrumentMetrics
instrumentPowerEvent:ttsId:
instrumentRequestReceivedWithText:requestedVoiceType:requestedVoiceFootprint:isPrivate:
instrumentSpeechCancelled
instrumentSpeechEndedWithAudioDuration:synthesisLatency:realTimeFactor:promptCount:errorCode:
instrumentSpeechFailedWithErrorCodes:
instrumentSpeechStartedWithSource:customerPerceivedLatency:audioOutputRoute:voiceType:voiceFootprint:voiceVersion:resourceVersion:isWhisper:
instrumentVoiceFallbackOccurredWithVoice:resource:
instrumentVoicedProcessStartedPowerEvent
intValue
integerConverter
integerValue
internalSettings
invalidate
invokeDaemon:
isANECompilationPlatform
isAppleProduct
isAudioQueueRunning
isAudioQueueStalled
isBluetoothRoute
isCancelled
isEagerCache
isEqual:
isEqualToDictionary:
isEqualToString:
isExecuting
isExistingAccessoryId:
isFinished
isHomeHub
isHomePod
isKindOfClass:
isMemberOfClass:
isNeuralFallbackCondition
isPreinstalledCacheAvailableForRequest:
isReadableFileAtPath:
isReadyForMoreMediaData
isSeedBuild
isServerTTS
isSimilarTo:
isSiriClientBundleIdentifier:
isSpeaking
isSynthesisCached
isVoiceReadyToUse
isWarmStart
killDaemon
knowledgeStore
language
languageCode
languages
lastObject
lastPathComponent
lastSynthesisRequest
lastSynthesisRequestCreatedTimeStamp
lastTTSRequestDate
length
linkId
loadEngineForVoice:resources:
loadResource:error:
loadResourceAtPath:mimeType:error:
localizedDescription
localizedInterstitialStringForKey:language:
lock
logFinish
logUtterance
logWithEventContext:
logWithEventContext:ttsIdentifier:
longLongValue
lowInactiveMemory
magicVersion
main
mainRunLoop
makeRequestLinkEvent
mappedAudioQueuedTimeStamp
mappedData
meta_info
migrateAssetsWithProgress:
mmap
moveItemAtPath:toPath:error:
mutableBytes
mutablePCMData
name
neuralAlignmentStall
neuralAudioClick
neuralDidFallback
neuralFallback
neuralPlaybackSemaphore
noRemainTasks
notifyQueue
numOfPromptsTriggered
numberWithDouble:
numberWithInt:
numberWithInteger:
numberWithLongLong:
object
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
offset
onDiskCacheForHash:
ongoingNotifications
orderedSet
ospreyCore
ospreyCore:didFinishWithError:
ospreyCore:didReceiveAudio:wordTimingInfo:
ospreyEndpointURL
ospreyServiceEndpointURL
ospreyStartStreamingRequest:dataHandler:metaInfoHandler:completion:
ospreyStartSynthesisRequest:responseHandler:completion:
outputPath
outputRoute
outputRouteFromRouteInfo:
packetCount
packetDescriptions
packetDescriptionsRange
parallelQueueWithIdentifier:
path
pathWithComponents:
pause
pausePlayback
pauseSpeechRequest:atMark:
pcmAudioDataFromOpusAudio:
pcmBufferSize
peakPowerForChannel:
performLanguageFallBackIfNeededWithRequest:
performRoundTripOspreyTTS
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performStreamingOspreyTTS
periodic:urgency:
phonemeSystem
phonemes
pitch
play
playbackBeginDate
playbackIntervalId
playbackServices
playback_description
playerStreamDescription
playingBufferCount
popInlineStreamRequestForSpeakRequest:
popShortTermCacheForHash:
populatePCMDataWithSiriOpusSData:withOpusASBD:
populateWithOpusData:
populateWithPCMData:
portType
postNotificationName:object:
powerProfile
precomposedStringWithCanonicalMapping
preferenceInterface
preferredDownloadForVoice:
preferred_voice_type
preinstalledAudioHashForLanguage:name:
preinstalledCacheDir
preinstalledCacheForText:language:name:
prepareForSynthesis
preprocessRequestBeforeSynthesis:
previewAudioURLForLanguage:voiceName:previewType:
previewPlayer
previewRequestDidStartPlaying:
previewType
previousProvider
prewarmIfNeededWithRequest:reply:
prewarmQueue
prewarmService
prewarmWithRequest:
proceedWithServerTTS
proceedWithSpeechCache:
processData:
promptCount
purge:urgency:
purgeAsset:
purgeImpl:urgency:
purgeable:urgency:
purgeableAssetsWithInfo:urgency:
queryPhaticCapabilityWithRequest:reply:
queuedNotification
racingMutex
rate
readyForEagerTask
recursiveLockAttr
refreshTimeoutCondition
registerCacheDelete
registerPostInstallActivity
remoteObjectProxy
removeAllObjects
removeDirectory:
removeInProgressDownloadVoiceKey:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeOldFiles
removeTimeObserver:
renderer
rendererEnqueuedAudioDuration
renderers
reply
reportAudio:
reportFinish
reportInstrumentMetrics
reportInstrumentMetrics:
reportSpeechStart
reportTimingInfo
reportWordTimingInfo:
requestCreatedTimestamp
requestFromVSRequest:
requestMediaDataWhenReadyOnQueue:usingBlock:
requestedVoiceContext
reserved
resetCache
resetMobileAssetDefaults
resource
resourceList
resourceMimeTypes
resourcePath
respondsToSelector:
resume
resumeCurrentTask
resumePlayback
retain
retainCount
retrieveSessionWithID:
retryDeviceOnNetworkStall
roundTripTTS:responseHandler:
routeInfo
sampleBuffer
sampleRate
sample_idx
sample_rate
schemaFootprintFromFootprint:
schemaVoiceGenderFromGender:
schemaVoiceTypeFromType:
searchPathURL
selectVoiceForLang:name:type:gender:footprint:
selectVoiceResourceAssetForLanguage:
selectedVoice
selectedVoiceResource
self
serializedData
serverAudio
serverConfig
serverFirstPacketTimestamp
serverStreamingRequestWithMethodName:requestData:requestBuilder:streamingResponseHandler:completion:
serverTTSTimeout
sessionID
session_id
setActive:error:
setActive:withOptions:error:
setActiveSessionCount:
setAllowsCellularAccess:
setApp_id:
setAsbd:
setAssetsManager:
setAudio:
setAudioBytesRange:
setAudioData:
setAudioDumpFileAttributes:
setAudioDumpPath:
setAudioDuration:
setAudioOutputRoute:
setAudioPowerUpdateQueue:
setAudioPowerUpdater:
setAudioQueue:
setAudioQueueBufferLock:
setAudioQueueFutureEndDate:
setAudioQueueStartDate:
setAudioSession:
setAudioStartTimeStamp:
setAudioStartTimestampDiffs:
setAudioTimeStamp:
setAudio_type:
setBits_per_channel:
setBoundaryTimeObserverForTimingInfos:usingBlock:
setBufferDurationLimit:
setBytes_per_frame:
setBytes_per_packet:
setCache:
setCacheStore:
setCacheTimer:
setCachedEngine:
setCachingQueue:
setCachingService:
setCanUseServerTTS:
setCancelled:
setCategory:error:
setChannel_type:
setChannels_per_frame:
setClientBundleIdentifier:
setClientTraceIdentifier:
setCompletion:
setCompletionBlock:
setComponent:
setCompressedAudio:
setConnectionIdentifier:
setContentAsOPTTSBeginTextToSpeechStreamingResponse:
setContentAsOPTTSFinalTextToSpeechStreamingResponse:
setContentAsOPTTSPartialTextToSpeechStreamingResponse:
setContentAsOPTTSStartTextToSpeechStreamingRequest:
setContentVersion:
setContent_type:
setContext:
setContextId:
setContext_info:
setCurrentPreviewURL:
setCurrent_pkt_number:
setCustomerPerceivedLatencyInSecond:
setDataQueue:
setDateFormat:
setDecoder_description:
setDeferredTTSTimingInfo:
setDelaysRateChangeUntilHasSufficientMediaData:
setDelegate:
setDelegateCallbackQueue:
setDequeueCondition:
setDeviceCore:
setDeviceID:
setDeviceTTSCore:
setDeviceTTSWaitTime:
setDialog_identifier:
setDidReceiveAudio:
setDidReceiveAudioCondition:
setDirPath:
setDisableDeviceRacing:
setEagerRequestCreatedTimestampDiffs:
setEagerTasks:
setEnable_word_timing_info:
setEndOfSiriTTSUtterance:
setEnded:
setEngine:
setEnqueuedMappedAudioInfo:
setEnqueuedSampleCount:
setError:
setErrorCode:
setErrorCodes:
setErrorHandler:
setError_code:
setError_str:
setEventMetadata:
setExists:
setExperiment:
setExperimentIdentifier:
setExperiment_identifier:
setFailed:
setFe_feature:
setFe_feature_only:
setFeature_flags:
setFinalTimingInfo:
setFloatConverter:
setFootprint:
setFormat_flags:
setFormat_id:
setFrames_per_packet:
setGender:
setHubManagementClient:
setImplementation:
setInMemoryCaches:
setInputTextLength:
setInstrumentMetrics:
setIntegerConverter:
setInternalSettings:
setIsCacheHitFromDisk:
setIsCacheHitFromMemory:
setIsEagerCache:
setIsNeuralFallbackCondition:
setIsServerStreamTTS:
setIsServerTTSRacing:
setIsServerTimeout:
setIsSpeechRequest:
setKnowledgeStore:
setLanguage:
setLanguageCode:
setLanguages:
setLastSynthesisRequest:
setLastSynthesisRequestCreatedTimeStamp:
setLastTTSRequestDate:
setLength:
setLinkId:
setLoadedResources:
setLock:
setMappedAudioInfo:
setMappedAudioQueuedTimeStamp:
setMappedData:
setMeta_info:
setMeteringEnabled:
setName:
setNeuralAlignmentStall:
setNeuralAudioClick:
setNeuralFallback:
setNeuralPlaybackSemaphore:
setNoRemainTasks:
setObject:forKey:
setObject:forKey:timeToLive:
setObject:forKeyedSubscript:
setObserverForWordTimings:
setOffset:
setOngoingNotifications:
setOpusDataHandler:
setOspreyCore:
setOutputPath:
setPacketDescriptions:
setPacketDescriptionsRange:
setPcmBufferSize:
setPhonemeSystem:
setPhonemes:
setPitch:
setPlaybackBeginDate:
setPlaybackIntervalId:
setPlaybackService:
setPlaybackServices:
setPlayback_description:
setPlayingBufferCount:
setPowerProfile:
setPreferenceInterface:
setPreferred_voice_type:
setPreinstalledCacheDir:
setPreviewPlayer:
setPreviousProvider:
setPrewarmQueue:
setPrewarmService:
setQuality:
setQueuedNotification:
setRate:
setRate:time:
setReadyForEagerTask:
setRecursiveLockAttr:
setRefreshTimeoutCondition:
setRenderer:
setRendererEnqueuedAudioDuration:
setReply:
setRequest:
setRequestCreatedTimestamp:
setRequestReceived:
setRequestReceivedTier1:
setRequestedVoiceContext:
setReserved:
setResource:
setResourceVersion:
setSample_idx:
setSearchPathURL:
setSelectedVoice:
setSelectedVoiceResource:
setServerConfig:
setServerFirstPacketTimestamp:
setServerLastPacketTimestamp:
setServerTTSClient:
setServerTTSConfig:
setSessionID:
setSession_id:
setShortTermCache:
setShouldStop:
setSiriInstrumentation:
setSiriRequestId:
setSource:
setSpeakTask:
setSpeakTasks:
setSpeakingQueue:
setSpeechBeginTimestamp:
setSpeechContext:
setSpeechEndTimestamp:
setSpeechStartReported:
setSpeech_id:
setStartTime:
setStartedOrChanged:
setStartedProvidingData:
setState:
setStateChangeCondition:
setStateLock:
setStreamID:
setStreamRequestQueue:
setStream_id:
setStreamingResource:
setStreamingVoice:
setStreaming_playback_buffer_size_in_seconds:
setSubscribedVoiceAssets:withClientID:forAccessoryID:
setSubscribedVoices:forClientID:accessoryID:
setSynchronizer:
setSynthesisBeginTimestamp:
setSynthesisCore:
setSynthesisEffect:
setSynthesisEndTimestamp:
setSynthesisHasIssue:
setSynthesisLatencyInSecond:
setSynthesisRealTimeFactor:
setSynthesisSource:
setSynthesizedAudioDurationInSecond:
setSynthesizerTransaction:
setTarget:
setTaskAuxiliaryQueue:
setText:
setTextRange:
setTextToSynthesize:
setThreadLock:
setThreadMutexAttr:
setTimebase:
setTimeoutCondition:
setTimeoutIntervalForRequest:
setTimeoutIntervalForResource:
setTimeoutValue:
setTimestamp:
setTimingObserver:
setTotal_pkt_number:
setTtsId:
setType:
setUpdateLock:
setUseCompression:
setUseDeviceSynthesis:
setUseServerResponse:
setUtterance:
setUuid:
setValue:
setVersion:
setVoice:
setVoiceAssetKey:
setVoiceBoostGainDecibels:
setVoiceBoostUnit:
setVoiceBooster:
setVoiceContext:
setVoiceFallbackOccurred:
setVoiceFootprint:
setVoiceName:
setVoiceResource:
setVoiceResourceAssetKey:
setVoiceSelection:
setVoiceSettings:
setVoiceType:
setVoiceVersion:
setVoice_name:
setVolume:
setWaitForStateChangeMutex:
setWithArray:
setWord:
setWordTimingInfo:
setWord_timing_info:
sha256hex
sharedAVSystemController
sharedInstance
sharedManager
sharedPowerLogger
sharedService
sharedServices
sharedStream
shortTermCache
shortTermCacheForHash:
shortTermCachedEngineForVoice:voiceResource:
shortTermCachedEngines
shouldCache
shouldDeferDeviceTTS
shouldDelayVoiceUpdate
shouldRelyOnServerTTS
shouldSpeak
shouldStop
shouldStreamAudioData
shouldUseServerTTSForRequest:
shouldWaitCurrentSpeaking
shouldWhisper
signal
signalNewDataWithError:
signalQueueRunningStateChange
simulateNetworkStall
siriInstrumentation
siriRequestId
size
sortedArrayUsingComparator:
sourceOfTTS
speakCachedAudio
speakRetryPhrase
speakTask
speakTasks
speakingQueue
speechBeginTimestamp
speechCache
speechEndTimestamp
speechRequest:didReceiveTimingInfo:
speechRequest:didReportInstrumentMetrics:
speechRequest:didStartWithMark:forRange:
speechRequest:didStopWithSuccess:phonemesSpoken:error:
speechRequestDidContinue:
speechRequestDidPause:
speechRequestDidStart:
speechStartReported
speechSynthesisResource
speechSynthesisVoice
speech_id
spinNextTask
standardInstance
start
startPhonemesRequest:phonemeSystem:reply:
startPlayback
startPlaybackServiceWithAudioSessionID:
startPresynthesizedAudioRequest:
startSpeechRequest:reply:
startStreamingWithId:
startSynthesisRequest:
startVoicePreviewForLanguageCode:voiceName:previewType:startedPlaying:completion:
startVoicePreviewWithURL:startedPlaying:completion:
startedProvidingData
state
stateChangeCondition
stateLock
stop
stopAtMarker:
stopRequestingMediaData
stopSpeechRequest:atMark:
stopVoicePreview
stopWaiting
streamAudio
streamBufferDuration
streamID
streamId
streamRequestQueue
streamTTS:beginHandler:chunkHandler:endHandler:completion:
stream_id
streamingPlaybackBufferSize
streamingResource
streamingVoice
streaming_playback_buffer_size_in_seconds
stringByAppendingString:
stringByReplacingOccurrencesOfString:withString:
stringOfSourceOfTTS:
stringWithFormat:
stringWithUTF8String:
subdataWithRange:
subscribedVoicesForClientID:accessoryID:
superclass
suspendCurrentTask
synchronizer
synthesisBeginTimestamp
synthesisCore
synthesisCore:didReceiveAudio:
synthesisCore:didReceiveProcessingWordTimingInfo:
synthesisCore:didReceiveWordTimingInfo:
synthesisEndTimestamp
synthesisHasIssue
synthesisRequest:didFinishWithInstrumentMetrics:error:
synthesisRequest:didGenerateAudioChunk:
synthesisRequest:didReceiveTimingInfo:
synthesisSourceFromSource:
synthesize
synthesizeAndSpeak
synthesizeText:loggable:callback:
synthesizerTransaction
taskAuxiliaryQueue
taskHash
taskWithCreatedTimeStamp:
tasksWithDelegate:
text
textRange
threadLock
threadMutex
timeIntervalSinceDate:
timeIntervalSinceNow
timeToLiveTimerFired:
timeToSpeakLatency
timebase
timeoutCondition
timeoutForAppId:
timeoutValue
timerWithTimeInterval:target:selector:userInfo:repeats:
timestamp
timingInfos
timingObserver
totalCacheSize
totalDiagnosticFileSize
totalSizeOfAssets:
total_pkt_number
transferPreinstallErrorMessagesOfLanguage:voiceName:forAccessoryID:
triggerCellularDownloadedVoiceAssets:withClientID:
triggerNeuralCompiling
ttsId
ttsPolicy
ttsSynthesisLatency
type
typeStringFromType:
unarchivedObjectOfClasses:fromData:error:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
uninitialize
unloadCachedEngineWithVoice:
unloadEngine
unlock
unsignedIntValue
unsignedIntegerValue
updateLock
updateMeters
updateTrialVoiceResourceWithLanguage:
updateVoiceIfNeeded:
updateVoicesAndVoiceResources
updateWithConnectionIdentifier:keepActive:
useDeviceSynthesis
useSSMLInput
useServerResponse
useSiriTTSService
userDefaultsKnowledgeStore
userInfo
utf16TimingInfoWithUTF8Range:withText:
utterance
value
valueForEntitlement:
valueForKey:
valueWithBytes:objCType:
voice
voiceAssetKey
voiceAssetsForSubscription:
voiceBoostGainDecibels
voiceBoostUnit
voiceBooster
voiceContext
voiceData
voiceKey
voiceName
voicePath
voiceResource
voiceResourceAssetKey
voiceResourceKey
voiceSelection
voiceSelectionWithRequest:error:
voiceSelection_noRetry_WithRequest:error:
voiceSettings
voiceType
voice_name
volume
vsDescription
vs_convertToSSML
vs_insertContextInfo:
vs_stringFrom4CC:
vs_textifyEmojiWithLanguage:
vs_voice
vs_voiceResource
vs_wordTimingInfos:withText:
wait
waitForAudioQueueStop
waitForStateChangeMutex
waitUntilAudioFinished
waitUntilDate:
waitUntilFinished
waitUntilFinishedIfAudioReceivedWithin:
waitUntilPrewarmFinish
willBeginAccessPower
word
wordTimingInfo
word_timing_info
writeAudioIfNeeded:
writeToFile:atomically:
writeToFile:options:error:
writeToFilePath:
writeWaveToFilePath:
zone
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v16@0:8
@"VSInstrumentMetrics"16@0:8
v24@0:8@16
v24@0:8@"NSArray"16
@"VSSpeechRequest"16@0:8
v24@0:8@"VSSiriInstrumentation"16
@"<AFAudioPowerProviding>"16@0:8
v24@0:8@"<VSSpeechSpeakableProtocol>"16
@24@0:8@16
v20@0:8B16
@"VSSpeechSpeakTask"
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
v24@0:8Q16
^{opaqueCMSampleBuffer=}
{_NSRange="location"Q"length"Q}
@60@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20
v40@0:8@16q24@32
@32@0:8@16@?24
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
I16@0:8
v20@0:8I16
v40@0:8@"NSData"16q24@"NSData"32
@"NSError"16@0:8
@32@0:8@"NSArray"16@?<v@?{?=qiIq}>24
v24@0:8@"NSError"16
B32@0:8^f16^f24
^{opaqueCMSampleBuffer=}24@0:8@16
d24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
{_opaque_pthread_mutex_t=q[56c]}16@0:8
v80@0:8{_opaque_pthread_mutex_t=q[56c]}16
q16@0:8
v24@0:8q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
d16@0:8
v24@0:8d16
@"NSError"
@"AVSampleBufferAudioRenderer"
@"AVSampleBufferRenderSynchronizer"
@"NSObject<OS_dispatch_queue>"
@"NSString"
@"VSMappedData"
@"NSMutableArray"
@"NSObject<OS_dispatch_semaphore>"
{?="value"q"timescale"i"flags"I"epoch"q}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16Q56
v20@0:8f16
f16@0:8
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{OpaqueAudioComponentInstance=}16@0:8
v24@0:8^{OpaqueAudioComponentInstance=}16
{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16@0:8
v80@0:8{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}16
^{OpaqueAudioConverter=}
^{OpaqueAudioComponentInstance=}
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
@32@0:8@16@24
@"VSSpeechRequest"
@"VSInstrumentMetrics"
@"VSDeviceTTSCore"
v40@0:8@16@24@32
@"NSArray"
@"<VSSpeechServiceDelegate>"
@"VSSpeechEngine"
@"VSVoiceBooster"
@"VSAudioPlaybackService"
@"VSVoiceAssetSelection"
@"VSVoiceResourceAsset"
@"VSCachingService"
@"VSPrewarmService"
@"VSSiriInstrumentation"
@"<VSSpeechCacheItem>"
@"VSAudioData"
@"VSStreamAudioData"
v32@0:8@16@24
v32@0:8@"VSDeviceTTSCore"16@"VSAudioData"24
v32@0:8@"VSDeviceTTSCore"16@"NSArray"24
v40@0:8@"VSOspreyTTSCore"16@"VSAudioData"24@"NSArray"32
v32@0:8@"VSOspreyTTSCore"16@"NSError"24
@28@0:8@16B24
{_opaque_pthread_cond_t=q[40c]}16@0:8
v64@0:8{_opaque_pthread_cond_t=q[40c]}16
@"VSSpeechServerTask"
@"VSSpeechInternalSettings"
@"VSOspreyTTSCore"
@"VSSiriServerConfiguration"
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
Vv28@0:8@16B24
Vv32@0:8@16@?24
Vv24@0:8@16
Vv32@0:8@16q24
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv40@0:8@16q24@?32
Vv40@0:8@16@24@32
Vv32@0:8@16@24
Vv64@0:8@16@24q32q40q48@?56
Vv28@0:8@"NSString"16B24
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv32@0:8@"VSSpeechRequest"16q24
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv32@0:8@"VSPreviewRequest"16@?<v@?dB>24
Vv40@0:8@"VSSpeechRequest"16q24@?<v@?@"NSString"@"NSError">32
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv40@0:8@"NSArray"16@"NSString"24@"NSUUID"32
Vv40@0:8@"NSString"16@"NSUUID"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?@"NSArray">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv64@0:8@"NSString"16@"NSString"24q32q40q48@?<v@?@"VSVoiceAsset"@"NSError">56
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
Vv24@0:8@?<v@?i>16
Vv48@0:8@16q24{_NSRange=QQ}32
Vv44@0:8@16B24@28@36
Vv36@0:8@16B24@28
Vv48@0:8@"VSSpeechRequest"16q24{_NSRange=QQ}32
Vv44@0:8@"VSSpeechRequest"16B24@"NSString"28@"NSError"36
Vv32@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv32@0:8@"VSSpeechRequest"16@"VSAudioData"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv36@0:8@"VSPresynthesizedAudioRequest"16B24@"NSError"28
Vv40@0:8@"VSPresynthesizedAudioRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv24@0:8@"VSPreviewRequest"16
@"NSXPCConnection"
@"VSHHManagementClient"
@"VSHMHomeManager"
@"AFAudioPowerUpdater"
@"NSObject<OS_os_transaction>"
@"<VSOspreyTTSCoreDelegate>"
@"VSVoiceAsset"
@"VSServerTTSClient"
@"VSTimeoutCondition"
@"NSCondition"
@40@0:8@16@24q32
v56@0:8@16@24q32@?40@?48
v28@0:8@16B24
v32@0:8@16Q24
v28@0:8@"AVAudioPlayer"16B24
v32@0:8@"AVAudioPlayer"16@"NSError"24
v24@0:8@"AVAudioPlayer"16
v32@0:8@"AVAudioPlayer"16Q24
v40@0:8@16@?24@?32
@?16@0:8
v24@0:8@?16
@"AVAudioPlayer"
@"NSURL"
@"NSData"16@0:8
@32@0:8@"NSString"16@"NSData"24
@56@0:8@16@24@32@40@48
@"NSData"
@40@0:8@16@24@32
@24@0:8^{_NSZone=}16
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^v16
@"NSMutableDictionary"
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^v16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^v16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^v16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^v16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^v16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^v16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^v16
r^{TextToSpeechRequest=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^v16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^v16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^v16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
i16@0:8
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^v16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^v16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^v16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^v16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^v16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@48@0:8^{OpaqueCMTimebase=}16@24@32@?40
^{OpaqueCMTimebase=}16@0:8
@"NSObject<OS_dispatch_source>"
^{OpaqueCMTimebase=}
@44@0:8I16r^v20q28r^v36
^{OpaqueAudioQueue=}16@0:8
v24@0:8^{OpaqueAudioQueue=}16
v24@0:8^{OpaqueCMTimebase=}16
^{OpaqueAudioQueue=}
@"NSDate"
@"NSDictionary"
d64@0:8Q16{AudioStreamBasicDescription=dIIIIIIII}24
Q64@0:8d16{AudioStreamBasicDescription=dIIIIIIII}24
@64@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20B60
v32@0:8@16@?24
@"VSAudioRouteInfo"
@"<VSAudioPlaybackServiceProtocol><AFAudioPowerProviding>"
@32@0:8@16^@24
@"<VSDeviceTTSCoreDelegate>"
@28@0:8@16i24
q24@0:8@16
@24@0:8d16
B24@0:8d16
@24@0:8Q16
@32@0:8Q16@24
@"VSMobileAssetsManager"
@"VSPreferencesInterface"
@"NSLock"
v56@0:8@16@?24@?32@?40@?48
f24@0:8d16
v32@0:8@16q24
@"CKKnowledgeStore"
v40@0:8@16@24d32
@"NSCache"
@"SATTSSpeechSynthesisResource"
@"SATTSSpeechSynthesisVoice"
@"VSPresynthesizedAudioRequest"
@"NSMutableData"
@"<AFAudioPowerProviding>"
{_opaque_pthread_mutexattr_t=q[8c]}16@0:8
v32@0:8{_opaque_pthread_mutexattr_t=q[8c]}16
@"NSMutableSet"
{_opaque_pthread_mutexattr_t="__sig"q"__opaque"[8c]}
v20@0:8i16
v48@0:8@16@?24@?32@?40
v64@0:8@16@24@32@40@48@?56
@"VSSpeechCache"
@"VSShortTermCache"
i24@0:8q16
i24@0:8@16
v44@0:8@16q24q32B40
v76@0:8q16d24@32q40q48Q56Q64B72
v56@0:8d16d24d32Q40q48
@"NSUUID"
@56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
v40@0:8@16Q24@32
Q24@0:8@16
@"NSOperation<VSSpeechTaskProtocol>"
B64@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
{AudioStreamBasicDescription=dIIIIIIII}24@0:8@16
@24@0:8q16
^v16@0:8
