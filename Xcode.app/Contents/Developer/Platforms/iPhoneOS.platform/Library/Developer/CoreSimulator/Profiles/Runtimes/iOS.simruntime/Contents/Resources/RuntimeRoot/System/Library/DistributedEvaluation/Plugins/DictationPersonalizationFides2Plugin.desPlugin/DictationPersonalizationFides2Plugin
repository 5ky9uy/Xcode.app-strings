init
UUID
UUIDString
setExists:
setStartedOrChanged:
_wrapAndEmitTopLevelEvent:
objectForKeyedSubscript:
countByEnumeratingWithState:objects:count:
initWithUUIDString:
initWithNSUUID:
setAsrId:
removeObjectForKey:
intValue
setErrorCode:
setRecognizedTokens:
setCorrectedTokens:
addObject:
setDatapackVersion:
setConfusionPairs:
setLinkId:
setRedecodingResults:
setEnded:
isEqualToString:
setExperimentStatusCode:
unsignedIntValue
setNumAudioFilesAvailable:
setNumAudioFilesSelected:
_audioFileResultsFromResultDict:privateAudioFileResultsOut:
setAudioFileResults:
_plmMetricsFromPlmDict:
setPersonalizedLanguageModelMetrics:
_decodingResultsWithAudioDict:privateTokensOut:
setDecodingResults:
setTokens:
setRecognitionResult:
allKeys
initWithBase64EncodedString:options:
decompressedDataUsingAlgorithm:error:
JSONObjectWithData:options:error:
setConfigName:
_decodingMetricsFromMetricsDict:
setDecodingMetrics:
_tokensFromTokenDict:privateTokens:
_utteranceInfosFromUtteranceInfoDict:privateTokens:
setUtterances:
floatValue
setWallRealTimeFactor:
setAverageActiveTokensPerFrame:
unsignedLongLongValue
setJitQueryDurationInMs:
setJitLanguageModelEnrollmentDurationInMs:
componentsSeparatedByString:
objectAtIndexedSubscript:
doubleValue
numberWithDouble:
setStartTimeInNs:
setEndTimeInNs:
valueForKey:
setWeights:
setLanguageModelInterpolationWeights:
_resultInfosFromResultInfoDict:privateTokens:
setResults:
setStageName:
setIsAligned:
_choiceInfosFromChoiceInfoDicts:privateTokens:
setChoices:
_tokensFromTokensArray:privateTokens:
setGraphCost:
setAcousticCost:
setSilenceStartTimeInNs:
setToken:
setSilenceAcousticCost:
setNumBackoffs:
setLanguageModelCosts:
setText:
setPhoneSequence:
containsObject:
indexOfObject:
setLinkIndex:
count
boolValue
setAppendSpaceAfter:
setConfidence:
_transcriptMetadataFromPopDict:
setTrain:
setTest:
setDev:
setExternal:
setBestWeight:
setTotalDurationInMs:
_lmMetricsFromEvalDict:perplexityName:timesDict:
setTrains:
setTests:
setDevs:
setExternals:
setNgramOrder:
setResidualAdaptationWeight:
setTrainingDurationInMs:
setConversionDurationInMs:
setOptimizationDurationInMs:
setTranscriptionMetrics:
setEvaluationMetrics:
stringByReplacingOccurrencesOfString:withString:
convertLanguageCodeToSchemaLocale:
setUserLocale:
setModelMetrics:
setNumDocumentsRejected:
setNumSentencesRejected:
setNumDocumentsAccepted:
setNumSentencesAccepted:
setNumTokensAccepted:
setNumTokensOutOfVocabularyAccepted:
setNumDocumentsDictated:
setNumDocumentsTyped:
setNumTokensDictated:
setNumTokensTyped:
setNumSentencesMungeRejected:
setNumSentencesMungeChanged:
setLinearInterpolationWeight:
setNumUtterances:
setNumWords:
setNumOutOfVocabularyWords:
setNumInvalidTokens:
setNumInvalidUtterances:
setPerplexity:
setPerplexityOne:
setHits:
setNgramHits:
setDodMlId:
setExperimentName:
setEventMetadata:
setPersonalizationExperimentContext:
setUserEditExperimentContext:
setUserEditExperimentEndedTier1:
setAudioFileResultTier1:
sharedStream
emitMessage:
initWithExperimentId:
logUserEditExperimentStartedOrChanged
logUserEditExperimentEndedAndTier1WithResultsDict:
logDictationPersonalizationExperimentStartedOrChanged
logDictationPersonalizationExperimentEndedAndTier1WithResultsDict:
datapackVersion
.cxx_destruct
_dodmlId
_experimentId
_datapackVersion
T@"NSString",&,N,V_datapackVersion
initialize
generateTTSAudiosFromTexts:language:downsample:
invalidate
initWithDelegate:instanceUUID:
initWithLanguage:assetType:
modelPropertiesForAssetConfig:error:
modelVersion
recipe
recipeUserInfo
unsignedIntegerValue
matchingRecordSet
nativeRecordInfo
mutableCopy
exchangeObjectAtIndex:withObjectAtIndex:
nativeRecordDataForRecordUUID:error:
setObject:forKeyedSubscript:
length
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
attachments
path
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
code
numberWithInteger:
userInfo
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
integerValue
setWithArray:
sharedAnalytics
logEventWithType:context:
completeWithJSONResult:binaryResult:completionHandler:
_modelVersionForLanguage:
_selectRecordsWithSession:recordInfosOut:recordDatasOut:error:
completeWithError:completionHandler:
recordFromData:
correctedText
samplingRate
activity
_invalidate
generateAudioWithTexts:language:completion:
_invalidated
array
setValue:forKey:
subarrayWithRange:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
sharedPreferences
dictationIsEnabled
performSystematicErrorEvaluation:
dictionary
numberWithUnsignedInteger:
_redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:
removePersonalizedLMForFidesOnly:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
evaluateRecipe:recordInfo:recordData:attachments:error:
telemetryWithRecordSet:
shouldDownloadAttachmentWithURL:recipe:recordInfo:
serverSafeRecordInfoWithRecordInfo:
evaluateRecipe:matchingRecordSet:error:
evaluateRecipe:matchingRecordSet:binaryResult:error:
performEvaluation:
_trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:
_queue
_smtClient
_recognizer
getOfflineDictationStatusWithCompletion:
allObjects
firstObject
languageCode
currentLocale
localeIdentifier
lastPathComponent
caseInsensitiveCompare:
siriDataSharingOptInStatus
%s Fides SELF: Logging object created successfully: dodmlId=%@, experimentId=%@
%s Fides SELF: Utterance Info could not be decompressed - it will not be logged.
%s Fides SELF: Utterance Info could not be deserialized - it will not be logged.
%s Fides SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s Fides SELF: Expected interpolation weight sets separated by delimter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s Fides SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the DODML ASR SELF schema.
%s Fides SELF: Wrapping and logging an event of type %@
SRAudioGenerator: Start generating TTS audio with language: %@
%s PLM: Invalidating
%s language: %@ modelVersion: %@ error: %@
%s Nil record data: %@
%s PLM: Recipe missing language
%s PLM: user language: %@
%s PLM: User language (%@) does not match recipe language (%@)
%s PLM: Recipe attachments missing configuration
%s PLM: Client start training
%s PLM: Client finished training
%s PLM: Client training failed: %@
%s Run evaluation using embeddedspeech recognizer for language %@
%s Evaluation failure
%s Starting systematic error evaluation in DictationPersonalizationFidesPlugin
%s SEE: No model installed
%s SEE: Rejected model
%s record info: %@
%s Nil record data
%s Unable to load localSpeechDESRecord
%s No corrected text in record, skipping TTS ASR pipeline
%s Sampling rate does not match, record sampling rate: %lu, downsampling rate: %lu
%s Retrieved corrected text: %@
%s No corrected text found in sampled dodML records, exiting...
%s SEE: eligibilityHandler deferred
%s Failed to generate TTS audio, error: %@
%s Failed to generate TTS audios
%s TTS failure when performing systematic error evaluation
%s Error running evaluation %@
%s ASR failure when performing systematic error evaluation, continuing
%s Recognized text and TTS ASR output did not match but was required to match, continuing
%s SEE: Deferred
%s Starting Fides evaluation for Dictation Personalization
%s Attachments: %@
%s Fides data size: %ld
%s Fides recipe parameters: %@
%s PLM: Dictation disabled
%s internal %d optIn %d reportWithFides %d
%s Performing systematic error evaluation instead of dictation personalization
%s PLM: No model installed
%s PLM: Rejected model
%s PLM: eligibilityHandler deferred
%s PLM: Deferred
%s PLM: installedLanguages=%@
%s PLM: Found one dictation language %@
%s PLM: Trying Siri language %@ result %@
%s PLM: Trying system language %@ result %@
-[FidesSelfHelper initWithExperimentId:]
confusionPairs
asrSelfComponentIdentifier
errorCode
recognizedPair
correctedPair
languageMetadata
status
Required Personalized LM not found
numAudio
numSelectedAudio
personalizedLM
audioResults
asrSelfComponentId
tokens
metrics
uttInfos
uttInfosCompressed
-[FidesSelfHelper _decodingResultsWithAudioDict:privateTokensOut:]
WallRTF
AverageActiveTokensPerFrame
jitQueryDurationInMs
jitLmeDurationInMs
lm_interp_weights
floatValue
-[FidesSelfHelper _decodingMetricsFromMetricsDict:]
results
startMillis
endMillis
aligned
choices
graphCost
acousticCost
startTime
endTime
removeSpaceAfter
silenceStartTime
confidence
text
phoneSequence
train
data
test
external
eval
model-selection
best-weight
totalTime
train-ppl
times
test-ppl
dev-ppl
external-ppl
model
order
residualAdaptationWeight
training
conversion
optimization
userLanguage
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numSentencesMungeRejected
numSentencesMungeChanged
utterances
words
OOVs
invalidTokens
invalidUtterances
PPL1
ngramHits
-[FidesSelfHelper _wrapAndEmitTopLevelEvent:]
com.apple.speech.speechmodeltraining
SRAudioGenerator
-[DictationPersonalizationFidesPlugin _invalidate]
DictationPersonalizationFidesPlugin.m
_queue
-[DictationPersonalizationFidesPlugin _invalidate]_block_invoke
v8@?0
-[DictationPersonalizationFidesPlugin _invalidated]
-[DictationPersonalizationFidesPlugin _modelVersionForLanguage:]
minAudio
maxAudio
language
-[DictationPersonalizationFidesPlugin _selectRecordsWithSession:recordInfosOut:recordDatasOut:error:]
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]
PLM: Recipe missing language
lm-personalize.json
PLM: Recipe attachments missing configuration
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]_block_invoke_2
v24@?0@"NSDictionary"8@"NSError"16
trainErrorCode
trainErrorDescription
asset
-[DictationPersonalizationFidesPlugin _redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:]
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]
com.apple.siri.speech-recognition-systematic-error
leftContextSize
rightContextSize
recordLimit
keepMTELogging
recognizedTTSASRShouldMatch
caseSensitive
skipLME
wordSenseAccessList
experimentId
modelVersions
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke_2
v16@?0@"NSObject<OS_xpc_object>"8
Deferred
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke
modelVersion
correctedOutput
recognizedOutput
editDistanceRecognizedTTSASR
timestamp
interactionId
-[DictationPersonalizationFidesPlugin performEvaluation:]
PLM: Dictation disabled
reportWithFides
disableMTELogging
User not opted-in
performSystematicErrorEvaluation
com.apple.siri.speech-dictation-personalization
-[DictationPersonalizationFidesPlugin performEvaluation:]_block_invoke
getPersonalizedLMUserLanguage
FidesSelfHelper
SRAudioGenerator
DictationPersonalizationFidesPlugin
DESRecipeEvaluation
NSObject
@24@0:8@16
v16@0:8
v24@0:8@16
@32@0:8@16^@24
@32@0:8@16@24
@40@0:8@16@24@32
@16@0:8
@"NSUUID"
@"NSString"
@36@0:8@16@24B32
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@56@0:8@16@24@32@40^@48
B40@0:8@16@24@32
@40@0:8@16@24^@32
@48@0:8@16@24^@32^@40
@"NSDictionary"56@0:8@"NSDictionary"16@"NSDictionary"24@"NSData"32@"NSArray"40^@48
@"NSDictionary"24@0:8@"DESRecordSet"16
B40@0:8@"NSURL"16@"NSDictionary"24@"NSDictionary"32
@"NSDictionary"24@0:8@"NSDictionary"16
@"NSDictionary"40@0:8@"DESRecipe"16@"DESRecordSet"24^@32
@"NSDictionary"48@0:8@"DESRecipe"16@"DESRecordSet"24^@32^@40
v24@0:8@"DESRecipeEvaluationSession"16
B48@0:8@16^@24^@32^@40
B56@0:8@16@24^@32^@40^@48
B76@0:8@16@24@32@40@48B56@60^@68
@"NSObject<OS_dispatch_queue>"
@"SpeechModelTrainingClient"
@"CoreEmbeddedSpeechRecognizer"
init
UUID
UUIDString
setExists:
setStartedOrChanged:
_wrapAndEmitTopLevelEvent:
objectForKeyedSubscript:
countByEnumeratingWithState:objects:count:
initWithUUIDString:
initWithNSUUID:
setAsrId:
removeObjectForKey:
intValue
setErrorCode:
setRecognizedTokens:
setCorrectedTokens:
addObject:
setDatapackVersion:
setConfusionPairs:
setLinkId:
setRedecodingResults:
setEnded:
isEqualToString:
setExperimentStatusCode:
unsignedIntValue
setNumAudioFilesAvailable:
setNumAudioFilesSelected:
_audioFileResultsFromResultDict:privateAudioFileResultsOut:
setAudioFileResults:
_plmMetricsFromPlmDict:
setPersonalizedLanguageModelMetrics:
_decodingResultsWithAudioDict:privateTokensOut:
setDecodingResults:
setTokens:
setRecognitionResult:
allKeys
initWithBase64EncodedString:options:
decompressedDataUsingAlgorithm:error:
JSONObjectWithData:options:error:
setConfigName:
_decodingMetricsFromMetricsDict:
setDecodingMetrics:
_tokensFromTokenDict:privateTokens:
_utteranceInfosFromUtteranceInfoDict:privateTokens:
setUtterances:
floatValue
setWallRealTimeFactor:
setAverageActiveTokensPerFrame:
unsignedLongLongValue
setJitQueryDurationInMs:
setJitLanguageModelEnrollmentDurationInMs:
componentsSeparatedByString:
objectAtIndexedSubscript:
doubleValue
numberWithDouble:
setStartTimeInNs:
setEndTimeInNs:
valueForKey:
setWeights:
setLanguageModelInterpolationWeights:
_resultInfosFromResultInfoDict:privateTokens:
setResults:
setStageName:
setIsAligned:
_choiceInfosFromChoiceInfoDicts:privateTokens:
setChoices:
_tokensFromTokensArray:privateTokens:
setGraphCost:
setAcousticCost:
setSilenceStartTimeInNs:
setToken:
setSilenceAcousticCost:
setNumBackoffs:
setLanguageModelCosts:
setText:
setPhoneSequence:
containsObject:
indexOfObject:
setLinkIndex:
count
boolValue
setAppendSpaceAfter:
setConfidence:
_transcriptMetadataFromPopDict:
setTrain:
setTest:
setDev:
setExternal:
setBestWeight:
setTotalDurationInMs:
_lmMetricsFromEvalDict:perplexityName:timesDict:
setTrains:
setTests:
setDevs:
setExternals:
setNgramOrder:
setResidualAdaptationWeight:
setTrainingDurationInMs:
setConversionDurationInMs:
setOptimizationDurationInMs:
setTranscriptionMetrics:
setEvaluationMetrics:
stringByReplacingOccurrencesOfString:withString:
convertLanguageCodeToSchemaLocale:
setUserLocale:
setModelMetrics:
setNumDocumentsRejected:
setNumSentencesRejected:
setNumDocumentsAccepted:
setNumSentencesAccepted:
setNumTokensAccepted:
setNumTokensOutOfVocabularyAccepted:
setNumDocumentsDictated:
setNumDocumentsTyped:
setNumTokensDictated:
setNumTokensTyped:
setNumSentencesMungeRejected:
setNumSentencesMungeChanged:
setLinearInterpolationWeight:
setNumUtterances:
setNumWords:
setNumOutOfVocabularyWords:
setNumInvalidTokens:
setNumInvalidUtterances:
setPerplexity:
setPerplexityOne:
setHits:
setNgramHits:
setDodMlId:
setExperimentName:
setEventMetadata:
setPersonalizationExperimentContext:
setUserEditExperimentContext:
setUserEditExperimentEndedTier1:
setAudioFileResultTier1:
sharedStream
emitMessage:
initWithExperimentId:
logUserEditExperimentStartedOrChanged
logUserEditExperimentEndedAndTier1WithResultsDict:
logDictationPersonalizationExperimentStartedOrChanged
logDictationPersonalizationExperimentEndedAndTier1WithResultsDict:
datapackVersion
.cxx_destruct
_dodmlId
_experimentId
_datapackVersion
T@"NSString",&,N,V_datapackVersion
initialize
generateTTSAudiosFromTexts:language:downsample:
invalidate
initWithDelegate:instanceUUID:
initWithLanguage:assetType:
modelPropertiesForAssetConfig:error:
modelVersion
recipe
recipeUserInfo
unsignedIntegerValue
matchingRecordSet
nativeRecordInfo
mutableCopy
exchangeObjectAtIndex:withObjectAtIndex:
nativeRecordDataForRecordUUID:error:
setObject:forKeyedSubscript:
length
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
attachments
path
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
code
numberWithInteger:
userInfo
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
integerValue
setWithArray:
sharedAnalytics
logEventWithType:context:
completeWithJSONResult:binaryResult:completionHandler:
_modelVersionForLanguage:
_selectRecordsWithSession:recordInfosOut:recordDatasOut:error:
completeWithError:completionHandler:
recordFromData:
correctedText
samplingRate
activity
_invalidate
generateAudioWithTexts:language:completion:
_invalidated
array
setValue:forKey:
subarrayWithRange:
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
sharedPreferences
dictationIsEnabled
performSystematicErrorEvaluation:
dictionary
numberWithUnsignedInteger:
_redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:
removePersonalizedLMForFidesOnly:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
evaluateRecipe:recordInfo:recordData:attachments:error:
telemetryWithRecordSet:
shouldDownloadAttachmentWithURL:recipe:recordInfo:
serverSafeRecordInfoWithRecordInfo:
evaluateRecipe:matchingRecordSet:error:
evaluateRecipe:matchingRecordSet:binaryResult:error:
performEvaluation:
_trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:
_queue
_smtClient
_recognizer
getOfflineDictationStatusWithCompletion:
allObjects
firstObject
languageCode
currentLocale
localeIdentifier
lastPathComponent
caseInsensitiveCompare:
siriDataSharingOptInStatus
%s Fides SELF: Logging object created successfully: dodmlId=%@, experimentId=%@
%s Fides SELF: Utterance Info could not be decompressed - it will not be logged.
%s Fides SELF: Utterance Info could not be deserialized - it will not be logged.
%s Fides SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s Fides SELF: Expected interpolation weight sets separated by delimter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s Fides SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the DODML ASR SELF schema.
%s Fides SELF: Wrapping and logging an event of type %@
SRAudioGenerator: Start generating TTS audio with language: %@
%s PLM: Invalidating
%s language: %@ modelVersion: %@ error: %@
%s Nil record data: %@
%s PLM: Recipe missing language
%s PLM: user language: %@
%s PLM: User language (%@) does not match recipe language (%@)
%s PLM: Recipe attachments missing configuration
%s PLM: Client start training
%s PLM: Client finished training
%s PLM: Client training failed: %@
%s Run evaluation using embeddedspeech recognizer for language %@
%s Evaluation failure
%s Starting systematic error evaluation in DictationPersonalizationFidesPlugin
%s SEE: No model installed
%s SEE: Rejected model
%s record info: %@
%s Nil record data
%s Unable to load localSpeechDESRecord
%s No corrected text in record, skipping TTS ASR pipeline
%s Sampling rate does not match, record sampling rate: %lu, downsampling rate: %lu
%s Retrieved corrected text: %@
%s No corrected text found in sampled dodML records, exiting...
%s SEE: eligibilityHandler deferred
%s Failed to generate TTS audio, error: %@
%s Failed to generate TTS audios
%s TTS failure when performing systematic error evaluation
%s Error running evaluation %@
%s ASR failure when performing systematic error evaluation, continuing
%s Recognized text and TTS ASR output did not match but was required to match, continuing
%s SEE: Deferred
%s Starting Fides evaluation for Dictation Personalization
%s Attachments: %@
%s Fides data size: %ld
%s Fides recipe parameters: %@
%s PLM: Dictation disabled
%s internal %d optIn %d reportWithFides %d
%s Performing systematic error evaluation instead of dictation personalization
%s PLM: No model installed
%s PLM: Rejected model
%s PLM: eligibilityHandler deferred
%s PLM: Deferred
%s PLM: installedLanguages=%@
%s PLM: Found one dictation language %@
%s PLM: Trying Siri language %@ result %@
%s PLM: Trying system language %@ result %@
-[FidesSelfHelper initWithExperimentId:]
confusionPairs
asrSelfComponentIdentifier
errorCode
recognizedPair
correctedPair
languageMetadata
status
Required Personalized LM not found
numAudio
numSelectedAudio
personalizedLM
audioResults
asrSelfComponentId
tokens
metrics
uttInfos
uttInfosCompressed
-[FidesSelfHelper _decodingResultsWithAudioDict:privateTokensOut:]
WallRTF
AverageActiveTokensPerFrame
jitQueryDurationInMs
jitLmeDurationInMs
lm_interp_weights
floatValue
-[FidesSelfHelper _decodingMetricsFromMetricsDict:]
results
startMillis
endMillis
aligned
choices
graphCost
acousticCost
startTime
endTime
removeSpaceAfter
silenceStartTime
confidence
text
phoneSequence
train
data
test
external
eval
model-selection
best-weight
totalTime
train-ppl
times
test-ppl
dev-ppl
external-ppl
model
order
residualAdaptationWeight
training
conversion
optimization
userLanguage
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numSentencesMungeRejected
numSentencesMungeChanged
utterances
words
OOVs
invalidTokens
invalidUtterances
PPL1
ngramHits
-[FidesSelfHelper _wrapAndEmitTopLevelEvent:]
com.apple.speech.speechmodeltraining
SRAudioGenerator
-[DictationPersonalizationFidesPlugin _invalidate]
DictationPersonalizationFidesPlugin.m
_queue
-[DictationPersonalizationFidesPlugin _invalidate]_block_invoke
v8@?0
-[DictationPersonalizationFidesPlugin _invalidated]
-[DictationPersonalizationFidesPlugin _modelVersionForLanguage:]
minAudio
maxAudio
language
-[DictationPersonalizationFidesPlugin _selectRecordsWithSession:recordInfosOut:recordDatasOut:error:]
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]
PLM: Recipe missing language
lm-personalize.json
PLM: Recipe attachments missing configuration
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]_block_invoke_2
v24@?0@"NSDictionary"8@"NSError"16
trainErrorCode
trainErrorDescription
asset
-[DictationPersonalizationFidesPlugin _redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:]
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]
com.apple.siri.speech-recognition-systematic-error
leftContextSize
rightContextSize
recordLimit
keepMTELogging
recognizedTTSASRShouldMatch
caseSensitive
skipLME
wordSenseAccessList
experimentId
modelVersions
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke_2
v16@?0@"NSObject<OS_xpc_object>"8
Deferred
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke
modelVersion
correctedOutput
recognizedOutput
editDistanceRecognizedTTSASR
timestamp
interactionId
-[DictationPersonalizationFidesPlugin performEvaluation:]
PLM: Dictation disabled
reportWithFides
disableMTELogging
User not opted-in
performSystematicErrorEvaluation
com.apple.siri.speech-dictation-personalization
-[DictationPersonalizationFidesPlugin performEvaluation:]_block_invoke
getPersonalizedLMUserLanguage
FidesSelfHelper
SRAudioGenerator
DictationPersonalizationFidesPlugin
DESRecipeEvaluation
NSObject
@24@0:8@16
v16@0:8
v24@0:8@16
@32@0:8@16^@24
@32@0:8@16@24
@40@0:8@16@24@32
@16@0:8
@"NSUUID"
@"NSString"
@36@0:8@16@24B32
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@56@0:8@16@24@32@40^@48
B40@0:8@16@24@32
@40@0:8@16@24^@32
@48@0:8@16@24^@32^@40
@"NSDictionary"56@0:8@"NSDictionary"16@"NSDictionary"24@"NSData"32@"NSArray"40^@48
@"NSDictionary"24@0:8@"DESRecordSet"16
B40@0:8@"NSURL"16@"NSDictionary"24@"NSDictionary"32
@"NSDictionary"24@0:8@"NSDictionary"16
@"NSDictionary"40@0:8@"DESRecipe"16@"DESRecordSet"24^@32
@"NSDictionary"48@0:8@"DESRecipe"16@"DESRecordSet"24^@32^@40
v24@0:8@"DESRecipeEvaluationSession"16
B48@0:8@16^@24^@32^@40
B56@0:8@16@24^@32^@40^@48
B76@0:8@16@24@32@40@48B56@60^@68
@"NSObject<OS_dispatch_queue>"
@"SpeechModelTrainingClient"
@"CoreEmbeddedSpeechRecognizer"
