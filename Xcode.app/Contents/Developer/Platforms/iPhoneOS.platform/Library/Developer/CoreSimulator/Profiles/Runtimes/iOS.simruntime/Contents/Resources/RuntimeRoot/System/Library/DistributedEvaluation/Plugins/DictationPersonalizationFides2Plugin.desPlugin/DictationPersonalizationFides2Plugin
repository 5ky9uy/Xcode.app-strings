_redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:
JSONObjectWithData:options:error:
allKeys
T@"NSString",&,N,V_datapackVersion
datapackVersion
TQ,R
isProxy
UUIDString
release
_choiceInfosFromChoiceInfoDicts:privateTokens:
setDev:
_decodingMetricsFromMetricsDict:
setNumBackoffs:
_dodmlId
.cxx_destruct
_transcriptMetadataFromPopDict:
T#,R
containsObject:
T@"NSString",R,C
initWithNSUUID:
UUID
recordFromData:
_audioFileResultsFromResultDict:privateAudioFileResultsOut:
setAverageActiveTokensPerFrame:
_datapackVersion
setEndTimeInNs:
_decodingResultsWithAudioDict:privateTokensOut:
sharedAnalytics
_experimentId
_invalidate
_invalidated
_lmMetricsFromEvalDict:perplexityName:timesDict:
_modelVersionForLanguage:
_plmMetricsFromPlmDict:
_queue
_recognizer
_resultInfosFromResultInfoDict:privateTokens:
_selectRecordsWithSession:recordInfosOut:recordDatasOut:error:
_smtClient
_tokensFromTokenDict:privateTokens:
_tokensFromTokensArray:privateTokens:
_trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:
_utteranceInfosFromUtteranceInfoDict:privateTokens:
_wrapAndEmitTopLevelEvent:
activity
addObject:
addPostprocessingEntityCategoryCounts:
addPreprocessingEntityCategoryCounts:
allObjects
array
attachments
autorelease
boolValue
caseInsensitiveCompare:
class
code
completeWithError:completionHandler:
completeWithJSONResult:binaryResult:completionHandler:
componentsSeparatedByString:
conformsToProtocol:
convertLanguageCodeToSchemaLocale:
correctedText
count
countByEnumeratingWithState:objects:count:
currentLocale
debugDescription
decompressedDataUsingAlgorithm:error:
description
dictationIsEnabled
dictionary
dictionaryWithObjects:forKeys:count:
doubleValue
emitMessage:
enumerateKeysAndObjectsUsingBlock:
errorWithDomain:code:userInfo:
evaluateRecipe:matchingRecordSet:binaryResult:error:
evaluateRecipe:matchingRecordSet:error:
evaluateRecipe:recordInfo:recordData:attachments:error:
exchangeObjectAtIndex:withObjectAtIndex:
firstObject
floatValue
generateAudioWithTexts:language:completion:
getOfflineDictationStatusWithCompletion:
hash
indexOfObject:
init
initWithBase64EncodedString:options:
initWithDelegate:instanceUUID:
initWithExperimentId:
initWithLanguage:assetType:
initWithUUIDString:
intValue
integerValue
invalidate
isEqual:
isEqualToString:
isKindOfClass:
isMemberOfClass:
languageCode
lastPathComponent
length
localeIdentifier
logDictationPersonalizationExperimentEndedAndTier1WithResultsDict:
logDictationPersonalizationExperimentStartedOrChanged
logEventWithType:context:
logUserEditExperimentEndedAndTier1WithResultsDict:
logUserEditExperimentStartedOrChanged
matchingRecordSet
modelPropertiesForAssetConfig:error:
modelVersion
mutableCopy
nativeRecordDataForRecordUUID:error:
nativeRecordInfo
numberWithDouble:
numberWithInteger:
numberWithUnsignedInteger:
objectAtIndexedSubscript:
objectForKeyedSubscript:
path
performEvaluation:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSystematicErrorEvaluation:
processInfo
recipe
recipeUserInfo
removeObjectForKey:
removePersonalizedLMForFidesOnly:
respondsToSelector:
retain
retainCount
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
samplingRate
self
serverSafeRecordInfoWithRecordInfo:
setAcousticCost:
setAppendSpaceAfter:
setAsrId:
setAudioFileResultTier1:
setAudioFileResults:
setBestWeight:
setChoices:
setConfidence:
setConfigName:
setConfusionPairs:
setConversionDurationInMs:
setCorrectedTokens:
setCount:
setDatapackVersion:
setDecodeDurationInNs:
setDecodingMetrics:
setDecodingResults:
setDeviceThermalState:
setDevs:
setDodMlId:
setEnded:
setEntityCategory:
setErrorCode:
setEvaluationMetrics:
setEventMetadata:
setExists:
setExperimentName:
setExperimentStatusCode:
setExternal:
setExternals:
setGraphCost:
setHits:
setIsAligned:
setJitLanguageModelEnrollmentDurationInMs:
setJitQueryDurationInMs:
setLanguageModelCosts:
setLanguageModelInterpolationWeights:
setLinearInterpolationWeight:
setLinkId:
setLinkIndex:
setModelMetrics:
setModelTrainingStatusCode:
setNgramHits:
setNgramOrder:
setNumAudioFilesAvailable:
setNumAudioFilesSelected:
setNumDocumentsAccepted:
setNumDocumentsDictated:
setNumDocumentsRejected:
setNumDocumentsTyped:
setNumFiniteStateTransducerArcs:
setNumFiniteStateTransducerStates:
setNumInvalidTokens:
setNumInvalidUtterances:
setNumOutOfVocabularyWords:
setNumSentencesAccepted:
setNumSentencesMungeChanged:
setNumSentencesMungeRejected:
setNumSentencesRejected:
setNumTokensAccepted:
setNumTokensDictated:
setNumTokensEstimatedExamined:
setNumTokensOutOfVocabularyAccepted:
setNumTokensTyped:
setNumUtterances:
setNumWords:
setObject:forKeyedSubscript:
setOptimizationDurationInMs:
setPerplexity:
setPerplexityOne:
setPersonalizationExperimentContext:
setPersonalizedLanguageModelMetrics:
setPhoneSequence:
setRecognitionResult:
setRecognizedTokens:
setRedecodingResults:
setResidualAdaptationWeight:
setResults:
setSilenceAcousticCost:
setSilenceStartTimeInNs:
setStageName:
setStartTimeInNs:
setStartedOrChanged:
setTest:
setTests:
setText:
setTextProcessingDurationInNs:
setToken:
setTokens:
setTotalDurationInMs:
setTrain:
setTrainingDurationInMs:
setTrains:
setTranscriptionMetrics:
setUserEditExperimentContext:
setUserEditExperimentEndedTier1:
setUserLocale:
setUtterances:
setValue:forKey:
setWallRealTimeFactor:
setWeights:
setWithArray:
sharedPreferences
sharedStream
shouldDownloadAttachmentWithURL:recipe:recordInfo:
siriDataSharingOptInStatus
stringByReplacingOccurrencesOfString:withString:
subarrayWithRange:
superclass
telemetryWithRecordSet:
thermalState
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
userInfo
valueForKey:
valueForKeyPath:
zone
%s Fides SELF: Logging object created successfully: dodmlId=%@, experimentId=%@
%s Fides SELF: Utterance Info could not be decompressed - it will not be logged.
%s Fides SELF: Utterance Info could not be deserialized - it will not be logged.
%s Fides SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s Fides SELF: Expected interpolation weight sets separated by delimter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s Fides SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the DODML ASR SELF schema.
%s Fides SELF: Wrapping and logging an event of type %@
%s PLM: Invalidating
%s language: %@ modelVersion: %@ error: %@
%s Nil record data: %@
%s PLM: Recipe missing language
%s PLM: user language: %@
%s PLM: User language (%@) does not match recipe language (%@)
%s PLM: Recipe attachments missing configuration
%s PLM: Client start training
%s PLM: Client finished training
%s PLM: Client training failed: %@
%s Run evaluation using embeddedspeech recognizer for language %@
%s Evaluation failure
%s Starting systematic error evaluation in DictationPersonalizationFidesPlugin
%s SEE: No model installed
%s SEE: Rejected model
%s record info: %@
%s Nil record data
%s Unable to load localSpeechDESRecord
%s No corrected text in record, skipping TTS ASR pipeline
%s Sampling rate does not match, record sampling rate: %lu, downsampling rate: %lu
%s Retrieved corrected text: %@
%s No corrected text found in sampled dodML records, exiting...
%s SEE: eligibilityHandler deferred
%s Failed to generate TTS audio, error: %@
%s Failed to generate TTS audios
%s TTS failure when performing systematic error evaluation
%s Error running evaluation %@
%s ASR failure when performing systematic error evaluation, continuing
%s Recognized text and TTS ASR output did not match but was required to match, continuing
%s SEE: Deferred
%s Starting Fides evaluation for Dictation Personalization
%s Attachments: %@
%s Fides data size: %ld
%s Fides recipe parameters: %@
%s PLM: Dictation disabled
%s internal %d optIn %d reportWithFides %d
%s Performing systematic error evaluation instead of dictation personalization
%s PLM: No model installed
%s PLM: Rejected model
%s PLM: eligibilityHandler deferred
%s PLM: Deferred
%s PLM: installedLanguages=%@
%s PLM: Found one dictation language %@
%s PLM: Trying Siri language %@ result %@
%s PLM: Trying system language %@ result %@
-[FidesSelfHelper initWithExperimentId:]
confusionPairs
asrSelfComponentIdentifier
errorCode
recognizedPair
correctedPair
languageMetadata
status
Required Personalized LM not found
numAudio
numSelectedAudio
textProcessingDuration
personalizedLM
audioResults
asrSelfComponentId
tokens
metrics
uttInfos
uttInfosCompressed
-[FidesSelfHelper _decodingResultsWithAudioDict:privateTokensOut:]
DecodeDuration
WallRTF
AverageActiveTokensPerFrame
jitQueryDurationInMs
jitLmeDurationInMs
jitDataStats.preprocessingCategoryCounts
v32@?0@8@16^B24
jitDataStats.postprocessingCategoryCounts
jitDataStats
lm_interp_weights
floatValue
-[FidesSelfHelper _decodingMetricsFromMetricsDict:]
results
startMillis
endMillis
aligned
choices
graphCost
acousticCost
startTime
endTime
removeSpaceAfter
silenceStartTime
confidence
text
phoneSequence
train
data
test
external
eval
model-selection
best-weight
totalTime
train-ppl
times
test-ppl
dev-ppl
external-ppl
model
order
residualAdaptationWeight
training
conversion
optimization
numStates
numArcs
trainErrorCode
userLanguage
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numSentencesMungeRejected
numSentencesMungeChanged
numTokensEstimatedExamined
utterances
words
OOVs
invalidTokens
invalidUtterances
PPL1
ngramHits
-[FidesSelfHelper _wrapAndEmitTopLevelEvent:]
-[DictationPersonalizationFidesPlugin _invalidate]
DictationPersonalizationFidesPlugin.m
_queue
-[DictationPersonalizationFidesPlugin _invalidate]_block_invoke
v8@?0
-[DictationPersonalizationFidesPlugin _invalidated]
-[DictationPersonalizationFidesPlugin _modelVersionForLanguage:]
minAudio
maxAudio
language
-[DictationPersonalizationFidesPlugin _selectRecordsWithSession:recordInfosOut:recordDatasOut:error:]
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]
PLM: Recipe missing language
lm-personalize.json
PLM: Recipe attachments missing configuration
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]_block_invoke_2
v24@?0@"NSDictionary"8@"NSError"16
trainErrorDescription
asset
-[DictationPersonalizationFidesPlugin _redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:]
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]
com.apple.siri.speech-recognition-systematic-error
leftContextSize
rightContextSize
recordLimit
keepMTELogging
recognizedTTSASRShouldMatch
caseSensitive
skipLME
wordSenseAccessList
experimentId
modelVersions
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke_2
v16@?0@"NSObject<OS_xpc_object>"8
Deferred
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke
modelVersion
correctedOutput
recognizedOutput
editDistanceRecognizedTTSASR
timestamp
interactionId
-[DictationPersonalizationFidesPlugin performEvaluation:]
PLM: Dictation disabled
reportWithFides
disableMTELogging
User not opted-in
performSystematicErrorEvaluation
com.apple.siri.speech-dictation-personalization
-[DictationPersonalizationFidesPlugin performEvaluation:]_block_invoke
getPersonalizedLMUserLanguage
FidesSelfHelper
DictationPersonalizationFidesPlugin
DESRecipeEvaluation
NSObject
@24@0:8@16
v16@0:8
v24@0:8@16
@32@0:8@16^@24
@32@0:8@16@24
@40@0:8@16@24@32
@16@0:8
@"NSUUID"
@"NSString"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@56@0:8@16@24@32@40^@48
B40@0:8@16@24@32
@40@0:8@16@24^@32
@48@0:8@16@24^@32^@40
@"NSDictionary"56@0:8@"NSDictionary"16@"NSDictionary"24@"NSData"32@"NSArray"40^@48
@"NSDictionary"24@0:8@"DESRecordSet"16
B40@0:8@"NSURL"16@"NSDictionary"24@"NSDictionary"32
@"NSDictionary"24@0:8@"NSDictionary"16
@"NSDictionary"40@0:8@"DESRecipe"16@"DESRecordSet"24^@32
@"NSDictionary"48@0:8@"DESRecipe"16@"DESRecordSet"24^@32^@40
v24@0:8@"DESRecipeEvaluationSession"16
B48@0:8@16^@24^@32^@40
B56@0:8@16@24^@32^@40^@48
B76@0:8@16@24@32@40@48B56@60^@68
@"NSObject<OS_dispatch_queue>"
@"SpeechModelTrainingClient"
@"CoreEmbeddedSpeechRecognizer"
_redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:
JSONObjectWithData:options:error:
allKeys
T@"NSString",&,N,V_datapackVersion
datapackVersion
TQ,R
isProxy
UUIDString
release
_choiceInfosFromChoiceInfoDicts:privateTokens:
setDev:
_decodingMetricsFromMetricsDict:
setNumBackoffs:
_dodmlId
.cxx_destruct
_transcriptMetadataFromPopDict:
T#,R
containsObject:
T@"NSString",R,C
initWithNSUUID:
UUID
recordFromData:
_audioFileResultsFromResultDict:privateAudioFileResultsOut:
setAverageActiveTokensPerFrame:
_datapackVersion
setEndTimeInNs:
_decodingResultsWithAudioDict:privateTokensOut:
sharedAnalytics
_experimentId
_invalidate
_invalidated
_lmMetricsFromEvalDict:perplexityName:timesDict:
_modelVersionForLanguage:
_plmMetricsFromPlmDict:
_queue
_recognizer
_resultInfosFromResultInfoDict:privateTokens:
_selectRecordsWithSession:recordInfosOut:recordDatasOut:error:
_smtClient
_tokensFromTokenDict:privateTokens:
_tokensFromTokensArray:privateTokens:
_trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:
_utteranceInfosFromUtteranceInfoDict:privateTokens:
_wrapAndEmitTopLevelEvent:
activity
addObject:
addPostprocessingEntityCategoryCounts:
addPreprocessingEntityCategoryCounts:
allObjects
array
attachments
autorelease
boolValue
caseInsensitiveCompare:
class
code
completeWithError:completionHandler:
completeWithJSONResult:binaryResult:completionHandler:
componentsSeparatedByString:
conformsToProtocol:
convertLanguageCodeToSchemaLocale:
correctedText
count
countByEnumeratingWithState:objects:count:
currentLocale
debugDescription
decompressedDataUsingAlgorithm:error:
description
dictationIsEnabled
dictionary
dictionaryWithObjects:forKeys:count:
doubleValue
emitMessage:
enumerateKeysAndObjectsUsingBlock:
errorWithDomain:code:userInfo:
evaluateRecipe:matchingRecordSet:binaryResult:error:
evaluateRecipe:matchingRecordSet:error:
evaluateRecipe:recordInfo:recordData:attachments:error:
exchangeObjectAtIndex:withObjectAtIndex:
firstObject
floatValue
generateAudioWithTexts:language:completion:
getOfflineDictationStatusWithCompletion:
hash
indexOfObject:
init
initWithBase64EncodedString:options:
initWithDelegate:instanceUUID:
initWithExperimentId:
initWithLanguage:assetType:
initWithUUIDString:
intValue
integerValue
invalidate
isEqual:
isEqualToString:
isKindOfClass:
isMemberOfClass:
languageCode
lastPathComponent
length
localeIdentifier
logDictationPersonalizationExperimentEndedAndTier1WithResultsDict:
logDictationPersonalizationExperimentStartedOrChanged
logEventWithType:context:
logUserEditExperimentEndedAndTier1WithResultsDict:
logUserEditExperimentStartedOrChanged
matchingRecordSet
modelPropertiesForAssetConfig:error:
modelVersion
mutableCopy
nativeRecordDataForRecordUUID:error:
nativeRecordInfo
numberWithDouble:
numberWithInteger:
numberWithUnsignedInteger:
objectAtIndexedSubscript:
objectForKeyedSubscript:
path
performEvaluation:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performSystematicErrorEvaluation:
processInfo
recipe
recipeUserInfo
removeObjectForKey:
respondsToSelector:
retain
retainCount
runCorrectedTextEvaluationWithAudioDatas:recordDatas:language:samplingRate:caseSensitive:skipLME:wordSenseAccessListSet:completion:
runEvaluationWithDESRecordDatas:language:recipe:attachments:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
runEvaluationWithDESRecordDatas:language:recipe:fidesPersonalizedLMPath:fidesPersonalizedLMTrainingAsset:scrubResult:completion:
samplingRate
self
serverSafeRecordInfoWithRecordInfo:
setAcousticCost:
setAppendSpaceAfter:
setAsrId:
setAudioFileResultTier1:
setAudioFileResults:
setBestWeight:
setChoices:
setConfidence:
setConfigName:
setConfusionPairs:
setConversionDurationInMs:
setCorrectedTokens:
setCount:
setDatapackVersion:
setDecodeDurationInNs:
setDecodingMetrics:
setDecodingResults:
setDeviceThermalState:
setDevs:
setDodMlId:
setEnded:
setEntityCategory:
setErrorCode:
setEvaluationMetrics:
setEventMetadata:
setExists:
setExperimentName:
setExperimentStatusCode:
setExternal:
setExternals:
setGraphCost:
setHits:
setIsAligned:
setJitLanguageModelEnrollmentDurationInMs:
setJitQueryDurationInMs:
setLanguageModelCosts:
setLanguageModelInterpolationWeights:
setLinearInterpolationWeight:
setLinkId:
setLinkIndex:
setModelMetrics:
setModelTrainingStatusCode:
setNgramHits:
setNgramOrder:
setNumAudioFilesAvailable:
setNumAudioFilesSelected:
setNumDocumentsAccepted:
setNumDocumentsDictated:
setNumDocumentsRejected:
setNumDocumentsTyped:
setNumFiniteStateTransducerArcs:
setNumFiniteStateTransducerStates:
setNumInvalidTokens:
setNumInvalidUtterances:
setNumOutOfVocabularyWords:
setNumSentencesAccepted:
setNumSentencesMungeChanged:
setNumSentencesMungeRejected:
setNumSentencesRejected:
setNumTokensAccepted:
setNumTokensDictated:
setNumTokensEstimatedExamined:
setNumTokensOutOfVocabularyAccepted:
setNumTokensTyped:
setNumUtterances:
setNumWords:
setObject:forKeyedSubscript:
setOptimizationDurationInMs:
setPerplexity:
setPerplexityOne:
setPersonalizationExperimentContext:
setPersonalizedLanguageModelMetrics:
setPhoneSequence:
setRecognitionResult:
setRecognizedTokens:
setRedecodingResults:
setResidualAdaptationWeight:
setResults:
setSilenceAcousticCost:
setSilenceStartTimeInNs:
setStageName:
setStartTimeInNs:
setStartedOrChanged:
setTest:
setTests:
setText:
setTextProcessingDurationInNs:
setToken:
setTokens:
setTotalDurationInMs:
setTrain:
setTrainingDurationInMs:
setTrains:
setTranscriptionMetrics:
setUserEditExperimentContext:
setUserEditExperimentEndedTier1:
setUserLocale:
setUtterances:
setValue:forKey:
setWallRealTimeFactor:
setWeights:
setWithArray:
sharedPreferences
sharedStream
shouldDownloadAttachmentWithURL:recipe:recordInfo:
siriDataSharingOptInStatus
stringByReplacingOccurrencesOfString:withString:
subarrayWithRange:
superclass
telemetryWithRecordSet:
thermalState
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
unsignedLongValue
userInfo
valueForKey:
valueForKeyPath:
zone
%s Fides SELF: Logging object created successfully: dodmlId=%@, experimentId=%@
%s Fides SELF: Utterance Info could not be decompressed - it will not be logged.
%s Fides SELF: Utterance Info could not be deserialized - it will not be logged.
%s Fides SELF: Encountered malformed string during SELF logging for interpolation weights in speech results from recognizer. String: %@
%s Fides SELF: Expected interpolation weight sets separated by delimter ';' - starting with a set of weights delimited by ',' and ending the with start/end times delimited by ':'. Ex: '0.999646,0.000354:0:4280;0.947514,0.000158:0:3859'
%s Fides SELF: Failed trying to wrap and emit top-level ASR event because event type was not mapped to loggable message type in the DODML ASR SELF schema.
%s Fides SELF: Wrapping and logging an event of type %@
%s PLM: Invalidating
%s language: %@ modelVersion: %@ error: %@
%s Nil record data: %@
%s PLM: Recipe missing language
%s PLM: user language: %@
%s PLM: User language (%@) does not match recipe language (%@)
%s PLM: Recipe attachments missing configuration
%s PLM: Client start training
%s PLM: Client finished training
%s PLM: Client training failed: %@
%s Run evaluation using embeddedspeech recognizer for language %@
%s Evaluation failure
%s Starting systematic error evaluation in DictationPersonalizationFidesPlugin
%s SEE: No model installed
%s SEE: Rejected model
%s record info: %@
%s Nil record data
%s Unable to load localSpeechDESRecord
%s No corrected text in record, skipping TTS ASR pipeline
%s Sampling rate does not match, record sampling rate: %lu, downsampling rate: %lu
%s Retrieved corrected text: %@
%s No corrected text found in sampled dodML records, exiting...
%s SEE: eligibilityHandler deferred
%s Failed to generate TTS audio, error: %@
%s Failed to generate TTS audios
%s TTS failure when performing systematic error evaluation
%s Error running evaluation %@
%s ASR failure when performing systematic error evaluation, continuing
%s Recognized text and TTS ASR output did not match but was required to match, continuing
%s SEE: Deferred
%s Starting Fides evaluation for Dictation Personalization
%s Attachments: %@
%s Fides data size: %ld
%s Fides recipe parameters: %@
%s PLM: Dictation disabled
%s internal %d optIn %d reportWithFides %d
%s Performing systematic error evaluation instead of dictation personalization
%s PLM: No model installed
%s PLM: Rejected model
%s PLM: eligibilityHandler deferred
%s PLM: Deferred
%s PLM: installedLanguages=%@
%s PLM: Found one dictation language %@
%s PLM: Trying Siri language %@ result %@
%s PLM: Trying system language %@ result %@
-[FidesSelfHelper initWithExperimentId:]
confusionPairs
asrSelfComponentIdentifier
errorCode
recognizedPair
correctedPair
languageMetadata
status
Required Personalized LM not found
numAudio
numSelectedAudio
textProcessingDuration
personalizedLM
audioResults
asrSelfComponentId
tokens
metrics
uttInfos
uttInfosCompressed
-[FidesSelfHelper _decodingResultsWithAudioDict:privateTokensOut:]
DecodeDuration
WallRTF
AverageActiveTokensPerFrame
jitQueryDurationInMs
jitLmeDurationInMs
jitDataStats.preprocessingCategoryCounts
v32@?0@8@16^B24
jitDataStats.postprocessingCategoryCounts
jitDataStats
lm_interp_weights
floatValue
-[FidesSelfHelper _decodingMetricsFromMetricsDict:]
results
startMillis
endMillis
aligned
choices
graphCost
acousticCost
startTime
endTime
removeSpaceAfter
silenceStartTime
confidence
text
phoneSequence
train
data
test
external
eval
model-selection
best-weight
totalTime
train-ppl
times
test-ppl
dev-ppl
external-ppl
model
order
residualAdaptationWeight
training
conversion
optimization
numStates
numArcs
trainErrorCode
userLanguage
numDocumentsRejected
numSentencesRejected
numDocuments
numSentences
numTokens
numTokensOOV
numDocumentsDictated
numDocumentsTyped
numTokensDictated
numTokensTyped
numSentencesMungeRejected
numSentencesMungeChanged
numTokensEstimatedExamined
utterances
words
OOVs
invalidTokens
invalidUtterances
PPL1
ngramHits
-[FidesSelfHelper _wrapAndEmitTopLevelEvent:]
-[DictationPersonalizationFidesPlugin _invalidate]
DictationPersonalizationFidesPlugin.m
_queue
-[DictationPersonalizationFidesPlugin _invalidate]_block_invoke
v8@?0
-[DictationPersonalizationFidesPlugin _invalidated]
-[DictationPersonalizationFidesPlugin _modelVersionForLanguage:]
minAudio
maxAudio
language
-[DictationPersonalizationFidesPlugin _selectRecordsWithSession:recordInfosOut:recordDatasOut:error:]
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]
PLM: Recipe missing language
lm-personalize.json
PLM: Recipe attachments missing configuration
-[DictationPersonalizationFidesPlugin _trainPersonalizedLMWithSession:directory:trainingAssetOut:resultOut:error:]_block_invoke_2
v24@?0@"NSDictionary"8@"NSError"16
trainErrorDescription
asset
-[DictationPersonalizationFidesPlugin _redecodeWithSession:selectedRecordInfos:selectedRecordDatas:personalizedLMPath:personalizedLMTrainingAsset:optIn:result:error:]
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]
com.apple.siri.speech-recognition-systematic-error
leftContextSize
rightContextSize
recordLimit
keepMTELogging
recognizedTTSASRShouldMatch
caseSensitive
skipLME
wordSenseAccessList
experimentId
modelVersions
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke_2
v16@?0@"NSObject<OS_xpc_object>"8
Deferred
-[DictationPersonalizationFidesPlugin performSystematicErrorEvaluation:]_block_invoke
modelVersion
correctedOutput
recognizedOutput
editDistanceRecognizedTTSASR
timestamp
interactionId
-[DictationPersonalizationFidesPlugin performEvaluation:]
PLM: Dictation disabled
reportWithFides
disableMTELogging
User not opted-in
performSystematicErrorEvaluation
com.apple.siri.speech-dictation-personalization
-[DictationPersonalizationFidesPlugin performEvaluation:]_block_invoke
getPersonalizedLMUserLanguage
FidesSelfHelper
DictationPersonalizationFidesPlugin
DESRecipeEvaluation
NSObject
@24@0:8@16
v16@0:8
v24@0:8@16
@32@0:8@16^@24
@32@0:8@16@24
@40@0:8@16@24@32
@16@0:8
@"NSUUID"
@"NSString"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@56@0:8@16@24@32@40^@48
B40@0:8@16@24@32
@40@0:8@16@24^@32
@48@0:8@16@24^@32^@40
@"NSDictionary"56@0:8@"NSDictionary"16@"NSDictionary"24@"NSData"32@"NSArray"40^@48
@"NSDictionary"24@0:8@"DESRecordSet"16
B40@0:8@"NSURL"16@"NSDictionary"24@"NSDictionary"32
@"NSDictionary"24@0:8@"NSDictionary"16
@"NSDictionary"40@0:8@"DESRecipe"16@"DESRecordSet"24^@32
@"NSDictionary"48@0:8@"DESRecipe"16@"DESRecordSet"24^@32^@40
v24@0:8@"DESRecipeEvaluationSession"16
B48@0:8@16^@24^@32^@40
B56@0:8@16@24^@32^@40^@48
B76@0:8@16@24@32@40@48B56@60^@68
@"NSObject<OS_dispatch_queue>"
@"SpeechModelTrainingClient"
@"CoreEmbeddedSpeechRecognizer"
