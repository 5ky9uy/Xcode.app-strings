@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
?St13runtime_error
N8DSPGraph9ExceptionE
St9exception
St12length_error
St11logic_error
mcpl)
St20bad_array_new_length
St9bad_alloc
@xfuapraexoba
xfuapargxoba
MbP?St12out_of_range
NSt3__117bad_function_callE
cmcp!
cmcp!
mcpl,
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
xfuadgisxoba
xfuaftmlxoba
got no answer for question %@
BuildVersion
timeRange
decibelLevel
type
detectorIdentifier
composedDetector
illegal call to unavailable init selector: %s
-[SNComposedDetector init]
cannot deserialized MLModel
cannot serialize MLModel
cannot copy MLModel
-[SNDetectorVariant init]
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
-[SNFallingEdgeSmoother init]
illegal call to unavailable new selector: %s
+[SNFallingEdgeSmoother new]
tuningPrefix
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/b1b7133b-aed3-11ed-bf78-863efbbaf80d/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.4.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
doa.dspg
PropertyStrip
doa.propstrip
AUStrip
doa.austrip
Failed to create graph
basic_string
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
vector
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
expected double; got %@
expected unsigned integer; got %@
expected int32; got %@
expected uint32; got %@
expected positive number; got %@
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
q16@?0q8
v8@?0
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v24@?0^{OpaqueAudioQueue=}8@"AVAudioSession"16
/Library/Audio/Tunings
SoundAnalysis
Applause
SNVGGishApplauseModel
Babble
SNVGGishBabbleModel
Cheering
SNVGGishCheeringModel
Laughter
SNVGGishLaughterModel
Music
SNVGGishMusicModel
Speech
SNVGGishSpeechModel
Distressed Baby
SNVGGishDistressedBabyModel
Smoke Alarm
SNVGGishSmokeAlarmModel
Fire Alarm
SNVGGishFireAlarmModel
Doorbell
SNVGGishDoorbellModel
Buzzer
SNVGGishBuzzerModel
Beep
SNVGGishBeepModel
Ding Bell
SNVGGishDingBellModel
Dog Bark
SNVGGishDogBarkModel
Cat Meow
SNVGGishCatMeowModel
Door Knock
SNVGGishDoorKnockModel
Shouting
SNVGGishShoutingModel
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNSoundPrintASmokeAlarmModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
SNAudioQualityModel
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
elevation
spatialSpectrum
%@ azmimuth: %f elevation: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
com.apple.SoundAnalysis.AllAnalysisRequests
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
v8@?0
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
@32@?0@8@16^@24
@24@?0@8^@16
multiple keys mapping to the same value: %@
B32@?0@8@16^@24
B24@?0@8@16
@"NSArray"16@?0@8
B16@?0@8
@"NSNumber"24@?0@"NSNumber"8@16
@"<NSFastEnumeration>"24@?0@8^@16
@"NSDictionary"24@?0@8^@16
@"NSDictionary"16@?0@"<NSCopying>"8
bad collection; contains `nil`
@8@?0
@24@?0@8@16
q24@?0@"NSNumber"8@"NSNumber"16
partition size may not be 0
failed to divide into partitions of size %@; remainder %@
@16@?0@8
@"NSArray"32@?0@"<NSFastEnumeration>"8@"NSNumber"16^@24
@16@?0@"NSArray"8
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
mic_injection_file_path
sysdiagnose_historical_duration
daemon_recording_path
delete_recordings_without_detection
first_pass_recording_predicate
first_pass_recording_history_duration
enable_second_pass_recording_in_daemon
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
microphone_array_channel_map
@"NSNumber"24@?0@8^@16
Library
Caches
AudioCaptures
default
audio
results
-[SNUltronReportOperator init]
unrecognized input port ID: %@
v32@?0@"NSString"8@16@"NSError"24
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
expected non-silent audio buffer
expected no NaN-valued audio samples
expected no infinite audio samples
v32@?0@"NSString"8@"AVAudioPCMBuffer"16@"NSError"24
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
v32@?0@"NSString"8@"<SNResult>"16@"NSError"24
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
Unsupported dimension count
%@ detected: %@
Expected multi array to have standard strides
Expected count to be non-negative
Expected new dimension count to be at least as large as original
SNMultiArrayUtils.mm
unsupported data type %@
IncludePaths
Substitutions
Value
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
-[SNRecordOperator init]
v16@?0^@8
failed to record audio to file
com.apple.SoundAnalysis.remoteanalyzer
all_data
label
dataset
embedding
inference_window_size
exemplar
negative
positive
training
validation
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
-[SNKShotLabel init]
+[SNKShotLabel new]
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
v16@?0@"SNKShotFeaturizationStreamResult"8
v24@?0@"SNKShotFeaturizationStreamCompletion"8@"NSError"16
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
Not enough audio segments found to continue.
v32@?0@"NSNumber"8@"MLMultiArray"16q24
v24@?0@"NSNumber"8@"MLMultiArray"16
B8@?0
MLModelCreatorDefinedKey
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
could not translate number to label: %@
expected same number of embeddings and labels
@"SNKShotFeaturizationStreamResult"32@?0@"MLMultiArray"8@"NSNumber"16^@24
unrecognized label type: %@
unrecognized dataset type: %@
@"NSDictionary"24@?0@"SNKShotFeaturizationStreamResult"8^@16
-[SNKeyValueMutation init]
unrecognized mutation type
key to be added already exists (%@)
v24@?0@8@16
required key missing from dictionary: %@
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
v24@?0@"<SNRequest>"8@"NSError"16
SNSystemAudioAnalyzerRemote.m
request
observer
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
-[SNResultsForwarder init]
v24@?0@"<SNRequest>"8@"<SNResult>"16
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
unrecognized classifier type
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
resultsPredicate
resultsPredicateLeakCount
Couldn't find soundIdentifier for detectorIdentifier %@
<Unknown Sound>
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
graph
Audio format must be PCM
Audio format channel count and sample rate must be nonzero
InvalidFormatException
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
@"NSObject<SNTimeRangeProvidingWritable>"16@?0@"NSObject<SNTimeRangeProvidingWritable>"8
%@_%@
@"NSString"16@?0@"SNDetectionResult"8
@"NSNumber"16@?0@"SNDetectionResult"8
timestamp
@"NSDictionary"16@?0@"NSArray"8
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
could not query build version and recording path
SNSoundDetectionUtils.mm
minimumStepSize <= windowLengthFrames
minimumStepSize % factor == 0
no supported feature extractor for detector variant
@"<SNFeatureExtractorConfiguration>"24@?0@"MLModel"8@"SNDetectorHeadModelMetadata"16
cannot create feature extractor config for identifier: %@
[identifier isEqual:detectorHeadModelMetadata.featureExtractorIdentifier]
expected feature extractor in detector head model metadata
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
v32@?0@"NSString"8@16@"NSError"24
expected termination or input but got both: input %@, error %@
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
#24@?0@"NSString"8^@16
could not derive tagged model classes from tags
unsupported feature extractor: %@
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
DSPGraph ABI runtime/compile-time mismatch
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
SNUtils.mm
Expected only one user-supplied input feature; got: %@
MultiArrayInput
MultiArrayOutput
soundanalysisd
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
VerifyNotTrashingOwnedBuffer
mBufferMemory == NULL
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"NSString"8@?0
-[SNFileInjectOperator init]
B24@?0@"AVAudioPCMBuffer"8^@16
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
buffer populator produced excess frames: %@
did not process all frames; remaining %@
failed to make buffer with format %@, capacity %@
@"AVAudioPCMBuffer"16@?0^@8
B28@?0@"AVAudioPCMBuffer"8I16^@20
B16@?0@"NSValue"8
used bad buffer populator
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
expected object %@ of class %@ to be one of %@
expected object %@ of class %@ to be kind of %@
@"NSValue"16@?0@"<SNTimeRangeProviding>"8
@32@?0@8@"NSArray"16^@24
B16@?0@"<SNTimeRangeProviding>"8
@"NSArray"16@?0@"NSArray"8
error getting ring buffer bounds: %@
ring buffer sample rate is not integral: %@
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
v20@?0i8@"NSError"12
v56@?0{?={?=qiIq}{?=qiIq}}8
{?=qiIq}56@?0{?=qiIq}8{?=qiIq}32
-[SNAudioRecordingQueue init]
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
expected file url; got %@
cannot write without overwriting at path %@
com.apple.SoundAnalysis.AnalyzerQueue
v8@?0
Analyzer Requests (%@)
@"NSString"16@?0@"<SNRequest>"8
requests
@16@?0^@8
Results History (%p)
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
failed to reanchor
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
-[SNOptional init]
RPFTSource
v16@?0@"RPFileTransferProgress"8
could not allocate enough memory for serialized state
^{os_state_data_s=I(?=b32I){os_state_data_decoder_s=[64c][64c]}[64c][0C]}16@?0^{os_state_hints_s=I*II}8
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
bad expression type %@ (expected %@)
B24@?0@8^@16
expected number value
keypath %@ is not one of options
B24@?0@"NSString"8^@16
bad predicate type; requires NSComparisonPredicate
bad predicate operator type; got %@, expected one of %@
B24@?0Q8^@16
B24@?0@"NSExpression"8^@16
classifierIdentifier
-[SNClassifierVariant init]
cannot encode MLModel
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
-[SNSystemAudioAnalyzerLocal setAudioConfiguration:]
SNSystemAudioAnalyzerLocal.m
[_requests count] == 0
Failed to start system audio.
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B16@?0@8
not all items are serializable to plists
@24@?0@"<SNPlistSerializable>"8^@16
string could not be parsed as number: '%@'
no class exists with name: '%@'
B16@?0@"NSString"8
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
%@/distance_classifier.mlmodelc
category
mode
options
channelMap
useSiriAudioRouting
prefersNoMicrophoneUsageIndicator
prefersNoInterruptions
%@, %@, AVAudioSessionOptions: %lu, prefersNoMicrophoneUsageIndicator: %d, prefersNoInterruptions: %d, useSiriAudioRouting: %d, channelMap: %@
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Only single-channel audio is supported.
Bad number of dimensions on audio input shape.
Expected output batch size %d.
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
denylist
windowSize
hopSize
feedback_connections
inputFeature
-[SNModelFeatureConnection init]
@"NSDictionary"24@?0@"NSDictionary"8^@16
couldn't parse feedback connection; expected format 'source -> destination'; got: '%@'
@"SNModelFeatureConnection"24@?0@"NSString"8^@16
@"NSString"16@?0@"SNModelFeatureConnection"8
expected destination features to be unique; got %@
expected all source features to have affiliated outputs: source features = (%@); outputs = (%@)
expected all destination features to have affiliated inputs: destination features = (%@); inputs = (%@)
@"NSSet"24@?0@"NSString"8^@16
@"NSNumber"24@?0@"NSString"8^@16
@"NSString"24@?0@"NSString"8^@16
@"NSDictionary"24@?0@?<@"NSDictionary"@?@^@>8^@16
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
vector
-[SNPredicateFilterOperator init]
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
@"NSValue"16@?0@"NSValue"8
start time follows target time
time (%@) not in expected range (%@)
time range start and duration expected to have timescale %@
@"NSValue"16@?0@"NSNumber"8
@"NSValue"24@?0@"NSValue"8@"NSValue"16
@"NSValue"24@?0@"NSValue"8^@16
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected non-nil request
expected non-nil observer
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
yyyyMMdd'T'HHmmss'Z'
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss'Z'
input1
detectedHistoryIn
input_1
detectedHistoryOut
mlmodelc
output1
audioSamples
soundprint/Placeholder
Sigmoid
SNSoundPrint100kFireAlarmModel
thresholdedHistoryIn
thresholdedHistoryOut
classLabel
SNSoundClassifierVersion1Model
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintKEmbeddingModel
final_output
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel map (zero-indexed) %@ with result %d
Unsupported product type
Could register audio units. Returning nil for %@
Client rejected due to insufficient entitlements.
Removing %@, since it doesn't contain any detections
Try enable injection. Handler: %p; Success: %@; URL: %@
Disable injection. Handler: %p.
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer with In-Process Computation
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
Observer %@ for request %@ completed with error %@
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
SNDetectSoundRequest decoded (and rejected) a forbidden predicate
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Error analyzing audio buffer; unknown exception
Error analyzing audio buffer; generic exception: %s
Error analyzing audio buffer; DSPGraph exception %s (file: %s; function: %s; line: %@)
Error analyzing audio buffer; DSPGraph exception %s
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Failed to open audio file %@ with error %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Audio Running Heartbeat (%@); time changed from %@ to %@
Audio Heartbeat Reanchor (%@); time changed from %@ to %@
Audio Processed Heartbeat (%@); time changed from %@ to %@
Audio Processed Reanchor (%@); time changed from %@ to %@
%@ consecutive audio heartbeats detected unhealthy buffers. Error: %@.
Not enough funds to schedule audio buffer for processing! Queue Funds Spent: %@. Queue Funds Earned: %@. Buffer Length: %@. 
Queue already running
Failed to create audio queue
Starting audio queue
Error starting audio queue, %@
Stopping audio queue
Completed first pass for request %@ with error %@
Beginning second pass for request %@
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Collecting state information (title: %@)
Error capturing state! %@
Error preparing captured state! %@
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
Observer %@ for request %@ completed with error: %@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Starting audio input. %@, %@
Analyzer capable of injection (%p).
Failed to deactivate AVAudioSession with error %@
SNAudioRecordingQueue interrupted
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 feature
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
attempt to remove nil request
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNAudioQualityModel.mlmodelc in the bundle resource
SNSystemUtils
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNComposedDetector
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNFallingEdgeSmoother
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNNumberUtils
SNAtomicUtils
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNPlatformUtils
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNCollectionUtils
SNSpeechDistanceResult
SNUserDefaults
SNUltronReportOperator
SNOperator
SNDeleteFilesRequest
SNAudioBufferUtils
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNPlistSerializable
SNDetectEventUtils
SNMLModelCacheKey
SNAudioMultiArrayUtils
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNMultiArrayUtils
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNFeatureExtractorConfiguration
SNProcessorCreating
SNResultsXPCSubscriber
SNResultsObserving
SNRecordOperator
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotLabel
SNKShotFeaturizationStreamResult
SNKShotFeaturizationStreamCompletion
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNKShotSegment
SNKShotFeaturizer
SNFileListingResult
SNKeyValueMutation
SNKVOTrampoline
SNKeyValueUtils
SNSystemAudioAnalyzerRemote
SNResultsForwarder
SNObserverUtils
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNAudioFormatUtils
SNDiscoverFileServerRequest
SNUltronUtils
SNSoundDetectionUtils
SNValidateModel
SNDaemon
SNOperatorUtils
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNBooleanCancellable
SNCancellable
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
SNFileInjectOperator
DSPGMLInputProvider
MLFeatureProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNAudioFileUtils
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNObjectUtils
SNTwoPassConfiguration
SNHistoryUtils
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNFileUtils
SNAudioStreamAnalyzer
SNLogMelBasedFeatureExtractor
SNScheduleUtils
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNOptional
SNOptionalUtils
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNPredicateUtils
SNClassifierVariant
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNPlistUtils
SNStringUtils
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNDetectorHeadModelMetadata
SNModelFeatureConnection
SNModelMetadataUtils
SNPredicateFilterOperator
SNResultsXPCPublisher
SNTimeUtils
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNDateUtils
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrintASmokeAlarmModelInput
SNSoundPrintASmokeAlarmModelOutput
SNSoundPrintASmokeAlarmModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNAudioQualityModelInput
SNAudioQualityModelOutput
SNAudioQualityModel
Sigmoid
.cxx_destruct
T@"NSArray",R,C
CMTimeValue
T@"NSError",R,N
Detected
Tf,V_backgroundEnergyPercentile
T#,R
T{?=qiIq},V_inferenceWindowSize
T@"MLModelConfiguration",&,N,V_modelConfiguration
T@"MLModelDescription",R,V_modelDescription
_commandFilters
T@"MLMultiArray",&,N,V_Sigmoid
_format
T@"MLMultiArray",&,N,V_audioSamples
_input1
T@"MLMultiArray",&,N,V_detectedHistoryOut
_modelBlockSize
T@"MLMultiArray",&,N,V_framewiseEmbedding
_offset
T@"MLMultiArray",&,N,V_input_1
_processingTree
T@"MLMultiArray",&,N,V_soundprint_Placeholder
_recordOperator
T@"MLMultiArray",&,N,V_thresholdedHistoryIn
_resultsHandler
T@"MLMultiArray",&,V_data
_serverBasePath
T@"MLMultiArray",&,V_exemplarEmbedding
_streak
T@"NSArray",C,N,V_channelMap
_windowDuration
T@"NSArray",C,V_segments
allowEvaluation
T@"NSArray",C,V_trainingDataLabels
analyzeInRange:
T@"NSArray",C,V_validationDataLabels
arrayWithArray:
T@"NSArray",R,C,V_knownClassifications
availableInputs
T@"NSArray",R,N,V_spatialSpectrum
bundleForClass:
T@"NSArray",V_fileURLs
containsObject:
T@"NSDictionary",&,N,V_final_output
dateFromString:
T@"NSNumber",C,V_exemplarIndex
dictionaryValue
T@"NSNumber",C,V_sampleRate
initWithFormat:
T@"NSPredicate",C,N,V_resultsPredicate
initWithModel:dictionary:error:
T@"NSString",&,N,V_classLabel
initWithSoundprint_Placeholder:
T@"NSString",C,N,V_classifierIdentifier
input_1
T@"NSString",C,V_featureExtractorIdentifier
isEqualToArray:
T@"NSString",R
itemURL
T@"NSString",R,C,V_identifier
multiArrayValue
T@"NSString",R,N,V_identifier
numberWithBool:
T@"NSString",R,N,V_soundIdentifier
opaqueSessionID
T@"NSURL",R
output1
T@"SNKShotLabel",&,V_label
removeObserver:
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
rightExpression
T@"SNTwoPassConfiguration",R
T@?,C
setDatasetType:
T@?,C,V_endSecondPassHandler
setFrameLength:
TB,N,V_shouldThrowException
setUrl:
TB,R
soundIdentifier
TI,N,V_blockSize
stateIn
TI,R,D
stringByAppendingPathComponent:
TI,R,N,V_blockSize
stringFromDate:
TI,R,V_windowLengthFrames
TQ,R
valueWithRange:
.cxx_construct
T@"MLMultiArray",&,N,V_Detected
CMTimeRangeValue
T@"NSArray",R,N
Confidence
T^v,R,N
JSONObjectWithData:options:error:
Tf,V_foregroundEnergyPercentile
T@"MLModel",R,N,V_model
T@"MLModelDescription",R
_audioIsRunning
T@"MLMultiArray",&,N,V_Confidence
_errors
T@"MLMultiArray",&,N,V__637
_hopSizeSamples
T@"MLMultiArray",&,N,V_detectedHistoryIn
_labels
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
_object
T@"MLMultiArray",&,N,V_input1
_outputProvider
T@"MLMultiArray",&,N,V_output1
_processorCache
T@"MLMultiArray",&,N,V_stateIn
_recordingQueue
T@"MLMultiArray",&,N,V_thresholdedHistoryOut
_server
T@"MLMultiArray",&,V_exemplar
_stepSizeFrames
T@"MLMultiArray",R,N,V_featureVector
_streamAnalyzer
T@"NSArray",C,N,V_commands
allKeys
T@"NSArray",C,V_trainingDataEmbeddings
analyze
T@"NSArray",C,V_validationDataEmbeddings
arousal
T@"NSArray",R
audioBufferList
T@"NSArray",R,D,N
azimuth
T@"NSArray",R,V_enumeratedDurations
classifications
T@"NSDictionary",&,N,V__9
currentCalendar
T@"NSDictionary",R
dealloc
T@"NSNumber",C,V_hopSizeInSamples
initWithDouble:
T@"NSNumber",C,V_windowSizeInSamples
initWithInput1:
T@"NSSet",R,N
initWithModel:modelDescription:
T@"NSString",C,N,V_category
inputSampleRate
T@"NSString",C,N,V_mode
isAtEnd
T@"NSString",C,V_soundIdentifier
isProxy
T@"NSString",R,C
keyPath
T@"NSString",R,N
T@"NSString",R,N,V_name
numberWithLong:
T@"NSURL",C,V_url
options
T@"SNFileServerInfo",R
release
T@"SNTimeDurationConstraint",R,N
results
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
setCategory:mode:options:error:
T@?,C,V_beginSecondPassHandler
setDay:
TB,N,V_graphIsDeadEnded
setServiceType:
TB,N,V_useSiriAudioRouting
shapeConstraint
TB,R,N
spatialSpectrum
TI,R
strides
TI,R,N
stringByAppendingPathExtension:
TI,R,V_stepSizeFrames
uppercaseString
TQ,N,V_options
valence
T^{Box=},R,N
Td,N
Td,N,V_computationalDutyCycle
Td,N,V_confidence
Td,N,V_currentFrameValue
Td,N,V_magnitudeThreshold
Td,N,V_meanValue
Td,N,V_sampleRate
Td,N,V_standardDeviation
Td,R
Td,R,D
Td,R,N
Td,R,N,V_confidenceThreshold
Td,R,N,V_sampleRate
Td,R,V_confidence
Td,V_overlapFactor
Tf,N,V_overlapFactor
Tf,R,N
Tf,V_similarityThreshold
Tq,N,V_blocksBetweenTriggers
Tq,N,V_featurePrintType
Tq,N,V_hopSizeSamples
Tq,N,V_resultsPredicateLeakCount
Tq,R
Tq,R,N
Tq,R,N,V_completeCount
Tq,R,N,V_featurePrintType
Tq,R,N,V_minDurationBlocks
Tq,R,V_type
Tq,V_datasetType
T{?=qiIq},N,V_windowDuration
T{?=qiIq},R,N
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
T{?=qiIq},V_windowDuration
T{?={?=qiIq}{?=qiIq}},N
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
T{?={?=qiIq}{?=qiIq}},V_timeRange
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
T{shared_ptr<DSPGraph::Graph>=},R,N
URLByAppendingPathComponent:
URLByDeletingLastPathComponent
URLOfModelInThisBundle
UTF8String
_637
_Confidence
_Detected
_Sigmoid
__637
_activeProcessorsCache
_allInputFeatureNames
_analysisQueue
_analysisState
_analyzer
_analyzerHost
_analyzerInfos
_analyzerQueue
_aqCallbackScheduler
_arousal
_audioConfiguration
_audioFile
_audioQueue
_audioQueueConfiguration
_audioSamples
_audioSession
_azimuth
_backgroundEnergyPercentile
_beginSecondPassHandler
_blockSize
_blocksBetweenTriggers
_box
_boxName
_bufferHandler
_buildVersion
_busIndex
_cacheAccessRecency
_cacheStorage
_cachedClassifications
_category
_channelCount
_channelIndex
_channelMap
_classLabel
_classLabelsDenylist
_classificationDictionary
_classifier
_classifierIdentifier
_commands
_completeCount
_completionHandler
_composedDetector
_computationalDutyCycle
_confidence
_confidenceThreshold
_configuration
_configurationError
_configureAudioQueue
_configured
_connectionToServerGenerator
_coordinator
_createSecondPassControllerFunction
_creationFlags
_currentFormat
_currentFrameValue
_customModel
_data
_datasetType
_date
_decibelLevel
_destinationDirectory
_destinationFeatureName
_detected
_detectedHistoryIn
_detectedHistoryOut
_detectionResults
_detector
_detectorBoxName
_detectorHead
_detectorHeadModel
_detectorIdentifier
_detectorVariant
_dispatchQueue
_dominance
_dspItems
_durationRange
_elevation
_embeddings
_endSecondPassHandler
_enumeratedDurations
_error
_eventHandlerQueue
_eventHandlerQueueFundsEarned
_eventHandlerQueueFundsSpent
_eventHandlerQueueStopped
_exemplar
_exemplarEmbedding
_exemplarIndex
_featureCache
_featureDescription
_featureExtractor
_featureExtractorConfiguration
_featureExtractorIdentifier
_featureExtractorType
_featurePrintType
_featureVector
_feedbackConnections
_fileItems
_fileName
_fileServer
_fileSize
_fileURLs
_filename
_files
_final_output
_firstPassAnalyzer
_firstPassRecordingHistoryDuration
_firstPassRecordingPredicate
_firstPassRequest
_firstPassResultToComparableFunction
_firstPassResultsHistory
_firstPassUltronReportOps
_firstResultBelowEndThresholdStartTime
_fixedLengthEmbedding
_foregroundEnergyPercentile
_framesProcessed
_framewiseEmbedding
_generator
_graph
_graphIsDeadEnded
_hangoverDuration
_historicalDataAmount
_history
_hopSizeInSamples
_identifier
_idsDeviceID
_impl
_includePaths
_inferenceWindowSize
_input
_inputConstraint
_inputFeatureName
_inputFile
_inputProvider
_inputSensitivity
_input_1
_interpreter
_interruptionHandler
_isCancelled
_itemURL
_keyPath
_keys
_knownClassifications
_label
_lastAudioHeartbeatTime
_lastEventTime
_lastProcessingHeartbeatTime
_lastResult
_leakCount
_leakRemaining
_link
_listener
_localDestinationPath
_lock
_logMelExtractionParameters
_magnitudeThreshold
_maxCacheSize
_maxHistoryLength
_maximumObservableOffset
_meanValue
_minDurationBlocks
_minSegmentDuration
_minimumObservableOffset
_mlModel
_mode
_model
_modelConfiguration
_modelDescription
_modelOutput
_modelOutputFilter
_mood
_name
_observeValue
_observers
_offsetInInputFile
_options
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
_output1
_outputConfidenceFeatureName
_outputConstraint
_outputDetectedFeatureName
_outputFeatureName
_outputFile
_outputLabel
_outputShape
_overlapFactor
_overlapFilter
_path
_peakTime
_peakValue
_pendingInvalidationHandlers
_preProcessCallback
_predicate
_predicateFilter
_prefersNoInterruptions
_prefersNoMicrophoneUsageIndicator
_processingContexts
_queryPath
_queue
_receiver
_recordFormat
_referenceAudioFile
_referenceSampleRate
_registeredRequests
_remoteObservers
_request
_requestDescription
_requestState
_requestType
_requests
_resourcePath
_results
_resultsPredicate
_resultsPredicateLeakCount
_resultsToDiscardCount
_ringBuffer
_ringBufferWriteBufferList
_rootDirectory
_running
_sampleRate
_scratchFloatSpace
_secondPassAnalyzers
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassIsActive
_secondPassRequest
_secondPassResultToComparableFunction
_secondPassTriggerTime
_secondPassUltronReportOps
_segments
_serverFilePaths
_serverInfo
_session
_sharedProcessor
_shouldRebuildProcessingTree
_shouldThrowException
_similarityThreshold
_smoothingDuration
_soundIdentifier
_soundprint_Placeholder
_sourceFeatureName
_spatialSpectrum
_standardDeviation
_state
_stateIn
_subscriber
_substitutions
_sysdiagnoseHistoryDuration
_systemConfiguration
_taskCompletionMap
_text
_thresholdedHistoryIn
_thresholdedHistoryOut
_timeBetweenTriggers
_timeConverter
_timeRange
_trainingDataEmbeddings
_trainingDataLabels
_transaction
_tuningPrefix
_twoPassConfiguration
_type
_unhealthyBufferCount
_unregisterLogCollectHook
_url
_useSiriAudioRouting
_valence
_validationDataEmbeddings
_validationDataLabels
_value
_vendedModels
_wasCancelled
_windowDurationConstraint
_windowLengthFrames
_windowSizeInSamples
_wrappedModel
_xpcConnectionToServer
activate
activateWithCompletion:
adaptToSystemConfiguration:error:
addAudio:
addEntriesFromDictionary:
addItem:
addObject:
addObjectsFromArray:
addObserver:forKeyPath:options:context:
addObserver:selector:name:object:
addRequest:completionHandler:resultsHandler:
addRequest:completionHandler:resultsHandler:error:
addRequest:withObserver:error:
addRequestInBackground:withObserver:
allObjects
allValidDetectorIdentifiers
allValidSoundIdentifiers
allValues
allocWithZone:
analyzeAudioBuffer:atAudioFramePosition:
analyzeWithCompletionHandler:
anyObject
appendString:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObject:
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
attributesOfFileSystemForPath:error:
attributesOfItemAtPath:error:
audioSamples
automaticallyNotifiesObserversForKey:
autorelease
backgroundEnergyPercentile
beginSecondPassHandler
binarySampleRepresentation
blockSize
blocksBetweenTriggers
boolValue
bytes
cancel
cancelAnalysis
category
channelCount
channelIndex
channelLayout
channelMap
class
classLabel
classLabels
classificationForIdentifier:
classifierIdentifier
clearCompleteCount
clearErrors
clearResults
clientSampleRate
clientSampleTimeFromSampleTime:fromBox:
commands
commonFormat
compare:
compileModelAtURL:error:
completeAnalysis
completeCount
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
computationalDutyCycle
confidence
confidenceThreshold
configureNewAnalyzersToComputeInThisProcess:
conformsToProtocol:
constantValue
constraintWithShape:dataType:
contentsOfDirectoryAtPath:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createAnalyzerWithError:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createProcessorWithError:
createSecondPassController
createSystemAudioAnalyzer
createWithSampleRate:windowDuration:overlapFactor:error:
currentFrameValue
currentHandler
currentRunLoop
data
dataPointer
dataType
dataWithBytes:length:
dataWithContentsOfURL:options:error:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
datasetType
date
dateByAddingTimeInterval:
dateFromComponents:
debugDescription
decibelLevel
decisionDelay
decodeArrayOfObjectsOfClass:forKey:
decodeBoolForKey:
decodeCMTimeForKey:
decodeCMTimeRangeForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decoupledIO
defaultCenter
defaultManager
defaultWindowDuration
deregisterRequestID:
description
detected
detectedHistoryIn
detectedHistoryOut
detectorIdentifier
dictionary
dictionaryRepresentation
dictionaryWithCapacity:
dictionaryWithContentsOfFile:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didChangeValueForKey:
dominance
doubleValue
durationRange
edPKData
elevation
encodeBool:forKey:
encodeCMTime:forKey:
encodeCMTimeRange:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeWithCoder:
endAudio
endSecondPassHandler
endTimesFromTimeRangeCollection:
endpoint
enumerateKeysAndObjectsUsingBlock:
enumeratedDurations
enumeratedShapes
error
errorWithDomain:code:userInfo:
errors
evaluateWithObject:
exceptionWithName:reason:userInfo:
exemplar
exemplarEmbedding
exemplarIndex
expressionType
extractDefaultOutputFeatureFromFeatureProvider:
extractOutputWithOptionalName:fromFeatureProvider:
featureDescriptionWithName:type:optional:constraints:
featureExtractorConfigurationForIdentifier:detectorHeadModelMetadata:modelConfiguration:error:
featureExtractorIdentifier
featureNames
featurePrintType
featureValueForName:
featureValueWithDictionary:error:
featureValueWithMultiArray:
featureValueWithString:
featureVector
featuresAtIndex:
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
featurizeFiles:hallucinatorModelURL:queue:resultHandler:completionHandler:
fileExistsAtPath:
fileFormat
fileItems
fileName
fileSize
fileURLWithPath:
fileURLWithPath:isDirectory:
fileURLWithPathComponents:
fileURLs
filename
filterUsingPredicate:
final_output
finish
firstObject
firstPassDidProduceResult:
fixedLengthEmbedding
flags
floatChannelData
floatValue
foregroundEnergyPercentile
format
frameCapacity
frameLength
framePosition
framewiseEmbedding
getIdentitiesWithCompletion:
getLatestSuperVector
getResourceValue:forKey:error:
graph
graphIsDeadEnded
handleAVAudioSessionInterruption:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
handleAVAudioSessionRouteChange:
handleFailureInMethod:object:file:lineNumber:description:
hangoverDuration
hasPrefix:
hash
hopSizeInSamples
hopSizeSamples
identifier
idsDeviceID
idsDeviceIdentifier
indexOfObject:
indexOfObjectIdenticalTo:
inferenceWindowSize
init
initAsNegativeLabel
initAsPositiveLabel
initAuxiliarySession
initForReading:commonFormat:interleaved:error:
initForReading:error:
initForWriting:settings:commonFormat:interleaved:error:
initSecondaryReader:format:error:
initWithAudioConfiguration:
initWithAudioFile:
initWithAudioSamples:
initWithAudioTimeStamp:sampleRate:
initWithBinarySampleRepresentation:metadata:timestamp:
initWithBox:fromGraph:
initWithCapacity:
initWithClassificationDictionary:
initWithClassifierIdentifier:error:
initWithCoder:
initWithCommonFormat:sampleRate:interleaved:channelLayout:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
initWithConfiguration:
initWithConfiguration:error:
initWithContentsOfURL:configuration:error:
initWithContentsOfURL:error:
initWithDSPGraph:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithDetectorIdentifier:error:
initWithDetectorVariant:soundIdentifier:modelConfiguration:resultsPredicate:resultsPredicateLeakCount:
initWithDictionary:error:
initWithDictionary:resourcePath:
initWithDurationRange:
initWithEnumeratedDurations:
initWithFeaturePrintType:
initWithFeaturePrintType:featureVector:
initWithFeatureProviderArray:
initWithFiles:serverBasePath:serverInfo:
initWithFinal_output:classLabel:
initWithFixedLengthEmbedding:framewiseEmbedding:
initWithIdentifier:
initWithIdentifier:confidence:
initWithIdentifier:detectedValue:
initWithInput1:stateIn:detectedHistoryIn:
initWithInput1:stateIn:thresholdedHistoryIn:detectedHistoryIn:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
initWithInput_1:Confidence:Detected:detectedHistoryOut:
initWithInput_1:Confidence:Detected:thresholdedHistoryOut:detectedHistoryOut:
initWithLayoutTag:
initWithListenerEndpoint:
initWithLocaleIdentifier:
initWithMLModel:
initWithMLModel:error:
initWithMachServiceName:
initWithMachServiceName:options:
initWithModelClass:modelConfiguration:
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
initWithModelDescription:parameterDictionary:error:
initWithMood:valence:arousal:dominance:
initWithOutput1:
initWithOverlapFactor:error:
initWithPCMFormat:frameCapacity:
initWithRequestType:
initWithRootDirectory:
initWithSampleRate:windowDuration:overlapFactor:error:
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
initWithServerInfo:queryPath:
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
initWithShape:dataType:error:
initWithSigmoid:
initWithSmoothingDuration:
initWithSoundIdentifier:
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithStreamDescription:
initWithStreamDescription:channelLayout:
initWithSuiteName:
initWithTuningPrefix:
initWithURL:error:
initWithUnsignedInt:
initWithVGGishBasedMLModel:soundIdentifier:
initWith_637:
initWith_9:classLabel:
input1
inputDescriptionsByName
inputNumberOfChannels
insertObject:atIndex:
intValue
integerValue
interfaceWithProtocol:
intersectSet:
invalidate
isAllowedShape:error:
isEqual:
isEqualToString:
isEqualToTimeDurationConstraint:
isFileURL
isInterleaved
isKindOfClass:
isMemberOfClass:
isOptional
isSubsetOfSet:
knownClassifications
label
lastObject
launchTaskWithQueue:completionHandler:resultsHandler:
leftExpression
length
listener:shouldAcceptNewConnection:
loadContentsOfURL:configuration:completionHandler:
loadWithConfiguration:completionHandler:
localizedDescription
longLongValue
magnitudeThreshold
meanValue
metadata
minDurationBlocks
minSegmentDuration
minusOrderedSet:
minusSet:
mode
model
modelConfiguration
modelDescription
modelURLForCurrentProduct
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
mood
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
multiArrayConstraint
mutableAudioBufferList
mutableCopy
name
nonretainedObjectValue
null
numberFromMultiArrayDataElement:dataType:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observeValueForKeyPath:ofObject:change:context:
offset
orderedSetWithArray:
outputDescriptionsByName
outputFeatureSize
overlapFactor
path
pathComponents
pathExtension
pathForResource:ofType:
pathWithComponents:
peakTime
peakValue
performQuery:
performSegmentationRequest:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
plistFromFeaturizationResult:error:
plistRepresentationWithError:
portType
predicateOperatorType
predicateWithFormat:
predictedFeatureName
predictedProbabilitiesName
predictionFromAudioSamples:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionFromInput1:error:
predictionFromInput1:stateIn:detectedHistoryIn:error:
predictionFromInput1:stateIn:thresholdedHistoryIn:detectedHistoryIn:error:
predictionFromSoundprint_Placeholder:error:
predictionsFromBatch:options:error:
predictionsFromInputs:options:error:
prepareTemplateAndReturnError:
primeGraph
processInfo
processInput:portID:downstreamHandler:
processName
processTerminationWithOptionalError:portID:downstreamHandler:
processValue:time:
processingFormat
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
raise:format:
rangeValue
readIntoBuffer:error:
readIntoBuffer:frameCount:error:
registerRequestID:options:handler:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
removeAllObjects
removeAllRequests
removeItemAtPath:error:
removeItemAtURL:error:
removeLastObject
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObserver:forKeyPath:context:
removeRequest:
request:didFailWithError:
request:didProduceResult:
requestDidComplete:
resetForNewRequest
resourcePath
resourceURL
respondsToSelector:
resultsBox
resultsBoxName
resultsFromBox:renderedWithFrameCount:
resultsPredicate
resultsPredicateLeakCount
resume
retain
retainCount
reverseObjectEnumerator
sampleRate
sampleTime
saturatedIntegerFromNumber:
saturatedUnsignedIntegerFromNumber:
scanDouble:
scanLongLong:
scanUnsignedLongLong:
scannerWithString:
secondPassDidProduceResult:
segments
self
sendInputToUltronReporter:recentFramesOfAudioBuffer:startingFromTime:error:
sendRequestID:request:destinationID:options:responseHandler:
serverInfo
setActive:error:
setAudioConfiguration:
setAudioSamples:
setBackgroundEnergyPercentile:
setBeginSecondPassHandler:
setBlockSize:
setBlocksBetweenTriggers:
setCategory:
setChannelMap:
setClassLabel:
setClasses:forSelector:argumentIndex:ofReply:
setClassifierIdentifier:
setCommands:
setCompletionHandler:
setComputationalDutyCycle:
setConfidence:
setCurrentFrameValue:
setData:
setDateFormat:
setDelegate:
setDestinationID:
setDetected:
setDetectedHistoryIn:
setDetectedHistoryOut:
setDeviceChangedHandler:
setDeviceFoundHandler:
setDeviceLostHandler:
setDispatchQueue:
setEndSecondPassHandler:
setExemplar:
setExemplarEmbedding:
setExemplarIndex:
setExportedInterface:
setExportedObject:
setFeatureExtractorIdentifier:
setFeaturePrintType:
setFileURLs:
setFilename:
setFinal_output:
setFixedLengthEmbedding:
setFlags:
setForegroundEnergyPercentile:
setFramePosition:
setFramewiseEmbedding:
setGraphIsDeadEnded:
setHangoverDuration:
setHopSizeInSamples:
setHopSizeSamples:
setHour:
setInferenceWindowSize:
setInput1:
setInput_1:
setInterface:forSelector:argumentIndex:ofReply:
setInterruptionHandler:
setInvalidationHandler:
setItemURL:
setLabel:
setLocalDeviceUpdatedHandler:
setLocale:
setMagnitudeThreshold:
setMeanValue:
setMinSegmentDuration:
setMinute:
setMode:
setModelConfiguration:
setMonth:
setNanosecond:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setOptions:
setOutput1:
setOverlapFactor:
setPath:
setPeerPublicKey:
setProgressHandler:
setReceivedItemHandler:
setRemoteObjectInterface:
setResultsPredicate:
setResultsPredicate:error:
setResultsPredicateLeakCount:
setRootDirectoryURL:
setSampleRate:
setSecond:
setSegments:
setShouldThrowException:
setSigmoid:
setSimilarityThreshold:
setSoundIdentifier:
setSoundprint_Placeholder:
setStandardDeviation:
setStateIn:
setTargetID:
setTemporaryDirectoryURL:
setThresholdedHistoryIn:
setThresholdedHistoryOut:
setTimeRange:
setTimeZone:
setTrainingDataEmbeddings:
setTrainingDataLabels:
setUseSiriAudioRouting:
setValidationDataEmbeddings:
setValidationDataLabels:
setValue:forKey:
setValue:forKeyPath:
setWindowDuration:
setWindowSizeInSamples:
setWithArray:
setWithObject:
setWithSet:
setYear:
set_637:
set_9:
settings
shape
sharedProcessorConfiguration
shouldLogRequests
shouldLogResultsHistory
shouldThrowException
similarityThreshold
sizeRangeForDimension
sleepForTimeInterval:
sliceAtOrigin:shape:squeeze:error:
sortUsingComparator:
sortedArrayUsingComparator:
soundprint_Placeholder
standardDeviation
start
state
stepSizeFrames
stepSizeFramesForWindowLengthFrames:overlapFactor:minimumStepSize:roundingDownToNearestMultipleOf:
stop
streamDescription
string
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringValue
stringWithFormat:
stringWithUTF8String:
strongToWeakObjectsMapTable
subarrayWithRange:
substringFromIndex:
substringToIndex:
superclass
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
thresholdedHistoryIn
thresholdedHistoryOut
timeConversionDictionary
timeRange
timeWithSampleTime:atRate:
timeZoneWithName:
trainingDataEmbeddings
trainingDataLabels
twoPassConfiguration
type
unarchivedArrayOfObjectsOfClass:fromData:error:
unarchivedObjectOfClass:fromData:error:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
updateProcessingTreeFormat:
useSiriAudioRouting
validationDataEmbeddings
validationDataLabels
valueForEntitlement:
valueForKey:
valueForKeyPath:
valueWithCMTime:
valueWithCMTimeRange:
valueWithNonretainedObject:
valueWithPointer:
whitespaceAndNewlineCharacterSet
willChangeValueForKey:
windowDuration
windowDurationConstraint
windowLengthFrames
windowSizeInSamples
writeFromBuffer:error:
writeToURL:options:error:
xpcAddRequest:withObserver:completionHandler:
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcRemoveRequest:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequest:didProduceResult:completionHandler:
xpcRequestDidComplete:completionHandler:
xpcSetAudioConfiguration:completionHandler:
zone
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v16@0:8
@"NSString"
@"MLModel"
@"SNComposedDetector"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@48@0:8d16d24d32d40
@40@0:8{?=qiIq}16
B44@0:8B16{?=qiIq}20
{?="value"q"timescale"i"flags"I"epoch"q}
@"NSValue"
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
v20@0:8f16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
q16@0:8
v24@0:8q16
@"SNTimeDurationConstraint"
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
@"NSError"
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8I16
@"SNDetectSignalThresholdRequestImpl"
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@"NSXPCConnection"
@"NSMutableArray"
v40@0:8@16@"NSString"24@?<v@?@"NSString"@@"NSError">32
v40@0:8@"NSError"16@"NSString"24@?<v@?@"NSString"@@"NSError">32
@"SNRecordOperator"
@"NSURL"
@"NSDate"
@40@0:8@16@24@32
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"SNDetectorHeadConfiguration"
@"SNPredicateFilterOperator"
v24@0:8@?16
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
@28@0:8@16B24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@"SNTwoPassConfiguration"
@32@0:8@16@24
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@16@24
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"AVAudioFormat"
v20@0:8B16
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"SNKShotLabel"
@"NSNumber"
@48@0:8@16@24@32@?40
@56@0:8@16@24@32@?40@?48
@32@0:8@16^@24
v48@0:8@16@24@32^v40
@"SNAudioConfiguration"
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@"SNVoiceTriggerResult"
@"NSSet"
@"SNClassifierVariant"
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@56@0:8@16@24@32@40q48
@"SNDetectorVariant"
@"MLModelConfiguration"
@"NSPredicate"
B64@0:8@16^v24{?=qiIq}32^@56
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[32C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@48@0:8@16@24@32@40
@"<SNRequest>"
@"NSObject<OS_os_transaction>"
@"SNAudioQueueConfiguration"
@"AVAudioSession"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
B48@0:8@16@?24@?32^@40
v32@0:8@16q24
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
@"SNNullDetector"
@"SNAudioRecordingQueue"
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
@32@0:8@16d24
v24@0:8Q16
@?16@0:8
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
@56@0:8@16@24@32@40@48
@56@0:8@16@24@32@40^@48
@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
?St13runtime_error
N8DSPGraph9ExceptionE
St9exception
St12length_error
St11logic_error
mcpl)
cmcp!
St20bad_array_new_length
St9bad_alloc
@xfuapraexoba
mron
xfuapargxoba
MbP?St12out_of_range
NSt3__117bad_function_callE
cmcp!
cmcp!
mcpl,
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
xfuadgisxoba
xfuaftmlxoba
got no answer for question %@
BuildVersion
timeRange
decibelLevel
type
detectorIdentifier
composedDetector
illegal call to unavailable init selector: %s
-[SNComposedDetector init]
cannot deserialized MLModel
cannot serialize MLModel
cannot copy MLModel
-[SNDetectorVariant init]
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
-[SNFallingEdgeSmoother init]
illegal call to unavailable new selector: %s
+[SNFallingEdgeSmoother new]
tuningPrefix
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/b1b7133b-aed3-11ed-bf78-863efbbaf80d/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.4.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
doa.dspg
PropertyStrip
doa.propstrip
AUStrip
doa.austrip
Failed to create graph
basic_string
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
vector
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
expected double; got %@
expected unsigned integer; got %@
expected int32; got %@
expected uint32; got %@
expected positive number; got %@
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
q16@?0q8
v8@?0
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v24@?0^{OpaqueAudioQueue=}8@"AVAudioSession"16
/Library/Audio/Tunings
SoundAnalysis
Applause
SNVGGishApplauseModel
Babble
SNVGGishBabbleModel
Cheering
SNVGGishCheeringModel
Laughter
SNVGGishLaughterModel
Music
SNVGGishMusicModel
Speech
SNVGGishSpeechModel
Distressed Baby
SNVGGishDistressedBabyModel
Smoke Alarm
SNVGGishSmokeAlarmModel
Fire Alarm
SNVGGishFireAlarmModel
Doorbell
SNVGGishDoorbellModel
Buzzer
SNVGGishBuzzerModel
Beep
SNVGGishBeepModel
Ding Bell
SNVGGishDingBellModel
Dog Bark
SNVGGishDogBarkModel
Cat Meow
SNVGGishCatMeowModel
Door Knock
SNVGGishDoorKnockModel
Shouting
SNVGGishShoutingModel
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNSoundPrintASmokeAlarmModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
SNAudioQualityModel
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
elevation
spatialSpectrum
%@ azmimuth: %f elevation: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
com.apple.SoundAnalysis.AllAnalysisRequests
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
v8@?0
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
@32@?0@8@16^@24
@24@?0@8^@16
multiple keys mapping to the same value: %@
B32@?0@8@16^@24
B24@?0@8@16
@"NSArray"16@?0@8
B16@?0@8
@"NSNumber"24@?0@"NSNumber"8@16
@"<NSFastEnumeration>"24@?0@8^@16
@"NSDictionary"24@?0@8^@16
@"NSDictionary"16@?0@"<NSCopying>"8
bad collection; contains `nil`
@8@?0
@24@?0@8@16
q24@?0@"NSNumber"8@"NSNumber"16
partition size may not be 0
failed to divide into partitions of size %@; remainder %@
@16@?0@8
@"NSArray"32@?0@"<NSFastEnumeration>"8@"NSNumber"16^@24
@16@?0@"NSArray"8
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
mic_injection_file_path
sysdiagnose_historical_duration
daemon_recording_path
delete_recordings_without_detection
first_pass_recording_predicate
first_pass_recording_history_duration
enable_second_pass_recording_in_daemon
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
microphone_array_channel_map
@"NSNumber"24@?0@8^@16
Library
Caches
AudioCaptures
default
audio
results
-[SNUltronReportOperator init]
unrecognized input port ID: %@
v32@?0@"NSString"8@16@"NSError"24
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
expected non-silent audio buffer
expected no NaN-valued audio samples
expected no infinite audio samples
v32@?0@"NSString"8@"AVAudioPCMBuffer"16@"NSError"24
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
v32@?0@"NSString"8@"<SNResult>"16@"NSError"24
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
Unsupported dimension count
%@ detected: %@
Expected multi array to have standard strides
Expected count to be non-negative
Expected new dimension count to be at least as large as original
SNMultiArrayUtils.mm
unsupported data type %@
IncludePaths
Substitutions
Value
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
-[SNRecordOperator init]
v16@?0^@8
failed to record audio to file
com.apple.SoundAnalysis.remoteanalyzer
all_data
label
dataset
embedding
inference_window_size
exemplar
negative
positive
training
validation
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
-[SNKShotLabel init]
+[SNKShotLabel new]
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
v16@?0@"SNKShotFeaturizationStreamResult"8
v24@?0@"SNKShotFeaturizationStreamCompletion"8@"NSError"16
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
Not enough audio segments found to continue.
v32@?0@"NSNumber"8@"MLMultiArray"16q24
v24@?0@"NSNumber"8@"MLMultiArray"16
B8@?0
MLModelCreatorDefinedKey
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
could not translate number to label: %@
expected same number of embeddings and labels
@"SNKShotFeaturizationStreamResult"32@?0@"MLMultiArray"8@"NSNumber"16^@24
unrecognized label type: %@
unrecognized dataset type: %@
@"NSDictionary"24@?0@"SNKShotFeaturizationStreamResult"8^@16
-[SNKeyValueMutation init]
unrecognized mutation type
key to be added already exists (%@)
v24@?0@8@16
required key missing from dictionary: %@
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
v24@?0@"<SNRequest>"8@"NSError"16
SNSystemAudioAnalyzerRemote.m
request
observer
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
-[SNResultsForwarder init]
v24@?0@"<SNRequest>"8@"<SNResult>"16
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
unrecognized classifier type
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
resultsPredicate
resultsPredicateLeakCount
Couldn't find soundIdentifier for detectorIdentifier %@
<Unknown Sound>
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
graph
Audio format must be PCM
Audio format channel count and sample rate must be nonzero
InvalidFormatException
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
@"NSObject<SNTimeRangeProvidingWritable>"16@?0@"NSObject<SNTimeRangeProvidingWritable>"8
%@_%@
@"NSString"16@?0@"SNDetectionResult"8
@"NSNumber"16@?0@"SNDetectionResult"8
timestamp
@"NSDictionary"16@?0@"NSArray"8
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
could not query build version and recording path
SNSoundDetectionUtils.mm
minimumStepSize <= windowLengthFrames
minimumStepSize % factor == 0
no supported feature extractor for detector variant
@"<SNFeatureExtractorConfiguration>"24@?0@"MLModel"8@"SNDetectorHeadModelMetadata"16
cannot create feature extractor config for identifier: %@
[identifier isEqual:detectorHeadModelMetadata.featureExtractorIdentifier]
expected feature extractor in detector head model metadata
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
v32@?0@"NSString"8@16@"NSError"24
expected termination or input but got both: input %@, error %@
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
#24@?0@"NSString"8^@16
could not derive tagged model classes from tags
unsupported feature extractor: %@
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
DSPGraph ABI runtime/compile-time mismatch
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
SNUtils.mm
Expected only one user-supplied input feature; got: %@
MultiArrayInput
MultiArrayOutput
soundanalysisd
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
VerifyNotTrashingOwnedBuffer
CABufferList.h
mBufferMemory == NULL
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"NSString"8@?0
-[SNFileInjectOperator init]
B24@?0@"AVAudioPCMBuffer"8^@16
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
buffer populator produced excess frames: %@
did not process all frames; remaining %@
failed to make buffer with format %@, capacity %@
@"AVAudioPCMBuffer"16@?0^@8
B28@?0@"AVAudioPCMBuffer"8I16^@20
B16@?0@"NSValue"8
used bad buffer populator
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
expected object %@ of class %@ to be one of %@
expected object %@ of class %@ to be kind of %@
@"NSValue"16@?0@"<SNTimeRangeProviding>"8
@32@?0@8@"NSArray"16^@24
B16@?0@"<SNTimeRangeProviding>"8
@"NSArray"16@?0@"NSArray"8
error getting ring buffer bounds: %@
ring buffer sample rate is not integral: %@
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
v20@?0i8@"NSError"12
v56@?0{?={?=qiIq}{?=qiIq}}8
{?=qiIq}56@?0{?=qiIq}8{?=qiIq}32
-[SNAudioRecordingQueue init]
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
expected file url; got %@
cannot write without overwriting at path %@
com.apple.SoundAnalysis.AnalyzerQueue
v8@?0
Analyzer Requests (%@)
@"NSString"16@?0@"<SNRequest>"8
requests
@16@?0^@8
Results History (%p)
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
failed to reanchor
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
-[SNOptional init]
RPFTSource
v16@?0@"RPFileTransferProgress"8
could not allocate enough memory for serialized state
^{os_state_data_s=I(?=b32I){os_state_data_decoder_s=[64c][64c]}[64c][0C]}16@?0^{os_state_hints_s=I*II}8
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
bad expression type %@ (expected %@)
B24@?0@8^@16
expected number value
keypath %@ is not one of options
B24@?0@"NSString"8^@16
bad predicate type; requires NSComparisonPredicate
bad predicate operator type; got %@, expected one of %@
B24@?0Q8^@16
B24@?0@"NSExpression"8^@16
classifierIdentifier
-[SNClassifierVariant init]
cannot encode MLModel
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
-[SNSystemAudioAnalyzerLocal setAudioConfiguration:]
SNSystemAudioAnalyzerLocal.m
[_requests count] == 0
Failed to start system audio.
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B16@?0@8
not all items are serializable to plists
@24@?0@"<SNPlistSerializable>"8^@16
string could not be parsed as number: '%@'
no class exists with name: '%@'
B16@?0@"NSString"8
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
%@/distance_classifier.mlmodelc
category
mode
options
channelMap
useSiriAudioRouting
prefersNoMicrophoneUsageIndicator
prefersNoInterruptions
%@, %@, AVAudioSessionOptions: %lu, prefersNoMicrophoneUsageIndicator: %d, prefersNoInterruptions: %d, useSiriAudioRouting: %d, channelMap: %@
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Only single-channel audio is supported.
Bad number of dimensions on audio input shape.
Expected output batch size %d.
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
denylist
windowSize
hopSize
feedback_connections
inputFeature
-[SNModelFeatureConnection init]
@"NSDictionary"24@?0@"NSDictionary"8^@16
couldn't parse feedback connection; expected format 'source -> destination'; got: '%@'
@"SNModelFeatureConnection"24@?0@"NSString"8^@16
@"NSString"16@?0@"SNModelFeatureConnection"8
expected destination features to be unique; got %@
expected all source features to have affiliated outputs: source features = (%@); outputs = (%@)
expected all destination features to have affiliated inputs: destination features = (%@); inputs = (%@)
@"NSSet"24@?0@"NSString"8^@16
@"NSNumber"24@?0@"NSString"8^@16
@"NSString"24@?0@"NSString"8^@16
@"NSDictionary"24@?0@?<@"NSDictionary"@?@^@>8^@16
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
vector
-[SNPredicateFilterOperator init]
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
@"NSValue"16@?0@"NSValue"8
start time follows target time
time (%@) not in expected range (%@)
time range start and duration expected to have timescale %@
@"NSValue"16@?0@"NSNumber"8
@"NSValue"24@?0@"NSValue"8@"NSValue"16
@"NSValue"24@?0@"NSValue"8^@16
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected non-nil request
expected non-nil observer
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
yyyyMMdd'T'HHmmss'Z'
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss'Z'
input1
detectedHistoryIn
input_1
detectedHistoryOut
mlmodelc
output1
audioSamples
soundprint/Placeholder
Sigmoid
SNSoundPrint100kFireAlarmModel
thresholdedHistoryIn
thresholdedHistoryOut
classLabel
SNSoundClassifierVersion1Model
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintKEmbeddingModel
final_output
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel map (zero-indexed) %@ with result %d
Unsupported product type
Could register audio units. Returning nil for %@
Client rejected due to insufficient entitlements.
Removing %@, since it doesn't contain any detections
Try enable injection. Handler: %p; Success: %@; URL: %@
Disable injection. Handler: %p.
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer with In-Process Computation
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
Observer %@ for request %@ completed with error %@
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
SNDetectSoundRequest decoded (and rejected) a forbidden predicate
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Error analyzing audio buffer; unknown exception
Error analyzing audio buffer; generic exception: %s
Error analyzing audio buffer; DSPGraph exception %s (file: %s; function: %s; line: %@)
Error analyzing audio buffer; DSPGraph exception %s
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Failed to open audio file %@ with error %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Audio Running Heartbeat (%@); time changed from %@ to %@
Audio Heartbeat Reanchor (%@); time changed from %@ to %@
Audio Processed Heartbeat (%@); time changed from %@ to %@
Audio Processed Reanchor (%@); time changed from %@ to %@
%@ consecutive audio heartbeats detected unhealthy buffers. Error: %@.
Not enough funds to schedule audio buffer for processing! Queue Funds Spent: %@. Queue Funds Earned: %@. Buffer Length: %@. 
Queue already running
Failed to create audio queue
Starting audio queue
Error starting audio queue, %@
Stopping audio queue
Completed first pass for request %@ with error %@
Beginning second pass for request %@
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Collecting state information (title: %@)
Error capturing state! %@
Error preparing captured state! %@
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
Observer %@ for request %@ completed with error: %@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Starting audio input. %@, %@
Analyzer capable of injection (%p).
Failed to deactivate AVAudioSession with error %@
SNAudioRecordingQueue interrupted
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 feature
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
attempt to remove nil request
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNAudioQualityModel.mlmodelc in the bundle resource
SNSystemUtils
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNComposedDetector
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNFallingEdgeSmoother
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNNumberUtils
SNAtomicUtils
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNPlatformUtils
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNCollectionUtils
SNSpeechDistanceResult
SNUserDefaults
SNUltronReportOperator
SNOperator
SNDeleteFilesRequest
SNAudioBufferUtils
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNPlistSerializable
SNDetectEventUtils
SNMLModelCacheKey
SNAudioMultiArrayUtils
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNMultiArrayUtils
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNFeatureExtractorConfiguration
SNProcessorCreating
SNResultsXPCSubscriber
SNResultsObserving
SNRecordOperator
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotLabel
SNKShotFeaturizationStreamResult
SNKShotFeaturizationStreamCompletion
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNKShotSegment
SNKShotFeaturizer
SNFileListingResult
SNKeyValueMutation
SNKVOTrampoline
SNKeyValueUtils
SNSystemAudioAnalyzerRemote
SNResultsForwarder
SNObserverUtils
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNAudioFormatUtils
SNDiscoverFileServerRequest
SNUltronUtils
SNSoundDetectionUtils
SNValidateModel
SNDaemon
SNOperatorUtils
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNBooleanCancellable
SNCancellable
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
SNFileInjectOperator
DSPGMLInputProvider
MLFeatureProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNAudioFileUtils
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNObjectUtils
SNTwoPassConfiguration
SNHistoryUtils
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNFileUtils
SNAudioStreamAnalyzer
SNLogMelBasedFeatureExtractor
SNScheduleUtils
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNOptional
SNOptionalUtils
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNPredicateUtils
SNClassifierVariant
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNPlistUtils
SNStringUtils
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNDetectorHeadModelMetadata
SNModelFeatureConnection
SNModelMetadataUtils
SNPredicateFilterOperator
SNResultsXPCPublisher
SNTimeUtils
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNDateUtils
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrintASmokeAlarmModelInput
SNSoundPrintASmokeAlarmModelOutput
SNSoundPrintASmokeAlarmModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNAudioQualityModelInput
SNAudioQualityModelOutput
SNAudioQualityModel
Sigmoid
.cxx_destruct
T@"NSArray",R,C
CMTimeValue
T@"NSError",R,N
Detected
Tf,V_backgroundEnergyPercentile
T@"MLModel",R,N,V_model
T{?=qiIq},V_inferenceWindowSize
T@"MLModelDescription",R
T@"MLMultiArray",&,N,V_Confidence
_commandFilters
T@"MLMultiArray",&,N,V__637
_format
T@"MLMultiArray",&,N,V_detectedHistoryIn
_input1
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
_modelBlockSize
T@"MLMultiArray",&,N,V_input1
_offset
T@"MLMultiArray",&,N,V_output1
_processingTree
T@"MLMultiArray",&,N,V_stateIn
_recordOperator
T@"MLMultiArray",&,N,V_thresholdedHistoryOut
_resultsHandler
T@"MLMultiArray",&,V_exemplar
_serverBasePath
T@"MLMultiArray",R,N,V_featureVector
_streak
T@"NSArray",C,N,V_commands
_windowDuration
T@"NSArray",C,V_trainingDataEmbeddings
allowEvaluation
T@"NSArray",C,V_validationDataEmbeddings
analyzeInRange:
T@"NSArray",R
arrayWithArray:
T@"NSArray",R,D,N
availableInputs
T@"NSArray",R,V_enumeratedDurations
bundleForClass:
T@"NSDictionary",&,N,V__9
containsObject:
T@"NSDictionary",R
dictionaryValue
T@"NSNumber",C,V_hopSizeInSamples
initWithFormat:
T@"NSNumber",C,V_windowSizeInSamples
initWithModel:dictionary:error:
T@"NSSet",R,N
initWithSoundprint_Placeholder:
T@"NSString",C,N,V_category
input_1
T@"NSString",C,N,V_mode
isEqualToArray:
T@"NSString",C,V_soundIdentifier
itemURL
T@"NSString",R,C
multiArrayValue
T@"NSString",R,N
numberWithBool:
T@"NSString",R,N,V_name
opaqueSessionID
T@"NSURL",C,V_url
output1
T@"SNFileServerInfo",R
removeObserver:
T@"SNTimeDurationConstraint",R,N
rightExpression
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
setDatasetType:
T@?,C,V_beginSecondPassHandler
setServiceType:
TB,N,V_graphIsDeadEnded
shapeConstraint
TB,N,V_useSiriAudioRouting
spatialSpectrum
TB,R,N
strides
TI,R
stringByAppendingPathExtension:
TI,R,N
uppercaseString
TI,R,V_stepSizeFrames
valence
TQ,N,V_options
.cxx_construct
T@"MLMultiArray",&,N,V_Detected
CMTimeRangeValue
T@"NSArray",R,N
Confidence
T^v,R,N
T#,R
Tf,V_foregroundEnergyPercentile
T@"MLModelConfiguration",&,N,V_modelConfiguration
T@"MLModelDescription",R,V_modelDescription
_audioIsRunning
T@"MLMultiArray",&,N,V_Sigmoid
_errors
T@"MLMultiArray",&,N,V_audioSamples
_hopSizeSamples
T@"MLMultiArray",&,N,V_detectedHistoryOut
_labels
T@"MLMultiArray",&,N,V_framewiseEmbedding
_object
T@"MLMultiArray",&,N,V_input_1
_outputProvider
T@"MLMultiArray",&,N,V_soundprint_Placeholder
_processorCache
T@"MLMultiArray",&,N,V_thresholdedHistoryIn
_recordingQueue
T@"MLMultiArray",&,V_data
_server
T@"MLMultiArray",&,V_exemplarEmbedding
_stepSizeFrames
T@"NSArray",C,N,V_channelMap
_streamAnalyzer
T@"NSArray",C,V_segments
allKeys
T@"NSArray",C,V_trainingDataLabels
analyze
T@"NSArray",C,V_validationDataLabels
arousal
T@"NSArray",R,C,V_knownClassifications
audioBufferList
T@"NSArray",R,N,V_spatialSpectrum
azimuth
T@"NSArray",V_fileURLs
classifications
T@"NSDictionary",&,N,V_final_output
dealloc
T@"NSNumber",C,V_exemplarIndex
initWithDouble:
T@"NSNumber",C,V_sampleRate
initWithInput1:
T@"NSPredicate",C,N,V_resultsPredicate
initWithModel:modelDescription:
T@"NSString",&,N,V_classLabel
inputSampleRate
T@"NSString",C,N,V_classifierIdentifier
isAtEnd
T@"NSString",C,V_featureExtractorIdentifier
isProxy
T@"NSString",R
keyPath
T@"NSString",R,C,V_identifier
T@"NSString",R,N,V_identifier
numberWithLong:
T@"NSString",R,N,V_soundIdentifier
options
T@"NSURL",R
release
T@"SNKShotLabel",&,V_label
results
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
T@"SNTwoPassConfiguration",R
setCategory:mode:options:error:
T@?,C
setFrameLength:
T@?,C,V_endSecondPassHandler
setUrl:
TB,N,V_shouldThrowException
soundIdentifier
TB,R
stateIn
TI,N,V_blockSize
stringByAppendingPathComponent:
TI,R,D
stringFromDate:
TI,R,N,V_blockSize
TI,R,V_windowLengthFrames
valueWithRange:
TQ,R
T^{Box=},R,N
Td,N
Td,N,V_computationalDutyCycle
Td,N,V_confidence
Td,N,V_currentFrameValue
Td,N,V_magnitudeThreshold
Td,N,V_meanValue
Td,N,V_sampleRate
Td,N,V_standardDeviation
Td,R
Td,R,D
Td,R,N
Td,R,N,V_confidenceThreshold
Td,R,N,V_sampleRate
Td,R,V_confidence
Td,V_overlapFactor
Tf,N,V_overlapFactor
Tf,R,N
Tf,V_similarityThreshold
Tq,N,V_blocksBetweenTriggers
Tq,N,V_featurePrintType
Tq,N,V_hopSizeSamples
Tq,N,V_resultsPredicateLeakCount
Tq,R
Tq,R,N
Tq,R,N,V_completeCount
Tq,R,N,V_featurePrintType
Tq,R,N,V_minDurationBlocks
Tq,R,V_type
Tq,V_datasetType
T{?=qiIq},N,V_windowDuration
T{?=qiIq},R,N
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
T{?=qiIq},V_windowDuration
T{?={?=qiIq}{?=qiIq}},N
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
T{?={?=qiIq}{?=qiIq}},V_timeRange
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
T{shared_ptr<DSPGraph::Graph>=},R,N
URLByAppendingPathComponent:
URLByDeletingLastPathComponent
URLOfModelInThisBundle
UTF8String
_637
_Confidence
_Detected
_Sigmoid
__637
_activeProcessorsCache
_allInputFeatureNames
_analysisQueue
_analysisState
_analyzer
_analyzerHost
_analyzerInfos
_analyzerQueue
_aqCallbackScheduler
_arousal
_audioConfiguration
_audioFile
_audioQueue
_audioQueueConfiguration
_audioSamples
_audioSession
_azimuth
_backgroundEnergyPercentile
_beginSecondPassHandler
_blockSize
_blocksBetweenTriggers
_box
_boxName
_bufferHandler
_buildVersion
_busIndex
_cacheAccessRecency
_cacheStorage
_cachedClassifications
_category
_channelCount
_channelIndex
_channelMap
_classLabel
_classLabelsDenylist
_classificationDictionary
_classifier
_classifierIdentifier
_commands
_completeCount
_completionHandler
_composedDetector
_computationalDutyCycle
_confidence
_confidenceThreshold
_configuration
_configurationError
_configureAudioQueue
_configured
_connectionToServerGenerator
_coordinator
_createSecondPassControllerFunction
_creationFlags
_currentFormat
_currentFrameValue
_customModel
_data
_datasetType
_date
_decibelLevel
_destinationDirectory
_destinationFeatureName
_detected
_detectedHistoryIn
_detectedHistoryOut
_detectionResults
_detector
_detectorBoxName
_detectorHead
_detectorHeadModel
_detectorIdentifier
_detectorVariant
_dispatchQueue
_dominance
_dspItems
_durationRange
_elevation
_embeddings
_endSecondPassHandler
_enumeratedDurations
_error
_eventHandlerQueue
_eventHandlerQueueFundsEarned
_eventHandlerQueueFundsSpent
_eventHandlerQueueStopped
_exemplar
_exemplarEmbedding
_exemplarIndex
_featureCache
_featureDescription
_featureExtractor
_featureExtractorConfiguration
_featureExtractorIdentifier
_featureExtractorType
_featurePrintType
_featureVector
_feedbackConnections
_fileItems
_fileName
_fileServer
_fileSize
_fileURLs
_filename
_files
_final_output
_firstPassAnalyzer
_firstPassRecordingHistoryDuration
_firstPassRecordingPredicate
_firstPassRequest
_firstPassResultToComparableFunction
_firstPassResultsHistory
_firstPassUltronReportOps
_firstResultBelowEndThresholdStartTime
_fixedLengthEmbedding
_foregroundEnergyPercentile
_framesProcessed
_framewiseEmbedding
_generator
_graph
_graphIsDeadEnded
_hangoverDuration
_historicalDataAmount
_history
_hopSizeInSamples
_identifier
_idsDeviceID
_impl
_includePaths
_inferenceWindowSize
_input
_inputConstraint
_inputFeatureName
_inputFile
_inputProvider
_inputSensitivity
_input_1
_interpreter
_interruptionHandler
_isCancelled
_itemURL
_keyPath
_keys
_knownClassifications
_label
_lastAudioHeartbeatTime
_lastEventTime
_lastProcessingHeartbeatTime
_lastResult
_leakCount
_leakRemaining
_link
_listener
_localDestinationPath
_lock
_logMelExtractionParameters
_magnitudeThreshold
_maxCacheSize
_maxHistoryLength
_maximumObservableOffset
_meanValue
_minDurationBlocks
_minSegmentDuration
_minimumObservableOffset
_mlModel
_mode
_model
_modelConfiguration
_modelDescription
_modelOutput
_modelOutputFilter
_mood
_name
_observeValue
_observers
_offsetInInputFile
_options
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
_output1
_outputConfidenceFeatureName
_outputConstraint
_outputDetectedFeatureName
_outputFeatureName
_outputFile
_outputLabel
_outputShape
_overlapFactor
_overlapFilter
_path
_peakTime
_peakValue
_pendingInvalidationHandlers
_preProcessCallback
_predicate
_predicateFilter
_prefersNoInterruptions
_prefersNoMicrophoneUsageIndicator
_processingContexts
_queryPath
_queue
_receiver
_recordFormat
_referenceAudioFile
_referenceSampleRate
_registeredRequests
_remoteObservers
_request
_requestDescription
_requestState
_requestType
_requests
_resourcePath
_results
_resultsPredicate
_resultsPredicateLeakCount
_resultsToDiscardCount
_ringBuffer
_ringBufferWriteBufferList
_rootDirectory
_running
_sampleRate
_scratchFloatSpace
_secondPassAnalyzers
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassIsActive
_secondPassRequest
_secondPassResultToComparableFunction
_secondPassTriggerTime
_secondPassUltronReportOps
_segments
_serverFilePaths
_serverInfo
_session
_sharedProcessor
_shouldRebuildProcessingTree
_shouldThrowException
_similarityThreshold
_smoothingDuration
_soundIdentifier
_soundprint_Placeholder
_sourceFeatureName
_spatialSpectrum
_standardDeviation
_state
_stateIn
_subscriber
_substitutions
_sysdiagnoseHistoryDuration
_systemConfiguration
_taskCompletionMap
_text
_thresholdedHistoryIn
_thresholdedHistoryOut
_timeBetweenTriggers
_timeConverter
_timeRange
_trainingDataEmbeddings
_trainingDataLabels
_transaction
_tuningPrefix
_twoPassConfiguration
_type
_unhealthyBufferCount
_unregisterLogCollectHook
_url
_useSiriAudioRouting
_valence
_validationDataEmbeddings
_validationDataLabels
_value
_vendedModels
_wasCancelled
_windowDurationConstraint
_windowLengthFrames
_windowSizeInSamples
_wrappedModel
_xpcConnectionToServer
activate
activateWithCompletion:
adaptToSystemConfiguration:error:
addAudio:
addEntriesFromDictionary:
addItem:
addObject:
addObjectsFromArray:
addObserver:selector:name:object:
addRequest:completionHandler:resultsHandler:
addRequest:completionHandler:resultsHandler:error:
addRequest:withObserver:error:
addRequestInBackground:withObserver:
allObjects
allValidDetectorIdentifiers
allValidSoundIdentifiers
allValues
allocWithZone:
analyzeAudioBuffer:atAudioFramePosition:
analyzeWithCompletionHandler:
anyObject
appendString:
archivedDataWithRootObject:requiringSecureCoding:error:
array
arrayByAddingObject:
arrayByAddingObjectsFromArray:
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
attributesOfFileSystemForPath:error:
attributesOfItemAtPath:error:
audioSamples
automaticallyNotifiesObserversForKey:
autorelease
backgroundEnergyPercentile
beginSecondPassHandler
binarySampleRepresentation
blockSize
blocksBetweenTriggers
boolValue
bytes
cancel
cancelAnalysis
category
channelCount
channelIndex
channelLayout
channelMap
class
classLabel
classLabels
classificationForIdentifier:
classifierIdentifier
clearCompleteCount
clearErrors
clearResults
clientSampleRate
clientSampleTimeFromSampleTime:fromBox:
commands
commonFormat
compare:
compileModelAtURL:error:
completeAnalysis
completeCount
componentsJoinedByString:
componentsSeparatedByCharactersInSet:
componentsSeparatedByString:
computationalDutyCycle
confidence
confidenceThreshold
configureNewAnalyzersToComputeInThisProcess:
conformsToProtocol:
constantValue
constraintWithShape:dataType:
contentsOfDirectoryAtPath:error:
copy
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createAnalyzerWithError:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createProcessorWithError:
createSecondPassController
createSystemAudioAnalyzer
createWithSampleRate:windowDuration:overlapFactor:error:
currentFrameValue
currentHandler
currentRunLoop
data
dataPointer
dataType
dataWithBytes:length:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
datasetType
date
dateByAddingTimeInterval:
debugDescription
decibelLevel
decisionDelay
decodeArrayOfObjectsOfClass:forKey:
decodeBoolForKey:
decodeCMTimeForKey:
decodeCMTimeRangeForKey:
decodeDoubleForKey:
decodeFloatForKey:
decodeIntegerForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
decoupledIO
defaultCenter
defaultManager
defaultWindowDuration
deregisterRequestID:
description
detected
detectedHistoryIn
detectedHistoryOut
detectorIdentifier
dictionary
dictionaryRepresentation
dictionaryWithCapacity:
dictionaryWithContentsOfFile:
dictionaryWithDictionary:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
didChangeValueForKey:
dominance
doubleValue
durationRange
edPKData
elevation
encodeBool:forKey:
encodeCMTime:forKey:
encodeCMTimeRange:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeWithCoder:
endSecondPassHandler
endTimesFromTimeRangeCollection:
enumerateKeysAndObjectsUsingBlock:
enumeratedDurations
enumeratedShapes
error
errorWithDomain:code:userInfo:
errors
evaluateWithObject:
exceptionWithName:reason:userInfo:
exemplar
exemplarEmbedding
exemplarIndex
expressionType
extractDefaultOutputFeatureFromFeatureProvider:
extractOutputWithOptionalName:fromFeatureProvider:
featureDescriptionWithName:type:optional:constraints:
featureExtractorConfigurationForIdentifier:detectorHeadModelMetadata:modelConfiguration:error:
featureExtractorIdentifier
featureNames
featurePrintType
featureValueForName:
featureValueWithDictionary:error:
featureValueWithMultiArray:
featureValueWithString:
featureVector
featuresAtIndex:
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
featurizeFiles:hallucinatorModelURL:queue:resultHandler:completionHandler:
fileExistsAtPath:
fileFormat
fileItems
fileName
fileSize
fileURLWithPath:
fileURLWithPath:isDirectory:
fileURLs
filename
filterUsingPredicate:
final_output
finish
firstObject
firstPassDidProduceResult:
fixedLengthEmbedding
flags
floatChannelData
floatValue
foregroundEnergyPercentile
format
frameCapacity
frameLength
framePosition
framewiseEmbedding
getIdentitiesWithCompletion:
getLatestSuperVector
graph
graphIsDeadEnded
handleAVAudioSessionInterruption:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
handleAVAudioSessionRouteChange:
handleFailureInMethod:object:file:lineNumber:description:
hangoverDuration
hasPrefix:
hash
hopSizeInSamples
hopSizeSamples
identifier
idsDeviceID
idsDeviceIdentifier
indexOfObject:
indexOfObjectIdenticalTo:
inferenceWindowSize
init
initAsNegativeLabel
initAsPositiveLabel
initAuxiliarySession
initForReading:commonFormat:interleaved:error:
initForReading:error:
initForWriting:settings:commonFormat:interleaved:error:
initSecondaryReader:format:error:
initWithAudioConfiguration:
initWithAudioFile:
initWithAudioSamples:
initWithAudioTimeStamp:sampleRate:
initWithBinarySampleRepresentation:metadata:timestamp:
initWithBox:fromGraph:
initWithCapacity:
initWithClassificationDictionary:
initWithClassifierIdentifier:error:
initWithCoder:
initWithCommonFormat:sampleRate:interleaved:channelLayout:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
initWithConfiguration:
initWithConfiguration:error:
initWithContentsOfURL:configuration:error:
initWithContentsOfURL:error:
initWithDSPGraph:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithDetectorIdentifier:error:
initWithDetectorVariant:soundIdentifier:modelConfiguration:resultsPredicate:resultsPredicateLeakCount:
initWithDictionary:error:
initWithDictionary:resourcePath:
initWithDurationRange:
initWithEnumeratedDurations:
initWithFeaturePrintType:
initWithFeaturePrintType:featureVector:
initWithFeatureProviderArray:
initWithFiles:serverBasePath:serverInfo:
initWithFinal_output:classLabel:
initWithFixedLengthEmbedding:framewiseEmbedding:
initWithIdentifier:
initWithIdentifier:confidence:
initWithIdentifier:detectedValue:
initWithInput1:stateIn:detectedHistoryIn:
initWithInput1:stateIn:thresholdedHistoryIn:detectedHistoryIn:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
initWithInput_1:Confidence:Detected:detectedHistoryOut:
initWithInput_1:Confidence:Detected:thresholdedHistoryOut:detectedHistoryOut:
initWithLayoutTag:
initWithLocaleIdentifier:
initWithMLModel:
initWithMLModel:error:
initWithMachServiceName:
initWithMachServiceName:options:
initWithModelClass:modelConfiguration:
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
initWithModelDescription:parameterDictionary:error:
initWithMood:valence:arousal:dominance:
initWithOutput1:
initWithOverlapFactor:error:
initWithPCMFormat:frameCapacity:
initWithRequestType:
initWithRootDirectory:
initWithSampleRate:windowDuration:overlapFactor:error:
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
initWithServerInfo:queryPath:
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
initWithShape:dataType:error:
initWithSigmoid:
initWithSmoothingDuration:
initWithSoundIdentifier:
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithStreamDescription:
initWithStreamDescription:channelLayout:
initWithSuiteName:
initWithTuningPrefix:
initWithURL:error:
initWithUnsignedInt:
initWithVGGishBasedMLModel:soundIdentifier:
initWith_637:
initWith_9:classLabel:
input1
inputDescriptionsByName
inputNumberOfChannels
insertObject:atIndex:
intValue
integerValue
interfaceWithProtocol:
invalidate
isAllowedShape:error:
isEqual:
isEqualToString:
isEqualToTimeDurationConstraint:
isFileURL
isInterleaved
isKindOfClass:
isMemberOfClass:
isOptional
isSubsetOfSet:
knownClassifications
label
lastObject
launchTaskWithQueue:completionHandler:resultsHandler:
leftExpression
length
listener:shouldAcceptNewConnection:
loadContentsOfURL:configuration:completionHandler:
loadWithConfiguration:completionHandler:
localizedDescription
longLongValue
magnitudeThreshold
meanValue
metadata
minDurationBlocks
minSegmentDuration
minusOrderedSet:
mode
model
modelConfiguration
modelDescription
modelURLForCurrentProduct
modelWithContentsOfURL:configuration:error:
modelWithContentsOfURL:error:
mood
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
multiArrayConstraint
mutableAudioBufferList
mutableCopy
name
nonretainedObjectValue
null
numberFromMultiArrayDataElement:dataType:
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInt:
numberWithUnsignedInteger:
numberWithUnsignedLong:
numberWithUnsignedLongLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
observeValueForKeyPath:ofObject:change:context:
offset
orderedSetWithArray:
outputDescriptionsByName
outputFeatureSize
overlapFactor
path
pathExtension
pathForResource:ofType:
pathWithComponents:
peakTime
peakValue
performQuery:
performSegmentationRequest:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
plistFromFeaturizationResult:error:
plistRepresentationWithError:
portType
predicateOperatorType
predicateWithFormat:
predictedFeatureName
predictedProbabilitiesName
predictionFromAudioSamples:error:
predictionFromFeatures:error:
predictionFromFeatures:options:error:
predictionFromInput1:error:
predictionFromInput1:stateIn:detectedHistoryIn:error:
predictionFromInput1:stateIn:thresholdedHistoryIn:detectedHistoryIn:error:
predictionFromSoundprint_Placeholder:error:
predictionsFromBatch:options:error:
predictionsFromInputs:options:error:
prepareTemplateAndReturnError:
primeGraph
processInfo
processInput:portID:downstreamHandler:
processName
processTerminationWithOptionalError:portID:downstreamHandler:
processValue:time:
processingFormat
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
raise:format:
rangeValue
readIntoBuffer:error:
readIntoBuffer:frameCount:error:
registerRequestID:options:handler:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
removeAllObjects
removeAllRequests
removeItemAtPath:error:
removeItemAtURL:error:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeRequest:
request:didFailWithError:
request:didProduceResult:
requestDidComplete:
resetForNewRequest
resourcePath
respondsToSelector:
resultsBox
resultsBoxName
resultsFromBox:renderedWithFrameCount:
resultsPredicate
resultsPredicateLeakCount
resume
retain
retainCount
reverseObjectEnumerator
sampleRate
sampleTime
saturatedIntegerFromNumber:
saturatedUnsignedIntegerFromNumber:
scanDouble:
scanLongLong:
scanUnsignedLongLong:
scannerWithString:
secondPassDidProduceResult:
segments
self
sendInputToUltronReporter:recentFramesOfAudioBuffer:startingFromTime:error:
sendRequestID:request:destinationID:options:responseHandler:
serverInfo
setActive:error:
setAudioConfiguration:
setAudioSamples:
setBackgroundEnergyPercentile:
setBeginSecondPassHandler:
setBlockSize:
setBlocksBetweenTriggers:
setCategory:
setChannelMap:
setClassLabel:
setClasses:forSelector:argumentIndex:ofReply:
setClassifierIdentifier:
setCommands:
setCompletionHandler:
setComputationalDutyCycle:
setConfidence:
setCurrentFrameValue:
setData:
setDateFormat:
setDelegate:
setDestinationID:
setDetected:
setDetectedHistoryIn:
setDetectedHistoryOut:
setDeviceChangedHandler:
setDeviceFoundHandler:
setDeviceLostHandler:
setDispatchQueue:
setEndSecondPassHandler:
setExemplar:
setExemplarEmbedding:
setExemplarIndex:
setExportedInterface:
setExportedObject:
setFeatureExtractorIdentifier:
setFeaturePrintType:
setFileURLs:
setFilename:
setFinal_output:
setFixedLengthEmbedding:
setFlags:
setForegroundEnergyPercentile:
setFramePosition:
setFramewiseEmbedding:
setGraphIsDeadEnded:
setHangoverDuration:
setHopSizeInSamples:
setHopSizeSamples:
setInferenceWindowSize:
setInput1:
setInput_1:
setInterface:forSelector:argumentIndex:ofReply:
setInterruptionHandler:
setInvalidationHandler:
setItemURL:
setLabel:
setLocalDeviceUpdatedHandler:
setLocale:
setMagnitudeThreshold:
setMeanValue:
setMinSegmentDuration:
setMode:
setModelConfiguration:
setObject:atIndexedSubscript:
setObject:forKey:
setObject:forKeyedSubscript:
setOptions:
setOutput1:
setOverlapFactor:
setPath:
setPeerPublicKey:
setProgressHandler:
setReceivedItemHandler:
setRemoteObjectInterface:
setResultsPredicate:
setResultsPredicate:error:
setResultsPredicateLeakCount:
setRootDirectoryURL:
setSampleRate:
setSegments:
setShouldThrowException:
setSigmoid:
setSimilarityThreshold:
setSoundIdentifier:
setSoundprint_Placeholder:
setStandardDeviation:
setStateIn:
setTargetID:
setTemporaryDirectoryURL:
setThresholdedHistoryIn:
setThresholdedHistoryOut:
setTimeRange:
setTimeZone:
setTrainingDataEmbeddings:
setTrainingDataLabels:
setUseSiriAudioRouting:
setValidationDataEmbeddings:
setValidationDataLabels:
setValue:forKey:
setValue:forKeyPath:
setWindowDuration:
setWindowSizeInSamples:
setWithArray:
set_637:
set_9:
settings
shape
sharedProcessorConfiguration
shouldLogRequests
shouldLogResultsHistory
shouldThrowException
similarityThreshold
sizeRangeForDimension
sleepForTimeInterval:
sliceAtOrigin:shape:squeeze:error:
sortUsingComparator:
sortedArrayUsingComparator:
soundprint_Placeholder
standardDeviation
start
state
stepSizeFrames
stepSizeFramesForWindowLengthFrames:overlapFactor:minimumStepSize:roundingDownToNearestMultipleOf:
stop
streamDescription
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringValue
stringWithFormat:
stringWithUTF8String:
strongToWeakObjectsMapTable
subarrayWithRange:
substringFromIndex:
substringToIndex:
superclass
supportsSecureCoding
synchronousRemoteObjectProxyWithErrorHandler:
thresholdedHistoryIn
thresholdedHistoryOut
timeConversionDictionary
timeRange
timeWithSampleTime:atRate:
timeZoneWithName:
trainingDataEmbeddings
trainingDataLabels
twoPassConfiguration
type
unarchivedArrayOfObjectsOfClass:fromData:error:
unarchivedObjectOfClass:fromData:error:
unsignedIntValue
unsignedIntegerValue
unsignedLongLongValue
updateProcessingTreeFormat:
useSiriAudioRouting
validationDataEmbeddings
validationDataLabels
valueForEntitlement:
valueForKey:
valueWithCMTime:
valueWithCMTimeRange:
valueWithNonretainedObject:
valueWithPointer:
whitespaceAndNewlineCharacterSet
willChangeValueForKey:
windowDuration
windowDurationConstraint
windowLengthFrames
windowSizeInSamples
writeFromBuffer:error:
writeToURL:options:error:
xpcAddRequest:withObserver:completionHandler:
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcRemoveRequest:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequest:didProduceResult:completionHandler:
xpcRequestDidComplete:completionHandler:
xpcSetAudioConfiguration:completionHandler:
zone
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v16@0:8
@"NSString"
@"MLModel"
@"SNComposedDetector"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@48@0:8d16d24d32d40
@40@0:8{?=qiIq}16
B44@0:8B16{?=qiIq}20
{?="value"q"timescale"i"flags"I"epoch"q}
@"NSValue"
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
v20@0:8f16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
q16@0:8
v24@0:8q16
@"SNTimeDurationConstraint"
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
@"NSError"
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8I16
@"SNDetectSignalThresholdRequestImpl"
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@"NSXPCConnection"
@"NSMutableArray"
v40@0:8@16@"NSString"24@?<v@?@"NSString"@@"NSError">32
v40@0:8@"NSError"16@"NSString"24@?<v@?@"NSString"@@"NSError">32
@"SNRecordOperator"
@"NSURL"
@"NSDate"
@40@0:8@16@24@32
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"SNDetectorHeadConfiguration"
@"SNPredicateFilterOperator"
v24@0:8@?16
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
@28@0:8@16B24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@"SNTwoPassConfiguration"
@32@0:8@16@24
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@16@24
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"AVAudioFormat"
v20@0:8B16
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"SNKShotLabel"
@"NSNumber"
@48@0:8@16@24@32@?40
@56@0:8@16@24@32@?40@?48
@32@0:8@16^@24
v48@0:8@16@24@32^v40
@"SNAudioConfiguration"
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@"SNVoiceTriggerResult"
@"NSSet"
@"SNClassifierVariant"
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@56@0:8@16@24@32@40q48
@"SNDetectorVariant"
@"MLModelConfiguration"
@"NSPredicate"
B64@0:8@16^v24{?=qiIq}32^@56
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[24C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@48@0:8@16@24@32@40
@"<SNRequest>"
@"NSObject<OS_os_transaction>"
@"SNAudioQueueConfiguration"
@"AVAudioSession"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
B48@0:8@16@?24@?32^@40
v32@0:8@16q24
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
@"SNNullDetector"
@"SNAudioRecordingQueue"
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
@32@0:8@16d24
v24@0:8Q16
@?16@0:8
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
@56@0:8@16@24@32@40@48
@56@0:8@16@24@32@40^@48
