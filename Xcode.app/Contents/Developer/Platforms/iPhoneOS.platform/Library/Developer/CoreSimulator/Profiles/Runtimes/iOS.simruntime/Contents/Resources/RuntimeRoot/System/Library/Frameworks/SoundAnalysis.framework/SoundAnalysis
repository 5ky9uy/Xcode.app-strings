@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
@N8DSPGraph9ExceptionE
St9exception
St13runtime_error
St12length_error
St11logic_error
@xfuapraexoba
xfuapargxoba
MbP?NSt3__117bad_function_callE
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
mcpl)
mcpl,
xfuadgisxoba
xfuaftmlxoba
timeRange
decibelLevel
type
detectorIdentifier
cannot encode MLModel
cannot copy MLModel
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/fed91392-8650-11ec-bf32-6613bcf0e2ee/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.4.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
b238a_mic_voice_recognition_bf.dspg
PropertyStrip
b238a_mic_voice_recognition_bf.propstrip
AUStrip
b238a_mic_voice_recognition_bf.austrip
Failed to create graph
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
v8@?0
illegal call to unavailable init selector: %s
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v16@?0^{OpaqueAudioQueue=}8
Applause
Babble
Cheering
Laughter
Music
Speech
Distressed Baby
Smoke Alarm
Fire Alarm
Doorbell
Buzzer
Beep
Ding Bell
Dog Bark
Cat Meow
Door Knock
Shouting
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
Processing tree graph is null
.dot
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
spatialSpectrum
%@ azmimuth: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
enable_second_pass_recording_in_daemon
daemon_recording_path
recording_directory_maximum_size_bytes
recording_time_to_live_seconds
delete_recordings_without_detection
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
enable_verbose_logging
SoundAnalysisAnonymousClient
Library
Caches
AudioCaptures
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
%@ detected: %@
IncludePaths
Substitutions
Value
SNSoundPrintFeatureExtractorConfiguration.mm
overlapFactor >= 0.0 && overlapFactor < 1.0
VerifyNotTrashingOwnedBuffer
mBufferMemory == NULL
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
com.apple.SoundAnalysis.remoteanalyzer
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
embedding
label
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
feature
tokenGroup
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
Error setting up hallucinator input.
Error running inference on hallucinator.
hallucinated
Error creating negatives MLMultiArray.
MLModelCreatorDefinedKey
numTokenGroups
Unable to load hallucinator metadata.
Error shifting segment.
Error clipping segment to file bounds.
Error sizing segment to match extended exemplar.
Error calculating embeddings.
Failed to hallucinate feature.
Failed to generate negative.
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
v20@?0@"MLMultiArray"8B16
Failed to collect embeddings at single time shift.
Not enough audio segments found to continue.
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifierIdentifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
Unknown classifier identifier
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
Couldn't find soundIdentifier for detectorIdentifier %@
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
SNDSPGraphBox.mm
graph
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
SNLogMelBasedFeatureExtractorConfiguration.mm
approximateOverlapFactor >= 0.0 && approximateOverlapFactor < 1.0
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
Audio format must be PCM
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
yyyy-MM-dd-HHmmss
%@_%@
yyyy-MM-dd HH:mm:ss
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
+[SNUtils copyAudioBufferList:to:frameCount:bytesPerFrame:]
SNUtils.mm
sourceBufferList->mNumberBuffers > 0
sourceBufferList->mNumberBuffers == destinationBufferList->mNumberBuffers
sourceBufferList->mBuffers[bufferIdx].mNumberChannels > 0
frameCount*bytesPerFrame <= sourceBufferList->mBuffers[bufferIdx].mDataByteSize
frameCount*bytesPerFrame <= destinationBufferList->mBuffers[bufferIdx].mDataByteSize
denylist
MultiArrayInput
MultiArrayOutput
feedback_connections
soundanalysisd
InternalBuild
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
results
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"SNDSPGraphBox"8@?0
@"NSMutableSet"8@?0
@"NSString"8@?0
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
InvalidFormatException
com.apple.SoundAnalysis.AnalyzerQueue
BuildVersion
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
timestamp
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
RPFTSource
v16@?0@"RPFileTransferProgress"8
%@_%@_bus%ld_%@.caf
%@ startRecordingPort was unsuccessful
SNDSPGraphUtilities
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
B24@?0@8^@16
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B8@?0
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
category
mode
options
%@ %@ %lu
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
SNThresholdBasedSecondPassController.m
secondPassHangoverPeriod >= 0.0
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
soundprint/Placeholder
Sigmoid
SNSoundPrint100kCatMeowModel
mlmodelc
input1
detectedHistoryIn
input_1
detectedHistoryOut
SNVGGishDoorbellModel
SNVGGishDistressedBabyModel
SNVGGishDingBellModel
output1
SNVGGishLaughterModel
SNSoundPrint100kBuzzerModel
SNVGGishApplauseModel
SNVGGishFireAlarmModel
SNSoundPrint100kShoutingModel
audioSamples
SNSoundPrint100kFireAlarmModel
SNSoundPrint100kBeepModel
SNVGGishDoorKnockModel
classLabel
SNSoundClassifierVersion1Model
SNVGGishBabbleModel
SNVGGishDogBarkModel
SNSoundPrint100kDogBarkModel
SNVGGishBeepModel
SNSoundPrint100kDistressedBabyModel
SNSoundPrint100kDoorbellModel
SNSoundPrint100kSmokeAlarmModel
SNVGGishShoutingModel
SNVGGishSpeechModel
SNVGGishCatMeowModel
SNVGGishSmokeAlarmModel
SNSoundPrintKEmbeddingModel
SNVGGishMusicModel
SNSoundPrint100kDingBellModel
SNVGGishBuzzerModel
SNVGGishCheeringModel
SNSoundPrint100kDoorKnockModel
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) start
(SNSystemAudioAnalyzerXPCPublisher:%@) stop
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel assignment %u with result %d
Could register audio units. Returning nil for %@
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer with In-Process Computation
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
(SNSystemAudioAnalyzerRemote:%@) start
(SNSystemAudioAnalyzerRemote:%@) stop
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
Unknown featureExtractorIdentifier %@
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Unimplemented
Error analyzing audio buffer
Removing %@, since it doesn't contain any detections
Failed to write results log file with error %@
Started recording graph
Failed to start recording graph
No sample rate metadata provided in model. Defaulting to %d
Feedback connection destination %@ not present in model
Feedback connection source %@ not present in model
Couldn't parse feedback connection. Should be 'source -> destination'
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
Failed to open audio file %@ with error %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Queue already running
Failed to create audio queue
Starting audio queue
Stopping audio queue
Completed first pass for request %@ with error %@
Resizing historical ring buffer from %d to %d frames after adding %@
Beginning second pass for request %@
Couldn't begin second pass recording with error %@
Couldn't begin recording, no path set
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Resizing historical ring buffer from %d to %d frames after removing %@
Wrote file %@ at %@ with result %d.
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Box %s doesn't exist in graph
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
(SNSystemAudioAnalyzerLocal:%@) start
(SNSystemAudioAnalyzerLocal:%@) stop
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Audio failed to start. Retrying in %d seconds
Failed to deactivate AVAudioSession with error %@
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature has more than one non-unitary dimension
Additional input feature dimensions must be have size 1
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 input feature
Output feature has more than one non-unitary dimension
Additional output feature dimensions must be have size 1
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) start
(SNSystemAudioAnalyzerXPCSubscriber:%@) stop
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
Could not load SNSoundPrint100kCatMeowModel.mlmodelc in the bundle resource
Could not load SNVGGishDoorbellModel.mlmodelc in the bundle resource
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishDingBellModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kBuzzerModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kShoutingModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kBeepModel.mlmodelc in the bundle resource
Could not load SNVGGishDoorKnockModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNVGGishDogBarkModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDogBarkModel.mlmodelc in the bundle resource
Could not load SNVGGishBeepModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDoorbellModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishShoutingModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishCatMeowModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNVGGishSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDingBellModel.mlmodelc in the bundle resource
Could not load SNVGGishBuzzerModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDoorKnockModel.mlmodelc in the bundle resource
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNSpeechDistanceResult
SNUserDefaults
SNDeleteFilesRequest
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNMLModelCacheKey
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNProcessorCreating
SNDictionaryAdditions
SNResultsXPCSubscriber
SNResultsObserving
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNHallucinatorInputProvider
MLFeatureProvider
SNKShotSegment
0 2@
SNKShotFeaturizer
SNFileListingResult
SNSystemAudioAnalyzerRemote
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNDiscoverFileServerRequest
SNValidateModel
SNDaemon
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNResultsForwarder
SNBooleanCancellable
SNCancellable
SNModelFeatureConnection
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
DSPGMLInputProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNTwoPassConfiguration
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNAudioStreamAnalyzer
SNUltronResultsLogger
SNLogMelBasedFeatureExtractor
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNResultsXPCPublisher
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNSoundPrint100kCatMeowModelInput
SNSoundPrint100kCatMeowModelOutput
SNSoundPrint100kCatMeowModel
SNVGGishDoorbellModelInput
SNVGGishDoorbellModelOutput
SNVGGishDoorbellModel
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishDingBellModelInput
SNVGGishDingBellModelOutput
SNVGGishDingBellModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kBuzzerModelInput
SNSoundPrint100kBuzzerModelOutput
SNSoundPrint100kBuzzerModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNSoundPrint100kShoutingModelInput
SNSoundPrint100kShoutingModelOutput
SNSoundPrint100kShoutingModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrint100kBeepModelInput
SNSoundPrint100kBeepModelOutput
SNSoundPrint100kBeepModel
SNVGGishDoorKnockModelInput
SNVGGishDoorKnockModelOutput
SNVGGishDoorKnockModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNVGGishDogBarkModelInput
SNVGGishDogBarkModelOutput
SNVGGishDogBarkModel
SNSoundPrint100kDogBarkModelInput
SNSoundPrint100kDogBarkModelOutput
SNSoundPrint100kDogBarkModel
SNVGGishBeepModelInput
SNVGGishBeepModelOutput
SNVGGishBeepModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kDistressedBabyModelInput
SNSoundPrint100kDistressedBabyModelOutput
SNSoundPrint100kDistressedBabyModel
SNSoundPrint100kDoorbellModelInput
SNSoundPrint100kDoorbellModelOutput
SNSoundPrint100kDoorbellModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishShoutingModelInput
SNVGGishShoutingModelOutput
SNVGGishShoutingModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNVGGishCatMeowModelInput
SNVGGishCatMeowModelOutput
SNVGGishCatMeowModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNVGGishSmokeAlarmModelInput
SNVGGishSmokeAlarmModelOutput
SNVGGishSmokeAlarmModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNSoundPrint100kDingBellModelInput
SNSoundPrint100kDingBellModelOutput
SNSoundPrint100kDingBellModel
SNVGGishBuzzerModelInput
SNVGGishBuzzerModelOutput
SNVGGishBuzzerModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNSoundPrint100kDoorKnockModelInput
SNSoundPrint100kDoorKnockModelOutput
SNSoundPrint100kDoorKnockModel
allocWithZone:
init
timeRange
setTimeRange:
decibelLevel
setDecibelLevel:
isEqualToLKFSResult:
valueWithCMTimeRange:
isEqual:
hash
numberWithFloat:
decodeObjectOfClass:forKey:
decodeDoubleForKey:
CMTimeRangeValue
encodeObject:forKey:
encodeDouble:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},N
_decibelLevel
_timeRange
Tf,N,V_decibelLevel
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
decodeIntegerForKey:
initWithDetectorIdentifier:
encodeInteger:forKey:
raise:format:
detectorIdentifier
isEqualToDetectorVariant:
type
vggishBasedMLModel
numberWithInteger:
initWithVGGishBasedMLModel:
.cxx_destruct
_type
_vggishBasedMLModel
_detectorIdentifier
Tq,R,V_type
T@"MLModel",R,V_vggishBasedMLModel
T@"NSString",R,V_detectorIdentifier
mood
valence
arousal
dominance
confidence
stringWithFormat:
setMood:
setValence:
setArousal:
setDominance:
setConfidence:
isEqualToSpeechEmotionResult:
numberWithDouble:
unarchivedObjectOfClass:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithBinarySampleRepresentation:
initWithBinarySampleRepresentation:metadata:timestamp:
binarySampleRepresentation
Td,R,N
Td,N
_confidence
_mood
_valence
_arousal
_dominance
Td,V_mood
Td,V_valence
Td,V_arousal
Td,V_dominance
Td,N,V_confidence
isEqualToEstimateDirectionOfArrivalRequest:
createAnalyzerWithError:
spatialSpectrum
_spatialSpectrum
T@"NSArray",R,N,V_spatialSpectrum
setAzimuth:
setSpatialSpectrum:
arrayWithObjects:count:
bundleForClass:
resourcePath
populateClientError:withCode:underlyingError:message:
stringWithUTF8String:
resultsBox
adaptToSystemConfiguration:error:
graph
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
resultsFromBox:renderedWithFrameCount:
sharedProcessorConfiguration
primeGraph
T^v,R,N
azimuth
.cxx_construct
_graph
Tf,R,N
T@"NSArray",R,N
initWithArray:resourcePath:
graphWithConfiguration:
defaultWindowDuration
initWithFeaturePrintType:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
windowDurationConstraint
roundTime:toAllowableTime:
initWithFeaturePrintType:overlapFactor:windowDuration:
isEqualToCreateFeaturePrintRequest:
featurePrintType
setFeaturePrintType:
overlapFactor
setOverlapFactor:
windowDuration
setWindowDuration:
valueWithCMTime:
decodeFloatForKey:
decodeCMTimeForKey:
encodeFloat:forKey:
encodeCMTime:forKey:
_overlapFactor
_windowDurationConstraint
_featurePrintType
_windowDuration
Tq,N,V_featurePrintType
Tf,N,V_overlapFactor
T{?=qiIq},N,V_windowDuration
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
blockSize
createWithSampleRate:windowDuration:overlapFactor:error:
TI,R,N
T{?=qiIq},R,N
T@"SNTimeDurationConstraint",R,N
sampleRate
featureNames
count
allObjects
firstObject
featureValueForName:
extractDefaultOutputFeatureFromFeatureProvider:
multiArrayValue
outputProvider
extractOutputWithOptionalName:fromFeatureProvider:
initWithFeaturePrintType:featureVector:
_featureExtractor
_outputFeatureName
_resultsToDiscardCount
initWithOverlapFactor:error:
vggishFrontEndProcessingModelDescription
initWithModelDescription:parameterDictionary:error:
initWithMLCustomModel:modelDescription:
anyInputMultiArrayShape:
modelBlockSize:
model
resultsBoxName
UTF8String
modelSampleRate:orDefaultRate:
vggishFeatureEmbeddingInputShape
numberOfElements:
vggishFeatureEmbeddingOutputShape
initWithEnumeratedDurations:
_blockSize
TI,R,N,V_blockSize
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
vggishFrontEndProcessingInputShape
modelDescription
inputDescriptionsByName
allValues
objectAtIndexedSubscript:
multiArrayConstraint
lastDimensionSizeRange:
numberWithLongLong:
numberWithUnsignedInteger:
numberWithUnsignedLong:
createSoundPrintAFeatureExtractorWithModelConfiguration:
shapeConstraint
windowDurationConstraintFromMultiArrayShapeConstraint:sampleRate:
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithSampleRate:windowDuration:overlapFactor:error:
createSoundPrintKFeatureExtractor
anyOutputMultiArrayShape:
dataWithBytes:length:
addAudio:
endAudio
getLatestSuperVector
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
isEqualToSpeechDistanceRequest:
setCurrentFrameValue:
setMeanValue:
setStandardDeviation:
setServerInfo:
setState:
initWithServerInfo:state:
serverInfo
state
_serverInfo
_state
T@"SNFileServerInfo",&,N,V_serverInfo
TQ,N,V_state
xpcRequest:didProduceResult:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequestDidComplete:completionHandler:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithReceiver:
synchronousRemoteObjectProxyWithErrorHandler:
xpcAddRequest:withObserver:completionHandler:
errorWithCode:underlyingError:message:
xpcRemoveRequest:completionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcStartWithCompletionHandler:
xpcStopWithCompletionHandler:
xpcSetAudioConfiguration:completionHandler:
setAudioConfiguration:
addRequest:withObserver:error:
removeRequest:
removeAllRequests
start
stop
initWithSubscriber:
_subscriber
creationFlags
setCreationFlags:
configureAudioQueue
setConfigureAudioQueue:
_creationFlags
_configureAudioQueue
TI,V_creationFlags
T@?,C,V_configureAudioQueue
enableAlwaysOnAudioRouting:
setChannelAssignment:onQueue:
builtInMicrophoneAnalysisChannelNumberOrDefault:
createDefaultAudioQueueConfigurationUsingChannelNumber:
sharedInstance
availableInputs
countByEnumeratingWithState:objects:count:
portType
isEqualToString:
builtInMicrophoneDeviceUID
createSiriAudioQueueConfigurationUsingChannelNumber:
audioQueueConfiguration
T@"SNAudioQueueConfiguration",R
setFileName:
setError:
initWithFileName:error:
fileName
error
_fileName
_error
T@"NSString",&,N,V_fileName
T@"NSError",&,N,V_error
allValidSoundIdentifiers
initWithDetectorHead:featureExtractor:soundIdentifier:
detectorHead
featureExtractor
soundIdentifier
_detectorHead
_soundIdentifier
T@"NSString",R,N,V_detectorHead
T@"NSString",R,N,V_featureExtractor
T@"NSString",R,N,V_soundIdentifier
queue
launchTaskWithQueue:completionHandler:resultsHandler:
_removeRequest:error:
taskCompletionMap
valueWithPointer:
setObject:forKeyedSubscript:
objectForKey:
removeObjectForKey:
requests
addRequest:completionHandler:resultsHandler:
setRequests:
setTaskCompletionMap:
setQueue:
_requests
_taskCompletionMap
_queue
T@"NSMutableArray",&,N,V_requests
T@"NSMutableDictionary",&,N,V_taskCompletionMap
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
CMTimeValue
sortedArrayUsingComparator:
isEqualToTimeDurationConstraint:
initWithDurationRange:
durationRange
enumeratedDurations
isEqualToArray:
decodeCMTimeRangeForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeCMTimeRange:forKey:
_enumeratedDurations
_durationRange
T@"NSArray",R,V_enumeratedDurations
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
initWithSampleRate:blockSize:magnitudeThreshold:
setSampleRate:
setBlockSize:
magnitudeThreshold
setMagnitudeThreshold:
isEqualToDetectSignalThresholdRequest:
numberWithUnsignedInt:
_detector
_sampleRate
_magnitudeThreshold
Td,N,V_sampleRate
TI,N,V_blockSize
Td,N,V_magnitudeThreshold
array
addObject:
dictionaryWithObjectsAndKeys:
errorWithDomain:code:userInfo:
isEqualToDirectionOfArrivalResult:
_azimuth
Tf,N,V_azimuth
T@"NSArray",&,N,V_spatialSpectrum
allKeys
dictionaryWithObjects:forKeys:count:
initWithDictionary:error:
predictionFromFeatures:options:error:
outputDescriptionsByName
predictionsFromBatch:options:error:
_modelDescription
_model
registerAudioUnits
initWithAudioFile:overlapFactor:
initWithAudioFile:
_referenceAudioFile
Td,V_overlapFactor
processingFormat
length
setChannelIndex:
setPeakValue:
setPeakTime:
channelCount
_systemConfiguration
_referenceSampleRate
_channelCount
_framesProcessed
Td,R,V_overlapFactor
initWithDictionary:resourcePath:
graphWithGraphInfo:
initWithPCMFormat:frameCapacity:
setFramePosition:
readIntoBuffer:error:
streamDescription
audioBufferList
createSystemAudioAnalyzer
setDelegate:
resume
endpoint
initWithListenerEndpoint:
setExportedInterface:
setExportedObject:
launchAsMachServiceWithName:
initWithMachServiceName:
launchWithResourceCoordinator:onXPCListener:
initWithResourceCoordinator:onListener:
launchDefaultServer
listener:shouldAcceptNewConnection:
connectLocally
_listener
_coordinator
initToConnectToMachServiceWithName:queue:
initWithMachServiceName:options:
setInterruptionHandler:
setInvalidationHandler:
newConnectionToMachServiceWithName:lostConnectionHandler:queue:
initWithConnectionGenerator:queue:
_handleLostConnection
setRemoteObjectInterface:
_connectionToServerWithInvalidationHandler:queue:
remoteObjectProxy
_remoteResourceCoordinatorWithInvalidationHandler:queue:
_createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
defaultClient
createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
_connectionToServerGenerator
_xpcConnectionToServer
_pendingInvalidationHandlers
meanValue
currentFrameValue
standardDeviation
isEqualToSpeechDistanceResult:
_currentFrameValue
_meanValue
_standardDeviation
Td,N,V_currentFrameValue
Td,N,V_meanValue
Td,N,V_standardDeviation
userDefaults
boolForKey:
stringForKey:
integerForKey:
doubleForKey:
intValue
numberWithInt:
builtInMicrophoneAnalysisChannelNumber
instance
initWithSuiteName:
setUserDefaults:
mainBundle
bundleIdentifier
pathWithComponents:
registerDefaults:
enableSecondPassRecordingInDaemon
daemonRecordingPath
recordingDirectoryMaximumSizeBytes
recordingTimeToLiveSeconds
deleteRecordingsWithoutDetection
enableFileServer
fileServerRootDirectory
enableVerboseLogging
T@"NSString",R
Tq,R
Td,R
T@"NSNumber",R
_userDefaults
T@"NSUserDefaults",&,N,V_userDefaults
setFiles:
setServerBasePath:
setDispatchQueue:
files
serverBasePath
identifier
sendRequestID:request:destinationID:options:responseHandler:
activateWithCompletion:
invalidate
initWithFiles:serverBasePath:serverInfo:
_files
_serverBasePath
T@"NSArray",&,N,V_files
T@"NSString",&,N,V_serverBasePath
T@"MLModelDescription",R
_customModel
T@"MLModelDescription",R,V_modelDescription
initWithModel:
_lock
userSuppliedInputFeatureNames:
userSuppliedOutputFeatureNames:
containsObject:
outputLabel
dataType
initWithIdentifier:
windowLengthFrames
completeTimingInfoInResult:windowLengthFrames:usingBox:
floatValue
setDetected:
setDetectorIdentifier:
featureExtractorConfiguration
initWithConfiguration:
_configuration
_detectorBoxName
_inputFeatureName
_outputConfidenceFeatureName
_outputDetectedFeatureName
objectForKeyedSubscript:
shape
stepSizeFrames
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
_receiver
detected
isEqualToDetectionResult:
numberWithBool:
decodeBoolForKey:
encodeBool:forKey:
_detected
_identifier
TB,N,V_detected
T@"NSString",&,N,V_detectorIdentifier
T@"NSString",R,N,V_identifier
initWithKeys:
isEqualToModelCacheKey:
initWithModelClass:modelConfiguration:
_keys
createSecondPassController
twoPassConfiguration
T@"SNTwoPassConfiguration",R
initWithTwoPassConfiguration:createSecondPassControllerFunction:
_createSecondPassControllerFunction
_twoPassConfiguration
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
isEqualToSpeechUtteranceResult:
stringByAppendingPathComponent:
path
text
includePaths
substitutions
setPath:
setText:
setIncludePaths:
setSubstitutions:
_path
_text
_includePaths
_substitutions
T@"NSString",&,N,V_path
T@"NSString",&,N,V_text
T@"NSArray",&,N,V_includePaths
T@"NSDictionary",&,N,V_substitutions
value
containsOnlyAUStrips:
_value
T@"NSString",R,N,V_path
T@"NSDictionary",R,N,V_value
_resourcePath
T@"NSString",R,N,V_resourcePath
dspItems
setDspItems:
_dspItems
T@"NSArray",&,N,V_dspItems
applyAUStrip:toGraph:
name
applyPropertyStrip:toGraph:
compileText:withSubstitutions:includingPaths:
compileFile:withSubstitutions:includingPaths:
setAUStrip:
dictionaryWithContentsOfFile:
setPropertyStrip:withResourcePath:
isEqualToSoundPrintFeatureExtractorConfiguration:
createProcessorWithError:
initWithModel:overlapFactor:
outputFeatureSize
_windowLengthFrames
_stepSizeFrames
_outputFeatureSize
T@"<SNMLModel>",R,V_model
Td,R,V_sampleRate
TI,R,V_windowLengthFrames
TI,R,V_stepSizeFrames
TI,R,V_outputFeatureSize
null
setObject:forKey:
sn_setSafeObject:forKey:
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithClient:queue:
selectAppropriateImplForThisProcess
initWithImpl:
configureNewAnalyzersToComputeInThisProcess:
initWithAudioConfiguration:
addRequestInBackground:withObserver:
_impl
fileURLs
setFileURLs:
backgroundEnergyPercentile
setBackgroundEnergyPercentile:
foregroundEnergyPercentile
setForegroundEnergyPercentile:
hangoverDuration
setHangoverDuration:
minSegmentDuration
setMinSegmentDuration:
similarityThreshold
setSimilarityThreshold:
_backgroundEnergyPercentile
_foregroundEnergyPercentile
_similarityThreshold
_fileURLs
_hangoverDuration
_minSegmentDuration
T@"NSArray",V_fileURLs
Tf,V_backgroundEnergyPercentile
Tf,V_foregroundEnergyPercentile
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
Tf,V_similarityThreshold
trainingDataEmbeddings
setTrainingDataEmbeddings:
trainingDataLabels
setTrainingDataLabels:
validationDataEmbeddings
setValidationDataEmbeddings:
validationDataLabels
setValidationDataLabels:
exemplar
setExemplar:
inferenceWindowSize
setInferenceWindowSize:
_trainingDataEmbeddings
_trainingDataLabels
_validationDataEmbeddings
_validationDataLabels
_exemplar
_inferenceWindowSize
T@"NSArray",C,V_trainingDataEmbeddings
T@"NSArray",C,V_trainingDataLabels
T@"NSArray",C,V_validationDataEmbeddings
T@"NSArray",C,V_validationDataLabels
T@"MLMultiArray",&,V_exemplar
T{?=qiIq},V_inferenceWindowSize
exemplarEmbedding
setExemplarEmbedding:
segments
setSegments:
exemplarIndex
setExemplarIndex:
_exemplarEmbedding
_segments
_exemplarIndex
T@"MLMultiArray",&,V_exemplarEmbedding
T@"NSArray",C,V_segments
T@"NSNumber",C,V_exemplarIndex
embeddings
setEmbeddings:
labels
setLabels:
_embeddings
_labels
T@"NSArray",C,V_embeddings
T@"NSArray",C,V_labels
setWithObjects:
indexOfObject:
feature
featureValueWithMultiArray:
tokenGroup
T@"NSSet",R,N
setFeature:
setTokenGroup:
_feature
_tokenGroup
T@"MLMultiArray",&,N,V_feature
T@"MLMultiArray",&,N,V_tokenGroup
setUrl:
_url
T{?={?=qiIq}{?=qiIq}},V_timeRange
T@"NSURL",C,V_url
initWithShape:dataType:error:
dataPointer
arrayWithObjects:
initWithCapacity:
getTimeRangeEncompassingEntireAudioFileAtURL:error:
clipTimeRange:toBounds:
resizeSegment:toDuration:error:
initWithURL:error:
analyzeInRange:
errors
results
doubleValue
collectResultsForRequest:fromSegment:error:
collectFeaturePrintsOfType:fromSegment:withWindowDuration:withOverlapFactor:error:
initForReading:commonFormat:interleaved:error:
fileFormat
getFirstFeaturePrintOfType:fromSegment:withWindowDuration:withOverlapFactor:error:
featureVector
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
sliceAtOrigin:shape:squeeze:error:
multiArrayViewExpandingDimensionsAtAxis:
float32MatrixWithValues:error:
strides
metadata
integerValue
shiftSegment:byAmount:error:
clipSegmentToFileBoundaries:error:
hallucinateNewEmbeddingSimilarToSoundPrintEmbedding:withHallucinator:withHallucinationTokenGroup:error:
generateNegativeEmbeddingFromPositiveSoundPrintEmbedding:usingNegativeSoundPrintEmbeddingArray:randomNumberGenerator:error:
defaultRandomNumberGenerator
featurizeFiles:randomNumberGenerator:hallucinatorModelURL:cancellable:error:
analyze
addObjectsFromArray:
cosineSimilarityBetweenOneFeatureVector:andAnotherFeatureVector:error:
lastObject
ensureMinimumDuration:forSegment:error:
cosineSimilarityBetweenOneFloat32Array:andAnotherFloat32Array:length:error:
ensureIsValidHallucinatorV3Model:error:
generateDatasetUsingNewHallucinator:segments:exemplarLength:datasetIdentifier:randomNumberGenerator:error:
collectEmbeddingsAtOneTimeShift:forSegment:numHallucinatedExamples:exemplarDuration:hallucinator:negativeEmbeddingArray:resultHandler:randomNumberGenerator:error:
isCancelled
performSegmentationRequest:error:
localizedDescription
loadModelAtURL:withTimeout:error:
recognizeHallucinatorModel:error:
subarrayWithRange:
generateDatasetFrom:numTimeShifts:extendeExemplartLength:secondsAugmentAroundSegment:sampleRate:hallucinator:numHallucinatedExamples:datasetIdentifier:randomNumberGenerator:cancellable:error:
standardizeTimeRange:directionShouldBePositive:negativeShouldResideInTimescale:
generateRandomTimeOffsetInRange:randomNumberGenerator:
generateRandomTimeInRange:randomNumberGenerator:
addOffset:toTimeRange:
resizeOneSegment:toDuration:
emitTimeShiftsForSegment:shiftWindow:randomNumberGenerator:count:datasetIdentifier:foregroundAudioLength:handler:error:
ensureModelDescription:hasInputFeatureNames:hasOutputFeatureNames:error:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:shapeOptions:error:
readNumRepetitionsPerTimeShiftFromHallucinator:error:
readNumTimeShiftsPerSegmentFromHallucinator:error:
valueWithRange:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:dimensionSizeRanges:error:
ensureFeatureWithDescription:isOptional:error:
ensureFeatureWithDescription:isOptional:isFreelyShapedMultiArrayWithDataType:error:
ensureIsValidHallucinatorV1Model:error:
toMLMultiArrayConvertFromFloatScalar:error:
dictionaryWithDictionary:
toFloatScalarConvertFromMLMultiArray:error:
packageHallucinatorInputFeaturesForegroundAudio:backgroundAudio:repetitionCounter:datasetIdentifier:shiftAmount:originalSegmentLength:state:error:
predictionFromFeatures:error:
unpackageHallucinatorOutputs:handler:error:
convertScaleForTimeRange:toValue:preferShrinkingWhenRounding:
clipTimeRange:toBounds:handler:
findBackgroundRegionsSurroundingForegroundSegment:handler:error:
zeroBufferPopulator
flushBytesFromPreciseTimeRangeInAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:intoSink:error:
selectBackgroundNoiseRegionsSurroundingSegment:eligibleTimeSpanPrecedingSegment:eligibleTimeSpanFollowingSegment:handler:error:
findBackgroundRegionsSurroundingForegroundSegments:handler:error:
flushBytesFromStreamSource:toBuffer:ofSizeInBytes:error:
resampleOneSegment:toSampleRate:
createMultiArrayContainingPreciseTimeRangeOfAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:numDimensions:error:
applyHallucinator:foregroundAudio:backgroundAudio:repetitionCounter:datasetIdentifier:shiftAmount:originalSegmentLength:state:handler:error:
hallucinateOneTimeShiftedSegment:hallucinator:hallucinatorStateFetcher:backgroundAudio:datasetIdentifier:shiftAmount:originalSegmentLength:numRepetitionsPerTimeShift:handler:error:
resampleSegments:toSampleRate:
extractBackgroundNoiseMatchingLength:fromSegments:error:
generateHallucinateFunctionWithHallucinator:backgroundAudio:numRepetitionsPerTimeShift:handler:error:
emitTimeShiftsForManySegments:shiftWindow:randomNumberGenerator:numTimeShiftsPerSegment:datasetIdentifier:foregroundAudioLength:handler:error:
pseudoRandomNumberGeneratorWithSeed:
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
featurizeFiles:randomNumberGenerator:hallucinatorModelURL:error:
randomlyShiftTimeRange:byAmountWithinWindow:randomNumberGenerator:
resizeSegments:toDuration:
setFileItems:
initWithFileItems:
fileItems
_fileItems
T@"NSArray",&,N,V_fileItems
dictionary
initWithRemoteAnalyzerGenerator:queue:
_invalidateAnalyzer:
_invalidateActiveAnalyzer
copy
_removeAllRequests
connectionLostError
sleepForTimeInterval:
_acquireSystemAudioAnalyzer
removeAllObjects
_setAudioConfiguration:
_addRequest:withObserver:
_removeRequest:
invalidateActiveAnalyzer
_registeredRequests
_analyzer
_generator
_audioConfiguration
setIdentifier:
setIdsDeviceID:
setModel:
setName:
initWithIdentifier:idsDeviceID:model:name:
idsDeviceID
_idsDeviceID
_name
T@"NSString",&,N,V_identifier
T@"NSString",&,N,V_idsDeviceID
T@"NSString",&,N,V_model
T@"NSString",&,N,V_name
isEqualToSpeechEmotionRequest:
bytes
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
initWithSampleRate:channelCount:
initWithDouble:
initWithUnsignedInt:
setChannelCount:
TI,N,V_channelCount
initWithTimeBetweenTriggers:
removeOverlappingResults:
_timeBetweenTriggers
_lastResult
shapeNonUnitaryDimensionCount:
predictedProbabilitiesName
predictedFeatureName
exceptionWithName:reason:userInfo:
feedbackConnections:
denylistFromModelDescription:
dictionaryValue
filterClassLabelsInDictionary:usingDenylist:
initWithClassificationDictionary:
setClassifierIdentifier:
completeTimingInfoInResult:usingBox:modelBlockSize:
initWithMLModel:overlapFactor:windowDuration:classifierIdentifier:error:
classifierIdentifier
_modelBlockSize
_feedbackConnections
_classLabelsDenylist
_classifierIdentifier
T{?=qiIq},R,V_windowDuration
T@"NSString",R,V_classifierIdentifier
filteredClassLabelsFromModelDescription:
createSoundClassifierVersion1
initWithMLModel:error:
isEqualToClassifySoundRequest:
decodeObjectForKey:
knownClassificationsForClassifierIdentifier:error:
initWithClassifierIdentifier:error:
knownClassifications
_knownClassifications
T@"NSString",&,V_classifierIdentifier
T{?=qiIq},V_windowDuration
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"NSArray",R,C,V_knownClassifications
modelChannelCount:
initWithFormat:
framePosition
readIntoBuffer:frameCount:error:
sendErrorToAllRequests:
analyzeAudioBuffer:atAudioFramePosition:
frameLength
advanceSamples:withHandler:
completeAnalysis
fullFileTimeRange
detailedDescription
analyzeWithCompletionHandler:
cancelAnalysis
_audioFile
_streamAnalyzer
_wasCancelled
initWithRequestType:
decisionDelay
requestType
isEqualToDetectSpeechUtteranceRequest:
_requestType
Tq,R,V_requestType
softVAD
hardVAD
TB,R,N
clientResultsFromProcessorResults:
clientSampleTimeFromSampleTime:fromBox:
clientSampleRate
dictionaryWithCapacity:
timeConversionDictionary
T@"NSDictionary",R
addEntriesFromDictionary:
valueForKey:
convertTime:fromBox:usingConverter:
setValue:forKey:
convertTimeRange:fromBox:usingConverter:
initWithAnalyzer:completionHandler:resultsHandler:timeConverter:
handleDSPGraphPostRenderCallbackFromBox:numFrames:
handleAnalyzerCompletion
handleAnalyzerError:
requestDidReturnError:
primeAnalyzerGraph
requestState
setRequestState:
_timeConverter
_resultsHandler
_completionHandler
_requestState
T@,R,N
Tq,N,V_requestState
initWithSoundIdentifier:
defaultDetectorIdentifierForSoundIdentifier:
initWithDetectorVariant:soundIdentifier:
splitDetectorInfoForDetectorIdentifier:
initWithDetectorVariant:soundIdentifier:modelConfiguration:
isEqualToDetectSoundRequest:
T@"NSArray",R,D,N
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithDetectorIdentifier:error:
initWithVGGishBasedMLModel:soundIdentifier:
modelConfiguration
setModelConfiguration:
_detectorVariant
_modelConfiguration
T@"MLModelConfiguration",&,N,V_modelConfiguration
initWithModel:approximateOverlapFactor:
initWithMLModel:detectorIdentifier:outputLabel:sampleRate:windowLengthFrames:stepSizeFrames:featureExtractorConfiguration:
sharedLockedVGGishFeatureExtractorWithModelConfiguration:
detectorConfigurationWithLogMelBasedFeatureExtractor:detectorHead:detectorIdentifier:soundIdentifier:
detectorHeadConfigurationForDetectorIdentifier:soundIdentifier:modelConfiguration:
sharedLockedModelOfClass:modelConfiguration:
sharedLockedSoundPrint100kFeatureExtractorWithModelConfiguration:
detectorConfigurationWithAudioBasedFeatureExtractor:detectorHead:detectorIdentifier:
detectorHeadConfigurationForDetectorVariant:soundIdentifier:modelConfiguration:
T{shared_ptr<DSPGraph::Graph>=},R,N
T^{Box=},R,N
initWithBox:fromGraph:
startRecordingPort:toFile:
stopRecordingPort:
startInjectingPort:toFile:shouldLoop:
stopInjectingPort:
numInputs
numOutputs
getParameterList:numParameterIDs:inScope:
getParameterInfo:forID:inScope:
getParameter:forID:scope:element:
hasParameter:scope:element:
setParameter:forID:scope:element:bufferOffset:
_box
T^v,R,N,V_box
Tq,R,N
T@"NSString",R,N
idsDeviceIdentifier
setLocalDeviceUpdatedHandler:
setDeviceLostHandler:
setDeviceFoundHandler:
setDeviceChangedHandler:
isOptional
sizeRangeForDimension
rangeValue
enumeratedShapes
ensureMultiArrayConstraint:hasDataType:error:
ensureMultiArrayShapeConstraint:hasDimensionSizeRanges:error:
ensureMultiArrayShapeConstraint:hasShapeOptions:error:
ensureMultiArrayIsFreelyShapedByShapeConstraint:error:
ensureMultiArrayIsRequiredByFeatureDescription:error:
ensureMultiArrayConstraint:hasDataType:andDimensionSizeRanges:error:
ensureMultiArrayConstraint:hasDataType:andShapeOptions:error:
ensureMultiArrayIsFreelyShapedWithConstraint:hasDataType:error:
valueForEntitlement:error:
boolValue
isCurrentProcessEntitledToHostDaemon
createFileServer
currentRunLoop
isInternalBuild
initWithRootDirectory:
_fileServer
isEqualToLogMelBasedFeatureExtractorConfiguration:
logMelStepSize
_logMelStepSize
TI,R,V_logMelStepSize
setInterface:forSelector:argumentIndex:ofReply:
defaultMaxCacheSize
initWithWrappedModel:maxCacheSize:
initWithWrappedModel:
withWrappedModel:maxCacheSize:
withWrappedModel:
wrappedModel
_maxCacheSize
_cacheStorage
_cacheAccessRecency
_wrappedModel
T@"<SNMLModel>",R,V_wrappedModel
strongToWeakObjectsMapTable
sharedLockedModelWithKey:orCreateNewModelWithWithFunction:
_vendedModels
initWithConfiguration:error:
createModelOfClass:modelConfiguration:
sharedLockedModelOfClass:memoized:modelConfiguration:
vggishFeatureExtractorModelClass
soundPrint100kFeatureExtractorModelClass
soundPrintAFeatureExtractorModelClass
soundPrintKFeatureExtractorModelClass
createModelOfClass:
soundClassifierVersion1Modelclass
sharedLockedModelOfClass:
vggishModelClassForSoundIdentifier:
createVGGishFeatureExtractorWithModelConfiguration:
createSoundPrint100kFeatureExtractorWithModelConfiguration:
soundprint100kModelClassForSoundIdentifier:
sharedLockedSoundPrintAFeatureExtractorWithModelConfiguration:
sharedLockedSoundPrintKFeatureExtractor
createSharedLockedSoundClassifierVersion1
isEqualToFeaturePrint:
cosineSimilarityBetweenOneFeaturePrint:andAnotherFeaturePrint:error:
cosineSimilarityBetweenOneOneFeaturePrint:andAnotherFeaturePrint:error:
cosineSimilarityToFeaturePrint:error:
_featureVector
Tq,R,N,V_featurePrintType
T@"MLMultiArray",R,N,V_featureVector
request
setRequest:
resultsHandler
setResultsHandler:
completionHandler
setCompletionHandler:
analyzerHost
setAnalyzerHost:
sharedProcessor
setSharedProcessor:
configured
setConfigured:
configurationError
setConfigurationError:
_configured
_request
_analyzerHost
_sharedProcessor
_configurationError
T@"<SNAnalyzerCreating>",&,N,V_request
T@?,C,N,V_resultsHandler
T@?,C,N,V_completionHandler
T@"SNAnalyzerHost",&,N,V_analyzerHost
T@"<SNProcessing>",&,N,V_sharedProcessor
TB,N,V_configured
T@"NSError",&,N,V_configurationError
isFormatPCM:
updateProcessingTreeFormat:
stopRecording
dealloc
removeObject:
addRequest:completionHandler:resultsHandler:error:
addResult:
indexOfObjectIdenticalTo:
completionHandlerWithClientCompletionHandler:forRequest:
resultsHandlerWithClientResultsHandler:forRequest:
createAnalyzerInfoForRequest:completionHandler:resultsHandler:error:
configureAnalyzer:withFormat:
arrayByAddingObject:
arrayWithArray:
removeObjectAtIndex:
removeAnalyzerInfoForRequest:
sharedProcessorWithConfiguration:
updateTreeProcessingContexts
handleAnalysisPrimingError
format
configureAnalysisTreeWithFormat:
splitBuffer:intoBuffersWithFrameCount:
handleAnalyzeAudioBufferError
date
setDateFormat:
stringFromDate:
stringByAppendingPathExtension:
initWithDirectoryPath:fileNameWithoutExtension:dateString:soundIdentifier:
initWithDSPGraph:
stopRecordingBoxesInGraph:
directoryPath
fileNameWithoutExtension
audioFileFrameCount:
detectionResults
detectionCountInResults:
defaultManager
removeItemAtPath:error:
writeResultsToFileWithAudioFrameCount:error:
analyzerInfoForRequest:
analyzeAudioBufferList:withAudioFrameCount:atAudioFramePosition:
writeDSPGraphDotFilesToDirectory:
startRecordingToDirectory:requestDescription:error:
_processorCache
_processingContexts
_processingTree
_currentFormat
_analyzerInfos
_resultsLogger
_shouldRebuildProcessingTree
startRecordingFirstBoxInGraph:toDirectory:withFileName:error:
initWithInputSensitivity:
isEqualToMeasureLKFSRequest:
inputSensitivity
_inputSensitivity
Tf,R,N,V_inputSensitivity
setQueryPath:
setServiceType:
setDestinationID:
queryPath
performQuery:
initWithServerInfo:queryPath:
_queryPath
T@"NSString",&,N,V_queryPath
unsignedIntegerValue
mutableAudioBufferList
setFrameLength:
frameCapacity
componentsSeparatedByString:
mutableCopy
removeObjectsForKeys:
classLabels
removeObjectsInArray:
vggishFrontEndProcessingOutputShape
constraintWithShape:dataType:
featureDescriptionWithName:type:optional:constraints:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
modelBlockSize:channelCount:
parseFeedbackConnectionsString:
destinationFeatureName
sourceFeatureName
userSuppliedFeatureNames:direction:
subtractSet:from:
minusSet:
whitespaceAndNewlineCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
initWithSourceFeatureName:destinationFeatureName:
processInfo
processName
stringByReplacingOccurrencesOfString:withString:
stringByAppendingString:
_deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filterUsingPredicate:
fileCreationDate:
compare:
sortUsingComparator:
diskSpaceRemainingBytesContainingDirectory:
unsignedLongLongValue
fileSizeBytes:
stringByDeletingPathExtension
attributesOfItemAtPath:error:
attributesOfFileSystemForPath:error:
fileURLWithPath:
initForReading:error:
valueForEntitlement:fromTask:error:
convertScaleForTimeRange:toValue:startRoundingMethod:durationRoundingMethod:
standardizeTime:negativeShouldResideInTimescale:
standardizeTimeRange:directionShouldBePositive:
standardizeTimeRange:negativeShouldResideInTimescale:
makeInvalidTimeRange
getTimeRangeEncompassingEntireAudioFile:
processFrameCount:bufferFactory:populator:handler:completionHandler:
channelLayout
initWithStreamDescription:channelLayout:
initSecondaryReader:format:error:
readFramesFromAudioFile:frameCount:maxFramesPerBuffer:recycleBuffers:handler:error:
readFramesFromAudioFile:frameCount:atSampleRate:maxFramesPerBuffer:recycleBuffers:handler:error:
readPreciseTimeDurationFromAudioFile:timeDuration:maxFramesPerBuffer:recycleBuffers:handler:error:
readPreciseTimeRangeFromAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
flushAudioBuffer:channelIndex:intoSink:error:
commonFormat
loadContentsOfURL:configuration:completionHandler:
silenceUnfilledFramesInBuffer:
copyAudioBufferList:to:frameCount:bytesPerFrame:
multiArrayConstraintLastDimensionIsFlexible:
isRunningInDaemon
loggingPrefixForRequest:
deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
checkTimeRange:isIdenticalToOther:
readApproximateTimeDurationFromAudioFile:timeDuration:roundingMethod:maxFramesPerBuffer:recycleBuffers:handler:error:
readApproximateTimeRangeFromAudioFile:timeRange:preferShrinkingWhenRounding:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
automaticallyNotifiesObserversForKey:
willChangeValueForKey:
didChangeValueForKey:
clearResults
clearErrors
clearCompleteCount
completeCount
_results
_errors
_completeCount
Tq,R,N,V_completeCount
initWithCompletionHandler:resultsHandler:
setIsCancelled:
cancel
_isCancelled
TB,V_isCancelled
_sourceFeatureName
_destinationFeatureName
T@"NSString",R,V_sourceFeatureName
T@"NSString",R,V_destinationFeatureName
initWithStreamDescription:
setVariableSliceDuration:forSampleRate:
sliceDurationInSamples
initialized
configure
unconfigure
initialize
uninitialize
reset
getParameter:forID:
hasParameter:
setParameter:forID:
getPropertySize:isWritable:forID:
getProperty:withSize:forID:
setProperty:withSize:forID:
boxWithName:
boxes
numberOfInputs
numberOfOutputs
writeDotFileToPath:
T@"NSString",C,N
setObject:atIndexedSubscript:
shapeFromMultiArrayConstraint:lastDimensionCountIfFlexible:
initWithFeatureDescription:allInputFeatureNames:elementCountPerChannel:channelCount:
setFeatureValue:forFeatureName:
input
setInput:
_featureDescription
_featureCache
_allInputFeatureNames
_input
T@"MLMultiArray",&,N,V_input
feedbackConnections
setFeedbackConnections:
inputProvider
setInputProvider:
setOutputProvider:
_inputProvider
_outputProvider
T@"<SNMLModel>",&,N,V_model
T@"NSArray",&,N,V_feedbackConnections
T@"DSPGMLInputProvider",&,N,V_inputProvider
T@"<MLFeatureProvider>",&,N,V_outputProvider
compileModelAtURL:error:
modelWithContentsOfURL:error:
filename
setFilename:
fileSize
setFileSize:
itemURL
setItemURL:
initWithFileItem:
_filename
_fileSize
_itemURL
T@"NSString",&,N,V_filename
Tq,N,V_fileSize
T@"NSURL",&,N,V_itemURL
initWithConfidence:timeRange:
Td,R,N,V_confidence
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
minDurationBlocks
confidenceThreshold
arrayWithCapacity:
initWithCommand:
processNewTimestep:timeRange:
history
_maxHistoryLength
_confidenceThreshold
_streak
_history
T@"NSString",R,N,V_name
T@"NSMutableArray",R,N,V_history
initWithCommands:
processNewResults:timeRange:
commandFilters
_commandFilters
T@"NSArray",R,N,V_commandFilters
offset
setOffset:
isEqualToAudioOffsetResult:
_offset
Td,N,V_offset
setServerFilePaths:
setLocalDestinationPath:
deregisterRequestID:
registerRequestID:options:handler:
getIdentitiesWithCompletion:
edPKData
serverFilePaths
flags
setFlags:
prepareTemplateAndReturnError:
localDestinationPath
fileURLWithPath:isDirectory:
setTemporaryDirectoryURL:
setReceivedItemHandler:
setPeerPublicKey:
setTargetID:
activate
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
_serverFilePaths
_localDestinationPath
T@"NSArray",&,N,V_serverFilePaths
T@"NSString",&,N,V_localDestinationPath
initWithFirstPassRequest:secondPassRequest:historicalDataAmount:
firstPassRequest
secondPassRequest
historicalDataAmount
_firstPassRequest
_secondPassRequest
_historicalDataAmount
T@"<SNRequest>",R,V_firstPassRequest
T@"<SNRequest>",R,V_secondPassRequest
Td,R,V_historicalDataAmount
floatChannelData
initWithAudioTimeStamp:sampleRate:
initWithBufferHandler:queue:recordFormat:
handleAudioBufferCallbackForQueue:buffer:startTime:numberPacketDescriptions:packetDescriptions:
_bufferHandlerQueue
_bufferHandler
_transaction
_recordFormat
_stop
opaqueSessionID
initWithFormat:audioQueueConfiguration:
startHandlingBuffersOnQueue:audioSession:handler:
_audioQueueConfiguration
_running
_audioQueue
_aqCallbackScheduler
anyObject
isAllowedShape:error:
preProcessCallback
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
setPreProcessCallback:
_inputConstraint
_outputConstraint
_scratchFloatSpace
_modelOutput
_preProcessCallback
T@?,C,N,V_preProcessCallback
removeRequestAsync:
_addRequest:completionHandler:resultsHandler:error:
_addTwoPassRequest:completionHandler:resultsHandler:error:
_addSinglePassRequest:completionHandler:resultsHandler:error:
handleBeginSecondPassForRequest:secondPassController:completionHandler:resultsHandler:
setBeginSecondPassHandler:
handleEndSecondPassForRequest:
setEndSecondPassHandler:
firstPassDidProduceResult:
dateByAddingTimeInterval:
valueWithNonretainedObject:
shouldRecordSecondPass
secondPassRecordingPath
deleteWAVAndTextFilesCreatedBeforeLastWeekInDirectory:
secondPassDidProduceResult:
_removeTwoPassRequest:
_removeSinglePassRequest:
_analyzeAudioBuffer:atAudioFramePosition:
string
appendString:
_analyzerQueue
_firstPassAnalyzer
_secondPassAnalyzers
_ringBuffer
_ringBufferWriteBufferList
createUltronResultsDictionaryFromDetectionResults:
createUltronFinalDictionaryWithDetectionResults:dateString:fileNameWithoutExtension:soundIdenfifier:frameCount:
writeDictionaryAsJSON:fileNameWithoutExtension:directoryPath:error:
dataWithJSONObject:options:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToFile:options:error:
_dateString
_wroteResults
_startingTime
_detectionResults
_directoryPath
_fileNameWithoutExtension
T@"NSString",R,V_directoryPath
T@"NSString",R,V_fileNameWithoutExtension
T@"NSArray",R,V_detectionResults
_minDurationBlocks
Tq,R,N,V_minDurationBlocks
Td,R,N,V_confidenceThreshold
initWithModel:request:
isEqualToMeasureDetectVoiceTriggerRequest:
initWithModel:dictionary:error:
hopSizeSamples
setHopSizeSamples:
blocksBetweenTriggers
setBlocksBetweenTriggers:
commands
setCommands:
_hopSizeSamples
_blocksBetweenTriggers
_commands
Td,R,N,V_sampleRate
Tq,N,V_hopSizeSamples
Tq,N,V_blocksBetweenTriggers
T@"NSArray",C,N,V_commands
_modelOutputFilter
_overlapFilter
setLink:
link
setProgressHandler:
rootDirectory
addItem:
finish
server
createDefaultServer
setServer:
setRootDirectory:
_server
_link
_rootDirectory
T@"CUFileServer",&,N,V_server
T@"RPCompanionLinkClient",&,N,V_link
T@"NSString",&,N,V_rootDirectory
setRootDirectoryURL:
pathExtension
boxName
setBoxName:
busIndex
setBusIndex:
_boxName
_busIndex
T@"NSString",&,V_boxName
Tq,V_busIndex
T@"NSString",&,V_fileName
startRecordingWithBoxRecordingInfos:inGraph:toDirectory:error:
startRecordingBoxes:inGraph:toDirectory:error:
startInjectingBoxes:inGraph:error:
stopInjectingBoxesInGraph:
initWithSampleRate:blockSize:computationalDutyCycle:graphIsDeadEnded:shouldThrowException:
computationalDutyCycle
setComputationalDutyCycle:
graphIsDeadEnded
setGraphIsDeadEnded:
shouldThrowException
setShouldThrowException:
isEqualToNullRequest:
_graphIsDeadEnded
_shouldThrowException
_computationalDutyCycle
Td,N,V_computationalDutyCycle
TB,N,V_graphIsDeadEnded
TB,N,V_shouldThrowException
initWithCommonFormat:sampleRate:channels:interleaved:
defaultCenter
handleAVAudioSessionInterruption:
addObserver:selector:name:object:
handleAVAudioSessionRouteChange:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
_addRequest:withObserver:error:
startAudio
stopAudio
initAuxiliarySession
category
mode
options
setCategory:mode:options:error:
setActive:error:
sampleTime
handleAudioStreamInterrupted
_dispatchQueue
_analysisQueue
_recordingQueue
_recordingState
_clientStartedAnalysis
_audioSession
makeHandlerForUInt32ParameterWithBlock:
makeHandlerForFloatParameterWithBlock:
makeHandlerForInt32ParameterWithBlock:
makeHandlerForStringParameterWithChoices:block:
defaultLogMelExtractionParameters
overrideLogMelExtractionParameters:withContentsOfParameterDictionary:error:
resetLogMelExtractionParameters:overrideWithParameterDictionary:error:
validateModelDescription:logMelExtractionParameters:withHandler:error:
initWithDataPointer:shape:dataType:strides:deallocator:error:
_logMelExtractionParameters
stringMapFromStringDictionary:
stringVectorFromStringArray:
_interpreter
isEqualToEstimateAudioOffsetRequest:
updateMinMaxDelayWithSampleRate:micDelay:refDelay:eclen:
setMinimumObservableOffset:
minimumObservableOffset
setMaximumObservableOffset:
maximumObservableOffset
_minimumObservableOffset
_maximumObservableOffset
Td,R,N,V_offset
Td,N,V_minimumObservableOffset
Td,N,V_maximumObservableOffset
initWithIdentifier:confidence:
classificationsFromClassificationDictionary:
enumerateKeysAndObjectsUsingBlock:
_init
classificationDictionary
setClassificationDictionary:
isEqualToClassificationResult:
classificationForIdentifier:
classifications
_cachedClassifications
_classificationDictionary
T@"NSDictionary",C,N,V_classificationDictionary
T@"NSString",C,N,V_classifierIdentifier
T@"NSArray",R,C
isEqualToClassification:
T@"NSString",R,C,V_identifier
Td,R,V_confidence
modelURLForCurrentProduct
isEqualToSignalThresholdResult:
isEqualToAudioConfiguration:
setCategory:
setMode:
setOptions:
_category
_mode
_options
T@"NSString",C,N,V_category
T@"NSString",C,N,V_mode
TQ,N,V_options
hasPrefix:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:matcher:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:
generateInputFeatureMappingsFromOuterDescription:toInnerDescription:
generateOutputFeatureMappingsFromOuterDescription:toInnerDescription:
innerInputFeatureProviderFromOuter:outerToInnerInputFeatureNameMappings:error:
outerOutputFeatureProviderFromInner:outerToInnerOutputFeatureNameMappings:error:
initWithModel:modelDescription:
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
removeLastObject
validateModelDescription:underlyingModelDescription:error:
_outputShape
beginSecondPassHandler
endSecondPassHandler
T@?,C
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassTriggerTime
_firstResultBelowEndThresholdStartTime
_secondPassIsActive
_firstPassResultToComparableFunction
_secondPassResultToComparableFunction
_beginSecondPassHandler
_endSecondPassHandler
T@?,C,V_beginSecondPassHandler
T@?,C,V_endSecondPassHandler
_featureExtractorConfiguration
_outputLabel
T@"<SNProcessorCreating>",R,N,V_featureExtractorConfiguration
T@"NSString",R,N,V_detectorIdentifier
T@"<SNMLModel>",R,N,V_model
T@"NSString",R,N,V_outputLabel
TI,R,N,V_windowLengthFrames
TI,R,N,V_stepSizeFrames
audioProcessorWithConfiguration:
createAudioProcessorWithConfiguration:
_activeProcessorsCache
isEqualToNullResult:
peakTime
peakValue
channelIndex
_peakValue
_channelIndex
_peakTime
Td,N,V_peakValue
T{?=qiIq},N,V_peakTime
Tq,N,V_channelIndex
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
remoteObjectProxyWithErrorHandler:
_remoteObservers
initWithSoundprint_Placeholder:
soundprint_Placeholder
setSoundprint_Placeholder:
_soundprint_Placeholder
T@"MLMultiArray",&,N,V_soundprint_Placeholder
initWithSigmoid:
Sigmoid
setSigmoid:
_Sigmoid
T@"MLMultiArray",&,N,V_Sigmoid
pathForResource:ofType:
URLOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
initWithMLModel:
modelWithContentsOfURL:configuration:error:
initWithFeatureProviderArray:
featuresAtIndex:
loadWithConfiguration:completionHandler:
predictionFromSoundprint_Placeholder:error:
predictionsFromInputs:options:error:
T@"MLModel",R,N,V_model
initWithInput1:stateIn:detectedHistoryIn:
initWithInput1:
input1
setInput1:
stateIn
setStateIn:
detectedHistoryIn
setDetectedHistoryIn:
_input1
_stateIn
_detectedHistoryIn
T@"MLMultiArray",&,N,V_input1
T@"MLMultiArray",&,N,V_stateIn
T@"MLMultiArray",&,N,V_detectedHistoryIn
initWithInput_1:Confidence:Detected:detectedHistoryOut:
input_1
setInput_1:
Confidence
Detected
detectedHistoryOut
setDetectedHistoryOut:
_input_1
_Confidence
_Detected
_detectedHistoryOut
T@"MLMultiArray",&,N,V_input_1
T@"MLMultiArray",&,N,V_Confidence
T@"MLMultiArray",&,N,V_Detected
T@"MLMultiArray",&,N,V_detectedHistoryOut
predictionFromInput1:stateIn:detectedHistoryIn:error:
initWithOutput1:
output1
setOutput1:
_output1
T@"MLMultiArray",&,N,V_output1
predictionFromInput1:error:
initWithAudioSamples:
audioSamples
setAudioSamples:
_audioSamples
T@"MLMultiArray",&,N,V_audioSamples
initWith_637:
_637
set_637:
__637
T@"MLMultiArray",&,N,V__637
predictionFromAudioSamples:error:
featureValueWithDictionary:error:
featureValueWithString:
initWith_646:classLabel:
_646
set_646:
classLabel
setClassLabel:
__646
_classLabel
T@"NSDictionary",&,N,V__646
T@"NSString",&,N,V_classLabel
stringValue
initWithFixedLengthEmbedding:framewiseEmbedding:
fixedLengthEmbedding
setFixedLengthEmbedding:
framewiseEmbedding
setFramewiseEmbedding:
_fixedLengthEmbedding
_framewiseEmbedding
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
T@"MLMultiArray",&,N,V_framewiseEmbedding
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
v20@0:8f16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
q16@0:8
v16@0:8
@"MLModel"
@"NSString"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
v24@0:8q16
@"SNTimeDurationConstraint"
{?="value"q"timescale"i"flags"I"epoch"q}
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@32@0:8@16@24
@52@0:8q16f24{?=qiIq}28
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@32@0:8@16Q24
v24@0:8Q16
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
v20@0:8I16
@?16@0:8
v24@0:8@?16
@20@0:8I16
v24@0:8^{OpaqueAudioQueue=}16
v28@0:8I16^{OpaqueAudioQueue=}20
@"NSError"
@40@0:8@16@24@32
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
v32@0:8@16@24
@"NSMutableArray"
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
@"SNDetectSignalThresholdRequestImpl"
@36@0:8d16I24d28
@40@0:8q16@24@32
v48@0:8^@16q24@32@40
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@32@0:8@16d24
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@40@0:8@16@?24@32
@32@0:8@?16@24
@"NSXPCConnection"
I20@0:8I16
@"NSUserDefaults"
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
v36@0:8@16I24^v28
@"SNDetectorHeadConfiguration"
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
v20@0:8B16
@32@0:8#16@24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@32@0:8@16@?24
@"SNTwoPassConfiguration"
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"NSNumber"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"NSURL"
@?20@0:8I16
@32@0:8@16^@24
@56@0:8@16{?=qiIq}24^@48
@56@0:8{?=qiIq}16@40^@48
@56@0:8q16@24@32@40^@48
@48@0:8@16@24Q32^@40
@48@0:8@16@24@?32^@40
B120@0:8{?=qiIq}16@40Q48{?=qiIq}56@80@88@?96@?104^@112
@48@0:8@16@24@32@?40
@84@0:8@16i24i28i32i36@40i48@52@?60@68^@76
@48@0:8@16@?24@32^@40
@56@0:8@16@?24@32@40^@48
{?=qiIq}72@0:8{?={?=qiIq}{?=qiIq}}16@?64
{?={?=qiIq}{?=qiIq}}120@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64@?112
B136@0:8@16{?={?=qiIq}{?=qiIq}}24@?72Q80@88{?=qiIq}96@?120^@128
i32@0:8@16^@24
@80@0:8@16@24@32@40@48@56@64^@72
B40@0:8@16@?24^@32
B96@0:8@16@24@32@40@48@56@64@72@?80^@88
B136@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72@?120^@128
@48@0:8@16{?=qiIq}24
@28@0:8@16i24
B96@0:8@16@24@?32@40@48@56@64Q72@?80^@88
@?56@0:8@16@24Q32@?40^@48
@80@0:8@16@24{?=qiIq}32@56@?64^@72
@"SNAudioConfiguration"
@48@0:8@16@24@32@40
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@28@0:8d16I24
@40@0:8{?=qiIq}16
@"SNVoiceTriggerResult"
v36@0:8@16^v24I32
@72@0:8@16d24{?=qiIq}32@56^@64
I28@0:8I16@?20
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
{?=qiIq}56@0:8{?=qiIq}16^v40@48
{?={?=qiIq}{?=qiIq}}80@0:8{?={?=qiIq}{?=qiIq}}16^v64@72
@48@0:8@16@?24@?32@40
v28@0:8^v16i24
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@28@0:8@16B24
@"SNDetectorVariant"
@"MLModelConfiguration"
{shared_ptr<DSPGraph::Graph>=}16@0:8
@28@0:8^{Box=}16i24
^{Box=}16@0:8
@"NSArray"28@0:8^{Box=}16i24
@40@0:8^v16{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}24
B32@0:8q16@24
B24@0:8q16
B36@0:8q16@24B32
B36@0:8^I16^q24I32
B32@0:8^{AudioUnitParameterInfo=[52c]^{__CFString}I^{__CFString}IfffI}16I24I28
B36@0:8^f16I24I28I32
B28@0:8I16I20I24
B40@0:8f16I20I24I28q32
B36@0:8@16B24^@28
B40@0:8@16q24^@32
B48@0:8@16q24@32^@40
B52@0:8@16B24q28@36^@44
B44@0:8@16B24q28^@36
B48@0:8@16@24@32^@40
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@24@0:8#16
@36@0:8#16B24@28
#24@0:8@16
@48@0:8^f16^f24Q32^@40
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@48@0:8@16@?24@?32^@40
@?32@0:8@?16@24
B48@0:8@16@?24@?32^@40
v36@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16I24q28
v32@0:8@16q24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[32C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"AVAudioFormat"
@"SNUltronResultsLogger"
@20@0:8f16
@28@0:8@16I24
v40@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^{AudioBufferList=I[1{AudioBuffer=II^v}]}24I32I36
i24@0:8@16
{?=qiIq}48@0:8{?=qiIq}16@40
I28@0:8@16I24
I24@0:8@16
{_NSRange=QQ}24@0:8@16
@32@0:8@16q24
v40@0:8@16@24q32
q24@0:8@16
@40@0:8@16^{__SecTask=}24^@32
B112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}76@0:8{?={?=qiIq}{?=qiIq}}16i64I68I72
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16i64B68
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
{?=qiIq}44@0:8{?=qiIq}16B40
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16B64B68
v120@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64@?112
{?={?=qiIq}{?=qiIq}}112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}88@0:8{?=qiIq}16{?={?=qiIq}{?=qiIq}}40
{?={?=qiIq}{?=qiIq}}24@0:8@16
{?={?=qiIq}{?=qiIq}}32@0:8@16^@24
v52@0:8I16@?20@?28@?36@?44
I52@0:8@16I24I28B32@?36^@44
I60@0:8@16I24d28I36B40@?44^@52
{?=qiIq}72@0:8@16{?=qiIq}24I48B52@?56^@64
{?=qiIq}76@0:8@16{?=qiIq}24I48I52B56@?60^@68
B112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88@?96^@104
B116@0:8@16{?={?=qiIq}{?=qiIq}}24B72I76B80@?84@?92@?100^@108
B48@0:8@16Q24@?32^@40
B48@0:8@?16^v24Q32^@40
@112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88Q96^@104
@40@0:8@16d24^@32
@32@0:8@?16@?24
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@32@0:8{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16
B32@0:8q16q24
B28@0:8^f16I24
B20@0:8I16
B24@0:8f16I20
B36@0:8^I16^B24I32
B36@0:8^v16^I24I32
B32@0:8r^v16I24I28
@40@0:8@16@24I32I36
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@72@0:8d16{?={?=qiIq}{?=qiIq}}24
@72@0:8@16{?={?=qiIq}{?=qiIq}}24
@"<SNRequest>"
@40@0:8@?16@24@32
v52@0:8^{OpaqueAudioQueue=}16^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}24r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}32I40r^{AudioStreamPacketDescription=qII}44
@"NSObject<OS_os_transaction>"
B40@0:8@16@24@?32
@"SNAudioQueueConfiguration"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@56@0:8@16@24@32{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>={__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>=^{Graph}}}40^@48
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
v48@0:8@16@24@?32@?40
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@56@0:8@16@24@32@40q48
B32@0:8q16^@24
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
@"SNNullDetector"
@44@0:8d16I24d28B36B40
@"SNAudioRecordingQueue"
@"AVAudioSession"
@?32@0:8@16@?24
@?24@0:8@?16
{SNLogMelParameters=fIffiIIIIii}16@0:8
B40@0:8^{SNLogMelParameters=fIffiIIIIii}16@24^@32
B84@0:8@16{SNLogMelParameters=fIffiIIIIii}24@?68^@76
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}24@0:8@16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}24@0:8@16
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
v32@0:8f16f20f24f28
@40@0:8@16@24@?32
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@56@0:8d16d24d32@?40@?48
@64@0:8@16@24@32d40I48I52@56
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
?N8DSPGraph9ExceptionE
St9exception
St13runtime_error
St12length_error
St11logic_error
@xfuapraexoba
mron
xfuapargxoba
MbP?NSt3__117bad_function_callE
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
cmcp!
mcpl)
mcpl,
xfuadgisxoba
xfuaftmlxoba
timeRange
decibelLevel
type
detectorIdentifier
cannot encode MLModel
cannot copy MLModel
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/fed91392-8650-11ec-bf32-6613bcf0e2ee/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator15.4.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
b238a_mic_voice_recognition_bf.dspg
PropertyStrip
b238a_mic_voice_recognition_bf.propstrip
AUStrip
b238a_mic_voice_recognition_bf.austrip
Failed to create graph
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
v8@?0
illegal call to unavailable init selector: %s
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v16@?0^{OpaqueAudioQueue=}8
Applause
Babble
Cheering
Laughter
Music
Speech
Distressed Baby
Smoke Alarm
Fire Alarm
Doorbell
Buzzer
Beep
Ding Bell
Dog Bark
Cat Meow
Door Knock
Shouting
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
Processing tree graph is null
.dot
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
spatialSpectrum
%@ azmimuth: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
enable_second_pass_recording_in_daemon
daemon_recording_path
recording_directory_maximum_size_bytes
recording_time_to_live_seconds
delete_recordings_without_detection
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
enable_verbose_logging
SoundAnalysisAnonymousClient
Library
Caches
AudioCaptures
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
%@ detected: %@
IncludePaths
Substitutions
Value
SNSoundPrintFeatureExtractorConfiguration.mm
overlapFactor >= 0.0 && overlapFactor < 1.0
VerifyNotTrashingOwnedBuffer
mBufferMemory == NULL
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
com.apple.SoundAnalysis.remoteanalyzer
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
embedding
label
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
feature
tokenGroup
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
Error setting up hallucinator input.
Error running inference on hallucinator.
hallucinated
Error creating negatives MLMultiArray.
MLModelCreatorDefinedKey
numTokenGroups
Unable to load hallucinator metadata.
Error shifting segment.
Error clipping segment to file bounds.
Error sizing segment to match extended exemplar.
Error calculating embeddings.
Failed to hallucinate feature.
Failed to generate negative.
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
v20@?0@"MLMultiArray"8B16
Failed to collect embeddings at single time shift.
Not enough audio segments found to continue.
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifierIdentifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
Unknown classifier identifier
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
Couldn't find soundIdentifier for detectorIdentifier %@
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
SNDSPGraphBox.mm
graph
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
SNLogMelBasedFeatureExtractorConfiguration.mm
approximateOverlapFactor >= 0.0 && approximateOverlapFactor < 1.0
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
Audio format must be PCM
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
yyyy-MM-dd-HHmmss
%@_%@
yyyy-MM-dd HH:mm:ss
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
+[SNUtils copyAudioBufferList:to:frameCount:bytesPerFrame:]
SNUtils.mm
sourceBufferList->mNumberBuffers > 0
sourceBufferList->mNumberBuffers == destinationBufferList->mNumberBuffers
sourceBufferList->mBuffers[bufferIdx].mNumberChannels > 0
frameCount*bytesPerFrame <= sourceBufferList->mBuffers[bufferIdx].mDataByteSize
frameCount*bytesPerFrame <= destinationBufferList->mBuffers[bufferIdx].mDataByteSize
denylist
MultiArrayInput
MultiArrayOutput
feedback_connections
soundanalysisd
InternalBuild
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
results
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"SNDSPGraphBox"8@?0
@"NSMutableSet"8@?0
@"NSString"8@?0
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
InvalidFormatException
com.apple.SoundAnalysis.AnalyzerQueue
BuildVersion
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
timestamp
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
RPFTSource
v16@?0@"RPFileTransferProgress"8
%@_%@_bus%ld_%@.caf
%@ startRecordingPort was unsuccessful
SNDSPGraphUtilities
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
B24@?0@8^@16
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B8@?0
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
category
mode
options
%@ %@ %lu
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
SNThresholdBasedSecondPassController.m
secondPassHangoverPeriod >= 0.0
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
soundprint/Placeholder
Sigmoid
SNSoundPrint100kCatMeowModel
mlmodelc
input1
detectedHistoryIn
input_1
detectedHistoryOut
SNVGGishDoorbellModel
SNVGGishDistressedBabyModel
SNVGGishDingBellModel
output1
SNVGGishLaughterModel
SNSoundPrint100kBuzzerModel
SNVGGishApplauseModel
SNVGGishFireAlarmModel
SNSoundPrint100kShoutingModel
audioSamples
SNSoundPrint100kFireAlarmModel
SNSoundPrint100kBeepModel
SNVGGishDoorKnockModel
classLabel
SNSoundClassifierVersion1Model
SNVGGishBabbleModel
SNVGGishDogBarkModel
SNSoundPrint100kDogBarkModel
SNVGGishBeepModel
SNSoundPrint100kDistressedBabyModel
SNSoundPrint100kDoorbellModel
SNSoundPrint100kSmokeAlarmModel
SNVGGishShoutingModel
SNVGGishSpeechModel
SNVGGishCatMeowModel
SNVGGishSmokeAlarmModel
SNSoundPrintKEmbeddingModel
SNVGGishMusicModel
SNSoundPrint100kDingBellModel
SNVGGishBuzzerModel
SNVGGishCheeringModel
SNSoundPrint100kDoorKnockModel
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) start
(SNSystemAudioAnalyzerXPCPublisher:%@) stop
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel assignment %u with result %d
Could register audio units. Returning nil for %@
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer with In-Process Computation
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
(SNSystemAudioAnalyzerRemote:%@) start
(SNSystemAudioAnalyzerRemote:%@) stop
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
Unknown featureExtractorIdentifier %@
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Unimplemented
Error analyzing audio buffer
Removing %@, since it doesn't contain any detections
Failed to write results log file with error %@
Started recording graph
Failed to start recording graph
No sample rate metadata provided in model. Defaulting to %d
Feedback connection destination %@ not present in model
Feedback connection source %@ not present in model
Couldn't parse feedback connection. Should be 'source -> destination'
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
Failed to open audio file %@ with error %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Queue already running
Failed to create audio queue
Starting audio queue
Stopping audio queue
Completed first pass for request %@ with error %@
Resizing historical ring buffer from %d to %d frames after adding %@
Beginning second pass for request %@
Couldn't begin second pass recording with error %@
Couldn't begin recording, no path set
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Resizing historical ring buffer from %d to %d frames after removing %@
Wrote file %@ at %@ with result %d.
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Box %s doesn't exist in graph
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
(SNSystemAudioAnalyzerLocal:%@) start
(SNSystemAudioAnalyzerLocal:%@) stop
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Audio failed to start. Retrying in %d seconds
Failed to deactivate AVAudioSession with error %@
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature has more than one non-unitary dimension
Additional input feature dimensions must be have size 1
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 input feature
Output feature has more than one non-unitary dimension
Additional output feature dimensions must be have size 1
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) start
(SNSystemAudioAnalyzerXPCSubscriber:%@) stop
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
Could not load SNSoundPrint100kCatMeowModel.mlmodelc in the bundle resource
Could not load SNVGGishDoorbellModel.mlmodelc in the bundle resource
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishDingBellModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kBuzzerModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kShoutingModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kBeepModel.mlmodelc in the bundle resource
Could not load SNVGGishDoorKnockModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNVGGishDogBarkModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDogBarkModel.mlmodelc in the bundle resource
Could not load SNVGGishBeepModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDoorbellModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishShoutingModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishCatMeowModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNVGGishSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDingBellModel.mlmodelc in the bundle resource
Could not load SNVGGishBuzzerModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kDoorKnockModel.mlmodelc in the bundle resource
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNSpeechDistanceResult
SNUserDefaults
SNDeleteFilesRequest
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNMLModelCacheKey
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNProcessorCreating
SNDictionaryAdditions
SNResultsXPCSubscriber
SNResultsObserving
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNHallucinatorInputProvider
MLFeatureProvider
SNKShotSegment
0 2@
SNKShotFeaturizer
SNFileListingResult
SNSystemAudioAnalyzerRemote
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNDiscoverFileServerRequest
SNValidateModel
SNDaemon
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNResultsForwarder
SNBooleanCancellable
SNCancellable
SNModelFeatureConnection
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
DSPGMLInputProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNTwoPassConfiguration
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNAudioStreamAnalyzer
SNUltronResultsLogger
SNLogMelBasedFeatureExtractor
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNResultsXPCPublisher
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNSoundPrint100kCatMeowModelInput
SNSoundPrint100kCatMeowModelOutput
SNSoundPrint100kCatMeowModel
SNVGGishDoorbellModelInput
SNVGGishDoorbellModelOutput
SNVGGishDoorbellModel
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishDingBellModelInput
SNVGGishDingBellModelOutput
SNVGGishDingBellModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kBuzzerModelInput
SNSoundPrint100kBuzzerModelOutput
SNSoundPrint100kBuzzerModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNSoundPrint100kShoutingModelInput
SNSoundPrint100kShoutingModelOutput
SNSoundPrint100kShoutingModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrint100kBeepModelInput
SNSoundPrint100kBeepModelOutput
SNSoundPrint100kBeepModel
SNVGGishDoorKnockModelInput
SNVGGishDoorKnockModelOutput
SNVGGishDoorKnockModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNVGGishDogBarkModelInput
SNVGGishDogBarkModelOutput
SNVGGishDogBarkModel
SNSoundPrint100kDogBarkModelInput
SNSoundPrint100kDogBarkModelOutput
SNSoundPrint100kDogBarkModel
SNVGGishBeepModelInput
SNVGGishBeepModelOutput
SNVGGishBeepModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kDistressedBabyModelInput
SNSoundPrint100kDistressedBabyModelOutput
SNSoundPrint100kDistressedBabyModel
SNSoundPrint100kDoorbellModelInput
SNSoundPrint100kDoorbellModelOutput
SNSoundPrint100kDoorbellModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishShoutingModelInput
SNVGGishShoutingModelOutput
SNVGGishShoutingModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNVGGishCatMeowModelInput
SNVGGishCatMeowModelOutput
SNVGGishCatMeowModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNVGGishSmokeAlarmModelInput
SNVGGishSmokeAlarmModelOutput
SNVGGishSmokeAlarmModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNSoundPrint100kDingBellModelInput
SNSoundPrint100kDingBellModelOutput
SNSoundPrint100kDingBellModel
SNVGGishBuzzerModelInput
SNVGGishBuzzerModelOutput
SNVGGishBuzzerModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNSoundPrint100kDoorKnockModelInput
SNSoundPrint100kDoorKnockModelOutput
SNSoundPrint100kDoorKnockModel
allocWithZone:
init
timeRange
setTimeRange:
decibelLevel
setDecibelLevel:
isEqualToLKFSResult:
valueWithCMTimeRange:
isEqual:
hash
numberWithFloat:
decodeObjectOfClass:forKey:
decodeDoubleForKey:
CMTimeRangeValue
encodeObject:forKey:
encodeDouble:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},N
_decibelLevel
_timeRange
Tf,N,V_decibelLevel
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
decodeIntegerForKey:
initWithDetectorIdentifier:
encodeInteger:forKey:
raise:format:
detectorIdentifier
isEqualToDetectorVariant:
type
vggishBasedMLModel
numberWithInteger:
initWithVGGishBasedMLModel:
.cxx_destruct
_type
_vggishBasedMLModel
_detectorIdentifier
Tq,R,V_type
T@"MLModel",R,V_vggishBasedMLModel
T@"NSString",R,V_detectorIdentifier
mood
valence
arousal
dominance
confidence
stringWithFormat:
setMood:
setValence:
setArousal:
setDominance:
setConfidence:
isEqualToSpeechEmotionResult:
numberWithDouble:
unarchivedObjectOfClass:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithBinarySampleRepresentation:
initWithBinarySampleRepresentation:metadata:timestamp:
binarySampleRepresentation
Td,R,N
Td,N
_confidence
_mood
_valence
_arousal
_dominance
Td,V_mood
Td,V_valence
Td,V_arousal
Td,V_dominance
Td,N,V_confidence
isEqualToEstimateDirectionOfArrivalRequest:
createAnalyzerWithError:
spatialSpectrum
_spatialSpectrum
T@"NSArray",R,N,V_spatialSpectrum
setAzimuth:
setSpatialSpectrum:
arrayWithObjects:count:
bundleForClass:
resourcePath
populateClientError:withCode:underlyingError:message:
stringWithUTF8String:
resultsBox
adaptToSystemConfiguration:error:
graph
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
resultsFromBox:renderedWithFrameCount:
sharedProcessorConfiguration
primeGraph
T^v,R,N
azimuth
.cxx_construct
_graph
Tf,R,N
T@"NSArray",R,N
initWithArray:resourcePath:
graphWithConfiguration:
defaultWindowDuration
initWithFeaturePrintType:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
windowDurationConstraint
roundTime:toAllowableTime:
initWithFeaturePrintType:overlapFactor:windowDuration:
isEqualToCreateFeaturePrintRequest:
featurePrintType
setFeaturePrintType:
overlapFactor
setOverlapFactor:
windowDuration
setWindowDuration:
valueWithCMTime:
decodeFloatForKey:
decodeCMTimeForKey:
encodeFloat:forKey:
encodeCMTime:forKey:
_overlapFactor
_windowDurationConstraint
_featurePrintType
_windowDuration
Tq,N,V_featurePrintType
Tf,N,V_overlapFactor
T{?=qiIq},N,V_windowDuration
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
blockSize
createWithSampleRate:windowDuration:overlapFactor:error:
TI,R,N
T{?=qiIq},R,N
T@"SNTimeDurationConstraint",R,N
sampleRate
featureNames
count
allObjects
firstObject
featureValueForName:
extractDefaultOutputFeatureFromFeatureProvider:
multiArrayValue
outputProvider
extractOutputWithOptionalName:fromFeatureProvider:
initWithFeaturePrintType:featureVector:
_featureExtractor
_outputFeatureName
_resultsToDiscardCount
initWithOverlapFactor:error:
vggishFrontEndProcessingModelDescription
initWithModelDescription:parameterDictionary:error:
initWithMLCustomModel:modelDescription:
anyInputMultiArrayShape:
modelBlockSize:
model
resultsBoxName
UTF8String
modelSampleRate:orDefaultRate:
vggishFeatureEmbeddingInputShape
numberOfElements:
vggishFeatureEmbeddingOutputShape
initWithEnumeratedDurations:
_blockSize
TI,R,N,V_blockSize
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
vggishFrontEndProcessingInputShape
modelDescription
inputDescriptionsByName
allValues
objectAtIndexedSubscript:
multiArrayConstraint
lastDimensionSizeRange:
numberWithLongLong:
numberWithUnsignedInteger:
numberWithUnsignedLong:
createSoundPrintAFeatureExtractorWithModelConfiguration:
shapeConstraint
windowDurationConstraintFromMultiArrayShapeConstraint:sampleRate:
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithSampleRate:windowDuration:overlapFactor:error:
createSoundPrintKFeatureExtractor
anyOutputMultiArrayShape:
dataWithBytes:length:
addAudio:
endAudio
getLatestSuperVector
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
isEqualToSpeechDistanceRequest:
setCurrentFrameValue:
setMeanValue:
setStandardDeviation:
setServerInfo:
setState:
initWithServerInfo:state:
serverInfo
state
_serverInfo
_state
T@"SNFileServerInfo",&,N,V_serverInfo
TQ,N,V_state
xpcRequest:didProduceResult:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequestDidComplete:completionHandler:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithReceiver:
synchronousRemoteObjectProxyWithErrorHandler:
xpcAddRequest:withObserver:completionHandler:
errorWithCode:underlyingError:message:
xpcRemoveRequest:completionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcStartWithCompletionHandler:
xpcStopWithCompletionHandler:
xpcSetAudioConfiguration:completionHandler:
setAudioConfiguration:
addRequest:withObserver:error:
removeRequest:
removeAllRequests
start
stop
initWithSubscriber:
_subscriber
creationFlags
setCreationFlags:
configureAudioQueue
setConfigureAudioQueue:
_creationFlags
_configureAudioQueue
TI,V_creationFlags
T@?,C,V_configureAudioQueue
enableAlwaysOnAudioRouting:
setChannelAssignment:onQueue:
builtInMicrophoneAnalysisChannelNumberOrDefault:
createDefaultAudioQueueConfigurationUsingChannelNumber:
sharedInstance
availableInputs
countByEnumeratingWithState:objects:count:
portType
isEqualToString:
builtInMicrophoneDeviceUID
createSiriAudioQueueConfigurationUsingChannelNumber:
audioQueueConfiguration
T@"SNAudioQueueConfiguration",R
setFileName:
setError:
initWithFileName:error:
fileName
error
_fileName
_error
T@"NSString",&,N,V_fileName
T@"NSError",&,N,V_error
allValidSoundIdentifiers
initWithDetectorHead:featureExtractor:soundIdentifier:
detectorHead
featureExtractor
soundIdentifier
_detectorHead
_soundIdentifier
T@"NSString",R,N,V_detectorHead
T@"NSString",R,N,V_featureExtractor
T@"NSString",R,N,V_soundIdentifier
queue
launchTaskWithQueue:completionHandler:resultsHandler:
_removeRequest:error:
taskCompletionMap
valueWithPointer:
setObject:forKeyedSubscript:
objectForKey:
removeObjectForKey:
requests
addRequest:completionHandler:resultsHandler:
setRequests:
setTaskCompletionMap:
setQueue:
_requests
_taskCompletionMap
_queue
T@"NSMutableArray",&,N,V_requests
T@"NSMutableDictionary",&,N,V_taskCompletionMap
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
CMTimeValue
sortedArrayUsingComparator:
isEqualToTimeDurationConstraint:
initWithDurationRange:
durationRange
enumeratedDurations
isEqualToArray:
decodeCMTimeRangeForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeCMTimeRange:forKey:
_enumeratedDurations
_durationRange
T@"NSArray",R,V_enumeratedDurations
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
initWithSampleRate:blockSize:magnitudeThreshold:
setSampleRate:
setBlockSize:
magnitudeThreshold
setMagnitudeThreshold:
isEqualToDetectSignalThresholdRequest:
numberWithUnsignedInt:
_detector
_sampleRate
_magnitudeThreshold
Td,N,V_sampleRate
TI,N,V_blockSize
Td,N,V_magnitudeThreshold
array
addObject:
dictionaryWithObjectsAndKeys:
errorWithDomain:code:userInfo:
isEqualToDirectionOfArrivalResult:
_azimuth
Tf,N,V_azimuth
T@"NSArray",&,N,V_spatialSpectrum
allKeys
dictionaryWithObjects:forKeys:count:
initWithDictionary:error:
predictionFromFeatures:options:error:
outputDescriptionsByName
predictionsFromBatch:options:error:
_modelDescription
_model
registerAudioUnits
initWithAudioFile:overlapFactor:
initWithAudioFile:
_referenceAudioFile
Td,V_overlapFactor
processingFormat
length
setChannelIndex:
setPeakValue:
setPeakTime:
channelCount
_systemConfiguration
_referenceSampleRate
_channelCount
_framesProcessed
Td,R,V_overlapFactor
initWithDictionary:resourcePath:
graphWithGraphInfo:
initWithPCMFormat:frameCapacity:
setFramePosition:
readIntoBuffer:error:
streamDescription
audioBufferList
createSystemAudioAnalyzer
setDelegate:
resume
endpoint
initWithListenerEndpoint:
setExportedInterface:
setExportedObject:
launchAsMachServiceWithName:
initWithMachServiceName:
launchWithResourceCoordinator:onXPCListener:
initWithResourceCoordinator:onListener:
launchDefaultServer
listener:shouldAcceptNewConnection:
connectLocally
_listener
_coordinator
initToConnectToMachServiceWithName:queue:
initWithMachServiceName:options:
setInterruptionHandler:
setInvalidationHandler:
newConnectionToMachServiceWithName:lostConnectionHandler:queue:
initWithConnectionGenerator:queue:
_handleLostConnection
setRemoteObjectInterface:
_connectionToServerWithInvalidationHandler:queue:
remoteObjectProxy
_remoteResourceCoordinatorWithInvalidationHandler:queue:
_createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
defaultClient
createRemoteSystemAudioAnalyzerWithInvalidationHandler:queue:
_connectionToServerGenerator
_xpcConnectionToServer
_pendingInvalidationHandlers
meanValue
currentFrameValue
standardDeviation
isEqualToSpeechDistanceResult:
_currentFrameValue
_meanValue
_standardDeviation
Td,N,V_currentFrameValue
Td,N,V_meanValue
Td,N,V_standardDeviation
userDefaults
boolForKey:
stringForKey:
integerForKey:
doubleForKey:
intValue
numberWithInt:
builtInMicrophoneAnalysisChannelNumber
instance
initWithSuiteName:
setUserDefaults:
mainBundle
bundleIdentifier
pathWithComponents:
registerDefaults:
enableSecondPassRecordingInDaemon
daemonRecordingPath
recordingDirectoryMaximumSizeBytes
recordingTimeToLiveSeconds
deleteRecordingsWithoutDetection
enableFileServer
fileServerRootDirectory
enableVerboseLogging
T@"NSString",R
Tq,R
Td,R
T@"NSNumber",R
_userDefaults
T@"NSUserDefaults",&,N,V_userDefaults
setFiles:
setServerBasePath:
setDispatchQueue:
files
serverBasePath
identifier
sendRequestID:request:destinationID:options:responseHandler:
activateWithCompletion:
invalidate
initWithFiles:serverBasePath:serverInfo:
_files
_serverBasePath
T@"NSArray",&,N,V_files
T@"NSString",&,N,V_serverBasePath
T@"MLModelDescription",R
_customModel
T@"MLModelDescription",R,V_modelDescription
initWithModel:
_lock
userSuppliedInputFeatureNames:
userSuppliedOutputFeatureNames:
containsObject:
outputLabel
dataType
initWithIdentifier:
windowLengthFrames
completeTimingInfoInResult:windowLengthFrames:usingBox:
floatValue
setDetected:
setDetectorIdentifier:
featureExtractorConfiguration
initWithConfiguration:
_configuration
_detectorBoxName
_inputFeatureName
_outputConfidenceFeatureName
_outputDetectedFeatureName
objectForKeyedSubscript:
shape
stepSizeFrames
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
_receiver
detected
isEqualToDetectionResult:
numberWithBool:
decodeBoolForKey:
encodeBool:forKey:
_detected
_identifier
TB,N,V_detected
T@"NSString",&,N,V_detectorIdentifier
T@"NSString",R,N,V_identifier
initWithKeys:
isEqualToModelCacheKey:
initWithModelClass:modelConfiguration:
_keys
createSecondPassController
twoPassConfiguration
T@"SNTwoPassConfiguration",R
initWithTwoPassConfiguration:createSecondPassControllerFunction:
_createSecondPassControllerFunction
_twoPassConfiguration
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
isEqualToSpeechUtteranceResult:
stringByAppendingPathComponent:
path
text
includePaths
substitutions
setPath:
setText:
setIncludePaths:
setSubstitutions:
_path
_text
_includePaths
_substitutions
T@"NSString",&,N,V_path
T@"NSString",&,N,V_text
T@"NSArray",&,N,V_includePaths
T@"NSDictionary",&,N,V_substitutions
value
containsOnlyAUStrips:
_value
T@"NSString",R,N,V_path
T@"NSDictionary",R,N,V_value
_resourcePath
T@"NSString",R,N,V_resourcePath
dspItems
setDspItems:
_dspItems
T@"NSArray",&,N,V_dspItems
applyAUStrip:toGraph:
name
applyPropertyStrip:toGraph:
compileText:withSubstitutions:includingPaths:
compileFile:withSubstitutions:includingPaths:
setAUStrip:
dictionaryWithContentsOfFile:
setPropertyStrip:withResourcePath:
isEqualToSoundPrintFeatureExtractorConfiguration:
createProcessorWithError:
initWithModel:overlapFactor:
outputFeatureSize
_windowLengthFrames
_stepSizeFrames
_outputFeatureSize
T@"<SNMLModel>",R,V_model
Td,R,V_sampleRate
TI,R,V_windowLengthFrames
TI,R,V_stepSizeFrames
TI,R,V_outputFeatureSize
null
setObject:forKey:
sn_setSafeObject:forKey:
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithClient:queue:
selectAppropriateImplForThisProcess
initWithImpl:
configureNewAnalyzersToComputeInThisProcess:
initWithAudioConfiguration:
addRequestInBackground:withObserver:
_impl
fileURLs
setFileURLs:
backgroundEnergyPercentile
setBackgroundEnergyPercentile:
foregroundEnergyPercentile
setForegroundEnergyPercentile:
hangoverDuration
setHangoverDuration:
minSegmentDuration
setMinSegmentDuration:
similarityThreshold
setSimilarityThreshold:
_backgroundEnergyPercentile
_foregroundEnergyPercentile
_similarityThreshold
_fileURLs
_hangoverDuration
_minSegmentDuration
T@"NSArray",V_fileURLs
Tf,V_backgroundEnergyPercentile
Tf,V_foregroundEnergyPercentile
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
Tf,V_similarityThreshold
trainingDataEmbeddings
setTrainingDataEmbeddings:
trainingDataLabels
setTrainingDataLabels:
validationDataEmbeddings
setValidationDataEmbeddings:
validationDataLabels
setValidationDataLabels:
exemplar
setExemplar:
inferenceWindowSize
setInferenceWindowSize:
_trainingDataEmbeddings
_trainingDataLabels
_validationDataEmbeddings
_validationDataLabels
_exemplar
_inferenceWindowSize
T@"NSArray",C,V_trainingDataEmbeddings
T@"NSArray",C,V_trainingDataLabels
T@"NSArray",C,V_validationDataEmbeddings
T@"NSArray",C,V_validationDataLabels
T@"MLMultiArray",&,V_exemplar
T{?=qiIq},V_inferenceWindowSize
exemplarEmbedding
setExemplarEmbedding:
segments
setSegments:
exemplarIndex
setExemplarIndex:
_exemplarEmbedding
_segments
_exemplarIndex
T@"MLMultiArray",&,V_exemplarEmbedding
T@"NSArray",C,V_segments
T@"NSNumber",C,V_exemplarIndex
embeddings
setEmbeddings:
labels
setLabels:
_embeddings
_labels
T@"NSArray",C,V_embeddings
T@"NSArray",C,V_labels
setWithObjects:
indexOfObject:
feature
featureValueWithMultiArray:
tokenGroup
T@"NSSet",R,N
setFeature:
setTokenGroup:
_feature
_tokenGroup
T@"MLMultiArray",&,N,V_feature
T@"MLMultiArray",&,N,V_tokenGroup
setUrl:
_url
T{?={?=qiIq}{?=qiIq}},V_timeRange
T@"NSURL",C,V_url
initWithShape:dataType:error:
dataPointer
arrayWithObjects:
initWithCapacity:
getTimeRangeEncompassingEntireAudioFileAtURL:error:
clipTimeRange:toBounds:
resizeSegment:toDuration:error:
initWithURL:error:
analyzeInRange:
errors
results
doubleValue
collectResultsForRequest:fromSegment:error:
collectFeaturePrintsOfType:fromSegment:withWindowDuration:withOverlapFactor:error:
initForReading:commonFormat:interleaved:error:
fileFormat
getFirstFeaturePrintOfType:fromSegment:withWindowDuration:withOverlapFactor:error:
featureVector
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
sliceAtOrigin:shape:squeeze:error:
multiArrayViewExpandingDimensionsAtAxis:
float32MatrixWithValues:error:
strides
metadata
integerValue
shiftSegment:byAmount:error:
clipSegmentToFileBoundaries:error:
hallucinateNewEmbeddingSimilarToSoundPrintEmbedding:withHallucinator:withHallucinationTokenGroup:error:
generateNegativeEmbeddingFromPositiveSoundPrintEmbedding:usingNegativeSoundPrintEmbeddingArray:randomNumberGenerator:error:
defaultRandomNumberGenerator
featurizeFiles:randomNumberGenerator:hallucinatorModelURL:cancellable:error:
analyze
addObjectsFromArray:
cosineSimilarityBetweenOneFeatureVector:andAnotherFeatureVector:error:
lastObject
ensureMinimumDuration:forSegment:error:
cosineSimilarityBetweenOneFloat32Array:andAnotherFloat32Array:length:error:
ensureIsValidHallucinatorV3Model:error:
generateDatasetUsingNewHallucinator:segments:exemplarLength:datasetIdentifier:randomNumberGenerator:error:
collectEmbeddingsAtOneTimeShift:forSegment:numHallucinatedExamples:exemplarDuration:hallucinator:negativeEmbeddingArray:resultHandler:randomNumberGenerator:error:
isCancelled
performSegmentationRequest:error:
localizedDescription
loadModelAtURL:withTimeout:error:
recognizeHallucinatorModel:error:
subarrayWithRange:
generateDatasetFrom:numTimeShifts:extendeExemplartLength:secondsAugmentAroundSegment:sampleRate:hallucinator:numHallucinatedExamples:datasetIdentifier:randomNumberGenerator:cancellable:error:
standardizeTimeRange:directionShouldBePositive:negativeShouldResideInTimescale:
generateRandomTimeOffsetInRange:randomNumberGenerator:
generateRandomTimeInRange:randomNumberGenerator:
addOffset:toTimeRange:
resizeOneSegment:toDuration:
emitTimeShiftsForSegment:shiftWindow:randomNumberGenerator:count:datasetIdentifier:foregroundAudioLength:handler:error:
ensureModelDescription:hasInputFeatureNames:hasOutputFeatureNames:error:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:shapeOptions:error:
readNumRepetitionsPerTimeShiftFromHallucinator:error:
readNumTimeShiftsPerSegmentFromHallucinator:error:
valueWithRange:
ensureFeatureWithDescription:isOptional:isMultiArrayWithDataType:dimensionSizeRanges:error:
ensureFeatureWithDescription:isOptional:error:
ensureFeatureWithDescription:isOptional:isFreelyShapedMultiArrayWithDataType:error:
ensureIsValidHallucinatorV1Model:error:
toMLMultiArrayConvertFromFloatScalar:error:
dictionaryWithDictionary:
toFloatScalarConvertFromMLMultiArray:error:
packageHallucinatorInputFeaturesForegroundAudio:backgroundAudio:repetitionCounter:datasetIdentifier:shiftAmount:originalSegmentLength:state:error:
predictionFromFeatures:error:
unpackageHallucinatorOutputs:handler:error:
convertScaleForTimeRange:toValue:preferShrinkingWhenRounding:
clipTimeRange:toBounds:handler:
findBackgroundRegionsSurroundingForegroundSegment:handler:error:
zeroBufferPopulator
flushBytesFromPreciseTimeRangeInAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:intoSink:error:
selectBackgroundNoiseRegionsSurroundingSegment:eligibleTimeSpanPrecedingSegment:eligibleTimeSpanFollowingSegment:handler:error:
findBackgroundRegionsSurroundingForegroundSegments:handler:error:
flushBytesFromStreamSource:toBuffer:ofSizeInBytes:error:
resampleOneSegment:toSampleRate:
createMultiArrayContainingPreciseTimeRangeOfAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:numDimensions:error:
applyHallucinator:foregroundAudio:backgroundAudio:repetitionCounter:datasetIdentifier:shiftAmount:originalSegmentLength:state:handler:error:
hallucinateOneTimeShiftedSegment:hallucinator:hallucinatorStateFetcher:backgroundAudio:datasetIdentifier:shiftAmount:originalSegmentLength:numRepetitionsPerTimeShift:handler:error:
resampleSegments:toSampleRate:
extractBackgroundNoiseMatchingLength:fromSegments:error:
generateHallucinateFunctionWithHallucinator:backgroundAudio:numRepetitionsPerTimeShift:handler:error:
emitTimeShiftsForManySegments:shiftWindow:randomNumberGenerator:numTimeShiftsPerSegment:datasetIdentifier:foregroundAudioLength:handler:error:
pseudoRandomNumberGeneratorWithSeed:
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
featurizeFiles:randomNumberGenerator:hallucinatorModelURL:error:
randomlyShiftTimeRange:byAmountWithinWindow:randomNumberGenerator:
resizeSegments:toDuration:
setFileItems:
initWithFileItems:
fileItems
_fileItems
T@"NSArray",&,N,V_fileItems
dictionary
initWithRemoteAnalyzerGenerator:queue:
_invalidateAnalyzer:
_invalidateActiveAnalyzer
copy
_removeAllRequests
connectionLostError
sleepForTimeInterval:
_acquireSystemAudioAnalyzer
removeAllObjects
_setAudioConfiguration:
_addRequest:withObserver:
_removeRequest:
invalidateActiveAnalyzer
_registeredRequests
_analyzer
_generator
_audioConfiguration
setIdentifier:
setIdsDeviceID:
setModel:
setName:
initWithIdentifier:idsDeviceID:model:name:
idsDeviceID
_idsDeviceID
_name
T@"NSString",&,N,V_identifier
T@"NSString",&,N,V_idsDeviceID
T@"NSString",&,N,V_model
T@"NSString",&,N,V_name
isEqualToSpeechEmotionRequest:
bytes
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
initWithSampleRate:channelCount:
initWithDouble:
initWithUnsignedInt:
setChannelCount:
TI,N,V_channelCount
initWithTimeBetweenTriggers:
removeOverlappingResults:
_timeBetweenTriggers
_lastResult
shapeNonUnitaryDimensionCount:
predictedProbabilitiesName
predictedFeatureName
exceptionWithName:reason:userInfo:
feedbackConnections:
denylistFromModelDescription:
dictionaryValue
filterClassLabelsInDictionary:usingDenylist:
initWithClassificationDictionary:
setClassifierIdentifier:
completeTimingInfoInResult:usingBox:modelBlockSize:
initWithMLModel:overlapFactor:windowDuration:classifierIdentifier:error:
classifierIdentifier
_modelBlockSize
_feedbackConnections
_classLabelsDenylist
_classifierIdentifier
T{?=qiIq},R,V_windowDuration
T@"NSString",R,V_classifierIdentifier
filteredClassLabelsFromModelDescription:
createSoundClassifierVersion1
initWithMLModel:error:
isEqualToClassifySoundRequest:
decodeObjectForKey:
knownClassificationsForClassifierIdentifier:error:
initWithClassifierIdentifier:error:
knownClassifications
_knownClassifications
T@"NSString",&,V_classifierIdentifier
T{?=qiIq},V_windowDuration
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"NSArray",R,C,V_knownClassifications
modelChannelCount:
initWithFormat:
framePosition
readIntoBuffer:frameCount:error:
sendErrorToAllRequests:
analyzeAudioBuffer:atAudioFramePosition:
frameLength
advanceSamples:withHandler:
completeAnalysis
fullFileTimeRange
detailedDescription
analyzeWithCompletionHandler:
cancelAnalysis
_audioFile
_streamAnalyzer
_wasCancelled
initWithRequestType:
decisionDelay
requestType
isEqualToDetectSpeechUtteranceRequest:
_requestType
Tq,R,V_requestType
softVAD
hardVAD
TB,R,N
clientResultsFromProcessorResults:
clientSampleTimeFromSampleTime:fromBox:
clientSampleRate
dictionaryWithCapacity:
timeConversionDictionary
T@"NSDictionary",R
addEntriesFromDictionary:
valueForKey:
convertTime:fromBox:usingConverter:
setValue:forKey:
convertTimeRange:fromBox:usingConverter:
initWithAnalyzer:completionHandler:resultsHandler:timeConverter:
handleDSPGraphPostRenderCallbackFromBox:numFrames:
handleAnalyzerCompletion
handleAnalyzerError:
requestDidReturnError:
primeAnalyzerGraph
requestState
setRequestState:
_timeConverter
_resultsHandler
_completionHandler
_requestState
T@,R,N
Tq,N,V_requestState
initWithSoundIdentifier:
defaultDetectorIdentifierForSoundIdentifier:
initWithDetectorVariant:soundIdentifier:
splitDetectorInfoForDetectorIdentifier:
initWithDetectorVariant:soundIdentifier:modelConfiguration:
isEqualToDetectSoundRequest:
T@"NSArray",R,D,N
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithDetectorIdentifier:error:
initWithVGGishBasedMLModel:soundIdentifier:
modelConfiguration
setModelConfiguration:
_detectorVariant
_modelConfiguration
T@"MLModelConfiguration",&,N,V_modelConfiguration
initWithModel:approximateOverlapFactor:
initWithMLModel:detectorIdentifier:outputLabel:sampleRate:windowLengthFrames:stepSizeFrames:featureExtractorConfiguration:
sharedLockedVGGishFeatureExtractorWithModelConfiguration:
detectorConfigurationWithLogMelBasedFeatureExtractor:detectorHead:detectorIdentifier:soundIdentifier:
detectorHeadConfigurationForDetectorIdentifier:soundIdentifier:modelConfiguration:
sharedLockedModelOfClass:modelConfiguration:
sharedLockedSoundPrint100kFeatureExtractorWithModelConfiguration:
detectorConfigurationWithAudioBasedFeatureExtractor:detectorHead:detectorIdentifier:
detectorHeadConfigurationForDetectorVariant:soundIdentifier:modelConfiguration:
T{shared_ptr<DSPGraph::Graph>=},R,N
T^{Box=},R,N
initWithBox:fromGraph:
startRecordingPort:toFile:
stopRecordingPort:
startInjectingPort:toFile:shouldLoop:
stopInjectingPort:
numInputs
numOutputs
getParameterList:numParameterIDs:inScope:
getParameterInfo:forID:inScope:
getParameter:forID:scope:element:
hasParameter:scope:element:
setParameter:forID:scope:element:bufferOffset:
_box
T^v,R,N,V_box
Tq,R,N
T@"NSString",R,N
idsDeviceIdentifier
setLocalDeviceUpdatedHandler:
setDeviceLostHandler:
setDeviceFoundHandler:
setDeviceChangedHandler:
isOptional
sizeRangeForDimension
rangeValue
enumeratedShapes
ensureMultiArrayConstraint:hasDataType:error:
ensureMultiArrayShapeConstraint:hasDimensionSizeRanges:error:
ensureMultiArrayShapeConstraint:hasShapeOptions:error:
ensureMultiArrayIsFreelyShapedByShapeConstraint:error:
ensureMultiArrayIsRequiredByFeatureDescription:error:
ensureMultiArrayConstraint:hasDataType:andDimensionSizeRanges:error:
ensureMultiArrayConstraint:hasDataType:andShapeOptions:error:
ensureMultiArrayIsFreelyShapedWithConstraint:hasDataType:error:
valueForEntitlement:error:
boolValue
isCurrentProcessEntitledToHostDaemon
createFileServer
currentRunLoop
isInternalBuild
initWithRootDirectory:
_fileServer
isEqualToLogMelBasedFeatureExtractorConfiguration:
logMelStepSize
_logMelStepSize
TI,R,V_logMelStepSize
setInterface:forSelector:argumentIndex:ofReply:
defaultMaxCacheSize
initWithWrappedModel:maxCacheSize:
initWithWrappedModel:
withWrappedModel:maxCacheSize:
withWrappedModel:
wrappedModel
_maxCacheSize
_cacheStorage
_cacheAccessRecency
_wrappedModel
T@"<SNMLModel>",R,V_wrappedModel
strongToWeakObjectsMapTable
sharedLockedModelWithKey:orCreateNewModelWithWithFunction:
_vendedModels
initWithConfiguration:error:
createModelOfClass:modelConfiguration:
sharedLockedModelOfClass:memoized:modelConfiguration:
vggishFeatureExtractorModelClass
soundPrint100kFeatureExtractorModelClass
soundPrintAFeatureExtractorModelClass
soundPrintKFeatureExtractorModelClass
createModelOfClass:
soundClassifierVersion1Modelclass
sharedLockedModelOfClass:
vggishModelClassForSoundIdentifier:
createVGGishFeatureExtractorWithModelConfiguration:
createSoundPrint100kFeatureExtractorWithModelConfiguration:
soundprint100kModelClassForSoundIdentifier:
sharedLockedSoundPrintAFeatureExtractorWithModelConfiguration:
sharedLockedSoundPrintKFeatureExtractor
createSharedLockedSoundClassifierVersion1
isEqualToFeaturePrint:
cosineSimilarityBetweenOneFeaturePrint:andAnotherFeaturePrint:error:
cosineSimilarityBetweenOneOneFeaturePrint:andAnotherFeaturePrint:error:
cosineSimilarityToFeaturePrint:error:
_featureVector
Tq,R,N,V_featurePrintType
T@"MLMultiArray",R,N,V_featureVector
request
setRequest:
resultsHandler
setResultsHandler:
completionHandler
setCompletionHandler:
analyzerHost
setAnalyzerHost:
sharedProcessor
setSharedProcessor:
configured
setConfigured:
configurationError
setConfigurationError:
_configured
_request
_analyzerHost
_sharedProcessor
_configurationError
T@"<SNAnalyzerCreating>",&,N,V_request
T@?,C,N,V_resultsHandler
T@?,C,N,V_completionHandler
T@"SNAnalyzerHost",&,N,V_analyzerHost
T@"<SNProcessing>",&,N,V_sharedProcessor
TB,N,V_configured
T@"NSError",&,N,V_configurationError
isFormatPCM:
updateProcessingTreeFormat:
stopRecording
dealloc
removeObject:
addRequest:completionHandler:resultsHandler:error:
addResult:
indexOfObjectIdenticalTo:
completionHandlerWithClientCompletionHandler:forRequest:
resultsHandlerWithClientResultsHandler:forRequest:
createAnalyzerInfoForRequest:completionHandler:resultsHandler:error:
configureAnalyzer:withFormat:
arrayByAddingObject:
arrayWithArray:
removeObjectAtIndex:
removeAnalyzerInfoForRequest:
sharedProcessorWithConfiguration:
updateTreeProcessingContexts
handleAnalysisPrimingError
format
configureAnalysisTreeWithFormat:
splitBuffer:intoBuffersWithFrameCount:
handleAnalyzeAudioBufferError
date
setDateFormat:
stringFromDate:
stringByAppendingPathExtension:
initWithDirectoryPath:fileNameWithoutExtension:dateString:soundIdentifier:
initWithDSPGraph:
stopRecordingBoxesInGraph:
directoryPath
fileNameWithoutExtension
audioFileFrameCount:
detectionResults
detectionCountInResults:
defaultManager
removeItemAtPath:error:
writeResultsToFileWithAudioFrameCount:error:
analyzerInfoForRequest:
analyzeAudioBufferList:withAudioFrameCount:atAudioFramePosition:
writeDSPGraphDotFilesToDirectory:
startRecordingToDirectory:requestDescription:error:
_processorCache
_processingContexts
_processingTree
_currentFormat
_analyzerInfos
_resultsLogger
_shouldRebuildProcessingTree
startRecordingFirstBoxInGraph:toDirectory:withFileName:error:
initWithInputSensitivity:
isEqualToMeasureLKFSRequest:
inputSensitivity
_inputSensitivity
Tf,R,N,V_inputSensitivity
setQueryPath:
setServiceType:
setDestinationID:
queryPath
performQuery:
initWithServerInfo:queryPath:
_queryPath
T@"NSString",&,N,V_queryPath
unsignedIntegerValue
mutableAudioBufferList
setFrameLength:
frameCapacity
componentsSeparatedByString:
mutableCopy
removeObjectsForKeys:
classLabels
removeObjectsInArray:
vggishFrontEndProcessingOutputShape
constraintWithShape:dataType:
featureDescriptionWithName:type:optional:constraints:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
modelBlockSize:channelCount:
parseFeedbackConnectionsString:
destinationFeatureName
sourceFeatureName
userSuppliedFeatureNames:direction:
subtractSet:from:
minusSet:
whitespaceAndNewlineCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
initWithSourceFeatureName:destinationFeatureName:
processInfo
processName
stringByReplacingOccurrencesOfString:withString:
stringByAppendingString:
_deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
contentsOfDirectoryAtPath:error:
predicateWithFormat:
filterUsingPredicate:
fileCreationDate:
compare:
sortUsingComparator:
diskSpaceRemainingBytesContainingDirectory:
unsignedLongLongValue
fileSizeBytes:
stringByDeletingPathExtension
attributesOfItemAtPath:error:
attributesOfFileSystemForPath:error:
fileURLWithPath:
initForReading:error:
valueForEntitlement:fromTask:error:
convertScaleForTimeRange:toValue:startRoundingMethod:durationRoundingMethod:
standardizeTime:negativeShouldResideInTimescale:
standardizeTimeRange:directionShouldBePositive:
standardizeTimeRange:negativeShouldResideInTimescale:
makeInvalidTimeRange
getTimeRangeEncompassingEntireAudioFile:
processFrameCount:bufferFactory:populator:handler:completionHandler:
channelLayout
initWithStreamDescription:channelLayout:
initSecondaryReader:format:error:
readFramesFromAudioFile:frameCount:maxFramesPerBuffer:recycleBuffers:handler:error:
readFramesFromAudioFile:frameCount:atSampleRate:maxFramesPerBuffer:recycleBuffers:handler:error:
readPreciseTimeDurationFromAudioFile:timeDuration:maxFramesPerBuffer:recycleBuffers:handler:error:
readPreciseTimeRangeFromAudioFile:timeRange:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
flushAudioBuffer:channelIndex:intoSink:error:
commonFormat
loadContentsOfURL:configuration:completionHandler:
silenceUnfilledFramesInBuffer:
copyAudioBufferList:to:frameCount:bytesPerFrame:
multiArrayConstraintLastDimensionIsFlexible:
isRunningInDaemon
loggingPrefixForRequest:
deleteWAVAndTextFilesInDirectory:createdBeforeDate:withRemainingDirectoryByteSizeLessThan:
checkTimeRange:isIdenticalToOther:
readApproximateTimeDurationFromAudioFile:timeDuration:roundingMethod:maxFramesPerBuffer:recycleBuffers:handler:error:
readApproximateTimeRangeFromAudioFile:timeRange:preferShrinkingWhenRounding:maxFramesPerBuffer:recycleBuffers:prefixBufferPopulator:suffixBufferPopulator:handler:error:
automaticallyNotifiesObserversForKey:
willChangeValueForKey:
didChangeValueForKey:
clearResults
clearErrors
clearCompleteCount
completeCount
_results
_errors
_completeCount
Tq,R,N,V_completeCount
initWithCompletionHandler:resultsHandler:
setIsCancelled:
cancel
_isCancelled
TB,V_isCancelled
_sourceFeatureName
_destinationFeatureName
T@"NSString",R,V_sourceFeatureName
T@"NSString",R,V_destinationFeatureName
initWithStreamDescription:
setVariableSliceDuration:forSampleRate:
sliceDurationInSamples
initialized
configure
unconfigure
initialize
uninitialize
reset
getParameter:forID:
hasParameter:
setParameter:forID:
getPropertySize:isWritable:forID:
getProperty:withSize:forID:
setProperty:withSize:forID:
boxWithName:
boxes
numberOfInputs
numberOfOutputs
writeDotFileToPath:
T@"NSString",C,N
setObject:atIndexedSubscript:
shapeFromMultiArrayConstraint:lastDimensionCountIfFlexible:
initWithFeatureDescription:allInputFeatureNames:elementCountPerChannel:channelCount:
setFeatureValue:forFeatureName:
input
setInput:
_featureDescription
_featureCache
_allInputFeatureNames
_input
T@"MLMultiArray",&,N,V_input
feedbackConnections
setFeedbackConnections:
inputProvider
setInputProvider:
setOutputProvider:
_inputProvider
_outputProvider
T@"<SNMLModel>",&,N,V_model
T@"NSArray",&,N,V_feedbackConnections
T@"DSPGMLInputProvider",&,N,V_inputProvider
T@"<MLFeatureProvider>",&,N,V_outputProvider
compileModelAtURL:error:
modelWithContentsOfURL:error:
filename
setFilename:
fileSize
setFileSize:
itemURL
setItemURL:
initWithFileItem:
_filename
_fileSize
_itemURL
T@"NSString",&,N,V_filename
Tq,N,V_fileSize
T@"NSURL",&,N,V_itemURL
initWithConfidence:timeRange:
Td,R,N,V_confidence
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
minDurationBlocks
confidenceThreshold
arrayWithCapacity:
initWithCommand:
processNewTimestep:timeRange:
history
_maxHistoryLength
_confidenceThreshold
_streak
_history
T@"NSString",R,N,V_name
T@"NSMutableArray",R,N,V_history
initWithCommands:
processNewResults:timeRange:
commandFilters
_commandFilters
T@"NSArray",R,N,V_commandFilters
offset
setOffset:
isEqualToAudioOffsetResult:
_offset
Td,N,V_offset
setServerFilePaths:
setLocalDestinationPath:
deregisterRequestID:
registerRequestID:options:handler:
getIdentitiesWithCompletion:
edPKData
serverFilePaths
flags
setFlags:
prepareTemplateAndReturnError:
localDestinationPath
fileURLWithPath:isDirectory:
setTemporaryDirectoryURL:
setReceivedItemHandler:
setPeerPublicKey:
setTargetID:
activate
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
_serverFilePaths
_localDestinationPath
T@"NSArray",&,N,V_serverFilePaths
T@"NSString",&,N,V_localDestinationPath
initWithFirstPassRequest:secondPassRequest:historicalDataAmount:
firstPassRequest
secondPassRequest
historicalDataAmount
_firstPassRequest
_secondPassRequest
_historicalDataAmount
T@"<SNRequest>",R,V_firstPassRequest
T@"<SNRequest>",R,V_secondPassRequest
Td,R,V_historicalDataAmount
floatChannelData
initWithAudioTimeStamp:sampleRate:
initWithBufferHandler:queue:recordFormat:
handleAudioBufferCallbackForQueue:buffer:startTime:numberPacketDescriptions:packetDescriptions:
_bufferHandlerQueue
_bufferHandler
_transaction
_recordFormat
_stop
opaqueSessionID
initWithFormat:audioQueueConfiguration:
startHandlingBuffersOnQueue:audioSession:handler:
_audioQueueConfiguration
_running
_audioQueue
_aqCallbackScheduler
anyObject
isAllowedShape:error:
preProcessCallback
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
setPreProcessCallback:
_inputConstraint
_outputConstraint
_scratchFloatSpace
_modelOutput
_preProcessCallback
T@?,C,N,V_preProcessCallback
removeRequestAsync:
_addRequest:completionHandler:resultsHandler:error:
_addTwoPassRequest:completionHandler:resultsHandler:error:
_addSinglePassRequest:completionHandler:resultsHandler:error:
handleBeginSecondPassForRequest:secondPassController:completionHandler:resultsHandler:
setBeginSecondPassHandler:
handleEndSecondPassForRequest:
setEndSecondPassHandler:
firstPassDidProduceResult:
dateByAddingTimeInterval:
valueWithNonretainedObject:
shouldRecordSecondPass
secondPassRecordingPath
deleteWAVAndTextFilesCreatedBeforeLastWeekInDirectory:
secondPassDidProduceResult:
_removeTwoPassRequest:
_removeSinglePassRequest:
_analyzeAudioBuffer:atAudioFramePosition:
string
appendString:
_analyzerQueue
_firstPassAnalyzer
_secondPassAnalyzers
_ringBuffer
_ringBufferWriteBufferList
createUltronResultsDictionaryFromDetectionResults:
createUltronFinalDictionaryWithDetectionResults:dateString:fileNameWithoutExtension:soundIdenfifier:frameCount:
writeDictionaryAsJSON:fileNameWithoutExtension:directoryPath:error:
dataWithJSONObject:options:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToFile:options:error:
_dateString
_wroteResults
_startingTime
_detectionResults
_directoryPath
_fileNameWithoutExtension
T@"NSString",R,V_directoryPath
T@"NSString",R,V_fileNameWithoutExtension
T@"NSArray",R,V_detectionResults
_minDurationBlocks
Tq,R,N,V_minDurationBlocks
Td,R,N,V_confidenceThreshold
initWithModel:request:
isEqualToMeasureDetectVoiceTriggerRequest:
initWithModel:dictionary:error:
hopSizeSamples
setHopSizeSamples:
blocksBetweenTriggers
setBlocksBetweenTriggers:
commands
setCommands:
_hopSizeSamples
_blocksBetweenTriggers
_commands
Td,R,N,V_sampleRate
Tq,N,V_hopSizeSamples
Tq,N,V_blocksBetweenTriggers
T@"NSArray",C,N,V_commands
_modelOutputFilter
_overlapFilter
setLink:
link
setProgressHandler:
rootDirectory
addItem:
finish
server
createDefaultServer
setServer:
setRootDirectory:
_server
_link
_rootDirectory
T@"CUFileServer",&,N,V_server
T@"RPCompanionLinkClient",&,N,V_link
T@"NSString",&,N,V_rootDirectory
setRootDirectoryURL:
pathExtension
boxName
setBoxName:
busIndex
setBusIndex:
_boxName
_busIndex
T@"NSString",&,V_boxName
Tq,V_busIndex
T@"NSString",&,V_fileName
startRecordingWithBoxRecordingInfos:inGraph:toDirectory:error:
startRecordingBoxes:inGraph:toDirectory:error:
startInjectingBoxes:inGraph:error:
stopInjectingBoxesInGraph:
initWithSampleRate:blockSize:computationalDutyCycle:graphIsDeadEnded:shouldThrowException:
computationalDutyCycle
setComputationalDutyCycle:
graphIsDeadEnded
setGraphIsDeadEnded:
shouldThrowException
setShouldThrowException:
isEqualToNullRequest:
_graphIsDeadEnded
_shouldThrowException
_computationalDutyCycle
Td,N,V_computationalDutyCycle
TB,N,V_graphIsDeadEnded
TB,N,V_shouldThrowException
initWithCommonFormat:sampleRate:channels:interleaved:
defaultCenter
handleAVAudioSessionInterruption:
addObserver:selector:name:object:
handleAVAudioSessionRouteChange:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
_addRequest:withObserver:error:
startAudio
stopAudio
initAuxiliarySession
category
mode
options
setCategory:mode:options:error:
setActive:error:
sampleTime
handleAudioStreamInterrupted
_dispatchQueue
_analysisQueue
_recordingQueue
_recordingState
_clientStartedAnalysis
_audioSession
makeHandlerForUInt32ParameterWithBlock:
makeHandlerForFloatParameterWithBlock:
makeHandlerForInt32ParameterWithBlock:
makeHandlerForStringParameterWithChoices:block:
defaultLogMelExtractionParameters
overrideLogMelExtractionParameters:withContentsOfParameterDictionary:error:
resetLogMelExtractionParameters:overrideWithParameterDictionary:error:
validateModelDescription:logMelExtractionParameters:withHandler:error:
initWithDataPointer:shape:dataType:strides:deallocator:error:
_logMelExtractionParameters
stringMapFromStringDictionary:
stringVectorFromStringArray:
_interpreter
isEqualToEstimateAudioOffsetRequest:
updateMinMaxDelayWithSampleRate:micDelay:refDelay:eclen:
setMinimumObservableOffset:
minimumObservableOffset
setMaximumObservableOffset:
maximumObservableOffset
_minimumObservableOffset
_maximumObservableOffset
Td,R,N,V_offset
Td,N,V_minimumObservableOffset
Td,N,V_maximumObservableOffset
initWithIdentifier:confidence:
classificationsFromClassificationDictionary:
enumerateKeysAndObjectsUsingBlock:
_init
classificationDictionary
setClassificationDictionary:
isEqualToClassificationResult:
classificationForIdentifier:
classifications
_cachedClassifications
_classificationDictionary
T@"NSDictionary",C,N,V_classificationDictionary
T@"NSString",C,N,V_classifierIdentifier
T@"NSArray",R,C
isEqualToClassification:
T@"NSString",R,C,V_identifier
Td,R,V_confidence
modelURLForCurrentProduct
isEqualToSignalThresholdResult:
isEqualToAudioConfiguration:
setCategory:
setMode:
setOptions:
_category
_mode
_options
T@"NSString",C,N,V_category
T@"NSString",C,N,V_mode
TQ,N,V_options
hasPrefix:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:matcher:
generateFeatureMappingsFromOuterFeatureNames:toInnerFeatureNames:
generateInputFeatureMappingsFromOuterDescription:toInnerDescription:
generateOutputFeatureMappingsFromOuterDescription:toInnerDescription:
innerInputFeatureProviderFromOuter:outerToInnerInputFeatureNameMappings:error:
outerOutputFeatureProviderFromInner:outerToInnerOutputFeatureNameMappings:error:
initWithModel:modelDescription:
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
removeLastObject
validateModelDescription:underlyingModelDescription:error:
_outputShape
beginSecondPassHandler
endSecondPassHandler
T@?,C
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassTriggerTime
_firstResultBelowEndThresholdStartTime
_secondPassIsActive
_firstPassResultToComparableFunction
_secondPassResultToComparableFunction
_beginSecondPassHandler
_endSecondPassHandler
T@?,C,V_beginSecondPassHandler
T@?,C,V_endSecondPassHandler
_featureExtractorConfiguration
_outputLabel
T@"<SNProcessorCreating>",R,N,V_featureExtractorConfiguration
T@"NSString",R,N,V_detectorIdentifier
T@"<SNMLModel>",R,N,V_model
T@"NSString",R,N,V_outputLabel
TI,R,N,V_windowLengthFrames
TI,R,N,V_stepSizeFrames
audioProcessorWithConfiguration:
createAudioProcessorWithConfiguration:
_activeProcessorsCache
isEqualToNullResult:
peakTime
peakValue
channelIndex
_peakValue
_channelIndex
_peakTime
Td,N,V_peakValue
T{?=qiIq},N,V_peakTime
Tq,N,V_channelIndex
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
remoteObjectProxyWithErrorHandler:
_remoteObservers
initWithSoundprint_Placeholder:
soundprint_Placeholder
setSoundprint_Placeholder:
_soundprint_Placeholder
T@"MLMultiArray",&,N,V_soundprint_Placeholder
initWithSigmoid:
Sigmoid
setSigmoid:
_Sigmoid
T@"MLMultiArray",&,N,V_Sigmoid
pathForResource:ofType:
URLOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
initWithMLModel:
modelWithContentsOfURL:configuration:error:
initWithFeatureProviderArray:
featuresAtIndex:
loadWithConfiguration:completionHandler:
predictionFromSoundprint_Placeholder:error:
predictionsFromInputs:options:error:
T@"MLModel",R,N,V_model
initWithInput1:stateIn:detectedHistoryIn:
initWithInput1:
input1
setInput1:
stateIn
setStateIn:
detectedHistoryIn
setDetectedHistoryIn:
_input1
_stateIn
_detectedHistoryIn
T@"MLMultiArray",&,N,V_input1
T@"MLMultiArray",&,N,V_stateIn
T@"MLMultiArray",&,N,V_detectedHistoryIn
initWithInput_1:Confidence:Detected:detectedHistoryOut:
input_1
setInput_1:
Confidence
Detected
detectedHistoryOut
setDetectedHistoryOut:
_input_1
_Confidence
_Detected
_detectedHistoryOut
T@"MLMultiArray",&,N,V_input_1
T@"MLMultiArray",&,N,V_Confidence
T@"MLMultiArray",&,N,V_Detected
T@"MLMultiArray",&,N,V_detectedHistoryOut
predictionFromInput1:stateIn:detectedHistoryIn:error:
initWithOutput1:
output1
setOutput1:
_output1
T@"MLMultiArray",&,N,V_output1
predictionFromInput1:error:
initWithAudioSamples:
audioSamples
setAudioSamples:
_audioSamples
T@"MLMultiArray",&,N,V_audioSamples
initWith_637:
_637
set_637:
__637
T@"MLMultiArray",&,N,V__637
predictionFromAudioSamples:error:
featureValueWithDictionary:error:
featureValueWithString:
initWith_646:classLabel:
_646
set_646:
classLabel
setClassLabel:
__646
_classLabel
T@"NSDictionary",&,N,V__646
T@"NSString",&,N,V_classLabel
stringValue
initWithFixedLengthEmbedding:framewiseEmbedding:
fixedLengthEmbedding
setFixedLengthEmbedding:
framewiseEmbedding
setFramewiseEmbedding:
_fixedLengthEmbedding
_framewiseEmbedding
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
T@"MLMultiArray",&,N,V_framewiseEmbedding
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
v20@0:8f16
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
q16@0:8
v16@0:8
@"MLModel"
@"NSString"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
v24@0:8q16
@"SNTimeDurationConstraint"
{?="value"q"timescale"i"flags"I"epoch"q}
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@32@0:8@16@24
@52@0:8q16f24{?=qiIq}28
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@32@0:8@16Q24
v24@0:8Q16
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
v20@0:8I16
@?16@0:8
v24@0:8@?16
@20@0:8I16
v24@0:8^{OpaqueAudioQueue=}16
v28@0:8I16^{OpaqueAudioQueue=}20
@"NSError"
@40@0:8@16@24@32
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
v32@0:8@16@24
@"NSMutableArray"
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
@"SNDetectSignalThresholdRequestImpl"
@36@0:8d16I24d28
@40@0:8q16@24@32
v48@0:8^@16q24@32@40
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@32@0:8@16d24
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@40@0:8@16@?24@32
@32@0:8@?16@24
@"NSXPCConnection"
I20@0:8I16
@"NSUserDefaults"
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
v36@0:8@16I24^v28
@"SNDetectorHeadConfiguration"
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
v20@0:8B16
@32@0:8#16@24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@32@0:8@16@?24
@"SNTwoPassConfiguration"
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"NSNumber"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"NSURL"
@?20@0:8I16
@32@0:8@16^@24
@56@0:8@16{?=qiIq}24^@48
@56@0:8{?=qiIq}16@40^@48
@56@0:8q16@24@32@40^@48
@48@0:8@16@24Q32^@40
@48@0:8@16@24@?32^@40
B120@0:8{?=qiIq}16@40Q48{?=qiIq}56@80@88@?96@?104^@112
@48@0:8@16@24@32@?40
@84@0:8@16i24i28i32i36@40i48@52@?60@68^@76
@48@0:8@16@?24@32^@40
@56@0:8@16@?24@32@40^@48
{?=qiIq}72@0:8{?={?=qiIq}{?=qiIq}}16@?64
{?={?=qiIq}{?=qiIq}}120@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64@?112
B136@0:8@16{?={?=qiIq}{?=qiIq}}24@?72Q80@88{?=qiIq}96@?120^@128
i32@0:8@16^@24
@80@0:8@16@24@32@40@48@56@64^@72
B40@0:8@16@?24^@32
B96@0:8@16@24@32@40@48@56@64@72@?80^@88
B136@0:8@16{?={?=qiIq}{?=qiIq}}24{?={?=qiIq}{?=qiIq}}72@?120^@128
@48@0:8@16{?=qiIq}24
@28@0:8@16i24
B96@0:8@16@24@?32@40@48@56@64Q72@?80^@88
@?56@0:8@16@24Q32@?40^@48
@80@0:8@16@24{?=qiIq}32@56@?64^@72
@"SNAudioConfiguration"
@48@0:8@16@24@32@40
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@28@0:8d16I24
@40@0:8{?=qiIq}16
@"SNVoiceTriggerResult"
v36@0:8@16^v24I32
@72@0:8@16d24{?=qiIq}32@56^@64
I28@0:8I16@?20
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
{?=qiIq}56@0:8{?=qiIq}16^v40@48
{?={?=qiIq}{?=qiIq}}80@0:8{?={?=qiIq}{?=qiIq}}16^v64@72
@48@0:8@16@?24@?32@40
v28@0:8^v16i24
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@28@0:8@16B24
@"SNDetectorVariant"
@"MLModelConfiguration"
{shared_ptr<DSPGraph::Graph>=}16@0:8
@28@0:8^{Box=}16i24
^{Box=}16@0:8
@"NSArray"28@0:8^{Box=}16i24
@40@0:8^v16{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}24
B32@0:8q16@24
B24@0:8q16
B36@0:8q16@24B32
B36@0:8^I16^q24I32
B32@0:8^{AudioUnitParameterInfo=[52c]^{__CFString}I^{__CFString}IfffI}16I24I28
B36@0:8^f16I24I28I32
B28@0:8I16I20I24
B40@0:8f16I20I24I28q32
B36@0:8@16B24^@28
B40@0:8@16q24^@32
B48@0:8@16q24@32^@40
B52@0:8@16B24q28@36^@44
B44@0:8@16B24q28^@36
B48@0:8@16@24@32^@40
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@24@0:8#16
@36@0:8#16B24@28
#24@0:8@16
@48@0:8^f16^f24Q32^@40
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@48@0:8@16@?24@?32^@40
@?32@0:8@?16@24
B48@0:8@16@?24@?32^@40
v36@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16I24q28
v32@0:8@16q24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[24C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"AVAudioFormat"
@"SNUltronResultsLogger"
@20@0:8f16
@28@0:8@16I24
v40@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^{AudioBufferList=I[1{AudioBuffer=II^v}]}24I32I36
i24@0:8@16
{?=qiIq}48@0:8{?=qiIq}16@40
I28@0:8@16I24
I24@0:8@16
{_NSRange=QQ}24@0:8@16
@32@0:8@16q24
v40@0:8@16@24q32
q24@0:8@16
@40@0:8@16^{__SecTask=}24^@32
B112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}76@0:8{?={?=qiIq}{?=qiIq}}16i64I68I72
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16i64B68
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
{?=qiIq}44@0:8{?=qiIq}16B40
{?={?=qiIq}{?=qiIq}}72@0:8{?={?=qiIq}{?=qiIq}}16B64B68
v120@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64@?112
{?={?=qiIq}{?=qiIq}}112@0:8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64
{?={?=qiIq}{?=qiIq}}88@0:8{?=qiIq}16{?={?=qiIq}{?=qiIq}}40
{?={?=qiIq}{?=qiIq}}24@0:8@16
{?={?=qiIq}{?=qiIq}}32@0:8@16^@24
v52@0:8I16@?20@?28@?36@?44
I52@0:8@16I24I28B32@?36^@44
I60@0:8@16I24d28I36B40@?44^@52
{?=qiIq}72@0:8@16{?=qiIq}24I48B52@?56^@64
{?=qiIq}76@0:8@16{?=qiIq}24I48I52B56@?60^@68
B112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88@?96^@104
B116@0:8@16{?={?=qiIq}{?=qiIq}}24B72I76B80@?84@?92@?100^@108
B48@0:8@16Q24@?32^@40
B48@0:8@?16^v24Q32^@40
@112@0:8@16{?={?=qiIq}{?=qiIq}}24I72B76@?80@?88Q96^@104
@40@0:8@16d24^@32
@32@0:8@?16@?24
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@32@0:8{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16
B32@0:8q16q24
B28@0:8^f16I24
B20@0:8I16
B24@0:8f16I20
B36@0:8^I16^B24I32
B36@0:8^v16^I24I32
B32@0:8r^v16I24I28
@40@0:8@16@24I32I36
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@72@0:8d16{?={?=qiIq}{?=qiIq}}24
@72@0:8@16{?={?=qiIq}{?=qiIq}}24
@"<SNRequest>"
@40@0:8@?16@24@32
v52@0:8^{OpaqueAudioQueue=}16^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}24r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}32I40r^{AudioStreamPacketDescription=qII}44
@"NSObject<OS_os_transaction>"
B40@0:8@16@24@?32
@"SNAudioQueueConfiguration"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@56@0:8@16@24@32{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>={__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>=^{Graph}}}40^@48
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
v48@0:8@16@24@?32@?40
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@56@0:8@16@24@32@40q48
B32@0:8q16^@24
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
@"SNNullDetector"
@44@0:8d16I24d28B36B40
@"SNAudioRecordingQueue"
@"AVAudioSession"
@?32@0:8@16@?24
@?24@0:8@?16
{SNLogMelParameters=fIffiIIIIii}16@0:8
B40@0:8^{SNLogMelParameters=fIffiIIIIii}16@24^@32
B84@0:8@16{SNLogMelParameters=fIffiIIIIii}24@?68^@76
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__hash_table<std::__hash_value_type<std::string, std::string>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, std::string>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::string>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::string>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::string>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}24@0:8@16
{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}24@0:8@16
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
v32@0:8f16f20f24f28
@40@0:8@16@24@?32
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@56@0:8d16d24d32@?40@?48
@64@0:8@16@24@32d40I48I52@56
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
