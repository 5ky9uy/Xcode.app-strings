@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
?St13runtime_error
N8DSPGraph9ExceptionE
St9exception
mcpl)
St12length_error
St11logic_error
@xfuapraexoba
xfuapargxoba
MbP?NSt3__117bad_function_callE
cmcp!
cmcp!
mcpl,
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
xfuadgisxoba
xfuaftmlxoba
got no answer for question %@
BuildVersion
timeRange
decibelLevel
type
detectorIdentifier
composedDetector
illegal call to unavailable init selector: %s
-[SNComposedDetector init]
cannot deserialized MLModel
cannot serialize MLModel
cannot copy MLModel
-[SNDetectorVariant init]
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
tuningPrefix
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/48450d15-d858-11ec-878a-3e2aa58faa6a/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.0.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
doa.dspg
PropertyStrip
doa.propstrip
AUStrip
doa.austrip
Failed to create graph
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
@"NSNumber"16@?0@"NSNumber"8
expected unsigned integer; got %@
expected int32; got %@
expected uint32; got %@
expected positive number; got %@
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
q16@?0q8
v8@?0
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v24@?0^{OpaqueAudioQueue=}8@"AVAudioSession"16
/Library/Audio/Tunings
SoundAnalysis
Applause
SNVGGishApplauseModel
Babble
SNVGGishBabbleModel
Cheering
SNVGGishCheeringModel
Laughter
SNVGGishLaughterModel
Music
SNVGGishMusicModel
Speech
SNVGGishSpeechModel
Distressed Baby
SNVGGishDistressedBabyModel
Smoke Alarm
SNVGGishSmokeAlarmModel
Fire Alarm
SNVGGishFireAlarmModel
Doorbell
SNVGGishDoorbellModel
Buzzer
SNVGGishBuzzerModel
Beep
SNVGGishBeepModel
Ding Bell
SNVGGishDingBellModel
Dog Bark
SNVGGishDogBarkModel
Cat Meow
SNVGGishCatMeowModel
Door Knock
SNVGGishDoorKnockModel
Shouting
SNVGGishShoutingModel
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNSoundPrintASmokeAlarmModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
SNAudioQualityModel
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
elevation
spatialSpectrum
%@ azmimuth: %f elevation: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
com.apple.SoundAnalysis.AllAnalysisRequests
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
v8@?0
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
@32@?0@8@16^@24
@24@?0@8^@16
multiple keys mapping to the same value: %@
B32@?0@8@16^@24
B24@?0@8@16
@"NSArray"16@?0@8
B16@?0@8
@"NSNumber"24@?0@"NSNumber"8@16
@"<NSFastEnumeration>"24@?0@8^@16
@"NSDictionary"24@?0@8^@16
@"NSDictionary"16@?0@"<NSCopying>"8
bad collection; contains `nil`
@8@?0
@24@?0@8@16
q24@?0@"NSNumber"8@"NSNumber"16
partition size may not be 0
failed to divide into partitions of size %@; remainder %@
@"NSArray"32@?0@"<NSFastEnumeration>"8@"NSNumber"16^@24
@16@?0@"NSArray"8
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
enable_verbose_logging
sysdiagnose_historical_duration
daemon_recording_path
delete_recordings_without_detection
first_pass_recording_predicate
first_pass_recording_history_duration
enable_second_pass_recording_in_daemon
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
microphone_array_channel_map
@"NSNumber"24@?0@8^@16
bad type within defaults array
Library
Caches
AudioCaptures
default
audio
results
-[SNUltronReportOperator init]
unrecognized input port ID: %@
v32@?0@"NSString"8@16@"NSError"24
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
v32@?0@"NSString"8@"<SNResult>"16@"NSError"24
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
Unsupported dimension count
%@ detected: %@
Expected multi array to have standard strides
Expected count to be non-negative
Expected new dimension count to be at least as large as original
IncludePaths
Substitutions
Value
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
-[SNRecordOperator init]
failed to record audio to file
com.apple.SoundAnalysis.remoteanalyzer
all_data
label
dataset
embedding
inference_window_size
exemplar
negative
positive
training
validation
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
-[SNKShotLabel init]
illegal call to unavailable new selector: %s
+[SNKShotLabel new]
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
v16@?0@"SNKShotFeaturizationStreamResult"8
v24@?0@"SNKShotFeaturizationStreamCompletion"8@"NSError"16
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
Not enough audio segments found to continue.
v32@?0@"NSNumber"8@"MLMultiArray"16q24
v24@?0@"NSNumber"8@"MLMultiArray"16
B8@?0
MLModelCreatorDefinedKey
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
could not translate number to label: %@
expected same number of embeddings and labels
@"SNKShotFeaturizationStreamResult"32@?0@"MLMultiArray"8@"NSNumber"16^@24
unrecognized label type: %@
unrecognized dataset type: %@
@"NSDictionary"24@?0@"SNKShotFeaturizationStreamResult"8^@16
-[SNKeyValueMutation init]
unrecognized mutation type
key to be added already exists (%@)
v24@?0@8@16
required key missing from dictionary: %@
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
v24@?0@"<SNRequest>"8@"NSError"16
SNSystemAudioAnalyzerRemote.m
request
observer
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
-[SNResultsForwarder init]
v24@?0@"<SNRequest>"8@"<SNResult>"16
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
unrecognized classifier type
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
resultsPredicate
resultsPredicateLeakCount
Couldn't find soundIdentifier for detectorIdentifier %@
<Unknown Sound>
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
graph
Audio format must be PCM
Audio format channel count and sample rate must be nonzero
InvalidFormatException
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
@"NSObject<SNTimeRangeProvidingWritable>"16@?0@"NSObject<SNTimeRangeProvidingWritable>"8
%@_%@
@"NSString"16@?0@"SNDetectionResult"8
@"NSNumber"16@?0@"SNDetectionResult"8
timestamp
@"NSDictionary"16@?0@"NSArray"8
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
could not query build version and recording path
SNSoundDetectionUtils.mm
minimumStepSize <= windowLengthFrames
no supported feature extractor for detector variant
@"<SNFeatureExtractorConfiguration>"24@?0@"MLModel"8@"SNDetectorHeadModelMetadata"16
cannot create feature extractor config for identifier: %@
[identifier isEqual:detectorHeadModelMetadata.featureExtractorIdentifier]
expected feature extractor in detector head model metadata
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
v32@?0@"NSString"8@16@"NSError"24
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
#24@?0@"NSString"8^@16
could not derive tagged model classes from tags
unsupported feature extractor: %@
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
DSPGraph ABI runtime/compile-time mismatch
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
SNUtils.mm
Expected only one user-supplied input feature; got: %@
MultiArrayInput
MultiArrayOutput
soundanalysisd
InternalBuild
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
VerifyNotTrashingOwnedBuffer
mBufferMemory == NULL
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"NSString"8@?0
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
expected object %@ of class %@ to be kind of %@
@24@?0@8@?<@@?@>16
@"NSValue"16@?0@"<SNTimeRangeProviding>"8
@32@?0@8@"NSArray"16^@24
B16@?0@"<SNTimeRangeProviding>"8
@"NSArray"16@?0@"NSArray"8
error getting ring buffer bounds: %@
ring buffer sample rate is not integral: %@
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
v56@?0{?={?=qiIq}{?=qiIq}}8
{?=qiIq}56@?0{?=qiIq}8{?=qiIq}32
-[SNAudioRecordingQueue init]
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
expected file url; got %@
cannot write without overwriting at path %@
com.apple.SoundAnalysis.AnalyzerQueue
Results History (%p)
@16@?0^@8
v8@?0
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
failed to reanchor
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
-[SNOptional init]
RPFTSource
v16@?0@"RPFileTransferProgress"8
could not allocate enough memory for serialized state
^{os_state_data_s=I(?=b32I){os_state_data_decoder_s=[64c][64c]}[64c][0C]}16@?0^{os_state_hints_s=I*II}8
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
bad expression type %@ (expected %@)
B24@?0@8^@16
expected number value
keypath %@ is not one of options
B24@?0@"NSString"8^@16
bad predicate type; requires NSComparisonPredicate
bad predicate operator type; got %@, expected one of %@
B24@?0Q8^@16
B24@?0@"NSExpression"8^@16
classifierIdentifier
-[SNClassifierVariant init]
cannot encode MLModel
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
-[SNSystemAudioAnalyzerLocal setAudioConfiguration:]
SNSystemAudioAnalyzerLocal.m
[_requests count] == 0
Failed to start system audio.
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B16@?0@8
not all items are serializable to plists
@24@?0@"<SNPlistSerializable>"8^@16
string could not be parsed as int: '%@'
no class exists with name: '%@'
B16@?0@"NSString"8
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
%@/distance_classifier.mlmodelc
category
mode
options
channelMap
useSiriAudioRouting
%@, %@, AVAudioSessionOptions: %lu, useSiriAudioRouting: %d, channelMap: %@
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Only single-channel audio is supported.
Bad number of dimensions on audio input shape.
Expected output batch size %d.
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
denylist
windowSize
hopSize
feedback_connections
inputFeature
-[SNModelFeatureConnection init]
@"NSDictionary"24@?0@"NSDictionary"8^@16
couldn't parse feedback connection; expected format 'source -> destination'; got: '%@'
@"SNModelFeatureConnection"24@?0@"NSString"8^@16
@"NSString"16@?0@"SNModelFeatureConnection"8
expected destination features to be unique; got %@
expected all source features to have affiliated outputs: source features = (%@); outputs = (%@)
expected all destination features to have affiliated inputs: destination features = (%@); inputs = (%@)
@"NSSet"24@?0@"NSString"8^@16
@"NSNumber"24@?0@"NSString"8^@16
@"NSString"24@?0@"NSString"8^@16
@"NSDictionary"24@?0@?<@"NSDictionary"@?@^@>8^@16
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
-[SNPredicateFilterOperator init]
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
start time follows target time
@"NSValue"16@?0@"NSValue"8
time (%@) not in expected range (%@)
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected non-nil request
expected non-nil observer
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
yyyyMMdd'T'HHmmss'Z'
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss'Z'
input1
detectedHistoryIn
input_1
detectedHistoryOut
mlmodelc
output1
audioSamples
soundprint/Placeholder
Sigmoid
SNSoundPrint100kFireAlarmModel
classLabel
SNSoundClassifierVersion1Model
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintKEmbeddingModel
final_output
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) start
(SNSystemAudioAnalyzerXPCPublisher:%@) stop
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel map (zero-indexed) %@ with result %d
Unsupported product type
Could register audio units. Returning nil for %@
Client rejected due to insufficient entitlements.
Removing %@, since it doesn't contain any detections
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
(SNSystemAudioAnalyzerRemote:%@) start
(SNSystemAudioAnalyzerRemote:%@) stop
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
SNDetectSoundRequest decoded (and rejected) a forbidden predicate
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Error analyzing audio buffer
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
Failed to open audio file %@ with error %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Audio Running Heartbeat (%@); time changed from %@ to %@
Audio Heartbeat Reanchor (%@); time changed from %@ to %@
Not enough funds to schedule audio buffer for processing!Queue Funds Spent: %@. Queue Funds Earned: %@.Buffer Length: %@.
Queue already running
Failed to create audio queue
Starting audio queue
Error starting audio queue, %@
Stopping audio queue
Completed first pass for request %@ with error %@
Beginning second pass for request %@
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Collecting state information (title: %@)
Error capturing state! %@
Error preparing captured state! %@
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
(SNSystemAudioAnalyzerLocal:%@) start
(SNSystemAudioAnalyzerLocal:%@) stop
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Starting audio input. %@, %@
Failed to deactivate AVAudioSession with error %@
SNAudioRecordingQueue interrupted
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 feature
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) start
(SNSystemAudioAnalyzerXPCSubscriber:%@) stop
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
attempt to remove nil request
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNAudioQualityModel.mlmodelc in the bundle resource
SNSystemUtils
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNComposedDetector
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNNumberUtils
SNAtomicUtils
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNPlatformUtils
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNCollectionUtils
SNSpeechDistanceResult
SNUserDefaults
SNUltronReportOperator
SNOperator
SNDeleteFilesRequest
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNPlistSerializable
SNMLModelCacheKey
SNAudioMultiArrayUtils
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNMultiArrayUtils
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNFeatureExtractorConfiguration
SNProcessorCreating
SNResultsXPCSubscriber
SNResultsObserving
SNRecordOperator
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotLabel
SNKShotFeaturizationStreamResult
SNKShotFeaturizationStreamCompletion
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNKShotSegment
SNKShotFeaturizer
SNFileListingResult
SNKeyValueMutation
SNKeyValueUtils
SNSystemAudioAnalyzerRemote
SNResultsForwarder
SNObserverUtils
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNAudioFormatUtils
SNDiscoverFileServerRequest
SNUltronUtils
SNSoundDetectionUtils
SNValidateModel
SNDaemon
SNOperatorUtils
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNBooleanCancellable
SNCancellable
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
DSPGMLInputProvider
MLFeatureProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNObjectUtils
SNTwoPassConfiguration
SNHistoryUtils
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNFileUtils
SNAudioStreamAnalyzer
SNLogMelBasedFeatureExtractor
SNScheduleUtils
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNOptional
SNOptionalUtils
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNPredicateUtils
SNClassifierVariant
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNPlistUtils
SNStringUtils
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNDetectorHeadModelMetadata
SNModelFeatureConnection
SNModelMetadataUtils
SNPredicateFilterOperator
SNResultsXPCPublisher
SNTimeUtils
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNDateUtils
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrintASmokeAlarmModelInput
SNSoundPrintASmokeAlarmModelOutput
SNSoundPrintASmokeAlarmModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNAudioQualityModelInput
SNAudioQualityModelOutput
SNAudioQualityModel
stringWithFormat:
allocWithZone:
init
timeRange
setTimeRange:
decibelLevel
valueWithCMTimeRange:
isEqual:
hash
numberWithFloat:
decodeObjectOfClass:forKey:
decodeDoubleForKey:
CMTimeRangeValue
encodeObject:forKey:
encodeDouble:forKey:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
T{?={?=qiIq}{?=qiIq}},R,N
T{?={?=qiIq}{?=qiIq}},N
_decibelLevel
_timeRange
Tf,R,N
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
raise:format:
.cxx_destruct
_featureExtractorType
_detectorHeadModel
decodeIntegerForKey:
encodeInteger:forKey:
copy
numberWithInteger:
_type
_composedDetector
_detectorIdentifier
mood
valence
arousal
dominance
confidence
setConfidence:
numberWithDouble:
unarchivedObjectOfClass:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithBinarySampleRepresentation:metadata:timestamp:
binarySampleRepresentation
Td,R,N
Td,N
initWithMood:valence:arousal:dominance:
_confidence
_mood
_valence
_arousal
_dominance
Td,R
Td,N,V_confidence
initWithTuningPrefix:
isEqualToString:
createAnalyzerWithError:
spatialSpectrum
_tuningPrefix
_spatialSpectrum
T@"NSArray",R,N,V_spatialSpectrum
resultsBox
arrayWithObjects:count:
stringWithUTF8String:
adaptToSystemConfiguration:error:
graph
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
resultsFromBox:renderedWithFrameCount:
sharedProcessorConfiguration
primeGraph
T^v,R,N
.cxx_construct
_graph
_azimuth
defaultWindowDuration
initWithFeaturePrintType:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
windowDurationConstraint
featurePrintType
setFeaturePrintType:
overlapFactor
setOverlapFactor:
windowDuration
setWindowDuration:
valueWithCMTime:
decodeFloatForKey:
decodeCMTimeForKey:
encodeFloat:forKey:
encodeCMTime:forKey:
_overlapFactor
_windowDurationConstraint
_featurePrintType
_windowDuration
Tq,N,V_featurePrintType
Tf,N,V_overlapFactor
T{?=qiIq},N,V_windowDuration
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
blockSize
createWithSampleRate:windowDuration:overlapFactor:error:
TI,R,N
T{?=qiIq},R,N
T@"SNTimeDurationConstraint",R,N
extractDefaultOutputFeatureFromFeatureProvider:
featureNames
count
allObjects
firstObject
featureValueForName:
extractOutputWithOptionalName:fromFeatureProvider:
type
multiArrayValue
initWithFeaturePrintType:featureVector:
_featureExtractor
_outputFeatureName
_resultsToDiscardCount
initWithOverlapFactor:error:
initWithModelDescription:parameterDictionary:error:
model
resultsBoxName
UTF8String
sampleRate
initWithEnumeratedDurations:
_blockSize
TI,R,N,V_blockSize
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
modelDescription
inputDescriptionsByName
allValues
objectAtIndexedSubscript:
multiArrayConstraint
numberWithLongLong:
numberWithUnsignedInteger:
numberWithUnsignedLong:
shapeConstraint
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithSampleRate:windowDuration:overlapFactor:error:
dataWithBytes:length:
addAudio:
endAudio
getLatestSuperVector
initWithConfigFile:configRoot:sampleRate:delegate:queue:
resetForNewRequest
setCurrentFrameValue:
setMeanValue:
setStandardDeviation:
bundleForClass:
resourcePath
serverInfo
state
_serverInfo
_state
T@"SNFileServerInfo",R
compare:
integerValue
unsignedIntegerValue
numberWithUnsignedLongLong:
numberWithInt:
numberWithUnsignedInt:
numberWithShort:
numberWithUnsignedShort:
numberWithChar:
numberWithUnsignedChar:
xpcRequest:didProduceResult:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequestDidComplete:completionHandler:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
synchronousRemoteObjectProxyWithErrorHandler:
xpcAddRequest:withObserver:completionHandler:
xpcRemoveRequest:completionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcStartWithCompletionHandler:
xpcStopWithCompletionHandler:
xpcSetAudioConfiguration:completionHandler:
setAudioConfiguration:
addRequest:withObserver:error:
removeRequest:
removeAllRequests
start
stop
_subscriber
_creationFlags
_configureAudioQueue
setChannelMap:
useSiriAudioRouting
channelMap
availableInputs
countByEnumeratingWithState:objects:count:
portType
objectAtIndex:
unsignedIntValue
length
substringToIndex:
uppercaseString
substringFromIndex:
stringByAppendingString:
pathWithComponents:
fileName
error
_fileName
_error
T@"NSString",R,N
T@"NSError",R,N
allValidSoundIdentifiers
allValidDetectorIdentifiers
_detectorHead
_soundIdentifier
launchTaskWithQueue:completionHandler:resultsHandler:
valueWithPointer:
setObject:forKeyedSubscript:
objectForKey:
removeObjectForKey:
addRequest:completionHandler:resultsHandler:
_taskCompletionMap
_queue
CMTimeValue
sortedArrayUsingComparator:
initWithDurationRange:
isEqualToTimeDurationConstraint:
durationRange
enumeratedDurations
isEqualToArray:
decodeCMTimeRangeForKey:
setWithArray:
decodeObjectOfClasses:forKey:
encodeCMTimeRange:forKey:
_enumeratedDurations
_durationRange
Tq,R,V_type
T@"NSArray",R,V_enumeratedDurations
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
setSampleRate:
setBlockSize:
magnitudeThreshold
setMagnitudeThreshold:
_detector
_sampleRate
_magnitudeThreshold
Td,N,V_sampleRate
TI,N,V_blockSize
Td,N,V_magnitudeThreshold
array
addObject:
dictionaryWithObjectsAndKeys:
errorWithDomain:code:userInfo:
azimuth
elevation
_elevation
T@"NSArray",R,N
allKeys
dictionaryWithObjects:forKeys:count:
initWithDictionary:error:
predictionFromFeatures:options:error:
outputDescriptionsByName
predictionsFromBatch:options:error:
_modelDescription
_model
initWithAudioFile:
_referenceAudioFile
Td,V_overlapFactor
processingFormat
_systemConfiguration
_referenceSampleRate
_channelCount
_framesProcessed
initWithDictionary:resourcePath:
initWithPCMFormat:frameCapacity:
setFramePosition:
readIntoBuffer:error:
streamDescription
audioBufferList
createSystemAudioAnalyzer
setDelegate:
resume
endpoint
initWithListenerEndpoint:
setExportedInterface:
setExportedObject:
valueForEntitlement:
boolValue
initWithMachServiceName:
listener:shouldAcceptNewConnection:
_listener
_coordinator
initWithMachServiceName:options:
setInterruptionHandler:
setInvalidationHandler:
setRemoteObjectInterface:
remoteObjectProxy
_connectionToServerGenerator
_xpcConnectionToServer
_pendingInvalidationHandlers
orderedSetWithArray:
minusOrderedSet:
dictionary
setObject:forKey:
containsObject:
lastObject
reverseObjectEnumerator
meanValue
currentFrameValue
standardDeviation
_currentFrameValue
_meanValue
_standardDeviation
Td,N,V_currentFrameValue
Td,N,V_meanValue
Td,N,V_standardDeviation
initWithSuiteName:
boolForKey:
doubleForKey:
stringForKey:
arrayForKey:
predicateWithFormat:
defaultManager
path
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
processInput:portID:downstreamHandler:
processTerminationWithOptionalError:portID:downstreamHandler:
removeItemAtURL:error:
_recordOperator
_destinationDirectory
_date
_requestDescription
_buildVersion
_detectionResults
setDispatchQueue:
identifier
sendRequestID:request:destinationID:options:responseHandler:
activateWithCompletion:
invalidate
initWithFiles:serverBasePath:serverInfo:
_files
_serverBasePath
T@"MLModelDescription",R
_customModel
T@"MLModelDescription",R,V_modelDescription
_lock
dataType
initWithIdentifier:
floatValue
initWithConfiguration:
_configuration
_detectorBoxName
_inputFeatureName
_outputConfidenceFeatureName
_outputDetectedFeatureName
_predicateFilter
objectForKeyedSubscript:
shape
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
_receiver
initWithIdentifier:detectedValue:
detected
detectorIdentifier
numberWithBool:
decodeBoolForKey:
encodeBool:forKey:
plistRepresentationWithError:
_detected
_identifier
T@"NSString",R,N,V_identifier
TB,R,N
initWithModelClass:modelConfiguration:
_keys
numberWithLong:
createSecondPassController
twoPassConfiguration
T@"SNTwoPassConfiguration",R
_createSecondPassControllerFunction
_twoPassConfiguration
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
insertObject:atIndex:
strides
mutableCopy
dataPointer
initWithDataPointer:shape:dataType:strides:deallocator:error:
stringByAppendingPathComponent:
_path
_text
_includePaths
_substitutions
_value
_resourcePath
_dspItems
dictionaryWithContentsOfFile:
createProcessorWithError:
windowLengthFrames
stepSizeFrames
outputFeatureSize
TI,R
_windowLengthFrames
_stepSizeFrames
Td,R,D
TI,R,V_windowLengthFrames
TI,R,V_stepSizeFrames
TI,R,D
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
settings
commonFormat
isInterleaved
initForWriting:settings:commonFormat:interleaved:error:
dealloc
writeFromBuffer:error:
_format
_outputFile
initWithAudioConfiguration:
addRequestInBackground:withObserver:
_impl
fileURLs
setFileURLs:
backgroundEnergyPercentile
setBackgroundEnergyPercentile:
foregroundEnergyPercentile
setForegroundEnergyPercentile:
hangoverDuration
setHangoverDuration:
minSegmentDuration
setMinSegmentDuration:
similarityThreshold
setSimilarityThreshold:
_backgroundEnergyPercentile
_foregroundEnergyPercentile
_similarityThreshold
_fileURLs
_hangoverDuration
_minSegmentDuration
T@"NSArray",V_fileURLs
Tf,V_backgroundEnergyPercentile
Tf,V_foregroundEnergyPercentile
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
Tf,V_similarityThreshold
initAsNegativeLabel
initAsPositiveLabel
data
setData:
label
setLabel:
datasetType
setDatasetType:
_data
_label
_datasetType
T@"MLMultiArray",&,V_data
T@"SNKShotLabel",&,V_label
Tq,V_datasetType
exemplar
setExemplar:
inferenceWindowSize
setInferenceWindowSize:
_exemplar
_inferenceWindowSize
T@"MLMultiArray",&,V_exemplar
T{?=qiIq},V_inferenceWindowSize
trainingDataEmbeddings
setTrainingDataEmbeddings:
trainingDataLabels
setTrainingDataLabels:
validationDataEmbeddings
setValidationDataEmbeddings:
validationDataLabels
setValidationDataLabels:
_trainingDataEmbeddings
_trainingDataLabels
_validationDataEmbeddings
_validationDataLabels
T@"NSArray",C,V_trainingDataEmbeddings
T@"NSArray",C,V_trainingDataLabels
T@"NSArray",C,V_validationDataEmbeddings
T@"NSArray",C,V_validationDataLabels
exemplarEmbedding
setExemplarEmbedding:
segments
setSegments:
exemplarIndex
setExemplarIndex:
_exemplarEmbedding
_segments
_exemplarIndex
T@"MLMultiArray",&,V_exemplarEmbedding
T@"NSArray",C,V_segments
T@"NSNumber",C,V_exemplarIndex
_embeddings
_labels
setUrl:
_url
T{?={?=qiIq}{?=qiIq}},V_timeRange
T@"NSURL",C,V_url
initWithShape:dataType:error:
arrayWithObjects:
initWithCapacity:
initWithURL:error:
analyzeInRange:
errors
results
doubleValue
featurizeFiles:hallucinatorModelURL:queue:resultHandler:completionHandler:
initForReading:commonFormat:interleaved:error:
analyze
featureVector
sliceAtOrigin:shape:squeeze:error:
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
fileFormat
addObjectsFromArray:
performSegmentationRequest:error:
localizedDescription
intValue
subarrayWithRange:
metadata
valueWithRange:
dictionaryWithDictionary:
predictionFromFeatures:error:
arrayByAddingObjectsFromArray:
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
plistFromFeaturizationResult:error:
fileItems
_fileItems
T@"NSArray",R
valueWithNonretainedObject:
_keyPath
valueForKeyPath:
setValue:forKeyPath:
setWithObject:
setWithSet:
minusSet:
intersectSet:
sleepForTimeInterval:
removeAllObjects
_registeredRequests
_analyzer
_generator
_audioConfiguration
_completionHandler
_resultsHandler
idsDeviceID
name
_idsDeviceID
_name
T@"NSString",R
bytes
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
initWithDouble:
initWithUnsignedInt:
_timeBetweenTriggers
_lastResult
predictedProbabilitiesName
predictedFeatureName
exceptionWithName:reason:userInfo:
dictionaryValue
initWithClassificationDictionary:
setClassifierIdentifier:
_modelBlockSize
_classLabelsDenylist
_classifierIdentifier
initWithMLModel:error:
initWithClassifierIdentifier:error:
knownClassifications
_classifier
_knownClassifications
T{?=qiIq},V_windowDuration
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"NSArray",R,C,V_knownClassifications
initWithFormat:
framePosition
readIntoBuffer:frameCount:error:
analyzeAudioBuffer:atAudioFramePosition:
frameLength
completeAnalysis
analyzeWithCompletionHandler:
cancelAnalysis
_audioFile
_streamAnalyzer
_wasCancelled
initWithRequestType:
decisionDelay
_requestType
clientSampleTimeFromSampleTime:fromBox:
clientSampleRate
dictionaryWithCapacity:
timeConversionDictionary
T@"NSDictionary",R
addEntriesFromDictionary:
valueForKey:
setValue:forKey:
_timeConverter
_requestState
initWithSoundIdentifier:
initWithDetectorVariant:soundIdentifier:modelConfiguration:resultsPredicate:resultsPredicateLeakCount:
soundIdentifier
allowEvaluation
setResultsPredicate:error:
T@"NSArray",R,D,N
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithDetectorIdentifier:error:
initWithVGGishBasedMLModel:soundIdentifier:
setResultsPredicate:
setResultsPredicateLeakCount:
modelConfiguration
setModelConfiguration:
resultsPredicate
resultsPredicateLeakCount
_detectorVariant
_modelConfiguration
_resultsPredicate
_resultsPredicateLeakCount
T@"NSString",R,N,V_soundIdentifier
T@"MLModelConfiguration",&,N,V_modelConfiguration
T@"NSPredicate",C,N,V_resultsPredicate
Tq,N,V_resultsPredicateLeakCount
T{shared_ptr<DSPGraph::Graph>=},R,N
T^{Box=},R,N
initWithBox:fromGraph:
_box
channelCount
idsDeviceIdentifier
setLocalDeviceUpdatedHandler:
setDeviceLostHandler:
setDeviceFoundHandler:
setDeviceChangedHandler:
stringByAppendingPathExtension:
URLByAppendingPathComponent:
sendInputToUltronReporter:recentFramesOfAudioBuffer:startingFromTime:error:
date
fileURLWithPath:
stepSizeFramesForWindowLengthFrames:overlapFactor:minimumStepSize:roundingDownToNearestMultipleOf:
hopSizeInSamples
windowSizeInSamples
featureExtractorConfigurationForIdentifier:detectorHeadModelMetadata:modelConfiguration:error:
featureExtractorIdentifier
isOptional
sizeRangeForDimension
rangeValue
enumeratedShapes
currentRunLoop
initWithRootDirectory:
_fileServer
setInterface:forSelector:argumentIndex:ofReply:
_maxCacheSize
_cacheStorage
_cacheAccessRecency
_wrappedModel
strongToWeakObjectsMapTable
_vendedModels
initWithConfiguration:error:
_featureVector
Tq,R,N,V_featurePrintType
T@"MLMultiArray",R,N,V_featureVector
_configured
_request
_analyzerHost
_sharedProcessor
_configurationError
removeObject:
indexOfObjectIdenticalTo:
arrayByAddingObject:
arrayWithArray:
removeObjectAtIndex:
updateProcessingTreeFormat:
format
_processorCache
_processingContexts
_processingTree
_currentFormat
_requests
_analyzerInfos
_shouldRebuildProcessingTree
_inputSensitivity
setServiceType:
setDestinationID:
setPath:
setCompletionHandler:
performQuery:
initWithServerInfo:queryPath:
_queryPath
mutableAudioBufferList
setFrameLength:
frameCapacity
classLabels
constraintWithShape:dataType:
featureDescriptionWithName:type:optional:constraints:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
processInfo
processName
stringByReplacingOccurrencesOfString:withString:
contentsOfDirectoryAtPath:error:
filterUsingPredicate:
sortUsingComparator:
unsignedLongLongValue
removeItemAtPath:error:
stringByDeletingPathExtension
attributesOfItemAtPath:error:
attributesOfFileSystemForPath:error:
initForReading:error:
null
channelLayout
initWithStreamDescription:channelLayout:
initSecondaryReader:format:error:
loadContentsOfURL:configuration:completionHandler:
automaticallyNotifiesObserversForKey:
willChangeValueForKey:
didChangeValueForKey:
clearResults
clearErrors
clearCompleteCount
completeCount
_results
_errors
_completeCount
Tq,R,N,V_completeCount
cancel
_isCancelled
initWithStreamDescription:
initWithDSPGraph:
setObject:atIndexedSubscript:
featureValueWithMultiArray:
T@"NSSet",R,N
_featureDescription
_featureCache
_allInputFeatureNames
_input
_feedbackConnections
_inputProvider
_outputProvider
compileModelAtURL:error:
modelWithContentsOfURL:error:
filename
fileSize
itemURL
_filename
_fileSize
_itemURL
Tq,R
T@"NSURL",R
minDurationBlocks
confidenceThreshold
arrayWithCapacity:
_maxHistoryLength
_confidenceThreshold
_streak
_history
_commandFilters
offset
_offset
deregisterRequestID:
registerRequestID:options:handler:
getIdentitiesWithCompletion:
edPKData
flags
setFlags:
prepareTemplateAndReturnError:
fileURLWithPath:isDirectory:
setTemporaryDirectoryURL:
setReceivedItemHandler:
setPeerPublicKey:
setTargetID:
activate
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
_serverFilePaths
_localDestinationPath
_firstPassRequest
_secondPassRequest
_historicalDataAmount
nonretainedObjectValue
floatChannelData
initWithAudioTimeStamp:sampleRate:
_eventHandlerQueue
_eventHandlerQueueFundsSpent
_eventHandlerQueueFundsEarned
_eventHandlerQueueStopped
_bufferHandler
_interruptionHandler
_transaction
_recordFormat
_lastHeartbeatTime
opaqueSessionID
_audioQueueConfiguration
_session
_dispatchQueue
_running
_audioQueue
_aqCallbackScheduler
anyObject
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
isAllowedShape:error:
_inputConstraint
_outputConstraint
_scratchFloatSpace
_modelOutput
_preProcessCallback
isFileURL
getResourceValue:forKey:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
removeLastObject
pathComponents
fileURLWithPathComponents:
URLByDeletingLastPathComponent
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileExistsAtPath:
writeToURL:options:error:
dataWithJSONObject:options:error:
dataWithContentsOfURL:options:error:
JSONObjectWithData:options:error:
shouldLogResultsHistory
addRequest:completionHandler:resultsHandler:error:
evaluateWithObject:
setBeginSecondPassHandler:
setEndSecondPassHandler:
firstPassDidProduceResult:
dateByAddingTimeInterval:
secondPassDidProduceResult:
string
appendString:
_analyzerQueue
_firstPassRecordingPredicate
_firstPassRecordingHistoryDuration
_sysdiagnoseHistoryDuration
_firstPassAnalyzer
_secondPassAnalyzers
_secondPassUltronReportOps
_firstPassUltronReportOps
_firstPassResultsHistory
_ringBuffer
_ringBufferWriteBufferList
_unregisterLogCollectHook
_analysisState
_minDurationBlocks
T@"NSString",R,N,V_name
Tq,R,N,V_minDurationBlocks
Td,R,N,V_confidenceThreshold
initWithModel:dictionary:error:
hopSizeSamples
setHopSizeSamples:
blocksBetweenTriggers
setBlocksBetweenTriggers:
commands
setCommands:
_hopSizeSamples
_blocksBetweenTriggers
_commands
Td,R,N,V_sampleRate
Tq,N,V_hopSizeSamples
Tq,N,V_blocksBetweenTriggers
T@"NSArray",C,N,V_commands
_modelOutputFilter
_overlapFilter
_object
setProgressHandler:
setFilename:
setItemURL:
addItem:
finish
_server
_link
_rootDirectory
setRootDirectoryURL:
pathExtension
_boxName
_busIndex
setDateFormat:
stringFromDate:
componentsSeparatedByString:
dataWithPropertyList:format:options:error:
computationalDutyCycle
setComputationalDutyCycle:
graphIsDeadEnded
setGraphIsDeadEnded:
shouldThrowException
setShouldThrowException:
_graphIsDeadEnded
_shouldThrowException
_computationalDutyCycle
Td,N,V_computationalDutyCycle
TB,N,V_graphIsDeadEnded
TB,N,V_shouldThrowException
initAuxiliarySession
decoupledIO
inputSampleRate
inputNumberOfChannels
expressionType
constantValue
keyPath
predicateOperatorType
leftExpression
rightExpression
_mlModel
indexOfObject:
category
mode
options
setCategory:mode:options:error:
setActive:error:
initWithLayoutTag:
initWithCommonFormat:sampleRate:interleaved:channelLayout:
sampleTime
defaultCenter
handleAVAudioSessionInterruption:
addObserver:selector:name:object:
handleAVAudioSessionRouteChange:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
removeObserver:
_analysisQueue
_recordingQueue
_recordingState
_clientStartedAnalysis
_observers
_audioSession
_logMelExtractionParameters
stringValue
componentsSeparatedByCharactersInSet:
whitespaceAndNewlineCharacterSet
componentsJoinedByString:
_interpreter
_minimumObservableOffset
_maximumObservableOffset
initWithIdentifier:confidence:
enumerateKeysAndObjectsUsingBlock:
classifierIdentifier
classificationForIdentifier:
classifications
_cachedClassifications
_classificationDictionary
T@"NSString",C,N,V_classifierIdentifier
T@"NSArray",R,C
T@"NSString",R,C,V_identifier
Td,R,V_confidence
modelURLForCurrentProduct
setCategory:
setMode:
setOptions:
unarchivedArrayOfObjectsOfClass:fromData:error:
setUseSiriAudioRouting:
decodeArrayOfObjectsOfClass:forKey:
_useSiriAudioRouting
_category
_mode
_options
_channelMap
T@"NSString",C,N,V_category
T@"NSString",C,N,V_mode
TQ,N,V_options
T@"NSArray",C,N,V_channelMap
TB,N,V_useSiriAudioRouting
hasPrefix:
initWithModel:modelDescription:
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
_outputShape
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
beginSecondPassHandler
endSecondPassHandler
T@?,C
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassTriggerTime
_firstResultBelowEndThresholdStartTime
_secondPassIsActive
_firstPassResultToComparableFunction
_secondPassResultToComparableFunction
_beginSecondPassHandler
_endSecondPassHandler
T@?,C,V_beginSecondPassHandler
T@?,C,V_endSecondPassHandler
_featureExtractorConfiguration
_outputLabel
_activeProcessorsCache
peakTime
peakValue
channelIndex
_peakValue
_channelIndex
_peakTime
Tq,R,N
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
setFeatureExtractorIdentifier:
setWindowSizeInSamples:
setHopSizeInSamples:
setSoundIdentifier:
_featureExtractorIdentifier
_windowSizeInSamples
_hopSizeInSamples
T@"NSNumber",C,V_sampleRate
T@"NSString",C,V_featureExtractorIdentifier
T@"NSNumber",C,V_windowSizeInSamples
T@"NSNumber",C,V_hopSizeInSamples
T@"NSString",C,V_soundIdentifier
_sourceFeatureName
_destinationFeatureName
isSubsetOfSet:
_leakRemaining
_predicate
_leakCount
remoteObjectProxyWithErrorHandler:
endTimesFromTimeRangeCollection:
_remoteObservers
timeZoneWithName:
setTimeZone:
initWithLocaleIdentifier:
setLocale:
dateFromString:
setYear:
setMonth:
setDay:
setHour:
setMinute:
setSecond:
setNanosecond:
currentCalendar
dateFromComponents:
initWithInput1:stateIn:detectedHistoryIn:
input1
stateIn
detectedHistoryIn
initWithInput1:
setInput1:
setStateIn:
setDetectedHistoryIn:
_input1
_stateIn
_detectedHistoryIn
T@"MLMultiArray",&,N,V_input1
T@"MLMultiArray",&,N,V_stateIn
T@"MLMultiArray",&,N,V_detectedHistoryIn
input_1
Confidence
Detected
detectedHistoryOut
initWithInput_1:Confidence:Detected:detectedHistoryOut:
setInput_1:
setDetected:
setDetectedHistoryOut:
_input_1
_Confidence
_Detected
_detectedHistoryOut
T@"MLMultiArray",&,N,V_input_1
T@"MLMultiArray",&,N,V_Confidence
T@"MLMultiArray",&,N,V_Detected
T@"MLMultiArray",&,N,V_detectedHistoryOut
pathForResource:ofType:
URLOfModelInThisBundle
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
initWithMLModel:
modelWithContentsOfURL:configuration:error:
initWithFeatureProviderArray:
featuresAtIndex:
loadWithConfiguration:completionHandler:
predictionFromInput1:stateIn:detectedHistoryIn:error:
predictionsFromInputs:options:error:
T@"MLModel",R,N,V_model
output1
initWithOutput1:
setOutput1:
_output1
T@"MLMultiArray",&,N,V_output1
predictionFromInput1:error:
audioSamples
initWithAudioSamples:
setAudioSamples:
_audioSamples
T@"MLMultiArray",&,N,V_audioSamples
_637
initWith_637:
set_637:
__637
T@"MLMultiArray",&,N,V__637
predictionFromAudioSamples:error:
soundprint_Placeholder
initWithSoundprint_Placeholder:
setSoundprint_Placeholder:
_soundprint_Placeholder
T@"MLMultiArray",&,N,V_soundprint_Placeholder
Sigmoid
initWithSigmoid:
setSigmoid:
_Sigmoid
T@"MLMultiArray",&,N,V_Sigmoid
predictionFromSoundprint_Placeholder:error:
featureValueWithDictionary:error:
classLabel
featureValueWithString:
initWith_9:classLabel:
set_9:
setClassLabel:
_classLabel
T@"NSDictionary",&,N,V__9
T@"NSString",&,N,V_classLabel
fixedLengthEmbedding
framewiseEmbedding
initWithFixedLengthEmbedding:framewiseEmbedding:
setFixedLengthEmbedding:
setFramewiseEmbedding:
_fixedLengthEmbedding
_framewiseEmbedding
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
T@"MLMultiArray",&,N,V_framewiseEmbedding
final_output
initWithFinal_output:classLabel:
setFinal_output:
_final_output
T@"NSDictionary",&,N,V_final_output
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v16@0:8
@"NSString"
@"MLModel"
@"SNComposedDetector"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@48@0:8d16d24d32d40
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
v20@0:8f16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
q16@0:8
v24@0:8q16
@"SNTimeDurationConstraint"
{?="value"q"timescale"i"flags"I"epoch"q}
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
@"NSError"
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8I16
@"SNDetectSignalThresholdRequestImpl"
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@"NSXPCConnection"
@"NSMutableArray"
v40@0:8@16@"NSString"24@?<v@?@"NSString"@@"NSError">32
v40@0:8@"NSError"16@"NSString"24@?<v@?@"NSString"@@"NSError">32
@"SNRecordOperator"
@"NSURL"
@"NSDate"
@40@0:8@16@24@32
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"SNDetectorHeadConfiguration"
@"SNPredicateFilterOperator"
v24@0:8@?16
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
@28@0:8@16B24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@"SNTwoPassConfiguration"
@32@0:8@16@24
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@16@24
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"AVAudioFormat"
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"SNKShotLabel"
@"NSNumber"
@48@0:8@16@24@32@?40
@56@0:8@16@24@32@?40@?48
@32@0:8@16^@24
@"SNAudioConfiguration"
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@"SNVoiceTriggerResult"
@"NSSet"
@"SNClassifierVariant"
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@56@0:8@16@24@32@40q48
@"SNDetectorVariant"
@"MLModelConfiguration"
@"NSPredicate"
B64@0:8@16^v24{?=qiIq}32^@56
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[32C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@48@0:8@16@24@32@40
@"<SNRequest>"
@"NSObject<OS_os_transaction>"
@"SNAudioQueueConfiguration"
@"AVAudioSession"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
B48@0:8@16@?24@?32^@40
v32@0:8@16q24
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
v20@0:8B16
@"SNNullDetector"
@"SNAudioRecordingQueue"
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
@32@0:8@16d24
v24@0:8Q16
@?16@0:8
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
@(#)PROGRAM:SoundAnalysis  PROJECT:SoundAnalysis-1
?St13runtime_error
N8DSPGraph9ExceptionE
St9exception
mcpl)
cmcp!
St12length_error
St11logic_error
@xfuapraexoba
mron
xfuapargxoba
MbP?NSt3__117bad_function_callE
cmcp!
cmcp!
mcpl,
xfuamlpslppa
.AN5caulk19bad_expected_accessIvEE
xfualmrcxoba
xfuaxtncxoba
xfuadgisxoba
xfuaftmlxoba
got no answer for question %@
BuildVersion
timeRange
decibelLevel
type
detectorIdentifier
composedDetector
illegal call to unavailable init selector: %s
-[SNComposedDetector init]
cannot deserialized MLModel
cannot serialize MLModel
cannot copy MLModel
-[SNDetectorVariant init]
mood
valence
arousal
dominance
confidence
%@ Mood: %.2f Valence: %.2f Arousal: %.2f Dominance: %.2f Confidence: %.2f %@
tuningPrefix
Failed to create DSPGraph
/AppleInternal/Library/BuildRoots/48450d15-d858-11ec-878a-3e2aa58faa6a/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator16.0.Internal.sdk/System/Library/PrivateFrameworks/AudioToolboxCore.framework/PrivateHeaders/DSPGraph_Box.h
Box::out inIndex out of range! box %s has %zu outputs but input %u was requested
Type
DSPGraph
Path
doa.dspg
PropertyStrip
doa.propstrip
AUStrip
doa.austrip
Failed to create graph
featurePrintType
overlapFactor
windowDuration
Invalid parameter not satisfying: %@
overlapFactor >= 0.f
overlapFactor < 1.f
-[SNFeaturePrintExtractor adaptToSystemConfiguration:error:]
SNCreateFeaturePrintRequest.mm
[featureExtractorClass conformsToProtocol:@protocol(SNFeaturePrintExtractorProtocol)]
Feature extractor should have only one output feature
Feature extractor should only use MultiArray features
LogMelSpectrogram
context
logMelSpectrogram
deadEnd
-[SNVGGishExtractor initWithOverlapFactor:error:]
overlapFactor >= 0.0
overlapFactor < 1.0
FeaturePrintBox
Requested block size %@ not in allowable range %@ to %@
CoreML
createCoreMLGraph
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
com.apple.SoundAnalysis.EARAudioProcessor
initialize
DSPGraph_EARAudioProcessorBox.mm
in(0).format().mSampleRate == 16000
in(0).format().mChannelsPerFrame == 1
in(0).format().mBytesPerFrame == 2
config
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_EARAudioProcessorBox.mm
inputs must be 16kHz
Box::in inIndex out of range! box %s has %zu inputs but input %u was requested
EARAudioProcessorBox
DIST
b238a_distance_estimation.dspg
b238a_distance_estimation.propstrip
b238a_distance_estimation.austrip
@"NSNumber"16@?0@"NSNumber"8
expected unsigned integer; got %@
expected int32; got %@
expected uint32; got %@
expected positive number; got %@
FormatMatchingNode
SoundAnalysis_FormatMatchingNode.cpp
upstreamFormat.mBlockSize == 1
downstreamFormat.mBlockSize == 1
setUpstreamFormat
formatMatchingGraph
input
channelMapper
output
q16@?0q8
v8@?0
-[SNSystemAudioAnalyzerXPCPublisher init]
v16@?0@"NSError"8
could not add request; communication with server failed
v24@?0^{OpaqueAudioQueue=}8@"AVAudioSession"16
/Library/Audio/Tunings
SoundAnalysis
Applause
SNVGGishApplauseModel
Babble
SNVGGishBabbleModel
Cheering
SNVGGishCheeringModel
Laughter
SNVGGishLaughterModel
Music
SNVGGishMusicModel
Speech
SNVGGishSpeechModel
Distressed Baby
SNVGGishDistressedBabyModel
Smoke Alarm
SNVGGishSmokeAlarmModel
Fire Alarm
SNVGGishFireAlarmModel
Doorbell
SNVGGishDoorbellModel
Buzzer
SNVGGishBuzzerModel
Beep
SNVGGishBeepModel
Ding Bell
SNVGGishDingBellModel
Dog Bark
SNVGGishDogBarkModel
Cat Meow
SNVGGishCatMeowModel
Door Knock
SNVGGishDoorKnockModel
Shouting
SNVGGishShoutingModel
SNSoundPrintALaughterModel
SNSoundPrintAShoutingModel
SNSoundPrintASpeechModel
SNSoundPrintASmokeAlarmModel
SNVGGishEmbeddingModel
SNSoundPrint100kEmbeddingModel
SNSoundPrintAEmbeddingModel
com.apple.SoundAnalysis.classifier.v1
SNAudioQualityModel
com.apple.SoundAnalysis.System
Unknown request of type %@
enumeratedDurations
durationRange
q24@?0@"NSValue"8@"NSValue"16
SNTimeDurationConstraint.m
Unhandled enum case
processBuffer
SoundAnalysis_ProcessingTree.cpp
inputBuffer.mNumFrames == expectedNumberOfFrames
treeGraph
addProcessingContext
!findAnalyzerNodeForContext(processingContext)
setProcessingContexts
format().mBlockSize > 0
removeNodeRecursively
node
removeProcessingContext
requestProcessingNode
MultiRateGraphBox
SingleRateGraphBox
getCurrentInputSampleFromGraphBox
false
convertSampleTimeToRootSampleTime
Couldn't find GraphBox containing graph
buildTreeGraphRecursively
downstreamNode->upstreamNode()
formatsAreEquivalent(downstreamNode->upstreamFB(), downstreamNode->upstreamNode()->downstreamFB())
GraphBoxCommon
DSPGraph_GraphBox.h
inGraph
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_GraphBox.h
%s %s graph must have at least one input bus.
%s %s graph must have the same sample rate for all input busses to be used in a GraphBox
%s %s graph must have the same sample rate for all output busses to be used in a GraphBox
innerGraph %p
setParameter
DSPGraph parameters must have global scope and master element.
getParameter
process
isIntegral(numPacketsToWrite)
prepareGraphIOData
mGraphIODataIn.at(0).mNumFrames == inNumFrames
isIntegral(numPacketsOut)
outNumBytes <= mOutBufferList->GetCapacityBytes()
findGraphBoxContainingBox
Tick delta too large
sampleRate
blockSize
magnitudeThreshold
-[SNDetectSignalThresholdRequestImpl resultsFromBox:renderedWithFrameCount:]
SNDetectSignalThresholdRequest.mm
allBussesSignalRanges.size() == 1
allBussesSignalRanges.at(0).size() == 1
detectorEndPosition >= detectorStartPosition
signalDetector
com.apple.SoundAnalysis
azimuth
elevation
spatialSpectrum
%@ azmimuth: %f elevation: %f
_SNVGGishFeatureEmbeddingCustomModel
Couldn't load VGGish model
SNCorrelateAudioRequest.mm
CrossCorrelator
Failed to set properties and parameters on graph
(            
graphName "AudioCorrelator"                        
[def procSampleRate %d]            
[def blockSize %d]            
[def numChannels %d]            
[def numBuses %d]                        
in input                        
box CrossCorrelator (aufx xcor appl) [numBuses] [numBuses]            
box dead dead [numBuses] [numBuses]                        
wire input  CrossCorrelator ([procSampleRate] [numChannels] [blockSize])            
wire CrossCorrelator dead ([procSampleRate] [numChannels] [blockSize]))
Text
CopyDataFrom
CABufferList.h
mBufferCapacity == 0 || other.mBuffers[i].mDataByteSize <= mBufferCapacity
com.apple.soundanalysisd
com.apple.SoundAnalysis.AllAnalysisRequests
-[SNAnalysisServer init]
com.apple.SoundAnalysis.client
v8@?0
-[SNAnalysisClient init]
@"NSXPCConnection"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
logMelContext
melTransform
com.apple.SNFileSharing
FileSharingVersion
FileTransferRequest
FileTransferComplete
FileTransferDeleteFile
targetPublicKey
targetID
basePath
filePaths
@32@?0@8@16^@24
@24@?0@8^@16
multiple keys mapping to the same value: %@
B32@?0@8@16^@24
B24@?0@8@16
@"NSArray"16@?0@8
B16@?0@8
@"NSNumber"24@?0@"NSNumber"8@16
@"<NSFastEnumeration>"24@?0@8^@16
@"NSDictionary"24@?0@8^@16
@"NSDictionary"16@?0@"<NSCopying>"8
bad collection; contains `nil`
@8@?0
@24@?0@8@16
q24@?0@"NSNumber"8@"NSNumber"16
partition size may not be 0
failed to divide into partitions of size %@; remainder %@
@"NSArray"32@?0@"<NSFastEnumeration>"8@"NSNumber"16^@24
@16@?0@"NSArray"8
currentFrameValue
meanValue
standardDeviation
%@ mean distance (meters): %f
enable_verbose_logging
sysdiagnose_historical_duration
daemon_recording_path
delete_recordings_without_detection
first_pass_recording_predicate
first_pass_recording_history_duration
enable_second_pass_recording_in_daemon
enable_file_server
file_server_root_directory
built_in_microphone_analysis_channel_number
microphone_array_channel_map
@"NSNumber"24@?0@8^@16
bad type within defaults array
Library
Caches
AudioCaptures
default
audio
results
-[SNUltronReportOperator init]
unrecognized input port ID: %@
v32@?0@"NSString"8@16@"NSError"24
v32@?0@"NSDictionary"8@"NSDictionary"16@"NSError"24
Confidence
Detected
%@ Detector
SNDetectorHead.mm
Couldn't find output feature
Detectors must use multi-array feature type
Only double and float32 multiArray feature types are currently supported
Detectors should only have one output dimension
Detector output should only have one value
v32@?0@"NSString"8@"<SNResult>"16@"NSError"24
-[SNResourceCoordinatorXPCSubscriber init]
identifier
detected
%@: %@ detected with confidence %f at %@
SNMLModelCacheKey.m
modelClass != nil
modelConfiguration != nil
Unsupported dimension count
%@ detected: %@
Expected multi array to have standard strides
Expected count to be non-negative
Expected new dimension count to be at least as large as original
IncludePaths
Substitutions
Value
-[SNResultsXPCSubscriber init]
failed to initialize instance of class %@
-[SNRecordOperator init]
failed to record audio to file
com.apple.SoundAnalysis.remoteanalyzer
all_data
label
dataset
embedding
inference_window_size
exemplar
negative
positive
training
validation
foreground
background
shiftIteration
stateIn
shiftedSamples
segmentLength
stateOut
iterationsPerTimeshift
timeshiftsPerSegment
-[SNKShotLabel init]
illegal call to unavailable new selector: %s
+[SNKShotLabel new]
I12@?0I8
Failed to clip segment to file.
Failed resize segment.
Failed to allocate resources.
Failed to initialize analyzer.
Failed to register request.
Failed to perform request.
Failed to generate feature prints.
No feature prints generated.
v16@?0@"SNKShotFeaturizationStreamResult"8
v24@?0@"SNKShotFeaturizationStreamCompletion"8@"NSError"16
Error loading audio files.
Error creating SN analyzer.
Error adding SN LogMel request.
error making slice.
allocation error.
error getting bottom indices.
error allocating.
error getting top indices.
error in logistic regression
error allocating
error smoothing
error rounding
error getting segments
@"NSError"8@?0
Failed to fit segment to file.
Error computing SoundPrint.
q24@?0@8@16
Error ensuring segment length.
Error collecting LogMel.
error getting slice
error getting similarity
Not enough audio segments found to continue.
v32@?0@"NSNumber"8@"MLMultiArray"16q24
v24@?0@"NSNumber"8@"MLMultiArray"16
B8@?0
MLModelCreatorDefinedKey
could not read key from hallucinator metadata: %@
invalid specification for input feature: '%@'
invalid specification for output feature: '%@'
Expected multiarray embedding output.
Expected multiarray label output.
Expected multiarray state output.
v152@?0{?={?=qiIq}{?=qiIq}}8{?={?=qiIq}{?=qiIq}}56{?={?=qiIq}{?=qiIq}}104
B72@?0@"AVAudioFile"8{?={?=qiIq}{?=qiIq}}16^@64
B120@?0@"SNKShotSegment"8{?={?=qiIq}{?=qiIq}}16{?={?=qiIq}{?=qiIq}}64^@112
B24@?0@?<B@?^vQ^@>8^@16
@"MLMultiArray"8@?0
B40@?0@"MLMultiArray"8@"NSNumber"16@"MLMultiArray"24^@32
B48@?0@"SNKShotSegment"8@"NSNumber"16@"NSNumber"24@"NSNumber"32^@40
B32@?0@"MLMultiArray"8@"NSNumber"16^@24
could not translate number to label: %@
expected same number of embeddings and labels
@"SNKShotFeaturizationStreamResult"32@?0@"MLMultiArray"8@"NSNumber"16^@24
unrecognized label type: %@
unrecognized dataset type: %@
@"NSDictionary"24@?0@"SNKShotFeaturizationStreamResult"8^@16
-[SNKeyValueMutation init]
unrecognized mutation type
key to be added already exists (%@)
v24@?0@8@16
required key missing from dictionary: %@
Server connection lost
-[SNSystemAudioAnalyzerRemote init]
@"<SNSystemAudioAnalyzerProtocol>"24@?0@?<v@?>8@"NSObject<OS_dispatch_queue>"16
v24@?0@"<SNRequest>"8@"NSError"16
SNSystemAudioAnalyzerRemote.m
request
observer
analyzerProcessingGraph should be non-null
ProcessingContext
SoundAnalysis_ProcessingContext.cpp
requestProcessingGraph->configured()
sharedProcessingGraph->configured()
-[SNResultsForwarder init]
v24@?0@"<SNRequest>"8@"<SNResult>"16
config-model-epoch-mvn-60.json
floatToFixedConverter
speechEmotionAnalyzer
%f, %d
classifier
Invalid model, userSuppliedInputFeatureNames.count = %lu
Invalid model, input feature must be a multi-array
Invalid model, input feature must be one dimensional (for mono audio), or two dimensional (for multichannel audio).
Invalid model, block size must be 2 or greater
Invalid model, classification models must have 'predictedProbabilitesName' and 'predictedFeaturesKey' properties
-init is not a valid initializer for the class SNClassifySoundRequest
+new is not a valid class method for the class SNClassifySoundRequest
unrecognized classifier type
Invalid classifier identifier provided: %@
Classifier
createGraphWithModel
SNClassifySoundRequest.mm
Couldn't open audio file %@
com.apple.SoundAnalysis.FileAnalyzer
-[SNAudioFileAnalyzer advanceSamples:withHandler:]
SNAudioFileAnalyzer.mm
self->_audioFile.length > self->_audioFile.framePosition
Couldn't read audio into buffer
v16@?0@"AVAudioPCMBuffer"8
requestType
AUNeuralNetVAD.dspg
AUNeuralNetVAD_SiriEndpointer.propstrip
AUNeuralNetVAD_Siri.austrip
NNVAD
-[SNAnalyzerHost adaptToSystemConfiguration:error:]
SNAnalyzerHost.mm
resultsBox
+[SNAnalyzerHost convertTimeRange:fromBox:usingConverter:]
clientSampleTimeEnd >= clientSampleTimeStart
SoundPrintEmbedding
embeddingExtractor
createGraph
SNSoundPrintFeatureExtractor.mm
configuration.stepSizeFrames > 0 && configuration.stepSizeFrames <= configuration.windowLengthFrames
soundIdentifier
detectorVariant
modelConfiguration
resultsPredicate
resultsPredicateLeakCount
Couldn't find soundIdentifier for detectorIdentifier %@
<Unknown Sound>
%@ identifier: %@
Do not call %@
-[SNDSPGraphBox init]
graph
Audio format must be PCM
Audio format channel count and sample rate must be nonzero
InvalidFormatException
com.apple.soundanalysis
companion service connection interrupted
v16@?0@"RPCompanionLinkDevice"8
version
v20@?0@"RPCompanionLinkDevice"8I16
@"NSObject<SNTimeRangeProvidingWritable>"16@?0@"NSObject<SNTimeRangeProvidingWritable>"8
%@_%@
@"NSString"16@?0@"SNDetectionResult"8
@"NSNumber"16@?0@"SNDetectionResult"8
timestamp
@"NSDictionary"16@?0@"NSArray"8
buildVersion
listenType
fileName
audioStringDate
confidenceValues
userFeedback
numberOfSamples
could not query build version and recording path
SNSoundDetectionUtils.mm
minimumStepSize <= windowLengthFrames
no supported feature extractor for detector variant
@"<SNFeatureExtractorConfiguration>"24@?0@"MLModel"8@"SNDetectorHeadModelMetadata"16
cannot create feature extractor config for identifier: %@
[identifier isEqual:detectorHeadModelMetadata.featureExtractorIdentifier]
expected feature extractor in detector head model metadata
expected feature optionality to equal %@
expected shape constraint to have ranged type
expected shape constraint to require %@ dimensions
expected shape constraint dimension %@ to match range: %@
expected shape constraint to enumerated type
expected shape constraint to have shape options %@
expected shape constraint to have unspecified type
expected constraint to have data type %@
expected feature to have multi array type
expected input features to match %@
expected output features to match %@
com.apple.SoundAnalysis.CanHostDaemon
v32@?0@"NSString"8@16@"NSError"24
illegal call to unavailable method: %s
-[SNMemoizedMLModel init]
-[SNMemoizedMLModel initWithModelDescription:parameterDictionary:error:]
+[SNMemoizedMLModel new]
@"MLModel"8@?0
#24@?0@"NSString"8^@16
could not derive tagged model classes from tags
unsupported feature extractor: %@
@"SNSplitDetectorInfo"32@?0#8#16@"NSString"24
featureVector
cannot copy MLMultiArray
cannot hash MLMultiArray
cannot encode MLMultiArray
operator()
SNFeaturePrint.mm
SNForwardPassAudioStreamAnalyzer.mm
DSPGraph ABI runtime/compile-time mismatch
v16@?0@"<SNResult>"8
Error creating analyzer
Error configuring analyzer
Error updating tree format
Error configuring analysis tree
Audio format changed mid-stream from %@ to %@. Please configure a new analyzer if the stream format changes.
Error during analysis
Failed to prime analysis
levelMeasurer
dead
v24@?0@"CUFileResponse"8@"NSError"16
SNUtils.mm
Expected only one user-supplied input feature; got: %@
MultiArrayInput
MultiArrayOutput
soundanalysisd
InternalBuild
SELF endswith[c] '.wav'
q24@?0@"NSString"8@"NSString"16
unable to read entitlement
failed to acquire task
Could not create MLMultiarray.
Cannot access data: nil MLMultiarray.
@"AVAudioPCMBuffer"8@?0
B24@?0@"AVAudioPCMBuffer"8^@16
v20@?0I8@"NSError"12
Couldn't read negative duration
prefix did not populate all requested frames
did not process all frames
suffix did not populate all requested frames
B32@?0^v8Q16^@24
B16@?0@"AVAudioPCMBuffer"8
unsupported audio file format; need float32
bad num dimensions; need >0
v24@?0@"MLModel"8@"NSError"16
timeout expired while attempting to load model
errors
completeCount
copyRecentFramesOfAudioRingBufferToAVAudioBuffer
sourceBufferStartTime <= sourceBufferEndTime
copyRecentFrames
unownedViewOfRecentFrames
numberOfRecentFrames <= sourceBuffer.frameLength
VerifyNotTrashingOwnedBuffer
CABufferList.h
mBufferMemory == NULL
-[SNResourceCoordinatorXPCPublisher init]
v16@?0@"<SNSystemAudioAnalyzerXPCProtocol>"8
-[SNDSPGraph init]
SNDSPGraph.mm
@"NSString"8@?0
addDownstreamNodes
SoundAnalysis_ProcessingNode.cpp
!elementFoundInList(node, mDownstreamNodes)
CA::StreamDescription::IsEquivalent(node->upstreamFB().mFormat, downstreamFB().mFormat)
removeDownstreamNodes
elementFoundInList(node, mDownstreamNodes)
processingBox
mProcessingBox
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_CoreMLBox.mm
only supports 1 bus in 1 bus out
input format must be deinterleaved
output must be single channel
input and output sample rates must match
MLModel input doesn't match CoreMLBox upstream block size
DSPGraph_CoreMLBox.mm
inABL
outABL
inABL->mBuffers[0].mDataByteSize == mInputNumBytes
input data must be Float32
Error: Model input size (
 bytes) doesn't match audio input size (
 bytes)
prediction failed
MLModel output must have only one feature (MLMultiArray)
MLModel output must be an MLMultiArray
Error: Model output size (
unsupported CoreML data type
CoreMLBox
offset
%@ offset: %f
v32@?0@"NSDictionary"8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSDictionary"@"NSError">24
v24@?0@"NSArray"8@"NSError"16
-[SNCopyFilesRequest launchTaskWithQueue:completionHandler:resultsHandler:]_block_invoke
SNCopyFilesRequest.m
error == nil
v24@?0@"RPFileTransferItem"8@?<v@?@"NSError">16
expected object %@ of class %@ to be kind of %@
@24@?0@8@?<@@?@>16
@"NSValue"16@?0@"<SNTimeRangeProviding>"8
@32@?0@8@"NSArray"16^@24
B16@?0@"<SNTimeRangeProviding>"8
@"NSArray"16@?0@"NSArray"8
error getting ring buffer bounds: %@
ring buffer sample rate is not integral: %@
-[SNAudioRecordingQueueScheduler init]
com.apple.SoundAnalysis.AnalysisInProgress
v56@?0{?={?=qiIq}{?=qiIq}}8
{?=qiIq}56@?0{?=qiIq}8{?=qiIq}32
-[SNAudioRecordingQueue init]
Unexpected MultiArray size %ld
Unexpected error processing model
Must only have one input audio feature
Model needs an input constraint
Must allow %@ shaped vector as input
Must only have one output multiarray feature
Model needs an output constraint
Must allow %@ shaped vector as output
_SNVGGishFrontEndProcessingCustomModel
adjustSingleChannelIODataAhead
SNVGGishFrontEndProcessingCustomModel.mm
data.mBufferList->mBuffers[0].mDataByteSize >= framesToAdjust * sizeof(float)
v24@?0^v8^{GraphIOData=II{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}^{AudioBufferList}}16
scratchFloatSpace.size() >= multiArray.count
expected file url; got %@
cannot write without overwriting at path %@
com.apple.SoundAnalysis.AnalyzerQueue
Results History (%p)
@16@?0^@8
v8@?0
-[SNLogMelBasedFeatureExtractor resultsFromBox:renderedWithFrameCount:]
SNLogMelBasedFeatureExtractor.mm
-[SNLogMelBasedFeatureExtractor resultsBox]
melContext
classifierContext
failed to reanchor
Name
MinDurationBlocks
ConfidenceThreshold
Failed to parse trigger dictionary, required keys not found
AudioHopSizeSamples
AudioSampleRate
BlocksBetweenTriggers
Commands
Failed to parse dictionary, trigger not found in given model
Failed to parse dictionary
DSPGraph_ContextBox.cpp
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_ContextBox.cpp
validateFormats
Context box can't produce variable output frames.
input and output channel counts don't match
ContextBox has no inputs
mMaxFrames > 1
number of context frames must be greater than block size
isIntegral(mOutputHopSize)
inNumFrames <= mMaxFrames
inNumFrames == mMaxFrames
selfLatencyInTicks
setHistoricalBuffer
historical buffer size must match ring buffer readAvail
-[SNOptional init]
RPFTSource
v16@?0@"RPFileTransferProgress"8
could not allocate enough memory for serialized state
^{os_state_data_s=I(?=b32I){os_state_data_decoder_s=[64c][64c]}[64c][0C]}16@?0^{os_state_hints_s=I*II}8
computationalDutyCycle
graphIsDeadEnded
shouldThrowException
Throwing a fake exception to aid in unit testing
bad expression type %@ (expected %@)
B24@?0@8^@16
expected number value
keypath %@ is not one of options
B24@?0@"NSString"8^@16
bad predicate type; requires NSComparisonPredicate
bad predicate operator type; got %@, expected one of %@
B24@?0Q8^@16
B24@?0@"NSExpression"8^@16
classifierIdentifier
-[SNClassifierVariant init]
cannot encode MLModel
com.apple.soundanalysis.SystemAudioAnalyzer
com.apple.soundanalysis.SystemAudioAnalyzer.analysis
-[SNSystemAudioAnalyzerLocal setAudioConfiguration:]
SNSystemAudioAnalyzerLocal.m
[_requests count] == 0
Failed to start system audio.
v24@?0@"AVAudioBuffer"8@"AVAudioTime"16
Audio stream interrupted
n_mels
fmin
fmax
mel_type
norm
hop_length
win_length
win_offset
n_fft
fft_offset
slaney
none
expected one of choices: %@
expected string
expected number
@?<B@?@^@>16@?0@?<v@?I>8
@?<B@?@^@>16@?0@?<v@?f>8
@?<B@?@^@>16@?0@?<v@?i>8
@?<B@?@^@>24@?0@"NSArray"8@?<v@?@"NSString">16
v12@?0I8
v12@?0f8
v16@?0@"NSString"8
v12@?0i8
invalid parameter for key %@
B24@?0@"NSArray"8^@16
expected exactly one feature
B24@?0@"MLFeatureDescription"8^@16
expected all features to be MLMultiArray instances
expected all features to be required
expected constraint: <BATCH>x<NCHAN>x<NSAMPLES> NCHAN is in range [1, 1]
expected constraint: <BATCH>x<NCHAN>x<NMELS>x<NFRAMES> where BATCH is in range [1, IntMax + 1], NCHAN is in range [1, 1], NMELS is given by `n_mels` model parameter
@"NSString"24@?0@"NSArray"8^@16
model input validation failed
model output validation failed
v24@?0@"NSString"8@"NSString"16
v16@?0^v8
B16@?0@8
not all items are serializable to plists
@24@?0@"<SNPlistSerializable>"8^@16
string could not be parsed as int: '%@'
no class exists with name: '%@'
B16@?0@"NSString"8
@"SNDSPGraph"8@?0
LEC5
audio_offset_estimator.dspg
audio_offset_estimator.austrip
classificationDictionary
-init is not a valid initializer for the class SNClassificationResult
+new is not a valid class method for the class SNClassificationResult
v32@?0@"NSString"8@"NSNumber"16^B24
%@ %@
-init is not a valid initializer for the class SNClassification
+new is not a valid class method for the class SNClassification
%@ = %f
%@/distance_classifier.mlmodelc
category
mode
options
channelMap
useSiriAudioRouting
%@, %@, AVAudioSessionOptions: %lu, useSiriAudioRouting: %d, channelMap: %@
B24@?0@"NSString"8@"NSString"16
feature provider does not provide expected feature names
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
framewiseEmbedding
fixedLengthEmbedding
-[_SNSoundPrintFeatureEmbeddingCustomModel initWithModel:modelDescription:]
SNSoundPrintCustomModel.mm
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
Only single-channel audio is supported.
Bad number of dimensions on audio input shape.
Expected output batch size %d.
Couldn't load SoundPrintA model
/System/Library/Frameworks/AudioToolbox.framework/libAudioDSP.dylib
RegisterAudioUnits_InternalUnsearchable
floatFormatWithContext
SNDSPGraphUtils.mm
sampleRate > 0 && blockSize > 0 && contextSize > 0 && channelCount > 0
floatFormat
sampleRate > 0 && blockSize > 0
denylist
windowSize
hopSize
feedback_connections
inputFeature
-[SNModelFeatureConnection init]
@"NSDictionary"24@?0@"NSDictionary"8^@16
couldn't parse feedback connection; expected format 'source -> destination'; got: '%@'
@"SNModelFeatureConnection"24@?0@"NSString"8^@16
@"NSString"16@?0@"SNModelFeatureConnection"8
expected destination features to be unique; got %@
expected all source features to have affiliated outputs: source features = (%@); outputs = (%@)
expected all destination features to have affiliated inputs: destination features = (%@); inputs = (%@)
@"NSSet"24@?0@"NSString"8^@16
@"NSNumber"24@?0@"NSString"8^@16
@"NSString"24@?0@"NSString"8^@16
@"NSDictionary"24@?0@?<@"NSDictionary"@?@^@>8^@16
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_SignalDetectorBox.cpp
inputs must be LPCM
DSPGraph_SignalDetectorBox.cpp
mInputSignalRanges.at(busIdx).at(channelIdx).capacity() >= inNumFrames
SignalDetectorBox
-[SNPredicateFilterOperator init]
-[SNResultsXPCPublisher init]
failed to initialize instance of class %s
-[SNResultsXPCPublisher initWithSubscriber:]
/Library/Caches/com.apple.xbs/Sources/Listen_Sim/Framework/Internal/Core/DSPGraph/DSPGraph_LogMelTransformBox.cpp
input must be single channel
DSPGraph_LogMelTransformBox.cpp
LogMelTransformBox
start time follows target time
@"NSValue"16@?0@"NSValue"8
time (%@) not in expected range (%@)
-[SNSystemAudioAnalyzerXPCSubscriber init]
expected non-nil request
expected non-nil observer
expected NSXPC to pass a proxy object for argument `observer`
could not add request; unknown error
yyyyMMdd'T'HHmmss'Z'
en_US_POSIX
yyyy-MM-dd'T'HH:mm:ss'Z'
input1
detectedHistoryIn
input_1
detectedHistoryOut
mlmodelc
output1
audioSamples
soundprint/Placeholder
Sigmoid
SNSoundPrint100kFireAlarmModel
classLabel
SNSoundClassifierVersion1Model
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintKEmbeddingModel
final_output
(SNSystemAudioAnalyzerXPCPublisher:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCPublisher:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCPublisher:%@) start
(SNSystemAudioAnalyzerXPCPublisher:%@) stop
(SNSystemAudioAnalyzerXPCPublisher:%@) setAudioConfiguration
Couldn't obtain the built-in mic UID. Skipping setting of the AQ channel assignments
Set audio queue channel map (zero-indexed) %@ with result %d
Unsupported product type
Could register audio units. Returning nil for %@
Client rejected due to insufficient entitlements.
Removing %@, since it doesn't contain any detections
Detector model must contain one user supplied feature. Model contains %@
Detector model must contain one user supplied output feature, or two output features named %@ and %@. Model contains %@
IncludePaths parse failed
Substitutions parse failed
SNDSPConfiguration parse failed
Applying AUStrip %@ to graph %@ failed
Error applying AUStrip. DSPGraph must be the first item in a DSPConfiguration.
Applying PropertyStrip %@ to graph %@ failed
Error applying PropertyStrip. DSPGraph must be the first item in a DSPConfiguration.
DSPGraphInfo doesn't specify either text or path
AUStripInfo doesn't specify either value or path
PropertyStripInfo doesn't specify either value or path
SNSoundPrintFeatureExtractor models must have one input feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray input feature
SNSoundPrintFeatureExtractor models must have one output feature
SNSoundPrintFeatureExtractor model must have an MLMultiArray output feature
Instantiating SNSystemAudioAnalyzer in Daemon
(SNSystemAudioAnalyzer:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) addRequestInBackground:%@ withObserver:%@
(SNSystemAudioAnalyzer:%@) removeRequest:%@
(SNSystemAudioAnalyzer:%@) removeAllRequests
(SNSystemAudioAnalyzer:%@) start
(SNSystemAudioAnalyzer:%@) stop
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidated: %@
(SNSystemAudioAnalyzerRemote: %@) remote analyzer invalidation attempted; stalling further activity
(SNSystemAudioAnalyzerRemote: %@) finished stalling after analyzer invalidation attempt
(SNSystemAudioAnalyzerRemote:%@) _setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) setAudioConfiguration
(SNSystemAudioAnalyzerRemote:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerRemote:%@) removeRequest:%@
(SNSystemAudioAnalyzerRemote:%@) removeAllRequests
(SNSystemAudioAnalyzerRemote:%@) start
(SNSystemAudioAnalyzerRemote:%@) stop
EAR framework returned %lu bytes instead of %d float elements
Couldn't find detector for soundIdentifier %@
SNDetectSoundRequest decoded (and rejected) a forbidden predicate
Failed to create detector head configuration for sound identifier named '%@'
Unknown exception caught!
Caught OSStatus exception %d %4.4s
std::exception caught: %s.
Caught graph exception %d %4.4s %s in %s:%i
Companion service connection invalidated
Could not contact remote SNFileServer to query version (this may not be an issue; not all devices are expected to host SNFileServers); reason: %@
Device found %@
Version check messaged failed with error %@
Version %@
device updated: %@ with changes: %ld
Link failed to activate with error %@
error querying entitlement %@: %@
inadequate entitlements to host daemon
Activated file server with error %@
SNLogMelBasedFeatureExtractor models must have one input feature
SNLogMelBasedFeatureExtractor model has input feature size %@, expected %@
SNLogMelBasedFeatureExtractor models must have one output feature
SNLogMelBasedFeatureExtractor model has output feature size %@, expected a 1-d multi array
Created model of class %@ with error %@
for handler %p: result (%@) produced by request %@
for handler %p: termination (%@) received from request %@
Required shared request not found with configuration %@
request failed to adapt to system configuration %@ with error %@
failed to set processing contexts
Caught error: %s
Unknown error
Unknown error while priming
Priming error: %s
Error analyzing audio buffer
Failed to get files list. Giving up on directory size reduction. Error: %@
Sorting files by date failed; continuing but may have unpredictable results.
No SoundAnalysis file removal needed. Directory size approx: %lld kb.
Deleting these sound files + their associated metadata files: %@
Failed to delete audio file %@. Error: %@
Failed to delete text file %@. Error: %@
Failed to open audio file %@ with error %@
%@ didProduce %@
%@ didFailWith %@
%@ didComplete
AUStrip is nil
PropertyStrip is nil
Model must have MLMultiArray features
CoreMLBox configured to receive %@ elements. CoreMLModel input expects %@ total elements
Error allocating MLMultiArray
Unable to compile model at %@ with error %@
MLModel successfully loaded!
No CoreML model set: %@
MLModel must have at least one feature in and one feature out
MLModel must have only one user defined input. Has %@
MLModel supports block sizes in range %@. CoreMLBox block size is %d.
MLModel input requires %d total elements. CoreMLBox wire block size is %d, with %d channels
Error creating input provider
No CoreML model prepared. Bypassing.
No MLModel, bypassing this process call
CoreML prediction failed with %@
Audio is already running. Model will be loaded next time audio is restarted
Set CoreMLModel URL at path %@
Error creating URL from path: %@
Transfer completed
Fetched local device identity
Fetched server device identity %@
File sharing messaged failed with error %@
Received a file sharing request response %@
Received a file item %@
Audio Running Heartbeat (%@); time changed from %@ to %@
Audio Heartbeat Reanchor (%@); time changed from %@ to %@
Not enough funds to schedule audio buffer for processing!Queue Funds Spent: %@. Queue Funds Earned: %@.Buffer Length: %@.
Queue already running
Failed to create audio queue
Starting audio queue
Error starting audio queue, %@
Stopping audio queue
Completed first pass for request %@ with error %@
Beginning second pass for request %@
Completed second pass for request %@ with error %@
Beginning %f seconds of historical data catch-up for request %@
Ended historical data catch-up for request %@
Ending second pass for request %@
Received version request
Received file transfer request
Progressing %@
Finished transferring files with error %@
Message transmitted!: %@
Skipping transferring of file %@
Requested file path %@
Received file deletion request on server for file path: %@
File deletion request failed on the server: %@
Collecting state information (title: %@)
Error capturing state! %@
Error preparing captured state! %@
(SNSystemAudioAnalyzerLocal:%@) setAudioConfiguration:%@
(SNSystemAudioAnalyzerLocal:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerLocal:%@) removeRequest:%@
(SNSystemAudioAnalyzerLocal:%@) removeAllRequests
(SNSystemAudioAnalyzerLocal:%@) start
(SNSystemAudioAnalyzerLocal:%@) stop
Failed to set AVAudioSession with error %@
Failed to activate AVAudioSession with error %@
Starting audio input. %@, %@
Failed to deactivate AVAudioSession with error %@
SNAudioRecordingQueue interrupted
AVAudioSession interrupted %@
AVAudioSession route change %@
AVAudioSession media services lost %@
AVAudioSession media services reset %@
Graph %@ couldn't be compiled
Graph couldn't be compiled from text
No distance classifier model available on this product
Input feature count doesn't match
Input feature description has > 1 input feature
Input feature isn't an MLMultiArray
Input feature must contain floating point data
Output feature count doesn't match
Output feature description has > 1 feature
Output feature must contain floating point data
Error: Unable to call RegisterAudioUnits_InternalUnsearchable from libAudioDSP.dylib.
Processor not found with configuration %@
(SNSystemAudioAnalyzerXPCSubscriber:%@) addRequest:%@ withObserver:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeRequest:%@
(SNSystemAudioAnalyzerXPCSubscriber:%@) removeAllRequests
(SNSystemAudioAnalyzerXPCSubscriber:%@) start
(SNSystemAudioAnalyzerXPCSubscriber:%@) stop
(SNSystemAudioAnalyzerXPCSubscriber:%@) setAudioConfiguration
attempt to remove nil request
Could not load SNVGGishDistressedBabyModel.mlmodelc in the bundle resource
Could not load SNVGGishLaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishApplauseModel.mlmodelc in the bundle resource
Could not load SNVGGishFireAlarmModel.mlmodelc in the bundle resource
Could not load SNVGGishEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAEmbeddingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kFireAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundClassifierVersion1Model.mlmodelc in the bundle resource
Could not load SNVGGishBabbleModel.mlmodelc in the bundle resource
Could not load SNSoundPrintAShoutingModel.mlmodelc in the bundle resource
Could not load SNSoundPrint100kSmokeAlarmModel.mlmodelc in the bundle resource
Could not load SNSoundPrintASpeechModel.mlmodelc in the bundle resource
Could not load SNVGGishSpeechModel.mlmodelc in the bundle resource
Could not load SNSoundPrintALaughterModel.mlmodelc in the bundle resource
Could not load SNSoundPrintKEmbeddingModel.mlmodelc in the bundle resource
Could not load SNVGGishMusicModel.mlmodelc in the bundle resource
Could not load SNVGGishCheeringModel.mlmodelc in the bundle resource
Could not load SNAudioQualityModel.mlmodelc in the bundle resource
SNSystemUtils
SNLKFSResult
NSCopying
NSSecureCoding
NSCoding
SNTimeRangeProvidingWritable
SNTimeRangeProviding
NSObject
SNComposedDetector
SNDetectorVariant
SNSpeechEmotionResult
SRSampling
SNConfidenceProvidingWritable
SNConfidenceProviding
SNResult
SNEstimateDirectionOfArrivalRequest
SNAnalyzerCreating
SNRequest
SNDirectionOfArrivalEstimator
SNAnalyzing
SNProcessing
SNCreateFeaturePrintRequest
SNFeaturePrintExtractorProtocol
SNFeaturePrintExtractor
SNVGGishExtractor
SNLogMelSpectrogramExtractor
SNSoundPrintExtractorBase
SNSoundPrintAExtractor
SNSoundPrintKExtractor
SNEstimateSpeechDistanceRequest
SNDistanceEstimator
SNFileServerDiscoveryResult
SNNumberUtils
SNAtomicUtils
SNResultsObservingXPCProtocol
SNSystemAudioAnalyzerXPCPublisher
SNSystemAudioAnalyzerProtocol
SNAudioQueueConfiguration
SNAudioDataSourceUtilities
SNPlatformUtils
SNFileDeletionResult
AllValidSoundIdentifiers
SNSplitDetectorInfo
SNTaskCreating
SNFileSystem
SNTimeDurationConstraint
SNDetectSignalThresholdRequest
SNDetectSignalThresholdRequestImpl
SNError
SNDirectionOfArrivalResult
_SNVGGishFeatureEmbeddingCustomModel
MLCustomModel
SNCorrelateAudioRequest
SNAudioCorrelator
SNSystemServiceResourceCoordinator
SNResourceCoordinatorProtocol
SNAnalysisServer
NSXPCListenerDelegate
SNAnalysisClient
SNCollectionUtils
SNSpeechDistanceResult
SNUserDefaults
SNUltronReportOperator
SNOperator
SNDeleteFilesRequest
SNMLCustomModel
SNMLModel
SNMLLockedModel
SNDetectorHead
SNResourceCoordinatorXPCSubscriber
SNResourceCoordinatorXPCProtocol
SNDetectionResult
SNPlistSerializable
SNMLModelCacheKey
SNAudioMultiArrayUtils
SNCustomTwoPassRequest
SNTwoPassRequest
SNSpeechUtteranceResult
SNMultiArrayUtils
SNDSPItemInfo
SNDSPGraphInfo
SNAUStripInfo
SNPropertyStripInfo
SNDSPConfiguration
SNDSPGraphLoader
SNSoundPrintFeatureExtractorConfiguration
SNFeatureExtractorConfiguration
SNProcessorCreating
SNResultsXPCSubscriber
SNResultsObserving
SNRecordOperator
SNSystemAudioAnalyzer
SNKShotSegmentationRequest
SNKShotLabel
SNKShotFeaturizationStreamResult
SNKShotFeaturizationStreamCompletion
SNKShotFeaturizationResult
SNKShotSegmentationResult
SNKShotDataset
SNKShotSegment
SNKShotFeaturizer
SNFileListingResult
SNKeyValueMutation
SNKeyValueUtils
SNSystemAudioAnalyzerRemote
SNResultsForwarder
SNObserverUtils
SNFileServerInfo
SNEstimateSpeechEmotionRequest
SNSpeechEmotionEstimator
EARSyncPSRAudioProcessorDelegate
SNSystemConfiguration
SNFilterVoiceTriggerResults
SNSoundClassifier
SNClassifySoundRequest
SNAudioFileAnalyzer
SNDetectSpeechUtteranceRequest
SNSpeechUtteranceDetector
SNTimeConversionDictionaryProviding
SNAnalyzerHost
SNSoundPrintFeatureExtractor
SNDetectSoundRequest
SNSoundDetector
SNDSPGraphBox
SNAudioFormatUtils
SNDiscoverFileServerRequest
SNUltronUtils
SNSoundDetectionUtils
SNValidateModel
SNDaemon
SNOperatorUtils
SNLogMelBasedFeatureExtractorConfiguration
SNMemoizedMLModel
SNLockedMLModelFactory
SNMLModelFactory
SNFeaturePrint
SNAnalyzerInfo
SNForwardPassAudioStreamAnalyzer
SNTimeConverting
SNMeasureLKFSRequest
SNAudioLevelMeasurer
SNListFilesRequest
SNUtils
SNResultsCollector
SNResultsPrinter
SNBooleanCancellable
SNCancellable
SNResourceCoordinatorXPCPublisher
SNDSPGraph
SNVoiceTriggerResult
DSPGMLInputProvider
MLFeatureProvider
DSPGCoreMLInfo
SNFileCopyingResult
SNVoiceTriggerCommandDataPoint
SNVoiceTriggerCommandFilter
SNProcessVoiceTriggerModelOutput
SNAudioOffsetResult
SNCopyFilesRequest
SNObjectUtils
SNTwoPassConfiguration
SNHistoryUtils
SNAudioRecordingQueueScheduler
SNAudioRecordingQueue
SNDSPGraphCustomModel
_SNVGGishFrontEndProcessingCustomModel
SNFileUtils
SNAudioStreamAnalyzer
SNLogMelBasedFeatureExtractor
SNScheduleUtils
SNVoiceTriggerCommand
SNDetectVoiceTriggerRequest
SNVoiceTriggerDetector
SNOptional
SNOptionalUtils
SNFileServer
SNBoxRecordingInfo
SNDSPGraphUtilities
SNSystemAudioAnalyzerXPCProtocol
SNNullRequest
SNNullDetector
SNPredicateUtils
SNClassifierVariant
SNSystemAudioAnalyzerLocal
SNLogMelSpectrogramCustomModelUtils
_SNLogMelSpectrogramCustomModel
SNPlistUtils
SNStringUtils
SNDSPGraphInterpreter
SNEstimateAudioOffsetRequest
SNAudioOffsetEstimator
SNClassificationResult
SNClassification
SNDistanceClassifier
SNSignalThresholdResult
SNAudioConfiguration
SNWrapModel
_SNSoundPrintFeatureEmbeddingCustomModel
_SNSoundPrintAFeatureEmbeddingCustomModel
_SNSoundPrintKFeatureEmbeddingCustomModel
SNAudioUnitRegistration
SNThresholdBasedSecondPassController
SNSecondPassController
SNDetectorHeadConfiguration
SNAudioProcessorCache
SNNullResult
SNAudioCorrelationResult
SNDetectorHeadModelMetadata
SNModelFeatureConnection
SNModelMetadataUtils
SNPredicateFilterOperator
SNResultsXPCPublisher
SNTimeUtils
NSXPCProxyCreating
SNSystemAudioAnalyzerXPCSubscriber
SNDateUtils
SNVGGishDistressedBabyModelInput
SNVGGishDistressedBabyModelOutput
SNVGGishDistressedBabyModel
SNVGGishLaughterModelInput
SNVGGishLaughterModelOutput
SNVGGishLaughterModel
SNSoundPrint100kEmbeddingModelInput
SNSoundPrint100kEmbeddingModelOutput
SNSoundPrint100kEmbeddingModel
SNVGGishApplauseModelInput
SNVGGishApplauseModelOutput
SNVGGishApplauseModel
SNVGGishFireAlarmModelInput
SNVGGishFireAlarmModelOutput
SNVGGishFireAlarmModel
SNVGGishEmbeddingModelInput
SNVGGishEmbeddingModelOutput
SNVGGishEmbeddingModel
SNSoundPrintAEmbeddingModelInput
SNSoundPrintAEmbeddingModelOutput
SNSoundPrintAEmbeddingModel
SNSoundPrint100kFireAlarmModelInput
SNSoundPrint100kFireAlarmModelOutput
SNSoundPrint100kFireAlarmModel
SNSoundPrintASmokeAlarmModelInput
SNSoundPrintASmokeAlarmModelOutput
SNSoundPrintASmokeAlarmModel
SNSoundClassifierVersion1ModelInput
SNSoundClassifierVersion1ModelOutput
SNSoundClassifierVersion1Model
SNVGGishBabbleModelInput
SNVGGishBabbleModelOutput
SNVGGishBabbleModel
SNSoundPrintAShoutingModelInput
SNSoundPrintAShoutingModelOutput
SNSoundPrintAShoutingModel
SNSoundPrint100kSmokeAlarmModelInput
SNSoundPrint100kSmokeAlarmModelOutput
SNSoundPrint100kSmokeAlarmModel
SNSoundPrintASpeechModelInput
SNSoundPrintASpeechModelOutput
SNSoundPrintASpeechModel
SNVGGishSpeechModelInput
SNVGGishSpeechModelOutput
SNVGGishSpeechModel
SNSoundPrintALaughterModelInput
SNSoundPrintALaughterModelOutput
SNSoundPrintALaughterModel
SNSoundPrintKEmbeddingModelInput
SNSoundPrintKEmbeddingModelOutput
SNSoundPrintKEmbeddingModel
SNVGGishMusicModelInput
SNVGGishMusicModelOutput
SNVGGishMusicModel
SNVGGishCheeringModelInput
SNVGGishCheeringModelOutput
SNVGGishCheeringModel
SNAudioQualityModelInput
SNAudioQualityModelOutput
SNAudioQualityModel
bytes
writeFromBuffer:error:
willChangeValueForKey:
whitespaceAndNewlineCharacterSet
valueWithRange:
valueWithPointer:
valueWithNonretainedObject:
valueWithCMTimeRange:
valueWithCMTime:
valueForKey:
valueForEntitlement:
uppercaseString
unsignedLongLongValue
unsignedIntegerValue
unsignedIntValue
unarchivedObjectOfClass:fromData:error:
unarchivedArrayOfObjectsOfClass:fromData:error:
timeZoneWithName:
substringToIndex:
substringFromIndex:
subarrayWithRange:
strongToWeakObjectsMapTable
stringWithUTF8String:
stringWithFormat:
stringValue
stringFromDate:
stringForKey:
stringByReplacingOccurrencesOfString:withString:
stringByDeletingPathExtension
stringByAppendingString:
stringByAppendingPathExtension:
stringByAppendingPathComponent:
strides
streamDescription
sortedArrayUsingComparator:
sortUsingComparator:
sliceAtOrigin:shape:squeeze:error:
sleepForTimeInterval:
sizeRangeForDimension
shapeConstraint
shape
settings
setWithArray:
setValue:forKeyPath:
setValue:forKey:
setTimeZone:
setTemporaryDirectoryURL:
setTargetID:
setServiceType:
setRootDirectoryURL:
setRemoteObjectInterface:
setReceivedItemHandler:
setProgressHandler:
setPeerPublicKey:
setPath:
setObject:forKeyedSubscript:
setObject:forKey:
setObject:atIndexedSubscript:
setLocale:
setLocalDeviceUpdatedHandler:
setItemURL:
setInvalidationHandler:
setInterruptionHandler:
setInterface:forSelector:argumentIndex:ofReply:
setFramePosition:
setFrameLength:
setFlags:
setFilename:
setExportedObject:
setExportedInterface:
setDispatchQueue:
setDeviceLostHandler:
setDeviceFoundHandler:
setDeviceChangedHandler:
setDestinationID:
setDelegate:
setDateFormat:
setCompletionHandler:
setClasses:forSelector:argumentIndex:ofReply:
setCategory:mode:options:error:
setActive:error:
sendRequestID:request:destinationID:options:responseHandler:
sampleTime
rightExpression
reverseObjectEnumerator
resume
resourcePath
resetForNewRequest
removeObserver:
removeObjectForKey:
removeObjectAtIndex:
removeObject:
removeItemAtURL:error:
removeItemAtPath:error:
removeAllObjects
registerRequestID:options:handler:
readIntoBuffer:frameCount:error:
readIntoBuffer:error:
rangeValue
raise:format:
processingFormat
processName
processInfo
prepareTemplateAndReturnError:
predictedProbabilitiesName
predictedFeatureName
predicateWithFormat:
predicateOperatorType
portType
performQuery:
pathWithComponents:
pathForResource:ofType:
pathExtension
path
outputDescriptionsByName
orderedSetWithArray:
opaqueSessionID
objectForKeyedSubscript:
objectForKey:
objectAtIndexedSubscript:
objectAtIndex:
numberWithUnsignedLong:
numberWithUnsignedInteger:
numberWithUnsignedInt:
numberWithLongLong:
numberWithLong:
numberWithInteger:
numberWithInt:
numberWithFloat:
numberWithDouble:
numberWithBool:
null
nonretainedObjectValue
mutableCopy
mutableAudioBufferList
multiArrayValue
multiArrayConstraint
multiArrayByConcatenatingMultiArrays:alongAxis:dataType:
modelWithContentsOfURL:error:
modelWithContentsOfURL:configuration:error:
minusOrderedSet:
metadata
localizedDescription
length
leftExpression
lastObject
keyPath
isSubsetOfSet:
isOptional
isInterleaved
isFileURL
isEqualToString:
isEqualToArray:
isAllowedShape:error:
invalidate
interfaceWithProtocol:
integerValue
intValue
insertObject:atIndex:
inputSampleRate
inputNumberOfChannels
inputDescriptionsByName
initWithUnsignedInt:
initWithSuiteName:
initWithStreamDescription:channelLayout:
initWithStreamDescription:
initWithShape:dataType:error:
initWithPCMFormat:frameCapacity:
initWithMachServiceName:options:
initWithMachServiceName:
initWithLocaleIdentifier:
initWithLayoutTag:
initWithInputDescriptions:outputDescriptions:predictedFeatureName:predictedProbabilitiesName:metadata:
initWithFeatureProviderArray:
initWithDouble:
initWithDictionary:error:
initWithDataPointer:shape:dataType:strides:deallocator:error:
initWithConfigFile:configRoot:sampleRate:delegate:queue:
initWithCommonFormat:sampleRate:interleaved:channelLayout:
initWithCapacity:
initWithAudioTimeStamp:sampleRate:
initSecondaryReader:format:error:
initForWriting:settings:commonFormat:interleaved:error:
initForReading:error:
initForReading:commonFormat:interleaved:error:
initAuxiliarySession
indexOfObjectIdenticalTo:
indexOfObject:
idsDeviceIdentifier
hasPrefix:
handleFailureInMethod:object:file:lineNumber:description:
getLatestSuperVector
getIdentitiesWithCompletion:
framePosition
frameLength
frameCapacity
format
floatValue
floatChannelData
flags
firstObject
finish
filterUsingPredicate:
fileURLWithPath:isDirectory:
fileURLWithPath:
fileFormat
fileExistsAtPath:
featuresAtIndex:
featureValueWithString:
featureValueWithMultiArray:
featureValueWithDictionary:error:
featureDescriptionWithName:type:optional:constraints:
expressionType
exceptionWithName:reason:userInfo:
evaluateWithObject:
errorWithDomain:code:userInfo:
enumeratedShapes
enumerateKeysAndObjectsUsingBlock:
encodeObject:forKey:
encodeInteger:forKey:
encodeFloat:forKey:
encodeDouble:forKey:
encodeCMTimeRange:forKey:
encodeCMTime:forKey:
encodeBool:forKey:
edPKData
doubleValue
doubleForKey:
didChangeValueForKey:
dictionaryWithObjectsAndKeys:
dictionaryWithObjects:forKeys:count:
dictionaryWithDictionary:
dictionaryWithContentsOfFile:
dictionaryWithCapacity:
dictionaryValue
dictionary
deregisterRequestID:
defaultManager
defaultCenter
decoupledIO
decodeObjectOfClasses:forKey:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
decodeFloatForKey:
decodeDoubleForKey:
decodeCMTimeRangeForKey:
decodeCMTimeForKey:
decodeBoolForKey:
decodeArrayOfObjectsOfClass:forKey:
dateByAddingTimeInterval:
date
dataWithPropertyList:format:options:error:
dataWithJSONObject:options:error:
dataWithBytes:length:
dataType
dataPointer
currentRunLoop
currentHandler
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
countByEnumeratingWithState:objects:count:
count
copy
contentsOfDirectoryAtPath:error:
containsObject:
constraintWithShape:dataType:
constantValue
componentsSeparatedByString:
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
compileModelAtURL:error:
compare:
commonFormat
classLabels
channelLayout
channelCount
writeToURL:options:error:
bundleForClass:
boolValue
boolForKey:
availableInputs
audioBufferList
attributesOfItemAtPath:error:
attributesOfFileSystemForPath:error:
arrayWithObjects:count:
arrayWithObjects:
arrayWithCapacity:
arrayWithArray:
arrayForKey:
arrayByAddingObjectsFromArray:
arrayByAddingObject:
array
archivedDataWithRootObject:requiringSecureCoding:error:
appendString:
anyObject
allowEvaluation
allocWithZone:
allValues
allObjects
allKeys
addObserver:selector:name:object:
addObjectsFromArray:
addObject:
addItem:
addEntriesFromDictionary:
addAudio:
activate
UTF8String
URLByDeletingLastPathComponent
CMTimeValue
URLByAppendingPathComponent:
CMTimeRangeValue
init
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
TB,R
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
timeRange
T{?={?=qiIq}{?=qiIq}},R,N
setTimeRange:
T{?={?=qiIq}{?=qiIq}},N
decibelLevel
_decibelLevel
_timeRange
Tf,R,N
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
.cxx_destruct
_featureExtractorType
_detectorHeadModel
_type
_composedDetector
_detectorIdentifier
initWithBinarySampleRepresentation:metadata:timestamp:
binarySampleRepresentation
confidence
Td,R,N
setConfidence:
Td,N
initWithMood:valence:arousal:dominance:
mood
valence
arousal
dominance
_confidence
_mood
_valence
_arousal
_dominance
Td,R
Td,N,V_confidence
createAnalyzerWithError:
initWithTuningPrefix:
spatialSpectrum
_tuningPrefix
_spatialSpectrum
T@"NSArray",R,N,V_spatialSpectrum
adaptToSystemConfiguration:error:
graph
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N
resultsFromBox:renderedWithFrameCount:
sharedProcessorConfiguration
resultsBox
primeGraph
T^v,R,N
.cxx_construct
_graph
_azimuth
initWithFeaturePrintType:
overlapFactor
setOverlapFactor:
windowDuration
setWindowDuration:
windowDurationConstraint
featurePrintType
setFeaturePrintType:
_overlapFactor
_windowDurationConstraint
_featurePrintType
_windowDuration
Tq,N,V_featurePrintType
Tf,N,V_overlapFactor
T{?=qiIq},N,V_windowDuration
T@"SNTimeDurationConstraint",R,N,V_windowDurationConstraint
blockSize
createWithSampleRate:windowDuration:overlapFactor:error:
defaultWindowDuration
TI,R,N
T{?=qiIq},R,N
T@"SNTimeDurationConstraint",R,N
extractDefaultOutputFeatureFromFeatureProvider:
extractOutputWithOptionalName:fromFeatureProvider:
_featureExtractor
_outputFeatureName
_resultsToDiscardCount
resultsBoxName
sampleRate
initWithOverlapFactor:error:
_blockSize
TI,R,N,V_blockSize
T{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}},R,N,V_graph
initWithSoundPrintModel:sampleRate:windowDuration:overlapFactor:error:
initWithSampleRate:windowDuration:overlapFactor:error:
serverInfo
state
_serverInfo
_state
T@"SNFileServerInfo",R
xpcRequest:didProduceResult:completionHandler:
xpcRequest:didFailWithError:completionHandler:
xpcRequestDidComplete:completionHandler:
setAudioConfiguration:
addRequest:withObserver:error:
removeRequest:
removeAllRequests
start
stop
_subscriber
_creationFlags
_configureAudioQueue
fileName
error
_fileName
_error
T@"NSString",R,N
T@"NSError",R,N
allValidSoundIdentifiers
allValidDetectorIdentifiers
_detectorHead
_soundIdentifier
launchTaskWithQueue:completionHandler:resultsHandler:
addRequest:completionHandler:resultsHandler:
_taskCompletionMap
_queue
isEqualToTimeDurationConstraint:
initWithEnumeratedDurations:
initWithDurationRange:
type
enumeratedDurations
durationRange
_enumeratedDurations
_durationRange
Tq,R,V_type
T@"NSArray",R,V_enumeratedDurations
T{?={?=qiIq}{?=qiIq}},R,V_durationRange
setSampleRate:
setBlockSize:
magnitudeThreshold
setMagnitudeThreshold:
_detector
_sampleRate
_magnitudeThreshold
Td,N,V_sampleRate
TI,N,V_blockSize
Td,N,V_magnitudeThreshold
azimuth
elevation
_elevation
T@"NSArray",R,N
initWithModelDescription:parameterDictionary:error:
predictionFromFeatures:options:error:
predictionsFromBatch:options:error:
_modelDescription
_model
initWithAudioFile:
_referenceAudioFile
Td,V_overlapFactor
_systemConfiguration
_referenceSampleRate
_channelCount
_framesProcessed
createSystemAudioAnalyzer
listener:shouldAcceptNewConnection:
_listener
_coordinator
_connectionToServerGenerator
_xpcConnectionToServer
_pendingInvalidationHandlers
currentFrameValue
setCurrentFrameValue:
meanValue
setMeanValue:
standardDeviation
setStandardDeviation:
_currentFrameValue
_meanValue
_standardDeviation
Td,N,V_currentFrameValue
Td,N,V_meanValue
Td,N,V_standardDeviation
processInput:portID:downstreamHandler:
processTerminationWithOptionalError:portID:downstreamHandler:
_recordOperator
_destinationDirectory
_date
_requestDescription
_buildVersion
_detectionResults
initWithFiles:serverBasePath:serverInfo:
_files
_serverBasePath
modelDescription
T@"MLModelDescription",R
_customModel
T@"MLModelDescription",R,V_modelDescription
_lock
initWithConfiguration:
_configuration
_detectorBoxName
_inputFeatureName
_outputConfidenceFeatureName
_outputDetectedFeatureName
_predicateFilter
xpcCreateSystemAudioAnalyzerWithCompletionHandler:
_receiver
plistRepresentationWithError:
initWithIdentifier:
initWithIdentifier:detectedValue:
detected
identifier
detectorIdentifier
_detected
_identifier
T@"NSString",R,N,V_identifier
TB,R,N
initWithModelClass:modelConfiguration:
_keys
createSecondPassController
twoPassConfiguration
T@"SNTwoPassConfiguration",R
_createSecondPassControllerFunction
_twoPassConfiguration
T@"SNTwoPassConfiguration",R,V_twoPassConfiguration
initWithDictionary:resourcePath:
_path
_text
_includePaths
_substitutions
_value
_resourcePath
_dspItems
createProcessorWithError:
windowLengthFrames
stepSizeFrames
outputFeatureSize
TI,R
_windowLengthFrames
_stepSizeFrames
Td,R,D
TI,R,V_windowLengthFrames
TI,R,V_stepSizeFrames
TI,R,D
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
dealloc
_format
_outputFile
initWithAudioConfiguration:
addRequestInBackground:withObserver:
_impl
fileURLs
setFileURLs:
backgroundEnergyPercentile
setBackgroundEnergyPercentile:
foregroundEnergyPercentile
setForegroundEnergyPercentile:
hangoverDuration
setHangoverDuration:
minSegmentDuration
setMinSegmentDuration:
similarityThreshold
setSimilarityThreshold:
_backgroundEnergyPercentile
_foregroundEnergyPercentile
_similarityThreshold
_fileURLs
_hangoverDuration
_minSegmentDuration
T@"NSArray",V_fileURLs
Tf,V_backgroundEnergyPercentile
Tf,V_foregroundEnergyPercentile
T{?=qiIq},V_hangoverDuration
T{?=qiIq},V_minSegmentDuration
Tf,V_similarityThreshold
initAsNegativeLabel
initAsPositiveLabel
data
setData:
label
setLabel:
datasetType
setDatasetType:
_data
_label
_datasetType
T@"MLMultiArray",&,V_data
T@"SNKShotLabel",&,V_label
Tq,V_datasetType
exemplar
setExemplar:
inferenceWindowSize
setInferenceWindowSize:
_exemplar
_inferenceWindowSize
T@"MLMultiArray",&,V_exemplar
T{?=qiIq},V_inferenceWindowSize
trainingDataEmbeddings
setTrainingDataEmbeddings:
trainingDataLabels
setTrainingDataLabels:
validationDataEmbeddings
setValidationDataEmbeddings:
validationDataLabels
setValidationDataLabels:
_trainingDataEmbeddings
_trainingDataLabels
_validationDataEmbeddings
_validationDataLabels
T@"NSArray",C,V_trainingDataEmbeddings
T@"NSArray",C,V_trainingDataLabels
T@"NSArray",C,V_validationDataEmbeddings
T@"NSArray",C,V_validationDataLabels
exemplarEmbedding
setExemplarEmbedding:
segments
setSegments:
exemplarIndex
setExemplarIndex:
_exemplarEmbedding
_segments
_exemplarIndex
T@"MLMultiArray",&,V_exemplarEmbedding
T@"NSArray",C,V_segments
T@"NSNumber",C,V_exemplarIndex
_embeddings
_labels
setUrl:
_url
T{?={?=qiIq}{?=qiIq}},V_timeRange
T@"NSURL",C,V_url
featurizeFiles:hallucinatorModelURL:queue:completionHandler:
featurizeFiles:hallucinatorModelURL:queue:resultHandler:completionHandler:
performSegmentationRequest:error:
plistFromFeaturizationResult:error:
fileItems
_fileItems
T@"NSArray",R
_keyPath
_registeredRequests
_analyzer
_generator
_audioConfiguration
_completionHandler
_resultsHandler
idsDeviceID
model
name
_idsDeviceID
_name
T@"NSString",R
psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:
psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:
_timeBetweenTriggers
_lastResult
_modelBlockSize
_classLabelsDenylist
_classifierIdentifier
initWithMLModel:error:
initWithClassifierIdentifier:error:
knownClassifications
_classifier
_knownClassifications
T{?=qiIq},V_windowDuration
T@"SNTimeDurationConstraint",R,V_windowDurationConstraint
T@"NSArray",R,C,V_knownClassifications
initWithURL:error:
analyzeInRange:
analyze
analyzeWithCompletionHandler:
cancelAnalysis
_audioFile
_streamAnalyzer
_wasCancelled
initWithRequestType:
decisionDelay
_requestType
timeConversionDictionary
T@"NSDictionary",R
_timeConverter
_requestState
T@"NSArray",R,D,N
initWithSoundIdentifier:shouldUseTwoPassDetection:
initWithSoundIdentifier:
initWithDetectorIdentifier:error:
initWithDetectorVariant:soundIdentifier:modelConfiguration:resultsPredicate:resultsPredicateLeakCount:
initWithVGGishBasedMLModel:soundIdentifier:
setResultsPredicate:error:
setResultsPredicate:
setResultsPredicateLeakCount:
soundIdentifier
modelConfiguration
setModelConfiguration:
resultsPredicate
resultsPredicateLeakCount
_detectorVariant
_modelConfiguration
_resultsPredicate
_resultsPredicateLeakCount
T@"NSString",R,N,V_soundIdentifier
T@"MLModelConfiguration",&,N,V_modelConfiguration
T@"NSPredicate",C,N,V_resultsPredicate
Tq,N,V_resultsPredicateLeakCount
T{shared_ptr<DSPGraph::Graph>=},R,N
T^{Box=},R,N
initWithBox:fromGraph:
_box
sendInputToUltronReporter:recentFramesOfAudioBuffer:startingFromTime:error:
stepSizeFramesForWindowLengthFrames:overlapFactor:minimumStepSize:roundingDownToNearestMultipleOf:
featureExtractorConfigurationForIdentifier:detectorHeadModelMetadata:modelConfiguration:error:
_fileServer
_maxCacheSize
_cacheStorage
_cacheAccessRecency
_wrappedModel
_vendedModels
initWithFeaturePrintType:featureVector:
featureVector
_featureVector
Tq,R,N,V_featurePrintType
T@"MLMultiArray",R,N,V_featureVector
_configured
_request
_analyzerHost
_sharedProcessor
_configurationError
initWithFormat:
updateProcessingTreeFormat:
clientSampleTimeFromSampleTime:fromBox:
clientSampleRate
_processorCache
_processingContexts
_processingTree
_currentFormat
_requests
_analyzerInfos
_shouldRebuildProcessingTree
_inputSensitivity
initWithServerInfo:queryPath:
_queryPath
automaticallyNotifiesObserversForKey:
results
clearResults
errors
clearErrors
clearCompleteCount
completeCount
_results
_errors
_completeCount
Tq,R,N,V_completeCount
cancel
_isCancelled
initWithDSPGraph:
featureValueForName:
featureNames
T@"NSSet",R,N
_featureDescription
_featureCache
_allInputFeatureNames
_input
_feedbackConnections
_inputProvider
_outputProvider
filename
fileSize
itemURL
_filename
_fileSize
_itemURL
Tq,R
T@"NSURL",R
_maxHistoryLength
_confidenceThreshold
_streak
_history
_commandFilters
offset
_offset
initWithServerInfo:serverBasePath:serverFilePaths:localDestinationPath:
_serverFilePaths
_localDestinationPath
_firstPassRequest
_secondPassRequest
_historicalDataAmount
_eventHandlerQueue
_eventHandlerQueueFundsSpent
_eventHandlerQueueFundsEarned
_eventHandlerQueueStopped
_bufferHandler
_interruptionHandler
_transaction
_recordFormat
_lastHeartbeatTime
_audioQueueConfiguration
_session
_dispatchQueue
_running
_audioQueue
_aqCallbackScheduler
initWithModelDescription:expectedInputShape:expectedOutputShape:graph:error:
_inputConstraint
_outputConstraint
_scratchFloatSpace
_modelOutput
_preProcessCallback
shouldLogResultsHistory
addRequest:completionHandler:resultsHandler:error:
analyzeAudioBuffer:atAudioFramePosition:
completeAnalysis
_analyzerQueue
_firstPassRecordingPredicate
_firstPassRecordingHistoryDuration
_sysdiagnoseHistoryDuration
_firstPassAnalyzer
_secondPassAnalyzers
_secondPassUltronReportOps
_firstPassUltronReportOps
_firstPassResultsHistory
_ringBuffer
_ringBufferWriteBufferList
_unregisterLogCollectHook
_analysisState
minDurationBlocks
confidenceThreshold
_minDurationBlocks
T@"NSString",R,N,V_name
Tq,R,N,V_minDurationBlocks
Td,R,N,V_confidenceThreshold
initWithModel:dictionary:error:
hopSizeSamples
setHopSizeSamples:
blocksBetweenTriggers
setBlocksBetweenTriggers:
commands
setCommands:
_hopSizeSamples
_blocksBetweenTriggers
_commands
Td,R,N,V_sampleRate
Tq,N,V_hopSizeSamples
Tq,N,V_blocksBetweenTriggers
T@"NSArray",C,N,V_commands
_modelOutputFilter
_overlapFilter
_object
initWithRootDirectory:
activateWithCompletion:
_server
_link
_rootDirectory
_boxName
_busIndex
xpcAddRequest:withObserver:completionHandler:
xpcRemoveRequest:completionHandler:
xpcRemoveAllRequestsWithCompletionHandler:
xpcStartWithCompletionHandler:
xpcStopWithCompletionHandler:
xpcSetAudioConfiguration:completionHandler:
computationalDutyCycle
setComputationalDutyCycle:
graphIsDeadEnded
setGraphIsDeadEnded:
shouldThrowException
setShouldThrowException:
_graphIsDeadEnded
_shouldThrowException
_computationalDutyCycle
Td,N,V_computationalDutyCycle
TB,N,V_graphIsDeadEnded
TB,N,V_shouldThrowException
_mlModel
handleAVAudioSessionInterruption:
handleAVAudioSessionRouteChange:
handleAVAudioSessionMediaServicesLost:
handleAVAudioSessionMediaServicesReset:
_analysisQueue
_recordingQueue
_recordingState
_clientStartedAnalysis
_observers
_audioSession
_logMelExtractionParameters
_interpreter
_minimumObservableOffset
_maximumObservableOffset
initWithClassificationDictionary:
classificationForIdentifier:
classifications
classifierIdentifier
setClassifierIdentifier:
_cachedClassifications
_classificationDictionary
T@"NSString",C,N,V_classifierIdentifier
T@"NSArray",R,C
initWithIdentifier:confidence:
T@"NSString",R,C,V_identifier
Td,R,V_confidence
modelURLForCurrentProduct
category
setCategory:
mode
setMode:
options
setOptions:
channelMap
setChannelMap:
useSiriAudioRouting
setUseSiriAudioRouting:
_useSiriAudioRouting
_category
_mode
_options
_channelMap
T@"NSString",C,N,V_category
T@"NSString",C,N,V_mode
TQ,N,V_options
T@"NSArray",C,N,V_channelMap
TB,N,V_useSiriAudioRouting
initWithModel:modelDescription:
_outerToInnerInputFeatureNameMappings
_outerToInnerOutputFeatureNameMappings
_outputShape
initWithSecondPassBeginThreshold:secondPassEndThreshold:secondPassHangoverPeriod:firstPassResultToComparableFunction:secondPassResultToComparableFunction:
firstPassDidProduceResult:
secondPassDidProduceResult:
beginSecondPassHandler
setBeginSecondPassHandler:
endSecondPassHandler
setEndSecondPassHandler:
T@?,C
_secondPassBeginThreshold
_secondPassEndThreshold
_secondPassHangoverPeriod
_secondPassTriggerTime
_firstResultBelowEndThresholdStartTime
_secondPassIsActive
_firstPassResultToComparableFunction
_secondPassResultToComparableFunction
_beginSecondPassHandler
_endSecondPassHandler
T@?,C,V_beginSecondPassHandler
T@?,C,V_endSecondPassHandler
_featureExtractorConfiguration
_outputLabel
_activeProcessorsCache
peakTime
peakValue
channelIndex
_peakValue
_channelIndex
_peakTime
Tq,R,N
T{?={?=qiIq}{?=qiIq}},N,VtimeRange
featureExtractorIdentifier
setFeatureExtractorIdentifier:
windowSizeInSamples
setWindowSizeInSamples:
hopSizeInSamples
setHopSizeInSamples:
setSoundIdentifier:
_featureExtractorIdentifier
_windowSizeInSamples
_hopSizeInSamples
T@"NSNumber",C,V_sampleRate
T@"NSString",C,V_featureExtractorIdentifier
T@"NSNumber",C,V_windowSizeInSamples
T@"NSNumber",C,V_hopSizeInSamples
T@"NSString",C,V_soundIdentifier
_sourceFeatureName
_destinationFeatureName
_leakRemaining
_predicate
_leakCount
endTimesFromTimeRangeCollection:
remoteObjectProxy
remoteObjectProxyWithErrorHandler:
synchronousRemoteObjectProxyWithErrorHandler:
_remoteObservers
initWithInput1:
initWithInput1:stateIn:detectedHistoryIn:
input1
setInput1:
stateIn
setStateIn:
detectedHistoryIn
setDetectedHistoryIn:
_input1
_stateIn
_detectedHistoryIn
T@"MLMultiArray",&,N,V_input1
T@"MLMultiArray",&,N,V_stateIn
T@"MLMultiArray",&,N,V_detectedHistoryIn
initWithInput_1:Confidence:Detected:detectedHistoryOut:
input_1
setInput_1:
Confidence
Detected
setDetected:
detectedHistoryOut
setDetectedHistoryOut:
_input_1
_Confidence
_Detected
_detectedHistoryOut
T@"MLMultiArray",&,N,V_input_1
T@"MLMultiArray",&,N,V_Confidence
T@"MLMultiArray",&,N,V_Detected
T@"MLMultiArray",&,N,V_detectedHistoryOut
URLOfModelInThisBundle
loadWithConfiguration:completionHandler:
loadContentsOfURL:configuration:completionHandler:
initWithMLModel:
initWithConfiguration:error:
initWithContentsOfURL:error:
initWithContentsOfURL:configuration:error:
predictionFromFeatures:error:
predictionFromInput1:stateIn:detectedHistoryIn:error:
predictionsFromInputs:options:error:
T@"MLModel",R,N,V_model
initWithOutput1:
output1
setOutput1:
_output1
T@"MLMultiArray",&,N,V_output1
predictionFromInput1:error:
initWithAudioSamples:
audioSamples
setAudioSamples:
_audioSamples
T@"MLMultiArray",&,N,V_audioSamples
initWith_637:
_637
set_637:
__637
T@"MLMultiArray",&,N,V__637
predictionFromAudioSamples:error:
initWithSoundprint_Placeholder:
soundprint_Placeholder
setSoundprint_Placeholder:
_soundprint_Placeholder
T@"MLMultiArray",&,N,V_soundprint_Placeholder
initWithSigmoid:
Sigmoid
setSigmoid:
_Sigmoid
T@"MLMultiArray",&,N,V_Sigmoid
predictionFromSoundprint_Placeholder:error:
initWith_9:classLabel:
set_9:
classLabel
setClassLabel:
_classLabel
T@"NSDictionary",&,N,V__9
T@"NSString",&,N,V_classLabel
initWithFixedLengthEmbedding:framewiseEmbedding:
fixedLengthEmbedding
setFixedLengthEmbedding:
framewiseEmbedding
setFramewiseEmbedding:
_fixedLengthEmbedding
_framewiseEmbedding
T@"MLMultiArray",&,N,V_fixedLengthEmbedding
T@"MLMultiArray",&,N,V_framewiseEmbedding
initWithFinal_output:classLabel:
final_output
setFinal_output:
_final_output
T@"NSDictionary",&,N,V_final_output
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
{?={?=qiIq}{?=qiIq}}16@0:8
v64@0:8{?={?=qiIq}{?=qiIq}}16
f16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v16@0:8
@"NSString"
@"MLModel"
@"SNComposedDetector"
@40@0:8@16@24d32
@40@0:8@"NSData"16@"NSDictionary"24d32
@"NSData"16@0:8
d16@0:8
v24@0:8d16
@48@0:8d16d24d32d40
@24@0:8^@16
@"<SNAnalyzing>"24@0:8^@16
@"NSArray"
B32@0:8@16^@24
{shared_ptr<DSPGraph::Graph>=^{Graph}^{__shared_weak_count}}16@0:8
B32@0:8@"SNSystemConfiguration"16^@24
@28@0:8^v16i24
^v16@0:8
@"NSArray"28@0:8^v16i24
{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}
@24@0:8q16
v20@0:8f16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
q16@0:8
v24@0:8q16
@"SNTimeDurationConstraint"
{?="value"q"timescale"i"flags"I"epoch"q}
I16@0:8
@60@0:8d16{?=qiIq}24f48^@52
@"<SNFeaturePrintExtractorProtocol>"60@0:8d16{?=qiIq}24f48^@52
@"SNTimeDurationConstraint"16@0:8
@"<SNFeaturePrintExtractorProtocol>"
@28@0:8f16^@20
@68@0:8@16d24{?=qiIq}32f56^@60
@"SNFileServerInfo"
v40@0:8@16@24@?32
v32@0:8@16@?24
v40@0:8@"<SNRequest>"16@"<SNResult>"24@?<v@?>32
v40@0:8@"<SNRequest>"16@"NSError"24@?<v@?>32
v32@0:8@"<SNRequest>"16@?<v@?>24
B40@0:8@16@24^@32
v24@0:8@"SNAudioConfiguration"16
B40@0:8@"<SNRequest>"16@"<SNResultsObserving>"24^@32
v24@0:8@"<SNRequest>"16
@"<SNSystemAudioAnalyzerXPCProtocol><NSXPCProxyCreating>"
@"NSError"
@?40@0:8@16@?24@?32
@?<v@?>40@0:8@"NSObject<OS_dispatch_queue>"16@?<v@?@"NSError">24@?<v@?@"<SNResult>">32
v40@0:8@16@?24@?32
@"NSMutableDictionary"
@"NSObject<OS_dispatch_queue>"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v20@0:8I16
@"SNDetectSignalThresholdRequestImpl"
@40@0:8@16@24^@32
@40@0:8@"MLModelDescription"16@"NSDictionary"24^@32
@"<MLFeatureProvider>"40@0:8@"<MLFeatureProvider>"16@"MLPredictionOptions"24^@32
@"<MLBatchProvider>"40@0:8@"<MLBatchProvider>"16@"MLPredictionOptions"24^@32
@"MLModelDescription"
@"AVAudioFile"
@"SNSystemConfiguration"
@"<SNSystemAudioAnalyzerProtocol>"16@0:8
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"SNSystemServiceResourceCoordinator"
@"NSXPCConnection"
@"NSMutableArray"
v40@0:8@16@"NSString"24@?<v@?@"NSString"@@"NSError">32
v40@0:8@"NSError"16@"NSString"24@?<v@?@"NSString"@@"NSError">32
@"SNRecordOperator"
@"NSURL"
@"NSDate"
@40@0:8@16@24@32
@"MLModelDescription"16@0:8
@"<MLCustomModel>"
@"<SNMLModel>"
{mutex="__m_"{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}}
@"SNDetectorHeadConfiguration"
@"SNPredicateFilterOperator"
v24@0:8@?16
v24@0:8@?<v@?@"<SNSystemAudioAnalyzerXPCProtocol>">16
@"<SNResourceCoordinatorProtocol>"
@28@0:8@16B24
@"<SNSecondPassController>"16@0:8
@"SNTwoPassConfiguration"16@0:8
@"SNTwoPassConfiguration"
@32@0:8@16@24
@"NSDictionary"
@"<SNProcessing>"24@0:8^@16
v32@0:8@16@24
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
@"<SNResultsObserving>"
@"AVAudioFormat"
@"<SNSystemAudioAnalyzerProtocol>"
@"MLMultiArray"
@"SNKShotLabel"
@"NSNumber"
@48@0:8@16@24@32@?40
@56@0:8@16@24@32@?40@?48
@32@0:8@16^@24
@"SNAudioConfiguration"
v48@0:8@16@24Q32Q40
v48@0:8@"EARSyncPSRAudioProcessor"16@"NSData"24Q32Q40
@"SNVoiceTriggerResult"
@"NSSet"
@"SNClassifierVariant"
@"SNAudioStreamAnalyzer"
@"NSDictionary"16@0:8
@"<SNAnalyzing>"
@"<SNTimeConverting>"
@"SNSoundPrintFeatureExtractorConfiguration"
@56@0:8@16@24@32@40q48
@"SNDetectorVariant"
@"MLModelConfiguration"
@"NSPredicate"
B64@0:8@16^v24{?=qiIq}32^@56
@"SNFileServer"
{unordered_map<SoundAnalysis::MD5Hash, id<MLFeatureProvider>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, std::allocator<std::pair<const SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__table_"{__hash_table<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>, std::allocator<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::hash<SoundAnalysis::MD5Hash>, std::equal_to<SoundAnalysis::MD5Hash>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<SoundAnalysis::MD5Hash, std::__hash_value_type<SoundAnalysis::MD5Hash, id<MLFeatureProvider>>, std::equal_to<SoundAnalysis::MD5Hash>, std::hash<SoundAnalysis::MD5Hash>, true>>="__value_"f}}}
{list<SoundAnalysis::MD5Hash, std::allocator<SoundAnalysis::MD5Hash>>="__end_"{__list_node_base<SoundAnalysis::MD5Hash, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::MD5Hash, void *>>>="__value_"Q}}
@"NSMapTable"
@32@0:8q16@24
@"<SNAnalyzerCreating>"
@"SNAnalyzerHost"
@"<SNProcessing>"
q32@0:8q16^v24
@"SNAudioProcessorCache"
{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}
{ProcessingTree="mGraph"{shared_ptr<DSPGraph::Graph>="__ptr_"^{Graph}"__cntrl_"^{__shared_weak_count}}"mProcessingContexts"{list<SoundAnalysis::ProcessingContext, std::allocator<SoundAnalysis::ProcessingContext>>="__end_"{__list_node_base<SoundAnalysis::ProcessingContext, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingContext, void *>>>="__value_"Q}}"mFormatMatchingNodes"{list<SoundAnalysis::FormatMatchingNode, std::allocator<SoundAnalysis::FormatMatchingNode>>="__end_"{__list_node_base<SoundAnalysis::FormatMatchingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::FormatMatchingNode, void *>>>="__value_"Q}}"mSharedProcessingNodes"{list<SoundAnalysis::SharedProcessingNode, std::allocator<SoundAnalysis::SharedProcessingNode>>="__end_"{__list_node_base<SoundAnalysis::SharedProcessingNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::SharedProcessingNode, void *>>>="__value_"Q}}"mAnalyzerNodes"{list<SoundAnalysis::AnalyzerNode, std::allocator<SoundAnalysis::AnalyzerNode>>="__end_"{__list_node_base<SoundAnalysis::AnalyzerNode, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::AnalyzerNode, void *>>>="__value_"Q}}"mRootNode"{RootNode="_vptr$ProcessingNode"^^?"mUpstreamNode"^{ProcessingNode}"mDownstreamNodes"{list<SoundAnalysis::ProcessingNode *, std::allocator<SoundAnalysis::ProcessingNode *>>="__end_"{__list_node_base<SoundAnalysis::ProcessingNode *, void *>="__prev_"^v"__next_"^v}"__size_alloc_"{__compressed_pair<unsigned long, std::allocator<std::__list_node<SoundAnalysis::ProcessingNode *, void *>>>="__value_"Q}}"mProcessingBox"^{Box}"mUpstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}"mDownstreamFormat"{FormatAndBlockSize="mFormat"{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}"mBlockSize"I}}"mMaxFramesPerSlice"I"mWillInitializeCallback"{function<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__f_"{__value_func<void (std::shared_ptr<DSPGraph::Graph>, unsigned long)>="__buf_"{type="__lx"[24C]}"__f_"^v}}"mCurrentInputSampleTime"q}
@"<SNResourceCoordinatorXPCProtocol><NSXPCProxyCreating>"
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
@"MLFeatureDescription"
@"DSPGMLInputProvider"
@"<MLFeatureProvider>"
@48@0:8@16@24@32@40
@"<SNRequest>"
@"NSObject<OS_os_transaction>"
@"SNAudioQueueConfiguration"
@"AVAudioSession"
^{OpaqueAudioQueue=}
@"SNAudioRecordingQueueScheduler"
@"MLMultiArrayConstraint"
{unique_ptr<DSPGraph::Graph, std::default_delete<DSPGraph::Graph>>="__ptr_"{__compressed_pair<DSPGraph::Graph *, std::default_delete<DSPGraph::Graph>>="__value_"^{Graph}}}
{vector<float, std::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::allocator<float>>="__value_"^f}}
@"SNDSPGraphCustomModel"
B48@0:8@16@?24@?32^@40
v32@0:8@16q24
@"SNForwardPassAudioStreamAnalyzer"
{unique_ptr<AT::RingBuffer, std::default_delete<AT::RingBuffer>>="__ptr_"{__compressed_pair<AT::RingBuffer *, std::default_delete<AT::RingBuffer>>="__value_"^{RingBuffer}}}
{unique_ptr<CABufferList, std::default_delete<CABufferList>>="__ptr_"{__compressed_pair<CABufferList *, std::default_delete<CABufferList>>="__value_"^{CABufferList}}}
@"SNLogMelBasedFeatureExtractorConfiguration"
@"SNDetectVoiceTriggerRequest"
@"SNProcessVoiceTriggerModelOutput"
@"SNFilterVoiceTriggerResults"
@"CUFileServer"
@"RPCompanionLinkClient"
v40@0:8@"<SNRequest>"16@"<SNResultsObservingXPCProtocol>"24@?<v@?@"NSError">32
v24@0:8@?<v@?>16
v32@0:8@"SNAudioConfiguration"16@?<v@?>24
v20@0:8B16
@"SNNullDetector"
@"SNAudioRecordingQueue"
{SNLogMelParameters="sampleRate"f"numMelBands"I"minFrequency"f"maxFrequency"f"melType"i"hopLength"I"windowLength"I"windowOffset"I"fftLength"I"fftOffset"i"normalizationStrategy"i}
{unique_ptr<DSPGraph::Interpreter, std::default_delete<DSPGraph::Interpreter>>="__ptr_"{__compressed_pair<DSPGraph::Interpreter *, std::default_delete<DSPGraph::Interpreter>>="__value_"^{Interpreter}}}
@"SNAudioOffsetEstimator"
@32@0:8@16d24
v24@0:8Q16
@?16@0:8
v24@0:8@"<SNResult>"16
@?<v@?>16@0:8
@"<SNProcessorCreating>"
@"<SNResultsObservingXPCProtocol><NSXPCProxyCreating>"
@24@0:8@?16
@24@0:8@?<v@?@"NSError">16
@48@0:8@16@24@32^@40
