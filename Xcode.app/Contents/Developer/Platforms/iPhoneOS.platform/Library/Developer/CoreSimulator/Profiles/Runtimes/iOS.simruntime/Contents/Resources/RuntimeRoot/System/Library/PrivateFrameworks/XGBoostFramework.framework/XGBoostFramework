@(#)PROGRAM:XGBoostFramework  PROJECT:CoreML-1
NSt3__110__function6__funcIN7xgboost9predictor3$_0ENS_9allocatorIS4_EEFPNS2_9PredictorEPKNS2_16GenericParameterENS_10shared_ptrINS_13unordered_mapIPNS2_7DMatrixENS2_20PredictionCacheEntryENS_4hashISF_EENS_8equal_toISF_EENS5_INS_4pairIKSF_SG_EEEEEEEEEEE
NSt3__110__function6__baseIFPN7xgboost9PredictorEPKNS2_16GenericParameterENS_10shared_ptrINS_13unordered_mapIPNS2_7DMatrixENS2_20PredictionCacheEntryENS_4hashISB_EENS_8equal_toISB_EENS_9allocatorINS_4pairIKSB_SC_EEEEEEEEEEE
N7xgboost9predictor12CPUPredictorE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_10SparsePageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_10SparsePageEEEE27__shared_ptr_default_deleteIS4_S4_EE
N7xgboost9predictor3$_0E
N4dmlc5ErrorE
NSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
NSt3__110__function6__baseIFPN7xgboost6MetricEPKcEEE
N7xgboost6metric7EvalAMSE
N7xgboost6MetricE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalAucE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost6metric3$_2ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric9EvalAucPRE
N7xgboost6metric3$_2E
NSt3__110__function6__funcIN7xgboost6metric3$_3ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalPrecisionE
N7xgboost6metric12EvalRankListE
N7xgboost6metric3$_3E
NSt3__110__function6__funcIN7xgboost6metric3$_4ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric8EvalNDCGE
N7xgboost6metric3$_4E
NSt3__110__function6__funcIN7xgboost6metric3$_5ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalMAPE
N7xgboost6metric3$_5E
NSt3__110__function6__funcIN7xgboost6metric3$_6ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalCoxE
N7xgboost6metric3$_6E
N4dmlc9parameter10FieldEntryIfEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIfEEfEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIfEEfEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
NSt3__110__function6__baseIFPN7xgboost11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_16LinearSquareLossEEE
N7xgboost11ObjFunctionE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_15SquaredLogErrorEEE
N7xgboost3obj3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_2ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_18LogisticRegressionEEE
N7xgboost3obj3$_2E
NSt3__110__function6__funcIN7xgboost3obj3$_3ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_22LogisticClassificationEEE
N7xgboost3obj3$_3E
NSt3__110__function6__funcIN7xgboost3obj3$_4ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_11LogisticRawEEE
N7xgboost3obj3$_4E
NSt3__110__function6__funcIN7xgboost3obj3$_5ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj3$_5E
NSt3__110__function6__funcIN7xgboost3obj3$_6ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj17PoissonRegressionE
N7xgboost3obj3$_6E
NSt3__110__function6__funcIN7xgboost3obj3$_7ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13CoxRegressionE
N7xgboost3obj3$_7E
NSt3__110__function6__funcIN7xgboost3obj3$_8ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj15GammaRegressionE
N7xgboost3obj3$_8E
NSt3__110__function6__funcIN7xgboost3obj3$_9ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj17TweedieRegressionE
N7xgboost3obj3$_9E
N4dmlc9parameter16FieldAccessEntryE
N7xgboost12ConfigurableE
N7xgboost5ValueE
N4dmlc10ParamErrorE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonStringENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonStringEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonObjectENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonObjectEEE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree13TreeRefresherE
NSt3__110__function6__funcIZN7xgboost4tree13TreeRefresher6UpdateEPNS2_16HostDeviceVectorINS2_6detail20GradientPairInternalIfEEEEPNS2_7DMatrixERKNS_6vectorIPNS2_7RegTreeENS_9allocatorISF_EEEEEUlvE_NSG_ISL_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZN7xgboost4tree13TreeRefresher6UpdateEPNS_16HostDeviceVectorINS_6detail20GradientPairInternalIfEEEEPNS_7DMatrixERKNSt3__16vectorIPNS_7RegTreeENSA_9allocatorISD_EEEEEUlvE_
N7xgboost4tree3$_0E
NSt3__117bad_function_callE
NSt3__110__function6__baseIFPN7xgboost11TreeUpdaterEvEEE
N7xgboost11TreeUpdaterE
NSt3__120__shared_ptr_pointerIPN7xgboost11JsonIntegerENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_11JsonIntegerEEE
N4dmlc9parameter10FieldEntryImEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryImEEmEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryImEEmEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_28PairwiseLambdaWeightComputerEEE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_24NDCGLambdaWeightComputerEEE
N7xgboost3obj3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_2ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_23MAPLambdaWeightComputerEEE
N7xgboost3obj3$_2E
N4dmlc2io15LocalFileSystemE
N4dmlc2io10FileStreamE
N4dmlc10SeekStreamE
N4dmlc6StreamE
N4dmlc9parameter10FieldEntryIbEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIbEEbEE
N4dmlc9parameter10FieldEntryIiEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIiEEiEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIiEEiEE
N7xgboost4data17EllpackPageSourceE
N7xgboost10DataSourceINS_11EllpackPageEEE
N4dmlc8DataIterIN7xgboost11EllpackPageEEE
N4dmlc2io14InputSplitBaseE
N4dmlc10InputSplitE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree10TreePrunerE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost6linear3$_0ENS_9allocatorIS4_EEFPNS2_13LinearUpdaterEvEEE
NSt3__110__function6__baseIFPN7xgboost13LinearUpdaterEvEEE
N7xgboost6linear17CoordinateUpdaterE
N7xgboost13LinearUpdaterE
N7xgboost6linear21CyclicFeatureSelectorE
N7xgboost6linear15FeatureSelectorE
N7xgboost6linear22ShuffleFeatureSelectorE
N7xgboost6linear22ThriftyFeatureSelectorE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_7CSCPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_7CSCPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
N7xgboost6linear21GreedyFeatureSelectorE
N7xgboost6linear21RandomFeatureSelectorE
N7xgboost6linear3$_0E
N4dmlc2io12LineSplitterE
BNSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric14EvalMatchErrorE
N7xgboost6metric14EvalMClassBaseINS0_14EvalMatchErrorEEE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric16EvalMultiLogLossE
N7xgboost6metric14EvalMClassBaseINS0_16EvalMultiLogLossEEE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj8HingeObjE
N7xgboost3obj3$_0E
N7xgboost9PredictorE
N7xgboost4tree14SplitEvaluatorE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS3_14SplitEvaluatorENS_10unique_ptrIS7_NS_14default_deleteIS7_EEEEEEE
NSt3__110__function6__baseIFPN7xgboost4tree14SplitEvaluatorENS_10unique_ptrIS4_NS_14default_deleteIS4_EEEEEEE
N7xgboost4tree10ElasticNetE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS3_14SplitEvaluatorENS_10unique_ptrIS7_NS_14default_deleteIS7_EEEEEEE
N7xgboost4tree19MonotonicConstraintE
N7xgboost4tree3$_1E
:N7xgboost6common10SparseCutsE
N7xgboost6common11CutsBuilderE
N7xgboost6common9DenseCutsE
N5rabit5utils19MemoryFixSizeBufferE
_N5rabit5utils18MemoryBufferStreamE
;N7xgboost4tree17QuantileHistMakerE
N7xgboost4tree17QuantileHistMaker7BuilderE
NSt3__110__function6__funcIPFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES6_ENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES6_EEE
PFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES3_E
FbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES3_E
NSt3__110__function6__funcIN7xgboost4tree3$_2ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree3$_2E
NSt3__110__function6__funcIN7xgboost4tree3$_3ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree3$_3E
NSt3__120__shared_ptr_emplaceIN7xgboost16HostDeviceVectorIjEENS_9allocatorIS3_EEEE
N7xgboost3gbm13GBLinearModelE
N7xgboost5ModelE
NSt3__120__shared_ptr_pointerIPN7xgboost8JsonNullENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_8JsonNullEEE
NSt3__120__shared_ptr_pointerIPN7xgboost9JsonArrayENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_9JsonArrayEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonNumberENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonNumberEEE
gpu_coord_descent
N4dmlc9parameter10FieldEntryINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EE
NSt3__110__function6__funcIN7xgboost3gbm3$_0ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
NSt3__110__function6__baseIFPN7xgboost15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS_9allocatorIS8_EEEEPKNS2_17LearnerModelParamEEEE
N7xgboost3gbm8GBLinearE
N7xgboost15GradientBoosterE
N7xgboost3gbm3$_0E
NSt3__110__function6__funcIN7xgboost6linear3$_0ENS_9allocatorIS4_EEFPNS2_13LinearUpdaterEvEEE
N7xgboost6linear14ShotgunUpdaterE
N7xgboost6linear3$_0E
N7xgboost3gbm6GBTreeE
N4dmlc9parameter10FieldEntryIN7xgboost15TreeProcessTypeEEE
N4dmlc9parameter10FieldEntryIN7xgboost13PredictorTypeEEE
N4dmlc9parameter10FieldEntryIN7xgboost10TreeMethodEEE
NSt3__110__function6__funcIN7xgboost3gbm3$_4ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapIPN7xgboost7DMatrixENS2_20PredictionCacheEntryENS_4hashIS4_EENS_8equal_toIS4_EENS_9allocatorINS_4pairIKS4_S5_EEEEEENSA_ISF_EEEE
N7xgboost3gbm3$_4E
NSt3__110__function6__funcIN7xgboost3gbm3$_5ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
N7xgboost3gbm4DartE
N7xgboost3gbm3$_5E
NSt3__120__shared_ptr_pointerIPN7xgboost11JsonBooleanENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_11JsonBooleanEEE
N7xgboost4data15SimpleCSRSourceE
N7xgboost10DataSourceINS_10SparsePageEEE
N4dmlc8DataIterIN7xgboost10SparsePageEEE
N4dmlc2io10FileSystemE
N4dmlc8DataIterINS_8RowBlockIjfEEEE
N4dmlc8DataIterINS_8RowBlockIyfEEEE
N4dmlc8DataIterINS_8RowBlockIjiEEEE
N4dmlc8DataIterINS_8RowBlockIyiEEEE
N4dmlc8DataIterINS_8RowBlockIjxEEEE
N4dmlc8DataIterINS_8RowBlockIyxEEEE
N4dmlc4data12LibSVMParserIjfEE
N4dmlc4data14TextParserBaseIjfEE
N4dmlc4data10ParserImplIjfEE
N4dmlc6ParserIjfEE
N4dmlc4data14ThreadedParserIjfEE
N4dmlc12ThreadedIterINSt3__16vectorINS_4data17RowBlockContainerIjfEENS1_9allocatorIS5_EEEEEE
N4dmlc8DataIterINSt3__16vectorINS_4data17RowBlockContainerIjfEENS1_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIjfEC1EPNS3_10ParserImplIjfEEEUlPPNS_6vectorINS3_17RowBlockContainerIjfEENS_9allocatorISB_EEEEE_NSC_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPNS_6vectorIN4dmlc4data17RowBlockContainerIjfEENS_9allocatorIS6_EEEEEEE
ZN4dmlc4data14ThreadedParserIjfEC1EPNS0_10ParserImplIjfEEEUlPPNSt3__16vectorINS0_17RowBlockContainerIjfEENS6_9allocatorIS9_EEEEE_
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIjfEC1EPNS3_10ParserImplIjfEEEUlvE_NS_9allocatorIS9_EEFvvEEE
ZN4dmlc4data14ThreadedParserIjfEC1EPNS0_10ParserImplIjfEEEUlvE_
N4dmlc4data12LibSVMParserIyfEE
N4dmlc4data14TextParserBaseIyfEE
N4dmlc4data10ParserImplIyfEE
N4dmlc6ParserIyfEE
N4dmlc4data14ThreadedParserIyfEE
N4dmlc12ThreadedIterINSt3__16vectorINS_4data17RowBlockContainerIyfEENS1_9allocatorIS5_EEEEEE
N4dmlc8DataIterINSt3__16vectorINS_4data17RowBlockContainerIyfEENS1_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIyfEC1EPNS3_10ParserImplIyfEEEUlPPNS_6vectorINS3_17RowBlockContainerIyfEENS_9allocatorISB_EEEEE_NSC_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPNS_6vectorIN4dmlc4data17RowBlockContainerIyfEENS_9allocatorIS6_EEEEEEE
ZN4dmlc4data14ThreadedParserIyfEC1EPNS0_10ParserImplIyfEEEUlPPNSt3__16vectorINS0_17RowBlockContainerIyfEENS6_9allocatorIS9_EEEEE_
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIyfEC1EPNS3_10ParserImplIyfEEEUlvE_NS_9allocatorIS9_EEFvvEEE
ZN4dmlc4data14ThreadedParserIyfEC1EPNS0_10ParserImplIyfEEEUlvE_
N4dmlc4data11LibFMParserIjfEE
N4dmlc4data11LibFMParserIyfEE
N4dmlc4data9CSVParserIjfEE
N4dmlc4data9CSVParserIyfEE
N4dmlc4data9CSVParserIjiEE
N4dmlc4data14TextParserBaseIjiEE
N4dmlc4data10ParserImplIjiEE
N4dmlc6ParserIjiEE
N4dmlc4data9CSVParserIyiEE
N4dmlc4data14TextParserBaseIyiEE
N4dmlc4data10ParserImplIyiEE
N4dmlc6ParserIyiEE
N4dmlc4data9CSVParserIjxEE
N4dmlc4data14TextParserBaseIjxEE
N4dmlc4data10ParserImplIjxEE
N4dmlc6ParserIjxEE
N4dmlc4data9CSVParserIyxEE
N4dmlc4data14TextParserBaseIyxEE
N4dmlc4data10ParserImplIyxEE
N4dmlc6ParserIyxEE
N4dmlc12ScopedThreadE
N7xgboost10JsonStringE
N7xgboost9JsonArrayE
N7xgboost10JsonObjectE
N7xgboost10JsonNumberE
N7xgboost11JsonIntegerE
N7xgboost8JsonNullE
N7xgboost11JsonBooleanE
N7xgboost10JsonReaderE
N7xgboost10JsonWriterE
N7xgboost29FixedPrecisionStreamContainerINSt3__19allocatorIcEEEE
N4dmlc2io16RecordIOSplitterE
N7xgboost7DMatrixE
N4dmlc7istreamE
N4dmlc7istream5InBufE
N4dmlc12ThreadedIterIN7xgboost10SparsePageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_10SparsePageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost10SparsePageEEEE
ZN7xgboost4data16SparsePageSourceINS_10SparsePageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_10SparsePageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_10SparsePageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data16SparsePageSourceINS_10SparsePageEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10SparsePageENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost10SparsePageEE27__shared_ptr_default_deleteIS2_S2_EE
N4dmlc2io15SingleFileSplitE
N4dmlc2io18ThreadedInputSplitE
N4dmlc12ThreadedIterINS_2io14InputSplitBase5ChunkEEE
N4dmlc8DataIterINS_2io14InputSplitBase5ChunkEEE
NSt3__110__function6__funcIZN4dmlc2io18ThreadedInputSplitC1EPNS3_14InputSplitBaseEmEUlPPNS5_5ChunkEE_NS_9allocatorISA_EEFbS9_EEE
NSt3__110__function6__baseIFbPPN4dmlc2io14InputSplitBase5ChunkEEEE
ZN4dmlc2io18ThreadedInputSplitC1EPNS0_14InputSplitBaseEmEUlPPNS2_5ChunkEE_
NSt3__110__function6__funcIZN4dmlc2io18ThreadedInputSplitC1EPNS3_14InputSplitBaseEmEUlvE_NS_9allocatorIS7_EEFvvEEE
ZN4dmlc2io18ThreadedInputSplitC1EPNS0_14InputSplitBaseEmEUlvE_
N4dmlc2io16CachedInputSplitE
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlPPNS3_14InputSplitBase5ChunkEE_NS_9allocatorIS9_EEFbS8_EEE
ZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlPPNS0_14InputSplitBase5ChunkEE_
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlvE_NS_9allocatorIS5_EEFvvEEE
ZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlvE_
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit15InitPreprocIterEvEUlPPNS3_14InputSplitBase5ChunkEE_NS_9allocatorIS9_EEFbS8_EEE
ZN4dmlc2io16CachedInputSplit15InitPreprocIterEvEUlPPNS0_14InputSplitBase5ChunkEE_
NSt3__110__function6__funcIPFvvENS_9allocatorIS3_EES2_EE
PFvvE
FvvE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11SketchMakerE
N7xgboost4tree9BaseMakerE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_13SortedCSCPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_13SortedCSCPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4data3$_0ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_10SparsePageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_10SparsePageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_10SparsePageEEE
N7xgboost4data16SparsePageFormatINS_10SparsePageEEE
N7xgboost4data3$_0E
NSt3__110__function6__funcIN7xgboost4data3$_1ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_7CSCPageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_7CSCPageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_7CSCPageEEE
N7xgboost4data16SparsePageFormatINS_7CSCPageEEE
N7xgboost4data3$_1E
NSt3__110__function6__funcIN7xgboost4data3$_2ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_13SortedCSCPageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_13SortedCSCPageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_13SortedCSCPageEEE
N7xgboost4data16SparsePageFormatINS_13SortedCSCPageEEE
N7xgboost4data3$_2E
N4dmlc2io23IndexedRecordIOSplitterE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree8ColMakerE
N7xgboost4tree8ColMaker7BuilderE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree12DistColMakerE
N7xgboost4tree12DistColMaker7BuilderE
N7xgboost4tree3$_1E
N4dmlc12SerializableE
N7xgboost7LearnerE
N7xgboost11LearnerImplE
N4dmlc9parameter10FieldEntryIjEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIjEEjEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIjEEjEE
N4dmlc9parameter10FieldEntryIN7xgboost13DataSplitModeEEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj20SoftmaxMultiClassObjE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj3$_1E
NSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_11EvalRowRMSEEEE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_12EvalRowRMSLEEEE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost6metric3$_2ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_10EvalRowMAEEEE
N7xgboost6metric3$_2E
NSt3__110__function6__funcIN7xgboost6metric3$_3ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_14EvalRowLogLossEEE
N7xgboost6metric3$_3E
NSt3__110__function6__funcIN7xgboost6metric3$_4ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_20EvalPoissonNegLogLikEEE
N7xgboost6metric3$_4E
NSt3__110__function6__funcIN7xgboost6metric3$_5ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_17EvalGammaDevianceEEE
N7xgboost6metric3$_5E
NSt3__110__function6__funcIN7xgboost6metric3$_6ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_16EvalGammaNLogLikEEE
N7xgboost6metric3$_6E
NSt3__110__function6__funcIN7xgboost6metric3$_7ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_9EvalErrorEEE
N7xgboost6metric3$_7E
NSt3__110__function6__funcIN7xgboost6metric3$_8ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_18EvalTweedieNLogLikEEE
N7xgboost6metric3$_8E
.sorted.col.pageN7xgboost4data17SparsePageDMatrixE
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_10SparsePageEEES3_EE
N7xgboost17BatchIteratorImplINS_10SparsePageEEE
N7xgboost4data16SparsePageSourceINS_7CSCPageEEE
N7xgboost10DataSourceINS_7CSCPageEEE
N4dmlc8DataIterIN7xgboost7CSCPageEEE
N4dmlc12ThreadedIterIN7xgboost7CSCPageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_7CSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost7CSCPageEEEE
ZN7xgboost4data16SparsePageSourceINS_7CSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_7CSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_7CSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_7CSCPageEEES3_EE
N7xgboost17BatchIteratorImplINS_7CSCPageEEE
N7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEE
N7xgboost10DataSourceINS_13SortedCSCPageEEE
N4dmlc8DataIterIN7xgboost13SortedCSCPageEEE
N4dmlc12ThreadedIterIN7xgboost13SortedCSCPageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_13SortedCSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost13SortedCSCPageEEEE
ZN7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_13SortedCSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_13SortedCSCPageEEES3_EE
N7xgboost17BatchIteratorImplINS_13SortedCSCPageEEE
N7xgboost4data23SparseBatchIteratorImplINS0_17EllpackPageSourceENS_11EllpackPageEEE
N7xgboost17BatchIteratorImplINS_11EllpackPageEEE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_11EllpackPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_11EllpackPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
N7xgboost6common16PeekableInStreamE
N7xgboost6common15FixedSizeStreamE
N7xgboost4data13SimpleDMatrixE
N7xgboost4data23SimpleBatchIteratorImplINS_10SparsePageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_7CSCPageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_13SortedCSCPageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_11EllpackPageEEE
N7xgboost4data12DenseAdapterE
N7xgboost4data6detail19SingleBatchDataIterINS0_17DenseAdapterBatchEEE
N4dmlc8DataIterIN7xgboost4data17DenseAdapterBatchEEE
NSt3__120__shared_ptr_pointerIPN7xgboost7DMatrixENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost7DMatrixEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11TreeSyncherE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11CQHistMakerE
N7xgboost4tree9HistMakerE
NSt3__110__function6__funcIZN7xgboost4tree11CQHistMaker10CreateHistERKNS_6vectorINS2_6detail20GradientPairInternalIfEENS_9allocatorIS8_EEEEPNS2_7DMatrixERKNS5_IjNS9_IjEEEERKNS2_7RegTreeEEUlvE_NS9_ISN_EEFvvEEE
ZN7xgboost4tree11CQHistMaker10CreateHistERKNSt3__16vectorINS_6detail20GradientPairInternalIfEENS2_9allocatorIS6_EEEEPNS_7DMatrixERKNS3_IjNS7_IjEEEERKNS_7RegTreeEEUlvE_
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree23GlobalProposalHistMakerE
N7xgboost4tree3$_1E
N7xgboost7RegTreeE
N4dmlc9parameter10FieldEntryINSt3__16vectorIiNS2_9allocatorIiEEEEEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryINSt3__16vectorIiNS3_9allocatorIiEEEEEES7_EE
N4dmlc9parameter10FieldEntryIdEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIdEEdEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIdEEdEE
NSt3__110__function6__funcIN7xgboost3$_0ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
NSt3__110__function6__baseIFPN7xgboost13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEbEEE
N7xgboost13TextGeneratorE
N7xgboost13TreeGeneratorE
N7xgboost3$_0E
NSt3__110__function6__funcIN7xgboost3$_1ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
N7xgboost13JsonGeneratorE
N7xgboost3$_1E
NSt3__110__function6__funcIN7xgboost3$_2ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
N7xgboost17GraphvizGeneratorE
N7xgboost3$_2E
N7xgboost3gbm11GBTreeModelE
N5rabit6engine13AllreduceBaseE
N5rabit6engine7IEngineE
cpu_predictor
Make predictions using CPU.
basic_string
vector
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/predictor/cpu_predictor.cc
Check failed: cache_
%02d:%02d:%02d
Stack trace:
  [bt] (
DMLC_LOG_STACK_TRACE_DEPTH
Check failed: 
model.learner_model_param_->num_output_group != 0
out_preds->Size() == n
Ignoring the base margin, since it has incorrect length. 
The base margin must be an array of length 
[num_class] * [number of data points], i.e. 
[number of data points], i.e. 
Instead, all data points will use 
base_score = 
 vs. 
model.param.size_leaf_vector == 0
size_leaf_vector is enforced to 0 so far
preds.size() == p_fmat->Info().num_row_ * num_group
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/data.h
Check failed: impl_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/span.h
Check failed: _ptr || _count == 0
Check failed: _idx < size()
ngroup != 0
ncolumns != 0
AMS metric for higgs.
Area under curve for both classification and rank.
aucpr
Area under PR curve for both classification and rank.
precision@k for rank.
ndcg
ndcg@k for rank.
map@k for rank.
cox-nloglik
Negative log partial likelihood of Cox proportioanl hazards model.
vector
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/rank_metric.cc
Check failed: param != nullptr
AMS must be in format ams@k
ams@
Check failed: !distributed
metric AMS do not support distributed evaluation
best-ams-ratio=
info.labels_.Size() != 0U
label set cannot be empty
preds.Size() == info.labels_.Size()
label size predict size not match
gptr.back() == info.labels_.Size()
EvalAuc: group structure must match number of prediction
dat[1] > 0.0f
AUC: the dataset only contains pos or neg samples
EvalAucPR: group structure must match number of prediction
Check failed: !auc_error
AUC-PR: error in calculation
AUC-PR: the dataset only contains pos or neg samples
dat[0] <= dat[1]
AUC-PR: AUC > 1.0
%u[-]?
gptr.size() != 0U
must specify group when constructing rank file
gptr.back() == preds.Size()
EvalRanklist: group structure must match number of prediction
Cox metric does not support distributed evaluation
RegLossParam
Regression with squared error.
Regression with root mean squared logarithmic error.
Logistic regression for probability regression task.
Logistic regression for binary classification task.
Logistic regression for classification, output score before logistic transformation.
reg:linear
PoissonRegressionParam
count:poisson
Possion regression for count data.
survival:cox
Cox regression for censored survival data (negative labels are considered censored).
reg:gamma
Gamma regression for severity data.
TweedieRegressionParam
reg:tweedie
Tweedie regression for insurance data.
reg:squarederror
reg:squaredlogerror
reg:logistic
binary:logistic
binary:logitraw
scale_pos_weight
Scale the weight of positive examples by this factor
Invalid Parameter format for 
 expect 
 but value='
Required parameter 
 of 
 is not presented
Out of range value for 
, value='
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./parameter.h
pos <= value.length()
Some trailing characters could not be parsed: '
Out of range value
No conversion could be performed
infinity
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./strtonum.h
*p == ')'
Invalid NAN literal
value 
 for Parameter 
 exceed bound [
 should be greater equal to 
 should be smaller equal to 
 optional, default=
, required
float
key 
 has already been registered in 
reg_loss_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/json.h
Invalid cast, from 
 to 
Cannot find argument '
', Possible Arguments:
----------------
    
name
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/regression_obj.cu
Label set is empty.
labels are not correctly provided
preds.size=
, label.size=
info.weights_.Size() == ndata
Number of weights should be equal to number of data points.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/../common/transform.h
Not part of device code. WITH_CUDA: 
rmse
label must be greater than -1 for rmsle so that log(label + 1) can be valid.
rmsle
label must be in [0,1] for logistic regression
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/./regression_loss.h
Check failed: base_score > 0.0f && base_score < 1.0f
base_score must be in (0,1) for logistic loss, got: 
error
reg:linear is now deprecated in favor of reg:squarederror.
max_delta_step
Maximum delta step we allow each weight estimation to be. This parameter is required for possion regression.
poisson_regression_param
PoissonRegression: label must be nonnegative
poisson-nloglik
Check failed: last_abs_y <= abs_y
CoxRegression: labels must be in sorted order, 
MetaInfo::LabelArgsort failed!
GammaRegression: label must be nonnegative
gamma-nloglik
tweedie_variance_power
Tweedie variance power.  Must be between in range [1, 2).
tweedie_regression_param
tweedie-nloglik@
TweedieRegression: label must be nonnegative
refresh
Refresher that refreshes the weight and statistics according to data.
train_param
map::at:  key not found
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_refresh.cc
batch.Size() < std::numeric_limits<unsigned>::max()
rank
statistic
count
elapsed
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/timer.cc
Timer for 
 did not get stopped properly.
 calls @ 
======== Monitor: 
 ========
From rank: 
LambdaRankParam
Pairwise rank objective.
LambdaRank with NDCG as objective.
LambdaRank with MAP as objective.
rank:pairwise
rank:ndcg
rank:map
num_pairsample
Number of pair generated for each instance.
fix_list_weight
Normalize the weight of each list by this value, if equals 0, no effect will happen
lambda_rank_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/rank_obj.cu
Check failed: gptr.size() != 0 && gptr.back() == info.labels_.Size()
group structure not consistent with #rows
Computing 
 gradients on CPU.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/local_filesys.cc
LocalFileSystem.GetPathInfo: detected symlink 
 error: 
LocalFileSystem.GetPathInfo: 
LocalFileSystem.ListDirectory 
stdin
stdout
file://
Check failed: allow_null
 LocalFileSystem::Open "
Check failed: std::fwrite(ptr, 1, size, fp_) == size
FileStream.Write incomplete
Check failed: !std::fseek(fp_, static_cast<long>(pos), SEEK_SET)
ConsoleLoggerParam
WARNING: 
DEBUG: 
INFO: 
silent
Do not print information during training.
verbosity
Flag to print out detailed breakdown of runtime.
debug_verbose
true
false
boolean
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/parameter.h
Invalid Input: '
', valid values are: 
optional, default=
enum_back_map_.count(value) != 0U
Value not found in enum declared
 has not been registered in 
Alias 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/ellpack_page_source.cc
Internal Error: XGBoost is not compiled with CUDA but EllpackPageSource is required
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/input_split_base.cc
Check failed: files_[i].size % align_bytes == 0
file do not align by 
 bytes
Check failed: offset_end_ >file_offset_[file_ptr_end_]
Check failed: file_ptr_end_ < files_.size()
 bad regex 
This could due to compiler version, g++-4.9 is needed
files_.size() != 0U
Cannot find any files that matches the URI pattern 
curr=
,begin=
,end=
,fileptr=
,fileoffset=
offset[
file offset not calculated correctly
prune
Pruner that prune the tree according to statistics.
vector
sync
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_prune.cc
tree pruning end, 
 extra nodes, 
 pruned nodes, max_depth=
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/tree_model.h
Check failed: nodes_[nodes_[rid].LeftChild() ].IsLeaf()
Check failed: nodes_[nodes_[rid].RightChild()].IsLeaf()
nid >= 1
CoordinateParam
coord_descent
Update linear model according to coordinate descent algorithm.
top_k
The number of top features to select in 'thrifty' feature_selector. The value of zero means using all the features.
CoordinateUpdater
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/coordinate_common.h
unknown coordinate selector: 
UpdateFeature
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/line_split.cc
Check failed: begin != end
Objective candidate: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/objective.cc
Unknown objective function: `
merror
Multiclass classification error.
mlogloss
Multiclass negative loglikelihood.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/multiclass_metric.cu
Check failed: preds.Size() % info.labels_.Size() == 0
label and prediction size not match
nclass >= 1U
mlogloss and merror are only used for multi-class classification,
 use logloss for binary classification
Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class)
MultiClassEvaluation: label must be in [0, num_class),
 num_class=
 but found 
 in label
the rabit has not been initialized
cannot initialize reduce handle twice
must intialize handle to call AllReduce
%s, shutting down process
%s, rabit is configured to keep process running
AssertError:%s, shutting down process
AssertError:%s, rabit is configured to keep process running
unique_lock::unlock: not locked
binary:hinge
Hinge loss. Expects labels to be in [0,1f]
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/hinge.cu
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/predictor/predictor.cc
Unknown predictor type 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/split_evaluator.cc
Unknown SplitEvaluator 
elastic_net
Use an elastic net regulariser
monotonic
Enforces that the tree is monotonically increasing/decreasing w.r.t. specified features
ElasticNet does not accept an inner SplitEvaluator
Check failed: r->params_
MonotonicConstraint must be given an inner evaluator
Check failed: c->params_
Check failed: !std::isnan(mid)
Check failed: nodeid < upper_.size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/tree_updater.cc
Unknown tree updater 
HistogramCuts
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/hist_util.cc
Building quantile cut on a sparse dataset.
Building quantile cut on a dense dataset or distributed environment.
Total number of hist bins: 
end_col >= beg_col
Build
page.Size() <= dmat->Info().num_col_
Load balance
SingleThreadBuild: 
Concat
nthread == omp_get_num_threads()
Init
summary_array.size() == in_sketchs->size()
p_cuts_->cut_values_.size() <= std::numeric_limits<uint32_t>::max()
cut_size > p_cuts_->cut_ptrs_.back()
cut.Values().size() > 0U
ibegin + inst.size() == iend
sibling.size() == size
parent.size() == size
SparseCuts
DenseCuts
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/./hist_util.h
Row 
 does not lie in any group!
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/./quantile.h
invalid init parameter
Check failed: nlevel <= limit_size * eps
Check failed: index_ != span_->size()
Check failed: index_ < span_->size()
mingap=
, maxgap=
, wgap=
Check failed: size <= sa.size + sb.size
bug in combine
 check quantile stats, nbig=
, n=
 srcsize=
, maxsize=
, range=
, chunk=
Check failed: nbig < n
quantile: too many large chunk
] rmin=
, rmax=
, wmin=
, v=
write position exceed fixed buffer size
fi.Read(&this->size, sizeof(this->size)) == sizeof(this->size)
fi.Read(this->data, this->size * sizeof(Entry)) == this->size * sizeof(Entry)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/metric.cc
Unknown metric function 
read can not have position excceed buffer length
too large type_nbytes=%lu, buffer_size=%lu
GetSockError
Socket %s Error:%s
Poll
Socket::Close double close the socket or close without create
ReadToRingBuffer: buffer not allocated
ReadToRingBuffer: max_size_read check
Allreduce: boundary check
NULL
thread constructor failed
SyncHistograms
BuildLocalHistograms
BuildNodeStats
Update
UpdatePredictionCache
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_quantile_hist.cc
out_preds.size() > 0U
Check failed: (*p_last_tree_)[nid].IsLeaf()
Check failed: (param_.max_depth > 0 || param_.max_leaves > 0)
max_depth or max_leaves cannot be both 0 (unlimited); 
at least one should be a positive quantity.
Check failed: param_.max_depth > 0
max_depth cannot be 0 (unlimited) 
when grow_policy is depthwise.
InitData
min_nbins_per_feature > 0U
EvaluateSplit
ApplySplit
upper_bound < static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
InitNewNode
grow_fast_histmaker
(Deprecated, use grow_quantile_histmaker instead.) Grow tree using quantized histogram.
grow_quantile_histmaker
Grow tree using quantized histogram.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/column_matrix.h
gmat.cut.Ptrs()[fid + 1] - gmat.cut.Ptrs()[fid] <= max_val
Quantile::Builder
seed
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/hist_util.h
row_ptr_[nid] != kMax
row_ptr_[nid] == kMax
SubtractionTrick
BuildHist
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/row_set.h
Check failed: e.begin != nullptr
access element that is not in the set
elem_of_each_node_.size() == 0U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/random.h
features.size() > 0
Check failed: node.IsLeaf()
param.num_nodes < std::numeric_limits<int>::max()
number of nodes in the tree exceed 2^31
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/threading_utils.h
begin < end
cut_ptr[fid] <= static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
cut_ptr[fid + 1] <= static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
i < first_dimension_.size()
i < ranges_.size()
grow_fast_histmaker is deprecated, 
use grow_quantile_histmaker instead.
weights
DeprecatedGBLinearModelParam
GBLinearTrainParam
gblinear
Linear booster, implement generalized linear model.
updater
shotgun
Update algorithm for linear model. One of shotgun/coord_descent
tolerance
Stop if largest weight update is smaller than this number.
max_row_perbatch
Maximum rows per batch.
string
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gblinear.cc
get<String>(in["name"]) == "gblinear"
model
GBLinear
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/gbm.h
XGBoost version not compiled with GPU support.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gblinear_model.h
fi->Read(&param, sizeof(param)) == sizeof(param)
DoBoost
PredictBatchInternal
PredictBatch
ntree_limit == 0U
GBLinear::Predict ntrees is only valid for gbtree predictor
gblinear does not support prediction of leaf index
GBLinear::PredictContribution: ntrees is only valid for gbtree predictor
json
  { "bias": [
      
    ],
    "weight": [
    ]
bias:
weight:
gblinear_train_param
Update linear model according to shotgun coordinate descent algorithm.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/updater_shotgun.cc
Unsupported feature selector for shotgun updater.
Supported options are: {cyclic, shuffle}
GBTree
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree.cc
DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using`tree_method` parameter instead.
Check failed: this->configured_
Check failed: tparam_.GetInitialised()
Using updaters: 
grow_histmaker,prune
Tree method is automatically selected to be 'approx' for distributed training.
Tree method is automatically set to 'approx' since external-memory data matrix is used.
Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.
Using tree method: 
grow_colmaker,prune
Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.
grow_gpu_hist
Unknown tree_method (
) detected
BoostNewTrees
in_gpair->Size() % ngroup == 0U
must have exactly ngroup*nrow gpairs
ups.size() == updaters_.size()
Internal Error: 
 mismatched updater sequence.
Specified updaters: 
Actual updaters: 
model_.trees.size() < model_.trees_to_update.size()
CommitModel
Check failed: configured_
gbtree
get<String>(in["name"]) == "gbtree"
gbtree_train_param
predictor
auto
tree_method
hist
Loading from a raw memory buffer on CPU only machine.  Change tree_method to hist.
specified_updater
GBTreeModelParam
GBTreeTrainParam
DartTrainParam
Tree booster, gradient boosted trees.
dart
Tree booster, dart.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree.h
Check failed: cpu_predictor_
distcol
num_trees
Number of features used for training and prediction.
size_leaf_vector
Reserved option for vector tree.
num_parallel_tree
Number of parallel trees constructed during each iteration. This option is used to support boosted random forest.
updater_seq
Tree updater sequence.
process_type
default
update
Whether to run the normal boosting process that creates new trees, or to update the trees in an existing model.
gpu_predictor
Predictor algorithm type
approx
exact
gpu_hist
Choice of tree construction method.
Enum 
 exisit!
Enums: 
sample_type
uniform
weighted
Different types of sampling algorithm.
normalize_type
tree
forest
Different types of normalization algorithm.
rate_drop
Fraction of trees to drop during the dropout.
one_drop
Whether at least one tree should always be dropped during the dropout.
skip_drop
Probability of skipping the dropout during a boosting iteration.
learning_rate
Learning rate(step size) of update.
get<String>(in["name"]) == "dart"
weight_drop
out_preds->size() == n
num_group == model_.learner_model_param_->num_output_group
model_.param.size_leaf_vector == 0
dart_train_param
drop 
 trees, 
weight = 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbm.cc
Unknown gbm type 
tmagic == kMagic
invalid format, magic number mismatch
vector
LibSVMParserParam
LibFMParserParam
CSVParserParam
libsvm
libfm
format
File format
indexing_mode
If >0, treat all feature indices as 1-based. If =0, treat all feature indices as 0-based. If <0, use heuristic to automatically detect mode of indexing. See https://en.wikipedia.org/wiki/Array_data_type#Index_origin for more details on indexing modes.
If >0, treat all field and feature indices as 1-based. If =0, treat all field and feature indices as 0-based. If <0, use heuristic to automatically detect mode of indexing. See https://en.wikipedia.org/wiki/Array_data_type#Index_origin for more details on indexing modes.
File format.
label_column
Column index (0-based) that will put into label.
delimiter
Delimiter used in the csv file.
weight_column
Column index that will put into instance weights.
.split
.part
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/uri_spec.h
name_cache.size() == 1U
only one `#` is allowed in file path for cachefile specification
Check failed: std::getline(is, kv.first, '=')
Invalid uri argument format
 for key in arg 
Check failed: std::getline(is, kv.second)
 for value in arg 
name_args.size() == 1U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/threadediter.h
Check failed: !producer_sig_processed_.load(std::memory_order_acquire)
Check failed: producer_sig_.load(std::memory_order_acquire) == kProduce
Make sure you call BeforeFirst not inconcurrent with Next!
Check failed: produce_end_.load(std::memory_order_acquire)
Check failed: out_data_ != NULL
Calling Value at beginning or end?
No thread
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./row_block.h
label.size() + 1 == offset.size()
offset.back() == index.size()
Check failed: offset.back() == value.size() || value.size() == 0
text
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./libsvm_parser.h
param_.format == "libsvm"
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./text_parser.h
chunk.size != 0U
qid:
Check failed: out->label.size() + 1 == out->offset.size()
sign == true
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/parser.h
cannot call ParseNext
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/libfm_parser.h
param_.format == "libfm"
Check failed: out->field.size() == out->index.size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/csv_parser.h
param_.format == "csv"
Check failed: param_.label_column != param_.weight_column || param_.label_column < 0
Must have distinct columns for labels and instance weights
Delimiter '
' is not found in the line. 
Expected '
' as the delimiter to separate fields.
Check failed: out->weight.size() == 0 || out->weight.size() + 1 == out->offset.size()
null
\u%04x
String
Number
Object
Array
Boolean
Null
Integer
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/json.cc
Object of type 
 can not be indexed by Integer.
 can not be indexed by string.
  Please try obtaining std::string first.
Unknown construct
, around character: 
Unknown escape
Expecting null value "null"
ch != -1
cursor_.Pos(): 
raw_str_.size():
exp > (kExpMax - digit) / 10
Overflow
Expecting boolean value "true".
Expecting boolean value "false".
beg <= size_
Expecting: "
", got: "
Failed to set locale: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/recordio_split.cc
Check failed: fi->Read(&lrec, sizeof(lrec)) != 0
invalid record io format
(reinterpret_cast<size_t>(begin) & 3UL) == 0U
(reinterpret_cast<size_t>(end) & 3UL) == 0U
Check failed: p >= pbegin + 2
Check failed: chunk->begin + 2 * sizeof(uint32_t) <= chunk->end
Invalid RecordIO Format
(reinterpret_cast<size_t>(chunk->begin) & 3UL) == 0U
(reinterpret_cast<size_t>(chunk->end) & 3UL) == 0U
Check failed: chunk->begin <= chunk->end
Check failed: cflag == 1U
Check failed: p[0] == RecordIOWriter::kMagic
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/data.cc
major == 1
Binary DMatrix generated by XGBoost: 
 is no longer supported. 
Please process and save your data in current version: 
 again.
Check failed: fi->Read(&num_row_, sizeof(num_row_)) == sizeof(num_row_)
MetaInfo: invalid format
Check failed: fi->Read(&num_col_, sizeof(num_col_)) == sizeof(num_col_)
Check failed: fi->Read(&num_nonzero_, sizeof(num_nonzero_)) == sizeof(num_nonzero_)
Check failed: fi->Read(&labels_.HostVector())
Check failed: fi->Read(&group_ptr_)
Check failed: fi->Read(&weights_.HostVector())
Check failed: fi->Read(&base_margin_.HostVector())
label
Unknown data type
weight
base_margin
group
Unknown metainfo: 
self_offset.size() == other_offset.size()
self_data.size(): 
other_data.size(): 
beg <= data.size()
ptr < offset.size()
.row.page
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/./sparse_page_source.h
cache_shards.size() != 0U
Writing 
 in 
 MB/s, 
 written
SparsePageSource::CreateRowPage Finished writing to 
.fmt-
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_writer.h
name_shards.size() == format_shards.size()
SparsePageWriter Finished writing to 
Unknown format type 
Check failed: *out_page == nullptr
Check failed: qrecycle_.Pop(out_page)
key >= builder_base_row_offset
finfo->Read(&tmagic, sizeof(tmagic)) == sizeof(tmagic)
Check failed: fi->Read(&format)
Invalid page format
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io.cc
Please compile with DMLC_USE_HDFS=1 to use hdfs
Please compile with DMLC_USE_S3=1 to use S3
Please compile with DMLC_USE_AZURE=1 to use Azure
unknown filesystem protocol 
Check failed: part < nsplit
invalid input parameter for InputSplit::Create
indexed_recordio
need to pass index file to use IndexedRecordIO
recordio
unknown input split type 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/single_file_split.h
Check failed: fp_ != NULL
SingleFileSplit: fail to open 
Check failed: part_index == 0 && num_parts == 1
InputSplit do not support write
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/cached_input_split.h
Check failed: nread == sizeof(size)
 has invalid cache file format
Check failed: fi_->Read(p->begin, size) == size
BeforeFirst is not supported
Check failed: this->InitCachedIter()
Failed to initialize CachedIter
ResetPartition is not supported in CachedInputSplit
grow_skmaker
Approximate sketching maker.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/./updater_basemaker-inl.h
sketch->temp.size < max_size
invalid maximum size max_size=
, stemp.size
INFO: rmax=
, sum_total=
, naxt_goal=
, size=
sketch->temp.size <= max_size
Finalize: invalid maximum size, max_size=
, stemp.size=
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/param.h
ret > 0U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_skmaker.cc
qexpand_.size() != 0U
node2workindex_[nid] == static_cast<int>(wid)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/linear_updater.cc
Unknown linear updater 
LinearTrainParam
Learning rate of each update.
reg_lambda
L2 regularization on weights.
reg_alpha
L1 regularization on weights.
feature_selector
cyclic
shuffle
thrifty
greedy
random
Feature selection or ordering method.
lambda
alpha
Raw binary data format.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_raw_format.cc
page->offset.Size() != 0U
Invalid SparsePage file
fi->Read(dmlc::BeginPtr(data_vec), (page->data).Size() * sizeof(Entry)) == (page->data).Size() * sizeof(Entry)
fid + 1 < disk_offset_.size()
disk_offset_[fid] > curr_offset
fi->Read(dmlc::BeginPtr(data_vec) + offset_vec[i], size_to_read * sizeof(Entry)) == size_to_read * sizeof(Entry)
Check failed: page.offset.Size() != 0 && offset_vec[0] == 0
offset_vec.back() == page.data.Size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/indexed_recordio_split.cc
expanded_list.size() == 1ul
IndexedRecordIOSplitter does not support multiple index files
ColMakerTrainParam
grow_colmaker
Grow tree with parallelization over columns.
Distributed column split version of tree maker.
opt_dense_col
EXP Param: speed optimization for dense column.
colmaker_train_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_colmaker.cc
feat_set.size() == num_features
Check failed: param_.cache_opt
Support for `cache_opt' is removed in 1.0.0
fmat.Info().num_row_ == position_.size()
ridx < position_.size()
ridx exceed bound 
ridx=
 pos=
trees.size() == 1U
DistColMaker: only support one tree at a time
Check failed: !tree[nid].IsLeaf()
inconsistent reduce information
nid >= 0
LearnerModelParamLegacy
LearnerTrainParam
GenericParameter
gpu_id
eval_metric
CONFIG-offset:
num_round
Learner
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/learner.cc
Check failed: IsA<Object>(in)
learner
learner_model_param
objective
gradient_booster
booster
attributes
base_score
num_feature
num_class
Check failed: !this->need_configuration_
Call Configure before saving model.
Configure
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/generic_parameters.h
n_gpus: 
n_gpus
Check failed: matrix != nullptr
num_col <= static_cast<uint64_t>(std::numeric_limits<unsigned>::max())
Unfortunately, XGBoost does not support data matrices with 
 features or greater
mparam_.num_feature != 0
0 feature is supplied.  Are you using raw Booster interface?
num_output_group
multi:softmax
_param
Parameters: { 
 } might not be used.
  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.
UpdateOneIter
PredictRaw
Predictions
GetGradient
Gradients
Check failed: tparam_.dsplit != DataSplitMode::kAuto
Precondition violated; dsplit cannot be 'auto' in distributed mode
Column-wise data split is currently not supported.
Check failed: weights.Size() == info.group_ptr_.size() - 1
weights size: 
groups size: 
num rows: 
Number of weights should be equal to number of groups in ranking task.
Check failed: gbm_ != nullptr
Predict must happen after Load or configuration
BoostOneIter
EvalOneIter
multiple_predictions <= 1
Perform one kind of prediction at a time.
bs64
header != "bs64"
Base64 format is no longer supported in brick.
fp.Read(&header[0], 4) == 4U
fi->Read(&mparam_, sizeof(mparam_)) == sizeof(mparam_)
BoostLearner: wrong model format
fi->Read(&len, sizeof(len)) == sizeof(len)
fi->Read(&gap, sizeof(gap)) == sizeof(gap)
fi->Read(&tparam_.objective[0], len) == len
Check failed: fi->Read(&tparam_.booster)
SAVED_PARAM_
count_poisson_max_delta_step
rabit_bootstrap_cache
The model hasn't been built yet.  Are you using raw Booster interface?
learner_train_param
metrics
generic_param
Model
Config
fp.Read(&header[0], header.size()) == serialisation_header_.size()
header == serialisation_header_
fp.Read(&json_offset, sizeof(json_offset)) == sizeof(json_offset)
json_offset > 0
Global bias of the model.
Number of features in training data, this parameter will be automatically detected by learner.
Number of class option for multi-class classifier.  By default equals 0 and corresponds to binary classifier.
int (non-negative)
dsplit
Data split mode for distributed training.
disable_default_eval_metric
flag to disable default metric. Set to >0 to disable
Gradient booster used for training.
Objective function used for obtaining gradient.
Random number seed during training.
random_state
seed_per_iteration
Seed PRNG determnisticly via iterator number, this option will be switched on automatically on distributed mode.
nthread
Number of threads to use.
n_jobs
The primary GPU device ordinal.
gpu_page_size
GPU page size when running in external memory mode.
enable_experimental_json_serialization
Enable using JSON for memory serialization (Python Pickle, rabit checkpoints etc.).
validate_parameters
Enable to check whether parameters are used or not.
Deprecated. Single process multi-GPU training is no longer supported.
Please switch to distributed training with one process per GPU.
This can be done using Dask or Spark.  See documentation for details.
SoftmaxMultiClassParam
Softmax for multi-class classification, output class index.
multi:softprob
Softmax for multi-class classification, output probability distribution.
Number of output class in the multi-class classification.
softmax_multiclass_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/multiclass_obj.cu
Check failed: preds.Size() == (static_cast<size_t>(param_.num_class) * info.labels_.Size())
SoftmaxMultiClassObj: label size and pred size does not match.
label.Size() * num_class: 
num_class: 
preds.Size(): 
SoftmaxMultiClassObj: label must be in [0, num_class).
Check failed: _offset < size() || size() == 0
Check failed: (_count == dynamic_extent) || (_offset + _count <= size())
Check failed: (index_ + n) <= span_->size()
Check failed: span_ == rhs.span_
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/host_device_vector.cc
Check failed: 
Size() == other.Size()
vector
Rooted mean square error.
Rooted mean square log error.
Mean absolute error.
logloss
Negative loglikelihood for logistic regression.
Negative loglikelihood for poisson regression.
gamma-deviance
Residual deviance for gamma regression.
Negative log-likelihood for gamma regression.
Binary classification error.
tweedie-nloglik
tweedie-nloglik@rho for tweedie regression.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/elementwise_metric.cu
label set is empty
label and prediction size not match, 
hint: use merror or mlogloss for multi-class classification
sscanf(param, "%f", &threshold_) == 1
unable to parse the threshold value for the error metric
tweedie-nloglik must be in format tweedie-nloglik@rho
Check failed: rho_ < 2 && rho_ >= 1
tweedie variance power must be in interval [1, 2)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_dmatrix.cc
Check failed: cast
.col.page
.sorted.col.page
param.gpu_id >= 0
param.max_bin >= 2
Check failed: source_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_source.h
Unknown page type: 
Writing to 
SparsePageSource: Finished writing to 
version
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/version.cc
Invaid version format in loaded JSON object: 
Incorrect version format found in binary file.  Binary file from XGBoost < 1.0.0 is no longer supported. Please generate it again.
version:
fi->Read(&read[0], verstr.size()) == verstr.size()
fi->Read(&major, sizeof(major)) == sizeof(major)
fi->Read(&minor, sizeof(major)) == sizeof(minor)
fi->Read(&patch, sizeof(major)) == sizeof(patch)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/io.cc
Opening 
 failed: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/io.h
Not implemented
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/simple_dmatrix.cc
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/./simple_batch_iterator.h
Check failed: page_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/constraints.cc
Failed to parse feature interaction constraint:
With error:
newsize != 0
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./json.h
ch == '['
Error at
, Expect '{' but get '
 Line 
, around ^`
ch == ','
, JSON array expect ']' or ','. Get '
' instead
Check failed: !is_->fail()
, Expect number
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/c_api/c_api.cc
DMatrix/Booster has not been intialized or has already been disposed.
str.size() > 2
str[0] == '{'
Syncher that synchronize the tree in all distributed nodes.
grow_local_histmaker
Tree constructor that uses approximate histogram construction.
grow_histmaker
Tree constructor that uses approximate global of histogram construction.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_histmaker.cc
max_depth must be larger than 0
summary_array_.size() == sketchs_.size()
offset == -2
this->wspace_.rptr.size() == (fset.size() + 1) * this->qexpand_.size() + 1
fid * 2 + 1 < fminmax_.size()
FeatHelper fid exceed query bound 
Check failed: tree[nid].IsLeaf()
fid * 2 < fminmax_.size()
, hist.size=
hist[
, hist.last=
istart != hist.size
this->qexpand_.size() == 1U
this->wspace_.rptr.back() == this->wspace_.cut.size()
TreeParam
TrainParam
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/tree_model.cc
Unknown Model Builder:
Dump text representation of tree
Dump json representation of tree
GraphvizParam
Dump graphviz representation of tree
fi->Read(&param, sizeof(TreeParam)) == sizeof(TreeParam)
param.num_nodes != 0
fi->Read(dmlc::BeginPtr(nodes_), sizeof(Node) * nodes_.size()) == sizeof(Node) * nodes_.size()
fi->Read(dmlc::BeginPtr(stats_), sizeof(RTreeNodeStat) * stats_.size()) == sizeof(RTreeNodeStat) * stats_.size()
static_cast<int>(deleted_nodes_.size()) == param.num_deleted
param.num_nodes == static_cast<int>(nodes_.size())
param.num_nodes == static_cast<int>(stats_.size())
param.deprecated_num_roots == 1
tree_param
n_nodes != 0
loss_changes
loss_changes.size() == n_nodes
sum_hessian
sum_hessian.size() == n_nodes
base_weights
base_weights.size() == n_nodes
leaf_child_counts
leaf_child_counts.size() == n_nodes
left_children
lefts.size() == n_nodes
right_children
rights.size() == n_nodes
parents
parents.size() == n_nodes
split_indices
indices.size() == n_nodes
split_conditions
conds.size() == n_nodes
default_left
default_left.size() == n_nodes
static_cast<bst_node_t>(deleted_nodes_.size()) == param.num_deleted
num_nodes
get<String>(out["tree_param"]["num_nodes"]) == std::to_string(param.num_nodes)
this->node_mean_values_.size() > 0U
unique_path[i].pweight == 0
Unique path 
 must have zero weight
vector
Number of features used in tree construction.
Size of leaf vector, reserved for vector tree
min_split_loss
Minimum loss reduction required to make a further partition.
max_depth
Maximum depth of the tree; 0 indicates no limit; a limit is required for depthwise policy
max_leaves
Maximum number of leaves; 0 indicates no limit.
max_bin
if using histogram-based algorithm, maximum number of bins per feature
grow_policy
depthwise
lossguide
Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow depth-wise. 1: favor splitting at nodes with highest loss change. (cf. LightGBM)
min_child_weight
Minimum sum of instance weight(hessian) needed in a child.
L2 regularization on leaf weight
L1 regularization on leaf weight
default_direction
learn
left
right
Default direction choice when encountering a missing value
Maximum delta step we allow each tree's weight estimate to be. If the value is set to 0, it means there is no constraint
subsample
Row subsample ratio of training instance.
colsample_bynode
Subsample ratio of columns, resample on each node (split).
colsample_bylevel
Subsample ratio of columns, resample on each level.
colsample_bytree
Subsample ratio of columns, resample on each tree construction.
sketch_eps
EXP Param: Sketch accuracy of approximate algorithm.
sketch_ratio
EXP Param: Sketch accuracy related parameter of approximate algorithm.
cache_opt
EXP Param: Cache aware optimization.
refresh_leaf
Whether the refresh updater needs to update leaf values.
monotone_constraints
Constraint of variable monotonicity
interaction_constraints
Constraints for interaction representing permitted interactions.The constraints must be specified in the form of a nest list,e.g. [[0, 1], [2, 3, 4]], where each inner list is a group ofindices of features that are allowed to interact with each other.See tutorial for more information
split_evaluator
elastic_net,monotonic
The criteria to use for ranking splits
sparse_threshold
percentage threshold for treating a feature as sparse
enable_feature_grouping
if >0, enable feature grouping to ameliorate work imbalance among worker threads
max_conflict_rate
when grouping features, how many "conflicts" to allow.conflict is when an instance has nonzero values for two or more features.default is 0, meaning features should be strictly complementary.
max_search_group
when grouping features, how much effort to expend to prevent singleton groups. We'll try to insert each feature into existing groups before creating a new group for that feature; to save time, only up to (max_search_group) of existing groups will be considered. If set to zero, ALL existing groups will be examined.
gamma
double
{nid}:[{fname}] yes={yes},no={no}
{nid}
{fname}
{yes}
{no}
pos != std::string::npos
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/feature_map.h
idx < names_.size()
FeatureMap feature index exceed bound
{tabs}{nid}:[{fname}<{cond}] yes={left},no={right},missing={missing}
{tabs}
{cond}
{left}
{right}
{missing}
,gain={loss_chg},cover={sum_hess}
{loss_chg}
{sum_hess}
{tabs}{nid}:[f{fname}<{cond}] yes={left},no={right},missing={missing}
Unknown feature map type.
{tabs}{nid}:leaf={leaf}{stats}
,cover={cover}
{leaf}
{stats}
{cover}
{parent}{stat}
{left}
{right}
{parent}
{stat}
{nodes}
{nodes}
 "nodeid": {nid}, "depth": {depth}, "split": "{fname}", "yes": {yes}, "no": {no}}
{depth}
 "nodeid": {nid}, "depth": {depth}, "split": "{fname}", "split_condition": {cond}, "yes": {left}, "no": {right}, "missing": {missing}
, "gain": {loss_chg}, "cover": {sum_hess}
 "nodeid": {nid}, "depth": {depth}, "split": {fname}, "split_condition": {cond}, "yes": {left}, "no": {right}, "missing": {missing}
{{properties} {stat}, "children": [{left}, {right}
{indent}]}
{properties}
{indent}
{ "nodeid": {nid}, "leaf": {leaf} {stat}}
, "cover": {sum_hess} 
{newline}{indent}{nodes}
{newline}
yes_color
#0000FF
Edge color when meets the node condition.
no_color
#FF0000
Edge color when doesn't meet the node condition.
rankdir
Passed to graphiz via graph_attr.
condition_node_params
Conditional node configuration
leaf_node_params
Leaf node configuration
graph_attrs
Any other extra attributes for graphviz `graph_attr`.
Failed to parse graphviz parameters:
edge
    graph [ {key}="{value}" ]
{key}
{value}
The following parameters for graphviz are not recognized:
ch == '{'
, JSON object expect '}' or ',' '
ch == ':'
, Expect ':' but get '
ch == '\"'
, Expect '"' but get '
unknown string escape \
, Expect '"' but reach end of line 
    {nid} [ label="{fname}{<}{cond}" {params}]
{params}
    {nid} -> {child} [label="{is_missing}" color="{color}"]
{child}
{color}
{is_missing}
yes, missing
    {nid} [ label="leaf={leaf-value}" {params}]
{leaf-value}
{parent}
{left}
{right}
digraph {
    graph [ rankdir={rankdir} ]
{graph_attrs}
{nodes}}
{rankdir}
{graph_attrs}
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/ellpack_page.cc
Internal Error: XGBoost is not compiled with CUDA but EllpackPage is required
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree_model.cc
param.num_trees == static_cast<int32_t>(trees.size())
GBTree: invalid model file
fi->Read(dmlc::BeginPtr(tree_info), sizeof(int32_t) * param.num_trees) == sizeof(int32_t) * param.num_trees
param.num_trees == static_cast<int>(trees.size())
gbtree_model_param
trees
tree_info
worker
rabit_reduce_buffer
256MB
DMLC_TASK_ID
DMLC_ROLE
DMLC_NUM_ATTEMPT
DMLC_TRACKER_URI
DMLC_TRACKER_PORT
DMLC_WORKER_CONNECT_RETRY
DMLC_WORKER_STOP_PROCESS_ON_ERROR
%[^=]=%s
mapred_tip_id
mapreduce_task_id
hadoop_mode is set but cannot find mapred_task_id
rabit_task_id
rabit_hadoop_mode
mapred_task_id
rabit_num_trial
mapred_map_tasks
mapreduce_job_maps
hadoop_mode is set but cannot find mapred_map_tasks
rabit_world_size
Rabit Module currently only work with dmlc worker, quit this program by exit 0
can only call Init once
start
shutdown
failed to shutdown due to %s
print
rabit_tracker_uri
rabit_tracker_port
rabit_reduce_ring_mincount
rabit_reduce_ring_mincount should be greater than 0
invalid value of DMLC_WORKER_STOP_PROCESS_ON_ERROR
rabit_debug
rabit_timeout
rabit_timeout_sec
rabit_timeout_sec should be non negative second
connect to (failed): [%s]
Connect
retry connect to ip(retry time %d): [%s]
ReConnectLink failure 1
ReConnectLink failure 2
sync::Invalid tracker message, init failure
ReConnectLink failure 3
ReConnectLink failure 4
must keep rank to same if the node already have one
ReConnectLink fail to bind the ports specified
ReConnectLink failure 5
ReConnectLink failure 6
ReConnectLink failure 7
ReConnectLink failure 8
ReConnectLink failure 9
ReConnectLink failure 10
ReConnectLink failure 12
ReConnectLink failure 13
ReConnectLink failure, link rank inconsistent
Override a link that is active
ReConnectLink failure 14
ReConnectLink failure 15
ReConnectLink: bad socket
cannot find parent in the link
cannot find prev ring in the link
cannot find next ring in the link
failed in ReconnectLink %s
buffer size inconsistent
must assign buffer_size
Allreduce: size check
Allreduce: boundary error
Broadcast: root should be smaller than world size
need to assume rank structure
write ptr boundary check
[%d] read_ptr boundary check
fail to get host name
error during send SendStr
%lu%c
invalid format for %s
invalid format for %s,shhould be {integer}{unit}, unit can be {B, KB, MB, GB}
Create
cannot obtain address of %s
Does not support IPv6
SendAll
RecvAll
SetKeepAlive
SO_LINGER
0.0.0.0
TryBindHost
error during send RecvStr
Accept
SetNonBlock-1
SetNonBlock-2
Allreduce failed
Broadcast failed
InitAfterException: not implemented
@(#)PROGRAM:XGBoostFramework  PROJECT:CoreML-1
NSt3__110__function6__funcIN7xgboost9predictor3$_0ENS_9allocatorIS4_EEFPNS2_9PredictorEPKNS2_16GenericParameterENS_10shared_ptrINS_13unordered_mapIPNS2_7DMatrixENS2_20PredictionCacheEntryENS_4hashISF_EENS_8equal_toISF_EENS5_INS_4pairIKSF_SG_EEEEEEEEEEE
NSt3__110__function6__baseIFPN7xgboost9PredictorEPKNS2_16GenericParameterENS_10shared_ptrINS_13unordered_mapIPNS2_7DMatrixENS2_20PredictionCacheEntryENS_4hashISB_EENS_8equal_toISB_EENS_9allocatorINS_4pairIKSB_SC_EEEEEEEEEEE
N7xgboost9predictor12CPUPredictorE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_10SparsePageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_10SparsePageEEEE27__shared_ptr_default_deleteIS4_S4_EE
NSt3__114default_deleteIN7xgboost17BatchIteratorImplINS1_10SparsePageEEEEE
N7xgboost9predictor3$_0E
N4dmlc5ErrorE
NSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
NSt3__110__function6__baseIFPN7xgboost6MetricEPKcEEE
N7xgboost6metric7EvalAMSE
N7xgboost6MetricE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalAucE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost6metric3$_2ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric9EvalAucPRE
N7xgboost6metric3$_2E
NSt3__110__function6__funcIN7xgboost6metric3$_3ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalPrecisionE
N7xgboost6metric12EvalRankListE
N7xgboost6metric3$_3E
NSt3__110__function6__funcIN7xgboost6metric3$_4ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric8EvalNDCGE
N7xgboost6metric3$_4E
NSt3__110__function6__funcIN7xgboost6metric3$_5ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalMAPE
N7xgboost6metric3$_5E
NSt3__110__function6__funcIN7xgboost6metric3$_6ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric7EvalCoxE
N7xgboost6metric3$_6E
$N4dmlc9parameter10FieldEntryIfEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIfEEfEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIfEEfEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
NSt3__110__function6__baseIFPN7xgboost11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_16LinearSquareLossEEE
N7xgboost11ObjFunctionE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_15SquaredLogErrorEEE
N7xgboost3obj3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_2ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_18LogisticRegressionEEE
N7xgboost3obj3$_2E
NSt3__110__function6__funcIN7xgboost3obj3$_3ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_22LogisticClassificationEEE
N7xgboost3obj3$_3E
NSt3__110__function6__funcIN7xgboost3obj3$_4ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj10RegLossObjINS0_11LogisticRawEEE
N7xgboost3obj3$_4E
NSt3__110__function6__funcIN7xgboost3obj3$_5ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj3$_5E
NSt3__110__function6__funcIN7xgboost3obj3$_6ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj17PoissonRegressionE
N7xgboost3obj3$_6E
NSt3__110__function6__funcIN7xgboost3obj3$_7ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13CoxRegressionE
N7xgboost3obj3$_7E
NSt3__110__function6__funcIN7xgboost3obj3$_8ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj15GammaRegressionE
N7xgboost3obj3$_8E
NSt3__110__function6__funcIN7xgboost3obj3$_9ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj17TweedieRegressionE
N7xgboost3obj3$_9E
N4dmlc9parameter16FieldAccessEntryE
N7xgboost12ConfigurableE
N7xgboost5ValueE
N4dmlc10ParamErrorE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonStringENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonStringEEE
NSt3__114default_deleteIN7xgboost10JsonStringEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonObjectENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonObjectEEE
NSt3__114default_deleteIN7xgboost10JsonObjectEEE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree13TreeRefresherE
NSt3__110__function6__funcIZN7xgboost4tree13TreeRefresher6UpdateEPNS2_16HostDeviceVectorINS2_6detail20GradientPairInternalIfEEEEPNS2_7DMatrixERKNS_6vectorIPNS2_7RegTreeENS_9allocatorISF_EEEEEUlvE_NSG_ISL_EEFvvEEE
NSt3__110__function6__baseIFvvEEE
ZN7xgboost4tree13TreeRefresher6UpdateEPNS_16HostDeviceVectorINS_6detail20GradientPairInternalIfEEEEPNS_7DMatrixERKNSt3__16vectorIPNS_7RegTreeENSA_9allocatorISD_EEEEEUlvE_
N7xgboost4tree3$_0E
NSt3__117bad_function_callE
NSt3__110__function6__baseIFPN7xgboost11TreeUpdaterEvEEE
N7xgboost11TreeUpdaterE
NSt3__120__shared_ptr_pointerIPN7xgboost11JsonIntegerENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_11JsonIntegerEEE
NSt3__114default_deleteIN7xgboost11JsonIntegerEEE
N4dmlc9parameter10FieldEntryImEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryImEEmEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryImEEmEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_28PairwiseLambdaWeightComputerEEE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_24NDCGLambdaWeightComputerEEE
N7xgboost3obj3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_2ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj13LambdaRankObjINS0_23MAPLambdaWeightComputerEEE
N7xgboost3obj3$_2E
N4dmlc2io15LocalFileSystemE
N4dmlc2io10FileStreamE
N4dmlc10SeekStreamE
N4dmlc6StreamE
N4dmlc9parameter10FieldEntryIbEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIbEEbEE
N4dmlc9parameter10FieldEntryIiEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIiEEiEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIiEEiEE
N7xgboost4data17EllpackPageSourceE
N7xgboost10DataSourceINS_11EllpackPageEEE
N4dmlc8DataIterIN7xgboost11EllpackPageEEE
llff<
9N4dmlc2io14InputSplitBaseE
N4dmlc10InputSplitE
NSt3__111__end_stateIcEE
NSt3__16__nodeIcEE
NSt3__120__shared_ptr_pointerIPNS_13__empty_stateIcEENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrINS_13__empty_stateIcEEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteINS_13__empty_stateIcEEEE
NSt3__113__empty_stateIcEE
NSt3__116__owns_one_stateIcEE
NSt3__115__has_one_stateIcEE
NSt3__120__l_anchor_multilineIcEE
NSt3__120__r_anchor_multilineIcEE
NSt3__115__word_boundaryIcNS_12regex_traitsIcEEEE
NSt3__111__lookaheadIcNS_12regex_traitsIcEEEE
NSt3__123__match_any_but_newlineIcEE
NSt3__118__match_char_icaseIcNS_12regex_traitsIcEEEE
NSt3__120__match_char_collateIcNS_12regex_traitsIcEEEE
NSt3__112__match_charIcEE
NSt3__116__back_ref_icaseIcNS_12regex_traitsIcEEEE
NSt3__118__back_ref_collateIcNS_12regex_traitsIcEEEE
NSt3__110__back_refIcEE
NSt3__120__bracket_expressionIcNS_12regex_traitsIcEEEE
NSt3__128__begin_marked_subexpressionIcEE
NSt3__126__end_marked_subexpressionIcEE
NSt3__16__loopIcEE
NSt3__117__owns_two_statesIcEE
NSt3__117__repeat_one_loopIcEE
NSt3__111__alternateIcEE
NSt3__121__empty_non_own_stateIcEE
NSt3__111__match_anyIcEE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree10TreePrunerE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost6linear3$_0ENS_9allocatorIS4_EEFPNS2_13LinearUpdaterEvEEE
NSt3__110__function6__baseIFPN7xgboost13LinearUpdaterEvEEE
N7xgboost6linear17CoordinateUpdaterE
N7xgboost13LinearUpdaterE
N7xgboost6linear21CyclicFeatureSelectorE
N7xgboost6linear15FeatureSelectorE
N7xgboost6linear22ShuffleFeatureSelectorE
N7xgboost6linear22ThriftyFeatureSelectorE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_7CSCPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_7CSCPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
NSt3__114default_deleteIN7xgboost17BatchIteratorImplINS1_7CSCPageEEEEE
N7xgboost6linear21GreedyFeatureSelectorE
N7xgboost6linear21RandomFeatureSelectorE
N7xgboost6linear3$_0E
N4dmlc2io12LineSplitterE
BNSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric14EvalMatchErrorE
N7xgboost6metric14EvalMClassBaseINS0_14EvalMatchErrorEEE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric16EvalMultiLogLossE
N7xgboost6metric14EvalMClassBaseINS0_16EvalMultiLogLossEEE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj8HingeObjE
N7xgboost3obj3$_0E
N7xgboost9PredictorE
N7xgboost4tree14SplitEvaluatorE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS3_14SplitEvaluatorENS_10unique_ptrIS7_NS_14default_deleteIS7_EEEEEEE
NSt3__110__function6__baseIFPN7xgboost4tree14SplitEvaluatorENS_10unique_ptrIS4_NS_14default_deleteIS4_EEEEEEE
N7xgboost4tree10ElasticNetE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS3_14SplitEvaluatorENS_10unique_ptrIS7_NS_14default_deleteIS7_EEEEEEE
N7xgboost4tree19MonotonicConstraintE
N7xgboost4tree3$_1E
3@9N7xgboost6common10SparseCutsE
N7xgboost6common11CutsBuilderE
N7xgboost6common9DenseCutsE
N5rabit5utils19MemoryFixSizeBufferE
N5rabit5utils18MemoryBufferStreamE
N7xgboost4tree17QuantileHistMakerE
N7xgboost4tree17QuantileHistMaker7BuilderE
NSt3__110__function6__funcIPFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES6_ENS_9allocatorIS8_EES7_EE
NSt3__110__function6__baseIFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES6_EEE
PFbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES3_E
FbN7xgboost4tree17QuantileHistMaker7Builder11ExpandEntryES3_E
NSt3__110__function6__funcIN7xgboost4tree3$_2ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree3$_2E
NSt3__110__function6__funcIN7xgboost4tree3$_3ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree3$_3E
NSt3__120__shared_ptr_emplaceIN7xgboost16HostDeviceVectorIjEENS_9allocatorIS3_EEEE
N7xgboost3gbm13GBLinearModelE
N7xgboost5ModelE
NSt3__120__shared_ptr_pointerIPN7xgboost8JsonNullENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_8JsonNullEEE
NSt3__114default_deleteIN7xgboost8JsonNullEEE
NSt3__120__shared_ptr_pointerIPN7xgboost9JsonArrayENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_9JsonArrayEEE
NSt3__114default_deleteIN7xgboost9JsonArrayEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10JsonNumberENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_10JsonNumberEEE
NSt3__114default_deleteIN7xgboost10JsonNumberEEE
N4dmlc9parameter10FieldEntryINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEEES9_EE
NSt3__110__function6__funcIN7xgboost3gbm3$_0ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
NSt3__110__function6__baseIFPN7xgboost15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS_9allocatorIS8_EEEEPKNS2_17LearnerModelParamEEEE
N7xgboost3gbm8GBLinearE
N7xgboost15GradientBoosterE
N7xgboost3gbm3$_0E
NSt3__110__function6__funcIN7xgboost6linear3$_0ENS_9allocatorIS4_EEFPNS2_13LinearUpdaterEvEEE
N7xgboost6linear14ShotgunUpdaterE
N7xgboost6linear3$_0E
(FYN7xgboost3gbm6GBTreeE
N4dmlc9parameter10FieldEntryIN7xgboost15TreeProcessTypeEEE
N4dmlc9parameter10FieldEntryIN7xgboost13PredictorTypeEEE
N4dmlc9parameter10FieldEntryIN7xgboost10TreeMethodEEE
NSt3__110__function6__funcIN7xgboost3gbm3$_4ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
NSt3__120__shared_ptr_emplaceINS_13unordered_mapIPN7xgboost7DMatrixENS2_20PredictionCacheEntryENS_4hashIS4_EENS_8equal_toIS4_EENS_9allocatorINS_4pairIKS4_S5_EEEEEENSA_ISF_EEEE
N7xgboost3gbm3$_4E
NSt3__110__function6__funcIN7xgboost3gbm3$_5ENS_9allocatorIS4_EEFPNS2_15GradientBoosterERKNS_6vectorINS_10shared_ptrINS2_7DMatrixEEENS5_ISC_EEEEPKNS2_17LearnerModelParamEEEE
N7xgboost3gbm4DartE
N7xgboost3gbm3$_5E
NSt3__120__shared_ptr_pointerIPN7xgboost11JsonBooleanENS_10shared_ptrINS1_5ValueEE27__shared_ptr_default_deleteIS5_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost5ValueEE27__shared_ptr_default_deleteIS2_NS1_11JsonBooleanEEE
NSt3__114default_deleteIN7xgboost11JsonBooleanEEE
N7xgboost4data15SimpleCSRSourceE
N7xgboost10DataSourceINS_10SparsePageEEE
N4dmlc8DataIterIN7xgboost10SparsePageEEE
N4dmlc2io10FileSystemE
N4dmlc8DataIterINS_8RowBlockIjfEEEE
N4dmlc8DataIterINS_8RowBlockIyfEEEE
N4dmlc8DataIterINS_8RowBlockIjiEEEE
N4dmlc8DataIterINS_8RowBlockIyiEEEE
N4dmlc8DataIterINS_8RowBlockIjxEEEE
N4dmlc8DataIterINS_8RowBlockIyxEEEE
N4dmlc4data12LibSVMParserIjfEE
N4dmlc4data14TextParserBaseIjfEE
N4dmlc4data10ParserImplIjfEE
N4dmlc6ParserIjfEE
N4dmlc4data14ThreadedParserIjfEE
N4dmlc12ThreadedIterINSt3__16vectorINS_4data17RowBlockContainerIjfEENS1_9allocatorIS5_EEEEEE
N4dmlc8DataIterINSt3__16vectorINS_4data17RowBlockContainerIjfEENS1_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIjfEC1EPNS3_10ParserImplIjfEEEUlPPNS_6vectorINS3_17RowBlockContainerIjfEENS_9allocatorISB_EEEEE_NSC_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPNS_6vectorIN4dmlc4data17RowBlockContainerIjfEENS_9allocatorIS6_EEEEEEE
ZN4dmlc4data14ThreadedParserIjfEC1EPNS0_10ParserImplIjfEEEUlPPNSt3__16vectorINS0_17RowBlockContainerIjfEENS6_9allocatorIS9_EEEEE_
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIjfEC1EPNS3_10ParserImplIjfEEEUlvE_NS_9allocatorIS9_EEFvvEEE
ZN4dmlc4data14ThreadedParserIjfEC1EPNS0_10ParserImplIjfEEEUlvE_
N4dmlc4data12LibSVMParserIyfEE
N4dmlc4data14TextParserBaseIyfEE
N4dmlc4data10ParserImplIyfEE
N4dmlc6ParserIyfEE
N4dmlc4data14ThreadedParserIyfEE
N4dmlc12ThreadedIterINSt3__16vectorINS_4data17RowBlockContainerIyfEENS1_9allocatorIS5_EEEEEE
N4dmlc8DataIterINSt3__16vectorINS_4data17RowBlockContainerIyfEENS1_9allocatorIS5_EEEEEE
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIyfEC1EPNS3_10ParserImplIyfEEEUlPPNS_6vectorINS3_17RowBlockContainerIyfEENS_9allocatorISB_EEEEE_NSC_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPNS_6vectorIN4dmlc4data17RowBlockContainerIyfEENS_9allocatorIS6_EEEEEEE
ZN4dmlc4data14ThreadedParserIyfEC1EPNS0_10ParserImplIyfEEEUlPPNSt3__16vectorINS0_17RowBlockContainerIyfEENS6_9allocatorIS9_EEEEE_
NSt3__110__function6__funcIZN4dmlc4data14ThreadedParserIyfEC1EPNS3_10ParserImplIyfEEEUlvE_NS_9allocatorIS9_EEFvvEEE
ZN4dmlc4data14ThreadedParserIyfEC1EPNS0_10ParserImplIyfEEEUlvE_
N4dmlc4data11LibFMParserIjfEE
N4dmlc4data11LibFMParserIyfEE
N4dmlc4data9CSVParserIjfEE
N4dmlc4data9CSVParserIyfEE
N4dmlc4data9CSVParserIjiEE
N4dmlc4data14TextParserBaseIjiEE
N4dmlc4data10ParserImplIjiEE
N4dmlc6ParserIjiEE
N4dmlc4data9CSVParserIyiEE
N4dmlc4data14TextParserBaseIyiEE
N4dmlc4data10ParserImplIyiEE
N4dmlc6ParserIyiEE
N4dmlc4data9CSVParserIjxEE
N4dmlc4data14TextParserBaseIjxEE
N4dmlc4data10ParserImplIjxEE
N4dmlc6ParserIjxEE
N4dmlc4data9CSVParserIyxEE
N4dmlc4data14TextParserBaseIyxEE
N4dmlc4data10ParserImplIyxEE
N4dmlc6ParserIyxEE
N4dmlc12ScopedThreadE
!N7xgboost10JsonStringE
N7xgboost9JsonArrayE
N7xgboost10JsonObjectE
N7xgboost10JsonNumberE
N7xgboost11JsonIntegerE
N7xgboost8JsonNullE
N7xgboost11JsonBooleanE
N7xgboost10JsonReaderE
N7xgboost10JsonWriterE
N7xgboost29FixedPrecisionStreamContainerINSt3__19allocatorIcEEEE
N4dmlc2io16RecordIOSplitterE
bkN7xgboost7DMatrixE
N4dmlc7istreamE
N4dmlc7istream5InBufE
N4dmlc12ThreadedIterIN7xgboost10SparsePageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_10SparsePageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost10SparsePageEEEE
ZN7xgboost4data16SparsePageSourceINS_10SparsePageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_10SparsePageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_10SparsePageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data16SparsePageSourceINS_10SparsePageEEE
NSt3__120__shared_ptr_pointerIPN7xgboost10SparsePageENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost10SparsePageEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN7xgboost10SparsePageEEE
N4dmlc2io15SingleFileSplitE
N4dmlc2io18ThreadedInputSplitE
N4dmlc12ThreadedIterINS_2io14InputSplitBase5ChunkEEE
N4dmlc8DataIterINS_2io14InputSplitBase5ChunkEEE
NSt3__110__function6__funcIZN4dmlc2io18ThreadedInputSplitC1EPNS3_14InputSplitBaseEmEUlPPNS5_5ChunkEE_NS_9allocatorISA_EEFbS9_EEE
NSt3__110__function6__baseIFbPPN4dmlc2io14InputSplitBase5ChunkEEEE
ZN4dmlc2io18ThreadedInputSplitC1EPNS0_14InputSplitBaseEmEUlPPNS2_5ChunkEE_
NSt3__110__function6__funcIZN4dmlc2io18ThreadedInputSplitC1EPNS3_14InputSplitBaseEmEUlvE_NS_9allocatorIS7_EEFvvEEE
ZN4dmlc2io18ThreadedInputSplitC1EPNS0_14InputSplitBaseEmEUlvE_
N4dmlc2io16CachedInputSplitE
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlPPNS3_14InputSplitBase5ChunkEE_NS_9allocatorIS9_EEFbS8_EEE
ZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlPPNS0_14InputSplitBase5ChunkEE_
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlvE_NS_9allocatorIS5_EEFvvEEE
ZN4dmlc2io16CachedInputSplit14InitCachedIterEvEUlvE_
NSt3__110__function6__funcIZN4dmlc2io16CachedInputSplit15InitPreprocIterEvEUlPPNS3_14InputSplitBase5ChunkEE_NS_9allocatorIS9_EEFbS8_EEE
ZN4dmlc2io16CachedInputSplit15InitPreprocIterEvEUlPPNS0_14InputSplitBase5ChunkEE_
NSt3__110__function6__funcIPFvvENS_9allocatorIS3_EES2_EE
PFvvE
FvvE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11SketchMakerE
N7xgboost4tree9BaseMakerE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_13SortedCSCPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_13SortedCSCPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
NSt3__114default_deleteIN7xgboost17BatchIteratorImplINS1_13SortedCSCPageEEEEE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4data3$_0ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_10SparsePageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_10SparsePageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_10SparsePageEEE
N7xgboost4data16SparsePageFormatINS_10SparsePageEEE
N7xgboost4data3$_0E
NSt3__110__function6__funcIN7xgboost4data3$_1ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_7CSCPageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_7CSCPageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_7CSCPageEEE
N7xgboost4data16SparsePageFormatINS_7CSCPageEEE
N7xgboost4data3$_1E
NSt3__110__function6__funcIN7xgboost4data3$_2ENS_9allocatorIS4_EEFPNS3_16SparsePageFormatINS2_13SortedCSCPageEEEvEEE
NSt3__110__function6__baseIFPN7xgboost4data16SparsePageFormatINS2_13SortedCSCPageEEEvEEE
N7xgboost4data19SparsePageRawFormatINS_13SortedCSCPageEEE
N7xgboost4data16SparsePageFormatINS_13SortedCSCPageEEE
N7xgboost4data3$_2E
N4dmlc2io23IndexedRecordIOSplitterE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree8ColMakerE
N7xgboost4tree8ColMaker7BuilderE
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree12DistColMakerE
N7xgboost4tree12DistColMaker7BuilderE
N7xgboost4tree3$_1E
N4dmlc12SerializableE
COHN7xgboost7LearnerE
N7xgboost11LearnerImplE
N4dmlc9parameter10FieldEntryIjEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIjEEjEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIjEEjEE
N4dmlc9parameter10FieldEntryIN7xgboost13DataSplitModeEEE
NSt3__110__function6__funcIN7xgboost3obj3$_0ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj20SoftmaxMultiClassObjE
N7xgboost3obj3$_0E
NSt3__110__function6__funcIN7xgboost3obj3$_1ENS_9allocatorIS4_EEFPNS2_11ObjFunctionEvEEE
N7xgboost3obj3$_1E
0NSt3__110__function6__funcIN7xgboost6metric3$_0ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_11EvalRowRMSEEEE
N7xgboost6metric3$_0E
NSt3__110__function6__funcIN7xgboost6metric3$_1ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_12EvalRowRMSLEEEE
N7xgboost6metric3$_1E
NSt3__110__function6__funcIN7xgboost6metric3$_2ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_10EvalRowMAEEEE
N7xgboost6metric3$_2E
NSt3__110__function6__funcIN7xgboost6metric3$_3ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_14EvalRowLogLossEEE
N7xgboost6metric3$_3E
NSt3__110__function6__funcIN7xgboost6metric3$_4ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_20EvalPoissonNegLogLikEEE
N7xgboost6metric3$_4E
NSt3__110__function6__funcIN7xgboost6metric3$_5ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_17EvalGammaDevianceEEE
N7xgboost6metric3$_5E
NSt3__110__function6__funcIN7xgboost6metric3$_6ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_16EvalGammaNLogLikEEE
N7xgboost6metric3$_6E
NSt3__110__function6__funcIN7xgboost6metric3$_7ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_9EvalErrorEEE
N7xgboost6metric3$_7E
NSt3__110__function6__funcIN7xgboost6metric3$_8ENS_9allocatorIS4_EEFPNS2_6MetricEPKcEEE
N7xgboost6metric13EvalEWiseBaseINS0_18EvalTweedieNLogLikEEE
N7xgboost6metric3$_8E
9G?N7xgboost4data17SparsePageDMatrixE
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_10SparsePageEEES3_EE
N7xgboost17BatchIteratorImplINS_10SparsePageEEE
N7xgboost4data16SparsePageSourceINS_7CSCPageEEE
N7xgboost10DataSourceINS_7CSCPageEEE
N4dmlc8DataIterIN7xgboost7CSCPageEEE
N4dmlc12ThreadedIterIN7xgboost7CSCPageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_7CSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost7CSCPageEEEE
ZN7xgboost4data16SparsePageSourceINS_7CSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_7CSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_7CSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_7CSCPageEEES3_EE
N7xgboost17BatchIteratorImplINS_7CSCPageEEE
N7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEE
N7xgboost10DataSourceINS_13SortedCSCPageEEE
N4dmlc8DataIterIN7xgboost13SortedCSCPageEEE
N4dmlc12ThreadedIterIN7xgboost13SortedCSCPageEEE
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_13SortedCSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlPPS5_E_NSA_ISH_EEFbSG_EEE
NSt3__110__function6__baseIFbPPN7xgboost13SortedCSCPageEEEE
ZN7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlPPS2_E_
NSt3__110__function6__funcIZN7xgboost4data16SparsePageSourceINS2_13SortedCSCPageEEC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESE_EUlvE_NSA_ISF_EEFvvEEE
ZN7xgboost4data16SparsePageSourceINS_13SortedCSCPageEEC1ERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEESC_EUlvE_
N7xgboost4data23SparseBatchIteratorImplINS0_16SparsePageSourceINS_13SortedCSCPageEEES3_EE
N7xgboost17BatchIteratorImplINS_13SortedCSCPageEEE
N7xgboost4data23SparseBatchIteratorImplINS0_17EllpackPageSourceENS_11EllpackPageEEE
N7xgboost17BatchIteratorImplINS_11EllpackPageEEE
NSt3__120__shared_ptr_pointerIPN7xgboost17BatchIteratorImplINS1_11EllpackPageEEENS_10shared_ptrIS4_E27__shared_ptr_default_deleteIS4_S4_EENS_9allocatorIS4_EEEE
NSt3__110shared_ptrIN7xgboost17BatchIteratorImplINS1_11EllpackPageEEEE27__shared_ptr_default_deleteIS4_S4_EE
NSt3__114default_deleteIN7xgboost17BatchIteratorImplINS1_11EllpackPageEEEEE
N7xgboost6common16PeekableInStreamE
N7xgboost6common15FixedSizeStreamE
N7xgboost4data13SimpleDMatrixE
N7xgboost4data23SimpleBatchIteratorImplINS_10SparsePageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_7CSCPageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_13SortedCSCPageEEE
N7xgboost4data23SimpleBatchIteratorImplINS_11EllpackPageEEE
N7xgboost4data12DenseAdapterE
N7xgboost4data6detail19SingleBatchDataIterINS0_17DenseAdapterBatchEEE
N4dmlc8DataIterIN7xgboost4data17DenseAdapterBatchEEE
NSt3__120__shared_ptr_pointerIPN7xgboost7DMatrixENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN7xgboost7DMatrixEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN7xgboost7DMatrixEEE
NSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11TreeSyncherE
N7xgboost4tree3$_0E
3tFNSt3__110__function6__funcIN7xgboost4tree3$_0ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree11CQHistMakerE
N7xgboost4tree9HistMakerE
NSt3__110__function6__funcIZN7xgboost4tree11CQHistMaker10CreateHistERKNS_6vectorINS2_6detail20GradientPairInternalIfEENS_9allocatorIS8_EEEEPNS2_7DMatrixERKNS5_IjNS9_IjEEEERKNS2_7RegTreeEEUlvE_NS9_ISN_EEFvvEEE
ZN7xgboost4tree11CQHistMaker10CreateHistERKNSt3__16vectorINS_6detail20GradientPairInternalIfEENS2_9allocatorIS6_EEEEPNS_7DMatrixERKNS3_IjNS7_IjEEEERKNS_7RegTreeEEUlvE_
N7xgboost4tree3$_0E
NSt3__110__function6__funcIN7xgboost4tree3$_1ENS_9allocatorIS4_EEFPNS2_11TreeUpdaterEvEEE
N7xgboost4tree23GlobalProposalHistMakerE
N7xgboost4tree3$_1E
N7xgboost7RegTreeE
N4dmlc9parameter10FieldEntryINSt3__16vectorIiNS2_9allocatorIiEEEEEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryINSt3__16vectorIiNS3_9allocatorIiEEEEEES7_EE
N4dmlc9parameter10FieldEntryIdEE
N4dmlc9parameter17FieldEntryNumericINS0_10FieldEntryIdEEdEE
N4dmlc9parameter14FieldEntryBaseINS0_10FieldEntryIdEEdEE
NSt3__110__function6__funcIN7xgboost3$_0ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
NSt3__110__function6__baseIFPN7xgboost13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEbEEE
N7xgboost13TextGeneratorE
N7xgboost13TreeGeneratorE
N7xgboost3$_0E
NSt3__110__function6__funcIN7xgboost3$_1ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
N7xgboost13JsonGeneratorE
N7xgboost3$_1E
NSt3__110__function6__funcIN7xgboost3$_2ENS_9allocatorIS3_EEFPNS2_13TreeGeneratorERKNS2_10FeatureMapENS_12basic_stringIcNS_11char_traitsIcEENS4_IcEEEEbEEE
N7xgboost17GraphvizGeneratorE
N7xgboost3$_2E
N7xgboost3gbm11GBTreeModelE
N5rabit6engine13AllreduceBaseE
N5rabit6engine7IEngineE
cpu_predictor
Make predictions using CPU.
basic_string
vector
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/predictor/cpu_predictor.cc
Check failed: cache_
%02d:%02d:%02d
Stack trace:
  [bt] (
DMLC_LOG_STACK_TRACE_DEPTH
Check failed: 
model.learner_model_param_->num_output_group != 0
out_preds->Size() == n
Ignoring the base margin, since it has incorrect length. 
The base margin must be an array of length 
[num_class] * [number of data points], i.e. 
[number of data points], i.e. 
Instead, all data points will use 
base_score = 
 vs. 
model.param.size_leaf_vector == 0
size_leaf_vector is enforced to 0 so far
preds.size() == p_fmat->Info().num_row_ * num_group
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/data.h
Check failed: impl_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/span.h
Check failed: _ptr || _count == 0
Check failed: _idx < size()
ngroup != 0
ncolumns != 0
AMS metric for higgs.
Area under curve for both classification and rank.
aucpr
Area under PR curve for both classification and rank.
precision@k for rank.
ndcg
ndcg@k for rank.
map@k for rank.
cox-nloglik
Negative log partial likelihood of Cox proportioanl hazards model.
vector
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/rank_metric.cc
Check failed: param != nullptr
AMS must be in format ams@k
ams@
Check failed: !distributed
metric AMS do not support distributed evaluation
best-ams-ratio=
info.labels_.Size() != 0U
label set cannot be empty
preds.Size() == info.labels_.Size()
label size predict size not match
gptr.back() == info.labels_.Size()
EvalAuc: group structure must match number of prediction
dat[1] > 0.0f
AUC: the dataset only contains pos or neg samples
EvalAucPR: group structure must match number of prediction
Check failed: !auc_error
AUC-PR: error in calculation
AUC-PR: the dataset only contains pos or neg samples
dat[0] <= dat[1]
AUC-PR: AUC > 1.0
%u[-]?
gptr.size() != 0U
must specify group when constructing rank file
gptr.back() == preds.Size()
EvalRanklist: group structure must match number of prediction
Cox metric does not support distributed evaluation
RegLossParam
Regression with squared error.
Regression with root mean squared logarithmic error.
Logistic regression for probability regression task.
Logistic regression for binary classification task.
Logistic regression for classification, output score before logistic transformation.
reg:linear
PoissonRegressionParam
count:poisson
Possion regression for count data.
survival:cox
Cox regression for censored survival data (negative labels are considered censored).
reg:gamma
Gamma regression for severity data.
TweedieRegressionParam
reg:tweedie
Tweedie regression for insurance data.
reg:squarederror
reg:squaredlogerror
reg:logistic
binary:logistic
binary:logitraw
scale_pos_weight
Scale the weight of positive examples by this factor
Invalid Parameter format for 
 expect 
 but value='
Required parameter 
 of 
 is not presented
Out of range value for 
, value='
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./parameter.h
pos <= value.length()
Some trailing characters could not be parsed: '
Out of range value
No conversion could be performed
infinity
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./strtonum.h
*p == ')'
Invalid NAN literal
value 
 for Parameter 
 exceed bound [
 should be greater equal to 
 should be smaller equal to 
 optional, default=
, required
float
key 
 has already been registered in 
reg_loss_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/json.h
Invalid cast, from 
 to 
Cannot find argument '
', Possible Arguments:
----------------
    
name
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/regression_obj.cu
Label set is empty.
labels are not correctly provided
preds.size=
, label.size=
info.weights_.Size() == ndata
Number of weights should be equal to number of data points.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/../common/transform.h
Not part of device code. WITH_CUDA: 
rmse
label must be greater than -1 for rmsle so that log(label + 1) can be valid.
rmsle
label must be in [0,1] for logistic regression
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/./regression_loss.h
Check failed: base_score > 0.0f && base_score < 1.0f
base_score must be in (0,1) for logistic loss, got: 
error
reg:linear is now deprecated in favor of reg:squarederror.
max_delta_step
Maximum delta step we allow each weight estimation to be. This parameter is required for possion regression.
poisson_regression_param
PoissonRegression: label must be nonnegative
poisson-nloglik
Check failed: last_abs_y <= abs_y
CoxRegression: labels must be in sorted order, 
MetaInfo::LabelArgsort failed!
GammaRegression: label must be nonnegative
gamma-nloglik
tweedie_variance_power
Tweedie variance power.  Must be between in range [1, 2).
tweedie_regression_param
tweedie-nloglik@
TweedieRegression: label must be nonnegative
refresh
Refresher that refreshes the weight and statistics according to data.
train_param
map::at:  key not found
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_refresh.cc
batch.Size() < std::numeric_limits<unsigned>::max()
rank
statistic
count
elapsed
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/timer.cc
Timer for 
 did not get stopped properly.
 calls @ 
======== Monitor: 
 ========
From rank: 
LambdaRankParam
Pairwise rank objective.
LambdaRank with NDCG as objective.
LambdaRank with MAP as objective.
rank:pairwise
rank:ndcg
rank:map
num_pairsample
Number of pair generated for each instance.
fix_list_weight
Normalize the weight of each list by this value, if equals 0, no effect will happen
lambda_rank_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/rank_obj.cu
Check failed: gptr.size() != 0 && gptr.back() == info.labels_.Size()
group structure not consistent with #rows
Computing 
 gradients on CPU.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/local_filesys.cc
LocalFileSystem.GetPathInfo: detected symlink 
 error: 
LocalFileSystem.GetPathInfo: 
LocalFileSystem.ListDirectory 
stdin
stdout
file://
Check failed: allow_null
 LocalFileSystem::Open "
Check failed: std::fwrite(ptr, 1, size, fp_) == size
FileStream.Write incomplete
Check failed: !std::fseek(fp_, static_cast<long>(pos), SEEK_SET)
ConsoleLoggerParam
WARNING: 
DEBUG: 
INFO: 
silent
Do not print information during training.
verbosity
Flag to print out detailed breakdown of runtime.
debug_verbose
true
false
boolean
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/parameter.h
Invalid Input: '
', valid values are: 
optional, default=
enum_back_map_.count(value) != 0U
Value not found in enum declared
 has not been registered in 
Alias 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/ellpack_page_source.cc
Internal Error: XGBoost is not compiled with CUDA but EllpackPageSource is required
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/input_split_base.cc
Check failed: files_[i].size % align_bytes == 0
file do not align by 
 bytes
Check failed: offset_end_ >file_offset_[file_ptr_end_]
Check failed: file_ptr_end_ < files_.size()
 bad regex 
This could due to compiler version, g++-4.9 is needed
files_.size() != 0U
Cannot find any files that matches the URI pattern 
curr=
,begin=
,end=
,fileptr=
,fileoffset=
offset[
file offset not calculated correctly
prune
Pruner that prune the tree according to statistics.
vector
sync
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_prune.cc
tree pruning end, 
 extra nodes, 
 pruned nodes, max_depth=
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/tree_model.h
Check failed: nodes_[nodes_[rid].LeftChild() ].IsLeaf()
Check failed: nodes_[nodes_[rid].RightChild()].IsLeaf()
nid >= 1
CoordinateParam
coord_descent
Update linear model according to coordinate descent algorithm.
top_k
The number of top features to select in 'thrifty' feature_selector. The value of zero means using all the features.
CoordinateUpdater
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/coordinate_common.h
unknown coordinate selector: 
UpdateFeature
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/line_split.cc
Check failed: begin != end
Objective candidate: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/objective.cc
Unknown objective function: `
merror
Multiclass classification error.
mlogloss
Multiclass negative loglikelihood.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/multiclass_metric.cu
Check failed: preds.Size() % info.labels_.Size() == 0
label and prediction size not match
nclass >= 1U
mlogloss and merror are only used for multi-class classification,
 use logloss for binary classification
Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class)
MultiClassEvaluation: label must be in [0, num_class),
 num_class=
 but found 
 in label
the rabit has not been initialized
cannot initialize reduce handle twice
must intialize handle to call AllReduce
%s, shutting down process
%s, rabit is configured to keep process running
AssertError:%s, shutting down process
AssertError:%s, rabit is configured to keep process running
unique_lock::unlock: not locked
binary:hinge
Hinge loss. Expects labels to be in [0,1f]
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/hinge.cu
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/predictor/predictor.cc
Unknown predictor type 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/split_evaluator.cc
Unknown SplitEvaluator 
elastic_net
Use an elastic net regulariser
monotonic
Enforces that the tree is monotonically increasing/decreasing w.r.t. specified features
ElasticNet does not accept an inner SplitEvaluator
Check failed: r->params_
MonotonicConstraint must be given an inner evaluator
Check failed: c->params_
Check failed: !std::isnan(mid)
Check failed: nodeid < upper_.size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/tree_updater.cc
Unknown tree updater 
HistogramCuts
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/hist_util.cc
Building quantile cut on a sparse dataset.
Building quantile cut on a dense dataset or distributed environment.
Total number of hist bins: 
end_col >= beg_col
Build
page.Size() <= dmat->Info().num_col_
Load balance
SingleThreadBuild: 
Concat
nthread == omp_get_num_threads()
Init
summary_array.size() == in_sketchs->size()
p_cuts_->cut_values_.size() <= std::numeric_limits<uint32_t>::max()
cut_size > p_cuts_->cut_ptrs_.back()
cut.Values().size() > 0U
ibegin + inst.size() == iend
sibling.size() == size
parent.size() == size
SparseCuts
DenseCuts
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/./hist_util.h
Row 
 does not lie in any group!
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/./quantile.h
invalid init parameter
Check failed: nlevel <= limit_size * eps
Check failed: index_ != span_->size()
Check failed: index_ < span_->size()
mingap=
, maxgap=
, wgap=
Check failed: size <= sa.size + sb.size
bug in combine
 check quantile stats, nbig=
, n=
 srcsize=
, maxsize=
, range=
, chunk=
Check failed: nbig < n
quantile: too many large chunk
] rmin=
, rmax=
, wmin=
, v=
write position exceed fixed buffer size
fi.Read(&this->size, sizeof(this->size)) == sizeof(this->size)
fi.Read(this->data, this->size * sizeof(Entry)) == this->size * sizeof(Entry)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/metric.cc
Unknown metric function 
read can not have position excceed buffer length
too large type_nbytes=%lu, buffer_size=%lu
GetSockError
Socket %s Error:%s
Poll
Socket::Close double close the socket or close without create
ReadToRingBuffer: buffer not allocated
ReadToRingBuffer: max_size_read check
Allreduce: boundary check
NULL
thread constructor failed
SyncHistograms
BuildLocalHistograms
BuildNodeStats
Update
UpdatePredictionCache
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_quantile_hist.cc
out_preds.size() > 0U
Check failed: (*p_last_tree_)[nid].IsLeaf()
Check failed: (param_.max_depth > 0 || param_.max_leaves > 0)
max_depth or max_leaves cannot be both 0 (unlimited); 
at least one should be a positive quantity.
Check failed: param_.max_depth > 0
max_depth cannot be 0 (unlimited) 
when grow_policy is depthwise.
InitData
min_nbins_per_feature > 0U
EvaluateSplit
ApplySplit
upper_bound < static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
InitNewNode
grow_fast_histmaker
(Deprecated, use grow_quantile_histmaker instead.) Grow tree using quantized histogram.
grow_quantile_histmaker
Grow tree using quantized histogram.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/column_matrix.h
gmat.cut.Ptrs()[fid + 1] - gmat.cut.Ptrs()[fid] <= max_val
Quantile::Builder
seed
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/hist_util.h
row_ptr_[nid] != kMax
row_ptr_[nid] == kMax
SubtractionTrick
BuildHist
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/row_set.h
Check failed: e.begin != nullptr
access element that is not in the set
elem_of_each_node_.size() == 0U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/random.h
features.size() > 0
Check failed: node.IsLeaf()
param.num_nodes < std::numeric_limits<int>::max()
number of nodes in the tree exceed 2^31
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/../common/threading_utils.h
begin < end
cut_ptr[fid] <= static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
cut_ptr[fid + 1] <= static_cast<uint32_t>(std::numeric_limits<int32_t>::max())
i < first_dimension_.size()
i < ranges_.size()
grow_fast_histmaker is deprecated, 
use grow_quantile_histmaker instead.
weights
DeprecatedGBLinearModelParam
GBLinearTrainParam
gblinear
Linear booster, implement generalized linear model.
updater
shotgun
Update algorithm for linear model. One of shotgun/coord_descent
tolerance
Stop if largest weight update is smaller than this number.
max_row_perbatch
Maximum rows per batch.
string
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gblinear.cc
get<String>(in["name"]) == "gblinear"
model
GBLinear
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/gbm.h
XGBoost version not compiled with GPU support.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gblinear_model.h
fi->Read(&param, sizeof(param)) == sizeof(param)
DoBoost
PredictBatchInternal
PredictBatch
ntree_limit == 0U
GBLinear::Predict ntrees is only valid for gbtree predictor
gblinear does not support prediction of leaf index
GBLinear::PredictContribution: ntrees is only valid for gbtree predictor
json
  { "bias": [
      
    ],
    "weight": [
    ]
bias:
weight:
gblinear_train_param
Update linear model according to shotgun coordinate descent algorithm.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/updater_shotgun.cc
Unsupported feature selector for shotgun updater.
Supported options are: {cyclic, shuffle}
GBTree
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree.cc
DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using`tree_method` parameter instead.
Check failed: this->configured_
Check failed: tparam_.GetInitialised()
Using updaters: 
grow_histmaker,prune
Tree method is automatically selected to be 'approx' for distributed training.
Tree method is automatically set to 'approx' since external-memory data matrix is used.
Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.
Using tree method: 
grow_colmaker,prune
Tree method is selected to be 'hist', which uses a single updater grow_quantile_histmaker.
grow_gpu_hist
Unknown tree_method (
) detected
BoostNewTrees
in_gpair->Size() % ngroup == 0U
must have exactly ngroup*nrow gpairs
ups.size() == updaters_.size()
Internal Error: 
 mismatched updater sequence.
Specified updaters: 
Actual updaters: 
model_.trees.size() < model_.trees_to_update.size()
CommitModel
Check failed: configured_
gbtree
get<String>(in["name"]) == "gbtree"
gbtree_train_param
predictor
auto
tree_method
hist
Loading from a raw memory buffer on CPU only machine.  Change tree_method to hist.
specified_updater
GBTreeModelParam
GBTreeTrainParam
DartTrainParam
Tree booster, gradient boosted trees.
dart
Tree booster, dart.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree.h
Check failed: cpu_predictor_
distcol
num_trees
Number of features used for training and prediction.
size_leaf_vector
Reserved option for vector tree.
num_parallel_tree
Number of parallel trees constructed during each iteration. This option is used to support boosted random forest.
updater_seq
Tree updater sequence.
process_type
default
update
Whether to run the normal boosting process that creates new trees, or to update the trees in an existing model.
gpu_predictor
Predictor algorithm type
approx
exact
gpu_hist
Choice of tree construction method.
Enum 
 exisit!
Enums: 
sample_type
uniform
weighted
Different types of sampling algorithm.
normalize_type
tree
forest
Different types of normalization algorithm.
rate_drop
Fraction of trees to drop during the dropout.
one_drop
Whether at least one tree should always be dropped during the dropout.
skip_drop
Probability of skipping the dropout during a boosting iteration.
learning_rate
Learning rate(step size) of update.
get<String>(in["name"]) == "dart"
weight_drop
out_preds->size() == n
num_group == model_.learner_model_param_->num_output_group
model_.param.size_leaf_vector == 0
dart_train_param
drop 
 trees, 
weight = 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbm.cc
Unknown gbm type 
tmagic == kMagic
invalid format, magic number mismatch
vector
LibSVMParserParam
LibFMParserParam
CSVParserParam
libsvm
libfm
format
File format
indexing_mode
If >0, treat all feature indices as 1-based. If =0, treat all feature indices as 0-based. If <0, use heuristic to automatically detect mode of indexing. See https://en.wikipedia.org/wiki/Array_data_type#Index_origin for more details on indexing modes.
If >0, treat all field and feature indices as 1-based. If =0, treat all field and feature indices as 0-based. If <0, use heuristic to automatically detect mode of indexing. See https://en.wikipedia.org/wiki/Array_data_type#Index_origin for more details on indexing modes.
File format.
label_column
Column index (0-based) that will put into label.
delimiter
Delimiter used in the csv file.
weight_column
Column index that will put into instance weights.
.split
.part
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/uri_spec.h
name_cache.size() == 1U
only one `#` is allowed in file path for cachefile specification
Check failed: std::getline(is, kv.first, '=')
Invalid uri argument format
 for key in arg 
Check failed: std::getline(is, kv.second)
 for value in arg 
name_args.size() == 1U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/threadediter.h
Check failed: !producer_sig_processed_.load(std::memory_order_acquire)
Check failed: producer_sig_.load(std::memory_order_acquire) == kProduce
Make sure you call BeforeFirst not inconcurrent with Next!
Check failed: produce_end_.load(std::memory_order_acquire)
Check failed: out_data_ != NULL
Calling Value at beginning or end?
No thread
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./row_block.h
label.size() + 1 == offset.size()
offset.back() == index.size()
Check failed: offset.back() == value.size() || value.size() == 0
text
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./libsvm_parser.h
param_.format == "libsvm"
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/./text_parser.h
chunk.size != 0U
qid:
Check failed: out->label.size() + 1 == out->offset.size()
sign == true
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/parser.h
cannot call ParseNext
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/libfm_parser.h
param_.format == "libfm"
Check failed: out->field.size() == out->index.size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/data/csv_parser.h
param_.format == "csv"
Check failed: param_.label_column != param_.weight_column || param_.label_column < 0
Must have distinct columns for labels and instance weights
Delimiter '
' is not found in the line. 
Expected '
' as the delimiter to separate fields.
Check failed: out->weight.size() == 0 || out->weight.size() + 1 == out->offset.size()
null
\u%04x
String
Number
Object
Array
Boolean
Null
Integer
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/json.cc
Object of type 
 can not be indexed by Integer.
 can not be indexed by string.
  Please try obtaining std::string first.
Unknown construct
, around character: 
Unknown escape
Expecting null value "null"
ch != -1
cursor_.Pos(): 
raw_str_.size():
exp > (kExpMax - digit) / 10
Overflow
Expecting boolean value "true".
Expecting boolean value "false".
beg <= size_
Expecting: "
", got: "
Failed to set locale: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/recordio_split.cc
Check failed: fi->Read(&lrec, sizeof(lrec)) != 0
invalid record io format
(reinterpret_cast<size_t>(begin) & 3UL) == 0U
(reinterpret_cast<size_t>(end) & 3UL) == 0U
Check failed: p >= pbegin + 2
Check failed: chunk->begin + 2 * sizeof(uint32_t) <= chunk->end
Invalid RecordIO Format
(reinterpret_cast<size_t>(chunk->begin) & 3UL) == 0U
(reinterpret_cast<size_t>(chunk->end) & 3UL) == 0U
Check failed: chunk->begin <= chunk->end
Check failed: cflag == 1U
Check failed: p[0] == RecordIOWriter::kMagic
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/data.cc
major == 1
Binary DMatrix generated by XGBoost: 
 is no longer supported. 
Please process and save your data in current version: 
 again.
Check failed: fi->Read(&num_row_, sizeof(num_row_)) == sizeof(num_row_)
MetaInfo: invalid format
Check failed: fi->Read(&num_col_, sizeof(num_col_)) == sizeof(num_col_)
Check failed: fi->Read(&num_nonzero_, sizeof(num_nonzero_)) == sizeof(num_nonzero_)
Check failed: fi->Read(&labels_.HostVector())
Check failed: fi->Read(&group_ptr_)
Check failed: fi->Read(&weights_.HostVector())
Check failed: fi->Read(&base_margin_.HostVector())
label
Unknown data type
weight
base_margin
group
Unknown metainfo: 
self_offset.size() == other_offset.size()
self_data.size(): 
other_data.size(): 
beg <= data.size()
ptr < offset.size()
.row.page
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/./sparse_page_source.h
cache_shards.size() != 0U
Writing 
 in 
 MB/s, 
 written
SparsePageSource::CreateRowPage Finished writing to 
.fmt-
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_writer.h
name_shards.size() == format_shards.size()
SparsePageWriter Finished writing to 
Unknown format type 
Check failed: *out_page == nullptr
Check failed: qrecycle_.Pop(out_page)
key >= builder_base_row_offset
finfo->Read(&tmagic, sizeof(tmagic)) == sizeof(tmagic)
Check failed: fi->Read(&format)
Invalid page format
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io.cc
Please compile with DMLC_USE_HDFS=1 to use hdfs
Please compile with DMLC_USE_S3=1 to use S3
Please compile with DMLC_USE_AZURE=1 to use Azure
unknown filesystem protocol 
Check failed: part < nsplit
invalid input parameter for InputSplit::Create
indexed_recordio
need to pass index file to use IndexedRecordIO
recordio
unknown input split type 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/single_file_split.h
Check failed: fp_ != NULL
SingleFileSplit: fail to open 
Check failed: part_index == 0 && num_parts == 1
InputSplit do not support write
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/cached_input_split.h
Check failed: nread == sizeof(size)
 has invalid cache file format
Check failed: fi_->Read(p->begin, size) == size
BeforeFirst is not supported
Check failed: this->InitCachedIter()
Failed to initialize CachedIter
ResetPartition is not supported in CachedInputSplit
grow_skmaker
Approximate sketching maker.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/./updater_basemaker-inl.h
sketch->temp.size < max_size
invalid maximum size max_size=
, stemp.size
INFO: rmax=
, sum_total=
, naxt_goal=
, size=
sketch->temp.size <= max_size
Finalize: invalid maximum size, max_size=
, stemp.size=
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/param.h
ret > 0U
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_skmaker.cc
qexpand_.size() != 0U
node2workindex_[nid] == static_cast<int>(wid)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/linear/linear_updater.cc
Unknown linear updater 
LinearTrainParam
Learning rate of each update.
reg_lambda
L2 regularization on weights.
reg_alpha
L1 regularization on weights.
feature_selector
cyclic
shuffle
thrifty
greedy
random
Feature selection or ordering method.
lambda
alpha
Raw binary data format.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_raw_format.cc
page->offset.Size() != 0U
Invalid SparsePage file
fi->Read(dmlc::BeginPtr(data_vec), (page->data).Size() * sizeof(Entry)) == (page->data).Size() * sizeof(Entry)
fid + 1 < disk_offset_.size()
disk_offset_[fid] > curr_offset
fi->Read(dmlc::BeginPtr(data_vec) + offset_vec[i], size_to_read * sizeof(Entry)) == size_to_read * sizeof(Entry)
Check failed: page.offset.Size() != 0 && offset_vec[0] == 0
offset_vec.back() == page.data.Size()
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/src/io/indexed_recordio_split.cc
expanded_list.size() == 1ul
IndexedRecordIOSplitter does not support multiple index files
ColMakerTrainParam
grow_colmaker
Grow tree with parallelization over columns.
Distributed column split version of tree maker.
opt_dense_col
EXP Param: speed optimization for dense column.
colmaker_train_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_colmaker.cc
feat_set.size() == num_features
Check failed: param_.cache_opt
Support for `cache_opt' is removed in 1.0.0
fmat.Info().num_row_ == position_.size()
ridx < position_.size()
ridx exceed bound 
ridx=
 pos=
trees.size() == 1U
DistColMaker: only support one tree at a time
Check failed: !tree[nid].IsLeaf()
inconsistent reduce information
nid >= 0
LearnerModelParamLegacy
LearnerTrainParam
GenericParameter
gpu_id
eval_metric
CONFIG-offset:
num_round
Learner
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/learner.cc
Check failed: IsA<Object>(in)
learner
learner_model_param
objective
gradient_booster
booster
attributes
base_score
num_feature
num_class
Check failed: !this->need_configuration_
Call Configure before saving model.
Configure
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/generic_parameters.h
n_gpus: 
n_gpus
Check failed: matrix != nullptr
num_col <= static_cast<uint64_t>(std::numeric_limits<unsigned>::max())
Unfortunately, XGBoost does not support data matrices with 
 features or greater
mparam_.num_feature != 0
0 feature is supplied.  Are you using raw Booster interface?
num_output_group
multi:softmax
_param
Parameters: { 
 } might not be used.
  This may not be accurate due to some parameters are only used in language bindings but
  passed down to XGBoost core.  Or some parameters are not used but slip through this
  verification. Please open an issue if you find above cases.
UpdateOneIter
PredictRaw
Predictions
GetGradient
Gradients
Check failed: tparam_.dsplit != DataSplitMode::kAuto
Precondition violated; dsplit cannot be 'auto' in distributed mode
Column-wise data split is currently not supported.
Check failed: weights.Size() == info.group_ptr_.size() - 1
weights size: 
groups size: 
num rows: 
Number of weights should be equal to number of groups in ranking task.
Check failed: gbm_ != nullptr
Predict must happen after Load or configuration
BoostOneIter
EvalOneIter
multiple_predictions <= 1
Perform one kind of prediction at a time.
bs64
header != "bs64"
Base64 format is no longer supported in brick.
fp.Read(&header[0], 4) == 4U
fi->Read(&mparam_, sizeof(mparam_)) == sizeof(mparam_)
BoostLearner: wrong model format
fi->Read(&len, sizeof(len)) == sizeof(len)
fi->Read(&gap, sizeof(gap)) == sizeof(gap)
fi->Read(&tparam_.objective[0], len) == len
Check failed: fi->Read(&tparam_.booster)
SAVED_PARAM_
count_poisson_max_delta_step
rabit_bootstrap_cache
The model hasn't been built yet.  Are you using raw Booster interface?
learner_train_param
metrics
generic_param
Model
Config
fp.Read(&header[0], header.size()) == serialisation_header_.size()
header == serialisation_header_
fp.Read(&json_offset, sizeof(json_offset)) == sizeof(json_offset)
json_offset > 0
Global bias of the model.
Number of features in training data, this parameter will be automatically detected by learner.
Number of class option for multi-class classifier.  By default equals 0 and corresponds to binary classifier.
int (non-negative)
dsplit
Data split mode for distributed training.
disable_default_eval_metric
flag to disable default metric. Set to >0 to disable
Gradient booster used for training.
Objective function used for obtaining gradient.
Random number seed during training.
random_state
seed_per_iteration
Seed PRNG determnisticly via iterator number, this option will be switched on automatically on distributed mode.
nthread
Number of threads to use.
n_jobs
The primary GPU device ordinal.
gpu_page_size
GPU page size when running in external memory mode.
enable_experimental_json_serialization
Enable using JSON for memory serialization (Python Pickle, rabit checkpoints etc.).
validate_parameters
Enable to check whether parameters are used or not.
Deprecated. Single process multi-GPU training is no longer supported.
Please switch to distributed training with one process per GPU.
This can be done using Dask or Spark.  See documentation for details.
SoftmaxMultiClassParam
Softmax for multi-class classification, output class index.
multi:softprob
Softmax for multi-class classification, output probability distribution.
Number of output class in the multi-class classification.
softmax_multiclass_param
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/objective/multiclass_obj.cu
Check failed: preds.Size() == (static_cast<size_t>(param_.num_class) * info.labels_.Size())
SoftmaxMultiClassObj: label size and pred size does not match.
label.Size() * num_class: 
num_class: 
preds.Size(): 
SoftmaxMultiClassObj: label must be in [0, num_class).
Check failed: _offset < size() || size() == 0
Check failed: (_count == dynamic_extent) || (_offset + _count <= size())
Check failed: (index_ + n) <= span_->size()
Check failed: span_ == rhs.span_
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/host_device_vector.cc
Check failed: 
Size() == other.Size()
vector
Rooted mean square error.
Rooted mean square log error.
Mean absolute error.
logloss
Negative loglikelihood for logistic regression.
Negative loglikelihood for poisson regression.
gamma-deviance
Residual deviance for gamma regression.
Negative log-likelihood for gamma regression.
Binary classification error.
tweedie-nloglik
tweedie-nloglik@rho for tweedie regression.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/metric/elementwise_metric.cu
label set is empty
label and prediction size not match, 
hint: use merror or mlogloss for multi-class classification
sscanf(param, "%f", &threshold_) == 1
unable to parse the threshold value for the error metric
tweedie-nloglik must be in format tweedie-nloglik@rho
Check failed: rho_ < 2 && rho_ >= 1
tweedie variance power must be in interval [1, 2)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_dmatrix.cc
Check failed: cast
.col.page
.sorted.col.page
param.gpu_id >= 0
param.max_bin >= 2
Check failed: source_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/sparse_page_source.h
Unknown page type: 
Writing to 
SparsePageSource: Finished writing to 
version
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/version.cc
Invaid version format in loaded JSON object: 
Incorrect version format found in binary file.  Binary file from XGBoost < 1.0.0 is no longer supported. Please generate it again.
version:
fi->Read(&read[0], verstr.size()) == verstr.size()
fi->Read(&major, sizeof(major)) == sizeof(major)
fi->Read(&minor, sizeof(major)) == sizeof(minor)
fi->Read(&patch, sizeof(major)) == sizeof(patch)
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/io.cc
Opening 
 failed: 
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/common/io.h
Not implemented
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/simple_dmatrix.cc
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/./simple_batch_iterator.h
Check failed: page_ != nullptr
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/constraints.cc
Failed to parse feature interaction constraint:
With error:
newsize != 0
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/dmlc-core/include/dmlc/./json.h
ch == '['
Error at
, Expect '{' but get '
 Line 
, around ^`
ch == ','
, JSON array expect ']' or ','. Get '
' instead
Check failed: !is_->fail()
, Expect number
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/c_api/c_api.cc
DMatrix/Booster has not been intialized or has already been disposed.
str.size() > 2
str[0] == '{'
Syncher that synchronize the tree in all distributed nodes.
grow_local_histmaker
Tree constructor that uses approximate histogram construction.
grow_histmaker
Tree constructor that uses approximate global of histogram construction.
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/updater_histmaker.cc
max_depth must be larger than 0
summary_array_.size() == sketchs_.size()
offset == -2
this->wspace_.rptr.size() == (fset.size() + 1) * this->qexpand_.size() + 1
fid * 2 + 1 < fminmax_.size()
FeatHelper fid exceed query bound 
Check failed: tree[nid].IsLeaf()
fid * 2 < fminmax_.size()
, hist.size=
hist[
, hist.last=
istart != hist.size
this->qexpand_.size() == 1U
this->wspace_.rptr.back() == this->wspace_.cut.size()
TreeParam
TrainParam
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/tree/tree_model.cc
Unknown Model Builder:
Dump text representation of tree
Dump json representation of tree
GraphvizParam
Dump graphviz representation of tree
fi->Read(&param, sizeof(TreeParam)) == sizeof(TreeParam)
param.num_nodes != 0
fi->Read(dmlc::BeginPtr(nodes_), sizeof(Node) * nodes_.size()) == sizeof(Node) * nodes_.size()
fi->Read(dmlc::BeginPtr(stats_), sizeof(RTreeNodeStat) * stats_.size()) == sizeof(RTreeNodeStat) * stats_.size()
static_cast<int>(deleted_nodes_.size()) == param.num_deleted
param.num_nodes == static_cast<int>(nodes_.size())
param.num_nodes == static_cast<int>(stats_.size())
param.deprecated_num_roots == 1
tree_param
n_nodes != 0
loss_changes
loss_changes.size() == n_nodes
sum_hessian
sum_hessian.size() == n_nodes
base_weights
base_weights.size() == n_nodes
leaf_child_counts
leaf_child_counts.size() == n_nodes
left_children
lefts.size() == n_nodes
right_children
rights.size() == n_nodes
parents
parents.size() == n_nodes
split_indices
indices.size() == n_nodes
split_conditions
conds.size() == n_nodes
default_left
default_left.size() == n_nodes
static_cast<bst_node_t>(deleted_nodes_.size()) == param.num_deleted
num_nodes
get<String>(out["tree_param"]["num_nodes"]) == std::to_string(param.num_nodes)
this->node_mean_values_.size() > 0U
unique_path[i].pweight == 0
Unique path 
 must have zero weight
vector
Number of features used in tree construction.
Size of leaf vector, reserved for vector tree
min_split_loss
Minimum loss reduction required to make a further partition.
max_depth
Maximum depth of the tree; 0 indicates no limit; a limit is required for depthwise policy
max_leaves
Maximum number of leaves; 0 indicates no limit.
max_bin
if using histogram-based algorithm, maximum number of bins per feature
grow_policy
depthwise
lossguide
Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow depth-wise. 1: favor splitting at nodes with highest loss change. (cf. LightGBM)
min_child_weight
Minimum sum of instance weight(hessian) needed in a child.
L2 regularization on leaf weight
L1 regularization on leaf weight
default_direction
learn
left
right
Default direction choice when encountering a missing value
Maximum delta step we allow each tree's weight estimate to be. If the value is set to 0, it means there is no constraint
subsample
Row subsample ratio of training instance.
colsample_bynode
Subsample ratio of columns, resample on each node (split).
colsample_bylevel
Subsample ratio of columns, resample on each level.
colsample_bytree
Subsample ratio of columns, resample on each tree construction.
sketch_eps
EXP Param: Sketch accuracy of approximate algorithm.
sketch_ratio
EXP Param: Sketch accuracy related parameter of approximate algorithm.
cache_opt
EXP Param: Cache aware optimization.
refresh_leaf
Whether the refresh updater needs to update leaf values.
monotone_constraints
Constraint of variable monotonicity
interaction_constraints
Constraints for interaction representing permitted interactions.The constraints must be specified in the form of a nest list,e.g. [[0, 1], [2, 3, 4]], where each inner list is a group ofindices of features that are allowed to interact with each other.See tutorial for more information
split_evaluator
elastic_net,monotonic
The criteria to use for ranking splits
sparse_threshold
percentage threshold for treating a feature as sparse
enable_feature_grouping
if >0, enable feature grouping to ameliorate work imbalance among worker threads
max_conflict_rate
when grouping features, how many "conflicts" to allow.conflict is when an instance has nonzero values for two or more features.default is 0, meaning features should be strictly complementary.
max_search_group
when grouping features, how much effort to expend to prevent singleton groups. We'll try to insert each feature into existing groups before creating a new group for that feature; to save time, only up to (max_search_group) of existing groups will be considered. If set to zero, ALL existing groups will be examined.
gamma
double
{nid}:[{fname}] yes={yes},no={no}
{nid}
{fname}
{yes}
{no}
pos != std::string::npos
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/include/xgboost/feature_map.h
idx < names_.size()
FeatureMap feature index exceed bound
{tabs}{nid}:[{fname}<{cond}] yes={left},no={right},missing={missing}
{tabs}
{cond}
{left}
{right}
{missing}
,gain={loss_chg},cover={sum_hess}
{loss_chg}
{sum_hess}
{tabs}{nid}:[f{fname}<{cond}] yes={left},no={right},missing={missing}
Unknown feature map type.
{tabs}{nid}:leaf={leaf}{stats}
,cover={cover}
{leaf}
{stats}
{cover}
{parent}{stat}
{left}
{right}
{parent}
{stat}
{nodes}
{nodes}
 "nodeid": {nid}, "depth": {depth}, "split": "{fname}", "yes": {yes}, "no": {no}}
{depth}
 "nodeid": {nid}, "depth": {depth}, "split": "{fname}", "split_condition": {cond}, "yes": {left}, "no": {right}, "missing": {missing}
, "gain": {loss_chg}, "cover": {sum_hess}
 "nodeid": {nid}, "depth": {depth}, "split": {fname}, "split_condition": {cond}, "yes": {left}, "no": {right}, "missing": {missing}
{{properties} {stat}, "children": [{left}, {right}
{indent}]}
{properties}
{indent}
{ "nodeid": {nid}, "leaf": {leaf} {stat}}
, "cover": {sum_hess} 
{newline}{indent}{nodes}
{newline}
yes_color
#0000FF
Edge color when meets the node condition.
no_color
#FF0000
Edge color when doesn't meet the node condition.
rankdir
Passed to graphiz via graph_attr.
condition_node_params
Conditional node configuration
leaf_node_params
Leaf node configuration
graph_attrs
Any other extra attributes for graphviz `graph_attr`.
Failed to parse graphviz parameters:
edge
    graph [ {key}="{value}" ]
{key}
{value}
The following parameters for graphviz are not recognized:
ch == '{'
, JSON object expect '}' or ',' '
ch == ':'
, Expect ':' but get '
ch == '\"'
, Expect '"' but get '
unknown string escape \
, Expect '"' but reach end of line 
    {nid} [ label="{fname}{<}{cond}" {params}]
{params}
    {nid} -> {child} [label="{is_missing}" color="{color}"]
{child}
{color}
{is_missing}
yes, missing
    {nid} [ label="leaf={leaf-value}" {params}]
{leaf-value}
{parent}
{left}
{right}
digraph {
    graph [ rankdir={rankdir} ]
{graph_attrs}
{nodes}}
{rankdir}
{graph_attrs}
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/data/ellpack_page.cc
Internal Error: XGBoost is not compiled with CUDA but EllpackPage is required
/Library/Caches/com.apple.xbs/Sources/CoreML_Sim/xgboost/src/gbm/gbtree_model.cc
param.num_trees == static_cast<int32_t>(trees.size())
GBTree: invalid model file
fi->Read(dmlc::BeginPtr(tree_info), sizeof(int32_t) * param.num_trees) == sizeof(int32_t) * param.num_trees
param.num_trees == static_cast<int>(trees.size())
gbtree_model_param
trees
tree_info
worker
rabit_reduce_buffer
256MB
DMLC_TASK_ID
DMLC_ROLE
DMLC_NUM_ATTEMPT
DMLC_TRACKER_URI
DMLC_TRACKER_PORT
DMLC_WORKER_CONNECT_RETRY
DMLC_WORKER_STOP_PROCESS_ON_ERROR
%[^=]=%s
mapred_tip_id
mapreduce_task_id
hadoop_mode is set but cannot find mapred_task_id
rabit_task_id
rabit_hadoop_mode
mapred_task_id
rabit_num_trial
mapred_map_tasks
mapreduce_job_maps
hadoop_mode is set but cannot find mapred_map_tasks
rabit_world_size
Rabit Module currently only work with dmlc worker, quit this program by exit 0
can only call Init once
start
shutdown
failed to shutdown due to %s
print
rabit_tracker_uri
rabit_tracker_port
rabit_reduce_ring_mincount
rabit_reduce_ring_mincount should be greater than 0
invalid value of DMLC_WORKER_STOP_PROCESS_ON_ERROR
rabit_debug
rabit_timeout
rabit_timeout_sec
rabit_timeout_sec should be non negative second
connect to (failed): [%s]
Connect
retry connect to ip(retry time %d): [%s]
ReConnectLink failure 1
ReConnectLink failure 2
sync::Invalid tracker message, init failure
ReConnectLink failure 3
ReConnectLink failure 4
must keep rank to same if the node already have one
ReConnectLink fail to bind the ports specified
ReConnectLink failure 5
ReConnectLink failure 6
ReConnectLink failure 7
ReConnectLink failure 8
ReConnectLink failure 9
ReConnectLink failure 10
ReConnectLink failure 12
ReConnectLink failure 13
ReConnectLink failure, link rank inconsistent
Override a link that is active
ReConnectLink failure 14
ReConnectLink failure 15
ReConnectLink: bad socket
cannot find parent in the link
cannot find prev ring in the link
cannot find next ring in the link
failed in ReconnectLink %s
buffer size inconsistent
must assign buffer_size
Allreduce: size check
Allreduce: boundary error
Broadcast: root should be smaller than world size
need to assume rank structure
write ptr boundary check
[%d] read_ptr boundary check
fail to get host name
error during send SendStr
%lu%c
invalid format for %s
invalid format for %s,shhould be {integer}{unit}, unit can be {B, KB, MB, GB}
Create
cannot obtain address of %s
Does not support IPv6
SendAll
RecvAll
SetKeepAlive
SO_LINGER
0.0.0.0
TryBindHost
error during send RecvStr
Accept
SetNonBlock-1
SetNonBlock-2
Allreduce failed
Broadcast failed
InitAfterException: not implemented
