[[SSMLESCAPED]]
[[[SSMLESCAPED]]]
%@<say-as interpret-as="characters">%@</say-as>%@
%@<break time="%%dms" />%@
<mark name="%@" />
%@%@%@
<speak>
</speak>
v8@?0
%@(?<enclosedssml>((.|\n)*?))%@
(?<delimiter>(%@|%@))
delimiter
enclosedssml
\amp;
\quot;
\#39;
\#47;
\gt;
\lt;
STARTED
DID NOT START
v12@?0B8
v28@?0@"AVAudioPCMBuffer"8@"NSArray"16B24
-[TTSSynthesisProviderSpeechServer supportedIPAPhonemeLanguages]
-[TTSSynthesisProviderSpeechServer synthesizerInstanceDestroyed:]
-[TTSSynthesisProviderSpeechServer employSpeechMarkupForType:language:]
-[TTSSynthesisProviderSpeechServer audioFileSettingsForVoice:]
-[TTSSynthesisProviderSpeechServer isSiriService]
-[TTSSynthesisProviderSpeechServer isNashvilleService]
-[TTSSynthesisProviderSpeechServer canInitializeSpeech:]
-[TTSSynthesisProviderSpeechServer loadedVoiceResources]
+[TTSSynthesisProviderSpeechServer regexRules]
TTSErrorDomain
originalString
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
ignoreCase
appliesToAllApps
uuid
replacementRange
%@: Original: %@, Replacement: %@, Phonemes: %@, Languages: %@
ttsaudioqueue
com.apple.speech.synthesis.voice.alex
com.apple.speech.synthesis.voice.bruce
com.apple.speech.synthesis.voice.fred
com.apple.speech.synthesis.voice.agnes
com.apple.speech.synthesis.voice.princess
com.apple.speech.synthesis.voice.albert
com.apple.speech.synthesis.voice.kathy
com.apple.speech.synthesis.voice.bells
com.apple.speech.synthesis.voice.badnews
com.apple.speech.synthesis.voice.deranged
com.apple.speech.synthesis.voice.hysterical
com.apple.speech.synthesis.voice.junior
com.apple.speech.synthesis.voice.organ
com.apple.speech.synthesis.voice.bahh
com.apple.speech.synthesis.voice.zarvox
com.apple.speech.synthesis.voice.ralph
com.apple.speech.synthesis.voice.boing
com.apple.speech.synthesis.voice.cellos
com.apple.speech.synthesis.voice.goodnews
com.apple.speech.synthesis.voice.bubbles
com.apple.speech.synthesis.voice.trinoids
com.apple.speech.synthesis.voice.whisper
com.apple.speech.synthesis.voice.victoria
com.apple.speech.synthesis.voice.vicki
(?<root>com\.apple\.speech\.synthesis\.voice\.custom\.siri\.[^.]*)(\.(?<quality>(premium|compact)))?$
com\.apple\.speech\.synthesis\.voice\.(?<name>[^.]*)(\.(?<quality>premium|compact))?$
com\.apple\.ttsbundle\.(?<name>[^.]*)\-(?<quality>premium|compact|Premium|Compact)$
TTSCachedVoiceIdentifiersToMigrateKey
TTSCachedIsMigrationCompleteKey
com.apple.speech.voice.Alex
com.apple.speech.synthesis.voice.Alex
name
quality
%@.%@.%@.%@
_male
_female
com.apple.maui.voice
premium
enhanced
high
.maui.
%@.compact
%@.%@
%@_%@_%@_premium
AFLocalization
Class getAFLocalizationClass(void)_block_invoke
TTSAXResourceMigrationUtilities.m
Unable to find class %s
void *AssistantServicesLibrary(void)
com.apple.MobileAsset.VoiceServices.VoiceResources
voice_configs.plist
ar-001
ar-SA
nb-NO
no-NO
TextToSpeech.VoiceResources
v32@?0d8q16q24
v16@?0@"TTSAsset"8
Accessibility
Download failed
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
Invalid
MacinTalk
Gryphon
Custom
Maui
Kona
LegacyCombinedVocalizer
LegacyVocalizer
SynthesizerExtension
None
Hydra
SiriNeural
Contents
Contents/VoiceBundle
AssetData
Name
VoiceId
Languages
Type
Subtype
Footprint
Gender
MemoryPeak
Build
VoiceAsset
Sample
NoveltyVoice
AssetSize
IsInstalled
CanBeDownloaded
AssetId
SpeechVoice
componentSubType
synthesizerBundleIdentifier
com.apple.speech.MacinTalkFramework.MacinTalkAUSP
com.apple.speech.MacinTalkFramework
mctk
Apple
SpeechVoiceNames
com.apple.ax.KonaTTSSupport.KonaSynthesizer
%@_VOICE_WITH_NAME
TTSAXResource<%p> Name:%@ ID:%@ Type:[%ld:%ld] Foot:%ld Langs:[%@] Installed:%ld
com.apple.voiceservices.language
com.apple.SpeakSelection
en-US
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
IPHONE_SIMULATOR_ROOT
zh-Hans
zh-CN
com.apple.language.changed
TTSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
vocalizer_resources
ax_resources
ax_gryphon_resource_order
ax_compact_resource_order
vocalizer_resource_order
_voices
default
legacy
Voice resource, Languages: %@, ContentVersion: %@, MasteredVersion: %@
_languages
_searchPathURL
s5l8942x
s5l8947x
s5l8950x
s5l8955x
s5l8960x
t7001
s7002
t8002
q24@?0@8@16
filename
mime-type
InternalBuild
DisableGryphon
com.apple.voiced
HardwarePlatform
range
com.apple.voiceservices.assetInstalled
/System/Library/PrivateFrameworks/VoiceServices.framework
/System/Library/PrivateFrameworks/TextToSpeech.framework
/System/Library/PrivateFrameworks/TextToSpeechMauiSupport.framework
TTSResources
broker.hdr.asset
broker.hdr
FormatVersion
Language
VoiceName
common
Tones
voice_format_version.plist
com.apple.voiceservices.class
title
TTSSynthesisProviderCachedComponentsKey
com.apple.TTS.synthProviderVoicesDidUpdate
com.apple.accessibility.systemvoiceprovider
auDescType
auDescSubType
auDescManufacturer
auDescFlags
auDescFlagsMask
bundleIdentifier
containerBundleIdentifier
version
isFirstParty
voices
%@ %@ %@
auspmanager.voiceloading
auspmanager.componentquery
B32@?0@"TTSSynthesisProviderComponentRecord"8Q16^B24
B32@?0@"AVAudioUnitComponent"8Q16^B24
@16@?0@"AVAudioUnitComponent"8
@16@?0@"AVSpeechSynthesisProviderVoice"8
v24@?0@"AVAudioUnit"8@"NSError"16
com.apple.siri.SiriTTSService.synthesizer
TTSEnableSiriSynthesisProvider
Contents/%@.caf
Info.plist
MobileAssetProperties
com.apple.speech.synthesis.voice.Vicki
AllCachedAvailableResourcesKey
TTSResourceCacheVersionKey
TTSCachedBuildNumberKey
com.accessibility.resourcepref
com.accessibility.asset-loading
%@=%@ 
v32@?0@"NSString"8@"NSArray"16^B24
v16@?0@"<TTSAXResourceManagerObserver>"8
v28@?0d8B16@"NSError"20
@unionOfArrays.self
B32@?0@"TTSAXResource"8Q16^B24
com.apple.voice.compact
compact
super-compact
^[^-]{2,3}-[^-]{2,3}(-[^-]{2,3})?$
B32@?0@"TTSSpeechVoice"8Q16^B24
@16@?0@"TTSSpeechVoice"8
@16@?0@"TTSAXResource"8
@16@?0@"TTSVoiceAsset"8
Alex
v24@?0@"NSArray"8@"NSError"16
GeneralLanguageCodeMap
VoiceIdSampleStringMap
CanonicalLanguageCodeVoiceNamesMap
plist
FALLBACK_SAMPLE_TEXT
[%@ %p] %@ language: %@ footprint: %@ rate: %lf pitch: %lf volume: %lf
textForAttributes
attributes
text
languageCode
voice
outputPath
gender
rate
pitch
volume
maintainsInput
audioSessionIDIsValid
audioSessionID
audioQueueFlags
ssmlRepresentation
synthesisProviderVoice
premium-high
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
VoiceVersion
Version
_CompatibilityVersion
_MasteredVersion
male
female
neural
CombinedVoiceProject
LanguagesCompatibility
.compact.
.super-compact.
.premium.
kTTSSynthesisProviderVoiceAttributeGroupName
com.apple.SynthesisProvider.updatedVoices
%c%c%c%c
AU Desc: (Manufacturer: %u) (Type: %u) (SubType: %u) (Flags: %u) (Flag Mask: %u)
%@_%@_%@
%@_%@
AU Desc: (Manufacturer: %@) (Type: %@) (SubType: %@) (Flags: %u) (Flag Mask: %u)
[%@ %p] Name: %@, Identifier: %@, Supported Languages %@, Age: %li, Gender: %li, Size: %lli, Version: %@
%@, AUComponent %@
identifier
supportedLanguages
primaryLanguages
voiceSize
manufacturerName
extraAttributes
com.apple.ttsbundle
com.apple.ttsbundle.siri
com.apple.ttsbundle.gryphon
com.apple.ttsbundle.gryphon-neural
com.apple.speech.synthesis.voice
com.apple.voice
speech.synthesis.provider.
AllCachedAvailableVoicesKey
language-creation
System/Library/TTSPlugins
speechbundle
original
replacement
q24@?0@"TTSSpeechVoice"8@"TTSSpeechVoice"16
TTSSpeechSynthesizer
v32@?0@"TTSSubstitution"8Q16^B24
he-IL
ja-JP
\b%@\b
(?<=\s|^)%@(?=\s|$)
q24@?0@"NSDictionary"8@"NSDictionary"16
speech string is empty
siri
identifier == %@
not currently speaking
no active speech job
TTSAudioSessionChannel -> %@
v16@?0@"NSArray"8
%@[%p]: Name: %@ Identifier: %@ Footprint: %d Language: %@ Gender: %@ [default %d] [fallbackDefault: %d] Provider: %@
language
footprint
isDefault
isFallbackDefault
canBeDownloaded
isNoveltyVoice
isSystemVoice
voiceType
serviceIdentifier
nonCombinedVoiceId
com.apple.eloquence
synthprovider.stateChange
synthprovider.playbackQueue
synthprovider.offlineRendering
v24@?0@"NSArray"8@"AVSpeechSynthesisProviderRequest"16
macintalk
v32@?0I8r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}12I20q24
v24@?0@"AVAudioPCMBuffer"8B16B20
@16@?0@"AVSpeechSynthesisMarker"8
B32@?0@"TTSStringTransformation"8Q16^B24
q24@?0@"TTSStringTransformation"8@"TTSStringTransformation"16
%@ Name: %@, Languages: %@, Gender: %@, Footprint: %@, Neural: %@, Installed: %@, Version: %@/%@
_name
_gender
_footprint
_isInstalled
_isBuiltInVoice
_voicePath
_neural
fileSizeWithNumber
MasteredVersion
CompatabilityVersion
ContentVersion
VoicePath
com.apple.Accessibility
TTSRosebud
Default
Compact
Super Compact
Premium
Premium High
Male
Female
pt-BR
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
PTQ+ABwag03BwO/CKvIK/A
HWModelStr
n111
n121
Maged
bg-BG
Daria
ca-ES
Montserrat
hr-HR
Lana
uk-UA
Lesya
vi-VN
Linh
ms-MY
Amira
Sinji
cs-CZ
Zuzana
da-DK
Sara
nl-BE
Ellen
nl-NL
Xander
en-AU
Karen
en-IE
Moira
Daniel
Samantha
en-IN
Rishi
en-ZA
Tessa
fi-FI
Satu
fr-CA
Amelie
fr-FR
Thomas
de-DE
Anna
el-GR
Melina
Carmit
hi-IN
Lekha
hu-HU
Mariska
id-ID
Damayanti
it-IT
Alice
Kyoko
ko-KR
Yuna
Tingting
Meijia
Nora
pl-PL
Zosia
Luciana
pt-PT
Joana
ro-RO
Ioana
ru-RU
Milena
sk-SK
Laura
es-ES
Monica
es-MX
Paulina
sv-SE
Alva
th-TH
Kanya
tr-TR
Yelda
VSUtilities
Class getVSUtilitiesClass(void)_block_invoke
TTSSharedUtilities.m
void *VoiceServicesLibrary(void)
%@%i
ttsStartReplyBlockKey
ttsAudioSessionKey
ttsAudioDeviceKey
ttsAudioQueueFlags
VoiceProvider: Initializing server for %@
VoiceProvider: error creating ssml de-escaping regex: %@
VoiceProvider: error creating ssml delimiter regex: %@
VoiceProvider: cant find synthesizer for: %@
VoiceProvider: Converted request: %@
Retrieved Audio Session ID was different than requested!
VoiceProvider: Hit reply block of startSynthesizingSpeechRequest: %@
VoiceProvider: Could not start synthesis for request %@, converted from tts request %@
VoiceProvider: Pause at mark %@ speaking request: %@
VoiceProvider: [pause] cant find synthesizer for: %@
VoiceProvider: Request did not pause as expected for. %@
VoiceProvider: Warning: Unhandled TTSSpeechMark. Please implement.
VoiceProvider: [continue] cant find synthesizer for: %@
VoiceProvider: Continue Speech Request: %@
VoiceProvider: Could not continue speech request %@
VoiceProvider: Hit Stop speaking request: %@
VoiceProvider: [stop] cant find synthesizer for: %@
VoiceProvider: Warning: Unhandled TTSSpeechMark in stopSpeechRequest. Please implement.
VoiceProvider: Hit %s
VoiceProvider: Finished speaking %@
VoiceProvider: Did start speaking string at range (%@, %@)
VoiceProvider: Marker out of range! %@
TTSAQ: Failed to start on attempt %@
TTSAQ: Calling start on %@
TTSAQ: failed to start with err %@
TTSAQ: Calling stop on %@
TTSAQ: Audio session changed, rebuilding audio queue.
TTSAQ: Audio format changed, rebuilding audio queue.
TTSAQ: Audio queue flags changed to %@, rebuilding audio queue.
TTSAQ: Calling dispose on %@
TTSAQ: New AQ: %@
TTSAQ: Audio Queue stopped
TTSAQ: Audio Queue started
Migration is not complete, attempting to complete now.
Migration is complete, no need to restart.
Unable to find updated identifier for nil legacy identifier using language code: %@
No voice found for language code: %@. Attempting to find fallback language.
Found fallback language code: %@
Updated identifier: %@
Compact resource is not installed, falling back to on disk super-compact variant %@ => %@
Beginning download for compact resource from %@
Unable to complete migration for resource: %@, remaining voices to migrate: %@
Voices left to migrate: %@
Error writing migration complete flag to preferences: %@
Error unarchiving flag for completed migration: %@
Error, process other than axassetsd tried to write migration voice list to preferences
Error writing voices to migrate to preferences: %@
Error unarchiving voices to migrate: %@
SiriTTS returned nil deprecated voices. %@
Found installed voice resources for %@: %@
Downloading voice resources asset %@
Downloaded voice resources for %@
Error while attempting to unarchive the voiceConfigData: %@
Wrong voice type passed in %@
Reqeuesting cancel asset download
Canceled asset download
TTSAsset::listAssetsOfTypes (voiceTypes=%@ filter=%@): %@
Setting importance to %d
Could NOT set the thread priority
Successfully set the thread priority
Normal thread priority is %d
session interrupted
mediaserverd died
AUDIOSESSION: Setting up audio session
error setting HW sample rate: %ld
AUDIOSESSION: category = %d
error %ld setting audio category
error %ld setting bluetooth allowability
AUDIOSESSION: Bluetooth %sabled
active count went negative for input!
active count went negative for output!
active count went negative!
AUDIOSESSION: activity %d --> %s
AUDIOSESSION: Active --> FALSE
AUDIOSESSION: Active --> TRUE
error %ld activating or deactivating session for activity %ld
could not stop queue (%d)
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Couldn't initialize the engine voice format versions
[TTSSynthesisProviderRequestHandler init] Cannot use 0 bytes per frame!
Called completedRequestRendering more than once!
TTSVoiceProvider::Reconcile records: Source cache: %ld
  - %@
TTSVoiceProvider::Component cache updated with %@ additions and %@ evictions.
VoiceProvider: voice load failed for component %@ after %@ attempts.
VoiceProvider: Recovered cache entry for first party SSE %@
VoiceProvider audio component initialization error %@
VoiceProvider could not retrieve remote pid %@, subtype: %@
VoiceProvider voices returned nil for record %@
VoiceProvider loaded %@ voices for bundle identifier: %@
VoiceProvider voice load timed out for record %@.
VoiceProvider: failed to set component cache preference %@.
all voices %@
VoiceProvider: failed to read component cache preference.
VoiceProvider: failed to decode component cache preference with exception: %@
Allowing Siri TTS service synthesizer
Skipping Siri TTS service synthesizer
Requesting resources. waitForInstalledAssets=%ld. Found resources in cache: %@
Requesting resources. waitForInstalledAssets=%ld. No resources found in cache. Setting resources to on-disk resources for maui/macintalk/legacy
Requesting resources. Found locally available resources: %@
Returning requesting resources. waitForInstalledAssets=%ld. %@
Updating in-memory resources: %@
Running block to compute expensive resources
Will ask assetController to refresh only-installed TTSResource AXAssets now
Tried to merge in installed assets before initial in-memory cache build.
Updating cache after computing expensive resources
Will merge in expensive resources. sync=%ld
Samples asset has not been initialized, attempting to read from mobile asset.
Samples asset was nil, it has not been downloaded yet.
Samples asset has been found: %@
Will refresh resources for type: %@
Failed to load maui/macintalk on-disk resources. Could not find maui framework!
Will ask assetController to refresh TTSResource AXAssets now
Requested axassetsd to rebuild the preferences cache
No download resource in _stopDownloadSiriVoiceAssetWithResource:
No asset for resource: %@
Stopped downloading %@
No resource for download: %@
Resource already installed: %@
Started downloading %@
No resource in _downloadSiriVoiceAssetWithResource:
Cannot download Siri asset. No asset instance found for resource: %@
Will ask SiriTTS to download asset: %@
Siri asset download progress: %{public}@ %{public}f
Speech sample DL: Already downloaded. Bailing
Speech sample DL: Already in progress. downloadingSamples=%ld samplesAsset.isDownloading=%ld
Speech sample DL: Could not find sample asset to download.
Speech sample DL: About to kick off download.
Speech sample DL: Samples started download.
Error, attempted to delete asset that is not installed.
Multiple default resources found for language: %@. Returning one at random
No default resources found for language: %@. 
Will find local resources at path: %@
Error reading languages in for local resources.
Error creating language-code regex: %@
Invalid directory format %@
Error reading in local voices for language %@.
Resource for %@ is nil
Did find local resources at path: %@. %@
Attempted to play a sample, but not sample assets were found
Requesting refreshed TTSResource assets (sync). onlyInstalled=%ld
Resetting in-memory resources to nil
Error: A process other than axassetsd attempted to write to the preferences cache.
No resource cache version found in preferences
Read resource cache version from preferences: %@
No catalog build number found in preferences
Read catalog build number from preferences: %@
Error: A process other than axassetsd attempted to write the build version to user preferences.
Cache version mismatch. Returning nil for resource preferences.
No resource data found in preferences
Error unarchiving resources: %@
Error unarchiving resources: unexpected type %@
Read resources cache from preferences: %@
Error writing resources to preferences: %@
AXAssetControllerObserver: Download completed for resource: %@ with asset: %@
Download failed: %@, %@
Download succeeded: %@
No download resource %@
DL progress: %{public}@ %{public}f
Will find Siri resources. onlyInstalled=%ld
Error: TTSAsset had nil name %@ or identifier %@. Asset: %@
Error: TTSAsset was nil while refreshing siri resources
Returning Siri resources (onlyInstalled=%ld): %@
Will find resources for synthesis providers
TTSAXResource.init was nil. Name must be provided in data
Did find %ld resources for synthesis providers
Will find resources for legacy assets
Legacy combined vocalizer asset or asset properties were nil: [Asset]: %@, [Asset Name]: %@, [Asset Languages]: %@, [Asset Gender]: %@, [Compact Identifier]: %@, [Premium Identifier]: %@
Returning Legacy resources: %@
Will find Macintalk resources
Did find %ld Macintalk resources
Will download legacy resource for testing: %@
Cannot download voice for testing. No assset found for ID: %@
Downloading legacy asset for testing: %@ %@
Received notification: %@. Will reset in-memory resources
Error reading general language code data.
Error reading sample string data.
Unable to find language code for voice name: %@
%@ requested speech voices be updated
Speech Error: %@
Skipping %@ since unified speech is enabled
Bundle err: %@
Unable to find voice service for identifier: %@, voice: %@, resource: %@
Could not find voice for identifier: %@
Media services reset
replacements order %@
Will replace: %@ in range %@ for %@
Error creating SSML %@
File did not exist at content path: %@ %@. Attempting to fallback to default voice for language: %@
Error: Unable to speak. No speech service: voice: %@ identifier: %@, language: %@, resource: %@
Error: Unable to speak. No request owner: service: %@ identifier: %@, language: %@
We do not have a record of this request owner: %@ [%@]
Speech processing error: [%@] / mark: %@ / range: %@, %@
Channel should not be nil. Are we deallocating the TTSAudioSessionChannel but holding a reference to it, perhaps in our unit tests?
Phonemes retrieved: %@
There was no speech service used to initiate audio
TextToSpeech-PlaybackStarted
AudioUnit had no output busses.
AudioUnit had no audioUnitOutputFormat.
Error initializing offline engine %@
Could not start offline engine. Error: %@
Setting up new AU for voice %@
Will start synthesizing with component description %@
Error: Already had an AU (%@, %@) while expecting to instantiate new AU (%@, %@)
Component was nil
VoiceProvider: Failed to start audio player.
Couldn't find audio unit for request %{public}@
Asked AU to synthesize %@
Now rendering %@
Realtime audio stopped during offline rendering.
Audio Unit encountered an error after sending some valid buffer.
Audio Unit failed to start after %li attempts.
Audio Unit reinitialization attempt failed.
Audio Unit reinitialization attempt succeeded! Continuing render.
SSEOfflineRenderFirstBuffer
SSEOfflineRender
Audio Unit render loop exited without completing.
Pausing immediately
VoiceProvider**: Stopping immediately
Received markers %@, for request %@
VoiceProvider**: Stopping at mark %@
VoiceProvider**: Pausing at mark %@
VoiceProvider**: Beginning deferred stop
VoiceProvider: ignoring playback request for old speech job.
playAndFlush: No more request handlers found.
VoiceProvider**: exiting buffer scheduling loop for canceled speech request.
VoiceProvider**: Ignoring AVFoundation completion callback since player should be stopped.
SSEFirstBuffer
Error creating regex %@
Invalid language format was used to initialize TTS voice asset
?333333
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
TTSSynthesisProviderSpeechServer
TTSSynthesisProviderAudioEngineProtocol
TTSSpeechService
NSObject
TTSSpeechSynthesizerDelegate
TTSSpeechServiceUnitTesting
TTSSubstitution
NSSecureCoding
NSCoding
NSCopying
TTSWrappedAudioQueueBuffer
TTSWrappedAudioQueue
TTSSynthesisProviderAudioOutput
TTSAXResourceMigrationUtilities
TTSSiriAssetManager
TTSAssetBase
TTSAXResource
TTSAudioSession
TTSVoiceResourceAsset
VocalizerUtilities
TTSSpeechAdditions
TTSFormatArgument
TTSSynthesisProviderPlayableBuffer
TTSSynthesisProviderRequestHandler
TTSSynthesisProviderComponentRecord
TTSSynthesisProviderVoiceManager
TextToSpeech
TTSAXResourceManager
AXAssetControllerObserver
TTSLocaleUtilities
TTSSpeechRequest
TTSWordMarker
TTSMarker
TTSPhonemeMarker
TTSGenericMarker
AXSpeechPublicInterface_Private
TTSSpeechSynthesizer
TTSSpeechConnectionDelegate
D"##
TTSAudioSessionChannel
IPAPhonemeSupport
TTSSpeechRequestOwner
TTSSpeechRequestDelegate
TTSSpeechVoice
SynthesisProviderAdditions
TTSSynthesisProviderAudioEngine
TTSSynthesisProviderHandlerDelegate
TTSStringTransformation
TTSSpeechString
TTSRegexCache
TTSVoiceAsset
TTSProviderUtility
BinaryStringRepresentation
init
dictionary
speechEngines
numberWithUnsignedLongLong:
objectForKeyedSubscript:
synthesizerInstanceID
_speechEngineForSynthesizerInstance:
isSpeechActive
setDelegate:
setObject:forKeyedSubscript:
synthesisProviderVoice
_escapeSSML:
stringWithFormat:
initWithString:
floatValue
setRate:
setVolume:
setPitchMultiplier:
shared
generateSSMLFromAVSpeechUtterance:
error
ssmlResult
stringByReplacingOccurrencesOfString:withString:
escapedPatternForString:
regularExpressionWithPattern:options:error:
copy
length
matchesInString:options:range:
countByEnumeratingWithState:objects:count:
rangeWithName:
substringWithRange:
isEqualToString:
range
stringByPaddingToLength:withString:startingAtIndex:
stringByReplacingCharactersInRange:withString:
initWithOriginalString:
reverseObjectEnumerator
transformRange:to:
errorWithDomain:code:userInfo:
speechRequestDidStopWithSuccess:phonemesSpoken:forService:error:
ssmlRepresentation
_unescapeDelimeterBoundedSSMLInString:
setSpeechString:
speechString
transformedString
setSsmlRepresentation:
AVSpeechSynthesisProviderRequestFromTTSSpeechRequest:
valueWithNonretainedObject:
requestMapping
setObject:forKey:
audioSessionID
retrieveSessionWithID:
opaqueSessionID
setAudioSession:
audioQueueFlags
setAudioQueueFlags:
speechRequestDidStartForService:
audioBufferCallback
synthesizeSilently
startSynthesizingSpeechRequest:withBufferCallback:silently:reply:
numberWithInteger:
speechRequestDidPauseForService:
pauseImmediately:
AVMarkerMarkFromTTSMark:
pauseAtMark:reply:
speechRequestDidContinueForService:
continueSpeechRequest:
stopImmediately:
stopAtMark:reply:
objectForKey:
removeObjectForKey:
mark
textRange
translateRangeInTransformedString:
originalString
_nonSSMLSubstringRangeForRange:fromSSML:
numberWithUnsignedInteger:
setWordRange:
markName
setName:
phoneme
setPhoneme:
_ttsMarkerForSSEMarker:forRequest:
speechRequestMarker:didStartForService:
convertRange:forSSML:
convertedRange
getVoicesForLanguage:reply:
setServiceQueue:
regexRules
synthesisProviderDidFinishSpeakingRequest:successfully:withError:
synthesisProviderDidStartSpeakingMarker:forRequest:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
initializeSpeechServerInstance:
synthesizerInstanceDestroyed:
setServiceQueue:forSynthesizerInstanceID:
startSpeechRequest:
pauseSpeechRequest:atMark:
stopSpeechRequest:atMark:
getVoicesForLanguage:queryingMobileAssets:reply:
getSpeechIsActiveForRequest:reply:
supportedIPAPhonemeLanguages
speechMarkupStringForType:voice:string:
isVoiceValid:
employSpeechMarkupForType:language:
lhPhonemesFromIPA:language:
phonemesFromIPA:language:
phonemesFromLHPhonemes:language:
enclosedStringWithPhonemes:
nashvilleVoiceIdentifier:footprint:voiceType:gender:assetVoiceName:
nashvilleVoiceName:footprint:voiceType:gender:assetVoiceName:
embeddedRateMarkupForVoice:string:rate:
embeddedPitchMarkupForVoice:string:pitch:
embeddedVolumeMarkupForVoice:string:volume:
combinedProsodyMarkupForVoice:string:rate:pitch:volume:
genericMarkerMarkupForVoice:name:
audioFileSettingsForVoice:
serviceIdentifier
isSiriService
isNashvilleService
isSiriNeuralVoice:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didEncounterMarker:forRequest:
speechSynthesizer:didSynthesizeSilentlyToURL:forRequest:
canInitializeSpeech:
loadedVoiceResources
serviceQueue
setRequestMapping:
setSpeechEngines:
.cxx_destruct
_serviceQueue
_requestMapping
_speechEngines
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceQueue
T@"NSMutableDictionary",&,N,V_requestMapping
T@"NSMutableDictionary",&,N,V_speechEngines
UUID
setUuid:
setIgnoreCase:
setAppliesToAllApps:
decodeObjectOfClass:forKey:
setOriginalString:
setReplacementString:
setPhonemes:
setWithObjects:
decodeObjectOfClasses:forKey:
setLanguages:
setVoiceIds:
setBundleIdentifiers:
decodeBoolForKey:
setActive:
rangeValue
setReplacementRange:
encodeObject:forKey:
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
encodeBool:forKey:
ignoreCase
appliesToAllApps
uuid
replacementRange
valueWithRange:
dealloc
allocWithZone:
alphanumericCharacterSet
invertedSet
stringByTrimmingCharactersInSet:
substringToIndex:
substringFromIndex:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
isReplacementTextAllPunctuation
isReplacementTextSurroundedByPunctuation
isUserSubstitution
setIsUserSubstitution:
_active
_ignoreCase
_appliesToAllApps
_isReplacementTextAllPunctuation
_isReplacementTextSurroundedByPunctuation
_isUserSubstitution
_originalString
_replacementString
_phonemes
_languages
_voiceIds
_uuid
_bundleIdentifiers
_replacementRange
T@"NSUUID",&,N,V_uuid
T@"NSString",C,N,V_originalString
T@"NSString",C,N,V_replacementString
T@"NSString",C,N,V_phonemes
T@"NSSet",C,N,V_languages
T@"NSSet",C,N,V_voiceIds
TB,N,V_active
TB,N,V_ignoreCase
T{_NSRange=QQ},N,V_replacementRange
TB,N,V_appliesToAllApps
T@"NSSet",C,N,V_bundleIdentifiers
TB,R,N,V_isReplacementTextAllPunctuation
TB,R,N,V_isReplacementTextSurroundedByPunctuation
TB,N,V_isUserSubstitution
byteSize
aqBuffer
setAqBuffer:
completionHandler
setCompletionHandler:
_aqBuffer
_completionHandler
T^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I},N,V_aqBuffer
T@?,C,N,V_completionHandler
TQ,R,N
initWithCommonFormat:sampleRate:channels:interleaved:
_tearDownAudioQueue
state
frameLength
format
streamDescription
availableBuffers
count
allKeys
firstObject
aqRef
_minimumBufferByteSize
numberWithLong:
inflightBuffers
buffersAvailable
wait
scheduleBuffer:completionHandler:
audioBufferList
audioQueueDispatchQueue
_play
sleepForTimeInterval:
shouldRebuildAudioQueue
setShouldRebuildAudioQueue:
_rebuildAudioQueue
setState:
audioQueueActive
audioSession
setPreferredIOBufferDuration:error:
setFormat:
numberWithUnsignedInt:
date
timeIntervalSince1970
setLastActiveTime:
broadcast
sampleRate
setAqRef:
setAvailableBuffers:
setInflightBuffers:
play
pause
stop
setOutputFormat:
isRunning
pokeAudio
bufferCallback:
setBuffersAvailable:
setAudioQueueDispatchQueue:
lastActiveTime
setAudioQueueActive:
_bufferLock
_shouldRebuildAudioQueue
_audioQueueActive
_audioQueueFlags
_aqRef
_format
_state
_buffersAvailable
_audioQueueDispatchQueue
_lastActiveTime
_inflightBuffers
_availableBuffers
_audioSession
T^{OpaqueAudioQueue=},N,V_aqRef
T@"AVAudioFormat",&,N,V_format
TQ,N,V_state
T@"NSCondition",&,N,V_buffersAvailable
T@"NSObject<OS_dispatch_queue>",&,N,V_audioQueueDispatchQueue
TI,N,V_audioQueueFlags
Td,N,V_lastActiveTime
TB,N,V_shouldRebuildAudioQueue
TB,V_audioQueueActive
T@"NSMutableDictionary",&,N,V_inflightBuffers
T@"NSMutableDictionary",&,N,V_availableBuffers
T@"AVAudioSession",&,N,V_audioSession
_readVoiceIdentifiersToMigrateFromPreferences
_readIsMigrationCompleteFromPreferences
isEqualToNumber:
isMigrationComplete
assetsService
restartTTSResourceMigration
lowercaseString
containsObject:
obsoleteVoicesWithReplacements
sharedInstance
regexForString:atStart:
firstMatchInString:options:range:
numberOfRanges
containsString:
capitalizedString
defaultVoiceIdentifierForGeneralLanguageCode:
languageCodeForResourceName:withType:
stringByAppendingFormat:
hasPrefix:
componentsSeparatedByString:
objectAtIndexedSubscript:
voiceNamesForOutputLanguageCode:gender:
allVoices:
language
identifier
hasSuffix:
gender
name
_remapGenderedSiriVoiceIdentifiers:
updatedIdentifierForLegacyIdentifier:withLanguageCode:
resourceWithVoiceId:
isInstalled
downloadResourceWithVoiceId:
deleteCompactResourceIfNeededForIdentifier:
allValues
voiceId
mutableCopy
writeVoiceIdentifiersToMigrateToPreferences:
writeIsMigrationCompleteToPreferences:
archivedDataWithRootObject:requiringSecureCoding:error:
initForReadingFromData:error:
arrayWithObjects:count:
setWithArray:
deprecatedVoicesMap
restartMigrationIfNeeded
legacyIdentifierForUpdatedIdentifierDuringMigration:
convertIdentifierIfNeeded:
downloadCompactResourceIfNeededForIdentifier:
resourceNeedsMigration:
resourceCompletedMigration:
setAssetsService:
setIsMigrationComplete:
setObsoleteVoicesWithReplacements:
_isMigrationComplete
_assetsService
_obsoleteVoicesWithReplacements
T@"AXAssetsService",&,N,V_assetsService
TB,N,V_isMigrationComplete
T@"NSDictionary",&,N,V_obsoleteVoicesWithReplacements
currentHandler
stringWithUTF8String:
handleFailureInFunction:file:lineNumber:description:
convertTTSLanguageCodeToSiriLanguageCode:
dictionaryWithObjects:forKeys:count:
voiceResources
bestAssetOfTypes:matching:
downloadWithReservation:useBattery:progress:then:
setBundleIdentifier:
versionNumber
stringValue
setMasteredVersion:
setCompatibilityVersion:
setContentVersion:
supportedLanguages
locallyAvailable
bundle
bundleURL
setSearchPathURL:
stringByDeletingPathExtension
propertyListWithData:options:format:error:
syncWithConfigData:voiceType:
URLByAppendingPathComponent:
syncWithConfigFile:voiceType:
compact
premium
premiumhigh
vocalizerVoice
customVoice
gryphonVoice
footprint
voiceType
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
technology
gryphon
neural
quality
string
initWithName:languages:gender:footprint:isInstalled:isBuiltIn:masteredVersion:compatibilityVersion:neural:
_voiceTypeForAssetTechnology:
bundlePath
setVoicePath:
setVoiceType:
setIdentifier:
downloading
setIsDownloading:
diskSize
unsignedIntValue
setFileSize:
ttsAssetFromVoiceAsset:
purgeImmediately:
cancelDownloadingThen:
assistantVoiceMaps
custom
vocalizer
_assetsForLanguage:voiceType:installedOnly:
_assetTechnologyForVoiceType:
_assetTypesForVoiceType:
listAssetsOfTypes:matching:
voiceAssetFromTTSAsset:
addObject:
allObjects
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:
_assetFilterForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
_footprintForType:
numberWithBool:
voiceResourceForLanguage:voiceType:onDiskData:
spaceCheck:
purgeAsset:
assetIsDownloading:
stopDownload:
downloadAsset:progressHandler:
assetsForLanguage:voiceType:
installedAssetsForLanguage:voiceType:
installedAssetForLanguage:gender:footprint:voiceName:voiceType:
assetForLanguage:gender:footprint:voiceName:voiceType:
bundleIdentifier
compatibilityVersion
contentVersion
masteredVersion
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
properties
initWithData:
_resourceTypeFromStringInput:
_resourceSubtypeFromStringInput:
_resourceFootprintFromStringInput:
_resourceGenderFromStringInput:
boolValue
integerValue
_ensureMacinTalkComponent
voiceAsset
axAsset
assetId
type
primaryLanguage
subtype
setVoiceAsset:
voicePath
_isSystemVoice
refreshAssetForResource:installedOnly:
setAxAsset:
localURL
bundleWithPath:
pathForResource:ofType:
fileURLWithPath:
path
stringByAppendingPathComponent:
memoryPeak
memoryPeakExceedsActiveJetsamLimit
fileSize
unarchivedFileSize
unsignedIntegerValue
downloadSize
setLanguage:
setFootprint:
canBeDownloaded
setCanBeDownloaded:
setIsSystemVoice:
isNoveltyVoice
setIsNoveltyVoice:
setGender:
_isDefault
setIsDefault:
synthesizerBundleIdentifier
componentSubType
initWithName:identifier:primaryLanguages:supportedLanguages:
setSynthesisProviderVoice:
setSynthesizerBundleIdentifier:
setAuComponentDesc:
setManufacturerName:
setIsFirstParty:
localizedName:forLanguage:
bundleForClass:
localizedName
speechVoice
uppercaseString
localizedStringForKey:
localizedStringWithFormat:
_isDennisVoice
componentsJoinedByString:
assetSize
decodeIntegerForKey:
encodeInteger:forKey:
initWithAsset:
contentPath
shouldFilterResourceFromUI
localizedNameWithFootprint
setAssetId:
setSpeechVoice:
setComponentSubType:
setAssetSize:
setIsInstalled:
setMemoryPeak:
_isNoveltyVoice
_isInstalled
_canBeDownloaded
_axAsset
_voiceAsset
_name
_voiceId
_type
_subtype
_gender
_assetId
_speechVoice
_synthesizerBundleIdentifier
_componentSubType
_footprint
_assetSize
_memoryPeak
T@"NSString",&,N,V_assetId
T@"TTSSpeechVoice",&,N,V_speechVoice
T@"NSString",&,N,V_synthesizerBundleIdentifier
T@"NSString",&,N,V_componentSubType
Tq,N,V_footprint
TQ,N,V_assetSize
TB,N,V_isInstalled
TB,N,V_canBeDownloaded
Tq,N,V_memoryPeak
T@"AXAsset",&,N,V_axAsset
T@"TTSVoiceAsset",&,N,V_voiceAsset
T@"NSArray",R,N,V_languages
T@"NSString",R,N,V_name
T@"NSString",R,N
T@"NSString",R,N,V_voiceId
TQ,R,N,V_type
TQ,R,N,V_subtype
Tq,R,N,V_gender
TB,R,N,V_isNoveltyVoice
cStringUsingEncoding:
stringByAppendingString:
defaultCenter
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
removeObserver:
userInfo
_setupAudioSession
setPreferredSampleRate:error:
code
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
doubleValue
currentRoute
inputs
objectAtIndex:
portType
dictionaryWithContentsOfURL:
array
indexOfObject:
compare:
sortedArrayUsingComparator:
setResourceList:
setVoiceConfig:
voiceConfig
legacyPlatforms
defaultVoice
defaultTypeString
defaultFootprintString
resourceList
searchPathURL
_resourceList
_searchPathURL
_voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSURL",C,N,V_searchPathURL
voice
vocalizerFootprint
vocalizerGender
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
stringByStandardizingPath
removeItemAtURL:error:
initWithContentsOfURL:
data
appendBytes:length:
dataUsingEncoding:
appendData:
filePathURL
attributesOfItemAtPath:error:
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
attributes
formattedArg
replaceCharactersInRange:withString:
setAttributes:range:
startFrameOffset
buffer
endFrameOffset
setStartFrameOffset:
setBuffer:
_startFrameOffset
_buffer
TI,N,V_startFrameOffset
TI,R,N
T@"AVAudioPCMBuffer",&,N,V_buffer
queuedMarkers
ax_enqueueObject:
currentAudioBufferFrameCount
setCurrentAudioBufferFrameCount:
delegate
managingSpeechRequest
didGeneratePlayableBuffers:forRequest:
isFinishedReceivingBuffers
setIsFinishedReceivingBuffers:
byteSampleOffset
bytesPerFrame
removeObject:
initWithRequest:bytesPerFrame:
addMarkers:
addBuffers:
completedRequestRendering
dequeueMarkersUpToFrame:
setManagingSpeechRequest:
setBytesPerFrame:
setQueuedMarkers:
_isFinishedReceivingBuffers
_currentAudioBufferFrameCount
_delegate
_managingSpeechRequest
_bytesPerFrame
_queuedMarkers
T@"AVSpeechSynthesisProviderRequest",&,N,V_managingSpeechRequest
TI,N,V_currentAudioBufferFrameCount
TQ,N,V_bytesPerFrame
T@"NSMutableArray",&,N,V_queuedMarkers
TB,N,V_isFinishedReceivingBuffers
T@"<TTSSynthesisProviderHandlerDelegate>",W,N,V_delegate
componentDescription
containerBundleIdentifier
version
isFirstParty
voices
setVoices:
setContainerBundleIdentifier:
setVersion:
intValue
setComponentDescription:
_isFirstParty
_containerBundleIdentifier
_version
_voices
_componentDescription
T{AudioComponentDescription=IIIII},N,V_componentDescription
T@"NSString",&,N,V_bundleIdentifier
T@"NSString",&,N,V_containerBundleIdentifier
T@"NSString",&,N,V_version
TB,N,V_isFirstParty
T@"NSArray",&,N,V_voices
reconcileCachedComponents
operationQueue
componentCache
_reconcileCachedComponents:
_reloadVoiceForBundleIdentifierPrefix:
_reloadVoiceForBundleIdentifierHash:
ax_filteredArrayUsingBlock:
macintalkAudioUnitProvider
sharedAudioUnitComponentManager
componentsMatchingDescription:
audioComponentDescription
_componentIsEqual:to:
versionString
indexOfObjectPassingTest:
removeObjectAtIndex:
ax_mappedArrayUsingBlock:
_loadVoicesForComponents:
addObjectsFromArray:
setComponentCache:
allSynthesisProviderVoices
synthesisProviderVoicesDidChange:
_loadVoicesForComponentRecord:dispatchGroup:
componentQueryQueue
_loadVoicesForComponentWithTimeout:timeout:
AUAudioUnit
remoteProcessIdentifier
informationForPlugInWithPid:
_synthesizerHasEntitlement:entitlement:
speechVoices
ax_arrayByRemovingDuplicates
manufacturerName
instantiateWithComponentDescription:options:completionHandler:
defaultCStringEncoding
allSynthesisProviderTTSVoices
voiceFromAVSpeechSynthesisProviderVoice:
remoteProcessAuditToken
voiceCache
resetInMemoryCache
T@"NSArray",&
T@"NSDictionary",R
T@"NSArray",R
reloadVoicesForBundleIdentifierPrefix:
reloadVoicesForBundleIdentifierHash:
purgeAndReloadAllComponents
_systemAudioUnitProviders
setOperationQueue:
setComponentQueryQueue:
_operationQueue
_componentQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_operationQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_componentQueryQueue
T@"<TTSSynthesisProviderVoiceManagerDelegate>",W,N,V_delegate
encodeBytes:length:forKey:
decodeBytesForKey:returnedLength:
tts_encodeBytes:size:forKey:
tts_decodeBytesIntoObject:size:forKey:
tts_encodeMatrixFloat4x4:forKey:
tts_decodeMatrixFloat4x4ForKey:
policy
assetControllerWithPolicy:qosClass:shouldRefreshForAssetInstallNotifications:
setUserInitiated:
addObserver:
weakObjectsHashTable
_readResourcesFromPreferences
_debugCountSummaryForResources:
_findLocalResourcesForPath:
addEntriesFromDictionary:
_getSynthesisProviderResources
_updateCachedResources:
_mergeInExpensiveInstalledAssets:notifyObservers:
appendString:
appendFormat:
enumerateKeysAndObjectsUsingBlock:
_findResourcesForLegacyAssets
_axAssetsForTTSAXResourceModel:
_resourcesForAssets:
_refreshSiriResources:
_dictionaryForResources:
_findAndSwapLegacyMacinTalkAssetsForMacinTalkResources:
setAllAvailableLanguages:
_notifyObserversOfCacheUpdate
assetLoadingQueue
_refreshSamples:
assetController
refreshAssetsWithAttributesSynchronously:installedOnly:
updateTTSResourcesForActionType:
resourceWithAssetId:
_downloadResource:userInitiated:
downloadResourceWithVoiceId:userInitiated:
_downloadSiriVoiceAssetWithResource:
_stopDownloadSiriVoiceAssetWithResource:
_stopDownloadResource:
finishedDownloadingResource:wasCancelled:
_performBlockOnObservers:
_refreshAssetForResource:withAssetController:installedOnly:
stopDownloadAsset:completion:
legacyCombinedVocalizerAssetController
downloadAssets:successStartBlock:
downloadProgressForVoiceId:progress:storageSize:requiredDiskSpace:
samplesAsset
fileExistsAtPath:
isDownloading
downloadingSamples
setDownloadingSamples:
setSamplesAsset:
_deleteResource:
_deleteSiriVoiceAssetWithResource:
legacyMacinTalkAssetController
purgeAssetsSynchronously:
rebuildSystemCacheForActionType:
finishedDeletingResource:
_resourcesWithType:subType:languageCode:
resources
valueForKeyPath:
_resourceWithVoiceId:assetId:
resourcesWithLanguage:type:
isDefault
resourcesWithType:subType:
contentsOfDirectoryAtPath:error:
dictionaryWithContentsOfFile:
ax_flatMappedArrayUsingBlock:
arrayByAddingObjectsFromArray:
setByAddingObjectsFromArray:
refreshInstalledAssetsSynchronously
refreshWithoutCatalogUpdateSynchronously
purgeInMemoryCachedAssets
resourceCacheDidReceiveUpdate
assetPolicy
updateAssetForPolicy:
_readCatalogBuildNumberFromPreferences
_refreshResourcesForManagerType:
preferenceWriteQueue
_writeResourceCacheVersionToPreferences
_writeResourcesToPreferences:
readResourceCacheVersionFromPreferences
unarchivedObjectOfClasses:fromData:error:
primaryLanguages
isAssetCatalogInstalled
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
downloadResourceWithAssetId:
stopDownloadResourceWithVoiceId:
downloadSamplesIfNecessary
deleteResourceWithAssetId:
deleteResourceWithVoiceId:
defaultVoiceForLanguage:
superCompactVoiceIdForCompactVoiceId:
speechVoiceWithVoiceId:
refreshedResourcesForResources:
sampleURLForVoiceId:
allLanguagesForVoices:
allAvailableLanguages
_managerTypeForResourceType:
_isValidResourceTypeKey:
resetResourcesCache
resetInMemoryAssetCatalogs
updateCatalogIfNeeded
catalogBuildVersion
refreshResourcesCacheForManagerType:
updateCatalogBuildVersion:
_downloadLegacyResourceForTesting:
setAssetController:
setLegacyCombinedVocalizerAssetController:
setLegacyMacinTalkAssetController:
setCatalogBuildVersion:
setPreferenceWriteQueue:
setAssetLoadingQueue:
_resourcesLock
_resourcesById
_resources
_observersLock
_observers
_downloadingSamples
_assetController
_legacyCombinedVocalizerAssetController
_legacyMacinTalkAssetController
_allAvailableLanguages
_samplesAsset
_catalogBuildVersion
_preferenceWriteQueue
_assetLoadingQueue
T@"AXAssetController",&,N,V_assetController
T@"AXAssetController",&,N,V_legacyCombinedVocalizerAssetController
T@"AXAssetController",&,N,V_legacyMacinTalkAssetController
T@"NSSet",&,N,V_allAvailableLanguages
T@"AXAsset",&,N,V_samplesAsset
T@"NSString",&,N,V_catalogBuildVersion
TB,N,V_downloadingSamples
T@"NSObject<OS_dispatch_queue>",&,N,V_preferenceWriteQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetLoadingQueue
generalLanguageCodeData
voiceIdSampleStringData
canonicalLanguageCodeVoiceNamesData
sampleStringForVoiceIdentifier:
defaultVoiceIdentifierForVoiceName:
setGeneralLanguageCodeData:
setVoiceIdSampleStringData:
setCanonicalLanguageCodeVoiceNamesData:
_generalLanguageCodeData
_voiceIdSampleStringData
_canonicalLanguageCodeVoiceNamesData
T@"NSDictionary",&,N,V_generalLanguageCodeData
T@"NSDictionary",&,N,V_voiceIdSampleStringData
T@"NSDictionary",&,N,V_canonicalLanguageCodeVoiceNamesData
encodeDouble:forKey:
encodeInt32:forKey:
setText:
setLanguageCode:
setVoice:
setOutputPath:
decodeDoubleForKey:
setPitch:
setMaintainsInput:
setAudioSessionIDIsValid:
decodeInt32ForKey:
setAudioSessionID:
decodePropertyListForKey:
speechRequestDidStart:forService:
speechRequestDidPause:forService:
speechRequestDidContinue:forService:
speechRequest:withMarker:didStartForService:
speechRequest:didStopWithSuccess:phonemesSpoken:forService:error:
speechRequest:didSynthesizeSilentlyToURL:
speechRequestDidSynthesizeSilentlyToURL:forService:
text
attributedText
setAttributedText:
languageCode
outputPath
rate
pitch
volume
maintainsInput
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
skipLuthorRules
setSkipLuthorRules:
audioSessionIDIsValid
latency
setLatency:
dispatchTime
setDispatchTime:
handledTime
setHandledTime:
useMonarchStyleRate
setUseMonarchStyleRate:
channels
setChannels:
setSynthesizerInstanceID:
clientContext
setClientContext:
setAudioBufferCallback:
originalWordRanges
setOriginalWordRanges:
processedWordRanges
setProcessedWordRanges:
replacedWords
setReplacedWords:
wordRangeCallbacksDispatched
setWordRangeCallbacksDispatched:
setSynthesizeSilently:
_maintainsInput
_supportsAccurateWordCallbacks
_skipLuthorRules
_audioSessionIDIsValid
_useMonarchStyleRate
_synthesizeSilently
_audioSessionID
_text
_attributedText
_voice
_ssmlRepresentation
_speechString
_synthesisProviderVoice
_languageCode
_outputPath
_rate
_pitch
_volume
_latency
_dispatchTime
_handledTime
_channels
_synthesizerInstanceID
_clientContext
_audioBufferCallback
_originalWordRanges
_processedWordRanges
_replacedWords
_wordRangeCallbacksDispatched
T@"NSString",C,N,V_text
T@"NSAttributedString",C,N,V_attributedText
T@"TTSSpeechVoice",C,N,V_voice
T@"NSString",C,N,V_ssmlRepresentation
T@"TTSSpeechString",&,N,V_speechString
T@"AVSpeechSynthesisProviderVoice",C,N,V_synthesisProviderVoice
T@"NSString",C,N,V_languageCode
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_maintainsInput
TB,N,V_supportsAccurateWordCallbacks
TB,N,V_skipLuthorRules
TB,N,V_audioSessionIDIsValid
TI,N,V_audioSessionID
Td,N,V_latency
Td,N,V_dispatchTime
Td,N,V_handledTime
TB,N,V_useMonarchStyleRate
T@"NSArray",&,N,V_channels
TQ,N,V_synthesizerInstanceID
T^v,N,V_clientContext
T@?,C,N,V_audioBufferCallback
T@"NSString",&,N,V_originalString
T@"NSMutableArray",&,N,V_originalWordRanges
T@"NSMutableArray",&,N,V_processedWordRanges
T@"NSMutableArray",&,N,V_replacedWords
Tq,N,V_wordRangeCallbacksDispatched
TB,N,V_synthesizeSilently
markType
Tq,R,N
wordRange
_wordRange
T{_NSRange=QQ},N,V_wordRange
alphabet
setAlphabet:
_phoneme
_alphabet
T@"NSString",&,N,V_phoneme
Tq,N,V_alphabet
T@"NSString",&,N,V_name
setSupportedLanguages:
setPrimaryLanguages:
setAge:
setVoiceSize:
mainBundle
extraAttributes
voiceSize
auComponentDesc
localeWithLocaleIdentifier:
formUnionWithCharacterSet:
numberWithLongLong:
longLongValue
decodeDictionaryWithKeysOfClasses:objectsOfClasses:forKey:
setExtraAttributes:
groupName
supportedCharacterSet
uniqueAudioDescTriple
uniqueAudioDescSpeechSynthTuple
fullBundleIdentifier
updateSpeechVoices
T@"NSArray",&,N
T@"NSDictionary",&,N
T{AudioComponentDescription=IIIII},N
T@"NSString",&,N
TB,N
initWithKeyOptions:valueOptions:capacity:
loadAndReturnError:
principalClass
voiceForIdentifier:
isSystemVoice
_initializeServers
setService:
_speechVoiceForIdentifier:language:footprint:
service
initWithSpeechService:
availableVoicesForLanguageCode:queryingMobileAssets:
sortUsingComparator:
lock
unlock
_mediaServicesDied
removeAllObjects
_stopSpeakingRequest:atNextBoundary:synchronously:error:
enumerateObjectsUsingBlock:
localizedUppercaseString
localizedLowercaseString
stringWithCharacters:length:
ignoreSubstitutions
_substitutionLanguageMatchesSpecialCase:withLanguage:
_skipSubstition:language:bundleIdentifier:voice:
punctuationCharacterSet
symbolCharacterSet
characterAtIndex:
characterIsMember:
rangeOfString:options:range:
_determineSubstitution:text:wordRange:request:
anyObject
isSSMLValid:
unavailableVoiceIdentifiers
outputChannels
_preprocessText:languageCode:
phonemeSubstitutions
userSubstitutions
_processUserSubstitutions:toText:request:bundleIdentifier:voice:
applySSMLTransformation:string:voice:
nonCombinedVoiceId
predicateWithFormat:
filteredArrayUsingPredicate:
request
stopCurrentSpeechRequestAtMark:waitUntilStopped:
pauseCurrentSpeechRequestAtMark:waitUntilPaused:
continueCurrentSpeechRequest
_setDelegate:
startSpeakingString:toURL:withLanguageCode:error:
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
stopSpeakingAtNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
lastObject
isSystemSpeakingOnBehalfOfCurrentConnection
unionSet:
delegateTargetQueue
_processMarker:forRequest:
initialize
isSystemVoice:
employSpeechMarkupForType:identifier:withLanguage:
genericMarkMarkupForIdentifier:name:
combinedProsodyMarkupForIdentifier:string:rate:pitch:volume:
speechMarkupStringForType:forIdentifier:string:
testingSetAllVoices:
setVoiceAssetsForTesting:
voiceAssetsForTesting
synthesizerForSynthesizerID:
voiceAccessQueue
setTestingAvailableVoicesForLanguageCode:
availableLanguageCodes
setSpeechJobFinishedUnitTestBlock:
setSpeechJobStartedUnitTestBlock:
remapVoiceIdentifier:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMarker:
connection:speechRequest:didSynthesizeSilentlyToURL:
testingLastRuleConversion
testingSetLastRuleConversion:replacement:
setOutputChannels:
setUserSubstitutions:
setPhonemeSubstitutions:
resolvedVoiceIdentifier
resolvedVoiceIdentifierForLanguageCode:
voiceIdentifier
startSpeakingString:error:
startSpeakingString:toURL:error:
startSpeakingString:withLanguageCode:error:
stopSpeakingAtNextBoundary:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingWithError:
isSpeaking
minimumRate
maximumRate
useSpecificAudioSession:
useAudioQueueFlags:
startSpeakingString:request:error:
startSpeakingString:withLanguageCode:request:error:
startSpeakingString:toURL:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
stopSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
continueSpeakingRequest:withError:
setDelegateTargetQueue:
setVoiceIdentifier:
requestClientIdentifier
setRequestClientIdentifier:
speakingRequestClientContext
setSpeakingRequestClientContext:
setIgnoreSubstitutions:
_useSharedSession
_currentRequestOwners
_speechRequests
_synthesizerFlags
_outputChannels
_testingLastRuleConversion
_ignoreSubstitutions
_delegateTargetQueue
_voiceIdentifier
_requestClientIdentifier
_speakingRequestClientContext
_userSubstitutions
_phonemeSubstitutions
T@"<TTSSpeechSynthesizerDelegate>",W,D,N
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateTargetQueue
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
T@"NSString",&,N,V_voiceIdentifier
TQ,N,V_requestClientIdentifier
T^v,N,V_speakingRequestClientContext
TI,R,N,V_audioSessionID
T@"NSArray",C,N,V_userSubstitutions
T@"NSArray",C,N,V_phonemeSubstitutions
TB,N,V_ignoreSubstitutions
setChannel:
channel
channelLabel
channelNumber
channelName
owningPortUID
channelWithChannel:
convertChannels:
setChannelName:
setChannelNumber:
setChannelLabel:
setOwningPortUID:
_channelLabel
_channel
_channelName
_channelNumber
_owningPortUID
T@"AVAudioSessionChannelDescription",&,N,V_channel
T@"NSString",&,N,V_channelName
TQ,N,V_channelNumber
TI,N,V_channelLabel
T@"NSString",&,N,V_owningPortUID
setIPASpeechPhonemes:
IPASpeechPhonemes
T@"NSString",&,D,N
setSpeechService:
speechService
_setRequest:
_request
_speechService
T@"<TTSSpeechService>",W,N,V_speechService
T@"<TTSSpeechConnectionDelegate>",W,N,V_delegate
T@"TTSSpeechRequest",R,N,V_request
isFallbackDefault
setNonCombinedVoiceId:
setServiceIdentifier:
localizedNameForLanguage:
excludeInAvailableVoiceList
isCombinedFootprint
_isFallbackDefault
_excludeInAvailableVoiceList
_isCombinedFootprint
_language
_identifier
_voiceType
_nonCombinedVoiceId
_serviceIdentifier
_service
T@"NSString",&,N,V_serviceIdentifier
T@"<TTSSpeechService>",W,N,V_service
T@"NSString",&,N,V_language
T@"NSString",&,N,V_identifier
TB,N,V_isDefault
TB,N,V_isSystemVoice
TB,R,N,V_isFallbackDefault
TB,R,N,V_excludeInAvailableVoiceList
Tq,N,V_voiceType
TB,N,V_isNoveltyVoice
TB,R,N,V_isCombinedFootprint
T@"NSString",&,N,V_nonCombinedVoiceId
T@"AVSpeechSynthesisProviderVoice",&,N,V_synthesisProviderVoice
receivedMarkers:forRequest:
audioUnitObservedToken
audioUnit
removeRenderObserver:
playerState
setPlayerState:
setBufferCallback:
setDeferredPlayerState:
offlineToRealtimePlayer
offlineRenderingQueue
currentRequestHandler
_finishRequestRendering
cancelSpeechRequest
setAudioUnitObservedToken:
_safelyCallDeferredReplyBlock:
deferredReplyBlock
setDeferredReplyBlock:
audioUnitOutputBus
audioUnitOutputFormat
setOfflineEngine:
avAudioUnit
maximumFramesToRender
offlineEngine
initWithStreamDescription:
enableManualRenderingMode:format:maximumFrameCount:error:
startAndReturnError:
attachNode:
outputNode
connect:to:format:
_setupAudioUnitForVoice:remote:
registerSubclass:asComponentDescription:name:version:
audioUnitName
setMaximumFramesToRender:
setRenderingOffline:
setAvAudioUnit:
markerBlock
setSpeechSynthesisOutputMetadataBlock:
_setupOfflineEngine
_setupAudioUnitForVoice:
setIsSynthesizingSilently:
setTtsServiceDidStartReplyBlock:
_startPlaying
renderSpeechRequest:
manualRenderingFormat
manualRenderingMaximumFrameCount
initWithPCMFormat:frameCapacity:
tokenByAddingRenderObserver:
frameCapacity
renderOffline:toBuffer:error:
safelyCallStartCompletionForRequest:didStart:
setCurrentRequestHandler:
synthesizeSpeechRequest:
renderWithObserver:
_pausePlaying
_stopPlaying
markerByteOffsetScalingFactor
setByteSampleOffset:
deferredStateChangeQueue
deferredPlayerState
playBuffers:forRequest:
setFrameLength:
playbackQueue
ax_dequeueObject
bufferCallback
isSynthesizingSilently
_handleMarkerPlayback:forRequest:
ttsServiceDidStartReplyBlock
outputBusses
prewarmAudioUnitForVoice:
startSynthesizingSpeechRequest:reply:
setOfflineToRealtimePlayer:
file
setFile:
setDeferredStateChangeQueue:
setPlaybackQueue:
setOfflineRenderingQueue:
setMarkerBlock:
offlineRenderingInProgress
setOfflineRenderingInProgress:
_isSynthesizingSilently
_offlineRenderingInProgress
_offlineToRealtimePlayer
_file
_avAudioUnit
_deferredStateChangeQueue
_playerState
_deferredPlayerState
_deferredReplyBlock
_offlineEngine
_audioUnitObservedToken
_playbackQueue
_offlineRenderingQueue
_currentRequestHandler
_markerBlock
_bufferCallback
T@"NSObject<TTSSynthesisProviderAudioOutput>",&,N,V_offlineToRealtimePlayer
T@"AVAudioFile",&,N,V_file
T@"AVAudioUnit",&,N,V_avAudioUnit
T@"NSObject<OS_dispatch_queue>",&,N,V_deferredStateChangeQueue
TQ,N,V_playerState
TQ,N,V_deferredPlayerState
T@?,C,N,V_deferredReplyBlock
T@"AVAudioEngine",&,N,V_offlineEngine
T@"NSNumber",&,N,V_audioUnitObservedToken
T@"NSObject<OS_dispatch_queue>",&,N,V_playbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_offlineRenderingQueue
T@"TTSSynthesisProviderRequestHandler",&,N,V_currentRequestHandler
T@?,C,N,V_markerBlock
T@?,C,N,V_bufferCallback
TB,N,V_isSynthesizingSilently
TB,N,V_offlineRenderingInProgress
T@"<TTSSynthesisProviderAudioEngineProtocol>",W,N,V_delegate
T@"AVAudioFormat",R
replacement
initWithRange:andReplacement:
sizeDelta
setRange:
setReplacement:
offsetFromEnd
setOffsetFromEnd:
finalRange
setFinalRange:
_replacement
_offsetFromEnd
_range
_finalRange
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_replacement
TQ,N,V_offsetFromEnd
T{_NSRange=QQ},N,V_finalRange
_rangeIsValid:
transformations
_insertTransformation:forEncapsulatedTerminator:
insertAtLocation:string:
insertObject:atIndex:
setTransformations:
encapsulateSubstringAtRange:withPrefix:andSuffix:
setTransformedString:
_transformedString
_transformations
T@"NSString",&,N,V_transformedString
T@"NSMutableArray",&,N,V_transformations
cache
initWithPattern:options:error:
setValue:forKey:
regexForString:
setCache:
_cache
T@"NSMutableDictionary",&,N,V_cache
initWithDictionaryRepresentation:
dictionaryRepresentation
isBuiltInVoice
_neural
_isDownloading
_isBuiltInVoice
_voicePath
_fileSize
Tq,R,N,V_footprint
TB,R,N,V_neural
TB,R,N,V_isInstalled
TB,N,V_isDownloading
TB,R,N,V_isBuiltInVoice
T@"NSString",&,N,V_voicePath
Tq,N,V_fileSize
stringWithCapacity:
enumerateSubstringsInRange:options:usingBlock:
hasAMX
sortDescriptorWithKey:ascending:comparator:
compare:options:
sortedArrayUsingDescriptors:
initWithSSMLRepresentation:voice:
binaryStringRepresentationOfInt:numberOfDigits:chunkLength:
insertString:atIndex:
binaryStringRepresentationOfInt:
ax_nextDequeuedObjects:
T@?,C,N
T@"AVAudioSession",&,N
TI,N
renderErrorFromAU:
lastRenderError
@16@0:8
v36@0:8@16B24@28
v32@0:8@16@24
v36@0:8@"AVSpeechSynthesisProviderRequest"16B24@"NSError"28
v32@0:8@"AVSpeechSynthesisMarker"16@"AVSpeechSynthesisProviderRequest"24
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8Q16
v32@0:8@16Q24
Vv24@0:8@16
Vv32@0:8@16q24
Vv36@0:8@16B24@?28
Vv32@0:8@16@?24
@40@0:8q16@24@32
B32@0:8q16@24
@32@0:8@16@24
@24@0:8@16
@56@0:8@16q24q32q40@48
@40@0:8@16@24d32
@56@0:8@16@24@32@40@48
v32@0:8@"NSObject<OS_dispatch_queue>"16Q24
Vv24@0:8@"TTSSpeechRequest"16
Vv32@0:8@"TTSSpeechRequest"16q24
Vv36@0:8@"NSString"16B24@?<v@?@"NSArray">28
Vv32@0:8@"TTSSpeechRequest"16@?<v@?B>24
@"NSSet"16@0:8
@"NSString"40@0:8q16@"TTSSpeechVoice"24@"NSString"32
B24@0:8@"TTSSpeechVoice"16
B32@0:8q16@"NSString"24
@"NSString"32@0:8@"NSString"16@"NSString"24
@"NSString"24@0:8@"NSString"16
@"NSString"56@0:8@"NSString"16q24q32q40@"NSString"48
@"NSString"40@0:8@"TTSSpeechVoice"16@"NSString"24d32
@"NSString"56@0:8@"TTSSpeechVoice"16@"NSString"24@"NSNumber"32@"NSNumber"40@"NSNumber"48
@"NSString"32@0:8@"TTSSpeechVoice"16@"NSString"24
@"NSDictionary"24@0:8@"TTSSpeechVoice"16
v44@0:8@16@24B32@36
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v40@0:8@16@24@32
v32@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24
v44@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSError"36
v52@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v48@0:8@"TTSSpeechSynthesizer"16{_NSRange=QQ}24@"TTSSpeechRequest"40
v40@0:8@"TTSSpeechSynthesizer"16@"<TTSMarker>"24@"TTSSpeechRequest"32
v40@0:8@"TTSSpeechSynthesizer"16@"NSURL"24@"TTSSpeechRequest"32
^{__CFArray=}16@0:8
@24@0:8Q16
{_NSRange=QQ}40@0:8{_NSRange=QQ}16@32
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
v20@0:8B16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@"NSString"
@"NSSet"
@"NSUUID"
{_NSRange="location"Q"length"Q}
^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}16@0:8
v24@0:8^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}16
@?16@0:8
v24@0:8@?16
^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}
v32@0:8@16@?24
v20@0:8I16
v32@0:8@"AVAudioPCMBuffer"16@?<v@?>24
v24@0:8@"AVAudioSession"16
v24@0:8@"AVAudioFormat"16
^{OpaqueAudioQueue=}16@0:8
v24@0:8^{OpaqueAudioQueue=}16
I16@0:8
d16@0:8
v24@0:8d16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
^{OpaqueAudioQueue=}
@"AVAudioFormat"
@"NSCondition"
@"AVAudioSession"
@"AXAssetsService"
@"NSDictionary"
@40@0:8@16q24@32
@24@0:8q16
q24@0:8@16
@32@0:8@16q24
@36@0:8@16q24B32
@56@0:8@16q24q32@40q48
@60@0:8@16q24q32@40q48B56
@"NSNumber"
q16@0:8
Q24@0:8@16
v24@0:8q16
@"AXAsset"
@"TTSVoiceAsset"
@"NSArray"
@"TTSSpeechVoice"
q36@0:8B16q20q28
v28@0:8B16q20
{?="category"q"activity"q}
^{__CFBag=}
v32@0:8@16q24
@"NSURL"
@"AVAudioPCMBuffer"
@32@0:8@16Q24
@"<TTSSynthesisProviderHandlerDelegate>"
@"AVSpeechSynthesisProviderRequest"
@"NSMutableArray"
{AudioComponentDescription=IIIII}16@0:8
v36@0:8{AudioComponentDescription=IIIII}16
{AudioComponentDescription="componentType"I"componentSubType"I"componentManufacturer"I"componentFlags"I"componentFlagsMask"I}
B32@0:8@16r*24
B56@0:8{AudioComponentDescription=IIIII}16{AudioComponentDescription=IIIII}36
B32@0:8@16d24
@"<TTSSynthesisProviderVoiceManagerDelegate>"
v40@0:8^v16Q24@32
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
v24@0:8B16B20
@20@0:8B16
v28@0:8@16B24
@32@0:8Q16Q24
@40@0:8Q16Q24@32
Q24@0:8Q16
@28@0:8@16B24
@36@0:8@16@24B32
@"NSHashTable"
@"AXAssetController"
v44@0:8B16@20@28@36
^v16@0:8
v24@0:8^v16
@"<TTSSpeechRequestDelegate>"
@"NSAttributedString"
@"TTSSpeechString"
@"AVSpeechSynthesisProviderVoice"
@48@0:8@16@24@32@40
B40@0:8q16@24@32
@40@0:8@16@24q32
v32@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24
v52@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"<TTSMarker>"32
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"NSURL"32
v20@0:8f16
B32@0:8@16@24
B48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@56@0:8@16@24{_NSRange=QQ}32@48
B64@0:8@16@24@32@40^@48^@56
B44@0:8@16q24B32^@36
B32@0:8@16^@24
B40@0:8@16@24^@32
B48@0:8@16@24@32^@40
B32@0:8q16^@24
B36@0:8q16B24^@28
B24@0:8^@16
f16@0:8
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B56@0:8@16@24@32^@40^@48
B40@0:8@16q24^@32
@"<TTSSpeechSynthesizerDelegate>"
{?="delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateDidEncounterMarkerWithRequest"b1"delegateSynthesizedSilentlyURL"b1"willUseInput"b1}
@"AVAudioSessionChannelDescription"
Vv32@0:8@16@24
Vv40@0:8@16@24@32
Vv52@0:8@16B24@28@36@44
Vv32@0:8@"TTSSpeechRequest"16@"<TTSSpeechService>"24
Vv40@0:8@"TTSSpeechRequest"16@"<TTSMarker>"24@"<TTSSpeechService>"32
Vv52@0:8@"TTSSpeechRequest"16B24@"NSString"28@"<TTSSpeechService>"36@"NSError"44
Vv32@0:8@"TTSSpeechRequest"16@"NSURL"24
v28@0:8q16B24
@"<TTSSpeechConnectionDelegate>"
@"TTSSpeechRequest"
@"<TTSSpeechService>"
v32@0:8@"NSArray"16@"AVSpeechSynthesisProviderRequest"24
B28@0:8@16B24
v44@0:8@16@?24B32@?36
v32@0:8q16@?24
@"<TTSSynthesisProviderAudioEngineProtocol>"
@"NSObject<TTSSynthesisProviderAudioOutput>"
@"AVAudioFile"
@"AVAudioUnit"
@"AVAudioEngine"
@"TTSSynthesisProviderRequestHandler"
@40@0:8{_NSRange=QQ}16@32
B40@0:8{_NSRange=QQ}16@32
B32@0:8Q16@24
B48@0:8{_NSRange=QQ}16@32@40
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
B32@0:8{_NSRange=QQ}16
@76@0:8@16@24q32q40B48B52@56@64B72
q24@0:8q16
@32@0:8q16I24I28
i16@0:8
i24@0:8^{OpaqueAudioComponentInstance=}16
lpaa
?333333
[[SSMLESCAPED]]
[[[SSMLESCAPED]]]
%@<say-as interpret-as="characters">%@</say-as>%@
%@<break time="%%dms" />%@
<mark name="%@" />
%@%@%@
<speak>
</speak>
v8@?0
%@(?<enclosedssml>((.|\n)*?))%@
(?<delimiter>(%@|%@))
delimiter
enclosedssml
\amp;
\quot;
\#39;
\#47;
\gt;
\lt;
STARTED
DID NOT START
v12@?0B8
v28@?0@"AVAudioPCMBuffer"8@"NSArray"16B24
-[TTSSynthesisProviderSpeechServer supportedIPAPhonemeLanguages]
-[TTSSynthesisProviderSpeechServer synthesizerInstanceDestroyed:]
-[TTSSynthesisProviderSpeechServer employSpeechMarkupForType:language:]
-[TTSSynthesisProviderSpeechServer audioFileSettingsForVoice:]
-[TTSSynthesisProviderSpeechServer isSiriService]
-[TTSSynthesisProviderSpeechServer isNashvilleService]
-[TTSSynthesisProviderSpeechServer canInitializeSpeech:]
-[TTSSynthesisProviderSpeechServer loadedVoiceResources]
+[TTSSynthesisProviderSpeechServer regexRules]
TTSErrorDomain
originalString
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
ignoreCase
appliesToAllApps
uuid
replacementRange
%@: Original: %@, Replacement: %@, Phonemes: %@, Languages: %@
ttsaudioqueue
com.apple.speech.synthesis.voice.alex
com.apple.speech.synthesis.voice.bruce
com.apple.speech.synthesis.voice.fred
com.apple.speech.synthesis.voice.agnes
com.apple.speech.synthesis.voice.princess
com.apple.speech.synthesis.voice.albert
com.apple.speech.synthesis.voice.kathy
com.apple.speech.synthesis.voice.bells
com.apple.speech.synthesis.voice.badnews
com.apple.speech.synthesis.voice.deranged
com.apple.speech.synthesis.voice.hysterical
com.apple.speech.synthesis.voice.junior
com.apple.speech.synthesis.voice.organ
com.apple.speech.synthesis.voice.bahh
com.apple.speech.synthesis.voice.zarvox
com.apple.speech.synthesis.voice.ralph
com.apple.speech.synthesis.voice.boing
com.apple.speech.synthesis.voice.cellos
com.apple.speech.synthesis.voice.goodnews
com.apple.speech.synthesis.voice.bubbles
com.apple.speech.synthesis.voice.trinoids
com.apple.speech.synthesis.voice.whisper
com.apple.speech.synthesis.voice.victoria
com.apple.speech.synthesis.voice.vicki
(?<root>com\.apple\.speech\.synthesis\.voice\.custom\.siri\.[^.]*)(\.(?<quality>(premium|compact)))?$
com\.apple\.speech\.synthesis\.voice\.(?<name>[^.]*)(\.(?<quality>premium|compact))?$
com\.apple\.ttsbundle\.(?<name>[^.]*)\-(?<quality>premium|compact|Premium|Compact)$
TTSCachedVoiceIdentifiersToMigrateKey
TTSCachedIsMigrationCompleteKey
com.apple.speech.voice.Alex
com.apple.speech.synthesis.voice.Alex
name
quality
%@.%@.%@.%@
_male
_female
com.apple.maui.voice
premium
enhanced
high
.maui.
%@.compact
%@.%@
%@_%@_%@_premium
AFLocalization
Class getAFLocalizationClass(void)_block_invoke
TTSAXResourceMigrationUtilities.m
Unable to find class %s
void *AssistantServicesLibrary(void)
com.apple.MobileAsset.VoiceServices.VoiceResources
voice_configs.plist
ar-001
ar-SA
nb-NO
no-NO
TextToSpeech.VoiceResources
v32@?0d8q16q24
v16@?0@"TTSAsset"8
Accessibility
Download failed
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
Invalid
MacinTalk
Gryphon
Custom
Maui
Kona
LegacyCombinedVocalizer
LegacyVocalizer
SynthesizerExtension
None
Hydra
SiriNeural
Contents
Contents/VoiceBundle
AssetData
Name
VoiceId
Languages
Type
Subtype
Footprint
Gender
MemoryPeak
Build
VoiceAsset
Sample
NoveltyVoice
AssetSize
IsInstalled
CanBeDownloaded
AssetId
SpeechVoice
componentSubType
synthesizerBundleIdentifier
com.apple.speech.MacinTalkFramework.MacinTalkAUSP
com.apple.speech.MacinTalkFramework
mctk
Apple
SpeechVoiceNames
com.apple.ax.KonaTTSSupport.KonaSynthesizer
%@_VOICE_WITH_NAME
TTSAXResource<%p> Name:%@ ID:%@ Type:[%ld:%ld] Foot:%ld Langs:[%@] Installed:%ld
com.apple.voiceservices.language
com.apple.SpeakSelection
en-US
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
IPHONE_SIMULATOR_ROOT
zh-Hans
zh-CN
com.apple.language.changed
TTSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
vocalizer_resources
ax_resources
ax_gryphon_resource_order
ax_compact_resource_order
vocalizer_resource_order
_voices
default
legacy
Voice resource, Languages: %@, ContentVersion: %@, MasteredVersion: %@
_languages
_searchPathURL
s5l8942x
s5l8947x
s5l8950x
s5l8955x
s5l8960x
t7001
s7002
t8002
q24@?0@8@16
filename
mime-type
InternalBuild
DisableGryphon
com.apple.voiced
HardwarePlatform
range
com.apple.voiceservices.assetInstalled
/System/Library/PrivateFrameworks/VoiceServices.framework
/System/Library/PrivateFrameworks/TextToSpeech.framework
/System/Library/PrivateFrameworks/TextToSpeechMauiSupport.framework
TTSResources
broker.hdr.asset
broker.hdr
FormatVersion
Language
VoiceName
common
Tones
voice_format_version.plist
com.apple.voiceservices.class
title
TTSSynthesisProviderCachedComponentsKey
com.apple.TTS.synthProviderVoicesDidUpdate
com.apple.accessibility.systemvoiceprovider
auDescType
auDescSubType
auDescManufacturer
auDescFlags
auDescFlagsMask
bundleIdentifier
containerBundleIdentifier
version
isFirstParty
voices
%@ %@ %@
auspmanager.voiceloading
auspmanager.componentquery
B32@?0@"TTSSynthesisProviderComponentRecord"8Q16^B24
B32@?0@"AVAudioUnitComponent"8Q16^B24
@16@?0@"AVAudioUnitComponent"8
@16@?0@"AVSpeechSynthesisProviderVoice"8
v24@?0@"AVAudioUnit"8@"NSError"16
com.apple.siri.SiriTTSService.synthesizer
TTSEnableSiriSynthesisProvider
Contents/%@.caf
Info.plist
MobileAssetProperties
com.apple.speech.synthesis.voice.Vicki
AllCachedAvailableResourcesKey
TTSResourceCacheVersionKey
TTSCachedBuildNumberKey
com.accessibility.resourcepref
com.accessibility.asset-loading
%@=%@ 
v32@?0@"NSString"8@"NSArray"16^B24
v16@?0@"<TTSAXResourceManagerObserver>"8
v28@?0d8B16@"NSError"20
@unionOfArrays.self
B32@?0@"TTSAXResource"8Q16^B24
com.apple.voice.compact
compact
super-compact
^[^-]{2,3}-[^-]{2,3}(-[^-]{2,3})?$
B32@?0@"TTSSpeechVoice"8Q16^B24
@16@?0@"TTSSpeechVoice"8
@16@?0@"TTSAXResource"8
@16@?0@"TTSVoiceAsset"8
Alex
v24@?0@"NSArray"8@"NSError"16
GeneralLanguageCodeMap
VoiceIdSampleStringMap
CanonicalLanguageCodeVoiceNamesMap
plist
FALLBACK_SAMPLE_TEXT
[%@ %p] %@ language: %@ footprint: %@ rate: %lf pitch: %lf volume: %lf
textForAttributes
attributes
text
languageCode
voice
outputPath
gender
rate
pitch
volume
maintainsInput
audioSessionIDIsValid
audioSessionID
audioQueueFlags
ssmlRepresentation
synthesisProviderVoice
premium-high
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
VoiceVersion
Version
_CompatibilityVersion
_MasteredVersion
male
female
neural
CombinedVoiceProject
LanguagesCompatibility
.compact.
.super-compact.
.premium.
kTTSSynthesisProviderVoiceAttributeGroupName
com.apple.SynthesisProvider.updatedVoices
%c%c%c%c
AU Desc: (Manufacturer: %u) (Type: %u) (SubType: %u) (Flags: %u) (Flag Mask: %u)
%@_%@_%@
%@_%@
AU Desc: (Manufacturer: %@) (Type: %@) (SubType: %@) (Flags: %u) (Flag Mask: %u)
[%@ %p] Name: %@, Identifier: %@, Supported Languages %@, Age: %li, Gender: %li, Size: %lli, Version: %@
%@, AUComponent %@
identifier
supportedLanguages
primaryLanguages
voiceSize
manufacturerName
extraAttributes
com.apple.ttsbundle
com.apple.ttsbundle.siri
com.apple.ttsbundle.gryphon
com.apple.ttsbundle.gryphon-neural
com.apple.speech.synthesis.voice
com.apple.voice
speech.synthesis.provider.
AllCachedAvailableVoicesKey
language-creation
System/Library/TTSPlugins
speechbundle
original
replacement
q24@?0@"TTSSpeechVoice"8@"TTSSpeechVoice"16
TTSSpeechSynthesizer
v32@?0@"TTSSubstitution"8Q16^B24
he-IL
ja-JP
\b%@\b
(?<=\s|^)%@(?=\s|$)
q24@?0@"NSDictionary"8@"NSDictionary"16
speech string is empty
siri
identifier == %@
not currently speaking
no active speech job
TTSAudioSessionChannel -> %@
v16@?0@"NSArray"8
%@[%p]: Name: %@ Identifier: %@ Footprint: %d Language: %@ Gender: %@ [default %d] [fallbackDefault: %d] Provider: %@
language
footprint
isDefault
isFallbackDefault
canBeDownloaded
isNoveltyVoice
isSystemVoice
voiceType
serviceIdentifier
nonCombinedVoiceId
com.apple.eloquence
synthprovider.stateChange
synthprovider.playbackQueue
synthprovider.offlineRendering
v24@?0@"NSArray"8@"AVSpeechSynthesisProviderRequest"16
macintalk
v32@?0I8r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}12I20q24
v24@?0@"AVAudioPCMBuffer"8B16B20
@16@?0@"AVSpeechSynthesisMarker"8
B32@?0@"TTSStringTransformation"8Q16^B24
q24@?0@"TTSStringTransformation"8@"TTSStringTransformation"16
%@ Name: %@, Languages: %@, Gender: %@, Footprint: %@, Neural: %@, Installed: %@, Version: %@/%@
_name
_gender
_footprint
_isInstalled
_isBuiltInVoice
_voicePath
_neural
fileSizeWithNumber
MasteredVersion
CompatabilityVersion
ContentVersion
VoicePath
com.apple.Accessibility
TTSRosebud
Default
Compact
Super Compact
Premium
Premium High
Male
Female
pt-BR
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
PTQ+ABwag03BwO/CKvIK/A
HWModelStr
n111
n121
Maged
bg-BG
Daria
ca-ES
Montserrat
hr-HR
Lana
uk-UA
Lesya
vi-VN
Linh
ms-MY
Amira
Sinji
cs-CZ
Zuzana
da-DK
Sara
nl-BE
Ellen
nl-NL
Xander
en-AU
Karen
en-IE
Moira
Daniel
Samantha
en-IN
Rishi
en-ZA
Tessa
fi-FI
Satu
fr-CA
Amelie
fr-FR
Thomas
de-DE
Anna
el-GR
Melina
Carmit
hi-IN
Lekha
hu-HU
Mariska
id-ID
Damayanti
it-IT
Alice
Kyoko
ko-KR
Yuna
Tingting
Meijia
Nora
pl-PL
Zosia
Luciana
pt-PT
Joana
ro-RO
Ioana
ru-RU
Milena
sk-SK
Laura
es-ES
Monica
es-MX
Paulina
sv-SE
Alva
th-TH
Kanya
tr-TR
Yelda
VSUtilities
Class getVSUtilitiesClass(void)_block_invoke
TTSSharedUtilities.m
void *VoiceServicesLibrary(void)
%@%i
ttsStartReplyBlockKey
ttsAudioSessionKey
ttsAudioDeviceKey
ttsAudioQueueFlags
VoiceProvider: Initializing server for %@
VoiceProvider: error creating ssml de-escaping regex: %@
VoiceProvider: error creating ssml delimiter regex: %@
VoiceProvider: cant find synthesizer for: %@
VoiceProvider: Converted request: %@
Retrieved Audio Session ID was different than requested!
VoiceProvider: Hit reply block of startSynthesizingSpeechRequest: %@
VoiceProvider: Could not start synthesis for request %@, converted from tts request %@
VoiceProvider: Pause at mark %@ speaking request: %@
VoiceProvider: [pause] cant find synthesizer for: %@
VoiceProvider: Request did not pause as expected for. %@
VoiceProvider: Warning: Unhandled TTSSpeechMark. Please implement.
VoiceProvider: [continue] cant find synthesizer for: %@
VoiceProvider: Continue Speech Request: %@
VoiceProvider: Could not continue speech request %@
VoiceProvider: Hit Stop speaking request: %@
VoiceProvider: [stop] cant find synthesizer for: %@
VoiceProvider: Warning: Unhandled TTSSpeechMark in stopSpeechRequest. Please implement.
VoiceProvider: Hit %s
VoiceProvider: Finished speaking %@
VoiceProvider: Did start speaking string at range (%@, %@)
VoiceProvider: Marker out of range! %@
TTSAQ: Failed to start on attempt %@
TTSAQ: Calling start on %@
TTSAQ: failed to start with err %@
TTSAQ: Calling stop on %@
TTSAQ: Audio session changed, rebuilding audio queue.
TTSAQ: Audio format changed, rebuilding audio queue.
TTSAQ: Audio queue flags changed to %@, rebuilding audio queue.
TTSAQ: Calling dispose on %@
TTSAQ: New AQ: %@
TTSAQ: Audio Queue stopped
TTSAQ: Audio Queue started
Migration is not complete, attempting to complete now.
Migration is complete, no need to restart.
Unable to find updated identifier for nil legacy identifier using language code: %@
No voice found for language code: %@. Attempting to find fallback language.
Found fallback language code: %@
Updated identifier: %@
Compact resource is not installed, falling back to on disk super-compact variant %@ => %@
Beginning download for compact resource from %@
Unable to complete migration for resource: %@, remaining voices to migrate: %@
Voices left to migrate: %@
Error writing migration complete flag to preferences: %@
Error unarchiving flag for completed migration: %@
Error, process other than axassetsd tried to write migration voice list to preferences
Error writing voices to migrate to preferences: %@
Error unarchiving voices to migrate: %@
SiriTTS returned nil deprecated voices. %@
Found installed voice resources for %@: %@
Downloading voice resources asset %@
Downloaded voice resources for %@
Error while attempting to unarchive the voiceConfigData: %@
Wrong voice type passed in %@
Reqeuesting cancel asset download
Canceled asset download
TTSAsset::listAssetsOfTypes (voiceTypes=%@ filter=%@): %@
Setting importance to %d
Could NOT set the thread priority
Successfully set the thread priority
Normal thread priority is %d
session interrupted
mediaserverd died
AUDIOSESSION: Setting up audio session
error setting HW sample rate: %ld
AUDIOSESSION: category = %d
error %ld setting audio category
error %ld setting bluetooth allowability
AUDIOSESSION: Bluetooth %sabled
active count went negative for input!
active count went negative for output!
active count went negative!
AUDIOSESSION: activity %d --> %s
AUDIOSESSION: Active --> FALSE
AUDIOSESSION: Active --> TRUE
error %ld activating or deactivating session for activity %ld
could not stop queue (%d)
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Couldn't initialize the engine voice format versions
[TTSSynthesisProviderRequestHandler init] Cannot use 0 bytes per frame!
Called completedRequestRendering more than once!
TTSVoiceProvider::Reconcile records: Source cache: %ld
  - %@
TTSVoiceProvider::Component cache updated with %@ additions and %@ evictions.
VoiceProvider: voice load failed for component %@ after %@ attempts.
VoiceProvider: Recovered cache entry for first party SSE %@
VoiceProvider audio component initialization error %@
VoiceProvider could not retrieve remote pid %@, subtype: %@
VoiceProvider voices returned nil for record %@
VoiceProvider loaded %@ voices for bundle identifier: %@
VoiceProvider voice load timed out for record %@.
VoiceProvider: failed to set component cache preference %@.
all voices %@
VoiceProvider: failed to read component cache preference.
VoiceProvider: failed to decode component cache preference with exception: %@
Allowing Siri TTS service synthesizer
Skipping Siri TTS service synthesizer
Requesting resources. waitForInstalledAssets=%ld. Found resources in cache: %@
Requesting resources. waitForInstalledAssets=%ld. No resources found in cache. Setting resources to on-disk resources for maui/macintalk/legacy
Requesting resources. Found locally available resources: %@
Returning requesting resources. waitForInstalledAssets=%ld. %@
Updating in-memory resources: %@
Running block to compute expensive resources
Will ask assetController to refresh only-installed TTSResource AXAssets now
Tried to merge in installed assets before initial in-memory cache build.
Updating cache after computing expensive resources
Will merge in expensive resources. sync=%ld
Samples asset has not been initialized, attempting to read from mobile asset.
Samples asset was nil, it has not been downloaded yet.
Samples asset has been found: %@
Will refresh resources for type: %@
Failed to load maui/macintalk on-disk resources. Could not find maui framework!
Will ask assetController to refresh TTSResource AXAssets now
Requested axassetsd to rebuild the preferences cache
No download resource in _stopDownloadSiriVoiceAssetWithResource:
No asset for resource: %@
Stopped downloading %@
No resource for download: %@
Resource already installed: %@
Started downloading %@
No resource in _downloadSiriVoiceAssetWithResource:
Cannot download Siri asset. No asset instance found for resource: %@
Will ask SiriTTS to download asset: %@
Siri asset download progress: %{public}@ %{public}f
Speech sample DL: Already downloaded. Bailing
Speech sample DL: Already in progress. downloadingSamples=%ld samplesAsset.isDownloading=%ld
Speech sample DL: Could not find sample asset to download.
Speech sample DL: About to kick off download.
Speech sample DL: Samples started download.
Error, attempted to delete asset that is not installed.
Multiple default resources found for language: %@. Returning one at random
No default resources found for language: %@. 
Will find local resources at path: %@
Error reading languages in for local resources.
Error creating language-code regex: %@
Invalid directory format %@
Error reading in local voices for language %@.
Resource for %@ is nil
Did find local resources at path: %@. %@
Attempted to play a sample, but not sample assets were found
Requesting refreshed TTSResource assets (sync). onlyInstalled=%ld
Resetting in-memory resources to nil
Error: A process other than axassetsd attempted to write to the preferences cache.
No resource cache version found in preferences
Read resource cache version from preferences: %@
No catalog build number found in preferences
Read catalog build number from preferences: %@
Error: A process other than axassetsd attempted to write the build version to user preferences.
Cache version mismatch. Returning nil for resource preferences.
No resource data found in preferences
Error unarchiving resources: %@
Error unarchiving resources: unexpected type %@
Read resources cache from preferences: %@
Error writing resources to preferences: %@
AXAssetControllerObserver: Download completed for resource: %@ with asset: %@
Download failed: %@, %@
Download succeeded: %@
No download resource %@
DL progress: %{public}@ %{public}f
Will find Siri resources. onlyInstalled=%ld
Error: TTSAsset had nil name %@ or identifier %@. Asset: %@
Error: TTSAsset was nil while refreshing siri resources
Returning Siri resources (onlyInstalled=%ld): %@
Will find resources for synthesis providers
TTSAXResource.init was nil. Name must be provided in data
Did find %ld resources for synthesis providers
Will find resources for legacy assets
Legacy combined vocalizer asset or asset properties were nil: [Asset]: %@, [Asset Name]: %@, [Asset Languages]: %@, [Asset Gender]: %@, [Compact Identifier]: %@, [Premium Identifier]: %@
Returning Legacy resources: %@
Will find Macintalk resources
Did find %ld Macintalk resources
Will download legacy resource for testing: %@
Cannot download voice for testing. No assset found for ID: %@
Downloading legacy asset for testing: %@ %@
Received notification: %@. Will reset in-memory resources
Error reading general language code data.
Error reading sample string data.
Unable to find language code for voice name: %@
%@ requested speech voices be updated
Speech Error: %@
Skipping %@ since unified speech is enabled
Bundle err: %@
Unable to find voice service for identifier: %@, voice: %@, resource: %@
Could not find voice for identifier: %@
Media services reset
replacements order %@
Will replace: %@ in range %@ for %@
Error creating SSML %@
File did not exist at content path: %@ %@. Attempting to fallback to default voice for language: %@
Error: Unable to speak. No speech service: voice: %@ identifier: %@, language: %@, resource: %@
Error: Unable to speak. No request owner: service: %@ identifier: %@, language: %@
We do not have a record of this request owner: %@ [%@]
Speech processing error: [%@] / mark: %@ / range: %@, %@
Channel should not be nil. Are we deallocating the TTSAudioSessionChannel but holding a reference to it, perhaps in our unit tests?
Phonemes retrieved: %@
There was no speech service used to initiate audio
TextToSpeech-PlaybackStarted
AudioUnit had no output busses.
AudioUnit had no audioUnitOutputFormat.
Error initializing offline engine %@
Could not start offline engine. Error: %@
Setting up new AU for voice %@
Will start synthesizing with component description %@
Error: Already had an AU (%@, %@) while expecting to instantiate new AU (%@, %@)
Component was nil
SSEFirstBuffer
VoiceProvider: Failed to start audio player.
Couldn't find audio unit for request %{public}@
Asked AU to synthesize %@
Now rendering %@
Realtime audio stopped during offline rendering.
Audio Unit encountered an error after sending some valid buffer.
Audio Unit failed to start after %li attempts.
Audio Unit reinitialization attempt failed.
Audio Unit reinitialization attempt succeeded! Continuing render.
SSEOfflineRenderFirstBuffer
SSEOfflineRender
Audio Unit render loop exited without completing.
Pausing immediately
VoiceProvider**: Stopping immediately
Received markers %@, for request %@
VoiceProvider**: Stopping at mark %@
VoiceProvider**: Pausing at mark %@
VoiceProvider**: Beginning deferred stop
VoiceProvider: ignoring playback request for old speech job.
playAndFlush: No more request handlers found.
VoiceProvider**: exiting buffer scheduling loop for canceled speech request.
VoiceProvider**: Ignoring AVFoundation completion callback since player should be stopped.
Error creating regex %@
Invalid language format was used to initialize TTS voice asset
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
TTSSynthesisProviderSpeechServer
TTSSynthesisProviderAudioEngineProtocol
TTSSpeechService
NSObject
TTSSpeechSynthesizerDelegate
TTSSpeechServiceUnitTesting
TTSSubstitution
NSSecureCoding
NSCoding
NSCopying
TTSWrappedAudioQueueBuffer
TTSWrappedAudioQueue
TTSSynthesisProviderAudioOutput
TTSAXResourceMigrationUtilities
TTSSiriAssetManager
TTSAssetBase
TTSAXResource
TTSAudioSession
TTSVoiceResourceAsset
VocalizerUtilities
TTSSpeechAdditions
TTSFormatArgument
TTSSynthesisProviderPlayableBuffer
TTSSynthesisProviderRequestHandler
TTSSynthesisProviderComponentRecord
TTSSynthesisProviderVoiceManager
TextToSpeech
TTSAXResourceManager
AXAssetControllerObserver
TTSLocaleUtilities
TTSSpeechRequest
TTSWordMarker
TTSMarker
TTSPhonemeMarker
TTSGenericMarker
AXSpeechPublicInterface_Private
TTSSpeechSynthesizer
TTSSpeechConnectionDelegate
D"##
TTSAudioSessionChannel
IPAPhonemeSupport
TTSSpeechRequestOwner
TTSSpeechRequestDelegate
TTSSpeechVoice
SynthesisProviderAdditions
TTSSynthesisProviderAudioEngine
TTSSynthesisProviderHandlerDelegate
TTSStringTransformation
TTSSpeechString
TTSRegexCache
TTSVoiceAsset
TTSProviderUtility
BinaryStringRepresentation
count
voiceSize
localeWithLocaleIdentifier:
audioUnitName
objectForKey:
countByEnumeratingWithState:objects:count:
allValues
localizedLowercaseString
objectForKeyedSubscript:
streamDescription
sortedArrayUsingDescriptors:
properties
insertObject:atIndex:
string
characterAtIndex:
UUID
allocWithZone:
currentHandler
propertyListWithData:options:format:error:
downloadSize
setSpeechSynthesisOutputMetadataBlock:
generateSSMLFromAVSpeechUtterance:
stringByAppendingFormat:
insertString:atIndex:
characterIsMember:
alphanumericCharacterSet
punctuationCharacterSet
wait
downloadWithReservation:useBattery:progress:then:
stringByAppendingPathComponent:
code
setByAddingObjectsFromArray:
currentRoute
downloading
localizedStringWithFormat:
anyObject
weakObjectsHashTable
stringByAppendingString:
custom
setByteSampleOffset:
appendBytes:length:
instantiateWithComponentDescription:options:completionHandler:
purgeAssetsSynchronously:
stringByDeletingPathExtension
compact
localizedUppercaseString
customVoice
purgeImmediately:
appendData:
intValue
locallyAvailable
setMaximumFramesToRender:
opaqueSessionID
stringByPaddingToLength:withString:startingAtIndex:
setCategory:error:
compare:
integerValue
unarchivedFileSize
data
appendFormat:
purgeInMemoryCachedAssets
ax_arrayByRemovingDuplicates
lock
stringByReplacingCharactersInRange:withString:
gryphon
setCategory:withOptions:error:
compare:options:
invertedSet
quality
dataUsingEncoding:
appendString:
unarchivedObjectOfClasses:fromData:error:
longLongValue
stringByReplacingOccurrencesOfString:withString:
gryphonVoice
ax_dequeueObject
setObject:forKey:
date
isAssetCatalogInstalled
lowercaseString
ax_enqueueObject:
handleFailureInFunction:file:lineNumber:description:
stringByStandardizingPath
setObject:forKeyedSubscript:
decodeBoolForKey:
ax_filteredArrayUsingBlock:
unionSet:
enableManualRenderingMode:format:maximumFrameCount:error:
stringByTrimmingCharactersInSet:
AUAudioUnit
outputBusses
decodeBytesForKey:returnedLength:
unlock
hasAMX
rangeOfString:options:range:
IOBufferDuration
ax_flatMappedArrayUsingBlock:
mainBundle
hasPrefix:
stringValue
rangeValue
unsignedIntValue
decodeDictionaryWithKeysOfClasses:objectsOfClasses:forKey:
encodeBool:forKey:
restartTTSResourceMigration
ax_mappedArrayUsingBlock:
hasSuffix:
outputLatency
stringWithCapacity:
rangeWithName:
isEqualToNumber:
unsignedIntegerValue
retrieveSessionWithID:
bestAssetOfTypes:matching:
decodeDoubleForKey:
encodeBytes:length:forKey:
manualRenderingFormat
stringWithCharacters:length:
isEqualToString:
archivedDataWithRootObject:requiringSecureCoding:error:
outputNode
updateAssetForPolicy:
decodeInt32ForKey:
reverseObjectEnumerator
encodeDouble:forKey:
manualRenderingMaximumFrameCount
stringWithFormat:
decodeIntegerForKey:
array
updateTTSResourcesForActionType:
boolValue
encodeInt32:forKey:
stringWithUTF8String:
path
componentsJoinedByString:
decodeObjectOfClass:forKey:
setUserInitiated:
arrayByAddingObjectsFromArray:
mark
broadcast
sampleRate
encodeInteger:forKey:
substringFromIndex:
pathForResource:ofType:
componentsMatchingDescription:
decodeObjectOfClasses:forKey:
arrayWithObjects:count:
uppercaseString
markName
encodeObject:forKey:
substringToIndex:
componentsSeparatedByString:
indexOfObject:
decodePropertyListForKey:
setValue:forKey:
substringWithRange:
indexOfObjectPassingTest:
userInfo
defaultCStringEncoding
assetControllerWithPolicy:qosClass:shouldRefreshForAssetInstallNotifications:
enumerateKeysAndObjectsUsingBlock:
connect:to:format:
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
defaultCenter
setPitchMultiplier:
enumerateObjectsUsingBlock:
informationForPlugInWithPid:
defaultManager
refreshAssetsWithAttributesSynchronously:installedOnly:
isSSMLValid:
bundle
enumerateSubstringsInRange:options:usingBlock:
setPreferredIOBufferDuration:error:
valueForKeyPath:
refreshInstalledAssetsSynchronously
error
matchesInString:options:range:
URLByAppendingPathComponent:
bundleForClass:
initForReadingFromData:error:
valueWithNonretainedObject:
setPreferredSampleRate:error:
errorWithDomain:code:userInfo:
setActive:error:
refreshWithoutCatalogUpdateSynchronously
assetPolicy
maximumFramesToRender
symbolCharacterSet
valueWithRange:
escapedPatternForString:
setAge:
initWithCommonFormat:sampleRate:channels:interleaved:
setVoiceSize:
bundlePath
registerSubclass:asComponentDescription:name:version:
initWithContentsOfURL:
regularExpressionWithPattern:options:error:
versionNumber
mutableCopy
bundleURL
speechVoices
fileExistsAtPath:
assistantVoiceMaps
versionString
remoteProcessAuditToken
setRenderingOffline:
bundleWithPath:
filePathURL
containsObject:
initWithKeyOptions:valueOptions:capacity:
vocalizer
remoteProcessIdentifier
ssmlResult
attachNode:
byteSampleOffset
containsString:
setFrameLength:
setWithArray:
vocalizerVoice
removeAllObjects
fileURLWithPath:
startAndReturnError:
synthesisProviderVoicesDidChange:
setWithObjects:
removeItemAtURL:error:
attributesOfItemAtPath:error:
setAttributes:range:
filteredArrayUsingPredicate:
removeObject:
cStringUsingEncoding:
addEntriesFromDictionary:
contentsOfDirectoryAtPath:error:
initWithPCMFormat:frameCapacity:
synthesizeSpeechRequest:
removeObjectAtIndex:
numberOfRanges
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
initWithPattern:options:error:
dictionary
shared
removeObjectForKey:
audioBufferList
numberWithBool:
lastObject
addObject:
policy
sharedAudioUnitComponentManager
audioComponentDescription
dictionaryWithContentsOfFile:
firstMatchInString:options:range:
numberWithInteger:
cancelDownloadingThen:
portType
addObjectsFromArray:
dictionaryWithContentsOfURL:
numberWithLong:
firstObject
removeRenderObserver:
cancelSpeechRequest
technology
predicateWithFormat:
initWithSSMLRepresentation:voice:
dictionaryWithObjects:forKeys:count:
floatValue
numberWithLongLong:
convertRange:forSSML:
addObserver:selector:name:object:
length
numberWithUnsignedInt:
capitalizedString
renderOffline:toBuffer:error:
textRange
premium
initWithStreamDescription:
diskSize
numberWithUnsignedInteger:
category
formUnionWithCharacterSet:
convertedRange
initWithString:
allKeys
timeIntervalSince1970
premiumhigh
sleepForTimeInterval:
voiceNamesForOutputLanguageCode:gender:
listAssetsOfTypes:matching:
doubleValue
numberWithUnsignedLongLong:
categoryOptions
stopDownloadAsset:completion:
copy
allObjects
tokenByAddingRenderObserver:
replaceCharactersInRange:withString:
loadAndReturnError:
objectAtIndex:
sortDescriptorWithKey:ascending:comparator:
frameCapacity
inputLatency
voiceResources
localURL
downloadAssets:successStartBlock:
objectAtIndexedSubscript:
frameLength
principalClass
inputs
sortUsingComparator:
sortedArrayUsingComparator:
init
regexRules
synthesisProviderDidFinishSpeakingRequest:successfully:withError:
synthesisProviderDidStartSpeakingMarker:forRequest:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
initializeSpeechServerInstance:
synthesizerInstanceDestroyed:
setServiceQueue:forSynthesizerInstanceID:
startSpeechRequest:
pauseSpeechRequest:atMark:
continueSpeechRequest:
stopSpeechRequest:atMark:
getVoicesForLanguage:queryingMobileAssets:reply:
getSpeechIsActiveForRequest:reply:
supportedIPAPhonemeLanguages
speechMarkupStringForType:voice:string:
isVoiceValid:
employSpeechMarkupForType:language:
lhPhonemesFromIPA:language:
phonemesFromIPA:language:
phonemesFromLHPhonemes:language:
enclosedStringWithPhonemes:
nashvilleVoiceIdentifier:footprint:voiceType:gender:assetVoiceName:
nashvilleVoiceName:footprint:voiceType:gender:assetVoiceName:
embeddedRateMarkupForVoice:string:rate:
embeddedPitchMarkupForVoice:string:pitch:
embeddedVolumeMarkupForVoice:string:volume:
combinedProsodyMarkupForVoice:string:rate:pitch:volume:
genericMarkerMarkupForVoice:name:
audioFileSettingsForVoice:
serviceIdentifier
isSiriService
isNashvilleService
isSiriNeuralVoice:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didEncounterMarker:forRequest:
speechSynthesizer:didSynthesizeSilentlyToURL:forRequest:
canInitializeSpeech:
loadedVoiceResources
_speechEngineForSynthesizerInstance:
getVoicesForLanguage:reply:
_unescapeDelimeterBoundedSSMLInString:
_escapeSSML:
_ttsMarkerForSSEMarker:forRequest:
_nonSSMLSubstringRangeForRange:fromSSML:
serviceQueue
setServiceQueue:
requestMapping
setRequestMapping:
speechEngines
setSpeechEngines:
.cxx_destruct
_serviceQueue
_requestMapping
_speechEngines
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceQueue
T@"NSMutableDictionary",&,N,V_requestMapping
T@"NSMutableDictionary",&,N,V_speechEngines
dealloc
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
setReplacementString:
originalString
setOriginalString:
replacementString
phonemes
setPhonemes:
languages
setLanguages:
voiceIds
setVoiceIds:
active
setActive:
ignoreCase
setIgnoreCase:
replacementRange
setReplacementRange:
uuid
setUuid:
appliesToAllApps
setAppliesToAllApps:
bundleIdentifiers
setBundleIdentifiers:
isReplacementTextAllPunctuation
isReplacementTextSurroundedByPunctuation
isUserSubstitution
setIsUserSubstitution:
_active
_ignoreCase
_appliesToAllApps
_isReplacementTextAllPunctuation
_isReplacementTextSurroundedByPunctuation
_isUserSubstitution
_originalString
_replacementString
_phonemes
_languages
_voiceIds
_uuid
_bundleIdentifiers
_replacementRange
T@"NSUUID",&,N,V_uuid
T@"NSString",C,N,V_originalString
T@"NSString",C,N,V_replacementString
T@"NSString",C,N,V_phonemes
T@"NSSet",C,N,V_languages
T@"NSSet",C,N,V_voiceIds
TB,N,V_active
TB,N,V_ignoreCase
T{_NSRange=QQ},N,V_replacementRange
TB,N,V_appliesToAllApps
T@"NSSet",C,N,V_bundleIdentifiers
TB,R,N,V_isReplacementTextAllPunctuation
TB,R,N,V_isReplacementTextSurroundedByPunctuation
TB,N,V_isUserSubstitution
byteSize
aqBuffer
setAqBuffer:
completionHandler
setCompletionHandler:
_aqBuffer
_completionHandler
T^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I},N,V_aqBuffer
T@?,C,N,V_completionHandler
TQ,R,N
scheduleBuffer:completionHandler:
play
pause
stop
setAudioSession:
setOutputFormat:
isRunning
setAudioQueueFlags:
_play
pokeAudio
bufferCallback:
_minimumBufferByteSize
_tearDownAudioQueue
_rebuildAudioQueue
aqRef
setAqRef:
format
setFormat:
state
setState:
buffersAvailable
setBuffersAvailable:
audioQueueDispatchQueue
setAudioQueueDispatchQueue:
audioQueueFlags
lastActiveTime
setLastActiveTime:
shouldRebuildAudioQueue
setShouldRebuildAudioQueue:
audioQueueActive
setAudioQueueActive:
inflightBuffers
setInflightBuffers:
availableBuffers
setAvailableBuffers:
audioSession
_bufferLock
_shouldRebuildAudioQueue
_audioQueueActive
_audioQueueFlags
_aqRef
_format
_state
_buffersAvailable
_audioQueueDispatchQueue
_lastActiveTime
_inflightBuffers
_availableBuffers
_audioSession
T^{OpaqueAudioQueue=},N,V_aqRef
T@"AVAudioFormat",&,N,V_format
TQ,N,V_state
T@"NSCondition",&,N,V_buffersAvailable
T@"NSObject<OS_dispatch_queue>",&,N,V_audioQueueDispatchQueue
TI,N,V_audioQueueFlags
Td,N,V_lastActiveTime
TB,N,V_shouldRebuildAudioQueue
TB,V_audioQueueActive
T@"NSMutableDictionary",&,N,V_inflightBuffers
T@"NSMutableDictionary",&,N,V_availableBuffers
T@"AVAudioSession",&,N,V_audioSession
sharedInstance
isMigrationComplete
restartMigrationIfNeeded
updatedIdentifierForLegacyIdentifier:withLanguageCode:
legacyIdentifierForUpdatedIdentifierDuringMigration:
_remapGenderedSiriVoiceIdentifiers:
convertIdentifierIfNeeded:
downloadCompactResourceIfNeededForIdentifier:
deleteCompactResourceIfNeededForIdentifier:
resourceNeedsMigration:
resourceCompletedMigration:
writeIsMigrationCompleteToPreferences:
_readIsMigrationCompleteFromPreferences
writeVoiceIdentifiersToMigrateToPreferences:
_readVoiceIdentifiersToMigrateFromPreferences
obsoleteVoicesWithReplacements
assetsService
setAssetsService:
setIsMigrationComplete:
setObsoleteVoicesWithReplacements:
_isMigrationComplete
_assetsService
_obsoleteVoicesWithReplacements
T@"AXAssetsService",&,N,V_assetsService
TB,N,V_isMigrationComplete
T@"NSDictionary",&,N,V_obsoleteVoicesWithReplacements
convertTTSLanguageCodeToSiriLanguageCode:
voiceResourceForLanguage:voiceType:onDiskData:
_footprintForType:
_assetTypesForVoiceType:
ttsAssetFromVoiceAsset:
voiceAssetFromTTSAsset:
spaceCheck:
purgeAsset:
assetIsDownloading:
stopDownload:
deprecatedVoicesMap
downloadAsset:progressHandler:
_voiceTypeForAssetTechnology:
_assetTechnologyForVoiceType:
assetsForLanguage:voiceType:
installedAssetsForLanguage:voiceType:
_assetsForLanguage:voiceType:installedOnly:
installedAssetForLanguage:gender:footprint:voiceName:voiceType:
assetForLanguage:gender:footprint:voiceName:voiceType:
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
_assetFilterForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
initWithAsset:
initWithData:
footprint
assetId
contentPath
primaryLanguage
memoryPeakExceedsActiveJetsamLimit
shouldFilterResourceFromUI
isInstalled
assetSize
speechVoice
localizedName
localizedStringForKey:
localizedNameWithFootprint
_isDennisVoice
canBeDownloaded
_isSystemVoice
_isDefault
_ensureMacinTalkComponent
_resourceTypeFromStringInput:
_resourceSubtypeFromStringInput:
_resourceFootprintFromStringInput:
_resourceGenderFromStringInput:
axAsset
setAxAsset:
voiceAsset
setVoiceAsset:
name
voiceId
type
subtype
gender
isNoveltyVoice
setAssetId:
setSpeechVoice:
synthesizerBundleIdentifier
setSynthesizerBundleIdentifier:
componentSubType
setComponentSubType:
setFootprint:
setAssetSize:
setIsInstalled:
setCanBeDownloaded:
memoryPeak
setMemoryPeak:
_isNoveltyVoice
_isInstalled
_canBeDownloaded
_axAsset
_voiceAsset
_name
_voiceId
_type
_subtype
_gender
_assetId
_speechVoice
_synthesizerBundleIdentifier
_componentSubType
_footprint
_assetSize
_memoryPeak
T@"NSString",&,N,V_assetId
T@"TTSSpeechVoice",&,N,V_speechVoice
T@"NSString",&,N,V_synthesizerBundleIdentifier
T@"NSString",&,N,V_componentSubType
Tq,N,V_footprint
TQ,N,V_assetSize
TB,N,V_isInstalled
TB,N,V_canBeDownloaded
Tq,N,V_memoryPeak
T@"AXAsset",&,N,V_axAsset
T@"TTSVoiceAsset",&,N,V_voiceAsset
T@"NSArray",R,N,V_languages
T@"NSString",R,N,V_name
T@"NSString",R,N
T@"NSString",R,N,V_voiceId
TQ,R,N,V_type
TQ,R,N,V_subtype
Tq,R,N,V_gender
TB,R,N,V_isNoveltyVoice
_audioSessionInterrupted:
_mediaServicesWereReset:
_setupAudioSession
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
legacyPlatforms
syncWithConfigFile:voiceType:
syncWithConfigData:voiceType:
defaultVoice
defaultTypeString
defaultFootprintString
resourceList
setResourceList:
searchPathURL
setSearchPathURL:
voiceConfig
setVoiceConfig:
_resourceList
_searchPathURL
_voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSURL",C,N,V_searchPathURL
vocalizerFootprint
vocalizerGender
attributedStringWithFormatAndAttributes:
formatSpecifier
attributes
formattedArg
appendString:withAttributes:
endFrameOffset
startFrameOffset
setStartFrameOffset:
buffer
setBuffer:
_startFrameOffset
_buffer
TI,N,V_startFrameOffset
TI,R,N
T@"AVAudioPCMBuffer",&,N,V_buffer
initWithRequest:bytesPerFrame:
addMarkers:
addBuffers:
completedRequestRendering
dequeueMarkersUpToFrame:
delegate
setDelegate:
managingSpeechRequest
setManagingSpeechRequest:
isFinishedReceivingBuffers
setIsFinishedReceivingBuffers:
currentAudioBufferFrameCount
setCurrentAudioBufferFrameCount:
bytesPerFrame
setBytesPerFrame:
queuedMarkers
setQueuedMarkers:
_isFinishedReceivingBuffers
_currentAudioBufferFrameCount
_delegate
_managingSpeechRequest
_bytesPerFrame
_queuedMarkers
T@"AVSpeechSynthesisProviderRequest",&,N,V_managingSpeechRequest
TI,N,V_currentAudioBufferFrameCount
TQ,N,V_bytesPerFrame
T@"NSMutableArray",&,N,V_queuedMarkers
TB,N,V_isFinishedReceivingBuffers
T@"<TTSSynthesisProviderHandlerDelegate>",W,N,V_delegate
componentDescription
setComponentDescription:
containerBundleIdentifier
setContainerBundleIdentifier:
version
setVersion:
isFirstParty
setIsFirstParty:
voices
setVoices:
_isFirstParty
_containerBundleIdentifier
_version
_voices
_componentDescription
T{AudioComponentDescription=IIIII},N,V_componentDescription
T@"NSString",&,N,V_bundleIdentifier
T@"NSString",&,N,V_containerBundleIdentifier
T@"NSString",&,N,V_version
TB,N,V_isFirstParty
T@"NSArray",&,N,V_voices
macintalkAudioUnitProvider
setComponentCache:
voiceCache
componentCache
resetInMemoryCache
allSynthesisProviderVoices
allSynthesisProviderTTSVoices
_synthesizerHasEntitlement:entitlement:
_componentIsEqual:to:
T@"NSArray",&
T@"NSDictionary",R
T@"NSArray",R
reconcileCachedComponents
reloadVoicesForBundleIdentifierPrefix:
reloadVoicesForBundleIdentifierHash:
_reloadVoiceForBundleIdentifierPrefix:
_reloadVoiceForBundleIdentifierHash:
purgeAndReloadAllComponents
_systemAudioUnitProviders
_reconcileCachedComponents:
_loadVoicesForComponents:
_loadVoicesForComponentRecord:dispatchGroup:
_loadVoicesForComponentWithTimeout:timeout:
operationQueue
setOperationQueue:
componentQueryQueue
setComponentQueryQueue:
_operationQueue
_componentQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_operationQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_componentQueryQueue
T@"<TTSSynthesisProviderVoiceManagerDelegate>",W,N,V_delegate
tts_encodeBytes:size:forKey:
tts_decodeBytesIntoObject:size:forKey:
tts_encodeMatrixFloat4x4:forKey:
tts_decodeMatrixFloat4x4ForKey:
finishedDownloadingResource:wasCancelled:
downloadProgressForVoiceId:progress:storageSize:requiredDiskSpace:
finishedDeletingResource:
resourceCacheDidReceiveUpdate
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
resources
_debugCountSummaryForResources:
_updateCachedResources:
_mergeInExpensiveInstalledAssets:notifyObservers:
samplesAsset
_refreshSamples:
_refreshResourcesForManagerType:
rebuildSystemCacheForActionType:
downloadResourceWithAssetId:
downloadResourceWithVoiceId:
downloadResourceWithVoiceId:userInitiated:
stopDownloadResourceWithVoiceId:
_stopDownloadSiriVoiceAssetWithResource:
_stopDownloadResource:
_downloadResource:userInitiated:
_downloadSiriVoiceAssetWithResource:
downloadSamplesIfNecessary
deleteResourceWithAssetId:
deleteResourceWithVoiceId:
_deleteResource:
_deleteSiriVoiceAssetWithResource:
resourcesWithLanguage:type:
resourcesWithType:subType:
_resourcesWithType:subType:languageCode:
resourceWithVoiceId:
resourceWithAssetId:
_resourceWithVoiceId:assetId:
defaultVoiceForLanguage:
languageCodeForResourceName:withType:
superCompactVoiceIdForCompactVoiceId:
_findLocalResourcesForPath:
speechVoiceWithVoiceId:
refreshedResourcesForResources:
sampleURLForVoiceId:
_resourcesForAssets:
allVoices:
allLanguagesForVoices:
allAvailableLanguages
_managerTypeForResourceType:
_isValidResourceTypeKey:
_dictionaryForResources:
_axAssetsForTTSAXResourceModel:
resetResourcesCache
resetInMemoryAssetCatalogs
_notifyObserversOfCacheUpdate
updateCatalogIfNeeded
catalogBuildVersion
refreshAssetForResource:installedOnly:
_refreshAssetForResource:withAssetController:installedOnly:
refreshResourcesCacheForManagerType:
readResourceCacheVersionFromPreferences
_writeResourceCacheVersionToPreferences
_readCatalogBuildNumberFromPreferences
updateCatalogBuildVersion:
_readResourcesFromPreferences
_writeResourcesToPreferences:
addObserver:
removeObserver:
_performBlockOnObservers:
_refreshSiriResources:
_getSynthesisProviderResources
_findResourcesForLegacyAssets
_findAndSwapLegacyMacinTalkAssetsForMacinTalkResources:
_downloadLegacyResourceForTesting:
assetController
setAssetController:
legacyCombinedVocalizerAssetController
setLegacyCombinedVocalizerAssetController:
legacyMacinTalkAssetController
setLegacyMacinTalkAssetController:
setAllAvailableLanguages:
setSamplesAsset:
setCatalogBuildVersion:
downloadingSamples
setDownloadingSamples:
preferenceWriteQueue
setPreferenceWriteQueue:
assetLoadingQueue
setAssetLoadingQueue:
_resourcesLock
_resourcesById
_resources
_observersLock
_observers
_downloadingSamples
_assetController
_legacyCombinedVocalizerAssetController
_legacyMacinTalkAssetController
_allAvailableLanguages
_samplesAsset
_catalogBuildVersion
_preferenceWriteQueue
_assetLoadingQueue
T@"AXAssetController",&,N,V_assetController
T@"AXAssetController",&,N,V_legacyCombinedVocalizerAssetController
T@"AXAssetController",&,N,V_legacyMacinTalkAssetController
T@"NSSet",&,N,V_allAvailableLanguages
T@"AXAsset",&,N,V_samplesAsset
T@"NSString",&,N,V_catalogBuildVersion
TB,N,V_downloadingSamples
T@"NSObject<OS_dispatch_queue>",&,N,V_preferenceWriteQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetLoadingQueue
canonicalLanguageCodeVoiceNamesData
generalLanguageCodeData
voiceIdSampleStringData
defaultVoiceIdentifierForGeneralLanguageCode:
sampleStringForVoiceIdentifier:
defaultVoiceIdentifierForVoiceName:
setGeneralLanguageCodeData:
setVoiceIdSampleStringData:
setCanonicalLanguageCodeVoiceNamesData:
_generalLanguageCodeData
_voiceIdSampleStringData
_canonicalLanguageCodeVoiceNamesData
T@"NSDictionary",&,N,V_generalLanguageCodeData
T@"NSDictionary",&,N,V_voiceIdSampleStringData
T@"NSDictionary",&,N,V_canonicalLanguageCodeVoiceNamesData
speechRequestDidStartForService:
speechRequestDidPauseForService:
speechRequestDidContinueForService:
speechRequestMarker:didStartForService:
speechRequestDidStopWithSuccess:phonemesSpoken:forService:error:
speechRequestDidSynthesizeSilentlyToURL:forService:
text
setText:
attributedText
setAttributedText:
voice
setVoice:
ssmlRepresentation
setSsmlRepresentation:
speechString
setSpeechString:
synthesisProviderVoice
setSynthesisProviderVoice:
languageCode
setLanguageCode:
setGender:
outputPath
setOutputPath:
rate
setRate:
pitch
setPitch:
volume
setVolume:
maintainsInput
setMaintainsInput:
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
skipLuthorRules
setSkipLuthorRules:
audioSessionIDIsValid
setAudioSessionIDIsValid:
audioSessionID
setAudioSessionID:
latency
setLatency:
dispatchTime
setDispatchTime:
handledTime
setHandledTime:
useMonarchStyleRate
setUseMonarchStyleRate:
channels
setChannels:
synthesizerInstanceID
setSynthesizerInstanceID:
clientContext
setClientContext:
audioBufferCallback
setAudioBufferCallback:
originalWordRanges
setOriginalWordRanges:
processedWordRanges
setProcessedWordRanges:
replacedWords
setReplacedWords:
wordRangeCallbacksDispatched
setWordRangeCallbacksDispatched:
synthesizeSilently
setSynthesizeSilently:
_maintainsInput
_supportsAccurateWordCallbacks
_skipLuthorRules
_audioSessionIDIsValid
_useMonarchStyleRate
_synthesizeSilently
_audioSessionID
_text
_attributedText
_voice
_ssmlRepresentation
_speechString
_synthesisProviderVoice
_languageCode
_outputPath
_rate
_pitch
_volume
_latency
_dispatchTime
_handledTime
_channels
_synthesizerInstanceID
_clientContext
_audioBufferCallback
_originalWordRanges
_processedWordRanges
_replacedWords
_wordRangeCallbacksDispatched
T@"NSString",C,N,V_text
T@"NSAttributedString",C,N,V_attributedText
T@"TTSSpeechVoice",C,N,V_voice
T@"NSString",C,N,V_ssmlRepresentation
T@"TTSSpeechString",&,N,V_speechString
T@"AVSpeechSynthesisProviderVoice",C,N,V_synthesisProviderVoice
T@"NSString",C,N,V_languageCode
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_maintainsInput
TB,N,V_supportsAccurateWordCallbacks
TB,N,V_skipLuthorRules
TB,N,V_audioSessionIDIsValid
TI,N,V_audioSessionID
Td,N,V_latency
Td,N,V_dispatchTime
Td,N,V_handledTime
TB,N,V_useMonarchStyleRate
T@"NSArray",&,N,V_channels
TQ,N,V_synthesizerInstanceID
T^v,N,V_clientContext
T@?,C,N,V_audioBufferCallback
T@"NSString",&,N,V_originalString
T@"NSMutableArray",&,N,V_originalWordRanges
T@"NSMutableArray",&,N,V_processedWordRanges
T@"NSMutableArray",&,N,V_replacedWords
Tq,N,V_wordRangeCallbacksDispatched
TB,N,V_synthesizeSilently
markType
Tq,R,N
wordRange
setWordRange:
_wordRange
T{_NSRange=QQ},N,V_wordRange
phoneme
setPhoneme:
alphabet
setAlphabet:
_phoneme
_alphabet
T@"NSString",&,N,V_phoneme
Tq,N,V_alphabet
setName:
T@"NSString",&,N,V_name
initWithName:identifier:primaryLanguages:supportedLanguages:
groupName
supportedCharacterSet
uniqueAudioDescTriple
uniqueAudioDescSpeechSynthTuple
fullBundleIdentifier
setAuComponentDesc:
auComponentDesc
setManufacturerName:
manufacturerName
setPrimaryLanguages:
primaryLanguages
setSupportedLanguages:
supportedLanguages
setExtraAttributes:
extraAttributes
updateSpeechVoices
T@"NSArray",&,N
T@"NSDictionary",&,N
T{AudioComponentDescription=IIIII},N
T@"NSString",&,N
TB,N
_mediaServicesDied
initialize
_initializeServers
isSystemVoice:
unavailableVoiceIdentifiers
voiceForIdentifier:
employSpeechMarkupForType:identifier:withLanguage:
genericMarkMarkupForIdentifier:name:
combinedProsodyMarkupForIdentifier:string:rate:pitch:volume:
speechMarkupStringForType:forIdentifier:string:
testingSetAllVoices:
setVoiceAssetsForTesting:
voiceAssetsForTesting
synthesizerForSynthesizerID:
voiceAccessQueue
setTestingAvailableVoicesForLanguageCode:
availableVoicesForLanguageCode:queryingMobileAssets:
availableLanguageCodes
setSpeechJobFinishedUnitTestBlock:
setSpeechJobStartedUnitTestBlock:
remapVoiceIdentifier:
_speechVoiceForIdentifier:language:footprint:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMarker:
connection:speechRequest:didSynthesizeSilentlyToURL:
testingLastRuleConversion
testingSetLastRuleConversion:replacement:
_setDelegate:
setOutputChannels:
outputChannels
setUserSubstitutions:
setPhonemeSubstitutions:
resolvedVoiceIdentifier
resolvedVoiceIdentifierForLanguageCode:
voiceIdentifier
_preprocessText:languageCode:
_substitutionLanguageMatchesSpecialCase:withLanguage:
_skipSubstition:language:bundleIdentifier:voice:
_processUserSubstitutions:toText:request:bundleIdentifier:voice:
_determineSubstitution:text:wordRange:request:
applySSMLTransformation:string:voice:
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
startSpeakingString:error:
startSpeakingString:toURL:error:
startSpeakingString:withLanguageCode:error:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:error:
stopSpeakingAtNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:error:
pauseSpeakingAtNextBoundary:synchronously:error:
continueSpeakingWithError:
isSpeaking
minimumRate
maximumRate
useSpecificAudioSession:
useAudioQueueFlags:
startSpeakingString:request:error:
startSpeakingString:withLanguageCode:request:error:
startSpeakingString:toURL:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
stopSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
continueSpeakingRequest:withError:
_processMarker:forRequest:
delegateTargetQueue
setDelegateTargetQueue:
setVoiceIdentifier:
requestClientIdentifier
setRequestClientIdentifier:
speakingRequestClientContext
setSpeakingRequestClientContext:
userSubstitutions
phonemeSubstitutions
ignoreSubstitutions
setIgnoreSubstitutions:
_useSharedSession
_currentRequestOwners
_speechRequests
_synthesizerFlags
_outputChannels
_testingLastRuleConversion
_ignoreSubstitutions
_delegateTargetQueue
_voiceIdentifier
_requestClientIdentifier
_speakingRequestClientContext
_userSubstitutions
_phonemeSubstitutions
T@"<TTSSpeechSynthesizerDelegate>",W,D,N
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateTargetQueue
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
T@"NSString",&,N,V_voiceIdentifier
TQ,N,V_requestClientIdentifier
T^v,N,V_speakingRequestClientContext
TI,R,N,V_audioSessionID
T@"NSArray",C,N,V_userSubstitutions
T@"NSArray",C,N,V_phonemeSubstitutions
TB,N,V_ignoreSubstitutions
channelWithChannel:
convertChannels:
channelLabel
channelNumber
channelName
owningPortUID
channel
setChannel:
setChannelName:
setChannelNumber:
setChannelLabel:
setOwningPortUID:
_channelLabel
_channel
_channelName
_channelNumber
_owningPortUID
T@"AVAudioSessionChannelDescription",&,N,V_channel
T@"NSString",&,N,V_channelName
TQ,N,V_channelNumber
TI,N,V_channelLabel
T@"NSString",&,N,V_owningPortUID
setIPASpeechPhonemes:
IPASpeechPhonemes
T@"NSString",&,D,N
speechRequestDidStart:forService:
speechRequestDidPause:forService:
speechRequestDidContinue:forService:
speechRequest:withMarker:didStartForService:
speechRequest:didStopWithSuccess:phonemesSpoken:forService:error:
speechRequest:didSynthesizeSilentlyToURL:
initWithSpeechService:
_setRequest:
isSystemSpeakingOnBehalfOfCurrentConnection
stopCurrentSpeechRequestAtMark:waitUntilStopped:
pauseCurrentSpeechRequestAtMark:waitUntilPaused:
continueCurrentSpeechRequest
request
speechService
setSpeechService:
_request
_speechService
T@"<TTSSpeechService>",W,N,V_speechService
T@"<TTSSpeechConnectionDelegate>",W,N,V_delegate
T@"TTSSpeechRequest",R,N,V_request
localizedName:forLanguage:
setIdentifier:
localizedNameForLanguage:
language
setLanguage:
identifier
isDefault
setIsDefault:
isSystemVoice
setIsSystemVoice:
isFallbackDefault
excludeInAvailableVoiceList
voiceType
setVoiceType:
setIsNoveltyVoice:
isCombinedFootprint
nonCombinedVoiceId
setNonCombinedVoiceId:
setServiceIdentifier:
service
setService:
_isFallbackDefault
_excludeInAvailableVoiceList
_isCombinedFootprint
_language
_identifier
_voiceType
_nonCombinedVoiceId
_serviceIdentifier
_service
T@"NSString",&,N,V_serviceIdentifier
T@"<TTSSpeechService>",W,N,V_service
T@"NSString",&,N,V_language
T@"NSString",&,N,V_identifier
TB,N,V_isDefault
TB,N,V_isSystemVoice
TB,R,N,V_isFallbackDefault
TB,R,N,V_excludeInAvailableVoiceList
Tq,N,V_voiceType
TB,N,V_isNoveltyVoice
TB,R,N,V_isCombinedFootprint
T@"NSString",&,N,V_nonCombinedVoiceId
T@"AVSpeechSynthesisProviderVoice",&,N,V_synthesisProviderVoice
voiceFromAVSpeechSynthesisProviderVoice:
safelyCallStartCompletionForRequest:didStart:
didGeneratePlayableBuffers:forRequest:
_startPlaying
_stopPlaying
_pausePlaying
_safelyCallDeferredReplyBlock:
_setupOfflineEngine
_setupAudioUnitForVoice:
_setupAudioUnitForVoice:remote:
prewarmAudioUnitForVoice:
startSynthesizingSpeechRequest:reply:
startSynthesizingSpeechRequest:withBufferCallback:silently:reply:
renderWithObserver:
renderSpeechRequest:
_finishRequestRendering
pauseImmediately:
stopImmediately:
receivedMarkers:forRequest:
stopAtMark:reply:
pauseAtMark:reply:
_handleMarkerPlayback:forRequest:
playBuffers:forRequest:
audioUnit
audioUnitOutputBus
audioUnitOutputFormat
markerByteOffsetScalingFactor
isSpeechActive
offlineToRealtimePlayer
setOfflineToRealtimePlayer:
file
setFile:
avAudioUnit
setAvAudioUnit:
deferredStateChangeQueue
setDeferredStateChangeQueue:
playerState
setPlayerState:
deferredPlayerState
setDeferredPlayerState:
deferredReplyBlock
setDeferredReplyBlock:
offlineEngine
setOfflineEngine:
audioUnitObservedToken
setAudioUnitObservedToken:
playbackQueue
setPlaybackQueue:
offlineRenderingQueue
setOfflineRenderingQueue:
currentRequestHandler
setCurrentRequestHandler:
markerBlock
setMarkerBlock:
bufferCallback
setBufferCallback:
isSynthesizingSilently
setIsSynthesizingSilently:
offlineRenderingInProgress
setOfflineRenderingInProgress:
_isSynthesizingSilently
_offlineRenderingInProgress
_offlineToRealtimePlayer
_file
_avAudioUnit
_deferredStateChangeQueue
_playerState
_deferredPlayerState
_deferredReplyBlock
_offlineEngine
_audioUnitObservedToken
_playbackQueue
_offlineRenderingQueue
_currentRequestHandler
_markerBlock
_bufferCallback
T@"NSObject<TTSSynthesisProviderAudioOutput>",&,N,V_offlineToRealtimePlayer
T@"AVAudioFile",&,N,V_file
T@"AVAudioUnit",&,N,V_avAudioUnit
T@"NSObject<OS_dispatch_queue>",&,N,V_deferredStateChangeQueue
TQ,N,V_playerState
TQ,N,V_deferredPlayerState
T@?,C,N,V_deferredReplyBlock
T@"AVAudioEngine",&,N,V_offlineEngine
T@"NSNumber",&,N,V_audioUnitObservedToken
T@"NSObject<OS_dispatch_queue>",&,N,V_playbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_offlineRenderingQueue
T@"TTSSynthesisProviderRequestHandler",&,N,V_currentRequestHandler
T@?,C,N,V_markerBlock
T@?,C,N,V_bufferCallback
TB,N,V_isSynthesizingSilently
TB,N,V_offlineRenderingInProgress
T@"<TTSSynthesisProviderAudioEngineProtocol>",W,N,V_delegate
T@"AVAudioFormat",R
initWithRange:andReplacement:
sizeDelta
range
setRange:
replacement
setReplacement:
offsetFromEnd
setOffsetFromEnd:
finalRange
setFinalRange:
_replacement
_offsetFromEnd
_range
_finalRange
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_replacement
TQ,N,V_offsetFromEnd
T{_NSRange=QQ},N,V_finalRange
initWithOriginalString:
transformRange:to:
insertAtLocation:string:
encapsulateSubstringAtRange:withPrefix:andSuffix:
translateRangeInTransformedString:
transformedString
_rangeIsValid:
_insertTransformation:forEncapsulatedTerminator:
setTransformedString:
transformations
setTransformations:
_transformedString
_transformations
T@"NSString",&,N,V_transformedString
T@"NSMutableArray",&,N,V_transformations
regexForString:
regexForString:atStart:
cache
setCache:
_cache
T@"NSMutableDictionary",&,N,V_cache
initWithName:languages:gender:footprint:isInstalled:isBuiltIn:masteredVersion:compatibilityVersion:neural:
initWithDictionaryRepresentation:
dictionaryRepresentation
neural
isDownloading
setIsDownloading:
isBuiltInVoice
voicePath
setVoicePath:
fileSize
setFileSize:
_neural
_isDownloading
_isBuiltInVoice
_voicePath
_fileSize
Tq,R,N,V_footprint
TB,R,N,V_neural
TB,R,N,V_isInstalled
TB,N,V_isDownloading
TB,R,N,V_isBuiltInVoice
T@"NSString",&,N,V_voicePath
Tq,N,V_fileSize
AVMarkerMarkFromTTSMark:
AVSpeechSynthesisProviderRequestFromTTSSpeechRequest:
binaryStringRepresentationOfInt:
binaryStringRepresentationOfInt:numberOfDigits:chunkLength:
ax_nextDequeuedObjects:
setTtsServiceDidStartReplyBlock:
ttsServiceDidStartReplyBlock
T@?,C,N
T@"AVAudioSession",&,N
TI,N
lastRenderError
renderErrorFromAU:
@16@0:8
v36@0:8@16B24@28
v32@0:8@16@24
v36@0:8@"AVSpeechSynthesisProviderRequest"16B24@"NSError"28
v32@0:8@"AVSpeechSynthesisMarker"16@"AVSpeechSynthesisProviderRequest"24
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8Q16
v32@0:8@16Q24
Vv24@0:8@16
Vv32@0:8@16q24
Vv36@0:8@16B24@?28
Vv32@0:8@16@?24
@40@0:8q16@24@32
B32@0:8q16@24
@32@0:8@16@24
@24@0:8@16
@56@0:8@16q24q32q40@48
@40@0:8@16@24d32
@56@0:8@16@24@32@40@48
v32@0:8@"NSObject<OS_dispatch_queue>"16Q24
Vv24@0:8@"TTSSpeechRequest"16
Vv32@0:8@"TTSSpeechRequest"16q24
Vv36@0:8@"NSString"16B24@?<v@?@"NSArray">28
Vv32@0:8@"TTSSpeechRequest"16@?<v@?B>24
@"NSSet"16@0:8
@"NSString"40@0:8q16@"TTSSpeechVoice"24@"NSString"32
B24@0:8@"TTSSpeechVoice"16
B32@0:8q16@"NSString"24
@"NSString"32@0:8@"NSString"16@"NSString"24
@"NSString"24@0:8@"NSString"16
@"NSString"56@0:8@"NSString"16q24q32q40@"NSString"48
@"NSString"40@0:8@"TTSSpeechVoice"16@"NSString"24d32
@"NSString"56@0:8@"TTSSpeechVoice"16@"NSString"24@"NSNumber"32@"NSNumber"40@"NSNumber"48
@"NSString"32@0:8@"TTSSpeechVoice"16@"NSString"24
@"NSDictionary"24@0:8@"TTSSpeechVoice"16
v44@0:8@16@24B32@36
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v40@0:8@16@24@32
v32@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24
v44@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSError"36
v52@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v48@0:8@"TTSSpeechSynthesizer"16{_NSRange=QQ}24@"TTSSpeechRequest"40
v40@0:8@"TTSSpeechSynthesizer"16@"<TTSMarker>"24@"TTSSpeechRequest"32
v40@0:8@"TTSSpeechSynthesizer"16@"NSURL"24@"TTSSpeechRequest"32
^{__CFArray=}16@0:8
@24@0:8Q16
{_NSRange=QQ}40@0:8{_NSRange=QQ}16@32
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
v20@0:8B16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@"NSString"
@"NSSet"
@"NSUUID"
{_NSRange="location"Q"length"Q}
^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}16@0:8
v24@0:8^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}16
@?16@0:8
v24@0:8@?16
^{AudioQueueBuffer=I^vI^vI^{AudioStreamPacketDescription}I}
v32@0:8@16@?24
v20@0:8I16
v32@0:8@"AVAudioPCMBuffer"16@?<v@?>24
v24@0:8@"AVAudioSession"16
v24@0:8@"AVAudioFormat"16
^{OpaqueAudioQueue=}16@0:8
v24@0:8^{OpaqueAudioQueue=}16
I16@0:8
d16@0:8
v24@0:8d16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
^{OpaqueAudioQueue=}
@"AVAudioFormat"
@"NSCondition"
@"AVAudioSession"
@"AXAssetsService"
@"NSDictionary"
@40@0:8@16q24@32
@24@0:8q16
q24@0:8@16
@32@0:8@16q24
@36@0:8@16q24B32
@56@0:8@16q24q32@40q48
@60@0:8@16q24q32@40q48B56
@"NSNumber"
q16@0:8
Q24@0:8@16
v24@0:8q16
@"AXAsset"
@"TTSVoiceAsset"
@"NSArray"
@"TTSSpeechVoice"
q36@0:8B16q20q28
v28@0:8B16q20
{?="category"q"activity"q}
^{__CFBag=}
v32@0:8@16q24
@"NSURL"
@"AVAudioPCMBuffer"
@32@0:8@16Q24
@"<TTSSynthesisProviderHandlerDelegate>"
@"AVSpeechSynthesisProviderRequest"
@"NSMutableArray"
{AudioComponentDescription=IIIII}16@0:8
v36@0:8{AudioComponentDescription=IIIII}16
{AudioComponentDescription="componentType"I"componentSubType"I"componentManufacturer"I"componentFlags"I"componentFlagsMask"I}
B32@0:8@16r*24
B56@0:8{AudioComponentDescription=IIIII}16{AudioComponentDescription=IIIII}36
B32@0:8@16d24
@"<TTSSynthesisProviderVoiceManagerDelegate>"
v40@0:8^v16Q24@32
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
v24@0:8B16B20
@20@0:8B16
v28@0:8@16B24
@32@0:8Q16Q24
@40@0:8Q16Q24@32
Q24@0:8Q16
@28@0:8@16B24
@36@0:8@16@24B32
@"NSHashTable"
@"AXAssetController"
v44@0:8B16@20@28@36
^v16@0:8
v24@0:8^v16
@"<TTSSpeechRequestDelegate>"
@"NSAttributedString"
@"TTSSpeechString"
@"AVSpeechSynthesisProviderVoice"
@48@0:8@16@24@32@40
B40@0:8q16@24@32
@40@0:8@16@24q32
v32@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24
v52@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"<TTSMarker>"32
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"NSURL"32
v20@0:8f16
B32@0:8@16@24
B48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@56@0:8@16@24{_NSRange=QQ}32@48
B64@0:8@16@24@32@40^@48^@56
B44@0:8@16q24B32^@36
B32@0:8@16^@24
B40@0:8@16@24^@32
B48@0:8@16@24@32^@40
B32@0:8q16^@24
B36@0:8q16B24^@28
B24@0:8^@16
f16@0:8
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B56@0:8@16@24@32^@40^@48
B40@0:8@16q24^@32
@"<TTSSpeechSynthesizerDelegate>"
{?="delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateDidEncounterMarkerWithRequest"b1"delegateSynthesizedSilentlyURL"b1"willUseInput"b1}
@"AVAudioSessionChannelDescription"
Vv32@0:8@16@24
Vv40@0:8@16@24@32
Vv52@0:8@16B24@28@36@44
Vv32@0:8@"TTSSpeechRequest"16@"<TTSSpeechService>"24
Vv40@0:8@"TTSSpeechRequest"16@"<TTSMarker>"24@"<TTSSpeechService>"32
Vv52@0:8@"TTSSpeechRequest"16B24@"NSString"28@"<TTSSpeechService>"36@"NSError"44
Vv32@0:8@"TTSSpeechRequest"16@"NSURL"24
v28@0:8q16B24
@"<TTSSpeechConnectionDelegate>"
@"TTSSpeechRequest"
@"<TTSSpeechService>"
v32@0:8@"NSArray"16@"AVSpeechSynthesisProviderRequest"24
B28@0:8@16B24
v44@0:8@16@?24B32@?36
v32@0:8q16@?24
@"<TTSSynthesisProviderAudioEngineProtocol>"
@"NSObject<TTSSynthesisProviderAudioOutput>"
@"AVAudioFile"
@"AVAudioUnit"
@"AVAudioEngine"
@"TTSSynthesisProviderRequestHandler"
@40@0:8{_NSRange=QQ}16@32
B40@0:8{_NSRange=QQ}16@32
B32@0:8Q16@24
B48@0:8{_NSRange=QQ}16@32@40
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
B32@0:8{_NSRange=QQ}16
@76@0:8@16@24q32q40B48B52@56@64B72
q24@0:8q16
@32@0:8q16I24I28
i16@0:8
i24@0:8^{OpaqueAudioComponentInstance=}16
