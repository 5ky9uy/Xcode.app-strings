[[SSMLESCAPED]]
[[[SSMLESCAPED]]]
%@<say-as interpret-as="characters">%@</say-as>%@
%@<break time="%%dms" />%@
<speak>
</speak>
%@%@%@
v8@?0
%@(?<enclosedssml>((.|\n)*?))%@
(?<delimiter>(%@|%@))
delimiter
enclosedssml
\amp;
\quot;
\#39;
\#47;
\gt;
\lt;
STARTED
DID NOT START
v12@?0B8
v28@?0@"AVAudioPCMBuffer"8@"NSArray"16B24
-[TTSSynthesisProviderSpeechServer supportedIPAPhonemeLanguages]
-[TTSSynthesisProviderSpeechServer synthesizerInstanceDestroyed:]
-[TTSSynthesisProviderSpeechServer employSpeechMarkupForType:language:]
-[TTSSynthesisProviderSpeechServer audioFileSettingsForVoice:]
-[TTSSynthesisProviderSpeechServer isSiriService]
-[TTSSynthesisProviderSpeechServer isNashvilleService]
-[TTSSynthesisProviderSpeechServer canInitializeSpeech:]
-[TTSSynthesisProviderSpeechServer loadedVoiceResources]
+[TTSSynthesisProviderSpeechServer regexRules]
TTSErrorDomain
originalString
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
ignoreCase
appliesToAllApps
uuid
replacementRange
%@: Original: %@, Replacement: %@, Phonemes: %@, Languages: %@
self
com.apple.speech.synthesis.voice.alex
com.apple.speech.synthesis.voice.bruce
com.apple.speech.synthesis.voice.fred
com.apple.speech.synthesis.voice.agnes
com.apple.speech.synthesis.voice.princess
com.apple.speech.synthesis.voice.albert
com.apple.speech.synthesis.voice.kathy
com.apple.speech.synthesis.voice.bells
com.apple.speech.synthesis.voice.badnews
com.apple.speech.synthesis.voice.deranged
com.apple.speech.synthesis.voice.hysterical
com.apple.speech.synthesis.voice.junior
com.apple.speech.synthesis.voice.organ
com.apple.speech.synthesis.voice.bahh
com.apple.speech.synthesis.voice.zarvox
com.apple.speech.synthesis.voice.ralph
com.apple.speech.synthesis.voice.boing
com.apple.speech.synthesis.voice.cellos
com.apple.speech.synthesis.voice.goodnews
com.apple.speech.synthesis.voice.bubbles
com.apple.speech.synthesis.voice.trinoids
com.apple.speech.synthesis.voice.whisper
com.apple.speech.synthesis.voice.victoria
com.apple.speech.synthesis.voice.vicki
(?<root>com\.apple\.speech\.synthesis\.voice\.custom\.siri\.[^.]*)(\.(?<quality>(premium|compact)))?$
com\.apple\.speech\.synthesis\.voice\.(?<name>[^.]*)(\.(?<quality>premium|compact))?$
com\.apple\.ttsbundle\.(?<name>[^.]*)\-(?<quality>premium|compact|Premium|Compact)$
TTSCachedVoiceIdentifiersToMigrateKey
TTSCachedIsMigrationCompleteKey
com.apple.speech.voice.Alex
com.apple.speech.synthesis.voice.Alex
name
quality
%@.%@.%@.%@
com.apple.maui.voice
premium
enhanced
high
.maui.
%@.compact
%@.%@
%@_%@_%@_premium
com.apple.MobileAsset.VoiceServices.VoiceResources
voice_configs.plist
ar-001
ar-SA
TextToSpeech.VoiceResources
v32@?0d8q16q24
v16@?0@"TTSAsset"8
Accessibility
Download failed
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
Invalid
MacinTalk
Gryphon
Custom
Maui
Kona
LegacyCombinedVocalizer
LegacyVocalizer
SynthesizerExtension
None
Hydra
SiriNeural
Contents
Contents/VoiceBundle
AssetData
Name
VoiceId
Languages
Type
Subtype
Footprint
Gender
MemoryPeak
Build
VoiceAsset
Sample
NoveltyVoice
AssetSize
IsInstalled
CanBeDownloaded
AssetId
SpeechVoice
componentSubType
synthesizerBundleIdentifier
com.apple.speech.MacinTalkFramework.MacinTalkAUSP
com.apple.speech.MacinTalkFramework
mctk
Apple
SpeechVoiceNames
com.apple.ax.KonaTTSSupport.KonaSynthesizer
%@_VOICE_WITH_NAME
TTSAXResource<%p> Name:%@ ID:%@ Type:[%ld:%ld] Foot:%ld Langs:[%@] Installed:%ld
com.apple.voiceservices.language
com.apple.SpeakSelection
en-US
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
IPHONE_SIMULATOR_ROOT
zh-Hans
zh-CN
com.apple.language.changed
TTSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
vocalizer_resources
ax_resources
ax_gryphon_resource_order
ax_compact_resource_order
vocalizer_resource_order
_voices
default
legacy
Voice resource, Languages: %@, ContentVersion: %@, MasteredVersion: %@
_languages
_searchPathURL
s5l8942x
s5l8947x
s5l8950x
s5l8955x
s5l8960x
t7001
s7002
t8002
q24@?0@8@16
filename
mime-type
InternalBuild
DisableGryphon
com.apple.voiced
HardwarePlatform
range
com.apple.voiceservices.assetInstalled
/System/Library/PrivateFrameworks/VoiceServices.framework
/System/Library/PrivateFrameworks/TextToSpeech.framework
/System/Library/PrivateFrameworks/TextToSpeechMauiSupport.framework
TTSResources
broker.hdr.asset
broker.hdr
FormatVersion
Language
VoiceName
common
Tones
voice_format_version.plist
com.apple.voiceservices.class
title
marker.operation.queue
TTSSynthesisProviderCachedComponentsKey
com.apple.TTS.synthProviderVoicesDidUpdate
com.apple.accessibility.systemvoiceprovider
auDescType
auDescSubType
auDescManufacturer
auDescFlags
auDescFlagsMask
bundleIdentifier
version
isFirstParty
voices
%@ %@ %@
auspmanager.voiceloading
auspmanager.componentquery
B32@?0@"TTSSynthesisProviderComponentRecord"8Q16^B24
B32@?0@"AVAudioUnitComponent"8Q16^B24
@16@?0@"AVAudioUnitComponent"8
@16@?0@"AVSpeechSynthesisProviderVoice"8
v24@?0@"AVAudioUnit"8@"NSError"16
com.apple.siri.SiriTTSService.synthesizer
TTSEnableSiriSynthesisProvider
Contents/%@.caf
Info.plist
MobileAssetProperties
/Library/Caches/TTSResourceCache.plist
com.apple.speech.synthesis.voice.Vicki
AllCachedAvailableResourcesKey
TTSResourceCacheVersionKey
TTSCachedBuildNumberKey
com.accessibility.resourcepref
com.accessibility.asset-loading
%@=%ld 
v32@?0@"NSString"8@"NSArray"16^B24
v16@?0@"<TTSAXResourceManagerObserver>"8
v28@?0d8B16@"NSError"20
@unionOfArrays.self
B32@?0@"TTSAXResource"8Q16^B24
com.apple.voice.compact
compact
super-compact
^[^-]{2,3}-[^-]{2,3}(-[^-]{2,3})?$
B32@?0@"TTSSpeechVoice"8Q16^B24
@16@?0@"TTSSpeechVoice"8
@16@?0@"TTSAXResource"8
@16@?0@"TTSVoiceAsset"8
Alex
v24@?0@"NSArray"8@"NSError"16
GeneralLanguageCodeMap
VoiceIdSampleStringMap
CanonicalLanguageCodeVoiceNamesMap
plist
FALLBACK_SAMPLE_TEXT
[%@ %p] %@ language: %@ footprint: %@ rate: %lf pitch: %lf volume: %lf
textForAttributes
attributes
text
languageCode
voice
outputPath
gender
rate
pitch
volume
maintainsInput
audioSessionIDIsValid
audioSessionID
audioQueueFlags
ssmlRepresentation
synthesisProviderVoice
premium-high
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
VoiceVersion
Version
_CompatibilityVersion
_MasteredVersion
male
female
neural
CombinedVoiceProject
LanguagesCompatibility
.compact.
.super-compact.
.premium.
kTTSSynthesisProviderVoiceAttributeGroupName
%c%c%c%c
AU Desc: (Manufacturer: %u) (Type: %u) (SubType: %u) (Flags: %u) (Flag Mask: %u)
%@_%@_%@
%@_%@
AU Desc: (Manufacturer: %@) (Type: %@) (SubType: %@) (Flags: %u) (Flag Mask: %u)
com.apple.SynthesisProvider.updatedVoices
[%@ %p] Name: %@, Identifier: %@, Supported Languages %@, Age: %li, Gender: %li, Size: %lli, Version: %@
%@, AUComponent %@
identifier
supportedLanguages
primaryLanguages
voiceSize
manufacturerName
extraAttributes
com.apple.ttsbundle
com.apple.ttsbundle.siri
com.apple.ttsbundle.gryphon
com.apple.ttsbundle.gryphon-neural
com.apple.speech.synthesis.voice
com.apple.voice
speech.synthesis.provider.
AllCachedAvailableVoicesKey
language-creation
System/Library/TTSPlugins
TTSSpeechBundle
speechbundle
original
replacement
q24@?0@"TTSSpeechVoice"8@"TTSSpeechVoice"16
TTSSpeechSynthesizer
v32@?0@"TTSSubstitution"8Q16^B24
he-IL
ja-JP
\b%@\b
(?<=\s|^)%@(?=\s|$)
q24@?0@"NSDictionary"8@"NSDictionary"16
_male
_female
speech string is empty
siri
identifier == %@
not currently speaking
no active speech job
TTSAudioSessionChannel -> %@
AFLocalization
Class getAFLocalizationClass(void)_block_invoke
TTSSpeechSynthesizer.m
Unable to find class %s
void *AssistantServicesLibrary(void)
There was no speech service used to initiate audio
v16@?0@"NSArray"8
%@[%p]: Name: %@ Identifier: %@ Footprint: %d Language: %@ Gender: %@ [default %d] [fallbackDefault: %d] Provider: %@
language
footprint
isDefault
isFallbackDefault
canBeDownloaded
isNoveltyVoice
isSystemVoice
voiceType
serviceIdentifier
nonCombinedVoiceId
com.apple.eloquence
synthprovider.stateChange
synthprovider.playbackQueue
synthprovider.offlineRendering
v24@?0@"NSArray"8@"AVSpeechSynthesisProviderRequest"16
macintalk
v32@?0I8r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}12I20q24
v24@?0@"AVAudioPCMBuffer"8B16B20
@16@?0@"AVSpeechSynthesisMarker"8
v16@?0q8
synthprovider.playerState
synthprovider.engineShutdown
synthprovider.completionHandler
B32@?0@"TTSStringTransformation"8Q16^B24
q24@?0@"TTSStringTransformation"8@"TTSStringTransformation"16
%@ Name: %@, Languages: %@, Gender: %@, Footprint: %@, Neural: %@, Installed: %@, Version: %@/%@
_name
_gender
_footprint
_isInstalled
_isBuiltInVoice
_voicePath
_neural
fileSizeWithNumber
MasteredVersion
CompatabilityVersion
ContentVersion
VoicePath
com.apple.Accessibility
TTSRosebud
Default
Compact
Super Compact
Premium
Premium High
Male
Female
pt-BR
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
PTQ+ABwag03BwO/CKvIK/A
HWModelStr
n111
n121
Maged
bg-BG
Daria
ca-ES
Montserrat
hr-HR
Lana
uk-UA
Lesya
vi-VN
Linh
ms-MY
Amira
Sinji
cs-CZ
Zuzana
da-DK
Sara
nl-BE
Ellen
nl-NL
Xander
en-AU
Karen
en-IE
Moira
Daniel
Samantha
en-IN
Rishi
en-ZA
Tessa
fi-FI
Satu
fr-CA
Amelie
fr-FR
Thomas
de-DE
Anna
el-GR
Melina
Carmit
hi-IN
Lekha
hu-HU
Mariska
id-ID
Damayanti
it-IT
Alice
Kyoko
ko-KR
Yuna
Tingting
Meijia
nb-NO
Nora
pl-PL
Zosia
Luciana
pt-PT
Joana
ro-RO
Ioana
ru-RU
Milena
sk-SK
Laura
es-ES
Monica
es-MX
Paulina
sv-SE
Alva
th-TH
Kanya
tr-TR
Yelda
VSUtilities
Class getVSUtilitiesClass(void)_block_invoke
TTSSharedUtilities.m
void *VoiceServicesLibrary(void)
%@%i
ttsStartReplyBlockKey
ttsAudioSessionKey
ttsAudioDeviceKey
VoiceProvider: Initializing server for %@
VoiceProvider: error creating ssml de-escaping regex: %@
VoiceProvider: error creating ssml delimiter regex: %@
VoiceProvider: cant find synthesizer for: %@
VoiceProvider: Converted request: %@
Retrieved Audio Session ID was different than requested!
VoiceProvider: Hit reply block of startSynthesizingSpeechRequest: %@
VoiceProvider: Could not start synthesis for request %@, converted from tts request %@
VoiceProvider: Pause at mark %@ speaking request: %@
VoiceProvider: [pause] cant find synthesizer for: %@
VoiceProvider: Request did not pause as expected for. %@
VoiceProvider: Warning: Unhandled TTSSpeechMark. Please implement.
VoiceProvider: [continue] cant find synthesizer for: %@
VoiceProvider: Continue Speech Request: %@
VoiceProvider: Could not continue speech request %@
VoiceProvider: Hit Stop speaking request: %@
VoiceProvider: [stop] cant find synthesizer for: %@
VoiceProvider: Warning: Unhandled TTSSpeechMark in stopSpeechRequest. Please implement.
VoiceProvider: Hit %s
VoiceProvider: Did start speaking string at range (%@, %@)
VoiceProvider: Marker out of range! %@
MarkerBufferGroupings: bytesPerFrame was 0!
MarkerBufferGroupings: byteSampleOffset larger than frame length!
Creating noMetadataSplit returned nil!
Creating metadataSplit returned nil! Creating empty buffer with markers.
Word callbacks for offset %@ forwarded to next buffer group.
AVAudioPCMBuffer copy(from) - no capacity!
AVAudioPCMBuffer copy(from) - formats must match!
AVAudioPCMBuffer copy(from) - No frames to copy!
AVAudioPCMBuffer copyStarting - Starting sample out of range!
AVAudioPCMBuffer copyStarting - Could not create buffer!
AVAudioPCMBuffer copyUpTo - Could not create buffer!
AVAudioPCMBuffer copyFromUpTo - Starting sample out of range!
AVAudioPCMBuffer copyFromUpTo - Starting sample equal to ending sample!
AVAudioPCMBuffer copyFromUpTo - Could not create buffer!
Could not split buffers
Migration is not complete, attempting to complete now.
Migration is complete, no need to restart.
Unable to find updated identifier for nil legacy identifier using language code: %@
No voice found for language code: %@. Attempting to find fallback language.
Found fallback language code: %@
Compact resource is not installed, falling back to on disk super-compact variant %@ => %@
Beginning download for compact resource from %@
Unable to complete migration for resource: %@, remaining voices to migrate: %@
Voices left to migrate: %@
Error writing migration complete flag to preferences: %@
Error unarchiving flag for completed migration: %@
Error, process other than axassetsd tried to write migration voice list to preferences
Error writing voices to migrate to preferences: %@
Error unarchiving voices to migrate: %@
SiriTTS returned nil deprecated voices. %@
Found installed voice resources for %@: %@
Downloading voice resources asset %@
Downloaded voice resources for %@
Wrong voice type passed in %@
Reqeuesting cancel asset download
Canceled asset download
TTSAsset::listAssetsOfTypes (voiceTypes=%@ filter=%@): %@
Setting importance to %d
Could NOT set the thread priority
Successfully set the thread priority
Normal thread priority is %d
session interrupted
mediaserverd died
AUDIOSESSION: Setting up audio session
error setting HW sample rate: %ld
AUDIOSESSION: category = %d
error %ld setting audio category
error %ld setting bluetooth allowability
AUDIOSESSION: Bluetooth %sabled
active count went negative for input!
active count went negative for output!
active count went negative!
AUDIOSESSION: activity %d --> %s
AUDIOSESSION: Active --> FALSE
AUDIOSESSION: Active --> TRUE
error %ld activating or deactivating session for activity %ld
could not stop queue (%d)
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Couldn't initialize the engine voice format versions
[TTSSynthesisProviderRequestHandler init] Cannot use 0 bytes per frame!
Markers were sent out of order. Need to sort
Called completedRequestRendering more than once!
TTSVoiceProvider::Reconcile records: Source cache: %ld
  - %@
TTSVoiceProvider::Component cache updated with %@ additions and %@ evictions.
VoiceProvider: voice load failed for component %@ after %@ attempts.
VoiceProvider: Recovered cache entry for first party SSE %@
VoiceProvider audio component initialization error %@
VoiceProvider could not retrieve remote pid %@, subtype: %@
VoiceProvider voices returned nil for record %@
VoiceProvider loaded %@ voices for bundle identifier: %@
VoiceProvider voice load timed out for record %@.
VoiceProvider: failed to set component cache preference %@.
all voices %@
VoiceProvider: failed to read component cache preference.
VoiceProvider: failed to decode component cache preference with exception: %@
Allowing Siri TTS service synthesizer
Skipping Siri TTS service synthesizer
Requesting resources. waitForInstalledAssets=%ld. Found resources in cache: %@
Requesting resources. waitForInstalledAssets=%ld. No resources found in cache. Setting resources to on-disk resources for maui/macintalk/legacy
Requesting resources. Found locally available resources: %@
Returning requesting resources. waitForInstalledAssets=%ld. %@
Updating in-memory resources: %@
Running block to compute expensive resources
Will ask assetController to refresh only-installed TTSResource AXAssets now
Tried to merge in installed assets before initial in-memory cache build.
Updating cache after computing expensive resources
Will merge in expensive resources. sync=%ld
Samples asset has not been initialized, attempting to read from mobile asset.
Samples asset was nil, it has not been downloaded yet.
Samples asset has been found: %@
Will refresh resources for type: %@
Failed to load maui/macintalk on-disk resources. Could not find maui framework!
Will ask assetController to refresh TTSResource AXAssets now
Requested axassetsd to rebuild the preferences cache
No download resource in _stopDownloadSiriVoiceAssetWithResource:
No asset for resource: %@
Stopped downloading %@
No resource for download: %@
Resource already installed: %@
Started downloading %@
No resource in _downloadSiriVoiceAssetWithResource:
Cannot download Siri asset. No asset instance found for resource: %@
Will ask SiriTTS to download asset: %@
Siri asset download progress: %{public}@ %{public}f
Speech sample DL: Already downloaded. Bailing
Speech sample DL: Already in progress. downloadingSamples=%ld samplesAsset.isDownloading=%ld
Speech sample DL: Could not find sample asset to download.
Speech sample DL: About to kick off download.
Speech sample DL: Samples started download.
Error, attempted to delete asset that is not installed.
Multiple default resources found for language: %@. Returning one at random
No default resources found for language: %@. 
Will find local resources at path: %@
Error reading languages in for local resources.
Error creating language-code regex: %@
Invalid directory format %@
Error reading in local voices for language %@.
Resource for %@ is nil
Did find local resources at path: %@. %@
Attempted to play a sample, but not sample assets were found
Requesting refreshed TTSResource assets (sync). onlyInstalled=%ld
Resetting in-memory resources to nil
Error: A process other than axassetsd attempted to write to the preferences cache.
No resource cache version found in preferences
Read resource cache version from preferences: %@
No catalog build number found in preferences
Read catalog build number from preferences: %@
Error: A process other than axassetsd attempted to write the build version to user preferences.
Cache version mismatch. Returning nil for resource preferences.
No resource data found in preferences
Error unarchiving resources: %@
Error unarchiving resources: unexpected type %@
Read resources cache from preferences: %@
Error writing resources to preferences: %@
AXAssetControllerObserver: Download completed for resource: %@ with asset: %@
Download failed: %@, %@
Download succeeded: %@
No download resource %@
DL progress: %{public}@ %{public}f
Will find Siri resources. onlyInstalled=%ld
Error: TTSAsset had nil name %@ or identifier %@. Asset: %@
Error: TTSAsset was nil while refreshing siri resources
Returning Siri resources (onlyInstalled=%ld): %@
Will find resources for synthesis providers
TTSAXResource.init was nil. Name must be provided in data
Did find %ld resources for synthesis providers
Will find resources for legacy assets
Legacy combined vocalizer asset or asset properties were nil: [Asset]: %@, [Asset Name]: %@, [Asset Languages]: %@, [Asset Gender]: %@, [Compact Identifier]: %@, [Premium Identifier]: %@
Returning Legacy resources: %@
Will find Macintalk resources
Did find %ld Macintalk resources
Will download legacy resource for testing: %@
Cannot download voice for testing. No assset found for ID: %@
Downloading legacy asset for testing: %@ %@
Received notification: %@. Will reset in-memory resources
Error reading general language code data.
Error reading sample string data.
Unable to find language code for voice name: %@
%@ requested speech voices be updated
Speech Error: %@
Skipping %@ since unified speech is enabled
Bundle err: %@
Unable to find voice service for identifier: %@, voice: %@, resource: %@
Could not find voice for identifier: %@
Got a voice with a nil identifier
Error: %@
Unable to retrieve cached TTS voices: %@
Media services reset
Updated identifier: %@
Error creating SSML %@
File did not exist at content path: %@ %@. Attempting to fallback to default voice for language: %@
Error: Unable to speak. No speech service: voice: %@ identifier: %@, language: %@, resource: %@
Error: Unable to speak. No request owner: service: %@ identifier: %@, language: %@
We do not have a record of this request owner: %@ [%@]
Speech processing error: [%@] / mark: %d / range: %d, %d
Channel should not be nil. Are we deallocating the TTSAudioSessionChannel but holding a reference to it, perhaps in our unit tests?
Phonemes retrieved: %@
TextToSpeech-PlaybackStarted
AudioUnit had no output busses.
Error initializing offline engine %@
Could not start offline engine. Error: %@
Setting up new AU for voice %@
Will start synthesizing with component description %@
Error: Already had an AU (%@, %@) while expecting to instantiate new AU (%@, %@)
Component was nil
Couldn't find audio unit for request %{public}@
Asked AU to synthesize %@
Now rendering %@
Realtime audio stopped during offline rendering.
Audio Unit encountered an error after sending some valid buffer.
Audio Unit failed to start after %li attempts.
Audio Unit reinitialization attempt failed.
Audio Unit reinitialization attempt succeeded! Continuing render.
SSEOfflineRenderFirstBuffer
Audio Unit Sample: %@ %@
SSEOfflineRender
Audio Unit render loop exited without completing.
Pausing immediately
VoiceProvider**: Stopping immediately
Received markers %@, for request %@
VoiceProvider**: Stopping at mark %@
VoiceProvider**: Pausing at mark %@
VoiceProvider**: Beginning deferred stop
VoiceProvider: ignoring playback request for old speech job.
playAndFlush: No more request handlers found.
VoiceProvider: Failed to restart audio engine.
VoiceProvider**: exiting buffer scheduling loop for canceled speech request.
VoiceProvider**: Ignoring AVFoundation completion callback since player should be stopped.
SSEFirstBuffer
VoiceProvider outputFormat %@ => %@
Unable to set preffered IO Buffer Duration
Unable to set preffered sample rate
Unable to set session on engine
VoiceProvider: Audio output initialization failed after %@ attempts
Could not start real-time engine. Error: %@
Could not start player on attempt %@. Error: %@
VoiceProvider**: Pausing audio engine
Error creating regex %@
Invalid language format was used to initialize TTS voice asset
?333333
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
TTSSynthesisProviderSpeechServer
TTSSynthesisProviderAudioEngineProtocol
TTSSpeechService
NSObject
TTSSpeechSynthesizerDelegate
TTSSpeechServiceUnitTesting
TTSSubstitution
NSSecureCoding
NSCoding
NSCopying
TTSSynthesisProviderPlayableBuffer
TTSSynthesisProviderMarkerSupport
SynthesisProvider
TTSAXResourceMigrationUtilities
TTSSiriAssetManager
TTSAssetBase
TTSAXResource
TTSAudioSession
TTSVoiceResourceAsset
VocalizerUtilities
TTSSpeechAdditions
TTSFormatArgument
TTSSynthesisProviderRequestHandler
TTSSynthesisProviderComponentRecord
TTSSynthesisProviderVoiceManager
TextToSpeech
TTSAXResourceManager
AXAssetControllerObserver
TTSLocaleUtilities
TTSSpeechRequest
AXSpeechPublicInterface_Private
TTSSpeechSynthesizer
TTSSpeechConnectionDelegate
D"##
TTSAudioSessionChannel
IPAPhonemeSupport
TTSSpeechRequestOwner
TTSSpeechRequestDelegate
TTSSpeechVoice
SynthesisProviderAdditions
TTSSynthesisProviderAudioEngine
TTSSynthesisProviderHandlerDelegate
TTSSynthesisProviderAudioOutput
TTSStringTransformation
TTSSpeechString
TTSRegexCache
TTSVoiceAsset
TTSProviderUtility
BinaryStringRepresentation
init
dictionary
speechEngines
numberWithUnsignedLongLong:
objectForKeyedSubscript:
synthesizerInstanceID
_speechEngineForSynthesizerInstance:
isSpeechActive
setDelegate:
setObject:forKeyedSubscript:
synthesisProviderVoice
_escapeSSML:
stringWithFormat:
initWithString:
floatValue
setRate:
setVolume:
setPitchMultiplier:
shared
generateSSMLFromAVSpeechUtterance:
error
ssmlResult
stringByReplacingOccurrencesOfString:withString:
escapedPatternForString:
regularExpressionWithPattern:options:error:
copy
length
matchesInString:options:range:
countByEnumeratingWithState:objects:count:
rangeWithName:
substringWithRange:
isEqualToString:
range
stringByPaddingToLength:withString:startingAtIndex:
stringByReplacingCharactersInRange:withString:
initWithOriginalString:
reverseObjectEnumerator
transformRange:to:
errorWithDomain:code:userInfo:
speechRequestDidStopWithSuccess:phonemesSpoken:forService:error:
ssmlRepresentation
_unescapeDelimeterBoundedSSMLInString:
setSpeechString:
speechString
transformedString
setSsmlRepresentation:
AVSpeechSynthesisProviderRequestFromTTSSpeechRequest:
valueWithNonretainedObject:
requestMapping
setObject:forKey:
audioSessionID
retrieveSessionWithID:
opaqueSessionID
setAudioSession:
speechRequestDidStartForService:
audioBufferCallback
synthesizeSilently
startSynthesizingSpeechRequest:withBufferCallback:silently:reply:
numberWithInteger:
speechRequestDidPauseForService:
pauseImmediately:
AVMarkerMarkFromTTSMark:
pauseAtMark:reply:
speechRequestDidContinueForService:
continueSpeechRequest:
stopImmediately:
stopAtMark:reply:
objectForKey:
removeObjectForKey:
mark
textRange
translateRangeInTransformedString:
originalString
_nonSSMLSubstringRangeForRange:fromSSML:
numberWithUnsignedInteger:
speechRequestMark:didStartForRange:forService:
convertRange:forSSML:
convertedRange
getVoicesForLanguage:reply:
setServiceQueue:
regexRules
synthesisProviderDidFinishSpeakingRequest:successfully:withError:
synthesisProviderDidStartSpeakingMarker:forRequest:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
initializeSpeechServerInstance:
synthesizerInstanceDestroyed:
setServiceQueue:forSynthesizerInstanceID:
startSpeechRequest:
pauseSpeechRequest:atMark:
stopSpeechRequest:atMark:
getVoicesForLanguage:queryingMobileAssets:reply:
getSpeechIsActiveForRequest:reply:
supportedIPAPhonemeLanguages
speechMarkupStringForType:voice:string:
isVoiceValid:
employSpeechMarkupForType:language:
lhPhonemesFromIPA:language:
phonemesFromIPA:language:
phonemesFromLHPhonemes:language:
enclosedStringWithPhonemes:
nashvilleVoiceIdentifier:footprint:voiceType:gender:assetVoiceName:
nashvilleVoiceName:footprint:voiceType:gender:assetVoiceName:
embeddedRateMarkupForVoice:string:rate:
embeddedPitchMarkupForVoice:string:pitch:
embeddedVolumeMarkupForVoice:string:volume:
combinedProsodyMarkupForVoice:string:rate:pitch:volume:
audioFileSettingsForVoice:
serviceIdentifier
isSiriService
isNashvilleService
isSiriNeuralVoice:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didSynthesizeSilentlyToURL:forRequest:
canInitializeSpeech:
loadedVoiceResources
serviceQueue
setRequestMapping:
setSpeechEngines:
.cxx_destruct
_serviceQueue
_requestMapping
_speechEngines
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceQueue
T@"NSMutableDictionary",&,N,V_requestMapping
T@"NSMutableDictionary",&,N,V_speechEngines
UUID
setUuid:
setIgnoreCase:
setAppliesToAllApps:
decodeObjectOfClass:forKey:
setOriginalString:
setReplacementString:
setPhonemes:
setWithObjects:
decodeObjectOfClasses:forKey:
setLanguages:
setVoiceIds:
setBundleIdentifiers:
decodeBoolForKey:
setActive:
rangeValue
setReplacementRange:
encodeObject:forKey:
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
encodeBool:forKey:
ignoreCase
appliesToAllApps
uuid
replacementRange
valueWithRange:
dealloc
allocWithZone:
alphanumericCharacterSet
invertedSet
stringByTrimmingCharactersInSet:
substringToIndex:
substringFromIndex:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
isReplacementTextAllPunctuation
isReplacementTextSurroundedByPunctuation
isUserSubstitution
setIsUserSubstitution:
_active
_ignoreCase
_appliesToAllApps
_isReplacementTextAllPunctuation
_isReplacementTextSurroundedByPunctuation
_isUserSubstitution
_originalString
_replacementString
_phonemes
_languages
_voiceIds
_uuid
_bundleIdentifiers
_replacementRange
T@"NSUUID",&,N,V_uuid
T@"NSString",C,N,V_originalString
T@"NSString",C,N,V_replacementString
T@"NSString",C,N,V_phonemes
T@"NSSet",C,N,V_languages
T@"NSSet",C,N,V_voiceIds
TB,N,V_active
TB,N,V_ignoreCase
T{_NSRange=QQ},N,V_replacementRange
TB,N,V_appliesToAllApps
T@"NSSet",C,N,V_bundleIdentifiers
TB,R,N,V_isReplacementTextAllPunctuation
TB,R,N,V_isReplacementTextSurroundedByPunctuation
TB,N,V_isUserSubstitution
startFrameOffset
setStartFrameOffset:
buffer
setBuffer:
associatedMarkers
setAssociatedMarkers:
_startFrameOffset
_buffer
_associatedMarkers
TI,N,V_startFrameOffset
T@"AVAudioPCMBuffer",&,N,V_buffer
T@"NSArray",&,N,V_associatedMarkers
format
streamDescription
byteSampleOffset
frameLength
addObject:
arrayWithObjects:count:
mutableCopy
sortDescriptorWithKey:ascending:
allKeys
sortedArrayUsingDescriptors:
array
unsignedIntegerValue
copyStartingFromSample:upToSample:
initWithPCMFormat:frameCapacity:
numberWithUnsignedInt:
copyStartingFromSample:
generateMarkerBufferGroupingsFromMarkers:buffer:bufferStartOffset:
frameCapacity
floatChannelData
channelCount
int16ChannelData
int32ChannelData
setFrameLength:
copyFromBuffer:fromOffset:numFrames:
copyUpToSample:
splitBufferAtByteOffset:
_readVoiceIdentifiersToMigrateFromPreferences
count
_readIsMigrationCompleteFromPreferences
isEqualToNumber:
isMigrationComplete
assetsService
restartTTSResourceMigration
lowercaseString
containsObject:
obsoleteVoicesWithReplacements
sharedInstance
regexForString:atStart:
firstMatchInString:options:range:
numberOfRanges
containsString:
capitalizedString
defaultVoiceIdentifierForGeneralLanguageCode:
languageCodeForResourceName:withType:
hasPrefix:
updatedIdentifierForLegacyIdentifier:withLanguageCode:
hasSuffix:
resourceWithVoiceId:
isInstalled
downloadResourceWithVoiceId:
deleteCompactResourceIfNeededForIdentifier:
allValues
voiceId
writeVoiceIdentifiersToMigrateToPreferences:
writeIsMigrationCompleteToPreferences:
archivedDataWithRootObject:requiringSecureCoding:error:
initForReadingFromData:error:
setWithArray:
deprecatedVoicesMap
restartMigrationIfNeeded
legacyIdentifierForUpdatedIdentifierDuringMigration:
convertIdentifierIfNeeded:
downloadCompactResourceIfNeededForIdentifier:
resourceNeedsMigration:
resourceCompletedMigration:
setAssetsService:
setIsMigrationComplete:
setObsoleteVoicesWithReplacements:
_isMigrationComplete
_assetsService
_obsoleteVoicesWithReplacements
T@"AXAssetsService",&,N,V_assetsService
TB,N,V_isMigrationComplete
T@"NSDictionary",&,N,V_obsoleteVoicesWithReplacements
dictionaryWithObjects:forKeys:count:
voiceResources
bestAssetOfTypes:matching:
downloadWithReservation:useBattery:progress:then:
setBundleIdentifier:
versionNumber
stringValue
setMasteredVersion:
setCompatibilityVersion:
setContentVersion:
supportedLanguages
locallyAvailable
bundle
bundleURL
setSearchPathURL:
URLByAppendingPathComponent:
syncWithConfigFile:voiceType:
compact
premium
premiumhigh
vocalizerVoice
customVoice
gryphonVoice
numberWithLong:
firstObject
gender
footprint
name
voiceType
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
technology
gryphon
neural
quality
string
initWithName:languages:gender:footprint:isInstalled:isBuiltIn:masteredVersion:compatibilityVersion:neural:
_voiceTypeForAssetTechnology:
bundlePath
setVoicePath:
setVoiceType:
setIdentifier:
downloading
setIsDownloading:
diskSize
unsignedIntValue
setFileSize:
ttsAssetFromVoiceAsset:
purgeImmediately:
cancelDownloadingThen:
assistantVoiceMaps
custom
vocalizer
_assetsForLanguage:voiceType:installedOnly:
_assetTechnologyForVoiceType:
_assetTypesForVoiceType:
listAssetsOfTypes:matching:
voiceAssetFromTTSAsset:
allObjects
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:
_assetFilterForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
_footprintForType:
numberWithBool:
voiceResourceForLanguage:voiceType:
spaceCheck:
purgeAsset:
assetIsDownloading:
stopDownload:
downloadAsset:progressHandler:
assetsForLanguage:voiceType:
installedAssetsForLanguage:voiceType:
installedAssetForLanguage:gender:footprint:voiceName:voiceType:
assetForLanguage:gender:footprint:voiceName:voiceType:
bundleIdentifier
compatibilityVersion
contentVersion
masteredVersion
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
properties
initWithData:
_resourceTypeFromStringInput:
_resourceSubtypeFromStringInput:
_resourceFootprintFromStringInput:
_resourceGenderFromStringInput:
boolValue
integerValue
_ensureMacinTalkComponent
voiceAsset
axAsset
assetId
type
primaryLanguage
subtype
setVoiceAsset:
voicePath
_isSystemVoice
refreshAssetForResource:installedOnly:
setAxAsset:
localURL
bundleWithPath:
pathForResource:ofType:
fileURLWithPath:
path
stringByAppendingPathComponent:
memoryPeak
memoryPeakExceedsActiveJetsamLimit
fileSize
unarchivedFileSize
downloadSize
setName:
setLanguage:
setFootprint:
canBeDownloaded
setCanBeDownloaded:
setIsSystemVoice:
isNoveltyVoice
setIsNoveltyVoice:
setGender:
_isDefault
setIsDefault:
synthesizerBundleIdentifier
componentSubType
initWithName:identifier:primaryLanguages:supportedLanguages:
setSynthesisProviderVoice:
setSynthesizerBundleIdentifier:
setAuComponentDesc:
setManufacturerName:
setIsFirstParty:
localizedName:forLanguage:
bundleForClass:
localizedName
speechVoice
uppercaseString
localizedStringForKey:
localizedStringWithFormat:
_isDennisVoice
componentsJoinedByString:
assetSize
decodeIntegerForKey:
encodeInteger:forKey:
initWithAsset:
contentPath
shouldFilterResourceFromUI
localizedNameWithFootprint
setAssetId:
setSpeechVoice:
setComponentSubType:
setAssetSize:
setIsInstalled:
setMemoryPeak:
_isNoveltyVoice
_isInstalled
_canBeDownloaded
_axAsset
_voiceAsset
_name
_voiceId
_type
_subtype
_gender
_assetId
_speechVoice
_synthesizerBundleIdentifier
_componentSubType
_footprint
_assetSize
_memoryPeak
T@"NSString",&,N,V_assetId
T@"TTSSpeechVoice",&,N,V_speechVoice
T@"NSString",&,N,V_synthesizerBundleIdentifier
T@"NSString",&,N,V_componentSubType
Tq,N,V_footprint
TQ,N,V_assetSize
TB,N,V_isInstalled
TB,N,V_canBeDownloaded
Tq,N,V_memoryPeak
T@"AXAsset",&,N,V_axAsset
T@"TTSVoiceAsset",&,N,V_voiceAsset
T@"NSArray",R,N,V_languages
T@"NSString",R,N,V_name
T@"NSString",R,N
T@"NSString",R,N,V_voiceId
TQ,R,N,V_type
TQ,R,N,V_subtype
Tq,R,N,V_gender
TB,R,N,V_isNoveltyVoice
cStringUsingEncoding:
stringWithUTF8String:
stringByAppendingString:
defaultCenter
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
removeObserver:
userInfo
_setupAudioSession
setPreferredSampleRate:error:
code
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
doubleValue
currentRoute
inputs
objectAtIndex:
portType
dictionaryWithContentsOfURL:
indexOfObject:
compare:
sortedArrayUsingComparator:
setResourceList:
setVoiceConfig:
voiceConfig
legacyPlatforms
defaultVoice
defaultTypeString
defaultFootprintString
resourceList
searchPathURL
_resourceList
_searchPathURL
_voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSURL",C,N,V_searchPathURL
voice
vocalizerFootprint
vocalizerGender
defaultManager
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
stringByStandardizingPath
removeItemAtURL:error:
initWithContentsOfURL:
data
appendBytes:length:
dataUsingEncoding:
appendData:
filePathURL
attributesOfItemAtPath:error:
appendString:withAttributes:
attributedStringWithFormatAndAttributes:
formatSpecifier
attributes
formattedArg
replaceCharactersInRange:withString:
setAttributes:range:
operationQueue
bytesPerFrame
queuedMarkers
ax_enqueueObject:
currentMarkerFrameLimit
setCurrentMarkerFrameLimit:
effectiveMarkerFrameLimit
setEffectiveMarkerFrameLimit:
updatePlayableBuffers
queuedBuffers
currentAudioBufferFrameCount
setCurrentAudioBufferFrameCount:
isFinishedReceivingBuffers
generatedPlayableFrames
ax_nextDequeuedObject
ax_dequeueObject
_dequeueMarkersForFrameRange:end:
setGeneratedPlayableFrames:
delegate
managingSpeechRequest
didGeneratePlayableBuffers:forRequest:
setIsFinishedReceivingBuffers:
setMinimumFrameCushion:
initWithRequest:bytesPerFrame:
addMarkers:
addBuffers:
completedRequestRendering
setFrameCushion:
setManagingSpeechRequest:
setOperationQueue:
setBytesPerFrame:
minimumFrameCushion
setQueuedBuffers:
setQueuedMarkers:
_isFinishedReceivingBuffers
_currentAudioBufferFrameCount
_generatedPlayableFrames
_delegate
_managingSpeechRequest
_currentMarkerFrameLimit
_effectiveMarkerFrameLimit
_operationQueue
_bytesPerFrame
_minimumFrameCushion
_queuedBuffers
_queuedMarkers
T@"AVSpeechSynthesisProviderRequest",&,N,V_managingSpeechRequest
Tq,N,V_currentMarkerFrameLimit
Tq,N,V_effectiveMarkerFrameLimit
TI,N,V_currentAudioBufferFrameCount
T@"NSObject<OS_dispatch_queue>",&,N,V_operationQueue
TQ,N,V_bytesPerFrame
TQ,N,V_minimumFrameCushion
T@"NSMutableArray",&,N,V_queuedBuffers
T@"NSMutableArray",&,N,V_queuedMarkers
TI,N,V_generatedPlayableFrames
TB,N,V_isFinishedReceivingBuffers
T@"<TTSSynthesisProviderHandlerDelegate>",W,N,V_delegate
componentDescription
version
isFirstParty
voices
setVoices:
setVersion:
intValue
setComponentDescription:
_isFirstParty
_version
_voices
_componentDescription
T{AudioComponentDescription=IIIII},N,V_componentDescription
T@"NSString",&,N,V_bundleIdentifier
T@"NSString",&,N,V_version
TB,N,V_isFirstParty
T@"NSArray",&,N,V_voices
reconcileCachedComponents
componentCache
_reconcileCachedComponents:
_reloadVoiceForBundleIdentifierPrefix:
ax_filteredArrayUsingBlock:
macintalkAudioUnitProvider
sharedAudioUnitComponentManager
componentsMatchingDescription:
audioComponentDescription
_componentIsEqual:to:
versionString
indexOfObjectPassingTest:
removeObjectAtIndex:
ax_mappedArrayUsingBlock:
_loadVoicesForComponents:
addObjectsFromArray:
setComponentCache:
allSynthesisProviderVoices
synthesisProviderVoicesDidChange:
_loadVoicesForComponentRecord:dispatchGroup:
componentQueryQueue
_loadVoicesForComponentWithTimeout:timeout:
sleepForTimeInterval:
AUAudioUnit
remoteProcessIdentifier
informationForPlugInWithPid:
_synthesizerHasEntitlement:entitlement:
speechVoices
ax_arrayByRemovingDuplicates
manufacturerName
instantiateWithComponentDescription:options:completionHandler:
defaultCStringEncoding
allSynthesisProviderTTSVoices
identifier
voiceFromAVSpeechSynthesisProviderVoice:
remoteProcessAuditToken
voiceCache
resetInMemoryCache
T@"NSArray",&
T@"NSDictionary",R
T@"NSArray",R
reconcileCachedComponentsAsync
reloadVoicesForBundleIdentifierPrefix:
reloadVoicesForBundleIdentifierPrefixAsync:
purgeAndReloadAllComponents
_systemAudioUnitProviders
setComponentQueryQueue:
_componentQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_componentQueryQueue
T@"<TTSSynthesisProviderVoiceManagerDelegate>",W,N,V_delegate
encodeBytes:length:forKey:
decodeBytesForKey:returnedLength:
tts_encodeBytes:size:forKey:
tts_decodeBytesIntoObject:size:forKey:
tts_encodeMatrixFloat4x4:forKey:
tts_decodeMatrixFloat4x4ForKey:
policy
assetControllerWithPolicy:qosClass:shouldRefreshForAssetInstallNotifications:
setUserInitiated:
addObserver:
weakObjectsHashTable
resources:
_readResourcesFromPreferences
_debugCountSummaryForResources:
_findLocalResourcesForPath:
addEntriesFromDictionary:
_getSynthesisProviderResources
_updateCachedResources:
_mergeInExpensiveInstalledAssets:notifyObservers:
appendString:
appendFormat:
enumerateKeysAndObjectsUsingBlock:
_findResourcesForLegacyAssets
_axAssetsForTTSAXResourceModel:
_resourcesForAssets:
_refreshSiriResources:
_dictionaryForResources:
_findAndSwapLegacyMacinTalkAssetsForMacinTalkResources:
setAllAvailableLanguages:
_notifyObserversOfCacheUpdate
assetLoadingQueue
_refreshSamples:
assetController
refreshAssetsWithAttributesSynchronously:installedOnly:
updateTTSResourcesForActionType:
resourceWithAssetId:
_downloadResource:userInitiated:
downloadResourceWithVoiceId:userInitiated:
_downloadSiriVoiceAssetWithResource:
_stopDownloadSiriVoiceAssetWithResource:
_stopDownloadResource:
finishedDownloadingResource:wasCancelled:
_performBlockOnObservers:
_refreshAssetForResource:withAssetController:installedOnly:
stopDownloadAsset:completion:
legacyCombinedVocalizerAssetController
downloadAssets:successStartBlock:
downloadProgressForVoiceId:progress:storageSize:requiredDiskSpace:
samplesAsset
fileExistsAtPath:
isDownloading
downloadingSamples
setDownloadingSamples:
setSamplesAsset:
_deleteResource:
_deleteSiriVoiceAssetWithResource:
legacyMacinTalkAssetController
purgeAssetsSynchronously:
rebuildSystemCacheForActionType:
finishedDeletingResource:
_resourcesWithType:subType:languageCode:waitForInstalledAssets:
resourcesWithType:subType:waitForInstalledAssets:
valueForKeyPath:
_resourceWithVoiceId:assetId:
resources
resourcesWithLanguage:type:
isDefault
resourcesWithType:subType:
contentsOfDirectoryAtPath:error:
dictionaryWithContentsOfFile:
allVoices:
allVoices:waitForInstalledAssets:
language
ax_flatMappedArrayUsingBlock:
arrayByAddingObjectsFromArray:
setByAddingObjectsFromArray:
refreshInstalledAssetsSynchronously
refreshWithoutCatalogUpdateSynchronously
purgeInMemoryCachedAssets
resourceCacheDidReceiveUpdate
assetPolicy
updateAssetForPolicy:
_readCatalogBuildNumberFromPreferences
componentsSeparatedByString:
_refreshResourcesForManagerType:
preferenceWriteQueue
_writeResourceCacheVersionToPreferences
_writeResourcesToPreferences:
readResourceCacheVersionFromPreferences
unarchivedObjectOfClasses:fromData:error:
removeObject:
primaryLanguages
isAssetCatalogInstalled
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
downloadResourceWithAssetId:
stopDownloadResourceWithVoiceId:
downloadSamplesIfNecessary
deleteResourceWithAssetId:
deleteResourceWithVoiceId:
defaultVoiceForLanguage:
superCompactVoiceIdForCompactVoiceId:
speechVoiceWithVoiceId:
refreshedResourcesForResources:
sampleURLForVoiceId:
allLanguagesForVoices:waitForInstalledAssets:
allAvailableLanguages
_managerTypeForResourceType:
_isValidResourceTypeKey:
resetResourcesCache
resetInMemoryAssetCatalogs
updateCatalogIfNeeded
catalogBuildVersion
refreshResourcesCacheForManagerType:
updateCatalogBuildVersion:
_downloadLegacyResourceForTesting:
setAssetController:
setLegacyCombinedVocalizerAssetController:
setLegacyMacinTalkAssetController:
setCatalogBuildVersion:
setPreferenceWriteQueue:
setAssetLoadingQueue:
_resourcesLock
_resourcesById
_resources
_observersLock
_observers
_downloadingSamples
_assetController
_legacyCombinedVocalizerAssetController
_legacyMacinTalkAssetController
_allAvailableLanguages
_samplesAsset
_catalogBuildVersion
_preferenceWriteQueue
_assetLoadingQueue
T@"AXAssetController",&,N,V_assetController
T@"AXAssetController",&,N,V_legacyCombinedVocalizerAssetController
T@"AXAssetController",&,N,V_legacyMacinTalkAssetController
T@"NSSet",&,N,V_allAvailableLanguages
T@"AXAsset",&,N,V_samplesAsset
T@"NSString",&,N,V_catalogBuildVersion
TB,N,V_downloadingSamples
T@"NSObject<OS_dispatch_queue>",&,N,V_preferenceWriteQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetLoadingQueue
generalLanguageCodeData
voiceIdSampleStringData
canonicalLanguageCodeVoiceNamesData
sampleStringForVoiceIdentifier:
defaultVoiceIdentifierForVoiceName:
setGeneralLanguageCodeData:
setVoiceIdSampleStringData:
setCanonicalLanguageCodeVoiceNamesData:
_generalLanguageCodeData
_voiceIdSampleStringData
_canonicalLanguageCodeVoiceNamesData
T@"NSDictionary",&,N,V_generalLanguageCodeData
T@"NSDictionary",&,N,V_voiceIdSampleStringData
T@"NSDictionary",&,N,V_canonicalLanguageCodeVoiceNamesData
encodeDouble:forKey:
encodeInt32:forKey:
setText:
setLanguageCode:
setVoice:
setOutputPath:
decodeDoubleForKey:
setPitch:
setMaintainsInput:
setAudioSessionIDIsValid:
decodeInt32ForKey:
setAudioSessionID:
setAudioQueueFlags:
decodePropertyListForKey:
speechRequestDidStart:forService:
speechRequestDidPause:forService:
speechRequestDidContinue:forService:
speechRequest:withMark:didStartForRange:forService:
speechRequest:didStopWithSuccess:phonemesSpoken:forService:error:
speechRequest:didSynthesizeSilentlyToURL:
speechRequestDidSynthesizeSilentlyToURL:forService:
text
attributedText
setAttributedText:
languageCode
outputPath
rate
pitch
volume
maintainsInput
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
skipLuthorRules
setSkipLuthorRules:
audioSessionIDIsValid
audioQueueFlags
latency
setLatency:
dispatchTime
setDispatchTime:
handledTime
setHandledTime:
useMonarchStyleRate
setUseMonarchStyleRate:
channels
setChannels:
setSynthesizerInstanceID:
clientContext
setClientContext:
setAudioBufferCallback:
originalWordRanges
setOriginalWordRanges:
processedWordRanges
setProcessedWordRanges:
replacedWords
setReplacedWords:
wordRangeCallbacksDispatched
setWordRangeCallbacksDispatched:
setSynthesizeSilently:
_maintainsInput
_supportsAccurateWordCallbacks
_skipLuthorRules
_audioSessionIDIsValid
_useMonarchStyleRate
_synthesizeSilently
_audioSessionID
_audioQueueFlags
_text
_attributedText
_voice
_ssmlRepresentation
_speechString
_synthesisProviderVoice
_languageCode
_outputPath
_rate
_pitch
_volume
_latency
_dispatchTime
_handledTime
_channels
_synthesizerInstanceID
_clientContext
_audioBufferCallback
_originalWordRanges
_processedWordRanges
_replacedWords
_wordRangeCallbacksDispatched
T@"NSString",C,N,V_text
T@"NSAttributedString",C,N,V_attributedText
T@"TTSSpeechVoice",C,N,V_voice
T@"NSString",C,N,V_ssmlRepresentation
T@"TTSSpeechString",&,N,V_speechString
T@"AVSpeechSynthesisProviderVoice",C,N,V_synthesisProviderVoice
T@"NSString",C,N,V_languageCode
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_maintainsInput
TB,N,V_supportsAccurateWordCallbacks
TB,N,V_skipLuthorRules
TB,N,V_audioSessionIDIsValid
TI,N,V_audioSessionID
TI,N,V_audioQueueFlags
Td,N,V_latency
Td,N,V_dispatchTime
Td,N,V_handledTime
TB,N,V_useMonarchStyleRate
T@"NSArray",&,N,V_channels
TQ,N,V_synthesizerInstanceID
T^v,N,V_clientContext
T@?,C,N,V_audioBufferCallback
T@"NSString",&,N,V_originalString
T@"NSMutableArray",&,N,V_originalWordRanges
T@"NSMutableArray",&,N,V_processedWordRanges
T@"NSMutableArray",&,N,V_replacedWords
Tq,N,V_wordRangeCallbacksDispatched
TB,N,V_synthesizeSilently
setSupportedLanguages:
setPrimaryLanguages:
setAge:
setVoiceSize:
mainBundle
UTF8String
extraAttributes
voiceSize
auComponentDesc
localeWithLocaleIdentifier:
formUnionWithCharacterSet:
numberWithLongLong:
longLongValue
decodeDictionaryWithKeysOfClasses:objectsOfClasses:forKey:
setExtraAttributes:
groupName
supportedCharacterSet
uniqueAudioDescTriple
uniqueAudioDescSpeechSynthTuple
fullBundleIdentifier
updateSpeechVoices
T@"NSArray",&,N
T@"NSDictionary",&,N
T{AudioComponentDescription=IIIII},N
T@"NSString",&,N
TB,N
initWithKeyOptions:valueOptions:capacity:
loadAndReturnError:
principalClass
_initializeServers
availableVoicesForLanguageCode:queryingMobileAssets:
voiceForIdentifier:
isSystemVoice
setService:
_speechVoiceForIdentifier:language:footprint:
service
refreshAllAvailableVoices:
availableLanguageCodes
excludeInAvailableVoiceList
localizedCompare:
sortUsingComparator:
initWithSpeechService:
lock
unlock
_mediaServicesDied
removeAllObjects
_stopSpeakingRequest:atNextBoundary:synchronously:error:
enumerateObjectsUsingBlock:
localizedUppercaseString
localizedLowercaseString
stringWithCharacters:length:
ignoreSubstitutions
_substitutionLanguageMatchesSpecialCase:withLanguage:
_skipSubstition:language:bundleIdentifier:voice:
punctuationCharacterSet
symbolCharacterSet
characterAtIndex:
characterIsMember:
rangeOfString:options:range:
_determineSubstitution:text:wordRange:request:
anyObject
stringByAppendingFormat:
objectAtIndexedSubscript:
voiceNamesForOutputLanguageCode:gender:
allAvailableVoices
isSSMLValid:
remapVoiceIdentifier:
unavailableVoiceIdentifiers
outputChannels
_preprocessText:languageCode:
phonemeSubstitutions
userSubstitutions
_processUserSubstitutions:toText:request:bundleIdentifier:voice:
applySSMLTransformation:string:voice:
nonCombinedVoiceId
predicateWithFormat:
filteredArrayUsingPredicate:
request
stopCurrentSpeechRequestAtMark:waitUntilStopped:
pauseCurrentSpeechRequestAtMark:waitUntilPaused:
continueCurrentSpeechRequest
_setDelegate:
startSpeakingString:toURL:withLanguageCode:error:
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
stopSpeakingAtNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:synchronously:error:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
lastObject
isSystemSpeakingOnBehalfOfCurrentConnection
unionSet:
delegateTargetQueue
initialize
availableVoices
isSystemVoice:
employSpeechMarkupForType:identifier:withLanguage:
combinedProsodyMarkupForIdentifier:string:rate:pitch:volume:
speechMarkupStringForType:forIdentifier:string:
testingSetAllVoices:
setVoiceAssetsForTesting:
voiceAssetsForTesting
synthesizerForSynthesizerID:
refreshAllAvailableVoices
voiceAccessQueue
setTestingAvailableVoicesForLanguageCode:
setSpeechJobFinishedUnitTestBlock:
setSpeechJobStartedUnitTestBlock:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:didSynthesizeSilentlyToURL:
testingLastRuleConversion
testingSetLastRuleConversion:replacement:
setOutputChannels:
setUserSubstitutions:
setPhonemeSubstitutions:
resolvedVoiceIdentifier
resolvedVoiceIdentifierForLanguageCode:
voiceIdentifier
startSpeakingString:error:
startSpeakingString:toURL:error:
startSpeakingString:withLanguageCode:error:
stopSpeakingAtNextBoundary:error:
pauseSpeakingAtNextBoundary:error:
continueSpeakingWithError:
isSpeaking
minimumRate
maximumRate
useSpecificAudioSession:
useAudioQueueFlags:
startSpeakingString:request:error:
startSpeakingString:withLanguageCode:request:error:
startSpeakingString:toURL:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
stopSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
continueSpeakingRequest:withError:
setDelegateTargetQueue:
setVoiceIdentifier:
requestClientIdentifier
setRequestClientIdentifier:
speakingRequestClientContext
setSpeakingRequestClientContext:
setIgnoreSubstitutions:
_useSharedSession
_currentRequestOwners
_speechRequests
_synthesizerFlags
_outputChannels
_testingLastRuleConversion
_ignoreSubstitutions
_delegateTargetQueue
_voiceIdentifier
_requestClientIdentifier
_speakingRequestClientContext
_userSubstitutions
_phonemeSubstitutions
T@"<TTSSpeechSynthesizerDelegate>",W,D,N
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateTargetQueue
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
T@"NSString",&,N,V_voiceIdentifier
TQ,N,V_requestClientIdentifier
T^v,N,V_speakingRequestClientContext
TI,R,N,V_audioSessionID
T@"NSArray",C,N,V_userSubstitutions
T@"NSArray",C,N,V_phonemeSubstitutions
TB,N,V_ignoreSubstitutions
setChannel:
channel
channelLabel
channelNumber
channelName
owningPortUID
channelWithChannel:
convertChannels:
setChannelName:
setChannelNumber:
setChannelLabel:
setOwningPortUID:
_channelLabel
_channel
_channelName
_channelNumber
_owningPortUID
T@"AVAudioSessionChannelDescription",&,N,V_channel
T@"NSString",&,N,V_channelName
TQ,N,V_channelNumber
TI,N,V_channelLabel
T@"NSString",&,N,V_owningPortUID
setIPASpeechPhonemes:
IPASpeechPhonemes
T@"NSString",&,D,N
currentHandler
handleFailureInFunction:file:lineNumber:description:
setSpeechService:
speechService
_setRequest:
_request
_speechService
T@"<TTSSpeechService>",W,N,V_speechService
T@"<TTSSpeechConnectionDelegate>",W,N,V_delegate
T@"TTSSpeechRequest",R,N,V_request
isFallbackDefault
setNonCombinedVoiceId:
setServiceIdentifier:
localizedNameForLanguage:
isCombinedFootprint
_isFallbackDefault
_excludeInAvailableVoiceList
_isCombinedFootprint
_language
_identifier
_voiceType
_nonCombinedVoiceId
_serviceIdentifier
_service
T@"NSString",&,N,V_serviceIdentifier
T@"<TTSSpeechService>",W,N,V_service
T@"NSString",&,N,V_name
T@"NSString",&,N,V_language
T@"NSString",&,N,V_identifier
TB,N,V_isDefault
TB,N,V_isSystemVoice
TB,R,N,V_isFallbackDefault
TB,R,N,V_excludeInAvailableVoiceList
Tq,N,V_voiceType
TB,N,V_isNoveltyVoice
TB,R,N,V_isCombinedFootprint
T@"NSString",&,N,V_nonCombinedVoiceId
T@"AVSpeechSynthesisProviderVoice",&,N,V_synthesisProviderVoice
receivedMarkers:forRequest:
audioUnitObservedToken
audioUnit
removeRenderObserver:
playerState
setPlayerState:
isSynthesizingSilently
offlineToRealtimePlayer
play
setBufferCallback:
setDeferredPlayerState:
stop
offlineRenderingQueue
currentRequestHandler
_finishRequestRendering
cancelSpeechRequest
setAudioUnitObservedToken:
_safelyCallDeferredReplyBlock:
pause
deferredReplyBlock
setDeferredReplyBlock:
audioUnitOutputBus
setOfflineEngine:
audioUnitOutputFormat
sampleRate
avAudioUnit
maximumFramesToRender
offlineEngine
initWithStreamDescription:
enableManualRenderingMode:format:maximumFrameCount:error:
startAndReturnError:
attachNode:
outputNode
connect:to:format:
_setupAudioUnitForVoice:remote:
registerSubclass:asComponentDescription:name:version:
audioUnitName
setMaximumFramesToRender:
setRenderingOffline:
setAvAudioUnit:
markerBlock
setSpeechSynthesisOutputMetadataBlock:
_setupOfflineEngine
_setupAudioUnitForVoice:
setIsSynthesizingSilently:
setTtsServiceDidStartReplyBlock:
_startPlaying
renderSpeechRequest:
manualRenderingFormat
manualRenderingMaximumFrameCount
tokenByAddingRenderObserver:
renderOffline:toBuffer:error:
setOutputFormat:
audioSession
safelyCallStartCompletionForRequest:didStart:
setCurrentRequestHandler:
synthesizeSpeechRequest:
renderWithObserver:
audioBufferList
numberWithInt:
numberWithFloat:
_pausePlaying
_stopPlaying
markerByteOffsetScalingFactor
setByteSampleOffset:
deferredStateChangeQueue
deferredPlayerState
playBuffers:forRequest:
playbackQueue
isRunning
bufferCallback
_handleMarkerPlayback:forRequest:
scheduleBuffer:completionCallbackType:completionHandler:
ttsServiceDidStartReplyBlock
outputBusses
prewarmAudioUnitForVoice:
startSynthesizingSpeechRequest:reply:
setOfflineToRealtimePlayer:
file
setFile:
setDeferredStateChangeQueue:
setPlaybackQueue:
setOfflineRenderingQueue:
setMarkerBlock:
offlineRenderingInProgress
setOfflineRenderingInProgress:
_isSynthesizingSilently
_offlineRenderingInProgress
_offlineToRealtimePlayer
_file
_avAudioUnit
_deferredStateChangeQueue
_playerState
_deferredPlayerState
_deferredReplyBlock
_offlineEngine
_audioUnitObservedToken
_playbackQueue
_offlineRenderingQueue
_currentRequestHandler
_markerBlock
_bufferCallback
T@"TTSSynthesisProviderAudioOutput",&,N,V_offlineToRealtimePlayer
T@"AVAudioFile",&,N,V_file
T@"AVAudioUnit",&,N,V_avAudioUnit
T@"NSObject<OS_dispatch_queue>",&,N,V_deferredStateChangeQueue
TQ,N,V_playerState
TQ,N,V_deferredPlayerState
T@?,C,N,V_deferredReplyBlock
T@"AVAudioEngine",&,N,V_offlineEngine
T@"NSNumber",&,N,V_audioUnitObservedToken
T@"NSObject<OS_dispatch_queue>",&,N,V_playbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_offlineRenderingQueue
T@"TTSSynthesisProviderRequestHandler",&,N,V_currentRequestHandler
T@?,C,N,V_markerBlock
T@?,C,N,V_bufferCallback
TB,N,V_isSynthesizingSilently
TB,N,V_offlineRenderingInProgress
T@"<TTSSynthesisProviderAudioEngineProtocol>",W,N,V_delegate
T@"AVAudioFormat",R
engine
player
mainMixerNode
outputFormat
setOutputVolume:
isPlaying
playerStateChangeQueue
detachNode:
setPreferredIOBufferDuration:error:
_play:
_scheduleEngineShutdown
completionHandlerQueue
engineShutdownQueue
engineShutdownTimer
setEngineShutdownTimer:
setEngine:
setPlayer:
setEngineShutdownQueue:
setPlayerStateChangeQueue:
setCompletionHandlerQueue:
_engine
_player
_outputFormat
_audioSession
_engineShutdownTimer
_engineShutdownQueue
_playerStateChangeQueue
_completionHandlerQueue
T@"AVAudioEngine",&,N,V_engine
T@"AVAudioPlayerNode",&,N,V_player
T@"AVAudioFormat",&,N,V_outputFormat
T@"AVAudioSession",&,N,V_audioSession
T@"NSObject<OS_dispatch_source>",&,N,V_engineShutdownTimer
T@"NSObject<OS_dispatch_queue>",&,N,V_engineShutdownQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_playerStateChangeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_completionHandlerQueue
replacement
initWithRange:andReplacement:
sizeDelta
setRange:
setReplacement:
offsetFromEnd
setOffsetFromEnd:
finalRange
setFinalRange:
_replacement
_offsetFromEnd
_range
_finalRange
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_replacement
TQ,N,V_offsetFromEnd
T{_NSRange=QQ},N,V_finalRange
_rangeIsValid:
transformations
_insertTransformation:forEncapsulatedTerminator:
insertAtLocation:string:
insertObject:atIndex:
setTransformations:
encapsulateSubstringAtRange:withPrefix:andSuffix:
setTransformedString:
_transformedString
_transformations
T@"NSString",&,N,V_transformedString
T@"NSMutableArray",&,N,V_transformations
cache
initWithPattern:options:error:
setValue:forKey:
regexForString:
setCache:
_cache
T@"NSMutableDictionary",&,N,V_cache
initWithDictionaryRepresentation:
dictionaryRepresentation
isBuiltInVoice
_neural
_isDownloading
_isBuiltInVoice
_voicePath
_fileSize
Tq,R,N,V_footprint
TB,R,N,V_neural
TB,R,N,V_isInstalled
TB,N,V_isDownloading
TB,R,N,V_isBuiltInVoice
T@"NSString",&,N,V_voicePath
Tq,N,V_fileSize
stringWithCapacity:
enumerateSubstringsInRange:options:usingBlock:
hasAMX
sortDescriptorWithKey:ascending:comparator:
compare:options:
initWithSSMLRepresentation:voice:
binaryStringRepresentationOfInt:numberOfDigits:chunkLength:
insertString:atIndex:
binaryStringRepresentationOfInt:
ax_nextDequeuedObjects:
T@?,C,N
T@"AVAudioSession",&,N
renderErrorFromAU:
lastRenderError
@16@0:8
v36@0:8@16B24@28
v32@0:8@16@24
v36@0:8@"AVSpeechSynthesisProviderRequest"16B24@"NSError"28
v32@0:8@"AVSpeechSynthesisMarker"16@"AVSpeechSynthesisProviderRequest"24
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8Q16
v32@0:8@16Q24
Vv24@0:8@16
Vv32@0:8@16q24
Vv36@0:8@16B24@?28
Vv32@0:8@16@?24
@40@0:8q16@24@32
B32@0:8q16@24
@32@0:8@16@24
@24@0:8@16
@56@0:8@16q24q32q40@48
@40@0:8@16@24d32
@56@0:8@16@24@32@40@48
v32@0:8@"NSObject<OS_dispatch_queue>"16Q24
Vv24@0:8@"TTSSpeechRequest"16
Vv32@0:8@"TTSSpeechRequest"16q24
Vv36@0:8@"NSString"16B24@?<v@?@"NSArray">28
Vv32@0:8@"TTSSpeechRequest"16@?<v@?B>24
@"NSSet"16@0:8
@"NSString"40@0:8q16@"TTSSpeechVoice"24@"NSString"32
B24@0:8@"TTSSpeechVoice"16
B32@0:8q16@"NSString"24
@"NSString"32@0:8@"NSString"16@"NSString"24
@"NSString"24@0:8@"NSString"16
@"NSString"56@0:8@"NSString"16q24q32q40@"NSString"48
@"NSString"40@0:8@"TTSSpeechVoice"16@"NSString"24d32
@"NSString"56@0:8@"TTSSpeechVoice"16@"NSString"24@"NSNumber"32@"NSNumber"40@"NSNumber"48
@"NSDictionary"24@0:8@"TTSSpeechVoice"16
v44@0:8@16@24B32@36
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v40@0:8@16@24@32
v32@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24
v44@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSError"36
v52@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v48@0:8@"TTSSpeechSynthesizer"16{_NSRange=QQ}24@"TTSSpeechRequest"40
v40@0:8@"TTSSpeechSynthesizer"16@"NSURL"24@"TTSSpeechRequest"32
^{__CFArray=}16@0:8
@24@0:8Q16
{_NSRange=QQ}40@0:8{_NSRange=QQ}16@32
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
v20@0:8B16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@"NSString"
@"NSSet"
@"NSUUID"
{_NSRange="location"Q"length"Q}
I16@0:8
v20@0:8I16
@"AVAudioPCMBuffer"
@"NSArray"
@36@0:8@16@24I32
I32@0:8@16I24I28
@20@0:8I16
@24@0:8I16I20
@"AXAssetsService"
@"NSDictionary"
@32@0:8@16q24
@24@0:8q16
v32@0:8@16@?24
q24@0:8@16
@36@0:8@16q24B32
@56@0:8@16q24q32@40q48
@60@0:8@16q24q32@40q48B56
@"NSNumber"
q16@0:8
Q24@0:8@16
v24@0:8q16
@"AXAsset"
@"TTSVoiceAsset"
@"TTSSpeechVoice"
q36@0:8B16q20q28
v28@0:8B16q20
{?="category"q"activity"q}
^{__CFBag=}
v32@0:8@16q24
@"NSURL"
@32@0:8@16Q24
@32@0:8q16q24
@"<TTSSynthesisProviderHandlerDelegate>"
@"AVSpeechSynthesisProviderRequest"
@"NSMutableArray"
{AudioComponentDescription=IIIII}16@0:8
v36@0:8{AudioComponentDescription=IIIII}16
{AudioComponentDescription="componentType"I"componentSubType"I"componentManufacturer"I"componentFlags"I"componentFlagsMask"I}
B32@0:8@16r*24
B56@0:8{AudioComponentDescription=IIIII}16{AudioComponentDescription=IIIII}36
B32@0:8@16d24
@"<TTSSynthesisProviderVoiceManagerDelegate>"
v40@0:8^v16Q24@32
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
@20@0:8B16
v24@0:8B16B20
v28@0:8@16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@44@0:8Q16Q24@32B40
@24@0:8B16B20
Q24@0:8Q16
@28@0:8@16B24
@36@0:8@16@24B32
v24@0:8@?16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"NSHashTable"
@"AXAssetController"
v48@0:8q16{_NSRange=QQ}24@40
v44@0:8B16@20@28@36
d16@0:8
v24@0:8d16
^v16@0:8
v24@0:8^v16
@?16@0:8
@"<TTSSpeechRequestDelegate>"
@"NSAttributedString"
@"TTSSpeechString"
@"AVSpeechSynthesisProviderVoice"
@48@0:8@16@24@32@40
B40@0:8q16@24@32
@40@0:8@16@24q32
v56@0:8@16@24q32{_NSRange=QQ}40
v32@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24
v52@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"NSURL"32
v20@0:8f16
B32@0:8@16@24
B48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@56@0:8@16@24{_NSRange=QQ}32@48
B64@0:8@16@24@32@40^@48^@56
B44@0:8@16q24B32^@36
B32@0:8@16^@24
B40@0:8@16@24^@32
B48@0:8@16@24@32^@40
B32@0:8q16^@24
B36@0:8q16B24^@28
B24@0:8^@16
f16@0:8
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B56@0:8@16@24@32^@40^@48
B40@0:8@16q24^@32
@"<TTSSpeechSynthesizerDelegate>"
{?="delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateSynthesizedSilentlyURL"b1"willUseInput"b1}
@"AVAudioSessionChannelDescription"
Vv32@0:8@16@24
Vv56@0:8@16q24{_NSRange=QQ}32@48
Vv52@0:8@16B24@28@36@44
Vv32@0:8@"TTSSpeechRequest"16@"<TTSSpeechService>"24
Vv56@0:8@"TTSSpeechRequest"16q24{_NSRange=QQ}32@"<TTSSpeechService>"48
Vv52@0:8@"TTSSpeechRequest"16B24@"NSString"28@"<TTSSpeechService>"36@"NSError"44
Vv32@0:8@"TTSSpeechRequest"16@"NSURL"24
v28@0:8q16B24
@"<TTSSpeechConnectionDelegate>"
@"TTSSpeechRequest"
@"<TTSSpeechService>"
v32@0:8@"NSArray"16@"AVSpeechSynthesisProviderRequest"24
B28@0:8@16B24
v44@0:8@16@?24B32@?36
v32@0:8q16@?24
@"<TTSSynthesisProviderAudioEngineProtocol>"
@"TTSSynthesisProviderAudioOutput"
@"AVAudioFile"
@"AVAudioUnit"
@"AVAudioEngine"
@"TTSSynthesisProviderRequestHandler"
B24@0:8q16
v40@0:8@16q24@?32
@"AVAudioPlayerNode"
@"AVAudioFormat"
@"AVAudioSession"
@"NSObject<OS_dispatch_source>"
@40@0:8{_NSRange=QQ}16@32
B40@0:8{_NSRange=QQ}16@32
B32@0:8Q16@24
B48@0:8{_NSRange=QQ}16@32@40
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
B32@0:8{_NSRange=QQ}16
@76@0:8@16@24q32q40B48B52@56@64B72
q24@0:8q16
@32@0:8q16I24I28
i16@0:8
i24@0:8^{OpaqueAudioComponentInstance=}16
lpaa
?333333
[[SSMLESCAPED]]
[[[SSMLESCAPED]]]
%@<say-as interpret-as="characters">%@</say-as>%@
%@<break time="%%dms" />%@
<speak>
</speak>
%@%@%@
v8@?0
%@(?<enclosedssml>((.|\n)*?))%@
(?<delimiter>(%@|%@))
delimiter
enclosedssml
\amp;
\quot;
\#39;
\#47;
\gt;
\lt;
STARTED
DID NOT START
v12@?0B8
v28@?0@"AVAudioPCMBuffer"8@"NSArray"16B24
-[TTSSynthesisProviderSpeechServer supportedIPAPhonemeLanguages]
-[TTSSynthesisProviderSpeechServer synthesizerInstanceDestroyed:]
-[TTSSynthesisProviderSpeechServer employSpeechMarkupForType:language:]
-[TTSSynthesisProviderSpeechServer audioFileSettingsForVoice:]
-[TTSSynthesisProviderSpeechServer isSiriService]
-[TTSSynthesisProviderSpeechServer isNashvilleService]
-[TTSSynthesisProviderSpeechServer canInitializeSpeech:]
-[TTSSynthesisProviderSpeechServer loadedVoiceResources]
+[TTSSynthesisProviderSpeechServer regexRules]
TTSErrorDomain
originalString
replacementString
phonemes
languages
voiceIds
bundleIdentifiers
active
ignoreCase
appliesToAllApps
uuid
replacementRange
%@: Original: %@, Replacement: %@, Phonemes: %@, Languages: %@
self
com.apple.speech.synthesis.voice.alex
com.apple.speech.synthesis.voice.bruce
com.apple.speech.synthesis.voice.fred
com.apple.speech.synthesis.voice.agnes
com.apple.speech.synthesis.voice.princess
com.apple.speech.synthesis.voice.albert
com.apple.speech.synthesis.voice.kathy
com.apple.speech.synthesis.voice.bells
com.apple.speech.synthesis.voice.badnews
com.apple.speech.synthesis.voice.deranged
com.apple.speech.synthesis.voice.hysterical
com.apple.speech.synthesis.voice.junior
com.apple.speech.synthesis.voice.organ
com.apple.speech.synthesis.voice.bahh
com.apple.speech.synthesis.voice.zarvox
com.apple.speech.synthesis.voice.ralph
com.apple.speech.synthesis.voice.boing
com.apple.speech.synthesis.voice.cellos
com.apple.speech.synthesis.voice.goodnews
com.apple.speech.synthesis.voice.bubbles
com.apple.speech.synthesis.voice.trinoids
com.apple.speech.synthesis.voice.whisper
com.apple.speech.synthesis.voice.victoria
com.apple.speech.synthesis.voice.vicki
(?<root>com\.apple\.speech\.synthesis\.voice\.custom\.siri\.[^.]*)(\.(?<quality>(premium|compact)))?$
com\.apple\.speech\.synthesis\.voice\.(?<name>[^.]*)(\.(?<quality>premium|compact))?$
com\.apple\.ttsbundle\.(?<name>[^.]*)\-(?<quality>premium|compact|Premium|Compact)$
TTSCachedVoiceIdentifiersToMigrateKey
TTSCachedIsMigrationCompleteKey
com.apple.speech.voice.Alex
com.apple.speech.synthesis.voice.Alex
name
quality
%@.%@.%@.%@
com.apple.maui.voice
premium
enhanced
high
.maui.
%@.compact
%@.%@
%@_%@_%@_premium
com.apple.MobileAsset.VoiceServices.VoiceResources
voice_configs.plist
ar-001
ar-SA
TextToSpeech.VoiceResources
v32@?0d8q16q24
v16@?0@"TTSAsset"8
Accessibility
Download failed
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
Invalid
MacinTalk
Gryphon
Custom
Maui
Kona
LegacyCombinedVocalizer
LegacyVocalizer
SynthesizerExtension
None
Hydra
SiriNeural
Contents
Contents/VoiceBundle
AssetData
Name
VoiceId
Languages
Type
Subtype
Footprint
Gender
MemoryPeak
Build
VoiceAsset
Sample
NoveltyVoice
AssetSize
IsInstalled
CanBeDownloaded
AssetId
SpeechVoice
componentSubType
synthesizerBundleIdentifier
com.apple.speech.MacinTalkFramework.MacinTalkAUSP
com.apple.speech.MacinTalkFramework
mctk
Apple
SpeechVoiceNames
com.apple.ax.KonaTTSSupport.KonaSynthesizer
%@_VOICE_WITH_NAME
TTSAXResource<%p> Name:%@ ID:%@ Type:[%ld:%ld] Foot:%ld Langs:[%@] Installed:%ld
com.apple.voiceservices.language
com.apple.SpeakSelection
en-US
Auto Downloaded Assets
%@-%@
en-GB
zh-HK
zh-TW
RecognitionResources/Express
IPHONE_SIMULATOR_ROOT
zh-Hans
zh-CN
com.apple.language.changed
TTSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
vocalizer_resources
ax_resources
ax_gryphon_resource_order
ax_compact_resource_order
vocalizer_resource_order
_voices
default
legacy
Voice resource, Languages: %@, ContentVersion: %@, MasteredVersion: %@
_languages
_searchPathURL
s5l8942x
s5l8947x
s5l8950x
s5l8955x
s5l8960x
t7001
s7002
t8002
q24@?0@8@16
filename
mime-type
InternalBuild
DisableGryphon
com.apple.voiced
HardwarePlatform
range
com.apple.voiceservices.assetInstalled
/System/Library/PrivateFrameworks/VoiceServices.framework
/System/Library/PrivateFrameworks/TextToSpeech.framework
/System/Library/PrivateFrameworks/TextToSpeechMauiSupport.framework
TTSResources
broker.hdr.asset
broker.hdr
FormatVersion
Language
VoiceName
common
Tones
voice_format_version.plist
com.apple.voiceservices.class
title
marker.operation.queue
TTSSynthesisProviderCachedComponentsKey
com.apple.TTS.synthProviderVoicesDidUpdate
com.apple.accessibility.systemvoiceprovider
auDescType
auDescSubType
auDescManufacturer
auDescFlags
auDescFlagsMask
bundleIdentifier
version
isFirstParty
voices
%@ %@ %@
auspmanager.voiceloading
auspmanager.componentquery
B32@?0@"TTSSynthesisProviderComponentRecord"8Q16^B24
B32@?0@"AVAudioUnitComponent"8Q16^B24
@16@?0@"AVAudioUnitComponent"8
@16@?0@"AVSpeechSynthesisProviderVoice"8
v24@?0@"AVAudioUnit"8@"NSError"16
com.apple.siri.SiriTTSService.synthesizer
TTSEnableSiriSynthesisProvider
Contents/%@.caf
Info.plist
MobileAssetProperties
/Library/Caches/TTSResourceCache.plist
com.apple.speech.synthesis.voice.Vicki
AllCachedAvailableResourcesKey
TTSResourceCacheVersionKey
TTSCachedBuildNumberKey
com.accessibility.resourcepref
com.accessibility.asset-loading
%@=%ld 
v32@?0@"NSString"8@"NSArray"16^B24
v16@?0@"<TTSAXResourceManagerObserver>"8
v28@?0d8B16@"NSError"20
@unionOfArrays.self
B32@?0@"TTSAXResource"8Q16^B24
com.apple.voice.compact
compact
super-compact
^[^-]{2,3}-[^-]{2,3}(-[^-]{2,3})?$
B32@?0@"TTSSpeechVoice"8Q16^B24
@16@?0@"TTSSpeechVoice"8
@16@?0@"TTSAXResource"8
@16@?0@"TTSVoiceAsset"8
Alex
v24@?0@"NSArray"8@"NSError"16
GeneralLanguageCodeMap
VoiceIdSampleStringMap
CanonicalLanguageCodeVoiceNamesMap
plist
FALLBACK_SAMPLE_TEXT
[%@ %p] %@ language: %@ footprint: %@ rate: %lf pitch: %lf volume: %lf
textForAttributes
attributes
text
languageCode
voice
outputPath
gender
rate
pitch
volume
maintainsInput
audioSessionIDIsValid
audioSessionID
audioQueueFlags
ssmlRepresentation
synthesisProviderVoice
premium-high
com.apple.MobileAsset.VoiceServices.CustomVoice
com.apple.MobileAsset.VoiceServices.GryphonVoice
com.apple.MobileAsset.VoiceServices.CombinedVocalizerVoices
com.apple.MobileAsset.VoiceServicesVocalizerVoice
com.apple.MobileAsset.MacinTalkVoiceAssets
VoiceVersion
Version
_CompatibilityVersion
_MasteredVersion
male
female
neural
CombinedVoiceProject
LanguagesCompatibility
.compact.
.super-compact.
.premium.
kTTSSynthesisProviderVoiceAttributeGroupName
%c%c%c%c
AU Desc: (Manufacturer: %u) (Type: %u) (SubType: %u) (Flags: %u) (Flag Mask: %u)
%@_%@_%@
%@_%@
AU Desc: (Manufacturer: %@) (Type: %@) (SubType: %@) (Flags: %u) (Flag Mask: %u)
com.apple.SynthesisProvider.updatedVoices
[%@ %p] Name: %@, Identifier: %@, Supported Languages %@, Age: %li, Gender: %li, Size: %lli, Version: %@
%@, AUComponent %@
identifier
supportedLanguages
primaryLanguages
voiceSize
manufacturerName
extraAttributes
com.apple.ttsbundle
com.apple.ttsbundle.siri
com.apple.ttsbundle.gryphon
com.apple.ttsbundle.gryphon-neural
com.apple.speech.synthesis.voice
com.apple.voice
speech.synthesis.provider.
AllCachedAvailableVoicesKey
language-creation
System/Library/TTSPlugins
TTSSpeechBundle
speechbundle
original
replacement
q24@?0@"TTSSpeechVoice"8@"TTSSpeechVoice"16
TTSSpeechSynthesizer
v32@?0@"TTSSubstitution"8Q16^B24
he-IL
ja-JP
\b%@\b
(?<=\s|^)%@(?=\s|$)
q24@?0@"NSDictionary"8@"NSDictionary"16
_male
_female
speech string is empty
siri
identifier == %@
not currently speaking
no active speech job
TTSAudioSessionChannel -> %@
AFLocalization
Class getAFLocalizationClass(void)_block_invoke
TTSSpeechSynthesizer.m
Unable to find class %s
void *AssistantServicesLibrary(void)
There was no speech service used to initiate audio
v16@?0@"NSArray"8
%@[%p]: Name: %@ Identifier: %@ Footprint: %d Language: %@ Gender: %@ [default %d] [fallbackDefault: %d] Provider: %@
language
footprint
isDefault
isFallbackDefault
canBeDownloaded
isNoveltyVoice
isSystemVoice
voiceType
serviceIdentifier
nonCombinedVoiceId
com.apple.eloquence
synthprovider.stateChange
synthprovider.playbackQueue
synthprovider.offlineRendering
v24@?0@"NSArray"8@"AVSpeechSynthesisProviderRequest"16
macintalk
v32@?0I8r^{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}12I20q24
v24@?0@"AVAudioPCMBuffer"8B16B20
@16@?0@"AVSpeechSynthesisMarker"8
v16@?0q8
synthprovider.playerState
synthprovider.engineShutdown
synthprovider.completionHandler
B32@?0@"TTSStringTransformation"8Q16^B24
q24@?0@"TTSStringTransformation"8@"TTSStringTransformation"16
%@ Name: %@, Languages: %@, Gender: %@, Footprint: %@, Neural: %@, Installed: %@, Version: %@/%@
_name
_gender
_footprint
_isInstalled
_isBuiltInVoice
_voicePath
_neural
fileSizeWithNumber
MasteredVersion
CompatabilityVersion
ContentVersion
VoicePath
com.apple.Accessibility
TTSRosebud
Default
Compact
Super Compact
Premium
Premium High
Male
Female
pt-BR
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
PTQ+ABwag03BwO/CKvIK/A
HWModelStr
n111
n121
Maged
bg-BG
Daria
ca-ES
Montserrat
hr-HR
Lana
uk-UA
Lesya
vi-VN
Linh
ms-MY
Amira
Sinji
cs-CZ
Zuzana
da-DK
Sara
nl-BE
Ellen
nl-NL
Xander
en-AU
Karen
en-IE
Moira
Daniel
Samantha
en-IN
Rishi
en-ZA
Tessa
fi-FI
Satu
fr-CA
Amelie
fr-FR
Thomas
de-DE
Anna
el-GR
Melina
Carmit
hi-IN
Lekha
hu-HU
Mariska
id-ID
Damayanti
it-IT
Alice
Kyoko
ko-KR
Yuna
Tingting
Meijia
nb-NO
Nora
pl-PL
Zosia
Luciana
pt-PT
Joana
ro-RO
Ioana
ru-RU
Milena
sk-SK
Laura
es-ES
Monica
es-MX
Paulina
sv-SE
Alva
th-TH
Kanya
tr-TR
Yelda
VSUtilities
Class getVSUtilitiesClass(void)_block_invoke
TTSSharedUtilities.m
void *VoiceServicesLibrary(void)
%@%i
ttsStartReplyBlockKey
ttsAudioSessionKey
ttsAudioDeviceKey
VoiceProvider: Initializing server for %@
VoiceProvider: error creating ssml de-escaping regex: %@
VoiceProvider: error creating ssml delimiter regex: %@
VoiceProvider: cant find synthesizer for: %@
VoiceProvider: Converted request: %@
Retrieved Audio Session ID was different than requested!
VoiceProvider: Hit reply block of startSynthesizingSpeechRequest: %@
VoiceProvider: Could not start synthesis for request %@, converted from tts request %@
VoiceProvider: Pause at mark %@ speaking request: %@
VoiceProvider: [pause] cant find synthesizer for: %@
VoiceProvider: Request did not pause as expected for. %@
VoiceProvider: Warning: Unhandled TTSSpeechMark. Please implement.
VoiceProvider: [continue] cant find synthesizer for: %@
VoiceProvider: Continue Speech Request: %@
VoiceProvider: Could not continue speech request %@
VoiceProvider: Hit Stop speaking request: %@
VoiceProvider: [stop] cant find synthesizer for: %@
VoiceProvider: Warning: Unhandled TTSSpeechMark in stopSpeechRequest. Please implement.
VoiceProvider: Hit %s
VoiceProvider: Did start speaking string at range (%@, %@)
VoiceProvider: Marker out of range! %@
MarkerBufferGroupings: bytesPerFrame was 0!
MarkerBufferGroupings: byteSampleOffset larger than frame length!
Creating noMetadataSplit returned nil!
Creating metadataSplit returned nil! Creating empty buffer with markers.
Word callbacks for offset %@ forwarded to next buffer group.
AVAudioPCMBuffer copy(from) - no capacity!
AVAudioPCMBuffer copy(from) - formats must match!
AVAudioPCMBuffer copy(from) - No frames to copy!
AVAudioPCMBuffer copyStarting - Starting sample out of range!
AVAudioPCMBuffer copyStarting - Could not create buffer!
AVAudioPCMBuffer copyUpTo - Could not create buffer!
AVAudioPCMBuffer copyFromUpTo - Starting sample out of range!
AVAudioPCMBuffer copyFromUpTo - Starting sample equal to ending sample!
AVAudioPCMBuffer copyFromUpTo - Could not create buffer!
Could not split buffers
Migration is not complete, attempting to complete now.
Migration is complete, no need to restart.
Unable to find updated identifier for nil legacy identifier using language code: %@
No voice found for language code: %@. Attempting to find fallback language.
Found fallback language code: %@
Compact resource is not installed, falling back to on disk super-compact variant %@ => %@
Beginning download for compact resource from %@
Unable to complete migration for resource: %@, remaining voices to migrate: %@
Voices left to migrate: %@
Error writing migration complete flag to preferences: %@
Error unarchiving flag for completed migration: %@
Error, process other than axassetsd tried to write migration voice list to preferences
Error writing voices to migrate to preferences: %@
Error unarchiving voices to migrate: %@
SiriTTS returned nil deprecated voices. %@
Found installed voice resources for %@: %@
Downloading voice resources asset %@
Downloaded voice resources for %@
Wrong voice type passed in %@
Reqeuesting cancel asset download
Canceled asset download
TTSAsset::listAssetsOfTypes (voiceTypes=%@ filter=%@): %@
Setting importance to %d
Could NOT set the thread priority
Successfully set the thread priority
Normal thread priority is %d
session interrupted
mediaserverd died
AUDIOSESSION: Setting up audio session
error setting HW sample rate: %ld
AUDIOSESSION: category = %d
error %ld setting audio category
error %ld setting bluetooth allowability
AUDIOSESSION: Bluetooth %sabled
active count went negative for input!
active count went negative for output!
active count went negative!
AUDIOSESSION: activity %d --> %s
AUDIOSESSION: Active --> FALSE
AUDIOSESSION: Active --> TRUE
error %ld activating or deactivating session for activity %ld
could not stop queue (%d)
Now looking for the fallback language: %@
Looking for the resources in %@
Can't find the resources anywhere!
Found the resources here: %@
No TTS resources for asset. Trying fallback language for %@
Using asset fallback language %@
Couldn't get the engine format version for language %@
VoiceEngineFormatVersions hasn't been initialized, voices may not be compatible
Couldn't initialize the engine voice format versions
[TTSSynthesisProviderRequestHandler init] Cannot use 0 bytes per frame!
Markers were sent out of order. Need to sort
Called completedRequestRendering more than once!
TTSVoiceProvider::Reconcile records: Source cache: %ld
  - %@
TTSVoiceProvider::Component cache updated with %@ additions and %@ evictions.
VoiceProvider: voice load failed for component %@ after %@ attempts.
VoiceProvider: Recovered cache entry for first party SSE %@
VoiceProvider audio component initialization error %@
VoiceProvider could not retrieve remote pid %@, subtype: %@
VoiceProvider voices returned nil for record %@
VoiceProvider loaded %@ voices for bundle identifier: %@
VoiceProvider voice load timed out for record %@.
VoiceProvider: failed to set component cache preference %@.
all voices %@
VoiceProvider: failed to read component cache preference.
VoiceProvider: failed to decode component cache preference with exception: %@
Allowing Siri TTS service synthesizer
Skipping Siri TTS service synthesizer
Requesting resources. waitForInstalledAssets=%ld. Found resources in cache: %@
Requesting resources. waitForInstalledAssets=%ld. No resources found in cache. Setting resources to on-disk resources for maui/macintalk/legacy
Requesting resources. Found locally available resources: %@
Returning requesting resources. waitForInstalledAssets=%ld. %@
Updating in-memory resources: %@
Running block to compute expensive resources
Will ask assetController to refresh only-installed TTSResource AXAssets now
Tried to merge in installed assets before initial in-memory cache build.
Updating cache after computing expensive resources
Will merge in expensive resources. sync=%ld
Samples asset has not been initialized, attempting to read from mobile asset.
Samples asset was nil, it has not been downloaded yet.
Samples asset has been found: %@
Will refresh resources for type: %@
Failed to load maui/macintalk on-disk resources. Could not find maui framework!
Will ask assetController to refresh TTSResource AXAssets now
Requested axassetsd to rebuild the preferences cache
No download resource in _stopDownloadSiriVoiceAssetWithResource:
No asset for resource: %@
Stopped downloading %@
No resource for download: %@
Resource already installed: %@
Started downloading %@
No resource in _downloadSiriVoiceAssetWithResource:
Cannot download Siri asset. No asset instance found for resource: %@
Will ask SiriTTS to download asset: %@
Siri asset download progress: %{public}@ %{public}f
Speech sample DL: Already downloaded. Bailing
Speech sample DL: Already in progress. downloadingSamples=%ld samplesAsset.isDownloading=%ld
Speech sample DL: Could not find sample asset to download.
Speech sample DL: About to kick off download.
Speech sample DL: Samples started download.
Error, attempted to delete asset that is not installed.
Multiple default resources found for language: %@. Returning one at random
No default resources found for language: %@. 
Will find local resources at path: %@
Error reading languages in for local resources.
Error creating language-code regex: %@
Invalid directory format %@
Error reading in local voices for language %@.
Resource for %@ is nil
Did find local resources at path: %@. %@
Attempted to play a sample, but not sample assets were found
Requesting refreshed TTSResource assets (sync). onlyInstalled=%ld
Resetting in-memory resources to nil
Error: A process other than axassetsd attempted to write to the preferences cache.
No resource cache version found in preferences
Read resource cache version from preferences: %@
No catalog build number found in preferences
Read catalog build number from preferences: %@
Error: A process other than axassetsd attempted to write the build version to user preferences.
Cache version mismatch. Returning nil for resource preferences.
No resource data found in preferences
Error unarchiving resources: %@
Error unarchiving resources: unexpected type %@
Read resources cache from preferences: %@
Error writing resources to preferences: %@
AXAssetControllerObserver: Download completed for resource: %@ with asset: %@
Download failed: %@, %@
Download succeeded: %@
No download resource %@
DL progress: %{public}@ %{public}f
Will find Siri resources. onlyInstalled=%ld
Error: TTSAsset had nil name %@ or identifier %@. Asset: %@
Error: TTSAsset was nil while refreshing siri resources
Returning Siri resources (onlyInstalled=%ld): %@
Will find resources for synthesis providers
TTSAXResource.init was nil. Name must be provided in data
Did find %ld resources for synthesis providers
Will find resources for legacy assets
Legacy combined vocalizer asset or asset properties were nil: [Asset]: %@, [Asset Name]: %@, [Asset Languages]: %@, [Asset Gender]: %@, [Compact Identifier]: %@, [Premium Identifier]: %@
Returning Legacy resources: %@
Will find Macintalk resources
Did find %ld Macintalk resources
Will download legacy resource for testing: %@
Cannot download voice for testing. No assset found for ID: %@
Downloading legacy asset for testing: %@ %@
Received notification: %@. Will reset in-memory resources
Error reading general language code data.
Error reading sample string data.
Unable to find language code for voice name: %@
%@ requested speech voices be updated
Speech Error: %@
Skipping %@ since unified speech is enabled
Bundle err: %@
Unable to find voice service for identifier: %@, voice: %@, resource: %@
Could not find voice for identifier: %@
Got a voice with a nil identifier
Error: %@
Unable to retrieve cached TTS voices: %@
Media services reset
Updated identifier: %@
Error creating SSML %@
File did not exist at content path: %@ %@. Attempting to fallback to default voice for language: %@
Error: Unable to speak. No speech service: voice: %@ identifier: %@, language: %@, resource: %@
Error: Unable to speak. No request owner: service: %@ identifier: %@, language: %@
We do not have a record of this request owner: %@ [%@]
Speech processing error: [%@] / mark: %d / range: %d, %d
Channel should not be nil. Are we deallocating the TTSAudioSessionChannel but holding a reference to it, perhaps in our unit tests?
Phonemes retrieved: %@
TextToSpeech-PlaybackStarted
AudioUnit had no output busses.
Error initializing offline engine %@
Could not start offline engine. Error: %@
Setting up new AU for voice %@
Will start synthesizing with component description %@
Error: Already had an AU (%@, %@) while expecting to instantiate new AU (%@, %@)
Component was nil
SSEFirstBuffer
Couldn't find audio unit for request %{public}@
Asked AU to synthesize %@
Now rendering %@
Realtime audio stopped during offline rendering.
Audio Unit encountered an error after sending some valid buffer.
Audio Unit failed to start after %li attempts.
Audio Unit reinitialization attempt failed.
Audio Unit reinitialization attempt succeeded! Continuing render.
SSEOfflineRenderFirstBuffer
Audio Unit Sample: %@ %@
SSEOfflineRender
Audio Unit render loop exited without completing.
Pausing immediately
VoiceProvider**: Stopping immediately
Received markers %@, for request %@
VoiceProvider**: Stopping at mark %@
VoiceProvider**: Pausing at mark %@
VoiceProvider**: Beginning deferred stop
VoiceProvider: ignoring playback request for old speech job.
playAndFlush: No more request handlers found.
VoiceProvider: Failed to restart audio engine.
VoiceProvider**: exiting buffer scheduling loop for canceled speech request.
VoiceProvider**: Ignoring AVFoundation completion callback since player should be stopped.
VoiceProvider outputFormat %@ => %@
Unable to set preffered IO Buffer Duration
Unable to set preffered sample rate
Unable to set session on engine
VoiceProvider: Audio output initialization failed after %@ attempts
Could not start real-time engine. Error: %@
Could not start player on attempt %@. Error: %@
VoiceProvider**: Pausing audio engine
Error creating regex %@
Invalid language format was used to initialize TTS voice asset
softlink:r:path:/System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
softlink:r:path:/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
TTSSynthesisProviderSpeechServer
TTSSynthesisProviderAudioEngineProtocol
TTSSpeechService
NSObject
TTSSpeechSynthesizerDelegate
TTSSpeechServiceUnitTesting
TTSSubstitution
NSSecureCoding
NSCoding
NSCopying
TTSSynthesisProviderPlayableBuffer
TTSSynthesisProviderMarkerSupport
SynthesisProvider
TTSAXResourceMigrationUtilities
TTSSiriAssetManager
TTSAssetBase
TTSAXResource
TTSAudioSession
TTSVoiceResourceAsset
VocalizerUtilities
TTSSpeechAdditions
TTSFormatArgument
TTSSynthesisProviderRequestHandler
TTSSynthesisProviderComponentRecord
TTSSynthesisProviderVoiceManager
TextToSpeech
TTSAXResourceManager
AXAssetControllerObserver
TTSLocaleUtilities
TTSSpeechRequest
AXSpeechPublicInterface_Private
TTSSpeechSynthesizer
TTSSpeechConnectionDelegate
D"##
TTSAudioSessionChannel
IPAPhonemeSupport
TTSSpeechRequestOwner
TTSSpeechRequestDelegate
TTSSpeechVoice
SynthesisProviderAdditions
TTSSynthesisProviderAudioEngine
TTSSynthesisProviderHandlerDelegate
TTSSynthesisProviderAudioOutput
TTSStringTransformation
TTSSpeechString
TTSRegexCache
TTSVoiceAsset
TTSProviderUtility
BinaryStringRepresentation
objectForKeyedSubscript:
decodeBoolForKey:
int32ChannelData
appendData:
principalClass
replaceCharactersInRange:withString:
ax_filteredArrayUsingBlock:
setSpeechSynthesisOutputMetadataBlock:
stringByReplacingCharactersInRange:withString:
intValue
decodeBytesForKey:returnedLength:
appendFormat:
ax_flatMappedArrayUsingBlock:
unionSet:
enableManualRenderingMode:format:maximumFrameCount:error:
stringByReplacingOccurrencesOfString:withString:
properties
integerValue
appendString:
decodeDictionaryWithKeysOfClasses:objectsOfClasses:forKey:
localizedStringWithFormat:
ax_mappedArrayUsingBlock:
unlock
gryphon
invertedSet
stringByStandardizingPath
decodeDoubleForKey:
encodeBool:forKey:
unsignedIntValue
punctuationCharacterSet
ax_nextDequeuedObject
gryphonVoice
localizedUppercaseString
componentsJoinedByString:
stringByTrimmingCharactersInSet:
isAssetCatalogInstalled
decodeInt32ForKey:
bestAssetOfTypes:matching:
locallyAvailable
unsignedIntegerValue
encodeBytes:length:forKey:
componentsMatchingDescription:
handleFailureInFunction:file:lineNumber:description:
stringValue
decodeIntegerForKey:
purgeAssetsSynchronously:
updateAssetForPolicy:
encodeDouble:forKey:
lock
opaqueSessionID
setByAddingObjectsFromArray:
componentsSeparatedByString:
hasAMX
decodeObjectOfClass:forKey:
archivedDataWithRootObject:requiringSecureCoding:error:
purgeImmediately:
stringWithCapacity:
boolValue
encodeInt32:forKey:
longLongValue
hasPrefix:
setByteSampleOffset:
decodeObjectOfClasses:forKey:
array
purgeInMemoryCachedAssets
stringWithCharacters:length:
setMaximumFramesToRender:
lowercaseString
encodeInteger:forKey:
updateTTSResourcesForActionType:
hasSuffix:
UTF8String
stringWithFormat:
isEqualToNumber:
quality
connect:to:format:
arrayByAddingObjectsFromArray:
decodePropertyListForKey:
encodeObject:forKey:
setCategory:error:
isEqualToString:
arrayWithObjects:count:
stringWithUTF8String:
defaultCStringEncoding
bundle
uppercaseString
mainBundle
setCategory:withOptions:error:
outputBusses
defaultCenter
substringFromIndex:
bundleForClass:
mainMixerNode
setObject:forKey:
substringToIndex:
defaultManager
assetControllerWithPolicy:qosClass:shouldRefreshForAssetInstallNotifications:
userInfo
setObject:forKeyedSubscript:
substringWithRange:
rangeOfString:options:range:
enumerateKeysAndObjectsUsingBlock:
outputLatency
indexOfObject:
manualRenderingFormat
rangeValue
bundlePath
setUserInitiated:
enumerateObjectsUsingBlock:
indexOfObjectPassingTest:
manualRenderingMaximumFrameCount
outputNode
rangeWithName:
bundleURL
valueForKeyPath:
containsObject:
informationForPlugInWithPid:
enumerateSubstringsInRange:options:usingBlock:
assetPolicy
mark
error
valueWithNonretainedObject:
bundleWithPath:
containsString:
setValue:forKey:
path
isPlaying
errorWithDomain:code:userInfo:
valueWithRange:
byteSampleOffset
initForReadingFromData:error:
pathForResource:ofType:
AUAudioUnit
symbolCharacterSet
escapedPatternForString:
restartTTSResourceMigration
isSSMLValid:
retrieveSessionWithID:
versionNumber
cStringUsingEncoding:
initWithContentsOfURL:
contentsOfDirectoryAtPath:error:
assistantVoiceMaps
reverseObjectEnumerator
matchesInString:options:range:
setOutputVolume:
versionString
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
maximumFramesToRender
vocalizer
fileExistsAtPath:
initWithKeyOptions:valueOptions:capacity:
attachNode:
vocalizerVoice
cancelDownloadingThen:
filePathURL
sampleRate
speechVoices
setPitchMultiplier:
synthesisProviderVoicesDidChange:
refreshAssetsByForceUpdatingCatalog:updatingCatalogIfNeeded:catalogRefreshOverrideTimeout:completion:
detachNode:
setVoiceSize:
cancelSpeechRequest
dictionary
attributesOfItemAtPath:error:
refreshAssetsWithAttributesSynchronously:installedOnly:
mutableCopy
fileURLWithPath:
convertRange:forSSML:
ssmlResult
addEntriesFromDictionary:
dictionaryWithContentsOfFile:
refreshInstalledAssetsSynchronously
synthesizeSpeechRequest:
capitalizedString
setPreferredIOBufferDuration:error:
convertedRange
initWithPCMFormat:frameCapacity:
filteredArrayUsingPredicate:
startAndReturnError:
setPreferredSampleRate:error:
dictionaryWithContentsOfURL:
refreshWithoutCatalogUpdateSynchronously
category
copy
addObject:
initWithPattern:options:error:
dictionaryWithObjects:forKeys:count:
setWithArray:
categoryOptions
audioBufferList
addObjectsFromArray:
audioComponentDescription
setWithObjects:
registerSubclass:asComponentDescription:name:version:
URLByAppendingPathComponent:
regularExpressionWithPattern:options:error:
diskSize
technology
channelCount
firstMatchInString:options:range:
setActive:error:
addObserver:selector:name:object:
initWithSSMLRepresentation:voice:
doubleValue
setRenderingOffline:
shared
numberOfRanges
firstObject
setAge:
textRange
remoteProcessAuditToken
floatChannelData
numberWithBool:
lastObject
sharedAudioUnitComponentManager
setFrameLength:
initWithStreamDescription:
remoteProcessIdentifier
downloadAssets:successStartBlock:
floatValue
tokenByAddingRenderObserver:
voiceNamesForOutputLanguageCode:gender:
count
UUID
numberWithFloat:
initWithString:
allKeys
removeAllObjects
audioUnitName
characterAtIndex:
numberWithInt:
countByEnumeratingWithState:objects:count:
allObjects
removeItemAtURL:error:
numberWithInteger:
voiceResources
IOBufferDuration
formUnionWithCharacterSet:
characterIsMember:
inputLatency
stopDownloadAsset:completion:
length
removeObject:
format
numberWithLong:
code
setAttributes:range:
sleepForTimeInterval:
inputs
voiceSize
policy
currentHandler
downloadSize
removeObjectAtIndex:
sortDescriptorWithKey:ascending:
frameCapacity
numberWithLongLong:
allValues
portType
downloadWithReservation:useBattery:progress:then:
removeObjectForKey:
listAssetsOfTypes:matching:
frameLength
numberWithUnsignedInt:
compact
predicateWithFormat:
sortDescriptorWithKey:ascending:comparator:
insertObject:atIndex:
downloading
loadAndReturnError:
numberWithUnsignedInteger:
compare:
sortUsingComparator:
streamDescription
currentRoute
insertString:atIndex:
localURL
removeRenderObserver:
numberWithUnsignedLongLong:
sortedArrayUsingComparator:
weakObjectsHashTable
allocWithZone:
premium
string
compare:options:
custom
localeWithLocaleIdentifier:
sortedArrayUsingDescriptors:
objectAtIndex:
alphanumericCharacterSet
premiumhigh
customVoice
stringByAppendingFormat:
ax_arrayByRemovingDuplicates
localizedCompare:
renderOffline:toBuffer:error:
generateSSMLFromAVSpeechUtterance:
objectAtIndexedSubscript:
stringByAppendingPathComponent:
data
instantiateWithComponentDescription:options:completionHandler:
anyObject
ax_dequeueObject
unarchivedFileSize
localizedLowercaseString
objectForKey:
dataUsingEncoding:
appendBytes:length:
int16ChannelData
stringByAppendingString:
ax_enqueueObject:
unarchivedObjectOfClasses:fromData:error:
stringByPaddingToLength:withString:startingAtIndex:
init
regexRules
synthesisProviderDidFinishSpeakingRequest:successfully:withError:
synthesisProviderDidStartSpeakingMarker:forRequest:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
initializeSpeechServerInstance:
synthesizerInstanceDestroyed:
setServiceQueue:forSynthesizerInstanceID:
startSpeechRequest:
pauseSpeechRequest:atMark:
continueSpeechRequest:
stopSpeechRequest:atMark:
getVoicesForLanguage:queryingMobileAssets:reply:
getSpeechIsActiveForRequest:reply:
supportedIPAPhonemeLanguages
speechMarkupStringForType:voice:string:
isVoiceValid:
employSpeechMarkupForType:language:
lhPhonemesFromIPA:language:
phonemesFromIPA:language:
phonemesFromLHPhonemes:language:
enclosedStringWithPhonemes:
nashvilleVoiceIdentifier:footprint:voiceType:gender:assetVoiceName:
nashvilleVoiceName:footprint:voiceType:gender:assetVoiceName:
embeddedRateMarkupForVoice:string:rate:
embeddedPitchMarkupForVoice:string:pitch:
embeddedVolumeMarkupForVoice:string:volume:
combinedProsodyMarkupForVoice:string:rate:pitch:volume:
audioFileSettingsForVoice:
serviceIdentifier
isSiriService
isNashvilleService
isSiriNeuralVoice:
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didSynthesizeSilentlyToURL:forRequest:
canInitializeSpeech:
loadedVoiceResources
_speechEngineForSynthesizerInstance:
getVoicesForLanguage:reply:
_unescapeDelimeterBoundedSSMLInString:
_escapeSSML:
_nonSSMLSubstringRangeForRange:fromSSML:
serviceQueue
setServiceQueue:
requestMapping
setRequestMapping:
speechEngines
setSpeechEngines:
.cxx_destruct
_serviceQueue
_requestMapping
_speechEngines
T@"NSObject<OS_dispatch_queue>",&,N,V_serviceQueue
T@"NSMutableDictionary",&,N,V_requestMapping
T@"NSMutableDictionary",&,N,V_speechEngines
dealloc
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
setReplacementString:
originalString
setOriginalString:
replacementString
phonemes
setPhonemes:
languages
setLanguages:
voiceIds
setVoiceIds:
active
setActive:
ignoreCase
setIgnoreCase:
replacementRange
setReplacementRange:
uuid
setUuid:
appliesToAllApps
setAppliesToAllApps:
bundleIdentifiers
setBundleIdentifiers:
isReplacementTextAllPunctuation
isReplacementTextSurroundedByPunctuation
isUserSubstitution
setIsUserSubstitution:
_active
_ignoreCase
_appliesToAllApps
_isReplacementTextAllPunctuation
_isReplacementTextSurroundedByPunctuation
_isUserSubstitution
_originalString
_replacementString
_phonemes
_languages
_voiceIds
_uuid
_bundleIdentifiers
_replacementRange
T@"NSUUID",&,N,V_uuid
T@"NSString",C,N,V_originalString
T@"NSString",C,N,V_replacementString
T@"NSString",C,N,V_phonemes
T@"NSSet",C,N,V_languages
T@"NSSet",C,N,V_voiceIds
TB,N,V_active
TB,N,V_ignoreCase
T{_NSRange=QQ},N,V_replacementRange
TB,N,V_appliesToAllApps
T@"NSSet",C,N,V_bundleIdentifiers
TB,R,N,V_isReplacementTextAllPunctuation
TB,R,N,V_isReplacementTextSurroundedByPunctuation
TB,N,V_isUserSubstitution
startFrameOffset
setStartFrameOffset:
buffer
setBuffer:
associatedMarkers
setAssociatedMarkers:
_startFrameOffset
_buffer
_associatedMarkers
TI,N,V_startFrameOffset
T@"AVAudioPCMBuffer",&,N,V_buffer
T@"NSArray",&,N,V_associatedMarkers
generateMarkerBufferGroupingsFromMarkers:buffer:bufferStartOffset:
copyFromBuffer:fromOffset:numFrames:
copyStartingFromSample:
copyUpToSample:
copyStartingFromSample:upToSample:
splitBufferAtByteOffset:
sharedInstance
isMigrationComplete
restartMigrationIfNeeded
updatedIdentifierForLegacyIdentifier:withLanguageCode:
legacyIdentifierForUpdatedIdentifierDuringMigration:
convertIdentifierIfNeeded:
downloadCompactResourceIfNeededForIdentifier:
deleteCompactResourceIfNeededForIdentifier:
resourceNeedsMigration:
resourceCompletedMigration:
writeIsMigrationCompleteToPreferences:
_readIsMigrationCompleteFromPreferences
writeVoiceIdentifiersToMigrateToPreferences:
_readVoiceIdentifiersToMigrateFromPreferences
obsoleteVoicesWithReplacements
assetsService
setAssetsService:
setIsMigrationComplete:
setObsoleteVoicesWithReplacements:
_isMigrationComplete
_assetsService
_obsoleteVoicesWithReplacements
T@"AXAssetsService",&,N,V_assetsService
TB,N,V_isMigrationComplete
T@"NSDictionary",&,N,V_obsoleteVoicesWithReplacements
voiceResourceForLanguage:voiceType:
_footprintForType:
_assetTypesForVoiceType:
ttsAssetFromVoiceAsset:
voiceAssetFromTTSAsset:
spaceCheck:
purgeAsset:
assetIsDownloading:
stopDownload:
deprecatedVoicesMap
downloadAsset:progressHandler:
_voiceTypeForAssetTechnology:
_assetTechnologyForVoiceType:
assetsForLanguage:voiceType:
installedAssetsForLanguage:voiceType:
_assetsForLanguage:voiceType:installedOnly:
installedAssetForLanguage:gender:footprint:voiceName:voiceType:
assetForLanguage:gender:footprint:voiceName:voiceType:
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:
_siriAssetForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
_assetFilterForLanguage:gender:footprint:voiceName:voiceType:locallyAvailable:
bundleIdentifier
setBundleIdentifier:
compatibilityVersion
setCompatibilityVersion:
contentVersion
setContentVersion:
masteredVersion
setMasteredVersion:
_bundleIdentifier
_compatibilityVersion
_contentVersion
_masteredVersion
T@"NSString",C,N,V_bundleIdentifier
T@"NSNumber",C,N,V_compatibilityVersion
T@"NSNumber",C,N,V_contentVersion
T@"NSString",C,N,V_masteredVersion
initWithAsset:
initWithData:
footprint
assetId
contentPath
primaryLanguage
memoryPeakExceedsActiveJetsamLimit
shouldFilterResourceFromUI
isInstalled
assetSize
speechVoice
localizedName
localizedStringForKey:
localizedNameWithFootprint
_isDennisVoice
canBeDownloaded
_isSystemVoice
_isDefault
_ensureMacinTalkComponent
_resourceTypeFromStringInput:
_resourceSubtypeFromStringInput:
_resourceFootprintFromStringInput:
_resourceGenderFromStringInput:
axAsset
setAxAsset:
voiceAsset
setVoiceAsset:
name
voiceId
type
subtype
gender
isNoveltyVoice
setAssetId:
setSpeechVoice:
synthesizerBundleIdentifier
setSynthesizerBundleIdentifier:
componentSubType
setComponentSubType:
setFootprint:
setAssetSize:
setIsInstalled:
setCanBeDownloaded:
memoryPeak
setMemoryPeak:
_isNoveltyVoice
_isInstalled
_canBeDownloaded
_axAsset
_voiceAsset
_name
_voiceId
_type
_subtype
_gender
_assetId
_speechVoice
_synthesizerBundleIdentifier
_componentSubType
_footprint
_assetSize
_memoryPeak
T@"NSString",&,N,V_assetId
T@"TTSSpeechVoice",&,N,V_speechVoice
T@"NSString",&,N,V_synthesizerBundleIdentifier
T@"NSString",&,N,V_componentSubType
Tq,N,V_footprint
TQ,N,V_assetSize
TB,N,V_isInstalled
TB,N,V_canBeDownloaded
Tq,N,V_memoryPeak
T@"AXAsset",&,N,V_axAsset
T@"TTSVoiceAsset",&,N,V_voiceAsset
T@"NSArray",R,N,V_languages
T@"NSString",R,N,V_name
T@"NSString",R,N
T@"NSString",R,N,V_voiceId
TQ,R,N,V_type
TQ,R,N,V_subtype
Tq,R,N,V_gender
TB,R,N,V_isNoveltyVoice
_audioSessionInterrupted:
_mediaServicesWereReset:
_setupAudioSession
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
legacyPlatforms
syncWithConfigFile:voiceType:
defaultVoice
defaultTypeString
defaultFootprintString
resourceList
setResourceList:
searchPathURL
setSearchPathURL:
voiceConfig
setVoiceConfig:
_resourceList
_searchPathURL
_voiceConfig
T@"NSDictionary",C,N,V_voiceConfig
T@"NSArray",C,N,V_languages
T@"NSArray",C,N,V_resourceList
T@"NSURL",C,N,V_searchPathURL
vocalizerFootprint
vocalizerGender
attributedStringWithFormatAndAttributes:
formatSpecifier
attributes
formattedArg
appendString:withAttributes:
initWithRequest:bytesPerFrame:
addMarkers:
addBuffers:
updatePlayableBuffers
completedRequestRendering
setFrameCushion:
_dequeueMarkersForFrameRange:end:
delegate
setDelegate:
managingSpeechRequest
setManagingSpeechRequest:
isFinishedReceivingBuffers
setIsFinishedReceivingBuffers:
currentMarkerFrameLimit
setCurrentMarkerFrameLimit:
currentAudioBufferFrameCount
setCurrentAudioBufferFrameCount:
generatedPlayableFrames
setGeneratedPlayableFrames:
effectiveMarkerFrameLimit
setEffectiveMarkerFrameLimit:
operationQueue
setOperationQueue:
bytesPerFrame
setBytesPerFrame:
minimumFrameCushion
setMinimumFrameCushion:
queuedBuffers
setQueuedBuffers:
queuedMarkers
setQueuedMarkers:
_isFinishedReceivingBuffers
_currentAudioBufferFrameCount
_generatedPlayableFrames
_delegate
_managingSpeechRequest
_currentMarkerFrameLimit
_effectiveMarkerFrameLimit
_operationQueue
_bytesPerFrame
_minimumFrameCushion
_queuedBuffers
_queuedMarkers
T@"AVSpeechSynthesisProviderRequest",&,N,V_managingSpeechRequest
Tq,N,V_currentMarkerFrameLimit
Tq,N,V_effectiveMarkerFrameLimit
TI,N,V_currentAudioBufferFrameCount
T@"NSObject<OS_dispatch_queue>",&,N,V_operationQueue
TQ,N,V_bytesPerFrame
TQ,N,V_minimumFrameCushion
T@"NSMutableArray",&,N,V_queuedBuffers
T@"NSMutableArray",&,N,V_queuedMarkers
TI,N,V_generatedPlayableFrames
TB,N,V_isFinishedReceivingBuffers
T@"<TTSSynthesisProviderHandlerDelegate>",W,N,V_delegate
componentDescription
setComponentDescription:
version
setVersion:
isFirstParty
setIsFirstParty:
voices
setVoices:
_isFirstParty
_version
_voices
_componentDescription
T{AudioComponentDescription=IIIII},N,V_componentDescription
T@"NSString",&,N,V_bundleIdentifier
T@"NSString",&,N,V_version
TB,N,V_isFirstParty
T@"NSArray",&,N,V_voices
macintalkAudioUnitProvider
setComponentCache:
voiceCache
componentCache
resetInMemoryCache
allSynthesisProviderVoices
allSynthesisProviderTTSVoices
_synthesizerHasEntitlement:entitlement:
_componentIsEqual:to:
T@"NSArray",&
T@"NSDictionary",R
T@"NSArray",R
reconcileCachedComponents
reconcileCachedComponentsAsync
reloadVoicesForBundleIdentifierPrefix:
reloadVoicesForBundleIdentifierPrefixAsync:
_reloadVoiceForBundleIdentifierPrefix:
purgeAndReloadAllComponents
_systemAudioUnitProviders
_reconcileCachedComponents:
_loadVoicesForComponents:
_loadVoicesForComponentRecord:dispatchGroup:
_loadVoicesForComponentWithTimeout:timeout:
componentQueryQueue
setComponentQueryQueue:
_componentQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_componentQueryQueue
T@"<TTSSynthesisProviderVoiceManagerDelegate>",W,N,V_delegate
tts_encodeBytes:size:forKey:
tts_decodeBytesIntoObject:size:forKey:
tts_encodeMatrixFloat4x4:forKey:
tts_decodeMatrixFloat4x4ForKey:
finishedDownloadingResource:wasCancelled:
downloadProgressForVoiceId:progress:storageSize:requiredDiskSpace:
finishedDeletingResource:
resourceCacheDidReceiveUpdate
assetController:didFinishRefreshingAssets:wasSuccessful:error:
assetController:asset:downloadProgressTotalWritten:totalExpected:isStalled:expectedTimeRemaining:
assetController:didFinishDownloadingAsset:wasSuccessful:error:hasRemainingDownloads:
assetController:didFinishPurgingAssets:wasSuccessful:error:
assetController:willUpdateCatalogForPolicy:
assetController:didUpdateCatalogForPolicy:wasSuccessful:error:
resources
resources:
_debugCountSummaryForResources:
_updateCachedResources:
_mergeInExpensiveInstalledAssets:notifyObservers:
samplesAsset
_refreshSamples:
_refreshResourcesForManagerType:
rebuildSystemCacheForActionType:
downloadResourceWithAssetId:
downloadResourceWithVoiceId:
downloadResourceWithVoiceId:userInitiated:
stopDownloadResourceWithVoiceId:
_stopDownloadSiriVoiceAssetWithResource:
_stopDownloadResource:
_downloadResource:userInitiated:
_downloadSiriVoiceAssetWithResource:
downloadSamplesIfNecessary
deleteResourceWithAssetId:
deleteResourceWithVoiceId:
_deleteResource:
_deleteSiriVoiceAssetWithResource:
resourcesWithLanguage:type:
resourcesWithType:subType:
resourcesWithType:subType:waitForInstalledAssets:
_resourcesWithType:subType:languageCode:waitForInstalledAssets:
resourceWithVoiceId:
resourceWithAssetId:
_resourceWithVoiceId:assetId:
defaultVoiceForLanguage:
languageCodeForResourceName:withType:
superCompactVoiceIdForCompactVoiceId:
_findLocalResourcesForPath:
speechVoiceWithVoiceId:
refreshedResourcesForResources:
sampleURLForVoiceId:
_resourcesForAssets:
allVoices:
allVoices:waitForInstalledAssets:
allLanguagesForVoices:waitForInstalledAssets:
allAvailableLanguages
_managerTypeForResourceType:
_isValidResourceTypeKey:
_dictionaryForResources:
_axAssetsForTTSAXResourceModel:
resetResourcesCache
resetInMemoryAssetCatalogs
_notifyObserversOfCacheUpdate
updateCatalogIfNeeded
catalogBuildVersion
refreshAssetForResource:installedOnly:
_refreshAssetForResource:withAssetController:installedOnly:
refreshResourcesCacheForManagerType:
readResourceCacheVersionFromPreferences
_writeResourceCacheVersionToPreferences
_readCatalogBuildNumberFromPreferences
updateCatalogBuildVersion:
_readResourcesFromPreferences
_writeResourcesToPreferences:
addObserver:
removeObserver:
_performBlockOnObservers:
_refreshSiriResources:
_getSynthesisProviderResources
_findResourcesForLegacyAssets
_findAndSwapLegacyMacinTalkAssetsForMacinTalkResources:
_downloadLegacyResourceForTesting:
assetController
setAssetController:
legacyCombinedVocalizerAssetController
setLegacyCombinedVocalizerAssetController:
legacyMacinTalkAssetController
setLegacyMacinTalkAssetController:
setAllAvailableLanguages:
setSamplesAsset:
setCatalogBuildVersion:
downloadingSamples
setDownloadingSamples:
preferenceWriteQueue
setPreferenceWriteQueue:
assetLoadingQueue
setAssetLoadingQueue:
_resourcesLock
_resourcesById
_resources
_observersLock
_observers
_downloadingSamples
_assetController
_legacyCombinedVocalizerAssetController
_legacyMacinTalkAssetController
_allAvailableLanguages
_samplesAsset
_catalogBuildVersion
_preferenceWriteQueue
_assetLoadingQueue
T@"AXAssetController",&,N,V_assetController
T@"AXAssetController",&,N,V_legacyCombinedVocalizerAssetController
T@"AXAssetController",&,N,V_legacyMacinTalkAssetController
T@"NSSet",&,N,V_allAvailableLanguages
T@"AXAsset",&,N,V_samplesAsset
T@"NSString",&,N,V_catalogBuildVersion
TB,N,V_downloadingSamples
T@"NSObject<OS_dispatch_queue>",&,N,V_preferenceWriteQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetLoadingQueue
canonicalLanguageCodeVoiceNamesData
generalLanguageCodeData
voiceIdSampleStringData
defaultVoiceIdentifierForGeneralLanguageCode:
sampleStringForVoiceIdentifier:
defaultVoiceIdentifierForVoiceName:
setGeneralLanguageCodeData:
setVoiceIdSampleStringData:
setCanonicalLanguageCodeVoiceNamesData:
_generalLanguageCodeData
_voiceIdSampleStringData
_canonicalLanguageCodeVoiceNamesData
T@"NSDictionary",&,N,V_generalLanguageCodeData
T@"NSDictionary",&,N,V_voiceIdSampleStringData
T@"NSDictionary",&,N,V_canonicalLanguageCodeVoiceNamesData
speechRequestDidStartForService:
speechRequestDidPauseForService:
speechRequestDidContinueForService:
speechRequestMark:didStartForRange:forService:
speechRequestDidStopWithSuccess:phonemesSpoken:forService:error:
speechRequestDidSynthesizeSilentlyToURL:forService:
text
setText:
attributedText
setAttributedText:
voice
setVoice:
ssmlRepresentation
setSsmlRepresentation:
speechString
setSpeechString:
synthesisProviderVoice
setSynthesisProviderVoice:
languageCode
setLanguageCode:
setGender:
outputPath
setOutputPath:
rate
setRate:
pitch
setPitch:
volume
setVolume:
maintainsInput
setMaintainsInput:
supportsAccurateWordCallbacks
setSupportsAccurateWordCallbacks:
skipLuthorRules
setSkipLuthorRules:
audioSessionIDIsValid
setAudioSessionIDIsValid:
audioSessionID
setAudioSessionID:
audioQueueFlags
setAudioQueueFlags:
latency
setLatency:
dispatchTime
setDispatchTime:
handledTime
setHandledTime:
useMonarchStyleRate
setUseMonarchStyleRate:
channels
setChannels:
synthesizerInstanceID
setSynthesizerInstanceID:
clientContext
setClientContext:
audioBufferCallback
setAudioBufferCallback:
originalWordRanges
setOriginalWordRanges:
processedWordRanges
setProcessedWordRanges:
replacedWords
setReplacedWords:
wordRangeCallbacksDispatched
setWordRangeCallbacksDispatched:
synthesizeSilently
setSynthesizeSilently:
_maintainsInput
_supportsAccurateWordCallbacks
_skipLuthorRules
_audioSessionIDIsValid
_useMonarchStyleRate
_synthesizeSilently
_audioSessionID
_audioQueueFlags
_text
_attributedText
_voice
_ssmlRepresentation
_speechString
_synthesisProviderVoice
_languageCode
_outputPath
_rate
_pitch
_volume
_latency
_dispatchTime
_handledTime
_channels
_synthesizerInstanceID
_clientContext
_audioBufferCallback
_originalWordRanges
_processedWordRanges
_replacedWords
_wordRangeCallbacksDispatched
T@"NSString",C,N,V_text
T@"NSAttributedString",C,N,V_attributedText
T@"TTSSpeechVoice",C,N,V_voice
T@"NSString",C,N,V_ssmlRepresentation
T@"TTSSpeechString",&,N,V_speechString
T@"AVSpeechSynthesisProviderVoice",C,N,V_synthesisProviderVoice
T@"NSString",C,N,V_languageCode
Tq,N,V_gender
T@"NSURL",C,N,V_outputPath
Td,N,V_rate
Td,N,V_pitch
Td,N,V_volume
TB,N,V_maintainsInput
TB,N,V_supportsAccurateWordCallbacks
TB,N,V_skipLuthorRules
TB,N,V_audioSessionIDIsValid
TI,N,V_audioSessionID
TI,N,V_audioQueueFlags
Td,N,V_latency
Td,N,V_dispatchTime
Td,N,V_handledTime
TB,N,V_useMonarchStyleRate
T@"NSArray",&,N,V_channels
TQ,N,V_synthesizerInstanceID
T^v,N,V_clientContext
T@?,C,N,V_audioBufferCallback
T@"NSString",&,N,V_originalString
T@"NSMutableArray",&,N,V_originalWordRanges
T@"NSMutableArray",&,N,V_processedWordRanges
T@"NSMutableArray",&,N,V_replacedWords
Tq,N,V_wordRangeCallbacksDispatched
TB,N,V_synthesizeSilently
initWithName:identifier:primaryLanguages:supportedLanguages:
groupName
supportedCharacterSet
uniqueAudioDescTriple
uniqueAudioDescSpeechSynthTuple
fullBundleIdentifier
setAuComponentDesc:
auComponentDesc
setManufacturerName:
manufacturerName
setPrimaryLanguages:
primaryLanguages
setSupportedLanguages:
supportedLanguages
setExtraAttributes:
extraAttributes
updateSpeechVoices
T@"NSArray",&,N
T@"NSDictionary",&,N
T{AudioComponentDescription=IIIII},N
T@"NSString",&,N
TB,N
_mediaServicesDied
initialize
_initializeServers
availableVoices
isSystemVoice:
unavailableVoiceIdentifiers
voiceForIdentifier:
employSpeechMarkupForType:identifier:withLanguage:
combinedProsodyMarkupForIdentifier:string:rate:pitch:volume:
speechMarkupStringForType:forIdentifier:string:
testingSetAllVoices:
setVoiceAssetsForTesting:
voiceAssetsForTesting
synthesizerForSynthesizerID:
refreshAllAvailableVoices
refreshAllAvailableVoices:
allAvailableVoices
voiceAccessQueue
setTestingAvailableVoicesForLanguageCode:
availableVoicesForLanguageCode:queryingMobileAssets:
availableLanguageCodes
setSpeechJobFinishedUnitTestBlock:
setSpeechJobStartedUnitTestBlock:
remapVoiceIdentifier:
_speechVoiceForIdentifier:language:footprint:
connection:speechRequestDidStart:
connection:speechRequestDidPause:
connection:speechRequestDidContinue:
connection:speechRequest:didStopAtEnd:phonemesSpoken:error:
connection:speechRequest:willSpeakMark:inRange:
connection:speechRequest:didSynthesizeSilentlyToURL:
testingLastRuleConversion
testingSetLastRuleConversion:replacement:
_setDelegate:
setOutputChannels:
outputChannels
setUserSubstitutions:
setPhonemeSubstitutions:
resolvedVoiceIdentifier
resolvedVoiceIdentifierForLanguageCode:
voiceIdentifier
_preprocessText:languageCode:
_substitutionLanguageMatchesSpecialCase:withLanguage:
_skipSubstition:language:bundleIdentifier:voice:
_processUserSubstitutions:toText:request:bundleIdentifier:voice:
_determineSubstitution:text:wordRange:request:
applySSMLTransformation:string:voice:
_startSpeakingString:orAttributedString:toURL:withLanguageCode:request:error:
_stopSpeakingRequest:atNextBoundary:synchronously:error:
_pauseSpeakingRequest:atNextBoundary:synchronously:error:
_continueSpeakingRequest:withError:
startSpeakingString:error:
startSpeakingString:toURL:error:
startSpeakingString:withLanguageCode:error:
startSpeakingString:toURL:withLanguageCode:error:
stopSpeakingAtNextBoundary:error:
stopSpeakingAtNextBoundary:synchronously:error:
pauseSpeakingAtNextBoundary:error:
pauseSpeakingAtNextBoundary:synchronously:error:
continueSpeakingWithError:
isSpeaking
minimumRate
maximumRate
useSpecificAudioSession:
useAudioQueueFlags:
startSpeakingString:request:error:
startSpeakingString:withLanguageCode:request:error:
startSpeakingString:toURL:withLanguageCode:request:error:
stopSpeakingRequest:atNextBoundary:error:
stopSpeakingRequest:atNextBoundary:synchronously:error:
pauseSpeakingRequest:atNextBoundary:error:
pauseSpeakingRequest:atNextBoundary:synchronously:error:
continueSpeakingRequest:withError:
delegateTargetQueue
setDelegateTargetQueue:
setVoiceIdentifier:
requestClientIdentifier
setRequestClientIdentifier:
speakingRequestClientContext
setSpeakingRequestClientContext:
userSubstitutions
phonemeSubstitutions
ignoreSubstitutions
setIgnoreSubstitutions:
_useSharedSession
_currentRequestOwners
_speechRequests
_synthesizerFlags
_outputChannels
_testingLastRuleConversion
_ignoreSubstitutions
_delegateTargetQueue
_voiceIdentifier
_requestClientIdentifier
_speakingRequestClientContext
_userSubstitutions
_phonemeSubstitutions
T@"<TTSSpeechSynthesizerDelegate>",W,D,N
T@"NSObject<OS_dispatch_queue>",&,N,V_delegateTargetQueue
Tf,N,V_rate
Tf,N,V_pitch
Tf,N,V_volume
T@"NSString",&,N,V_voiceIdentifier
TQ,N,V_requestClientIdentifier
T^v,N,V_speakingRequestClientContext
TI,R,N,V_audioSessionID
T@"NSArray",C,N,V_userSubstitutions
T@"NSArray",C,N,V_phonemeSubstitutions
TB,N,V_ignoreSubstitutions
channelWithChannel:
convertChannels:
channelLabel
channelNumber
channelName
owningPortUID
channel
setChannel:
setChannelName:
setChannelNumber:
setChannelLabel:
setOwningPortUID:
_channelLabel
_channel
_channelName
_channelNumber
_owningPortUID
T@"AVAudioSessionChannelDescription",&,N,V_channel
T@"NSString",&,N,V_channelName
TQ,N,V_channelNumber
TI,N,V_channelLabel
T@"NSString",&,N,V_owningPortUID
setIPASpeechPhonemes:
IPASpeechPhonemes
T@"NSString",&,D,N
speechRequestDidStart:forService:
speechRequestDidPause:forService:
speechRequestDidContinue:forService:
speechRequest:withMark:didStartForRange:forService:
speechRequest:didStopWithSuccess:phonemesSpoken:forService:error:
speechRequest:didSynthesizeSilentlyToURL:
initWithSpeechService:
_setRequest:
isSystemSpeakingOnBehalfOfCurrentConnection
stopCurrentSpeechRequestAtMark:waitUntilStopped:
pauseCurrentSpeechRequestAtMark:waitUntilPaused:
continueCurrentSpeechRequest
request
speechService
setSpeechService:
_request
_speechService
T@"<TTSSpeechService>",W,N,V_speechService
T@"<TTSSpeechConnectionDelegate>",W,N,V_delegate
T@"TTSSpeechRequest",R,N,V_request
localizedName:forLanguage:
setIdentifier:
localizedNameForLanguage:
setName:
language
setLanguage:
identifier
isDefault
setIsDefault:
isSystemVoice
setIsSystemVoice:
isFallbackDefault
excludeInAvailableVoiceList
voiceType
setVoiceType:
setIsNoveltyVoice:
isCombinedFootprint
nonCombinedVoiceId
setNonCombinedVoiceId:
setServiceIdentifier:
service
setService:
_isFallbackDefault
_excludeInAvailableVoiceList
_isCombinedFootprint
_language
_identifier
_voiceType
_nonCombinedVoiceId
_serviceIdentifier
_service
T@"NSString",&,N,V_serviceIdentifier
T@"<TTSSpeechService>",W,N,V_service
T@"NSString",&,N,V_name
T@"NSString",&,N,V_language
T@"NSString",&,N,V_identifier
TB,N,V_isDefault
TB,N,V_isSystemVoice
TB,R,N,V_isFallbackDefault
TB,R,N,V_excludeInAvailableVoiceList
Tq,N,V_voiceType
TB,N,V_isNoveltyVoice
TB,R,N,V_isCombinedFootprint
T@"NSString",&,N,V_nonCombinedVoiceId
T@"AVSpeechSynthesisProviderVoice",&,N,V_synthesisProviderVoice
voiceFromAVSpeechSynthesisProviderVoice:
safelyCallStartCompletionForRequest:didStart:
didGeneratePlayableBuffers:forRequest:
_startPlaying
_stopPlaying
_pausePlaying
_safelyCallDeferredReplyBlock:
_setupOfflineEngine
_setupAudioUnitForVoice:
_setupAudioUnitForVoice:remote:
prewarmAudioUnitForVoice:
startSynthesizingSpeechRequest:reply:
startSynthesizingSpeechRequest:withBufferCallback:silently:reply:
renderWithObserver:
renderSpeechRequest:
_finishRequestRendering
pauseImmediately:
stopImmediately:
receivedMarkers:forRequest:
stopAtMark:reply:
pauseAtMark:reply:
_handleMarkerPlayback:forRequest:
playBuffers:forRequest:
audioUnit
audioUnitOutputBus
audioUnitOutputFormat
markerByteOffsetScalingFactor
isSpeechActive
offlineToRealtimePlayer
setOfflineToRealtimePlayer:
file
setFile:
avAudioUnit
setAvAudioUnit:
deferredStateChangeQueue
setDeferredStateChangeQueue:
playerState
setPlayerState:
deferredPlayerState
setDeferredPlayerState:
deferredReplyBlock
setDeferredReplyBlock:
offlineEngine
setOfflineEngine:
audioUnitObservedToken
setAudioUnitObservedToken:
playbackQueue
setPlaybackQueue:
offlineRenderingQueue
setOfflineRenderingQueue:
currentRequestHandler
setCurrentRequestHandler:
markerBlock
setMarkerBlock:
bufferCallback
setBufferCallback:
isSynthesizingSilently
setIsSynthesizingSilently:
offlineRenderingInProgress
setOfflineRenderingInProgress:
_isSynthesizingSilently
_offlineRenderingInProgress
_offlineToRealtimePlayer
_file
_avAudioUnit
_deferredStateChangeQueue
_playerState
_deferredPlayerState
_deferredReplyBlock
_offlineEngine
_audioUnitObservedToken
_playbackQueue
_offlineRenderingQueue
_currentRequestHandler
_markerBlock
_bufferCallback
T@"TTSSynthesisProviderAudioOutput",&,N,V_offlineToRealtimePlayer
T@"AVAudioFile",&,N,V_file
T@"AVAudioUnit",&,N,V_avAudioUnit
T@"NSObject<OS_dispatch_queue>",&,N,V_deferredStateChangeQueue
TQ,N,V_playerState
TQ,N,V_deferredPlayerState
T@?,C,N,V_deferredReplyBlock
T@"AVAudioEngine",&,N,V_offlineEngine
T@"NSNumber",&,N,V_audioUnitObservedToken
T@"NSObject<OS_dispatch_queue>",&,N,V_playbackQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_offlineRenderingQueue
T@"TTSSynthesisProviderRequestHandler",&,N,V_currentRequestHandler
T@?,C,N,V_markerBlock
T@?,C,N,V_bufferCallback
TB,N,V_isSynthesizingSilently
TB,N,V_offlineRenderingInProgress
T@"<TTSSynthesisProviderAudioEngineProtocol>",W,N,V_delegate
T@"AVAudioFormat",R
isRunning
setOutputFormat:
setAudioSession:
play
_play:
pause
stop
scheduleBuffer:completionCallbackType:completionHandler:
_scheduleEngineShutdown
engine
setEngine:
player
setPlayer:
outputFormat
audioSession
engineShutdownTimer
setEngineShutdownTimer:
engineShutdownQueue
setEngineShutdownQueue:
playerStateChangeQueue
setPlayerStateChangeQueue:
completionHandlerQueue
setCompletionHandlerQueue:
_engine
_player
_outputFormat
_audioSession
_engineShutdownTimer
_engineShutdownQueue
_playerStateChangeQueue
_completionHandlerQueue
T@"AVAudioEngine",&,N,V_engine
T@"AVAudioPlayerNode",&,N,V_player
T@"AVAudioFormat",&,N,V_outputFormat
T@"AVAudioSession",&,N,V_audioSession
T@"NSObject<OS_dispatch_source>",&,N,V_engineShutdownTimer
T@"NSObject<OS_dispatch_queue>",&,N,V_engineShutdownQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_playerStateChangeQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_completionHandlerQueue
initWithRange:andReplacement:
sizeDelta
range
setRange:
replacement
setReplacement:
offsetFromEnd
setOffsetFromEnd:
finalRange
setFinalRange:
_replacement
_offsetFromEnd
_range
_finalRange
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_replacement
TQ,N,V_offsetFromEnd
T{_NSRange=QQ},N,V_finalRange
initWithOriginalString:
transformRange:to:
insertAtLocation:string:
encapsulateSubstringAtRange:withPrefix:andSuffix:
translateRangeInTransformedString:
transformedString
_rangeIsValid:
_insertTransformation:forEncapsulatedTerminator:
setTransformedString:
transformations
setTransformations:
_transformedString
_transformations
T@"NSString",&,N,V_transformedString
T@"NSMutableArray",&,N,V_transformations
regexForString:
regexForString:atStart:
cache
setCache:
_cache
T@"NSMutableDictionary",&,N,V_cache
initWithName:languages:gender:footprint:isInstalled:isBuiltIn:masteredVersion:compatibilityVersion:neural:
initWithDictionaryRepresentation:
dictionaryRepresentation
neural
isDownloading
setIsDownloading:
isBuiltInVoice
voicePath
setVoicePath:
fileSize
setFileSize:
_neural
_isDownloading
_isBuiltInVoice
_voicePath
_fileSize
Tq,R,N,V_footprint
TB,R,N,V_neural
TB,R,N,V_isInstalled
TB,N,V_isDownloading
TB,R,N,V_isBuiltInVoice
T@"NSString",&,N,V_voicePath
Tq,N,V_fileSize
AVMarkerMarkFromTTSMark:
AVSpeechSynthesisProviderRequestFromTTSSpeechRequest:
binaryStringRepresentationOfInt:
binaryStringRepresentationOfInt:numberOfDigits:chunkLength:
ax_nextDequeuedObjects:
setTtsServiceDidStartReplyBlock:
ttsServiceDidStartReplyBlock
T@?,C,N
T@"AVAudioSession",&,N
lastRenderError
renderErrorFromAU:
@16@0:8
v36@0:8@16B24@28
v32@0:8@16@24
v36@0:8@"AVSpeechSynthesisProviderRequest"16B24@"NSError"28
v32@0:8@"AVSpeechSynthesisMarker"16@"AVSpeechSynthesisProviderRequest"24
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8Q16
v32@0:8@16Q24
Vv24@0:8@16
Vv32@0:8@16q24
Vv36@0:8@16B24@?28
Vv32@0:8@16@?24
@40@0:8q16@24@32
B32@0:8q16@24
@32@0:8@16@24
@24@0:8@16
@56@0:8@16q24q32q40@48
@40@0:8@16@24d32
@56@0:8@16@24@32@40@48
v32@0:8@"NSObject<OS_dispatch_queue>"16Q24
Vv24@0:8@"TTSSpeechRequest"16
Vv32@0:8@"TTSSpeechRequest"16q24
Vv36@0:8@"NSString"16B24@?<v@?@"NSArray">28
Vv32@0:8@"TTSSpeechRequest"16@?<v@?B>24
@"NSSet"16@0:8
@"NSString"40@0:8q16@"TTSSpeechVoice"24@"NSString"32
B24@0:8@"TTSSpeechVoice"16
B32@0:8q16@"NSString"24
@"NSString"32@0:8@"NSString"16@"NSString"24
@"NSString"24@0:8@"NSString"16
@"NSString"56@0:8@"NSString"16q24q32q40@"NSString"48
@"NSString"40@0:8@"TTSSpeechVoice"16@"NSString"24d32
@"NSString"56@0:8@"TTSSpeechVoice"16@"NSString"24@"NSNumber"32@"NSNumber"40@"NSNumber"48
@"NSDictionary"24@0:8@"TTSSpeechVoice"16
v44@0:8@16@24B32@36
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v40@0:8@16@24@32
v32@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24
v44@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSError"36
v52@0:8@"TTSSpeechSynthesizer"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v48@0:8@"TTSSpeechSynthesizer"16{_NSRange=QQ}24@"TTSSpeechRequest"40
v40@0:8@"TTSSpeechSynthesizer"16@"NSURL"24@"TTSSpeechRequest"32
^{__CFArray=}16@0:8
@24@0:8Q16
{_NSRange=QQ}40@0:8{_NSRange=QQ}16@32
v24@0:8@16
v16@0:8
@"NSObject<OS_dispatch_queue>"
@"NSMutableDictionary"
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
v20@0:8B16
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
@"NSString"
@"NSSet"
@"NSUUID"
{_NSRange="location"Q"length"Q}
I16@0:8
v20@0:8I16
@"AVAudioPCMBuffer"
@"NSArray"
@36@0:8@16@24I32
I32@0:8@16I24I28
@20@0:8I16
@24@0:8I16I20
@"AXAssetsService"
@"NSDictionary"
@32@0:8@16q24
@24@0:8q16
v32@0:8@16@?24
q24@0:8@16
@36@0:8@16q24B32
@56@0:8@16q24q32@40q48
@60@0:8@16q24q32@40q48B56
@"NSNumber"
q16@0:8
Q24@0:8@16
v24@0:8q16
@"AXAsset"
@"TTSVoiceAsset"
@"TTSSpeechVoice"
q36@0:8B16q20q28
v28@0:8B16q20
{?="category"q"activity"q}
^{__CFBag=}
v32@0:8@16q24
@"NSURL"
@32@0:8@16Q24
@32@0:8q16q24
@"<TTSSynthesisProviderHandlerDelegate>"
@"AVSpeechSynthesisProviderRequest"
@"NSMutableArray"
{AudioComponentDescription=IIIII}16@0:8
v36@0:8{AudioComponentDescription=IIIII}16
{AudioComponentDescription="componentType"I"componentSubType"I"componentManufacturer"I"componentFlags"I"componentFlagsMask"I}
B32@0:8@16r*24
B56@0:8{AudioComponentDescription=IIIII}16{AudioComponentDescription=IIIII}36
B32@0:8@16d24
@"<TTSSynthesisProviderVoiceManagerDelegate>"
v40@0:8^v16Q24@32
v88@0:8{?=[4]}16@80
{?=[4]}24@0:8@16
v60@0:8@16@24q32q40B48d52
v48@0:8@16@24B32@36B44
v44@0:8@"AXAssetController"16@"NSArray"24B32@"NSError"36
v60@0:8@"AXAssetController"16@"AXAsset"24q32q40B48d52
v48@0:8@"AXAssetController"16@"AXAsset"24B32@"NSError"36B44
v32@0:8@"AXAssetController"16@"AXAssetPolicy"24
v44@0:8@"AXAssetController"16@"AXAssetPolicy"24B32@"NSError"36
@20@0:8B16
v24@0:8B16B20
v28@0:8@16B24
@32@0:8Q16Q24
@36@0:8Q16Q24B32
@44@0:8Q16Q24@32B40
@24@0:8B16B20
Q24@0:8Q16
@28@0:8@16B24
@36@0:8@16@24B32
v24@0:8@?16
{os_unfair_lock_s="_os_unfair_lock_opaque"I}
@"NSHashTable"
@"AXAssetController"
v48@0:8q16{_NSRange=QQ}24@40
v44@0:8B16@20@28@36
d16@0:8
v24@0:8d16
^v16@0:8
v24@0:8^v16
@?16@0:8
@"<TTSSpeechRequestDelegate>"
@"NSAttributedString"
@"TTSSpeechString"
@"AVSpeechSynthesisProviderVoice"
@48@0:8@16@24@32@40
B40@0:8q16@24@32
@40@0:8@16@24q32
v56@0:8@16@24q32{_NSRange=QQ}40
v32@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24
v52@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24B32@"NSString"36@"NSError"44
v56@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24q32{_NSRange=QQ}40
v40@0:8@"TTSSpeechRequestOwner"16@"TTSSpeechRequest"24@"NSURL"32
v20@0:8f16
B32@0:8@16@24
B48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@56@0:8@16@24{_NSRange=QQ}32@48
B64@0:8@16@24@32@40^@48^@56
B44@0:8@16q24B32^@36
B32@0:8@16^@24
B40@0:8@16@24^@32
B48@0:8@16@24@32^@40
B32@0:8q16^@24
B36@0:8q16B24^@28
B24@0:8^@16
f16@0:8
B40@0:8@16^@24^@32
B48@0:8@16@24^@32^@40
B56@0:8@16@24@32^@40^@48
B40@0:8@16q24^@32
@"<TTSSpeechSynthesizerDelegate>"
{?="delegateStartWithRequest"b1"delegateFinishWithRequest"b1"delegateFinishWithPhonemesSpokenWithRequest"b1"delegatePauseWithRequest"b1"delegateContinueWithRequest"b1"delegateWillSpeakWithRequest"b1"delegateSynthesizedSilentlyURL"b1"willUseInput"b1}
@"AVAudioSessionChannelDescription"
Vv32@0:8@16@24
Vv56@0:8@16q24{_NSRange=QQ}32@48
Vv52@0:8@16B24@28@36@44
Vv32@0:8@"TTSSpeechRequest"16@"<TTSSpeechService>"24
Vv56@0:8@"TTSSpeechRequest"16q24{_NSRange=QQ}32@"<TTSSpeechService>"48
Vv52@0:8@"TTSSpeechRequest"16B24@"NSString"28@"<TTSSpeechService>"36@"NSError"44
Vv32@0:8@"TTSSpeechRequest"16@"NSURL"24
v28@0:8q16B24
@"<TTSSpeechConnectionDelegate>"
@"TTSSpeechRequest"
@"<TTSSpeechService>"
v32@0:8@"NSArray"16@"AVSpeechSynthesisProviderRequest"24
B28@0:8@16B24
v44@0:8@16@?24B32@?36
v32@0:8q16@?24
@"<TTSSynthesisProviderAudioEngineProtocol>"
@"TTSSynthesisProviderAudioOutput"
@"AVAudioFile"
@"AVAudioUnit"
@"AVAudioEngine"
@"TTSSynthesisProviderRequestHandler"
B24@0:8q16
v40@0:8@16q24@?32
@"AVAudioPlayerNode"
@"AVAudioFormat"
@"AVAudioSession"
@"NSObject<OS_dispatch_source>"
@40@0:8{_NSRange=QQ}16@32
B40@0:8{_NSRange=QQ}16@32
B32@0:8Q16@24
B48@0:8{_NSRange=QQ}16@32@40
{_NSRange=QQ}32@0:8{_NSRange=QQ}16
B32@0:8{_NSRange=QQ}16
@76@0:8@16@24q32q40B48B52@56@64B72
q24@0:8q16
@32@0:8q16I24I28
i16@0:8
i24@0:8^{OpaqueAudioComponentInstance=}16
