@(#)PROGRAM:MPSNeuralNetwork  PROJECT:MPS-1
19FilterNodeFileError
<empty>
21ResourceNodeFileError
@333?
[%@ apply...] commandBuffer may not be nil]
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixFullyConnectedGradient.mm
[%@ apply...] input gradient matrix may not be nil
[%@ apply...] weight matrix may not be nil
[%@ apply...] result gradient for weight matrix may not be nil
[%@ apply...] input matrix origin z component must be 0
[%@ apply...] weight matrix origin z component must be 0
[%@ apply...] result matrix origin z component must be 0
Only MPSDataTypeFloat32 is supported.
Matrices contain batches, batching not supported.
secondarySourceMatrixOrigin.y not within domain of weight matrix.
secondarySourceMatrixOrigin.x not within domain of weight matrix.
primarySourceMatrixOrigin not within domain of input gradient matrix.
[%@ apply...] input data matrix may not be nil
[%@ apply...] result gradient for bias vector may not be nil
secondarySourceMatrixOrigin.y not within domain of input data matrix.
secondarySourceMatrixOrigin.x not within domain of input data matrix.
[%@ initWithCoder:device:] Failed: unsupported file version.
MatrixFullyConnectedGradient
MPSMatrixFullyConnectedGradient._alpha;
MPSMatrixFullyConnectedGradient._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnectedGradient._sourceInputFeatureChannels;
MPSMatrixFullyConnectedGradient._sourceOutputFeatureChannels;
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNReshape.mm
ReshapeOperation
ReshapeGradientOperation
pad before (x,y,ch) = (%lu, %lu, %lu)
pad after  (x,y,ch) = (%lu, %lu, %lu)
secondary source fc count = %lu
[initWithCoder:] out of memory?: could not decode fillValueArray
padBefore: (%d, %d, %d), 
padAfter: (%d, %d, %d)            
fillValue: %f
fillValueBuf: %s
created by %@
Source %p and destination %p shaapes are not the same sizes
Source feature channel offset for rehape must be 0 %lu
Destination feature channel offset for rehape must be 0 %lu
reshape_kernel
MPSNNReshape._reshapedWidth;
MPSNNReshape._reshapedHeight;
MPSNNReshape._reshapedFeatureChannels;
[... copyWithZone:device](copyBuffer) out of memory: could not allocate internal data
MPSNNPad_paddingSizeBefore.x
MPSNNPad_paddingSizeBefore.y
MPSNNPad_paddingSizeBefore.channel
MPSNNPad_paddingSizeAfter.x
MPSNNPad_paddingSizeAfter.y
MPSNNPad_paddingSizeAfter.channel
MPSNNPad_fillValue
MPSNNPad_aBufLenFP32
%@%@
.length
.data
MPSNNPad_aBuf
[MPSNNPad encode] Error: Number of feature channels in result (%d) not large enough (needed %lu).
cnnPadKernel
v16@?0@"<MTLCommandBuffer>"8
cnnPadGradientKernel
[%@ initWithDevice:] is not allowed. Please use initializers that are not marked NS_UNAVAILABLE.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNPoolingGradient.mm
zero pad size X: %lu
zero pad size Y:%lu
MPSCNNPoolingGradient.sourceSize.width
MPSCNNPoolingGradient.sourceSize.height
MPSCNNPoolingGradient.sourceSize.depth
[%@ encode...] Destination feature channel offset too large!
[%@ encode...] Destination feature channel offset Not multiple of 4!
MPSCNNPoolingGradient_generic_max_2d_2d
MPSCNNPoolingGradient_generic_max_2dArray_2dArray
MPSCNNPoolingGradient_generic_average_2d_2d
MPSCNNPoolingGradient_generic_average_2dArray_2dArray
MPSCNNPoolingGradient_generic_dilatedmax_2d_2d
MPSCNNPoolingGradient_generic_dilatedmax_2dArray_2dArray
MPSCNNPoolingGradient_generic_L2norm_2d_2d
MPSCNNPoolingGradient_generic_L2norm_2dArray_2dArray
MPSCNNPoolingGradient_generic_batch
MPSCNNPoolingGradient_inStateTex_batch
MPSCNNPoolingGradient.padSizeX
MPSCNNPoolingGradient.padSizeY
Error: The only valid values for primaryStrideInPixelsX (%lu) are 0 or 1.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNArithmetic.mm
Error: The only valid values for primaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for primaryStrideInFeatureChannels (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsX (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInFeatureChannels (%lu) are 0 or 1.
Cannot directly initialize MPSCNNArithmetic. Use one of the sub-classes of MPSCNNArithmetic.
invalid arithmetic operator type (%u)
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
primaryStrideInFeatureChannels: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
arithmeticType: %lu
[%@ resultStatesForSourceImage...] sourceStates must be nil for this filter]
Error: [%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] called with less than two source images.
[%@ %@] Error: destination state may not be nil
[%@ %@] Error: destination state must be a MPSCNNArithmeticGradientState
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
isSecondarySourceFilter: %d
arithmeticType: %lu
MPSArithmetic.primaryScale
MPSArithmetic.secondaryScale
MPSArithmetic.bias
MPSArithmetic.minimumValue
MPSArithmetic.maximumValue
MPSArithmetic.primaryStrideInFeatureChannels
MPSArithmetic.secondaryStrideInFeatureChannels
MPSArithmetic.arithmeticType
[%@ encode...] MPSImageFeatureChannelsInterleavedPerPixel is not supported
[%@ encode...] invalid arithmetic operation
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + src.featureChannels > dest.featureChannels
[%@ encode...] equality threshold is negative.
MPSCNNMath_Arithmetic
MPSCNNMath_Arithmetic_Special_SubtractGradient
MPSCNNMath_Arithmetic_4Pixel_StrideXY0
MPSArithmetic.isSecondarySourceFilter
[%@ encode...] partial computation failed
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSRNNLayer.mm
[%@ initWithDevice:rnnDescriptors:] device may not be nil
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor.inputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptor:] outputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu] may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].inputFeatureChannels must be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].outputFeatureChannels must be larger than zero
[%@ copyWithZone:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] Problem decoding layer stack
[%@ encodeWithCoder:] Problem allocating internal data
[%@ encode...] sourceMatrices[%d].rows == %d, should match destinationMatrices[%d].rows == %d
[%@ encode...] sourceMatrices[%d].columns == %d, should match layer input feature channels == %d
[%@ encode...] destinationMatrices[%d].columns == %d, should match layer output feature channels == %d
Out of memory in MPSRNNMatrixTrainingLayer:createWeightMatrices
[%@ encode...] Error: empty set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: matrix Id not found on this layer.
[%@ encode...] Error: Invalid matrix Id for single gate
[%@ encode...] Error: Datatype conversions in encodeCopyWeightsToCommandBuffer: not supported yet
[%@ encode...] Error: only MPSDataTypeFloat32 supported currently
[%@ encode...] Error: source size is (%lu, %lu) (rows, columns) - should be (%lu, %lu) 
[%@ encode...] Error: Invalid matrix Id for LSTM
[%@ encode...] Error: Invalid set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: Invalid matrix Id for GRU
[%@ encode...] Error: Number of weight matrices (%lu), does not match number of weightGradient matrices (%lu)
[%@ encode...] Error: Number of weight matrices (%lu), does not match number at init time (%lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match weightGradient matrix dimensions (rows = %lu, columns = %lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match init time weight matrix dimensions (rows = %lu, columns = %lu)
[%@ encode...] forwardSources[%d].rows == %d, should match sourceGradients[%d].rows == %d
[%@ encode...] forwardSources[%d].columns == %d, should match layer input feature channels == %d
[%@ encode...] sourceGradients[%d].columns == %d, should match layer output feature channels == %d
[%@ encode...] forwardSources[%d].rows == %d, should match destinationGradients[%d].rows == %d
[%@ encode...] destinationGradients[%d].columns == %d, should match layer input feature channels == %d
MPSRNNMatrixVecMulFloat4
MPSRNNMatrixVecMulFloat1
MPSRNNMatrixVecMulFloat1_nonMult4
MPSRNNCopyData
MPSRNNAddSequenceData
MPSRNNMultiInputKernelFloat1
MPSRNNMultiInputKernelFloat1_nonMult4
MPSRNNCombineInputVecs
RNNAddBiasToOutput
MPSRNNLSTMRecursionTex0
MPSRNNLSTMRecursionTex1
MPSRNNLSTMRecursionCombined0float
MPSRNNLSTMRecursionCombined1float
MPSRNNLSTMFullRecursion0float
MPSRNNLSTMFullRecursion1float
MPSRNNLSTMRecursionCombined0half
MPSRNNLSTMRecursionCombined1half
MPSRNNLSTMFullRecursion0half
MPSRNNLSTMFullRecursion1half
MPSRNNBreakUpToOutputVecs
MPSRNNReduceToBiasGradient
MPSRNNClearFloatBuffer
MPSRNNClearCharBuffer
kMPSRNNLayer._inputFeatureChannels
kMPSRNNLayer._outputFeatureChannels
kMPSRNNLayer._numberOfLayers
kMPSRNNLayer._recurrentOutputIsTemporary
kMPSRNNLayer._storeAllIntermediateStates
kMPSRNNLayer._bidirectionalCombineMode
kMPSRNNLayer.layerTypes
[%@ encode...] commandBuffer may not be nil]
[%@ encode...] source may not be nil
[%@ encode...] destination may not be nil
[%@ encode...] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
MPSRNNImageCombine_2d_2d_2d_float
MPSRNNImageCombine_2d_2dArray_2d_float
MPSRNNImageCombine_2dArray_2d_2d_float
MPSRNNImageCombine_2dArray_2dArray_2d_float
MPSRNNImageCombine_2d_2d_2dArray_float
MPSRNNImageCombine_2d_2dArray_2dArray_float
MPSRNNImageCombine_2dArray_2d_2dArray_float
MPSRNNImageCombine_2dArray_2dArray_2dArray_float
MPSRNNGateCombine_2d_2d_2d_float
MPSRNNGateCombine_2d_2dArray_2d_float
MPSRNNGateCombine_2dArray_2d_2d_float
MPSRNNGateCombine_2dArray_2dArray_2d_float
MPSRNNGateCombine_2d_2d_2dArray_float
MPSRNNGateCombine_2d_2dArray_2dArray_float
MPSRNNGateCombine_2dArray_2d_2dArray_float
MPSRNNGateCombine_2dArray_2dArray_2dArray_float
MPSRNNPNormCombine_2d_2d_2d_float
MPSRNNPNormCombine_2d_2dArray_2d_float
MPSRNNPNormCombine_2dArray_2d_2d_float
MPSRNNPNormCombine_2dArray_2dArray_2d_float
MPSRNNPNormCombine_2d_2d_2dArray_float
MPSRNNPNormCombine_2d_2dArray_2dArray_float
MPSRNNPNormCombine_2dArray_2d_2dArray_float
MPSRNNPNormCombine_2dArray_2dArray_2dArray_float
MPSLSTMMultiInputKernelFloat1
MPSLSTMMultiInputKernelFloat2
MPSLSTMMultiInputKernelFloat3
MPSLSTMMultiInputKernelFloat4
MPSLSTMMultiInputKernelFloat5
MPSLSTMMultiInputKernelFloat6
MPSLSTMMultiInputKernelFloat7
MPSLSTMMultiInputKernelFloat8
MPSLSTMMultiInputKernelFloat9
MPSLSTMMultiInputKernelFloat10
MPSLSTMMultiInputKernelFloat11
MPSLSTMMultiInputKernelFloat12
MPSLSTMMultiInputKernelFloat13
MPSLSTMMultiInputKernelFloat14
MPSLSTMMultiInputKernelFloat15
MPSLSTMMultiInputKernelFloat16
MPSRNNLSTMRecursionfloat00_11_1
MPSRNNLSTMRecursionhalf00_11_1
MPSRNNLSTMRecursionchar00_11_1
MPSRNNLSTMRecursionfloat00_11_2
MPSRNNLSTMRecursionhalf00_11_2
MPSRNNLSTMRecursionchar00_11_2
MPSRNNLSTMRecursionfloat00_11_4
MPSRNNLSTMRecursionhalf00_11_4
MPSRNNLSTMRecursionchar00_11_4
MPSRNNLSTMRecursionfloat00_11_8
MPSRNNLSTMRecursionhalf00_11_8
MPSRNNLSTMRecursionchar00_11_8
MPSRNNLSTMRecursionfloat00_41_1
MPSRNNLSTMRecursionhalf00_41_1
MPSRNNLSTMRecursionchar00_41_1
MPSRNNLSTMRecursionfloat00_42_1
MPSRNNLSTMRecursionhalf00_42_1
MPSRNNLSTMRecursionchar00_42_1
MPSRNNLSTMRecursionfloat00_44_1
MPSRNNLSTMRecursionhalf00_44_1
MPSRNNLSTMRecursionchar00_44_1
MPSRNNLSTMRecursionfloat00_81_1
MPSRNNLSTMRecursionhalf00_81_1
MPSRNNLSTMRecursionchar00_81_1
MPSRNNLSTMRecursionfloat00_82_1
MPSRNNLSTMRecursionhalf00_82_1
MPSRNNLSTMRecursionchar00_82_1
MPSRNNSingleGateGradientRecursion_float_14_1
MPSRNNSingleGateGradientRecursion_float_24_1
MPSRNNSingleGateGradientRecursion_float_44_1
MPSRNNSingleGateGradientRecursion_half_14_1
MPSRNNSingleGateGradientRecursion_half_24_1
MPSRNNSingleGateGradientRecursion_half_44_1
MPSRNNSingleGateGradientRecursion_char_14_1
MPSRNNSingleGateGradientRecursion_char_24_1
MPSRNNSingleGateGradientRecursion_char_44_1
MPSRNNLSTMGradientRecursion_float_14_1
MPSRNNLSTMGradientRecursion_float_24_1
MPSRNNLSTMGradientRecursion_float_44_1
MPSRNNLSTMGradientRecursion_half_14_1
MPSRNNLSTMGradientRecursion_half_24_1
MPSRNNLSTMGradientRecursion_half_44_1
MPSRNNLSTMGradientRecursion_char_14_1
MPSRNNLSTMGradientRecursion_char_24_1
MPSRNNLSTMGradientRecursion_char_44_1
MPSRNNGRUGradientRecursion1_float_14_1
MPSRNNGRUGradientRecursion1_float_24_1
MPSRNNGRUGradientRecursion1_float_44_1
MPSRNNGRUGradientRecursion1_half_14_1
MPSRNNGRUGradientRecursion1_half_24_1
MPSRNNGRUGradientRecursion1_half_44_1
MPSRNNGRUGradientRecursion1_char_14_1
MPSRNNGRUGradientRecursion1_char_24_1
MPSRNNGRUGradientRecursion1_char_44_1
MPSRNNGRUGradientRecursion2_float_14_1
MPSRNNGRUGradientRecursion2_float_24_1
MPSRNNGRUGradientRecursion2_float_44_1
MPSRNNGRUGradientRecursion2_half_14_1
MPSRNNGRUGradientRecursion2_half_24_1
MPSRNNGRUGradientRecursion2_half_44_1
MPSRNNGRUGradientRecursion2_char_14_1
MPSRNNGRUGradientRecursion2_char_24_1
MPSRNNGRUGradientRecursion2_char_44_1
MPSRNNSingleGateRec_float00_1_2
MPSRNNSingleGateRec_float00_1_4
MPSRNNSingleGateRec_float00_8_2
MPSRNNSingleGateRec_float00_8_4
MPSRNNSingleGateRec_half00_1_2
MPSRNNSingleGateRec_half00_1_4
MPSRNNSingleGateRec_half00_8_2
MPSRNNSingleGateRec_half00_8_4
MPSRNNSingleGateRec_char00_1_2
MPSRNNSingleGateRec_char00_1_4
MPSRNNSingleGateRec_char00_8_2
MPSRNNSingleGateRec_char00_8_4
MPSRNNGRURecursion1float00_11
MPSRNNGRURecursion1float00_44
MPSRNNGRURecursion1half00_11
MPSRNNGRURecursion1half00_44
MPSRNNGRURecursion1char00_11
MPSRNNGRURecursion1char00_44
MPSRNNGRURecursion2float00_11
MPSRNNGRURecursion2float00_44
MPSRNNGRURecursion2half00_11
MPSRNNGRURecursion2half00_44
MPSRNNGRURecursion2char00_11
MPSRNNGRURecursion2char00_44
Only MPSDataTypeFloat32 and MPSDataTypeFloat16 supported
Unsupported Metal device
[copySingleGateLayer copyWithZone:device] out of memory: could not allocate internal data
[copyLSTMLayer copyWithZone:device] out of memory: could not allocate internal data
[initWithCoder:] out of memory: could not allocate internal data
%@%d
kMPSRNNLayer.common.direction
kMPSRNNLayer.common.useUnitXForm
kMPSRNNLayer.common.nHiddenFeatures
kMPSRNNLayer.common.nInputFeatures
kMPSRNNLayer.common.nOutputFeatures
kMPSRNNLayer.common.nRecurrentOutputFeatures
kMPSRNNLayer.common.inputTransform
kMPSRNNLayer.common.outputTransform
kMPSRNNLayer.common.recurrentOutputTransform
kMPSRNNLayer.common.inputTransform.hasBias
kMPSRNNLayer.common.outputTransform.hasBias
kMPSRNNLayer.common.recurrentOutputTransform.hasBias
MPSRNNLayer.SingleGate.inputXForm
MPSRNNLayer.SingleGate.recurrentXForm
MPSRNNLayer.SingleGate.hasBias
MPSRNNLayer.SingleGate.biasData
.convolution
kMPSRNNLayer.neuron.neuronType
kMPSRNNLayer.neuron.neuronParamA
kMPSRNNLayer.neuron.neuronParamB
kMPSRNNLayer.neuron.neuronParamC
[initWithCoder:](decodeLSTMLayer) out of memory: could not allocate internal data
MPSRNNLayer.LSTM.inputGate
MPSRNNLayer.LSTM.forgetGate
MPSRNNLayer.LSTM.cellGate
MPSRNNLayer.LSTM.outputGate
MPSRNNLayer.LSTM.recursionXFormsCombined
MPSRNNLayer.LSTM.finalNeuron
MPSRNNLayer.LSTM.inputXFormsCombined
MPSRNNLayer.LSTM.coupleForgetGateToInputGate
MPSRNNLayer.LSTM.cellClipThreshold
.inputXForm
.recurrentXForm
.peepholeXForm
.hasBias
.biasVector
.peepholeVector
.nHiddenFeatures
[initWithCoder:](decodeGRULayer) out of memory: could not allocate internal data
MPSRNNLayer.GRU.inputGateInputXform
MPSRNNLayer.GRU.inputGateRecXform
MPSRNNLayer.GRU.inputGateBias
MPSRNNLayer.GRU.inputGateHasBias
MPSRNNLayer.GRU.inputNeuron
MPSRNNLayer.GRU.recGateInputXform
MPSRNNLayer.GRU.recGateRecXform
MPSRNNLayer.GRU.recGateBias
MPSRNNLayer.GRU.recGateHasBias
MPSRNNLayer.GRU.recurrentNeuron
MPSRNNLayer.GRU.outputGateInputXform
MPSRNNLayer.GRU.outputGateRecXform
MPSRNNLayer.GRU.outputGateMemoryform
MPSRNNLayer.GRU.outputGateBias
MPSRNNLayer.GRU.outputGateHasBias
MPSRNNLayer.GRU.outputNeuron
MPSRNNLayer.GRU.pNormGateValue
MPSRNNLayer.GRU.flipOutputGates
Out of memory initializing RNN training layer
[... initWithCoder:device](decodeTransform) out of memory: could not allocate internal data
.dataType
.biasLength
.biasData
.rows
.rowBytes
.columns
[... encodeWithCoder:](encodeTransform) Invalid transform buffer
[MPSNNScaleNode init] Error: Abstract class. 
Please use MPSNNBilinearScaleNode or MPSNNLanczosScaleNode instead.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNScale.mm
region provider: %@
size: {%lu, %lu, %lu}
use entire image
Internal error: [%@ initWithDevice:] unavailable
region provider: %@
Size: { %lu, %lu, %lu}
<copy entire image>
%@ error: Filter does not support result depth != 1
%@ %p error: the resampling filter does not support featureChannels > 4.
Error: class %@ does not conform to <MPSImageTransformProvider>
MPSNNScale.className
MPSNNScale.o
MPSNNScale.transformProviderName
MPSNNScale.handleName
MPSNNScale.handle.o
MPSNNScale.destSize.x
MPSNNScale.destSize.y
MPSNNScale.destSize.z
[MPSNNGraph encode...]: Error: MPSNNPadding method %p returned a nil formatting descriptor for an intermediate image.
The encode can not continue.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/FilterNode.h
Internal error: default encode for unary kernels doesn't take an input state
<missing label>
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
float16
float32
unorm8
unorm16
snorm8
snorm16
uint8
uint6
sint8
sint16
bfloat16
<unknown channel format>
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
*** Warning: kernel %s (%s) produces a result of size %lu x %lu. We will probably assert soon.
Perhaps the MPSNNGraph input image is too small for this network, or an upstream padding
policy was incorrect (full>same>valid), or a stride too large?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImage for destination.  Encode failed.
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSImageInternal.h
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNConcatenation.mm
[%@ encode...] sourceImages may not be nil
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLPixelFormat is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLTextureUsage is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] sourceImages length is 0. Can not produce a result.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  The MPSImageFeatureChannelsLayout must match between source and destination MPSImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu and dest image must have the same feature channel layout
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  the sum of feature channels in the source images  must fit within the destination image
[%@ encodeToCommandBuffer:sourceImages:destinationImage] Error: source image %lu (%p) has invalid feature channel layout.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] internal error: unable to create MTLTextureType2DArray view of src texture %p
[%@ encodeBatchToCommandBuffer:sourceImages:destinationImage:] Error: there are not enough source images in batch %lu (%lu) to fill the destination batch %lu
[%@ encodeToCommandBuffer: sourceImages:] sourceImages.count may not be 0
[%@ %@] Error: command buffer may not be NULL
[%@ %@] Error: sourceImage batch may not be NULL
[%@ %@] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImages may not be NULL
[%@ resultStateBatchForSourceImages:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
%@, %lu
slice offsets:              {%@}
feature channels per slice: {%@}
ConcatenateInterleaved
ConcatenateInterleaved_array
ConcatenateArray
ConcatenateArray_array
Please initialize the %@ class with initWithDevice:weights
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionGradientForData.mm
[%@ initWithDevice:convolutionDescriptor:weights:] device may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] convolutionDescriptor may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] 8-bit weights not supported in
kernel width must be > 0
kernel height must be > 0
number of input feature channels must be > 0
number of output feature channels must be > 0
strideX must be > 0
strideY must be > 0
dilationRateX must be > 0
dilationRateY must be > 0
number of groups must be > 0
Subpixel convolution does not currently supported gradient back propagation
Depthwise convoution gradient is only supported for channel multipler == 1
requested use of float32 weights, but weight buffer has type 0x%16.16llx
kernelWeightsDataType must be MPSDataTypeFloat16 for weights of type 0x%16.16llx
Lock creation failed
Failed to create weights buffer
weights.load should return YES
data source returned nil weights
Weights layout of convolution gradient object %s does not match that of state object %s
weights to reload method cannot be nil
weights buffer should have %lu bytes of data
Number of source feature channels needed by convolution %lu are not available in image with %lu feature channels
Number of destination feature channels needed by convolution gradient w.r.t data %lu are not available in image with %lu feature channels at offset %lu
Layout of convolution and convolution gradient object mismatch
clearWeightsAndBiasesBuffer
MPSCNNConvolutionWeightsLayoutOHWI
MPSCNNConvolutionWeightsLayoutOIHW
MPSCNNConvolutionGradientIsFullyConnected
kMPSCNNConvolutionGradientSerializeWeightsAndBiases
kMPSCNNConvolutionGradientConvolutionTranspose
MPSCNNConvolutionGradientInputFeatureChannels
MPSCNNConvolutionGradientOutputFeatureChannels
MPSCNNConvolutionGradientGroups
MPSCNNConvolutionChannelMultiplier
kMPSCNNConvolutionGradientWeightsDataType
kMPSCNNConvolutionGradientPreferredWeightsDataType
kMPSCNNConvolutionGradientWeightsLayout
kMPSCNNConvolutionGradientOption
Gradient filter not implemented for reduction kernels.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNReductionNodes.mm
Internal error: default encode for gradient kernels doesn't take an result state
Internal error: default encode for gradient kernels has an input state
Internal error: gradient kernels take an input state
Internal error: gradient kernels take multiple input images
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalizationGradient.mm
[%@ apply...] input matrix may not be nil
[%@ apply...] gradient matrix may not be nil
[%@ apply...] input mean vector may not be nil
[%@ apply...] input variance vector may not be nil
[%@ apply...] result gradient for data matrix may not be nil
Only outputs of MPSDataTypeFloat32 are supported.
Only beta vector value types of MPSDataTypeFloat32 are supported.
Only gamma vector value types of MPSDataTypeFloat32 are supported.
Only input matrix value types of MPSDataTypeFloat32 are supported.
PReLU not supported.
MatrixBatchNormalizationGradient
MPSMatrixBatchNormalizationGradient._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalizationGradient._sourceInputFeatureChannels;
MPSMatrixBatchNormalizationGradient._neuronType;
MPSMatrixBatchNormalizationGradient._neuronA;
MPSMatrixBatchNormalizationGradient._neuronB;
MPSMatrixBatchNormalizationGradient._neuronC;
MPSMatrixBatchNormalizationGradient._epsilon;
[%@ initWithDevice:keepProbability:seed:] Failed: the valid range of keepProbability (%lu) is (0.0f, 1.0f]
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNDropout.mm
keepProbability: %f
seed: %lu
MPSCNNDropoutKeepProbability
MPSCNNDropoutSeed
MPSCNNDropoutMaskStrideInPixelsWidth
MPSCNNDropoutMaskStrideInPixelsHeight
MPSCNNDropoutMaskStrideInPixelsDepth
[%@ encode...] valid values for maskStrideInPixels {%lu %lu %lu} are 0 and 1
MPSDropoutRGBA
MPSDropoutRG
MPSDropoutR
_MPSCommandBufferRetainListKey
MPSCNNDropoutGradientKeepProbability
MPSCNNDropoutGradientSeed
MPSCNNDropoutGradientMaskStrideInPixelsWidth
MPSCNNDropoutGradientMaskStrideInPixelsHeight
MPSCNNDropoutGradientMaskStrideInPixelsDepth
Cannot directly initialize MPSCNNUpsampling. Use one of the sub-classes of MPSCNNUpsampling.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNUpsampling.mm
scale factor in the x dimension (%lu) must be > 0
scale factor in the y dimension (%lu) must be > 0
invalid filter type (%lu)
scaleFactorX: %f
scaleFactorY: %f
MPSCNNUpsampling.filterType
MPSCNNUpsampling.scaleFactorX
MPSCNNUpsampling.scaleFactorY
MPSCNNUpsampling.alignCorners
[%@ encode...] Specificed scaleFactorX would result in destination texture width that exceeds the maximum allowed texture width
[%@ encode...] Specificed scaleFactorY would result in destination texture height that exceeds the maximum allowed texture height
MPSCNNUpsampling_general
MPSCNNUpsampling_SWBilinear
MPSCNNGradientKernel.kernelOffsetX
MPSCNNGradientKernel.kernelOffsetY
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] no padding method set. Can not compute result.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSCNNGradientKernel.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] the object padding method %p does not respond to the destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor: selector
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImage for destination.  Encode failed.
[%@ encode] Error: Gradient filters do not support gradient operations for Inference kernels that use the clipRect to operate on a subregion of the result
This would force the gradient kernel to have to do software edging at significant performance cost.
Use the slice operator to  trim away the unwanted parts of the gradient input.
[%@ encode] Error: Unknown state type.  Encode failed.
[%@ encodeToCommandBuffer:sourceGradients:...] Unable to create MPSImageDescriptor for destination.  Encode failed.
a: %f
b: %f
c: %f
Internal error: encountered unknown neuron type
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNNeuronNodes.mm
%@ (%s)
MPSCNNNeuron (%s)
MPSCNNNeuronGradient (%s)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSGridSample.mm
GridSample
grid_sample
[%@ encode...] secondary source must have 2 feature channels
MPSNNGridSample.useGridValueAsInputCoordinate
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixFullyConnected.mm
[%@ apply...] result matrix may not be nil
Only bias vector value types of MPSDataTypeFloat32 are supported.
Only weight matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
filter.batchStart not within domain of inputMatrix.
filter.batchStart not within domain of weightMatrix.
filter.batchStart not within domain of resultMatrix.
filter.batchStart not within domain of biasVector.
secondarySourceMatrixOrigin.y not within domain of weightMatrix.
secondarySourceMatrixOrigin.x not within domain of weightMatrix.
primarySourceMatrixOrigin not within domain of inputMatrix.
PReLU param-A array failed to set.
[%@ initWithCoder:device:] Failed: Unable to read array for MPSCNNNeuronTypePReLU.
For PReLU, use -setNeuronToPReLUWithParametersA:
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
sourceOutputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
Only outputs of MPSDataTypeFloat32 and MPSDataTypeFloat16 are supported.
Input matrix value type must match output matrix value type.
sourceMatrixOrigin not within domain of inputMatrix.
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixFullyConnectedTexture_M4
MatrixNeuron_float
MatrixNeuron_half
MatrixFullyConnected_FP32_G13P
MatrixFullyConnected_FP16_G13P
MatrixFullyConnected_AnyM
MPSMatrixFullyConnected._alpha;
MPSMatrixFullyConnected._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnected._sourceInputFeatureChannels;
MPSMatrixFullyConnected._sourceOutputFeatureChannels;
MPSMatrixFullyConnected._neuronType;
MPSMatrixFullyConnected._neuronA;
MPSMatrixFullyConnected._neuronB;
MPSMatrixFullyConnected._neuronC;
MPSMatrixFullyConnected._perChannelNeuronA;
[%@ initWithDevice:dataSource:] dataSource.load should return YES
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalization.mm
[%@ initWithDevice:dataSource:fusedNeuronDescriptor] neuron is of type PReLU but data is nil.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported.  Batch normalization state requires a source state.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:] Attempting to use statistics from a temporary MPSCNNBatchNormalizationState with readCount of 0.
[%@ encodeBatchToCommandBuffer...] Error: convenience methods that return a image batch must have clipRect.origin.z = 0.  We can't return empty batch nodes in a NSArray.
Cannot create state for images with more feature channels than used to initialize batch normalization filter.
[%@ reloadDataSource:] dataSource.load should return YES
state does not have valid gamma and beta buffers.
reloadGammaAndBeta
state does not have valid mean and variance buffers.
reloadMeanAndVariance
[%@ %@] Error: Unable to decode data source.
[%@ %@] Error: dataSource does not support NSSecureCoding
feature channels: %lu
epsilon: %g
data source: %@
neuron:
batchNormSimpleBufferCopy
encodeBatchToCommandBuffer: Neuron is of type PReLU but parameter buffer is nil.
imageBatchNormalization
Error: Can not decode. Unable to find class implementation for "%@".
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSCoreInternal.h
kMPSCNNBatchNormalization.s
kMPSCNNBatchNormalization.o
kMPSCNNBatchNormalizationIsNeuronFusedKey
kMPSCNNBatchNormalizationFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLUData
kMPSCNNBatchNormalizationFusedNeuronA
kMPSCNNBatchNormalizationFusedNeuronB
kMPSCNNBatchNormalizationFusedNeuronC
MPSCNNConvolutionTransposeGradienState was not created with MPSCNNConvolutionGradientState (auto-encoder). convolution property is not available
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionTranspose.mm
Please use correct initializer.
convolutionTranspose: %@ %p "%@"
Filter weights pointer should be non-null
Feature channel layout of source and MPSCNNConvolutionTranspose filter doesn't match
Feature channel layout of destination and MPSCNNConvolutionTranspose filter doesn't match
Number of source feature channels needed by convolution %lu are not available in image with %lu feacture channels
Number of destination feature channels needed by convolution %lu are not available in image with %lu feature channels at offset %lu
Accumulator precision must be set to MPSNNConvolutionAccumulatorPrecisionOptionFloat when using float32 kernel weights
Please use encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationState:destinationStateIsTemporary:
Please use encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationStates:destinationStateIsTemporary:
%@inputFeatureChannels: %lu
outputFeatureChannels: %lu
Feature channel layout: %lu
Groups: %lu 
kernelOffset: {%zd, %zd}
neuron type: %s
neuron A:  %10.14f
neuron B:  %10.14f
neuron C:  %10.14f
Error: -[MPSCNNConvolution reloadWeightsAndBiasesWithDataSource:] does not support changing the data source.
It has been deprecated. Please use -reloadWeightsAndBiasesFromDataSource instead.
MPSCNNConvolutionTransposeVers
MPSCNNConvolutionTransposeWidth
MPSCNNConvolutionTransposeHeight
MPSCNNConvolutionTransposeInputFeatureChannels
MPSCNNConvolutionTransposeOutputFeatureChannels
MPSCNNConvolutionTransposeStrideInPixelsX
MPSCNNConvolutionTransposeStrideInPixelsY
MPSCNNConvolutionTransposeDilationRateX
MPSCNNConvolutionTransposeDilationRateY
MPSCNNConvolutionTransposeGroups
MPSCNNConvolutionTransposeFeatureChannelsLayout
MPSCNNConvolutionTransposeKernelOffsetX
MPSCNNConvolutionTransposeKernelOffsetY
MPSCNNConvolutionTransposeFusedNeuronClassKey
MPSCNNConvolutionTransposeNeuron
MPSCNNConvolutionTransposeConvolutionClassKey
MPSCNNConvolutionTransposeConvolutionKey
cnnConv1xIn8xOutH
cnnConv1xIn8xOutArrayH
cnnConv3xIn8xOutH
cnnConv3xIn8xOutArrayH
cnnConv8xIn8xOutH
cnnConv8xIn8xOutArrayH
cnnConv3In8xOutH
cnnConv3In8xOutArrayH
cnnConv1In8xOutH
cnnConv1In8xOutArrayH
cnnConv1In8xOutH3x3
cnnConv1In8xOutArrayH3x3
cnnConv1In8xOutH5x5
cnnConv1In8xOutArrayH5x5
cnnConv8xIn4xOutH1x1
cnnConv8xIn4xOutArrayH1x1
cnnConv8xIn8xOutH1x1
cnnConv8xIn8xOutArrayH1x1
cnnConv8xIn1xOutH
cnnConv8xIn1xOutArrayH
cnnConv8xIn2xOutH
cnnConv8xIn2xOutArrayH
cnnConv8xIn3xOutH
cnnConv8xIn3xOutArrayH
cnnConv8xIn4xOutH
cnnConv8xIn4xOutArrayH
cnnConv8xIn8xOutHgroup
cnnConv8xIn8xOutArrayHgroup
You must call -gradientFiltersWithSources:gradientImages: for this filter
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNArithmeticNodes.mm
[%@ gradientFiltersWithSources:] This method requires one gradient image as input
[%@ gradientFiltersWithSources:] gradientImages[0] must be valid and contain the source gradient
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNBinaryArithmeticNode
Internal error: default encode for binary kernels doesn't take an input state
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalizationGradient.mm
imageInstanceNormalizationThreadgroupDot
imageInstanceNormalizationImageDot
imageInstanceNormalizationGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationStatisticsGradient.mm
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientStates:destinationGradient:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
imageInitialDotBase
imageFinalSumBase
imageThreadgroupSumDotBase
kMPSCNNBatchNormalizationStatisticsGradientIsNeuronFusedKey
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLULength
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronA
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronB
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronC
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingNearestNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNUpsamplingNodes.mm
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingBilinearNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNOptimizers.mm
[%@ initWithCoder:device:] Unsupported file version. Could not init object.
            
learningRate:
            
gradientRescale:
            
applyGradientClipping:
            
gradientClipMax:
            
gradientClipMin:
            
regularizationType:
            
regularizationScale:
            
momentumScale:
            
useNesterovMomentum:
inputGradientMatrix
inputValuesMatrix
inputMomentumMatrix
resultValuesMatrix
[resultState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionSourceState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionGradientState isKindOfClass: MPSCNNConvolutionGradientState] failed
[inputMomentumVectors count] > 0 failed
convolutionResultState.numberOfWeights == convolutionSourceState.numberOfWeights failed 
convolutionResultState.numberOfBiases == convolutionSourceState.numberOfBiases failed 
[batchNormalizationSourceState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[batchNormalizationGradientState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[resultState isKindOfClass: MPSCNNNormalizationGammaAndBetaState.class] failed
inputGradientState.gradientForGamma returned nil
[batchNormalizationState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
            
decay:
            
epsilon:
            
momentumScale:
            
centered:
inputSumOfSquaresMatrix
inputMomentumMatrix != nil failed for a non 0 momentumScale
inputWeightedSumMatrix != nil failed for a centered RMSProp
inputWeightedSumMatrix
inputSumOfSquaresVectors != nil failed
[inputSumOfSquaresVectors count] > 0 failed
            
beta1:
            
beta2:
            
epsilon:
%f            
timeStep:
inputVelocityMatrix
maximumVelocityMatrix
inputMomentumVectors != nil failed
inputVelocityVectors != nil failed
[inputVelocityVectors count] > 0 failed
[maximumVelocityVectors count] > 0 failed
[maximumVelocityVectors count] == [inputVelocityVectors count failed 
kMPSNNOptimizer.learningRate
kMPSNNOptimizer.gradientRescale
kMPSNNOptimizer.applyGradientClipping
kMPSNNOptimizer.gradientClipMax
kMPSNNOptimizer.gradientClipMin
kMPSNNOptimizer.regularizationType
kMPSNNOptimizer.regularizationScale
kMPSNNOptimizer.momentumScale
kMPSNNOptimizer.useNestrovMomentum
sgdUpdate
sgdUpdate4
sgdMomentumUpdate
sgdMomentumUpdate4
adamUpdate
adamUpdate4
amsGradUpdate
amsGradUpdate4
%s.dataType == MPSDataTypeFloat32 failed, Optimizers currently support only Float32 datatype vectors
%s.matrices == 1 failed, Optimizers currently support only 1  matrix per MPSMatrix
inputGradientMatrix.rows == %s.rows failed, number of elements must be same
inputGradientMatrix.columns == %s.columns failed, number of elements must be same
kMPSNNOptimizer.decay
kMPSNNOptimizer.epsilon
kMPSNNOptimizer.centered
rmsPropUpdate
rmsPropUpdate4
kMPSNNOptimizer.beta1
kMPSNNOptimizer.beta2
kMPSNNOptimizer.timeStep
[%@ initWithDevice:resultImage:resultStates:] error: resultImage may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNGraph.mm
[%@ initWithDevice:resultImage:resultStates:] error: resultImage must be a child class of MPSNNImageNode
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph consumes MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces intermediate image objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a MPSImage
[MPSNNGraph encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:] error: source images must currently be type compatible with half float texture loads.
Source image [%lu] has pixel format %s
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
Did you perhaps forget to provide the state objects for labels and weights for the loss layer?
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceStates[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: destination image allocator may not be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a array of MPSImage
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is not a MPSImage
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: %lu MPSStateBatches expected as input. nil was passed.
<nil>
<no description>
outputStateIsTemporary:              %s
destinatonImageAllocator:            %s
default intermediate storage foramt: %s
result is needed:                    %s
list of nodes:
(Note: missing nodes have been optimized away.)
[%@ initWithCoder:device:] Failed: unable to read class of MPSNNGraph destination image allocator.
[%@ initWithCoder:device:] Failed: unable to find class of MPSNNGraph destination image allocator %@ in application.
MPS Warning: failure to unpack graph default image allocator with unarchiver. MPSTemporaryImage defaultAllocator will be used.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: outputStateIsTemporary must be set to NO for this method
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the destinationImageAllocator is set to create a temporary image.
A temporary image only lives as long as the MTLCommandBuffer. Its contents would be invalid by the time you were able to use them.
MPSErrorDomain
Failed to allocate MPSImage
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModePrivate. Perhaps you made a MPSTemporaryImage instead by mistake? That can't work.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModeMemoryless
MPS Internal Error: Unexpected command buffer status encountered: %lu
[%@ initWithDevice:resultImage:] internal error: could not create filter for node:
[%@ initWithDevice:resultImage:] internal error: source image is NULL
[%@ initWithDevice:resultImage:] internal error: state image is NULL
 result image id <-- filter <-- {filter source image id list}
 ============================================================
v24@?0^v8^{PrintStackFrame=}16
   * an image passed into the graph
   0 is the graph result image.
   () the result may be only partially overwritten.
Summary:
%4lu %s
Init MPSNNGraph %p
%lu nodes are specified.
Some may have been pruned because they were not needed to produce a result.
Initial graph:
v40@?0^v8^v16Q24^{EmptyStackFrame=}32
Final graph:
v24@?0^v8^{EmptyStackFrame=}16
Rejected contraction of %s:
it uses MPSNNPaddingMethodCustom without MPSNNPaddingMethodCustomAllowForNodeFusion
Rejected contraction of %s into %s:
the intermediate image is read by another filter (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu) or exported from the graph
  Attempting to contract consecutive filter passes into a single pass...
Removed %s because it does nothing
Can not contract %s: 
Contracted %s into %s
v24@?0^v8^{OptimizationStackFrame=}16
  Removed %lu passes
  No passes removed by contraction.
(This is common in training graphs because the intermediate tensors are needed for gradient passes.)
  Pruning unproductive filter nodes...
Pruned %s
  Pruned %lu nodes.
  Attempting to use feature channel offsets to eliminate concatenation and slice passes...
Optimized away %s
Optimized away %s
  Removed %lu passes
Verify Graph:
No filters in graph.
Error: node %p %@ "%@" has no result image. All MPS nodes are required to have a result.
Error: node %s has no result image. All MPS nodes are required to have a result.
Error: nothing reads the result from node %p %@ "%@".  All MPS nodes are required to have a result.
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES?
Error: nothing reads the result from node %s. 
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES.
Error: node %s has a missing result state? %lu
Error: nothing reads the result state from node %p %@ "%@".
Error: nothing reads the result state %lu from node %s. 
%lu issues reported.
Optimizing graph structure...
End graph optimization passes.
Error: using image with 0 read count
v40@?0^v8^v16Q24^{EncodeFrame=@@@@@QQQ^{Graph}}32
v24@?0^v8^{EncodeFrame=@@@@@QQQ^{Graph}}16
Legend:
FilterNodeType[filter.index] {src.width x src.height x src.featureChannels src.format}[src.index] ->
{dest.width x dest.height x dest.featureChannels dest.format}[dest.index] offset: destinationFeatureChannelOffset
=============================================================================================================
v40@?0^v8^v16Q24^{EncodeBatchFrame=@@@@@QQQ^{Graph}}32
v24@?0^v8^{EncodeBatchFrame=@@@@@QQQ^{Graph}}16
<none specified>
Internal Error: unhandled MPSImageFeatureChannelFormat %lu in [%@ debugDescription]
resultFormat:  %s
v24@?0^v8^{AutoreleasePoolStackFrame=@}16
<no filters>
Warning: Some parts of the encoded graph appear to be missing. 
 %lu filters, %lu images and %lu states were found.
 Expected: %lu filters, %lu images, %lu states
Error: The indices of the returned graph image nodes are missing.
, %lu
Filter: %@ {%lu}
Source Images: %lu {%s}
Source States: %lu
Result Images: %lu {%lu}
Result States: %lu
Filter:
  %@
<missing MPSNNFilterNode>
Error: could not unpack resource node. File data segment too small
Error: could not unpack resource node. File version too new
Error: could not unpack resource node. unknown exception %u
MPSNNGraphc
MPSNNGraphA
MPSNNGraphFI
MPSNNGraphResultIsNeeded
MPSNNGraphOutputStateIsTemporary
(%lu)
%lu 
%5s <-- %s <-- 
%lu%s
{%lu%s
, %lu%s
[%lu] %@ %p "%@"
[%lu] %@ %p
%@ %p
%@ "%@"
MPSNNGraph.filterNodes
MPSNNGraph.imageNodes
MPSNNGraph.stateNodes
MPSNNGraph.resultIndexCount
MPSNNGraph.resultIndices
MPSNNGraph.filterCount
MPSNNGraph.imageCount
MPSNNGraph.stateCount
MPSNNGraph.exportedImages
Data
ResourceWrapper.d
ResourceWrapper.hc
ResourceWrapper.h
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu   "%s"
padding policy: %s
(%@ --> %@)
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
Out of memory:  Append node failed. This graph is unlikely to produce expected results.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/NodeList.h
copyWeightsAndBiasesApple
export
reloadForward
reloadBackward
depthwiseConvolve_1xChannelMultiplier_3x3_noDilation
depthwiseConvolve_1xChannelMultiplier
Destination feature channel format %lu + number of output feature channels of filter %lu is more than feature channels available to write in destination image %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionApple.mm
output feature channels %lu must be multiple of scaleFactor^2 %lu
Number of feature channels in destination image %lu must be >= output feature channel of convolution / scaleFactor^2 %lu
Half accumulator does not have enough bits to keep signal from source with bit depth %d
Half accumulator does not have enough range to keep signal from bfloat16 source
dequantizeApple
Number of source feature channels needed by convolution %lu must be equal to number of channels in image but image has %lu feacture channels
Scale factor of > 1 is not supported for interleaved per pixel layout
dilationRateX of > 1 is not supported for interleaved per pixel layout
dilationRateY of > 1 is not supported for interleaved per pixel layout
cnnConv_Update_Depthwise_Apple
cnnConv_Update_Apple
cnnConv_Update_reduction
cnnConvArray_1xIn_4xOut_1_1
cnnConvArray_1xIn_4xOut_2_1
cnnConvArray_1xIn_4xOut_3_1
cnnConvArray_1xIn_4xOut_4_1
cnnConvArray_1xIn_4xOut_1_2
cnnConvArray_1xIn_4xOut_2_2
cnnConvArray_1xIn_4xOut_1_3
cnnConvArray_1xIn_4xOut_1_4
cnnConvArray_1xIn_8xOut_1_1
cnnConvArray_1xIn_8xOut_2_1
cnnConvArray_1xIn_8xOut_3_1
cnnConvArray_1xIn_8xOut_4_1
cnnConvArray_1xIn_8xOut_1_2
cnnConvArray_1xIn_8xOut_2_2
cnnConvArray_1xIn_8xOut_1_3
cnnConvArray_1xIn_8xOut_1_4
cnnConvArray_1xIn_16xOut_1_1
cnnConvArray_1xIn_16xOut_2_1
cnnConvArray_1xIn_16xOut_3_1
cnnConvArray_1xIn_16xOut_4_1
cnnConvArray_1xIn_16xOut_1_2
cnnConvArray_1xIn_16xOut_2_2
cnnConvArray_1xIn_16xOut_1_3
cnnConvArray_1xIn_16xOut_1_4
cnnConvArray_2xIn_4xOut_1_1
cnnConvArray_2xIn_4xOut_2_1
cnnConvArray_2xIn_4xOut_3_1
cnnConvArray_2xIn_4xOut_4_1
cnnConvArray_2xIn_4xOut_1_2
cnnConvArray_2xIn_4xOut_2_2
cnnConvArray_2xIn_4xOut_1_3
cnnConvArray_2xIn_4xOut_1_4
cnnConvArray_2xIn_8xOut_1_1
cnnConvArray_2xIn_8xOut_2_1
cnnConvArray_2xIn_8xOut_3_1
cnnConvArray_2xIn_8xOut_4_1
cnnConvArray_2xIn_8xOut_1_2
cnnConvArray_2xIn_8xOut_2_2
cnnConvArray_2xIn_8xOut_1_3
cnnConvArray_2xIn_8xOut_1_4
cnnConvArray_2xIn_16xOut_1_1
cnnConvArray_2xIn_16xOut_2_1
cnnConvArray_2xIn_16xOut_3_1
cnnConvArray_2xIn_16xOut_4_1
cnnConvArray_2xIn_16xOut_1_2
cnnConvArray_2xIn_16xOut_2_2
cnnConvArray_2xIn_16xOut_1_3
cnnConvArray_2xIn_16xOut_1_4
cnnConvArray_3xIn_4xOut_1_1
cnnConvArray_3xIn_4xOut_2_1
cnnConvArray_3xIn_4xOut_3_1
cnnConvArray_3xIn_4xOut_4_1
cnnConvArray_3xIn_4xOut_1_2
cnnConvArray_3xIn_4xOut_2_2
cnnConvArray_3xIn_4xOut_1_3
cnnConvArray_3xIn_4xOut_1_4
cnnConvArray_3xIn_8xOut_1_1
cnnConvArray_3xIn_8xOut_2_1
cnnConvArray_3xIn_8xOut_3_1
cnnConvArray_3xIn_8xOut_4_1
cnnConvArray_3xIn_8xOut_1_2
cnnConvArray_3xIn_8xOut_2_2
cnnConvArray_3xIn_8xOut_1_3
cnnConvArray_3xIn_8xOut_1_4
cnnConvArray_3xIn_16xOut_1_1
cnnConvArray_3xIn_16xOut_2_1
cnnConvArray_3xIn_16xOut_3_1
cnnConvArray_3xIn_16xOut_4_1
cnnConvArray_3xIn_16xOut_1_2
cnnConvArray_3xIn_16xOut_2_2
cnnConvArray_3xIn_16xOut_1_3
cnnConvArray_3xIn_16xOut_1_4
cnnConvArray_4xIn_4xOut_1_1
cnnConvArray_4xIn_4xOut_2_1
cnnConvArray_4xIn_4xOut_3_1
cnnConvArray_4xIn_4xOut_4_1
cnnConvArray_4xIn_4xOut_1_2
cnnConvArray_4xIn_4xOut_2_2
cnnConvArray_4xIn_4xOut_1_3
cnnConvArray_4xIn_4xOut_1_4
cnnConvArray_4xIn_8xOut_1_1
cnnConvArray_4xIn_8xOut_2_1
cnnConvArray_4xIn_8xOut_3_1
cnnConvArray_4xIn_8xOut_4_1
cnnConvArray_4xIn_8xOut_1_2
cnnConvArray_4xIn_8xOut_2_2
cnnConvArray_4xIn_8xOut_1_3
cnnConvArray_4xIn_8xOut_1_4
cnnConvArray_4xIn_16xOut_1_1
cnnConvArray_4xIn_16xOut_2_1
cnnConvArray_4xIn_16xOut_3_1
cnnConvArray_4xIn_16xOut_4_1
cnnConvArray_4xIn_16xOut_1_2
cnnConvArray_4xIn_16xOut_2_2
cnnConvArray_4xIn_16xOut_1_3
cnnConvArray_4xIn_16xOut_1_4
cnnConvArray_8xIn_4xOut_1_1
cnnConvArray_8xIn_4xOut_2_1
cnnConvArray_8xIn_4xOut_3_1
cnnConvArray_8xIn_4xOut_4_1
cnnConvArray_8xIn_4xOut_1_2
cnnConvArray_8xIn_4xOut_2_2
cnnConvArray_8xIn_4xOut_1_3
cnnConvArray_8xIn_4xOut_1_4
cnnConvArray_8xIn_8xOut_1_1
cnnConvArray_8xIn_8xOut_2_1
cnnConvArray_8xIn_8xOut_3_1
cnnConvArray_8xIn_8xOut_4_1
cnnConvArray_8xIn_8xOut_1_2
cnnConvArray_8xIn_8xOut_2_2
cnnConvArray_8xIn_8xOut_1_3
cnnConvArray_8xIn_8xOut_1_4
cnnConvArray_8xIn_16xOut_1_1
cnnConvArray_8xIn_16xOut_2_1
cnnConvArray_8xIn_16xOut_3_1
cnnConvArray_8xIn_16xOut_4_1
cnnConvArray_8xIn_16xOut_1_2
cnnConvArray_8xIn_16xOut_2_2
cnnConvArray_8xIn_16xOut_1_3
cnnConvArray_8xIn_16xOut_1_4
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNormalizationGradient.mm
alpha:          %f
beta:           %f
delta:          %f
p0:             %f
pm:             %f
ps:             %f
cross_channel_normalization_gradient
cross_channel_normalization_gradient_array
local_contrast_normalization_gradient
local_contrast_normalization_gradient_array
spatial_normalization_gradient
spatial_normalization_gradient_array
MPSCNNCrossChannelNormalizationGradient.kernelSize
MPSCNNCrossChannelNormalizationGradient.alpha
MPSCNNCrossChannelNormalizationGradient.beta
MPSCNNCrossChannelNormalizationGradient.delta
[%@ encode...] info->primaryOffset.z != 0 not supported
[%@ encode...] info->primaryOffset.z == info->secondaryOffset.z failed
[%@ encode...] info->clipRect.origin.z != 0 not supported
MPSCNNSpatialNormalizationGradient.alpha
MPSCNNSpatialNormalizationGradient.beta
MPSCNNSpatialNormalizationGradient.delta
[%@ encode...] not enough source images:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough destination images:  offset.z + clipRect.size.depth > destinationImage.numberOfImages
MPSCNNLocalContrastNormalizationGradient.alpha
MPSCNNLocalContrastNormalizationGradient.beta
MPSCNNLocalContrastNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.p0
MPSCNNLocalContrastNormalizationGradient.pm
MPSCNNLocalContrastNormalizationGradient.ps
[%@ initWithSource:labels:lossDescriptor:] descriptor may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSNNLossNode.mm
[%@ gradientFilterWithSources:] Error: the MPSNNLoss filter doesn't have a corresponding loss gradient filter.
It produces the gradient directly as its MPSImage destination and consequently acts as its own gradient filter.
Error: loss nodes do not have a separate gradient pass. The gradient image must either be nil or lossNode.resultImage.
[%@ gradientFilterWithSources:] Error: the MPSNNInitialGradient filter doesn't have a corresponding gradient filter.
Error: the MPSNNInitialGradient filter doesn't have a corresponding gradient filter.
Internal error: The Loss filter needs loss information. The loss labels are missing. 
[%@ cnnLossDataDescriptorWithData:layout:size:...] invalid data layout type (%lu)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNLoss.mm
layout: %s
size: {%lu, %lu, %lu}
bytesPerRow: %lu
bytesPerImage: %lu
[%@ setLabelSmoothing...] labelSmoothing must be in the range [0.0f, 1.0f]
[%@ setLabelSmoothing...] labelSmoothing parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy, MPSCNNLossTypeSigmoidCrossEntropy
[%@ setNumberOfClasses...] number of classes must be greater than 0
[%@ setNumberOfClasses...] number of classes parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy
[%@ setEpsion...] epsilon parameter is valid only for the following loss type(s): MPSCNNLossTypeLog
[%@ setDelta...] delta parameter is valid only for the following loss type(s): MPSCNNLossTypeHuber
[%@ cnnLossDescriptorWithType:reductionType:...] invalid loss type (%lu)
[%@ cnnLossDescriptorWithType:reductionType:...] invalid reduction type (%lu)
lossType: %d
reductionType: %d across batches: %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
Method unavailable. Use one of the available interfaces instead.
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] lossImageSize dimensions must be > 1
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels must be valid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= labels.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weightsDescriptor is specified, but the weights data is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) must match the size of labels data ({%lu, %lu, %lu})
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= weights.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
Cannot directly initialize MPSCNNLoss. Use initWithDevice:lossDescriptor: instead.
invalid loss type (%lu)
invalid reduction type (%lu)
lossType: %d
reductionType: %d, across batches = %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
_weight = %f
_labelSmoothing = %f
_epsilon = %f
_delta = %f
lossType: %d
reductionType: %d, across batch = %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
lossType: %d
reductionType: %d, across batch: %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
MPSDataLayoutHeightxWidthxFeatureChannels
MPSDataLayoutFeatureChannelsxHeightxWidth
Invalid data layout type
MPSCNNLossLossType
MPSCNNLossReductionType
MPSCNNLossReduceAcrossBatches
MPSCNNLossWeight
MPSCNNLossLabelSmoothing
MPSCNNLossNumberOfClasses
MPSCNNLossEpsilon
MPSCNNLossDelta
nil != [stateLabels labelsImage], user must pass a labels image through state to calculate loss
nil != sourceImage[0]
nil != stateLabels, user must pass a labels state to calculate loss
nil != srcImage[bIdx]
nil != [stateLabels weightsImage], user must pass a weights image if first weights image is passed
[%@ encode...] number of non-zero weights cannot be 0 for reduction type MPSCNNReductionTypeSumByNonZeroWeights
gridWidth != [stateLabels labelsImage].width, the labels in state must be the same dimension as input image
gridHeight == [stateLabels labelsImage].height, the labels in state must be the same dimension as input image
((info->src.image.featureChannels) + 3) / 4) == (([stateLabels labelsImage].featureChannels + 3) / 4), the labels in state must be the same dimension as input image
LossBatch
LossFinalizeBatch
LossFinalizeAcrossBatch
countNonZeroes
finalizeCountNonZeroes
MPSCNNGram_hasPropertyCallback
MPSCNNGram_propertyCallback
MPSNNLossGradientComputeLabelGradients
LossBatchFwd
LossBatchGradient
Cannot directly initialize MPSCNNUpsamplingGradient. Use one of the sub-classes of MPSCNNUpsamplingGradient.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNUpsamplingGradient.mm
MPSCNNUpsamplingGradient.filterType
MPSCNNUpsamplingGradient.scaleFactorX
MPSCNNUpsamplingGradient.scaleFactorY
MPSCNNUpsamplingGradient_general
[%@ encode...] filter initialized with no feature channels.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNGroupNormalization.mm
[%@ encode...] filter: numberOfFeatureChannels must be divisible by numOfGroups.
Cannot create state for images containing multiple images.
data source: %p %@
epsilon: %g
numberOfGroups: %d
[%@ gradientForGamma] Gradient state does not contain a buffer for gamma gradient values.
[%@ gradientForBeta] Gradient state does not contain a buffer for beta gradient values.
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
group normalization filter: %@
feature channels: %lu
feature channels: %lu
epsilon: %g
imageGroupNormalizationThreadgroupSum
imageGroupNormalizationImageSum
imageGroupNormalization
[%@ encode...] filter initialized with %lu feature channels but destination (after offset) contains only %lu feature channels.
[%@ encode...] filter initialized with %lu feature channels but source (after offset) contains only %lu feature channels.
reduceFeatureChannelsIntoGroups
kMPSCNNGroupNormalization.s
kMPSCNNGroupNormalization.o
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNPermute.mm
[%@ %@] Permutations involving channel and image dimension not supported on this device.
MPSPermute3
MPSNNPermuteDimensionOrder0
MPSNNPermuteDimensionOrder1
MPSNNPermuteDimensionOrder2
MPSNNPermuteDimensionOrder3
MPSBatchTranspose
parent filter: %p
format:          %d
handle:          <%p> %@
                 %@
allocator:       %p
exportFromGraph: %s
synchronize:     %s
stopGradient:    %s
parent filter: %p
handle: <%p> %@
synchronize: %s
        %@
[%@ initWithSourceImages...] sourceImages may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNGraphNodes.mm
[%@ initWithSourceImages...] sourceImages.count may not be 0
[%@ initWithSourceImages...] sourceStates.count may not be 0
[%@ %@] Error: the source filter that produces the source image %p apparently has been released and no longer exists.
Consequently, you wont be able to construct a graph to produce this image. The graph of nodes will not be usable.
This is a common mistake. The result image doesn't retain its parent. That would cause a reference cycle.
Your application needs to keep the parent filter around so that the result image sticks around, until after
some other filter is initialized to consume the result image. The consuming filter will retain the parent filter
of the intermediate image, so that all you need to keep a reference for is the last filter in the chain.
Image:
(parent filter no longer available, so can't be reported here.)
Note: To prevent graph propagation beyond an image node, see -stopGradient.
[%@ %@] Error: the source filter that produces the source state %p apparently has been released and no longer exists.
Consequently, you wont be able to construct a graph to produce this state. The graph of nodes will not be usable.
This is a common mistake. The result state doesn't retain its parent. That would cause a reference cycle.
Your application needs to keep the parent filter around so that the result state sticks around, until after
some other filter is initialized to consume the result state. The consuming filter will retain the parent filter
of the intermediate image, so that all you need to keep a reference for is the last filter in the chain.
State:
(parent filter no longer available, so can't be reported here.)
%@, %p
%@ "%@"
source images:  %@
source states:  %@
resultImage:    %p
result states:  %@
padding policy: 
<no label>
[%@ newFilterNode] Internal error: child class fails to override this method.
[%@ gradientFilterWithSources:] This is not a unary filter. Please use gradientFiltersWithSources: (extra 's') instead. 
[%@ gradientFilterWithSources:] Internal error: this isn't a unary filter and needs to override this method to return multiple filters
gradient for %p "%@" (%@)
gradient for %p (%@)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNSlice.mm
Source Index: %lu
Error: EncodeSlice() encountered caller of wrong class type
Insufficient number of feature channels in destination %p
slice_along_width_height
slice_along_feature_channels
MPSNNConcatenationGradient.sourceIndex
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalization.mm
data source: %p %@
epsilon: %g
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
instance normalization filter: %@
feature channels: %lu
epsilon: %g
imageInstanceNormalizationThreadgroupSum
imageInstanceNormalizationImageSum
imageInstanceNormalization
kMPSCNNInstanceNormalization.s
kMPSCNNInstanceNormalization.o
resize width (%lu) must be > 0
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNCropAndResize.mm
resize height (%lu) must be > 0
Number of regions (%lu) must be > 0
regions argument cannot be a nil value
MPSRegion origin.z must be 0
MPSRegion size.depth must be 0
[%s initWithCoder:device:] failed. Regions array size mismatch
CropAndResizeBilinearOperation
crop_and_resize_bilinear_tex2d_tex2d
crop_and_resize_bilinear_tex2d_tex2darray
crop_and_resize_bilinear_tex2d_tex2d_float32
crop_and_resize_bilinear_tex2d_tex2darray_float32
MPSNNCropAndResizeBilinear.resizeWidth
MPSNNCropAndResizeBilinear.resizeHeight
MPSNNCropAndResizeBilinear.numberOfRegions
MPSNNCropAndResizeBilinear.regions
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNPooling.mm
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
dilationRateX (%lu) must be > 0
dilationRateY (%lu) must be > 0
dilationRateX: %lu
dilationRateY: %lu
MPSCNNPooling.kernelWidth
MPSCNNPooling.kernelHeight
MPSCNNPooling.strideX
MPSCNNPooling.strideY
[%@ encode...] unsupported feature channels layout (MPSImageFeatureChannelsInterleavedPerPixel)
MPSCNNPooling_horizontal_tex2d_tex2d_max
MPSCNNPooling_horizontal_tex2darray_tex2darray_max
MPSCNNPooling_horizontal2_tex2d_tex2d_max
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max
MPSCNNPooling_vertical_tex2d_tex2d_max
MPSCNNPooling_vertical_tex2darray_tex2darray_max
MPSCNNPooling_2x2_tex2d_tex2d_max
MPSCNNPooling_2x2_tex2darray_tex2darray_max
MPSCNNPooling_3x3_tex2d_tex2d_max
MPSCNNPooling_3x3_tex2darray_tex2darray_max
MPSCNNPooling_new_tex2d_tex2d_max_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_new_tex2d_tex2d_max_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_vertical_tex2d_tex2d_max_swEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_2x2_tex2d_tex2d_max_swEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_3x3_tex2d_tex2d_max_swEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg
MPSCNNPooling_horizontal2_tex2d_tex2d_avg
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg
MPSCNNPooling_vertical_tex2d_tex2d_avg
MPSCNNPooling_vertical_tex2darray_tex2darray_avg
MPSCNNPooling_2x2_tex2d_tex2d_avg
MPSCNNPooling_2x2_tex2darray_tex2darray_avg
MPSCNNPooling_3x3_tex2d_tex2d_avg
MPSCNNPooling_3x3_tex2darray_tex2darray_avg
MPSCNNPooling_new_tex2d_tex2d_avg_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_vertical_tex2d_tex2d_avg_shEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_2x2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_3x3_tex2d_tex2d_avg_shEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_2
cnnPoolingGeneric
cnnPoolingGeneric_ppt2
MPSCNNPooling.padSizeX
MPSCNNPooling.padSizeY
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationGradient.mm
imageBatchNormalizationGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBinaryKernel.mm
<NULL>
primaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld  len: %ld}
secondaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destChannelOffset{%ld} 
device:        %p
primary edge mode:     %s
secondary edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
2nd KernelSize: {%lu x %lu}
primary stride:      {%lu x %lu}
secondary stride:      {%lu x %lu}
dilation rate:        {%lu x %lu}
2nd dilation rate:    {%lu x %lu}
backwards?  %s
broadcasting?  %s
padding:       %@
MPSImageEdgeModeClamp
MPSImageEdgeModeZero
destinationFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelOffset must be multiple of 4
secondarySourceFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelMaxCount must be multiple of 4
secondarySourceFeatureChannelMaxCount must be multiple of 4
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  primary source image is a temporary image with readCount of 0.
Backing texture for primary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  secondary source image is a temporary image with readCount of 0.
Backing texture for secondary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  destination image is a temporary image with readCount of 0.
Backing texture for destination image is no longer valid. image=%p
Feature Channel Layout of primary source and destination does not match
Feature Channel Layout of secondary source and destination does not match
Primary source %p texture type (%lu) is unsupported
Secondary source %p texture type (%lu) is unsupported
Primary source %p texture format %lu must support filtering.
Secondary source %p texture format %lu must support filtering.
Primary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Secondary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Primary source MTLTextureType2D must have primaryOffset.z = 0
Primary source MTLTextureType2D must have clipRect.size.depth = 1
Primary source MTLTextureTypeArray2D must have 0 <= primaryOffset.z < primaryImage.numberOfImages
Primary source MTLTextureTypeArray2D must have clipRect.size.depth such that _primaryOffset.z + clipRect.depth < primaryImage.numberOfImages
Secondary source MTLTextureType2D must have secondaryOffset.z = 0
Secondary source MTLTextureType2D must have clipRect.size.depth = 1
Secondary source MTLTextureTypeArray2D must have 0 <= secondaryOffset.z < secondaryImage.numberOfImages
Secondary source MTLTextureTypeArray2D must have clipRect.size.depth such that _secondaryOffset.z + clipRect.depth < secondaryImage.numberOfImages
Destination %p texture type (%lu) is unsupported
Destination %p texture format %lu  must be writable.
Destination %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Destination MTLTextureType2D must have clipRect.origin.z = 0
Destination MTLTextureType2D must have clipRect.size.depth = 1
Destination MTLTextureTypeArray2D must have 0 <= clipRect.origin.z < dest.numberOfImages
Destination MTLTextureTypeArray2D must have clipRect.size.depth such that clipRect.origin.z + clipRect.depth < dest.numberOfImages
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of primary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of secondary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture.  Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of primary source
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of secondary source
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of destination
[%@ encode...] primary source may not be nil
[%@ encode...] secondary source may not be nil
[%@ %@] Error: the primary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the primary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the secondary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the secondary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the destination image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ batchEncode...] out of memory: unable to allocate storage to hold encode arguments on device.
[%@ encode...] the primary offset.z may not be negative
[%@ encode...] the secondary offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > primaryImages.count(%lu)
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > secondaryImages.count(%lu)
[%@ encode...] each of the individual primary source images in a batch must have numberOfImages = 1
[%@ encode...] each of the individual secondary source images in a batch must have numberOfImages = 1
[%@ encode...] error: all primary source image sizes must match
[%@ encode...] error: all secondary source image sizes must match
[%@ encode...] error: all primary source number of feature channels must match
[%@ encode...] error: all secondary source number of feature channels must match
[%@ %@] Error: the primary source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ %@] Error: the secondaryImage source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ encode...] each of the individual destination images in a batch must have numberOfImages = 1
[%@ encode...] error: all destination image sizes must match
[%@ encode...] error: all destination number of feature channels must match
[%@ destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset] Error:
 This is a binary filter. sourceImages should be an array of at least length 2.
%@: Error for filters that support broadcasting the input source image widths must match (or be 1)
%@: Error for filters that support broadcasting the input source image heights must match (or be 1)
%@: Error for filters that support broadcasting the input source image count must match (or be 1)
%@: Error for filters that support broadcasting the number of input source image feature channels must match (or be 1)
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch count is smaller than the primaryImage batch count
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
Internal error: [%@ encodeWithCoder:] unavailable
MPSCNNBinaryKernel.primaryOffset.x
MPSCNNBinaryKernel.primaryOffset.y
MPSCNNBinaryKernel.primaryOffset.z
MPSCNNBinaryKernel.secondaryOffset.x
MPSCNNBinaryKernel.secondaryOffset.y
MPSCNNBinaryKernel.secondaryOffset.z
MPSCNNBinaryKernel.clipRect.origin.x
MPSCNNBinaryKernel.clipRect.origin.y
MPSCNNBinaryKernel.clipRect.origin.z
MPSCNNBinaryKernel.clipRect.size.width
MPSCNNBinaryKernel.clipRect.size.height
MPSCNNBinaryKernel.clipRect.size.depth
MPSCNNBinaryKernel.destinationFeatureChannelOffset
MPSCNNBinaryKernel.sourceFeatureChannelOffset1
MPSCNNBinaryKernel.sourceFeatureChannelOffset2
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount1
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount2
MPSCNNBinaryKernel.primaryEdgeMode
MPSCNNBinaryKernel.secondaryEdgeMode
MPSCNNBinaryKernel.checkFlags
MPSCNNBinaryKernel.kernelWidth
MPSCNNBinaryKernel.kernelHeight
MPSCNNBinaryKernel.secondaryKernelWidth
MPSCNNBinaryKernel.secondaryKernelHeight
MPSCNNBinaryKernel.primaryStride.x
MPSCNNBinaryKernel.primaryStride.y
MPSCNNBinaryKernel.secondaryStride.x
MPSCNNBinaryKernel.secondaryStride.y
MPSCNNBinaryKernel.dilationRate.x
MPSCNNBinaryKernel.dilationRate.y
MPSCNNBinaryKernel.secondaryDilationRate.x
MPSCNNBinaryKernel.secondaryDilationRate.y
MPSCNNBinaryKernel.isBackward
MPSCNNBinaryKernel.supportsBroadcasting
MPSCNNBinaryKernel.data
MPSCNNBinaryKernel.padding
MPSCNNBinaryKernel.data2
MPSCNNBinaryKernel.allocator
MPSCNNBinaryImageFilter.className
MPSCNNBinaryImageFilter.class
Error: attempted to extract gamma buffer from temporary MPSState with readCount of 0.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationState.mm
Error: attempted to extract beta buffer from temporary MPSState with readCount of 0.
Error: attempted to extract mean buffer from temporary MPSState with readCount of 0.
Error: attempted to extract variance buffer from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForGamma from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForBeta from temporary MPSState with readCount of 0.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNResize.mm
ResizeBilinearOperation
resize_bilinear_tex2d_tex2d
resize_bilinear_tex2darray_tex2darray
resize_bilinear_tex2d_tex2d_float32
resize_bilinear_tex2darray_tex2darray_float32
MPSNNResizeBilinear.resizeWidth
MPSNNResizeBilinear.resizeHeight
MPSNNResizeBilinear.alignCorners
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNDropoutNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNDropoutNodes.mm
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNGroupNormalizationGradient.mm
imageGroupNormalizationThreadgroupDot
imageGroupNormalizationImageDot
imageGroupNormalizationGradient
reduceFeatureChannelsIntoGroupsDot
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid neuron type (%lu)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNeuron.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid initialization method for the following neuron type(s): MPSCNNNeuronPReLU
[%@ cnnNeuronPReLUDescriptorWithData:...] data must be valid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid (not a multiple of sizeof(float))
neuronType: %s
a: %f 
b: %f 
c: %f 
data: %p
neuronType: %s
a: %f 
b: %f
neuronType: %s
a: %f 
b: %f 
c: %f
invalid neuron type (%lu)
[%@ initWithDevice:neuronDescriptor:...] data in neuron descriptor must be valid
[%@ initWithDevice:neuronDescriptor:...] data length (%lu) is invalid
Cannot directly initialize MPSCNNNeuron. Use initWithDevice:neuronDescriptor: or one of the sub-classes of MPSCNNNeuron
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation. See the requirements listed for the newBufferWithBytesNoCopy:length:options:deallocator Metal API.
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation
v24@?0^v8Q16
MPSCNNNeuronTypeNone  (f(x) = x)
MPSCNNNeuronTypeReLU  (f(x) = x >= 0 ? x : a * x)
MPSCNNNeuronTypeLinear  (f(x) = a * x + b)
MPSCNNNeuronTypeSigmoid  (f(x) = 1 / (1 + e^-x))
MPSCNNNeuronTypeHardSigmoid  (f(x) = clamp((x * a) + b, 0, 1))
MPSCNNNeuronTypeTanH    (f(x) = a * tanh(b * x))
MPSCNNNeuronTypeAbsolute  (f(x) = fabs(x))
MPSCNNNeuronTypeSoftPlus  (f(x) = a * log(1 + e^(b * x)))
MPSCNNNeuronTypeSoftSign  (f(x) = x / (1 + abs(x)))
MPSCNNNeuronTypeELU   (f(x) = x >= 0 ? x : a * (exp(x) - 1))
MPSCNNNeuronTypePReLU  (f(x[i]) = x[i] >= 0 ? x[i] : a[i] * x[i]), i in [0,featureChannels-1]
MPSCNNNeuronTypeReLUN  (f(x) = min((x >= 0 ? x : a * x), b))
MPSCNNNeuronTypePower  (f(x) = (a * x + b) ^ c)
MPSCNNNeuronTypeExponential  (f(x) = c ^ (a * x + b))
MPSCNNNeuronTypeLogarithm  (f(x) = log_c(a * x + b))
MPSCNNNeuronTypeGeLU  (f(x) = (1.0 + erf(x * sqrt(0.5))) * 0.5 * x)
<invalid/missing type>
neuronType: %s
a: %f
b: %f
c: %f
data: %p
neuronType: %s
a: %f
b: %f
c: %f
neuronType: %s
a: %f
b: %f
Cannot call this initializer on this class.
MPSNNNeuronDescriptor.A
MPSNNNeuronDescriptor.B
MPSNNNeuronDescriptor.C
MPSNNNeuronDescriptor.neuronType
MPSNNNeuronDescriptor.PReLuData
MPSNNNeuronDescriptor.PReLuCount
MPSCNNNeuronTypeName
MPSCNNNeuronA
MPSCNNNeuronB
MPSCNNNeuronC
MPSCNNNeuronAArrayIsNil
MPSCNNNeuronAArrayLength
MPSCNNNeuronAArray
cnnNeuronGradient
cnnNeuron
MPSCNNNeuronGradientTypeName
MPSCNNNeuronGradientA
MPSCNNNeuronGradientB
MPSCNNNeuronGradientC
MPSCNNNeuronGradientAArrayIsNil
MPSCNNNeuronGradientAArrayLength
MPSCNNNeuronGradientAArray
alpha = %f
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNGramMatrix.mm
alpha: %f
MPSCNNGram_alpha
Cannot directly initialize MPSNNReduceUnary. Use one of the sub-classes of MPSNNReduceUnary.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNReduce.mm
ReduceOperation: %lu
Cannot directly initialize MPSNNReduceBinary. Use one of the sub-classes of MPSNNReduce.
reduce_min_row_simd_rgba
reduce_min_column_simd_rgba
reduce_min_feature_channels_simd_rgba
reduce_argument_min_feature_channels_simd_rgba_uint
reduce_argument_min_feature_channels_simd_rgba_float
reduce_max_row_simd_rgba
reduce_max_column_simd_rgba
reduce_max_feature_channels_simd_rgba
reduce_argument_max_feature_channels_simd_rgba_uint
reduce_argument_max_feature_channels_simd_rgba_float
reduce_mean_row_simd_rgba
reduce_mean_column_simd_rgba
reduce_mean_feature_channels_simd_rgba
reduce_mean_feature_channels_and_weight_simd_rgba
reduce_array_min_row_simd_rgba
reduce_array_min_column_simd_rgba
reduce_array_min_feature_channels_simd_rgba
reduce_array_argument_min_feature_channels_simd_rgba_uint
reduce_array_argument_min_feature_channels_simd_rgba_float
reduce_array_max_row_simd_rgba
reduce_array_max_column_simd_rgba
reduce_array_max_feature_channels_simd_rgba
reduce_array_argument_max_feature_channels_simd_rgba_uint
reduce_array_argument_max_feature_channels_simd_rgba_float
reduce_array_mean_row_simd_rgba
reduce_array_mean_column_simd_rgba
reduce_array_mean_feature_channels_simd_rgba
reduce_array_mean_feature_channels_and_weight_simd_rgba
reduce_local_correlation
reduce_min_row_quadshuffle_rgba
reduce_min_column_quadshuffle_rgba
reduce_max_row_quadshuffle_rgba
reduce_max_column_quadshuffle_rgba
reduce_mean_row_quadshuffle_rgba
reduce_mean_column_quadshuffle_rgba
reduce_array_min_row_quadshuffle_rgba
reduce_array_min_column_quadshuffle_rgba
reduce_array_min_feature_channels_quadshuffle_rgba
reduce_array_argument_min_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_min_feature_channels_quadshuffle_rgba_float
reduce_array_max_row_quadshuffle_rgba
reduce_array_max_column_quadshuffle_rgba
reduce_array_max_feature_channels_quadshuffle_rgba
reduce_array_argument_max_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_max_feature_channels_quadshuffle_rgba_float
reduce_array_mean_row_quadshuffle_rgba
reduce_array_mean_column_quadshuffle_rgba
reduce_array_mean_feature_channels_quadshuffle_rgba
reduce_array_mean_feature_channels_and_weight_quadshuffle_rgba
MPSNNReduce.clipRectSource.origin.x
MPSNNReduce.clipRectSource.origin.y
MPSNNReduce.clipRectSource.origin.z
MPSNNReduce.clipRectSource.size.width
MPSNNReduce.clipRectSource.size.height
MPSNNReduce.clipRectSource.size.depth
MPSNNReduce.reduceOp
MPSNNReduce.weight
[%@ encode...] filter cannot have stride 0 in either dimension.
MPSNNReduce.primarySourceClipRect.origin.x
MPSNNReduce.primarySourceClipRect.origin.y
MPSNNReduce.primarySourceClipRect.origin.z
MPSNNReduce.primarySourceClipRect.size.width
MPSNNReduce.primarySourceClipRect.size.height
MPSNNReduce.primarySourceClipRect.size.depth
MPSNNReduce.secondarySourceClipRect.origin.x
MPSNNReduce.secondarySourceClipRect.origin.y
MPSNNReduce.secondarySourceClipRect.origin.z
MPSNNReduce.secondarySourceClipRect.size.width
MPSNNReduce.secondarySourceClipRect.size.height
MPSNNReduce.secondarySourceClipRect.size.depth
MPSNNReduce.windowInX
MPSNNReduce.windowInY
MPSNNReduce.strideInX
MPSNNReduce.strideInY
[<MPSCNNConvolutionDataSource> initWithSource:neuronInfo:batchNorm] Internal error: attempted to overwrite a convolution data source descriptor batch norm info with another set of batch norm info.
These should not be coalesced.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/BackwardsCompatibility.mm
rangesForUInt8Kernel
rangesForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method 
lookupTableForUInt8Kernel
lookupTableForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method
MPSWeightsWrapper_SecureCoding.c0
MPSWeightsWrapper_SecureCoding.o0
MPSWeightsWrapper_SecureCoding.c1
MPSWeightsWrapper_SecureCoding.o1
MPSWeightsWrapper_SecureCoding.c2
MPSWeightsWrapper_SecureCoding.o2
MPSWeightsWrapper_SecureCoding.it
MPSWeightsWrapper_SecureCoding.ia
MPSWeightsWrapper_SecureCoding.ib
MPSWeightsWrapper_SecureCoding.ic
MPSWeightsWrapper_SecureCoding.id
Error: expected secure coding support from object: 
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNKernel.mm
offset:        {%ld,%ld,%ld} sourceFeatureChannelRange{offset: %ld, len: %lu}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destinationFeatureChannelOffset{%ld} 
device:        %p
edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
stride:        {%lu x %lu}
dilation factor {%lu x %lu}
backwards?  %s
destinationImageAllocator: %@
padding:       %@
sourceFeatureChannelOffset must be multiple of 4
setSourceFeatureChannelMaxCount must be multiple of 4
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: sourceImage batch may not be NULL
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
Feature Channel Layout of source and destination does not match
Source %p texture type (%lu) is unsupported
Source %p texture format %lu  must support filtering.
Source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Source MTLTextureType2D must have offset.z = 0
Source MTLTextureType2D must have clipRect.size.depth = 1
Source MTLTextureTypeArray2D must have 0 <= offset.z < source.numberOfImages
Source MTLTextureTypeArray2D must have clipRect.size.depth such that _offset.z + clipRect.depth < source.numberOfImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: the filter edge mode must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: The number of source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for source image must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of source
[%@ encode...] Error: an error (%s) was encountered preventing this kernel from encoding.
[%@ encode...] Error: commandBuffer may not be nil]
[%@ encode...] Error: source may not be nil
[%@ encode...] Error: destination may not be nil
[%@ encode...] Error: options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ encode...] Error: source feature channel offset (%lu) is too large to fit in the source image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) is too large to fit in the destination image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) must be divisible by 4.
Other values would require read-modify-write on individual texels which is not supported by some hardware and a problem for concurrent operation everywhere.
[%@ encode...]: Error: non-zero source feature channel offset unsupported for compound MPSImages. Use a MPSImageBatch instead.
[%@ %@] Error: the source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ encode...] the offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ encode...] Error invalid operation: offset.z(%d) < 0
[%@ encode...] Error invalid operation: the offset.z.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ encode...] each of the individual source images in a batch must have numberOfImages = 1
[%@ encode...] error: all source image sizes must match
[%@ encode...] error: all source number of feature channels must match
[%@ %@] Error: the source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
%s | %s | %s%s%s
%s, %s, %s%s%s
[MPSNNDefaultPadding paddingWithMethod:]: Can not create a new object with a custom sizing policy.
You must implement your own object using the MPSNNPadding Policy.
MPSCreatePaddingPolicy(): invalid / unknown bits in MPSNNPaddingMethod.
Error: overrelease of MPS owned MPSNNDefaultPadding object:
  %@
%@  variant: %@
MPSCNNKernel.offset.x
MPSCNNKernel.offset.y
MPSCNNKernel.offset.z
MPSCNNKernel.clipRect.origin.x
MPSCNNKernel.clipRect.origin.y
MPSCNNKernel.clipRect.origin.z
MPSCNNKernel.clipRect.size.width
MPSCNNKernel.clipRect.size.height
MPSCNNKernel.clipRect.size.depth
MPSCNNKernel.destinationFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelMaxCount
MPSCNNKernel.edgeMode
MPSCNNKernel.checkFlags
MPSCNNKernel.kernelWidth
MPSCNNKernel.kernelHeight
MPSCNNKernel.stride.x
MPSCNNKernel.stride.y
MPSCNNKernel.dilation.x
MPSCNNKernel.dilation.y
MPSCNNKernel.isBackward
MPSCNNKernel.data
MPSCNNKernel.padding
MPSCNNKernel.data2
MPSCNNKernel.allocator
[%@ resource] Internal error: unhandled resource type
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSStateInternal.h
SizeValidOnly
SizeSame
SizeFull
Size_reserved
AlignCentered
AlignTopLeft
AlignBottomRight
Align_reserved
AddRemainderToTopLeft
AddRemainderToTopRight
AddRemainderToBottomLeft
AddRemainderToBottomRight
MPSNNPaddingMethod.CustomAllowForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.Custom (inhibits node fusion)
MPSNNPaddingMethod.Custom (allow for node fusion)
MPSNNPaddingMethod.ExcludeEdges
MPSNNPaddingMethod.ExcludeEdges | CustomAllowForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.ExcludeEdges | Custom (inhibits node fusion)MPSNNPaddingMethod.ExcludeEdges | Custom (allow for node fusion)
kMPSNNPaddingMethod_vers
kMPSNNPaddingMethod
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelWidth may not be 0
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNPoolingNodes.mm
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelHeight may not be 0
MPS internal error: Need to override newFilterNodeForDevice for %@
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelWidth may not be 0
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelHeight may not be 0
[%@ initWithGradientImages:forwardFilter:] Error forwardFilter %p is not a MPSCNNPoolingNode
[%@ initWithGradientImages:forwardFilter:] Error: the filter <%p> is not a MPSCNNDilatedPoolingMaxNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixNeuronGradient.mm
[%@ apply...] source gradient matrix may not be nil
Matrices/vectors contain batches, batching not supported.
Only bias gradient vector value types of MPSDataTypeFloat32 are supported.
MatrixNeuronGradient
MPSMatrixNeuronGradient._alpha;
MPSMatrixNeuronGradient._sourceNumberOfFeatureVectors;
MPSMatrixNeuronGradient._sourceInputFeatureChannels;
MPSMatrixNeuronGradient._neuronType;
MPSMatrixNeuronGradient._neuronA;
MPSMatrixNeuronGradient._neuronB;
MPSMatrixNeuronGradient._neuronC;
MPSMatrixNeuronGradient._perChannelNeuronA;
^v32@?0@"MPSKernel"8r^^v16^Q24
^v32@?0^{_NSZone=}8r^v16@"<MTLDevice>"24
Error: unable to read node data for %@ <%p>. File (or data chunk within file) too small.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/FilterNodeConstructors.mm
Error: unable to read node data for %@ <%p>. File version too new.
Error: unable to read node data for %@ <%p>. File version too old.
Error: unable to read node data for %@ <%p>. File could not be parsed.
Error: unable to read node data for %@ <%p>. Unhandled / unknown error %u.
MPSInternalError: Cant copy object with internal id out of bounds.
MPSInternalError: attempted to copy object type %lu but ended up with object type %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionA14.mm
v8@?0
MPS_DIRECTCONV_NODMA
cnnConvArrayGeneralA14
cnnConvArrayUpdateGeneralA14
cnnConvWinograd_2x2_3x3_32x32_256
cnnConvWinograd_2x2_3x3_32x16_256
cnnConvWinograd_2x2_3x3_16x32_256
cnnConvWinograd_2x2_3x3_16x16_128
cnnConvWinograd_2x2_3x3_32x32_256_linear
cnnConvWinograd_2x2_3x3_32x16_256_linear
cnnConvWinograd_8x8_3x3_32x32_256
cnnConvWinograd_8x8_3x3_32x32_256_half_intermediate
MPS_DISABLE_SIMDMATMUL
MPS_DIRECT_CONVOLUTION
[%@ %@] Error: method not available. Use -initWithDevice:sourceCount: instead.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNMultiaryKernel.mm
[%@ %@] Error: invalid index: %lu.  This filter has %lu sources.
MPSCNNMultiaryKernel.srcCount
MPSCNNMultiaryKernel.srcDataKeyv1
MPSCNNMultiaryKernel.isBackwards
MPSCNNMultiaryKernel.supportsBroadcasting
MPSCNNMultiaryKernel.clipRect.origin.x
MPSCNNMultiaryKernel.clipRect.origin.y
MPSCNNMultiaryKernel.clipRect.origin.z
MPSCNNMultiaryKernel.clipRect.size.x
MPSCNNMultiaryKernel.clipRect.size.y
MPSCNNMultiaryKernel.clipRect.size.z
MPSCNNMultiaryKernel.destinationFeatureChannelOffset
MPSCNNMultiaryKernel.paddingType
MPSCNNMultiaryKernel.paddingData
MPSCNNMultiaryKernel.allocatorType
MPSCNNMultiaryKernel.allocatorData
MPSCNNMultiaryKernel.checkFlags
[%@ %@] Error: private data missing or in future format. Unable to decode object.
[%@ %@] Error: unexpected data length found in file. Unable to decode object.
[%@ %@] commandBuffer may not be nil]
[%@ %@] source may not be nil
[%@ %@] destination may not be nil
[%@ %@] Error: destination may not be nil
[%@ %@] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ %@] the offset.z of source %lu may not be negative
[%@ %@]: the filter edge mode for source image must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ %@] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ %@] each of the individual source images in a batch must have numberOfImages = 1
[%@ %@] error: all source image sizes must match
[%@ %@:sourceStates:] Error: sourceImages may not be NULL
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNSoftMaxGradient.mm
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->secondarySrc.featureChannels - info->secondarySourceFeatureChannelOffset) failed
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) <=                    (info->dest.featureChannels) failed
softmax_gradient
softmax_gradient_array
softmax_gradient_multipass
softmax_gradient_multipass_array
log_softmax_gradient
log_softmax_gradient_array
log_softmax_gradient_multipass
log_softmax_gradient_multipass_array
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) <=                    (info->dest.featureChannels - destinationFeatureChannelOffset) failed
[%@ initWithSource:] Probable error: concatenate a image with nothing?
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNConcatenationNode.mm
{%lu x %lu x %lu}[%lu](offset:0)
"%@"
%s (%lu) [%s] -> {%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
%s (%lu) %lu*[%s] -> %lu*{%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the gradient state was not produced by a MPSNNConcatenationNode.
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the sourceImage provided was not among the input images to the MPSNNConcatenationNode
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNSpatialNormalizationNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNNormalizationNodes.mm
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNLocalContrastNormalizationNode
[%@ initWithSource:dataSource:] dataSource may not be NULL
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:instanceNormalizationState:
instance normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
Error: unable to do GPU group normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:groupNormalizationState:
group normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU group normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNBatchNormalizationNode
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
batch normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU batch normalization update pass because the data source doesn't implement -updateGammaAndBetaWithBatchNormalizationState:
Batch normalization node calculates statistics
Please initialize the %@ class with initWithDevice:weights:
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInnerProduct.mm
Number of groups for inner product should be 1
strideX for inner product should be 1
strideY for inner product should be 1
Please initialize the %@ class with initWithDevice:convolutionDescriptor:kernelWeights:biasTerms
initializer unavailable
strideX should be 1 for fully connected kernel
strideY should be 1 for fully connected kernel
dilationRateX should be 1 for fully connected kernel
dilationRateY should be 1 for fully connected kernel
Number of groups should be 1 fully connected kernel
Kernel width and src width must match for fully connected kernel
Kernel height and src height must match for fully connected kernel
clipRect width must be 1 for fully connected kernel
clipRect height must be 1 for fully connected kernel
[%@ initWithSource:convolutionDescriptor:kernelWeights:biasTerms]: kernel weights may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNConvolutionGraphNodes.mm
MPSGraph internal error: cant append filter after filter creation.
MPSGraph internal error: convolution filter node missing data source?
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: gradient state may not be nil
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState doesn't have a parent convolution with a dataSource.
There are no weights to use here and MPS can not continue.
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState creator isn't a convolution or convolution transpose node.
There are no weights to use here and MPS can not continue.
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNConvolutionNode
MPSNNTrainingStyleUpdateDeviceNone
MPSNNTrainingStyleUpdateDeviceCPU
MPSNNTrainingStyleUpdateDeviceGPU
MPSNNTrainingStyleUpdateDeviceAll
training style: %@
CNNConvolutionGradientFilterNode::InitFilter() Error: unexpectedly could not get a data source from the inference convolution node.
Can not continue...
Err: Unable to trigger -load on MPSCNNConvolutionDataSource: <%p>
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights must have a descriptor
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights.descriptor can not contain an integrated neuron.
A separate node must be built for neurons for training.
The graph will automatically integrate them later for inference.
Error while unpacking a convolution gradient node: a valid dataSource could not be found in either the gradient node or its partner convolution to initialize the convolution weights
Error: could not updates weights for convolution without a MPSCNNConvolutionDataSource to talk to.
Perhaps your data source doesn't conform to <NSSecureCoding> and couldn't be saved?
Perhaps you created the convolution gradient node with a nil data source and there is no matching convolution node that has a datasource?
Error: can not update data source "%@" on GPU, because it does not implement updateWeightasAndBiasesWithCommandBuffer:sourceState:gradientState:.
convolution gradient weight update pass: the gradients may not be in a temporary image for CPU update.
Find the state result from the forward convolution and set it to be .exportFromGraph = YES
Error: can not update data source "%@" on GPU, because it does not implement -updateWeightasAndBiasesWithCommandBuffer:sourceState:gradient:.
convolution gradient weight update pass: the weight gradients may not be in a temporary state for CPU update.
convolution gradient weight update pass: the weights may not be in a temporary state for CPU update.
%@.convolutionGradientState is an invalid operation.  The class doesn't support producing state.
%@.convolutionState is an invalid operation.  The class doesn't support producing state.
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionGradientState
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionTransposeGradientState
CNNConvolutionTransposeFilterNode::Encode(): MPSCNNConvolutionTransposeGradientState passed in mismatches with source MPSCNNConvolutionGradientState.
fused: %s,  a = %g b = %g c = %g
imageInitialSumBase
imageThreadgroupSumBase
Error: [%@ load] returned NO.  MPS can wait no longer for data and can not proceed.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/DataSourceWrappers.mm
Error: [%@ descriptor] returned nil.  MPS can wait no longer for data and can not proceed.
Error: [MPSCNNConvolutionDescriptor copyWithZone:] failed
Error: convolution data source over purged: 
aggregation container for %@ "%@"
aggregation container for %@ "%@"
convolution descriptor: %@batch norm data source: %@neuron descriptor:      %@
aggregation container for %@ "%@"
convolution descriptor: %@neuron descriptor:      %@
supportsSecureCoding
initWithCoder:
encodeWithCoder:
MPSConvolutionDataSourceWrapper.dataSource
MPSConvolutionDataSourceWrapper.c
MPSConvolutionDataSourceWrapper.batchNorm
MPSConvolutionDataSourceWrapper.b
MPSConvolutionDataSourceWrapper.neuron
MPSConvolutionDataSourceWrapper.n
Error: Can not encode convolution data source. It doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch norm descriptor doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch neuron doesn not conform to NSSSecureCoding.
lossXYDescriptor: 
lossWHDescriptor: 
lossConfidenceDescriptor: 
lossClassesDescriptor: 
reductionType = %d
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
%lu) (w, h) = (%f, %f)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNYOLOLoss.mm
_reductionType == lossDescriptor.XYLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.WHLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.confidenceLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.classesLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
lossXY: 
lossWH: 
lossConfidence: 
lossClasses: 
reductionType = %d, across batches = %s
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
MPSCNNYOLOLossReductionType
MPSCNNYOLOLossReduceAcrossBatch
MPSCNNYOLOLossNumberOfAnchorBoxes
kMPSCNNYOLOLoss_scaleXY_Key
kMPSCNNYOLOLoss_scaleWH_Key
kMPSCNNYOLOLoss_scaleNoObject_Key
kMPSCNNYOLOLoss_scaleObject_Key
kMPSCNNYOLOLoss_scaleClass_Key
kMPSCNNYOLOLoss_minIOUForObjectPresence_Key
kMPSCNNYOLOLoss_maxIOUForObjectAbsence_Key
kMPSCNNYOLOLoss_rescore_Key
%@.className
MPSCNNYOLOLossLossXY
MPSCNNYOLOLossLossWH
MPSCNNYOLOLossLossConfidence
MPSCNNYOLOLossLossClasses
MPSCNNYOLOLossAnchorBoxes
((info->src.image.featureChannels) / numAnchorBoxes) > 5, failed, input image does not have enough feature channels for the anchor boxes
((info->src.image.featureChannels) %% numAnchorBoxes) == 0, failed, input image feature channels must be a multiple of number of anchor boxes
YOLOLossBatch
YOLOFinalizeBatch
YoloLossFinalizeAcrossBatch
MPSNNNeuronDescriptor for fusing with convoution cannot be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolution.mm
Use -setNeuronType:parameterA:parameterB instead
Number of groups should be 1 for depthwise convolution.
Number of input channels must be divisible by groups parameter
Number of output channels must be divisible by groups parameter
Number of input channels in each group must be multiple of 4
Number of output channels in each group must be multiple of 4
kernel width: %lu
kernel height: %lu
Input feature channels: %lu
Output feature channels: %lu
X stride (pixels): %lu
Y stride (pixels): %lu
Groups:    %lu
subPixelScaleFactor:    %lu
dilationRateX:    %lu
dilationRateY:    %lu
Batch norm data: %p
neuron:
Error: can not add neuron to descriptor that already has one.
neuron already set on the convolution descriptor next layer cannot be fused
outputFeatureChannels (%lu) in convolution descriptor must be multiple of scaleFactor*scaleFactor=%lu becuase these values are rearragned in scaleFactor x scaleFactor pixel block by sub pixel convolution with each pixel having outputFeatureChannels/(scaleFactor*scaleFactor) channels
When number of groups (%lu) is greater than 1, number of feature channel in upsampled output image (outputFeatureChannels/(scaleFactor*scaleFactor)) (%lu) must be multiple of 4
outputFeatureChannels (%lu) in convolution descriptor must be multiple of _inputFeatureChannels (%lu)
channelMultiplier:    %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least one source image are expected for a MPSCNNConvolutionTranspose.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
convolution: %@ %p "%@"
vDSP_vsmul
vDSP_vma
8-bit weights are only allowed for interleaved per array slice layout
for depth wise convolution, number of output feature channels (%lu) must be multiple of input feature channels (%lu)
for depth wise convolution, currently only channel multiplier of 1 is supported.
for depth wise convolution, groups should be 1.
depth wise convolution currently only supported for FP weights.
parameterA of depreated neuron property doesnt match the value set for neuronParameterA of convolution descriptor.
parameterB of depreated neuron property doesnt match the value set for neuronParameterB of convolution descriptor.
Neuron type of depreated neuron property doesnt match the value set for neuronType of convolution descriptor.
[%@ initWithDevice:convolutionDescriptor:weights:] weights may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] weights.load should return YES
Only MPSDataTypeFloat32, MPSDataTypeFloat16 and MPSDataTypeUInt8 are supported by convolution.
Data source does not implement rangesForUInt8Kernel method
rangesForUInt8Kernel method returned nil
Data source does not implement lookupTableForUInt8Kernel method
lookupTableForUInt8Kernel method returned nil
Only linear or loopup table based dequantization available for UInt8 datatype
Weights data provider data type is UInt8 but no method implemented to dequantize the weights or methods returned nil LUT/ranges
[%@ initWithDevice:convolutionDescriptor:weights:] unsupported weights.dataType: 0x%16.16llx
Failed to load data source
data source does not repond to selector lookupTableForUInt8Kernel
data source does not repond to selector rangesForUInt8Kernel
Convolution object was not created with data source. Use initWithDevice:weights
data source load failed
MPSNNConvolutionAccumulatorPrecisionOptionHalf
MPSNNConvolutionAccumulatorPrecisionOptionFloat
inputFeatureChannels: %lu
outputFeatureChannels:   %lu
Feature channel layout:  %lu
Groups:                  %lu
scaleFactor:             %lu
Accumulator precision:   %s
srcWidth %lu srcHeight %lu inputChannels %lu destWidth %lu destHeight %lu outputChannels %lu kernelWidth %lu kernelHeight %lu strideX %lu strideY %lu group %lu dilationX %lu dilationY %lu channelMultiplier %lu batchSize %lu
Feature channel layout of source and MPSCNNConvolution filter doesn't match
Feature channel layout of destination and MPSCNNConvolution filter doesn't match
Accumulator precision must be set to MPSNNConvolutionAccumulatorPrecisionOptionFloat when using Float32 kernel weights
[%@ initWithDevice:convolutionDescriptor:weights:] dataSource.load should return YES
weights layout mismatch. Layout of convolution objct is %s while state object layout is %s
biases buffer should have %lu bytes of data
MPSCNNConvolutionWeightsAndBiases state expect weights data type to be either float32 or float16
weightsOffsets must be aligned to size of element in weights buffers
biasesOffsets must be aligned to size of element in biases buffers
Not enough elements in weights buffer
Not enough elements in biases buffer
MPSCNNConvolutionDescriptorVers
MPSCNNConvolutionDescriptorWidth
MPSCNNConvolutionDescriptorHeight
MPSCNNConvolutionDescriptorInputFeatureChannels
MPSCNNConvolutionDescriptorOutputFeatureChannels
MPSCNNConvolutionDescriptorStrideInPixelsX
MPSCNNConvolutionDescriptorStrideInPixelsY
MPSCNNConvolutionDescriptorGroups
MPSCNNConvolutionDescriptorFeatureChannelsLayout
MPSCNNConvolutionDescriptorSubPixelScaleFactor
MPSCNNConvolutionDescriptorDilationRateX
MPSCNNConvolutionDescriptorDilationRateY
MPSCNNConvolutionDescriptorNeuronType
MPSCNNConvolutionDescriptorNeuronA
MPSCNNConvolutionDescriptorNeuronB
MPSCNNConvolutionDescriptorNeuronC
MPSCNNConvolutionDescriptorIsDepthWiseConvolution
MPSCNNConvolutionDescriptorBatchNormalization.isNull
MPSCNNConvolutionDescriptorBatchNormalization.data
MPSCNNConvolutionDescriptorNeuronParameterA.isNull
MPSCNNConvolutionDescriptorNeuronParameterA.data
MPSCNNConvolutionWeight.dataLayout
MPSCNNConvolutionWeight.dataType
MPSCNNConvolutionBias.isNull
MPSCNNConvolutionWeight.data
MPSCNNConvolutionBias.data
MPSCNNConvolutionQuantizationData.data
cnnFullyConnectedH
cnnFullyConnectedArrayH
MPSCNNConvolutionFeatureChannelsLayout
MPSCNNConvolutionIsFullyConnected
MPSCNNConvolutionIsConvolutionTranspose
MPSCNNConvolutionConvertFloat32Weights
MPSCNNConvolutionFlags
MPSCNNConvolutionNeuronBufferA.isNull
MPSCNNConvolutionNeuronBufferA.data
MPSCNNConvolutionBatchNormalizationData.isNull
MPSCNNConvolutionBatchNormalizationData.data
MPSCNNConvolutionDataSourceClass
MPSCNNConvolutionDataSource
MPSCNNConvolutionInputFeatureChannels
MPSCNNConvolutionOutputFeatureChannels
MPSCNNConvolutionGroups
MPSCNNConvolutionNeuronInfo.type
MPSCNNConvolutionNeuronInfo.a
MPSCNNConvolutionNeuronInfo.b
MPSCNNConvolutionNeuronInfo.c
MPSCNNConvolutionScaleFactor
MPSCNNConvolutionQuantizationType
MPSCNNConvolutionChannelMultipler
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNormalization.mm
alpha:          %f
beta:           %f
delta:          %f
MPSCNNNormalization_tex2d_tex2d_CHNorm
MPSCNNNormalization_tex2darray_tex2darray_CHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw2
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw3
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw4
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw5
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw6
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw7
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw8
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw9
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt2
MPSCNNNormalization_ArrayFC_GenCHNorm
MPSCNNNormalization_horizontal_tex2d_tex2d_XYNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_vertical_tex2d_tex2d_XYNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_horizontal_tex2d_tex2d_LCNNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_vertical_tex2d_tex2d_LCNNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNCrossChannelNormalization.kernelSize
MPSCNNCrossChannelNormalization.alpha
MPSCNNCrossChannelNormalization.beta
MPSCNNCrossChannelNormalization.delta
MPSCNNSpatialNormalization.alpha
MPSCNNSpatialNormalization.beta
MPSCNNSpatialNormalization.delta
MPSCNNLocalContrastNormalization.alpha
MPSCNNLocalContrastNormalization.beta
MPSCNNLocalContrastNormalization.delta
MPSCNNLocalContrastNormalization.p0
MPSCNNLocalContrastNormalization.pm
MPSCNNLocalContrastNormalization.ps
v32@?0@"MPSMatrix"8Q16^B24
commandBuffer may not be nil.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixSum.mm
Requires at least two matrices to compute a sum.
Only matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
Offset vector must be of type MPSDataTypeUInt32.
MatrixSum_float
MatrixSum_half
MPSMatrixSum.rows
MPSMatrixSum.columns
MPSMatrixSum.count
MPSMatrixSum.transpose
MPSMatrixSum.neuronType
MPSMatrixSum.neuronA
MPSMatrixSum.neuronB
MPSMatrixSum.neuronC
MPSMatrixSum.resultOrigin.x
MPSMatrixSum.resultOrigin.y
MPSMatrixSum.resultOrigin.z
MatrixSumRemainder_float
MatrixSumRemainder_half
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionTransposeGradient.mm
Subpixel convolution transpose does not currently supported gradient back propagation
Depthwise descriptor is not valid for convolution transpose
MPSCNNConvolutionTransposeGradientInputFeatureChannels
MPSCNNConvolutionTransposeGradientOutputFeatureChannels
MPSCNNConvolutionTransposeGradientGroups
MPSCNNConvolutionTransposeGradientOption
MPSCNNConvolutionTransposeGradientConvolutionGradientClass
MPSCNNConvolutionTransposeGradientConvolutionGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNSoftMax.mm
softmaxNleq4_RGBA
softmaxNgt4leq8_RGBA
softmaxNgt8leq12_RGBA
softmaxNdiv4_RGBA
softmaxN_RGBA
softmaxN_threadgroup
softmaxNleq4_array_RGBA
softmaxNgt4leq8_array_RGBA
softmaxNgt8leq12_array_RGBA
softmaxNdiv4_array_RGBA
softmaxN_array_RGBA
softmaxN_array_interleaved_pixel_threadgroup
softmaxN_array_interleaved_slice_threadgroup
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalization.mm
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixBatchNormalization
MPSMatrixBatchNormalization._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalization._sourceInputFeatureChannels;
MPSMatrixBatchNormalization._neuronType;
MPSMatrixBatchNormalization._neuronA;
MPSMatrixBatchNormalization._neuronB;
MPSMatrixBatchNormalization._neuronC;
MPSMatrixBatchNormalization._epsilon;
MPSMatrixBatchNormalization._computeStatistics;
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNGradientKernel.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSNNGradientState.mm
offset: {%ld, %ld, %ld}
clipRect:                          {origin:{%lu, %lu, %lu}, size:{%lu, %lu, %lu}}
dest size:                         {w:%lu, h:%lu, images:%lu}
destination feature channel offset: %lu
source feature channel offset:      %lu
kernel size:                        %lu x %lu
pixel stride:                       %lu x %lu
dilation rate:                      %lu x %lu
padding:                            
max batch size:                     %lu
is backwards:                       %@
edge mode:                          %lu
source size:                       {%lu, %lu, %lu} fc: %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNBinaryGradientKernel.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: primary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: secondary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBinaryConvolution.mm
number of groups must be 1
[%@ initWithCoder:device:] failed. %@
Problem decoding buffers
Problem creating pooling filter for internal use.
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
inputFeatureChannels: %lu
outputFeatureChannels: %lu
NeuronType: %d
outputBias: %d
outputScale: %d
inputBias: %d
inputScale: %d
PoolingFilter: %@
convType: %lu
flags: %lu
kMPSCNNBinaryConvolution._fullyConnected
kMPSCNNBinaryConvolution._kernelWidth
kMPSCNNBinaryConvolution._kernelHeight
kMPSCNNBinaryConvolution._inputFeatureChannels
kMPSCNNBinaryConvolution._outputFeatureChannels
kMPSCNNBinaryConvolution._strideInPixelsX
kMPSCNNBinaryConvolution._strideInPixelsY
kMPSCNNBinaryConvolution._flags
kMPSCNNBinaryConvolution._convType
kMPSCNNBinaryConvolution._outputScaleValue
kMPSCNNBinaryConvolution._weights
kMPSCNNBinaryConvolution._inputbias
kMPSCNNBinaryConvolution._inputScale
kMPSCNNBinaryConvolution._outputbias
kMPSCNNBinaryConvolution._outputScale
kMPSCNNBinaryConvolution._neuronType
kMPSCNNBinaryConvolution._neuronParamA
kMPSCNNBinaryConvolution._neuronParamB
kMPSCNNBinaryConvolution._neuronParamC
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + outputFeatureChannels > dest.featureChannels
MPSCNNBinarize_2d_2d_float
MPSCNNBinarize_2d_2dArray_float
MPSCNNBinarize_2dArray_2d_float
MPSCNNBinarize_2dArray_2dArray_float
MPSCNNBetaBinarize_2d_2d_float
MPSCNNBetaBinarize_2d_2dArray_float
MPSCNNBetaBinarize_2dArray_2d_float
MPSCNNBetaBinarize_2dArray_2dArray_float
MPSCNNBinarizePixelFC_2d_2d_float
MPSCNNBinarizePixelFC_2d_2dArray_float
MPSCNNBinarizePixelFC_2dArray_2d_float
MPSCNNBinarizePixelFC_2dArray_2dArray_float
MPSCNNBetaBinarizePixelFC_2d_2d_float
MPSCNNBetaBinarizePixelFC_2d_2dArray_float
MPSCNNBetaBinarizePixelFC_2dArray_2d_float
MPSCNNBetaBinarizePixelFC_2dArray_2dArray_float
MPSCNNBinaryConvolve_2d_2d_float
MPSCNNBinaryConvolve_2d_2dArray_float
MPSCNNBinaryConvolve_2dArray_2d_float
MPSCNNBinaryConvolve_2dArray_2dArray_float
MPSCNNBetaBinaryConvolve_2d_2d_float
MPSCNNBetaBinaryConvolve_2d_2dArray_float
MPSCNNBetaBinaryConvolve_2dArray_2d_float
MPSCNNBetaBinaryConvolve_2dArray_2dArray_float
MPSCNNBinaryConvolvePixelFC_2d_2d_float
MPSCNNBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNImageScale_2d_2d_float
MPSCNNImageScale_2d_2dArray_float
MPSCNNImageScale_2dArray_2d_float
MPSCNNImageScale_2dArray_2dArray_float
MPSCNNImageScalePixelFC_2d_2d_float
MPSCNNImageScalePixelFC_2d_2dArray_float
MPSCNNImageScalePixelFC_2dArray_2d_float
MPSCNNImageScalePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightConvolve_2d_2d_float
MPSCNNBinaryWeightConvolve_2d_2dArray_float
MPSCNNBinaryWeightConvolve_2dArray_2d_float
MPSCNNBinaryWeightConvolve_2dArray_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnected_2d_2d_float
MPSCNNBinaryWeightFullyConnected_2d_2dArray_float
MPSCNNBinaryWeightFullyConnected_2dArray_2d_float
MPSCNNBinaryWeightFullyConnected_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2dArray_float
Internal error: undefined device in MPSCNNBinConvFunctionConstructor
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Plugin/MPSCNNKernelPlugin.mm
[%@ encodeToCommandBuffer:computeCommandEncoder:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:]  Error: The device driver has failed to override this method
MPSMatrixFullyConnectedGradient
MPSNNReshape
MPSNNReshapeGradient
MPSNNPadGradientState
MPSNNPad
MPSNNPadGradient
MPSCNNPoolingGradient
MPSCNNPoolingMaxGradient
MPSCNNPoolingAverageGradient
MPSCNNPoolingL2NormGradient
MPSCNNDilatedPoolingMaxGradient
MPSCNNArithmeticGradientState
MPSCNNArithmetic
MPSCNNAdd
MPSCNNSubtract
MPSCNNMultiply
MPSCNNDivide
MPSNNCompare
MPSCNNArithmeticGradient
MPSCNNAddGradient
MPSCNNSubtractGradient
MPSCNNMultiplyGradient
MPSRNNRecurrentImageState
MPSRNNRecurrentMatrixState
MPSRNNMatrixTrainingState
MPSRNNDescriptor
MPSRNNSingleGateDescriptor
MPSLSTMDescriptor
MPSGRUDescriptor
TmpWeights
MPSCNNConvolutionDataSource
NSCopying
NSObject
TmpWeightsLUT
TmpWeightsLIN
MPSCNNConvolutionDescriptorNoNeuron
MPSRNNImageInferenceLayer
MPSRNNMatrixInferenceLayer
MPSRNNMatrixTrainingLayer
MPSNNScaleNode
MPSNNBilinearScaleNode
MPSNNLanczosScaleNode
MPSNNScale
MPSNNConcatenation
MPSNNConcatenationGradientState
MPSCNNConvolutionGradient
MPSNNUnaryReductionNode
MPSNNReductionRowMinNode
MPSNNReductionColumnMinNode
MPSNNReductionFeatureChannelsMinNode
MPSNNReductionFeatureChannelsArgumentMinNode
MPSNNReductionRowMaxNode
MPSNNReductionColumnMaxNode
MPSNNReductionFeatureChannelsMaxNode
MPSNNReductionFeatureChannelsArgumentMaxNode
MPSNNReductionRowMeanNode
MPSNNReductionColumnMeanNode
MPSNNReductionFeatureChannelsMeanNode
MPSNNReductionSpatialMeanNode
MPSNNReductionSpatialMeanGradientNode
MPSNNReductionRowSumNode
MPSNNReductionColumnSumNode
MPSNNReductionFeatureChannelsSumNode
MPSMatrixBatchNormalizationGradient
MPSCNNDropoutGradientState
MPSCNNDropoutRandomState
NSSecureCoding
NSCoding
MPSCNNDropout
MPSCNNDropoutGradient
MPSCNNUpsampling
MPSCNNUpsamplingNearest
MPSCNNUpsamplingBilinear
MPSCNNGradientKernel
MPSCNNNeuronNode
MPSCNNNeuronAbsoluteNode
MPSCNNNeuronELUNode
MPSCNNNeuronReLUNNode
MPSCNNNeuronLinearNode
MPSCNNNeuronReLUNode
MPSCNNNeuronSigmoidNode
MPSCNNNeuronHardSigmoidNode
MPSCNNNeuronSoftPlusNode
MPSCNNNeuronSoftSignNode
MPSCNNNeuronTanHNode
MPSCNNNeuronPReLUNode
MPSCNNNeuronPowerNode
MPSCNNNeuronExponentialNode
MPSCNNNeuronLogarithmNode
MPSCNNNeuronGeLUNode
MPSCNNNeuronGradientNode
MPSNNReshapeNode
MPSNNReshapeGradientNode
MPSNNPadNode
MPSNNPadGradientNode
MPSNNGridSample
MPSMatrixFullyConnected
MPSMatrixNeuron
MPSCNNBatchNormalizationDataSource
MPSCNNBatchNormalization
MPSCNNConvolutionTransposeGradientState
MPSCNNConvolutionTranspose
MPSNNBinaryArithmeticNode
MPSNNAdditionNode
MPSNNSubtractionNode
MPSNNMultiplicationNode
MPSNNDivisionNode
MPSNNComparisonNode
MPSNNArithmeticGradientStateNode
MPSNNArithmeticGradientNode
MPSNNAdditionGradientNode
MPSNNSubtractionGradientNode
MPSNNMultiplicationGradientNode
MPSCNNInstanceNormalizationGradient
MPSCNNBatchNormalizationStatisticsGradient
MPSCNNUpsamplingNearestNode
MPSCNNUpsamplingBilinearNode
MPSCNNUpsamplingNearestGradientNode
MPSCNNUpsamplingBilinearGradientNode
MPSNNOptimizerDescriptor
MPSNNOptimizer
MPSNNOptimizerStochasticGradientDescent
MPSNNOptimizerRMSProp
MPSNNOptimizerAdam
MPSImageAllocator
MPSNNGraph
MPSNNTrainableNode
FilterNodeWrapper
MPSHandle
ResourceWrapper
NodeWrapper
MPSCNNCrossChannelNormalizationGradient
MPSCNNSpatialNormalizationGradient
MPSCNNLocalContrastNormalizationGradient
MPSNNLabelsNode
MPSCNNLossNode
MPSCNNYOLOLossNode
MPSNNForwardLossNode
MPSNNLossGradientNode
MPSNNInitialGradientNode
MPSCNNLossDataDescriptor
MPSCNNLossDescriptor
MPSCNNLossLabels
MPSCNNLoss
MPSNNLossGradientState
MPSNNForwardLoss
MPSNNLossGradient
MPSNNInitialGradient
MPSCNNUpsamplingGradient
MPSCNNUpsamplingNearestGradient
MPSCNNUpsamplingBilinearGradient
MPSCNNGroupNormalizationDataSource
MPSCNNGroupNormalization
MPSCNNGroupNormalizationGradientState
MPSNNPermuteGradientState
MPSNNPermute
MPSNNPermuteGradient
MPSNNImageNode
MPSNNStateNode
MPSNNFilterNode
MPSNNGradientFilterNode
MPSNNGradientStateNode
MPSNNBinaryGradientStateNode
MPSNNMultiaryGradientStateNode
MPSNNSlice
MPSNNConcatenationGradient
MPSCNNInstanceNormalizationDataSource
MPSCNNInstanceNormalization
MPSCNNNormalizationGammaAndBetaState
MPSCNNInstanceNormalizationGradientState
MPSNNCropAndResizeBilinear
MPSCNNPooling
MPSCNNPoolingMax
MPSCNNPoolingAverage
MPSCNNPoolingL2Norm
MPSCNNDilatedPoolingMax
MPSCNNBatchNormalizationGradient
MPSNNPadding
MPSImageSizeEncodingState
MPSCNNBinaryKernel
MPSCNNBinaryImageFilter
MPSCNNBatchNormalizationState
MPSCNNNormalizationMeanAndVarianceState
MPSNNResizeBilinear
MPSCNNDropoutNode
MPSCNNDropoutGradientNode
MPSCNNSoftMaxNode
MPSCNNLogSoftMaxNode
MPSCNNSoftMaxGradientNode
MPSCNNLogSoftMaxGradientNode
MPSCNNGroupNormalizationGradient
MPSNNNeuronDescriptor
MPSCNNNeuron
MPSCNNNeuronGradient
MPSCNNNeuronLinear
MPSCNNNeuronReLU
MPSCNNNeuronPReLU
MPSCNNNeuronSigmoid
MPSCNNNeuronHardSigmoid
MPSCNNNeuronTanH
MPSCNNNeuronAbsolute
MPSCNNNeuronSoftPlus
MPSCNNNeuronSoftSign
MPSCNNNeuronELU
MPSCNNNeuronReLUN
MPSCNNNeuronPower
MPSCNNNeuronExponential
MPSCNNNeuronLogarithm
MPSNNPermuteNode
MPSNNPermuteGradientNode
MPSNNGramGradientState
MPSNNGramMatrixCalculation
MPSNNGramMatrixCalculationGradient
MPSNNReduceUnary
MPSNNReduceRowMin
MPSNNReduceColumnMin
MPSNNReduceFeatureChannelsMin
MPSNNReduceFeatureChannelsArgumentMin
MPSNNReduceRowMax
MPSNNReduceColumnMax
MPSNNReduceFeatureChannelsMax
MPSNNReduceFeatureChannelsArgumentMax
MPSNNReduceRowMean
MPSNNReduceColumnMean
MPSNNReduceFeatureChannelsMean
MPSNNReduceRowSum
MPSNNReduceColumnSum
MPSNNReduceFeatureChannelsSum
MPSNNReduceBinary
MPSNNReduceFeatureChannelsAndWeightsMean
MPSNNReduceFeatureChannelsAndWeightsSum
MPSNNLocalCorrelation
MPSWeightsWrapper
MPSWeightsWrapper_SecureCoding
MPSCNNKernel
MPSNNDefaultPadding
MPSNNTensorFlowPoolingPadding
MPSNNTensorFlowPoolingPaddingValidOnly
ExplicitZeroPadding
MPSCNNPoolingNode
MPSCNNPoolingMaxNode
MPSCNNPoolingAverageNode
MPSCNNPoolingL2NormNode
MPSCNNDilatedPoolingMaxNode
MPSCNNPoolingGradientNode
MPSCNNPoolingMaxGradientNode
MPSCNNPoolingAverageGradientNode
MPSCNNPoolingL2NormGradientNode
MPSCNNDilatedPoolingMaxGradientNode
MPSMatrixNeuronGradient
MPSCNNMultiaryKernel
MPSCNNSoftMaxGradient
MPSCNNLogSoftMaxGradient
MPSNNConcatenationNode
MPSNNConcatenationGradientNode
MPSCNNNormalizationNode
MPSCNNSpatialNormalizationNode
MPSCNNSpatialNormalizationGradientNode
MPSCNNLocalContrastNormalizationNode
MPSCNNLocalContrastNormalizationGradientNode
MPSCNNCrossChannelNormalizationNode
MPSCNNCrossChannelNormalizationGradientNode
MPSCNNInstanceNormalizationNode
MPSCNNInstanceNormalizationGradientNode
MPSCNNGroupNormalizationNode
MPSCNNGroupNormalizationGradientNode
MPSCNNBatchNormalizationNode
MPSCNNBatchNormalizationGradientNode
MPSCNNFullyConnected
MPSCNNFullyConnectedGradient
MPSCNNConvolutionGradientStateNode
MPSCNNConvolutionTransposeGradientStateNode
MPSCNNConvolutionStateNode
MPSCNNConvolutionNode
MPSCNNConvolutionGradientNode
MPSCNNConvolutionTransposeGradientNode
MPSCNNFullyConnectedNode
MPSCNNFullyConnectedGradientNode
MPSCNNBinaryConvolutionNode
MPSCNNBinaryFullyConnectedNode
MPSCNNConvolutionTransposeNode
MPSNNGramMatrixCalculationNode
MPSNNGramMatrixCalculationGradientNode
MPSCNNBatchNormalizationStatistics
MPSConvolutionDataSourceWrapper
MPSConvolutionDataSourceWrapper_SecureCoding
MPSCNNYOLOLossDescriptor
MPSCNNYOLOLoss
MPSCNNConvolutionDescriptor
MPSCNNSubPixelConvolutionDescriptor
MPSCNNDepthWiseConvolutionDescriptor
MPSCNNConvolutionState
MPSCNNConvolutionGradientState
MPSPluginCNNConvolutionDescriptor
MPSCNNConvolution
MPSCNNConvolutionWeightsAndBiasesState
MPSCNNCrossChannelNormalization
MPSCNNSpatialNormalization
MPSCNNLocalContrastNormalization
MPSMatrixSum
MPSCNNConvolutionTransposeGradient
MPSCNNSoftMax
MPSCNNLogSoftMax
MPSMatrixBatchNormalization
MPSNNGradientState
MPSNNBinaryGradientState
MPSNNMultiaryGradientState
MPSCNNBinaryConvolution
MPSCNNBinaryFullyConnected
MPSExternalCNNUnary
MPSExternalPluginBase
MPSExternalCNNBinary
MPSExternalCNNPoolingAverage
initWithDevice:
primarySourceMatrixOrigin
secondarySourceMatrixOrigin
resultMatrixOrigin
dataType
matrices
columns
rows
vectors
copyWithZone:device:
initWithCoder:device:
decodeDoubleForKey:
decodeInt64ForKey:
encodeWithCoder:
encodeDouble:forKey:
encodeInt64:forKey:
libraryInfo:
encodeGradientForDataToCommandBuffer:gradientMatrix:weightMatrix:resultGradientForDataMatrix:
encodeGradientForWeightsAndBiasToCommandBuffer:gradientMatrix:inputMatrix:resultGradientForWeightMatrix:resultGradientForBiasVector:
sourceNumberOfFeatureVectors
setSourceNumberOfFeatureVectors:
sourceInputFeatureChannels
setSourceInputFeatureChannels:
sourceOutputFeatureChannels
setSourceOutputFeatureChannels:
alpha
setAlpha:
_sourceNumberOfFeatureVectors
_sourceInputFeatureChannels
_sourceOutputFeatureChannels
_alpha
TQ,N,V_sourceNumberOfFeatureVectors
TQ,N,V_sourceOutputFeatureChannels
TQ,N,V_sourceInputFeatureChannels
Td,N,V_alpha
setConstantValue:type:atIndex:
initWithCommandBuffer:withDispatchType:
setLabel:
stringWithFormat:
stringByAppendingString:
rowBytes
maxTotalThreadsPerThreadgroup
setComputePipelineState:
data
setBuffer:offset:atIndex:
setBytes:length:atIndex:
dispatchThreadgroups:threadsPerThreadgroup:
endEncoding
debugDescription
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:
setWidth:
setHeight:
setFeatureChannels:
encodeToCommandBuffer:sourceImage:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
encodeToCommandBuffer:sourceImage:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeBatchToCommandBuffer:sourceImages:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
_reshapedWidth
_reshapedHeight
_reshapedFeatureChannels
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset:
objectAtIndexedSubscript:
width
height
featureChannels
initWithResource:
temporaryStateWithCommandBuffer:
dealloc
_fwdPadBefore
_fwdPadAfter
_srcImgFcCount
initWithDevice:paddingSizeBefore:paddingSizeAfter:fillValueArray:
length
newBufferWithLength:options:
contents
bytes
decodeFloatForKey:
encodeFloat:forKey:
destinationImageDescriptorForSourceImages:sourceStates:
offset
setOffset:
copyToGradientState:sourceImage:sourceStates:destinationImage:
initWithDevice:paddingSizeBefore:paddingSizeAfter:
isResultStateReusedAcrossBatch
resultStateForSourceImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:
paddingSizeBefore
setPaddingSizeBefore:
paddingSizeAfter
setPaddingSizeAfter:
fillValue
setFillValue:
_aBuf
_aBufFP32Len
_fillValue
_paddingSizeBefore
_paddingSizeAfter
T{MPSImageCoordinate=QQQ},N,V_paddingSizeBefore
T{MPSImageCoordinate=QQQ},N,V_paddingSizeAfter
Tf,N,V_fillValue
isEqual:
maxBatchSize
arrayLength
strideInPixelsX
strideInPixelsY
setTexture:atIndex:
setSamplerState:atIndex:
primaryStrideInPixelsX
primaryStrideInPixelsY
decodeBoolForKey:
newBufferWithBytes:length:options:
initWithFormat:
decodeBytesForKey:returnedLength:
encodeBool:forKey:
encodeBytes:length:forKey:
sourceFeatureChannelMaxCount
numberOfImages
retainedReferences
addCompletedHandler:
maxThreadsPerThreadgroup
count
getObjects:range:
setTextures:withRange:
primarySourceFeatureChannelMaxCount
initWithDevice:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
initWithDevice:kernelWidth:kernelHeight:
setKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
sourceSize
setSourceSize:
_sourceSize
T{?=QQQ},N,V_sourceSize
setPlugin:
zeroPadSizeX
setZeroPadSizeX:
zeroPadSizeY
setZeroPadSizeY:
_zeroPadSizeX
_zeroPadSizeY
TQ,N,V_zeroPadSizeX
TQ,N,V_zeroPadSizeY
initWithDevice:kernelWidth:kernelHeight:dilationRateX:dilationRateY:strideInPixelsX:strideInPixelsY:
newTextureViewWithPixelFormat:textureType:levels:slices:
threadExecutionWidth
resourceCount
init
_resourcePixelFormat
_resourceSize
_primaryFCStride
_secondaryFCStride
plugin
textureType
setTextureType:
setPixelFormat:
setArrayLength:
initWithDevice:textureDescriptor:
temporaryStateWithCommandBuffer:textureDescriptor:
copyToBinaryGradientState:primaryImage:secondaryImage:sourceStates:destinationImage:
pixelFormat
privateResultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:commandBuffer:isTemporary:
primarySourceFeatureChannelOffset
secondarySourceFeatureChannelOffset
secondarySourceFeatureChannelMaxCount
encodeToCommandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
setPrimaryStrideInPixelsX:
setPrimaryStrideInPixelsY:
setPrimaryStrideInFeatureChannels:
setSecondaryStrideInPixelsX:
setSecondaryStrideInPixelsY:
setSecondaryStrideInFeatureChannels:
initWithDevice:arithmeticType:
resultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationImages:
primaryScale
setPrimaryScale:
secondaryScale
setSecondaryScale:
bias
setBias:
minimumValue
setMinimumValue:
maximumValue
setMaximumValue:
primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
_primaryScale
_secondaryScale
_bias
_minimumValue
_maximumValue
_primaryStrideInFeatureChannels
_secondaryStrideInFeatureChannels
_arithmeticType
Tf,N,V_primaryScale
Tf,N,V_secondaryScale
Tf,N,V_bias
TQ,N,V_primaryStrideInFeatureChannels
TQ,N,V_secondaryStrideInFeatureChannels
Tf,N,V_minimumValue
Tf,N,V_maximumValue
comparisonType
setComparisonType:
threshold
setThreshold:
_threshold
_comparisonType
TQ,N,V_comparisonType
Tf,N,V_threshold
readBinaryGradientState:isSecondarySourceFilter:
initWithDevice:arithmeticType:isSecondarySourceFilter:
isSecondarySourceFilter
_isSecondarySourceFilter
_reduceRows
_reduceColumns
_reduceFeatureChannels
TB,R,N,V_isSecondarySourceFilter
initWithDevice:isSecondarySourceFilter:
secondaryStrideInPixelsX
secondaryStrideInPixelsY
texture
initWithTexture:featureChannels:
imageDescriptorWithChannelFormat:width:height:featureChannels:numberOfImages:usage:
pushDebugGroup:
popDebugGroup
temporaryImageWithCommandBuffer:imageDescriptor:
device
initWithDevice:imageDescriptor:
setReadCount:
getRecurrentOutputImageForLayerIndex:
getMemoryCellImageForLayerIndex:
initWithCommandBuffer:recurrentImageDescriptors:cellImageDescriptors:isTemporary:layerCount:
isTemporary
recurrentImages
cellImages
nLayers
_isTemporary
initWithDevice:commandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
temporaryMatrixWithCommandBuffer:matrixDescriptor:
initWithBuffer:descriptor:
getRecurrentOutputMatrixForLayerIndex:
getMemoryCellMatrixForLayerIndex:
initWithCommandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
recurrentMatrices
cellMatrices
initForSingleGateWithCommandBuffer:matrixDescriptor:isTemporary:
singleGateZ
inputFeatureChannels
setInputFeatureChannels:
outputFeatureChannels
setOutputFeatureChannels:
inputTransform
setInputTransform:
outputTransform
setOutputTransform:
recurrentOutputTransform
setRecurrentOutputTransform:
useLayerInputUnitTransformMode
setUseLayerInputUnitTransformMode:
layerSequenceDirection
setLayerSequenceDirection:
useFloat32Weights
setUseFloat32Weights:
internalKernelSelector
setInternalKernelSelector:
_useLayerInputUnitTransformMode
_useFloat32Weights
_inputFeatureChannels
_outputFeatureChannels
_inputTransform
_outputTransform
_recurrentOutputTransform
_layerSequenceDirection
_internalKernelSelector
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentOutputTransform
TQ,N,V_internalKernelSelector
TQ,N,V_inputFeatureChannels
TQ,N,V_outputFeatureChannels
TB,N,V_useLayerInputUnitTransformMode
TB,N,V_useFloat32Weights
TQ,N,V_layerSequenceDirection
initWithInputFeatureChannels:outputFeatureChannels:
createRNNSingleGateDescriptorWithInputFeatureChannels:outputFeatureChannels:
inputWeights
setInputWeights:
recurrentWeights
setRecurrentWeights:
_inputWeights
_recurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentWeights
createLSTMDescriptorWithInputFeatureChannels:outputFeatureChannels:
memoryWeightsAreDiagonal
setMemoryWeightsAreDiagonal:
inputGateInputWeights
setInputGateInputWeights:
inputGateRecurrentWeights
setInputGateRecurrentWeights:
inputGateMemoryWeights
setInputGateMemoryWeights:
forgetGateInputWeights
setForgetGateInputWeights:
forgetGateRecurrentWeights
setForgetGateRecurrentWeights:
forgetGateMemoryWeights
setForgetGateMemoryWeights:
outputGateInputWeights
setOutputGateInputWeights:
outputGateRecurrentWeights
setOutputGateRecurrentWeights:
outputGateMemoryWeights
setOutputGateMemoryWeights:
cellGateInputWeights
setCellGateInputWeights:
cellGateRecurrentWeights
setCellGateRecurrentWeights:
cellGateMemoryWeights
setCellGateMemoryWeights:
cellToOutputNeuronType
setCellToOutputNeuronType:
cellToOutputNeuronParamA
setCellToOutputNeuronParamA:
cellToOutputNeuronParamB
setCellToOutputNeuronParamB:
cellToOutputNeuronParamC
setCellToOutputNeuronParamC:
cellClipThreshold
setCellClipThreshold:
coupleForgetGateToInputGate
setCoupleForgetGateToInputGate:
_memoryWeightsAreDiagonal
_coupleForgetGateToInputGate
_cellToOutputNeuronType
_cellToOutputNeuronParamA
_cellToOutputNeuronParamB
_cellToOutputNeuronParamC
_cellClipThreshold
_inputGateInputWeights
_inputGateRecurrentWeights
_inputGateMemoryWeights
_forgetGateInputWeights
_forgetGateRecurrentWeights
_forgetGateMemoryWeights
_outputGateInputWeights
_outputGateRecurrentWeights
_outputGateMemoryWeights
_cellGateInputWeights
_cellGateRecurrentWeights
_cellGateMemoryWeights
Tf,N,V_cellClipThreshold
TB,N,V_coupleForgetGateToInputGate
TB,N,V_memoryWeightsAreDiagonal
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateMemoryWeights
Ti,N,V_cellToOutputNeuronType
Tf,N,V_cellToOutputNeuronParamA
Tf,N,V_cellToOutputNeuronParamB
Tf,N,V_cellToOutputNeuronParamC
createGRUDescriptorWithInputFeatureChannels:outputFeatureChannels:
recurrentGateInputWeights
setRecurrentGateInputWeights:
recurrentGateRecurrentWeights
setRecurrentGateRecurrentWeights:
outputGateInputGateWeights
setOutputGateInputGateWeights:
gatePnormValue
setGatePnormValue:
flipOutputGates
setFlipOutputGates:
_flipOutputGates
_gatePnormValue
_recurrentGateInputWeights
_recurrentGateRecurrentWeights
_outputGateInputGateWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputGateWeights
Tf,N,V_gatePnormValue
TB,N,V_flipOutputGates
label
weights
biasTerms
copyWithZone:
initWithConvDescriptor:
allocWithZone:
initWithWeights:useBias:desc:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
TQ,R
T#,R
T@"NSString",R,C
descriptor
load
purge
rangesForUInt8Kernel
lookupTableForUInt8Kernel
weightsQuantizationType
updateWithCommandBuffer:gradientState:sourceState:
updateWithGradientState:sourceState:
weightsLayout
kernelWeightsDataType
_parentObj
_convDesc
_hasBias
setNeuronType:
setA:
setB:
setC:
clipRect
destinationFeatureChannelOffset
storeAllIntermediateStates
addObject:
initWithDevice:rnnDescriptor:
initWithDevice:rnnDescriptors:
encodeSequenceToCommandBuffer:sourceImages:destinationImages:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardImages:destinationBackwardImages:
numberOfLayers
recurrentOutputIsTemporary
setRecurrentOutputIsTemporary:
setStoreAllIntermediateStates:
bidirectionalCombineMode
setBidirectionalCombineMode:
layerTypes
layers
forwardLayers
forwardLayerTypes
nForwardLayers
backwardLayers
backwardLayerTypes
nBackwardLayers
_recurrentOutputIsTemporary
_storeAllIntermediateStates
_numberOfLayers
_bidirectionalCombineMode
TQ,R,N,V_inputFeatureChannels
TQ,R,N,V_outputFeatureChannels
TQ,R,N,V_numberOfLayers
TB,N,V_recurrentOutputIsTemporary
TB,N,V_storeAllIntermediateStates
TQ,N,V_bidirectionalCombineMode
initWithDevice:transposeLeft:transposeRight:resultRows:resultColumns:interiorColumns:alpha:beta:
encodeSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:recurrentInputState:recurrentOutputStates:
readCount
matrixDescriptorWithRows:columns:rowBytes:dataType:
encodeSequenceToCommandBuffer:sourceMatrices:destinationMatrices:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardMatrices:destinationBackwardMatrices:
recurrentStateForBatchSize:
temporaryRecurrentStateForCommandBuffer:batchSize:
propagateFullRecurrentRows
setPropagateFullRecurrentRows:
gemmKernel
gemmKernelNonTranspose
_propagateFullRecurrentRows
TB,N,V_propagateFullRecurrentRows
encodeForwardSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:trainingStates:recurrentInputState:recurrentOutputStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:forwardSourceOffsets:sourceGradients:sourceGradientOffsets:destinationGradients:destinationOffsets:weightGradients:trainingStates:recurrentInputState:recurrentOutputStates:weights:
initWithDevice:rnnDescriptor:trainableWeights:
createWeightGradientMatrices:dataType:
createTemporaryWeightGradientMatrices:dataType:commandBuffer:
createWeightMatrices:
encodeCopyWeightsToCommandBuffer:weights:matrixId:matrix:copyFromWeightsToMatrix:matrixOffset:
encodeForwardSequenceToCommandBuffer:sourceMatrices:destinationMatrices:trainingStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:sourceGradients:destinationGradients:weightGradients:trainingStates:weights:
recurrentStateForBatchSize:forGradientPass:
temporaryRecurrentStateForCommandBuffer:batchSize:forGradientPass:
trainingStateIsTemporary
setTrainingStateIsTemporary:
accumulateWeightGradients
setAccumulateWeightGradients:
layerType
layer
gemmKernel_noAccumulate
gemmKernelNonTranspose_noAccumulate
gemmKernelTN
gemmKernelTN_accumulate
weightDescriptors
_trainingStateIsTemporary
_accumulateWeightGradients
TB,N,V_trainingStateIsTemporary
TB,N,V_accumulateWeightGradients
imageDescriptorWithChannelFormat:width:height:featureChannels:
setNumberOfImages:
setChannelFormat:
setUsage:
setStorageMode:
channelFormat
setBuffers:offsets:withRange:
rowBytesForColumns:dataType:
setRows:
setThreadgroupMemoryLength:atIndex:
setK:
setN:
setM:
setResultMatrixOrigin:
encodeToCommandBuffer:encoder:leftMatrix:rightMatrix:resultMatrix:
setColumns:
setRowBytes:
setLeftMatrixOrigin:
setRightMatrixOrigin:
neuronInfo
lastObject
initWithDevice:weights:
decodeObjectForKey:
encodeObject:forKey:
arrayWithObjects:count:
initWithSourceImages:sourceStates:paddingPolicy:
initWithSource:transformProvider:outputSize:
nodeWithSource:transformProvider:outputSize:
nodeWithSource:outputSize:
privateInitWithSource:transformProvider:outputSize:
initWithSource:outputSize:
_transformProvider
_size
newFilterNode
initWithDevice:transformProvider:handle:outputSize:scaleClass:
setClipRect:
encodeInteger:forKey:
decodeIntegerForKey:
setOptions:
setEdgeMode:
transformForSourceImage:handle:
setScaleTransform:
_destSize
_filter
_handle
decodeObjectOfClass:forKey:
setDestinationFeatureChannelOffset:
setSourceFeatureChannelOffset:
setSourceFeatureChannelMaxCount:
padding
setDestinationImageAllocator:
setPadding:
encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
encodeToCommandBuffer:sourceImage:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImages:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:
cStringUsingEncoding:
sourceFeatureChannelOffset
imageForCommandBuffer:imageDescriptor:kernel:
arrayWithCapacity:
setObject:atIndexedSubscript:
imageBatchForCommandBuffer:imageDescriptor:kernel:count:
temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:
resultStateBatchForSourceImage:sourceStates:destinationImage:
encodingStorageSizeForSourceImage:sourceStates:destinationImage:
batchEncodingStorageSizeForSourceImage:sourceStates:destinationImage:
encodeToCommandBuffer:sourceImages:destinationImage:
copyToGradientState:sourceImages:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImages:sourceStates:destinationImage:
initWithObjects:count:
resultStateForSourceImages:sourceStates:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImages:sourceStates:destinationImage:
resultStateBatchForSourceImages:sourceStates:destinationImage:
_sliceCount
_info
usage
initialize:convDesc:weights:dataType:weightsLayout:fullyConnected:convolutionTranspose:preferredWeightsDataType:
initialize:weights:fullyConnected:convolutionTranspose:
weightsDataType
weightsOffset
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setGroups:
setStrideInPixelsX:
setStrideInPixelsY:
setDilationRateX:
setDilationRateY:
convolution
dataSource
convolutionTranspose
PeakAtWeightsWithConvolutionGradientState:
featureChannelFormat
preferredWeightsDataType
filterHandlesPlugin
initWithDevice:weights:fullyConnected:
initWithDevice:weights:convolutionTranspose:
reloadWeightsAndBiasesFromDataSource
reloadWeightsAndBiasesWithCommandBuffer:state:
biases
PeakAtWeightsWithConvolutionTransposeGradientState:
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
channelMultiplier
gradientOption
setGradientOption:
serializeWeightsAndBiases
setSerializeWeightsAndBiases:
_groups
_channelMultiplier
_gradientOption
_weights
_fullyConnected
_convolutionTranspose
_weightsDataType
_preferredWeightsDataType
_weightsLayout
_dataSource
_lock
_serializeWeightsAndBiases
TQ,R,N,V_groups
TQ,R,N,V_channelMultiplier
T@"<MPSCNNConvolutionDataSource>",R,&,N,V_dataSource
TQ,N,V_gradientOption
TB,N,V_serializeWeightsAndBiases
initWithSource:
nodeWithSource:
gradientFilterWithSource:
clipRectSource
setClipRectSource:
_clipRectSource
T{?={?=QQQ}{?=QQQ}},N,V_clipRectSource
gradientClass
initWithSourceGradient:sourceImage:gradientState:
initWithGradientImages:sourceImages:gradientState:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:
weight
setWeight:
_weight
Tf,N,V_weight
encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationImages:
setPrimarySourceFeatureChannelOffset:
setPrimarySourceFeatureChannelMaxCount:
setSecondarySourceFeatureChannelOffset:
setSecondarySourceFeatureChannelMaxCount:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
destinationImageAllocator
temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
resultStateBatchForPrimaryImage:secondaryImage:sourceStates:destinationImage:
encodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:
batchEncodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:
computeCommandEncoder
decodeInt32ForKey:
encodeInt32:forKey:
encodeToCommandBuffer:gradientMatrix:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultGradientForDataMatrix:resultGradientForGammaVector:resultGradientForBetaVector:
neuronType
neuronParameterA
neuronParameterB
neuronParameterC
setNeuronType:parameterA:parameterB:parameterC:
neuronA
setNeuronA:
neuronB
setNeuronB:
neuronC
setNeuronC:
epsilon
setEpsilon:
_neuronType
_neuronA
_neuronB
_neuronC
_epsilon
Ti,N,V_neuronType
Tf,N,V_neuronA
Tf,N,V_neuronB
Tf,N,V_neuronC
Tf,N,V_epsilon
synchronizeOnCommandBuffer:
dataWithBytes:length:
maskData
_maskStrideInPixels
_keepProbability
_commonBufferOffsetBytes
_commonMaskBuffer
initWithSeed:
initWithCoder:
supportsSecureCoding
TB,R
_rngState
resetSeedOnCommandBuffer:seed:
initWithDevice:destinationDataType:seed:
setDistributionType:
initWithDevice:keepProbability:seed:maskStrideInPixels:
initWithDevice:destinationDataType:state:distributionDescriptor:
synchronizeStateOnCommandBuffer:
exportState
privateResultStateForSourceImage:sourceStates:destinationImage:commandBuffer:isTemporary:
initWithDevice:keepProbability:state:maskStrideInPixels:
synchronizeRandomStateOnCommandBuffer:
exportRandomState
keepProbability
seed
maskStrideInPixels
_seed
_parallelGenerator
Tf,R,N,V_keepProbability
TQ,R,N,V_seed
T{?=QQQ},R,N,V_maskStrideInPixels
encodeToCommandBuffer:computeEncoder:destinationBuffer:destinationOffset:numEntries:
userDictionary
objectForKey:
setObject:forKey:
removeObjectForKey:
paddingWithMethod:
scaleFactorX
scaleFactorY
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:alignCorners:
alignCorners
_filterType
_scaleFactorX
_scaleFactorY
_alignCorners
Td,R,N,V_scaleFactorX
Td,R,N,V_scaleFactorY
TB,R,N,V_alignCorners
initWithDevice:integerScaleFactorX:integerScaleFactorY:
initWithDevice:integerScaleFactorX:integerScaleFactorY:alignCorners:
maxTextureWidth2D
maxTextureHeight2D
paddingMethod
primaryOffset
secondaryOffset
setPrimaryOffset:
setSecondaryOffset:
destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:
encodeToCommandEncoder:commandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeToCommandEncoder:commandBuffer:sourceGradient:sourceImage:gradientState:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeBatchToCommandEncoder:commandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
encodeBatchToCommandEncoder:commandBuffer:sourceGradients:sourceImages:gradientStates:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
resultStateForPrimaryImage:secondaryImage:sourceStates:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:
readGradientState:
isStateModified
kernelOffsetX
setKernelOffsetX:
kernelOffsetY
setKernelOffsetY:
_kernelOffsetX
_kernelOffsetY
Tq,N,V_kernelOffsetX
Tq,N,V_kernelOffsetY
nodeWithSource:a:
nodeWithSource:a:b:
nodeWithSource:aData:
nodeWithSource:a:b:c:
cnnNeuronDescriptorWithType:a:b:c:
nodeWithSource:descriptor:
initWithSource:type:a:b:c:
_type
Tf,R,N,V_a
Tf,R,N,V_b
Tf,R,N,V_c
cnnNeuronPReLUDescriptorWithData:noCopy:
initWithDevice:neuronDescriptor:
initWithSource:a:
initWithSource:a:b:
initWithSource:aData:
_aData
initWithSource:a:b:c:
initWithSourceGradient:sourceImage:gradientState:descriptor:
initWithGradientImages:forwardFilter:
nodeWithSourceGradient:sourceImage:gradientState:descriptor:
_descriptor
T@"MPSNNNeuronDescriptor",R,N,V_descriptor
initWithSource:resultWidth:resultHeight:resultFeatureChannels:
nodeWithSource:resultWidth:resultHeight:resultFeatureChannels:
_resultWidth
_resultHeight
_resultFeatureChannels
initWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
nodeWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
_edgeMode
useGridValueAsInputCoordinate
setUseGridValueAsInputCoordinate:
_useGridValueAsInputCoordinate
TB,N,V_useGridValueAsInputCoordinate
newMatrixFullyConnected
batchStart
encodeToCommandBuffer:inputMatrix:weightMatrix:biasVector:resultMatrix:
setNeuronToPReLUWithParametersA:
_encode
neuronAParamBuf
_plugin
sourceMatrixOrigin
encodeToCommandBuffer:inputMatrix:biasVector:resultMatrix:
batchSize
minimumLinearTextureAlignmentForPixelFormat:
matrixBytes
vectorBytes
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
newTextureWithDescriptor:offset:bytesPerRow:
numberOfFeatureChannels
gamma
beta
mean
variance
copy
initWithDevice:dataSource:fusedNeuronDescriptor:
encodeToCommandBuffer:sourceImage:inState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:inStates:destinationImages:
encodeToCommandBuffer:sourceImage:inState:
initDeferredWithDevice:numberOfFeatureChannels:epsilon:batchNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:epsilon:batchNormalization:
reloadDataSourceDeprecated:doReloadWeights:doReloadStats:
reloadGammaAndBetaFromDataSource
reloadMeanAndVarianceFromDataSource
updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
updateMeanAndVarianceWithCommandBuffer:batchNormalizationState:
updateGammaAndBetaWithBatchNormalizationState:
updateMeanAndVarianceWithBatchNormalizationState:
initWithBytes:length:
initWithDevice:dataSource:
encodeToCommandBuffer:sourceImage:batchNormalizationState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:destinationImages:
encodeToCommandBuffer:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:
reloadDataSource:
reloadGammaAndBetaWithCommandBuffer:gammaAndBetaState:
reloadMeanAndVarianceWithCommandBuffer:meanAndVarianceState:
_gamma
_beta
_meanDS
_varDS
_stateNeedsToLoad
_fusedNeuronDescriptor
_preluBuffer
_numberOfFeatureChannels
TQ,R,N,V_numberOfFeatureChannels
T@"<MPSCNNBatchNormalizationDataSource>",R,&,N,V_dataSource
initWithBytes:length:encoding:
initWithResource:weightsLayout:
initWithDevice:resourceList:convolution:weightsLayout:
temporaryStateWithCommandBuffer:resourceList:
primaryKernelWidth
primaryKernelHeight
primaryDilationRateX
primaryDilationRateY
temporaryStateWithCommandBuffer:resourceList:convolutionTranspose:convolutionGradientState:weightsLayout:
temporaryStateWithCommandBuffer:resourceList:convolutionTranspose:convolutionGradientState:
sourceWidth
sourceHeight
initWithDevice:resourceList:convolution:
initWithDevice:resourceList:convolutionTranspose:convolutionGradientState:
initWithDevice:resourceList:convolutionTranspose:convolutionGradientState:weightsLayout:
convolutionGradientState
_convolutionGradientState
T@"MPSCNNConvolutionGradientState",R,N,V_convolutionGradientState
T@"MPSCNNConvolutionTranspose",R,&,N,V_convolutionTranspose
weightsBufferLength
accumulatorPrecisionOption
setAccumulatorPrecisionOption:
initialize:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initialize:weights:fullyConnected:
fusedNeuronDescriptor
initWithDevice:weights:fullyConnected:convolutionTranspose:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:convolutionTranspose:
neuronABuffer
quantizationType
quantizationBuffer
encodeBatchToCommandBuffer:sourceImages:inStates:
encodeToCommandBuffer:sourceImage:sourceState:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationStateIsTemporary:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:kernelOffset:
sourceOffset
resourceListForSourceImages:destinationImages:
exportWeightsAndBiasesWithCommandBuffer:resultStateCanBeTemporary:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:
encodeToCommandBuffer:sourceImage:convolutionState:
encodeToCommandBuffer:sourceImage:convolutionGradientState:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationImages:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationStates:destinationStateIsTemporary:
reloadWeightsAndBiasesWithDataSource:
appendBatchBarrier
featureChannelsLayout
_featureChannelsLayout
_convolution
TQ,R,N,V_featureChannelsLayout
TQ,R,N
TQ,N
T@"<MPSCNNConvolutionDataSource>",R,&,N
initWithSources:
initWithLeftSource:rightSource:
resultState
nodeWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
nodeWithSources:
nodeWithLeftSource:rightSource:
gradientFilterWithSources:
gradientFiltersWithSources:
_primaryStrideInPixelsX
_primaryStrideInPixelsY
_secondaryStrideInPixelsX
_secondaryStrideInPixelsY
TQ,N,V_primaryStrideInPixelsX
TQ,N,V_primaryStrideInPixelsY
TQ,N,V_secondaryStrideInPixelsX
TQ,N,V_secondaryStrideInPixelsY
initWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
initWithGradientImages:sourceImages:binaryGradientState:paddingPolicy:
initWithGradientImages:forwardFilter:isSecondarySourceFilter:
secondaryKernelWidth
secondaryKernelHeight
secondaryDilationRateX
secondaryDilationRateY
initWithDevice:fusedNeuronDescriptor:
accumulatesOverBatch
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:
initWithSource:integerScaleFactorX:integerScaleFactorY:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:
initWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
initWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
nodeWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
setLearningRate:
setGradientRescale:
setApplyGradientClipping:
setGradientClipMax:
setGradientClipMin:
setRegularizationType:
setRegularizationScale:
initWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
initWithLearningRate:gradientRescale:regularizationType:regularizationScale:
optimizerDescriptorWithLearningRate:gradientRescale:regularizationType:regularizationScale:
optimizerDescriptorWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
learningRate
gradientRescale
applyGradientClipping
gradientClipMax
gradientClipMin
regularizationType
regularizationScale
_learningRate
_gradientRescale
_applyGradientClipping
_gradientClipMax
_gradientClipMin
_regularizationType
_regularizationScale
Tf,N,V_learningRate
Tf,N,V_gradientRescale
TB,N,V_applyGradientClipping
Tf,N,V_gradientClipMax
Tf,N,V_gradientClipMin
Tf,N,V_regularizationScale
TQ,N,V_regularizationType
initWithDevice:optimizerDescriptor:
Tf,R,N,V_learningRate
Tf,R,N,V_gradientRescale
Tf,R,N,V_gradientClipMax
Tf,R,N,V_gradientClipMin
Tf,R,N,V_regularizationScale
TQ,R,N,V_regularizationType
initWithDevice:momentumScale:useNesterovMomentum:optimizerDescriptor:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:resultValuesMatrix:
numberOfWeights
vectorDescriptorWithLength:dataType:
gradientForWeights
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:resultValuesVector:
gradientForBiases
numberOfBiases
batchNormalization
gradientForGamma
gradientForBeta
useNestrovMomentum
initWithDevice:learningRate:
initWithDevice:momentumScale:useNestrovMomentum:optimizerDescriptor:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:resultState:
momentumScale
useNesterovMomentum
_momentumScale
_useNesterovMomentum
Tf,R,N,V_momentumScale
TB,R,N,V_useNesterovMomentum
TB,R,N
initWithDevice:decay:epsilon:momentumScale:centered:optimizerDescriptor:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputSumOfSquaresMatrix:inputWeightedSumMatrix:inputMomentumMatrix:resultValuesMatrix:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:resultValuesVector:
initWithDevice:decay:epsilon:optimizerDescriptor:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputSumOfSquaresMatrix:resultValuesMatrix:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:inputWeightedSumVector:inputMomentumVector:resultValuesVector:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputSumOfSquaresVectors:resultState:
decay
centered
_decay
_centered
Td,R,N,V_momentumScale
TB,R,N,V_centered
Td,R,N,V_decay
Tf,R,N,V_epsilon
initWithDevice:beta1:beta2:epsilon:timeStep:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:inputVelocityVector:maximumVelocityVector:resultValuesVector:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:inputVelocityMatrix:maximumVelocityMatrix:resultValuesMatrix:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:inputVelocityVector:resultValuesVector:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:inputVelocityMatrix:resultValuesMatrix:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:inputVelocityVectors:resultState:
beta1
beta2
timeStep
setTimeStep:
_beta1
_beta2
_timeStep
_timeStepSemaphore
Td,R,N,V_beta1
Td,R,N,V_beta2
TQ,N,V_timeStep
initWithDevice:resultImage:resultImageIsNeeded:
initWithDevice:resultImage:
defaultAllocator
initWithDevice:resultImages:resultsAreNeeded:
encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
encodeBatchToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
containsValueForKey:
commandBufferWithUnretainedReferences
encodeToCommandBuffer:sourceImages:
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
storageMode
status
error
commit
graphWithDevice:resultImage:resultImageIsNeeded:
graphWithDevice:resultImage:
graphWithDevice:resultImages:resultsAreNeeded:
resultImageIsNeeded
sourceImageHandles
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
encodeBatchToCommandBuffer:sourceImages:sourceStates:
executeAsyncWithSourceImages:completionHandler:
reloadFromDataSources
readCountForSourceImageAtIndex:
readCountForSourceStateAtIndex:
outputStateIsTemporary
setOutputStateIsTemporary:
format
setFormat:
.cxx_destruct
.cxx_construct
_graph
_destinationImageAllocator
_format
_resultIsNeeded
_outputStateIsTemporary
T@"NSArray",R,C,N
T@"<MPSHandle>",R,N
TB,N,V_outputStateIsTemporary
T@"<MPSImageAllocator>",&,N,V_destinationImageAllocator
TQ,N,V_format
handle
sourceImages
sourceStates
intValue
numberWithInt:
allKeys
allValues
unsignedIntegerValue
paddingPolicy
prefetchStorageWithCommandBuffer:imageDescriptorList:
options
commitAndContinue
resultImage
imageAllocator
trainingStyle
setTrainingStyle:
resultStatesNoAllocate
wrapperWithFilterNode:
dataWithBytesNoCopy:length:freeWhenDone:
setWithObject:
unarchivedObjectOfClasses:fromData:device:error:
archivedDataWithRootObject:requiringSecureCoding:error:
initWithFilterNode:
node
wrapperWithResource:
_node
initWithCapacity:
null
isSubclassOfClass:
setWithArray:
decodeObjectOfClasses:forKey:
objectAtIndex:
kernelWidth
kernelHeight
subPixelScaleFactor
commandQueue
getGPUPriority
initWithDevice:kernelSize:
kernelSize
setBeta:
delta
setDelta:
_kernelSize
_delta
Tf,N,V_alpha
Tf,N,V_beta
Tf,N,V_delta
TQ,R,N,V_kernelSize
setP0:
setPm:
setPs:
Tf,N,V_p0
Tf,N,V_pm
Tf,N,V_ps
initWithSource:lossDescriptor:
initWithParent:
trainingGraphWithSourceGradient:nodeHandler:
nodeWithSource:lossDescriptor:
inputLabels
_labels
T@"MPSNNLabelsNode",R,&,N,V_labels
initWithDevice:lossDescriptor:
initWithSource:labels:weights:lossDescriptor:
lossType
reductionType
labelSmoothing
numberOfClasses
reduceAcrossBatch
initWithSourceGradient:sourceImage:labels:weights:gradientState:lossDescriptor:isLabelsGradientFilter:
initWithSourceGradient:sourceImage:labels:gradientState:lossDescriptor:isLabelsGradientFilter:
gradientFiltersWithSource:
nodeWithSource:labels:weights:lossDescriptor:
nodeWithSource:labels:lossDescriptor:
nodeWithSources:lossDescriptor:
initWithSource:labels:lossDescriptor:
initWithSources:lossDescriptor:
propertyCallBack
setPropertyCallBack:
_lossType
_reductionType
_labelSmoothing
_numberOfClasses
_propertyCallBack
_reduceAcrossBatch
TI,R,N,V_lossType
Ti,R,N,V_reductionType
TQ,R,N,V_numberOfClasses
TB,R,N,V_reduceAcrossBatch
Tf,R,N,V_weight
Tf,R,N,V_labelSmoothing
Tf,R,N,V_delta
T@"<MPSNNLossCallback>",&,N,V_propertyCallBack
encodeBatchToCommandBuffer:sourceImages:labels:weights:destinationStates:destinationImages:
nodeWithSourceGradient:sourceImage:labels:weights:gradientState:lossDescriptor:isLabelsGradientFilter:
nodeWithSourceGradient:sourceImage:labels:gradientState:lossDescriptor:isLabelsGradientFilter:
nodeWithSources:gradientState:lossDescriptor:isLabelsGradientFilter:
initWithSources:gradientState:lossDescriptor:isLabelsGradientFilter:
isLabelsGradientFilter
_isLabelsGradientFilter
TB,R,N,V_isLabelsGradientFilter
setComputeLabelGradients:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:labels:weights:sourceStates:destinationGradients:
encodeToCommandBuffer:sourceImage:labels:destinationImage:
lossImage
encodeBatchToCommandBuffer:sourceImages:labels:destinationImages:
cnnLossDataDescriptorWithData:layout:size:
layout
size
bytesPerRow
setBytesPerRow:
bytesPerImage
setBytesPerImage:
_data
_layout
_bytesPerRow
_bytesPerImage
TQ,R,N,V_layout
T{?=QQQ},R,N,V_size
TQ,N,V_bytesPerRow
TQ,N,V_bytesPerImage
cnnLossDescriptorWithType:reductionType:
setLabelSmoothing:
setNumberOfClasses:
setLossType:
setReductionType:
setReduceAcrossBatch:
TI,N,V_lossType
Ti,N,V_reductionType
TB,N,V_reduceAcrossBatch
Tf,N,V_labelSmoothing
TQ,N,V_numberOfClasses
initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:
appendTexture:
initWithDevice:resourceList:
writeBytes:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:
initWithDevice:labelsDescriptor:
initWithDevice:lossImageSize:labelsImage:weightsImage:
labelsImage
weightsImage
_lossImageSize
_isScalarLoss
_userData
_userDataLayout
_numFeatureChannels_labels
_numFeatureChannels_loss
_userLabelsImage
_userWeightsImage
_hasStateWeights
_computeNonZeroWeights
initWithDevice:descriptor:
countByEnumeratingWithState:objects:count:
resultStateForSourceImage:sourceStates:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:
encodeToCommandBuffer:sourceImage:labels:
encodeBatchToCommandBuffer:sourceImages:labels:
_reductionBuffer
_firstLossImage
_lossLabels
encodeBatchToCommandBuffer:sourceImages:labels:weights:destinationStates:destinationStateIsTemporary:
_propertyCallback
scalarWeightForSourceImage:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:labels:weights:sourceStates:
computeLabelGradients
_firstLossGradientImage
_computeLabelGradients
TB,N,V_computeLabelGradients
cnnNeuronDescriptorWithType:a:b:
_neuronFilter
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:
numberOfGroups
initWithDevice:numberOfFeatureChannels:groupNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:groupNormalization:
setNumberOfGroups:
updateGammaAndBetaWithCommandBuffer:groupNormalizationStateBatch:
updateGammaAndBetaWithGroupNormalizationStateBatch:
reloadDataSourceDeprecated:
_numberOfGroups
T@"<MPSCNNGroupNormalizationDataSource>",R,&,N,V_dataSource
resourceListWithBufferSizes:
groupNormalization
_groupNormalization
T@"MPSCNNGroupNormalization",R,&,N,V_groupNormalization
T@"<MTLBuffer>",R,N
dilationRateX
dilationRateY
_fwdPermuteOrder
_revPermuteOrder
subarrayWithRange:
encodeBatchInternalToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:srcSize:destSize:testClipRect:testMaxClipRect:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:
dimensionOrder
setDimensionOrder:
_dimensionOrder
T{MPSNNDimensionOrder=[4Q]},N,V_dimensionOrder
_revPermuteKernel
setImageAllocator:
initWithHandle:
nodeWithHandle:
exportedNodeWithHandle:
debugQuickLookObject
setHandle:
exportFromGraph
setExportFromGraph:
synchronizeResource
setSynchronizeResource:
stopGradient
setStopGradient:
_parent
_imageAllocator
_clientCount
_exportFromGraph
_synchronize
_stopGradient
_initializedWithParent
T@"<MPSHandle>",&,N,V_handle
T@"<MPSImageAllocator>",&,N,V_imageAllocator
TB,N,V_exportFromGraph
TB,N,V_synchronize
TB,N,V_stopGradient
setPaddingPolicy:
setArray:
initWithObjects:
resultStates
_sourceImages
_sourceStates
_resultImage
_resultStates
_paddingPolicy
_label
T@"MPSNNImageNode",R,N,V_resultImage
T@"MPSNNStateNode",R,N
T@"NSArray",R,N
T@"<MPSNNPadding>",&,N,V_paddingPolicy
T@"NSString",C,V_label
arrayByAddingObjectsFromArray:
initWithDevice:sourceIndex:
_sourceIndex
initWithDevice:numberOfFeatureChannels:instanceNormalization:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:instanceNormalization:
updateGammaAndBetaWithCommandBuffer:instanceNormalizationStateBatch:
updateGammaAndBetaWithInstanceNormalizationStateBatch:
T@"<MPSCNNInstanceNormalizationDataSource>",R,&,N,V_dataSource
arrayWithObjects:
initWithResources:
temporaryStateWithCommandBuffer:bufferSize:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:
initWithDevice:bufferSize:
initWithGamma:beta:
_initialized
instanceNormalization
_instanceNormalization
T@"MPSCNNInstanceNormalization",R,&,N,V_instanceNormalization
initWithDevice:resizeWidth:resizeHeight:numberOfRegions:regions:
resizeWidth
resizeHeight
numberOfRegions
regions
_resizeWidth
_resizeHeight
_numberOfRegions
_regions
_gpuRegions
TQ,R,N,V_resizeWidth
TQ,R,N,V_resizeHeight
TQ,R,N,V_numberOfRegions
Tr^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}},R,N,V_regions
newPlugin
newCNNPoolingAverageWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
encodeBatchToCommandBuffer:computeCommandEncoder:options:sourceTextures:sourceInfo:destinationTextures:destinationInfo:zeroPadSizeX:zeroPadSizeY:predicationBuffer:predicationOffset:
pluginSupportsBatchEncode
newCNNDilatedPoolingMaxWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
setResourceOptions:
resourceListWithTextureDescriptors:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:destinationGradient:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:destinationGradients:
inverse
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
batchRepresentation
encodeInternalToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:subBatchIndex:batchSize:clipRect:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:subBatchIndex:batchSize:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
encodeInternalBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:destinationImages:clipRect:
encodeBatchToCommandBuffer:computeCommandEncoder:options:pluginOptions:primaryTextures:primaryInfo:secondaryTextures:secondaryInfo:destinationTextures:destinationInfo:predicationBuffer:predicationOffset:
primarySourceRegionForDestinationSize:
secondarySourceRegionForDestinationSize:
encodeToCommandBuffer:primaryImage:secondaryImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:destinationImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:destinationImages:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
primaryEdgeMode
setPrimaryEdgeMode:
secondaryEdgeMode
setSecondaryEdgeMode:
isBackwards
_primaryOffset
_secondaryOffset
_clipRect
_destinationFeatureChannelOffset
_primarySourceFeatureChannelOffset
_secondarySourceFeatureChannelOffset
_primarySourceFeatureChannelMaxCount
_secondarySourceFeatureChannelMaxCount
_pluginSupportsBatchEncode
_primaryKernelWidth
_primaryKernelHeight
_secondaryKernelWidth
_secondaryKernelHeight
_primaryDilationRateX
_primaryDilationRateY
_secondaryDilationRateX
_secondaryDilationRateY
_isBackwards
_supportsBroadcasting
_padding
_primaryEdgeMode
_secondaryEdgeMode
_checkFlags
_batchEncode
_encodeData
_pluginOptions
T{?=qqq},N,V_primaryOffset
T{?=qqq},N,V_secondaryOffset
T{?={?=QQQ}{?=QQQ}},N,V_clipRect
TQ,N,V_destinationFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelOffset
TQ,N,V_secondarySourceFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelMaxCount
TQ,N,V_secondarySourceFeatureChannelMaxCount
TQ,N,V_primaryEdgeMode
TQ,N,V_secondaryEdgeMode
TQ,R,N,V_primaryKernelWidth
TQ,R,N,V_primaryKernelHeight
TQ,R,N,V_secondaryKernelWidth
TQ,R,N,V_secondaryKernelHeight
TQ,R,N,V_primaryDilationRateX
TQ,R,N,V_primaryDilationRateY
TQ,R,N,V_secondaryDilationRateX
TQ,R,N,V_secondaryDilationRateY
TB,R,N,V_isBackwards
T@"<MPSNNPadding>",&,N,V_padding
primaryStrideInPixels
secondaryStrideInPixels
initWithFilter:
subImageWithFeatureChannelRange:
reset
_batchNormalization
_accumulationCount
T@"MPSCNNBatchNormalization",R,&,N,V_batchNormalization
initWithMean:variance:
initWithDevice:resizeWidth:resizeHeight:alignCorners:
initWithSource:keepProbability:
initWithSource:keepProbability:seed:maskStrideInPixels:
nodeWithSource:keepProbability:
nodeWithSource:keepProbability:seed:maskStrideInPixels:
_maskStride
T{?=QQQ},R,N,V_maskStride
initWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
nodeWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
initializeWithType:a:b:c:
initWithType:a:b:c:
initializeWithPReLUWithData:noCopy:
initWithPReLUWithData:noCopy:
initWithBytesNoCopy:length:freeWhenDone:
cnnNeuronDescriptorWithType:a:
cnnNeuronDescriptorWithType:
setData:
_noCopy
_count
Tf,N,V_a
Tf,N,V_b
Tf,N,V_c
T@"NSData",&,N,V_data
initializeWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
initializeWithNeuronType:neuronParameterA:count:
newCNNNeuronWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
newCNNNeuronWithNeuronType:neuronParameterAArray:count:
minBufferNoCopyAlignmentBytes
newBufferWithBytesNoCopy:length:options:deallocator:
initWithBytesNoCopy:length:deallocator:
privateInitWithDevice:a:b:c:type:
privateInitWithDevice:a:count:type:
Ti,R,N,V_neuronType
T@"NSData",R,&,N,V_data
initWithDevice:a:b:
initWithDevice:neuronDescriptor:aArray:
initWithDevice:a:
initWithDevice:a:count:
initWithDevice:a:b:c:
initWithSource:dimensionOrder:
nodeWithSource:dimensionOrder:
_order
initWithDevice:alpha:
_filters
initWithDevice:dataLayout:
alphaForSourceImage:destinationImage:
encodeBatchToCommandBuffer:encoder:sourceImages:destinationMatrix:
matrixDescriptorWithRows:columns:matrices:rowBytes:matrixBytes:dataType:
encodeBatchToCommandBuffer:encoder:sourceMatrix:destinationImages:
initWithDevice:copyRows:copyColumns:sourcesAreTransposed:destinationsAreTransposed:
descriptorWithSourceMatrix:destinationMatrix:offsets:
encodeToCommandBuffer:encoder:copyDescriptor:rowPermuteIndices:rowPermuteOffset:columnPermuteIndices:columnPermuteOffset:
initWithDevice:count:rows:columns:transpose:
encodeToCommandBuffer:encoder:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
setWeightValue:
initWithDevice:reduceOperation:
_reduceOp
_weightValue
T{?=qqq},N
weight:
reduceOp
primarySourceClipRect
setPrimarySourceClipRect:
secondarySourceClipRect
setSecondarySourceClipRect:
_clipRectPrimarySource
_secondarySourceClipRect
_primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_secondarySourceClipRect
initWithDevice:doWeightedSumByNonZeroWeights:
doWeightedSumByNonZeroWeights
initWithDevice:windowInX:windowInY:strideInX:strideInY:
windowInX
setWindowInX:
windowInY
setWindowInY:
strideInX
setStrideInX:
strideInY
setStrideInY:
_windowInX
_windowInY
_strideInX
_strideInY
TQ,N,V_windowInX
TQ,N,V_windowInY
TQ,N,V_strideInX
TQ,N,V_strideInY
newTextureViewWithPixelFormat:
newDescriptorWithNeuronInfo:
setBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:
initWithSource:neuronInfo:batchNorm:
_source
encodeToCommandEncoder:commandBuffer:sourceImage:inState:
encodeToCommandEncoder:commandBuffer:sourceImage:inState:destinationImage:
destinationImageWithCommandBuffer:sourceImage:inState:
encodeToCommandEncoder:commandBuffer:sourceImage:sourceState:destinationState:destinationStateIsTemporary:
encodeToCommandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:
encodeToCommandEncoder:commandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:
encodeInternalToCommputeEncoder:commandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:clipRect:shouldHandleCompoundImageNatively:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:inStates:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:sourceStates:destinationStates:destinationStateIsTemporary:
encodeInternalBatchToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:clipRect:
encodeBatchToCommandBuffer:computeCommandEncoder:options:pluginOptions:sourceTextures:sourceInfo:destinationTextures:destinationInfo:predicationBuffer:predicationOffset:
sourceRegionForDestinationSize:
encodeToCommandEncoder:commandBuffer:sourceImage:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationState:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationStates:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
sourcePositionOfTopLeftCornerOfFilterWindow
edgeMode
_offset
_sourceFeatureChannelOffset
_sourceFeatureChannelMaxCount
_kernelWidth
_kernelHeight
_strideInPixelsX
_strideInPixelsY
_dilationRateX
_dilationRateY
_maxBatchSize
T{?=qqq},N,V_offset
TQ,N,V_sourceFeatureChannelOffset
TQ,N,V_sourceFeatureChannelMaxCount
TQ,N,V_edgeMode
TQ,R,N,V_kernelWidth
TQ,R,N,V_kernelHeight
TQ,R,N,V_strideInPixelsX
TQ,R,N,V_strideInPixelsY
TQ,R,N,V_dilationRateX
TQ,R,N,V_dilationRateY
initWithPaddingMethod:
initWithPaddingLeft:paddingRight:paddingTop:paddingBottom:
paddingForTensorflowAveragePooling
paddingForTensorflowAveragePoolingValidOnly
zeroPaddingWithTopAmount:bottomAmount:leftAmount:rightAmount:
_method
_mpsOwned
_paddingLeft
_paddingRight
_paddingTop
_paddingBottom
initWithSource:filterSize:
initWithSource:filterSize:stride:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
nodeWithSource:filterSize:
nodeWithSource:filterSize:stride:
initWithSource:filterSize:stride:dilationRate:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSource:filterSize:stride:dilationRate:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
encodeToCommandBuffer:gradientMatrix:inputMatrix:biasVector:resultGradientForDataMatrix:resultGradientForBiasVector:
decodeIntForKey:
encodeToCommandBuffer:sourceImages:inState:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImages:inState:destinationImage:
encodeToCommandBuffer:sourceImages:inState:
encodeToCommandEncoder:commandBuffer:sourceImages:inState:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:sourceStates:
encodeToCommandEncoder:commandBuffer:sourceImages:destinationState:destinationStateIsTemporary:
initWithSourceCount:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:
initWithDevice:sourceCount:
offsetAtIndex:
setOffset:atIndex:
sourceFeatureChannelOffsetAtIndex:
setSourceFeatureChannelOffset:atIndex:
sourceFeatureChannelMaxCountAtIndex:
setSourceFeatureChannelMaxCount:atIndex:
edgeModeAtIndex:
setEdgeMode:atIndex:
kernelWidthAtIndex:
setKernelWidth:atIndex:
setKernelWidth:
kernelHeightAtIndex:
setKernelHeight:atIndex:
setKernelHeight:
strideInPixelsXatIndex:
setStrideInPixelsX:atIndex:
strideInPixelsYatIndex:
setStrideInPixelsY:atIndex:
dilationRateXatIndex:
setDilationRateX:atIndex:
dilationRateYatIndex:
setDilationRateY:atIndex:
encodeToCommandEncoder:commandBuffer:sourceImages:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImages:
encodeToCommandBuffer:sourceImages:destinationState:destinationStateIsTemporary:
sourceCount
_srcInfo
_srcCount
TQ,R,N,V_srcCount
_reductionKernel
initWithSource:kernelSize:
nodeWithSource:kernelSize:
TQ,N,V_kernelWidth
TQ,N,V_kernelHeight
initWithSourceGradient:sourceImage:gradientState:kernelSize:
nodeWithSourceGradient:sourceImage:gradientState:kernelSize:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
kernelSizeInFeatureChannels
setKernelSizeInFeatureChannels:
_kernelSizeInFeatureChannels
TQ,N,V_kernelSizeInFeatureChannels
initWithSource:dataSource:
nodeWithSource:dataSource:
_trainingStyle
TQ,N,V_trainingStyle
calculateStatistics
arrayByAddingObject:
flags
setFlags:
_flags
TQ,N,V_flags
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initWithSource:weights:
initWithSource:weights:state:
nodeWithSource:weights:
convolutionState
accumulatorPrecision
setAccumulatorPrecision:
_accumulatorPrecision
T@"MPSCNNConvolutionStateNode",R,N
T@"<MPSCNNConvolutionDataSource>",R,N,V_weights
TQ,N,V_accumulatorPrecision
T@"MPSCNNConvolutionGradientStateNode",R,N
wrapperForDataSource:
appendNeuron:
appendBatchNorm:
initWithSourceGradient:sourceImage:convolutionGradientState:weights:
initWithSourceGradient:sourceImage:gradientState:weights:
nodeWithSourceGradient:sourceImage:convolutionGradientState:weights:
initWithSourceGradient:sourceImage:convolutionTransposeGradientState:weights:
nodeWithSourceGradient:sourceImage:convolutionTransposeGradientState:weights:
initWithSource:weights:scaleValue:type:flags:
initWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
nodeWithSource:weights:scaleValue:type:flags:
nodeWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
_scaleValue
_outputBiasTerms
_outputScaleTerms
_inputBiasTerms
_inputScaleTerms
initWithDevice:convolutionData:scaleValue:type:flags:
initWithDevice:convolutionData:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
initWithSource:convolutionGradientState:weights:
initWithSource:convolutionState:weights:
nodeWithSource:convolutionGradientState:weights:
nodeWithSource:convolutionState:weights:
initWithSource:alpha:
nodeWithSource:alpha:
Tf,R,N,V_alpha
T@"<MPSNNGramMatrixCallback>",&,N,V_propertyCallBack
initWithSourceGradient:sourceImage:gradientState:alpha:
nodeWithSourceGradient:sourceImage:gradientState:alpha:
initWithDataSource:
initialize
appendNeuronDescriptor:
setFusedNeuronDescriptor:
hasBatchNorm
_batchNorm
_neuron
_loadCount
isEqualToString:
setAnchorBoxes:
setNumberOfAnchorBoxes:
setScaleXY:
setScaleWH:
setScaleNoObject:
setScaleObject:
setScaleClass:
setMinIOUForObjectPresence:
setMaxIOUForObjectAbsence:
setRescore:
setXYLossDescriptor:
setWHLossDescriptor:
setConfidenceLossDescriptor:
setClassesLossDescriptor:
initWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
cnnLossDescriptorWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
XYLossDescriptor
WHLossDescriptor
confidenceLossDescriptor
classesLossDescriptor
rescore
scaleXY
scaleWH
scaleNoObject
scaleObject
scaleClass
minIOUForObjectPresence
maxIOUForObjectAbsence
anchorBoxes
numberOfAnchorBoxes
_XYLossDescriptor
_WHLossDescriptor
_confidenceLossDescriptor
_classesLossDescriptor
_rescore
_scaleXY
_scaleWH
_scaleNoObject
_scaleObject
_scaleClass
_minIOUForObjectPresence
_maxIOUForObjectAbsence
_anchorBoxes
_numberOfAnchorBoxes
T@"MPSCNNLossDescriptor",&,N,V_XYLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_WHLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_confidenceLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_classesLossDescriptor
TB,N,V_rescore
Tf,N,V_scaleXY
Tf,N,V_scaleWH
Tf,N,V_scaleNoObject
Tf,N,V_scaleObject
Tf,N,V_scaleClass
Tf,N,V_minIOUForObjectPresence
Tf,N,V_maxIOUForObjectAbsence
TQ,N,V_numberOfAnchorBoxes
T@"NSData",&,N,V_anchorBoxes
initializeSupportFiltersWithDevice:lossDescriptor:
countPresetobjectsSourceImages:labels:
readBytes:dataLayout:imageIndex:
lossXY
lossWH
lossConfidence
lossClasses
_lossXY
_lossWH
_lossConfidence
_lossClasses
_countOfPresentObjects
_encodingSemaphore
_firstLossTexture
T@"MPSCNNLoss",R,&,N,V_lossXY
T@"MPSCNNLoss",R,&,N,V_lossWH
T@"MPSCNNLoss",R,&,N,V_lossConfidence
T@"MPSCNNLoss",R,&,N,V_lossClasses
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setNeuron:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:postFilters:
setNeuronParameterA:
setNeuronParameterB:
setNeuronParameterC:
setNeuronType:parameterA:parameterB:
hasBatchNormData
setFeatureChannelsLayout:
neuron
_batchNormalizationData
_deprecated_neuron
_subPixelScaleFactor
_depthWiseConvolution
_neuron_deprecated
TQ,N,V_featureChannelsLayout
TQ,N,V_strideInPixelsX
TQ,N,V_strideInPixelsY
TQ,N,V_groups
TQ,N,V_dilationRateX
TQ,N,V_dilationRateY
T@"MPSNNNeuronDescriptor",&,N,V_fusedNeuronDescriptor
T@"MPSCNNNeuron",&,N,V_neuron_deprecated
setSubPixelScaleFactor:
initWithSourceWidth:sourceHeight:kernelWidth:kernelHeight:sourceOffset:
_originalConvolutionSourceWidth
_originalConvolutionSourceHeight
_srcOffset
T{?=qqq},R,N,V_srcOffset
TQ,R,N,V_originalConvolutionSourceWidth
TQ,R,N,V_originalConvolutionSourceHeight
temporaryStateWithCommandBuffer:resourceList:convolution:
temporaryStateWithCommandBuffer:resourceList:convolution:weightsLayout:
numberOfWeightGradients
gradientForWeightsLayout
numberOfBiasGradients
_intermediateWeightsBuffer
_intermeidateBiasesBuffer
_numReductionBlocks
_needReductionInN
_needReductionInXY
_dimSizeN
T@"MPSCNNConvolution",R,&,N,V_convolution
TI,R,N
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:strideInPixelsX:strideInPixelsY:groups:dilationRateX:dilationRateY:channelMultiplier:subPixelScaleFactor:isFullyConnected:isConvolutionTranspose:fusedNeuronDescriptor:
isFullyConnected
isConvolutionTranspose
_isFullyConnected
_isConvolutionTranspose
T@"MPSNNNeuronDescriptor",R,N,V_fusedNeuronDescriptor
TQ,R,N,V_subPixelScaleFactor
TB,R,N,V_isFullyConnected
TB,R,N,V_isConvolutionTranspose
PrepareAndLoadData:dataType:weightsLayout:weights:biases:quantizationType:ranges:lookUpTable:convertFloat32Weights:
initialize:convolutionDescriptor:kernelWeights:dataType:weightsLayout:range:lookUpTable:qType:biasTerms:flags:fullyConnected:convolutionTranspose:preferredWeightsDataType:
initializeWithDevice:weights:fullyConnected:convolutionTranspose:
biasesOffset
initWithDevice:cnnConvolutionDescriptor:weightsDataType:weightsLayout:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:weightsDataType:weightsLayout:
encodeToCommandBuffer:sourceImage:destinationImage:state:
_convertFloat32Weights
_qWts
_qType
_scaleFactor
_biasOriginal
_neuronABuffer
_accumulatorPrecisionOption
TQ,R,N,V_scaleFactor
T@"MPSCNNNeuron",R,N,V_neuron_deprecated
Ti,R,N
Tf,R,N
bufferSizeAtIndex:
initializeWithWeightsCount:weightsOffset:weightsDataType:weightsLayout:biasesCount:biasesOffset:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:weightsDataType:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:
initWithWeights:biases:weightsDataType:
initWithWeights:biases:weightsDataType:weightsLayout:
initWithDevice:cnnConvolutionDescriptor:weightsDataType:
initWithWeights:biases:
initWithDevice:cnnConvolutionDescriptor:
initWithWeights:weightsOffset:biases:biasesOffset:cnnConvolutionDescriptor:
initWithWeights:weightsOffset:weightsDataType:weightsLayout:biases:biasesOffset:cnnConvolutionDescriptor:
_numberOfWeights
_numberOfBiases
_weightsOffset
_biasesOffset
enumerateObjectsUsingBlock:
encodeToCommandBuffer:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
transpose
_transpose
_rows
_columns
_resultMatrixOrigin
TQ,R,N,V_rows
TQ,R,N,V_columns
TQ,R,N,V_count
TB,R,N,V_transpose
T{?=QQQ},N,V_resultMatrixOrigin
PeakAtWeights:
_convolutionGradient
newCNNSoftMax
encodeToCommandBuffer:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultMatrix:
computeStatistics
setComputeStatistics:
_computeStatistics
TB,N,V_computeStatistics
_destFeatureChannels
_srcSize
_sourceFeatureChannels
_initOnce
_provenance
_primarySrcSize
_primarySourceFeatureChannels
_secondarySrcSize
_secondarySourceFeatureChannels
_srcSizes
initWithDeviceImpl:convolutionDescriptor:kernelWeights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
createBuffersFromkernelWeights:inputBiasTerms:inputScaleTerms:outputBiasTerms:outputScaleTerms:useHalfPrecision:
copyBuffer:device:
initWithDeviceImpl:convolutionDescriptor:kernelWeights:biasTerms:scaleValue:type:flags:
_neuronInfo
_filterStride
_outputbias
_outputScale
_inputbias
_inputScale
_convType
_poolingFilter
_outputScaleValue
initWithDeviceImpl:convolutionDescriptor:kernelWeights:scaleValue:type:flags:
doesNotRecognizeSelector:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:pluginOptions:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
encodeWithFilter:encoder:commandBuffer:callInfo:
encodeBatchWithFilter:encoder:commandBuffer:callInfo:
encodeToCommandBuffer:computeCommandEncoder:options:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:
r^{MPSLibraryInfo=iI*^?{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}}24@0:8^v16
@24@0:8@16
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@32@0:8^{_NSZone=}16@24
@32@0:8@16@24
v24@0:8@16
Q16@0:8
v24@0:8Q16
d16@0:8
v24@0:8d16
@16@0:8
@48@0:8@16@24Q32^{?=qqq}40
@56@0:8@16@24Q32Q40Q48
@68@0:8@16@24^@32B40Q44Q52Q60
@64@0:8@16@24Q32^{?=qqq}40^{?=qqq}48^{?=qqq}56
v16@0:8
{MPSImageCoordinate="x"Q"y"Q"channel"Q}
@72@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48@72
B16@0:8
@40@0:8@16@24@32
@48@0:8@16@24@32@40
{MPSImageCoordinate=QQQ}16@0:8
v40@0:8{MPSImageCoordinate=QQQ}16
f16@0:8
v20@0:8f16
@"<MTLBuffer>"
@40@0:8@16Q24Q32
@56@0:8@16Q24Q32Q40Q48
v48@0:8Q16Q24Q32Q40
{?=QQQ}16@0:8
v40@0:8{?=QQQ}16
{?="width"Q"height"Q"depth"Q}
@72@0:8@16Q24Q32Q40Q48Q56Q64
@28@0:8@16i24
@60@0:8@16@24@32@40@48B56
@56@0:8@16@24@32@40@48
@32@0:8@16i24B28
@"MPSNNReduceUnary"
@28@0:8@16B24
@24@0:8Q16
@48@0:8@16^@24^@32B40i44
@56@0:8@16@24^@32^@40B48i52
@36@0:8@16@24B32
@"MPSMatrix"
v20@0:8B16
@"<MPSCNNConvolutionDataSource>"
@32@0:8Q16Q24
i16@0:8
v20@0:8i16
@24@0:8^{_NSZone=}16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
I16@0:8
^v16@0:8
^f16@0:8
^16@0:8
B32@0:8@16@24
@"MPSCNNConvolutionDescriptor"16@0:8
@"MPSCNNConvolutionWeightsAndBiasesState"40@0:8@"<MTLCommandBuffer>"16@"MPSCNNConvolutionGradientState"24@"MPSCNNConvolutionWeightsAndBiasesState"32
B32@0:8@"MPSCNNConvolutionGradientState"16@"MPSCNNConvolutionWeightsAndBiasesState"24
@32@0:8^{_NSZone=}16@"<MTLDevice>"24
@36@0:8@16B24@28
@"MPSCNNConvolutionDescriptor"
v72@0:8@16@24^Q32@40^Q48@56@64
@32@0:8@16Q24
@"MPSMatrixMultiplication"
v28@0:8@16I24
v36@0:8@16I24@28
v76@0:8@16@24Q32@40B48{?=QQQ}52
v88@0:8@16@24^Q32@40^Q48@56@64@72@80
v112@0:8@16@24^Q32@40^Q48@56^Q64@72@80@88@96@104
v72@0:8@16@24@32@40@48@56@64
@28@0:8Q16B24
@36@0:8@16Q24B32
@"NSMutableArray"
@56@0:8@16@24{?=QQQ}32
@48@0:8@16{?=QQQ}24
@"<MPSImageTransformProvider>"
@72@0:8@16@24@32{?=QQQ}40#64
@"MPSImageScale"
@"<MPSHandle>"
v40@0:8@16@24@32
^{MPSSliceInfo=QQ}
v60@0:8@16@24^v32I40I44B48B52I56
v40@0:8@16@24B32B36
v32@0:8@16@24
Q40@0:8@16@24@32
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{?={?=QQQ}{?=QQQ}}16@0:8
v64@0:8{?={?=QQQ}{?=QQQ}}16
{?="origin"{?="x"Q"y"Q"z"Q}"size"{?="width"Q"height"Q"depth"Q}}
v96@0:8@16@24@32@40@48@56@64@72@80@88
v32@0:8i16f20f24f28
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"MPSParallelRandomMTGP32State"
v32@0:8@16Q24
@60@0:8@16f24Q28{?=QQQ}36
@60@0:8@16f24@28{?=QQQ}36
@52@0:8@16@24@32@40B48
@"MPSParallelRandomMTGP32"
@52@0:8@16Q24Q32Q40B48
@44@0:8@16Q24Q32B40
v64@0:8@16@24@32@40@48@56
v28@0:8@16B24
q16@0:8
v24@0:8q16
@40@0:8@16i24f28f32f36
@28@0:8@16f24
@32@0:8@16f24f28
@"NSData"
@36@0:8@16f24f28f32
@"MPSNNNeuronDescriptor"
@48@0:8@16Q24Q32Q40
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48Q72
@"<MPSExternalMatrixFullyConnected>"
@"MPSCNNNormalizationGammaAndBetaState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
@"MPSCNNNormalizationMeanAndVarianceState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
B24@0:8@"MPSCNNBatchNormalizationState"16
@44@0:8@16@24^@32B40
v32@0:8@16B24B28
@"<MPSCNNBatchNormalizationDataSource>"
@52@0:8@16@24@32@40I48
@28@0:8@16I24
@44@0:8@16@24@32I40
@"MPSCNNConvolutionTranspose"
@"MPSCNNConvolutionGradientState"
@56@0:8@16@24r^f32r^f40Q48
@60@0:8@16@24r^f32r^f40Q48B56
@52@0:8@16@24@32^@40B48
@"MPSCNNConvolution"
@44@0:8@16@24@32B40
@56@0:8@16@24@32d40d48
@36@0:8f16f20Q24f32
@48@0:8f16f20B24f28f32Q36f44
@40@0:8@16f24B28@32
@44@0:8@16d24f32@36
@56@0:8@16d24f32d36B44@48
@60@0:8@16d24d32f40Q44@52
@"NSObject<OS_dispatch_semaphore>"
@48@0:8@16@24@32Q40
@"MPSImage"40@0:8@"<MTLCommandBuffer>"16@"MPSImageDescriptor"24@"MPSKernel"32
@"NSArray"48@0:8@"<MTLCommandBuffer>"16@"MPSImageDescriptor"24@"MPSKernel"32Q40
@40@0:8@16@24^B32
@32@0:8@16@?24
Q24@0:8Q16
{Graph="_graphSourceImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphSourceStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphIntermediateImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graph"@"MPSNNGraph""_filters"{NodeList<FilterGraphNode *>="_items"^^{FilterGraphNode}"_count"Q"_storageSize"Q}"_images"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_states"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_cpuUpdateSem"@"NSObject<OS_dispatch_semaphore>""_graphNull"@"NSNull"}
@"<MPSImageAllocator>"
@24@0:8^v16
@"MPSNNLabelsNode"
@"MPSCNNLossDescriptor"
@"MPSCNNYOLOLossDescriptor"
@"<MPSNNLossCallback>"
@68@0:8@16@24@32@40@48@56B64
@56@0:8@16Q24{?=QQQ}32
@24@0:8I16i20
v20@0:8I16
@64@0:8@16{?=QQQ}24@48@56
@"MPSImage"
@"MPSCNNLossLabels"
@60@0:8@16@24@32@40^@48B56
@64@0:8@16@24@32@40@48@56
@"<MTLTexture>"
@"MPSCNNNeuron"
@"MPSCNNNormalizationGammaAndBetaState"32@0:8@"<MTLCommandBuffer>"16@"NSArray"24
B24@0:8@"NSArray"16
@"<MPSCNNGroupNormalizationDataSource>"
@40@0:8@16Q24@32
@"MPSCNNGroupNormalization"
{MPSNNDimensionOrder="dimensions"[4Q]}
v200@0:8@16@24@32@40@48{?=QQQ}56{?=QQQ}80{?={?=QQQ}{?=QQQ}}104{?={?=QQQ}{?=QQQ}}152
{MPSNNDimensionOrder=[4Q]}16@0:8
v48@0:8{MPSNNDimensionOrder=[4Q]}16
@"MPSNNPermute"
@"MPSNNFilterNode"
^{FilterGraphNode=}16@0:8
@"MPSNNImageNode"
@"<MPSNNPadding>"
@"NSString"
@"<MPSCNNInstanceNormalizationDataSource>"
@"MPSCNNInstanceNormalization"
@56@0:8@16Q24Q32Q40r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}48
r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}16@0:8
^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}
^{Region_params=}
@"MPSImageDescriptor"48@0:8@"NSArray"16@"NSArray"24@"MPSKernel"32@"MPSImageDescriptor"40
{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}40@0:8{?=QQQ}16
v128@0:8@16@24@32@40@48@56Q64Q72{?={?=QQQ}{?=QQQ}}80
v80@0:8@16@24@32@40@48@56Q64Q72
v112@0:8@16@24@32@40@48@56{?={?=QQQ}{?=QQQ}}64
Q48@0:8@16@24@32@40
{?=qqq}16@0:8
v40@0:8{?=qqq}16
{?="x"q"y"q"z"q}
@"MPSExternalCNNBinary"
@44@0:8@16Q24f32@36
@"MPSCNNBatchNormalization"
@76@0:8@16@24@32f40Q44{?=QQQ}52
@32@0:8i16f20f24f28
@28@0:8i16f20f24
@24@0:8i16f20
@20@0:8i16
{NeuronInfo=ifff@}16@0:8
@40@0:8@16f24f28f32i36
@44@0:8@16r^f24Q32i40
v36@0:8i16r^f20Q28
@40@0:8@16@24r^f32
@40@0:8@16r^f24Q32
@56@0:8@16{MPSNNDimensionOrder=[4Q]}24
@"<MPSNNGramMatrixCallback>"
{MPSCNNGramFilters_s="i2mCopy"@"MPSImageCopyToMatrix""m2iCopy"@"MPSMatrixCopyToImage""gemm_TN"@"MPSMatrixMultiplication"}
{MPSCNNGramGradientFilters_s="fwdFilters"{MPSCNNGramFilters_s="i2mCopy"@"MPSImageCopyToMatrix""m2iCopy"@"MPSMatrixCopyToImage""gemm_TN"@"MPSMatrixMultiplication"}"gemm_NN"@"MPSMatrixMultiplication"}
@56@0:8@16{NeuronInfo=ifff@}24@48
{NeuronInfo="type"i"a"f"b"f"c"f"aData"@"NSData"}
v124@0:8@16@24@32@40@48Q56Q64{?={?=QQQ}{?=QQQ}}72B120
v72@0:8@16@24@32@40@48Q56Q64
v64@0:8@16@24@32@40Q48Q56
v104@0:8@16@24@32@40@48{?={?=QQQ}{?=QQQ}}56
@56@0:8@16@24Q32^{?=qqq}40^{?=qqq}48
16@0:8
@"MPSExternalCNNUnary"
@48@0:8Q16Q24Q32Q40
@80@0:8@16@24@32Q40Q48Q56Q64@72
@88@0:8@16@24@32Q40Q48Q56Q64Q72Q80
{?=qqq}24@0:8Q16
v48@0:8{?=qqq}16Q40
v32@0:8Q16Q24
@40@0:8@16@24Q32
^{NNKernelSourceParams={?=qqq}QQQQQQQQQ}
@"MPSNNReduceFeatureChannelsAndWeightsSum"
@"MPSNNReduceFeatureChannelsSum"
@56@0:8@16@24@32Q40Q48
@64@0:8@16@24r^f32r^f40Q48B56B60
@40@0:8@16@24B32B36
@52@0:8@16@24f32Q36Q44
@80@0:8@16@24r^f32r^f40r^f48r^f56Q64Q72
@44@0:8@16@24@32f40
B24@0:8r^{NeuronInfo=ifff@}16
@"NSObject"
{atomic<long>="__a_"{__cxx_atomic_impl<long, std::__cxx_atomic_base_impl<long>>="__a_value"Aq}}
@52@0:8I16I20I24I28i32@36Q44
f32@0:8@16@24
@"MPSCNNLoss"
@56@0:8Q16Q24Q32Q40@48
v28@0:8i16f20f24
v52@0:8r^f16r^f24r^f32r^f40f48
@40@0:8{NeuronInfo=ifff@}16
@72@0:8Q16Q24Q32Q40{?=qqq}48
@120@0:8Q16Q24Q32Q40Q48Q56Q64Q72Q80Q88Q96B104B108@112
B72@0:8@16I24I28r^v32r^f40i48r^52r^f60B68
B96@0:8@16@24r^v32I40I44r^48r^f56i64r^f68Q76B84B88I92
v48@0:8@16@24@32^@40
@36@0:8@16@24I32
@40@0:8@16@24I32I36
v56@0:8Q16Q24I32I36Q40Q48
@56@0:8@16Q24@32Q40@48
@64@0:8@16Q24I32I36@40Q48@56
v72@0:8@16@24@32@40@48@56Q64
v80@0:8@16@24@32@40@48@56@64Q72
{?="x"Q"y"Q"z"Q}
@"MPSCNNConvolutionGradient"
^{?=QQQ}
v60@0:8r^I16r^f24r^f32r^f40r^f48B56
@68@0:8@16@24r^I32r^f40f48Q52Q60
@88@0:8@16@24r^I32r^f40r^f48r^f56r^f64Q72Q80
@"MPSCNNPoolingAverage"
@60@0:8@16@24r^I32f40Q44Q52
@24@0:8@"<MTLDevice>"16
@"<MTLDevice>"16@0:8
Q96@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72@80Q88
Q96@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32Q40@"NSArray"48r^{?=QQ{?=qqq}{?=qqq}QQ}56@"NSArray"64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72@"<MTLBuffer>"80Q88
Q72@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64
Q80@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}QQQQ}40
Q48@0:8@16@24@32r^{?=QQQ^{?}I@{?=SSSSSS{?=SSSS}}I@{?=SSSS}{?={?=QQQ}{?=QQQ}}{?=qqq}QQ}40
Q112@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQ{?=qqq}{?=qqq}QQ}72@80r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}88@96Q104
Q112@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32Q40@"NSArray"48r^{?=QQ{?=qqq}{?=qqq}QQ}56@"NSArray"64r^{?=QQ{?=qqq}{?=qqq}QQ}72@"NSArray"80r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}88@"<MTLBuffer>"96Q104
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQ{?=qqq}{?=qqq}QQ}64@72r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}80
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}{?=qqq}QQQQQ}40
Q48@0:8@16@24@32r^{?=QQQ^{?}I@{?=SSSSSS{?=SSSS}}I@{?=SSSS}I@{?=SSSS}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}QQQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80
Q104@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80@88Q96
Q88@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}{?=qqq}QQ}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80
Q104@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"NSArray"40r^{?=QQ{?=qqq}{?=qqq}QQ}48@"NSArray"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80@"<MTLBuffer>"88Q96
)\o?
L7i?
)\o?
L7i?
@(#)PROGRAM:MPSNeuralNetwork  PROJECT:MPS-1
)5EHK_
19FilterNodeFileError
<empty>
21ResourceNodeFileError
"&*.C
333?
[%@ apply...] commandBuffer may not be nil]
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixFullyConnectedGradient.mm
[%@ apply...] input gradient matrix may not be nil
[%@ apply...] weight matrix may not be nil
[%@ apply...] result gradient for weight matrix may not be nil
[%@ apply...] input matrix origin z component must be 0
[%@ apply...] weight matrix origin z component must be 0
[%@ apply...] result matrix origin z component must be 0
Only MPSDataTypeFloat32 is supported.
Matrices contain batches, batching not supported.
secondarySourceMatrixOrigin.y not within domain of weight matrix.
secondarySourceMatrixOrigin.x not within domain of weight matrix.
primarySourceMatrixOrigin not within domain of input gradient matrix.
[%@ apply...] input data matrix may not be nil
[%@ apply...] result gradient for bias vector may not be nil
secondarySourceMatrixOrigin.y not within domain of input data matrix.
secondarySourceMatrixOrigin.x not within domain of input data matrix.
[%@ initWithCoder:device:] Failed: unsupported file version.
MatrixFullyConnectedGradient
MPSMatrixFullyConnectedGradient._alpha;
MPSMatrixFullyConnectedGradient._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnectedGradient._sourceInputFeatureChannels;
MPSMatrixFullyConnectedGradient._sourceOutputFeatureChannels;
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNReshape.mm
ReshapeOperation
ReshapeGradientOperation
pad before (x,y,ch) = (%lu, %lu, %lu)
pad after  (x,y,ch) = (%lu, %lu, %lu)
secondary source fc count = %lu
[initWithCoder:] out of memory?: could not decode fillValueArray
padBefore: (%d, %d, %d), 
padAfter: (%d, %d, %d)            
fillValue: %f
fillValueBuf: %s
created by %@
Source %p and destination %p shaapes are not the same sizes
Source feature channel offset for rehape must be 0 %lu
Destination feature channel offset for rehape must be 0 %lu
reshape_kernel
MPSNNReshape._reshapedWidth;
MPSNNReshape._reshapedHeight;
MPSNNReshape._reshapedFeatureChannels;
[... copyWithZone:device](copyBuffer) out of memory: could not allocate internal data
MPSNNPad_paddingSizeBefore.x
MPSNNPad_paddingSizeBefore.y
MPSNNPad_paddingSizeBefore.channel
MPSNNPad_paddingSizeAfter.x
MPSNNPad_paddingSizeAfter.y
MPSNNPad_paddingSizeAfter.channel
MPSNNPad_fillValue
MPSNNPad_aBufLenFP32
%@%@
.length
.data
MPSNNPad_aBuf
[MPSNNPad encode] Error: Number of feature channels in result (%d) not large enough (needed %lu).
cnnPadKernel
v16@?0@"<MTLCommandBuffer>"8
cnnPadGradientKernel
[%@ initWithDevice:] is not allowed. Please use initializers that are not marked NS_UNAVAILABLE.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNPoolingGradient.mm
zero pad size X: %lu
zero pad size Y:%lu
MPSCNNPoolingGradient.sourceSize.width
MPSCNNPoolingGradient.sourceSize.height
MPSCNNPoolingGradient.sourceSize.depth
[%@ encode...] Destination feature channel offset too large!
[%@ encode...] Destination feature channel offset Not multiple of 4!
MPSCNNPoolingGradient_generic_max_2d_2d
MPSCNNPoolingGradient_generic_max_2dArray_2dArray
MPSCNNPoolingGradient_generic_average_2d_2d
MPSCNNPoolingGradient_generic_average_2dArray_2dArray
MPSCNNPoolingGradient_generic_dilatedmax_2d_2d
MPSCNNPoolingGradient_generic_dilatedmax_2dArray_2dArray
MPSCNNPoolingGradient_generic_L2norm_2d_2d
MPSCNNPoolingGradient_generic_L2norm_2dArray_2dArray
MPSCNNPoolingGradient_generic_batch
MPSCNNPoolingGradient_inStateTex_batch
MPSCNNPoolingGradient.padSizeX
MPSCNNPoolingGradient.padSizeY
Error: The only valid values for primaryStrideInPixelsX (%lu) are 0 or 1.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNArithmetic.mm
Error: The only valid values for primaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for primaryStrideInFeatureChannels (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsX (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInPixelsY (%lu) are 0 or 1.
Error: The only valid values for secondaryStrideInFeatureChannels (%lu) are 0 or 1.
Cannot directly initialize MPSCNNArithmetic. Use one of the sub-classes of MPSCNNArithmetic.
invalid arithmetic operator type (%u)
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
primaryStrideInFeatureChannels: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
arithmeticType: %lu
[%@ resultStatesForSourceImage...] sourceStates must be nil for this filter]
Error: [%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] called with less than two source images.
[%@ %@] Error: destination state may not be nil
[%@ %@] Error: destination state must be a MPSCNNArithmeticGradientState
primaryScale: %f
secondaryScale: %f
bias: %f
minmumValue: %f
maximumValue: %f
primaryStrideInPixelsX: %lu
primaryStrideInPixelsY: %lu
secondaryStrideInPixelsX: %lu
secondaryStrideInPixelsY: %lu
secondaryStrideInFeatureChannels: %lu
isSecondarySourceFilter: %d
arithmeticType: %lu
MPSArithmetic.primaryScale
MPSArithmetic.secondaryScale
MPSArithmetic.bias
MPSArithmetic.minimumValue
MPSArithmetic.maximumValue
MPSArithmetic.primaryStrideInFeatureChannels
MPSArithmetic.secondaryStrideInFeatureChannels
MPSArithmetic.arithmeticType
[%@ encode...] MPSImageFeatureChannelsInterleavedPerPixel is not supported
[%@ encode...] invalid arithmetic operation
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + src.featureChannels > dest.featureChannels
[%@ encode...] equality threshold is negative.
MPSCNNMath_Arithmetic
MPSCNNMath_Arithmetic_Special_SubtractGradient
MPSCNNMath_Arithmetic_4Pixel_StrideXY0
MPSArithmetic.isSecondarySourceFilter
[%@ encode...] partial computation failed
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSRNNLayer.mm
[%@ initWithDevice:rnnDescriptors:] device may not be nil
[%@ initWithDevice:rnnDescriptor:] rnnDescriptor.inputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptor:] outputFeatureChannels has to be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu] may not be nil
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].inputFeatureChannels must be larger than zero
[%@ initWithDevice:rnnDescriptors:] rnnDescriptors[%lu].outputFeatureChannels must be larger than zero
[%@ copyWithZone:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] out of memory: could not allocate internal data
[%@ initWithCoder:device] Problem decoding layer stack
[%@ encodeWithCoder:] Problem allocating internal data
[%@ encode...] sourceMatrices[%d].rows == %d, should match destinationMatrices[%d].rows == %d
[%@ encode...] sourceMatrices[%d].columns == %d, should match layer input feature channels == %d
[%@ encode...] destinationMatrices[%d].columns == %d, should match layer output feature channels == %d
Out of memory in MPSRNNMatrixTrainingLayer:createWeightMatrices
[%@ encode...] Error: empty set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: matrix Id not found on this layer.
[%@ encode...] Error: Invalid matrix Id for single gate
[%@ encode...] Error: Datatype conversions in encodeCopyWeightsToCommandBuffer: not supported yet
[%@ encode...] Error: only MPSDataTypeFloat32 supported currently
[%@ encode...] Error: source size is (%lu, %lu) (rows, columns) - should be (%lu, %lu) 
[%@ encode...] Error: Invalid matrix Id for LSTM
[%@ encode...] Error: Invalid set of weights in encodeCopyWeightsToCommandBuffer:
[%@ encode...] Error: Invalid matrix Id for GRU
[%@ encode...] Error: Number of weight matrices (%lu), does not match number of weightGradient matrices (%lu)
[%@ encode...] Error: Number of weight matrices (%lu), does not match number at init time (%lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match weightGradient matrix dimensions (rows = %lu, columns = %lu)
[%@ encode...] Error: weight matrix (%lu) dimensions (rows = %lu, columns = %lu), does not match init time weight matrix dimensions (rows = %lu, columns = %lu)
[%@ encode...] forwardSources[%d].rows == %d, should match sourceGradients[%d].rows == %d
[%@ encode...] forwardSources[%d].columns == %d, should match layer input feature channels == %d
[%@ encode...] sourceGradients[%d].columns == %d, should match layer output feature channels == %d
[%@ encode...] forwardSources[%d].rows == %d, should match destinationGradients[%d].rows == %d
[%@ encode...] destinationGradients[%d].columns == %d, should match layer input feature channels == %d
MPSRNNMatrixVecMulFloat4
MPSRNNMatrixVecMulFloat1
MPSRNNMatrixVecMulFloat1_nonMult4
MPSRNNCopyData
MPSRNNAddSequenceData
MPSRNNMultiInputKernelFloat1
MPSRNNMultiInputKernelFloat1_nonMult4
MPSRNNCombineInputVecs
RNNAddBiasToOutput
MPSRNNLSTMRecursionTex0
MPSRNNLSTMRecursionTex1
MPSRNNLSTMRecursionCombined0float
MPSRNNLSTMRecursionCombined1float
MPSRNNLSTMFullRecursion0float
MPSRNNLSTMFullRecursion1float
MPSRNNLSTMRecursionCombined0half
MPSRNNLSTMRecursionCombined1half
MPSRNNLSTMFullRecursion0half
MPSRNNLSTMFullRecursion1half
MPSRNNBreakUpToOutputVecs
MPSRNNReduceToBiasGradient
MPSRNNClearFloatBuffer
MPSRNNClearCharBuffer
kMPSRNNLayer._inputFeatureChannels
kMPSRNNLayer._outputFeatureChannels
kMPSRNNLayer._numberOfLayers
kMPSRNNLayer._recurrentOutputIsTemporary
kMPSRNNLayer._storeAllIntermediateStates
kMPSRNNLayer._bidirectionalCombineMode
kMPSRNNLayer.layerTypes
[%@ encode...] commandBuffer may not be nil]
[%@ encode...] source may not be nil
[%@ encode...] destination may not be nil
[%@ encode...] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
MPSRNNImageCombine_2d_2d_2d_float
MPSRNNImageCombine_2d_2dArray_2d_float
MPSRNNImageCombine_2dArray_2d_2d_float
MPSRNNImageCombine_2dArray_2dArray_2d_float
MPSRNNImageCombine_2d_2d_2dArray_float
MPSRNNImageCombine_2d_2dArray_2dArray_float
MPSRNNImageCombine_2dArray_2d_2dArray_float
MPSRNNImageCombine_2dArray_2dArray_2dArray_float
MPSRNNGateCombine_2d_2d_2d_float
MPSRNNGateCombine_2d_2dArray_2d_float
MPSRNNGateCombine_2dArray_2d_2d_float
MPSRNNGateCombine_2dArray_2dArray_2d_float
MPSRNNGateCombine_2d_2d_2dArray_float
MPSRNNGateCombine_2d_2dArray_2dArray_float
MPSRNNGateCombine_2dArray_2d_2dArray_float
MPSRNNGateCombine_2dArray_2dArray_2dArray_float
MPSRNNPNormCombine_2d_2d_2d_float
MPSRNNPNormCombine_2d_2dArray_2d_float
MPSRNNPNormCombine_2dArray_2d_2d_float
MPSRNNPNormCombine_2dArray_2dArray_2d_float
MPSRNNPNormCombine_2d_2d_2dArray_float
MPSRNNPNormCombine_2d_2dArray_2dArray_float
MPSRNNPNormCombine_2dArray_2d_2dArray_float
MPSRNNPNormCombine_2dArray_2dArray_2dArray_float
MPSLSTMMultiInputKernelFloat1
MPSLSTMMultiInputKernelFloat2
MPSLSTMMultiInputKernelFloat3
MPSLSTMMultiInputKernelFloat4
MPSLSTMMultiInputKernelFloat5
MPSLSTMMultiInputKernelFloat6
MPSLSTMMultiInputKernelFloat7
MPSLSTMMultiInputKernelFloat8
MPSLSTMMultiInputKernelFloat9
MPSLSTMMultiInputKernelFloat10
MPSLSTMMultiInputKernelFloat11
MPSLSTMMultiInputKernelFloat12
MPSLSTMMultiInputKernelFloat13
MPSLSTMMultiInputKernelFloat14
MPSLSTMMultiInputKernelFloat15
MPSLSTMMultiInputKernelFloat16
MPSRNNLSTMRecursionfloat00_11_1
MPSRNNLSTMRecursionhalf00_11_1
MPSRNNLSTMRecursionchar00_11_1
MPSRNNLSTMRecursionfloat00_11_2
MPSRNNLSTMRecursionhalf00_11_2
MPSRNNLSTMRecursionchar00_11_2
MPSRNNLSTMRecursionfloat00_11_4
MPSRNNLSTMRecursionhalf00_11_4
MPSRNNLSTMRecursionchar00_11_4
MPSRNNLSTMRecursionfloat00_11_8
MPSRNNLSTMRecursionhalf00_11_8
MPSRNNLSTMRecursionchar00_11_8
MPSRNNLSTMRecursionfloat00_41_1
MPSRNNLSTMRecursionhalf00_41_1
MPSRNNLSTMRecursionchar00_41_1
MPSRNNLSTMRecursionfloat00_42_1
MPSRNNLSTMRecursionhalf00_42_1
MPSRNNLSTMRecursionchar00_42_1
MPSRNNLSTMRecursionfloat00_44_1
MPSRNNLSTMRecursionhalf00_44_1
MPSRNNLSTMRecursionchar00_44_1
MPSRNNLSTMRecursionfloat00_81_1
MPSRNNLSTMRecursionhalf00_81_1
MPSRNNLSTMRecursionchar00_81_1
MPSRNNLSTMRecursionfloat00_82_1
MPSRNNLSTMRecursionhalf00_82_1
MPSRNNLSTMRecursionchar00_82_1
MPSRNNSingleGateGradientRecursion_float_14_1
MPSRNNSingleGateGradientRecursion_float_24_1
MPSRNNSingleGateGradientRecursion_float_44_1
MPSRNNSingleGateGradientRecursion_half_14_1
MPSRNNSingleGateGradientRecursion_half_24_1
MPSRNNSingleGateGradientRecursion_half_44_1
MPSRNNSingleGateGradientRecursion_char_14_1
MPSRNNSingleGateGradientRecursion_char_24_1
MPSRNNSingleGateGradientRecursion_char_44_1
MPSRNNLSTMGradientRecursion_float_14_1
MPSRNNLSTMGradientRecursion_float_24_1
MPSRNNLSTMGradientRecursion_float_44_1
MPSRNNLSTMGradientRecursion_half_14_1
MPSRNNLSTMGradientRecursion_half_24_1
MPSRNNLSTMGradientRecursion_half_44_1
MPSRNNLSTMGradientRecursion_char_14_1
MPSRNNLSTMGradientRecursion_char_24_1
MPSRNNLSTMGradientRecursion_char_44_1
MPSRNNGRUGradientRecursion1_float_14_1
MPSRNNGRUGradientRecursion1_float_24_1
MPSRNNGRUGradientRecursion1_float_44_1
MPSRNNGRUGradientRecursion1_half_14_1
MPSRNNGRUGradientRecursion1_half_24_1
MPSRNNGRUGradientRecursion1_half_44_1
MPSRNNGRUGradientRecursion1_char_14_1
MPSRNNGRUGradientRecursion1_char_24_1
MPSRNNGRUGradientRecursion1_char_44_1
MPSRNNGRUGradientRecursion2_float_14_1
MPSRNNGRUGradientRecursion2_float_24_1
MPSRNNGRUGradientRecursion2_float_44_1
MPSRNNGRUGradientRecursion2_half_14_1
MPSRNNGRUGradientRecursion2_half_24_1
MPSRNNGRUGradientRecursion2_half_44_1
MPSRNNGRUGradientRecursion2_char_14_1
MPSRNNGRUGradientRecursion2_char_24_1
MPSRNNGRUGradientRecursion2_char_44_1
MPSRNNSingleGateRec_float00_1_2
MPSRNNSingleGateRec_float00_1_4
MPSRNNSingleGateRec_float00_8_2
MPSRNNSingleGateRec_float00_8_4
MPSRNNSingleGateRec_half00_1_2
MPSRNNSingleGateRec_half00_1_4
MPSRNNSingleGateRec_half00_8_2
MPSRNNSingleGateRec_half00_8_4
MPSRNNSingleGateRec_char00_1_2
MPSRNNSingleGateRec_char00_1_4
MPSRNNSingleGateRec_char00_8_2
MPSRNNSingleGateRec_char00_8_4
MPSRNNGRURecursion1float00_11
MPSRNNGRURecursion1float00_44
MPSRNNGRURecursion1half00_11
MPSRNNGRURecursion1half00_44
MPSRNNGRURecursion1char00_11
MPSRNNGRURecursion1char00_44
MPSRNNGRURecursion2float00_11
MPSRNNGRURecursion2float00_44
MPSRNNGRURecursion2half00_11
MPSRNNGRURecursion2half00_44
MPSRNNGRURecursion2char00_11
MPSRNNGRURecursion2char00_44
Only MPSDataTypeFloat32 and MPSDataTypeFloat16 supported
Unsupported Metal device
[copySingleGateLayer copyWithZone:device] out of memory: could not allocate internal data
[copyLSTMLayer copyWithZone:device] out of memory: could not allocate internal data
[initWithCoder:] out of memory: could not allocate internal data
%@%d
kMPSRNNLayer.common.direction
kMPSRNNLayer.common.useUnitXForm
kMPSRNNLayer.common.nHiddenFeatures
kMPSRNNLayer.common.nInputFeatures
kMPSRNNLayer.common.nOutputFeatures
kMPSRNNLayer.common.nRecurrentOutputFeatures
kMPSRNNLayer.common.inputTransform
kMPSRNNLayer.common.outputTransform
kMPSRNNLayer.common.recurrentOutputTransform
kMPSRNNLayer.common.inputTransform.hasBias
kMPSRNNLayer.common.outputTransform.hasBias
kMPSRNNLayer.common.recurrentOutputTransform.hasBias
MPSRNNLayer.SingleGate.inputXForm
MPSRNNLayer.SingleGate.recurrentXForm
MPSRNNLayer.SingleGate.hasBias
MPSRNNLayer.SingleGate.biasData
.convolution
kMPSRNNLayer.neuron.neuronType
kMPSRNNLayer.neuron.neuronParamA
kMPSRNNLayer.neuron.neuronParamB
kMPSRNNLayer.neuron.neuronParamC
[initWithCoder:](decodeLSTMLayer) out of memory: could not allocate internal data
MPSRNNLayer.LSTM.inputGate
MPSRNNLayer.LSTM.forgetGate
MPSRNNLayer.LSTM.cellGate
MPSRNNLayer.LSTM.outputGate
MPSRNNLayer.LSTM.recursionXFormsCombined
MPSRNNLayer.LSTM.finalNeuron
MPSRNNLayer.LSTM.inputXFormsCombined
MPSRNNLayer.LSTM.coupleForgetGateToInputGate
MPSRNNLayer.LSTM.cellClipThreshold
.inputXForm
.recurrentXForm
.peepholeXForm
.hasBias
.biasVector
.peepholeVector
.nHiddenFeatures
[initWithCoder:](decodeGRULayer) out of memory: could not allocate internal data
MPSRNNLayer.GRU.inputGateInputXform
MPSRNNLayer.GRU.inputGateRecXform
MPSRNNLayer.GRU.inputGateBias
MPSRNNLayer.GRU.inputGateHasBias
MPSRNNLayer.GRU.inputNeuron
MPSRNNLayer.GRU.recGateInputXform
MPSRNNLayer.GRU.recGateRecXform
MPSRNNLayer.GRU.recGateBias
MPSRNNLayer.GRU.recGateHasBias
MPSRNNLayer.GRU.recurrentNeuron
MPSRNNLayer.GRU.outputGateInputXform
MPSRNNLayer.GRU.outputGateRecXform
MPSRNNLayer.GRU.outputGateMemoryform
MPSRNNLayer.GRU.outputGateBias
MPSRNNLayer.GRU.outputGateHasBias
MPSRNNLayer.GRU.outputNeuron
MPSRNNLayer.GRU.pNormGateValue
MPSRNNLayer.GRU.flipOutputGates
Out of memory initializing RNN training layer
[... initWithCoder:device](decodeTransform) out of memory: could not allocate internal data
.dataType
.biasLength
.biasData
.rows
.rowBytes
.columns
[... encodeWithCoder:](encodeTransform) Invalid transform buffer
[MPSNNScaleNode init] Error: Abstract class. 
Please use MPSNNBilinearScaleNode or MPSNNLanczosScaleNode instead.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNScale.mm
region provider: %@
size: {%lu, %lu, %lu}
use entire image
Internal error: [%@ initWithDevice:] unavailable
region provider: %@
Size: { %lu, %lu, %lu}
<copy entire image>
%@ error: Filter does not support result depth != 1
%@ %p error: the resampling filter does not support featureChannels > 4.
Error: class %@ does not conform to <MPSImageTransformProvider>
MPSNNScale.className
MPSNNScale.o
MPSNNScale.transformProviderName
MPSNNScale.handleName
MPSNNScale.handle.o
MPSNNScale.destSize.x
MPSNNScale.destSize.y
MPSNNScale.destSize.z
[MPSNNGraph encode...]: Error: MPSNNPadding method %p returned a nil formatting descriptor for an intermediate image.
The encode can not continue.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/FilterNode.h
Internal error: default encode for unary kernels doesn't take an input state
<missing label>
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
float16
float32
unorm8
unorm16
snorm8
snorm16
uint8
uint6
sint8
sint16
bfloat16
<unknown channel format>
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
*** Warning: kernel %s (%s) produces a result of size %lu x %lu. We will probably assert soon.
Perhaps the MPSNNGraph input image is too small for this network, or an upstream padding
policy was incorrect (full>same>valid), or a stride too large?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImage for destination.  Encode failed.
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSImageInternal.h
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNConcatenation.mm
[%@ encode...] sourceImages may not be nil
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLPixelFormat is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] destination MTLTextureUsage is not writable.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] sourceImages length is 0. Can not produce a result.
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  The MPSImageFeatureChannelsLayout must match between source and destination MPSImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image %lu and dest image must have the same feature channel layout
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  the sum of feature channels in the source images  must fit within the destination image
[%@ encodeToCommandBuffer:sourceImages:destinationImage] Error: source image %lu (%p) has invalid feature channel layout.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] internal error: unable to create MTLTextureType2DArray view of src texture %p
[%@ encodeBatchToCommandBuffer:sourceImages:destinationImage:] Error: there are not enough source images in batch %lu (%lu) to fill the destination batch %lu
[%@ encodeToCommandBuffer: sourceImages:] sourceImages.count may not be 0
[%@ %@] Error: command buffer may not be NULL
[%@ %@] Error: sourceImage batch may not be NULL
[%@ %@] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImages may not be NULL
[%@ resultStateBatchForSourceImages:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
%@, %lu
slice offsets:              {%@}
feature channels per slice: {%@}
ConcatenateInterleaved
ConcatenateInterleaved_array
ConcatenateArray
ConcatenateArray_array
Please initialize the %@ class with initWithDevice:weights
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionGradientForData.mm
[%@ initWithDevice:convolutionDescriptor:weights:] device may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] convolutionDescriptor may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] 8-bit weights not supported in
kernel width must be > 0
kernel height must be > 0
number of input feature channels must be > 0
number of output feature channels must be > 0
strideX must be > 0
strideY must be > 0
dilationRateX must be > 0
dilationRateY must be > 0
number of groups must be > 0
Subpixel convolution does not currently supported gradient back propagation
Depthwise convoution gradient is only supported for channel multipler == 1
requested use of float32 weights, but weight buffer has type 0x%16.16llx
kernelWeightsDataType must be MPSDataTypeFloat16 for weights of type 0x%16.16llx
Lock creation failed
Failed to create weights buffer
weights.load should return YES
data source returned nil weights
Weights layout of convolution gradient object %s does not match that of state object %s
weights to reload method cannot be nil
weights buffer should have %lu bytes of data
Number of source feature channels needed by convolution %lu are not available in image with %lu feature channels
Number of destination feature channels needed by convolution gradient w.r.t data %lu are not available in image with %lu feature channels at offset %lu
Layout of convolution and convolution gradient object mismatch
clearWeightsAndBiasesBuffer
MPSCNNConvolutionWeightsLayoutOHWI
MPSCNNConvolutionWeightsLayoutOIHW
MPSCNNConvolutionGradientIsFullyConnected
kMPSCNNConvolutionGradientSerializeWeightsAndBiases
kMPSCNNConvolutionGradientConvolutionTranspose
MPSCNNConvolutionGradientInputFeatureChannels
MPSCNNConvolutionGradientOutputFeatureChannels
MPSCNNConvolutionGradientGroups
MPSCNNConvolutionChannelMultiplier
kMPSCNNConvolutionGradientWeightsDataType
kMPSCNNConvolutionGradientPreferredWeightsDataType
kMPSCNNConvolutionGradientWeightsLayout
kMPSCNNConvolutionGradientOption
Gradient filter not implemented for reduction kernels.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNReductionNodes.mm
Internal error: default encode for gradient kernels doesn't take an result state
Internal error: default encode for gradient kernels has an input state
Internal error: gradient kernels take an input state
Internal error: gradient kernels take multiple input images
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalizationGradient.mm
[%@ apply...] input matrix may not be nil
[%@ apply...] gradient matrix may not be nil
[%@ apply...] input mean vector may not be nil
[%@ apply...] input variance vector may not be nil
[%@ apply...] result gradient for data matrix may not be nil
Only outputs of MPSDataTypeFloat32 are supported.
Only beta vector value types of MPSDataTypeFloat32 are supported.
Only gamma vector value types of MPSDataTypeFloat32 are supported.
Only input matrix value types of MPSDataTypeFloat32 are supported.
PReLU not supported.
MatrixBatchNormalizationGradient
MPSMatrixBatchNormalizationGradient._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalizationGradient._sourceInputFeatureChannels;
MPSMatrixBatchNormalizationGradient._neuronType;
MPSMatrixBatchNormalizationGradient._neuronA;
MPSMatrixBatchNormalizationGradient._neuronB;
MPSMatrixBatchNormalizationGradient._neuronC;
MPSMatrixBatchNormalizationGradient._epsilon;
[%@ initWithDevice:keepProbability:seed:] Failed: the valid range of keepProbability (%lu) is (0.0f, 1.0f]
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNDropout.mm
keepProbability: %f
seed: %lu
MPSCNNDropoutKeepProbability
MPSCNNDropoutSeed
MPSCNNDropoutMaskStrideInPixelsWidth
MPSCNNDropoutMaskStrideInPixelsHeight
MPSCNNDropoutMaskStrideInPixelsDepth
[%@ encode...] valid values for maskStrideInPixels {%lu %lu %lu} are 0 and 1
MPSDropoutRGBA
MPSDropoutRG
MPSDropoutR
_MPSCommandBufferRetainListKey
MPSCNNDropoutGradientKeepProbability
MPSCNNDropoutGradientSeed
MPSCNNDropoutGradientMaskStrideInPixelsWidth
MPSCNNDropoutGradientMaskStrideInPixelsHeight
MPSCNNDropoutGradientMaskStrideInPixelsDepth
Cannot directly initialize MPSCNNUpsampling. Use one of the sub-classes of MPSCNNUpsampling.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNUpsampling.mm
scale factor in the x dimension (%lu) must be > 0
scale factor in the y dimension (%lu) must be > 0
invalid filter type (%lu)
scaleFactorX: %f
scaleFactorY: %f
MPSCNNUpsampling.filterType
MPSCNNUpsampling.scaleFactorX
MPSCNNUpsampling.scaleFactorY
MPSCNNUpsampling.alignCorners
[%@ encode...] Specificed scaleFactorX would result in destination texture width that exceeds the maximum allowed texture width
[%@ encode...] Specificed scaleFactorY would result in destination texture height that exceeds the maximum allowed texture height
MPSCNNUpsampling_general
MPSCNNUpsampling_SWBilinear
MPSCNNGradientKernel.kernelOffsetX
MPSCNNGradientKernel.kernelOffsetY
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] no padding method set. Can not compute result.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSCNNGradientKernel.mm
[%@ destinationImageDescriptorForSourceImages:sourceStates:updateOffset:] the object padding method %p does not respond to the destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor: selector
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:sourceImage:] Unable to create MPSImage for destination.  Encode failed.
[%@ encode] Error: Gradient filters do not support gradient operations for Inference kernels that use the clipRect to operate on a subregion of the result
This would force the gradient kernel to have to do software edging at significant performance cost.
Use the slice operator to  trim away the unwanted parts of the gradient input.
[%@ encode] Error: Unknown state type.  Encode failed.
[%@ encodeToCommandBuffer:sourceGradients:...] Unable to create MPSImageDescriptor for destination.  Encode failed.
a: %f
b: %f
c: %f
Internal error: encountered unknown neuron type
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNNeuronNodes.mm
%@ (%s)
MPSCNNNeuron (%s)
MPSCNNNeuronGradient (%s)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSGridSample.mm
GridSample
grid_sample
[%@ encode...] secondary source must have 2 feature channels
MPSNNGridSample.useGridValueAsInputCoordinate
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixFullyConnected.mm
[%@ apply...] result matrix may not be nil
Only bias vector value types of MPSDataTypeFloat32 are supported.
Only weight matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
filter.batchStart not within domain of inputMatrix.
filter.batchStart not within domain of weightMatrix.
filter.batchStart not within domain of resultMatrix.
filter.batchStart not within domain of biasVector.
secondarySourceMatrixOrigin.y not within domain of weightMatrix.
secondarySourceMatrixOrigin.x not within domain of weightMatrix.
primarySourceMatrixOrigin not within domain of inputMatrix.
PReLU param-A array failed to set.
[%@ initWithCoder:device:] Failed: Unable to read array for MPSCNNNeuronTypePReLU.
For PReLU, use -setNeuronToPReLUWithParametersA:
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
sourceOutputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
Only outputs of MPSDataTypeFloat32 and MPSDataTypeFloat16 are supported.
Input matrix value type must match output matrix value type.
sourceMatrixOrigin not within domain of inputMatrix.
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
alpha:
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixFullyConnectedTexture_M4
MatrixNeuron_float
MatrixNeuron_half
MatrixFullyConnected_FP32_G13P
MatrixFullyConnected_FP16_G13P
MatrixFullyConnected_AnyM
MPSMatrixFullyConnected._alpha;
MPSMatrixFullyConnected._sourceNumberOfFeatureVectors;
MPSMatrixFullyConnected._sourceInputFeatureChannels;
MPSMatrixFullyConnected._sourceOutputFeatureChannels;
MPSMatrixFullyConnected._neuronType;
MPSMatrixFullyConnected._neuronA;
MPSMatrixFullyConnected._neuronB;
MPSMatrixFullyConnected._neuronC;
MPSMatrixFullyConnected._perChannelNeuronA;
[%@ initWithDevice:dataSource:] dataSource.load should return YES
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalization.mm
[%@ initWithDevice:dataSource:fusedNeuronDescriptor] neuron is of type PReLU but data is nil.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported.  Batch normalization state requires a source state.
[%@ encodeToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:...:destinationState:...] Error: destination states not supported. Batch normalization state requires a source state.
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:] Attempting to use statistics from a temporary MPSCNNBatchNormalizationState with readCount of 0.
[%@ encodeBatchToCommandBuffer...] Error: convenience methods that return a image batch must have clipRect.origin.z = 0.  We can't return empty batch nodes in a NSArray.
Cannot create state for images with more feature channels than used to initialize batch normalization filter.
[%@ reloadDataSource:] dataSource.load should return YES
state does not have valid gamma and beta buffers.
reloadGammaAndBeta
state does not have valid mean and variance buffers.
reloadMeanAndVariance
[%@ %@] Error: Unable to decode data source.
[%@ %@] Error: dataSource does not support NSSecureCoding
feature channels: %lu
epsilon: %g
data source: %@
neuron:
batchNormSimpleBufferCopy
encodeBatchToCommandBuffer: Neuron is of type PReLU but parameter buffer is nil.
imageBatchNormalization
Error: Can not decode. Unable to find class implementation for "%@".
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSCoreInternal.h
kMPSCNNBatchNormalization.s
kMPSCNNBatchNormalization.o
kMPSCNNBatchNormalizationIsNeuronFusedKey
kMPSCNNBatchNormalizationFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLUData
kMPSCNNBatchNormalizationFusedNeuronA
kMPSCNNBatchNormalizationFusedNeuronB
kMPSCNNBatchNormalizationFusedNeuronC
MPSCNNConvolutionTransposeGradienState was not created with MPSCNNConvolutionGradientState (auto-encoder). convolution property is not available
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionTranspose.mm
Please use correct initializer.
convolutionTranspose: %@ %p "%@"
Filter weights pointer should be non-null
Feature channel layout of source and MPSCNNConvolutionTranspose filter doesn't match
Feature channel layout of destination and MPSCNNConvolutionTranspose filter doesn't match
Number of source feature channels needed by convolution %lu are not available in image with %lu feacture channels
Number of destination feature channels needed by convolution %lu are not available in image with %lu feature channels at offset %lu
Accumulator precision must be set to MPSNNConvolutionAccumulatorPrecisionOptionFloat when using float32 kernel weights
Please use encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationState:destinationStateIsTemporary:
Please use encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationStates:destinationStateIsTemporary:
%@inputFeatureChannels: %lu
outputFeatureChannels: %lu
Feature channel layout: %lu
Groups: %lu 
kernelOffset: {%zd, %zd}
neuron type: %s
neuron A:  %10.14f
neuron B:  %10.14f
neuron C:  %10.14f
Error: -[MPSCNNConvolution reloadWeightsAndBiasesWithDataSource:] does not support changing the data source.
It has been deprecated. Please use -reloadWeightsAndBiasesFromDataSource instead.
MPSCNNConvolutionTransposeVers
MPSCNNConvolutionTransposeWidth
MPSCNNConvolutionTransposeHeight
MPSCNNConvolutionTransposeInputFeatureChannels
MPSCNNConvolutionTransposeOutputFeatureChannels
MPSCNNConvolutionTransposeStrideInPixelsX
MPSCNNConvolutionTransposeStrideInPixelsY
MPSCNNConvolutionTransposeDilationRateX
MPSCNNConvolutionTransposeDilationRateY
MPSCNNConvolutionTransposeGroups
MPSCNNConvolutionTransposeFeatureChannelsLayout
MPSCNNConvolutionTransposeKernelOffsetX
MPSCNNConvolutionTransposeKernelOffsetY
MPSCNNConvolutionTransposeFusedNeuronClassKey
MPSCNNConvolutionTransposeNeuron
MPSCNNConvolutionTransposeConvolutionClassKey
MPSCNNConvolutionTransposeConvolutionKey
cnnConv1xIn8xOutH
cnnConv1xIn8xOutArrayH
cnnConv3xIn8xOutH
cnnConv3xIn8xOutArrayH
cnnConv8xIn8xOutH
cnnConv8xIn8xOutArrayH
cnnConv3In8xOutH
cnnConv3In8xOutArrayH
cnnConv1In8xOutH
cnnConv1In8xOutArrayH
cnnConv1In8xOutH3x3
cnnConv1In8xOutArrayH3x3
cnnConv1In8xOutH5x5
cnnConv1In8xOutArrayH5x5
cnnConv8xIn4xOutH1x1
cnnConv8xIn4xOutArrayH1x1
cnnConv8xIn8xOutH1x1
cnnConv8xIn8xOutArrayH1x1
cnnConv8xIn1xOutH
cnnConv8xIn1xOutArrayH
cnnConv8xIn2xOutH
cnnConv8xIn2xOutArrayH
cnnConv8xIn3xOutH
cnnConv8xIn3xOutArrayH
cnnConv8xIn4xOutH
cnnConv8xIn4xOutArrayH
cnnConv8xIn8xOutHgroup
cnnConv8xIn8xOutArrayHgroup
You must call -gradientFiltersWithSources:gradientImages: for this filter
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNArithmeticNodes.mm
[%@ gradientFiltersWithSources:] This method requires one gradient image as input
[%@ gradientFiltersWithSources:] gradientImages[0] must be valid and contain the source gradient
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNBinaryArithmeticNode
Internal error: default encode for binary kernels doesn't take an input state
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalizationGradient.mm
imageInstanceNormalizationThreadgroupDot
imageInstanceNormalizationImageDot
imageInstanceNormalizationGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationStatisticsGradient.mm
[%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientStates:destinationGradient:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
[%@ encodeToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients] Error: Unavailable.  Use [%@ encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState]
imageInitialDotBase
imageFinalSumBase
imageThreadgroupSumDotBase
kMPSCNNBatchNormalizationStatisticsGradientIsNeuronFusedKey
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronType
kMPSCNNBatchNormalizationFusedNeuronPReLULength
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronA
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronB
kMPSCNNBatchNormalizationStatisticsGradientFusedNeuronC
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingNearestNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNUpsamplingNodes.mm
[%@ initWithGradientImages:forwardFilter:] filter %@ <%p>must be of class MPSCNNUpsamplingBilinearNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNOptimizers.mm
[%@ initWithCoder:device:] Unsupported file version. Could not init object.
            
learningRate:
            
gradientRescale:
            
applyGradientClipping:
            
gradientClipMax:
            
gradientClipMin:
            
regularizationType:
            
regularizationScale:
            
momentumScale:
            
useNesterovMomentum:
inputGradientMatrix
inputValuesMatrix
inputMomentumMatrix
resultValuesMatrix
[resultState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionSourceState isKindOfClass: MPSCNNConvolutionWeightsAndBiasesState.class] failed
[convolutionGradientState isKindOfClass: MPSCNNConvolutionGradientState] failed
[inputMomentumVectors count] > 0 failed
convolutionResultState.numberOfWeights == convolutionSourceState.numberOfWeights failed 
convolutionResultState.numberOfBiases == convolutionSourceState.numberOfBiases failed 
[batchNormalizationSourceState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[batchNormalizationGradientState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
[resultState isKindOfClass: MPSCNNNormalizationGammaAndBetaState.class] failed
inputGradientState.gradientForGamma returned nil
[batchNormalizationState isKindOfClass: MPSCNNBatchNormalizationState.class] failed
            
decay:
            
epsilon:
            
momentumScale:
            
centered:
inputSumOfSquaresMatrix
inputMomentumMatrix != nil failed for a non 0 momentumScale
inputWeightedSumMatrix != nil failed for a centered RMSProp
inputWeightedSumMatrix
inputSumOfSquaresVectors != nil failed
[inputSumOfSquaresVectors count] > 0 failed
            
beta1:
            
beta2:
            
epsilon:
%f            
timeStep:
inputVelocityMatrix
maximumVelocityMatrix
inputMomentumVectors != nil failed
inputVelocityVectors != nil failed
[inputVelocityVectors count] > 0 failed
[maximumVelocityVectors count] > 0 failed
[maximumVelocityVectors count] == [inputVelocityVectors count failed 
kMPSNNOptimizer.learningRate
kMPSNNOptimizer.gradientRescale
kMPSNNOptimizer.applyGradientClipping
kMPSNNOptimizer.gradientClipMax
kMPSNNOptimizer.gradientClipMin
kMPSNNOptimizer.regularizationType
kMPSNNOptimizer.regularizationScale
kMPSNNOptimizer.momentumScale
kMPSNNOptimizer.useNestrovMomentum
sgdUpdate
sgdUpdate4
sgdMomentumUpdate
sgdMomentumUpdate4
adamUpdate
adamUpdate4
amsGradUpdate
amsGradUpdate4
%s.dataType == MPSDataTypeFloat32 failed, Optimizers currently support only Float32 datatype vectors
%s.matrices == 1 failed, Optimizers currently support only 1  matrix per MPSMatrix
inputGradientMatrix.rows == %s.rows failed, number of elements must be same
inputGradientMatrix.columns == %s.columns failed, number of elements must be same
kMPSNNOptimizer.decay
kMPSNNOptimizer.epsilon
kMPSNNOptimizer.centered
rmsPropUpdate
rmsPropUpdate4
kMPSNNOptimizer.beta1
kMPSNNOptimizer.beta2
kMPSNNOptimizer.timeStep
[%@ initWithDevice:resultImage:resultStates:] error: resultImage may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNGraph.mm
[%@ initWithDevice:resultImage:resultStates:] error: resultImage must be a child class of MPSNNImageNode
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph consumes MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:] Error: This graph produces intermediate image objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:destinationImage:] Error: This graph produces MPSState objects.
Please use-encodeToCommandBuffer:sourceImages:sourceStates:destinationImage:destinationStates: instead.
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a MPSImage
[MPSNNGraph encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:] error: source images must currently be type compatible with half float texture loads.
Source image [%lu] has pixel format %s
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
Did you perhaps forget to provide the state objects for labels and weights for the loss layer?
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceStates[%lu] is nil
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: destination image allocator may not be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: command buffer may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages may no be nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source images (%lu) does not match the number needed for the graph (%lu)
You may be thinking that this array is for handling every image in your library at once.
However, actually this array is here to handle graphs and sub-graphs that take multiple different image nodes at different places in the graph.
If you do want to process multiple images concurrently, you can batch up multiple images in the same MPSImage.
 See MPSImage.numberOfImages
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu] is not a array of MPSImage
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is nil
[%@ encodeBatchToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: sourceImages[%lu][%lu] is not a MPSImage
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: number of source states (%lu) does not match the number needed for the graph (%lu)
[%@ encodeToCommandBuffer:sourceImages:sourceState:destinationImage:destinationStates:] Error: %lu MPSStateBatches expected as input. nil was passed.
<nil>
<no description>
outputStateIsTemporary:              %s
destinatonImageAllocator:            %s
default intermediate storage foramt: %s
result is needed:                    %s
list of nodes:
(Note: missing nodes have been optimized away.)
[%@ initWithCoder:device:] Failed: unable to read class of MPSNNGraph destination image allocator.
[%@ initWithCoder:device:] Failed: unable to find class of MPSNNGraph destination image allocator %@ in application.
MPS Warning: failure to unpack graph default image allocator with unarchiver. MPSTemporaryImage defaultAllocator will be used.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: outputStateIsTemporary must be set to NO for this method
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the destinationImageAllocator is set to create a temporary image.
A temporary image only lives as long as the MTLCommandBuffer. Its contents would be invalid by the time you were able to use them.
MPSErrorDomain
Failed to allocate MPSImage
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModePrivate. Perhaps you made a MPSTemporaryImage instead by mistake? That can't work.
[%@ executeAsyncWithSourceImages:completionHandler:] Error: the output MPSImage.texture may not be MTLStorageModeMemoryless
MPS Internal Error: Unexpected command buffer status encountered: %lu
[%@ initWithDevice:resultImage:] internal error: could not create filter for node:
[%@ initWithDevice:resultImage:] internal error: source image is NULL
[%@ initWithDevice:resultImage:] internal error: state image is NULL
 result image id <-- filter <-- {filter source image id list}
 ============================================================
v24@?0^v8^{PrintStackFrame=}16
   * an image passed into the graph
   0 is the graph result image.
   () the result may be only partially overwritten.
Summary:
%4lu %s
Init MPSNNGraph %p
%lu nodes are specified.
Some may have been pruned because they were not needed to produce a result.
Initial graph:
v40@?0^v8^v16Q24^{EmptyStackFrame=}32
Final graph:
v24@?0^v8^{EmptyStackFrame=}16
Rejected contraction of %s:
it uses MPSNNPaddingMethodCustom without MPSNNPaddingMethodCustomAllowForNodeFusion
Rejected contraction of %s into %s:
the intermediate image is read by another filter (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu)
Rejected contraction of %s into %s:
it produces a state that is read at least once (%lu) or exported from the graph
  Attempting to contract consecutive filter passes into a single pass...
Removed %s because it does nothing
Can not contract %s: 
Contracted %s into %s
v24@?0^v8^{OptimizationStackFrame=}16
  Removed %lu passes
  No passes removed by contraction.
(This is common in training graphs because the intermediate tensors are needed for gradient passes.)
  Pruning unproductive filter nodes...
Pruned %s
  Pruned %lu nodes.
  Attempting to use feature channel offsets to eliminate concatenation and slice passes...
Optimized away %s
Optimized away %s
  Removed %lu passes
Verify Graph:
No filters in graph.
Error: node %p %@ "%@" has no result image. All MPS nodes are required to have a result.
Error: node %s has no result image. All MPS nodes are required to have a result.
Error: nothing reads the result from node %p %@ "%@".  All MPS nodes are required to have a result.
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES?
Error: nothing reads the result from node %s. 
Possibly you forgot to use node.result in another filter or set node.exportFromGraph=YES.
Error: node %s has a missing result state? %lu
Error: nothing reads the result state from node %p %@ "%@".
Error: nothing reads the result state %lu from node %s. 
%lu issues reported.
Optimizing graph structure...
End graph optimization passes.
Error: using image with 0 read count
v40@?0^v8^v16Q24^{EncodeFrame=@@@@@QQQ^{Graph}}32
v24@?0^v8^{EncodeFrame=@@@@@QQQ^{Graph}}16
Legend:
FilterNodeType[filter.index] {src.width x src.height x src.featureChannels src.format}[src.index] ->
{dest.width x dest.height x dest.featureChannels dest.format}[dest.index] offset: destinationFeatureChannelOffset
=============================================================================================================
v40@?0^v8^v16Q24^{EncodeBatchFrame=@@@@@QQQ^{Graph}}32
v24@?0^v8^{EncodeBatchFrame=@@@@@QQQ^{Graph}}16
<none specified>
Internal Error: unhandled MPSImageFeatureChannelFormat %lu in [%@ debugDescription]
resultFormat:  %s
v24@?0^v8^{AutoreleasePoolStackFrame=@}16
<no filters>
Warning: Some parts of the encoded graph appear to be missing. 
 %lu filters, %lu images and %lu states were found.
 Expected: %lu filters, %lu images, %lu states
Error: The indices of the returned graph image nodes are missing.
, %lu
Filter: %@ {%lu}
Source Images: %lu {%s}
Source States: %lu
Result Images: %lu {%lu}
Result States: %lu
Filter:
  %@
<missing MPSNNFilterNode>
Error: could not unpack resource node. File data segment too small
Error: could not unpack resource node. File version too new
Error: could not unpack resource node. unknown exception %u
MPSNNGraphc
MPSNNGraphA
MPSNNGraphFI
MPSNNGraphResultIsNeeded
MPSNNGraphOutputStateIsTemporary
(%lu)
%lu 
%5s <-- %s <-- 
%lu%s
{%lu%s
, %lu%s
[%lu] %@ %p "%@"
[%lu] %@ %p
%@ %p
%@ "%@"
MPSNNGraph.filterNodes
MPSNNGraph.imageNodes
MPSNNGraph.stateNodes
MPSNNGraph.resultIndexCount
MPSNNGraph.resultIndices
MPSNNGraph.filterCount
MPSNNGraph.imageCount
MPSNNGraph.stateCount
MPSNNGraph.exportedImages
Data
ResourceWrapper.d
ResourceWrapper.hc
ResourceWrapper.h
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu   "%s"
padding policy: %s
(%@ --> %@)
%s[%lu] {%lu x %lu x %lu %s}[%lu](offset:%lu) + {%lu x %lu x %lu %s}[%lu](offset:%lu) -> {%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
%s[%lu] %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) + %lu*{%lu x %lu x %lu %s}[%lu](offset:%lu) -> %lu*{%lu x %lu x %lu %s}[%lu]  offset: %lu  "%s"
padding policy: %s
Out of memory:  Append node failed. This graph is unlikely to produce expected results.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/NodeList.h
copyWeightsAndBiasesApple
export
reloadForward
reloadBackward
depthwiseConvolve_1xChannelMultiplier_3x3_noDilation
depthwiseConvolve_1xChannelMultiplier
Destination feature channel format %lu + number of output feature channels of filter %lu is more than feature channels available to write in destination image %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionApple.mm
output feature channels %lu must be multiple of scaleFactor^2 %lu
Number of feature channels in destination image %lu must be >= output feature channel of convolution / scaleFactor^2 %lu
Half accumulator does not have enough bits to keep signal from source with bit depth %d
Half accumulator does not have enough range to keep signal from bfloat16 source
dequantizeApple
Number of source feature channels needed by convolution %lu must be equal to number of channels in image but image has %lu feacture channels
Scale factor of > 1 is not supported for interleaved per pixel layout
dilationRateX of > 1 is not supported for interleaved per pixel layout
dilationRateY of > 1 is not supported for interleaved per pixel layout
cnnConv_Update_Depthwise_Apple
cnnConv_Update_Apple
cnnConv_Update_reduction
cnnConvArray_1xIn_4xOut_1_1
cnnConvArray_1xIn_4xOut_2_1
cnnConvArray_1xIn_4xOut_3_1
cnnConvArray_1xIn_4xOut_4_1
cnnConvArray_1xIn_4xOut_1_2
cnnConvArray_1xIn_4xOut_2_2
cnnConvArray_1xIn_4xOut_1_3
cnnConvArray_1xIn_4xOut_1_4
cnnConvArray_1xIn_8xOut_1_1
cnnConvArray_1xIn_8xOut_2_1
cnnConvArray_1xIn_8xOut_3_1
cnnConvArray_1xIn_8xOut_4_1
cnnConvArray_1xIn_8xOut_1_2
cnnConvArray_1xIn_8xOut_2_2
cnnConvArray_1xIn_8xOut_1_3
cnnConvArray_1xIn_8xOut_1_4
cnnConvArray_1xIn_16xOut_1_1
cnnConvArray_1xIn_16xOut_2_1
cnnConvArray_1xIn_16xOut_3_1
cnnConvArray_1xIn_16xOut_4_1
cnnConvArray_1xIn_16xOut_1_2
cnnConvArray_1xIn_16xOut_2_2
cnnConvArray_1xIn_16xOut_1_3
cnnConvArray_1xIn_16xOut_1_4
cnnConvArray_2xIn_4xOut_1_1
cnnConvArray_2xIn_4xOut_2_1
cnnConvArray_2xIn_4xOut_3_1
cnnConvArray_2xIn_4xOut_4_1
cnnConvArray_2xIn_4xOut_1_2
cnnConvArray_2xIn_4xOut_2_2
cnnConvArray_2xIn_4xOut_1_3
cnnConvArray_2xIn_4xOut_1_4
cnnConvArray_2xIn_8xOut_1_1
cnnConvArray_2xIn_8xOut_2_1
cnnConvArray_2xIn_8xOut_3_1
cnnConvArray_2xIn_8xOut_4_1
cnnConvArray_2xIn_8xOut_1_2
cnnConvArray_2xIn_8xOut_2_2
cnnConvArray_2xIn_8xOut_1_3
cnnConvArray_2xIn_8xOut_1_4
cnnConvArray_2xIn_16xOut_1_1
cnnConvArray_2xIn_16xOut_2_1
cnnConvArray_2xIn_16xOut_3_1
cnnConvArray_2xIn_16xOut_4_1
cnnConvArray_2xIn_16xOut_1_2
cnnConvArray_2xIn_16xOut_2_2
cnnConvArray_2xIn_16xOut_1_3
cnnConvArray_2xIn_16xOut_1_4
cnnConvArray_3xIn_4xOut_1_1
cnnConvArray_3xIn_4xOut_2_1
cnnConvArray_3xIn_4xOut_3_1
cnnConvArray_3xIn_4xOut_4_1
cnnConvArray_3xIn_4xOut_1_2
cnnConvArray_3xIn_4xOut_2_2
cnnConvArray_3xIn_4xOut_1_3
cnnConvArray_3xIn_4xOut_1_4
cnnConvArray_3xIn_8xOut_1_1
cnnConvArray_3xIn_8xOut_2_1
cnnConvArray_3xIn_8xOut_3_1
cnnConvArray_3xIn_8xOut_4_1
cnnConvArray_3xIn_8xOut_1_2
cnnConvArray_3xIn_8xOut_2_2
cnnConvArray_3xIn_8xOut_1_3
cnnConvArray_3xIn_8xOut_1_4
cnnConvArray_3xIn_16xOut_1_1
cnnConvArray_3xIn_16xOut_2_1
cnnConvArray_3xIn_16xOut_3_1
cnnConvArray_3xIn_16xOut_4_1
cnnConvArray_3xIn_16xOut_1_2
cnnConvArray_3xIn_16xOut_2_2
cnnConvArray_3xIn_16xOut_1_3
cnnConvArray_3xIn_16xOut_1_4
cnnConvArray_4xIn_4xOut_1_1
cnnConvArray_4xIn_4xOut_2_1
cnnConvArray_4xIn_4xOut_3_1
cnnConvArray_4xIn_4xOut_4_1
cnnConvArray_4xIn_4xOut_1_2
cnnConvArray_4xIn_4xOut_2_2
cnnConvArray_4xIn_4xOut_1_3
cnnConvArray_4xIn_4xOut_1_4
cnnConvArray_4xIn_8xOut_1_1
cnnConvArray_4xIn_8xOut_2_1
cnnConvArray_4xIn_8xOut_3_1
cnnConvArray_4xIn_8xOut_4_1
cnnConvArray_4xIn_8xOut_1_2
cnnConvArray_4xIn_8xOut_2_2
cnnConvArray_4xIn_8xOut_1_3
cnnConvArray_4xIn_8xOut_1_4
cnnConvArray_4xIn_16xOut_1_1
cnnConvArray_4xIn_16xOut_2_1
cnnConvArray_4xIn_16xOut_3_1
cnnConvArray_4xIn_16xOut_4_1
cnnConvArray_4xIn_16xOut_1_2
cnnConvArray_4xIn_16xOut_2_2
cnnConvArray_4xIn_16xOut_1_3
cnnConvArray_4xIn_16xOut_1_4
cnnConvArray_8xIn_4xOut_1_1
cnnConvArray_8xIn_4xOut_2_1
cnnConvArray_8xIn_4xOut_3_1
cnnConvArray_8xIn_4xOut_4_1
cnnConvArray_8xIn_4xOut_1_2
cnnConvArray_8xIn_4xOut_2_2
cnnConvArray_8xIn_4xOut_1_3
cnnConvArray_8xIn_4xOut_1_4
cnnConvArray_8xIn_8xOut_1_1
cnnConvArray_8xIn_8xOut_2_1
cnnConvArray_8xIn_8xOut_3_1
cnnConvArray_8xIn_8xOut_4_1
cnnConvArray_8xIn_8xOut_1_2
cnnConvArray_8xIn_8xOut_2_2
cnnConvArray_8xIn_8xOut_1_3
cnnConvArray_8xIn_8xOut_1_4
cnnConvArray_8xIn_16xOut_1_1
cnnConvArray_8xIn_16xOut_2_1
cnnConvArray_8xIn_16xOut_3_1
cnnConvArray_8xIn_16xOut_4_1
cnnConvArray_8xIn_16xOut_1_2
cnnConvArray_8xIn_16xOut_2_2
cnnConvArray_8xIn_16xOut_1_3
cnnConvArray_8xIn_16xOut_1_4
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNormalizationGradient.mm
alpha:          %f
beta:           %f
delta:          %f
p0:             %f
pm:             %f
ps:             %f
cross_channel_normalization_gradient
cross_channel_normalization_gradient_array
local_contrast_normalization_gradient
local_contrast_normalization_gradient_array
spatial_normalization_gradient
spatial_normalization_gradient_array
MPSCNNCrossChannelNormalizationGradient.kernelSize
MPSCNNCrossChannelNormalizationGradient.alpha
MPSCNNCrossChannelNormalizationGradient.beta
MPSCNNCrossChannelNormalizationGradient.delta
[%@ encode...] info->primaryOffset.z != 0 not supported
[%@ encode...] info->primaryOffset.z == info->secondaryOffset.z failed
[%@ encode...] info->clipRect.origin.z != 0 not supported
MPSCNNSpatialNormalizationGradient.alpha
MPSCNNSpatialNormalizationGradient.beta
MPSCNNSpatialNormalizationGradient.delta
[%@ encode...] not enough source images:  offset.z + clipRect.size.depth > sourceImage.numberOfImages
[%@ encode...] not enough destination images:  offset.z + clipRect.size.depth > destinationImage.numberOfImages
MPSCNNLocalContrastNormalizationGradient.alpha
MPSCNNLocalContrastNormalizationGradient.beta
MPSCNNLocalContrastNormalizationGradient.delta
MPSCNNLocalContrastNormalizationGradient.p0
MPSCNNLocalContrastNormalizationGradient.pm
MPSCNNLocalContrastNormalizationGradient.ps
[%@ initWithSource:labels:lossDescriptor:] descriptor may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSNNLossNode.mm
[%@ gradientFilterWithSources:] Error: the MPSNNLoss filter doesn't have a corresponding loss gradient filter.
It produces the gradient directly as its MPSImage destination and consequently acts as its own gradient filter.
Error: loss nodes do not have a separate gradient pass. The gradient image must either be nil or lossNode.resultImage.
[%@ gradientFilterWithSources:] Error: the MPSNNInitialGradient filter doesn't have a corresponding gradient filter.
Error: the MPSNNInitialGradient filter doesn't have a corresponding gradient filter.
Internal error: The Loss filter needs loss information. The loss labels are missing. 
[%@ cnnLossDataDescriptorWithData:layout:size:...] invalid data layout type (%lu)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNLoss.mm
layout: %s
size: {%lu, %lu, %lu}
bytesPerRow: %lu
bytesPerImage: %lu
[%@ setLabelSmoothing...] labelSmoothing must be in the range [0.0f, 1.0f]
[%@ setLabelSmoothing...] labelSmoothing parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy, MPSCNNLossTypeSigmoidCrossEntropy
[%@ setNumberOfClasses...] number of classes must be greater than 0
[%@ setNumberOfClasses...] number of classes parameter is valid only for the following loss type(s): MPSCNNLossTypeSoftMaxCrossEntropy
[%@ setEpsion...] epsilon parameter is valid only for the following loss type(s): MPSCNNLossTypeLog
[%@ setDelta...] delta parameter is valid only for the following loss type(s): MPSCNNLossTypeHuber
[%@ cnnLossDescriptorWithType:reductionType:...] invalid loss type (%lu)
[%@ cnnLossDescriptorWithType:reductionType:...] invalid reduction type (%lu)
lossType: %d
reductionType: %d across batches: %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
Method unavailable. Use one of the available interfaces instead.
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] lossImageSize dimensions must be > 1
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels must be valid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] labels.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= labels.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of labels data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weightsDescriptor is specified, but the weights data is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) must match the size of labels data ({%lu, %lu, %lu})
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] weights.length (%lu) is invalid (not a multiple of sizeof(float))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= weights.length (%lu))
[%@ initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:...] size of weights data ({%lu, %lu, %lu}) is invalid (must be >= lossImageSize ({%lu %lu %lu}))
Cannot directly initialize MPSCNNLoss. Use initWithDevice:lossDescriptor: instead.
invalid loss type (%lu)
invalid reduction type (%lu)
lossType: %d
reductionType: %d, across batches = %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
_weight = %f
_labelSmoothing = %f
_epsilon = %f
_delta = %f
lossType: %d
reductionType: %d, across batch = %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
lossType: %d
reductionType: %d, across batch: %s
weight: %f
labelSmoothing: %f
numberOfClasses: %lu
epsilon: %f
delta: %f
MPSDataLayoutHeightxWidthxFeatureChannels
MPSDataLayoutFeatureChannelsxHeightxWidth
Invalid data layout type
MPSCNNLossLossType
MPSCNNLossReductionType
MPSCNNLossReduceAcrossBatches
MPSCNNLossWeight
MPSCNNLossLabelSmoothing
MPSCNNLossNumberOfClasses
MPSCNNLossEpsilon
MPSCNNLossDelta
nil != [stateLabels labelsImage], user must pass a labels image through state to calculate loss
nil != sourceImage[0]
nil != stateLabels, user must pass a labels state to calculate loss
nil != srcImage[bIdx]
nil != [stateLabels weightsImage], user must pass a weights image if first weights image is passed
[%@ encode...] number of non-zero weights cannot be 0 for reduction type MPSCNNReductionTypeSumByNonZeroWeights
gridWidth != [stateLabels labelsImage].width, the labels in state must be the same dimension as input image
gridHeight == [stateLabels labelsImage].height, the labels in state must be the same dimension as input image
((info->src.image.featureChannels) + 3) / 4) == (([stateLabels labelsImage].featureChannels + 3) / 4), the labels in state must be the same dimension as input image
LossBatch
LossFinalizeBatch
LossFinalizeAcrossBatch
countNonZeroes
finalizeCountNonZeroes
MPSCNNGram_hasPropertyCallback
MPSCNNGram_propertyCallback
MPSNNLossGradientComputeLabelGradients
LossBatchFwd
LossBatchGradient
Cannot directly initialize MPSCNNUpsamplingGradient. Use one of the sub-classes of MPSCNNUpsamplingGradient.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNUpsamplingGradient.mm
MPSCNNUpsamplingGradient.filterType
MPSCNNUpsamplingGradient.scaleFactorX
MPSCNNUpsamplingGradient.scaleFactorY
MPSCNNUpsamplingGradient_general
[%@ encode...] filter initialized with no feature channels.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNGroupNormalization.mm
[%@ encode...] filter: numberOfFeatureChannels must be divisible by numOfGroups.
Cannot create state for images containing multiple images.
data source: %p %@
epsilon: %g
numberOfGroups: %d
[%@ gradientForGamma] Gradient state does not contain a buffer for gamma gradient values.
[%@ gradientForBeta] Gradient state does not contain a buffer for beta gradient values.
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
group normalization filter: %@
feature channels: %lu
feature channels: %lu
epsilon: %g
imageGroupNormalizationThreadgroupSum
imageGroupNormalizationImageSum
imageGroupNormalization
[%@ encode...] filter initialized with %lu feature channels but destination (after offset) contains only %lu feature channels.
[%@ encode...] filter initialized with %lu feature channels but source (after offset) contains only %lu feature channels.
reduceFeatureChannelsIntoGroups
kMPSCNNGroupNormalization.s
kMPSCNNGroupNormalization.o
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNPermute.mm
[%@ %@] Permutations involving channel and image dimension not supported on this device.
MPSPermute3
MPSNNPermuteDimensionOrder0
MPSNNPermuteDimensionOrder1
MPSNNPermuteDimensionOrder2
MPSNNPermuteDimensionOrder3
MPSBatchTranspose
parent filter: %p
format:          %d
handle:          <%p> %@
                 %@
allocator:       %p
exportFromGraph: %s
synchronize:     %s
stopGradient:    %s
parent filter: %p
handle: <%p> %@
synchronize: %s
        %@
[%@ initWithSourceImages...] sourceImages may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNGraphNodes.mm
[%@ initWithSourceImages...] sourceImages.count may not be 0
[%@ initWithSourceImages...] sourceStates.count may not be 0
[%@ %@] Error: the source filter that produces the source image %p apparently has been released and no longer exists.
Consequently, you wont be able to construct a graph to produce this image. The graph of nodes will not be usable.
This is a common mistake. The result image doesn't retain its parent. That would cause a reference cycle.
Your application needs to keep the parent filter around so that the result image sticks around, until after
some other filter is initialized to consume the result image. The consuming filter will retain the parent filter
of the intermediate image, so that all you need to keep a reference for is the last filter in the chain.
Image:
(parent filter no longer available, so can't be reported here.)
Note: To prevent graph propagation beyond an image node, see -stopGradient.
[%@ %@] Error: the source filter that produces the source state %p apparently has been released and no longer exists.
Consequently, you wont be able to construct a graph to produce this state. The graph of nodes will not be usable.
This is a common mistake. The result state doesn't retain its parent. That would cause a reference cycle.
Your application needs to keep the parent filter around so that the result state sticks around, until after
some other filter is initialized to consume the result state. The consuming filter will retain the parent filter
of the intermediate image, so that all you need to keep a reference for is the last filter in the chain.
State:
(parent filter no longer available, so can't be reported here.)
%@, %p
%@ "%@"
source images:  %@
source states:  %@
resultImage:    %p
result states:  %@
padding policy: 
<no label>
[%@ newFilterNode] Internal error: child class fails to override this method.
[%@ gradientFilterWithSources:] This is not a unary filter. Please use gradientFiltersWithSources: (extra 's') instead. 
[%@ gradientFilterWithSources:] Internal error: this isn't a unary filter and needs to override this method to return multiple filters
gradient for %p "%@" (%@)
gradient for %p (%@)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNSlice.mm
Source Index: %lu
Error: EncodeSlice() encountered caller of wrong class type
Insufficient number of feature channels in destination %p
slice_along_width_height
slice_along_feature_channels
MPSNNConcatenationGradient.sourceIndex
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInstanceNormalization.mm
data source: %p %@
epsilon: %g
meanAndVariance: %@
gradientGamma %@
tgradientBeta %@
instance normalization filter: %@
feature channels: %lu
epsilon: %g
imageInstanceNormalizationThreadgroupSum
imageInstanceNormalizationImageSum
imageInstanceNormalization
kMPSCNNInstanceNormalization.s
kMPSCNNInstanceNormalization.o
resize width (%lu) must be > 0
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNCropAndResize.mm
resize height (%lu) must be > 0
Number of regions (%lu) must be > 0
regions argument cannot be a nil value
MPSRegion origin.z must be 0
MPSRegion size.depth must be 0
[%s initWithCoder:device:] failed. Regions array size mismatch
CropAndResizeBilinearOperation
crop_and_resize_bilinear_tex2d_tex2d
crop_and_resize_bilinear_tex2d_tex2darray
crop_and_resize_bilinear_tex2d_tex2d_float32
crop_and_resize_bilinear_tex2d_tex2darray_float32
MPSNNCropAndResizeBilinear.resizeWidth
MPSNNCropAndResizeBilinear.resizeHeight
MPSNNCropAndResizeBilinear.numberOfRegions
MPSNNCropAndResizeBilinear.regions
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNPooling.mm
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
dilationRateX (%lu) must be > 0
dilationRateY (%lu) must be > 0
dilationRateX: %lu
dilationRateY: %lu
MPSCNNPooling.kernelWidth
MPSCNNPooling.kernelHeight
MPSCNNPooling.strideX
MPSCNNPooling.strideY
[%@ encode...] unsupported feature channels layout (MPSImageFeatureChannelsInterleavedPerPixel)
MPSCNNPooling_horizontal_tex2d_tex2d_max
MPSCNNPooling_horizontal_tex2darray_tex2darray_max
MPSCNNPooling_horizontal2_tex2d_tex2d_max
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max
MPSCNNPooling_vertical_tex2d_tex2d_max
MPSCNNPooling_vertical_tex2darray_tex2darray_max
MPSCNNPooling_2x2_tex2d_tex2d_max
MPSCNNPooling_2x2_tex2darray_tex2darray_max
MPSCNNPooling_3x3_tex2d_tex2d_max
MPSCNNPooling_3x3_tex2darray_tex2darray_max
MPSCNNPooling_new_tex2d_tex2d_max_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_new_tex2d_tex2d_max_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_max_swEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_vertical_tex2d_tex2d_max_swEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_2x2_tex2d_tex2d_max_swEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_3x3_tex2d_tex2d_max_swEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_max_swEdge
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_max_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_max_swEdge_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg
MPSCNNPooling_horizontal2_tex2d_tex2d_avg
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg
MPSCNNPooling_vertical_tex2d_tex2d_avg
MPSCNNPooling_vertical_tex2darray_tex2darray_avg
MPSCNNPooling_2x2_tex2d_tex2d_avg
MPSCNNPooling_2x2_tex2darray_tex2darray_avg
MPSCNNPooling_3x3_tex2d_tex2d_avg
MPSCNNPooling_3x3_tex2darray_tex2darray_avg
MPSCNNPooling_new_tex2d_tex2d_avg_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x2_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_5x5_2
MPSCNNPooling_horizontal_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_horizontal2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_horizontal2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_vertical_tex2d_tex2d_avg_shEdge
MPSCNNPooling_vertical_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_2x2_tex2d_tex2d_avg_shEdge
MPSCNNPooling_2x2_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_3x3_tex2d_tex2d_avg_shEdge
MPSCNNPooling_3x3_tex2darray_tex2darray_avg_shEdge
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x1_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x2_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x2_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x2_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x3_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x3_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x4_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x4_2
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_1x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_2x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_3x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_4x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_0
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_1
MPSCNNPooling_new_tex2d_tex2d_avg_swEdge_5x5_2
MPSCNNPooling_new_tex2darray_tex2darray_avg_swEdge_5x5_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_2x2_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_0
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_1
MPSCNNPooling_newXDir_tex2d_tex2d_max_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_3x3_2
MPSCNNPooling_newXDir_tex2d_tex2d_max_swEdge_3x3_2
MPSCNNPooling_newXDir_tex2darray_tex2darray_max_swEdge_3x3_2
cnnPoolingGeneric
cnnPoolingGeneric_ppt2
MPSCNNPooling.padSizeX
MPSCNNPooling.padSizeY
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationGradient.mm
imageBatchNormalizationGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBinaryKernel.mm
<NULL>
primaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld  len: %ld}
secondaryOffset:        {%ld,%ld,%ld}  feature channel offset {loc: %ld len: %ld}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destChannelOffset{%ld} 
device:        %p
primary edge mode:     %s
secondary edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
2nd KernelSize: {%lu x %lu}
primary stride:      {%lu x %lu}
secondary stride:      {%lu x %lu}
dilation rate:        {%lu x %lu}
2nd dilation rate:    {%lu x %lu}
backwards?  %s
broadcasting?  %s
padding:       %@
MPSImageEdgeModeClamp
MPSImageEdgeModeZero
destinationFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelOffset must be multiple of 4
secondarySourceFeatureChannelOffset must be multiple of 4
primarySourceFeatureChannelMaxCount must be multiple of 4
secondarySourceFeatureChannelMaxCount must be multiple of 4
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:] Unable to create MPSImageDescriptor for destination.  Encode failed.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  primary source image is a temporary image with readCount of 0.
Backing texture for primary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:] error:  secondary source image is a temporary image with readCount of 0.
Backing texture for secondary source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  destination image is a temporary image with readCount of 0.
Backing texture for destination image is no longer valid. image=%p
Feature Channel Layout of primary source and destination does not match
Feature Channel Layout of secondary source and destination does not match
Primary source %p texture type (%lu) is unsupported
Secondary source %p texture type (%lu) is unsupported
Primary source %p texture format %lu must support filtering.
Secondary source %p texture format %lu must support filtering.
Primary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Secondary source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Primary source MTLTextureType2D must have primaryOffset.z = 0
Primary source MTLTextureType2D must have clipRect.size.depth = 1
Primary source MTLTextureTypeArray2D must have 0 <= primaryOffset.z < primaryImage.numberOfImages
Primary source MTLTextureTypeArray2D must have clipRect.size.depth such that _primaryOffset.z + clipRect.depth < primaryImage.numberOfImages
Secondary source MTLTextureType2D must have secondaryOffset.z = 0
Secondary source MTLTextureType2D must have clipRect.size.depth = 1
Secondary source MTLTextureTypeArray2D must have 0 <= secondaryOffset.z < secondaryImage.numberOfImages
Secondary source MTLTextureTypeArray2D must have clipRect.size.depth such that _secondaryOffset.z + clipRect.depth < secondaryImage.numberOfImages
Destination %p texture type (%lu) is unsupported
Destination %p texture format %lu  must be writable.
Destination %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Destination MTLTextureType2D must have clipRect.origin.z = 0
Destination MTLTextureType2D must have clipRect.size.depth = 1
Destination MTLTextureTypeArray2D must have 0 <= clipRect.origin.z < dest.numberOfImages
Destination MTLTextureTypeArray2D must have clipRect.size.depth such that clipRect.origin.z + clipRect.depth < dest.numberOfImages
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for primaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for secondaryImage must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of primary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: The number of secondary source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture.  Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of primary source
[%@ encodeToCommandBuffer:primaryTexture:secondaryTexture:destinationTexture:] Internal Error: unable to make texture2d view of secondary source
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of destination
[%@ encode...] primary source may not be nil
[%@ encode...] secondary source may not be nil
[%@ %@] Error: the primary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the primary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the secondary source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ %@] Error: the secondary source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ %@] Error: the destination image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
[%@ batchEncode...] out of memory: unable to allocate storage to hold encode arguments on device.
[%@ encode...] the primary offset.z may not be negative
[%@ encode...] the secondary offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > primaryImages.count(%lu)
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > secondaryImages.count(%lu)
[%@ encode...] each of the individual primary source images in a batch must have numberOfImages = 1
[%@ encode...] each of the individual secondary source images in a batch must have numberOfImages = 1
[%@ encode...] error: all primary source image sizes must match
[%@ encode...] error: all secondary source image sizes must match
[%@ encode...] error: all primary source number of feature channels must match
[%@ encode...] error: all secondary source number of feature channels must match
[%@ %@] Error: the primary source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ %@] Error: the secondaryImage source image texture has a zero read count, and has probably already been released for reuse by another texture or buffer.
[%@ encode...] each of the individual destination images in a batch must have numberOfImages = 1
[%@ encode...] error: all destination image sizes must match
[%@ encode...] error: all destination number of feature channels must match
[%@ destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset] Error:
 This is a binary filter. sourceImages should be an array of at least length 2.
%@: Error for filters that support broadcasting the input source image widths must match (or be 1)
%@: Error for filters that support broadcasting the input source image heights must match (or be 1)
%@: Error for filters that support broadcasting the input source image count must match (or be 1)
%@: Error for filters that support broadcasting the number of input source image feature channels must match (or be 1)
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch count is smaller than the primaryImage batch count
[%@ resultStateBatchForPrimaryImage:secondaryImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: primaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:] Error: secondaryImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: if sourceStates is non-NULL, there must be at least as many source states as source images
Internal error: [%@ encodeWithCoder:] unavailable
MPSCNNBinaryKernel.primaryOffset.x
MPSCNNBinaryKernel.primaryOffset.y
MPSCNNBinaryKernel.primaryOffset.z
MPSCNNBinaryKernel.secondaryOffset.x
MPSCNNBinaryKernel.secondaryOffset.y
MPSCNNBinaryKernel.secondaryOffset.z
MPSCNNBinaryKernel.clipRect.origin.x
MPSCNNBinaryKernel.clipRect.origin.y
MPSCNNBinaryKernel.clipRect.origin.z
MPSCNNBinaryKernel.clipRect.size.width
MPSCNNBinaryKernel.clipRect.size.height
MPSCNNBinaryKernel.clipRect.size.depth
MPSCNNBinaryKernel.destinationFeatureChannelOffset
MPSCNNBinaryKernel.sourceFeatureChannelOffset1
MPSCNNBinaryKernel.sourceFeatureChannelOffset2
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount1
MPSCNNBinaryKernel.sourceFeatureChannelMaxCount2
MPSCNNBinaryKernel.primaryEdgeMode
MPSCNNBinaryKernel.secondaryEdgeMode
MPSCNNBinaryKernel.checkFlags
MPSCNNBinaryKernel.kernelWidth
MPSCNNBinaryKernel.kernelHeight
MPSCNNBinaryKernel.secondaryKernelWidth
MPSCNNBinaryKernel.secondaryKernelHeight
MPSCNNBinaryKernel.primaryStride.x
MPSCNNBinaryKernel.primaryStride.y
MPSCNNBinaryKernel.secondaryStride.x
MPSCNNBinaryKernel.secondaryStride.y
MPSCNNBinaryKernel.dilationRate.x
MPSCNNBinaryKernel.dilationRate.y
MPSCNNBinaryKernel.secondaryDilationRate.x
MPSCNNBinaryKernel.secondaryDilationRate.y
MPSCNNBinaryKernel.isBackward
MPSCNNBinaryKernel.supportsBroadcasting
MPSCNNBinaryKernel.data
MPSCNNBinaryKernel.padding
MPSCNNBinaryKernel.data2
MPSCNNBinaryKernel.allocator
MPSCNNBinaryImageFilter.className
MPSCNNBinaryImageFilter.class
Error: attempted to extract gamma buffer from temporary MPSState with readCount of 0.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBatchNormalizationState.mm
Error: attempted to extract beta buffer from temporary MPSState with readCount of 0.
Error: attempted to extract mean buffer from temporary MPSState with readCount of 0.
Error: attempted to extract variance buffer from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForGamma from temporary MPSState with readCount of 0.
Error: attempted to extract gradientForBeta from temporary MPSState with readCount of 0.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNResize.mm
ResizeBilinearOperation
resize_bilinear_tex2d_tex2d
resize_bilinear_tex2darray_tex2darray
resize_bilinear_tex2d_tex2d_float32
resize_bilinear_tex2darray_tex2darray_float32
MPSNNResizeBilinear.resizeWidth
MPSNNResizeBilinear.resizeHeight
MPSNNResizeBilinear.alignCorners
[%@ initWithGradientImage:forwardFilter:] filter <%p> must be a member of class MPSNNDropoutNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNDropoutNodes.mm
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNGroupNormalizationGradient.mm
imageGroupNormalizationThreadgroupDot
imageGroupNormalizationImageDot
imageGroupNormalizationGradient
reduceFeatureChannelsIntoGroupsDot
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid neuron type (%lu)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNeuron.mm
[%@ cnnNeuronDescriptorWithType:a:b:c:...] invalid initialization method for the following neuron type(s): MPSCNNNeuronPReLU
[%@ cnnNeuronPReLUDescriptorWithData:...] data must be valid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid
[%@ cnnNeuronPReLUDescriptorWithData:count:...] data length (%lu) is invalid (not a multiple of sizeof(float))
neuronType: %s
a: %f 
b: %f 
c: %f 
data: %p
neuronType: %s
a: %f 
b: %f
neuronType: %s
a: %f 
b: %f 
c: %f
invalid neuron type (%lu)
[%@ initWithDevice:neuronDescriptor:...] data in neuron descriptor must be valid
[%@ initWithDevice:neuronDescriptor:...] data length (%lu) is invalid
Cannot directly initialize MPSCNNNeuron. Use initWithDevice:neuronDescriptor: or one of the sub-classes of MPSCNNNeuron
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation. See the requirements listed for the newBufferWithBytesNoCopy:length:options:deallocator Metal API.
noCopy flag is set to YES, but the memory allocation does not meet the requirements for no-copy allocation
v24@?0^v8Q16
MPSCNNNeuronTypeNone  (f(x) = x)
MPSCNNNeuronTypeReLU  (f(x) = x >= 0 ? x : a * x)
MPSCNNNeuronTypeLinear  (f(x) = a * x + b)
MPSCNNNeuronTypeSigmoid  (f(x) = 1 / (1 + e^-x))
MPSCNNNeuronTypeHardSigmoid  (f(x) = clamp((x * a) + b, 0, 1))
MPSCNNNeuronTypeTanH    (f(x) = a * tanh(b * x))
MPSCNNNeuronTypeAbsolute  (f(x) = fabs(x))
MPSCNNNeuronTypeSoftPlus  (f(x) = a * log(1 + e^(b * x)))
MPSCNNNeuronTypeSoftSign  (f(x) = x / (1 + abs(x)))
MPSCNNNeuronTypeELU   (f(x) = x >= 0 ? x : a * (exp(x) - 1))
MPSCNNNeuronTypePReLU  (f(x[i]) = x[i] >= 0 ? x[i] : a[i] * x[i]), i in [0,featureChannels-1]
MPSCNNNeuronTypeReLUN  (f(x) = min((x >= 0 ? x : a * x), b))
MPSCNNNeuronTypePower  (f(x) = (a * x + b) ^ c)
MPSCNNNeuronTypeExponential  (f(x) = c ^ (a * x + b))
MPSCNNNeuronTypeLogarithm  (f(x) = log_c(a * x + b))
MPSCNNNeuronTypeGeLU  (f(x) = (1.0 + erf(x * sqrt(0.5))) * 0.5 * x)
<invalid/missing type>
neuronType: %s
a: %f
b: %f
c: %f
data: %p
neuronType: %s
a: %f
b: %f
c: %f
neuronType: %s
a: %f
b: %f
Cannot call this initializer on this class.
MPSNNNeuronDescriptor.A
MPSNNNeuronDescriptor.B
MPSNNNeuronDescriptor.C
MPSNNNeuronDescriptor.neuronType
MPSNNNeuronDescriptor.PReLuData
MPSNNNeuronDescriptor.PReLuCount
MPSCNNNeuronTypeName
MPSCNNNeuronA
MPSCNNNeuronB
MPSCNNNeuronC
MPSCNNNeuronAArrayIsNil
MPSCNNNeuronAArrayLength
MPSCNNNeuronAArray
cnnNeuronGradient
cnnNeuron
MPSCNNNeuronGradientTypeName
MPSCNNNeuronGradientA
MPSCNNNeuronGradientB
MPSCNNNeuronGradientC
MPSCNNNeuronGradientAArrayIsNil
MPSCNNNeuronGradientAArrayLength
MPSCNNNeuronGradientAArray
alpha = %f
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNGramMatrix.mm
alpha: %f
MPSCNNGram_alpha
Cannot directly initialize MPSNNReduceUnary. Use one of the sub-classes of MPSNNReduceUnary.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSNNReduce.mm
ReduceOperation: %lu
Cannot directly initialize MPSNNReduceBinary. Use one of the sub-classes of MPSNNReduce.
reduce_min_row_simd_rgba
reduce_min_column_simd_rgba
reduce_min_feature_channels_simd_rgba
reduce_argument_min_feature_channels_simd_rgba_uint
reduce_argument_min_feature_channels_simd_rgba_float
reduce_max_row_simd_rgba
reduce_max_column_simd_rgba
reduce_max_feature_channels_simd_rgba
reduce_argument_max_feature_channels_simd_rgba_uint
reduce_argument_max_feature_channels_simd_rgba_float
reduce_mean_row_simd_rgba
reduce_mean_column_simd_rgba
reduce_mean_feature_channels_simd_rgba
reduce_mean_feature_channels_and_weight_simd_rgba
reduce_array_min_row_simd_rgba
reduce_array_min_column_simd_rgba
reduce_array_min_feature_channels_simd_rgba
reduce_array_argument_min_feature_channels_simd_rgba_uint
reduce_array_argument_min_feature_channels_simd_rgba_float
reduce_array_max_row_simd_rgba
reduce_array_max_column_simd_rgba
reduce_array_max_feature_channels_simd_rgba
reduce_array_argument_max_feature_channels_simd_rgba_uint
reduce_array_argument_max_feature_channels_simd_rgba_float
reduce_array_mean_row_simd_rgba
reduce_array_mean_column_simd_rgba
reduce_array_mean_feature_channels_simd_rgba
reduce_array_mean_feature_channels_and_weight_simd_rgba
reduce_local_correlation
reduce_min_row_quadshuffle_rgba
reduce_min_column_quadshuffle_rgba
reduce_max_row_quadshuffle_rgba
reduce_max_column_quadshuffle_rgba
reduce_mean_row_quadshuffle_rgba
reduce_mean_column_quadshuffle_rgba
reduce_array_min_row_quadshuffle_rgba
reduce_array_min_column_quadshuffle_rgba
reduce_array_min_feature_channels_quadshuffle_rgba
reduce_array_argument_min_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_min_feature_channels_quadshuffle_rgba_float
reduce_array_max_row_quadshuffle_rgba
reduce_array_max_column_quadshuffle_rgba
reduce_array_max_feature_channels_quadshuffle_rgba
reduce_array_argument_max_feature_channels_quadshuffle_rgba_uint
reduce_array_argument_max_feature_channels_quadshuffle_rgba_float
reduce_array_mean_row_quadshuffle_rgba
reduce_array_mean_column_quadshuffle_rgba
reduce_array_mean_feature_channels_quadshuffle_rgba
reduce_array_mean_feature_channels_and_weight_quadshuffle_rgba
MPSNNReduce.clipRectSource.origin.x
MPSNNReduce.clipRectSource.origin.y
MPSNNReduce.clipRectSource.origin.z
MPSNNReduce.clipRectSource.size.width
MPSNNReduce.clipRectSource.size.height
MPSNNReduce.clipRectSource.size.depth
MPSNNReduce.reduceOp
MPSNNReduce.weight
[%@ encode...] filter cannot have stride 0 in either dimension.
MPSNNReduce.primarySourceClipRect.origin.x
MPSNNReduce.primarySourceClipRect.origin.y
MPSNNReduce.primarySourceClipRect.origin.z
MPSNNReduce.primarySourceClipRect.size.width
MPSNNReduce.primarySourceClipRect.size.height
MPSNNReduce.primarySourceClipRect.size.depth
MPSNNReduce.secondarySourceClipRect.origin.x
MPSNNReduce.secondarySourceClipRect.origin.y
MPSNNReduce.secondarySourceClipRect.origin.z
MPSNNReduce.secondarySourceClipRect.size.width
MPSNNReduce.secondarySourceClipRect.size.height
MPSNNReduce.secondarySourceClipRect.size.depth
MPSNNReduce.windowInX
MPSNNReduce.windowInY
MPSNNReduce.strideInX
MPSNNReduce.strideInY
[<MPSCNNConvolutionDataSource> initWithSource:neuronInfo:batchNorm] Internal error: attempted to overwrite a convolution data source descriptor batch norm info with another set of batch norm info.
These should not be coalesced.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/BackwardsCompatibility.mm
rangesForUInt8Kernel
rangesForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method 
lookupTableForUInt8Kernel
lookupTableForUInt8Kernel called on MPSCNNConvolutionDataSource that does not support the optional protocol method
MPSWeightsWrapper_SecureCoding.c0
MPSWeightsWrapper_SecureCoding.o0
MPSWeightsWrapper_SecureCoding.c1
MPSWeightsWrapper_SecureCoding.o1
MPSWeightsWrapper_SecureCoding.c2
MPSWeightsWrapper_SecureCoding.o2
MPSWeightsWrapper_SecureCoding.it
MPSWeightsWrapper_SecureCoding.ia
MPSWeightsWrapper_SecureCoding.ib
MPSWeightsWrapper_SecureCoding.ic
MPSWeightsWrapper_SecureCoding.id
Error: expected secure coding support from object: 
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNKernel.mm
offset:        {%ld,%ld,%ld} sourceFeatureChannelRange{offset: %ld, len: %lu}
clip:          origin{%lu,%lu,%lu} size{%lu,%lu,%lu} destinationFeatureChannelOffset{%ld} 
device:        %p
edge mode:     %s
Encode Proc:   %s
Kernel Size:   {%lu x %lu}
stride:        {%lu x %lu}
dilation factor {%lu x %lu}
backwards?  %s
destinationImageAllocator: %@
padding:       %@
sourceFeatureChannelOffset must be multiple of 4
setSourceFeatureChannelMaxCount must be multiple of 4
[%@ resultStateBatchForSourceImages:sourceStates:] Error: sourceImage batch may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: command buffer may not be NULL
[%@ temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:] Error: sourceImage batch may not be NULL
[%@ encodeToCommandBuffer:sourceImage:destinationImage:] error:  source image is a temporary image with readCount of 0.
Backing texture for source image is no longer valid. image=%p
Perhaps you forgot to set the readCount property?
Feature Channel Layout of source and destination does not match
Source %p texture type (%lu) is unsupported
Source %p texture format %lu  must support filtering.
Source %p texture type must be MTLTextureType2D or MTLTextureType2D_array
Source MTLTextureType2D must have offset.z = 0
Source MTLTextureType2D must have clipRect.size.depth = 1
Source MTLTextureTypeArray2D must have 0 <= offset.z < source.numberOfImages
Source MTLTextureTypeArray2D must have clipRect.size.depth such that _offset.z + clipRect.depth < source.numberOfImages
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: the filter edge mode must be MPSImageEdgeModeZero for feature channels > 4.
[%@ encodeToCommandBuffer:sourceImage:destinationImage]: The number of source feature channels must match the number of destination feature channels for this filter.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture: can not operate in place.
[%@ encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage]: the filter edge mode for source image must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ encodeToCommandBuffer:...]: source MPSImage contains a nil texture. Cannot continue.
[%@ encodeToCommandBuffer:...]: destination MPSImage contains a nil texture. Perhaps it was lazily allocated but turned out to be too large? Cannot continue.
[%@ encodeToCommandBuffer:sourceTexture:destinationTexture:] Internal Error: unable to make texture2d view of source
[%@ encode...] Error: an error (%s) was encountered preventing this kernel from encoding.
[%@ encode...] Error: commandBuffer may not be nil]
[%@ encode...] Error: source may not be nil
[%@ encode...] Error: destination may not be nil
[%@ encode...] Error: options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ encode...] Error: source feature channel offset (%lu) is too large to fit in the source image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) is too large to fit in the destination image (%p).
[%@ encode...] Error: destination feature channel offset (%lu) must be divisible by 4.
Other values would require read-modify-write on individual texels which is not supported by some hardware and a problem for concurrent operation everywhere.
[%@ encode...]: Error: non-zero source feature channel offset unsupported for compound MPSImages. Use a MPSImageBatch instead.
[%@ %@] Error: the source image texture is uninitialized.
This typically means that nothing has written to it yet, and its contents are undefined.
[%@ encode...] the offset.z may not be negative
[%@ encode...] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ encode...] Error invalid operation: offset.z(%d) < 0
[%@ encode...] Error invalid operation: the offset.z.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ encode...] each of the individual source images in a batch must have numberOfImages = 1
[%@ encode...] error: all source image sizes must match
[%@ encode...] error: all source number of feature channels must match
[%@ %@] Error: the source image texture is temporary and has a readCount of 0.
Its texel storage is probably in use for another texture now.
%s | %s | %s%s%s
%s, %s, %s%s%s
[MPSNNDefaultPadding paddingWithMethod:]: Can not create a new object with a custom sizing policy.
You must implement your own object using the MPSNNPadding Policy.
MPSCreatePaddingPolicy(): invalid / unknown bits in MPSNNPaddingMethod.
Error: overrelease of MPS owned MPSNNDefaultPadding object:
  %@
%@  variant: %@
MPSCNNKernel.offset.x
MPSCNNKernel.offset.y
MPSCNNKernel.offset.z
MPSCNNKernel.clipRect.origin.x
MPSCNNKernel.clipRect.origin.y
MPSCNNKernel.clipRect.origin.z
MPSCNNKernel.clipRect.size.width
MPSCNNKernel.clipRect.size.height
MPSCNNKernel.clipRect.size.depth
MPSCNNKernel.destinationFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelOffset
MPSCNNKernel.sourceFeatureChannelMaxCount
MPSCNNKernel.edgeMode
MPSCNNKernel.checkFlags
MPSCNNKernel.kernelWidth
MPSCNNKernel.kernelHeight
MPSCNNKernel.stride.x
MPSCNNKernel.stride.y
MPSCNNKernel.dilation.x
MPSCNNKernel.dilation.y
MPSCNNKernel.isBackward
MPSCNNKernel.data
MPSCNNKernel.padding
MPSCNNKernel.data2
MPSCNNKernel.allocator
[%@ resource] Internal error: unhandled resource type
/Library/Caches/com.apple.xbs/Binaries/MetalPerformanceShaders_Sim/install/Symbols/BuiltProducts/MPSCore.framework/PrivateHeaders/Internal/MPSStateInternal.h
SizeValidOnly
SizeSame
SizeFull
Size_reserved
AlignCentered
AlignTopLeft
AlignBottomRight
Align_reserved
AddRemainderToTopLeft
AddRemainderToTopRight
AddRemainderToBottomLeft
AddRemainderToBottomRight
MPSNNPaddingMethod.CustomAllowForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.Custom (inhibits node fusion)
MPSNNPaddingMethod.Custom (allow for node fusion)
MPSNNPaddingMethod.ExcludeEdges
MPSNNPaddingMethod.ExcludeEdges | CustomAllowForNodeFusion (ignored without MPSNNPaddingMethodCustom)
MPSNNPaddingMethod.ExcludeEdges | Custom (inhibits node fusion)MPSNNPaddingMethod.ExcludeEdges | Custom (allow for node fusion)
kMPSNNPaddingMethod_vers
kMPSNNPaddingMethod
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelWidth may not be 0
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNPoolingNodes.mm
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY]: kernelHeight may not be 0
MPS internal error: Need to override newFilterNodeForDevice for %@
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelWidth may not be 0
[%@ initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY]: kernelHeight may not be 0
[%@ initWithGradientImages:forwardFilter:] Error forwardFilter %p is not a MPSCNNPoolingNode
[%@ initWithGradientImages:forwardFilter:] Error: the filter <%p> is not a MPSCNNDilatedPoolingMaxNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixNeuronGradient.mm
[%@ apply...] source gradient matrix may not be nil
Matrices/vectors contain batches, batching not supported.
Only bias gradient vector value types of MPSDataTypeFloat32 are supported.
MatrixNeuronGradient
MPSMatrixNeuronGradient._alpha;
MPSMatrixNeuronGradient._sourceNumberOfFeatureVectors;
MPSMatrixNeuronGradient._sourceInputFeatureChannels;
MPSMatrixNeuronGradient._neuronType;
MPSMatrixNeuronGradient._neuronA;
MPSMatrixNeuronGradient._neuronB;
MPSMatrixNeuronGradient._neuronC;
MPSMatrixNeuronGradient._perChannelNeuronA;
^v32@?0@"MPSKernel"8r^^v16^Q24
^v32@?0^{_NSZone=}8r^v16@"<MTLDevice>"24
Error: unable to read node data for %@ <%p>. File (or data chunk within file) too small.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/FilterNodeConstructors.mm
Error: unable to read node data for %@ <%p>. File version too new.
Error: unable to read node data for %@ <%p>. File version too old.
Error: unable to read node data for %@ <%p>. File could not be parsed.
Error: unable to read node data for %@ <%p>. Unhandled / unknown error %u.
MPSInternalError: Cant copy object with internal id out of bounds.
MPSInternalError: attempted to copy object type %lu but ended up with object type %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionA14.mm
v8@?0
MPS_DIRECTCONV_NODMA
cnnConvArrayGeneralA14
cnnConvArrayUpdateGeneralA14
cnnConvWinograd_2x2_3x3_32x32_256
cnnConvWinograd_2x2_3x3_32x16_256
cnnConvWinograd_2x2_3x3_16x32_256
cnnConvWinograd_2x2_3x3_16x16_128
cnnConvWinograd_2x2_3x3_32x32_256_linear
cnnConvWinograd_2x2_3x3_32x16_256_linear
cnnConvWinograd_8x8_3x3_32x32_256
cnnConvWinograd_8x8_3x3_32x32_256_half_intermediate
MPS_DISABLE_SIMDMATMUL
MPS_DIRECT_CONVOLUTION
[%@ %@] Error: method not available. Use -initWithDevice:sourceCount: instead.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNMultiaryKernel.mm
[%@ %@] Error: invalid index: %lu.  This filter has %lu sources.
MPSCNNMultiaryKernel.srcCount
MPSCNNMultiaryKernel.srcDataKeyv1
MPSCNNMultiaryKernel.isBackwards
MPSCNNMultiaryKernel.supportsBroadcasting
MPSCNNMultiaryKernel.clipRect.origin.x
MPSCNNMultiaryKernel.clipRect.origin.y
MPSCNNMultiaryKernel.clipRect.origin.z
MPSCNNMultiaryKernel.clipRect.size.x
MPSCNNMultiaryKernel.clipRect.size.y
MPSCNNMultiaryKernel.clipRect.size.z
MPSCNNMultiaryKernel.destinationFeatureChannelOffset
MPSCNNMultiaryKernel.paddingType
MPSCNNMultiaryKernel.paddingData
MPSCNNMultiaryKernel.allocatorType
MPSCNNMultiaryKernel.allocatorData
MPSCNNMultiaryKernel.checkFlags
[%@ %@] Error: private data missing or in future format. Unable to decode object.
[%@ %@] Error: unexpected data length found in file. Unable to decode object.
[%@ %@] commandBuffer may not be nil]
[%@ %@] source may not be nil
[%@ %@] destination may not be nil
[%@ %@] Error: destination may not be nil
[%@ %@] options flag(s) 0x%16.16lx is unknown or invalid for use with this filter
[%@ %@] the offset.z of source %lu may not be negative
[%@ %@]: the filter edge mode for source image must be MPSImageEdgeModeZero or MPSImageEdgeModeClamp for this filter.
[%@ %@] Error invalid operation: the clipRect.origin.z(%lu) + clipRect.size.depth(%lu) > destinationImages.count(%lu)
[%@ %@] each of the individual source images in a batch must have numberOfImages = 1
[%@ %@] error: all source image sizes must match
[%@ %@:sourceStates:] Error: sourceImages may not be NULL
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNSoftMaxGradient.mm
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) ==                    (info->secondarySrc.featureChannels - info->secondarySourceFeatureChannelOffset) failed
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) <=                    (info->dest.featureChannels) failed
softmax_gradient
softmax_gradient_array
softmax_gradient_multipass
softmax_gradient_multipass_array
log_softmax_gradient
log_softmax_gradient_array
log_softmax_gradient_multipass
log_softmax_gradient_multipass_array
[%@ encode...] (info->primarySrc.featureChannels - info->primarySourceFeatureChannelOffset) <=                    (info->dest.featureChannels - destinationFeatureChannelOffset) failed
[%@ initWithSource:] Probable error: concatenate a image with nothing?
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSNNConcatenationNode.mm
{%lu x %lu x %lu}[%lu](offset:0)
"%@"
%s (%lu) [%s] -> {%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
%s (%lu) %lu*[%s] -> %lu*{%lu x %lu x %lu}[%lu]
offset: %lu
padding policy: n/a
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the gradient state was not produced by a MPSNNConcatenationNode.
[%@ initWithSourceGradient:sourceImage:gradientState:] Error: the sourceImage provided was not among the input images to the MPSNNConcatenationNode
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNSpatialNormalizationNode
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNNormalizationNodes.mm
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNLocalContrastNormalizationNode
[%@ initWithSource:dataSource:] dataSource may not be NULL
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:instanceNormalizationState:
instance normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
Error: unable to do GPU group normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:groupNormalizationState:
group normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU group normalization update pass because the data source doesn't implement -updateGammaAndBetaWithNormalizationState:
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNBatchNormalizationNode
Error: unable to do GPU instance normalization update pass because the data source doesn't implement -updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
batch normalization gradient  update pass: the state may not be a temporary state for CPU update.
Error: unable to do GPU batch normalization update pass because the data source doesn't implement -updateGammaAndBetaWithBatchNormalizationState:
Batch normalization node calculates statistics
Please initialize the %@ class with initWithDevice:weights:
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNInnerProduct.mm
Number of groups for inner product should be 1
strideX for inner product should be 1
strideY for inner product should be 1
Please initialize the %@ class with initWithDevice:convolutionDescriptor:kernelWeights:biasTerms
initializer unavailable
strideX should be 1 for fully connected kernel
strideY should be 1 for fully connected kernel
dilationRateX should be 1 for fully connected kernel
dilationRateY should be 1 for fully connected kernel
Number of groups should be 1 fully connected kernel
Kernel width and src width must match for fully connected kernel
Kernel height and src height must match for fully connected kernel
clipRect width must be 1 for fully connected kernel
clipRect height must be 1 for fully connected kernel
[%@ initWithSource:convolutionDescriptor:kernelWeights:biasTerms]: kernel weights may not be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/MPSCNNConvolutionGraphNodes.mm
MPSGraph internal error: cant append filter after filter creation.
MPSGraph internal error: convolution filter node missing data source?
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: gradient state may not be nil
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState doesn't have a parent convolution with a dataSource.
There are no weights to use here and MPS can not continue.
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] Error: dataSource is nil, and gradientState creator isn't a convolution or convolution transpose node.
There are no weights to use here and MPS can not continue.
[%@ initWithGradientImages:forwardFilter:] Errr: filter is not a MPSCNNConvolutionNode
MPSNNTrainingStyleUpdateDeviceNone
MPSNNTrainingStyleUpdateDeviceCPU
MPSNNTrainingStyleUpdateDeviceGPU
MPSNNTrainingStyleUpdateDeviceAll
training style: %@
CNNConvolutionGradientFilterNode::InitFilter() Error: unexpectedly could not get a data source from the inference convolution node.
Can not continue...
Err: Unable to trigger -load on MPSCNNConvolutionDataSource: <%p>
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights must have a descriptor
[%@ initWithSourceGradient:sourceImage:convolutionGradientState:weights:] weights.descriptor can not contain an integrated neuron.
A separate node must be built for neurons for training.
The graph will automatically integrate them later for inference.
Error while unpacking a convolution gradient node: a valid dataSource could not be found in either the gradient node or its partner convolution to initialize the convolution weights
Error: could not updates weights for convolution without a MPSCNNConvolutionDataSource to talk to.
Perhaps your data source doesn't conform to <NSSecureCoding> and couldn't be saved?
Perhaps you created the convolution gradient node with a nil data source and there is no matching convolution node that has a datasource?
Error: can not update data source "%@" on GPU, because it does not implement updateWeightasAndBiasesWithCommandBuffer:sourceState:gradientState:.
convolution gradient weight update pass: the gradients may not be in a temporary image for CPU update.
Find the state result from the forward convolution and set it to be .exportFromGraph = YES
Error: can not update data source "%@" on GPU, because it does not implement -updateWeightasAndBiasesWithCommandBuffer:sourceState:gradient:.
convolution gradient weight update pass: the weight gradients may not be in a temporary state for CPU update.
convolution gradient weight update pass: the weights may not be in a temporary state for CPU update.
%@.convolutionGradientState is an invalid operation.  The class doesn't support producing state.
%@.convolutionState is an invalid operation.  The class doesn't support producing state.
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionGradientState
CNNConvolutionTransposeFilterNode::Encode(): state passed to convolution transpose must be a MPSCNNConvolutionTransposeGradientState
CNNConvolutionTransposeFilterNode::Encode(): MPSCNNConvolutionTransposeGradientState passed in mismatches with source MPSCNNConvolutionGradientState.
fused: %s,  a = %g b = %g c = %g
imageInitialSumBase
imageThreadgroupSumBase
Error: [%@ load] returned NO.  MPS can wait no longer for data and can not proceed.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Graph/DataSourceWrappers.mm
Error: [%@ descriptor] returned nil.  MPS can wait no longer for data and can not proceed.
Error: [MPSCNNConvolutionDescriptor copyWithZone:] failed
Error: convolution data source over purged: 
aggregation container for %@ "%@"
aggregation container for %@ "%@"
convolution descriptor: %@batch norm data source: %@neuron descriptor:      %@
aggregation container for %@ "%@"
convolution descriptor: %@neuron descriptor:      %@
supportsSecureCoding
initWithCoder:
encodeWithCoder:
MPSConvolutionDataSourceWrapper.dataSource
MPSConvolutionDataSourceWrapper.c
MPSConvolutionDataSourceWrapper.batchNorm
MPSConvolutionDataSourceWrapper.b
MPSConvolutionDataSourceWrapper.neuron
MPSConvolutionDataSourceWrapper.n
Error: Can not encode convolution data source. It doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch norm descriptor doesn not conform to NSSSecureCoding.
Error: Can not encode convolution. The fused batch neuron doesn not conform to NSSSecureCoding.
lossXYDescriptor: 
lossWHDescriptor: 
lossConfidenceDescriptor: 
lossClassesDescriptor: 
reductionType = %d
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
%lu) (w, h) = (%f, %f)
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNYOLOLoss.mm
_reductionType == lossDescriptor.XYLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.WHLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.confidenceLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
_reductionType == lossDescriptor.classesLossDescriptor.reductionType, all losses in YOLOLoss must have the same reductionType
lossXY: 
lossWH: 
lossConfidence: 
lossClasses: 
reductionType = %d, across batches = %s
scaleXY = %f
scaleWH = %f
scaleNoObject = %f
scaleObject = %f
scaleClass = %f
minIOUForObjectPresence = %f
maxIOUForObjectAbsence = %f
numberOfAnchorBoxes = %lu
anchorBoxes:
MPSCNNYOLOLossReductionType
MPSCNNYOLOLossReduceAcrossBatch
MPSCNNYOLOLossNumberOfAnchorBoxes
kMPSCNNYOLOLoss_scaleXY_Key
kMPSCNNYOLOLoss_scaleWH_Key
kMPSCNNYOLOLoss_scaleNoObject_Key
kMPSCNNYOLOLoss_scaleObject_Key
kMPSCNNYOLOLoss_scaleClass_Key
kMPSCNNYOLOLoss_minIOUForObjectPresence_Key
kMPSCNNYOLOLoss_maxIOUForObjectAbsence_Key
kMPSCNNYOLOLoss_rescore_Key
%@.className
MPSCNNYOLOLossLossXY
MPSCNNYOLOLossLossWH
MPSCNNYOLOLossLossConfidence
MPSCNNYOLOLossLossClasses
MPSCNNYOLOLossAnchorBoxes
((info->src.image.featureChannels) / numAnchorBoxes) > 5, failed, input image does not have enough feature channels for the anchor boxes
((info->src.image.featureChannels) %% numAnchorBoxes) == 0, failed, input image feature channels must be a multiple of number of anchor boxes
YOLOLossBatch
YOLOFinalizeBatch
YoloLossFinalizeAcrossBatch
MPSNNNeuronDescriptor for fusing with convoution cannot be nil
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolution.mm
Use -setNeuronType:parameterA:parameterB instead
Number of groups should be 1 for depthwise convolution.
Number of input channels must be divisible by groups parameter
Number of output channels must be divisible by groups parameter
Number of input channels in each group must be multiple of 4
Number of output channels in each group must be multiple of 4
kernel width: %lu
kernel height: %lu
Input feature channels: %lu
Output feature channels: %lu
X stride (pixels): %lu
Y stride (pixels): %lu
Groups:    %lu
subPixelScaleFactor:    %lu
dilationRateX:    %lu
dilationRateY:    %lu
Batch norm data: %p
neuron:
Error: can not add neuron to descriptor that already has one.
neuron already set on the convolution descriptor next layer cannot be fused
outputFeatureChannels (%lu) in convolution descriptor must be multiple of scaleFactor*scaleFactor=%lu becuase these values are rearragned in scaleFactor x scaleFactor pixel block by sub pixel convolution with each pixel having outputFeatureChannels/(scaleFactor*scaleFactor) channels
When number of groups (%lu) is greater than 1, number of feature channel in upsampled output image (outputFeatureChannels/(scaleFactor*scaleFactor)) (%lu) must be multiple of 4
outputFeatureChannels (%lu) in convolution descriptor must be multiple of _inputFeatureChannels (%lu)
channelMultiplier:    %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least one source image are expected for a MPSCNNConvolutionTranspose.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
convolution: %@ %p "%@"
vDSP_vsmul
vDSP_vma
8-bit weights are only allowed for interleaved per array slice layout
for depth wise convolution, number of output feature channels (%lu) must be multiple of input feature channels (%lu)
for depth wise convolution, currently only channel multiplier of 1 is supported.
for depth wise convolution, groups should be 1.
depth wise convolution currently only supported for FP weights.
parameterA of depreated neuron property doesnt match the value set for neuronParameterA of convolution descriptor.
parameterB of depreated neuron property doesnt match the value set for neuronParameterB of convolution descriptor.
Neuron type of depreated neuron property doesnt match the value set for neuronType of convolution descriptor.
[%@ initWithDevice:convolutionDescriptor:weights:] weights may not be nil
[%@ initWithDevice:convolutionDescriptor:weights:] weights.load should return YES
Only MPSDataTypeFloat32, MPSDataTypeFloat16 and MPSDataTypeUInt8 are supported by convolution.
Data source does not implement rangesForUInt8Kernel method
rangesForUInt8Kernel method returned nil
Data source does not implement lookupTableForUInt8Kernel method
lookupTableForUInt8Kernel method returned nil
Only linear or loopup table based dequantization available for UInt8 datatype
Weights data provider data type is UInt8 but no method implemented to dequantize the weights or methods returned nil LUT/ranges
[%@ initWithDevice:convolutionDescriptor:weights:] unsupported weights.dataType: 0x%16.16llx
Failed to load data source
data source does not repond to selector lookupTableForUInt8Kernel
data source does not repond to selector rangesForUInt8Kernel
Convolution object was not created with data source. Use initWithDevice:weights
data source load failed
MPSNNConvolutionAccumulatorPrecisionOptionHalf
MPSNNConvolutionAccumulatorPrecisionOptionFloat
inputFeatureChannels: %lu
outputFeatureChannels:   %lu
Feature channel layout:  %lu
Groups:                  %lu
scaleFactor:             %lu
Accumulator precision:   %s
srcWidth %lu srcHeight %lu inputChannels %lu destWidth %lu destHeight %lu outputChannels %lu kernelWidth %lu kernelHeight %lu strideX %lu strideY %lu group %lu dilationX %lu dilationY %lu channelMultiplier %lu batchSize %lu
Feature channel layout of source and MPSCNNConvolution filter doesn't match
Feature channel layout of destination and MPSCNNConvolution filter doesn't match
Accumulator precision must be set to MPSNNConvolutionAccumulatorPrecisionOptionFloat when using Float32 kernel weights
[%@ initWithDevice:convolutionDescriptor:weights:] dataSource.load should return YES
weights layout mismatch. Layout of convolution objct is %s while state object layout is %s
biases buffer should have %lu bytes of data
MPSCNNConvolutionWeightsAndBiases state expect weights data type to be either float32 or float16
weightsOffsets must be aligned to size of element in weights buffers
biasesOffsets must be aligned to size of element in biases buffers
Not enough elements in weights buffer
Not enough elements in biases buffer
MPSCNNConvolutionDescriptorVers
MPSCNNConvolutionDescriptorWidth
MPSCNNConvolutionDescriptorHeight
MPSCNNConvolutionDescriptorInputFeatureChannels
MPSCNNConvolutionDescriptorOutputFeatureChannels
MPSCNNConvolutionDescriptorStrideInPixelsX
MPSCNNConvolutionDescriptorStrideInPixelsY
MPSCNNConvolutionDescriptorGroups
MPSCNNConvolutionDescriptorFeatureChannelsLayout
MPSCNNConvolutionDescriptorSubPixelScaleFactor
MPSCNNConvolutionDescriptorDilationRateX
MPSCNNConvolutionDescriptorDilationRateY
MPSCNNConvolutionDescriptorNeuronType
MPSCNNConvolutionDescriptorNeuronA
MPSCNNConvolutionDescriptorNeuronB
MPSCNNConvolutionDescriptorNeuronC
MPSCNNConvolutionDescriptorIsDepthWiseConvolution
MPSCNNConvolutionDescriptorBatchNormalization.isNull
MPSCNNConvolutionDescriptorBatchNormalization.data
MPSCNNConvolutionDescriptorNeuronParameterA.isNull
MPSCNNConvolutionDescriptorNeuronParameterA.data
MPSCNNConvolutionWeight.dataLayout
MPSCNNConvolutionWeight.dataType
MPSCNNConvolutionBias.isNull
MPSCNNConvolutionWeight.data
MPSCNNConvolutionBias.data
MPSCNNConvolutionQuantizationData.data
cnnFullyConnectedH
cnnFullyConnectedArrayH
MPSCNNConvolutionFeatureChannelsLayout
MPSCNNConvolutionIsFullyConnected
MPSCNNConvolutionIsConvolutionTranspose
MPSCNNConvolutionConvertFloat32Weights
MPSCNNConvolutionFlags
MPSCNNConvolutionNeuronBufferA.isNull
MPSCNNConvolutionNeuronBufferA.data
MPSCNNConvolutionBatchNormalizationData.isNull
MPSCNNConvolutionBatchNormalizationData.data
MPSCNNConvolutionDataSourceClass
MPSCNNConvolutionDataSource
MPSCNNConvolutionInputFeatureChannels
MPSCNNConvolutionOutputFeatureChannels
MPSCNNConvolutionGroups
MPSCNNConvolutionNeuronInfo.type
MPSCNNConvolutionNeuronInfo.a
MPSCNNConvolutionNeuronInfo.b
MPSCNNConvolutionNeuronInfo.c
MPSCNNConvolutionScaleFactor
MPSCNNConvolutionQuantizationType
MPSCNNConvolutionChannelMultipler
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNNormalization.mm
alpha:          %f
beta:           %f
delta:          %f
MPSCNNNormalization_tex2d_tex2d_CHNorm
MPSCNNNormalization_tex2darray_tex2darray_CHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_false
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw1_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw2_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw3_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw4_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw5_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw6_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw7_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw8_true
MPSCNNNormalization_tex2d_tex2d_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2darray_tex2darray_TGMCHNorm_fw9_true
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw2
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw3
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw4
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw5
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw6
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw7
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw8
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_fw9
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt1
MPSCNNNormalization_tex2d_tex2d_AFCL_CHNorm_ppt2
MPSCNNNormalization_ArrayFC_GenCHNorm
MPSCNNNormalization_horizontal_tex2d_tex2d_XYNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_vertical_tex2d_tex2d_XYNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_XYNorm
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_XYNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_XYNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_XYNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_XYNormMxN
MPSCNNNormalization_horizontal_tex2d_tex2d_LCNNorm
MPSCNNNormalization_horizontal_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_vertical_tex2d_tex2d_LCNNorm
MPSCNNNormalization_vertical_tex2darray_tex2darray_LCNNorm
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x1
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x1
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm1x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm1x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x2
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x2
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm2x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm2x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x3
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x3
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x3
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x3
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm3x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm3x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x4
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x4
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm4x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm4x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x5
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x5
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x5
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x5
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm5x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm5x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x6
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x6
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm6x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm6x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x7
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x7
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x7
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x7
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm7x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm7x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x8
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x8
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm8x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm8x0
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm1x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm1x9
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNorm0x9
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNorm0x9
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x1
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x1
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNorm9x0
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNorm9x0
MPSCNNNormalization_XFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_XFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNNormalization_YFast_tex2d_tex2d_LCNNormMxN
MPSCNNNormalization_YFast_tex2darray_tex2darray_LCNNormMxN
MPSCNNCrossChannelNormalization.kernelSize
MPSCNNCrossChannelNormalization.alpha
MPSCNNCrossChannelNormalization.beta
MPSCNNCrossChannelNormalization.delta
MPSCNNSpatialNormalization.alpha
MPSCNNSpatialNormalization.beta
MPSCNNSpatialNormalization.delta
MPSCNNLocalContrastNormalization.alpha
MPSCNNLocalContrastNormalization.beta
MPSCNNLocalContrastNormalization.delta
MPSCNNLocalContrastNormalization.p0
MPSCNNLocalContrastNormalization.pm
MPSCNNLocalContrastNormalization.ps
v32@?0@"MPSMatrix"8Q16^B24
commandBuffer may not be nil.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixSum.mm
Requires at least two matrices to compute a sum.
Only matrix value types of MPSDataTypeFloat16 and MPSDataTypeFloat32 are supported.
Offset vector must be of type MPSDataTypeUInt32.
MatrixSum_float
MatrixSum_half
MPSMatrixSum.rows
MPSMatrixSum.columns
MPSMatrixSum.count
MPSMatrixSum.transpose
MPSMatrixSum.neuronType
MPSMatrixSum.neuronA
MPSMatrixSum.neuronB
MPSMatrixSum.neuronC
MPSMatrixSum.resultOrigin.x
MPSMatrixSum.resultOrigin.y
MPSMatrixSum.resultOrigin.z
MatrixSumRemainder_float
MatrixSumRemainder_half
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNConvolutionTransposeGradient.mm
Subpixel convolution transpose does not currently supported gradient back propagation
Depthwise descriptor is not valid for convolution transpose
MPSCNNConvolutionTransposeGradientInputFeatureChannels
MPSCNNConvolutionTransposeGradientOutputFeatureChannels
MPSCNNConvolutionTransposeGradientGroups
MPSCNNConvolutionTransposeGradientOption
MPSCNNConvolutionTransposeGradientConvolutionGradientClass
MPSCNNConvolutionTransposeGradientConvolutionGradient
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNSoftMax.mm
softmaxNleq4_RGBA
softmaxNgt4leq8_RGBA
softmaxNgt8leq12_RGBA
softmaxNdiv4_RGBA
softmaxN_RGBA
softmaxN_threadgroup
softmaxNleq4_array_RGBA
softmaxNgt4leq8_array_RGBA
softmaxNgt8leq12_array_RGBA
softmaxNdiv4_array_RGBA
softmaxN_array_RGBA
softmaxN_array_interleaved_pixel_threadgroup
softmaxN_array_interleaved_slice_threadgroup
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSMatrixBatchNormalization.mm
sourceNumberOfFeatureVectors:  
sourceInputFeatureChannels:  
neuronType:  
neuronParamA:  
neuronParamB:  
neuronParamC:  
MatrixBatchNormalization
MPSMatrixBatchNormalization._sourceNumberOfFeatureVectors;
MPSMatrixBatchNormalization._sourceInputFeatureChannels;
MPSMatrixBatchNormalization._neuronType;
MPSMatrixBatchNormalization._neuronA;
MPSMatrixBatchNormalization._neuronB;
MPSMatrixBatchNormalization._neuronC;
MPSMatrixBatchNormalization._epsilon;
MPSMatrixBatchNormalization._computeStatistics;
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNGradientKernel.
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MetalPerformanceShaders/MPSNNGradientState.mm
offset: {%ld, %ld, %ld}
clipRect:                          {origin:{%lu, %lu, %lu}, size:{%lu, %lu, %lu}}
dest size:                         {w:%lu, h:%lu, images:%lu}
destination feature channel offset: %lu
source feature channel offset:      %lu
kernel size:                        %lu x %lu
pixel stride:                       %lu x %lu
dilation rate:                      %lu x %lu
padding:                            
max batch size:                     %lu
is backwards:                       %@
edge mode:                          %lu
source size:                       {%lu, %lu, %lu} fc: %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
Error: at least two source Images are expected for a MPSCNNBinaryGradientKernel.
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: primary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
[%@ destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:]
 Error: secondary kernelSize mismatch, filter kernelSize is %lu x %lu state has kernelSize %lu x %lu
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Filters/MPSCNNBinaryConvolution.mm
number of groups must be 1
[%@ initWithCoder:device:] failed. %@
Problem decoding buffers
Problem creating pooling filter for internal use.
kernelWidth: %lu
kernelHeight: %lu
stride X: %lu
stride Y: %lu
inputFeatureChannels: %lu
outputFeatureChannels: %lu
NeuronType: %d
outputBias: %d
outputScale: %d
inputBias: %d
inputScale: %d
PoolingFilter: %@
convType: %lu
flags: %lu
kMPSCNNBinaryConvolution._fullyConnected
kMPSCNNBinaryConvolution._kernelWidth
kMPSCNNBinaryConvolution._kernelHeight
kMPSCNNBinaryConvolution._inputFeatureChannels
kMPSCNNBinaryConvolution._outputFeatureChannels
kMPSCNNBinaryConvolution._strideInPixelsX
kMPSCNNBinaryConvolution._strideInPixelsY
kMPSCNNBinaryConvolution._flags
kMPSCNNBinaryConvolution._convType
kMPSCNNBinaryConvolution._outputScaleValue
kMPSCNNBinaryConvolution._weights
kMPSCNNBinaryConvolution._inputbias
kMPSCNNBinaryConvolution._inputScale
kMPSCNNBinaryConvolution._outputbias
kMPSCNNBinaryConvolution._outputScale
kMPSCNNBinaryConvolution._neuronType
kMPSCNNBinaryConvolution._neuronParamA
kMPSCNNBinaryConvolution._neuronParamB
kMPSCNNBinaryConvolution._neuronParamC
[%@ encode...] not enough destination feature channels:  destinationFeatureChannelOffset + outputFeatureChannels > dest.featureChannels
MPSCNNBinarize_2d_2d_float
MPSCNNBinarize_2d_2dArray_float
MPSCNNBinarize_2dArray_2d_float
MPSCNNBinarize_2dArray_2dArray_float
MPSCNNBetaBinarize_2d_2d_float
MPSCNNBetaBinarize_2d_2dArray_float
MPSCNNBetaBinarize_2dArray_2d_float
MPSCNNBetaBinarize_2dArray_2dArray_float
MPSCNNBinarizePixelFC_2d_2d_float
MPSCNNBinarizePixelFC_2d_2dArray_float
MPSCNNBinarizePixelFC_2dArray_2d_float
MPSCNNBinarizePixelFC_2dArray_2dArray_float
MPSCNNBetaBinarizePixelFC_2d_2d_float
MPSCNNBetaBinarizePixelFC_2d_2dArray_float
MPSCNNBetaBinarizePixelFC_2dArray_2d_float
MPSCNNBetaBinarizePixelFC_2dArray_2dArray_float
MPSCNNBinaryConvolve_2d_2d_float
MPSCNNBinaryConvolve_2d_2dArray_float
MPSCNNBinaryConvolve_2dArray_2d_float
MPSCNNBinaryConvolve_2dArray_2dArray_float
MPSCNNBetaBinaryConvolve_2d_2d_float
MPSCNNBetaBinaryConvolve_2d_2dArray_float
MPSCNNBetaBinaryConvolve_2dArray_2d_float
MPSCNNBetaBinaryConvolve_2dArray_2dArray_float
MPSCNNBinaryConvolvePixelFC_2d_2d_float
MPSCNNBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2d_2dArray_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2d_float
MPSCNNBetaBinaryConvolvePixelFC_2dArray_2dArray_float
MPSCNNImageScale_2d_2d_float
MPSCNNImageScale_2d_2dArray_float
MPSCNNImageScale_2dArray_2d_float
MPSCNNImageScale_2dArray_2dArray_float
MPSCNNImageScalePixelFC_2d_2d_float
MPSCNNImageScalePixelFC_2d_2dArray_float
MPSCNNImageScalePixelFC_2dArray_2d_float
MPSCNNImageScalePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightConvolve_2d_2d_float
MPSCNNBinaryWeightConvolve_2d_2dArray_float
MPSCNNBinaryWeightConvolve_2dArray_2d_float
MPSCNNBinaryWeightConvolve_2dArray_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2d_2dArray_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2d_float
MPSCNNBinaryWeightConvolvePixelFC_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnected_2d_2d_float
MPSCNNBinaryWeightFullyConnected_2d_2dArray_float
MPSCNNBinaryWeightFullyConnected_2dArray_2d_float
MPSCNNBinaryWeightFullyConnected_2dArray_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2d_2dArray_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2d_float
MPSCNNBinaryWeightFullyConnectedPixelFC_2dArray_2dArray_float
Internal error: undefined device in MPSCNNBinConvFunctionConstructor
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders_Sim/MPSNeuralNetwork/Plugin/MPSCNNKernelPlugin.mm
[%@ encodeToCommandBuffer:computeCommandEncoder:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:]  Error: The device driver has failed to override this method
[%@ encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:]  Error: The device driver has failed to override this method
MPSMatrixFullyConnectedGradient
MPSNNReshape
MPSNNReshapeGradient
MPSNNPadGradientState
MPSNNPad
MPSNNPadGradient
MPSCNNPoolingGradient
MPSCNNPoolingMaxGradient
MPSCNNPoolingAverageGradient
MPSCNNPoolingL2NormGradient
MPSCNNDilatedPoolingMaxGradient
MPSCNNArithmeticGradientState
MPSCNNArithmetic
MPSCNNAdd
MPSCNNSubtract
MPSCNNMultiply
MPSCNNDivide
MPSNNCompare
MPSCNNArithmeticGradient
MPSCNNAddGradient
MPSCNNSubtractGradient
MPSCNNMultiplyGradient
MPSRNNRecurrentImageState
MPSRNNRecurrentMatrixState
MPSRNNMatrixTrainingState
MPSRNNDescriptor
MPSRNNSingleGateDescriptor
MPSLSTMDescriptor
MPSGRUDescriptor
TmpWeights
MPSCNNConvolutionDataSource
NSCopying
NSObject
TmpWeightsLUT
TmpWeightsLIN
MPSCNNConvolutionDescriptorNoNeuron
MPSRNNImageInferenceLayer
MPSRNNMatrixInferenceLayer
MPSRNNMatrixTrainingLayer
MPSNNScaleNode
MPSNNBilinearScaleNode
MPSNNLanczosScaleNode
MPSNNScale
MPSNNConcatenation
MPSNNConcatenationGradientState
MPSCNNConvolutionGradient
MPSNNUnaryReductionNode
MPSNNReductionRowMinNode
MPSNNReductionColumnMinNode
MPSNNReductionFeatureChannelsMinNode
MPSNNReductionFeatureChannelsArgumentMinNode
MPSNNReductionRowMaxNode
MPSNNReductionColumnMaxNode
MPSNNReductionFeatureChannelsMaxNode
MPSNNReductionFeatureChannelsArgumentMaxNode
MPSNNReductionRowMeanNode
MPSNNReductionColumnMeanNode
MPSNNReductionFeatureChannelsMeanNode
MPSNNReductionSpatialMeanNode
MPSNNReductionSpatialMeanGradientNode
MPSNNReductionRowSumNode
MPSNNReductionColumnSumNode
MPSNNReductionFeatureChannelsSumNode
MPSMatrixBatchNormalizationGradient
MPSCNNDropoutGradientState
MPSCNNDropoutRandomState
NSSecureCoding
NSCoding
MPSCNNDropout
MPSCNNDropoutGradient
MPSCNNUpsampling
MPSCNNUpsamplingNearest
MPSCNNUpsamplingBilinear
MPSCNNGradientKernel
MPSCNNNeuronNode
MPSCNNNeuronAbsoluteNode
MPSCNNNeuronELUNode
MPSCNNNeuronReLUNNode
MPSCNNNeuronLinearNode
MPSCNNNeuronReLUNode
MPSCNNNeuronSigmoidNode
MPSCNNNeuronHardSigmoidNode
MPSCNNNeuronSoftPlusNode
MPSCNNNeuronSoftSignNode
MPSCNNNeuronTanHNode
MPSCNNNeuronPReLUNode
MPSCNNNeuronPowerNode
MPSCNNNeuronExponentialNode
MPSCNNNeuronLogarithmNode
MPSCNNNeuronGeLUNode
MPSCNNNeuronGradientNode
MPSNNReshapeNode
MPSNNReshapeGradientNode
MPSNNPadNode
MPSNNPadGradientNode
MPSNNGridSample
MPSMatrixFullyConnected
MPSMatrixNeuron
MPSCNNBatchNormalizationDataSource
MPSCNNBatchNormalization
MPSCNNConvolutionTransposeGradientState
MPSCNNConvolutionTranspose
MPSNNBinaryArithmeticNode
MPSNNAdditionNode
MPSNNSubtractionNode
MPSNNMultiplicationNode
MPSNNDivisionNode
MPSNNComparisonNode
MPSNNArithmeticGradientStateNode
MPSNNArithmeticGradientNode
MPSNNAdditionGradientNode
MPSNNSubtractionGradientNode
MPSNNMultiplicationGradientNode
MPSCNNInstanceNormalizationGradient
MPSCNNBatchNormalizationStatisticsGradient
MPSCNNUpsamplingNearestNode
MPSCNNUpsamplingBilinearNode
MPSCNNUpsamplingNearestGradientNode
MPSCNNUpsamplingBilinearGradientNode
MPSNNOptimizerDescriptor
MPSNNOptimizer
MPSNNOptimizerStochasticGradientDescent
MPSNNOptimizerRMSProp
MPSNNOptimizerAdam
MPSImageAllocator
MPSNNGraph
MPSNNTrainableNode
FilterNodeWrapper
MPSHandle
ResourceWrapper
NodeWrapper
MPSCNNCrossChannelNormalizationGradient
MPSCNNSpatialNormalizationGradient
MPSCNNLocalContrastNormalizationGradient
MPSNNLabelsNode
MPSCNNLossNode
MPSCNNYOLOLossNode
MPSNNForwardLossNode
MPSNNLossGradientNode
MPSNNInitialGradientNode
MPSCNNLossDataDescriptor
MPSCNNLossDescriptor
MPSCNNLossLabels
MPSCNNLoss
MPSNNLossGradientState
MPSNNForwardLoss
MPSNNLossGradient
MPSNNInitialGradient
MPSCNNUpsamplingGradient
MPSCNNUpsamplingNearestGradient
MPSCNNUpsamplingBilinearGradient
MPSCNNGroupNormalizationDataSource
MPSCNNGroupNormalization
MPSCNNGroupNormalizationGradientState
MPSNNPermuteGradientState
MPSNNPermute
MPSNNPermuteGradient
MPSNNImageNode
MPSNNStateNode
MPSNNFilterNode
MPSNNGradientFilterNode
MPSNNGradientStateNode
MPSNNBinaryGradientStateNode
MPSNNMultiaryGradientStateNode
MPSNNSlice
MPSNNConcatenationGradient
MPSCNNInstanceNormalizationDataSource
MPSCNNInstanceNormalization
MPSCNNNormalizationGammaAndBetaState
MPSCNNInstanceNormalizationGradientState
MPSNNCropAndResizeBilinear
MPSCNNPooling
MPSCNNPoolingMax
MPSCNNPoolingAverage
MPSCNNPoolingL2Norm
MPSCNNDilatedPoolingMax
MPSCNNBatchNormalizationGradient
MPSNNPadding
MPSImageSizeEncodingState
MPSCNNBinaryKernel
MPSCNNBinaryImageFilter
MPSCNNBatchNormalizationState
MPSCNNNormalizationMeanAndVarianceState
MPSNNResizeBilinear
MPSCNNDropoutNode
MPSCNNDropoutGradientNode
MPSCNNSoftMaxNode
MPSCNNLogSoftMaxNode
MPSCNNSoftMaxGradientNode
MPSCNNLogSoftMaxGradientNode
MPSCNNGroupNormalizationGradient
MPSNNNeuronDescriptor
MPSCNNNeuron
MPSCNNNeuronGradient
MPSCNNNeuronLinear
MPSCNNNeuronReLU
MPSCNNNeuronPReLU
MPSCNNNeuronSigmoid
MPSCNNNeuronHardSigmoid
MPSCNNNeuronTanH
MPSCNNNeuronAbsolute
MPSCNNNeuronSoftPlus
MPSCNNNeuronSoftSign
MPSCNNNeuronELU
MPSCNNNeuronReLUN
MPSCNNNeuronPower
MPSCNNNeuronExponential
MPSCNNNeuronLogarithm
MPSNNPermuteNode
MPSNNPermuteGradientNode
MPSNNGramGradientState
MPSNNGramMatrixCalculation
MPSNNGramMatrixCalculationGradient
MPSNNReduceUnary
MPSNNReduceRowMin
MPSNNReduceColumnMin
MPSNNReduceFeatureChannelsMin
MPSNNReduceFeatureChannelsArgumentMin
MPSNNReduceRowMax
MPSNNReduceColumnMax
MPSNNReduceFeatureChannelsMax
MPSNNReduceFeatureChannelsArgumentMax
MPSNNReduceRowMean
MPSNNReduceColumnMean
MPSNNReduceFeatureChannelsMean
MPSNNReduceRowSum
MPSNNReduceColumnSum
MPSNNReduceFeatureChannelsSum
MPSNNReduceBinary
MPSNNReduceFeatureChannelsAndWeightsMean
MPSNNReduceFeatureChannelsAndWeightsSum
MPSNNLocalCorrelation
MPSWeightsWrapper
MPSWeightsWrapper_SecureCoding
MPSCNNKernel
MPSNNDefaultPadding
MPSNNTensorFlowPoolingPadding
MPSNNTensorFlowPoolingPaddingValidOnly
ExplicitZeroPadding
MPSCNNPoolingNode
MPSCNNPoolingMaxNode
MPSCNNPoolingAverageNode
MPSCNNPoolingL2NormNode
MPSCNNDilatedPoolingMaxNode
MPSCNNPoolingGradientNode
MPSCNNPoolingMaxGradientNode
MPSCNNPoolingAverageGradientNode
MPSCNNPoolingL2NormGradientNode
MPSCNNDilatedPoolingMaxGradientNode
MPSMatrixNeuronGradient
MPSCNNMultiaryKernel
MPSCNNSoftMaxGradient
MPSCNNLogSoftMaxGradient
MPSNNConcatenationNode
MPSNNConcatenationGradientNode
MPSCNNNormalizationNode
MPSCNNSpatialNormalizationNode
MPSCNNSpatialNormalizationGradientNode
MPSCNNLocalContrastNormalizationNode
MPSCNNLocalContrastNormalizationGradientNode
MPSCNNCrossChannelNormalizationNode
MPSCNNCrossChannelNormalizationGradientNode
MPSCNNInstanceNormalizationNode
MPSCNNInstanceNormalizationGradientNode
MPSCNNGroupNormalizationNode
MPSCNNGroupNormalizationGradientNode
MPSCNNBatchNormalizationNode
MPSCNNBatchNormalizationGradientNode
MPSCNNFullyConnected
MPSCNNFullyConnectedGradient
MPSCNNConvolutionGradientStateNode
MPSCNNConvolutionTransposeGradientStateNode
MPSCNNConvolutionStateNode
MPSCNNConvolutionNode
MPSCNNConvolutionGradientNode
MPSCNNConvolutionTransposeGradientNode
MPSCNNFullyConnectedNode
MPSCNNFullyConnectedGradientNode
MPSCNNBinaryConvolutionNode
MPSCNNBinaryFullyConnectedNode
MPSCNNConvolutionTransposeNode
MPSNNGramMatrixCalculationNode
MPSNNGramMatrixCalculationGradientNode
MPSCNNBatchNormalizationStatistics
MPSConvolutionDataSourceWrapper
MPSConvolutionDataSourceWrapper_SecureCoding
MPSCNNYOLOLossDescriptor
MPSCNNYOLOLoss
MPSCNNConvolutionDescriptor
MPSCNNSubPixelConvolutionDescriptor
MPSCNNDepthWiseConvolutionDescriptor
MPSCNNConvolutionState
MPSCNNConvolutionGradientState
MPSPluginCNNConvolutionDescriptor
MPSCNNConvolution
MPSCNNConvolutionWeightsAndBiasesState
MPSCNNCrossChannelNormalization
MPSCNNSpatialNormalization
MPSCNNLocalContrastNormalization
MPSMatrixSum
MPSCNNConvolutionTransposeGradient
MPSCNNSoftMax
MPSCNNLogSoftMax
MPSMatrixBatchNormalization
MPSNNGradientState
MPSNNBinaryGradientState
MPSNNMultiaryGradientState
MPSCNNBinaryConvolution
MPSCNNBinaryFullyConnected
MPSExternalCNNUnary
MPSExternalPluginBase
MPSExternalCNNBinary
MPSExternalCNNPoolingAverage
writeBytes:dataLayout:bytesPerRow:bytesPerImage:region:featureChannelInfo:imageIndex:
addObject:
allKeys
allValues
allocWithZone:
alphaForSourceImage:destinationImage:
appendTexture:
archivedDataWithRootObject:requiringSecureCoding:error:
arrayByAddingObject:
arrayByAddingObjectsFromArray:
arrayLength
arrayWithCapacity:
arrayWithObjects:
arrayWithObjects:count:
batchRepresentation
batchSize
batchStart
bufferSizeAtIndex:
bytes
cStringUsingEncoding:
channelFormat
commandBufferWithUnretainedReferences
commandQueue
commit
commitAndContinue
computeCommandEncoder
containsValueForKey:
contents
copy
countByEnumeratingWithState:objects:count:
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
decodeBoolForKey:
decodeBytesForKey:returnedLength:
decodeDoubleForKey:
decodeFloatForKey:
decodeInt32ForKey:
decodeInt64ForKey:
decodeIntForKey:
decodeIntegerForKey:
decodeObjectForKey:
decodeObjectOfClass:forKey:
decodeObjectOfClasses:forKey:
defaultAllocator
descriptorWithSourceMatrix:destinationMatrix:offsets:
dictionaryWithObjects:forKeys:count:
dispatchThreadgroups:threadsPerThreadgroup:
doesNotRecognizeSelector:
encodeBatchToCommandBuffer:encoder:sourceImages:destinationMatrix:
encodeBatchToCommandBuffer:encoder:sourceMatrix:destinationImages:
encodeBool:forKey:
encodeBytes:length:forKey:
encodeDouble:forKey:
encodeFloat:forKey:
encodeInt32:forKey:
encodeInt64:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeToCommandBuffer:computeEncoder:destinationBuffer:destinationOffset:numEntries:
encodeToCommandBuffer:encoder:copyDescriptor:rowPermuteIndices:rowPermuteOffset:columnPermuteIndices:columnPermuteOffset:
encodeToCommandBuffer:encoder:leftMatrix:rightMatrix:resultMatrix:
endEncoding
enumerateObjectsUsingBlock:
error
errorWithDomain:code:userInfo:
exportState
featureChannelFormat
featureChannels
getGPUPriority
getObjects:range:
height
imageDescriptorWithChannelFormat:width:height:featureChannels:
imageDescriptorWithChannelFormat:width:height:featureChannels:numberOfImages:usage:
initWithBuffer:descriptor:
initWithBytes:length:
initWithBytes:length:encoding:
initWithBytesNoCopy:length:deallocator:
initWithBytesNoCopy:length:freeWhenDone:
initWithCapacity:
initWithCommandBuffer:withDispatchType:
initWithDevice:copyRows:copyColumns:sourcesAreTransposed:destinationsAreTransposed:
initWithDevice:dataLayout:
initWithDevice:descriptor:
initWithDevice:destinationDataType:seed:
initWithDevice:destinationDataType:state:distributionDescriptor:
initWithDevice:imageDescriptor:
initWithDevice:textureDescriptor:
initWithDevice:transposeLeft:transposeRight:resultRows:resultColumns:interiorColumns:alpha:beta:
initWithFormat:
initWithObjects:
initWithObjects:count:
initWithTexture:featureChannels:
intValue
isEqualToString:
isSubclassOfClass:
lastObject
length
matrices
matrixBytes
matrixDescriptorWithRows:columns:matrices:rowBytes:matrixBytes:dataType:
matrixDescriptorWithRows:columns:rowBytes:dataType:
maxTextureHeight2D
maxTextureWidth2D
maxThreadsPerThreadgroup
maxTotalThreadsPerThreadgroup
minBufferNoCopyAlignmentBytes
minimumLinearTextureAlignmentForPixelFormat:
newBufferWithBytes:length:options:
newBufferWithBytesNoCopy:length:options:deallocator:
newBufferWithLength:options:
newTextureViewWithPixelFormat:
newTextureViewWithPixelFormat:textureType:levels:slices:
newTextureWithDescriptor:offset:bytesPerRow:
null
numberOfImages
numberWithInt:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
options
pixelFormat
popDebugGroup
prefetchStorageWithCommandBuffer:imageDescriptorList:
primarySourceMatrixOrigin
primaryStrideInPixels
pushDebugGroup:
readBytes:dataLayout:imageIndex:
readCount
removeObjectForKey:
resourceCount
resourceListWithBufferSizes:
resourceListWithTextureDescriptors:
retainedReferences
rowBytes
rowBytesForColumns:dataType:
scalarWeightForSourceImage:destinationImage:
secondarySourceMatrixOrigin
secondaryStrideInPixels
setArray:
setArrayLength:
setBuffer:offset:atIndex:
setBuffers:offsets:withRange:
setBytes:length:atIndex:
setChannelFormat:
setColumns:
setComputePipelineState:
setConstantValue:type:atIndex:
setDistributionType:
setFeatureChannels:
setHeight:
setK:
setLeftMatrixOrigin:
setM:
setN:
setNumberOfImages:
setObject:atIndexedSubscript:
setObject:forKey:
setPixelFormat:
setResourceOptions:
setRightMatrixOrigin:
setRowBytes:
setRows:
setSamplerState:atIndex:
setScaleTransform:
setStorageMode:
setTexture:atIndex:
setTextureType:
setTextures:withRange:
setThreadgroupMemoryLength:atIndex:
setUsage:
setWidth:
setWithArray:
setWithObject:
sourceMatrixOrigin
status
storageMode
stringByAppendingString:
stringWithFormat:
subImageWithFeatureChannelRange:
subarrayWithRange:
synchronizeStateOnCommandBuffer:
temporaryImageWithCommandBuffer:imageDescriptor:
temporaryMatrixWithCommandBuffer:matrixDescriptor:
temporaryStateWithCommandBuffer:resourceList:
temporaryStateWithCommandBuffer:textureDescriptor:
texture
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
textureType
threadExecutionWidth
unarchivedObjectOfClasses:fromData:device:error:
unsignedIntegerValue
usage
userDictionary
vectorBytes
vectorDescriptorWithLength:dataType:
vectors
width
addCompletedHandler:
initWithDevice:
copyWithZone:device:
initWithCoder:device:
encodeWithCoder:
libraryInfo:
encodeGradientForDataToCommandBuffer:gradientMatrix:weightMatrix:resultGradientForDataMatrix:
encodeGradientForWeightsAndBiasToCommandBuffer:gradientMatrix:inputMatrix:resultGradientForWeightMatrix:resultGradientForBiasVector:
sourceNumberOfFeatureVectors
setSourceNumberOfFeatureVectors:
sourceInputFeatureChannels
setSourceInputFeatureChannels:
sourceOutputFeatureChannels
setSourceOutputFeatureChannels:
alpha
setAlpha:
_sourceNumberOfFeatureVectors
_sourceInputFeatureChannels
_sourceOutputFeatureChannels
_alpha
TQ,N,V_sourceNumberOfFeatureVectors
TQ,N,V_sourceOutputFeatureChannels
TQ,N,V_sourceInputFeatureChannels
Td,N,V_alpha
debugDescription
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:
encodeToCommandBuffer:sourceImage:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeBatchToCommandBuffer:sourceImages:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:reshapedWidth:reshapedHeight:reshapedFeatureChannels:
_reshapedWidth
_reshapedHeight
_reshapedFeatureChannels
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:primaryOffset:secondaryOffset:kernelOffset:
initWithResource:
temporaryStateWithCommandBuffer:
dealloc
_fwdPadBefore
_fwdPadAfter
_srcImgFcCount
destinationImageDescriptorForSourceImages:sourceStates:
initWithDevice:paddingSizeBefore:paddingSizeAfter:
initWithDevice:paddingSizeBefore:paddingSizeAfter:fillValueArray:
isResultStateReusedAcrossBatch
resultStateForSourceImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:
paddingSizeBefore
setPaddingSizeBefore:
paddingSizeAfter
setPaddingSizeAfter:
fillValue
setFillValue:
_aBuf
_aBufFP32Len
_fillValue
_paddingSizeBefore
_paddingSizeAfter
T{MPSImageCoordinate=QQQ},N,V_paddingSizeBefore
T{MPSImageCoordinate=QQQ},N,V_paddingSizeAfter
Tf,N,V_fillValue
initWithDevice:kernelWidth:kernelHeight:
initWithDevice:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
setKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
maxBatchSize
sourceSize
setSourceSize:
_sourceSize
T{?=QQQ},N,V_sourceSize
zeroPadSizeX
setZeroPadSizeX:
zeroPadSizeY
setZeroPadSizeY:
_zeroPadSizeX
_zeroPadSizeY
TQ,N,V_zeroPadSizeX
TQ,N,V_zeroPadSizeY
initWithDevice:kernelWidth:kernelHeight:dilationRateX:dilationRateY:strideInPixelsX:strideInPixelsY:
init
_resourcePixelFormat
_resourceSize
_primaryFCStride
_secondaryFCStride
copyToBinaryGradientState:primaryImage:secondaryImage:sourceStates:destinationImage:
setPrimaryStrideInPixelsX:
setPrimaryStrideInPixelsY:
setPrimaryStrideInFeatureChannels:
setSecondaryStrideInPixelsX:
setSecondaryStrideInPixelsY:
setSecondaryStrideInFeatureChannels:
initWithDevice:arithmeticType:
privateResultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:commandBuffer:isTemporary:
resultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationImages:
primaryScale
setPrimaryScale:
secondaryScale
setSecondaryScale:
bias
setBias:
minimumValue
setMinimumValue:
maximumValue
setMaximumValue:
primaryStrideInFeatureChannels
secondaryStrideInFeatureChannels
_primaryScale
_secondaryScale
_bias
_minimumValue
_maximumValue
_primaryStrideInFeatureChannels
_secondaryStrideInFeatureChannels
_arithmeticType
Tf,N,V_primaryScale
Tf,N,V_secondaryScale
Tf,N,V_bias
TQ,N,V_primaryStrideInFeatureChannels
TQ,N,V_secondaryStrideInFeatureChannels
Tf,N,V_minimumValue
Tf,N,V_maximumValue
comparisonType
setComparisonType:
threshold
setThreshold:
_threshold
_comparisonType
TQ,N,V_comparisonType
Tf,N,V_threshold
initWithDevice:arithmeticType:isSecondarySourceFilter:
isSecondarySourceFilter
_isSecondarySourceFilter
_reduceRows
_reduceColumns
_reduceFeatureChannels
TB,R,N,V_isSecondarySourceFilter
initWithDevice:isSecondarySourceFilter:
setReadCount:
getRecurrentOutputImageForLayerIndex:
getMemoryCellImageForLayerIndex:
initWithCommandBuffer:recurrentImageDescriptors:cellImageDescriptors:isTemporary:layerCount:
isTemporary
recurrentImages
cellImages
nLayers
_isTemporary
getRecurrentOutputMatrixForLayerIndex:
getMemoryCellMatrixForLayerIndex:
initWithCommandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
initWithDevice:commandBuffer:recurrentMatrixDescriptors:cellMatrixDescriptors:isTemporary:layerCount:
recurrentMatrices
cellMatrices
initForSingleGateWithCommandBuffer:matrixDescriptor:isTemporary:
singleGateZ
inputFeatureChannels
setInputFeatureChannels:
outputFeatureChannels
setOutputFeatureChannels:
inputTransform
setInputTransform:
outputTransform
setOutputTransform:
recurrentOutputTransform
setRecurrentOutputTransform:
useLayerInputUnitTransformMode
setUseLayerInputUnitTransformMode:
layerSequenceDirection
setLayerSequenceDirection:
useFloat32Weights
setUseFloat32Weights:
internalKernelSelector
setInternalKernelSelector:
_useLayerInputUnitTransformMode
_useFloat32Weights
_inputFeatureChannels
_outputFeatureChannels
_inputTransform
_outputTransform
_recurrentOutputTransform
_layerSequenceDirection
_internalKernelSelector
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputTransform
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentOutputTransform
TQ,N,V_internalKernelSelector
TQ,N,V_inputFeatureChannels
TQ,N,V_outputFeatureChannels
TB,N,V_useLayerInputUnitTransformMode
TB,N,V_useFloat32Weights
TQ,N,V_layerSequenceDirection
createRNNSingleGateDescriptorWithInputFeatureChannels:outputFeatureChannels:
initWithInputFeatureChannels:outputFeatureChannels:
inputWeights
setInputWeights:
recurrentWeights
setRecurrentWeights:
_inputWeights
_recurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentWeights
createLSTMDescriptorWithInputFeatureChannels:outputFeatureChannels:
memoryWeightsAreDiagonal
setMemoryWeightsAreDiagonal:
inputGateInputWeights
setInputGateInputWeights:
inputGateRecurrentWeights
setInputGateRecurrentWeights:
inputGateMemoryWeights
setInputGateMemoryWeights:
forgetGateInputWeights
setForgetGateInputWeights:
forgetGateRecurrentWeights
setForgetGateRecurrentWeights:
forgetGateMemoryWeights
setForgetGateMemoryWeights:
outputGateInputWeights
setOutputGateInputWeights:
outputGateRecurrentWeights
setOutputGateRecurrentWeights:
outputGateMemoryWeights
setOutputGateMemoryWeights:
cellGateInputWeights
setCellGateInputWeights:
cellGateRecurrentWeights
setCellGateRecurrentWeights:
cellGateMemoryWeights
setCellGateMemoryWeights:
cellToOutputNeuronType
setCellToOutputNeuronType:
cellToOutputNeuronParamA
setCellToOutputNeuronParamA:
cellToOutputNeuronParamB
setCellToOutputNeuronParamB:
cellToOutputNeuronParamC
setCellToOutputNeuronParamC:
cellClipThreshold
setCellClipThreshold:
coupleForgetGateToInputGate
setCoupleForgetGateToInputGate:
_memoryWeightsAreDiagonal
_coupleForgetGateToInputGate
_cellToOutputNeuronType
_cellToOutputNeuronParamA
_cellToOutputNeuronParamB
_cellToOutputNeuronParamC
_cellClipThreshold
_inputGateInputWeights
_inputGateRecurrentWeights
_inputGateMemoryWeights
_forgetGateInputWeights
_forgetGateRecurrentWeights
_forgetGateMemoryWeights
_outputGateInputWeights
_outputGateRecurrentWeights
_outputGateMemoryWeights
_cellGateInputWeights
_cellGateRecurrentWeights
_cellGateMemoryWeights
Tf,N,V_cellClipThreshold
TB,N,V_coupleForgetGateToInputGate
TB,N,V_memoryWeightsAreDiagonal
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_inputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_forgetGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateMemoryWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_cellGateMemoryWeights
Ti,N,V_cellToOutputNeuronType
Tf,N,V_cellToOutputNeuronParamA
Tf,N,V_cellToOutputNeuronParamB
Tf,N,V_cellToOutputNeuronParamC
createGRUDescriptorWithInputFeatureChannels:outputFeatureChannels:
recurrentGateInputWeights
setRecurrentGateInputWeights:
recurrentGateRecurrentWeights
setRecurrentGateRecurrentWeights:
outputGateInputGateWeights
setOutputGateInputGateWeights:
gatePnormValue
setGatePnormValue:
flipOutputGates
setFlipOutputGates:
_flipOutputGates
_gatePnormValue
_recurrentGateInputWeights
_recurrentGateRecurrentWeights
_outputGateInputGateWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateInputWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_recurrentGateRecurrentWeights
T@"<MPSCNNConvolutionDataSource>",&,N,V_outputGateInputGateWeights
Tf,N,V_gatePnormValue
TB,N,V_flipOutputGates
copyWithZone:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
TQ,R
T#,R
T@"NSString",R,C
dataType
descriptor
weights
biasTerms
load
purge
label
rangesForUInt8Kernel
lookupTableForUInt8Kernel
weightsQuantizationType
updateWithCommandBuffer:gradientState:sourceState:
updateWithGradientState:sourceState:
weightsLayout
kernelWeightsDataType
initWithWeights:useBias:desc:
_parentObj
_convDesc
_hasBias
initWithConvDescriptor:
initWithDevice:rnnDescriptor:
initWithDevice:rnnDescriptors:
encodeSequenceToCommandBuffer:sourceImages:destinationImages:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardImages:destinationBackwardImages:
numberOfLayers
recurrentOutputIsTemporary
setRecurrentOutputIsTemporary:
storeAllIntermediateStates
setStoreAllIntermediateStates:
bidirectionalCombineMode
setBidirectionalCombineMode:
layerTypes
layers
forwardLayers
forwardLayerTypes
nForwardLayers
backwardLayers
backwardLayerTypes
nBackwardLayers
_recurrentOutputIsTemporary
_storeAllIntermediateStates
_numberOfLayers
_bidirectionalCombineMode
TQ,R,N,V_inputFeatureChannels
TQ,R,N,V_outputFeatureChannels
TQ,R,N,V_numberOfLayers
TB,N,V_recurrentOutputIsTemporary
TB,N,V_storeAllIntermediateStates
TQ,N,V_bidirectionalCombineMode
encodeSequenceToCommandBuffer:sourceMatrices:destinationMatrices:recurrentInputState:recurrentOutputStates:
encodeSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:recurrentInputState:recurrentOutputStates:
encodeBidirectionalSequenceToCommandBuffer:sourceSequence:destinationForwardMatrices:destinationBackwardMatrices:
recurrentStateForBatchSize:
temporaryRecurrentStateForCommandBuffer:batchSize:
propagateFullRecurrentRows
setPropagateFullRecurrentRows:
gemmKernel
gemmKernelNonTranspose
_propagateFullRecurrentRows
TB,N,V_propagateFullRecurrentRows
initWithDevice:rnnDescriptor:trainableWeights:
createWeightGradientMatrices:dataType:
createTemporaryWeightGradientMatrices:dataType:commandBuffer:
createWeightMatrices:
encodeCopyWeightsToCommandBuffer:weights:matrixId:matrix:copyFromWeightsToMatrix:matrixOffset:
encodeForwardSequenceToCommandBuffer:sourceMatrices:sourceOffsets:destinationMatrices:destinationOffsets:trainingStates:recurrentInputState:recurrentOutputStates:weights:
encodeForwardSequenceToCommandBuffer:sourceMatrices:destinationMatrices:trainingStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:forwardSourceOffsets:sourceGradients:sourceGradientOffsets:destinationGradients:destinationOffsets:weightGradients:trainingStates:recurrentInputState:recurrentOutputStates:weights:
encodeGradientSequenceToCommandBuffer:forwardSources:sourceGradients:destinationGradients:weightGradients:trainingStates:weights:
recurrentStateForBatchSize:forGradientPass:
temporaryRecurrentStateForCommandBuffer:batchSize:forGradientPass:
trainingStateIsTemporary
setTrainingStateIsTemporary:
accumulateWeightGradients
setAccumulateWeightGradients:
layerType
layer
gemmKernel_noAccumulate
gemmKernelNonTranspose_noAccumulate
gemmKernelTN
gemmKernelTN_accumulate
weightDescriptors
_trainingStateIsTemporary
_accumulateWeightGradients
TB,N,V_trainingStateIsTemporary
TB,N,V_accumulateWeightGradients
initWithSourceImages:sourceStates:paddingPolicy:
nodeWithSource:transformProvider:outputSize:
nodeWithSource:outputSize:
privateInitWithSource:transformProvider:outputSize:
initWithSource:transformProvider:outputSize:
initWithSource:outputSize:
_transformProvider
_size
newFilterNode
setLabel:
transformForSourceImage:handle:
initWithDevice:transformProvider:handle:outputSize:scaleClass:
setOptions:
setEdgeMode:
_destSize
_filter
_handle
imageBatchForCommandBuffer:imageDescriptor:kernel:count:
copyToGradientState:sourceImage:sourceStates:destinationImage:
encodeToCommandBuffer:sourceImages:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImage:
resultStateForSourceImages:sourceStates:destinationImage:
temporaryResultStateForCommandBuffer:sourceImages:sourceStates:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:
temporaryResultStateBatchForCommandBuffer:sourceImages:sourceStates:destinationImage:
resultStateBatchForSourceImage:sourceStates:destinationImage:
resultStateBatchForSourceImages:sourceStates:destinationImage:
copyToGradientState:sourceImages:sourceStates:destinationImage:
_sliceCount
_info
convolutionTranspose
weightsDataType
preferredWeightsDataType
filterHandlesPlugin
initialize:convDesc:weights:dataType:weightsLayout:fullyConnected:convolutionTranspose:preferredWeightsDataType:
initialize:weights:fullyConnected:convolutionTranspose:
initWithDevice:weights:fullyConnected:
initWithDevice:weights:convolutionTranspose:
initWithDevice:weights:
reloadWeightsAndBiasesFromDataSource
reloadWeightsAndBiasesWithCommandBuffer:state:
biases
PeakAtWeightsWithConvolutionGradientState:
encodingStorageSizeForSourceImage:sourceStates:destinationImage:
batchEncodingStorageSizeForSourceImage:sourceStates:destinationImage:
PeakAtWeightsWithConvolutionTransposeGradientState:
sourceGradientFeatureChannels
sourceImageFeatureChannels
groups
channelMultiplier
gradientOption
setGradientOption:
dataSource
serializeWeightsAndBiases
setSerializeWeightsAndBiases:
_groups
_channelMultiplier
_gradientOption
_weights
_fullyConnected
_convolutionTranspose
_weightsDataType
_preferredWeightsDataType
_weightsLayout
_dataSource
_lock
_serializeWeightsAndBiases
TQ,R,N,V_groups
TQ,R,N,V_channelMultiplier
T@"<MPSCNNConvolutionDataSource>",R,&,N,V_dataSource
TQ,N,V_gradientOption
TB,N,V_serializeWeightsAndBiases
nodeWithSource:
initWithSource:
gradientFilterWithSource:
clipRectSource
setClipRectSource:
_clipRectSource
T{?={?=QQQ}{?=QQQ}},N,V_clipRectSource
gradientClass
initWithGradientImages:sourceImages:gradientState:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:
initWithSourceGradient:sourceImage:gradientState:
weight
setWeight:
_weight
Tf,N,V_weight
encodeToCommandBuffer:gradientMatrix:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultGradientForDataMatrix:resultGradientForGammaVector:resultGradientForBetaVector:
neuronType
neuronParameterA
neuronParameterB
neuronParameterC
setNeuronType:parameterA:parameterB:parameterC:
setNeuronType:
neuronA
setNeuronA:
neuronB
setNeuronB:
neuronC
setNeuronC:
epsilon
setEpsilon:
_neuronType
_neuronA
_neuronB
_neuronC
_epsilon
Ti,N,V_neuronType
Tf,N,V_neuronA
Tf,N,V_neuronB
Tf,N,V_neuronC
Tf,N,V_epsilon
synchronizeOnCommandBuffer:
maskData
_maskStrideInPixels
_keepProbability
_commonBufferOffsetBytes
_commonMaskBuffer
supportsSecureCoding
initWithCoder:
TB,R
initWithSeed:
_rngState
resetSeedOnCommandBuffer:seed:
initWithDevice:keepProbability:seed:maskStrideInPixels:
initWithDevice:keepProbability:state:maskStrideInPixels:
synchronizeRandomStateOnCommandBuffer:
exportRandomState
privateResultStateForSourceImage:sourceStates:destinationImage:commandBuffer:isTemporary:
keepProbability
seed
maskStrideInPixels
_seed
_parallelGenerator
Tf,R,N,V_keepProbability
TQ,R,N,V_seed
T{?=QQQ},R,N,V_maskStrideInPixels
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:alignCorners:
scaleFactorX
scaleFactorY
alignCorners
_filterType
_scaleFactorX
_scaleFactorY
_alignCorners
Td,R,N,V_scaleFactorX
Td,R,N,V_scaleFactorY
TB,R,N,V_alignCorners
initWithDevice:integerScaleFactorX:integerScaleFactorY:
initWithDevice:integerScaleFactorX:integerScaleFactorY:alignCorners:
destinationImageDescriptorForSourceImages:sourceStates:forKernel:suggestedDescriptor:
resultStateForPrimaryImage:secondaryImage:sourceStates:
temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:
encodeToCommandEncoder:commandBuffer:sourceGradient:sourceImage:gradientState:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:
encodeToCommandEncoder:commandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:
encodeBatchToCommandEncoder:commandBuffer:sourceGradients:sourceImages:gradientStates:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
encodeBatchToCommandEncoder:commandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:
readGradientState:
readBinaryGradientState:isSecondarySourceFilter:
isStateModified
kernelOffsetX
setKernelOffsetX:
kernelOffsetY
setKernelOffsetY:
_kernelOffsetX
_kernelOffsetY
Tq,N,V_kernelOffsetX
Tq,N,V_kernelOffsetY
nodeWithSource:descriptor:
initWithSource:type:a:b:c:
_type
Tf,R,N,V_a
Tf,R,N,V_b
Tf,R,N,V_c
nodeWithSource:a:
initWithSource:a:
nodeWithSource:a:b:
initWithSource:a:b:
nodeWithSource:aData:
initWithSource:aData:
_aData
nodeWithSource:a:b:c:
initWithSource:a:b:c:
initWithGradientImages:forwardFilter:
nodeWithSourceGradient:sourceImage:gradientState:descriptor:
initWithSourceGradient:sourceImage:gradientState:descriptor:
_descriptor
T@"MPSNNNeuronDescriptor",R,N,V_descriptor
nodeWithSource:resultWidth:resultHeight:resultFeatureChannels:
initWithSource:resultWidth:resultHeight:resultFeatureChannels:
_resultWidth
_resultHeight
_resultFeatureChannels
nodeWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
initWithSource:paddingSizeBefore:paddingSizeAfter:edgeMode:
_edgeMode
useGridValueAsInputCoordinate
setUseGridValueAsInputCoordinate:
_useGridValueAsInputCoordinate
TB,N,V_useGridValueAsInputCoordinate
newMatrixFullyConnected
encodeToCommandBuffer:inputMatrix:weightMatrix:biasVector:resultMatrix:
setNeuronToPReLUWithParametersA:
_encode
neuronAParamBuf
_plugin
encodeToCommandBuffer:inputMatrix:biasVector:resultMatrix:
encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:
encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
numberOfFeatureChannels
gamma
beta
mean
variance
updateGammaAndBetaWithCommandBuffer:batchNormalizationState:
updateMeanAndVarianceWithCommandBuffer:batchNormalizationState:
updateGammaAndBetaWithBatchNormalizationState:
updateMeanAndVarianceWithBatchNormalizationState:
initWithDevice:dataSource:fusedNeuronDescriptor:
initWithDevice:dataSource:
encodeToCommandBuffer:sourceImage:batchNormalizationState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:destinationImages:
encodeToCommandBuffer:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceImages:batchNormalizationState:
reloadDataSourceDeprecated:doReloadWeights:doReloadStats:
reloadDataSource:
reloadGammaAndBetaFromDataSource
reloadMeanAndVarianceFromDataSource
reloadGammaAndBetaWithCommandBuffer:gammaAndBetaState:
reloadMeanAndVarianceWithCommandBuffer:meanAndVarianceState:
_gamma
_beta
_meanDS
_varDS
_stateNeedsToLoad
_fusedNeuronDescriptor
_preluBuffer
_numberOfFeatureChannels
TQ,R,N,V_numberOfFeatureChannels
T@"<MPSCNNBatchNormalizationDataSource>",R,&,N,V_dataSource
initWithResource:weightsLayout:
initWithDevice:resourceList:convolution:weightsLayout:
temporaryStateWithCommandBuffer:resourceList:convolutionTranspose:convolutionGradientState:weightsLayout:
temporaryStateWithCommandBuffer:resourceList:convolutionTranspose:convolutionGradientState:
sourceWidth
sourceHeight
convolution
initWithDevice:resourceList:convolution:
initWithDevice:resourceList:convolutionTranspose:convolutionGradientState:
initWithDevice:resourceList:convolutionTranspose:convolutionGradientState:weightsLayout:
convolutionGradientState
_convolutionGradientState
T@"MPSCNNConvolutionGradientState",R,N,V_convolutionGradientState
T@"MPSCNNConvolutionTranspose",R,&,N,V_convolutionTranspose
encodeToCommandBuffer:sourceImage:inState:
encodeBatchToCommandBuffer:sourceImages:inStates:
encodeToCommandBuffer:sourceImage:inState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:inStates:destinationImages:
encodeToCommandBuffer:sourceImage:sourceState:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:sourceStates:destinationStates:destinationStateIsTemporary:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:sourceOffset:kernelOffset:
weightsBufferLength
accumulatorPrecisionOption
setAccumulatorPrecisionOption:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:
initialize:weights:fullyConnected:
initialize:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
encodeToCommandBuffer:sourceImage:convolutionState:
encodeToCommandBuffer:sourceImage:convolutionGradientState:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationImage:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationImages:
encodeToCommandBuffer:sourceImage:convolutionGradientState:destinationState:destinationStateIsTemporary:
encodeBatchToCommandBuffer:sourceImages:convolutionGradientStates:destinationStates:destinationStateIsTemporary:
reloadWeightsAndBiasesWithDataSource:
exportWeightsAndBiasesWithCommandBuffer:resultStateCanBeTemporary:
appendBatchBarrier
featureChannelsLayout
_featureChannelsLayout
_convolution
TQ,R,N,V_featureChannelsLayout
TQ,R,N
TQ,N
T@"<MPSCNNConvolutionDataSource>",R,&,N
nodeWithSources:
nodeWithLeftSource:rightSource:
initWithSources:
initWithLeftSource:rightSource:
gradientFilterWithSources:
gradientFiltersWithSources:
primaryStrideInPixelsX
primaryStrideInPixelsY
secondaryStrideInPixelsX
secondaryStrideInPixelsY
_primaryStrideInPixelsX
_primaryStrideInPixelsY
_secondaryStrideInPixelsX
_secondaryStrideInPixelsY
TQ,N,V_primaryStrideInPixelsX
TQ,N,V_primaryStrideInPixelsY
TQ,N,V_secondaryStrideInPixelsX
TQ,N,V_secondaryStrideInPixelsY
initWithGradientImages:sourceImages:binaryGradientState:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
initWithSourceGradient:sourceImage:gradientState:isSecondarySourceFilter:
initWithGradientImages:forwardFilter:isSecondarySourceFilter:
initWithDevice:fusedNeuronDescriptor:
accumulatesOverBatch
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:
initWithSource:integerScaleFactorX:integerScaleFactorY:
nodeWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
initWithSource:integerScaleFactorX:integerScaleFactorY:alignCorners:
nodeWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
initWithSourceGradient:sourceImage:gradientState:scaleFactorX:scaleFactorY:
optimizerDescriptorWithLearningRate:gradientRescale:regularizationType:regularizationScale:
optimizerDescriptorWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
initWithLearningRate:gradientRescale:applyGradientClipping:gradientClipMax:gradientClipMin:regularizationType:regularizationScale:
initWithLearningRate:gradientRescale:regularizationType:regularizationScale:
learningRate
setLearningRate:
gradientRescale
setGradientRescale:
applyGradientClipping
setApplyGradientClipping:
gradientClipMax
setGradientClipMax:
gradientClipMin
setGradientClipMin:
regularizationType
setRegularizationType:
regularizationScale
setRegularizationScale:
_learningRate
_gradientRescale
_applyGradientClipping
_gradientClipMax
_gradientClipMin
_regularizationType
_regularizationScale
Tf,N,V_learningRate
Tf,N,V_gradientRescale
TB,N,V_applyGradientClipping
Tf,N,V_gradientClipMax
Tf,N,V_gradientClipMin
Tf,N,V_regularizationScale
TQ,N,V_regularizationType
initWithDevice:optimizerDescriptor:
Tf,R,N,V_learningRate
Tf,R,N,V_gradientRescale
Tf,R,N,V_gradientClipMax
Tf,R,N,V_gradientClipMin
Tf,R,N,V_regularizationScale
TQ,R,N,V_regularizationType
useNestrovMomentum
initWithDevice:learningRate:
initWithDevice:momentumScale:useNesterovMomentum:optimizerDescriptor:
initWithDevice:momentumScale:useNestrovMomentum:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:resultValuesVector:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:resultValuesMatrix:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:resultState:
momentumScale
useNesterovMomentum
_momentumScale
_useNesterovMomentum
Tf,R,N,V_momentumScale
TB,R,N,V_useNesterovMomentum
TB,R,N
initWithDevice:decay:epsilon:optimizerDescriptor:
initWithDevice:decay:epsilon:momentumScale:centered:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:resultValuesVector:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputSumOfSquaresMatrix:resultValuesMatrix:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputSumOfSquaresVector:inputWeightedSumVector:inputMomentumVector:resultValuesVector:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputSumOfSquaresMatrix:inputWeightedSumMatrix:inputMomentumMatrix:resultValuesMatrix:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputSumOfSquaresVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputSumOfSquaresVectors:resultState:
decay
centered
_decay
_centered
Td,R,N,V_momentumScale
TB,R,N,V_centered
Td,R,N,V_decay
Tf,R,N,V_epsilon
initWithDevice:beta1:beta2:epsilon:timeStep:optimizerDescriptor:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:inputVelocityVector:resultValuesVector:
encodeToCommandBuffer:inputGradientVector:inputValuesVector:inputMomentumVector:inputVelocityVector:maximumVelocityVector:resultValuesVector:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:inputVelocityMatrix:resultValuesMatrix:
encodeToCommandBuffer:inputGradientMatrix:inputValuesMatrix:inputMomentumMatrix:inputVelocityMatrix:maximumVelocityMatrix:resultValuesMatrix:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:convolutionGradientState:convolutionSourceState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationGradientState:batchNormalizationSourceState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:inputVelocityVectors:resultState:
encodeToCommandBuffer:batchNormalizationState:inputMomentumVectors:inputVelocityVectors:maximumVelocityVectors:resultState:
beta1
beta2
timeStep
setTimeStep:
_beta1
_beta2
_timeStep
_timeStepSemaphore
Td,R,N,V_beta1
Td,R,N,V_beta2
TQ,N,V_timeStep
imageForCommandBuffer:imageDescriptor:kernel:
graphWithDevice:resultImage:resultImageIsNeeded:
graphWithDevice:resultImage:
graphWithDevice:resultImages:resultsAreNeeded:
resultImageIsNeeded
initWithDevice:resultImage:
initWithDevice:resultImage:resultImageIsNeeded:
initWithDevice:resultImages:resultsAreNeeded:
sourceImageHandles
sourceStateHandles
intermediateImageHandles
resultStateHandles
resultHandle
encodeToCommandBuffer:sourceImages:
encodeBatchToCommandBuffer:sourceImages:sourceStates:
encodeToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
encodeBatchToCommandBuffer:sourceImages:sourceStates:intermediateImages:destinationStates:
executeAsyncWithSourceImages:completionHandler:
reloadFromDataSources
readCountForSourceImageAtIndex:
readCountForSourceStateAtIndex:
outputStateIsTemporary
setOutputStateIsTemporary:
destinationImageAllocator
setDestinationImageAllocator:
format
setFormat:
.cxx_destruct
.cxx_construct
_graph
_destinationImageAllocator
_format
_resultIsNeeded
_outputStateIsTemporary
T@"NSArray",R,C,N
T@"<MPSHandle>",R,N
TB,N,V_outputStateIsTemporary
T@"<MPSImageAllocator>",&,N,V_destinationImageAllocator
TQ,N,V_format
trainingStyle
setTrainingStyle:
wrapperWithFilterNode:
node
initWithFilterNode:
wrapperWithResource:
_node
initWithDevice:kernelSize:
kernelSize
setBeta:
delta
setDelta:
_kernelSize
_delta
Tf,N,V_alpha
Tf,N,V_beta
Tf,N,V_delta
TQ,R,N,V_kernelSize
setP0:
setPm:
setPs:
Tf,N,V_p0
Tf,N,V_pm
Tf,N,V_ps
nodeWithSource:lossDescriptor:
initWithSource:lossDescriptor:
trainingGraphWithSourceGradient:nodeHandler:
inputLabels
_labels
T@"MPSNNLabelsNode",R,&,N,V_labels
nodeWithSource:labels:weights:lossDescriptor:
nodeWithSource:labels:lossDescriptor:
nodeWithSources:lossDescriptor:
initWithSource:labels:weights:lossDescriptor:
initWithSource:labels:lossDescriptor:
initWithSources:lossDescriptor:
gradientFiltersWithSource:
lossType
reductionType
labelSmoothing
numberOfClasses
reduceAcrossBatch
propertyCallBack
setPropertyCallBack:
_lossType
_reductionType
_labelSmoothing
_numberOfClasses
_propertyCallBack
_reduceAcrossBatch
TI,R,N,V_lossType
Ti,R,N,V_reductionType
TQ,R,N,V_numberOfClasses
TB,R,N,V_reduceAcrossBatch
Tf,R,N,V_weight
Tf,R,N,V_labelSmoothing
Tf,R,N,V_delta
T@"<MPSNNLossCallback>",&,N,V_propertyCallBack
nodeWithSourceGradient:sourceImage:labels:weights:gradientState:lossDescriptor:isLabelsGradientFilter:
nodeWithSourceGradient:sourceImage:labels:gradientState:lossDescriptor:isLabelsGradientFilter:
nodeWithSources:gradientState:lossDescriptor:isLabelsGradientFilter:
initWithSourceGradient:sourceImage:labels:weights:gradientState:lossDescriptor:isLabelsGradientFilter:
initWithSourceGradient:sourceImage:labels:gradientState:lossDescriptor:isLabelsGradientFilter:
initWithSources:gradientState:lossDescriptor:isLabelsGradientFilter:
isLabelsGradientFilter
_isLabelsGradientFilter
TB,R,N,V_isLabelsGradientFilter
cnnLossDataDescriptorWithData:layout:size:
layout
size
bytesPerRow
setBytesPerRow:
bytesPerImage
setBytesPerImage:
_data
_layout
_bytesPerRow
_bytesPerImage
TQ,R,N,V_layout
T{?=QQQ},R,N,V_size
TQ,N,V_bytesPerRow
TQ,N,V_bytesPerImage
cnnLossDescriptorWithType:reductionType:
setLabelSmoothing:
setNumberOfClasses:
setLossType:
setReductionType:
setReduceAcrossBatch:
TI,N,V_lossType
Ti,N,V_reductionType
TB,N,V_reduceAcrossBatch
Tf,N,V_labelSmoothing
TQ,N,V_numberOfClasses
initWithDevice:resourceList:
initWithDevice:labelsDescriptor:
initWithDevice:lossImageSize:labelsDescriptor:weightsDescriptor:
initWithDevice:lossImageSize:labelsImage:weightsImage:
lossImage
labelsImage
weightsImage
_lossImageSize
_isScalarLoss
_userData
_userDataLayout
_numFeatureChannels_labels
_numFeatureChannels_loss
_userLabelsImage
_userWeightsImage
_hasStateWeights
_computeNonZeroWeights
initWithDevice:lossDescriptor:
resultStateForSourceImage:sourceStates:
temporaryResultStateForCommandBuffer:sourceImage:sourceStates:
encodeToCommandBuffer:sourceImage:labels:destinationImage:
encodeToCommandBuffer:sourceImage:labels:
encodeBatchToCommandBuffer:sourceImages:labels:destinationImages:
encodeBatchToCommandBuffer:sourceImages:labels:
_reductionBuffer
_firstLossImage
_lossLabels
encodeBatchToCommandBuffer:sourceImages:labels:weights:destinationStates:destinationImages:
encodeBatchToCommandBuffer:sourceImages:labels:weights:destinationStates:destinationStateIsTemporary:
_propertyCallback
encodeBatchToCommandBuffer:sourceGradients:sourceImages:labels:weights:sourceStates:destinationGradients:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:labels:weights:sourceStates:
computeLabelGradients
setComputeLabelGradients:
_firstLossGradientImage
_computeLabelGradients
TB,N,V_computeLabelGradients
_neuronFilter
initWithDevice:filterType:integerScaleFactorX:integerScaleFactorY:
numberOfGroups
setNumberOfGroups:
updateGammaAndBetaWithCommandBuffer:groupNormalizationStateBatch:
updateGammaAndBetaWithGroupNormalizationStateBatch:
reloadDataSourceDeprecated:
_numberOfGroups
T@"<MPSCNNGroupNormalizationDataSource>",R,&,N,V_dataSource
temporaryStateWithCommandBuffer:numberOfFeatureChannels:groupNormalization:
gradientForGamma
gradientForBeta
initWithDevice:numberOfFeatureChannels:groupNormalization:
groupNormalization
_groupNormalization
T@"MPSCNNGroupNormalization",R,&,N,V_groupNormalization
T@"<MTLBuffer>",R,N
_fwdPermuteOrder
_revPermuteOrder
encodeBatchInternalToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:srcSize:destSize:testClipRect:testMaxClipRect:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:
dimensionOrder
setDimensionOrder:
_dimensionOrder
T{MPSNNDimensionOrder=[4Q]},N,V_dimensionOrder
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:destinationImages:
_revPermuteKernel
nodeWithHandle:
exportedNodeWithHandle:
initWithHandle:
initWithParent:
debugQuickLookObject
handle
setHandle:
imageAllocator
setImageAllocator:
exportFromGraph
setExportFromGraph:
synchronizeResource
setSynchronizeResource:
stopGradient
setStopGradient:
_parent
_imageAllocator
_clientCount
_exportFromGraph
_synchronize
_stopGradient
_initializedWithParent
T@"<MPSHandle>",&,N,V_handle
T@"<MPSImageAllocator>",&,N,V_imageAllocator
TB,N,V_exportFromGraph
TB,N,V_synchronize
TB,N,V_stopGradient
resultState
resultStates
resultStatesNoAllocate
sourceImages
sourceStates
paddingPolicy
setPaddingPolicy:
resultImage
_sourceImages
_sourceStates
_resultImage
_resultStates
_paddingPolicy
_label
T@"MPSNNImageNode",R,N,V_resultImage
T@"MPSNNStateNode",R,N
T@"NSArray",R,N
T@"<MPSNNPadding>",&,N,V_paddingPolicy
T@"NSString",C,V_label
initWithDevice:sourceIndex:
_sourceIndex
updateGammaAndBetaWithCommandBuffer:instanceNormalizationStateBatch:
updateGammaAndBetaWithInstanceNormalizationStateBatch:
T@"<MPSCNNInstanceNormalizationDataSource>",R,&,N,V_dataSource
initWithResources:
temporaryStateWithCommandBuffer:bufferSize:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:
initWithDevice:bufferSize:
initWithGamma:beta:
_initialized
temporaryStateWithCommandBuffer:numberOfFeatureChannels:instanceNormalization:
initWithDevice:numberOfFeatureChannels:instanceNormalization:
instanceNormalization
_instanceNormalization
T@"MPSCNNInstanceNormalization",R,&,N,V_instanceNormalization
initWithDevice:resizeWidth:resizeHeight:numberOfRegions:regions:
resizeWidth
resizeHeight
numberOfRegions
regions
_resizeWidth
_resizeHeight
_numberOfRegions
_regions
_gpuRegions
TQ,R,N,V_resizeWidth
TQ,R,N,V_resizeHeight
TQ,R,N,V_numberOfRegions
Tr^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}},R,N,V_regions
encodeToCommandBuffer:sourceImage:destinationImage:
encodeBatchToCommandBuffer:sourceImages:destinationImages:
encodeToCommandBuffer:sourceImage:
encodeBatchToCommandBuffer:sourceImages:
newPlugin
newCNNPoolingAverageWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
encodeBatchToCommandBuffer:computeCommandEncoder:options:sourceTextures:sourceInfo:destinationTextures:destinationInfo:zeroPadSizeX:zeroPadSizeY:predicationBuffer:predicationOffset:
pluginSupportsBatchEncode
newCNNDilatedPoolingMaxWithKernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
dilationRateX
dilationRateY
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:destinationGradient:
encodeToCommandBuffer:sourceGradient:sourceImage:batchNormalizationState:
encodeBatchToCommandBuffer:sourceGradients:sourceImages:batchNormalizationState:destinationGradients:
paddingMethod
inverse
encodeBatchToCommandBuffer:computeCommandEncoder:options:pluginOptions:primaryTextures:primaryInfo:secondaryTextures:secondaryInfo:destinationTextures:destinationInfo:predicationBuffer:predicationOffset:
primarySourceRegionForDestinationSize:
secondarySourceRegionForDestinationSize:
setDestinationFeatureChannelOffset:
setPrimarySourceFeatureChannelOffset:
setSecondarySourceFeatureChannelOffset:
setPrimarySourceFeatureChannelMaxCount:
setSecondarySourceFeatureChannelMaxCount:
encodeToCommandBuffer:primaryImage:secondaryImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:destinationImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:
encodeInternalToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:subBatchIndex:batchSize:clipRect:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:subBatchIndex:batchSize:
encodeToCommandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeToCommandEncoder:commandBuffer:primaryImage:secondaryImage:inState:destinationImage:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:inStates:
encodeBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:
encodeInternalBatchToCommandEncoder:commandBuffer:primaryImages:secondaryImages:inStates:destinationImages:clipRect:
resultStateBatchForPrimaryImage:secondaryImage:sourceStates:destinationImage:
temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:
plugin
setPlugin:
encodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:
batchEncodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:
primaryOffset
setPrimaryOffset:
secondaryOffset
setSecondaryOffset:
clipRect
setClipRect:
primaryEdgeMode
setPrimaryEdgeMode:
secondaryEdgeMode
setSecondaryEdgeMode:
destinationFeatureChannelOffset
primarySourceFeatureChannelOffset
primarySourceFeatureChannelMaxCount
secondarySourceFeatureChannelOffset
secondarySourceFeatureChannelMaxCount
primaryKernelWidth
primaryKernelHeight
secondaryKernelWidth
secondaryKernelHeight
primaryDilationRateX
primaryDilationRateY
secondaryDilationRateX
secondaryDilationRateY
isBackwards
padding
setPadding:
_primaryOffset
_secondaryOffset
_clipRect
_destinationFeatureChannelOffset
_primarySourceFeatureChannelOffset
_secondarySourceFeatureChannelOffset
_primarySourceFeatureChannelMaxCount
_secondarySourceFeatureChannelMaxCount
_pluginSupportsBatchEncode
_primaryKernelWidth
_primaryKernelHeight
_secondaryKernelWidth
_secondaryKernelHeight
_primaryDilationRateX
_primaryDilationRateY
_secondaryDilationRateX
_secondaryDilationRateY
_isBackwards
_supportsBroadcasting
_padding
_primaryEdgeMode
_secondaryEdgeMode
_checkFlags
_batchEncode
_encodeData
_pluginOptions
T{?=qqq},N,V_primaryOffset
T{?=qqq},N,V_secondaryOffset
T{?={?=QQQ}{?=QQQ}},N,V_clipRect
TQ,N,V_destinationFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelOffset
TQ,N,V_secondarySourceFeatureChannelOffset
TQ,N,V_primarySourceFeatureChannelMaxCount
TQ,N,V_secondarySourceFeatureChannelMaxCount
TQ,N,V_primaryEdgeMode
TQ,N,V_secondaryEdgeMode
TQ,R,N,V_primaryKernelWidth
TQ,R,N,V_primaryKernelHeight
TQ,R,N,V_secondaryKernelWidth
TQ,R,N,V_secondaryKernelHeight
TQ,R,N,V_primaryDilationRateX
TQ,R,N,V_primaryDilationRateY
TQ,R,N,V_secondaryDilationRateX
TQ,R,N,V_secondaryDilationRateY
TB,R,N,V_isBackwards
T@"<MPSNNPadding>",&,N,V_padding
initWithFilter:
temporaryStateWithCommandBuffer:numberOfFeatureChannels:epsilon:batchNormalization:
initDeferredWithDevice:numberOfFeatureChannels:epsilon:batchNormalization:
reset
batchNormalization
_batchNormalization
_accumulationCount
T@"MPSCNNBatchNormalization",R,&,N,V_batchNormalization
initWithMean:variance:
initWithDevice:resizeWidth:resizeHeight:alignCorners:
nodeWithSource:keepProbability:
nodeWithSource:keepProbability:seed:maskStrideInPixels:
initWithSource:keepProbability:
initWithSource:keepProbability:seed:maskStrideInPixels:
_maskStride
T{?=QQQ},R,N,V_maskStride
nodeWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
initWithSourceGradient:sourceImage:gradientState:keepProbability:seed:maskStrideInPixels:
cnnNeuronDescriptorWithType:a:b:c:
cnnNeuronDescriptorWithType:a:b:
cnnNeuronDescriptorWithType:a:
cnnNeuronDescriptorWithType:
cnnNeuronPReLUDescriptorWithData:noCopy:
initializeWithType:a:b:c:
initWithType:a:b:c:
initializeWithPReLUWithData:noCopy:
initWithPReLUWithData:noCopy:
neuronInfo
setA:
setB:
setC:
data
setData:
_noCopy
_count
Tf,N,V_a
Tf,N,V_b
Tf,N,V_c
T@"NSData",&,N,V_data
newCNNNeuronWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
newCNNNeuronWithNeuronType:neuronParameterAArray:count:
initWithDevice:neuronDescriptor:
privateInitWithDevice:a:b:c:type:
privateInitWithDevice:a:count:type:
initializeWithNeuronType:neuronParameterA:neuronParameterB:neuronParameterC:
initializeWithNeuronType:neuronParameterA:count:
Ti,R,N,V_neuronType
T@"NSData",R,&,N,V_data
initWithDevice:a:b:
initWithDevice:neuronDescriptor:aArray:
initWithDevice:a:
initWithDevice:a:count:
initWithDevice:a:b:c:
nodeWithSource:dimensionOrder:
initWithSource:dimensionOrder:
_order
initWithDevice:alpha:
_filters
setWeightValue:
initWithDevice:reduceOperation:
_reduceOp
_weightValue
offset
T{?=qqq},N
weight:
reduceOp
primarySourceClipRect
setPrimarySourceClipRect:
secondarySourceClipRect
setSecondarySourceClipRect:
_clipRectPrimarySource
_secondarySourceClipRect
_primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_primarySourceClipRect
T{?={?=QQQ}{?=QQQ}},N,V_secondarySourceClipRect
initWithDevice:doWeightedSumByNonZeroWeights:
doWeightedSumByNonZeroWeights
initWithDevice:windowInX:windowInY:strideInX:strideInY:
windowInX
setWindowInX:
windowInY
setWindowInY:
strideInX
setStrideInX:
strideInY
setStrideInY:
_windowInX
_windowInY
_strideInX
_strideInY
TQ,N,V_windowInX
TQ,N,V_windowInY
TQ,N,V_strideInX
TQ,N,V_strideInY
initWithSource:neuronInfo:batchNorm:
_source
encodeBatchToCommandBuffer:computeCommandEncoder:options:pluginOptions:sourceTextures:sourceInfo:destinationTextures:destinationInfo:predicationBuffer:predicationOffset:
sourceRegionForDestinationSize:
setSourceFeatureChannelOffset:
setSourceFeatureChannelMaxCount:
encodeToCommandEncoder:commandBuffer:sourceImage:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationState:destinationImage:
destinationImageWithCommandBuffer:sourceImage:inState:
encodeToCommandEncoder:commandBuffer:sourceImage:inState:
encodeToCommandEncoder:commandBuffer:sourceImage:sourceState:destinationState:destinationStateIsTemporary:
encodeToCommandEncoder:commandBuffer:sourceImage:destinationState:destinationStateIsTemporary:
encodeToCommandEncoder:commandBuffer:sourceImage:inState:destinationImage:
encodeInternalToCommputeEncoder:commandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:clipRect:shouldHandleCompoundImageNatively:
encodeToCommandEncoder:commandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:
encodeToCommandBuffer:sourceImage:inState:destinationImage:subBatchIndex:batchSize:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationStates:destinationImages:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:inStates:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:sourceStates:destinationStates:destinationStateIsTemporary:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:
encodeInternalBatchToCommandEncoder:commandBuffer:sourceImages:inStates:destinationImages:clipRect:
sourcePositionOfTopLeftCornerOfFilterWindow
setOffset:
edgeMode
sourceFeatureChannelOffset
sourceFeatureChannelMaxCount
kernelWidth
kernelHeight
strideInPixelsX
strideInPixelsY
_offset
_sourceFeatureChannelOffset
_sourceFeatureChannelMaxCount
_kernelWidth
_kernelHeight
_strideInPixelsX
_strideInPixelsY
_dilationRateX
_dilationRateY
_maxBatchSize
T{?=qqq},N,V_offset
TQ,N,V_sourceFeatureChannelOffset
TQ,N,V_sourceFeatureChannelMaxCount
TQ,N,V_edgeMode
TQ,R,N,V_kernelWidth
TQ,R,N,V_kernelHeight
TQ,R,N,V_strideInPixelsX
TQ,R,N,V_strideInPixelsY
TQ,R,N,V_dilationRateX
TQ,R,N,V_dilationRateY
paddingWithMethod:
paddingForTensorflowAveragePooling
paddingForTensorflowAveragePoolingValidOnly
zeroPaddingWithTopAmount:bottomAmount:leftAmount:rightAmount:
initWithPaddingMethod:
_method
_mpsOwned
initWithPaddingLeft:paddingRight:paddingTop:paddingBottom:
_paddingLeft
_paddingRight
_paddingTop
_paddingBottom
nodeWithSource:filterSize:
nodeWithSource:filterSize:stride:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:
initWithSource:filterSize:stride:
initWithSource:filterSize:
nodeWithSource:filterSize:stride:dilationRate:
initWithSource:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
initWithSource:filterSize:stride:dilationRate:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:paddingPolicy:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:strideInPixelsX:strideInPixelsY:dilationRateX:dilationRateY:
encodeToCommandBuffer:gradientMatrix:inputMatrix:biasVector:resultGradientForDataMatrix:resultGradientForBiasVector:
initWithDevice:sourceCount:
offsetAtIndex:
setOffset:atIndex:
sourceFeatureChannelOffsetAtIndex:
setSourceFeatureChannelOffset:atIndex:
sourceFeatureChannelMaxCountAtIndex:
setSourceFeatureChannelMaxCount:atIndex:
edgeModeAtIndex:
setEdgeMode:atIndex:
kernelWidthAtIndex:
setKernelWidth:atIndex:
setKernelWidth:
kernelHeightAtIndex:
setKernelHeight:atIndex:
setKernelHeight:
strideInPixelsXatIndex:
setStrideInPixelsX:atIndex:
setStrideInPixelsX:
strideInPixelsYatIndex:
setStrideInPixelsY:atIndex:
setStrideInPixelsY:
dilationRateXatIndex:
setDilationRateX:atIndex:
setDilationRateX:
dilationRateYatIndex:
setDilationRateY:atIndex:
setDilationRateY:
encodeToCommandEncoder:commandBuffer:sourceImages:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImages:inState:destinationImage:
encodeToCommandBuffer:sourceImages:inState:destinationImage:
encodeToCommandEncoder:commandBuffer:sourceImages:
encodeToCommandEncoder:commandBuffer:sourceImages:inState:
encodeToCommandBuffer:sourceImages:inState:
encodeBatchToCommandEncoder:commandBuffer:sourceImages:sourceStates:
encodeToCommandEncoder:commandBuffer:sourceImages:destinationState:destinationStateIsTemporary:
encodeToCommandBuffer:sourceImages:destinationState:destinationStateIsTemporary:
destinationImageDescriptorForSourceImages:sourceStates:paddingMethod:
sourceCount
_srcInfo
_srcCount
TQ,R,N,V_srcCount
_reductionKernel
nodeWithSource:kernelSize:
initWithSource:kernelSize:
TQ,N,V_kernelWidth
TQ,N,V_kernelHeight
nodeWithSourceGradient:sourceImage:gradientState:kernelSize:
initWithSourceGradient:sourceImage:gradientState:kernelSize:
nodeWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
initWithSourceGradient:sourceImage:gradientState:kernelWidth:kernelHeight:
kernelSizeInFeatureChannels
setKernelSizeInFeatureChannels:
_kernelSizeInFeatureChannels
TQ,N,V_kernelSizeInFeatureChannels
nodeWithSource:dataSource:
initWithSource:dataSource:
_trainingStyle
TQ,N,V_trainingStyle
calculateStatistics
flags
setFlags:
_flags
TQ,N,V_flags
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:
initWithDevice:convolutionDescriptor:kernelWeights:biasTerms:flags:fullyConnected:convolutionTranspose:
initWithDevice:weights:fullyConnected:convolutionTranspose:
nodeWithSource:weights:
initWithSource:weights:
initWithSource:weights:state:
convolutionState
accumulatorPrecision
setAccumulatorPrecision:
_accumulatorPrecision
T@"MPSCNNConvolutionStateNode",R,N
T@"<MPSCNNConvolutionDataSource>",R,N,V_weights
TQ,N,V_accumulatorPrecision
T@"MPSCNNConvolutionGradientStateNode",R,N
nodeWithSourceGradient:sourceImage:convolutionGradientState:weights:
initWithSourceGradient:sourceImage:gradientState:weights:
initWithSourceGradient:sourceImage:convolutionGradientState:weights:
nodeWithSourceGradient:sourceImage:convolutionTransposeGradientState:weights:
initWithSourceGradient:sourceImage:convolutionTransposeGradientState:weights:
nodeWithSource:weights:scaleValue:type:flags:
nodeWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
initWithSource:weights:scaleValue:type:flags:
initWithSource:weights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
_scaleValue
_outputBiasTerms
_outputScaleTerms
_inputBiasTerms
_inputScaleTerms
nodeWithSource:convolutionGradientState:weights:
nodeWithSource:convolutionState:weights:
initWithSource:convolutionGradientState:weights:
initWithSource:convolutionState:weights:
nodeWithSource:alpha:
initWithSource:alpha:
Tf,R,N,V_alpha
T@"<MPSNNGramMatrixCallback>",&,N,V_propertyCallBack
nodeWithSourceGradient:sourceImage:gradientState:alpha:
initWithSourceGradient:sourceImage:gradientState:alpha:
fusedNeuronDescriptor
wrapperForDataSource:
appendBatchNorm:
initialize
initWithDataSource:
appendNeuron:
appendNeuronDescriptor:
hasBatchNorm
_batchNorm
_neuron
_loadCount
cnnLossDescriptorWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
initWithXYLossType:WHLossType:confidenceLossType:classesLossType:reductionType:anchorBoxes:numberOfAnchorBoxes:
XYLossDescriptor
setXYLossDescriptor:
WHLossDescriptor
setWHLossDescriptor:
confidenceLossDescriptor
setConfidenceLossDescriptor:
classesLossDescriptor
setClassesLossDescriptor:
rescore
setRescore:
scaleXY
setScaleXY:
scaleWH
setScaleWH:
scaleNoObject
setScaleNoObject:
scaleObject
setScaleObject:
scaleClass
setScaleClass:
minIOUForObjectPresence
setMinIOUForObjectPresence:
maxIOUForObjectAbsence
setMaxIOUForObjectAbsence:
anchorBoxes
setAnchorBoxes:
numberOfAnchorBoxes
setNumberOfAnchorBoxes:
_XYLossDescriptor
_WHLossDescriptor
_confidenceLossDescriptor
_classesLossDescriptor
_rescore
_scaleXY
_scaleWH
_scaleNoObject
_scaleObject
_scaleClass
_minIOUForObjectPresence
_maxIOUForObjectAbsence
_anchorBoxes
_numberOfAnchorBoxes
T@"MPSCNNLossDescriptor",&,N,V_XYLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_WHLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_confidenceLossDescriptor
T@"MPSCNNLossDescriptor",&,N,V_classesLossDescriptor
TB,N,V_rescore
Tf,N,V_scaleXY
Tf,N,V_scaleWH
Tf,N,V_scaleNoObject
Tf,N,V_scaleObject
Tf,N,V_scaleClass
Tf,N,V_minIOUForObjectPresence
Tf,N,V_maxIOUForObjectAbsence
TQ,N,V_numberOfAnchorBoxes
T@"NSData",&,N,V_anchorBoxes
initializeSupportFiltersWithDevice:lossDescriptor:
countPresetobjectsSourceImages:labels:
lossXY
lossWH
lossConfidence
lossClasses
_lossXY
_lossWH
_lossConfidence
_lossClasses
_countOfPresentObjects
_encodingSemaphore
_firstLossTexture
T@"MPSCNNLoss",R,&,N,V_lossXY
T@"MPSCNNLoss",R,&,N,V_lossWH
T@"MPSCNNLoss",R,&,N,V_lossConfidence
T@"MPSCNNLoss",R,&,N,V_lossClasses
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
cnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:postFilters:
setFusedNeuronDescriptor:
setNeuronParameterA:
setNeuronParameterB:
setNeuronParameterC:
setNeuronType:parameterA:parameterB:
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:
hasBatchNormData
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:
setGroups:
setBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:
setNeuron:
newDescriptorWithNeuronInfo:
setFeatureChannelsLayout:
neuron
_batchNormalizationData
_deprecated_neuron
_subPixelScaleFactor
_depthWiseConvolution
_neuron_deprecated
TQ,N,V_featureChannelsLayout
TQ,N,V_strideInPixelsX
TQ,N,V_strideInPixelsY
TQ,N,V_groups
TQ,N,V_dilationRateX
TQ,N,V_dilationRateY
T@"MPSNNNeuronDescriptor",&,N,V_fusedNeuronDescriptor
T@"MPSCNNNeuron",&,N,V_neuron_deprecated
subPixelScaleFactor
setSubPixelScaleFactor:
initWithSourceWidth:sourceHeight:kernelWidth:kernelHeight:sourceOffset:
sourceOffset
_originalConvolutionSourceWidth
_originalConvolutionSourceHeight
_srcOffset
T{?=qqq},R,N,V_srcOffset
TQ,R,N,V_originalConvolutionSourceWidth
TQ,R,N,V_originalConvolutionSourceHeight
temporaryStateWithCommandBuffer:resourceList:convolution:
temporaryStateWithCommandBuffer:resourceList:convolution:weightsLayout:
numberOfWeightGradients
gradientForWeightsLayout
numberOfBiasGradients
gradientForWeights
gradientForBiases
_intermediateWeightsBuffer
_intermeidateBiasesBuffer
_numReductionBlocks
_needReductionInN
_needReductionInXY
_dimSizeN
T@"MPSCNNConvolution",R,&,N,V_convolution
TI,R,N
initWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:strideInPixelsX:strideInPixelsY:groups:dilationRateX:dilationRateY:channelMultiplier:subPixelScaleFactor:isFullyConnected:isConvolutionTranspose:fusedNeuronDescriptor:
isFullyConnected
isConvolutionTranspose
_isFullyConnected
_isConvolutionTranspose
T@"MPSNNNeuronDescriptor",R,N,V_fusedNeuronDescriptor
TQ,R,N,V_subPixelScaleFactor
TB,R,N,V_isFullyConnected
TB,R,N,V_isConvolutionTranspose
neuronABuffer
quantizationBuffer
quantizationType
PrepareAndLoadData:dataType:weightsLayout:weights:biases:quantizationType:ranges:lookUpTable:convertFloat32Weights:
initialize:convolutionDescriptor:kernelWeights:dataType:weightsLayout:range:lookUpTable:qType:biasTerms:flags:fullyConnected:convolutionTranspose:preferredWeightsDataType:
initializeWithDevice:weights:fullyConnected:convolutionTranspose:
encodeToCommandBuffer:sourceImage:destinationImage:state:
resourceListForSourceImages:destinationImages:
_convertFloat32Weights
_qWts
_qType
_scaleFactor
_biasOriginal
_neuronABuffer
_accumulatorPrecisionOption
TQ,R,N,V_scaleFactor
T@"MPSCNNNeuron",R,N,V_neuron_deprecated
Ti,R,N
Tf,R,N
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:weightsDataType:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:weightsDataType:weightsLayout:
temporaryCNNConvolutionWeightsAndBiasesStateWithCommandBuffer:cnnConvolutionDescriptor:
numberOfWeights
numberOfBiases
weightsOffset
biasesOffset
initializeWithWeightsCount:weightsOffset:weightsDataType:weightsLayout:biasesCount:biasesOffset:
initWithWeights:biases:weightsDataType:
initWithWeights:biases:weightsDataType:weightsLayout:
initWithDevice:cnnConvolutionDescriptor:weightsDataType:
initWithDevice:cnnConvolutionDescriptor:weightsDataType:weightsLayout:
initWithWeights:biases:
initWithDevice:cnnConvolutionDescriptor:
initWithWeights:weightsOffset:biases:biasesOffset:cnnConvolutionDescriptor:
initWithWeights:weightsOffset:weightsDataType:weightsLayout:biases:biasesOffset:cnnConvolutionDescriptor:
_numberOfWeights
_numberOfBiases
_weightsOffset
_biasesOffset
initWithDevice:count:rows:columns:transpose:
encodeToCommandBuffer:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
encodeToCommandBuffer:encoder:sourceMatrices:resultMatrix:scaleVector:offsetVector:biasVector:startIndex:
rows
columns
count
transpose
resultMatrixOrigin
setResultMatrixOrigin:
_transpose
_rows
_columns
_resultMatrixOrigin
TQ,R,N,V_rows
TQ,R,N,V_columns
TQ,R,N,V_count
TB,R,N,V_transpose
T{?=QQQ},N,V_resultMatrixOrigin
PeakAtWeights:
_convolutionGradient
newCNNSoftMax
encodeToCommandBuffer:inputMatrix:meanVector:varianceVector:gammaVector:betaVector:resultMatrix:
computeStatistics
setComputeStatistics:
_computeStatistics
TB,N,V_computeStatistics
_destFeatureChannels
_srcSize
_sourceFeatureChannels
_initOnce
_provenance
_primarySrcSize
_primarySourceFeatureChannels
_secondarySrcSize
_secondarySourceFeatureChannels
initWithSourceCount:
_srcSizes
createBuffersFromkernelWeights:inputBiasTerms:inputScaleTerms:outputBiasTerms:outputScaleTerms:useHalfPrecision:
initWithDeviceImpl:convolutionDescriptor:kernelWeights:biasTerms:scaleValue:type:flags:
initWithDevice:convolutionData:scaleValue:type:flags:
initWithDeviceImpl:convolutionDescriptor:kernelWeights:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
initWithDevice:convolutionData:outputBiasTerms:outputScaleTerms:inputBiasTerms:inputScaleTerms:type:flags:
copyBuffer:device:
_neuronInfo
_filterStride
_outputbias
_outputScale
_inputbias
_inputScale
_convType
_poolingFilter
_outputScaleValue
initWithDeviceImpl:convolutionDescriptor:kernelWeights:scaleValue:type:flags:
device
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:pluginOptions:sourceTexture:sourceInfo:destinationTexture:destinationInfo:
encodeWithFilter:encoder:commandBuffer:callInfo:
encodeBatchWithFilter:encoder:commandBuffer:callInfo:
encodeToCommandBuffer:computeCommandEncoder:options:primaryTexture:primaryInfo:secondaryTexture:secondaryInfo:destinationTexture:destinationInfo:
encodeToCommandBuffer:computeCommandEncoder:options:sourceTexture:sourceInfo:destinationTexture:destinationInfo:zeroPadSizeX:zeroPadSizeY:
r^{MPSLibraryInfo=iI*^?{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}{MPSDeviceSpecificInfo=^{MPSKernelInfo}^?Q}}24@0:8^v16
@24@0:8@16
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40@48
@32@0:8^{_NSZone=}16@24
@32@0:8@16@24
v24@0:8@16
Q16@0:8
v24@0:8Q16
d16@0:8
v24@0:8d16
@16@0:8
@48@0:8@16@24Q32^{?=qqq}40
@56@0:8@16@24Q32Q40Q48
@68@0:8@16@24^@32B40Q44Q52Q60
@64@0:8@16@24Q32^{?=qqq}40^{?=qqq}48^{?=qqq}56
v16@0:8
{MPSImageCoordinate="x"Q"y"Q"channel"Q}
@72@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48@72
B16@0:8
@40@0:8@16@24@32
@48@0:8@16@24@32@40
{MPSImageCoordinate=QQQ}16@0:8
v40@0:8{MPSImageCoordinate=QQQ}16
f16@0:8
v20@0:8f16
@"<MTLBuffer>"
@40@0:8@16Q24Q32
@56@0:8@16Q24Q32Q40Q48
v48@0:8Q16Q24Q32Q40
{?=QQQ}16@0:8
v40@0:8{?=QQQ}16
{?="width"Q"height"Q"depth"Q}
@72@0:8@16Q24Q32Q40Q48Q56Q64
@28@0:8@16i24
@60@0:8@16@24@32@40@48B56
@56@0:8@16@24@32@40@48
@32@0:8@16i24B28
@"MPSNNReduceUnary"
@28@0:8@16B24
@24@0:8Q16
@48@0:8@16^@24^@32B40i44
@56@0:8@16@24^@32^@40B48i52
@36@0:8@16@24B32
@"MPSMatrix"
v20@0:8B16
@"<MPSCNNConvolutionDataSource>"
@32@0:8Q16Q24
i16@0:8
v20@0:8i16
@24@0:8^{_NSZone=}16
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
I16@0:8
^v16@0:8
^f16@0:8
^16@0:8
B32@0:8@16@24
@"MPSCNNConvolutionDescriptor"16@0:8
@"MPSCNNConvolutionWeightsAndBiasesState"40@0:8@"<MTLCommandBuffer>"16@"MPSCNNConvolutionGradientState"24@"MPSCNNConvolutionWeightsAndBiasesState"32
B32@0:8@"MPSCNNConvolutionGradientState"16@"MPSCNNConvolutionWeightsAndBiasesState"24
@32@0:8^{_NSZone=}16@"<MTLDevice>"24
@36@0:8@16B24@28
@"MPSCNNConvolutionDescriptor"
v72@0:8@16@24^Q32@40^Q48@56@64
@32@0:8@16Q24
@"MPSMatrixMultiplication"
v28@0:8@16I24
v36@0:8@16I24@28
v76@0:8@16@24Q32@40B48{?=QQQ}52
v88@0:8@16@24^Q32@40^Q48@56@64@72@80
v112@0:8@16@24^Q32@40^Q48@56^Q64@72@80@88@96@104
v72@0:8@16@24@32@40@48@56@64
@28@0:8Q16B24
@36@0:8@16Q24B32
@"NSMutableArray"
@56@0:8@16@24{?=QQQ}32
@48@0:8@16{?=QQQ}24
@"<MPSImageTransformProvider>"
@72@0:8@16@24@32{?=QQQ}40#64
@"MPSImageScale"
@"<MPSHandle>"
v40@0:8@16@24@32
^{MPSSliceInfo=QQ}
v60@0:8@16@24^v32I40I44B48B52I56
v40@0:8@16@24B32B36
v32@0:8@16@24
Q40@0:8@16@24@32
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{?={?=QQQ}{?=QQQ}}16@0:8
v64@0:8{?={?=QQQ}{?=QQQ}}16
{?="origin"{?="x"Q"y"Q"z"Q}"size"{?="width"Q"height"Q"depth"Q}}
v96@0:8@16@24@32@40@48@56@64@72@80@88
v32@0:8i16f20f24f28
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"MPSParallelRandomMTGP32State"
v32@0:8@16Q24
@60@0:8@16f24Q28{?=QQQ}36
@60@0:8@16f24@28{?=QQQ}36
@52@0:8@16@24@32@40B48
@"MPSParallelRandomMTGP32"
@52@0:8@16Q24Q32Q40B48
@44@0:8@16Q24Q32B40
v64@0:8@16@24@32@40@48@56
v28@0:8@16B24
q16@0:8
v24@0:8q16
@40@0:8@16i24f28f32f36
@28@0:8@16f24
@32@0:8@16f24f28
@"NSData"
@36@0:8@16f24f28f32
@"MPSNNNeuronDescriptor"
@48@0:8@16Q24Q32Q40
@80@0:8@16{MPSImageCoordinate=QQQ}24{MPSImageCoordinate=QQQ}48Q72
@"<MPSExternalMatrixFullyConnected>"
@"MPSCNNNormalizationGammaAndBetaState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
@"MPSCNNNormalizationMeanAndVarianceState"32@0:8@"<MTLCommandBuffer>"16@"MPSCNNBatchNormalizationState"24
B24@0:8@"MPSCNNBatchNormalizationState"16
@44@0:8@16@24^@32B40
v32@0:8@16B24B28
@"<MPSCNNBatchNormalizationDataSource>"
@52@0:8@16@24@32@40I48
@28@0:8@16I24
@44@0:8@16@24@32I40
@"MPSCNNConvolutionTranspose"
@"MPSCNNConvolutionGradientState"
@56@0:8@16@24r^f32r^f40Q48
@60@0:8@16@24r^f32r^f40Q48B56
@52@0:8@16@24@32^@40B48
@"MPSCNNConvolution"
@44@0:8@16@24@32B40
@56@0:8@16@24@32d40d48
@36@0:8f16f20Q24f32
@48@0:8f16f20B24f28f32Q36f44
@40@0:8@16f24B28@32
@44@0:8@16d24f32@36
@56@0:8@16d24f32d36B44@48
@60@0:8@16d24d32f40Q44@52
@"NSObject<OS_dispatch_semaphore>"
@48@0:8@16@24@32Q40
@"MPSImage"40@0:8@"<MTLCommandBuffer>"16@"MPSImageDescriptor"24@"MPSKernel"32
@"NSArray"48@0:8@"<MTLCommandBuffer>"16@"MPSImageDescriptor"24@"MPSKernel"32Q40
@40@0:8@16@24^B32
@32@0:8@16@?24
Q24@0:8Q16
{Graph="_graphSourceImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphSourceStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphIntermediateImages"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graphResultStates"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_graph"@"MPSNNGraph""_filters"{NodeList<FilterGraphNode *>="_items"^^{FilterGraphNode}"_count"Q"_storageSize"Q}"_images"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_states"{NodeList<ResourceGraphNode *>="_items"^^{ResourceGraphNode}"_count"Q"_storageSize"Q}"_cpuUpdateSem"@"NSObject<OS_dispatch_semaphore>""_graphNull"@"NSNull"}
@"<MPSImageAllocator>"
@24@0:8^v16
@"MPSNNLabelsNode"
@"MPSCNNLossDescriptor"
@"MPSCNNYOLOLossDescriptor"
@"<MPSNNLossCallback>"
@68@0:8@16@24@32@40@48@56B64
@56@0:8@16Q24{?=QQQ}32
@24@0:8I16i20
v20@0:8I16
@64@0:8@16{?=QQQ}24@48@56
@"MPSImage"
@"MPSCNNLossLabels"
@60@0:8@16@24@32@40^@48B56
@64@0:8@16@24@32@40@48@56
@"<MTLTexture>"
@"MPSCNNNeuron"
@"MPSCNNNormalizationGammaAndBetaState"32@0:8@"<MTLCommandBuffer>"16@"NSArray"24
B24@0:8@"NSArray"16
@"<MPSCNNGroupNormalizationDataSource>"
@40@0:8@16Q24@32
@"MPSCNNGroupNormalization"
{MPSNNDimensionOrder="dimensions"[4Q]}
v200@0:8@16@24@32@40@48{?=QQQ}56{?=QQQ}80{?={?=QQQ}{?=QQQ}}104{?={?=QQQ}{?=QQQ}}152
{MPSNNDimensionOrder=[4Q]}16@0:8
v48@0:8{MPSNNDimensionOrder=[4Q]}16
@"MPSNNPermute"
@"MPSNNFilterNode"
^{FilterGraphNode=}16@0:8
@"MPSNNImageNode"
@"<MPSNNPadding>"
@"NSString"
@"<MPSCNNInstanceNormalizationDataSource>"
@"MPSCNNInstanceNormalization"
@56@0:8@16Q24Q32Q40r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}48
r^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}16@0:8
^{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}
^{Region_params=}
@"MPSImageDescriptor"48@0:8@"NSArray"16@"NSArray"24@"MPSKernel"32@"MPSImageDescriptor"40
{MPSRegion={MPSOrigin=ddd}{MPSSize=ddd}}40@0:8{?=QQQ}16
v128@0:8@16@24@32@40@48@56Q64Q72{?={?=QQQ}{?=QQQ}}80
v80@0:8@16@24@32@40@48@56Q64Q72
v112@0:8@16@24@32@40@48@56{?={?=QQQ}{?=QQQ}}64
Q48@0:8@16@24@32@40
{?=qqq}16@0:8
v40@0:8{?=qqq}16
{?="x"q"y"q"z"q}
@"MPSExternalCNNBinary"
@44@0:8@16Q24f32@36
@"MPSCNNBatchNormalization"
@76@0:8@16@24@32f40Q44{?=QQQ}52
@32@0:8i16f20f24f28
@28@0:8i16f20f24
@24@0:8i16f20
@20@0:8i16
{NeuronInfo=ifff@}16@0:8
@40@0:8@16f24f28f32i36
@44@0:8@16r^f24Q32i40
v36@0:8i16r^f20Q28
@40@0:8@16@24r^f32
@40@0:8@16r^f24Q32
@56@0:8@16{MPSNNDimensionOrder=[4Q]}24
@"<MPSNNGramMatrixCallback>"
{MPSCNNGramFilters_s="i2mCopy"@"MPSImageCopyToMatrix""m2iCopy"@"MPSMatrixCopyToImage""gemm_TN"@"MPSMatrixMultiplication"}
{MPSCNNGramGradientFilters_s="fwdFilters"{MPSCNNGramFilters_s="i2mCopy"@"MPSImageCopyToMatrix""m2iCopy"@"MPSMatrixCopyToImage""gemm_TN"@"MPSMatrixMultiplication"}"gemm_NN"@"MPSMatrixMultiplication"}
@56@0:8@16{NeuronInfo=ifff@}24@48
{NeuronInfo="type"i"a"f"b"f"c"f"aData"@"NSData"}
v124@0:8@16@24@32@40@48Q56Q64{?={?=QQQ}{?=QQQ}}72B120
v72@0:8@16@24@32@40@48Q56Q64
v64@0:8@16@24@32@40Q48Q56
v104@0:8@16@24@32@40@48{?={?=QQQ}{?=QQQ}}56
@56@0:8@16@24Q32^{?=qqq}40^{?=qqq}48
16@0:8
@"MPSExternalCNNUnary"
@48@0:8Q16Q24Q32Q40
@80@0:8@16@24@32Q40Q48Q56Q64@72
@88@0:8@16@24@32Q40Q48Q56Q64Q72Q80
{?=qqq}24@0:8Q16
v48@0:8{?=qqq}16Q40
v32@0:8Q16Q24
@40@0:8@16@24Q32
^{NNKernelSourceParams={?=qqq}QQQQQQQQQ}
@"MPSNNReduceFeatureChannelsAndWeightsSum"
@"MPSNNReduceFeatureChannelsSum"
@56@0:8@16@24@32Q40Q48
@64@0:8@16@24r^f32r^f40Q48B56B60
@40@0:8@16@24B32B36
@52@0:8@16@24f32Q36Q44
@80@0:8@16@24r^f32r^f40r^f48r^f56Q64Q72
@44@0:8@16@24@32f40
B24@0:8r^{NeuronInfo=ifff@}16
@"NSObject"
{atomic<long>="__a_"{__cxx_atomic_impl<long, std::__cxx_atomic_base_impl<long>>="__a_value"Aq}}
@52@0:8I16I20I24I28i32@36Q44
f32@0:8@16@24
@"MPSCNNLoss"
@56@0:8Q16Q24Q32Q40@48
v28@0:8i16f20f24
v52@0:8r^f16r^f24r^f32r^f40f48
@40@0:8{NeuronInfo=ifff@}16
@72@0:8Q16Q24Q32Q40{?=qqq}48
@120@0:8Q16Q24Q32Q40Q48Q56Q64Q72Q80Q88Q96B104B108@112
B72@0:8@16I24I28r^v32r^f40i48r^52r^f60B68
B96@0:8@16@24r^v32I40I44r^48r^f56i64r^f68Q76B84B88I92
v48@0:8@16@24@32^@40
@36@0:8@16@24I32
@40@0:8@16@24I32I36
v56@0:8Q16Q24I32I36Q40Q48
@56@0:8@16Q24@32Q40@48
@64@0:8@16Q24I32I36@40Q48@56
v72@0:8@16@24@32@40@48@56Q64
v80@0:8@16@24@32@40@48@56@64Q72
{?="x"Q"y"Q"z"Q}
@"MPSCNNConvolutionGradient"
^{?=QQQ}
v60@0:8r^I16r^f24r^f32r^f40r^f48B56
@68@0:8@16@24r^I32r^f40f48Q52Q60
@88@0:8@16@24r^I32r^f40r^f48r^f56r^f64Q72Q80
@"MPSCNNPoolingAverage"
@60@0:8@16@24r^I32f40Q44Q52
@24@0:8@"<MTLDevice>"16
@"<MTLDevice>"16@0:8
Q96@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72@80Q88
Q96@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32Q40@"NSArray"48r^{?=QQ{?=qqq}{?=qqq}QQ}56@"NSArray"64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72@"<MTLBuffer>"80Q88
Q72@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64
Q80@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}72
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}QQQQ}40
Q48@0:8@16@24@32r^{?=QQQ^{?}I@{?=SSSSSS{?=SSSS}}I@{?=SSSS}{?={?=QQQ}{?=QQQ}}{?=qqq}QQ}40
Q112@0:8@16@24Q32Q40@48r^{?=QQ{?=qqq}{?=qqq}QQ}56@64r^{?=QQ{?=qqq}{?=qqq}QQ}72@80r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}88@96Q104
Q112@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32Q40@"NSArray"48r^{?=QQ{?=qqq}{?=qqq}QQ}56@"NSArray"64r^{?=QQ{?=qqq}{?=qqq}QQ}72@"NSArray"80r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}88@"<MTLBuffer>"96Q104
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQ{?=qqq}{?=qqq}QQ}64@72r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}80
Q48@0:8@16@24@32r^{?={MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{MPSStateInfo=@}{MPSImageInfo=@^{MPSPixelInfo}IQQ@Q}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}{?=qqq}QQQQQ}40
Q48@0:8@16@24@32r^{?=QQQ^{?}I@{?=SSSSSS{?=SSSS}}I@{?=SSSS}I@{?=SSSS}{?={?=QQQ}{?=QQQ}}{?=qqq}{?=qqq}QQQ}40
Q88@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80
Q104@0:8@16@24Q32@40r^{?=QQ{?=qqq}{?=qqq}QQ}48@56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80@88Q96
Q88@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"<MTLTexture>"40r^{?=QQ{?=qqq}{?=qqq}QQ}48@"<MTLTexture>"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80
Q104@0:8@"<MTLCommandBuffer>"16@"<MTLComputeCommandEncoder>"24Q32@"NSArray"40r^{?=QQ{?=qqq}{?=qqq}QQ}48@"NSArray"56r^{?=QQQ{?={?=QQQ}{?=QQQ}}Q}64Q72Q80@"<MTLBuffer>"88Q96
)\o?
L7i?
)\o?
L7i?
