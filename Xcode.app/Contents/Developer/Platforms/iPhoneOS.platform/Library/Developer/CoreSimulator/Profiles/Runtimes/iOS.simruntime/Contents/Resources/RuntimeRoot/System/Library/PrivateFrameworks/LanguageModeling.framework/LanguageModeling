N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
;N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
N13sentencepiece9character5ModelE
N13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
@?N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__121__basic_string_commonILb1EEE
N13sentencepiece14ModelInterfaceE
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
_N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
?ffffff
@333333
33s?
NSt3__110__function6__funcIZ16-[LMTrial start]E3$_0NS_9allocatorIS2_EEFvRKNS_12basic_stringIcNS_11char_traitsIcEENS3_IcEEEERKNS_8optionalIN2LM15TrialParametersEEEEEE
Z16-[LMTrial start]E3$_0
NSt3__110__function6__funcIZ50LMLanguageModelPerformMaintenanceWithEffectiveTimeE3$_0NS_9allocatorIS2_EEFvRN2LM11DynamicDataEEEE
NSt3__110__function6__baseIFvRN2LM11DynamicDataEEEE
Z50LMLanguageModelPerformMaintenanceWithEffectiveTimeE3$_0
N17language_modeling2v126ToucanLanguageModelSessionE
NSt3__110__function6__funcIZN17language_modeling2v1L24bestWordMatchFromLexiconERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE4$_16NSB_ISG_EEFvPK10__CFStringjdNS4_13SourceLexiconERbEEE
ZN17language_modeling2v1L24bestWordMatchFromLexiconERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEE4$_16
NSt3__110__function6__funcIZN17language_modeling2v126ToucanLanguageModelSession37combinedConditionalProbabilityBatchedERKNS_6vectorINS5_INS3_14SanitizedTokenENS_9allocatorIS6_EEEENS7_IS9_EEEERKNS3_17LinguisticContextEE3$_4NS7_ISH_EEFdmEEE
ZN17language_modeling2v126ToucanLanguageModelSession37combinedConditionalProbabilityBatchedERKNSt3__16vectorINS3_INS0_14SanitizedTokenENS2_9allocatorIS4_EEEENS5_IS7_EEEERKNS0_17LinguisticContextEE3$_4
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession31_combinedConditionalProbabilityERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEbRmbE3$_7NS_9allocatorISC_EEFdmEEE
ZNK17language_modeling2v126ToucanLanguageModelSession31_combinedConditionalProbabilityERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEbRmbE3$_7
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession18_staticPredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmRmE4$_11NSA_ISG_EEFvRKNS3_14SanitizedTokenERNS8_IjNSA_IjEEEEEEE
NSt3__110__function6__baseIFvRKN17language_modeling2v114SanitizedTokenERNS_6vectorIjNS_9allocatorIjEEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession18_staticPredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmRmE4$_11
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmmE3$_2NSA_ISF_EEFbRKNS3_10PredictionEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmmE3$_2
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmmE4$_12NSA_ISF_EEFbRKNS3_10PredictionEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmmE4$_12
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession22_normalizeStemsForBiasERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS6_EEEERKNS5_INS3_14SanitizedTokenENS7_ISC_EEEEE4$_14NS7_ISH_EEFSC_RKSC_RKNS_8optionalISC_EERSE_EEE
NSt3__110__function6__baseIFN17language_modeling2v114SanitizedTokenERKS4_RKNS_8optionalIS4_EERNS_6vectorIS4_NS_9allocatorIS4_EEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession22_normalizeStemsForBiasERKNSt3__16vectorINS0_14CompletionStemENS2_9allocatorIS4_EEEERKNS3_INS0_14SanitizedTokenENS5_ISA_EEEEE4$_14
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_fragmentIDsERNS3_21LinguisticContextImplEE4$_15NS_9allocatorIS7_EEFvRKNS3_14SanitizedTokenERNS_6vectorIjNS8_IjEEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_fragmentIDsERNS0_21LinguisticContextImplEE4$_15
NSt3__120__shared_ptr_emplaceIN2LM18MontrealClassModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN2LM21MontrealTokenIDMapperENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM21MontrealTokenIDMapperEEE
NSt3__120__shared_ptr_emplaceIN2LM21MontrealLanguageModelENS_9allocatorIS2_EEEE
N2LM22CompositeLanguageModelE
NSt3__123enable_shared_from_thisIN2LM22CompositeLanguageModelEEE
NSt3__120__shared_ptr_pointerIPN2LM10FSTGrammarENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM10FSTGrammarEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__110__function6__funcIZN2LML38enumerateSortkeyEquivalentsFromLexiconERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS2_7LexiconENS2_13SourceLexiconERKNS_8functionIFvPK10__CFStringjdSE_RbEEEE3$_2NS6_ISO_EEFvSI_jdSJ_EEE
NSt3__110__function6__baseIFvPK10__CFStringjdRbEEE
ZN2LML38enumerateSortkeyEquivalentsFromLexiconERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEERKNS_7LexiconENS_13SourceLexiconERKNS0_8functionIFvPK10__CFStringjdSC_RbEEEE3$_2
NSt3__120__shared_ptr_pointerIPN2LM22CompositeLanguageModelENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM22CompositeLanguageModelEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_pointerIPN2LM10ParametersENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM10ParametersEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_emplaceIN2LM22TokenClassDistributionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM22MontrealCompositeModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM10NgramModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM15StemSuffixModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN2LM14ResourceLoaderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM14ResourceLoaderEEE
N2LM10TokenIDMapINS_15AttributedTokenEEE
NSt3__110__function6__funcIZNK2LM22CompositeLanguageModel22conditionalProbabilityEjNS_4spanIKjLm18446744073709551615EEERNS2_18CompositeScoreInfoEPNS2_6LoggerEbbRKNS_8functionIFdmEEEE3$_0NS_9allocatorISG_EESC_EE
NSt3__110__function6__baseIFdmEEE
ZNK2LM22CompositeLanguageModel22conditionalProbabilityEjNSt3__14spanIKjLm18446744073709551615EEERNS_18CompositeScoreInfoEPNS_6LoggerEbbRKNS1_8functionIFdmEEEE3$_0
NSt3__110__function6__funcIZNK2LM22CompositeLanguageModel33enumerateSortkeyEquivalentEntriesERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8functionIFvPK10__CFStringjdRbEEEE3$_1NS7_ISL_EEFvSF_jdNS2_13SourceLexiconESG_EEE
ZNK2LM22CompositeLanguageModel33enumerateSortkeyEquivalentEntriesERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS1_8functionIFvPK10__CFStringjdRbEEEE3$_1
N2LM20LegacyDynamicLexiconE
N17language_modeling2v119ToucanLanguageModelE
N2LM11LexiconImplE
N2LM14LegacyMontrealE
NSt3__123enable_shared_from_thisIN2LM14LegacyMontrealEEE
NSt3__120__shared_ptr_pointerIPN2LM14LegacyMontrealENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM14LegacyMontrealEE27__shared_ptr_default_deleteIS2_S2_EE
N2LM29GermanGrammaticalityEvaluatorE
N2LM15LexiconDatabaseE
NSt3__120__shared_ptr_pointerIPN2LM11DynamicDataENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM11DynamicDataEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__120__shared_ptr_pointerIPN2LM28DynamicLanguageModelMetadataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM28DynamicLanguageModelMetadataEEE
NSt3__120__shared_ptr_pointerIPN2LM15NgramPoolFacadeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM15NgramPoolFacadeEEE
NSt3__120__shared_ptr_emplaceIN2LM21PrunableSharedLexiconENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM18DynamicLexiconImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM19NgramPoolFacadeImplENS_9allocatorIS2_EEEE
N2LM32BTriePositionInterpreterInternalE
N2LM23BTrieFatBaseInterpreterE
N2LM27BTrieCompactBaseInterpreterE
N2LM24BTrieFlatBaseInterpreterE
N2LM20BTrieNoOpInterpreterE
112141718191A1B1C1E1F1G1H1I1J1K1L1M1N1
O1P1Q1R1S1T1U1V1W1X1Y1Z1[1\1]1^1_1`1a1b1c1
1121314151617191:1;1<1=1>1?1@1A1B1D1E1F1G1H1J1K1L1M1N1
N2LM18JointLanguageModelE
NSt3__110__function6__funcIPFiP7__sFILEENS_9allocatorIS5_EES4_EE
NSt3__110__function6__baseIFiP7__sFILEEEE
PFiP7__sFILEE
FiP7__sFILEE
NSt3__120__shared_ptr_emplaceIN2LM19TrialParameterStoreENS_9allocatorIS2_EEEE
N3fst10MappedFileE
N2LM23MontrealInferenceEngineE
N2LM15InferenceEngineE
N2LM30RussianGrammaticalityEvaluatorE
N2LM17CoreLMPrefixCoderE
N2LM11CoreLMCoderINS_11PrefixCoderEEE
N2LM18SentencePieceCoderINS_11PrefixCoderEEE
N2LM11PrefixCoderE
N2LM14VocabularyImplE
N2LM26MontrealMultiTokenIDMapperE
N2LM31NeuralModelPredictionEnumeratorE
N2LM15StemSuffixModelE
N2LM30StemSuffixPredictionEnumeratorE
N2LM17LexiconCursorImplE
NSt3__110__function6__funcIZN2LM17LexiconCursorImplC1EPK9_LXCursorNS_8functionIFbPK8_LXEntryEEENS2_11TokenSourceEE3$_0NS_9allocatorISE_EEFbSA_SA_EEE
NSt3__110__function6__baseIFbPK8_LXEntryS4_EEE
ZN2LM17LexiconCursorImplC1EPK9_LXCursorNSt3__18functionIFbPK8_LXEntryEEENS_11TokenSourceEE3$_0
NSt3__110__function6__funcIZN2LM17LexiconCursorImplC1EPK9_LXCursorNS_8functionIFbPK8_LXEntryEEENS2_11TokenSourceEE3$_1NS_9allocatorISE_EEFbS6_S6_EEE
NSt3__110__function6__baseIFbPK9_LXCursorS4_EEE
ZN2LM17LexiconCursorImplC1EPK9_LXCursorNSt3__18functionIFbPK8_LXEntryEEENS_11TokenSourceEE3$_1
N2LM24ListBasedTokenEnumeratorE
N2LM19VariantEnumeratorV2E
N2LM17LemmaEnumeratorV1E
N2LM17LemmaEnumeratorV2E
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14MemoryPoolBaseE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst15MemoryArenaBaseE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
NSt3__15dequeIiNS_9allocatorIiEEEE
NSt3__112__deque_baseIiNS_9allocatorIiEEEE
NSt3__119__deque_base_commonILb1EEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_13PoolAllocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi2EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi2EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi4EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi4EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi8EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi8EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi16EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi16EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi32EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi32EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi64EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi64EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_IS6_EEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_IS7_EEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINSt3__111__list_nodeIiPvEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINSt3__111__list_nodeIiPvEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi2EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi2EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi4EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi4EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi8EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi8EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi16EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi16EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi32EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi32EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi64EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi64EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINSt3__111__hash_nodeIiPvEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINSt3__111__hash_nodeIiPvEEE2TNILi1EEEE4LinkEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IjEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IjEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
20LanguageModelWrapper
27PredictionEnumeratorWrapper
22StreamTokenizerWrapper
17VocabularyWrapper
22LanguageContextWrapper
30LanguageLikelihoodModelWrapper
N2LM27LanguageLikelihoodModelImplE
N17language_modeling2v120TokenIDLanguageModelE
N17language_modeling2v117LanguageModelImplE
NSt3__110__function6__funcIZN17language_modeling2v1L24blocklistContextTokenIDsERNS3_21LinguisticContextImplEjRKNS3_14TokenConverterENS3_9MatchTypeEE3$_0NS_9allocatorISA_EEFjRKNS3_14SanitizedTokenERKNS_6vectorIjNSB_IjEEEEEEE
ZN17language_modeling2v1L24blocklistContextTokenIDsERNS0_21LinguisticContextImplEjRKNS0_14TokenConverterENS0_9MatchTypeEE3$_0
N2LM26CompositeVariantEnumeratorE
N3fst11SymbolTableE
N2LM23SQLiteDatabaseExceptionE
N17language_modeling2v123BlocklistTokenConverterE
StaticTokenIDCacheSize
NSt3__110__function6__funcIZN17language_modeling2v1L52bestLinguisticallyEquivalentTokenIDFromStaticLexiconERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_3NSB_ISG_EEFvPK10__CFStringjdNS4_13SourceLexiconERbEEE
ZN17language_modeling2v1L52bestLinguisticallyEquivalentTokenIDFromStaticLexiconERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEE3$_3
NSt3__110__function6__funcIZNK17language_modeling2v123BlocklistTokenConverter7convertERNS3_13TokenSequenceEE3$_1NS_9allocatorIS7_EEFbjEEE
ZNK17language_modeling2v123BlocklistTokenConverter7convertERNS0_13TokenSequenceEE3$_1
NSt3__110__function6__funcIZNK17language_modeling2v123BlocklistTokenConverter7convertERNS3_13TokenSequenceEE3$_2NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEEEEE
ZNK17language_modeling2v123BlocklistTokenConverter7convertERNS0_13TokenSequenceEE3$_2
 NSt3__110__function6__funcIZNK17language_modeling2v115StringTokenizer8tokenizeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERNS3_13TokenSequenceEE3$_0NS8_ISF_EEFbjEEE
ZNK17language_modeling2v115StringTokenizer8tokenizeERKNSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEERNS0_13TokenSequenceEE3$_0
N2LM19BeamSearchPredictorE
N2LM22NeuralNetworkPredictorE
N2LM20MecabraLexiconCursorE
N2LM26MecabraStaticLexiconCursorE
N2LM20RecencyLanguageModelE
N2LM22MontrealCompositeModelE
NSt3__120__shared_ptr_pointerIPN2LM13LexiconCursorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM13LexiconCursorEEE
N2LM22TransientLanguageModelE
N2LM29TransientPredictionEnumeratorE
NSt3__120__shared_ptr_pointerIPN2LM16TransientLexiconENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM16TransientLexiconEEE
NSt3__110__function6__funcIZNK2LM22TransientLanguageModel26insertPredictionsForPrefixEPK10__CFStringlRNS_14priority_queueINS2_13TransientItemENS_6vectorIS8_NS_9allocatorIS8_EEEENS2_17TransientItemLessEEE13LMLexiconTypeE3$_0NSA_ISH_EEFvS6_dEEE
NSt3__110__function6__baseIFvPK10__CFStringdEEE
ZNK2LM22TransientLanguageModel26insertPredictionsForPrefixEPK10__CFStringlRNSt3__114priority_queueINS_13TransientItemENS4_6vectorIS6_NS4_9allocatorIS6_EEEENS_17TransientItemLessEEE13LMLexiconTypeE3$_0
N2LM26NeuralLanguageModelAdapterE
N2LM19LegacyMontrealStateE
N2LM15SharedNgramPoolE
N2LM16StringTokenIDMapE
xNUMBx
xLINKx
xTERMx
xPAUSEx
xHASHx
xUSERx
xRCHRx
xSINGNUMBx
xPLRNUMBx
N2LM29CompositeCompletionEnumeratorE
NSt3__120__shared_ptr_emplaceIN2LM15TuriTrialClientENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZZN2LM13TrialServices5startERKNS_10shared_ptrINS2_11TrialClientEEERKNS4_IKNS2_19TrialParameterStoreEEERKNS_8functionIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8optionalINS2_15TrialParametersEEEEEEENK3$_0clEvEUlSM_SR_E_NSI_ISX_EESS_EE
NSt3__110__function6__baseIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8optionalIN2LM15TrialParametersEEEEEE
ZZN2LM13TrialServices5startERKNSt3__110shared_ptrINS_11TrialClientEEERKNS2_IKNS_19TrialParameterStoreEEERKNS1_8functionIFvRKNS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS1_8optionalINS_15TrialParametersEEEEEEENK3$_0clEvEUlSK_SP_E_
23NoopNgramPoolEnumerator
N2LM19NgramPoolEnumeratorE
20PredictionEnumeratorI14word_unigram_tE
20PredictionEnumeratorI13word_bigram_tE
20PredictionEnumeratorI12word_ngram_tE
20PredictionEnumeratorI15word_ngram_v4_tE
N2LM27LexiconCompletionEnumeratorE
N2LM17StaticLexiconTrieE
N2LM11LexiconTrieE
N2LM18MutableLexiconTrieE
N17language_modeling2v124LinguisticTokenConverterE
N17language_modeling2v114TokenConverterE
NSt3__110__function6__funcIZNK17language_modeling2v124LinguisticTokenConverter7convertERNS3_13TokenSequenceEE3$_3NS_9allocatorIS7_EEFbjEEE
ZNK17language_modeling2v124LinguisticTokenConverter7convertERNS0_13TokenSequenceEE3$_3
NSt3__110__function6__funcIZNK17language_modeling2v124LinguisticTokenConverter7convertERNS3_13TokenSequenceEE3$_2NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEENS_4spanIKjLm18446744073709551615EEEEEE
ZNK17language_modeling2v124LinguisticTokenConverter7convertERNS0_13TokenSequenceEE3$_2
NSt3__110__function6__funcIZN17language_modeling2v1L23getConversionCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERN2LM22CompositeLanguageModelERT_EUlPK10__CFStringjdNSI_13SourceLexiconERbE_NS8_ISS_EEFvSP_jdSQ_SR_EEE
ZN17language_modeling2v1L23getConversionCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNS2_12basic_stringIcNS2_11char_traitsIcEENS6_IcEEEERN2LM22CompositeLanguageModelERT_EUlPK10__CFStringjdNSG_13SourceLexiconERbE_
NSt3__110__function6__funcIZN17language_modeling2v1L14trimCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNT_10value_typeERSB_PK10__CFLocaleEUlRKSB_E_NS8_ISL_EEFbRKS7_EEE
NSt3__110__function6__baseIFbRKN17language_modeling2v124LinguisticTokenConverter19ConversionCandidateEEEE
ZN17language_modeling2v1L14trimCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNT_10value_typeERS9_PK10__CFLocaleEUlRKS9_E_
NSt3__110__function6__funcIZN17language_modeling2v1L14trimCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNT_10value_typeERSB_PK10__CFLocaleEUlRKSB_E0_NS8_ISL_EEFbRKS7_EEE
ZN17language_modeling2v1L14trimCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNT_10value_typeERS9_PK10__CFLocaleEUlRKS9_E0_
N2LM25PredictionCacheEnumeratorE
N2LM28MontrealDefaultTokenIDMapperE
N2LM24CompositeLemmaEnumeratorE
N2LM15TokenEnumeratorE
N2LM21StemSuffixIDConverterE
N2LM33FragmentModelPredictionEnumeratorE
N2LM29MontrealFragmentTokenIDMapperE
NSt3__120__shared_ptr_emplaceIN2LM14FSTNetworkImplENS_9allocatorIS2_EEEE
N2LM20MecabraStaticLexiconE
N2LM14MecabraLexiconE
N2LM30MecabraFileMappedStaticLexiconE
N2LM28MecabraInMemoryStaticLexiconE
N2LM29CompositePredictionEnumeratorE
N2LM18CacheLanguageModelE
N2LM17AbstractBlocklistE
N2LM16TransientLexiconE
N2LM14NgramBlocklistE
N2LM21MontrealLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM17CoreLMPrefixCoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM26HypothesisPrefixTerminatorENS_9allocatorIS2_EEEE
N2LM26HypothesisPrefixTerminatorE
N2LM20HypothesisTerminatorE
NSt3__120__shared_ptr_emplaceIN2LM17CoreLMSuffixCoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM26HypothesisSuffixTerminatorENS_9allocatorIS2_EEEE
N2LM26HypothesisSuffixTerminatorE
NSt3__120__shared_ptr_pointerIPN2LM19NeuralLanguageModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM19NeuralLanguageModelEEE
NSt3__120__shared_ptr_emplaceIN2LM19BeamSearchPredictorENS_9allocatorIS2_EEEE
N2LM20MontrealNetworkStateE
N2LM18NeuralNetworkStateE
N2LM33LanguageLikelihoodModelDispatcherE
N2LM23LanguageLikelihoodModelE
N2LM15TuriTrialClientE
N2LM11TrialClientE
NSt3__120__shared_ptr_emplaceIN2LM15TuriTrialClient13ClientWrapperENS_9allocatorIS3_EEEE
N2LM20VocabularyDispatcherE
N2LM10VocabularyE
N2LM25TokenIDBlocklistDecoratorE
N2LM9BlocklistE
N2LM15LXLexiconCursorE
N2LM13LexiconCursorE
N2LM22CompositeLexiconCursorE
N2LM28StemSuffixLexiconIDConverterE
N2LM16TokenIDConverterE
N2LM30TurkishGrammaticalityEvaluatorE
N2LM8CFLoggerE
N2LM6LoggerE
N2LM18StringBufferLoggerE
NSt3__110__function6__funcIZN2LM22LexiconStringConverter22getDefaultConverterFcnEvE3$_0NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
NSt3__110__function6__baseIFN3nlp11CFScopedPtrIPK10__CFStringEES6_EEE
ZN2LM22LexiconStringConverter22getDefaultConverterFcnEvE3$_0
NSt3__120__shared_ptr_emplaceIN6Hangul15StringConverterENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_1NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
ZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_1
NSt3__110__function6__funcIZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_2NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
ZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_2
N2LM17BaseLanguageModelE
N2LM19NeuralLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM23MontrealInferenceEngineENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM21CoreLMInferenceEngineENS_9allocatorIS2_EEEE
NeuralNetworkForwardPassLimit
NSt3__110__function6__funcIZN2LML23assembleMonolithicCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISH_EEFNS4_INS5_IDhEENS8_ISK_EEEEvEEE
NSt3__110__function6__baseIFNS_10unique_ptrIN2LM18MontrealStateCacheIDhEENS_14default_deleteIS5_EEEEvEEE
NSt3__110__function6__funcIZZN2LML23assembleMonolithicCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISI_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISM_EEEEvEEE
NSt3__110__function6__baseIFNS_10unique_ptrIN2LM18MontrealCacheEntryIDhEENS_14default_deleteIS5_EEEEvEEE
N2LM14FullCacheEntryIDhEE
N2LM18MontrealCacheEntryIDhEE
ZZN2LML23assembleMonolithicCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
N2LM13LRUStateCacheIDhEE
N2LM17LRUStateBaseCacheIDhEE
N2LM18MontrealStateCacheIDhEE
ZN2LML23assembleMonolithicCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEEUlvE_
N2LM18LazyCacheDecoratorIDhEE
NSt3__110__function6__funcIZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISM_EEFNS4_INS5_IDhEENS8_ISP_EEEEvEEE
NSt3__110__function6__funcIZZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISN_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISR_EEEEvEEE
ZZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
NSt3__110__function6__funcIZZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE0_NS_9allocatorISN_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISR_EEEEvEEE
N2LM16SparseCacheEntryIDhEE
ZZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE0_
N2LM20SegregatedStateCacheIDhEE
ZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEEUlvE_
NSt3__110__function6__funcIZN2LML24assembleIncrementalCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISH_EEFNS4_INS5_IDhEENS8_ISK_EEEEvEEE
NSt3__110__function6__funcIZZN2LML24assembleIncrementalCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISI_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISM_EEEEvEEE
ZZN2LML24assembleIncrementalCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
N2LM24LRUIncrementalStateCacheIDhEE
ZN2LML24assembleIncrementalCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEEUlvE_
N2LM17CoreLMSuffixCoderE
N2LM11CoreLMCoderINS_11SuffixCoderEEE
N2LM18SentencePieceCoderINS_11SuffixCoderEEE
N2LM11SuffixCoderE
N2LM18NeuralNetworkCoderE
N5boost9algorithm6detail13first_finderFIPKcNS0_8is_equalEEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N2LM10MorphologyE
N2LM10NgramModelE
N2LM13LanguageModelE
N2LM30NgramModelPredictionEnumeratorE
N2LM21CoreLMInferenceEngineE
N2LM14BlocklistIDMapE
N2LM5BiMapIjjEE
N2LM28PredictionOverrideEnumeratorE
N2LM18DynamicLexiconImplE
N2LM21PrunableSharedLexiconE
N2LM14DynamicLexiconE
NSt3__110__function6__funcIZN2LM12LexiconUtils19makeTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS2_11TokenSourceEE3$_0NS_9allocatorISB_EEFbPK8_LXEntryEEE
ZN2LM12LexiconUtils19makeTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS_11TokenSourceEE3$_0
NSt3__110__function6__funcIZN2LM12LexiconUtils25makePoliteTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS2_11TokenSourceEE3$_1NS_9allocatorISB_EEFbPK8_LXEntryEEE
ZN2LM12LexiconUtils25makePoliteTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS_11TokenSourceEE3$_1
N2LM16CompositeLexiconE
N2LM10RefCountedINS_16CompositeLexiconEEE
N2LM7LexiconE
NSt3__120__shared_ptr_emplaceIN2LM8ResourceENS_9allocatorIS2_EEEE
N2LM19NgramPoolFacadeImplE
N2LM15NgramPoolFacadeE
N2LM8ObserverINS_10ParametersEEE
NSt3__110__function6__funcINS_6__bindIMN2LM10ParametersEKFfjjEJPKS4_RKNS_12placeholders4__phILi1EEERKNSA_ILi2EEEEEENS_9allocatorISH_EEFfjjEEE
NSt3__110__function6__baseIFfjjEEE
NSt3__16__bindIMN2LM10ParametersEKFfjjEJPKS2_RKNS_12placeholders4__phILi1EEERKNS8_ILi2EEEEEE
NSt3__118__weak_result_typeIMN2LM10ParametersEKFfjjEEE
N2LM23LexiconFrameworkAdaptorE
N2LM14LexiconAdaptorE
N2LM21MecabraLexiconAdaptorE
NSt3__110__function6__funcIZNK2LM23LexiconFrameworkAdaptor19makeTokenEnumeratorEPK10__CFStringE3$_0NS_9allocatorIS7_EEFbPK8_LXEntryEEE
NSt3__110__function6__baseIFbPK8_LXEntryEEE
ZNK2LM23LexiconFrameworkAdaptor19makeTokenEnumeratorEPK10__CFStringE3$_0
N2LM14FSTNetworkImplE
N2LM10FSTNetworkE
N2LM10TokenIDMapINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
NSt3__110__function6__funcIZN17language_modeling2v113TokenSequence14updateTokenIDsERKNS_8functionIFbjEEERKNS5_IFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEEEUlSH_NS_4spanIKjLm18446744073709551615EEEE_NSD_ISP_EEFjSH_SO_EEE
NSt3__110__function6__baseIFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_4spanIKjLm18446744073709551615EEEEEE
ZN17language_modeling2v113TokenSequence14updateTokenIDsERKNSt3__18functionIFbjEEERKNS3_IFjRKNS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEEEEUlSF_NS2_4spanIKjLm18446744073709551615EEEE_
NSt3__110__function6__funcIZN17language_modeling2v112TokenLearner17learnFromSequenceERNS3_13TokenSequenceEE3$_0NS_9allocatorIS7_EEFbjEEE
NSt3__110__function6__baseIFbjEEE
ZN17language_modeling2v112TokenLearner17learnFromSequenceERNS0_13TokenSequenceEE3$_0
NSt3__110__function6__funcIZN17language_modeling2v112TokenLearner17learnFromSequenceERNS3_13TokenSequenceEE3$_1NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEEEEE
NSt3__110__function6__baseIFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN17language_modeling2v112TokenLearner17learnFromSequenceERNS0_13TokenSequenceEE3$_1
N2LM20DynamicLanguageModelE
N2LM40DynamicLanguageModelPredictionEnumeratorE
N2LM20PredictionEnumeratorE
NSt3__110__function6__funcINS_6__bindIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS3_15NgramPredictionEEJPS4_RKNS_12placeholders4__phILi1EEEEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN2LM15NgramPredictionEEEE
NSt3__16__bindIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS1_15NgramPredictionEEJPS2_RKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS1_15NgramPredictionEEEE
NSt3__115binary_functionIPKN2LM40DynamicLanguageModelPredictionEnumeratorERKNS1_15NgramPredictionEbEE
N2LM6CFTypeE
N2LM30RomanceGrammaticalityEvaluatorE
N2LM23GrammaticalityEvaluatorE
NSt3__110__function6__funcIZN17language_modeling2v147enumerateLinguisticallyEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_22TokenEnumerationPolicyERKNS_8functionIFvPK10__CFStringjdNS4_13SourceLexiconERbEEEE3$_0NSB_ISR_EESN_EE
NSt3__110__function6__baseIFvPK10__CFStringjdN2LM13SourceLexiconERbEEE
ZN17language_modeling2v147enumerateLinguisticallyEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS1_22TokenEnumerationPolicyERKNS5_8functionIFvPK10__CFStringjdNS1_13SourceLexiconERbEEEE3$_0
NSt3__110__function6__funcIZN17language_modeling2v149enumerateCaseAndDiacriticEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_22TokenEnumerationPolicyERKNS_8functionIFvPK10__CFStringjdNS4_13SourceLexiconERbEEEE3$_1NSB_ISR_EESN_EE
ZN17language_modeling2v149enumerateCaseAndDiacriticEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS1_22TokenEnumerationPolicyERKNS5_8functionIFvPK10__CFStringjdNS1_13SourceLexiconERbEEEE3$_1
N2LM15ClassNgramModelE
N2LM17CoreLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM23ToucanTokenIDMapperStubENS_9allocatorIS2_EEEE
N2LM23ToucanTokenIDMapperStubE
N2LM21MontrealTokenIDMapperE
N17language_modeling2v127TokenIDLanguageModelSessionE
N17language_modeling2v124LanguageModelSessionImplE
N3nlp25ResourceCreationExceptionE
AdaptationContextCacheSize
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession30combinedConditionalProbabilityERKNS3_14SanitizedTokenERKNS3_17LinguisticContextERN2LM18CompositeScoreInfoEbRKNS_8functionIFdmEEEE3$_7NS_9allocatorISJ_EEFjS7_RKNS_6vectorIjNSK_IjEEEEEEE
NSt3__110__function6__baseIFjRKN17language_modeling2v114SanitizedTokenERKNS_6vectorIjNS_9allocatorIjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession30combinedConditionalProbabilityERKNS0_14SanitizedTokenERKNS0_17LinguisticContextERN2LM18CompositeScoreInfoEbRKNSt3__18functionIFdmEEEE3$_7
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession11predictionsERKNS3_17LinguisticContextEmN2LM29CompositePredictionEnumerator16PredictionSubsetEE3$_1NS_9allocatorISB_EEFbRKNS3_10PredictionEEEE
NSt3__110__function6__baseIFbRKN17language_modeling2v110PredictionEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession11predictionsERKNS0_17LinguisticContextEmN2LM29CompositePredictionEnumerator16PredictionSubsetEE3$_1
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession21_enumeratePredictionsERNS3_21LinguisticContextImplEmN2LM29CompositePredictionEnumerator16PredictionSubsetElRKNS_8functionIFbRKNS3_10PredictionEEEEE3$_8NS_9allocatorISI_EEFjRKNS3_14SanitizedTokenERKNS_6vectorIjNSJ_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession21_enumeratePredictionsERNS0_21LinguisticContextImplEmN2LM29CompositePredictionEnumerator16PredictionSubsetElRKNSt3__18functionIFbRKNS0_10PredictionEEEEE3$_8
NSt3__117bad_function_callE
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS_8functionIFbRKNS3_10PredictionEEEEE3$_9NSA_ISQ_EEFjRKNS3_14SanitizedTokenERKNS8_IjNSA_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS5_8functionIFbRKNS0_10PredictionEEEEE3$_9
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS_8functionIFbRKNS3_10PredictionEEEEE4$_10NSA_ISQ_EEFjRKNS3_14SanitizedTokenERKNS8_IjNSA_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS5_8functionIFbRKNS0_10PredictionEEEEE4$_10
PredictionCandidateCount
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession12adaptToTokenERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEE4$_12NS_9allocatorISB_EEFjS7_RKNS_6vectorIjNSC_IjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession12adaptToTokenERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEE4$_12
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession14unAdaptToTokenERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEE4$_13NS_9allocatorISB_EEFjS7_RKNS_6vectorIjNSC_IjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession14unAdaptToTokenERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEE4$_13
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/dev/urandom
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
 000000000000
com.apple.NLPUtils
TMPDIR
/tmp
/nlptemp-XXXXXX
File at URL is not readable
File at URL is not a valid property list
Property list at URL is not a dictionary
%@: %@
com.apple.NLPUtils.ErrorDomain
LMTrialParametersDidChangeNotification
Cannot provide split
static (word)
static (sp)
static (unknown)
dynamic-lm
transient + supplemental
penalty
convertAbsoluteTime
convertTimePoint
createWithEncodedRepresentation
TrialParameters.mm
dict
B90D4859-A11E-4A91-A804-CFABD2A099BF
a required parameter was NULL
LMLanguageModelPreheatContexts
LMLanguageModel.cpp
false && "NULL language model reference"
try_push_back
probability
Probability.cpp
locale
getLocaleIdentifierFromOptions
LanguageModeling_Vocabulary.cpp
false && "Invalid CFType for kLMVocabularyLocaleKey"
adaptToToken
canReasonAbout
detailedConditionalProbability
recordWordRevision
clearPriorText
clearDynamicLearningCache
flushCacheAndRecencyData
supportsPrefixCompletions
supportsFragmentsBasedConditionalProbability
Lexicon creation failed: %s
Lexicon id converter creation failed: %s
Unigrams
lstsfmap%@
sessionType
appIdentifier
recipientIdentifier
namedEntityWordLexicon
namedEntityPhraseLexicon
supplementalWordLexicon
supplementalPhraseLexicon
testingParametersGeometryModelBundlePath
LanguageModelForConditionalProbability
LanguageModelForCompletionsAndPredictions
LanguageModelForConditionalProbabilityUserSetting
UseForConditionalProbability
UseForCompletionsAndPredictions
SupportsConditionalProbability
SupportsCompletionsAndPredictions
TokenIDLanguageModel
ToucanLanguageModelOnCPU
wordSeparator
makeSession
blocklistStatus
flushDynamicData
clearDynamicDataForTesting
wireMemory
unwireMemory
deallocateInternalBuffers
Success
_staticPredictions
ToucanLanguageModelSession.cpp
stems.size() > 0
_U_NT52
ToucanAutoCorrection
isPredictionResultingInLoop
index > 0
_U_NT51
_U_NT56
_U_NT54
_U_NT55
string_view::substr
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
convertAssetBundleType
LMLinguisticData.cpp
false && "unsupported LinguisticData asset type"
Failed to create LanguageLikelihoodModel database
DROP TABLE IF EXISTS LangMatrix
DROP TABLE IF EXISTS RecipientByLangMatrix
DROP TABLE IF EXISTS OfflineAdaptationTimeByApp
DROP TABLE IF EXISTS MetaData
DROP TABLE IF EXISTS EmojiByApp
CREATE TABLE RecipientByLangMatrix (RecipientId TEXT, Language TEXT, CharCount, PRIMARY KEY(RecipientId, Language))
CREATE TABLE OfflineAdaptationTimeByApp (ApplicationId TEXT PRIMARY KEY, Time DOUBLE)
CREATE TABLE MetaData (MetaData TEXT PRIMARY KEY, Value TEXT)
CREATE TABLE EmojiByApp (ApplicationId TEXT PRIMARY KEY, Count INT, Time DOUBLE)
INSERT INTO MetaData VALUES (?,?)
Version
DELETE FROM RecipientByLangMatrix
DELETE FROM EmojiByApp
DELETE FROM OfflineAdaptationTimeByApp
INSERT INTO RecipientByLangMatrix VALUES (?,?,?)
INSERT INTO OfflineAdaptationTimeByApp VALUES (?,?)
INSERT INTO EmojiByApp VALUES (?,?,?)
Serialization of languagelikelihood.dat model failed: %s
SELECT * FROM MetaData
SELECT * FROM RecipientByLangMatrix
SELECT * FROM EmojiByApp
SELECT * FROM OfflineAdaptationTimeByApp
Deserialization of languagelikelihood.dat model failed: %s
-wal
-shm
failed to remove dynamic languagelikelihood model
SQLite database corrupted
SQLite database open failure
SQLite database save failure
SQLite database initialization failure
SQLite database statement preparation failure
LinguisticContextImpl.cpp
cache.size() <= m_tokens.size()
m_fragmentCaches.size() == m_cumulativeFragmentCounts.size()
counts.size() <= m_tokens.size()
remove_first
count <= m_tokens.size()
operator()
fragmentCount > fragmentsToRemove
maxent.cpp
conditional_probability
prod != 0
max_label >= 0
error: cannot open 
classify
_num_classes == (int)membp.size()
Feature
maxent.h
id >= 0 && id < (int)id2mef.size()
ME_Feature
l >= 0 && l <= MAX_LABEL_TYPES
f >= 0 && f <= 0xffffff
id >= 0 && id < (int)id2str.size()
invalid language model creation options
initialize_block_invoke
LMCompositeLanguageModel.cpp
v24@?0r^v8^B16
No static lexicons to associate with FST grammar
<missing>
Resource initialization failed: %s
loadDynamicData
!m_dynamicData
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}12@?0I8
addLexicon
false && "Unknown external lexicon type"
removeLexicon
locale=
, adaptation=
enabled
disabled
, montreal=
CompositeLanguageModel
extractMaxDynamicPredictions
false && "Malformed resource bundle: duplicate MaxDynamicPredictions keys."
MaxDynamicPredictions
Could not find item
Could not convert
dynamicids resource file is incompatible (version %d, expected version %d)
dynamicRangeMin
dynamicRangeMax
dynamicLimitsMin
dynamicLimitsMax
dynamicids resource file is incompatible with the parameters the client has set (dynamicIDLimits [%d, %d], expected dynamicIDLimits [%d, %d])
Dynamic Lexicon Trie initialization failed: %s (%s)
Probation lexicon initialization failed: %s (%s)
Dynamic Lexicon initialization failed: %s
Inconsistency in dynamic word id ranges: %d, expected max (%d)
Inconsistency in dynamic word id ranges: %d, expected min (%d)
Unexpected dynamic word id ranges: (dynamicIDRanges [%d, %d], dynamicIDLimits [%d, %d])
LMLegacyDynamicLexicon.cpp
false && "add() is not supported in LegacyDynamicLexicon()"
remove
false && "remove() is not supported in LegacyDynamicLexicon()"
clear
false && "clear() is not supported in LegacyDynamicLexicon"
false && "enumerateSortkeyEquivalentEntries() is not supported in LegacyDynamicLexicon"
false && "createLXCursorRoot() is not supported in LegacyDynamicLexicon"
flushData
false && "flushData() is not supported in LegacyDynamicLexicon"
writeDebugDump
false && "writeDebugDump() is not supported in LegacyDynamicLexicon"
false && "prune() is not supported in LegacyDynamicLexicon"
false && "createPrunedCopy() is not supported in LegacyDynamicLexicon"
incrementUsageCount
false && "incrementUsageCount() is not supported in LegacyDynamicLexicon"
false && "incrementPenaltyCount() is not supported in LegacyDynamicLexicon"
false && "getPenaltyCount() is not supported in LegacyDynamicLexicon"
false && "getUsageCount() is not supported in LegacyDynamicLexicon"
false && "blocklistToken() is not supported in LegacyDynamicLexicon"
false && "incrementUsageCountForRecentToken() is not supported in LegacyDynamicLexicon"
reviewProbationaryEntries
false && "reviewProbationaryEntries() is not supported in LegacyDynamicLexicon"
addOrUpdateTokenWithAttributes
false && "addOrUpdateTokenWithAttributes() is not supported in LegacyDynamicLexicon"
updateAttributesForToken
false && "updateAttributesForToken() is not supported in LegacyDynamicLexicon"
copyTokenAttributes
false && "copyTokenAttributes() is not supported in LegacyDynamicLexicon"
getIntegerAttributeValue
false && "getIntegerAttributeValue() is not supported in LegacyDynamicLexicon"
copyStringAttributeValue
false && "copyStringAttributeValue() is not supported in LegacyDynamicLexicon"
default
determineModelType
ToucanLanguageModel
Associating Toucan LM with Trial experiment:
Failed to create the lexicon: 
Failed to soft-link Montreal: 
MRLModelCreate returned nullptr
unknown error
Failed to create an instance of LegacyMontreal: 
LegacyMontreal.cpp
kMRLModelFileLocationKey
MRLModelCreate
MRLModelGetOutputSize
MRLModelRelease
MRLModelRecognizeIncremental
MRLModelRecognizeIncrementalClassPlusSuffixIds
MRLModelStateCreate
MRLModelStateSave
MRLModelStateRelease
MRLModelLock
MRLModelUnlock
MRLModelReset
Failed to create lexicon database
LMLexiconDatabase.cpp
false && "enumerateSortKeyEquivalentEntries is not supported in LexiconDatabase"
false && "createLXCursorRoot is not supported in LexiconDatabase"
binding attributes failed: %s
binding attributes failed: missing or incompatible token string
Copy token attributes failed: %s
Get integer attribute value failed: %s
Copy String attribute value failed: %s
Unable to serialize lexicon database: %s
failed to remove lexicon database
prune
failed to prune lexicon database
false && "incrementPenaltyCount() is not supported in LexiconDatabase"
false && "getPenaltyCount() is not supported in LexiconDatabase"
false && "getUsageCount() is not supported in LexiconDatabase"
false && "blocklistToken() is not supported in LexiconDatabase"
incrementUsageCountForRecentToken
false && "incrementUsageCountForRecentToken() is not supported in LexiconDatabase"
PRAGMA journal_mode = WAL;
Words
Failed to close database, error code: %d  error message: %s
:memory:
main
BEGIN IMMEDIATE
Could not begin transaction, error %d
COMMIT
Could not commit transaction, error %d
ROLLBACK
Could not execute SQL "%s", error message: %s
v20@?0I8^B12
failed to initialize exemplar set for %s (error code %d)
MaintenanceNotification
didPerformPruning
^v8@?0
v16@?0^v8
dynamic.lm
v24@?0r*8^B16
/langlikelihood.dat
B12@?0i8
lexicon.plist
model.txt
cache.txt
recency.txt
DynamicData
v32@?0{span<const unsigned int, 18446744073709551615UL>=^IQ}8I24f28
com.apple.NLPUtils.SingletonResourceManager
dynamic resource serialization failed: %@
Locale is missing from ResourceLoader options
ResourceLoader
invalid type for bundle name
resources
LMResourceLoader.cpp
resourceContainer->has_key(kResourcesKey)
mismatched lexicon compatibility versions
v24@?0^{__CFDictionary=}8^B16
Failed to load bundle: %s
%@-dynamic.lm
%@_%@-dynamic.lm
Resources
Priority
UseExistingModelFiles
hi-Latn
Locale
Language
Alternate locales
appendTrialBundles
%d.%d
Malformed language model configuration: mismatched lemmatized blocklist resources
Malformed language model configuration: too many lemmatized blocklist resources
qualifiers
type
subtype
field
request
person
location
event
navigation
health
self
recipient
3rd person
current location
recent location
recent address
FaceTime
xSURNAMEx
xFULLNAMEx
xMEDIANAMEx
xPHONEx
xMOBILEPHONEx
xHOMEPHONEx
xWORKPHONEx
xFAXNUMBERx
xEMAILx
xADDRESSx
xHOMEADDRESSx
xWORKADDRESSx
xHOMECITYx
xWORKCITYx
xPOSTALCODEx
xCOMPANYx
xBIRTHDAYx
xFACETIMEx
xNEXTEVENTNAMEx
xNEXTTIMEAVAILABLEx
xDURATIONOFAVAILABILITYx
xLASTEVENTOFDAYx
xTIMEOFMEETINGx
xLOCATIONOFMEETINGx
xLOCATIONx
xDISTANCEAWAYx
xETAx
xETASPECIFICx
xETAINTERVALx
xNAMEOFDESTINATIONx
xNAMEOFSTREETx
xSOCIALMEDIAx
xACTIVEENERGYx
xCYCLINGDISTANCEx
xEXERCISEMINUTESx
xPUSHESx
xROLLHOURSx
xSLEEPANALYSISx
xSTANDHOURSx
xSTEPSx
xSWIMMINGDISTANCEx
xWALKINGRUNNINGDISTANCEx
xWEIGHTx
xWHEELCHAIRDISTANCEx
xWORKOUTSx
xABSOLUTEURLx
v28@?0I8Q12^B20
LINGUISTIC_DATA
/System/Library/LinguisticData/
/usr/share/mecabra/%@
%@/%@
true
dynamic resource serialization failed: %d (%s)
%s/%s
Library/LanguageModeling
Extracting archive 
 failed with status=
xTERMx
Provided parameter store path is invalid: 
TrialParameterCache.plist
Failed to get path for trial parameter cache from URL: 
(null)
LanguageModelBundlePath
ExperimentParameters
getStoreDictionary
CacheVersion
extractParameterDictionary
failed to unmap region: 
Mapping of file failed: 
File mapping at offset 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
unexpected key type in schema
Type
unexpected value type in schema for attribute %s and key %s
Integer
String
unsupported type for key %s (supported types are String and Integer)
Unique
IsTokenString
DefaultValue
unexpected value type in schema for key
schema should only specify one token string key
schema must specify a token string key
copyCurrentIncrementalState
MontrealInferenceEngine.cpp
m_architecture == NNModelArchitecture::Transformer
position
temperature
segment
false && "stateless conditional probability computation not supported"
Unable to create montreal model: empty path
MontrealInferenceEngine
Malformed language model configuration plist: invalid value for key=
MRLNeuralNetworkModelLock
MRLNeuralNetworkModelUnLock
getOutput
output != nullptr
MRLNeuralNetworkGetOutput
setInput
MRLNeuralNetworkSetInput
MRLNeuralNetworkSetPartialOutputIndices
setInputTensor
InputDimension
SequenceLength
failed to sanitize text='
CoreLMPrefixCoder
CoreLMPrefixCoder.cpp
type == NeuralNetworkCoderType::Prefix
com.apple.LanguageModeling
Default
LanguageModelingSignposts
VocabularyDidChange
invalid locale value for creating vocabulary
MontrealMultiTokenIDMapper
open()
fstat()
mmap()
 failed for '
LMMontrealMultiTokenIDMapper.h
NeuralModelPredictionEnumerator
NeuralModelPredictionEnumerator.cpp
m_tokenIDMapper->modelType() == NNModelType::Word || m_tokenIDMapper->modelType() == NNModelType::SubWord
getPrediction
false && "getPrediction: called without predictions"
predictValidStemFromPrefix
m_tokenIDMapper->isPrefixID(context.back())
wordIsComplete
false && "no tokens provided"
false && "unexpected non-combining ID"
mapper.isPrefixID(lastToken) || mapper.isStemID(lastToken)
burst trie header check failed
v24@?0^{_LXCursor=}8*16
getToken
LMLexiconCursorImpl.cpp
!m_entries.empty()
probation lexicon file is invalid
probation lexicon file is incompatible (version %d, expected version %d)
variant map file is invalid
variant map file is incompatible (version %d)
LMVariantMap.cpp
v20@?0I8C12B16
enumerateVariants
false && "Out of bounds memory access in enumerateVariants"
_W-1
_W-2
Lex_
Failed to open the FST file for reading: 
Failed to read the FST file header: 
const
vector
Unknown FST type: 
Failed to load FST grammar
prediction
LMFstGrammar.cpp
end >= begin
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
ImplToFst: Assignment operator disallowed
null
VectorFst::Write: write failed: 
Inconsistent number of states observed during write
tropical
standard
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
(size) <= (cache_size_)
/Library/Caches/com.apple.xbs/Sources/LanguageModeling_Sim/Source/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
Check failed: "
" file: 
 line: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of arcs observed during write
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
SortedMatcher: bad match type
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
 and 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
sp.dat
URL missing for CoreLM tokenizer resource
modelInfo.plist
getCoreLMMaxSequenceLength
CoreLMUtils.mm
modelInfo
MaximumSequenceLength
copyCoreLMSupportedConfigurations
SupportedBatchSizesAndSequenceLengthsForLM
SupportedBatchSizesAndSequenceLengthsForLM key missing in modelInfo.plist
eJGhnVvylF3dMOHBKJzeiw
NAME
AMBIGIOUS_NAME
PLACE_NAME
RACE_SINGULAR
RACE_PLURAL
COLOR_RACE_SINGULAR
COLOR_RACE_PLURAL
RELIGION_NAME
RELIGION_PEOPLE_SINGULAR
RELIGION_PEOPLE_PLURAL
kNLGazetteerCompressedModelURL
NLGazetteerCreate
NLGazetteerCopyLabel
Could not find a compatible tokenIDMapper for file at '
DDScannerCreate
DDScannerScanStringWithRange
DDScannerCopyResultsWithOptions
DDResultGetRangeForURLification
DDResultGetCategory
DDScannerReset
LanguageModelWrapper
PredictionEnumeratorWrapper
StreamTokenizerWrapper
VocabularyWrapper
LanguageContextWrapper
LanguageLikelihoodModelWrapper
v40@?0^{__EmojiTokenWrapper=}8{?=qq}16^B32
Multilingual-
.model
/System/Library/LinguisticData/RequiredAssets_
.bundle/AssetData/
Failed to load Multilingual Classifier from %s
Serialization of languagelikelihood.dat model failed due to busy signal: %s
localeIdentifier
adaptationEnabled
useMontreal
dynamicLexiconName
customResourceDirectory
addSystemResources
customDynamicResourceDirectory
generateFstPrimingToken
trialParameters
enableABTesting
excludeMobileAssets
disableDynamicLanguageModels
addVocabulary
TokenIDLanguageModel.cpp
vocabulary
removeVocabulary
convertMatchType
false && "Invalid match type"
Unknown lexicon identifier: 
B24@?0r^v8r^v16
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
addCrashReportMessage
Malformed legacy blocklist bundle configuration: cannot load the legacy blocklist resource
Malformed lemmatized blocklist bundle configuration: cannot load the lemmatized blocklist resource
Malformed lemmatized blocklist bundle configuration: cannot load the blocklist id map resource
_getInfoDictionary
BlocklistBundle.cpp
d && "An Info.plist file was unable to be read from the bundle"
_getContents
(contents != 0) && "There should files contained within the blocklist bundle"
%@.%@
CFBundleVersion
Contents
Name
Weight
MontrealModelType
MontrealCacheType
MontrealFullCacheSize
MontrealSparseCacheSize
InputLayerName
OutputLayerName
OutputNodeName
TrainedWithUNK
ForwardPassLimit
CoderType
PrefixMatchingType
LMLexiconCompatibilityVersion
invalid bundle
bundle does not exist
dynamic dictionary bundle path is not a directory
%@.dat
modelWasTrainedWithUNK
mkpath_np failed for dynamic model bundle: 
failed to set backup exclusion for dynamic model bundle: 
Info.plist
invalid Info.plist creation parameters
CFBundleDevelopmentRegion
CFBundleIdentifier
CFBundleInfoDictionaryVersion
CFBundleName
CFBundlePackageType
CFBundleShortVersionString
CFBundleSignature
com.apple.LanguageModeling.%@
English
BNDL
????
writeInfoDictionary failed:
writeInfoDictionary failed: unspecified error
Could not reset statement, error code: %d error message: %s
Could not bind int, error code: %d error message: %s
Could not bind double, error code %d error message: %s
Could not bind blob, error code %d error message: %s
Could not bind text, error code %d error message: %s
BlocklistTokenConverter.cpp
updateTokenIDs
TokenSequence.hpp
m_tokens.size() == m_tokenIDs.size()
v28@?0r*8q16I24
best
recency
lexicon
dynamic
cdistr
chlm
tags
meta
blocklist
stlm
sflm
stsfmap
params
overrides
morphology
mecabralexicon
lexdb
Phrases
Suffixes
lstsfmap
variants
Delta
dynamicids
probation
dynamic-lexicon
searchquery
newmorphology
override-variants
blocklist-bundle
LMMontrealCompositeModel.cpp
NeuralLanguageModelAdapter
NeuralLanguageModelAdapter.cpp
m_tokenIDMapper
createPredictionEnumerator
Unsupported major/minor version (
) for 
Network
Network.cpp
m_NrOfEdges > 0
m_NrOfNodes > 0
n < getNrOfNodes()
predictions
largestInputId() == neuralModel.outputLayerSize() - 1
MaxFragmentModelPredictions
FSTBeamWidth
MaxFanoutEdgesEvaluatedForPrediction
getEdge
Network.h
edgeIdx < getNrOfEdges()
isInitial
nodeForPrefix
false && "Failed to find node for prefix"
getNode
FragmentModelFST
Failed to read from input file stream
Overriding configuration key='
' with user preferences value='
worst
PriorityQueue.h
!m_predictions.empty()
PriorityQueue
PriorityQueue.hpp
m_maxPredictionCount > 0
flushAccumulatedTokens
LMStreamTokenizer.cpp
!m_internalTokens.empty()
externalTokenIndexInBounds
internalTokenIndex < m_internalTokens.size()
v36@?0{?=qq}8i24^B28
could not open 
token ID map file has unexpected format on line 
xSYMBx
xPARENTHESISx
xEMOTx
xDATEx
xBOSx
xGIVENNAMEx
xPERSONFAMILYNAMEx
xRECIPGIVENNAMEx
xRECIPFAMILYNAMEx
xCITYx
xPERSONFULLNAMEx
<UNK_L1>
xSINGULAR_FAMILYNAMEx
xSINGULAR_PERSONALNAMEx
xCOUNTRYx
xSTATEx
xORGANIZATIONx
com.apple.LanguageModeling.TrialServices
lexicon file is invalid
lexicon file is incompatible (version %d, expected version %d)
LMLexiconTrie.cpp
false && "enumerateSortkeyEquivalentEntries() is not supported in StaticLexiconTrie"
fstat failed
lexicon trie file is incompatible (version %d, expected version %d)
dynamic id limits incompatible with lexicon trie header: %d, expected %d)
lseek failed
malformed lexicon file
trie creation failed
convert
LinguisticTokenConverter.cpp
rescoreCandidates
trimCandidates
!candidates.empty()
Invalid token id map file
Invalid token id map file - magic number incorrect
Token id map file is incompatible (version %d, expected version %d)
Invalid token id map file - unexpected file size
MontrealDefaultTokenIDMapper
getFSTNetwork
LMMontrealDefaultTokenIDMapper.h
LMTIByteString.cpp
buffer_size <= std::numeric_limits<uint16_t>::max()
stem suffix ID converter file is invalid
stem suffix ID converter file is incompatible (version %d, expected version %d)
Recipients
SpatialTemporal
failed to remove context tag map
bitset set argument out of range
bitset test argument out of range
com.apple.mobilesms
com.apple.messages
com.facebook
com.twitter
com.instagram
com.snapchat
com.pinterest
com.vine
com.tumblr
com.whatsapp
com.apple.mobilemail
com.apple.mail
I12@?0I8
MontrealFragmentTokenIDMapper
LMMontrealFragmentTokenIDMapper.cpp
size == 1
nnTokenIDs.front() == kMontrealTokenIDBeginningOfSentence
size == 2
nnTokenIDs[0] == kMontrealTokenIDUNK
nnTokenIDs[1] == m_fstNetwork->endOfWordTokenID()
mapToLMToken
getMaxLMTokenID
isNonCombiningID
LMMontrealFragmentTokenIDMapper.h
false && "isNonCombiningID() not supported for fragment models"
cache
LMTransientLexicon.cpp
false && "Not Implemented"
ngram set file is invalid
ngram set file version is not supported
MontrealLanguageModel
pop_back
CompletionStemImpl.cpp
m_tokens.size() == m_sanitizedTokens.size()
m_tokens.size() == m_normalizedTokens.size()
lastToken
Failed at loading Toucan language Model Resource
CoreLM configuration
Exact
CaseInsensitive
DiacriticInsensitive
CaseAndDiacriticInsensitive
Invalid prefix matching type=
Prefix
SuffixV1
SuffixV2
Invalid coder type=
makeNeuralModel
ToucanResourceLoader.cpp
isH13ANEPresent()
prefixTokensRange
ToucanTokenIDMapperStub.hpp
false && "Not supported for Toucan"
stemTokensRange
suffixTokensRange
hasSparseFanout
com.apple.LanguageModeling.LanguageLikelihoodModel
langlikelihood.dat
com.apple.LanguageModeling.LanguageLikelihoodModelCreation
LanguageLikelihoodModel creation failed: %s
v16@?0@"<TRINamespaceUpdateProtocol>"8
TuriTrialClient
TRINamespace
Unable to find class %s
deliverTrialParameters
TuriTrialClient.mm
identifiers.experimentId
identifiers.treatmentId
Delivering trial parameters for 
languageModelArchive
geometryModelArchive
trialExperimentId
trialDeploymentId
trialTreatmentId
Experiment Parameters:
Language model bundle path:
registerTrialParametersWithCrashReporter
LanguageIntelligence language model experiment info:
TrialData
ClientWrapper
TRIClient
com.apple.LanguageModeling.Vocabulary
TokenIDBlocklistDecorator
TokenIDBlocklistDecorator.cpp
m_blocklist
m_tokenIDMap
normalizeForExactMatching
ToucanUtils.cpp
Model resource is missing MontrealModelType
Invalid model type=
specialHandlingOfPossessiveForm
encoded.size() == 1
TextInputCore
TransformerLMForAutocorrection
invalid stem suffix lexicon ID converter plist
NonStemSuffixCount
StemSuffixClasses
Abbreviation
StemCount
SuffixCount
LMDebug
LexiconMigrationStage
LegacyTextInputLexicon
en_US
dynamic-text.dat
%@-dynamic-text.dat
LexiconMigrator
kRootCollator
kDefaultCustomCollator
kCustomTurkishCollator
kCustomNordicCollator
kCustomCombiningMarkCollator
kCustomTamilCollator
(unknown custom collator)
LMTIKeyboardCreateCustomCollationRulesForCollatorType
LMTIKeyboardCollator.cpp
type != kRootCollator
& [before 1] a < ' ' < '&' 
LMTIKeyboardCollatorCompile
failed to compile rules for collator type %s: %s
getRootCollator_block_invoke
U_SUCCESS(error)
getRootCollator
rootCollator
Collator customization failed: %s
com.apple.LanguageModeling.KeyboardCollator
%@/collator.dat
/System/Library/PrivateFrameworks/Lexicon.framework/collator.dat
givenName
familyName
nickname
hash
topNPredictions
BaseLanguageModel.cpp
m_tokenIDMapper->modelType() != NNModelType::Fragment
range.max < m_sizeOutput && "max value of Montreal token ID range exceeds model output size"
populateOutputLayer
succeeded
failed
v1.0
v2.0
CoreLM
Language model bundle contains invalid model type: '
BaseLanguageModel
assembleCache
LMMontrealCacheFactory.hpp
false && "unknown montreal model type"
segregated
monolithic
incremental
getCacheType
false && "unknown cache type"
Montreal resource is missing the 'MontrealFullCacheSize' configuration parameter.
extractSize
false && "missing dictionary entry"
false && "wrong type for dictionary entry"
false && "Failed to parse CFNumber as kCFNumberIntType"
getOldestEntry
LRUStateBaseCache.hpp
entryIterator != m_cache.end()
populateProbabilities
false && "client requested probabilities for a context that's not in the cache"
getProbability
false && "client requested a probability for a context that's not in the cache"
Montreal resource is missing the 'MontrealSparseCacheSize' configuration parameter.
SegregatedStateCache
LMSegregatedStateCache.hpp
m_tokenIDMapper->modelType() != NNModelType::Word && "Unsupported model type"
MRLNeuralNetworkIncrementalStateCreate
_registerUsageOfBranch
LRUIncrementalStateCache.hpp
index >= 0
getState
MRLNeuralNetworkResetIncrementalState
MRLNeuralNetworkAppendIncrementalState
compute_sort_key
LMTIStringFunctions.cpp
ustr_len <= ustr.size()
key_len <= key.size()
key[key_len - 1] == 0
CoreLMSuffixCoder
CoreLMSuffixCoder.cpp
isWordBoundaryIndex
index < encoding.size()
. . .
_U_CAP_
I'll
I've
it's
that's
he's
there's
she's
what's
let's
who's
here's
how's
where's
else's
It's
That's
He's
There's
She's
What's
Let's
Who's
Here's
How's
Where's
Else's
_U_NT08
<unk>
<pad>
UniLM
_U_PRE
_U_NT
John
xyz.com
fragmentString
SentencePieceCoder.hpp
fragmentID < m_tokenIDToFragmentStrMap.size()
bundleName
addSystemToCustomResources
appContext
appGenre
recipientContext
spatialTemporalContext
contextIdentifier
dynamicDataSchema
staticModelsEnabled
useSerializedCache
DynamicModelOrder
AdaptationVersionNumber
MaxDynamicModelSize
PruningTargetSize
StaticModelWeight
CacheModelWeight
DynamicModelWeight
RecencyModelWeight
DynamicModelTagMatchCountWeight
DynamicModelTagGenreMatchCountWeight
DynamicModelTagRecipientMatchCountWeight
DynamicModelTagSpatialTemporalMatchCountWeight
DynamicModelTagMismatchCountWeight
DynamicUnigramCountThreshold
DynamicNgramCountThreshold
RecencyUnigramCountThreshold
RecencyNgramCountThreshold
DynamicEmojiUnigramCountThreshold
DynamicEmojiNgramCountThreshold
DynamicTotalUnigramCountThreshold
MinDynamicTokensTypedThreshold
DynamicNgramWeights
UseSpecialNumberToken
FirstDynamicTokenID
LastDynamicTokenID
TagBitCount
DynamicTokenPenalty
customWords
customLexiconName
customLexiconDeltaName
MaxDynamicLexiconEntryCount
useDynamicTokenCharacterFilter
unknownTokenPenalty
DifferentialPrivacyEnabled
DecayExponent
maxMontrealPredictions
maxMontrealClassMemberPredictions
montrealFullCacheSize
montrealSparseCacheSize
addressBookNamePenalty
negativeLearningThreshold
languageLikelihoodModelEnabled
useMontrealUNK
excludeInformalDynamicData
shouldExcludeMobileAssets
requiresStaticModel
informalAppGenre
formalAppGenre
enableSearchQueryModelLoading
selfSender
payload
invalid tag bit count (valid values are 8 and 16)
invalid dynamic token ID range
 cannot be set after creation
appContextChanged
appGenreChanged
recipientContextChanged
spatialTemporalContextChanged
morphology file is invalid
morphology file version is not supported
ngram model file is invalid
ngram model file is incompatible (version %d, expected version %d)
dynamic and static token ID ranges are overlapping
NgramModel
mlock
munlock
output
_bestConfigurationMatch
CoreLMInferenceEngine.cpp
contextLength > 0
_copyInput
m_inputs[offset] == kMontrealTokenIDBeginningOfSentence
input
qk_mask
workingContext[0] == kMontrealTokenIDBeginningOfSentence
truncatedContextLengths.size() == numInputs
conditionalProbabilities.size() == numQueries
outputSize
m_coreOutputSize == MontrealInferenceEngine::outputSize()
_ane.espresso
_cpu.espresso
modelPath
.net
resource not found at 
copyConfigurations
config.second.size() > 0
validBatchSizes
batchSizes.size() > 0
CoreLMInferenceEngine
NeuralNetwork.hpp
map::at:  key not found
setInputTensorANE
MRLNeuralNetworkSetInputTensor
ShapeDimension
Width
Height
Channel
MRLNeuralNetworkTensorCreate
MRLNeuralNetworkTensorAppendData
completionTrieAddListNode
LMCompletionTrie.cpp
nodes.size() <= trie->reserved[CONTAINER_SIZE]
completionTrieSerializeLevels
bitcount == count
Invalid blocklistID map: mismatched magic number
Unsupported blocklistID map version (recorded=
, required=
Corrupt blocklistID map: entry count mismatch (recorded=
, actual=
adaptation version number was missing
adaptation version number had unexpected type %ld
failed to remove dynamic model metadata
adaptationVersion
didResetMessages
wordsSinceLastDecay
numberOfTokensTyped
creationTime
lastDecay
lastPruning
lastOfflineAdaptation
lastOfflineAdaptationTime1
lastOfflineAdaptationTime2
lastFlushTimeKey
NeuralNetwork
MRLNeuralNetworkCreate returned nullptr
MRLNeuralNetworkPredict
MRLNeuralNetworkCopyStates
kMRLNeuralNetworkOptionModelURLKey
kMRLNeuralNetworkOptionEngineKey
MRLNeuralNetworkCreate
MRLNeuralNetworkCopyInputNamesAndDimensions
MRLNeuralNetworkCopyOutputNamesAndDimensions
MRLNeuralNetworkClear
MRLNeuralNetworkGetOutputDimension
MRLNeuralNetworkCopyIncrementalStates
DictionaryRef_iterator iterator out of range.
override file is invalid
override file version is not supported
createPrunedCopy
LMDynamicLexiconImpl.cpp
entry
Dynamic
Failed to create the lexicon
Failed to create the lexicon: (null)
DynamicLexiconImpl
v28@?0I8d12^B20
incrementPenaltyCount
LMPrunableSharedLexicon.cpp
false && "incrementPenaltyCount() is not supported in PrunableSharedLexicon"
getPenaltyCount
false && "getPenaltyCount() is not supported in PrunableSharedLexicon"
getUsageCount
false && "getUsageCount() is not supported in PrunableSharedLexicon"
blocklistToken
false && "blocklistToken() is not supported in PrunableSharedLexicon"
LMTIString.cpp
initialize
len <= m_capacity
ensure_capacity
m_capacity >= InitialCapacity
data_in_allocated_internal_buffer()
Hant
Lexicon resources not found
v44@?0I8r*12d20I28I32^B36
enumerateSortkeyEquivalentEntries
LMCompositeLexicon.cpp
false && "not implemented"
createLXCursorRoot
/%@.dat
%@-%@-%@_%@
%@-%@_%@_%@
%@-%@-%@
%@-%@_%@
%@-%@
UPDATE 
SET TokenID = ? WHERE TokenID = ?
 = ?
INSERT INTO 
 (TokenID
) VALUES (?
 SET 
 WHERE TokenID=?
SELECT 
 FROM Words WHERE TokenID = ?
TokenID FROM Words WHERE 
SELECT TokenID FROM Words WHERE 
 = ? LIMIT 1
CREATE TABLE 
 (TokenID INTEGER PRIMARY KEY, 
DROP TABLE 
 FROM 
SELECT TokenID from Words
SELECT MAX(TokenID) from Words
SELECT COUNT(TokenID) from Words
BLOB
INTEGER
v20@?0I8I12f16
B12@?0I8
tags.plist
weightFunction
LMNgramPoolFacadeImpl.cpp
wordSeparatorForLocale
AdapterUtils.cpp
!localeIdentifier.empty()
Missing 
 resource
Duplicate 
 resources:
Could not construct
token class distribution file is invalid
token class distribution file is incompatible (version %d, expected version %d)
LexiconFrameworkAdaptor
LMLexiconAdaptor.cpp
error
Failed to create the lexicon framework adapter
v24@?0^{_LXEntry=}8*16
findSinglePathForOutputId
LMFSTNetwork.cpp
nnTokenIDs.size() >= maxMontrealTokensForLMTokenID()
Unable to allocate
Invalid dynamic data
v16@?0I8f12
Invalid class model file
Invalid class model file - magic number incorrect
class mapping file is incompatible (version %d, expected version %d)
Invalid class model file - unexpected file size
Failed to memory map entire class model file
Invalid class model file: %d classes declared but members only listed for %d
Invalid class model file: the final class boundary is at %d but there are %d members in the map
v40@?0{TokenMetaData=IIId}8^B32
(file_size=
, offset=
, object_size=
attempted to read beyond the end of the mapped file 
learnFromToken
count_letters_if_word
TokenLearner.cpp
length > 0
dynamic model
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
read
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
A coder is required in the creation of a CoreLanguageModel
_forward
CoreLanguageModel.cpp
context[0] == kMontrealTokenIDBeginningOfSentence
context.size() != priorContextLength
CoreLanguageModel
compressOutputLayer
NeuralNetworkUtils.hpp
uncompressed.size() == compressed.size() && "mismatched output layer sizes"
DefaultRecipientID
conditionalProbability
combinedConditionalProbability
TokenIDLanguageModelSession.cpp
success
combinedConditionalProbabilityBatched
scoreInfos.size() == tokens.size()
scoreInfos[i].size() == tokens[i].size()
_enumeratePredictions
enumeratePredictions
addPriorText
false
adaptToText
unAdaptToToken
registerNegativeEvidence
v8@?0
Prediction
toString
TokenIDAdapterUtils.hpp
Environment is missing required key: 
Language model creation failed: %s
%{signpost.description:begin_time}llu
CreateLanguageModel
Failed to create token id mapper: %s
locale=%s
PerformMaintenance
Invalid CFType for kLMVocabularyLocaleKey: %@
Model type selected for conditional probablity: %s
%s: caught unexpected exception: %s
loading resource id %ld type %d with path %s
Duplicate montreal resources: %s, %s
Duplicate montreal supplemental model resources: %s, %s
Skipping unsupported resource: LanguageModelFSTBlocklistResourceType
Duplicate bias normalization resource found: %s, %s
Failed to load default blocklist
Failed to load quickpath blocklist
No traditional n-gram models to load: falling back on the montreal supplemental model
Resource initialization failed: %s
Creating CompositeLanguageModel (%@):
Deltas are not supported for multiple lexicons. Attempting to apply deltas to all provided lexicons...
Adaptation disabled: could not load/create dynamic data in %@
Unknown external lexicon type: %ld
%s: failed to enumerate vocabulary entries for text=%s: %s
failed to create the FST grammar from file=%s [unknown exception]
failed to create the FST Grammar from file=%s [%s]
failed to create a static lexicon for migration: %s
%s: Running model type %s since LD has set key %s to true and the architecture is LSTM based
%s: Running model type %s since LD has set key %s to true and the architecture is not LSTM based
%s: Running model type %s since user toggled internal preference
%s: Running model type %s since device is H13ANE and LD has set key %s to true
%s: Running model type %s since transformer autocorrection flag is enabled
%s: Falling back to default model type %s
MontrealRecognizeIncremental
unknown neural network output class: %d
dynamic data was already loaded with incompatible parameters
resetting dynamic data due to validation failure
reseting adaptation data due to adaptation version number mismatch
cache flush failed: %s
recency flush failed: %s
failed to remove dynamic model
applying exponential decay for dynamic model bundle: %s
Resource loader initialized with trial parameters: %s
%s: Failed to acquire lock on the languageModelBundlePath.
Malformed resource properties (missing resource type):
%s: Using A/B testing bundle at: %@
Loaded ngram blocklist: %s
Loaded legacy ngram blocklist from bundle: %s
Loaded lemmatized blocklist from bundle: %s
Loaded lemmatized blocklist: %s
Loaded lemmatized blocklist id map: %s
Failed to create the default trial parameter store: %s
Unable to write trial parameters to file at '%s': %@
Malformed parameter cache at '%s'
File at '%s' is not a valid plist.
%s: failed: %s
Wrote zero-length trial parameter cache with path=%s, expected_contents=%s
Wrote invalid trial parameter cache with path=%s, expected_contents=%s
Failed to verify plist at path=%s, expected_contents=%s: %s
%s: Failed to get language code for locale identifier: %s
std::filesystem::exists() failed: %s
Failed to remove file at %s: %s
%s: Mangling montreal model path (appending path with '.net')
%s() failed: %@
%s() not found as neural network input
Could not find a valid prediction for context: [%s]
Out of bounds memory access in enumerateVariants: %p not in [%p, %p)
%s: Caught unexpected exception: %s
%s: Malformed options dictionary: invalid value for key='%@'
ToucanGenerateCompletions
Supplemental model failed calculating P( %d | [ %s ] )
Montreal failed calculating P( %d | [ %s ] )
Supplemental LM failed to calculate %s
unknown montreal model type in instance of MontrealTokenIDMapper: %d
Failed to find node for prefix: [%s]
Failed to start Trial Services: default parameter store is not available
Kicking off initialization of trial bundle
Saved trial parameters: %s for locale: %s to the store
Cleared trial parameters in the store
%s: Failed to calculate P( %d | [ %s ] )
%s: Loaded tokenID mapper: %s
limiting forward passes to %ld, with contextLength=%zu and priorContextLength=%zu
failed to insert montreal state into the cache
%s: Runtime check failed: Trial.framework is not available
Initializing Turi Trial client
Received addUpdateHandlerForNamespaceName() callback
Device is not currently part of an A/B testing experiment
Device is enrolled in an A/B testing experiment with id=%@
%s: Failed to deliver trial parameters for experiment '%@': %s
The file for factor=%@ is not yet available, or is not part of this treatment
%s: Failed to initialize TRIClient
failed to migrate entry '%s'
successfully migrated %u of %u dynamic lexicon entries
migration failed: could not load dynamic ngram pool at %s
migration failed: could not load the legacy dynamic lexicon
unable to migrate entry with tokenID=%u (failed to lookup corresponding string)
failed to migrate entry '%s' with tokenID=%u
failed to create a mutable lexicon: %s
failed to create a mutable lexicon
migrating %s lexicon using source file: %s and destination bundle: %s
migrating %s lexicon using LM resources and destination bundle: %s
could not create legacy lexicon: %s
skipping migration of string='%s'; already exists with tokenID=%u
Dynamic model initialization failed: %s
%s wiring montreal model memory
%s un-wiring montreal model memory
No model type configured; falling back on the legacy montreal model
assembling monolithic cache for locale='%@': cacheSize=%lu
assembling segregated cache for locale='%@': fullCacheSize=%lu, sparseCacheSize=%lu
assembling incremental cache for locale='%@': cacheSize=%lu
Options is updating %s from %d to %d
LD has already modified  %s, not updating from %d to %d
LD is Updating %s from %d to %d
%s: Loaded language model: %s
%s: mlock() failed: %s
%s: munlock() failed: %s
%s: Mangling ANE model path from CPU model path (replacing '_cpu.espresso' with '_ane.espresso')
%s: Loaded neural language model: %s
Unable to load network model
Unable to run inference on the NN Model
Entry for tokenID=%u is missing from the '%@' lexicon
failed to add new entry with string=%s, tokenID=%u
Failed to look up toucan resources: %s
%s: addTokenForString() failed for: %@
A coder is required to use a CoreLanguageModel
%s: Failed to create enumerator for context='%s'
%s: Failed to create enumerator for stem='%s'
%s: Unexpected adaptation type: %d (this function is only expected to be used for offline adaptation)
%s: called with unknown word: %s
Unsupported token type: %d
Setting configuration value %s=%zu (overridden by user preferences)
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
softlink:o:path:/System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore
softlink:o:path:/System/Library/PrivateFrameworks/Trial.framework/Trial
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
LMTrial
LMTrialDataSource
NSObject
initWithDataSource:
init
start
dataSource
startWithParametersUpdateCallback:
localeIdentifier
UTF8String
encodeTrialParameters:
loadParametersWithLocaleIdentifier:
notificationCenter
postNotificationName:object:
sharedInstance
encodedTrialParametersForLocale:
handleUpdatedTrialParameters:forLocaleIdentifier:
.cxx_destruct
.cxx_construct
trialParametersByLocaleIdentifier
_dataSource
T@"<LMTrialDataSource>",R,V_dataSource
defaultCenter
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
T@"NSNotificationCenter",R
stringWithUTF8String:
dictionaryWithContentsOfFile:
allKeys
containsObject:
objectForKeyedSubscript:
intValue
countByEnumeratingWithState:objects:count:
objectForKey:
namespaceNameFromId:
refresh
addUpdateHandlerForNamespaceName:usingBlock:
removeUpdateHandlerForToken:
experimentIdentifiersWithNamespaceName:
experimentId
treatmentId
levelForFactor:withNamespaceName:
stringValue
fileValue
hasAsset
hasPath
path
deploymentId
clientWithIdentifier:
@16@0:8
@72@0:8{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}16
@24@0:8@16
v16@0:8
v80@0:8{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}16r^v72
{map<std::string, std::optional<LM::TrialParameters>, std::less<std::string>, std::allocator<std::pair<const std::string, std::optional<LM::TrialParameters>>>>="__tree_"{__tree<std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::optional<LM::TrialParameters>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::optional<LM::TrialParameters>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::less<std::string>, true>>="__value_"Q}}}
@"<LMTrialDataSource>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v64@0:8{function<void (const std::string &, const std::optional<LM::TrialParameters> &)>={__value_func<void (const std::string &, const std::optional<LM::TrialParameters> &)>={type=[32C]}^v}}16
{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}24@0:8r^v16
@"NSNotificationCenter"16@0:8
 " & 0 
N13sentencepiece10normalizer10NormalizerE
N5Darts15DoubleArrayImplIvvivEE
N13sentencepiece22SentencePieceProcessorE
N13sentencepiece4word5ModelE
*-0N13sentencepiece9character5ModelE
$1WW
BPHN13sentencepiece7unigram7LatticeE
N13sentencepiece7unigram9ModelBaseE
N13sentencepiece7unigram5ModelE
N5Darts7Details9ExceptionE
$5FW
N13sentencepiece11TrainerSpecE
N13sentencepiece14NormalizerSpecE
N13sentencepiece24ModelProto_SentencePieceE
N13sentencepiece10ModelProtoE
NSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
N13sentencepiece14ModelInterfaceE
$).38=BGLQV
N13sentencepiece31SentencePieceText_SentencePieceE
N13sentencepiece17SentencePieceTextE
N13sentencepiece22NBestSentencePieceTextE
N6google8protobuf8internal29InternalMetadataWithArenaBaseINSt3__112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEENS1_29InternalMetadataWithArenaLiteEE9ContainerE
N13sentencepiece3bpe5ModelE
N6google8protobuf11MessageLiteE
N6google8protobuf8internal12FieldSkipperE
N6google8protobuf8internal29CodedOutputStreamFieldSkipperE
N6google8protobuf14FatalExceptionE
N6google8protobuf7ClosureE
N6google8protobuf8internal16FunctionClosure0E
N6google8protobuf2io20ZeroCopyOutputStreamE
N6google8protobuf2io17ArrayOutputStreamE
N6google8protobuf2io18StringOutputStreamE
-BWl
"+4=Oajr{
N6google8protobuf8internal15ExtensionFinderE
N6google8protobuf8internal24GeneratedExtensionFinderE
NSt3__121__basic_string_commonILb1EEE
N6google8protobuf13RepeatedFieldIiEE
N6google8protobuf13RepeatedFieldIxEE
N6google8protobuf13RepeatedFieldIjEE
N6google8protobuf13RepeatedFieldIyEE
N6google8protobuf13RepeatedFieldIfEE
N6google8protobuf13RepeatedFieldIdEE
N6google8protobuf13RepeatedFieldIbEE
N6google8protobuf16RepeatedPtrFieldINSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
N6google8protobuf8internal20RepeatedPtrFieldBaseE
N6google8protobuf16RepeatedPtrFieldINS0_11MessageLiteEEE
?ffffff
333333
ff&?ff
>33s?
4Fgj
"(7AMSYciox
"4KK
O]Udd
`iiii
!-ee
SX^uu
!-ee
SX^uu
!-ee
SX^uu
!-ee
IW8m g
IUNNSt3__110__function6__funcIZ16-[LMTrial start]E3$_0NS_9allocatorIS2_EEFvRKNS_12basic_stringIcNS_11char_traitsIcEENS3_IcEEEERKNS_8optionalIN2LM15TrialParametersEEEEEE
Z16-[LMTrial start]E3$_0
NSt3__110__function6__funcIZ50LMLanguageModelPerformMaintenanceWithEffectiveTimeE3$_0NS_9allocatorIS2_EEFvRN2LM11DynamicDataEEEE
NSt3__110__function6__baseIFvRN2LM11DynamicDataEEEE
Z50LMLanguageModelPerformMaintenanceWithEffectiveTimeE3$_0
N17language_modeling2v126ToucanLanguageModelSessionE
NSt3__110__function6__funcIZN17language_modeling2v1L24bestWordMatchFromLexiconERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE4$_16NSB_ISG_EEFvPK10__CFStringjdNS4_13SourceLexiconERbEEE
ZN17language_modeling2v1L24bestWordMatchFromLexiconERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEE4$_16
NSt3__110__function6__funcIZN17language_modeling2v126ToucanLanguageModelSession37combinedConditionalProbabilityBatchedERKNS_6vectorINS5_INS3_14SanitizedTokenENS_9allocatorIS6_EEEENS7_IS9_EEEERKNS3_17LinguisticContextEE3$_4NS7_ISH_EEFdmEEE
ZN17language_modeling2v126ToucanLanguageModelSession37combinedConditionalProbabilityBatchedERKNSt3__16vectorINS3_INS0_14SanitizedTokenENS2_9allocatorIS4_EEEENS5_IS7_EEEERKNS0_17LinguisticContextEE3$_4
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession31_combinedConditionalProbabilityERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEbRmbE3$_7NS_9allocatorISC_EEFdmEEE
ZNK17language_modeling2v126ToucanLanguageModelSession31_combinedConditionalProbabilityERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEbRmbE3$_7
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession18_staticPredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmRmE4$_11NSA_ISG_EEFvRKNS3_14SanitizedTokenERNS8_IjNSA_IjEEEEEEE
NSt3__110__function6__baseIFvRKN17language_modeling2v114SanitizedTokenERNS_6vectorIjNS_9allocatorIjEEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession18_staticPredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmRmE4$_11
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmmE3$_2NSA_ISF_EEFbRKNS3_10PredictionEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmmE3$_2
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmmE4$_12NSA_ISF_EEFbRKNS3_10PredictionEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_completionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmmE4$_12
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession22_normalizeStemsForBiasERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS6_EEEERKNS5_INS3_14SanitizedTokenENS7_ISC_EEEEE4$_14NS7_ISH_EEFSC_RKSC_RKNS_8optionalISC_EERSE_EEE
NSt3__110__function6__baseIFN17language_modeling2v114SanitizedTokenERKS4_RKNS_8optionalIS4_EERNS_6vectorIS4_NS_9allocatorIS4_EEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession22_normalizeStemsForBiasERKNSt3__16vectorINS0_14CompletionStemENS2_9allocatorIS4_EEEERKNS3_INS0_14SanitizedTokenENS5_ISA_EEEEE4$_14
NSt3__110__function6__funcIZNK17language_modeling2v126ToucanLanguageModelSession12_fragmentIDsERNS3_21LinguisticContextImplEE4$_15NS_9allocatorIS7_EEFvRKNS3_14SanitizedTokenERNS_6vectorIjNS8_IjEEEEEEE
ZNK17language_modeling2v126ToucanLanguageModelSession12_fragmentIDsERNS0_21LinguisticContextImplEE4$_15
NSt3__120__shared_ptr_emplaceIN2LM18MontrealClassModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN2LM21MontrealTokenIDMapperENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM21MontrealTokenIDMapperEEE
NSt3__120__shared_ptr_emplaceIN2LM21MontrealLanguageModelENS_9allocatorIS2_EEEE
N2LM22CompositeLanguageModelE
NSt3__123enable_shared_from_thisIN2LM22CompositeLanguageModelEEE
NSt3__120__shared_ptr_pointerIPN2LM10FSTGrammarENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM10FSTGrammarEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN2LM10FSTGrammarEEE
NSt3__110__function6__funcIZN2LML38enumerateSortkeyEquivalentsFromLexiconERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS2_7LexiconENS2_13SourceLexiconERKNS_8functionIFvPK10__CFStringjdSE_RbEEEE3$_2NS6_ISO_EEFvSI_jdSJ_EEE
NSt3__110__function6__baseIFvPK10__CFStringjdRbEEE
ZN2LML38enumerateSortkeyEquivalentsFromLexiconERKNSt3__112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEERKNS_7LexiconENS_13SourceLexiconERKNS0_8functionIFvPK10__CFStringjdSC_RbEEEE3$_2
NSt3__120__shared_ptr_pointerIPN2LM22CompositeLanguageModelENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM22CompositeLanguageModelEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN2LM22CompositeLanguageModelEEE
NSt3__120__shared_ptr_pointerIPN2LM10ParametersENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM10ParametersEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN2LM10ParametersEEE
NSt3__120__shared_ptr_emplaceIN2LM22TokenClassDistributionENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM22MontrealCompositeModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM10NgramModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM15StemSuffixModelENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_pointerIPN2LM14ResourceLoaderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM14ResourceLoaderEEE
N2LM10TokenIDMapINS_15AttributedTokenEEE
NSt3__110__function6__funcIZNK2LM22CompositeLanguageModel22conditionalProbabilityEjNS_4spanIKjLm18446744073709551615EEERNS2_18CompositeScoreInfoEPNS2_6LoggerEbbRKNS_8functionIFdmEEEE3$_0NS_9allocatorISG_EESC_EE
NSt3__110__function6__baseIFdmEEE
ZNK2LM22CompositeLanguageModel22conditionalProbabilityEjNSt3__14spanIKjLm18446744073709551615EEERNS_18CompositeScoreInfoEPNS_6LoggerEbbRKNS1_8functionIFdmEEEE3$_0
NSt3__110__function6__funcIZNK2LM22CompositeLanguageModel33enumerateSortkeyEquivalentEntriesERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8functionIFvPK10__CFStringjdRbEEEE3$_1NS7_ISL_EEFvSF_jdNS2_13SourceLexiconESG_EEE
ZNK2LM22CompositeLanguageModel33enumerateSortkeyEquivalentEntriesERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS1_8functionIFvPK10__CFStringjdRbEEEE3$_1
N2LM20LegacyDynamicLexiconE
N17language_modeling2v119ToucanLanguageModelE
N2LM11LexiconImplE
N2LM14LegacyMontrealE
NSt3__123enable_shared_from_thisIN2LM14LegacyMontrealEEE
NSt3__120__shared_ptr_pointerIPN2LM14LegacyMontrealENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM14LegacyMontrealEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN2LM14LegacyMontrealEEE
N2LM29GermanGrammaticalityEvaluatorE
N2LM15LexiconDatabaseE
NSt3__120__shared_ptr_pointerIPN2LM11DynamicDataENS_10shared_ptrIS2_E27__shared_ptr_default_deleteIS2_S2_EENS_9allocatorIS2_EEEE
NSt3__110shared_ptrIN2LM11DynamicDataEE27__shared_ptr_default_deleteIS2_S2_EE
NSt3__114default_deleteIN2LM11DynamicDataEEE
NSt3__120__shared_ptr_pointerIPN2LM28DynamicLanguageModelMetadataENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM28DynamicLanguageModelMetadataEEE
NSt3__120__shared_ptr_pointerIPN2LM15NgramPoolFacadeENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM15NgramPoolFacadeEEE
NSt3__120__shared_ptr_emplaceIN2LM21PrunableSharedLexiconENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM18DynamicLexiconImplENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM19NgramPoolFacadeImplENS_9allocatorIS2_EEEE
N2LM32BTriePositionInterpreterInternalE
N2LM23BTrieFatBaseInterpreterE
N2LM27BTrieCompactBaseInterpreterE
N2LM24BTrieFlatBaseInterpreterE
N2LM20BTrieNoOpInterpreterE
112141718191A1B1C1E1F1G1H1I1J1K1L1M1N1O1P1Q1R1S1T1U1V1W1X1Y1Z1[1\1]1^1_1`1a1b1c11121314151617191:1;1<1=1>1?1@1A1B1D1E1F1G1H1J1K1L1M1N1
N2LM18JointLanguageModelE
NSt3__110__function6__funcIPFiP7__sFILEENS_9allocatorIS5_EES4_EE
NSt3__110__function6__baseIFiP7__sFILEEEE
PFiP7__sFILEE
FiP7__sFILEE
NSt3__120__shared_ptr_emplaceIN2LM19TrialParameterStoreENS_9allocatorIS2_EEEE
N3fst10MappedFileE
N2LM23MontrealInferenceEngineE
N2LM15InferenceEngineE
N2LM30RussianGrammaticalityEvaluatorE
N2LM17CoreLMPrefixCoderE
N2LM11CoreLMCoderINS_11PrefixCoderEEE
N2LM18SentencePieceCoderINS_11PrefixCoderEEE
N2LM11PrefixCoderE
N2LM14VocabularyImplE
N2LM26MontrealMultiTokenIDMapperE
N2LM31NeuralModelPredictionEnumeratorE
N2LM15StemSuffixModelE
N2LM30StemSuffixPredictionEnumeratorE
N2LM17LexiconCursorImplE
NSt3__110__function6__funcIZN2LM17LexiconCursorImplC1EPK9_LXCursorNS_8functionIFbPK8_LXEntryEEENS2_11TokenSourceEE3$_0NS_9allocatorISE_EEFbSA_SA_EEE
NSt3__110__function6__baseIFbPK8_LXEntryS4_EEE
ZN2LM17LexiconCursorImplC1EPK9_LXCursorNSt3__18functionIFbPK8_LXEntryEEENS_11TokenSourceEE3$_0
NSt3__110__function6__funcIZN2LM17LexiconCursorImplC1EPK9_LXCursorNS_8functionIFbPK8_LXEntryEEENS2_11TokenSourceEE3$_1NS_9allocatorISE_EEFbS6_S6_EEE
NSt3__110__function6__baseIFbPK9_LXCursorS4_EEE
ZN2LM17LexiconCursorImplC1EPK9_LXCursorNSt3__18functionIFbPK8_LXEntryEEENS_11TokenSourceEE3$_1
N2LM24ListBasedTokenEnumeratorE
N2LM19VariantEnumeratorV2E
N2LM17LemmaEnumeratorV1E
N2LM17LemmaEnumeratorV2E
N3fst9ImplToFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst11ExpandedFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst14MemoryPoolBaseE
N3fst11MemoryArenaINS_10MemoryPoolINS_8DfsStateINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEE4LinkEEE
N3fst15MemoryArenaBaseE
N3fst9ImplToFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst10MutableFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst17VectorFstBaseImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS5_EEEEEE
N3fst7FstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS4_NSt3__19allocatorIS4_EEEEEE
N3fst16ImplToMutableFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst17ImplToExpandedFstINS_13VectorFstImplINS_11VectorStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENSt3__19allocatorIS6_EEEEEENS_10MutableFstIS6_EEEE
N3fst18MutableArcIteratorINS_9VectorFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_11VectorStateIS5_NSt3__19allocatorIS5_EEEEEEEE
N3fst22MutableArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst15ArcIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst13CacheBaseImplINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_13PoolAllocatorIS5_EEEENS_17DefaultCacheStoreIS5_EEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi2EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi2EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi4EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi4EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi8EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi8EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi16EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi16EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi32EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi32EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi64EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_6ArcTplINS_17TropicalWeightTplIfEEEEE2TNILi64EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS1_IS6_EEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINS_10CacheStateINS_6ArcTplINS_17TropicalWeightTplIfEEEENS2_IS7_EEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINSt3__111__list_nodeIiPvEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINSt3__111__list_nodeIiPvEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi1EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi2EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi2EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi4EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi4EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi8EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi8EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi16EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi16EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi32EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi32EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS2_11__hash_nodeIiPvEEEEE2TNILi64EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorIPNSt3__116__hash_node_baseIPNS3_11__hash_nodeIiPvEEEEE2TNILi64EEEE4LinkEEE
N3fst10MemoryPoolINS_13PoolAllocatorINSt3__111__hash_nodeIiPvEEE2TNILi1EEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_13PoolAllocatorINSt3__111__hash_nodeIiPvEEE2TNILi1EEEE4LinkEEE
N3fst17StateIteratorBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst8ConstFstINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst17ImplToExpandedFstINS_12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEENS_11ExpandedFstIS5_EEEE
N3fst12ConstFstImplINS_6ArcTplINS_17TropicalWeightTplIfEEEEjEE
N3fst10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst9ImplToFstINS_18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEENS_3FstIS5_EEEE
N3fst13SortedMatcherINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEE
N3fst11MatcherBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEEEE
N3fst10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEEE
N3fst11MemoryArenaINS_10MemoryPoolINS_11ArcIteratorINS_3FstINS_6ArcTplINS_17TropicalWeightTplIfEEEEEEEEE4LinkEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst18ComposeFstImplBaseINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS4_EEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_21SequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_24AltSequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IjEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_23PushLabelsComposeFilterINS_24PushWeightsComposeFilterINS_22LookAheadComposeFilterINS_21SequenceComposeFilterINS_16LookAheadMatcherINS_3FstIS5_EEEESE_EESE_SE_LNS_9MatchTypeE2EEESE_SE_LSG_2EEESE_SE_LSG_2EEENS_24GenericComposeStateTableIS5_NS_15PairFilterStateINSL_INS_18IntegerFilterStateIaEENS_17WeightFilterStateIS4_EEEENSM_IjEEEENS_24DefaultComposeStateTupleIiSS_EENS_21CompactHashStateTableISU_NS_11ComposeHashISU_EEEEEEEE
N3fst13StateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst18CacheStateIteratorINS_10ComposeFstINS_6ArcTplINS_17TropicalWeightTplIfEEEENS_17DefaultCacheStoreIS5_EEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_17NullComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_24AltSequenceComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst14ComposeFstImplINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
N3fst17ComposeFstMatcherINS_17DefaultCacheStoreINS_6ArcTplINS_17TropicalWeightTplIfEEEEEENS_18MatchComposeFilterINS_7MatcherINS_3FstIS5_EEEESB_EENS_24GenericComposeStateTableIS5_NS_18IntegerFilterStateIaEENS_24DefaultComposeStateTupleIiSF_EENS_21CompactHashStateTableISH_NS_11ComposeHashISH_EEEEEEEE
20LanguageModelWrapper
27PredictionEnumeratorWrapper
22StreamTokenizerWrapper
17VocabularyWrapper
22LanguageContextWrapper
30LanguageLikelihoodModelWrapper
N2LM27LanguageLikelihoodModelImplE
N17language_modeling2v120TokenIDLanguageModelE
N17language_modeling2v117LanguageModelImplE
NSt3__110__function6__funcIZN17language_modeling2v1L24blocklistContextTokenIDsERNS3_21LinguisticContextImplEjRKNS3_14TokenConverterENS3_9MatchTypeEE3$_0NS_9allocatorISA_EEFjRKNS3_14SanitizedTokenERKNS_6vectorIjNSB_IjEEEEEEE
ZN17language_modeling2v1L24blocklistContextTokenIDsERNS0_21LinguisticContextImplEjRKNS0_14TokenConverterENS0_9MatchTypeEE3$_0
N2LM26CompositeVariantEnumeratorE
N3fst11SymbolTableE
N2LM23SQLiteDatabaseExceptionE
N17language_modeling2v123BlocklistTokenConverterE
StaticTokenIDCacheSize
NSt3__110__function6__funcIZN17language_modeling2v1L52bestLinguisticallyEquivalentTokenIDFromStaticLexiconERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_3NSB_ISG_EEFvPK10__CFStringjdNS4_13SourceLexiconERbEEE
ZN17language_modeling2v1L52bestLinguisticallyEquivalentTokenIDFromStaticLexiconERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEE3$_3
NSt3__110__function6__funcIZNK17language_modeling2v123BlocklistTokenConverter7convertERNS3_13TokenSequenceEE3$_1NS_9allocatorIS7_EEFbjEEE
ZNK17language_modeling2v123BlocklistTokenConverter7convertERNS0_13TokenSequenceEE3$_1
NSt3__110__function6__funcIZNK17language_modeling2v123BlocklistTokenConverter7convertERNS3_13TokenSequenceEE3$_2NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEEEEE
ZNK17language_modeling2v123BlocklistTokenConverter7convertERNS0_13TokenSequenceEE3$_2
 NSt3__110__function6__funcIZNK17language_modeling2v115StringTokenizer8tokenizeERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERNS3_13TokenSequenceEE3$_0NS8_ISF_EEFbjEEE
ZNK17language_modeling2v115StringTokenizer8tokenizeERKNSt3__112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEERNS0_13TokenSequenceEE3$_0
N2LM19BeamSearchPredictorE
N2LM22NeuralNetworkPredictorE
N2LM20MecabraLexiconCursorE
N2LM26MecabraStaticLexiconCursorE
N2LM20RecencyLanguageModelE
N2LM22MontrealCompositeModelE
NSt3__120__shared_ptr_pointerIPN2LM13LexiconCursorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM13LexiconCursorEEE
N2LM22TransientLanguageModelE
N2LM29TransientPredictionEnumeratorE
NSt3__120__shared_ptr_pointerIPN2LM16TransientLexiconENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM16TransientLexiconEEE
NSt3__110__function6__funcIZNK2LM22TransientLanguageModel26insertPredictionsForPrefixEPK10__CFStringlRNS_14priority_queueINS2_13TransientItemENS_6vectorIS8_NS_9allocatorIS8_EEEENS2_17TransientItemLessEEE13LMLexiconTypeE3$_0NSA_ISH_EEFvS6_dEEE
NSt3__110__function6__baseIFvPK10__CFStringdEEE
ZNK2LM22TransientLanguageModel26insertPredictionsForPrefixEPK10__CFStringlRNSt3__114priority_queueINS_13TransientItemENS4_6vectorIS6_NS4_9allocatorIS6_EEEENS_17TransientItemLessEEE13LMLexiconTypeE3$_0
N2LM26NeuralLanguageModelAdapterE
N2LM19LegacyMontrealStateE
N2LM15SharedNgramPoolE
N2LM16StringTokenIDMapE
xNUMBx
xLINKx
xTERMx
xPAUSEx
xHASHx
xUSERx
xRCHRx
xSINGNUMBx
xPLRNUMBx
N2LM29CompositeCompletionEnumeratorE
NSt3__120__shared_ptr_emplaceIN2LM15TuriTrialClientENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZZN2LM13TrialServices5startERKNS_10shared_ptrINS2_11TrialClientEEERKNS4_IKNS2_19TrialParameterStoreEEERKNS_8functionIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8optionalINS2_15TrialParametersEEEEEEENK3$_0clEvEUlSM_SR_E_NSI_ISX_EESS_EE
NSt3__110__function6__baseIFvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS_8optionalIN2LM15TrialParametersEEEEEE
ZZN2LM13TrialServices5startERKNSt3__110shared_ptrINS_11TrialClientEEERKNS2_IKNS_19TrialParameterStoreEEERKNS1_8functionIFvRKNS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS1_8optionalINS_15TrialParametersEEEEEEENK3$_0clEvEUlSK_SP_E_
23NoopNgramPoolEnumerator
N2LM19NgramPoolEnumeratorE
20PredictionEnumeratorI14word_unigram_tE
20PredictionEnumeratorI13word_bigram_tE
20PredictionEnumeratorI12word_ngram_tE
20PredictionEnumeratorI15word_ngram_v4_tE
N2LM27LexiconCompletionEnumeratorE
N2LM17StaticLexiconTrieE
N2LM11LexiconTrieE
N2LM18MutableLexiconTrieE
N17language_modeling2v124LinguisticTokenConverterE
N17language_modeling2v114TokenConverterE
NSt3__110__function6__funcIZNK17language_modeling2v124LinguisticTokenConverter7convertERNS3_13TokenSequenceEE3$_3NS_9allocatorIS7_EEFbjEEE
ZNK17language_modeling2v124LinguisticTokenConverter7convertERNS0_13TokenSequenceEE3$_3
NSt3__110__function6__funcIZNK17language_modeling2v124LinguisticTokenConverter7convertERNS3_13TokenSequenceEE3$_2NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEENS_4spanIKjLm18446744073709551615EEEEEE
ZNK17language_modeling2v124LinguisticTokenConverter7convertERNS0_13TokenSequenceEE3$_2
NSt3__110__function6__funcIZN17language_modeling2v1L23getConversionCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEERN2LM22CompositeLanguageModelERT_EUlPK10__CFStringjdNSI_13SourceLexiconERbE_NS8_ISS_EEFvSP_jdSQ_SR_EEE
ZN17language_modeling2v1L23getConversionCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNS2_12basic_stringIcNS2_11char_traitsIcEENS6_IcEEEERN2LM22CompositeLanguageModelERT_EUlPK10__CFStringjdNSG_13SourceLexiconERbE_
NSt3__110__function6__funcIZN17language_modeling2v1L14trimCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNT_10value_typeERSB_PK10__CFLocaleEUlRKSB_E_NS8_ISL_EEFbRKS7_EEE
NSt3__110__function6__baseIFbRKN17language_modeling2v124LinguisticTokenConverter19ConversionCandidateEEEE
ZN17language_modeling2v1L14trimCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNT_10value_typeERS9_PK10__CFLocaleEUlRKS9_E_
NSt3__110__function6__funcIZN17language_modeling2v1L14trimCandidatesINS_6vectorINS3_24LinguisticTokenConverter19ConversionCandidateENS_9allocatorIS7_EEEEEEvRKNT_10value_typeERSB_PK10__CFLocaleEUlRKSB_E0_NS8_ISL_EEFbRKS7_EEE
ZN17language_modeling2v1L14trimCandidatesINSt3__16vectorINS0_24LinguisticTokenConverter19ConversionCandidateENS2_9allocatorIS5_EEEEEEvRKNT_10value_typeERS9_PK10__CFLocaleEUlRKS9_E0_
N2LM25PredictionCacheEnumeratorE
N2LM28MontrealDefaultTokenIDMapperE
N2LM24CompositeLemmaEnumeratorE
N2LM15TokenEnumeratorE
N2LM21StemSuffixIDConverterE
N2LM33FragmentModelPredictionEnumeratorE
N2LM29MontrealFragmentTokenIDMapperE
NSt3__120__shared_ptr_emplaceIN2LM14FSTNetworkImplENS_9allocatorIS2_EEEE
N2LM20MecabraStaticLexiconE
N2LM14MecabraLexiconE
N2LM30MecabraFileMappedStaticLexiconE
N2LM28MecabraInMemoryStaticLexiconE
N2LM29CompositePredictionEnumeratorE
N2LM18CacheLanguageModelE
N2LM17AbstractBlocklistE
N2LM16TransientLexiconE
N2LM14NgramBlocklistE
N2LM21MontrealLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM17CoreLMPrefixCoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM26HypothesisPrefixTerminatorENS_9allocatorIS2_EEEE
N2LM26HypothesisPrefixTerminatorE
N2LM20HypothesisTerminatorE
NSt3__120__shared_ptr_emplaceIN2LM17CoreLMSuffixCoderENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM26HypothesisSuffixTerminatorENS_9allocatorIS2_EEEE
N2LM26HypothesisSuffixTerminatorE
NSt3__120__shared_ptr_pointerIPN2LM19NeuralLanguageModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
NSt3__114default_deleteIN2LM19NeuralLanguageModelEEE
NSt3__120__shared_ptr_emplaceIN2LM19BeamSearchPredictorENS_9allocatorIS2_EEEE
N2LM20MontrealNetworkStateE
N2LM18NeuralNetworkStateE
N2LM33LanguageLikelihoodModelDispatcherE
N2LM23LanguageLikelihoodModelE
N2LM15TuriTrialClientE
N2LM11TrialClientE
NSt3__120__shared_ptr_emplaceIN2LM15TuriTrialClient13ClientWrapperENS_9allocatorIS3_EEEE
N2LM20VocabularyDispatcherE
N2LM10VocabularyE
N2LM25TokenIDBlocklistDecoratorE
N2LM9BlocklistE
N2LM15LXLexiconCursorE
N2LM13LexiconCursorE
N2LM22CompositeLexiconCursorE
N2LM28StemSuffixLexiconIDConverterE
N2LM16TokenIDConverterE
N2LM30TurkishGrammaticalityEvaluatorE
N2LM8CFLoggerE
N2LM6LoggerE
N2LM18StringBufferLoggerE
NSt3__110__function6__funcIZN2LM22LexiconStringConverter22getDefaultConverterFcnEvE3$_0NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
NSt3__110__function6__baseIFN3nlp11CFScopedPtrIPK10__CFStringEES6_EEE
ZN2LM22LexiconStringConverter22getDefaultConverterFcnEvE3$_0
NSt3__120__shared_ptr_emplaceIN6Hangul15StringConverterENS_9allocatorIS2_EEEE
NSt3__110__function6__funcIZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_1NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
ZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_1
NSt3__110__function6__funcIZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_2NS_9allocatorIS4_EEFN3nlp11CFScopedPtrIPK10__CFStringEESB_EEE
ZN2LM22LexiconStringConverter21hangulStringConverterEvE3$_2
N2LM17BaseLanguageModelE
N2LM19NeuralLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM23MontrealInferenceEngineENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2LM21CoreLMInferenceEngineENS_9allocatorIS2_EEEE
NeuralNetworkForwardPassLimit
NSt3__110__function6__funcIZN2LML23assembleMonolithicCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISH_EEFNS4_INS5_IDhEENS8_ISK_EEEEvEEE
NSt3__110__function6__baseIFNS_10unique_ptrIN2LM18MontrealStateCacheIDhEENS_14default_deleteIS5_EEEEvEEE
NSt3__110__function6__funcIZZN2LML23assembleMonolithicCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISI_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISM_EEEEvEEE
NSt3__110__function6__baseIFNS_10unique_ptrIN2LM18MontrealCacheEntryIDhEENS_14default_deleteIS5_EEEEvEEE
N2LM14FullCacheEntryIDhEE
N2LM18MontrealCacheEntryIDhEE
ZZN2LML23assembleMonolithicCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
N2LM13LRUStateCacheIDhEE
N2LM17LRUStateBaseCacheIDhEE
N2LM18MontrealStateCacheIDhEE
ZN2LML23assembleMonolithicCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEEUlvE_
N2LM18LazyCacheDecoratorIDhEE
NSt3__110__function6__funcIZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISM_EEFNS4_INS5_IDhEENS8_ISP_EEEEvEEE
NSt3__110__function6__funcIZZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISN_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISR_EEEEvEEE
ZZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
NSt3__110__function6__funcIZZN2LML23assembleSegregatedCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS_10shared_ptrINS2_21MontrealTokenIDMapperEEERKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE0_NS_9allocatorISN_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISR_EEEEvEEE
N2LM16SparseCacheEntryIDhEE
ZZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE0_
N2LM20SegregatedStateCacheIDhEE
ZN2LML23assembleSegregatedCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS1_10shared_ptrINS_21MontrealTokenIDMapperEEERKNS_8ResourceERKNS_10ParametersEEUlvE_
NSt3__110__function6__funcIZN2LML24assembleIncrementalCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEEUlvE_NS_9allocatorISH_EEFNS4_INS5_IDhEENS8_ISK_EEEEvEEE
NSt3__110__function6__funcIZZN2LML24assembleIncrementalCacheIDhEENS_10unique_ptrINS2_18MontrealStateCacheIT_EENS_14default_deleteIS7_EEEEmmRKNS2_8ResourceERKNS2_10ParametersEENKUlvE_clEvEUlvE_NS_9allocatorISI_EEFNS4_INS2_18MontrealCacheEntryIDhEENS8_ISM_EEEEvEEE
ZZN2LML24assembleIncrementalCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEENKUlvE_clEvEUlvE_
N2LM24LRUIncrementalStateCacheIDhEE
ZN2LML24assembleIncrementalCacheIDhEENSt3__110unique_ptrINS_18MontrealStateCacheIT_EENS1_14default_deleteIS5_EEEEmmRKNS_8ResourceERKNS_10ParametersEEUlvE_
N2LM17CoreLMSuffixCoderE
N2LM11CoreLMCoderINS_11SuffixCoderEEE
N2LM18SentencePieceCoderINS_11SuffixCoderEEE
N2LM11SuffixCoderE
N2LM18NeuralNetworkCoderE
N5boost9algorithm6detail13first_finderFIPKcNS0_8is_equalEEE
N5boost9exceptionE
N5boost16exception_detail10clone_baseE
N5boost9algorithm6detail13token_finderFINS1_10is_any_ofFIcEEEE
N2LM10MorphologyE
N2LM10NgramModelE
N2LM13LanguageModelE
N2LM30NgramModelPredictionEnumeratorE
N2LM21CoreLMInferenceEngineE
N2LM14BlocklistIDMapE
N2LM5BiMapIjjEE
N2LM28PredictionOverrideEnumeratorE
N2LM18DynamicLexiconImplE
N2LM21PrunableSharedLexiconE
N2LM14DynamicLexiconE
NSt3__110__function6__funcIZN2LM12LexiconUtils19makeTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS2_11TokenSourceEE3$_0NS_9allocatorISB_EEFbPK8_LXEntryEEE
ZN2LM12LexiconUtils19makeTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS_11TokenSourceEE3$_0
NSt3__110__function6__funcIZN2LM12LexiconUtils25makePoliteTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS2_11TokenSourceEE3$_1NS_9allocatorISB_EEFbPK8_LXEntryEEE
ZN2LM12LexiconUtils25makePoliteTokenEnumeratorEPK10_LXLexiconPK10__CFStringNS_11TokenSourceEE3$_1
N2LM16CompositeLexiconE
N2LM10RefCountedINS_16CompositeLexiconEEE
N2LM7LexiconE
NSt3__120__shared_ptr_emplaceIN2LM8ResourceENS_9allocatorIS2_EEEE
N2LM19NgramPoolFacadeImplE
N2LM15NgramPoolFacadeE
N2LM8ObserverINS_10ParametersEEE
NSt3__110__function6__funcINS_6__bindIMN2LM10ParametersEKFfjjEJPKS4_RKNS_12placeholders4__phILi1EEERKNSA_ILi2EEEEEENS_9allocatorISH_EEFfjjEEE
NSt3__110__function6__baseIFfjjEEE
NSt3__16__bindIMN2LM10ParametersEKFfjjEJPKS2_RKNS_12placeholders4__phILi1EEERKNS8_ILi2EEEEEE
NSt3__118__weak_result_typeIMN2LM10ParametersEKFfjjEEE
N2LM23LexiconFrameworkAdaptorE
N2LM14LexiconAdaptorE
N2LM21MecabraLexiconAdaptorE
NSt3__110__function6__funcIZNK2LM23LexiconFrameworkAdaptor19makeTokenEnumeratorEPK10__CFStringE3$_0NS_9allocatorIS7_EEFbPK8_LXEntryEEE
NSt3__110__function6__baseIFbPK8_LXEntryEEE
ZNK2LM23LexiconFrameworkAdaptor19makeTokenEnumeratorEPK10__CFStringE3$_0
N2LM14FSTNetworkImplE
N2LM10FSTNetworkE
N2LM10TokenIDMapINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
NSt3__110__function6__funcIZN17language_modeling2v113TokenSequence14updateTokenIDsERKNS_8functionIFbjEEERKNS5_IFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEEEUlSH_NS_4spanIKjLm18446744073709551615EEEE_NSD_ISP_EEFjSH_SO_EEE
NSt3__110__function6__baseIFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_4spanIKjLm18446744073709551615EEEEEE
ZN17language_modeling2v113TokenSequence14updateTokenIDsERKNSt3__18functionIFbjEEERKNS3_IFjRKNS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEEEEUlSF_NS2_4spanIKjLm18446744073709551615EEEE_
NSt3__110__function6__funcIZN17language_modeling2v112TokenLearner17learnFromSequenceERNS3_13TokenSequenceEE3$_0NS_9allocatorIS7_EEFbjEEE
NSt3__110__function6__baseIFbjEEE
ZN17language_modeling2v112TokenLearner17learnFromSequenceERNS0_13TokenSequenceEE3$_0
NSt3__110__function6__funcIZN17language_modeling2v112TokenLearner17learnFromSequenceERNS3_13TokenSequenceEE3$_1NS_9allocatorIS7_EEFjRKNS_12basic_stringIcNS_11char_traitsIcEENS8_IcEEEEEEE
NSt3__110__function6__baseIFjRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
ZN17language_modeling2v112TokenLearner17learnFromSequenceERNS0_13TokenSequenceEE3$_1
N2LM20DynamicLanguageModelE
N2LM40DynamicLanguageModelPredictionEnumeratorE
N2LM20PredictionEnumeratorE
NSt3__110__function6__funcINS_6__bindIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS3_15NgramPredictionEEJPS4_RKNS_12placeholders4__phILi1EEEEEENS_9allocatorISG_EEFbS7_EEE
NSt3__110__function6__baseIFbRKN2LM15NgramPredictionEEEE
NSt3__16__bindIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS1_15NgramPredictionEEJPS2_RKNS_12placeholders4__phILi1EEEEEE
NSt3__118__weak_result_typeIMN2LM40DynamicLanguageModelPredictionEnumeratorEKFbRKNS1_15NgramPredictionEEEE
NSt3__115binary_functionIPKN2LM40DynamicLanguageModelPredictionEnumeratorERKNS1_15NgramPredictionEbEE
N2LM6CFTypeE
N2LM30RomanceGrammaticalityEvaluatorE
N2LM23GrammaticalityEvaluatorE
NSt3__110__function6__funcIZN17language_modeling2v147enumerateLinguisticallyEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_22TokenEnumerationPolicyERKNS_8functionIFvPK10__CFStringjdNS4_13SourceLexiconERbEEEE3$_0NSB_ISR_EESN_EE
NSt3__110__function6__baseIFvPK10__CFStringjdN2LM13SourceLexiconERbEEE
ZN17language_modeling2v147enumerateLinguisticallyEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS1_22TokenEnumerationPolicyERKNS5_8functionIFvPK10__CFStringjdNS1_13SourceLexiconERbEEEE3$_0
NSt3__110__function6__funcIZN17language_modeling2v149enumerateCaseAndDiacriticEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS4_22TokenEnumerationPolicyERKNS_8functionIFvPK10__CFStringjdNS4_13SourceLexiconERbEEEE3$_1NSB_ISR_EESN_EE
ZN17language_modeling2v149enumerateCaseAndDiacriticEquivalentLexiconEntriesERKN2LM22CompositeLanguageModelERKNSt3__112basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS1_22TokenEnumerationPolicyERKNS5_8functionIFvPK10__CFStringjdNS1_13SourceLexiconERbEEEE3$_1
N2LM15ClassNgramModelE
N2LM17CoreLanguageModelE
NSt3__120__shared_ptr_emplaceIN2LM23ToucanTokenIDMapperStubENS_9allocatorIS2_EEEE
N2LM23ToucanTokenIDMapperStubE
N2LM21MontrealTokenIDMapperE
N17language_modeling2v127TokenIDLanguageModelSessionE
N17language_modeling2v124LanguageModelSessionImplE
N3nlp25ResourceCreationExceptionE
AdaptationContextCacheSize
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession30combinedConditionalProbabilityERKNS3_14SanitizedTokenERKNS3_17LinguisticContextERN2LM18CompositeScoreInfoEbRKNS_8functionIFdmEEEE3$_7NS_9allocatorISJ_EEFjS7_RKNS_6vectorIjNSK_IjEEEEEEE
NSt3__110__function6__baseIFjRKN17language_modeling2v114SanitizedTokenERKNS_6vectorIjNS_9allocatorIjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession30combinedConditionalProbabilityERKNS0_14SanitizedTokenERKNS0_17LinguisticContextERN2LM18CompositeScoreInfoEbRKNSt3__18functionIFdmEEEE3$_7
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession11predictionsERKNS3_17LinguisticContextEmN2LM29CompositePredictionEnumerator16PredictionSubsetEE3$_1NS_9allocatorISB_EEFbRKNS3_10PredictionEEEE
NSt3__110__function6__baseIFbRKN17language_modeling2v110PredictionEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession11predictionsERKNS0_17LinguisticContextEmN2LM29CompositePredictionEnumerator16PredictionSubsetEE3$_1
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession21_enumeratePredictionsERNS3_21LinguisticContextImplEmN2LM29CompositePredictionEnumerator16PredictionSubsetElRKNS_8functionIFbRKNS3_10PredictionEEEEE3$_8NS_9allocatorISI_EEFjRKNS3_14SanitizedTokenERKNS_6vectorIjNSJ_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession21_enumeratePredictionsERNS0_21LinguisticContextImplEmN2LM29CompositePredictionEnumerator16PredictionSubsetElRKNSt3__18functionIFbRKNS0_10PredictionEEEEE3$_8
NSt3__117bad_function_callE
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS_8functionIFbRKNS3_10PredictionEEEEE3$_9NSA_ISQ_EEFjRKNS3_14SanitizedTokenERKNS8_IjNSA_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS5_8functionIFbRKNS0_10PredictionEEEEE3$_9
NSt3__110__function6__funcIZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS3_17LinguisticContextERKNS_6vectorINS3_14CompletionStemENS_9allocatorIS9_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS_8functionIFbRKNS3_10PredictionEEEEE4$_10NSA_ISQ_EEFjRKNS3_14SanitizedTokenERKNS8_IjNSA_IjEEEEEEE
ZNK17language_modeling2v127TokenIDLanguageModelSession20enumeratePredictionsERKNS0_17LinguisticContextERKNSt3__16vectorINS0_14CompletionStemENS5_9allocatorIS7_EEEEmN2LM29CompositePredictionEnumerator16PredictionSubsetERKNS5_8functionIFbRKNS0_10PredictionEEEEE4$_10
PredictionCandidateCount
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession12adaptToTokenERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEE4$_12NS_9allocatorISB_EEFjS7_RKNS_6vectorIjNSC_IjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession12adaptToTokenERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEE4$_12
NSt3__110__function6__funcIZN17language_modeling2v127TokenIDLanguageModelSession14unAdaptToTokenERKNS3_14SanitizedTokenERKNS3_17LinguisticContextEE4$_13NS_9allocatorISB_EEFjS7_RKNS_6vectorIjNSC_IjEEEEEEE
ZN17language_modeling2v127TokenIDLanguageModelSession14unAdaptToTokenERKNS0_14SanitizedTokenERKNS0_17LinguisticContextEE4$_13
~*?33s?
precompiled_charsmap is empty.
Normalizer model is not available.
length < 0
norm_to_org and normalized are inconsistent
Trie blob is broken.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/util.h
'result' Must be non NULL
Cannot open 
input ifstream is null
Model file is broken
Model is not initialized.
Normalizer is not initialized.
output container is null
Empty piece is not allowed.
consumed index is out-of-range.
original index is out-of-range.
all normalized characters are not consumed.
output proto is null
NBestEncode returns empty result
nbest_size must be 0 < nbest_size <= 512 or nbest_size < 0.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_processor.cc
LOG(
ERROR
Returns default value 
</s>
Unknown extra_option type
reverse
option 
 is not available.
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arenastring.h
CHECK failed: initial_value != NULL: 
/dev/urandom
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/repeated_field.h
CHECK failed: (index) >= (0): 
CHECK failed: (index) < (current_size_): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_factory.cc
Unknown model_type: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/char_model.cc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/unigram_model.cc
best_node
nbest_size >= 1. Returns empty result.
Too big agenda. shrinking
(num_nodes) < (trie_results.size())
model file is already precompiled.
No pieces are loaded.
Cannot build double-array.
No entry is found in the trie.
precompiled_trie is empty.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:776: exception: failed to resize pool: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1214: exception: failed to insert key: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1216: exception: failed to insert key: zero-length key
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1230: exception: failed to insert key: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1235: exception: failed to insert key: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:915: exception: failed to build rank index: std::bad_alloc
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1453: exception: failed to modify unit: too large offset
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1799: exception: failed to build double-array: invalid null character
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1801: exception: failed to build double-array: negative value
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/third_party/darts_clone/darts.h:1816: exception: failed to build double-array: wrong key order
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece_model.pb.cc
CHECK failed: !model_prefix_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !input_format_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: (&from) != (this): 
sentencepiece.TrainerSpec
CHECK failed: !name_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: !precompiled_charsmap_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.NormalizerSpec
CHECK failed: !piece_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.ModelProto.SentencePiece
CHECK failed: !precompiled_trie_.IsDefault( &::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
CHECK failed: trainer_spec_ != NULL: 
CHECK failed: normalizer_spec_ != NULL: 
sentencepiece.ModelProto
CHECK failed: (n) >= (0): 
down_cast
casts.h
f == NULL || dynamic_cast<To>(f) != NULL
CHECK failed: (&other) != (this): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.cc
User defined symbol is not supported.
 is already defined.
!result.empty()
Cancelled
Unknown
Invalid argument
Deadline exceeded
Not found
Already exists
Permission denied
Unauthenticated
Resource exhausted
Failed precondition
Aborted
Out of range
Unimplemented
Internal
Unavailable
Data loss
Unkown code:
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/sentencepiece.pb.cc
CHECK failed: !surface_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText.SentencePiece
CHECK failed: !text_.IsDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited()): 
sentencepiece.SentencePieceText
sentencepiece.NBestSentencePieceText
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/bpe_model.cc
Invalid character length.
(index) >= (0)
(index) < (static_cast<int>(symbols.size()))
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/src/model_interface.h
Not implemented.
(cannot determine missing fields for lite message)
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/message_lite.cc
CHECK failed: !coded_out.HadError(): 
parse
Can't 
 message of type "
" because it is missing required fields: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/wire_format_lite.cc
CHECK failed: (value.size()) <= (kint32max): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/coded_stream.cc
A protocol message was rejected because it was too big (more than 
 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
CHECK failed: (buffer_size) >= (0): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/generated_message_util.cc
Not implemented field number 
 with type 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/stubs/common.cc
This program requires version 
 of the Protocol Buffer runtime library, but the installed version is 
.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
This program was compiled against version 
 of the Protocol Buffer runtime library, which is not compatible with the installed version (
).  Contact the program author for an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in "
%d.%d.%d
INFO
WARNING
FATAL
[libprotobuf %s %s:%d] %s
pthread_mutex_lock: 
pthread_mutex_unlock: 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream.cc
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
CHECK failed: (last_returned_size_) > (0): 
BackUp() can only be called after a successful Next().
CHECK failed: (count) <= (last_returned_size_): 
CHECK failed: (count) >= (0): 
CHECK failed: target_ != NULL: 
Cannot allocate buffer larger than kint32max for 
StringOutputStream.
CHECK failed: (count) <= (target_->size()): 
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/extension_set.cc
Non-primitive types can't be packed.
can't reach here.
/Library/Caches/com.apple.xbs/Sources/SentencePiece_Sim/ProtocolBuffers/src/google/protobuf/arena.cc
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - kHeaderSize): 
 000000000000
com.apple.NLPUtils
TMPDIR
/tmp
/nlptemp-XXXXXX
File at URL is not readable
File at URL is not a valid property list
Property list at URL is not a dictionary
%@: %@
com.apple.NLPUtils.ErrorDomain
LMTrialParametersDidChangeNotification
Cannot provide split
static (word)
static (sp)
static (unknown)
dynamic-lm
transient + supplemental
penalty
convertAbsoluteTime
convertTimePoint
createWithEncodedRepresentation
TrialParameters.mm
dict
B90D4859-A11E-4A91-A804-CFABD2A099BF
a required parameter was NULL
LMLanguageModelPreheatContexts
LMLanguageModel.cpp
false && "NULL language model reference"
try_push_back
probability
Probability.cpp
locale
getLocaleIdentifierFromOptions
LanguageModeling_Vocabulary.cpp
false && "Invalid CFType for kLMVocabularyLocaleKey"
adaptToToken
canReasonAbout
detailedConditionalProbability
recordWordRevision
clearPriorText
clearDynamicLearningCache
flushCacheAndRecencyData
supportsPrefixCompletions
supportsFragmentsBasedConditionalProbability
Lexicon creation failed: %s
Lexicon id converter creation failed: %s
Unigrams
lstsfmap%@
sessionType
appIdentifier
recipientIdentifier
namedEntityWordLexicon
namedEntityPhraseLexicon
supplementalWordLexicon
supplementalPhraseLexicon
testingParametersGeometryModelBundlePath
LanguageModelForConditionalProbability
LanguageModelForCompletionsAndPredictions
LanguageModelForConditionalProbabilityUserSetting
UseForConditionalProbability
UseForCompletionsAndPredictions
SupportsConditionalProbability
SupportsCompletionsAndPredictions
TokenIDLanguageModel
ToucanLanguageModelOnCPU
wordSeparator
makeSession
blocklistStatus
flushDynamicData
clearDynamicDataForTesting
wireMemory
unwireMemory
deallocateInternalBuffers
Success
_staticPredictions
ToucanLanguageModelSession.cpp
stems.size() > 0
_U_NT52
ToucanAutoCorrection
isPredictionResultingInLoop
index > 0
_U_NT51
_U_NT56
_U_NT54
_U_NT55
string_view::substr
v44@?0^{__CFURL=}8i16^{__CFLocale=}20^{__CFString=}28^B36
convertAssetBundleType
LMLinguisticData.cpp
false && "unsupported LinguisticData asset type"
Failed to create LanguageLikelihoodModel database
DROP TABLE IF EXISTS LangMatrix
DROP TABLE IF EXISTS RecipientByLangMatrix
DROP TABLE IF EXISTS OfflineAdaptationTimeByApp
DROP TABLE IF EXISTS MetaData
DROP TABLE IF EXISTS EmojiByApp
CREATE TABLE RecipientByLangMatrix (RecipientId TEXT, Language TEXT, CharCount, PRIMARY KEY(RecipientId, Language))
CREATE TABLE OfflineAdaptationTimeByApp (ApplicationId TEXT PRIMARY KEY, Time DOUBLE)
CREATE TABLE MetaData (MetaData TEXT PRIMARY KEY, Value TEXT)
CREATE TABLE EmojiByApp (ApplicationId TEXT PRIMARY KEY, Count INT, Time DOUBLE)
INSERT INTO MetaData VALUES (?,?)
Version
DELETE FROM RecipientByLangMatrix
DELETE FROM EmojiByApp
DELETE FROM OfflineAdaptationTimeByApp
INSERT INTO RecipientByLangMatrix VALUES (?,?,?)
INSERT INTO OfflineAdaptationTimeByApp VALUES (?,?)
INSERT INTO EmojiByApp VALUES (?,?,?)
Serialization of languagelikelihood.dat model failed: %s
SELECT * FROM MetaData
SELECT * FROM RecipientByLangMatrix
SELECT * FROM EmojiByApp
SELECT * FROM OfflineAdaptationTimeByApp
Deserialization of languagelikelihood.dat model failed: %s
-wal
-shm
failed to remove dynamic languagelikelihood model
SQLite database corrupted
SQLite database open failure
SQLite database save failure
SQLite database initialization failure
SQLite database statement preparation failure
LinguisticContextImpl.cpp
cache.size() <= m_tokens.size()
m_fragmentCaches.size() == m_cumulativeFragmentCounts.size()
counts.size() <= m_tokens.size()
remove_first
count <= m_tokens.size()
operator()
fragmentCount > fragmentsToRemove
maxent.cpp
conditional_probability
prod != 0
max_label >= 0
error: cannot open 
classify
_num_classes == (int)membp.size()
Feature
maxent.h
id >= 0 && id < (int)id2mef.size()
ME_Feature
l >= 0 && l <= MAX_LABEL_TYPES
f >= 0 && f <= 0xffffff
id >= 0 && id < (int)id2str.size()
invalid language model creation options
initialize_block_invoke
LMCompositeLanguageModel.cpp
v24@?0r^v8^B16
No static lexicons to associate with FST grammar
<missing>
Resource initialization failed: %s
loadDynamicData
!m_dynamicData
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}12@?0I8
addLexicon
false && "Unknown external lexicon type"
removeLexicon
locale=
, adaptation=
enabled
disabled
, montreal=
CompositeLanguageModel
extractMaxDynamicPredictions
false && "Malformed resource bundle: duplicate MaxDynamicPredictions keys."
MaxDynamicPredictions
Could not find item
Could not convert
dynamicids resource file is incompatible (version %d, expected version %d)
dynamicRangeMin
dynamicRangeMax
dynamicLimitsMin
dynamicLimitsMax
dynamicids resource file is incompatible with the parameters the client has set (dynamicIDLimits [%d, %d], expected dynamicIDLimits [%d, %d])
Dynamic Lexicon Trie initialization failed: %s (%s)
Probation lexicon initialization failed: %s (%s)
Dynamic Lexicon initialization failed: %s
Inconsistency in dynamic word id ranges: %d, expected max (%d)
Inconsistency in dynamic word id ranges: %d, expected min (%d)
Unexpected dynamic word id ranges: (dynamicIDRanges [%d, %d], dynamicIDLimits [%d, %d])
LMLegacyDynamicLexicon.cpp
false && "add() is not supported in LegacyDynamicLexicon()"
remove
false && "remove() is not supported in LegacyDynamicLexicon()"
clear
false && "clear() is not supported in LegacyDynamicLexicon"
false && "enumerateSortkeyEquivalentEntries() is not supported in LegacyDynamicLexicon"
false && "createLXCursorRoot() is not supported in LegacyDynamicLexicon"
flushData
false && "flushData() is not supported in LegacyDynamicLexicon"
writeDebugDump
false && "writeDebugDump() is not supported in LegacyDynamicLexicon"
false && "prune() is not supported in LegacyDynamicLexicon"
false && "createPrunedCopy() is not supported in LegacyDynamicLexicon"
incrementUsageCount
false && "incrementUsageCount() is not supported in LegacyDynamicLexicon"
false && "incrementPenaltyCount() is not supported in LegacyDynamicLexicon"
false && "getPenaltyCount() is not supported in LegacyDynamicLexicon"
false && "getUsageCount() is not supported in LegacyDynamicLexicon"
false && "blocklistToken() is not supported in LegacyDynamicLexicon"
false && "incrementUsageCountForRecentToken() is not supported in LegacyDynamicLexicon"
reviewProbationaryEntries
false && "reviewProbationaryEntries() is not supported in LegacyDynamicLexicon"
addOrUpdateTokenWithAttributes
false && "addOrUpdateTokenWithAttributes() is not supported in LegacyDynamicLexicon"
updateAttributesForToken
false && "updateAttributesForToken() is not supported in LegacyDynamicLexicon"
copyTokenAttributes
false && "copyTokenAttributes() is not supported in LegacyDynamicLexicon"
getIntegerAttributeValue
false && "getIntegerAttributeValue() is not supported in LegacyDynamicLexicon"
copyStringAttributeValue
false && "copyStringAttributeValue() is not supported in LegacyDynamicLexicon"
default
determineModelType
ToucanLanguageModel
Associating Toucan LM with Trial experiment:
Failed to create the lexicon: 
Failed to soft-link Montreal: 
MRLModelCreate returned nullptr
unknown error
Failed to create an instance of LegacyMontreal: 
LegacyMontreal.cpp
kMRLModelFileLocationKey
MRLModelCreate
MRLModelGetOutputSize
MRLModelRelease
MRLModelRecognizeIncremental
MRLModelRecognizeIncrementalClassPlusSuffixIds
MRLModelStateCreate
MRLModelStateSave
MRLModelStateRelease
MRLModelLock
MRLModelUnlock
MRLModelReset
Failed to create lexicon database
LMLexiconDatabase.cpp
false && "enumerateSortKeyEquivalentEntries is not supported in LexiconDatabase"
false && "createLXCursorRoot is not supported in LexiconDatabase"
binding attributes failed: %s
binding attributes failed: missing or incompatible token string
Copy token attributes failed: %s
Get integer attribute value failed: %s
Copy String attribute value failed: %s
Unable to serialize lexicon database: %s
failed to remove lexicon database
prune
failed to prune lexicon database
false && "incrementPenaltyCount() is not supported in LexiconDatabase"
false && "getPenaltyCount() is not supported in LexiconDatabase"
false && "getUsageCount() is not supported in LexiconDatabase"
false && "blocklistToken() is not supported in LexiconDatabase"
incrementUsageCountForRecentToken
false && "incrementUsageCountForRecentToken() is not supported in LexiconDatabase"
PRAGMA journal_mode = WAL;
Words
Failed to close database, error code: %d  error message: %s
:memory:
main
BEGIN IMMEDIATE
Could not begin transaction, error %d
COMMIT
Could not commit transaction, error %d
ROLLBACK
Could not execute SQL "%s", error message: %s
v20@?0I8^B12
failed to initialize exemplar set for %s (error code %d)
MaintenanceNotification
didPerformPruning
^v8@?0
v16@?0^v8
dynamic.lm
v24@?0r*8^B16
/langlikelihood.dat
B12@?0i8
lexicon.plist
model.txt
cache.txt
recency.txt
DynamicData
v32@?0{span<const unsigned int, 18446744073709551615UL>=^IQ}8I24f28
com.apple.NLPUtils.SingletonResourceManager
dynamic resource serialization failed: %@
Locale is missing from ResourceLoader options
ResourceLoader
invalid type for bundle name
resources
LMResourceLoader.cpp
resourceContainer->has_key(kResourcesKey)
mismatched lexicon compatibility versions
v24@?0^{__CFDictionary=}8^B16
Failed to load bundle: %s
%@-dynamic.lm
%@_%@-dynamic.lm
Resources
Priority
UseExistingModelFiles
hi-Latn
Locale
Language
Alternate locales
appendTrialBundles
%d.%d
Malformed language model configuration: mismatched lemmatized blocklist resources
Malformed language model configuration: too many lemmatized blocklist resources
qualifiers
type
subtype
field
request
person
location
event
navigation
health
self
recipient
3rd person
current location
recent location
recent address
FaceTime
xSURNAMEx
xFULLNAMEx
xMEDIANAMEx
xPHONEx
xMOBILEPHONEx
xHOMEPHONEx
xWORKPHONEx
xFAXNUMBERx
xEMAILx
xADDRESSx
xHOMEADDRESSx
xWORKADDRESSx
xHOMECITYx
xWORKCITYx
xPOSTALCODEx
xCOMPANYx
xBIRTHDAYx
xFACETIMEx
xNEXTEVENTNAMEx
xNEXTTIMEAVAILABLEx
xDURATIONOFAVAILABILITYx
xLASTEVENTOFDAYx
xTIMEOFMEETINGx
xLOCATIONOFMEETINGx
xLOCATIONx
xDISTANCEAWAYx
xETAx
xETASPECIFICx
xETAINTERVALx
xNAMEOFDESTINATIONx
xNAMEOFSTREETx
xSOCIALMEDIAx
xACTIVEENERGYx
xCYCLINGDISTANCEx
xEXERCISEMINUTESx
xPUSHESx
xROLLHOURSx
xSLEEPANALYSISx
xSTANDHOURSx
xSTEPSx
xSWIMMINGDISTANCEx
xWALKINGRUNNINGDISTANCEx
xWEIGHTx
xWHEELCHAIRDISTANCEx
xWORKOUTSx
xABSOLUTEURLx
v28@?0I8Q12^B20
LINGUISTIC_DATA
/System/Library/LinguisticData/
/usr/share/mecabra/%@
%@/%@
true
dynamic resource serialization failed: %d (%s)
%s/%s
Library/LanguageModeling
Extracting archive 
 failed with status=
xTERMx
Provided parameter store path is invalid: 
TrialParameterCache.plist
Failed to get path for trial parameter cache from URL: 
(null)
LanguageModelBundlePath
ExperimentParameters
getStoreDictionary
CacheVersion
extractParameterDictionary
failed to unmap region: 
Mapping of file failed: 
File mapping at offset 
 of file 
 could not be honored, reading instead.
Failed to read 
 bytes at offset 
from "
unexpected key type in schema
Type
unexpected value type in schema for attribute %s and key %s
Integer
String
unsupported type for key %s (supported types are String and Integer)
Unique
IsTokenString
DefaultValue
unexpected value type in schema for key
schema should only specify one token string key
schema must specify a token string key
copyCurrentIncrementalState
MontrealInferenceEngine.cpp
m_architecture == NNModelArchitecture::Transformer
position
temperature
segment
false && "stateless conditional probability computation not supported"
Unable to create montreal model: empty path
MontrealInferenceEngine
Malformed language model configuration plist: invalid value for key=
MRLNeuralNetworkModelLock
MRLNeuralNetworkModelUnLock
getOutput
output != nullptr
MRLNeuralNetworkGetOutput
setInput
MRLNeuralNetworkSetInput
MRLNeuralNetworkSetPartialOutputIndices
setInputTensor
InputDimension
SequenceLength
failed to sanitize text='
CoreLMPrefixCoder
CoreLMPrefixCoder.cpp
type == NeuralNetworkCoderType::Prefix
com.apple.LanguageModeling
Default
LanguageModelingSignposts
VocabularyDidChange
invalid locale value for creating vocabulary
MontrealMultiTokenIDMapper
open()
fstat()
mmap()
 failed for '
LMMontrealMultiTokenIDMapper.h
NeuralModelPredictionEnumerator
NeuralModelPredictionEnumerator.cpp
m_tokenIDMapper->modelType() == NNModelType::Word || m_tokenIDMapper->modelType() == NNModelType::SubWord
getPrediction
false && "getPrediction: called without predictions"
predictValidStemFromPrefix
m_tokenIDMapper->isPrefixID(context.back())
wordIsComplete
false && "no tokens provided"
false && "unexpected non-combining ID"
mapper.isPrefixID(lastToken) || mapper.isStemID(lastToken)
burst trie header check failed
v24@?0^{_LXCursor=}8*16
getToken
LMLexiconCursorImpl.cpp
!m_entries.empty()
probation lexicon file is invalid
probation lexicon file is incompatible (version %d, expected version %d)
variant map file is invalid
variant map file is incompatible (version %d)
LMVariantMap.cpp
v20@?0I8C12B16
enumerateVariants
false && "Out of bounds memory access in enumerateVariants"
_W-1
_W-2
Lex_
Failed to open the FST file for reading: 
Failed to read the FST file header: 
const
vector
Unknown FST type: 
Failed to load FST grammar
prediction
LMFstGrammar.cpp
end >= begin
Fst::Write: No write stream method for 
 Fst type
Fst::Write: No write filename method for 
ImplToFst: Assignment operator disallowed
null
VectorFst::Write: write failed: 
Inconsistent number of states observed during write
tropical
standard
Fst::UpdateFstHeader: write failed: 
Fst::Write: Can't open file: 
standard output
(size) <= (cache_size_)
/Library/Caches/com.apple.xbs/Sources/LanguageModeling_Sim/Source/fst/cache.h
GCCacheStore:GC: Unable to free all cached states
Check failed: "
" file: 
 line: 
Could not align file during write after header
Could not align file during write after writing states
ConstFst Write write failed: 
Inconsistent number of arcs observed during write
ConstFst::Read: Alignment failed: 
ConstFst::Read: Read failed: 
FstImpl::ReadHeader: Fst not of type "
FstImpl::ReadHeader: Arc not of type "
FstImpl::ReadHeader: Obsolete 
 Fst version: 
VectorFst::Read: read failed: 
VectorFst::Read: unexpected end of file: 
SortedMatcher: bad match type
compose
ComposeFst: output symbol table of 1st argument 
does not match input symbol table of 2nd argument
CompatSymbols: Symbol table check sums do not match. 
Table sizes are 
 and 
ComposeFst: 1st argument requires matching but cannot.
ComposeFst: 2nd argument requires matching but cannot.
ComposeFst: 1st argument cannot match on output labels 
and 2nd argument cannot match on input labels (sort?).
ComposeFst: both sides can't require match
ComposeFstMatcher: safe copy not supported
LookAheadComposeFilter: 1st argument cannot 
match/look-ahead on output labels and 2nd argument 
cannot match/look-ahead on input labels.
LookAheadMatcher: No look-ahead matcher defined
MultiEpsMatcher: Bad multi-eps label: 0
sp.dat
URL missing for CoreLM tokenizer resource
modelInfo.plist
getCoreLMMaxSequenceLength
CoreLMUtils.mm
modelInfo
MaximumSequenceLength
copyCoreLMSupportedConfigurations
SupportedBatchSizesAndSequenceLengthsForLM
SupportedBatchSizesAndSequenceLengthsForLM key missing in modelInfo.plist
eJGhnVvylF3dMOHBKJzeiw
NAME
AMBIGIOUS_NAME
PLACE_NAME
RACE_SINGULAR
RACE_PLURAL
COLOR_RACE_SINGULAR
COLOR_RACE_PLURAL
RELIGION_NAME
RELIGION_PEOPLE_SINGULAR
RELIGION_PEOPLE_PLURAL
kNLGazetteerCompressedModelURL
NLGazetteerCreate
NLGazetteerCopyLabel
Could not find a compatible tokenIDMapper for file at '
DDScannerCreate
DDScannerScanStringWithRange
DDScannerCopyResultsWithOptions
DDResultGetRangeForURLification
DDResultGetCategory
DDScannerReset
LanguageModelWrapper
PredictionEnumeratorWrapper
StreamTokenizerWrapper
VocabularyWrapper
LanguageContextWrapper
LanguageLikelihoodModelWrapper
v40@?0^{__EmojiTokenWrapper=}8{?=qq}16^B32
Multilingual-
.model
/System/Library/LinguisticData/RequiredAssets_
.bundle/AssetData/
Failed to load Multilingual Classifier from %s
Serialization of languagelikelihood.dat model failed due to busy signal: %s
localeIdentifier
adaptationEnabled
useMontreal
dynamicLexiconName
customResourceDirectory
addSystemResources
customDynamicResourceDirectory
generateFstPrimingToken
trialParameters
enableABTesting
excludeMobileAssets
disableDynamicLanguageModels
addVocabulary
TokenIDLanguageModel.cpp
vocabulary
removeVocabulary
convertMatchType
false && "Invalid match type"
Unknown lexicon identifier: 
B24@?0r^v8r^v16
SymbolTable::Read: read failed
SymbolTable::Write: write failed
Missing required field separator
Negative symbol table entry when not allowed
addCrashReportMessage
Malformed legacy blocklist bundle configuration: cannot load the legacy blocklist resource
Malformed lemmatized blocklist bundle configuration: cannot load the lemmatized blocklist resource
Malformed lemmatized blocklist bundle configuration: cannot load the blocklist id map resource
_getInfoDictionary
BlocklistBundle.cpp
d && "An Info.plist file was unable to be read from the bundle"
_getContents
(contents != 0) && "There should files contained within the blocklist bundle"
%@.%@
CFBundleVersion
Contents
Name
Weight
MontrealModelType
MontrealCacheType
MontrealFullCacheSize
MontrealSparseCacheSize
InputLayerName
OutputLayerName
OutputNodeName
TrainedWithUNK
ForwardPassLimit
CoderType
PrefixMatchingType
LMLexiconCompatibilityVersion
invalid bundle
bundle does not exist
dynamic dictionary bundle path is not a directory
%@.dat
modelWasTrainedWithUNK
mkpath_np failed for dynamic model bundle: 
failed to set backup exclusion for dynamic model bundle: 
Info.plist
invalid Info.plist creation parameters
CFBundleDevelopmentRegion
CFBundleIdentifier
CFBundleInfoDictionaryVersion
CFBundleName
CFBundlePackageType
CFBundleShortVersionString
CFBundleSignature
com.apple.LanguageModeling.%@
English
BNDL
????
writeInfoDictionary failed:
writeInfoDictionary failed: unspecified error
Could not reset statement, error code: %d error message: %s
Could not bind int, error code: %d error message: %s
Could not bind double, error code %d error message: %s
Could not bind blob, error code %d error message: %s
Could not bind text, error code %d error message: %s
BlocklistTokenConverter.cpp
updateTokenIDs
TokenSequence.hpp
m_tokens.size() == m_tokenIDs.size()
v28@?0r*8q16I24
best
recency
lexicon
dynamic
cdistr
chlm
tags
meta
blocklist
stlm
sflm
stsfmap
params
overrides
morphology
mecabralexicon
lexdb
Phrases
Suffixes
lstsfmap
variants
Delta
dynamicids
probation
dynamic-lexicon
searchquery
newmorphology
override-variants
blocklist-bundle
LMMontrealCompositeModel.cpp
NeuralLanguageModelAdapter
NeuralLanguageModelAdapter.cpp
m_tokenIDMapper
createPredictionEnumerator
Unsupported major/minor version (
) for 
Network
Network.cpp
m_NrOfEdges > 0
m_NrOfNodes > 0
n < getNrOfNodes()
predictions
largestInputId() == neuralModel.outputLayerSize() - 1
MaxFragmentModelPredictions
FSTBeamWidth
MaxFanoutEdgesEvaluatedForPrediction
getEdge
Network.h
edgeIdx < getNrOfEdges()
isInitial
nodeForPrefix
false && "Failed to find node for prefix"
getNode
FragmentModelFST
Failed to read from input file stream
Overriding configuration key='
' with user preferences value='
worst
PriorityQueue.h
!m_predictions.empty()
PriorityQueue
PriorityQueue.hpp
m_maxPredictionCount > 0
flushAccumulatedTokens
LMStreamTokenizer.cpp
!m_internalTokens.empty()
externalTokenIndexInBounds
internalTokenIndex < m_internalTokens.size()
v36@?0{?=qq}8i24^B28
could not open 
token ID map file has unexpected format on line 
xSYMBx
xPARENTHESISx
xEMOTx
xDATEx
xBOSx
xGIVENNAMEx
xPERSONFAMILYNAMEx
xRECIPGIVENNAMEx
xRECIPFAMILYNAMEx
xCITYx
xPERSONFULLNAMEx
<UNK_L1>
xSINGULAR_FAMILYNAMEx
xSINGULAR_PERSONALNAMEx
xCOUNTRYx
xSTATEx
xORGANIZATIONx
com.apple.LanguageModeling.TrialServices
lexicon file is invalid
lexicon file is incompatible (version %d, expected version %d)
LMLexiconTrie.cpp
false && "enumerateSortkeyEquivalentEntries() is not supported in StaticLexiconTrie"
fstat failed
lexicon trie file is incompatible (version %d, expected version %d)
dynamic id limits incompatible with lexicon trie header: %d, expected %d)
lseek failed
malformed lexicon file
trie creation failed
convert
LinguisticTokenConverter.cpp
rescoreCandidates
trimCandidates
!candidates.empty()
Invalid token id map file
Invalid token id map file - magic number incorrect
Token id map file is incompatible (version %d, expected version %d)
Invalid token id map file - unexpected file size
MontrealDefaultTokenIDMapper
getFSTNetwork
LMMontrealDefaultTokenIDMapper.h
LMTIByteString.cpp
buffer_size <= std::numeric_limits<uint16_t>::max()
stem suffix ID converter file is invalid
stem suffix ID converter file is incompatible (version %d, expected version %d)
Recipients
SpatialTemporal
failed to remove context tag map
bitset set argument out of range
bitset test argument out of range
com.apple.mobilesms
com.apple.messages
com.facebook
com.twitter
com.instagram
com.snapchat
com.pinterest
com.vine
com.tumblr
com.whatsapp
com.apple.mobilemail
com.apple.mail
I12@?0I8
MontrealFragmentTokenIDMapper
LMMontrealFragmentTokenIDMapper.cpp
size == 1
nnTokenIDs.front() == kMontrealTokenIDBeginningOfSentence
size == 2
nnTokenIDs[0] == kMontrealTokenIDUNK
nnTokenIDs[1] == m_fstNetwork->endOfWordTokenID()
mapToLMToken
getMaxLMTokenID
isNonCombiningID
LMMontrealFragmentTokenIDMapper.h
false && "isNonCombiningID() not supported for fragment models"
cache
LMTransientLexicon.cpp
false && "Not Implemented"
ngram set file is invalid
ngram set file version is not supported
MontrealLanguageModel
pop_back
CompletionStemImpl.cpp
m_tokens.size() == m_sanitizedTokens.size()
m_tokens.size() == m_normalizedTokens.size()
lastToken
Failed at loading Toucan language Model Resource
CoreLM configuration
Exact
CaseInsensitive
DiacriticInsensitive
CaseAndDiacriticInsensitive
Invalid prefix matching type=
Prefix
SuffixV1
SuffixV2
Invalid coder type=
makeNeuralModel
ToucanResourceLoader.cpp
isH13ANEPresent()
prefixTokensRange
ToucanTokenIDMapperStub.hpp
false && "Not supported for Toucan"
stemTokensRange
suffixTokensRange
hasSparseFanout
com.apple.LanguageModeling.LanguageLikelihoodModel
langlikelihood.dat
com.apple.LanguageModeling.LanguageLikelihoodModelCreation
LanguageLikelihoodModel creation failed: %s
v16@?0@"<TRINamespaceUpdateProtocol>"8
TuriTrialClient
TRINamespace
Unable to find class %s
deliverTrialParameters
TuriTrialClient.mm
identifiers.experimentId
identifiers.treatmentId
Delivering trial parameters for 
languageModelArchive
geometryModelArchive
trialExperimentId
trialDeploymentId
trialTreatmentId
Experiment Parameters:
Language model bundle path:
registerTrialParametersWithCrashReporter
LanguageIntelligence language model experiment info:
TrialData
ClientWrapper
TRIClient
com.apple.LanguageModeling.Vocabulary
TokenIDBlocklistDecorator
TokenIDBlocklistDecorator.cpp
m_blocklist
m_tokenIDMap
normalizeForExactMatching
ToucanUtils.cpp
Model resource is missing MontrealModelType
Invalid model type=
specialHandlingOfPossessiveForm
encoded.size() == 1
TextInputCore
TransformerLMForAutocorrection
invalid stem suffix lexicon ID converter plist
NonStemSuffixCount
StemSuffixClasses
Abbreviation
StemCount
SuffixCount
LMDebug
LexiconMigrationStage
LegacyTextInputLexicon
en_US
dynamic-text.dat
%@-dynamic-text.dat
LexiconMigrator
kRootCollator
kDefaultCustomCollator
kCustomTurkishCollator
kCustomNordicCollator
kCustomCombiningMarkCollator
kCustomTamilCollator
(unknown custom collator)
LMTIKeyboardCreateCustomCollationRulesForCollatorType
LMTIKeyboardCollator.cpp
type != kRootCollator
& [before 1] a < ' ' < '&' 
LMTIKeyboardCollatorCompile
failed to compile rules for collator type %s: %s
getRootCollator_block_invoke
U_SUCCESS(error)
getRootCollator
rootCollator
Collator customization failed: %s
com.apple.LanguageModeling.KeyboardCollator
%@/collator.dat
/System/Library/PrivateFrameworks/Lexicon.framework/collator.dat
givenName
familyName
nickname
hash
topNPredictions
BaseLanguageModel.cpp
m_tokenIDMapper->modelType() != NNModelType::Fragment
range.max < m_sizeOutput && "max value of Montreal token ID range exceeds model output size"
populateOutputLayer
succeeded
failed
v1.0
v2.0
CoreLM
Language model bundle contains invalid model type: '
BaseLanguageModel
assembleCache
LMMontrealCacheFactory.hpp
false && "unknown montreal model type"
segregated
monolithic
incremental
getCacheType
false && "unknown cache type"
Montreal resource is missing the 'MontrealFullCacheSize' configuration parameter.
extractSize
false && "missing dictionary entry"
false && "wrong type for dictionary entry"
false && "Failed to parse CFNumber as kCFNumberIntType"
getOldestEntry
LRUStateBaseCache.hpp
entryIterator != m_cache.end()
populateProbabilities
false && "client requested probabilities for a context that's not in the cache"
getProbability
false && "client requested a probability for a context that's not in the cache"
Montreal resource is missing the 'MontrealSparseCacheSize' configuration parameter.
SegregatedStateCache
LMSegregatedStateCache.hpp
m_tokenIDMapper->modelType() != NNModelType::Word && "Unsupported model type"
MRLNeuralNetworkIncrementalStateCreate
_registerUsageOfBranch
LRUIncrementalStateCache.hpp
index >= 0
getState
MRLNeuralNetworkResetIncrementalState
MRLNeuralNetworkAppendIncrementalState
compute_sort_key
LMTIStringFunctions.cpp
ustr_len <= ustr.size()
key_len <= key.size()
key[key_len - 1] == 0
CoreLMSuffixCoder
CoreLMSuffixCoder.cpp
isWordBoundaryIndex
index < encoding.size()
. . .
_U_CAP_
I'll
I've
it's
that's
he's
there's
she's
what's
let's
who's
here's
how's
where's
else's
It's
That's
He's
There's
She's
What's
Let's
Who's
Here's
How's
Where's
Else's
_U_NT08
<unk>
<pad>
UniLM
_U_PRE
_U_NT
John
xyz.com
fragmentString
SentencePieceCoder.hpp
fragmentID < m_tokenIDToFragmentStrMap.size()
bundleName
addSystemToCustomResources
appContext
appGenre
recipientContext
spatialTemporalContext
contextIdentifier
dynamicDataSchema
staticModelsEnabled
useSerializedCache
DynamicModelOrder
AdaptationVersionNumber
MaxDynamicModelSize
PruningTargetSize
StaticModelWeight
CacheModelWeight
DynamicModelWeight
RecencyModelWeight
DynamicModelTagMatchCountWeight
DynamicModelTagGenreMatchCountWeight
DynamicModelTagRecipientMatchCountWeight
DynamicModelTagSpatialTemporalMatchCountWeight
DynamicModelTagMismatchCountWeight
DynamicUnigramCountThreshold
DynamicNgramCountThreshold
RecencyUnigramCountThreshold
RecencyNgramCountThreshold
DynamicEmojiUnigramCountThreshold
DynamicEmojiNgramCountThreshold
DynamicTotalUnigramCountThreshold
MinDynamicTokensTypedThreshold
DynamicNgramWeights
UseSpecialNumberToken
FirstDynamicTokenID
LastDynamicTokenID
TagBitCount
DynamicTokenPenalty
customWords
customLexiconName
customLexiconDeltaName
MaxDynamicLexiconEntryCount
useDynamicTokenCharacterFilter
unknownTokenPenalty
DifferentialPrivacyEnabled
DecayExponent
maxMontrealPredictions
maxMontrealClassMemberPredictions
montrealFullCacheSize
montrealSparseCacheSize
addressBookNamePenalty
negativeLearningThreshold
languageLikelihoodModelEnabled
useMontrealUNK
excludeInformalDynamicData
shouldExcludeMobileAssets
requiresStaticModel
informalAppGenre
formalAppGenre
enableSearchQueryModelLoading
selfSender
payload
invalid tag bit count (valid values are 8 and 16)
invalid dynamic token ID range
 cannot be set after creation
appContextChanged
appGenreChanged
recipientContextChanged
spatialTemporalContextChanged
morphology file is invalid
morphology file version is not supported
ngram model file is invalid
ngram model file is incompatible (version %d, expected version %d)
dynamic and static token ID ranges are overlapping
NgramModel
mlock
munlock
output
_bestConfigurationMatch
CoreLMInferenceEngine.cpp
contextLength > 0
_copyInput
m_inputs[offset] == kMontrealTokenIDBeginningOfSentence
input
qk_mask
workingContext[0] == kMontrealTokenIDBeginningOfSentence
truncatedContextLengths.size() == numInputs
conditionalProbabilities.size() == numQueries
outputSize
m_coreOutputSize == MontrealInferenceEngine::outputSize()
_ane.espresso
_cpu.espresso
modelPath
.net
resource not found at 
copyConfigurations
config.second.size() > 0
validBatchSizes
batchSizes.size() > 0
CoreLMInferenceEngine
NeuralNetwork.hpp
map::at:  key not found
setInputTensorANE
MRLNeuralNetworkSetInputTensor
ShapeDimension
Width
Height
Channel
MRLNeuralNetworkTensorCreate
MRLNeuralNetworkTensorAppendData
completionTrieAddListNode
LMCompletionTrie.cpp
nodes.size() <= trie->reserved[CONTAINER_SIZE]
completionTrieSerializeLevels
bitcount == count
Invalid blocklistID map: mismatched magic number
Unsupported blocklistID map version (recorded=
, required=
Corrupt blocklistID map: entry count mismatch (recorded=
, actual=
adaptation version number was missing
adaptation version number had unexpected type %ld
failed to remove dynamic model metadata
adaptationVersion
didResetMessages
wordsSinceLastDecay
numberOfTokensTyped
creationTime
lastDecay
lastPruning
lastOfflineAdaptation
lastOfflineAdaptationTime1
lastOfflineAdaptationTime2
lastFlushTimeKey
NeuralNetwork
MRLNeuralNetworkCreate returned nullptr
MRLNeuralNetworkPredict
MRLNeuralNetworkCopyStates
kMRLNeuralNetworkOptionModelURLKey
kMRLNeuralNetworkOptionEngineKey
MRLNeuralNetworkCreate
MRLNeuralNetworkCopyInputNamesAndDimensions
MRLNeuralNetworkCopyOutputNamesAndDimensions
MRLNeuralNetworkClear
MRLNeuralNetworkGetOutputDimension
MRLNeuralNetworkCopyIncrementalStates
DictionaryRef_iterator iterator out of range.
override file is invalid
override file version is not supported
createPrunedCopy
LMDynamicLexiconImpl.cpp
entry
Dynamic
Failed to create the lexicon
Failed to create the lexicon: (null)
DynamicLexiconImpl
v28@?0I8d12^B20
incrementPenaltyCount
LMPrunableSharedLexicon.cpp
false && "incrementPenaltyCount() is not supported in PrunableSharedLexicon"
getPenaltyCount
false && "getPenaltyCount() is not supported in PrunableSharedLexicon"
getUsageCount
false && "getUsageCount() is not supported in PrunableSharedLexicon"
blocklistToken
false && "blocklistToken() is not supported in PrunableSharedLexicon"
LMTIString.cpp
initialize
len <= m_capacity
ensure_capacity
m_capacity >= InitialCapacity
data_in_allocated_internal_buffer()
Hant
Lexicon resources not found
v44@?0I8r*12d20I28I32^B36
enumerateSortkeyEquivalentEntries
LMCompositeLexicon.cpp
false && "not implemented"
createLXCursorRoot
/%@.dat
%@-%@-%@_%@
%@-%@_%@_%@
%@-%@-%@
%@-%@_%@
%@-%@
UPDATE 
SET TokenID = ? WHERE TokenID = ?
 = ?
INSERT INTO 
 (TokenID
) VALUES (?
 SET 
 WHERE TokenID=?
SELECT 
 FROM Words WHERE TokenID = ?
TokenID FROM Words WHERE 
SELECT TokenID FROM Words WHERE 
 = ? LIMIT 1
CREATE TABLE 
 (TokenID INTEGER PRIMARY KEY, 
DROP TABLE 
 FROM 
SELECT TokenID from Words
SELECT MAX(TokenID) from Words
SELECT COUNT(TokenID) from Words
BLOB
INTEGER
v20@?0I8I12f16
B12@?0I8
tags.plist
weightFunction
LMNgramPoolFacadeImpl.cpp
wordSeparatorForLocale
AdapterUtils.cpp
!localeIdentifier.empty()
Missing 
 resource
Duplicate 
 resources:
token class distribution file is invalid
token class distribution file is incompatible (version %d, expected version %d)
LexiconFrameworkAdaptor
LMLexiconAdaptor.cpp
error
Failed to create the lexicon framework adapter
v24@?0^{_LXEntry=}8*16
findSinglePathForOutputId
LMFSTNetwork.cpp
nnTokenIDs.size() >= maxMontrealTokensForLMTokenID()
Unable to allocate
Invalid dynamic data
v16@?0I8f12
Invalid class model file
Invalid class model file - magic number incorrect
class mapping file is incompatible (version %d, expected version %d)
Invalid class model file - unexpected file size
Failed to memory map entire class model file
Invalid class model file: %d classes declared but members only listed for %d
Invalid class model file: the final class boundary is at %d but there are %d members in the map
v40@?0{TokenMetaData=IIId}8^B32
(file_size=
, offset=
, object_size=
attempted to read beyond the end of the mapped file 
learnFromToken
count_letters_if_word
TokenLearner.cpp
length > 0
dynamic model
AlignInput: can't determine stream position
AlignOutput: can't determine stream position
read
FstHeader::Read: Bad FST header: 
FstHeader::Read: read failed: 
Unknown file read mode 
A coder is required in the creation of a CoreLanguageModel
_forward
CoreLanguageModel.cpp
context[0] == kMontrealTokenIDBeginningOfSentence
context.size() != priorContextLength
CoreLanguageModel
compressOutputLayer
NeuralNetworkUtils.hpp
uncompressed.size() == compressed.size() && "mismatched output layer sizes"
DefaultRecipientID
conditionalProbability
combinedConditionalProbability
TokenIDLanguageModelSession.cpp
success
combinedConditionalProbabilityBatched
scoreInfos.size() == tokens.size()
scoreInfos[i].size() == tokens[i].size()
_enumeratePredictions
enumeratePredictions
addPriorText
false
adaptToText
unAdaptToToken
registerNegativeEvidence
v8@?0
Prediction
toString
TokenIDAdapterUtils.hpp
Could not construct
Environment is missing required key: 
Language model creation failed: %s
%{signpost.description:begin_time}llu
CreateLanguageModel
Failed to create token id mapper: %s
locale=%s
PerformMaintenance
Invalid CFType for kLMVocabularyLocaleKey: %@
Model type selected for conditional probablity: %s
%s: caught unexpected exception: %s
loading resource id %ld type %d with path %s
Duplicate montreal resources: %s, %s
Duplicate montreal supplemental model resources: %s, %s
Skipping unsupported resource: LanguageModelFSTBlocklistResourceType
Duplicate bias normalization resource found: %s, %s
Failed to load default blocklist
Failed to load quickpath blocklist
No traditional n-gram models to load: falling back on the montreal supplemental model
Resource initialization failed: %s
Creating CompositeLanguageModel (%@):
Deltas are not supported for multiple lexicons. Attempting to apply deltas to all provided lexicons...
Adaptation disabled: could not load/create dynamic data in %@
Unknown external lexicon type: %ld
%s: failed to enumerate vocabulary entries for text=%s: %s
failed to create the FST grammar from file=%s [unknown exception]
failed to create the FST Grammar from file=%s [%s]
failed to create a static lexicon for migration: %s
%s: Running model type %s since LD has set key %s to true and the architecture is LSTM based
%s: Running model type %s since LD has set key %s to true and the architecture is not LSTM based
%s: Running model type %s since user toggled internal preference
%s: Running model type %s since device is H13ANE and LD has set key %s to true
%s: Running model type %s since transformer autocorrection flag is enabled
%s: Falling back to default model type %s
MontrealRecognizeIncremental
unknown neural network output class: %d
dynamic data was already loaded with incompatible parameters
resetting dynamic data due to validation failure
reseting adaptation data due to adaptation version number mismatch
cache flush failed: %s
recency flush failed: %s
failed to remove dynamic model
applying exponential decay for dynamic model bundle: %s
Resource loader initialized with trial parameters: %s
%s: Failed to acquire lock on the languageModelBundlePath.
Malformed resource properties (missing resource type):
%s: Using A/B testing bundle at: %@
Loaded ngram blocklist: %s
Loaded legacy ngram blocklist from bundle: %s
Loaded lemmatized blocklist from bundle: %s
Loaded lemmatized blocklist: %s
Loaded lemmatized blocklist id map: %s
Failed to create the default trial parameter store: %s
Unable to write trial parameters to file at '%s': %@
Malformed parameter cache at '%s'
File at '%s' is not a valid plist.
%s: failed: %s
Wrote zero-length trial parameter cache with path=%s, expected_contents=%s
Wrote invalid trial parameter cache with path=%s, expected_contents=%s
Failed to verify plist at path=%s, expected_contents=%s: %s
%s: Failed to get language code for locale identifier: %s
std::filesystem::exists() failed: %s
Failed to remove file at %s: %s
%s: Mangling montreal model path (appending path with '.net')
%s() failed: %@
%s() not found as neural network input
%s: Loaded tokenID mapper: %s
Could not find a valid prediction for context: [%s]
Out of bounds memory access in enumerateVariants: %p not in [%p, %p)
%s: Caught unexpected exception: %s
%s: Malformed options dictionary: invalid value for key='%@'
ToucanGenerateCompletions
Supplemental model failed calculating P( %d | [ %s ] )
Montreal failed calculating P( %d | [ %s ] )
Supplemental LM failed to calculate %s
unknown montreal model type in instance of MontrealTokenIDMapper: %d
Failed to find node for prefix: [%s]
Failed to start Trial Services: default parameter store is not available
Kicking off initialization of trial bundle
Saved trial parameters: %s for locale: %s to the store
Cleared trial parameters in the store
%s: Failed to calculate P( %d | [ %s ] )
limiting forward passes to %ld, with contextLength=%zu and priorContextLength=%zu
failed to insert montreal state into the cache
%s: Runtime check failed: Trial.framework is not available
Initializing Turi Trial client
Received addUpdateHandlerForNamespaceName() callback
Device is not currently part of an A/B testing experiment
Device is enrolled in an A/B testing experiment with id=%@
%s: Failed to deliver trial parameters for experiment '%@': %s
The file for factor=%@ is not yet available, or is not part of this treatment
%s: Failed to initialize TRIClient
failed to migrate entry '%s'
successfully migrated %u of %u dynamic lexicon entries
migration failed: could not load dynamic ngram pool at %s
migration failed: could not load the legacy dynamic lexicon
unable to migrate entry with tokenID=%u (failed to lookup corresponding string)
failed to migrate entry '%s' with tokenID=%u
failed to create a mutable lexicon: %s
failed to create a mutable lexicon
migrating %s lexicon using source file: %s and destination bundle: %s
migrating %s lexicon using LM resources and destination bundle: %s
could not create legacy lexicon: %s
skipping migration of string='%s'; already exists with tokenID=%u
Dynamic model initialization failed: %s
%s wiring montreal model memory
%s un-wiring montreal model memory
No model type configured; falling back on the legacy montreal model
assembling monolithic cache for locale='%@': cacheSize=%lu
assembling segregated cache for locale='%@': fullCacheSize=%lu, sparseCacheSize=%lu
assembling incremental cache for locale='%@': cacheSize=%lu
Options is updating %s from %d to %d
LD has already modified  %s, not updating from %d to %d
LD is Updating %s from %d to %d
%s: Loaded language model: %s
%s: mlock() failed: %s
%s: munlock() failed: %s
%s: Mangling ANE model path from CPU model path (replacing '_cpu.espresso' with '_ane.espresso')
%s: Loaded neural language model: %s
Unable to load network model
Unable to run inference on the NN Model
Entry for tokenID=%u is missing from the '%@' lexicon
failed to add new entry with string=%s, tokenID=%u
Failed to look up toucan resources: %s
%s: addTokenForString() failed for: %@
A coder is required to use a CoreLanguageModel
%s: Failed to create enumerator for context='%s'
%s: Failed to create enumerator for stem='%s'
%s: Unexpected adaptation type: %d (this function is only expected to be used for offline adaptation)
%s: called with unknown word: %s
Unsupported token type: %d
Setting configuration value %s=%zu (overridden by user preferences)
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/CoreNLP.framework/CoreNLP
softlink:o:path:/System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore
softlink:o:path:/System/Library/PrivateFrameworks/Trial.framework/Trial
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
softlink:o:path:/System/Library/PrivateFrameworks/Montreal.framework/Montreal
LMTrial
LMTrialDataSource
NSObject
experimentId
path
localeIdentifier
fileValue
containsObject:
experimentIdentifiersWithNamespaceName:
refresh
deploymentId
treatmentId
hasPath
levelForFactor:withNamespaceName:
namespaceNameFromId:
postNotificationName:object:
allKeys
addUpdateHandlerForNamespaceName:usingBlock:
removeUpdateHandlerForToken:
objectForKey:
stringWithUTF8String:
dictionaryWithContentsOfFile:
objectForKeyedSubscript:
intValue
hasAsset
defaultCenter
clientWithIdentifier:
stringValue
UTF8String
countByEnumeratingWithState:objects:count:
init
sharedInstance
encodeTrialParameters:
initWithDataSource:
start
encodedTrialParametersForLocale:
handleUpdatedTrialParameters:forLocaleIdentifier:
dataSource
.cxx_destruct
.cxx_construct
trialParametersByLocaleIdentifier
_dataSource
T@"<LMTrialDataSource>",R,V_dataSource
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
startWithParametersUpdateCallback:
loadParametersWithLocaleIdentifier:
notificationCenter
T@"NSNotificationCenter",R
@16@0:8
@72@0:8{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}16
@24@0:8@16
v16@0:8
v80@0:8{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}16r^v72
{map<std::string, std::optional<LM::TrialParameters>, std::less<std::string>, std::allocator<std::pair<const std::string, std::optional<LM::TrialParameters>>>>="__tree_"{__tree<std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::__map_value_compare<std::string, std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::optional<LM::TrialParameters>>>>="__begin_node_"^v"__pair1_"{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::optional<LM::TrialParameters>>, void *>>>="__value_"{__tree_end_node<std::__tree_node_base<void *> *>="__left_"^v}}"__pair3_"{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::optional<LM::TrialParameters>>, std::less<std::string>, true>>="__value_"Q}}}
@"<LMTrialDataSource>"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v48@0:8{function<void (const std::string &, const std::optional<LM::TrialParameters> &)>={__value_func<void (const std::string &, const std::optional<LM::TrialParameters> &)>={type=[24C]}^v}}16
{optional<LM::TrialParameters>=(?=c{TrialParameters={path={basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}}{map<std::string, std::string, std::less<std::string>, std::allocator<std::pair<const std::string, std::string>>>={__tree<std::__value_type<std::string, std::string>, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>, std::allocator<std::__value_type<std::string, std::string>>>=^v{__compressed_pair<std::__tree_end_node<std::__tree_node_base<void *> *>, std::allocator<std::__tree_node<std::__value_type<std::string, std::string>, void *>>>={__tree_end_node<std::__tree_node_base<void *> *>=^v}}{__compressed_pair<unsigned long, std::__map_value_compare<std::string, std::__value_type<std::string, std::string>, std::less<std::string>, true>>=Q}}}})B}24@0:8r^v16
@"NSNotificationCenter"16@0:8
 " & 0 
