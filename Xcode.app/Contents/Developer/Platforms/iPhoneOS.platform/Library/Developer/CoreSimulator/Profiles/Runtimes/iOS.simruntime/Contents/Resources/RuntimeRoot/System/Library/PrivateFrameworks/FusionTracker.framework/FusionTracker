@(#)PROGRAM:FusionTracker  PROJECT:FusionTracker-1
N2ft11KalmanTrackE
NxA@
BUm}BUm
CCXZ
B,%IC
333CUm
BUm}C
::B@
BUm}B
CC,;
C,%IC,%
333CUm}CUm
7T=
=#1A=P
;block8_box/conv_cls_pos/Conv2D
block8_box/conv_cls_neg/Conv2D
block7_box/conv_cls_pos/Conv2D
block7_box/conv_cls_neg/Conv2D
block6_box/conv_cls/Conv2D/q
block9_box/conv_cls/Conv2D/q
block10_box/conv_cls/Conv2D/q
block11_box/conv_cls/Conv2D/q
block8_box/conv_loc/Conv2D/q
block7_box/conv_loc/Conv2D/q
block6_box/conv_loc/Conv2D/q
block9_box/conv_loc/Conv2D/q
block10_box/conv_loc/Conv2D/q
block11_box/conv_loc/Conv2D/q
BUm}BUm
NBUm
B333Cjy[C
333CUm
BUm}C
Bjy[C
BUm}B
B333C33
Bjy[C
333CUm}CUm
Cjy[C
ff&?
>ff&?
ff&?
7>q 
=9{'=4
<block8_box/conv_cls/Conv2D
block7_box/conv_cls/Conv2D
block6_box/conv_cls/Conv2D
block9_box/conv_cls/Conv2D
block10_box/conv_cls/Conv2D
block11_box/conv_cls/Conv2D
block8_box/conv_loc/Conv2D
block7_box/conv_loc/Conv2D
block6_box/conv_loc/Conv2D
block9_box/conv_loc/Conv2D
block10_box/conv_loc/Conv2D
block11_box/conv_loc/Conv2D
block8_box/conv_roll/Conv2D
block7_box/conv_roll/Conv2D
block6_box/conv_roll/Conv2D
block9_box/conv_roll/Conv2D
block10_box/conv_roll/Conv2D
block11_box/conv_roll/Conv2D
block8_box/conv_yaw/Conv2D
block7_box/conv_yaw/Conv2D
block6_box/conv_yaw/Conv2D
block9_box/conv_yaw/Conv2D
block10_box/conv_yaw/Conv2D
block11_box/conv_yaw/Conv2D
NSt3__120__shared_ptr_emplaceIN2ft16CinematicTrackerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft5FrameENS_9allocatorIS2_EEEE
N2ik17PixelBufferTensorE
N2ik6TensorE
N2ik11EspressoNetE
NSt3__120__shared_ptr_emplaceIN2ik4core16EspressoNetStateENS_9allocatorIS3_EEEE
N2ik14InferenceErrorE
NSt3__120__shared_ptr_emplaceIN2ik4core18PixelBufferStorageENS_9allocatorIS3_EEEE
N2ik4core18PixelBufferStorageE
N2ik13TensorStorageE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
N2ik4core14EspressoBinderE
N2ik6BinderE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_emplaceIN2ik4core21EspressoBufferStorageENS_9allocatorIS3_EEEE
N2ik4core21EspressoBufferStorageE
NSt3__117bad_function_callE
@trk
<G_96/Conv_4/Conv2D/q
zDNSt3__120__shared_ptr_emplaceIN2ft11KalmanTrackENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft10ProxyTrackENS_9allocatorIS2_EEEE
N2ft5TrackE
1.7.3
=S>D=
\;conv2d_sm/convolution/q
conv2d_lb/convolution/q
conv2d_rb/convolution/q
conv2d_pitch/convolution/q
conv2d_yaw/convolution/q
conv2d_roll/convolution/q
conv2d_eye/convolution/q
procedure_1
procedure_2
procedure_3
procedure_4
procedure_5
procedure_6
procedure_7
procedure_8
procedure_9
procedure_10
NSt3__120__shared_ptr_pointerIP10__CVBufferPFvS2_ENS_9allocatorIS1_EEEE
PFvP10__CVBufferE
N2ft10ProxyTrackE
N2ft20SiameseRpnStageErrorE
attr
?ffffff
?ffffff
7R=]
o->f
BoxEncoding_0/Conv2D/q
BoxEncoding_1/Conv2D/q
BoxEncoding_2/Conv2D/q
BoxEncoding_3/Conv2D/q
BoxEncoding_4/Conv2D/q
BoxEncoding_5/Conv2D/q
ClassPredictor_0/Conv2D/q
ClassPredictor_1/Conv2D/q
ClassPredictor_2/Conv2D/q
ClassPredictor_3/Conv2D/q
ClassPredictor_4/Conv2D/q
ClassPredictor_5/Conv2D/q
?ff&?ff&?ff&?ff&?ff&?
,_?33s?33s?33s?33s?33s?
Prior time step not established.
Frame has invalid timestamp.
kalman
preProcess
acattrnode.cpp
numFaces <= 10
bmBufferDequantizeInt8
bmbufferprivate.h
input.pixelFormat == kBmBufferPixelFormatType_Int8
input.height == output.height
input.width == output.width
bmBufferDequantizeUInt8
input.pixelFormat == kBmBufferPixelFormatType_UInt8
bmBufferPixelAtFloat
x < buf.width && y < buf.height
bmBufferPixelSize
false
ttDetCategoryFromIsp
ttdetrect.cpp
cat < CISP_TT_DET_CATEGORY_COUNT
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
acCropResizeGenerateConfig
accropresize.cpp
!(dstWidth & 0x01) && !(dstHeight & 0x01)
srcPyrInfo.numLevels <= 4
pyrInd == 0 || srcPyrInfo.widths[pyrInd] <= srcPyrInfo.widths[pyrInd - 1]
pyrInd == 0 || srcPyrInfo.heights[pyrInd] <= srcPyrInfo.heights[pyrInd - 1]
xStartY < srcPyrInfo.widths[crop.pyrIndex]
yStartY < srcPyrInfo.heights[crop.pyrIndex]
init
acdetnode.cpp
count
m_config.fmBboxCounts[scaleInd]
bboxBufChCount
state.magic == 0xde71
classBufChCount
classPosBufChCount
classNegBufChCount
rollBufChCount
yawBufChCount
getClsBufferInds
posInd != ((uint32_t)-1)
negInd != ((uint32_t)-1)
acDetCategoryToIsp
cat != kAcDetCategory_Background
cat < kAcDetCategoryMax
acAttrReduceSmile
acattrreduce.cpp
smileThreshold <= 100
acAttrReduceBlink
(*netOutput).height >= kOutputCount
blinkThreshold <= 100
occludedThreshold <= 100
acAttrReduceYaw
numBins <= 10
acAttrReduceRoll
acDetRectSmallRectSuppression
acdetrect.cpp
sortedRects[justSelected].score >= sortedRects[check].score
remaining <= check
acDetRectLowMergeCountSuppression
acDetRectWeightedMerge
rects
acDetCategoryFromIsp
cat < CISP_AC_DET_CATEGORY_COUNT
instancePostProcess
tttrkrpnnode.cpp
netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Half || netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Float
setUpNetBuffers
ptr - (const uint8_t*)netBufferPtrs.instanceCrop == params.instanceCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.exemplarCrop == params.exemplarCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.templateKernels[i] == params.templateNetOutBatchBytes[i]
ptr - (const uint8_t*)netBufferPtrs.xcorrOutputs[i] == params.xcorrNetOutBatchBytes[i]
bmBufferDequantizeHalf
input.pixelFormat == kBmBufferPixelFormatType_Half
output.pixelFormat == kBmBufferPixelFormatType_Float
identifier
objectKind
lastDetectionTime
boxConfidence
detectionConfidence
lastTappedTime
isHighPriority
sourceObservationId
isTapSpawned
metadata
sourceFrameTimestamp
tracks
mostRecentTapTime
detectorDidRun
SiameseRPN at invalid stage: 
subject_tracking_initializer_v2
image
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
subject_tracking_tracker_v2
instance_image
regress_adjust
classification_x_corr
None
Initialize
Track
TapToBox
Unknown
Track not yet initialized.
Observation timestamp does not match frame timestamp.
map::at:  key not found
v8@?0
com.apple.FusionTracker
default
com.apple.coremedia
enable_tap_to_track_overlap_with_isp_mitigation
ttt_rpn_precision_level
simResizeVisPipeBinning
simresizevispipe.cpp
startX == 0.0f && startY == 0.0f
xStep == 1 || xStep == 2 || xStep == 4 || xStep == 8
yStep == 1 || yStep == 2 || yStep == 4 || yStep == 8
simResizeVisPipe
scaleX <= ISP_RESIZE_MAX_SCALE && scaleY <= ISP_RESIZE_MAX_SCALE
scaleX >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE && scaleY >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE
(scaleX <= 1 && scaleY <= 1) || (method != SimResizeVisPipeMethod::Area)
output.width <= ISP_RESIZE_MAX_WIDTH
output.height <= ISP_RESIZE_MAX_HEIGHT
bmBufferPixelAtUInt16
inputHandler
input.rowBytes % sizeof(uint16_t) == 0
input.rowBytes == shiftedInput.rowBytes
input.width == shiftedInput.width
input.height == shiftedInput.height
input.pixelFormat == shiftedInput.pixelFormat
input.pixelFormat == kBmBufferPixelFormatType_UInt16
outputHandler
output.rowBytes % sizeof(uint16_t) == 0
acNonMaxSuppression
acnonmaxsuppression.cpp
__null != rects
acCrossClassSuppression
acNonMaxSuppressionSmallbox
acRemoveOverlapBoxes
numRects <= tempBytes
Detector post processing
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
+N9mZUAHooNvMiQnjeTJ8g
Error encountered during: 
 [espresso error: 
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Null CVPixelBuffer encountered.
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
Unknown data type
Unsupported CVPixelBuffer type: 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Model has no pre-declared outputs.
Unsupported image buffer type
Binding vImage_Buffer
Binding CVPixelBuffer
Binding espresso_buffer_t
Binding output buffer
Unsupported tensor rank: 
Unsupported espresso type encountered.
Unpacking tensor shape
Detector op failed: 
 / internal code = 
unordered_map::at: key not found
Get detector params
Incorrect data type requested.
Expected a rank 4 NCHW tensor.
bmBufferResizeCHW
bmbuffergeometry.cpp
bmBufferPartialResizeCHW
bmBufferResizeCoordConvert
pad < kBmBufferResizePadMax
srcW && srcH && dstW && dstH
bmBufferResizeCoordConvertReversed
bmBufferResize2xCHW
dst.pixelFormat == src.pixelFormat
src.pixelFormat == kBmBufferPixelFormatType_Int8
srcViewHeight * numChannels == src.height
dstViewHeight * numChannels == dst.height
bmBufferPixelAtInt8
bmBufferResize2xSingleChannelCHW
src.height > 0
dst.width == src.width * 2
dst.height == src.height * 2
bmBufferResizeBicubicCHW
bmBufferResizeBicubicSingleChannelCHW
src.width && src.height
dst.width >= src.width
dst.height >= src.height
src.pixelFormat == kBmBufferPixelFormatType_Float
dst.pixelFormat == kBmBufferPixelFormatType_Float
bmArgMax
bmmath.cpp
Unknown track type encountered: 
proxy
Expected exactly one input image. Found: %zd instead.
/System/Library/ImagingNetworks
/System/Library/PrivateFrameworks/Celestial.framework
com.apple.Celestial
classifiers
.espresso.net
B24@?0@"NSString"8@"NSDictionary"16
q24@?0@"NSString"8@"NSString"16
.net
Predict called before initialization
Failed to create IOSurface-backed CVPixelBuffer.
Failed to create pixel buffer pool. Status = 
Failed to create pixel buffer. Status = 
ttNonMaxSuppression
ttnonmaxsuppression.cpp
ttNonMaxSuppression2
ttNonMaxSuppressionSmallbox
ttRemoveOverlapBoxes
simResizeBGRA8888AccelerateFramework
simresize.cpp
dstViewWidth <= dstWidth
dstViewHeight <= dstHeight
simImageChMeanGetTempBuffers
numTempBytes >= bs.totalBytes()
append
bmmixedbufsize.h
!m_nextChunkOffset
nextChunk
m_nextChunkOffset <= m_totalBytes
Exemplar pre-processing
Fetching exemplar ROI
Exemplar post-processing
Instance pre-processing
Fetching instance ROI
Instance post-processing
Expected to be in stage 
. Curent stage instead: 
SiameseRpn op failed: 
Tracker handle creation
Get tracker params
espresso.net
input_color_image
input_tap_image
prediction
tap_to_box_v2_fp16
addToHeap
ttHeap.cpp
heap->magic == 0x12345678
removeFromHeap
acDetBboxCoderDecodeAll
acdetbboxcoder.cpp
7 == config.categoryCount || 5 == config.categoryCount
config.posChannelCounts[layerInd] > 0
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Int8
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Int8
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Int8
rollBuf.pixelFormat == kBmBufferPixelFormatType_Int8
yawBuf.pixelFormat == kBmBufferPixelFormatType_Int8
layerHeight * numLogitsUniPosChs == logitsUniPosBuf->height
logitsUniPosBuf->width == offsetsBuf.width
layerHeight * numDefaults * 4 == offsetsBuf.height
globalDefaultBoxInd < defaultBoxWidthsHeightsLen
outBoxInd < maxOutBoxes
acDetBboxCoderDecodeAllFloat
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Float
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Float
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Float
rollBuf.pixelFormat == kBmBufferPixelFormatType_Float
yawBuf.pixelFormat == kBmBufferPixelFormatType_Float
logitsUniPosStride * (uint32_t)sizeof(float) == layerHeight * logitsUniPosBuf->rowBytes
acDetBboxCoderPoseDegrees
predictions.width == numPoseBins
bmMunkres
bmmunkres.cpp
size > 0
maxMatches >= size
xi != 0
bmMunkresGetTempBuffers
tempBuffers
bmMunkresMaxAssignmentsGetTempBuffers
bmMunkresSubtractMinPerRow
rowMin >= 0
minCol < costBuf.height
bmMunkresSubtractMinPerCol
colMin >= 0
minRow < costBuf.width
bmMunkresMaxAssignments
temp
0 <= aCol[r]
bmMunkresUpdateCost
rowLineFlags != nullptr
colLineFlags != nullptr
MSR not available on current platform.
Unable to locate model: 
Tracking result was nil.
Unexpected number of tracks detected. Expected at most one. Found: 
Tracking state was nil.
High priority tracking state was nil.
Invalid high priority tracking op encountered: 
Color buffer preprocessing failed
Exemplar preprocessing failed.
Tracker preprocessing failed.
No active tracking session present.
Instance preprocessing failed.
Instance post-processing failed.
0000000
Tap-to-track det
ttDetCategoryToIsp
ttdetnode.cpp
cat != kTtDetCategory_Background
cat < kTtDetCategoryMax
ttAssocSetUpMunkresCost
ttassoc.cpp
costBufLen >= costMatSize * costMatSize
ttAssocCore
unmatchedDetObjectCount < unmatchedDetObjectsLen
ti < numTrkObjects
ttAssocTrkDetGetTempBuffers
ttAssocObjectRemoveKilled
minKillLevel > kTtAssocObjectKillFlag_None
ttAssocTrkDet
numTrkObjects <= maxTrkObjects
numDetObjects <= maxTrkObjects
tempBufBytes >= ttAssocTrkDetTempBytes(maxTrkObjects)
isDetRunningThisFrame || !numDetObjects
costMatSize * costMatSize <= maxTrkObjects * maxTrkObjects
ki >= n
i == 0 || trkObjects[ti].age <= trkObjects[killTemp[i - 1].index].age
trkObjects[ti].killFlag == kTtAssocObjectKillFlag_Maybe
numTrkObjects - trkKillCount + unmatchedDetObjectCount <= maxTrkObjects
newNumTrkObjects < maxTrkObjects
TtAssocObjectRemoveOldOverlapObjects
trkObjects->objects[justSelected].age <= trkObjects->objects[check].age
bmBufferPixelAtUInt8
RPN score cutoff set to %0.4f
Requested source rect is invalid.
Post processing invoked multiple times.
Internal inconsistency: high priority track missing during tracking update.
Operation requested for high priority tracking not completed.
Invalid commit token. State: %llu, Tracker: %llu.
Internal inconsistency: observation index out of bounds: %zd
A previous tracking state has not been committed.
FusionTracker error: %s
Internal inconsistency: detection-less track is not high-priority.
Terminating detectionless track. IoU exceeded: %0.2f > %0.2f
RPN Precision Level set to %d (defaults value: %d)
Encountered an error during: %s
 -> Espresso Error: %s
Bipartite matching exception: %s
Observation ID has internal track mask set.
Duplicate track ID provided in observation: %lld
TapToBox prediction below threshold.
Network not found: %s
Tap buffer size mismatch.
Failed to get tap buffer base address.
Tap coordinates are out of bounds.
TapToBox tap rendering failed.
TapToBox preprocessing resample failed.
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_DestinationRectangle
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_ScalingMode to 'kVTScalingMode_CropSourceToCleanAperture'
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_SourceCropRectangle
FTVTScaler error: VTPixelTransferSessionTransferImage failed
FTVTScaler error: dstBuffer has unsupported pixelformat. Mean computation only supported for dstBuffer formats: 'kCVPixelFormatType_32BGRA'
MSR preprocessing failed.
SiameseRPN exemplar network loaded: %s
SiameseRPN instance network loaded: %s
FTCinematicTapToTrack error: %s
FTCinematicTrack
NSSecureCoding
NSCoding
FTCinematicTapRequest
FTCinematicTapResponse
FTCinematicTrackingResult
FTCinematicHighPriorityTrackerState
FTCinematicTrackingState
FTCinematicInput
FTCinematicTracker
FTCinematicConfig
FTBipartiteMatcher
FTImageTensorDescriptor
FTTensorReference
FTNetworkDescriptor
FTEspressoBuffer
FTUtils
FTTapToBox
FTVTScaler
FTScaling
FTTapToTrackPreprocessor
FTCinematicTapToTrack
init
setLastTappedTime:
decodeInt64ForKey:
fusionTracker_decodeCGRectForKey:
fusionTracker_decodeCMTimeForKey:
decodeFloatForKey:
decodeBoolForKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
encodeInt64:forKey:
fusionTracker_encodeCMTime:forKey:
encodeFloat:forKey:
encodeBool:forKey:
fusionTracker_encodeCGRect:forKey:
encodeObject:forKey:
setIdentifier:
setBox:
setObjectKind:
setLastDetectionTime:
setBoxConfidence:
setDetectionConfidence:
setIsHighPriority:
setSourceObservationId:
supportsSecureCoding
fromTrack:isHighPriority:
encodeWithCoder:
initWithCoder:
TB,R
identifier
objectKind
lastDetectionTime
boxConfidence
detectionConfidence
lastTappedTime
metadata
setMetadata:
isTapSpawned
setIsTapSpawned:
isHighPriority
sourceObservationId
.cxx_destruct
_isTapSpawned
_isHighPriority
_boxConfidence
_detectionConfidence
_identifier
_objectKind
_metadata
_sourceObservationId
_lastDetectionTime
_lastTappedTime
_box
Tq,N,V_identifier
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
TQ,N,V_objectKind
T{?=qiIq},N,V_lastDetectionTime
Tf,N,V_boxConfidence
Tf,N,V_detectionConfidence
T{?=qiIq},N,V_lastTappedTime
T@"NSDictionary",&,N,V_metadata
TB,N,V_isTapSpawned
TB,N,V_isHighPriority
TQ,V_sourceObservationId
setTapPoint:
setTrackId:
tapPoint
trackId
_trackId
_tapPoint
T{CGPoint=dd},N,V_tapPoint
Tq,N,V_trackId
request
setRequest:
wasSuccessful
setWasSuccessful:
tappedTrack
setTappedTrack:
_wasSuccessful
_request
_tappedTrack
T@"FTCinematicTapRequest",&,N,V_request
TB,N,V_wasSuccessful
T@"FTCinematicTrack",&,N,V_tappedTrack
setSourceFrameTimestamp:
setMostRecentTapTime:
setDetectorDidRun:
sourceFrameTimestamp
tracks
setTracks:
mostRecentTapTime
detectorDidRun
tapResponse
setTapResponse:
_detectorDidRun
_tracks
_tapResponse
_sourceFrameTimestamp
_mostRecentTapTime
T{?=qiIq},N,V_sourceFrameTimestamp
T@"NSArray",&,N,V_tracks
T{?=qiIq},N,V_mostRecentTapTime
TB,N,V_detectorDidRun
T@"FTCinematicTapResponse",&,N,V_tapResponse
_setup
_setupOp
_setupSessionStorage
setSessionStorage:
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:
exemplarInputRoiForTargetRect:
_unsafeMeanFillAndScaleSourceBuffer:destinationBuffer:sourceRect:meanPixel:scaler:
instanceInputRoi
_validatePostProcessingInvocation
_updateHighPriorityTrackWithRect:confidence:isTapToTrack:
initWithTracker:frame:
targetRect
preProcessExemplarInputFromSourceBuffer:toDestinationBuffer:forTargetRect:meanPixel:scaler:
preProcessInstanceInputFromSourceBuffer:toDestinationBuffer:meanPixel:scaler:
postProcessExemplarOutputs:forTargetRect:
postProcessInstanceOutputs:
abort
completed
opDescription
sessionStorage
setOp:
setTargetRect:
.cxx_construct
_tracker
_frame
_isTapToTrack
_finalized
_sessionStorage
_targetRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_targetRect
Tq,N,V_op
T@"NSMutableDictionary",&,N,V_sessionStorage
arrayWithCapacity:
input
observations
count
objectAtIndexedSubscript:
addObject:
tapRequest
countByEnumeratingWithState:objects:count:
stateWithTracker:frame:input:
commit
highPriorityTrackerState
_commitToken
_isTapToTrackOverlapWithIspMitigationEnabled
_highPriorityTrackerState
_input
T@"FTCinematicHighPriorityTrackerState",R,N,V_highPriorityTrackerState
T@"FTCinematicInput",R,N,V_input
setHighPriorityTrackId:
setTapPosition:
confidence
frameTimestamp
lastDetectionTimestamp
mapToInternalObservations
tapPosition
setTapRequest:
setObservations:
highPriorityTrackId
_tapRequest
_observations
_highPriorityTrackId
_tapPosition
T{CGPoint=dd},N,V_tapPosition
T@"FTCinematicTapRequest",&,N,V_tapRequest
T@"NSArray",&,N,V_observations
Tq,N,V_highPriorityTrackId
ensureObservationTimestampMatchesFrame
setName:
bgraSquareImageWithName:size:
setInputImages:
setOutputNames:
highPriorityExemplarNetworkDescriptor
name
setSourceNetworkName:
setSourceOutputName:
setDestinationInputName:
setInputReferences:
networkDescriptor
highPriorityInstanceNetworkDescriptor
tapToBoxNetworkDescriptor
initWithConfig:
computeTrackingStateForInput:
setEnsureObservationTimestampMatchesFrame:
setAllowTrackPromotion:
allowTrackPromotion
_ensureObservationTimestampMatchesFrame
_allowTrackPromotion
TB,N,V_ensureObservationTimestampMatchesFrame
TB,N,V_allowTrackPromotion
objectForKeyedSubscript:
buffer
UTF8String
initWithSuiteName:
boolForKey:
integerForKey:
initWithInitialSize:
initWithCapacity:
numberWithLongLong:
computeMatchingForCostMatrix:withRowCount:columnCount:
_optimizer
setSize:
setPixelFormat:
descriptorWithName:size:pixelFormat:
bgraImageWithName:size:
pixelFormat
size
_pixelFormat
_name
_size
T@"NSString",&,N,V_name
TI,N,V_pixelFormat
T{CGSize=dd},N,V_size
sourceNetworkName
sourceOutputName
destinationInputName
_sourceNetworkName
_sourceOutputName
_destinationInputName
T@"NSString",&,N,V_sourceNetworkName
T@"NSString",&,N,V_sourceOutputName
T@"NSString",&,N,V_destinationInputName
inputImages
firstObject
onlyImageInput
inputReferences
outputNames
_inputImages
_inputReferences
_outputNames
T@"NSArray",&,N,V_inputImages
T@"NSArray",&,N,V_inputReferences
T@"NSArray",&,N,V_outputNames
bufferWithEspressoBuffer:
_buffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},R,N,V_buffer
bundleWithIdentifier:
bundleWithPath:
bundleForClass:
defaultManager
contentsOfDirectoryAtPath:error:
array
hasSuffix:
stringByAppendingPathComponent:
stringByAppendingString:
lastPathComponent
hasPrefix:
predicateWithBlock:
filteredArrayUsingPredicate:
stringWithFormat:
containsString:
compare:options:
sortedArrayUsingComparator:
pathsForResourcesOfType:inDirectory:
dictionaryWithObjects:forKeys:count:
dictionary
numberWithUnsignedLong:
setValue:forKey:
stringWithUTF8String:
networkPath
objectAtIndex:
preprocessForTap:inSourceImageBuffer:destinationImageBuffer:tapBuffer:scaler:
postProcessNetworkOutput:
defaultConfidenceThreshold
predictionForTap:inBuffer:scaler:
pathForResource:ofType:
networkInputImageSize
networkInputTapImageSize
renderTap:inBuffer:
predictBoxForTap:inBuffer:scaler:
_net
_inputImageTensor
_inputTapTensor
_inputMap
_outputTensor
device
initWithDevice:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setUsage:
newTextureWithDescriptor:
dealloc
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:mean:
newTextureWithDescriptor:iosurface:plane:
commandBuffer
encodeToCommandBuffer:sourceTexture:destinationTexture:
waitUntilCompleted
getBytes:bytesPerRow:fromRegion:mipmapLevel:
initWithCommandQueue:
_device
_commandQueue
_meanFilter
_meanTexture
_transferSession
initWithScaler:
preprocessBuffer:
bgraPixelBuffer
meanPixel
_intermediateBuffer
_meanPixel
_scaler
initWithEspressoEngine:scalingBackend:commandQueue:
_setupScalerWithBackend:
_setupNetworksWithEngine:
_resolveNetworkPath:
_espressoConfigFromDescriptor:engine:
_preprocessBuffer:andValidateState:isOp:
_maybeFetchTrackByCommittingState:
_unsafeStartTrackingRect:colorBuffer:
_unsafeStepTrackingWithFrame:
trackerWithCommandQueue:
predictRectForPoint:inColorBuffer:
startTrackingRect:colorBuffer:
stepTrackingWithFrame:
reset
isTrackingActive
_preprocessor
_exemplarNetDesc
_instanceNetDesc
_exemplarNet
_instanceNet
_exemplarCrop
_instanceCrop
_tapToBox
dictionaryWithCapacity:
setObject:forKeyedSubscript:
B16@0:8
@36@0:8{shared_ptr<ft::Track>=^{Track}^{__shared_weak_count}}16B32
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
q16@0:8
v24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q16@0:8
v24@0:8Q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
f16@0:8
v20@0:8f16
v20@0:8B16
v16@0:8
@"NSDictionary"
{?="value"q"timescale"i"flags"I"epoch"q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"FTCinematicTapRequest"
@"FTCinematicTrack"
@"NSArray"
@"FTCinematicTapResponse"
@48@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B76@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}3264@68
B44@0:8^{__CVBuffer=}16^{__CVBuffer=}2432@36
B60@0:8{Rect<double>=dddd}16d48B56
B56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B24@0:8@16
{shared_ptr<ft::CinematicTracker>="__ptr_"^{CinematicTracker}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<ft::Frame>="__ptr_"^{Frame}"__cntrl_"^{__shared_weak_count}}
@"NSMutableDictionary"
@56@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32@48
@"FTCinematicHighPriorityTrackerState"
@"FTCinematicInput"
{vector<ft::Observation, std::allocator<ft::Observation>>=^{Observation}^{Observation}{__compressed_pair<ft::Observation *, std::allocator<ft::Observation>>=^{Observation}}}16@0:8
@24@0:8Q16
@40@0:8r^f16Q24Q32
{unique_ptr<ft::HungarianMatcher, std::default_delete<ft::HungarianMatcher>>="__ptr_"{__compressed_pair<ft::HungarianMatcher *, std::default_delete<ft::HungarianMatcher>>="__value_"^{HungarianMatcher}}}
@44@0:8@16{CGSize=dd}24I40
@40@0:8@16{CGSize=dd}24
@32@0:8@16d24
I16@0:8
v20@0:8I16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
@"NSString"
{CGSize="width"d"height"d}
@184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v48@0:8{?=qiIq}16@40
{?=qiIq}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B64@0:8{CGPoint=dd}16^{__CVBuffer=}32^{__CVBuffer=}40^{__CVBuffer=}48@56
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
d16@0:8
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{unique_ptr<ik::EspressoNet, std::default_delete<ik::EspressoNet>>="__ptr_"{__compressed_pair<ik::EspressoNet *, std::default_delete<ik::EspressoNet>>="__value_"^{EspressoNet}}}
{PixelBufferTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
{unordered_map<std::string, ik::Tensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, ik::Tensor>>>="__table_"{__hash_table<std::__hash_value_type<std::string, ik::Tensor>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, ik::Tensor>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{EspressoTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
B96@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
B104@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64^96
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageStatisticsMean"
@"<MTLTexture>"
^{OpaqueVTPixelTransferSession=}
B24@0:8^{__CVBuffer=}16
^{__CVBuffer=}16@0:8
16@0:8
{shared_ptr<__CVBuffer>="__ptr_"^{__CVBuffer}"__cntrl_"^{__shared_weak_count}}
@"<FTScaling>"
@32@0:8i16i20@24
v20@0:8i16
v24@0:8r^v16
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}24@0:8@16
{EspressoConfig={vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}{optional<espresso_engine_t>=(?=ci)B}iii{optional<espresso_plan_priority_t>=(?=ci)B}{optional<void *>=(?=c^v)B}{unordered_map<std::string, espresso_simple_image_preprocessing_params_t, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, espresso_simple_image_preprocessing_params_t>>>={__hash_table<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=QQ*}{__short=(?=Cc)[23c]}{__raw=[3Q]})}}}}32@0:8@16r^v24
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
v40@0:8^{__CVBuffer=}16@24q32
B56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8^{__CVBuffer=}16
@"FTTapToTrackPreprocessor"
@"FTNetworkDescriptor"
@"FTTapToBox"
@"FTCinematicTracker"
@(#)PROGRAM:FusionTracker  PROJECT:FusionTracker-1
?N2ft11KalmanTrackE
NxA@
BUm}BUm
CCXZ
B,%IC
333CUm
BUm}C
::B@
BUm}B
CC,;
C,%IC,%
333CUm}CUm
7T=
=#1A=P
;block8_box/conv_cls_pos/Conv2D
block8_box/conv_cls_neg/Conv2D
block7_box/conv_cls_pos/Conv2D
block7_box/conv_cls_neg/Conv2D
block6_box/conv_cls/Conv2D/q
block9_box/conv_cls/Conv2D/q
block10_box/conv_cls/Conv2D/q
block11_box/conv_cls/Conv2D/q
block8_box/conv_loc/Conv2D/q
block7_box/conv_loc/Conv2D/q
block6_box/conv_loc/Conv2D/q
block9_box/conv_loc/Conv2D/q
block10_box/conv_loc/Conv2D/q
block11_box/conv_loc/Conv2D/q
BUm}BUm
NBUm
B333Cjy[C
333CUm
BUm}C
Bjy[C
BUm}B
B333C33
Bjy[C
333CUm}CUm
Cjy[C
ff&?
>ff&?
ff&?
7>q 
=9{'=4
<block8_box/conv_cls/Conv2D
block7_box/conv_cls/Conv2D
block6_box/conv_cls/Conv2D
block9_box/conv_cls/Conv2D
block10_box/conv_cls/Conv2D
block11_box/conv_cls/Conv2D
block8_box/conv_loc/Conv2D
block7_box/conv_loc/Conv2D
block6_box/conv_loc/Conv2D
block9_box/conv_loc/Conv2D
block10_box/conv_loc/Conv2D
block11_box/conv_loc/Conv2D
block8_box/conv_roll/Conv2D
block7_box/conv_roll/Conv2D
block6_box/conv_roll/Conv2D
block9_box/conv_roll/Conv2D
block10_box/conv_roll/Conv2D
block11_box/conv_roll/Conv2D
block8_box/conv_yaw/Conv2D
block7_box/conv_yaw/Conv2D
block6_box/conv_yaw/Conv2D
block9_box/conv_yaw/Conv2D
block10_box/conv_yaw/Conv2D
block11_box/conv_yaw/Conv2D
NSt3__120__shared_ptr_emplaceIN2ft16CinematicTrackerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft5FrameENS_9allocatorIS2_EEEE
N2ik17PixelBufferTensorE
N2ik6TensorE
N2ik11EspressoNetE
NSt3__120__shared_ptr_emplaceIN2ik4core16EspressoNetStateENS_9allocatorIS3_EEEE
N2ik14InferenceErrorE
NSt3__120__shared_ptr_emplaceIN2ik4core18PixelBufferStorageENS_9allocatorIS3_EEEE
N2ik4core18PixelBufferStorageE
N2ik13TensorStorageE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
N2ik4core14EspressoBinderE
N2ik6BinderE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_emplaceIN2ik4core21EspressoBufferStorageENS_9allocatorIS3_EEEE
N2ik4core21EspressoBufferStorageE
NSt3__117bad_function_callE
<G_96/Conv_4/Conv2D/q
zDNSt3__120__shared_ptr_emplaceIN2ft11KalmanTrackENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft10ProxyTrackENS_9allocatorIS2_EEEE
N2ft5TrackE
1.7.3
=S>D=
\;conv2d_sm/convolution/q
conv2d_lb/convolution/q
conv2d_rb/convolution/q
conv2d_pitch/convolution/q
conv2d_yaw/convolution/q
conv2d_roll/convolution/q
conv2d_eye/convolution/q
procedure_1
procedure_2
procedure_3
procedure_4
procedure_5
procedure_6
procedure_7
procedure_8
procedure_9
procedure_10
NSt3__120__shared_ptr_pointerIP10__CVBufferPFvS2_ENS_9allocatorIS1_EEEE
PFvP10__CVBufferE
N2ft10ProxyTrackE
N2ft20SiameseRpnStageErrorE
attr
7R=]
o->f
BoxEncoding_0/Conv2D/q
BoxEncoding_1/Conv2D/q
BoxEncoding_2/Conv2D/q
BoxEncoding_3/Conv2D/q
BoxEncoding_4/Conv2D/q
BoxEncoding_5/Conv2D/q
ClassPredictor_0/Conv2D/q
ClassPredictor_1/Conv2D/q
ClassPredictor_2/Conv2D/q
ClassPredictor_3/Conv2D/q
ClassPredictor_4/Conv2D/q
ClassPredictor_5/Conv2D/q
?ff&?ff&?ff&?ff&?ff&?
,_?33s?33s?33s?33s?33s?
Prior time step not established.
Frame has invalid timestamp.
kalman
preProcess
acattrnode.cpp
numFaces <= 10
bmBufferDequantizeInt8
bmbufferprivate.h
input.pixelFormat == kBmBufferPixelFormatType_Int8
input.height == output.height
input.width == output.width
bmBufferDequantizeUInt8
input.pixelFormat == kBmBufferPixelFormatType_UInt8
bmBufferPixelAtFloat
x < buf.width && y < buf.height
bmBufferPixelSize
false
ttDetCategoryFromIsp
ttdetrect.cpp
cat < CISP_TT_DET_CATEGORY_COUNT
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
acCropResizeGenerateConfig
accropresize.cpp
!(dstWidth & 0x01) && !(dstHeight & 0x01)
srcPyrInfo.numLevels <= 4
pyrInd == 0 || srcPyrInfo.widths[pyrInd] <= srcPyrInfo.widths[pyrInd - 1]
pyrInd == 0 || srcPyrInfo.heights[pyrInd] <= srcPyrInfo.heights[pyrInd - 1]
xStartY < srcPyrInfo.widths[crop.pyrIndex]
yStartY < srcPyrInfo.heights[crop.pyrIndex]
init
acdetnode.cpp
count
m_config.fmBboxCounts[scaleInd]
bboxBufChCount
state.magic == 0xde71
classBufChCount
classPosBufChCount
classNegBufChCount
rollBufChCount
yawBufChCount
getClsBufferInds
posInd != ((uint32_t)-1)
negInd != ((uint32_t)-1)
acDetCategoryToIsp
cat != kAcDetCategory_Background
cat < kAcDetCategoryMax
acAttrReduceSmile
acattrreduce.cpp
smileThreshold <= 100
acAttrReduceBlink
(*netOutput).height >= kOutputCount
blinkThreshold <= 100
occludedThreshold <= 100
acAttrReduceYaw
numBins <= 10
acAttrReduceRoll
acDetRectSmallRectSuppression
acdetrect.cpp
sortedRects[justSelected].score >= sortedRects[check].score
remaining <= check
acDetRectLowMergeCountSuppression
acDetRectWeightedMerge
rects
acDetCategoryFromIsp
cat < CISP_AC_DET_CATEGORY_COUNT
instancePostProcess
tttrkrpnnode.cpp
netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Half || netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Float
setUpNetBuffers
ptr - (const uint8_t*)netBufferPtrs.instanceCrop == params.instanceCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.exemplarCrop == params.exemplarCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.templateKernels[i] == params.templateNetOutBatchBytes[i]
ptr - (const uint8_t*)netBufferPtrs.xcorrOutputs[i] == params.xcorrNetOutBatchBytes[i]
bmBufferDequantizeHalf
input.pixelFormat == kBmBufferPixelFormatType_Half
output.pixelFormat == kBmBufferPixelFormatType_Float
identifier
objectKind
lastDetectionTime
boxConfidence
detectionConfidence
lastTappedTime
isHighPriority
sourceObservationId
isTapSpawned
metadata
sourceFrameTimestamp
tracks
mostRecentTapTime
detectorDidRun
SiameseRPN at invalid stage: 
subject_tracking_initializer_v2
image
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
subject_tracking_tracker_v2
instance_image
regress_adjust
classification_x_corr
None
Initialize
Track
TapToBox
Unknown
Track not yet initialized.
Observation timestamp does not match frame timestamp.
map::at:  key not found
v8@?0
com.apple.FusionTracker
default
com.apple.coremedia
enable_tap_to_track_overlap_with_isp_mitigation
ttt_rpn_precision_level
simResizeVisPipeBinning
simresizevispipe.cpp
startX == 0.0f && startY == 0.0f
xStep == 1 || xStep == 2 || xStep == 4 || xStep == 8
yStep == 1 || yStep == 2 || yStep == 4 || yStep == 8
simResizeVisPipe
scaleX <= ISP_RESIZE_MAX_SCALE && scaleY <= ISP_RESIZE_MAX_SCALE
scaleX >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE && scaleY >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE
(scaleX <= 1 && scaleY <= 1) || (method != SimResizeVisPipeMethod::Area)
output.width <= ISP_RESIZE_MAX_WIDTH
output.height <= ISP_RESIZE_MAX_HEIGHT
bmBufferPixelAtUInt16
inputHandler
input.rowBytes % sizeof(uint16_t) == 0
input.rowBytes == shiftedInput.rowBytes
input.width == shiftedInput.width
input.height == shiftedInput.height
input.pixelFormat == shiftedInput.pixelFormat
input.pixelFormat == kBmBufferPixelFormatType_UInt16
outputHandler
output.rowBytes % sizeof(uint16_t) == 0
acNonMaxSuppression
acnonmaxsuppression.cpp
__null != rects
acCrossClassSuppression
acNonMaxSuppressionSmallbox
acRemoveOverlapBoxes
numRects <= tempBytes
offsets_0
offsets_1
offsets_2
offsets_3
offsets_4
offsets_5
logits_roll_0
logits_roll_1
logits_roll_2
logits_roll_3
logits_roll_4
logits_roll_5
logits_yaw_0
logits_yaw_1
logits_yaw_2
logits_yaw_3
logits_yaw_4
logits_yaw_5
Detector post processing
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
+N9mZUAHooNvMiQnjeTJ8g
Error encountered during: 
 [espresso error: 
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Null CVPixelBuffer encountered.
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
Unknown data type
Unsupported CVPixelBuffer type: 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Model has no pre-declared outputs.
Executing plan
Unsupported image buffer type
Binding vImage_Buffer
Binding CVPixelBuffer
Binding espresso_buffer_t
Binding output buffer
Unsupported tensor rank: 
Unsupported espresso type encountered.
Unpacking tensor shape
Detector op failed: 
 / internal code = 
unordered_map::at: key not found
Create detector
Start detector
Get detector params
Incorrect data type requested.
Expected a rank 4 NCHW tensor.
bmBufferResizeCHW
bmbuffergeometry.cpp
bmBufferPartialResizeCHW
bmBufferResizeCoordConvert
pad < kBmBufferResizePadMax
srcW && srcH && dstW && dstH
bmBufferResizeCoordConvertReversed
bmBufferResize2xCHW
dst.pixelFormat == src.pixelFormat
src.pixelFormat == kBmBufferPixelFormatType_Int8
srcViewHeight * numChannels == src.height
dstViewHeight * numChannels == dst.height
bmBufferPixelAtInt8
bmBufferResize2xSingleChannelCHW
src.height > 0
dst.width == src.width * 2
dst.height == src.height * 2
bmBufferResizeBicubicCHW
bmBufferResizeBicubicSingleChannelCHW
src.width && src.height
dst.width >= src.width
dst.height >= src.height
src.pixelFormat == kBmBufferPixelFormatType_Float
dst.pixelFormat == kBmBufferPixelFormatType_Float
bmArgMax
bmmath.cpp
Unknown track type encountered: 
proxy
Expected exactly one input image. Found: %zd instead.
/System/Library/ImagingNetworks
/System/Library/PrivateFrameworks/Celestial.framework
com.apple.Celestial
classifiers
.espresso.net
B24@?0@"NSString"8@"NSDictionary"16
q24@?0@"NSString"8@"NSString"16
.net
Predict called before initialization
Failed to create IOSurface-backed CVPixelBuffer.
Failed to create pixel buffer pool. Status = 
Failed to create pixel buffer. Status = 
ttNonMaxSuppression
ttnonmaxsuppression.cpp
ttNonMaxSuppression2
ttNonMaxSuppressionSmallbox
ttRemoveOverlapBoxes
simResizeBGRA8888AccelerateFramework
simresize.cpp
dstViewWidth <= dstWidth
dstViewHeight <= dstHeight
simImageChMeanGetTempBuffers
numTempBytes >= bs.totalBytes()
append
bmmixedbufsize.h
!m_nextChunkOffset
nextChunk
m_nextChunkOffset <= m_totalBytes
Exemplar pre-processing
Fetching exemplar ROI
Exemplar post-processing
Instance pre-processing
Fetching instance ROI
Instance post-processing
Expected to be in stage 
. Curent stage instead: 
SiameseRpn op failed: 
Tracker handle creation
Get tracker params
RPN start
espresso.net
input_color_image
input_tap_image
prediction
tap_to_box_v2_fp16
addToHeap
ttHeap.cpp
heap->magic == 0x12345678
removeFromHeap
acDetBboxCoderDecodeAll
acdetbboxcoder.cpp
7 == config.categoryCount || 5 == config.categoryCount
config.posChannelCounts[layerInd] > 0
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Int8
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Int8
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Int8
rollBuf.pixelFormat == kBmBufferPixelFormatType_Int8
yawBuf.pixelFormat == kBmBufferPixelFormatType_Int8
layerHeight * numLogitsUniPosChs == logitsUniPosBuf->height
logitsUniPosBuf->width == offsetsBuf.width
layerHeight * numDefaults * 4 == offsetsBuf.height
globalDefaultBoxInd < defaultBoxWidthsHeightsLen
outBoxInd < maxOutBoxes
acDetBboxCoderDecodeAllFloat
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Float
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Float
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Float
rollBuf.pixelFormat == kBmBufferPixelFormatType_Float
yawBuf.pixelFormat == kBmBufferPixelFormatType_Float
logitsUniPosStride * (uint32_t)sizeof(float) == layerHeight * logitsUniPosBuf->rowBytes
acDetBboxCoderPoseDegrees
predictions.width == numPoseBins
bmMunkres
bmmunkres.cpp
size > 0
maxMatches >= size
xi != 0
bmMunkresGetTempBuffers
tempBuffers
bmMunkresMaxAssignmentsGetTempBuffers
bmMunkresSubtractMinPerRow
rowMin >= 0
minCol < costBuf.height
bmMunkresSubtractMinPerCol
colMin >= 0
minRow < costBuf.width
bmMunkresMaxAssignments
temp
0 <= aCol[r]
bmMunkresUpdateCost
rowLineFlags != nullptr
colLineFlags != nullptr
MSR not available on current platform.
Unable to locate model: 
Tracking result was nil.
Unexpected number of tracks detected. Expected at most one. Found: 
Tracking state was nil.
High priority tracking state was nil.
Invalid high priority tracking op encountered: 
Color buffer preprocessing failed
Exemplar preprocessing failed.
Tracker preprocessing failed.
No active tracking session present.
Instance preprocessing failed.
Instance post-processing failed.
0000000
Tap-to-track det
ttDetCategoryToIsp
ttdetnode.cpp
cat != kTtDetCategory_Background
cat < kTtDetCategoryMax
ttAssocSetUpMunkresCost
ttassoc.cpp
costBufLen >= costMatSize * costMatSize
ttAssocCore
unmatchedDetObjectCount < unmatchedDetObjectsLen
ti < numTrkObjects
ttAssocTrkDetGetTempBuffers
ttAssocObjectRemoveKilled
minKillLevel > kTtAssocObjectKillFlag_None
ttAssocTrkDet
numTrkObjects <= maxTrkObjects
numDetObjects <= maxTrkObjects
tempBufBytes >= ttAssocTrkDetTempBytes(maxTrkObjects)
isDetRunningThisFrame || !numDetObjects
costMatSize * costMatSize <= maxTrkObjects * maxTrkObjects
ki >= n
i == 0 || trkObjects[ti].age <= trkObjects[killTemp[i - 1].index].age
trkObjects[ti].killFlag == kTtAssocObjectKillFlag_Maybe
numTrkObjects - trkKillCount + unmatchedDetObjectCount <= maxTrkObjects
newNumTrkObjects < maxTrkObjects
TtAssocObjectRemoveOldOverlapObjects
trkObjects->objects[justSelected].age <= trkObjects->objects[check].age
bmBufferPixelAtUInt8
RPN score cutoff set to %0.4f
Requested source rect is invalid.
Post processing invoked multiple times.
Internal inconsistency: high priority track missing during tracking update.
Operation requested for high priority tracking not completed.
Invalid commit token. State: %llu, Tracker: %llu.
Internal inconsistency: observation index out of bounds: %zd
A previous tracking state has not been committed.
FusionTracker error: %s
Internal inconsistency: detection-less track is not high-priority.
Terminating detectionless track. IoU exceeded: %0.2f > %0.2f
RPN Precision Level set to %d (defaults value: %d)
Encountered an error during: %s
 -> Espresso Error: %s
Bipartite matching exception: %s
Observation ID has internal track mask set.
Duplicate track ID provided in observation: %lld
TapToBox prediction below threshold.
Network not found: %s
Tap buffer size mismatch.
Failed to get tap buffer base address.
Tap coordinates are out of bounds.
TapToBox tap rendering failed.
TapToBox preprocessing resample failed.
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_DestinationRectangle
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_ScalingMode to 'kVTScalingMode_CropSourceToCleanAperture'
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_SourceCropRectangle
FTVTScaler error: VTPixelTransferSessionTransferImage failed
FTVTScaler error: dstBuffer has unsupported pixelformat. Mean computation only supported for dstBuffer formats: 'kCVPixelFormatType_32BGRA'
MSR preprocessing failed.
SiameseRPN exemplar network loaded: %s
SiameseRPN instance network loaded: %s
FTCinematicTapToTrack error: %s
FTCinematicTrack
NSSecureCoding
NSCoding
FTCinematicTapRequest
FTCinematicTapResponse
FTCinematicTrackingResult
FTCinematicHighPriorityTrackerState
FTCinematicTrackingState
FTCinematicInput
FTCinematicTracker
FTCinematicConfig
FTBipartiteMatcher
FTImageTensorDescriptor
FTTensorReference
FTNetworkDescriptor
FTEspressoBuffer
FTUtils
FTTapToBox
FTVTScaler
FTScaling
FTTapToTrackPreprocessor
FTCinematicTapToTrack
initWithCapacity:
compare:options:
newTextureWithDescriptor:iosurface:plane:
boolForKey:
setValue:forKey:
array
lastPathComponent
hasSuffix:
setUsage:
encodeFloat:forKey:
count
newTextureWithDescriptor:
objectForKeyedSubscript:
hasPrefix:
decodeObjectOfClasses:forKey:
contentsOfDirectoryAtPath:error:
stringWithUTF8String:
predicateWithBlock:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
sortedArrayUsingComparator:
commandBuffer
encodeBool:forKey:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
initWithDevice:
lastDetectionTimestamp
stringByAppendingString:
objectAtIndexedSubscript:
decodeInt64ForKey:
encodeToCommandBuffer:sourceTexture:destinationTexture:
dictionaryWithObjects:forKeys:count:
objectAtIndex:
dictionaryWithCapacity:
setObject:forKeyedSubscript:
confidence
addObject:
stringByAppendingPathComponent:
decodeFloatForKey:
UTF8String
integerForKey:
bundleWithPath:
frameTimestamp
pathsForResourcesOfType:inDirectory:
defaultManager
numberWithUnsignedLong:
bundleWithIdentifier:
initWithSuiteName:
arrayWithObjects:count:
pathForResource:ofType:
firstObject
setWithArray:
decodeBoolForKey:
dictionary
encodeObject:forKey:
waitUntilCompleted
numberWithLongLong:
device
filteredArrayUsingPredicate:
arrayWithCapacity:
bundleForClass:
countByEnumeratingWithState:objects:count:
encodeInt64:forKey:
init
supportsSecureCoding
fromTrack:isHighPriority:
encodeWithCoder:
initWithCoder:
TB,R
identifier
setIdentifier:
setBox:
objectKind
setObjectKind:
lastDetectionTime
setLastDetectionTime:
boxConfidence
setBoxConfidence:
detectionConfidence
setDetectionConfidence:
lastTappedTime
setLastTappedTime:
metadata
setMetadata:
isTapSpawned
setIsTapSpawned:
isHighPriority
setIsHighPriority:
sourceObservationId
setSourceObservationId:
.cxx_destruct
_isTapSpawned
_isHighPriority
_boxConfidence
_detectionConfidence
_identifier
_objectKind
_metadata
_sourceObservationId
_lastDetectionTime
_lastTappedTime
_box
Tq,N,V_identifier
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
TQ,N,V_objectKind
T{?=qiIq},N,V_lastDetectionTime
Tf,N,V_boxConfidence
Tf,N,V_detectionConfidence
T{?=qiIq},N,V_lastTappedTime
T@"NSDictionary",&,N,V_metadata
TB,N,V_isTapSpawned
TB,N,V_isHighPriority
TQ,V_sourceObservationId
tapPoint
setTapPoint:
trackId
setTrackId:
_trackId
_tapPoint
T{CGPoint=dd},N,V_tapPoint
Tq,N,V_trackId
request
setRequest:
wasSuccessful
setWasSuccessful:
tappedTrack
setTappedTrack:
_wasSuccessful
_request
_tappedTrack
T@"FTCinematicTapRequest",&,N,V_request
TB,N,V_wasSuccessful
T@"FTCinematicTrack",&,N,V_tappedTrack
sourceFrameTimestamp
setSourceFrameTimestamp:
tracks
setTracks:
mostRecentTapTime
setMostRecentTapTime:
detectorDidRun
setDetectorDidRun:
tapResponse
setTapResponse:
_detectorDidRun
_tracks
_tapResponse
_sourceFrameTimestamp
_mostRecentTapTime
T{?=qiIq},N,V_sourceFrameTimestamp
T@"NSArray",&,N,V_tracks
T{?=qiIq},N,V_mostRecentTapTime
TB,N,V_detectorDidRun
T@"FTCinematicTapResponse",&,N,V_tapResponse
initWithTracker:frame:
_setup
_setupSessionStorage
_setupOp
targetRect
exemplarInputRoiForTargetRect:
instanceInputRoi
_unsafeMeanFillAndScaleSourceBuffer:destinationBuffer:sourceRect:meanPixel:scaler:
preProcessExemplarInputFromSourceBuffer:toDestinationBuffer:forTargetRect:meanPixel:scaler:
preProcessInstanceInputFromSourceBuffer:toDestinationBuffer:meanPixel:scaler:
_validatePostProcessingInvocation
_updateHighPriorityTrackWithRect:confidence:isTapToTrack:
postProcessExemplarOutputs:forTargetRect:
postProcessInstanceOutputs:
abort
completed
opDescription
sessionStorage
setSessionStorage:
setOp:
setTargetRect:
.cxx_construct
_tracker
_frame
_isTapToTrack
_finalized
_sessionStorage
_targetRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_targetRect
Tq,N,V_op
T@"NSMutableDictionary",&,N,V_sessionStorage
stateWithTracker:frame:input:
commit
highPriorityTrackerState
input
_commitToken
_isTapToTrackOverlapWithIspMitigationEnabled
_highPriorityTrackerState
_input
T@"FTCinematicHighPriorityTrackerState",R,N,V_highPriorityTrackerState
T@"FTCinematicInput",R,N,V_input
mapToInternalObservations
tapPosition
setTapPosition:
tapRequest
setTapRequest:
observations
setObservations:
highPriorityTrackId
setHighPriorityTrackId:
_tapRequest
_observations
_highPriorityTrackId
_tapPosition
T{CGPoint=dd},N,V_tapPosition
T@"FTCinematicTapRequest",&,N,V_tapRequest
T@"NSArray",&,N,V_observations
Tq,N,V_highPriorityTrackId
highPriorityExemplarNetworkDescriptor
highPriorityInstanceNetworkDescriptor
tapToBoxNetworkDescriptor
initWithConfig:
computeTrackingStateForInput:
ensureObservationTimestampMatchesFrame
setEnsureObservationTimestampMatchesFrame:
allowTrackPromotion
setAllowTrackPromotion:
_ensureObservationTimestampMatchesFrame
_allowTrackPromotion
TB,N,V_ensureObservationTimestampMatchesFrame
TB,N,V_allowTrackPromotion
initWithInitialSize:
computeMatchingForCostMatrix:withRowCount:columnCount:
_optimizer
descriptorWithName:size:pixelFormat:
bgraImageWithName:size:
bgraSquareImageWithName:size:
name
setName:
pixelFormat
setPixelFormat:
size
setSize:
_pixelFormat
_name
_size
T@"NSString",&,N,V_name
TI,N,V_pixelFormat
T{CGSize=dd},N,V_size
sourceNetworkName
setSourceNetworkName:
sourceOutputName
setSourceOutputName:
destinationInputName
setDestinationInputName:
_sourceNetworkName
_sourceOutputName
_destinationInputName
T@"NSString",&,N,V_sourceNetworkName
T@"NSString",&,N,V_sourceOutputName
T@"NSString",&,N,V_destinationInputName
onlyImageInput
inputImages
setInputImages:
inputReferences
setInputReferences:
outputNames
setOutputNames:
_inputImages
_inputReferences
_outputNames
T@"NSArray",&,N,V_inputImages
T@"NSArray",&,N,V_inputReferences
T@"NSArray",&,N,V_outputNames
bufferWithEspressoBuffer:
buffer
_buffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},R,N,V_buffer
fusionTracker_encodeCMTime:forKey:
fusionTracker_decodeCMTimeForKey:
fusionTracker_encodeCGRect:forKey:
fusionTracker_decodeCGRectForKey:
networkPath
networkInputImageSize
networkInputTapImageSize
networkDescriptor
renderTap:inBuffer:
preprocessForTap:inSourceImageBuffer:destinationImageBuffer:tapBuffer:scaler:
postProcessNetworkOutput:
defaultConfidenceThreshold
predictionForTap:inBuffer:scaler:
predictBoxForTap:inBuffer:scaler:
_net
_inputImageTensor
_inputTapTensor
_inputMap
_outputTensor
dealloc
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:mean:
initWithCommandQueue:
_device
_commandQueue
_meanFilter
_meanTexture
_transferSession
initWithScaler:
preprocessBuffer:
bgraPixelBuffer
meanPixel
_intermediateBuffer
_meanPixel
_scaler
trackerWithCommandQueue:
initWithEspressoEngine:scalingBackend:commandQueue:
_setupScalerWithBackend:
_setupNetworksWithEngine:
_resolveNetworkPath:
_espressoConfigFromDescriptor:engine:
predictRectForPoint:inColorBuffer:
_maybeFetchTrackByCommittingState:
_preprocessBuffer:andValidateState:isOp:
_unsafeStartTrackingRect:colorBuffer:
_unsafeStepTrackingWithFrame:
startTrackingRect:colorBuffer:
stepTrackingWithFrame:
reset
isTrackingActive
_preprocessor
_exemplarNetDesc
_instanceNetDesc
_exemplarNet
_instanceNet
_exemplarCrop
_instanceCrop
_tapToBox
B16@0:8
@36@0:8{shared_ptr<ft::Track>=^{Track}^{__shared_weak_count}}16B32
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
q16@0:8
v24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q16@0:8
v24@0:8Q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
f16@0:8
v20@0:8f16
v20@0:8B16
v16@0:8
@"NSDictionary"
{?="value"q"timescale"i"flags"I"epoch"q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"FTCinematicTapRequest"
@"FTCinematicTrack"
@"NSArray"
@"FTCinematicTapResponse"
@48@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B76@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}3264@68
B44@0:8^{__CVBuffer=}16^{__CVBuffer=}2432@36
B60@0:8{Rect<double>=dddd}16d48B56
B56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B24@0:8@16
{shared_ptr<ft::CinematicTracker>="__ptr_"^{CinematicTracker}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<ft::Frame>="__ptr_"^{Frame}"__cntrl_"^{__shared_weak_count}}
@"NSMutableDictionary"
@56@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32@48
@"FTCinematicHighPriorityTrackerState"
@"FTCinematicInput"
{vector<ft::Observation, std::allocator<ft::Observation>>=^{Observation}^{Observation}{__compressed_pair<ft::Observation *, std::allocator<ft::Observation>>=^{Observation}}}16@0:8
@24@0:8Q16
@40@0:8r^f16Q24Q32
{unique_ptr<ft::HungarianMatcher, std::default_delete<ft::HungarianMatcher>>="__ptr_"{__compressed_pair<ft::HungarianMatcher *, std::default_delete<ft::HungarianMatcher>>="__value_"^{HungarianMatcher}}}
@44@0:8@16{CGSize=dd}24I40
@40@0:8@16{CGSize=dd}24
@32@0:8@16d24
I16@0:8
v20@0:8I16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
@"NSString"
{CGSize="width"d"height"d}
@184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v48@0:8{?=qiIq}16@40
{?=qiIq}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B64@0:8{CGPoint=dd}16^{__CVBuffer=}32^{__CVBuffer=}40^{__CVBuffer=}48@56
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
d16@0:8
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{unique_ptr<ik::EspressoNet, std::default_delete<ik::EspressoNet>>="__ptr_"{__compressed_pair<ik::EspressoNet *, std::default_delete<ik::EspressoNet>>="__value_"^{EspressoNet}}}
{PixelBufferTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
{unordered_map<std::string, ik::Tensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, ik::Tensor>>>="__table_"{__hash_table<std::__hash_value_type<std::string, ik::Tensor>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, ik::Tensor>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{EspressoTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
B96@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
B104@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64^96
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageStatisticsMean"
@"<MTLTexture>"
^{OpaqueVTPixelTransferSession=}
B24@0:8^{__CVBuffer=}16
^{__CVBuffer=}16@0:8
16@0:8
{shared_ptr<__CVBuffer>="__ptr_"^{__CVBuffer}"__cntrl_"^{__shared_weak_count}}
@"<FTScaling>"
@32@0:8i16i20@24
v20@0:8i16
v24@0:8r^v16
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}24@0:8@16
{EspressoConfig={vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}{optional<espresso_engine_t>=(?=ci)B}iii{optional<espresso_plan_priority_t>=(?=ci)B}{optional<void *>=(?=c^v)B}{unordered_map<std::string, espresso_simple_image_preprocessing_params_t, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, espresso_simple_image_preprocessing_params_t>>>={__hash_table<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*QQ}{__short=[23c]{?=C}}{__raw=[3Q]})}}}}32@0:8@16r^v24
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
v40@0:8^{__CVBuffer=}16@24q32
B56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8^{__CVBuffer=}16
@"FTTapToTrackPreprocessor"
@"FTNetworkDescriptor"
@"FTTapToBox"
@"FTCinematicTracker"
