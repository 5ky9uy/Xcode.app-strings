@(#)PROGRAM:FusionTracker  PROJECT:FusionTracker-1
N2ft11KalmanTrackE
NxA@
BUm}BUm
CCXZ
B,%IC
333CUm
BUm}C
::B@
BUm}B
CC,;
C,%IC,%
333CUm}CUm
7T=
=#1A=P
;block8_box/conv_cls_pos/Conv2D
block8_box/conv_cls_neg/Conv2D
block7_box/conv_cls_pos/Conv2D
block7_box/conv_cls_neg/Conv2D
block6_box/conv_cls/Conv2D/q
block9_box/conv_cls/Conv2D/q
block10_box/conv_cls/Conv2D/q
block11_box/conv_cls/Conv2D/q
block8_box/conv_loc/Conv2D/q
block7_box/conv_loc/Conv2D/q
block6_box/conv_loc/Conv2D/q
block9_box/conv_loc/Conv2D/q
block10_box/conv_loc/Conv2D/q
block11_box/conv_loc/Conv2D/q
BUm}BUm
NBUm
B333Cjy[C
333CUm
BUm}C
Bjy[C
BUm}B
B333C33
Bjy[C
333CUm}CUm
Cjy[C
ff&?
>ff&?
ff&?
7>q 
=9{'=4
<block8_box/conv_cls/Conv2D
block7_box/conv_cls/Conv2D
block6_box/conv_cls/Conv2D
block9_box/conv_cls/Conv2D
block10_box/conv_cls/Conv2D
block11_box/conv_cls/Conv2D
block8_box/conv_loc/Conv2D
block7_box/conv_loc/Conv2D
block6_box/conv_loc/Conv2D
block9_box/conv_loc/Conv2D
block10_box/conv_loc/Conv2D
block11_box/conv_loc/Conv2D
block8_box/conv_roll/Conv2D
block7_box/conv_roll/Conv2D
block6_box/conv_roll/Conv2D
block9_box/conv_roll/Conv2D
block10_box/conv_roll/Conv2D
block11_box/conv_roll/Conv2D
block8_box/conv_yaw/Conv2D
block7_box/conv_yaw/Conv2D
block6_box/conv_yaw/Conv2D
block9_box/conv_yaw/Conv2D
block10_box/conv_yaw/Conv2D
block11_box/conv_yaw/Conv2D
NSt3__120__shared_ptr_emplaceIN2ft16CinematicTrackerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft5FrameENS_9allocatorIS2_EEEE
N2ik17PixelBufferTensorE
N2ik6TensorE
N2ik11EspressoNetE
NSt3__120__shared_ptr_emplaceIN2ik4core16EspressoNetStateENS_9allocatorIS3_EEEE
N2ik14InferenceErrorE
NSt3__120__shared_ptr_emplaceIN2ik4core18PixelBufferStorageENS_9allocatorIS3_EEEE
N2ik4core18PixelBufferStorageE
N2ik13TensorStorageE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
N2ik4core24CorePixelBufferScopeLockE
N2ik20PixelBufferScopeLockE
N2ik4core14EspressoBinderE
N2ik6BinderE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_emplaceIN2ik4core21EspressoBufferStorageENS_9allocatorIS3_EEEE
N2ik4core21EspressoBufferStorageE
NSt3__117bad_function_callE
@trk
<G_96/Conv_4/Conv2D/q
zDNSt3__120__shared_ptr_emplaceIN2ft11KalmanTrackENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft10ProxyTrackENS_9allocatorIS2_EEEE
N2ft5TrackE
1.7.3
=S>D=
\;conv2d_sm/convolution/q
conv2d_lb/convolution/q
conv2d_rb/convolution/q
conv2d_pitch/convolution/q
conv2d_yaw/convolution/q
conv2d_roll/convolution/q
conv2d_eye/convolution/q
procedure_1
procedure_2
procedure_3
procedure_4
procedure_5
procedure_6
procedure_7
procedure_8
procedure_9
procedure_10
NSt3__120__shared_ptr_pointerIP10__CVBufferPFvS2_ENS_9allocatorIS1_EEEE
PFvP10__CVBufferE
N2ft10ProxyTrackE
N2ft20SiameseRpnStageErrorE
attr
?ffffff
?ffffff
7R=]
o->f
BoxEncoding_0/Conv2D/q
BoxEncoding_1/Conv2D/q
BoxEncoding_2/Conv2D/q
BoxEncoding_3/Conv2D/q
BoxEncoding_4/Conv2D/q
BoxEncoding_5/Conv2D/q
ClassPredictor_0/Conv2D/q
ClassPredictor_1/Conv2D/q
ClassPredictor_2/Conv2D/q
ClassPredictor_3/Conv2D/q
ClassPredictor_4/Conv2D/q
ClassPredictor_5/Conv2D/q
?ff&?ff&?ff&?ff&?ff&?
,_?33s?33s?33s?33s?33s?
Prior time step not established.
Frame has invalid timestamp.
kalman
preProcess
acattrnode.cpp
numFaces <= 10
bmBufferDequantizeInt8
bmbufferprivate.h
input.pixelFormat == kBmBufferPixelFormatType_Int8
input.height == output.height
input.width == output.width
bmBufferDequantizeUInt8
input.pixelFormat == kBmBufferPixelFormatType_UInt8
bmBufferPixelAtFloat
x < buf.width && y < buf.height
bmBufferPixelSize
false
ttDetCategoryFromIsp
ttdetrect.cpp
cat < CISP_TT_DET_CATEGORY_COUNT
vector
acCropResizeGenerateConfig
accropresize.cpp
!(dstWidth & 0x01) && !(dstHeight & 0x01)
srcPyrInfo.numLevels <= 4
pyrInd == 0 || srcPyrInfo.widths[pyrInd] <= srcPyrInfo.widths[pyrInd - 1]
pyrInd == 0 || srcPyrInfo.heights[pyrInd] <= srcPyrInfo.heights[pyrInd - 1]
xStartY < srcPyrInfo.widths[crop.pyrIndex]
yStartY < srcPyrInfo.heights[crop.pyrIndex]
init
acdetnode.cpp
count
m_config.fmBboxCounts[scaleInd]
bboxBufChCount
state.magic == 0xde71
classBufChCount
classPosBufChCount
classNegBufChCount
rollBufChCount
yawBufChCount
getClsBufferInds
posInd != ((uint32_t)-1)
negInd != ((uint32_t)-1)
acDetCategoryToIsp
cat != kAcDetCategory_Background
cat < kAcDetCategoryMax
acAttrReduceSmile
acattrreduce.cpp
smileThreshold <= 100
acAttrReduceBlink
(*netOutput).height >= kOutputCount
blinkThreshold <= 100
occludedThreshold <= 100
acAttrReduceYaw
numBins <= 10
acAttrReduceRoll
acDetRectSmallRectSuppression
acdetrect.cpp
sortedRects[justSelected].score >= sortedRects[check].score
remaining <= check
acDetRectLowMergeCountSuppression
acDetRectWeightedMerge
rects
acDetCategoryFromIsp
cat < CISP_AC_DET_CATEGORY_COUNT
instancePostProcess
tttrkrpnnode.cpp
netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Half || netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Float
setUpNetBuffers
ptr - (const uint8_t*)netBufferPtrs.instanceCrop == params.instanceCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.exemplarCrop == params.exemplarCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.templateKernels[i] == params.templateNetOutBatchBytes[i]
ptr - (const uint8_t*)netBufferPtrs.xcorrOutputs[i] == params.xcorrNetOutBatchBytes[i]
bmBufferDequantizeHalf
input.pixelFormat == kBmBufferPixelFormatType_Half
output.pixelFormat == kBmBufferPixelFormatType_Float
identifier
objectKind
lastDetectionTime
boxConfidence
detectionConfidence
lastTappedTime
isHighPriority
sourceObservationId
isTapSpawned
metadata
sourceFrameTimestamp
tracks
mostRecentTapTime
detectorDidRun
SiameseRPN at invalid stage: 
subject_tracking_initializer_v2
image
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
subject_tracking_tracker_v2
instance_image
regress_adjust
classification_x_corr
None
Initialize
Track
TapToBox
Unknown
Track not yet initialized.
basic_string
Observation timestamp does not match frame timestamp.
int8
uint8
uint10
uint12
uint14
uint16
float
half
map::at:  key not found
v8@?0
com.apple.FusionTracker
default
com.apple.coremedia
enable_tap_to_track_overlap_with_isp_mitigation
ttt_rpn_precision_level
simResizeVisPipeBinning
simresizevispipe.cpp
startX == 0.0f && startY == 0.0f
xStep == 1 || xStep == 2 || xStep == 4 || xStep == 8
yStep == 1 || yStep == 2 || yStep == 4 || yStep == 8
simResizeVisPipe
scaleX <= ISP_RESIZE_MAX_SCALE && scaleY <= ISP_RESIZE_MAX_SCALE
scaleX >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE && scaleY >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE
(scaleX <= 1 && scaleY <= 1) || (method != SimResizeVisPipeMethod::Area)
output.width <= ISP_RESIZE_MAX_WIDTH
output.height <= ISP_RESIZE_MAX_HEIGHT
bmBufferPixelAtUInt16
inputHandler
input.rowBytes % sizeof(uint16_t) == 0
input.rowBytes == shiftedInput.rowBytes
input.width == shiftedInput.width
input.height == shiftedInput.height
input.pixelFormat == shiftedInput.pixelFormat
input.pixelFormat == kBmBufferPixelFormatType_UInt16
outputHandler
output.rowBytes % sizeof(uint16_t) == 0
acNonMaxSuppression
acnonmaxsuppression.cpp
__null != rects
acCrossClassSuppression
acNonMaxSuppressionSmallbox
acRemoveOverlapBoxes
numRects <= tempBytes
Detector post processing
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
+N9mZUAHooNvMiQnjeTJ8g
Error encountered during: 
 [espresso error: 
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Null CVPixelBuffer encountered.
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
Unknown data type
Unsupported CVPixelBuffer type: 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Model has no pre-declared outputs.
Unsupported image buffer type
Binding vImage_Buffer
Binding CVPixelBuffer
Binding espresso_buffer_t
Binding output buffer
Unsupported tensor rank: 
Unsupported espresso type encountered.
Unpacking tensor shape
Detector op failed: 
 / internal code = 
unordered_map::at: key not found
Get detector params
Incorrect data type requested.
Expected a rank 4 NCHW tensor.
bmBufferResizeCHW
bmbuffergeometry.cpp
bmBufferPartialResizeCHW
bmBufferResizeCoordConvert
pad < kBmBufferResizePadMax
srcW && srcH && dstW && dstH
bmBufferResizeCoordConvertReversed
bmBufferResize2xCHW
dst.pixelFormat == src.pixelFormat
src.pixelFormat == kBmBufferPixelFormatType_Int8
srcViewHeight * numChannels == src.height
dstViewHeight * numChannels == dst.height
bmBufferPixelAtInt8
bmBufferResize2xSingleChannelCHW
src.height > 0
dst.width == src.width * 2
dst.height == src.height * 2
bmBufferResizeBicubicCHW
bmBufferResizeBicubicSingleChannelCHW
src.width && src.height
dst.width >= src.width
dst.height >= src.height
src.pixelFormat == kBmBufferPixelFormatType_Float
dst.pixelFormat == kBmBufferPixelFormatType_Float
bmArgMax
bmmath.cpp
Unknown track type encountered: 
proxy
Expected exactly one input image. Found: %zd instead.
/System/Library/ImagingNetworks
/System/Library/PrivateFrameworks/Celestial.framework
com.apple.Celestial
classifiers
.espresso.net
B24@?0@"NSString"8@"NSDictionary"16
q24@?0@"NSString"8@"NSString"16
.net
Predict called before initialization
Failed to create IOSurface-backed CVPixelBuffer.
Failed to create pixel buffer pool. Status = 
Failed to create pixel buffer. Status = 
ttNonMaxSuppression
ttnonmaxsuppression.cpp
ttNonMaxSuppression2
ttNonMaxSuppressionSmallbox
ttRemoveOverlapBoxes
simResizeBGRA8888AccelerateFramework
simresize.cpp
dstViewWidth <= dstWidth
dstViewHeight <= dstHeight
simImageChMeanGetTempBuffers
numTempBytes >= bs.totalBytes()
append
bmmixedbufsize.h
!m_nextChunkOffset
nextChunk
m_nextChunkOffset <= m_totalBytes
Exemplar pre-processing
Fetching exemplar ROI
Exemplar post-processing
Instance pre-processing
Fetching instance ROI
Instance post-processing
Expected to be in stage 
. Curent stage instead: 
SiameseRpn op failed: 
Tracker handle creation
Get tracker params
espresso.net
input_color_image
input_tap_image
prediction
tap_to_box_v2_fp16
addToHeap
ttHeap.cpp
heap->magic == 0x12345678
removeFromHeap
acDetBboxCoderDecodeAll
acdetbboxcoder.cpp
7 == config.categoryCount || 5 == config.categoryCount
config.posChannelCounts[layerInd] > 0
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Int8
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Int8
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Int8
rollBuf.pixelFormat == kBmBufferPixelFormatType_Int8
yawBuf.pixelFormat == kBmBufferPixelFormatType_Int8
layerHeight * numLogitsUniPosChs == logitsUniPosBuf->height
logitsUniPosBuf->width == offsetsBuf.width
layerHeight * numDefaults * 4 == offsetsBuf.height
globalDefaultBoxInd < defaultBoxWidthsHeightsLen
outBoxInd < maxOutBoxes
acDetBboxCoderDecodeAllFloat
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Float
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Float
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Float
rollBuf.pixelFormat == kBmBufferPixelFormatType_Float
yawBuf.pixelFormat == kBmBufferPixelFormatType_Float
logitsUniPosStride * (uint32_t)sizeof(float) == layerHeight * logitsUniPosBuf->rowBytes
acDetBboxCoderPoseDegrees
predictions.width == numPoseBins
bmMunkres
bmmunkres.cpp
size > 0
maxMatches >= size
xi != 0
bmMunkresGetTempBuffers
tempBuffers
bmMunkresMaxAssignmentsGetTempBuffers
bmMunkresSubtractMinPerRow
rowMin >= 0
minCol < costBuf.height
bmMunkresSubtractMinPerCol
colMin >= 0
minRow < costBuf.width
bmMunkresMaxAssignments
temp
0 <= aCol[r]
bmBufferPixelAtUInt8
bmMunkresUpdateCost
rowLineFlags != nullptr
colLineFlags != nullptr
MSR not available on current platform.
Unable to locate model: 
Tracking result was nil.
Unexpected number of tracks detected. Expected at most one. Found: 
Tracking state was nil.
High priority tracking state was nil.
Invalid high priority tracking op encountered: 
Color buffer preprocessing failed
Exemplar preprocessing failed.
Tracker preprocessing failed.
No active tracking session present.
Instance preprocessing failed.
Instance post-processing failed.
0000000
Tap-to-track det
ttDetCategoryToIsp
ttdetnode.cpp
cat != kTtDetCategory_Background
cat < kTtDetCategoryMax
ttAssocSetUpMunkresCost
ttassoc.cpp
costBufLen >= costMatSize * costMatSize
ttAssocCore
unmatchedDetObjectCount < unmatchedDetObjectsLen
ti < numTrkObjects
ttAssocTrkDetGetTempBuffers
ttAssocObjectRemoveKilled
minKillLevel > kTtAssocObjectKillFlag_None
ttAssocTrkDet
numTrkObjects <= maxTrkObjects
numDetObjects <= maxTrkObjects
tempBufBytes >= ttAssocTrkDetTempBytes(maxTrkObjects)
isDetRunningThisFrame || !numDetObjects
costMatSize * costMatSize <= maxTrkObjects * maxTrkObjects
ki >= n
i == 0 || trkObjects[ti].age <= trkObjects[killTemp[i - 1].index].age
trkObjects[ti].killFlag == kTtAssocObjectKillFlag_Maybe
numTrkObjects - trkKillCount + unmatchedDetObjectCount <= maxTrkObjects
newNumTrkObjects < maxTrkObjects
TtAssocObjectRemoveOldOverlapObjects
trkObjects->objects[justSelected].age <= trkObjects->objects[check].age
RPN score cutoff set to %0.4f
Requested source rect is invalid.
Post processing invoked multiple times.
Internal inconsistency: high priority track missing during tracking update.
Operation requested for high priority tracking not completed.
Invalid commit token. State: %llu, Tracker: %llu.
Internal inconsistency: observation index out of bounds: %zd
A previous tracking state has not been committed.
FusionTracker error: %s
Internal inconsistency: detection-less track is not high-priority.
Terminating detectionless track. IoU exceeded: %0.2f > %0.2f
RPN Precision Level set to %d (defaults value: %d)
Encountered an error during: %s
 -> Espresso Error: %s
Bipartite matching exception: %s
Observation ID has internal track mask set.
Duplicate track ID provided in observation: %lld
TapToBox prediction below threshold.
Network not found: %s
Tap buffer size mismatch.
Failed to get tap buffer base address.
Tap coordinates are out of bounds.
TapToBox tap rendering failed.
TapToBox preprocessing resample failed.
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_DestinationRectangle
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_ScalingMode to 'kVTScalingMode_CropSourceToCleanAperture'
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_SourceCropRectangle
FTVTScaler error: VTPixelTransferSessionTransferImage failed
FTVTScaler error: dstBuffer has unsupported pixelformat. Mean computation only supported for dstBuffer formats: 'kCVPixelFormatType_32BGRA'
MSR preprocessing failed.
SiameseRPN exemplar network loaded: %s
SiameseRPN instance network loaded: %s
FTCinematicTapToTrack error: %s
FTCinematicTrack
NSSecureCoding
NSCoding
FTCinematicTapRequest
FTCinematicTapResponse
FTCinematicTrackingResult
FTCinematicHighPriorityTrackerState
FTCinematicTrackingState
FTCinematicInput
FTCinematicTracker
FTCinematicConfig
FTBipartiteMatcher
FTImageTensorDescriptor
FTTensorReference
FTNetworkDescriptor
FTEspressoBuffer
FTUtils
FTTapToBox
FTVTScaler
FTScaling
FTTapToTrackPreprocessor
FTCinematicTapToTrack
T@"NSDictionary",&,N,V_metadata
.cxx_destruct
T{?=qiIq},N,V_mostRecentTapTime
T@"FTCinematicInput",R,N,V_input
_detectorDidRun
T@"FTCinematicTapRequest",&,N,V_tapRequest
_inputTapTensor
T@"FTCinematicTrack",&,N,V_tappedTrack
_lastTappedTime
T@"NSArray",&,N,V_inputReferences
_scaler
T@"NSArray",&,N,V_outputNames
_tracks
T@"NSMutableDictionary",&,N,V_sessionStorage
T@"NSString",&,N,V_name
bundleWithPath:
T@"NSString",&,N,V_sourceOutputName
dealloc
TB,N,V_detectorDidRun
initWithDevice:
TB,N,V_isHighPriority
inputReferences
TB,N,V_wasSuccessful
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:
TI,N,V_pixelFormat
setInputImages:
TQ,V_sourceObservationId
setPixelFormat:
Tf,N,V_detectionConfidence
setTapResponse:
Tq,N,V_identifier
stringByAppendingPathComponent:
Tq,N,V_trackId
.cxx_construct
T{?=qiIq},N,V_lastDetectionTime
T@"FTCinematicHighPriorityTrackerState",R,N,V_highPriorityTrackerState
_buffer
T@"FTCinematicTapRequest",&,N,V_request
_device
T@"FTCinematicTapResponse",&,N,V_tapResponse
_isHighPriority
T@"NSArray",&,N,V_inputImages
T@"NSArray",&,N,V_observations
_sessionStorage
T@"NSArray",&,N,V_tracks
bgraPixelBuffer
T@"NSString",&,N,V_destinationInputName
bundleForClass:
T@"NSString",&,N,V_sourceNetworkName
containsString:
TB,N,V_allowTrackPromotion
initWithConfig:
TB,N,V_ensureObservationTimestampMatchesFrame
initWithScaler:
TB,N,V_isTapSpawned
request
TB,R
setBox:
TQ,N,V_objectKind
setOutputNames:
Tf,N,V_boxConfidence
setTapPosition:
Tq,N,V_highPriorityTrackId
setTappedTrack:
Tq,N,V_op
trackId
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},R,N,V_buffer
T{?=qiIq},N,V_lastTappedTime
T{?=qiIq},N,V_sourceFrameTimestamp
T{CGPoint=dd},N,V_tapPoint
T{CGPoint=dd},N,V_tapPosition
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_targetRect
T{CGSize=dd},N,V_size
UTF8String
_allowTrackPromotion
_box
_boxConfidence
_commandQueue
_commitToken
_destinationInputName
_detectionConfidence
_ensureObservationTimestampMatchesFrame
_espressoConfigFromDescriptor:engine:
_exemplarCrop
_exemplarNet
_exemplarNetDesc
_finalized
_frame
_highPriorityTrackId
_highPriorityTrackerState
_identifier
_input
_inputImageTensor
_inputImages
_inputMap
_inputReferences
_instanceCrop
_instanceNet
_instanceNetDesc
_intermediateBuffer
_isTapSpawned
_isTapToTrack
_isTapToTrackOverlapWithIspMitigationEnabled
_lastDetectionTime
_maybeFetchTrackByCommittingState:
_meanFilter
_meanPixel
_meanTexture
_metadata
_mostRecentTapTime
_name
_net
_objectKind
_observations
_optimizer
_outputNames
_outputTensor
_pixelFormat
_preprocessBuffer:andValidateState:isOp:
_preprocessor
_request
_resolveNetworkPath:
_setup
_setupNetworksWithEngine:
_setupOp
_setupScalerWithBackend:
_setupSessionStorage
_size
_sourceFrameTimestamp
_sourceNetworkName
_sourceObservationId
_sourceOutputName
_tapPoint
_tapPosition
_tapRequest
_tapResponse
_tapToBox
_tappedTrack
_targetRect
_trackId
_tracker
_transferSession
_unsafeMeanFillAndScaleSourceBuffer:destinationBuffer:sourceRect:meanPixel:scaler:
_unsafeStartTrackingRect:colorBuffer:
_unsafeStepTrackingWithFrame:
_updateHighPriorityTrackWithRect:confidence:isTapToTrack:
_validatePostProcessingInvocation
_wasSuccessful
abort
addObject:
allowTrackPromotion
array
arrayWithCapacity:
arrayWithObjects:count:
bgraImageWithName:size:
bgraSquareImageWithName:size:
boolForKey:
boxConfidence
buffer
bufferWithEspressoBuffer:
bundleWithIdentifier:
commandBuffer
commit
compare:options:
completed
computeMatchingForCostMatrix:withRowCount:columnCount:
computeTrackingStateForInput:
confidence
contentsOfDirectoryAtPath:error:
count
countByEnumeratingWithState:objects:count:
decodeBoolForKey:
decodeFloatForKey:
decodeInt64ForKey:
decodeObjectOfClasses:forKey:
defaultConfidenceThreshold
defaultManager
descriptorWithName:size:pixelFormat:
destinationInputName
detectionConfidence
detectorDidRun
device
dictionary
dictionaryWithCapacity:
dictionaryWithObjects:forKeys:count:
encodeBool:forKey:
encodeFloat:forKey:
encodeInt64:forKey:
encodeObject:forKey:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeWithCoder:
ensureObservationTimestampMatchesFrame
exemplarInputRoiForTargetRect:
filteredArrayUsingPredicate:
firstObject
frameTimestamp
fromTrack:isHighPriority:
fusionTracker_decodeCGRectForKey:
fusionTracker_decodeCMTimeForKey:
fusionTracker_encodeCGRect:forKey:
fusionTracker_encodeCMTime:forKey:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
hasPrefix:
hasSuffix:
highPriorityExemplarNetworkDescriptor
highPriorityInstanceNetworkDescriptor
highPriorityTrackId
highPriorityTrackerState
identifier
init
initWithCapacity:
initWithCoder:
initWithCommandQueue:
initWithEspressoEngine:scalingBackend:commandQueue:
initWithInitialSize:
initWithSuiteName:
initWithTracker:frame:
input
inputImages
instanceInputRoi
integerForKey:
isHighPriority
isTapSpawned
isTrackingActive
lastDetectionTime
lastDetectionTimestamp
lastPathComponent
lastTappedTime
mapToInternalObservations
meanPixel
metadata
mostRecentTapTime
name
networkDescriptor
networkInputImageSize
networkInputTapImageSize
networkPath
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
numberWithLongLong:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKeyedSubscript:
objectKind
observations
onlyImageInput
opDescription
outputNames
pathForResource:ofType:
pathsForResourcesOfType:inDirectory:
pixelFormat
postProcessExemplarOutputs:forTargetRect:
postProcessInstanceOutputs:
postProcessNetworkOutput:
preProcessExemplarInputFromSourceBuffer:toDestinationBuffer:forTargetRect:meanPixel:scaler:
preProcessInstanceInputFromSourceBuffer:toDestinationBuffer:meanPixel:scaler:
predicateWithBlock:
predictBoxForTap:inBuffer:scaler:
predictRectForPoint:inColorBuffer:
predictionForTap:inBuffer:scaler:
preprocessBuffer:
preprocessForTap:inSourceImageBuffer:destinationImageBuffer:tapBuffer:scaler:
renderTap:inBuffer:
reset
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:mean:
sessionStorage
setAllowTrackPromotion:
setBoxConfidence:
setDestinationInputName:
setDetectionConfidence:
setDetectorDidRun:
setEnsureObservationTimestampMatchesFrame:
setHighPriorityTrackId:
setIdentifier:
setInputReferences:
setIsHighPriority:
setIsTapSpawned:
setLastDetectionTime:
setLastTappedTime:
setMetadata:
setMostRecentTapTime:
setName:
setObject:forKeyedSubscript:
setObjectKind:
setObservations:
setOp:
setRequest:
setSessionStorage:
setSize:
setSourceFrameTimestamp:
setSourceNetworkName:
setSourceObservationId:
setSourceOutputName:
setTapPoint:
setTapRequest:
setTargetRect:
setTrackId:
setTracks:
setUsage:
setValue:forKey:
setWasSuccessful:
setWithArray:
size
sortedArrayUsingComparator:
sourceFrameTimestamp
sourceNetworkName
sourceObservationId
sourceOutputName
startTrackingRect:colorBuffer:
stateWithTracker:frame:input:
stepTrackingWithFrame:
stringByAppendingString:
stringWithFormat:
stringWithUTF8String:
supportsSecureCoding
tapPoint
tapPosition
tapRequest
tapResponse
tapToBoxNetworkDescriptor
tappedTrack
targetRect
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
trackerWithCommandQueue:
tracks
waitUntilCompleted
wasSuccessful
B16@0:8
@36@0:8{shared_ptr<ft::Track>=^{Track}^{__shared_weak_count}}16B32
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
q16@0:8
v24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q16@0:8
v24@0:8Q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
f16@0:8
v20@0:8f16
v20@0:8B16
v16@0:8
@"NSDictionary"
{?="value"q"timescale"i"flags"I"epoch"q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"FTCinematicTapRequest"
@"FTCinematicTrack"
@"NSArray"
@"FTCinematicTapResponse"
@48@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B76@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}3264@68
B44@0:8^{__CVBuffer=}16^{__CVBuffer=}2432@36
B60@0:8{Rect<double>=dddd}16d48B56
B56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B24@0:8@16
{shared_ptr<ft::CinematicTracker>="__ptr_"^{CinematicTracker}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<ft::Frame>="__ptr_"^{Frame}"__cntrl_"^{__shared_weak_count}}
@"NSMutableDictionary"
@56@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32@48
@"FTCinematicHighPriorityTrackerState"
@"FTCinematicInput"
{vector<ft::Observation, std::allocator<ft::Observation>>=^{Observation}^{Observation}{__compressed_pair<ft::Observation *, std::allocator<ft::Observation>>=^{Observation}}}16@0:8
@24@0:8Q16
@40@0:8r^f16Q24Q32
{unique_ptr<ft::HungarianMatcher, std::default_delete<ft::HungarianMatcher>>="__ptr_"{__compressed_pair<ft::HungarianMatcher *, std::default_delete<ft::HungarianMatcher>>="__value_"^{HungarianMatcher}}}
@44@0:8@16{CGSize=dd}24I40
@40@0:8@16{CGSize=dd}24
@32@0:8@16d24
I16@0:8
v20@0:8I16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
@"NSString"
{CGSize="width"d"height"d}
@184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v48@0:8{?=qiIq}16@40
{?=qiIq}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B64@0:8{CGPoint=dd}16^{__CVBuffer=}32^{__CVBuffer=}40^{__CVBuffer=}48@56
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
d16@0:8
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{unique_ptr<ik::EspressoNet, std::default_delete<ik::EspressoNet>>="__ptr_"{__compressed_pair<ik::EspressoNet *, std::default_delete<ik::EspressoNet>>="__value_"^{EspressoNet}}}
{PixelBufferTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
{unordered_map<std::string, ik::Tensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, ik::Tensor>>>="__table_"{__hash_table<std::__hash_value_type<std::string, ik::Tensor>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, ik::Tensor>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{EspressoTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
B96@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
B104@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64^96
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageStatisticsMean"
@"<MTLTexture>"
^{OpaqueVTPixelTransferSession=}
B24@0:8^{__CVBuffer=}16
^{__CVBuffer=}16@0:8
16@0:8
{shared_ptr<__CVBuffer>="__ptr_"^{__CVBuffer}"__cntrl_"^{__shared_weak_count}}
@"<FTScaling>"
@32@0:8i16i20@24
v20@0:8i16
v24@0:8r^v16
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long={?=b1b63}Q*}{__short={?=b1b7}[0c][23c]}{__raw=[3Q]})}}}24@0:8@16
{EspressoConfig={vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}{optional<espresso_engine_t>=(?=ci)B}iii{optional<espresso_plan_priority_t>=(?=ci)B}{optional<void *>=(?=c^v)B}{unordered_map<std::string, espresso_simple_image_preprocessing_params_t, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, espresso_simple_image_preprocessing_params_t>>>={__hash_table<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long={?=b1b63}Q*}{__short={?=b1b7}[0c][23c]}{__raw=[3Q]})}}}}32@0:8@16r^v24
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
v40@0:8^{__CVBuffer=}16@24q32
B56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8^{__CVBuffer=}16
@"FTTapToTrackPreprocessor"
@"FTNetworkDescriptor"
@"FTTapToBox"
@"FTCinematicTracker"
@(#)PROGRAM:FusionTracker  PROJECT:FusionTracker-1
?N2ft11KalmanTrackE
NxA@
BUm}BUm
CCXZ
B,%IC
333CUm
BUm}C
::B@
BUm}B
CC,;
C,%IC,%
333CUm}CUm
7T=
=#1A=P
;block8_box/conv_cls_pos/Conv2D
block8_box/conv_cls_neg/Conv2D
block7_box/conv_cls_pos/Conv2D
block7_box/conv_cls_neg/Conv2D
block6_box/conv_cls/Conv2D/q
block9_box/conv_cls/Conv2D/q
block10_box/conv_cls/Conv2D/q
block11_box/conv_cls/Conv2D/q
block8_box/conv_loc/Conv2D/q
block7_box/conv_loc/Conv2D/q
block6_box/conv_loc/Conv2D/q
block9_box/conv_loc/Conv2D/q
block10_box/conv_loc/Conv2D/q
block11_box/conv_loc/Conv2D/q
BUm}BUm
NBUm
B333Cjy[C
333CUm
BUm}C
Bjy[C
BUm}B
B333C33
Bjy[C
333CUm}CUm
Cjy[C
ff&?
>ff&?
ff&?
7>q 
=9{'=4
<block8_box/conv_cls/Conv2D
block7_box/conv_cls/Conv2D
block6_box/conv_cls/Conv2D
block9_box/conv_cls/Conv2D
block10_box/conv_cls/Conv2D
block11_box/conv_cls/Conv2D
block8_box/conv_loc/Conv2D
block7_box/conv_loc/Conv2D
block6_box/conv_loc/Conv2D
block9_box/conv_loc/Conv2D
block10_box/conv_loc/Conv2D
block11_box/conv_loc/Conv2D
block8_box/conv_roll/Conv2D
block7_box/conv_roll/Conv2D
block6_box/conv_roll/Conv2D
block9_box/conv_roll/Conv2D
block10_box/conv_roll/Conv2D
block11_box/conv_roll/Conv2D
block8_box/conv_yaw/Conv2D
block7_box/conv_yaw/Conv2D
block6_box/conv_yaw/Conv2D
block9_box/conv_yaw/Conv2D
block10_box/conv_yaw/Conv2D
block11_box/conv_yaw/Conv2D
NSt3__120__shared_ptr_emplaceIN2ft16CinematicTrackerENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft5FrameENS_9allocatorIS2_EEEE
N2ik17PixelBufferTensorE
N2ik6TensorE
N2ik11EspressoNetE
NSt3__120__shared_ptr_emplaceIN2ik4core16EspressoNetStateENS_9allocatorIS3_EEEE
N2ik14InferenceErrorE
NSt3__120__shared_ptr_emplaceIN2ik4core18PixelBufferStorageENS_9allocatorIS3_EEEE
N2ik4core18PixelBufferStorageE
N2ik13TensorStorageE
NSt3__120__shared_ptr_pointerIPhNS_10shared_ptrIA_hE27__shared_ptr_default_deleteIS3_hEENS_9allocatorIhEEEE
NSt3__110shared_ptrIA_hE27__shared_ptr_default_deleteIS1_hEE
N2ik4core24CorePixelBufferScopeLockE
N2ik20PixelBufferScopeLockE
N2ik4core14EspressoBinderE
N2ik6BinderE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_emplaceIN2ik4core21EspressoBufferStorageENS_9allocatorIS3_EEEE
N2ik4core21EspressoBufferStorageE
NSt3__117bad_function_callE
<G_96/Conv_4/Conv2D/q
zDNSt3__120__shared_ptr_emplaceIN2ft11KalmanTrackENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft10ProxyTrackENS_9allocatorIS2_EEEE
N2ft5TrackE
1.7.3
=S>D=
\;conv2d_sm/convolution/q
conv2d_lb/convolution/q
conv2d_rb/convolution/q
conv2d_pitch/convolution/q
conv2d_yaw/convolution/q
conv2d_roll/convolution/q
conv2d_eye/convolution/q
procedure_1
procedure_2
procedure_3
procedure_4
procedure_5
procedure_6
procedure_7
procedure_8
procedure_9
procedure_10
NSt3__120__shared_ptr_pointerIP10__CVBufferPFvS2_ENS_9allocatorIS1_EEEE
PFvP10__CVBufferE
N2ft10ProxyTrackE
N2ft20SiameseRpnStageErrorE
attr
7R=]
o->f
BoxEncoding_0/Conv2D/q
BoxEncoding_1/Conv2D/q
BoxEncoding_2/Conv2D/q
BoxEncoding_3/Conv2D/q
BoxEncoding_4/Conv2D/q
BoxEncoding_5/Conv2D/q
ClassPredictor_0/Conv2D/q
ClassPredictor_1/Conv2D/q
ClassPredictor_2/Conv2D/q
ClassPredictor_3/Conv2D/q
ClassPredictor_4/Conv2D/q
ClassPredictor_5/Conv2D/q
?ff&?ff&?ff&?ff&?ff&?
,_?33s?33s?33s?33s?33s?
Prior time step not established.
Frame has invalid timestamp.
kalman
preProcess
acattrnode.cpp
numFaces <= 10
bmBufferDequantizeInt8
bmbufferprivate.h
input.pixelFormat == kBmBufferPixelFormatType_Int8
input.height == output.height
input.width == output.width
bmBufferDequantizeUInt8
input.pixelFormat == kBmBufferPixelFormatType_UInt8
bmBufferPixelAtFloat
x < buf.width && y < buf.height
bmBufferPixelSize
false
ttDetCategoryFromIsp
ttdetrect.cpp
cat < CISP_TT_DET_CATEGORY_COUNT
vector
acCropResizeGenerateConfig
accropresize.cpp
!(dstWidth & 0x01) && !(dstHeight & 0x01)
srcPyrInfo.numLevels <= 4
pyrInd == 0 || srcPyrInfo.widths[pyrInd] <= srcPyrInfo.widths[pyrInd - 1]
pyrInd == 0 || srcPyrInfo.heights[pyrInd] <= srcPyrInfo.heights[pyrInd - 1]
xStartY < srcPyrInfo.widths[crop.pyrIndex]
yStartY < srcPyrInfo.heights[crop.pyrIndex]
init
acdetnode.cpp
count
m_config.fmBboxCounts[scaleInd]
bboxBufChCount
state.magic == 0xde71
classBufChCount
classPosBufChCount
classNegBufChCount
rollBufChCount
yawBufChCount
getClsBufferInds
posInd != ((uint32_t)-1)
negInd != ((uint32_t)-1)
acDetCategoryToIsp
cat != kAcDetCategory_Background
cat < kAcDetCategoryMax
acAttrReduceSmile
acattrreduce.cpp
smileThreshold <= 100
acAttrReduceBlink
(*netOutput).height >= kOutputCount
blinkThreshold <= 100
occludedThreshold <= 100
acAttrReduceYaw
numBins <= 10
acAttrReduceRoll
acDetRectSmallRectSuppression
acdetrect.cpp
sortedRects[justSelected].score >= sortedRects[check].score
remaining <= check
acDetRectLowMergeCountSuppression
acDetRectWeightedMerge
rects
acDetCategoryFromIsp
cat < CISP_AC_DET_CATEGORY_COUNT
instancePostProcess
tttrkrpnnode.cpp
netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Half || netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Float
setUpNetBuffers
ptr - (const uint8_t*)netBufferPtrs.instanceCrop == params.instanceCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.exemplarCrop == params.exemplarCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.templateKernels[i] == params.templateNetOutBatchBytes[i]
ptr - (const uint8_t*)netBufferPtrs.xcorrOutputs[i] == params.xcorrNetOutBatchBytes[i]
bmBufferDequantizeHalf
input.pixelFormat == kBmBufferPixelFormatType_Half
output.pixelFormat == kBmBufferPixelFormatType_Float
identifier
objectKind
lastDetectionTime
boxConfidence
detectionConfidence
lastTappedTime
isHighPriority
sourceObservationId
isTapSpawned
metadata
sourceFrameTimestamp
tracks
mostRecentTapTime
detectorDidRun
SiameseRPN at invalid stage: 
subject_tracking_initializer_v2
image
net_exempler_reg
net_exempler_cls
r1_kernel
cls1_kernel
subject_tracking_tracker_v2
instance_image
regress_adjust
classification_x_corr
None
Initialize
Track
TapToBox
Unknown
Track not yet initialized.
basic_string
Observation timestamp does not match frame timestamp.
int8
uint8
uint10
uint12
uint14
uint16
float
half
map::at:  key not found
v8@?0
com.apple.FusionTracker
default
com.apple.coremedia
enable_tap_to_track_overlap_with_isp_mitigation
ttt_rpn_precision_level
simResizeVisPipeBinning
simresizevispipe.cpp
startX == 0.0f && startY == 0.0f
xStep == 1 || xStep == 2 || xStep == 4 || xStep == 8
yStep == 1 || yStep == 2 || yStep == 4 || yStep == 8
simResizeVisPipe
scaleX <= ISP_RESIZE_MAX_SCALE && scaleY <= ISP_RESIZE_MAX_SCALE
scaleX >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE && scaleY >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE
(scaleX <= 1 && scaleY <= 1) || (method != SimResizeVisPipeMethod::Area)
output.width <= ISP_RESIZE_MAX_WIDTH
output.height <= ISP_RESIZE_MAX_HEIGHT
bmBufferPixelAtUInt16
inputHandler
input.rowBytes % sizeof(uint16_t) == 0
input.rowBytes == shiftedInput.rowBytes
input.width == shiftedInput.width
input.height == shiftedInput.height
input.pixelFormat == shiftedInput.pixelFormat
input.pixelFormat == kBmBufferPixelFormatType_UInt16
outputHandler
output.rowBytes % sizeof(uint16_t) == 0
acNonMaxSuppression
acnonmaxsuppression.cpp
__null != rects
acCrossClassSuppression
acNonMaxSuppressionSmallbox
acRemoveOverlapBoxes
numRects <= tempBytes
offsets_0
offsets_1
offsets_2
offsets_3
offsets_4
offsets_5
logits_roll_0
logits_roll_1
logits_roll_2
logits_roll_3
logits_roll_4
logits_roll_5
logits_yaw_0
logits_yaw_1
logits_yaw_2
logits_yaw_3
logits_yaw_4
logits_yaw_5
Detector post processing
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
+N9mZUAHooNvMiQnjeTJ8g
Error encountered during: 
 [espresso error: 
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Null CVPixelBuffer encountered.
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
Unknown data type
Unsupported CVPixelBuffer type: 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Model has no pre-declared outputs.
Executing plan
Unsupported image buffer type
Binding vImage_Buffer
Binding CVPixelBuffer
Binding espresso_buffer_t
Binding output buffer
Unsupported tensor rank: 
Unsupported espresso type encountered.
Unpacking tensor shape
Detector op failed: 
 / internal code = 
unordered_map::at: key not found
Create detector
Start detector
Get detector params
Incorrect data type requested.
Expected a rank 4 NCHW tensor.
bmBufferResizeCHW
bmbuffergeometry.cpp
bmBufferPartialResizeCHW
bmBufferResizeCoordConvert
pad < kBmBufferResizePadMax
srcW && srcH && dstW && dstH
bmBufferResizeCoordConvertReversed
bmBufferResize2xCHW
dst.pixelFormat == src.pixelFormat
src.pixelFormat == kBmBufferPixelFormatType_Int8
srcViewHeight * numChannels == src.height
dstViewHeight * numChannels == dst.height
bmBufferPixelAtInt8
bmBufferResize2xSingleChannelCHW
src.height > 0
dst.width == src.width * 2
dst.height == src.height * 2
bmBufferResizeBicubicCHW
bmBufferResizeBicubicSingleChannelCHW
src.width && src.height
dst.width >= src.width
dst.height >= src.height
src.pixelFormat == kBmBufferPixelFormatType_Float
dst.pixelFormat == kBmBufferPixelFormatType_Float
bmArgMax
bmmath.cpp
Unknown track type encountered: 
proxy
Expected exactly one input image. Found: %zd instead.
/System/Library/ImagingNetworks
/System/Library/PrivateFrameworks/Celestial.framework
com.apple.Celestial
classifiers
.espresso.net
B24@?0@"NSString"8@"NSDictionary"16
q24@?0@"NSString"8@"NSString"16
.net
Predict called before initialization
Failed to create IOSurface-backed CVPixelBuffer.
Failed to create pixel buffer pool. Status = 
Failed to create pixel buffer. Status = 
ttNonMaxSuppression
ttnonmaxsuppression.cpp
ttNonMaxSuppression2
ttNonMaxSuppressionSmallbox
ttRemoveOverlapBoxes
simResizeBGRA8888AccelerateFramework
simresize.cpp
dstViewWidth <= dstWidth
dstViewHeight <= dstHeight
simImageChMeanGetTempBuffers
numTempBytes >= bs.totalBytes()
append
bmmixedbufsize.h
!m_nextChunkOffset
nextChunk
m_nextChunkOffset <= m_totalBytes
Exemplar pre-processing
Fetching exemplar ROI
Exemplar post-processing
Instance pre-processing
Fetching instance ROI
Instance post-processing
Expected to be in stage 
. Curent stage instead: 
SiameseRpn op failed: 
Tracker handle creation
Get tracker params
RPN start
espresso.net
input_color_image
input_tap_image
prediction
tap_to_box_v2_fp16
addToHeap
ttHeap.cpp
heap->magic == 0x12345678
removeFromHeap
acDetBboxCoderDecodeAll
acdetbboxcoder.cpp
7 == config.categoryCount || 5 == config.categoryCount
config.posChannelCounts[layerInd] > 0
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Int8
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Int8
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Int8
rollBuf.pixelFormat == kBmBufferPixelFormatType_Int8
yawBuf.pixelFormat == kBmBufferPixelFormatType_Int8
layerHeight * numLogitsUniPosChs == logitsUniPosBuf->height
logitsUniPosBuf->width == offsetsBuf.width
layerHeight * numDefaults * 4 == offsetsBuf.height
globalDefaultBoxInd < defaultBoxWidthsHeightsLen
outBoxInd < maxOutBoxes
acDetBboxCoderDecodeAllFloat
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Float
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Float
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Float
rollBuf.pixelFormat == kBmBufferPixelFormatType_Float
yawBuf.pixelFormat == kBmBufferPixelFormatType_Float
logitsUniPosStride * (uint32_t)sizeof(float) == layerHeight * logitsUniPosBuf->rowBytes
acDetBboxCoderPoseDegrees
predictions.width == numPoseBins
bmMunkres
bmmunkres.cpp
size > 0
maxMatches >= size
xi != 0
bmMunkresGetTempBuffers
tempBuffers
bmMunkresMaxAssignmentsGetTempBuffers
bmMunkresSubtractMinPerRow
rowMin >= 0
minCol < costBuf.height
bmMunkresSubtractMinPerCol
colMin >= 0
minRow < costBuf.width
bmMunkresMaxAssignments
temp
0 <= aCol[r]
bmBufferPixelAtUInt8
bmMunkresUpdateCost
rowLineFlags != nullptr
colLineFlags != nullptr
MSR not available on current platform.
Unable to locate model: 
Tracking result was nil.
Unexpected number of tracks detected. Expected at most one. Found: 
Tracking state was nil.
High priority tracking state was nil.
Invalid high priority tracking op encountered: 
Color buffer preprocessing failed
Exemplar preprocessing failed.
Tracker preprocessing failed.
No active tracking session present.
Instance preprocessing failed.
Instance post-processing failed.
0000000
Tap-to-track det
ttDetCategoryToIsp
ttdetnode.cpp
cat != kTtDetCategory_Background
cat < kTtDetCategoryMax
ttAssocSetUpMunkresCost
ttassoc.cpp
costBufLen >= costMatSize * costMatSize
ttAssocCore
unmatchedDetObjectCount < unmatchedDetObjectsLen
ti < numTrkObjects
ttAssocTrkDetGetTempBuffers
ttAssocObjectRemoveKilled
minKillLevel > kTtAssocObjectKillFlag_None
ttAssocTrkDet
numTrkObjects <= maxTrkObjects
numDetObjects <= maxTrkObjects
tempBufBytes >= ttAssocTrkDetTempBytes(maxTrkObjects)
isDetRunningThisFrame || !numDetObjects
costMatSize * costMatSize <= maxTrkObjects * maxTrkObjects
ki >= n
i == 0 || trkObjects[ti].age <= trkObjects[killTemp[i - 1].index].age
trkObjects[ti].killFlag == kTtAssocObjectKillFlag_Maybe
numTrkObjects - trkKillCount + unmatchedDetObjectCount <= maxTrkObjects
newNumTrkObjects < maxTrkObjects
TtAssocObjectRemoveOldOverlapObjects
trkObjects->objects[justSelected].age <= trkObjects->objects[check].age
RPN score cutoff set to %0.4f
Requested source rect is invalid.
Post processing invoked multiple times.
Internal inconsistency: high priority track missing during tracking update.
Operation requested for high priority tracking not completed.
Invalid commit token. State: %llu, Tracker: %llu.
Internal inconsistency: observation index out of bounds: %zd
A previous tracking state has not been committed.
FusionTracker error: %s
Internal inconsistency: detection-less track is not high-priority.
Terminating detectionless track. IoU exceeded: %0.2f > %0.2f
RPN Precision Level set to %d (defaults value: %d)
Encountered an error during: %s
 -> Espresso Error: %s
Bipartite matching exception: %s
Observation ID has internal track mask set.
Duplicate track ID provided in observation: %lld
TapToBox prediction below threshold.
Network not found: %s
Tap buffer size mismatch.
Failed to get tap buffer base address.
Tap coordinates are out of bounds.
TapToBox tap rendering failed.
TapToBox preprocessing resample failed.
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_DestinationRectangle
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_ScalingMode to 'kVTScalingMode_CropSourceToCleanAperture'
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_SourceCropRectangle
FTVTScaler error: VTPixelTransferSessionTransferImage failed
FTVTScaler error: dstBuffer has unsupported pixelformat. Mean computation only supported for dstBuffer formats: 'kCVPixelFormatType_32BGRA'
MSR preprocessing failed.
SiameseRPN exemplar network loaded: %s
SiameseRPN instance network loaded: %s
FTCinematicTapToTrack error: %s
FTCinematicTrack
NSSecureCoding
NSCoding
FTCinematicTapRequest
FTCinematicTapResponse
FTCinematicTrackingResult
FTCinematicHighPriorityTrackerState
FTCinematicTrackingState
FTCinematicInput
FTCinematicTracker
FTCinematicConfig
FTBipartiteMatcher
FTImageTensorDescriptor
FTTensorReference
FTNetworkDescriptor
FTEspressoBuffer
FTUtils
FTTapToBox
FTVTScaler
FTScaling
FTTapToTrackPreprocessor
FTCinematicTapToTrack
T@"NSDictionary",&,N,V_metadata
.cxx_destruct
T{?=qiIq},N,V_mostRecentTapTime
T@"FTCinematicInput",R,N,V_input
_detectorDidRun
T@"FTCinematicTapRequest",&,N,V_tapRequest
_inputTapTensor
T@"FTCinematicTrack",&,N,V_tappedTrack
_lastTappedTime
T@"NSArray",&,N,V_inputReferences
_scaler
T@"NSArray",&,N,V_outputNames
_tracks
T@"NSMutableDictionary",&,N,V_sessionStorage
T@"NSString",&,N,V_name
bundleWithPath:
T@"NSString",&,N,V_sourceOutputName
initWithConfig:
TB,N,V_detectorDidRun
initWithScaler:
TB,N,V_isHighPriority
request
TB,N,V_wasSuccessful
setBox:
TI,N,V_pixelFormat
setOutputNames:
TQ,V_sourceObservationId
setTapPosition:
Tf,N,V_detectionConfidence
setTappedTrack:
Tq,N,V_identifier
trackId
.cxx_construct
T{?=qiIq},N,V_lastDetectionTime
T@"FTCinematicHighPriorityTrackerState",R,N,V_highPriorityTrackerState
_buffer
T@"FTCinematicTapRequest",&,N,V_request
_device
T@"FTCinematicTapResponse",&,N,V_tapResponse
_isHighPriority
T@"NSArray",&,N,V_inputImages
T@"NSArray",&,N,V_observations
_sessionStorage
T@"NSArray",&,N,V_tracks
bgraPixelBuffer
T@"NSString",&,N,V_destinationInputName
bundleForClass:
T@"NSString",&,N,V_sourceNetworkName
dealloc
TB,N,V_allowTrackPromotion
initWithDevice:
TB,N,V_ensureObservationTimestampMatchesFrame
inputReferences
TB,N,V_isTapSpawned
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:
TB,R
setInputImages:
TQ,N,V_objectKind
setPixelFormat:
Tf,N,V_boxConfidence
setTapResponse:
Tq,N,V_highPriorityTrackId
stringByAppendingPathComponent:
Tq,N,V_op
Tq,N,V_trackId
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},R,N,V_buffer
T{?=qiIq},N,V_lastTappedTime
T{?=qiIq},N,V_sourceFrameTimestamp
T{CGPoint=dd},N,V_tapPoint
T{CGPoint=dd},N,V_tapPosition
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_box
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_targetRect
T{CGSize=dd},N,V_size
UTF8String
_allowTrackPromotion
_box
_boxConfidence
_commandQueue
_commitToken
_destinationInputName
_detectionConfidence
_ensureObservationTimestampMatchesFrame
_espressoConfigFromDescriptor:engine:
_exemplarCrop
_exemplarNet
_exemplarNetDesc
_finalized
_frame
_highPriorityTrackId
_highPriorityTrackerState
_identifier
_input
_inputImageTensor
_inputImages
_inputMap
_inputReferences
_instanceCrop
_instanceNet
_instanceNetDesc
_intermediateBuffer
_isTapSpawned
_isTapToTrack
_isTapToTrackOverlapWithIspMitigationEnabled
_lastDetectionTime
_maybeFetchTrackByCommittingState:
_meanFilter
_meanPixel
_meanTexture
_metadata
_mostRecentTapTime
_name
_net
_objectKind
_observations
_optimizer
_outputNames
_outputTensor
_pixelFormat
_preprocessBuffer:andValidateState:isOp:
_preprocessor
_request
_resolveNetworkPath:
_setup
_setupNetworksWithEngine:
_setupOp
_setupScalerWithBackend:
_setupSessionStorage
_size
_sourceFrameTimestamp
_sourceNetworkName
_sourceObservationId
_sourceOutputName
_tapPoint
_tapPosition
_tapRequest
_tapResponse
_tapToBox
_tappedTrack
_targetRect
_trackId
_tracker
_transferSession
_unsafeMeanFillAndScaleSourceBuffer:destinationBuffer:sourceRect:meanPixel:scaler:
_unsafeStartTrackingRect:colorBuffer:
_unsafeStepTrackingWithFrame:
_updateHighPriorityTrackWithRect:confidence:isTapToTrack:
_validatePostProcessingInvocation
_wasSuccessful
abort
addObject:
allowTrackPromotion
array
arrayWithCapacity:
arrayWithObjects:count:
bgraImageWithName:size:
bgraSquareImageWithName:size:
boolForKey:
boxConfidence
buffer
bufferWithEspressoBuffer:
bundleWithIdentifier:
commandBuffer
commit
compare:options:
completed
computeMatchingForCostMatrix:withRowCount:columnCount:
computeTrackingStateForInput:
confidence
contentsOfDirectoryAtPath:error:
count
countByEnumeratingWithState:objects:count:
decodeBoolForKey:
decodeFloatForKey:
decodeInt64ForKey:
decodeObjectOfClasses:forKey:
defaultConfidenceThreshold
defaultManager
descriptorWithName:size:pixelFormat:
destinationInputName
detectionConfidence
detectorDidRun
device
dictionary
dictionaryWithCapacity:
dictionaryWithObjects:forKeys:count:
encodeBool:forKey:
encodeFloat:forKey:
encodeInt64:forKey:
encodeObject:forKey:
encodeToCommandBuffer:sourceTexture:destinationTexture:
encodeWithCoder:
ensureObservationTimestampMatchesFrame
exemplarInputRoiForTargetRect:
filteredArrayUsingPredicate:
firstObject
frameTimestamp
fromTrack:isHighPriority:
fusionTracker_decodeCGRectForKey:
fusionTracker_decodeCMTimeForKey:
fusionTracker_encodeCGRect:forKey:
fusionTracker_encodeCMTime:forKey:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
hasPrefix:
hasSuffix:
highPriorityExemplarNetworkDescriptor
highPriorityInstanceNetworkDescriptor
highPriorityTrackId
highPriorityTrackerState
identifier
init
initWithCapacity:
initWithCoder:
initWithCommandQueue:
initWithEspressoEngine:scalingBackend:commandQueue:
initWithInitialSize:
initWithSuiteName:
initWithTracker:frame:
input
inputImages
instanceInputRoi
integerForKey:
isHighPriority
isTapSpawned
isTrackingActive
lastDetectionTime
lastDetectionTimestamp
lastPathComponent
lastTappedTime
mapToInternalObservations
meanPixel
metadata
mostRecentTapTime
name
networkDescriptor
networkInputImageSize
networkInputTapImageSize
networkPath
newTextureWithDescriptor:
newTextureWithDescriptor:iosurface:plane:
numberWithLongLong:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKeyedSubscript:
objectKind
observations
onlyImageInput
opDescription
outputNames
pathForResource:ofType:
pathsForResourcesOfType:inDirectory:
pixelFormat
postProcessExemplarOutputs:forTargetRect:
postProcessInstanceOutputs:
postProcessNetworkOutput:
preProcessExemplarInputFromSourceBuffer:toDestinationBuffer:forTargetRect:meanPixel:scaler:
preProcessInstanceInputFromSourceBuffer:toDestinationBuffer:meanPixel:scaler:
predicateWithBlock:
predictBoxForTap:inBuffer:scaler:
predictRectForPoint:inColorBuffer:
predictionForTap:inBuffer:scaler:
preprocessBuffer:
preprocessForTap:inSourceImageBuffer:destinationImageBuffer:tapBuffer:scaler:
renderTap:inBuffer:
reset
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:mean:
sessionStorage
setAllowTrackPromotion:
setBoxConfidence:
setDestinationInputName:
setDetectionConfidence:
setDetectorDidRun:
setEnsureObservationTimestampMatchesFrame:
setHighPriorityTrackId:
setIdentifier:
setInputReferences:
setIsHighPriority:
setIsTapSpawned:
setLastDetectionTime:
setLastTappedTime:
setMetadata:
setMostRecentTapTime:
setName:
setObject:forKeyedSubscript:
setObjectKind:
setObservations:
setOp:
setRequest:
setSessionStorage:
setSize:
setSourceFrameTimestamp:
setSourceNetworkName:
setSourceObservationId:
setSourceOutputName:
setTapPoint:
setTapRequest:
setTargetRect:
setTrackId:
setTracks:
setUsage:
setValue:forKey:
setWasSuccessful:
setWithArray:
size
sortedArrayUsingComparator:
sourceFrameTimestamp
sourceNetworkName
sourceObservationId
sourceOutputName
startTrackingRect:colorBuffer:
stateWithTracker:frame:input:
stepTrackingWithFrame:
stringByAppendingString:
stringWithUTF8String:
supportsSecureCoding
tapPoint
tapPosition
tapRequest
tapResponse
tapToBoxNetworkDescriptor
tappedTrack
targetRect
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
trackerWithCommandQueue:
tracks
waitUntilCompleted
wasSuccessful
B16@0:8
@36@0:8{shared_ptr<ft::Track>=^{Track}^{__shared_weak_count}}16B32
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@16@0:8
q16@0:8
v24@0:8q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q16@0:8
v24@0:8Q16
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
f16@0:8
v20@0:8f16
v20@0:8B16
v16@0:8
@"NSDictionary"
{?="value"q"timescale"i"flags"I"epoch"q}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
@"FTCinematicTapRequest"
@"FTCinematicTrack"
@"NSArray"
@"FTCinematicTapResponse"
@48@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B76@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}3264@68
B44@0:8^{__CVBuffer=}16^{__CVBuffer=}2432@36
B60@0:8{Rect<double>=dddd}16d48B56
B56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
B24@0:8@16
{shared_ptr<ft::CinematicTracker>="__ptr_"^{CinematicTracker}"__cntrl_"^{__shared_weak_count}}
{shared_ptr<ft::Frame>="__ptr_"^{Frame}"__cntrl_"^{__shared_weak_count}}
@"NSMutableDictionary"
@56@0:8{shared_ptr<ft::CinematicTracker>=^{CinematicTracker}^{__shared_weak_count}}16{shared_ptr<ft::Frame>=^{Frame}^{__shared_weak_count}}32@48
@"FTCinematicHighPriorityTrackerState"
@"FTCinematicInput"
{vector<ft::Observation, std::allocator<ft::Observation>>=^{Observation}^{Observation}{__compressed_pair<ft::Observation *, std::allocator<ft::Observation>>=^{Observation}}}16@0:8
@24@0:8Q16
@40@0:8r^f16Q24Q32
{unique_ptr<ft::HungarianMatcher, std::default_delete<ft::HungarianMatcher>>="__ptr_"{__compressed_pair<ft::HungarianMatcher *, std::default_delete<ft::HungarianMatcher>>="__value_"^{HungarianMatcher}}}
@44@0:8@16{CGSize=dd}24I40
@40@0:8@16{CGSize=dd}24
@32@0:8@16d24
I16@0:8
v20@0:8I16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
@"NSString"
{CGSize="width"d"height"d}
@184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v48@0:8{?=qiIq}16@40
{?=qiIq}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
B40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B64@0:8{CGPoint=dd}16^{__CVBuffer=}32^{__CVBuffer=}40^{__CVBuffer=}48@56
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
d16@0:8
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{unique_ptr<ik::EspressoNet, std::default_delete<ik::EspressoNet>>="__ptr_"{__compressed_pair<ik::EspressoNet *, std::default_delete<ik::EspressoNet>>="__value_"^{EspressoNet}}}
{PixelBufferTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
{unordered_map<std::string, ik::Tensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, ik::Tensor>>>="__table_"{__hash_table<std::__hash_value_type<std::string, ik::Tensor>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, ik::Tensor>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{EspressoTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
B96@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
B104@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64^96
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageStatisticsMean"
@"<MTLTexture>"
^{OpaqueVTPixelTransferSession=}
B24@0:8^{__CVBuffer=}16
^{__CVBuffer=}16@0:8
16@0:8
{shared_ptr<__CVBuffer>="__ptr_"^{__CVBuffer}"__cntrl_"^{__shared_weak_count}}
@"<FTScaling>"
@32@0:8i16i20@24
v20@0:8i16
v24@0:8r^v16
{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*Qb63b1}{__short=[23c][0C]b7b1}{__raw=[3Q]})}}}24@0:8@16
{EspressoConfig={vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}{optional<espresso_engine_t>=(?=ci)B}iii{optional<espresso_plan_priority_t>=(?=ci)B}{optional<void *>=(?=c^v)B}{unordered_map<std::string, espresso_simple_image_preprocessing_params_t, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, espresso_simple_image_preprocessing_params_t>>>={__hash_table<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>>>={unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>={__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>>=^^v{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>={__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *> *>>=Q}}}}{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *>>>={__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, void *> *>=^v}}{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::hash<std::string>, std::equal_to<std::string>, true>>=Q}{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, espresso_simple_image_preprocessing_params_t>, std::equal_to<std::string>, std::hash<std::string>, true>>=f}}}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>={__rep=(?={__long=*Qb63b1}{__short=[23c][0C]b7b1}{__raw=[3Q]})}}}}32@0:8@16r^v24
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}40@0:8{CGPoint=dd}16^{__CVBuffer=}32
v40@0:8^{__CVBuffer=}16@24q32
B56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8^{__CVBuffer=}16
@"FTTapToTrackPreprocessor"
@"FTNetworkDescriptor"
@"FTTapToBox"
@"FTCinematicTracker"
