@(#)PROGRAM:FusionTracker  PROJECT:FusionTracker-1
?N2ft11KalmanTrackE
NxA@
BUm}BUm
CCXZ
B,%IC
333CUm
BUm}C
::B@
BUm}B
CC,;
C,%IC,%
333CUm}CUm
7T=
=#1A=P
;block8_box/conv_cls_pos/Conv2D
block8_box/conv_cls_neg/Conv2D
block7_box/conv_cls_pos/Conv2D
block7_box/conv_cls_neg/Conv2D
block6_box/conv_cls/Conv2D/q
block9_box/conv_cls/Conv2D/q
block10_box/conv_cls/Conv2D/q
block11_box/conv_cls/Conv2D/q
block8_box/conv_loc/Conv2D/q
block7_box/conv_loc/Conv2D/q
block6_box/conv_loc/Conv2D/q
block9_box/conv_loc/Conv2D/q
block10_box/conv_loc/Conv2D/q
block11_box/conv_loc/Conv2D/q
Ga==
BUm}BUm
NBUm
B333Cjy[C
333CUm
BUm}C
Bjy[C
BUm}B
B333C33
Bjy[C
333CUm}CUm
Cjy[C
ff&?
>ff&?
ff&?
7>q 
=9{'=4
<block8_box/conv_cls/Conv2D
block7_box/conv_cls/Conv2D
block6_box/conv_cls/Conv2D
block9_box/conv_cls/Conv2D
block10_box/conv_cls/Conv2D
block11_box/conv_cls/Conv2D
block8_box/conv_loc/Conv2D
block7_box/conv_loc/Conv2D
block6_box/conv_loc/Conv2D
block9_box/conv_loc/Conv2D
block10_box/conv_loc/Conv2D
block11_box/conv_loc/Conv2D
block8_box/conv_roll/Conv2D
block7_box/conv_roll/Conv2D
block6_box/conv_roll/Conv2D
block9_box/conv_roll/Conv2D
block10_box/conv_roll/Conv2D
block11_box/conv_roll/Conv2D
block8_box/conv_yaw/Conv2D
block7_box/conv_yaw/Conv2D
block6_box/conv_yaw/Conv2D
block9_box/conv_yaw/Conv2D
block10_box/conv_yaw/Conv2D
block11_box/conv_yaw/Conv2D
N2ik6TensorE
NSt3__117bad_function_callE
@trk
<G_96/Conv_4/Conv2D/q
zDNSt3__120__shared_ptr_emplaceIN2ft11KalmanTrackENS_9allocatorIS2_EEEE
NSt3__120__shared_ptr_emplaceIN2ft10ProxyTrackENS_9allocatorIS2_EEEE
N2ft5TrackE
1.7.3
=S>D=
\;conv2d_sm/convolution/q
conv2d_lb/convolution/q
conv2d_rb/convolution/q
conv2d_pitch/convolution/q
conv2d_yaw/convolution/q
conv2d_roll/convolution/q
conv2d_eye/convolution/q
procedure_1
procedure_2
procedure_3
procedure_4
procedure_5
procedure_6
procedure_7
procedure_8
procedure_9
procedure_10
NSt3__120__shared_ptr_pointerIP10__CVBufferPFvS2_ENS_9allocatorIS1_EEEE
PFvP10__CVBufferE
N2ft10ProxyTrackE
N2ft20SiameseRpnStageErrorE
attr
7R=]
o->f
BoxEncoding_0/Conv2D/q
BoxEncoding_1/Conv2D/q
BoxEncoding_2/Conv2D/q
BoxEncoding_3/Conv2D/q
BoxEncoding_4/Conv2D/q
BoxEncoding_5/Conv2D/q
ClassPredictor_0/Conv2D/q
ClassPredictor_1/Conv2D/q
ClassPredictor_2/Conv2D/q
ClassPredictor_3/Conv2D/q
ClassPredictor_4/Conv2D/q
ClassPredictor_5/Conv2D/q
?ff&?ff&?ff&?ff&?ff&?
,_?33s?33s?33s?33s?33s?
'7N2ik14InferenceErrorE
N2ik11EspressoNetE
N2ik14EspressoTensorE
NSt3__120__shared_ptr_emplaceIN2ik21EspressoBufferStorageENS_9allocatorIS2_EEEE
N2ik21EspressoBufferStorageE
N2ik13TensorStorageE
N2ik17PixelBufferTensorE
NSt3__120__shared_ptr_emplaceIN2ik18PixelBufferStorageENS_9allocatorIS2_EEEE
N2ik18PixelBufferStorageE
Prior time step not established.
Frame has invalid timestamp.
kalman
preProcess
acattrnode.cpp
numFaces <= 10
bmBufferDequantizeInt8
bmbufferprivate.h
input.pixelFormat == kBmBufferPixelFormatType_Int8
input.height == output.height
input.width == output.width
bmBufferDequantizeUInt8
input.pixelFormat == kBmBufferPixelFormatType_UInt8
bmBufferPixelAtFloat
x < buf.width && y < buf.height
bmBufferPixelSize
false
ttDetCategoryFromIsp
ttdetrect.cpp
cat < CISP_TT_DET_CATEGORY_COUNT
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
acCropResizeGenerateConfig
accropresize.cpp
!(dstWidth & 0x01) && !(dstHeight & 0x01)
srcPyrInfo.numLevels <= 4
pyrInd == 0 || srcPyrInfo.widths[pyrInd] <= srcPyrInfo.widths[pyrInd - 1]
pyrInd == 0 || srcPyrInfo.heights[pyrInd] <= srcPyrInfo.heights[pyrInd - 1]
xStartY < srcPyrInfo.widths[crop.pyrIndex]
yStartY < srcPyrInfo.heights[crop.pyrIndex]
init
acdetnode.cpp
count
m_config.fmBboxCounts[scaleInd]
bboxBufChCount
state.magic == 0xde71
classBufChCount
classPosBufChCount
classNegBufChCount
rollBufChCount
yawBufChCount
getClsBufferInds
posInd != ((uint32_t)-1)
negInd != ((uint32_t)-1)
acDetCategoryToIsp
cat != kAcDetCategory_Background
cat < kAcDetCategoryMax
acAttrReduceSmile
acattrreduce.cpp
smileThreshold <= 100
acAttrReduceBlink
(*netOutput).height >= kOutputCount
blinkThreshold <= 100
occludedThreshold <= 100
acAttrReduceYaw
numBins <= 10
acAttrReduceRoll
acDetRectSmallRectSuppression
acdetrect.cpp
sortedRects[justSelected].score >= sortedRects[check].score
remaining <= check
acDetRectLowMergeCountSuppression
acDetRectWeightedMerge
rects
acDetCategoryFromIsp
cat < CISP_AC_DET_CATEGORY_COUNT
instancePostProcess
tttrkrpnnode.cpp
netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Half || netOutputs[i].pixelFormat == kBmBufferPixelFormatType_Float
setUpNetBuffers
ptr - (const uint8_t*)netBufferPtrs.instanceCrop == params.instanceCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.exemplarCrop == params.exemplarCropBatchBytes
ptr - (const uint8_t*)netBufferPtrs.templateKernels[i] == params.templateNetOutBatchBytes[i]
ptr - (const uint8_t*)netBufferPtrs.xcorrOutputs[i] == params.xcorrNetOutBatchBytes[i]
bmBufferDequantizeHalf
input.pixelFormat == kBmBufferPixelFormatType_Half
output.pixelFormat == kBmBufferPixelFormatType_Float
map::at:  key not found
v8@?0
com.apple.FusionTracker
default
simResizeVisPipeBinning
simresizevispipe.cpp
startX == 0.0f && startY == 0.0f
xStep == 1 || xStep == 2 || xStep == 4 || xStep == 8
yStep == 1 || yStep == 2 || yStep == 4 || yStep == 8
simResizeVisPipe
scaleX <= ISP_RESIZE_MAX_SCALE && scaleY <= ISP_RESIZE_MAX_SCALE
scaleX >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE && scaleY >= ISP_RESIZE_MIN_SCALE * ISP_RESIZE_MIN_SCALE
(scaleX <= 1 && scaleY <= 1) || (method != SimResizeVisPipeMethod::Area)
output.width <= ISP_RESIZE_MAX_WIDTH
output.height <= ISP_RESIZE_MAX_HEIGHT
bmBufferPixelAtUInt16
inputHandler
input.rowBytes % sizeof(uint16_t) == 0
input.rowBytes == shiftedInput.rowBytes
input.width == shiftedInput.width
input.height == shiftedInput.height
input.pixelFormat == shiftedInput.pixelFormat
input.pixelFormat == kBmBufferPixelFormatType_UInt16
outputHandler
output.rowBytes % sizeof(uint16_t) == 0
acNonMaxSuppression
acnonmaxsuppression.cpp
__null != rects
acCrossClassSuppression
acNonMaxSuppressionSmallbox
acRemoveOverlapBoxes
numRects <= tempBytes
image
Detector post processing
Detector op failed: 
 / internal code = 
Get detector params
unordered_map::at: key not found
Incorrect data type requested.
bmBufferResizeCHW
bmbuffergeometry.cpp
bmBufferPartialResizeCHW
bmBufferResizeCoordConvert
pad < kBmBufferResizePadMax
srcW && srcH && dstW && dstH
bmBufferResizeCoordConvertReversed
bmBufferResize2xCHW
dst.pixelFormat == src.pixelFormat
src.pixelFormat == kBmBufferPixelFormatType_Int8
srcViewHeight * numChannels == src.height
dstViewHeight * numChannels == dst.height
bmBufferPixelAtInt8
bmBufferResize2xSingleChannelCHW
src.height > 0
dst.width == src.width * 2
dst.height == src.height * 2
bmBufferResizeBicubicCHW
bmBufferResizeBicubicSingleChannelCHW
src.width && src.height
dst.width >= src.width
dst.height >= src.height
src.pixelFormat == kBmBufferPixelFormatType_Float
dst.pixelFormat == kBmBufferPixelFormatType_Float
bmArgMax
bmmath.cpp
Unknown track type encountered: 
proxy
Expected exactly one input image. Found: %zd instead.
/System/Library/ImagingNetworks
/System/Library/PrivateFrameworks/Celestial.framework
com.apple.Celestial
classifiers
.espresso.net
B24@?0@"NSString"8@"NSDictionary"16
q24@?0@"NSString"8@"NSString"16
.net
Predict called before initialization
Failed to create IOSurface-backed CVPixelBuffer.
Failed to create pixel buffer pool. Status = 
Failed to create pixel buffer. Status = 
ttNonMaxSuppression
ttnonmaxsuppression.cpp
ttNonMaxSuppression2
ttNonMaxSuppressionSmallbox
ttRemoveOverlapBoxes
simResizeBGRA8888AccelerateFramework
simresize.cpp
dstViewWidth <= dstWidth
dstViewHeight <= dstHeight
simImageChMeanGetTempBuffers
numTempBytes >= bs.totalBytes()
append
bmmixedbufsize.h
!m_nextChunkOffset
nextChunk
m_nextChunkOffset <= m_totalBytes
Exemplar pre-processing
Fetching exemplar ROI
net_exempler_reg
net_exempler_cls
Exemplar post-processing
Instance pre-processing
Fetching instance ROI
classification_x_corr
Instance post-processing
Expected to be in stage 
. Curent stage instead: 
SiameseRpn op failed: 
Tracker handle creation
Get tracker params
tap_to_box_v2_fp16
espresso.net
input_color_image
input_tap_image
prediction
TapToBox
addToHeap
ttHeap.cpp
heap->magic == 0x12345678
removeFromHeap
acDetBboxCoderDecodeAll
acdetbboxcoder.cpp
7 == config.categoryCount || 5 == config.categoryCount
config.posChannelCounts[layerInd] > 0
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Int8
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Int8
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Int8
rollBuf.pixelFormat == kBmBufferPixelFormatType_Int8
yawBuf.pixelFormat == kBmBufferPixelFormatType_Int8
layerHeight * numLogitsUniPosChs == logitsUniPosBuf->height
logitsUniPosBuf->width == offsetsBuf.width
layerHeight * numDefaults * 4 == offsetsBuf.height
globalDefaultBoxInd < defaultBoxWidthsHeightsLen
outBoxInd < maxOutBoxes
acDetBboxCoderDecodeAllFloat
logitsUniPosBuf->pixelFormat == kBmBufferPixelFormatType_Float
!logitsNegBuf || logitsNegBuf->pixelFormat == kBmBufferPixelFormatType_Float
offsetsBuf.pixelFormat == kBmBufferPixelFormatType_Float
rollBuf.pixelFormat == kBmBufferPixelFormatType_Float
yawBuf.pixelFormat == kBmBufferPixelFormatType_Float
logitsUniPosStride * (uint32_t)sizeof(float) == layerHeight * logitsUniPosBuf->rowBytes
acDetBboxCoderPoseDegrees
predictions.width == numPoseBins
bmMunkres
bmmunkres.cpp
size > 0
maxMatches >= size
xi != 0
bmMunkresGetTempBuffers
tempBuffers
bmMunkresMaxAssignmentsGetTempBuffers
bmMunkresSubtractMinPerRow
rowMin >= 0
minCol < costBuf.height
bmMunkresSubtractMinPerCol
colMin >= 0
minRow < costBuf.width
bmMunkresMaxAssignments
temp
0 <= aCol[r]
bmMunkresUpdateCost
rowLineFlags != nullptr
colLineFlags != nullptr
0000000
Tap-to-track det
ttDetCategoryToIsp
ttdetnode.cpp
cat != kTtDetCategory_Background
cat < kTtDetCategoryMax
ttAssocSetUpMunkresCost
ttassoc.cpp
costBufLen >= costMatSize * costMatSize
ttAssocCore
unmatchedDetObjectCount < unmatchedDetObjectsLen
ti < numTrkObjects
ttAssocTrkDetGetTempBuffers
ttAssocObjectRemoveKilled
minKillLevel > kTtAssocObjectKillFlag_None
ttAssocTrkDet
numTrkObjects <= maxTrkObjects
numDetObjects <= maxTrkObjects
tempBufBytes >= ttAssocTrkDetTempBytes(maxTrkObjects)
isDetRunningThisFrame || !numDetObjects
costMatSize * costMatSize <= maxTrkObjects * maxTrkObjects
ki >= n
i == 0 || trkObjects[ti].age <= trkObjects[killTemp[i - 1].index].age
trkObjects[ti].killFlag == kTtAssocObjectKillFlag_Maybe
numTrkObjects - trkKillCount + unmatchedDetObjectCount <= maxTrkObjects
newNumTrkObjects < maxTrkObjects
TtAssocObjectRemoveOldOverlapObjects
trkObjects->objects[justSelected].age <= trkObjects->objects[check].age
bmBufferPixelAtUInt8
Failed to create espresso context.
Failed to create espresso plan.
Setting plan priorty
Loading espresso Network
Sharing intermediate buffer
Declaring network output
Setting preprocessing params
Building espresso plan
Executing plan
Model has no pre-declared outputs.
Model must have exactly one pre-declared output.
Binding input buffer
Binding output buffer
Error encountered during: 
 [espresso error: 
Unsupported espresso type encountered.
Failed to allocate aligned memory.
Unknown data type
Unknown data type.
Encountered an error during: %s
 -> Espresso Error: %s
Tensor types mismatch.
Tensor sizes mismatch.
Invalid dimensions requested for CVPixelBuffer creation.
Failed to create CVPixelBuffer. Status = 
Failed to lock pixel buffer.
Failed to unlock pixel buffer.
Pixel buffer is not backed by an IOSurface.
Unsupported CVPixelBuffer type: 
Null CVPixelBuffer encountered.
Binding CVPixelBuffer
Failed to get CVPixelBuffer's data. Ensure the buffer was locked.
Bipartite matching exception: %s
Observation ID has internal track mask set.
Duplicate track ID provided in observation: %lld
TapToBox prediction below threshold.
Tap buffer size mismatch.
Failed to get tap buffer base address.
Tap coordinates are out of bounds.
TapToBox tap rendering failed.
TapToBox preprocessing resample failed.
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_DestinationRectangle
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_ScalingMode to 'kVTScalingMode_CropSourceToCleanAperture'
FTVTScaler error: Failed to set kVTPixelTransferPropertyKey_SourceCropRectangle
FTVTScaler error: VTPixelTransferSessionTransferImage failed
FTVTScaler error: dstBuffer has unsupported pixelformat. Mean computation only supported for dstBuffer formats: 'kCVPixelFormatType_32BGRA'
FTBipartiteMatcher
FTImageTensorDescriptor
FTTensorReference
FTNetworkDescriptor
FTEspressoBuffer
FTUtils
FTTapToBox
FTVTScaler
FTScaling
init
initWithInitialSize:
initWithCapacity:
numberWithLongLong:
addObject:
computeMatchingForCostMatrix:withRowCount:columnCount:
.cxx_destruct
.cxx_construct
_optimizer
setName:
setSize:
setPixelFormat:
descriptorWithName:size:pixelFormat:
bgraImageWithName:size:
bgraSquareImageWithName:size:
name
pixelFormat
size
_pixelFormat
_name
_size
T@"NSString",&,N,V_name
TI,N,V_pixelFormat
T{CGSize=dd},N,V_size
sourceNetworkName
setSourceNetworkName:
sourceOutputName
setSourceOutputName:
destinationInputName
setDestinationInputName:
_sourceNetworkName
_sourceOutputName
_destinationInputName
T@"NSString",&,N,V_sourceNetworkName
T@"NSString",&,N,V_sourceOutputName
T@"NSString",&,N,V_destinationInputName
setOutputNames:
inputImages
count
firstObject
onlyImageInput
setInputImages:
inputReferences
setInputReferences:
outputNames
_inputImages
_inputReferences
_outputNames
T@"NSArray",&,N,V_inputImages
T@"NSArray",&,N,V_inputReferences
T@"NSArray",&,N,V_outputNames
bufferWithEspressoBuffer:
buffer
_buffer
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},R,N,V_buffer
bundleWithIdentifier:
bundleWithPath:
bundleForClass:
defaultManager
contentsOfDirectoryAtPath:error:
array
countByEnumeratingWithState:objects:count:
hasSuffix:
stringByAppendingPathComponent:
stringByAppendingString:
lastPathComponent
hasPrefix:
predicateWithBlock:
filteredArrayUsingPredicate:
stringWithFormat:
containsString:
compare:options:
sortedArrayUsingComparator:
UTF8String
pathsForResourcesOfType:inDirectory:
encodeObject:forKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
fusionTracker_encodeCMTime:forKey:
fusionTracker_decodeCMTimeForKey:
fusionTracker_encodeCGRect:forKey:
fusionTracker_decodeCGRectForKey:
dictionaryWithObjects:forKeys:count:
dictionary
numberWithUnsignedLong:
setValue:forKey:
stringWithUTF8String:
networkDescriptor
networkPath
objectAtIndex:
preprocessForTap:inSourceImageBuffer:destinationImageBuffer:tapBuffer:scaler:
postProcessNetworkOutput:
defaultConfidenceThreshold
predictionForTap:inBuffer:scaler:
pathForResource:ofType:
networkInputImageSize
networkInputTapImageSize
renderTap:inBuffer:
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:
predictBoxForTap:inBuffer:scaler:
_net
_inputImageTensor
_inputTapTensor
_inputMap
_outputTensor
device
initWithDevice:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setUsage:
newTextureWithDescriptor:
dealloc
scaleSourceBuffer:toDestinationBuffer:sourceROI:destinationROI:mean:
newTextureWithDescriptor:iosurface:plane:
commandBuffer
encodeToCommandBuffer:sourceTexture:destinationTexture:
commit
waitUntilCompleted
getBytes:bytesPerRow:fromRegion:mipmapLevel:
initWithCommandQueue:
_device
_commandQueue
_meanFilter
_meanTexture
_transferSession
setObject:forKey:
@24@0:8Q16
@16@0:8
@40@0:8r^f16Q24Q32
v16@0:8
{unique_ptr<ft::HungarianMatcher, std::default_delete<ft::HungarianMatcher>>="__ptr_"{__compressed_pair<ft::HungarianMatcher *, std::default_delete<ft::HungarianMatcher>>="__value_"^{HungarianMatcher}}}
@44@0:8@16{CGSize=dd}24I40
@40@0:8@16{CGSize=dd}24
@32@0:8@16d24
v24@0:8@16
I16@0:8
v20@0:8I16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
@"NSString"
{CGSize="width"d"height"d}
@"NSArray"
@184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
v48@0:8{?=qiIq}16@40
{?=qiIq}24@0:8@16
v56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
d16@0:8
B40@0:8{CGPoint=dd}16^{__CVBuffer=}32
B64@0:8{CGPoint=dd}16^{__CVBuffer=}32^{__CVBuffer=}40^{__CVBuffer=}48@56
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}24@0:8r^{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?={CGRect={CGPoint=dd}{CGSize=dd}}d}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{CGRect={CGPoint=dd}{CGSize=dd}}48@0:8{CGPoint=dd}16^{__CVBuffer=}32@40
{unique_ptr<ik::EspressoNet, std::default_delete<ik::EspressoNet>>="__ptr_"{__compressed_pair<ik::EspressoNet *, std::default_delete<ik::EspressoNet>>="__value_"^{EspressoNet}}}
{PixelBufferTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
{unordered_map<std::string, ik::Tensor, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, ik::Tensor>>>="__table_"{__hash_table<std::__hash_value_type<std::string, ik::Tensor>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>, std::allocator<std::__hash_value_type<std::string, ik::Tensor>>>="__bucket_list_"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__ptr_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>>="__value_"^^v"__value_"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__data_"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *> *>>="__value_"Q}}}}"__p1_"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *>>>="__value_"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, ik::Tensor>, void *> *>="__next_"^v}}"__p2_"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::hash<std::string>, std::equal_to<std::string>, true>>="__value_"Q}"__p3_"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, ik::Tensor>, std::equal_to<std::string>, std::hash<std::string>, true>>="__value_"f}}}
{EspressoTensor="_vptr$Tensor"^^?"type_"i"shape_"{TensorShape="sizes_"{vector<unsigned long, std::allocator<unsigned long>>="__begin_"^Q"__end_"^Q"__end_cap_"{__compressed_pair<unsigned long *, std::allocator<unsigned long>>="__value_"^Q}}}"storage_"{shared_ptr<ik::TensorStorage>="__ptr_"^{TensorStorage}"__cntrl_"^{__shared_weak_count}}}
B96@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
B104@0:8^{__CVBuffer=}16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64^96
@24@0:8@16
@"<MTLDeviceSPI>"
@"<MTLCommandQueue>"
@"MPSImageStatisticsMean"
@"<MTLTexture>"
^{OpaqueVTPixelTransferSession=}
