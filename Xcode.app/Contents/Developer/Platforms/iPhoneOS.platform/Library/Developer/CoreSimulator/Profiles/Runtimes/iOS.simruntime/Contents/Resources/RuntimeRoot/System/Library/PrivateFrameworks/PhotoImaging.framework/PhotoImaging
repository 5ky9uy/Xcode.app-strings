?YAH
?YAH
pCh?
UUUUUU
?UUUUUU
?YAH
?ffffff
@<,_
ffffff
zt?:
?ffffff
MbP?+
v@UUUUUU
333333
UUU?
?~0d>
0Xr
?g|_\
#?6t>=
333333
?333333
?ffffff
Mb@?@(#)PROGRAM:PhotoImaging  PROJECT:Neutrino-3502.18.222
smartTone
smartColor
smartBlackAndWhite
grain
autoEnhance
whiteBalance
cropStraighten
redEye
apertureRedEye
depthEffect
livePhotoKeyFrame
videoPosterFrame
trim
slomo
portraitEffect
orientation
autoLoop
highResFusion
retouch
vignette
sharpen
noiseReduction
definition
curves
levels
selectiveColor
effect
effect3D
mute
rawNoiseReduction
source
T@"NUComposition",R,C,N
changeDelegate
T@"<PICompositionControllerDelegate>",W,N,V_changeDelegate
imageOrientation
Tq,N,V_imageOrientation
PICompositionController(0x%X): %@
enabled
value
com.apple.photo
+[PICompositionSerializer _sanitizeComposition:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Controllers/Conversion/PICompositionSerializer.m
Adjustment for %@ is identity
PICompositionSerializer
exception
dictionary
v32@?0@"NSString"8#16^B24
Value for key %@ has type %@; expected type %@
PICompositionSerializerDomain
Missing required key: %@
masterWidth
masterHeight
adjustments
formatVersion
metadata
+[PICompositionSerializer serializeComposition:versionInfo:serializerMetadata:error:]
T@"NSData",&,N,V_data
T@"NSString",&,N,V_formatIdentifier
T@"NSString",&,N,V_formatVersion
versionInfo
Serialization map does not contain identifierName
formatIdentifier
identifier
auto
current
inputKeys
omitIfDisabled
settings
Serialization map has no entry for %@
Missing identifierName
Invalid parameter not satisfying: %@
<Unknown File>
Tq,N,V_width
Tq,N,V_height
Tq,N,V_orientation
Orientation
nil identifierName
Unsupported adjustment: 
Missing definition in conversion map for the adjustment key: 
dummy
file://dummy.jpg
destinationUTI
T@"NSString",R,V_destinationUTI
destinationLongExposureURL
T@"NSURL",R,V_destinationLongExposureURL
destinationMaskURL
T@"NSURL",R,V_destinationMaskURL
outputColorSpace
T@"NUColorSpace",R
-[PIAutoLoopExportRequest initWithComposition:destinationURL:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/AutoLoop/PIAutoLoopRequests.m
Initializer not available: -[%@ %@], use designated initializer instead.
-[PIAutoLoopExportRequest initWithRequest:]
Tq,N,V_flavor
T@"NSDictionary",C,N,V_recipe
cleanAperture
T{?={?=qq}{?=qq}},N,V_cleanAperture
PIZlibErrorDomain
compressionLevel
Ti,N,V_compressionLevel
strategy
Ti,N,V_strategy
windowBits
Ti,N,V_windowBits
memoryLevel
Ti,N,V_memoryLevel
chunkSize
TQ,N,V_chunkSize
-[PIZlibDataCompressionOptions setCompressionStrategy:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Util/PIZLibDataCompression.m
unknown strategy %d
-[PIZlibDataCompressionOptions setCompressionLevel:]
unknown level %d
createBuffer
T@?,C,N,V_createBuffer
growData
T@?,C,N,V_growData
decompressAllAtOnce
TB,N,V_decompressAllAtOnce
growData != nil
-[PIZlibDataDecompressionOptions setGrowData:]
Invalid parameter not satisfying: %s
createBuffer != nil
-[PIZlibDataDecompressionOptions setCreateBuffer:]
v24@?0@"NSData"8@"NSMutableData"16
@"NSMutableData"16@?0@"NSData"8
+[PIZlibDataCompression decompressData:options:error:]
1.2.11
English Error String - Not Localized
%@ %@
zlib-error: 
%@ %@ %s
unknown error
Z_VERSION_ERROR
Z_BUF_ERROR
Z_MEM_ERROR
Z_DATA_ERROR
Z_STREAM_ERROR
Z_ERRNO
should be < 4GB, so casts from NSUInteger to uInt below will not be invalid
+[PIZlibDataCompression compressData:options:error:]
non-instantiable class, use the class methods!
T@"NSDictionary",C,N
T@"NSString",C,N
recipe
flavor
keyFrameTime
T{?=qiIq},N
scale
time
Td,N
intensityKey
T@"NSString",R,N
radiusKey
falloffKey
falloff
radius
intensity
T@"NSDictionary",R,N
TB,N
T@"NUIdentifier",&,N,V_identifier
displayName
adjustment
T@"NUAdjustment",R,N,V_adjustment
T@"NSArray",R,N
displayInputKeys
canBeEnabled
TB,R,N
-[PIAdjustmentController setIsAuto:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Controllers/PIAdjustmentController.m
Adjustment does not have an auto setting
-[PIAdjustmentController isAuto]
-[PIAdjustmentController setEnabled:]
Adjustment does not have an enabled setting
-[PIAdjustmentController enabled]
-[PIAdjustmentController inputKeys]
Adjustment empty
-[PIAdjustmentController displayName]
PIFaceObservationCache
-[PILongExposureFusionAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PILongExposureFusionAutoCalculator.m
AutoLoop not supported
pre-AutoLoop
PILongExposureFusionAutoCalculator-videoProperties
Tq,N
version
kind
-[PIAutoLoopAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIAutoLoopAutoCalculator.m
B32@?0@"AVMetadataItem"8Q16^B24
T@"CIImage",&,N,V_inputImage
Td,N,V_temperature
Td,N,V_tint
inputBVector
inputGVector
inputRVector
-[PITempTintFilter outputImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PITempTintFilter.m
inputImage
CIColorMatrix
inputImage cannot be nil
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
T@"<NURenderStatistics>",R
T@"NSDictionary",R
T@"NSDictionary",&,V_recipe
videoSource
T@"AVAsset",&,N,V_videoSource
T@"NSDictionary",&,N,V_recipe
-[PIAutoLoopAnalysisJob render:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/AutoLoop/PIAutoLoopJob+Analysis.m
AutoLoop is not supported
-[PIAutoLoopAnalysisJob prepare:]
unable to find video source node
neutralGray
faceBalance
tempTint
warmTint
rawState
Tq,R,V_rawState
+[PIFaceBalanceAutoCalculator faceBalanceFromFaceImage:forFaceRect:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIWhiteBalanceAutoCalculators.m
unsupported format - incorrect white balance
+[PIFaceBalanceAutoCalculator faceBalanceResultFromFaceObservations:request:error:]
PIRAWFaceBalanceAutoCalculator.responseQueue
WarmFace
WarmTint
WarmTemp
Strength
Warmth
OrigQ
OrigI
Failure in rendering image
face-balance buffer render request
+[PIFaceBalanceAutoCalculator calculateRAWWithRequest:completion:]
PIFaceBalanceAutoCalculator - RAW: face request
/Master/Source
+[PIFaceBalanceAutoCalculator calculateWithRequest:completion:]
CIFaceBalance
return Filter('CIEdges', { 'inputImage' : input, 'inputIntensity' : 1.0 });
CIAreaAverage
v16@?0@"<NUBuffer>"8
color
PIWhiteBalanceAutoCalculator
-[PIWhiteBalanceAutoCalculator submit:]
PIFaceBalanceAutoCalculator.responseQueue
colorType
tint
temperature
grayColor
v16@?0^{NUResponse=#}8
faceStrength
faceWarmth
faceQ
faceI
pi_grayColorResultValue
T{?={?=[4d]}{?=[4d]}d},R
RGBResultValue
T{?=[4d]},R
{?=[4d]}
{?={?=[4d]}{?=[4d]}d}
vec4 meaningBlur(vec4 im, vec4 b)
vec4 result = im;
float thresh = 0.1;
float g1 = max(max(im.r, im.g), im.b);
float g2 = dot(b.rgb, vec3(1.0/3.0));
float diff = max(g2-g1, -1.0);
diff = smoothstep(0.1-thresh, 0.1+thresh, diff);
result.rgb = mix(im.rgb, b.rgb, diff+0.5);
return result;
vec4 clarityNew(vec4 s, vec4 b, float intensity)
float sl = (s.r + s.g + s.b);
float bl = (b.r + b.g + b.b);
float dl = sl + (sl - bl) * intensity;
float mult = dl / max(sl, 0.0001);
mult = 1.571 * (mult - 1.0);
mult = mult / (1.0 + abs(mult));
mult += 1.0;
mult = clamp(mult, 1.0 - 0.5 * abs(intensity), 1.0 + 1.0 * abs(intensity));
s.rgb = s.rgb * mult;
return s;
kernel vec4 definition(sampler image, sampler blur, float intensity)
vec4 imgSample = sample(image, samplerCoord(image));
vec4 blurSample = sample(blur, samplerCoord(blur));
vec4 meaning = meaningBlur(imgSample, blurSample);
vec4 clarity = clarityNew(imgSample, meaning, intensity);
return clarity;
T@"CIImage",&,V_inputImage
inputBlurImage
T@"CIImage",&,V_inputBlurImage
T@"NSNumber",&,V_inputIntensity
strengthKey
neutralKey
toneKey
grainKey
hueKey
attributeStrengthKey
attributeNeutralGammaKey
attributeToneKey
attributeHueKey
attributeGrainKey
inputSeed
inputHue
inputGrain
inputTone
inputNeutralGamma
inputStrength
tone
neutral
strength
request
T@"NUImageExportRequest",&,V_request
inputSize
T{?=qq},V_inputSize
geometry
T@"NUImageGeometry",&,V_geometry
auxiliaryImages
T@"NSDictionary",&,V_auxiliaryImages
T@"NSDictionary",C,V_properties
T{?=qq},D
T@"NSData",&,V_data
priority
T@"NUPriority",&,V_priority
T@"NUColorSpace",&,V_colorSpace
pairingIdentifier
T@"NSString",C,V_pairingIdentifier
scalePolicy
T@"<NUScalePolicy>",&,V_scalePolicy
metadataProcessor
T@?,C,V_metadataProcessor
imageExportFormat
T@"NUImageExportFormat",C,V_imageExportFormat
optimizeForSharing
TB,V_optimizeForSharing
primaryURL
T@"NSURL",&,V_primaryURL
videoComplementURL
T@"NSURL",&,V_videoComplementURL
videoPosterFrameURL
T@"NSURL",&,V_videoPosterFrameURL
PICompositionExporter.video
height
width
yOrigin
xOrigin
roll
pitch
reference
sourceSpatialOvercapture
sourceSelect
-[PICompositionExporter addVideoProperties:composition:options:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Util/PICompositionExporter.m
Unknown autoloop flavor
PICompositionExporter.videoProperties
PICompositionExporter.imageProperties.transaction
PICompositionExporter.imageProperties
v32@?0@"NSString"8@"<NUAuxiliaryImage>"16^B24
PICompositionExporter.image
unable to prepare image properties
-[PICompositionExporter init]
metadataConverter must be set
metadataConverter
T@"<PICompositionExporterMetadataConverter>",&
Regions
convertFromLabToRGB
convertFromRGBToLab
bilateralFinalize
bilateralAdd_9
bilateralAdd_8
bilateralAdd_7
bilateralAdd_6
bilateralAdd_5
bilateralAdd_4
bilateralAdd_3
bilateralAdd_2
bilateralAdd_1
kernel vec4 convertFromRGBToLab(sampler src)
vec3 f;
vec4 pix, color;
pix = unpremultiply(sample(src, samplerCoord(src)));
color.xyz = pix.r * vec3(0.449695,  0.316251, 0.18452  )
+ pix.g * vec3(0.244634,  0.672034, 0.0833318)
+ pix.b * vec3(0.0251829, 0.141184, 0.922602 );
color.xyz *= vec3(1.052111, 1.0, 0.918417);
f = compare(color.xyz - 0.00885645, 7.787037 * color.xyz + 0.137931, pow(color.xyz, vec3(0.333333)));
color.r = 116.0 * f.y - 16.0;
color.g = 500.0 * (f.x - f.y);
color.b = 200.0 * (f.y - f.z);
color.rgb *= 0.005;
color.a = 1.0;
return color;
kernel vec4 convertFromLabToRGB(sampler src, sampler original)
vec3 f, cie;
vec4 color, pix, opix;
pix = sample(src, samplerCoord(src));
opix = sample(original, samplerCoord(original));
pix.rgb *= 200.0;
f.y = (pix.r + 16.0) / 116.0;
f.x = f.y + pix.g * 0.002;
f.z = f.y - pix.b * 0.005;
color.xyz = f * f * f;
cie = compare(color.xyz - 0.00885645, (f.xyz - 0.137931) / 7.787037, color.xyz);
cie *= vec3(0.95047, 1.0, 1.08883);
color.rgb = cie.x * vec3(2.95176,   -1.28951, -0.47388  )
+ cie.y * vec3(-1.0851,    1.99084,  0.0372023)
+ cie.z * vec3(0.0854804, -0.269456, 1.09113  );
color.a = opix.a;
return premultiply(color);
float luminanceWeight(vec4 pix, vec4 center, float slope)
return max(1.0 + (slope * length(pix.rgb - center.rgb)), 0.0);
vec4 bilateralRow_1(sampler src, float slope, vec2 offset1, float weight1)
float diff1;
vec2 coord;
vec4 pix1, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
diff1 = luminanceWeight(pix1, center, slope) * weight1;
return vec4(diff1 * pix1.rgb, diff1);
kernel vec4 bilateralAdd_1(sampler src, sampler sums, float slope, vec2 offset1, float weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_1(src, slope, offset1, weight1);
vec4 bilateralRow_2(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 weight1)
float diff1, diff2;
vec2 coord;
vec4 pix1, pix2, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb, diff1 + diff2);
kernel vec4 bilateralAdd_2(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_2(src, slope, offset1, offset2, weight1);
vec4 bilateralRow_3(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
float diff1, diff2, diff3;
vec2 coord;
vec4 pix1, pix2, pix3, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb, diff1 + diff2 + diff3);
kernel vec4 bilateralAdd_3(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_3(src, slope, offset1, offset2, offset3, weight1);
vec4 bilateralRow_4(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec4 weight1)
float diff1, diff2, diff3, diff4;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb,
diff1 + diff2 + diff3 + diff4);
kernel vec4 bilateralAdd_4(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3,
vec2 offset4, vec4 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_4(src, slope, offset1, offset2, offset3, offset4, weight1);
vec4 bilateralRow_5(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec4 weight1, float weight2)
float diff1, diff2, diff3, diff4, diff5;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb,
diff1 + diff2 + diff3 + diff4 + diff5);
kernel vec4 bilateralAdd_5(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec4 weight1, float weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_5(src, slope, offset1, offset2, offset3, offset4, offset5, weight1, weight2);
vec4 bilateralRow_6(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec4 weight1, vec2 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6);
kernel vec4 bilateralAdd_6(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec4 weight1, vec2 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_6(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, weight1, weight2);
vec4 bilateralRow_7(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7);
kernel vec4 bilateralAdd_7(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_7(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, weight1, weight2);
vec4 bilateralRow_8(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6,
vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8);
kernel vec4 bilateralAdd_8(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_8(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, weight1, weight2);
vec4 bilateralRow_9(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6, vec2 offset7,
vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, pix9, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
pix9 = sample(src, samplerTransform(src, coord + offset9));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
diff9 = luminanceWeight(pix9, center, slope) * weight3;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb + diff9 * pix9.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8 + diff9);
kernel vec4 bilateralAdd_9(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_9(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, offset9,
weight1, weight2, weight3);
kernel vec4 bilateralFinalize(sampler sums)
vec4 sum;
sum = sample(sums, samplerCoord(sums));
return vec4(sum.rgb / max(sum.a, 0.001), 1.0);
T@"NSArray",&,V_inputPoints
T@"NSArray",&,V_inputWeights
T@"NSNumber",&,V_inputEdgeDetail
inputVersion
T@"NSNumber",&,V_inputVersion
points.count > 0
-[GUBilateralConvolution boundsForPointArray:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIBilateralFilter.m
bilateralLoop11
bilateralLoop5
bilateralLoop2
kernel vec4 bilateralLoop2(sampler src, float slope, vec2 weights12)
vec2 coord;
vec4 center = sample(src, samplerCoord(src));
vec4 sum;
vec4 pix0, pix1, pix2;
vec4 pix3,       pix5;
vec4 pix6, pix7, pix8;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-2.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -1.0));
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dy;
pix3 = sample(src, coord);
coord = coord + dx;
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dy;
pix6 = sample(src, coord);
coord = coord + dx;
pix7 = sample(src, coord);
coord = coord + dx;
pix8 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights12.y);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights12.x) + sum;
sum =                                        center                            + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix7 - center)))) * (pix7 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix8 - center)))) * (pix8 * weights12.y) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop5(sampler src, float slope, vec4 weights1245)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-4.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -2.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop11(sampler src, float slope, vec4 weights1245, vec4 weights89AD)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4, pix5, pix6;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-6.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-2.0, -3.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.y) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
inputBorder
T@"NSNumber",&,V_inputBorder
inputEdgeDetail
T@"NSNumber",&,V_inputRadius
-[PIBilateralFilter outputImage]
unable to allocate convolution table in bilateral filter
inputWeights
inputPoints
ridiculously large radius for bilateral filter
com.apple.livephoto
com.apple.video
com.apple.video.slomo
string
T@"NSString",R,W,N
majorVersion
TQ,R,N,V_majorVersion
minorVersion
TQ,R,N,V_minorVersion
platform
T@"NSString",R,C,N,V_platform
%lu.%lu
%lu.%lu.%@
^([0-9]+)\.([0-9]+)\.(OSX|iOS)$
^([0-9]+)\.([0-9]+)$
amountKey
Tq,N,V_version
portraitInfo
-[PIOrientationAdjustmentController setOrientation:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Controllers/PIOrientationAdjustmentController.m
None
UnexpectedRuntimeError
NoBuildingDetected
PanoAndFFCNotSupported
FacesTooLarge
SalientAreaTooSmall
SalientHumansAndAnimalsTooLarge
SalientBoundingBoxMissing
ConfidenceTooLow
LimitExceeded
NotEnoughLines
CorrectedAreaIsSmall
debugLineDetectionImage
T@"CIImage",&,N,V_debugLineDetectionImage
maxAutoYaw
T@"NSNumber",C,V_maxAutoYaw
maxAutoPitch
T@"NSNumber",C,V_maxAutoPitch
maxAutoAngle
T@"NSNumber",C,V_maxAutoAngle
minimumConfidence
Td,V_minimumConfidence
Td,V_maxFaceSize
disableOnPanos
TB,V_disableOnPanos
disableOnFrontFacingCameraImages
TB,V_disableOnFrontFacingCameraImages
shouldRunDetectorsIfNecessary
TB,V_shouldRunDetectorsIfNecessary
shouldRunBuildingCheck
TB,V_shouldRunBuildingCheck
Td,N,V_minSalientArea
Td,N,V_maxSalientSubjectArea
saliencyObservation
T@"VNSaliencyImageObservation",&,N,V_saliencyObservation
angleSeedDegreesCCW
Td,V_angleSeedDegreesCCW
debugFilesEnabled
TB,V_debugFilesEnabled
debugFilesPrefix
T@"NSString",C,V_debugFilesPrefix
debugDiagnostics
T@"NSMutableDictionary",R,V_debugDiagnostics
faceObservationCache
T@"PIFaceObservationCache",&,N,V_faceObservationCache
T@"PIFaceObservationCache",&,N
-[PIPerspectiveAutoCalculator submitVerified:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIPerspectiveAutoCalculator.m
NUPixelSize NUPixelSizeMake(NSInteger, NSInteger)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/Core/Geometry/NUGeometryPrimitives.h
angle
yawError
ciYawError
pitchError
ciPitchError
debugImage
rollAngleInDegreesCW
yawExpandLeftDegrees
pitchExpandTopDegrees
passesConfidenceCheck
submitVerified
CIAutoPerspective
saliencyHeatMap
(width >= 0) && (height >= 0)
<Unknown Function>
rollLimit
yawLimit
pitchLimit
focalLength
canGenerateNewCropRect
-[PIPerspectiveAutoCalculator passesConfidenceCheck:error:]
minConfidence
Not supported by Core Image. Default: YES
supported
confidence
-[PIPerspectiveAutoCalculator canGenerateNewCropRect:]
v16@?0@"PIAdjustmentController"8
preseedRoll
-[PIPerspectiveAutoCalculator primaryImageProperties:]
-[PIPerspectiveAutoCalculator submit:]
passesFaceCheck
passesSaliencyCheck
passesImagePropertiesCheck
submit
-[PIPerspectiveAutoCalculator passesSaliencyCheck:]
salientArea
minSalientArea
maxFaceSize
maxSalientSubjectArea
-[PIPerspectiveAutoCalculator passesImagePropertiesCheck:]
isSelfieCam
aspectRatio
Apple
front camera
-[PIPerspectiveAutoCalculator passesFaceCheck:]
faceSize
faces != nil
-[PIPerspectiveAutoCalculator getSizeOfAllFaces:]
Edit
%@PerspectiveLineDetection-png.DBG
%@PerspectiveEvaluation-txt.DBG
yawError.underlyingError
pitchError.underlyingError
%@.underlyingError
%@.error
%@.%@
-[PIPerspectiveAutoCalculator initWithComposition:]
pitch != nil
+[PIPerspectiveAutoCalculator undoOrientation:forPitch:yaw:angle:]
yaw != nil
angle != nil
luminanceKey
luminance
Flash
ApertureValue
FNumber
ExposureTime
ShutterSpeedValue
ISOSpeedRatings
cropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N
angleRadians
pitchRadians
yawRadians
autoCropped
-[PICropAdjustmentController setCropRect:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Controllers/PICropAdjustmentController.m
cannot set empty crop rect
constraintHeight
constraintWidth
inputDecoderVersion
localAutoValue
statistics
inputLight
inputLightKey
offsetBlackKey
offsetBrightnessKey
offsetContrastKey
offsetExposureKey
offsetHighlightsKey
offsetLocalLightKey
offsetShadowsKey
attributeBrightnessKey
attributeContrastKey
attributeExposureKey
attributeHighlightsKey
attributeShadowsKey
attributeBlackPointKey
attributeLocalLightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLightMapHeightKey
inputRawHighlights
inputLocalLight
inputBlack
inputHighlights
inputShadows
inputBrightness
inputContrast
inputExposure
offsetShadows
offsetLocalLight
offsetHighlights
offsetExposure
offsetContrast
offsetBrightness
offsetBlack
inputLightMapHeight
inputLightMapWidth
inputLightMap
fuse_image_compute
blur_image_compute_3x3
blur_image_compute_5x5
blur_image_compute_7x7
ncc_coarse_compute
ncc_compute
warp_homography
rgba_to_luma
jointbilateralfilter
kernel vec4 jointbilateralfilter(sampler mask, sampler guide, vec2 rad, vec3 sig) __attribute__((outputFormat(kCIFormatRh)))
vec2 coord = destCoord();
float rh = rad.x;
float rv = rad.y;
vec4 p0 = sample(mask, samplerTransform(mask, coord));
vec4 g0 = sample(guide, samplerTransform(guide, coord));
vec4 result = vec4(0.0f);
float w_sum = 0.0f;
for(float yo=-rad.y;  yo<=rad.y;  yo++) {
for(float xo=-rad.x;  xo<=rad.x;  xo++) {
vec2 dc = vec2(xo, yo);
vec4 p = sample(mask, samplerTransform(mask, coord + dc));
vec4 g = sample(guide, samplerTransform(guide, coord + dc));
float d = dot(dc, dc);
float pdif = dot(p-p0,p-p0);
float gdif = dot(g-g0,g-g0);
float w = exp(dot(sig, vec3(d,pdif,gdif)));
result += w*p;
w_sum += w;
result /= w_sum;
return vec4(result.rgb, 1.0);
kernel vec4 rgba_to_luma(__sample rgb)
const vec4 rgb2y = vec4(0.2999,0.5870,0.1140,0.0);
float luma = dot(rgb, rgb2y);
return vec4(luma, luma, luma, 1.0);
kernel vec2 warp_homography(vec3 h012, vec3 h345, vec3 h678)
vec3 coord = vec3(destCoord(), 1.f);
float norm = 1.f / dot(h678, coord);
float x = norm * dot(h012, coord);
float y = norm * dot(h345, coord);
return vec2(x,y);
kernel vec4 ncc_compute(sampler img1, sampler img2) __attribute__((outputFormat(kCIFormatR8)))
vec2 coord = destCoord();
float sum1   = float(0.0);
float sum2   = float(0.0);
float sumSq1 = float(0.0);
float sumSq2 = float(0.0);
float sumCrs = float(0.0);
float ncc;
float p1, p2;
const int halfKernel = 3;
const vec4 meanOp = vec4(1.0/3.0, 1.0/3.0, 1.0/3.0, 0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
p1 = dot(meanOp, sample(img1, samplerTransform(img1, coord + vec2(x, y))));
p2 = dot(meanOp, sample(img2, samplerTransform(img2, coord + vec2(x, y))));
sum1 += p1;
sum2 += p2;
sumSq1 += p1*p1;
sumSq2 += p2*p2;
sumCrs += p1*p2;
count += 1.0;
float denom = (sumSq1-sum1*sum1/count) * (sumSq2-sum2*sum2/count);
ncc = compare(denom, 0.0, ((sumCrs-(sum1*sum2/count)))/sqrt(denom));
ncc = max(ncc, 0.0);
return vec4(ncc, ncc, ncc, 1.0);
kernel vec4 ncc_coarse_compute(__sample ncc, vec2 edge) __attribute__((outputFormat(kCIFormatR8)))
float value = smoothstep(edge.x, edge.y, ncc.r);
return vec4(value, value, value, 1.0);
kernel vec4 blur_image_compute_3x3(sampler img)
const int halfKernel = 1;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_5x5(sampler img)
const int halfKernel = 2;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_7x7(sampler img)
const int halfKernel = 3;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 fuse_image_compute(sampler refImg, sampler guideImg, sampler blurImg, sampler weightImg, sampler maskImg, vec2 threshold)
vec4 ref       = sample(refImg, samplerCoord(refImg));
vec4 refBlur   = ref;
vec4 guide     = sample(guideImg, samplerCoord(guideImg));
vec4 guideBlur = sample(blurImg, samplerCoord(blurImg));
float weight   = sample(weightImg, samplerCoord(weightImg)).r;
float mask     = sample(maskImg, samplerCoord(maskImg)).r;
vec3 CbCoef = vec3(-0.1726, -0.3391, 0.5117);
vec3 CrCoef = vec3(0.5115, -0.4282, -0.0830);
float CbRef   = dot(CbCoef, ref.rgb);
float CbGuide = dot(CbCoef, guideBlur.rgb);
float CrRef   = dot(CrCoef, ref.rgb);
float CrGuide = dot(CrCoef, guideBlur.rgb);
float crDiff = smoothstep(0.0, 0.2, abs(CbRef-CbGuide));
float cbDiff = smoothstep(0.0, 0.2, abs(CrRef-CrGuide));
float chDiff = smoothstep(0.0,0.3,crDiff+cbDiff);
float weight1 = (1.0-smoothstep(threshold.x,threshold.y,mask));
weight *= weight1 * (1.0-chDiff);
vec4 value = mix(ref, (0.9*(guide-guideBlur)+refBlur), weight);
return value;
kernel vec4 dynamismMap(sampler imageMax, sampler imageMin, float logisticGain, float logisticMid) __attribute__((outputFormat(kCIFormatRGBAh)))
const float MAX_VAL = 1.74;
const float THRESHOLD = 0.05;
vec2 dc = destCoord();
vec2 sc;
sc = dc + vec2(-1,-1);
vec4 pMax00 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin00 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,0);
vec4 pMax01 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin01 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,1);
vec4 pMax02 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin02 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(0,-1);
vec4 pMax10 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin10 = sample(imageMin, samplerTransform(imageMin, sc));
vec4 pMax11 = sample(imageMax, samplerTransform(imageMax, dc));
vec4 pMin11 = sample(imageMin, samplerTransform(imageMin, dc));
sc = dc + vec2(0,1);
vec4 pMax12 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin12 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,-1);
vec4 pMax20 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin20 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,0);
vec4 pMax21 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin21 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,1);
vec4 pMax22 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin22 = sample(imageMin, samplerTransform(imageMin, sc));
float minDevCMaxNMin = distance(pMax11, pMin00);
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin01) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin02) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin10) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin11) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin12) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin20) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin21) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin22) );
float minDevCMinNMax = distance(pMin11, pMax00);
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax01) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax02) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax10) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax11) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax12) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax20) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax21) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax22) );
float outVal = min(minDevCMaxNMin , minDevCMinNMax) / MAX_VAL;
outVal = 1.0f / (1.0f + exp(-logisticGain*(outVal - logisticMid)));
vec4 outPixel = vec4(outVal, outVal, outVal, 1.0);
return outPixel;
kernel vec4 alphaCompositing(__sample src, __sample dst, float a)
return mix(dst, src, a);
SkipShaderPrewarm
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Util/PIPhotoEditHelper.m
endScale
startScale
start
aperture
depthInfo
inputCorrectionInfo
composition
PISmartToneAdjustmentKey
T@"NSString",R,N,V_PISmartToneAdjustmentKey
PISmartColorAdjustmentKey
T@"NSString",R,N,V_PISmartColorAdjustmentKey
PISmartBWAdjustmentKey
T@"NSString",R,N,V_PISmartBWAdjustmentKey
PIGrainAdjustmentKey
T@"NSString",R,N,V_PIGrainAdjustmentKey
PIAutoEnhanceAdjustmentKey
T@"NSString",R,N,V_PIAutoEnhanceAdjustmentKey
PIWhiteBalanceAdjustmentKey
T@"NSString",R,N,V_PIWhiteBalanceAdjustmentKey
PIRedEyeAdjustmentKey
T@"NSString",R,N,V_PIRedEyeAdjustmentKey
PIApertureRedEyeAdjustmentKey
T@"NSString",R,N,V_PIApertureRedEyeAdjustmentKey
PIRetouchAdjustmentKey
T@"NSString",R,N,V_PIRetouchAdjustmentKey
PIVignetteAdjustmentKey
T@"NSString",R,N,V_PIVignetteAdjustmentKey
PISharpenAdjustmentKey
T@"NSString",R,N,V_PISharpenAdjustmentKey
PINoiseReductionAdjustmentKey
T@"NSString",R,N,V_PINoiseReductionAdjustmentKey
PIDefinitionAdjustmentKey
T@"NSString",R,N,V_PIDefinitionAdjustmentKey
PICurvesAdjustmentKey
T@"NSString",R,N,V_PICurvesAdjustmentKey
PILevelsAdjustmentKey
T@"NSString",R,N,V_PILevelsAdjustmentKey
PISelectiveColorAdjustmentKey
T@"NSString",R,N,V_PISelectiveColorAdjustmentKey
PIEffectAdjustmentKey
T@"NSString",R,N,V_PIEffectAdjustmentKey
PIEffect3DAdjustmentKey
T@"NSString",R,N,V_PIEffect3DAdjustmentKey
PICropAdjustmentKey
T@"NSString",R,N,V_PICropAdjustmentKey
PITrimAdjustmentKey
T@"NSString",R,N,V_PITrimAdjustmentKey
PISlomoAdjustmentKey
T@"NSString",R,N,V_PISlomoAdjustmentKey
PILivePhotoKeyFrameAdjustmentKey
T@"NSString",R,N,V_PILivePhotoKeyFrameAdjustmentKey
PIVideoPosterFrameAdjustmentKey
T@"NSString",R,N,V_PIVideoPosterFrameAdjustmentKey
PIAutoLoopAdjustmentKey
T@"NSString",R,N,V_PIAutoLoopAdjustmentKey
PIHighResFusionAdjustmentKey
T@"NSString",R,N,V_PIHighResFusionAdjustmentKey
PIMuteAdjustmentKey
T@"NSString",R,N,V_PIMuteAdjustmentKey
PIDepthAdjustmentKey
T@"NSString",R,N,V_PIDepthAdjustmentKey
PIPortraitAdjustmentKey
T@"NSString",R,N,V_PIPortraitAdjustmentKey
PIOrientationAdjustmentKey
T@"NSString",R,N,V_PIOrientationAdjustmentKey
PIRawAdjustmentKey
T@"NSString",R,N,V_PIRawAdjustmentKey
PIRawNoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIRawNoiseReductionAdjustmentKey
PISourceAdjustmentKey
T@"NSString",R,N,V_PISourceAdjustmentKey
allAdjustmentTypes
nonVisualAdjustmentTypes
ResetTagInput('/pre-Geometry', input);
return GetTag('/post-Geometry');
/ShowOriginalSource
var image = input;
ResetTagInput('/pre-Geometry', image);
return GetTag('/post-Geometry');
v32@?0@"NSString"8@"NSString"16^B24
composition != nil
+[PIPhotoEditHelper videoRenderRequestWithComposition:fitInSize:wideGamut:]
+[PIPhotoEditHelper _imageRenderRequestWithComposition:wideGamut:]
targetSize.width > 0 && targetSize.height > 0
+[PIPhotoEditHelper imageRenderRequestWithComposition:fillInSize:wideGamut:]
+[PIPhotoEditHelper imageRenderRequestWithComposition:fitInSize:wideGamut:]
+[PIPhotoEditHelper videoPropertiesRequestWithComposition:]
+[PIPhotoEditHelper imagePropertiesRequestWithComposition:]
+[PIPhotoEditHelper geometryRequestWithComposition:]
name != nil
+[PIPhotoEditHelper newImageRenderClientWithName:]
identifier != nil
+[PIPhotoEditHelper newAdjustmentWithIdentifier:]
+[PIPhotoEditHelper newAdjustmentWithName:]
photoSource != nil
+[PIPhotoEditHelper livePhotoSourceWithPhotoSource:videoSource:]
videoSource != nil
%@+%@
+[PIPhotoEditHelper videoSourceWithURL:]
+[PIPhotoEditHelper imageSourceWithCIImage:orientation:]
+[PIPhotoEditHelper imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:]
+[PIPhotoEditHelper imageSourceWithURL:type:useEmbeddedPreview:]
%@ %a
%@ (preview) %a
ContourV2
CIPortraitEffectContourV2
StudioV2
Contour
CIPortraitEffectStudioV2
CIPortraitEffectContour
Commercial
Light
CIPortraitEffectCommercial
CIPortraitEffectLight
StageWhite
CIPortraitEffectStageWhite
StageMonoV2
StageV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageV2
BlackoutMono
Black
CIPortraitEffectBlackoutMono
CIPortraitEffectBlack
3DNoir
3DSilverplate
CIPhotoEffect3DNoir
CIPhotoEffect3DSilverplate
3DDramaticCool
3DDramaticWarm
CIPhotoEffect3DDramaticCool
CIPhotoEffect3DDramaticWarm
3DDramatic
3DVividCool
CIPhotoEffect3DDramatic
CIPhotoEffect3DVividCool
3DVividWarm
3DVivid
CIPhotoEffect3DVividWarm
CIPhotoEffect3DVivid
Instant
Transfer
CIPhotoEffectInstant
CIPhotoEffectTransfer
Process
Chrome
CIPhotoEffectProcess
CIPhotoEffectChrome
Fade
Noir
CIPhotoEffectFade
CIPhotoEffectNoir
Tonal
Mono
CIPhotoEffectTonal
CIPhotoEffectMono
+[PIForwardFakeBoost kernel]_block_invoke
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIFakeBoost.m
boost kernel is nil
kernel vec4 forwardBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k) - k;
vec3 neg = min(im.rgb, 0.0);
neg *= 2.8;
im.rgb = clamp(im.rgb, 0.0, k);
im.rgb = ((1.0+n)*im.rgb)/(1.0+(n*im.rgb)) + neg;
im.r = pos.r > 0.0 ? (.91803 + .470304*pos.r) : im.r;
im.g = pos.g > 0.0 ? (.91803 + .470304*pos.g) : im.g;
im.b = pos.b > 0.0 ? (.91803 + .470304*pos.b) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
inputBoost
Td,V_inputBoost
-[PIForwardFakeBoost outputImage]
+[PIInverseFakeBoost kernel]_block_invoke
inverse boost kernel is nil
kernel vec4 inverseBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k);
vec3 neg = min(im.rgb, 0.0);
im.rgb = clamp(im.rgb, 0.0, k);
neg *= .35714286;
im.rgb = im.rgb/(n+1.0-(im.rgb*n)) + neg;
im.r = pos.r > 0.8 ? k + 2.126286*(pos.r-.91803) : im.r;
im.g = pos.g > 0.8 ? k + 2.126286*(pos.g-.91803) : im.g;
im.b = pos.b > 0.8 ? k + 2.126286*(pos.b-.91803) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
-[PIInverseFakeBoost outputImage]
Effect
Effect3D
SmartTone
SmartColor
SmartBlackAndWhite
Grain
WhiteBalance
Crop
AutoEnhance
RedEyeBB
AutoLoop
HighResolutionFusion
Trim
SlowMotion
LivePhotoKeyFrame
VideoPosterFrame
Mute
DepthEffect
PortraitEffect
SelectiveColor
compositionName
identifierName
custom
customSerialization
customCompositionName
customIdentifierName
autoValue
requiresEnabled
portraitEffectFilterName
alignment
v24@?0@"NSMutableDictionary"8@"NUAdjustment"16
timescale
rate
regions
timeRange
endTime
startTime
redEyeCorrections
sensitivity
center
pointY
pointX
inputSpots
RKRedEyeOperation
data
pressure
yLocation
xLocation
points
hasSource
sourceOffset
repairEdges
opacity
softness
Repair
mode
brushStroke
inputStrokes
RKRetouchOperation
corrections
RKSelectiveColorOperation
RGBCurvePoints
blueCurvePoints
pointsL
pointsB
greenCurvePoints
redCurvePoints
pointsG
pointsR
RKCurvesOperation
inputWhiteDstBlue
inputWhiteSrcBlue
whiteDstBlue
whiteSrcBlue
inputHilightDstBlue
inputHilightSrcBlue
hilightDstBlue
hilightSrcBlue
inputMidDstBlue
inputMidSrcBlue
midDstBlue
midSrcBlue
inputShadowDstBlue
inputShadowSrcBlue
shadowDstBlue
shadowSrcBlue
inputBlackDstBlue
inputBlackSrcBlue
blackDstBlue
blackSrcBlue
inputWhiteDstGreen
inputWhiteSrcGreen
whiteDstGreen
whiteSrcGreen
inputHilightDstGreen
inputHilightSrcGreen
hilightDstGreen
hilightSrcGreen
inputMidDstGreen
inputMidSrcGreen
midDstGreen
midSrcGreen
inputShadowDstGreen
inputShadowSrcGreen
shadowDstGreen
shadowSrcGreen
inputBlackDstGreen
inputBlackSrcGreen
blackDstGreen
blackSrcGreen
inputWhiteDstRed
inputWhiteSrcRed
whiteDstRed
whiteSrcRed
inputHilightDstRed
inputHilightSrcRed
hilightDstRed
hilightSrcRed
inputMidDstRed
inputMidSrcRed
midDstRed
midSrcRed
inputShadowDstRed
inputShadowSrcRed
shadowDstRed
shadowSrcRed
inputBlackDstRed
inputBlackSrcRed
blackDstRed
blackSrcRed
inputWhiteDstRGB
inputWhiteSrcRGB
whiteDstRGB
whiteSrcRGB
inputHilightDstRGB
inputHilightSrcRGB
hilightDstRGB
hilightSrcRGB
inputMidDstRGB
inputMidSrcRGB
midDstRGB
midSrcRGB
inputShadowDstRGB
inputShadowSrcRGB
shadowDstRGB
shadowSrcRGB
inputBlackDstRGB
inputBlackSrcRGB
blackDstRGB
blackSrcRGB
colorSpace
inputColorSpace
RKLevelsOperation
warmFace
warmTemp
warm
face
grayQ
grayI
grayY
grayWarmth
inputMethodVersion
RKRawDecodeOperation
inputLNRAmount
inputCNRAmount
inputDetailAmount
detail
DGRAWReduceNoiseOperation
straightenAngle
effectIntensity
effectVersion
effectName
inputSharpness
inputEdgeScale
edges
RKProSharpenOperation
edgeDetail
RKNoiseReductionOperation
DGDefinition2Operation
inputFalloff
inputRadius
inputIntensity
DGVignetteEffectOperation
seed
amount
offsetNeutralGamma
inputBlackAndWhite
offsetTone
offsetGrain
offsetStrength
offsetCast
offsetSaturation
inputColor
lightMapAvg
lightMap
offsetBlackPoint
v24@?0@"NSDictionary"8@"NUAdjustment"16
autoRedEyeCorrections
allCorrections
RedEye
ApertureRedEye
Clone
B16@?0@"NSDictionary"8
Retouch
Curves
sRGB
Adobe RGB
Display P3
Generic P3
Levels
RawNoiseReduction
CropStraighten
@"NSString"24@?0@"NSDictionary"8@"NUAdjustment"16
@"NSString"16@?0@"NSDictionary"8
Sharpen
NoiseReduction
Definition
Vignette
_accumError
T@"NSError",&,V__accumError
isReadyForMoreData
TB,R
-[PILongExposureAccumulator _exportOutputImage:format:colorSpace:toURL:uti:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/AutoLoop/PIAutoLoopJob+LongExposure.m
destinationURL != nil
Failed to create CGImageRef
Failed to create CGImageDestinationRef
Failed to finalize image destination
-[PILongExposureAccumulator writeMaskImage:UTI:error:]
v16@?0@"CIImage"8
-[PILongExposureAccumulator writeLongExposureImage:UTI:colorSpace:error:]
-[PILongExposureAccumulator _accumulate:error:]
B16@?0@"CIRenderDestination"8
failed to render maximum image
failed to render minimum image
CIBoxBlur
failed to render average image
frame != nil
-[PILongExposureAccumulator accumulate:error:]
failed to init accumulator
Accumulation was cancelled
PILongExposureAccumulator.state
PILongExposureAccumulator.accum
observation
T@"VNImageHomographicAlignmentObservation",R,C
extent
T{?={?=qq}{?=qq}},R,N
T@"VNImageHomographicAlignmentObservation",C,N,V_observation
T{?={?=qq}{?=qq}},N,V_extent
guideExtent
T{?={?=qq}{?=qq}},N,V_guideExtent
stillImage
T@"CIImage",&,N,V_stillImage
T@"VNImageHomographicAlignmentObservation",&,N,V_observation
-[PILongExposureRegistrationJob render:]
Image registration failure (expected 1 observation)
Failed to render luma
Failed to allocate intermediate pixel buffer
-[PILongExposureRegistrationJob prepare:]
Malformed AutoLoop recipe : crop
return Source(composition.source, {'skipOrientation':true});
/AutoLoop/LongExposure
/RAW/SushiLevel1
/Master%@
inputDestinationImage
T@"CIImage",&,N,V_inputDestinationImage
T@"NSArray",&,N,V_inputCorrectionInfo
T@"NSString",&,N,V_inputCameraModel
CILanczosScaleTransform
inputScale
CIRedEyeCorrection
inputCameraModel
posterFrameTime
dynamic
@"NSString"16@?0@"NUAdjustment"8
convexHull
/private/var/mobile/Media/PhotoData/CaptureDebug/
id<NUBuffer> computeRepairMask(__strong id<NUBuffer>, uint16_t *)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIApertureRedEye.mm
void seedFill(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, const uint32_t, const NSInteger, const NSInteger)
repairBuffer != nil
void applyRepairMask(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, double, const uint32_t)
reddesty out of bounds
reddestx out of bounds
Buffer must be RGBA16 type for red eye repairs
kernel vec4 facebalance(__sample src, vec2 gamma, vec3 matchMinusOrigStrength)
vec4 pix = src;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  matchMinusOrigStrength.rg;
float strength = matchMinusOrigStrength.z*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
inputOrigI
Td,N,V_inputOrigI
inputOrigQ
Td,N,V_inputOrigQ
Td,N,V_inputStrength
inputWarmth
Td,N,V_inputWarmth
facebalance
inputPointsR
T@"NSArray",&,V_inputPointsR
inputPointsG
T@"NSArray",&,V_inputPointsG
inputPointsB
T@"NSArray",&,V_inputPointsB
inputPointsL
T@"NSArray",&,V_inputPointsL
tableR != nil
+[PICurvesLUTFilter tableImageFromRed:green:blue:luminance:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PICurvesFilter.mm
tableG != nil
tableB != nil
tableL != nil
v56@?0^v8Q16Q24Q32Q40Q48
inputTableImage
T@"CIImage",&,V_inputTableImage
vec4 curve_sample(float x, sampler2D table, vec2 domain, vec2 normalizer)
x = (x - domain.x) / (domain.y - domain.x);
x = clamp(x, 0.0001, 0.9999);
x = normalizer.x * x + normalizer.y;
return texture2D(table, vec2(x, 0.5));
kernel vec4 curves_rgb_lum(__sample color, sampler2D table, vec2 domain, vec2 normalizer)
vec4 pixel = color;
pixel.r = curve_sample(pixel.r, table, domain, normalizer).r;
pixel.g = curve_sample(pixel.g, table, domain, normalizer).g;
pixel.b = curve_sample(pixel.b, table, domain, normalizer).b;
float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11));
float lum1 = curve_sample(lum0, table, domain, normalizer).a;
float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0));
float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0);
float lum_offset = lum1 - lum1c;
pixel.rgb = lum_scale * pixel.rgb + lum_offset;
return pixel;
colorBalance
PPtogHDR
gHDRtoPP
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
kernel vec4 colorBalance(__sample image, float colorI, float colorQ, float str, vec2 gamma)
vec4 pix = image;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  vec2(colorI,colorQ);
float strength = str*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
inputWarmTemp
T@"NSNumber",&,N,V_inputWarmTemp
inputWarmTint
T@"NSNumber",&,N,V_inputWarmTint
T@"NSNumber",&,N,V_inputStrength
inputHasFace
T@"NSNumber",&,N,V_inputHasFace
inputIsRaw
T@"NSNumber",&,N,V_inputIsRaw
-[PIColorBalanceFilter outputImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIColorBalanceFilter.m
PIGlobalSettings
-[PIAutoLoopExportJob initWithVideoExportRequest:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/AutoLoop/PIAutoLoopJob+Export.m
B8@?0
PI_AUTOLOOP_EXPORT_USE_METAL
+[NUJSRenderPipeline(PhotosPipeline) newPhotosPipeline:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIPhotosPipeline.m
Couldn't find the specified Pipeline
PhotosPipeline
Couldn't find bundle for class %@
point
T{CGPoint=dd},R,N,V_point
Td,R,N,V_value
<%@ %p point=(%f, %f) value=%f>
redEyeSpots
-[PIApertureRedEyeAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIApertureRedEyeAutoCalculator.m
pre-Adjustments
T@"NSMutableData",&,Vdata
elementByteSize
TQ,R,VelementByteSize
rowElements
TQ,R,VrowElements
TQ,R,Vwidth
TQ,R,Vheight
format
Ti,R,Vformat
-[PISmartBlackAndWhiteAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PISmartBlackAndWhiteAutoCalculator.mm
v24@?0@"<NUBufferTile>"8^B16
v16@?0@"<NUMutableBuffer>"8
void calculate_bw_auto_matrix_lum_contrast(__strong id<NUBuffer>, CGColorSpaceRef, MsgBlackAndWhiteSettings *)
Produced invalid BlackAndWhite settings, using defaults
xi < w && yi < h
MatrixFloatType &MsgMatrix<double>::operator()(size_t, size_t) [MatrixFloatType = double]
index < data.size()
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
num == w
void MsgMatrix<double>::AppendRow(const NumberType *, uint) [MatrixFloatType = double, NumberType = double]
T@"NSArray",C,N
whiteDst
whiteSrc
hilightDst
hilightSrc
midDst
midSrc
shadowDst
shadowSrc
blackDst
blackSrc
-[PILevelsAutoCalculator calculateSettingsForImageHistogram:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PILevelsAutoCalculator.m
This is an abstract method! Subclass '%@' should provide concrete implementation
-[PILevelsAutoCalculator submit:]
pre-Levels
Blue
Green
creationDate
T@"NSDate",&,N,V_creationDate
creationTimeZone
T@"NSTimeZone",&,N,V_creationTimeZone
title
T@"NSString",C,N,V_title
caption
T@"NSString",C,N,V_caption
keywords
T@"NSArray",C,N,V_keywords
peopleNames
T@"NSArray",C,N,V_peopleNames
location
T@"CLLocation",C,N,V_location
T@"CLLocation",C,N
T@"NSDate",R,N
T@"NSTimeZone",R,N
iptcMutableDictionary
T@"NSMutableDictionary",&,N,V_iptcMutableDictionary
iptcDictionary
T@"NSDictionary",R,C,N
yyyy:MM:dd
HH:mm:ss.SS
en_US
en_US_POSIX
metadataItems
T@"NSArray",R,C,N
v32@?0@8@16^B24
adjustmentConstants
T@"PIAdjustmentConstants",R,N
-[PICompositionController(AdjustmentExtensions) _adjustmentControllerForKey:creatingIfNecessary:expectedClass:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Controllers/PICompositionController+AdjustmentExtensions.m
Adjustment controller for key %@ is of class: %@, but was expected to be %@
Td,R,N,V_x
Td,R,N,V_y
TB,R,N,GisEditable,V_editable
not editable
editable
<%@:%p> [(%.3f, %.3f), %s]
inputStillImage
T@"CIImage",&,N,V_inputStillImage
inputMaskImage
T@"CIImage",&,N,V_inputMaskImage
inputRenderScale
T@"NSNumber",&,N,V_inputRenderScale
inputVideoScale
T@"NSNumber",&,N,V_inputVideoScale
inputAlignmentExtent
T@"CIVector",&,N,V_inputAlignmentExtent
inputAlignmentTransform
T@"CIVector",&,N,V_inputAlignmentTransform
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
long-exp-fusion-image.tiff
long-exp-refined-mask-image.tiff
long-exp-ncc-map-image.tiff
long-exp-guide-image.tiff
long-exp-still-image.tiff
long-exp-mask-image.tiff
long-exp-input-image.tiff
PI_LONG_EXPOSURE_DUMP_INTERMEDIATES
kBlendMaskThreshold1
kBlendMaskThreshold0
kNCCEdge1
kNCCEdge0
kNCCBlurHalfSize
@"NSString"8@?0
PI_LONG_EXPOSURE_FUSION_PARAMS
inputWhiteDst
inputWhiteSrc
inputHilightDst
inputHilightSrc
inputMidDst
inputMidSrc
inputShadowDst
inputShadowSrc
inputBlackDst
inputBlackSrc
kernel vec4 levelsNewGammaForP3 (sampler src, sampler LUT)
vec4
p,r;
vec2
c1,c2;
float
p  = sample(src, samplerCoord(src));
vec3 neg = min(p.rgb, 0.0);
vec3 pos = max(p.rgb, 1.0)-1.0;
p.rgb = clamp(p.rgb, 0.0, 1.0);
f = p.r * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.r = r.r * 4.0 - 1.0;
f = p.g * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.g = r.g * 4.0 - 1.0;
f = p.b * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.b = r.b * 4.0 - 1.0;
p.rgb = max(p.rgb, 0.0);
p.rgb = p.rgb + pos + neg;
return p;
T@"NSNumber",&,N,V_inputBlackSrcRGB
T@"NSNumber",&,N,V_inputBlackDstRGB
T@"NSNumber",&,N,V_inputShadowSrcRGB
T@"NSNumber",&,N,V_inputShadowDstRGB
T@"NSNumber",&,N,V_inputMidSrcRGB
T@"NSNumber",&,N,V_inputMidDstRGB
T@"NSNumber",&,N,V_inputHilightSrcRGB
T@"NSNumber",&,N,V_inputHilightDstRGB
T@"NSNumber",&,N,V_inputWhiteSrcRGB
T@"NSNumber",&,N,V_inputWhiteDstRGB
T@"NSNumber",&,N,V_inputBlackSrcRed
T@"NSNumber",&,N,V_inputBlackDstRed
T@"NSNumber",&,N,V_inputShadowSrcRed
T@"NSNumber",&,N,V_inputShadowDstRed
T@"NSNumber",&,N,V_inputMidSrcRed
T@"NSNumber",&,N,V_inputMidDstRed
T@"NSNumber",&,N,V_inputHilightSrcRed
T@"NSNumber",&,N,V_inputHilightDstRed
T@"NSNumber",&,N,V_inputWhiteSrcRed
T@"NSNumber",&,N,V_inputWhiteDstRed
T@"NSNumber",&,N,V_inputBlackSrcGreen
T@"NSNumber",&,N,V_inputBlackDstGreen
T@"NSNumber",&,N,V_inputShadowSrcGreen
T@"NSNumber",&,N,V_inputShadowDstGreen
T@"NSNumber",&,N,V_inputMidSrcGreen
T@"NSNumber",&,N,V_inputMidDstGreen
T@"NSNumber",&,N,V_inputHilightSrcGreen
T@"NSNumber",&,N,V_inputHilightDstGreen
T@"NSNumber",&,N,V_inputWhiteSrcGreen
T@"NSNumber",&,N,V_inputWhiteDstGreen
T@"NSNumber",&,N,V_inputBlackSrcBlue
T@"NSNumber",&,N,V_inputBlackDstBlue
T@"NSNumber",&,N,V_inputShadowSrcBlue
T@"NSNumber",&,N,V_inputShadowDstBlue
T@"NSNumber",&,N,V_inputMidSrcBlue
T@"NSNumber",&,N,V_inputMidDstBlue
T@"NSNumber",&,N,V_inputHilightSrcBlue
T@"NSNumber",&,N,V_inputHilightDstBlue
T@"NSNumber",&,N,V_inputWhiteSrcBlue
T@"NSNumber",&,N,V_inputWhiteDstBlue
T@"NSString",&,N,V_inputColorSpace
-[PILevelsFilter _LUTImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PILevelsFilter.m
Failed converting data to RGBAh: %ld
Mirror
LongExposure
T@"NUIdentifier",R
PhotosComposition
+[PISchema registerPhotosSchema]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PISchema.m
failed to construct photos pipeline %@
failed to register %@: %@
+[PISchema photosCompositionSchema]
Failed to register schema %@: %@
required
PortraitEffect~1.0
Effect3D~1.0
DepthEffect~1.0
SelectiveColor~1.0
Curves~1.0
Levels~1.0
NoiseReduction~1.0
Orientation~1.0
Vignette~1.0
AutoLoop~1.0
Mute~1.0
HighResolutionFusion~1.0
VideoPosterFrame~1.0
LivePhotoKeyFrame~1.0
SlowMotion~1.0
Trim~1.0
CropStraighten~1.0
Effect~1.0
Definition~1.0
Sharpen~1.0
Grain~1.0
SmartBlackAndWhite~1.0
SmartColor~1.0
SmartTone~1.0
ApertureRedEye~1.0
RedEye~1.0
WhiteBalance~1.0
Retouch~1.0
com.apple.photo:Source~1.0
RawNoiseReduction~1.0
RAW~1.0
contents
Composition
+[PISchema selectiveColorSchema]
saturation
hueShift
spread
blue
green
maximum
minimum
number
properties
compound
content
array
default
bool
Adjustment
+[PISchema curvesSchema]
+[PISchema levelsSchema]
values
enum
+[PISchema whiteBalanceSchema]
identity
grayStrength
ui_maximum
ui_minimum
+[PISchema noiseReductionSchema]
+[PISchema definitionSchema]
+[PISchema orientationSchema]
+[PISchema vignetteSchema]
+[PISchema retouchSchema]
+[PISchema apertureRedEyeSchema]
+[PISchema redEyeSchema]
opaque
iPhone
+[PISchema effectSchema]
+[PISchema portraitEffectSchema]
+[PISchema effect3DSchema]
+[PISchema depthEffectSchema]
+[PISchema highResFusionSchema]
+[PISchema autoLoopSchema]
+[PISchema videoPosterFrameSchema]
+[PISchema muteSchema]
+[PISchema livePhotoKeyFrameSchema]
+[PISchema slomoSchema]
+[PISchema trimSchema]
+[PISchema cropSchema]
+[PISchema sharpenSchema]
+[PISchema grainSchema]
+[PISchema smartBlackAndWhiteSchema]
+[PISchema smartColorSchema]
inputCast
inputSaturation
+[PISchema smartToneSchema]
+[PISchema rawNoiseReductionSchema]
contrast
sharpness
+[PISchema rawSchema]
inputSushiLevel
finalizerError
T@"NSError",&,N,V_finalizerError
disposition
Tq,R,V_disposition
T@"NUComposition",R,C,V_composition
shouldPerformAutoCrop
TB,V_shouldPerformAutoCrop
shouldPerformAutoStraighten
TB,V_shouldPerformAutoStraighten
maxAutoStraighten
Td,V_maxAutoStraighten
-[PICropAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PICropAutoCalculator.m
{CGRect={CGPoint=dd}{CGSize=dd}}
autoCrop
straightenAngleInDegreesCCW
CIAutoStraighten
bounds
error != nil
-[PICropAutoCalculator undoExifOrientation:error:]
Source geometry has 0 size
satPercentileG98
satPercentile98
satPercentile75
inputColorKey
offsetSaturationKey
offsetCastKey
attributeVibrancyKey
attributeCastKey
inputCorrections
T@"NSArray",&,N,V_inputCorrections
iptLumHueSatTable
inputBackgroundImage
CIAdditionCompositing
add_gaussian
CIConstantColorGenerator
iptToSRGB
srgbToIPT
kernel vec4 iptLumHueSatTable(sampler image, __table sampler hueSatLumTable)
vec4 im = sample(image, samplerCoord(image)) ;
vec4 result = im;
float hueIdx = 359.0 * 0.5 * (atan(im.b, im.g)/3.1416 + 1.0);
hueIdx = clamp(hueIdx, 0.0, 359.0) + 0.5;
float hueChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).r);
float satChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).g);
float lumChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).b);
float chroma = sqrt(im.g*im.g+im.b*im.b) ;
chroma *= satChange ;
float hue = atan(im.b, im.g) + hueChange ;
vec3 adjustIm = im.rgb;
float hueAngle = hue  ;
lumChange = mix(1.0, lumChange, chroma);
adjustIm.r *= lumChange;
adjustIm.g = chroma * cos(hueAngle) ;
adjustIm.b = chroma * sin(hueAngle) ;
result.rgb = mix(im.rgb, adjustIm.rgb, 1.0) ;
result.rgb = adjustIm.rgb;
result.a = im.a ;
return result ;
kernel vec4 srgbToIPT(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, ipt;
lms = im.r * vec3(0.3139902162, 0.155372406, 0.017752387) +
im.g * vec3(0.6395129383, 0.7578944616, 0.109442094) +
im.b * vec3(0.0464975462, 0.0867014186, 0.8725692246);
lms = sign(lms)*pow(abs(lms), vec3(0.43, 0.43, 0.43));
ipt = lms.r * vec3(0.4, 4.455, 0.8056) +
lms.g * vec3(0.4, -4.851, 0.3572) +
lms.b * vec3(0.2, 0.3960, -1.1628);
return vec4(ipt, im.a);
kernel vec4 iptToSRGB(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, rgb;
lms = im.rrr +
im.g * vec3(0.09756893,-0.11387649,0.03261511) +
im.b * vec3(0.20522644, 0.13321716,  -0.67688718);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
rgb = lms.r * vec3( 5.472212058380287,  -1.125241895533569,   0.029801651173470) +
lms.g * vec3(-4.641960098354470, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974,  -0.167895202223709, 1.163647892783812);
return vec4(rgb, im.a);
kernel vec4 add_gaussian(sampler srcTable, float tableSize, float hueAmplitude, float satAmplitude, float lumAmplitude, float gaussX, float gaussSigmaSquared) {
vec2 d = destCoord();
vec4 src = sample(srcTable, samplerCoord(srcTable));
float x = d.x / (tableSize - 1.0);
float dist = min(min(abs(x - gaussX), abs(x - 1.0 - gaussX)), abs(x + 1.0 - gaussX));
float p = -((dist * dist) / (2.0 * gaussSigmaSquared));
float ep = exp(p);
float hue = hueAmplitude * ep;
float sat = satAmplitude * ep;
float lum = lumAmplitude * ep;
float h = clamp(src.r + hue, -1.0, 1.0);
float s = clamp(src.g + sat, -1.0, 1.0);
float l = clamp(src.b + lum, -1.0, 1.0);
return vec4(h,s,l,1.0);
convertFromYIQToRGB
convertFromRGBToYIQ
kernel vec4 convertFromRGBToYIQ(sampler src, float gamma)
vec4 pix ;
vec3 pix2;
pix = sample(src, samplerCoord(src));
pix.rgb = sign(pix.rgb)*pow(abs(pix.rgb), vec3(1.0/gamma)) ;
pix2.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
return vec4(pix2, pix.a);
kernel vec4 convertFromYIQToRGB(sampler src, float gamma)
vec4 color, pix;
pix = sample(src, samplerCoord(src));
color.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
color.rgb = sign(color.rgb)*pow(abs(color.rgb), vec3(gamma, gamma, gamma) );
color.a = pix.a;
return color;
kernel vec4 whiteBalance(sampler image, float grayY, float grayI, float grayQ, float strength)
vec4 im = sample(image, samplerCoord(image)) ;
vec2 grayOffset = vec2(grayI, grayQ) ;
vec4 result ;
float newStrength = 1.0 + (strength-1.0)*(1.0-im.r) ;
result.r = im.r ;
result.gb = im.gb + newStrength*grayOffset ;
float damp = max(min(1.0, im.r/(grayY+0.00001)),0.0) ;
result.rgb = mix(im.rgb, result.rgb, damp) ;
result.a = im.a ;
return result ;
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
warmth
T@"NSNumber",&,N,V_strength
T@"NSNumber",&,N,V_warmth
T@"NSNumber",&,N,V_y
T@"NSNumber",&,N,V_i
T@"NSNumber",&,N,V_q
-[PINeutralGrayWhiteBalanceFilter outputImage]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PINeutralGrayWhiteBalanceFilter.m
-[PISmartToneAutoCalculator submit:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIAutoCalculators.mm
PISmartToneAutoCalculator
v8@?0
CILocalLight
CISmartTone
-[PISmartColorAutoCalculator submit:]
CISmartColor
-[PIRedEyeAutoCalculator submit:]
touchDiameter
locationY
locationX
/masterSpace
%@-%d-%ld.tiff
cgImage != NULL
+[PIImageIO writeCGImage:fileURL:options:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Util/PIImageIO.m
fileURL != nil
Failed to write image to file %@
Successfully wrote image to file %@
+[PIImageIO writeCGImage:fileURL:]
GU %@ %@
Unhandled bit depth: %ld
image != nil
+[PIImageIO writeImage:fileURL:]
edgesKey
+[PIApertureRedEyeProcessorKernel processWithInputs:arguments:output:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIApertureRedEyeFilter.mm
output.format == kCIFormatRGBAf
Sensitivity
+[PIApertureRedEyeProcessorKernel convertFixed16:toFloat:count:]
Bad fixed 16 to float conversion
+[PIApertureRedEyeProcessorKernel convertFloat:toFixed16:count:]
Bad float to fixed 16 conversion
inputSensitivity
portraitStrength
capturedPortraitMajorVersion
capturedPortraitMinorVersion
portraitDisableStage
Tf,N,V_aperture
Tf,N,V_portraitStrength
T@"NSNumber",&,N,V_minimumAperture
T@"NSNumber",&,N,V_maximumAperture
portraitMajorVersion
TQ,N,V_portraitMajorVersion
portraitMinorVersion
TQ,N,V_portraitMinorVersion
T{?=ii},N,V_versionInfo
<%@:%p aperture:%f minimumAperture: %@ maximumAperture: %@>
error != NULL
+[PIValuesAtCapture valuesAtCaptureFromImageProperties:error:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PIPortraitAutoCalculator.m
portraitLightingEffectStrength
Depth data version mismatch, asset has %@ but we can only handle %@
depthData:DepthDataVersion
Missing auxiliary metadata
Failed to load auxiliary data
Missing camera calibration data
Low quality depth data is not supported
Unfiltered depth data is not supported
Failed to load depth data
Portrait was previously applied
v16@?0@"NUResponse"8
-[PIPortraitAutoCalculator submit:]
capturedPortraitStrength
capturedAperture
metadata != nil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromCameraMetadata:]
faceObservations != nil
+[PIPortraitAutoCalculator portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:]
NUOrientationIsValid(orientation)
faceLandmarks
rightPupil
leftPupil
innerLips
outerLips
medianLine
noseCrest
nose
rightEyebrow
leftEyebrow
rightEye
leftEye
faceContour
allPoints
faceOrientationIndex
faceJunkinessIndex
faceBoundingBox
+[PIPortraitAutoCalculator depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:]
faces
focusRect
lumaNoiseScale
maximumAperture
minimumAperture
chinY
chinX
Insufficient number of landmark points
noseY
noseX
rightEyeY
rightEyeX
leftEyeY
leftEyeX
+[PIPortraitAutoCalculator portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:]
-[PIDepthEffectApertureAutoCalculator submit:]
+[PIPipelineFilters autoloopStabilizedVideoFilter]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Adjustments/PIPipelineFilters.m
Could not construct autoloopStabilizedVideoFilter filter from inline source
ResetTagInput('/AutoLoop/Output', GetTag('/AutoLoop/StabilizedVideo'));
return input;
+[PIPipelineFilters applyOrientationFilter]
Could not construct pipeline filter from source: %@
var output = input;
var orientation = composition.orientation;
if (orientation) {
    output = Orient(input, orientation.value);
return output;
+[PIPipelineFilters stopAtTagIncludeOrientationFilter:]
Could not construct stopAtTagIncludeOrientationFilter from inline source
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Orientation', tagNode);
return GetTag('/Orientation');
+[PIPipelineFilters stopAtTagIncludeGeometryFilter:]
Could not construct stopAtTagIncludeGeometryFilter from inline source
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Geometry', tagNode);
return GetTag('/post-Geometry');
/post-Geometry
/pre-Geometry
+[PIPipelineFilters perspectiveStraightenWithoutCropFilter]
Could not construct perspectiveStraightenWithoutCropFilter filter from inline source
var preCrop = GetTag('/perspectiveStraighten');if (preCrop) {   ResetTagInput('/Crop', preCrop);
}return input;
+[PIPipelineFilters noGeometryFilter]
Could not construct noGeometry filter from inline source
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Geometry', preGeometry);
return input;
+[PIPipelineFilters stripAllTimeAdjustmentsFilter]
Could not construct stripAllTimeAdjustmentsFilter filter from inline source
var image = GetTag('pre-Trim');ResetTagInput('Trim', image);
image = GetTag('pre-SloMo');ResetTagInput('SloMo', image);
return input;
+[PIPipelineFilters iosCropToolFilter]_block_invoke
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Adjustments', preGeometry);
return input;
+[PIPipelineFilters noCropFilter]
Could not construct noCropFilter filter from inline source
var preCrop = GetTag('/pre-Crop');ResetTagInput('/pre-Orientation', preCrop);
return input;
+[PIPipelineFilters noMuteFilter]
Could not construct noMuteFilter filter from inline source
var preMute = GetTag('pre-Mute');ResetTagInput('Mute', preMute);
return GetTag('Image');
+[PIPipelineFilters noTrimFilter]
Could not construct noTrimFilter filter from inline source
var output = input
var preTrim = GetTag('/pre-Trim');ResetTagInput('/SloMo', preTrim);
let slomo = composition.slomo
if (slomo) {
    var startTime = TimeMake(slomo.start, slomo.startScale)
    var endTime = TimeMake(slomo.end, slomo.endScale)
    output = SloMo(input, startTime, endTime, slomo.rate)
return output;
+[PIPipelineFilters noRedEyeFilter]
Could not construct noRedEye filter from inline source
var source = GetTag('/pre-RedEye');ResetTagInput('/post-RedEye', source);
return GetTag('/post-RedEye');
var sourceSettings = { 'skipOrientation' : true }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
  return Source(composition.source, sourceSettings); 
} else {
  return GetTag("/ShowOriginalSource");
var sourceSettings = { }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
} else { throw "expected RAW in rawSourceFilterIncludingOrientation"; }
return Source(composition.source, sourceSettings); 
var sourceSettings = {  };
var rawAdjustment = composition.raw
if (rawAdjustment) {
    sourceSettings['inputDecoderVersion'] = rawAdjustment.inputDecoderVersion
var image = Source(composition.source, sourceSettings)
var rawImage = GetTagInput('RAW/Linear')
if (rawImage) {
    image = rawImage
    image = Filter('PIForwardFakeBoost', {'inputImage' : image, 'inputBoost' : 1.0,})
return image
var source = GetTag('/pre-Adjustments');
ResetTagInput('/pre-Crop', source);
source = GetTag('/Crop');
orientation = source.geometry.orientation;
source = Orient(source, orientation);
return source;
var tagNode = GetTag('/pre-Adjustments');
orientation = tagNode.geometry.orientation;
var node = Orient(tagNode, orientation);
return node;
warmTempKey
warmTintKey
warmFaceKey
none
recipe != nil
NSDictionary * _Nonnull PIAutoLoopRecipeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/AutoLoop/PIAutoLoop.m
CGRect PIAutoLoopRecipeGetCropRect(NSDictionary *__strong _Nonnull)
origin_y
origin_x
BOOL PIAutoLoopRecipeHasGoodStabilization(NSDictionary *__strong _Nonnull)
frameTransform != nil
CMTime PIAutoLoopRecipeFrameTransformGetTime(NSDictionary *__strong)
frameTransform_rawTime
matrix_float3x3 PIAutoLoopRecipeFrameTransformGetHomography(NSDictionary *__strong)
frameTransform_homography
NSDictionary * _Nonnull PIAutoLoopRecipeGetInstructionAtTime(NSDictionary *__strong _Nonnull, CMTime)
CMTIME_IS_VALID(time)
q24@?0@"NSDictionary"8@"NSDictionary"16
loopFrameData_presTime
loopRecipe_frameInstructions
CMTime PIAutoLoopRecipeGetFrameDuration(NSDictionary *__strong _Nonnull)
NSDictionary * _Nullable PIAutoLoopRecipeGetFlavorParameters(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
CMTimeRange PIAutoLoopRecipeGetTimeRangeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
-[PICurvesAutoCalculator computeCurvesForImageHistogram:]
/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3502.18.222/PhotoImaging/Autocalculators/PICurvesAutoCalculator.m
completion != nil
-[PICurvesAutoCalculator submit:]
pre-Curves
class %@ is not the correct type, its superclass should be %@
Continue: %{public}@
Trace: %{public}@
Fail: %{public}@
facerect yiq = %.5f, %.5f, %.5f
Buffer sizes are not the same: %{public}@ vs %{public}@
Buffer size is %@, bytes per row is %ld, dark_thr=%f, sat_thr=%f, noise_thr=%f
all done summing, np_gw is %d, np_ge is %d
wp_ge {%f, %f, %f, %f} wp_gw {%f, %f, %f, %f}, Sushi? %@
aperture=%@, shutterSpeed=%@, iso=%@
Brightness is %@, greenChannelPercentage is %f, Sushi: %@
Choosing gray world instead of gray edge
RGB = %f, %f, %f
YIQ = %f, %f, %f from %f, %f, %f
Failed to export video: %@
[NUVideoRotationExportRequest isCompatibleWithComposition] failed. Error:%@
failed to render auxiliary image data: %@
Failed to prepare video metadata: %@
Failed to export image to data: %@
Failed to export image to %@: %@
Unable to create regex for pattern: %@
Can PLPhotoEditPFDataConverter interpret identifier %@? %@. Version %@? %@
validation issue: recipe is blank on the autoloop adjustment
validation issue: no flavor specified on the autoloop adjustment
validation issue: Missing inputCorrectionInfo on a redeye adjustment
validation issue: Missing depthInfo on a depth adjustment
validation issue: Missing portraitInfo on a portrait adjustment
validation issue: invalid trim startTime or endTime
Writing long-exposure motion mask to %{public}@
Writing long-exposure image to %{public}@
waitUntilReadyForMoreData: waited for %0.1fms
High-resolution image registration failure : %@
Still image node:
Still image geometry:
Still image:
clap=%@, crop=%@, fullSize=%@, videoScale=%@ => guide rect: %@
[XMP metadata builder] Failed create data from XMP metadata %@
[XMP metadata builder] Failed to set value for dictionary name %{public}@ key %{public}@ value %{private}@
Missing inputImage
Missing inputMaskImage
Missing inputStillImage
Missing inputRenderScale
Missing inputVideoScale
Missing inputAlignmentExtent
Malformed inputAlignmentExtent vector
Missing inputAlignmentTransform
Malformed inputAlignmentTransform vector
Writing intermediate long exposure fusion images to : %@
Loading long-exposure fusion tuning parameters from file: %@
Failed to load fusion tuning parameters.
Using fusion tuning parameters: {kNCCBlurHalfSize=%d, kNCCEdge0=%f, kNCCEdge1=%f, kBlendMaskThreshold0=%f, kBlendMaskThreshold1=%f}
Failed to apply red eye repair. error: %{public}@
Depth effects not supported: %@
Couldn't deserialize face observations from metadata: %@, assuming empty, error: %@.
Invalid face indexes from metadata: %@, ignored. Error: %@
Couldn't deserialize face observations from metadata: %@
Invalid focus rect: {%g,%g,%g,%g}
Metadata dictionary missing fullSizeWith or fullSizeHeight:
Metadata dictionary missing exif aux dictionary:
Exif aux dictionary missing MWG region dictionary:
MWG region dictionary missing region list:
Region list does not contain a focus rect:
Malformed focus rect dictionary:
s-curve black: %f
s-curve point %d: (%f, %f)
s-curve white: %f
red curve: blackPoint = %f, whitePoint = %f
green curve: blackPoint = %f, whitePoint = %f
blue curve: blackPoint = %f, whitePoint = %f
PICompositionController
NSCopying
PICompositionSerializer
PICompositionSerializationResult
PICompositionSerializerMetadata
PIAutoCalculatorUtils
PIAutoLoopExportRequest
PIAutoLoopExportClient
PIAutoLoopAnalysisRequest
PIAutoLoopAnalysisClient
PILongExposureRegistrationRequest
PIZlibDataCompressionOptions
PIZlibDataDecompressionOptions
PIZlibDataCompression
PIAutoLoopAdjustmentController
PILivePhotoKeyFrameAdjustmentController
PIVignetteAdjustmentController
PIAdjustmentController
PIFaceObservationCache
PILongExposureFusionAutoCalculator
PIEffectAdjustmentController
PIAutoLoopAutoCalculator
PIMakerNoteUtilities
PITempTintFilter
NSObject
NURenderResult
PIAutoLoopAnalysisResult
_PIAutoLoopAnalysisResult
PIAutoLoopAnalysisJob
PIFaceBalanceAutoCalculator
NUTimeBased
_PIWhiteColorCalculator
PIWhiteBalanceAutoCalculator
GrayColorResult
RGBResult
PIDefinitionFilter
PISmartBlackAndWhiteAdjustmentController
PICompositionExportImagePrepareResult
PICompositionExportResult
PICompositionExportAuxiliaryResult
PICompositionExportDataResult
PICompositionExporterOptions
PICompositionExporterVideoOptions
PICompositionExporterImageOptions
PICompositionExporterAuxiliaryOptions
PICompositionExporter
GUBilateralConvolution
GUBWBilateralConvolution
PIBilateralFilter
PIPhotoEditAdjustmentsVersion
PINoiseReductionAdjustmentController
PIPortraitAdjustmentController
PIOrientationAdjustmentController
PIDefinitionAdjustmentController
PIPerspectiveAutoCalculator
PIFaceObservingAutoCalculator
PIRawNoiseReductionAdjustmentController
PICropAdjustmentController
PIRawAdjustmentController
PISmartToneAdjustmentController
PIAutoLoopKernels
PIPhotoEditHelper
PIAdjustmentConstants
PIForwardFakeBoost
PIInverseFakeBoost
PICoreImageUtilities
PICompositionSerializerConstants
PILongExposureAccumulator
PILongExposureRegistrationResult
_PILongExposureRegistrationResult
PILongExposureRegistrationJob
PIRAWTempTintSampler
PITagColorSampler
PIRedEye
PIVideoPosterFrameAdjustmentController
PICompositionSerializerFormatVersion
PICaptureDebugUtilities
PISlomoAdjustmentController
PIRAWFaceBalance
PICurvesLUTFilter
PICurvesFilter
PIColorBalanceFilter
PIHighResFusionAdjustmentController
PIGlobalSettings
PIAutoLoopExportJob
PIJSRenderPipeline
PhotosPipeline
PIClusterPoint
PIApertureRedEyeAutoCalculator
PIMsgImageBuffer
PISmartBlackAndWhiteAutoCalculator
PITrimAdjustmentController
PIRedEyeAdjustmentController
PILevelsAutoCalculator
PILevelsLuminanceAutoCalculator
PILevelsRGBAutoCalculator
PIExportMetadataBuilder
PIExportImageMetadataBuilder
PIExportVideoMetadataBuilder
PIExportXMPMetadataBuilder
AdjustmentExtensions
PICurveControlPoint
PILongExposureFusion
PILevelsFilter
PISchema
PICompositionFinalizer
PICompositionFinalizerResult
PICropAutoCalculator
PISmartColorAdjustmentController
PISelectiveColorFilter
PINeutralGrayWhiteBalanceFilter
PISmartToneAutoCalculator
PISmartColorAutoCalculator
PIRedEyeAutoCalculator
PIManualRedEyeAutoCalculator
PISourceSampler
PIImageIO
PISharpenAdjustmentController
PIApertureRedEyeProcessorKernel
PIApertureRedEyeFilter
PIValuesAtCapture
PIPortraitAutoCalculator
PIDepthEffectApertureAutoCalculator
PIPipelineFilters
Debug
PIWhiteBalanceAdjustmentController
PIDepthAdjustmentController
PICurvesAutoCalculator
PICurvesLuminanceAutoCalculator
PICurvesRGBAutoCalculator
_composition
_delegateFlags
_identifierMap
_changeDelegate
_imageOrientation
copyWithZone:
initWithComposition:
composition
setChangeDelegate:
compositionKeys
availableKeys
addAdjustmentWithKey:
replaceAdjustment:withKey:
removeAdjustmentWithKey:
adjustmentControllerForKey:
modifyAdjustmentWithKey:modificationBlock:
applyChangesFromCompositionController:
isEqual:visualChangesOnly:
isEqual:forKeys:visualChangesOnly:
isEqual:forKeys:comparisonBlock:
debugDescription
differingAdjustmentsWithComposition:
userOrientation
_adjustmentControllerClassForKey:
setSource:mediaType:
.cxx_destruct
changeDelegate
imageOrientation
setImageOrientation:
setMediaType:
isSubclassOfClass:
compositionController:adjustmentControllerClassForKey:
adjustmentControllerClassForKey:
addObject:
arrayWithObjects:count:
countByEnumeratingWithState:objects:count:
stringWithFormat:
alloc
boolValue
_keyToIdentifierMap
integerValue
containsObject:
allKeys
schema
isEqualToString:
compositionController:didUpdateAdjustments:
compositionController:didUpdateAdjustment:
reset
initWithIdentifier:
copy
compositionController:didRemoveAdjustment:
compositionController:didAddAdjustment:
addObjectsFromArray:
contents
schemaForKey:
settingForAdjustmentKey:settingKey:
photosSchema
schemaWithIdentifier:
sharedRegistry
initialize
disableApertureEffects:
canInterpretDataWithFormatIdentifier:formatVersion:
deserializeCompositionFromData:formatIdentifier:formatVersion:error:
validateCompositionWithMissingSource:error:
deserializeCompositionFromAdjustments:metadata:formatIdentifier:formatVersion:error:
serializeComposition:versionInfo:error:
serializeComposition:versionInfo:serializerMetadata:error:
validateAdjustmentsEnvelope:error:
_validateValueTypesForKeys:requiredKeys:inDictionary:error:
serializeDictionary:error:
deserializeDictionaryFromData:error:
_sanitizeComposition:
componentsJoinedByString:
callStackSymbols
errorWithDomain:code:userInfo:
dictionaryWithObjects:forKeys:count:
JSONObjectWithData:options:error:
dataWithJSONObject:options:error:
enumerateKeysAndObjectsUsingBlock:
initWithDomain:code:userInfo:
setWithArray:
setData:
setFormatVersion:
setFormatIdentifier:
_data
_formatIdentifier
_formatVersion
data
formatIdentifier
formatVersion
numberWithInt:
numberWithBool:
setWithObjects:
array
orientation
height
numberWithInteger:
width
handleFailureInMethod:object:file:lineNumber:description:
currentHandler
stringWithUTF8String:
setOrientation:
setHeight:
setWidth:
size
_width
_height
_orientation
initWithName:
stringByAppendingString:
validateComposition:error:
URLWithString:
convertFacePoint:toImagePointWithFaceRect:orientation:
averagePoints:pointCount:
averageCGPoints:pointCount:
handleFailureInFunction:file:lineNumber:description:
_destinationUTI
_destinationLongExposureURL
_destinationMaskURL
initWithRequest:
initWithComposition:destinationURL:
initWithComposition:stabilizedVideoURL:longExposureDestinationURL:maskDestinationURL:destinationUTI:
newRenderJob
mediaComponentType
outputColorSpace
submit:
destinationUTI
destinationLongExposureURL
destinationMaskURL
submitGeneric:
sRGBColorSpace
colorSpaceFromVideoColorProperties:
objectForKey:
outputSettings
setCompletionBlock:
submitRequest:
submitGenericRequest:
setGenericCompletionBlock:
_flavor
flavor
setFlavor:
_recipe
_cleanAperture
recipe
setRecipe:
cleanAperture
setCleanAperture:
_compressionLevel
_strategy
_windowBits
_memoryLevel
_chunkSize
setCompressionLevel:
setCompressionStrategy:
compressionLevel
strategy
setStrategy:
windowBits
setWindowBits:
memoryLevel
setMemoryLevel:
chunkSize
setChunkSize:
defaultOptions
_decompressAllAtOnce
_createBuffer
_growData
setCreateBuffer:
setGrowData:
createBuffer
growData
decompressAllAtOnce
setDecompressAllAtOnce:
increaseLengthBy:
length
dataWithLength:
compressData:options:error:
decompressData:options:error:
dataWithData:
setLength:
mutableBytes
dictionary
init
raise:format:
flavorKey
recipeKey
initWithAdjustment:
keyFrameTime
setKeyFrameTime:
scaleKey
timeKey
numberWithLongLong:
intValue
longLongValue
intensity
setIntensity:
radius
setRadius:
falloff
setFalloff:
falloffKey
numberWithDouble:
doubleValue
radiusKey
intensityKey
_changes
_identifier
_adjustment
displayName
displayInputKeys
inputKeys
settingForKey:
hasInputKey:
enabled
setEnabled:
canBeEnabled
canHaveAuto
hasAutoKeyInSchema
isAuto
setIsAuto:
objectForKeyedSubscript:
setObject:forKeyedSubscript:
setValue:forUndefinedKey:
valueForUndefinedKey:
valuesForArrayInputKey:
setFromAdjustment:
interpolateFromStart:toEnd:progress:
timeFromInputKey:timescaleKey:
visualInputKeys
isEqual:forKeys:
isSettingEqual:forKey:
_setPrimitiveValue:forKey:
_primitiveValueForKey:
settings
_isDefault
identifier
setIdentifier:
adjustment
count
defaultValue
valueForKey:
setValue:forKey:
isEqualToValue:
values
autoKey
enabledKey
name
_group
_queue
_result
submit:response:
submitSynchronous:error:
submitGenericSynchronous:
result:
initWithResult:
faceRequestWithRequest:
setSampleMode:
initWithTargetPixelCount:
setPipelineFilters:
_computeCleanAperture:
initWithError:
unsupportedError:object:
stopAtTagFilter:
setName:
setKind:
kind
setVersion:
version
floatValue
versionKey
kindKey
addAssetIdentifier:toMetadataDictionary:
addAssetIdentifier:toMetadataArray:
removeAssetIdentifierFromMetadataArray:
removeObjectAtIndex:
indexOfObjectPassingTest:
setValue:
metadataItem
mutableCopy
_inputImage
_temperature
_tint
outputImage
setInputVectorsForFilter:
inputImage
setInputImage:
temperature
setTemperature:
tint
setTint:
vectorWithX:Y:Z:W:
filterWithName:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
statistics
_videoSource
wantsOutputGeometry
wantsOutputVideo
wantsCompleteStage
cacheKey
scalePolicy
analysisRequest
prepare:
render:
result
videoSource
setVideoSource:
asset:
missingError:object:
renderNode
oneToOneScalePolicy
stringValue
finalize
nu_updateDigest:
_rawState
time
setTime:
initWithRequest:isRAW:
rawState
rawProperties
calculateRAWWithRequest:completion:
calculateWithRequest:completion:
faceBalanceResultFromFaceObservations:request:error:
faceRectFromNormalizedFaceRet:forImageExtent:scaleX:scaleY:
faceBalanceFromFaceImage:forFaceRect:
readBufferRegion:withBlock:
bytesAtPoint:
frameRect
buffer
validRegion
BGRA8
RGBA8
isEqualToPixelFormat:
ARGB8
errorWithCode:reason:object:underlyingError:
setResponseQueue:
setRegionPolicy:
initWithRect:
bounds
addRect:
boundingBox
imageSize
faces
initWithRequest:dataExtractor:options:
_bufferRenderClient
_imageDataClient
_useSushi
initWithComposition:useSushi:
readBufferFromImage:withRGBAfBufferBlock:
calculateColorWithProperties:completion:
_brightnessMultiplierFromImageProperties:
_computeWhitePointColorWithGrayEdgesBuffer:grayWorldBuffer:greenChannelPercentage:RAWCameraSpaceProperties:
_whitePointColorFromGrayEdgesImage:grayWorldImage:greenChannelPercentage:RAWCameraSpaceProperties:
_configureRequest:
_computeGreenPercentage:
_submitGWRenderRequest:
_submitGERenderRequest:
initWithScript:
initWithSource:
submitRequest:completion:
initWithComposition:dataExtractor:options:
setTileSize:
genericRGBLinearColorSpace
setPixelFormat:
RGBAh
whiteFactor
whiteValue
rowBytes
metadata
commitAndNotifyOnQueue:withBlock:
pi_valueWithGrayColorResult:
rawCameraSpaceProperties
begin
returnStorage:
writeBufferInRegion:block:
regionWithRect:
newStorageWithSize:format:
RGBAf
bufferFactory
sharedFactory
initWithName:responseQueue:
_useTempTint:
_correctedRGBResultFromResult:
_chooseNeutralGrayForNonSushi:
_chooseTempTintForSushi:RAWProperties:brightness:
objectAtIndexedSubscript:
inputNeutralXYFromRGB:
valueWithRGBResult:
responseQueue
pi_grayColorResultValue
valueWithBytes:objCType:
getValue:
RGBResultValue
definitionKernel
kernelWithString:
_inputBlurImage
_inputIntensity
inputBlurImage
setInputBlurImage:
inputIntensity
setInputIntensity:
imageByPremultiplyingAlpha
applyWithExtent:arguments:
imageByUnpremultiplyingAlpha
strengthKey
neutralKey
toneKey
grainKey
hueKey
inputStrengthKey
inputNeutralGammaKey
inputToneKey
inputGrainKey
inputHueKey
inputSeedKey
attributeStrengthKey
attributeNeutralGammaKey
attributeToneKey
attributeHueKey
attributeGrainKey
setStrength:
strength
setNeutral:
neutral
setTone:
tone
setGrain:
grain
setHue:
_request
_inputSize
request
setRequest:
inputSize
setInputSize:
_geometry
geometry
setGeometry:
_auxiliaryImages
_properties
auxiliaryImages
setAuxiliaryImages:
properties
setProperties:
_priority
_colorSpace
_pairingIdentifier
_scalePolicy
priority
setPriority:
colorSpace
setColorSpace:
pairingIdentifier
setPairingIdentifier:
setScalePolicy:
displayP3ColorSpace
initWithLevel:
_metadataProcessor
metadataProcessor
setMetadataProcessor:
_optimizeForSharing
_imageExportFormat
setImageExportFormatJpegWithQuality:
imageExportFormatForURL:
imageExportFormat
setImageExportFormat:
optimizeForSharing
setOptimizeForSharing:
defaultFormatForURL:
setCompressionQuality:
_primaryURL
_videoComplementURL
_videoPosterFrameURL
primaryURL
setPrimaryURL:
videoComplementURL
setVideoComplementURL:
videoPosterFrameURL
setVideoPosterFrameURL:
exportImageToURL:composition:options:completion:
exportImageToDataWithComposition:options:completion:
exportVideoToURL:composition:options:completion:
exportComposition:toPrimaryURL:videoComplementURL:videoPosterFrameURL:completionQueue:completion:
exportComposition:options:completionQueue:completion:
variationForFlavor:
prepareImageExportRequest:options:completion:
prepareAuxiliaryImagesFetchProperties:options:completion:
addImageProperties:composition:options:error:
_prepareToExportVideo:options:completion:
addVideoProperties:composition:options:error:
shouldTryVideoRotationFastPath:options:
_exportVideoToURL:composition:options:metadata:progress:completion:
_exportVideoToURLFull:composition:options:metadata:progress:completion:
submitWithProgress:completion:
setOutputSettings:
CGColorSpace
setObject:forKey:
setMetadata:
videoMetadataForVariation:error:
metadataConverter
invalidError:object:
setPhotoFeatureFlags:properties:error:
numberWithUnsignedInteger:
unsignedIntegerValue
photoFeatureFlags:error:
numberWithShort:
setPhotoProcessingFlags:properties:error:
photoProcessingFlagsFromProperties:error:
setImageVariation:properties:error:
auxiliaryImage
setAuxiliaryImageType:
auxiliaryImagesProperties
setCoreGraphicsInfoDictionariesByAuxiliaryType:
dictionaryRepresentationForAuxiliaryDataType:
setImageProperties:
unknownError:object:
resetImageProperties:preserveRegions:
numberWithUnsignedInt:
UUIDString
UUID
mediaType
discreteProgressWithTotalUnitCount:
destinationData
setFormat:
setRenderToData:
setDestinationURL:
setMetadataConverter:
removeObjectForKey:
bilateralKernels
RGBToLabKernels
bilateralAdd1Kernel
bilateralAdd2Kernel
bilateralAdd3Kernel
bilateralAdd4Kernel
bilateralAdd5Kernel
bilateralAdd6Kernel
bilateralAdd7Kernel
bilateralAdd8Kernel
bilateralAdd9Kernel
bilateralFinalizeKernel
RGBToLabKernel
LabToRGBKernel
_inputPoints
_inputWeights
_inputEdgeDetail
_inputVersion
samplesPerPass
boundsForPointArray:
enlargedBounds:withPoints:
bilateralAddROI:destRect:userInfo:
doBilateralPass:points:weights:sums:slope:
inputPoints
setInputPoints:
inputWeights
setInputWeights:
inputEdgeDetail
setInputEdgeDetail:
inputVersion
setInputVersion:
subarrayWithRange:
samplerWithImage:options:
vectorWithX:Y:Z:
vectorWithX:Y:
applyWithExtent:roiCallback:arguments:
objectAtIndex:
unionWith:
definition
shapeWithRect:
BWBilateralKernels
bilateralLoop2Kernel
bilateralLoop5Kernel
bilateralLoop11Kernel
_inputBorder
bilateralROI:destRect:userInfo:
doBilateralLoop:points:weights:slope:
inputBorder
setInputBorder:
samplerWithImage:
customAttributes
dictionaryWithObjectsAndKeys:
_inputRadius
inputRadius
setInputRadius:
numberWithFloat:
arrayWithCapacity:
_majorVersion
_minorVersion
_platform
initWithMajor:minor:platform:
initWithMajor:minor:
string
compare:
isEqualToAdjustmentVersion:
majorVersion
minorVersion
platform
stringByAppendingFormat:
caseInsensitiveCompare:
versionWithMajor:minor:platform:
versionFromString:
substringWithRange:
rangeAtIndex:
firstMatchInString:options:range:
regularExpressionWithPattern:options:error:
amountKey
_version
setPortraitInfo:
portraitInfo
canRenderPortraitEffect
portraitInfoKey
valueKey
_disableOnPanos
_disableOnFrontFacingCameraImages
_shouldRunDetectorsIfNecessary
_shouldRunBuildingCheck
_debugFilesEnabled
_faceObservationCache
_maxAutoYaw
_maxAutoPitch
_maxAutoAngle
_minimumConfidence
_maxFaceSize
_minSalientArea
_maxSalientSubjectArea
_saliencyObservation
_angleSeedDegreesCCW
_debugFilesPrefix
_debugDiagnostics
_debugLineDetectionImage
faceObservationCache
setFaceObservationCache:
perspectiveErrorFromCoreImage:
addMethodDiagnostics:details:
addMethodResultToDiagnostics:error:setYawPitchError:
wrapAsUnexpectedError:
writeDebugDiagnosticsToDisk
getSizeOfAllFaces:
passesFaceCheck:
hasFrontFacingCameraDimentions:
isFrontFacingCameraImage:pixelSize:
passesImagePropertiesCheck:
passesSaliencyCheck:
primaryImageProperties:
canGenerateNewCropRect:
passesConfidenceCheck:error:
submitVerified:
maxAutoYaw
setMaxAutoYaw:
maxAutoPitch
setMaxAutoPitch:
maxAutoAngle
setMaxAutoAngle:
minimumConfidence
setMinimumConfidence:
maxFaceSize
setMaxFaceSize:
disableOnPanos
setDisableOnPanos:
disableOnFrontFacingCameraImages
setDisableOnFrontFacingCameraImages:
shouldRunDetectorsIfNecessary
setShouldRunDetectorsIfNecessary:
shouldRunBuildingCheck
setShouldRunBuildingCheck:
minSalientArea
setMinSalientArea:
maxSalientSubjectArea
setMaxSalientSubjectArea:
saliencyObservation
setSaliencyObservation:
angleSeedDegreesCCW
setAngleSeedDegreesCCW:
debugFilesEnabled
setDebugFilesEnabled:
debugFilesPrefix
setDebugFilesPrefix:
debugDiagnostics
debugLineDetectionImage
setDebugLineDetectionImage:
undoOrientation:forPitch:yaw:angle:
null
imageByApplyingTransform:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
dataWithBytes:length:
pixelBuffer
defaultFocalLength
setComposition:
setRollAngle:constrainCropRectWithTargetArea:
initWithMasterImageSize:
nonLocalizedFailureReason
salientObjects
containsString:
hasPrefix:
PNGRepresentationOfImage:format:colorSpace:options:
contextWithOptions:
writeToURL:atomically:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
defaultManager
URLByAppendingPathComponent:
userInfo
luminanceKey
shortValue
isGeometryIdentityForImageSize:
isCropConstrained
isCropIdentityForImageSize:
cropRect
constraintWidth
constraintHeight
angle
angleRadians
pitch
pitchRadians
yawRadians
autoCropped
setCropRect:
setConstraintWidth:
setConstraintHeight:
setAngle:
setAngleRadians:
setPitch:
setPitchRadians:
setYaw:
setYawRadians:
setAutoCropped:
heightKey
widthKey
yOriginKey
xOriginKey
yawKey
pitchKey
angleKey
maximumValue
minimumValue
constraintHeightKey
constraintWidthKey
setInputDecoderVersion:
inputDecoderVersion
_smartSettings
_updateSettingsWithInputLight:
computedSettings
setInputLight:
inputLight
setInputExposure:
inputExposure
setInputBrightness:
inputBrightness
setInputContrast:
inputContrast
setInputShadows:
inputShadows
setInputHighlights:
inputHighlights
setInputBlack:
inputBlack
setInputLocalLight:
inputLocalLight
setInputRawHighlights:
inputRawHighlights
setStatistics:
offsetBlack
setOffsetBlack:
offsetBrightness
setOffsetBrightness:
offsetContrast
setOffsetContrast:
offsetExposure
setOffsetExposure:
offsetHighlights
setOffsetHighlights:
offsetLocalLight
setOffsetLocalLight:
offsetShadows
setOffsetShadows:
offsetShadowsKey
offsetLocalLightKey
offsetHighlightsKey
offsetExposureKey
offsetContrastKey
offsetBrightnessKey
offsetBlackKey
statisticsKey
inputRawHighlightsKey
inputLocalLightKey
inputBlackKey
inputHighlightsKey
inputShadowsKey
inputContrastKey
inputBrightnessKey
inputExposureKey
inputLightKey
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
attributeBrightnessKey
attributeContrastKey
attributeExposureKey
attributeHighlightsKey
attributeShadowsKey
attributeBlackPointKey
attributeLocalLightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLightMapHeightKey
alphaCompositingKernel
dynamismMapKernel
longExposureFusionKernels
dynamismMapRefineKernel
rgbToLumaKernel
homographyKernel
nccKernel
nccCoarseKernel
blur7x7Kernel
blur5x5Kernel
blur3x3Kernel
fusionKernel
assetIdentifierForURL:type:useEmbeddedPreview:
imageSourceWithURL:type:useEmbeddedPreview:
imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:
imageSourceWithCIImage:orientation:
videoSourceWithURL:
livePhotoSourceWithPhotoSource:videoSource:
newComposition
newAdjustmentWithName:
newAdjustmentWithIdentifier:
newImageRenderClientWithName:
geometryRequestWithComposition:
imagePropertiesRequestWithComposition:
videoPropertiesRequestWithComposition:
imageRenderRequestWithComposition:fitInSize:wideGamut:
imageRenderRequestWithComposition:fillInSize:wideGamut:
_imageRenderRequestWithComposition:wideGamut:
newCGImageFromBufferImage:
priorityWithLevel:
videoRenderRequestWithComposition:fitInSize:wideGamut:
is3DEffect:
isPortraitEffect:
isPortraitStageEffect:
effectNameForFilterName:
filterNameForEffectName:
pipelineFiltersForCropping
pipelineFiltersForOriginalGeometry
pipelineFiltersForShowingOriginalWithGeometry
pipelineFiltersForRAWShowingOriginalWithGeometry
newCompositionControllerWithComposition:
adjustmentConstants
validatedCompositionCopyForComposition:mediaType:
knownFormatsVersionsMap
preheatEditDependencies
prepareForPerformingRequestsOfClass:error:
initWithCVPixelBuffer:options:
boolForKey:
standardUserDefaults
PIMuteAdjustmentKey
PITrimAdjustmentKey
PIPortraitAdjustmentKey
PIDepthAdjustmentKey
PIRedEyeAdjustmentKey
PIAutoLoopAdjustmentKey
_PISmartToneAdjustmentKey
_PISmartColorAdjustmentKey
_PISmartBWAdjustmentKey
_PIGrainAdjustmentKey
_PIAutoEnhanceAdjustmentKey
_PIWhiteBalanceAdjustmentKey
_PIRedEyeAdjustmentKey
_PIApertureRedEyeAdjustmentKey
_PIRetouchAdjustmentKey
_PIVignetteAdjustmentKey
_PISharpenAdjustmentKey
_PINoiseReductionAdjustmentKey
_PIDefinitionAdjustmentKey
_PICurvesAdjustmentKey
_PILevelsAdjustmentKey
_PISelectiveColorAdjustmentKey
_PIEffectAdjustmentKey
_PIEffect3DAdjustmentKey
_PICropAdjustmentKey
_PITrimAdjustmentKey
_PISlomoAdjustmentKey
_PILivePhotoKeyFrameAdjustmentKey
_PIVideoPosterFrameAdjustmentKey
_PIAutoLoopAdjustmentKey
_PIHighResFusionAdjustmentKey
_PIMuteAdjustmentKey
_PIDepthAdjustmentKey
_PIPortraitAdjustmentKey
_PIOrientationAdjustmentKey
_PIRawAdjustmentKey
_PIRawNoiseReductionAdjustmentKey
_PISourceAdjustmentKey
allAdjustmentTypes
nonVisualAdjustmentTypes
PISmartToneAdjustmentKey
PISmartColorAdjustmentKey
PISmartBWAdjustmentKey
PIGrainAdjustmentKey
PIAutoEnhanceAdjustmentKey
PIWhiteBalanceAdjustmentKey
PIApertureRedEyeAdjustmentKey
PIRetouchAdjustmentKey
PIVignetteAdjustmentKey
PISharpenAdjustmentKey
PINoiseReductionAdjustmentKey
PIDefinitionAdjustmentKey
PICurvesAdjustmentKey
PILevelsAdjustmentKey
PISelectiveColorAdjustmentKey
PIEffectAdjustmentKey
PIEffect3DAdjustmentKey
PICropAdjustmentKey
PISlomoAdjustmentKey
PILivePhotoKeyFrameAdjustmentKey
PIVideoPosterFrameAdjustmentKey
PIHighResFusionAdjustmentKey
PIOrientationAdjustmentKey
PIRawAdjustmentKey
PIRawNoiseReductionAdjustmentKey
PISourceAdjustmentKey
allValues
initWithTargetSize:
setExtentPolicy:
setResolvedSourceDefinition:
initWithImageSourceDefinition:videoSourceDefinition:
resolvedSourceDefinition
setAssetIdentifier:
assetIdentifier
initWithSourceDefinitions:
initWithURL:UTI:
initWithCIImage:orientation:
setUseEmbeddedPreview:
absoluteString
timeIntervalSinceReferenceDate
getResourceValue:forKey:error:
dictionaryWithDictionary:
addEntriesFromDictionary:
kernel
_inputBoost
inputBoost
setInputBoost:
kernelsDictionaryWithString:
kernelsWithString:
conversionMap
mapForSerialization
arrayWithArray:
base64EncodedStringWithOptions:
initWithBase64EncodedString:options:
_pixelSize
_renderer
_temporaryDestinationStorage
_averageAccumulationStorage
_minimumAccumulationStorage
_maximumAccumulationStorage
_frameCount
_stateQueue
_accumQueue
_accumSemaphore
_readySemaphore
_doneGroup
_inputFrames
_finished
_imageOptions
__accumError
initWithSize:renderer:
dealloc
workingColorSpace
cancel
start:
_initializeStorage:image:error:
isReadyForMoreData
_isReadyForMoreData
markAsFinished
_markAsFinished
waitUntilDone
accumulate:error:
_appendInputFrame:
nextInputFrame
_nextInputFrame
_start
_initializeAccumulation
_initializeAccumulation:
_accumulate:
_accumulate:error:
writeLongExposureImage:UTI:colorSpace:error:
writeMaskImage:UTI:error:
_dynamismMapWithMinImage:maxImage:extent:
_exportOutputImage:format:colorSpace:toURL:uti:error:
_accumError
set_accumError:
failureError:object:
createCGImage:fromRect:format:colorSpace:deferred:
extent
context
imageByClampingToExtent
useAsCIImageWithOptions:renderer:block:
useAsCIRenderDestinationWithRenderer:block:
renderImage:rect:toDestination:atPoint:error:
imageByApplyingFilter:withInputParameters:
componentMin
componentMax
imageWithCVPixelBuffer:options:
CVPixelBuffer
imageWithColor:
colorWithRed:green:blue:colorSpace:
canceledError:object:
sRGBLinearColorSpace
surfaceStoragePool
initWithCapacity:
observation
_observation
_extent
setObservation:
setExtent:
_stillImage
_guideExtent
wantsOutputImage
wantsRenderScaleClampedToNativeScale
registrationRequest
newRenderPipelineStateForEvaluationMode:
guideExtent
setGuideExtent:
stillImage
setStillImage:
errorWithCode:reason:object:
results
performRequests:error:
initWithTargetedCVPixelBuffer:options:
waitUntilCompletedAndReturnError:
initWithPixelBuffer:
newPixelBufferOfSize:format:
imageByCroppingToRect:
imageByColorMatchingWorkingSpaceToColorSpace:
renderScale
outputGeometry
videoProperties:
prepareNode
outputImage:
outputImageGeometry:
nodeByReplayingAgainstCache:error:
setScale:
prepareNodeWithPipelineState:error:
_shouldWaitForDependentJobs
initWithComposition:responseQueue:
_pipelineFilters
initWithComposition:tag:responseQueue:
_inputDestinationImage
_inputCorrectionInfo
_inputCameraModel
inputDestinationImage
setInputDestinationImage:
inputCorrectionInfo
setInputCorrectionInfo:
inputCameraModel
setInputCameraModel:
imageByCompositingOverImage:
posterFrameTime
setPosterFrameTime:
locallySupportedFormatVersions
currentFormatVersion
_versionRules
versionRules
formatVersionForAdjustment:identifier:
adjustmentDataFormatVersionForComposition:
indexOfObject:
captureDebugDirectoryForComposition:
URLByAppendingPathComponent:isDirectory:
fileURLWithPath:
stringByDeletingPathExtension
lastPathComponent
firstObject
sourceDefinitions
startTime
setStartTime:
endTime
setEndTime:
rate
setRate:
rateKey
endScaleKey
endKey
startScaleKey
startKey
bytesPerPixel
initWithSize:format:
mutableBytesAtPoint:
RG16
faceBalanceKernels
linearWideGamutColorSpace
_inputOrigI
_inputOrigQ
_inputStrength
_inputWarmth
inputOrigI
setInputOrigI:
inputOrigQ
setInputOrigQ:
inputStrength
setInputStrength:
inputWarmth
setInputWarmth:
imageByColorMatchingColorSpaceToWorkingSpace:
_inputPointsR
_inputPointsG
_inputPointsB
_inputPointsL
inputPointsR
setInputPointsR:
inputPointsG
setInputPointsG:
inputPointsB
setInputPointsB:
inputPointsL
setInputPointsL:
tableImageFromRed:green:blue:luminance:
calculateCurveTable:
curvePointsFromDictionaries:
initWithImageProvider:width:height:format:colorSpace:options:
initWithLength:
_inputTableImage
inputTableImage
setInputTableImage:
curvesKernel
colorBalanceKernels
gHDRtoPPKernel
PPtogHDRKernel
colorBalanceKernel
_inputWarmTemp
_inputWarmTint
_inputHasFace
_inputIsRaw
applyInputConversion:
applyOutputConversion:
inputWarmTemp
setInputWarmTemp:
inputWarmTint
setInputWarmTint:
inputHasFace
setInputHasFace:
inputIsRaw
setInputIsRaw:
alignment
setAlignment:
alignmentKey
_settings
decoratorRenderFiltersForImages
decoratorRenderFiltersForVideos
globalSettings
initWithAutoLoopExportRequest:
initWithVideoExportRequest:
autoLoopExportRequest
renderer
metalRenderer
shouldUseMetalRenderer
initWithMetalDevice:options:
boolSettingForKey:defaultValue:
setUpContext:
URLForResource:withExtension:
bundleForClass:
newPhotosPipelineAtSourceURL:error:
initWithURL:
newPhotosPipeline:
_value
_point
initWithCGPoint:value:
distanceFromPoint:
isEqualToPoint:
point
value
allocWithZone:
_faceRequest
apertureRedEyeResultFromFaceObservations:imageSize:
normalizedPoints
pointCount
rightEye
leftEye
landmarks
cancelAllRequests
renderContext
elementByteSize
rowElements
format
bufferColorspace
initWithBytes:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithData:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
bytes
image
dataWithBytesNoCopy:length:freeWhenDone:
_calculateBlackAndWhiteSettingsFromBufferImage:
initWithTargetPixelSize:
CIFormat
hasCorrections
inputCorrectionInfoKey
calculateSettingsForImageHistogram:
calculateSettingsForSingleChannelHistogram:suffix:
percentile:
histogram
luminance
blue
green
_creationDate
_creationTimeZone
_caption
_title
_keywords
_peopleNames
_location
setCreationDate:timeZone:
title
setTitle:
caption
setCaption:
keywords
setKeywords:
peopleNames
setPeopleNames:
location
setLocation:
creationDate
creationTimeZone
combinedKeywordsAndPeople
setCreationDate:
setCreationTimeZone:
defaultTimeZone
_iptcMutableDictionary
_updateCreationDate
iptcDictionary
iptcMutableDictionary
setIptcMutableDictionary:
stringFromDate:
setTimeZone:
iptcTimeFormatter
iptcDateFormatter
_dateFormatterTemplate
_gpsTimeFormatter
_gpsDateFormatter
gpsDictionaryForLocation:
course
speed
horizontalAccuracy
altitude
verticalAccuracy
timestamp
coordinate
setDateFormat:
timeZoneForSecondsFromGMT:
setCalendar:
calendarWithIdentifier:
setLocale:
localeWithLocaleIdentifier:
setFormatOptions:
commonItemForKey:string:
titleItem
captionItem
locationItem
creationDateItem
videoDateFormatter
keywordsItem
metadataItems
setKey:
setKeySpace:
iso6709Notation
xmpCreateDateFormatter
xmpData
autoLoopAdjustmentController
highResFusionAdjustmentController
rawNoiseReductionAdjustmentController
sharpenAdjustmentController
whiteBalanceAdjustmentController
noiseReductionAdjustmentController
definitionAdjustmentController
vignetteAdjustmentController
smartToneAdjustmentControllerCreatingIfNecessary:
_adjustmentControllerForKey:creatingIfNecessary:expectedClass:
smartColorAdjustmentControllerCreatingIfNecessary:
smartBWAdjustmentControllerCreatingIfNecessary:
cropAdjustmentControllerCreatingIfNecessary:
redEyeAdjustmentControllerCreatingIfNecessary:
livePhotoKeyFrameAdjustmentControllerCreatingIfNecessary:
videoPosterFrameAdjustmentControllerCreatingIfNecessary:
depthAdjustmentControllerCreatingIfNecessary:
trimAdjustmentControllerCreatingIfNecessary:
slomoAdjustmentControllerCreatingIfNecessary:
effectAdjustmentControllerCreatingIfNecessary:
effect3DAdjustmentControllerCreatingIfNecessary:
portraitAdjustmentControllerCreatingIfNecessary:
orientationAdjustmentControllerCreatingIfNecessary:
autoLoopAdjustmentControllerCreatingIfNecessary:
highResFusionAdjustmentControllerCreatingIfNecessary:
rawNoiseReductionAdjustmentControllerCreatingIfNecessary:
sharpenAdjustmentControllerCreatingIfNecessary:
whiteBalanceAdjustmentControllerCreatingIfNecessary:
noiseReductionAdjustmentControllerCreatingIfNecessary:
definitionAdjustmentControllerCreatingIfNecessary:
vignetteAdjustmentControllerCreatingIfNecessary:
smartToneAdjustmentController
smartColorAdjustmentController
smartBWAdjustmentController
cropAdjustmentController
redEyeAdjustmentController
livePhotoKeyFrameAdjustmentController
videoPosterFrameAdjustmentController
depthAdjustmentController
trimAdjustmentController
slomoAdjustmentController
effectAdjustmentController
effect3DAdjustmentController
portraitAdjustmentController
orientationAdjustmentController
_editable
initWithX:y:editable:
initWithDictionary:
dictionaryRepresentation
isEditable
_inputStillImage
_inputMaskImage
_inputRenderScale
_inputVideoScale
_inputAlignmentExtent
_inputAlignmentTransform
alignImage:transform:extent:
_computeNCCMapFromImage:toImage:scale:
_refineMaskImage:guideImage:scale:
_fuseImage:withGuideImage:weightImage:maskImage:
inputStillImage
setInputStillImage:
inputMaskImage
setInputMaskImage:
inputRenderScale
setInputRenderScale:
inputVideoScale
setInputVideoScale:
inputAlignmentExtent
setInputAlignmentExtent:
inputAlignmentTransform
setInputAlignmentTransform:
imageByApplyingTransform:highQualityDownsample:
applyWithExtent:roiCallback:inputImage:arguments:
writeToTIFF:
currentDirectoryPath
debugDumpIntermediateImages
valueAtIndex:
CGRectValue
loadFusionTuningParameters
_debugDumpIntermediateImages
dictionaryWithContentsOfFile:
stringSettingForKey:defaultValue:
P3Kernel
defaultValueForKey:
_customAttributesForKey:
_inputBlackSrcRGB
_inputBlackDstRGB
_inputShadowSrcRGB
_inputShadowDstRGB
_inputMidSrcRGB
_inputMidDstRGB
_inputHilightSrcRGB
_inputHilightDstRGB
_inputWhiteSrcRGB
_inputWhiteDstRGB
_inputBlackSrcRed
_inputBlackDstRed
_inputShadowSrcRed
_inputShadowDstRed
_inputMidSrcRed
_inputMidDstRed
_inputHilightSrcRed
_inputHilightDstRed
_inputWhiteSrcRed
_inputWhiteDstRed
_inputBlackSrcGreen
_inputBlackDstGreen
_inputShadowSrcGreen
_inputShadowDstGreen
_inputMidSrcGreen
_inputMidDstGreen
_inputHilightSrcGreen
_inputHilightDstGreen
_inputWhiteSrcGreen
_inputWhiteDstGreen
_inputBlackSrcBlue
_inputBlackDstBlue
_inputShadowSrcBlue
_inputShadowDstBlue
_inputMidSrcBlue
_inputMidDstBlue
_inputHilightSrcBlue
_inputHilightDstBlue
_inputWhiteSrcBlue
_inputWhiteDstBlue
_inputColorSpace
setDefaults
floatValueForKey:defaultValue:clearIfNotDefault:
_LUTImage
inputBlackSrcRGB
setInputBlackSrcRGB:
inputBlackDstRGB
setInputBlackDstRGB:
inputShadowSrcRGB
setInputShadowSrcRGB:
inputShadowDstRGB
setInputShadowDstRGB:
inputMidSrcRGB
setInputMidSrcRGB:
inputMidDstRGB
setInputMidDstRGB:
inputHilightSrcRGB
setInputHilightSrcRGB:
inputHilightDstRGB
setInputHilightDstRGB:
inputWhiteSrcRGB
setInputWhiteSrcRGB:
inputWhiteDstRGB
setInputWhiteDstRGB:
inputBlackSrcRed
setInputBlackSrcRed:
inputBlackDstRed
setInputBlackDstRed:
inputShadowSrcRed
setInputShadowSrcRed:
inputShadowDstRed
setInputShadowDstRed:
inputMidSrcRed
setInputMidSrcRed:
inputMidDstRed
setInputMidDstRed:
inputHilightSrcRed
setInputHilightSrcRed:
inputHilightDstRed
setInputHilightDstRed:
inputWhiteSrcRed
setInputWhiteSrcRed:
inputWhiteDstRed
setInputWhiteDstRed:
inputBlackSrcGreen
setInputBlackSrcGreen:
inputBlackDstGreen
setInputBlackDstGreen:
inputShadowSrcGreen
setInputShadowSrcGreen:
inputShadowDstGreen
setInputShadowDstGreen:
inputMidSrcGreen
setInputMidSrcGreen:
inputMidDstGreen
setInputMidDstGreen:
inputHilightSrcGreen
setInputHilightSrcGreen:
inputHilightDstGreen
setInputHilightDstGreen:
inputWhiteSrcGreen
setInputWhiteSrcGreen:
inputWhiteDstGreen
setInputWhiteDstGreen:
inputBlackSrcBlue
setInputBlackSrcBlue:
inputBlackDstBlue
setInputBlackDstBlue:
inputShadowSrcBlue
setInputShadowSrcBlue:
inputShadowDstBlue
setInputShadowDstBlue:
inputMidSrcBlue
setInputMidSrcBlue:
inputMidDstBlue
setInputMidDstBlue:
inputHilightSrcBlue
setInputHilightSrcBlue:
inputHilightDstBlue
setInputHilightDstBlue:
inputWhiteSrcBlue
setInputWhiteSrcBlue:
inputWhiteDstBlue
setInputWhiteDstBlue:
inputColorSpace
setInputColorSpace:
applyWithExtent:roiCallback:arguments:options:
displayP3LinearColorSpace
samplerWithImage:keysAndValues:
rawSchema
rawNoiseReductionSchema
smartToneSchema
smartColorSchema
smartBlackAndWhiteSchema
grainSchema
sharpenSchema
cropSchema
trimSchema
slomoSchema
livePhotoKeyFrameSchema
muteSchema
videoPosterFrameSchema
autoLoopSchema
highResFusionSchema
depthEffectSchema
effect3DSchema
portraitEffectSchema
effectSchema
redEyeSchema
apertureRedEyeSchema
retouchSchema
vignetteSchema
orientationSchema
definitionSchema
noiseReductionSchema
whiteBalanceSchema
levelsSchema
curvesSchema
selectiveColorSchema
photosCompositionSchema
registeredPhotosSchemaIdentifier
registerPhotosSchema
registerRenderPipeline:forIdentifier:
registerSchemas:error:
renderPipelineForIdentifier:
deserializeFromDictionary:error:
numberWithLong:
_finalizerError
performHorizonCorrectionWithCompletion:
performPerspectiveCorrectionWithCompletion:
finalizerError
setFinalizerError:
initWithDisposition:composition:
_disposition
disposition
_shouldPerformAutoCrop
_shouldPerformAutoStraighten
_maxAutoStraighten
imageProperties:
undoExifOrientation:error:
shouldPerformAutoCrop
setShouldPerformAutoCrop:
shouldPerformAutoStraighten
setShouldPerformAutoStraighten:
maxAutoStraighten
setMaxAutoStraighten:
_stats
_updateSettingsWithInputColor:
setInputColor:
inputColor
setInputSaturation:
inputSaturation
setInputCast:
inputCast
setOffsetCast:
offsetCast
setOffsetSaturation:
offsetSaturation
offsetSaturationKey
offsetCastKey
inputCastKey
inputSaturationKey
inputColorKey
attributeVibrancyKey
attributeCastKey
_inputCorrections
hueSatLumTable
inputCorrections
setInputCorrections:
convertFromIPT:
selectiveColorKernels
convertToIPT:
iptHueAngleFromRed:green:blue:
colorWithRed:green:blue:alpha:colorSpace:
iptFromLinearInto:fromRed:green:blue:
hueAngleFrom:
RGBToYIQKernel
YIQToRGBKernel
whiteBalanceKernel
_strength
_warmth
isDefaultWarmth:
warmth
setWarmth:
setY:
setI:
setQ:
vectorWithX:
setDataExtractor:
submitSynchronous:
_options
initWithRequest:options:
_touchDiameter
initWithComposition:location:touchDiameter:
writeImage:fileURL:
writeCGImage:fileURL:
writeCGImage:fileURL:options:
writeImage:toTemporaryDirectoryWithBasename:
writeImage:toDirectoryAtPath:withBasename:
stringByAppendingPathComponent:
path
pathExtension
buildNumber
currentSoftwareVersion
edgesKey
ROIForCenterPoint:radius:
convertFloat:toFixed16:count:
convertFixed16:toFloat:count:
processWithInputs:arguments:output:error:
roiForInput:arguments:outputRect:
formatForInputAtIndex:
outputFormat
copyPixelsFromImage:srcRect:destImage:destOrigin:
initWithMutableBuffer:colorSpace:validRegion:
initWithBuffer:colorSpace:validRegion:
initWithSize:format:rowBytes:bytes:
initWithSize:format:rowBytes:mutableBytes:
RGBA16
region
bytesPerRow
baseAddress
inputSpots
applyWithExtent:inputs:arguments:error:
vectorWithCGRect:
pointValue
_aperture
_portraitStrength
_minimumAperture
_maximumAperture
_portraitMajorVersion
_portraitMinorVersion
_versionInfo
aperture
setAperture:
portraitStrength
setPortraitStrength:
minimumAperture
setMinimumAperture:
maximumAperture
setMaximumAperture:
portraitMajorVersion
setPortraitMajorVersion:
portraitMinorVersion
setPortraitMinorVersion:
versionInfo
setVersionInfo:
valuesAtCaptureFromImageProperties:error:
depthBlurEffectSimulatedAperture
depthBlurEffectRenderingParameters
auxiliaryCoreGraphicsInfoDictionary:
cameraCalibrationData
depthDataQuality
isDepthDataFiltered
underlyingAVDepthData
auxiliaryImage:
unsignedIntValue
_calculateWithImageProperties:valuesAtCapture:completion:
portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
isStillImageDisparity:
focusRectDictionaryFromMetadata:
focusRectDictionaryFromRect:
canApplyPortraitEffectsWithMetadata:
depthEffectInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:
portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:
portraitInfoDictionaryFromCameraMetadata:
luminanceNoiseAmplitude
apertureFocalRatio
maximumApertureFocalRatio
minimumApertureFocalRatio
focusRectangle
faceOrientation
objectsAtIndexes:
indexesOfShallowDepthOfFieldObservations
unarchivedObjectOfClasses:fromData:error:
faceObservationsData
roll
faceOrientationIndex
faceJunkinessIndex
allPoints
nose
autoCropFilter
exifOrientationAndCropStraightenOnly
rawFaceBalanceFilter
rawSourceFilterIncludingOrientation
sourceFilterNoOrientation
sushiLevel1Filter
noRedEyeFilter
noTrimFilter
noMuteFilter
noCropFilter
iosCropToolFilter
stripAllTimeAdjustmentsFilter
noGeometryFilter
perspectiveStraightenWithoutCropFilter
preGeometryFilter
postGeometryFilter
stopAtTagIncludeGeometryFilter:
stopAtTagIncludeOrientationFilter:
applyOrientationFilter
autoloopStabilizedVideoFilter
colorType
setColorType:
faceStrength
setFaceStrength:
faceWarmth
setFaceWarmth:
faceI
setFaceI:
faceQ
setFaceQ:
grayStrength
setGrayStrength:
grayWarmth
setGrayWarmth:
grayY
setGrayY:
grayI
setGrayI:
grayQ
setGrayQ:
warmTemp
setWarmTemp:
warmTint
setWarmTint:
warmFace
setWarmFace:
warmFaceKey
warmTintKey
warmTempKey
tintKey
temperatureKey
grayQKey
grayIKey
grayYKey
grayWarmthKey
grayStrengthKey
faceQKey
faceIKey
faceWarmthKey
faceStrengthKey
colorTypeKey
stringForColorType:
colorTypeForString:
canRenderDepth
setDepthInfo:
depthInfo
capturedAperture
depthInfoKey
apertureKey
initWithExtent:renderScale:orientation:
indexOfObject:inSortedRange:options:usingComparator:
uniqueInputNode
lastObject
dictionariesFromPoints:
_defaultCurveArray
autoValuesForBlackPoint:whitePoint:
replaceObjectAtIndex:withObject:
computeCurvesForImageHistogram:
setParameters:
setColorMatrix:
curvePointAtIndex:blackPoint:whitePoint:histogram:
insertObject:atIndex:
@"NUComposition"
{?="hasDidAdd"B"hasDidRemove"B"hasDidModify"B"hasDidModifyMultiple"B"hasClassForController"B}
@"NSDictionary"
@"<PICompositionControllerDelegate>"
@24@0:8^{_NSZone=}16
@24@0:8@16
@16@0:8
v24@0:8@16
v32@0:8@16@24
v32@0:8@16@?24
B28@0:8@16B24
B36@0:8@16@24B32
B40@0:8@16@24@?32
q16@0:8
#24@0:8@16
v32@0:8@16q24
v16@0:8
v24@0:8q16
@32@0:8@16@24
v20@0:8B16
B32@0:8@16@24
@48@0:8@16@24@32o^@40
B32@0:8@16o^@24
@56@0:8@16@24@32@40o^@48
@40@0:8@16@24o^@32
B48@0:8@16@24@32o^@40
@32@0:8@16o^@24
@"NSData"
@"NSString"
{CGPoint=dd}72@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32q64
{CGPoint=dd}32@0:8r^{CGPoint=dd}16Q24
@"NSURL"
@56@0:8@16@24@32@40@48
v24@0:8@?16
{?="origin"{?="x"q"y"q}"size"{?="width"q"height"q}}
{?={?=qq}{?=qq}}16@0:8
v48@0:8{?={?=qq}{?=qq}}16
v20@0:8i16
i16@0:8
Q16@0:8
v24@0:8Q16
@?16@0:8
B16@0:8
@40@0:8@16@24^@32
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
d16@0:8
v24@0:8d16
@"NSMutableDictionary"
@"NUIdentifier"
@"NUAdjustment"
B24@0:8@16
v40@0:8@16@24d32
{?=qiIq}32@0:8@16@24
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_queue>"
@"<NUFaceDetectionResult>"
@"CIImage"
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8@"Protocol"16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
@"NSString"16@0:8
@"<NURenderStatistics>"16@0:8
@"NSDictionary"16@0:8
@"AVAsset"
B24@0:8o^@16
@28@0:8@16B24
{?={?=qq}{?=qq}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?={?=qq}{?=qq}}48d80d88
{?=ddd}56@0:8@16{?={?=qq}{?=qq}}24
@"NUBufferRenderClient"
@"NUImageDataClient"
{?={?=[4d]}{?=[4d]}d}48@0:8@16@24d32@40
B48@0:8{?=[4d]}16
{?=[4d]}48@0:8{?=[4d]}16
{?=[4d]}88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=dd}104@0:8{?={?=[4d]}{?=[4d]}d}16@88d96
{?={?=[4d]}{?=[4d]}d}16@0:8
@88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=[4d]}16@0:8
@48@0:8{?=[4d]}16
@"NSNumber"
@"NUImageExportRequest"
{?="width"q"height"q}
{?=qq}16@0:8
v32@0:8{?=qq}16
@"NUImageGeometry"
@"NUPriority"
@"NUColorSpace"
@"<NUScalePolicy>"
@"NUImageExportFormat"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
@48@0:8@16@24@32@?40
@64@0:8@16@24@32@40@48@?56
@48@0:8@16@24@32^@40
v64@0:8@16@24@32@40@48@?56
@"NSArray"
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@48@0:8@16@24@32@40
@40@0:8Q16Q24@32
@32@0:8Q16Q24
q24@0:8@16
@"PIFaceObservationCache"
@"VNSaliencyImageObservation"
@"PIFaceObservationCache"16@0:8
v24@0:8@"PIFaceObservationCache"16
v36@0:8@16@24B32
f24@0:8@16
B32@0:8{?=qq}16
B40@0:8@16{?=qq}24
@24@0:8o^@16
v48@0:8q16^d24^d32^d40
B32@0:8{CGSize=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{?="exposure"d"contrast"d"brightness"d"shadows"d"highlights"d"black"d"rawHighlights"d"localLight"d}
@36@0:8@16@24B32
@52@0:8@16@24@32q40B48
@32@0:8@16q24
@44@0:8@16{CGSize=dd}24B40
^{CGImage=}24@0:8@16
@24@0:8q16
@"<NURenderer>"
@"<NUSurfaceStorage>"
@"NSObject<OS_dispatch_semaphore>"
@"NSMutableArray"
@"NSError"
@40@0:8{?=qq}16@32
B40@0:8@16@24o^@32
@64@0:8@16@24{?={?=qq}{?=qq}}32
B60@0:8@16i24^{CGColorSpace=}28@36@44o^@52
@"VNImageHomographicAlignmentObservation"16@0:8
@"VNImageHomographicAlignmentObservation"
^{CGColorSpace=}16@0:8
{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}24@0:8@16
@48@0:8r^f16r^f24r^f32r^f40
{CGPoint="x"d"y"d}
@40@0:8{CGPoint=dd}16d32
d32@0:8{CGPoint=dd}16
{CGPoint=dd}16@0:8
@"NUFaceDetectionRequest"
@40@0:8@16{?=qq}24
^{CGColorSpace=}
@"NSMutableData"
@68@0:8^v16Q24Q32q40Q48i56^{CGColorSpace=}60
@68@0:8@16Q24Q32q40Q48i56^{CGColorSpace=}60
^v16@0:8
@"NSDate"
@"NSTimeZone"
@"CLLocation"
v32@0:8@"NSDate"16@"NSTimeZone"24
v24@0:8@"NSString"16
@"NSArray"16@0:8
v24@0:8@"NSArray"16
@"CLLocation"16@0:8
v24@0:8@"CLLocation"16
@"NSDate"16@0:8
@"NSTimeZone"16@0:8
@36@0:8@16B24#28
@20@0:8B16
@36@0:8d16d24B32
@"CIVector"
@104@0:8@16{?=[3]}24{CGRect={CGPoint=dd}{CGSize=dd}}72
@40@0:8@16@24d32
d40@0:8@16d24^B32
@32@0:8q16@24
B32@0:8^{?={?=qq}{?=qq}}16o^@24
{?="p75"d"p98"d"autoValue"d"g98"d}
{?="sat"d"contrast"d"cast"d}
v36@0:8^f16f24f28f32
f24@0:8r^f16
d40@0:8d16d24d32
B24@0:8d16
@48@0:8@16{CGPoint=dd}24d40
B32@0:8^{CGImage=}16@24
B40@0:8^{CGImage=}16@24@32
@40@0:8@16@24@32
{?={?=qq}{?=qq}}40@0:8{CGPoint=dd}16d32
v40@0:8r^f16^S24Q32
v40@0:8r^S16^f24Q32
B48@0:8@16@24@32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
{?="major"i"minor"i}
f16@0:8
v20@0:8f16
{?=ii}16@0:8
v24@0:8{?=ii}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@48@0:8@16@24q32@40
@52@0:8@16@24@32f40q44
@40@0:8@16q24@32
@32@0:8d16d24
{CGPoint=dd}44@0:8i16d20d28@36
