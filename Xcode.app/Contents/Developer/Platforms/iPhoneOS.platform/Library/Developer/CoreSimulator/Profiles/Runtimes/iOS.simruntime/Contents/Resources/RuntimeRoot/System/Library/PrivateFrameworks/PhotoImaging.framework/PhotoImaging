 @333333
VUUUUU
?YAH
?ffffff
@<,_
@ffffff
?UUUUUU
ffffff
?ffffff
MbP?+
v@UUUUUU
?333333
?ffffff
?333333
0@hfffff
333333
VUUUUU
?VUUUUU
?YAH
?YAH
pCh?
?UUUUUU
UUUUUU
UUUUUU
?UUUUUU
zt?{
UUUUUU
?UUUUUU
Mbp?
?333333
Mb@?
UUU?
?~0d>
@(#)PROGRAM:PhotoImaging  PROJECT:Neutrino-3642.28.150
N6VRF_V111SessionImplE
N6VRF_V17SessionE
NSt3__114default_deleteIN6VRF_V111SessionImplEEE
NSt3__120__shared_ptr_pointerIPN6VRF_V111SessionImplENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
0Xr
?g|_\
12VRFTrackImpl
8VRFTrack
NSt3__114default_deleteI8VRFTrackEE
NSt3__120__shared_ptr_pointerIP8VRFTrackNS_14default_deleteIS1_EENS_9allocatorIS1_EEEE
N6VRF_V211SessionImplE
N6VRF_V27SessionE
NSt3__114default_deleteIN6VRF_V211SessionImplEEE
NSt3__120__shared_ptr_pointerIPN6VRF_V211SessionImplENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
#?6t>=
333333
?333333
?ffffff
14VRFSessionBase
10VRFSession
isCandidateForReframe
TB,R
isCandidateForPerspective
isCandidateForHorizon
facts.candidateForVideo == true
facts.candidateForStill == true
state.hasAdjustments == true
state.reframingAllowed == false
state.pano == true
state.video == true AND state.livePhoto == true
state.deviceIsStationary == true
v16@?0@"NURuleSystem"8
state.backFacing == false
state.largeSubject == true
facts.isStitched == true AND facts.hasHorizonLine == true
facts.isStitched == true AND facts.hasBuilding == true
facts.isStitched == true AND facts.validSubjects == true
(state.videoDuration * $VideoDurationBelowMinZoomRatio) < state.videoDurationBelowMinZoom
state.videoQualityScore < $VideoQualityScoreThreshold
(state.videoDuration * $VideoDurationWithSubjectsRatio) > state.videoDurationWithSubjects
state.videoDuration > $VideoDurationUpperBound
state.videoDuration < $VideoDurationLowerBound
state.video == true
state.horizonLineAngleInDegrees > -$HorizonAngleInDegreesMinThreshold AND state.horizonLineAngleInDegrees < $HorizonAngleInDegreesMinThreshold
state.horizonLineAngleInDegrees < -$HorizonAngleInDegreesMaxThreshold OR state.horizonLineAngleInDegrees > $HorizonAngleInDegreesMaxThreshold
hasHorizonLine
state.horizonLinePresent == true
state.largestSubjectArea <= $MinimumSubjectSize
state.largeSubjectFace == true
(state.subjectCount - state.intersectingSubjectCount) > $MaxDisparateSubjects
state.allSubjectsInsidePrimaryBounds == true
validSubjects
state.subjectCount >= $SubjectCountMinThreshold
state.buildingConfidence > $BuildingConfidenceThreshold
hasBuilding
state.buildingCount > 0
state.stitchConfidence < $StitchConfidenceThreshold
isStitched
state.stitched == true OR state.perfectlyStitched == true
addRule exception : %@
v24@?0@"NSString"8@"NSString"16
v24@?0@"NSString"8@?<v@?@"NURuleSystem">16
candidateForHorizon
candidateForPerspective
candidateForReframe
candidateForVideo
candidateForStill
mutablePoints
T@"NSMutableSet",R,C,N,V_mutablePoints
saliencyScale
Tf,R,N,V_saliencyScale
salientObject
TB,R,N,GisSalientObject,V_salientObject
body
T@"PIReframeSubject",R,N,V_body
direction
TQ,R,N,V_direction
centerPoint
T{CGPoint=dd},R,N,V_centerPoint
boundingBox
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
points
T@"NSSet",R,C,N
expandedSubject
T@"PIReframeSubject",R,N
<%@ %p centerPoint=(%f, %f) points=%@>
smartTone
smartColor
smartBlackAndWhite
autoEnhance
whiteBalance
cropStraighten
redEye
apertureRedEye
depthEffect
livePhotoKeyFrame
videoPosterFrame
trim
slomo
portraitEffect
autoLoop
highResFusion
retouch
vignette
sharpen
noiseReduction
definition
curves
levels
selectiveColor
effect
effect3D
mute
rawNoiseReduction
videoReframe
sourceSelect
sourceSpatialOvercapture
composition
T@"NUComposition",R,C,N
changeDelegate
T@"<PICompositionControllerDelegate>",W,N,V_changeDelegate
mediaType
Tq,N,V_mediaType
imageOrientation
Tq,N,V_imageOrientation
sourceSelection
Tq,N
v16@?0@"PISmartToneAdjustmentController"8
PICompositionController(0x%X): %@
primary
com.apple.photo
+[PICompositionSerializer _sanitizeComposition:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Controllers/Conversion/PICompositionSerializer.m
Adjustment for %@ is identity
PICompositionSerializer
exception
dictionary
v32@?0@"NSString"8#16^B24
Value for key %@ has type %@; expected type %@
PICompositionSerializerDomain
Missing required key: %@
masterWidth
masterHeight
adjustments
metadata
+[PICompositionSerializer serializeComposition:versionInfo:serializerMetadata:error:]
data
T@"NSData",&,N,V_data
formatIdentifier
T@"NSString",&,N,V_formatIdentifier
formatVersion
T@"NSString",&,N,V_formatVersion
Serialization map does not contain identifierName
auto
current
omitIfDisabled
Serialization map has no entry for %@
Missing identifierName
Invalid parameter not satisfying: %@
<Unknown File>
width
Tq,N,V_width
height
Tq,N,V_height
orientation
Tq,N,V_orientation
Orientation
nil identifierName
Unsupported adjustment: 
Missing definition in conversion map for the adjustment key: 
dummy
file://dummy.jpg
denistyThreshold
TQ,N,V_denistyThreshold
neighborhoodOffset
Tq,N,V_neighborhoodOffset
saliencyThreshold
Td,N,V_saliencyThreshold
saliencyDeltaThreshold
Td,N,V_saliencyDeltaThreshold
initialSaliencyValue
Td,N,V_initialSaliencyValue
useRegressedSaliencyBoxes
TB,N,V_useRegressedSaliencyBoxes
unionIOUThreshold
Td,N,V_unionIOUThreshold
clusterToRegressedRatio
Td,N,V_clusterToRegressedRatio
regressedConfidenceThreshold
Td,N,V_regressedConfidenceThreshold
highSaliencyThreshold
Td,N,V_highSaliencyThreshold
interSalientObjectDistance
Tq,N,V_interSalientObjectDistance
maxSalientObjectsCount
TQ,N,V_maxSalientObjectsCount
salientClusterConvergenceMaxDistance
Td,N,V_salientClusterConvergenceMaxDistance
defaultConfiguration
T@"PIExpandedSubjectCalculatorConfiguration",R,N
saliencyRevisionOneConfiguration
regressedSalientSubjects
T@"NSArray",R,C,N,V_regressedSalientSubjects
TQ,R,N
configuration
T@"PIExpandedSubjectCalculatorConfiguration",R,N,V_configuration
detectedSubjects
T@"NSArray",R,C,N,V_detectedSubjects
saliencyData
T@"NSArray",R,C,N,V_saliencyData
expandedSubjects
T@"NSArray",R,C,N,V_expandedSubjects
subjectDirection
TQ,N,V_subjectDirection
saliencyImageObservation
T@"VNSaliencyImageObservation",R,N,V_saliencyImageObservation
/var/tmp/saliency-%f.jpeg
saveSaliencyHeatmap
getTrackDominance
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/VRFSessionV1.mm
getViewRect
reframeSegment
getCamerawork
reframeKeyframe
sceneSegment
expandSubjectsInKeyframe
subjectExpander
Keyframes - Postprocessed
keyframe: time: %.4f compositionScore: %.4f outOfViewScore: %.4f
Global Keyframes - NLMS
Global Keyframes - Consolidated
Global Keyframes - Deadzone
getCompositionAnchor
getCompositionScore
Reframe Segments - Final
segment [ %.4f : %.4f ] reframe = %s {
  subjects: { 
%ld 
Reframe Segments - Coalesced
propagateReframeSegments
Reframe Segments - Propogated
Reframe Segments - Subdivided
createSceneSegments
cameraMotionMarkers.size()
subjectGroupMarkers.size()
Scene Segments
segment [ %.4f : %.4f ] {
  avgCameraMotion: <%.4f, %.4f>
camera motion segment marker: %.4f avgCameraMotion: <%.4f, %.4f>
subject group segment marker: %.4f 
subjects: { 
/tmp/CameraMotionSamples.txt
%.4f, %.4f, %.4f
/tmp/CameraMotionSamplesSmoothed.txt
/tmp/CameraMotionBins.txt
%.4f, %u
/tmp/CameraMotionBinsSmoothed.txt
scalePolicy
T@"<NUScalePolicy>",&,N,V_scalePolicy
stillReframeRequest
T@"PIStillReframeRequest",R,N
reframeResult
T@"PIReframeResult",&,N,V_reframeResult
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
confidence
Td,N,V_confidence
saliencyObservation
T@"VNSaliencyImageObservation",&,N,V_saliencyObservation
ANODSubjects
T@"NSArray",C,N,V_ANODSubjects
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
statistics
T@"<NURenderStatistics>",R
Td,R,N
T@"VNSaliencyImageObservation",R,N
T@"NSArray",R,C,N
-[PIStillReframeJob render:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIStillReframeRequest.m
ReframeEvaluation.DBG
forceStillReframeResult
Invalid parameter not satisfying: %s
-[PIStillReframeJob initWithRequest:]
Initializer not available: -[%@ %@], use designated initializer instead.
 Scale Policy: %@
destinationUTI
T@"NSString",R,V_destinationUTI
destinationLongExposureURL
T@"NSURL",R,V_destinationLongExposureURL
destinationMaskURL
T@"NSURL",R,V_destinationMaskURL
outputColorSpace
T@"NUColorSpace",R
-[PIAutoLoopExportRequest initWithComposition:destinationURL:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/AutoLoop/PIAutoLoopRequests.m
-[PIAutoLoopExportRequest initWithRequest:]
flavor
Tq,N,V_flavor
recipe
T@"NSDictionary",C,N,V_recipe
cleanAperture
T{?={?=qq}{?=qq}},N,V_cleanAperture
PIZlibErrorDomain
compressionLevel
Ti,N,V_compressionLevel
strategy
Ti,N,V_strategy
windowBits
Ti,N,V_windowBits
memoryLevel
Ti,N,V_memoryLevel
chunkSize
TQ,N,V_chunkSize
-[PIZlibDataCompressionOptions setCompressionStrategy:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Util/PIZLibDataCompression.m
unknown strategy %d
-[PIZlibDataCompressionOptions setCompressionLevel:]
unknown level %d
createBuffer
T@?,C,N,V_createBuffer
growData
T@?,C,N,V_growData
decompressAllAtOnce
TB,N,V_decompressAllAtOnce
growData != nil
-[PIZlibDataDecompressionOptions setGrowData:]
createBuffer != nil
-[PIZlibDataDecompressionOptions setCreateBuffer:]
v24@?0@"NSData"8@"NSMutableData"16
@"NSMutableData"16@?0@"NSData"8
+[PIZlibDataCompression decompressData:options:error:]
1.2.11
English Error String - Not Localized
%@ %@
zlib-error: 
%@ %@ %s
Z_ERRNO
Z_STREAM_ERROR
Z_DATA_ERROR
Z_MEM_ERROR
Z_BUF_ERROR
Z_VERSION_ERROR
unknown error
should be < 4GB, so casts from NSUInteger to uInt below will not be invalid
+[PIZlibDataCompression compressData:options:error:]
non-instantiable class, use the class methods!
T@"NSDictionary",C,N
T@"NSString",C,N
stabilizedCropRect
Height
Width
NormStabilizeInstructions
keyFrameTime
T{?=qiIq},N
scale
intensity
Td,N
radius
falloff
intensityKey
T@"NSString",R,N
radiusKey
falloffKey
settings
T@"NSDictionary",R,N
enabled
TB,N
identifier
T@"NUIdentifier",&,N,V_identifier
displayName
adjustment
T@"NUAdjustment",R,N,V_adjustment
inputKeys
T@"NSArray",R,N
displayInputKeys
canBeEnabled
TB,R,N
-[PIAdjustmentController setIsAuto:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Controllers/PIAdjustmentController.m
Adjustment does not have an auto setting
-[PIAdjustmentController isAuto]
-[PIAdjustmentController setEnabled:]
Adjustment does not have an enabled setting
-[PIAdjustmentController enabled]
-[PIAdjustmentController inputKeys]
Adjustment empty
-[PIAdjustmentController displayName]
PIReframeAutoCalculatorConfidenceKey
PIReframeAutoCalculatorXOriginKey
PIReframeAutoCalculatorYOriginKey
PIReframeAutoCalculatorWidthKey
PIReframeAutoCalculatorHeightKey
PIReframeAutoCalculatorSaliencyObservationKey
PIReframeAutoCalculatorANODSubjectsKey
PIReframeAutoCalculatorKeyframesKey
PIReframeAutoCalculatorStabCropRectKey
{?={?=qq}{?=qq}}
Unknown media type
PIFaceObservationCache
spatialOvercaptureFused
spatialOvercapture
time
T{?=qiIq},R,N,V_time
homography
T{?=[3]},R,N,V_homography
dictionaryRepresentation
T@"NSDictionary",R,C,N
timeScale
timeValue
<%@:%p time:%@>
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIReframeKeyframe.m
unexpected homography
count
-[PILongExposureFusionAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PILongExposureFusionAutoCalculator.m
AutoLoop not supported
pre-AutoLoop
PILongExposureFusionAutoCalculator-videoProperties
kind
version
-[PIAutoLoopAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIAutoLoopAutoCalculator.m
B32@?0@"AVMetadataItem"8Q16^B24
inputImage
T@"CIImage",&,N,V_inputImage
temperature
Td,N,V_temperature
tint
Td,N,V_tint
inputBVector
inputGVector
inputRVector
-[PITempTintFilter outputImage]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PITempTintFilter.m
CIColorMatrix
inputImage cannot be nil
all(minsize <= maxr.wh)
CRect CRectClamp(CRect, Float2, const CRect &)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/CRect.mm
T@"NSDictionary",R
T@"NSDictionary",&,V_recipe
videoSource
T@"AVAsset",&,N,V_videoSource
T@"NSDictionary",&,N,V_recipe
-[PIAutoLoopAnalysisJob render:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/AutoLoop/PIAutoLoopJob+Analysis.m
AutoLoop is not supported
-[PIAutoLoopAnalysisJob prepare:]
unable to find video source node
neutralGray
faceBalance
tempTint
rawState
Tq,R,V_rawState
+[PIFaceBalanceAutoCalculator faceBalanceFromFaceImage:forFaceRect:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIWhiteBalanceAutoCalculators.m
unsupported format - incorrect white balance
+[PIFaceBalanceAutoCalculator faceBalanceResultFromFaceObservations:request:error:]
PIRAWFaceBalanceAutoCalculator.responseQueue
WarmFace
WarmTint
WarmTemp
Strength
Warmth
OrigQ
OrigI
Failure in rendering image
face-balance buffer render request
+[PIFaceBalanceAutoCalculator calculateRAWWithRequest:completion:]
PIFaceBalanceAutoCalculator - RAW: face request
/Master/Source
+[PIFaceBalanceAutoCalculator calculateWithRequest:completion:]
CIFaceBalance
return Filter('CIEdges', { 'inputImage' : input, 'inputIntensity' : 1.0 });
CIAreaAverage
v16@?0@"<NUBuffer>"8
color
PIWhiteBalanceAutoCalculator
-[PIWhiteBalanceAutoCalculator submit:]
PIFaceBalanceAutoCalculator.responseQueue
grayColor
pi_grayColorResultValue
T{?={?=[4d]}{?=[4d]}d},R
RGBResultValue
T{?=[4d]},R
{?=[4d]}
{?={?=[4d]}{?=[4d]}d}
Create
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/VRFSession.mm
vec4 meaningBlur(vec4 im, vec4 b)
vec4 result = im;
float thresh = 0.1;
float g1 = max(max(im.r, im.g), im.b);
float g2 = dot(b.rgb, vec3(1.0/3.0));
float diff = max(g2-g1, -1.0);
diff = smoothstep(0.1-thresh, 0.1+thresh, diff);
result.rgb = mix(im.rgb, b.rgb, diff+0.5);
return result;
vec4 clarityNew(vec4 s, vec4 b, float intensity)
float sl = (s.r + s.g + s.b);
float bl = (b.r + b.g + b.b);
float dl = sl + (sl - bl) * intensity;
float mult = dl / max(sl, 0.0001);
mult = 1.571 * (mult - 1.0);
mult = mult / (1.0 + abs(mult));
mult += 1.0;
mult = clamp(mult, 1.0 - 0.5 * abs(intensity), 1.0 + 1.0 * abs(intensity));
s.rgb = s.rgb * mult;
return s;
kernel vec4 definition(sampler image, sampler blur, float intensity)
vec4 imgSample = sample(image, samplerCoord(image));
vec4 blurSample = sample(blur, samplerCoord(blur));
vec4 meaning = meaningBlur(imgSample, blurSample);
vec4 clarity = clarityNew(imgSample, meaning, intensity);
return clarity;
T@"CIImage",&,V_inputImage
inputBlurImage
T@"CIImage",&,V_inputBlurImage
inputIntensity
T@"NSNumber",&,V_inputIntensity
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_bounds
Td,R,N,V_confidence
strengthKey
neutralKey
toneKey
grainKey
hueKey
attributeStrengthKey
attributeNeutralGammaKey
attributeToneKey
attributeHueKey
attributeGrainKey
inputSeed
inputHue
inputGrain
inputTone
inputNeutralGamma
strength
neutral
tone
grain
request
T@"NUImageExportRequest",&,V_request
inputSize
T{?=qq},V_inputSize
geometry
T@"NUImageGeometry",&,V_geometry
auxiliaryImages
T@"NSDictionary",&,V_auxiliaryImages
properties
T@"NSDictionary",C,V_properties
T{?=qq},D
companionImageData
T@"NSData",&,V_companionImageData
companionVideoURL
T@"NSURL",&,V_companionVideoURL
T@"NSData",&,V_data
priority
T@"NUPriority",&,V_priority
colorSpace
T@"NUColorSpace",&,V_colorSpace
pairingIdentifier
T@"NSString",C,V_pairingIdentifier
T@"<NUScalePolicy>",&,V_scalePolicy
metadataProcessor
T@?,C,V_metadataProcessor
increaseBitRateIfNecessary
TB,N,V_increaseBitRateIfNecessary
bypassOutputSettingsIfNoComposition
TB,N,V_bypassOutputSettingsIfNoComposition
imageExportFormat
T@"NUImageExportFormat",C,V_imageExportFormat
optimizeForSharing
TB,V_optimizeForSharing
primaryURL
T@"NSURL",&,V_primaryURL
videoComplementURL
T@"NSURL",&,V_videoComplementURL
videoPosterFrameURL
T@"NSURL",&,V_videoPosterFrameURL
renderCompanionResources
TB,V_renderCompanionResources
reframeCropAdjustment
T@"NUAdjustment",&,V_reframeCropAdjustment
reframeVideoAdjustment
T@"NUAdjustment",&,V_reframeVideoAdjustment
PICompositionExporter.video
yOrigin
xOrigin
roll
reference
-[PICompositionExporter addVideoProperties:composition:options:error:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Util/PICompositionExporter.m
Unknown autoloop flavor
PICompositionExporter.videoProperties
PICompositionExporter.imageProperties.transaction
PICompositionExporter.imageProperties
v32@?0@"NSString"8@"<NUAuxiliaryImage>"16^B24
PICompositionExporter.image
unable to prepare image properties
_companion
-[PICompositionExporter init]
metadataConverter must be set
metadataConverter
T@"<PICompositionExporterMetadataConverter>",&
Regions
convertFromLabToRGB
convertFromRGBToLab
bilateralFinalize
bilateralAdd_9
bilateralAdd_8
bilateralAdd_7
bilateralAdd_6
bilateralAdd_5
bilateralAdd_4
bilateralAdd_3
bilateralAdd_2
bilateralAdd_1
kernel vec4 convertFromRGBToLab(sampler src)
vec3 f;
vec4 pix, color;
pix = unpremultiply(sample(src, samplerCoord(src)));
color.xyz = pix.r * vec3(0.449695,  0.316251, 0.18452  )
+ pix.g * vec3(0.244634,  0.672034, 0.0833318)
+ pix.b * vec3(0.0251829, 0.141184, 0.922602 );
color.xyz *= vec3(1.052111, 1.0, 0.918417);
f = compare(color.xyz - 0.00885645, 7.787037 * color.xyz + 0.137931, pow(color.xyz, vec3(0.333333)));
color.r = 116.0 * f.y - 16.0;
color.g = 500.0 * (f.x - f.y);
color.b = 200.0 * (f.y - f.z);
color.rgb *= 0.005;
color.a = 1.0;
return color;
kernel vec4 convertFromLabToRGB(sampler src, sampler original)
vec3 f, cie;
vec4 color, pix, opix;
pix = sample(src, samplerCoord(src));
opix = sample(original, samplerCoord(original));
pix.rgb *= 200.0;
f.y = (pix.r + 16.0) / 116.0;
f.x = f.y + pix.g * 0.002;
f.z = f.y - pix.b * 0.005;
color.xyz = f * f * f;
cie = compare(color.xyz - 0.00885645, (f.xyz - 0.137931) / 7.787037, color.xyz);
cie *= vec3(0.95047, 1.0, 1.08883);
color.rgb = cie.x * vec3(2.95176,   -1.28951, -0.47388  )
+ cie.y * vec3(-1.0851,    1.99084,  0.0372023)
+ cie.z * vec3(0.0854804, -0.269456, 1.09113  );
color.a = opix.a;
return premultiply(color);
float luminanceWeight(vec4 pix, vec4 center, float slope)
return max(1.0 + (slope * length(pix.rgb - center.rgb)), 0.0);
vec4 bilateralRow_1(sampler src, float slope, vec2 offset1, float weight1)
float diff1;
vec2 coord;
vec4 pix1, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
diff1 = luminanceWeight(pix1, center, slope) * weight1;
return vec4(diff1 * pix1.rgb, diff1);
kernel vec4 bilateralAdd_1(sampler src, sampler sums, float slope, vec2 offset1, float weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_1(src, slope, offset1, weight1);
vec4 bilateralRow_2(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 weight1)
float diff1, diff2;
vec2 coord;
vec4 pix1, pix2, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb, diff1 + diff2);
kernel vec4 bilateralAdd_2(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_2(src, slope, offset1, offset2, weight1);
vec4 bilateralRow_3(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
float diff1, diff2, diff3;
vec2 coord;
vec4 pix1, pix2, pix3, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb, diff1 + diff2 + diff3);
kernel vec4 bilateralAdd_3(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_3(src, slope, offset1, offset2, offset3, weight1);
vec4 bilateralRow_4(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec4 weight1)
float diff1, diff2, diff3, diff4;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb,
diff1 + diff2 + diff3 + diff4);
kernel vec4 bilateralAdd_4(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3,
vec2 offset4, vec4 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_4(src, slope, offset1, offset2, offset3, offset4, weight1);
vec4 bilateralRow_5(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec4 weight1, float weight2)
float diff1, diff2, diff3, diff4, diff5;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb,
diff1 + diff2 + diff3 + diff4 + diff5);
kernel vec4 bilateralAdd_5(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec4 weight1, float weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_5(src, slope, offset1, offset2, offset3, offset4, offset5, weight1, weight2);
vec4 bilateralRow_6(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec4 weight1, vec2 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6);
kernel vec4 bilateralAdd_6(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec4 weight1, vec2 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_6(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, weight1, weight2);
vec4 bilateralRow_7(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7);
kernel vec4 bilateralAdd_7(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_7(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, weight1, weight2);
vec4 bilateralRow_8(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6,
vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8);
kernel vec4 bilateralAdd_8(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_8(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, weight1, weight2);
vec4 bilateralRow_9(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6, vec2 offset7,
vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, pix9, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
pix9 = sample(src, samplerTransform(src, coord + offset9));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
diff9 = luminanceWeight(pix9, center, slope) * weight3;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb + diff9 * pix9.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8 + diff9);
kernel vec4 bilateralAdd_9(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_9(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, offset9,
weight1, weight2, weight3);
kernel vec4 bilateralFinalize(sampler sums)
vec4 sum;
sum = sample(sums, samplerCoord(sums));
return vec4(sum.rgb / max(sum.a, 0.001), 1.0);
inputPoints
T@"NSArray",&,V_inputPoints
inputWeights
T@"NSArray",&,V_inputWeights
inputEdgeDetail
T@"NSNumber",&,V_inputEdgeDetail
inputVersion
T@"NSNumber",&,V_inputVersion
points.count > 0
-[GUBilateralConvolution boundsForPointArray:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIBilateralFilter.m
bilateralLoop11
bilateralLoop5
bilateralLoop2
kernel vec4 bilateralLoop2(sampler src, float slope, vec2 weights12)
vec2 coord;
vec4 center = sample(src, samplerCoord(src));
vec4 sum;
vec4 pix0, pix1, pix2;
vec4 pix3,       pix5;
vec4 pix6, pix7, pix8;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-2.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -1.0));
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dy;
pix3 = sample(src, coord);
coord = coord + dx;
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dy;
pix6 = sample(src, coord);
coord = coord + dx;
pix7 = sample(src, coord);
coord = coord + dx;
pix8 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights12.y);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights12.x) + sum;
sum =                                        center                            + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix7 - center)))) * (pix7 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix8 - center)))) * (pix8 * weights12.y) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop5(sampler src, float slope, vec4 weights1245)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-4.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -2.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop11(sampler src, float slope, vec4 weights1245, vec4 weights89AD)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4, pix5, pix6;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-6.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-2.0, -3.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.y) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
inputBorder
T@"NSNumber",&,V_inputBorder
inputRadius
T@"NSNumber",&,V_inputRadius
-[PIBilateralFilter outputImage]
unable to allocate convolution table in bilateral filter
ridiculously large radius for bilateral filter
com.apple.livephoto
com.apple.video
com.apple.video.slomo
string
T@"NSString",R,W,N
majorVersion
TQ,R,N,V_majorVersion
minorVersion
TQ,R,N,V_minorVersion
subMinorVersion
TQ,R,N,V_subMinorVersion
platform
T@"NSString",R,C,N,V_platform
%lu.%lu%@%@
.%lu
amountKey
portraitInfo
Tq,N,V_version
@"NUAdjustment"16@?0@"NUAdjustment"8
-[PIOrientationAdjustmentController setOrientation:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Controllers/PIOrientationAdjustmentController.m
v48@?0{CGRect={CGPoint=dd}{CGSize=dd}}8^{CGContext=}40
type
Tq,R,N,V_type
Tq,R,N,V_identifier
source
Tq,R,N,V_source
expandedBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_expandedBounds
edgeBleed
Tq,N,V_edgeBleed
isHuman
isAnimal
supportsSecureCoding
(%.4f, %.4f, %.4f, %.4f)
  edgeBleed=%@
maxY 
maxX 
minY 
minX 
  expandedBounds=%@
  bounds=%@
<%@ %p %@ %@ id=%lu conf=%.2f>
Human Face
Human Body
Cat Body
Cat Head
Dog Body
Dog Head
Salient Object
Unknown
None
UnexpectedRuntimeError
NoBuildingDetected
PanoAndFFCNotSupported
FacesTooLarge
SalientAreaTooSmall
SalientHumansAndAnimalsTooLarge
SalientBoundingBoxMissing
ConfidenceTooLow
LimitExceeded
NotEnoughLines
CorrectedAreaIsSmall
LessThanMinimumCorrection
debugLineDetectionImage
T@"CIImage",&,N,V_debugLineDetectionImage
maxAutoYaw
T@"NSNumber",C,V_maxAutoYaw
maxAutoPitch
T@"NSNumber",C,V_maxAutoPitch
maxAutoAngle
T@"NSNumber",C,V_maxAutoAngle
minimumPitchCorrection
Td,V_minimumPitchCorrection
minimumYawCorrection
Td,V_minimumYawCorrection
minimumAngleCorrection
Td,V_minimumAngleCorrection
minimumConfidence
Td,V_minimumConfidence
maxFaceSize
Td,V_maxFaceSize
minimumPitchCorrectionArea
Td,V_minimumPitchCorrectionArea
minimumYawCorrectionArea
Td,V_minimumYawCorrectionArea
disableOnPanos
TB,V_disableOnPanos
disableOnFrontFacingCameraImages
TB,V_disableOnFrontFacingCameraImages
shouldRunDetectorsIfNecessary
TB,V_shouldRunDetectorsIfNecessary
shouldRunBuildingCheck
TB,V_shouldRunBuildingCheck
minSalientArea
Td,N,V_minSalientArea
maxSalientSubjectArea
Td,N,V_maxSalientSubjectArea
angleSeedDegreesCCW
Td,V_angleSeedDegreesCCW
debugFilesEnabled
TB,V_debugFilesEnabled
debugFilesPrefix
T@"NSString",C,V_debugFilesPrefix
debugDiagnostics
T@"NSMutableDictionary",R,V_debugDiagnostics
faceObservationCache
T@"PIFaceObservationCache",&,N,V_faceObservationCache
T@"PIFaceObservationCache",&,N
-[PIPerspectiveAutoCalculator submitVerified:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIPerspectiveAutoCalculator.m
NUPixelSize NUPixelSizeMake(NSInteger, NSInteger)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/Core/Geometry/NUGeometryPrimitives.h
yawError
ciYawError
pitchError
ciPitchError
yawCorrectionAreaCoverage
pitchCorrectionAreaCoverage
debugImage
rollAngleInDegreesCW
yawExpandLeftDegrees
pitchExpandTopDegrees
passesMinimumCorrectionCheck
passesConfidenceCheck
submitVerified
CIAutoPerspective
saliencyHeatMap
(width >= 0) && (height >= 0)
<Unknown Function>
rollLimit
yawLimit
pitchLimit
focalLength
canGenerateNewCropRect
-[PIPerspectiveAutoCalculator passesMinimumCorrectionCheck:error:]
-[PIPerspectiveAutoCalculator passesConfidenceCheck:error:]
minConfidence
Not supported by Core Image. Default: YES
supported
-[PIPerspectiveAutoCalculator canGenerateNewCropRect:]
setToPrimary
preseedRoll
-[PIPerspectiveAutoCalculator primaryImageProperties:]
-[PIPerspectiveAutoCalculator overcaptureImageProperties:]
No overcapture
-[PIPerspectiveAutoCalculator submit:]
passesBuildingCheck
passesFaceCheck
passesSaliencyCheck
passesImagePropertiesCheck
submit
-[PIPerspectiveAutoCalculator passesSaliencyCheck:]
faceArea
subjectArea
salientArea
-[PIPerspectiveAutoCalculator passesBuildingCheck:]
-[PIPerspectiveAutoCalculator passesImagePropertiesCheck:]
isSelfieCam
aspectRatio
Apple
front camera
-[PIPerspectiveAutoCalculator passesFaceCheck:]
faceSize
faces != nil
-[PIPerspectiveAutoCalculator getSizeOfAllFaces:]
Edit
%@PerspectiveLineDetection-png.DBG
%@PerspectiveEvaluation-txt.DBG
yawError.underlyingError
pitchError.underlyingError
%@.underlyingError
%@.error
%@.%@
-[PIPerspectiveAutoCalculator initWithComposition:]
pitch != nil
+[PIPerspectiveAutoCalculator undoOrientation:forPitch:yaw:angle:]
yaw != nil
angle != nil
luminanceKey
luminance
Flash
ApertureValue
FNumber
ExposureTime
ShutterSpeedValue
ISOSpeedRatings
cropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N
constraintWidth
constraintHeight
angle
angleRadians
pitch
pitchRadians
yawRadians
autoCropped
smart
TB,N,GisSmart
originalCrop
TB,N,GisOriginalCrop
-[PICropAdjustmentController setCropRect:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Controllers/PICropAdjustmentController.m
cannot set empty crop rect
inputDecoderVersion
inputLight
offsetBlack
offsetBrightness
offsetContrast
offsetExposure
offsetHighlights
offsetLocalLight
offsetShadows
overcaptureStatistics
localAutoValue
inputLightKey
offsetBlackKey
offsetBrightnessKey
offsetContrastKey
offsetExposureKey
offsetHighlightsKey
offsetLocalLightKey
offsetShadowsKey
attributeBrightnessKey
attributeContrastKey
attributeExposureKey
attributeHighlightsKey
attributeShadowsKey
attributeBlackPointKey
attributeLocalLightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLightMapHeightKey
overcaptureStatisticsKey
sourceSelectionKey
inputRawHighlights
inputLocalLight
inputBlack
inputHighlights
inputShadows
inputBrightness
inputContrast
inputExposure
inputLightMapHeight
inputLightMapWidth
inputLightMap
fuse_image_compute
blur_image_compute_3x3
blur_image_compute_5x5
blur_image_compute_7x7
ncc_coarse_compute
ncc_compute
warp_homography
rgba_to_luma
jointbilateralfilter
kernel vec4 jointbilateralfilter(sampler mask, sampler guide, vec2 rad, vec3 sig) __attribute__((outputFormat(kCIFormatRh)))
vec2 coord = destCoord();
float rh = rad.x;
float rv = rad.y;
vec4 p0 = sample(mask, samplerTransform(mask, coord));
vec4 g0 = sample(guide, samplerTransform(guide, coord));
vec4 result = vec4(0.0f);
float w_sum = 0.0f;
for(float yo=-rad.y;  yo<=rad.y;  yo++) {
for(float xo=-rad.x;  xo<=rad.x;  xo++) {
vec2 dc = vec2(xo, yo);
vec4 p = sample(mask, samplerTransform(mask, coord + dc));
vec4 g = sample(guide, samplerTransform(guide, coord + dc));
float d = dot(dc, dc);
float pdif = dot(p-p0,p-p0);
float gdif = dot(g-g0,g-g0);
float w = exp(dot(sig, vec3(d,pdif,gdif)));
result += w*p;
w_sum += w;
result /= w_sum;
return vec4(result.rgb, 1.0);
kernel vec4 rgba_to_luma(__sample rgb)
const vec4 rgb2y = vec4(0.2999,0.5870,0.1140,0.0);
float luma = dot(rgb, rgb2y);
return vec4(luma, luma, luma, 1.0);
kernel vec2 warp_homography(vec3 h012, vec3 h345, vec3 h678)
vec3 coord = vec3(destCoord(), 1.f);
float norm = 1.f / dot(h678, coord);
float x = norm * dot(h012, coord);
float y = norm * dot(h345, coord);
return vec2(x,y);
kernel vec4 ncc_compute(sampler img1, sampler img2) __attribute__((outputFormat(kCIFormatR8)))
vec2 coord = destCoord();
float sum1   = float(0.0);
float sum2   = float(0.0);
float sumSq1 = float(0.0);
float sumSq2 = float(0.0);
float sumCrs = float(0.0);
float ncc;
float p1, p2;
const int halfKernel = 3;
const vec4 meanOp = vec4(1.0/3.0, 1.0/3.0, 1.0/3.0, 0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
p1 = dot(meanOp, sample(img1, samplerTransform(img1, coord + vec2(x, y))));
p2 = dot(meanOp, sample(img2, samplerTransform(img2, coord + vec2(x, y))));
sum1 += p1;
sum2 += p2;
sumSq1 += p1*p1;
sumSq2 += p2*p2;
sumCrs += p1*p2;
count += 1.0;
float denom = (sumSq1-sum1*sum1/count) * (sumSq2-sum2*sum2/count);
ncc = compare(denom, 0.0, ((sumCrs-(sum1*sum2/count)))/sqrt(denom));
ncc = max(ncc, 0.0);
return vec4(ncc, ncc, ncc, 1.0);
kernel vec4 ncc_coarse_compute(__sample ncc, vec2 edge) __attribute__((outputFormat(kCIFormatR8)))
float value = smoothstep(edge.x, edge.y, ncc.r);
return vec4(value, value, value, 1.0);
kernel vec4 blur_image_compute_3x3(sampler img)
const int halfKernel = 1;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_5x5(sampler img)
const int halfKernel = 2;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_7x7(sampler img)
const int halfKernel = 3;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 fuse_image_compute(sampler refImg, sampler guideImg, sampler blurImg, sampler weightImg, sampler maskImg, vec2 threshold)
vec4 ref       = sample(refImg, samplerCoord(refImg));
vec4 refBlur   = ref;
vec4 guide     = sample(guideImg, samplerCoord(guideImg));
vec4 guideBlur = sample(blurImg, samplerCoord(blurImg));
float weight   = sample(weightImg, samplerCoord(weightImg)).r;
float mask     = sample(maskImg, samplerCoord(maskImg)).r;
vec3 CbCoef = vec3(-0.1726, -0.3391, 0.5117);
vec3 CrCoef = vec3(0.5115, -0.4282, -0.0830);
float CbRef   = dot(CbCoef, ref.rgb);
float CbGuide = dot(CbCoef, guideBlur.rgb);
float CrRef   = dot(CrCoef, ref.rgb);
float CrGuide = dot(CrCoef, guideBlur.rgb);
float crDiff = smoothstep(0.0, 0.2, abs(CbRef-CbGuide));
float cbDiff = smoothstep(0.0, 0.2, abs(CrRef-CrGuide));
float chDiff = smoothstep(0.0,0.3,crDiff+cbDiff);
float weight1 = (1.0-smoothstep(threshold.x,threshold.y,mask));
weight *= weight1 * (1.0-chDiff);
vec4 value = mix(ref, (0.9*(guide-guideBlur)+refBlur), weight);
return value;
kernel vec4 dynamismMap(sampler imageMax, sampler imageMin, float logisticGain, float logisticMid) __attribute__((outputFormat(kCIFormatRGBAh)))
const float MAX_VAL = 1.74;
const float THRESHOLD = 0.05;
vec2 dc = destCoord();
vec2 sc;
sc = dc + vec2(-1,-1);
vec4 pMax00 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin00 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,0);
vec4 pMax01 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin01 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,1);
vec4 pMax02 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin02 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(0,-1);
vec4 pMax10 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin10 = sample(imageMin, samplerTransform(imageMin, sc));
vec4 pMax11 = sample(imageMax, samplerTransform(imageMax, dc));
vec4 pMin11 = sample(imageMin, samplerTransform(imageMin, dc));
sc = dc + vec2(0,1);
vec4 pMax12 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin12 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,-1);
vec4 pMax20 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin20 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,0);
vec4 pMax21 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin21 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,1);
vec4 pMax22 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin22 = sample(imageMin, samplerTransform(imageMin, sc));
float minDevCMaxNMin = distance(pMax11, pMin00);
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin01) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin02) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin10) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin11) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin12) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin20) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin21) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin22) );
float minDevCMinNMax = distance(pMin11, pMax00);
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax01) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax02) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax10) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax11) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax12) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax20) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax21) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax22) );
float outVal = min(minDevCMaxNMin , minDevCMinNMax) / MAX_VAL;
outVal = 1.0f / (1.0f + exp(-logisticGain*(outVal - logisticMid)));
vec4 outPixel = vec4(outVal, outVal, outVal, 1.0);
return outPixel;
kernel vec4 alphaCompositing(__sample src, __sample dst, float a)
return mix(dst, src, a);
SkipShaderPrewarm
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Util/PIPhotoEditHelper.m
endScale
startScale
start
PISmartToneAdjustmentKey
T@"NSString",R,N,V_PISmartToneAdjustmentKey
PISmartColorAdjustmentKey
T@"NSString",R,N,V_PISmartColorAdjustmentKey
PISmartBWAdjustmentKey
T@"NSString",R,N,V_PISmartBWAdjustmentKey
PIGrainAdjustmentKey
T@"NSString",R,N,V_PIGrainAdjustmentKey
PIAutoEnhanceAdjustmentKey
T@"NSString",R,N,V_PIAutoEnhanceAdjustmentKey
PIWhiteBalanceAdjustmentKey
T@"NSString",R,N,V_PIWhiteBalanceAdjustmentKey
PIRedEyeAdjustmentKey
T@"NSString",R,N,V_PIRedEyeAdjustmentKey
PIApertureRedEyeAdjustmentKey
T@"NSString",R,N,V_PIApertureRedEyeAdjustmentKey
PIRetouchAdjustmentKey
T@"NSString",R,N,V_PIRetouchAdjustmentKey
PIVignetteAdjustmentKey
T@"NSString",R,N,V_PIVignetteAdjustmentKey
PISharpenAdjustmentKey
T@"NSString",R,N,V_PISharpenAdjustmentKey
PINoiseReductionAdjustmentKey
T@"NSString",R,N,V_PINoiseReductionAdjustmentKey
PIDefinitionAdjustmentKey
T@"NSString",R,N,V_PIDefinitionAdjustmentKey
PICurvesAdjustmentKey
T@"NSString",R,N,V_PICurvesAdjustmentKey
PILevelsAdjustmentKey
T@"NSString",R,N,V_PILevelsAdjustmentKey
PISelectiveColorAdjustmentKey
T@"NSString",R,N,V_PISelectiveColorAdjustmentKey
PIEffectAdjustmentKey
T@"NSString",R,N,V_PIEffectAdjustmentKey
PIEffect3DAdjustmentKey
T@"NSString",R,N,V_PIEffect3DAdjustmentKey
PICropAdjustmentKey
T@"NSString",R,N,V_PICropAdjustmentKey
PITrimAdjustmentKey
T@"NSString",R,N,V_PITrimAdjustmentKey
PISlomoAdjustmentKey
T@"NSString",R,N,V_PISlomoAdjustmentKey
PILivePhotoKeyFrameAdjustmentKey
T@"NSString",R,N,V_PILivePhotoKeyFrameAdjustmentKey
PIVideoPosterFrameAdjustmentKey
T@"NSString",R,N,V_PIVideoPosterFrameAdjustmentKey
PIAutoLoopAdjustmentKey
T@"NSString",R,N,V_PIAutoLoopAdjustmentKey
PIHighResFusionAdjustmentKey
T@"NSString",R,N,V_PIHighResFusionAdjustmentKey
PIMuteAdjustmentKey
T@"NSString",R,N,V_PIMuteAdjustmentKey
PIDepthAdjustmentKey
T@"NSString",R,N,V_PIDepthAdjustmentKey
PIPortraitAdjustmentKey
T@"NSString",R,N,V_PIPortraitAdjustmentKey
PIOrientationAdjustmentKey
T@"NSString",R,N,V_PIOrientationAdjustmentKey
PIRawAdjustmentKey
T@"NSString",R,N,V_PIRawAdjustmentKey
PIRawNoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIRawNoiseReductionAdjustmentKey
PIVideoReframeAdjustmentKey
T@"NSString",R,N,V_PIVideoReframeAdjustmentKey
PISourceSelectAdjustmentKey
T@"NSString",R,N,V_PISourceSelectAdjustmentKey
PISourceAdjustmentKey
T@"NSString",R,N,V_PISourceAdjustmentKey
PIOvercaptureSourceAdjustmentKey
T@"NSString",R,N,V_PIOvercaptureSourceAdjustmentKey
allAdjustmentTypes
nonVisualAdjustmentTypes
ResetTagInput('/pre-Geometry', input);
return GetTag('/post-Geometry');
/ShowOriginalSource
var image = input;
ResetTagInput('/pre-VideoReframe', image);
image = GetTag('VideoReframe');
ResetTagInput('/pre-Geometry', image);
return GetTag('/post-Geometry');
v32@?0@"NSString"8@"NSString"16^B24
composition != nil
+[PIPhotoEditHelper videoRenderRequestWithComposition:fitInSize:wideGamut:]
+[PIPhotoEditHelper _imageRenderRequestWithComposition:wideGamut:]
targetSize.width > 0 && targetSize.height > 0
+[PIPhotoEditHelper imageRenderRequestWithComposition:fillInSize:wideGamut:]
+[PIPhotoEditHelper imageRenderRequestWithComposition:fitInSize:wideGamut:]
+[PIPhotoEditHelper videoPropertiesRequestWithComposition:]
+[PIPhotoEditHelper imagePropertiesRequestWithComposition:]
+[PIPhotoEditHelper geometryRequestWithComposition:]
name != nil
+[PIPhotoEditHelper newImageRenderClientWithName:]
identifier != nil
+[PIPhotoEditHelper newAdjustmentWithIdentifier:]
+[PIPhotoEditHelper newAdjustmentWithName:]
photoSource != nil
+[PIPhotoEditHelper livePhotoSourceWithPhotoSource:videoSource:]
videoSource != nil
%@+%@
+[PIPhotoEditHelper videoSourceWithURL:]
+[PIPhotoEditHelper imageSourceWithCIImage:orientation:]
+[PIPhotoEditHelper imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:]
+[PIPhotoEditHelper imageSourceWithURL:type:useEmbeddedPreview:]
%@ %a
%@ (preview) %a
ContourV2
CIPortraitEffectContourV2
StudioV2
Contour
CIPortraitEffectStudioV2
CIPortraitEffectContour
Commercial
Light
CIPortraitEffectCommercial
CIPortraitEffectLight
StageWhite
CIPortraitEffectStageWhite
StageMonoV2
StageV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageV2
BlackoutMono
Black
CIPortraitEffectBlackoutMono
CIPortraitEffectBlack
3DNoir
3DSilverplate
CIPhotoEffect3DNoir
CIPhotoEffect3DSilverplate
3DDramaticCool
3DDramaticWarm
CIPhotoEffect3DDramaticCool
CIPhotoEffect3DDramaticWarm
3DDramatic
3DVividCool
CIPhotoEffect3DDramatic
CIPhotoEffect3DVividCool
3DVividWarm
3DVivid
CIPhotoEffect3DVividWarm
CIPhotoEffect3DVivid
Instant
Transfer
CIPhotoEffectInstant
CIPhotoEffectTransfer
Process
Chrome
CIPhotoEffectProcess
CIPhotoEffectChrome
Fade
Noir
CIPhotoEffectFade
CIPhotoEffectNoir
Tonal
Mono
CIPhotoEffectTonal
CIPhotoEffectMono
+[PIForwardFakeBoost kernel]_block_invoke
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIFakeBoost.m
boost kernel is nil
kernel vec4 forwardBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k) - k;
vec3 neg = min(im.rgb, 0.0);
neg *= 2.8;
im.rgb = clamp(im.rgb, 0.0, k);
im.rgb = ((1.0+n)*im.rgb)/(1.0+(n*im.rgb)) + neg;
im.r = pos.r > 0.0 ? (.91803 + .470304*pos.r) : im.r;
im.g = pos.g > 0.0 ? (.91803 + .470304*pos.g) : im.g;
im.b = pos.b > 0.0 ? (.91803 + .470304*pos.b) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
inputBoost
Td,V_inputBoost
-[PIForwardFakeBoost outputImage]
+[PIInverseFakeBoost kernel]_block_invoke
inverse boost kernel is nil
kernel vec4 inverseBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k);
vec3 neg = min(im.rgb, 0.0);
im.rgb = clamp(im.rgb, 0.0, k);
neg *= .35714286;
im.rgb = im.rgb/(n+1.0-(im.rgb*n)) + neg;
im.r = pos.r > 0.8 ? k + 2.126286*(pos.r-.91803) : im.r;
im.g = pos.g > 0.8 ? k + 2.126286*(pos.g-.91803) : im.g;
im.b = pos.b > 0.8 ? k + 2.126286*(pos.b-.91803) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
-[PIInverseFakeBoost outputImage]
/tmp/VRFTrack_%ld_raw.txt
/tmp/VRFTrack_%ld.txt
%.4f, %.4f, %.4f, %.4f, %.4f 
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/BSpline.inl
extend
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/VRFTrack.mm
time < head || time > tail
Effect
Effect3D
SmartTone
SmartColor
SmartBlackAndWhite
Grain
WhiteBalance
Crop
AutoEnhance
RedEyeBB
AutoLoop
HighResolutionFusion
Trim
SlowMotion
LivePhotoKeyFrame
VideoPosterFrame
Mute
DepthEffect
PortraitEffect
SelectiveColor
VideoReframe
SourceSelect
compositionName
identifierName
custom
customSerialization
customCompositionName
customIdentifierName
autoValue
requiresEnabled
v24@?0@"NSMutableDictionary"8@"NUAdjustment"16
portraitEffectFilterName
timescale
regions
timeRange
redEyeCorrections
sensitivity
center
pointY
pointX
inputSpots
RKRedEyeOperation
pressure
yLocation
xLocation
hasSource
sourceOffset
repairEdges
opacity
softness
Repair
mode
brushStroke
inputStrokes
RKRetouchOperation
corrections
RKSelectiveColorOperation
RGBCurvePoints
blueCurvePoints
pointsL
pointsB
greenCurvePoints
redCurvePoints
pointsG
pointsR
RKCurvesOperation
whiteDstBlue
whiteSrcBlue
hilightDstBlue
hilightSrcBlue
midDstBlue
midSrcBlue
shadowDstBlue
shadowSrcBlue
blackDstBlue
blackSrcBlue
whiteDstGreen
whiteSrcGreen
hilightDstGreen
hilightSrcGreen
midDstGreen
midSrcGreen
shadowDstGreen
shadowSrcGreen
blackDstGreen
blackSrcGreen
whiteDstRed
whiteSrcRed
hilightDstRed
hilightSrcRed
midDstRed
midSrcRed
shadowDstRed
shadowSrcRed
blackDstRed
blackSrcRed
whiteDstRGB
whiteSrcRGB
hilightDstRGB
hilightSrcRGB
midDstRGB
midSrcRGB
shadowDstRGB
shadowSrcRGB
blackDstRGB
blackSrcRGB
RKLevelsOperation
warm
face
inputMethodVersion
RKRawDecodeOperation
inputLNRAmount
inputCNRAmount
inputDetailAmount
detail
DGRAWReduceNoiseOperation
straightenAngle
effectIntensity
effectVersion
effectName
inputSharpness
inputEdgeScale
edges
RKProSharpenOperation
edgeDetail
RKNoiseReductionOperation
DGDefinition2Operation
inputFalloff
DGVignetteEffectOperation
seed
amount
offsetNeutralGamma
inputBlackAndWhite
offsetTone
offsetGrain
offsetStrength
lightMapAvg
lightMap
offsetBlackPoint
v24@?0@"NSDictionary"8@"NUAdjustment"16
autoRedEyeCorrections
allCorrections
RedEye
ApertureRedEye
Clone
B16@?0@"NSDictionary"8
Retouch
Curves
Display P3
sRGB
Adobe RGB
Generic P3
Levels
RawNoiseReduction
CropStraighten
@"NSString"24@?0@"NSDictionary"8@"NUAdjustment"16
@"NSString"16@?0@"NSDictionary"8
Sharpen
NoiseReduction
Definition
Vignette
_accumError
T@"NSError",&,V__accumError
isReadyForMoreData
-[PILongExposureAccumulator _exportOutputImage:format:colorSpace:toURL:uti:error:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/AutoLoop/PIAutoLoopJob+LongExposure.m
destinationURL != nil
Failed to create CGImageRef
Failed to create CGImageDestinationRef
Failed to finalize image destination
-[PILongExposureAccumulator writeMaskImage:UTI:error:]
v16@?0@"CIImage"8
-[PILongExposureAccumulator writeLongExposureImage:UTI:colorSpace:error:]
-[PILongExposureAccumulator _accumulate:error:]
B16@?0@"CIRenderDestination"8
failed to render maximum image
failed to render minimum image
CIBoxBlur
failed to render average image
frame != nil
-[PILongExposureAccumulator accumulate:error:]
failed to init accumulator
Accumulation was cancelled
PILongExposureAccumulator.state
PILongExposureAccumulator.accum
observation
T@"VNImageHomographicAlignmentObservation",R,C
extent
T{?={?=qq}{?=qq}},R,N
T@"VNImageHomographicAlignmentObservation",C,N,V_observation
T{?={?=qq}{?=qq}},N,V_extent
guideExtent
T{?={?=qq}{?=qq}},N,V_guideExtent
stillImage
T@"CIImage",&,N,V_stillImage
T@"VNImageHomographicAlignmentObservation",&,N,V_observation
-[PILongExposureRegistrationJob render:]
Image registration failure (expected 1 observation)
Failed to render luma
Failed to allocate intermediate pixel buffer
-[PILongExposureRegistrationJob prepare:]
Malformed AutoLoop recipe : crop
return Source(composition.source, {'skipOrientation':true});
/AutoLoop/LongExposure
/RAW/SushiLevel1
/Master%@
inputDestinationImage
T@"CIImage",&,N,V_inputDestinationImage
inputCorrectionInfo
T@"NSArray",&,N,V_inputCorrectionInfo
inputCameraModel
T@"NSString",&,N,V_inputCameraModel
CILanczosScaleTransform
inputScale
CIRedEyeCorrection
posterFrameTime
dynamic
@"NSString"16@?0@"NUAdjustment"8
1.5.1
overcaptureComputed
computed
convexHull
T{?=qiIq},R,V_time
subjects
T@"NSArray",R,V_subjects
estimatedCenterMotion
T{CGVector=dd},R,V_estimatedCenterMotion
estimatedMotionBlur
T{CGVector=dd},R,V_estimatedMotionBlur
trajectoryHomography
T{?=[3]},R,V_trajectoryHomography
timedMetadataArray
T@"NSArray",R,N,VtimedMetadataArray
-[PIVideoReframeMetadataExtractor extractMetadata]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIVideoReframeMetadataExtractor.mm
mdataGroup.items.count == 1
0 && "unexpected metadata identifier"
0 && "unexpected metadata data type"
err == noErr
-[PIVideoReframeMetadataExtractor motionBlurVectorFromMetadata:]
-[PIVideoReframeMetadataExtractor overwriteTrackingMetadataWithPlist:]
type >= 0
Confidence
Source
DogBody
CatBody
HumanFace
HumanBody
Type
Subjects
Time
Invalid plist at path: %@
init is not a valid initializer
/private/var/mobile/Media/PhotoData/CaptureDebug/
startTime
endTime
rate
id<NUBuffer> computeRepairMask(__strong id<NUBuffer>, uint16_t *)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIApertureRedEye.mm
void seedFill(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, const uint32_t, const NSInteger, const NSInteger)
repairBuffer != nil
void applyRepairMask(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, double, const uint32_t)
reddesty out of bounds
reddestx out of bounds
Buffer must be RGBA16 type for red eye repairs
kernel vec4 facebalance(__sample src, vec2 gamma, vec3 matchMinusOrigStrength)
vec4 pix = src;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  matchMinusOrigStrength.rg;
float strength = matchMinusOrigStrength.z*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
inputOrigI
Td,N,V_inputOrigI
inputOrigQ
Td,N,V_inputOrigQ
inputStrength
Td,N,V_inputStrength
inputWarmth
Td,N,V_inputWarmth
facebalance
inputPointsR
T@"NSArray",&,V_inputPointsR
inputPointsG
T@"NSArray",&,V_inputPointsG
inputPointsB
T@"NSArray",&,V_inputPointsB
inputPointsL
T@"NSArray",&,V_inputPointsL
tableR != nil
+[PICurvesLUTFilter tableImageFromRed:green:blue:luminance:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PICurvesFilter.mm
tableG != nil
tableB != nil
tableL != nil
v56@?0^v8Q16Q24Q32Q40Q48
inputTableImage
T@"CIImage",&,V_inputTableImage
vec4 curve_sample(float x, sampler2D table, vec2 domain, vec2 normalizer)
x = (x - domain.x) / (domain.y - domain.x);
x = clamp(x, 0.0001, 0.9999);
x = normalizer.x * x + normalizer.y;
return texture2D(table, vec2(x, 0.5));
kernel vec4 curves_rgb_lum(__sample color, sampler2D table, vec2 domain, vec2 normalizer)
vec4 pixel = color;
pixel.r = curve_sample(pixel.r, table, domain, normalizer).r;
pixel.g = curve_sample(pixel.g, table, domain, normalizer).g;
pixel.b = curve_sample(pixel.b, table, domain, normalizer).b;
float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11));
float lum1 = curve_sample(lum0, table, domain, normalizer).a;
float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0));
float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0);
float lum_offset = lum1 - lum1c;
pixel.rgb = lum_scale * pixel.rgb + lum_offset;
return pixel;
colorBalance
PPtogHDR
gHDRtoPP
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
kernel vec4 colorBalance(__sample image, float colorI, float colorQ, float str, vec2 gamma)
vec4 pix = image;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  vec2(colorI,colorQ);
float strength = str*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
inputWarmTemp
T@"NSNumber",&,N,V_inputWarmTemp
inputWarmTint
T@"NSNumber",&,N,V_inputWarmTint
T@"NSNumber",&,N,V_inputStrength
inputHasFace
T@"NSNumber",&,N,V_inputHasFace
inputIsRaw
T@"NSNumber",&,N,V_inputIsRaw
-[PIColorBalanceFilter outputImage]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIColorBalanceFilter.m
alignment
debugDecoratorFiltersEnabled
PIGlobalSettings
-[PIAutoLoopExportJob initWithVideoExportRequest:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/AutoLoop/PIAutoLoopJob+Export.m
B8@?0
PI_AUTOLOOP_EXPORT_USE_METAL
OvercaptureRectForAutoCrop
{CGRect={CGPoint=dd}{CGSize=dd}}64@?0{CGSize=dd}8{CGSize=dd}24{CGSize=dd}40@"JSValue"56
@"NUJSRenderNode"24@?0@"NUJSRenderNode"8@"JSValue"16
-[PIJSRenderPipeline setUpContext:]_block_invoke
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIPhotosPipeline.m
Unable to unwrap the input node!
input to VideoReframe cannot be nil
Invalid data type for stabCropRect
Invalid data type for keyframes
Invalid data type for adjustmentValue
/System/Library/Frameworks/JavaScriptCore.framework/JavaScriptCore
JSContext
Unable to find class %s
+[NUJSRenderPipeline(PhotosPipeline) newPhotosPipeline:]
Couldn't find the specified Pipeline
PhotosPipeline
Couldn't find bundle for class %@
point
T{CGPoint=dd},R,N,V_point
value
Td,R,N,V_value
<%@ %p point=(%f, %f) value=%f>
redEyeSpots
-[PIApertureRedEyeAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIApertureRedEyeAutoCalculator.m
pre-Adjustments
T@"NSMutableData",&,Vdata
elementByteSize
TQ,R,VelementByteSize
rowElements
TQ,R,VrowElements
TQ,R,Vwidth
TQ,R,Vheight
format
Ti,R,Vformat
-[PISmartBlackAndWhiteAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PISmartBlackAndWhiteAutoCalculator.mm
v24@?0@"<NUBufferTile>"8^B16
v16@?0@"<NUMutableBuffer>"8
void calculate_bw_auto_matrix_lum_contrast(__strong id<NUBuffer>, CGColorSpaceRef, MsgBlackAndWhiteSettings *)
Produced invalid BlackAndWhite settings, using defaults
xi < w && yi < h
MatrixFloatType &MsgMatrix<double>::operator()(size_t, size_t) [MatrixFloatType = double]
index < data.size()
num == w
void MsgMatrix<double>::AppendRow(const NumberType *, uint) [MatrixFloatType = double, NumberType = double]
T@"NSArray",C,N
whiteDst
whiteSrc
hilightDst
hilightSrc
midDst
midSrc
shadowDst
shadowSrc
blackDst
blackSrc
-[PILevelsAutoCalculator calculateSettingsForImageHistogram:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PILevelsAutoCalculator.m
This is an abstract method! Subclass '%@' should provide concrete implementation
-[PILevelsAutoCalculator submit:]
pre-Levels
Blue
Green
creationDate
T@"NSDate",&,N,V_creationDate
creationTimeZone
T@"NSTimeZone",&,N,V_creationTimeZone
title
T@"NSString",C,N,V_title
caption
T@"NSString",C,N,V_caption
keywords
T@"NSArray",C,N,V_keywords
peopleNames
T@"NSArray",C,N,V_peopleNames
location
T@"CLLocation",C,N,V_location
T@"CLLocation",C,N
T@"NSDate",R,N
T@"NSTimeZone",R,N
iptcMutableDictionary
T@"NSMutableDictionary",&,N,V_iptcMutableDictionary
exifMutableDictionary
T@"NSMutableDictionary",&,N,V_exifMutableDictionary
tiffMutableDictionary
T@"NSMutableDictionary",&,N,V_tiffMutableDictionary
iptcDictionary
exifDictionary
tiffDictionary
+00:00
yyyy:MM:dd
HH:mm:ss.SS
en_US
en_US_POSIX
yyyy:MM:dd HH:mm:ss
metadataItems
v32@?0@8@16^B24
adjustmentConstants
T@"PIAdjustmentConstants",R,N
-[PICompositionController(AdjustmentExtensions) _adjustmentControllerForKey:creatingIfNecessary:expectedClass:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Controllers/PICompositionController+AdjustmentExtensions.m
Adjustment controller for key %@ is of class: %@, but was expected to be %@
Td,R,N,V_x
Td,R,N,V_y
TB,R,N,GisEditable,V_editable
not editable
editable
<%@:%p> [(%.3f, %.3f), %s]
inputStillImage
T@"CIImage",&,N,V_inputStillImage
inputMaskImage
T@"CIImage",&,N,V_inputMaskImage
inputRenderScale
T@"NSNumber",&,N,V_inputRenderScale
inputVideoScale
T@"NSNumber",&,N,V_inputVideoScale
inputAlignmentExtent
T@"CIVector",&,N,V_inputAlignmentExtent
inputAlignmentTransform
T@"CIVector",&,N,V_inputAlignmentTransform
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
long-exp-fusion-image.tiff
long-exp-refined-mask-image.tiff
long-exp-ncc-map-image.tiff
long-exp-guide-image.tiff
long-exp-still-image.tiff
long-exp-mask-image.tiff
long-exp-input-image.tiff
PI_LONG_EXPOSURE_DUMP_INTERMEDIATES
kBlendMaskThreshold1
kBlendMaskThreshold0
kNCCEdge1
kNCCEdge0
kNCCBlurHalfSize
@"NSString"8@?0
PI_LONG_EXPOSURE_FUSION_PARAMS
inputWhiteDst
inputWhiteSrc
inputHilightDst
inputHilightSrc
inputMidDst
inputMidSrc
inputShadowDst
inputShadowSrc
inputBlackDst
inputBlackSrc
kernel vec4 levelsNewGammaForP3 (sampler src, sampler LUT)
vec4
p,r;
vec2
c1,c2;
float
p  = sample(src, samplerCoord(src));
vec3 neg = min(p.rgb, 0.0);
vec3 pos = max(p.rgb, 1.0)-1.0;
p.rgb = clamp(p.rgb, 0.0, 1.0);
f = p.r * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.r = r.r * 4.0 - 1.0;
f = p.g * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.g = r.g * 4.0 - 1.0;
f = p.b * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.b = r.b * 4.0 - 1.0;
p.rgb = max(p.rgb, 0.0);
p.rgb = p.rgb + pos + neg;
return p;
inputBlackSrcRGB
T@"NSNumber",&,N,V_inputBlackSrcRGB
inputBlackDstRGB
T@"NSNumber",&,N,V_inputBlackDstRGB
inputShadowSrcRGB
T@"NSNumber",&,N,V_inputShadowSrcRGB
inputShadowDstRGB
T@"NSNumber",&,N,V_inputShadowDstRGB
inputMidSrcRGB
T@"NSNumber",&,N,V_inputMidSrcRGB
inputMidDstRGB
T@"NSNumber",&,N,V_inputMidDstRGB
inputHilightSrcRGB
T@"NSNumber",&,N,V_inputHilightSrcRGB
inputHilightDstRGB
T@"NSNumber",&,N,V_inputHilightDstRGB
inputWhiteSrcRGB
T@"NSNumber",&,N,V_inputWhiteSrcRGB
inputWhiteDstRGB
T@"NSNumber",&,N,V_inputWhiteDstRGB
inputBlackSrcRed
T@"NSNumber",&,N,V_inputBlackSrcRed
inputBlackDstRed
T@"NSNumber",&,N,V_inputBlackDstRed
inputShadowSrcRed
T@"NSNumber",&,N,V_inputShadowSrcRed
inputShadowDstRed
T@"NSNumber",&,N,V_inputShadowDstRed
inputMidSrcRed
T@"NSNumber",&,N,V_inputMidSrcRed
inputMidDstRed
T@"NSNumber",&,N,V_inputMidDstRed
inputHilightSrcRed
T@"NSNumber",&,N,V_inputHilightSrcRed
inputHilightDstRed
T@"NSNumber",&,N,V_inputHilightDstRed
inputWhiteSrcRed
T@"NSNumber",&,N,V_inputWhiteSrcRed
inputWhiteDstRed
T@"NSNumber",&,N,V_inputWhiteDstRed
inputBlackSrcGreen
T@"NSNumber",&,N,V_inputBlackSrcGreen
inputBlackDstGreen
T@"NSNumber",&,N,V_inputBlackDstGreen
inputShadowSrcGreen
T@"NSNumber",&,N,V_inputShadowSrcGreen
inputShadowDstGreen
T@"NSNumber",&,N,V_inputShadowDstGreen
inputMidSrcGreen
T@"NSNumber",&,N,V_inputMidSrcGreen
inputMidDstGreen
T@"NSNumber",&,N,V_inputMidDstGreen
inputHilightSrcGreen
T@"NSNumber",&,N,V_inputHilightSrcGreen
inputHilightDstGreen
T@"NSNumber",&,N,V_inputHilightDstGreen
inputWhiteSrcGreen
T@"NSNumber",&,N,V_inputWhiteSrcGreen
inputWhiteDstGreen
T@"NSNumber",&,N,V_inputWhiteDstGreen
inputBlackSrcBlue
T@"NSNumber",&,N,V_inputBlackSrcBlue
inputBlackDstBlue
T@"NSNumber",&,N,V_inputBlackDstBlue
inputShadowSrcBlue
T@"NSNumber",&,N,V_inputShadowSrcBlue
inputShadowDstBlue
T@"NSNumber",&,N,V_inputShadowDstBlue
inputMidSrcBlue
T@"NSNumber",&,N,V_inputMidSrcBlue
inputMidDstBlue
T@"NSNumber",&,N,V_inputMidDstBlue
inputHilightSrcBlue
T@"NSNumber",&,N,V_inputHilightSrcBlue
inputHilightDstBlue
T@"NSNumber",&,N,V_inputHilightDstBlue
inputWhiteSrcBlue
T@"NSNumber",&,N,V_inputWhiteSrcBlue
inputWhiteDstBlue
T@"NSNumber",&,N,V_inputWhiteDstBlue
inputColorSpace
T@"NSString",&,N,V_inputColorSpace
-[PILevelsFilter _LUTImage]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PILevelsFilter.m
Failed converting data to RGBAh: %ld
Mirror
LongExposure
T@"NUIdentifier",R
PhotosComposition
+[PISchema registerPhotosSchema]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PISchema.m
failed to construct photos pipeline %@
failed to register %@: %@
+[PISchema photosCompositionSchema]
Failed to register schema %@: %@
required
VideoReframe~1.0
PortraitEffect~1.0
Effect3D~1.0
DepthEffect~1.0
SelectiveColor~1.0
Curves~1.0
Levels~1.0
NoiseReduction~1.0
Orientation~1.0
Vignette~1.0
AutoLoop~1.0
Mute~1.0
HighResolutionFusion~1.0
VideoPosterFrame~1.0
LivePhotoKeyFrame~1.0
SlowMotion~1.0
Trim~1.0
CropStraighten~1.0
Effect~1.0
Definition~1.0
Sharpen~1.0
Grain~1.0
SmartBlackAndWhite~1.0
SmartColor~1.0
SmartTone~1.0
ApertureRedEye~1.0
RedEye~1.0
WhiteBalance~1.0
Retouch~1.0
SourceSelect~1.0
com.apple.photo:Source~1.0
RawNoiseReduction~1.0
RAW~1.0
contents
Composition
+[PISchema videoReframeSchema]
compound
bool
Adjustment
default
content
array
maximum
minimum
number
+[PISchema selectiveColorSchema]
saturation
hueShift
spread
blue
green
+[PISchema curvesSchema]
+[PISchema levelsSchema]
values
enum
+[PISchema whiteBalanceSchema]
identity
ui_maximum
ui_minimum
+[PISchema noiseReductionSchema]
+[PISchema definitionSchema]
+[PISchema orientationSchema]
+[PISchema vignetteSchema]
+[PISchema retouchSchema]
+[PISchema apertureRedEyeSchema]
+[PISchema redEyeSchema]
opaque
iPhone
+[PISchema effectSchema]
+[PISchema portraitEffectSchema]
+[PISchema effect3DSchema]
+[PISchema depthEffectSchema]
+[PISchema highResFusionSchema]
+[PISchema autoLoopSchema]
+[PISchema videoPosterFrameSchema]
+[PISchema muteSchema]
+[PISchema livePhotoKeyFrameSchema]
+[PISchema slomoSchema]
+[PISchema trimSchema]
+[PISchema cropSchema]
+[PISchema sharpenSchema]
+[PISchema grainSchema]
+[PISchema smartBlackAndWhiteSchema]
+[PISchema smartColorSchema]
inputCast
inputSaturation
+[PISchema smartToneSchema]
+[PISchema rawNoiseReductionSchema]
contrast
sharpness
+[PISchema rawSchema]
inputSushiLevel
+[PISchema sourceSelectSchema]
com.apple.mobileslideshow.reframe.photo.eligible-pass
com.apple.mobileslideshow.reframe.photo.eligible-fail
com.apple.mobileslideshow.reframe.video.eligible-pass
com.apple.mobileslideshow.reframe.video.eligible-fail
com.apple.mobileslideshow.reframe.type.photo.subject
com.apple.mobileslideshow.reframe.type.video.subject
com.apple.mobileslideshow.reframe.type.photo.horizon
com.apple.mobileslideshow.reframe.type.photo.perspective
finalizerError
T@"NSError",&,N,V_finalizerError
performedActions
TQ,N,V_performedActions
reframeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_reframeRect
rollAngleDegrees
Td,N,V_rollAngleDegrees
pitchAngleDegrees
Td,N,V_pitchAngleDegrees
yawAngleDegrees
Td,N,V_yawAngleDegrees
keyframes
T@"NSArray",C,N,V_keyframes
stabCropRect
T{?={?=qq}{?=qq}},N,V_stabCropRect
candidacy
TQ,N,V_candidacy
Capture
minRotateCameraPerspectiveCorrection
minVerticalCameraPerspectiveCorrection
minHorizontalCameraPerspectiveCorrection
maxCameraRotatePerspectiveCorrection
maxCameraHorizontalPerspectiveCorrection
maxCameraVerticalPerspectiveCorrection
maxCameraAutoStraightenCorrection
disposition
Tq,R,V_disposition
T@"NUComposition",R,C,V_composition
v16@?0@"PIAdjustmentController"8
enable_perspective_correction
PICompositionFinalizer
PIComopsitionFinalizer requires a sourceSpatialOvercapture
horizon
perpsective
reframe
shouldPerformAutoCrop
TB,V_shouldPerformAutoCrop
shouldPerformAutoStraighten
TB,V_shouldPerformAutoStraighten
shouldUseAutoStraightenVerticalDetector
TB,V_shouldUseAutoStraightenVerticalDetector
autoStraightenVerticalAngleThreshold
T@"NSNumber",C,V_autoStraightenVerticalAngleThreshold
autoStraightenDominantAngleDiffThreshold
T@"NSNumber",C,V_autoStraightenDominantAngleDiffThreshold
maxAutoStraighten
Td,V_maxAutoStraighten
minAutoStraighten
Td,V_minAutoStraighten
-[PICropAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PICropAutoCalculator.m
%@AutoCropEvaluation-txt.DBG
error
autoCrop
belowMinimum
limitExceeded
straightenAngleInDegreesCCW
CIAutoStraighten
filterOptions
kCIImageAutoAdjustLevel_DominantAngleDiffThreshold
kCIImageAutoAdjustLevel_VerticalAngleThreshold
kCIImageAutoAdjustLevel_UseVerticalDetector
-[PICropAutoCalculator undoExifOrientation:error:]
Source geometry has 0 size
+[PICropAutoCalculator(Utilities) updateCropAdjustment:after:error:]
v16@?0@"PICropAdjustmentController"8
stitchedOvercaptureRect
v16@?0@"PISourceSelectAdjustmentController"8
getSpan
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/CatmullRom.inl
vrfPositionKernelSize
vrfPhaseShift
%f, 
Gaussian1D
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/Internal/VRFFilters.h
ABS(weightSum - 1) < 0.01
VRFLoggingEnabled
vrfSmoothingMethod
vrfAreaLookBehind
vrfAreaLookAhead
inputColor
offsetSaturation
offsetCast
satPercentileG98
satPercentile98
satPercentile75
inputColorKey
offsetSaturationKey
offsetCastKey
attributeVibrancyKey
attributeCastKey
inputCorrections
T@"NSArray",&,N,V_inputCorrections
iptLumHueSatTable
inputBackgroundImage
CIAdditionCompositing
add_gaussian
CIConstantColorGenerator
iptToSRGB
srgbToIPT
kernel vec4 iptLumHueSatTable(sampler image, __table sampler hueSatLumTable)
vec4 im = sample(image, samplerCoord(image)) ;
vec4 result = im;
float hueIdx = 359.0 * 0.5 * (atan(im.b, im.g)/3.1416 + 1.0);
hueIdx = clamp(hueIdx, 0.0, 359.0) + 0.5;
float hueChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).r);
float satChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).g);
float lumChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).b);
float chroma = sqrt(im.g*im.g+im.b*im.b) ;
chroma *= satChange ;
float hue = atan(im.b, im.g) + hueChange ;
vec3 adjustIm = im.rgb;
float hueAngle = hue  ;
lumChange = mix(1.0, lumChange, chroma);
adjustIm.r *= lumChange;
adjustIm.g = chroma * cos(hueAngle) ;
adjustIm.b = chroma * sin(hueAngle) ;
result.rgb = mix(im.rgb, adjustIm.rgb, 1.0) ;
result.rgb = adjustIm.rgb;
result.a = im.a ;
return result ;
kernel vec4 srgbToIPT(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, ipt;
lms = im.r * vec3(0.3139902162, 0.155372406, 0.017752387) +
im.g * vec3(0.6395129383, 0.7578944616, 0.109442094) +
im.b * vec3(0.0464975462, 0.0867014186, 0.8725692246);
lms = sign(lms)*pow(abs(lms), vec3(0.43, 0.43, 0.43));
ipt = lms.r * vec3(0.4, 4.455, 0.8056) +
lms.g * vec3(0.4, -4.851, 0.3572) +
lms.b * vec3(0.2, 0.3960, -1.1628);
return vec4(ipt, im.a);
kernel vec4 iptToSRGB(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, rgb;
lms = im.rrr +
im.g * vec3(0.09756893,-0.11387649,0.03261511) +
im.b * vec3(0.20522644, 0.13321716,  -0.67688718);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
rgb = lms.r * vec3( 5.472212058380287,  -1.125241895533569,   0.029801651173470) +
lms.g * vec3(-4.641960098354470, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974,  -0.167895202223709, 1.163647892783812);
return vec4(rgb, im.a);
kernel vec4 add_gaussian(sampler srcTable, float tableSize, float hueAmplitude, float satAmplitude, float lumAmplitude, float gaussX, float gaussSigmaSquared) {
vec2 d = destCoord();
vec4 src = sample(srcTable, samplerCoord(srcTable));
float x = d.x / (tableSize - 1.0);
float dist = min(min(abs(x - gaussX), abs(x - 1.0 - gaussX)), abs(x + 1.0 - gaussX));
float p = -((dist * dist) / (2.0 * gaussSigmaSquared));
float ep = exp(p);
float hue = hueAmplitude * ep;
float sat = satAmplitude * ep;
float lum = lumAmplitude * ep;
float h = clamp(src.r + hue, -1.0, 1.0);
float s = clamp(src.g + sat, -1.0, 1.0);
float l = clamp(src.b + lum, -1.0, 1.0);
return vec4(h,s,l,1.0);
T{?=qiIq},N,V_time
sampleMode
Tq,N,V_sampleMode
keyframeSequence
T@"PIReframeKeyframeSequence",&,N,V_keyframeSequence
inputVideoProperties
T@"<NUVideoProperties>",&,N,V_inputVideoProperties
frameDuration
T{?=qiIq},N,V_frameDuration
CIPerspectiveTransform
inputBottomRight
inputBottomLeft
inputTopRight
inputTopLeft
pipelineState
Could not get the input image properties
Could not get the input geometry
Could not get the input image
-[PIVideoReframeNode _evaluateImageGeometry:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIVideoReframeNode.m
Failed to get input geometry
-[PIVideoReframeNode _evaluateVideoProperties:]
-[PIVideoReframeNode initWithSettings:inputs:]
invalid crop rect
convertFromYIQToRGB
convertFromRGBToYIQ
kernel vec4 convertFromRGBToYIQ(sampler src, float gamma)
vec4 pix ;
vec3 pix2;
pix = sample(src, samplerCoord(src));
pix.rgb = sign(pix.rgb)*pow(abs(pix.rgb), vec3(1.0/gamma)) ;
pix2.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
return vec4(pix2, pix.a);
kernel vec4 convertFromYIQToRGB(sampler src, float gamma)
vec4 color, pix;
pix = sample(src, samplerCoord(src));
color.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
color.rgb = sign(color.rgb)*pow(abs(color.rgb), vec3(gamma, gamma, gamma) );
color.a = pix.a;
return color;
kernel vec4 whiteBalance(sampler image, float grayY, float grayI, float grayQ, float strength)
vec4 im = sample(image, samplerCoord(image)) ;
vec2 grayOffset = vec2(grayI, grayQ) ;
vec4 result ;
float newStrength = 1.0 + (strength-1.0)*(1.0-im.r) ;
result.r = im.r ;
result.gb = im.gb + newStrength*grayOffset ;
float damp = max(min(1.0, im.r/(grayY+0.00001)),0.0) ;
result.rgb = mix(im.rgb, result.rgb, damp) ;
result.a = im.a ;
return result ;
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
T@"NSNumber",&,N,V_strength
warmth
T@"NSNumber",&,N,V_warmth
T@"NSNumber",&,N,V_y
T@"NSNumber",&,N,V_i
T@"NSNumber",&,N,V_q
-[PINeutralGrayWhiteBalanceFilter outputImage]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PINeutralGrayWhiteBalanceFilter.m
-[PISmartToneAutoCalculator submit:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIAutoCalculators.mm
PISmartToneAutoCalculator
CILocalLight
CISmartTone
-[PISmartColorAutoCalculator submit:]
CISmartColor
force
TB,V_force
-[PIRedEyeAutoCalculator submit:]
touchDiameter
locationY
locationX
/masterSpace
%@-%d-%ld.tiff
cgImage != NULL
+[PIImageIO writeCGImage:fileURL:options:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Util/PIImageIO.m
fileURL != nil
Failed to write image to file %@
Successfully wrote image to file %@
+[PIImageIO writeCGImage:fileURL:]
GU %@ %@
Unhandled bit depth: %ld
image != nil
+[PIImageIO writeImage:fileURL:]
unwantedSubjectInclusionThreshold
Td,N,V_unwantedSubjectInclusionThreshold
dominantToPeripheralSubjectRatioThreshold
Td,N,V_dominantToPeripheralSubjectRatioThreshold
minimumCorrectionThreshold
Td,N,V_minimumCorrectionThreshold
humanFaceBoundsContainmentThreshold
Td,N,V_humanFaceBoundsContainmentThreshold
humanBodyBoundsContainmentThreshold
Td,N,V_humanBodyBoundsContainmentThreshold
humanBodyExpandedBoundsContainmentThreshold
Td,N,V_humanBodyExpandedBoundsContainmentThreshold
humanBodyBoundsContainmentCoefficient
Td,N,V_humanBodyBoundsContainmentCoefficient
petBoundsContainmentThreshold
Td,N,V_petBoundsContainmentThreshold
petExpandedBoundsContainmentThreshold
Td,N,V_petExpandedBoundsContainmentThreshold
petBoundsContainmentCoefficient
Td,N,V_petBoundsContainmentCoefficient
facePaddingFactor
Td,N,V_facePaddingFactor
bodyPaddingAmount
Td,N,V_bodyPaddingAmount
overscanPercentageAllowed
Td,N,V_overscanPercentageAllowed
unwantedSubjectStartingThreshold
Td,N,V_unwantedSubjectStartingThreshold
shouldAttemptReframe
TB,R,N,V_shouldAttemptReframe
mutableSubjects
T@"NSMutableArray",R,C,N,V_mutableSubjects
ruleSystem
T@"NURuleSystem",R,N,V_ruleSystem
sceneContainsPet
TB,N,V_sceneContainsPet
sceneContainsHuman
TB,N,V_sceneContainsHuman
sceneContainsMultipleSubjects
TB,N,V_sceneContainsMultipleSubjects
T@"PIStillReframerConfiguration",R,N,V_configuration
overscanBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_overscanBounds
viewBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_viewBounds
T@"NSArray",R,C,N,V_ANODSubjects
T@"VNSaliencyImageObservation",R,N,V_saliencyObservation
result
T@"PIReframeResult",R,N,V_result
evaluationData
T@"NSData",R,N
postGateInsignificantCorrection
postGateEqualViewBounds
reframedBounds
i12@?0i8
state.%K.type == %@
shouldIncludeSubject
state.%K == TRUE && facts.%K == TRUE && state.%K == TRUE
state.%K < constants.overscanPercentageAllowed
canIncludeSubject
candidateRectAllowed
amountOfOverscanUsed
object
candidateReframedBounds
expandedBoundsPercentageInside
boundsPercentageInside
v24@?0@"NSPredicate"8@"NSString"16
@"NSString"32@?0@"NSPredicate"8Q16@"NSString"24
@"NSString"32@?0Q8@"NSString"16@24
peripheralSubject-%ld
dominantSubject
q24@?0@"PIReframeSubject"8@"PIReframeSubject"16
v24@?0@"PIReframeSubject"8@?<i@?i>16
(%f, %f, %f, %f)
reframing
T@"PIStillReframerConfiguration",R,N
v24@?0@"VNRequest"8@"NSError"16
subject%ld-%@
edgesKey
frameProvider
T@?,C,N,V_frameProvider
revision
Tq,R,N,V_revision
v8@?0
Invalid viewRect
Invalid cleanAperture
Invalid encodedPixelSize
PIVideoReframer is an abstract base class
defaultRevision
Tq,R
{CGRect={CGPoint=dd}{CGSize=dd}}
{CGPoint=dd}
viewRect
blobCentroid
blobRect
blobSubjects
subjectsReframed
tail
head
subjectsTracked
avgCameraMotionY
avgCameraMotionX
frameDominance
Td,V_frameDominance
cameraCorrelation
Td,V_cameraCorrelation
usedInReframing
TB,V_usedInReframing
  cameraCorrelation=%.2f
  frameDominance=%.2f
<%@ %p %@ id=%lu conf=%.2f>
velocity
T{CGVector=dd},V_velocity
acceleration
T{CGVector=dd},V_acceleration
isVirtualHead
TB,V_isVirtualHead
isVirtualTail
TB,V_isVirtualTail
Invalid revision
+[PIVideoReframer defaultConfigForRevision:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIVideoReframer.mm
0 && "unreachable"
+[PIApertureRedEyeProcessorKernel processWithInputs:arguments:output:error:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIApertureRedEyeFilter.mm
output.format == kCIFormatRGBAf
Sensitivity
+[PIApertureRedEyeProcessorKernel convertFixed16:toFloat:count:]
Bad fixed 16 to float conversion
+[PIApertureRedEyeProcessorKernel convertFloat:toFixed16:count:]
Bad float to fixed 16 conversion
inputSensitivity
capturedPortraitMajorVersion
capturedPortraitMinorVersion
portraitDisableStage
aperture
Tf,N,V_aperture
portraitStrength
Tf,N,V_portraitStrength
minimumAperture
T@"NSNumber",&,N,V_minimumAperture
maximumAperture
T@"NSNumber",&,N,V_maximumAperture
portraitMajorVersion
TQ,N,V_portraitMajorVersion
portraitMinorVersion
TQ,N,V_portraitMinorVersion
versionInfo
T{?=ii},N,V_versionInfo
<%@:%p aperture:%f minimumAperture: %@ maximumAperture: %@>
error != NULL
+[PIValuesAtCapture valuesAtCaptureFromImageProperties:error:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PIPortraitAutoCalculator.m
portraitLightingEffectStrength
Depth data version mismatch, asset has %@ but we can only handle %@
depthData:DepthDataVersion
Missing auxiliary metadata
Failed to load auxiliary data
Missing camera calibration data
Low quality depth data is not supported
Unfiltered depth data is not supported
Failed to load depth data
Portrait was previously applied
v16@?0@"NUResponse"8
-[PIPortraitAutoCalculator submit:]
capturedPortraitStrength
capturedAperture
metadata != nil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromCameraMetadata:]
faceObservations != nil
+[PIPortraitAutoCalculator portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:]
NUOrientationIsValid(orientation)
faceLandmarks
rightPupil
leftPupil
innerLips
outerLips
medianLine
noseCrest
nose
rightEyebrow
leftEyebrow
rightEye
leftEye
faceContour
allPoints
faceOrientationIndex
faceJunkinessIndex
faceBoundingBox
+[PIPortraitAutoCalculator depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:]
faces
focusRect
lumaNoiseScale
chinY
chinX
Insufficient number of landmark points
noseY
noseX
rightEyeY
rightEyeX
leftEyeY
leftEyeX
+[PIPortraitAutoCalculator portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:]
-[PIDepthEffectApertureAutoCalculator submit:]
+[PIPipelineFilters spatialOvercaptureVideoSourceFilter]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Adjustments/PIPipelineFilters.m
Could not construct overcaptureSourceFilter filter from inline source
return Source(composition.sourceSpatialOvercapture, {  })
+[PIPipelineFilters primarySourceFilter]
Could not construct primarySourceFilter filter from inline source
return Source(composition.source, { 'skipOrientation' : true })
+[PIPipelineFilters overcaptureSourceFilter]
return Source(composition.sourceSpatialOvercapture, { 'skipOrientation' : true })
+[PIPipelineFilters autoloopStabilizedVideoFilter]
Could not construct autoloopStabilizedVideoFilter filter from inline source
ResetTagInput('/AutoLoop/Output', GetTag('/AutoLoop/StabilizedVideo'));
return input;
+[PIPipelineFilters applyOrientationFilter]
Could not construct pipeline filter from source: %@
var output = input;
var orientation = composition.orientation;
if (orientation) {
    output = Orient(input, orientation.value);
return output;
+[PIPipelineFilters stopAtTagIncludeOrientationFilter:]
Could not construct stopAtTagIncludeOrientationFilter from inline source
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Orientation', tagNode);
return GetTag('/Orientation');
+[PIPipelineFilters stopAtTagIncludeGeometryFilter:]
Could not construct stopAtTagIncludeGeometryFilter from inline source
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Geometry', tagNode);
return GetTag('/post-Geometry');
/perspectiveStraighten
/post-Geometry
/pre-Geometry
+[PIPipelineFilters perspectiveStraightenWithoutCropFilter]
Could not construct perspectiveStraightenWithoutCropFilter filter from inline source
var preCrop = GetTag('/perspectiveStraighten');if (preCrop) {   ResetTagInput('/Crop', preCrop);
}return input;
+[PIPipelineFilters noGeometryFilter]
Could not construct noGeometry filter from inline source
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Geometry', preGeometry);
return input;
+[PIPipelineFilters stripAllTimeAdjustmentsFilter]
Could not construct stripAllTimeAdjustmentsFilter filter from inline source
var image = GetTag('pre-Trim');ResetTagInput('Trim', image);
image = GetTag('pre-SloMo');ResetTagInput('SloMo', image);
return input;
+[PIPipelineFilters iosCropToolFilter]_block_invoke
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Adjustments', preGeometry);
return input;
+[PIPipelineFilters noCropFilter]
Could not construct noCropFilter filter from inline source
var preCrop = GetTag('/pre-Crop');ResetTagInput('/pre-Orientation', preCrop);
return input;
+[PIPipelineFilters noMuteFilter]
Could not construct noMuteFilter filter from inline source
var preMute = GetTag('pre-Mute');ResetTagInput('Mute', preMute);
return GetTag('Image');
+[PIPipelineFilters noTrimFilter]
Could not construct noTrimFilter filter from inline source
var output = input
var preTrim = GetTag('/pre-Trim');ResetTagInput('/SloMo', preTrim);
let slomo = composition.slomo
if (slomo) {
    var startTime = TimeMake(slomo.start, slomo.startScale)
    var endTime = TimeMake(slomo.end, slomo.endScale)
    output = SloMo(input, startTime, endTime, slomo.rate)
return output;
+[PIPipelineFilters noRedEyeFilter]
Could not construct noRedEye filter from inline source
var source = GetTag('/pre-RedEye');ResetTagInput('/post-RedEye', source);
return GetTag('/post-RedEye');
var sourceSettings = { 'skipOrientation' : true }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
  return Source(composition.source, sourceSettings); 
} else {
  return GetTag("/ShowOriginalSource");
var sourceSettings = { }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
} else { throw "expected RAW in rawSourceFilterIncludingOrientation"; }
return Source(composition.source, sourceSettings); 
var sourceSettings = { 'skipOrientation': true };
var rawAdjustment = composition.raw
if (rawAdjustment) {
    sourceSettings['inputDecoderVersion'] = rawAdjustment.inputDecoderVersion
var image = Source(composition.source, sourceSettings)
var rawImage = GetTagInput('RAW/Linear')
if (rawImage) {
    image = rawImage
    image = Filter('PIForwardFakeBoost', {'inputImage' : image, 'inputBoost' : 1.0,})
var orientation = composition.orientation
if (orientation) { image = Orient(image, orientation.value) }
return image
var source = GetTag('/pre-Adjustments');
ResetTagInput('/pre-Crop', source);
source = GetTag('/Crop');
orientation = source.geometry.orientation;
source = Orient(source, orientation);
return source;
var tagNode = GetTag('/pre-Adjustments');
orientation = tagNode.geometry.orientation;
var node = Orient(tagNode, orientation);
return node;
+[PIPipelineFilters(Debug) socPseudoColorFilter]_block_invoke
let output = input;
var image = GetTag('pre-VideoReframe');
if (image) {
    var videoReframe = composition.videoReframe;
    if (videoReframe && videoReframe.enabled) {
        image = VideoReframe(image, videoReframe);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('VideoReframe', image);
    }
else { // image or live-photo { 
    var crop = composition.cropStraighten;
    var image = GetTag('pre-Crop');
    if (crop && crop.smart == 1 && image) {
        if (crop.pitch || crop.yaw) {
            var perspectiveTransform = PerspectiveTransformMake(crop.angle, crop.pitch, crop.yaw, image.geometry);
            image = Transform(image, perspectiveTransform);
        } else {
            var straightenTransform = StraightenTransformMake(crop.angle, image.geometry);
            image = Transform(image, straightenTransform);
        }
        // Apply the crop rect to the incoming image;
        image = Crop(image, crop.xOrigin, crop.yOrigin, crop.width, crop.height);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('Crop', image);
    }
return output;
colorType
faceStrength
faceWarmth
faceI
faceQ
grayStrength
grayWarmth
grayY
grayI
grayQ
warmTemp
warmTint
warmFace
warmTempKey
warmTintKey
warmFaceKey
none
T@"NSArray",R,C,N,V_keyframes
T{?={?=qq}{?=qq}},R,N,V_stabCropRect
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Reframer/PIVideoReframeRequest.m
%f,%f,%f,%f
-[PIVideoReframeRenderJob _createStabilizedKeyframesFromReframer:videoTrack:viewRect:timedMetadata:error:]
ABS(sx - sy) < 1e-4
rawTime
frameInstructions
Failure in ICCalcCinematicL1Corrections
l1 window stride
l1 window length
reframing transforms dict
Failure in ICSynthesizeAnalysis
homographies map to reference
homographies are inverted
corrections crop rect
invalid padded rect
ReframeRects.DBG
ReframeSubjects.DBG
confidenceThreshold
maxStabilizeCrop
vrfPostgateRecoveryImprovement
error != nil
-[PIVideoReframeRenderJob prepare:]
^{CGImage=}32@?0{?=qiIq}8
Invalid metadata in asset
Failed to initialize metadata extractor
depthInfo
T{?={?=qq}{?=qq}},N
recipe != nil
NSDictionary * _Nonnull PIAutoLoopRecipeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/AutoLoop/PIAutoLoop.m
CGRect PIAutoLoopRecipeGetCropRect(NSDictionary *__strong _Nonnull)
origin_y
origin_x
BOOL PIAutoLoopRecipeHasGoodStabilization(NSDictionary *__strong _Nonnull)
frameTransform != nil
CMTime PIAutoLoopRecipeFrameTransformGetTime(NSDictionary *__strong)
frameTransform_rawTime
matrix_float3x3 PIAutoLoopRecipeFrameTransformGetHomography(NSDictionary *__strong)
frameTransform_homography
NSDictionary * _Nonnull PIAutoLoopRecipeGetInstructionAtTime(NSDictionary *__strong _Nonnull, CMTime)
CMTIME_IS_VALID(time)
q24@?0@"NSDictionary"8@"NSDictionary"16
loopFrameData_presTime
loopRecipe_frameInstructions
CMTime PIAutoLoopRecipeGetFrameDuration(NSDictionary *__strong _Nonnull)
NSDictionary * _Nullable PIAutoLoopRecipeGetFlavorParameters(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
CMTimeRange PIAutoLoopRecipeGetTimeRangeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
-[PICurvesAutoCalculator computeCurvesForImageHistogram:]
/AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/PhotoImaging_Sim/PhotoImaging-3642.28.150/PhotoImaging/Autocalculators/PICurvesAutoCalculator.m
completion != nil
-[PICurvesAutoCalculator submit:]
pre-Curves
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
class %@ is not the correct type, its superclass should be %@
Continue: %{public}@
Trace: %{public}@
Fail: %{public}@
facerect yiq = %.5f, %.5f, %.5f
Buffer sizes are not the same: %{public}@ vs %{public}@
Buffer size is %@, bytes per row is %ld, dark_thr=%f, sat_thr=%f, noise_thr=%f
all done summing, np_gw is %d, np_ge is %d
wp_ge {%f, %f, %f, %f} wp_gw {%f, %f, %f, %f}, Sushi? %@
aperture=%@, shutterSpeed=%@, iso=%@
Brightness is %@, greenChannelPercentage is %f, Sushi: %@
Choosing gray world instead of gray edge
RGB = %f, %f, %f
YIQ = %f, %f, %f from %f, %f, %f
Failed to export video: %@
NUVideoRotationExportRequest failed. Error:%@
[PICompositionExporter shouldTryVideoRotationFastPath] failed. Error:%@
failed to render auxiliary image data: %@
Failed to prepare video metadata: %@
Failed to export image to data: %@
Failed to export image to %@: %@
invalid format version: %@
Requesting forced cleanup of Vision caches
Can PLPhotoEditPFDataConverter interpret identifier %@? %@. Version %@? %@
validation issue: recipe is blank on the autoloop adjustment
validation issue: no flavor specified on the autoloop adjustment
validation issue: Missing inputCorrectionInfo on a redeye adjustment
validation issue: Missing depthInfo on a depth adjustment
validation issue: Missing portraitInfo on a portrait adjustment
validation issue: invalid trim startTime or endTime
Writing long-exposure motion mask to %{public}@
Writing long-exposure image to %{public}@
waitUntilReadyForMoreData: waited for %0.1fms
High-resolution image registration failure : %@
Still image node:
Still image geometry:
Still image:
clap=%@, crop=%@, fullSize=%@, videoScale=%@ => guide rect: %@
Error creating asset reader: %@
Can't add metadata output for asset
Failed to start reading asset
Starting metadata extraction
Finished metadata extraction
Can't find enabled video track in asset: %@
Asset does not contain Live Photo metadata track
Track does not contain V3 metadata
[XMP metadata builder] Failed create data from XMP metadata %@
[XMP metadata builder] Failed to set value for dictionary name %{public}@ key %{public}@ value %{private}@
Missing inputImage
Missing inputMaskImage
Missing inputStillImage
Missing inputRenderScale
Missing inputVideoScale
Missing inputAlignmentExtent
Malformed inputAlignmentExtent vector
Missing inputAlignmentTransform
Malformed inputAlignmentTransform vector
Writing intermediate long exposure fusion images to : %@
Loading long-exposure fusion tuning parameters from file: %@
Failed to load fusion tuning parameters.
Using fusion tuning parameters: {kNCCBlurHalfSize=%d, kNCCEdge0=%f, kNCCEdge1=%f, kBlendMaskThreshold0=%f, kBlendMaskThreshold1=%f}
Received error while finalizing: %@
Starting reframe auto calculator
Starting horizon auto calculator
Starting perspective auto calculator
Skipping perspective auto calculator due to reframing occurring
Finished perspective auto calculator: %@
Finished horizon auto calculator: %@
Finished reframe auto calculator: %@
Beginning finalization for candidates: %@
Finalizer result contains keyframes: %@
Finalizer result contains reframed rect: (%f, %f, %f, %f) roll angle degrees: %f
Finalizer result contains roll angle degrees: %f pitch angle degrees: %f yaw angle degrees: %f
Finalizer result did not contain a change
Could not write PICropAutoCalculator debug diagnostics. %@
Failed to compute overcapture rect %@
Starting still reframe
Dominant subject: %@
Removing peripheral subject: %@
Adding wanted face: %@
Correcting for subject %@
Requesting forced clean up of Vision caches
Resetting reframed bounds (%@) to view bounds due to low confidence
Final reframe bounds are %@
Still reframe subjects: %@
Failed to apply red eye repair. error: %{public}@
Depth effects not supported: %@
Couldn't deserialize face observations from metadata: %@, assuming empty, error: %@.
Invalid face indexes from metadata: %@, ignored. Error: %@
Couldn't deserialize face observations from metadata: %@
Invalid focus rect: {%g,%g,%g,%g}
Metadata dictionary missing fullSizeWith or fullSizeHeight:
Metadata dictionary missing exif aux dictionary:
Exif aux dictionary missing MWG region dictionary:
MWG region dictionary missing region list:
Region list does not contain a focus rect:
Malformed focus rect dictionary:
PIVideoFrameRequest: not generating keyframes due to low reframing confidence: %f
s-curve black: %f
s-curve point %d: (%f, %f)
s-curve white: %f
red curve: blackPoint = %f, whitePoint = %f
green curve: blackPoint = %f, whitePoint = %f
blue curve: blackPoint = %f, whitePoint = %f
PIReframeRules
PISubjectCluster
PICompositionController
NSCopying
PICompositionSerializer
PICompositionSerializationResult
PICompositionSerializerMetadata
PIExpandedSubjectCalculatorConfiguration
PIExpandedSubjectCalculator
PIStillReframeRequest
PIStillReframeJob
_PIStillReframeResult
PIStillReframeResult
NURenderResult
NSObject
PIAutoCalculatorUtils
PIAutoLoopExportRequest
PIAutoLoopExportClient
PIAutoLoopAnalysisRequest
PIAutoLoopAnalysisClient
PILongExposureRegistrationRequest
PIZlibDataCompressionOptions
PIZlibDataDecompressionOptions
PIZlibDataCompression
PIAutoLoopAdjustmentController
PILivePhotoKeyFrameAdjustmentController
PIVignetteAdjustmentController
PIAdjustmentController
PIReframeAutoCalculator
PIFaceObservationCache
PISourceSelectAdjustmentController
PIReframeKeyframe
PIReframeKeyframeSequence
PILongExposureFusionAutoCalculator
PIEffectAdjustmentController
PIAutoLoopAutoCalculator
PIMakerNoteUtilities
PITempTintFilter
PIAutoLoopAnalysisResult
_PIAutoLoopAnalysisResult
PIAutoLoopAnalysisJob
PIFaceBalanceAutoCalculator
NUTimeBased
_PIWhiteColorCalculator
PIWhiteBalanceAutoCalculator
GrayColorResult
RGBResult
PIDefinitionFilter
PIReframeResult
PISmartBlackAndWhiteAdjustmentController
PICompositionExportImagePrepareResult
PICompositionExportResult
PICompositionExportAuxiliaryResult
PICompositionExportDataResult
PICompositionExporterOptions
PICompositionExporterVideoOptions
PICompositionExporterImageOptions
PICompositionExporterAuxiliaryOptions
PICompositionExporter
GUBilateralConvolution
GUBWBilateralConvolution
PIBilateralFilter
PIPhotoEditAdjustmentsVersion
PINoiseReductionAdjustmentController
PIPortraitAdjustmentController
PICompositionNoOpRemoval
PIOrientationAdjustmentController
PIDefinitionAdjustmentController
PIReframeSubject
NSSecureCoding
NSCoding
PIPerspectiveAutoCalculator
PIFaceObservingAutoCalculator
PIRawNoiseReductionAdjustmentController
PICropAdjustmentController
PIRawAdjustmentController
PISmartToneAdjustmentController
PIAutoLoopKernels
PIPhotoEditHelper
PIAdjustmentConstants
PIForwardFakeBoost
PIInverseFakeBoost
PICoreImageUtilities
PICompositionSerializerConstants
PILongExposureAccumulator
PILongExposureRegistrationResult
_PILongExposureRegistrationResult
PILongExposureRegistrationJob
PIRAWTempTintSampler
PITagColorSampler
PIRedEye
PIVideoPosterFrameAdjustmentController
PICompositionSerializerFormatVersion
PIVideoReframeTimedMetadata
PIVideoReframeMetadataExtractor
PICaptureDebugUtilities
PISlomoAdjustmentController
PIRAWFaceBalance
PICurvesLUTFilter
PICurvesFilter
PIColorBalanceFilter
PIHighResFusionAdjustmentController
PIGlobalSettings
PIAutoLoopExportJob
PIJSRenderPipeline
PhotosPipeline
PIClusterPoint
PIApertureRedEyeAutoCalculator
PIMsgImageBuffer
PISmartBlackAndWhiteAutoCalculator
PITrimAdjustmentController
PIRedEyeAdjustmentController
PILevelsAutoCalculator
PILevelsLuminanceAutoCalculator
PILevelsRGBAutoCalculator
PIExportMetadataBuilder
PIExportImageMetadataBuilder
PIExportVideoMetadataBuilder
PIExportXMPMetadataBuilder
AdjustmentExtensions
PICurveControlPoint
PILongExposureFusion
PILevelsFilter
PISchema
PICompositionFinalizer
PICompositionFinalizerResult
PICropAutoCalculator
Utilities
PISmartColorAdjustmentController
PISelectiveColorFilter
PIVideoReframePipelineStateSetting
PIVideoReframeNode
PINeutralGrayWhiteBalanceFilter
PISmartToneAutoCalculator
PISmartColorAutoCalculator
PIRedEyeAutoCalculator
PIManualRedEyeAutoCalculator
PISourceSampler
PIImageIO
PIStillReframerConfiguration
PIStillReframer
PISharpenAdjustmentController
PIVideoReframer
PIVideoReframerV1
PIVideoReframeDebugSubjectV1
PIVideoReframeDebugSubject
PIVideoReframerV2
PIVideoReframeDebugSubjectV2
PIApertureRedEyeProcessorKernel
PIApertureRedEyeFilter
PIValuesAtCapture
PIPortraitAutoCalculator
PIDepthEffectApertureAutoCalculator
PIPipelineFilters
Debug
PIWhiteBalanceAdjustmentController
PIVideoReframeRenderJob
_PIVideoReframeResult
PIVideoReframeResult
PIVideoReframeRequest
PIDepthAdjustmentController
PIVideoReframeAdjustmentController
PICurvesAutoCalculator
PICurvesLuminanceAutoCalculator
PICurvesRGBAutoCalculator
isCandidateForReframe
isCandidateForPerspective
isCandidateForHorizon
gradeForFact:
factCandidateForHorizon
factCandidateForPerspective
factCandidateForReframe
factCandidateForStill
factCandidateForVideo
sharedPregateRules
pregateRulesSystemWithConstants:
addRulesFromArray:
setConstants:
setEnableLogging:
initWithArray:
retractFact:
addObject:
ruleWithPredicate:retractingFact:grade:
predicateWithFormat:
ruleWithPredicate:assertingFact:grade:
ruleWithPredicate:action:
initWithCapacity:
_salientObject
_saliencyScale
_body
_direction
_mutablePoints
_centerPoint
initWithBody:face:saliencyScale:
initSalientClusterWithCenterPoint:saliencyScale:
initWithBody:direction:saliencyScale:
description
shouldAllowPoint:
expandedSubject
points
addPoint:
addPointsFromCluster:
boundingBox
body
direction
centerPoint
mutablePoints
saliencyScale
isSalientObject
.cxx_destruct
countByEnumeratingWithState:objects:count:
copy
stringWithFormat:
subjectForExpansionWithSaliencyScale:startingSubject:
directionForBody:face:
_composition
_delegateFlags
_identifierMap
_changeDelegate
_mediaType
_imageOrientation
copyWithZone:
initWithComposition:
composition
setChangeDelegate:
compositionKeys
availableKeys
addAdjustmentWithKey:
replaceAdjustment:withKey:
removeAdjustmentWithKey:
adjustmentControllerForKey:
modifyAdjustmentWithKey:modificationBlock:
applyChangesFromCompositionController:
isEqual:visualChangesOnly:
isEqual:forKeys:visualChangesOnly:
isEqual:forKeys:comparisonBlock:
debugDescription
differingAdjustmentsWithComposition:
userOrientation
sourceSelection
setSourceSelection:
setOvercaptureSource:
_adjustmentControllerClassForKey:
setSource:mediaType:
setMediaType:
changeDelegate
mediaType
imageOrientation
setImageOrientation:
isSubclassOfClass:
compositionController:adjustmentControllerClassForKey:
adjustmentControllerClassForKey:
arrayWithObjects:count:
alloc
boolValue
_keyToIdentifierMap
integerValue
containsObject:
allKeys
schema
isEqualToString:
compositionController:didUpdateAdjustments:
compositionController:didUpdateAdjustment:
reset
initWithIdentifier:
compositionController:didRemoveAdjustment:
compositionController:didAddAdjustment:
addObjectsFromArray:
contents
schemaForKey:
settingForAdjustmentKey:settingKey:
photosSchema
schemaWithIdentifier:
sharedRegistry
initialize
disableApertureEffects:
canInterpretDataWithFormatIdentifier:formatVersion:
deserializeCompositionFromData:formatIdentifier:formatVersion:error:
validateCompositionWithMissingSource:error:
deserializeCompositionFromAdjustments:metadata:formatIdentifier:formatVersion:error:
serializeComposition:versionInfo:error:
serializeComposition:versionInfo:serializerMetadata:error:
validateAdjustmentsEnvelope:error:
_validateValueTypesForKeys:requiredKeys:inDictionary:error:
serializeDictionary:error:
deserializeDictionaryFromData:error:
_sanitizeComposition:
componentsJoinedByString:
callStackSymbols
errorWithDomain:code:userInfo:
dictionaryWithObjects:forKeys:count:
JSONObjectWithData:options:error:
dataWithJSONObject:options:error:
enumerateKeysAndObjectsUsingBlock:
initWithDomain:code:userInfo:
setWithArray:
setData:
setFormatVersion:
setFormatIdentifier:
_data
_formatIdentifier
_formatVersion
data
formatIdentifier
formatVersion
numberWithInt:
numberWithBool:
setWithObjects:
array
orientation
height
numberWithInteger:
width
handleFailureInMethod:object:file:lineNumber:description:
currentHandler
stringWithUTF8String:
setOrientation:
setHeight:
setWidth:
size
_width
_height
_orientation
initWithName:
stringByAppendingString:
validateComposition:error:
URLWithString:
_useRegressedSaliencyBoxes
_denistyThreshold
_neighborhoodOffset
_saliencyThreshold
_saliencyDeltaThreshold
_initialSaliencyValue
_unionIOUThreshold
_clusterToRegressedRatio
_regressedConfidenceThreshold
_highSaliencyThreshold
_interSalientObjectDistance
_maxSalientObjectsCount
_salientClusterConvergenceMaxDistance
denistyThreshold
setDenistyThreshold:
neighborhoodOffset
setNeighborhoodOffset:
saliencyThreshold
setSaliencyThreshold:
saliencyDeltaThreshold
setSaliencyDeltaThreshold:
initialSaliencyValue
setInitialSaliencyValue:
useRegressedSaliencyBoxes
setUseRegressedSaliencyBoxes:
unionIOUThreshold
setUnionIOUThreshold:
clusterToRegressedRatio
setClusterToRegressedRatio:
regressedConfidenceThreshold
setRegressedConfidenceThreshold:
highSaliencyThreshold
setHighSaliencyThreshold:
interSalientObjectDistance
setInterSalientObjectDistance:
maxSalientObjectsCount
setMaxSalientObjectsCount:
salientClusterConvergenceMaxDistance
setSalientClusterConvergenceMaxDistance:
defaultConfiguration
saliencyRevisionOneConfiguration
_expandedSubjects
_configuration
_detectedSubjects
_saliencyData
_subjectDirection
_saliencyImageObservation
_regressedSalientSubjects
initWithDetectedSubjects:saliencyData:configuration:
initWithDetectedSubjects:cgImage:
initWithDetectedSubjects:ciImage:ciContext:configuration:
neighborsForPoint:
closestClusterForPoint:fromClusters:
clusterPoints:intoClusters:
findBestStartingPointForStartingPoint:
findSalientPointsWithSaliencyScale:outsideOfSubjectsRect:
expandedSubjects
configuration
detectedSubjects
saliencyData
subjectDirection
setSubjectDirection:
saliencyImageObservation
regressedSalientSubjects
consolidateCandidateSalientClusters:maxDistance:
removeAllObjects
arrayWithArray:
removeObject:
floatValue
objectAtIndexedSubscript:
unionSet:
setWithSet:
anyObject
salientSubjectsWithImageRequestHandler:
saliencyDataForSaliencyObservation:
saliencyObservationWithImageRequestHandler:
initWithCIImage:options:
initWithCGImage:options:
performRequests:error:
initWithCompletionHandler:
salientObjects
firstObject
results
setPrivateRevision:error:
numberWithFloat:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
fileURLWithPath:
context
initWithCVPixelBuffer:
timeIntervalSince1970
boolForKey:
standardUserDefaults
pixelBuffer
_scalePolicy
newRenderJob
mediaComponentType
submit:
scalePolicy
setScalePolicy:
submitGeneric:
initWithStillReframeRequest:
_reframeResult
initWithRequest:
stillReframeRequest
wantsOutputImage
wantsOutputGeometry
wantsCompleteStage
cacheKey
render:
result
cleanUp
reframeResult
setReframeResult:
setSaliencyObservation:
saliencyObservation
setANODSubjects:
ANODSubjects
setConfidence:
confidence
setBounds:
bounds
_confidence
_saliencyObservation
_ANODSubjects
_bounds
statistics
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
writeToURL:atomically:
URLByAppendingPathComponent:
outputGeometry
setPipelineFilters:
stringValue
finalize
nu_updateDigest:
renderNode
stringByAppendingFormat:
oneToOneScalePolicy
convertFacePoint:toImagePointWithFaceRect:orientation:
averagePoints:pointCount:
averageCGPoints:pointCount:
handleFailureInFunction:file:lineNumber:description:
_destinationUTI
_destinationLongExposureURL
_destinationMaskURL
initWithComposition:destinationURL:
initWithComposition:stabilizedVideoURL:longExposureDestinationURL:maskDestinationURL:destinationUTI:
outputColorSpace
destinationUTI
destinationLongExposureURL
destinationMaskURL
sRGBColorSpace
colorSpaceFromVideoColorProperties:
objectForKey:
outputSettings
setCompletionBlock:
submitRequest:
submitGenericRequest:
setGenericCompletionBlock:
_flavor
flavor
setFlavor:
_recipe
_cleanAperture
recipe
setRecipe:
cleanAperture
setCleanAperture:
_compressionLevel
_strategy
_windowBits
_memoryLevel
_chunkSize
setCompressionLevel:
setCompressionStrategy:
compressionLevel
strategy
setStrategy:
windowBits
setWindowBits:
memoryLevel
setMemoryLevel:
chunkSize
setChunkSize:
defaultOptions
_decompressAllAtOnce
_createBuffer
_growData
setCreateBuffer:
setGrowData:
createBuffer
growData
decompressAllAtOnce
setDecompressAllAtOnce:
increaseLengthBy:
length
dataWithLength:
compressData:options:error:
decompressData:options:error:
dataWithData:
setLength:
mutableBytes
dictionary
init
raise:format:
stabilizedCropRect
flavorKey
recipeKey
doubleValue
initWithAdjustment:
keyFrameTime
setKeyFrameTime:
scaleKey
timeKey
numberWithLongLong:
intValue
longLongValue
intensity
setIntensity:
radius
setRadius:
falloff
setFalloff:
falloffKey
numberWithDouble:
radiusKey
intensityKey
_changes
_identifier
_adjustment
displayName
displayInputKeys
inputKeys
settingForKey:
hasInputKey:
enabled
setEnabled:
canBeEnabled
canHaveAuto
hasAutoKeyInSchema
isAuto
setIsAuto:
objectForKeyedSubscript:
setObject:forKeyedSubscript:
setValue:forUndefinedKey:
valueForUndefinedKey:
valuesForArrayInputKey:
setFromAdjustment:
interpolateFromStart:toEnd:progress:
timeFromInputKey:timescaleKey:
visualInputKeys
isEqual:forKeys:
isSettingEqual:forKey:
_setPrimitiveValue:forKey:
_primitiveValueForKey:
settings
_isDefault
identifier
setIdentifier:
adjustment
defaultValue
valueForKey:
setValue:forKey:
isEqualToValue:
values
autoKey
enabledKey
name
reframeStillWithCompletion:
reframeVideoWithCompletion:
initWithError:
initWithResult:
valueWithBytes:objCType:
result:
dictionaryWithDictionary:
unsupportedError:object:
_group
_queue
_result
submit:response:
submitSynchronous:error:
submitGenericSynchronous:
faceRequestWithRequest:
initWithTargetPixelCount:
sourceSelectionKey
stringForSourceSelection:
sourceSelectionForString:
_time
_homography
initWithTime:homography:
initWithDictionaryRepresentation:
dictionaryRepresentation
time
homography
mutableCopy
count
_homographySequence
initWithKeyframeArray:
interpolation
homographyAtTime:
sparseSequence
sampleAtTime:
initWithCount:times:values:
_computeCleanAperture:
stopAtTagFilter:
setName:
setKind:
kind
setVersion:
version
versionKey
kindKey
addAssetIdentifier:toMetadataDictionary:
addAssetIdentifier:toMetadataArray:
removeAssetIdentifierFromMetadataArray:
removeObjectAtIndex:
indexOfObjectPassingTest:
setValue:
metadataItem
_inputImage
_temperature
_tint
outputImage
setInputVectorsForFilter:
inputImage
setInputImage:
temperature
setTemperature:
tint
setTint:
vectorWithX:Y:Z:W:
filterWithName:
_videoSource
wantsOutputVideo
analysisRequest
prepare:
videoSource
setVideoSource:
asset:
missingError:object:
_rawState
setTime:
initWithRequest:isRAW:
rawState
rawProperties
calculateRAWWithRequest:completion:
calculateWithRequest:completion:
faceBalanceResultFromFaceObservations:request:error:
faceRectFromNormalizedFaceRet:forImageExtent:scaleX:scaleY:
faceBalanceFromFaceImage:forFaceRect:
readBufferRegion:withBlock:
bytesAtPoint:
frameRect
buffer
validRegion
BGRA8
RGBA8
isEqualToPixelFormat:
ARGB8
maximumValue
minimumValue
errorWithCode:reason:object:underlyingError:
setResponseQueue:
setRegionPolicy:
initWithRect:
addRect:
imageSize
faces
initWithRequest:dataExtractor:options:
_bufferRenderClient
_imageDataClient
_useSushi
initWithComposition:useSushi:
readBufferFromImage:withRGBAfBufferBlock:
calculateColorWithProperties:completion:
_brightnessMultiplierFromImageProperties:
_computeWhitePointColorWithGrayEdgesBuffer:grayWorldBuffer:greenChannelPercentage:RAWCameraSpaceProperties:
_whitePointColorFromGrayEdgesImage:grayWorldImage:greenChannelPercentage:RAWCameraSpaceProperties:
_configureRequest:
_computeGreenPercentage:
_submitGWRenderRequest:
_submitGERenderRequest:
initWithScript:
initWithSource:
submitRequest:completion:
initWithComposition:dataExtractor:options:
setTileSize:
genericRGBLinearColorSpace
setPixelFormat:
RGBAh
whiteFactor
whiteValue
rowBytes
metadata
commitAndNotifyOnQueue:withBlock:
pi_valueWithGrayColorResult:
rawCameraSpaceProperties
begin
returnStorage:
writeBufferInRegion:block:
regionWithRect:
newStorageWithSize:format:
RGBAf
bufferFactory
sharedFactory
initWithName:responseQueue:
_useTempTint:
_correctedRGBResultFromResult:
_chooseNeutralGrayForNonSushi:
_chooseTempTintForSushi:RAWProperties:brightness:
inputNeutralXYFromRGB:
valueWithRGBResult:
responseQueue
pi_grayColorResultValue
getValue:
RGBResultValue
definitionKernel
kernelWithString:
_inputBlurImage
_inputIntensity
inputBlurImage
setInputBlurImage:
inputIntensity
setInputIntensity:
imageByPremultiplyingAlpha
applyWithExtent:arguments:
imageByUnpremultiplyingAlpha
initWithBounds:confidence:ANODSubjects:saliencyObservation:
strengthKey
neutralKey
toneKey
grainKey
hueKey
inputStrengthKey
inputNeutralGammaKey
inputToneKey
inputGrainKey
inputHueKey
inputSeedKey
attributeStrengthKey
attributeNeutralGammaKey
attributeToneKey
attributeHueKey
attributeGrainKey
setStrength:
strength
setNeutral:
neutral
setTone:
tone
setGrain:
grain
setHue:
_request
_inputSize
request
setRequest:
inputSize
setInputSize:
_geometry
geometry
setGeometry:
_companionImageData
_companionVideoURL
_auxiliaryImages
_properties
companionImageData
setCompanionImageData:
companionVideoURL
setCompanionVideoURL:
auxiliaryImages
setAuxiliaryImages:
properties
setProperties:
_priority
_colorSpace
_pairingIdentifier
priority
setPriority:
colorSpace
setColorSpace:
pairingIdentifier
setPairingIdentifier:
displayP3ColorSpace
initWithLevel:
_increaseBitRateIfNecessary
_bypassOutputSettingsIfNoComposition
_metadataProcessor
metadataProcessor
setMetadataProcessor:
increaseBitRateIfNecessary
setIncreaseBitRateIfNecessary:
bypassOutputSettingsIfNoComposition
setBypassOutputSettingsIfNoComposition:
_optimizeForSharing
_imageExportFormat
setImageExportFormatJpegWithQuality:
imageExportFormatForURL:
imageExportFormat
setImageExportFormat:
optimizeForSharing
setOptimizeForSharing:
defaultFormatForURL:
setCompressionQuality:
_renderCompanionResources
_primaryURL
_videoComplementURL
_videoPosterFrameURL
_reframeCropAdjustment
_reframeVideoAdjustment
primaryURL
setPrimaryURL:
videoComplementURL
setVideoComplementURL:
videoPosterFrameURL
setVideoPosterFrameURL:
renderCompanionResources
setRenderCompanionResources:
reframeCropAdjustment
setReframeCropAdjustment:
reframeVideoAdjustment
setReframeVideoAdjustment:
exportImageToURL:composition:options:completion:
exportImageToDataWithComposition:options:completion:
exportVideoToURL:composition:options:completion:
exportComposition:toPrimaryURL:videoComplementURL:videoPosterFrameURL:completionQueue:completion:
exportComposition:options:completionQueue:completion:
variationForFlavor:
prepareImageExportRequest:options:completion:
prepareAuxiliaryImagesFetchProperties:options:completion:
addImageProperties:composition:options:error:
_prepareToExportVideo:options:completion:
addVideoProperties:composition:options:error:
shouldTryVideoRotationFastPath:options:
_exportVideoToURL:composition:options:metadata:progress:completion:
_exportVideoToURLFull:composition:options:metadata:progress:completion:
submitWithProgress:completion:
setOutputSettings:
CGColorSpace
setObject:forKey:
setBitRateMultiplicationFactor:
setMetadata:
videoMetadataForVariation:error:
metadataConverter
invalidError:object:
setPhotoFeatureFlags:properties:error:
numberWithUnsignedInteger:
unsignedIntegerValue
photoFeatureFlags:error:
numberWithShort:
setPhotoProcessingFlags:properties:error:
photoProcessingFlagsFromProperties:error:
setImageVariation:properties:error:
auxiliaryImage
setAuxiliaryImageType:
auxiliaryImagesProperties
setCoreGraphicsInfoDictionariesByAuxiliaryType:
dictionaryRepresentationForAuxiliaryDataType:
setImageProperties:
unknownError:object:
resetImageProperties:preserveRegions:
numberWithUnsignedInt:
URLByAppendingPathComponent:isDirectory:
stringByAppendingPathExtension:
pathExtension
stringByDeletingPathExtension
lastPathComponent
URLForDirectory:inDomain:appropriateForURL:create:error:
defaultManager
UUIDString
UUID
discreteProgressWithTotalUnitCount:
destinationData
setFormat:
setRenderToData:
setDestinationURL:
setMetadataConverter:
removeObjectForKey:
bilateralKernels
RGBToLabKernels
bilateralAdd1Kernel
bilateralAdd2Kernel
bilateralAdd3Kernel
bilateralAdd4Kernel
bilateralAdd5Kernel
bilateralAdd6Kernel
bilateralAdd7Kernel
bilateralAdd8Kernel
bilateralAdd9Kernel
bilateralFinalizeKernel
RGBToLabKernel
LabToRGBKernel
_inputPoints
_inputWeights
_inputEdgeDetail
_inputVersion
samplesPerPass
boundsForPointArray:
enlargedBounds:withPoints:
bilateralAddROI:destRect:userInfo:
doBilateralPass:points:weights:sums:slope:
inputPoints
setInputPoints:
inputWeights
setInputWeights:
inputEdgeDetail
setInputEdgeDetail:
inputVersion
setInputVersion:
subarrayWithRange:
samplerWithImage:options:
vectorWithX:Y:Z:
vectorWithX:Y:
applyWithExtent:roiCallback:arguments:
objectAtIndex:
unionWith:
definition
shapeWithRect:
BWBilateralKernels
bilateralLoop2Kernel
bilateralLoop5Kernel
bilateralLoop11Kernel
_inputBorder
bilateralROI:destRect:userInfo:
doBilateralLoop:points:weights:slope:
inputBorder
setInputBorder:
samplerWithImage:
customAttributes
dictionaryWithObjectsAndKeys:
_inputRadius
inputRadius
setInputRadius:
arrayWithCapacity:
_majorVersion
_minorVersion
_subMinorVersion
_platform
initWithMajor:minor:subMinor:platform:
initWithMajor:minor:subMinor:
string
asOrderedInteger
compare:
isEqualToAdjustmentVersion:
majorVersion
minorVersion
subMinorVersion
platform
caseInsensitiveCompare:
versionWithMajor:minor:subMinor:platform:
versionFromString:
rangeOfCharacterFromSet:
invertedSet
decimalDigitCharacterSet
componentsSeparatedByString:
amountKey
_version
setPortraitInfo:
portraitInfo
canRenderPortraitEffect
portraitInfoKey
_noOpRemovalFunctions
noOpRemovalFunctions
copyOfAdjustmentRemovingNoOps:identifier:
copyOfCompositionRemovingNoOps:
valueKey
imageWithCGImage:
imageByApplyingTransform:
imageByCompositingOverImage:
_type
_source
_edgeBleed
_expandedBounds
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithType:source:identifier:confidence:
isHuman
isAnimal
type
source
expandedBounds
setExpandedBounds:
edgeBleed
setEdgeBleed:
stringByReplacingOccurrencesOfString:withString:
decodeObjectForKey:
decodeDoubleForKey:
decodeIntegerForKey:
encodeObject:forKey:
encodeDouble:forKey:
encodeInteger:forKey:
allocWithZone:
appendFormat:
appendString:
labels
_disableOnPanos
_disableOnFrontFacingCameraImages
_shouldRunDetectorsIfNecessary
_shouldRunBuildingCheck
_debugFilesEnabled
_faceObservationCache
_maxAutoYaw
_maxAutoPitch
_maxAutoAngle
_minimumPitchCorrection
_minimumYawCorrection
_minimumAngleCorrection
_minimumConfidence
_maxFaceSize
_minimumPitchCorrectionArea
_minimumYawCorrectionArea
_minSalientArea
_maxSalientSubjectArea
_angleSeedDegreesCCW
_debugFilesPrefix
_debugDiagnostics
_debugLineDetectionImage
faceObservationCache
setFaceObservationCache:
perspectiveErrorFromCoreImage:
addMethodDiagnostics:details:
addMethodResultToDiagnostics:error:setYawPitchError:
wrapAsUnexpectedError:
writeDebugDiagnosticsToDisk
getSizeOfAllFaces:
passesFaceCheck:
hasFrontFacingCameraDimentions:
isFrontFacingCameraImage:pixelSize:
passesImagePropertiesCheck:
passesBuildingCheck:
passesSaliencyCheck:
overcaptureImageProperties:
primaryImageProperties:
canGenerateNewCropRect:
passesConfidenceCheck:error:
passesMinimumCorrectionCheck:error:
submitVerified:
maxAutoYaw
setMaxAutoYaw:
maxAutoPitch
setMaxAutoPitch:
maxAutoAngle
setMaxAutoAngle:
minimumPitchCorrection
setMinimumPitchCorrection:
minimumYawCorrection
setMinimumYawCorrection:
minimumAngleCorrection
setMinimumAngleCorrection:
minimumConfidence
setMinimumConfidence:
maxFaceSize
setMaxFaceSize:
minimumPitchCorrectionArea
setMinimumPitchCorrectionArea:
minimumYawCorrectionArea
setMinimumYawCorrectionArea:
disableOnPanos
setDisableOnPanos:
disableOnFrontFacingCameraImages
setDisableOnFrontFacingCameraImages:
shouldRunDetectorsIfNecessary
setShouldRunDetectorsIfNecessary:
shouldRunBuildingCheck
setShouldRunBuildingCheck:
minSalientArea
setMinSalientArea:
maxSalientSubjectArea
setMaxSalientSubjectArea:
angleSeedDegreesCCW
setAngleSeedDegreesCCW:
debugFilesEnabled
setDebugFilesEnabled:
debugFilesPrefix
setDebugFilesPrefix:
debugDiagnostics
debugLineDetectionImage
setDebugLineDetectionImage:
undoOrientation:forPitch:yaw:angle:
null
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
dataWithBytes:length:
defaultFocalLength
setRollAngle:constrainCropRectWithTargetArea:
initWithMasterImageSize:
initWithMasterImageSize:stitchedImageSize:
isFusedOvercapture
setComposition:
nonLocalizedFailureReason
observations
containsString:
hasPrefix:
PNGRepresentationOfImage:format:colorSpace:options:
contextWithOptions:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
userInfo
requestVisionCleanUp
requestForcedCleanup
luminanceKey
shortValue
isGeometryIdentityForImageSize:
isCropConstrained
isCropIdentityForImageSize:
cropRect
constraintWidth
constraintHeight
angle
angleRadians
pitch
pitchRadians
yawRadians
autoCropped
isSmart
isOriginalCrop
setCropRect:
setConstraintWidth:
setConstraintHeight:
setAngle:
setAngleRadians:
setPitch:
setPitchRadians:
setYaw:
setYawRadians:
setAutoCropped:
setSmart:
setOriginalCrop:
originalCropKey
smartKey
heightKey
widthKey
yOriginKey
xOriginKey
yawKey
pitchKey
angleKey
constraintHeightKey
constraintWidthKey
setInputDecoderVersion:
inputDecoderVersion
_smartSettings
_updateSettingsWithInputLight:
computedSettings
setInputLight:
inputLight
setInputExposure:
inputExposure
setInputBrightness:
inputBrightness
setInputContrast:
inputContrast
setInputShadows:
inputShadows
setInputHighlights:
inputHighlights
setInputBlack:
inputBlack
setInputLocalLight:
inputLocalLight
setInputRawHighlights:
inputRawHighlights
setStatistics:
setOvercaptureStatistics:
overcaptureStatistics
offsetBlack
setOffsetBlack:
offsetBrightness
setOffsetBrightness:
offsetContrast
setOffsetContrast:
offsetExposure
setOffsetExposure:
offsetHighlights
setOffsetHighlights:
offsetLocalLight
setOffsetLocalLight:
offsetShadows
setOffsetShadows:
offsetShadowsKey
offsetLocalLightKey
offsetHighlightsKey
offsetExposureKey
offsetContrastKey
offsetBrightnessKey
offsetBlackKey
overcaptureStatisticsKey
statisticsKey
inputRawHighlightsKey
inputLocalLightKey
inputBlackKey
inputHighlightsKey
inputShadowsKey
inputContrastKey
inputBrightnessKey
inputExposureKey
inputLightKey
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
attributeBrightnessKey
attributeContrastKey
attributeExposureKey
attributeHighlightsKey
attributeShadowsKey
attributeBlackPointKey
attributeLocalLightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLightMapHeightKey
alphaCompositingKernel
dynamismMapKernel
longExposureFusionKernels
dynamismMapRefineKernel
rgbToLumaKernel
homographyKernel
nccKernel
nccCoarseKernel
blur7x7Kernel
blur5x5Kernel
blur3x3Kernel
fusionKernel
assetIdentifierForURL:type:useEmbeddedPreview:
imageSourceWithURL:type:useEmbeddedPreview:
imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:
imageSourceWithCIImage:orientation:
videoSourceWithURL:
livePhotoSourceWithPhotoSource:videoSource:
newComposition
newAdjustmentWithName:
newAdjustmentWithIdentifier:
newImageRenderClientWithName:
geometryRequestWithComposition:
imagePropertiesRequestWithComposition:
videoPropertiesRequestWithComposition:
imageRenderRequestWithComposition:fitInSize:wideGamut:
imageRenderRequestWithComposition:fillInSize:wideGamut:
_imageRenderRequestWithComposition:wideGamut:
newCGImageFromBufferImage:
priorityWithLevel:
videoRenderRequestWithComposition:fitInSize:wideGamut:
is3DEffect:
isPortraitEffect:
isPortraitStageEffect:
effectNameForFilterName:
filterNameForEffectName:
pipelineFiltersForCropping
pipelineFiltersForOriginalGeometry
pipelineFiltersForShowingOriginalWithGeometry
pipelineFiltersForRAWShowingOriginalWithGeometry
newCompositionControllerWithComposition:
adjustmentConstants
validatedCompositionCopyForComposition:mediaType:
knownFormatsVersionsMap
updateCropAdjustmentController:after:error:
preheatEditDependencies
prepareForPerformingRequestsOfClass:error:
initWithCVPixelBuffer:options:
PIMuteAdjustmentKey
PITrimAdjustmentKey
PIPortraitAdjustmentKey
PIDepthAdjustmentKey
PIRedEyeAdjustmentKey
PIAutoLoopAdjustmentKey
_PISmartToneAdjustmentKey
_PISmartColorAdjustmentKey
_PISmartBWAdjustmentKey
_PIGrainAdjustmentKey
_PIAutoEnhanceAdjustmentKey
_PIWhiteBalanceAdjustmentKey
_PIRedEyeAdjustmentKey
_PIApertureRedEyeAdjustmentKey
_PIRetouchAdjustmentKey
_PIVignetteAdjustmentKey
_PISharpenAdjustmentKey
_PINoiseReductionAdjustmentKey
_PIDefinitionAdjustmentKey
_PICurvesAdjustmentKey
_PILevelsAdjustmentKey
_PISelectiveColorAdjustmentKey
_PIEffectAdjustmentKey
_PIEffect3DAdjustmentKey
_PICropAdjustmentKey
_PITrimAdjustmentKey
_PISlomoAdjustmentKey
_PILivePhotoKeyFrameAdjustmentKey
_PIVideoPosterFrameAdjustmentKey
_PIAutoLoopAdjustmentKey
_PIHighResFusionAdjustmentKey
_PIMuteAdjustmentKey
_PIDepthAdjustmentKey
_PIPortraitAdjustmentKey
_PIOrientationAdjustmentKey
_PIRawAdjustmentKey
_PIRawNoiseReductionAdjustmentKey
_PIVideoReframeAdjustmentKey
_PISourceSelectAdjustmentKey
_PISourceAdjustmentKey
_PIOvercaptureSourceAdjustmentKey
allAdjustmentTypes
nonVisualAdjustmentTypes
PISmartToneAdjustmentKey
PISmartColorAdjustmentKey
PISmartBWAdjustmentKey
PIGrainAdjustmentKey
PIAutoEnhanceAdjustmentKey
PIWhiteBalanceAdjustmentKey
PIApertureRedEyeAdjustmentKey
PIRetouchAdjustmentKey
PIVignetteAdjustmentKey
PISharpenAdjustmentKey
PINoiseReductionAdjustmentKey
PIDefinitionAdjustmentKey
PICurvesAdjustmentKey
PILevelsAdjustmentKey
PISelectiveColorAdjustmentKey
PIEffectAdjustmentKey
PIEffect3DAdjustmentKey
PICropAdjustmentKey
PISlomoAdjustmentKey
PILivePhotoKeyFrameAdjustmentKey
PIVideoPosterFrameAdjustmentKey
PIHighResFusionAdjustmentKey
PIOrientationAdjustmentKey
PIRawAdjustmentKey
PIRawNoiseReductionAdjustmentKey
PIVideoReframeAdjustmentKey
PISourceSelectAdjustmentKey
PISourceAdjustmentKey
PIOvercaptureSourceAdjustmentKey
allValues
initWithTargetSize:
setExtentPolicy:
setResolvedSourceDefinition:
initWithImageSourceDefinition:videoSourceDefinition:
resolvedSourceDefinition
setAssetIdentifier:
assetIdentifier
initWithSourceDefinitions:
initWithURL:UTI:
initWithCIImage:orientation:
setUseEmbeddedPreview:
absoluteString
timeIntervalSinceReferenceDate
getResourceValue:forKey:error:
addEntriesFromDictionary:
kernel
_inputBoost
inputBoost
setInputBoost:
kernelsDictionaryWithString:
kernelsWithString:
conversionMap
mapForSerialization
base64EncodedStringWithOptions:
initWithBase64EncodedString:options:
_pixelSize
_renderer
_temporaryDestinationStorage
_averageAccumulationStorage
_minimumAccumulationStorage
_maximumAccumulationStorage
_frameCount
_stateQueue
_accumQueue
_accumSemaphore
_readySemaphore
_doneGroup
_inputFrames
_finished
_imageOptions
__accumError
initWithSize:renderer:
dealloc
workingColorSpace
cancel
start:
_initializeStorage:image:error:
isReadyForMoreData
_isReadyForMoreData
markAsFinished
_markAsFinished
waitUntilDone
accumulate:error:
_appendInputFrame:
nextInputFrame
_nextInputFrame
_start
_initializeAccumulation
_initializeAccumulation:
_accumulate:
_accumulate:error:
writeLongExposureImage:UTI:colorSpace:error:
writeMaskImage:UTI:error:
_dynamismMapWithMinImage:maxImage:extent:
_exportOutputImage:format:colorSpace:toURL:uti:error:
_accumError
set_accumError:
failureError:object:
createCGImage:fromRect:format:colorSpace:deferred:
extent
imageByClampingToExtent
useAsCIImageWithOptions:renderer:block:
useAsCIRenderDestinationWithRenderer:block:
renderImage:rect:toDestination:atPoint:error:
imageByApplyingFilter:withInputParameters:
componentMin
componentMax
imageWithCVPixelBuffer:options:
CVPixelBuffer
imageWithColor:
colorWithRed:green:blue:colorSpace:
canceledError:object:
sRGBLinearColorSpace
surfaceStoragePool
observation
_observation
_extent
setObservation:
setExtent:
_stillImage
_guideExtent
wantsRenderScaleClampedToNativeScale
registrationRequest
newRenderPipelineStateForEvaluationMode:
guideExtent
setGuideExtent:
stillImage
setStillImage:
errorWithCode:reason:object:
initWithTargetedCVPixelBuffer:options:
waitUntilCompletedAndReturnError:
initWithPixelBuffer:
newPixelBufferOfSize:format:
imageByCroppingToRect:
imageByColorMatchingWorkingSpaceToColorSpace:
renderScale
videoProperties:
prepareNode
outputImage:
outputImageGeometry:
nodeByReplayingAgainstCache:error:
setScale:
prepareNodeWithPipelineState:error:
_shouldWaitForDependentJobs
initWithComposition:responseQueue:
_pipelineFilters
initWithComposition:tag:responseQueue:
_inputDestinationImage
_inputCorrectionInfo
_inputCameraModel
inputDestinationImage
setInputDestinationImage:
inputCorrectionInfo
setInputCorrectionInfo:
inputCameraModel
setInputCameraModel:
posterFrameTime
setPosterFrameTime:
locallySupportedFormatVersions
currentFormatVersion
_versionRules
versionRules
formatVersionForAdjustment:identifier:
adjustmentDataFormatVersionForComposition:
indexOfObject:
_subjects
_estimatedCenterMotion
_estimatedMotionBlur
_trajectoryHomography
setSubjects:
setEstimatedCenterMotion:
setEstimatedMotionBlur:
setTrajectoryHomography:
subjects
estimatedCenterMotion
estimatedMotionBlur
trajectoryHomography
_asset
_videoTrack
_mdataTrack
ndcMetadataTransform
pxlMetadataTransform
timedMetadataArray
initWithAVAsset:
overwriteTrackingMetadataWithPlist:
subjectsFromMetadata:
centerMotionVectorFromMetadata:
motionBlurVectorFromMetadata:
trajectoryeHomographyFromMetadata:containsV3Metadata:
extractMetadata
dataValue
dataType
items
nextTimedMetadataGroup
startReading
initWithAssetReaderTrackOutput:
addOutput:
canAddOutput:
initWithTrack:outputSettings:
assetReaderWithAsset:error:
initWithContentsOfFile:
encodedPixelSizeOfTrack:oriented:
formatDescriptions
tracks
firstEnabledVideoTrackInAsset:error:
exceptionWithName:reason:userInfo:
captureDebugDirectoryForComposition:
sourceDefinitions
startTime
setStartTime:
endTime
setEndTime:
rate
setRate:
rateKey
endScaleKey
endKey
startScaleKey
startKey
bytesPerPixel
initWithSize:format:
mutableBytesAtPoint:
RG16
faceBalanceKernels
linearWideGamutColorSpace
_inputOrigI
_inputOrigQ
_inputStrength
_inputWarmth
inputOrigI
setInputOrigI:
inputOrigQ
setInputOrigQ:
inputStrength
setInputStrength:
inputWarmth
setInputWarmth:
imageByColorMatchingColorSpaceToWorkingSpace:
_inputPointsR
_inputPointsG
_inputPointsB
_inputPointsL
inputPointsR
setInputPointsR:
inputPointsG
setInputPointsG:
inputPointsB
setInputPointsB:
inputPointsL
setInputPointsL:
tableImageFromRed:green:blue:luminance:
calculateCurveTable:
curvePointsFromDictionaries:
initWithImageProvider:width:height:format:colorSpace:options:
initWithLength:
_inputTableImage
inputTableImage
setInputTableImage:
curvesKernel
colorBalanceKernels
gHDRtoPPKernel
PPtogHDRKernel
colorBalanceKernel
_inputWarmTemp
_inputWarmTint
_inputHasFace
_inputIsRaw
applyInputConversion:
applyOutputConversion:
inputWarmTemp
setInputWarmTemp:
inputWarmTint
setInputWarmTint:
inputHasFace
setInputHasFace:
inputIsRaw
setInputIsRaw:
alignment
setAlignment:
alignmentKey
_settings
decoratorRenderFiltersForImages
decoratorRenderFiltersForVideos
globalSettings
initWithAutoLoopExportRequest:
initWithVideoExportRequest:
autoLoopExportRequest
renderer:
metalRenderer
shouldUseMetalRenderer
initWithMetalDevice:options:
boolSettingForKey:defaultValue:
setUpContext:
toRect
initWithNode:context:
node
toDictionary
setError:
isObject
contextForContext:
currentContext
jsContext
newPhotosPipelineAtSourceURL:error:
initWithURL:
newPhotosPipeline:
bundleForClass:
URLForResource:withExtension:
_value
_point
initWithCGPoint:value:
distanceFromPoint:
isEqualToPoint:
point
value
_faceRequest
apertureRedEyeResultFromFaceObservations:imageSize:
normalizedPoints
pointCount
rightEye
leftEye
landmarks
cancelAllRequests
renderContext
elementByteSize
rowElements
format
bufferColorspace
initWithBytes:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithData:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
bytes
image
dataWithBytesNoCopy:length:freeWhenDone:
_calculateBlackAndWhiteSettingsFromBufferImage:
initWithTargetPixelSize:
CIFormat
hasCorrections
inputCorrectionInfoKey
calculateSettingsForImageHistogram:
calculateSettingsForSingleChannelHistogram:suffix:
percentile:
histogram
luminance
blue
green
_creationDate
_creationTimeZone
_caption
_title
_keywords
_peopleNames
_location
setCreationDate:timeZone:
title
setTitle:
caption
setCaption:
keywords
setKeywords:
peopleNames
setPeopleNames:
location
setLocation:
creationDate
creationTimeZone
combinedKeywordsAndPeople
setCreationDate:
setCreationTimeZone:
defaultTimeZone
_iptcMutableDictionary
_exifMutableDictionary
_tiffMutableDictionary
_updateCreationDate
iptcDictionary
exifDictionary
tiffDictionary
iptcMutableDictionary
setIptcMutableDictionary:
exifMutableDictionary
setExifMutableDictionary:
tiffMutableDictionary
setTiffMutableDictionary:
secondsFromGMT
_exifTimeZoneOffsetFormatter
_exifSubsecTimeFormatter
_exifDateTimeFormatter
stringFromDate:
setTimeZone:
iptcTimeFormatter
iptcDateFormatter
_dateFormatterTemplate
_gpsTimeFormatter
_gpsDateFormatter
gpsDictionaryForLocation:
course
speed
horizontalAccuracy
altitude
verticalAccuracy
timestamp
coordinate
setDateFormat:
timeZoneForSecondsFromGMT:
setCalendar:
calendarWithIdentifier:
setLocale:
localeWithLocaleIdentifier:
setFormatOptions:
setDateStyle:
setTimeStyle:
commonItemForKey:string:
titleItem
captionItem
locationItem
creationDateItem
videoDateFormatter
keywordsItem
metadataItems
setKey:
setKeySpace:
iso6709Notation
xmpCreateDateFormatter
xmpData
trimAdjustmentController
slomoAdjustmentController
effectAdjustmentController
effect3DAdjustmentController
portraitAdjustmentController
orientationAdjustmentController
autoLoopAdjustmentController
highResFusionAdjustmentController
rawNoiseReductionAdjustmentController
sharpenAdjustmentController
whiteBalanceAdjustmentController
noiseReductionAdjustmentController
definitionAdjustmentController
vignetteAdjustmentController
videoReframeAdjustmentController
sourceSelectAdjustmentController
smartToneAdjustmentControllerCreatingIfNecessary:
_adjustmentControllerForKey:creatingIfNecessary:expectedClass:
smartColorAdjustmentControllerCreatingIfNecessary:
smartBWAdjustmentControllerCreatingIfNecessary:
cropAdjustmentControllerCreatingIfNecessary:
redEyeAdjustmentControllerCreatingIfNecessary:
livePhotoKeyFrameAdjustmentControllerCreatingIfNecessary:
videoPosterFrameAdjustmentControllerCreatingIfNecessary:
depthAdjustmentControllerCreatingIfNecessary:
trimAdjustmentControllerCreatingIfNecessary:
slomoAdjustmentControllerCreatingIfNecessary:
effectAdjustmentControllerCreatingIfNecessary:
effect3DAdjustmentControllerCreatingIfNecessary:
portraitAdjustmentControllerCreatingIfNecessary:
orientationAdjustmentControllerCreatingIfNecessary:
autoLoopAdjustmentControllerCreatingIfNecessary:
highResFusionAdjustmentControllerCreatingIfNecessary:
rawNoiseReductionAdjustmentControllerCreatingIfNecessary:
sharpenAdjustmentControllerCreatingIfNecessary:
whiteBalanceAdjustmentControllerCreatingIfNecessary:
noiseReductionAdjustmentControllerCreatingIfNecessary:
definitionAdjustmentControllerCreatingIfNecessary:
vignetteAdjustmentControllerCreatingIfNecessary:
videoReframeAdjustmentControllerCreatingIfNecessary:
sourceSelectAdjustmentControllerCreatingIfNecessary:
smartToneAdjustmentController
smartColorAdjustmentController
smartBWAdjustmentController
cropAdjustmentController
redEyeAdjustmentController
livePhotoKeyFrameAdjustmentController
videoPosterFrameAdjustmentController
depthAdjustmentController
_editable
initWithX:y:editable:
initWithDictionary:
isEditable
_inputStillImage
_inputMaskImage
_inputRenderScale
_inputVideoScale
_inputAlignmentExtent
_inputAlignmentTransform
alignImage:transform:extent:
_computeNCCMapFromImage:toImage:scale:
_refineMaskImage:guideImage:scale:
_fuseImage:withGuideImage:weightImage:maskImage:
inputStillImage
setInputStillImage:
inputMaskImage
setInputMaskImage:
inputRenderScale
setInputRenderScale:
inputVideoScale
setInputVideoScale:
inputAlignmentExtent
setInputAlignmentExtent:
inputAlignmentTransform
setInputAlignmentTransform:
imageByApplyingTransform:highQualityDownsample:
applyWithExtent:roiCallback:inputImage:arguments:
writeToTIFF:
currentDirectoryPath
debugDumpIntermediateImages
valueAtIndex:
CGRectValue
loadFusionTuningParameters
_debugDumpIntermediateImages
dictionaryWithContentsOfFile:
stringSettingForKey:defaultValue:
P3Kernel
defaultValueForKey:
_customAttributesForKey:
_inputBlackSrcRGB
_inputBlackDstRGB
_inputShadowSrcRGB
_inputShadowDstRGB
_inputMidSrcRGB
_inputMidDstRGB
_inputHilightSrcRGB
_inputHilightDstRGB
_inputWhiteSrcRGB
_inputWhiteDstRGB
_inputBlackSrcRed
_inputBlackDstRed
_inputShadowSrcRed
_inputShadowDstRed
_inputMidSrcRed
_inputMidDstRed
_inputHilightSrcRed
_inputHilightDstRed
_inputWhiteSrcRed
_inputWhiteDstRed
_inputBlackSrcGreen
_inputBlackDstGreen
_inputShadowSrcGreen
_inputShadowDstGreen
_inputMidSrcGreen
_inputMidDstGreen
_inputHilightSrcGreen
_inputHilightDstGreen
_inputWhiteSrcGreen
_inputWhiteDstGreen
_inputBlackSrcBlue
_inputBlackDstBlue
_inputShadowSrcBlue
_inputShadowDstBlue
_inputMidSrcBlue
_inputMidDstBlue
_inputHilightSrcBlue
_inputHilightDstBlue
_inputWhiteSrcBlue
_inputWhiteDstBlue
_inputColorSpace
setDefaults
floatValueForKey:defaultValue:clearIfNotDefault:
_LUTImage
inputBlackSrcRGB
setInputBlackSrcRGB:
inputBlackDstRGB
setInputBlackDstRGB:
inputShadowSrcRGB
setInputShadowSrcRGB:
inputShadowDstRGB
setInputShadowDstRGB:
inputMidSrcRGB
setInputMidSrcRGB:
inputMidDstRGB
setInputMidDstRGB:
inputHilightSrcRGB
setInputHilightSrcRGB:
inputHilightDstRGB
setInputHilightDstRGB:
inputWhiteSrcRGB
setInputWhiteSrcRGB:
inputWhiteDstRGB
setInputWhiteDstRGB:
inputBlackSrcRed
setInputBlackSrcRed:
inputBlackDstRed
setInputBlackDstRed:
inputShadowSrcRed
setInputShadowSrcRed:
inputShadowDstRed
setInputShadowDstRed:
inputMidSrcRed
setInputMidSrcRed:
inputMidDstRed
setInputMidDstRed:
inputHilightSrcRed
setInputHilightSrcRed:
inputHilightDstRed
setInputHilightDstRed:
inputWhiteSrcRed
setInputWhiteSrcRed:
inputWhiteDstRed
setInputWhiteDstRed:
inputBlackSrcGreen
setInputBlackSrcGreen:
inputBlackDstGreen
setInputBlackDstGreen:
inputShadowSrcGreen
setInputShadowSrcGreen:
inputShadowDstGreen
setInputShadowDstGreen:
inputMidSrcGreen
setInputMidSrcGreen:
inputMidDstGreen
setInputMidDstGreen:
inputHilightSrcGreen
setInputHilightSrcGreen:
inputHilightDstGreen
setInputHilightDstGreen:
inputWhiteSrcGreen
setInputWhiteSrcGreen:
inputWhiteDstGreen
setInputWhiteDstGreen:
inputBlackSrcBlue
setInputBlackSrcBlue:
inputBlackDstBlue
setInputBlackDstBlue:
inputShadowSrcBlue
setInputShadowSrcBlue:
inputShadowDstBlue
setInputShadowDstBlue:
inputMidSrcBlue
setInputMidSrcBlue:
inputMidDstBlue
setInputMidDstBlue:
inputHilightSrcBlue
setInputHilightSrcBlue:
inputHilightDstBlue
setInputHilightDstBlue:
inputWhiteSrcBlue
setInputWhiteSrcBlue:
inputWhiteDstBlue
setInputWhiteDstBlue:
inputColorSpace
setInputColorSpace:
applyWithExtent:roiCallback:arguments:options:
displayP3LinearColorSpace
samplerWithImage:keysAndValues:
sourceSelectSchema
rawSchema
rawNoiseReductionSchema
smartToneSchema
smartColorSchema
smartBlackAndWhiteSchema
grainSchema
sharpenSchema
cropSchema
trimSchema
slomoSchema
livePhotoKeyFrameSchema
muteSchema
videoPosterFrameSchema
autoLoopSchema
highResFusionSchema
depthEffectSchema
effect3DSchema
portraitEffectSchema
effectSchema
redEyeSchema
apertureRedEyeSchema
retouchSchema
vignetteSchema
orientationSchema
definitionSchema
noiseReductionSchema
whiteBalanceSchema
levelsSchema
curvesSchema
selectiveColorSchema
videoReframeSchema
photosCompositionSchema
registeredPhotosSchemaIdentifier
registerPhotosSchema
registerRenderPipeline:forIdentifier:
registerSchemas:error:
renderPipelineForIdentifier:
deserializeFromDictionary:error:
numberWithLong:
_candidacy
_finalizerError
_performedActions
_rollAngleDegrees
_pitchAngleDegrees
_yawAngleDegrees
_keyframes
_reframeRect
_stabCropRect
performNextActionWithCompletion:
shouldPerformAction:
hasPerformedAction:
markActionAsPerformed:
performReframeWithCompletion:
performHorizonCorrectionWithCompletion:
performPerspectiveCorrectionWithCompletion:
processStillReframeResult:
processVideoReframeResult:
processHorizonResult:
processPerspectiveResult:
candidacy
setCandidacy:
finalizerError
setFinalizerError:
performedActions
setPerformedActions:
reframeRect
setReframeRect:
rollAngleDegrees
setRollAngleDegrees:
pitchAngleDegrees
setPitchAngleDegrees:
yawAngleDegrees
setYawAngleDegrees:
keyframes
setKeyframes:
stabCropRect
setStabCropRect:
getValue:size:
floatForKey:
initWithDisposition:composition:
_disposition
disposition
getCropRectThatCompletelyContainsMasterImageForPitch:yaw:roll:
descriptionForCandidacy:
_shouldPerformAutoCrop
_shouldPerformAutoStraighten
_shouldUseAutoStraightenVerticalDetector
_autoStraightenVerticalAngleThreshold
_autoStraightenDominantAngleDiffThreshold
_maxAutoStraighten
_minAutoStraighten
imageProperties:
undoExifOrientation:error:
shouldPerformAutoCrop
setShouldPerformAutoCrop:
shouldPerformAutoStraighten
setShouldPerformAutoStraighten:
shouldUseAutoStraightenVerticalDetector
setShouldUseAutoStraightenVerticalDetector:
autoStraightenVerticalAngleThreshold
setAutoStraightenVerticalAngleThreshold:
autoStraightenDominantAngleDiffThreshold
setAutoStraightenDominantAngleDiffThreshold:
maxAutoStraighten
setMaxAutoStraighten:
minAutoStraighten
setMinAutoStraighten:
overcaptureRectForStitchedOvercaptureSize:overcaptureVideoComplementSize:primarySize:autoLoopStabilizedCropRect:
stitchedOvercaptureRect:primaryRect:forComposition:error:
initWithMasterImageRect:stitchedImageRect:
setRollRadians:
integralCropRect:
updateCropAdjustment:after:error:
_stats
_updateSettingsWithInputColor:
setInputColor:
inputColor
setInputSaturation:
inputSaturation
setInputCast:
inputCast
setOffsetCast:
offsetCast
setOffsetSaturation:
offsetSaturation
offsetSaturationKey
offsetCastKey
inputCastKey
inputSaturationKey
inputColorKey
attributeVibrancyKey
attributeCastKey
_inputCorrections
hueSatLumTable
inputCorrections
setInputCorrections:
convertFromIPT:
selectiveColorKernels
convertToIPT:
iptHueAngleFromRed:green:blue:
colorWithRed:green:blue:alpha:colorSpace:
iptFromLinearInto:fromRed:green:blue:
hueAngleFrom:
_sampleMode
nu_evaluateWithPipelineState:error:
sampleMode
setSampleMode:
_keyframeSequence
_inputVideoProperties
_frameDuration
initWithKeyframes:stabCropRect:input:
initWithSettings:inputs:
shouldCacheNodeForPipelineState:
resolvedNodeWithCachedInputs:settings:pipelineState:error:
requiresVideoComposition
_evaluateVideoProperties:
_evaluateImageGeometry:
_evaluateImage:
_stabilizeImage:cleanRect:cropRect:transform:geometry:
keyframeSequence
setKeyframeSequence:
inputVideoProperties
setInputVideoProperties:
frameDuration
setFrameDuration:
scaledSize
vectorWithCGPoint:
inputForKey:
initWithExtent:renderScale:orientation:
inputs
setSize:
initWithProperties:
outputVideoComposition:
evaluationMode
RGBToYIQKernel
YIQToRGBKernel
whiteBalanceKernel
_strength
_warmth
isDefaultWarmth:
warmth
setWarmth:
setY:
setI:
setQ:
vectorWithX:
setDataExtractor:
submitSynchronous:
_force
_options
force
setForce:
setOptions:
options
internalComposition
initWithRequest:options:
_touchDiameter
initWithComposition:location:touchDiameter:
writeImage:fileURL:
writeCGImage:fileURL:
writeCGImage:fileURL:options:
writeImage:toTemporaryDirectoryWithBasename:
writeImage:toDirectoryAtPath:withBasename:
stringByAppendingPathComponent:
path
buildNumber
currentSoftwareVersion
_humanFaceBoundsContainmentThreshold
_humanBodyBoundsContainmentThreshold
_humanBodyExpandedBoundsContainmentThreshold
_humanBodyBoundsContainmentCoefficient
_petBoundsContainmentThreshold
_petExpandedBoundsContainmentThreshold
_petBoundsContainmentCoefficient
_facePaddingFactor
_bodyPaddingAmount
_overscanPercentageAllowed
_unwantedSubjectStartingThreshold
_unwantedSubjectInclusionThreshold
_dominantToPeripheralSubjectRatioThreshold
_minimumCorrectionThreshold
humanFaceBoundsContainmentThreshold
setHumanFaceBoundsContainmentThreshold:
humanBodyBoundsContainmentThreshold
setHumanBodyBoundsContainmentThreshold:
humanBodyExpandedBoundsContainmentThreshold
setHumanBodyExpandedBoundsContainmentThreshold:
humanBodyBoundsContainmentCoefficient
setHumanBodyBoundsContainmentCoefficient:
petBoundsContainmentThreshold
setPetBoundsContainmentThreshold:
petExpandedBoundsContainmentThreshold
setPetExpandedBoundsContainmentThreshold:
petBoundsContainmentCoefficient
setPetBoundsContainmentCoefficient:
facePaddingFactor
setFacePaddingFactor:
bodyPaddingAmount
setBodyPaddingAmount:
overscanPercentageAllowed
setOverscanPercentageAllowed:
unwantedSubjectStartingThreshold
setUnwantedSubjectStartingThreshold:
unwantedSubjectInclusionThreshold
setUnwantedSubjectInclusionThreshold:
dominantToPeripheralSubjectRatioThreshold
setDominantToPeripheralSubjectRatioThreshold:
minimumCorrectionThreshold
setMinimumCorrectionThreshold:
_shouldAttemptReframe
_sceneContainsPet
_sceneContainsHuman
_sceneContainsMultipleSubjects
_mutableSubjects
_ruleSystem
_overscanBounds
_viewBounds
initWithConfiguration:expandedSubjectConfiguration:overscanBounds:viewBounds:image:
initWithConfiguration:overscanBounds:viewBounds:subjects:
evaluationData
invalidateCaches
calculateReframedRect
canIncludeSubject:boundsPercentageInside:expandedBoundsPercentageInside:
clamppedSubjectBoundsForEdgeBleed:
candidateRectForSubject:
amountOfOverscanUsedByRect:
shouldAllowCandidateRect:forUnwantedSubjects:
confidenceWithBounds:
overscanBounds
viewBounds
shouldAttemptReframe
mutableSubjects
ruleSystem
sceneContainsPet
setSceneContainsPet:
sceneContainsHuman
setSceneContainsHuman:
sceneContainsMultipleSubjects
setSceneContainsMultipleSubjects:
setStateObject:forKey:
state
keyForSubjectWithIndex:prefix:
evaluate
addRule:
arrayByAddingObjectsFromArray:
sortedArrayUsingComparator:
archivedDataWithRootObject:requiringSecureCoding:error:
subjectDirectionForImageOrientation:
detectedSubjectsForImage:context:
initWithOptions:
edgesKey
session
encodedPixelSize
pixelRect
clapRect
viewRect
processGroup
_frameProvider
_revision
initWithEncodedPixelSize:orientation:clapRect:viewRect:config:
setFrameProvider:
startReframingAtTime:
updateWithTrackedSubjects:atTime:
updateWithEstimatedCameraMotion:atTime:
finishReframingAtTime:
processReframe:completion:
reframedViewRectAtTime:
frameProvider
revision
.cxx_construct
defaultRevision
defaultConfigForRevision:
reframerWithRevision:encodedPixelSize:orientation:clapRect:viewRect:config:
v1Session
debugSceneSegments
debugReframeSegments
debugKeyframes
debugSubjectsAtTime:
debugCameraMotionAtTime:
setWithCapacity:
_usedInReframing
_frameDominance
_cameraCorrelation
frameDominance
setFrameDominance:
cameraCorrelation
setCameraCorrelation:
usedInReframing
setUsedInReframing:
_velocity
_acceleration
velocity
setVelocity:
acceleration
setAcceleration:
v2Session
debugRawReframedViewRectAtTime:
debugCenterOfInterestAtTime:
_isVirtualHead
_isVirtualTail
isVirtualHead
setIsVirtualHead:
isVirtualTail
setIsVirtualTail:
ROIForCenterPoint:radius:
convertFloat:toFixed16:count:
convertFixed16:toFloat:count:
processWithInputs:arguments:output:error:
roiForInput:arguments:outputRect:
formatForInputAtIndex:
outputFormat
copyPixelsFromImage:srcRect:destImage:destOrigin:
initWithMutableBuffer:colorSpace:validRegion:
initWithBuffer:colorSpace:validRegion:
initWithSize:format:rowBytes:bytes:
initWithSize:format:rowBytes:mutableBytes:
RGBA16
region
bytesPerRow
baseAddress
inputSpots
applyWithExtent:inputs:arguments:error:
vectorWithCGRect:
pointValue
_aperture
_portraitStrength
_minimumAperture
_maximumAperture
_portraitMajorVersion
_portraitMinorVersion
_versionInfo
aperture
setAperture:
portraitStrength
setPortraitStrength:
minimumAperture
setMinimumAperture:
maximumAperture
setMaximumAperture:
portraitMajorVersion
setPortraitMajorVersion:
portraitMinorVersion
setPortraitMinorVersion:
versionInfo
setVersionInfo:
valuesAtCaptureFromImageProperties:error:
depthBlurEffectSimulatedAperture
getMinMaxSimulatedApertureFrom:minValue:maxValue:version:
depthBlurEffectRenderingParameters
auxiliaryCoreGraphicsInfoDictionary:
cameraCalibrationData
depthDataQuality
isDepthDataFiltered
underlyingAVDepthData
auxiliaryImage:
unsignedIntValue
_calculateWithImageProperties:valuesAtCapture:completion:
portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
isStillImageDisparity:
focusRectDictionaryFromMetadata:
focusRectDictionaryFromRect:
canApplyPortraitEffectsWithMetadata:
depthEffectInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:
portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:
portraitInfoDictionaryFromCameraMetadata:
luminanceNoiseAmplitude
apertureFocalRatio
maximumApertureFocalRatio
minimumApertureFocalRatio
focusRectangle
faceOrientation
objectsAtIndexes:
indexesOfShallowDepthOfFieldObservations
unarchivedObjectOfClasses:fromData:error:
faceObservationsData
roll
faceOrientationIndex
faceJunkinessIndex
allPoints
nose
autoCropFilter
exifOrientationAndCropStraightenOnly
rawFaceBalanceFilter
rawSourceFilterIncludingOrientation
sourceFilterNoOrientation
sushiLevel1Filter
noRedEyeFilter
noTrimFilter
noMuteFilter
noCropFilter
iosCropToolFilter
stripAllTimeAdjustmentsFilter
noGeometryFilter
perspectiveStraightenWithoutCropFilter
preGeometryFilter
postGeometryFilter
inputToCropFilter
stopAtTagIncludeGeometryFilter:
stopAtTagIncludeOrientationFilter:
applyOrientationFilter
autoloopStabilizedVideoFilter
overcaptureSourceFilter
primarySourceFilter
spatialOvercaptureVideoSourceFilter
socPseudoColorFilter
colorType
setColorType:
faceStrength
setFaceStrength:
faceWarmth
setFaceWarmth:
faceI
setFaceI:
faceQ
setFaceQ:
grayStrength
setGrayStrength:
grayWarmth
setGrayWarmth:
grayY
setGrayY:
grayI
setGrayI:
grayQ
setGrayQ:
warmTemp
setWarmTemp:
warmTint
setWarmTint:
warmFace
setWarmFace:
warmFaceKey
warmTintKey
warmTempKey
tintKey
temperatureKey
grayQKey
grayIKey
grayYKey
grayWarmthKey
grayStrengthKey
faceQKey
faceIKey
faceWarmthKey
faceStrengthKey
colorTypeKey
stringForColorType:
colorTypeForString:
wantsRenderStage
videoReframeRequest
_writeDiagnosticFilesForReframer:metadata:
_createStabilizedKeyframesFromReframer:videoTrack:viewRect:timedMetadata:error:
_createKeyframesFromReframer:videoTrack:viewRect:timedMetadata:error:
initWithKeyframes:confidence:stabCropRect:
nominalFrameRate
UTF8String
cleanApertureOfTrack:oriented:
writeToURL:error:
lastObject
copyCGImageAtTime:actualTime:error:
setAppliesPreferredTrackTransform:
setRequestedTimeToleranceAfter:
setRequestedTimeToleranceBefore:
setApertureMode:
initWithAsset:
videoOrientationForAssetPreferredTransform:
preferredTransform
outputVideo
canRenderDepth
setDepthInfo:
depthInfo
capturedAperture
depthInfoKey
apertureKey
copyKeyframesTrimmingToTimeRange:
stabCropRectKey
keyframesKey
indexOfObject:inSortedRange:options:usingComparator:
uniqueInputNode
dictionariesFromPoints:
_defaultCurveArray
autoValuesForBlackPoint:whitePoint:
replaceObjectAtIndex:withObject:
computeCurvesForImageHistogram:
setParameters:
setColorMatrix:
curvePointAtIndex:blackPoint:whitePoint:histogram:
insertObject:atIndex:
B16@0:8
@16@0:8
@24@0:8@16
@"PIReframeSubject"
@"NSMutableSet"
{CGPoint="x"d"y"d}
@36@0:8@16@24f32
@36@0:8{CGPoint=dd}16f32
@36@0:8@16Q24f32
B32@0:8{CGPoint=dd}16
v24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
Q16@0:8
{CGPoint=dd}16@0:8
f16@0:8
v16@0:8
@28@0:8f16@20
Q32@0:8@16@24
@"NUComposition"
{?="hasDidAdd"B"hasDidRemove"B"hasDidModify"B"hasDidModifyMultiple"B"hasClassForController"B}
@"NSDictionary"
@"<PICompositionControllerDelegate>"
@24@0:8^{_NSZone=}16
v32@0:8@16@24
v32@0:8@16@?24
B28@0:8@16B24
B36@0:8@16@24B32
B40@0:8@16@24@?32
q16@0:8
v24@0:8q16
#24@0:8@16
v32@0:8@16q24
@32@0:8@16@24
v20@0:8B16
B32@0:8@16@24
@48@0:8@16@24@32o^@40
B32@0:8@16o^@24
@56@0:8@16@24@32@40o^@48
@40@0:8@16@24o^@32
B48@0:8@16@24@32o^@40
@32@0:8@16o^@24
@"NSData"
@"NSString"
v24@0:8Q16
d16@0:8
v24@0:8d16
@"NSArray"
@"PIExpandedSubjectCalculatorConfiguration"
@"VNSaliencyImageObservation"
@40@0:8@16@24@32
@32@0:8@16^{CGImage=}24
@48@0:8@16@24@32@40
@32@0:8{CGPoint=dd}16
@52@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20
v32@0:8@16d24
@"<NUScalePolicy>"
v24@0:8@?16
@"PIReframeResult"
B24@0:8o^@16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@"VNSaliencyImageObservation"16@0:8
@"NSArray"16@0:8
@"<NURenderStatistics>"16@0:8
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8@"Protocol"16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
@"NSString"16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGPoint=dd}72@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32q64
{CGPoint=dd}32@0:8r^{CGPoint=dd}16Q24
@"NSURL"
@56@0:8@16@24@32@40@48
{?="origin"{?="x"q"y"q}"size"{?="width"q"height"q}}
{?={?=qq}{?=qq}}16@0:8
v48@0:8{?={?=qq}{?=qq}}16
v20@0:8i16
i16@0:8
@?16@0:8
@40@0:8@16@24^@32
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
@"NSMutableDictionary"
@"NUIdentifier"
@"NUAdjustment"
v40@0:8@16@24d32
{?=qiIq}32@0:8@16@24
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_queue>"
@"<NUFaceDetectionResult>"
q24@0:8@16
@24@0:8q16
{?="value"q"timescale"i"flags"I"epoch"q}
{?="columns"[3]}
@88@0:8{?=qiIq}16{?=[3]}40
{?=[3]}16@0:8
@"NUKeyframeSequenceMatrixFloat33"
{?=[3]}40@0:8{?=qiIq}16
@"CIImage"
@"NSDictionary"16@0:8
@"AVAsset"
@28@0:8@16B24
{?={?=qq}{?=qq}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?={?=qq}{?=qq}}48d80d88
{?=ddd}56@0:8@16{?={?=qq}{?=qq}}24
@"NUBufferRenderClient"
@"NUImageDataClient"
{?={?=[4d]}{?=[4d]}d}48@0:8@16@24d32@40
B48@0:8{?=[4d]}16
{?=[4d]}48@0:8{?=[4d]}16
{?=[4d]}88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=dd}104@0:8{?={?=[4d]}{?=[4d]}d}16@88d96
{?={?=[4d]}{?=[4d]}d}16@0:8
@88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=[4d]}16@0:8
@48@0:8{?=[4d]}16
@"NSNumber"
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48@56@64
@"NUImageExportRequest"
{?="width"q"height"q}
{?=qq}16@0:8
v32@0:8{?=qq}16
@"NUImageGeometry"
@"NUPriority"
@"NUColorSpace"
@"NUImageExportFormat"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
@48@0:8@16@24@32@?40
@64@0:8@16@24@32@40@48@?56
@48@0:8@16@24@32^@40
v64@0:8@16@24@32@40@48@?56
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@48@0:8Q16Q24Q32@40
@40@0:8Q16Q24Q32
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8q16q24q32d40
@"PIFaceObservationCache"
@"PIFaceObservationCache"16@0:8
v24@0:8@"PIFaceObservationCache"16
v36@0:8@16@24B32
f24@0:8@16
B32@0:8{?=qq}16
B40@0:8@16{?=qq}24
@24@0:8o^@16
v48@0:8q16^d24^d32^d40
B32@0:8{CGSize=dd}16
{?="exposure"d"contrast"d"brightness"d"shadows"d"highlights"d"black"d"rawHighlights"d"localLight"d}
@36@0:8@16@24B32
@52@0:8@16@24@32q40B48
@32@0:8@16q24
@44@0:8@16{CGSize=dd}24B40
^{CGImage=}24@0:8@16
@"<NURenderer>"
@"<NUSurfaceStorage>"
@"NSObject<OS_dispatch_semaphore>"
@"NSMutableArray"
@"NSError"
@40@0:8{?=qq}16@32
B40@0:8@16@24o^@32
@64@0:8@16@24{?={?=qq}{?=qq}}32
B60@0:8@16i24^{CGColorSpace=}28@36@44o^@52
@"VNImageHomographicAlignmentObservation"16@0:8
@"VNImageHomographicAlignmentObservation"
{CGVector="dx"d"dy"d}
v32@0:8{CGVector=dd}16
v64@0:8{?=[3]}16
{CGVector=dd}16@0:8
@"AVAssetTrack"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{CGVector=dd}24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{?=[3]}32@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16^B24
^{CGColorSpace=}16@0:8
{vector<float, std::__1::allocator<float> >=^f^f{__compressed_pair<float *, std::__1::allocator<float> >=^f}}24@0:8@16
@48@0:8r^f16r^f24r^f32r^f40
@40@0:8{CGPoint=dd}16d32
d32@0:8{CGPoint=dd}16
@"NUFaceDetectionRequest"
@40@0:8@16{?=qq}24
^{CGColorSpace=}
@"NSMutableData"
@68@0:8^v16Q24Q32q40Q48i56^{CGColorSpace=}60
@68@0:8@16Q24Q32q40Q48i56^{CGColorSpace=}60
^v16@0:8
@"NSDate"
@"NSTimeZone"
@"CLLocation"
v32@0:8@"NSDate"16@"NSTimeZone"24
v24@0:8@"NSString"16
v24@0:8@"NSArray"16
@"CLLocation"16@0:8
v24@0:8@"CLLocation"16
@"NSDate"16@0:8
@"NSTimeZone"16@0:8
@36@0:8@16B24#28
@20@0:8B16
@36@0:8d16d24B32
@"CIVector"
@104@0:8@16{?=[3]}24{CGRect={CGPoint=dd}{CGSize=dd}}72
@40@0:8@16@24d32
d40@0:8@16d24^B32
B24@0:8Q16
@32@0:8q16@24
@24@0:8Q16
B32@0:8^{?={?=qq}{?=qq}}16o^@24
B48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{CGRect={CGPoint=dd}{CGSize=dd}}24@32o^@40
{CGRect={CGPoint=dd}{CGSize=dd}}96@0:8{?=qq}16{?=qq}32{?=qq}48{CGRect={CGPoint=dd}{CGSize=dd}}64
{?="p75"d"p98"d"autoValue"d"g98"d}
{?="sat"d"contrast"d"cast"d}
v36@0:8^f16f24f28f32
f24@0:8r^f16
d40@0:8d16d24d32
@"PIReframeKeyframeSequence"
@"<NUVideoProperties>"
@64@0:8@16{?={?=qq}{?=qq}}24@56
@144@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{?=[3]}88@136
B24@0:8d16
@48@0:8@16{CGPoint=dd}24d40
B32@0:8^{CGImage=}16@24
B40@0:8^{CGImage=}16@24@32
@"PIStillReframerConfiguration"
@"NURuleSystem"
@104@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64@96
@96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56@88
B40@0:8@16^d24^d32
d48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
B56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
@32@0:8Q16@24
Q24@0:8q16
{shared_ptr<VRFSession>="__ptr_"^{VRFSession}"__cntrl_"^{__shared_weak_count}}
(CenteredRect=""{?="x"d"y"d"w"d"h"d}""{?="xy""wh"}"xywh")
@112@0:8{?=qq}16q32{?={?=qq}{?=qq}}40{?={?=qq}{?=qq}}72r^(?={?=dd}{?={?=ii}{?=ii}})104
v48@0:8@16{?=qiIq}24
v56@0:8{CGVector=dd}16{?=qiIq}32
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8{?=qiIq}16
(?={?=dd}{?={?=ii}{?=ii}})24@0:8q16
@120@0:8q16{?=qq}24q40{?={?=qq}{?=qq}}48{?={?=qq}{?=qq}}80r^(?={?=dd}{?={?=ii}{?=ii}})112
r^{Session=^^?{?=qiIq}{?=qiIq}@?{unordered_map<long, std::__1::shared_ptr<VRFTrack>, std::__1::hash<long>, std::__1::equal_to<long>, std::__1::allocator<std::__1::pair<const long, std::__1::shared_ptr<VRFTrack> > > >={__hash_table<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::__unordered_map_hasher<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::hash<long>, true>, std::__1::__unordered_map_equal<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::equal_to<long>, true>, std::__1::allocator<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> > > >={unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> > >={__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> > >=^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>}{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> >={__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> >=Q}}}}{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> > >={__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>=^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>}}}{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::hash<long>, true> >=Q}{__compressed_pair<float, std::__1::__unordered_map_equal<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::equal_to<long>, true> >=f}}}{CatmullRom<double __attribute__((ext_vector_type(2)))>={map<double, double __attribute__((ext_vector_type(2))), std::__1::less<double>, std::__1::allocator<std::__1::pair<const double, double __attribute__((ext_vector_type(2)))> > >={__tree<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::__map_value_compare<double, std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::less<double>, true>, std::__1::allocator<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<double, std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::less<double>, true> >=Q}}}}}
@40@0:8{?=qiIq}16
{CGVector=dd}40@0:8{?=qiIq}16
^{Session=^^?{?=qiIq}{?=qiIq}@?{unordered_map<long, std::__1::shared_ptr<VRFTrack>, std::__1::hash<long>, std::__1::equal_to<long>, std::__1::allocator<std::__1::pair<const long, std::__1::shared_ptr<VRFTrack> > > >={__hash_table<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::__unordered_map_hasher<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::hash<long>, true>, std::__1::__unordered_map_equal<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::equal_to<long>, true>, std::__1::allocator<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> > > >={unique_ptr<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *[], std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> > >={__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> **, std::__1::__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> > >=^^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>}{__bucket_list_deallocator<std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> >={__compressed_pair<unsigned long, std::__1::allocator<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *> *> >=Q}}}}{__compressed_pair<std::__1::__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>, std::__1::allocator<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> > >={__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>=^{__hash_node_base<std::__1::__hash_node<std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, void *> *>}}}{__compressed_pair<unsigned long, std::__1::__unordered_map_hasher<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::hash<long>, true> >=Q}{__compressed_pair<float, std::__1::__unordered_map_equal<long, std::__1::__hash_value_type<long, std::__1::shared_ptr<VRFTrack> >, std::__1::equal_to<long>, true> >=f}}}{CatmullRom<double __attribute__((ext_vector_type(2)))>={map<double, double __attribute__((ext_vector_type(2))), std::__1::less<double>, std::__1::allocator<std::__1::pair<const double, double __attribute__((ext_vector_type(2)))> > >={__tree<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::__map_value_compare<double, std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::less<double>, true>, std::__1::allocator<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<double, std::__1::__value_type<double, double __attribute__((ext_vector_type(2)))>, std::__1::less<double>, true> >=Q}}}}}
{CGPoint=dd}40@0:8{?=qiIq}16
{?={?=qq}{?=qq}}40@0:8{CGPoint=dd}16d32
v40@0:8r^f16^S24Q32
v40@0:8r^S16^f24Q32
B48@0:8@16@24@32^@40
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
{?="major"i"minor"i}
v20@0:8f16
{?=ii}16@0:8
v24@0:8{?=ii}16
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@48@0:8@16@24q32@40
@52@0:8@16@24@32f40q44
@40@0:8@16q24@32
B80@0:8@16@24{?={?=qq}{?=qq}}32@64o^@72
@64@0:8@16d24{?={?=qq}{?=qq}}32
@64@0:8{?={?=qiIq}{?=qiIq}}16
@32@0:8d16d24
{CGPoint=dd}44@0:8i16d20d28@36
