?F]k
433333
?ffffff
?YAH
@<,_
?ffffff
?333333
333333
333333
?UUUUUU
?______
?TTTTTT
yE>)\
Ww'&l
MbP?
333333
?ffffff
?ffffff
?333333
333333
ffffff
333333
333333
@UUUUUU
@333333
?ffffff
z>UUUUUU
?YAH
?YAH
pCh?
zt?{
p?33
UUUUUU
?UUUUUU
4@333333
sU?gDi?
z?-C
Mb@?
UUU?
]?~0d>
@(#)PROGRAM:PhotoImaging  PROJECT:Neutrino-540.1.140
0Xr
?g|_\
ADBE
mntrRGB XYZ 
;acspAPPL
none
-ADBE
cprt
2desc
kwtpt
bkpt
rTRC
gTRC
bTRC
rXYZ
gXYZ
bXYZ
text
Copyright 2000 Adobe Systems Incorporated
desc
Adobe WGG linear
XYZ 
XYZ 
curv
XYZ 
XYZ 
iXYZ 
#?6t>=
<Xa<
<R>)<
A><QMI<
N-=y#3=*
OE=&
N,>;
2>F(6>
<>&T@>u
dN>;
Gl>#.p>
?Jy!?
V*?9%,?w
1?l{3?!X5?
77?"
NF=O
 >Me!>
">LP#>
)>k'*>"
^+>w
,>o+->D
->O\.>
1>uv2>N
T5>y
5>pw6>
7>t'8>M
D9>F
`:> 
z;>%
=>34>>Y
>>=H?>
A> zB>
E>>"F>]
F>9*G>
0H>K
;K>o
<L>l
;M>Z
M>;:N>
O>U2P>
P>k,Q>
Q>1%R>0
gW>i
HY>#
Y>&7Z>)
$[>$
]>B[^>
Mc>r
0d>h
f>cCg>
ni>r
Jj> 
%k>G
l>oFm>
n>gao>
q>!wq>L
q>4Kr>
+u>`
u>Acv>
x>35y>
z>U3{>
{>(c|>
,}>h
?%"?
+?Y5?
>?|H?
n?Bx?
< ?(D ?8L ?GT ?W\ ?gd ?vl ?
!?F%!?E-!?D5!?C=!?AE!?@M!?PU!?O]!?Me!?Lm!?Ku!?9}!?8
,"?v4"?u<"?cD"?QL"??T"?-\"?
9#?lA#?ZI#?7Q#?
x#?g
<$?kD$?8L$?
c$?{k$?Gs$?
%?B&%?
=%?RE%?
\%?Rd%?
{%?A
&?c%&?
<&?1D&?
S&?B[&?
j&?Tr&?
"'?9*'?
1'?~9'?)A'?
H'?nP'?
_'?Mg'?
v'?,~'?
(?l%(?
4(?)<(?
C(?^K(?
i(?.q(?
x(?R
)?R&)?
-)?T5)?
<)?gD)?
K)?iS)?
Z)?kb)?
i)?~q)?
*?1%*?
,*?"4*?
C*?{J*?
Q*?mY*?
`*?^h*?
o*?>w*?
+?)"+?
0+?a8+?
?+?0G+?
V+?h]+?
d+?7l+?
{+?o
+,?a3,?
B,?fI,?
X,?l_,?
n,?qu,?
-?$%-?|,-?
;-?_B-?
P-?CX-?
n-?\u-?
+.?<2.?
G.?3O.?zV.?
d.?+l.?`s.?
6/?K=/?
Y/?5a/?jh/?
?0?AF0?fM0?
q0?!x0?E
?1?,F1?@M1?TT1?h[1?|b1?
=2?1D2?4K2?7R2?KY2?N`2?Qg2?Tn2?Xu2?[|2?^
3?t$3?w+3?j23?m93?_@3?cG3?UN3?XU3?K\3?=c3?@j3?2q3?6x3?(
V4?t]4?gd4?Hk4?;r4?
35?`:5?BA5?$H5?
c5?{j5?\q5?>x5? 
#6?o*6?@16?
L6?eS6?GZ6?
u6?[|6?,
7?|&7?<-7?
A7?oH7?/O7?
c7?Qj7?
~7?b
8?E
'8?E.8?
;8?tB8?4I8?
V8?d]8?$d8?
q8?Sx8?
&9?w-9?&49?
A9?4H9?
U9?B\9?
i9?Pp9?
}9?^
:?5$:?
1:?"8:?
>:?oE:?
R:?\Y:?
f:?Hm:?
z:?$
;?$;?
3;?X:;?
G;?#N;?
T;?O[;?
a;?{h;?
u;?5|;?
<?f
-<?+4<?
:<?FA<?
G<?QN<?
T<?l[<?
u<? |<?
%=?I,=?
2=?T9=?
?=?NF=?
L=?XS=?
Y=?R`=?
f=?Lm=?
s=?Wz=?
">?A)>?
/>?*6>?
<>?$C>?
P>?zV>?
\>?cc>?
i>?Lp>?
v>?5}>?
*??]1??
7??6>??
K??zQ??
W??B^??
w??N~??
*@?H1@?
=@?[D@?
J@?"Q@?~W@?
]@?4d@?
p@?Ww@?
)A?o/A?
<A?pBA?
OA?aUA?
bA?bhA?
uA?S{A?
B?kB?
+B?+2B?v8B?
EB?UKB?
WB?5^B?odB?
qB?OwB?
C?u C?
,C?33C?m9C?
EC?+LC?eRC?
^C?#eC?]kC?
~C?U
&D?M,D?v2D?
ED?MKD?
]D?$dD?MjD?
0E??6E?h<E?
UE?6[E?_aE?
zE?,
,F?+2F?T8F?l>F?
]F?0cF?IiF?aoF?yuF?
G?S G?l&G?
PG?WG?%]G?=cG?DiG?]oG?uuG?|{G?
H?)%H?A+H?H1H?P7H?W=H?pCH?wIH?
I?S"I?[(I?Q.I?Y4I?`:I?W@I?_FI?ULI?]RI?SXI?[^I?cdI?YjI?apI?WvI?N|I?V
SJ?}YJ?t_J?keJ?akJ?XqJ?OwJ?F}J?,
)K?w/K?n5K?T;K?JAK?0GK?'MK?
vK?x|K?o
3L?i9L?>?L?$EL?
bL?whL?]nL?CtL?
M?:$M? *M?
AM?ZGM?/MM?
dM?{jM?PpM?%vM?
0N?~6N?S<N?
SN?\YN?1_N?
pN?dvN?9|N?
O?1$O?
/O?~5O?T;O?
LO?eRO?*XO?
cO?wiO?;oO?
!P?t'P?8-P?
8P?u>P?(DP?
OP?eUP?)[P?
fP?UlP?
}P?E
Q?E
Q?p#Q?$)Q?
4Q??:Q?
EQ?ZKQ?
VQ?t\Q?(bQ?
mQ?CsQ?
~Q?^
R?s
R?}#R?0)R?
4R?*:R?
ER?4KR?
VR?-\R?
gR?&mR?
rR?}xR? ~R?
'S?<-S?
8S?%>S?
CS?kIS?
TS?SZS?
eS?+kS?
pS?qvS?
/T?H5T?
:T?}@T?
KT?DQT?
VT?y\T?
gT?@mT?
rT?uxT?
U?h%U?
;U?BAU?
FU?ULU?
QU?yWU?
bU?0hU?
mU?CsU?
xU?g~U?
$V?=*V?
/V?P5V?
:V?d@V?
EV?wKV?
VV?\V?
lV?"rV?
wV?5}V?
W?}"W?
SW?yYW?
^W?|dW?
iW?moW?
tW?pzW?
X?>$X?
)X?0/X?
4X?!:X?
OX?eUX?
ZX?W`X?
eX?8kX?
pX?)vX?
Y?l$Y?
)Y?</Y?
DY?oJY?
OY??UY?
ZY? `Y?
kY?apY?
uY?B{Y?
#Z?g(Z?
-Z?73Z?
>Z?gCZ?
HZ?8NZ?
XZ?h^Z?
cZ?'iZ?
sZ?WyZ?
[?! [?p%[?
*[?/0[?
:[?O@[?
K[?]P[?
[[?|`[?
e[?+k[?
u[?J{[?
!\?g&\?
1\?e6\?
A\?cF\?
Q\?`V\?
a\?^f\?
p\?\v\?
]?m ]?
+]?Y0]?
:]?F@]?
J]?"P]?qU]?
`]?^e]?
o]?:u]?
(^?,.^?j3^?
=^?FC^?
S^?OX^?
h^?Ym^?
w^?$}^?s
_?>%_?|*_?
4_?6:_?u?_?
I_?/O_?\T_?
d_?Ui_?
y_?=~_?{
 `?[%`?
4`?2:`?`?`?
O`?7T`?dY`?
i`?;n`?is`?
#a?$)a?Q.a?
Ca?4Ha?bMa?
ba?Ega?rla?
b?|b?
!b?>&b?Z+b?
Eb?IJb?fOb?
cb?'ib?Dnb?qsb?
,c?<1c?Y6c?u;c?
Uc?2Zc?N_c?kdc?
d?:!d?F&d?c+d?
Td?2Yd?>^d?Zcd?fhd?
$e?5)e?A.e?L3e?X8e?u=e?
ze? 
f?[f?f
g?xg?s
g?u g?
%g?|*g?w/g?
4g?~9g?y>g?
Hg?{Mg?
Wg?}\g?xag?
kg?zpg?uug?
zg?|
sh?uxh?p}h?k
Mi?~Ri?iWi?d\i?Nai?8fi?3ki?
&j?k+j?U0j??5j?;:j?%?j?
aj?ffj?Qkj?;pj?%uj?
%k?|*k?f/k?P4k?*9k?
Vk?`[k?J`k?4ek?
l?S#l?,(l?
;l?}@l?VEl?0Jl?
bl?Zgl?3ll?
m?=m?
m?l$m?E)m?
<m?tAm?NFm?
Ym?l^m?Ecm?
vm?t{m?=
n?%$n?
2n?X7n?2<n?
Jn?fOn?.Tn?
bn?sgn?<ln?
zn?o
o?l"o?5'o?
5o?X:o?
Ho?jMo?3Ro?
`o?Veo?
so?hxo?1}o?
p?Ap?
-p?U2p?
@p?VEp?
Sp?XXp? ]p?
fp?Ykp?"pp?
yp?Z~p?#
q?Z
q?J$q?
-q?r2q?*7q?
@q?cEq?
Sq?SXq?
aq?{fq?3kq?
tq?[yq?
,r?@1r?
:r?W?r?
Hr?nMr?&Rr?
[r?=`r?
ir?Tnr?sr?
wr?l|r?$
 s?>%s?
.s?D3s?
<s?JAs?
Js?QOs?
Xs?W]s?
fs?]ks?
ts?dys?
t?K!t?
*t?@/t?
8t?6=t?
Ft?+Kt?
Ot?zTt?!Yt?
]t?obt?
kt?ept?ut?
yt?J~t?
 u?F%u?
.u?+3u?
7u?h<u?
Eu?MJu?
Su?2Xu?
\u?pau?
ju?Tou?
xu?(}u?
v?9v?
v?:#v?
'v?w,v?
5v?K:v?
>v?xCv?
Lv?LQv?
Uv?yZv?
cv?Mhv?
lv?zqv?
zv?N
w?t$w?
-w?82w?
6w?T;w?
Mw?DRw?
Vw?`[w?
dw?#iw?
mw??rw?
vw?l{w?
x?O$x?
(x?k-x?
6x?;x?
?x?(Dx?
Hx?DMx?
Qx?`Vx?
Zx?|_x?
qx?:vx?
zx?V
"y?='y?
+y?Y0y?
4y?e9y?
=y?pBy?
Fy?{Ky?
]y?(by?
fy?3ky?
oy??ty?
xy?J}y?
z?W$z?
(z?b-z?
1z?m6z?
:z?h?z?
Cz?sHz?
Lz?nQz?
Uz?hZz?
^z?scz?
gz?nlz?
pz?yuz?
yz?t~z?
{?! {?
L{?zQ{?
U{?dZ{?
^{?^c{?
g{?Yl{?
p{?Cu{?
y{?=~{?
0|?i5|?
9|?S>|?
B|?=G|?
K|?'P|?
a|?of|?
j|?Xo|?
s|?Bx|?
||?,
}?%!}?
)}?s.}?
2}?]7}?
;}?5@}?
Q}?\V}?
Z}?5_}?
p}?\u}?
y}?F~}?
!~?>&~?
/~?{3~?
7~?S<~?
@~?,E~?
M~?YR~?
V~?1[~?
d~?nh~?
l~?7q~?
z~?t~~?
333333
?333333
?ffffff
Fail: %{public}@
job: %{public}@
Trace:
%{public}@
Trace:
%{public}@
Tap-to-track: client requested stop at %@
Tap-to-track: tracking lost at %@
PIColorNormalizationAnalysis
Tried to set sceneLabel to unsupported value: %ld
Setting bounding boxes based on orientation (%@) and observations: %@
Setting face bounding boxes based on orientation (%@) and observations: %@
Continue: %{public}@
Failed to load compute pipeline: %@
Failed to load user palette '%@', error: %@
class %@ is not the correct type, its superclass should be %@
Unable to serialize finalized composition: %{public}@
Error executing command buffer '%{public}@': %{public}@
CPV rendering failure, returned status %d
Could not apply PIPortraitVideoProcessor: %@
Failed to prewarm portrait renderer: %{public}@
Failed to obtain video properties: %{public}@
Using recipe directory at '%{public}@'
Failed to load style recipe for identifier '%@', error: %@
Missing configuration file '%{private}@'
PARALLAX CLOCK: luminance is %f - %@
ColorBGStandard: suggested %@ for background luminance of %.2f
ColorBG color: %@ -> neutral: %@ lowKey: %0.3f highKey: %0.3f
Couldn't find a single candidate style for category %{public}@, falling back to Original
Median luminance: %f
Percent above chroma min: %0.0f%%, max hues: %ld
Found %ld dominant hues: %@
Found %ld dominant grays: %@
facerect yiq = %.5f, %.5f, %.5f
Choosing gray world instead of gray edge
Brightness is %@, greenChannelPercentage is %f, Sushi: %@
aperture=%@, shutterSpeed=%@, iso=%@
Buffer sizes are not the same: %{public}@ vs %{public}@
Buffer size is %@, bytes per row is %ld, dark_thr=%f, sat_thr=%f, noise_thr=%f
all done summing, np_gw is %d, np_ge is %d
wp_ge {%f, %f, %f, %f} wp_gw {%f, %f, %f, %f}, Sushi? %@
RGB = %f, %f, %f
YIQ = %f, %f, %f from %f, %f, %f
Failed to export image to %@: %@
Failed to export image to data: %@
Failed to prepare video metadata: %@
Unexpected Live Photo export format pairing. Video codec (%{public}@) and image export format (%{public}@)
Export Composition: exportImage: %{public}@ / exportVideoComplement: %{public}@ / exportVideo: %{public}@ / exportVideoPosterFrame: %{public}@
Export Composition: exporting image
Export Composition: exporting image complete
Export Composition: exporting video complement
Export Composition: exporting video complement complete
Export Composition: exporting video
Export Composition: exporting video complete
Export Composition: exporting video poster frame
Export Composition: exporting video poster frame complete
Export Composition: exporting overcapture image
Export Composition: exporting overcapture image complete
Export Composition: exporting overcapture video
Export Composition: exporting overcapture video complete
Export Composition: waiting on notify
Export Composition: notify triggered
Export Composition: calling completion with error: %{public}@
Export Composition: callling completion with result: %{public}@
failed to render auxiliary image data: %@
Skipping applyVideoOrientationAsMetadata. Bounces and Autoloops are not supported. Falling back to burned-in orientation.
Skipping applyVideoOrientationAsMetadata. Flipped orientations are not supported. Falling back to burned-in orientation.
Failed to export video: %@
invalid format version: %@
Failed to update layout: %{public}@
Failed to compute clock overlap: %{public}@
Failed to compute clock material: %{public}@
Failed to render layer stack, error: %{public}@
Pixel-based headroom zoom final range %@,%@: %@,%@
Unable to calculate a new inactiveRect; falling back to visible frame
PIParallaxLegacyPosterStyle.localLight
PIPortraitVideoMetadataSample: unexpected number of items for identifier %@: %@
PIPortraitVideoMetadataSample: item %@ is not of expected class %@
Error unarchiving cameraInfo metadata: %@
CINE: allocating new PT renderer: %@
CINE: recycling unused PT renderer: %@ (%lu remaining)
CINE: need new render state due to rendering version mismatch
CINE: need new render state due to sensor mismatch
CINE: allocating new renderState with metadata: %p
Requesting forced cleanup of Vision caches
Unsupported filter parameter: %{public}@
Parameter %{public}@ is not a valid color value: %{public}@
Parameter %{public}@ is not a valid number value: %{public}@
Error evaluating filter definition: %@, error: %@
CPV asset editability: onAppleSilicon: %s, hasMetalDeviceForPortrait: %s, oniOS: %s
CPV assets aren't editable because there is no metal device with support for portrait rendering
CPV assets aren't editable because the device has no ANE
CPV assets are editable
HDR asset not editable because this device doesn't support 10-bit HEVC encoding
HDR asset not editable because this device doesn't support HDR
HDR asset not editable because editing not supported on DolbyVision 5
CPV asset checking for editability
CPV asset not editable because it's in a legacy, unsupported format
CPV asset editable due to override
CPV asset not editable because CPV assets are not editable on this device
CPV asset not editable because this asset is not playable on this device
CPV asset not editable because this device doesn't support HDR
CPV asset is editable
validation issue: recipe is blank on the autoloop adjustment
validation issue: no flavor specified on the autoloop adjustment
validation issue: Missing inputCorrectionInfo on a redeye adjustment
validation issue: Missing depthInfo on a depth adjustment
validation issue: Missing portraitInfo on a portrait adjustment
validation issue: invalid trim startTime or endTime
Can PLPhotoEditPFDataConverter interpret identifier %{public}@? %@. Version %{public}@? %@
Failed to load filter named '%@'
PFSizeGetAspectRatio produced an undefined aspect ratio from size %@. Returning %f. Use PFSizeGetAspectRatioWithDefault() to provide a value for this case.
PARALLAX CLOCK: execution time %.2f ms
waitUntilReadyForMoreData: waited for %0.1fms
Writing long-exposure image to %{public}@
Writing long-exposure motion mask to %{public}@
Still image node:
Still image geometry:
Still image:
clap=%@, crop=%@, fullSize=%@, videoScale=%@ => guide rect: %@
High-resolution image registration failure : %@
Unable to load scoring ranges dictionary from %@, error %@
Unable to load scoring plist, using fallback
Failed to load scoring configuration: %@
MediaAnalysis not available
currentSystemCanRenderAsset: error retrieving rendering version from asset: %@
Failed to render %{public}@, error: %{public}@
Failed to allocate pixel buffer for render cache entry (size=%ldx%ld, format=%{public}@)
Cache miss for image: %{public}@ cost: %lu digest: %llx
Loading long-exposure fusion tuning parameters from file: %@
Failed to load fusion tuning parameters.
Using fusion tuning parameters: {kNCCBlurHalfSize=%d, kNCCEdge0=%f, kNCCEdge1=%f, kBlendMaskThreshold0=%f, kBlendMaskThreshold1=%f}
Missing inputImage
Missing inputMaskImage
Missing inputStillImage
Missing inputRenderScale
Missing inputVideoScale
Missing inputAlignmentExtent
Malformed inputAlignmentExtent vector
Missing inputAlignmentTransform
Malformed inputAlignmentTransform vector
Writing intermediate long exposure fusion images to : %@
Evaluating pipeline as HDR input
PISegmentationLoader.memory.warmUp
Ensuring segmentation resources with counter %ld
Freeing segmentation loader resources with counter %ld
PISegmentationLoader.memory.purge
PISegmentationLoader.item
Warning: PISegmentationLoader layout configuration unspecified! Using override layout configuration '%{public}@'
Warning: Override layout configuration '%{public}@' not found, using generic fallback
Warning: PISegmentationLoader layout configuration unspecified! Using the layout configuration matching this device
PISegmentationLoader.proxy
PISegmentationLoader.properties
PISegmentationLoader.fullSize
Failed to compute proxy image size, error: %{public}@
Cancelling segmentation loader
Triggering non-foreground user initiated download for asset with local identifier: %{public}@
Loading resource %ld for asset %{public}@, allow download? %d
Successfully loaded resource %ld for asset %{public}@ in %0.3fs
Failed to load resource %ld for asset %{public}@ after %0.3fs, error: %{public}@
Cancelled loading resource %ld for asset %{public}@ after %0.3fs
PISegmentationLoader.classify
PISegmentationLoader.segment
PISegmentationLoader.regions
PISegmentationLoader.infill
PISegmentationLoader.layout
PISegmentationLoader.colorAnalysis
PISegmentationLoader.localLightData
Known classification: %{public}@
Previous classification attempt yielded 'other'
Current classification is unspecified
Classified image as %{public}@
Detectors failed to classify asset. Falling back to segmentation strategy.
Vision detection failed: %{public}@
Image segmentation response: %@
Image segmentation failed: %{public}@
Full Image color analysis response: %@
Full Image color analysis failed: %{public}@
Foreground color analysis response: %@
Foreground color analysis failed: %{public}@
Background color analysis response: %@
Background color analysis failed: %{public}@
Parallax infill response: %@
Parallax infill failed: %{public}@
MAD pets results: %@, pets face results: %@, error: %@
Failed to load pets regions: %{public}@
Vision detection response: %@
Failed to run face/saliency detection: %{public}@
Parallax layout response: %{public}@
Failed to layout item: %{public}@
Local light data response: %{public}@
Failed to compute local light data: %{public}@
Failed to deserialize segmentation adjustment data: %{public}@
Failed to read orientation for image file: %@, error: %{public}@
PISegmentationLoader.data.read
Failed to read cached segmentation data from: %{public}@, error: %{public}@
Cached segmentation version mismatch: got %ld, expected %ld
Cached segmentation source mode mismatch: got %ld, expected %ld
Cached segmentation disabled flag mismatch: got %d, expected %d
Cached segmentation infill algorithm mismatch: got %ld, expected %ld
Cached segmentation layout configuration mismatch: got %{public}@, expected %{public}@
Cached segmentation classification mismatch: got %{public}@, expected %{public}@
PISegmentationLoader.data.write
Failed to save segmentation data for asset: %{public}@, error:%{public}@
PISegmentationLoader.archive.write
PISegmentationLoader.archive.read
PISegmentationLoader.layerStack.render
PISegmentationLoader.wallpaper.write
Failed to save segmentation item and layer stack to wallpaper URL: %{public}@
Failed to create wallpaper directory: %{public}@
Failed to export segmentation item: %{public}@
PISegmentationLoader.layerStack.write
Failed to export layer stack: %{public}@
Failed to load segmentation item from wallpaper: %{public}@
PISegmentationLoader.layerStack.read
Failed to load layer stack from wallpaper: %{public}@
Failed to render layer stack: %{public}@
Failed to reload segmentation item from wallpaper: %{public}@
Beginning finalization for candidates: %@
No overcapture source found in composition, removing any candidate bits for reframing
Finalizer result contains roll angle degrees: %f pitch angle degrees: %f yaw angle degrees: %f
Finalizer result did not contain a change
Received error while finalizing: %@
Starting horizon auto calculator
Finished horizon auto calculator: %@
Starting perspective auto calculator
Finished perspective auto calculator: %@
Could not write PICropAutoCalculator debug diagnostics. %@
Failed to compute overcapture rect %@
Can't find enabled video track in asset: %@
Asset does not contain Live Photo metadata track
Track does not contain V3 metadata
Error creating asset reader: %@
Can't add metadata output for asset
Failed to start reading asset
Starting metadata extraction
Finished metadata extraction
PISmartToneAutoCalculator submitSynchronous isHDRComposition: %s
PISmartToneAutoCalculator smartTone request submitting: %{public}@
PISmartToneAutoCalculator smartTone result: %{public}@
PISmartToneAutoCalculator localLight request submitting: %{public}@
PISmartToneAutoCalculator localLight result: %{public}@
PISmartToneAutoCalculator submit isHDRComposition: %s
PISmartToneAutoCalculator global result: %{public}@
PISmartToneAutoCalculator going to commit and wait
PISmartToneAutoCalculator committed
PISmartToneAutoCalculator completed
PISmartToneAutoCalculator error: %{public}@
PISmartToneAutoCalculator coalesced
Failed to deserialize layout configuration: %{public}@, error: %{public}@
Can load cold asset? %{public}@ => %{public}@
Failed to deserialize style from dictionary: %{public}@, error: %{public}@
Unknown style option, ignored: %{public}@
Upgrading wallpaper at %{public}@ to %{public}@, options: %{public}@
Failed to export refreshed wallpaper at %{public}@ to %{public}@, error: %{public}@
Successfully exported refreshed wallpaper at %{public}@ to %{public}@
Failed to load poster configuration from: '%{public}@', error: %{public}@
Failed to upgrade poster configuration from: '%{public}@' to: '%{public}@', error: %{public}@
Successfully upgraded poster configuration from: '%{public}@' to: '%{public}@'
Upgrading poster media: SETTING .hasInactiveContent
Upgrading poster media: CLEARING .hasInactiveContent
Upgrading poster media: %{public}@
Successfully upgraded poster media: %{public}@
Failed to upgraded poster media: %{public}@, error: %{public}@
Failed to upgrade %lu poster media
Successfully upgraded %lu poster media
Successfully upgraded poster configuration from '%{public}@' to '%{public}@'
Failed to save poster configuration to '%{public}@', error: %{public}@
Failed to apply red eye repair. error: %{public}@
PIPortraitAutoCalculator getMinMaxSimulatedAperture returned error:%i (minAperture:%f maxAperture:%f version:%d)
Cant get focusRect - Metadata dictionary missing fullSizeWith or fullSizeHeight:
Cant get focusRect - Metadata dictionary missing exif aux dictionary:
Cant get focusRect - Exif aux dictionary missing MWG region dictionary:
Cant get focusRect - MWG region dictionary missing region list:
Cant get focusRect - Region list does not contain a focus rect:
Cant get focusRect - Malformed focus rect dictionary:
Invalid focus rect: {%g,%g,%g,%g}
Couldn't deserialize face observations from metadata: %@, assuming empty, error: %@.
Invalid face indexes from metadata: %@, ignored. Error: %@
Couldn't deserialize face observations from metadata: %@
s-curve black: %f
s-curve point %d: (%f, %f)
s-curve white: %f
red curve: blackPoint = %f, whitePoint = %f
green curve: blackPoint = %f, whitePoint = %f
blue curve: blackPoint = %f, whitePoint = %f
Initializer not available: -[%@ %@], use designated initializer instead.
-[PIParallaxInfillJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxInfillRequest.m
Missing matte image
Invalid matte image size
Invalid matte image
Output image must not be nil
-[PIParallaxInfillJob render:]
Matte image must not be nil
Failed to generate background infill image
Failed to allocate buffer from pool
failed to render
Invalid parameter not satisfying: %s
-[PITapToTrackRenderJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PITapToTrackRequest.m
No metal device for request
Failed to find output video asset
Failed to make asset reader for video
Failed to read first frame for video
Failed to find rect to track at initial point
Failed to add detection and start tracking
Failed to get finalized track from tracking session
kernel vec4 _hdrOffsetPosBW(sampler image) { vec4 im = sample(image, samplerCoord(image)); float offset = (im.r + im.g + im.b) / 3.0f; offset = max(0.0f, offset - 1.0f); return vec4(offset, offset, offset, 0.0f); }
kernel vec4 _hdrOffsetPos(sampler image) { vec4 im = sample(image, samplerCoord(image)); float r = max(im.r - 1.0f, 0.0f); float g = max(im.g - 1.0f, 0.0f); float b = max(im.b - 1.0f, 0.0f); return vec4(r, g, b, 0.0f); }
s_hdrOffsetPos kernel is nil
+[PIPhotoEffectHDR kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PIPhotoEffectHDR.m
inputImage cannot be nil
-[PIPhotoEffectHDR outputImage]
inputImage
CIAdditionCompositing
inputBackgroundImage
s_hdrOffsetPosBlackAndWhite kernel is nil
+[PIPhotoEffectBlackAndWhiteHDR kernelBlackAndWhite]_block_invoke
-[PIPhotoEffectBlackAndWhiteHDR outputImage]
+[PIPhotoEffect3DHDR kernel]_block_invoke
-[PIPhotoEffect3DHDR outputImage]
inputThreshold
inputDepthMap
+[PIPhotoEffect3DBlackAndWhiteHDR kernelBlackAndWhite]_block_invoke
-[PIPhotoEffect3DBlackAndWhiteHDR outputImage]
PhotoImaging
PIColorNormalizationFilter
PITempTintFilter
temperature
inputTemperature
tint
inputTint
PIHighKey
CISmartToneFilter
CISmartColorFilter
normalization != nil
+[PIColorNormalizationFilter colorCubeForNormalization:dimension:targetColorSpace:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIColorNormalizationFilter.m
colorSpace != NULL
PIColorNormalization
candidateForStill
candidateForVideo
candidateForReframe
candidateForPerspective
candidateForHorizon
addRule exception : %@
v24@?0@"NSString"8@?<v@?@"NURuleSystem">16
v24@?0@"NSString"8@"NSString"16
isStitched
validSubjects
hasHorizonLine
hasBuilding
state.stitched == true OR state.perfectlyStitched == true
state.stitchConfidence < $StitchConfidenceThreshold
state.buildingCount > 0
state.buildingConfidence > $BuildingConfidenceThreshold
state.subjectCount >= $SubjectCountMinThreshold
state.allSubjectsInsidePrimaryBounds == true
(state.subjectCount - state.intersectingSubjectCount) > $MaxDisparateSubjects
state.largeSubjectFace == true
state.largestSubjectArea <= $MinimumSubjectSize
state.horizonLinePresent == true
state.horizonLineAngleInDegrees < -$HorizonAngleInDegreesMaxThreshold OR state.horizonLineAngleInDegrees > $HorizonAngleInDegreesMaxThreshold
state.horizonLineAngleInDegrees > -$HorizonAngleInDegreesMinThreshold AND state.horizonLineAngleInDegrees < $HorizonAngleInDegreesMinThreshold
state.video == true
state.videoDuration < $VideoDurationLowerBound
state.videoDuration > $VideoDurationUpperBound
(state.videoDuration * $VideoDurationWithSubjectsRatio) > state.videoDurationWithSubjects
state.videoQualityScore < $VideoQualityScoreThreshold
(state.videoDuration * $VideoDurationBelowMinZoomRatio) < state.videoDurationBelowMinZoom
facts.isStitched == true AND facts.validSubjects == true
facts.isStitched == true AND facts.hasBuilding == true
facts.isStitched == true AND facts.hasHorizonLine == true
state.largeSubject == true
state.backFacing == false
state.deviceIsStationary == true
state.video == true AND state.livePhoto == true
state.pano == true
state.reframingAllowed == false
state.hasAdjustments == true
facts.candidateForStill == true
facts.candidateForVideo == true
platedFood
sunriseSunset
genericLandscape
intensity
sceneLabel
sceneConfidence
faceBoundingBoxes
boundingBoxes
-[PIDisparitySampleJob render:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIDisparitySampleRequest.m
Failed to read video frame
Incompatible disparity buffer
inputStrength
inputScale
vec3 localContrast(vec3 im, vec3 shc, float amt) { float midAmt = amt; vec3 neg = min(im, 0.0); vec3 pos = max(im, 1.0)-1.0; im = clamp(im, 0.0, 1.0); float y = dot(im, vec3(0.3333)); y = sqrt(y); y = y*(1.0-y); im = sqrt(im); float pivot = sqrt(shc.g); float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + im.g * vec3(0.587*a) + im.b * vec3(0.114*a) + im + vec3(b); im = mix(im, vec3(pivot), -y*midAmt); im = mix(im, pix, 0.8); im = max(im, 0.0); im *= im; im = im + neg + pos; return im; } vec3 localContrastHLG(vec3 im, vec3 shc, float hlg_scale, float amt) { return localContrast(im.rgb/hlg_scale, shc.rgb/hlg_scale, amt).rgb * hlg_scale; } kernel vec4 _localContrastHDR(__sample im, __sample shc, float hlg_scale, float amt) { float max_comp = max(im.r,max(im.g,im.b)); float threshold = 0.75 * hlg_scale; if (max_comp <= 1.0) { im.rgb = localContrast(im.rgb, shc.rgb, amt); } else if (max_comp < threshold) { vec3 retSDR = localContrast(im.rgb, shc.rgb, amt); vec3 retHDR = localContrastHLG(im.rgb, shc.rgb, hlg_scale, amt); float lerp_t = (max_comp - 1.0) / (threshold - 1.0); im.rgb = mix(retSDR, retHDR, lerp_t); } else { im.rgb = localContrastHLG(im.rgb, shc.rgb, hlg_scale, amt); } return im; }
CIColorMatrix
inputRVector
inputGVector
inputBVector
inputAVector
inputBiasVector
CIColorClamp
inputMinComponents
inputMaxComponents
CIEdgePreserveUpsampleFilter
inputSmallImage
inputSpatialSigma
inputLumaSigma
intermediate.visibleRect.size.width >= 1
-[PIParallaxLayoutHelper intermediateWithZoomStrategy:intermediate:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationLayout.m
overlapStrategy != PFParallaxUtilityOverlapForceMetadataAvoid
-[PIParallaxLayoutHelper intermediateWithOverlapStrategy:intermediate:]
<%@:%p accept=%@ pref=%@ faces=%@ pets=%@>
regions != nil
+[PISegmentationLayoutRegions dictionaryFromRegions:]
@"NSDictionary"40@?0{CGRect={CGPoint=dd}{CGSize=dd}}8
@"NSArray"16@?0@"NSArray"8
acceptable
preferred
faces
pets
+[PISegmentationLayoutRegions regionsFromDictionary:error:]
B24@?0@8^{CGRect={CGPoint=dd}{CGSize=dd}}16
Expected a rect value
B24@?0@"NSArray"8@"NSMutableArray"16
Expected an array of rect values
layoutConfiguration != nil
+[PISegmentationLayout generateLayoutForLayoutConfiguration:imageSize:regions:parallaxClassification:context:matte:layoutScore:cropScore:clockOverlapAcceptable:]
layoutConfiguration.screenSize.height > 0
imageSize.height > 0
<%@:%p layerOrder:%@ intersectsForeground:%@>
-[_PIParallaxClockLayoutJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxClockLayoutRequest.m
Missing segmentation item
-[_PIParallaxClockLayoutJob prepare:]
Missing parallax layout
Missing renderer
-[_PIParallaxClockLayoutJob render:]
This is an abstract method! Subclass '%@' should provide concrete implementation
-[PIParallaxClockLayoutRequest initWithComposition:]
-[PIParallaxClockLayoutRequest initWithSegmentationItem:]
kernel vec4 highKey(__sample im, float str)
vec3 neg = min(im.rgb, 0.0);
vec3 pos = max(im.rgb, 1.0) - 1.0;
im = clamp(im, 0.0, 1.0);
vec4 im2 = 1.0-((im-1.0)*(im-1.0));
im2 = sqrt(im2);
float y = dot(im.rgb, vec3(.333333));
float y2 = sqrt(1.0-(y-1.0)*(y-1.0));
y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5);
vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0);
im3 = mix(im3, im2, .7*sqrt(y2));
im3 = mix(im, im3, sqrt(y));
im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg;
return im;
high key kernel is nil
+[PIHighKey kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIHighKey.m
-[PIHighKey outputImage]
inputStrength cannot be nil
/System/Library/Frameworks/CoreImage.framework/inp_gen_eds2_00_q16.espresso.weights
CIInpaintingFilter
inputInpaintingMode
Metal unavailable
inputTexture != nil
+[PIParallaxInwardFillKernel fillSourceTexture:intoDestinationTexture:withCommandBuffer:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationInfillFilter.m
outputTexture != nil
commandBuffer != nil
Missing input texture
-[PIParallaxInwardFillKernel encodeToCommandBuffer:destinationTexture:]
Failed to allocate intermediate texture
pi::inward_fill_down
pi::inward_fill_up
LumaHueChroma
HueTone
v24@?0Q8^B16
version
mode
primaryColors
secondaryColors
suggestionIndices
url != nil
+[PIParallaxColorPalette loadPaletteFromURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorPalette.m
Failed to parse color palette plist data
+[PIParallaxColorPalette _paletteWithConfigurationDictionary:error:]
Invalid version number
Unsupported palette version
Invalid mode value
Invalid primary color values
Invalid secondary color values
Invalid suggestion indices
Invalid suggestion index
Missing suggestion indices
Unknown color mode: %@
+[PIParallaxColorPalette _serializeColors:mode:]
colorValues != nil
+[PIParallaxColorPalette _loadColorsFromValues:mode:error:]
Invalid color values
primaryColors != nil
-[PIParallaxColorPalette initWithPrimaryColors:secondaryColors:suggestionIndices:]
secondaryColors != nil
suggestionIndices != nil
suggestionIndices.lastIndex < primaryColors.count
Secondary color palette should be empty or equal in size to the primary palette
ColorBGPalette
ColorWashSinglePalette
ColorWashDuotonePalette
plist
Failed to load color palette '%@', error: %@
+[PIParallaxColorPalette loadPaletteWithName:]
Tonal colors: %@
B16@?0Q8
The palette can't be empty
-[PIParallaxColorPalette _lookupColor:withPredicate:]
Failed to find a nearest color
smartTone
smartColor
smartBlackAndWhite
grain
autoEnhance
whiteBalance
cropStraighten
redEye
apertureRedEye
depthEffect
livePhotoKeyFrame
videoPosterFrame
trim
slomo
portraitEffect
orientation
autoLoop
highResFusion
retouch
vignette
sharpen
noiseReduction
definition
curves
levels
selectiveColor
effect
effect3D
mute
rawNoiseReduction
source
videoReframe
debug
sourceSelect
sourceSpatialOvercapture
portraitVideo
videoStabilize
videoCrossfadeLoop
semanticEnhance
enabled
value
primary
PICompositionController(%p): %@
v16@?0@"PISmartToneAdjustmentController"8
com.apple.photo
adjustmentFormatIdentifier
adjustmentFormatVersion
adjustmentData
PICompositionSerializer.m
Invalid parameter not satisfying: %@
adjustments
metadata
file://dummy.jpg
dummy
identifier
PICompositionSerializerDomain
Missing identifierName
Missing definition in conversion map for the adjustment key: 
settings
Unsupported adjustment: 
Configuration does not support Aperature adjustments.
Configuration does not support CTM adjustments.
nil identifierName
inputKeys
omitIfDisabled
Orientation
PICompositionSerializer-geometry
Invalid adjustment stack for needsGeometry=NO
masterWidth
masterHeight
Serialization map has no entry for %@
+[PICompositionSerializer serializeComposition:versionInfo:serializerMetadata:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/Conversion/PICompositionSerializer.m
Serialization map does not contain identifierName
current
auto
formatIdentifier
formatVersion
versionInfo
Missing required key: %@
Value for key %@ has type %@; expected type %@
v32@?0@"NSString"8#16^B24
PICompositionSerializer
exception
dictionary
data is not an NSData: %@: %@
Adjustment for %@ is identity
+[PICompositionSerializer _sanitizeComposition:]
composition
CFBundleVersion
platform
buildNumber
appVersion
schemaRevision
kernel vec4 levelsHDR (sampler src, sampler LUT) { vec4 p,r; vec2 c1,c2; float f; p = sample(src, samplerCoord(src)); vec3 neg = min(p.rgb, 0.0); vec3 pos = max(p.rgb, 1.0)-1.0; p.rgb = clamp(p.rgb, 0.0, 1.0); f = p.r * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.r = r.r; f = p.g * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.g = r.g; f = p.b * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.b = r.b; p.rgb = max(p.rgb, 0.0); p.rgb = p.rgb + pos + neg; return p; }
inputBlackSrc
inputBlackDst
inputShadowSrc
inputShadowDst
inputMidSrc
inputMidDst
inputHilightSrc
inputHilightDst
inputWhiteSrc
inputWhiteDst
inputBlackSrcRGB
inputBlackDstRGB
inputShadowSrcRGB
inputShadowDstRGB
inputMidSrcRGB
inputMidDstRGB
inputHilightSrcRGB
inputHilightDstRGB
inputWhiteSrcRGB
inputWhiteDstRGB
inputBlackSrcRed
inputBlackDstRed
inputShadowSrcRed
inputShadowDstRed
inputMidSrcRed
inputMidDstRed
inputHilightSrcRed
inputHilightDstRed
inputWhiteSrcRed
inputWhiteDstRed
inputBlackSrcGreen
inputBlackDstGreen
inputShadowSrcGreen
inputShadowDstGreen
inputMidSrcGreen
inputMidDstGreen
inputHilightSrcGreen
inputHilightDstGreen
inputWhiteSrcGreen
inputWhiteDstGreen
inputBlackSrcBlue
inputBlackDstBlue
inputShadowSrcBlue
inputShadowDstBlue
inputMidSrcBlue
inputMidDstBlue
inputHilightSrcBlue
inputHilightDstBlue
inputWhiteSrcBlue
inputWhiteDstBlue
Green
Blue
Failed converting data to RGBAh: %ld
-[PILevelsFilterHDR _LUTImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PILevelsFilterHDR.m
score
/Master/Source
data != nil
+[PIColorNormalizationAutoCalculator autoCalculatorWithImageData:orientation:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIColorNormalizationAutoCalculator.m
-[PIColorNormalizationAutoCalculator submit:]
Feature Unavailable
No color normalization available
kernel vec4 _falseColorHDRDebug(sampler image, float cutoff){   vec4 im = sample(image, samplerCoord(image));   if (im.x < 0.0 && im.y < 0.0 && im.z < 0.0) {        return vec4(0.0 , 0.6 , 0.2 , 1.0);   }   if (im.x > cutoff && im.y > cutoff && im.z > cutoff) {        return vec4(1.0 , 0.0 , 1.0 , 1.0);   }   if (im.x > cutoff || im.y > cutoff || im.z > cutoff) {        return vec4(0.6 , 0.0 , 0.6 , 1.0);   }   return im;}
s_falseColorHDRDebugKernelSource kernel is nil
+[PIFalseColorHDRDebug kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PIFalseColorHDRDebug.m
-[PIFalseColorHDRDebug outputImage]
-[PIAutoLoopExportRequest initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopRequests.m
-[PIAutoLoopExportRequest initWithComposition:destinationURL:]
Unexpected input pixel format
+[PIPortraitVideoProcessor _configureRGBColorTexture:format:isHDR:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoFilter.m
unexpected inputs
+[PIPortraitVideoProcessor processWithInputs:arguments:output:error:]
expected a device
expected a texture
aperture
focusDistance
quality
isHDR
globalMetadata
timedMetadata
Expected an input color texture
Expected an input disparity texture
colorPixelBuffer
missing direct source color pixel buffer
disparityPixelBuffer
missing direct source disparity pixel buffer
v16@?0@"<MTLCommandBuffer>"8
Invalid index
+[PIPortraitVideoProcessor formatForInputAtIndex:]
imageExtents
+[PIPortraitVideoProcessor applyWithInputImage:disparityImage:inputPixelBuffer:disparityPixelBuffer:globalMetadata:timedMetadata:aperture:focusedDisparity:quality:debugMode:isHDR:error:]
inputImage != nil || inputPixelBuffer != nil
disparityImage != nil || disparityPixelBuffer != nil
PIPortrait: cinematic renderer supports RGB10Packed
NormStabilizeInstructions
stabCropRect
Width
Height
flavor
recipe
kernel vec4 ipt_from_srgb(__sample im)
vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) +
im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) +
im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462);
lms = sign(lms)*pow(abs(lms), vec3(0.43));
vec3 ipt = lms.r * vec3(0.4,  4.455,  0.8056) +
lms.g * vec3(0.4, -4.851,  0.3572) +
lms.b * vec3(0.2,  0.396,-1.1628);
return vec4(ipt, im.a);
kernel vec4 ipt_to_srgb(__sample ipt)
vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) +
ipt.g * vec3(0.0976,-0.1139, 0.0326) +
ipt.b * vec3(0.2052, 0.1332,-0.6769);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
vec3 im = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) +
lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812);
return vec4(im, ipt.a);
kernel vec4 ipt_to_hue_chroma(__sample im)
vec4 ihc = im;
ihc.g = atan(im.b, im.g);
ihc.b = sqrt(im.g*im.g+im.b*im.b);
return ihc;
kernel vec4 ipt_from_hue_chroma(__sample ihc)
vec4 ipt = ihc;
ipt.g = ihc.b * cos(ihc.g);
ipt.b = ihc.b * sin(ihc.g);
return ipt;
kernel vec4 ipt_hue_chroma_scale_hue(__sample ihc, vec2 hso) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float hueScale = hso.x;
float hueOffset = hso.y;
hue = hueScale * hue + hueOffset;
return vec4(luma, hue, chroma, alpha);
kernel vec4 ipt_hue_chroma_filter_hue(__sample ihc, vec4 hcr) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float hueTarget = hcr.x;
float hueRange = hcr.y;
float hueModulo = hcr.z;
float chromaMin = hcr.w;
float chromaFactor = step(chromaMin, chroma);
float hueDelta = min(abs(hue - hueTarget), min(abs(hue + hueModulo - hueTarget), abs(hue - hueModulo - hueTarget)));
float hueFactor = 1.0 - smoothstep(0.0, hueRange, hueDelta);
alpha *= hueFactor * chromaFactor;
return vec4(luma, hue, chroma, alpha);
kernel vec4 ipt_hue_chroma_filter_luma(__sample ihc, vec3 hcr) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float lumaTarget = hcr.x;
float lumaRange = hcr.y;
float chromaMax = hcr.z;
float chromaFactor = 1.0 - step(chromaMax, chroma);
float lumaDelta = abs(luma - lumaTarget);
float lumaFactor = 1.0 - smoothstep(0.0, lumaRange, lumaDelta);
alpha *= lumaFactor * chromaFactor;
return vec4(luma, hue, chroma, alpha);
+[PIIPTHueChromaFilter kernelNamed:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIIPTHueChromaFilter.m
ipt_hue_chroma_scale_hue
+[PIIPTHueChromaFilter normalizeHueChromaImage:]
+[PIIPTHueChromaFilter denormalizeHueChromaImage:]
ipt_from_srgb
ipt_to_srgb
ipt_to_hue_chroma
ipt_from_hue_chroma
ipt_hue_chroma_filter_hue
ipt_hue_chroma_filter_luma
-[PIVideoCrossfadeLoopNode initWithSettings:inputs:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Video Stabilization/PIVideoCrossfadeLoopNode.m
input != nil
-[PIVideoCrossfadeLoopNode initWithInput:timeRange:crossfadeDuration:startTime:]
CMTIME_IS_VALID(crossfadeDuration)
CMTIMERANGE_IS_VALID(loopTimeRange)
crossfadeDuration
startTime
loopTimeRange
-[PIVideoCrossfadeLoopNode nodeByReplayingAgainstCache:pipelineState:error:]
Missing primary video frame
video
secondary
Missing secondary video frame
CIDissolveTransition
-[PIVideoCrossfadeLoopNode _evaluateVideo:]
[[AVMutableComposition alloc] init] failed.
No input video track found
Failed to update video track when inserting the pre-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the pre-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update video track when inserting the crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update video track when inserting the post-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the post-crossfade content with source range %@ from track %@ to time %@ in track %@.
-[PIVideoCrossfadeLoopNode _evaluateVideoComposition:]
Unsupported video configuration
-[PIVideoCrossfadeLoopNode _evaluateAudioMix:]
time
scale
radius
falloff
Adjustment empty
-[PIAdjustmentController displayName]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PIAdjustmentController.m
-[PIAdjustmentController inputKeys]
Adjustment does not have an enabled setting
-[PIAdjustmentController enabled]
-[PIAdjustmentController setEnabled:]
Adjustment does not have an auto setting
-[PIAdjustmentController isAuto]
-[PIAdjustmentController setIsAuto:]
<%@: %p; adjustment = %@>
-[PIParallaxFilter outputForegroundImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxFilter.m
-[PIParallaxFilter outputBackgroundImage]
-[PIParallaxFilter outputMatteImage]
-[_PIParallaxClockMaterialJob render:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxClockMaterialRequest.m
Request needs either a layerStack or a segmentationItem
-[PIParallaxClockMaterialRequest initWithComposition:]
__dominantInputSettingsKey
debugMode
disparityKeyframes
apertureKeyframes
NUScaleIsValid(scale)
-[PIPortraitVideoRenderNode _targetScaleForScale:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoRenderNode.m
-[PIPortraitVideoRenderNode nodeByReplayingAgainstCache:pipelineState:error:]
state != nil
-[PIPortraitVideoRenderNode _prewarmPortraitRendererWithPipelineState:error:]
No device specified for prewarm
portraitVideoMetadata
PIPortraitVideoRenderNode: expected a valid portraitVideoMetadata sample
PIPortrait: passing YUV source buffers directly to the cinematic renderer
renderTime
renderQuality
sourceTransferFunction
useSourceBuffersDirectly
Source image isn't backed by a CVPixelBuffer
Could not get the input image
Could not get the disparityImage
Could not get the timed metadata
Could not get the source transfer function
Could not get the render time
PIFaceObservationCache
PIFaceObservationCache-newRequest
Original
StudioBright
StudioDark
ColorBGStandard
BlackWhiteHighKey
BlackWhiteStage
BlackWhiteMono
ColorWashSingle
ColorWashDuotone
Original-Inactive
StudioBright-Inactive
StudioDark-Inactive
ColorBGStandard-Inactive
BlackWhiteHighKey-Inactive
BlackWhiteStage-Inactive
BlackWhiteMono-Inactive
ColorWashSingle-Inactive
ColorWashDuotone-Inactive
The bundle should contain recipes for all known identifiers
+[PIParallaxStyleRecipeRegistry recipeForIdentifier:]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipeRegistry.m
-[PIParallaxStyleUserURLProvider init]
spatialOvercapture
spatialOvercaptureFused
Unspecified Key
Low Key
Neutral Key
High Key
SF Soft Time
SF Rounded Time
New York Time
ADT Slab Time
SF Stencil Time
SF Rail Time
+[PIParallaxStyle styleWithColorAnalysis:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyle.m
clockColor != nil
-[PIParallaxStyle initWithClockColor:colorSuggestions:]
suggestions != nil
Unknown style kind: %@
+[PIParallaxStyle defaultStyleForKind:colorAnalysis:]
+[PIParallaxStyle styleWithParameters:colorSuggestions:]
+[PIParallaxStyle styleWithBakedStyle:]
<%@: %p; parameters = %@>
-[PIParallaxStyle parameters]
-[PIParallaxStyle kind]
-[PIParallaxStyle recipeIdentifier]
-Inactive
BLACK
WHITE
B16@?0@"PFParallaxPaletteSuggestion"8
-[PIParallaxStyle configureForCategory:]
parameters != nil
+[PIParallaxOriginalStyle styleWithParameters:colorSuggestions:]
+[PIParallaxStudioStyle styleWithParameters:colorSuggestions:]
@"PFParallaxPaletteSuggestion"16@?0@"PFParallaxColor"8
backgroundColor != nil
-[PIParallaxColorBGStandardStyle initWithBackgroundColor:clockColor:colorSuggestions:]
+[PIParallaxBlackWhiteMonoStyle styleWithParameters:colorSuggestions:]
@"PFParallaxColor"24@?0@"PFParallaxColor"8@"PIParallaxColorAnalysis"16
@"PFParallaxColor"16@?0@"PFParallaxColor"8
+[PIParallaxColorWashSingleStyle styleWithParameters:colorSuggestions:]
-[PIParallaxColorWashSingleStyle initWithColor:clockColor:suggestions:]
Failed to retrieve secondary color from palette
+[PIParallaxColorWashDuotoneStyle styleWithColorAnalysis:]
+[PIParallaxColorWashDuotoneStyle styleWithParameters:colorSuggestions:]
primaryColor != nil
-[PIParallaxColorWashDuotoneStyle initWithPrimaryColor:secondaryColor:clockColor:colorSuggestions:]
secondaryColor != nil
-[PIParallaxRecipeStyle initWithIdentifier:recipe:]
<%@: %p; identifier = %@, recipe = %@>
timeValue
timeScale
%@: t=%@, v=%f
<%@ %p %@ %@ id=%lu conf=%.2f>
  bounds=%@
  expandedBounds=%@
  edgeBleed=%@
type
confidence
edgeBleed
bounds
expandedBounds
Human Face
Human Body
Cat Body
Cat Head
Dog Body
Dog Head
Salient Object
Unknown
(%.4f, %.4f, %.4f, %.4f)
minX 
minY 
maxX 
maxY 
B16@?0@"PFParallaxLayerStyle"8
<%@:%p class=%@ matte=%@ conf=%@ infill=%@ layout=%@ resource=%@ composition=%@>
archiveURL != nil
-[PIParallaxSegmentationItem saveToURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationItem.m
Failed to create archive directory
asset.resource
Failed to archive asset resource
segmentation.data.aar
Failed to archive segmentation data
-[PIParallaxSegmentationItem loadFromURL:error:]
Failed to load asset resource
Failed to load segmentation data
-[PIParallaxSegmentationItem saveAssetResourceToURL:error:]
Missing asset resource
-[PIParallaxSegmentationItem saveSegmentationDataToURL:error:]
Failed to write segmentation archive
Failed to serialize contents plist
contents.plist
Failed to archive contents plist data
Failed to write segmentation matte
matte.heic
Failed to archive segmentation matte data
Failed to write segmentation background
background.heic
Failed to archive segmentation background data
Failed to close archive file
-[PIParallaxSegmentationItem loadSegmentationDataFromURL:error:]
Failed to read segmentation archive
Failed to decode contents plist data
Expected contents.plist data
Failed to deserialize contents plist
Invalid contents plist
Failed to load contents dictionary
Failed to decode matte image data
Expected matte.heic data
Failed to read matte image data
Failed to decode background image data
Expected background.heic data
Failed to read background image data
Missing context info!
-[PIParallaxSegmentationItem contentsDictionary]
classification
hasMatte
hasBackground
regions
layout
scores
colorAnalysis
localLightData
systemVersion
sourceMode
infillAlgorithm
layoutConfiguration
segmentationDisabled
contents != nil
-[PIParallaxSegmentationItem loadContentsFromDictionary:hasMatte:hasBackground:error:]
Missing version info
Invalid version info
Unsupported version
Invalid system version info
Invalid system name
Invalid system version
Invalid system build version
Invalid source mode
Invalid segmentation disabled flag
Invalid infill algorithm
Invalid layout configuration
Failed to deserialize layout configuration
Missing classification info
Expected classification string
Missing matte image info
Expected boolean
Missing background image info
Expected regions dictionary
Failed to deserialize regions info
Expected layout dictionary
Failed to deserialize layout info
Expected score dictionary
Invalid score key
Invalid score value
Invalid color analysis info
Failed to deserialize color analysis info
styles
Expected styles array
Invalid style value
Invalid style dictionary
Unsupported style kind
Invalid local light data
+[PIParallaxSegmentationItem writeImageBuffer:toURL:error:]
Failed to encode pixel buffer
+[PIParallaxSegmentationItem readImageBufferFromURL:error:]
Failed to decode pixel buffer
+[PIParallaxSegmentationItem dataForImageBuffer:error:]
imageData != nil
+[PIParallaxSegmentationItem imageBufferFromData:error:]
cinematographyState
renderingVersionAtCapture
-[PIParallaxColorSuggester init]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorSuggester.m
analysis != nil
-[PIParallaxColorSuggester initWithColorAnalysis:]
color != nil
-[PIParallaxColorSuggester suggestedColorForColor:]
inputColor
outputColor
hueMin <= hueMax
-[PIParallaxColorSuggester addRuleWithHueMin:hueMax:suggestion:]
B16@?0@"NURuleSystem"8
v16@?0@"NURuleSystem"8
colors != nil
-[PIParallaxColorSuggester suggestedColorsForColors:fromColorPalette:]
B16@?0@"PFParallaxColor"8
homography
<%@:%p time:%@>
<%@: %p; lum = %.3f colors = %@>
-[_PIParallaxColorAnalysisJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorAnalysisRequest.m
-[_PIParallaxColorAnalysisJob prepare:]
Hue/chroma conversion failed
-[_PIParallaxColorAnalysisJob render:]
No storage pool
hue-%ld
gray-%ld
-[_PIParallaxColorAnalysisJob _beginRenderingImage:colorSpace:format:error:]
No storage allocated
hueChromaImage != nil
-[_PIParallaxColorAnalysisJob _beginRenderNormalizedHueChromaImage:targetHue:hueRange:chromaMin:error:]
PIIPTHueChromaColorFilter
inputHueTarget
inputHueRange
inputChromaMin
inputHueIsNormalized
Failed to produce filtered Hue/Chroma image
-[_PIParallaxColorAnalysisJob _beginRenderNormalizedHueChromaImage:targetGray:grayRange:chromaMax:error:]
PIIPTHueChromaGrayFilter
inputLumaTarget
inputLumaRange
inputChromaMax
-[_PIParallaxColorAnalysisJob _waitForRenderResources:]
Failed to render image
Failed to compute histogram
-[_PIParallaxColorAnalysisJob complete:]
q24@?0@"_PIParallaxRenderResource"8@"_PIParallaxRenderResource"16
luminance
foregroundLuminance
backgroundLuminance
@"NSArray"16@?0@"PFParallaxColor"8
colors
foregroundColors
backgroundColors
+[PIParallaxColorAnalysis loadFromContentsDictionary:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorAnalysis.m
Incompatible color analysis version
Invalid luminance value
Invalid color array
Failed to deserialize color values
PILongExposureFusionAutoCalculator-videoProperties
pre-AutoLoop
-[PILongExposureFusionAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PILongExposureFusionAutoCalculator.m
AutoLoop not supported
kind
-[PIAutoLoopAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIAutoLoopAutoCalculator.m
B32@?0@"AVMetadataItem"8Q16^B24
-[PITempTintFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PITempTintFilter.m
-[PIAutoLoopAnalysisJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+Analysis.m
unable to find video source node
-[PIAutoLoopAnalysisJob render:]
AutoLoop is not supported
-[PIVideoStabilizeRenderJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIVideoStabilizeRequest.m
Stabilize request was cancelled
frameInstructions
rawTime
void CreateKeyframesFromHomographyDictionary(NSDictionary *__strong, NUPixelSize, NSMutableArray<PIReframeKeyframe *> *__strong, NUPixelRect *)
PIVideoStabilizeRequest.m
unexpected homography
Failure in ICSynthesizeAnalysis
Failure in ICAnalyzeInputMotion
No available analysis types were allowed
Failure in ICCalcCinematicL1Corrections
neutralGray
faceBalance
tempTint
warmTint
PIFaceBalanceAutoCalculator-imageProperties
+[PIFaceBalanceAutoCalculator calculateWithRequest:completion:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIWhiteBalanceAutoCalculators.m
CIFaceBalance
PIFaceBalanceAutoCalculator-calculate
WarmTemp
WarmTint
warmTemp
+[PIFaceBalanceAutoCalculator calculateRAWWithRequest:completion:]
PIFaceBalanceAutoCalculator-RAW-face-request
+[PIFaceBalanceAutoCalculator faceBalanceResultFromFaceObservations:request:error:]
PIWhiteBalanceAutoCalculator-face-balance
PIRAWFaceBalanceAutoCalculator.responseQueue
Failure in rendering image
OrigI
OrigQ
Warmth
Strength
WarmFace
unsupported format - incorrect white balance
+[PIFaceBalanceAutoCalculator faceBalanceFromFaceImage:forFaceRect:]
{?={?=[4d]}{?=[4d]}d}
{?=[4d]}
colorType
grayColor
-[PIWhiteBalanceAutoCalculator submit:]
PIWhiteBalanceAutoCalculator-imageProperties
PIFaceBalanceAutoCalculator.responseQueue
faceI
faceQ
faceWarmth
faceStrength
PIWhiteBalanceAutoCalculator
color
v16@?0@"<NUBuffer>"8
CIAreaAverage
PIWhiteColorCalculator-computeGreenPercentage
PIWhiteColorCalculator-grayWorld
PIWhiteColorCalculator-grayEdges
return Filter('CIEdges', { 'inputImage' : input, 'inputIntensity' : 1.0 });
Expected non-NULL pixels passed in
void customRGBtoYIQ(const CGFloat *, double *, double, double, double)
vec4 meaningBlur(vec4 im, vec4 b)
vec4 result = im;
float thresh = 0.1;
float g1 = max(max(im.r, im.g), im.b);
float g2 = dot(b.rgb, vec3(1.0/3.0));
float diff = max(g2-g1, -1.0);
diff = smoothstep(0.1-thresh, 0.1+thresh, diff);
result.rgb = mix(im.rgb, b.rgb, diff+0.5);
return result;
vec4 clarityNew(vec4 s, vec4 b, float intensity)
float sl = (s.r + s.g + s.b);
float bl = (b.r + b.g + b.b);
float dl = sl + (sl - bl) * intensity;
float mult = dl / max(sl, 0.0001);
mult = 1.571 * (mult - 1.0);
mult = mult / (1.0 + abs(mult));
mult += 1.0;
mult = clamp(mult, 1.0 - 0.5 * abs(intensity), 1.0 + 1.0 * abs(intensity));
s.rgb = s.rgb * mult;
return s;
kernel vec4 definition(sampler image, sampler blur, float intensity)
vec4 imgSample = sample(image, samplerCoord(image));
vec4 blurSample = sample(blur, samplerCoord(blur));
vec4 meaning = meaningBlur(imgSample, blurSample);
vec4 clarity = clarityNew(imgSample, meaning, intensity);
return clarity;
strength
neutral
tone
inputNeutralGamma
inputTone
inputGrain
inputHue
inputSeed
<%@:%p - priority: %@, color space: %@, scale policy: %@>
<%@:%p - priority: %@, color space: %@, scale policy: %@, video codec type: %@, bypass settings: %@, orientation as metadata: %@, hardware encoder: %@>
Export URL UTI (%@) does not match expected export format (%@)
-[PICompositionExporterImageOptions imageExportFormatForURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PICompositionExporter.m
metadataConverter must be set
-[PICompositionExporter init]
PICompositionExporter-videoProperties
Expecting HEIF/HEVC or JPEG/H264 when exporting Live Photo still and video complement
Unexpected video codec when attempting to export Live Photo
Unexpected image export format when attempting to export Live Photo
_companion
unable to prepare image properties
PICompositionExporter-image
PICompositionExporter-auxPropertiesRequest
PICompositionExporter-%@
PICompositionExporter.imageProperties.transaction
Regions
-[PICompositionExporter addVideoProperties:composition:options:error:]
Unknown autoloop flavor
PICompositionExporter-video
float luminanceWeight(vec4 pix, vec4 center, float slope)
return max(1.0 + (slope * length(pix.rgb - center.rgb)), 0.0);
vec4 bilateralRow_1(sampler src, float slope, vec2 offset1, float weight1)
float diff1;
vec2 coord;
vec4 pix1, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
diff1 = luminanceWeight(pix1, center, slope) * weight1;
return vec4(diff1 * pix1.rgb, diff1);
kernel vec4 bilateralAdd_1(sampler src, sampler sums, float slope, vec2 offset1, float weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_1(src, slope, offset1, weight1);
vec4 bilateralRow_2(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 weight1)
float diff1, diff2;
vec2 coord;
vec4 pix1, pix2, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb, diff1 + diff2);
kernel vec4 bilateralAdd_2(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_2(src, slope, offset1, offset2, weight1);
vec4 bilateralRow_3(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
float diff1, diff2, diff3;
vec2 coord;
vec4 pix1, pix2, pix3, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb, diff1 + diff2 + diff3);
kernel vec4 bilateralAdd_3(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_3(src, slope, offset1, offset2, offset3, weight1);
vec4 bilateralRow_4(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec4 weight1)
float diff1, diff2, diff3, diff4;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb,
diff1 + diff2 + diff3 + diff4);
kernel vec4 bilateralAdd_4(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3,
vec2 offset4, vec4 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_4(src, slope, offset1, offset2, offset3, offset4, weight1);
vec4 bilateralRow_5(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec4 weight1, float weight2)
float diff1, diff2, diff3, diff4, diff5;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb,
diff1 + diff2 + diff3 + diff4 + diff5);
kernel vec4 bilateralAdd_5(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec4 weight1, float weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_5(src, slope, offset1, offset2, offset3, offset4, offset5, weight1, weight2);
vec4 bilateralRow_6(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec4 weight1, vec2 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6);
kernel vec4 bilateralAdd_6(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec4 weight1, vec2 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_6(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, weight1, weight2);
vec4 bilateralRow_7(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7);
kernel vec4 bilateralAdd_7(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_7(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, weight1, weight2);
vec4 bilateralRow_8(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6,
vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8);
kernel vec4 bilateralAdd_8(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_8(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, weight1, weight2);
vec4 bilateralRow_9(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6, vec2 offset7,
vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, pix9, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
pix9 = sample(src, samplerTransform(src, coord + offset9));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
diff9 = luminanceWeight(pix9, center, slope) * weight3;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb + diff9 * pix9.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8 + diff9);
kernel vec4 bilateralAdd_9(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_9(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, offset9,
weight1, weight2, weight3);
kernel vec4 bilateralFinalize(sampler sums)
vec4 sum;
sum = sample(sums, samplerCoord(sums));
return vec4(sum.rgb / max(sum.a, 0.001), 1.0);
kernel vec4 bilateralLoop2(sampler src, float slope, vec2 weights12)
vec2 coord;
vec4 center = sample(src, samplerCoord(src));
vec4 sum;
vec4 pix0, pix1, pix2;
vec4 pix3,       pix5;
vec4 pix6, pix7, pix8;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-2.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -1.0));
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dy;
pix3 = sample(src, coord);
coord = coord + dx;
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dy;
pix6 = sample(src, coord);
coord = coord + dx;
pix7 = sample(src, coord);
coord = coord + dx;
pix8 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights12.y);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights12.x) + sum;
sum =                                        center                            + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix7 - center)))) * (pix7 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix8 - center)))) * (pix8 * weights12.y) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop5(sampler src, float slope, vec4 weights1245)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-4.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -2.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop11(sampler src, float slope, vec4 weights1245, vec4 weights89AD)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4, pix5, pix6;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-6.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-2.0, -3.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.y) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 convertFromRGBToLab(sampler src)
vec3 f;
vec4 pix, color;
pix = unpremultiply(sample(src, samplerCoord(src)));
color.xyz = pix.r * vec3(0.449695,  0.316251, 0.18452  )
+ pix.g * vec3(0.244634,  0.672034, 0.0833318)
+ pix.b * vec3(0.0251829, 0.141184, 0.922602 );
color.xyz *= vec3(1.052111, 1.0, 0.918417);
f = compare(color.xyz - 0.00885645, 7.787037 * color.xyz + 0.137931, pow(color.xyz, vec3(0.333333)));
color.r = 116.0 * f.y - 16.0;
color.g = 500.0 * (f.x - f.y);
color.b = 200.0 * (f.y - f.z);
color.rgb *= 0.005;
color.a = 1.0;
return color;
kernel vec4 convertFromLabToRGB(sampler src, sampler original)
vec3 f, cie;
vec4 color, pix, opix;
pix = sample(src, samplerCoord(src));
opix = sample(original, samplerCoord(original));
pix.rgb *= 200.0;
f.y = (pix.r + 16.0) / 116.0;
f.x = f.y + pix.g * 0.002;
f.z = f.y - pix.b * 0.005;
color.xyz = f * f * f;
cie = compare(color.xyz - 0.00885645, (f.xyz - 0.137931) / 7.787037, color.xyz);
cie *= vec3(0.95047, 1.0, 1.08883);
color.rgb = cie.x * vec3(2.95176,   -1.28951, -0.47388  )
+ cie.y * vec3(-1.0851,    1.99084,  0.0372023)
+ cie.z * vec3(0.0854804, -0.269456, 1.09113  );
color.a = opix.a;
return premultiply(color);
bilateralAdd_1
bilateralAdd_2
bilateralAdd_3
bilateralAdd_4
bilateralAdd_5
bilateralAdd_6
bilateralAdd_7
bilateralAdd_8
bilateralAdd_9
bilateralFinalize
convertFromRGBToLab
convertFromLabToRGB
points.count > 0
-[GUBilateralConvolution boundsForPointArray:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIBilateralFilter.m
bilateralLoop2
bilateralLoop5
bilateralLoop11
inputEdgeDetail
ridiculously large radius for bilateral filter
-[PIBilateralFilter outputImage]
inputPoints
inputWeights
unable to allocate convolution table in bilateral filter
com.apple.livephoto
com.apple.video
com.apple.video.slomo
.%lu
%lu.%lu%@%@
satPercentile75
satPercentile98
satPercentileG98
satAutoValue
inputVibrancy
inputCast
kernel vec4 _smartcolor_contrast_HDR (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 strength = max(strength, -0.35); 
 vec4 result; 
 result.rgb = im.rgb/(strength + 1.0 - (im.rgb*strength)) + pos; 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_contrast_darken_HDR (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 float gray = 1.0-min(dot(im.rgb, vec3(0.5, 0.7, -0.20)), 1.0); 
 vec4 result; 
 result.rgb = strength < 0.0 ? pow(im.rgb, vec3(1.0-strength*gray)) : im.rgb/(strength+1.0-(im.rgb*strength)); 
 result.rgb += pos; result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_gt1_HDR (__sample im, float amt) 
 float gray = dot(clamp(im.rgb, 0.0, 1.0), vec3(.3, .5, .2)); 
 float y = dot(clamp(im.rgb, 0.0, 1.0), vec3(.4, .2, .1)); 
 float damp = 1.0-4.0*y*(1.0-y); 
 float s = 1.0/(im.r+im.g+im.b); 
 float r = im.r*s; 
 float b = im.b*s; 
 float d = 1.0-.8*smoothstep(0.2, 0.4, r-b); 
 damp *= d; 
 damp = amt > 2.5 ? min(damp+(amt-2.5)/5.0, 1.0) : damp; 
 float sat = min(amt, 3.0); 
 vec4 result; 
 result.rgb = (im.rgb - gray)*sat + gray; 
 result.rgb = mix(im.rgb, result.rgb, damp); 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_lt1_HDR (__sample im, float amt) 
 float gray = dot(im.rgb, vec3(0.333333)); 
 im.rgb = mix(vec3(gray), im.rgb, amt); 
 return im; 
kernel vec4 _smartcolor_cast_HDR (__sample im, float lum, float grayI, float grayQ, float strength) 
 vec4 pix = clamp(im, 0.0, 1.0); 
 pix.rgb = pow(pix.rgb, vec3(.25)); 
 pix.rgb = pix.r * vec3(0.299, 0.595716, 0.211456) + 
 pix.g * vec3(0.587, -0.274453, -0.522591) + 
 pix.b * vec3(0.114, -0.321263, 0.311135); 
 vec2 grayOffset = vec2(grayI, grayQ) ; 
 vec3 result = pix.rgb; 
 float newStrength = 1.0 + (strength-1.0)*(1.0-pix.r) ; 
 result.gb = pix.gb + newStrength*grayOffset ; 
 float damp = max(min(1.0, pix.r/(lum+0.00001)),0.0) ; 
 result.rgb = mix(pix.rgb, result.rgb, damp) ; 
 pix.rgb = result.r * vec3(1.0) + 
 result.g * vec3(0.956296, -0.272122, -1.10699) + 
 result.b * vec3(0.621024, -0.647381, 1.70461); 
 pix.rgb = clamp(pix.rgb, 0.0, 1.0); 
 pix.rgb *= pix.rgb*pix.rgb*pix.rgb; 
 pix.rgb += min(im.rgb, 0.0) + max(im.rgb,1.0) -1.0; 
 return pix; 
CIVibrance
inputAmount
PISmartColorHDR-sat-histogram
Aperture
Photos
ColorNorm
inputAlgorithm
Auto-Enhance input: %llX, target: %llX
%@-%llX
*** failed to compute color normalization, ignored
PIAutoEnhanceFilter
CILocalLight
*** failed to compute smart tone statistics: %@
CISmartTone
autoValue
localAutoValue
CISmartColor
*** failed to compute smart color statistics: %@
*** failed to compute face balance statistics: %@
inputOrigI
inputOrigQ
inputWarmth
inputShadows
CILocalLightFilter
inputLocalLight
inputSmartShadows
inputLightMap
lightMap
inputLightMapWidth
lightMapWidth
inputLightMapHeight
lightMapHeight
CIHighKey
inputBrightness
inputExposure
inputContrast
inputHighlights
inputBlack
inputRawHighlights
-[PIParallaxCompoundLayerStackRequest initWithSegmentationItem:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxCompoundLayerStackRequest.m
-[PIParallaxCompoundLayerStackRequest initWithComposition:]
-[PIParallaxCompoundLayerStackRequest newRenderJob]
v16@?0@"PFParallaxLayerStack"8
v24@?0@"NSString"8Q16
v16@?0@"PFParallaxLayout"8
@"<NURenderStatistics>"16@?0@"<NURenderResult>"8
crossfadeDurationValue
crossfadeDurationTimescale
startTimeValue
startTimeTimescale
timeRangeStartValue
timeRangeStartTimescale
timeRangeDurationValue
timeRangeDurationTimescale
CIConstantColorGenerator
Failed to produce histogram for matte image
+[PISegmentationHelper histogramForSegmentationMatteImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationHelper.m
q24@?0^q8q16
CIColorThreshold
CIColorInvert
segmentationMatte != nil
+[PISegmentationHelper computeAvoidOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:outputUnsafeOverlap:context:]
+[PISegmentationHelper _computeAvoidingRect:imageSize:maxYMotion:segmentationMatte:layoutConfiguration:context:]
saliency preferred
saliency acceptable
padded
inactive
inTime
visible
device %d x %d
9:41
Semibold
bg lum
bg col %ld
fg lum
fg col %ld
Helvetica
CICircleGenerator
portraitInfo
spillMatteAllowed
legacyPosterStyle
+[PIParallaxLegacyPosterStyle applyInactiveStyleToImage:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLegacyPosterStyle.m
Inactive filter is not available
Failed to produce background image with filter
@"NUAdjustment"16@?0@"NUAdjustment"8
grayI
grayQ
grayWarmth
grayY
warmFace
-[PIOrientationAdjustmentController setOrientation:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PIOrientationAdjustmentController.m
+[PIParallaxStyleRecipeArchiver writeRecipe:toURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipeArchiver.m
Failed to open recipe destination file
+[PIParallaxStyleRecipeArchiver serializeRecipe:]
parameters
foreground
background
matte
+[PIParallaxStyleRecipeArchiver unarchivedStyleRecipeWithURL:error:]
Failed to open recipe source file
+[PIParallaxStyleRecipeArchiver deserializeRecipe:error:]
dictionary != nil
Missing recipe parameters
Invalid recipe parameters
Failed to deserialize recipe parameters
Missing foreground filters
Invalid foreground filters dictionary
Failed to deserialize foreground filters
Missing background filters
Invalid background filters dictionary
Failed to deserialize background filters
Missing matte filters
Invalid matte filters dictionary
Failed to deserialize matte filters
unit
Unknown parameter type: %@
+[PIParallaxStyleRecipeArchiver _serializeParameter:]
+[PIParallaxStyleRecipeArchiver _deserializeParameters:version:error:]
Invalid parameter name
Invalid parameter dictionary
v32@?0@"NSString"8@"NSDictionary"16^B24
+[PIParallaxStyleRecipeArchiver _deserializeParameter:version:error:]
Missing parameter type
Invalid parameter type
number
Missing number value
Expected a number value
Invalid unit value
Unknown unit value
Missing color values
Expected color values
Expected 4 color values
Expected 4 numbers
Expected 3 color values
Expected 3 numbers
point
Missing point values
Expected point values
Expected 2 point values
Expected 2 numbers
Missing mode value
Expected mode value
binding
Missing binding value
Expected binding value
Unrecognized parameter type
v32@?0@"PIParallaxStyleDefinition"8Q16^B24
filter
name
filters
Unknown definition type: %@
+[PIParallaxStyleRecipeArchiver _serializeDefinition:]
serializedFilters != nil
+[PIParallaxStyleRecipeArchiver _deserializeFilterDefinitions:version:error:]
Invalid definition dictionary
v32@?0@"NSDictionary"8Q16^B24
+[PIParallaxStyleRecipeArchiver _deserializeFilterDefinition:version:error:]
Missing definition type
Invalid filter definition type
filterName
Missing filter name
Invalid filter name
Missing filter parameters
Invalid filter parameters
Filed to deserialize filter parameters
Missing stack name
Invalid stack name
Missing stack filters
Invalid stack filters
Failed to deserialize stack filters
Unrecognized definition type
mdta/com.apple.quicktime.cinematic-video.rendering
mdta/com.apple.quicktime.disparity-float
mdta/com.apple.quicktime.aperture-float
mdta/com.apple.quicktime.camera-dictionary
PIPortraitVideoMetadata.m
metadataGroup != nil
outError != nil
Could not decode timed rendering data
Missing disparity rendering metadata
Missing aperture rendering metadata
v24@?0@"PTRenderPipeline"8@"<PTRenderState>"16
device != nil
-[PIPortraitVideoRenderer initWithDevice:colorSize:disparitySize:quality:debugMode:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoRenderer.m
!NUPixelSizeIsEmpty(colorSize)
!NUPixelSizeIsEmpty(disparitySize)
quality >= PTQualityPreviewLow && quality <= PTQualityExportProfessional
<%@:%p device:%@ color=%ldx%ld disparity=%ldx%ld quality=%d debug=%ld>
PIPortraitVideoRenderer.pool
B32@?0@"PIPortraitVideoRenderer"8Q16^B24
Expected _renderPipeline and _renderState to be allocated at the same time
-[PIPortraitVideoRenderer prepareToRenderWithMetadata:]
kernel vec4 _highKeyHDR(__sample im, float str) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0) - 1.0; 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0-((im-1.0)*(im-1.0)); 
 im2 = sqrt(im2); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = sqrt(1.0-(y-1.0)*(y-1.0)); 
 y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 im3 = mix(im3, im2, .7*sqrt(y2)); 
 im3 = mix(im, im3, sqrt(y)) ; 
 im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg; 
 return im; } 
None
UnexpectedRuntimeError
NoBuildingDetected
PanoAndFFCNotSupported
FacesTooLarge
ConfidenceTooLow
LimitExceeded
NotEnoughLines
CorrectedAreaIsSmall
LessThanMinimumCorrection
-[PIPerspectiveAutoCalculator initWithComposition:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIPerspectiveAutoCalculator.m
%@.%@
%@.error
%@.underlyingError
pitchError
yawError
pitchError.underlyingError
yawError.underlyingError
%@PerspectiveEvaluation-txt.DBG
%@PerspectiveLineDetection-png.DBG
Edit
PIPerspectiveAutoCalculator-debug
faces != nil
-[PIPerspectiveAutoCalculator getSizeOfAllFaces:]
-[PIPerspectiveAutoCalculator passesFaceCheck:]
PIPerspectiveAutoCalculator-faceCheck
faceSize
maxFaceSize
passesFaceCheck
Apple
front
camera
-[PIPerspectiveAutoCalculator passesImagePropertiesCheck:]
PIPerspectiveAutoCalculator-selfieAndAspectRatioCheck
aspectRatio
isSelfieCam
passesImagePropertiesCheck
-[PIPerspectiveAutoCalculator passesBuildingCheck:]
PIPerspectiveAutoCalculator-classify
minConfidence
passesBuildingCheck
-[PIPerspectiveAutoCalculator submit:]
pitch
angle
-[PIPerspectiveAutoCalculator overcaptureImageProperties:]
No overcapture
PIPerspectiveAutoCalculator-overcaptureImageProperties
-[PIPerspectiveAutoCalculator primaryImageProperties:]
PIPerspectiveAutoCalculator-primaryImageProperties
-[PIPerspectiveAutoCalculator canGenerateNewCropRect:]
preseedRoll
canGenerateNewCropRect
setToPrimary
xOrigin
yOrigin
width
height
pitch != nil
+[PIPerspectiveAutoCalculator undoOrientation:forPitch:yaw:angle:]
yaw != nil
angle != nil
-[PIPerspectiveAutoCalculator passesConfidenceCheck:error:]
passesConfidenceCheck
supported
Not supported by Core Image. Default: YES
-[PIPerspectiveAutoCalculator passesMinimumCorrectionCheck:error:]
pitchExpandTopDegrees
yawExpandLeftDegrees
rollAngleInDegreesCW
passesMinimumCorrectionCheck
minimumPitchCorrection
minimumYawCorrection
minimumAngleCorrection
-[PIPerspectiveAutoCalculator submitVerified:]
focalLength
pitchLimit
yawLimit
rollLimit
minimumPitchCorrectionArea
minimumYawCorrectionArea
CIAutoPerspective
submitVerified
debugImage
pitchCorrectionAreaCoverage
yawCorrectionAreaCoverage
ciPitchError
ciYawError
PIPerspectiveAutoCalculator-getPrimaryOrientation
Flash
FNumber
ApertureValue
ShutterSpeedValue
ExposureTime
ISOSpeedRatings
cannot set empty crop rect
-[PICropAdjustmentController setCropRect:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PICropAdjustmentController.m
constraintWidth
constraintHeight
smart
originalCrop
inputDecoderVersion
v32@?0@"NSString"8@16^B24
definitions != nil
-[PIParallaxRecipeFilter _evaluateImageWithFilterDefinitions:inputImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxRecipeFilter.m
Failed to produce an image
inputLight
offsetBlack
offsetBrightness
offsetContrast
offsetExposure
offsetHighlights
offsetLocalLight
offsetShadows
statistics
overcaptureStatistics
kernel vec4 alphaCompositing(__sample src, __sample dst, float a)
return mix(dst, src, a);
kernel vec4 dynamismMap(sampler imageMax, sampler imageMin, float logisticGain, float logisticMid) __attribute__((outputFormat(kCIFormatRGBAh)))
const float MAX_VAL = 1.74;
const float THRESHOLD = 0.05;
vec2 dc = destCoord();
vec2 sc;
sc = dc + vec2(-1,-1);
vec4 pMax00 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin00 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,0);
vec4 pMax01 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin01 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,1);
vec4 pMax02 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin02 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(0,-1);
vec4 pMax10 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin10 = sample(imageMin, samplerTransform(imageMin, sc));
vec4 pMax11 = sample(imageMax, samplerTransform(imageMax, dc));
vec4 pMin11 = sample(imageMin, samplerTransform(imageMin, dc));
sc = dc + vec2(0,1);
vec4 pMax12 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin12 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,-1);
vec4 pMax20 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin20 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,0);
vec4 pMax21 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin21 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,1);
vec4 pMax22 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin22 = sample(imageMin, samplerTransform(imageMin, sc));
float minDevCMaxNMin = distance(pMax11, pMin00);
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin01) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin02) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin10) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin11) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin12) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin20) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin21) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin22) );
float minDevCMinNMax = distance(pMin11, pMax00);
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax01) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax02) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax10) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax11) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax12) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax20) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax21) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax22) );
float outVal = min(minDevCMaxNMin , minDevCMinNMax) / MAX_VAL;
outVal = 1.0f / (1.0f + exp(-logisticGain*(outVal - logisticMid)));
vec4 outPixel = vec4(outVal, outVal, outVal, 1.0);
return outPixel;
kernel vec4 jointbilateralfilter(sampler mask, sampler guide, vec2 rad, vec3 sig) __attribute__((outputFormat(kCIFormatRh)))
vec2 coord = destCoord();
float rh = rad.x;
float rv = rad.y;
vec4 p0 = sample(mask, samplerTransform(mask, coord));
vec4 g0 = sample(guide, samplerTransform(guide, coord));
vec4 result = vec4(0.0f);
float w_sum = 0.0f;
for(float yo=-rad.y;  yo<=rad.y;  yo++) {
for(float xo=-rad.x;  xo<=rad.x;  xo++) {
vec2 dc = vec2(xo, yo);
vec4 p = sample(mask, samplerTransform(mask, coord + dc));
vec4 g = sample(guide, samplerTransform(guide, coord + dc));
float d = dot(dc, dc);
float pdif = dot(p-p0,p-p0);
float gdif = dot(g-g0,g-g0);
float w = exp(dot(sig, vec3(d,pdif,gdif)));
result += w*p;
w_sum += w;
result /= w_sum;
return vec4(result.rgb, 1.0);
kernel vec4 rgba_to_luma(__sample rgb)
const vec4 rgb2y = vec4(0.2999,0.5870,0.1140,0.0);
float luma = dot(rgb, rgb2y);
return vec4(luma, luma, luma, 1.0);
kernel vec2 warp_homography(vec3 h012, vec3 h345, vec3 h678)
vec3 coord = vec3(destCoord(), 1.f);
float norm = 1.f / dot(h678, coord);
float x = norm * dot(h012, coord);
float y = norm * dot(h345, coord);
return vec2(x,y);
kernel vec4 ncc_compute(sampler img1, sampler img2) __attribute__((outputFormat(kCIFormatR8)))
vec2 coord = destCoord();
float sum1   = float(0.0);
float sum2   = float(0.0);
float sumSq1 = float(0.0);
float sumSq2 = float(0.0);
float sumCrs = float(0.0);
float ncc;
float p1, p2;
const int halfKernel = 3;
const vec4 meanOp = vec4(1.0/3.0, 1.0/3.0, 1.0/3.0, 0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
p1 = dot(meanOp, sample(img1, samplerTransform(img1, coord + vec2(x, y))));
p2 = dot(meanOp, sample(img2, samplerTransform(img2, coord + vec2(x, y))));
sum1 += p1;
sum2 += p2;
sumSq1 += p1*p1;
sumSq2 += p2*p2;
sumCrs += p1*p2;
count += 1.0;
float denom = (sumSq1-sum1*sum1/count) * (sumSq2-sum2*sum2/count);
ncc = compare(denom, 0.0, ((sumCrs-(sum1*sum2/count)))/sqrt(denom));
ncc = max(ncc, 0.0);
return vec4(ncc, ncc, ncc, 1.0);
kernel vec4 ncc_coarse_compute(__sample ncc, vec2 edge) __attribute__((outputFormat(kCIFormatR8)))
float value = smoothstep(edge.x, edge.y, ncc.r);
return vec4(value, value, value, 1.0);
kernel vec4 blur_image_compute_3x3(sampler img)
const int halfKernel = 1;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_5x5(sampler img)
const int halfKernel = 2;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_7x7(sampler img)
const int halfKernel = 3;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 fuse_image_compute(sampler refImg, sampler guideImg, sampler blurImg, sampler weightImg, sampler maskImg, vec2 threshold)
vec4 ref       = sample(refImg, samplerCoord(refImg));
vec4 refBlur   = ref;
vec4 guide     = sample(guideImg, samplerCoord(guideImg));
vec4 guideBlur = sample(blurImg, samplerCoord(blurImg));
float weight   = sample(weightImg, samplerCoord(weightImg)).r;
float mask     = sample(maskImg, samplerCoord(maskImg)).r;
vec3 CbCoef = vec3(-0.1726, -0.3391, 0.5117);
vec3 CrCoef = vec3(0.5115, -0.4282, -0.0830);
float CbRef   = dot(CbCoef, ref.rgb);
float CbGuide = dot(CbCoef, guideBlur.rgb);
float CrRef   = dot(CrCoef, ref.rgb);
float CrGuide = dot(CrCoef, guideBlur.rgb);
float crDiff = smoothstep(0.0, 0.2, abs(CbRef-CbGuide));
float cbDiff = smoothstep(0.0, 0.2, abs(CrRef-CrGuide));
float chDiff = smoothstep(0.0,0.3,crDiff+cbDiff);
float weight1 = (1.0-smoothstep(threshold.x,threshold.y,mask));
weight *= weight1 * (1.0-chDiff);
vec4 value = mix(ref, (0.9*(guide-guideBlur)+refBlur), weight);
return value;
jointbilateralfilter
rgba_to_luma
warp_homography
ncc_compute
ncc_coarse_compute
blur_image_compute_7x7
blur_image_compute_5x5
blur_image_compute_3x3
fuse_image_compute
CIPhotoEffectMono
Mono
CIPhotoEffectTonal
Tonal
CIPhotoEffectNoir
Noir
CIPhotoEffectFade
Fade
CIPhotoEffectChrome
Chrome
CIPhotoEffectProcess
Process
CIPhotoEffectTransfer
Transfer
CIPhotoEffectInstant
Instant
CIPhotoEffect3DVivid
3DVivid
CIPhotoEffect3DVividWarm
3DVividWarm
CIPhotoEffect3DVividCool
3DVividCool
CIPhotoEffect3DDramatic
3DDramatic
CIPhotoEffect3DDramaticWarm
3DDramaticWarm
CIPhotoEffect3DDramaticCool
3DDramaticCool
CIPhotoEffect3DSilverplate
3DSilverplate
CIPhotoEffect3DNoir
3DNoir
CIPortraitEffectBlack
Black
CIPortraitEffectBlackoutMono
BlackoutMono
CIPortraitEffectStageV2
StageV2
CIPortraitEffectStageMonoV2
StageMonoV2
CIPortraitEffectStageWhite
StageWhite
CIPortraitEffectLight
Light
CIPortraitEffectCommercial
Commercial
CIPortraitEffectContour
Contour
CIPortraitEffectStudioV2
StudioV2
CIPortraitEffectContourV2
ContourV2
%@ (preview) %a
%@ %a
+[PIPhotoEditHelper imageSourceWithURL:type:useEmbeddedPreview:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIPhotoEditHelper.m
+[PIPhotoEditHelper imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:]
+[PIPhotoEditHelper imageSourceWithCIImage:orientation:]
+[PIPhotoEditHelper videoSourceWithURL:]
photoSource != nil
+[PIPhotoEditHelper livePhotoSourceWithPhotoSource:videoSource:]
videoSource != nil
%@+%@
name != nil
+[PIPhotoEditHelper newAdjustmentWithName:]
+[PIPhotoEditHelper newAdjustmentWithIdentifier:]
+[PIPhotoEditHelper newImageRenderClientWithName:]
+[PIPhotoEditHelper geometryRequestWithComposition:]
+[PIPhotoEditHelper imagePropertiesRequestWithComposition:]
+[PIPhotoEditHelper videoPropertiesRequestWithComposition:]
targetSize.width > 0 && targetSize.height > 0
+[PIPhotoEditHelper imageRenderRequestWithComposition:fitInSize:wideGamut:]
PIPhotoEditHelper-targetSize-image
+[PIPhotoEditHelper imageRenderRequestWithComposition:fillInSize:wideGamut:]
PIPhotoEditHelper-fillSquare-image
+[PIPhotoEditHelper _imageRenderRequestWithComposition:wideGamut:]
PIPhotoEditHelper-basic-image
+[PIPhotoEditHelper videoRenderRequestWithComposition:fitInSize:]
v16@?0q8
overrideVideoEditability
v32@?0@"NSString"8@"NSString"16^B24
var image = input;
ResetTagInput('/pre-VideoReframe', image);
image = GetTag('VideoReframe');
ResetTagInput('/pre-Geometry', image);
return GetTag('/post-Geometry');
/pre-VideoReframe
VideoReframe
/pre-Geometry
/post-Geometry
/ShowOriginalSource
ResetTagInput('/pre-Geometry', input);
return GetTag('/post-Geometry');
PIPhotoEditHelper.m
inputCorrectionInfo
depthInfo
start
startScale
endScale
SkipShaderPrewarm
boostVersion
boostParams
gainMapVersion
gainMapParameters
kernel vec4 forwardBoostWithBoost(sampler image, float boost) {
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k) - k;
vec3 neg = min(im.rgb, 0.0);
neg *= 2.8;
im.rgb = clamp(im.rgb, 0.0, k);
im.rgb = ((1.0+n)*im.rgb)/(1.0+(n*im.rgb)) + neg;
im.r = pos.r > 0.0 ? (.91803 + .470304*pos.r) : im.r;
im.g = pos.g > 0.0 ? (.91803 + .470304*pos.g) : im.g;
im.b = pos.b > 0.0 ? (.91803 + .470304*pos.b) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
kernel vec4 inverseBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float kinv = 0.91803;
vec3 pos = max(im.rgb, kinv);
vec3 neg = min(im.rgb, 0.0);
im.rgb = clamp(im.rgb, 0.0, kinv);
neg *= .35714286;
im.rgb = im.rgb/(n+1.0-(im.rgb*n)) + neg;
im.r = pos.r > kinv ? 0.8 + 2.126286*(pos.r-kinv) : im.r;
im.g = pos.g > kinv ? 0.8 + 2.126286*(pos.g-kinv) : im.g;
im.b = pos.b > kinv ? 0.8 + 2.126286*(pos.b-kinv) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
kernel vec4 forwardBoost3(__sample im, float boost, vec4 abcd, vec3 p0, vec3 p1) {
float a = abcd.x;
float b = abcd.y;
float c = abcd.z;
float d = abcd.w;
vec3 x = im.rgb;
vec3 f = (a * x + b) / (c * x + d);
float x0 = p0.x;
float y0 = p0.y;
float s0 = p0.z;
float a0 = y0*y0;
float c0 = y0 - s0*x0;
float d0 = s0*x0*x0;
vec3 f0 = (a0 * x) / (c0 * x + d0);
vec3 l0 = (a0 / d0) * x;
f0 = compare(x, l0, f0);
float x1 = p1.x;
float y1 = p1.y;
float s1 = p1.z;
float a1 = (1.f-y1)*(1.f-y1);
float c1 = (1.f-y1) - s1*(1.f-x1);
float d1 = s1 *(1.f-x1)*(1.f-x1);
vec3 f1 = 1.f - (a1 * (1.f - x)) / (c1 * (1.f - x) + d1);
vec3 l1 = 1.f - (a1 / d1) * (1.f - x);
f1 = compare(1.f - x, l1, f1);
f = compare(x - p0.x, f0, compare(x - p1.x, f, f1));
im.rgb = mix(im.rgb, f, boost);
return im;
kernel vec4 inverseBoost3(__sample im, float boost, vec4 abcd, vec3 p0, vec3 p1) {
float a = abcd.x;
float b = abcd.y;
float c = abcd.z;
float d = abcd.w;
vec3 y = im.rgb;
vec3 g = (d * y - b) / (a - c * y);
float x0 = p0.x;
float y0 = p0.y;
float s0 = p0.z;
float a0 = x0*x0;
float c0 = x0 - y0/s0;
float d0 = y0*y0/s0;
vec3 g0 = (a0 * y) / (c0 * y + d0);
vec3 l0 = (a0 / d0) * y;
g0 = compare(y, l0, g0);
float x1 = p1.x;
float y1 = p1.y;
float s1 = p1.z;
float a1 = (1.f-x1)*(1.f-x1);
float c1 = (1.f-x1) - (1.f-y1)/s1;
float d1 = (1.f-y1)*(1.f-y1)/s1;
vec3 g1 = 1.f - (a1 * (1.f - y)) / (c1 * (1.f - y) + d1);
vec3 l1 = 1.f - (a1 / d1) * (1.f - y);
g1 = compare(1.f - y, l1, g1);
g = compare(y - p0.y, g0, compare(y - p1.y, g, g1));
im.rgb = mix(im.rgb, g, boost);
return im;
+[PIFakeBoost kernelFB0]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIFakeBoost.m
+[PIFakeBoost kernelFB3]
properties != nil
+[PIFakeBoost boostParametersFromRawProperties:]
-[PIFakeBoost outputImageFB0]
-[PIFakeBoost outputImageFB3]
Invalid boost parameters
Invalid points parameters
boost kernel is nil
+[PIForwardFakeBoost kernelFB0]_block_invoke
+[PIForwardFakeBoost kernelFB3]_block_invoke
inverse boost kernel is nil
+[PIInverseFakeBoost kernelFB0]_block_invoke
+[PIInverseFakeBoost kernelFB3]_block_invoke
PIAttributeTypeMode
PIAttributeAvailableModes
default
metallib
Failed to load metal lib data: %@
+[PICoreImageUtilities metalLibraryData]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PICoreImageUtilities.m
AutoEnhance
AutoLoop
Crop
DepthEffect
Effect
Effect3D
Grain
HighResolutionFusion
LivePhotoKeyFrame
Mute
PortraitEffect
PortraitVideo
RedEyeBB
SelectiveColor
SemanticEnhance
SlowMotion
SmartBlackAndWhite
SmartColor
SmartTone
SourceSelect
Trim
VideoCrossfadeLoop
VideoPosterFrame
VideoStabilize
WhiteBalance
compositionName
identifierName
custom
customSerialization
customCompositionName
customIdentifierName
requiresEnabled
offsetBlackPoint
v24@?0@"NSDictionary"8@"NUAdjustment"16
v32@?0@8@16^B24
offsetSaturation
offsetCast
offsetStrength
offsetGrain
offsetTone
inputBlackAndWhite
offsetNeutralGamma
amount
seed
DGVignetteEffectOperation
Vignette
inputIntensity
inputRadius
inputFalloff
DGDefinition2Operation
Definition
RKNoiseReductionOperation
NoiseReduction
edgeDetail
RKProSharpenOperation
Sharpen
inputEdgeScale
edges
inputSharpness
@"NSString"16@?0@"NSDictionary"8
effectName
@"NSString"24@?0@"NSDictionary"8@"NUAdjustment"16
effectVersion
effectIntensity
CropStraighten
straightenAngle
DGRAWReduceNoiseOperation
RawNoiseReduction
inputDetailAmount
detail
inputCNRAmount
inputLNRAmount
RKRawDecodeOperation
inputMethodVersion
colorComponents
slope
bias
RKLevelsOperation
Levels
colorSpace
inputColorSpace
blackSrcRGB
blackDstRGB
shadowSrcRGB
shadowDstRGB
midSrcRGB
midDstRGB
hilightSrcRGB
hilightDstRGB
whiteSrcRGB
whiteDstRGB
blackSrcRed
blackDstRed
shadowSrcRed
shadowDstRed
midSrcRed
midDstRed
hilightSrcRed
hilightDstRed
whiteSrcRed
whiteDstRed
blackSrcGreen
blackDstGreen
shadowSrcGreen
shadowDstGreen
midSrcGreen
midDstGreen
hilightSrcGreen
hilightDstGreen
whiteSrcGreen
whiteDstGreen
blackSrcBlue
blackDstBlue
shadowSrcBlue
shadowDstBlue
midSrcBlue
midDstBlue
hilightSrcBlue
hilightDstBlue
whiteSrcBlue
whiteDstBlue
Generic P3
Display P3
Adobe RGB
sRGB
RKCurvesOperation
Curves
RGBCurvePoints
pointsL
redCurvePoints
pointsR
greenCurvePoints
pointsG
blueCurvePoints
pointsB
RKSelectiveColorOperation
corrections
RKRetouchOperation
Retouch
B16@?0@"NSDictionary"8
inputStrokes
hasSource
brushStroke
softness
opacity
repairEdges
sourceOffset
data
xLocation
yLocation
pressure
points
clipRect
detectedFaces
RKRedEyeOperation
ApertureRedEye
inputSpots
pointX
center
pointY
sensitivity
RedEye
allCorrections
redEyeCorrections
autoRedEyeCorrections
endTime
timeRange
rate
timescale
alignment
glassesMatteAllowed
portraitEffectFilterName
keyframes
cropFraction
analysisType
v24@?0@"NSMutableDictionary"8@"NUAdjustment"16
face
warm
inputDetectedFaces
flags
epoch
lightMapAvg
vec4 _curve_sample_HDR(float x, sampler2D table, vec2 domain, vec2 normalizer) { x = (x - domain.x) / (domain.y - domain.x); x = clamp(x, 0.0001, 0.9999); x = normalizer.x * x + normalizer.y; return texture2D(table, vec2(x, 0.5)); } kernel vec4 _curves_rgb_lum_HDR(__sample color, sampler2D table, vec2 domain, vec2 normalizer) { vec4 pixel = color; pixel.r = _curve_sample_HDR(pixel.r, table, domain, normalizer).r; pixel.g = _curve_sample_HDR(pixel.g, table, domain, normalizer).g; pixel.b = _curve_sample_HDR(pixel.b, table, domain, normalizer).b; float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11)); float lum1 = _curve_sample_HDR(lum0, table, domain, normalizer).a; float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0)); float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0); float lum_offset = lum1 - lum1c; pixel.rgb = lum_scale * pixel.rgb + lum_offset; pixel.rgb = min(pixel.rgb, 1.0); return pixel; }
-[_PIParallaxLayoutJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayoutRequest.m
Missing layout configuration
Missing layout regions
Invalid segmentation matte size
Invalid segmentation classification
Invalid segmentation confidence map size
-[_PIParallaxLayoutJob render:]
Missing output geometry
Failed to generate segmentation layout
-[_PIParallaxLayoutJob complete:]
layer stack has no background layer
none
pixels
degrees
count
logic
stack
clockFont
clockColor
<%@:%p parameters: %@
foreground:%@
 background: %@
 matte: %@>
-[PIParallaxStyleDefinition type]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipe.m
-[PIParallaxStyleDefinition isEqualToParallaxStyleDefinition:]
-[PIParallaxStyleDefinition evaluateWithContext:error:]
-[PIParallaxStyleFilterDefinition init]
context != nil
-[PIParallaxStyleFilterDefinition evaluateWithContext:error:]
Unknown filter
Failed to set filter parameter value
Unknown filter parameter
v32@?0@"NSString"8@"PIParallaxStyleParameter"16^B24
Failed to evaluate filter parameters
Local
inputLightMapImage
inputTargetBackgroundImage
filter produced invalid image
CILocalContrast
LocalContrast
<%@:%p filter:%@ parameters: %@>
-[PIParallaxStyleFilterStackDefinition init]
-[PIParallaxStyleFilterStackDefinition evaluateWithContext:error:]
<%@:%p stack:%@ filters:%@>
-[PIParallaxStyleParameter type]
-[PIParallaxStyleParameter evaluateWithContext:error:]
-[PIParallaxStyleParameter isEqualToParallaxStyleParameter:]
(%@, unit: %@) 
(R:%@, G:%@, B:%@, A:%@)
(X:%@, Y:%@, unit: %@)
(>%@)
-[PIParallaxStyleBindingParameter evaluateWithContext:error:]
Unable to find source for variable bound to '%@'
($%@)
_PIDynamicLocalLightMapPrepare
inputGuideImage
PILongExposureAccumulator.state
PILongExposureAccumulator.accum
Accumulation was cancelled
PILongExposureAccumulator-main-j%lld
failed to init accumulator
B16@?0@"CIRenderDestination"8
frame != nil
-[PILongExposureAccumulator accumulate:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+LongExposure.m
-[PILongExposureAccumulator _accumulate:error:]
PILongExposureAccumulator-average-j%lld
failed to render average image
v16@?0@"CIImage"8
CIBoxBlur
PILongExposureAccumulator-minimum-j%lld
failed to render minimum image
PILongExposureAccumulator-maximum-j%lld
failed to render maximum image
-[PILongExposureAccumulator writeLongExposureImage:UTI:colorSpace:error:]
-[PILongExposureAccumulator writeMaskImage:UTI:error:]
-[PILongExposureAccumulator _exportOutputImage:format:colorSpace:toURL:uti:error:]
Failed to finalize image destination
Failed to create CGImageDestinationRef
Failed to create CGImageRef
/AutoLoop/LongExposure
-[PILongExposureRegistrationJob prepare:]
return Source(composition.source, {'skipOrientation':true});
Malformed AutoLoop recipe : crop
-[PILongExposureRegistrationJob render:]
Failed to allocate intermediate pixel buffer
PILongExposureRegistrationJob-render-j%lld
PILongExposureRegistrationJob-reference-j%lld
Failed to render luma
Image registration failure (expected 1 observation)
/RAW/SushiLevel1
/Master%@
CIRedEyeCorrection
inputCameraModel
CILanczosScaleTransform
1.5.1
1.9.1
1.10
computed
overcaptureComputed
dynamic
@"NSString"16@?0@"NUAdjustment"8
SDOFRenderingVersion
convexHull
/private/var/mobile/Media/PhotoData/CaptureDebug/
Repair
Clone
RepairML
<%@: %p; min = %.2f, max = %.2f, manualMin = %.2f, manualMax = %.2f, depthMin = %.2f, depthMax = %.2f>
manualMin
manualMax
depthMin
depthMax
SegmentationScoreRanges
monochrome
assetURL
-[PIPortraitVideoDebugDetectionsRenderNode resolvedNodeWithCachedInputs:settings:pipelineState:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoDebugDetectionsRenderNode.m
v20@?0B8@"NSError"12
%@-labelImageCache
-[PIPortraitVideoDebugDetectionsRenderNode _evaluateImage:]
Face
Head
Torso
Sports Ball
AutoFocus
%@ %@
%@ G:%@
kernel vec4 ipt_hue_chroma_color_wash(__sample s, vec3 c) {
float luma = s.x;
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 ipt_hue_chroma_color_wash_fixed(__sample s, vec3 c) {
float luma = (s.x <= 0.5) ? mix(0.0, c.x, 2.0*s.x) : mix(c.x, 1.0, 2.0*(s.x-0.5));
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 ipt_hue_chroma_color_wash_variable(__sample s, vec3 c) {
float x0 = 0.5;
float y0 = 0.5 + 0.75 * (c.x - 0.5);
float a = (y0 - x0) / (x0 * (1.0 - y0));
float luma = (s.x * (a + 1.0)) / (s.x * a + 1.0);
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 rgb_color_wash_variable(__sample s, __color c) {
float l0 = dot(c.rgb, vec3(0.299, 0.587, 0.114));
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= l0) {
cw = mix(vec3(0), c.rgb, l/l0);
} else {
cw = mix(c.rgb, vec3(1), (l-l0)/(1-l0));
return vec4(cw, 1.0);
kernel vec4 rgb_color_wash_variable_smooth(__sample s, __color c) {
float x0 = dot(c.rgb, vec3(0.299, 0.587, 0.114));
vec3 y0 = clamp(c.rgb, 0.05, 0.95);
float x = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 a = (y0 - x0) / (x0 * (1.0 - y0));
vec3 y = (x * (a + 1.0)) / (x * a + 1.0);
return vec4(y, 1.0);
kernel vec4 rgb_color_wash_fixed(__sample s, __color c) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= 0.5) {
cw = mix(vec3(0), c.rgb, 2*l);
} else {
cw = mix(c.rgb, vec3(1), 2*(l-0.5));
return vec4(cw, 1.0);
kernel vec4 rgb_color_wash_fixed_smooth(__sample s, __color c) {
float x0 = 0.5;
vec3 y0 = clamp(c.rgb, 0.05, 0.95);
float x = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 a = (y0 - x0) / (x0 * (1.0 - y0));
vec3 y = (x * (a + 1.0)) / (x * a + 1.0);
return vec4(y, 1.0);
kernel vec4 ipt_color_wash_duo(__sample s, vec3 c0, vec3 c1) {
vec3 cw = mix(c0, c1, s.x);
return vec4(cw, s.a);
kernel vec4 ipt_color_wash_duo_fixed(__sample s, vec3 c0, vec3 c1) {
vec3 cw;
cw.x = (s.x <= 0.2) ? mix(0.0, c0.x, s.x/0.2) : (s.x <= 0.8) ? mix(c0.x, c1.x, (s.x-0.2)/(0.8-0.2)) : mix(c1.x, 1.0, (s.x-0.8)/(1.0-0.8));
float x = clamp((s.x-0.2)/(0.8-0.2), 0.0, 1.0);
cw.yz = mix(c0.yz, c1.yz, x);
return vec4(cw, s.a);
kernel vec4 ipt_color_wash_duo_variable(__sample s, vec3 c0, vec3 c1) {
vec3 cw;
cw.x = (s.x <= c0.x) ? mix(0.0, c0.x, s.x/c0.x) : (s.x <= c1.x) ? mix(c0.x, c1.x, (s.x-c0.x)/(c1.x-c0.x)) : mix(c1.x, 1.0, (s.x-c1.x)/(1.0-c1.x));
float x = clamp((s.x-c0.x)/(c1.x-c0.x), 0.0, 1.0);
cw.yz = mix(c0.yz, c1.yz, x);
return vec4(cw, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo(__sample s, vec3 c0, vec3 c1) {
vec3 lhc = mix(c0, c1, s.x);
lhc.z = 0.5*(s.z+lhc.z);
return vec4(lhc, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo_fixed(__sample s, vec3 c0, vec3 c1) {
float l = (s.x <= 0.8) ? mix(c0.x, c1.x, s.x/0.8) : mix(c1.x, 1.0, (s.x-0.8)/(1.0-0.8));
float x = clamp(s.x/0.8, 0.0, 1.0);
vec2 hc = mix(c0.yz, c1.yz, x);
hc.y = 0.5*(s.z+hc.y);
return vec4(l, hc.x, hc.y, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo_variable(__sample s, vec3 c0, vec3 c1) {
float l = (s.x <= c1.x) ? mix(c0.x, c1.x, s.x/c1.x) : mix(c1.x, 1.0, (s.x-c1.x)/(1.0-c1.x));
float x = clamp(s.x/c1.x, 0.0, 1.0);
vec2 hc = mix(c0.yz, c1.yz, x);
hc.y = 0.5*(s.z+hc.y);
return vec4(l, hc.x, hc.y, s.a);
kernel vec4 rgb_color_wash_duo(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw = mix(c0.rgb, c1.rgb, l);
return vec4(cw, s.a);
kernel vec4 rgb_color_wash_duo_fixed(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= 0.75) {
cw = mix(c0.rgb, c1.rgb, l/0.75);
} else {
cw = mix(c1.rgb, vec3(1), 4*(l-0.75));
return vec4(cw, s.a);
kernel vec4 rgb_color_wash_duo_variable(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
float l0 = dot(c0.rgb, vec3(0.299, 0.587, 0.114));
float l1 = dot(c1.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= l1) {
cw = mix(c0.rgb, c1.rgb, l/l1);
} else {
cw = mix(c1.rgb, vec3(1), (l-l1)/(1-l1));
return vec4(cw, s.a);
ipt_hue_chroma_color_wash
ipt_hue_chroma_color_wash_fixed
ipt_hue_chroma_color_wash_variable
rgb_color_wash_fixed
rgb_color_wash_variable
rgb_color_wash_fixed_smooth
rgb_color_wash_variable_smooth
inputMode
HueChroma
HueChromaFixed
HueChromaVariable
RGBFixed
RGBFixedSmooth
RGBVariable
RGBVariableSmooth
MonoLight
CISoftLightBlendMode
ipt_color_wash_duo
ipt_color_wash_duo_fixed
ipt_color_wash_duo_variable
ipt_hue_chroma_color_wash_duo
ipt_hue_chroma_color_wash_duo_fixed
ipt_hue_chroma_color_wash_duo_variable
rgb_color_wash_duo
rgb_color_wash_duo_fixed
rgb_color_wash_duo_variable
inputShadowColor
inputHighlightColor
IPTFixed
IPTVariable
outputExposure
falseColorHDR
inputRAWGamutMapMax
Buffer must be RGBA16 type for red eye repairs
id<NUBuffer> computeRepairMask(__strong id<NUBuffer>, uint16_t *)
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/ApertureRedEye/PIApertureRedEye.mm
reddestx out of bounds
void seedFill(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, const uint32_t, const NSInteger, const NSInteger)
reddesty out of bounds
void applyRepairMask(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, double, const uint32_t)
repairBuffer != nil
kernel vec4 facebalance(__sample src, vec2 gamma, vec3 matchMinusOrigStrength)
vec4 pix = src;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  matchMinusOrigStrength.rg;
float strength = matchMinusOrigStrength.z*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
facebalance
vec4 curve_sample(float x, sampler2D table, vec2 domain, vec2 normalizer)
x = (x - domain.x) / (domain.y - domain.x);
x = clamp(x, 0.0001, 0.9999);
x = normalizer.x * x + normalizer.y;
return texture2D(table, vec2(x, 0.5));
kernel vec4 curves_rgb_lum(__sample color, sampler2D table, vec2 domain, vec2 normalizer)
vec4 pixel = color;
pixel.r = curve_sample(pixel.r, table, domain, normalizer).r;
pixel.g = curve_sample(pixel.g, table, domain, normalizer).g;
pixel.b = curve_sample(pixel.b, table, domain, normalizer).b;
float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11));
float lum1 = curve_sample(lum0, table, domain, normalizer).a;
float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0));
float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0);
float lum_offset = lum1 - lum1c;
pixel.rgb = lum_scale * pixel.rgb + lum_offset;
return pixel;
tableR != nil
+[PICurvesLUTFilter tableImageFromRed:green:blue:luminance:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PICurvesFilter.mm
tableG != nil
tableB != nil
tableL != nil
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
kernel vec4 colorBalance(__sample image, float colorI, float colorQ, float str, vec2 gamma)
vec4 pix = image;
vec3 neg = min(pix.rgb, 0.0);
vec3 pos = max(pix.rgb, 1.0) - 1.0;
pix.rgb = pow(clamp(pix.rgb, 0.0, 1.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb += vec2(colorI,colorQ);
float strength = str*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.y));
pix.rgb += pos + neg;
return pix;
inputWarmTemp
inputWarmTint
inputHasFace
gHDRtoPP
PPtogHDR
colorBalance
-[PIColorBalanceFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIColorBalanceFilter.m
@"NSString"16@?0@"NSString"8
CIMix
CIGammaAdjust
CIExposureAdjust
CIProSharpenEdges
PILocalContrastHDR
CILocalLightMapPrepare
CIPhotoGrain
CISmartBlackAndWhite
CIVignetteEffect
PIFalseColorHDRDebug
PIColorBalanceFilter
PIRAWFaceBalance
PINeutralGrayWhiteBalanceFilter
PIBilateralFilter
PICurvesLUTFilter
PICurvesFilter
PISelectiveColorFilter
PILevelsFilter
PIGlobalSettings
IPXRootSettings
PXSettingsArchiveKey
editSettings
PURootSettings
photoEditingSettings
PI_SEGMENT_ROUND_TRIP_PROXY
PI_SEGMENT_DISABLE_SEGMENTATION
PI_SEGMENT_INFILL_ALGO
PI_SEGMENT_TINT_LAYERS
PI_SEGMENT_DISABLE_CACHE
PI_SEGMENT_PREVIEW_DISABLE_CLOCK
PI_SEGMENT_PREVIEW_HIGH_QUALITY
PI_SEGMENT_MANUAL_GATING_LENIENCE
PI_STYLE_RECIPE_DIR_PATH
PI_USE_STYLE_RECIPE_CONFIG
PI_PARALLAX_LAYOUT_CONFIG
PI_PARALLAX_DISABLE_UPGRADE
PI_CINEMATIC_ALLOW_YUV_SOURCE
PI_CINEMATIC_ALLOW_RGB10_PACKED
PI_AUTOLOOP_EXPORT_USE_METAL
B8@?0
-[PIAutoLoopExportJob initWithVideoExportRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+Export.m
@"NUJSRenderNode"24@?0@"NUJSRenderNode"8@"JSValue"16
Invalid data type for adjustmentValue
Invalid data type for keyframes
Invalid data type for stabCropRect
input to VideoReframe cannot be nil
Unable to unwrap the input node!
-[PIJSRenderPipeline setUpContext:]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPhotosPipeline.m
Missing duration for crossfade
input to VideoCrossfadeLoop cannot be nil
{CGRect={CGPoint=dd}{CGSize=dd}}64@?0{CGSize=dd}8{CGSize=dd}24{CGSize=dd}40@"JSValue"56
OvercaptureRectForAutoCrop
Couldn't find bundle for class %@
+[NUJSRenderPipeline(PhotosPipeline) newPhotosPipeline:]
PhotosPipeline
Couldn't find the specified Pipeline
JSContext
Class getJSContextClass(void)_block_invoke
JavaScriptCoreSoftLinking.h
Unable to find class %s
void *JavaScriptCoreLibrary(void)
-[PIApertureRedEyeAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIApertureRedEyeAutoCalculator.m
PIApertureRedEyeAutoCalculator-faceDetection
pre-Adjustments
redEyeSpots
PILocalLightHDR-stats
NSNumber
kernel vec4 _shadowKernelHDR(__sample im, __sample adj, float str) { adj.r = 3.4*adj.r-1.2; vec3 neg = min(im.rgb, 0.0); vec3 pos = max(im.rgb, 1.0)-1.0; im.rgb = clamp(im.rgb, 0.0, 1.0); vec4 orig = im; float y = sqrt(dot(im.rgb, vec3(.33333))); float s = mix(0.0, adj.r, str); vec3 gain = s > 0.0 ? vec3(0.0) : vec3(s*s) * vec3(-2.75, -2.75, -2.5); im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); float m = 1.0 + 1.85*s*(max(0.1-y, 0.0)) ; im.rgb = (clamp(m*im.rgb, 0.0, 1.0)); float midAmt = s < 0.0 ? min(s*s,1.0) : 0.0; y = y*(1.0-y); im.rgb = sqrt(im.rgb); float pivot = .4; float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); im.rgb = mix(im.rgb, pix, 0.8); im.rgb = max(im.rgb, 0.0); im.rgb *= im.rgb; im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; return im; }
kernel vec4 _polyKernelHDR(__sample im, __sample adj, float str) { adj.r = 3.4*adj.r-1.2; vec3 neg = min(im.rgb, 0.0); vec3 pos = max(im.rgb, 1.0)-1.0; im.rgb = clamp(im.rgb, 0.0, 1.0); vec4 orig = im; float y = sqrt(dot(im.rgb, vec3(.33333))); float s = mix(0.0, adj.r, str); vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s); im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); im.rgb = (clamp(im.rgb, 0.0, 1.0)); float midAmt = min(str, .5); y = y*(1.0-y); im.rgb = sqrt(im.rgb); float pivot = max(adj.g, 0.5); float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); im.rgb = mix(im.rgb, pix, 0.8); im.rgb = max(im.rgb, 0.0); im.rgb *= im.rgb; im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; return im; }
-[PILocalLightFilterHDR outputImage]
PILocalLightHDR.m
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
CGRectEqualToRect([lightMapImage extent], [inputImage extent])
PILocalLightHDR
_lightMapImageFromData_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
CIEdgePreserveUpsampleRGFilter
-[PIParallaxAsset initWithFileURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxAsset.m
<%@: %p; fileURL = %@>
Asset is not local
proxy.jpg
Failed to load thumbnail image
Failed to load image properties
PIParallaxAsset.m
Unsupported
Failed to read image file
MediaAnalysis not available
v16@?0@"<NUMutableBuffer>"8
v24@?0@"<NUBufferTile>"8^B16
-[PISmartBlackAndWhiteAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PISmartBlackAndWhiteAutoCalculator.mm
PISmartBlackAndWhiteAutoCalculator-renderInputImage
Produced invalid BlackAndWhite settings, using defaults
void calculate_bw_auto_matrix_lum_contrast(__strong id<NUBuffer>, CGColorSpaceRef, MsgBlackAndWhiteSettings *)
num == w
void MsgMatrix<double>::AppendRow(const NumberType *, uint) [MatrixFloatType = double, NumberType = double]
xi < w && yi < h
MatrixFloatType &MsgMatrix<double>::operator()(size_t, size_t) [MatrixFloatType = double]
index < data.size()
inputScaleFactor
kernel vec4 _smartBlackAndWhiteHDR(__sample imageHDR, sampler2D hueImage, vec4 rgbWeights, vec4 normalizer) { float hueTableScaleFactor = rgbWeights.w; float hueImageWidth = normalizer.x; float huePixelCenter = normalizer.y; float neutralGamma = normalizer.z; float phototone = normalizer.w; float bw = dot(imageHDR.rgb / 12.0, rgbWeights.rgb); bw = clamp(bw, 0.0, 1.0); vec3 lms; lms.x = dot(imageHDR.rgb, vec3(0.3139902162, 0.6395129383, 0.0464975462)); lms.y = dot(imageHDR.rgb, vec3(0.155372406, 0.7578944616, 0.0867014186)); lms.z = dot(imageHDR.rgb, vec3(0.017752387, 0.109442094, 0.8725692246)); lms = pow(lms, vec3(0.43)); float i = dot(lms, vec3(0.4,0.4,0.2)); float p = dot(lms, vec3(4.4550,-4.8510,0.3960)); float t = dot(lms, vec3(0.8056,0.3572,-1.1628)); float chroma = sqrt(p*p+t*t); float hue = 0.5 + (atan(t, p) / 6.28318530718); vec2 huePt = vec2(hue * hueImageWidth + huePixelCenter, 0.5); float hueGamma = hueTableScaleFactor * texture2D(hueImage, huePt).a; float cd = 0.06 + 0.53 * abs(i-0.5); float lowSaturationDamp = smoothstep(0.0, 1.0, (chroma)/cd); float intensityDamp = smoothstep(0.0, 1.0, 1.0 - i); float lowLuminosityDamp = smoothstep(0.0, 1.0, 25.0 * i); float hWeight = lowSaturationDamp * intensityDamp * lowLuminosityDamp; hueGamma -= 1; hueGamma *= hWeight; hueGamma += 1; bw = pow(bw, hueGamma); float bwSDR = clamp(bw * 12.0, 0.0, 1.0); float midLumWeight = bwSDR*(1.0 - bwSDR); float grayWeight = 1.0 - smoothstep(0.0, 1.0, chroma * 10.0); float nWeight = midLumWeight * grayWeight; neutralGamma -= 1; neutralGamma *= nWeight; neutralGamma *= -2; neutralGamma += 1; bw = pow(bw, neutralGamma); bw = bw * 12.0; bw = clamp(bw, 0.0, 12.0); float df0 = 0.812379; float result; if (bw < df0) { result = 1.8031*bw*bw*bw - 2.1972*bw*bw + 1.3823*bw; } else { float scale = 12.0 - df0; float x = (bw - df0) / scale; result = 1.8031*x*x*x - 2.1972*x*x + 1.3823*x; result = result * scale + df0; result -= 0.158305860; } bw = mix(bw, result,-phototone); return vec4(bw,bw,bw,imageHDR.a); }
PIPhotoGrainHDR
inputISO
There is no need to call smartBlackAndWhiteStatistics.
Just use [CIFilter filterWithName:@"PISmartBlackAndWhiteHDR"] instead.
There is no need to call smartBlackAndWhiteAdjustmentsForValue:andStatistics:.
PICinematicVideoUtilities.m
Can't find global cinematic metadata in asset
Unexpected global rendering metadata class
-[_PIParallaxRenderCacheEntry initWithImage:format:colorSpace:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayerStackRequest.m
format != nil
space != nil
Invalid image extent
renderer != nil
-[_PIParallaxRenderCacheEntry render:error:]
layout != nil
-[_PIParallaxLayerStackScalePolicy initWithLayout:]
-[_PIParallaxLayerStackJob initWithRequest:]
-[_PIParallaxLayerStackJob effectiveLayout]
-[_PIParallaxLayerStackJob backfillScalePolicy]
-[_PIParallaxLayerStackJob prepare:]
Missing output image
MatteImage
Failed to render background layer
Failed to render foreground layer
buffer != nil
-[_PIParallaxLayerStackJob layerForBuffer:image:zPosition:identifier:]
identifier != nil
Failed to create pixel buffer
Failed to create renderDestination
-[_PIParallaxLayerStackJob cacheImage:key:format:colorSpace:]
key != nil
-[PIParallaxLayerStackRequest initWithSegmentationItem:]
-[PIParallaxLayerStackRequest initWithComposition:]
debugInput
debugMatte
debugMatteCrop
debugLocalConfidence
debugConfidenceMap
debugInfill
debugLayout
debugPreview
debugColorAnalysis
debugLayoutIntermediate_%d
-[PILevelsAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PILevelsAutoCalculator.m
PILevelsAutoCalculator-histogram
pre-Levels
-[PILevelsAutoCalculator calculateSettingsForImageHistogram:]
blackSrc
blackDst
shadowSrc
shadowDst
midSrc
midDst
hilightSrc
hilightDst
whiteSrc
whiteDst
Adjustment controller for key %@ is of class: %@, but was expected to be %@
-[PICompositionController(AdjustmentExtensions) _adjustmentControllerForKey:creatingIfNecessary:expectedClass:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PICompositionController+AdjustmentExtensions.m
<%@:%p> [(%.3f, %.3f), %s]
editable
not editable
Warning smartToneStatistics will soon need [receiver properties] be non-nil so flash-fired state can be determined.
tonalRange
highKey
blackPoint
whitePoint
kernel vec4 _smarttone_brightness_neg_HDR (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 c.rgb = max(c.rgb, 0.0); 
 vec3 pix = pow(c.rgb, vec3(gamma)); 
 float lum = dot(c.rgb, vec3(0.39, .5, .11)); 
 vec3 pix2 = lum>0.0 ? c.rgb*pow(lum, gamma)/lum : vec3(0.0); 
 pix = mix(pix, pix2, 0.8) + neg; 
 return vec4(pix, c.a); 
kernel vec4 _smarttone_brightness_pos_HDR (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 vec3 pos = max(c.rgb, 1.0)-1.0; 
 c.rgb = clamp(c.rgb, 0.0, 1.0); 
 vec3 m = 1.0-c.rgb; 
 float a = 0.6; 
 vec4 result = c; 
 result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
 c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
 result.rgb = mix(c.rgb, result.rgb, .85); 
 result.rgb = result.rgb+neg+pos; 
 return result; 
kernel vec4 _smarttone_contrast_HDR (__sample im, float midAmt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 float sat = (im.r-y)*(im.r-y)+(im.g-y)*(im.g-y)+(im.b-y)*(im.b-y); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float a = midAmt*y; 
 float b = -0.5*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(0.5), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8+sat); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
kernel vec4 _smarttone_contrast_HDR (__sample im, float midAmt, float maxVal) 
 midAmt = midAmt / maxVal; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, maxVal) - maxVal; 
 im.rgb = clamp(im.rgb, 0.0, maxVal); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 im.rgb = sqrt(im.rgb); 
 float sat = dot(im.rgb - vec3(y), im.rgb - vec3(y)) / sqrt(maxVal); 
 y = y*(sqrt(maxVal)-y); 
 float a = midAmt*y; 
 float b = -0.5*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(0.5), -a); 
 im.rgb = mix(im.rgb, pix, clamp(0.8+sat, 0.0, 1.0)); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
kernel vec4 _smarttone_highlightcontrast_HDR (__sample pix, float highAmt, float sat) 
 float maxVal = 1.0; vec3 neg = min(pix.rgb, 0.0); 
 vec3 pos = max(pix.rgb, maxVal) - maxVal; 
 pix.rgb = clamp(pix.rgb, 0.0, maxVal); 
 float lum = clamp(dot(pix.rgb, vec3(.3333)),0.0,1.0); 
 vec3 high = pow(pix.rgb, vec3(3.0 - 2.0*highAmt)); 
 float pivot = 0.8; 
 vec3 pix1 = (high - pivot)*(4.0 - 3.0*highAmt) + pivot; 
 float h = highAmt*highAmt*highAmt*highAmt; 
 float a = (4.0 - 3.0*h); 
 vec3 pix2 = (lum-pivot)*a+pivot + high.rgb -lum; 
 high = mix(pix2, pix1, sat); 
 pix.rgb = mix(pix.rgb, high, lum*lum); 
 pix.rgb = pix.rgb + neg + pos; 
 return pix; 
kernel vec4 _rawHighlightsHDR(__sample pix, float gain) 
 vec3 high = gain*pix.rgb; 
 float lum = clamp(dot(pix.rgb, vec3(.3333)), 0.0, 1.0); 
 vec3 neg = min(high, 0.0); 
 high.rgb = mix(max(pix.rgb, 0.0), high.rgb, lum*lum) + neg; 
 return vec4(high, pix.a); 
CIHighlightShadowAdjust
inputShadowAmount
inputHighlightAmount
PISmartToneFilterHDR-histogram
componentAdd
componentMultiply
componentMin
componentMax
clear
destination
sourceOver
destinationOver
sourceIn
destinationIn
sourceOut
destinationOut
sourceAtop
destinationAtop
exclusiveOr
multiply
screen
overlay
darken
lighten
colorDodge
colorBurn
hardLight
softLight
difference
exclusion
saturation
luminosity
subtract
divide
linearBurn
linearDodge
vividLight
linearLight
pinLight
hardMix
darkerColor
lighterColor
*** Couldn't find blend kernel for blend mode '%@'
inputBlendMode
PI_LONG_EXPOSURE_FUSION_PARAMS
@"NSString"8@?0
kNCCBlurHalfSize
kNCCEdge0
kNCCEdge1
kBlendMaskThreshold0
kBlendMaskThreshold1
PI_LONG_EXPOSURE_DUMP_INTERMEDIATES
long-exp-input-image.tiff
long-exp-mask-image.tiff
long-exp-still-image.tiff
long-exp-guide-image.tiff
long-exp-ncc-map-image.tiff
long-exp-refined-mask-image.tiff
long-exp-fusion-image.tiff
-[PIModernPhotosPipeline _processedRenderNodeForComposition:input:pipelineState:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIModernPhotosPipeline.m
pipelineState != nil
LongExposure
inputSushiLevel
kCGImageSourceShouldExtendRaw
inputGamutMapMax
inputNoiseReductionDetailAmount
inputUIColorNoiseReductionAmount
inputUILuminanceNoiseReductionAmount
sharpness
inputNoiseReductionSharpnessAmount
contrast
inputNoiseReductionContrastAmount
inputNeutralTemperature
inputNeutralTint
Video
mediaComponentType
hardCropCleanAperture
defaultFrameTime
skipOrientation
Master
unsupported sourceSelect adjustment
RAW/Linear
Source
ShowOriginalSource
PIForwardFakeBoost
inputBoost
inputVersion
inputParams
Intermediate
keepCacheWhenAtOneToOne
Disparity
Image
Source does not contain depth
PortraitEffectsMatte
HairSegmentationMatte
SkinSegmentationMatte
TeethSegmentationMatte
GlassesSegmentationMatte
MeteorPlusGainMap
focusRect
inputAperture
inputFocusRect
leftEyeX
leftEyeY
rightEyeX
rightEyeY
noseX
noseY
chinX
chinY
inputLeftEyePosition
inputRightEyePosition
inputFaceMidPoint
inputChinPosition
Missing required depth settings
inputShiftmapImage
inputCalibrationData
inputAuxDataMetadata
inputOriginalSize
CIDepthEffectMakeBlurMap
inputMatteImage
inputHairImage
inputGlassesImage
inputPower
inputEV
faceLandmarks
inputFaceLandmarkArray
inputDisparity
inputMatte
inputBlurMap
inputFaceMask
inputHairMask
inputTeethMask
CIPortraitEffectV2
inputGenerateSpillMatte
inputFullSizeImage
CIPortraitEffect%@
PortraitV2-zeroStrength
PortraitV2
pre-PortraitVideo
auxiliaryImageType
nativeScale
post-PortraitVideo
inputLumaNoiseScale
lumaNoiseScale
shape
inputShape
CIDepthEffectApplyBlurMap
inputGainMap
masterSpace
pre-WB
inputIsRaw
warmth
pre-Mute
pre-LivePhotoKeyFrame
pre-Trim
pre-SloMo
SloMo
inputConfidence
inputFaceBoxArray
CIDynamicFood
inputBoundingBoxArray
sunsetOrSunrise
CIDynamicRender
Unknown sceneLabel when rendering semantic enhance adjustment
inputTargetImage
inputTime
inputSaturation
pre-Curves
inputPointsR
inputPointsG
inputPointsB
inputPointsL
inputTableImage
green
blue
spread
hueShift
inputCorrections
CIPhotoEffect%@
filterVersion
pre-VideoReframe
pre-VideoStabilize
pre-VideoCrossfadeLoop
pre-Geometry
pre-Crop
perspectiveStraighten
resetCleanAperture
{?={?=qq}{?=qq}}
projectUsingCleanAperture
{?=qq}
projectUsingOriginalSize
com.apple.quicktime.live-photo.vitality-disabled
projectUsingEstimatedCleanAperture
pre-Orientation
post-Geometry
inputCenter
post-Adjustments
PIInverseFakeBoost
Master/RAW/Linear
inputCutoff
kernel vec4 levelsNewGammaForP3 (sampler src, sampler LUT)
vec4
p,r;
vec2
c1,c2;
float
p  = sample(src, samplerCoord(src));
vec3 neg = min(p.rgb, 0.0);
vec3 pos = max(p.rgb, 1.0)-1.0;
p.rgb = clamp(p.rgb, 0.0, 1.0);
f = p.r * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.r = r.r * 4.0 - 1.0;
f = p.g * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.g = r.g * 4.0 - 1.0;
f = p.b * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.b = r.b * 4.0 - 1.0;
p.rgb = max(p.rgb, 0.0);
p.rgb = p.rgb + pos + neg;
return p;
-[PILevelsFilter _LUTImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PILevelsFilter.m
com.apple.photos.PhotoImaging
segmentation
Unbalanced call to ensureResources detected! (%ld)
+[PISegmentationLoader ensureResources]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationLoader.m
Unbalanced call to freeResources detected! (%ld)
+[PISegmentationLoader freeResources]
-[PISegmentationLoader initWithParallaxAsset:]
PISegmentationItemLoader.state
PISegmentationItemLoader.loading
item != nil
-[PISegmentationLoader initWithSegmentationItem:parallaxAsset:]
v16@?0@"PIParallaxSegmentationItem"8
v24@?0@"PFParallaxAssetResource"8@"NSError"16
B24@?0@"NSString"8@"NSString"16
Missing composition
-[PISegmentationLoader _classify:completion:]
-[PISegmentationLoader _segment:completion:]
B32@?0@"<NUImageBuffer>"8@"<NUImageBuffer>"16Q24
v24@?0@"<NUImageBuffer>"8@"<NUImageBuffer>"16
composition != nil
-[PISegmentationLoader _performSegmentation:type:completion:]
-[PISegmentationLoader _analyzeColors:completion:]
Missing original layout
-[PISegmentationLoader _loadBackground:completion:]
-[PISegmentationLoader _loadRegions:completion:]
v32@?0@"NSArray"8@"NSArray"16@"NSError"24
-[PISegmentationLoader _performLayout:completion:]
item.composition != nil
-[PISegmentationLoader _loadLocalLightData:completion:]
resource != nil
+[PISegmentationLoader segmentationCompositionForAssetResource:]
proxyImage != NULL
+[PISegmentationLoader segmentationCompositionForProxyImage:orientation:]
imageURL != nil
+[PISegmentationLoader segmentationCompositionForImageURL:fileUTI:orientation:proxyImage:]
v16@?0@"PIOrientationAdjustmentController"8
+[PISegmentationLoader segmentationSourceForImageURL:fileUTI:orientation:proxyImage:]
currentInfo != nil
-[PISegmentationLoader _tryLoadSegmentationItemFromCache:]
B16@?0@"NSURL"8
+[PISegmentationLoader saveSegmentationItem:toURL:error:]
Invalid segmentation item: %@
+[PISegmentationLoader loadSegmentationItemFromURL:error:]
Segmentation item is incomplete
+[PISegmentationLoader saveSegmentationItem:layerStackOptions:configuration:style:layout:toWallpaperURL:completion:]
v24@?0@"PFParallaxLayerStack"8@"NSError"16
+[PISegmentationLoader generateLayerStackForItem:style:layout:options:completion:]
+[PISegmentationLoader saveSegmentationItem:layerStack:toWallpaperURL:error:]
Failed to create wallpaper directory
input.segmentation
Failed to export segmentation item
output.layerStack
Failed to export layer stack
+[PISegmentationLoader loadSegmentationItemFromWallpaperURL:error:]
Segmentation item from wallpaper is incomplete
Failed to load segmentation item from wallpaper
+[PISegmentationLoader loadLayerStackFromWallpaperURL:options:error:]
Failed to load layer stack from wallpaper
+[PISegmentationLoader renderPreviewLayerStackFromWallpaperURL:styleCategory:completion:]
+[PISegmentationLoader reloadSegmentationItemFromWallpaperURL:asset:completion:]
Null
Not available
<%@:%p %@>
-[_PIParallaxLayoutInactiveFrameJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayoutInactiveFrameRequest.m
-[_PIParallaxLayoutInactiveFrameJob prepare:]
-[_PIParallaxLayoutInactiveFrameJob render:]
-[_PIParallaxLayoutInactiveFrameJob complete:]
-[PIParallaxLayoutInactiveFrameRequest initWithComposition:]
segmentationItem != nil
-[PIParallaxLayoutInactiveFrameRequest initWithSegmentationItem:]
Mirror
Adjustment
SourceSelect~1.0
enum
values
Failed to register schema %@: %@
+[PISchema sourceSelectSchema]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PISchema.m
RAW~1.0
opaque
required
+[PISchema rawSchema]
RawNoiseReduction~1.0
bool
minimum
maximum
ui_minimum
ui_maximum
+[PISchema rawNoiseReductionSchema]
SmartTone~1.0
+[PISchema smartToneSchema]
SmartColor~1.0
+[PISchema smartColorSchema]
SmartBlackAndWhite~1.0
+[PISchema smartBlackAndWhiteSchema]
Grain~1.0
+[PISchema grainSchema]
Sharpen~1.0
+[PISchema sharpenSchema]
CropStraighten~1.0
+[PISchema cropSchema]
Trim~1.0
+[PISchema trimSchema]
SlowMotion~1.0
+[PISchema slomoSchema]
LivePhotoKeyFrame~1.0
+[PISchema livePhotoKeyFrameSchema]
Mute~1.0
+[PISchema muteSchema]
VideoPosterFrame~1.0
+[PISchema videoPosterFrameSchema]
AutoLoop~1.0
+[PISchema autoLoopSchema]
HighResolutionFusion~1.0
+[PISchema highResFusionSchema]
DepthEffect~1.0
+[PISchema depthEffectSchema]
Effect3D~1.0
+[PISchema effect3DSchema]
PortraitEffect~1.0
+[PISchema portraitEffectSchema]
+[PISchema effectSchema]
iPhone
+[PISchema redEyeSchema]
array
content
compound
properties
+[PISchema apertureRedEyeSchema]
+[PISchema retouchSchema]
+[PISchema vignetteSchema]
Orientation~1.0
+[PISchema orientationSchema]
+[PISchema definitionSchema]
+[PISchema noiseReductionSchema]
grayStrength
identity
+[PISchema whiteBalanceSchema]
+[PISchema levelsSchema]
+[PISchema curvesSchema]
+[PISchema selectiveColorSchema]
VideoReframe~1.0
+[PISchema videoReframeSchema]
VideoStabilize~1.0
pixel
gyro
+[PISchema videoStabilizeSchema]
VideoCrossfadeLoop~1.0
+[PISchema videoCrossfadeLoopSchema]
Debug
+[PISchema debugSchema]
SemanticEnhance~1.0
+[PISchema semanticEnhance]
PortraitVideo~1.0
+[PISchema portraitVideoSchema]
Composition
PhotosComposition
contents
com.apple.photo:Source~1.0
reference
Retouch~1.0
WhiteBalance~1.0
RedEye~1.0
ApertureRedEye~1.0
Definition~1.0
Effect~1.0
Vignette~1.0
NoiseReduction~1.0
Levels~1.0
Curves~1.0
SelectiveColor~1.0
Debug~1.0
+[PISchema photosCompositionSchema]
failed to register %@: %@
+[PISchema registerPhotosSchema]
com.apple.mobileslideshow.reframe.photo.eligible-pass
com.apple.mobileslideshow.reframe.photo.eligible-fail
com.apple.mobileslideshow.reframe.video.eligible-pass
com.apple.mobileslideshow.reframe.video.eligible-fail
com.apple.mobileslideshow.reframe.type.photo.horizon
com.apple.mobileslideshow.reframe.type.photo.perspective
PICompositionFinalizer-primaryImageProperties
PICompositionFinalizer-overcaptureImageProperties
v16@?0@"PIAdjustmentController"8
maxCameraAutoStraightenCorrection
Capture
maxCameraVerticalPerspectiveCorrection
maxCameraHorizontalPerspectiveCorrection
maxCameraRotatePerspectiveCorrection
minHorizontalCameraPerspectiveCorrection
minVerticalCameraPerspectiveCorrection
minRotateCameraPerspectiveCorrection
enable_perspective_correction
reframe
perpsective
horizon
PICropAutoCalculator-imageProperties
-[PICropAutoCalculator undoExifOrientation:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PICropAutoCalculator.m
Source geometry has 0 size
-[PICropAutoCalculator submit:]
PICropAutoCalculator-faceDetection
{CGRect={CGPoint=dd}{CGSize=dd}}
maxAutoStraighten
filterOptions
CIAutoStraighten
straightenAngleInDegreesCCW
limitExceeded
belowMinimum
autoCrop
result
error
%@AutoCropEvaluation-txt.DBG
v16@?0@"PISourceSelectAdjustmentController"8
v16@?0@"PIAutoLoopAdjustmentController"8
PICropAutoCalculator-stitchedOvercaptureRect
+[PICropAutoCalculator(Utilities) updateCropAdjustment:after:error:]
PICropAutoCalculator-getBeforeGeometry
PICropAutoCalculator-getAfterGeometry
v16@?0@"PICropAdjustmentController"8
kernel vec4 iptLumHueSatTable(sampler image, __table sampler hueSatLumTable)
vec4 im = sample(image, samplerCoord(image)) ;
vec4 result = im;
float hueIdx = 359.0 * 0.5 * (atan(im.b, im.g)/3.1416 + 1.0);
hueIdx = clamp(hueIdx, 0.0, 359.0) + 0.5;
float hueChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).r);
float satChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).g);
float lumChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).b);
float chroma = sqrt(im.g*im.g+im.b*im.b) ;
chroma *= satChange ;
float hue = atan(im.b, im.g) + hueChange ;
vec3 adjustIm = im.rgb;
float hueAngle = hue  ;
lumChange = mix(1.0, lumChange, clamp(chroma,-0.7,0.7));
adjustIm.r *= lumChange;
adjustIm.g = chroma * cos(hueAngle) ;
adjustIm.b = chroma * sin(hueAngle) ;
result.rgb = adjustIm.rgb;
result.a = im.a ;
return result ;
kernel vec4 srgbToIPT(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, ipt;
lms = im.r * vec3(0.3139902162, 0.155372406, 0.017752387) +
im.g * vec3(0.6395129383, 0.7578944616, 0.109442094) +
im.b * vec3(0.0464975462, 0.0867014186, 0.8725692246);
lms = sign(lms)*pow(abs(lms), vec3(0.43, 0.43, 0.43));
ipt = lms.r * vec3(0.4, 4.455, 0.8056) +
lms.g * vec3(0.4, -4.851, 0.3572) +
lms.b * vec3(0.2, 0.3960, -1.1628);
return vec4(ipt, im.a);
kernel vec4 iptToSRGB(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, rgb;
lms = im.rrr +
im.g * vec3(0.09756893,-0.11387649,0.03261511) +
im.b * vec3(0.20522644, 0.13321716,  -0.67688718);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
rgb = lms.r * vec3( 5.472212058380287,  -1.125241895533569,   0.029801651173470) +
lms.g * vec3(-4.641960098354470, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974,  -0.167895202223709, 1.163647892783812);
return vec4(rgb, im.a);
kernel vec4 add_gaussian(sampler srcTable, float tableSize, float hueAmplitude, float satAmplitude, float lumAmplitude, float gaussX, float gaussSigmaSquared) {
vec2 d = destCoord();
vec4 src = sample(srcTable, samplerCoord(srcTable));
float x = d.x / (tableSize - 1.0);
float dist = min(min(abs(x - gaussX), abs(x - 1.0 - gaussX)), abs(x + 1.0 - gaussX));
float p = -((dist * dist) / (2.0 * gaussSigmaSquared));
float ep = exp(p);
float hue = hueAmplitude * ep;
float sat = satAmplitude * ep;
float lum = lumAmplitude * ep;
float h = clamp(src.r + hue, -1.0, 1.0);
float s = clamp(src.g + sat, -1.0, 1.0);
float l = clamp(src.b + lum, -1.0, 1.0);
return vec4(h,s,l,1.0);
srgbToIPT
iptToSRGB
add_gaussian
iptLumHueSatTable
PIVideoReframeNode.m
invalid crop rect
pipelineState
-[PIVideoReframeNode initWithSettings:inputs:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIVideoReframeNode.m
-[PIVideoReframeNode _evaluateVideoProperties:]
error != nil
-[PIVideoReframeNode _evaluateImageGeometry:]
Failed to get input geometry
Could not get the input geometry
Could not get the input image properties
CIPerspectiveTransform
inputTopLeft
inputTopRight
inputBottomLeft
inputBottomRight
showStabilizationWatermark
init is not a valid initializer
Invalid plist at path: %@
Time
Subjects
Type
HumanBody
HumanFace
CatBody
DogBody
-[PIVideoReframeMetadataExtractor overwriteTrackingMetadataWithPlist:]
PIVideoReframeMetadataExtractor.mm
type >= 0
Confidence
-[PIVideoReframeMetadataExtractor motionBlurVectorFromMetadata:]
-[PIVideoReframeMetadataExtractor extractMetadata]
mdataGroup.items.count == 1
0 && "unexpected metadata identifier"
0 && "unexpected metadata data type"
err == noErr
kernel vec4 convertFromRGBToYIQ(sampler src, float gamma)
vec4 pix ;
vec3 pix2;
pix = sample(src, samplerCoord(src));
pix.rgb = sign(pix.rgb)*pow(abs(pix.rgb), vec3(1.0/gamma)) ;
pix2.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
return vec4(pix2, pix.a);
kernel vec4 convertFromYIQToRGB(sampler src, float gamma)
vec4 color, pix;
pix = sample(src, samplerCoord(src));
color.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
color.rgb = sign(color.rgb)*pow(abs(color.rgb), vec3(gamma, gamma, gamma) );
color.a = pix.a;
return color;
kernel vec4 whiteBalance(sampler image, float grayY, float grayI, float grayQ, float strength)
vec4 im = sample(image, samplerCoord(image)) ;
vec2 grayOffset = vec2(grayI, grayQ) ;
vec4 result ;
float newStrength = 1.0 + (strength-1.0)*(1.0-im.r) ;
result.r = im.r ;
result.gb = im.gb + newStrength*grayOffset ;
float damp = max(min(1.0, im.r/(grayY+0.00001)),0.0) ;
result.rgb = mix(im.rgb, result.rgb, damp) ;
result.a = im.a ;
return result ;
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
convertFromRGBToYIQ
convertFromYIQToRGB
-[PINeutralGrayWhiteBalanceFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PINeutralGrayWhiteBalanceFilter.m
PISmartToneAutoCalculator
-[PISmartToneAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIAutoCalculators.mm
-[PISmartColorAutoCalculator submit:]
-[PIRedEyeAutoCalculator submit:]
PIRedEyeAutoCalculator-getLensInfo
locationX
locationY
touchDiameter
inputRect
MPSImageReduce unavailable
/masterSpace
kernel vec4 _blendGrainsHDR(__sample isoImages, float log10iso)
  vec4 c = isoImages; 
  float mix10_50    = mix(c.r, c.g, log10iso*1.43067655809 
                                           - 1.43067655809); 
  float mix50_400   = mix(c.g, c.b, log10iso*1.10730936496 
                                           - 1.88128539659); 
  float mix400_3200 = mix(c.b, c.a, log10iso*1.10730936496 
                                           - 2.88128539659); 
  float v = compare(log10iso - 1.69897000434,                     mix10_50,                     compare(log10iso - 2.60205999133,                             mix50_400,                             mix400_3200)); 
  return vec4(v,v,v,1.0);
kernel vec4 _grainBlendAndMixHDR(__sample img, __sample grainImage, float contrast, float mixAmount)
  vec3 rgb = img.rgb;
  float luminance = clamp(dot(rgb, vec3(.333333)), 0.0, 1.0); 
  float gamma = 4.01 - 2.0*luminance;
  rgb = sign(rgb) * pow(abs(rgb), vec3(1.0/gamma));
  float grain = grainImage.r - 0.5;
  float mult = contrast * grain;
  rgb += (max(luminance, 0.5) * mult * (1.0-luminance));
  rgb = sign(rgb) * pow(abs(rgb), vec3(gamma));
  rgb = min(rgb, 12.0);
  return mix(img, vec4(rgb,img.a), mixAmount);
kernel vec2 _paddedTile2(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
1536 x 1536 noise grain image prov
v56@?0^v8Q16Q24Q32Q40Q48
generateNoiseImage_block_invoke
PIPhotoGrainHDR.m
width==512*3
height==512*3
x==0
y==0
kernel vec4 _grainGenCombineHDR (__sample r, __sample g, __sample b, __sample a)
{ return vec4(r.x, g.x, b.x, a.x); }
CIUnsharpMask
Classification
LayoutConfiguration
LowResolution
DisableDownload
DisableSegmentation
DisableRendering
PetsRegions
Priority
PetsFaceRegions
Style
LayerStackOptions
OutOfProcess
WallpaperUpgradeMode
asset != nil
+[PISegmentation computeSegmentationScoresForAsset:options:completion:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentation.m
options != nil
v24@?0@"<PISegmentationItem>"8@"NSError"16
+[PISegmentation loadSegmentationItemForAsset:options:completion:]
Invalid classification option: %@
+[PISegmentation cancelSegmentationForAsset:]
NO (timeout)
+[PISegmentation exportWallpaperForAsset:toURL:options:completion:]
wallpaperURL != nil
Segmentation failure
Invalid additionalLayerOptions: %@
+[PISegmentation _layerStackOptionsFromOptions:]
sourceURL != nil
+[PISegmentation upgradeWallpaperAtURL:exportToURL:options:completion:]
destinationURL != nil
v24@?0@"PFPosterEditConfiguration"8@"NSError"16
Not implemented yet
v16@?0@"NSError"8
Failed to load poster configuration from source URL
Failed to upgrade poster configuration from source URL
v24@?0@"PFPosterConfiguration"8@"NSError"16
PISegmentation.upgrade
Failed to upgrade some poster media
Failed to save poster configuration
v8@?0
+[PIImageIO writeImage:fileURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIImageIO.m
cgImage != NULL
+[PIImageIO writeCGImage:fileURL:]
fileURL != nil
Unhandled bit depth: %ld
+[PIImageIO writeCGImage:fileURL:options:]
Successfully wrote image to file %@
Failed to write image to file %@
%@-%d-%ld.tiff
GU %@ %@
Sensitivity
Bad float to fixed 16 conversion
+[PIApertureRedEyeProcessorKernel convertFloat:toFixed16:count:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/ApertureRedEye/PIApertureRedEyeFilter.mm
Bad fixed 16 to float conversion
+[PIApertureRedEyeProcessorKernel convertFixed16:toFloat:count:]
+[PIApertureRedEyeProcessorKernel processWithInputs:arguments:output:error:]
PIApertureRedEyeFilter.mm
output.format == kCIFormatRGBAf
inputSensitivity
portraitStrength
capturedPortraitMajorVersion
capturedPortraitMinorVersion
portraitDisableStage
+[PIValuesAtCapture valuesAtCaptureFromImageProperties:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIPortraitAutoCalculator.m
Portrait was previously applied.
Failed to load depth data
Unfiltered depth data is not supported
Low quality depth data is not supported
Missing camera calibration data
Failed to load auxiliary data
Missing auxiliary metadata
Depth data version mismatch, asset has %@ but we can only handle %@
We only know up to sDOF version %d. Found: %d
<%@:%p aperture:%f minimumAperture:%@ maximumAperture:%@ portraitStrength:%f SDOFRenderingVersion:%lu portraitMajorVersion:%lu portraitMinorVersion:%lu>
-[PIPortraitAutoCalculator submit:]
PIPortraitAutoCalculator-getValuesAtCapture-imageProperties
capturedAperture
capturedPortraitStrength
v16@?0@"NUResponse"8
PIPortraitAutoCalculator-faceDetect
faceObservations != nil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:]
metadata != nil
NUOrientationIsValid(orientation)
Insufficient number of landmark points
+[PIPortraitAutoCalculator depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:]
minimumAperture
maximumAperture
+[PIPortraitAutoCalculator portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:]
faceBoundingBox
faceJunkinessIndex
faceOrientationIndex
roll
allPoints
faceContour
leftEye
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromCameraMetadata:]
-[PIDepthEffectApertureAutoCalculator submit:]
PIDepthEffectApertureAutoCalculator-getValuesAtCapture-imageProperties
depthData:DepthDataVersion
var tagNode = GetTag('/pre-Adjustments');
orientation = tagNode.geometry.orientation;
var node = Orient(tagNode, orientation);
return node;
@"NURenderNode"40@?0@"NURenderPipelineHelper"8@"NUComposition"16@"NURenderNode"24^@32
/pre-Adjustments
var source = GetTag('/pre-Adjustments');
ResetTagInput('/pre-Crop', source);
source = GetTag('/Crop');
orientation = source.geometry.orientation;
source = Orient(source, orientation);
return source;
/pre-Crop
/Crop
var sourceSettings = { 'skipOrientation': true };
var rawAdjustment = composition.raw
if (rawAdjustment) {
    sourceSettings['inputDecoderVersion'] = rawAdjustment.inputDecoderVersion
var image = Source(composition.source, sourceSettings)
var rawImage = GetTagInput('RAW/Linear')
if (rawImage) {
    image = rawImage
    image = Filter('PIForwardFakeBoost', {'inputImage' : image, 'inputBoost' : 1.0,})
var orientation = composition.orientation
if (orientation) { image = Orient(image, orientation.value) }
return image
Raw/Linear
var sourceSettings = { }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
} else { throw "expected RAW in rawSourceFilterIncludingOrientation"; }
return Source(composition.source, sourceSettings); 
expected RAW in rawSourceFilterIncludingOrientation
+[PIPipelineFilters rawSourceFilterIncludingOrientation]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPipelineFilters.m
var sourceSettings = { 'skipOrientation' : true }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
  return Source(composition.source, sourceSettings); 
} else {
  return GetTag("/ShowOriginalSource");
var source = GetTag('/pre-RedEye');ResetTagInput('/post-RedEye', source);
return GetTag('/post-RedEye');
/pre-RedEye
/post-RedEye
Could not construct noRedEye filter from inline source
+[PIPipelineFilters noRedEyeFilter]
var output = input
var preTrim = GetTag('/pre-Trim');ResetTagInput('/SloMo', preTrim);
let slomo = composition.slomo
if (slomo) {
    var startTime = TimeMake(slomo.start, slomo.startScale)
    var endTime = TimeMake(slomo.end, slomo.endScale)
    output = SloMo(input, startTime, endTime, slomo.rate)
return output;
/pre-Trim
/SloMo
Could not construct noTrimFilter filter from inline source
+[PIPipelineFilters noTrimFilter]
var preMute = GetTag('pre-Mute');ResetTagInput('Mute', preMute);
return GetTag('Image');
Could not construct noMuteFilter filter from inline source
+[PIPipelineFilters noMuteFilter]
var preCrop = GetTag('/pre-Crop');ResetTagInput('/pre-Orientation', preCrop);
return input;
/pre-Orientation
Could not construct noCropFilter filter from inline source
+[PIPipelineFilters noCropFilter]
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Adjustments', preGeometry);
return input;
/post-Adjustments
Could not construct noGeometry filter from inline source
+[PIPipelineFilters iosCropToolFilter]_block_invoke
var image = GetTag('pre-Trim');ResetTagInput('Trim', image);
image = GetTag('pre-SloMo');ResetTagInput('SloMo', image);
return input;
Could not construct stripAllTimeAdjustmentsFilter filter from inline source
+[PIPipelineFilters stripAllTimeAdjustmentsFilter]
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Geometry', preGeometry);
return input;
+[PIPipelineFilters noGeometryFilter]
var preOrientation = GetTag('/pre-Orientation');ResetTagInput('/Orientation', preOrientation);
return input;
/Orientation
Could not construct noOrientationFilter filter from inline source
+[PIPipelineFilters noOrientationFilter]
return null;
Could not construct pipeline filter from source: %@
+[PIPipelineFilters orientationAsMetaDataFilter]
var preCrop = GetTag('/perspectiveStraighten');if (preCrop) {   ResetTagInput('/Crop', preCrop);
}return input;
/perspectiveStraighten
Could not construct perspectiveStraightenWithoutCropFilter filter from inline source
+[PIPipelineFilters perspectiveStraightenWithoutCropFilter]
var output = input;
var prePortraitVideoNode = GetTag('pre-PortraitVideo');
if (prePortraitVideoNode) {
    ResetTagInput('/post-PortraitVideo', prePortraitVideoNode);
return output;
/post-PortraitVideo
Could not construct histogramOptimizationFilter from inline source
+[PIPipelineFilters histogramOptimizationFilter]
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Geometry', tagNode);
return GetTag('/post-Geometry');
Could not construct stopAtTagIncludeGeometryFilter from inline source
+[PIPipelineFilters stopAtTagIncludeGeometryFilter:]
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Orientation', tagNode);
return GetTag('/Orientation');
Could not construct stopAtTagIncludeOrientationFilter from inline source
+[PIPipelineFilters stopAtTagIncludeOrientationFilter:]
var output = input;
var orientation = composition.orientation;
if (orientation) {
    output = Orient(input, orientation.value);
return output;
+[PIPipelineFilters applyOrientationFilter]
ResetTagInput('/AutoLoop/Output', GetTag('/AutoLoop/StabilizedVideo'));
return input;
/AutoLoop/Output
/AutoLoop/StabilizedVideo
Could not construct autoloopStabilizedVideoFilter filter from inline source
+[PIPipelineFilters autoloopStabilizedVideoFilter]
return Source(composition.sourceSpatialOvercapture, { 'skipOrientation' : true })
Could not construct overcaptureSourceFilter filter from inline source
+[PIPipelineFilters overcaptureSourceFilter]
return Source(composition.source, { 'skipOrientation' : true })
Could not construct primarySourceFilter filter from inline source
+[PIPipelineFilters primarySourceFilter]
return Source(composition.sourceSpatialOvercapture, {  })
+[PIPipelineFilters spatialOvercaptureVideoSourceFilter]
return input;
/PortraitV2-zeroStrength
/PortraitV2
Could not construct oneShotPortraitV2ExportFilter filter from inline source
+[PIPipelineFilters oneShotPortraitV2ExportFilter]
let output = input;
var image = GetTag('pre-VideoReframe');
if (image) {
    var videoReframe = composition.videoReframe;
    if (videoReframe && videoReframe.enabled) {
        image = VideoReframe(image, videoReframe);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('VideoReframe', image);
    }
else { // image or live-photo { 
    var crop = composition.cropStraighten;
    var image = GetTag('pre-Crop');
    if (crop && crop.smart == 1 && image) {
        if (crop.pitch || crop.yaw) {
            var perspectiveTransform = PerspectiveTransformMake(crop.angle, crop.pitch, crop.yaw, image.geometry);
            image = Transform(image, perspectiveTransform);
        } else {
            var straightenTransform = StraightenTransformMake(crop.angle, image.geometry);
            image = Transform(image, straightenTransform);
        }
        // Apply the crop rect to the incoming image;
        image = Crop(image, crop.xOrigin, crop.yOrigin, crop.width, crop.height);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('Crop', image);
    }
return output;
+[PIPipelineFilters(Debug) socPseudoColorFilter]_block_invoke
repairExtent != nil
+[PIRepairUtilities calcExtentsForStrokeRadius:offset:inputImageExtent:maskExtent:repairExtent:textureExtent:sourceExtent:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/Retouch/PIRepair.mm
textureExtent != nil
sourceExtent != nil
Bad half float to float conversion
+[PIRepairUtilities extractRGBAfPixelsFromImage:fromROI:]
PIRepair expects the incoming image to be RGBAh, not %@
inputMaskImage
inputMaskBoundingBox
inputFaceBoundingBoxes
PIRepair-applyRepairMLStrokeToMutableBuffer
Bad fixed float to half float conversion
+[PIRepairUtilities applyRepairStrokeToMutableBuffer:brushStroke:sourceOffset:repairEdges:]
vector
error != NULL
-[NURenderPipelineHelper(PI) videoReframe:reframes:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPhotosPipelineHelper.m
-[NURenderPipelineHelper(PI) videoCrossfadeLoop:crossfadeAdjustment:error:]
-[NURenderPipelineHelper(PI) portraitVideo:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:error:]
@"NSMutableArray"16@?0@"NSArray"8
-[NURenderPipelineHelper(PI) portraitVideoDebugDetectedObjects:source:cinematographyState:monochrome:error:]
Unexpected source type
extent
transform
AutoLoop/LongExposureMotion
PILongExposureFusion
inputStillImage
inputVideoScale
inputRenderScale
inputAlignmentExtent
inputAlignmentTransform
PIApertureRedEyeFilter
PIRedEye
inputDestinationImage
image != nil
+[PIHDRUtilities newHLGPixelBufferFromSDRImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIHDRUtilities.m
PIHDRInverseHLGFilter
Failed to start rendering %@ to: %@, error: %@
Succesfully rendered HLG buffer: %@
Failed to allocate pixel buffer
kernel vec4 hlg_luma_blending_inv(__sample sdr, float scale) 
  const vec3 lum_weights = vec3(0.2627, 0.6780, 0.0593); 
  float Ys = dot(lum_weights, sdr.rgb); 
  float Ymax = max(sdr.r, max(sdr.g, sdr.b)); 
  float Yb = 0.5*(Ys+Ymax); 
  const float gamma1 = 0.845906630893; 
  float absY = max(abs(Yb), 0.00001); 
  float gainInv = scale * pow(absY, 1.0/gamma1 - 1.0); 
  float3 hdr = gainInv * sdr.rgb; 
  return vec4(hdr.rgb, 1.0); 
recipe != nil
NSDictionary * _Nonnull PIAutoLoopRecipeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoop.m
CGRect PIAutoLoopRecipeGetCropRect(NSDictionary *__strong _Nonnull)
origin_x
origin_y
BOOL PIAutoLoopRecipeHasGoodStabilization(NSDictionary *__strong _Nonnull)
frameTransform != nil
CMTime PIAutoLoopRecipeFrameTransformGetTime(NSDictionary *__strong)
frameTransform_rawTime
matrix_float3x3 PIAutoLoopRecipeFrameTransformGetHomography(NSDictionary *__strong)
frameTransform_homography
NSDictionary * _Nonnull PIAutoLoopRecipeGetInstructionAtTime(NSDictionary *__strong _Nonnull, CMTime)
CMTIME_IS_VALID(time)
loopRecipe_frameInstructions
loopFrameData_presTime
q24@?0@"NSDictionary"8@"NSDictionary"16
CMTime PIAutoLoopRecipeGetFrameDuration(NSDictionary *__strong _Nonnull)
NSDictionary * _Nullable PIAutoLoopRecipeGetFlavorParameters(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
CMTimeRange PIAutoLoopRecipeGetTimeRangeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
completion != nil
-[PICurvesAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PICurvesAutoCalculator.m
-[PICurvesAutoCalculator computeCurvesForImageHistogram:]
softlink:r:path:/System/Library/Frameworks/JavaScriptCore.framework/JavaScriptCore
_PIParallaxInfillResult
PIParallaxInfillResult
NURenderResult
NSObject
PIParallaxInfillJob
PIParallaxInfillRequest
_PITapToTrackRenderResult
PITapToTrackResult
PITapToTrackRenderJob
PITapToTrackRequest
PIPhotoEffectHDR
PIPhotoEffectBlackAndWhiteHDR
PIPhotoEffectNoirHDR
PIPhotoEffectChromeHDR
PIPhotoEffectFadeHDR
PIPhotoEffectInstantHDR
PIPhotoEffectMonoHDR
PIPhotoEffectProcessHDR
PIPhotoEffectTonalHDR
PIPhotoEffectTransferHDR
PIPhotoEffectStageMonoHDR
PIPhotoEffect3DHDR
PIPhotoEffect3DBlackAndWhiteHDR
PIPhotoEffect3DVividHDR
PIPhotoEffect3DVividWarmHDR
PIPhotoEffect3DVividCoolHDR
PIPhotoEffect3DDramaticHDR
PIPhotoEffect3DDramaticCoolHDR
PIPhotoEffect3DDramaticWarmHDR
PIPhotoEffect3DSilverplateHDR
PIPhotoEffect3DNoirHDR
PIColorNormalizationFilter
PIReframeRules
PISemanticEnhanceAdjustmentController
_PIDisparitySampleResult
PIDisparitySampleResult
PIDisparitySampleJob
PIDisparitySampleRequest
PILocalContrastHDR
PIParallaxLayoutHelper
PISegmentationLayoutRegions
PFParallaxAssetRegions
PISegmentationLayout
_PIParallaxClockLayoutResult
PIParallaxClockLayoutResult
_PIParallaxClockLayoutJob
PIParallaxClockLayoutRequest
PIHighKey
PISegmentationInfillFilter
PISegmentationInwardFillProcessor
PIParallaxInwardFillKernel
PIParallaxColorPalette
PICompositionController
NSCopying
PICompositionSerializer
PICompositionSerializationResult
PICompositionSerializerMetadata
PILevelsFilterHDR
PIColorNormalizationAutoCalculator
NUTimeBased
PIFalseColorHDRDebug
PIAutoCalculatorUtils
PIAutoLoopExportRequest
PIAutoLoopExportClient
PIAutoLoopAnalysisRequest
PIAutoLoopAnalysisClient
PILongExposureRegistrationRequest
PIPortraitVideoProcessor
PIRGB10PortraitVideoProcessor
PIPortraitVideoFilter
PIAutoLoopAdjustmentController
PIIPTHueChromaFilter
PIIPTHueChromaColorFilter
PIIPTHueChromaGrayFilter
PIVideoCrossfadeLoopNode
PILivePhotoKeyFrameAdjustmentController
PIVignetteAdjustmentController
PIAdjustmentController
PIParallaxFilter
_PIParallaxClockMaterialResult
PIParallaxClockMaterialResult
_PIParallaxClockMaterialJob
PIParallaxClockMaterialRequest
NUDigest
PIPortraitVideoRenderNode
PIFaceObservationCache
PIParallaxStyleRecipeRegistry
PIParallaxStyleBundleURLProvider
PIParallaxStyleURLProvider
PIParallaxStyleUserURLProvider
PISourceSelectAdjustmentController
PIParallaxStyle
PIParallaxOriginalStyle
PIParallaxStudioStyle
PIParallaxTonalityModeStyle
PIParallaxColorBGStandardStyle
PIParallaxColorParameterStyle
PIParallaxBlackWhiteStudioStyle
PIParallaxBlackWhiteMonoStyle
PIParallaxColorWashSingleStyle
PIParallaxColorWashDuotoneStyle
PIParallaxRecipeStyle
PIScalarKeyframe
PIDictionaryRepresentable
PIReframeSubject
NSSecureCoding
NSCoding
PIParallaxSegmentationItem
PISegmentationItem
PISegmentationContextInfo
PIPortraitVideoAdjustmentController
PIParallaxColorSuggester
PIReframeKeyframe
PIReframeKeyframeSequence
_PIParallaxColorAnalysisResult
PIParallaxColorAnalysisResult
_PIParallaxRenderResource
_PIParallaxColorAnalysisJob
PIParallaxColorAnalysisRequest
PIParallaxColorAnalysis
PILongExposureFusionAutoCalculator
PIEffectAdjustmentController
PIAutoLoopAutoCalculator
PIMakerNoteUtilities
PITempTintFilter
PITimeVaryingPipelineStateSetting
_PIAutoLoopAnalysisResult
PIAutoLoopAnalysisResult
PIAutoLoopAnalysisJob
_PIVideoStabilizeFlowControl
ICFlowControl
_PIVideoStabilizeResult
PIVideoStabilizeResult
PIVideoStabilizeRenderJob
PIVideoStabilizeRequest
PIFaceBalanceAutoCalculator
GrayColorResult
RGBResult
PIWhiteBalanceAutoCalculator
_PIWhiteColorCalculator
PIDefinitionFilter
PISmartBlackAndWhiteAdjustmentController
PICompositionExporterDefaultMetadataConverter
PICompositionExporterMetadataConverter
PICompositionExportImagePrepareResult
PICompositionExportAuxiliaryResult
PICompositionExportResult
PICompositionExportDataResult
PICompositionExporterOptions
PICompositionExporterVideoOptions
PICompositionExporterImageOptions
PICompositionExporterAuxiliaryOptions
PICompositionExporter
GUBilateralConvolution
GUBWBilateralConvolution
PIBilateralFilter
PIPhotoEditAdjustmentsVersion
PINoiseReductionAdjustmentController
PrivateSmartColorHDR
PISmartColorFilterHDR
PIAutoEnhanceFilter
_PIParallaxCompoundLayerStackResult
PIParallaxLayerStackResult
PIParallaxCompoundLayerStackRequest
PIVideoCrossfadeLoopAdjustmentController
PISegmentationHelper
PIPortraitAdjustmentController
PIParallaxLegacyPosterStyle
PICompositionNoOpRemoval
PIOrientationAdjustmentController
PIParallaxStyleRecipeArchiver
PIPortraitVideoMetadataSample
PIPortraitVideoRenderer
PIDefinitionAdjustmentController
PIHighKeyHDR
PIPerspectiveAutoCalculator
PIFaceObservingAutoCalculator
PIRawNoiseReductionAdjustmentController
PICropAdjustmentController
PIRawAdjustmentController
PIParallaxRecipeFilter
PISmartToneAdjustmentController
PIAutoLoopKernels
PIPhotoEditHelper
PIAdjustmentConstants
PIFakeBoost
PIForwardFakeBoost
PIInverseFakeBoost
PICoreImageUtilities
PICompositionSerializerConstants
PICurvesFilterHDR
_PIParallaxLayoutResult
PIParallaxLayoutResult
_PIParallaxLayoutJob
PIParallaxLayoutRequest
PIParallaxLuminanceCalculator
PIParallaxStyleRecipe
PIParallaxStyleDefinition
PIParallaxStyleFilterDefinition
PIParallaxStyleFilterStackDefinition
PIParallaxStyleParameter
PIParallaxStyleNumberParameter
PIParallaxStyleColorParameter
PIParallaxStylePointParameter
PIParallaxStyleModeParameter
PIParallaxStyleBindingParameter
PIParallaxStyleEvaluationContext
PILongExposureAccumulator
_PILongExposureRegistrationResult
PILongExposureRegistrationResult
PILongExposureRegistrationJob
PIRAWTempTintSampler
PITagColorSampler
PIRedEye
PIVideoPosterFrameAdjustmentController
PICompositionSerializerFormatVersion
PICaptureDebugUtilities
PISlomoAdjustmentController
PISegmentationGatingRange
PISegmentationGatingRanges
PISegmentationGating
PIPortraitVideoDebugDetectionsRenderNode
PIColorWashFilter
PIColorWashDuoFilter
PIDebugAdjustmentController
PIGainMap
PIRAWFaceBalance
PICurvesLUTFilter
PICurvesFilter
PIColorBalanceFilter
PIPhotosPipelineHDRFilters
PIHighResFusionAdjustmentController
PIGlobalSettings
PIAutoLoopExportJob
PIJSRenderPipeline
PhotosPipeline
PIApertureRedEyeAutoCalculator
PrivateLocalLightHDR
PILocalLightMapPrepareHDR
PILocalLightFilterHDR
PIParallaxAsset
PFParallaxAsset
PFParallaxSegmentationResourceCaching
PIMsgImageBuffer
PISmartBlackAndWhiteAutoCalculator
PISmartBlackAndWhiteHDR
PrivateSmartBlackAndWhite
PITrimAdjustmentController
PIRedEyeAdjustmentController
PICinematicVideoUtilities
_PIParallaxRenderBuffer
NUImageBuffer
_PIParallaxRenderCacheEntry
_PIParallaxLayerStackResult
_PIParallaxLayerStackScalePolicy
NUScalePolicy
_PIParallaxLayerStackJob
_PIParallaxLayerStackRenderer
PIParallaxFilterCache
PIParallaxLayerStackRequest
_PIParallaxLayerStackDebugImageCollector
PILevelsAutoCalculator
PILevelsLuminanceAutoCalculator
PILevelsRGBAutoCalculator
AdjustmentExtensions
PICurveControlPoint
PrivateSmartToneHDR
PISmartToneFilterHDR
PICompositingFilter
PILongExposureFusion
PIModernPhotosPipeline
PILevelsFilter
PISegmentationLoader
PISegmentationLoading
_PISegmentationNullAsset
_PIParallaxLayoutInactiveFrameResult
PIParallaxLayoutInactiveFrameResult
_PIParallaxLayoutInactiveFrameJob
PIParallaxLayoutInactiveFrameRequest
PISchema
PICompositionFinalizer
PICompositionFinalizerResult
PIVideoStabilizeAdjustmentController
PICropAutoCalculator
Utilities
PISmartColorAdjustmentController
PISelectiveColorFilter
PIVideoReframeNode
PIVideoReframe
PIVideoReframeTimedMetadata
PIVideoReframeMetadataExtractor
PINeutralGrayWhiteBalanceFilter
PISmartToneAutoCalculator
PISmartColorAutoCalculator
PIRedEyeAutoCalculator
PIManualRedEyeAutoCalculator
PISegmentationCropFilter
PISegmentationMPSReduceProcessor
PISourceSampler
PIPhotoGrainHDR
PISegmentation
PIImageIO
PISharpenAdjustmentController
PIApertureRedEyeProcessorKernel
PIApertureRedEyeFilter
PIValuesAtCapture
PIPortraitAutoCalculator
PIDepthEffectApertureAutoCalculator
PIPipelineFilters
Debug
PIWhiteBalanceAdjustmentController
PIRepairUtilities
PIDepthAdjustmentController
PIVideoReframeAdjustmentController
PIHDRUtilities
PIHDRInverseHLGFilter
PICurvesAutoCalculator
PICurvesLuminanceAutoCalculator
PICurvesRGBAutoCalculator
CGColor
ARGB8
IPXEditSettings
BWBilateralKernels
CGRectValue
T@"CIImage",&,V_inputTableImage
CIImageProcessorDigestObject
T@"NSArray",C,N
CVPixelFormat
T@"NSArray",R,N
ICReportProgress:
T@"NSDictionary",R,C,N,V_ranges
JPEGCompressionQuality
T@"NSNumber",&,N,VinputContrast
LabToRGBKernel
T@"NSNumber",&,N,VinputStrength
P3KernelHDR
T@"NSNumber",&,V_inputIntensity
PIAutoEnhanceAdjustmentKey
T@"NSString",R,C,N,V_filterName
PICropAdjustmentKey
T@"NSURL",&,V_companionVideoURL
PIDefinitionAdjustmentKey
T@"PFParallaxColor",&,N,V_color
PIEffect3DAdjustmentKey
T@"PIParallaxInfillRequest",R,N
PIGrainAdjustmentKey
T@"PIParallaxStyle",&,N,V_style
PILevelsAdjustmentKey
TB,N,V_updateClockAreaLuminance
PIMuteAdjustmentKey
Td,N,V_rangeMin
PIOrientationAdjustmentKey
Td,V_minimumPitchCorrectionArea
PIPortraitAdjustmentKey
Tf,N,V_confidencePureBackground
PIRawAdjustmentKey
Tf,N,V_faceSize
PIRedEyeAdjustmentKey
Tq,R,N,V_source
PISelectiveColorAdjustmentKey
T{?={?=qq}{?=qq}},N,V_imageRect
PISharpenAdjustmentKey
PISmartBWAdjustmentKey
__defaultStyles
PISmartToneAdjustmentKey
_acceptableRect
PISourceSelectAdjustmentKey
_bounds
PIVideoCrossfadeLoopAdjustmentKey
_changeDelegate
PIVideoStabilizeAdjustmentKey
_colors
PIWhiteBalanceAdjustmentKey
_debugIntermediateLayoutBuffers
PPtogHDRKernel
_device
_disableOnPanos
RGBA16
_evaluateImage:
RGBAf
_expandedBounds
RGBResultValue
_finalizerError
RGBToYIQKernel
_height
ROIForCenterPoint:radius:
_imageHistogram
T#,R
_inputAlgorithm
T@"<MTLTexture>",&,N,V_sourceTexture
_inputBlurImage
T@"<NUImageBuffer>",&,N,V_debugColorAnalysisBuffer
_inputChromaMin
T@"<NUImageBuffer>",&,N,V_debugInfillBuffer
_inputIntensity
T@"<NUImageBuffer>",&,N,V_debugLayoutBuffer
_inputMaskImage
T@"<NUImageBuffer>",&,N,V_debugMatteBuffer
_inputMidDstRed
T@"<NUImageBuffer>",&,N,V_debugPreviewBuffer
_inputMidSrcRed
T@"<NUImageBuffer>",&,N,V_flattenedForegroundForDebugPreview
_layerStackMode
T@"<NUImageBuffer>",&,N,V_infilledImage
_layout
T@"<NUImageBuffer>",&,N,V_segmentationConfidenceMap
_loadingHandler
T@"<NUImageBuffer>",R,N
_luminanceValue
T@"<NUPurgeableStorage>",&,N,V_destination
_metadataClockOverlapAcceptable
T@"<NUScalePolicy>",&,N,V_scalePolicy
_nextInputFrame
T@"<NUVideoProperties>",&,N,V_inputVideoProperties
_portraitQualityForRenderScale:
T@"<PFParallaxAssetRegions>",&,N,V_layoutRegions
_readySemaphore
T@"<PFParallaxAssetRegions>",R,N
_renderPipeline
T@"<PFParallaxLayoutConfiguration>",R,N
_scores
T@"<PICompositionExporterMetadataConverter>",&
_segmentationConfidenceMapImage
T@"<PISegmentationItem>",R,N
_system
T@"AVAsset",&,N,V_videoSource
_warmth
T@"CIColor",&,N,V_inputHighlightColor
_yValue
T@"CIImage",&,N,V_backgroundImage
allKeys
T@"CIImage",&,N,V_debugConfidenceMapImage
analysisRequest
T@"CIImage",&,N,V_debugInputImage
applyVideoOrientationAsMetadata
T@"CIImage",&,N,V_debugLineDetectionImage
arrayWithArray:
T@"CIImage",&,N,V_debugMatteCropImage
attributeHueKey
T@"CIImage",&,N,V_debugPreviewImage
auxiliaryImage:
T@"CIImage",&,N,V_guideImage
availableStyles
T@"CIImage",&,N,V_image
backgroundLayer
T@"CIImage",&,N,V_inputDestinationImage
baseURL
T@"CIImage",&,N,V_inputForegroundImage
boolSettingForKey:defaultValue:
T@"CIImage",&,N,V_inputImage
centerMotionVectorFromMetadata:
T@"CIImage",&,N,V_inputMatteImage
chromaThreshold
T@"CIImage",&,N,V_inputTargetImage
clockLayerOrder
T@"CIImage",&,N,V_outputImage
colorsFromDictionary:key:error:
T@"CIImage",&,N,V_segmentationMatteImage
computeCurvesForImageHistogram:
T@"CIImage",&,N,VinputImage
constraintWidth
T@"CIImage",&,V_inputDepthMap
containsString:
T@"CIImage",R,N,V_cachedImage
convertFromIPT:
T@"CIRenderInfo",R,N,V_renderInfo
cropNode:cropRect:cropSettings:
T@"CIRenderTask",R,N,V_renderTask
dataWithLength:
T@"CIVector",&,N,V_inputAlignmentTransform
debugInputImage
T@"NSArray",&,N,V_debugIntermediateLayoutBuffers
defaultStrength
T@"NSArray",&,N,V_inputCorrectionInfo
disableDownload
T@"NSArray",&,V_inputPoints
effectiveLayout
T@"NSArray",&,V_inputPointsG
enabled
T@"NSArray",&,V_inputPointsR
ensureResources
T@"NSArray",C,N,V__availableStyles
faceOrientation
T@"NSArray",C,N,V_backgroundColors
falloff
T@"NSArray",C,N,V_dominantColors
filterHueKernel
T@"NSArray",C,N,V_foregroundColors
filters
T@"NSArray",C,N,V_petsFaceRegions
foregroundLayer
T@"NSArray",C,V_inputParams
grayStrengthKey
T@"NSArray",R,C,N,V_backgroundFilters
hasFrontFacingCameraDimentions:
T@"NSArray",R,C,N,V_foregroundFilters
T@"NSArray",R,C,N,V_matteFilters
imageWithCVPixelBuffer:options:
T@"NSArray",R,C,N,V_secondaryColors
infillAlgorithm
T@"NSArray",R,N,V_petRegions
initWithAssetReaderTrackOutput:
T@"NSArray",R,N,VpetRegions
initWithDevice:
T@"NSArray",R,V_subjects
initWithLength:
T@"NSCache",&,N,V_labelImageCache
initWithPixelBuffer:renderTask:
T@"NSData",&,V_companionImageData
initWithRecipe:
T@"NSDate",&,N,V_lastUseTime
initWithScript:
T@"NSDictionary",&,N,V_recipe
inputBrightness
T@"NSDictionary",&,V_recipe
inputEdgeDetail
T@"NSDictionary",C,N,V_localLightData
inputHighlights
T@"NSDictionary",C,N,V_recipe
inputLumaTarget
T@"NSDictionary",R
inputMidDstBlue
T@"NSDictionary",R,C,N,V_parameters
inputSaturation
T@"NSDictionary",R,N,V_cameraInfo
inputStillImage
T@"NSError",&,N,V_finalizerError
inputVideoScale
T@"NSIndexSet",R,C,N,V_suggestionIndices
isGeometryIdentityForImageSize:
T@"NSMutableDictionary",R,V_debugDiagnostics
isInUse
T@"NSNumber",&,N,V_i
isSmart
T@"NSNumber",&,N,V_inputBlackDstBlue
kindKey
T@"NSNumber",&,N,V_inputBlackDstRGB
leftEye
T@"NSNumber",&,N,V_inputBlackSrcBlue
lowercaseString
T@"NSNumber",&,N,V_inputBlackSrcRGB
maximumAperture
T@"NSNumber",&,N,V_inputChromaMax
T@"NSNumber",&,N,V_inputFocusedDisparity
nccCoarseKernel
T@"NSNumber",&,N,V_inputHilightDstGreen
newCommandQueue
T@"NSNumber",&,N,V_inputHilightDstRed
numberWithBool:
T@"NSNumber",&,N,V_inputHilightSrcGreen
openForWriting:
T@"NSNumber",&,N,V_inputHilightSrcRed
options
T@"NSNumber",&,N,V_inputHueRange
originalCropKey
T@"NSNumber",&,N,V_inputIntensity
parallaxPadding
T@"NSNumber",&,N,V_inputLumaRange
petsFaceRegions
T@"NSNumber",&,N,V_inputMidDstBlue
portraitInfoKey
T@"NSNumber",&,N,V_inputMidDstRGB
progressHandler
T@"NSNumber",&,N,V_inputMidSrcBlue
T@"NSNumber",&,N,V_inputMidSrcRGB
rateKey
T@"NSNumber",&,N,V_inputRenderDebugMode
rawTime
T@"NSNumber",&,N,V_inputRenderScale
regionWithRect:
T@"NSNumber",&,N,V_inputShadowDstGreen
release
T@"NSNumber",&,N,V_inputShadowDstRed
request
T@"NSNumber",&,N,V_inputShadowSrcGreen
resetTag:input:
T@"NSNumber",&,N,V_inputShadowSrcRed
result:
T@"NSNumber",&,N,V_inputVideoScale
rgbToLumaKernel
T@"NSNumber",&,N,V_inputWarmTint
samplerWithImage:keysAndValues:
T@"NSNumber",&,N,V_inputWhiteDstGreen
secondaryColors
T@"NSNumber",&,N,V_inputWhiteDstRed
setAutoCropped:
T@"NSNumber",&,N,V_inputWhiteSrcGreen
setBool:forKey:
T@"NSNumber",&,N,V_inputWhiteSrcRed
setComposition:
T@"NSNumber",&,N,V_maximumAperture
setContextInfo:
T@"NSNumber",&,N,V_q
setGuideExtent:
T@"NSNumber",&,N,V_warmth
setIncludeCinematicVideoTracks:
T@"NSNumber",&,N,VinputBlack
setInputBorder:
T@"NSNumber",&,N,VinputCast
setInputParams:
T@"NSNumber",&,N,VinputRawHighlights
setInputRadius:
T@"NSNumber",&,V_inputBorder
setInputWarmth:
T@"NSNumber",&,V_inputRadius
setLayoutScore:
T@"NSNumber",C,N
setObservation:
T@"NSNumber",C,N,VinputGrain
setOrientation:
T@"NSNumber",C,N,VinputISO
setPetsRegions:
T@"NSNumber",C,N,VinputScaleFactor
setRenderScale:
T@"NSNumber",C,N,VinputTone
setRollRadians:
T@"NSNumber",C,V_autoStraightenVerticalAngleThreshold
setScalePolicy:
T@"NSNumber",C,V_maxAutoPitch
setSegmentationInfillAlgorithm:
T@"NSNumber",R,N,V_alphaValue
setShouldPerformAutoStraighten:
T@"NSNumber",R,N,V_greenValue
setSourceIdentifier:forTrackID:
T@"NSNumber",R,N,V_redValue
setStorageMode:
T@"NSNumber",R,N,V_yValue
setVideoFrames:
T@"NSString",&,N,V_clockLayerOrder
setVisibleRect:
T@"NSString",&,N,V_formatVersion
setYCbCrMatrix:
T@"NSString",&,N,V_inputAlgorithm
set_accumError:
T@"NSString",&,N,V_inputCameraModel
smartToneSchema
T@"NSString",&,N,V_inputMode
stabCropRectKey
T@"NSString",C,N,V_systemBuildVersion
storage
T@"NSString",C,N,V_systemVersion
stringByAppendingPathExtension:
T@"NSString",C,V_debugFilesPrefix
submit:
T@"NSString",C,V_inputVersion
subpath
T@"NSString",R
timeKey
T@"NSString",R,C,N
toneKey
T@"NSString",R,C,N,V_platform
trackIdentifier
T@"NSString",R,C,N,V_variableName
upsampleBackgroundImage:toSize:
T@"NSString",R,N,V_PIApertureRedEyeAdjustmentKey
userOrientation
T@"NSString",R,N,V_PIAutoLoopAdjustmentKey
visualInputKeys
T@"NSString",R,N,V_PICurvesAdjustmentKey
warmUpResources
T@"NSString",R,N,V_PIDepthAdjustmentKey
T@"NSString",R,N,V_PIEffectAdjustmentKey
yawAngleDegrees
.cxx_destruct
HLGOpticalScale
BGRA8
PIVideoPosterFrameAdjustmentKey
CGColorSpace
RGBToLabKernels
CIFormat
T@"CIImage",R,N
CVPixelBuffer
T@"NSArray",C,N,V_dominantGrays
HDRFilterForSDRFilter:
T@"NSDictionary",C,V_properties
ICShouldBeCanceled
T@"NSNumber",&,N,V_inputHasFace
JSONObjectWithData:options:error:
T@"NSNumber",&,N,VinputExposure
P3Kernel
T@"NSNumber",&,N,VinputVibrancy
PIApertureRedEyeAdjustmentKey
T@"NSNumber",C,N,VinputStrength
PIAutoLoopAdjustmentKey
T@"NSString",R,V_destinationUTI
PICurvesAdjustmentKey
T@"NUColorSpace",&,V_colorSpace
PIDepthAdjustmentKey
T@"PIParallaxColorAnalysis",R,N
PIEffectAdjustmentKey
T@"PIParallaxLayoutRequest",R,N
PIHighResFusionAdjustmentKey
TB,N,V_preserveSourceColorSpace
PILivePhotoKeyFrameAdjustmentKey
Td,N,V_rangeMax
PINoiseReductionAdjustmentKey
Td,V_inputBoost
PIOvercaptureSourceAdjustmentKey
Tf,N,V_aperture
PIPortraitVideoAdjustmentKey
Tf,N,V_confidencePureForeground
PIRawNoiseReductionAdjustmentKey
Tq,N,V_priority
PIRetouchAdjustmentKey
Tq,R,V_rawState
PISemanticEnhanceAdjustmentKey
PISlomoAdjustmentKey
_PISemanticEnhanceAdjustmentKey
PISmartColorAdjustmentKey
_abort:
PISourceAdjustmentKey
_accumSemaphore
PITrimAdjustmentKey
_bundle
PIVideoReframeAdjustmentKey
_classification
PIVignetteAdjustmentKey
_completedTrack
PNGRepresentationOfImage:format:colorSpace:options:
_destinationUTI
PUEditSettings
_digest
RG16
_dominantColors
RGBA8
_evaluateVideo:
RGBAh
_extent
RGBToLabKernel
_flavor
RGBValues
_hueChromaImage
SDOFRenderingVersion
_initializeStorage:image:error:
T@"<MTLDevice>",R,N,V_device
_inputBlendMode
T@"<NUImageBuffer>",&,N,V_backgroundBuffer
_inputChromaMax
T@"<NUImageBuffer>",&,N,V_debugConfidenceMapBuffer
_inputHueTarget
T@"<NUImageBuffer>",&,N,V_debugInputBuffer
_inputLumaRange
T@"<NUImageBuffer>",&,N,V_debugLocalConfidenceBuffer
_inputMidDstRGB
T@"<NUImageBuffer>",&,N,V_debugMatteCropBuffer
_inputMidSrcRGB
T@"<NUImageBuffer>",&,N,V_flattenedBackgroundForDebugPreview
_inputThreshold
T@"<NUImageBuffer>",&,N,V_foregroundBuffer
_layers
T@"<NUImageBuffer>",&,N,V_segmentationBackground
_loadLocalLightData:completion:
T@"<NUImageBuffer>",&,N,V_segmentationMatte
_localLightData
T@"<NUImageBuffer>",R,N,V_pixelBuffer
_markAsFinished
T@"<NURenderStatistics>",R
_nFaces
T@"<NUScalePolicy>",&,V_scalePolicy
_originalLayout
T@"<PFParallaxAsset>",R,N,V_asset
_ranges
T@"<PFParallaxAssetRegions>",&,N,V_regions
_recipe
T@"<PFParallaxLayoutConfiguration>",&,N,V_layoutConfiguration
_result
T@"<PICompositionControllerDelegate>",W,N,V_changeDelegate
_secondaryColor
T@"<PIParallaxFilterCache>",&,N,V_cache
_source
T@"<PISegmentationItem>",R,N,V_segmentationItem
_videoCodecType
T@"CIColor",&,N,V_inputColor
_xValue
T@"CIColor",&,N,V_inputShadowColor
addTagWithName:inputNode:error:
T@"CIImage",&,N,V_debugColorAnalysisImage
allowCompressedInputsAndOutputs
T@"CIImage",&,N,V_debugInfillImage
applyImageOrientationAsMetadata
T@"CIImage",&,N,V_debugLayoutImage
applyWithForeground:background:
T@"CIImage",&,N,V_debugLocalConfidenceImage
assetIdentifier
T@"CIImage",&,N,V_debugMatteImage
autoKey
T@"CIImage",&,N,V_foregroundImage
auxiliaryImages
T@"CIImage",&,N,V_hueChromaImage
backgroundImage
T@"CIImage",&,N,V_inputBackgroundImage
base64EncodedStringWithOptions:
T@"CIImage",&,N,V_inputDisparityImage
bilateralROI:destRect:userInfo:
T@"CIImage",&,N,V_inputGuideImage
bundleForClass:
T@"CIImage",&,N,V_inputMaskImage
cgColor
T@"CIImage",&,N,V_inputStillImage
cleanUp
T@"CIImage",&,N,V_matteImage
colorProperties
T@"CIImage",&,N,V_segmentationConfidenceMapImage
compositionKeys
T@"CIImage",&,N,V_stillImage
conformsToType:
T@"CIImage",&,V_inputBlurImage
containsObject:
T@"CIImage",&,V_inputImage
context
T@"CIImage",R,N,V_image
copyOfCompositionRemovingNoOps:
T@"CIRenderTask",&,N,V_task
currentPlatform
T@"CIVector",&,N,V_inputAlignmentExtent
dealloc
T@"NSArray",&,N,V_colorSuggestions
debugMatteImage
T@"NSArray",&,N,V_debugIntermediateLayoutImages
destinationData
T@"NSArray",&,N,V_inputCorrections
disparityBuffer
T@"NSArray",&,V_inputPointsB
elementByteSize
T@"NSArray",&,V_inputPointsL
endTime
T@"NSArray",&,V_inputWeights
extractMetadata
T@"NSArray",C,N,V__defaultStyles
faceStrengthKey
T@"NSArray",C,N,V_colors
fileURL
T@"NSArray",C,N,V_dominantHues
filterWithName:
T@"NSArray",C,N,V_layers
foregroundImage
T@"NSArray",C,N,V_petsRegions
geometryRequestWithComposition:
T@"NSArray",R,C,N
groupIdentifier
T@"NSArray",R,C,N,V_filters
hasTonalityMode
T@"NSArray",R,C,N,V_keyframes
T@"NSArray",R,C,N,V_primaryColors
imageWithColor:
T@"NSArray",R,N,V_faceRegions
infillMaskForSegmentationMatte:
T@"NSArray",R,N,VfaceRegions
initWithColors:
T@"NSArray",R,N,VtimedMetadataArray
initWithLayout:
T@"NSCache",&,N,V_cache
initWithNumber:
T@"NSData",&,N,V_data
initWithRanges:
T@"NSData",&,V_data
initWithResult:
T@"NSDictionary",&,N
initWithSource:
T@"NSDictionary",&,V_auxiliaryImages
inputColorSpace
T@"NSDictionary",C,N
inputGuideImage
T@"NSDictionary",C,N,V_parameters
inputLocalLight
T@"NSDictionary",C,N,V_scores
inputMatteImage
T@"NSDictionary",R,C,N
inputMidSrcBlue
T@"NSDictionary",R,N
inputShadowsKey
T@"NSDictionary",R,N,V_rawHomographies
inputTableImage
T@"NSError",&,V__accumError
isEqualToArray:
T@"NSMutableData",&,Vdata
isHuman
T@"NSNumber",&,N
isProxy
T@"NSNumber",&,N,V_inputAperture
T@"NSNumber",&,N,V_inputBlackDstGreen
labelImageCache
T@"NSNumber",&,N,V_inputBlackDstRed
localIdentifier
T@"NSNumber",&,N,V_inputBlackSrcGreen
T@"NSNumber",&,N,V_inputBlackSrcRed
medianLuminance
T@"NSNumber",&,N,V_inputChromaMin
minimumAperture
T@"NSNumber",&,N,V_inputHilightDstBlue
neutral
T@"NSNumber",&,N,V_inputHilightDstRGB
T@"NSNumber",&,N,V_inputHilightSrcBlue
openForReading:
T@"NSNumber",&,N,V_inputHilightSrcRGB
optimizeForBackgroundProcessing
T@"NSNumber",&,N,V_inputHueIsNormalized
orientationAdjustmentController
T@"NSNumber",&,N,V_inputHueTarget
overlapStrategy
T@"NSNumber",&,N,V_inputIsRaw
parallaxWallpaperDisableUpgrade
T@"NSNumber",&,N,V_inputLumaTarget
photoEffectName
T@"NSNumber",&,N,V_inputMidDstGreen
posterFrameTime
T@"NSNumber",&,N,V_inputMidDstRed
pushDebugGroup:
T@"NSNumber",&,N,V_inputMidSrcGreen
quality
T@"NSNumber",&,N,V_inputMidSrcRed
rawHomographies
T@"NSNumber",&,N,V_inputRenderQuality
T@"NSNumber",&,N,V_inputShadowDstBlue
regions
T@"NSNumber",&,N,V_inputShadowDstRGB
render:
T@"NSNumber",&,N,V_inputShadowSrcBlue
requestRevision
T@"NSNumber",&,N,V_inputShadowSrcRGB
resolutionRatio
T@"NSNumber",&,N,V_inputStrength
results
T@"NSNumber",&,N,V_inputWarmTemp
roundedRectangleGeneratorFilter
T@"NSNumber",&,N,V_inputWhiteDstBlue
sceneConfidence
T@"NSNumber",&,N,V_inputWhiteDstRGB
semanticEnhance
T@"NSNumber",&,N,V_inputWhiteSrcBlue
setBitRateMultiplicationFactor:
T@"NSNumber",&,N,V_inputWhiteSrcRGB
setColorMatrix:
T@"NSNumber",&,N,V_luminanceValue
setCompression:
T@"NSNumber",&,N,V_minimumAperture
setDestination:
T@"NSNumber",&,N,V_strength
setHue:
T@"NSNumber",&,N,V_y
setInputAmount:
T@"NSNumber",&,N,VinputBrightness
setInputCutoff:
T@"NSNumber",&,N,VinputHighlights
setInputPoints:
T@"NSNumber",&,N,VinputShadows
setInputTimedRenderingMetadata:
T@"NSNumber",&,V_inputEdgeDetail
setLastUseTime:
T@"NSNumber",&,V_inputVersion
setMaxFaceSize:
T@"NSNumber",C,N,VinputAmount
setOffsetBlack:
T@"NSNumber",C,N,VinputHue
setOutputImage:
T@"NSNumber",C,N,VinputNeutralGamma
setPixelFormat:
T@"NSNumber",C,N,VinputSeed
setRenderState:
T@"NSNumber",C,V_autoStraightenDominantAngleDiffThreshold
setScaleFactor:
T@"NSNumber",C,V_maxAutoAngle
setSegmentationDebugTintLayers:
T@"NSNumber",C,V_maxAutoYaw
setSegmentationLoader:forAsset:
T@"NSNumber",R,N,V_blueValue
setSourceColor:
T@"NSNumber",R,N,V_numberValue
setSourceTrackIDForFrameTiming:
T@"NSNumber",R,N,V_xValue
setTemperature:
T@"NSObject<OS_dispatch_queue>",&,N,V_loadingHandlerQueue
setVideoSource:
T@"NSString",&,N,V_formatIdentifier
setWithObjects:
T@"NSString",&,N,V_identifier
setYaw:
T@"NSString",&,N,V_inputBlendMode
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
T@"NSString",&,N,V_inputColorSpace
sourceSelection
T@"NSString",C,N
stopAtTagIncludeGeometryFilter:
T@"NSString",C,N,V_systemName
stringByAppendingPathComponent:
T@"NSString",C,N,V_videoCodecType
subMinorVersion
T@"NSString",C,V_digest
submitVerified:
T@"NSString",C,V_pairingIdentifier
T@"NSString",R,C
tintKey
T@"NSString",R,C,N,V_modeValue
trackID
T@"NSString",R,C,N,V_stackName
uniqueInputNode
T@"NSString",R,N
T@"NSString",R,N,V_PIAutoEnhanceAdjustmentKey
version
T@"NSString",R,N,V_PICropAdjustmentKey
warmUpRequests:
T@"NSString",R,N,V_PIDefinitionAdjustmentKey
T@"NSString",R,N,V_PIEffect3DAdjustmentKey
T@"NSString",R,N,V_PIGrainAdjustmentKey
T@"NSString",R,N,V_PIHighResFusionAdjustmentKey
T@"NSString",R,N,V_PILevelsAdjustmentKey
T@"NSString",R,N,V_PILivePhotoKeyFrameAdjustmentKey
T@"NSString",R,N,V_PIMuteAdjustmentKey
T@"NSString",R,N,V_PINoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIOrientationAdjustmentKey
T@"NSString",R,N,V_PIOvercaptureSourceAdjustmentKey
T@"NSString",R,N,V_PIPortraitAdjustmentKey
T@"NSString",R,N,V_PIPortraitVideoAdjustmentKey
T@"NSString",R,N,V_PIRawAdjustmentKey
T@"NSString",R,N,V_PIRawNoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIRedEyeAdjustmentKey
T@"NSString",R,N,V_PIRetouchAdjustmentKey
T@"NSString",R,N,V_PISelectiveColorAdjustmentKey
T@"NSString",R,N,V_PISemanticEnhanceAdjustmentKey
T@"NSString",R,N,V_PISharpenAdjustmentKey
T@"NSString",R,N,V_PISlomoAdjustmentKey
T@"NSString",R,N,V_PISmartBWAdjustmentKey
T@"NSString",R,N,V_PISmartColorAdjustmentKey
T@"NSString",R,N,V_PISmartToneAdjustmentKey
T@"NSString",R,N,V_PISourceAdjustmentKey
T@"NSString",R,N,V_PISourceSelectAdjustmentKey
T@"NSString",R,N,V_PITrimAdjustmentKey
T@"NSString",R,N,V_PIVideoCrossfadeLoopAdjustmentKey
T@"NSString",R,N,V_PIVideoPosterFrameAdjustmentKey
T@"NSString",R,N,V_PIVideoReframeAdjustmentKey
T@"NSString",R,N,V_PIVideoStabilizeAdjustmentKey
T@"NSString",R,N,V_PIVignetteAdjustmentKey
T@"NSString",R,N,V_PIWhiteBalanceAdjustmentKey
T@"NSString",R,N,V_unit
T@"NSString",R,W,N
T@"NSURL",&,N,V_baseURL
T@"NSURL",&,N,V_cacheURL
T@"NSURL",&,N,V_fileURL
T@"NSURL",&,N,V_segmentationDataURL
T@"NSURL",&,V_primaryURL
T@"NSURL",&,V_videoComplementURL
T@"NSURL",&,V_videoPosterFrameURL
T@"NSURL",R,N
T@"NSURL",R,N,V_fileURL
T@"NSURL",R,V_destinationLongExposureURL
T@"NSURL",R,V_destinationMaskURL
T@"NUAdjustment",&,V_reframeCropAdjustment
T@"NUAdjustment",&,V_reframeVideoAdjustment
T@"NUAdjustment",R,N,V_adjustment
T@"NUCVPixelBuffer",&,N,V_inputColorPixelBuffer
T@"NUCVPixelBuffer",&,N,V_inputDisparityPixelBuffer
T@"NUColorSpace",&,N,V_colorSpace
T@"NUColorSpace",R
T@"NUColorSpace",R,N
T@"NUColorSpace",R,N,V_colorSpace
T@"NUComposition",&,N,V_composition
T@"NUComposition",R,C,N
T@"NUComposition",R,C,V_composition
T@"NUComposition",R,N
T@"NUIdentifier",&,N,V_identifier
T@"NUIdentifier",R
T@"NUImageExportFormat",C,V_imageExportFormat
T@"NUImageExportRequest",&,V_request
T@"NUImageGeometry",&,V_geometry
T@"NUImageHistogram",&,N,V_imageHistogram
T@"NUPixelFormat",&,N,V_pixelFormat
T@"NUPixelFormat",R,N
T@"NUPixelFormat",R,N,V_pixelFormat
T@"NUPriority",&,V_priority
T@"NURuleSystem",R,N,V_system
T@"PFParallaxAssetResource",&,N,V_resource
T@"PFParallaxColor",&,N
T@"PFParallaxColor",&,N,V_clockColor
T@"PFParallaxColor",&,N,V_primaryColor
T@"PFParallaxColor",&,N,V_secondaryColor
T@"PFParallaxColor",R,N
T@"PFParallaxLayerStack",&,N,V_layerStack
T@"PFParallaxLayerStack",R,N
T@"PFParallaxLayerStyle",R,N
T@"PFParallaxLayout",&,N,V_defaultLayout
T@"PFParallaxLayout",&,N,V_layout
T@"PFParallaxLayout",&,N,V_originalLayout
T@"PFParallaxLayout",R,N
T@"PFParallaxLayout",R,N,V_layout
T@"PFStoryRecipeDisplayAssetNormalization",&,N,VinputNormalization
T@"PFStoryRecipeDisplayAssetNormalization",R,N
T@"PIAdjustmentConstants",R,N
T@"PIFaceObservationCache",&,N
T@"PIFaceObservationCache",&,N,V_faceObservationCache
T@"PIParallaxClockLayoutRequest",R,N
T@"PIParallaxColorAnalysis",&,N,V_colorAnalysis
T@"PIParallaxColorAnalysisRequest",R,N
T@"PIParallaxLayoutInactiveFrameRequest",R,N
T@"PIParallaxStyle",R,N
T@"PIParallaxStyleRecipe",&,N,V_recipe
T@"PIParallaxStyleRecipe",R,N
T@"PIPortraitVideoMetadataSample",&,N,V_inputTimedRenderingMetadata
T@"PIPortraitVideoMetadataSample",R,N
T@"PIReframeKeyframeSequence",&,N,V_keyframeSequence
T@"PISegmentationContextInfo",&,N,V_contextInfo
T@"PTCinematographyScript",&,N,V_cinematographyScript
T@"PTCinematographyTrack",&,N,V_completedTrack
T@"PTCinematographyTrack",R,N
T@"PTCinematographyTrack",R,N,V_completedTrack
T@"PTGlobalRenderingMetadata",&,N,V_inputGlobalRenderingMetadata
T@"PTGlobalRenderingMetadata",R,N
T@"PTTimedRenderingMetadata",&,N,V_timedMetadata
T@"VNImageHomographicAlignmentObservation",&,N,V_observation
T@"VNImageHomographicAlignmentObservation",C,N,V_observation
T@"VNImageHomographicAlignmentObservation",R,C
T@"_PIParallaxLayerStackDebugImageCollector",&,N,V_debugImageCollector
T@?,C,N,V_downloadProgressHandler
T@?,C,N,V_loadingHandler
T@?,C,N,V_progressHandler
T@?,C,N,V_shouldCancelHandler
T@?,C,V_metadataProcessor
TB,N
TB,N,GisInUse,V_inUse
TB,N,GisOriginalCrop
TB,N,GisSmart
TB,N,V_allowSpillMatteOnOlderPortraitV2Captures
TB,N,V_analyzeBackground
TB,N,V_applyVideoOrientationAsMetadata
TB,N,V_bypassOutputSettingsIfNoComposition
TB,N,V_clockOverlapAcceptable
TB,N,V_computeDigest
TB,N,V_disableDownload
TB,N,V_disableRendering
TB,N,V_disableSegmentation
TB,N,V_facePositionAcceptable
TB,N,V_forceGlassesMatteOff
TB,N,V_forceSpillMatteOff
TB,N,V_includeCinematicVideoTracks
TB,N,V_increaseBitRateIfNecessary
TB,N,V_inputIsHDR
TB,N,V_isInCloud
TB,N,V_metadataClockOverlapAcceptable
TB,N,V_proxyOnly
TB,N,V_requireHardwareEncoder
TB,N,V_segmentationDisabled
TB,N,V_shouldApplyWatermark
TB,N,V_shouldInfillForeground
TB,N,V_updateClockZPosition
TB,N,V_updateInactiveFrame
TB,N,VparallaxStyleAvoidColorWashBrownOverride
TB,R
TB,R,N
TB,R,N,GisAnalysisAvailable
TB,R,N,GisAvailable
TB,R,N,GisEditable,V_editable
TB,V_applyImageOrientationAsMetadata
TB,V_applyVideoOrientationAsMetadata
TB,V_canPropagateOriginalAuxiliaryData
TB,V_clientRequestedStop
TB,V_debugFilesEnabled
TB,V_disableOnFrontFacingCameraImages
TB,V_disableOnPanos
TB,V_force
TB,V_optimizeForBackgroundProcessing
TB,V_optimizeForSharing
TB,V_renderCompanionResources
TB,V_shouldPerformAutoCrop
TB,V_shouldPerformAutoStraighten
TB,V_shouldRunBuildingCheck
TB,V_shouldUseAutoStraightenVerticalDetector
TQ,N
TQ,N,V_SDOFRenderingVersion
TQ,N,V_allowedAnalysisTypes
TQ,N,V_candidacy
TQ,N,V_classification
TQ,N,V_clockIntersection
TQ,N,V_layerStackOptions
TQ,N,V_loadingState
TQ,N,V_performedActions
TQ,N,V_portraitMajorVersion
TQ,N,V_portraitMinorVersion
TQ,N,V_segmentationClassification
TQ,N,V_version
TQ,R
TQ,R,N
TQ,R,N,V_analysisType
TQ,R,N,V_majorVersion
TQ,R,N,V_minorVersion
TQ,R,N,V_subMinorVersion
TQ,R,VelementByteSize
TQ,R,Vheight
TQ,R,VrowElements
TQ,R,Vwidth
T^{__CVBuffer=},R,N
Td,N
Td,N,V_allowedCropFraction
Td,N,V_backgroundLuminance
Td,N,V_chromaThreshold
Td,N,V_dominanceThreshold
Td,N,V_foregroundLuminance
Td,N,V_inputOrigI
Td,N,V_inputOrigQ
Td,N,V_inputStrength
Td,N,V_inputTemperature
Td,N,V_inputTint
Td,N,V_inputWarmth
Td,N,V_luminance
Td,N,V_medianLuminance
Td,N,V_pitchAngleDegrees
Td,N,V_renderScale
Td,N,V_rollAngleDegrees
Td,N,V_yawAngleDegrees
Td,R
Td,R,N
Td,R,N,V_aperture
Td,R,N,V_clockAreaLuminance
Td,R,N,V_confidence
Td,R,N,V_depthMax
Td,R,N,V_depthMin
Td,R,N,V_focusedDisparity
Td,R,N,V_manualMax
Td,R,N,V_manualMin
Td,R,N,V_max
Td,R,N,V_min
Td,R,N,V_x
Td,R,N,V_y
Td,V_JPEGCompressionQuality
Td,V_angleSeedDegreesCCW
Td,V_inputCutoff
Td,V_maxAutoStraighten
Td,V_maxFaceSize
Td,V_minAutoStraighten
Td,V_minimumAngleCorrection
Td,V_minimumConfidence
Td,V_minimumPitchCorrection
Td,V_minimumYawCorrection
Td,V_minimumYawCorrectionArea
Tf,N,V_confidenceMapScore
Tf,N,V_cropScore
Tf,N,V_faceLocalConfidence
Tf,N,V_groundedScore
Tf,N,V_inputThreshold
Tf,N,V_layoutScore
Tf,N,V_localConfidenceScore
Tf,N,V_mattePureBackground
Tf,N,V_mattePureForeground
Tf,N,V_nFaces
Tf,N,V_parallaxScore
Tf,N,V_portraitStrength
Tf,N,V_resolutionRatio
Tf,N,V_sampledDisparityValue
Tf,N,V_segmentationScore
Tf,R,N
Tf,R,N,V_sampledDisparityValue
Tf,V_inputThreshold
Ti,R,N
Ti,R,N,V_quality
Ti,R,Vformat
Tq,N
Tq,N,V_alphaCount
Tq,N,V_edgeBleed
Tq,N,V_flavor
Tq,N,V_height
Tq,N,V_imageOrientation
Tq,N,V_infillAlgorithm
Tq,N,V_layerStackMode
Tq,N,V_maxDominantColors
Tq,N,V_orientation
Tq,N,V_sampleMode
Tq,N,V_sourceMode
Tq,N,V_version
Tq,N,V_width
Tq,N,VparallaxStyleKeyLevelOverride
Tq,N,Vtonality
Tq,R,N
Tq,R,N,V_debugMode
Tq,R,N,V_identifier
Tq,R,N,V_type
Tq,R,V_disposition
T{?=[3]},R,N,V_homography
T{?=[3]},R,V_trajectoryHomography
T{?=[4d]},R
T{?=ffff},N,V_luminanceThresholds
T{?=ffff},N,V_luminanceWeights
T{?=ii},N,V_depthVersionInfo
T{?=qiIq},N
T{?=qiIq},N,V_frameDuration
T{?=qiIq},N,V_rawTime
T{?=qiIq},N,V_renderTime
T{?=qiIq},N,V_sampleTime
T{?=qiIq},N,V_startTime
T{?=qiIq},N,V_time
T{?=qiIq},N,Vtime
T{?=qiIq},R,N
T{?=qiIq},R,N,V_crossfadeDuration
T{?=qiIq},R,N,V_startTime
T{?=qiIq},R,N,V_time
T{?=qiIq},R,V_time
T{?=qq},D
T{?=qq},R,N
T{?=qq},R,N,V_colorSize
T{?=qq},R,N,V_disparitySize
T{?=qq},V_inputSize
T{?={?=[4d]}{?=[4d]}d},R
T{?={?=qiIq}{?=qiIq}},N
T{?={?=qiIq}{?=qiIq}},R,N,V_loopTimeRange
T{?={?=qq}{?=qq}},N
T{?={?=qq}{?=qq}},N,V_cleanAperture
T{?={?=qq}{?=qq}},N,V_extent
T{?={?=qq}{?=qq}},N,V_guideExtent
T{?={?=qq}{?=qq}},N,V_stabCropRect
T{?={?=qq}{?=qq}},R,N
T{?={?=qq}{?=qq}},R,N,V_stabCropRect
T{CGPoint=dd},N,V_normalizedImagePoint
T{CGRect={CGPoint=dd}{CGSize=dd}},N
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_expandedBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_inactiveRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_normalizedClipRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_sampleRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_visibleFrame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_visibleRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_acceptableCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_acceptableRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_preferredCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_preferredRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,VacceptableCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,VpreferredCropRect
T{CGVector=dd},R,V_estimatedCenterMotion
T{CGVector=dd},R,V_estimatedMotionBlur
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLWithString:
UUID
UUIDString
YIQToRGBKernel
_JPEGCompressionQuality
_LUTImage
_PIApertureRedEyeAdjustmentKey
_PIAutoEnhanceAdjustmentKey
_PIAutoLoopAdjustmentKey
_PICropAdjustmentKey
_PICurvesAdjustmentKey
_PIDefinitionAdjustmentKey
_PIDepthAdjustmentKey
_PIEffect3DAdjustmentKey
_PIEffectAdjustmentKey
_PIGrainAdjustmentKey
_PIHighResFusionAdjustmentKey
_PILevelsAdjustmentKey
_PILivePhotoKeyFrameAdjustmentKey
_PIMuteAdjustmentKey
_PINoiseReductionAdjustmentKey
_PIOrientationAdjustmentKey
_PIOvercaptureSourceAdjustmentKey
_PIPortraitAdjustmentKey
_PIPortraitVideoAdjustmentKey
_PIRawAdjustmentKey
_PIRawNoiseReductionAdjustmentKey
_PIRedEyeAdjustmentKey
_PIRetouchAdjustmentKey
_PISelectiveColorAdjustmentKey
_PISharpenAdjustmentKey
_PISlomoAdjustmentKey
_PISmartBWAdjustmentKey
_PISmartColorAdjustmentKey
_PISmartToneAdjustmentKey
_PISourceAdjustmentKey
_PISourceSelectAdjustmentKey
_PITrimAdjustmentKey
_PIVideoCrossfadeLoopAdjustmentKey
_PIVideoPosterFrameAdjustmentKey
_PIVideoReframeAdjustmentKey
_PIVideoStabilizeAdjustmentKey
_PIVignetteAdjustmentKey
_PIWhiteBalanceAdjustmentKey
_SDOFRenderingVersion
__accumError
__availableStyles
_acceptableCropRect
_accumError
_accumQueue
_accumulate:
_accumulate:error:
_addDummySourceToCompositionIfNeeded:
_adjustment
_adjustmentControllerClassForKey:
_adjustmentControllerForKey:creatingIfNecessary:expectedClass:
_allowSpillMatteOnOlderPortraitV2Captures
_allowedAnalysisTypes
_allowedCropFraction
_alphaCount
_alphaValue
_analysisType
_analyzeBackground
_analyzeColors:completion:
_angleSeedDegreesCCW
_aperture
_appendInputFrame:
_applyImageOrientationAsMetadata
_applyVideoOrientationAsMetadata
_asset
_autoStraightenDominantAngleDiffThreshold
_autoStraightenVerticalAngleThreshold
_auxiliaryImages
_availableStyles
_averageAccumulationStorage
_backgroundBuffer
_backgroundColors
_backgroundFilters
_backgroundImage
_backgroundLuminance
_baseURL
_beginRenderNormalizedHueChromaImage:targetGray:grayRange:chromaMax:error:
_beginRenderNormalizedHueChromaImage:targetHue:hueRange:chromaMin:error:
_beginRenderingImage:colorSpace:format:error:
_blueValue
_brightnessMultiplierFromImageProperties:
_bufferRenderClient
_bypassOutputSettingsIfNoComposition
_cache
_cacheSegmentationDataForItem:
_cacheURL
_cachedImage
_cachedImageEntries
_calculateBlackAndWhiteSettingsFromBufferImage:
_calculateWithImageProperties:valuesAtCapture:completion:
_cameraInfo
_cameraInfoFromMetadataGroup:
_canPropagateOriginalAuxiliaryData
_candidacy
_changes
_chooseNeutralGrayForNonSushi:
_chooseTempTintForSushi:RAWProperties:brightness:
_chromaThreshold
_cinematographyScript
_classify:completion:
_cleanAperture
_clientRequestedStop
_clockAreaLuminance
_clockColor
_clockIntersection
_clockLayerOrder
_clockOverlapAcceptable
_color
_colorAnalysis
_colorSize
_colorSpace
_colorSuggestions
_companionImageData
_companionVideoURL
_composition
_computeAllHistograms:
_computeAvoidingRect:imageSize:maxYMotion:segmentationMatte:layoutConfiguration:context:
_computeCleanAperture:
_computeDigest
_computeGreenPercentage:
_computeHeadroomZoomFactorWithVisibleFrame:scaleCenter:initialOverlap:matte:layoutConfiguration:context:
_computeNCCMapFromImage:toImage:scale:
_computeWhitePointColorWithGrayEdgesBuffer:grayWorldBuffer:greenChannelPercentage:RAWCameraSpaceProperties:
_confidence
_confidenceMapScore
_confidencePureBackground
_confidencePureForeground
_configureRGBColorTexture:format:isHDR:
_configureRequest:
_context
_contextInfo
_correctedRGBResultFromResult:
_cropScore
_crossfadeDuration
_customAttributesForKey:
_data
_debugColorAnalysisBuffer
_debugColorAnalysisImage
_debugConfidenceMapBuffer
_debugConfidenceMapImage
_debugDiagnostics
_debugDumpIntermediateImages
_debugFilesEnabled
_debugFilesPrefix
_debugImageCollector
_debugInfillBuffer
_debugInfillImage
_debugInputBuffer
_debugInputImage
_debugIntermediateLayoutImages
_debugLayoutBuffer
_debugLayoutImage
_debugLineDetectionImage
_debugLocalConfidenceBuffer
_debugLocalConfidenceImage
_debugMatteBuffer
_debugMatteCropBuffer
_debugMatteCropImage
_debugMatteImage
_debugMode
_debugPreviewBuffer
_debugPreviewImage
_defaultCurveArray
_defaultLayout
_defaultStyles
_delegateFlags
_depthMax
_depthMin
_depthVersionInfo
_deserializeFilterDefinition:version:error:
_deserializeFilterDefinitions:version:error:
_deserializeParameter:version:error:
_deserializeParameters:version:error:
_destination
_destinationLongExposureURL
_destinationMaskURL
_didLoad:completion:
_disableDownload
_disableOnFrontFacingCameraImages
_disableRendering
_disableSegmentation
_disparitySize
_disposition
_dominanceThreshold
_dominantGrays
_dominantHues
_doneGroup
_downloadProgressHandler
_dynamismMapWithMinImage:maxImage:extent:
_edgeBleed
_editable
_ensureResources
_error
_estimatedCenterMotion
_estimatedMotionBlur
_evaluateAudioMix:
_evaluateImageGeometry:
_evaluateImageWithFilterDefinitions:inputImage:
_evaluateVideoComposition:
_evaluateVideoProperties:
_exportOutputImage:format:colorSpace:toURL:uti:error:
_exportVideoToURL:composition:options:properties:progress:completion:
_faceLocalConfidence
_faceObservationCache
_facePositionAcceptable
_faceRegions
_faceRequest
_faceSize
_fileURL
_filterForRecipeIdentifier:
_filterName
_filters
_finished
_flattenedBackgroundForDebugPreview
_flattenedForegroundForDebugPreview
_focusedDisparity
_force
_forceGlassesMatteOff
_forceSpillMatteOff
_foregroundBuffer
_foregroundColors
_foregroundFilters
_foregroundImage
_foregroundLuminance
_formatIdentifier
_formatVersion
_frameCount
_frameDuration
_freeResources
_fuseImage:withGuideImage:weightImage:maskImage:
_geometry
_grainBlendAndMixKernel
_greenValue
_groundedScore
_group
_guideExtent
_guideImage
_handlePartialItem:loadingState:
_highKeyHDR
_homography
_homographySequence
_identifier
_identifierMap
_image
_imageByAddingDetection:toImage:isPrimary:canvasSize:inverseOrientation:
_imageDataClient
_imageExportFormat
_imageOptions
_imageOrientation
_imageRect
_imageRenderRequestWithComposition:wideGamut:
_inUse
_inactiveRect
_includeCinematicVideoTracks
_increaseBitRateIfNecessary
_infillAlgorithm
_infilledImage
_infilledImageBuffer
_initializeAccumulation
_initializeAccumulation:
_inputAlignmentExtent
_inputAlignmentTransform
_inputAperture
_inputBackgroundImage
_inputBlackDstBlue
_inputBlackDstGreen
_inputBlackDstRGB
_inputBlackDstRed
_inputBlackSrcBlue
_inputBlackSrcGreen
_inputBlackSrcRGB
_inputBlackSrcRed
_inputBoost
_inputBorder
_inputCameraModel
_inputColor
_inputColorPixelBuffer
_inputColorSpace
_inputCorrectionInfo
_inputCorrections
_inputCutoff
_inputDepthMap
_inputDestinationImage
_inputDisparityImage
_inputDisparityPixelBuffer
_inputEdgeDetail
_inputFocusedDisparity
_inputForegroundImage
_inputFrames
_inputGlobalRenderingMetadata
_inputGuideImage
_inputHasFace
_inputHighlightColor
_inputHilightDstBlue
_inputHilightDstGreen
_inputHilightDstRGB
_inputHilightDstRed
_inputHilightSrcBlue
_inputHilightSrcGreen
_inputHilightSrcRGB
_inputHilightSrcRed
_inputHueIsNormalized
_inputHueRange
_inputImage
_inputIsHDR
_inputIsRaw
_inputLumaTarget
_inputMatteImage
_inputMidDstBlue
_inputMidDstGreen
_inputMidSrcBlue
_inputMidSrcGreen
_inputMode
_inputOrigI
_inputOrigQ
_inputParams
_inputPoints
_inputPointsB
_inputPointsG
_inputPointsL
_inputPointsR
_inputRadius
_inputRenderDebugMode
_inputRenderQuality
_inputRenderScale
_inputShadowColor
_inputShadowDstBlue
_inputShadowDstGreen
_inputShadowDstRGB
_inputShadowDstRed
_inputShadowSrcBlue
_inputShadowSrcGreen
_inputShadowSrcRGB
_inputShadowSrcRed
_inputSize
_inputStillImage
_inputStrength
_inputTableImage
_inputTargetImage
_inputTemperature
_inputTimedRenderingMetadata
_inputTint
_inputVersion
_inputVideoProperties
_inputVideoScale
_inputWarmTemp
_inputWarmTint
_inputWarmth
_inputWeights
_inputWhiteDstBlue
_inputWhiteDstGreen
_inputWhiteDstRGB
_inputWhiteDstRed
_inputWhiteSrcBlue
_inputWhiteSrcGreen
_inputWhiteSrcRGB
_inputWhiteSrcRed
_interpolateGrainKernel
_isCancelled
_isDefault
_isIdentity
_isInCloud
_isLoading
_isReadyForMoreData
_isValidSegmentationMatteHistogramForDepth:
_item
_jobNumber
_kernelBneg
_kernelBpos
_kernelC
_kernelCNeg
_kernelCPos
_kernelC_hdr
_kernelCast
_kernelH
_kernelLocalContrast
_kernelRH
_kernelV_gt1
_kernelV_lt1
_keyToIdentifierMap
_keyframeSequence
_keyframes
_keyframesForKey:class:
_labelImageCache
_lastUseTime
_layerStack
_layerStackOptions
_layerStackOptionsFromOptions:
_layoutConfiguration
_layoutRegions
_layoutScore
_load:
_loadAssetResource:options:completion:
_loadAssetResourceForProxy:completion:
_loadBackground:completion:
_loadColorsFromValues:mode:error:
_loadFullSizeResource:completion:
_loadItem:completion:
_loadProxyResource:completion:
_loadRegions:completion:
_loadRequestID
_loadSegmentationData:completion:
_loadSegmentationItemFromURL:error:
_loadSegmentationItemFromWallpaperURL:error:
_loadingError
_loadingHandlerQueue
_loadingState
_localConfidenceScore
_localLightDataForImage:
_location
_lookupColor:withPredicate:
_loopTimeRange
_lowMemoryModeSupportedForComposition:
_luminance
_luminanceThresholds
_luminanceWeights
_majorVersion
_manualMax
_manualMin
_map
_matte
_matteFilters
_matteImage
_mattePureBackground
_mattePureForeground
_max
_maxAutoAngle
_maxAutoPitch
_maxAutoStraighten
_maxAutoYaw
_maxDominantColors
_maxFaceSize
_maximumAccumulationStorage
_maximumAperture
_mdataTrack
_medianLuminance
_metadataProcessor
_min
_minAutoStraighten
_minimumAccumulationStorage
_minimumAngleCorrection
_minimumAperture
_minimumConfidence
_minimumPitchCorrection
_minimumPitchCorrectionArea
_minimumYawCorrection
_minimumYawCorrectionArea
_minorVersion
_modeValue
_newHLGPixelBufferOfSize:
_noOpRemovalFunctions
_normalizedClipRect
_normalizedImagePoint
_numberValue
_observation
_optimizeForBackgroundProcessing
_optimizeForSharing
_options
_orientation
_outputImage
_paddedTileKernel
_pairingIdentifier
_paletteWithConfigurationDictionary:error:
_parallaxScore
_parameters
_performLayout:completion:
_performSegmentation:type:completion:
_performedActions
_petRegions
_petsFaceRegions
_petsRegions
_petsRequestID
_pipelineFilters
_pitchAngleDegrees
_pixelBuffer
_pixelFormat
_pixelSize
_platform
_polyKernelHDR
_populateAvailableStyles
_populateDefaultStyles
_portraitMajorVersion
_portraitMinorVersion
_portraitStrength
_preferredCropRect
_preferredRect
_preserveSourceColorSpace
_prewarmPortraitRendererWithPipelineState:error:
_primaryColor
_primaryColors
_primaryURL
_primitiveValueForKey:
_priority
_processedRenderNodeForComposition:input:pipelineState:error:
_progressHandler
_properties
_proxyOnly
_purgeRenderResources
_quality
_queue
_rangeMax
_rangeMin
_rawHomographies
_rawState
_rawTime
_recipesForIdentifiers:withURLProvider:
_recordError:
_recordResult:
_redValue
_refineMaskImage:guideImage:scale:
_reframeCropAdjustment
_reframeVideoAdjustment
_regions
_renderCompanionResources
_renderContext
_renderImage:toPixelBuffer:
_renderInfo
_renderResources
_renderScale
_renderState
_renderTask
_renderTime
_renderer
_reportProgressAtTime:rect:confidence:
_request
_requests
_requireHardwareEncoder
_resolutionRatio
_resource
_responseWithLayerStack:
_results
_rollAngleDegrees
_sampleMode
_sampleRect
_sampleTime
_sampledDisparityValue
_sanitizeComposition:
_saveSegmentationItem:layerStack:toWallpaperURL:completion:
_scalePolicy
_secondaryColors
_segment:completion:
_segmentationBackground
_segmentationClassification
_segmentationConfidenceMap
_segmentationDataURL
_segmentationDisabled
_segmentationItem
_segmentationMatte
_segmentationMatteImage
_segmentationScore
_serializeColors:mode:
_serializeComposition:versionInfo:needsGeometry:error:
_serializeDefinition:
_serializeFilters:
_serializeParameter:
_serializeParameters:
_setKeyframes:forKey:
_setPrimitiveValue:forKey:
_shadowKernelHDR
_shouldApplyWatermark
_shouldCancelHandler
_shouldInfillForeground
_shouldPerformAutoCrop
_shouldPerformAutoStraighten
_shouldRunBuildingCheck
_shouldUseAutoStraightenVerticalDetector
_shouldWaitForDependentJobs
_signpost
_smartSettings
_sourceBufferFromInput:error:
_sourceMode
_sourceTexture
_stabCropRect
_stabilizeImage:cleanRect:cropRect:transform:geometry:
_stackName
_start
_startTime
_stateQueue
_stats
_stillImage
_storagePool
_strength
_style
_styleFromOptions:item:
_subMinorVersion
_subjects
_submit:
_submitClockMaterialRequestWithLayerStack:completion:
_submitClockOverlapRequestWithLayout:completion:
_submitGERenderRequest:
_submitGWRenderRequest:
_submitInactiveLayoutRequest:
_submitLayerStackRequestForMode:layout:completion:
_submitLayerStackRequestsWithLayout:completion:
_suggestionIndices
_systemBuildVersion
_systemName
_systemVersion
_targetScaleForScale:
_task
_temporaryDestinationStorage
_time
_timedMetadata
_touchDiameter
_trajectoryHomography
_tryLoadSegmentationItemFromCache:
_type
_unit
_updateClockAreaLuminance
_updateClockZPosition
_updateInactiveFrame
_updateRenderState:withLegacyCameraInfo:
_updateSettingsWithInputColor:
_updateSettingsWithInputLight:
_upgradeFullPosterAtURL:exportToURL:options:completion:
_upgradeWallpaperAtURL:exportToURL:options:completion:
_useSushi
_useTempTint:
_validateValueTypesForKeys:requiredKeys:inDictionary:error:
_value
_variableName
_version
_versionRules
_videoComplementURL
_videoPosterFrameURL
_videoSource
_videoTrack
_visibleFrame
_visibleRect
_waitForRenderResources:
_whitePointColorFromGrayEdgesImage:grayWorldImage:greenChannelPercentage:RAWCameraSpaceProperties:
_width
_yawAngleDegrees
absoluteString
acceptableCropRect
accumulate:error:
addAdjustmentWithKey:
addAssetIdentifier:toMetadataArray:
addAssetIdentifier:toMetadataDictionary:
addBytes:length:
addCompletedHandler:
addDetectionAndStartTrackingRect:time:colorBuffer:disparityBuffer:
addDetectionForNextFrameAt:colorBuffer:disparityBuffer:
addEntriesFromDictionary:
addImageProperties:composition:options:error:
addIndex:
addMethodDiagnostics:details:
addMethodResultToDiagnostics:error:setYawPitchError:
addMutableTrackWithMediaType:preferredTrackID:
addObject:
addObjectsFromArray:
addOutput:
addRect:
addRule:
addRuleWithHueMin:hueMax:suggestion:
addRulesFromArray:
addVideoProperties:composition:options:error:
adjustment
adjustmentConstants
adjustmentControllerClassForKey:
adjustmentControllerForKey:
adjustmentData
adjustmentDataFormatVersionForComposition:
adjustmentFormat
adjustmentHasCTM:settings:
adjustmentHasPerspective:settings:
adjustmentInformationForComposition:error:
adjustmentInformationForComposition:needsGeometry:error:
adjustmentKeys
adjustmentValuesForKey:
adjustmentVersion
aggregateStatistics:
alignImage:transform:extent:
alignedRowBytesForWidth:
alignment
alignmentKey
allAdjustmentTypes
allAssetsCanUseHDRPipeline
allDetections
allPoints
allValues
allocWithZone:
allowPartialOutputRegion
allowSpillMatteOnOlderPortraitV2Captures
allowedAnalysisTypes
allowedCropFraction
alphaCompositingKernel
alphaCount
alphaValue
amountKey
analysisAvailable
analysisType
analyzeBackground
angle
angleKey
angleRadians
angleSeedDegreesCCW
aperture
apertureAutoEnhanceFiltersForImage:
apertureFocalRatio
apertureKey
apertureKeyframes
apertureRedEyeResultFromFaceObservations:imageSize:
apertureRedEyeSchema
appendFormat:
appendPoints:pointCount:
appendString:
applyAttachmentsToCVPixelBuffer:
applyChangesFromCompositionController:
applyInactiveStyleToImage:error:
applyInputConversion:
applyOrientationFilter
applyOutputConversion:
applyRepairMLStrokeToMutableBuffer:brushStroke:detectedFaces:context:error:
applyRepairStrokeToMutableBuffer:brushStroke:sourceOffset:repairEdges:
applyToRenderRequest:
applyToRenderState:
applyWithExtent:arguments:
applyWithExtent:inputs:arguments:error:
applyWithExtent:roiCallback:arguments:
applyWithExtent:roiCallback:arguments:options:
applyWithExtent:roiCallback:inputImage:arguments:
applyWithInputImage:disparityImage:inputPixelBuffer:disparityPixelBuffer:globalMetadata:timedMetadata:aperture:focusedDisparity:quality:debugMode:isHDR:error:
archiveURL
areCPVAssetsEditable
areaAverageFilter
areaHistogramFilter
array
arrayByAddingObject:
arrayWithCapacity:
arrayWithObjects:count:
asOrderedInteger
asset
asset:
assetIdentifierForURL:type:useEmbeddedPreview:
assetIsCinematicVideo:
assetReaderWithAsset:error:
assetUUID
assetWithURL:
attributeBlackPointKey
attributeBrightnessKey
attributeCastKey
attributeContrastKey
attributeExposureKey
attributeGrainKey
attributeHighlightsKey
attributeLightMapHeightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLocalLightKey
attributeNeutralGammaKey
attributeShadowsKey
attributeStrengthKey
attributeToneKey
attributeVibrancyKey
audioMix
audioMixInputParametersWithTrack:
autoAdjustmentFiltersWithOptions:
autoCalculatorWithImageData:orientation:
autoCropFilter
autoCropped
autoEnhanceCache
autoEnhanceFiltersForImage:algorithm:
autoKeysForPaste
autoLoopAdjustmentController
autoLoopAdjustmentControllerCreatingIfNecessary:
autoLoopExportRequest
autoLoopSchema
autoStraightenDominantAngleDiffThreshold
autoStraightenVerticalAngleThreshold
autoValuesForBlackPoint:whitePoint:
autoloopStabilizedVideoFilter
autorelease
auxiliaryCoreGraphicsInfoDictionary:
auxiliaryDataInfoMetadata
auxiliaryImage
auxiliaryImageFromComposition:type:mediaComponentType:error:
auxiliaryImageType
auxiliaryImagesProperties
available
availableBlendModes
availableDecoderVersions
availableKeys
availableStyleOfKind:
averageCGPoints:pointCount:
averagePoints:pointCount:
backfillScalePolicy
backgroundBuffer
backgroundColors
backgroundFilters
backgroundForImage:matte:
backgroundForImage:matte:infill:
backgroundLuminance
bakedStyle
baseAddress
begin
beginGroupWithName:error:
bestCropRectV2ForAspectRatio:sourcePixelWidth:sourcePixelHeight:sourceEssentialAreaRect:sourceSecondaryEssentialAreaRect:outputCropScore:
bestCropRectV2ForAspectRatio:withFocusRegion:sourcePixelWidth:sourcePixelHeight:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:outputCropScore:
bestCropRectV2ForParallaxClassification:layoutConfiguration:sourcePixelWidth:sourcePixelHeight:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:outputCropScore:outputLayoutScore:outputClockOverlapAcceptable:
bestLayout:
bilateralAdd1Kernel
bilateralAdd2Kernel
bilateralAdd3Kernel
bilateralAdd4Kernel
bilateralAdd5Kernel
bilateralAdd6Kernel
bilateralAdd7Kernel
bilateralAdd8Kernel
bilateralAdd9Kernel
bilateralAddROI:destRect:userInfo:
bilateralFinalizeKernel
bilateralKernels
bilateralLoop11Kernel
bilateralLoop2Kernel
bilateralLoop5Kernel
bimodalScoreForHistogram:
blackColor
blackImage
blackInfillImage:matte:
blendKernelForBlendMode:
blendWithMaskFilter
blue
blueColor
blueValue
blur3x3Kernel
blur5x5Kernel
blur7x7Kernel
boolForKey:
boolValue
boostCurveValueAt:
boostParametersFromRawProperties:
boundingBox
boundingBoxes
boundingBoxesKey
bounds
boundsForPointArray:
brushStrokeFromRetouchStrokeDictionary:
buffer
bufferColorspace
bufferFactory
buildNumber
bypassOutputSettingsIfNoComposition
bytes
bytesAtPoint:
bytesPerPixel
bytesPerRow
cache
cacheImage:key:format:colorSpace:
cacheKey
cacheNode:type:settings:error:
cacheURL
cachedImage
cachedImage:forKey:
calcExtentsForStrokeRadius:offset:inputImageExtent:maskExtent:repairExtent:textureExtent:sourceExtent:
calculateClockLuminanceValuesForLayerStack:renderer:error:
calculateColorWithProperties:completion:
calculateCurveTable:
calculateLuminanceValuesForImage:renderer:error:
calculateRAWWithRequest:completion:
calculateSettingsForImageHistogram:
calculateSettingsForSingleChannelHistogram:suffix:
calculateWithRequest:completion:
callStackSymbols
cameraCalibrationData
cameraInfo
canAddOutput:
canAdjustApertureValue
canApplyPortraitEffectsWithMetadata:
canBeEnabled
canGenerateNewCropRect:
canHaveAuto
canInflate
canInterpretDataWithFormatIdentifier:formatVersion:
canPerformGyroBasedStabilizationForAsset:
canPropagateOriginalAuxiliaryData
canPropagateOriginalLivePhotoMetadataTrack
canProvideMetadataForAVAsset:
canRenderDepth
canRenderPortraitEffect
cancel
cancelAllRequests
cancelParallaxResourceRequest:
cancelPetsRegionsRequest:
cancelSegmentationForAsset:
canceledError:object:
candidacy
capabilitiesForCurrentDevice
captureDebugDirectoryForComposition:
capturedAperture
caseInsensitiveCompare:
changeDelegate
changesDictionaryTrimmedByTimeRange:
chroma
ciImageTiled:closed:pressureMode:
cinematicAllowRGB10Packed
cinematicAllowYUVSourceInput
cinematicMetadataFromAsset:
cinematographyScript
cinematographyState
class
classification
cleanAperture
cleanApertureOfTrack:oriented:
clientRequestedStop
clipRect
clockAreaLuminance
clockColor
clockFont
clockIntersection
clockIntersectionFromTopRectMatteCoverage:bottomRectMatteCoverage:
clockLayoutRequest
clockMaterialRequest
clockOverlapAcceptable
clockOverlapAcceptableForLayoutConfiguration:
close
close:
color
colorAnalysis
colorAnalysisRequest
colorBGPalette
colorBalanceKernel
colorBalanceKernels
colorBuffer
colorCubeForNormalization:dimension:targetColorSpace:
colorInvertFilter
colorNormalizationFiltersForImage:
colorPaletteWithStyleKind:
colorSize
colorSpace
colorSpaceFromColorPrimaries:transferFunction:yccMatrix:
colorSpaceFromVideoColorProperties:
colorSuggestionForCategory:
colorSuggestions
colorThresholdFilter
colorType
colorTypeForString:
colorTypeKey
colorWashDuotonePalette
colorWashFixedKernel
colorWashFixedSmoothKernel
colorWashKernels
colorWashSinglePalette
colorWashVariableKernel
colorWashVariableSmoothKernel
colorWithCGColor:
colorWithRGBValues:error:
colorWithRed:green:blue:
colorWithRed:green:blue:alpha:
colorWithRed:green:blue:alpha:colorSpace:
colorWithRed:green:blue:colorSpace:
colors
commitAndNotifyOnQueue:withBlock:
companionImageData
companionVideoURL
compare:
complete:
completedTrack
componentMax
componentMin
componentsJoinedByString:
componentsSeparatedByString:
composition
compositionByRemovingVideoAndLivePhotoAdjustments:
compositionController:adjustmentControllerClassForKey:
compositionController:didAddAdjustment:
compositionController:didRemoveAdjustment:
compositionController:didUpdateAdjustment:
compositionController:didUpdateAdjustments:
compressData:options:error:
computeAlphaCoverageWithRect:foregroundImage:context:
computeAvoidOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:outputUnsafeOverlap:context:
computeClockLayerOrderWithVisibleFrame:foregroundImage:layoutConfiguration:context:
computeClockLayerOrderWithVisibleFrame:segmentationMatte:layoutConfiguration:context:interactive:
computeCommandEncoder
computeCropScoreForIntermediate:
computeDigest
computeHeadroomZoomFactorWithVisibleFrame:zoomTowardsTop:matte:layoutConfiguration:context:
computeHistogramFromBuffer:error:
computeInactiveAvoidingRectForVisibleRect:acceptableFrame:unsafeRect:imageSize:newVisibleRect:
computeInactiveFrameWithVisibleFrame:imageSize:canUpdateVisibleRect:segmentationMatte:layoutConfiguration:context:
computeLayoutsWithHelper:
computeMatteCoverageWithRect:segmentationMatte:context:
computeSegmentationScoresForAsset:options:completion:
computeTargetOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:context:
computedSettings
confidence
confidenceMapBuffer
confidenceMapScore
confidencePureBackground
confidencePureForeground
configuration
configurationType
configurationWithDeviceName:
configureForCategory:
conformRange:inRange:
conformsToProtocol:
constants
constraintHeight
constraintHeightKey
constraintWidthKey
containsIndex:
contents
contentsDictionary
contextForContext:
contextInfo
contextWithOptions:
conversionMap
convertFacePoint:toImagePointWithFaceRect:orientation:
convertFixed16:toFloat:count:
convertFloat:toFixed16:count:
convertHueChromaImageToIPT:
convertHueChromaImageToRGB:
convertIPTImageToHueChroma:
convertIPTImageToRGB:
convertRGBImageToHueChroma:
convertRGBImageToIPT:
convertToIPT:
coolColor
copy
copyItemAtURL:toURL:error:
copyKeyframesTrimmingToTimeRange:
copyOfAdjustmentRemovingNoOps:identifier:
copyPixelsFromImage:rect:destPtr:destPtrRowBytes:
copyPixelsFromImage:srcRect:destImage:destOrigin:
copyPixelsToImage:atPoint:fromBuffer:inRect:
copyPixelsToImage:rect:srcPtr:srcPtrRowBytes:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createCGImage:fromRect:
createCGImage:fromRect:format:colorSpace:deferred:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createHueArray
createRGBA:
createRenderStateWithQuality:
createSloMoWithInput:startTime:endTime:rate:error:
createYUV420:chroma:
cropAdjustmentController
cropAdjustmentControllerCreatingIfNecessary:
cropFraction
cropRect
cropSchema
cropScore
cropScoreThresholdForClassification:
crossfadeDuration
crossfadeDurationTimescaleKey
crossfadeDurationValueKey
curatedSegmentationGatingDecisionForSegmentationScores:
currentContext
currentContextInfo
currentDirectoryPath
currentFormatVersion
currentHandler
currentSoftwareVersion
currentSystemCanRenderAsset:
currentSystemRenderingVersion
currentVersion
curvePointAtIndex:blackPoint:whitePoint:histogram:
curvePointsFromDictionaries:
curvesKernel
curvesSchema
customAttributes
customPalette
data
dataForImageBuffer:error:
dataType
dataValue
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
debugColorAnalysisBuffer
debugColorAnalysisImage
debugConfidenceMapBuffer
debugConfidenceMapImage
debugDescription
debugDescriptionOfAssetTrack:
debugDiagnostics
debugDumpIntermediateImages
debugFilesEnabled
debugFilesPrefix
debugImageCollector
debugImageForColorAnalysis:inputImage:visibleFrame:
debugImageWithInputImage:finalLayout:intermediateLayout:faceRects:saliencyPreferrectRect:saliencyAcceptableRect:
debugImageWithInputImage:layout:faceRects:saliencyPreferrectRect:saliencyAcceptableRect:
debugInfillBuffer
debugInfillImage
debugInputBuffer
debugIntermediateLayoutBuffers
debugIntermediateLayoutImages
debugLayoutBuffer
debugLayoutImage
debugLayouts
debugLineDetectionImage
debugLocalConfidenceBuffer
debugLocalConfidenceImage
debugMatteBuffer
debugMatteCropBuffer
debugMatteCropImage
debugMode
debugNodeByApplyingFilterWithName:useHDRFilter:settingsAndInputs:
debugPreviewBuffer
debugPreviewImage
debugPreviewRenderWithBackground:foreground:layout:style:
debugSchema
debugTintedImage:isBackfill:
decimalDigitCharacterSet
decodeData:filename:error:
decodeDoubleForKey:
decodeIntegerForKey:
decodeObjectForKey:
decodingSupportForAVAsset:
decompressData:options:error:
defaultDominantColorWithAnalysis:
defaultFocalLength
defaultFormatForURL:
defaultLayout
defaultManager
defaultStyleForKind:colorAnalysis:
defaultStyleOfKind:
defaultStyles
defaultValue
defaultValueForKey:
definition
definitionAdjustmentController
definitionAdjustmentControllerCreatingIfNecessary:
definitionKernel
definitionSchema
denormalizeHueChromaImage:
depth
depthAdjustmentController
depthAdjustmentControllerCreatingIfNecessary:
depthBlurEffectRenderingParameters
depthBlurEffectSimulatedAperture
depthCameraCalibrationData
depthDataQuality
depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:
depthEffectInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
depthEffectSchema
depthEnabled
depthInfo
depthInfoKey
depthMax
depthMin
depthVersionInfo
description
descriptionForCandidacy:
deserializeCompositionFromAdjustments:metadata:formatIdentifier:formatVersion:error:
deserializeCompositionFromData:formatIdentifier:formatVersion:error:
deserializeDictionaryFromData:error:
deserializeFromDictionary:error:
deserializeMetadataWithType:fromGlobalMetadata:error:
deserializeRecipe:error:
destination
destinationLongExposureURL
destinationMaskURL
destinationUTI
detectionType
device
deviceConfiguration
deviceResolution
deviceScalePolicy
deviceSupportsHardware10BitHEVCEncoding
deviceSupportsHighDynamicRangeVideo
dictionariesFromPoints:
dictionary
dictionaryForKey:
dictionaryFromLayoutConfiguration:
dictionaryFromRegions:
dictionaryRepresentation
dictionaryWithContentsOfFile:
dictionaryWithContentsOfURL:error:
dictionaryWithDictionary:
dictionaryWithLayout:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
dictionaryWithStyle:
differingAdjustmentsWithComposition:
digest
dilateMask:withRadius:
disableApertureEffects:
disableIOSurfacePortaitExport
disableOnFrontFacingCameraImages
disableOnPanos
disableRendering
disableSegmentation
discreteProgressWithTotalUnitCount:
disparityKeyframes
disparitySize
dispatchThreadgroups:threadsPerThreadgroup:
displayInputKeys
displayName
displayP3ColorSpace
disposition
distanceToColor:
doBilateralLoop:points:weights:slope:
doBilateralPass:points:weights:sums:slope:
dominanceThreshold
dominantColor
dominantColors
dominantGrays
dominantHues
doubleForKey:
doubleValue
downloadProgressHandler
dynamismMapKernel
dynamismMapRefineKernel
edgeBleed
edgesKey
editConfiguration
editSettings
editable
effect3DAdjustmentController
effect3DAdjustmentControllerCreatingIfNecessary:
effect3DSchema
effectAdjustmentController
effectAdjustmentControllerCreatingIfNecessary:
effectNameForFilterName:
effectSchema
effectiveAcceptableRectForClassification:havePetFaces:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:
effectivePreferredRectForClassification:havePetFaces:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:
enableHDRSupport
enabledKey
encodeData:filename:error:
encodeDouble:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeRenderTo:withRenderRequest:
encodeToCommandBuffer:destinationTexture:
encodeWithCoder:
encodedPixelSizeOfTrack:oriented:
endEncoding
endGroupWithName:error:
endKey
endScaleKey
enlargedBounds:withPoints:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
erodeMask:withRadius:
error
errorWithCode:reason:object:
errorWithCode:reason:object:underlyingError:
errorWithDomain:code:userInfo:
estimatedCenterMotion
estimatedMotionBlur
evaluate:input:pipelineState:error:
evaluateWithContext:error:
evaluationMode
exceptionWithName:reason:userInfo:
exifOrientationAndCropStraightenOnly
expandedBounds
exportComposition:options:completionQueue:completion:
exportComposition:toPrimaryURL:videoComplementURL:videoPosterFrameURL:priority:completionQueue:completion:
exportImageToDataWithComposition:options:completion:
exportImageToURL:composition:options:completion:
exportVideoToURL:composition:options:completion:
exportWallpaperForAsset:toURL:options:completion:
extent
extractDataToDictionary:dataExtractor:options:context:colorSpace:error:
extractRGBAfPixelsFromImage:fromROI:
faceBalanceFromFaceImage:forFaceRect:
faceBalanceKernels
faceBalanceResultFromFaceObservations:request:error:
faceBoundingBoxesKey
faceI
faceIKey
faceJunkinessIndex
faceLocalConfidence
faceObservationCache
faceObservationsData
faceOrientationIndex
facePositionAcceptable
facePositionAcceptable:imageAspect:
faceQ
faceQKey
faceRectFromNormalizedFaceRet:forImageExtent:scaleX:scaleY:
faceRegions
faceRequestWithRequest:
faceSize
faceStrength
faceWarmth
faceWarmthKey
faces
factCandidateForHorizon
factCandidateForPerspective
factCandidateForReframe
factCandidateForStill
factCandidateForVideo
failureError:object:
falloffKey
falseColorHDR
falseColorHDRKey
fastInfillImage:matte:
fileExistsAtPath:
fileType
fileURLWithPath:
fillSourceTexture:intoDestinationTexture:withCommandBuffer:
filter
filterLumaKernel
filterName
filterNameForEffectName:
filterWithName:withInputParameters:
finalize
finalizeTrack
finalizerError
firstEnabledVideoTrackInAsset:error:
firstObject
flattenedBackgroundForDebugPreview
flattenedForegroundForDebugPreview
flavor
flavorKey
floatForKey:
floatValue
floatValueForKey:defaultValue:clearIfNotDefault:
focusDetection
focusRectDictionaryFromMetadata:
focusRectDictionaryFromRect:
focusRectangle
focusedDisparity
force
forceGlassesMatteOff
forceSpillMatteOff
foregroundBuffer
foregroundColors
foregroundFilters
foregroundForImage:matte:
foregroundLuminance
format
formatDescriptions
formatForInputAtIndex:
formatIdentifier
formatVersion
formatVersionForAdjustment:identifier:
frameDuration
frameNearestTime:
frameRect
framedRectImageWithCGRect:color:borderWidth:
freeAllResources:
freeResources
fullSizeGeometry
fusionKernel
gHDRtoPPKernel
gainMapParametersFromRawProperties:
gatingResultForSegmentationScores:
generateLayerStackForItem:style:layout:options:completion:
generateLayoutForLayoutConfiguration:imageSize:regions:parallaxClassification:context:matte:layoutScore:cropScore:clockOverlapAcceptable:
genericConfiguration
genericLandscapeSceneLabel
genericRGBLinearColorSpace
geometry
geometryBasedAdjustmentIdentifiers
getCropRectThatCompletelyContainsMasterImageForPitch:yaw:roll:
getMTLTextureFromPixelBuffer:device:
getMap
getMinMaxSimulatedApertureFrom:minValue:maxValue:version:
getNonNormalizedSettings:
getRectForPoint:colorBuffer:
getResourceValue:forKey:error:
getSizeOfAllFaces:
getTagWithPath:error:
getValue:
glassesMatteAllowed
glassesMatteAllowedKey
globalMetadata
globalSession
globalSettings
gradeForFact:
grain
grainInputSeedFromFrameTime
grainKey
grainSchema
grayI
grayIKey
grayQ
grayQKey
grayStrength
grayWarmth
grayWarmthKey
grayY
grayYKey
green
greenValue
gridSizeForThreadGroupSize:imageSize:
groundedScore
groundedScoreForSegmentationMatte:context:
groupSizeForImageSize:pipelineState:
guideExtent
guideImage
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handlePIGlobalSettings:
hasAutoKeyInSchema
hasColorParameter
hasCorrections
hasInputKey:
hasPerformedAction:
hasPrefix:
hasStaticTime
hash
height
heightKey
highKeyProperties
highKeyTone
highResFusionAdjustmentController
highResFusionAdjustmentControllerCreatingIfNecessary:
highResFusionSchema
histogram
histogramCalculationColorSpace
histogramForSegmentationMatte:
histogramForSegmentationMatteImage:
histogramOptimizationFilter
homography
homographyAtTime:
homographyKernel
hueAngleFrom:
hueArrayImage:
hueChromaColorWashDuoFixedKernel
hueChromaColorWashDuoKernel
hueChromaColorWashDuoVariableKernel
hueChromaColorWashKernel
hueChromaFixedColorWashKernel
hueChromaImage
hueChromaKernels
hueChromaVariableColorWashKernel
hueKey
hueSatLumTable
hwModelID
identifier
image
imageBufferFromData:error:
imageBufferWithSize:format:fromPool:
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
imageByApplyingGaussianBlurWithSigma:
imageByApplyingTransform:
imageByApplyingTransform:highQualityDownsample:
imageByCachingImage:format:colorSpace:key:
imageByClampingToExtent
imageByColorMatchingColorSpaceToWorkingSpace:
imageByColorMatchingWorkingSpaceToColorSpace:
imageByCompositingOverImage:
imageByCroppingToRect:
imageByPremultiplyingAlpha
imageByUnpremultiplyingAlpha
imageExportFormat
imageExportFormatForURL:
imageFileURL
imageHistogram
imageLayer:frame:zPosition:identifier:
imageOrientation
imageProperties:
imagePropertiesRequestWithComposition:
imageRect
imageRenderRequestWithComposition:fillInSize:wideGamut:
imageRenderRequestWithComposition:fitInSize:wideGamut:
imageSize
imageSourceWithCIImage:orientation:
imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:
imageSourceWithURL:type:useEmbeddedPreview:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
imageWithBitmapData:bytesPerRow:size:format:options:
imageWithCGImage:
imageWithCGImage:options:
imageWithCVPixelBuffer:
imageWithColor:extent:
imageWithData:
imageWithNUImageBuffer:
inUse
inactiveFilter
inactiveFrame
inactiveRecipeIdentifier
inactiveRect
inactiveStrategy
includeCinematicVideoTracks
increaseBitRateIfNecessary
indexOfColor:
indexOfObject:
indexOfObject:inSortedRange:options:usingComparator:
indexOfObjectPassingTest:
indexesOfShallowDepthOfFieldObservations
infillRequest
infilledImage
inflatePersonFaceRect:
infoDictionary
init
initFromMinAperture:maxAperture:aperture:portraitStrength:SDOFRenderingVersion:depthVersionInfo:
initWithAVAsset:
initWithAcceptableRect:preferredRect:faces:pets:
initWithAdjustment:
initWithAffineTransform:
initWithAnalysisData:
initWithArchiveURL:
initWithArray:
initWithAsset:
initWithAutoLoopExportRequest:
initWithBackgroundColor:clockColor:colorSuggestions:
initWithBase64EncodedString:options:
initWithBaseURL:
initWithBinCount:range:
initWithBitmapData:width:height:bytesPerRow:format:
initWithBuffer:colorSpace:validRegion:
initWithBytes:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithCGColorSpace:
initWithCIContext:matte:parallaxClassification:initialRect:imageSize:effectiveAcceptableRect:effectivePreferredRect:layoutConfiguration:
initWithCIImage:options:
initWithCIImage:orientation:
initWithCVPixelBuffer:
initWithCVPixelBuffer:options:
initWithCapacity:
initWithClockAreaLuminance:
initWithClockColor:colorSuggestions:
initWithCoder:
initWithColor:clockColor:suggestions:
initWithColorAnalysis:
initWithCommandQueue:
initWithCompletedTrack:
initWithComposition:
initWithComposition:dataExtractor:options:
initWithComposition:destinationURL:
initWithComposition:location:touchDiameter:
initWithComposition:responseQueue:
initWithComposition:stabilizedVideoURL:longExposureDestinationURL:maskDestinationURL:destinationUTI:
initWithComposition:startTime:pointToTrack:
initWithComposition:tag:responseQueue:
initWithComposition:time:sampleRect:
initWithComposition:useSushi:
initWithContentsOfFile:
initWithContentsOfURL:options:error:
initWithCount:times:values:
initWithData:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithDescriptor:
initWithDevice:colorSize:disparitySize:quality:debugMode:
initWithDevice:version:colorSize:disparitySize:
initWithDictionary:
initWithDictionaryRepresentation:
initWithDisparityValue:
initWithDisposition:composition:
initWithDomain:code:userInfo:
initWithError:
initWithExtent:renderScale:orientation:
initWithFileURL:
initWithFilterName:parameters:
initWithFilterName:settings:inputs:
initWithHue:tone:
initWithIdentifier:
initWithIdentifier:recipe:
initWithImage:format:colorSpace:
initWithImageProvider:width:height:format:colorSpace:options:
initWithImageSize:deviceResolution:parallaxPadding:visibleFrame:inactiveFrame:timeFrame:clockLayerOrder:clockIntersection:debugLayouts:
initWithImageSourceDefinition:videoSourceDefinition:
initWithIndexesInRange:
initWithInput:
initWithInput:assetURL:cinematographyState:monochrome:
initWithInput:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:
initWithInput:scale:
initWithInput:timeRange:crossfadeDuration:startTime:
initWithKeyframeArray:
initWithKeyframes:stabCropRect:analysisType:rawHomographies:
initWithKeyframes:stabCropRect:input:
initWithKind:parameters:colorSuggestions:
initWithLayerStack:
initWithLayers:size:layout:depthEnabled:parallaxDisabled:clockAreaLuminance:
initWithLevel:
initWithLuma:hue:chroma:
initWithMajor:minor:subMinor:
initWithMajor:minor:subMinor:platform:
initWithMasterImageRect:stitchedImageRect:
initWithMasterImageSize:
initWithMasterImageSize:stitchedImageSize:
initWithMetadataGroup:majorVersion:minorVersion:error:
initWithMetalDevice:options:
initWithMin:max:manualMin:manualMax:depthMin:depthMax:
initWithMode:
initWithMutableBuffer:colorSpace:validRegion:
initWithName:
initWithName:responseQueue:
initWithNode:context:
initWithNumber:unit:
initWithParallaxAsset:
initWithParallaxClassification:initialRect:imageSize:effectiveAcceptableRect:effectivePreferredRect:layoutConfiguration:
initWithParallaxClockLayoutRequest:
initWithParallaxColorAnalysisRequest:
initWithParallaxInfillRequest:
initWithParallaxLayerStackRequest:
initWithParallaxLayoutInactiveFrameRequest:
initWithParallaxLayoutRequest:
initWithParameters:foregroundFilters:backgroundFilters:matteFilters:
initWithPipelineState:
initWithPixelBuffer:
initWithPrimaryColor:secondaryColor:
initWithPrimaryColor:secondaryColor:clockColor:colorSuggestions:
initWithPrimaryColors:secondaryColors:
initWithPrimaryColors:secondaryColors:suggestionIndices:
initWithProperties:
initWithRadius:softness:opacity:clipRect:pressureMode:
initWithRect:
initWithRed:green:blue:
initWithRed:green:blue:alpha:
initWithRed:green:blue:alpha:colorSpace:
initWithRequest:
initWithRequest:dataExtractor:options:
initWithRequest:isRAW:
initWithRequest:options:
initWithScript:block:
initWithSegmentationItem:
initWithSegmentationItem:parallaxAsset:
initWithSettings:inputs:
initWithSize:format:
initWithSize:format:rowBytes:bytes:
initWithSize:format:rowBytes:mutableBytes:
initWithSize:renderer:jobNumber:
initWithSourceDefinitions:
initWithStackName:filters:
initWithTargetPixelCount:
initWithTargetPixelSize:
initWithTargetScale:effectiveScale:sampleMode:input:
initWithTargetSize:
initWithTargetedCVPixelBuffer:options:
initWithTime:homography:
initWithTime:value:
initWithTrack:outputSettings:
initWithType:source:identifier:confidence:
initWithURL:
initWithURL:UTI:
initWithVariableName:
initWithVideoExportRequest:
initWithVisibleRect:inactiveRect:zoomStrategy:overlapStrategy:parallaxStrategy:inactiveStrategy:
initWithVisibleRect:inactiveRect:zoomStrategy:overlapStrategy:parallaxStrategy:inactiveStrategy:cropScore:layoutScore:timeBottomOverlap:timeTopOverlap:unsafeAreaOverlap:uninflatedUnsafeAreaOverlap:
initWithX:Y:
initWithX:Y:unit:
initWithX:y:editable:
initialize
inpaintingInfillImage:matte:
input
inputAlgorithm
inputAlignmentExtent
inputAlignmentTransform
inputAmount
inputAperture
inputBackgroundImage
inputBlack
inputBlackDstBlue
inputBlackDstGreen
inputBlackDstRGB
inputBlackDstRed
inputBlackKey
inputBlackSrcBlue
inputBlackSrcGreen
inputBlackSrcRGB
inputBlackSrcRed
inputBlendMode
inputBlurImage
inputBoost
inputBorder
inputBrightnessKey
inputCameraModel
inputCast
inputCastKey
inputChromaMax
inputChromaMin
inputColor
inputColorKey
inputColorPixelBuffer
inputContrast
inputContrastKey
inputCorrectionInfo
inputCorrectionInfoKey
inputCorrections
inputCutoff
inputDecoderVersion
inputDepthMap
inputDestinationImage
inputDisparityImage
inputDisparityPixelBuffer
inputExposure
inputExposureKey
inputFocusedDisparity
inputForKey:
inputForPath:error:
inputForegroundImage
inputGlobalRenderingMetadata
inputGrain
inputGrainKey
inputHasFace
inputHighlightColor
inputHighlightsKey
inputHilightDstBlue
inputHilightDstGreen
inputHilightDstRGB
inputHilightDstRed
inputHilightSrcBlue
inputHilightSrcGreen
inputHilightSrcRGB
inputHilightSrcRed
inputHue
inputHueIsNormalized
inputHueKey
inputHueRange
inputHueTarget
inputISO
inputImage
inputIntensity
inputIsHDR
inputIsRaw
inputKeys
inputLight
inputLightDefault
inputLightKey
inputLightMap
inputLightMapHeight
inputLightMapImage
inputLightMapWidth
inputLocalLightKey
inputLumaRange
inputMaskImage
inputMidDstGreen
inputMidDstRGB
inputMidDstRed
inputMidSrcGreen
inputMidSrcRGB
inputMidSrcRed
inputMode
inputNeutralGamma
inputNeutralGammaKey
inputNeutralXYFromRGB:
inputNormalization
inputOrigI
inputOrigQ
inputParams
inputPoints
inputPointsB
inputPointsG
inputPointsL
inputPointsR
inputRAWGamutMapMaxKey
inputRadius
inputRawHighlights
inputRawHighlightsKey
inputRenderDebugMode
inputRenderQuality
inputRenderScale
inputSaturationKey
inputScale
inputScaleFactor
inputSeed
inputSeedKey
inputShadowColor
inputShadowDstBlue
inputShadowDstGreen
inputShadowDstRGB
inputShadowDstRed
inputShadowSrcBlue
inputShadowSrcGreen
inputShadowSrcRGB
inputShadowSrcRed
inputShadows
inputSize
inputSmartShadows
inputSpots
inputStreamWithURL:
inputStrength
inputStrengthKey
inputTargetImage
inputTemperature
inputThreshold
inputTimedRenderingMetadata
inputTint
inputToCropFilter
inputTone
inputToneKey
inputVersion
inputVibrancy
inputVideoProperties
inputWarmTemp
inputWarmTint
inputWarmth
inputWeights
inputWhiteDstBlue
inputWhiteDstGreen
inputWhiteDstRGB
inputWhiteDstRed
inputWhiteSrcBlue
inputWhiteSrcGreen
inputWhiteSrcRGB
inputWhiteSrcRed
inputs
insertObject:atIndex:
insertTimeRange:ofTrack:atTime:error:
instructions
intValue
integerForKey:
integerValue
integralCropRect:
intensity
intensityKey
intermediateWithInactiveStrategy:intermediate:
intermediateWithOverlapStrategy:intermediate:
intermediateWithZoomStrategy:intermediate:
internalComposition
interpolateFromStart:toEnd:progress:
interpolation
invalidError:object:
inverseAggregatedCurveValueAt:
inverseHLGLumaBlendingKernel
invertImage:
invertedSet
iosCropToolFilter
iptColorWashDuoFixedKernel
iptColorWashDuoKernel
iptColorWashDuoVariableKernel
iptFromLinearInto:fromRed:green:blue:
iptHueAngleFromRed:green:blue:
is3DEffect:
isAVAssetDolbyProfile5:error:
isAVAssetEditable:reason:
isAnalysisAvailable
isAnimal
isAppleProRaw
isAssetUnsupportedLegacyPortraitVideo:
isAuto
isAvailable
isCIFilterAvailable:propertyName:
isCanceled
isCandidateForHorizon
isCandidateForPerspective
isCandidateForReframe
isComplete
isCool
isCropConstrained
isCropIdentityForImageSize:
isDefaultWarmth:
isDepthDataFiltered
isDepthEnabled
isEditable
isEnabled
isEqual:
isEqual:forKeys:
isEqual:forKeys:comparisonBlock:
isEqual:forKeys:visualChangesOnly:
isEqual:visualChangesOnly:
isEqualToAdjustmentController:
isEqualToAdjustmentVersion:
isEqualToDate:
isEqualToDictionary:
isEqualToLayoutConfiguration:
isEqualToNumber:
isEqualToParallaxStyleDefinition:
isEqualToParallaxStyleFilterDefinition:
isEqualToParallaxStyleFilterStackDefinition:
isEqualToParallaxStyleParameter:
isEqualToParallaxStyleRecipe:
isEqualToPixelFormat:
isEqualToString:
isExportable
isFrontFacingCameraImage:pixelSize:
isFusedOvercapture
isHDR
isHDRComposition:
isInCloud
isKindOfClass:
isMLInpaintingAvailable
isMemberOfClass:
isMetalDeviceSupported:
isObject
isOriginalCrop
isPerspectiveZoomEnabled
isPlayable
isPortraitEffect:
isPortraitStageEffect:
isProxyOnly
isReadable
isReadableFileAtPath:
isReadyForMoreData
isRenderVersionSupported:
isSegmented
isSegmentedStyle:
isSensorRawCapture
isSettingEqual:forKey:
isSourceAvailable:sourceSettings:
isStillImageDisparity:
isSubclassOfClass:
isUnifiedBracketingHDRCapture
isValidSegmentationScoreForDepth:
isWarm
items
itur2100HLGColorSpace
jobNumber
jsContext
kernel
kernelBlackAndWhite
kernelFB0
kernelFB3
kernelNamed:
kernelWithFunctionName:fromMetalLibraryData:error:
kernelWithString:
kernelsDictionaryWithString:
kernelsWithString:
keyFrameTime
keyframeInArray:closestToTime:
keyframeSequence
keyframes
keyframesFromDictionaryRepresentations:
keyframesKey
kind
knownFormatsVersionsMap
label
labels
landmarks
lastIndex
lastObject
lastPathComponent
lastUseTime
latestVersion
layerForBuffer:image:zPosition:identifier:
layerStack
layerStackByUpdatingClockAreaLuminance:
layerStackByUpdatingDepthEnabled:
layerStackByUpdatingLayers:
layerStackByUpdatingParallaxDisabled:
layerStackMode
layerStackOptions
layerStackRequest
layers
layout
layoutByUpdatingClockIntersection:
layoutByUpdatingClockLayerOrder:
layoutByUpdatingImageSize:
layoutByUpdatingInactiveFrame:
layoutByUpdatingNormalizedVisibleFrame:
layoutByUpdatingVisibleFrame:
layoutByUpgradingToConfiguration:
layoutConfiguration
layoutConfigurationFromDictionary:error:
layoutGatingDecisionForSegmentationScores:
layoutInactiveFrameRequest
layoutRegions
layoutRequest
layoutScore
layoutWithDictionary:
length
levelsSchema
lightMapImage
linearGrayColorSpace
linearWideGamutColorSpace
livePhotoKeyFrameAdjustmentController
livePhotoKeyFrameAdjustmentControllerCreatingIfNecessary:
livePhotoKeyFrameMetadataFromNode:time:error:
livePhotoKeyFrameSchema
livePhotoSourceWithPhotoSource:videoSource:
loadContentsFromDictionary:hasMatte:hasBackground:error:
loadFilterWithName:
loadFromArchiveURL:error:
loadFromContentsDictionary:error:
loadFromURL:
loadFromURL:error:
loadFusionTuningParameters
loadLayerStackFromURL:options:error:
loadLayerStackFromWallpaperURL:options:error:
loadPaletteFromURL:error:
loadPaletteWithName:
loadParallaxResource:options:resultHandler:
loadPetsRegions:
loadSegmentationDataFromURL:error:
loadSegmentationItemForAsset:options:completion:
loadSegmentationItemFromURL:error:
loadSegmentationItemFromWallpaperURL:error:
loadSegmentationItemWithCompletion:
loadWithAsset:changesDictionary:completion:
loadingHandler
loadingHandlerQueue
loadingState
localConfidenceImage:
localConfidenceScore
localConfidenceScoreForLocalConfidenceImage:extent:context:
localLightData
localLightHDRStatisticsNoProxy
localLightStatisticsNoProxy
locallySupportedFormatVersions
logger
longExposureFusionKernels
longLongValue
loopTimeRange
loopTimeRangeDurationTimescaleKey
loopTimeRangeDurationValueKey
loopTimeRangeStartTimescaleKey
loopTimeRangeStartValueKey
lowKeyTone
luma
luminance
luminanceKey
luminanceNoiseAmplitude
luminanceThresholds
luminanceValue
luminanceWeights
magentaColor
mainBundle
mainDevice
majorVersion
manualMax
manualMin
manualSegmentationGatingDecisionForSegmentationScores:
mapForSerialization
markActionAsPerformed:
markAsFinished
matteFilters
matteHistogramIndicatesSubjectDetected:
matteImage
matteImageBuffer
mattePureBackground
mattePureForeground
maxAutoAngle
maxAutoPitch
maxAutoStraighten
maxAutoYaw
maxDominantColors
maxFaceSize
maxSDOFRenderingVersionSupported
maximumApertureFocalRatio
maximumValue
media
mediaComponentType
mediaType
mediaTypeForComposition:
median
medianColor
metadata
metadataClockOverlapAcceptable
metadataConverter
metadataGroup
metadataItem
metadataItemsFromArray:filteredByIdentifier:
metadataItemsWithMetadataType:value:error:
metadataProcessor
metalCommandBuffer
metalDevice
metalKernelWithFunctionName:error:
metalLibraryData
metalRenderer
metalTexture
meteorGainMapExposureCompensationMode
minAutoStraighten
minimumAngleCorrection
minimumApertureFocalRatio
minimumConfidence
minimumPitchCorrection
minimumPitchCorrectionArea
minimumValue
minimumYawCorrection
minimumYawCorrectionArea
minorVersion
mipmapLevelCount
mismatchError:object:
missingError:object:
modalityAnalysisWithLimit:sampleMode:
mode
modeValue
modifyAdjustmentWithKey:modificationBlock:
morphologyMaximumFilter
morphologyMinimumFilter
motionBlurVectorFromMetadata:
multiplyCompositingFilter
mutableBytes
mutableBytesAtPoint:
mutableCopy
muteSchema
nFaces
name
nccKernel
ndcMetadataTransform
networkAccessAllowed
neutralKey
neutralTone
newAdjustmentWithIdentifier:
newAdjustmentWithName:
newCGImageFromBufferImage:
newCIImageFromBufferImage:
newComposition
newCompositionControllerWithComposition:
newHLGPixelBufferFromSDRImage:
newImageRenderClientWithName:
newLinearWideGamutColorSpace
newPhotosPipeline:
newPhotosPipelineAtSourceURL:error:
newPixelBufferOfSize:format:
newRenderJob
newRenderPipelineStateForEvaluationMode:
newRenderedPixelBufferFromImage:hasAlpha:error:
newStorageWithSize:format:
newTextureViewWithPixelFormat:textureType:levels:slices:
newTextureWithDescriptor:
newWatchInfillFromImage:mask:
nextFrame
nextInputFrame
nextTimedMetadataGroup
noCropFilter
noGeometryFilter
noMuteFilter
noOpRemovalFunctions
noOrientationFilter
noRedEyeFilter
noTrimFilter
node
nodeByApplyingFilterWithName:useHDRFilter:settingsAndInputs:
nodeByReplayingAgainstCache:error:
nodeByReplayingAgainstCache:pipelineState:error:
nodeFromCache:cache:
noiseReductionAdjustmentController
noiseReductionAdjustmentControllerCreatingIfNecessary:
noiseReductionSchema
nominalFrameRate
nonLocalizedFailureReason
nonVisualAdjustmentTypes
normalizeHueChromaImage:
normalizedClipRect
normalizedImagePoint
normalizedPoints
normalizedVisibleFrame
nose
nu_digest
nu_evaluateWithPipelineState:error:
nu_updateDigest:
nu_waitUntilCompletedAndReturnError:
null
numberValue
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
objectFromData:withMajorVersion:minorVersion:
objectsAtIndexes:
observation
observations
offsetBlack
offsetBlackKey
offsetBrightness
offsetBrightnessKey
offsetCast
offsetCastKey
offsetContrast
offsetContrastKey
offsetExposure
offsetExposureKey
offsetHighlights
offsetHighlightsKey
offsetLocalLight
offsetLocalLightKey
offsetSaturation
offsetSaturationKey
offsetShadows
offsetShadowsKey
oneShotPortraitV2ExportFilter
oneToOneScalePolicy
open
openMask:withRadius:
optimizeForSharing
orientation
orientationAdjustmentControllerCreatingIfNecessary:
orientationAsMetaDataFilter
orientationSchema
orientedNode:withOrientation:
originalCleanAperture
originalCrop
originalLayout
originalSize
originalStyle
outputBackgroundImage
outputColorSpace
outputCropRect
outputExposureKey
outputForegroundImage
outputFormat
outputGeometry
outputImage
outputImage:
outputImageFB0
outputImageFB3
outputImageGeometry:
outputIsOpaque
outputMatteImage
outputNormalization
outputSettings
outputStreamWithURL:append:
outputTimedMetadataSampleWithIdentifier:atTime:error:
outputVideo
outputVideo:
outputVideoComposition:
overcaptureImageProperties:
overcaptureRectForAutoCrop:overcaptureVideoComplementSize:primarySize:CGRect:
overcaptureRectForStitchedOvercaptureSize:overcaptureVideoComplementSize:primarySize:autoLoopStabilizedCropRect:
overcaptureSource
overcaptureSourceFilter
overcaptureStatistics
overcaptureStatisticsKey
overwriteTrackingMetadataWithPlist:
pairingIdentifier
paletteColorForColor:
parallaxDisabled
parallaxInactiveFrame
parallaxLayoutConfigurationOverride
parallaxPaddingPct
parallaxScore
parallaxStrategy
parallaxStyleAvoidColorWashBrownOverride
parallaxStyleKeyLevelOverride
parallaxVisibleFrame
parameters
passesBuildingCheck:
passesConfidenceCheck:error:
passesFaceCheck:
passesImagePropertiesCheck:
passesMinimumCorrectionCheck:error:
pasteAdjustment:forMediaType:
pasteKeysForMediaType:
path
pathExtension
percentile:
performApertureRedeyeOnImage:useHDRFilter:redEyeAdjustment:
performHorizonCorrectionWithCompletion:
performLongExposureFusionForComposition:longExposureImage:useHDRFilter:error:
performNextActionWithCompletion:
performPerspectiveCorrectionWithCompletion:
performRedeyeOnImage:useHDRFilter:redEyeAdjustment:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performedActions
perspectiveErrorFromCoreImage:
perspectiveStraightenWithoutCropFilter
perspectiveTransformWithPitch:yaw:roll:imageRect:
petRegions
petsRegions
photoFeatureFlags:error:
photoProcessingFlagsFromProperties:error:
photosAutoEnhanceFiltersForImage:
photosCompositionSchema
photosSchema
pi_createColorCubeDataForFilters:dimension:colorSpace:
pi_grayColorResultValue
pi_imageByApplyingStabilizationWatermark
pi_valueWithGrayColorResult:
pipelineFiltersForCropping
pipelineFiltersForOriginalGeometry
pipelineFiltersForRAWShowingOriginalWithGeometry
pipelineFiltersForShowingOriginal
pipelineFiltersForShowingOriginalWithGeometry
pipelineStateForFunctionWithName:device:error:
pitch
pitchAngleDegrees
pitchKey
pitchRadians
pixelBasedIntermediateWithOverlapStrategy:intermediate:translationY:
pixelBuffer
pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:
pixelEffectiveAcceptable
pixelFormat
platedFoodSceneLabel
platform
pointCount
pointValue
popDebugGroup
portraitAdjustmentController
portraitAdjustmentControllerCreatingIfNecessary:
portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:
portraitEffectSchema
portraitInfo
portraitInfoDictionaryFromCameraMetadata:
portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
portraitLightingEffectStrength
portraitMajorVersion
portraitMinorVersion
portraitStrength
portraitVideo:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:error:
portraitVideoAdjustmentController
portraitVideoAdjustmentControllerCreatingIfNecessary:
portraitVideoDebugDetectedObjects:source:cinematographyState:monochrome:error:
portraitVideoSchema
postGeometryFilter
preGeometryFilter
predicateWithFormat:
preferredCropRect
pregateRulesSystemWithConstants:
preheatEditDependencies
prepare:
prepareAuxiliaryImagesFetchProperties:options:completion:
prepareForCIFilterWithFaces:cropRect:
prepareForPerformingRequests:error:
prepareImageExportRequest:options:completion:
prepareImagesForItem:renderer:layout:style:inputImage:matteImage:infillImage:foregroundImage:backgroundImage:
prepareNode
prepareNodeWithPipelineState:error:
prepareToRenderWithMetadata:
preserveSourceColorSpace
prewarmRendererForDevice:colorSize:disparitySize:quality:debugMode:globalRenderingMetadata:
primaryColor
primaryColors
primaryImageProperties:
primarySourceFilter
primaryURL
priority
priorityWithLevel:
processHorizonResult:
processPerspectiveResult:
processWithInputs:arguments:output:error:
properties
propertyListWithData:options:format:error:
propertyListWithStream:options:format:error:
proxyImage
proxyOnly
proxyScalePolicy
pxlMetadataTransform
radius
radiusKey
rangeMax
rangeMin
rangeOfCharacterFromSet:
rangeOfString:options:
ranges
rasterizeBrushStroke:atPoint:toBuffer:
rate
rawAdjustmentController
rawAdjustmentControllerCreatingIfNecessary:
rawAdjustmentWithRawImageProperties:
rawCameraSpaceProperties
rawFaceBalanceFilter
rawNoiseReductionAdjustmentController
rawNoiseReductionAdjustmentControllerCreatingIfNecessary:
rawNoiseReductionSchema
rawProperties
rawSchema
rawSourceFilterIncludingOrientation
rawState
rawToneCurveProperties
readBufferFromImage:withRGBAfBufferBlock:
readBufferInRegion:block:
readBufferRegion:withBlock:
readImageBufferFromURL:error:
readMetadataType:fromCGImageProperties:value:error:
rec709ColorSpace
recipe
recipeForIdentifier:
recipeIdentifier
recipeKey
rect
rectValue
recycleHLGPixelBuffer:
redEyeAdjustmentController
redEyeAdjustmentControllerCreatingIfNecessary:
redEyeSchema
redEyeSpotsWithCorrectionInfo:
redValue
reframeCropAdjustment
reframeVideoAdjustment
region
regionsFromDictionary:error:
registerPhotosSchema
registerRenderPipeline:forIdentifier:
registerSchemas:error:
registeredPhotosSchemaIdentifier
registrationRequest
releaseCachedResources
reloadSegmentationItemFromWallpaperURL:asset:completion:
remapPortraitV2Strength:portraitEffectKind:
removeAdjustmentWithKey:
removeAllObjects
removeAssetIdentifierFromMetadataArray:
removeItemAtURL:error:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectIdenticalTo:
render:error:
render:toBitmap:rowBytes:bounds:format:colorSpace:
renderCompanionResources
renderContext
renderImage:into:colorSpace:roi:imageSize:alpha:error:
renderImage:into:colorSpace:roi:imageSize:error:
renderImage:rect:toDestination:atPoint:error:
renderImagesWithRenderer:
renderInfo
renderNode
renderNodeFromSource:settings:error:
renderOnDevice:colorSize:disparitySize:quality:debugMode:globalRenderingMetadata:usingBlock:
renderPipelineForIdentifier:
renderPreviewLayerStackFromWallpaperURL:styleCategory:completion:
renderPriorityForResourcePriority:
renderQuality
renderScale
renderSize
renderState:matchesMetadata:
renderTask
renderTime
renderer:
renderingMetadataIdentifier
renderingVersion
renderingVersionAtCapture
renderingVersionFromAsset:error:
replaceAdjustment:withKey:
replaceObjectAtIndex:withObject:
requestLayout
requestVisionCleanUp
requireHardwareEncoder
requiresAudioMix
requiresVideoComposition
reset
resetAndEvaluateWithInitialState:
resetImageProperties:preserveRegions:
resetTag:input:error:
resolvedNodeWithCachedInputs:settings:pipelineState:error:
resolvedParameters
resolvedSourceDefinition
resource
resourceUnavailableError:object:
respondsToSelector:
responseQueue
result
resultLayersWithRenderer:
retain
retainCount
retouchSchema
retractFact:
returnStorage:
rgbColorWashDuoFixedKernel
rgbColorWashDuoKernel
rgbColorWashDuoVariableKernel
rightEye
roiForInput:arguments:outputRect:
roll
rollAngleDegrees
rowAverageFilter
rowBytes
rowElements
ruleWithBlockPredicate:action:
ruleWithPredicate:action:
ruleWithPredicate:assertingFact:grade:
ruleWithPredicate:retractingFact:grade:
sRGBColorSpace
sRGBLinearColorSpace
salientObjects
sampleAtTime:
sampleCount
sampleMode
sampleRect
sampleTime
sampledDisparityValue
samplerWithImage:
samplerWithImage:options:
samplesPerPass
saveAssetResourceToURL:error:
saveLayerStack:toURL:options:error:
saveSegmentationDataToURL:error:
saveSegmentationItem:layerStack:toWallpaperURL:error:
saveSegmentationItem:layerStackOptions:configuration:style:layout:toWallpaperURL:completion:
saveSegmentationItem:toURL:error:
saveToArchiveURL:error:
saveToURL:error:
scale
scaleForImageSize:
scaleHueKernel
scaleKey
scaleMultiplyOfScalar:
scaleNode:scale:error:
scalePolicy
scaleRect:scaleFactor:scaleCenter:
scaledExtent
scaledSize
scaledVector:
scene
sceneConfidenceKey
sceneLabelKey
schema
schemaForKey:
schemaWithIdentifier:
scoreAdjustmentWithUnscoredIntermediate:unsafeAreaOverlap:timeBottomOverlap:timeTopOverlap:
scoreIntermediate:
scores
screenSize
secondaryColor
segmentationBackground
segmentationClassification
segmentationCompositionForAssetResource:
segmentationCompositionForImageURL:fileUTI:orientation:proxyImage:
segmentationCompositionForProxyImage:orientation:
segmentationConfidenceMap
segmentationConfidenceMapImage
segmentationDataURL
segmentationDebugPreviewDisableClock
segmentationDebugPreviewHighQuality
segmentationDebugRoundTripProxyImage
segmentationDebugTintLayers
segmentationDisableCaching
segmentationDisabled
segmentationInfillAlgorithm
segmentationItem
segmentationLoaderForAsset:
segmentationManualGatingLenience
segmentationMatte
segmentationMatteImage
segmentationResourceURL
segmentationScore
segmentationScoreRanges
segmentationSourceForImageURL:fileUTI:orientation:proxyImage:
selectiveColorKernels
selectiveColorSchema
self
semanticEnhanceAdjustmentController
semanticEnhanceAdjustmentControllerCreatingIfNecessary:
sensorID
serializeComposition:versionInfo:error:
serializeComposition:versionInfo:serializerMetadata:error:
serializeDictionary:error:
serializeRecipe:
setAlignment:
setAllowSpillMatteOnOlderPortraitV2Captures:
setAllowedAnalysisTypes:
setAllowedCropFraction:
setAlphaCount:
setAlphaMode:
setAnalysisType:
setAnalyzeBackground:
setAngle:
setAngleRadians:
setAngleSeedDegreesCCW:
setAperture:
setApplyImageOrientationAsMetadata:
setApplyOrientationAsMetadata:
setApplyVideoOrientationAsMetadata:
setAssetIdentifier:
setAutoStraightenDominantAngleDiffThreshold:
setAutoStraightenVerticalAngleThreshold:
setAuxImages:
setAuxiliaryImageType:
setAuxiliaryImages:
setBackgroundBuffer:
setBackgroundColors:
setBackgroundImage:
setBackgroundLuminance:
setBaseURL:
setBoundingBoxesFromObservations:orientation:
setBounds:
setBypassOutputSettingsIfNoComposition:
setCache:
setCacheURL:
setCanHandleAdjustmentData:
setCanPropagateOriginalAuxiliaryData:
setCandidacy:
setChangeDelegate:
setChromaThreshold:
setCinematicAllowRGB10Packed:
setCinematicAllowYUVSourceInput:
setCinematographyScript:
setCinematographyState:
setClassification:
setCleanAperture:
setClientRequestedStop:
setClockColor:
setClockIntersection:
setClockLayerOrder:
setClockOverlapAcceptable:
setColor:
setColorAnalysis:
setColorPrimaries:
setColorSpace:
setColorSuggestions:
setColorType:
setColors:
setCompanionImageData:
setCompanionVideoURL:
setCompletedTrack:
setCompletionBlock:
setCompressionQuality:
setComputeDigest:
setComputePipelineState:
setConfidenceMapScore:
setConfidencePureBackground:
setConfidencePureForeground:
setConstants:
setConstraintHeight:
setConstraintWidth:
setConversionGain:
setCount:
setCountLimit:
setCropFraction:
setCropRect:
setCropScore:
setCrossfadeDuration:
setData:
setDataExtractor:
setDebugColorAnalysisBuffer:
setDebugColorAnalysisImage:
setDebugConfidenceMapBuffer:
setDebugConfidenceMapImage:
setDebugFilesEnabled:
setDebugFilesPrefix:
setDebugImageCollector:
setDebugInfillBuffer:
setDebugInfillImage:
setDebugInputBuffer:
setDebugInputImage:
setDebugIntermediateLayoutBuffers:
setDebugIntermediateLayoutImages:
setDebugLayoutBuffer:
setDebugLayoutImage:
setDebugLineDetectionImage:
setDebugLocalConfidenceBuffer:
setDebugLocalConfidenceImage:
setDebugMatteBuffer:
setDebugMatteCropBuffer:
setDebugMatteCropImage:
setDebugMatteImage:
setDebugMode:
setDebugPreviewBuffer:
setDebugPreviewImage:
setDebugRendering:
setDefaultLayout:
setDefaults
setDepthInfo:
setDepthVersionInfo:
setDestinationColor:
setDestinationURL:
setDigest:
setDisableDownload:
setDisableIntermediateCaching:
setDisableOnFrontFacingCameraImages:
setDisableOnPanos:
setDisableRendering:
setDisableSegmentation:
setDisparityKeyframes:
setDominanceThreshold:
setDominantColors:
setDominantGrays:
setDominantHues:
setDouble:forKey:
setDownloadProgressHandler:
setEdgeBleed:
setEditConfiguration:
setEnableLogging:
setEnabled:
setEndTime:
setError:
setEstimatedCenterMotion:
setEstimatedMotionBlur:
setEvaluatedForMode:
setExpandedBounds:
setExtent:
setExtentPolicy:
setFaceBoundingBoxesFromObservations:orientation:
setFaceI:
setFaceLocalConfidence:
setFaceObservationCache:
setFacePositionAcceptable:
setFaceQ:
setFaceSize:
setFaceStrength:
setFaceWarmth:
setFalloff:
setFalseColorHDR:
setFileType:
setFileURL:
setFinalizerError:
setFlattenedBackgroundForDebugPreview:
setFlattenedForegroundForDebugPreview:
setFlavor:
setFocalLenIn35mmFilm:
setFocusDistance:
setFontName:
setFontSize:
setForce:
setForceGlassesMatteOff:
setForceSpillMatteOff:
setForegroundBuffer:
setForegroundColors:
setForegroundImage:
setForegroundLuminance:
setFormat:
setFormatIdentifier:
setFormatVersion:
setFrameDuration:
setFromAdjustment:
setGenericCompletionBlock:
setGeometry:
setGlassesMatteAllowed:
setGrain:
setGrayI:
setGrayQ:
setGrayStrength:
setGrayWarmth:
setGrayY:
setGroundedScore:
setGuideImage:
setHeight:
setHistogramCalculationColorSpace:
setHueChromaImage:
setI:
setIdentifier:
setImage:
setImageExportFormat:
setImageFileURL:
setImageHistogram:
setImageOrientation:
setImageProperties:
setImageRect:
setImageSize:
setImageVariation:properties:error:
setInUse:
setInactiveRect:
setIncreaseBitRateIfNecessary:
setInfillAlgorithm:
setInfilledImage:
setInputAlgorithm:
setInputAlignmentExtent:
setInputAlignmentTransform:
setInputAperture:
setInputBackgroundImage:
setInputBlack:
setInputBlackDstBlue:
setInputBlackDstGreen:
setInputBlackDstRGB:
setInputBlackDstRed:
setInputBlackSrcBlue:
setInputBlackSrcGreen:
setInputBlackSrcRGB:
setInputBlackSrcRed:
setInputBlendMode:
setInputBlurImage:
setInputBoost:
setInputBrightness:
setInputCameraModel:
setInputCast:
setInputChromaMax:
setInputChromaMin:
setInputColor:
setInputColorPixelBuffer:
setInputColorSpace:
setInputContrast:
setInputCorrectionInfo:
setInputCorrections:
setInputDecoderVersion:
setInputDepthMap:
setInputDestinationImage:
setInputDisparityImage:
setInputDisparityPixelBuffer:
setInputEdgeDetail:
setInputExposure:
setInputFocusedDisparity:
setInputForegroundImage:
setInputGlobalRenderingMetadata:
setInputGrain:
setInputGuideImage:
setInputHasFace:
setInputHighlightColor:
setInputHighlights:
setInputHilightDstBlue:
setInputHilightDstGreen:
setInputHilightDstRGB:
setInputHilightDstRed:
setInputHilightSrcBlue:
setInputHilightSrcGreen:
setInputHilightSrcRGB:
setInputHilightSrcRed:
setInputHue:
setInputHueIsNormalized:
setInputHueRange:
setInputHueTarget:
setInputISO:
setInputImage:
setInputIntensity:
setInputIsHDR:
setInputIsRaw:
setInputLight:
setInputLocalLight:
setInputLumaRange:
setInputLumaTarget:
setInputMaskImage:
setInputMatteImage:
setInputMidDstBlue:
setInputMidDstGreen:
setInputMidDstRGB:
setInputMidDstRed:
setInputMidSrcBlue:
setInputMidSrcGreen:
setInputMidSrcRGB:
setInputMidSrcRed:
setInputMode:
setInputNeutralGamma:
setInputNormalization:
setInputOrigI:
setInputOrigQ:
setInputParameters:
setInputPointsB:
setInputPointsG:
setInputPointsL:
setInputPointsR:
setInputRawHighlights:
setInputRenderDebugMode:
setInputRenderQuality:
setInputRenderScale:
setInputSaturation:
setInputScaleFactor:
setInputSeed:
setInputShadowColor:
setInputShadowDstBlue:
setInputShadowDstGreen:
setInputShadowDstRGB:
setInputShadowDstRed:
setInputShadowSrcBlue:
setInputShadowSrcGreen:
setInputShadowSrcRGB:
setInputShadowSrcRed:
setInputShadows:
setInputSize:
setInputStillImage:
setInputStrength:
setInputTableImage:
setInputTargetImage:
setInputTemperature:
setInputThreshold:
setInputTint:
setInputTone:
setInputVectorsForFilter:
setInputVersion:
setInputVibrancy:
setInputVideoProperties:
setInputVideoScale:
setInputWarmTemp:
setInputWarmTint:
setInputWeights:
setInputWhiteDstBlue:
setInputWhiteDstGreen:
setInputWhiteDstRGB:
setInputWhiteDstRed:
setInputWhiteSrcBlue:
setInputWhiteSrcGreen:
setInputWhiteSrcRGB:
setInputWhiteSrcRed:
setInstructions:
setInteger:forKey:
setIntensity:
setIsAuto:
setIsDepthEnabled:
setIsInCloud:
setIsPerspectiveZoomEnabled:
setJPEGCompressionQuality:
setKeyFrameTime:
setKeyframeSequence:
setKeyframes:
setKind:
setLabel:
setLabelImageCache:
setLayerStack:
setLayerStackMode:
setLayerStackOptions:
setLayers:
setLayout:
setLayoutConfiguration:
setLayoutRegions:
setLoadingHandler:
setLoadingHandlerQueue:
setLoadingState:
setLocalConfidenceScore:
setLocalLightData:
setLoopTimeRange:
setLowMemoryModeEnabled:
setLuminance:
setLuminanceThresholds:
setLuminanceValue:
setLuminanceWeights:
setMaskImage:
setMatteImage:
setMattePureBackground:
setMattePureForeground:
setMaxAutoAngle:
setMaxAutoPitch:
setMaxAutoStraighten:
setMaxAutoYaw:
setMaxDominantColors:
setMaximumAperture:
setMedia:
setMediaType:
setMedianLuminance:
setMetadata:
setMetadataClockOverlapAcceptable:
setMetadataConverter:
setMetadataProcessor:
setMinAutoStraighten:
setMinimumAngleCorrection:
setMinimumAperture:
setMinimumConfidence:
setMinimumPitchCorrection:
setMinimumPitchCorrectionArea:
setMinimumYawCorrection:
setMinimumYawCorrectionArea:
setNFaces:
setName:
setNetworkAccessAllowed:
setNeutral:
setNormalizedClipRect:
setNormalizedImagePoint:
setNormalizedVisibleFrame:
setObject:forKey:
setObject:forKey:cost:
setObject:forKeyedSubscript:
setOffsetBrightness:
setOffsetCast:
setOffsetContrast:
setOffsetExposure:
setOffsetHighlights:
setOffsetLocalLight:
setOffsetSaturation:
setOffsetShadows:
setOptimizeForBackgroundProcessing:
setOptimizeForSharing:
setOptions:
setOriginalCrop:
setOriginalLayout:
setOutputSettings:
setOvercaptureSource:
setOvercaptureStatistics:
setPairingIdentifier:
setParallaxLayoutConfigurationOverride:
setParallaxScore:
setParallaxStyleAvoidColorWashBrownOverride:
setParallaxStyleKeyLevelOverride:
setParallaxWallpaperDisableUpgrade:
setParameters:
setPerformedActions:
setPerservesAlpha:
setPetsFaceRegions:
setPhotoFeatureFlags:properties:error:
setPhotoProcessingFlags:properties:error:
setPipelineFilters:
setPitch:
setPitchAngleDegrees:
setPitchRadians:
setPortraitInfo:
setPortraitMajorVersion:
setPortraitMinorVersion:
setPortraitStrength:
setPosterFrameTime:
setPreserveSourceColorSpace:
setPrimaryColor:
setPrimaryURL:
setPriority:
setProduceConfidenceMap:
setProgressHandler:
setProperties:
setProxyImage:
setProxyOnly:
setQ:
setRadius:
setRangeMax:
setRangeMin:
setRate:
setRawSensorHeight:
setRawSensorWidth:
setRawTime:
setReadNoise_1x:
setReadNoise_8x:
setRecipe:
setReframeCropAdjustment:
setReframeVideoAdjustment:
setRegionPolicy:
setRegions:
setRenderCompanionResources:
setRenderContext:
setRenderSize:
setRenderTime:
setRenderToData:
setRenderWithIOSurface:
setRenderingVersionAtCapture:
setRequest:
setRequireHardwareEncoder:
setRequiredSourceTrackIDs:
setResolutionRatio:
setResolvedSourceDefinition:
setResource:
setResponseQueue:
setResultHandlerQueue:
setRevision:
setRollAngle:constrainCropRectWithTargetArea:
setRollAngleDegrees:
setSDOFRenderingVersion:
setSampleMode:
setSampleRect:
setSampleTime:
setSampledDisparityValue:
setScale:
setScene:confidence:
setScores:
setSecondaryColor:
setSegmentationBackground:
setSegmentationClassification:
setSegmentationConfidenceMap:
setSegmentationConfidenceMapImage:
setSegmentationDataURL:
setSegmentationDebugPreviewDisableClock:
setSegmentationDebugPreviewHighQuality:
setSegmentationDebugRoundTripProxyImage:
setSegmentationDisableCaching:
setSegmentationDisabled:
setSegmentationManualGatingLenience:
setSegmentationMatte:
setSegmentationMatteImage:
setSegmentationScore:
setSegmentationType:
setShouldApplyWatermark:
setShouldCancelHandler:
setShouldInfillForeground:
setShouldPerformAutoCrop:
setShouldRunBuildingCheck:
setShouldUseAutoStraightenVerticalDetector:
setSize:
setSmart:
setSource:mediaType:
setSourceDisparity:
setSourceMode:
setSourceSelection:
setSourceTexture:
setSpillMatteAllowed:
setStabCropRect:
setStartTime:
setStateObject:forKey:
setStatistics:
setStillImage:
setStrength:
setStyle:
setStyleRecipeConfigDirectoryPath:
setSubjects:
setSystemBuildVersion:
setSystemName:
setSystemVersion:
setTask:
setText:
setTexture:atIndex:
setThreshold:
setTileSize:
setTime:
setTimeRange:
setTimedMetadata:
setTint:
setTonality:
setTone:
setTotalSensorCrop:
setTrajectoryHomography:
setTransferFunction:
setType:
setUpContext:
setUpdateClockAreaLuminance:
setUpdateClockZPosition:
setUpdateInactiveFrame:
setUsage:
setUseEmbeddedPreview:
setUseRGBA:
setUseStyleRecipeConfigDirectory:
setValue:
setValue:forKey:
setValue:forUndefinedKey:
setVersion:
setVideoCodecType:
setVideoComplementURL:
setVideoPosterFrameURL:
setVisibleFrame:
setVisionRequests:
setVisionSegmentationPolicy:
setVolume:atTime:
setVolumeRampFromStartVolume:toEndVolume:timeRange:
setWarmFace:
setWarmTemp:
setWarmTint:
setWarmth:
setWidth:
setWithArray:
setWithObject:
setY:
setYCbCrColorDepth:
setYCbCrFullRange:
setYawAngleDegrees:
setYawRadians:
set_availableStyles:
set_defaultStyles:
settingForAdjustmentKey:settingKey:
settingForKey:
settings
shapeWithRect:
sharedFactory
sharedPregateRules
sharedRegistry
sharpenAdjustmentController
sharpenAdjustmentControllerCreatingIfNecessary:
sharpenSchema
sharpnessWithIntensity:
shortValue
shouldAllowPerspectiveCorrection
shouldApplyWatermark
shouldCacheNodeForPipelineState:
shouldCancelHandler
shouldInfillForeground
shouldPerformAction:
shouldPerformAutoCrop
shouldPerformAutoStraighten
shouldRunBuildingCheck
shouldUseAutoStraightenVerticalDetector
shouldUseGainMapExposureCompensationForRawProperties:
shouldUseMetalRenderer
size
sizeInBytes
slomoAdjustmentController
slomoAdjustmentControllerCreatingIfNecessary:
slomoSchema
smart
smartBWAdjustmentController
smartBWAdjustmentControllerCreatingIfNecessary:
smartBlackAndWhiteAdjustmentsForValue:andStatistics:
smartBlackAndWhiteSchema
smartBlackAndWhiteStatistics
smartBlackWhiteKernel
smartColorAdjustmentController
smartColorAdjustmentControllerCreatingIfNecessary:
smartColorAdjustmentsForValue:andStatistics:
smartColorHDRStatistics
smartColorProperties
smartColorSchema
smartKey
smartToneAdjustmentController
smartToneAdjustmentControllerCreatingIfNecessary:
smartToneHDRStatistics
smartToneProperties
smoothWithFunction:windowSize:sampleMode:
socPseudoColorFilter
sortUsingComparator:
source
sourceDefinition:
sourceDefinitions
sourceFilterNoOrientation
sourceMode
sourceOutCompositingFilter
sourceSelectAdjustmentController
sourceSelectAdjustmentControllerCreatingIfNecessary:
sourceSelectSchema
sourceSelectionForString:
sourceSelectionKey
sourceTexture
sourceTransferFunction
sparseSequence
spatialOvercaptureVideoSourceFilter
spillMatteAllowed
spillMatteAllowedKey
stabCropRect
stabilizedCropRect
stackName
standardUserDefaults
start:
startKey
startReading
startReadingFrames:atTime:error:
startScaleKey
startTaskToRender:toDestination:error:
startTime
startTimeTimescaleKey
startTimeValueKey
state
statistics
statisticsKey
status
stillImage
stitchedOvercaptureRect:primaryRect:forComposition:error:
stopAtTagFilter:
stopAtTagIncludeOrientationFilter:
stopReadingFrames
straightenTransformWithAngle:extent:
strength
strengthKey
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringForColorType:
stringForKey:
stringForSourceSelection:
stringSettingForKey:defaultValue:
stringValue
stringWithFormat:
stringWithUTF8String:
stripAllTimeAdjustmentsFilter
strongToStrongObjectsMapTable
style
styleRecipeConfigDirectoryPath
styleWithBakedStyle:
styleWithColorAnalysis:
styleWithDictionary:error:
styleWithParameters:colorSuggestions:
subarrayWithRange:
subjects
subjectsFromMetadata:
submit:response:
submitGeneric:
submitGenericRequest:
submitGenericSynchronous:
submitRequest:
submitRequest:completion:
submitSynchronous:
submitSynchronous:error:
submitWithProgress:completion:
substringFromIndex:
suggestedColorForColor:
suggestedColorsForColors:fromColorPalette:
suggestedStyleForCategory:
suggestionAtIndex:
suggestionForColor:
suggestionIndices
sunriseSunsetSceneLabel
superclass
supportedIdentifiers
supportsANE
supportsManualClockIntersectionTolerance
supportsSecureCoding
supportsSegmentationResourceCaching
surfaceStoragePool
sushiLevel1Filter
synchronizeInputs
system
systemBuildVersion
systemName
systemVersion
tableImageFromRed:green:blue:luminance:
targetZoomFactorLimit
task
tempTintProperties
temperature
temperatureKey
textImageGeneratorFilter
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
textureType
threshold:
thresholdImage:withThreshold:
tightCropFrameFromMatteImage:
time
timeFrame
timeFromInputKey:timescaleKey:
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeOverlapCheckBottom
timeOverlapCheckThresholdForTopRect:isInteractive:
timeOverlapCheckTop
timeRange
timeRect
timedMetadata
timedMetadataArray
tint
toDictionary
toRect
tonality
tone
tracks
tracksWithMediaType:
trajectoryHomography
trajectoryeHomographyFromMetadata:containsV3Metadata:
transformNodeWithInput:transform:error:
trimAdjustmentController
trimAdjustmentControllerCreatingIfNecessary:
trimInput:startTime:endTime:error:
trimSchema
trimToTimeRange:usingScript:
tryLoadSegmentationForColdAsset:
type
typeWithFilenameExtension:
typeWithIdentifier:
unarchivedObjectOfClasses:fromData:error:
unarchivedStyleRecipeWithURL:error:
underlyingAVDepthData
undoExifOrientation:error:
undoOrientation:forPitch:yaw:angle:
unionWith:
unit
unknownError:object:
unsafeAreaInImageSpaceWithVisibleFrame:
unsafeRect
unsignedIntValue
unsignedIntegerValue
unsupportedError:object:
updateClockAreaLuminance
updateClockPropertiesWithClockAreaLuminance:
updateClockZPosition
updateCropAdjustment:after:error:
updateCropAdjustmentController:after:error:
updateInactiveFrame
updateSegmentationResource:
upgradePosterConfiguration:atURL:exportTo:options:completion:
upgradeWallpaperAtURL:exportToURL:options:completion:
upsampleMatteImage:guideImage:
urlForIdentifier:
useAsCIImageWithOptions:renderer:block:
useAsCIRenderDestinationWithRenderer:block:
useSourceBuffersDirectly
useStyleRecipeConfigDirectory
userInfo
validRegion
validateAdjustmentsEnvelope:error:
validateComposition:error:
validateCompositionWithMissingSource:error:
validatedCompositionCopyForComposition:mediaType:
value
valueAtIndex:
valueForKey:
valueForUndefinedKey:
valueKey
valueWithBytes:objCType:
valueWithCMTime:
valueWithIdentifier:inGroup:ofClass:
valueWithRGBResult:
values
valuesAtCaptureFromImageProperties:error:
valuesForArrayInputKey:
variableName
variationForFlavor:
vectorWithCGPoint:
vectorWithCGRect:
vectorWithFloats:
vectorWithX:
vectorWithX:Y:
vectorWithX:Y:Z:
vectorWithX:Y:Z:W:
versionForPortraitEffect:
versionFromString:
versionKey
versionRules
versionWithMajor:minor:subMinor:platform:
videoAssetIsHighDynamicRange:
videoCodecType
videoComplementURL
videoCrossfadeLoop:crossfadeAdjustment:error:
videoCrossfadeLoopAdjustmentController
videoCrossfadeLoopAdjustmentControllerCreatingIfNecessary:
videoCrossfadeLoopSchema
videoFrames
videoMetadataForVariation:error:
videoMetadataSamples
videoPosterFrameAdjustmentController
videoPosterFrameAdjustmentControllerCreatingIfNecessary:
videoPosterFrameSchema
videoPosterFrameURL
videoProperties:
videoPropertiesRequestWithComposition:
videoReframe:reframes:error:
videoReframeAdjustmentController
videoReframeAdjustmentControllerCreatingIfNecessary:
videoReframeSchema
videoRenderRequestWithComposition:fitInSize:
videoSource
videoSourceWithURL:
videoStabilizeAdjustmentController
videoStabilizeAdjustmentControllerCreatingIfNecessary:
videoStabilizeSchema
vignetteAdjustmentController
vignetteAdjustmentControllerCreatingIfNecessary:
vignetteSchema
visibleFrame
visibleRect
waitForRender:
waitUntilCompletedAndReturnError:
waitUntilDone
wantsCompleteStage
wantsOutputGeometry
wantsOutputImage
wantsOutputVideo
wantsRenderScaleClampedToNativeScale
wantsRenderStage
warmColor
warmFace
warmFaceKey
warmTemp
warmTempKey
warmTint
warmTintKey
warmUp
warmUpClassificationDetectors
warmth
watchInfillImage:matte:
whiteBalanceAdjustmentController
whiteBalanceAdjustmentControllerCreatingIfNecessary:
whiteBalanceKernel
whiteBalanceSchema
whiteColor
whiteFactor
whiteValue
width
widthKey
withLenience:
workingColorSpace
wrapAsUnexpectedError:
write:
writeBufferInRegion:block:
writeCGImage:fileURL:
writeCGImage:fileURL:options:
writeDebugDiagnosticsToDisk
writeImage:fileURL:
writeImage:toDirectoryAtPath:withBasename:
writeImage:toTemporaryDirectoryWithBasename:
writeImageBuffer:toURL:error:
writeLongExposureImage:UTI:colorSpace:error:
writeMaskImage:UTI:error:
writeMetadataType:value:toCGImageProperties:error:
writePropertyList:toStream:format:options:error:
writeRecipe:toURL:error:
writeToTIFF:
writeToURL:atomically:
writeToURL:error:
writeToURL:mode:error:
xOriginKey
xValue
yOriginKey
yValue
yawKey
yawRadians
yellowColor
zone
zoomStrategy
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"<NURenderStatistics>"16@0:8
@"<NUImageBuffer>"16@0:8
v24@0:8@16
v16@0:8
@"<NUImageBuffer>"
@24@0:8@16
B24@0:8o^@16
@"NUStorageImageBuffer"
@"CIRenderTask"
@"CIImage"
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8@?16
v20@0:8B16
@"<NUScalePolicy>"
@"NUPixelFormat"
@"NUColorSpace"
@"PTCinematographyTrack"16@0:8
@"PTCinematographyTrack"
v76@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40f72
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
@?16@0:8
{CGPoint="x"d"y"d}
{?="value"q"timescale"i"flags"I"epoch"q}
@64@0:8@16{?=qiIq}24{CGPoint=dd}48
f16@0:8
v20@0:8f16
@40@0:8@16q24^{CGColorSpace=}32
@"PFStoryRecipeDisplayAssetNormalization"
B32@0:8@16@24
v24@0:8d16
d16@0:8
v32@0:8q16d24
v32@0:8@16q24
@20@0:8f16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@80@0:8@16{?=qiIq}24{CGRect={CGPoint=dd}{CGSize=dd}}48
@"NSNumber"
@160@0:8@16@24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40{CGSize=dd}72{CGRect={CGPoint=dd}{CGSize=dd}}88{CGRect={CGPoint=dd}{CGSize=dd}}120@152
@144@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56{CGRect={CGPoint=dd}{CGSize=dd}}72{CGRect={CGPoint=dd}{CGSize=dd}}104@136
@32@0:8Q16@24
@40@0:8Q16@24d32
@"CIContext"
@32@0:8@16o^@24
@"NSArray"16@0:8
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80@88
@"NSArray"
@96@0:8@16{CGSize=dd}24@40Q48@56@64^d72^d80^B88
v24@0:8Q16
@"NSString"
@"PFParallaxLayout"
@"<PFParallaxLayoutConfiguration>"
@"<PISegmentationItem>"
@32@0:8@16@24
v24@0:8q16
i20@0:8i16
B48@0:8@16@24@32^@40
v40@0:8@16@24@32
v32@0:8@16@24
@"<MTLTexture>"
@40@0:8@16@24o^@32
B40@0:8@16@24o^@32
@40@0:8@16@24@32
Q32@0:8@16@?24
Q24@0:8@16
@24@0:8Q16
@"NSIndexSet"
#24@0:8@16
v32@0:8@16@?24
B28@0:8@16B24
B36@0:8@16@24B32
B40@0:8@16@24@?32
@"NUComposition"
{?="hasDidAdd"B"hasDidRemove"B"hasDidUpdate"B"hasDidUpdateMultiple"B"hasClassForController"B}
@"NSDictionary"
@"<PICompositionControllerDelegate>"
@48@0:8@16@24@32o^@40
B32@0:8@16o^@24
@56@0:8@16@24@32@40o^@48
@44@0:8@16@24B32o^@36
B48@0:8@16@24@32o^@40
@36@0:8@16B24o^@28
@"NSData"
d40@0:8@16d24^B32
@32@0:8@16q24
{CGPoint=dd}72@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32q64
{CGPoint=dd}32@0:8r^{CGPoint=dd}16Q24
@56@0:8@16@24@32@40@48
@"NSURL"
{?={?=qq}{?=qq}}16@0:8
v48@0:8{?={?=qq}{?=qq}}16
{?="origin"{?="x"q"y"q}"size"{?="width"q"height"q}}
v32@0:8@16i24B28
i16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
@108@0:8@16@24@32@40@48@56@64@72@80@88B96o^@100
@"NUCVPixelBuffer"
@"PTGlobalRenderingMetadata"
@"PIPortraitVideoMetadataSample"
@24@0:8q16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?=qiIq}72{?=qiIq}96
@24@0:8o^@16
{?={?=qiIq}{?=qiIq}}16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v40@0:8@16@24d32
{?=qiIq}32@0:8@16@24
@"NSMutableDictionary"
@"NUIdentifier"
@"NUAdjustment"
@"<PIParallaxFilterCache>"
@24@0:8d16
@"PFParallaxLayerStack"
@56@0:8@16@24@32@40q48
{?=qq}32@0:8{?=qq}16
i32@0:8{?=qq}16
^{__CVBuffer=}32@0:8@16o^@24
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_queue>"
@"<NUFaceDetectionResult>"
@"NSURL"24@0:8@"NSString"16
@"NSBundle"
q24@0:8@16
@"PFParallaxColor"
@"PFParallaxColor"16@0:8
v24@0:8@"PFParallaxColor"16
@48@0:8@16@24@32@40
@"PIParallaxStyleRecipe"
@48@0:8@16{?=qiIq}24
@24@0:8@"NSDictionary"16
@"NSDictionary"16@0:8
@48@0:8{?=qiIq}16d40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8q16q24q32d40
@"PFParallaxLayerStyle"24@0:8@"NSString"16
@"NUComposition"16@0:8
@"<PFParallaxAssetRegions>"16@0:8
@"PFParallaxLayout"16@0:8
@"<PFParallaxLayoutConfiguration>"16@0:8
@"PIParallaxColorAnalysis"16@0:8
@"PFParallaxLayerStyle"16@0:8
@"NSURL"16@0:8
B48@0:8@16^B24^B32o^@40
@"PFParallaxAssetResource"
@"<PFParallaxAssetRegions>"
@"PIParallaxColorAnalysis"
@"PISegmentationContextInfo"
@32@0:8@16#24
v72@0:8{?={?=qiIq}{?=qiIq}}16@64
v40@0:8d16d24@?32
@"NURuleSystem"
@88@0:8{?=qiIq}16{?=[3]}40
{?=[3]}16@0:8
{?="columns"[3]}
{?=[3]}40@0:8{?=qiIq}16
@"NUKeyframeSequenceMatrixFloat33"
{?=ffff}16@0:8
v32@0:8{?=ffff}16
@"<NUPurgeableStorage>"
@"NUImageHistogram"
{?="r"f"g"f"b"f"a"f}
@56@0:8@16d24d32d40o^@48
@"NUPurgeableStoragePool"
@"NSMutableArray"
@"AVAsset"
@72@0:8@16{?={?=qq}{?=qq}}24Q56@64
{?={?=qq}{?=qq}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?={?=qq}{?=qq}}48d80d88
{?=ddd}56@0:8@16{?={?=qq}{?=qq}}24
@28@0:8@16B24
{?={?=[4d]}{?=[4d]}d}16@0:8
@88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=[4d]}16@0:8
@48@0:8{?=[4d]}16
B48@0:8{?=[4d]}16
{?=[4d]}48@0:8{?=[4d]}16
{?=[4d]}88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=dd}104@0:8{?={?=[4d]}{?=[4d]}d}16@88d96
{?={?=[4d]}{?=[4d]}d}48@0:8@16@24d32@40
@"NUBufferRenderClient"
@"NUImageDataClient"
@32@0:8@16^@24
B40@0:8@16@24^@32
@"NSArray"32@0:8@16^@24
B40@0:8@16@"NSMutableDictionary"24^@32
@"NSNumber"32@0:8@"NSDictionary"16^@24
B40@0:8@"NSNumber"16@"NSMutableDictionary"24^@32
{?=qq}16@0:8
v32@0:8{?=qq}16
@"NUImageExportRequest"
{?="width"q"height"q}
@"NUImageGeometry"
@"NUPriority"
@"NUImageExportFormat"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
@48@0:8@16@24@32@?40
@72@0:8@16@24@32@40@48@56@?64
@48@0:8@16@24@32^@40
v64@0:8@16@24@32@40@48@?56
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@48@0:8Q16Q24Q32@40
@40@0:8Q16Q24Q32
@"PFParallaxLayerStack"16@0:8
v40@0:8q16@24@?32
@"NSError"
@"PIParallaxStyle"
v64@0:8{?={?=qiIq}{?=qiIq}}16
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@32@0:8@16d24
@40@0:8@16{CGSize=dd}24
{PISegmentationBimodalScore=fff}24@0:8@16
f64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
f32@0:8@16@24
{PISegmentationClockOverlapResult=@Qdd}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64
{PISegmentationClockOverlapResult=@Qdd}76@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64B72
d64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
d88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64@72@80
d96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64@72^d80@88
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGPoint=dd}56
d120@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{PISegmentationClockOverlapResult=@Qdd}64@96@104@112
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^B48@56@64@72
{CGRect={CGPoint=dd}{CGSize=dd}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64@72@80@88
{PISegmentationInactiveResult={CGRect={CGPoint=dd}{CGSize=dd}}{CGRect={CGPoint=dd}{CGSize=dd}}}92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48B64@68@76@84
@104@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40{CGRect={CGPoint=dd}{CGSize=dd}}72
@112@0:8@16@24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48{CGRect={CGPoint=dd}{CGSize=dd}}80
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
@40@0:8@16Q24o^@32
@40@0:8@16I24I28o^@32
@40@0:8@16@24#32
@"PTTimedRenderingMetadata"
v84@0:8@16{?=qq}24{?=qq}40i56q60@68@?76
v76@0:8@16{?=qq}24{?=qq}40i56q60@68
@68@0:8@16{?=qq}24{?=qq}40i56q60
@"PTRenderPipeline"
@"<PTRenderState>"
@"<MTLDevice>"
@"NSDate"
v48@0:8q16^d24^d32^d40
@"PIFaceObservationCache"16@0:8
v24@0:8@"PIFaceObservationCache"16
v36@0:8@16@24B32
f24@0:8@16
B32@0:8{?=qq}16
B40@0:8@16{?=qq}24
@"PIFaceObservationCache"
B32@0:8{CGSize=dd}16
{?="exposure"d"contrast"d"brightness"d"shadows"d"highlights"d"black"d"rawHighlights"d"localLight"d}
@36@0:8@16@24B32
@52@0:8@16@24@32q40B48
@44@0:8@16{CGSize=dd}24B40
^{CGImage=}24@0:8@16
B32@0:8@16^q24
@40@0:8@16Q24^{CGColorSpace=}32
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48d56
@48@0:8{?=qq}16@32Q40
@64@0:8@16@24{?={?=qq}{?=qq}}32
B60@0:8@16i24^{CGColorSpace=}28@36@44o^@52
@"<NURenderer>"
@"<NUSurfaceStorage>"
@"NSObject<OS_dispatch_semaphore>"
@"VNImageHomographicAlignmentObservation"16@0:8
@"VNImageHomographicAlignmentObservation"
@64@0:8d16d24d32d40d48d56
B28@0:8{PISegmentationBimodalScore=fff}16
@44@0:8@16@24@32B40
@60@0:8@16@24B32{CGSize=dd}36q52
@"PTCinematographyScript"
@"NSCache"
@"CIColor"
^{CGColorSpace=}16@0:8
{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}24@0:8@16
@48@0:8r^f16r^f24r^f32r^f40
@40@0:8@16{?=qq}24
@"NUFaceDetectionRequest"
v24@0:8@?<B@?@"NSURL">16
i40@0:8q16@24@?32
v20@0:8i16
i24@0:8@?16
i40@0:8q16@"PFParallaxAssetResourceOptions"24@?<v@?@"PFParallaxAssetResource"@"NSError">32
i24@0:8@?<v@?@"NSArray"@"NSArray"@"NSError">16
@68@0:8^v16Q24Q32q40Q48i56^{CGColorSpace=}60
@68@0:8@16Q24Q32q40Q48i56^{CGColorSpace=}60
^v16@0:8
^{CGColorSpace=}
@"NSMutableData"
v24@0:8^{?=Bffff[3f]}16
^f16@0:8
@24@0:8^f16
@32@0:8d16@24
Q32@0:8@16o^@24
^{__CVBuffer=}16@0:8
@"NUPixelFormat"16@0:8
@"NUColorSpace"16@0:8
@"CIRenderInfo"
@48@0:8@16@24d32@40
@"<NUImageBuffer>"36@0:8@"CIImage"16B24o^@28
@"PFParallaxLayer"48@0:8@"<NUImageBuffer>"16@"CIImage"24d32@"NSString"40
@"CIImage"32@0:8@"CIImage"16@"NSString"24
@"_PIParallaxLayerStackDebugImageCollector"
v88@0:8@16@24@32@40@48@56@64@72@80
@36@0:8@16B24#28
@20@0:8B16
@36@0:8d16d24B32
@104@0:8@16{?=[3]}24{CGRect={CGPoint=dd}{CGSize=dd}}72
@40@0:8@16@24d32
@"CIVector"
@32@0:8^{CGImage=}16q24
@48@0:8@16@24q32^{CGImage=}40
@72@0:8@16Q24@32@40@48@56@?64
@56@0:8@16@24@32Q40@?48
@40@0:8@16Q24^@32
@40@0:8@16@24@?32
v32@0:8@16Q24
v28@0:8B16@?20
v40@0:8@16q24@?32
@"NURenderContext"
@"PIParallaxSegmentationItem"
@"<PFParallaxAsset>"
B24@0:8Q16
@32@0:8q16@24
B32@0:8^{?={?=qq}{?=qq}}16o^@24
B48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{CGRect={CGPoint=dd}{CGSize=dd}}24@32o^@40
{CGRect={CGPoint=dd}{CGSize=dd}}96@0:8{?=qq}16{?=qq}32{?=qq}48{CGRect={CGPoint=dd}{CGSize=dd}}64
{?="p75"d"p98"d"autoValue"d"g98"d}
{?="sat"d"contrast"d"cast"d}
v36@0:8^f16f24f28f32
f24@0:8r^f16
d40@0:8d16d24d32
@64@0:8@16{?={?=qq}{?=qq}}24@56
@144@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{?=[3]}88@136
@"PIReframeKeyframeSequence"
@"<NUVideoProperties>"
v32@0:8{CGVector=dd}16
v64@0:8{?=[3]}16
{CGVector=dd}16@0:8
{CGVector="dx"d"dy"d}
@24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{CGVector=dd}24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{?=[3]}32@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16^B24
@"AVAssetTrack"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
B24@0:8d16
@48@0:8@16{CGPoint=dd}24d40
v56@0:8@16@24@32@40@?48
B32@0:8^{CGImage=}16@24
B40@0:8^{CGImage=}16@24@32
{?={?=qq}{?=qq}}40@0:8{CGPoint=dd}16d32
v40@0:8r^f16^S24Q32
v40@0:8r^S16^f24Q32
@48@0:8f16f20f24f28Q32{?=ii}40
{?=ii}16@0:8
v24@0:8{?=ii}16
{?="major"i"minor"i}
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@48@0:8@16@24q32@40
@52@0:8@16@24@32f40q44
@40@0:8@16q24@32
v128@0:8d16{?=qq}24{?={?=qq}{?=qq}}40{?={?=qq}{?=qq}}72^{?={?=qq}{?=qq}}104^{?={?=qq}{?=qq}}112^{?={?=qq}{?=qq}}120
@56@0:8@16{?={?=qq}{?=qq}}24
B56@0:8@16@24@32@40o^@48
v52@0:8@16@24{CGPoint=dd}32B48
^{CGImage=}32@0:8^{CGImage=}16^{CGImage=}24
@64@0:8@16@24@32@40q48o^@56
@52@0:8@16@24@32B40o^@44
@36@0:8@16B24@28
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{__CVBuffer=}24@0:8^{CGImage=}16
B32@0:8@16^{__CVBuffer=}24
^{__CVBuffer=}32@0:8{CGSize=dd}16
v24@0:8^{__CVBuffer=}16
@32@0:8d16d24
{CGPoint=dd}44@0:8i16d20d28@36
ffffff
[@q=
433333
?ffffff
?YAH
pCh?
@<,_
@+~h
?ffffff
?333333
?(D#$w
333333
333333
?UUUUUU
?______
?TTTTTT
Ww'&l
MbP?
333333
?ffffff
?ffffff
?333333
333333
ffffff
?333333
333333
@UUUUUU
Q@333333
?ffffff
z>UUUUUU
UUU?
]?~0d>
@(#)PROGRAM:PhotoImaging  PROJECT:Neutrino-540.1.140
0Xr
?g|_\
ADBE
mntrRGB XYZ 
;acspAPPL
none
-ADBE
cprt
2desc
kwtpt
bkpt
rTRC
gTRC
bTRC
rXYZ
gXYZ
bXYZ
text
Copyright 2000 Adobe Systems Incorporated
desc
Adobe WGG linear
XYZ 
XYZ 
curv
XYZ 
XYZ 
iXYZ 
#?6t>=
<Xa<
<R>)<
A><QMI<
N-=y#3=*
OE=&
N,>;
2>F(6>
<>&T@>u
dN>;
Gl>#.p>
?Jy!?
V*?9%,?w
1?l{3?!X5?
77?"
NF=O
 >Me!>
">LP#>
)>k'*>"
^+>w
,>o+->D
->O\.>
1>uv2>N
T5>y
5>pw6>
7>t'8>M
D9>F
`:> 
z;>%
=>34>>Y
>>=H?>
A> zB>
E>>"F>]
F>9*G>
0H>K
;K>o
<L>l
;M>Z
M>;:N>
O>U2P>
P>k,Q>
Q>1%R>0
gW>i
HY>#
Y>&7Z>)
$[>$
]>B[^>
Mc>r
0d>h
f>cCg>
ni>r
Jj> 
%k>G
l>oFm>
n>gao>
q>!wq>L
q>4Kr>
+u>`
u>Acv>
x>35y>
z>U3{>
{>(c|>
,}>h
?%"?
+?Y5?
>?|H?
n?Bx?
< ?(D ?8L ?GT ?W\ ?gd ?vl ?
!?F%!?E-!?D5!?C=!?AE!?@M!?PU!?O]!?Me!?Lm!?Ku!?9}!?8
,"?v4"?u<"?cD"?QL"??T"?-\"?
9#?lA#?ZI#?7Q#?
x#?g
<$?kD$?8L$?
c$?{k$?Gs$?
%?B&%?
=%?RE%?
\%?Rd%?
{%?A
&?c%&?
<&?1D&?
S&?B[&?
j&?Tr&?
"'?9*'?
1'?~9'?)A'?
H'?nP'?
_'?Mg'?
v'?,~'?
(?l%(?
4(?)<(?
C(?^K(?
i(?.q(?
x(?R
)?R&)?
-)?T5)?
<)?gD)?
K)?iS)?
Z)?kb)?
i)?~q)?
*?1%*?
,*?"4*?
C*?{J*?
Q*?mY*?
`*?^h*?
o*?>w*?
+?)"+?
0+?a8+?
?+?0G+?
V+?h]+?
d+?7l+?
{+?o
+,?a3,?
B,?fI,?
X,?l_,?
n,?qu,?
-?$%-?|,-?
;-?_B-?
P-?CX-?
n-?\u-?
+.?<2.?
G.?3O.?zV.?
d.?+l.?`s.?
6/?K=/?
Y/?5a/?jh/?
?0?AF0?fM0?
q0?!x0?E
?1?,F1?@M1?TT1?h[1?|b1?
=2?1D2?4K2?7R2?KY2?N`2?Qg2?Tn2?Xu2?[|2?^
3?t$3?w+3?j23?m93?_@3?cG3?UN3?XU3?K\3?=c3?@j3?2q3?6x3?(
V4?t]4?gd4?Hk4?;r4?
35?`:5?BA5?$H5?
c5?{j5?\q5?>x5? 
#6?o*6?@16?
L6?eS6?GZ6?
u6?[|6?,
7?|&7?<-7?
A7?oH7?/O7?
c7?Qj7?
~7?b
8?E
'8?E.8?
;8?tB8?4I8?
V8?d]8?$d8?
q8?Sx8?
&9?w-9?&49?
A9?4H9?
U9?B\9?
i9?Pp9?
}9?^
:?5$:?
1:?"8:?
>:?oE:?
R:?\Y:?
f:?Hm:?
z:?$
;?$;?
3;?X:;?
G;?#N;?
T;?O[;?
a;?{h;?
u;?5|;?
<?f
-<?+4<?
:<?FA<?
G<?QN<?
T<?l[<?
u<? |<?
%=?I,=?
2=?T9=?
?=?NF=?
L=?XS=?
Y=?R`=?
f=?Lm=?
s=?Wz=?
">?A)>?
/>?*6>?
<>?$C>?
P>?zV>?
\>?cc>?
i>?Lp>?
v>?5}>?
*??]1??
7??6>??
K??zQ??
W??B^??
w??N~??
*@?H1@?
=@?[D@?
J@?"Q@?~W@?
]@?4d@?
p@?Ww@?
)A?o/A?
<A?pBA?
OA?aUA?
bA?bhA?
uA?S{A?
B?kB?
+B?+2B?v8B?
EB?UKB?
WB?5^B?odB?
qB?OwB?
C?u C?
,C?33C?m9C?
EC?+LC?eRC?
^C?#eC?]kC?
~C?U
&D?M,D?v2D?
ED?MKD?
]D?$dD?MjD?
0E??6E?h<E?
UE?6[E?_aE?
zE?,
,F?+2F?T8F?l>F?
]F?0cF?IiF?aoF?yuF?
G?S G?l&G?
PG?WG?%]G?=cG?DiG?]oG?uuG?|{G?
H?)%H?A+H?H1H?P7H?W=H?pCH?wIH?
I?S"I?[(I?Q.I?Y4I?`:I?W@I?_FI?ULI?]RI?SXI?[^I?cdI?YjI?apI?WvI?N|I?V
SJ?}YJ?t_J?keJ?akJ?XqJ?OwJ?F}J?,
)K?w/K?n5K?T;K?JAK?0GK?'MK?
vK?x|K?o
3L?i9L?>?L?$EL?
bL?whL?]nL?CtL?
M?:$M? *M?
AM?ZGM?/MM?
dM?{jM?PpM?%vM?
0N?~6N?S<N?
SN?\YN?1_N?
pN?dvN?9|N?
O?1$O?
/O?~5O?T;O?
LO?eRO?*XO?
cO?wiO?;oO?
!P?t'P?8-P?
8P?u>P?(DP?
OP?eUP?)[P?
fP?UlP?
}P?E
Q?E
Q?p#Q?$)Q?
4Q??:Q?
EQ?ZKQ?
VQ?t\Q?(bQ?
mQ?CsQ?
~Q?^
R?s
R?}#R?0)R?
4R?*:R?
ER?4KR?
VR?-\R?
gR?&mR?
rR?}xR? ~R?
'S?<-S?
8S?%>S?
CS?kIS?
TS?SZS?
eS?+kS?
pS?qvS?
/T?H5T?
:T?}@T?
KT?DQT?
VT?y\T?
gT?@mT?
rT?uxT?
U?h%U?
;U?BAU?
FU?ULU?
QU?yWU?
bU?0hU?
mU?CsU?
xU?g~U?
$V?=*V?
/V?P5V?
:V?d@V?
EV?wKV?
VV?\V?
lV?"rV?
wV?5}V?
W?}"W?
SW?yYW?
^W?|dW?
iW?moW?
tW?pzW?
X?>$X?
)X?0/X?
4X?!:X?
OX?eUX?
ZX?W`X?
eX?8kX?
pX?)vX?
Y?l$Y?
)Y?</Y?
DY?oJY?
OY??UY?
ZY? `Y?
kY?apY?
uY?B{Y?
#Z?g(Z?
-Z?73Z?
>Z?gCZ?
HZ?8NZ?
XZ?h^Z?
cZ?'iZ?
sZ?WyZ?
[?! [?p%[?
*[?/0[?
:[?O@[?
K[?]P[?
[[?|`[?
e[?+k[?
u[?J{[?
!\?g&\?
1\?e6\?
A\?cF\?
Q\?`V\?
a\?^f\?
p\?\v\?
]?m ]?
+]?Y0]?
:]?F@]?
J]?"P]?qU]?
`]?^e]?
o]?:u]?
(^?,.^?j3^?
=^?FC^?
S^?OX^?
h^?Ym^?
w^?$}^?s
_?>%_?|*_?
4_?6:_?u?_?
I_?/O_?\T_?
d_?Ui_?
y_?=~_?{
 `?[%`?
4`?2:`?`?`?
O`?7T`?dY`?
i`?;n`?is`?
#a?$)a?Q.a?
Ca?4Ha?bMa?
ba?Ega?rla?
b?|b?
!b?>&b?Z+b?
Eb?IJb?fOb?
cb?'ib?Dnb?qsb?
,c?<1c?Y6c?u;c?
Uc?2Zc?N_c?kdc?
d?:!d?F&d?c+d?
Td?2Yd?>^d?Zcd?fhd?
$e?5)e?A.e?L3e?X8e?u=e?
ze? 
f?[f?f
g?xg?s
g?u g?
%g?|*g?w/g?
4g?~9g?y>g?
Hg?{Mg?
Wg?}\g?xag?
kg?zpg?uug?
zg?|
sh?uxh?p}h?k
Mi?~Ri?iWi?d\i?Nai?8fi?3ki?
&j?k+j?U0j??5j?;:j?%?j?
aj?ffj?Qkj?;pj?%uj?
%k?|*k?f/k?P4k?*9k?
Vk?`[k?J`k?4ek?
l?S#l?,(l?
;l?}@l?VEl?0Jl?
bl?Zgl?3ll?
m?=m?
m?l$m?E)m?
<m?tAm?NFm?
Ym?l^m?Ecm?
vm?t{m?=
n?%$n?
2n?X7n?2<n?
Jn?fOn?.Tn?
bn?sgn?<ln?
zn?o
o?l"o?5'o?
5o?X:o?
Ho?jMo?3Ro?
`o?Veo?
so?hxo?1}o?
p?Ap?
-p?U2p?
@p?VEp?
Sp?XXp? ]p?
fp?Ykp?"pp?
yp?Z~p?#
q?Z
q?J$q?
-q?r2q?*7q?
@q?cEq?
Sq?SXq?
aq?{fq?3kq?
tq?[yq?
,r?@1r?
:r?W?r?
Hr?nMr?&Rr?
[r?=`r?
ir?Tnr?sr?
wr?l|r?$
 s?>%s?
.s?D3s?
<s?JAs?
Js?QOs?
Xs?W]s?
fs?]ks?
ts?dys?
t?K!t?
*t?@/t?
8t?6=t?
Ft?+Kt?
Ot?zTt?!Yt?
]t?obt?
kt?ept?ut?
yt?J~t?
 u?F%u?
.u?+3u?
7u?h<u?
Eu?MJu?
Su?2Xu?
\u?pau?
ju?Tou?
xu?(}u?
v?9v?
v?:#v?
'v?w,v?
5v?K:v?
>v?xCv?
Lv?LQv?
Uv?yZv?
cv?Mhv?
lv?zqv?
zv?N
w?t$w?
-w?82w?
6w?T;w?
Mw?DRw?
Vw?`[w?
dw?#iw?
mw??rw?
vw?l{w?
x?O$x?
(x?k-x?
6x?;x?
?x?(Dx?
Hx?DMx?
Qx?`Vx?
Zx?|_x?
qx?:vx?
zx?V
"y?='y?
+y?Y0y?
4y?e9y?
=y?pBy?
Fy?{Ky?
]y?(by?
fy?3ky?
oy??ty?
xy?J}y?
z?W$z?
(z?b-z?
1z?m6z?
:z?h?z?
Cz?sHz?
Lz?nQz?
Uz?hZz?
^z?scz?
gz?nlz?
pz?yuz?
yz?t~z?
{?! {?
L{?zQ{?
U{?dZ{?
^{?^c{?
g{?Yl{?
p{?Cu{?
y{?=~{?
0|?i5|?
9|?S>|?
B|?=G|?
K|?'P|?
a|?of|?
j|?Xo|?
s|?Bx|?
||?,
}?%!}?
)}?s.}?
2}?]7}?
;}?5@}?
Q}?\V}?
Z}?5_}?
p}?\u}?
y}?F~}?
!~?>&~?
/~?{3~?
7~?S<~?
@~?,E~?
M~?YR~?
V~?1[~?
d~?nh~?
l~?7q~?
z~?t~~?
333333
?333333
?ffffff
sU?gDi?
z?-C
Fail: %{public}@
job: %{public}@
Trace:
%{public}@
Trace:
%{public}@
Tap-to-track: client requested stop at %@
Tap-to-track: tracking lost at %@
PIColorNormalizationAnalysis
Tried to set sceneLabel to unsupported value: %ld
Setting bounding boxes based on orientation (%@) and observations: %@
Setting face bounding boxes based on orientation (%@) and observations: %@
Continue: %{public}@
Failed to load compute pipeline: %@
Failed to load user palette '%@', error: %@
class %@ is not the correct type, its superclass should be %@
Unable to serialize finalized composition: %{public}@
Error executing command buffer '%{public}@': %{public}@
CPV rendering failure, returned status %d
Could not apply PIPortraitVideoProcessor: %@
Failed to prewarm portrait renderer: %{public}@
Failed to obtain video properties: %{public}@
Using recipe directory at '%{public}@'
Failed to load style recipe for identifier '%@', error: %@
Missing configuration file '%{private}@'
PARALLAX CLOCK: luminance is %f - %@
ColorBGStandard: suggested %@ for background luminance of %.2f
ColorBG color: %@ -> neutral: %@ lowKey: %0.3f highKey: %0.3f
Couldn't find a single candidate style for category %{public}@, falling back to Original
Median luminance: %f
Percent above chroma min: %0.0f%%, max hues: %ld
Found %ld dominant hues: %@
Found %ld dominant grays: %@
facerect yiq = %.5f, %.5f, %.5f
Choosing gray world instead of gray edge
Brightness is %@, greenChannelPercentage is %f, Sushi: %@
aperture=%@, shutterSpeed=%@, iso=%@
Buffer sizes are not the same: %{public}@ vs %{public}@
Buffer size is %@, bytes per row is %ld, dark_thr=%f, sat_thr=%f, noise_thr=%f
all done summing, np_gw is %d, np_ge is %d
wp_ge {%f, %f, %f, %f} wp_gw {%f, %f, %f, %f}, Sushi? %@
RGB = %f, %f, %f
YIQ = %f, %f, %f from %f, %f, %f
Failed to export image to %@: %@
Failed to export image to data: %@
Failed to prepare video metadata: %@
Unexpected Live Photo export format pairing. Video codec (%{public}@) and image export format (%{public}@)
Export Composition: exportImage: %{public}@ / exportVideoComplement: %{public}@ / exportVideo: %{public}@ / exportVideoPosterFrame: %{public}@
Export Composition: exporting image
Export Composition: exporting image complete
Export Composition: exporting video complement
Export Composition: exporting video complement complete
Export Composition: exporting video
Export Composition: exporting video complete
Export Composition: exporting video poster frame
Export Composition: exporting video poster frame complete
Export Composition: exporting overcapture image
Export Composition: exporting overcapture image complete
Export Composition: exporting overcapture video
Export Composition: exporting overcapture video complete
Export Composition: waiting on notify
Export Composition: notify triggered
Export Composition: calling completion with error: %{public}@
Export Composition: callling completion with result: %{public}@
failed to render auxiliary image data: %@
Skipping applyVideoOrientationAsMetadata. Bounces and Autoloops are not supported. Falling back to burned-in orientation.
Skipping applyVideoOrientationAsMetadata. Flipped orientations are not supported. Falling back to burned-in orientation.
Failed to export video: %@
invalid format version: %@
Failed to update layout: %{public}@
Failed to compute clock overlap: %{public}@
Failed to compute clock material: %{public}@
Failed to render layer stack, error: %{public}@
Pixel-based headroom zoom final range %@,%@: %@,%@
Unable to calculate a new inactiveRect; falling back to visible frame
PIParallaxLegacyPosterStyle.localLight
PIPortraitVideoMetadataSample: unexpected number of items for identifier %@: %@
PIPortraitVideoMetadataSample: item %@ is not of expected class %@
Error unarchiving cameraInfo metadata: %@
CINE: allocating new PT renderer: %@
CINE: recycling unused PT renderer: %@ (%lu remaining)
CINE: need new render state due to rendering version mismatch
CINE: need new render state due to sensor mismatch
CINE: allocating new renderState with metadata: %p
Requesting forced cleanup of Vision caches
Unsupported filter parameter: %{public}@
Parameter %{public}@ is not a valid color value: %{public}@
Parameter %{public}@ is not a valid number value: %{public}@
Error evaluating filter definition: %@, error: %@
CPV asset editability: onAppleSilicon: %s, hasMetalDeviceForPortrait: %s, oniOS: %s
CPV assets aren't editable because there is no metal device with support for portrait rendering
CPV assets aren't editable because the device has no ANE
CPV assets are editable
HDR asset not editable because this device doesn't support 10-bit HEVC encoding
HDR asset not editable because this device doesn't support HDR
HDR asset not editable because editing not supported on DolbyVision 5
CPV asset checking for editability
CPV asset not editable because it's in a legacy, unsupported format
CPV asset editable due to override
CPV asset not editable because CPV assets are not editable on this device
CPV asset not editable because this asset is not playable on this device
CPV asset not editable because this device doesn't support HDR
CPV asset is editable
validation issue: recipe is blank on the autoloop adjustment
validation issue: no flavor specified on the autoloop adjustment
validation issue: Missing inputCorrectionInfo on a redeye adjustment
validation issue: Missing depthInfo on a depth adjustment
validation issue: Missing portraitInfo on a portrait adjustment
validation issue: invalid trim startTime or endTime
Can PLPhotoEditPFDataConverter interpret identifier %{public}@? %@. Version %{public}@? %@
Failed to load filter named '%@'
PFSizeGetAspectRatio produced an undefined aspect ratio from size %@. Returning %f. Use PFSizeGetAspectRatioWithDefault() to provide a value for this case.
PARALLAX CLOCK: execution time %.2f ms
waitUntilReadyForMoreData: waited for %0.1fms
Writing long-exposure image to %{public}@
Writing long-exposure motion mask to %{public}@
Still image node:
Still image geometry:
Still image:
clap=%@, crop=%@, fullSize=%@, videoScale=%@ => guide rect: %@
High-resolution image registration failure : %@
Unable to load scoring ranges dictionary from %@, error %@
Unable to load scoring plist, using fallback
Failed to load scoring configuration: %@
MediaAnalysis not available
currentSystemCanRenderAsset: error retrieving rendering version from asset: %@
Failed to render %{public}@, error: %{public}@
Failed to allocate pixel buffer for render cache entry (size=%ldx%ld, format=%{public}@)
Cache miss for image: %{public}@ cost: %lu digest: %llx
Loading long-exposure fusion tuning parameters from file: %@
Failed to load fusion tuning parameters.
Using fusion tuning parameters: {kNCCBlurHalfSize=%d, kNCCEdge0=%f, kNCCEdge1=%f, kBlendMaskThreshold0=%f, kBlendMaskThreshold1=%f}
Missing inputImage
Missing inputMaskImage
Missing inputStillImage
Missing inputRenderScale
Missing inputVideoScale
Missing inputAlignmentExtent
Malformed inputAlignmentExtent vector
Missing inputAlignmentTransform
Malformed inputAlignmentTransform vector
Writing intermediate long exposure fusion images to : %@
Evaluating pipeline as HDR input
PISegmentationLoader.memory.warmUp
Ensuring segmentation resources with counter %ld
Freeing segmentation loader resources with counter %ld
PISegmentationLoader.memory.purge
PISegmentationLoader.item
Warning: PISegmentationLoader layout configuration unspecified! Using override layout configuration '%{public}@'
Warning: Override layout configuration '%{public}@' not found, using generic fallback
Warning: PISegmentationLoader layout configuration unspecified! Using the layout configuration matching this device
PISegmentationLoader.proxy
PISegmentationLoader.properties
PISegmentationLoader.fullSize
Failed to compute proxy image size, error: %{public}@
Cancelling segmentation loader
Triggering non-foreground user initiated download for asset with local identifier: %{public}@
Loading resource %ld for asset %{public}@, allow download? %d
Successfully loaded resource %ld for asset %{public}@ in %0.3fs
Failed to load resource %ld for asset %{public}@ after %0.3fs, error: %{public}@
Cancelled loading resource %ld for asset %{public}@ after %0.3fs
PISegmentationLoader.classify
PISegmentationLoader.segment
PISegmentationLoader.regions
PISegmentationLoader.infill
PISegmentationLoader.layout
PISegmentationLoader.colorAnalysis
PISegmentationLoader.localLightData
Known classification: %{public}@
Previous classification attempt yielded 'other'
Current classification is unspecified
Classified image as %{public}@
Detectors failed to classify asset. Falling back to segmentation strategy.
Vision detection failed: %{public}@
Image segmentation response: %@
Image segmentation failed: %{public}@
Full Image color analysis response: %@
Full Image color analysis failed: %{public}@
Foreground color analysis response: %@
Foreground color analysis failed: %{public}@
Background color analysis response: %@
Background color analysis failed: %{public}@
Parallax infill response: %@
Parallax infill failed: %{public}@
MAD pets results: %@, pets face results: %@, error: %@
Failed to load pets regions: %{public}@
Vision detection response: %@
Failed to run face/saliency detection: %{public}@
Parallax layout response: %{public}@
Failed to layout item: %{public}@
Local light data response: %{public}@
Failed to compute local light data: %{public}@
Failed to deserialize segmentation adjustment data: %{public}@
Failed to read orientation for image file: %@, error: %{public}@
PISegmentationLoader.data.read
Failed to read cached segmentation data from: %{public}@, error: %{public}@
Cached segmentation version mismatch: got %ld, expected %ld
Cached segmentation source mode mismatch: got %ld, expected %ld
Cached segmentation disabled flag mismatch: got %d, expected %d
Cached segmentation infill algorithm mismatch: got %ld, expected %ld
Cached segmentation layout configuration mismatch: got %{public}@, expected %{public}@
Cached segmentation classification mismatch: got %{public}@, expected %{public}@
PISegmentationLoader.data.write
Failed to save segmentation data for asset: %{public}@, error:%{public}@
PISegmentationLoader.archive.write
PISegmentationLoader.archive.read
PISegmentationLoader.layerStack.render
PISegmentationLoader.wallpaper.write
Failed to save segmentation item and layer stack to wallpaper URL: %{public}@
Failed to create wallpaper directory: %{public}@
Failed to export segmentation item: %{public}@
PISegmentationLoader.layerStack.write
Failed to export layer stack: %{public}@
Failed to load segmentation item from wallpaper: %{public}@
PISegmentationLoader.layerStack.read
Failed to load layer stack from wallpaper: %{public}@
Failed to render layer stack: %{public}@
Failed to reload segmentation item from wallpaper: %{public}@
Beginning finalization for candidates: %@
No overcapture source found in composition, removing any candidate bits for reframing
Finalizer result contains roll angle degrees: %f pitch angle degrees: %f yaw angle degrees: %f
Finalizer result did not contain a change
Received error while finalizing: %@
Starting horizon auto calculator
Finished horizon auto calculator: %@
Starting perspective auto calculator
Finished perspective auto calculator: %@
Could not write PICropAutoCalculator debug diagnostics. %@
Failed to compute overcapture rect %@
Can't find enabled video track in asset: %@
Asset does not contain Live Photo metadata track
Track does not contain V3 metadata
Error creating asset reader: %@
Can't add metadata output for asset
Failed to start reading asset
Starting metadata extraction
Finished metadata extraction
PISmartToneAutoCalculator submitSynchronous isHDRComposition: %s
PISmartToneAutoCalculator smartTone request submitting: %{public}@
PISmartToneAutoCalculator smartTone result: %{public}@
PISmartToneAutoCalculator localLight request submitting: %{public}@
PISmartToneAutoCalculator localLight result: %{public}@
PISmartToneAutoCalculator submit isHDRComposition: %s
PISmartToneAutoCalculator global result: %{public}@
PISmartToneAutoCalculator going to commit and wait
PISmartToneAutoCalculator committed
PISmartToneAutoCalculator completed
PISmartToneAutoCalculator error: %{public}@
PISmartToneAutoCalculator coalesced
Failed to deserialize layout configuration: %{public}@, error: %{public}@
Can load cold asset? %{public}@ => %{public}@
Failed to deserialize style from dictionary: %{public}@, error: %{public}@
Unknown style option, ignored: %{public}@
Upgrading wallpaper at %{public}@ to %{public}@, options: %{public}@
Failed to export refreshed wallpaper at %{public}@ to %{public}@, error: %{public}@
Successfully exported refreshed wallpaper at %{public}@ to %{public}@
Failed to load poster configuration from: '%{public}@', error: %{public}@
Failed to upgrade poster configuration from: '%{public}@' to: '%{public}@', error: %{public}@
Successfully upgraded poster configuration from: '%{public}@' to: '%{public}@'
Upgrading poster media: SETTING .hasInactiveContent
Upgrading poster media: CLEARING .hasInactiveContent
Upgrading poster media: %{public}@
Successfully upgraded poster media: %{public}@
Failed to upgraded poster media: %{public}@, error: %{public}@
Failed to upgrade %lu poster media
Successfully upgraded %lu poster media
Successfully upgraded poster configuration from '%{public}@' to '%{public}@'
Failed to save poster configuration to '%{public}@', error: %{public}@
Failed to apply red eye repair. error: %{public}@
PIPortraitAutoCalculator getMinMaxSimulatedAperture returned error:%i (minAperture:%f maxAperture:%f version:%d)
Cant get focusRect - Metadata dictionary missing fullSizeWith or fullSizeHeight:
Cant get focusRect - Metadata dictionary missing exif aux dictionary:
Cant get focusRect - Exif aux dictionary missing MWG region dictionary:
Cant get focusRect - MWG region dictionary missing region list:
Cant get focusRect - Region list does not contain a focus rect:
Cant get focusRect - Malformed focus rect dictionary:
Invalid focus rect: {%g,%g,%g,%g}
Couldn't deserialize face observations from metadata: %@, assuming empty, error: %@.
Invalid face indexes from metadata: %@, ignored. Error: %@
Couldn't deserialize face observations from metadata: %@
s-curve black: %f
s-curve point %d: (%f, %f)
s-curve white: %f
red curve: blackPoint = %f, whitePoint = %f
green curve: blackPoint = %f, whitePoint = %f
blue curve: blackPoint = %f, whitePoint = %f
Initializer not available: -[%@ %@], use designated initializer instead.
-[PIParallaxInfillJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxInfillRequest.m
Missing matte image
Invalid matte image size
Invalid matte image
Output image must not be nil
-[PIParallaxInfillJob render:]
Matte image must not be nil
Failed to generate background infill image
Failed to allocate buffer from pool
failed to render
Invalid parameter not satisfying: %s
-[PITapToTrackRenderJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PITapToTrackRequest.m
No metal device for request
Failed to find output video asset
Failed to make asset reader for video
Failed to read first frame for video
Failed to find rect to track at initial point
Failed to add detection and start tracking
Failed to get finalized track from tracking session
kernel vec4 _hdrOffsetPosBW(sampler image) { vec4 im = sample(image, samplerCoord(image)); float offset = (im.r + im.g + im.b) / 3.0f; offset = max(0.0f, offset - 1.0f); return vec4(offset, offset, offset, 0.0f); }
kernel vec4 _hdrOffsetPos(sampler image) { vec4 im = sample(image, samplerCoord(image)); float r = max(im.r - 1.0f, 0.0f); float g = max(im.g - 1.0f, 0.0f); float b = max(im.b - 1.0f, 0.0f); return vec4(r, g, b, 0.0f); }
s_hdrOffsetPos kernel is nil
+[PIPhotoEffectHDR kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PIPhotoEffectHDR.m
inputImage cannot be nil
-[PIPhotoEffectHDR outputImage]
inputImage
CIAdditionCompositing
inputBackgroundImage
s_hdrOffsetPosBlackAndWhite kernel is nil
+[PIPhotoEffectBlackAndWhiteHDR kernelBlackAndWhite]_block_invoke
-[PIPhotoEffectBlackAndWhiteHDR outputImage]
+[PIPhotoEffect3DHDR kernel]_block_invoke
-[PIPhotoEffect3DHDR outputImage]
inputThreshold
inputDepthMap
+[PIPhotoEffect3DBlackAndWhiteHDR kernelBlackAndWhite]_block_invoke
-[PIPhotoEffect3DBlackAndWhiteHDR outputImage]
PhotoImaging
PIColorNormalizationFilter
PITempTintFilter
temperature
inputTemperature
tint
inputTint
PIHighKey
CISmartToneFilter
CISmartColorFilter
normalization != nil
+[PIColorNormalizationFilter colorCubeForNormalization:dimension:targetColorSpace:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIColorNormalizationFilter.m
colorSpace != NULL
PIColorNormalization
candidateForStill
candidateForVideo
candidateForReframe
candidateForPerspective
candidateForHorizon
addRule exception : %@
v24@?0@"NSString"8@?<v@?@"NURuleSystem">16
v24@?0@"NSString"8@"NSString"16
isStitched
validSubjects
hasHorizonLine
hasBuilding
state.stitched == true OR state.perfectlyStitched == true
state.stitchConfidence < $StitchConfidenceThreshold
state.buildingCount > 0
state.buildingConfidence > $BuildingConfidenceThreshold
state.subjectCount >= $SubjectCountMinThreshold
state.allSubjectsInsidePrimaryBounds == true
(state.subjectCount - state.intersectingSubjectCount) > $MaxDisparateSubjects
state.largeSubjectFace == true
state.largestSubjectArea <= $MinimumSubjectSize
state.horizonLinePresent == true
state.horizonLineAngleInDegrees < -$HorizonAngleInDegreesMaxThreshold OR state.horizonLineAngleInDegrees > $HorizonAngleInDegreesMaxThreshold
state.horizonLineAngleInDegrees > -$HorizonAngleInDegreesMinThreshold AND state.horizonLineAngleInDegrees < $HorizonAngleInDegreesMinThreshold
state.video == true
state.videoDuration < $VideoDurationLowerBound
state.videoDuration > $VideoDurationUpperBound
(state.videoDuration * $VideoDurationWithSubjectsRatio) > state.videoDurationWithSubjects
state.videoQualityScore < $VideoQualityScoreThreshold
(state.videoDuration * $VideoDurationBelowMinZoomRatio) < state.videoDurationBelowMinZoom
facts.isStitched == true AND facts.validSubjects == true
facts.isStitched == true AND facts.hasBuilding == true
facts.isStitched == true AND facts.hasHorizonLine == true
state.largeSubject == true
state.backFacing == false
state.deviceIsStationary == true
state.video == true AND state.livePhoto == true
state.pano == true
state.reframingAllowed == false
state.hasAdjustments == true
facts.candidateForStill == true
facts.candidateForVideo == true
platedFood
sunriseSunset
genericLandscape
intensity
sceneLabel
sceneConfidence
faceBoundingBoxes
boundingBoxes
-[PIDisparitySampleJob render:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIDisparitySampleRequest.m
Failed to read video frame
Incompatible disparity buffer
inputStrength
inputScale
vec3 localContrast(vec3 im, vec3 shc, float amt) { float midAmt = amt; vec3 neg = min(im, 0.0); vec3 pos = max(im, 1.0)-1.0; im = clamp(im, 0.0, 1.0); float y = dot(im, vec3(0.3333)); y = sqrt(y); y = y*(1.0-y); im = sqrt(im); float pivot = sqrt(shc.g); float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + im.g * vec3(0.587*a) + im.b * vec3(0.114*a) + im + vec3(b); im = mix(im, vec3(pivot), -y*midAmt); im = mix(im, pix, 0.8); im = max(im, 0.0); im *= im; im = im + neg + pos; return im; } vec3 localContrastHLG(vec3 im, vec3 shc, float hlg_scale, float amt) { return localContrast(im.rgb/hlg_scale, shc.rgb/hlg_scale, amt).rgb * hlg_scale; } kernel vec4 _localContrastHDR(__sample im, __sample shc, float hlg_scale, float amt) { float max_comp = max(im.r,max(im.g,im.b)); float threshold = 0.75 * hlg_scale; if (max_comp <= 1.0) { im.rgb = localContrast(im.rgb, shc.rgb, amt); } else if (max_comp < threshold) { vec3 retSDR = localContrast(im.rgb, shc.rgb, amt); vec3 retHDR = localContrastHLG(im.rgb, shc.rgb, hlg_scale, amt); float lerp_t = (max_comp - 1.0) / (threshold - 1.0); im.rgb = mix(retSDR, retHDR, lerp_t); } else { im.rgb = localContrastHLG(im.rgb, shc.rgb, hlg_scale, amt); } return im; }
CIColorMatrix
inputRVector
inputGVector
inputBVector
inputAVector
inputBiasVector
CIColorClamp
inputMinComponents
inputMaxComponents
CIEdgePreserveUpsampleFilter
inputSmallImage
inputSpatialSigma
inputLumaSigma
intermediate.visibleRect.size.width >= 1
-[PIParallaxLayoutHelper intermediateWithZoomStrategy:intermediate:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationLayout.m
overlapStrategy != PFParallaxUtilityOverlapForceMetadataAvoid
-[PIParallaxLayoutHelper intermediateWithOverlapStrategy:intermediate:]
<%@:%p accept=%@ pref=%@ faces=%@ pets=%@>
regions != nil
+[PISegmentationLayoutRegions dictionaryFromRegions:]
@"NSDictionary"40@?0{CGRect={CGPoint=dd}{CGSize=dd}}8
@"NSArray"16@?0@"NSArray"8
acceptable
preferred
faces
pets
+[PISegmentationLayoutRegions regionsFromDictionary:error:]
B24@?0@8^{CGRect={CGPoint=dd}{CGSize=dd}}16
Expected a rect value
B24@?0@"NSArray"8@"NSMutableArray"16
Expected an array of rect values
layoutConfiguration != nil
+[PISegmentationLayout generateLayoutForLayoutConfiguration:imageSize:regions:parallaxClassification:context:matte:layoutScore:cropScore:clockOverlapAcceptable:]
layoutConfiguration.screenSize.height > 0
imageSize.height > 0
<%@:%p layerOrder:%@ intersectsForeground:%@>
-[_PIParallaxClockLayoutJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxClockLayoutRequest.m
Missing segmentation item
-[_PIParallaxClockLayoutJob prepare:]
Missing parallax layout
Missing renderer
-[_PIParallaxClockLayoutJob render:]
This is an abstract method! Subclass '%@' should provide concrete implementation
-[PIParallaxClockLayoutRequest initWithComposition:]
-[PIParallaxClockLayoutRequest initWithSegmentationItem:]
kernel vec4 highKey(__sample im, float str)
vec3 neg = min(im.rgb, 0.0);
vec3 pos = max(im.rgb, 1.0) - 1.0;
im = clamp(im, 0.0, 1.0);
vec4 im2 = 1.0-((im-1.0)*(im-1.0));
im2 = sqrt(im2);
float y = dot(im.rgb, vec3(.333333));
float y2 = sqrt(1.0-(y-1.0)*(y-1.0));
y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5);
vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0);
im3 = mix(im3, im2, .7*sqrt(y2));
im3 = mix(im, im3, sqrt(y));
im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg;
return im;
high key kernel is nil
+[PIHighKey kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIHighKey.m
-[PIHighKey outputImage]
inputStrength cannot be nil
/System/Library/Frameworks/CoreImage.framework/inp_gen_eds2_00_q16.espresso.weights
CIInpaintingFilter
inputInpaintingMode
Metal unavailable
inputTexture != nil
+[PIParallaxInwardFillKernel fillSourceTexture:intoDestinationTexture:withCommandBuffer:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationInfillFilter.m
outputTexture != nil
commandBuffer != nil
Missing input texture
-[PIParallaxInwardFillKernel encodeToCommandBuffer:destinationTexture:]
Failed to allocate intermediate texture
pi::inward_fill_down
pi::inward_fill_up
LumaHueChroma
HueTone
v24@?0Q8^B16
version
mode
primaryColors
secondaryColors
suggestionIndices
url != nil
+[PIParallaxColorPalette loadPaletteFromURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorPalette.m
Failed to parse color palette plist data
+[PIParallaxColorPalette _paletteWithConfigurationDictionary:error:]
Invalid version number
Unsupported palette version
Invalid mode value
Invalid primary color values
Invalid secondary color values
Invalid suggestion indices
Invalid suggestion index
Missing suggestion indices
Unknown color mode: %@
+[PIParallaxColorPalette _serializeColors:mode:]
colorValues != nil
+[PIParallaxColorPalette _loadColorsFromValues:mode:error:]
Invalid color values
primaryColors != nil
-[PIParallaxColorPalette initWithPrimaryColors:secondaryColors:suggestionIndices:]
secondaryColors != nil
suggestionIndices != nil
suggestionIndices.lastIndex < primaryColors.count
Secondary color palette should be empty or equal in size to the primary palette
ColorBGPalette
ColorWashSinglePalette
ColorWashDuotonePalette
plist
Failed to load color palette '%@', error: %@
+[PIParallaxColorPalette loadPaletteWithName:]
Tonal colors: %@
B16@?0Q8
The palette can't be empty
-[PIParallaxColorPalette _lookupColor:withPredicate:]
Failed to find a nearest color
smartTone
smartColor
smartBlackAndWhite
grain
autoEnhance
whiteBalance
cropStraighten
redEye
apertureRedEye
depthEffect
livePhotoKeyFrame
videoPosterFrame
trim
slomo
portraitEffect
orientation
autoLoop
highResFusion
retouch
vignette
sharpen
noiseReduction
definition
curves
levels
selectiveColor
effect
effect3D
mute
rawNoiseReduction
source
videoReframe
debug
sourceSelect
sourceSpatialOvercapture
portraitVideo
videoStabilize
videoCrossfadeLoop
semanticEnhance
enabled
value
primary
PICompositionController(%p): %@
v16@?0@"PISmartToneAdjustmentController"8
com.apple.photo
adjustmentFormatIdentifier
adjustmentFormatVersion
adjustmentData
PICompositionSerializer.m
Invalid parameter not satisfying: %@
adjustments
metadata
file://dummy.jpg
dummy
identifier
PICompositionSerializerDomain
Missing identifierName
Missing definition in conversion map for the adjustment key: 
settings
Unsupported adjustment: 
Configuration does not support Aperature adjustments.
Configuration does not support CTM adjustments.
nil identifierName
inputKeys
omitIfDisabled
Orientation
PICompositionSerializer-geometry
Invalid adjustment stack for needsGeometry=NO
masterWidth
masterHeight
Serialization map has no entry for %@
+[PICompositionSerializer serializeComposition:versionInfo:serializerMetadata:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/Conversion/PICompositionSerializer.m
Serialization map does not contain identifierName
current
auto
formatIdentifier
formatVersion
versionInfo
Missing required key: %@
Value for key %@ has type %@; expected type %@
v32@?0@"NSString"8#16^B24
PICompositionSerializer
exception
dictionary
data is not an NSData: %@: %@
Adjustment for %@ is identity
+[PICompositionSerializer _sanitizeComposition:]
composition
CFBundleVersion
platform
buildNumber
appVersion
schemaRevision
kernel vec4 levelsHDR (sampler src, sampler LUT) { vec4 p,r; vec2 c1,c2; float f; p = sample(src, samplerCoord(src)); vec3 neg = min(p.rgb, 0.0); vec3 pos = max(p.rgb, 1.0)-1.0; p.rgb = clamp(p.rgb, 0.0, 1.0); f = p.r * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.r = r.r; f = p.g * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.g = r.g; f = p.b * 1024; c1 = vec2(floor(f)+0.5, 0.5); c2 = vec2(ceil(f)+0.5, 0.5); r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f)); p.b = r.b; p.rgb = max(p.rgb, 0.0); p.rgb = p.rgb + pos + neg; return p; }
inputBlackSrc
inputBlackDst
inputShadowSrc
inputShadowDst
inputMidSrc
inputMidDst
inputHilightSrc
inputHilightDst
inputWhiteSrc
inputWhiteDst
inputBlackSrcRGB
inputBlackDstRGB
inputShadowSrcRGB
inputShadowDstRGB
inputMidSrcRGB
inputMidDstRGB
inputHilightSrcRGB
inputHilightDstRGB
inputWhiteSrcRGB
inputWhiteDstRGB
inputBlackSrcRed
inputBlackDstRed
inputShadowSrcRed
inputShadowDstRed
inputMidSrcRed
inputMidDstRed
inputHilightSrcRed
inputHilightDstRed
inputWhiteSrcRed
inputWhiteDstRed
inputBlackSrcGreen
inputBlackDstGreen
inputShadowSrcGreen
inputShadowDstGreen
inputMidSrcGreen
inputMidDstGreen
inputHilightSrcGreen
inputHilightDstGreen
inputWhiteSrcGreen
inputWhiteDstGreen
inputBlackSrcBlue
inputBlackDstBlue
inputShadowSrcBlue
inputShadowDstBlue
inputMidSrcBlue
inputMidDstBlue
inputHilightSrcBlue
inputHilightDstBlue
inputWhiteSrcBlue
inputWhiteDstBlue
Green
Blue
Failed converting data to RGBAh: %ld
-[PILevelsFilterHDR _LUTImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PILevelsFilterHDR.m
score
/Master/Source
data != nil
+[PIColorNormalizationAutoCalculator autoCalculatorWithImageData:orientation:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIColorNormalizationAutoCalculator.m
-[PIColorNormalizationAutoCalculator submit:]
Feature Unavailable
No color normalization available
kernel vec4 _falseColorHDRDebug(sampler image, float cutoff){   vec4 im = sample(image, samplerCoord(image));   if (im.x < 0.0 && im.y < 0.0 && im.z < 0.0) {        return vec4(0.0 , 0.6 , 0.2 , 1.0);   }   if (im.x > cutoff && im.y > cutoff && im.z > cutoff) {        return vec4(1.0 , 0.0 , 1.0 , 1.0);   }   if (im.x > cutoff || im.y > cutoff || im.z > cutoff) {        return vec4(0.6 , 0.0 , 0.6 , 1.0);   }   return im;}
s_falseColorHDRDebugKernelSource kernel is nil
+[PIFalseColorHDRDebug kernel]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/HDR/PIFalseColorHDRDebug.m
-[PIFalseColorHDRDebug outputImage]
-[PIAutoLoopExportRequest initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopRequests.m
-[PIAutoLoopExportRequest initWithComposition:destinationURL:]
Unexpected input pixel format
+[PIPortraitVideoProcessor _configureRGBColorTexture:format:isHDR:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoFilter.m
unexpected inputs
+[PIPortraitVideoProcessor processWithInputs:arguments:output:error:]
expected a device
expected a texture
aperture
focusDistance
quality
isHDR
globalMetadata
timedMetadata
Expected an input color texture
Expected an input disparity texture
colorPixelBuffer
missing direct source color pixel buffer
disparityPixelBuffer
missing direct source disparity pixel buffer
v16@?0@"<MTLCommandBuffer>"8
Invalid index
+[PIPortraitVideoProcessor formatForInputAtIndex:]
imageExtents
+[PIPortraitVideoProcessor applyWithInputImage:disparityImage:inputPixelBuffer:disparityPixelBuffer:globalMetadata:timedMetadata:aperture:focusedDisparity:quality:debugMode:isHDR:error:]
inputImage != nil || inputPixelBuffer != nil
disparityImage != nil || disparityPixelBuffer != nil
PIPortrait: cinematic renderer supports RGB10Packed
NormStabilizeInstructions
stabCropRect
Width
Height
flavor
recipe
kernel vec4 ipt_from_srgb(__sample im)
vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) +
im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) +
im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462);
lms = sign(lms)*pow(abs(lms), vec3(0.43));
vec3 ipt = lms.r * vec3(0.4,  4.455,  0.8056) +
lms.g * vec3(0.4, -4.851,  0.3572) +
lms.b * vec3(0.2,  0.396,-1.1628);
return vec4(ipt, im.a);
kernel vec4 ipt_to_srgb(__sample ipt)
vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) +
ipt.g * vec3(0.0976,-0.1139, 0.0326) +
ipt.b * vec3(0.2052, 0.1332,-0.6769);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
vec3 im = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) +
lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812);
return vec4(im, ipt.a);
kernel vec4 ipt_to_hue_chroma(__sample im)
vec4 ihc = im;
ihc.g = atan(im.b, im.g);
ihc.b = sqrt(im.g*im.g+im.b*im.b);
return ihc;
kernel vec4 ipt_from_hue_chroma(__sample ihc)
vec4 ipt = ihc;
ipt.g = ihc.b * cos(ihc.g);
ipt.b = ihc.b * sin(ihc.g);
return ipt;
kernel vec4 ipt_hue_chroma_scale_hue(__sample ihc, vec2 hso) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float hueScale = hso.x;
float hueOffset = hso.y;
hue = hueScale * hue + hueOffset;
return vec4(luma, hue, chroma, alpha);
kernel vec4 ipt_hue_chroma_filter_hue(__sample ihc, vec4 hcr) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float hueTarget = hcr.x;
float hueRange = hcr.y;
float hueModulo = hcr.z;
float chromaMin = hcr.w;
float chromaFactor = step(chromaMin, chroma);
float hueDelta = min(abs(hue - hueTarget), min(abs(hue + hueModulo - hueTarget), abs(hue - hueModulo - hueTarget)));
float hueFactor = 1.0 - smoothstep(0.0, hueRange, hueDelta);
alpha *= hueFactor * chromaFactor;
return vec4(luma, hue, chroma, alpha);
kernel vec4 ipt_hue_chroma_filter_luma(__sample ihc, vec3 hcr) {
float luma = ihc.r;
float hue = ihc.g;
float chroma = ihc.b;
float alpha = ihc.a;
float lumaTarget = hcr.x;
float lumaRange = hcr.y;
float chromaMax = hcr.z;
float chromaFactor = 1.0 - step(chromaMax, chroma);
float lumaDelta = abs(luma - lumaTarget);
float lumaFactor = 1.0 - smoothstep(0.0, lumaRange, lumaDelta);
alpha *= lumaFactor * chromaFactor;
return vec4(luma, hue, chroma, alpha);
+[PIIPTHueChromaFilter kernelNamed:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIIPTHueChromaFilter.m
ipt_hue_chroma_scale_hue
+[PIIPTHueChromaFilter normalizeHueChromaImage:]
+[PIIPTHueChromaFilter denormalizeHueChromaImage:]
ipt_from_srgb
ipt_to_srgb
ipt_to_hue_chroma
ipt_from_hue_chroma
ipt_hue_chroma_filter_hue
ipt_hue_chroma_filter_luma
-[PIVideoCrossfadeLoopNode initWithSettings:inputs:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Video Stabilization/PIVideoCrossfadeLoopNode.m
input != nil
-[PIVideoCrossfadeLoopNode initWithInput:timeRange:crossfadeDuration:startTime:]
CMTIME_IS_VALID(crossfadeDuration)
CMTIMERANGE_IS_VALID(loopTimeRange)
crossfadeDuration
startTime
loopTimeRange
-[PIVideoCrossfadeLoopNode nodeByReplayingAgainstCache:pipelineState:error:]
Missing primary video frame
video
secondary
Missing secondary video frame
CIDissolveTransition
-[PIVideoCrossfadeLoopNode _evaluateVideo:]
[[AVMutableComposition alloc] init] failed.
No input video track found
Failed to update video track when inserting the pre-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the pre-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update video track when inserting the crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update video track when inserting the post-crossfade content with source range %@ from track %@ to time %@ in track %@.
Failed to update audio track when inserting the post-crossfade content with source range %@ from track %@ to time %@ in track %@.
-[PIVideoCrossfadeLoopNode _evaluateVideoComposition:]
Unsupported video configuration
-[PIVideoCrossfadeLoopNode _evaluateAudioMix:]
time
scale
radius
falloff
Adjustment empty
-[PIAdjustmentController displayName]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PIAdjustmentController.m
-[PIAdjustmentController inputKeys]
Adjustment does not have an enabled setting
-[PIAdjustmentController enabled]
-[PIAdjustmentController setEnabled:]
Adjustment does not have an auto setting
-[PIAdjustmentController isAuto]
-[PIAdjustmentController setIsAuto:]
<%@: %p; adjustment = %@>
-[PIParallaxFilter outputForegroundImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxFilter.m
-[PIParallaxFilter outputBackgroundImage]
-[PIParallaxFilter outputMatteImage]
-[_PIParallaxClockMaterialJob render:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxClockMaterialRequest.m
Request needs either a layerStack or a segmentationItem
-[PIParallaxClockMaterialRequest initWithComposition:]
__dominantInputSettingsKey
debugMode
disparityKeyframes
apertureKeyframes
NUScaleIsValid(scale)
-[PIPortraitVideoRenderNode _targetScaleForScale:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoRenderNode.m
-[PIPortraitVideoRenderNode nodeByReplayingAgainstCache:pipelineState:error:]
state != nil
-[PIPortraitVideoRenderNode _prewarmPortraitRendererWithPipelineState:error:]
No device specified for prewarm
portraitVideoMetadata
PIPortraitVideoRenderNode: expected a valid portraitVideoMetadata sample
PIPortrait: passing YUV source buffers directly to the cinematic renderer
renderTime
renderQuality
sourceTransferFunction
useSourceBuffersDirectly
Source image isn't backed by a CVPixelBuffer
Could not get the input image
Could not get the disparityImage
Could not get the timed metadata
Could not get the source transfer function
Could not get the render time
PIFaceObservationCache
PIFaceObservationCache-newRequest
Original
StudioBright
StudioDark
ColorBGStandard
BlackWhiteHighKey
BlackWhiteStage
BlackWhiteMono
ColorWashSingle
ColorWashDuotone
Original-Inactive
StudioBright-Inactive
StudioDark-Inactive
ColorBGStandard-Inactive
BlackWhiteHighKey-Inactive
BlackWhiteStage-Inactive
BlackWhiteMono-Inactive
ColorWashSingle-Inactive
ColorWashDuotone-Inactive
The bundle should contain recipes for all known identifiers
+[PIParallaxStyleRecipeRegistry recipeForIdentifier:]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipeRegistry.m
-[PIParallaxStyleUserURLProvider init]
spatialOvercapture
spatialOvercaptureFused
Unspecified Key
Low Key
Neutral Key
High Key
SF Soft Time
SF Rounded Time
New York Time
ADT Slab Time
SF Stencil Time
SF Rail Time
+[PIParallaxStyle styleWithColorAnalysis:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyle.m
clockColor != nil
-[PIParallaxStyle initWithClockColor:colorSuggestions:]
suggestions != nil
Unknown style kind: %@
+[PIParallaxStyle defaultStyleForKind:colorAnalysis:]
+[PIParallaxStyle styleWithParameters:colorSuggestions:]
+[PIParallaxStyle styleWithBakedStyle:]
<%@: %p; parameters = %@>
-[PIParallaxStyle parameters]
-[PIParallaxStyle kind]
-[PIParallaxStyle recipeIdentifier]
-Inactive
BLACK
WHITE
B16@?0@"PFParallaxPaletteSuggestion"8
-[PIParallaxStyle configureForCategory:]
parameters != nil
+[PIParallaxOriginalStyle styleWithParameters:colorSuggestions:]
+[PIParallaxStudioStyle styleWithParameters:colorSuggestions:]
@"PFParallaxPaletteSuggestion"16@?0@"PFParallaxColor"8
backgroundColor != nil
-[PIParallaxColorBGStandardStyle initWithBackgroundColor:clockColor:colorSuggestions:]
+[PIParallaxBlackWhiteMonoStyle styleWithParameters:colorSuggestions:]
@"PFParallaxColor"24@?0@"PFParallaxColor"8@"PIParallaxColorAnalysis"16
@"PFParallaxColor"16@?0@"PFParallaxColor"8
+[PIParallaxColorWashSingleStyle styleWithParameters:colorSuggestions:]
-[PIParallaxColorWashSingleStyle initWithColor:clockColor:suggestions:]
Failed to retrieve secondary color from palette
+[PIParallaxColorWashDuotoneStyle styleWithColorAnalysis:]
+[PIParallaxColorWashDuotoneStyle styleWithParameters:colorSuggestions:]
primaryColor != nil
-[PIParallaxColorWashDuotoneStyle initWithPrimaryColor:secondaryColor:clockColor:colorSuggestions:]
secondaryColor != nil
-[PIParallaxRecipeStyle initWithIdentifier:recipe:]
<%@: %p; identifier = %@, recipe = %@>
timeValue
timeScale
%@: t=%@, v=%f
<%@ %p %@ %@ id=%lu conf=%.2f>
  bounds=%@
  expandedBounds=%@
  edgeBleed=%@
type
confidence
edgeBleed
bounds
expandedBounds
Human Face
Human Body
Cat Body
Cat Head
Dog Body
Dog Head
Salient Object
Unknown
(%.4f, %.4f, %.4f, %.4f)
minX 
minY 
maxX 
maxY 
B16@?0@"PFParallaxLayerStyle"8
<%@:%p class=%@ matte=%@ conf=%@ infill=%@ layout=%@ resource=%@ composition=%@>
archiveURL != nil
-[PIParallaxSegmentationItem saveToURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationItem.m
Failed to create archive directory
asset.resource
Failed to archive asset resource
segmentation.data.aar
Failed to archive segmentation data
-[PIParallaxSegmentationItem loadFromURL:error:]
Failed to load asset resource
Failed to load segmentation data
-[PIParallaxSegmentationItem saveAssetResourceToURL:error:]
Missing asset resource
-[PIParallaxSegmentationItem saveSegmentationDataToURL:error:]
Failed to write segmentation archive
Failed to serialize contents plist
contents.plist
Failed to archive contents plist data
Failed to write segmentation matte
matte.heic
Failed to archive segmentation matte data
Failed to write segmentation background
background.heic
Failed to archive segmentation background data
Failed to close archive file
-[PIParallaxSegmentationItem loadSegmentationDataFromURL:error:]
Failed to read segmentation archive
Failed to decode contents plist data
Expected contents.plist data
Failed to deserialize contents plist
Invalid contents plist
Failed to load contents dictionary
Failed to decode matte image data
Expected matte.heic data
Failed to read matte image data
Failed to decode background image data
Expected background.heic data
Failed to read background image data
Missing context info!
-[PIParallaxSegmentationItem contentsDictionary]
classification
hasMatte
hasBackground
regions
layout
scores
colorAnalysis
localLightData
systemVersion
sourceMode
infillAlgorithm
layoutConfiguration
segmentationDisabled
contents != nil
-[PIParallaxSegmentationItem loadContentsFromDictionary:hasMatte:hasBackground:error:]
Missing version info
Invalid version info
Unsupported version
Invalid system version info
Invalid system name
Invalid system version
Invalid system build version
Invalid source mode
Invalid segmentation disabled flag
Invalid infill algorithm
Invalid layout configuration
Failed to deserialize layout configuration
Missing classification info
Expected classification string
Missing matte image info
Expected boolean
Missing background image info
Expected regions dictionary
Failed to deserialize regions info
Expected layout dictionary
Failed to deserialize layout info
Expected score dictionary
Invalid score key
Invalid score value
Invalid color analysis info
Failed to deserialize color analysis info
styles
Expected styles array
Invalid style value
Invalid style dictionary
Unsupported style kind
Invalid local light data
+[PIParallaxSegmentationItem writeImageBuffer:toURL:error:]
Failed to encode pixel buffer
+[PIParallaxSegmentationItem readImageBufferFromURL:error:]
Failed to decode pixel buffer
+[PIParallaxSegmentationItem dataForImageBuffer:error:]
imageData != nil
+[PIParallaxSegmentationItem imageBufferFromData:error:]
cinematographyState
renderingVersionAtCapture
-[PIParallaxColorSuggester init]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorSuggester.m
analysis != nil
-[PIParallaxColorSuggester initWithColorAnalysis:]
color != nil
-[PIParallaxColorSuggester suggestedColorForColor:]
inputColor
outputColor
hueMin <= hueMax
-[PIParallaxColorSuggester addRuleWithHueMin:hueMax:suggestion:]
B16@?0@"NURuleSystem"8
v16@?0@"NURuleSystem"8
colors != nil
-[PIParallaxColorSuggester suggestedColorsForColors:fromColorPalette:]
B16@?0@"PFParallaxColor"8
homography
<%@:%p time:%@>
<%@: %p; lum = %.3f colors = %@>
-[_PIParallaxColorAnalysisJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorAnalysisRequest.m
-[_PIParallaxColorAnalysisJob prepare:]
Hue/chroma conversion failed
-[_PIParallaxColorAnalysisJob render:]
No storage pool
hue-%ld
gray-%ld
-[_PIParallaxColorAnalysisJob _beginRenderingImage:colorSpace:format:error:]
No storage allocated
hueChromaImage != nil
-[_PIParallaxColorAnalysisJob _beginRenderNormalizedHueChromaImage:targetHue:hueRange:chromaMin:error:]
PIIPTHueChromaColorFilter
inputHueTarget
inputHueRange
inputChromaMin
inputHueIsNormalized
Failed to produce filtered Hue/Chroma image
-[_PIParallaxColorAnalysisJob _beginRenderNormalizedHueChromaImage:targetGray:grayRange:chromaMax:error:]
PIIPTHueChromaGrayFilter
inputLumaTarget
inputLumaRange
inputChromaMax
-[_PIParallaxColorAnalysisJob _waitForRenderResources:]
Failed to render image
Failed to compute histogram
-[_PIParallaxColorAnalysisJob complete:]
q24@?0@"_PIParallaxRenderResource"8@"_PIParallaxRenderResource"16
luminance
foregroundLuminance
backgroundLuminance
@"NSArray"16@?0@"PFParallaxColor"8
colors
foregroundColors
backgroundColors
+[PIParallaxColorAnalysis loadFromContentsDictionary:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxColorAnalysis.m
Incompatible color analysis version
Invalid luminance value
Invalid color array
Failed to deserialize color values
PILongExposureFusionAutoCalculator-videoProperties
pre-AutoLoop
-[PILongExposureFusionAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PILongExposureFusionAutoCalculator.m
AutoLoop not supported
kind
-[PIAutoLoopAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIAutoLoopAutoCalculator.m
B32@?0@"AVMetadataItem"8Q16^B24
-[PITempTintFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PITempTintFilter.m
-[PIAutoLoopAnalysisJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+Analysis.m
unable to find video source node
-[PIAutoLoopAnalysisJob render:]
AutoLoop is not supported
-[PIVideoStabilizeRenderJob prepare:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIVideoStabilizeRequest.m
Stabilize request was cancelled
frameInstructions
rawTime
void CreateKeyframesFromHomographyDictionary(NSDictionary *__strong, NUPixelSize, NSMutableArray<PIReframeKeyframe *> *__strong, NUPixelRect *)
PIVideoStabilizeRequest.m
unexpected homography
Failure in ICSynthesizeAnalysis
Failure in ICAnalyzeInputMotion
No available analysis types were allowed
Failure in ICCalcCinematicL1Corrections
neutralGray
faceBalance
tempTint
warmTint
PIFaceBalanceAutoCalculator-imageProperties
+[PIFaceBalanceAutoCalculator calculateWithRequest:completion:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIWhiteBalanceAutoCalculators.m
CIFaceBalance
PIFaceBalanceAutoCalculator-calculate
WarmTemp
WarmTint
warmTemp
+[PIFaceBalanceAutoCalculator calculateRAWWithRequest:completion:]
PIFaceBalanceAutoCalculator-RAW-face-request
+[PIFaceBalanceAutoCalculator faceBalanceResultFromFaceObservations:request:error:]
PIWhiteBalanceAutoCalculator-face-balance
PIRAWFaceBalanceAutoCalculator.responseQueue
Failure in rendering image
OrigI
OrigQ
Warmth
Strength
WarmFace
unsupported format - incorrect white balance
+[PIFaceBalanceAutoCalculator faceBalanceFromFaceImage:forFaceRect:]
{?={?=[4d]}{?=[4d]}d}
{?=[4d]}
colorType
grayColor
-[PIWhiteBalanceAutoCalculator submit:]
PIWhiteBalanceAutoCalculator-imageProperties
PIFaceBalanceAutoCalculator.responseQueue
faceI
faceQ
faceWarmth
faceStrength
PIWhiteBalanceAutoCalculator
color
v16@?0@"<NUBuffer>"8
CIAreaAverage
PIWhiteColorCalculator-computeGreenPercentage
PIWhiteColorCalculator-grayWorld
PIWhiteColorCalculator-grayEdges
return Filter('CIEdges', { 'inputImage' : input, 'inputIntensity' : 1.0 });
Expected non-NULL pixels passed in
void customRGBtoYIQ(const CGFloat *, double *, double, double, double)
vec4 meaningBlur(vec4 im, vec4 b)
vec4 result = im;
float thresh = 0.1;
float g1 = max(max(im.r, im.g), im.b);
float g2 = dot(b.rgb, vec3(1.0/3.0));
float diff = max(g2-g1, -1.0);
diff = smoothstep(0.1-thresh, 0.1+thresh, diff);
result.rgb = mix(im.rgb, b.rgb, diff+0.5);
return result;
vec4 clarityNew(vec4 s, vec4 b, float intensity)
float sl = (s.r + s.g + s.b);
float bl = (b.r + b.g + b.b);
float dl = sl + (sl - bl) * intensity;
float mult = dl / max(sl, 0.0001);
mult = 1.571 * (mult - 1.0);
mult = mult / (1.0 + abs(mult));
mult += 1.0;
mult = clamp(mult, 1.0 - 0.5 * abs(intensity), 1.0 + 1.0 * abs(intensity));
s.rgb = s.rgb * mult;
return s;
kernel vec4 definition(sampler image, sampler blur, float intensity)
vec4 imgSample = sample(image, samplerCoord(image));
vec4 blurSample = sample(blur, samplerCoord(blur));
vec4 meaning = meaningBlur(imgSample, blurSample);
vec4 clarity = clarityNew(imgSample, meaning, intensity);
return clarity;
strength
neutral
tone
inputNeutralGamma
inputTone
inputGrain
inputHue
inputSeed
<%@:%p - priority: %@, color space: %@, scale policy: %@>
<%@:%p - priority: %@, color space: %@, scale policy: %@, video codec type: %@, bypass settings: %@, orientation as metadata: %@, hardware encoder: %@>
Export URL UTI (%@) does not match expected export format (%@)
-[PICompositionExporterImageOptions imageExportFormatForURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PICompositionExporter.m
metadataConverter must be set
-[PICompositionExporter init]
PICompositionExporter-videoProperties
Expecting HEIF/HEVC or JPEG/H264 when exporting Live Photo still and video complement
Unexpected video codec when attempting to export Live Photo
Unexpected image export format when attempting to export Live Photo
_companion
unable to prepare image properties
PICompositionExporter-image
PICompositionExporter-auxPropertiesRequest
PICompositionExporter-%@
PICompositionExporter.imageProperties.transaction
Regions
-[PICompositionExporter addVideoProperties:composition:options:error:]
Unknown autoloop flavor
PICompositionExporter-video
float luminanceWeight(vec4 pix, vec4 center, float slope)
return max(1.0 + (slope * length(pix.rgb - center.rgb)), 0.0);
vec4 bilateralRow_1(sampler src, float slope, vec2 offset1, float weight1)
float diff1;
vec2 coord;
vec4 pix1, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
diff1 = luminanceWeight(pix1, center, slope) * weight1;
return vec4(diff1 * pix1.rgb, diff1);
kernel vec4 bilateralAdd_1(sampler src, sampler sums, float slope, vec2 offset1, float weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_1(src, slope, offset1, weight1);
vec4 bilateralRow_2(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 weight1)
float diff1, diff2;
vec2 coord;
vec4 pix1, pix2, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb, diff1 + diff2);
kernel vec4 bilateralAdd_2(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_2(src, slope, offset1, offset2, weight1);
vec4 bilateralRow_3(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1)
float diff1, diff2, diff3;
vec2 coord;
vec4 pix1, pix2, pix3, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb, diff1 + diff2 + diff3);
kernel vec4 bilateralAdd_3(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_3(src, slope, offset1, offset2, offset3, weight1);
vec4 bilateralRow_4(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec4 weight1)
float diff1, diff2, diff3, diff4;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb,
diff1 + diff2 + diff3 + diff4);
kernel vec4 bilateralAdd_4(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3,
vec2 offset4, vec4 weight1, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_4(src, slope, offset1, offset2, offset3, offset4, weight1);
vec4 bilateralRow_5(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec4 weight1, float weight2)
float diff1, diff2, diff3, diff4, diff5;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb,
diff1 + diff2 + diff3 + diff4 + diff5);
kernel vec4 bilateralAdd_5(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec4 weight1, float weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_5(src, slope, offset1, offset2, offset3, offset4, offset5, weight1, weight2);
vec4 bilateralRow_6(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec4 weight1, vec2 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6);
kernel vec4 bilateralAdd_6(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec4 weight1, vec2 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_6(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, weight1, weight2);
vec4 bilateralRow_7(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7);
kernel vec4 bilateralAdd_7(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4,
vec2 offset5, vec2 offset6, vec2 offset7, vec4 weight1, vec3 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_7(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, weight1, weight2);
vec4 bilateralRow_8(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6,
vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8);
kernel vec4 bilateralAdd_8(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec4 weight1, vec4 weight2, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_8(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, weight1, weight2);
vec4 bilateralRow_9(sampler src, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5, vec2 offset6, vec2 offset7,
vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3)
float diff1, diff2, diff3, diff4, diff5, diff6, diff7, diff8, diff9;
vec2 coord;
vec4 pix1, pix2, pix3, pix4, pix5, pix6, pix7, pix8, pix9, center;
coord = destCoord();
center = sample(src, samplerCoord(src));
pix1 = sample(src, samplerTransform(src, coord + offset1));
pix2 = sample(src, samplerTransform(src, coord + offset2));
pix3 = sample(src, samplerTransform(src, coord + offset3));
pix4 = sample(src, samplerTransform(src, coord + offset4));
pix5 = sample(src, samplerTransform(src, coord + offset5));
pix6 = sample(src, samplerTransform(src, coord + offset6));
pix7 = sample(src, samplerTransform(src, coord + offset7));
pix8 = sample(src, samplerTransform(src, coord + offset8));
pix9 = sample(src, samplerTransform(src, coord + offset9));
diff1 = luminanceWeight(pix1, center, slope) * weight1.x;
diff2 = luminanceWeight(pix2, center, slope) * weight1.y;
diff3 = luminanceWeight(pix3, center, slope) * weight1.z;
diff4 = luminanceWeight(pix4, center, slope) * weight1.w;
diff5 = luminanceWeight(pix5, center, slope) * weight2.x;
diff6 = luminanceWeight(pix6, center, slope) * weight2.y;
diff7 = luminanceWeight(pix7, center, slope) * weight2.z;
diff8 = luminanceWeight(pix8, center, slope) * weight2.w;
diff9 = luminanceWeight(pix9, center, slope) * weight3;
return vec4(diff1 * pix1.rgb + diff2 * pix2.rgb + diff3 * pix3.rgb + diff4 * pix4.rgb + diff5 * pix5.rgb + diff6 * pix6.rgb + diff7 * pix7.rgb + diff8 * pix8.rgb + diff9 * pix9.rgb,
diff1 + diff2 + diff3 + diff4 + diff5 + diff6 + diff7 + diff8 + diff9);
kernel vec4 bilateralAdd_9(sampler src, sampler sums, float slope, vec2 offset1, vec2 offset2, vec2 offset3, vec2 offset4, vec2 offset5,
vec2 offset6, vec2 offset7, vec2 offset8, vec2 offset9, vec4 weight1, vec4 weight2, float weight3, float sumWeight)
vec4 sum;
sum = sample(sums, samplerCoord(sums))*sumWeight;
return sum + bilateralRow_9(src, slope, offset1, offset2, offset3, offset4, offset5, offset6, offset7, offset8, offset9,
weight1, weight2, weight3);
kernel vec4 bilateralFinalize(sampler sums)
vec4 sum;
sum = sample(sums, samplerCoord(sums));
return vec4(sum.rgb / max(sum.a, 0.001), 1.0);
kernel vec4 bilateralLoop2(sampler src, float slope, vec2 weights12)
vec2 coord;
vec4 center = sample(src, samplerCoord(src));
vec4 sum;
vec4 pix0, pix1, pix2;
vec4 pix3,       pix5;
vec4 pix6, pix7, pix8;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-2.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -1.0));
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dy;
pix3 = sample(src, coord);
coord = coord + dx;
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dy;
pix6 = sample(src, coord);
coord = coord + dx;
pix7 = sample(src, coord);
coord = coord + dx;
pix8 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights12.y);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights12.x) + sum;
sum =                                        center                            + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights12.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix7 - center)))) * (pix7 * weights12.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix8 - center)))) * (pix8 * weights12.y) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop5(sampler src, float slope, vec4 weights1245)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-4.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-1.0, -2.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 bilateralLoop11(sampler src, float slope, vec4 weights1245, vec4 weights89AD)
vec2  coord;
vec4  center = sample(src, samplerCoord(src));
vec4  sum;
vec4  pix0, pix1, pix2, pix3, pix4, pix5, pix6;
vec2 dx = samplerTransform(src, vec2( 1.0, 0.0)) - samplerTransform(src, vec2(0.0, 0.0));
vec2 dy = samplerTransform(src, vec2(-6.0, 1.0)) - samplerTransform(src, vec2(0.0, 0.0));
coord = samplerTransform(src, destCoord() + vec2(-2.0, -3.0));
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w);
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.x) + sum;
sum =                                        center                              + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.y) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.z) + sum;
pix0 = sample(src, coord);
coord = coord + dx;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
coord = coord + dx;
pix6 = sample(src, coord);
coord = coord + dx + dy;
sum = (1.0 - min(1.0, (slope * length(pix0 - center)))) * (pix0 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights1245.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights1245.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.x) + sum;
sum = (1.0 - min(1.0, (slope * length(pix6 - center)))) * (pix6 * weights89AD.w) + sum;
pix1 = sample(src, coord);
coord = coord + dx;
pix2 = sample(src, coord);
coord = coord + dx;
pix3 = sample(src, coord);
coord = coord + dx;
pix4 = sample(src, coord);
coord = coord + dx;
pix5 = sample(src, coord);
sum = (1.0 - min(1.0, (slope * length(pix1 - center)))) * (pix1 * weights89AD.w) + sum;
sum = (1.0 - min(1.0, (slope * length(pix2 - center)))) * (pix2 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix3 - center)))) * (pix3 * weights89AD.y) + sum;
sum = (1.0 - min(1.0, (slope * length(pix4 - center)))) * (pix4 * weights89AD.z) + sum;
sum = (1.0 - min(1.0, (slope * length(pix5 - center)))) * (pix5 * weights89AD.w) + sum;
return vec4(sum.rgb / sum.a, 1.0);
kernel vec4 convertFromRGBToLab(sampler src)
vec3 f;
vec4 pix, color;
pix = unpremultiply(sample(src, samplerCoord(src)));
color.xyz = pix.r * vec3(0.449695,  0.316251, 0.18452  )
+ pix.g * vec3(0.244634,  0.672034, 0.0833318)
+ pix.b * vec3(0.0251829, 0.141184, 0.922602 );
color.xyz *= vec3(1.052111, 1.0, 0.918417);
f = compare(color.xyz - 0.00885645, 7.787037 * color.xyz + 0.137931, pow(color.xyz, vec3(0.333333)));
color.r = 116.0 * f.y - 16.0;
color.g = 500.0 * (f.x - f.y);
color.b = 200.0 * (f.y - f.z);
color.rgb *= 0.005;
color.a = 1.0;
return color;
kernel vec4 convertFromLabToRGB(sampler src, sampler original)
vec3 f, cie;
vec4 color, pix, opix;
pix = sample(src, samplerCoord(src));
opix = sample(original, samplerCoord(original));
pix.rgb *= 200.0;
f.y = (pix.r + 16.0) / 116.0;
f.x = f.y + pix.g * 0.002;
f.z = f.y - pix.b * 0.005;
color.xyz = f * f * f;
cie = compare(color.xyz - 0.00885645, (f.xyz - 0.137931) / 7.787037, color.xyz);
cie *= vec3(0.95047, 1.0, 1.08883);
color.rgb = cie.x * vec3(2.95176,   -1.28951, -0.47388  )
+ cie.y * vec3(-1.0851,    1.99084,  0.0372023)
+ cie.z * vec3(0.0854804, -0.269456, 1.09113  );
color.a = opix.a;
return premultiply(color);
bilateralAdd_1
bilateralAdd_2
bilateralAdd_3
bilateralAdd_4
bilateralAdd_5
bilateralAdd_6
bilateralAdd_7
bilateralAdd_8
bilateralAdd_9
bilateralFinalize
convertFromRGBToLab
convertFromLabToRGB
points.count > 0
-[GUBilateralConvolution boundsForPointArray:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIBilateralFilter.m
bilateralLoop2
bilateralLoop5
bilateralLoop11
inputEdgeDetail
ridiculously large radius for bilateral filter
-[PIBilateralFilter outputImage]
inputPoints
inputWeights
unable to allocate convolution table in bilateral filter
com.apple.livephoto
com.apple.video
com.apple.video.slomo
.%lu
%lu.%lu%@%@
satPercentile75
satPercentile98
satPercentileG98
satAutoValue
inputVibrancy
inputCast
kernel vec4 _smartcolor_contrast_HDR (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 strength = max(strength, -0.35); 
 vec4 result; 
 result.rgb = im.rgb/(strength + 1.0 - (im.rgb*strength)) + pos; 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_contrast_darken_HDR (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 float gray = 1.0-min(dot(im.rgb, vec3(0.5, 0.7, -0.20)), 1.0); 
 vec4 result; 
 result.rgb = strength < 0.0 ? pow(im.rgb, vec3(1.0-strength*gray)) : im.rgb/(strength+1.0-(im.rgb*strength)); 
 result.rgb += pos; result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_gt1_HDR (__sample im, float amt) 
 float gray = dot(clamp(im.rgb, 0.0, 1.0), vec3(.3, .5, .2)); 
 float y = dot(clamp(im.rgb, 0.0, 1.0), vec3(.4, .2, .1)); 
 float damp = 1.0-4.0*y*(1.0-y); 
 float s = 1.0/(im.r+im.g+im.b); 
 float r = im.r*s; 
 float b = im.b*s; 
 float d = 1.0-.8*smoothstep(0.2, 0.4, r-b); 
 damp *= d; 
 damp = amt > 2.5 ? min(damp+(amt-2.5)/5.0, 1.0) : damp; 
 float sat = min(amt, 3.0); 
 vec4 result; 
 result.rgb = (im.rgb - gray)*sat + gray; 
 result.rgb = mix(im.rgb, result.rgb, damp); 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_lt1_HDR (__sample im, float amt) 
 float gray = dot(im.rgb, vec3(0.333333)); 
 im.rgb = mix(vec3(gray), im.rgb, amt); 
 return im; 
kernel vec4 _smartcolor_cast_HDR (__sample im, float lum, float grayI, float grayQ, float strength) 
 vec4 pix = clamp(im, 0.0, 1.0); 
 pix.rgb = pow(pix.rgb, vec3(.25)); 
 pix.rgb = pix.r * vec3(0.299, 0.595716, 0.211456) + 
 pix.g * vec3(0.587, -0.274453, -0.522591) + 
 pix.b * vec3(0.114, -0.321263, 0.311135); 
 vec2 grayOffset = vec2(grayI, grayQ) ; 
 vec3 result = pix.rgb; 
 float newStrength = 1.0 + (strength-1.0)*(1.0-pix.r) ; 
 result.gb = pix.gb + newStrength*grayOffset ; 
 float damp = max(min(1.0, pix.r/(lum+0.00001)),0.0) ; 
 result.rgb = mix(pix.rgb, result.rgb, damp) ; 
 pix.rgb = result.r * vec3(1.0) + 
 result.g * vec3(0.956296, -0.272122, -1.10699) + 
 result.b * vec3(0.621024, -0.647381, 1.70461); 
 pix.rgb = clamp(pix.rgb, 0.0, 1.0); 
 pix.rgb *= pix.rgb*pix.rgb*pix.rgb; 
 pix.rgb += min(im.rgb, 0.0) + max(im.rgb,1.0) -1.0; 
 return pix; 
CIVibrance
inputAmount
PISmartColorHDR-sat-histogram
Aperture
Photos
ColorNorm
inputAlgorithm
Auto-Enhance input: %llX, target: %llX
%@-%llX
*** failed to compute color normalization, ignored
PIAutoEnhanceFilter
CILocalLight
*** failed to compute smart tone statistics: %@
CISmartTone
autoValue
localAutoValue
CISmartColor
*** failed to compute smart color statistics: %@
*** failed to compute face balance statistics: %@
inputOrigI
inputOrigQ
inputWarmth
inputShadows
CILocalLightFilter
inputLocalLight
inputSmartShadows
inputLightMap
lightMap
inputLightMapWidth
lightMapWidth
inputLightMapHeight
lightMapHeight
CIHighKey
inputBrightness
inputExposure
inputContrast
inputHighlights
inputBlack
inputRawHighlights
-[PIParallaxCompoundLayerStackRequest initWithSegmentationItem:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxCompoundLayerStackRequest.m
-[PIParallaxCompoundLayerStackRequest initWithComposition:]
-[PIParallaxCompoundLayerStackRequest newRenderJob]
v16@?0@"PFParallaxLayerStack"8
v24@?0@"NSString"8Q16
v16@?0@"PFParallaxLayout"8
@"<NURenderStatistics>"16@?0@"<NURenderResult>"8
crossfadeDurationValue
crossfadeDurationTimescale
startTimeValue
startTimeTimescale
timeRangeStartValue
timeRangeStartTimescale
timeRangeDurationValue
timeRangeDurationTimescale
CIConstantColorGenerator
Failed to produce histogram for matte image
+[PISegmentationHelper histogramForSegmentationMatteImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationHelper.m
q24@?0^q8q16
CIColorThreshold
CIColorInvert
segmentationMatte != nil
+[PISegmentationHelper computeAvoidOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:outputUnsafeOverlap:context:]
+[PISegmentationHelper _computeAvoidingRect:imageSize:maxYMotion:segmentationMatte:layoutConfiguration:context:]
saliency preferred
saliency acceptable
padded
inactive
inTime
visible
device %d x %d
9:41
Semibold
bg lum
bg col %ld
fg lum
fg col %ld
Helvetica
CICircleGenerator
portraitInfo
spillMatteAllowed
legacyPosterStyle
+[PIParallaxLegacyPosterStyle applyInactiveStyleToImage:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLegacyPosterStyle.m
Inactive filter is not available
Failed to produce background image with filter
@"NUAdjustment"16@?0@"NUAdjustment"8
grayI
grayQ
grayWarmth
grayY
warmFace
-[PIOrientationAdjustmentController setOrientation:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PIOrientationAdjustmentController.m
+[PIParallaxStyleRecipeArchiver writeRecipe:toURL:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipeArchiver.m
Failed to open recipe destination file
+[PIParallaxStyleRecipeArchiver serializeRecipe:]
parameters
foreground
background
matte
+[PIParallaxStyleRecipeArchiver unarchivedStyleRecipeWithURL:error:]
Failed to open recipe source file
+[PIParallaxStyleRecipeArchiver deserializeRecipe:error:]
dictionary != nil
Missing recipe parameters
Invalid recipe parameters
Failed to deserialize recipe parameters
Missing foreground filters
Invalid foreground filters dictionary
Failed to deserialize foreground filters
Missing background filters
Invalid background filters dictionary
Failed to deserialize background filters
Missing matte filters
Invalid matte filters dictionary
Failed to deserialize matte filters
unit
Unknown parameter type: %@
+[PIParallaxStyleRecipeArchiver _serializeParameter:]
+[PIParallaxStyleRecipeArchiver _deserializeParameters:version:error:]
Invalid parameter name
Invalid parameter dictionary
v32@?0@"NSString"8@"NSDictionary"16^B24
+[PIParallaxStyleRecipeArchiver _deserializeParameter:version:error:]
Missing parameter type
Invalid parameter type
number
Missing number value
Expected a number value
Invalid unit value
Unknown unit value
Missing color values
Expected color values
Expected 4 color values
Expected 4 numbers
Expected 3 color values
Expected 3 numbers
point
Missing point values
Expected point values
Expected 2 point values
Expected 2 numbers
Missing mode value
Expected mode value
binding
Missing binding value
Expected binding value
Unrecognized parameter type
v32@?0@"PIParallaxStyleDefinition"8Q16^B24
filter
name
filters
Unknown definition type: %@
+[PIParallaxStyleRecipeArchiver _serializeDefinition:]
serializedFilters != nil
+[PIParallaxStyleRecipeArchiver _deserializeFilterDefinitions:version:error:]
Invalid definition dictionary
v32@?0@"NSDictionary"8Q16^B24
+[PIParallaxStyleRecipeArchiver _deserializeFilterDefinition:version:error:]
Missing definition type
Invalid filter definition type
filterName
Missing filter name
Invalid filter name
Missing filter parameters
Invalid filter parameters
Filed to deserialize filter parameters
Missing stack name
Invalid stack name
Missing stack filters
Invalid stack filters
Failed to deserialize stack filters
Unrecognized definition type
mdta/com.apple.quicktime.cinematic-video.rendering
mdta/com.apple.quicktime.disparity-float
mdta/com.apple.quicktime.aperture-float
mdta/com.apple.quicktime.camera-dictionary
PIPortraitVideoMetadata.m
metadataGroup != nil
outError != nil
Could not decode timed rendering data
Missing disparity rendering metadata
Missing aperture rendering metadata
v24@?0@"PTRenderPipeline"8@"<PTRenderState>"16
device != nil
-[PIPortraitVideoRenderer initWithDevice:colorSize:disparitySize:quality:debugMode:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoRenderer.m
!NUPixelSizeIsEmpty(colorSize)
!NUPixelSizeIsEmpty(disparitySize)
quality >= PTQualityPreviewLow && quality <= PTQualityExportProfessional
<%@:%p device:%@ color=%ldx%ld disparity=%ldx%ld quality=%d debug=%ld>
PIPortraitVideoRenderer.pool
B32@?0@"PIPortraitVideoRenderer"8Q16^B24
Expected _renderPipeline and _renderState to be allocated at the same time
-[PIPortraitVideoRenderer prepareToRenderWithMetadata:]
kernel vec4 _highKeyHDR(__sample im, float str) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0) - 1.0; 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0-((im-1.0)*(im-1.0)); 
 im2 = sqrt(im2); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = sqrt(1.0-(y-1.0)*(y-1.0)); 
 y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 im3 = mix(im3, im2, .7*sqrt(y2)); 
 im3 = mix(im, im3, sqrt(y)) ; 
 im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg; 
 return im; } 
None
UnexpectedRuntimeError
NoBuildingDetected
PanoAndFFCNotSupported
FacesTooLarge
ConfidenceTooLow
LimitExceeded
NotEnoughLines
CorrectedAreaIsSmall
LessThanMinimumCorrection
-[PIPerspectiveAutoCalculator initWithComposition:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIPerspectiveAutoCalculator.m
%@.%@
%@.error
%@.underlyingError
pitchError
yawError
pitchError.underlyingError
yawError.underlyingError
%@PerspectiveEvaluation-txt.DBG
%@PerspectiveLineDetection-png.DBG
Edit
PIPerspectiveAutoCalculator-debug
faces != nil
-[PIPerspectiveAutoCalculator getSizeOfAllFaces:]
-[PIPerspectiveAutoCalculator passesFaceCheck:]
PIPerspectiveAutoCalculator-faceCheck
faceSize
maxFaceSize
passesFaceCheck
Apple
front
camera
-[PIPerspectiveAutoCalculator passesImagePropertiesCheck:]
PIPerspectiveAutoCalculator-selfieAndAspectRatioCheck
aspectRatio
isSelfieCam
passesImagePropertiesCheck
-[PIPerspectiveAutoCalculator passesBuildingCheck:]
PIPerspectiveAutoCalculator-classify
minConfidence
passesBuildingCheck
-[PIPerspectiveAutoCalculator submit:]
pitch
angle
-[PIPerspectiveAutoCalculator overcaptureImageProperties:]
No overcapture
PIPerspectiveAutoCalculator-overcaptureImageProperties
-[PIPerspectiveAutoCalculator primaryImageProperties:]
PIPerspectiveAutoCalculator-primaryImageProperties
-[PIPerspectiveAutoCalculator canGenerateNewCropRect:]
preseedRoll
canGenerateNewCropRect
setToPrimary
xOrigin
yOrigin
width
height
pitch != nil
+[PIPerspectiveAutoCalculator undoOrientation:forPitch:yaw:angle:]
yaw != nil
angle != nil
-[PIPerspectiveAutoCalculator passesConfidenceCheck:error:]
passesConfidenceCheck
supported
Not supported by Core Image. Default: YES
-[PIPerspectiveAutoCalculator passesMinimumCorrectionCheck:error:]
pitchExpandTopDegrees
yawExpandLeftDegrees
rollAngleInDegreesCW
passesMinimumCorrectionCheck
minimumPitchCorrection
minimumYawCorrection
minimumAngleCorrection
-[PIPerspectiveAutoCalculator submitVerified:]
focalLength
pitchLimit
yawLimit
rollLimit
minimumPitchCorrectionArea
minimumYawCorrectionArea
CIAutoPerspective
submitVerified
debugImage
pitchCorrectionAreaCoverage
yawCorrectionAreaCoverage
ciPitchError
ciYawError
PIPerspectiveAutoCalculator-getPrimaryOrientation
Flash
FNumber
ApertureValue
ShutterSpeedValue
ExposureTime
ISOSpeedRatings
cannot set empty crop rect
-[PICropAdjustmentController setCropRect:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PICropAdjustmentController.m
constraintWidth
constraintHeight
smart
originalCrop
inputDecoderVersion
v32@?0@"NSString"8@16^B24
definitions != nil
-[PIParallaxRecipeFilter _evaluateImageWithFilterDefinitions:inputImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxRecipeFilter.m
Failed to produce an image
inputLight
offsetBlack
offsetBrightness
offsetContrast
offsetExposure
offsetHighlights
offsetLocalLight
offsetShadows
statistics
overcaptureStatistics
kernel vec4 alphaCompositing(__sample src, __sample dst, float a)
return mix(dst, src, a);
kernel vec4 dynamismMap(sampler imageMax, sampler imageMin, float logisticGain, float logisticMid) __attribute__((outputFormat(kCIFormatRGBAh)))
const float MAX_VAL = 1.74;
const float THRESHOLD = 0.05;
vec2 dc = destCoord();
vec2 sc;
sc = dc + vec2(-1,-1);
vec4 pMax00 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin00 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,0);
vec4 pMax01 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin01 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(-1,1);
vec4 pMax02 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin02 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(0,-1);
vec4 pMax10 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin10 = sample(imageMin, samplerTransform(imageMin, sc));
vec4 pMax11 = sample(imageMax, samplerTransform(imageMax, dc));
vec4 pMin11 = sample(imageMin, samplerTransform(imageMin, dc));
sc = dc + vec2(0,1);
vec4 pMax12 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin12 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,-1);
vec4 pMax20 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin20 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,0);
vec4 pMax21 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin21 = sample(imageMin, samplerTransform(imageMin, sc));
sc = dc + vec2(1,1);
vec4 pMax22 = sample(imageMax, samplerTransform(imageMax, sc));
vec4 pMin22 = sample(imageMin, samplerTransform(imageMin, sc));
float minDevCMaxNMin = distance(pMax11, pMin00);
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin01) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin02) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin10) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin11) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin12) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin20) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin21) );
minDevCMaxNMin = min( minDevCMaxNMin , distance(pMax11, pMin22) );
float minDevCMinNMax = distance(pMin11, pMax00);
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax01) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax02) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax10) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax11) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax12) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax20) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax21) );
minDevCMinNMax = min( minDevCMinNMax , distance(pMin11, pMax22) );
float outVal = min(minDevCMaxNMin , minDevCMinNMax) / MAX_VAL;
outVal = 1.0f / (1.0f + exp(-logisticGain*(outVal - logisticMid)));
vec4 outPixel = vec4(outVal, outVal, outVal, 1.0);
return outPixel;
kernel vec4 jointbilateralfilter(sampler mask, sampler guide, vec2 rad, vec3 sig) __attribute__((outputFormat(kCIFormatRh)))
vec2 coord = destCoord();
float rh = rad.x;
float rv = rad.y;
vec4 p0 = sample(mask, samplerTransform(mask, coord));
vec4 g0 = sample(guide, samplerTransform(guide, coord));
vec4 result = vec4(0.0f);
float w_sum = 0.0f;
for(float yo=-rad.y;  yo<=rad.y;  yo++) {
for(float xo=-rad.x;  xo<=rad.x;  xo++) {
vec2 dc = vec2(xo, yo);
vec4 p = sample(mask, samplerTransform(mask, coord + dc));
vec4 g = sample(guide, samplerTransform(guide, coord + dc));
float d = dot(dc, dc);
float pdif = dot(p-p0,p-p0);
float gdif = dot(g-g0,g-g0);
float w = exp(dot(sig, vec3(d,pdif,gdif)));
result += w*p;
w_sum += w;
result /= w_sum;
return vec4(result.rgb, 1.0);
kernel vec4 rgba_to_luma(__sample rgb)
const vec4 rgb2y = vec4(0.2999,0.5870,0.1140,0.0);
float luma = dot(rgb, rgb2y);
return vec4(luma, luma, luma, 1.0);
kernel vec2 warp_homography(vec3 h012, vec3 h345, vec3 h678)
vec3 coord = vec3(destCoord(), 1.f);
float norm = 1.f / dot(h678, coord);
float x = norm * dot(h012, coord);
float y = norm * dot(h345, coord);
return vec2(x,y);
kernel vec4 ncc_compute(sampler img1, sampler img2) __attribute__((outputFormat(kCIFormatR8)))
vec2 coord = destCoord();
float sum1   = float(0.0);
float sum2   = float(0.0);
float sumSq1 = float(0.0);
float sumSq2 = float(0.0);
float sumCrs = float(0.0);
float ncc;
float p1, p2;
const int halfKernel = 3;
const vec4 meanOp = vec4(1.0/3.0, 1.0/3.0, 1.0/3.0, 0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
p1 = dot(meanOp, sample(img1, samplerTransform(img1, coord + vec2(x, y))));
p2 = dot(meanOp, sample(img2, samplerTransform(img2, coord + vec2(x, y))));
sum1 += p1;
sum2 += p2;
sumSq1 += p1*p1;
sumSq2 += p2*p2;
sumCrs += p1*p2;
count += 1.0;
float denom = (sumSq1-sum1*sum1/count) * (sumSq2-sum2*sum2/count);
ncc = compare(denom, 0.0, ((sumCrs-(sum1*sum2/count)))/sqrt(denom));
ncc = max(ncc, 0.0);
return vec4(ncc, ncc, ncc, 1.0);
kernel vec4 ncc_coarse_compute(__sample ncc, vec2 edge) __attribute__((outputFormat(kCIFormatR8)))
float value = smoothstep(edge.x, edge.y, ncc.r);
return vec4(value, value, value, 1.0);
kernel vec4 blur_image_compute_3x3(sampler img)
const int halfKernel = 1;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_5x5(sampler img)
const int halfKernel = 2;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 blur_image_compute_7x7(sampler img)
const int halfKernel = 3;
vec2 coord = destCoord();
vec4 sum = vec4(0.0);
float count = 0.0;
for(int y=-halfKernel; y<=halfKernel; y++) {
for(int x=-halfKernel; x<=halfKernel; x++) {
sum += sample(img, samplerTransform(img, coord + vec2(x, y)));
count += 1.0;
sum = sum/(count);
return sum;
kernel vec4 fuse_image_compute(sampler refImg, sampler guideImg, sampler blurImg, sampler weightImg, sampler maskImg, vec2 threshold)
vec4 ref       = sample(refImg, samplerCoord(refImg));
vec4 refBlur   = ref;
vec4 guide     = sample(guideImg, samplerCoord(guideImg));
vec4 guideBlur = sample(blurImg, samplerCoord(blurImg));
float weight   = sample(weightImg, samplerCoord(weightImg)).r;
float mask     = sample(maskImg, samplerCoord(maskImg)).r;
vec3 CbCoef = vec3(-0.1726, -0.3391, 0.5117);
vec3 CrCoef = vec3(0.5115, -0.4282, -0.0830);
float CbRef   = dot(CbCoef, ref.rgb);
float CbGuide = dot(CbCoef, guideBlur.rgb);
float CrRef   = dot(CrCoef, ref.rgb);
float CrGuide = dot(CrCoef, guideBlur.rgb);
float crDiff = smoothstep(0.0, 0.2, abs(CbRef-CbGuide));
float cbDiff = smoothstep(0.0, 0.2, abs(CrRef-CrGuide));
float chDiff = smoothstep(0.0,0.3,crDiff+cbDiff);
float weight1 = (1.0-smoothstep(threshold.x,threshold.y,mask));
weight *= weight1 * (1.0-chDiff);
vec4 value = mix(ref, (0.9*(guide-guideBlur)+refBlur), weight);
return value;
jointbilateralfilter
rgba_to_luma
warp_homography
ncc_compute
ncc_coarse_compute
blur_image_compute_7x7
blur_image_compute_5x5
blur_image_compute_3x3
fuse_image_compute
CIPhotoEffectMono
Mono
CIPhotoEffectTonal
Tonal
CIPhotoEffectNoir
Noir
CIPhotoEffectFade
Fade
CIPhotoEffectChrome
Chrome
CIPhotoEffectProcess
Process
CIPhotoEffectTransfer
Transfer
CIPhotoEffectInstant
Instant
CIPhotoEffect3DVivid
3DVivid
CIPhotoEffect3DVividWarm
3DVividWarm
CIPhotoEffect3DVividCool
3DVividCool
CIPhotoEffect3DDramatic
3DDramatic
CIPhotoEffect3DDramaticWarm
3DDramaticWarm
CIPhotoEffect3DDramaticCool
3DDramaticCool
CIPhotoEffect3DSilverplate
3DSilverplate
CIPhotoEffect3DNoir
3DNoir
CIPortraitEffectBlack
Black
CIPortraitEffectBlackoutMono
BlackoutMono
CIPortraitEffectStageV2
StageV2
CIPortraitEffectStageMonoV2
StageMonoV2
CIPortraitEffectStageWhite
StageWhite
CIPortraitEffectLight
Light
CIPortraitEffectCommercial
Commercial
CIPortraitEffectContour
Contour
CIPortraitEffectStudioV2
StudioV2
CIPortraitEffectContourV2
ContourV2
%@ (preview) %a
%@ %a
+[PIPhotoEditHelper imageSourceWithURL:type:useEmbeddedPreview:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIPhotoEditHelper.m
+[PIPhotoEditHelper imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:]
+[PIPhotoEditHelper imageSourceWithCIImage:orientation:]
+[PIPhotoEditHelper videoSourceWithURL:]
photoSource != nil
+[PIPhotoEditHelper livePhotoSourceWithPhotoSource:videoSource:]
videoSource != nil
%@+%@
name != nil
+[PIPhotoEditHelper newAdjustmentWithName:]
+[PIPhotoEditHelper newAdjustmentWithIdentifier:]
+[PIPhotoEditHelper newImageRenderClientWithName:]
+[PIPhotoEditHelper geometryRequestWithComposition:]
+[PIPhotoEditHelper imagePropertiesRequestWithComposition:]
+[PIPhotoEditHelper videoPropertiesRequestWithComposition:]
targetSize.width > 0 && targetSize.height > 0
+[PIPhotoEditHelper imageRenderRequestWithComposition:fitInSize:wideGamut:]
PIPhotoEditHelper-targetSize-image
+[PIPhotoEditHelper imageRenderRequestWithComposition:fillInSize:wideGamut:]
PIPhotoEditHelper-fillSquare-image
+[PIPhotoEditHelper _imageRenderRequestWithComposition:wideGamut:]
PIPhotoEditHelper-basic-image
+[PIPhotoEditHelper videoRenderRequestWithComposition:fitInSize:]
v16@?0q8
overrideVideoEditability
v32@?0@"NSString"8@"NSString"16^B24
var image = input;
ResetTagInput('/pre-VideoReframe', image);
image = GetTag('VideoReframe');
ResetTagInput('/pre-Geometry', image);
return GetTag('/post-Geometry');
/pre-VideoReframe
VideoReframe
/pre-Geometry
/post-Geometry
/ShowOriginalSource
ResetTagInput('/pre-Geometry', input);
return GetTag('/post-Geometry');
PIPhotoEditHelper.m
inputCorrectionInfo
depthInfo
start
startScale
endScale
SkipShaderPrewarm
boostVersion
boostParams
gainMapVersion
gainMapParameters
kernel vec4 forwardBoostWithBoost(sampler image, float boost) {
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float k = 0.8;
vec3 pos = max(im.rgb, k) - k;
vec3 neg = min(im.rgb, 0.0);
neg *= 2.8;
im.rgb = clamp(im.rgb, 0.0, k);
im.rgb = ((1.0+n)*im.rgb)/(1.0+(n*im.rgb)) + neg;
im.r = pos.r > 0.0 ? (.91803 + .470304*pos.r) : im.r;
im.g = pos.g > 0.0 ? (.91803 + .470304*pos.g) : im.g;
im.b = pos.b > 0.0 ? (.91803 + .470304*pos.b) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
kernel vec4 inverseBoostWithBoost(sampler image, float boost){
vec4 im = sample(image, samplerCoord(image));
vec4 orig = im;
float n = 1.8;
float kinv = 0.91803;
vec3 pos = max(im.rgb, kinv);
vec3 neg = min(im.rgb, 0.0);
im.rgb = clamp(im.rgb, 0.0, kinv);
neg *= .35714286;
im.rgb = im.rgb/(n+1.0-(im.rgb*n)) + neg;
im.r = pos.r > kinv ? 0.8 + 2.126286*(pos.r-kinv) : im.r;
im.g = pos.g > kinv ? 0.8 + 2.126286*(pos.g-kinv) : im.g;
im.b = pos.b > kinv ? 0.8 + 2.126286*(pos.b-kinv) : im.b;
im.rgb = mix(orig.rgb, im.rgb, boost);
return im;
kernel vec4 forwardBoost3(__sample im, float boost, vec4 abcd, vec3 p0, vec3 p1) {
float a = abcd.x;
float b = abcd.y;
float c = abcd.z;
float d = abcd.w;
vec3 x = im.rgb;
vec3 f = (a * x + b) / (c * x + d);
float x0 = p0.x;
float y0 = p0.y;
float s0 = p0.z;
float a0 = y0*y0;
float c0 = y0 - s0*x0;
float d0 = s0*x0*x0;
vec3 f0 = (a0 * x) / (c0 * x + d0);
vec3 l0 = (a0 / d0) * x;
f0 = compare(x, l0, f0);
float x1 = p1.x;
float y1 = p1.y;
float s1 = p1.z;
float a1 = (1.f-y1)*(1.f-y1);
float c1 = (1.f-y1) - s1*(1.f-x1);
float d1 = s1 *(1.f-x1)*(1.f-x1);
vec3 f1 = 1.f - (a1 * (1.f - x)) / (c1 * (1.f - x) + d1);
vec3 l1 = 1.f - (a1 / d1) * (1.f - x);
f1 = compare(1.f - x, l1, f1);
f = compare(x - p0.x, f0, compare(x - p1.x, f, f1));
im.rgb = mix(im.rgb, f, boost);
return im;
kernel vec4 inverseBoost3(__sample im, float boost, vec4 abcd, vec3 p0, vec3 p1) {
float a = abcd.x;
float b = abcd.y;
float c = abcd.z;
float d = abcd.w;
vec3 y = im.rgb;
vec3 g = (d * y - b) / (a - c * y);
float x0 = p0.x;
float y0 = p0.y;
float s0 = p0.z;
float a0 = x0*x0;
float c0 = x0 - y0/s0;
float d0 = y0*y0/s0;
vec3 g0 = (a0 * y) / (c0 * y + d0);
vec3 l0 = (a0 / d0) * y;
g0 = compare(y, l0, g0);
float x1 = p1.x;
float y1 = p1.y;
float s1 = p1.z;
float a1 = (1.f-x1)*(1.f-x1);
float c1 = (1.f-x1) - (1.f-y1)/s1;
float d1 = (1.f-y1)*(1.f-y1)/s1;
vec3 g1 = 1.f - (a1 * (1.f - y)) / (c1 * (1.f - y) + d1);
vec3 l1 = 1.f - (a1 / d1) * (1.f - y);
g1 = compare(1.f - y, l1, g1);
g = compare(y - p0.y, g0, compare(y - p1.y, g, g1));
im.rgb = mix(im.rgb, g, boost);
return im;
+[PIFakeBoost kernelFB0]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIFakeBoost.m
+[PIFakeBoost kernelFB3]
properties != nil
+[PIFakeBoost boostParametersFromRawProperties:]
-[PIFakeBoost outputImageFB0]
-[PIFakeBoost outputImageFB3]
Invalid boost parameters
Invalid points parameters
boost kernel is nil
+[PIForwardFakeBoost kernelFB0]_block_invoke
+[PIForwardFakeBoost kernelFB3]_block_invoke
inverse boost kernel is nil
+[PIInverseFakeBoost kernelFB0]_block_invoke
+[PIInverseFakeBoost kernelFB3]_block_invoke
PIAttributeTypeMode
PIAttributeAvailableModes
default
metallib
Failed to load metal lib data: %@
+[PICoreImageUtilities metalLibraryData]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PICoreImageUtilities.m
AutoEnhance
AutoLoop
Crop
DepthEffect
Effect
Effect3D
Grain
HighResolutionFusion
LivePhotoKeyFrame
Mute
PortraitEffect
PortraitVideo
RedEyeBB
SelectiveColor
SemanticEnhance
SlowMotion
SmartBlackAndWhite
SmartColor
SmartTone
SourceSelect
Trim
VideoCrossfadeLoop
VideoPosterFrame
VideoStabilize
WhiteBalance
compositionName
identifierName
custom
customSerialization
customCompositionName
customIdentifierName
requiresEnabled
offsetBlackPoint
v24@?0@"NSDictionary"8@"NUAdjustment"16
v32@?0@8@16^B24
offsetSaturation
offsetCast
offsetStrength
offsetGrain
offsetTone
inputBlackAndWhite
offsetNeutralGamma
amount
seed
DGVignetteEffectOperation
Vignette
inputIntensity
inputRadius
inputFalloff
DGDefinition2Operation
Definition
RKNoiseReductionOperation
NoiseReduction
edgeDetail
RKProSharpenOperation
Sharpen
inputEdgeScale
edges
inputSharpness
@"NSString"16@?0@"NSDictionary"8
effectName
@"NSString"24@?0@"NSDictionary"8@"NUAdjustment"16
effectVersion
effectIntensity
CropStraighten
straightenAngle
DGRAWReduceNoiseOperation
RawNoiseReduction
inputDetailAmount
detail
inputCNRAmount
inputLNRAmount
RKRawDecodeOperation
inputMethodVersion
colorComponents
slope
bias
RKLevelsOperation
Levels
colorSpace
inputColorSpace
blackSrcRGB
blackDstRGB
shadowSrcRGB
shadowDstRGB
midSrcRGB
midDstRGB
hilightSrcRGB
hilightDstRGB
whiteSrcRGB
whiteDstRGB
blackSrcRed
blackDstRed
shadowSrcRed
shadowDstRed
midSrcRed
midDstRed
hilightSrcRed
hilightDstRed
whiteSrcRed
whiteDstRed
blackSrcGreen
blackDstGreen
shadowSrcGreen
shadowDstGreen
midSrcGreen
midDstGreen
hilightSrcGreen
hilightDstGreen
whiteSrcGreen
whiteDstGreen
blackSrcBlue
blackDstBlue
shadowSrcBlue
shadowDstBlue
midSrcBlue
midDstBlue
hilightSrcBlue
hilightDstBlue
whiteSrcBlue
whiteDstBlue
Generic P3
Display P3
Adobe RGB
sRGB
RKCurvesOperation
Curves
RGBCurvePoints
pointsL
redCurvePoints
pointsR
greenCurvePoints
pointsG
blueCurvePoints
pointsB
RKSelectiveColorOperation
corrections
RKRetouchOperation
Retouch
B16@?0@"NSDictionary"8
inputStrokes
hasSource
brushStroke
softness
opacity
repairEdges
sourceOffset
data
xLocation
yLocation
pressure
points
clipRect
detectedFaces
RKRedEyeOperation
ApertureRedEye
inputSpots
pointX
center
pointY
sensitivity
RedEye
allCorrections
redEyeCorrections
autoRedEyeCorrections
endTime
timeRange
rate
timescale
alignment
glassesMatteAllowed
portraitEffectFilterName
keyframes
cropFraction
analysisType
v24@?0@"NSMutableDictionary"8@"NUAdjustment"16
face
warm
inputDetectedFaces
flags
epoch
lightMapAvg
vec4 _curve_sample_HDR(float x, sampler2D table, vec2 domain, vec2 normalizer) { x = (x - domain.x) / (domain.y - domain.x); x = clamp(x, 0.0001, 0.9999); x = normalizer.x * x + normalizer.y; return texture2D(table, vec2(x, 0.5)); } kernel vec4 _curves_rgb_lum_HDR(__sample color, sampler2D table, vec2 domain, vec2 normalizer) { vec4 pixel = color; pixel.r = _curve_sample_HDR(pixel.r, table, domain, normalizer).r; pixel.g = _curve_sample_HDR(pixel.g, table, domain, normalizer).g; pixel.b = _curve_sample_HDR(pixel.b, table, domain, normalizer).b; float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11)); float lum1 = _curve_sample_HDR(lum0, table, domain, normalizer).a; float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0)); float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0); float lum_offset = lum1 - lum1c; pixel.rgb = lum_scale * pixel.rgb + lum_offset; pixel.rgb = min(pixel.rgb, 1.0); return pixel; }
-[_PIParallaxLayoutJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayoutRequest.m
Missing layout configuration
Missing layout regions
Invalid segmentation matte size
Invalid segmentation classification
Invalid segmentation confidence map size
-[_PIParallaxLayoutJob render:]
Missing output geometry
Failed to generate segmentation layout
-[_PIParallaxLayoutJob complete:]
layer stack has no background layer
none
pixels
degrees
count
logic
stack
clockFont
clockColor
<%@:%p parameters: %@
foreground:%@
 background: %@
 matte: %@>
-[PIParallaxStyleDefinition type]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxStyleRecipe.m
-[PIParallaxStyleDefinition isEqualToParallaxStyleDefinition:]
-[PIParallaxStyleDefinition evaluateWithContext:error:]
-[PIParallaxStyleFilterDefinition init]
context != nil
-[PIParallaxStyleFilterDefinition evaluateWithContext:error:]
Unknown filter
Failed to set filter parameter value
Unknown filter parameter
v32@?0@"NSString"8@"PIParallaxStyleParameter"16^B24
Failed to evaluate filter parameters
Local
inputLightMapImage
inputTargetBackgroundImage
filter produced invalid image
CILocalContrast
LocalContrast
<%@:%p filter:%@ parameters: %@>
-[PIParallaxStyleFilterStackDefinition init]
-[PIParallaxStyleFilterStackDefinition evaluateWithContext:error:]
<%@:%p stack:%@ filters:%@>
-[PIParallaxStyleParameter type]
-[PIParallaxStyleParameter evaluateWithContext:error:]
-[PIParallaxStyleParameter isEqualToParallaxStyleParameter:]
(%@, unit: %@) 
(R:%@, G:%@, B:%@, A:%@)
(X:%@, Y:%@, unit: %@)
(>%@)
-[PIParallaxStyleBindingParameter evaluateWithContext:error:]
Unable to find source for variable bound to '%@'
($%@)
_PIDynamicLocalLightMapPrepare
inputGuideImage
PILongExposureAccumulator.state
PILongExposureAccumulator.accum
Accumulation was cancelled
PILongExposureAccumulator-main-j%lld
failed to init accumulator
B16@?0@"CIRenderDestination"8
frame != nil
-[PILongExposureAccumulator accumulate:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+LongExposure.m
-[PILongExposureAccumulator _accumulate:error:]
PILongExposureAccumulator-average-j%lld
failed to render average image
v16@?0@"CIImage"8
CIBoxBlur
PILongExposureAccumulator-minimum-j%lld
failed to render minimum image
PILongExposureAccumulator-maximum-j%lld
failed to render maximum image
-[PILongExposureAccumulator writeLongExposureImage:UTI:colorSpace:error:]
-[PILongExposureAccumulator writeMaskImage:UTI:error:]
-[PILongExposureAccumulator _exportOutputImage:format:colorSpace:toURL:uti:error:]
Failed to finalize image destination
Failed to create CGImageDestinationRef
Failed to create CGImageRef
/AutoLoop/LongExposure
-[PILongExposureRegistrationJob prepare:]
return Source(composition.source, {'skipOrientation':true});
Malformed AutoLoop recipe : crop
-[PILongExposureRegistrationJob render:]
Failed to allocate intermediate pixel buffer
PILongExposureRegistrationJob-render-j%lld
PILongExposureRegistrationJob-reference-j%lld
Failed to render luma
Image registration failure (expected 1 observation)
/RAW/SushiLevel1
/Master%@
CIRedEyeCorrection
inputCameraModel
CILanczosScaleTransform
1.5.1
1.9.1
1.10
computed
overcaptureComputed
dynamic
@"NSString"16@?0@"NUAdjustment"8
SDOFRenderingVersion
convexHull
/private/var/mobile/Media/PhotoData/CaptureDebug/
Repair
Clone
RepairML
<%@: %p; min = %.2f, max = %.2f, manualMin = %.2f, manualMax = %.2f, depthMin = %.2f, depthMax = %.2f>
manualMin
manualMax
depthMin
depthMax
SegmentationScoreRanges
monochrome
assetURL
-[PIPortraitVideoDebugDetectionsRenderNode resolvedNodeWithCachedInputs:settings:pipelineState:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIPortraitVideoDebugDetectionsRenderNode.m
v20@?0B8@"NSError"12
%@-labelImageCache
-[PIPortraitVideoDebugDetectionsRenderNode _evaluateImage:]
Face
Head
Torso
Sports Ball
AutoFocus
%@ %@
%@ G:%@
kernel vec4 ipt_hue_chroma_color_wash(__sample s, vec3 c) {
float luma = s.x;
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 ipt_hue_chroma_color_wash_fixed(__sample s, vec3 c) {
float luma = (s.x <= 0.5) ? mix(0.0, c.x, 2.0*s.x) : mix(c.x, 1.0, 2.0*(s.x-0.5));
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 ipt_hue_chroma_color_wash_variable(__sample s, vec3 c) {
float x0 = 0.5;
float y0 = 0.5 + 0.75 * (c.x - 0.5);
float a = (y0 - x0) / (x0 * (1.0 - y0));
float luma = (s.x * (a + 1.0)) / (s.x * a + 1.0);
float hue = c.y;
float chroma = 0.5*(s.z+c.z);
return vec4(luma, hue, chroma, s.a);
kernel vec4 rgb_color_wash_variable(__sample s, __color c) {
float l0 = dot(c.rgb, vec3(0.299, 0.587, 0.114));
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= l0) {
cw = mix(vec3(0), c.rgb, l/l0);
} else {
cw = mix(c.rgb, vec3(1), (l-l0)/(1-l0));
return vec4(cw, 1.0);
kernel vec4 rgb_color_wash_variable_smooth(__sample s, __color c) {
float x0 = dot(c.rgb, vec3(0.299, 0.587, 0.114));
vec3 y0 = clamp(c.rgb, 0.05, 0.95);
float x = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 a = (y0 - x0) / (x0 * (1.0 - y0));
vec3 y = (x * (a + 1.0)) / (x * a + 1.0);
return vec4(y, 1.0);
kernel vec4 rgb_color_wash_fixed(__sample s, __color c) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= 0.5) {
cw = mix(vec3(0), c.rgb, 2*l);
} else {
cw = mix(c.rgb, vec3(1), 2*(l-0.5));
return vec4(cw, 1.0);
kernel vec4 rgb_color_wash_fixed_smooth(__sample s, __color c) {
float x0 = 0.5;
vec3 y0 = clamp(c.rgb, 0.05, 0.95);
float x = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 a = (y0 - x0) / (x0 * (1.0 - y0));
vec3 y = (x * (a + 1.0)) / (x * a + 1.0);
return vec4(y, 1.0);
kernel vec4 ipt_color_wash_duo(__sample s, vec3 c0, vec3 c1) {
vec3 cw = mix(c0, c1, s.x);
return vec4(cw, s.a);
kernel vec4 ipt_color_wash_duo_fixed(__sample s, vec3 c0, vec3 c1) {
vec3 cw;
cw.x = (s.x <= 0.2) ? mix(0.0, c0.x, s.x/0.2) : (s.x <= 0.8) ? mix(c0.x, c1.x, (s.x-0.2)/(0.8-0.2)) : mix(c1.x, 1.0, (s.x-0.8)/(1.0-0.8));
float x = clamp((s.x-0.2)/(0.8-0.2), 0.0, 1.0);
cw.yz = mix(c0.yz, c1.yz, x);
return vec4(cw, s.a);
kernel vec4 ipt_color_wash_duo_variable(__sample s, vec3 c0, vec3 c1) {
vec3 cw;
cw.x = (s.x <= c0.x) ? mix(0.0, c0.x, s.x/c0.x) : (s.x <= c1.x) ? mix(c0.x, c1.x, (s.x-c0.x)/(c1.x-c0.x)) : mix(c1.x, 1.0, (s.x-c1.x)/(1.0-c1.x));
float x = clamp((s.x-c0.x)/(c1.x-c0.x), 0.0, 1.0);
cw.yz = mix(c0.yz, c1.yz, x);
return vec4(cw, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo(__sample s, vec3 c0, vec3 c1) {
vec3 lhc = mix(c0, c1, s.x);
lhc.z = 0.5*(s.z+lhc.z);
return vec4(lhc, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo_fixed(__sample s, vec3 c0, vec3 c1) {
float l = (s.x <= 0.8) ? mix(c0.x, c1.x, s.x/0.8) : mix(c1.x, 1.0, (s.x-0.8)/(1.0-0.8));
float x = clamp(s.x/0.8, 0.0, 1.0);
vec2 hc = mix(c0.yz, c1.yz, x);
hc.y = 0.5*(s.z+hc.y);
return vec4(l, hc.x, hc.y, s.a);
kernel vec4 ipt_hue_chroma_color_wash_duo_variable(__sample s, vec3 c0, vec3 c1) {
float l = (s.x <= c1.x) ? mix(c0.x, c1.x, s.x/c1.x) : mix(c1.x, 1.0, (s.x-c1.x)/(1.0-c1.x));
float x = clamp(s.x/c1.x, 0.0, 1.0);
vec2 hc = mix(c0.yz, c1.yz, x);
hc.y = 0.5*(s.z+hc.y);
return vec4(l, hc.x, hc.y, s.a);
kernel vec4 rgb_color_wash_duo(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw = mix(c0.rgb, c1.rgb, l);
return vec4(cw, s.a);
kernel vec4 rgb_color_wash_duo_fixed(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= 0.75) {
cw = mix(c0.rgb, c1.rgb, l/0.75);
} else {
cw = mix(c1.rgb, vec3(1), 4*(l-0.75));
return vec4(cw, s.a);
kernel vec4 rgb_color_wash_duo_variable(__sample s, __color c0, __color c1) {
float l = dot(s.rgb, vec3(0.299, 0.587, 0.114));
float l0 = dot(c0.rgb, vec3(0.299, 0.587, 0.114));
float l1 = dot(c1.rgb, vec3(0.299, 0.587, 0.114));
vec3 cw;
if (l <= l1) {
cw = mix(c0.rgb, c1.rgb, l/l1);
} else {
cw = mix(c1.rgb, vec3(1), (l-l1)/(1-l1));
return vec4(cw, s.a);
ipt_hue_chroma_color_wash
ipt_hue_chroma_color_wash_fixed
ipt_hue_chroma_color_wash_variable
rgb_color_wash_fixed
rgb_color_wash_variable
rgb_color_wash_fixed_smooth
rgb_color_wash_variable_smooth
inputMode
HueChroma
HueChromaFixed
HueChromaVariable
RGBFixed
RGBFixedSmooth
RGBVariable
RGBVariableSmooth
MonoLight
CISoftLightBlendMode
ipt_color_wash_duo
ipt_color_wash_duo_fixed
ipt_color_wash_duo_variable
ipt_hue_chroma_color_wash_duo
ipt_hue_chroma_color_wash_duo_fixed
ipt_hue_chroma_color_wash_duo_variable
rgb_color_wash_duo
rgb_color_wash_duo_fixed
rgb_color_wash_duo_variable
inputShadowColor
inputHighlightColor
IPTFixed
IPTVariable
outputExposure
falseColorHDR
inputRAWGamutMapMax
Buffer must be RGBA16 type for red eye repairs
id<NUBuffer> computeRepairMask(__strong id<NUBuffer>, uint16_t *)
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/ApertureRedEye/PIApertureRedEye.mm
reddestx out of bounds
void seedFill(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, const uint32_t, const NSInteger, const NSInteger)
reddesty out of bounds
void applyRepairMask(__strong id<NUMutableBuffer>, __strong id<NUBuffer>, double, const uint32_t)
repairBuffer != nil
kernel vec4 facebalance(__sample src, vec2 gamma, vec3 matchMinusOrigStrength)
vec4 pix = src;
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb +=  matchMinusOrigStrength.rg;
float strength = matchMinusOrigStrength.z*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = max(pix.rgb, vec3(0.0));
pix.rgb = pow(pix.rgb, vec3(gamma.y));
return pix;
facebalance
vec4 curve_sample(float x, sampler2D table, vec2 domain, vec2 normalizer)
x = (x - domain.x) / (domain.y - domain.x);
x = clamp(x, 0.0001, 0.9999);
x = normalizer.x * x + normalizer.y;
return texture2D(table, vec2(x, 0.5));
kernel vec4 curves_rgb_lum(__sample color, sampler2D table, vec2 domain, vec2 normalizer)
vec4 pixel = color;
pixel.r = curve_sample(pixel.r, table, domain, normalizer).r;
pixel.g = curve_sample(pixel.g, table, domain, normalizer).g;
pixel.b = curve_sample(pixel.b, table, domain, normalizer).b;
float lum0 = dot(pixel.rgb, vec3(0.3, 0.59, 0.11));
float lum1 = curve_sample(lum0, table, domain, normalizer).a;
float lum1c = clamp(lum1, -8.0 * abs(lum0), 8.0 * abs(lum0));
float lum_scale = (lum0 == 0.0 ? 0.0 : lum1c / lum0);
float lum_offset = lum1 - lum1c;
pixel.rgb = lum_scale * pixel.rgb + lum_offset;
return pixel;
tableR != nil
+[PICurvesLUTFilter tableImageFromRed:green:blue:luminance:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PICurvesFilter.mm
tableG != nil
tableB != nil
tableL != nil
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
kernel vec4 colorBalance(__sample image, float colorI, float colorQ, float str, vec2 gamma)
vec4 pix = image;
vec3 neg = min(pix.rgb, 0.0);
vec3 pos = max(pix.rgb, 1.0) - 1.0;
pix.rgb = pow(clamp(pix.rgb, 0.0, 1.0), vec3(gamma.x));
pix.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
vec4 orig = pix ;
float chroma = min(1.0, 2.0*sqrt(pix.g*pix.g + pix.b*pix.b) );
pix.gb += vec2(colorI,colorQ);
float strength = str*pow(chroma, .4) ;
pix.gb = mix(orig.gb, pix.gb, strength) ;
pix.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
pix.rgb = pow(max(pix.rgb, 0.0), vec3(gamma.y));
pix.rgb += pos + neg;
return pix;
inputWarmTemp
inputWarmTint
inputHasFace
gHDRtoPP
PPtogHDR
colorBalance
-[PIColorBalanceFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PIColorBalanceFilter.m
@"NSString"16@?0@"NSString"8
CIMix
CIGammaAdjust
CIExposureAdjust
CIProSharpenEdges
PILocalContrastHDR
CILocalLightMapPrepare
CIPhotoGrain
CISmartBlackAndWhite
CIVignetteEffect
PIFalseColorHDRDebug
PIColorBalanceFilter
PIRAWFaceBalance
PINeutralGrayWhiteBalanceFilter
PIBilateralFilter
PICurvesLUTFilter
PICurvesFilter
PISelectiveColorFilter
PILevelsFilter
PIGlobalSettings
IPXRootSettings
PXSettingsArchiveKey
editSettings
PURootSettings
photoEditingSettings
PI_SEGMENT_ROUND_TRIP_PROXY
PI_SEGMENT_DISABLE_SEGMENTATION
PI_SEGMENT_INFILL_ALGO
PI_SEGMENT_TINT_LAYERS
PI_SEGMENT_DISABLE_CACHE
PI_SEGMENT_PREVIEW_DISABLE_CLOCK
PI_SEGMENT_PREVIEW_HIGH_QUALITY
PI_SEGMENT_MANUAL_GATING_LENIENCE
PI_STYLE_RECIPE_DIR_PATH
PI_USE_STYLE_RECIPE_CONFIG
PI_PARALLAX_LAYOUT_CONFIG
PI_PARALLAX_DISABLE_UPGRADE
PI_CINEMATIC_ALLOW_YUV_SOURCE
PI_CINEMATIC_ALLOW_RGB10_PACKED
PI_AUTOLOOP_EXPORT_USE_METAL
B8@?0
-[PIAutoLoopExportJob initWithVideoExportRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoopJob+Export.m
@"NUJSRenderNode"24@?0@"NUJSRenderNode"8@"JSValue"16
Invalid data type for adjustmentValue
Invalid data type for keyframes
Invalid data type for stabCropRect
input to VideoReframe cannot be nil
Unable to unwrap the input node!
-[PIJSRenderPipeline setUpContext:]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPhotosPipeline.m
Missing duration for crossfade
input to VideoCrossfadeLoop cannot be nil
{CGRect={CGPoint=dd}{CGSize=dd}}64@?0{CGSize=dd}8{CGSize=dd}24{CGSize=dd}40@"JSValue"56
OvercaptureRectForAutoCrop
Couldn't find bundle for class %@
+[NUJSRenderPipeline(PhotosPipeline) newPhotosPipeline:]
PhotosPipeline
Couldn't find the specified Pipeline
JSContext
Class getJSContextClass(void)_block_invoke
JavaScriptCoreSoftLinking.h
Unable to find class %s
void *JavaScriptCoreLibrary(void)
-[PIApertureRedEyeAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIApertureRedEyeAutoCalculator.m
PIApertureRedEyeAutoCalculator-faceDetection
pre-Adjustments
redEyeSpots
PILocalLightHDR-stats
NSNumber
kernel vec4 _shadowKernelHDR(__sample im, __sample adj, float str) { adj.r = 3.4*adj.r-1.2; vec3 neg = min(im.rgb, 0.0); vec3 pos = max(im.rgb, 1.0)-1.0; im.rgb = clamp(im.rgb, 0.0, 1.0); vec4 orig = im; float y = sqrt(dot(im.rgb, vec3(.33333))); float s = mix(0.0, adj.r, str); vec3 gain = s > 0.0 ? vec3(0.0) : vec3(s*s) * vec3(-2.75, -2.75, -2.5); im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); float m = 1.0 + 1.85*s*(max(0.1-y, 0.0)) ; im.rgb = (clamp(m*im.rgb, 0.0, 1.0)); float midAmt = s < 0.0 ? min(s*s,1.0) : 0.0; y = y*(1.0-y); im.rgb = sqrt(im.rgb); float pivot = .4; float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); im.rgb = mix(im.rgb, pix, 0.8); im.rgb = max(im.rgb, 0.0); im.rgb *= im.rgb; im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; return im; }
kernel vec4 _polyKernelHDR(__sample im, __sample adj, float str) { adj.r = 3.4*adj.r-1.2; vec3 neg = min(im.rgb, 0.0); vec3 pos = max(im.rgb, 1.0)-1.0; im.rgb = clamp(im.rgb, 0.0, 1.0); vec4 orig = im; float y = sqrt(dot(im.rgb, vec3(.33333))); float s = mix(0.0, adj.r, str); vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s); im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); im.rgb = (clamp(im.rgb, 0.0, 1.0)); float midAmt = min(str, .5); y = y*(1.0-y); im.rgb = sqrt(im.rgb); float pivot = max(adj.g, 0.5); float a = midAmt*y; float b = -pivot*a; vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); im.rgb = mix(im.rgb, pix, 0.8); im.rgb = max(im.rgb, 0.0); im.rgb *= im.rgb; im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; return im; }
-[PILocalLightFilterHDR outputImage]
PILocalLightHDR.m
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
CGRectEqualToRect([lightMapImage extent], [inputImage extent])
PILocalLightHDR
_lightMapImageFromData_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
CIEdgePreserveUpsampleRGFilter
-[PIParallaxAsset initWithFileURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxAsset.m
<%@: %p; fileURL = %@>
Asset is not local
proxy.jpg
Failed to load thumbnail image
Failed to load image properties
PIParallaxAsset.m
Unsupported
Failed to read image file
MediaAnalysis not available
v16@?0@"<NUMutableBuffer>"8
v24@?0@"<NUBufferTile>"8^B16
-[PISmartBlackAndWhiteAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PISmartBlackAndWhiteAutoCalculator.mm
PISmartBlackAndWhiteAutoCalculator-renderInputImage
Produced invalid BlackAndWhite settings, using defaults
void calculate_bw_auto_matrix_lum_contrast(__strong id<NUBuffer>, CGColorSpaceRef, MsgBlackAndWhiteSettings *)
num == w
void MsgMatrix<double>::AppendRow(const NumberType *, uint) [MatrixFloatType = double, NumberType = double]
xi < w && yi < h
MatrixFloatType &MsgMatrix<double>::operator()(size_t, size_t) [MatrixFloatType = double]
index < data.size()
inputScaleFactor
kernel vec4 _smartBlackAndWhiteHDR(__sample imageHDR, sampler2D hueImage, vec4 rgbWeights, vec4 normalizer) { float hueTableScaleFactor = rgbWeights.w; float hueImageWidth = normalizer.x; float huePixelCenter = normalizer.y; float neutralGamma = normalizer.z; float phototone = normalizer.w; float bw = dot(imageHDR.rgb / 12.0, rgbWeights.rgb); bw = clamp(bw, 0.0, 1.0); vec3 lms; lms.x = dot(imageHDR.rgb, vec3(0.3139902162, 0.6395129383, 0.0464975462)); lms.y = dot(imageHDR.rgb, vec3(0.155372406, 0.7578944616, 0.0867014186)); lms.z = dot(imageHDR.rgb, vec3(0.017752387, 0.109442094, 0.8725692246)); lms = pow(lms, vec3(0.43)); float i = dot(lms, vec3(0.4,0.4,0.2)); float p = dot(lms, vec3(4.4550,-4.8510,0.3960)); float t = dot(lms, vec3(0.8056,0.3572,-1.1628)); float chroma = sqrt(p*p+t*t); float hue = 0.5 + (atan(t, p) / 6.28318530718); vec2 huePt = vec2(hue * hueImageWidth + huePixelCenter, 0.5); float hueGamma = hueTableScaleFactor * texture2D(hueImage, huePt).a; float cd = 0.06 + 0.53 * abs(i-0.5); float lowSaturationDamp = smoothstep(0.0, 1.0, (chroma)/cd); float intensityDamp = smoothstep(0.0, 1.0, 1.0 - i); float lowLuminosityDamp = smoothstep(0.0, 1.0, 25.0 * i); float hWeight = lowSaturationDamp * intensityDamp * lowLuminosityDamp; hueGamma -= 1; hueGamma *= hWeight; hueGamma += 1; bw = pow(bw, hueGamma); float bwSDR = clamp(bw * 12.0, 0.0, 1.0); float midLumWeight = bwSDR*(1.0 - bwSDR); float grayWeight = 1.0 - smoothstep(0.0, 1.0, chroma * 10.0); float nWeight = midLumWeight * grayWeight; neutralGamma -= 1; neutralGamma *= nWeight; neutralGamma *= -2; neutralGamma += 1; bw = pow(bw, neutralGamma); bw = bw * 12.0; bw = clamp(bw, 0.0, 12.0); float df0 = 0.812379; float result; if (bw < df0) { result = 1.8031*bw*bw*bw - 2.1972*bw*bw + 1.3823*bw; } else { float scale = 12.0 - df0; float x = (bw - df0) / scale; result = 1.8031*x*x*x - 2.1972*x*x + 1.3823*x; result = result * scale + df0; result -= 0.158305860; } bw = mix(bw, result,-phototone); return vec4(bw,bw,bw,imageHDR.a); }
PIPhotoGrainHDR
inputISO
There is no need to call smartBlackAndWhiteStatistics.
Just use [CIFilter filterWithName:@"PISmartBlackAndWhiteHDR"] instead.
There is no need to call smartBlackAndWhiteAdjustmentsForValue:andStatistics:.
PICinematicVideoUtilities.m
Can't find global cinematic metadata in asset
Unexpected global rendering metadata class
-[_PIParallaxRenderCacheEntry initWithImage:format:colorSpace:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayerStackRequest.m
format != nil
space != nil
Invalid image extent
renderer != nil
-[_PIParallaxRenderCacheEntry render:error:]
layout != nil
-[_PIParallaxLayerStackScalePolicy initWithLayout:]
-[_PIParallaxLayerStackJob initWithRequest:]
-[_PIParallaxLayerStackJob effectiveLayout]
-[_PIParallaxLayerStackJob backfillScalePolicy]
-[_PIParallaxLayerStackJob prepare:]
Missing output image
MatteImage
Failed to render background layer
Failed to render foreground layer
buffer != nil
-[_PIParallaxLayerStackJob layerForBuffer:image:zPosition:identifier:]
identifier != nil
Failed to create pixel buffer
Failed to create renderDestination
-[_PIParallaxLayerStackJob cacheImage:key:format:colorSpace:]
key != nil
-[PIParallaxLayerStackRequest initWithSegmentationItem:]
-[PIParallaxLayerStackRequest initWithComposition:]
debugInput
debugMatte
debugMatteCrop
debugLocalConfidence
debugConfidenceMap
debugInfill
debugLayout
debugPreview
debugColorAnalysis
debugLayoutIntermediate_%d
-[PILevelsAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PILevelsAutoCalculator.m
PILevelsAutoCalculator-histogram
pre-Levels
-[PILevelsAutoCalculator calculateSettingsForImageHistogram:]
blackSrc
blackDst
shadowSrc
shadowDst
midSrc
midDst
hilightSrc
hilightDst
whiteSrc
whiteDst
Adjustment controller for key %@ is of class: %@, but was expected to be %@
-[PICompositionController(AdjustmentExtensions) _adjustmentControllerForKey:creatingIfNecessary:expectedClass:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Controllers/PICompositionController+AdjustmentExtensions.m
<%@:%p> [(%.3f, %.3f), %s]
editable
not editable
Warning smartToneStatistics will soon need [receiver properties] be non-nil so flash-fired state can be determined.
tonalRange
highKey
blackPoint
whitePoint
kernel vec4 _smarttone_brightness_neg_HDR (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 c.rgb = max(c.rgb, 0.0); 
 vec3 pix = pow(c.rgb, vec3(gamma)); 
 float lum = dot(c.rgb, vec3(0.39, .5, .11)); 
 vec3 pix2 = lum>0.0 ? c.rgb*pow(lum, gamma)/lum : vec3(0.0); 
 pix = mix(pix, pix2, 0.8) + neg; 
 return vec4(pix, c.a); 
kernel vec4 _smarttone_brightness_pos_HDR (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 vec3 pos = max(c.rgb, 1.0)-1.0; 
 c.rgb = clamp(c.rgb, 0.0, 1.0); 
 vec3 m = 1.0-c.rgb; 
 float a = 0.6; 
 vec4 result = c; 
 result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
 c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
 result.rgb = mix(c.rgb, result.rgb, .85); 
 result.rgb = result.rgb+neg+pos; 
 return result; 
kernel vec4 _smarttone_contrast_HDR (__sample im, float midAmt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 float sat = (im.r-y)*(im.r-y)+(im.g-y)*(im.g-y)+(im.b-y)*(im.b-y); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float a = midAmt*y; 
 float b = -0.5*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(0.5), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8+sat); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
kernel vec4 _smarttone_contrast_HDR (__sample im, float midAmt, float maxVal) 
 midAmt = midAmt / maxVal; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, maxVal) - maxVal; 
 im.rgb = clamp(im.rgb, 0.0, maxVal); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 im.rgb = sqrt(im.rgb); 
 float sat = dot(im.rgb - vec3(y), im.rgb - vec3(y)) / sqrt(maxVal); 
 y = y*(sqrt(maxVal)-y); 
 float a = midAmt*y; 
 float b = -0.5*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(0.5), -a); 
 im.rgb = mix(im.rgb, pix, clamp(0.8+sat, 0.0, 1.0)); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
kernel vec4 _smarttone_highlightcontrast_HDR (__sample pix, float highAmt, float sat) 
 float maxVal = 1.0; vec3 neg = min(pix.rgb, 0.0); 
 vec3 pos = max(pix.rgb, maxVal) - maxVal; 
 pix.rgb = clamp(pix.rgb, 0.0, maxVal); 
 float lum = clamp(dot(pix.rgb, vec3(.3333)),0.0,1.0); 
 vec3 high = pow(pix.rgb, vec3(3.0 - 2.0*highAmt)); 
 float pivot = 0.8; 
 vec3 pix1 = (high - pivot)*(4.0 - 3.0*highAmt) + pivot; 
 float h = highAmt*highAmt*highAmt*highAmt; 
 float a = (4.0 - 3.0*h); 
 vec3 pix2 = (lum-pivot)*a+pivot + high.rgb -lum; 
 high = mix(pix2, pix1, sat); 
 pix.rgb = mix(pix.rgb, high, lum*lum); 
 pix.rgb = pix.rgb + neg + pos; 
 return pix; 
kernel vec4 _rawHighlightsHDR(__sample pix, float gain) 
 vec3 high = gain*pix.rgb; 
 float lum = clamp(dot(pix.rgb, vec3(.3333)), 0.0, 1.0); 
 vec3 neg = min(high, 0.0); 
 high.rgb = mix(max(pix.rgb, 0.0), high.rgb, lum*lum) + neg; 
 return vec4(high, pix.a); 
CIHighlightShadowAdjust
inputShadowAmount
inputHighlightAmount
PISmartToneFilterHDR-histogram
componentAdd
componentMultiply
componentMin
componentMax
clear
destination
sourceOver
destinationOver
sourceIn
destinationIn
sourceOut
destinationOut
sourceAtop
destinationAtop
exclusiveOr
multiply
screen
overlay
darken
lighten
colorDodge
colorBurn
hardLight
softLight
difference
exclusion
saturation
luminosity
subtract
divide
linearBurn
linearDodge
vividLight
linearLight
pinLight
hardMix
darkerColor
lighterColor
*** Couldn't find blend kernel for blend mode '%@'
inputBlendMode
PI_LONG_EXPOSURE_FUSION_PARAMS
@"NSString"8@?0
kNCCBlurHalfSize
kNCCEdge0
kNCCEdge1
kBlendMaskThreshold0
kBlendMaskThreshold1
PI_LONG_EXPOSURE_DUMP_INTERMEDIATES
long-exp-input-image.tiff
long-exp-mask-image.tiff
long-exp-still-image.tiff
long-exp-guide-image.tiff
long-exp-ncc-map-image.tiff
long-exp-refined-mask-image.tiff
long-exp-fusion-image.tiff
-[PIModernPhotosPipeline _processedRenderNodeForComposition:input:pipelineState:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIModernPhotosPipeline.m
pipelineState != nil
LongExposure
inputSushiLevel
kCGImageSourceShouldExtendRaw
inputGamutMapMax
inputNoiseReductionDetailAmount
inputUIColorNoiseReductionAmount
inputUILuminanceNoiseReductionAmount
sharpness
inputNoiseReductionSharpnessAmount
contrast
inputNoiseReductionContrastAmount
inputNeutralTemperature
inputNeutralTint
Video
mediaComponentType
hardCropCleanAperture
defaultFrameTime
skipOrientation
Master
unsupported sourceSelect adjustment
RAW/Linear
Source
ShowOriginalSource
PIForwardFakeBoost
inputBoost
inputVersion
inputParams
Intermediate
keepCacheWhenAtOneToOne
Disparity
Image
Source does not contain depth
PortraitEffectsMatte
HairSegmentationMatte
SkinSegmentationMatte
TeethSegmentationMatte
GlassesSegmentationMatte
MeteorPlusGainMap
focusRect
inputAperture
inputFocusRect
leftEyeX
leftEyeY
rightEyeX
rightEyeY
noseX
noseY
chinX
chinY
inputLeftEyePosition
inputRightEyePosition
inputFaceMidPoint
inputChinPosition
Missing required depth settings
inputShiftmapImage
inputCalibrationData
inputAuxDataMetadata
inputOriginalSize
CIDepthEffectMakeBlurMap
inputMatteImage
inputHairImage
inputGlassesImage
inputPower
inputEV
faceLandmarks
inputFaceLandmarkArray
inputDisparity
inputMatte
inputBlurMap
inputFaceMask
inputHairMask
inputTeethMask
CIPortraitEffectV2
inputGenerateSpillMatte
inputFullSizeImage
CIPortraitEffect%@
PortraitV2-zeroStrength
PortraitV2
pre-PortraitVideo
auxiliaryImageType
nativeScale
post-PortraitVideo
inputLumaNoiseScale
lumaNoiseScale
shape
inputShape
CIDepthEffectApplyBlurMap
inputGainMap
masterSpace
pre-WB
inputIsRaw
warmth
pre-Mute
pre-LivePhotoKeyFrame
pre-Trim
pre-SloMo
SloMo
inputConfidence
inputFaceBoxArray
CIDynamicFood
inputBoundingBoxArray
sunsetOrSunrise
CIDynamicRender
Unknown sceneLabel when rendering semantic enhance adjustment
inputTargetImage
inputTime
inputSaturation
pre-Curves
inputPointsR
inputPointsG
inputPointsB
inputPointsL
inputTableImage
green
blue
spread
hueShift
inputCorrections
CIPhotoEffect%@
filterVersion
pre-VideoReframe
pre-VideoStabilize
pre-VideoCrossfadeLoop
pre-Geometry
pre-Crop
perspectiveStraighten
resetCleanAperture
{?={?=qq}{?=qq}}
projectUsingCleanAperture
{?=qq}
projectUsingOriginalSize
com.apple.quicktime.live-photo.vitality-disabled
projectUsingEstimatedCleanAperture
pre-Orientation
post-Geometry
inputCenter
post-Adjustments
PIInverseFakeBoost
Master/RAW/Linear
inputCutoff
kernel vec4 levelsNewGammaForP3 (sampler src, sampler LUT)
vec4
p,r;
vec2
c1,c2;
float
p  = sample(src, samplerCoord(src));
vec3 neg = min(p.rgb, 0.0);
vec3 pos = max(p.rgb, 1.0)-1.0;
p.rgb = clamp(p.rgb, 0.0, 1.0);
f = p.r * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.r = r.r * 4.0 - 1.0;
f = p.g * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.g = r.g * 4.0 - 1.0;
f = p.b * 255.0 + 256.0;
c1 = vec2(floor(f)+0.5, 0.5);
c2 = vec2(ceil(f)+0.5, 0.5);
r = mix(sample(LUT,samplerTransform(LUT,c1)), sample(LUT,samplerTransform(LUT,c2)), fract(f));
p.b = r.b * 4.0 - 1.0;
p.rgb = max(p.rgb, 0.0);
p.rgb = p.rgb + pos + neg;
return p;
-[PILevelsFilter _LUTImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PILevelsFilter.m
com.apple.photos.PhotoImaging
segmentation
Unbalanced call to ensureResources detected! (%ld)
+[PISegmentationLoader ensureResources]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentationLoader.m
Unbalanced call to freeResources detected! (%ld)
+[PISegmentationLoader freeResources]
-[PISegmentationLoader initWithParallaxAsset:]
PISegmentationItemLoader.state
PISegmentationItemLoader.loading
item != nil
-[PISegmentationLoader initWithSegmentationItem:parallaxAsset:]
v16@?0@"PIParallaxSegmentationItem"8
v24@?0@"PFParallaxAssetResource"8@"NSError"16
B24@?0@"NSString"8@"NSString"16
Missing composition
-[PISegmentationLoader _classify:completion:]
-[PISegmentationLoader _segment:completion:]
B32@?0@"<NUImageBuffer>"8@"<NUImageBuffer>"16Q24
v24@?0@"<NUImageBuffer>"8@"<NUImageBuffer>"16
composition != nil
-[PISegmentationLoader _performSegmentation:type:completion:]
-[PISegmentationLoader _analyzeColors:completion:]
Missing original layout
-[PISegmentationLoader _loadBackground:completion:]
-[PISegmentationLoader _loadRegions:completion:]
v32@?0@"NSArray"8@"NSArray"16@"NSError"24
-[PISegmentationLoader _performLayout:completion:]
item.composition != nil
-[PISegmentationLoader _loadLocalLightData:completion:]
resource != nil
+[PISegmentationLoader segmentationCompositionForAssetResource:]
proxyImage != NULL
+[PISegmentationLoader segmentationCompositionForProxyImage:orientation:]
imageURL != nil
+[PISegmentationLoader segmentationCompositionForImageURL:fileUTI:orientation:proxyImage:]
v16@?0@"PIOrientationAdjustmentController"8
+[PISegmentationLoader segmentationSourceForImageURL:fileUTI:orientation:proxyImage:]
currentInfo != nil
-[PISegmentationLoader _tryLoadSegmentationItemFromCache:]
B16@?0@"NSURL"8
+[PISegmentationLoader saveSegmentationItem:toURL:error:]
Invalid segmentation item: %@
+[PISegmentationLoader loadSegmentationItemFromURL:error:]
Segmentation item is incomplete
+[PISegmentationLoader saveSegmentationItem:layerStackOptions:configuration:style:layout:toWallpaperURL:completion:]
v24@?0@"PFParallaxLayerStack"8@"NSError"16
+[PISegmentationLoader generateLayerStackForItem:style:layout:options:completion:]
+[PISegmentationLoader saveSegmentationItem:layerStack:toWallpaperURL:error:]
Failed to create wallpaper directory
input.segmentation
Failed to export segmentation item
output.layerStack
Failed to export layer stack
+[PISegmentationLoader loadSegmentationItemFromWallpaperURL:error:]
Segmentation item from wallpaper is incomplete
Failed to load segmentation item from wallpaper
+[PISegmentationLoader loadLayerStackFromWallpaperURL:options:error:]
Failed to load layer stack from wallpaper
+[PISegmentationLoader renderPreviewLayerStackFromWallpaperURL:styleCategory:completion:]
+[PISegmentationLoader reloadSegmentationItemFromWallpaperURL:asset:completion:]
Null
Not available
<%@:%p %@>
-[_PIParallaxLayoutInactiveFrameJob initWithRequest:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PIParallaxLayoutInactiveFrameRequest.m
-[_PIParallaxLayoutInactiveFrameJob prepare:]
-[_PIParallaxLayoutInactiveFrameJob render:]
-[_PIParallaxLayoutInactiveFrameJob complete:]
-[PIParallaxLayoutInactiveFrameRequest initWithComposition:]
segmentationItem != nil
-[PIParallaxLayoutInactiveFrameRequest initWithSegmentationItem:]
Mirror
Adjustment
SourceSelect~1.0
enum
values
Failed to register schema %@: %@
+[PISchema sourceSelectSchema]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PISchema.m
RAW~1.0
opaque
required
+[PISchema rawSchema]
RawNoiseReduction~1.0
bool
minimum
maximum
ui_minimum
ui_maximum
+[PISchema rawNoiseReductionSchema]
SmartTone~1.0
+[PISchema smartToneSchema]
SmartColor~1.0
+[PISchema smartColorSchema]
SmartBlackAndWhite~1.0
+[PISchema smartBlackAndWhiteSchema]
Grain~1.0
+[PISchema grainSchema]
Sharpen~1.0
+[PISchema sharpenSchema]
CropStraighten~1.0
+[PISchema cropSchema]
Trim~1.0
+[PISchema trimSchema]
SlowMotion~1.0
+[PISchema slomoSchema]
LivePhotoKeyFrame~1.0
+[PISchema livePhotoKeyFrameSchema]
Mute~1.0
+[PISchema muteSchema]
VideoPosterFrame~1.0
+[PISchema videoPosterFrameSchema]
AutoLoop~1.0
+[PISchema autoLoopSchema]
HighResolutionFusion~1.0
+[PISchema highResFusionSchema]
DepthEffect~1.0
+[PISchema depthEffectSchema]
Effect3D~1.0
+[PISchema effect3DSchema]
PortraitEffect~1.0
+[PISchema portraitEffectSchema]
+[PISchema effectSchema]
iPhone
+[PISchema redEyeSchema]
array
content
compound
properties
+[PISchema apertureRedEyeSchema]
+[PISchema retouchSchema]
+[PISchema vignetteSchema]
Orientation~1.0
+[PISchema orientationSchema]
+[PISchema definitionSchema]
+[PISchema noiseReductionSchema]
grayStrength
identity
+[PISchema whiteBalanceSchema]
+[PISchema levelsSchema]
+[PISchema curvesSchema]
+[PISchema selectiveColorSchema]
VideoReframe~1.0
+[PISchema videoReframeSchema]
VideoStabilize~1.0
pixel
gyro
+[PISchema videoStabilizeSchema]
VideoCrossfadeLoop~1.0
+[PISchema videoCrossfadeLoopSchema]
Debug
+[PISchema debugSchema]
SemanticEnhance~1.0
+[PISchema semanticEnhance]
PortraitVideo~1.0
+[PISchema portraitVideoSchema]
Composition
PhotosComposition
contents
com.apple.photo:Source~1.0
reference
Retouch~1.0
WhiteBalance~1.0
RedEye~1.0
ApertureRedEye~1.0
Definition~1.0
Effect~1.0
Vignette~1.0
NoiseReduction~1.0
Levels~1.0
Curves~1.0
SelectiveColor~1.0
Debug~1.0
+[PISchema photosCompositionSchema]
failed to register %@: %@
+[PISchema registerPhotosSchema]
com.apple.mobileslideshow.reframe.photo.eligible-pass
com.apple.mobileslideshow.reframe.photo.eligible-fail
com.apple.mobileslideshow.reframe.video.eligible-pass
com.apple.mobileslideshow.reframe.video.eligible-fail
com.apple.mobileslideshow.reframe.type.photo.horizon
com.apple.mobileslideshow.reframe.type.photo.perspective
PICompositionFinalizer-primaryImageProperties
PICompositionFinalizer-overcaptureImageProperties
v16@?0@"PIAdjustmentController"8
maxCameraAutoStraightenCorrection
Capture
maxCameraVerticalPerspectiveCorrection
maxCameraHorizontalPerspectiveCorrection
maxCameraRotatePerspectiveCorrection
minHorizontalCameraPerspectiveCorrection
minVerticalCameraPerspectiveCorrection
minRotateCameraPerspectiveCorrection
enable_perspective_correction
reframe
perpsective
horizon
PICropAutoCalculator-imageProperties
-[PICropAutoCalculator undoExifOrientation:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PICropAutoCalculator.m
Source geometry has 0 size
-[PICropAutoCalculator submit:]
PICropAutoCalculator-faceDetection
{CGRect={CGPoint=dd}{CGSize=dd}}
maxAutoStraighten
filterOptions
CIAutoStraighten
straightenAngleInDegreesCCW
limitExceeded
belowMinimum
autoCrop
result
error
%@AutoCropEvaluation-txt.DBG
v16@?0@"PISourceSelectAdjustmentController"8
v16@?0@"PIAutoLoopAdjustmentController"8
PICropAutoCalculator-stitchedOvercaptureRect
+[PICropAutoCalculator(Utilities) updateCropAdjustment:after:error:]
PICropAutoCalculator-getBeforeGeometry
PICropAutoCalculator-getAfterGeometry
v16@?0@"PICropAdjustmentController"8
kernel vec4 iptLumHueSatTable(sampler image, __table sampler hueSatLumTable)
vec4 im = sample(image, samplerCoord(image)) ;
vec4 result = im;
float hueIdx = 359.0 * 0.5 * (atan(im.b, im.g)/3.1416 + 1.0);
hueIdx = clamp(hueIdx, 0.0, 359.0) + 0.5;
float hueChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).r);
float satChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).g);
float lumChange = (sample(hueSatLumTable, samplerTransform(hueSatLumTable, vec2(hueIdx,0.5))).b);
float chroma = sqrt(im.g*im.g+im.b*im.b) ;
chroma *= satChange ;
float hue = atan(im.b, im.g) + hueChange ;
vec3 adjustIm = im.rgb;
float hueAngle = hue  ;
lumChange = mix(1.0, lumChange, clamp(chroma,-0.7,0.7));
adjustIm.r *= lumChange;
adjustIm.g = chroma * cos(hueAngle) ;
adjustIm.b = chroma * sin(hueAngle) ;
result.rgb = adjustIm.rgb;
result.a = im.a ;
return result ;
kernel vec4 srgbToIPT(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, ipt;
lms = im.r * vec3(0.3139902162, 0.155372406, 0.017752387) +
im.g * vec3(0.6395129383, 0.7578944616, 0.109442094) +
im.b * vec3(0.0464975462, 0.0867014186, 0.8725692246);
lms = sign(lms)*pow(abs(lms), vec3(0.43, 0.43, 0.43));
ipt = lms.r * vec3(0.4, 4.455, 0.8056) +
lms.g * vec3(0.4, -4.851, 0.3572) +
lms.b * vec3(0.2, 0.3960, -1.1628);
return vec4(ipt, im.a);
kernel vec4 iptToSRGB(sampler image){
vec4 im = sample(image, samplerCoord(image));
vec3 lms, rgb;
lms = im.rrr +
im.g * vec3(0.09756893,-0.11387649,0.03261511) +
im.b * vec3(0.20522644, 0.13321716,  -0.67688718);
lms = sign(lms)*pow(abs(lms), vec3(1.0/.43));
rgb = lms.r * vec3( 5.472212058380287,  -1.125241895533569,   0.029801651173470) +
lms.g * vec3(-4.641960098354470, 2.293170938060623, -0.193180728257140) +
lms.b * vec3(0.169637076827974,  -0.167895202223709, 1.163647892783812);
return vec4(rgb, im.a);
kernel vec4 add_gaussian(sampler srcTable, float tableSize, float hueAmplitude, float satAmplitude, float lumAmplitude, float gaussX, float gaussSigmaSquared) {
vec2 d = destCoord();
vec4 src = sample(srcTable, samplerCoord(srcTable));
float x = d.x / (tableSize - 1.0);
float dist = min(min(abs(x - gaussX), abs(x - 1.0 - gaussX)), abs(x + 1.0 - gaussX));
float p = -((dist * dist) / (2.0 * gaussSigmaSquared));
float ep = exp(p);
float hue = hueAmplitude * ep;
float sat = satAmplitude * ep;
float lum = lumAmplitude * ep;
float h = clamp(src.r + hue, -1.0, 1.0);
float s = clamp(src.g + sat, -1.0, 1.0);
float l = clamp(src.b + lum, -1.0, 1.0);
return vec4(h,s,l,1.0);
srgbToIPT
iptToSRGB
add_gaussian
iptLumHueSatTable
PIVideoReframeNode.m
invalid crop rect
pipelineState
-[PIVideoReframeNode initWithSettings:inputs:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Render/PIVideoReframeNode.m
-[PIVideoReframeNode _evaluateVideoProperties:]
error != nil
-[PIVideoReframeNode _evaluateImageGeometry:]
Failed to get input geometry
Could not get the input geometry
Could not get the input image properties
CIPerspectiveTransform
inputTopLeft
inputTopRight
inputBottomLeft
inputBottomRight
showStabilizationWatermark
init is not a valid initializer
Invalid plist at path: %@
Time
Subjects
Type
HumanBody
HumanFace
CatBody
DogBody
-[PIVideoReframeMetadataExtractor overwriteTrackingMetadataWithPlist:]
PIVideoReframeMetadataExtractor.mm
type >= 0
Confidence
-[PIVideoReframeMetadataExtractor motionBlurVectorFromMetadata:]
-[PIVideoReframeMetadataExtractor extractMetadata]
mdataGroup.items.count == 1
0 && "unexpected metadata identifier"
0 && "unexpected metadata data type"
err == noErr
kernel vec4 convertFromRGBToYIQ(sampler src, float gamma)
vec4 pix ;
vec3 pix2;
pix = sample(src, samplerCoord(src));
pix.rgb = sign(pix.rgb)*pow(abs(pix.rgb), vec3(1.0/gamma)) ;
pix2.rgb = pix.r * vec3(0.299,  0.595716,  0.211456) +
pix.g * vec3(0.587, -0.274453, -0.522591) +
pix.b * vec3(0.114, -0.321263,  0.311135);
return vec4(pix2, pix.a);
kernel vec4 convertFromYIQToRGB(sampler src, float gamma)
vec4 color, pix;
pix = sample(src, samplerCoord(src));
color.rgb = pix.rrr +
pix.g * vec3(0.956296, -0.272122, -1.10699) +
pix.b * vec3(0.621024, -0.647381, 1.70461);
color.rgb = sign(color.rgb)*pow(abs(color.rgb), vec3(gamma, gamma, gamma) );
color.a = pix.a;
return color;
kernel vec4 whiteBalance(sampler image, float grayY, float grayI, float grayQ, float strength)
vec4 im = sample(image, samplerCoord(image)) ;
vec2 grayOffset = vec2(grayI, grayQ) ;
vec4 result ;
float newStrength = 1.0 + (strength-1.0)*(1.0-im.r) ;
result.r = im.r ;
result.gb = im.gb + newStrength*grayOffset ;
float damp = max(min(1.0, im.r/(grayY+0.00001)),0.0) ;
result.rgb = mix(im.rgb, result.rgb, damp) ;
result.a = im.a ;
return result ;
kernel vec4 gHDRtoPP(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(0.615429622407401,   0.114831839141528,   0.011544126697221) +
pix.g * vec3(0.367479646665836,   0.797943554457996,   0.064077744191180) +
pix.b * vec3(  0.016956659608091,   0.087783443422360,   0.924405601458102);
return vec4(pix2, pix.a);
kernel vec4 PPtogHDR(sampler image)
vec4 pix ;
vec3 pix2;
pix = sample(image, samplerCoord(image));
pix2 = pix.r * vec3(1.777445503202045,  -0.255296595099306,  -0.004500433755654) +
pix.g * vec3( -0.822224875430495,   1.380948853784730,  -0.085456231694984) +
pix.b * vec3(0.045475917061484,  -0.126454737973025,   1.089973874037625);
return vec4(pix2, pix.a);
convertFromRGBToYIQ
convertFromYIQToRGB
-[PINeutralGrayWhiteBalanceFilter outputImage]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/PINeutralGrayWhiteBalanceFilter.m
PISmartToneAutoCalculator
-[PISmartToneAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIAutoCalculators.mm
-[PISmartColorAutoCalculator submit:]
-[PIRedEyeAutoCalculator submit:]
PIRedEyeAutoCalculator-getLensInfo
locationX
locationY
touchDiameter
inputRect
MPSImageReduce unavailable
/masterSpace
kernel vec4 _blendGrainsHDR(__sample isoImages, float log10iso)
  vec4 c = isoImages; 
  float mix10_50    = mix(c.r, c.g, log10iso*1.43067655809 
                                           - 1.43067655809); 
  float mix50_400   = mix(c.g, c.b, log10iso*1.10730936496 
                                           - 1.88128539659); 
  float mix400_3200 = mix(c.b, c.a, log10iso*1.10730936496 
                                           - 2.88128539659); 
  float v = compare(log10iso - 1.69897000434,                     mix10_50,                     compare(log10iso - 2.60205999133,                             mix50_400,                             mix400_3200)); 
  return vec4(v,v,v,1.0);
kernel vec4 _grainBlendAndMixHDR(__sample img, __sample grainImage, float contrast, float mixAmount)
  vec3 rgb = img.rgb;
  float luminance = clamp(dot(rgb, vec3(.333333)), 0.0, 1.0); 
  float gamma = 4.01 - 2.0*luminance;
  rgb = sign(rgb) * pow(abs(rgb), vec3(1.0/gamma));
  float grain = grainImage.r - 0.5;
  float mult = contrast * grain;
  rgb += (max(luminance, 0.5) * mult * (1.0-luminance));
  rgb = sign(rgb) * pow(abs(rgb), vec3(gamma));
  rgb = min(rgb, 12.0);
  return mix(img, vec4(rgb,img.a), mixAmount);
kernel vec2 _paddedTile2(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
1536 x 1536 noise grain image prov
v56@?0^v8Q16Q24Q32Q40Q48
generateNoiseImage_block_invoke
PIPhotoGrainHDR.m
width==512*3
height==512*3
x==0
y==0
kernel vec4 _grainGenCombineHDR (__sample r, __sample g, __sample b, __sample a)
{ return vec4(r.x, g.x, b.x, a.x); }
CIUnsharpMask
Classification
LayoutConfiguration
LowResolution
DisableDownload
DisableSegmentation
DisableRendering
PetsRegions
Priority
PetsFaceRegions
Style
LayerStackOptions
OutOfProcess
WallpaperUpgradeMode
asset != nil
+[PISegmentation computeSegmentationScoresForAsset:options:completion:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Parallax/PISegmentation.m
options != nil
v24@?0@"<PISegmentationItem>"8@"NSError"16
+[PISegmentation loadSegmentationItemForAsset:options:completion:]
Invalid classification option: %@
+[PISegmentation cancelSegmentationForAsset:]
NO (timeout)
+[PISegmentation exportWallpaperForAsset:toURL:options:completion:]
wallpaperURL != nil
Segmentation failure
Invalid additionalLayerOptions: %@
+[PISegmentation _layerStackOptionsFromOptions:]
sourceURL != nil
+[PISegmentation upgradeWallpaperAtURL:exportToURL:options:completion:]
destinationURL != nil
v24@?0@"PFPosterEditConfiguration"8@"NSError"16
Not implemented yet
v16@?0@"NSError"8
Failed to load poster configuration from source URL
Failed to upgrade poster configuration from source URL
v24@?0@"PFPosterConfiguration"8@"NSError"16
PISegmentation.upgrade
Failed to upgrade some poster media
Failed to save poster configuration
v8@?0
+[PIImageIO writeImage:fileURL:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIImageIO.m
cgImage != NULL
+[PIImageIO writeCGImage:fileURL:]
fileURL != nil
Unhandled bit depth: %ld
+[PIImageIO writeCGImage:fileURL:options:]
Successfully wrote image to file %@
Failed to write image to file %@
%@-%d-%ld.tiff
GU %@ %@
Sensitivity
Bad float to fixed 16 conversion
+[PIApertureRedEyeProcessorKernel convertFloat:toFixed16:count:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/ApertureRedEye/PIApertureRedEyeFilter.mm
Bad fixed 16 to float conversion
+[PIApertureRedEyeProcessorKernel convertFixed16:toFloat:count:]
+[PIApertureRedEyeProcessorKernel processWithInputs:arguments:output:error:]
PIApertureRedEyeFilter.mm
output.format == kCIFormatRGBAf
inputSensitivity
portraitStrength
capturedPortraitMajorVersion
capturedPortraitMinorVersion
portraitDisableStage
+[PIValuesAtCapture valuesAtCaptureFromImageProperties:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PIPortraitAutoCalculator.m
Portrait was previously applied.
Failed to load depth data
Unfiltered depth data is not supported
Low quality depth data is not supported
Missing camera calibration data
Failed to load auxiliary data
Missing auxiliary metadata
Depth data version mismatch, asset has %@ but we can only handle %@
We only know up to sDOF version %d. Found: %d
<%@:%p aperture:%f minimumAperture:%@ maximumAperture:%@ portraitStrength:%f SDOFRenderingVersion:%lu portraitMajorVersion:%lu portraitMinorVersion:%lu>
-[PIPortraitAutoCalculator submit:]
PIPortraitAutoCalculator-getValuesAtCapture-imageProperties
capturedAperture
capturedPortraitStrength
v16@?0@"NUResponse"8
PIPortraitAutoCalculator-faceDetect
faceObservations != nil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:]
metadata != nil
NUOrientationIsValid(orientation)
Insufficient number of landmark points
+[PIPortraitAutoCalculator depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:]
minimumAperture
maximumAperture
+[PIPortraitAutoCalculator portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:]
faceBoundingBox
faceJunkinessIndex
faceOrientationIndex
roll
allPoints
faceContour
leftEye
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
medianLine
outerLips
innerLips
leftPupil
rightPupil
+[PIPortraitAutoCalculator portraitInfoDictionaryFromCameraMetadata:]
-[PIDepthEffectApertureAutoCalculator submit:]
PIDepthEffectApertureAutoCalculator-getValuesAtCapture-imageProperties
depthData:DepthDataVersion
var tagNode = GetTag('/pre-Adjustments');
orientation = tagNode.geometry.orientation;
var node = Orient(tagNode, orientation);
return node;
@"NURenderNode"40@?0@"NURenderPipelineHelper"8@"NUComposition"16@"NURenderNode"24^@32
/pre-Adjustments
var source = GetTag('/pre-Adjustments');
ResetTagInput('/pre-Crop', source);
source = GetTag('/Crop');
orientation = source.geometry.orientation;
source = Orient(source, orientation);
return source;
/pre-Crop
/Crop
var sourceSettings = { 'skipOrientation': true };
var rawAdjustment = composition.raw
if (rawAdjustment) {
    sourceSettings['inputDecoderVersion'] = rawAdjustment.inputDecoderVersion
var image = Source(composition.source, sourceSettings)
var rawImage = GetTagInput('RAW/Linear')
if (rawImage) {
    image = rawImage
    image = Filter('PIForwardFakeBoost', {'inputImage' : image, 'inputBoost' : 1.0,})
var orientation = composition.orientation
if (orientation) { image = Orient(image, orientation.value) }
return image
Raw/Linear
var sourceSettings = { }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
} else { throw "expected RAW in rawSourceFilterIncludingOrientation"; }
return Source(composition.source, sourceSettings); 
expected RAW in rawSourceFilterIncludingOrientation
+[PIPipelineFilters rawSourceFilterIncludingOrientation]_block_invoke
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPipelineFilters.m
var sourceSettings = { 'skipOrientation' : true }; 
var raw = composition.raw; 
if (raw) { 
  sourceSettings['inputDecoderVersion'] = raw.inputDecoderVersion; 
  var sushiLevel = raw.inputSushiLevel;
  if (sushiLevel) {
    sourceSettings['kCGImageSourceShouldExtendRaw'] = sushiLevel;
  return Source(composition.source, sourceSettings); 
} else {
  return GetTag("/ShowOriginalSource");
var source = GetTag('/pre-RedEye');ResetTagInput('/post-RedEye', source);
return GetTag('/post-RedEye');
/pre-RedEye
/post-RedEye
Could not construct noRedEye filter from inline source
+[PIPipelineFilters noRedEyeFilter]
var output = input
var preTrim = GetTag('/pre-Trim');ResetTagInput('/SloMo', preTrim);
let slomo = composition.slomo
if (slomo) {
    var startTime = TimeMake(slomo.start, slomo.startScale)
    var endTime = TimeMake(slomo.end, slomo.endScale)
    output = SloMo(input, startTime, endTime, slomo.rate)
return output;
/pre-Trim
/SloMo
Could not construct noTrimFilter filter from inline source
+[PIPipelineFilters noTrimFilter]
var preMute = GetTag('pre-Mute');ResetTagInput('Mute', preMute);
return GetTag('Image');
Could not construct noMuteFilter filter from inline source
+[PIPipelineFilters noMuteFilter]
var preCrop = GetTag('/pre-Crop');ResetTagInput('/pre-Orientation', preCrop);
return input;
/pre-Orientation
Could not construct noCropFilter filter from inline source
+[PIPipelineFilters noCropFilter]
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Adjustments', preGeometry);
return input;
/post-Adjustments
Could not construct noGeometry filter from inline source
+[PIPipelineFilters iosCropToolFilter]_block_invoke
var image = GetTag('pre-Trim');ResetTagInput('Trim', image);
image = GetTag('pre-SloMo');ResetTagInput('SloMo', image);
return input;
Could not construct stripAllTimeAdjustmentsFilter filter from inline source
+[PIPipelineFilters stripAllTimeAdjustmentsFilter]
let preGeometry = GetTag('/pre-Geometry');ResetTagInput('/post-Geometry', preGeometry);
return input;
+[PIPipelineFilters noGeometryFilter]
var preOrientation = GetTag('/pre-Orientation');ResetTagInput('/Orientation', preOrientation);
return input;
/Orientation
Could not construct noOrientationFilter filter from inline source
+[PIPipelineFilters noOrientationFilter]
return null;
Could not construct pipeline filter from source: %@
+[PIPipelineFilters orientationAsMetaDataFilter]
var preCrop = GetTag('/perspectiveStraighten');if (preCrop) {   ResetTagInput('/Crop', preCrop);
}return input;
/perspectiveStraighten
Could not construct perspectiveStraightenWithoutCropFilter filter from inline source
+[PIPipelineFilters perspectiveStraightenWithoutCropFilter]
var output = input;
var prePortraitVideoNode = GetTag('pre-PortraitVideo');
if (prePortraitVideoNode) {
    ResetTagInput('/post-PortraitVideo', prePortraitVideoNode);
return output;
/post-PortraitVideo
Could not construct histogramOptimizationFilter from inline source
+[PIPipelineFilters histogramOptimizationFilter]
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Geometry', tagNode);
return GetTag('/post-Geometry');
Could not construct stopAtTagIncludeGeometryFilter from inline source
+[PIPipelineFilters stopAtTagIncludeGeometryFilter:]
var tagNode = GetTag('%@');
if (tagNode) {
    ResetTagInput('/pre-Orientation', tagNode);
return GetTag('/Orientation');
Could not construct stopAtTagIncludeOrientationFilter from inline source
+[PIPipelineFilters stopAtTagIncludeOrientationFilter:]
var output = input;
var orientation = composition.orientation;
if (orientation) {
    output = Orient(input, orientation.value);
return output;
+[PIPipelineFilters applyOrientationFilter]
ResetTagInput('/AutoLoop/Output', GetTag('/AutoLoop/StabilizedVideo'));
return input;
/AutoLoop/Output
/AutoLoop/StabilizedVideo
Could not construct autoloopStabilizedVideoFilter filter from inline source
+[PIPipelineFilters autoloopStabilizedVideoFilter]
return Source(composition.sourceSpatialOvercapture, { 'skipOrientation' : true })
Could not construct overcaptureSourceFilter filter from inline source
+[PIPipelineFilters overcaptureSourceFilter]
return Source(composition.source, { 'skipOrientation' : true })
Could not construct primarySourceFilter filter from inline source
+[PIPipelineFilters primarySourceFilter]
return Source(composition.sourceSpatialOvercapture, {  })
+[PIPipelineFilters spatialOvercaptureVideoSourceFilter]
return input;
/PortraitV2-zeroStrength
/PortraitV2
Could not construct oneShotPortraitV2ExportFilter filter from inline source
+[PIPipelineFilters oneShotPortraitV2ExportFilter]
let output = input;
var image = GetTag('pre-VideoReframe');
if (image) {
    var videoReframe = composition.videoReframe;
    if (videoReframe && videoReframe.enabled) {
        image = VideoReframe(image, videoReframe);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('VideoReframe', image);
    }
else { // image or live-photo { 
    var crop = composition.cropStraighten;
    var image = GetTag('pre-Crop');
    if (crop && crop.smart == 1 && image) {
        if (crop.pitch || crop.yaw) {
            var perspectiveTransform = PerspectiveTransformMake(crop.angle, crop.pitch, crop.yaw, image.geometry);
            image = Transform(image, perspectiveTransform);
        } else {
            var straightenTransform = StraightenTransformMake(crop.angle, image.geometry);
            image = Transform(image, straightenTransform);
        }
        // Apply the crop rect to the incoming image;
        image = Crop(image, crop.xOrigin, crop.yOrigin, crop.width, crop.height);
        image = Filter(`CIColorMatrix`, {'inputImage' : image, 'inputBVector' : CIVectorMake(1,1,1,0)});
        ResetTagInput('Crop', image);
    }
return output;
+[PIPipelineFilters(Debug) socPseudoColorFilter]_block_invoke
repairExtent != nil
+[PIRepairUtilities calcExtentsForStrokeRadius:offset:inputImageExtent:maskExtent:repairExtent:textureExtent:sourceExtent:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Adjustments/Retouch/PIRepair.mm
textureExtent != nil
sourceExtent != nil
Bad half float to float conversion
+[PIRepairUtilities extractRGBAfPixelsFromImage:fromROI:]
PIRepair expects the incoming image to be RGBAh, not %@
inputMaskImage
inputMaskBoundingBox
inputFaceBoundingBoxes
PIRepair-applyRepairMLStrokeToMutableBuffer
Bad fixed float to half float conversion
+[PIRepairUtilities applyRepairStrokeToMutableBuffer:brushStroke:sourceOffset:repairEdges:]
vector
error != NULL
-[NURenderPipelineHelper(PI) videoReframe:reframes:error:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Pipeline/PIPhotosPipelineHelper.m
-[NURenderPipelineHelper(PI) videoCrossfadeLoop:crossfadeAdjustment:error:]
-[NURenderPipelineHelper(PI) portraitVideo:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:error:]
@"NSMutableArray"16@?0@"NSArray"8
-[NURenderPipelineHelper(PI) portraitVideoDebugDetectedObjects:source:cinematographyState:monochrome:error:]
Unexpected source type
extent
transform
AutoLoop/LongExposureMotion
PILongExposureFusion
inputStillImage
inputVideoScale
inputRenderScale
inputAlignmentExtent
inputAlignmentTransform
PIApertureRedEyeFilter
PIRedEye
inputDestinationImage
image != nil
+[PIHDRUtilities newHLGPixelBufferFromSDRImage:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Util/PIHDRUtilities.m
PIHDRInverseHLGFilter
Failed to start rendering %@ to: %@, error: %@
Succesfully rendered HLG buffer: %@
Failed to allocate pixel buffer
kernel vec4 hlg_luma_blending_inv(__sample sdr, float scale) 
  const vec3 lum_weights = vec3(0.2627, 0.6780, 0.0593); 
  float Ys = dot(lum_weights, sdr.rgb); 
  float Ymax = max(sdr.r, max(sdr.g, sdr.b)); 
  float Yb = 0.5*(Ys+Ymax); 
  const float gamma1 = 0.845906630893; 
  float absY = max(abs(Yb), 0.00001); 
  float gainInv = scale * pow(absY, 1.0/gamma1 - 1.0); 
  float3 hdr = gainInv * sdr.rgb; 
  return vec4(hdr.rgb, 1.0); 
recipe != nil
NSDictionary * _Nonnull PIAutoLoopRecipeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/AutoLoop/PIAutoLoop.m
CGRect PIAutoLoopRecipeGetCropRect(NSDictionary *__strong _Nonnull)
origin_x
origin_y
BOOL PIAutoLoopRecipeHasGoodStabilization(NSDictionary *__strong _Nonnull)
frameTransform != nil
CMTime PIAutoLoopRecipeFrameTransformGetTime(NSDictionary *__strong)
frameTransform_rawTime
matrix_float3x3 PIAutoLoopRecipeFrameTransformGetHomography(NSDictionary *__strong)
frameTransform_homography
NSDictionary * _Nonnull PIAutoLoopRecipeGetInstructionAtTime(NSDictionary *__strong _Nonnull, CMTime)
CMTIME_IS_VALID(time)
loopRecipe_frameInstructions
loopFrameData_presTime
q24@?0@"NSDictionary"8@"NSDictionary"16
CMTime PIAutoLoopRecipeGetFrameDuration(NSDictionary *__strong _Nonnull)
NSDictionary * _Nullable PIAutoLoopRecipeGetFlavorParameters(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
CMTimeRange PIAutoLoopRecipeGetTimeRangeForFlavor(NSDictionary *__strong _Nonnull, PIAutoLoopFlavor)
completion != nil
-[PICurvesAutoCalculator submit:]
/Library/Caches/com.apple.xbs/Sources/Photos_Sim/workspaces/neutrino/PhotoImaging/Autocalculators/PICurvesAutoCalculator.m
-[PICurvesAutoCalculator computeCurvesForImageHistogram:]
softlink:r:path:/System/Library/Frameworks/JavaScriptCore.framework/JavaScriptCore
_PIParallaxInfillResult
PIParallaxInfillResult
NURenderResult
NSObject
PIParallaxInfillJob
PIParallaxInfillRequest
_PITapToTrackRenderResult
PITapToTrackResult
PITapToTrackRenderJob
PITapToTrackRequest
PIPhotoEffectHDR
PIPhotoEffectBlackAndWhiteHDR
PIPhotoEffectNoirHDR
PIPhotoEffectChromeHDR
PIPhotoEffectFadeHDR
PIPhotoEffectInstantHDR
PIPhotoEffectMonoHDR
PIPhotoEffectProcessHDR
PIPhotoEffectTonalHDR
PIPhotoEffectTransferHDR
PIPhotoEffectStageMonoHDR
PIPhotoEffect3DHDR
PIPhotoEffect3DBlackAndWhiteHDR
PIPhotoEffect3DVividHDR
PIPhotoEffect3DVividWarmHDR
PIPhotoEffect3DVividCoolHDR
PIPhotoEffect3DDramaticHDR
PIPhotoEffect3DDramaticCoolHDR
PIPhotoEffect3DDramaticWarmHDR
PIPhotoEffect3DSilverplateHDR
PIPhotoEffect3DNoirHDR
PIColorNormalizationFilter
PIReframeRules
PISemanticEnhanceAdjustmentController
_PIDisparitySampleResult
PIDisparitySampleResult
PIDisparitySampleJob
PIDisparitySampleRequest
PILocalContrastHDR
PIParallaxLayoutHelper
PISegmentationLayoutRegions
PFParallaxAssetRegions
PISegmentationLayout
_PIParallaxClockLayoutResult
PIParallaxClockLayoutResult
_PIParallaxClockLayoutJob
PIParallaxClockLayoutRequest
PIHighKey
PISegmentationInfillFilter
PISegmentationInwardFillProcessor
PIParallaxInwardFillKernel
PIParallaxColorPalette
PICompositionController
NSCopying
PICompositionSerializer
PICompositionSerializationResult
PICompositionSerializerMetadata
PILevelsFilterHDR
PIColorNormalizationAutoCalculator
NUTimeBased
PIFalseColorHDRDebug
PIAutoCalculatorUtils
PIAutoLoopExportRequest
PIAutoLoopExportClient
PIAutoLoopAnalysisRequest
PIAutoLoopAnalysisClient
PILongExposureRegistrationRequest
PIPortraitVideoProcessor
PIRGB10PortraitVideoProcessor
PIPortraitVideoFilter
PIAutoLoopAdjustmentController
PIIPTHueChromaFilter
PIIPTHueChromaColorFilter
PIIPTHueChromaGrayFilter
PIVideoCrossfadeLoopNode
PILivePhotoKeyFrameAdjustmentController
PIVignetteAdjustmentController
PIAdjustmentController
PIParallaxFilter
_PIParallaxClockMaterialResult
PIParallaxClockMaterialResult
_PIParallaxClockMaterialJob
PIParallaxClockMaterialRequest
NUDigest
PIPortraitVideoRenderNode
PIFaceObservationCache
PIParallaxStyleRecipeRegistry
PIParallaxStyleBundleURLProvider
PIParallaxStyleURLProvider
PIParallaxStyleUserURLProvider
PISourceSelectAdjustmentController
PIParallaxStyle
PIParallaxOriginalStyle
PIParallaxStudioStyle
PIParallaxTonalityModeStyle
PIParallaxColorBGStandardStyle
PIParallaxColorParameterStyle
PIParallaxBlackWhiteStudioStyle
PIParallaxBlackWhiteMonoStyle
PIParallaxColorWashSingleStyle
PIParallaxColorWashDuotoneStyle
PIParallaxRecipeStyle
PIScalarKeyframe
PIDictionaryRepresentable
PIReframeSubject
NSSecureCoding
NSCoding
PIParallaxSegmentationItem
PISegmentationItem
PISegmentationContextInfo
PIPortraitVideoAdjustmentController
PIParallaxColorSuggester
PIReframeKeyframe
PIReframeKeyframeSequence
_PIParallaxColorAnalysisResult
PIParallaxColorAnalysisResult
_PIParallaxRenderResource
_PIParallaxColorAnalysisJob
PIParallaxColorAnalysisRequest
PIParallaxColorAnalysis
PILongExposureFusionAutoCalculator
PIEffectAdjustmentController
PIAutoLoopAutoCalculator
PIMakerNoteUtilities
PITempTintFilter
PITimeVaryingPipelineStateSetting
_PIAutoLoopAnalysisResult
PIAutoLoopAnalysisResult
PIAutoLoopAnalysisJob
_PIVideoStabilizeFlowControl
ICFlowControl
_PIVideoStabilizeResult
PIVideoStabilizeResult
PIVideoStabilizeRenderJob
PIVideoStabilizeRequest
PIFaceBalanceAutoCalculator
GrayColorResult
RGBResult
PIWhiteBalanceAutoCalculator
_PIWhiteColorCalculator
PIDefinitionFilter
PISmartBlackAndWhiteAdjustmentController
PICompositionExporterDefaultMetadataConverter
PICompositionExporterMetadataConverter
PICompositionExportImagePrepareResult
PICompositionExportAuxiliaryResult
PICompositionExportResult
PICompositionExportDataResult
PICompositionExporterOptions
PICompositionExporterVideoOptions
PICompositionExporterImageOptions
PICompositionExporterAuxiliaryOptions
PICompositionExporter
GUBilateralConvolution
GUBWBilateralConvolution
PIBilateralFilter
PIPhotoEditAdjustmentsVersion
PINoiseReductionAdjustmentController
PrivateSmartColorHDR
PISmartColorFilterHDR
PIAutoEnhanceFilter
_PIParallaxCompoundLayerStackResult
PIParallaxLayerStackResult
PIParallaxCompoundLayerStackRequest
PIVideoCrossfadeLoopAdjustmentController
PISegmentationHelper
PIPortraitAdjustmentController
PIParallaxLegacyPosterStyle
PICompositionNoOpRemoval
PIOrientationAdjustmentController
PIParallaxStyleRecipeArchiver
PIPortraitVideoMetadataSample
PIPortraitVideoRenderer
PIDefinitionAdjustmentController
PIHighKeyHDR
PIPerspectiveAutoCalculator
PIFaceObservingAutoCalculator
PIRawNoiseReductionAdjustmentController
PICropAdjustmentController
PIRawAdjustmentController
PIParallaxRecipeFilter
PISmartToneAdjustmentController
PIAutoLoopKernels
PIPhotoEditHelper
PIAdjustmentConstants
PIFakeBoost
PIForwardFakeBoost
PIInverseFakeBoost
PICoreImageUtilities
PICompositionSerializerConstants
PICurvesFilterHDR
_PIParallaxLayoutResult
PIParallaxLayoutResult
_PIParallaxLayoutJob
PIParallaxLayoutRequest
PIParallaxLuminanceCalculator
PIParallaxStyleRecipe
PIParallaxStyleDefinition
PIParallaxStyleFilterDefinition
PIParallaxStyleFilterStackDefinition
PIParallaxStyleParameter
PIParallaxStyleNumberParameter
PIParallaxStyleColorParameter
PIParallaxStylePointParameter
PIParallaxStyleModeParameter
PIParallaxStyleBindingParameter
PIParallaxStyleEvaluationContext
PILongExposureAccumulator
_PILongExposureRegistrationResult
PILongExposureRegistrationResult
PILongExposureRegistrationJob
PIRAWTempTintSampler
PITagColorSampler
PIRedEye
PIVideoPosterFrameAdjustmentController
PICompositionSerializerFormatVersion
PICaptureDebugUtilities
PISlomoAdjustmentController
PISegmentationGatingRange
PISegmentationGatingRanges
PISegmentationGating
PIPortraitVideoDebugDetectionsRenderNode
PIColorWashFilter
PIColorWashDuoFilter
PIDebugAdjustmentController
PIGainMap
PIRAWFaceBalance
PICurvesLUTFilter
PICurvesFilter
PIColorBalanceFilter
PIPhotosPipelineHDRFilters
PIHighResFusionAdjustmentController
PIGlobalSettings
PIAutoLoopExportJob
PIJSRenderPipeline
PhotosPipeline
PIApertureRedEyeAutoCalculator
PrivateLocalLightHDR
PILocalLightMapPrepareHDR
PILocalLightFilterHDR
PIParallaxAsset
PFParallaxAsset
PFParallaxSegmentationResourceCaching
PIMsgImageBuffer
PISmartBlackAndWhiteAutoCalculator
PISmartBlackAndWhiteHDR
PrivateSmartBlackAndWhite
PITrimAdjustmentController
PIRedEyeAdjustmentController
PICinematicVideoUtilities
_PIParallaxRenderBuffer
NUImageBuffer
_PIParallaxRenderCacheEntry
_PIParallaxLayerStackResult
_PIParallaxLayerStackScalePolicy
NUScalePolicy
_PIParallaxLayerStackJob
_PIParallaxLayerStackRenderer
PIParallaxFilterCache
PIParallaxLayerStackRequest
_PIParallaxLayerStackDebugImageCollector
PILevelsAutoCalculator
PILevelsLuminanceAutoCalculator
PILevelsRGBAutoCalculator
AdjustmentExtensions
PICurveControlPoint
PrivateSmartToneHDR
PISmartToneFilterHDR
PICompositingFilter
PILongExposureFusion
PIModernPhotosPipeline
PILevelsFilter
PISegmentationLoader
PISegmentationLoading
_PISegmentationNullAsset
_PIParallaxLayoutInactiveFrameResult
PIParallaxLayoutInactiveFrameResult
_PIParallaxLayoutInactiveFrameJob
PIParallaxLayoutInactiveFrameRequest
PISchema
PICompositionFinalizer
PICompositionFinalizerResult
PIVideoStabilizeAdjustmentController
PICropAutoCalculator
Utilities
PISmartColorAdjustmentController
PISelectiveColorFilter
PIVideoReframeNode
PIVideoReframe
PIVideoReframeTimedMetadata
PIVideoReframeMetadataExtractor
PINeutralGrayWhiteBalanceFilter
PISmartToneAutoCalculator
PISmartColorAutoCalculator
PIRedEyeAutoCalculator
PIManualRedEyeAutoCalculator
PISegmentationCropFilter
PISegmentationMPSReduceProcessor
PISourceSampler
PIPhotoGrainHDR
PISegmentation
PIImageIO
PISharpenAdjustmentController
PIApertureRedEyeProcessorKernel
PIApertureRedEyeFilter
PIValuesAtCapture
PIPortraitAutoCalculator
PIDepthEffectApertureAutoCalculator
PIPipelineFilters
Debug
PIWhiteBalanceAdjustmentController
PIRepairUtilities
PIDepthAdjustmentController
PIVideoReframeAdjustmentController
PIHDRUtilities
PIHDRInverseHLGFilter
PICurvesAutoCalculator
PICurvesLuminanceAutoCalculator
PICurvesRGBAutoCalculator
CGColor
ARGB8
IPXEditSettings
BWBilateralKernels
CGRectValue
T@"CIImage",&,V_inputTableImage
CIImageProcessorDigestObject
T@"NSArray",C,N
CVPixelFormat
T@"NSArray",R,N
ICReportProgress:
T@"NSDictionary",R,C,N,V_ranges
JPEGCompressionQuality
T@"NSNumber",&,N,VinputContrast
LabToRGBKernel
T@"NSNumber",&,N,VinputStrength
P3KernelHDR
T@"NSNumber",&,V_inputIntensity
PIAutoEnhanceAdjustmentKey
T@"NSString",R,C,N,V_filterName
PICropAdjustmentKey
T@"NSURL",&,V_companionVideoURL
PIDefinitionAdjustmentKey
T@"PFParallaxColor",&,N,V_color
PIEffect3DAdjustmentKey
T@"PIParallaxInfillRequest",R,N
PIGrainAdjustmentKey
T@"PIParallaxStyle",&,N,V_style
PILevelsAdjustmentKey
TB,N,V_updateClockAreaLuminance
PIMuteAdjustmentKey
Td,N,V_rangeMin
PIOrientationAdjustmentKey
Td,V_minimumPitchCorrectionArea
PIPortraitAdjustmentKey
Tf,N,V_confidencePureBackground
PIRawAdjustmentKey
Tf,N,V_faceSize
PIRedEyeAdjustmentKey
Tq,R,N,V_source
PISelectiveColorAdjustmentKey
T{?={?=qq}{?=qq}},N,V_imageRect
PISharpenAdjustmentKey
PISmartBWAdjustmentKey
__defaultStyles
PISmartToneAdjustmentKey
_acceptableRect
PISourceSelectAdjustmentKey
_bounds
PIVideoCrossfadeLoopAdjustmentKey
_changeDelegate
PIVideoStabilizeAdjustmentKey
_colors
PIWhiteBalanceAdjustmentKey
_debugIntermediateLayoutBuffers
PPtogHDRKernel
_device
_disableOnPanos
RGBA16
_evaluateImage:
RGBAf
_expandedBounds
RGBResultValue
_finalizerError
RGBToYIQKernel
_height
ROIForCenterPoint:radius:
_imageHistogram
T#,R
_inputAlgorithm
T@"<MTLTexture>",&,N,V_sourceTexture
_inputBlurImage
T@"<NUImageBuffer>",&,N,V_debugColorAnalysisBuffer
_inputChromaMin
T@"<NUImageBuffer>",&,N,V_debugInfillBuffer
_inputIntensity
T@"<NUImageBuffer>",&,N,V_debugLayoutBuffer
_inputMaskImage
T@"<NUImageBuffer>",&,N,V_debugMatteBuffer
_inputMidDstRed
T@"<NUImageBuffer>",&,N,V_debugPreviewBuffer
_inputMidSrcRed
T@"<NUImageBuffer>",&,N,V_flattenedForegroundForDebugPreview
_layerStackMode
T@"<NUImageBuffer>",&,N,V_infilledImage
_layout
T@"<NUImageBuffer>",&,N,V_segmentationConfidenceMap
_loadingHandler
T@"<NUImageBuffer>",R,N
_luminanceValue
T@"<NUPurgeableStorage>",&,N,V_destination
_metadataClockOverlapAcceptable
T@"<NUScalePolicy>",&,N,V_scalePolicy
_nextInputFrame
T@"<NUVideoProperties>",&,N,V_inputVideoProperties
_portraitQualityForRenderScale:
T@"<PFParallaxAssetRegions>",&,N,V_layoutRegions
_readySemaphore
T@"<PFParallaxAssetRegions>",R,N
_renderPipeline
T@"<PFParallaxLayoutConfiguration>",R,N
_scores
T@"<PICompositionExporterMetadataConverter>",&
_segmentationConfidenceMapImage
T@"<PISegmentationItem>",R,N
_system
T@"AVAsset",&,N,V_videoSource
_warmth
T@"CIColor",&,N,V_inputHighlightColor
_yValue
T@"CIImage",&,N,V_backgroundImage
allKeys
T@"CIImage",&,N,V_debugConfidenceMapImage
analysisRequest
T@"CIImage",&,N,V_debugInputImage
applyVideoOrientationAsMetadata
T@"CIImage",&,N,V_debugLineDetectionImage
arrayWithArray:
T@"CIImage",&,N,V_debugMatteCropImage
attributeHueKey
T@"CIImage",&,N,V_debugPreviewImage
auxiliaryImage:
T@"CIImage",&,N,V_guideImage
availableStyles
T@"CIImage",&,N,V_image
backgroundLayer
T@"CIImage",&,N,V_inputDestinationImage
baseURL
T@"CIImage",&,N,V_inputForegroundImage
boolSettingForKey:defaultValue:
T@"CIImage",&,N,V_inputImage
centerMotionVectorFromMetadata:
T@"CIImage",&,N,V_inputMatteImage
chromaThreshold
T@"CIImage",&,N,V_inputTargetImage
clockLayerOrder
T@"CIImage",&,N,V_outputImage
colorsFromDictionary:key:error:
T@"CIImage",&,N,V_segmentationMatteImage
computeCurvesForImageHistogram:
T@"CIImage",&,N,VinputImage
constraintWidth
T@"CIImage",&,V_inputDepthMap
containsString:
T@"CIImage",R,N,V_cachedImage
convertFromIPT:
T@"CIRenderInfo",R,N,V_renderInfo
cropNode:cropRect:cropSettings:
T@"CIRenderTask",R,N,V_renderTask
dataWithLength:
T@"CIVector",&,N,V_inputAlignmentTransform
debugInputImage
T@"NSArray",&,N,V_debugIntermediateLayoutBuffers
defaultStrength
T@"NSArray",&,N,V_inputCorrectionInfo
disableDownload
T@"NSArray",&,V_inputPoints
effectiveLayout
T@"NSArray",&,V_inputPointsG
enabled
T@"NSArray",&,V_inputPointsR
ensureResources
T@"NSArray",C,N,V__availableStyles
faceOrientation
T@"NSArray",C,N,V_backgroundColors
falloff
T@"NSArray",C,N,V_dominantColors
filterHueKernel
T@"NSArray",C,N,V_foregroundColors
filters
T@"NSArray",C,N,V_petsFaceRegions
foregroundLayer
T@"NSArray",C,V_inputParams
grayStrengthKey
T@"NSArray",R,C,N,V_backgroundFilters
hasFrontFacingCameraDimentions:
T@"NSArray",R,C,N,V_foregroundFilters
T@"NSArray",R,C,N,V_matteFilters
imageWithCVPixelBuffer:options:
T@"NSArray",R,C,N,V_secondaryColors
infillAlgorithm
T@"NSArray",R,N,V_petRegions
initWithAssetReaderTrackOutput:
T@"NSArray",R,N,VpetRegions
initWithDevice:
T@"NSArray",R,V_subjects
initWithLength:
T@"NSCache",&,N,V_labelImageCache
initWithPixelBuffer:renderTask:
T@"NSData",&,V_companionImageData
initWithRecipe:
T@"NSDate",&,N,V_lastUseTime
initWithScript:
T@"NSDictionary",&,N,V_recipe
inputBrightness
T@"NSDictionary",&,V_recipe
inputEdgeDetail
T@"NSDictionary",C,N,V_localLightData
inputHighlights
T@"NSDictionary",C,N,V_recipe
inputLumaTarget
T@"NSDictionary",R
inputMidDstBlue
T@"NSDictionary",R,C,N,V_parameters
inputSaturation
T@"NSDictionary",R,N,V_cameraInfo
inputStillImage
T@"NSError",&,N,V_finalizerError
inputVideoScale
T@"NSIndexSet",R,C,N,V_suggestionIndices
isGeometryIdentityForImageSize:
T@"NSMutableDictionary",R,V_debugDiagnostics
isInUse
T@"NSNumber",&,N,V_i
isSmart
T@"NSNumber",&,N,V_inputBlackDstBlue
kindKey
T@"NSNumber",&,N,V_inputBlackDstRGB
leftEye
T@"NSNumber",&,N,V_inputBlackSrcBlue
lowercaseString
T@"NSNumber",&,N,V_inputBlackSrcRGB
maximumAperture
T@"NSNumber",&,N,V_inputChromaMax
T@"NSNumber",&,N,V_inputFocusedDisparity
nccCoarseKernel
T@"NSNumber",&,N,V_inputHilightDstGreen
newCommandQueue
T@"NSNumber",&,N,V_inputHilightDstRed
numberWithBool:
T@"NSNumber",&,N,V_inputHilightSrcGreen
openForWriting:
T@"NSNumber",&,N,V_inputHilightSrcRed
options
T@"NSNumber",&,N,V_inputHueRange
originalCropKey
T@"NSNumber",&,N,V_inputIntensity
parallaxPadding
T@"NSNumber",&,N,V_inputLumaRange
petsFaceRegions
T@"NSNumber",&,N,V_inputMidDstBlue
portraitInfoKey
T@"NSNumber",&,N,V_inputMidDstRGB
progressHandler
T@"NSNumber",&,N,V_inputMidSrcBlue
T@"NSNumber",&,N,V_inputMidSrcRGB
rateKey
T@"NSNumber",&,N,V_inputRenderDebugMode
rawTime
T@"NSNumber",&,N,V_inputRenderScale
regionWithRect:
T@"NSNumber",&,N,V_inputShadowDstGreen
release
T@"NSNumber",&,N,V_inputShadowDstRed
request
T@"NSNumber",&,N,V_inputShadowSrcGreen
resetTag:input:
T@"NSNumber",&,N,V_inputShadowSrcRed
result:
T@"NSNumber",&,N,V_inputVideoScale
rgbToLumaKernel
T@"NSNumber",&,N,V_inputWarmTint
samplerWithImage:keysAndValues:
T@"NSNumber",&,N,V_inputWhiteDstGreen
secondaryColors
T@"NSNumber",&,N,V_inputWhiteDstRed
setAutoCropped:
T@"NSNumber",&,N,V_inputWhiteSrcGreen
setBool:forKey:
T@"NSNumber",&,N,V_inputWhiteSrcRed
setComposition:
T@"NSNumber",&,N,V_maximumAperture
setContextInfo:
T@"NSNumber",&,N,V_q
setGuideExtent:
T@"NSNumber",&,N,V_warmth
setIncludeCinematicVideoTracks:
T@"NSNumber",&,N,VinputBlack
setInputBorder:
T@"NSNumber",&,N,VinputCast
setInputParams:
T@"NSNumber",&,N,VinputRawHighlights
setInputRadius:
T@"NSNumber",&,V_inputBorder
setInputWarmth:
T@"NSNumber",&,V_inputRadius
setLayoutScore:
T@"NSNumber",C,N
setObservation:
T@"NSNumber",C,N,VinputGrain
setOrientation:
T@"NSNumber",C,N,VinputISO
setPetsRegions:
T@"NSNumber",C,N,VinputScaleFactor
setRenderScale:
T@"NSNumber",C,N,VinputTone
setRollRadians:
T@"NSNumber",C,V_autoStraightenVerticalAngleThreshold
setScalePolicy:
T@"NSNumber",C,V_maxAutoPitch
setSegmentationInfillAlgorithm:
T@"NSNumber",R,N,V_alphaValue
setShouldPerformAutoStraighten:
T@"NSNumber",R,N,V_greenValue
setSourceIdentifier:forTrackID:
T@"NSNumber",R,N,V_redValue
setStorageMode:
T@"NSNumber",R,N,V_yValue
setVideoFrames:
T@"NSString",&,N,V_clockLayerOrder
setVisibleRect:
T@"NSString",&,N,V_formatVersion
setYCbCrMatrix:
T@"NSString",&,N,V_inputAlgorithm
set_accumError:
T@"NSString",&,N,V_inputCameraModel
smartToneSchema
T@"NSString",&,N,V_inputMode
stabCropRectKey
T@"NSString",C,N,V_systemBuildVersion
storage
T@"NSString",C,N,V_systemVersion
stringByAppendingPathExtension:
T@"NSString",C,V_debugFilesPrefix
submit:
T@"NSString",C,V_inputVersion
subpath
T@"NSString",R
timeKey
T@"NSString",R,C,N
toneKey
T@"NSString",R,C,N,V_platform
trackIdentifier
T@"NSString",R,C,N,V_variableName
upsampleBackgroundImage:toSize:
T@"NSString",R,N,V_PIApertureRedEyeAdjustmentKey
userOrientation
T@"NSString",R,N,V_PIAutoLoopAdjustmentKey
visualInputKeys
T@"NSString",R,N,V_PICurvesAdjustmentKey
warmUpResources
T@"NSString",R,N,V_PIDepthAdjustmentKey
T@"NSString",R,N,V_PIEffectAdjustmentKey
yawAngleDegrees
.cxx_destruct
HLGOpticalScale
BGRA8
PIVideoPosterFrameAdjustmentKey
CGColorSpace
RGBToLabKernels
CIFormat
T@"CIImage",R,N
CVPixelBuffer
T@"NSArray",C,N,V_dominantGrays
HDRFilterForSDRFilter:
T@"NSDictionary",C,V_properties
ICShouldBeCanceled
T@"NSNumber",&,N,V_inputHasFace
JSONObjectWithData:options:error:
T@"NSNumber",&,N,VinputExposure
P3Kernel
T@"NSNumber",&,N,VinputVibrancy
PIApertureRedEyeAdjustmentKey
T@"NSNumber",C,N,VinputStrength
PIAutoLoopAdjustmentKey
T@"NSString",R,V_destinationUTI
PICurvesAdjustmentKey
T@"NUColorSpace",&,V_colorSpace
PIDepthAdjustmentKey
T@"PIParallaxColorAnalysis",R,N
PIEffectAdjustmentKey
T@"PIParallaxLayoutRequest",R,N
PIHighResFusionAdjustmentKey
TB,N,V_preserveSourceColorSpace
PILivePhotoKeyFrameAdjustmentKey
Td,N,V_rangeMax
PINoiseReductionAdjustmentKey
Td,V_inputBoost
PIOvercaptureSourceAdjustmentKey
Tf,N,V_aperture
PIPortraitVideoAdjustmentKey
Tf,N,V_confidencePureForeground
PIRawNoiseReductionAdjustmentKey
Tq,N,V_priority
PIRetouchAdjustmentKey
Tq,R,V_rawState
PISemanticEnhanceAdjustmentKey
PISlomoAdjustmentKey
_PISemanticEnhanceAdjustmentKey
PISmartColorAdjustmentKey
_abort:
PISourceAdjustmentKey
_accumSemaphore
PITrimAdjustmentKey
_bundle
PIVideoReframeAdjustmentKey
_classification
PIVignetteAdjustmentKey
_completedTrack
PNGRepresentationOfImage:format:colorSpace:options:
_destinationUTI
PUEditSettings
_digest
RG16
_dominantColors
RGBA8
_evaluateVideo:
RGBAh
_extent
RGBToLabKernel
_flavor
RGBValues
_hueChromaImage
SDOFRenderingVersion
_initializeStorage:image:error:
T@"<MTLDevice>",R,N,V_device
_inputBlendMode
T@"<NUImageBuffer>",&,N,V_backgroundBuffer
_inputChromaMax
T@"<NUImageBuffer>",&,N,V_debugConfidenceMapBuffer
_inputHueTarget
T@"<NUImageBuffer>",&,N,V_debugInputBuffer
_inputLumaRange
T@"<NUImageBuffer>",&,N,V_debugLocalConfidenceBuffer
_inputMidDstRGB
T@"<NUImageBuffer>",&,N,V_debugMatteCropBuffer
_inputMidSrcRGB
T@"<NUImageBuffer>",&,N,V_flattenedBackgroundForDebugPreview
_inputThreshold
T@"<NUImageBuffer>",&,N,V_foregroundBuffer
_layers
T@"<NUImageBuffer>",&,N,V_segmentationBackground
_loadLocalLightData:completion:
T@"<NUImageBuffer>",&,N,V_segmentationMatte
_localLightData
T@"<NUImageBuffer>",R,N,V_pixelBuffer
_markAsFinished
T@"<NURenderStatistics>",R
_nFaces
T@"<NUScalePolicy>",&,V_scalePolicy
_originalLayout
T@"<PFParallaxAsset>",R,N,V_asset
_ranges
T@"<PFParallaxAssetRegions>",&,N,V_regions
_recipe
T@"<PFParallaxLayoutConfiguration>",&,N,V_layoutConfiguration
_result
T@"<PICompositionControllerDelegate>",W,N,V_changeDelegate
_secondaryColor
T@"<PIParallaxFilterCache>",&,N,V_cache
_source
T@"<PISegmentationItem>",R,N,V_segmentationItem
_videoCodecType
T@"CIColor",&,N,V_inputColor
_xValue
T@"CIColor",&,N,V_inputShadowColor
addTagWithName:inputNode:error:
T@"CIImage",&,N,V_debugColorAnalysisImage
allowCompressedInputsAndOutputs
T@"CIImage",&,N,V_debugInfillImage
applyImageOrientationAsMetadata
T@"CIImage",&,N,V_debugLayoutImage
applyWithForeground:background:
T@"CIImage",&,N,V_debugLocalConfidenceImage
assetIdentifier
T@"CIImage",&,N,V_debugMatteImage
autoKey
T@"CIImage",&,N,V_foregroundImage
auxiliaryImages
T@"CIImage",&,N,V_hueChromaImage
backgroundImage
T@"CIImage",&,N,V_inputBackgroundImage
base64EncodedStringWithOptions:
T@"CIImage",&,N,V_inputDisparityImage
bilateralROI:destRect:userInfo:
T@"CIImage",&,N,V_inputGuideImage
bundleForClass:
T@"CIImage",&,N,V_inputMaskImage
cgColor
T@"CIImage",&,N,V_inputStillImage
cleanUp
T@"CIImage",&,N,V_matteImage
colorProperties
T@"CIImage",&,N,V_segmentationConfidenceMapImage
compositionKeys
T@"CIImage",&,N,V_stillImage
conformsToType:
T@"CIImage",&,V_inputBlurImage
containsObject:
T@"CIImage",&,V_inputImage
context
T@"CIImage",R,N,V_image
copyOfCompositionRemovingNoOps:
T@"CIRenderTask",&,N,V_task
currentPlatform
T@"CIVector",&,N,V_inputAlignmentExtent
dealloc
T@"NSArray",&,N,V_colorSuggestions
debugMatteImage
T@"NSArray",&,N,V_debugIntermediateLayoutImages
destinationData
T@"NSArray",&,N,V_inputCorrections
disparityBuffer
T@"NSArray",&,V_inputPointsB
elementByteSize
T@"NSArray",&,V_inputPointsL
endTime
T@"NSArray",&,V_inputWeights
extractMetadata
T@"NSArray",C,N,V__defaultStyles
faceStrengthKey
T@"NSArray",C,N,V_colors
fileURL
T@"NSArray",C,N,V_dominantHues
filterWithName:
T@"NSArray",C,N,V_layers
foregroundImage
T@"NSArray",C,N,V_petsRegions
geometryRequestWithComposition:
T@"NSArray",R,C,N
groupIdentifier
T@"NSArray",R,C,N,V_filters
hasTonalityMode
T@"NSArray",R,C,N,V_keyframes
T@"NSArray",R,C,N,V_primaryColors
imageWithColor:
T@"NSArray",R,N,V_faceRegions
infillMaskForSegmentationMatte:
T@"NSArray",R,N,VfaceRegions
initWithColors:
T@"NSArray",R,N,VtimedMetadataArray
initWithLayout:
T@"NSCache",&,N,V_cache
initWithNumber:
T@"NSData",&,N,V_data
initWithRanges:
T@"NSData",&,V_data
initWithResult:
T@"NSDictionary",&,N
initWithSource:
T@"NSDictionary",&,V_auxiliaryImages
inputColorSpace
T@"NSDictionary",C,N
inputGuideImage
T@"NSDictionary",C,N,V_parameters
inputLocalLight
T@"NSDictionary",C,N,V_scores
inputMatteImage
T@"NSDictionary",R,C,N
inputMidSrcBlue
T@"NSDictionary",R,N
inputShadowsKey
T@"NSDictionary",R,N,V_rawHomographies
inputTableImage
T@"NSError",&,V__accumError
isEqualToArray:
T@"NSMutableData",&,Vdata
isHuman
T@"NSNumber",&,N
isProxy
T@"NSNumber",&,N,V_inputAperture
T@"NSNumber",&,N,V_inputBlackDstGreen
labelImageCache
T@"NSNumber",&,N,V_inputBlackDstRed
localIdentifier
T@"NSNumber",&,N,V_inputBlackSrcGreen
T@"NSNumber",&,N,V_inputBlackSrcRed
medianLuminance
T@"NSNumber",&,N,V_inputChromaMin
minimumAperture
T@"NSNumber",&,N,V_inputHilightDstBlue
neutral
T@"NSNumber",&,N,V_inputHilightDstRGB
T@"NSNumber",&,N,V_inputHilightSrcBlue
openForReading:
T@"NSNumber",&,N,V_inputHilightSrcRGB
optimizeForBackgroundProcessing
T@"NSNumber",&,N,V_inputHueIsNormalized
orientationAdjustmentController
T@"NSNumber",&,N,V_inputHueTarget
overlapStrategy
T@"NSNumber",&,N,V_inputIsRaw
parallaxWallpaperDisableUpgrade
T@"NSNumber",&,N,V_inputLumaTarget
photoEffectName
T@"NSNumber",&,N,V_inputMidDstGreen
posterFrameTime
T@"NSNumber",&,N,V_inputMidDstRed
pushDebugGroup:
T@"NSNumber",&,N,V_inputMidSrcGreen
quality
T@"NSNumber",&,N,V_inputMidSrcRed
rawHomographies
T@"NSNumber",&,N,V_inputRenderQuality
T@"NSNumber",&,N,V_inputShadowDstBlue
regions
T@"NSNumber",&,N,V_inputShadowDstRGB
render:
T@"NSNumber",&,N,V_inputShadowSrcBlue
requestRevision
T@"NSNumber",&,N,V_inputShadowSrcRGB
resolutionRatio
T@"NSNumber",&,N,V_inputStrength
results
T@"NSNumber",&,N,V_inputWarmTemp
roundedRectangleGeneratorFilter
T@"NSNumber",&,N,V_inputWhiteDstBlue
sceneConfidence
T@"NSNumber",&,N,V_inputWhiteDstRGB
semanticEnhance
T@"NSNumber",&,N,V_inputWhiteSrcBlue
setBitRateMultiplicationFactor:
T@"NSNumber",&,N,V_inputWhiteSrcRGB
setColorMatrix:
T@"NSNumber",&,N,V_luminanceValue
setCompression:
T@"NSNumber",&,N,V_minimumAperture
setDestination:
T@"NSNumber",&,N,V_strength
setHue:
T@"NSNumber",&,N,V_y
setInputAmount:
T@"NSNumber",&,N,VinputBrightness
setInputCutoff:
T@"NSNumber",&,N,VinputHighlights
setInputPoints:
T@"NSNumber",&,N,VinputShadows
setInputTimedRenderingMetadata:
T@"NSNumber",&,V_inputEdgeDetail
setLastUseTime:
T@"NSNumber",&,V_inputVersion
setMaxFaceSize:
T@"NSNumber",C,N,VinputAmount
setOffsetBlack:
T@"NSNumber",C,N,VinputHue
setOutputImage:
T@"NSNumber",C,N,VinputNeutralGamma
setPixelFormat:
T@"NSNumber",C,N,VinputSeed
setRenderState:
T@"NSNumber",C,V_autoStraightenDominantAngleDiffThreshold
setScaleFactor:
T@"NSNumber",C,V_maxAutoAngle
setSegmentationDebugTintLayers:
T@"NSNumber",C,V_maxAutoYaw
setSegmentationLoader:forAsset:
T@"NSNumber",R,N,V_blueValue
setSourceColor:
T@"NSNumber",R,N,V_numberValue
setSourceTrackIDForFrameTiming:
T@"NSNumber",R,N,V_xValue
setTemperature:
T@"NSObject<OS_dispatch_queue>",&,N,V_loadingHandlerQueue
setVideoSource:
T@"NSString",&,N,V_formatIdentifier
setWithObjects:
T@"NSString",&,N,V_identifier
setYaw:
T@"NSString",&,N,V_inputBlendMode
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
T@"NSString",&,N,V_inputColorSpace
sourceSelection
T@"NSString",C,N
stopAtTagIncludeGeometryFilter:
T@"NSString",C,N,V_systemName
stringByAppendingPathComponent:
T@"NSString",C,N,V_videoCodecType
subMinorVersion
T@"NSString",C,V_digest
submitVerified:
T@"NSString",C,V_pairingIdentifier
T@"NSString",R,C
tintKey
T@"NSString",R,C,N,V_modeValue
trackID
T@"NSString",R,C,N,V_stackName
uniqueInputNode
T@"NSString",R,N
T@"NSString",R,N,V_PIAutoEnhanceAdjustmentKey
version
T@"NSString",R,N,V_PICropAdjustmentKey
warmUpRequests:
T@"NSString",R,N,V_PIDefinitionAdjustmentKey
T@"NSString",R,N,V_PIEffect3DAdjustmentKey
T@"NSString",R,N,V_PIGrainAdjustmentKey
T@"NSString",R,N,V_PIHighResFusionAdjustmentKey
T@"NSString",R,N,V_PILevelsAdjustmentKey
T@"NSString",R,N,V_PILivePhotoKeyFrameAdjustmentKey
T@"NSString",R,N,V_PIMuteAdjustmentKey
T@"NSString",R,N,V_PINoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIOrientationAdjustmentKey
T@"NSString",R,N,V_PIOvercaptureSourceAdjustmentKey
T@"NSString",R,N,V_PIPortraitAdjustmentKey
T@"NSString",R,N,V_PIPortraitVideoAdjustmentKey
T@"NSString",R,N,V_PIRawAdjustmentKey
T@"NSString",R,N,V_PIRawNoiseReductionAdjustmentKey
T@"NSString",R,N,V_PIRedEyeAdjustmentKey
T@"NSString",R,N,V_PIRetouchAdjustmentKey
T@"NSString",R,N,V_PISelectiveColorAdjustmentKey
T@"NSString",R,N,V_PISemanticEnhanceAdjustmentKey
T@"NSString",R,N,V_PISharpenAdjustmentKey
T@"NSString",R,N,V_PISlomoAdjustmentKey
T@"NSString",R,N,V_PISmartBWAdjustmentKey
T@"NSString",R,N,V_PISmartColorAdjustmentKey
T@"NSString",R,N,V_PISmartToneAdjustmentKey
T@"NSString",R,N,V_PISourceAdjustmentKey
T@"NSString",R,N,V_PISourceSelectAdjustmentKey
T@"NSString",R,N,V_PITrimAdjustmentKey
T@"NSString",R,N,V_PIVideoCrossfadeLoopAdjustmentKey
T@"NSString",R,N,V_PIVideoPosterFrameAdjustmentKey
T@"NSString",R,N,V_PIVideoReframeAdjustmentKey
T@"NSString",R,N,V_PIVideoStabilizeAdjustmentKey
T@"NSString",R,N,V_PIVignetteAdjustmentKey
T@"NSString",R,N,V_PIWhiteBalanceAdjustmentKey
T@"NSString",R,N,V_unit
T@"NSString",R,W,N
T@"NSURL",&,N,V_baseURL
T@"NSURL",&,N,V_cacheURL
T@"NSURL",&,N,V_fileURL
T@"NSURL",&,N,V_segmentationDataURL
T@"NSURL",&,V_primaryURL
T@"NSURL",&,V_videoComplementURL
T@"NSURL",&,V_videoPosterFrameURL
T@"NSURL",R,N
T@"NSURL",R,N,V_fileURL
T@"NSURL",R,V_destinationLongExposureURL
T@"NSURL",R,V_destinationMaskURL
T@"NUAdjustment",&,V_reframeCropAdjustment
T@"NUAdjustment",&,V_reframeVideoAdjustment
T@"NUAdjustment",R,N,V_adjustment
T@"NUCVPixelBuffer",&,N,V_inputColorPixelBuffer
T@"NUCVPixelBuffer",&,N,V_inputDisparityPixelBuffer
T@"NUColorSpace",&,N,V_colorSpace
T@"NUColorSpace",R
T@"NUColorSpace",R,N
T@"NUColorSpace",R,N,V_colorSpace
T@"NUComposition",&,N,V_composition
T@"NUComposition",R,C,N
T@"NUComposition",R,C,V_composition
T@"NUComposition",R,N
T@"NUIdentifier",&,N,V_identifier
T@"NUIdentifier",R
T@"NUImageExportFormat",C,V_imageExportFormat
T@"NUImageExportRequest",&,V_request
T@"NUImageGeometry",&,V_geometry
T@"NUImageHistogram",&,N,V_imageHistogram
T@"NUPixelFormat",&,N,V_pixelFormat
T@"NUPixelFormat",R,N
T@"NUPixelFormat",R,N,V_pixelFormat
T@"NUPriority",&,V_priority
T@"NURuleSystem",R,N,V_system
T@"PFParallaxAssetResource",&,N,V_resource
T@"PFParallaxColor",&,N
T@"PFParallaxColor",&,N,V_clockColor
T@"PFParallaxColor",&,N,V_primaryColor
T@"PFParallaxColor",&,N,V_secondaryColor
T@"PFParallaxColor",R,N
T@"PFParallaxLayerStack",&,N,V_layerStack
T@"PFParallaxLayerStack",R,N
T@"PFParallaxLayerStyle",R,N
T@"PFParallaxLayout",&,N,V_defaultLayout
T@"PFParallaxLayout",&,N,V_layout
T@"PFParallaxLayout",&,N,V_originalLayout
T@"PFParallaxLayout",R,N
T@"PFParallaxLayout",R,N,V_layout
T@"PFStoryRecipeDisplayAssetNormalization",&,N,VinputNormalization
T@"PFStoryRecipeDisplayAssetNormalization",R,N
T@"PIAdjustmentConstants",R,N
T@"PIFaceObservationCache",&,N
T@"PIFaceObservationCache",&,N,V_faceObservationCache
T@"PIParallaxClockLayoutRequest",R,N
T@"PIParallaxColorAnalysis",&,N,V_colorAnalysis
T@"PIParallaxColorAnalysisRequest",R,N
T@"PIParallaxLayoutInactiveFrameRequest",R,N
T@"PIParallaxStyle",R,N
T@"PIParallaxStyleRecipe",&,N,V_recipe
T@"PIParallaxStyleRecipe",R,N
T@"PIPortraitVideoMetadataSample",&,N,V_inputTimedRenderingMetadata
T@"PIPortraitVideoMetadataSample",R,N
T@"PIReframeKeyframeSequence",&,N,V_keyframeSequence
T@"PISegmentationContextInfo",&,N,V_contextInfo
T@"PTCinematographyScript",&,N,V_cinematographyScript
T@"PTCinematographyTrack",&,N,V_completedTrack
T@"PTCinematographyTrack",R,N
T@"PTCinematographyTrack",R,N,V_completedTrack
T@"PTGlobalRenderingMetadata",&,N,V_inputGlobalRenderingMetadata
T@"PTGlobalRenderingMetadata",R,N
T@"PTTimedRenderingMetadata",&,N,V_timedMetadata
T@"VNImageHomographicAlignmentObservation",&,N,V_observation
T@"VNImageHomographicAlignmentObservation",C,N,V_observation
T@"VNImageHomographicAlignmentObservation",R,C
T@"_PIParallaxLayerStackDebugImageCollector",&,N,V_debugImageCollector
T@?,C,N,V_downloadProgressHandler
T@?,C,N,V_loadingHandler
T@?,C,N,V_progressHandler
T@?,C,N,V_shouldCancelHandler
T@?,C,V_metadataProcessor
TB,N
TB,N,GisInUse,V_inUse
TB,N,GisOriginalCrop
TB,N,GisSmart
TB,N,V_allowSpillMatteOnOlderPortraitV2Captures
TB,N,V_analyzeBackground
TB,N,V_applyVideoOrientationAsMetadata
TB,N,V_bypassOutputSettingsIfNoComposition
TB,N,V_clockOverlapAcceptable
TB,N,V_computeDigest
TB,N,V_disableDownload
TB,N,V_disableRendering
TB,N,V_disableSegmentation
TB,N,V_facePositionAcceptable
TB,N,V_forceGlassesMatteOff
TB,N,V_forceSpillMatteOff
TB,N,V_includeCinematicVideoTracks
TB,N,V_increaseBitRateIfNecessary
TB,N,V_inputIsHDR
TB,N,V_isInCloud
TB,N,V_metadataClockOverlapAcceptable
TB,N,V_proxyOnly
TB,N,V_requireHardwareEncoder
TB,N,V_segmentationDisabled
TB,N,V_shouldApplyWatermark
TB,N,V_shouldInfillForeground
TB,N,V_updateClockZPosition
TB,N,V_updateInactiveFrame
TB,N,VparallaxStyleAvoidColorWashBrownOverride
TB,R
TB,R,N
TB,R,N,GisAnalysisAvailable
TB,R,N,GisAvailable
TB,R,N,GisEditable,V_editable
TB,V_applyImageOrientationAsMetadata
TB,V_applyVideoOrientationAsMetadata
TB,V_canPropagateOriginalAuxiliaryData
TB,V_clientRequestedStop
TB,V_debugFilesEnabled
TB,V_disableOnFrontFacingCameraImages
TB,V_disableOnPanos
TB,V_force
TB,V_optimizeForBackgroundProcessing
TB,V_optimizeForSharing
TB,V_renderCompanionResources
TB,V_shouldPerformAutoCrop
TB,V_shouldPerformAutoStraighten
TB,V_shouldRunBuildingCheck
TB,V_shouldUseAutoStraightenVerticalDetector
TQ,N
TQ,N,V_SDOFRenderingVersion
TQ,N,V_allowedAnalysisTypes
TQ,N,V_candidacy
TQ,N,V_classification
TQ,N,V_clockIntersection
TQ,N,V_layerStackOptions
TQ,N,V_loadingState
TQ,N,V_performedActions
TQ,N,V_portraitMajorVersion
TQ,N,V_portraitMinorVersion
TQ,N,V_segmentationClassification
TQ,N,V_version
TQ,R
TQ,R,N
TQ,R,N,V_analysisType
TQ,R,N,V_majorVersion
TQ,R,N,V_minorVersion
TQ,R,N,V_subMinorVersion
TQ,R,VelementByteSize
TQ,R,Vheight
TQ,R,VrowElements
TQ,R,Vwidth
T^{__CVBuffer=},R,N
Td,N
Td,N,V_allowedCropFraction
Td,N,V_backgroundLuminance
Td,N,V_chromaThreshold
Td,N,V_dominanceThreshold
Td,N,V_foregroundLuminance
Td,N,V_inputOrigI
Td,N,V_inputOrigQ
Td,N,V_inputStrength
Td,N,V_inputTemperature
Td,N,V_inputTint
Td,N,V_inputWarmth
Td,N,V_luminance
Td,N,V_medianLuminance
Td,N,V_pitchAngleDegrees
Td,N,V_renderScale
Td,N,V_rollAngleDegrees
Td,N,V_yawAngleDegrees
Td,R
Td,R,N
Td,R,N,V_aperture
Td,R,N,V_clockAreaLuminance
Td,R,N,V_confidence
Td,R,N,V_depthMax
Td,R,N,V_depthMin
Td,R,N,V_focusedDisparity
Td,R,N,V_manualMax
Td,R,N,V_manualMin
Td,R,N,V_max
Td,R,N,V_min
Td,R,N,V_x
Td,R,N,V_y
Td,V_JPEGCompressionQuality
Td,V_angleSeedDegreesCCW
Td,V_inputCutoff
Td,V_maxAutoStraighten
Td,V_maxFaceSize
Td,V_minAutoStraighten
Td,V_minimumAngleCorrection
Td,V_minimumConfidence
Td,V_minimumPitchCorrection
Td,V_minimumYawCorrection
Td,V_minimumYawCorrectionArea
Tf,N,V_confidenceMapScore
Tf,N,V_cropScore
Tf,N,V_faceLocalConfidence
Tf,N,V_groundedScore
Tf,N,V_inputThreshold
Tf,N,V_layoutScore
Tf,N,V_localConfidenceScore
Tf,N,V_mattePureBackground
Tf,N,V_mattePureForeground
Tf,N,V_nFaces
Tf,N,V_parallaxScore
Tf,N,V_portraitStrength
Tf,N,V_resolutionRatio
Tf,N,V_sampledDisparityValue
Tf,N,V_segmentationScore
Tf,R,N
Tf,R,N,V_sampledDisparityValue
Tf,V_inputThreshold
Ti,R,N
Ti,R,N,V_quality
Ti,R,Vformat
Tq,N
Tq,N,V_alphaCount
Tq,N,V_edgeBleed
Tq,N,V_flavor
Tq,N,V_height
Tq,N,V_imageOrientation
Tq,N,V_infillAlgorithm
Tq,N,V_layerStackMode
Tq,N,V_maxDominantColors
Tq,N,V_orientation
Tq,N,V_sampleMode
Tq,N,V_sourceMode
Tq,N,V_version
Tq,N,V_width
Tq,N,VparallaxStyleKeyLevelOverride
Tq,N,Vtonality
Tq,R,N
Tq,R,N,V_debugMode
Tq,R,N,V_identifier
Tq,R,N,V_type
Tq,R,V_disposition
T{?=[3]},R,N,V_homography
T{?=[3]},R,V_trajectoryHomography
T{?=[4d]},R
T{?=ffff},N,V_luminanceThresholds
T{?=ffff},N,V_luminanceWeights
T{?=ii},N,V_depthVersionInfo
T{?=qiIq},N
T{?=qiIq},N,V_frameDuration
T{?=qiIq},N,V_rawTime
T{?=qiIq},N,V_renderTime
T{?=qiIq},N,V_sampleTime
T{?=qiIq},N,V_startTime
T{?=qiIq},N,V_time
T{?=qiIq},N,Vtime
T{?=qiIq},R,N
T{?=qiIq},R,N,V_crossfadeDuration
T{?=qiIq},R,N,V_startTime
T{?=qiIq},R,N,V_time
T{?=qiIq},R,V_time
T{?=qq},D
T{?=qq},R,N
T{?=qq},R,N,V_colorSize
T{?=qq},R,N,V_disparitySize
T{?=qq},V_inputSize
T{?={?=[4d]}{?=[4d]}d},R
T{?={?=qiIq}{?=qiIq}},N
T{?={?=qiIq}{?=qiIq}},R,N,V_loopTimeRange
T{?={?=qq}{?=qq}},N
T{?={?=qq}{?=qq}},N,V_cleanAperture
T{?={?=qq}{?=qq}},N,V_extent
T{?={?=qq}{?=qq}},N,V_guideExtent
T{?={?=qq}{?=qq}},N,V_stabCropRect
T{?={?=qq}{?=qq}},R,N
T{?={?=qq}{?=qq}},R,N,V_stabCropRect
T{CGPoint=dd},N,V_normalizedImagePoint
T{CGRect={CGPoint=dd}{CGSize=dd}},N
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_expandedBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_inactiveRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_normalizedClipRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_sampleRect
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_visibleFrame
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_visibleRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_acceptableCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_acceptableRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_preferredCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_preferredRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,VacceptableCropRect
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,VpreferredCropRect
T{CGVector=dd},R,V_estimatedCenterMotion
T{CGVector=dd},R,V_estimatedMotionBlur
URLByAppendingPathComponent:
URLByAppendingPathComponent:isDirectory:
URLByAppendingPathExtension:
URLForDirectory:inDomain:appropriateForURL:create:error:
URLForResource:withExtension:
URLWithString:
UUID
UUIDString
YIQToRGBKernel
_JPEGCompressionQuality
_LUTImage
_PIApertureRedEyeAdjustmentKey
_PIAutoEnhanceAdjustmentKey
_PIAutoLoopAdjustmentKey
_PICropAdjustmentKey
_PICurvesAdjustmentKey
_PIDefinitionAdjustmentKey
_PIDepthAdjustmentKey
_PIEffect3DAdjustmentKey
_PIEffectAdjustmentKey
_PIGrainAdjustmentKey
_PIHighResFusionAdjustmentKey
_PILevelsAdjustmentKey
_PILivePhotoKeyFrameAdjustmentKey
_PIMuteAdjustmentKey
_PINoiseReductionAdjustmentKey
_PIOrientationAdjustmentKey
_PIOvercaptureSourceAdjustmentKey
_PIPortraitAdjustmentKey
_PIPortraitVideoAdjustmentKey
_PIRawAdjustmentKey
_PIRawNoiseReductionAdjustmentKey
_PIRedEyeAdjustmentKey
_PIRetouchAdjustmentKey
_PISelectiveColorAdjustmentKey
_PISharpenAdjustmentKey
_PISlomoAdjustmentKey
_PISmartBWAdjustmentKey
_PISmartColorAdjustmentKey
_PISmartToneAdjustmentKey
_PISourceAdjustmentKey
_PISourceSelectAdjustmentKey
_PITrimAdjustmentKey
_PIVideoCrossfadeLoopAdjustmentKey
_PIVideoPosterFrameAdjustmentKey
_PIVideoReframeAdjustmentKey
_PIVideoStabilizeAdjustmentKey
_PIVignetteAdjustmentKey
_PIWhiteBalanceAdjustmentKey
_SDOFRenderingVersion
__accumError
__availableStyles
_acceptableCropRect
_accumError
_accumQueue
_accumulate:
_accumulate:error:
_addDummySourceToCompositionIfNeeded:
_adjustment
_adjustmentControllerClassForKey:
_adjustmentControllerForKey:creatingIfNecessary:expectedClass:
_allowSpillMatteOnOlderPortraitV2Captures
_allowedAnalysisTypes
_allowedCropFraction
_alphaCount
_alphaValue
_analysisType
_analyzeBackground
_analyzeColors:completion:
_angleSeedDegreesCCW
_aperture
_appendInputFrame:
_applyImageOrientationAsMetadata
_applyVideoOrientationAsMetadata
_asset
_autoStraightenDominantAngleDiffThreshold
_autoStraightenVerticalAngleThreshold
_auxiliaryImages
_availableStyles
_averageAccumulationStorage
_backgroundBuffer
_backgroundColors
_backgroundFilters
_backgroundImage
_backgroundLuminance
_baseURL
_beginRenderNormalizedHueChromaImage:targetGray:grayRange:chromaMax:error:
_beginRenderNormalizedHueChromaImage:targetHue:hueRange:chromaMin:error:
_beginRenderingImage:colorSpace:format:error:
_blueValue
_brightnessMultiplierFromImageProperties:
_bufferRenderClient
_bypassOutputSettingsIfNoComposition
_cache
_cacheSegmentationDataForItem:
_cacheURL
_cachedImage
_cachedImageEntries
_calculateBlackAndWhiteSettingsFromBufferImage:
_calculateWithImageProperties:valuesAtCapture:completion:
_cameraInfo
_cameraInfoFromMetadataGroup:
_canPropagateOriginalAuxiliaryData
_candidacy
_changes
_chooseNeutralGrayForNonSushi:
_chooseTempTintForSushi:RAWProperties:brightness:
_chromaThreshold
_cinematographyScript
_classify:completion:
_cleanAperture
_clientRequestedStop
_clockAreaLuminance
_clockColor
_clockIntersection
_clockLayerOrder
_clockOverlapAcceptable
_color
_colorAnalysis
_colorSize
_colorSpace
_colorSuggestions
_companionImageData
_companionVideoURL
_composition
_computeAllHistograms:
_computeAvoidingRect:imageSize:maxYMotion:segmentationMatte:layoutConfiguration:context:
_computeCleanAperture:
_computeDigest
_computeGreenPercentage:
_computeHeadroomZoomFactorWithVisibleFrame:scaleCenter:initialOverlap:matte:layoutConfiguration:context:
_computeNCCMapFromImage:toImage:scale:
_computeWhitePointColorWithGrayEdgesBuffer:grayWorldBuffer:greenChannelPercentage:RAWCameraSpaceProperties:
_confidence
_confidenceMapScore
_confidencePureBackground
_confidencePureForeground
_configureRGBColorTexture:format:isHDR:
_configureRequest:
_context
_contextInfo
_correctedRGBResultFromResult:
_cropScore
_crossfadeDuration
_customAttributesForKey:
_data
_debugColorAnalysisBuffer
_debugColorAnalysisImage
_debugConfidenceMapBuffer
_debugConfidenceMapImage
_debugDiagnostics
_debugDumpIntermediateImages
_debugFilesEnabled
_debugFilesPrefix
_debugImageCollector
_debugInfillBuffer
_debugInfillImage
_debugInputBuffer
_debugInputImage
_debugIntermediateLayoutImages
_debugLayoutBuffer
_debugLayoutImage
_debugLineDetectionImage
_debugLocalConfidenceBuffer
_debugLocalConfidenceImage
_debugMatteBuffer
_debugMatteCropBuffer
_debugMatteCropImage
_debugMatteImage
_debugMode
_debugPreviewBuffer
_debugPreviewImage
_defaultCurveArray
_defaultLayout
_defaultStyles
_delegateFlags
_depthMax
_depthMin
_depthVersionInfo
_deserializeFilterDefinition:version:error:
_deserializeFilterDefinitions:version:error:
_deserializeParameter:version:error:
_deserializeParameters:version:error:
_destination
_destinationLongExposureURL
_destinationMaskURL
_didLoad:completion:
_disableDownload
_disableOnFrontFacingCameraImages
_disableRendering
_disableSegmentation
_disparitySize
_disposition
_dominanceThreshold
_dominantGrays
_dominantHues
_doneGroup
_downloadProgressHandler
_dynamismMapWithMinImage:maxImage:extent:
_edgeBleed
_editable
_ensureResources
_error
_estimatedCenterMotion
_estimatedMotionBlur
_evaluateAudioMix:
_evaluateImageGeometry:
_evaluateImageWithFilterDefinitions:inputImage:
_evaluateVideoComposition:
_evaluateVideoProperties:
_exportOutputImage:format:colorSpace:toURL:uti:error:
_exportVideoToURL:composition:options:properties:progress:completion:
_faceLocalConfidence
_faceObservationCache
_facePositionAcceptable
_faceRegions
_faceRequest
_faceSize
_fileURL
_filterForRecipeIdentifier:
_filterName
_filters
_finished
_flattenedBackgroundForDebugPreview
_flattenedForegroundForDebugPreview
_focusedDisparity
_force
_forceGlassesMatteOff
_forceSpillMatteOff
_foregroundBuffer
_foregroundColors
_foregroundFilters
_foregroundImage
_foregroundLuminance
_formatIdentifier
_formatVersion
_frameCount
_frameDuration
_freeResources
_fuseImage:withGuideImage:weightImage:maskImage:
_geometry
_grainBlendAndMixKernel
_greenValue
_groundedScore
_group
_guideExtent
_guideImage
_handlePartialItem:loadingState:
_highKeyHDR
_homography
_homographySequence
_identifier
_identifierMap
_image
_imageByAddingDetection:toImage:isPrimary:canvasSize:inverseOrientation:
_imageDataClient
_imageExportFormat
_imageOptions
_imageOrientation
_imageRect
_imageRenderRequestWithComposition:wideGamut:
_inUse
_inactiveRect
_includeCinematicVideoTracks
_increaseBitRateIfNecessary
_infillAlgorithm
_infilledImage
_infilledImageBuffer
_initializeAccumulation
_initializeAccumulation:
_inputAlignmentExtent
_inputAlignmentTransform
_inputAperture
_inputBackgroundImage
_inputBlackDstBlue
_inputBlackDstGreen
_inputBlackDstRGB
_inputBlackDstRed
_inputBlackSrcBlue
_inputBlackSrcGreen
_inputBlackSrcRGB
_inputBlackSrcRed
_inputBoost
_inputBorder
_inputCameraModel
_inputColor
_inputColorPixelBuffer
_inputColorSpace
_inputCorrectionInfo
_inputCorrections
_inputCutoff
_inputDepthMap
_inputDestinationImage
_inputDisparityImage
_inputDisparityPixelBuffer
_inputEdgeDetail
_inputFocusedDisparity
_inputForegroundImage
_inputFrames
_inputGlobalRenderingMetadata
_inputGuideImage
_inputHasFace
_inputHighlightColor
_inputHilightDstBlue
_inputHilightDstGreen
_inputHilightDstRGB
_inputHilightDstRed
_inputHilightSrcBlue
_inputHilightSrcGreen
_inputHilightSrcRGB
_inputHilightSrcRed
_inputHueIsNormalized
_inputHueRange
_inputImage
_inputIsHDR
_inputIsRaw
_inputLumaTarget
_inputMatteImage
_inputMidDstBlue
_inputMidDstGreen
_inputMidSrcBlue
_inputMidSrcGreen
_inputMode
_inputOrigI
_inputOrigQ
_inputParams
_inputPoints
_inputPointsB
_inputPointsG
_inputPointsL
_inputPointsR
_inputRadius
_inputRenderDebugMode
_inputRenderQuality
_inputRenderScale
_inputShadowColor
_inputShadowDstBlue
_inputShadowDstGreen
_inputShadowDstRGB
_inputShadowDstRed
_inputShadowSrcBlue
_inputShadowSrcGreen
_inputShadowSrcRGB
_inputShadowSrcRed
_inputSize
_inputStillImage
_inputStrength
_inputTableImage
_inputTargetImage
_inputTemperature
_inputTimedRenderingMetadata
_inputTint
_inputVersion
_inputVideoProperties
_inputVideoScale
_inputWarmTemp
_inputWarmTint
_inputWarmth
_inputWeights
_inputWhiteDstBlue
_inputWhiteDstGreen
_inputWhiteDstRGB
_inputWhiteDstRed
_inputWhiteSrcBlue
_inputWhiteSrcGreen
_inputWhiteSrcRGB
_inputWhiteSrcRed
_interpolateGrainKernel
_isCancelled
_isDefault
_isIdentity
_isInCloud
_isLoading
_isReadyForMoreData
_isValidSegmentationMatteHistogramForDepth:
_item
_jobNumber
_kernelBneg
_kernelBpos
_kernelC
_kernelCNeg
_kernelCPos
_kernelC_hdr
_kernelCast
_kernelH
_kernelLocalContrast
_kernelRH
_kernelV_gt1
_kernelV_lt1
_keyToIdentifierMap
_keyframeSequence
_keyframes
_keyframesForKey:class:
_labelImageCache
_lastUseTime
_layerStack
_layerStackOptions
_layerStackOptionsFromOptions:
_layoutConfiguration
_layoutRegions
_layoutScore
_load:
_loadAssetResource:options:completion:
_loadAssetResourceForProxy:completion:
_loadBackground:completion:
_loadColorsFromValues:mode:error:
_loadFullSizeResource:completion:
_loadItem:completion:
_loadProxyResource:completion:
_loadRegions:completion:
_loadRequestID
_loadSegmentationData:completion:
_loadSegmentationItemFromURL:error:
_loadSegmentationItemFromWallpaperURL:error:
_loadingError
_loadingHandlerQueue
_loadingState
_localConfidenceScore
_localLightDataForImage:
_location
_lookupColor:withPredicate:
_loopTimeRange
_lowMemoryModeSupportedForComposition:
_luminance
_luminanceThresholds
_luminanceWeights
_majorVersion
_manualMax
_manualMin
_map
_matte
_matteFilters
_matteImage
_mattePureBackground
_mattePureForeground
_max
_maxAutoAngle
_maxAutoPitch
_maxAutoStraighten
_maxAutoYaw
_maxDominantColors
_maxFaceSize
_maximumAccumulationStorage
_maximumAperture
_mdataTrack
_medianLuminance
_metadataProcessor
_min
_minAutoStraighten
_minimumAccumulationStorage
_minimumAngleCorrection
_minimumAperture
_minimumConfidence
_minimumPitchCorrection
_minimumPitchCorrectionArea
_minimumYawCorrection
_minimumYawCorrectionArea
_minorVersion
_modeValue
_newHLGPixelBufferOfSize:
_noOpRemovalFunctions
_normalizedClipRect
_normalizedImagePoint
_numberValue
_observation
_optimizeForBackgroundProcessing
_optimizeForSharing
_options
_orientation
_outputImage
_paddedTileKernel
_pairingIdentifier
_paletteWithConfigurationDictionary:error:
_parallaxScore
_parameters
_performLayout:completion:
_performSegmentation:type:completion:
_performedActions
_petRegions
_petsFaceRegions
_petsRegions
_petsRequestID
_pipelineFilters
_pitchAngleDegrees
_pixelBuffer
_pixelFormat
_pixelSize
_platform
_polyKernelHDR
_populateAvailableStyles
_populateDefaultStyles
_portraitMajorVersion
_portraitMinorVersion
_portraitStrength
_preferredCropRect
_preferredRect
_preserveSourceColorSpace
_prewarmPortraitRendererWithPipelineState:error:
_primaryColor
_primaryColors
_primaryURL
_primitiveValueForKey:
_priority
_processedRenderNodeForComposition:input:pipelineState:error:
_progressHandler
_properties
_proxyOnly
_purgeRenderResources
_quality
_queue
_rangeMax
_rangeMin
_rawHomographies
_rawState
_rawTime
_recipesForIdentifiers:withURLProvider:
_recordError:
_recordResult:
_redValue
_refineMaskImage:guideImage:scale:
_reframeCropAdjustment
_reframeVideoAdjustment
_regions
_renderCompanionResources
_renderContext
_renderImage:toPixelBuffer:
_renderInfo
_renderResources
_renderScale
_renderState
_renderTask
_renderTime
_renderer
_reportProgressAtTime:rect:confidence:
_request
_requests
_requireHardwareEncoder
_resolutionRatio
_resource
_responseWithLayerStack:
_results
_rollAngleDegrees
_sampleMode
_sampleRect
_sampleTime
_sampledDisparityValue
_sanitizeComposition:
_saveSegmentationItem:layerStack:toWallpaperURL:completion:
_scalePolicy
_secondaryColors
_segment:completion:
_segmentationBackground
_segmentationClassification
_segmentationConfidenceMap
_segmentationDataURL
_segmentationDisabled
_segmentationItem
_segmentationMatte
_segmentationMatteImage
_segmentationScore
_serializeColors:mode:
_serializeComposition:versionInfo:needsGeometry:error:
_serializeDefinition:
_serializeFilters:
_serializeParameter:
_serializeParameters:
_setKeyframes:forKey:
_setPrimitiveValue:forKey:
_shadowKernelHDR
_shouldApplyWatermark
_shouldCancelHandler
_shouldInfillForeground
_shouldPerformAutoCrop
_shouldPerformAutoStraighten
_shouldRunBuildingCheck
_shouldUseAutoStraightenVerticalDetector
_shouldWaitForDependentJobs
_signpost
_smartSettings
_sourceBufferFromInput:error:
_sourceMode
_sourceTexture
_stabCropRect
_stabilizeImage:cleanRect:cropRect:transform:geometry:
_stackName
_start
_startTime
_stateQueue
_stats
_stillImage
_storagePool
_strength
_style
_styleFromOptions:item:
_subMinorVersion
_subjects
_submit:
_submitClockMaterialRequestWithLayerStack:completion:
_submitClockOverlapRequestWithLayout:completion:
_submitGERenderRequest:
_submitGWRenderRequest:
_submitInactiveLayoutRequest:
_submitLayerStackRequestForMode:layout:completion:
_submitLayerStackRequestsWithLayout:completion:
_suggestionIndices
_systemBuildVersion
_systemName
_systemVersion
_targetScaleForScale:
_task
_temporaryDestinationStorage
_time
_timedMetadata
_touchDiameter
_trajectoryHomography
_tryLoadSegmentationItemFromCache:
_type
_unit
_updateClockAreaLuminance
_updateClockZPosition
_updateInactiveFrame
_updateRenderState:withLegacyCameraInfo:
_updateSettingsWithInputColor:
_updateSettingsWithInputLight:
_upgradeFullPosterAtURL:exportToURL:options:completion:
_upgradeWallpaperAtURL:exportToURL:options:completion:
_useSushi
_useTempTint:
_validateValueTypesForKeys:requiredKeys:inDictionary:error:
_value
_variableName
_version
_versionRules
_videoComplementURL
_videoPosterFrameURL
_videoSource
_videoTrack
_visibleFrame
_visibleRect
_waitForRenderResources:
_whitePointColorFromGrayEdgesImage:grayWorldImage:greenChannelPercentage:RAWCameraSpaceProperties:
_width
_yawAngleDegrees
absoluteString
acceptableCropRect
accumulate:error:
addAdjustmentWithKey:
addAssetIdentifier:toMetadataArray:
addAssetIdentifier:toMetadataDictionary:
addBytes:length:
addCompletedHandler:
addDetectionAndStartTrackingRect:time:colorBuffer:disparityBuffer:
addDetectionForNextFrameAt:colorBuffer:disparityBuffer:
addEntriesFromDictionary:
addImageProperties:composition:options:error:
addIndex:
addMethodDiagnostics:details:
addMethodResultToDiagnostics:error:setYawPitchError:
addMutableTrackWithMediaType:preferredTrackID:
addObject:
addObjectsFromArray:
addOutput:
addRect:
addRule:
addRuleWithHueMin:hueMax:suggestion:
addRulesFromArray:
addVideoProperties:composition:options:error:
adjustment
adjustmentConstants
adjustmentControllerClassForKey:
adjustmentControllerForKey:
adjustmentData
adjustmentDataFormatVersionForComposition:
adjustmentFormat
adjustmentHasCTM:settings:
adjustmentHasPerspective:settings:
adjustmentInformationForComposition:error:
adjustmentInformationForComposition:needsGeometry:error:
adjustmentKeys
adjustmentValuesForKey:
adjustmentVersion
aggregateStatistics:
alignImage:transform:extent:
alignedRowBytesForWidth:
alignment
alignmentKey
allAdjustmentTypes
allAssetsCanUseHDRPipeline
allDetections
allPoints
allValues
allocWithZone:
allowPartialOutputRegion
allowSpillMatteOnOlderPortraitV2Captures
allowedAnalysisTypes
allowedCropFraction
alphaCompositingKernel
alphaCount
alphaValue
amountKey
analysisAvailable
analysisType
analyzeBackground
angle
angleKey
angleRadians
angleSeedDegreesCCW
aperture
apertureAutoEnhanceFiltersForImage:
apertureFocalRatio
apertureKey
apertureKeyframes
apertureRedEyeResultFromFaceObservations:imageSize:
apertureRedEyeSchema
appendFormat:
appendPoints:pointCount:
appendString:
applyAttachmentsToCVPixelBuffer:
applyChangesFromCompositionController:
applyInactiveStyleToImage:error:
applyInputConversion:
applyOrientationFilter
applyOutputConversion:
applyRepairMLStrokeToMutableBuffer:brushStroke:detectedFaces:context:error:
applyRepairStrokeToMutableBuffer:brushStroke:sourceOffset:repairEdges:
applyToRenderRequest:
applyToRenderState:
applyWithExtent:arguments:
applyWithExtent:inputs:arguments:error:
applyWithExtent:roiCallback:arguments:
applyWithExtent:roiCallback:arguments:options:
applyWithExtent:roiCallback:inputImage:arguments:
applyWithInputImage:disparityImage:inputPixelBuffer:disparityPixelBuffer:globalMetadata:timedMetadata:aperture:focusedDisparity:quality:debugMode:isHDR:error:
archiveURL
areCPVAssetsEditable
areaAverageFilter
areaHistogramFilter
array
arrayByAddingObject:
arrayWithCapacity:
arrayWithObjects:count:
asOrderedInteger
asset
asset:
assetIdentifierForURL:type:useEmbeddedPreview:
assetIsCinematicVideo:
assetReaderWithAsset:error:
assetUUID
assetWithURL:
attributeBlackPointKey
attributeBrightnessKey
attributeCastKey
attributeContrastKey
attributeExposureKey
attributeGrainKey
attributeHighlightsKey
attributeLightMapHeightKey
attributeLightMapKey
attributeLightMapWidthKey
attributeLocalLightKey
attributeNeutralGammaKey
attributeShadowsKey
attributeStrengthKey
attributeToneKey
attributeVibrancyKey
audioMix
audioMixInputParametersWithTrack:
autoAdjustmentFiltersWithOptions:
autoCalculatorWithImageData:orientation:
autoCropFilter
autoCropped
autoEnhanceCache
autoEnhanceFiltersForImage:algorithm:
autoKeysForPaste
autoLoopAdjustmentController
autoLoopAdjustmentControllerCreatingIfNecessary:
autoLoopExportRequest
autoLoopSchema
autoStraightenDominantAngleDiffThreshold
autoStraightenVerticalAngleThreshold
autoValuesForBlackPoint:whitePoint:
autoloopStabilizedVideoFilter
autorelease
auxiliaryCoreGraphicsInfoDictionary:
auxiliaryDataInfoMetadata
auxiliaryImage
auxiliaryImageFromComposition:type:mediaComponentType:error:
auxiliaryImageType
auxiliaryImagesProperties
available
availableBlendModes
availableDecoderVersions
availableKeys
availableStyleOfKind:
averageCGPoints:pointCount:
averagePoints:pointCount:
backfillScalePolicy
backgroundBuffer
backgroundColors
backgroundFilters
backgroundForImage:matte:
backgroundForImage:matte:infill:
backgroundLuminance
bakedStyle
baseAddress
begin
beginGroupWithName:error:
bestCropRectV2ForAspectRatio:sourcePixelWidth:sourcePixelHeight:sourceEssentialAreaRect:sourceSecondaryEssentialAreaRect:outputCropScore:
bestCropRectV2ForAspectRatio:withFocusRegion:sourcePixelWidth:sourcePixelHeight:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:outputCropScore:
bestCropRectV2ForParallaxClassification:layoutConfiguration:sourcePixelWidth:sourcePixelHeight:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:outputCropScore:outputLayoutScore:outputClockOverlapAcceptable:
bestLayout:
bilateralAdd1Kernel
bilateralAdd2Kernel
bilateralAdd3Kernel
bilateralAdd4Kernel
bilateralAdd5Kernel
bilateralAdd6Kernel
bilateralAdd7Kernel
bilateralAdd8Kernel
bilateralAdd9Kernel
bilateralAddROI:destRect:userInfo:
bilateralFinalizeKernel
bilateralKernels
bilateralLoop11Kernel
bilateralLoop2Kernel
bilateralLoop5Kernel
bimodalScoreForHistogram:
blackColor
blackImage
blackInfillImage:matte:
blendKernelForBlendMode:
blendWithMaskFilter
blue
blueColor
blueValue
blur3x3Kernel
blur5x5Kernel
blur7x7Kernel
boolForKey:
boolValue
boostCurveValueAt:
boostParametersFromRawProperties:
boundingBox
boundingBoxes
boundingBoxesKey
bounds
boundsForPointArray:
brushStrokeFromRetouchStrokeDictionary:
buffer
bufferColorspace
bufferFactory
buildNumber
bypassOutputSettingsIfNoComposition
bytes
bytesAtPoint:
bytesPerPixel
bytesPerRow
cache
cacheImage:key:format:colorSpace:
cacheKey
cacheNode:type:settings:error:
cacheURL
cachedImage
cachedImage:forKey:
calcExtentsForStrokeRadius:offset:inputImageExtent:maskExtent:repairExtent:textureExtent:sourceExtent:
calculateClockLuminanceValuesForLayerStack:renderer:error:
calculateColorWithProperties:completion:
calculateCurveTable:
calculateLuminanceValuesForImage:renderer:error:
calculateRAWWithRequest:completion:
calculateSettingsForImageHistogram:
calculateSettingsForSingleChannelHistogram:suffix:
calculateWithRequest:completion:
callStackSymbols
cameraCalibrationData
cameraInfo
canAddOutput:
canAdjustApertureValue
canApplyPortraitEffectsWithMetadata:
canBeEnabled
canGenerateNewCropRect:
canHaveAuto
canInflate
canInterpretDataWithFormatIdentifier:formatVersion:
canPerformGyroBasedStabilizationForAsset:
canPropagateOriginalAuxiliaryData
canPropagateOriginalLivePhotoMetadataTrack
canProvideMetadataForAVAsset:
canRenderDepth
canRenderPortraitEffect
cancel
cancelAllRequests
cancelParallaxResourceRequest:
cancelPetsRegionsRequest:
cancelSegmentationForAsset:
canceledError:object:
candidacy
capabilitiesForCurrentDevice
captureDebugDirectoryForComposition:
capturedAperture
caseInsensitiveCompare:
changeDelegate
changesDictionaryTrimmedByTimeRange:
chroma
ciImageTiled:closed:pressureMode:
cinematicAllowRGB10Packed
cinematicAllowYUVSourceInput
cinematicMetadataFromAsset:
cinematographyScript
cinematographyState
class
classification
cleanAperture
cleanApertureOfTrack:oriented:
clientRequestedStop
clipRect
clockAreaLuminance
clockColor
clockFont
clockIntersection
clockIntersectionFromTopRectMatteCoverage:bottomRectMatteCoverage:
clockLayoutRequest
clockMaterialRequest
clockOverlapAcceptable
clockOverlapAcceptableForLayoutConfiguration:
close
close:
color
colorAnalysis
colorAnalysisRequest
colorBGPalette
colorBalanceKernel
colorBalanceKernels
colorBuffer
colorCubeForNormalization:dimension:targetColorSpace:
colorInvertFilter
colorNormalizationFiltersForImage:
colorPaletteWithStyleKind:
colorSize
colorSpace
colorSpaceFromColorPrimaries:transferFunction:yccMatrix:
colorSpaceFromVideoColorProperties:
colorSuggestionForCategory:
colorSuggestions
colorThresholdFilter
colorType
colorTypeForString:
colorTypeKey
colorWashDuotonePalette
colorWashFixedKernel
colorWashFixedSmoothKernel
colorWashKernels
colorWashSinglePalette
colorWashVariableKernel
colorWashVariableSmoothKernel
colorWithCGColor:
colorWithRGBValues:error:
colorWithRed:green:blue:
colorWithRed:green:blue:alpha:
colorWithRed:green:blue:alpha:colorSpace:
colorWithRed:green:blue:colorSpace:
colors
commitAndNotifyOnQueue:withBlock:
companionImageData
companionVideoURL
compare:
complete:
completedTrack
componentMax
componentMin
componentsJoinedByString:
componentsSeparatedByString:
composition
compositionByRemovingVideoAndLivePhotoAdjustments:
compositionController:adjustmentControllerClassForKey:
compositionController:didAddAdjustment:
compositionController:didRemoveAdjustment:
compositionController:didUpdateAdjustment:
compositionController:didUpdateAdjustments:
compressData:options:error:
computeAlphaCoverageWithRect:foregroundImage:context:
computeAvoidOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:outputUnsafeOverlap:context:
computeClockLayerOrderWithVisibleFrame:foregroundImage:layoutConfiguration:context:
computeClockLayerOrderWithVisibleFrame:segmentationMatte:layoutConfiguration:context:interactive:
computeCommandEncoder
computeCropScoreForIntermediate:
computeDigest
computeHeadroomZoomFactorWithVisibleFrame:zoomTowardsTop:matte:layoutConfiguration:context:
computeHistogramFromBuffer:error:
computeInactiveAvoidingRectForVisibleRect:acceptableFrame:unsafeRect:imageSize:newVisibleRect:
computeInactiveFrameWithVisibleFrame:imageSize:canUpdateVisibleRect:segmentationMatte:layoutConfiguration:context:
computeLayoutsWithHelper:
computeMatteCoverageWithRect:segmentationMatte:context:
computeSegmentationScoresForAsset:options:completion:
computeTargetOverlapYOffsetWithVisibleFrame:imageSize:segmentationMatte:layoutConfiguration:context:
computedSettings
confidence
confidenceMapBuffer
confidenceMapScore
confidencePureBackground
confidencePureForeground
configuration
configurationType
configurationWithDeviceName:
configureForCategory:
conformRange:inRange:
conformsToProtocol:
constants
constraintHeight
constraintHeightKey
constraintWidthKey
containsIndex:
contents
contentsDictionary
contextForContext:
contextInfo
contextWithOptions:
conversionMap
convertFacePoint:toImagePointWithFaceRect:orientation:
convertFixed16:toFloat:count:
convertFloat:toFixed16:count:
convertHueChromaImageToIPT:
convertHueChromaImageToRGB:
convertIPTImageToHueChroma:
convertIPTImageToRGB:
convertRGBImageToHueChroma:
convertRGBImageToIPT:
convertToIPT:
coolColor
copy
copyItemAtURL:toURL:error:
copyKeyframesTrimmingToTimeRange:
copyOfAdjustmentRemovingNoOps:identifier:
copyPixelsFromImage:rect:destPtr:destPtrRowBytes:
copyPixelsFromImage:srcRect:destImage:destOrigin:
copyPixelsToImage:atPoint:fromBuffer:inRect:
copyPixelsToImage:rect:srcPtr:srcPtrRowBytes:
copyWithZone:
count
countByEnumeratingWithState:objects:count:
createCGImage:fromRect:
createCGImage:fromRect:format:colorSpace:deferred:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
createHueArray
createRGBA:
createRenderStateWithQuality:
createSloMoWithInput:startTime:endTime:rate:error:
createYUV420:chroma:
cropAdjustmentController
cropAdjustmentControllerCreatingIfNecessary:
cropFraction
cropRect
cropSchema
cropScore
cropScoreThresholdForClassification:
crossfadeDuration
crossfadeDurationTimescaleKey
crossfadeDurationValueKey
curatedSegmentationGatingDecisionForSegmentationScores:
currentContext
currentContextInfo
currentDirectoryPath
currentFormatVersion
currentHandler
currentSoftwareVersion
currentSystemCanRenderAsset:
currentSystemRenderingVersion
currentVersion
curvePointAtIndex:blackPoint:whitePoint:histogram:
curvePointsFromDictionaries:
curvesKernel
curvesSchema
customAttributes
customPalette
data
dataForImageBuffer:error:
dataType
dataValue
dataWithBytes:length:
dataWithBytesNoCopy:length:freeWhenDone:
dataWithJSONObject:options:error:
dataWithPropertyList:format:options:error:
debugColorAnalysisBuffer
debugColorAnalysisImage
debugConfidenceMapBuffer
debugConfidenceMapImage
debugDescription
debugDescriptionOfAssetTrack:
debugDiagnostics
debugDumpIntermediateImages
debugFilesEnabled
debugFilesPrefix
debugImageCollector
debugImageForColorAnalysis:inputImage:visibleFrame:
debugImageWithInputImage:finalLayout:intermediateLayout:faceRects:saliencyPreferrectRect:saliencyAcceptableRect:
debugImageWithInputImage:layout:faceRects:saliencyPreferrectRect:saliencyAcceptableRect:
debugInfillBuffer
debugInfillImage
debugInputBuffer
debugIntermediateLayoutBuffers
debugIntermediateLayoutImages
debugLayoutBuffer
debugLayoutImage
debugLayouts
debugLineDetectionImage
debugLocalConfidenceBuffer
debugLocalConfidenceImage
debugMatteBuffer
debugMatteCropBuffer
debugMatteCropImage
debugMode
debugNodeByApplyingFilterWithName:useHDRFilter:settingsAndInputs:
debugPreviewBuffer
debugPreviewImage
debugPreviewRenderWithBackground:foreground:layout:style:
debugSchema
debugTintedImage:isBackfill:
decimalDigitCharacterSet
decodeData:filename:error:
decodeDoubleForKey:
decodeIntegerForKey:
decodeObjectForKey:
decodingSupportForAVAsset:
decompressData:options:error:
defaultDominantColorWithAnalysis:
defaultFocalLength
defaultFormatForURL:
defaultLayout
defaultManager
defaultStyleForKind:colorAnalysis:
defaultStyleOfKind:
defaultStyles
defaultValue
defaultValueForKey:
definition
definitionAdjustmentController
definitionAdjustmentControllerCreatingIfNecessary:
definitionKernel
definitionSchema
denormalizeHueChromaImage:
depth
depthAdjustmentController
depthAdjustmentControllerCreatingIfNecessary:
depthBlurEffectRenderingParameters
depthBlurEffectSimulatedAperture
depthCameraCalibrationData
depthDataQuality
depthEffectInfoDictionaryFromFaceObservations:focus:valuesAtCapture:lumaNoiseScale:orientation:
depthEffectInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
depthEffectSchema
depthEnabled
depthInfo
depthInfoKey
depthMax
depthMin
depthVersionInfo
description
descriptionForCandidacy:
deserializeCompositionFromAdjustments:metadata:formatIdentifier:formatVersion:error:
deserializeCompositionFromData:formatIdentifier:formatVersion:error:
deserializeDictionaryFromData:error:
deserializeFromDictionary:error:
deserializeMetadataWithType:fromGlobalMetadata:error:
deserializeRecipe:error:
destination
destinationLongExposureURL
destinationMaskURL
destinationUTI
detectionType
device
deviceConfiguration
deviceResolution
deviceScalePolicy
deviceSupportsHardware10BitHEVCEncoding
deviceSupportsHighDynamicRangeVideo
dictionariesFromPoints:
dictionary
dictionaryForKey:
dictionaryFromLayoutConfiguration:
dictionaryFromRegions:
dictionaryRepresentation
dictionaryWithContentsOfFile:
dictionaryWithContentsOfURL:error:
dictionaryWithDictionary:
dictionaryWithLayout:
dictionaryWithObjects:forKeys:count:
dictionaryWithObjectsAndKeys:
dictionaryWithStyle:
differingAdjustmentsWithComposition:
digest
dilateMask:withRadius:
disableApertureEffects:
disableIOSurfacePortaitExport
disableOnFrontFacingCameraImages
disableOnPanos
disableRendering
disableSegmentation
discreteProgressWithTotalUnitCount:
disparityKeyframes
disparitySize
dispatchThreadgroups:threadsPerThreadgroup:
displayInputKeys
displayName
displayP3ColorSpace
disposition
distanceToColor:
doBilateralLoop:points:weights:slope:
doBilateralPass:points:weights:sums:slope:
dominanceThreshold
dominantColor
dominantColors
dominantGrays
dominantHues
doubleForKey:
doubleValue
downloadProgressHandler
dynamismMapKernel
dynamismMapRefineKernel
edgeBleed
edgesKey
editConfiguration
editSettings
editable
effect3DAdjustmentController
effect3DAdjustmentControllerCreatingIfNecessary:
effect3DSchema
effectAdjustmentController
effectAdjustmentControllerCreatingIfNecessary:
effectNameForFilterName:
effectSchema
effectiveAcceptableRectForClassification:havePetFaces:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:
effectivePreferredRectForClassification:havePetFaces:sourcePreferredCropRectNormalized:sourceAcceptableCropRectNormalized:sourceFaceAreaRectNormalized:
enableHDRSupport
enabledKey
encodeData:filename:error:
encodeDouble:forKey:
encodeInteger:forKey:
encodeObject:forKey:
encodeRenderTo:withRenderRequest:
encodeToCommandBuffer:destinationTexture:
encodeWithCoder:
encodedPixelSizeOfTrack:oriented:
endEncoding
endGroupWithName:error:
endKey
endScaleKey
enlargedBounds:withPoints:
enumerateIndexesUsingBlock:
enumerateKeysAndObjectsUsingBlock:
enumerateObjectsUsingBlock:
erodeMask:withRadius:
error
errorWithCode:reason:object:
errorWithCode:reason:object:underlyingError:
errorWithDomain:code:userInfo:
estimatedCenterMotion
estimatedMotionBlur
evaluate:input:pipelineState:error:
evaluateWithContext:error:
evaluationMode
exceptionWithName:reason:userInfo:
exifOrientationAndCropStraightenOnly
expandedBounds
exportComposition:options:completionQueue:completion:
exportComposition:toPrimaryURL:videoComplementURL:videoPosterFrameURL:priority:completionQueue:completion:
exportImageToDataWithComposition:options:completion:
exportImageToURL:composition:options:completion:
exportVideoToURL:composition:options:completion:
exportWallpaperForAsset:toURL:options:completion:
extent
extractDataToDictionary:dataExtractor:options:context:colorSpace:error:
extractRGBAfPixelsFromImage:fromROI:
faceBalanceFromFaceImage:forFaceRect:
faceBalanceKernels
faceBalanceResultFromFaceObservations:request:error:
faceBoundingBoxesKey
faceI
faceIKey
faceJunkinessIndex
faceLocalConfidence
faceObservationCache
faceObservationsData
faceOrientationIndex
facePositionAcceptable
facePositionAcceptable:imageAspect:
faceQ
faceQKey
faceRectFromNormalizedFaceRet:forImageExtent:scaleX:scaleY:
faceRegions
faceRequestWithRequest:
faceSize
faceStrength
faceWarmth
faceWarmthKey
faces
factCandidateForHorizon
factCandidateForPerspective
factCandidateForReframe
factCandidateForStill
factCandidateForVideo
failureError:object:
falloffKey
falseColorHDR
falseColorHDRKey
fastInfillImage:matte:
fileExistsAtPath:
fileType
fileURLWithPath:
fillSourceTexture:intoDestinationTexture:withCommandBuffer:
filter
filterLumaKernel
filterName
filterNameForEffectName:
filterWithName:withInputParameters:
finalize
finalizeTrack
finalizerError
firstEnabledVideoTrackInAsset:error:
firstObject
flattenedBackgroundForDebugPreview
flattenedForegroundForDebugPreview
flavor
flavorKey
floatForKey:
floatValue
floatValueForKey:defaultValue:clearIfNotDefault:
focusDetection
focusRectDictionaryFromMetadata:
focusRectDictionaryFromRect:
focusRectangle
focusedDisparity
force
forceGlassesMatteOff
forceSpillMatteOff
foregroundBuffer
foregroundColors
foregroundFilters
foregroundForImage:matte:
foregroundLuminance
format
formatDescriptions
formatForInputAtIndex:
formatIdentifier
formatVersion
formatVersionForAdjustment:identifier:
frameDuration
frameNearestTime:
frameRect
framedRectImageWithCGRect:color:borderWidth:
freeAllResources:
freeResources
fullSizeGeometry
fusionKernel
gHDRtoPPKernel
gainMapParametersFromRawProperties:
gatingResultForSegmentationScores:
generateLayerStackForItem:style:layout:options:completion:
generateLayoutForLayoutConfiguration:imageSize:regions:parallaxClassification:context:matte:layoutScore:cropScore:clockOverlapAcceptable:
genericConfiguration
genericLandscapeSceneLabel
genericRGBLinearColorSpace
geometry
geometryBasedAdjustmentIdentifiers
getCropRectThatCompletelyContainsMasterImageForPitch:yaw:roll:
getMTLTextureFromPixelBuffer:device:
getMap
getMinMaxSimulatedApertureFrom:minValue:maxValue:version:
getNonNormalizedSettings:
getRectForPoint:colorBuffer:
getResourceValue:forKey:error:
getSizeOfAllFaces:
getTagWithPath:error:
getValue:
glassesMatteAllowed
glassesMatteAllowedKey
globalMetadata
globalSession
globalSettings
gradeForFact:
grain
grainInputSeedFromFrameTime
grainKey
grainSchema
grayI
grayIKey
grayQ
grayQKey
grayStrength
grayWarmth
grayWarmthKey
grayY
grayYKey
green
greenValue
gridSizeForThreadGroupSize:imageSize:
groundedScore
groundedScoreForSegmentationMatte:context:
groupSizeForImageSize:pipelineState:
guideExtent
guideImage
handleFailureInFunction:file:lineNumber:description:
handleFailureInMethod:object:file:lineNumber:description:
handlePIGlobalSettings:
hasAutoKeyInSchema
hasColorParameter
hasCorrections
hasInputKey:
hasPerformedAction:
hasPrefix:
hasStaticTime
hash
height
heightKey
highKeyProperties
highKeyTone
highResFusionAdjustmentController
highResFusionAdjustmentControllerCreatingIfNecessary:
highResFusionSchema
histogram
histogramCalculationColorSpace
histogramForSegmentationMatte:
histogramForSegmentationMatteImage:
histogramOptimizationFilter
homography
homographyAtTime:
homographyKernel
hueAngleFrom:
hueArrayImage:
hueChromaColorWashDuoFixedKernel
hueChromaColorWashDuoKernel
hueChromaColorWashDuoVariableKernel
hueChromaColorWashKernel
hueChromaFixedColorWashKernel
hueChromaImage
hueChromaKernels
hueChromaVariableColorWashKernel
hueKey
hueSatLumTable
hwModelID
identifier
image
imageBufferFromData:error:
imageBufferWithSize:format:fromPool:
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
imageByApplyingGaussianBlurWithSigma:
imageByApplyingTransform:
imageByApplyingTransform:highQualityDownsample:
imageByCachingImage:format:colorSpace:key:
imageByClampingToExtent
imageByColorMatchingColorSpaceToWorkingSpace:
imageByColorMatchingWorkingSpaceToColorSpace:
imageByCompositingOverImage:
imageByCroppingToRect:
imageByPremultiplyingAlpha
imageByUnpremultiplyingAlpha
imageExportFormat
imageExportFormatForURL:
imageFileURL
imageHistogram
imageLayer:frame:zPosition:identifier:
imageOrientation
imageProperties:
imagePropertiesRequestWithComposition:
imageRect
imageRenderRequestWithComposition:fillInSize:wideGamut:
imageRenderRequestWithComposition:fitInSize:wideGamut:
imageSize
imageSourceWithCIImage:orientation:
imageSourceWithURL:type:proxyImage:orientation:useEmbeddedPreview:
imageSourceWithURL:type:useEmbeddedPreview:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
imageWithBitmapData:bytesPerRow:size:format:options:
imageWithCGImage:
imageWithCGImage:options:
imageWithCVPixelBuffer:
imageWithColor:extent:
imageWithData:
imageWithNUImageBuffer:
inUse
inactiveFilter
inactiveFrame
inactiveRecipeIdentifier
inactiveRect
inactiveStrategy
includeCinematicVideoTracks
increaseBitRateIfNecessary
indexOfColor:
indexOfObject:
indexOfObject:inSortedRange:options:usingComparator:
indexOfObjectPassingTest:
indexesOfShallowDepthOfFieldObservations
infillRequest
infilledImage
inflatePersonFaceRect:
infoDictionary
init
initFromMinAperture:maxAperture:aperture:portraitStrength:SDOFRenderingVersion:depthVersionInfo:
initWithAVAsset:
initWithAcceptableRect:preferredRect:faces:pets:
initWithAdjustment:
initWithAffineTransform:
initWithAnalysisData:
initWithArchiveURL:
initWithArray:
initWithAsset:
initWithAutoLoopExportRequest:
initWithBackgroundColor:clockColor:colorSuggestions:
initWithBase64EncodedString:options:
initWithBaseURL:
initWithBinCount:range:
initWithBitmapData:width:height:bytesPerRow:format:
initWithBuffer:colorSpace:validRegion:
initWithBytes:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithCGColorSpace:
initWithCIContext:matte:parallaxClassification:initialRect:imageSize:effectiveAcceptableRect:effectivePreferredRect:layoutConfiguration:
initWithCIImage:options:
initWithCIImage:orientation:
initWithCVPixelBuffer:
initWithCVPixelBuffer:options:
initWithCapacity:
initWithClockAreaLuminance:
initWithClockColor:colorSuggestions:
initWithCoder:
initWithColor:clockColor:suggestions:
initWithColorAnalysis:
initWithCommandQueue:
initWithCompletedTrack:
initWithComposition:
initWithComposition:dataExtractor:options:
initWithComposition:destinationURL:
initWithComposition:location:touchDiameter:
initWithComposition:responseQueue:
initWithComposition:stabilizedVideoURL:longExposureDestinationURL:maskDestinationURL:destinationUTI:
initWithComposition:startTime:pointToTrack:
initWithComposition:tag:responseQueue:
initWithComposition:time:sampleRect:
initWithComposition:useSushi:
initWithContentsOfFile:
initWithContentsOfURL:options:error:
initWithCount:times:values:
initWithData:width:height:bytesPerRow:bytesPerComponent:format:colorspace:
initWithDescriptor:
initWithDevice:colorSize:disparitySize:quality:debugMode:
initWithDevice:version:colorSize:disparitySize:
initWithDictionary:
initWithDictionaryRepresentation:
initWithDisparityValue:
initWithDisposition:composition:
initWithDomain:code:userInfo:
initWithError:
initWithExtent:renderScale:orientation:
initWithFileURL:
initWithFilterName:parameters:
initWithFilterName:settings:inputs:
initWithHue:tone:
initWithIdentifier:
initWithIdentifier:recipe:
initWithImage:format:colorSpace:
initWithImageProvider:width:height:format:colorSpace:options:
initWithImageSize:deviceResolution:parallaxPadding:visibleFrame:inactiveFrame:timeFrame:clockLayerOrder:clockIntersection:debugLayouts:
initWithImageSourceDefinition:videoSourceDefinition:
initWithIndexesInRange:
initWithInput:
initWithInput:assetURL:cinematographyState:monochrome:
initWithInput:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:
initWithInput:scale:
initWithInput:timeRange:crossfadeDuration:startTime:
initWithKeyframeArray:
initWithKeyframes:stabCropRect:analysisType:rawHomographies:
initWithKeyframes:stabCropRect:input:
initWithKind:parameters:colorSuggestions:
initWithLayerStack:
initWithLayers:size:layout:depthEnabled:parallaxDisabled:clockAreaLuminance:
initWithLevel:
initWithLuma:hue:chroma:
initWithMajor:minor:subMinor:
initWithMajor:minor:subMinor:platform:
initWithMasterImageRect:stitchedImageRect:
initWithMasterImageSize:
initWithMasterImageSize:stitchedImageSize:
initWithMetadataGroup:majorVersion:minorVersion:error:
initWithMetalDevice:options:
initWithMin:max:manualMin:manualMax:depthMin:depthMax:
initWithMode:
initWithMutableBuffer:colorSpace:validRegion:
initWithName:
initWithName:responseQueue:
initWithNode:context:
initWithNumber:unit:
initWithParallaxAsset:
initWithParallaxClassification:initialRect:imageSize:effectiveAcceptableRect:effectivePreferredRect:layoutConfiguration:
initWithParallaxClockLayoutRequest:
initWithParallaxColorAnalysisRequest:
initWithParallaxInfillRequest:
initWithParallaxLayerStackRequest:
initWithParallaxLayoutInactiveFrameRequest:
initWithParallaxLayoutRequest:
initWithParameters:foregroundFilters:backgroundFilters:matteFilters:
initWithPipelineState:
initWithPixelBuffer:
initWithPrimaryColor:secondaryColor:
initWithPrimaryColor:secondaryColor:clockColor:colorSuggestions:
initWithPrimaryColors:secondaryColors:
initWithPrimaryColors:secondaryColors:suggestionIndices:
initWithProperties:
initWithRadius:softness:opacity:clipRect:pressureMode:
initWithRect:
initWithRed:green:blue:
initWithRed:green:blue:alpha:
initWithRed:green:blue:alpha:colorSpace:
initWithRequest:
initWithRequest:dataExtractor:options:
initWithRequest:isRAW:
initWithRequest:options:
initWithScript:block:
initWithSegmentationItem:
initWithSegmentationItem:parallaxAsset:
initWithSettings:inputs:
initWithSize:format:
initWithSize:format:rowBytes:bytes:
initWithSize:format:rowBytes:mutableBytes:
initWithSize:renderer:jobNumber:
initWithSourceDefinitions:
initWithStackName:filters:
initWithTargetPixelCount:
initWithTargetPixelSize:
initWithTargetScale:effectiveScale:sampleMode:input:
initWithTargetSize:
initWithTargetedCVPixelBuffer:options:
initWithTime:homography:
initWithTime:value:
initWithTrack:outputSettings:
initWithType:source:identifier:confidence:
initWithURL:
initWithURL:UTI:
initWithVariableName:
initWithVideoExportRequest:
initWithVisibleRect:inactiveRect:zoomStrategy:overlapStrategy:parallaxStrategy:inactiveStrategy:
initWithVisibleRect:inactiveRect:zoomStrategy:overlapStrategy:parallaxStrategy:inactiveStrategy:cropScore:layoutScore:timeBottomOverlap:timeTopOverlap:unsafeAreaOverlap:uninflatedUnsafeAreaOverlap:
initWithX:Y:
initWithX:Y:unit:
initWithX:y:editable:
initialize
inpaintingInfillImage:matte:
input
inputAlgorithm
inputAlignmentExtent
inputAlignmentTransform
inputAmount
inputAperture
inputBackgroundImage
inputBlack
inputBlackDstBlue
inputBlackDstGreen
inputBlackDstRGB
inputBlackDstRed
inputBlackKey
inputBlackSrcBlue
inputBlackSrcGreen
inputBlackSrcRGB
inputBlackSrcRed
inputBlendMode
inputBlurImage
inputBoost
inputBorder
inputBrightnessKey
inputCameraModel
inputCast
inputCastKey
inputChromaMax
inputChromaMin
inputColor
inputColorKey
inputColorPixelBuffer
inputContrast
inputContrastKey
inputCorrectionInfo
inputCorrectionInfoKey
inputCorrections
inputCutoff
inputDecoderVersion
inputDepthMap
inputDestinationImage
inputDisparityImage
inputDisparityPixelBuffer
inputExposure
inputExposureKey
inputFocusedDisparity
inputForKey:
inputForPath:error:
inputForegroundImage
inputGlobalRenderingMetadata
inputGrain
inputGrainKey
inputHasFace
inputHighlightColor
inputHighlightsKey
inputHilightDstBlue
inputHilightDstGreen
inputHilightDstRGB
inputHilightDstRed
inputHilightSrcBlue
inputHilightSrcGreen
inputHilightSrcRGB
inputHilightSrcRed
inputHue
inputHueIsNormalized
inputHueKey
inputHueRange
inputHueTarget
inputISO
inputImage
inputIntensity
inputIsHDR
inputIsRaw
inputKeys
inputLight
inputLightDefault
inputLightKey
inputLightMap
inputLightMapHeight
inputLightMapImage
inputLightMapWidth
inputLocalLightKey
inputLumaRange
inputMaskImage
inputMidDstGreen
inputMidDstRGB
inputMidDstRed
inputMidSrcGreen
inputMidSrcRGB
inputMidSrcRed
inputMode
inputNeutralGamma
inputNeutralGammaKey
inputNeutralXYFromRGB:
inputNormalization
inputOrigI
inputOrigQ
inputParams
inputPoints
inputPointsB
inputPointsG
inputPointsL
inputPointsR
inputRAWGamutMapMaxKey
inputRadius
inputRawHighlights
inputRawHighlightsKey
inputRenderDebugMode
inputRenderQuality
inputRenderScale
inputSaturationKey
inputScale
inputScaleFactor
inputSeed
inputSeedKey
inputShadowColor
inputShadowDstBlue
inputShadowDstGreen
inputShadowDstRGB
inputShadowDstRed
inputShadowSrcBlue
inputShadowSrcGreen
inputShadowSrcRGB
inputShadowSrcRed
inputShadows
inputSize
inputSmartShadows
inputSpots
inputStreamWithURL:
inputStrength
inputStrengthKey
inputTargetImage
inputTemperature
inputThreshold
inputTimedRenderingMetadata
inputTint
inputToCropFilter
inputTone
inputToneKey
inputVersion
inputVibrancy
inputVideoProperties
inputWarmTemp
inputWarmTint
inputWarmth
inputWeights
inputWhiteDstBlue
inputWhiteDstGreen
inputWhiteDstRGB
inputWhiteDstRed
inputWhiteSrcBlue
inputWhiteSrcGreen
inputWhiteSrcRGB
inputWhiteSrcRed
inputs
insertObject:atIndex:
insertTimeRange:ofTrack:atTime:error:
instructions
intValue
integerForKey:
integerValue
integralCropRect:
intensity
intensityKey
intermediateWithInactiveStrategy:intermediate:
intermediateWithOverlapStrategy:intermediate:
intermediateWithZoomStrategy:intermediate:
internalComposition
interpolateFromStart:toEnd:progress:
interpolation
invalidError:object:
inverseAggregatedCurveValueAt:
inverseHLGLumaBlendingKernel
invertImage:
invertedSet
iosCropToolFilter
iptColorWashDuoFixedKernel
iptColorWashDuoKernel
iptColorWashDuoVariableKernel
iptFromLinearInto:fromRed:green:blue:
iptHueAngleFromRed:green:blue:
is3DEffect:
isAVAssetDolbyProfile5:error:
isAVAssetEditable:reason:
isAnalysisAvailable
isAnimal
isAppleProRaw
isAssetUnsupportedLegacyPortraitVideo:
isAuto
isAvailable
isCIFilterAvailable:propertyName:
isCanceled
isCandidateForHorizon
isCandidateForPerspective
isCandidateForReframe
isComplete
isCool
isCropConstrained
isCropIdentityForImageSize:
isDefaultWarmth:
isDepthDataFiltered
isDepthEnabled
isEditable
isEnabled
isEqual:
isEqual:forKeys:
isEqual:forKeys:comparisonBlock:
isEqual:forKeys:visualChangesOnly:
isEqual:visualChangesOnly:
isEqualToAdjustmentController:
isEqualToAdjustmentVersion:
isEqualToDate:
isEqualToDictionary:
isEqualToLayoutConfiguration:
isEqualToNumber:
isEqualToParallaxStyleDefinition:
isEqualToParallaxStyleFilterDefinition:
isEqualToParallaxStyleFilterStackDefinition:
isEqualToParallaxStyleParameter:
isEqualToParallaxStyleRecipe:
isEqualToPixelFormat:
isEqualToString:
isExportable
isFrontFacingCameraImage:pixelSize:
isFusedOvercapture
isHDR
isHDRComposition:
isInCloud
isKindOfClass:
isMLInpaintingAvailable
isMemberOfClass:
isMetalDeviceSupported:
isObject
isOriginalCrop
isPerspectiveZoomEnabled
isPlayable
isPortraitEffect:
isPortraitStageEffect:
isProxyOnly
isReadable
isReadableFileAtPath:
isReadyForMoreData
isRenderVersionSupported:
isSegmented
isSegmentedStyle:
isSensorRawCapture
isSettingEqual:forKey:
isSourceAvailable:sourceSettings:
isStillImageDisparity:
isSubclassOfClass:
isUnifiedBracketingHDRCapture
isValidSegmentationScoreForDepth:
isWarm
items
itur2100HLGColorSpace
jobNumber
jsContext
kernel
kernelBlackAndWhite
kernelFB0
kernelFB3
kernelNamed:
kernelWithFunctionName:fromMetalLibraryData:error:
kernelWithString:
kernelsDictionaryWithString:
kernelsWithString:
keyFrameTime
keyframeInArray:closestToTime:
keyframeSequence
keyframes
keyframesFromDictionaryRepresentations:
keyframesKey
kind
knownFormatsVersionsMap
label
labels
landmarks
lastIndex
lastObject
lastPathComponent
lastUseTime
latestVersion
layerForBuffer:image:zPosition:identifier:
layerStack
layerStackByUpdatingClockAreaLuminance:
layerStackByUpdatingDepthEnabled:
layerStackByUpdatingLayers:
layerStackByUpdatingParallaxDisabled:
layerStackMode
layerStackOptions
layerStackRequest
layers
layout
layoutByUpdatingClockIntersection:
layoutByUpdatingClockLayerOrder:
layoutByUpdatingImageSize:
layoutByUpdatingInactiveFrame:
layoutByUpdatingNormalizedVisibleFrame:
layoutByUpdatingVisibleFrame:
layoutByUpgradingToConfiguration:
layoutConfiguration
layoutConfigurationFromDictionary:error:
layoutGatingDecisionForSegmentationScores:
layoutInactiveFrameRequest
layoutRegions
layoutRequest
layoutScore
layoutWithDictionary:
length
levelsSchema
lightMapImage
linearGrayColorSpace
linearWideGamutColorSpace
livePhotoKeyFrameAdjustmentController
livePhotoKeyFrameAdjustmentControllerCreatingIfNecessary:
livePhotoKeyFrameMetadataFromNode:time:error:
livePhotoKeyFrameSchema
livePhotoSourceWithPhotoSource:videoSource:
loadContentsFromDictionary:hasMatte:hasBackground:error:
loadFilterWithName:
loadFromArchiveURL:error:
loadFromContentsDictionary:error:
loadFromURL:
loadFromURL:error:
loadFusionTuningParameters
loadLayerStackFromURL:options:error:
loadLayerStackFromWallpaperURL:options:error:
loadPaletteFromURL:error:
loadPaletteWithName:
loadParallaxResource:options:resultHandler:
loadPetsRegions:
loadSegmentationDataFromURL:error:
loadSegmentationItemForAsset:options:completion:
loadSegmentationItemFromURL:error:
loadSegmentationItemFromWallpaperURL:error:
loadSegmentationItemWithCompletion:
loadWithAsset:changesDictionary:completion:
loadingHandler
loadingHandlerQueue
loadingState
localConfidenceImage:
localConfidenceScore
localConfidenceScoreForLocalConfidenceImage:extent:context:
localLightData
localLightHDRStatisticsNoProxy
localLightStatisticsNoProxy
locallySupportedFormatVersions
logger
longExposureFusionKernels
longLongValue
loopTimeRange
loopTimeRangeDurationTimescaleKey
loopTimeRangeDurationValueKey
loopTimeRangeStartTimescaleKey
loopTimeRangeStartValueKey
lowKeyTone
luma
luminance
luminanceKey
luminanceNoiseAmplitude
luminanceThresholds
luminanceValue
luminanceWeights
magentaColor
mainBundle
mainDevice
majorVersion
manualMax
manualMin
manualSegmentationGatingDecisionForSegmentationScores:
mapForSerialization
markActionAsPerformed:
markAsFinished
matteFilters
matteHistogramIndicatesSubjectDetected:
matteImage
matteImageBuffer
mattePureBackground
mattePureForeground
maxAutoAngle
maxAutoPitch
maxAutoStraighten
maxAutoYaw
maxDominantColors
maxFaceSize
maxSDOFRenderingVersionSupported
maximumApertureFocalRatio
maximumValue
media
mediaComponentType
mediaType
mediaTypeForComposition:
median
medianColor
metadata
metadataClockOverlapAcceptable
metadataConverter
metadataGroup
metadataItem
metadataItemsFromArray:filteredByIdentifier:
metadataItemsWithMetadataType:value:error:
metadataProcessor
metalCommandBuffer
metalDevice
metalKernelWithFunctionName:error:
metalLibraryData
metalRenderer
metalTexture
meteorGainMapExposureCompensationMode
minAutoStraighten
minimumAngleCorrection
minimumApertureFocalRatio
minimumConfidence
minimumPitchCorrection
minimumPitchCorrectionArea
minimumValue
minimumYawCorrection
minimumYawCorrectionArea
minorVersion
mipmapLevelCount
mismatchError:object:
missingError:object:
modalityAnalysisWithLimit:sampleMode:
mode
modeValue
modifyAdjustmentWithKey:modificationBlock:
morphologyMaximumFilter
morphologyMinimumFilter
motionBlurVectorFromMetadata:
multiplyCompositingFilter
mutableBytes
mutableBytesAtPoint:
mutableCopy
muteSchema
nFaces
name
nccKernel
ndcMetadataTransform
networkAccessAllowed
neutralKey
neutralTone
newAdjustmentWithIdentifier:
newAdjustmentWithName:
newCGImageFromBufferImage:
newCIImageFromBufferImage:
newComposition
newCompositionControllerWithComposition:
newHLGPixelBufferFromSDRImage:
newImageRenderClientWithName:
newLinearWideGamutColorSpace
newPhotosPipeline:
newPhotosPipelineAtSourceURL:error:
newPixelBufferOfSize:format:
newRenderJob
newRenderPipelineStateForEvaluationMode:
newRenderedPixelBufferFromImage:hasAlpha:error:
newStorageWithSize:format:
newTextureViewWithPixelFormat:textureType:levels:slices:
newTextureWithDescriptor:
newWatchInfillFromImage:mask:
nextFrame
nextInputFrame
nextTimedMetadataGroup
noCropFilter
noGeometryFilter
noMuteFilter
noOpRemovalFunctions
noOrientationFilter
noRedEyeFilter
noTrimFilter
node
nodeByApplyingFilterWithName:useHDRFilter:settingsAndInputs:
nodeByReplayingAgainstCache:error:
nodeByReplayingAgainstCache:pipelineState:error:
nodeFromCache:cache:
noiseReductionAdjustmentController
noiseReductionAdjustmentControllerCreatingIfNecessary:
noiseReductionSchema
nominalFrameRate
nonLocalizedFailureReason
nonVisualAdjustmentTypes
normalizeHueChromaImage:
normalizedClipRect
normalizedImagePoint
normalizedPoints
normalizedVisibleFrame
nose
nu_digest
nu_evaluateWithPipelineState:error:
nu_updateDigest:
nu_waitUntilCompletedAndReturnError:
null
numberValue
numberWithDouble:
numberWithFloat:
numberWithInt:
numberWithInteger:
numberWithLongLong:
numberWithUnsignedInteger:
numberWithUnsignedLong:
objectAtIndex:
objectAtIndexedSubscript:
objectForKey:
objectForKeyedSubscript:
objectFromData:withMajorVersion:minorVersion:
objectsAtIndexes:
observation
observations
offsetBlack
offsetBlackKey
offsetBrightness
offsetBrightnessKey
offsetCast
offsetCastKey
offsetContrast
offsetContrastKey
offsetExposure
offsetExposureKey
offsetHighlights
offsetHighlightsKey
offsetLocalLight
offsetLocalLightKey
offsetSaturation
offsetSaturationKey
offsetShadows
offsetShadowsKey
oneShotPortraitV2ExportFilter
oneToOneScalePolicy
open
openMask:withRadius:
optimizeForSharing
orientation
orientationAdjustmentControllerCreatingIfNecessary:
orientationAsMetaDataFilter
orientationSchema
orientedNode:withOrientation:
originalCleanAperture
originalCrop
originalLayout
originalSize
originalStyle
outputBackgroundImage
outputColorSpace
outputCropRect
outputExposureKey
outputForegroundImage
outputFormat
outputGeometry
outputImage
outputImage:
outputImageFB0
outputImageFB3
outputImageGeometry:
outputIsOpaque
outputMatteImage
outputNormalization
outputSettings
outputStreamWithURL:append:
outputTimedMetadataSampleWithIdentifier:atTime:error:
outputVideo
outputVideo:
outputVideoComposition:
overcaptureImageProperties:
overcaptureRectForAutoCrop:overcaptureVideoComplementSize:primarySize:CGRect:
overcaptureRectForStitchedOvercaptureSize:overcaptureVideoComplementSize:primarySize:autoLoopStabilizedCropRect:
overcaptureSource
overcaptureSourceFilter
overcaptureStatistics
overcaptureStatisticsKey
overwriteTrackingMetadataWithPlist:
pairingIdentifier
paletteColorForColor:
parallaxDisabled
parallaxInactiveFrame
parallaxLayoutConfigurationOverride
parallaxPaddingPct
parallaxScore
parallaxStrategy
parallaxStyleAvoidColorWashBrownOverride
parallaxStyleKeyLevelOverride
parallaxVisibleFrame
parameters
passesBuildingCheck:
passesConfidenceCheck:error:
passesFaceCheck:
passesImagePropertiesCheck:
passesMinimumCorrectionCheck:error:
pasteAdjustment:forMediaType:
pasteKeysForMediaType:
path
pathExtension
percentile:
performApertureRedeyeOnImage:useHDRFilter:redEyeAdjustment:
performHorizonCorrectionWithCompletion:
performLongExposureFusionForComposition:longExposureImage:useHDRFilter:error:
performNextActionWithCompletion:
performPerspectiveCorrectionWithCompletion:
performRedeyeOnImage:useHDRFilter:redEyeAdjustment:
performRequests:error:
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
performedActions
perspectiveErrorFromCoreImage:
perspectiveStraightenWithoutCropFilter
perspectiveTransformWithPitch:yaw:roll:imageRect:
petRegions
petsRegions
photoFeatureFlags:error:
photoProcessingFlagsFromProperties:error:
photosAutoEnhanceFiltersForImage:
photosCompositionSchema
photosSchema
pi_createColorCubeDataForFilters:dimension:colorSpace:
pi_grayColorResultValue
pi_imageByApplyingStabilizationWatermark
pi_valueWithGrayColorResult:
pipelineFiltersForCropping
pipelineFiltersForOriginalGeometry
pipelineFiltersForRAWShowingOriginalWithGeometry
pipelineFiltersForShowingOriginal
pipelineFiltersForShowingOriginalWithGeometry
pipelineStateForFunctionWithName:device:error:
pitch
pitchAngleDegrees
pitchKey
pitchRadians
pixelBasedIntermediateWithOverlapStrategy:intermediate:translationY:
pixelBuffer
pixelBufferToLumaChroma:pixelBuffer:outLuma:outChroma:read:write:
pixelEffectiveAcceptable
pixelFormat
platedFoodSceneLabel
platform
pointCount
pointValue
popDebugGroup
portraitAdjustmentController
portraitAdjustmentControllerCreatingIfNecessary:
portraitEffectInfoDictionaryFromFaceObservations:orientation:valuesAtCapture:
portraitEffectSchema
portraitInfo
portraitInfoDictionaryFromCameraMetadata:
portraitInfoDictionaryFromFaceObservations:metadata:orientation:valuesAtCapture:
portraitLightingEffectStrength
portraitMajorVersion
portraitMinorVersion
portraitStrength
portraitVideo:disparityInput:disparityKeyframes:apertureKeyframes:debugMode:error:
portraitVideoAdjustmentController
portraitVideoAdjustmentControllerCreatingIfNecessary:
portraitVideoDebugDetectedObjects:source:cinematographyState:monochrome:error:
portraitVideoSchema
postGeometryFilter
preGeometryFilter
predicateWithFormat:
preferredCropRect
pregateRulesSystemWithConstants:
preheatEditDependencies
prepare:
prepareAuxiliaryImagesFetchProperties:options:completion:
prepareForCIFilterWithFaces:cropRect:
prepareForPerformingRequests:error:
prepareImageExportRequest:options:completion:
prepareImagesForItem:renderer:layout:style:inputImage:matteImage:infillImage:foregroundImage:backgroundImage:
prepareNode
prepareNodeWithPipelineState:error:
prepareToRenderWithMetadata:
preserveSourceColorSpace
prewarmRendererForDevice:colorSize:disparitySize:quality:debugMode:globalRenderingMetadata:
primaryColor
primaryColors
primaryImageProperties:
primarySourceFilter
primaryURL
priority
priorityWithLevel:
processHorizonResult:
processPerspectiveResult:
processWithInputs:arguments:output:error:
properties
propertyListWithData:options:format:error:
propertyListWithStream:options:format:error:
proxyImage
proxyOnly
proxyScalePolicy
pxlMetadataTransform
radius
radiusKey
rangeMax
rangeMin
rangeOfCharacterFromSet:
rangeOfString:options:
ranges
rasterizeBrushStroke:atPoint:toBuffer:
rate
rawAdjustmentController
rawAdjustmentControllerCreatingIfNecessary:
rawAdjustmentWithRawImageProperties:
rawCameraSpaceProperties
rawFaceBalanceFilter
rawNoiseReductionAdjustmentController
rawNoiseReductionAdjustmentControllerCreatingIfNecessary:
rawNoiseReductionSchema
rawProperties
rawSchema
rawSourceFilterIncludingOrientation
rawState
rawToneCurveProperties
readBufferFromImage:withRGBAfBufferBlock:
readBufferInRegion:block:
readBufferRegion:withBlock:
readImageBufferFromURL:error:
readMetadataType:fromCGImageProperties:value:error:
rec709ColorSpace
recipe
recipeForIdentifier:
recipeIdentifier
recipeKey
rect
rectValue
recycleHLGPixelBuffer:
redEyeAdjustmentController
redEyeAdjustmentControllerCreatingIfNecessary:
redEyeSchema
redEyeSpotsWithCorrectionInfo:
redValue
reframeCropAdjustment
reframeVideoAdjustment
region
regionsFromDictionary:error:
registerPhotosSchema
registerRenderPipeline:forIdentifier:
registerSchemas:error:
registeredPhotosSchemaIdentifier
registrationRequest
releaseCachedResources
reloadSegmentationItemFromWallpaperURL:asset:completion:
remapPortraitV2Strength:portraitEffectKind:
removeAdjustmentWithKey:
removeAllObjects
removeAssetIdentifierFromMetadataArray:
removeItemAtURL:error:
removeObject:
removeObjectAtIndex:
removeObjectForKey:
removeObjectIdenticalTo:
render:error:
render:toBitmap:rowBytes:bounds:format:colorSpace:
renderCompanionResources
renderContext
renderImage:into:colorSpace:roi:imageSize:alpha:error:
renderImage:into:colorSpace:roi:imageSize:error:
renderImage:rect:toDestination:atPoint:error:
renderImagesWithRenderer:
renderInfo
renderNode
renderNodeFromSource:settings:error:
renderOnDevice:colorSize:disparitySize:quality:debugMode:globalRenderingMetadata:usingBlock:
renderPipelineForIdentifier:
renderPreviewLayerStackFromWallpaperURL:styleCategory:completion:
renderPriorityForResourcePriority:
renderQuality
renderScale
renderSize
renderState:matchesMetadata:
renderTask
renderTime
renderer:
renderingMetadataIdentifier
renderingVersion
renderingVersionAtCapture
renderingVersionFromAsset:error:
replaceAdjustment:withKey:
replaceObjectAtIndex:withObject:
requestLayout
requestVisionCleanUp
requireHardwareEncoder
requiresAudioMix
requiresVideoComposition
reset
resetAndEvaluateWithInitialState:
resetImageProperties:preserveRegions:
resetTag:input:error:
resolvedNodeWithCachedInputs:settings:pipelineState:error:
resolvedParameters
resolvedSourceDefinition
resource
resourceUnavailableError:object:
respondsToSelector:
responseQueue
result
resultLayersWithRenderer:
retain
retainCount
retouchSchema
retractFact:
returnStorage:
rgbColorWashDuoFixedKernel
rgbColorWashDuoKernel
rgbColorWashDuoVariableKernel
rightEye
roiForInput:arguments:outputRect:
roll
rollAngleDegrees
rowAverageFilter
rowBytes
rowElements
ruleWithBlockPredicate:action:
ruleWithPredicate:action:
ruleWithPredicate:assertingFact:grade:
ruleWithPredicate:retractingFact:grade:
sRGBColorSpace
sRGBLinearColorSpace
salientObjects
sampleAtTime:
sampleCount
sampleMode
sampleRect
sampleTime
sampledDisparityValue
samplerWithImage:
samplerWithImage:options:
samplesPerPass
saveAssetResourceToURL:error:
saveLayerStack:toURL:options:error:
saveSegmentationDataToURL:error:
saveSegmentationItem:layerStack:toWallpaperURL:error:
saveSegmentationItem:layerStackOptions:configuration:style:layout:toWallpaperURL:completion:
saveSegmentationItem:toURL:error:
saveToArchiveURL:error:
saveToURL:error:
scale
scaleForImageSize:
scaleHueKernel
scaleKey
scaleMultiplyOfScalar:
scaleNode:scale:error:
scalePolicy
scaleRect:scaleFactor:scaleCenter:
scaledExtent
scaledSize
scaledVector:
scene
sceneConfidenceKey
sceneLabelKey
schema
schemaForKey:
schemaWithIdentifier:
scoreAdjustmentWithUnscoredIntermediate:unsafeAreaOverlap:timeBottomOverlap:timeTopOverlap:
scoreIntermediate:
scores
screenSize
secondaryColor
segmentationBackground
segmentationClassification
segmentationCompositionForAssetResource:
segmentationCompositionForImageURL:fileUTI:orientation:proxyImage:
segmentationCompositionForProxyImage:orientation:
segmentationConfidenceMap
segmentationConfidenceMapImage
segmentationDataURL
segmentationDebugPreviewDisableClock
segmentationDebugPreviewHighQuality
segmentationDebugRoundTripProxyImage
segmentationDebugTintLayers
segmentationDisableCaching
segmentationDisabled
segmentationInfillAlgorithm
segmentationItem
segmentationLoaderForAsset:
segmentationManualGatingLenience
segmentationMatte
segmentationMatteImage
segmentationResourceURL
segmentationScore
segmentationScoreRanges
segmentationSourceForImageURL:fileUTI:orientation:proxyImage:
selectiveColorKernels
selectiveColorSchema
self
semanticEnhanceAdjustmentController
semanticEnhanceAdjustmentControllerCreatingIfNecessary:
sensorID
serializeComposition:versionInfo:error:
serializeComposition:versionInfo:serializerMetadata:error:
serializeDictionary:error:
serializeRecipe:
setAlignment:
setAllowSpillMatteOnOlderPortraitV2Captures:
setAllowedAnalysisTypes:
setAllowedCropFraction:
setAlphaCount:
setAlphaMode:
setAnalysisType:
setAnalyzeBackground:
setAngle:
setAngleRadians:
setAngleSeedDegreesCCW:
setAperture:
setApplyImageOrientationAsMetadata:
setApplyOrientationAsMetadata:
setApplyVideoOrientationAsMetadata:
setAssetIdentifier:
setAutoStraightenDominantAngleDiffThreshold:
setAutoStraightenVerticalAngleThreshold:
setAuxImages:
setAuxiliaryImageType:
setAuxiliaryImages:
setBackgroundBuffer:
setBackgroundColors:
setBackgroundImage:
setBackgroundLuminance:
setBaseURL:
setBoundingBoxesFromObservations:orientation:
setBounds:
setBypassOutputSettingsIfNoComposition:
setCache:
setCacheURL:
setCanHandleAdjustmentData:
setCanPropagateOriginalAuxiliaryData:
setCandidacy:
setChangeDelegate:
setChromaThreshold:
setCinematicAllowRGB10Packed:
setCinematicAllowYUVSourceInput:
setCinematographyScript:
setCinematographyState:
setClassification:
setCleanAperture:
setClientRequestedStop:
setClockColor:
setClockIntersection:
setClockLayerOrder:
setClockOverlapAcceptable:
setColor:
setColorAnalysis:
setColorPrimaries:
setColorSpace:
setColorSuggestions:
setColorType:
setColors:
setCompanionImageData:
setCompanionVideoURL:
setCompletedTrack:
setCompletionBlock:
setCompressionQuality:
setComputeDigest:
setComputePipelineState:
setConfidenceMapScore:
setConfidencePureBackground:
setConfidencePureForeground:
setConstants:
setConstraintHeight:
setConstraintWidth:
setConversionGain:
setCount:
setCountLimit:
setCropFraction:
setCropRect:
setCropScore:
setCrossfadeDuration:
setData:
setDataExtractor:
setDebugColorAnalysisBuffer:
setDebugColorAnalysisImage:
setDebugConfidenceMapBuffer:
setDebugConfidenceMapImage:
setDebugFilesEnabled:
setDebugFilesPrefix:
setDebugImageCollector:
setDebugInfillBuffer:
setDebugInfillImage:
setDebugInputBuffer:
setDebugInputImage:
setDebugIntermediateLayoutBuffers:
setDebugIntermediateLayoutImages:
setDebugLayoutBuffer:
setDebugLayoutImage:
setDebugLineDetectionImage:
setDebugLocalConfidenceBuffer:
setDebugLocalConfidenceImage:
setDebugMatteBuffer:
setDebugMatteCropBuffer:
setDebugMatteCropImage:
setDebugMatteImage:
setDebugMode:
setDebugPreviewBuffer:
setDebugPreviewImage:
setDebugRendering:
setDefaultLayout:
setDefaults
setDepthInfo:
setDepthVersionInfo:
setDestinationColor:
setDestinationURL:
setDigest:
setDisableDownload:
setDisableIntermediateCaching:
setDisableOnFrontFacingCameraImages:
setDisableOnPanos:
setDisableRendering:
setDisableSegmentation:
setDisparityKeyframes:
setDominanceThreshold:
setDominantColors:
setDominantGrays:
setDominantHues:
setDouble:forKey:
setDownloadProgressHandler:
setEdgeBleed:
setEditConfiguration:
setEnableLogging:
setEnabled:
setEndTime:
setError:
setEstimatedCenterMotion:
setEstimatedMotionBlur:
setEvaluatedForMode:
setExpandedBounds:
setExtent:
setExtentPolicy:
setFaceBoundingBoxesFromObservations:orientation:
setFaceI:
setFaceLocalConfidence:
setFaceObservationCache:
setFacePositionAcceptable:
setFaceQ:
setFaceSize:
setFaceStrength:
setFaceWarmth:
setFalloff:
setFalseColorHDR:
setFileType:
setFileURL:
setFinalizerError:
setFlattenedBackgroundForDebugPreview:
setFlattenedForegroundForDebugPreview:
setFlavor:
setFocalLenIn35mmFilm:
setFocusDistance:
setFontName:
setFontSize:
setForce:
setForceGlassesMatteOff:
setForceSpillMatteOff:
setForegroundBuffer:
setForegroundColors:
setForegroundImage:
setForegroundLuminance:
setFormat:
setFormatIdentifier:
setFormatVersion:
setFrameDuration:
setFromAdjustment:
setGenericCompletionBlock:
setGeometry:
setGlassesMatteAllowed:
setGrain:
setGrayI:
setGrayQ:
setGrayStrength:
setGrayWarmth:
setGrayY:
setGroundedScore:
setGuideImage:
setHeight:
setHistogramCalculationColorSpace:
setHueChromaImage:
setI:
setIdentifier:
setImage:
setImageExportFormat:
setImageFileURL:
setImageHistogram:
setImageOrientation:
setImageProperties:
setImageRect:
setImageSize:
setImageVariation:properties:error:
setInUse:
setInactiveRect:
setIncreaseBitRateIfNecessary:
setInfillAlgorithm:
setInfilledImage:
setInputAlgorithm:
setInputAlignmentExtent:
setInputAlignmentTransform:
setInputAperture:
setInputBackgroundImage:
setInputBlack:
setInputBlackDstBlue:
setInputBlackDstGreen:
setInputBlackDstRGB:
setInputBlackDstRed:
setInputBlackSrcBlue:
setInputBlackSrcGreen:
setInputBlackSrcRGB:
setInputBlackSrcRed:
setInputBlendMode:
setInputBlurImage:
setInputBoost:
setInputBrightness:
setInputCameraModel:
setInputCast:
setInputChromaMax:
setInputChromaMin:
setInputColor:
setInputColorPixelBuffer:
setInputColorSpace:
setInputContrast:
setInputCorrectionInfo:
setInputCorrections:
setInputDecoderVersion:
setInputDepthMap:
setInputDestinationImage:
setInputDisparityImage:
setInputDisparityPixelBuffer:
setInputEdgeDetail:
setInputExposure:
setInputFocusedDisparity:
setInputForegroundImage:
setInputGlobalRenderingMetadata:
setInputGrain:
setInputGuideImage:
setInputHasFace:
setInputHighlightColor:
setInputHighlights:
setInputHilightDstBlue:
setInputHilightDstGreen:
setInputHilightDstRGB:
setInputHilightDstRed:
setInputHilightSrcBlue:
setInputHilightSrcGreen:
setInputHilightSrcRGB:
setInputHilightSrcRed:
setInputHue:
setInputHueIsNormalized:
setInputHueRange:
setInputHueTarget:
setInputISO:
setInputImage:
setInputIntensity:
setInputIsHDR:
setInputIsRaw:
setInputLight:
setInputLocalLight:
setInputLumaRange:
setInputLumaTarget:
setInputMaskImage:
setInputMatteImage:
setInputMidDstBlue:
setInputMidDstGreen:
setInputMidDstRGB:
setInputMidDstRed:
setInputMidSrcBlue:
setInputMidSrcGreen:
setInputMidSrcRGB:
setInputMidSrcRed:
setInputMode:
setInputNeutralGamma:
setInputNormalization:
setInputOrigI:
setInputOrigQ:
setInputParameters:
setInputPointsB:
setInputPointsG:
setInputPointsL:
setInputPointsR:
setInputRawHighlights:
setInputRenderDebugMode:
setInputRenderQuality:
setInputRenderScale:
setInputSaturation:
setInputScaleFactor:
setInputSeed:
setInputShadowColor:
setInputShadowDstBlue:
setInputShadowDstGreen:
setInputShadowDstRGB:
setInputShadowDstRed:
setInputShadowSrcBlue:
setInputShadowSrcGreen:
setInputShadowSrcRGB:
setInputShadowSrcRed:
setInputShadows:
setInputSize:
setInputStillImage:
setInputStrength:
setInputTableImage:
setInputTargetImage:
setInputTemperature:
setInputThreshold:
setInputTint:
setInputTone:
setInputVectorsForFilter:
setInputVersion:
setInputVibrancy:
setInputVideoProperties:
setInputVideoScale:
setInputWarmTemp:
setInputWarmTint:
setInputWeights:
setInputWhiteDstBlue:
setInputWhiteDstGreen:
setInputWhiteDstRGB:
setInputWhiteDstRed:
setInputWhiteSrcBlue:
setInputWhiteSrcGreen:
setInputWhiteSrcRGB:
setInputWhiteSrcRed:
setInstructions:
setInteger:forKey:
setIntensity:
setIsAuto:
setIsDepthEnabled:
setIsInCloud:
setIsPerspectiveZoomEnabled:
setJPEGCompressionQuality:
setKeyFrameTime:
setKeyframeSequence:
setKeyframes:
setKind:
setLabel:
setLabelImageCache:
setLayerStack:
setLayerStackMode:
setLayerStackOptions:
setLayers:
setLayout:
setLayoutConfiguration:
setLayoutRegions:
setLoadingHandler:
setLoadingHandlerQueue:
setLoadingState:
setLocalConfidenceScore:
setLocalLightData:
setLoopTimeRange:
setLowMemoryModeEnabled:
setLuminance:
setLuminanceThresholds:
setLuminanceValue:
setLuminanceWeights:
setMaskImage:
setMatteImage:
setMattePureBackground:
setMattePureForeground:
setMaxAutoAngle:
setMaxAutoPitch:
setMaxAutoStraighten:
setMaxAutoYaw:
setMaxDominantColors:
setMaximumAperture:
setMedia:
setMediaType:
setMedianLuminance:
setMetadata:
setMetadataClockOverlapAcceptable:
setMetadataConverter:
setMetadataProcessor:
setMinAutoStraighten:
setMinimumAngleCorrection:
setMinimumAperture:
setMinimumConfidence:
setMinimumPitchCorrection:
setMinimumPitchCorrectionArea:
setMinimumYawCorrection:
setMinimumYawCorrectionArea:
setNFaces:
setName:
setNetworkAccessAllowed:
setNeutral:
setNormalizedClipRect:
setNormalizedImagePoint:
setNormalizedVisibleFrame:
setObject:forKey:
setObject:forKey:cost:
setObject:forKeyedSubscript:
setOffsetBrightness:
setOffsetCast:
setOffsetContrast:
setOffsetExposure:
setOffsetHighlights:
setOffsetLocalLight:
setOffsetSaturation:
setOffsetShadows:
setOptimizeForBackgroundProcessing:
setOptimizeForSharing:
setOptions:
setOriginalCrop:
setOriginalLayout:
setOutputSettings:
setOvercaptureSource:
setOvercaptureStatistics:
setPairingIdentifier:
setParallaxLayoutConfigurationOverride:
setParallaxScore:
setParallaxStyleAvoidColorWashBrownOverride:
setParallaxStyleKeyLevelOverride:
setParallaxWallpaperDisableUpgrade:
setParameters:
setPerformedActions:
setPerservesAlpha:
setPetsFaceRegions:
setPhotoFeatureFlags:properties:error:
setPhotoProcessingFlags:properties:error:
setPipelineFilters:
setPitch:
setPitchAngleDegrees:
setPitchRadians:
setPortraitInfo:
setPortraitMajorVersion:
setPortraitMinorVersion:
setPortraitStrength:
setPosterFrameTime:
setPreserveSourceColorSpace:
setPrimaryColor:
setPrimaryURL:
setPriority:
setProduceConfidenceMap:
setProgressHandler:
setProperties:
setProxyImage:
setProxyOnly:
setQ:
setRadius:
setRangeMax:
setRangeMin:
setRate:
setRawSensorHeight:
setRawSensorWidth:
setRawTime:
setReadNoise_1x:
setReadNoise_8x:
setRecipe:
setReframeCropAdjustment:
setReframeVideoAdjustment:
setRegionPolicy:
setRegions:
setRenderCompanionResources:
setRenderContext:
setRenderSize:
setRenderTime:
setRenderToData:
setRenderWithIOSurface:
setRenderingVersionAtCapture:
setRequest:
setRequireHardwareEncoder:
setRequiredSourceTrackIDs:
setResolutionRatio:
setResolvedSourceDefinition:
setResource:
setResponseQueue:
setResultHandlerQueue:
setRevision:
setRollAngle:constrainCropRectWithTargetArea:
setRollAngleDegrees:
setSDOFRenderingVersion:
setSampleMode:
setSampleRect:
setSampleTime:
setSampledDisparityValue:
setScale:
setScene:confidence:
setScores:
setSecondaryColor:
setSegmentationBackground:
setSegmentationClassification:
setSegmentationConfidenceMap:
setSegmentationConfidenceMapImage:
setSegmentationDataURL:
setSegmentationDebugPreviewDisableClock:
setSegmentationDebugPreviewHighQuality:
setSegmentationDebugRoundTripProxyImage:
setSegmentationDisableCaching:
setSegmentationDisabled:
setSegmentationManualGatingLenience:
setSegmentationMatte:
setSegmentationMatteImage:
setSegmentationScore:
setSegmentationType:
setShouldApplyWatermark:
setShouldCancelHandler:
setShouldInfillForeground:
setShouldPerformAutoCrop:
setShouldRunBuildingCheck:
setShouldUseAutoStraightenVerticalDetector:
setSize:
setSmart:
setSource:mediaType:
setSourceDisparity:
setSourceMode:
setSourceSelection:
setSourceTexture:
setSpillMatteAllowed:
setStabCropRect:
setStartTime:
setStateObject:forKey:
setStatistics:
setStillImage:
setStrength:
setStyle:
setStyleRecipeConfigDirectoryPath:
setSubjects:
setSystemBuildVersion:
setSystemName:
setSystemVersion:
setTask:
setText:
setTexture:atIndex:
setThreshold:
setTileSize:
setTime:
setTimeRange:
setTimedMetadata:
setTint:
setTonality:
setTone:
setTotalSensorCrop:
setTrajectoryHomography:
setTransferFunction:
setType:
setUpContext:
setUpdateClockAreaLuminance:
setUpdateClockZPosition:
setUpdateInactiveFrame:
setUsage:
setUseEmbeddedPreview:
setUseRGBA:
setUseStyleRecipeConfigDirectory:
setValue:
setValue:forKey:
setValue:forUndefinedKey:
setVersion:
setVideoCodecType:
setVideoComplementURL:
setVideoPosterFrameURL:
setVisibleFrame:
setVisionRequests:
setVisionSegmentationPolicy:
setVolume:atTime:
setVolumeRampFromStartVolume:toEndVolume:timeRange:
setWarmFace:
setWarmTemp:
setWarmTint:
setWarmth:
setWidth:
setWithArray:
setWithObject:
setY:
setYCbCrColorDepth:
setYCbCrFullRange:
setYawAngleDegrees:
setYawRadians:
set_availableStyles:
set_defaultStyles:
settingForAdjustmentKey:settingKey:
settingForKey:
settings
shapeWithRect:
sharedFactory
sharedPregateRules
sharedRegistry
sharpenAdjustmentController
sharpenAdjustmentControllerCreatingIfNecessary:
sharpenSchema
sharpnessWithIntensity:
shortValue
shouldAllowPerspectiveCorrection
shouldApplyWatermark
shouldCacheNodeForPipelineState:
shouldCancelHandler
shouldInfillForeground
shouldPerformAction:
shouldPerformAutoCrop
shouldPerformAutoStraighten
shouldRunBuildingCheck
shouldUseAutoStraightenVerticalDetector
shouldUseGainMapExposureCompensationForRawProperties:
shouldUseMetalRenderer
size
sizeInBytes
slomoAdjustmentController
slomoAdjustmentControllerCreatingIfNecessary:
slomoSchema
smart
smartBWAdjustmentController
smartBWAdjustmentControllerCreatingIfNecessary:
smartBlackAndWhiteAdjustmentsForValue:andStatistics:
smartBlackAndWhiteSchema
smartBlackAndWhiteStatistics
smartBlackWhiteKernel
smartColorAdjustmentController
smartColorAdjustmentControllerCreatingIfNecessary:
smartColorAdjustmentsForValue:andStatistics:
smartColorHDRStatistics
smartColorProperties
smartColorSchema
smartKey
smartToneAdjustmentController
smartToneAdjustmentControllerCreatingIfNecessary:
smartToneHDRStatistics
smartToneProperties
smoothWithFunction:windowSize:sampleMode:
socPseudoColorFilter
sortUsingComparator:
source
sourceDefinition:
sourceDefinitions
sourceFilterNoOrientation
sourceMode
sourceOutCompositingFilter
sourceSelectAdjustmentController
sourceSelectAdjustmentControllerCreatingIfNecessary:
sourceSelectSchema
sourceSelectionForString:
sourceSelectionKey
sourceTexture
sourceTransferFunction
sparseSequence
spatialOvercaptureVideoSourceFilter
spillMatteAllowed
spillMatteAllowedKey
stabCropRect
stabilizedCropRect
stackName
standardUserDefaults
start:
startKey
startReading
startReadingFrames:atTime:error:
startScaleKey
startTaskToRender:toDestination:error:
startTime
startTimeTimescaleKey
startTimeValueKey
state
statistics
statisticsKey
status
stillImage
stitchedOvercaptureRect:primaryRect:forComposition:error:
stopAtTagFilter:
stopAtTagIncludeOrientationFilter:
stopReadingFrames
straightenTransformWithAngle:extent:
strength
strengthKey
string
stringByAppendingFormat:
stringByAppendingString:
stringByDeletingPathExtension
stringByReplacingOccurrencesOfString:withString:
stringForColorType:
stringForKey:
stringForSourceSelection:
stringSettingForKey:defaultValue:
stringValue
stringWithFormat:
stringWithUTF8String:
stripAllTimeAdjustmentsFilter
strongToStrongObjectsMapTable
style
styleRecipeConfigDirectoryPath
styleWithBakedStyle:
styleWithColorAnalysis:
styleWithDictionary:error:
styleWithParameters:colorSuggestions:
subarrayWithRange:
subjects
subjectsFromMetadata:
submit:response:
submitGeneric:
submitGenericRequest:
submitGenericSynchronous:
submitRequest:
submitRequest:completion:
submitSynchronous:
submitSynchronous:error:
submitWithProgress:completion:
substringFromIndex:
suggestedColorForColor:
suggestedColorsForColors:fromColorPalette:
suggestedStyleForCategory:
suggestionAtIndex:
suggestionForColor:
suggestionIndices
sunriseSunsetSceneLabel
superclass
supportedIdentifiers
supportsANE
supportsManualClockIntersectionTolerance
supportsSecureCoding
supportsSegmentationResourceCaching
surfaceStoragePool
sushiLevel1Filter
synchronizeInputs
system
systemBuildVersion
systemName
systemVersion
tableImageFromRed:green:blue:luminance:
targetZoomFactorLimit
task
tempTintProperties
temperature
temperatureKey
textImageGeneratorFilter
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
textureType
threshold:
thresholdImage:withThreshold:
tightCropFrameFromMatteImage:
time
timeFrame
timeFromInputKey:timescaleKey:
timeIntervalSinceDate:
timeIntervalSinceReferenceDate
timeOverlapCheckBottom
timeOverlapCheckThresholdForTopRect:isInteractive:
timeOverlapCheckTop
timeRange
timeRect
timedMetadata
timedMetadataArray
tint
toDictionary
toRect
tonality
tone
tracks
tracksWithMediaType:
trajectoryHomography
trajectoryeHomographyFromMetadata:containsV3Metadata:
transformNodeWithInput:transform:error:
trimAdjustmentController
trimAdjustmentControllerCreatingIfNecessary:
trimInput:startTime:endTime:error:
trimSchema
trimToTimeRange:usingScript:
tryLoadSegmentationForColdAsset:
type
typeWithFilenameExtension:
typeWithIdentifier:
unarchivedObjectOfClasses:fromData:error:
unarchivedStyleRecipeWithURL:error:
underlyingAVDepthData
undoExifOrientation:error:
undoOrientation:forPitch:yaw:angle:
unionWith:
unit
unknownError:object:
unsafeAreaInImageSpaceWithVisibleFrame:
unsafeRect
unsignedIntValue
unsignedIntegerValue
unsupportedError:object:
updateClockAreaLuminance
updateClockPropertiesWithClockAreaLuminance:
updateClockZPosition
updateCropAdjustment:after:error:
updateCropAdjustmentController:after:error:
updateInactiveFrame
updateSegmentationResource:
upgradePosterConfiguration:atURL:exportTo:options:completion:
upgradeWallpaperAtURL:exportToURL:options:completion:
upsampleMatteImage:guideImage:
urlForIdentifier:
useAsCIImageWithOptions:renderer:block:
useAsCIRenderDestinationWithRenderer:block:
useSourceBuffersDirectly
useStyleRecipeConfigDirectory
userInfo
validRegion
validateAdjustmentsEnvelope:error:
validateComposition:error:
validateCompositionWithMissingSource:error:
validatedCompositionCopyForComposition:mediaType:
value
valueAtIndex:
valueForKey:
valueForUndefinedKey:
valueKey
valueWithBytes:objCType:
valueWithCMTime:
valueWithIdentifier:inGroup:ofClass:
valueWithRGBResult:
values
valuesAtCaptureFromImageProperties:error:
valuesForArrayInputKey:
variableName
variationForFlavor:
vectorWithCGPoint:
vectorWithCGRect:
vectorWithFloats:
vectorWithX:
vectorWithX:Y:
vectorWithX:Y:Z:
vectorWithX:Y:Z:W:
versionForPortraitEffect:
versionFromString:
versionKey
versionRules
versionWithMajor:minor:subMinor:platform:
videoAssetIsHighDynamicRange:
videoCodecType
videoComplementURL
videoCrossfadeLoop:crossfadeAdjustment:error:
videoCrossfadeLoopAdjustmentController
videoCrossfadeLoopAdjustmentControllerCreatingIfNecessary:
videoCrossfadeLoopSchema
videoFrames
videoMetadataForVariation:error:
videoMetadataSamples
videoPosterFrameAdjustmentController
videoPosterFrameAdjustmentControllerCreatingIfNecessary:
videoPosterFrameSchema
videoPosterFrameURL
videoProperties:
videoPropertiesRequestWithComposition:
videoReframe:reframes:error:
videoReframeAdjustmentController
videoReframeAdjustmentControllerCreatingIfNecessary:
videoReframeSchema
videoRenderRequestWithComposition:fitInSize:
videoSource
videoSourceWithURL:
videoStabilizeAdjustmentController
videoStabilizeAdjustmentControllerCreatingIfNecessary:
videoStabilizeSchema
vignetteAdjustmentController
vignetteAdjustmentControllerCreatingIfNecessary:
vignetteSchema
visibleFrame
visibleRect
waitForRender:
waitUntilCompletedAndReturnError:
waitUntilDone
wantsCompleteStage
wantsOutputGeometry
wantsOutputImage
wantsOutputVideo
wantsRenderScaleClampedToNativeScale
wantsRenderStage
warmColor
warmFace
warmFaceKey
warmTemp
warmTempKey
warmTint
warmTintKey
warmUp
warmUpClassificationDetectors
warmth
watchInfillImage:matte:
whiteBalanceAdjustmentController
whiteBalanceAdjustmentControllerCreatingIfNecessary:
whiteBalanceKernel
whiteBalanceSchema
whiteColor
whiteFactor
whiteValue
width
widthKey
withLenience:
workingColorSpace
wrapAsUnexpectedError:
write:
writeBufferInRegion:block:
writeCGImage:fileURL:
writeCGImage:fileURL:options:
writeDebugDiagnosticsToDisk
writeImage:fileURL:
writeImage:toDirectoryAtPath:withBasename:
writeImage:toTemporaryDirectoryWithBasename:
writeImageBuffer:toURL:error:
writeLongExposureImage:UTI:colorSpace:error:
writeMaskImage:UTI:error:
writeMetadataType:value:toCGImageProperties:error:
writePropertyList:toStream:format:options:error:
writeRecipe:toURL:error:
writeToTIFF:
writeToURL:atomically:
writeToURL:error:
writeToURL:mode:error:
xOriginKey
xValue
yOriginKey
yValue
yawKey
yawRadians
yellowColor
zone
zoomStrategy
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
@"<NURenderStatistics>"16@0:8
@"<NUImageBuffer>"16@0:8
v24@0:8@16
v16@0:8
@"<NUImageBuffer>"
@24@0:8@16
B24@0:8o^@16
@"NUStorageImageBuffer"
@"CIRenderTask"
@"CIImage"
@24@0:8^{_NSZone=}16
q16@0:8
v24@0:8@?16
v20@0:8B16
@"<NUScalePolicy>"
@"NUPixelFormat"
@"NUColorSpace"
@"PTCinematographyTrack"16@0:8
@"PTCinematographyTrack"
v76@0:8{?=qiIq}16{CGRect={CGPoint=dd}{CGSize=dd}}40f72
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
@?16@0:8
{CGPoint="x"d"y"d}
{?="value"q"timescale"i"flags"I"epoch"q}
@64@0:8@16{?=qiIq}24{CGPoint=dd}48
f16@0:8
v20@0:8f16
@40@0:8@16q24^{CGColorSpace=}32
@"PFStoryRecipeDisplayAssetNormalization"
B32@0:8@16@24
v24@0:8d16
d16@0:8
v32@0:8q16d24
v32@0:8@16q24
@20@0:8f16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@80@0:8@16{?=qiIq}24{CGRect={CGPoint=dd}{CGSize=dd}}48
@"NSNumber"
@160@0:8@16@24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40{CGSize=dd}72{CGRect={CGPoint=dd}{CGSize=dd}}88{CGRect={CGPoint=dd}{CGSize=dd}}120@152
@144@0:8Q16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56{CGRect={CGPoint=dd}{CGSize=dd}}72{CGRect={CGPoint=dd}{CGSize=dd}}104@136
@32@0:8Q16@24
@40@0:8Q16@24d32
@"CIContext"
@32@0:8@16o^@24
@"NSArray"16@0:8
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48@80@88
@"NSArray"
@96@0:8@16{CGSize=dd}24@40Q48@56@64^d72^d80^B88
v24@0:8Q16
@"NSString"
@"PFParallaxLayout"
@"<PFParallaxLayoutConfiguration>"
@"<PISegmentationItem>"
@32@0:8@16@24
v24@0:8q16
i20@0:8i16
B48@0:8@16@24@32^@40
v40@0:8@16@24@32
v32@0:8@16@24
@"<MTLTexture>"
@40@0:8@16@24o^@32
B40@0:8@16@24o^@32
@40@0:8@16@24@32
Q32@0:8@16@?24
Q24@0:8@16
@24@0:8Q16
@"NSIndexSet"
#24@0:8@16
v32@0:8@16@?24
B28@0:8@16B24
B36@0:8@16@24B32
B40@0:8@16@24@?32
@"NUComposition"
{?="hasDidAdd"B"hasDidRemove"B"hasDidUpdate"B"hasDidUpdateMultiple"B"hasClassForController"B}
@"NSDictionary"
@"<PICompositionControllerDelegate>"
@48@0:8@16@24@32o^@40
B32@0:8@16o^@24
@56@0:8@16@24@32@40o^@48
@44@0:8@16@24B32o^@36
B48@0:8@16@24@32o^@40
@36@0:8@16B24o^@28
@"NSData"
d40@0:8@16d24^B32
@32@0:8@16q24
{CGPoint=dd}72@0:8{CGPoint=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32q64
{CGPoint=dd}32@0:8r^{CGPoint=dd}16Q24
@56@0:8@16@24@32@40@48
@"NSURL"
{?={?=qq}{?=qq}}16@0:8
v48@0:8{?={?=qq}{?=qq}}16
{?="origin"{?="x"q"y"q}"size"{?="width"q"height"q}}
v32@0:8@16i24B28
i16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
@108@0:8@16@24@32@40@48@56@64@72@80@88B96o^@100
@"NUCVPixelBuffer"
@"PTGlobalRenderingMetadata"
@"PIPortraitVideoMetadataSample"
@24@0:8q16
@120@0:8@16{?={?=qiIq}{?=qiIq}}24{?=qiIq}72{?=qiIq}96
@24@0:8o^@16
{?={?=qiIq}{?=qiIq}}16@0:8
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
v40@0:8@16@24d32
{?=qiIq}32@0:8@16@24
@"NSMutableDictionary"
@"NUIdentifier"
@"NUAdjustment"
@"<PIParallaxFilterCache>"
@24@0:8d16
@"PFParallaxLayerStack"
@56@0:8@16@24@32@40q48
{?=qq}32@0:8{?=qq}16
i32@0:8{?=qq}16
^{__CVBuffer=}32@0:8@16o^@24
@"NSObject<OS_dispatch_group>"
@"NSObject<OS_dispatch_queue>"
@"<NUFaceDetectionResult>"
@"NSURL"24@0:8@"NSString"16
@"NSBundle"
q24@0:8@16
@"PFParallaxColor"
@"PFParallaxColor"16@0:8
v24@0:8@"PFParallaxColor"16
@48@0:8@16@24@32@40
@"PIParallaxStyleRecipe"
@48@0:8@16{?=qiIq}24
@24@0:8@"NSDictionary"16
@"NSDictionary"16@0:8
@48@0:8{?=qiIq}16d40
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@48@0:8q16q24q32d40
@"PFParallaxLayerStyle"24@0:8@"NSString"16
@"NUComposition"16@0:8
@"<PFParallaxAssetRegions>"16@0:8
@"PFParallaxLayout"16@0:8
@"<PFParallaxLayoutConfiguration>"16@0:8
@"PIParallaxColorAnalysis"16@0:8
@"PFParallaxLayerStyle"16@0:8
@"NSURL"16@0:8
B48@0:8@16^B24^B32o^@40
@"PFParallaxAssetResource"
@"<PFParallaxAssetRegions>"
@"PIParallaxColorAnalysis"
@"PISegmentationContextInfo"
@32@0:8@16#24
v72@0:8{?={?=qiIq}{?=qiIq}}16@64
v40@0:8d16d24@?32
@"NURuleSystem"
@88@0:8{?=qiIq}16{?=[3]}40
{?=[3]}16@0:8
{?="columns"[3]}
{?=[3]}40@0:8{?=qiIq}16
@"NUKeyframeSequenceMatrixFloat33"
{?=ffff}16@0:8
v32@0:8{?=ffff}16
@"<NUPurgeableStorage>"
@"NUImageHistogram"
{?="r"f"g"f"b"f"a"f}
@56@0:8@16d24d32d40o^@48
@"NUPurgeableStoragePool"
@"NSMutableArray"
@"AVAsset"
@72@0:8@16{?={?=qq}{?=qq}}24Q56@64
{?={?=qq}{?=qq}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{?={?=qq}{?=qq}}48d80d88
{?=ddd}56@0:8@16{?={?=qq}{?=qq}}24
@28@0:8@16B24
{?={?=[4d]}{?=[4d]}d}16@0:8
@88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=[4d]}16@0:8
@48@0:8{?=[4d]}16
B48@0:8{?=[4d]}16
{?=[4d]}48@0:8{?=[4d]}16
{?=[4d]}88@0:8{?={?=[4d]}{?=[4d]}d}16
{?=dd}104@0:8{?={?=[4d]}{?=[4d]}d}16@88d96
{?={?=[4d]}{?=[4d]}d}48@0:8@16@24d32@40
@"NUBufferRenderClient"
@"NUImageDataClient"
@32@0:8@16^@24
B40@0:8@16@24^@32
@"NSArray"32@0:8@16^@24
B40@0:8@16@"NSMutableDictionary"24^@32
@"NSNumber"32@0:8@"NSDictionary"16^@24
B40@0:8@"NSNumber"16@"NSMutableDictionary"24^@32
{?=qq}16@0:8
v32@0:8{?=qq}16
@"NUImageExportRequest"
{?="width"q"height"q}
@"NUImageGeometry"
@"NUPriority"
@"NUImageExportFormat"
v48@0:8@16@24@32@?40
v40@0:8@16@24@?32
@48@0:8@16@24@32@?40
@72@0:8@16@24@32@40@48@56@?64
@48@0:8@16@24@32^@40
v64@0:8@16@24@32@40@48@?56
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8q16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@48@0:8Q16Q24Q32@40
@40@0:8Q16Q24Q32
@"PFParallaxLayerStack"16@0:8
v40@0:8q16@24@?32
@"NSError"
@"PIParallaxStyle"
v64@0:8{?={?=qiIq}{?=qiIq}}16
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@32@0:8@16d24
@40@0:8@16{CGSize=dd}24
{PISegmentationBimodalScore=fff}24@0:8@16
f64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
f32@0:8@16@24
{PISegmentationClockOverlapResult=@Qdd}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64
{PISegmentationClockOverlapResult=@Qdd}76@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64B72
d64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
d88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64@72@80
d96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48@64@72^d80@88
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48{CGPoint=dd}56
d120@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{PISegmentationClockOverlapResult=@Qdd}64@96@104@112
d80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^B48@56@64@72
{CGRect={CGPoint=dd}{CGSize=dd}}96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48d64@72@80@88
{PISegmentationInactiveResult={CGRect={CGPoint=dd}{CGSize=dd}}{CGRect={CGPoint=dd}{CGSize=dd}}}92@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48B64@68@76@84
@104@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40{CGRect={CGPoint=dd}{CGSize=dd}}72
@112@0:8@16@24@32@40{CGRect={CGPoint=dd}{CGSize=dd}}48{CGRect={CGPoint=dd}{CGSize=dd}}80
@64@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32
@40@0:8@16Q24o^@32
@40@0:8@16I24I28o^@32
@40@0:8@16@24#32
@"PTTimedRenderingMetadata"
v84@0:8@16{?=qq}24{?=qq}40i56q60@68@?76
v76@0:8@16{?=qq}24{?=qq}40i56q60@68
@68@0:8@16{?=qq}24{?=qq}40i56q60
@"PTRenderPipeline"
@"<PTRenderState>"
@"<MTLDevice>"
@"NSDate"
v48@0:8q16^d24^d32^d40
@"PIFaceObservationCache"16@0:8
v24@0:8@"PIFaceObservationCache"16
v36@0:8@16@24B32
f24@0:8@16
B32@0:8{?=qq}16
B40@0:8@16{?=qq}24
@"PIFaceObservationCache"
B32@0:8{CGSize=dd}16
{?="exposure"d"contrast"d"brightness"d"shadows"d"highlights"d"black"d"rawHighlights"d"localLight"d}
@36@0:8@16@24B32
@52@0:8@16@24@32q40B48
@44@0:8@16{CGSize=dd}24B40
^{CGImage=}24@0:8@16
B32@0:8@16^q24
@40@0:8@16Q24^{CGColorSpace=}32
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48d56
@48@0:8{?=qq}16@32Q40
@64@0:8@16@24{?={?=qq}{?=qq}}32
B60@0:8@16i24^{CGColorSpace=}28@36@44o^@52
@"<NURenderer>"
@"<NUSurfaceStorage>"
@"NSObject<OS_dispatch_semaphore>"
@"VNImageHomographicAlignmentObservation"16@0:8
@"VNImageHomographicAlignmentObservation"
@64@0:8d16d24d32d40d48d56
B28@0:8{PISegmentationBimodalScore=fff}16
@44@0:8@16@24@32B40
@60@0:8@16@24B32{CGSize=dd}36q52
@"PTCinematographyScript"
@"NSCache"
@"CIColor"
^{CGColorSpace=}16@0:8
{vector<float, std::allocator<float>>=^f^f{__compressed_pair<float *, std::allocator<float>>=^f}}24@0:8@16
@48@0:8r^f16r^f24r^f32r^f40
@40@0:8@16{?=qq}24
@"NUFaceDetectionRequest"
v24@0:8@?<B@?@"NSURL">16
i40@0:8q16@24@?32
v20@0:8i16
i24@0:8@?16
i40@0:8q16@"PFParallaxAssetResourceOptions"24@?<v@?@"PFParallaxAssetResource"@"NSError">32
i24@0:8@?<v@?@"NSArray"@"NSArray"@"NSError">16
@68@0:8^v16Q24Q32q40Q48i56^{CGColorSpace=}60
@68@0:8@16Q24Q32q40Q48i56^{CGColorSpace=}60
^v16@0:8
^{CGColorSpace=}
@"NSMutableData"
v24@0:8^{?=Bffff[3f]}16
^f16@0:8
@24@0:8^f16
@32@0:8d16@24
Q32@0:8@16o^@24
^{__CVBuffer=}16@0:8
@"NUPixelFormat"16@0:8
@"NUColorSpace"16@0:8
@"CIRenderInfo"
@48@0:8@16@24d32@40
@"<NUImageBuffer>"36@0:8@"CIImage"16B24o^@28
@"PFParallaxLayer"48@0:8@"<NUImageBuffer>"16@"CIImage"24d32@"NSString"40
@"CIImage"32@0:8@"CIImage"16@"NSString"24
@"_PIParallaxLayerStackDebugImageCollector"
v88@0:8@16@24@32@40@48@56@64@72@80
@36@0:8@16B24#28
@20@0:8B16
@36@0:8d16d24B32
@104@0:8@16{?=[3]}24{CGRect={CGPoint=dd}{CGSize=dd}}72
@40@0:8@16@24d32
@"CIVector"
@32@0:8^{CGImage=}16q24
@48@0:8@16@24q32^{CGImage=}40
@72@0:8@16Q24@32@40@48@56@?64
@56@0:8@16@24@32Q40@?48
@40@0:8@16Q24^@32
@40@0:8@16@24@?32
v32@0:8@16Q24
v28@0:8B16@?20
v40@0:8@16q24@?32
@"NURenderContext"
@"PIParallaxSegmentationItem"
@"<PFParallaxAsset>"
B24@0:8Q16
@32@0:8q16@24
B32@0:8^{?={?=qq}{?=qq}}16o^@24
B48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{CGRect={CGPoint=dd}{CGSize=dd}}24@32o^@40
{CGRect={CGPoint=dd}{CGSize=dd}}96@0:8{?=qq}16{?=qq}32{?=qq}48{CGRect={CGPoint=dd}{CGSize=dd}}64
{?="p75"d"p98"d"autoValue"d"g98"d}
{?="sat"d"contrast"d"cast"d}
v36@0:8^f16f24f28f32
f24@0:8r^f16
d40@0:8d16d24d32
@64@0:8@16{?={?=qq}{?=qq}}24@56
@144@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{?=[3]}88@136
@"PIReframeKeyframeSequence"
@"<NUVideoProperties>"
v32@0:8{CGVector=dd}16
v64@0:8{?=[3]}16
{CGVector=dd}16@0:8
{CGVector="dx"d"dy"d}
@24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{CGVector=dd}24@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16
{?=[3]}32@0:8r^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16^B24
@"AVAssetTrack"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
B24@0:8d16
@48@0:8@16{CGPoint=dd}24d40
v56@0:8@16@24@32@40@?48
B32@0:8^{CGImage=}16@24
B40@0:8^{CGImage=}16@24@32
{?={?=qq}{?=qq}}40@0:8{CGPoint=dd}16d32
v40@0:8r^f16^S24Q32
v40@0:8r^S16^f24Q32
@48@0:8f16f20f24f28Q32{?=ii}40
{?=ii}16@0:8
v24@0:8{?=ii}16
{?="major"i"minor"i}
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@48@0:8@16@24q32@40
@52@0:8@16@24@32f40q44
@40@0:8@16q24@32
v128@0:8d16{?=qq}24{?={?=qq}{?=qq}}40{?={?=qq}{?=qq}}72^{?={?=qq}{?=qq}}104^{?={?=qq}{?=qq}}112^{?={?=qq}{?=qq}}120
@56@0:8@16{?={?=qq}{?=qq}}24
B56@0:8@16@24@32@40o^@48
v52@0:8@16@24{CGPoint=dd}32B48
^{CGImage=}32@0:8^{CGImage=}16^{CGImage=}24
@64@0:8@16@24@32@40q48o^@56
@52@0:8@16@24@32B40o^@44
@36@0:8@16B24@28
@64@0:8{?={?=qiIq}{?=qiIq}}16
^{__CVBuffer=}24@0:8^{CGImage=}16
B32@0:8@16^{__CVBuffer=}24
^{__CVBuffer=}32@0:8{CGSize=dd}16
v24@0:8^{__CVBuffer=}16
@32@0:8d16d24
{CGPoint=dd}44@0:8i16d20d28@36
ffffff
